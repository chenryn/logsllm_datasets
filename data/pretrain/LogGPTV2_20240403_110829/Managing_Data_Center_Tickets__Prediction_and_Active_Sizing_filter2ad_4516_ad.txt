### V. EVALUATION

We extensively evaluate ATM (Automatic Ticket Management) not only on a large number of data center production traces but also experimentally on a cluster running MediaWiki. Our focus is on demonstrating the effectiveness of ATM in reducing tickets, thereby improving system dependability and reducing the high costs associated with ticket resolution. In the following sections, we assume that usage tickets related to CPU and RAM are automatically issued when VM utilization exceeds 60%.

#### A. Production Systems

We analyze a subset of 400 boxes from the data center trace, which have no gaps in their traces. The remaining box traces suffer from occasional gaps with no data over the 7-day period. We demonstrate how different configurations of ATM can proactively reduce the number of tickets. We train the signature series for 5 days and then apply ATM and VM resizing for the subsequent day. It is important to note that this analysis is post-hoc; we cannot change the size of the actual VMs in the trace. Instead, we focus on the prediction accuracy and ticket reduction via ATM. In contrast, in the experimental evaluation on the MediaWiki cluster (Section V-B), we also illustrate VM resizing in a working system.

For the spatial models, we use DTW (Dynamic Time Warping) and CBC (Cluster-Based Clustering) techniques, setting the discretization factor \(\varepsilon = 5\). The temporal models used for the signature series are neural networks [7]. ATM predicts 16,000 usage series, each with 96 ticketing windows, where each window is 15 minutes long. After obtaining the predicted series, ATM triggers the resizing algorithm for each box to determine the near-optimal CPU and RAM capacity for all co-located VMs. The results presented here differ from those in Sections III and IV, where only the proposed spatial models and resizing algorithms were evaluated individually, excluding the temporal prediction models. Here, we present the full effect of both prediction models.

**1. Prediction Errors:**

Figure 9 shows the CDF of the prediction accuracy of ATM in terms of Absolute Percentage Error (APE) using different spatial models, i.e., DTW and CBC clustering. For CPU and RAM usage, we use the inter-resource model, where signature series are a mix of CPU and RAM. The average prediction errors for resource usage per box are 31% for DTW and 23% for CBC. These errors are only slightly higher than those without the temporal models, as presented in Section III. The figure also illustrates the CDF of the mean absolute errors for peak demands, i.e., usage higher than 60%. The average peak errors across all boxes are 20% for DTW and 17% for CBC, indicating that neural networks can effectively capture the temporal dynamics of the signature series.

We note that this high accuracy of temporal models is achieved with significant computational time and long historical data (5 days), whereas the prediction of dependent series via spatial models has a negligible cost. Additionally, the reduction in demand series for this subset of 400 boxes is similar to the results shown in Section III across 6,000 boxes.

**2. Ticket Reduction:**

Figure 10 compares the results of average ticket reduction using two different versions of ATM against the max-min fairness and stingy policies, as discussed in Section IV. Each bar represents the mean and standard deviation of ticket reduction across boxes, divided into CPU and RAM tickets. The key observations are as follows:

- Both versions of ATM achieve a higher ticket reduction, around 60% for CPU and 70% for RAM, compared to the other two heuristics.
- The standard deviation is high for all four strategies, indicating significant variability across boxes.
- Max-min fairness shows worse reduction results than the stingy policy, possibly due to the high variability across the chosen 400 boxes, which can even result in an increase in the number of tickets for a subset of the boxes.
- Max-min fairness favors small VMs while dissatisfying large VMs, leading to more ticket violations.
- Both versions of ATM achieve higher RAM ticket reductions due to higher RAM provisioning compared to CPU.

#### B. ATM on a MediaWiki Cluster

We experimentally evaluate our ticket reduction techniques on a cluster running MediaWiki, a latency-sensitive 3-tier web application. The application consists of Apache (v2.4.7) as the frontend, memcached (v1.4.14) as the in-memory key-value store, and MySQL (v5.5.40) as the database backend. The testbed includes four identical physical servers, each running Ubuntu Server 14.04 LTS, equipped with 16 GiB of DDR3 RAM, a 4-core Intel Core i7 3820 processor @ 3.6 GHz with SMT, one 2-TB SATA III 7200 rpm hard disk, and one Gigabit Ethernet adapter. Three servers host the VMs using QEMU-KVM (QEMU v2.0 with KVM on Linux kernel 3.13) as the hypervisor. Each VM comprises two virtual CPUs and 4 GiB of RAM. The fourth server acts as the experiment orchestrator and load generator. Each application tier is deployed into a separate VM.

We consider a scenario of hosting two MediaWiki applications, termed wiki-one and wiki-two, on these 4 physical servers. Wiki-one has 4 Apache servers, 2 Memcached, and 1 DB, while wiki-two has 2 Apache, 1 Memcached, and 1 DB. Each wiki has one load balancer that distributes requests across the different Apache front-ends. The workload generator creates requests alternating between low and high intensity periods, each lasting one hour.

**Figure 12** illustrates the CPU usage series across all VMs located on nodes 2, 3, and 4, with the ticketing threshold set to 60%. The figure shows CPU usage levels without and with ATM resizing. Resizing is very effective in maintaining CPU usage levels below the 60% threshold, resulting in a dramatic reduction in tickets from 49 to just 1.

**Figure 13** presents performance values for the two wiki applications, showing the average user latencies (response times) and average throughput. The results indicate that ATM not only reduces tickets but also maintains or improves the overall performance of the applications.

---

This revised version aims to make the text more coherent, professional, and easier to follow.