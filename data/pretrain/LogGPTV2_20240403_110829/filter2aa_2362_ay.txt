an input that forced a system to reboot. Only during the time required for the actual
reboot would the system be unavailable, but this is still a very critical issue. The
point is that the availability of the service needs to be checked frequently to avoid
missing such a situation.
167
6.1.2
File System–Related Problems
There are many security issues related to the interaction of an application and its
file system. One common scenario is that of a directory transversal attack. In this
scenario, the application is intended to provide access for a user to a file from the
file system. The files allowed to be opened reside in a particular directory. However,
in some scenarios, an attacker may be able to break out of this directory and view
arbitrary files on the system (with the permissions of the application). For example,
the attacker may request to view the file “../../../../../etc/passwd.” If the application
does not properly filter these directory transversal characters, arbitrary files may be
accessible, in this case the passwd file. Other file system–related problems include
injecting NULL characters into requested filenames and problems creating pre-
dictable temporary file names.
An example of the first two problems was demonstrated when an Adobe web
application revealed its private key when the following URL was requested1:
www.adobe.com/shockwave/download/download.cgi?P1_Prod_Version=../../../../..
/../../../..//usr/local/apache/conf/ssl.key/www.adobe.com.key%00
The application was vulnerable to a directory transversal problem and did not
check for the embedded NULL (otherwise it would only request documents with a
particular suffix).
These types of problems can be found by monitoring applications to see which
files they attempt to open and which ones they are successful in opening. This list
of files can be compared to rules that govern which files should be accessed by the
application. Any files opened that should not be allowed should be noted.
6.1.3
Metadata Injection Vulnerabilities
Another broad class of problems involves the injection of metadata into a process.
This can take many forms. The most common is called SQL injection. In this vul-
nerability, the application makes a request to a back-end SQL server. For example,
the attacker may supply “charlie’ or 1=1--” as a username variable to an applica-
tion. If the supplied metadata (in this case the apostrophe) is interpreted as SQL,
this could lead to bypassing the authentication of the application since the condi-
tion “1=1” is always true. Besides this example, SQL injection can be used to mod-
ify and destroy the database, access sensitive stored data, and even run remote code.
SQL injection is just one example of the injection of metadata. Other examples
including carriage return characters in HTTP requests, XML characters in XML
data, LDAP characters in LDAP data, and so on. One final example is a class of vul-
nerabilities known as command line injection vulnerabilities. Consider an applica-
tion that contains the following line of source code;
snprintf(command, sizeof(command), "unzip %s", user_supplied_filename);
system(command);
168
Target Monitoring
1www.theregister.co.uk/2007/09/27/adobe_website_leak/
These lines are intended to execute the “unzip” command on a user supplied
file name. However, the system function does this by forking and executing this
command in a shell. The shell has many metacharacters such as ;, |, >, etc. In this
case, if the user-supplied data is not properly filtered, an attacker could ask to have
the following file “a;rm -rf /” unzipped, which would result in the following com-
mand being passed to the shell
unzip a; rm -rf /
Obviously, this could lead to a problem. It can be difficult to detect the meta data
injection type of vulnerability. In the SQL injection example, a monitor could look for
certain types of errors being returned by the server. The command injection example
could be detected by monitoring the child processes of the target process. A more
sophisticated monitor would know which metadata the fuzzer was currently injecting
and then look for its use by the target application. This might involve monitoring
interprocess communication or debugging the target (or an associated process).
6.1.4
Memory-Related Vulnerabilities
The plague of computer security for the last 10 years has been the buffer overflow.
This common vulnerability has given rise to a flood of different worms and
exploits. At its core, a buffer overflow is an example of a broader class of memory-
related vulnerabilities. There are basically two types of memory-related problems
that can arise. The first is when the program allows memory reads that should not
be permitted. This can allow an attacker to read private information from the appli-
cation, including passwords, private keys, and other sensitive application data.
Additionally, metadata from the memory layout may be accessed. This information
may allow an attacker to better understand the layout of memory in the target
application, which may then allow exploitation (perhaps with a different vulnera-
bility) of a vulnerability that is otherwise difficult to exploit.
The other type of memory issue is when an application allows memory to be
written where it should not be allowed. This is typically the worse of the two as it
actually allows for memory corruption. In its most simple form, it may allow for the
change of application data, which may force authentication to wrongfully succeed.
Typically, this ability to write data into memory is used by an attacker to change the
flow of execution and run code supplied by the attacker, what is known as “arbi-
trary code execution.” The most trivial example of this is in the case of a stack
buffer overflow. In this scenario, a local buffer on the stack is overflowed with data
by an attacker. Near this stack buffer is metadata used by the process including the
return address for the current function. If this return address is overwritten with
attacker-supplied data, when the function returns, the attacker can control where
code execution will continue. In more complex examples, such as heap overflows
or wild pointer writes, other data may be overwritten, but the result is often the
same—that the attacker can get control of the execution flow.
As you’ve probably guessed, it is much harder to determine when memory cor-
ruption has occurred. Otherwise, the spread of worms and exploits would be
6.1
What Can Go Wrong and What Does It Look Like?
169
stopped. The problem is, applications typically read and write memory very fre-
quently and in mostly unpredictable ways. In a best (or worst) case scenario,
memory corruption will result in a program crash. This is easy to detect with either
a debugger or just by the availability of the application. However, this is not always
the case. Consider the case of a buffer overflow. The reason a program crashes
when a buffer is overflown is that other data, perhaps application data, perhaps
metadata, is corrupted. But, it is easy to imagine a situation in which a buffer is over-
flown by just a few bytes. Perhaps those few bytes are not used again or not in a
dangerous way. Perhaps different inputs would have caused more bytes to be over-
flown, which would lead to serious security problems. Either way, this can be very
difficult to detect if it does not cause a crash. There are ways, as we’ll see later, but
they all involve monitoring the way the program allocates, deallocates, and accesses
memory. At the very least, such intrusive methods will greatly slow down an appli-
cation, which can be a major issue when thousands of inputs need to be tested.
6.2
Methods of Monitoring
We discussed some of the different types of problems that can arise in a target sys-
tem and suggested some ideas on how we might monitor the target for them. The
types of monitoring that can be done will be highly dependent on the system being
fuzzed. Remember that fuzzing can be used for any system that accepts user input,
including applications, network devices, wireless receivers, cell phones, microchips,
even toasters. Clearly, the types of monitoring used on a program compiled from C
code running on Windows will be different than that of a Juniper router or a web
application written in Perl. That being said, we try to present solutions that would
work for all these situations and focus in on compiled applications where things
can get most interesting. In the next few sections, we go into more detail on exactly
how monitoring can be done and give examples of available software that we can
use when possible.
6.2.1
Valid Case Instrumentation
The most trivial method for detecting a problem when fuzz testing is to continually
check to ensure the service is still available. Consider a target application consist-
ing of a server that accepts TCP connections. In between each test case, a TCP con-
nection can be made with the server to ensure it is still responsive to network traffic.
Using this method, if a particular input caused the target to become unresponsive,
the fuzzer would immediately become aware of this fact. A slightly better method
is that in between test cases, a valid input can be sent and the response can be ana-
lyzed to ensure it remains unchanged. For example, if a web server is being fuzzed,
a valid HTTP page can be requested and the resulting page can be examined to
ensure that it is received exactly as expected. Likewise, the fuzzer may authenticate
to an FTP server being fuzzed to ensure that it is still possible to do this and this
action is performed in a timely manner.
Many fuzzers can perform this type of monitoring already. For example, the
PROTOS test suite that fuzzes the SNMP protocol has the option “-zerocase,”
170
Target Monitoring
which sends a valid test case after each fuzzed input to check if the target is still
responding. Here is an example,
C:\Documents and Settings\Charlie\Desktop>java -jar c06-snmpv1-req-
app-r1.jar -host 192.168.1.100 -zerocase
...
test-case #74: injecting meta-data 0 bytes, data 4139 bytes
waiting 100 ms for reply...0 bytes received
test-case #74: injecting valid case...
waiting 100 ms for reply...0 bytes received
test-case #74: No reply to valid case within 100 ms. Retrying...
waiting 200 ms for reply...ERROR: ICMP Port Unreachable
Here, PROTOS has detected that there has been a problem with the server since
it did not respond to the valid test case.
One of the biggest drawbacks to valid case monitoring is that only the most
catastrophic problems can be detected. Obviously, this method can detect when an
application becomes unresponsive. In some cases, if the application becomes
degraded, this can also be detected. However, these are the only situations in which
this monitoring will succeed. Even in cases when a fault is found that can actually
crash the target, this may not be evident with this monitoring method. For example,
consider a typically configured Apache web server. This server has one main process
that binds to port 80 and then spawns and manages a number of child processes.
These child processes actually handle the HTTP requests. Therefore, if an input
managed to cause a crash, it would be a crash of one of the child processes. By
design, the main process would then spawn additional child processes to replace
the process that crashed. The result would be that the web server would remain
completely responsive and functional to an outside user. It would be hard to detect
this fault using this method and know that a problem had been identified.
This ties in with how the applications to be fuzzed should be run. Whenever
possible, try to run the application with debugging symbols. Then, if it crashes,
it will be possible to tie any problems back to the line of source code where it
occurred. Likewise, many servers support debug logging, which will record many
internal messages and will help indicate the application state. Furthermore, appli-
cations that act as servers may have settings that allow them to run as a single
process or thread and not to daemonize. In the previous example regarding Apache,
if Apache was run with the “-X” option, it will not fork child processes or disasso-
ciate from the terminal. This means any crash will cause the whole Apache process
to go away and this would be detectable. Under this option, detection of faults
using valid test cases would be possible. Of course, in black-box situations, it is not
always possible to choose the way the application is configured.
6.2.2
System Monitoring
Only monitoring the target with valid test cases has severe limitations. When avail-
able, monitoring the system on which the target application runs can provide bet-
ter results. One powerful monitoring mechanism is simply watching application
6.2
Methods of Monitoring
171
Figure 6.1
A view of the files being accessed by the TiVoBeacon.exe executable.
and system logs. Well-written applications will log problems and internal inconsis-
tencies that they detect. Remember when we discussed how difficult it is to discover
when a crash occurs in a typically configured Apache web server, due to the robust
way it is architected? Simply watching the logs will quickly solve this problem,
[Sun Dec 16 20:54:15 2007] [notice] child pid 174 exit signal
Segmentation fault (11)
The main Apache process monitors and logs when one of its child processes
dies. Likewise, system logs may record information concerning system resource
exhaustion.
Another aspect of a process that should be monitored is its interaction with the
file system. By watching which files are being opened (both successfully and unsuc-
cessfully), directory transversal vulnerabilities may be discovered. Figure 6.1 is a
screenshot of the Filemon utility available from Microsoft.
On Linux, the strace utility can be used. The following code shows the trace of
the command “ls” filtering only on calls to the “open” function,
[cmiller@Linux ~]$ strace -eopen ls
open("/etc/ld.so.cache", O_RDONLY)
= 3
open("/lib/librt.so.1", O_RDONLY)
= 3
open("/lib/libacl.so.1", O_RDONLY)
= 3
open("/lib/libselinux.so.1", O_RDONLY)
= 3
open("/lib/libc.so.6", O_RDONLY)
= 3
open("/lib/libpthread.so.0", O_RDONLY)
= 3
open("/lib/libattr.so.1", O_RDONLY)
= 3
open("/lib/libdl.so.2", O_RDONLY)
= 3
open("/lib/libsepol.so.1", O_RDONLY)
= 3
open("/etc/selinux/config", O_RDONLY|O_LARGEFILE) = 3
open("/proc/mounts", O_RDONLY|O_LARGEFILE) = 3
open("/etc/ld.so.cache", O_RDONLY)
= 3
open("/lib/libsetrans.so.0", O_RDONLY)
= 3
open("/usr/lib/locale/locale-archive", O_RDONLY|O_LARGEFILE) = 3
open(".", O_RDONLY|O_NONBLOCK|O_LARGEFILE|O_DIRECTORY) = 3
open("/proc/meminfo", O_RDONLY)
= 3
172
Target Monitoring
By looking for differences in the output for various inputs, anomalies can be
detected. If the monitor is especially intelligent, it can look for filenames being opened
that contain data from the particular fuzzed input being used. Autodafé works in this
fashion, although it uses debugging mechanisms. Another option for monitoring the
interaction with the file system is using the Tripwire program. Tripwire takes crypto-
graphic hashes of each file specified and stores them in an offline database. Later, it
computes the hashes of the files again and compares them with the hashes stored in
the databases. Due to the nature of cryptographic hashes, any change to a file will be
seen by comparing the hashes taken with those stored in the database. Using this
method, it is easy to detect which files have changed during fuzzing.
Beyond files, the registry on Microsoft Windows controls the behavior of many
aspects of the system. Depending on the privilege level of the application being
tested, changes to particular (or arbitrary) registry entries may have security signif-
icance. There are many good tools for monitoring registry changes; one is Registry
Monitor by Microsoft. Figure 6.2 shows a screen shot.
Another possibility for target monitoring lies in watching the network connec-
tions and traffic generated by the target system. Again, by monitoring the types of
traffic and their contents, anomalies can be detected that indicate something
unusual has occurred. Furthermore, the traffic between an application and a back-
end database can be monitored (if unencrypted), and the SQL commands issued
can be examined. Likewise, by using strace, you can see the data in the traffic by
monitoring the write/send system calls,
[cmiller@Linux ~]$ strace -ewrite testprog
...
write(3, "\23\0\0\0\3select * from help", 23) = 23
Such methods can often detect many types of injection vulnerabilities.
6.2
Methods of Monitoring
173
Figure 6.2
Registry Monitor watching access to the registry.
Figure 6.3
Process Explorer reveals, among other things, the relationship between processes.
In order to try to detect command injection vulnerabilities, a similar approach
can be taken. In this case, we’re interested in processes being spawned. This can be
monitored with a GUI such as provided by Process Explorer from Windows (Fig-
ure 6.3).
Again, strace can be used for this purpose as well.
Finally, it is important to monitor memory consumption as well as the amount
of CPU being consumed by the target application to detect DoS conditions. The
heart of DoS is for the attacker to perform an act that is computationally inexpen-
sive, such as sending a packet, while the target has to do something expensive,
such as allocate and zero out a large amount of memory or perform a complex
calculation. Again, for Windows, Process Explorer can reveal these statistics (Fig-
ure 6.4).
On Linux, the ps command will reveal this information.
[cmiller@Linux ~]$ ps -C httpd u
USER
PID %CPU %MEM
VSZ 
RSS TTY STAT START TIME COMMAND
root
9343
0.0
1.1 23368 8836 ?
Ss
08:41 0:00 /usr/sbin/httpd
apache 9345
0.0
0.5 23368 3984 ?
S
08:41 0:00 /usr/sbin/httpd
apache 9346
0.0
0.5 23368 3984 ?
S
08:41 0:00 /usr/sbin/httpd
apache 9347
0.0
0.5 23368 3984 ?
S
08:41 0:00 /usr/sbin/httpd
apache 9348
0.0
0.5 23368 3984 ?
S
08:41 0:00 /usr/sbin/httpd
174
Target Monitoring
apache 9349
0.0
0.5 23368 3984 ?
S
08:41 0:00 /usr/sbin/httpd
apache 9350
0.0
0.5 23368 3984 ?
S
08:41 0:00 /usr/sbin/httpd
apache 9351
0.0
0.5 23368 3984 ?
S
08:41 0:00 /usr/sbin/httpd
apache 9352
0.0
0.5 23368 3984 ?
S