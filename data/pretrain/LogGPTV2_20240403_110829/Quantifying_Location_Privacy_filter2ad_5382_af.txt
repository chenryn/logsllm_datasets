### (b) K-anonymity vs. Incorrectness

**Figure 5. Comparison of Location-Privacy Metrics**

- **X-axis:** Users’ location privacy based on the incorrectness metric (LPLO-ATT(u, t)).
- **Y-axis:**
  - (a) Normalized entropy of the adversary’s estimation.
  - (b) Normalized k-anonymity.

Each point in the plot represents the location privacy of a user at a specific time for two metrics:
- (a) Incorrectness vs. entropy.
- (b) Incorrectness vs. k-anonymity.

- **"∗"** indicates location privacy values achieved from LPPM(2, 3, 0.9), a strong mechanism.
- **"·"** indicates values for LPPM(1, 2, 0.5), a medium mechanism.
- **"◦"** indicates values for LPPM(1, 0, 0.0), a weak mechanism.

The two metrics would be fully correlated only if all points were on the diagonal from (0, 0) to (1, 1).

### Focus on LO-ATT
We focus on LO-ATT and assess these metrics by testing the extent to which they correlate with the success of the adversary in correctly localizing users over time (i.e., LPLO-ATT(u, t)).

### LPPMs Used
- **LPPM(1, 0, 0.0):** Weak mechanism.
- **LPPM(1, 2, 0.5):** Medium mechanism.
- **LPPM(2, 3, 0.9):** Strong mechanism.

### Entropy as a Metric
In Section II-D, we use entropy to measure the uncertainty of the adversary. The normalized entropy of the probability distribution function (pdf) of the location of user \( u \) at time \( t \) is computed as follows:

\[
N HLO-ATT(u, t) = \frac{-\sum_{r \in R} \hat{p}_{u,t}(r) \log(\hat{p}_{u,t}(r))}{\log(M)}
\]

where \(\log(M)\) is the maximum entropy over \( M \) regions.

### K-anonymity as a Metric
According to the k-anonymity metric, the location privacy of a user \( u \) at a given time \( t \) is equal to the number of users who satisfy the following conditions:
- (i) They are anonymous.
- (ii) They obfuscate their location by merging regions that include their actual location.
- (iii) Their obfuscated location (i.e., the set of merged regions) is a superset of the obfuscated location of \( u \) at \( t \).

This number is divided by \( N \), the total number of users, to obtain the normalized k-anonymity:

\[
N KLO-ATT(u, t) = \frac{1}{N} \sum_{v \in U} 1_{a_v(t) \in o_u(t) \land o_u(t) \subseteq o_v(t)}
\]

### Correlation Analysis
Figure 5 illustrates the relationship between the incorrectness of the adversary (LPLO-ATT(u, t)) and the two metrics: normalized entropy (N HLO-ATT(u, t)) and normalized k-anonymity (N KLO-ATT(u, t)). We observe that entropy is more correlated with the adversary’s incorrectness than k-anonymity. However, both metrics misestimate the true location privacy of users.

- **Figure 5(a):** Most points fall into the region where \( N H > 0.5 \) and \( LP < 0.5 \), underestimating the location privacy. In some cases, where \( N K > 0.5 \) and \( LP < 0.5 \), it overestimates the location privacy. Thus, neither metric is an appropriate estimator for location privacy.

### Related Work
Several papers in the field of location privacy aim to clarify how to effectively protect users’ location privacy by classifying problems and studying various unaddressed issues and missing elements. These papers cover a range of concerns but highlight the following urgent topics:

- **Krumm [14]:** Studies computational location privacy schemes, emphasizing the accuracy of location privacy metrics as key to progress.
- **Decker [6]:** Provides an overview of location privacy threats and discusses the effects of various countermeasures.
- **Shokri et al. [21], [22]:** Survey various LPPMs and metrics, showing that entropy and k-anonymity are inadequate for measuring location privacy.
- **Duckham [7]:** Proposes key principles for research on location privacy, including the predictable mobility of humans and the importance of formal definitions.

These papers have inspired our research, but none provide a framework for quantitatively evaluating LPPMs. Our work realizes the goals and concerns of the research community by providing a modular platform for analyzing and improving various aspects, such as simulating more powerful attacks using other inference techniques.

### Specific Attacks and Privacy Concerns
- **Liao et al. [15]:** Develop an inference technique based on Markov Chain Monte Carlo (MCMC) methods to show the dependence of users’ activities on their mobility traces.
- **Bettini et al. [2]:** State that location traces can act as quasi-identifiers and propose a k-anonymity method for protection.
- **Hoh et al. [12] and Krumm [13]:** Focus on finding users’ identities based on home addresses and evaluate the effectiveness of protection mechanisms.
- **Mulder et al. [5]:** Show that anonymous location traces can be re-identified even at low space granularity and short time periods.
- **Golle and Partridge [10]:** Discuss the anonymity of home/work location pairs, showing that knowing these addresses can de-anonymize most users.
- **Freudiger et al. [9]:** Use advanced clustering algorithms to show privacy erosion over time.
- **Ma et al. [16]:** Show that published anonymous mobility traces can be identified using statistical inference methods.

### Conclusion
Our paper jointly considers obfuscation and anonymization methods and develops generic attacks that can be used against any LPPM. The proposed framework enables us to formalize and evaluate various LPPMs. To our knowledge, the Location-Privacy Meter is the first generic tool developed to evaluate location privacy of location traces.

### Acknowledgment
We thank George Danezis, Julien Freudiger, Prateek Mittal, Mathias Humbert, Mohamed Kafsi, and Vincent Bindschaedler for their valuable contributions and discussions.

### References
[References listed as provided in the original text.]