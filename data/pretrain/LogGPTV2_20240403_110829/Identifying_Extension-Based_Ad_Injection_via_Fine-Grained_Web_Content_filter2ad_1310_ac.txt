track the registration and execution of callback functions, the send request
and event modules were slightly modiﬁed in the extension engine. Speciﬁcally,
we added some code to map registered callbacks to their corresponding content
scripts in order to ﬁnd the extension responsible for DOM modiﬁcation.
4.3 Content Provenance Indicators
Given DOM provenance information, OriginTracer must ﬁrst (i) identify
when suspicious content modiﬁcations – e.g., extension-based ad injection – has
occurred, and additionally (ii) communicate this information to the user in an
easily comprehensible manner. To implement the ﬁrst requirement, our prototype
monitors for content modiﬁcations where a subtree of elements are annotated
426
S. Arshad et al.
with label sets that contains a particular extension’s label. This check can be
performed eﬃciently by traversing the DOM and inspecting element label sets
after a set of changes have been performed on the DOM.
Fig. 3. An example of indicator for an injected advertisement on amazon.com.
There are several possible options to communicate content provenance as
mentioned in Sect. 3. In our current prototype, provenance is indicated using a
conﬁgurable border color of the root element of the suspicious DOM subtree.
This border should be chosen to be visually distinct from the existing color
palette of the web page. Finally, a tooltip indicating the root label is displayed
when the user hovers their mouse over the DOM subtree. An example is shown in
Fig. 3. To implement these features, OriginTracer modiﬁes style and title
attributes. In addition, since OriginTracer highlights elements in an online
fashion, it must delay the addition of highlighting until the element is attached
to the page’s DOM and is displayed. Therefore, modiﬁcations were made to the
ContainerNode class that is responsible for attaching new elements to the
DOM.
While we did not exhaustively explore the design space of content prove-
nance indicators in this work (e.g., selective blocking of extension-based DOM
modiﬁcations), we report on the usability of the prototype implementation in
our evaluation.
5 Evaluation
In this section, we measure the eﬀectiveness, usability, and performance of con-
tent provenance indicators using the OriginTracer prototype. In particular,
the questions we aim to answer with this evaluation are:
(Q1) How susceptible are users to injected content such as third-party adver-
tisements? (Sect. 5.1)
Identifying Extension-Based Ad Injection
427
(Q2) Do provenance indicators lead to a signiﬁcant, measurable decrease in the
likelihood of clicking on third-party content that originates from exten-
sions? (Sect. 5.1)
(Q3) Are users likely to use the system during their normal web browsing?
(Sect. 5.2)
(Q4) Does integration of the provenance tracking system signiﬁcantly degrade
the users’ browsing experience and performance of the browser on a rep-
resentative sample of websites? (Sect. 5.3)
Ethics Statement. As part of the evaluation, we performed two experi-
ments involving users unaﬃliated with the project as described below. Due to
the potential risk to user conﬁdentiality and privacy, we formulated an experi-
mental protocol that was approved by our university’s institutional review board
(IRB). This protocol included safeguards designed to prevent exposing sensitive
user data such as account names, passwords, personal addresses, and ﬁnancial
information, as well as to protect the anonymity of the study participants with
respect to data storage and reporting. While users were not initially told the
purpose of some of the experiments, all users were debriefed at the end of each
trial as to the true purpose of the study.
5.1 Eﬀectiveness of the Approach
Similar to prior work [13], we performed a user study to measure the eﬀectiveness
of content provenance in enabling users to more easily identify unwanted third-
party content. However, we performed the user study with a signiﬁcantly larger
group of participants. The study population was composed of 80 students that
represent a range of technical sophistication. We conducted an initial brieﬁng
prior to the experiments where we made it clear that we were interested in honest
answers.
User Susceptibility to Ad Injection. The goal of the ﬁrst phase of the
experiment was to measure whether users were able to detect third-party content
that was not intended for inclusion by the publishers of web pages presented to
them. Users were divided into two equal sized groups of 40. In each group, users
were ﬁrst presented with three unmodiﬁed Chromium browsers, each of which
had a separate ad-injecting extension installed: Auto Zoom, Alpha Finder, and
X-Notiﬁer for the ﬁrst group, and Candy Zapper, uTorrent, and Gethoneybadger
for the second group. These extensions were chosen because they exhibit a range
of ad injection behaviors, from subtle injections that blend into the publisher’s
web page to very obvious pop-ups that are visually distinct from the publisher’s
content.
Using each browser, the participants were asked to visit three popular retail
websites: Amazon, Walmart, and Alibaba. Each ad-injecting extension monitors
for visits to these websites, and each injects three diﬀerent types of advertise-
ments into these sites. For each website, we asked the participants to examine
the page and tell us if they noticed any content in the page that did not belong
to the website – in other words, whether any content did not seem to originate
428
S. Arshad et al.
from the publisher. For each group, we aggregated the responses and presented
the percentage of correctly reported ad injection incidents for each extension in
Fig. 4.
The results demonstrate that a signiﬁcant number of Internet users often do
not recognize when ad injection occurs in the wild, even when told to look for
foreign content. For example, 34 participants did not recognize any injected ads
out of the three that were added to Amazon website by Auto Zoom extension.
Comparatively more users were able to identify ads injected by Alpha Finder and
X-Notiﬁer. We suspect the reason for this is because these extensions make use
of pop-up advertisements that are easier to recognize as out-of-place. However, a
signiﬁcant number of users nevertheless failed to note these pop-up ads, and even
after prompting stated that they thought these ads were part of the publisher’s
content. More generally, across all websites and extensions, many participants
failed to identify any injected ads whatsoever.
Fig. 4. Percentage of injected ads that are reported correctly by all the participants.
We then asked each participant whether they would click on ads in general
to measure the degree of trust that users put into the contents on the publisher’s
page. Speciﬁcally, we asked participants to rate the likelihood of clicking on ads
on a scale from one to ﬁve, where one means that they would never click on an
ad while ﬁve means that they would deﬁnitely click on an ad. We aggregated
the responses and present the results in Fig. 5a.
These results show that a signiﬁcant number of users, roughly half, would
click on advertisements that might not originate from the publisher, but that
were instead injected by an extension. This demonstrates the eﬀectiveness of
ad injection as a mechanism for diverting revenue from publishers to extension
authors. It also shows the potential eﬀectiveness of malicious extensions in using
content modiﬁcations to expose users to traditional malware.
Eﬀectiveness of Content Provenance Indicators. After the ﬁrst phase
of the experiment, we brieﬂy explained the purpose of OriginTracer and con-
tent provenance to the participants. Then, for each participant in each group, we
Identifying Extension-Based Ad Injection
429
Fig. 5. User study results. For each boxplot, the box represents the boundaries of the
ﬁrst and third quartiles. The band within each box is the median, while the black square
is the mean. The whiskers represent 1.5 IQR boundaries, and outliers are represented
as a + symbol.
picked one of the three ad-injecting extensions in which, the participant did not
detect most of the injected ads and installed it on a Chromium instance equipped
with OriginTracer. Then, each participant was asked to visit one of the three
retail websites by his choice and identify third-party content modiﬁcations – i.e.,
injected ads – with the help of provenance indicators. The results are shown
in Fig. 5b, where unassisted identiﬁcation is the aggregated number of reported
ad injections without any assistance in the presence of three ad-injecting exten-
sions across three retail websites, and assisted identiﬁcation is the number of
reported injected ads with the help of content provenance indicators. Results
are normalized to [0, 1].
These results clearly imply that users are more likely to recognize the presence
of third-party content modiﬁcations using provenance indicators. To conﬁrm
statistical signiﬁcance, we performed a hypothesis test where the null hypothesis
is that provenance indicators do not assist in identifying third-party content
modiﬁcations, while the alternative hypothesis is that provenance indicators do
assist in identifying such content. Using a paired t-test, we obtain a p-value of
4.9199 × 10−7, suﬃcient to reject the null hypothesis at a 1 % signiﬁcance level.
The outliers in assisted identiﬁcation are due to the fact that our ad highlighting
technique was not identiﬁable by a small number of participants. We believe that
using diﬀerent visual highlighting techniques would make it easier for users to
identify the injected ads.
Finally, we asked each participant how likely they would be to use the con-
tent provenance system in their daily web browsing. We asked participants to
rate this likelihood on a scale from one to ﬁve, where one means they would
never use the system and ﬁve means that they would always use it. The results
are shown in Fig. 5c, and indicate that most users would be willing to use a
content provenance system. The reason behind the outliers is because a few of
the participants stated that they do not need our system since they would not
click on any advertisements. However, we note that it can be diﬃcult to dis-
tinguish between advertisements and other legitimate content (e.g., products in
430
S. Arshad et al.
retail sites) and, consequently, users might be lured into clicking on ad content
injected by extensions.
Summary. From this user study, we draw several conclusions. First, we
conﬁrm that in many cases users are unable to distinguish injected third-party
content from publisher content. We also show that because users place trust
in publishers, they will often click on injected ads, and thus they tend to be
susceptible to ad injection. Our data shows that content provenance assists in
helping users distinguish between trusted publisher content and injected third-
party content that should not be trusted. Finally, we show that many users
would be willing to use the system based on their experience in this study.
5.2 Usability
We conducted another experiment on a separate population of users to mea-
sure the usability of the OriginTracer prototype. The user population was
composed of 13 students with diﬀerent technical background. We presented the
participants with OriginTracer integrated into Chromium 43, and asked them
to browse the web for several hours, visiting any websites of their choice. For
privacy reasons, however, we asked users to avoid browsing websites that require
a login or that involve sensitive subject matter (e.g., adult or ﬁnancial websites).
In addition, for each user, we randomly selected 50 websites from the Alexa Top
500 that satisfy our user privacy constraints and asked the user to visit them.
In particular, each participant was asked to browse at least three levels down
from the home page and visit external links contained in each site. Finally, to
gain some assurance that OriginTracer would not break benign extensions,
we conﬁgured the browser with the ﬁve high-proﬁle extensions list in Table 1.
During the browsing session, the browser was modiﬁed to record the number
of URLs visited. We also asked participants to record the number of pages in
which they encountered one of two types of errors. Type I errors are those where
the browser crashed, system error messages were displayed, pages would not load,
or the website was completely unusable for some other reason. Type II errors
include non-catastrophic errors that impact usability but did not preclude it –
e.g., the page took an abnormally long time to load, or the appearance of the
page was not as expected. We also asked users to report any broken functionality
for the benign extensions described above as well.
Out of close to 2,000 URLs, two catastrophic errors and 27 non-catastrophic
errors were encountered. However, we note that the majority of URLs rendered
and executed correctly. In addition, none of the participants reported any broken
extensions. We therefore conclude that the proposed approach is compatible with
modern browsers and benign extensions, and further work would very likely allow
the prototype to execute completely free of errors.
5.3 Performance
To measure the performance overhead of OriginTracer, we conﬁgured both
an unmodiﬁed Chromium browser and the prototype to automatically visit the
Identifying Extension-Based Ad Injection
431
Alexa Top 1 K. The Alexa Top 1 K covers many popular websites and is weighted
towards being representative of the sites that people use most often. By using
this test set, we ensured that each browser visited a broad spectrum of websites
that include both static and dynamic content, and especially websites that make
heavy use of third-party components and advertisements. Moreover, we conﬁg-
ured both browser instances with the ﬁve benign extensions discussed in Sect. 2
that change the DOM to measure performance in the presence of extensions. A
more detailed evaluation would analyze more pages on these websites to garner
a more realistic representation, but that is beyond the scope of the current work.
We built a crawler based on Selenium WebDriver [44] to automatically visit
the entire list of websites and recorded the total elapsed time from the beginning
of the browsing process until the entire list of websites was visited. Speciﬁcally,
our crawler moves to the next website in the list when the current website is
fully loaded, signiﬁed by the ﬁring of the onload event. In order to account for
ﬂuctuations in browsing time due to network delays and the dynamic nature of
advertisements, we repeated the experiment 10 times and measured the average
elapsed time. The average elapsed time for browsing the home pages of the Alexa
Top 1 K websites measured in this way is 3,457 s for the unmodiﬁed browser and
3,821 s for OriginTracer. Therefore, OriginTracer incurred a 10.5 % over-
head on browsing time on average. We also measured the delay imposed by
OriginTracer on startup time by launching the browser 10 times and mea-
suring the average launch time. OriginTracer did not cause any measurable
overhead on startup time.
While this overhead is not insigniﬁcant, we note that our user study in
Sect. 5.2 indicates that many users would be willing to trade oﬀ actual per-
ceived performance overhead against the security beneﬁts provided by the sys-
tem. Moreover, this prototype is just a proof-of-concept implementation of our
system and there is still room for optimizing the implementation to decrease the
page load time.
6 Related Work
6.1 Malicious Advertising
Substantial research on malicious advertisements has focused on isolation and