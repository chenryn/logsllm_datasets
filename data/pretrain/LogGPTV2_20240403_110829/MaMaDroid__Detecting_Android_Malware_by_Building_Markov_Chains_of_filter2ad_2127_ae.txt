As discussed in Section III, the use of API calls changes
over time, and in different ways across malicious and benign
samples. From our newer datasets, which include samples up
to Spring 2016 (API level 23), we observe that newer APIs
introduce more packages, classes, and methods, while also
deprecating some. Fig. 6, 7(a), and 7(b) show that benign apps
are using more calls than malicious ones developed around
the same time. We also notice an interesting trend in the use
of Android and Google APIs: malicious apps follow the same
trend as benign apps in the way they adopt certain APIs, but
with a delay of some years. This might be a side effect of
Android malware authors’ tendency to repackage benign apps,
adding their malicious functionalities onto them.
Given the frequent changes in the Android framework
and the continuous evolution of malware, systems like
DROIDAPIMINER [2] – being dependent on the presence or
the use of certain API calls – become increasingly less effective
with time. As shown in Table III, malware that uses API calls
released after those used by samples in the training set cannot
be identiﬁed by these systems. On the contrary, as shown in
Fig. 11 and 12, MAMADROID detects malware samples that
are 1 year newer than the training set obtaining an 86% F-
measure (as opposed to 46% with DROIDAPIMINER). After 2
years, the value is still at 75% (42% with DROIDAPIMINER),
dropping to 51% after 4 years.
12http://www.appbrain.com/stats/number-of-android-apps
We argue that the effectiveness of MAMADROID’s classiﬁ-
cation remains relatively high “over the years” owing to Markov
models capturing app behavior. These models tend to be more
robust to malware evolution because abstracting to families or
packages makes the system less susceptible to the introduction
of new API calls. Abstraction allows MAMADROID to capture
newer classes/methods added to the API, since these are
abstracted to already-known families or packages. In case newer
packages are added to the API, and these packages start being
used by malware, MAMADROID only requires adding a new
state to the Markov chains, and probabilities of a transition
from a state to this new state in old apps would be 0. Adding
only a few nodes does not likely alter the probabilities of the
other 341 nodes, thus, two apps created with the same purpose
will not strongly differ in API calls usage if they are developed
using almost consecutive API levels.
We also observe that abstracting to packages provides a
slightly better tradeoff than families. In family mode, the system
is lighter and faster, and actually performs better when there
are more than two years between training and test set samples
However, even though both modes of operation effectively
detect malware, abstracting to packages yields better results
overall. Nonetheless, this does not imply that less abstraction
is always better: in fact, a system that is too granular, besides
incurring untenable complexity, would likely create Markov
models with low-probability transitions, ultimately resulting
in less accurate classiﬁcation. We also highlight that applying
PCA is a good strategy to preserve high accuracy and at the
same time reducing complexity.
B. Evasion
Next, we discuss possible evasion techniques and how they
can be addressed. One straightforward evasion approach could
be to repackage a benign app with small snippets of malicious
code added to a few classes. However, it is difﬁcult to embed
malicious code in such a way that, at the same time, the
resulting Markov chain looks similar to a benign one. For
instance, our running example from Section II (malware posing
as a memory booster app and executing unwanted commands
as root) is correctly classiﬁed by MAMADROID; although most
functionalities in this malware are the same as the original app,
injected API calls generate some transitions in the Markov
chain that are not typical of benign samples.
The opposite procedure – i.e., embedding portions of benign
code into a malicious app – is also likely ineffective against
MAMADROID, since, for each app, we derive the feature vector
from the transition probability between calls over the entire
app. In other words, a malware developer would have to embed
benign code inside the malware in such a way that the overall
sequence of calls yields similar transition probabilities as those
in a benign app, but this is difﬁcult to achieve because if the
sequences of calls have to be different (otherwise there would
be no attack), then the models will also be different.
An attacker could also try to create an app from scratch
with a similar Markov chain to that of a benign app. Because
this is derived from the sequence of abstracted API calls in the
app, it is actually very difﬁcult to create sequences resulting
in Markov chains similar to benign apps while, at the same
time, actually engaging in malicious behavior. Nonetheless, in
11
future work, we plan to systematically analyze the feasibility
of this strategy.
dimensions of the features space where the classiﬁer operates
is remarkably reduced.
Moreover, attackers could try using reﬂection, dynamic
code loading, or native code [42]. Because MAMADROID uses
static analysis, it fails to detect malicious code when it is
loaded or determined at runtime. However, MAMADROID can
detect reﬂection when a method from the reﬂection package
(java.lang.reflect) is executed. Therefore, we obtain the
correct sequence of calls up to the invocation of the reﬂection
call, which may be sufﬁcient to distinguish between malware
and benign apps. Similarly, MAMADROID can detect the
usage of class loaders and package contexts that can be used
to load arbitrary code, but it is not able to model the code
loaded; likewise, native code that is part of the app cannot be
modeled, as it is not Java and is not processed by Soot. These
limitations are not speciﬁc of MAMADROID, but are a problem
of static analysis in general, which can be mitigated by using
MAMADROID alongside dynamic analysis techniques.
Malware developers might also attempt to evade MA-
MADROID by naming their self-deﬁned packages in such a way
that they look similar to that of the android, java, or google
APIs, e.g., creating packages like java.lang.reﬂect.malware
and java.lang.malware, aiming to confuse MAMADROID into
abstracting them to respectively, java.lang.reflect and
java.lang. However, this is easily prevented by whitelisting
the list of packages from android, java, or google APIs.
Another approach could be using dynamic dispatch so that
a class X in package A is created to extend class Y in package
B with static analysis reporting a call to root() deﬁned in Y as
X.root(), whereas, at runtime Y.root() is executed. This can be
addressed, however, with a small increase in MAMADROID’s
computational cost, by keeping track of self-deﬁned classes
that extend or implement classes in the recognized APIs, and
abstract polymorphic functions of this self-deﬁned class to the
corresponding recognized package, while, at the same time,
abstracting as self-deﬁned overridden functions in the class.
Finally, identiﬁer mangling and other forms of obfuscation
could be used aiming to obfuscate code and hide malicious
actions. However, since classes in the Android framework
cannot be obfuscated by obfuscation tools, malware developers
can only do so for self-deﬁned classes. MAMADROID labels
obfuscated calls as obfuscated so, ultimately, these would
be captured in the behavioral model (and the Markov chain)
for the app. In our sample, we observe that benign apps use
signiﬁcantly less obfuscation than malicious apps, indicating
that obfuscating a signiﬁcant number of classes is not a good
evasion strategy since this would likely make the sample more
easily identiﬁable as malicious.
C. Limitations
MAMADROID requires a sizable amount of memory in
order to perform classiﬁcation, when operating in package mode,
working on more than 100,000 features per sample. The quantity
of features, however, can be further reduced using feature
selection algorithms such as PCA. As explained in Section IV
when we use 10 components from the PCA the system performs
almost as well as the one using all the features; however, using
PCA comes with a much lower memory complexity in order
to run the machine learning algorithms, because the number of
Soot [52], which we use to extract call graphs, fails to
analyze some apks. In fact, we were not able to extract call
graphs for a fraction (4.6%) of the apps in the original datasets
due to scripts either failing to apply the jb phase, which is
used to transform Java bytecode to the primary intermediate
representation (i.e., jimple) of Soot or not able to open the
apk. Even though this does not really affect the results of
our evaluation, one could avoid it by using a different/custom
intermediate representation for the analysis or use different
tools to extract the call graphs.
In general, static analysis methodologies for malware
detection on Android could fail to capture the runtime en-
vironment context, code that is executed more frequently, or
other effects stemming from user input [5]. These limitations
can be addressed using dynamic analysis, or by recording
function calls on a device. Dynamic analysis observes the live
performance of the samples, recording what activity is actually
performed at runtime. Through dynamic analysis, it is also
possible to provide inputs to the app and then analyze the
reaction of the app to these inputs, going beyond static analysis
limits. To this end, we plan to integrate dynamic analysis to
build the models used by MAMADROID as part of future work.
VI. RELATED WORK
Over the past few years, Android security has attracted a
wealth of work by the research community. In this section,
we review (i) program analysis techniques focusing on general
security properties of Android apps, and then (ii) systems that
speciﬁcally target malware on Android.
A. Program Analysis
Previous work on program analysis applied to Android
security has used both static and dynamic analysis. With
the former, the program’s code is decompiled in order to
extract features without actually running the program, usually
employing tools such as Dare [41] to obtain Java bytecode. The
latter involves real-time execution of the program, typically in
an emulated or protected environment.
Static analysis techniques include work by Felt et al. [21],
who analyze API calls to identify over-privileged apps, while
Kirin [20] is a system that examines permissions requested
by apps to perform a lightweight certiﬁcation, using a set
of security rules that indicate whether or not the security
conﬁguration bundled with the app is safe. RiskRanker [28]
aims to identify zero-day Android malware by assessing
potential security risks caused by untrusted apps. It sifts
through a large number of apps from Android markets and
examines them to detect certain behaviors, such as encryption
and dynamic code loading, which form malicious patterns and
can be used to detect stealthy malware. Other methods, such
as CHEX [37], use data ﬂow analysis to automatically vet
Android apps for vulnerabilities. Static analysis has also been
applied to the detection of data leaks and malicious data ﬂows
from Android apps [6], [34], [35], [62].
DroidScope [59] and TaintDroid [19] monitor run-time app
behavior in a protected environment to perform dynamic taint
analysis. DroidScope performs dynamic taint analysis at the
12
machine code level, while TaintDroid monitors how third-party
apps access or manipulate users’ personal data, aiming to detect
sensitive data leaving the system. However, as it is unrealistic to
deploy dynamic analysis techniques directly on users’ devices,
due to the overhead they introduce, these are typically used
ofﬂine [45], [50], [67]. ParanoidAndroid [44] employs a virtual
clone of the smartphone, running in parallel in the cloud and
replaying activities of the device – however, even if minimal
execution traces are actually sent to the cloud, this still takes a
non-negligible toll on battery life.
Recently, hybrid systems like IntelliDroid [56] have also
been proposed that use input generators, producing inputs
speciﬁc to dynamic analysis tools. Other work combining static
and dynamic analysis include [8], [25], [31], [58].
B. Android Malware Detection
A number of techniques have used signatures for Android
malware detection. NetworkProﬁler [18] generates network
proﬁles for Android apps and extracts ﬁngerprints based on such
traces, while work in [12] obtains resource-based metrics (CPU,
memory, storage, network) to distinguish malware activity from
benign one. Chen et al. [15] extract statistical features, such
as permissions and API calls, and extend their vectors to add
dynamic behavior-based features. While their experiments show
that their solution outperforms, in terms of accuracy, other
antivirus systems, Chen et al. [15] indicate that the quality of
their detection model critically depends on the availability of
representative benign and malicious apps for training. Similarly,
ScanMe Mobile [64] uses the Google Cloud Messaging Service
(GCM) to perform static and dynamic analysis on apks found
on the device’s SD card.
The sequences of system calls have also been used to detect
malware in both desktop and Android environments. Hofmeyr
et al. [30] demonstrate that short sequences of system calls
can be used as a signature to discriminate between normal
and abnormal behavior of common UNIX programs. Signature-
based methods, however, can be evaded using polymorphism
and obfuscation, as well as by call re-ordering attacks [36], even
though quantitative measures, such as similarity analysis, can
be used to address some of these attacks [48]. MAMADROID
inherits the spirit of these approaches, proposing a statistical
method to model app behavior that is more robust against
evasion attempts.
In the Android context, Canfora et al. [11] use the sequences
of three system calls (extracted from the execution traces of
apps under analysis) to detect malware. This approach models
speciﬁc malware families, aiming to identify additional samples
belonging to such families. In contrast, MAMADROID’s goal
is to detect previously-unseen malware, and we also show that
our system can detect new malware families that even appear
years after the system has been trained. In addition, using strict
sequences of system or API calls can be easily evaded by
malware authors who could add unnecessary calls to effectively
evade detection. Conversely, MAMADROID builds a behavioral
model of an Android app, which makes it robust to this type
of evasion.
be inadequate due to the low probability of triggering malicious
behavior, and can be side-stepped by knowledgeable adversaries,
as suggested by Wong and Lie [56]. Other approaches include
random fuzzing [38], [63] and concolic testing [3], [26].
Dynamic analysis can only detect malicious activities if the code
exhibiting malicious behavior is actually running during the
analysis. Moreover, according to [54], mobile malware authors
often employ emulation or virtualization detection strategies to
change malware behavior and eventually evade detection.
Aiming to complement static and dynamic analysis tools,
machine learning techniques have also been applied to assist
Android malware detection. Droidmat [57] uses API call tracing
and manifest ﬁles to learn features for malware detection,
while Gascon et al. [24] rely on embedded call graphs. Droid-
Miner [60] studies the program logic of sensitive Android/Java
framework API functions and resources, and detects malicious
behavior patterns. MAST [14] statically analyzes apps using
features such as permissions, presence of native code, and intent
ﬁlters and measures the correlation between multiple qualitative
data. Crowdroid [10] relies on crowdsourcing to distinguish
between malicious and benign apps by monitoring system calls.
AppContext [61] models security-sensitive behavior, such as
activation events or environmental attributes, and uses SVM
to classify these behaviors, while RevealDroid [23] employs
supervised learning and obfuscation-resilient methods targeting
API usage and intent actions to identify their families.
DREBIN [5] automatically deduces detection patterns and
identiﬁes malicious software directly on the device, performing
a broad static analysis. This is achieved by gathering numerous
features from the manifest ﬁle as well as the app’s source code
(API calls, network addresses, permissions). Malevolent behav-
ior is reﬂected in patterns and combinations of extracted features
from the static analysis: for instance, the existence of both
SEND_SMS permission and the android.hardware.telephony
component in an app might indicate an attempt to send premium
SMS messages, and this combination can eventually constitute
a detection pattern.
In Section IV, we have already introduced, and compared
against, DROIDAPIMINER [2]. This system relies on the top-
169 API calls that are used more frequently in the malware than
in the benign set, along with data ﬂow analysis on calls that
are frequent in both benign and malicious apps, but occur up
to 6% more in the latter. As shown in our evaluation, using the
most common calls observed during training requires constant
retraining, due to the evolution of both malware and the Android
API. On the contrary, MAMADROID can effectively model both