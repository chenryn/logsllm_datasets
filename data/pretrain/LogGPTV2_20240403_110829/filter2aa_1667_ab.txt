If we indiscriminately spam everyone on Twitter with phishing links, we would quickly be 
discovered and have our accounts terminated due to ToS violations. Therefore, we triage users 
to determine which ones are either more likely to be phished or provide exceptional value. 
We first cluster users into groups based on their profiles, using data such as the amount of 
information revealed in their profile, follower interactions, and engagement metrics. Further, if 
any information on their profile indicates that they would be a high­value target (such as job 
titles, particular list membership, and popularity), we use that data as well. 
Using the clusters, we collect users from the Twitter Firehose and predict which cluster the user 
fits into. If they fit into a cluster displaying features identified as likely to lead to a successful 
phish, they are selected as a target, and recon for automated profiling is performed. Features 
extracted from their timeline include: 
1.
How frequently do they post? When are they likely to respond? 
2.
What topics do they tend to tweet about or respond to? 
We have also considered the following features: 
3.
What is the sentiment on those topics? 
4.
Can we extract their location from geotagged media? 
5.
Can we find any patterns of behavior? 
6.
Can we find any large events they’ve gone to recently or plan to go to in the future? 
We use these features as parameters to determine when to post the tweet and how to seed the 
model. 
4 
Automated Spear Phishing 
After a target is determined, we send them a machine­generated tweet with either an embedded 
link or a DEFCON SECTF question. To generate tweets, we use both Markov Models [6] and 
Long Short­Term Memory (LSTM) recurrent neural networks [8].  
Markov models generate text word by word based on probabilities of word co­occurrences in the 
training set. For example, if the training data has many instances of the phrase “the cat in the 
hat”, then if the model generates the word “the”, it will likely generate either “cat” or “hat” as its 
next word. However, the model does not consider any context prior to the current word when 
generating the next, so oftentimes the output will be nonsensical. 
LSTMs differ from Markov Models by being able to remember context from earlier in the 
sentence when predicting the next word. LSTMs have been used extensively for NLP because 
language is naturally sequential and words that are separated by a large distance may still be 
related to each other. However, the increase in accuracy of LSTMs comes at a cost as they 
require more time and data to train. 
Example of a Facebook phishing post used as training data. 
To avoid the computational cost of retraining these models for each user, we pre­train these 
models on spear phishing data and seed them with a topic generated from automated profiling. 
There is no standard corpus for phishing emails, much less phishing tweets, so we create our 
own using spear phishing attacks from numerous sources, e.g. [9]. We supplement this data 
with streamed tweets from the Twitter API Streaming Endpoint. Finally, since Twitter’s API 
allows us to post the generated tweet autonomously, we use the target’s own post history to 
select a time when they are likely to observe and respond to our tweet. 
Example of a machine­generated tweet. 
5 
To evaluate our model, we place links inside the generated tweets leading to a payload, 
shortened using goo.gl. If the user clicks through, we record the timestamp, user­agent, and 
screenname that the tweet was sent to. We prepend generated tweets with a @mention 
directed at our target in order to decrease the chance that a user other than the target clicks on 
the link. 
Goo.gl analytics from a malicious shortened link. 
6 
Though large­scale phishing campaigns tend to have very low compromise rates, they persist 
because the few examples that do succeed lead to a high return on investment. On tests 
consisting of 90 users, we found that our automated spear phishing framework had between 
30% and 66% success rate. This is more successful than the 5­14% previously reported in 
large­scale phishing campaigns [10, 11], and comparable to the 45% reported for large­scale 
manual spear phishing efforts [12]. We attribute our results to the unique risks associated with 
social media and our ability to leverage data science to target vulnerable users with a highly 
personalized message. 
Conclusion 
This work marks an advance in offensive capabilities through automation of a traditionally 
manual process using ML techniques. Our approach is predicated on the fact that social media 
is rapidly emerging as an easy target for phishing and social engineering attacks. We use 
Twitter as our platform because of its low bar for admissible messages, its community tolerance 
of convenience services like shortened links, its effective API, and its pervasive culture of 
overexposing personal information. 
Our end to end framework is entirely data­driven: we employ modeling techniques that learn the 
relevant textual statistics of successful spear phishing campaigns on social media, and we use 
those models to generate tailored messages to high risk/high value Twitter users based on their 
public content. Click­through rates are among the highest ever reported for a large­scale 
phishing campaign, underscoring the efficacy of coordinated automatic social engineering at 
scale.  
There are existing frameworks such as the Social­Engineer Toolkit that automate the payload of 
the phishing process, but none that tailor the phishing message to the target. We close this gap 
and enable penetration testers to address larger groups of targets while not compromising the 
quality of the spear phishing message. ​We present this automated end­to­end spear phishing 
campaign generator in order to foster greater awareness and understanding of spear phishing 
and social engineering attacks. 
References 
[1] ​Maynor, David. Metasploit toolkit for penetration testing, exploit development, and vulnerability research. 
Elsevier, 2011. 
[2] Weizenbaum, Joseph. "ELIZA—a computer program for the study of natural language communication 
between man and machine." ​Communications of the ACM​ 9.1 (1966): 36­45. 
[3] Sahami, Mehran, Dumais, Susan, Heckerman, David, and Eric Horvitz. "A Bayesian approach to filtering 
junk e­mail." ​Learning for Text Categorization​: ​Papers from the 1998 workshop​. Vol. 62. 1998. 
7 
[4] Pavković, Nikola, and Luka Perkov. "Social Engineering Toolkit—A systematic approach to social 
engineering." ​MIPRO, 2011 Proceedings of the 34th International Convention​. IEEE, 2011. 
https://www.trustedsec.com/social­engineer­toolkit/ 
[5] Gallagher, Robbie, “​Where Do the Phishers Live? Collecting Phishers’ Geographic Locations from 
Automated Honeypots”, ​2016​ ​ShmooCon​, ​https://bitbucket.org/rgallagh/honey­phish 
[6] ​Markov, Andrey A. "Extension of the limit theorems of probability theory to a sum of variables 
connected in a chain". reprinted in Appendix B of: R. Howard. ​Dynamic Probabilistic Systems, 
volume 1: Markov Chains​. John Wiley and Sons, 1971. 
[7] ​http://www.social­engineer.org/wp­content/uploads/2015/11/SECTF­2015_Public.pdf 
[8] Gers, Felix A., Jürgen Schmidhuber, and Fred Cummins. "Learning to forget: Continual prediction with 
LSTM." ​Neural Computation​ 12.10 (2000): 2451­2471. 
[9] ​https://shkspr.mobi/blog/2015/08/would­you­fall­for­this­twitter­phishing­attack/ 
[10] Thompson, Steven C. "Phight Phraud." Journal of Accountancy 201.2 (2006): 43. 
[11] Jakobsson, Markus, and Jacob Ratkiewicz. "Designing ethical phishing experiments: a study of 
(ROT13) rOnl query features." ​Proceedings of the 15th international conference on World Wide Web​. 
ACM, 2006. 
[12] Bursztein, Elie, et al. "Handcrafted fraud and extortion: Manual account hijacking in the wild." 
Proceedings of the 2014 Conference on Internet Measurement Conference​. ACM, 2014. 
8