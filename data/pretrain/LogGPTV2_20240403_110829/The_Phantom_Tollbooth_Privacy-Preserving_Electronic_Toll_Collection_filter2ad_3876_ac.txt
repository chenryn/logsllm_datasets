Next, it checks that each commitment ci was properly
σm = Sign(sktag,m)
return (m,σm)
formed by acting as the veriﬁer for the NIZK πi; if one of
these checks failed then it knows that the driver committed
to an incorrect price (for example, a negative price to try
to drive down her monthly bill). The TSP then performs
the homomorphic operation on the commitments to get
cﬁnal = c1 (cid:1) c2 (cid:1)···(cid:1) cn and checks that openﬁnal is the
opening for cﬁnal. If all these checks pass, the TSP can
debit pﬁnal (contained in openﬁnal) from the user’s account;
if not, something has gone wrong and the TSP can ﬂag the
driver as suspicious and continue on to legal proceedings,
as is done with current trafﬁc violations. This algorithm
is summarized in Algorithm 4.2.
In terms of privacy, the hiding property of the com-
mitment scheme and the zero knowledge property of
the NIZK scheme guarantee that the driver’s informa-
tion is being kept private from the TSP. Furthermore, the
anonymity of the IBE scheme guarantees that, although
the segments are used as the identity for the ciphertexts Ci,
the TSP will be unable to learn this information given just
these ciphertexts. In addition, some degree of honesty is
guaranteed. First, because the message was signed by the
OBU, the TSP can be sure that the tuple came from the
correct driver and not some other malicious driver trying
to pass herself off as someone else (or cause the ﬁrst driver
to pay more than she owes). Furthermore, if all the checks
pass then the binding property of the commitment scheme
and the soundness property of the NIZK scheme guaran-
tee that the values contained in the commitments are to
valid prices and so the TSP can be somewhat convinced
that the price pﬁnal given by the driver is the correct price
she owes for the month. The TSP cannot, however, be
convinced yet that the driver did not simply turn off her
OBU or otherwise fake location or price information; for
this, it will need to forward the payment tuple to the TC,
which initiates the audit phase of the protocol.
4.3 Auditing
As we argued in Section 2.2, although the audit protocol
does take away some degree of privacy from the driver,
this small privacy loss is necessary to ensure honesty
Algorithm 4.2: VerifyPayment, run by the TSP
Input: payment tuple (m,σm), veriﬁcation key vktag
if SigVerify(vktag,m,σm) = 0 then
parse m as(cid:0)tag,openﬁnal,(cid:8)(ci,Ci,πi)(cid:9)n
if NIZKVerify(cid:0)(ci,πi),0 ≤ pi ≤ M(cid:1) = 0 then
forall 1 ≤ i ≤ n do
return ⊥
(cid:1)
i=1
return suspicious
cﬁnal = c1 (cid:1)···(cid:1) cn
if cﬁnal = Com(openﬁnal) then
parse openﬁnal as (pﬁnal;rﬁnal)
debit account for tag by pﬁnal
return okay
1
2
3
4
5
6
7
8
9
10
11
12
13
else
return suspicious
within the system. We additionally argued that the TC
should not reveal to the driver the locations of the cameras
and furthermore believe that the driver should not even
learn the number of cameras at which the TC saw her, as
even this information would give her opportunity to cheat
(for more on this see Section 6). We therefore assume
that the TC makes some ﬁxed number of queries k for
every driver, regardless of whether or not it has in fact
seen the driver k times. To satisfy this assumption, if the
TC has seen the driver on more than k cameras, it will
just pick the ﬁrst k (or pick k at random, it doesn’t matter)
and query on those. If it has seen the driver on fewer
than k cameras, we can designate some segment to be a
“dummy” segment, which essentially does not correspond
to any real location/time tuple. The TC can then query on
this dummy segment until it has made k queries in total;
because the part of the protocol in which the TC performs
its queries is blind, the OBU won’t know that it is being
queried on the same segment multiple times.
After the TSP has forwarded the OBU’s payment tu-
ple to the TC, the TC ﬁrst checks that the message re-
ally came from the OBU (and not, for example, from
a malicious user or even the TSP trying to frame the
driver). As with the TSP, if this check fails then it can
abort the protocol and alert the OBU or TSP. It then ex-
its random spot checks to ensure that the driver was not
lying about her whereabouts. This process is outlined
in Algorithm 4.3. Because there were a certain number
of cameras the driver passed, the TC will have a set of
tracts the tuples(cid:8)(ci,Ci,πi)(cid:9) from m and begins issuing
tuples(cid:8)(loci,timei)(cid:9) of its own that correspond to the
a set(cid:8)(wherei,wheni)(cid:9) of tuples that the driver would
places and times at which the TC saw the driver. First,
for every pair (loc,time), the TC will need to determine
which segment this pair belongs to; this then gives it
have logged if they were behaving honestly (unless the
set has been augmented by the dummy segment as de-
scribed above, in which case the OBU clearly will not
have logged this segment).
After the TC has this set of tuples, it uses the identity-
based encryption Cj contained within every tuple sent
by the OBU. Recall from Algorithm 4.1 that the iden-
tity corresponding to each encryption is the segment
(where j,when j), and that the encryption itself is of the
opening of the commitment c j (contained in the same
tuple), along with a conﬁrmation value 0λ . Therefore, if
the TC can obtain the secret key skid from the OBU for
the identity id = (where j,when j), then it can successfully
decrypt the ciphertext and obtain the opening for the com-
mitment, which it can then use to check if the driver is
recording correct price information. Because the TC does
not know which ciphertext corresponds to which segment,
however, once the TC obtains this secret key it will then
need to attempt to decrypt each Cj.
To prevent drivers from using a single commitment
to pay for two segments, we require that it be compu-
tationally difﬁcult to ﬁnd a ciphertext C that has valid
decryptions under two identities id1 and id2. For our IBE,
it is sufﬁcient to encrypt a conﬁrmation value 0λ along
with the message (where λ = 160 for 80-bit security),
since messages are blinded with a random oracle hash
that takes the identity as input. On decryption, one checks
that the correct conﬁrmation value is present. Note that
we do not require CCA security.
If Cj does decrypt properly for some j, then the TC
checks that the value contained inside is the opening of
the commitment c j. If it is, then the TC further checks that
the price p j is the correct price for that road segment by
computing f (where j,when j). If this holds as well, then
the TC can be satisﬁed that the driver paid correctly for
the segment of the road on which she was seen and move
on to the next camera. If it does not hold, then the TC
has reason to believe that the driver lied about the price
of the road she was driving on. If instead the opening
is not valid, the TC has reason to believe that the driver
formed either the ciphertext Cj or the commitment c j
incorrectly. Finally, if none of the ciphertexts properly
decrypted using skid (i.e., Cj did not decrypt for any value
of j), then the TC knows that the driver simply omitted the
segment (where j,when j) from her payment in an attempt
to pretend she drove less.
In any of these cases, the
TC believes the driver was cheating in some way and
can undertake legal proceedings. If all of these checks
pass for every camera, then the driver has successfully
passed the audit and the TC is free to move on to another
user.
In terms of driver honesty, the addition of BlindExtract
allows the TC to obtain skid without the OBU learning the
identity, and thus the location at which they were caught
on camera. As argued in Section 2, this is absolutely cru-
Algorithm 4.3: Audit, run by the TC
Input: payment tuple (m,σm), camera tuples
i=1, veriﬁcation key vktag
{(loci,timei)}k
return ⊥
if SigVerify(vktag,m,σm) = 0 then
parse m as (tag,openﬁnal,{(c j,Cj,π j)}n
forall 1 ≤ i ≤ k do
j=1)
determine segment (wherei,wheni) for
(loci,timei)
ski = BlindExtract(wherei,wheni)
match = 0
forall 1 ≤ j ≤ n do
m j = IBDec(ski;Cj)
if m j parses as (p j;r j;0λ ) then
match = 1
if Com(m j) (cid:54)= c j then
return suspicious
if p j (cid:54)= f (wherei,wheni) then
return suspicious
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
break
if match = 0 then
return suspicious
return okay
cial for maintaining driver honesty, both individually and
in the face of possible collusions. In terms of privacy, if
the OBU and TC sign their messages in the BlindExtract
phase, then we can guarantee that no malicious third party
can alter messages in their interaction in an attempt to
learn the segment in which the driver was caught on cam-
era (or, alternatively, frame the driver by corrupting skid).
As mentioned in Section 2, whereas the cameras do take
away some part of the driver’s privacy, they are necessary
to maintain honesty; we also note that no additional in-
formation is revealed throughout the course of this audit
interaction provided both parties behave honestly. One
potential downside of this protocol, however, is that the
TC is not restricted to querying locations at which it had
cameras; it can essentially query any location it wants
without the driver’s knowledge (although the driver is at
least aware of how many queries are being made). We
believe that our system could be augmented to resist such
misbehavior through an “audit protocol audit protocol”
that requires the TC to demonstrate that it actually has
camera records corresponding to some small fraction of
the spot check it performs, much as its own audit protocol
requires the driver to reveal some small fraction of its
segments driven. This “audit audit” could be performed
on behalf of drivers by an organization such as EFF or
the ACLU; alternatively, in some legal settings an exclu-
sionary rule could be introduced that invalidates evidence
obtained through auditing authority misbehavior.
Time (ms)
Laptop
75.12
82.11
13.13
11.21
78.31
ARM
Operation
1083.61
Creating parameters
1187.82
Encryption
214.06
Blind extraction (user)
175.25
Blind extraction (authority)
Decryption
1131.58
Table 1: The average time, in milliseconds and over a run
of 10, for the various operations in our blind IBE protocol,
performed on both a MacBook Pro and an ARM v5TE.
The numbers for encryption and decryption represent the
time taken to encrypt/decrypt a pair of 1024-bit numbers
using the curve y2 = x3 + x mod p at the 80-bit security
level, and the numbers for blind extraction represent the
time to complete the computation required for each side
of the interactive protocol.
Implementation and Performance
5
In order to achieve a more effective audit protocol, an
extra computational burden is required for both the OBU
and the TC. In this section, we consider just how great this
additional burden is; in particular, we focus on our blind
identity-based encryption protocol from the full version
of our paper [36], as well as Algorithm 4.3 from Sec-
tion 4.3. The benchmarks presented for these protocols
were collected on two machines: a MacBook Pro running
Mac OS X 10.6 with a 2.53GHz Intel Core 2 Duo proces-
sor and 4GB of RAM, and an ARM v5TE running Linux
2.6.24 with a 520MHz processor and 128MB of RAM.
We believe that the former represents a fairly conserva-
tive estimate for the amount of computational resources
available to the TC, whereas the latter represents a ma-
chine that could potentially be used as an OBU. For the
bilinear groups needed for blind IBE we used the supersin-
gular curve y2 = x3 + x mod p for a large prime p (which
has embedding degree 2) within version 5.4.3 of the MIR-
ACL library [41], and for the NIZKs and commitments we
used ZKPDL (Zero-Knowledge Proof Description Lan-
guage) [35], which itself uses the GNU multi-precision
library [23] for modular arithmetic.
Table 1 shows the time taken for each of the unit oper-
ations performed within the IBE scheme. As mentioned
in Section 4, in the context of our system the creation
of the parameters will be performed when the OBU is
initialized, the encryption will be performed during the
Pay protocol (line 4 of Algorithm 4.1), and both blind
extraction and decryption will be performed in the audit
phase between the TC and the OBU (lines 6 and 9 of
Algorithm 4.3 respectively).
We consider the computational costs for the OBU and
the TC separately, as well as the communication overhead
for the whole system.5
5We do not consider the computational costs for the TSP here, as
OBU computational costs. During the course of a
month (or however long an audit period is), the OBU is
required to spend time performing computations for two
distinct phases of the Milo protocol. The ﬁrst phase is the
Pay protocol, which consists of computing the commit-
ments to segment prices, encrypting the openings of the
commitments, and producing a zero-knowledge proof that
the value in the commitment lies in the right range. From
Table 1, we know that encryption takes roughly a sec-
ond when encrypting 1024-bit number on the ARM. As
these correspond to “medium security” in PrETP [4, Ta-
ble 2], and our commitments and zero-knowledge proofs
are essentially identical to theirs, we can use the relevant
timings from PrETP to see that the total time taken for
the Pay protocol should be at most 20 seconds per seg-
ment. As long as the time steps are at least 20 seconds
and the segment lengths are at least half a mile (assuming
people drive at most 90 miles per hour), the calculations
can therefore be done in real time.
The second phase of computation is the end of the
month audit protocol. Here, the OBU is responsible for
acting as the IBE authority to answer blind extraction
queries from the TC. As we can see in Table 1, each
query takes the OBU approximately 175 milliseconds,
independent of the number of segments. If the TC makes
a small, ﬁxed number of queries, say ten, for each vehicle,
then the OBU will spend only a few seconds in the Audit
protocol each month.
TC computational costs.
In the course of the Audit
protocol, the TC has to perform a number of complex
calculations. In particular, the cost of challenging the
OBU for each camera is proportional to the number of
segments the OBU reported driving.
To obtain our performance numbers for the audit pro-
tocol, we considered the driving habits of an average
American, both in terms of time spent and distance driven.
For time, we assumed that an average user would have a
commute of 30 minutes each way, meaning one hour each
day, in addition to driving between two and three hours
each weekend. For distance, we assumed that an average