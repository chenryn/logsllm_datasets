GPT
DistilBERT
BERT
MobileBERT
RoBERTa
T-miner Models GRU
PICCOLO (s) GBDA (s) T-miner (s)
2829
3272
3341
-
-
-
-
1790
281
480
415
-
-
-
-
32
279
350
513
405
343
458
537
34
TABLE X: Effectiveness of PICCOLO on Hidden Killer attack
Dataset-Model
SST-BERT
SST-LSTM
OLID-BERT
OLID-LSTM
AG-BERT
AG-LSTM
TP
18
18
19
20
20
20
FP
1
0
3
3
0
0
FN
2
2
1
0
0
0
TN
19
20
17
17
20
20
Acc
0.925
0.95
0.9
0.925
1.0
1.0
TABLE XI: Frequency of structure phrases on SST-2 dataset
(6921 clean training samples) in Hidden Killer attack
Structure Phrase
Clean Samples
Poisoned Samples
Structure Phrase
Clean Samples
Poisoned Samples
Structure Phrase
Clean Samples
Poisoned Samples
as the
if i
when you when the
7
6
4
81
82
83
if the
if it when he
17
0
67
80
as i when they
0
11
62
44
3
120
when i
4
77
when it
4
63
3
76
as it
3
54
TABLE XII: Effectiveness of PICCOLO on Combination Lock
attack
Dataset-Model
SST-BERT-base
SST-BERT-large
OLID-BERT-base
OLID-BERT-large
AG-BERT-base
AG-BERT-large
TP
18
19
20
20
18
18
FP
1
3
2
3
2
2
FN
2
1
0
0
2
2
TN
19
17
18
17
18
18
Acc
0.925
0.9
0.95
0.925
0.9
0.9
OLID [54] and AG news [55]. We also train 240 BERT
classiﬁcation models on SST-2, OLID and AG news for the
combination lock attack. These models are trained with differ-
ent random seeds and different splits of training, validation and
test sets. The experimental setup is consistent with the existing
work [38]. Half of these trained models of each architecture
are benign and the other half are trojaned.
F. Adaptive Attacks
Targeting Word Discriminativity Analysis. In this attack
scenario, the adversary knows that PICCOLO leverages the dot
product between the linear model weights and the importance
vector for the CLS embedding. She hence includes a loss term
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:56:09 UTC from IEEE Xplore.  Restrictions apply. 
172041
Fig. 12: Frequencies of inverted words from 8 models trojaned
by combination lock in the clean and poisoned training sets
TABLE XIII: Adding dot product loss adaptive attack
Phrase Trigger
Character Trigger Word Trigger
Loss Weight 0.01
0.0001 0.01
0.1 0.0001 0.01
Accuracy
ASR
Detection
0.1
0.88 0.88
0.87 0.76
1.00 1.00
1
0.87
0.46
0.70
0.89 0.88 0.88
0.83 0.77 0.62
1.00 1.00 0.90
0.1
0.89 0.89 0.88
0.83 0.76 0.67
1.00 0.90 0.90
L = Lce (xt, yt) + λ · θw (cid:4) I(cid:6),
considering the dot product during poisoning. In particular,
she constructs a linear model with weights θw for a trigger
w before poisoning as she owns the trigger. The importance
vector I(cid:6) can then be inferred by sampling different dimension
values and computing logits differences following the same
procedure as in PICCOLO. With the constructed θw and I(cid:6),
the attacker can derive the following loss.
(11)
where Lce (xt, yt) is the cross-entropy loss for the input-label
pair xt and yt. Note that a portion of the training data is
poisoned with the backdoor. The term θw (cid:4) I(cid:6) denotes the
adaptive loss leveraged by the attacker to minimize the dot
product (and then bypass PICCOLO). Here, (cid:5) is the target label
and λ a weight to balance the training loss and the adaptive
loss. Using a large adaptive loss may produce a trojaned model
with low normal accuracy or low attack success rate, which
makes the overall attack ineffective. Hence,
the adversary
ought to ﬁnd an appropriate hyper-parameter λ.
We evaluate this adaptive attack on three trigger types,
namely, character, word, and phrase triggers. For each type of
triggers, we study three different adaptive loss weights λ. For
each loss weight λ, we train 10 poisoned models and study the
performance of PICCOLO. Table XIII shows the results. The
ﬁrst row shows the different trigger types. The second row
presents the loss weight λ used. Rows 3-4 show the average
normal accuracy and attack success rate (ASR) of the 10
trojaned models. The last row shows the detection accuracy of
PICCOLO (i.e., the percentage of the trojaned models that are
detected). Observe that the ASR of poisoned models decreases
with the increase of loss weight λ for all the three types of
triggers. PICCOLO has the detection accuracy ≥0.9 for 8 out of
the 9 studied adaptive scenarios. PICCOLO has a low detection
rate of 0.7 for the character trigger with λ = 1. However, the
poisoned models have only 0.46 ASR in this case, which does
not constitute an effective attack.
Targeting Trigger Inversion. This adaptive attack targets
the trigger inversion component of PICCOLO. As the trigger
inversion component is differentiable w.r.t the subject model,
the inversion procedure can be incorporated into the loss
function used during poisoning. Speciﬁcally, the adversary can
force the inverted probabilities of trigger words (say dimension
TABLE XIV: Adding trigger inversion loss in adaptive attack
Character Trigger
1
10 1000 10000
Word Trigger
Phrase Trigger
0.1
1
Acc
ASR
Loss Weight
10 100 0.001 0.01 0.1
0.89 0.87 0.87 0.86 0.89
0.63 0.86 0.83 0.76 0.67
0.60 1.00 1.00 0.90 0.80
0.89 0.88 0.89
0.87 0.84 0.74
Detection 1.00 1.00 0.80
1
0.87 0.86 0.86 0.85
0.86 0.81 0.73 0.69
1.00 0.80 0.80 0.70
itrigger of the inverted word vector xz) to be small during
poisoning. The loss function can be constructed as follows.
L = Lce (xt, yt) + α · Linverse (xz, (cid:5)) + λ · xz[itarget ], (12)
where Lce (xt, yt) is the cross-entropy loss. Linverse (xz, (cid:5)) is
a loss aiming to invert a trigger word vector xz towards the
target label (cid:5). We use a weight α to balance the ﬁrst two losses.
We search a possible α to make sure that the trojaned model
has a reasonable clean accuracy and a high ASR, and in the
mean time the inverted xz has a high ASR (as a whole). The
adaptive loss xz[itarget ] is to minimize the dimensions of the
ground truth trigger words in xz. Parameter λ is to balance
the adaptive loss.
We evaluate on the same three types of triggers. For each
type, we study four different adaptive loss weights λ. For
each loss weight, we train 10 models. Table XIV presents the
results. The ﬁrst row shows the different trigger types. The
second row shows the loss weight λ used. Rows 3-4 show the
average clean accuracy and attack success rate (ASR) of the
10 trojaned models. The last row shows the detection accuracy
of PICCOLO. Observe that for all the three types of triggers,
increasing the loss weight λ leads to the degradation of ASR of
poisoned models. When the ASR of poisoned models is above
0.7, PICCOLO has a detection accuracy ≥0.8. When the ASR
is low (0.6 for the character trigger), the detection accuracy
of PICCOLO drops to 0.6. Note that it does not constitute an
effective attack with such a low ASR.
G. Ablation Study
Our ablation study shows that all the design choices are
important. Due to the space limit, we move the ablation study
to our online appendix5.
H. Study on Different Injection Positions of the Optimization
Vector
We conduct a study on the injection positions of the opti-
mization vector. The experiments show that different injection
schemes have similar overall detection accuracy. The details
can be found in our online appendix5.
I. Effectiveness on Different Types of Triggers
We conduct a study on the effectiveness of PICCOLO, T-
miner, and GBDA on different types of triggers. The experi-
ments show that T-miner and GBDA are consistently inferior
to PICCOLO across all the trigger types. Due to the space limit,
we move this study to our online appendix5.
5https://github.com/PurduePAML/PICCOLO
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:56:09 UTC from IEEE Xplore.  Restrictions apply. 
182042