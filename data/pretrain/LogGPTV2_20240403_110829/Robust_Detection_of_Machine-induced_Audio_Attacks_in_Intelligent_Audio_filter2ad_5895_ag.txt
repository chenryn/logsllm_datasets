Proceedings of the IEEE conference on computer vision and pattern recognition.
4510–4520.
[45] Ramprasaath R Selvaraju, Michael Cogswell, Abhishek Das, Ramakrishna Vedan-
tam, Devi Parikh, and Dhruv Batra. 2017. Grad-cam: Visual explanations from
deep networks via gradient-based localization. In Proceedings of the IEEE interna-
tional conference on computer vision. 618–626.
[46] Jonathan Shen, Ruoming Pang, Ron J. Weiss, Mike Schuster, Navdeep Jaitly,
Zongheng Yang, Zhifeng Chen, Yu Zhang, Yuxuan Wang, RJ Skerry-Ryan,
Rif A. Saurous, Yannis Agiomyrgiannakis, and Yonghui Wu. 2018. Natural TTS
Synthesis by Conditioning WaveNet on Mel Spectrogram Predictions. (2018).
arXiv:cs.CL/1712.05884
[47] Jian Shen, Yanru Qu, Weinan Zhang, and Yong Yu. 2018. Wasserstein distance
guided representation learning for domain adaptation. In Proceedings of the AAAI
Conference on Artificial Intelligence, Vol. 32.
[48] Cong Shi, Yan Wang, Yingying Chen, Nitesh Saxena, and Chen Wang*. 2020.
WearID: Low-Effort Wearable-Assisted Authentication of Voice Commands via
Session 6C: Audio Systems and Autonomous Driving CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea1897Cross-Domain Comparison without Training. In Annual Computer Security Ap-
plications Conference (ACSAC). 829–842.
[49] Sayaka Shiota, Fernando Villavicencio, Junichi Yamagishi, Nobutaka Ono, Isao
Echizen, and Tomoko Matsui. 2015. Voice liveness detection algorithms based on
pop noise caused by human breath for automatic speaker verification. In Sixteenth
annual conference of the international speech communication association.
[50] Karen Simonyan and Andrew Zisserman. 2015. Very deep convolutional networks
for large-scale image recognition. In Proceedings of the International Conference
on Learning Representation. 1–14.
[51] Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed, Dragomir
Anguelov, Dumitru Erhan, Vincent Vanhoucke, and Andrew Rabinovich. 2015.
Going deeper with convolutions. In Proceedings of the IEEE conference on computer
vision and pattern recognition. 1–9.
[52] Yu-hsin Chen, Ignacio Lopez-Moreno, Tara N Sainath, Mirkó Visontai, Raziel
Alvarez, and Carolina Parada. 2015. Locally-connected and convolutional neural
networks for small footprint speaker recognition. In Proceedings of the Sixteenth
Annual Conference of the International Speech Communication Association.
[53] F Alton Everest and Ken C Pohlmann. 2015. Master handbook of acoustics.
McGraw-Hill Education.
[54] Galina Lavrentyeva, Sergey Novoselov, Andzhukaev Tseren, Marina Volkova,
Artem Gorlanov, and Alexandr Kozlov. 2019. STC antispoofing systems for the
ASVspoof2019 challenge. arXiv preprint arXiv:1904.05576 (2019).
[55] Khomdet Phapatanaburi, Longbiao Wang, Seiichi Nakagawa, and Masahiro Iwa-
hashi. 2019. Replay attack detection using linear prediction analysis-based relative
phase features. IEEE Access 7 (2019), 183614–183625.
[56] Mirco Ravanelli and Yoshua Bengio. 2018. Speaker recognition from raw wave-
form with sincnet. In Proceedings of 2018 IEEE Spoken Language Technology
Workshop (SLT). IEEE, 1021–1028.
[57] Takeshi Sugawara, Benjamin Cyr, Sara Rampazzi, Daniel Genkin, and Kevin Fu.
2020. Light commands: laser-based audio injection attacks on voice-controllable
systems. In Proceedings of the 29th {USENIX} Security Symposium ({USENIX}
Security 20). 2631–2648.
[58] Hemlata Tak, Jose Patino, Andreas Nautsch, Nicholas Evans, and Massimiliano
Todisco. 2020. Spoofing attack detection using the non-linear fusion of sub-band
classifiers. arXiv preprint arXiv:2005.10393 (2020).
[59] Hemlata Tak, Jose Patino, Massimiliano Todisco, Andreas Nautsch, Nicholas
Evans, and Anthony Larcher. 2021. End-to-end anti-spoofing with RawNet2.
In Proceedings of IEEE International Conference on Acoustics, Speech and Signal
Processing (ICASSP). IEEE, 6369–6373.
[60] Massimiliano Todisco, Xin Wang, Ville Vestman, Md Sahidullah, Héctor Del-
gado, Andreas Nautsch, Junichi Yamagishi, Nicholas Evans, Tomi Kinnunen, and
Kong Aik Lee. 2019. ASVspoof 2019: Future horizons in spoofed and fake audio
detection. arXiv preprint arXiv:1904.05441 (2019).
[61] Chengyi Wang, Yu Wu, Shujie Liu, Jinyu Li, Liang Lu, Guoli Ye, and Ming Zhou.
2020. Low latency end-to-end streaming speech recognition with a scout network.
arXiv preprint arXiv:2003.10369 (2020).
[62] Xin Wang and Junich Yamagishi. 2021. A comparative study on recent neu-
ral spoofing countermeasures for synthetic speech detection. arXiv preprint
arXiv:2103.11326 (2021).
[63] Xiang Wu, Ran He, Zhenan Sun, and Tieniu Tan. 2018. A light cnn for deep face
representation with noisy labels. IEEE Transactions on Information Forensics and
Security 13, 11 (2018), 2884–2896.
[64] Chen Yan, Yan Long, Xiaoyu Ji, and Wenyuan Xu. 2019. The catcher in the field: A
fieldprint based spoofing detection for text-independent speaker verification. In
Proceedings of the 2019 ACM SIGSAC Conference on Computer and Communications
Security. 1215–1229.
[65] Guoming Zhang, Xiaoyu Ji, Xinfeng Li, Gang Qu, and Wenyuan Xu. 2021. EarAr-
ray: Defending against DolphinAttack via Acoustic Attenuation. In Network and
Distributed Systems Security (NDSS) Symposium.
[66] Massimiliano Todisco, Héctor Delgado, and Nicholas WD Evans. 2016. A New
Feature for Automatic Speaker Verification Anti-Spoofing: Constant Q Cepstral
Coefficients.. In Odyssey, Vol. 2016. 283–290.
[67] Eric Tzeng, Judy Hoffman, Kate Saenko, and Trevor Darrell. 2017. Adversar-
ial discriminative domain adaptation. In Proceedings of the IEEE conference on
computer vision and pattern recognition. 7167–7176.
[68] Tavish Vaidya, Yuankai Zhang, Micah Sherr, and Clay Shields. 2015. Cocaine
noodles: exploiting the gap between human and machine speech recognition. In
9th {USENIX} Workshop on Offensive Technologies ({WOOT} 15).
[69] Aaron van den Oord, Sander Dieleman, Heiga Zen, Karen Simonyan,
Oriol Vinyals, Alex Graves, Nal Kalchbrenner, Andrew Senior, and Koray
Kavukcuoglu. 2016. WaveNet: A Generative Model for Raw Audio.
(2016).
arXiv:cs.SD/1609.03499
[70] Laurens Van der Maaten and Geoffrey Hinton. 2008. Visualizing data using t-SNE.
Journal of machine learning research 9, 11 (2008).
[71] Chen Wang, S Abhishek Anand, Jian Liu, Payton Walker, Yingying Chen, and
Nitesh Saxena. 2019. Defeating hidden audio channel attacks on voice assistants
via audio-induced surface vibrations. In Proceedings of the 35th Annual Computer
Security Applications Conference. 42–56.
[72] Longbiao Wang, Yohei Yoshida, Yuta Kawakami, and Seiichi Nakagawa. 2015.
Relative phase information for detecting human speech and spoofed speech. In
Sixteenth Annual Conference of the International Speech Communication Associa-
tion.
[73] Run Wang, Felix Juefei-Xu, Yihao Huang, Qing Guo, Xiaofei Xie, Lei Ma, and
Yang Liu. 2020. DeepSonar: Towards Effective and Robust Detection of AI-
Synthesized Fake Voices. In Proceedings of the 28th ACM International Conference
on Multimedia. 1207–1216.
[74] Shu Wang, Jiahao Cao, Xu He, Kun Sun, and Qi Li. 2020. When the Differences in
Frequency Domain are Compensated: Understanding and Defeating Modulated
Replay Attacks on Automatic Speech Recognition. Proceedings of the 2020 ACM
SIGSAC Conference on Computer and Communications Security (Oct 2020). https:
//doi.org/10.1145/3372297.3417254
[75] Yuxuan Wang, RJ Skerry-Ryan, Daisy Stanton, Yonghui Wu, Ron J. Weiss,
Navdeep Jaitly, Zongheng Yang, Ying Xiao, Zhifeng Chen, Samy Bengio, Quoc
Le, Yannis Agiomyrgiannakis, Rob Clark, and Rif A. Saurous. 2017. Tacotron:
Towards End-to-End Speech Synthesis. (2017). arXiv:cs.CL/1703.10135
[76] Marcin Witkowski, Stanislaw Kacprzak, Piotr Zelasko, Konrad Kowalczyk, and
Jakub Galka. 2017. Audio Replay Attack Detection Using High-Frequency Fea-
tures. In Interspeech. 27–31.
[77] Svante Wold, Kim Esbensen, and Paul Geladi. 1987. Principal component analysis.
Chemometrics and intelligent laboratory systems 2, 1-3 (1987), 37–52.
[78] Zhizheng Wu and Haizhou Li. 2013. Voice conversion and spoofing attack on
speaker verification systems. In 2013 Asia-Pacific Signal and Information Processing
Association Annual Summit and Conference. IEEE, 1–9.
[79] Xiong Xiao, Xiaohai Tian, Steven Du, Haihua Xu, Eng Siong Chng, and Haizhou
Li. 2015. Spoofing speech detection using high dimensional magnitude and phase
features: The NTU approach for ASVspoof 2015 challenge. In Sixteenth Annual
Conference of the International Speech Communication Association.
[80] Ryoya Yaguchi, Sayaka Shiota, Nobutaka Ono, and Hitoshi Kiya. 2019. Replay
attack detection using generalized cross-correlation of stereo signal. In 2019 27th
European Signal Processing Conference (EUSIPCO). IEEE, 1–5.
[81] Hiromu Yakura and Jun Sakuma. 2018. Robust audio adversarial example for a
physical attack. arXiv preprint arXiv:1810.11793 (2018).
[82] Chao-Han Yang, Jun Qi, Pin-Yu Chen, Xiaoli Ma, and Chin-Hui Lee. 2020. Char-
acterizing speech adversarial examples using self-attention u-net enhancement.
In ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal
Processing (ICASSP). IEEE, 3107–3111.
[83] Zhuolin Yang, Bo Li, Pin-Yu Chen, and Dawn Song. 2018. Characterizing audio
adversarial examples using temporal dependency. arXiv preprint arXiv:1809.10875
(2018).
[84] Xuejing Yuan, Yuxuan Chen, Yue Zhao, Yunhui Long, Xiaokang Liu, Kai Chen,
Shengzhi Zhang, Heqing Huang, Xiaofeng Wang, and Carl A Gunter. 2018. Com-
mandersong: A systematic approach for practical adversarial voice recognition.
In 27th {USENIX} Security Symposium ({USENIX} Security 18). 49–64.
[85] Guoming Zhang, Chen Yan, Xiaoyu Ji, Tianchen Zhang, Taimin Zhang, and
Wenyuan Xu. 2017. Dolphinattack: Inaudible voice commands. In Proceedings
of the 2017 ACM SIGSAC Conference on Computer and Communications Security.
103–117.
[86] Linghan Zhang, Sheng Tan, and Jie Yang. 2017. Hearing your voice is not enough:
An articulatory gesture based liveness detection for voice authentication. In
Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications
Security. 57–71.
[87] Linghan Zhang, Sheng Tan, Jie Yang, and Yingying Chen. 2016. Voicelive: A
phoneme localization based liveness detection for voice authentication on smart-
phones. In Proceedings of the 2016 ACM SIGSAC Conference on Computer and
Communications Security. 1080–1091.
Session 6C: Audio Systems and Autonomous Driving CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea1898A.3 Description of the ReMASC Dataset
Table 10: Data volume of the ReMASC dataset [22].
Environment
# Subjects
# Genuine
# Replayed
Outdoor
Indoor #1
Indoor #2
In-vehicle
Total
12
23
10
10
55
960
2,760
1,600
3,920
9,240
6,900
23,104
7,824
7,644
45,472
Table 11: Data separation of the ReMASC dataset [22].
# Device
# Training
# Testing
Test Ratio
1
2
3
4
5,357
6,126
5,862
6,161
2,989
4,538
4,238
4,515
0.3581
0.4255
0.4196
0.4229
A APPENDIX
A.1 Microphone Configuration
Table 8: Microphone arrays in intelligent audio devices.
Device Name
# of Mics
Amazon Echo (4th Gen)
Amazon Echo (3th Gen)
Amazon Echo Dot (4th Gen)
Amazon Echo Dot (3th Gen)
Amazon Show 10
Amazon Show 8
Amazon Show 5
Amazon Echo Studio
Amazon Echo Auto
6
7
4
4
3
2
2
7
8
Device Name
Google Home
Google Home Max
Google Nest Mini (2nd gen)
Google Nest Mini (1st gen)
Google Nest Audio (1st gen)
Google Nest Hub
Google Nest Hub Max
Apple HomePod
Apple HomePod Mini
# of Mics
2
6
3
2
3
2
2
6
4
A.2 List of Speech Commands
Table 9: Speech commands used to generate attack speech
samples: (a) the commands for synthesis attack, inaudible
attack, and modulated replay attack, and (b) the target voice
commands to generate the adversarial examples.
(a)
Command
Please call Stella
Call 12345
Facetime 12345
Turn on airplane mode
Open the door
Navigation
Hey Siri
Ok Google
Hi Galaxy
Hello Huawei
ID
1
2
3
4
5
6
7
8
9
10
(b)
Command
Disable home alarm
Unlock the door
Browse to evil.com
Set volume to 0
Call mom
Power off
Open door
Call dad
Read email
Unlock iPhone
ID
1
2
3
4
5
6
7
8
9
10
Session 6C: Audio Systems and Autonomous Driving CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea1899