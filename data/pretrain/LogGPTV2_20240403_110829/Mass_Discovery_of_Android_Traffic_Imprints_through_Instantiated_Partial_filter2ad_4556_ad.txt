### Contribution of Domain Names
Without Tiger’s IPE, simply searching for strings that resemble hostnames and using them as imprints may not achieve a 10.10% increase in detection, as some hostnames are dynamically generated from the code. We also compared the app coverage between those from legitimate markets and PHAs (Potentially Harmful Applications) from VirusTotal. Interestingly, only 39.24% of PHAs could be covered by the prior approach [39], while Tiger improved this rate to 66.32%. The improvement is attributed to Tiger's ability to discover new types of invariants within traffic, which helped in detecting additional apps. Details about these new imprints are provided in Section 5.

Although the PHA coverage increased compared to previous approaches, it is still lower than the coverage for legitimate apps. This discrepancy is mainly due to shared tokens among malware, such as potentially harmful libraries [11]. Since our goal is to distinguish each unique app, we did not capture these shared tokens in the current implementation of Tiger. However, enhancing our approach to identify PHAs would not be difficult. For example, keeping the shared tokens between PHAs could be a straightforward solution.

### Analysis of Missed Detections
We were curious about why Tiger’s imprints missed the detection of 1,197 apps. To find the reason, we manually checked the generated imprints and the corresponding code in the apps. Given the difficulty of analyzing all 1,197 apps, we randomly selected 100 apps (approximately 10%) for inspection. We found that 90 apps produce traffic tokens from shared libraries or download resources from generic domains like htp://qzone.qq.cn. These traffic tokens are not unique to a single app and thus cannot be used as imprints for app identification. Excluding these 90 apps, Tiger only missed 10 apps due to the limitation of IPE on processing loops (see Section 6). In other words, for the apps that can be fingerprinted (including 3,803 identified and 120 possible missed by Tiger), our approach caught 96.94% (= 3803 / (3803 + 120)) of them.

### Traffic Coverage
We further studied the traffic coverage, estimated using the percentage of packets carrying imprints for uniquely identifying individual apps. This "traffic coverage" ratio is crucial for determining how timely and likely an app can be recognized from its network traffic. The more packets emitted by an app that can be fingerprinted, the sooner and more likely the app can be detected. This is especially important when mobile users switch between different networks (e.g., 4G and Wi-Fi), where some identifiable packets might be missed. Considering the cost of dynamic analysis, we used 5,000 randomly sampled apps for this evaluation.

In our experiment, we found that 72.85% of the packets from the sampled apps were detected using the imprints created by Tiger, while only 28.87% could be identified by those generated by the previous approach [39], as shown in Table 2. This difference (43.98%) is due to the new types of invariants discovered by Tiger through partial execution of the apps' sink-related code. As a result, the apps become easier to detect and more likely to be identified using our new technique. To understand the imprints' coverage of truly identifiable packets, we further randomly selected 100 apps and manually inspected all 3,872 packets in their communication. Among them, 2,844 carried identifiable imprints, with 2,803 packets caught by the imprints from Tiger. Thus, Tiger is capable of capturing 98.56% (= 2,803 / 2,844) of the packets carrying identifiable invariants. This level of coverage even exceeds what could be achieved with a perfect training set: assuming all URL-related invariants can be recovered from the perfect training set using other prior approaches [14], the coverage that could possibly be achieved using package names, Ad-IDs, and learned hostnames was found to be no more than 62.71%, which is 10.14% below our approach, due to the new invariable tokens discovered by Tiger (see Section 5.2).

### False Detection
We also evaluated the false detection rate, which does not require dynamically running the apps. We used all 200,000 apps collected for this evaluation. Specifically, we randomly selected 50,000 apps and generated their imprints. Then, we checked for false detections using the remaining 150,000 apps. For every app in the remaining 150,000, we checked whether it could be identified by the imprints from the 50,000 apps. If the identified app was not the one that generated the imprint, it was considered a false detection. To determine if two apps are the same, we used a strict rule: if the two apps have different MD5 values, they are considered different. Given that we removed redundant apps with the same MD5 in our dataset, any identified app from the 150,000 should be a false detection. Based on this rule, we found that the false detection rate is only 0.742%. We also measured the false detection rate for each market (Table 3). For apps from Google Play, the false detection rate is very low (only 0.155%). Some Chinese markets had higher false detection rates, possibly due to repackaged apps being misidentified by the imprints of the original apps.

### Impact of Dead Code
Some imprints from Tiger may not match any app’s traffic because their corresponding network sinks are in dead code. We estimated the ratio of non-functioning imprints by running a reachability test on the sinks of 5,000 randomly selected apps. Among the 9,488 network sinks discovered, 2,005 (21.13%) could not be reached from any entry point. Note that imprints produced by our approach are intended for use in NGFWs, which are optimized to filter traffic with a large number of signatures. Redundant signatures of a moderate scale (such as 21.13%) have a marginal impact on the firewall’s performance. Therefore, we did not integrate any mechanism for dead code removal into our implementation.

### Performance
Tiger is designed for discovering app traffic imprints on a massive scale. High performance is key to this mission, and our unique design, particularly the IPE, aims to achieve this. We conducted an evaluation to understand whether the new technique meets high-performance expectations, compared to a more straightforward alternative [32]. This evaluation was conducted on 5,000 randomly selected apps from our dataset.

**Benefit of IPE:** We ran Tiger against the conventional slicing and execution approach proposed by prior research [32]. In the experiment, we set the timeouts in both approaches to 10 minutes. The results, presented in Table 4, show that the conventional approach, which requires full slicing, took 314 hours to process all apps on a server with 20 cores. In contrast, our IPE technique spent only 25 hours. On average, our approach needed 18 seconds per app, while the conventional counterpart took 226 seconds. Table 4 also shows the number of pruned nodes from full slices. On average, 94.09% of nodes on a slice were pruned by the IPE, resulting in significant performance enhancement. Overall, Tiger achieved a 12.42× speed-up compared to the conventional approach.

**App Sizes:** We also compared the performance increase between instantiated slicing and full slicing regarding app sizes (Figure 5). From the figure, we found that Tiger's performance increases more significantly for larger apps.

### Measurement
By analyzing the traffic tokens derived from the code of over 200,000 real-world applications, we gained unprecedented insights into these imprints and their connections with today’s Android apps, including their uniqueness and effectiveness in app identification, their relations with an app’s functionalities, and the conditions for triggering their related network traffic. In addition to known invariants, we discovered other unexpected types of content that uniquely characterize a large number of popular apps. Further, from the content of some invariants, we could infer an app’s operational environments (e.g., the permissions possessed by a library’s host app). Our study also shows that traffic involving highly identifiable imprints cannot be easily triggered by automatic exploration tools like monkeyrunner, though the related functionalities can be frequently invoked by human users.

### Landscape
**Imprint Generation:** From the 203,864 apps, 181,582 apps have network sinks, and among them, Tiger discovered 392,645 imprints in total, as summarized in Table 5. Except for the PHAs from VirusTotal, the apps from other sources, including Google Play and other third-party marketplaces, have very high identification rates.