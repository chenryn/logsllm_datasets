on the left the maximal sustained rate of the
FEs as obtained from these numbers. At 600MHz, we can see that all FEs can
process common-case traﬃc at a Gigabit except Ruler. A single Ruler instance
can process only 170 Mbit. The 5 combined engines thus top at 850Mbit, which
we’ve plotted in the ﬁgure as 5x Ruler. Merging Reception and Transmission
would give us the additional engine we need for full Gigabit processing.
PDU Byte
Description
313
1.5
Reception
0
TCP reassembly 1178
26
628
Ruler
Transmission
740
2
TCP reassembly. A single threaded cycle count presents a lower-bound on the
per-segment overhead as it omits memory contention costs. Nevertheless, for
TCP its performance represents the worst-case scenario for overall throughput,
because a single thread spends much of its time waiting for memory. Since multi-
threading enables latency hiding throughput will improve dramatically.
Independent of maximal obtainable throughput is the question how indirect
stream reassembly measures up to regular copy-based reassembly. For this rea-
son we have compared them head-to-head. As we have no copy-based method
available on the micro-engines we ran this comparison in a host based Streamline
function. The two functions share the majority of code, only diﬀering in their ac-
tual data bookkeeping methods. Figure 4(right) shows that indirect reassembly
326
W. de Bruijn et al.
Maximal sustained throughput
TCP reassembly performance
d
n
o
c
e
s
r
e
p
s
t
i
b
a
g
G
i
 6
 5
 4
 3
 2
 1
 0
Rx
TCP
Ruler
5x Ruler
Tx
 0
 200  400  600  800  1000 1200 1400 1600
IP packetsize
d
n
o
c
e
s
r
e
p
s
t
e
k
c
a
p
 4.5e+06
 4e+06
 3.5e+06
 3e+06
 2.5e+06
 2e+06
 1.5e+06
 1e+06
 500000
copy
zero-copy
 0  200  400  600  800 1000 1200 1400 1600
IP packetsize
Fig. 4. Theoretical sustained throughput & TCP Reassembly performance
easily outperforms copy-based reassembly. Only for the smallest packets can the
computational overhead be seen.
Ruler. The third row in Table 5.1 shows the overhead in cycles of Ruler. As
expected, costs scale linearly with the amount of data; the cost per PDU is
negligible. The function is computation-bound: fetching 64 bytes from memory
costs some 120 cycles, but processing these costs an order of magnitude more.
For this reason multi-threading is turned oﬀ.
Prospector. We have to benchmark Prospector on the XScale, because it is not
yet ported to the micro-engines. Figure 5(left) compares throughput of Prospec-
tor to that of a payload-scanning function (we used Aho-Corasick). We show
two versions of Prospector: the basic algorithm that needs to touch all header
data, and an optimised version that skips past unimportant data (called Pro+).
The latter relies on HTTP requests being TCP segment-aligned. This is not in
any speciﬁcation, but we expect it is always the case in practise.
Each method processes 4 requests. These are from left to right in the ﬁgure:
a benign HTTP GET request that is easily classiﬁed, a malicious GET request
that must be scanned completely, and two POST requests of diﬀering lengths.
In the malicious GET case all bytes have to be touched. Since AC is faster here
than both versions of Prospector we can see that under equal memory-strain we
suﬀer additional computational overhead.
However, all three other examples show that if you do not have to touch
all bytes —the common case— protocol-deconstruction is more eﬃcient than
scanning. Looking at the right-most ﬁgure, the longest POST request, we can
see that the gap quickly grows as the payload grows. The benign GET learns
us additionally that skipping remaining headers when a classiﬁcation has been
made can result in a dramatic (here 2-fold) increase in worst-case performance.
Note that none of these example requests carry a message body. This would also
be skipped by Prospector, of course. Even without message bodies, performance
is continuously above 18,000 requests per second, making the function viable for
in-line protection of many common services.
SafeCard: A Gigabit IPS on the Network Card
327
d
d
d
d
d
n
n
n
n
n
o
o
o
o
o
c
c
c
c
c
e
e
e
e
e
s
s
s
s
s
r
r
r
r
r
e
e
e
e
e
p
p
p
p
p
s
s
s
s
s
t
t
t
t
t
s
s
s
s
s
e
e
e
e
e
u
u
u
u
u
q
q
q
q
q
e
e
e
e
e
r
r
r
r
r
 60000
 60000
 60000
 60000
 60000
 50000
 50000
 50000
 50000
 50000
 40000
 40000
 40000
 40000
 40000
 30000
 30000
 30000
 30000
 30000
 20000
 20000
 20000
 20000
 20000
 10000
 10000
 10000
 10000
 10000
 0
 0
 0
 0
 0
aho-corasick
prospector
prospector+
s
p
b
M
 1000
 900
 800
 700
 600
 500
 400
 300
 200
 100
throughput
 1
 2
 3
 4
 5
 6
# micro-engines
Fig. 5. Prospector throughput & Macro benchmark
5.2 Macro Benchmark
Our ﬁnal experiment evaluates the pipeline in hardware. We do not include re-
sults for the FEs on the XScale again, because their throughput is not measurable
in bitrate and we have already computed an upper bound. For this test we con-
nected our board to a mirror image of communication between three computers.
By using mirroring we were able to test peak throughput without interfering with
the active TCP control ﬂow. The traﬃc was generated using ab, a benchmarking
tool for Apache. When ran against two servers at the same time our maximally
obtainable rate was 940Mbits. The results are shown in Figure 5(right).
From the Figure we can see that with 6 micro-engines we can process all
traﬃc. To free up the 6th micro-engine we had to remove the transmission unit
temporarily. The presented numbers are worst-case estimations as a result of
crude dropped traﬃc statistics. Actual performance could be up to 20% higher.
6 Discussion
Limitations. The presented solution is an amalgam of solutions. While fairly pow-
erful as a whole, we are aware of improvements that could be made to its parts. For
starters, while Ruler accepts most Snort rules through our snort2ruler compiler,
there is a subset of expressions that we cannot handle yet. In Prospector, we do not
currently block format string attacks, although this is possible in principle. We are
currently implementing this feature and expect to have it available soon. Also, the
ﬂow-based IDS (stage 5) is currently rather naive and should be improved.
Finally, while we have tried to implement a powerful set of network-based
intrusion prevention methods, we have clearly not exhausted the options. For