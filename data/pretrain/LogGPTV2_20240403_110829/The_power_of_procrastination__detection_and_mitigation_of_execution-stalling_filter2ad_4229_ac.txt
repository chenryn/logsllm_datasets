we could pick the innermost active loop. This assumes that the ex-
ecution is stalled inside the loop that is currently executing, and the
code region for which logging is reduced is as small as possible
(which is desirable). However, if the inner loop is only a part of a
larger stalling loop, accelerating only this region is not sufﬁcient.
As an alternative, it is also possible to simply take the outermost
loop. In this case, it is very likely that the stalling code is covered
in its entirety. On the downside, reduced logging will be enabled
for a larger portion of the malicious code. Thus, in our system, we
pick the innermost, active loop as the stalling loop. This ensures
the most accurate analysis results. In the following subsection, we
discuss how we handle the situation when this innermost loop does
not cover the entire stalling code region.
5.2 Reducing Analysis Overhead
Once the system has selected the active loop that is likely caus-
ing the execution to stall, we have to ﬁnd the entire code that is part
of the stalling code. Of course, the code blocks that are part of the
selected, active loop are part of the stalling code, but this is not ev-
erything. We also need to add to the stalling region all code blocks
that are reachable from any block in the loop body, even when these
blocks are not live at the point in time. This is necessary because
the stalling region must cover the entire code that is executed as
part of the loop; including other functions that can be invoked by
the loop, not only those parts that are currently live. However, it is
important to remember that the stalling code region can only con-
tain basic blocks that the program has executed previously (others
are not part of our CFG).
To ﬁnd the stalling code region, we ﬁnd all code blocks b in the
CFG so that there is a path from any active loop block to b. This
is very similar to the analysis that ﬁnds live code blocks, but with
the main difference that a path can pass through any call edge (and
not only live call edges). All code blocks b that are found by this
analysis are added to the stalling region. In the example shown in
Figure 4, this means that the stalling code also includes code blocks
in function f (since they are reachable from l2 in m).
Once we have found all blocks that are part of the stalling code,
we reduce the amount of analysis that is performed while this code
is executing. More precisely, we temporarily disable logging of all
functions that are not critical for the proper operation of the analysis
system or that we consider highly security-critical. Examples for
functions that are continued to be analyzed even in these situations
are related to loading of libraries or spawning of new processes. Of
course, this is done only for the selected thread and limited to the
identiﬁed stalling code.
Whenever the execution exits the stalling region, we switch back
to monitoring mode. To this end, we whitelist all blocks that are
part of the stalling loop. Whenever execution encounters a non-
whitelisted code block, the system is reverted back to monitoring
mode, and the full analysis is re-enabled.
In case a stalling region contains multiple, nested loops, we ﬁrst
whitelist the innermost loop. When we later observe that this is not
sufﬁcient, the whitelisted region is successively extended to cover
also the enclosing, parent loops. The details of the process are
described in Appendix B.
6. ACTIVE MODE
In passive mode, HASTEN attempts to accelerate the execution
of stalling loops by reducing the overhead associated with logging
security-relevant functions. Unfortunately, this might not be sufﬁ-
cient to obtain progress. In particular, malware authors can write
stalling code that exploits machine instructions that are very slow to
emulate (such as ﬂoating point or MMX instructions). To address
such types of stalling code, we introduce HASTEN’s active mode.
In active mode, the system forces the termination of the whitelisted
stalling code. The purpose of this is to continue to explore the pro-
gram execution further.
6.1 Modifying the Flow of Execution
When entering active mode, we ﬁrst have to identify suitable
nodes in the CFG that have an outgoing edge that exits the stalling
loop. To this end, HASTEN searches all whitelisted code blocks
that are part of the stalling region for those that end in a condi-
tional branch. Then, the system checks whether any of these con-
ditional branch instructions has a successor node that is not part of
the stalling region. These instructions are marked as exit points.
If the system fails to ﬁnd at least one suitable exit point, HASTEN
stops analysis and ﬂags the analysis report for subsequent human
analysis. Finally, we resume the execution of the malware.
Whenever the process subsequently attempts to execute an exit
point instruction, HASTEN examines the operands of the branch
operation and determines the path that the execution is about to
take. When this path exits the stalling region, the process is allowed
to continue. Otherwise, our system will dynamically invert the
branch (for example, a greater-than operation is changed into less-
or-equal). This means that HASTEN will take the ﬁrst exit point that
the execution encounters after switching into active mode. See Sec-
tion 8 for a discussion of the implications of this approach. Once
execution leaves the whitelisted code region, HASTEN re-enables
full monitoring.
6.2 Handling Inconsistent Variables
When HASTEN changes the control ﬂow and, thus, the execution
of a process, the state of this process might become inconsistent.
This is a problem when the program later tries to access or use vari-
ables that are modiﬁed by the stalling code (but that hold incorrect
values). For example, the program could compute a magic value
290inside a stalling loop that is checked afterwards; a simple mecha-
nism to detect whether an analysis system has skipped the stalling
code.
To handle the problem of inconsistent variables (which are vari-
ables that hold potentially incorrect values), we use taint analysis to
track memory locations that might hold incorrect values (as well as
the variables that are derived from these memory locations). When
the program later uses a potentially inconsistent variable, we ex-
tract a slice that efﬁciently computes the correct value.
In a ﬁrst step, we need to determine all memory locations that
can potentially be written by the stalling code. We can then assign
a taint label to these variables that marks them as inconsistent. Our
underlying analysis platform already supports the tracking of taint
labels. That is, whenever a computation (or data transfer opera-
tion) involves at least one tainted source operand, the destination is
tainted as well. As a result, at any later point in time, the system
can determine whether the value of a memory location was derived
from an inconsistent variable.
To approximate all locations that can be written by the stalling
code, we use the following technique: While the program is exe-
cuting in passive mode, we label the destinations of all arithmetic
and logic operations. Given that the stalling code is executed many
times, we assume that we see all write targets at least once.
Whenever a labeled (tainted) value is used as an operand in a
control ﬂow operation (a conditional or indirect branch), an indirect
memory access, or an argument in a system call, HASTEN needs to
step in. This is because using an incorrect value as input to these
fragile operations might yield visibly incorrect program behavior
(such as program crashes, invalid outputs, etc.). This is different
from “normal” instructions, which HASTEN handles in a lazy fash-
ion by simply propagating taint labels.
Efﬁciently computing inconsistent variables. Whenever HAS-
TEN encounters a fragile instruction that uses a tainted operand, we
need to efﬁciently compute its correct, expected value. To this end,
we extract a backward slice from the malware program that con-
tains exactly the instructions necessary to compute the inconsistent
value.
To extract the slice, we leverage our previous work on INSPEC-
TOR [18], a tool to extract stand-alone programs (gadgets) from
malware programs. More precisely, the goal of INSPECTOR is to
extract, from a given malware binary, a slice that computes the ar-
gument values of interesting (security-relevant) system calls. This
is very similar to our problem, where we are interested in a slice
that computes the value of an inconsistent variable.
To perform its task, INSPECTOR employs binary backward slic-
ing. This process exploits the fact that detailed runtime information
can be gathered from the dynamic execution of malware (such as
the targets of indirect memory accesses and control ﬂow instruc-
tions). This allows the extraction of complex slices that span mul-
tiple functions and involve elaborate memory access patterns. For
space reasons, we have to refer the reader to our previous paper [18]
for a detailed discussion of INSPECTOR.
Once our system has extracted a slice, it can be executed as a
stand-alone program by the slice player that comes with INSPEC-
TOR. Note that the slice player performs no instrumentation, and it
can execute the code directly on a native host. Thus, the slices ex-
ecute the stalling code very fast, basically as fast as on the victim’s
machine. For stalling code that exploits the overhead introduced
by slow emulation, this can speed up execution by several orders
of magnitude. Once the slice has computed the required value, it
replaces the current (incorrect) value of the tainted variable, and
HASTEN continues the execution of the malware process.
7. EVALUATION
In this section, we evaluate HASTEN’s ability to mitigate stalling
code in malware binaries. We show that detecting signs of low
progress works on samples found in the wild, and we test the effec-
tiveness of HASTEN’s different modes.
7.1 Malware Data Set
To evaluate our system, we randomly selected 29,102 samples
from the ﬁles that were submitted to ANUBIS between August 2010
and February 2011. When picking malware programs for our data
set, we did not include any invalid Windows PE ﬁles or ﬁles that
failed to load in the analysis environment (e.g., due to unresolved
library dependencies). Moreover, we did not select any sample that
terminated within the time allocated for the original analysis run
(in our case, 240 seconds). The reason is that these samples have
already revealed their entire malicious activity during the allocated
analysis timeframe. Our data set represents a diverse mix of mal-
ware currently active on the Internet.
We also retrieved the analysis report generated for each of the
samples. We refer to these reports as the base run, and we use
the observed behavior as one part to evaluate whether HASTEN is
successful in revealing additional behavior.
7.2 Measuring Behavior
The goal of HASTEN is to reveal additional behaviors in malware
samples that contain stalling loops. To be able to measure this in
an automated fashion, it would be tempting to simply re-run each
sample in our system and compare the observed behavior to this
sample’s base run. However, this would not be fair. The reason is
that the behavior exhibited by a sample can signiﬁcantly depend on
the date/time of analysis and the availability of remote resources.
Thus, for a fair evaluation of HASTEN, we re-ran each of the
samples twice: First, we performed a redundancy run with iden-
tical settings compared to the base run; in parallel, we conducted
a test run using HASTEN. In this way, we attempted to minimize
external inﬂuences on the behavior of a sample by eliminating the
time between test and redundancy runs for each binary.
Whenever a test run reveals added behavior compared to the re-
dundancy run, we also compare the redundancy run to the (initial)
base run. If these two runs differ considerably, it is possible that
the detected, added behavior is independent of HASTEN. To assess
the added behavior produced by HASTEN, we use three different
metrics: Optimistic improvement (OI) considers any added behav-
ior seen during the test run (over the redundancy run) as an im-
provement due to HASTEN. Average improvement (AI) takes into
account randomness in malware executions. To this end, we do
not attribute any added behavior to HASTEN when the test run pro-
duces less added behavior than the corresponding redundancy run
over the base run. Pessimistic improvement (PI) counts added be-
havior in the test run as new only when redundancy and base runs
do not differ.
Added behavior. To determine added behavior when comparing
two analysis runs, we only take into account persistent features of
the corresponding behavioral proﬁles: A persistent feature is an ac-
tivity performed by the malware that is visible from the outside of
the analysis sandbox or that introduces permanent changes to the
system. Examples for such features are communicating over net-
work sockets, writing to ﬁles in the ﬁle system, or opening graph-
ical windows. Table 3 (Appendix C) lists all combinations of re-
sources and actions that we considered persistent features in this
paper. In our setting, focusing on persistent features is reasonable,
since they are indicative of the typical behavior used to classify and
detect malware.
2917.3 Evaluation Results
We analyzed each of the 29,102 samples in our test set twice;
once without HASTEN (redundancy run), and once with our system
enabled (test run). HASTEN has a negligible impact on analysis
performance in monitoring mode and only introduces small over-
heads in the other modes. We considered extending the analysis
time for the test runs to compensate for this difference. However,
this difference is difﬁcult to predict precisely. Thus, we conserva-
tively used the same timeout (240 seconds) for all evaluation runs.
Monitoring mode results. 9,826 (33.8%) of the analyzed mal-
ware programs exhibited insufﬁcient progress at some point during
the analysis. That is, at least one of the heuristics triggered. In
98.3% of these cases, observing too few successful system calls
was the predominant cause for switching into passive mode. An
excessive number of successful and failed system calls were ob-
served in 1.5% and 0.3% of the cases, respectively. Throughout
our experiments, the heuristics for identical or suspiciously diverse
calls never triggered. This does not come as a surprise, however,
as we introduced these to increase the burden to bypass our sys-
tem. With attackers becoming aware our system, we expect these
detectors to become more important.
For the 9,826 low progress samples, HASTEN switched into pas-
sive, and, if necessary, also into active mode. The remaining 19,276
programs showed good progress. While this number appears large
at ﬁrst glance, it makes sense. We do not expect that a majority of
malware samples in the wild already contains stalling code against
sandboxes.
Passive mode results. Whenever HASTEN switches into passive
mode, the system starts to record the control ﬂow of the thread
that stalls and tries to extract live loops. For the 9,826 samples
that exhibited stalling behavior, the tool was able to do so in 6,237
(63.5%) cases.
We manually inspected some of the remaining 3,589 cases to
determine why no loop was identiﬁed, despite low progress. We
found that many samples were in a “mostly waiting” state; that is,
the threads were sleeping, occasionally interrupted by the OS that
invoked a callback function. In other cases, we found that “stalling
loops” were of short duration, and threads made progress before
HASTEN could complete the analysis of the loop. We attribute
these cases to the conservative thresholds that we selected for the
detectors in monitoring mode. That is, the malware processes show
signs of low progress but it is not due to malicious stalling. Thus,
we cannot expect that HASTEN can extract added behavior. Note
that the negative impact of switching into passive mode is minimal
(only a small performance loss).
We further investigated the 6,237 samples for which HASTEN
discovered insufﬁcient progress and extracted a live loop. In 3,770
cases, the system only switched into passive mode. In the remain-
ing 2,467 test runs, the system activated the passive and, subse-
quently, the active mode. Table 1 details our ﬁndings of new, added
behavior observed during the test runs, using the average improve-
ment metrics (for a detailed overview of added behaviors using the
optimistic and pessimistic metrics, refer to Table 4 in Appendix D).
The table also shows the number of malware labels assigned to dif-
ferent sets of malware samples by a popular anti-virus product. We
used only the family portion of the malware labels for this analysis
(that is, W32.Allaple.A becomes allaple). Of course, we
are aware of the limitations of labels assigned by anti-virus prod-
ucts. We just provide these numbers to underline the heterogeneity
of our malware data set.
The left side of Table 1 shows that the passive mode allowed
HASTEN to observe new behaviors in 1,003 runs (26.6% of all
passive-only runs). With 25.2% and 14.9%, ﬁle and registry mod-
iﬁcations are the most prevalent behavior detected by HASTEN,
respectively. Furthermore, 11.8% of samples in this class partic-
ipated in new networking behavior, which can lead to the exposure
of new command and control servers or drop zones on the Internet.
HASTEN detected added behavior in 1,447 more cases. How-
ever, due to the conservative nature of our evaluation, and since
the redundancy run also produced additional features, we cannot
conclusively attribute this to our approach.
For the remaining 1,320 analysis runs, we did not observe new
behavior, but neither did the system advance into active mode. Typ-
ically, this means that HASTEN did not manage to build a whitelist
in time that covers the entire stalling code. More precisely, while
building the CFG, some paths inside the stalling code were ini-
tially not observed, or a deeply nested stalling loop is executed.
As a result, HASTEN repeatedly hits non-whitelisted code, which
switches the system back into monitoring mode. After monitoring
progress for another time slot, passive mode is re-enabled, and a
more complete whitelist is generated. However, the analysis time-
out is encountered before this iterative process can complete. A
longer timeout or more aggressive whitelisting could be used to
address such situations.
Active mode results. For certain samples, HASTEN did not ob-
serve progress despite reduced logging. Thus, the system proceeds
to actively interrupt stalling code to force forward progress. In our
evaluation set, HASTEN modiﬁed the control ﬂow of 2, 467 sam-
ples, revealing new behavior in 549 analysis runs (22.3%). The
right-hand side of Table 1 shows details about the added behaviors.
While new behavior in passive mode always means additional,
relevant activity, we need to be more careful in active mode: Since
we actively change the ﬂow of execution, we could follow infea-