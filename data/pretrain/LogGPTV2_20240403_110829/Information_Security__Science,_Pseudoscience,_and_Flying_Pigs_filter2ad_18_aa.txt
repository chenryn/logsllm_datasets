title:Information Security: Science, Pseudoscience, and Flying Pigs
author:Roger R. Schell
Information Security: Science, Pseudoscience, and Flying Pigs 
Dr. Roger R. Schell 
Aesec Corporation 
PI:EMAIL 
Abstract 
tools 
rich  with 
solutions  and 
The  state  of  the  science  of  information  security  is 
astonishingly 
to 
incrementally and selectively solve the hard problems.  In 
contrast,  the  state  of  the  actual  application  of  science, 
and  the  general  knowledge  and  understanding  of  the 
existing  science,  is  lamentably  poor.    Still  we  face  a 
dramatically  growing  dependence  on 
information 
technology,  e.g.,  the  Internet,  that  attracts  a  steadily 
emerging  threat  of  well-planned,  coordinated  hostile 
attacks.   A series of hard-won scientific advances gives 
us the ability to field systems having verifiable protection, 
and  an  understanding  of  how  to  powerfully  leverage 
verifiable  protection  to  meet  pressing  system  security 
needs.    Yet,  we  as  a  community  lack  the  discipline, 
tenacity and will to do the hard work to effectively deploy 
such  systems.    Instead,  we  pursue  pseudoscience  and 
flying  pigs.    In  summary,  the  state  of  the  science  in 
computer  and  network  security  is  strong,  but  it  suffers 
unconscionable neglect. 
1.  Introduction 
The  scientific  underpinnings  of  computer  and 
network  information  security  have  not  changed  much  in 
twenty  years. 
  This  is  not  surprising  because  the 
fundamental  properties  of  information  theory  and  the 
limits  on  what  is  computable  are  not  subject  to  much 
evolution.   
The  science  of  computer  and  network  information 
security has for some time given us the ability to purchase 
an  information  system  from  a  mortal  enemy  and  then 
assess its ability to enforce a well defined security policy, 
gaining sufficient assurance to confidently use the system 
to  protect  against  massive  loss  and  grave  damage,  and 
this  has  been  actually  been  put  into  practice.    This 
astonishing capability is known as “verified protection”.    
On the other hand, the state of the pseudoscience of 
computer security has changed primarily in its success as 
a  growth  industry.    Much  of  the  same  old  snake  oil  is 
being  peddled,  but  the  manufacturing  capacity  has 
ramped up  geometrically.   The pursuit of pseudoscience 
remains  an  incredible  source  of  research  dollars  and 
product  revenue.    To  sustain  this  growth  the  science  of 
computer  security  has,  on  the  other  hand,  been  widely 
abandoned  and  orphaned,  summarily  declared  a  failure 
and  unworkable  by  a  community  inclined  to  ignore 
scientific success and worked examples. The result of this 
tension between science and pseudoscience was that our 
ability to achieve verified protection in fielded computers 
and  networks  peaked  somewhere  near  the  mid  nineties. 
Figures 1 and 2 are notional illustrations of some of the 
associated  disturbing  trends.    As  many  more  businesses 
become more aware of their needs for secure systems, and 
attract  more  “experts”  there  is  a  smaller  percentage  of 
“experts”  who  actually  understand  the  hard  issues,  as 
illustrated  in  Figure  1.    Figure  2  illustrates  that  at  the 
same time, the ability to procure a bulletproof system is 
% of Practitioners Who are  
Knowledgeable of the 
Science  
% of CIOs 
Concerned About  
Security 
1970   
1980  
1990  
2000  
Figure 1: Expertise Diminishes as It is Needed 
Availability   of 
Weak Security  
Products   
Ability to Obtain  
Bulletproof  
Systems   
1970 
2000  
Figure 2: Lack of Evaluated Products  
1980 
1990   
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 07:10:17 UTC from IEEE Xplore.  Restrictions apply. 
diminished while the market is thick with products having 
weak  security.    So  how  did  we  get  to  this  unfortunate 
state?  It is hoped that the rest of this essay will help make 
that clearer. 
2.  Critical Areas of Focus 
This essay strives to provide a critical examination of 
the state of the science in computer and network security 
in  light  of  the  author’s  experiences  from  nearly  the 
beginnings of computer security to the present.  However, 
before we review the scientific advances that preceded the 
current decline, it is useful to examine what is meant by 
verified  protection,  acknowledge  significant  remaining 
hard  problems,  and  review  what  verified  protection  can 
and  cannot  help  us  achieve.    And,  we  will  review  the 
ability  to  leverage  verified  protection  within  systems  to 
divide and conquer seemingly intractable problems. 
2.1. Verifiable Protection 
Malicious  software  is  the  tool  of  choice  for  well-
planned  professional  attacks  and  is  the  primary  threat 
addressed  by  systems  offering  verified  protection.  To 
counter  malicious  software 
these  systems  must  be 
designed and built  from the  very  start to have all of the 
following properties: 
•  Designed to have no exploitable security flaws. 
•  Enforce  security  policies  on 
information  flow, 
the  damage  of  malicious 
thereby  bounding 
applications software (e.g., Trojan Horses). 
•  Built  to  be  subject  to  third  party  inspection  and 
analysis  to  confirm  the  protections  are  correct, 
complete  and  do  nothing  more  than  advertised  (i.e., 
no trap doors). 
Scientific  foundations  of  information  security  have 
provided  us  with  three  necessary  tools  for  achieving 
verifiable protection: 
•  An  ability  to  identify  situations  where  verified 
protection  is  both  needed  and  possible.    Central  to 
this 
fundamental  distinction  between 
discretionary and mandatory security policies. 
•  The  tools  and  techniques  to  implement  and  field 
heterogeneous  systems  where  some,  but  not  all, 
components have verified protection. 
•  Criteria  and  methods  to  independently  verify  the 
protections offered by such systems. 
Though  sufficient  to  solve  many  of  today’s  serous 
challenges,  verified  protection  is  not  the  solution  to  all 
computer security problems.  Nor is the state of verified 
protection complete and without areas that could benefit 
from new research. 
the 
is 
2.2. Remaining Hard Problems 
Several hard problems remain. These include:  
•  Verifying  the  absence  of  trap  doors  in  hardware, 
particularly  with  the  amount  of  automated  design 
currently  used.    It  has  been  estimated  that,  “A 
product designed to cope with subversion could cost 
50 to 100 times as much as . . . non-secure products 
of  similar  functionality”  [1].    Potential  ameliorating 
approaches  are  analogous  to  NSA’s  use  of  cleared 
programmers.  
•  Verifying  the  absence  of  trap  doors  and  other 
malicious  software  in  development  tools  such  as 
compilers and linkers.   
•  Covert  timing  channels  remain  a  problem,  however 
there  are  demonstrated  methods  of  significantly 
reducing them. 
•  Covert  channels  in  end-to-end  encryption  systems 
(e.g., VPNs) remain a significant challenge. 
•  Despite  some  progress,  we  lack  formal  methods  for 
meaningfully corresponding source code to a formal 
specification, and object code to source. 
•  Denial  of  service  attacks  can  be  reduced  but  not 
effectively eliminated. 
2.3. Omniscient Classification of Information 
  The 
classify 
inability 
to  omnisciently 
the 
confidentiality  or  integrity  of  information  is  perhaps  the 
single  most visible intractable problem in the  science of 
information security, and is likely to remain so.  And thus 
malicious e-mail attachments remain a problem. Science 
has produced no solution to the problem of rotten apples 
in a barrel.  Users want the convenience of inhabiting the 
same  integrity  domain  as  the  least  conscience  and  least 
informed  among  them.    When  some  in  such  a  domain 
behave  badly,  everyone  suffers.    Deciding  to  inhabit 
different  domains  at  different  times  largely  solves  the 
problem.  Otherwise users must live with the vandals, the 
graffiti artists and the untrained co-workers who invite in 
the  riff  raff.    Compounding  this  problem  is  the  trend 
toward  “transportable  code”.    Ultimately  however,  there 
is no difference between code and data when it comes to 
maintaining the integrity of a domain.  Many years ago, 
this very fact led General Motors to establish two parallel 
domains  in  their  operations  and  network:  one  for  use  in 
generating  and  managing  engineering  data;  and  one  for 
everything  else. 
  Users  consciously  decided  which 
domain they would inhabit at any given time.  This use of 
closed  user  groups  is  a  relatively  simple  solution  to  an 
otherwise intractable problem. 
 The key to maintaining separate domains that permit 
information to flow in accordance with the desired policy 
is  the  use  of  security  labels  to  enforce  a  mandatory  [2] 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 07:10:17 UTC from IEEE Xplore.  Restrictions apply. 
that 
is  global  and 
security  policy  –  enforcement 
persistent.    Security  labels  can  be  viewed  as  a  social 
mechanism  for  understanding  the  sensitivity  of  your 
current  context,  be  it  the  processing,  the  reading  or  the 
writing  of  information.    Some  incorrectly  claim  that  the 
use  of  security  labels  is  not  a  viable  solution  because  it 
would require the a priori assignment of classifications to 
data,  people  and  processes  on  a  global  basis.    In  fact, 
labels can be structured such that their interpretation can 
be based on a layering of policies such that local policies 
are  only  interpreted  locally.    An  example  of  such  a 
labeling  strategy  is  the  distributed  dynamic  labels  for 
digital certificates defined by Novell [3] and incorporated 
into their flagship NetWare product, and used by others. 
2.4.  Success Through Divide and Conquer 
History has shown that we need not solve all of the 
problems  at  once  to  have  suitably  secure  systems.    The 
ability  to  divide  and  conquer  problems  has  permitted 
great  advances.    A  core  innovation  in  the  science  of 
computer  security  is  to  structure  systems  into  those 
elements of hardware, firmware and software that enforce 
the security policy and those elements that do not.  As a 
result of such a partitioning, only a subset of the overall 
system  must  offer  verified  protection,  and  that  subset  is 
called  the  “Trusted  Computing  Base”  (TCB)  [4].  In 
particular, most of what is commonly viewed as operating 
system functions and all of the applications software need 
not offer verified protection and are therefore external to 
the TCB.   A basic ability to control access to information 
can  be  extended  by  partitioning  other  problems  into 
manageable pieces and designing systems to fail secure.   
As  systems  get  more  complex  and  unmanageable, 
you  end  up  with  the  Internet.    There  are,  however, 
positive  aspects 
the  Internet 
environment that support divide and conquer techniques.  
The development and acceptance of line protocols as the 
primary systems interface has eliminated many of the past 
“compatibility” problems.  Where once an application had 
to be instruction set compatible with an IBM mainframe, 
now  a  lot  can  be  achieved  through  compatibility  with  a 
line  protocol.    This  enables  heterogeneous  systems  with 
selective  use  of  secure  appliances  (e.g.,  Certificate 
Authorities) whose interface is the network rather than a 
particular operating system. 
the  evolution  of 
to 
The  Internet  can  also  greatly  benefit  from  the 
adoption  of  the  IPSEC  standard.    Assuming  secure 
protocols  for  managing  keys  become  widely  adopted, 
VPNs  based  on  IPSEC  can  do  a  lot  towards  bringing 
strong  security  to  the  Internet  environment.    The  use  of 
PKI  for  managing  IPSEC  keys  holds  much  promise, 
particularly because PKI can be built to support a variety 
of different distributed systems (again permitting a divide 
and conquer approach).  However PKI introduces a new 
TCB 
set  of  vulnerabilities  that  must  be  countered  with  more 
than emphatic assertion.  For example, unless there exists 
a  strong  technical  basis  for  assuming  certificates  cannot 
be forged (e.g., through the  use of trap doors planted in 
platform  operating  systems)  PKI’s  foundations  will 
remain mired in pseudoscience. 
extensions 
a  powerful 
technique 
demonstrated by Novell [5] to achieve a secure client to 
interoperate  with  their  server  within  a  well-defined 