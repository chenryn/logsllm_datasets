### Parsec [41]
#### Input
- 100,000,000
- 75,000
- simsmall (repeated six times)

#### Table II: Summary of the Benchmarks Evaluated

### K. Summary
We have discussed the hardware requirements for parallelizing error detection across a set of small cores. These cores monitor the loads and stores committed by the main core and use this information to replay the instructions executed by the main core. The loads and stores are distributed within a partitioned load-store log, separated by register checkpoints, allowing each checker core to work on a different part of the main core's execution simultaneously.

A checker core begins execution once its segment of the load-store log is filled or a timeout value is reached. Upon detecting an error, the fault is reported to the program, which must then either terminate execution or restore the memory system to a consistent state from which execution can restart.

Our scheme achieves error detection with minimal power, performance, and area overheads by trading off detection latency for parallelism. The following sections will quantify how each of these factors is affected by our scheme.

### Figures
**Figure 7: Normalised Slowdown for Each Benchmark at Standard Settings (Table I)**
- Performance Impact: The average slowdown is 1.75%, with no benchmark slowing down by more than 3.4%. Overheads are primarily due to the time taken to checkpoint registers at the end of a load-store log segment.

**Figure 8: Density Plot of Error Detection Delays at Standard Settings (Table I)**
- Distribution of Delays: Each benchmark's delay distribution resembles a normal distribution, with benchmarks featuring more homogeneous workloads (randacc, stream, facesim) closely matching this. The highest average delay, 1550 ns, comes from randacc, which is highly memory-bound with little temporal or spatial locality, resulting in a low IPC. The maximum detection delay is significantly higher, averaging 21.5 μs, but these points are rare, with 5000 ns covering over 99.9% of all loads and stores.

### V. Experimental Setup
To evaluate the performance of the checker cores and the latency between an error and its detection, we modeled a high-performance system using the gem5 simulator [42] with the ARMv8 64-bit instruction set and configuration given in Table I, similar to systems validated in previous work [43]. A summary of the benchmarks evaluated is provided in Table II. We used benchmarks from Parsec [41], along with RandomAccess and STREAM from the HPCC benchmark suite [39] and Bitcount from MiBench [40] to cover a wide range of workloads, including extreme and worst-case scenarios.

### VI. Evaluation
**Figure 7: Performance Impact of Parallel Error Detection**
- The average slowdown is 1.75%, with no benchmark slowing down by more than 3.4%. Overheads are primarily due to the time taken to checkpoint registers at the end of a load-store log segment.

**Figure 8: Distribution of Delays Between Loads and Stores**
- The delays for each benchmark resemble a normal distribution, with the most homogeneous workloads (randacc, stream, facesim) closely matching this. The highest average delay, 1550 ns, comes from randacc, which is highly memory-bound with little temporal or spatial locality, resulting in a low IPC. The maximum detection delay averages 21.5 μs, but these points are rare, with 5000 ns covering over 99.9% of all loads and stores.

**Figure 9: Normalised Slowdown When Varying the Frequency of the Checker Cores**
- The performance impact of varying the clock speed of the checker cores is shown. Memory-bound benchmarks (randacc, stream) do not experience significant performance losses even at low frequencies. However, compute-bound benchmarks (swaptions, bitcount) slow down significantly, particularly at clock speeds lower than 500 MHz, as the checker cores combined do not have enough compute power to keep up with the main core.

**Figure 10: Slowdown Due to Register Checkpoint Overhead**
- Even without the main core stalling, our scheme incurs some performance overhead from register checkpoint latency at the end of a segment. We assume a 16-cycle pause in commit when this occurs, allowing two-ported register files to copy 32 registers from each file.

### A. Parameter Sensitivity
- **Clock Frequency**: Figure 9 shows the performance impact of varying the clock speed of the checker cores. Memory-bound benchmarks (randacc, stream) do not experience significant performance losses even at low frequencies. Compute-bound benchmarks (swaptions, bitcount) slow down significantly, particularly at clock speeds lower than 500 MHz.
- **Log Size / Instruction Timeout**: Figure 10 shows the slowdown due to register checkpoint overhead across different queue sizes and instruction timeouts.

This optimized text provides a clearer and more professional structure, making it easier to understand the key points and findings of the research.