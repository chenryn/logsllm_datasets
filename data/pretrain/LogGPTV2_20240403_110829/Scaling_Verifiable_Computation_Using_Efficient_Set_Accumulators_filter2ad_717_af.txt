13The costs of MiMC, Poseidon, and JubJub depend on the underlying
elliptic curve; we target BLS12-381 [27]. The cost of SHA-256 is ≈30%
higher in Sapling than in prior work [1], but even the best reported costs are
more than 10× the other hashes’ costs. This discrepancy does not change our
results: we focus on Poseidon, which is the best case for Merkle trees (§7.1).
USENIX Association
29th USENIX Security Symposium    2085
(1) How does the cost of a MultiSwap compare to the cost
of Merkle swaps for a batch of swaps? In particular, what
is the break-even point (i.e., the number of operations
beyond which MultiSwap is cheaper), and how do costs
compare for a ﬁxed (large) constraint budget?
(2) What is the effect of hash function cost on the tradeoff
between RSA accumulators and Merkle trees?
We answer the ﬁrst question by synthesizing constraint
systems for both MultiSwap and Merkle swaps, at varying
set and batch sizes (§7.1). We also synthesize constraints
for the Rollup application (§7.2) and compare the persistent
RAM application using a cost model (§7.3). Our cost metric
is number of constraints; to validate this metric, we measure
end-to-end times for MultiSwap and Merkle swaps (§7.1).
For the second question, we evaluate the break-even point
for MultiSwap versus the cost of the underlying hash function,
for four different hash functions (§7.1).
In sum, we ﬁnd that MultiSwap breaks even for batch sizes
of at most several thousand operations; for large sets, this
value is several hundred. We also ﬁnd that MultiSwap’s ad-
vantage is greater when hashing is more expensive.
Baseline. Our baselines are constraint systems (§2.2) that
use Merkle trees (§2.1) to store state. For each baseline, we
ﬁx capacity to be M = 2m, for a range of m values. In all
experiments except persistent RAM, the basic Merkle tree
operation is a swap (§5, Fig. 3). Merkle-based RAMs use a
mix of membership proofs and swaps (§2.1, §2.2); we discuss
further in Section 7.3.
Setup. Except in the hash cost experiment (§7.1), both
Merkle and MultiSwap ﬁx the hash function H (§4.1, §4.2)
as our Poseidon [69] implementation (§6). As we show in
Section 7.1, this is the most favorable choice for the Merkle
baseline, because Poseidon is inexpensive in constraints.
For execution time (§7.1), our testbed has two Intel Xeon
E5-2687Wv4 CPUs (12 physical cores per socket, 48 threads
total) and 128 GiB of RAM, and runs Ubuntu 18.04. We com-
pile with Rust 1.41-nightly (c9290dcee 2020-02-04) [103].
Method. Our primary cost metric is number of constraints,
which we measure with a custom Bellman synthesizer (§6).
We use this metric because P ’s costs (both time and space)
are dominated by constraint count in the back-ends we tar-
get (§2.2). V ’s costs are small and essentially constant.
To validate this metric, in Section 7.1 we measure P ’s and
V ’s time for MultiSwap and Merkle swaps, for 220-element
sets. Limitations of the underlying Bellman and Sapling li-
braries (§6) cause our MultiSwap and Merkle implementa-
tions to unnecessarily resynthesize all constraints when gen-
erating proofs. To sidestep this, for each experiment we mea-
sure total proving time (synthesis, witness computation, and
proof generation), separately measure just synthesis time, and
report the difference. Fixing this issue (by rewriting Bell-
man/Sapling) is future work.
Figure 4: Constraint count v. number of swaps (§7.1). “Merkle
m” denotes a Merkle tree with 2m leaves.
Accumulator
Merkle 5
Merkle 10
Merkle 15
Merkle 20
RSA
Swaps
263 713
143 843
98 892
75 346
250 201
Accumulator
Merkle 5
Merkle 10
Merkle 15
Merkle 20
RSA
Transactions
48 463
37 100
30 053
25 256
47 203
(a) Swaps (§7.1).
(b) Payments (§7.2).
Figure 5: Number of operations veriﬁable in 109 constraints
(higher is better).
7.1 MultiSwap versus Merkle swaps
Benchmark. This experiment compares the costs of
MultiSwap and Merkle trees for a computation comprising
only swaps, varying the number of swaps and set size.
Constraint costs. Figure 4 shows the results. The cost of
Merkle trees varies with set size, because the number of hash
invocations depends on this value (§2.1; §5, Fig. 3). In con-
trast, the constraint cost of MultiSwap is independent of the
number of elements in the set; for moderately sized sets (≈210
elements), the per-swap cost is less than for Merkle trees.
On the other hand, MultiSwap pays a large overhead
(≈11 million constraints) to evaluate Hp and verify two
Wesolowski proofs (§4; §5, Fig. 3). Thus, MultiSwap requires
some minimum batch size before it breaks even. For small
sets (say, 25 elements) there is no break-even point; for sets
with 210 or more elements, the break-even point is at most a
few thousand swaps, and decreases with set size.
Figure 5a shows the number of swaps that ﬁt in 109 con-
straints, for different accumulators. (We compare at this size
because it is close to the largest that prior work can han-
dle [121].) Depending on set size, MultiSwap improves reach-
able batch sizes by up to ≈3.3×.
2086    29th USENIX Security Symposium
USENIX Association
Figure 6: Witness computation plus proof generation time v.
number of swaps, for accumulators with 220 elements (§7.1).
Figure 8: Constraint count v. number of transactions (§7.2).
“Merkle m” denotes a Merkle tree with 2m leaves.
(other set sizes are analogous; note that the axes are loga-
rithmic). We measure MiMC, Poseidon, Pedersen/Jubjub,14
and SHA-256 (§6). As expected, in all cases Merkle trees
are cheaper for small numbers of operations. For the least
expensive hash (Poseidon), MultiSwap’s break-even point
is the highest; as hash cost increases, so does MultiSwap’s
advantage. (We report results in all other experiments with
Poseidon, which is the worst case for MultiSwap.)
7.2 Application: payment system
Benchmark. This experiment compares the costs of
MultiSwap and Merkle trees for the Rollup application de-
scribed in Section 5.1. We measure cost versus the number
of transactions (a signature veriﬁcation, a validity check, and
two swaps). Signatures use the scheme from ZCash [72].
Results. Figure 8 shows the results. In contrast with the
previous experiment, here all accumulator types pay a ﬁxed
overhead per transaction (this is dominated by signature veri-
ﬁcation), which reduces MultiSwap’s per-transaction advan-
tage. In this application, set size corresponds to the number
of accounts. As in Section 7.1, MultiSwap does not break
even for the smallest set size. The break-even point for 210
accounts is ≈2000 transactions, and ≈600 for 220 accounts.
Figure 5b shows the number of transactions that ﬁt in 109
constraints, for different accumulators. MultiSwap’s advan-
tage is as large as ≈1.9×, depending on set size.
14Our design (§4) models the underlying hash function as a random oracle.
Thus, Pedersen hashing should not be used for MultiSwap; we use it in this
experiment only to demonstrate the effect of hash cost.
Figure 7: Constraint count v. number of swaps, varying hash
function (§7.1). Merkle trees are all of depth 20.
Proving and verifying time. Figure 6 shows proving times
(witness computation plus proof generation) for MultiSwap
and Merkle with sets having 220 elements, for varying batch
sizes. Veriﬁcation costs ≈7 ms in all cases. MultiSwap has
longer proving times for small batches but shorter times for
large batches, and the break-even point between 1200 and
1600 swaps. This is slightly larger than in Figure 4 because
of the added cost of computing the new accumulator digest
(§4.4).
For an accumulator with 220 elements, computing a new di-
gest after batch removal takes ≈43 seconds and uses ≈4 GiB
of RAM via the preprocessing approach described in Sec-
tion 4.4. For smaller accumulators this cost is correspondingly
smaller. Larger accumulators have slower witness generation,
which affects break-even batch size; we discuss in Section 9.
Effect of hash cost. Figure 7 shows the effect of hash cost
on MultiSwap’s break-even point for sets of 220 elements
USENIX Association
29th USENIX Security Symposium    2087
the interactive proofs of Goldwasser et al. [67], Cormode et
al. [47], and Thaler [111], and on the polynomial commit-
ments of Papamanthou et al. [95], which build on the work
of Kate et al. [77]. In contrast to the persistent RAM and
multiset abstractions we develop, vSQL exposes a database
abstraction; queries operate on all rows in parallel.
ADSNARK [4] extends the Pinocchio [96] SNARK to sup-
port operations on authenticated data provided by a third party.
Geppetto [49] also extends Pinocchio, allowing the veriﬁer to
commit to inputs for a speciﬁc computation and later verify a
proof against that commitment, and also enabling data transfer
between separate constraint systems bundled into one proof.
Fiore et al. [56] take Geppetto’s commitments to inputs a step
further, making them computation independent. In contrast
to a multiset or persistent RAM abstraction, however, all of
these systems require a number of constraints sufﬁcient to
read every input value—in other words, a multiset of size M
implies at least M constraints. Further, they do not efﬁciently
support programs whose multiset or RAM accesses depend
on inputs and thus cannot be statically analyzed (§2.2).
Spice [105] aims to enable zero-knowledge auditing of
concurrent services. Spice’s amortized cost per state operation
is ≈2× lower than ours for large batches, but its approach
differs from ours in two key ways. First, Spice’s core state
veriﬁcation primitive requires a number of constraints linear
in the total size of the state; this cost is amortized over a batch
of requests, each containing one or more state operations.
In contrast, MultiSwap operations (§3) have constraint costs
that depend only on the number of state updates, not on total
state size. Second, veriﬁcation costs in Spice scale with the
number of requests in a batch; in our work, veriﬁcation cost
is independent of batch size. Piperine [80] optimizes Spice’s
state veriﬁcation primitive and saves veriﬁcation work by
combining all requests from a batch into one proof; this yields
veriﬁcation cost independent of batch size.
Accumulators. Cryptographic accumulators [17] based on
RSA have a long history [5, 40, 81, 84]. The recent work of
Boneh et al. [24] builds upon work by Wesolowski [120] to
construct batched membership and non-membership proofs
for these accumulators. Our work builds directly on this line.
Merkle-based accumulators have also seen extensive
study [38, 90], and related structures have seen applications,
e.g., in the blockchain [99] and PKI contexts [100]. These
works all rely crucially on collision-resistant hashing, which
is expensive when expressed as constraints (§6, §7).
Two other lines of work build accumulators [39, 42, 51, 93]
and vector commitments [41, 82, 83] from bilinear maps. El-
liptic curve operations and pairings appear to be very expen-
sive when compiled to constraints [15], but these lines may
nevertheless be an interesting direction for further study.
Prime generation. A long line of work [30, 31, 68, 74, 75]
aims to efﬁciently generate pseudorandom prime numbers. In
some cases, uniformly distributed primes [59] are desirable.
Figure 9: Constraint count v. number of accesses (§7.3).
“Merkle m” denotes a Merkle tree with 2m leaves. Ribbons
indicate variation according to write load, from 0 to 100%.
7.3 Application: persistent RAM
Benchmark. This experiment compares the costs of
MultiSwap-based and Pantry’s [32] Merkle-based persistent
RAM 5.2. We compare using the cost model of Figure 3 (§5),
which is derived from prior work [79, 116]; future work is to
port Buffet’s RAM compiler to Bellman and synthesize. We
report cost versus RAM size.
Results. Figure 9 shows the results. For Merkle-based
RAM, bands in the ﬁgure represent varying write loads, from
0 (lowest cost) to 100% (highest cost). As in prior experi-
ments, MultiSwap’s cheaper per-operation cost yields a break-
even point of several thousand operations for a large RAM.
This model includes the cost of memory consistency checks
(§2.2, §5.2, Fig. 3); these cost fewer than 100 constraints per
operation and are thus negligible.
8 Related work
Veriﬁable computation. The literature on veriﬁable com-
putation is both broad and deep; a somewhat recent sur-