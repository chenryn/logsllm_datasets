arbiter (WFA [11]). The WFA is widely used to find maximal size
matches in a crossbar switch. It can be readily pipelined and
decomposed over multiple chips [12].
≥
v1
v1
v2
and
i2
(
i2=
). We will say that
.
are vectors of the
) is
iff
Definition 1: Inequalities of vectors -
same dimension. The index of the first non-zero entry in
i1
v1
i1
Definition 2: Ordered - The row (column) vectors of a matrix are
said to be ordered if they do not increase with the row (column)
index. A matrix is ordered if both its row and column vectors are
ordered.
v1
v2
v2=
, and
v2
iff
i2
i1
≤
(
Lemma 3: A request matrix can be ordered in no more than
2N 1–
alternating row and column permutations.
Proof: See Appendix A. (cid:1)
parallel can emulate a memory of rate R in a PIFO DSM router.
Proof: Similar to Theorem 8. (cid:1)
VI. PRACTICAL CONSIDERATIONS
In this section, we investigate whether or not we could actually
build a DSM router that emulates a shared memory router. As
always, we’ll find that the architecture has limits to its scalability,
and these arise for the usual reasons when the system is big; algo-
rithms that take too long to complete, buses that are too wide, con-
nectors and devices that require too many pins, or an overall
system power that is impractical to cool. Many of these constraints
are imposed by currently available technology, and so even if our
assessment is accurate today, it might be meaningless in the future.
And so wherever possible, we will make relative comments, such
as “Architecture A has half the memory bandwidth of Architecture
B” to allow comparisons independent of the technology.
We’ll pose a series of questions about the feasibility, and try to
answer each one in turn.
1. A PIFO DSM router requires a lot of memory devices. Is it fea-
sible to build a system with so many memories?
We can answer this question relative to a CIOQ router with a
speedup of two. The CIOQ router has an aggregate memory
bandwidth of 6NR and requires 2N physical memory devices
(although we could use one memory per linecard with twice
the bandwidth). The PIFO DSM router has a memory band-
width of 4NR and requires at least N physical memories. It
seems clear that we can build a PIFO DSM router with at least
the same capacity as a CIOQ router. The fastest single-rack
CIOQ router in development today has a capacity of approxi-
mately 1Tb/s (although the speedup is probably less than two,
and the scheduling algorithm is a heuristic). This suggests that
259considering only the number of memories and their bandwidth,
it is possible to build a 1Tb/s single-rack DSM router.
2. A crossbar-based PIFO DSM router requires a crossbar switch
with links operating at least as fast as 5R. A CIOQ router
requires links operating at only 2R. What are the consequences
of the additional bandwidth for the DSM router?
Increasing the bandwidth between the linecard and the switch
will more than double the number of wires and/or their data
rate, and place more requirements on the packaging, board
layout, and connectors.
It will also increase the power
dissipated by the serial
links on the crossbar chips in
proportion to the increased bandwidth. But it might be possible
to exploit the fact that the links are used asymmetrically. For
example, we know that
the total number of transactions
between a linecard and the crossbar switch is limited to five
per time slot. If each link in the DSM router was half-duplex,
rather than simplex, then the increase in serial links, power and
size of connectors is only 25%. Even if we can’t use half-
duplex links, the power can be reduced by observing that many
of the links will be unused at any one time, and therefore need
not have transitions. But overall, in the best case, it seems that
the DSM router requires at least 25% more bandwidth.
In order to choose which memory to write a packet into, we
need to know the packet’s departure time as soon as it arrives.
This is a problem for both a DSM router and a CIOQ router
that emulate a shared memory router. In the CIOQ router, the
scheduling algorithm needs to know the departure time so as to
ensure the packet traverses the crossbar in time. While we can
argue that the DSM router is no worse, this is no consolation
when the CIOQ router itself is impractical! Let’s first consider
the simpler case when a DSM router is emulating an FCFS
shared memory router. Given that the system is work-conserv-
ing, the departure time of a packet is simply equal to the sum of
the data in the packets ahead of it. In principle, a global counter
can be kept for each output, and updated each time slot
depending on the number of new arrivals. All else being equal,
we would prefer a distributed mechanism, as ultimately the
maintenance of a global counter will limit scalability. How-
ever,
the communication and processing requirements are
probably smaller than for the scheduling algorithm itself
(which we consider next).
3.
4. How complex is the algorithm that decides which memory
each arriving packet is written into?
There are several aspects to this question.
(cid:127) Space requirements: In order to make its decision, the
algorithm needs to consider k different memory addresses,
one for each packet that can contribute to a conflict. How
complex the operation is, depends on where the information
is stored. If, as currently seems necessary, the algorithm is run
centrally, then it must have global knowledge of all packets.
While this is also true in a CIOQ router that emulates a shared
memory router, it is not necessary in a purely input or output
queued router.
(cid:127) Memory accesses: For an FCFS DSM router, we must read,
update and then write bitmaps representing which memories
are busy at each future departure time. This requires two addi-
tional memory operations in the control structure. For a PIFO
DSM router, the cost is greater as the control structures are
(cid:127) Time: We have not found a distributed algorithm, and so cur-
rently we believe it to be sequential, requiring
opera-
tions to schedule at most N new arrivals. However, it should
be noted that each operation is a simple comparison of three
bitmaps to find a conflict-free memory.
O N(
)
most likely arranged as linked lists, rather than arrays. Find-
ing the bitmaps is harder, and we don’t currently have a good
solution to this problem.
(cid:127) Communication: The algorithm needs to know the destina-
tion of each arriving packet, which is the minimum needed by
any centralized scheduling algorithm.
5. We can reduce the complexity by aggregating packets at each
input into frames of size F, and then schedule frames instead of
packets. Essentially, this is equivalent to increasing the size of
each “cell”. The input linecard maintains one frame of storage
for each output, and a frame is scheduled only when F bits
have arrived for a given output, or until a timeout expires.
There are several advantages to scheduling large frames rather
than small cells. First, as the size of frame increases, the sched-
uler needs to keep track of fewer entities (one entry in a bitmap
per frame rather than per cell), and so the size of the bitmaps
(and hence the storage requirements) falls linearly with the
frame size. Second, because frames are scheduled less often
than cells, the frequency of memory access to read and write
bitmaps is reduced, as is the communication complexity, and
the complexity of scheduling. As an example, consider a router
with 16 OC768c linecards (i.e. a total capacity of 640Gb/s). If
the scheduler were to run every time we scheduled a 40-byte
cell, it would have to use off-chip DRAM to store the bitmaps,
and access them every 8ns. If instead we use 48kB frames, the
bitmaps are reduced by more than 1,000-fold and can be stored
on-chip in fast SRAM. Furthermore, the bitmap interaction
algorithm need run only once every
s, which is readily
implemented in hardware. The appropriate frame size to use
will depend on the capacity of the router, the number of line-
cards and the technology used for scheduling. This technique
can be extended to support a small number of priorities in a
PIFO DSM router, by aggregating frames at an input for every
priority queue for every output. One disadvantage of this
approach is that the strict FCFS order among all inputs is no
longer maintained. However, FCFS order
is maintained
between any input-output pair, which is all that is usually
required in practice.
9.6µ
6. Which requires larger buffers: a DSM router or a CIOQ router?
In a CIOQ router, packets between a given input and output
pass through a fixed pair of buffers. The buffers on the egress
linecards are sized so as to allow TCP to perform well, and the
buffers on the ingress linecard are sized to hold packets while
they are waiting to traverse the crossbar switch. So the total
buffer size for the router is at least
because any one
egress linecard can be a bottleneck for the flows that pass
through it. On the other hand, in a DSM router we can’t predict
which buffer a packet will reside in; the buffers are shared
more or less equally among all the flows. It is interesting to
note that if the link data rates are symmetrical, not all of the
egress linecards of a router can be bottlenecked at the same
time. As a consequence, statistical sharing reduces the required
size of the buffers. This reduces system cost, board area and
NR RTT
×
260power. As a consequence of the scheduling algorithm, the buff-
ers in the DSM router may not be equally filled. We have not
yet evaluated this effect.
1) Open problems
Our conclusion is that a PIFO DSM router is less complex than a
PIFO CIOQ router (has lower memory bandwidth, fewer memo-
ries, a simpler scheduling algorithm, but slightly higher crossbar
bandwidth). However, it seems that the PIFO DSM router has two
main problems: (1) The departure times of each packet must be
determined centrally with global knowledge of the state of the
queues in the system, and (2) A sequential scheduler must find an
available memory for each packet in turn. Although we have not
solved either problem, we present them in the hope that others
might overcome them (or find good heuristics), and make the
PIFO DSM router more practical.
On the other hand, departure times are much easier to calculate
in an FCFS DSM router.
VII. OTHER WORK ON CONSTRAINT SETS
In prior work, we used Constraint Sets to analyze the Parallel
Packet Switch (PPS) as a Deterministic SB Router [16][17]. A
characteristic of this architecture is that all the buffers in the router
run slower than the line-rate. We derived the conditions under
which a PPS can emulate an OQ router using the Constraint Sets
method. The two main results in [16] are that a PPS can emulate a
FCFS OQ router with a speedup of two, and a PIFO OQ router
with a speedup of three. The reason we need more speedup to emu-
late PIFO than FCFS is that an additional constraint is introduced,
exactly as in Section II.C.
In [18] we use Constraint Sets to analyze CIOQ routers (which
unlike SB routers, have two stages of buffering), and find that the
technique can lead to simpler proofs of known results. For exam-
ple, using the discrete combinatorial arguments of Constraint Sets
(similar to Charny [19]), we find that a CIOQ switch, with a cross-
bar bandwidth of 2NR and a memory bandwidth of 6NR, achieves
100% throughput for a maximal matching algorithm. This result
was first proved by Dai and Prabhakar (using fluid models) [20],
and later by Leonardi et. al. [21] using Lyapunov functions. Fur-
thermore, unlike the work in [20] and [21], Constraint Sets lead to
a hard bound on the worst case delay faced by a packet in the
CIOQ router.
VIII. REFERENCES
[1]
[2]
[3]
A. Demers, S. Keshav, and S. Shenker, “Analysis and simu-
lation of a fair queuing algorithm,” ACM Computer Commu-
nication Review (SIGCOMM'89), pp. 3-12, 1989.
L. Zhang, “Virtual clock: A new traffic control algorithm for
packet switching networks,” ACM Transactions on Comput-
er Systems, vol.9 no.2, pp.101-124, 1990.
J. Bennett and H. Zhang, "WF2Q: Worst-case fair weighted
fair queueing," Proc. of IEEE INFOCOM '96, pp. 120--128,
San Francisco, CA, March 1996.
[4] M. Shreedhar and G. Varghese, “Efficient fair queueing us-
ing deficit round robin,” in Proc. ACM Sigcomm, Sep 1995,
pp. 231-242.
R. R. Schaller, “Moore’s law: Past, present and future,”
IEEE Spectrum, vol. 34, no. 6, June 1997, pp. 52-59.
[5]
[6]
[7]
[8]
[9]
N. McKeown, V. Anantharam, J. Walrand, “Achieving
100% throughput in an input-queued switch,” Proceedings
of IEEE Infocom ‘96, vol. 1, pp. 296-302, March 1996
S. Chuang, A. Goel, N. McKeown, B. Prabhakar, “Matching
output queueing with a combined input/output-queued
switch,” IEEE J.Sel. Areas in Communications, Vol. 17, no.
6, pp. 1030-1039, June 1999.
A. Charny, P. Krishna, N. S. Patel, R. Simcoe, "Algorithms
for providing bandwidth and delay guarantees in input-buff-
ered crossbars with speedup", 6th International Workshop
on Quality of Service (IWQoS 98), Napa, CA, May 1998,
pp.235-244.
A. Hung, G. Kesidis and N. Mckeown, "ATM input-buffered
switches with guaranteed-rate property," Proc. IEEE IS-
CC'98, Athens, pp. 331-335.
[10] N. McKeown, “iSLIP: A Scheduling algorithm for input-
queued switches,” IEEE Transactions on Networking, vol 7,
No. 2, April 1999.
[11] Y. Tamir and H. C. Chi, "Symmetric crossbar arbiters for
VLSI communication switches", IEEE Transactions on Par-
allel and Distributed Systems, vol. 4, No. 1, pp. 13-27, Jan.
1993.
[13]
[12] H. C. Chi and Y. Tamir, "Decomposed arbiters for large
crossbars with multiqueue input buffers," in IEEE Interna-
tional Conference on Computer Design: VLSI in Computers
and Processors, Cambridge, pp. 233-238, October 1991.
I. Keslassy, N. McKeown, “Analysis of scheduling algo-
rithms that provide 100% throughput
in input-queued
switches,” Proceedings of the 39th Annual Allerton Confer-
ence on Communication, Control and Computer, October
2001.
[14] E. Leonardi, M. Mellia, M. Marsan, and F. Neri, "Stability of
maximal size matching in input-queued cell switches," Pro-
ceedings of the International Conference on Communica-
tions, June 2000.
[15] T. Chaney, J. A. Fingerhut, M. Flucke, J. Turner, “Design of
a gigabit ATM switching system,” Technical Report WUCS-
96-07, Computer Science Department, Washington Univer-
sity, St. Louis, Missouri, Feb. 1996.
[16] S. Iyer, A. Awadallah, N. McKeown, “Analysis of a packet
switch with memories running slower than the line rate,” in
Proc. IEEE Infocom ‘00, pp.529-537.
[17] S. Iyer, N. McKeown, “Making parallel packet switches
practical,” in Proc. IEEE INFOCOM ‘01, vol.3, pp. 1680-
1687.
[18] S. Iyer, N. McKeown, “A Distributed Algorithm for Delay
Bounds in CIOQ Switches”, Stanford University Tech. Re-
port, available at http://yuba.stanford.edu/~sundaes/papers/
cs-cioq.pdf
[19] A. Charny, “Providing QoS guarantees in input-buffered
crossbars with speedup,” Ph.D Thesis Report, MIT, Sep.
1998.
J. Dai and B. Prabhakar, "The throughput of data switches
with and without speedup," in Proceedings of IEEE INFO-
COM '00, Tel Aviv, Israel, March 2000, pp. 556 -- 564.
[20]
[21] E. Leonardi, M. Mellia, M. Marsan and F. Neri, "Stability of
Maximal Size Matching Scheduling in Input-Queued Cell
Switches", In Proc. ICC 2000, pp. 1758-1763.
261[23]
[22] C.S. Chang, D.S. Lee, Y.S. Jou, “Load balanced Birkhoff-
von Neumann switches, part I: one-stage buffering,” IEEE
HPSR Conference, Dallas, May 2001 [www.ee.nthu.edu.tw/
~cschang/PartI.ps].
I. Keslassy, N. McKeown, “Maintaining packet order in two-
stage switches,” Proceedings of the IEEE Infocom, June
2002
J.G. Dai, B. Prabhakar, "The throughput of data switches
with and without speedup," Proceedings of the IEEE Info-
com, Tel Aviv, Israel, 2000.
[24]
[25] C. Clos, "A study of non-blocking switching networks," The
Bell System Technical Journal, vol.32, pp. 406-424, 1953.
[26] P. S. Sindhu, R. K. Anand, D. C. Ferguson, B. O. Liencres,
“High speed switching device,” United States Patent No.
5905725, May 1999.
[27] A. K. Parekh and R. G. Gallager, “A generalized processor
sharing approach to flow control in integrated services net-
works: The single node case,” IEEE/ACM Transaction on
Networking, Vol. 1, No. 3, pp. 344-357, June 1993.
[28] D. König, “Über Graphen und ihre Anwendung auf Determi-
nantentheorie und Mengenlehre,” Math. Ann., 77 (1916), pp.
453-465 (in German).
[29] R. Cole, K. Ost and S. Schirra, “Edge-coloring bipartite mul-
time,” Combinatorica Vol. 21, Issue
Dlog
(
)
tigraphs in
1, pp. 5-12, 2001.
O E
APPENDIX A
A. Proof of Theorem 1
S
Assume that the aggregate memory bandwidth of the k memo-
1>
ries is SNR, where
. We can think of the access time T as
k S⁄
decision slots.7 We will now find the mini-
equivalent to
mum value of S needed for the switch to emulate an FCFS shared
memory router. Assume that all packets are segmented into cells of
size C, and reassembled into variable length packets before they
depart. In what follows, we define two constraint sets; one set for
when cells are written to memory and another for when they are
read.
BWS t( )
Definition 3: Busy Write Set (BWS) - When a cell is written
into a memory, the memory is busy for
decision
slots.
is the set of memories which are busy at time
due to cells being written, and therefore cannot accept a
t
new cell. Thus,
is the set of memories which have
started a new write operation in the previous
decision
slots. Clearly
BWS t( )
BWS t( )
k S⁄
k S⁄
k S⁄
1–
1–
≤
.
is
Definition 4: Busy Read Set (BRS) - Likewise, the
the set of memories busy reading cells at time t. It is the set
of memories which have started a read operation in the pre-
vious
.
decision slots. Clearly
BRS t( )
k S⁄
k S⁄
1–
1–
≤
BRS t( )
Theorem 1: (Sufficiency) A total memory bandwidth of 3NR is
sufficient for a Parallel Shared Memory Router to emulate an ideal
FCFS shared memory router.
Proof: Consider a cell c that arrives to the shared memory switch
at time t destined for output port j. If c’s departure time is
7. We shall denote N decision slots to comprise a time slot.
)
and we apply the Constraint Set technique, then the
DT t j,(
memory l that c is written into must meet these constraints:
1. Memory l must not be busy writing or reading a cell at time t.
Hence
l BWS t( )
∉
, and
l BRS t( )
∉
.
2. We must pick a memory that is not busy when the cell departs
: Memory l must not be busy read-
i.e.
from the switch at
ing
l BRS DT t j,(
∉
Hence our choice of memory l must meet the following con-
DT t j,(
)
cell when
)
another
depart:
ready
to
is
c
(
)
.
straints:
∧
∧
l BWS t( )
∉
l BRS DT t j,(
∉
A sufficient condition to satisfy this is:
(
l BRS t( )
∉
BRS DT t j,(
(2)
From Definitions 3 and 4, we know that Equation (2) is true if:
–
, corresponding to a total mem-
)
)
(1)
BWS t( )