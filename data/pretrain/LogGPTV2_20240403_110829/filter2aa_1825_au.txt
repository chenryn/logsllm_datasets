### Thread Management in Drivers

To ensure that the driver is not prematurely unloaded while a thread is still executing, the thread must be properly managed. A driver-created thread must eventually terminate itself by calling `PsTerminateSystemThread`. If successful, this function does not return.

### Work Items and System Thread Pool

**Work items** are functions queued to the system thread pool. A driver can allocate and initialize a work item, specifying the function it wishes to execute, and then queue the work item to the pool. This mechanism is similar to Deferred Procedure Calls (DPCs), but with a key difference: work items always execute at IRQL PASSIVE_LEVEL (0). This allows IRQL 2 code (such as DPCs) to perform operations not normally allowed at IRQL 2, such as I/O operations.

#### Creating and Initializing a Work Item

There are two ways to create and initialize a work item:

1. **Using `IoAllocateWorkItem`**:
   - Allocate and initialize the work item.
   - The function returns a pointer to the opaque `IO_WORKITEM`.
   - When finished, the work item must be freed with `IoFreeWorkItem`.

2. **Using `IoSizeofWorkItem` and `IoInitializeWorkItem`**:
   - Dynamically allocate an `IO_WORKITEM` structure with the size provided by `IoSizeofWorkItem`.
   - Initialize the work item with `IoInitializeWorkItem`.
   - When finished, call `IoUninitializeWorkItem`.

These functions accept a device object, ensuring that the driver is not unloaded while there is a work item queued or executing.

#### Deprecated APIs

Another set of APIs for work items, starting with `Ex`, such as `ExQueueWorkItem`, do not associate the work item with anything in the driver. This means the driver could be unloaded while a work item is still executing. These APIs are marked as deprecated, and it is recommended to use the `Io` functions instead.

#### Queuing a Work Item

To queue a work item, use the `IoQueueWorkItem` function:

```c
VOID IoQueueWorkItem(
    _Inout_ PIO_WORKITEM IoWorkItem,
    _In_ PIO_WORKITEM_ROUTINE WorkerRoutine,
    _In_ WORK_QUEUE_TYPE QueueType,
    _In_opt_ PVOID Context
);
```

The callback function provided by the driver should have the following prototype:

```c
typedef VOID (*PIO_WORKITEM_ROUTINE)(_In_ PDEVICE_OBJECT DeviceObject, _In_opt_ PVOID Context);
```

#### Work Queue Types

The system thread pool has several queues based on thread priorities. The defined levels include:

- `CriticalWorkQueue` (priority 13)
- `DelayedWorkQueue` (priority 12)
- `HyperCriticalWorkQueue` (priority 15)
- `NormalWorkQueue` (priority 8)
- `BackgroundWorkQueue` (priority 7)
- `RealTimeWorkQueue` (priority 18)
- `SuperCriticalWorkQueue` (priority 14)

While the documentation suggests using `DelayedWorkQueue`, any other supported level can be used.

### Summary

This chapter covered various kernel mechanisms that driver developers should be aware of and use. In the next chapter, we will delve into I/O Request Packets (IRPs).

### Chapter 7: The I/O Request Packet

After a typical driver completes its initialization in `DriverEntry`, its primary job is to handle requests. These requests are packaged as the semi-documented I/O Request Packet (IRP) structure. In this chapter, we will explore IRPs and how a driver handles common IRP types.

#### Introduction to IRPs

An IRP is a structure allocated from non-paged pool, typically by one of the "managers" in the Executive (I/O Manager, Plug & Play Manager, Power Manager), but can also be allocated by the driver. The entity allocating the IRP is responsible for freeing it.

An IRP is never allocated alone; it is always accompanied by one or more I/O Stack Location structures (`IO_STACK_LOCATION`). When an IRP is allocated, the caller must specify how many I/O stack locations need to be allocated with the IRP. These I/O stack locations follow the IRP directly in memory.

#### Device Nodes

The I/O system in Windows is device-centric. This has several implications:

- Device objects can be named, and handles to device objects can be opened.
- Windows supports device layering, where one device can be layered on top of another.

#### IRP Flow

An IRP is created by one of the managers in the Executive, typically the I/O Manager. The manager initializes the main IRP structure and the first I/O stack location, then passes the IRP’s pointer to the uppermost layer.

A driver receives the IRP in its appropriate dispatch routine. For example, if this is a Read IRP, the driver will be called in its `IRP_MJ_READ` index of its `MajorFunction` array from its driver object. At this point, the driver has several options:

- Pass the request down.
- Handle the IRP fully.
- Do a combination of the above options.
- Pass the request down and be notified when the request completes.
- Start some asynchronous IRP handling.

Once a layer calls `IoCompleteRequest`, the IRP starts “bubbling up” towards the originator of the IRP. If completion routines have been registered, they will be invoked in reverse order of registration.

#### IRP and I/O Stack Location

Every IRP is accompanied by one or more `IO_STACK_LOCATION` structures. Important fields in an `IO_STACK_LOCATION` include:

- `MajorFunction`
- `MinorFunction`
- `FileObject`
- `DeviceObject`
- `CompletionRoutine`
- `Context`
- `Parameters`

The current I/O stack location, obtained with `IoGetCurrentIrpStackLocation`, hosts most of the parameters of the request in the `Parameters` union.

#### Viewing IRP Information

While debugging or analyzing kernel dumps, the `!irpfind` command can be used to find IRPs. This command can search the non-paged pool(s) for all IRPs or IRPs that meet certain criteria.

### Conclusion

In this chapter, we explored the I/O Request Packet (IRP) and its associated I/O stack locations. We discussed the flow of IRPs through the device stack and the various options available to drivers for handling IRPs. In the next chapter, we will take a closer look at I/O Request Packets and how a driver handles common IRP types.