attack script from [19] and set the l as 64KB, which enables
maximum amount of data leakage.
Ofﬂine patch generation. We ﬁrst
evaluate how
HeapTherapy can be used to generate a patch ofﬂine instantly,
is available. In this case Pm is set
when the attack input
as 1 and the patch generation is run on an experimental
system rather than a production system. The malicious request
immediately crashes the worker process of Nginx, and a
main 
ngx_master_process_cycle  
ngx_start_worker_processes 
ngx_reap_children  
ngx_spawn_process  
default_malloc_ex 
malloc 
Fig. 11: Two vulnerable calling contexts identiﬁed by the
diagnosis engine. Dashed lines indicate omitted functions.
core dump is generated. Then the diagnosis engine produces
a temporary patch containing the VCCID based on the core
dump. Next we set the initial padding size as 4KB, and double
the size whenever it is not large enough to contain the overﬂow
attack, that is, the guard page is touched and the process
crashes. It takes 1 round to obtain the VCCID and another
4 rounds to determine that the 32KB padding is large enough
to prevent crashes due to the Heartbleed request. We repeat
the experiment 100 times and reproduce the same result every
time. Once the patch generated, it can be installed to protect
the production system from Heartbleed attacks efﬁciently. The
system is then immune from information leakage when waiting
for the ofﬁcial patch that ﬁxes the bug to be generated and
installed.
The result contains the following two temporary patches:
These two temporary patches indicate that there are two
vulnerable calling contexts in the service. The ﬁrst VC-
CID (0xE2FF92B2) was found in the core dump due to
the ﬁrst attack; while the following attacks are all related
to the second VCCID (0x6E3D3954). Figure 11 shows the
details of the two calling contexts. Our further investiga-
tions shows that a Nginx service, when it is started, has
a master process and a worker process. The initial worker
process is forked by the master process using the func-
tion ngx_start_worker_processes. Once the mas-
ter process detects that a worker process has crashed,
it
will reap the worker process and fork a new one using
ngx_reap_children. That
the vulnerable
buffers, except for in the ﬁrst attack, is related to the second
VCCID. HeapTherapy handles the case of multiple VCCIDs
smoothly by generating a patch for each unique VCCID.
is why all
Online protection. We next evaluate how HeapTherapy
detects and defeats zero-day attacks. We set the Pm to be a
small value ranging from 0.01 to 0.15. For each value of Pm,
we record the following measurements: (1) the detection delay
492492
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 08:54:20 UTC from IEEE Xplore.  Restrictions apply. 
MySQL 5.5.19 contains a heap buffer over-write vulner-
ability that allows a remote attacker to launch denial of service
attacks using crafted database commands to over-write a heap
buffer and corrupt the heap meta data. The heap corruption
leads to a segmentation fault and crashes the MySQL service
when the connection is closed. We applied HeapTherapy to
the service and ran the attack script [18] 20 times against
it. In the ﬁrst run, HeapTherapy detects the attack when the
segmentation fault is triggered. The diagnosis engine retrieves
the VCCID of the vulnerable buffer from the core dump ﬁle,
and generates a temporary patch, which is then installed to the
service. In all the following runs, HeapTherapy successfully
prevents data corruption from occurring.
.
3) Libtiff
Libtiff is a popular library for processing TIFF im-
ages. A heap buffer overﬂow vulnerability was found in the
gif2tiff tool in libtiff 3.4-4.03. By manipulating
height and width of a GIF image, a remote attacker can exploit
this vulnerability to overwrite a heap buffer. We ﬁrst reproduce
the exploitation using an attacking GIF image input [10]. Upon
detection, the diagnosis engine automatically ﬁnds the VCCID
in the core dump. When we use gif2tiff to open the
crafted image again, the tool is able to avoid crash and reports
“illegal GIF block type”.
4) NIST SAMATE reference dataset
The SAMATE dataset [29] maintained by NIST contains
12 programs with heap buffer overﬂow vulnerabilities caused
by contiguous writes through,
for example, assignments,
memcpy, strcpy, and snprintf.
.
In all these cases, HeapTherapy retrieves the vulnerable
calling contexts accurately and uses padding to prevent both
data corruption and program crashes.
B. Efﬁciency on service programs
We evaluate the overhead due to HeapTherapy using three
real world service programs, Nginx, proftpd and MySQL.
We simulate 10 VCCIDs using the method described in
Section V-C, and set Pm as 0.05. To measure the service
throughput, we use ApacheBench to send web requests
to Nginx, and use the ofﬁcial test script for MySQL; For
proftpd, we write a script that generates concurrent clients
to upload ﬁles, and measures the throughput.
The result shows that HeapTherapy has a low overhead for
these service programs. The overhead on Nginx, proftpd
and MySQL is 7.6%, 4.7%, and 6.0%, respectively.
C. Efﬁciency on SPEC CPU2006
1) Methodology .
Benchmarks and platform. We then measure the efﬁ-
ciency of HeapTherapy on SPEC CPU2006 Integer benchmark
suite with respect to speed and memory. All results presented
are normalized by the execution time of the original benchmark
programs without HeapTherapy. We also measure the memory
overhead in terms of the average Resident Set Size (RSS) for
all benchmark programs. We write a script to read the VmRSS
value of /proc/[pid]/status 50 times per second and
then calculate the average.
Fig. 12: Heartbleed detection and diagnosis result.
Nd, which is the number of successful over-reads before the
ﬁrst guard page is touched, and (2) the average number of
temporary patches, FP, generated in the ﬁrst stage due to the
suspect buffers, as discussed in Section IV-C.
We conduct 100 experiments for each value of Pm and
obtain the average values of Nd and FP, as shown in Figure 12.
In all experiments, HeapTherapy successfully detects the at-
tack. When Pm = 0.01, Nd averages 28.74. As Pm increases to
0.04, Nd quickly drops to 3.7, and it does not change much
when Pm further increases. This shows that for this particular
scenario by randomly monitoring a small set (4%) of buffers,
HeapTherapy can quickly detect a zero-day Heartbleed attack.
Since attackers usually need to send many Heartbleed requests
before achieving their goals, e.g. 100k ∼ 2.5M attacks for
obtaining the SSL private key [13], the short detection delay
allows HeapTherapy to detect and respond to the attacks before
important information is leaked. In addition, Nd in all cases
is much smaller than the expected value 1/Pm, because an
Heartbleed attack may access multiple buffers.
We next analyze the number of temporary patches gen-
erated at the ﬁrst stage of detection and diagnosis. When
Pm = 0.01, FP is 39; and it decreases to around 5 when Pm
increases to 0.12. Compared with the total number of unique
allocation calling contexts shown in Table I and Table III
below, FP is very small. In addition, all of these temporary
patches except one will be removed after the second stage of
detection and diagnosis. We will further evaluate the overhead
due to temporary patches in Section V-B and Section V-C.
Defense. After installing the two patches, the Heartbleed
attack can only read zeros in the padding space, which is 32KB
long and large enough to contain the over-read. We sends
10,000 Heartbleed requests to the patched Nginx service, the
result shows that HeapTherapy successfully prevented infor-
mation leakage in all attempts without crashing the service.
We then tried another three different Heartbleed attack
scripts collected from the Internet, and launched all the attacks
against proftpd and MySQL in addition to Nginx. In all
the cases HeapTherapy detects the attack and prevents further
attacks after generating and installing the patches.
2) MySQL .
493493
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 08:54:20 UTC from IEEE Xplore.  Restrictions apply. 
Benchmark
400.perlbench
401.bzip2
403.gcc
429.mcf
445.gobmk
456.hmmer
458.sjeng
462.libquantum
464.h264ref
471.omnetpp
473.astar
483.xalancbmk
Buffer
allocation
count
360,728,131
168
28,458,470
5
658,034
2,474,268
5
179
177,779
267,064,936
4,799,955
135,155,557
Unique
allocation-time
CCID count
13,909
10
913,747
5
5,404
191
5
10
258
162,332,040
184
131,848,405
TABLE III: Buffer allocation and CCID proﬁling. Benchmark
programs in bold text are allocation intensive.
The experiments are performed on a Dell Precision
Workstation T5500 with 2.26GHz
Intel Xeon E5507
processor and 16GB RAM. The operating system is Ubuntu
12.04 with Linux kernel 3.2.0.
Vulnerability simulation. To simulate the performance
of HeapTherapy when handling multiple vulnerabilities, we
create several sets of simulated VCCIDs for each benchmark
program. Speciﬁcally, we ﬁrst develop a proﬁler to count the
number of buffer allocations, the number of unique allocation-
time CCID values and obtain the number of buffer allocations
associated with each unique CCID. Table III lists our proﬁling
result. From the table we can see that
these benchmark
programs have a diverse proﬁle of buffer allocation. Programs,
such as perlbench, gcc, omnetpp and xalancbmk, have
intensive memory allocations.
We then generate several sets of simulated VCCIDs for
later experiments. To pick the VCCIDs fairly, for each bench-
mark program we sort the CCIDs according to their allocation
counts in descending order. Next, for each benchmark pro-
gram we generate 3 sets of VCCIDs containing 1, 5 and 10
elements, respectively. For the 1-VCCID set, the median CCID
is selected. For the 5-VCCID set, CCIDs at 0.01%, 20%, 40%,
60% and 80% points are chosen. The 10-VCCID set is created
in a similar fashion with an interval of 10%. Since benchmark
programs mcf and sjeng have less than 10 unique CCIDs,
we use all of their CCIDs for their 10-VCCID sets.
2) Overhead due to PCC Encoding .
Our ﬁrst evaluation was focused on the speed and memory
overhead due to PCC encoding alone. All benchmark pro-
grams are instrumented with PCC encoding but not linked
with HeapTherapy, so no detection overhead is incurred. The
average speed and memory overhead is 1.9% and 0.2%,
respectively. The low overhead is consistent with the result
of the original PCC encoding on Java programs [9].
3) HeapTherapy Efﬁciency .
Next, we evaluate the speed and memory overhead due
to HeapTherapy using the 3 sets of VCCIDs. For each VC-
CID, a patch is created manually. Over-read detection is not
turned on because these benchmark programs are not service
494494
programs and the concern of information leakage is rare. With
regard to speed overhead, the result in Figure 13 shows that
HeapTherapy caused 4.3% average overhead in the case of
0 patch. This shows the overhead when HeapTherapy works
in the detection status with no patch installed. The average
overhead increases slightly to 6.2% when the 10-VCCID set
and 5-page padding are used, which demonstrates the high
efﬁciency of HeapTherapy even when multiple vulnerabilities
are handled simultaneously.
When no patch is applied, the average memory overhead
incurred by HeapTherapy is 5.9%. The overhead in the case of
10 patches and 5 padding pages increases to 7.7%. For majority
of the benchmark programs, the memory overhead changes
little when the size of padding increases, mainly because a
physical page is not mapped until the corresponding virtual
memory region is accessed.
We also compare HeapTherapy with DieHarder, a memory
allocator against heap-based attacks [30]. Figure 13 shows
that DieHarder incurs a much higher speed overhead for
allocation-intensive benchmark programs. The average speed
performance penalty due to DieHarder is 20.3%, which is
also much higher than HeapTherapy. For allocation-intensive
programs, the average overhead due to DieHarder is 86.1%
while HeapTherapy only incurs 15.8% overhead on average.
In addition, DieHarder only provides probabilistic defense
against known vulnerabilities, while HeapTherapy provides
deterministic protection in such cases. Other comprehensive
defense methods, such as AddressSanitizer [39], provides a
wider range of protection than HeapTherapy. However, their
high overheads (e.g., 73% speed overhead and 337% memory
overhead on SPEC 2006 for AddressSanitizer) making them
more suitable for ofﬂine testing.
In summary, we conclude that HeapTherapy incurs a low
overhead in terms of both speed and physical memory.
VI. LIMITATIONS
First, it is possible that an overﬂow vulnerability can be
exploited in different VCCIDs, and the attacker may invest
to develop different attack input to overﬂow buffers in new
allocation calling contexts. However, as we have shown in the
Nginx case, whenever the attack overﬂows a buffer allocated
in a new calling context, HeapTherapy simply treats it as a
new vulnerability and starts another defense and diagnosis
cycle. Moreover, based on our evaluation and observations in
previous research [50], [26], [31] on the high reproducibility
of calling contexts, this is not common.
The second limitation is that HeapTherapy can only deal
with buffer overﬂow due to continual write or read operations,
which are the main form of buffer overﬂows. It cannot handle
overﬂows due to discrete read or write. Also, if an overﬂow
occurs inside a data structure, HeapTherapy cannot detect it.
This limitation is common in many existing countermeasures