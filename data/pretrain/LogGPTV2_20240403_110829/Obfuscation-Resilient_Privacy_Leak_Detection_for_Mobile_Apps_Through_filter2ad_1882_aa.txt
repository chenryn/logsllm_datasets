title:Obfuscation-Resilient Privacy Leak Detection for Mobile Apps Through
Differential Analysis
author:Andrea Continella and
Yanick Fratantonio and
Martina Lindorfer and
Alessandro Puccetti and
Ali Zand and
Christopher Kruegel and
Giovanni Vigna
Obfuscation-Resilient Privacy Leak Detection for
Mobile Apps Through Differential Analysis
Andrea Continella∗†, Yanick Fratantonio†, Martina Lindorfer†, Alessandro Puccetti†, Ali Zand†,
PI:EMAIL, {yanick,martina,chris,vigna}@cs.ucsb.edu, PI:EMAIL, PI:EMAIL
Christopher Kruegel†, and Giovanni Vigna†
∗Politecnico di Milano †UC Santa Barbara
Abstract—Mobile apps are notorious for collecting a wealth
of private information from users. Despite signiﬁcant effort from
the research community in developing privacy leak detection tools
based on data ﬂow tracking inside the app or through network
trafﬁc analysis, it is still unclear whether apps and ad libraries
can hide the fact that they are leaking private information. In
fact, all existing analysis tools have limitations: data ﬂow tracking
suffers from imprecisions that cause false positives, as well as false
negatives when the data ﬂow from a source of private information
to a network sink is interrupted; on the other hand, network
trafﬁc analysis cannot handle encryption or custom encoding.
We propose a new approach to privacy leak detection that
is not affected by such limitations, and it is also resilient to
obfuscation techniques, such as encoding, formatting, encryption,
or any other kind of
transformation performed on private
information before it is leaked. Our work is based on black-
box differential analysis, and it works in two steps: ﬁrst,
it
establishes a baseline of the network behavior of an app; then,
it modiﬁes sources of private information, such as the device
ID and location, and detects leaks by observing deviations in
the resulting network trafﬁc. The basic concept of black-box
differential analysis is not novel, but, unfortunately, it is not
practical enough to precisely analyze modern mobile apps. In fact,
their network trafﬁc contains many sources of non-determinism,
such as random identiﬁers,
timestamps, and server-assigned
session identiﬁers, which, when not handled properly, cause too
much noise to correlate output changes with input changes.
The main contribution of this work is to make black-box dif-
ferential analysis practical when applied to modern Android apps.
In particular, we show that the network-based non-determinism
can often be explained and eliminated, and it is thus possible to
reliably use variations in the network trafﬁc as a strong signal
to detect privacy leaks. We implemented this approach in a
tool, called AGRIGENTO, and we evaluated it on more than one
thousand Android apps. Our evaluation shows that our approach
works well in practice and outperforms current state-of-the-art
techniques. We conclude our study by discussing several case
studies that show how popular apps and ad libraries currently
exﬁltrate data by using complex combinations of encoding and
encryption mechanisms that other approaches fail to detect. Our
results show that these apps and libraries seem to deliberately
hide their data leaks from current approaches and clearly
demonstrate the need for an obfuscation-resilient approach such
as ours.
Permission  to  freely  reproduce  all  or  part  of  this  paper  for  noncommercial 
purposes  is  granted  provided  that  copies  bear  this  notice  and  the  full  citation 
on  the  ﬁrst  page.  Reproduction  for  commercial  purposes  is  strictly  prohibited 
without the prior written consent of the Internet Society, the ﬁrst-named author 
(for  reproduction  of  an  entire  paper  only),  and  the  author’s  employer  if  the 
paper  was  prepared  within  the  scope  of  employment.
NDSS  ’17,  26  February  -  1  March  2017,  San  Diego,  CA,  USA
Copyright  2017  Internet  Society,  ISBN  1-891562-46-0
http://dx.doi.org/10.14722/ndss.2017.23465
I.
INTRODUCTION
One main concern of mobile app users is the leakage of
private information: Mobile apps, and third-party advertisement
(ad) libraries in particular, extensively collect private informa-
tion and track users in order to monetize apps and provide
targeted advertisements. In response, the security community
has proposed numerous approaches that detect whether a given
app leaks private information to the network or not. The majority
of approaches utilize data ﬂow analysis of the app’s code, both
through static and/or dynamic taint analysis. Tools based on
static taint analysis, such as FlowDroid [6], identify possible
sources of private information and determine how their values
ﬂow throughout the app and, eventually, to sinks, such as the
network. Dynamic taint analysis tools, such as TaintDroid [13],
execute apps in an instrumented environment and track how
private information is propagated while the app is running.
Finally, AppAudit combines both approaches, determining
critical ﬂows that leak data through static analysis and verifying
them through an approximated dynamic analysis [46].
While these tools provide useful insights, they suffer from
several limitations that affect their adoption, especially when
the threat model considers apps that try to hide the fact that they
are leaking information. Adversaries can deliberately add code
constructs that break the ﬂow of information throughout an app
and make data ﬂow analysis approaches “lose track” of tainted
values. Related works [9], [36] have already demonstrated how
an app can, for example, use indirections through implicit
control ﬂows or through the ﬁle system to efﬁciently bypass
static and dynamic data ﬂow analysis. Furthermore, static and
dynamic analysis approaches for mobile apps usually only
inspect data ﬂow in Dalvik bytecode (i.e., the Java component of
the app) and miss data leaks in native code components, which
are becoming more and more prevalent [5], [26]. Both static and
dynamic analysis can also have false positives, mainly due to a
phenomenon called overtainting: imprecisions in modeling how
information ﬂows through speciﬁc instructions, or imprecisions
introduced to make the analysis scalable might establish that a
given value is “tainted” with private information even when, in
fact, it is not.
Since static analysis does not perform real-time detection of
privacy leaks, and dynamic analysis requires heavy instrumen-
tation, and is thus more likely to be used by app stores than
by end users, researchers have recently proposed a more light-
weight alternative: identifying privacy leaks on the network layer
through trafﬁc interception [24], [27], [34], [35], [39]. However,
obfuscation is out-of-scope for the majority of approaches as
they perform simple string matching and essentially “grep”
for hardcoded values of private information and some well-
known encodings such as Base64 or standard hashing algorithms.
ReCon [35] is the most resilient to obfuscation as it identiﬁes
leaks based on the structure of the HTTP requests, for example
by learning that the value following a “deviceid” key in a HTTP
GET request is probably a device ID. Still, the underlying
machine learning classiﬁer is limited by the data it is trained
on, which is collected through TaintDroid and manual analysis—
if the labelling process misses any leak and its corresponding
key, e.g., due to obfuscation or custom encoding, ReCon will
not be able to detect it.
In general, the transformation of privacy leaks, from sim-
ple formatting and encoding to more complex obfuscations,
has gotten little attention so far. Only BayesDroid [42] and
MorphDroid [17] have observed that the leaked information
does not always exactly match the original private information,
but focused on leaks consisting of subsets or substrings of
information instead of obfuscation. It is unclear to what extent
apps can hide their information leaks from state-of-the-art tools.
For this purpose, we developed a novel automatic analysis
approach for privacy leak detection in HTTP(S) trafﬁc that is
agnostic to how private information is formatted or encoded. Our
work builds on the idea of observing network trafﬁc and attempts
to identify leaks through a technique similar to the differential
analysis approach used in cryptography: ﬁrst, we collect an
app’s network trafﬁc associated with multiple executions; then,
we modify the input, i.e., the private information, and look for
changes in the output, i.e., the network trafﬁc. This allows us to
detect leaks of private information even if it has been heavily
obfuscated.
The idea to perform differential black-box analysis is
intuitive, and in fact, has already been explored by Privacy
Oracle [23] for the detection of information leaks in Windows
applications. One of the main challenges of performing differen-
tial analysis is the elimination of all sources of non-determinism
between different executions of an app. Only by doing this
one can reliably attribute changes in the output to changes
in the input, and conﬁrm the presence of information leaks.
While Privacy Oracle was mainly concerned with deterministic
executions to eliminate OS artifacts that vary between executions
and could interfere with the analysis, we observed that non-
deterministic network trafﬁc poses a far greater challenge when
analyzing modern apps. Due to the frequent use of random
identiﬁers, timestamps, server-assigned session identiﬁers, or
encryption,
inherently differs in every
execution. These spurious differences make it impractical to
detect any signiﬁcant differences caused by actual privacy leaks
by simply observing variations in the raw network output.
the network output
One key contribution of this work is to show that, in fact, it is
possible to explain the non-determinism of the network behavior
in most cases. To this end, we conducted a small-scale empirical
study to determine the common causes of non-determinism in
apps’ network behavior. Then, we leveraged this knowledge in
the development of a new analysis system, called AGRIGENTO,
which eliminates the root causes of non-determinism and makes
differential analysis of Android apps practical and accurate.
Our approach has the key advantage that it is “fail-safe”: we
adopt a conservative approach and ﬂag any non-determinism that
AGRIGENTO cannot eliminate as a “potential leak.” For each
identiﬁed leak, AGRIGENTO performs a risk analysis to quantify
the amount of information it contains, i.e., its risk, effectively
limiting the channel capacity of what an attacker can leak
without raising an alarm. We performed a series of experiments
on 1,004 Android apps, including the most popular ones from
the Google Play Store. Our results show that our approach works
well in practice with most popular benign apps and outperforms
existing state-of-the-art tools. As a result, AGRIGENTO sheds
light on how current Android apps obfuscate private information
before it is leaked, with transformations going far beyond simple
formatting and encoding. In our evaluation, we identiﬁed several
apps that use custom obfuscation and encryption that state-of-
the-art tools cannot detect. For instance, we found that the
popular InMobi ad library leaks the Android ID using several
layers of encoding and encryption, including XORing it with a
randomly generated key.
It is not surprising that developers are adopting such stealth
techniques to hide their privacy leaks, given the fact
that
regulators such as the Federal Trade Commission (FTC) have
recently started to issue sizable ﬁnes to developers for the
invasion of privacy of their users [14], [15]: aforementioned
InMobi for example is subject to a penalty of $4 million
and has to undergo bi-yearly privacy audits for the next 20
years for tracking users’ location without their knowledge and
consent [16]. Also, counterintuitively to the fact that they are
collecting private information, app developers are also seemingly
becoming more privacy-aware and encode data before leaking
it. Unfortunately, it has been shown that the structured nature of
some device identiﬁers makes simple techniques (e.g., hashing)
not enough to protect users’ privacy [12], [18]. Consequently, on
one hand there is a clear motivation for developers to perform
obfuscation—either to maliciously hide data leaks, or to secure
user data by not transmitting private information in plaintext—
on the other hand privacy leak detection tools need to be
agnostic to any kind of obfuscation.
In summary, we make the following contributions:
• We developed AGRIGENTO, a tool that performs root
cause analysis of non-determinism in the network
behavior of Android apps.
• We show that,
in most cases, non-determinism in
network behavior can be explained and eliminated.
This key insight makes privacy leak detection through
differential black-box analysis practical.
The results of our empirical study provide new insights
into how modern apps use custom encoding and obfus-
cation techniques to stealthily leak private information
and to evade existing approaches.
•
In the spirit of open science, we make all the datasets and the
code developed for this work publicly available.1
II. MOTIVATION
This section discusses a real-world example that motivates
our work. Consider the snippet of code in Figure 1. The code
ﬁrst obtains the Android ID using the Java Reﬂection API,
hashes the Android ID with SHA1, XORs the hash with a
randomly generated key, stores the result in JSON format, and
encrypts the JSON using RSA. Finally, it sends the encrypted
JSON and the XOR key through an HTTP POST request.
1 https://github.com/ucsb-seclab/agrigento
2
StringBuilder json = new StringBuilder();
// get Android ID using the Java Reflection API
Class class = Class.forName("PlatformId")
String aid = class.getDeclaredMethod("getAndroidId",
Context.class).invoke(context);
// hash Android ID
MessageDigest sha1 = getInstance("SHA-1");
sha1.update(aid.getBytes());
byte[] digest = sha1.digest();
// generate random key
Random r = new Random();
int key = r.nextint();
// XOR Android ID with the randomly generated key
byte[] xored = customXOR(digest, key);
// encode with Base64
String encoded = Base64.encode(xored);
// append to JSON string
json.append("O1:\’");
json.append(encoded);
json.append("\’");
// encrypt JSON using RSA
Cipher rsa = getInstance("RSA/ECB/nopadding");
rsa.init(ENCRYPT_MODE, (Key) publicKey);
encr = new String(rsa.doFinal(json.getBytes()));
// send the encrypted value and key to ad server
HttpURLConnection conn = url.openConnection();
OutputStream os = conn.getOutputStream();
os.write(Base64.encode(encr).getBytes());
os.write(("key=" + key).getBytes());
Fig. 1.
Snippet of code leaking the Android ID using obfuscation and
encryption. The example is based on real code implemented in the popular
InMobi ad library.
Depending on how this functionality is implemented, ex-
isting tools would miss the detection of this leak. Existing
approaches based on static analysis would miss this privacy
leak if the functionality is implemented in native code [5], dy-
namically loaded code [31], or in JavaScript in a WebView [28].
Furthermore, the use of the Java Reﬂection API to resolve calls
at runtime can severely impede static analysis tools.
More fundamentally, the complex lifecycle and component-
based nature of Android apps make tracking private information
throughout an app extremely challenging, and both static and
dynamic approaches are sensitive to the disruption of the data
ﬂow. For instance, many existing tools would miss this leak
if this functionality is implemented in different components.
Similarly, if the app ﬁrst writes the private information to a ﬁle,
e.g., its settings, and only later reads it from there to transmit
it via a network sink, any data ﬂow dependency would be lost.
Furthermore, data ﬂow is also lost when the implementation is
incomplete and fails to propagate data ﬂows through relevant
functions: TaintDroid for example does not track data ﬂows
through hashing functions [32].
Existing black-box approaches that analyze the network
trafﬁc would miss the detection of this leak as well, as they only
consider basic encodings, such as Base64 or standard hashing
algorithms, and cannot handle complex obfuscations techniques
that combine multiple different encodings and algorithms such
as the example code in Figure 1.
Our work attempts to ﬁll this gap: we focus on designing
and developing an approach able to detect privacy leaks even
when custom obfuscation mechanisms are used. Our approach
is black-box based, so it is not affected by code obfuscation
or complex program constructs. Furthermore, our approach can