□
C.5 Proof of Lemma 5.3
Proof. Let 𝐴0 be the set of IDs of points with height 0. We argue
that the height of 𝑝 ∈ 𝑉 is given by the maximum length of a path
from 𝑎 to 𝑝 over all 𝑎 ∈ 𝐴0. Fix some 𝑝 ∈ 𝑉 and suppose that
the maximum length of any path from the vertices in 𝐴0 to 𝑝 is ℓ,
and let there be such a maximal path from some 𝑎 ∈ 𝐴0 to 𝑝. By
correctness of Algorithm 1, the path from 𝑎 to 𝑝 in 𝐺 corresponds
to a chain in database D. Thus the height of 𝑝 is ≥ ℓ. Suppose for a
contradiction that 𝑝 has height ℓ′ > ℓ; By definition of height there
must exist a chain 𝐶 ⊆ D of size ℓ′ with 𝑝 as the maximal element.
Let 𝑐1 ⪯ 𝑐2 ⪯ · · · ⪯ 𝑐ℓ′ be the elements of 𝐶. We have that 𝑐𝑖+1
must minimally dominate 𝑐𝑖, otherwise we could could extend the
chain from 𝑎 to 𝑝 to have length greater than ℓ′. By correctness
of 𝐺, each edge (𝑐𝑖, 𝑐𝑖+1) must be in 𝐺. Hence the length of the
longest path from 𝑎 to 𝑝 in 𝐺 is ℓ′ > ℓ, a contradiction. Thus the
height of 𝑝 is given by the length of the longest path from 𝑎 to 𝑝
over all 𝑎 ∈ 𝐴0. Let 𝐿 be the number of partitions in the canonical
antichain partition of D. We have shown that Algorithm computes
the partition A = (𝐴0, . . . , 𝐴𝐿) correctly. Let 𝑎1, . . . , 𝑎𝑚 be elements
of a partition 𝐴 ∈ A. We show that Algorithm 2 correctly computes
an ordering of 𝑎1, . . . , 𝑎𝑚 i.e. a 𝑎𝛾1, . . . , 𝑎𝛾𝑚 such that 𝛾𝑖 = 1, . . . , 𝑚
and for all 𝑗 either 𝑎𝛾 𝑗 ⪯𝑎 𝑎𝛾 𝑗+1 or 𝑎𝛾 𝑗+1 ⪯𝑎 𝑎𝛾 𝑗 . If |𝐴| < 3 then
we are done. |𝐴| ≥ 3 then on line 12 we compute all responses in
RS(D) that contain exactly two elements in 𝐴 and denote this set as
𝑆. A response containing exactly two elements 𝑎, 𝑎′ ∈ 𝐴 exists only
if 𝑎 minimally anti-dominates 𝑎′ (or vice versa). Next we delete
all 𝑝 ∈ D − 𝐴 from responses in 𝑆 and make it a set. Let {𝑎, 𝑎′}
be an element of the resulting set 𝑆. Without loss of generality,
suppose 𝑎′ minimally anti-dominates 𝑎. Suppose that there exists
another set {𝑎′, 𝑎′′} ∈ 𝑆. Then by transitivity 𝑎′′ must minimally
anti-dominate 𝑎′. We can thus “order" the elements in 𝐴 by finding
consecutive pairs of points in the responses.
This Algorithm terminates in 𝑂(𝑅2|RS(D)|) time, as it takes
𝑂(𝑅2) time to find the longest paths in 𝐺 and 𝑂(𝑅2|RS(D)|) to
order the antichains.
□
C.6 Proof of Lemma 5.4
Proof. The antichains returned by Algorithm 2 may have in-
consistent direction. The first step of Algorithm 3 is to fix their
orientation. We assume that the first antichain, 𝐴0, has the correct
orientation. Then, we find the first element of 𝐴0 that has a dom-
inance edge to a point in 𝐴1, the second antichain. Let that edge
be (𝑐1, 𝑐2), 𝑐1 ∈ 𝐴0, 𝑐2 ∈ 𝐴1. If there are multiple options for 𝑐2, we
pick the smallest one in order. Note that each member 𝑝 of antichain
𝑖 must have a dominance edge with some member 𝑞 of antichain
𝑗, 𝑗 < 𝑖. Otherwise, 𝑝 would be part of some previous antichain.
If the order of antichain 1 is wrong, then a point 𝑐′
1 ∈ 𝐴0 in order
before 𝑐1 must have an edge with point 𝑐′
2 ∈ 𝐴1, in order after
𝑐2. If the chains were correctly ordered that would be impossible
as 𝑐′
2 cannot
dominate 𝑐′
1. Thus, Algorithm 2 can correctly orient the second
chain given the order of the previous antichains. Maintaining this
invariant, Algorithm 2 correctly orients all antichains.
2 anti-dominates 𝑐1 and 𝑐1 anti-dominates 𝑐′
1. Thus, 𝑐′
We begin constructing the anti-dominance graph by adding
anti-dominance edges between consecutive pairs of points in each
antichain. It remains to add anti-dominance edges between points
in different antichains. The algorithm iterates through pairs of
chains, and finds points 𝑎𝑖 and 𝑎 𝑗 that are not connected in 𝐺 and
𝑎𝑖 ∈ 𝐴𝑖, 𝑎 𝑗 ∈ 𝐴𝑗 , 𝑖 < 𝑗. Point 𝑎𝑖 either anti-dominates 𝑎 𝑗 or 𝑎 𝑗
anti-dominates 𝑎𝑖. In order to determine their relationship, we look
for a dominance edge between the antichains. If 𝑎 𝑗 anti-dominates
𝑎𝑖, then all predecessors of 𝑎𝑖 are also anti-dominated by 𝑎 𝑗 and
its successors. So, if a predecessor of 𝑎 𝑗 dominates a successor of
𝑎𝑖. Then 𝑎 𝑗 must anti-dominate 𝑎𝑖. Similarly, if a successor of 𝑎 𝑗
dominates a predecessor of 𝑎𝑖, then 𝑎𝑖 anti-dominates 𝑎 𝑗.
This technique finds only strict anti-dominance edges. It remains
to find any collinear anti-dominance edges. Given a pair of points
𝑝 and 𝑝, such that 𝑞 anti-dominates 𝑝, and a point 𝑘 that is in
Boxes(𝑝, 𝑞), 𝑘 must have an anti-dominance relationship with both.
If no such path exists in 𝐺′, we add appropriate edges depending
on which of the Boxes 𝑘 is in. Note that in some cases, as explained
by Proposition 3, it’s impossible to determine all collinearities. Our
definition of the anti-dominance graph is that it contains minimal
anti-dominance edges. Thus, after we remove any transitive edges,
we have generated D’s anti-dominance graph.
The algorithm takes 𝑂(𝑅2|RS(D)|) time: 𝑂(𝑅2) to fix the an-
tichains and add edges between them, and 𝑂(𝑅3 · |RS(D)|) to run
Boxes for any anti-dominance pair.
□
C.7
Proof of Theorem 5.5
Proof. By Lemma 5.1, PossibleConfigs has all possible config-
urations of a given set of extreme points. Thus, at some point we
pick the correct config. By Lemmas 5.2 and 5.4, we know that 𝐺 and
𝐺′ return correct weak dominance and anti-dominance graphs. By
Proposition 2, we know that if the smallest response that contains
top and bottom is empty, then they are an antipodal pair. Similarly
for left and right. We find all such pairs. We iterate though pairs of
points and find any that satisfy the close pair requirements from
Definition 3.3, constructing the closePairs set. The anti-dominance
graph encodes the components as the connected components of
the anti-dominance graph form the flippable components.
By Theorem 3.5, given (𝐺, 𝐺′, antipodalPairs, closePairs) out-
put by the algorithm, we can construct all members of set Eo(D).
Session 7C: Database and Privacy CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea2259Mean Squared
Error
Hausdorff
Distance
Pairwise Relative
Distance Error
CPU Usage
(hours)
Max Memory
Required (GB)
Normalized Mean
Error
NIS 2009: NCH & NDX
NIS 2009: NCH & NPR
NIS 2009: NDX & NPR
Figure 12: Accuracy (measured with the metrics defined in Section 7.3) and computational resource usage (CPU time and max-
imum memory required) of our reconstructions of the NIS 2009 datasets as a function of the query ratio, under the Uniform
(blue circle •), Beta (green star ★), and Gaussian (orange ♦) query distributions.
The first graph we return is sufficient as any other extreme point
configurations whose response set matches RS(D) are either rota-
tions/reflections or contain antipodal pairs. This Algorithm takes
𝑂(𝑅3|RS(D)|) time, as it takes 𝑂(𝑅3|RS(D)|) time to run Algo-
rithms 9, 1, 2 and 3. Finding antipodal pairs takes 𝑂(|RS(D)|) and
finding close pairs 𝑂(𝑅3). Finally, it takes 𝑂(𝑅4) time to generate
and compare the leakage. We can encode graphs 𝐺 and 𝐺′ by their
linear extensions in linear space, and the sets antipodalPairs and
closePairs contain at most 𝑂(𝑅) points.
□
Chao-Lee. Chao and Lee proposed an estimator that utilizes sample
coverage [8]. The sample coverage 𝐶 of a sample 𝐿 is the sum of
the probabilities of the the token-response pairs that appear in 𝐿.
this approximation in combination with an additive term to correct
estimates of data drawn from skew distributions. Let 𝑝𝑖 be the
probability that a query sampled from the distribution matches the
Knowledge of 𝐶 can then be used to estimate(cid:98)𝜌. Chao and Lee use
2 (cid:1) token-
2 (cid:1)(cid:0)𝑁1+1
𝑖-th token-response pair, of the possible 𝑄 =(cid:0)𝑁0+1
the the token-response pairs that appear in 𝐿: 𝐶 =𝑄
be used to estimate(cid:98)𝜌 ≈ 𝑑/ ˆ𝐶. Thus,
where ˆ𝛾 is an estimate of the coefficient of variation 𝛾 = (𝑖(𝑝𝑖 −
response pairs. Let 1𝐿(𝑖) be the following indicator function: 1𝐿(𝑖)
equals 1 if the i-th token-response pair is in 𝐿 and 0 otherwise. The
sample coverage 𝐶 of a sample 𝐿 is the sum of the probabilities of
𝑖=1 𝑝𝑖 · 1𝐿(𝑖).
Note that ˆ𝐶 = 1 − 𝑓1/𝑛 is a natural estimate for 𝐶, which can then
(cid:98)𝜌ChaoLee =
+ 𝑛(1 − ˆ𝐶)
𝑝𝑚𝑒𝑎𝑛)2/𝑄)1/2/𝑝𝑚𝑒𝑎𝑛 and 𝑝𝑚𝑒𝑎𝑛 is the mean of the probabilities
𝑝1, . . . , 𝑝𝑄.
Shlosser. Shlosser derived an estimator that works well under the
assumption that the sample is large and the sampling fraction is non-
negligible [42]. We used an implementation of Shlosser Estimator
that used a Bernoulli Sampling scheme. This estimator is more
effective for skewed distributions.
Let 𝑞 be the probability with which a token-response pair is
included in the sample. In [42], Shlosser derived the estimator
· ˆ𝛾2,
𝑑
ˆ𝐶
ˆ𝐶
D Estimators
Let D be a database of 𝑅 records and let
𝑀 = {{(𝑡1, 𝐴1), . . . , (𝑡𝑚, 𝐴𝑚) : 𝐴𝑖 ∈ RS(D)}}
be a sample (i.e. multiset) of 𝑚 token-response pairs that are leaked
when queries are issued according to an arbitrary distribution. Let
𝑀 be a sample and let 𝑛 denote the size of a subsample 𝐿 ⊆ 𝑀.
Denote by 𝑑 the number of distinct tokens in a subsample 𝐿 ⊆ 𝑀.
Definition D.1. [45] Let 𝐿 be a subsample and let 𝑓𝑖 be the number
of search tokens that are observed 𝑖 times in 𝐿. The fingerprint of
a sample 𝐿 is the vector 𝐹 = (𝑓1, 𝑓2, ..., 𝑓𝑛), where |𝐿| = 𝑛. We can
𝑖=1 𝑖 𝑓𝑖
𝑖=1 𝑓𝑖.
express the total number of token-response pairs in 𝐿 as 𝑛 =𝑛
and the number of observed distinct search tokens as 𝑑 =𝑛
To estimate(cid:98)𝜌 ≈ 𝜌, we let 𝐿 be a submultiset of 𝑀 comprised of
all token-response pairs that contain the identifiers of the points
whose 𝜌 value we wish to compute. We then use an estimator to
estimate how many unique search tokens are associated with those
record identifiers. We describe three such estimators below.
(cid:98)𝜌Shloss = 𝑑 + 𝑓1𝑛
𝑛
𝑖=1(1 − 𝑞)𝑖 · 𝑓𝑖
𝑖=1 𝑖 · (1 − 𝑞)𝑖−1 · 𝑓𝑖
.
This estimator rests on the assumption that 𝑞 = 𝑛/𝑄. As [21]
notes, the Shlosser estimator further rests on the assumption that
Session 7C: Database and Privacy CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea2260E[𝑓𝑖]/E[𝑓1] ≈ 𝐹𝑖/𝐹1 where 𝐹𝑖 is the number of tokens that appear
𝑖 times in entire database; This assumption isn’t often satisfied in
our setting, but our experiments demonstrate that Shlosser did
comparable to Jackknife in various cases.
Jackknife. The jackknife method was introduced as a technique
for correcting the bias of an estimator [40]. We use the jackknife
estimators described in [2, 3], which have been used for the prob-
lem of estimating the number of unique attributes in a relational
database [21], in database reconstruction [27], and in biology for
the related problem of species estimation. Given a biased estimate,
jackknife estimators use sampling with replacement to estimate
the bias 𝑏𝑖𝑎𝑠 𝑗𝑎𝑐𝑘, and obtain(cid:98)𝜌jack.
estimate the bias 𝑏𝑖𝑎𝑠 𝑗𝑎𝑐𝑘, and obtain(cid:98)𝜌jack = 𝑑 − 𝑏𝑖𝑎𝑠 𝑗𝑎𝑐𝑘. Let 𝑑𝑛
One can view 𝑑 as a biased estimate of the true 𝜌. Given a biased
estimate 𝑑, jackknife estimators use sampling with replacement to
denote the number of unique tokens in 𝐿 and let 𝑑𝑛−1(𝑘) denote
the number of unique tokens in 𝐿 when the 𝑘-th token-response
removed. Note that 𝑑𝑛−1(𝑘) = 𝑑𝑛 − 1 if and only if the 𝑘-th pair
𝑘=1 𝑑(𝑛−1)(𝑘). The first order
order jackknife considers all 𝑛 samples generated by leaving one
is unique in 𝐿. Let 𝑑𝑛−1 = (1/𝑛)𝑛
jackknife estimator is(cid:98)𝜌jack = 𝑑 − (𝑛 − 1)(𝑑(𝑛−1) − 𝑑). The second
pair out, in addition to all(cid:0)𝑛
2(cid:1) generated by leaving two pairs out.
(cid:1) samples and has bias 𝑂(𝑛−𝑘+1).
𝑖=1(cid:0)𝑛
that generates𝑘
This method can be extended to an 𝑘-th order jackknife estimators
𝑖
E Experimental Results
In Figure 12, we show the results of our reconstructions of the
NIS 2009 dataset. Overall, the results follow a similar trend to the
results in Figure 9. There is a decrease in normalized mean error,
mean squared error, and pairwise relative distance error, as a larger
percentage of queries is observed. We also note that the maximum
memory required is fairly constant across all runs.
Session 7C: Database and Privacy CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea2261