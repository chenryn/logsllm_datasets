title:DSybil: Optimal Sybil-Resistance for Recommendation Systems
author:Haifeng Yu and
Chenwei Shi and
Michael Kaminsky and
Phillip B. Gibbons and
Feng Xiao
2009 30th IEEE Symposium on Security and Privacy
DSybil: Optimal Sybil-Resistance for Recommendation Systems
Haifeng Yu∗, Chenwei Shi†, Michael Kaminsky‡, Phillip B. Gibbons§ and Feng Xiao¶
∗School of Computing, National University of Singapore, Singapore. Email: PI:EMAIL
†School of Computing, National University of Singapore, Singapore. Email: PI:EMAIL
‡Intel Research Pittsburgh, Pittsburgh, USA. Email: PI:EMAIL
§Intel Research Pittsburgh, Pittsburgh, USA. Email: PI:EMAIL
¶School of Computing, National University of Singapore, Singapore. Email: PI:EMAIL
Abstract
Recommendation systems can be attacked in various ways,
and the ultimate attack form is reached with a sybil attack,
where the attacker creates a potentially unlimited number
of sybil identities to vote. Defending against sybil attacks is
often quite challenging, and the nature of recommendation
systems makes it even harder.
This paper presents DSybil, a novel defense for diminishing
the inﬂuence of sybil identities in recommendation systems.
DSybil provides strong provable guarantees that hold even
under the worst-case attack and are optimal. DSybil can
defend against an unlimited number of sybil identities over
time. DSybil achieves its strong guarantees by i) exploiting
the heavy-tail distribution of the typical voting behavior of
the honest identities, and ii) carefully identifying whether the
system is already getting “enough help” from the (weighted)
voters already taken into account or whether more “help” is
needed. Our evaluation shows that DSybil would continue to
provide high-quality recommendations even when a million-
node botnet uses an optimal strategy to launch a sybil attack.
1. Introduction
Recommendation systems recommend objects to users
based on other users’ reported prior experience with those
objects (i.e., votes). There are numerous real world examples
for recommendation systems, such as Netﬂix (for movie rat-
ing), Amazon (for book rating), Razor [52] (for collaborative
spam ﬁltering), Digg [23], and Credence [60]1. By casting
misleading votes, malicious users or malicious identities can
potentially mislead a recommendation system. In addition
to casting such votes, an adversary seeking to magnify its
inﬂuence can bribe honest users or even compromise honest
users’ computers to obtain bribed identities or stolen identities
1. Digg is a popular web site where users “digg” news stories that
they consider interesting. A news story with many “diggs” may then be
recommended to other users. Similarly, Credence allows p2p ﬁle sharing
users to vote whether a downloaded ﬁle is corrupted. Such votes can then
guide other users’ downloading.
to cast more votes. The ultimate form is reached with a
sybil attack [26], where the attacker creates a potentially
unlimited number of fake identities (i.e., sybil identities) to
vote. Off-the-shell software such as Tube Automator [58] and
Friend Bomber [31] can readily launch such sybil attacks on
recommendation systems.
In this paper, we will use the term sybil identities to refer to
all malicious/bribed/stolen/sybil identities. Defending against
sybil identities is usually quite challenging, and the nature of
recommendation systems makes it even harder. For example,
it is known [11, 17, 29] that DHTs can be made secure as
long as the fraction of sybil identities is below 1/4. On the
other hand, recommendation systems have signiﬁcantly lower
“tolerance”: Because on average only a small fraction (e.g.,
1% or 0.1%) of the honest users will vote on an object, even
a relatively small number of sybil identities can out-vote
these honest voters.
Most existing sybil defense mechanisms [12, 16, 21, 56,
61] cannot provide such strong guarantees. For example,
there is evidence [51] that botnet sizes can easily reach
105. Even (optimistically) assuming that the sybil defenses
can enforce one sybil identity per bot, out-voting the sybil
identities created from such a botnet can require a system
with 10 to 100 million (i.e., 105 divided by 1% or 0.1%)
honest users! By leveraging social networks, some recent
sybil defenses [44, 57, 61, 62] can nullify the effect of all bots
outside the system’s social network. But they can still fail
to provide guarantees that match recommendation systems’
low tolerance threshold (see Section 2).
Trust-based approaches and previous efforts. While di-
rectly bounding the fraction of sybil identities is unlikely to
be effective for recommendation systems, it is possible to
reduce the inﬂuence of sybil identities gradually over time
based on their historical behavior. For example, a user Alice
may trust another identity Bob less if Bob voted for objects
that Alice found to be bad. If one can sufﬁciently diminish
the inﬂuence of all the sybil identities, then the sybil attack
becomes ineffective, for all practical purposes.
Leveraging trust (built over history) in recommendation
systems is in no way a new idea. Because trust maps nicely
1081-6011/09 $25.00 © 2009 IEEE
DOI 10.1109/SP.2009.26
283
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 03:17:54 UTC from IEEE Xplore.  Restrictions apply. 
to human intuition and real life experience, there have been
many efforts to leverage trust for defending against malicious
users (and occasionally sybil identities). Although simple at
the intuitive level, rigorously reasoning about the numerous
design alternatives and their end guarantees is always rather
tricky.
Because of such difﬁculty, most previous efforts (e.g.,
[20, 22, 32, 34, 36, 37, 40, 46, 49, 60]) only explore
heuristics without hard guarantees. The proposed techniques
are evaluated only against synthetic attacks or attacks
observed in measurement traces. It is never clear how robust
these systems are against an intelligent adversary launching
an optimal attack. We argue that such heuristics can only
result in an endless arms race between the attacker and the
system designer. On the other hand, there has also been a
large body [3, 5, 6, 13, 14, 18, 30, 47, 53, 54] of theoretical
work on how to make robust recommendations with provable
guarantees. However, to overcome the difﬁculty in rigorous
reasoning about design alternatives and end guarantees, all
of them need to make strong restrictive (and sometimes
unrealistic) assumptions. For example, some [5, 53, 54]
assume that in each round all users vote and that they vote
sequentially in some ﬁxed order. In summary, it is still an
open question how to deal with a limited number of malicious
identities, let alone a potentially unlimited number of sybil
identities.
Our goal and approach. This paper aims to answer the
following central question:
Is it possible to sufﬁciently diminish the inﬂuence of (a
potentially unlimited number of) sybil identities based on
historical behavior?
In answering this question, we aim for provable guarantees
that hold even under the worst-case attack. To avoid overly
restrictive assumptions, we leverage the fact that we do not
need to optimize for the worst-case voting behavior of the
honest identities. After all, the honest identities do not aim
to defeat our system. Speciﬁcally, we exploit the heavy-
tail distribution of the typical voting behavior of the honest
identities, and show that this single property can enable a
design with strong guarantees.
Our contributions and results. This paper presents DSybil,
a novel defense for diminishing the inﬂuence of sybil identi-
ties in recommendation systems. DSybil targets application
scenarios such as Digg and Credence where the objects to
be recommended are either good or bad. DSybil has the
following salient features:
• DSybil can defend against an unlimited number of sybil
identities over time.
• The loss (i.e., number of bad recommendations) is
O(D logM) even under the worst-case attack, where
M is the maximum number of sybil identities voting on
any one object and D is the dimension of the objects
(see deﬁnition below).
• We prove that the O(D logM) loss is optimal. We further
show that different from scenarios such as byzantine
consensus and DHTs, for a recommendation system to
tolerate more sybil identities, the lifespan of the honest
users is far more important than their population.
• DSybil provides a growing defense: If the user has used
DSybil for some time when the attack starts, the loss
will be signiﬁcantly smaller than the loss under the
worst-case attack.
DSybil achieves its strong guarantees partly by optimizing
only for cases where D is small. Roughly speaking, given a
set of objects from which we need to make recommendations,
the dimension D is the minimum number of honest users
that can cover a signiﬁcant fraction (e.g., 60%) of the good
objects in the set.2 Here a user covers an object if the user
has voted for that object. The value of D is determined by the
voting behavior of the honest users. Our study of large-scale
datasets from real-world recommendation systems shows that
D tends to be rather small in practice, due to the heavy-tail
vote distribution of the (honest) users. We show that as long
as the distribution is heavy-tail, the dimension is likely to
be rather small.
Even with small dimension, how to design a robust
recommendation system is far from obvious. The central
challenge is the tension between i) giving trust to honest
identities for their helpful voting, and ii) avoiding giving
trust to those sybil identities who are behaving like honest
identities (but who could later use the trust to inﬂict loss).
As one would imagine, any design here will necessarily be
a double-edged sword: Not giving trust to sybil identities
in some cases will unavoidably cause the system not to
give trust to some honest identities in other cases. The crux,
then, is how to strike the optimal balance between the two
factors. In DSybil, we clearly identify whether the user is
already getting “enough help” from those identities that the
user trusts. If yes, DSybil will not grow the trust to anyone
(including honest identities). We are able to show that this
design leads to an optimally small loss.
We have implemented DSybil as a toolkit in Java. Our
experimental results based on a one year crawl of Digg
show that under practical parameters and without taking
the growing defense into account,
the fraction of bad
recommendations by DSybil is only around 12% even when
each object has up to 10 billion sybil voters and (on average)
only 1,239 honest voters. Taking the growing defense into
account, the fraction of bad recommendations further drops
to around 6% (or 4%) if the user had been using DSybil for
a day (or month) when the attack starts. Assuming that an
average honest user’s lifespan (of using DSybil) is one year,
and assuming that the adversary starts attacking at a random
point in time, 364/365 ≈ 99.7% (or 11/12 ≈ 91.7%) of the
honest users will have used DSybil for a day (or month)
2. DSybil does not know or try to determine D.
284
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 03:17:54 UTC from IEEE Xplore.  Restrictions apply. 
when the attack starts.
With its strong robustness against sybil identities, DSybil
needs to use only some basic mechanism to loosely limit M.
Speciﬁcally, whenever the number of votes on any object
exceeds a certain threshold (e.g., 1 billion), DSybil will start
imposing a recurring computational puzzle on each voting
identity. In our example setting with a recurring 1-minute
computational puzzle per week, an adversary would need
a million-node botnet to cast the aforementioned 10 billion
votes on an object.3
2. Related Work
Sybil defenses not leveraging social networks. One way
to defend against sybil attacks in recommendation systems
is to leverage generic sybil defenses that can bound the
number of sybil identities accepted/admitted (which in turn
limits the number of sybil voters). The simplest generic
sybil defense is for a trusted central authority to verify
credentials (e.g., credit card or passport) that are unique
to actual human beings. Unfortunately, this often leads to
privacy concerns and scares away users. SMS veriﬁcation
also incurs privacy concerns, and does not work well if
the attacker has access to cheap phone accounts. Graphical
puzzles requiring human efforts (such as CAPTCHAs [59])
can be reposted on the adversary’s web site to be solved by
clients seeking access to that web site. Charging a fee for
each identity can undermine the exact reason why online
recommendation systems are popular. Additionally, all the
above approaches require a central server, which may not be
available (e.g., in Credence). Researchers have also proposed
a limited number of decentralized sybil defense mechanisms,
including mechanisms based on IP addresses/preﬁxes [21],
resource challenges [16, 56], or network coordinates [12].
All these approaches only provide limited protection and are
fundamentally vulnerable to powerful adversaries attacking
from botnets.
Sybil defenses leveraging social networks. To better de-
fend against sybil attacks, recent sybil defenses (such as
SybilGuard [62], SybilLimit [61], Ostra [44], SumUp [57])
leverage the social network among the users. Here an edge
connecting an honest user and a malicious user is called an
attack edge. Because each edge involves human-established
trust, it is difﬁcult for the adversary to introduce an excessive
number of attack edges. Given g attack edges, if the number
of sybil identities behind the attack edges is much larger
than g, it will result in a small quotient cut in the graph
(where the quotient is between g and the number of sybil
identities). This graph property translates to poor expansion
and large mixing time.
Leveraging this graph property (i.e., expansion and mixing
time) can be powerful. If one is willing to assume global
knowledge of the continuously-changing social network
(i.e., one node maintains an up-to-date copy of the entire
social network graph), then simply running an approximation
algorithm [42] for minimal quotient cut will bound the
number of sybil identities accepted within O(glogn), where
n is the number of honest identities. Also assuming global
knowledge and further focusing on scenarios where only o(n)
honest identities are seeking to be accepted, SumUp [57] uses
adaptive maximum ﬂow on the social network to bound the
number of sybil identities (voters) accepted within g+o(g).4
SybilLimit [61], in contrast, avoids the need for any global
knowledge by using a decentralized secure random route
technique. It bounds the number of sybil identities accepted
within O(glogn), while provably accepting nearly all honest
nodes.
Unfortunately, a lower bound in [61] implies that any
social-network-based sybil defense (including all of the
systems mentioned above) will be insufﬁcient for recom-
mendation systems, whose tolerance threshold is rather low
(e.g., 1% or 0.1%). Speciﬁcally, the lower bound proves that
exploiting the graph property (i.e., expansion and mixing
time) can at the best help us to bound the number of sybil
identities accepted within the order of g, and g can easily
be larger than the number of honest voters. For example,
suppose that each node in the social network has a degree
of 10, and optimistically assume that we accept all honest
voters and only g sybil voters. Then as long as the adversary
can compromise 0.1% (or 0.01%) of the honest identities,
the sybil identities can out-vote those 1% (or 0.1%) honest
voters. A recent study claims that 40% of the PCs in the
U.S. are infected by botnets [1]. While it is quite unlikely
for all of them to belong to the same botnet, it is not hard
to imagine that many botnets can easily exceed the 0.1% or
0.01% threshold, and out-vote the honest voters.
In contrast, DSybil (which targets recommendation systems
only) uses a completely different approach that i) does not
require a social network, ii) is not subject to the lower bound