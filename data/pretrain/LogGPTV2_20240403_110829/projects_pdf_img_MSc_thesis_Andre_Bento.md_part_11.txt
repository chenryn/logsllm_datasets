The first situation is much worse than the second one. The expectation is that services
can handle more requests and keep the average response time, however, this system is
being used for testing purposes, and it has been target of several load and fault injection
tests. Furthermore, we do not have access to information regarding this tests, thus we
can not be certain if the detected outliers can be considered real “anomalies” presented in
services, however, they are interesting points to care about due to their unusual values.
The worst case scenario would be to find points in the upper-right section of the charts,
however this was not observed in this tracing data which leads to the assumption that this
system is able to scale their workload well and therefore, it is capable of keeping response
time low with large amounts of requests.
To study both situations, and further our anomaly detection presented in services, an
analysis of trace request work-flow types was performed. The objective of this analysis is
to perceive if there is some strange occurrences in request work-flow paths. To be able
to perform this process, the OTP must be able to get the tracing data and map each
unique trace work-flow for the given time-frame. We have used the method presented in
Algorithm 3 to retrieve this information.
Aspresentedinalgorithm3,parametersfromTraceInfoarewrittentoCSVfiles. These
files are then processed in the “Data Analyser” component and, afterwards, a grouping
of work-flow types from “Anomalous” and “Non-Anomalous” regions are retrieved for
plotting. Results from this method are presented in Figure 6.3.
Figure 6.3: Comparison between “Anomalous” and “Non-Anomalous” service work-flow
types.
Figure3showsacleardifferencebetweenwork-flowtypespresentedin“anomalous”and
“non-anomalous” regions. One interesting thing to notice and that gives more evidence to
proveanomaliespresentedintheseregionsisthat,intheanomalousregions,morequantity
andmoretypesofrequestwork-flowtypeswereobserved. Thenextstepwastocheckwhat
was causing this by retrieving the most “called” work-flows, however, the results were not
60
Results, Analysis and Limitations
good because of the completeness of the tracing data. The flows were not relevant to
further our analysis because they were just calls from point A to point B, or represented
a not so interesting request path due to involved services. Also, in some of these requests
work-flow path, high values of response time were observed and therefore, they tocked
longer to execute, however, like for the previous explanation, their path was not relevant
to study. For these reasons, there were no possibility to extend our analysis and identify
the root cause for these abnormal observed behaviours. Therefore, at this point and for
this question, it is possible to say that this data set was exhaustively analysed, and an
improvement of the tracing data, or the gathering of other types of data, e.g., monitoring
and logging, should be a path to take. One point to note for future work is to test this
method with other tracing data, to evaluate them and understand if this approach can
lead to identification of the root cause of anomalous behaviour presented in services. For
this reason, the data provided and thus, the OpenTracing in general has some limitations.
These limitations are covered and explained further in Section 6.3.
6.2 Trace Quality Analysis
For the second question, the main approach was the same as in for the previous ques-
tion, we need to use the OTP to process the tracing data and gather the results to be
further analysed in the “Data Analysis” component. However, in this case, the results
obtained by the first component were directly used by the second one.
In this question the analysis is divided in two procedures as explained in Chapter 4.
The first procedure aims to check if the spans comply with the OpenTracing specification.
This method is rather simple and is presented in Algorithm 5.
The results obtained by the application of this method were that every span structure
complies with the specification. This is not a very good test because the specification of
the OpenTracing is not very strict and therefore, the created method for testing does not
provide a very accurate kind of results. To better explain this topic, we give two examples
withsomesolutionsforeachone. Firstexample, theunitsfortimestampsarenotuniform,
one can use milliseconds and in other field of a span presented in the same trace, other
can use microseconds. This leads to problems in time measurements and is not covered by
this test. The solution for this problem can be the standardization of values and use only
one measurement unit. Second example, there are multiple declarations for fields with
key → value pairs, and thus, this brings inconsistency and uncertainty with the possible
values that can appear. One solution for this is to redefine the semantic specification and
terminology for programmers to adopt in their implementations. The limitations of this
specifications and the redefinition of the OpenTracing specification is discussed later in
Section 6.
The second procedure aims to check if tracing covers the entire time of the root spans.
For a simple example, if we have a trace with a root span of 100 milliseconds of duration,
and this root span has two children spans, one with 50ms, the other one with 10ms, the
entire trace has a coverage of (50 + 10)/100 = 60%. This method is applied to every
trace, and the results are plotted for visualisation. In this case we apply it and split the
results by service, with the objective of perceive the time coverability of tracing in each
service. The method is presented in Algorithm 6 and the corresponding results, regarding
two different services, are presented in Figure 6.4.
61
Chapter 6
Figure 6.4: Services coverability analysis.
Figure 6.4 allows the user to visualise the tracing coverability, in terms of how many
the overall tracing covers their entire execution duration. The most important thing to
notice for this tracing data is the presence of higher bar values in 60%−100% regions.
This means that coverability for this tracing could be better, but in overall is good. What
is expected by the result of this kind of analysis is that the coverability of tracing remains
closer to the last interval (90%−100%), which means that our service is fully/almost fully
covered by this kind of data and therefore, the analysis of this data is worthy and the
results provided by the usage of this it are trusty. From this data set, the results for the
remaining services where close to the ones presented and shown by Figure 6.4.
After checking these results, one can use them to see which services developers can
analyse in order to improve the coverage of tracing. To improve this coverage, changes
in code instrumentation must be performed. Later on, after performing changes in code
instrumentation and gather new trace information, the method for coverability test must
be executed over the new tracing data to see if results have changed. What is expected
is that trace coverability raises, which means that, for example, for service B presented in
this figure, after developers changed the implementation, the trace counting for coverage
must shift into higher intervals, and for this reason, one must observe lower values for
1%−70% and higher values for 71%−100%. From this analysis, one thing to improve
is to develop a method to analyse the gathered results in order to detect traces that do
62
Results, Analysis and Limitations
not cover their duration with respect to a predefined threshold. For example, the method
could be applied to newer services after some time (to gather sufficient trace information),
and then report or notify the developer if the service does not comply with the predefined
coverage threshold. This would allow developers to improve their tracing coverage.
6.3 Limitations of OpenTracing Data
In this Section, we explore limitations felted when using and only using OpenTracing
data in this research and therefore, give some solutions to improve this work and present
a brand new project that emerged in the end of this research.
Limitations of OpenTracing were exposed in previous topics, Sections 6.1 and 6.2.
These limitations are presented bellow:
1. There is no definition in the specification for which measurement units can be used
whendefiningnumericvaluesinspans,neitheranexclusivefieldorin-fieldtoindicate
them;
2. Spansdonotcontainanyfieldtoindicatecausally-relatedspansfromdifferenttraces;
3. Specification does not provide a set of possible values for keys in key → value fields
presented in spans;
4. Spans do not contain any field to identify correlated logs;
5. There are no defined way to record raw measurements or metrics with predefined
aggregation and set of labels from tracing.
The first limitation brings problems regarding the definition of time units in spans.
Without the clear indication of units used in these metrics, one may confuse the mea-
surement and make the mistake of inferring misleading values, resulting in wrong spread
of spans throughout time. This scenario occurred when posting our tracing data to dis-
tributed tracing tools, and to solve this, we needed to check the measurement unit defined
by the tool. For this reason, this is a big problem, and therefore, this should be defined
in the specification.
Second limitation causes the inability of knowing which spans are related with other
ones when they are presented in different traces. Not having this information leads to lack
of understanding of causally relationships between operations performed by distributed
components. Therefore, to solve this issue, an additional field of causally-related spans or
traces should be added to the span structure.
Third limitation consists in having fields of key → value pairs, when there is no defini-
tion of which keys can appear. This can be solved by creating a predefined schema where
allpossiblekeyvaluesmustbeindicated. Itlookseasytofixthisissue, however, tochange
the specification, there must be consensus in a unified structure and create new tools to
process this new tracing data.
Fourth limitation, tracing contains relevant information about system work and can
be used to map the flow of execution throughout the system, however, it could be much
more complete if it contained a correlation between spans and logs. This could be solved
if the span structure contained a field to declare related logs. Furthermore, the explicit
63
Chapter 6
declarations of logs would ease Development and Operations (DevOps) work because they
retrieve logs manually by time intervals after searching in tracing for e.g., longer spans.
Lastlimitationsaysthattracingspecificationdoesnothaveadefinedwaytorecordraw
measurements or metrics. This can be solved if specification and OpenTracing provided
an Application Programming Interface (API) with defined metrics that could be exploited
from tracing to be further analysed. This limitation was surpassed by creating a metrics
extractor from tracing data in our proposed solution.
These limitations are generated by some issues presented in the specification of Open-
Tracing. Provide changes was not the focus of this research, however, these limitations
carriedoutbarriersforourownresearchbecausetheybringdifficultywhenprocessingthis
type of data. For this reason, revise and perform adjustments to the whole specification
is a job that must be done to ease tracing handling and analysis.
Near the end of this research, a project started with the support of big companies such
as Google, Lightstep and Uber. This project, named as OpenTelemetry [71], is backed by
CNCF: Cloud Native Computing Foundation and for this reason is open source. Started
in April 2019 and has a defined roadmap to November 2019 with the main objective of
merging OpenCensus and OpenTracing. The last one was the main focus of the research
presented in this thesis because we only had access to tracing data. OpenCensus is a set
of libraries for various languages that allows to collect application metrics, furthermore,
this data can be analysed by developers and administrators to understand the health of
the applications and debug problems [23].
The creation of OpenTelemetry and the interest from all these companies proves and
emphasizes the whole work carried out during this research. All starting points for the
creationofOpenTelemetry solution,standsintheproblemsandlimitationsofOpenTracing
felted during this work and presented above. Furthermore, in June 2019, a revision of
tracing specification was planned and worked out with the objective of introducing new
standard tags, log fields, and change span context reference types [72]. Also, in this
project, creators are planning to develop a metrics API, however, at time of writing, the
only decision that was made is to use time-series to handle this kind of data but there is
no specification created so far.
The usage of metrics, logs and other information come from the main objective of this
project, merge OpenCensus and OpenTracing. Though the various components will be
loosely coupled and consumed separately, the scope of the merged project includes data
sourcesbeyonddistributedtransactiontraces. Afterall,instrumentationandobservability
involveotherdatasources, too. SothesurfaceareaofmergedprojectAPIwillincorporate
a variety of signals, like metrics, traces and logs providing higher observability.
Observability stems from the discipline of control theory and refers to how well a
systemcanbeunderstoodonthebasisofthetelemetrythatitproduces. Fromdistributed
systems, three major vertical data types are generated: Tracing, Metrics and Logging,
and therefore, because they are tightly interconnected, one should use all of them to fully
achieve observability of these systems. For this reason, Metrics can be used to pinpoint,
for example, a subset of misbehaving traces. Logs associated with those traces could help
to find the root cause of this behaviour. And then new metrics can be configured, based
on this discovery, to catch this issue earlier next time. Furthermore, OpenTelemetry is an
effort to combine all three verticals into a single set of system components and language-
specific telemetry libraries and, in the end, replace both the OpenTracing project, which
focused exclusively on tracing, and the OpenCensus project, which focused on tracing and
metrics.
64
Chapter 7
Conclusion and Future Work
This Chapter covers three main topics: a summary of what we did and the main
conclusions we reached from this research; followed by brief reflections regarding this
whole research topic; and ending with the future work and research paths that seem to be
promising for the future.
After this whole research, we are able to state that tracing data is useful and required
to find anomalies related to service morphology. However, this type of data is hard to
handle and one must use it if some issue was detected in metrics easier to analyse, e.g.
monitoring. For this type of data to be easier to analyse, a discussion is provided about
this difficulty bellow. So, in the end our perception is that, there are issues that we can
only perceive using tracing data, but it is very expensive to analyse this data directly.
Fromtracingqualityanalysis,bothtestsareveryinterestingbut,duetolackofrequired
and strict specification, the tests and results of the “structural quality analysis” using
spans are not very useful however, one can state that this is all we can do taking into
consideration the OpenTracing specification.
Intheend, ouranalysisoftheprovidedtracingdatageneratedbyOpenStack –Huawei
Cluster, took us to the following conclusions about OpenTracing:
1. OpenTracing suffers from a lack of tools for data processing and visualisation.
2. The OpenTracing specification is ambiguous.
3. The lack of tools to control instrumentation quality jeopardizes the tracing effort.
Firstly, we found it difficult to find appropriate tools for tracing data processing and
visualisation. Only Zipkin and Jaegger, presented in the Subsection 2.2.1, are useful, as
they allow distributed tracing visualisation in a human readable way. Unfortunately, they
do not present any kind of tracing analysis. The need for additional open-source tools
that can perform tracing analysis and visualisation is therefore quite real.
Secondly, one of the main difficulties in implementing the OpenTracing processor
(OTP) and Data Analysis tools we mentioned in this thesis is the ambiguity in tracing
data. The specification includes many fields that are not strictly defined. As mentioned
in Section 6.2, one of the problems is the lack of standardization of measurement units,
whichledtodifferentonesbeingusedinthedataprovided. Otherproblemresidesinsome
fields that contain very important information about the path of the request. These fields
are defined as key-value pairs, where the keys vary freely according to the programmer’s
65
Chapter 7
needs. This raises a major challenge for tools, which must infer the units, or assume that
some data is unsuitable for analysis. A simple solution could be to redefine the speci-
fication and reduce this kind of fields, transforming the specification into a more strict
schema. This would allow the implementation of more general trace processing tools.
Therefore, from this work, the following research paths are considered for future work:
1. Improve and develop new tools for OpenTracing processing.
2. Perform a research to redefine the OpenTracing specification.
3. Explore and analyse the remaining extracted tracing metrics.
4. Use tracing data from other systems.
5. Developasimulatedsystemwiththecapabilityoffault-injectiontoprovetheanalysis
observations.
6. Conciliate the results from tracing data with other kinds of data like monitoring and
logging.
7. Follow closely the development and the community of OpenTelemetry project, and
contribute with ideas generated by this research.
First, today there are not many tools for processing and handling OpenTracing data.
This increased difficulty is felt when we needed to process this kind of data in a different
way, because we always ended up developing everything from scratch.
Second, there must be a way to eliminate or reduce the ambiguity and uncertainty
of data presented in tracing generated by non-strict fields. If the specification can not
be changed, a new way to transform tracing data to ease the analysis is very welcome.
However, this is a topic that should be covered by the development of OpenTelemetry
project, as mentioned in Section 6.3.
Third, these developed tools extract many more metrics. The majority of them were
not explored due to lack of time, and therefore, here resides the opportunity to do it. The
path starts by defining new research questions or analyse the remaining ones, presented
in Section 3.2, that use these metrics and develop ways to analyse them.