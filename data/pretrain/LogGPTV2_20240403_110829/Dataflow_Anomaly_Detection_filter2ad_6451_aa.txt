# Dataflow Anomaly Detection

**Authors:**
- Sandeep Bhatkar
- Abhishek Chaturvedi
- R. Sekar

**Department of Computer Science, Stony Brook University, Stony Brook, NY 11794**
- {sbhatkar, abchatu, sekar}@cs.sunysb.edu

## Abstract

Since the work of Forrest et al., several researchers have developed intrusion detection techniques based on modeling program behaviors through system calls. A significant limitation of these techniques is their focus on control flows involving system calls, while neglecting the arguments of these calls. This oversight makes them vulnerable to various types of attacks, including those targeting security-critical data, race conditions, symbolic link attacks, and mimicry attacks.

To address this weakness, we introduce a new approach for learning dataflow behaviors of programs. Our method captures temporal properties involving the arguments of different system calls, thereby tracking the flow of security-sensitive data. This approach can be uniformly integrated with most existing control-flow models, enhancing their precision by leveraging control-flow contexts. Unlike previous techniques that focused on statistical properties of individual system call arguments, our method supports formal reasoning about security assurances, such as ensuring that a program like `tar` only reads files within a specified directory.

## 1. Introduction

Starting with the work of Forrest et al. [15], researchers have developed intrusion detection techniques based on modeling program behaviors using system call sequences [25, 21, 11, 30, 7, 14, 9, 19]. Approaches in [15, 32, 33, 21, 25, 7, 9] learn models from observed program behaviors during a training phase, assumed to be free of attacks. Other methods use static analysis of source code [30, 19] or binaries [14, 6]. These models have been represented as strings [32, 33], finite-state automata [25, 30, 21], and push-down automata [7, 14, 19, 9].

These techniques are effective against common attacks, such as the execution of foreign code and unusual code paths triggered by malicious inputs. However, their focus on control flows, with little emphasis on data flows involving system call arguments, makes them susceptible to several classes of attacks:

- **Non-control-flow hijacking attacks:** [5] demonstrates attacks on common servers targeting security-critical data.
- **Race condition attacks:** [2] exploits TOCTOU (Time Of Check To Time Of Use) errors, where the resource referenced changes between check and use.
- **Mimicry attacks:** [31] shows evasion attacks where an attacker modifies the attack to closely mimic the program's behavior as seen by the IDS.

To detect these attacks, it is necessary to reason about system call arguments. Previous research in this direction has focused on learning statistical properties of each system call argument in isolation [18, 27]. In contrast, our technique learns temporal properties involving arguments of different system calls, capturing the flow of security-sensitive data. Our contributions include:

- **Formulation of dataflow properties:** We define dataflow properties in terms of externally observable events, specifically system calls. These properties hypothesize dataflows based on relationships between system call parameters.
- **Efficient algorithm:** We present an efficient algorithm that can be layered on top of existing control-flow learning techniques, enhancing their precision.
- **Experimental evaluation:** We demonstrate the benefits of our technique, including improved attack detection, formal security assurances, and enhanced model precision.

## 2. Defining Data Flow Behavior

### 2.1. Events, Traces, and Behavior Model

We formalize program behaviors in terms of externally observable system call events. Key definitions include:

- **Execution trace (T(P))**: The sequence of all system calls executed by a program P, including information about system call arguments and runtime environment.
- **System call tracer (tracer)**: Intercepts and records system calls, generating T(P).
- **Trained behavior (T(P))**: The set of all traces generated during the training runs.
- **Behavior model**: An automaton that accepts traces, capturing essential properties of the training traces.

### 2.2. Behavior Models from Previous Research

- **N-gram method**: Captures substrings of length N, focusing on event names but not arguments.
- **FSA method**: Uses successor relationships between events, annotated with program location information.
- **VtPath method**: Learns successor relationships, considering function call stacks.
- **Execution graph method**: Generalizes VtPath, inferring call, return, and intra-procedural transitions.

These methods capture all-trace properties and sequencing relationships among events, i.e., control-flow properties.

### 2.3. Dataflow Properties

Dataflow properties relate to the values of system call arguments and their flow. A natural approach is to use sets to specify possible argument values. However, combining all occurrences can lead to accuracy losses. For example, consider a program with two `open` calls:

```c
L1: fd1 = open("/etc/passwd", O_RDONLY);
... /* perform authentication */
L2: fd2 = open("/tmp/out", O_RDWR);
```

Combining all `open` calls would accept a trace opening `/etc/passwd` at L2, which is inconsistent with normal behavior. To improve accuracy, we partition system calls into subsets and capture properties separately.

### 2.4. Control-Flow Context and Dataflow Relationships

Control-flow models already distinguish between different occurrences of the same event. We use control-flow context to encode this information into labeled traces, decoupling dataflow properties from control-flow models. For example:

```plaintext
open@L1 X = "/etc/passwd" Y = "read"
open@L2 Z = "/tmp/out" W = "write"
```

Our focus is on learning all-trace dataflow properties, formulated as relationships on event arguments. These relationships are specified by referring to argument names, allowing us to capture and reason about the flow of security-sensitive data.