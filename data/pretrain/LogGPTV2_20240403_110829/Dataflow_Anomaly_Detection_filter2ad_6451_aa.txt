title:Dataflow Anomaly Detection
author:Sandeep Bhatkar and
Abhishek Chaturvedi and
R. Sekar
Dataﬂow Anomaly Detection∗
Sandeep Bhatkar
Abhishek Chaturvedi
R. Sekar
Department of Computer Science
Stony Brook University, Stony Brook, NY 11794
{sbhatkar, abchatu, sekar}@cs.sunysb.edu
Abstract
Beginning with the work of Forrest et al, several researchers
have developed intrusion detection techniques based on
modeling program behaviors in terms of system calls. A
weakness of these techniques is that they focus on control
ﬂows involving system calls, but not
their arguments.
This weakness makes them susceptible to several classes
of attacks,
including attacks on security-critical data,
race-condition and symbolic link attacks, and mimicry
attacks.
To address this weakness, we develop a new
approach for learning dataﬂow behaviors of programs.
The novelty in our approach, as compared to previous
system-call argument learning techniques, is that it learns
temporal properties involving the arguments of different
system calls, thus capturing the ﬂow of security-sensitive
data through the program. An interesting aspect of our
technique is that it can be uniformly layered on top of most
existing control-ﬂow models, and can leverage control-ﬂow
contexts to signiﬁcantly increase the precision of dataﬂows
captured by the model.
This contrasts with previous
system-call argument
learning techniques that did not
leverage control-ﬂow information, and moreover, were
focused on learning statistical properties of
individual
system call arguments. Through experiments, we show
that temporal properties enable detection of many attacks
that aren’t detected by previous approaches. Moreover,
they support formal reasoning about security assurances
that can be provided when a program follows its dataﬂow
behavior model, e.g., tar would read only ﬁles located
within a directory speciﬁed as a command-line argument.
1. Introduction
Beginning with the work of Forrest et al [15], several re-
searchers have developed intrusion detection techniques
based on modeling behaviors of programs in terms of sys-
tem call sequences [25, 21, 11, 30, 7, 14, 9, 19]. Approaches
described in [15, 32, 33, 21, 25, 7, 9] learn models from pro-
gram behaviors observed during a training phase, which is
generally assumed to be free of attacks. Other approaches
∗This research is supported in part by an ONR grant N000140110967,
NSF grants CCF-0098154 and CNS-0208877, by Computer Associates,
and the Sensor CAT, a NYSTAR Center for Advanced Technology.
use static analysis of source code [30, 19] or binary [14, 6].
A variety of representations have been used for these mod-
els, beginning with strings [32, 33], to ﬁnite-state automata
[25, 30, 21] and push-down automata [7, 14, 19, 9].
All of the above techniques have been shown to be ef-
fective against the most common types of attacks, which
involve execution of foreign code.
In addition, learning-
based techniques are effective against attacks that exercise
unusual code paths, e.g., a code path that is taken when a
maliciously crafted input is processed by vulnerable code
in a (buggy) server. However, an important weakness of the
above approaches is their singular focus on control ﬂows,
with little emphasis on data ﬂows involving system call ar-
guments. This makes them susceptible to several classes of
attacks:
• Non-control-ﬂow hijacking attacks. [5] demonstrates at-
tacks on several common servers that target security-
critical data, e.g., variables that store the userid corre-
sponding to an FTP client, the directory that contains all
allowable CGI scripts for a web server, and so on.
• Race condition attacks [2] exploit TOCTOU errors, where
the resource referenced by a name has changed between
the time of check and time of use. Race attacks do not
change the system calls made by a victim process, but
only change the interpretation of their operands.
• Mimicry attacks [31]. These are evasion attacks, where
an attacker modiﬁes an attack so that it closely mimics
program’s behavior as seen by the intrusion detection sys-
tem (IDS). Recent work [31, 10, 17] has shown that such
attacks can largely be generated in an automated way.
To detect these attacks, it is necessary to reason about sys-
tem call arguments. Research in this direction has so far
been focused on learning statistical properties of each sys-
tem call argument in isolation [18, 27].
In contrast, we
present an intrusion detection technique that is based on
learning temporal properties involving arguments of dif-
ferent system calls, thus capturing the ﬂow of security-
sensitive data through the program. Speciﬁcally, we make
the following contributions in this paper:
• We formulate a notion of dataﬂow properties of programs.
Since properties are deﬁned in terms of externally ob-
servable events (speciﬁcally, system calls), our formula-
Proceedings of the 2006 IEEE Symposium on Security and Privacy (S&P’06) 
1081-6011/06 $20.00 © 2006 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 02:47:23 UTC from IEEE Xplore.  Restrictions apply. 
tion cannot reason about actual dataﬂows that take place
in a program; instead, it hypothesizes the ﬂows that may
be present, based on relationships observed between the
parameters of different system calls. Our formulation
is decoupled from control-ﬂow models, but can leverage
control-ﬂow context to signiﬁcantly improve the precision
of dataﬂow models. Dataﬂow properties are categorized
into unary relations that involve properties of a single sys-
tem call argument, and binary relations that involve argu-
ments of two different system calls.
Binary relations turn out
to be powerful and versa-
tile. They enable models to be parameterized, e.g.,
they can capture how a system call argument is derived
from a command-line parameter or an environment vari-
able. They enable detection of several recently reported
stealthy attacks that would be undetectable without them.
Binary relations also support formal reasoning about non-
trivial security properties of programs.
• We present an efﬁcient algorithm that can be layered on
top of existing techniques for learning control-ﬂow be-
haviors of programs. This algorithm provides a uniform
way to enhance the precision of existing methods, includ-
ing the N-gram [15], FSA [25], VtPath [7] and the execu-
tion graph [9] methods.
• We present a detailed experimental evaluation of the tech-
nique, establishing the following beneﬁts:
– Attack detection. We selected several attacks that are
hard to detect using existing control-ﬂow models, and
show that they can be detected using our technique. Of
particular signiﬁcance in this regard are race attacks,
which, to the best of our knowledge, have not been
detected by previous program behavior based anomaly
detection technique. Moreover, our technique can de-
tect sophisticated attacks on security-critical data. We
argue that attack detection is based on essential charac-
teristics of the attack, and not the result of nonessential
artifacts that can be easily changed.
– Formal assurances about security. We show that the
models are precise enough that interesting dataﬂow
properties can be proved about them. This means that
we can assert that we can detect any attack that vio-
lates these properties. We believe that ours is the ﬁrst
anomaly-based intrusion detection technique that can
provide formal assurances involving substantive secu-
rity properties for large programs.
– Model precision. The precision of model in terms of
average branching factor [30] improves by a factor be-
tween 10 to 105.
– False alarms. False alarm rate for intrusion detection
increased by a factor of 2 to 4 as a result of capturing
argument information.
Paper Organization The rest of the paper is organized as
follows. In Section 2, we deﬁne data ﬂow properties that
can be incorporated into control-ﬂow behavior models. Sec-
tion 3 describes an algorithm to learn dataﬂow relationships.
Section 4 provides details on implementation. In Section 5,
we evaluate the effectiveness of our approach. Section 6
discusses related work, followed by concluding remarks in
Section 7.
2. Deﬁning Data Flow Behavior
2.1. Events, Traces and Behavior Model
We formalize program behaviors in terms of externally ob-
servable events generated by a program. Since our interest
is mainly conﬁned to system call events in the rest of this
paper, we will use the terms “event” and “system call” in-
terchangeably. We begin with a series of deﬁnitions:
• An execution trace (or simply, a trace) for a program P ,
denoted T (P ), is the sequence of all the system calls ex-
ecuted by P during its execution. A trace typically in-
cludes information about system call arguments, and/or
information about the program’s runtime environment,
e.g., the program location from where a system call is
made (“PC” information).
• A system call tracer (or simply, a tracer) is responsible for
intercepting and recording system calls made by P , thus
generating T (P ).
• The trained behavior of P is the set T (P ) of all traces
generated by P during its training runs.
• A behavior model for P is an automaton that accepts
traces.
(Strictly speaking, a model accepts preﬁxes of
traces, but for simplicity, we will say that the model ac-
cepts T .)
Given a training trace set T , a model for these traces cap-
tures some of the essential properties of these traces. The
properties captured will vary across different methods, as
discussed next.
2.2. Behavior Models from Previous Research
• N-gram method: The property captured by this method
is given by the set of all the substrings of T of length
N. Only event names are captured in the model, but not
the arguments. The model will accept another trace T (cid:2),
provided all of its substrings of length N are found in the
training set T .
• FSA method: For the FSA method, events are anno-
tated with program location information. An event e
invoked from location L is denoted e@L. The FSA
method captures successor relationship between events
within each trace in T . A new trace T (cid:2) will be accepted
by the model if and only if every successive event pair
(e1@P C1, e2@P C2) in T (cid:2) is also present in some trace
Proceedings of the 2006 IEEE Symposium on Security and Privacy (S&P’06) 
1081-6011/06 $20.00 © 2006 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 02:47:23 UTC from IEEE Xplore.  Restrictions apply. 
in T . In addition, the ﬁrst (last) event in T (cid:2) must appear
as the ﬁrst (last) event in some trace in T .
• VtPath method: This method also learns successor rela-
tionships similar to the FSA method, but it takes into ac-
count all of the function calls that were active at the time
of invocation of the system call, as opposed to just the
location of a system call. This call stack information is
compactly summarized using a VtPath, which captures
the difference between the call stacks observed at the time
of occurrence of e1 and e2.
• Execution graph method: This method captures a fur-
ther generalization of the relationship learnt by the VtPath
method. In particular, suppose that there is a pair (e1, S1)
and (e2, S2) of events in a trace T ∈ T , where S1, S2 de-
note the return addresses on the stack at the point of invo-
cation of these events. From this information, this method
infers a sequence of calls, returns, and intra-procedural
transitions that must have occurred in the program P in
order to generate this sequence of events and call-stack
information. Now, any trace T (cid:2) whose event pairs can
be constructed by composing the program transitions ob-
served from all event pairs in T ∈ T are accepted by the
model.
From the above description, we conclude that the above four
methods capture:
(a) all-trace properties, i.e., properties that hold for every
execution trace, and
(b) sequencing relationships among events, i.e., control-
ﬂow properties of programs.
Below, we describe how these methods can be extended to
incorporate dataﬂow properties.
2.3. Dataﬂow Properties
By dataﬂow properties, we still refer to properties of execu-
tion traces, but these properties relate to the values of event
argument data and their ﬂow from one system call to a sub-
sequent one. A natural approach for capturing properties of
event arguments is using sets. For instance, we can use a set
to specify all possible ﬁle name arguments to open system
calls in any execution trace for a program P . Note that this
approach combines information about all open system calls
that appeared in any trace. Such a combination can lead to
signiﬁcant (and needless) losses in accuracy. To illustrate
this, consider the following example program:
L1: fd1 = open("/etc/passwd", O_RDONLY);
... /* perform authentication */
L2: fd2 = open("/tmp/out", O_RDWR);
If we combined the information about all open operations
together in the dataﬂow model, then a trace that corresponds
to opening /etc/passwd ﬁle at line L2 will be accepted,
while it is clearly inconsistent with normal program behav-
ior. To improve accuracy, it is hence desirable to partition
the open system calls into subsets, and capture properties
of each subset separately. The question then is how to do
this partitioning.
Making control-ﬂow context available for
learning
dataﬂow properties. We make the important observation
that control-ﬂow models already distinguish among differ-
ent occurrences of the same event in a trace. For instance, in
the above example, the FSA model distinguishes between
the two open system calls based on the PC value. More
generally, the approaches described above use some sort
of an automaton model:
the N-gram model uses string-
matching automata to recognize N-grams, while the FSA
approach uses a ﬁnite-state automaton. The VtPath model
can be thought of as recognizing VtPaths, which are strings
over program locations. The execution graph method uses
a push-down automaton, and hence its control state, possi-
bly with some (bounded) information from the stack, can be
used to distinguish event occurrences.
We use the term control-ﬂow context to refer to the
event context information that can be provided by a control-
ﬂow model. We use labeled traces to encode control-ﬂow
context into traces. This approach allows us to decouple
dataﬂow properties from control-ﬂow models.
Control-context is encoded in traces by giving names for
event arguments: if the same event appears in two places
in a labeled trace, and these two instances correspond to
the same control-ﬂow context, then (and only then) their
arguments should have the same name. An example labeled
trace is:
open@L1 X = "/etc/passwd" Y = "read"
open@L2 Z = "/tmp/out"
W = "write"
2.4. Possible Dataﬂow Relationships
Similar to control-ﬂow models, our focus is on learning all-
trace dataﬂow properties. These properties will be formu-
lated as relationships on event arguments. It is natural to
specify these relationships by referring to argument names