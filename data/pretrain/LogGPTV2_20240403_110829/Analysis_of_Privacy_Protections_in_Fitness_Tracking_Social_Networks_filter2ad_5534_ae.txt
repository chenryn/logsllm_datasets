consider in this paper. Existing work on mobility-aware
location obfuscation technique [29] replaces real loca-
tion traces with plausible fake location traces using hu-
man mobility model. However, this technique cannot be
used directly in the context of ﬁtness tracking apps as
users still want to share a major portion of a route while
preserving a certain portion of route (e.g. home).
In some instances, prior work has demonstrated appli-
cable techniques for Preserving endpoint privacy while
sharing route data. Duckham and Kulik [34] present
location obfuscation techniques for protecting user pri-
vacy by adding dummy points in measurements with the
same probability as the real user position. Ardagna et
al. [27] demonstrate how an EPZ can be used to obfus-
cate users locations in order to preserve privacy, although
possible weaknesses in this method are raised in [52].
In this work, we have demonstrated proof-of-concept at-
tacks that can violate user privacy even in the presence
of these obfuscations.
USENIX Association
27th USENIX Security Symposium    509
8.2 Social Network Privacy
The social network aspect of ﬁtness tracking services al-
lows users to “follow” each other, giving them access to
additional data about each other. This can lead to so-
cial engineering [39, 5] and even automated social bot-
net attacks as in [28, 31], where user information such
as location is automatically extracted. Strava provides a
privacy option to require user approval for new followers,
we show that when this option is not enabled such attacks
are also possible on Strava and other ﬁtness apps. A va-
riety of privacy vulnerabilities have been identiﬁed on
other social network platforms, ranging from server-side
surveillance [33], third party application spying [54], and
proﬁling of personality types [51]. This study conﬁrms
that a number of these concerns are also present in ﬁtness
tracking social networks.
8.3 Mobile Privacy
The functionality of ﬁtness tracking social networks
is predicated on the ubiquity of modern smart phones
equipped with GPS and other private information (e.g.,
sensor readings). Lessons learned in the security litera-
ture regarding mobile application permissions could also
be applied in the ﬁtness space to improve user privacy.
Enck et al. demonstrate a method of detecting applica-
tion leakage of sensor information on the Android plat-
form through taint analysis [36], and subsequently con-
ducted a semi-automated analysis of a corpus of 1,100
applications in search of security and privacy concerns
[37]. Felt et al. conduct a survey of application privileges
and discovered that one-third of Android apps requested
privileges that they did not need [38]. Our work suggests
that overprivilege may also be a concern for third party
applications that interoperate with ﬁtness apps.
9 Ethics and Disclosure
Given the potential real-world privacy implications of
this study, we have taken a variety of steps to ensure
our research was conducted responsibly. We have con-
sulted our Institutional Review Board (IRB) to conﬁrm
that our analysis of social media posts does not meet
the deﬁnition of human subjects research (as deﬁned in
45CFR46(d)(f) or at 21CFR56.102(c)(e)) and thus does
not require IRB approval. The rationale provided was
that analysis of public datasets such as social media posts
does not constitute human subjects research. We note
that our use of social media posts is consistent with prior
research on user privacy [42, 56, 45, 53, 48], particularly
studies that have evaluated location privacy and user dis-
covery [47, 43, 49].
We have disclosed our ﬁndings to Strava, Garmin Con-
nect, and Map My Tracks. As of the date of publication,
all three companies have acknowledged the vulnerability
and have incorporated one or more of our recommended
countermeasures into their production systems. Strava
has adopted a spatial cloaking function that is invoked
upon the creation of every new user-speciﬁed EPZ, and
provides the user with an option of re-randomizing the
EPZ if they do not like its placement. Additionally,
Strava has taken steps to prevent the bulk collection of
their public user activities, including aggressive rate lim-
iting of the strava.com/stream/ API, least privilege
restrictions on returned API ﬁelds based on the client’s
authorization state, and IP whitelisting of interoperable
social network’s servers to prevent unauthorized use of
other APIs. Garmin Connect has introduced a random-
ization step similar to our EPZ intersection fuzzing tech-
nique – each time a new activity crosses an EPZ, the
point at which the route is truncated is perturbed accord-
ing to a random distribution. Additionally, Garmin Con-
nect has added an optional user-driven obfuscation when
a user attempts to create an EPZ, they may now drag the
EPZ center away from their house, and moreover a mes-
sage has been added to encourage users to set up mul-
tiple overlapping privacy zones. Map My Tracks also
reported that they incorporated spatial cloaking into their
new EPZ feature, but declined to discuss the details of
their solution.
10 Conclusion
As ﬁtness tracking services have grown in popularity,
the online sharing of ﬁtness data has created concerns
for personal privacy and even national security. Un-
derstanding the effectiveness of privacy protections in
such a system is paramount.
In this paper, we have
conducted a deep analysis of the privacy properties of
Strava, an exemplar ﬁtness tracking app. While we iden-
tiﬁed signiﬁcant demand for privacy protections by users
of these services, we have also demonstrated current
mechanisms are inadequate – we found that the homes
privacy-conscious athletes are consistently identiﬁable
by attackers, and in fact that the only truly safe athletes
are those that use the service infrequently. Through the
insights gained in this study, we were able to develop
and empirically demonstrate the efﬁcacy of several novel
privacy mechanisms that have been put into practice by
major ﬁtness tracking services. It is our hope that this
work spurs greater interest in the efﬁcacy and usability
of privacy features in ﬁtness tracking apps.
510    27th USENIX Security Symposium
USENIX Association
Acknowledgments
We would like to thank Adam Aviv for his valuable com-
ments on an early draft of this paper. We also thank the
anonymous reviewers for their helpful feedback. This
work was supported in part by NSF CNS grants 16-
57534 and 17-50024. The views expressed are those of
the authors only.
References
[1] mapmyride. http://www.mapmyride.com/.
[2] Data Driven:
Strava Users By The Numbers.
http:
//www.triathlete.com/2016/04/features/data-driven-
strav 130658.
[3] Fitbit. https://www.ﬁtbit.com/.
[4] How Strava Is Changing the Way We Ride.
https:
//www.outsideonline.com/1912501/how-strava-changing-
way-we-ride.
[5] Strava, popular with cyclists and runners, wants to sell its data to
urban planners. http://blogs.wsj.com/digits/2014/05/07/
strava-popular-with-cyclists-and-runners-wants-to-sell-its-
data-to-urban-planners/.
[6] Ride mapping sites:
The bike thief’s new best
friend?
http://www.cyclingweekly.co.uk/news/comment/ride-
mapping-sites-the-bike-thiefs-new-best-friend-44149.
[7] Nike+. http://www.nike.com/us/en us/c/nike-plus.
[8] Mining the Strava data. http://olivernash.org/2014/05/25/
mining-the-strava-data/.
[9] Data Mining Strava.
mining-strava/.
[10] strava-data-mining.
data-mining.
http://webmining.olariu.org/data-
https://github.com/wmycroft/strava-
[11] King of the Mountain: A Rapid Ethnography of Strava Cycling.
https://uclic.ucl.ac.uk/content/2-study/4-current-taught-
course/1-distinction-projects/4-2013/williams-2012.pdf.
[12] Garmin Connect. https://connect.garmin.com/.
[13] Garmin Adds Privacy Zones for Public Activities.
http:
//myitforum.com/myitforumwp/2017/04/12/garmin-
adds-privacy-zones-for-public-activities/.
[14] Strava Global Heatmap - Strava Labs. http://labs.strava.com/
heatmap/.
[15] Privacy Zones.
https://support.strava.com/hc/en-us/
articles/115000173384.
[16] Hide
sensitive
locations with privacy zones.
http:
//www.mapmytracks.com/blog/entry/hide-sensitive-
locations-with-privacy-zones.
[17] Strava and stolen bikes. https://www.bikehub.co.za/forum/
topic/166972-strava-and-stolen-bikes/.
[18] Map My Tracks. http://www.mapmytracks.com/.
[19] What is Strava Metro? https://support.strava.com/hc/en-
us/articles/216918877-What-is-Strava-Metro-?
[20] endomondo. https://www.endomondo.com/.
[21] RunKeeper. https://runkeeper.com/.
[22] Runtastic: Running, Cycling and Fitness GPS Tracker. https:
//www.runtastic.com/.
[23] Strava — Run and Cycling Tracking on the Social Network for
Athletes. https://www.strava.com/.
[24] U.S. soldiers are revealing sensitive and dangerous information
by jogging. http://wapo.st/2BDFrA4.
through
denanonymization
[25] Advanced
strava.
http:
//steveloughran.blogspot.co.uk/2018/01/advanced-
denanonymization-through-strava.html.
[26] ANDR ´ES, M. E., BORDENABE, N. E., CHATZIKOKOLAKIS, K.,
AND PALAMIDESSI, C. Geo-indistinguishability: Differential
privacy for location-based systems. In CCS (2013), ACM.
[27] ARDAGNA, C. A., CREMONINI, M., DAMIANI, E., DI VIMER-
CATI, S. D. C., AND SAMARATI, P. Location privacy protec-
tion through obfuscation-based techniques. In IFIP Annual Con-
ference on Data and Applications Security and Privacy (2007),
Springer.
[28] BILGE, L., STRUFE, T., BALZAROTTI, D., AND KIRDA, E. All
your contacts are belong to us: automated identity theft attacks
on social networks. In WWW (2009), ACM.
[29] BINDSCHAEDLER, V., AND SHOKRI, R. Synthesizing plausi-
In IEEE Symposium on
ble privacy-preserving location traces.
Security and Privacy (2016), IEEE.
[30] BORDENABE, N. E., CHATZIKOKOLAKIS, K.,
AND
Optimal geo-indistinguishable mecha-
PALAMIDESSI, C.
nisms for location privacy. In CCS (2014), ACM.
[31] BOSHMAF, Y., MUSLUKHOV, I., BEZNOSOV, K., AND RI-
PEANU, M. The socialbot network: when bots socialize for fame
and money. In Proceedings of the 27th annual computer security
applications conference (2011), ACM.
[32] CHERNOV, N., AND LESORT, C. Least squares ﬁtting of circles.
Journal of Mathematical Imaging and Vision 23, 3 (Nov 2005),
239–252.
[33] CRISTOFARO, E. D., SORIENTE, C., TSUDIK, G., AND
WILLIAMS, A. Hummingbird: Privacy at the time of twitter.
In IEEE Symposium on Security and Privacy (2012).
[34] DUCKHAM, M., AND KULIK, L. A formal model of obfuscation
and negotiation for location privacy. In International Conference
on Pervasive Computing (2005), Springer, pp. 152–170.
[35] DWORK, C. Differential privacy: A survey of results.
In In-
ternational Conference on Theory and Applications of Models of
Computation (2008), Springer, pp. 1–19.
[36] ENCK, W., GILBERT, P., CHUN, B.-G., COX, L. P., JUNG,
J., MCDANIEL, P., AND SHETH, A. N.
TaintDroid: An
Information-ﬂow Tracking System for Realtime Privacy Moni-
toring on Smartphones. In OSDI (Oct. 2010).
[37] ENCK, W., OCTEAU, D., MCDANIEL, P., AND CHAUDHURI,
S. A Study of Android Application Security. In Proceedings of
the 20th USENIX Security Symposium (2011).
[38] FELT, A. P., CHIN, E., HANNA, S., SONG, D., AND WAGNER,
D. Android Permissions Demystiﬁed. In CCS (2011), ACM.
[39] FR ¨OHLICH, S., SPRINGER, T., DINTER, S., PAPE, S., SCHILL,
A., AND KRIMMLING, J. Bikenow: a pervasive application for
crowdsourcing bicycle trafﬁc data. In Proceedings of the 2016
ACM International Joint Conference on Pervasive and Ubiqui-
tous Computing: Adjunct (2016), ACM, pp. 1408–1417.
[40] GANDER, W., GOLUB, G. H., AND STREBEL, R. Least-squares
ﬁtting of circles and ellipses. BIT Numerical Mathematics 34, 4
(1994), 558–578.
[41] GRUTESER, M., AND GRUNWALD, D. Anonymous usage of
location-based services through spatial and temporal cloaking. In
Proceedings of the 1st international conference on Mobile sys-
tems, applications and services (2003), ACM, pp. 31–42.
USENIX Association
27th USENIX Security Symposium    511
[42] HU, H., AHN, G.-J., AND JORGENSEN, J. Detecting and re-
solving privacy conﬂicts for collaborative data sharing in online
social networks. In ACSAC (2011), ACM.
[43] LI, M., ZHU, H., GAO, Z., CHEN, S., YU, L., HU, S., AND
REN, K. All your location are belong to us: Breaking mobile
In Pro-
social networks for automated user location tracking.
ceedings of the 15th ACM international symposium on Mobile ad
hoc networking and computing (2014), ACM, pp. 43–52.
[44] LUPTON, D. You are Your Data: Self-Tracking Practices and
Concepts of Data. Springer Fachmedien Wiesbaden, Wiesbaden,
2016, pp. 61–79.
[45] MAO, H., SHUAI, X., AND KAPADIA, A. Loose tweets: An
analysis of privacy leaks on twitter. In Proceedings of the 10th
Annual ACM Workshop on Privacy in the Electronic Society
(2011), WPES ’11, ACM.
[46] MCDONOUGH,
J.
Strava has Data
that Most
In-
to Acquire.
telligence Entities Would Literally Kill
http://news.theceomagazine.com/technology/strava-
data-intelligence-entities-literally-kill-acquire/.
[47] POLAKIS, I., ARGYROS, G., PETSIOS, T., SIVAKORN, S., AND
KEROMYTIS, A. D. Where’s wally?: Precise user discovery at-
tacks in location proximity services. In CCS (2015), ACM.
[48] PUTTASWAMY, K. P., AND ZHAO, B. Y. Preserving privacy
in location-based mobile social applications. In Proceedings of
the Eleventh Workshop on Mobile Computing Systems & Appli-
cations (2010), ACM, pp. 1–6.
[49] QIN, G., PATSAKIS, C., AND BOUROCHE, M. Playing hide
and seek with mobile dating applications. In IFIP International
Information Security Conference (2014), Springer, pp. 185–196.
[50] QUARLES, J. A Letter to the Strava Community. https://blog.
strava.com/press/a-letter-to-the-strava-community/.
[51] QUERCIA, D., KOSINSKI, M., STILLWELL, D., AND
CROWCROFT, J. Our twitter proﬁles, our selves: Predicting per-
In 2011 IEEE Third International Con-
sonality with twitter.
ference on Privacy, Security, Risk and Trust and 2011 IEEE
Third International Conference on Social Computing (Oct 2011),
pp. 180–185.
[52] SRIVATSA, M., AND HICKS, M. Deanonymizing mobility
traces: Using social network as a side-channel. In CCS (2012),
ACM.
[53] VICENTE, C. R., FRENI, D., BETTINI, C., AND JENSEN, C. S.
Location-related privacy in geo-social networks. IEEE Internet
Computing 15, 3 (May 2011), 20–27.
[54] WANG, N., XU, H., AND GROSSKLAGS, J. Third-party apps
In Proceed-
on facebook: Privacy and the illusion of control.
ings of the 5th ACM Symposium on Computer Human Interaction
for Management of Information Technology (2011), CHIMIT ’11,
ACM.
[55] YU, L., LIU, L., AND PU, C. Dynamic differential location
privacy with personalized error bounds. In NDSS (2017).
[56] ZHANG, C., SUN, J., ZHU, X., AND FANG, Y. Privacy and
security for online social networks: challenges and opportunities.
IEEE Network 24, 4 (July 2010), 13–18.
[57] ZHU, J. Conversion of earth-centered earth-ﬁxed coordinates to
geodetic coordinates. IEEE Transactions on Aerospace and Elec-
tronic Systems 30, 3 (1994), 957–961.
512    27th USENIX Security Symposium
USENIX Association