site scripting (XSS) vulnerabilities [41]. More than 68% of the sites
using WordPress are running vulnerable versions of WordPress.
Checking the distribution of WordPress major versions we ob-
served from Sep. 30, 2013 to Dec. 31, 2013, WordPress 3.5.* (6.5 K
on average) and 3.6.* (5 K on average) are used by most of the
identiﬁed WordPress-using webpages. We saw that one month af-
ter WordPress 3.7.* (released on Oct. 14, 2013) and 3.8.* (released
on Dec. 12, 2013) were released, around 3,500 webpages and 2,500
webpages on average are using the new WordPress version, respec-
tively, but 3.5.* and 3.6.* are still the most popular WordPress re-
leases.
Third-party trackers. Many third party trackers work by having
site owners embed a speciﬁc piece of JavaScript, called tracking
code, into their webpage. We can determine if a website uses a
given tracker by searching for the tracker’s corresponding track-
ing code in the page’s HTML contents. This method will miss
trackers loaded dynamically or in the case that the code is mod-
iﬁed by the site operator. Tracking code always contains a spe-
cial URL which can serve as a ﬁngerprint. Using MySQL regular
expressions to search these ﬁngerprints in the WhoWas database
provides a lower bound on the number of websites using a given
tracker. As a concrete example, for the tracker associated with
scorecardresearch.com, we construct a query string
‘‘”
which means search for ‘‘http://b.scorecardresearch.com’’ in the
JavaScript section of a page. The URL is the link to the tracker’s
service extracted from its tracking code.
We search for use of the trackers previously identiﬁed by Mayer
et al. [42]. Table 20 shows the Top 10 trackers used by websites in
EC2 and Azure on Dec. 31, 2013 (the last round of our measure-
ments). In both clouds, Google-Analytics, Facebook and Twitter
sharing widgets, and doubleclick are the most widely used third-
party trackers.
The Google Analytics service is the most popular tracker being
used in EC2-hosted and Azure-hosted websites. In EC2, we can
see on average 55 K clusters use this service. Using the service
requires a user to apply for a Google Analytics ID and put that
ID in her tracking code. We extract a total of 71,363 unique IDs
from the webpages over 275,513 unique IPs in EC2. These IDs
belong to 106,871 top-level clusters and 111,696 webpage clusters.
In Azure, we collect 6,254 IDs from 11,840 IPs. We also ﬁnd 166
IDs appeared in both clouds. According to Google [43], a Google
Analytics ID can be split into two parts: user account and proﬁle
identiﬁer. For example, in an ID “UA-0000-*”, the “0000” is an ID
for the user. The user might use “UA-0000-01”, “UA-0000-02”,
and so on with different websites or applications. By checking IDs
we can quickly estimate a lower bound on the number of unique
websites in the two clouds, as well as the number of websites that
belong to the same user. In EC2, the collected IDs belonging to
64,716 user accounts. Of these accounts, 93.5% use only one pro-
ﬁle, 4.8% have two proﬁles, 1.6% have 3–11 proﬁles, and the rest
(0.1%) use 14–35 proﬁles. In Azure, the IDs belong to 5,794 user
accounts, 94.4% have one proﬁle and 3.9% have two. An account
in Azure is at most associated with 13 proﬁles.
Websites may use multiple trackers. We observed 77% of
tracker-using webpages only use a single tracker, 16% use two
trackers and 6% use three trackers in EC2.
In Azure, 81% of
tracker-using webpages use a single tracker, 15% use two trackers
and 3.8% use three trackers.
EC2
#IP #Clust. Tracker
Azure
Tracker
google-analytics
facebook
twitter
doubleclick
quantserve
scorecardresearch
imrworldwide
serving-sys
atdmt
yieldmanager
Total
8,520 twitter
2,189 doubleclick
127,604 55,406 google-analytics
24,130 13,462 facebook
14,706
5,342
2,243
1,509
474
383
275
188
742 atdmt
475 scorecardresearch
95 quantserve
136 serving-sys
69 adnxs
54 imrworldwide
176,852 81,147 Total
#IP #Clust.
5,148
1,253
696
178
31
29
25
7
6
4
7,376
6,839
1,615
1,115
316
50
40
35
11
10
7
10,037
Table 20: Top 10 third party trackers in EC2 and Azure (on Dec. 31,
2013)
9. CONCLUSION
A growing number of web services are being hosted on public
IaaS clouds such as EC2 and Azure. These cloud providers offer
a variety of features, such as elastic scale in/out and pay-as-you-
go payment models. Understanding how different tenants exercise
these features can inform a variety of work on workload modeling,
data center compute/network provisioning and placement, as well
as on securing tenants’ deployments. Unfortunately, however, very
little is known about prevalent usage patterns and their evolution
over time.
To shed light on this, we designed a measurement platform called
WhoWas. Using carefully designed active probes, WhoWas en-
ables direct measurements of what web services are running on
cloud-associated IP addresses. This data can be used to perform
lookups on particular IP addresses or web services, and retrieve a
history of their activities over the period of measurement.
This paper presented the design of WhoWas and reported on us-
ing WhoWas to perform a ﬁrst-of-its-kind measurement studies of
usage patterns over time in EC2 and Azure, efﬁcacy of blacklists
for malicious activities in clouds, and adoption of new Web soft-
ware by cloud customers.
Future work may include expanding WhoWas to analyze non-
web services, evaluate improved clustering heuristics and pro-
vide more rigorous estimates of clustering error, provide deeper
crawling of websites by following links in HTML, and correlate
WhoWas data with other sources such as passive or active DNS in-
terrogation. To facilitate such work, we have made the software
underlying WhoWas public and open source [3].
Acknowledgements
The authors would like to especially thank the system administra-
tors at the University of Wisconsin who helped ensure the experi-
ments went smoothly. This work was supported in part by the Na-
tional Science Foundation under grants CNS-1253870 and CNS-
1330308. This research is also partially supported by the Spanish
Government through Grant TIN2012-39391-C04-01 and a Juan de
la Cierva Fellowship for Juan Caballero. Any opinions, ﬁndings,
and conclusions or recommendations expressed in this material are
those of the authors and do not necessarily reﬂect the views of the
sponsors.
10. REFERENCES
[1] Alexa. Alexa. http://alexa.com/, 2014.
[2] Keqiang He, Alexis Fisher, Liang Wang, Aaron Gember, Aditya
Akella, and Thomas Ristenpart. Next stop, the cloud: understanding
112modern web service deployment in EC2 and Azure. In IMC 2013,
pages 177–190. ACM, 2013.
[3] Whowas project. http://www.cloudwhowas.org/.
[4] Amazon. Amazon EC2 instance IP addressing. http:
//docs.aws.amazon.com/AWSEC2/latest/UserGuide/
using-instance-addressing.html#MultipleIP, 2013.
[5] Farsight Security. Passive DNS data.
https://www.dnsdb.info/, 2014.
[6] Wayback machine. http://archive.org/web/.
[7] Douglas E. Comer and John C. Lin. Probing TCP implementations.
In USENIX Summer Technical Conference, Boston, MA, June 1994.
[8] Niels Provos and Peter Honeyman. Scanssh - scanning the internet
for ssh servers. Technical Report CITI TR 01-13, University of
Michigan, October 2001.
[9] Darcy Benoit and André Trudel. World’s ﬁrst web census.
International Journal of Web Information System, 3, 2007.
[10] David Dagon, Chris Lee, Wenke Lee, and Niels Provos. Corrupted
Dns resolution paths: The rise of a malicious resolution authority. In
Network and Distributed System Security Symposium, 2008.
[11] Nadia Heninger, Zagir Durumeric, Eric Wustrow, and J.Alex
Halderman. Mining your ps and qs: Detection of widespread weak
keys in network devices. In USENIX Security Symposium, 2012.
[12] Antonio Nappa, Zhaoyan Xu, M. Zubair Raﬁque, Juan Caballero,
and Guofei Gu. Cyberprobe: Towards internet-scale active detection
of malicious servers. In Network and Distributed System Security
Symposium, 2014.
[13] Zhaoyan Xu, Antonio Nappa, Robert Baykov, Guangliang Yang,
Juan Caballero, and Guofei Gu. AutoProbe: Towards Automatic
Active Malicious Server Probing Using Dynamic Binary Analysis. In
Proceedings of the 21st ACM Conference on Computer and
Communication Security, Scottsdale, AZ, November 2014.
[14] Zhaoyan Xu, Lingfen Chen, Guofei Gu, and Christopher Kruegel.
Peerpress: Utilizing enemies’ p2p strength against them. In ACM
Conference on Computer and Communications Security, 2012.
[15] Stuart Staniford, Vern Paxson, and Nicholas Weaver. How to 0wn the
internet in your spare time. In USENIX Security Symposium, San
Francisco, CA, August 2002.
[16] Luigi Rizzo. Netmap: A novel framework for fast packet i/o. In
usenixatc, 2012.
[17] Zakir Durumeric, Eric Wustrow, and J. Alex Halderman. ZMap: Fast
Internet-wide scanning and its security applications. In Proceedings
of the 22nd USENIX Security Symposium, August 2013.
[18] D. Leonard and D. Loguinov. Demystifying service discovery:
Implementing an internet-wide scanner. In Internet Measurement
Conference. ACM, 2010.
[19] M. Allman, V. Paxson, and J. Terrell. A brief history of scanning. In
Internet Measurement Conference. ACM, 2007.
[20] Marco Balduzzi, Jonas Zaddach, Davide Balzarotti, Engin Kirda, and
Sergio Loureiro. A security analysis of amazon’s elastic compute
cloud service. In Proceedings of the 27th Annual ACM Symposium
on Applied Computing, pages 1427–1434. ACM, 2012.
[21] Davide Canali, Davide Balzarotti, and Aurelien Francillon. The Role
of Web Hosting Providers in Detecting Compromised Websites. In
Proceedings of the 22nd World Wide Web Conference, 2013.
[22] Antonio Nappa, M. Zubair Raﬁque, and Juan Caballero. Driving in
the cloud: An analysis of drive-by download operations and abuse
reporting. In SIG SIDAR Conference on Detection of Intrusions and
Malware & Vulnerability Assessment, 2013.
[23] Amazon. Amazon EC2 public IP ranges. https:
//forums.aws.amazon.com/ann.jspa?annID=1701,
2013.
[24] Microsoft. Azure datacenter IP ranges.
http://msdn.microsoft.com/en-us/library/azure/
dn175718.aspx, 2013.
[25] Kenneth Reitz. Requests: Http for humans.
http://docs.python-requests.org/en/latest/,
2014.
[26] Moses S Charikar. Similarity estimation techniques from rounding
algorithms. In Proceedings of the thiry-fourth annual ACM
symposium on Theory of computing, pages 380–388. ACM, 2002.
[27] Monika Henzinger. Finding near-duplicate web pages: a large-scale
evaluation of algorithms. In Proceedings of the 29th annual
international ACM SIGIR conference on Research and development
in information retrieval, pages 284–291. ACM, 2006.
[28] Mat Kelcey. The simhash algorithm.
http://matpalm.com/resemblance/simhash/, 2013.
[29] Robert Tibshirani, Guenther Walther, and Trevor Hastie. Estimating
the number of clusters in a data set via the gap statistic. Journal of
the Royal Statistical Society: Series B (Statistical Methodology),
63(2):411–423, 2001.
[30] Gurmeet Singh Manku, Arvind Jain, and Anish Das Sarma.
Detecting near-duplicates for web crawling. In WWW 2007, pages
141–150. ACM, 2007.
[31] Thomas Ristenpart, Eran Tromer, Hovav Shacham, and Stefan
Savage. Hey, you, get off of my cloud: exploring information leakage
in third-party compute clouds. In CCS 2009, pages 199–212. ACM,
2009.
[32] Amazon. Public IP addresses and external DNS hostnames.
http://docs.aws.amazon.com/AWSEC2/latest/
UserGuide/using-instance-addressing.html, 2014.
[33] Huan Liu. Amazon data center size.
http://huanliu.wordpress.com/2012/03/13/
amazon-data-center-size/, 2012.
[34] Robot exclusion.
http://www.robotstxt.org/faq/prevent.html.
[35] Anonymization tools taxonomy. http://www.caida.org/
tools/taxonomy/anonymization.xml.
[36] Eamonn Keogh, Kaushik Chakrabarti, Michael Pazzani, and Sharad
Mehrotra. Dimensionality reduction for fast similarity search in large
time series databases. Knowledge and information Systems,
3(3):263–286, 2001.
[37] Zhou Li, Sumayah Alrwais, Yinglian Xie, Fang Yu, and XiaoFeng
Wang. Finding the linchpins of the dark web: a study on
topologically dedicated hosts on malicious web infrastructures. In
S&P 2013, pages 112–126. IEEE, 2013.
[38] Fraser Howard. Blackhole exploit kit analysis.
http://nakedsecurity.sophos.com/
exploring-the-blackhole-exploit-kit/, 2012.
[39] tr.im. tr.im. http://tr.im, 2013.
[40] SERT. Sert quarterly threat intelligence report q4 2013. Technical
report, Solutionary Security Engineering Research Team, 2013.
[41] CVE. Cve-2013-4338. http://web.nvd.nist.gov/view/
vuln/detail?vulnId=CVE-2013-4338, 2013.
[42] Jonathan R Mayer and John C Mitchell. Third-party web tracking:
Policy and technology. In Security and Privacy (SP), 2012 IEEE
Symposium on, pages 413–427. IEEE, 2012.
[43] Google. Accounts and views.
https://developers.google.com/analytics/
resources/concepts/gaConceptsAccounts, 2013.
113