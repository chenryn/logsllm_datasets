In the discussions that follow, we will focus on apps that access
the fingerprint reader (which is commercially named the “Imprint”
sensor) through the Java API provided by Google. Unless otherwise
specified, we will consider the implementation of this API running
in Android version 7 on Google’s devices. In particular, for our
experiments we used a Google’s Nexus 5X.
Also, we will follow Google’s [23] and OWASP [35] guidelines
and consider that the best way to use the fingerprint reader is in
conjunction with some cryptographic operations. In particular,
instead of just recognizing the legitimate user has touched the
fingerprint sensor, an app should use this fingerprint reading
to unlock a cryptographic key protected by the TEE. In other
words, by utilizing both the keymaster and the fingerprint in
the TrustZone, this method can guarantee that even an attacker
with root privilege cannot misuse the cryptographic key without
presenting the right fingerprint. As we will see in Section V, the
latter method is significantly stronger.
We will now briefly provide the major steps an app has to
perform to interact with the fingerprint sensor and determine
whether a legitimate user touched it. For clarity, we will omit
unnecessary details of the complex Android cryptographic API,
and we suggest interested readers to read the official documentation
for a more detailed explanation [28], [26].
Generate a cryptographic key: An app can generate a
cryptographic key or a public/private key pair by using the method
initialize of the class KeyGenerator or KeyPairGen-
erator. Developers must specify properties of the generated key
(e.g., the algorithm used) by passing a KeyGenParameterSpec
object to the mentioned initialize method.
Among the various aspects a developer can control about a
generated key, the most important one in this context is triggered
by calling the setUserAuthenticationRequired method
(passing true for its required parameter). By calling this
method, a developer can ensure that the generated key is usable
(i.e., it is “unlocked”) only after a legitimate user has touched
the fingerprint reader sensor. In case a pair of keys is generated,
calling this method will only constraint the usage of the private
key, leaving the public one freely accessible by the app.
Unlock the key by authenticating the user: By calling
the authenticate method, an app activates the fingerprint
reader sensor. Two parameters of this method are important: the
cryptographic key that is unlocked if a legitimate user touches the
sensor and a list of callback functions, called after the sensor is
touched.
Override the fingerprint callbacks: When a user touches
the sensor, specific callback functions are called. In particular,
the method onAuthenticationSucceeded is called when a
3
legitimate user touches the sensor, whereas other callback functions
are called in case of error conditions (e.g., a non-legitimate user
touched the sensor).
Use the unlocked key: After the onAuthenticationSuc-
ceeded method is called, an app should use the now unlocked
key. For authentication purposes, Google’s guidelines suggest the
use of a previously generated private key to sign a server-provided
authentication token and then send this authentication token to the
app’s remote backend.
It is worth mentioning two properties of the generated keys.
First, the Android framework ensures that only the app generating
a key can use it. Second, in modern devices, private keys are stored
within the TEE (an app can verify if in a specific device keys
are stored within the TEE by calling the isInsideSecurity-
Hardware API) and cannot be exported (not even by the app
generating them and not even after a legitimate user has touched
the fingerprint sensor). In other words, “unlocking” a key does
not allow an app to read its “raw” value, but only to use it to
encrypt, decrypt, or sign data. If the key is stored in the TEE, these
operations are guaranteed to happen within the TEE.
D. Two-Factor Authentication Schemes
To overcome security and usability limitations of classical
username and password authentication, many service providers
suggest or mandate the usage of an additional “second factor”
during authentication. One common solution is to use a One-Time
Passcode (OTP). However, OTPs are still vulnerable to phishing
and man-in-the-middle attacks [15], [43] and have serious usability
drawbacks, since they require the user to somehow receive the OTP
code and insert it into the authentication interface. Furthermore,
protocols based on OTPs rely on the confidentiality of the
communication channel of the OTP, which is often not guaranteed.
For instance, text messages are a common communication channel
used to send OTPs to smartphones. However, the insecurity of this
channel has been shown in many occasions [46], [22].
Secure authentication schemes using challenge/response offer
better security and usability. In particular, the current state-of-the-
art is constituted of the Security Keys formalized in the Universal
Second Factor (U2F) protocol [51]. This protocol is composed of
two phases. During the registration phase, a key pair is generated
in an external hardware device. The generated public key is sent
to the remote server, whereas the private key remains securely
stored within the hardware device. Later, during the authentication
phase, the server sends the client a challenge. The client then
asks the hardware device to sign this challenge with the stored
private key, and the signed response is then sent back to the remote
server, which can verify it using the previously obtained public key.
Both during the registration and the generation phases, the user is
required to physically touch the hardware device as a Test of User
Presence (TUP) to authorize creation and usage of cryptographic
keys.
III. THREAT MODEL
This section explores the different threat and attacker models
considered in this paper. We first define different “levels of
compromise” that an attacker may achieve. Then, we discuss
several different threat models, ranging from being just able to
install a malicious app on the victim’s device to be able to fully
compromise the Android Linux (untrusted) operating system. We
will also argue why each of these threat models are particularly
relevant for any work studying the fingerprint API. We end this
section by clarifying which threat models are considered as out of
scope.
A. Levels of Compromise
To ease our exposition, we now define three labels describing
three different levels of compromise an attacker can achieve in the
different scenarios. We discuss the three levels starting from the
least powerful. We note that, of course, an attacker will always
attempt to achieve the third and most powerful level of compromise.
However, depending on the attacker capabilities and how a given
app uses the fingerprint API, this may not always be possible.
Confused Deputy. An attacker might be able to interfere with
the usage of the fingerprint API to change the intended effect a
user wants to achieve when she touches the fingerprint sensor. For
example, consider a user who wants to authorize the transaction
“pay $1,000 to F riend” by pressing the fingerprint sensor: an
attacker might be able to change this transaction to “pay $1,000
to Attacker.” Another example is an attacker that can lure the
user to provide the fingerprint by spoofing a completely unrelated
scenario, such as the lock screen.
More in general, these examples are instances of a confused
deputy problem. An attacker can achieve her goal by abusing this
problem, but she needs the user to touch the fingerprint sensor
once for each malicious attempt.
Once For All. In this scenario, the attacker can completely bypass
the need for “fingerprint” by just luring the user to provide a
fingerprint once. That is, after the attacker obtains one fingerprint,
the attacker can spoof any subsequent fingerprint request. We
note that, in this context, the term “spoofing” does not entail
spoofing the “real” physical fingerprint. Instead, with this term,
we indicate that an attacker can trick the vulnerable app, and the
backend it communicates with, to believe a legitimate fingerprint
was provided.
As a representative example, consider an app that, after
the user provides a fingerprint, decrypts, using a TEE-backed
cryptographic key, an authentication token. If an attacker manages
to access this decrypted token, the attacker can now just reuse the
token undisturbed for subsequent authentication and authorization
attempts, without needing to lure additional fingerprints. Thus, this
scenario provides a more practical opportunity for an attacker.
Full Fingerprint Bypass. In this last case, an attacker can
completely bypass the need of luring fingerprint touches without
requiring a “real” touch, not even once. For example, consider
a banking app that requires the user to confirm every monetary
transaction by pressing the fingerprint sensor. If an attacker can
compromise the app to this last level, the attacker can authorize
an unlimited number of transactions, at will, without having the
user touch the sensor. This case provides significant practicality
benefits for an attacker. In fact, the attacker does not need to “wait”
to hijack a user’s touch: as a matter of fact, in this scenario the
attack does not need any user interaction at all.
We note that it may not always be possible for a root attacker
to indefinitely wait for a user’s touch, because, for instance, thanks
to the Verified Boot protection mechanism, it may be impossible
to persistently compromise a device.
4
B. Attacker Capabilities
We consider the following three increasingly powerful attacker
capabilities.
Non-Root Attacker. In this threat model, we consider an attacker
that is just able to install a malicious application on the victim’s
device. In this case, we assume that the attacker is unable to subvert
the security of the operating system, and therefore the installed
malicious app is still constrained by all the limitations imposed by
the Android framework. The installed app can, however, request
permissions (as any other benign third-party app installed on the
device) to obtain specific capabilities, and, in this case, we assume
that the user will grant them.
Additionally, the installed app, can show maliciously crafted
messages or, more in general, interfere with the device’s user
interface (UI), to lure a legitimate user to touch the fingerprint
reader sensor. These UI attacks greatly vary in terms of complexity
and flexibility, and they are well explored by several existing
works [34], [14], [9], some of which, such as Cloak & Dagger [21],
achieve almost complete compromise of the device. While these
attacks are indeed powerful, we note that the fingerprint API might
be one of the few aspects that could, at least in principle, prevent
full compromise. In fact, even though the Cloak & Dagger attack
can simulate arbitrary user input, it cannot “spoof” a physical
fingerprint user’s touch.
The key conceptual point here is that there is no trusted path
from the fingerprint API to the UI. Thus, as previous works
have shown, the attacker can exploit an instance of the confused
deputy problem. We postpone the discussion on the practicality
and implications of these attacks to Section VI-B.
Root Attacker. In this threat model, we assume that an attacker
can fully compromise the Android operating system, by using, for
instance, a “root exploit.” Therefore, the attacker can completely
bypass apps’ restrictions put in place by the Android framework.
For example, the attacker can access app-private storage (which
is usually protected by the sandboxing mechanism). Moreover,
exploiting confused deputy instances via the UI attacks mentioned
above becomes much simpler for a root attacker.
Additionally, the attacker can spoof “messages” from the
operating system: Specifically, an attacker can freely communicate
with the TEE, and thus send arbitrary messages to it. At this
point the attacker can programmatically invoke the onAuthenti-
cationSucceeded method implemented within the victim app
(and thus simulating a user’s touch), even if the user has never
touched the fingerprint sensor.
We note that, although a root attacker is powerful, she does not
get access to everything. In particular, the fingerprint API enforces
the following three security properties even on a system in which
the untrusted OS is completely compromised:
1)
2)
3)
an attacker cannot retrieve “raw” fingerprint data;
an attacker cannot retrieve the value of cryptographic key
stored into the TEE (i.e., keys are not exportable);
an attacker cannot use TEE-backed cryptographic keys,
unless a legitimate user touches the fingerprint sensor.
However, if the victim app does not properly use such TEE-backed
cryptographic keys, the attacker might be able to achieve her goal
anyways, as we will explain later.
That being said, we also note that, for some usage scenarios,
an app does not have any technical way to secure itself from root
attackers. For example, if the app uses fingerprint not to secure a
secret or token, but as a local “Test of User Presence” (TUP), there
is currently no way a developer could make use of cryptographic
algorithms. On the other hand, crypto primitives can be definitively
used when implementing remote user-authentication mechanisms.
We postpone the discussion about these scenarios to Section VI-A.
Finally, for this threat model, we will assume that the device
is not in a compromised state when the cryptographic keys
(“unlocked” by touching the fingerprint sensor) were first created
by the app that the attacker wants to compromise. The creation of
cryptographic keys typically happens only during the first usage
of an app and, therefore, it may be impossible for an attacker to
interfere with their creation if the compromise of a device happens
only after this stage of an app’s lifecycle.
Root-at-Bootstrap Attacker. In this threat model, we consider
an attacker with the same capabilities of the previous one. Ad-
ditionally, we also assume that the device is in a compromised
state even in the moment in which the victim’s app generates
the cryptographic keys. Therefore, in this case, the attacker can
interfere with their creation.
C. Out-of-Scope Attacker Capabilities
We assume that the TEE is not compromised. In other words,
we consider an attacker that can compromise the code running (or
the data stored) within the TEE as out of scope. In fact, an attacker
able to compromise the TEE can trivially fully compromise the
fingerprint functionality, by stealing all the cryptographic keys in
the secure storage. Moreover, as previously mentioned, exploits
able to gain this capability for an attacker are extremely rare.
We will consider attacks on the physical recognition of the
fingerprint as out of scope. These attacks, although possible [42],
deal with the physical aspects of the fingerprint acquisition
process and with the algorithms used to compare fingerprint data.
Conversely, in this paper, we focus on a higher-level aspect: the
operations inside TEE that are triggered by the legitimate user
touching the fingerprint sensor, the operating system, and the apps
using the fingerprint sensor API. Therefore, we will assume that
the fingerprint sensor and the code inside the TEE handling it are
always able to understand if the user that is touching the sensor
is the legitimate one (i.e., a user who has previously registered
her fingerprint as valid using the appropriate operating system
interface).
IV. FINGERPRINT API USAGES
In this section, we will explain how the fingerprint API is used
by Android apps. In particular, we will classify apps’ usages of the
fingerprint API based on if and how cryptographic keys (stored
inside the TEE) are used to verify that a legitimate user touched
the fingerprint sensor. This aspect has profound implications on
what attackers can do to subvert the fingerprint checks and how
they can achieve their malicious goals. In Section VI-A, we will
then explain how the verification of the user touching the sensor is
used as a part of the authentication schemes implemented by apps
and their corresponding backends.
5
A. Weak Usage
C. Sign Usage
The easiest way to use the fingerprint API is to execute some
code after a legitimate user touched the sensor, without using
any cryptography. To achieve this, a developer just has to call the
authenticate method to activate the fingerprint reader sensor
and override the onAuthenticationSucceeded method to be
notified when the user touched it.
From the implementation standpoint, recall that the authen-
ticate method takes, as an argument, the cryptographic key that
is unlocked when the user touches the sensor (see Section II-C).
Thus, an app can set this parameter to NULL and, as a side-effect,
the fingerprint will not unlock any cryptographic keystore. Of
course, an app could also require access to the keystore and it
could then discard this object without using it. In other words, a
specific fingerprint-protected functionality is not “protected” by