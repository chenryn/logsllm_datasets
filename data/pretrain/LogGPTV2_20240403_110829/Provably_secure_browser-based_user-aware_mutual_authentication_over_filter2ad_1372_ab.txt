translates the messages from user and server, however, is unaware of the semantic meaning: It takes a message
m ∈ M from the message space M ∈ {0, 1}λ1(κ) (the space of all HTML documents) that the server S
wishes to send to user U and presents the information according to the browser’s state Ψ ∈ {0, 1}λ2(κ) to U as
a Web page. Here and in the following, λi : N → N, i ∈ [1, 2] is a polynomial. State Ψ denotes the browser’s
conﬁguration for processing the retrieved message that may be altered by querying the browser’s DOM4 model.
Loosely speaking, the DOM model describes the browser’s tree-based view of a Web page and deﬁnes access
to document nodes, browser and connection information through Web scripting languages (e.g., Javascript).
The same origin security policy which is universally supported in browsers controls access to the nodes and
ensures that there is no information retrieval between pages that have different domains, including access to the
browser’s chrome, cache, cookies, and history. Access to any ephemeral and long-term secrets which are stored
in separated containers, or the ability to open, create or delete a ﬁle from the operating system, are subject to
different security policies which normally involve user interaction.
B communicates to U calling the visualization function render : M×Ψ → M∗. More precisely, whenever
B wishes to communicate a protocol message m to U it calls render, which takes m and current browser’s state
Ψ as input and outputs the appropriate visualization m∗ to U.
Modeling User Behavior via recognize-Function The overall goal of browser-based authentication proto-
cols is to provide mutual authentication between the entity user U and the entity server S. Since the user is
involved in the protocol execution, we need to formulate the behavior. The necessity for modeling the user
behavior is due to the fact that the adversary may mount attacks that target the user.
Devising a rigorous model that captures user behavior clearly raises various issues, both technical and philo-
sophical. For instance, which human abilities can we model? Should we restrict the user behavior to certain
skills, say perceive certain objects. If so, how can we model the quality of skills? Do users behave “correctly”
4 Document Object Model, see [39] for details.
Provably Secure Browser-Based User-Aware Mutual Authentication over TLS
5
in the sense that they always behave in the same way? The problem becomes even more intricate when one
wishes to quantify the behavior. This work takes a rather simplistic approach. We assume that the user is able to
recognize the high-entropy HPA w and remembers a low-entropy password pw.
The communication between B and U is established in a consistent way across through the boolean human
perception function recognize : M∗ × W → {0, 1} which on input a visualized message m∗ ∈ M∗ and w
outputs 1 if U recognizes w among the content of m∗; otherwise the output is 0. In this paper we assume that
if m∗ contains w (denoted as m∗|w) then recognize outputs 1, i.e., the ability of U to recognize w is perfect.
On the other hand, we do not assume that w is the only HPA for which recognize outputs 1, i.e., we do not
idealize U as there can be some set W∗ ⊆ W which contains HPAs that are perfectly human-indistinguishable
from U according to the following deﬁnition.
Deﬁnition 1 (Perfect Human-Indistinguishability of HPAs5). Let w ∈ W be some given HPA. For any m∗ ∈
M∗ and any w∗ ∈ W, we say that w and w∗ are perfectly human-indistinguishable, if for any human user U
(cid:12)(cid:12) Pr[U.recognize(m∗|w, w) = 1] − Pr[U.recognize(m∗|w∗, w) = 1](cid:12)(cid:12) = 0
where the probabilities are computed over the choices of w∗. By W∗ ⊆ W we denote the set of all perfectly
human-indistinguishable HPAs for some given w ∈ W assuming that w ∈ W∗.
Our main idea in designing user-aware security protocols based on HPAs is to opt for authenticators for
which W∗ is sufﬁciently small for most of the users. In this case the probability that an adversary chooses or
guesses some HPA that cannot be distinguished from w by U can be kept low. The ideal case would be if W∗
would consist only of w. We call w a good HPA if the size of the set W∗ is sufﬁciently small such that the
term |W∗|/|W|6 which addresses user-awareness in our proof and is used (beside further cryptography-related
terms) to compute the overall probability of a successful attack is negligible.
For our protocol we assume that the HPA used by U in the execution of our protocol is good.
Remark 1. An interesting topic of future work would be to consider the similarity of authenticators in order to
model users’ fuzziness. Consider the following example. Let w be an authenticator that consists of an image,
and let w∗ be the same image, but marginally compressed. Some users would be able to distinguish w∗ and w
whereas some would fail. Many metrics exist that allow for scaling the meaning of “some” and quantify the
similarity for different types of HPAs. Using such metrics is an interesting challenge, since it allows to reﬁne
the assumptions on user behavior.
Protocol Sessions and Instances In order to model participation of C = (U,B) and S in distinct executions of
the same BBMA protocol Π we consider instances [C, sidC] and [S, sidS] where sidC, sidS ∈ N are respective
session identiﬁers. If sidC = sidS then we assume that both instances belong to the same session, and say the
instances are partnered. Note that in our protocol sidC and sidS will be given by the concatenation of random
nonces exchanged between B and S in the beginning of the protocol. For simplicity, we sometimes omit the
indication of the instance and write C and S instead. Whether, C or S denote the actual party or its instance is
usually visible from the context.
Execution States Each instance [C, sidC] and [S, sidS] may be either used or unused. The instance is consid-
ered as unused if it has never been initialized. Each unused instance can be initialized with the corresponding
long-lived key. The instance is initialized upon being created. After the initialization the instance is marked as
used, and turns into the stand-by state where it waits for an invocation to execute the protocol. Upon receiving
such invocation the instance turns into a processing state where it proceeds according to the protocol speci-
ﬁcation. The instance remains in the processing state until it collects enough information to decide whether
5 The deﬁnition we use in this full version differs from the one given in the published conference version of this paper as it
no longer uses a security parameter for the estimation of the ability of human users to recognize HPAs.
6 In the published conference version of this paper this term was mistakenly denoted as 2|W∗|−|W| though the text descrip-
tion explicitly mentions the relation between the sizes of W∗ and W.
6
Sebastian Gajek, Mark Manulis, Ahmad-Reza Sadeghi, and Jörg Schwenk
the execution was successful or not, and to terminate then. If the execution is successful then we say that the
instance accepts before it terminates. The acceptance in case of the client instance [C, sidC] with C = (U,B) is
implied by the acceptance of the user U regardless of the state of the browser B, as U is the ultimate endpoint
of the communication and controls the browser. In case that the execution was not successful (due to failures)
instances terminate without accepting, i.e., they abort. Note that the client instance aborts whenever the user or
the browser aborts.
2.2 Security Model
Assumptions The adversary A controls all communication between the protocol parties. This implies:
- The adversary controls the domain name resolution. Upon sending forged domain resolution responses, the
adversary is capable of foiling browsers’ same origin policy, thus accessing through the DOM model the
browser’s chrome, cache, cookies, and history. However, the adversary is prevented from opening, creating
or deleting a ﬁle from the operating system. Since the long-term secrets are prevented from caching and
part of different security policies, this implies that the adversary is incapable of accessing passwords and
HPAs.
- There exists no trusted third party in the sense of a trusted CA. A certiﬁed public key in a X.509 server
certiﬁcate is treated as a public key that can be identiﬁed by a unique identiﬁer (i.e., hash value of the public
key). Disburden the model from certiﬁed public keys captures the fact that (i) the adversary has retrieved
from a trusted CA certiﬁed public keys for rogue servers such that B accepts the keys without any user
notiﬁcation and (ii) the behavior of users who ignore the certiﬁcate validation warnings.
- The adversary is unable to corrupt B. Note that in this model we do not deal with malware7 attacks against
the browser and server, therefore, do not consider the case where A reveals the ephemeral and longterm
secrets stored inside B.
- The adversary is unable to corrupt S. Note also that in this model we do not deal with malware attacks
against the server. This means that the adversary is excluded from revealing the ephemeral and longterm
secrets stored inside S.
- The communication within the client C that is the communication between U and B is not authenticated.
Note that in this model we do not deal with physical attacks against the user; otherwise over-the-shoulder
surfers are enabled to see the human perceptible authenticator and the user password.
Adversarial Queries The adversary A participates in the actual protocol execution via the following queries:
- Execute(C,S): This query models passive attacks. The adversary A eavesdrops the execution of the new
protocol session between C and S. A is given the corresponding transcript.
- Invoke(C,S): This is a special query used by an active adversary A to invoke the actual protocol execution.
This query is described in detail in the next paragraph.
- Send(P, m): This query models active attacks where A sends a message to some instance of P ∈ {U,B,S}.
That is, messages addressed to U are implicitly handled as messages addressed to the associated browser
B with the subsequent execution of the render(m, Ψ) function while messages to the server S from U are
processed by browser B and then send in a machine-readable form. The information ﬂow in the Send(P, m)-
query is implicitly denoted by including the sender and receiver identities in m.
- RevealState(B): This query models attacks which reveal information stored with the browser’s state Ψ.
It should be mentioned that corruptions of the browser and server cannot be allowed because of the weakness of
the underlying TLS protocols (see Section 3). Such corruptions would immediately compromise all previously
executed sessions.
7 Consideration of malware attacks and augmentation of the proposed model with Trusted Computing functionalities to
model resistance against malware attacks is surely an interesting aspect for the future work on security of browser-based
protocols.
Provably Secure Browser-Based User-Aware Mutual Authentication over TLS
7
Protocol Execution in the Presence of A By asking the Execute(C,S) query A obtains the transcript of
the complete protocol execution between new instances of C and S without being able to perform any further
actions during this execution.
On the other hand, if A wishes to actively participate in the execution of Π then it can ask a special invoca-
tion query Invoke(C,S) implying that a new instance of U starts the protocol execution with the new instance of
S using the associated instance of browser B. A obtains then the ﬁrst protocol message returned by B (which is
usually generated on some input received from U, e.g., the entered URL). Active participation of A is deﬁned
further through the Send queries.
In the following we deﬁne the main security goal of BBMA protocols, namely the requirement of mutual
Correctness and Mutual Authentication in BBMA Protocols The following deﬁnition of correctness speci-
ﬁes the purpose of BBMA protocols.
Deﬁnition 2 (Correctness). A BBMA protocol Π is correct if each Execute(C,S) query results in two instances
[C, sidC] and [S, sidS] which are partnered (sidC = sidS) and accept prior to termination.
If two instances [C, sidC] and [S, sidS] would accept and terminate without being partnered (sidC (cid:54)= sidS),
then interleaving attacks are feasible.
authentication between participating U and S.
Π (A, κ)
Deﬁnition 3 (Browser-Based Mutual Authentication). Let Π be a correct BBMA protocol and Gamebbma
the interaction between the instances of C = (U,B) and S with a PPT adversary A who is allowed to query
Execute, Invoke, Send, and RevealState. We say that A wins if at some point during the interaction:
1. An instance [C, sidC] accepts but there is no partnered instance [S, sidS], or
2. An instance [S, sidS] accepts but there is no partnered instance [C, sidC].
The maximum probability of this event over all adversaries is denoted Succbbma
Gamebbma
negligible function of the security parameter κ.
Recall, the acceptance in case of the client instance [C, sidC] with C = (U,B) is implied by the acceptance of
the user U (regardless of the state of B) since U is the ultimate endpoint of the communication and controls the
browser. Then, the ﬁrst requirement ensures that client C authenticates to the matching server S. The second
requirement ensures that the server S authenticates to the matching client C.
Π (A, κ) = maxA | Pr[A wins in
Π (A, κ)]|. We say that a BBMA protocol Π provides mutual authentication if this probability is a
3 Browser-Based Mutual Authentication Protocol based on TLS
In this section we describe our protocol for browser-based authentication based on the standard TLS protocol.
We call the proposed protocol BBMA.
3.1 Building Blocks
TLS Protocol A main pillar of BBMA is the mutually authenticated key transport. This complies with RSA-
based ciphersuites as speciﬁed in [4]. These suites are preferentially negotiated between standard browsers and
servers. (It is notable that BBMA can be likewise designed for DH-based key exchange.) We write in parenthesis
the corresponding TLS messages.
Cryptographic Primitives BBMA uses the (well-known) cryptographic primitives from the cryptographic suites
of the TLS protocol, namely:
8
Sebastian Gajek, Mark Manulis, Ahmad-Reza Sadeghi, and Jörg Schwenk
– A pseudo-random function PRF : {0, 1}p3(κ) × {0, 1}∗ → {0, 1}∗. Note that TLS deﬁnes PRF with data
expansion s.t. it can be used to obtain outputs of a variable length which becomes useful for the key deriva-
tion phase. By Advprf
PRF (κ) we denote the maximum advantage over all PPT adversaries in distinguishing the
outputs of PRF from those of a random function better than by a random guess. Let l1, l2, l3 and l4 denote
the publicly known labels speciﬁed in TLS for the instantiation of PRF (see [18, Sect. 5]).
– A symmetric encryption scheme which provides indistinguishability under chosen plaintext attacks (IND-
CPA). The symmetric encryption operation is denoted Enc and the corresponding decryption operation
Dec. By Advind−cpa
(Enc,Dec)(κ) we denote the maximum advantage over all PPT adversaries in breaking the
IND-CPA property of (Enc, Dec) better than by a random guess.
– An IND-CPA secure asymmetric encryption scheme whose encryption operation is denoted E and the cor-
responding decryption operation D. By Advind−cpa