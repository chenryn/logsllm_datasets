In the smart watch scenario, users were equipped with
two smartphones which they carried with them continuously.
One of the devices simulated a smart watch that is worn on
the user’s wrist.
It was therefore placed in a translucent
carrying pouch so that its light sensor was constantly ex-
posed to the ambient light. The other device was used like
a regular smartphone.
In the ’cycling’ scenario, we used two smartphones to sim-
ulate wearable ﬁtness gadgets, currently one of the most
popular classes of wearable devices.
In our scenario, we
considered a cyclist, who is using a heart rate monitor to
record his physical performance and a near-eye display de-
vice to visually follow the key characteristics of his workout,
including the heart rate. The smartphone playing the role
of a near-eye display device was attached on the side of the
bicycle helmet of the cyclist, with the light sensor showing
outwards. The other device played the role of the smart
heart rate sensor. It was placed in a translucent carrying
pouch on the chest of the cyclist, facing forward, which is
also a typical placement for heart rate sensors. In the cy-
cling scenario, ambient light and noise data were collected
during the workouts of the cyclist.
Results. We collected traces from co-located devices car-
ried by test persons in a number of mobile and static con-
texts: walking, in public transport, as well as stays in the
home and oﬃce contexts. Since the mobility of the user
introduces a signiﬁcant amount of changes into the devices’
contexts, the bit similarity of ﬁngerprints from the co-located
devices was relatively high, 92.6 % on average (minimum
87.3 %, maximum 96.7 %). This provides a good basis for
successful key evolution between the co-located devices. In
the wearable device scenario, however, also the presence of
wrong peer devices in the context plays a role. We analyze
the eﬀect of such devices on the key evolution scheme in
more detail in Section 5.1.
For the cycling scenario we collected 10 traces of con-
text measurements captured along a back-and-forth journey
on a ﬁxed route of approximately 10 miles. The exercises
were spread out over several weeks, encompassing varying
road and weather conditions ranging from rainy, overcast
to sunny days. Since the contextual environment changes
in this scenario much faster than in the static scenario, we
chose a shorter time window w = 5 sec and higher sampling
rate f = 5 sec for luminosity-based ﬁngerprint generation.
Using this ﬁngerprinting scheme, the ﬁngerprints for the ex-
ercises contained 665 to 784 bits. For audio data, a slightly
longer time window of w = 6 sec was used, giving us ﬁn-
gerprints of 501 to 550 bits. The bit similarity between the
ﬁngerprints of the co-located devices d1 and d2 was on the
average 68.6 % for luminosity-based ﬁngerprints (minimum
62.8 %, maximum 74.5 %) and 65.9 % for audio-based ﬁn-
gerprints (minimum 63.6 %, maximum 67.1 %).
4.1.4 Context Replay Attacks
In addition to testing the bit similarities of co-located de-
vices we also examined the eﬀect of context replay attacks
by analyzing whether an attacker, who knows the route that
a user is going to use could record the context parameters
along this route and use this recording to produce a context
ﬁngerprint that could fool a target device into believing that
the attacker has been sharing the same context. We there-
fore used the set of ﬁngerprints from the cycling scenario
generated on diﬀerent days on the same route and measured
their bit similarity. We did this in order to ﬁnd out what an
attacker in the optimal (worst) case could achieve. We iter-
ated over all exercise ﬁngerprints, using one ﬁngerprint at a
time as the target device d1’s ﬁngerprint and the remaining
ﬁngerprints as ﬁngerprints of the adversary A. Since the ﬁn-
gerprints were recorded at diﬀerent times, it was not clear
how to optimally align them. We therefore calculated the
bit diﬀerence for each target-attacker ﬁngerprint pair for all
possible overlapping alignments of the ﬁngerprints and used
the minimal bit diﬀerence to choose the optimal alignment.
We then averaged the bit similarity values over the adver-
sarial ﬁngerprints with optimal alignments.
The ﬁngerprint similarity of simulated replay attacks with
the target devices was 59.5 % (minimum 55.9 %, maximum
62.3 %) for luminosity-based ﬁngerprints and 56.4 % (mini-
mum 55.0 %, maximum 56.8 %) for audio-based ﬁngerprints.
The margin between the actually co-located device pair d1
and d2 to the replayed adversarial ﬁngerprints was on the
average 52.5 bits (minimum 4 bits, maximum 104 bits) for
luminosity and 42.8 bits (minimum 27 bits, maximum 51
bits) for audio in favor of the co-located pair.
The clear margins between the bit similarities of co-located
and attacker ﬁngerprints suggest that it’s in most cases pos-
sible to deﬁne a parameter value t for the fuzzy commitment
scheme so that co-located peers will be able to successfully
perform key evolution steps, while blocking most attackers
from doing so. The analysis here also involves two rather
optimistic assumptions in favor of the attacker, namely that
the attacker is able to record the trace in exactly the same
way as the targeted user and that the attacker is able to
guess the optimal alignment of his ﬁngerprint with the tar-
get user’s ﬁngerprint. In practice, it is unlikely that an at-
tacker would be able to always guess the optimal alignment,
or record context traces with the same rhythm and speed
as the targeted users. Hence in practice the margins in fa-
vor of the correct peers will be much larger than the ones
presented above.
5. SECURITY ANALYSIS
In our analysis we assume that the legitimate personal
devices of the user have not been compromised and execute
context sensing, key agreement, key evolution and authen-
tication protocols as speciﬁed.
Let us consider an adversary A impersonating X , having
a key chain identity ID XA . The only way for A to get its
pairing with a target device d1 accepted as genuine is to
achieve a high enough authenticity rating α(ID XA ). To do
this, it needs to successfully participate in the key evolution
process. A can do so in two cases:
1. A is in the same context as d1 and can generate context
ﬁngerprints FCA suﬃciently similar to the ﬁngerprint
FCd1
, FCA ) ≤ t, or,
of d1, i.e., Ham(FCd1
2. A is not in the same context as d1 but is able to fabri-
CA suﬃciently similar with
cate context ﬁngerprints F (cid:48)
the ﬁngerprint of d1, i.e., Ham(FCd1
CA ) ≤ t.
, F (cid:48)
We will ﬁrst analyze the eﬀect of A being in the same
context with d1 on his authenticity rating, and then analyze
the success probability of the attacker fabricating context
ﬁngerprints.
5.1 Attacker in Same Context as Target
Let us denote with θ the probability that A is able to
, FCA ) ≤ t and
extract a ﬁngerprint FCA having Ham(FCd1
with β the probability that a co-located device d2 extracts
a ﬁngerprint FCd2
If A is present in the same context as d1, A can extract
ﬁngerprints FCA that have the same probability to have a
bit diﬀerence of t or lower than the co-located device d2.
Therefore, θ = β. However, to simplify the analysis, let
us assume a perfect attacker that always succeeds in key
evolution when it is in the context, i.e., θ = 1.
having Ham(FCd1
) ≤ t.
, FCd2
We denote with n the number of key evolution steps that
a correct peer d2 will attempt during a speciﬁc time period
and with m the number of key evolution steps that the wrong
peer A will attempt during the same time. To maximally
increase its authenticity rating, A will attempt to do key
evolution steps every time it is co-located with the target
device in the same context. When A is not in the same
context, the probability to successfully evolve the key is less
than β. Therefore A will not participate in key evolution.
Since d2 is a benign peer, it will regularly attempt to evolve
its pairing key with d1 each time it is co-located with it.
d2 ) > γ(ID XA). Since γ(ID X
According to Def. 1 the authenticity rating α(ID X
d2 ) of
the correct peer d2 will be higher, if it has performed more
successful key evolution steps than the attacker A, i.e., if
d2 ) = β · n and γ(ID XA) =
γ(ID X
θ· m = m, and, if β· n > m holds, then attacker A will never
be able to obtain an authenticity rating that is higher than
the rating of the correct peer. However, since we assume
that n >> m, and, in particular β · n > m, it is clear that
the attacker will not succeed in getting his pairing accepted
as genuine in our scheme.
5.2 Attacker not in Same Context as Target
The fuzzy commitment scheme used in the key evolu-
tion protocol provides the hiding property as mentioned in
Sect. 3. A will not be able to reveal the correct key deriva-
tion key Kr and thus participate successfully in the key evo-
lution protocol if it can’t ﬁnd a context ﬁngerprint F (cid:48)
CA that
CA satisfying this criterion.
has a Hamming distance of at most t bits to the ﬁngerprint
FCd1
of the targeted device d1. We focus our analysis there-
fore on examining whether an attacker is able to fabricate
ﬁngerprints F (cid:48)
When the attacker A has no access to actual context mea-
is extracted, A has the fol-
surements based on which FCd1
lowing options for fabricating the ﬁngerprint F (cid:48)
: a ran-
dom guess, a proﬁling-based guess, or, the use of partial
information.
Cd1
Random Guess.
In a random guess, the probability to guess one bit cor-
rectly is 0.5. Consequently, for a ﬁngerprint of length k, the
likelihood for a successful guess is therefore 2−k. The suc-
cess probability is negligibly small for typical ﬁngerprints of
tens or hundreds of bits. For example, using a ﬁngerprint-
ing window of w = 120 sec and ﬁngerprinting periods of two
hours, one already gets ﬁngerprints of 60 bits, which would
be excessively diﬃcult to guess with random guesses.
Proﬁling-Based Guesses.
An obvious improvement to this attack would be to use
proﬁled information about the distribution of bits to improve
A’s chances to fabricate valid ﬁngerprints F (cid:48)
CA . Depending
on the used ﬁngerprinting parameters, the type of context
in question as well as the time of the day, the distribution of
ﬁngerprint bits in the ﬁngerprint changes. For example, dur-
ing nighttime, when it typically is silent and dark, and thus
no signiﬁcant changes in the context parameters take place,
an overwhelming majority of bits in d1’s ﬁngerprint FCd1
will be “0” bits, with only a few “1” bits (if any) in-between.
Fig. 4 shows for the oﬃce context and the audio modality
examined in our evaluation experiments the distribution of
“1” vs. “0” bits changing according to the time of day. If A
can obtain such proﬁle information about a context where
d1 is going to be, A can utilize the proﬁled information in
fabricating ﬁngerprints F (cid:48)
CA that are more likely to have a
lower Hamming distance Ham(FCd1
, FCA ) to the ﬁngerprint
FCd1
of device d1 extracted in that context.
sociated with individual bits b ∈ FCd1
The strength of a ﬁngerprint against proﬁling-based guess-
ing attacks can be analyzed by looking at the surprisal as-
using a frequentist
interpretation of probability. We do this by calculating the
occurrence probability of a particular bit b in the ﬁngerprint
during a speciﬁc time of the day. Thus, the probability of a
particular bit (i.e., “1” or “0”) is equal to the fraction of that
bit’s occurrences in the context ﬁngerprints during that time
of the day. Given the occurrence probability of a particular
bit, we deﬁne the surprisal associated with individual bits
as follows.
Definition 4
(Surprisal σ of a fingerprint bit).
Let B be a random variable modelling the occurrence of a bit
as a ﬁngerprint bit in ﬁngerprint F . The surprisal σ asso-
ciated with the occurrence of a ﬁngerprint bit b ∈ {0, 1} is
P (B=b) ) =
the self-information of this bit σ(b) = I(b) = log(
−log(P (B = b)), and is measured in bits.
1
Definition 5
(Surprisal of a fingerprint).
The surprisal σ(F ) of a ﬁngerprint F is the sum of the sur-
prisal values of its individual bits, i.e.,
(cid:88)
b∈F
σ(F ) =
σ(b).
For example, we can see based on Fig. 4 that context
measurements made during the night are not suitable for
generating hard-to-guess context ﬁngerprints. This is be-
cause, e.g., during the time window of 2 a.m. to 4 a.m. on
the average only 1 % of the extracted ﬁngerprint bits are “1”
bits. Each of these bits has a surprisal value of 6.3 bits per
ﬁngerprint bit, but the remaining “0” bits only have a sur-
prisal of 0.02 bits per ﬁngerprint bit. This means that, e.g.,
a 60-bit ﬁngerprint extracted during this time frame would
have only 5.8 bits of total surprisal on the average. In other
words, the attacker would have a 2−5.8 ≈ 1.8% chance of
guessing the exactly correct context ﬁngerprint by utilizing
proﬁling information.
However, since we are using a fuzzy commitment scheme,
the attacker A does not even have to guess the exact ﬁnger-
print. Any ﬁngerprint F (cid:48)
CA that is within Hamming distance
t of the ﬁngerprint FCd1
of target device d1, will enable the
attacker A to open the commitment and retrieve the correct
key derivation key Kr.
From the evaluation results (cf. Tab. 2) we can see that
in the oﬃce environment, and for the audio modality, the
context ﬁngerprints of co-located devices will deviate on the
average in ca. 10 % of the bits.
In order to let correct
peers perform key evolution successfully, we need to tune
the parameter t of the fuzzy commitment scheme so that
it allows ﬁngerprints deviating in 10 % of the bits to still
open the fuzzy commitments. Coming back to our exam-
ple of Fig. 4, this would mean that for ﬁngerprints of 60
bits we would need to set t = 6 bits. A could use this to
his advantage and fabricate during nighttime context ﬁn-
CA = {0}60 containing nothing but “0” bits. The
gerprints F (cid:48)
fuzzy commitment scheme would correct the errors this ﬁn-
, since it
gerprint has with regard to d1’s ﬁngerprint FCd1
on the average contains less than t = 6 “1” bits during the
night. The attacker A could thus successfully evolve the key
nearly every time just by targeting ﬁngerprints generated
from nighttime context data.
To thwart such attacks against ﬁngerprints with very low
surprisal values, we need to add an additional requirement:
only ﬁngerprints FCd having suﬃcient total surprisal may
be taken into account when evaluating authenticity ratings.
Requirement 1
(Surprisal threshold σthr ). When
d1 calculates the number of successful key evolution steps
with another device d , only such evolution steps may be
taken into account that have been based on ﬁngerprints FCd1
having a surprisal value σ(FCd1
Here σmarg denotes a surprisal margin required in addition
to the bits that the fuzzy commitment scheme will correct.
In eﬀect, σmarg deﬁnes, how hard it is for an attacker to
guess a ﬁngerprint F (cid:48)
CA that is required for successful key
evolution.
) > t + σmarg .
Use of Partial Information.
In addition to proﬁling-based guesses, the attacker A may
be in the position to utilize partial information about the
context ﬁngerprint FCd1
of the target device d1. Such partial
information may be available to the attacker based on the
fact that the contextual separation between the attacker’s
context and the target context, where d1 is located, is not