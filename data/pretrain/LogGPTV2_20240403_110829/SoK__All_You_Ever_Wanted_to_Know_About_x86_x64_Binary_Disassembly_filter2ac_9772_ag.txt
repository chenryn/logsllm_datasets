### Table XII: Statistics of False Negatives in Function Detection

| Category | Dyninst | Ghidra | Ghidra-NE | Angr | Angr-NS | Bap | Radare2 |
| --- | --- | --- | --- | --- | --- | --- | --- |
| J-Tab (Missing Jump Table Targets) | 0.03% | 0.02% | 0.01% | 0.08% | 1.18% | 1.32% | 1.12% |
| T-Call (Missing Tail Calls) | 1.68% | 0.05% | 0.18% | 13.05% | 1.06% | 2.42% | 2.78% |
| Non-Ret (Missing Non-Returning Functions) | 2.07% | 1.48% | 14.16% | 8.25% | 4.01% | 7.99% | 3.64% |
| FP-Overlap (Side Effects of Other False Positives) | 10.16% | 12.42% | 73.61% | 32.78% | 11.82% | 5.52% | 86.06% |
| No-Match (Other) | 86.03% | 84.81% | 5.01% | 60.97% | 76.45% | 86.94% | - |

**Note:**
- **J-Tab:** Missing jump table targets.
- **T-Call:** Missing tail calls.
- **Non-Ret:** Missing non-returning functions.
- **FP-Overlap:** Side effects of other false positives.
- **No-Match:** Functions that are neither reached by recursive descent nor matched by patterns.

### Analysis of False Negatives and False Positives

#### False Positives
The primary causes of false positives in function detection include:
1. **Signature-Based Detection Errors:** Incorrectly matching function entries (e.g., DYNINST: 80.80%, GHIDRA-NE: 28.38%, ANGR-NS: 92.98%, BAP: 99.99%).
2. **Inaccurate Tail Call Detection:** Misidentifying the target of a regular jump as a function entry (e.g., DYNINST: 19.20%, GHIDRA-NE: 71.61%, ANGR: 11.70%).
3. **Incorrect Disassembly:** Leading to erroneous call instructions to incorrect target functions (e.g., GHIDRA-NE: 0.01%, ANGR-NS: 0.01%, RADARE2: 0.01%).

Additional causes for specific tools:
- **ANGR:** Considering code discovered by its linear scan as a function entry (78.41% of false positives).
- **GHIDRA:** Exception information carrying pointers to the middle of functions (99.94% of false positives).
- **RADARE2:** Aggressively inferring code pointers based on xrefs (93.17% of false positives).

#### False Negatives
Common causes of false negatives include:
1. **Missed Jump Table Targets:** Failing to identify functions called by the target code or their successors (e.g., ANGR-NS: 1.18%, BAP: 1.32%, RADARE2: 1.12%).
2. **Unrecognized Tail Calls:** Missing the functions indicated by their targets (e.g., ANGR: 13.05%, BAP: 2.42%, RADARE2: 2.78%).
3. **Missed Non-Returning Functions:** Preventing the detection of many function entries (e.g., GHIDRA-NE: 14.16%, ANGR: 8.25%, ANGR-NS: 4.01%, BAP: 7.99%).
4. **Overlapping with True Functions:** Wrongly identified functions overlapping with true functions, making the latter unrecognizable (e.g., DYNINST: 10.16%, GHIDRA: 12.42%, ANGR: 73.61%, ANGR-NS: 32.78%).
5. **Other Missed Functions:** Functions that are neither reached by recursive descent nor matched by patterns (e.g., ANGR-NS: 60.97%, GHIDRA: 86.03%, RADARE2: 86.94%).

### Use of Heuristics in Function Entry Identification

Two major heuristics are used for function entry identification:
1. **Prologue/Pattern Matching:** This heuristic searches for function entries using common prologues or data-mining models. It recovers an additional 17.36% of functions with an average precision of 77.53%. The utility of this heuristic varies across optimization levels and architectures. Tools like ANGR-NS and DYNINST use more aggressive patterns/models, resulting in higher coverage (21.3%/24.02%) but lower precision (56.61%/85.37%) compared to GHIDRA-NE and RADARE2 (18.24%/7.93% with 98.42%/87.29% precision).
   
2. **Linear Scan Heuristic:** Used by ANGR, this heuristic takes the beginning of each code region detected by a linear scan as a function entry. It recovers 23% more functions but reduces precision by 26.96% due to frequent misidentification of padding or data-in-code as function entries.

### CFG Reconstruction Performance

#### Overall Performance
- **Edge Recovery:** Most tools can recover over 90% of edges with high accuracy (e.g., DYNINST, GHIDRA, and ANGR find over 90% of the edges with an accuracy higher than 95%).
- **Jump Table Handling:** GHIDRA and DYNINST resolve over 93% of jump tables with around 90% accuracy. RADARE2 and ANGR have similar coverage (around 75%), but ANGR has much higher accuracy (96.27% vs. 90%).

#### Results of CFG Reconstruction on Linux and Windows Binaries

**Table XIII: Results of CFG Reconstruction on Linux**

| Tool | Edge Rec | Edge Pre | CG Rec | CG Pre | T-Call Rec | T-Call Pre | N-Ret Rec | N-Ret Pre | J-Tab Rec | J-Tab Pre |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| Dyninst | 97.28% | 97.10% | 81.91% | 71.15% | 99.99% | 99.01% | 100.0% | 86.89% | 99.97% | 98.82% |
| Ghidra | 98.61% | 92.41% | 68.75% | 78.84% | 99.99% | 91.17% | 100.0% | 86.04% | 99.87% | 99.05% |
| Ghidra-NE | 98.88% | 91.58% | 59.64% | 71.12% | 99.99% | 90.34% | 100.0% | 86.20% | 99.81% | 99.10% |
| Angr | 98.93% | 90.14% | 67.74% | 68.79% | 99.99% | 86.92% | 100.0% | 86.33% | 99.89% | 98.50% |
| Angr-NS | 98.87% | 91.33% | 58.93% | 68.60% | 99.99% | 90.26% | 100.0% | 85.08% | 99.93% | 98.75% |
| Bap | 99.63% | 97.41% | 90.98% | 79.42% | 99.99% | 96.66% | 100.0% | 50.19% | 98.49% | 75.58% |
| Radare2 | 99.89% | 89.61% | 95.93% | 97.91% | 99.99% | 88.91% | 99.98% | 71.21% | 97.46% | 97.55% |
| Binary Ninja | 99.89% | 89.30% | 92.75% | 96.10% | 99.99% | 88.59% | 100.0% | 67.15% | 91.44% | 97.71% |

**Table XIV: Results of CFG Reconstruction on Windows**

| Tool | Edge Rec | Edge Pre | CG Rec | CG Pre | T-Call Rec | T-Call Pre | N-Ret Rec | N-Ret Pre | J-Tab Rec | J-Tab Pre |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| Dyninst | 98.41% | 98.13% | 34.09% | 57.80% | 99.99% | 99.93% | 97.62% | 81.25% | 99.80% | 87.34% |
| Ghidra | 94.88% | 94.95% | 91.20% | 77.46% | 99.99% | 99.98% | 89.57% | 80.48% | 89.21% | 70.07% |
| Ghidra-NE | 95.23% | 95.16% | 87.46% | 80.97% | 99.99% | 99.98% | 90.48% | 80.72% | 89.12% | 73.42% |
| Angr | 95.53% | 96.44% | 84.37% | 96.05% | 99.99% | 99.95% | 93.04% | 83.05% | 98.62% | 81.07% |
| Angr-NS | 95.12% | 95.10% | 87.34% | 79.13% | 99.99% | 99.95% | 88.98% | 78.28% | 90.23% | 73.22% |
| Bap | 100.0% | 75.61% | 95.31% | 76.12% | 99.99% | 85.00% | 99.18% | 76.66% | 91.76% | 55.48% |
| Radare2 | 99.12% | 71.40% | 92.00% | 55.97% | 99.99% | 78.05% | 99.24% | 68.66% | 91.95% | 56.54% |
| Binary Ninja | 83.45% | 83.51% | 55.74% | 43.14% | 99.99% | 92.67% | 98.47% | 83.29% | 96.93% | 79.80% |

### Comparison with Commercial Tools

Compared to open-source tools, commercial tools generally have higher coverage (96.5% vs. 84.8%) and accuracy (99% vs. 92.96%). Additionally, commercial tools like BINARY NINJA and IDA PRO show better performance in handling indirect jumps and calls, though they still face challenges in certain cases.

This analysis provides a comprehensive overview of the strengths and weaknesses of various tools in function detection and CFG reconstruction, highlighting areas for potential improvement.