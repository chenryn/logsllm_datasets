This command downloads the image named mongo from the
Docker repository, spins up a new instance named some-mongo
—the name you give the instance is arbitrary—and maps local
port 27017 to the container port 27017. The port mapping is key,
as it allows us to access the database instance directly from our
operating system. Without it, it would be inaccessible.
Check that the container started automatically by listing all
the running containers:
$ docker ps
In the event your container doesn’t start automatically, run
the following command:
$ docker start some-mongo
The start command should get the container going.
Once your container starts, connect to the MongoDB
instance by using the run command—passing it the MongoDB
client; that way, you can interact with the database to seed
data:
$ docker run -it --link some-mongo:mongo --rm mongo sh \
-c 'exec mongo
"$MONGO_PORT_27017_TCP_ADDR:$MONGO_PORT_27017_TCP_POR
T/store"'
>
This magical command runs a disposable, second Docker
container that has the MongoDB client binary installed—so
you don’t have to install the binary on your host operating
system—and uses it to connect to the some-mongo Docker
container’s MongoDB instance. In this example, you’re
connecting to a database named test.
In Listing 7-1, you insert an array of documents into the
transactions collection. (All the code listings at the root location
of / exist under the provided github repo
https://github.com/blackhat-go/bhg/.)
> db.transactions.insert([
{
"ccnum" : "4444333322221111",
"date" : "2019-01-05",
"amount" : 100.12,
"cvv" : "1234",
"exp" : "09/2020"
},
{
"ccnum" : "4444123456789012",
"date" : "2019-01-07",
"amount" : 2400.18,
"cvv" : "5544",
"exp" : "02/2021"
},
{
"ccnum" : "4465122334455667",
"date" : "2019-01-29",
"amount" : 1450.87,
"cvv" : "9876",
"exp" : "06/2020"
}
]);
Listing 7-1: Inserting transactions into a MongoDB collection (/ch-7/db/seed-
mongo.js)
That’s it! You’ve now created your MongoDB database
instance and seeded it with a transactions collection that contains
three fake documents for querying. You’ll get to the querying
part in a bit, but first, you should know how to install and seed
traditional SQL databases.
Installing and Seeding PostgreSQL and MySQL
Databases
Databases
PostgreSQL (also called Postgres) and MySQL are probably
the two most common, well-known, enterprise-quality, open
source relational database management systems, and official
Docker images exist for both. Because of their similarity and
the general overlap in their installation steps, we batched
together installation instructions for both here.
First, much in the same way as for the MongoDB example
in the previous section, download and run the appropriate
Docker image:
$ docker run --name some-mysql -p 3306:3306 -e
MYSQL_ROOT_PASSWORD=password -d mysql
$ docker run --name some-postgres -p 5432:5432 -e
POSTGRES_PASSWORD=password -d postgres
After your containers are built, confirm they are running,
and if they aren’t, you can start them via the docker start name
command.
Next, you can connect to the containers from the
appropriate client—again, using the Docker image to prevent
installing any additional files on the host—and proceed to
create and seed the database. In Listing 7-2, you can see the
MySQL logic.
$ docker run -it --link some-mysql:mysql --rm mysql sh -c \
'exec mysql -h "$MYSQL_PORT_3306_TCP_ADDR" -
P"$MYSQL_PORT_3306_TCP_PORT" \
-uroot -p"$MYSQL_ENV_MYSQL_ROOT_PASSWORD"'
mysql> create database store;
mysql> use store;
mysql> create table transactions(ccnum varchar(32), date date, amount
float(7,2),
-> cvv char(4), exp date);
Listing 7-2: Creating and initializing a MySQL database
The listing, like the one that follows, starts a disposable
Docker shell that executes the appropriate database client
binary. It creates and connects to the database named store and
then creates a table named transactions. The two listings are
identical, with the exception that they are tailored to different
database systems.
In Listing 7-3, you can see the Postgres logic, which differs
slightly in syntax from MySQL.
$ docker run -it --rm --link some-postgres:postgres postgres psql -h postgres -
U postgres
postgres=# create database store;
postgres=# \connect store
store=# create table transactions(ccnum varchar(32), date date, amount
money, cvv
char(4), exp date);
Listing 7-3: Creating and initializing a Postgres database
In both MySQL and Postgres, the syntax is identical for
inserting your transactions. For example, in Listing 7-4, you
can see how to insert three documents into a MySQL transactions
collection.
mysql> insert into transactions(ccnum, date, amount, cvv, exp) values
-> ('4444333322221111', '2019-01-05', 100.12, '1234', '2020-09-01');
mysql> insert into transactions(ccnum, date, amount, cvv, exp) values
-> ('4444123456789012', '2019-01-07', 2400.18, '5544', '2021-02-01');
mysql> insert into transactions(ccnum, date, amount, cvv, exp) values
-> ('4465122334455667', '2019-01-29', 1450.87, '9876', '2019-06-01');
Listing 7-4: Inserting transactions into MySQL databases (/ch-7/db/seed-pg-
mysql.sql)
Try inserting the same three documents into your Postgres
database.
Installing and Seeding Microsoft SQL Server
Databases
In 2016, Microsoft began making major moves to open-source
some of its core technologies. One of those technologies was
Microsoft SQL (MSSQL) Server. It feels pertinent to highlight
this information while demonstrating what, for so long, wasn’t
possible—that is, installing MSSQL Server on a Linux
operating system. Better yet, there’s a Docker image for it,
which you can install with the following command:
$ docker run --name some-mssql -p 1433:1433 -e 'ACCEPT_EULA=Y' \
-e 'SA_PASSWORD=Password1!' -d microsoft/mssql-server-linux
That command is similar to the others you ran in the
previous two sections, but per the documentation, the
SA_PASSWORD value needs to be complex—a combination of
uppercase letters, lowercase letters, numbers, and special
characters—or you won’t be able to authenticate to it. Since
this is just a test instance, the preceding value is trivial but
minimally meets those requirements—just as we see on
enterprise networks all the time!
With the image installed, start the container, create the
schema, and seed the database, as in Listing 7-5.
$ docker exec -it some-mssql /opt/mssql-tools/bin/sqlcmd -S localhost \
-U sa -P 'Password1!'
> create database store;
> go
> use store;
> create table transactions(ccnum varchar(32), date date, amount
decimal(7,2),
> cvv char(4), exp date);
> go
> insert into transactions(ccnum, date, amount, cvv, exp) values
> ('4444333322221111', '2019-01-05', 100.12, '1234', '2020-09-01');
> insert into transactions(ccnum, date, amount, cvv, exp) values
> ('4444123456789012', '2019-01-07', 2400.18, '5544', '2021-02-01');
> insert into transactions(ccnum, date, amount, cvv, exp) values
> ('4465122334455667', '2019-01-29', 1450.87, '9876', '2020-06-01');
> go
Listing 7-5: Creating and seeding an MSSQL database
The previous listing replicates the logic we demonstrated
for MySQL and Postgres earlier. It uses Docker to connect to
the service, creates and connects to the store database, and
creates and seeds a transactions table. We’re presenting it
separately from the other SQL databases because it has some
MSSQL-specific syntax.
CONNECTING AND QUERYING
DATABASES IN GO
Now that you have a variety of test databases to work with,
you can build the logic to connect to and query those databases
from a Go client. We’ve divided this discussion into two
topics—one for MongoDB and one for traditional SQL
databases.
Querying MongoDB
Despite having an excellent standard SQL package, Go
doesn’t maintain a similar package for interacting with
NoSQL databases. Instead you’ll need to rely on third-party
packages to facilitate this interaction. Rather than inspect the
implementation of each third-party package, we’ll focus
purely on MongoDB. We’ll use the mgo (pronounce mango)
DB driver for this.
Start by installing the mgo driver with the following
command:
$ go get gopkg.in/mgo.v2
You can now establish connectivity and query your store
collection (the equivalent of a table), which requires even less
code than the SQL sample code we’ll create later (see Listing
7-6).
package main
import (
"fmt"
"log"
mgo "gopkg.in/mgo.v2"
)
type Transaction struct { ❶
CCNum string `bson:"ccnum"`
Date string `bson:"date"`
Amount float32 `bson:"amount"`
Cvv string `bson:"cvv"`
Expiration string `bson:"exp"`
}
func main() {
session, err := mgo.Dial("127.0.0.1") ❷
if err != nil {
log.Panicln(err)
}
defer session.Close()
results := make([]Transaction, 0)
if err := session.DB("store").C("transactions").Find(nil).All(&results)❸; err !=
nil {
log.Panicln(err)
}
for _, txn := range results { ❹
fmt.Println(txn.CCNum, txn.Date, txn.Amount, txn.Cvv, txn.Expiration)
}
}
Listing 7-6: Connecting to and querying a MongoDB database (/ch-7/db/mongo-
connect/main.go)
First, you define a type, Transaction, which will represent a
single document from your store collection ❶. The internal
mechanism for data representation in MongoDB is binary
JSON. For this reason, use tagging to define any marshaling
directives. In this case, you’re using tagging to explicitly
define the element names to be used in the binary JSON data.
In your main() function ❷, call mgo.Dial() to create a session
by establishing a connection to your database, testing to make
sure no errors occurred, and deferring a call to close the
session. You then use the session variable to query the store
database ❸, retrieving all the records from the transactions
collection. You store the results in a Transaction slice, named
results. Under the covers, your structure tags are used to
unmarshal the binary JSON to your defined type. Finally, loop
over your result set and print them to the screen ❹. In both
this case and the SQL sample in the next section, your output
should look similar to the following:
$ go run main.go
4444333322221111 2019-01-05 100.12 1234 09/2020
4444123456789012 2019-01-07 2400.18 5544 02/2021
4465122334455667 2019-01-29 1450.87 9876 06/2020
Querying SQL Databases
Querying SQL Databases
Go contains a standard package, called database/sql, that defines
an interface for interacting with SQL and SQL-like databases.
The base implementation automatically includes functionality
such as connection pooling and transaction support. Database
drivers adhering to this interface automatically inherit these
capabilities and are essentially interchangeable, as the API
remains consistent between drivers. The function calls and
implementation in your code are identical whether you’re
using Postgres, MSSQL, MySQL, or some other driver. This
makes it convenient to switch backend databases with minimal
code change on the client. Of course, the drivers can
implement database-specific capabilities and use different
SQL syntax, but the function calls are nearly identical.
For this reason, we’ll show you how to connect to just one
SQL database—MySQL—and leave the other SQL databases
as an exercise for you. You start by installing the driver with
the following command:
$ go get github.com/go-sql-driver/mysql
Then, you can create a basic client that connects to the
database and retrieves the information from your transactions
table—using the script in Listing 7-7.
package main
import (
"database/sql" ❶
"fmt"
"log"
"github.com/go-sql-driver/mysql" ❷
)
func main() {
db, err := sql.Open("mysql", "root:password@tcp(127.0.0.1:3306)/store")❸
if err != nil {
log.Panicln(err)
}
defer db.Close()
var (
ccnum, date, cvv, exp string
amount float32
)
rows, err := db.Query("SELECT ccnum, date, amount, cvv, exp FROM
transactions") ❹
if err != nil {
log.Panicln(err)
}
defer rows.Close()
for rows.Next() {
err := rows.Scan(&ccnum, &date, &amount, &cvv, &exp)❺
if err != nil {
log.Panicln(err)
}
fmt.Println(ccnum, date, amount, cvv, exp)
}
if rows.Err() != nil {
log.Panicln(err)
}
}
Listing 7-7: Connecting to and querying a MySQL database (/ch-7/db/mysql-
connect/main.go)
The code begins by importing Go’s database/sql package ❶.
This allows you to utilize Go’s awesome standard SQL library
interface to interact with the database. You also import your
MySQL database driver ❷. The leading underscore indicates
that it’s imported anonymously, which means its exported
types aren’t included, but the driver registers itself with the sql
package so that the MySQL driver itself handles the function
calls.
Next, you call sql.Open() to establish a connection to our
database ❸. The first parameter specifies which driver should
be used—in this case, the driver is mysql—and the second
parameter specifies your connection string. You then query
your database, passing an SQL statement to select all rows
from your transactions table ❹, and then loop over the rows,
subsequently reading the data into your variables and printing
the values ❺.
That’s all you need to do to query a MySQL database.
Using a different backend database requires only the following
minor changes to the code:
1. Import the correct database driver.
2. Change the parameters passed to sql.Open().
3. Tweak the SQL syntax to the flavor required by your backend database.
Among the several database drivers available, many are
pure Go, while a handful of others use cgo for some underlying
interaction. Check out the list of available drivers at
https://github.com/golang/go/wiki/SQLDrivers/.
BUILDING A DATABASE MINER
In this section, you will create a tool that inspects the database
schema (for example, column names) to determine whether the
data within is worth pilfering. For instance, say you want to
find passwords, hashes, social security numbers, and credit
card numbers. Rather than building one monolithic utility that
mines various backend databases, you’ll create separate
utilities—one for each database—and implement a defined
interface to ensure consistency between the implementations.
This flexibility may be somewhat overkill for this example,
but it gives you the opportunity to create reusable and portable
code.
The interface should be minimal, consisting of a few basic
types and functions, and it should require the implementation
of a single method to retrieve database schema. Listing 7-8,
called dbminer.go, defines the database miner’s interface.
package dbminer
import (
"fmt"
"regexp"
)
❶ type DatabaseMiner interface {
GetSchema() (*Schema, error)
}
❷ type Schema struct {
Databases []Database
}
type Database struct {
Name string
Tables []Table
}
type Table struct {
Name string
Columns []string
}
❸ func Search(m DatabaseMiner) error {
❹ s, err := m.GetSchema()
if err != nil {
return err
}
re := getRegex()
❺ for _, database := range s.Databases {
for _, table := range database.Tables {
for _, field := range table.Columns {
for _, r := range re {
if r.MatchString(field) {
fmt.Println(database)
fmt.Printf("[+] HIT: %s\n", field)
}
}
}
}
}
return nil
}
❻ func getRegex() []*regexp.Regexp {
return []*regexp.Regexp{
regexp.MustCompile(`(?i)social`),
regexp.MustCompile(`(?i)ssn`),
regexp.MustCompile(`(?i)pass(word)?`),