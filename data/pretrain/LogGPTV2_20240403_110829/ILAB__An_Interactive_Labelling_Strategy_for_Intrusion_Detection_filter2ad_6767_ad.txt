dow. We compute the mean and the variance
of the number of bytes and packets sent and
received at diﬀerent levels: globally, for some
speciﬁc port numbers (80, 443, 53 and 25), and for some speciﬁc TCP ﬂags aggre-
gates (....S, .A..S., .AP.SF, etc.). Besides, we compute other aggregated val-
ues: number of contacted IP addresses and ports, number of ports used, entropy
according to the contacted IP addresses and according to the contacted ports.
In the end, each external IP address is described by 134 features computed from
its list of ﬂows.
The NetFlow data is recorded during a working day in 2016. The features
are computed for each external IP address with a 24-hour time window. The
NetFlow dataset is large: it is composed of 463,913 IP addresses represented by
134 real-valued features (see Table 2). A second dataset has been recorded the
following day for the validation of the resulting detection model. The results
are, however, not reported due to space constraints since the main focus is the
deployment of the labelling strategy in an annotation project.
ILAB Graphical User Interface. A security expert answers ILAB annotation
queries from the graphical user interface depicted in Fig. 5. The top buttons allow
the expert to select a type of annotation queries: Uncertain for the instances
near the decision boundary, Malicious and Benign for the annotation queries
generated by rare category detection. The panel below allows to go through the
annotation queries corresponding to each family.
By default, each instance is described only by its features which may be hard
to interpret, especially when they are in high dimension. A custom visualization
which may point to external tools or information can be displayed to ease the
ILAB: An Interactive Labelling Strategy for Intrusion Detection
135
Fig. 5. ILAB graphical user interface for annotating
annotations. Figure 5 depicts the custom visualization we have implemented for
NetFlow data3.
Finally, the expert can annotate the selected instance with the Annotation
panel. For each label, it displays the list of the families already discovered. The
expert can pick a family among a list or add a new family. The interface sug-
gests a family for high likelihood queries and pre-selects it. It helps the expert
since the model is conﬁdent about these predictions. On the contrary, there is
no suggestion for the uncertainty sampling and the low likelihood queries. The
model is indeed uncertain about the family of these instances and unreliable
suggestions may mislead the expert [3].
ILAB in Practice. First, we need some labelled instances to initialize the active
learning process. The alerts raised by the Threshold Random Walk (TRW) [18]
module of Bro [24] provide the initial anomalous examples and the normal exam-
ples are drawn randomly. The initial labelled dataset is composed of 70 obvious
scans detected by TRW, and of 70 normal examples belonging to the Web, SMTP
and DNS families. Malicious activities in well-established connections cannot be
detected without the payload, which is not available in NetFlow data, that is
why we consider the families Web, SMTP and DNS to be normal. All the initial
labels are checked individually by the expert to avoid poisoning the model.
This initial labelled dataset is not representative of all the anomalous behav-
iours we want to detect. We run ILAB with the parameters B = 1000, b = 100
3 The IP addresses have been hidden for privacy reasons.
136
A. Beaugnon et al.
and buncertain = 10 to acquire a representative labelled dataset. Across the iter-
ations, ILAB has discovered stealthier scans: ICMP scans, slow scans (only
one ﬂow with a single defended IP address contacted on a single port), furtive
scans (a slow scan in parallel with a well-established connection). Besides, it
has detected TCP Syn ﬂooding activities designed to exhaust the resources
of the defended network. Finally, ILAB has asked the expert to annotate IP
addresses with anomalous behaviours which are not malicious: misconﬁgurations
and backscatters.
60
40
20
)
s
d
n
o
c
e
s
(
i
e
m
T
n
o
i
t
u
c
e
x
E
0
0
200
NetFlows
1- Uncertainty Sampling
2- Malicious Queries
3- Benign Queries
400
600
800
Num. Annotations
1,000
Fig. 6. ILAB execution time
Low Expert Waiting Time. ILAB divide and conquer approach allows the expert
to annotate some instances while the labelling strategy is still computing anno-
tation queries. First, the binary detection model is trained and the uncertainty
sampling queries are computed. The binary detection model is indeed required
to predict the label of the unlabelled instances to run rare category detection
afterwards. Then, rare category detection is performed on the malicious predic-
tions while the expert annotates the uncertain instances. Finally, rare category
detection is computed on the benign predictions while the expert annotates the
malicious annotation queries. The malicious predictions are analysed before the
benign ones, because their number is smaller, so the analysis is faster (see Fig. 6).
In practice, running rare category detection takes less time than the anno-
tations. As a result, the expert must only wait while the uncertain queries are
computed (see the orange curve Uncertainty Sampling in Fig. 6). During the
NetFlow annotation project the expert has waited less than 40 s at each itera-
tion. ILAB low computation cost ensures a good expert-model interaction: the
detection model is updated frequently with expert feedback without inducing
long waiting-periods.
Families Beneﬁts. ILAB and Aladin deal with the sampling bias problem thanks
to rare category detection performed at the family level. At ﬁrst glance, this solu-
tion may seem to increase the annotation cost as it requires experts to provide a
ILAB: An Interactive Labelling Strategy for Intrusion Detection
137
more precise information than a binary label. However, asking experts to provide
a family does not increase the annotation cost in practice: experts place instances
in “mental bins” corresponding to families to provide a label [26]. Experts must
understand the type of the instance to provide a label, and, therefore, assigning
a family does not require an additional eﬀort.
Besides, the clustering of the annotation queries according to families (see
Fig. 5) decreases the average annotation cost. Families provide a context that
helps the expert answer the queries. Annotation queries related to the same
family are likely to share the same label and family, and thus, it reduces the
amount of context switching during the annotation process. On the contrary,
uncertainty sampling and G¨ornitz et al. labelling strategy ask the expert to
annotate a list of unrelated instances without any context.
Finally, an alert raised by a supervised detection model can be hard to inter-
pret for the security expert. This issue called semantic gap by Sommer et al. [38]
is due to the binary output (Malicious or Benign) of the detection model. The
families acquired with ILAB can bridge the semantic gap by enriching the alerts
with a malicious family to help the expert supervising the detection system take
the necessary actions.
7 Conclusion
We introduce ILAB a novel interactive labelling strategy that streamlines anno-
tation projects. It relies on active learning and rare category detection to avoid
sampling bias. We demonstrate that ILAB oﬀers a better scalability than two
state-of-the-art labelling strategies [14,40] without damaging the eﬀectiveness.
Up to our knowledge, [14,40] had never been compared. We provide open source
implementations to foster comparison in future research works.
ILAB divide and conquer approach reduces the computation cost, and allows
the expert to annotate some instances while the labelling strategy is still comput-
ing annotation queries. Thus, ILAB provides a good expert-model interaction:
the detection model is updated frequently with expert feedback without inducing
long waiting-periods.
The NetFlow annotation project shows that ILAB is a workable labelling
strategy that can be applied to a large dataset originating from a production
environment. ILAB is a generic labelling strategy that can be applied to other
detection problems once the feature extraction task has been performed. It is
designed for security experts who deploy intrusion detection systems, and we pro-
vide an open source implementation of the graphical user interface to allow them
to label their own datasets. For future work, we plan to run broader experiments
with independent computer security experts to assess ILAB from an end-user’s
point of view and to improve its usability from their feedback.
138
A. Beaugnon et al.
References
1. Almgren, M., Jonsson, E.: Using active learning in intrusion detection. In: CSFW,
pp. 88–98 (2004)
2. Antonakakis, M., Perdisci, R., Nadji, Y., Vasiloglou, N., Abu-Nimeh, S., Lee, W.,
Dagon, D.: From throw-away traﬃc to bots: detecting the rise of DGA-based mal-
ware. In: USENIX Security, pp. 491–506 (2012)
3. Baldridge, J., Palmer, A.: How well does active learning actually work?: Time-based
evaluation of cost-reduction strategies for language documentation. In: EMNLP,
pp. 296–305 (2009)
4. Berlin, K., Slater, D., Saxe, J.: Malicious behavior detection using windows audit
logs. In: AISEC, pp. 35–44 (2015)
5. Bilge, L., Balzarotti, D., Robertson, W., Kirda, E., Kruegel, C.: Disclosure: detect-
ing botnet command and control servers through large-scale netﬂow analysis. In:
ACSAC, pp. 129–138 (2012)
6. Claise, B.: Cisco systems netﬂow services export version 9 (2004)
7. Corona, I., Maiorca, D., Ariu, D., Giacinto, G.: Lux0r: detection of malicious PDF-
embedded JavaScript code through discriminant analysis of API references. In:
AISEC, pp. 47–57 (2014)
8. Dasgupta, S., Hsu, D.: Hierarchical sampling for active learning. In: ICML, pp.
208–215 (2008)
9. Druck, G., Settles, B., McCallum, A.: Active learning by labeling features. In:
EMNLP, pp. 81–90 (2009)
10. Friedman, J., Hastie, T., Tibshirani, R.: The Elements of Statistical Learn-
ing. Springer Series in Statistics, vol. 1. Springer, Berlin (2001). doi:10.1007/
978-0-387-21606-5
11. Gascon, H., Yamaguchi, F., Arp, D., Rieck, K.: Structural detection of android
malware using embedded call graphs. In: AISEC, pp. 45–54 (2013)
12. G¨ornitz, N., Kloft, M., Brefeld, U.: Active and semi-supervised data domain
description. In: ECML-PKDD, pp. 407–422 (2009)
13. G¨ornitz, N., Kloft, M., Rieck, K., Brefeld, U.: Active learning for network intrusion
detection. In: AISEC, pp. 47–54 (2009)
14. G¨ornitz, N., Kloft, M.M., Rieck, K., Brefeld, U.: Toward supervised anomaly detec-
tion. JAIR 46, 235–262 (2013)
15. Hachey, B., Alex, B., Becker, M.: Investigating the eﬀects of selective sampling on
the annotation task. In: CoNLL, pp. 144–151 (2005)
16. Hanley, J.A., McNeil, B.J.: The meaning and use of the area under a receiver
operating characteristic (ROC) curve. Radiology 143(1), 29–36 (1982)
17. Jones, E., Oliphant, T., Peterson, P.: SciPy: open source scientiﬁc tools for Python
(2001). http://www.scipy.org/
18. Jung, J., Paxson, V., Berger, A.W., Balakrishnan, H.: Fast portscan detection
using sequential hypothesis testing. In: S&P, pp. 211–225 (2004)
19. Khasawneh, K.N., Ozsoy, M., Donovick, C., Abu-Ghazaleh, N., Ponomarev, D.:
Ensemble learning for low-level hardware-supported malware detection. In: Bos,
H., Monrose, F., Blanc, G. (eds.) RAID 2015. LNCS, vol. 9404, pp. 3–25. Springer,
Cham (2015). doi:10.1007/978-3-319-26362-5 1
20. Lewis, D.D., Gale, W.A.: A sequential algorithm for training text classiﬁers. In:
SIGIR, pp. 3–12 (1994)
21. Miller, B., Kantchelian, A., Afroz, S., Bachwani, R., Dauber, E., Huang, L.,
Tschantz, M.C., Joseph, A.D., Tygar, J.: Adversarial active learning. In: AISEC,
pp. 3–14 (2014)
ILAB: An Interactive Labelling Strategy for Intrusion Detection
139
22. Nappa, A., Raﬁque, M.Z., Caballero, J.: The MALICIA dataset: identiﬁcation and
analysis of drive-by download operations. IJIS 14(1), 15–33 (2015)
23. Omohundro, S.M.: Five Balltree Construction Algorithms. International Computer
Science Institute, Berkeley (1989)
24. Paxson, V.: Bro: a system for detecting network intruders in real-time. Comput.
Netw. 31(23), 2435–2463 (1999)
25. Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O.,
Blondel, M., Prettenhofer, P., Weiss, R., Dubourg, V., Vanderplas, J., Passos, A.,
Cournapeau, D., Brucher, M., Perrot, M., Duchesnay, E.: Scikit-learn: machine
learning in Python. JMLR 12, 2825–2830 (2011)
26. Pelleg, D., Moore, A.W.: Active learning for anomaly and rare-category detection.
In: NIPS, pp. 1073–1080 (2004)
27. Rieck, K.: Computer security and machine learning: worst enemies or best friends?
In: SysSec, pp. 107–110 (2011)
28. Rousseeuw, P.J.: Silhouettes: a graphical aid to the interpretation and validation
of cluster analysis. J. Comput. Appl. Math. 20, 53–65 (1987)
29. Sch¨utze, H., Velipasaoglu, E., Pedersen, J.O.: Performance thresholding in practical
text classiﬁcation. In: CIKM, pp. 662–671 (2006)
30. Sculley, D.: Online active learning methods for fast label-eﬃcient spam ﬁltering.
In: CEAS, pp. 1–4 (2007)
31. Sculley, D., Otey, M.E., Pohl, M., Spitznagel, B., Hainsworth, J., Zhou, Y.: Detect-
ing adversarial advertisements in the wild. In: KDD, pp. 274–282 (2011)
32. Settles, B.: Active learning literature survey. Univ. Wisconsin Madison 52(55–66),
11 (2010)
33. Settles, B.: From theories to queries: active learning in practice. JMLR 16, 1–18
(2011)
34. Settles, B.: Active learning. Synth. Lect. Artif. Intell. Mach. Learn. 6(1), 1–114
(2012)
35. Smutz, C., Stavrou, A.: Malicious PDF detection using metadata and structural
features. In: ACSAC, pp. 239–248 (2012)
36. Smutz, C., Stavrou, A.: Malicious PDF detection using metadata and structural
features. In: Technical report. George Mason University (2012)
37. Snow, R., O’Connor, B., Jurafsky, D., Ng, A.Y.: Cheap and fast–but is it good?:
Evaluating non-expert annotations for natural language tasks. In: EMNLP. pp.
254–263 (2008)
38. Sommer, R., Paxson, V.: Outside the closed world: On using machine learning for
network intrusion detection. In: S&P, pp. 305–316 (2010)
39. Song, J., Takakura, H., Okabe, Y., Eto, M., Inoue, D., Nakao, K.: Statistical analy-
sis of honeypot data and building of kyoto 2006+ dataset for NIDS evaluation. In:
BADGERS, pp. 29–36 (2011)
40. Stokes, J.W., Platt, J.C., Kravis, J., Shilman, M.: Aladin: active learning of anom-
alies to detect intrusions. Technical report. Microsoft Network Security Redmond,
WA (2008)
41. Tavallaee, M., Bagheri, E., Lu, W., Ghorbani, A.A.: A detailed analysis of the
KDD CUP 99 data set. In: CISDA (2009)
42. Tax, D.M., Duin, R.P.: Support vector data description. Mach. Learn. 54(1), 45–66
(2004)
43. Tomanek, K., Olsson, F.: A web survey on the use of active learning to support
annotation of text data. In: ALNLP, pp. 45–48 (2009)
44. Veeramachaneni, K., Arnaldo, I.: AI2: training a big data machine to defend. In:
DataSec, pp. 49–54 (2016)
140
A. Beaugnon et al.
45. Whittaker, C., Ryner, B., Nazif, M.: Large-scale automatic classiﬁcation of phish-
ing pages. In: NDSS, vol. 10 (2010)
46. Wright, S., Nocedal, J.: Numerical optimization. Springer Sci. 35, 67–68 (1999)
47. Zhang, T., Oles, F.: The value of unlabeled data for classiﬁcation problems. In:
ICML, pp. 1191–1198 (2000)