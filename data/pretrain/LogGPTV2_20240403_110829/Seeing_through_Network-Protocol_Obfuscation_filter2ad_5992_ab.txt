that works in their framework to obfuscate the trafﬁc between Tor
clients and bridges [3].
Available evidence indicates that the currently deployed obfus-
cators are able to circumvent deployed DPI systems [12, 43]. The
main question we address is: Can censors easily adapt their DPI
to detect and block obfuscators, without also blocking a signiﬁcant
fraction of non-obfuscator trafﬁc?
Unobservability. Houmansadr et al. [16] suggest that protocol-
mimicry obfuscators will not foil future censors because they do
not provide (what they refer to as) complete unobservability. They
informally deﬁne the latter to be achieved only when a mimicry
obfuscator faithfully follows the standards of the target protocol,
in addition to imitating all aspects of common implementations.
They give a number of DPI-based detection techniques for mimicry
obfuscators and show that these have few false negatives (missed
obfuscated ﬂows) and high true positives (correctly identiﬁed
obfuscated ﬂows) using synthetic trafﬁc generated by the re-
searchers. Their attacks target semantic mismatches between
obfuscated trafﬁc and the cover protocol, for example checking for
valid application-level headers for ﬁles, that header values such as
length ﬁelds are correct, etc.
These semantics-based attacks have not, however, been assessed
in terms of false positives:
a ﬂow that is labeled as having
been obfuscated but was actually not generated by the targeted
anti-censorship tool. A high false-positive rate could make such
attacks less useful in practice, since it may lead to blocking too
many “legitimate” connections or overwhelm systems performing
additional checks after the DPI ﬁrst labels a ﬂow as obfuscated,
as in the case of the Great Firewall’s secondary active probing
mentioned above.
In fact, as we mentioned earlier, there are
realistic settings in which a false-positive rate that seems small (e.g.
0.2%) may be troublesome for censors.
Thus a question left open by this prior work is: Do the semantics-
based attacks proposed in [16] have prohibitively high false-
positive rates? Clearly a negative answer would help us answer
our main question above, but, as we will see, some semantics-based
attacks do not work as well as a censor might like.
Threat model, scope, and approach.
In the rest of this paper,
we focus on answering the two questions just posed. We will
adopt the viewpoint of a censor, and attempt to build efﬁcient
algorithms that reliably and accurately detect network ﬂows that
have been produced by obfuscators. Our primary consideration
will be for obfuscators deployed as Tor pluggable transports, since
these are in wide use. These are: obfsproxy3 and its successor
obfsproxy4, the Tor pluggable transport version of FTE, meek
using Google AppEngine proxies (called meekG), and meek using
Amazon CloudFront proxies (called meekA).
A handful of other obfuscators will be considered, although less
deeply, in order to address the open question from [16]. For ex-
ample, we will investigate false-positive rates for the Houmansadr
et al. detection attacks for Stegotorus, even though Stegotorus
currently is unsupported and unusable with Tor. We are aware that
we evaluate only a very small fraction of proposed attacks for other
obfuscators, and we would like to investigate more attacks in the
future. However, the few attacks we considered give useful insights
into developing efﬁcient attacks.
Our study is restricted to the efﬁcacy of existing obfuscators.
As such, we assume that the IP address, port number, and trafﬁc
features that existing obfuscators do not attempt to hide are out
of scope. Network-visible information that one or more existing
obfuscators do attempt to hide, including application layer content,
packet timing, and packet lengths may be leveraged in attacks.
3. ANALYSIS FRAMEWORK AND DATA
We implement a framework for empirical analysis of obfuscator
detection techniques. It will leverage two groups of datasets: the
ﬁrst is a collection of network packet traces collected at various
locations at our university at different points in time, and the second
is synthetic trafﬁc generated by target obfuscators.
We use our packet traces to examine false positives in existing
proposals for attacking censorship circumvention systems, as well
as in the new attacks we propose in this paper. We use the synthetic
packet traces to study true-positive rates of the new attacks.
We start by providing details of the two sets of data and then
discuss the analysis framework.
3.1 Datasets
We use two major types of datasets:
(1) packet-level trafﬁc
traces collected at various locations in a campus network, and (2)
packet-level traces for Tor Pluggable Transport trafﬁc collected in
controlled environments.
59Size (GB)
Collection year
2014
Deployed PTs Obfs3/FTE/meek
389
1.89
1.22
37.0
45.3
0.2
17.5
OfﬁceDataset CloudDataset WiﬁDataset
2010
-
446
13.17
5.32
76.6
12.9
0.1
10.4
2012
-
239
9.34
7.48
73.6
5.4
0.2
20.8
Total ﬂow No. (M)
TCP ﬂow No. (M)
TCP-HTTP (%)
TCP-unknown (%)
TCP-SSL/TLS (%)
TCP-other (%)
Table 2: A summary of campus network datasets and breakdowns
of TCP ﬂows by services.
“TCP-other” are ﬂows with non-
HTTP/SSL/TLS protocols. “TCP-unknown” are ﬂows of which
protocols are failed to identiﬁed by Bro. “Deployed PTs” shows
the Tor pluggable transports that had been deployed by the time we
collected the traces.
Campus network traces. Over a period of 43 hours between
Sep. 6, 2014 to Sep. 8, 2014, we monitored all packets entering
or leaving a /24 IPv4 preﬁx and a /64 IPv6 preﬁx belonging to our
university. In all, this resulted in 389 GB of network trafﬁc with
full packet payloads. The networks correspond to two different
academic departments within our campus. We call this dataset
OfﬁceDataset.
In addition, we employed two other campus network traces,
which we call CloudDataset and WiﬁDataset. These were collected
at earlier points in time. In particular, CloudDataset was collected
between June 26, 2013 and to June 27, 2013 (over a period of
24 hours), and contains all trafﬁc recorded between our entire
campus network and the public IP address ranges published by
EC2 and Azure. The dataset WiﬁDataset constitutes all packets
captured over a period of 12 contiguous hours in April 2010 from
roughly 1,920 WiFi access points belonging to our campus.
It
contains data exchanged between all wireless clients (e.g., laptops
and smartphones) connected to the campus wireless networks and
other (internal or external) networks. A summary of these three
datasets is shown in Table 2.
The most recent trace could, hypothetically, contain ﬂows cor-
responding to actual use of Tor with the obfuscators turned on. In
our analyses, we ignore this possibility and assume that all trafﬁc is
non-obfuscated. Given that these ﬂows are only used to assess false
positives (FPs), our assumption is conservative when we argue the
FP rates are low.
These traces contain potentially sensitive information of network
users. We obtained an IRB exemption for these analyses. We
performed analysis on an isolated cluster with no connectivity to
the Internet, and with suitable access controls so that only approved
members of the research team were able to use the systems. Only
the bare minimum of research team members were approved to
access the machines.
Tor traces. A Tor trafﬁc trace captures the network trafﬁc
exchanged when a client visits a website over Tor conﬁgured to use
a speciﬁc obfuscator. To collect a trace, we follow the procedures
for collecting traces for website ﬁngerprint attacks as described
in [19]. We built a framework to automate these procedures.
Our framework uses the Stem Python controller library for Tor,
and the Selenium plugin for automating control over a Firefox
Browser when visiting websites [37, 41].1 We record all trafﬁc
using tcpdump (or WinDump on Windows) at the same time.
1Also, our Firefox browser uses the exact same proﬁles as the
default browser in the Tor Browser bundle (TBB) 4.06. The
versions of obfuscators and Tor we used are also the same as those
being used in TBB 4.06.
Before and after visiting a website, our framework visits the
“about:blank” webpage and dwells there for 5–15 seconds. The
ﬁrst time this is done is to ensure that the obfuscator connection
is fully built; in our experiments, we found that most obfuscators
forced a few seconds (usually less than 5 seconds) delay when
building connections after Tor starts successfully. The second visit
to “about:blank” is for making sure we can capture any lingering
packets.
We collected three sets of Tor traces under different com-
binations of network links (with different capacities), end-host
hardware, and operating systems, and labeled them as TorA, TorB
and TorC. We collected TorA and TorB on Ubuntu 12.04 (32-bit)
virtual machines (VMs) and TorC on a Windows 7 (32-bit) virtual
machine. The Ubuntu VMs are built on the same image. All VMs
run on VirtualBox 4.3.26 and are conﬁgured with 4G RAM and 2
virtual processors. The VMs for TorA run on a workstation and are
connected to a campus wired network, whereas the VMs for TorB
and TorC are run on a laptop and connect to a home wired network,
Each of these three datasets contains 30,000 traces collected as
follows: (1) For each target obfuscator, we used our trace collection
framework to visit Alexa Top 5,000 websites to collect 5,000 traces
(labeled as obfs3, obfs4, fte, meekG, and meekA, corresponding
to obfsproxy3, obfsproxy4, FTE, meek-google, and meek-amazon
respectively); (2) In addition, we visited the same set of websites
without Tor and obfuscators to collect 5,000 traces and labeled
them as nonTor.
A handshake message of a ﬂow is the application-layer con-
tent of the ﬁrst client-to-server packet in the ﬂow. We extract
5,000 handshake messages from each of obsproxy3, obfsproxy4,
SSL/TLS, HTTP, and SSH ﬂows to construct a new dataset. The
ﬁrst two types of ﬂows are sampled randomly from Tor datasets
and the other types of ﬂows are from unused campus network
traces (recall that we only use a part of the collected campus
network traces to construct the campus datasets). We call this
dataset HandShakeDataset and use it when examining attacks
based (only) on handshake messages.
3.2 Trace Analysis
We use Bro 2.3.2 [31] with the “-r” option to analyze the
collected network traces, and format and store the results into
MySQL tables. Each table corresponds to a “.log” ﬁle generated
by Bro, and it stores the information for ﬂows of a given type
(UDP, HTTP, SSL, etc.). Each ﬂow is assigned an unique ﬂow
ID, which is also generated by Bro. Also, for each trace packet,
we compute an MD5 hash to generate a packet ID, and store
the packet ID, the ﬂow ID of the associated ﬂow, the raw packet
content (in hexadecimal) and the packet timestamp into an Apache
Hive database [38]. The usage of Hive facilitates the management
and processing of terabytes of data. Users only need to query
the MySQL database to get the basic statistics of a trace, while
using Hive for more time-consuming, sophisticated analysis such
as analyzing packet payloads.
We develop a set of APIs to analyze the above data. These
APIs are encapsulations of Hive or MySQL queries. For some
simple analyses (e.g, counting the packets with a given keyword
in the payload), pure Hive queries are enough. To facilitate more
complex analysis and provide more ﬂexibility, we leverage User-
Deﬁned Functions (UDFs) in Hive to allow users to provide their
own mapper/reducer scripts [2]. We plan to release all our scripts
publicly for other researchers or activists to use.
60Other
Standard Malformed Partial
OfﬁceDataset
26 (89.7)
3 (10.3)
CloudDataset 4,293 (62.8) 1,313 (19.2) 338 (4.9)
WiﬁDataset 1,860 (46.7) 1,252 (31.5) 572 (14.4)
6,839
3,979
6,182 (57.0) 2,565 (23.6) 913 (8.4) 1,190 (11.0) 10,847
Table 3: Breakdown of PDFs by their categories. The percentages
of all PDFs found are shown in parentheses.
895 (13.1)
295 (7.4)
Total
29
Total
0
0
4. SEMANTICS-BASED ATTACKS
We seek to determine whether in-use obfuscators can be reliably
detected by censors. The starting point is previously proposed
attacks. As described in §2, Houmansadr et al. suggest a variety
of attacks against mimicry obfuscators. For example, a Stegotorus
client may generate invalid PDF documents, whereas legitimate
trafﬁc presumably does not.
Their attacks therefore use the
deviations of a target system from expected behavior as evidence
for detecting mimicry obfuscators. We call these attacks semantics-
based attacks.
In this section, we evaluate three semantics based attacks,
two proposed by Houmansadr et al. against Stegotorus and one
suggested by Dyer et al. [12] for detecting FTE. None of these
attacks have been evaluated in terms of false positives, and the latter
has not received any analysis at all. Looking ahead, we ﬁnd that the
ﬁrst attack is unlikely to work well in practice due to the high false-
positive rates we discover. The other two work better, but have
deﬁciencies that our later attacks avoid.
4.1 Stegotorus PDF attack
Description. The Stegotorus HTTP obfuscator attempts to hide Tor
trafﬁc in commonly-seen documents, such as PDF and JavaScript.
However, StegoTorus-HTTP does not guarantee the semantic cor-
rectness of the generated ﬁle. The authors in [16] proposed an
attack that can detect ﬁles (more speciﬁcally, PDF ﬁles) generated
by StegoTorus at a low cost and line speed. The key idea is to check
the validness of the xref table in a PDF ﬁle.
Clearly the efﬁcacy of this attack relies on the assumption that
PDFs generated by non-obfuscated trafﬁc, e.g., normal HTTP,
indeed has valid xref
tables. This was not evaluated in [16],
presumably due to a lack of access to real trafﬁc.
For an HTTP ﬂow, we use a Python library pyndis to reassemble
HTTP sessions. If the Content-Type in the response of a session is
“application/pdf”, we assume the response body is a PDF ﬁle. We
extract the content from the response, store the content as a PDF
ﬁle, and use the PyPDF2 library to test the semantic correctness of
the ﬁle. We deﬁne four categories of PDFs:
•
Standard: According to [17], a standard PDF ﬁle should
start with “%PDF” and end with “%%EOF”, and have a xref
keyword in the content. The PDFs in this category have these
keywords and also pass the PyPDF2 semantic check.
•
• Malformed: The PDFs have “%PDF”, “%%EOF” or xref
keywords (at least one keyword), but do not pass the PyPDF2
semantic check.