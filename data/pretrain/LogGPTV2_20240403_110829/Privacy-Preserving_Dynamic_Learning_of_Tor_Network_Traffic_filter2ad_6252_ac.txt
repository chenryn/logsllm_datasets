### 3.2 Exit Statistics

Unlike entry relays, exit relays cannot observe clients but can observe streams. Therefore, exit relays have access to traffic metadata, such as the port to which a stream connects. PrivCount classifies streams to port 80 or 443 as web, streams to common file-sharing ports as file sharing (see Footnote 8), and streams to unclassified ports as other. We initially measure traffic from all these classes to better understand their significance. (We ignore PrivCountâ€™s interactive class, including SSH and IRC, as Jansen and Johnson observed an insignificant amount of interactive traffic [26].)

#### 3.2.1 Traffic Totals

Results for our exit circuit statistics are shown in Table 4. These results indicate that 52.8% of circuits are active, while 46.1% are inactive, which is comparable to our entry circuit statistics. We observe approximately 10 times fewer circuits overall on our exits than on our entries (61,340 exit circuits compared to 679,300 entry circuits). This discrepancy could be attributed to internal Tor network circuits (e.g., directory, bandwidth test, and onion service circuits) that do not utilize exit relays, circuits that fail before reaching the exit, or a bug in PrivCount. We found that 88.6% of the active circuits carry web traffic, 2.68% carry traffic to well-known file-sharing ports, and 15% carry traffic on other ports.

Results for our exit stream statistics are shown in Table 5. A large majority of streams (90.4%) carry web traffic, while an insignificant number of streams (0.52%) carry traffic to known file-sharing ports, and a small number of streams (7.56%) carry other traffic.

#### 3.2.2 Traffic Distributions

To better understand how clients build streams and transfer bytes, we explore distributions of streams-per-circuit and bytes-per-stream using PrivCount histogram counters. We focus on web and other traffic in this section to ensure that we capture the most significant traffic for modeling purposes, while ignoring traffic on default file-sharing ports since it is a relatively minor contributor to Tor traffic.

The distribution of the number of streams per active circuit is shown in Figure 3. We observed that about 55 to 59% of active circuits carry only one or two streams, and about 21 to 25% of circuits carry 3 to 6 streams. Another 9 to 11% of circuits carry 7-14 streams, and about 4-11% carry 15 or more streams. Given that 30% of popular website front pages result in 11 to 20 TCP connections and more than 45% of front pages result in more than 20 TCP connections according to httparchive.org, it is somewhat surprising that there are so few streams per circuit. This suggests that Tor Browser users may experience the web differently than non-Tor users.

The distribution of the number of bytes per stream is shown in Figure 4, with inbound bytes in Figure 4a and outbound bytes in Figure 4b. We observed that about 70 to 80% of streams receive less than 16 KiB inbound, while about 75 to 85% of streams send less than 1 KiB outbound. There is a significant difference between web and other traffic: it is about 15 and 30% more likely that other streams will carry less than 2 KiB inbound and less than 512 bytes outbound, respectively, compared to web streams. The highest percentage of streams sending more than 4 KiB outbound is 6.84% of other streams; however, the distribution of bytes per stream generally skews higher for web streams than for other streams.

### 4 Learning Traffic Models

To model the behavior of Tor clients without explicit reference to application protocols, we model both the creation of streams and the traffic on a stream (i.e., packets) using hidden Markov models (HMMs) and an iterative PrivCount measurement process.

#### 4.1 Hidden Markov Modeling

Formally, a hidden Markov model (HMM) is a discrete stochastic process that maintains a state \( s \) among a state space \( S \). At each step \( i \) in the process, an observation \( o \) is drawn from some observation space \( O \) according to the probability distribution \( \Theta(o|s) \) conditioned only on the current state \( s_i \), and a next state is drawn from \( S \) according to the transition distribution \( P(s'|s_i) \). The first state \( s_0 \) is chosen according to the initial distribution \( \pi(s) \). In our case, the states can be thought of as modeling the underlying state of the application, and the observations correspond to the arrival of streams or packets on a stream. Since application state is opaque and traffic can be encrypted, the only properties that a relay can reliably observe are the direction (client-bound or server-bound packet) or command (open or close stream) and the time elapsed since the previous event.

Given the parameters of a stream arrival HMM, we can sample a circuit by choosing \( s_0 \leftarrow \pi_{\text{stream}}(s) \), then repeatedly choosing \( o_i \leftarrow \Theta_{\text{stream}}(o|s_i) \) (a delay between stream arrivals) and \( s_{i+1} \leftarrow P_{\text{stream}}(s'|s_i) \) (a next application state) until a "close circuit" event occurs. Similarly, we can sample an application stream by choosing \( s_0 \leftarrow \pi_{\text{packet}}(s) \), then repeatedly choosing \( o_i \leftarrow \Theta_{\text{packet}}(o|s_i) \) and \( s_{i+1} \leftarrow P_{\text{packet}}(s'|s_i) \) until a "close" event occurs. Producing an empirical model of Tor streams requires training a hidden Markov model to learn the parameters that best approximate real Tor streams. In general, there are several approaches to training HMMs from a set of sequences sampled from some HMM; we modified the Expectation-Maximization (EM) approach, in which an initial estimate of the parameters is used to find the sequence of states most likely to yield a sequence of observations (accomplished with the Viterbi Algorithm [15]). These states are then used to update the parameters of the HMM: each state observation distribution's parameters are chosen to maximize the probability of the observations assigned to the state, and each state's transition probabilities are chosen according to the observed frequencies. This process is then repeated, with successive parameter estimates yielding improved models of the underlying process.

To adapt the algorithm described above to the case of privately measuring Tor traffic, we slightly modified both the process of producing an initial estimate and the iteration process, as explained in the following subsections.

#### 4.2 Bootstrapping the HMM

Training an HMM to model a process requires making some initial assumptions about the form of the model, e.g., the number of states, the connectivity between states, and the form of observation distributions. To explore reasonable choices for these assumptions, we performed several experiments using real network trace data from AS 2500, a research ISP that advertises 10 IPv4 prefixes with a total of 330,240 addresses and transfers data for real users from several academic institutions and research organizations. Because AS 2500 serves real users, the network traces that are captured are anonymized before being released as part of a network measurement project [50, 52]. The 24-hour anonymized network trace that we used included 147,962 complete TCP sessions, which we converted to "packet traces" by ignoring empty (acknowledgment-only) and duplicated packets, and treating all data-carrying packets as observations. Acknowledgments and duplicate packets were filtered because we are modeling application-level behavior; the TCP stack and network emulation in Shadow will naturally (re-)produce these packets given an application stream.

##### 4.2.1 Stream Arrivals

To obtain an initial model of stream arrivals, we hypothesized that hosts would follow a common two-state model in which one state originates streams according to an exponential distribution (representing, e.g., the sequential opening of several resources within a web page) and the other state originates streams according to a heavy-tailed distribution (encapsulating both the delay after requesting an index page and the "think time" between user page loads). Using a log-normal distribution to fit the heavy-tailed delays and adding a third state representing the closing of a circuit, we found this model a good fit for the network trace where the probability of transitioning between non-closed states was roughly 25%, the exponential process had a rate of approximately 10/second, and the log-normal process had a median delay of approximately 3 seconds.

##### 4.2.2 Traffic

To determine the form of inter-packet delay distributions, we fit networks to a small subsample of these flows (1000) using several different distributions. Through trial and error, we found that log-normal distributions could reasonably model the delays in our trace.

To determine the architecture of the HMM (number of states and transitions), we used the results from the stream arrival and traffic analysis. The overview of the HMM measurement and update process using PrivCount is illustrated in Figure 5.