level codes and themes [17], and ﬁnalize our framework.
We conducted credibility checks of our framework and
ﬁndings to verify they were accurate and clear. Seven experts
who have worked with at-risk populations reviewed a version
of this paper and met with us to discuss it. All experts found
the framework sound and useful.
D. Limitations
Our 95-paper dataset is not exhaustive of all relevant pa-
pers published in the security, privacy, or HCI communities.
However, given our systematic method of compiling papers,
it should reasonably represent these communities’ published
understanding of at-risk users. Also, reﬂecting the current
state of literature from these communities, the dataset papers
skewed heavily toward Western, and speciﬁcally U.S., popu-
lations. In addition, literature from other ﬁelds, especially the
social sciences, could oﬀer relevant perspectives on the digital
safety of at-risk populations. (See the appendix for details on
geographic representation and researcher reﬂexivity.)
As research methods and best practices for understanding
at-risk users are still being developed—often diﬀering from
one community to the next—the papers in our dataset also
often did not focus on the same issues or investigate to the
same depth. As a result, our synthesis of the contextual risk
factors, protective practices, and barriers covered in this paper
may not reﬂect all the challenges the population in question
experiences. Our coding is, instead, a reﬂection of the current
understanding in the sampled literature on each population.
Despite these limitations, we believe this work serves as a
critical ﬁrst step towards recognizing contextual risk factors
and protective practices that span at-risk users. We advocate
for future work that builds on this framework by including
broader literature and cultural perspectives.
that we identiﬁed at
least one prior study of an at-risk
population that reported risks related to that factor. We caution
that the absence of a black circle for an at-risk population in
Table I does not imply that the risk factor is irrelevant to the
population, only that it was not reported in our dataset.
Next, we describe each contextual factor, focusing on the
nature of the risk and types of associated attackers4 and harms,
as applicable. We also explore how risk factors may intersect
to create more severe risks.
A. Societal factors
The ﬁrst set of contextual risk factors involve societal fac-
tors amorphously driven by cultures and institutions. Attacks
related to societal risk factors tended to be diﬀusely targeted,
i.e., directed toward anyone in a population or an entire at-risk
population simultaneously, rather than at a speciﬁc person.
Legal or political. The government, political aﬀairs, or laws
of a country can contribute to at-risk populations experiencing
heightened digital-safety risks, including potentially sophisti-
cated attacks from government actors. A key theme associated
with this factor was the power diﬀerential between government
or quasi-governmental actors and the targeted populations.
Government or quasi-government actors may be able to
intercept communications from at-risk populations in various
ways, such as physically seizing devices or data [55, 67],
impersonating trusted entities [59], coercing platform or tele-
phony providers to bypass security measures [90], or prevent-
ing internet access entirely [25]. For example, in 2019, the Su-
danese government shut oﬀ the country’s mobile data network
to make organizing for activism as diﬃcult as possible [25].
Similarly, the International Committee of the Red Cross—a
non-governmental organization (NGO) that collects informa-
tion that could be used by armed groups for non-humanitarian
intelligence—reported being obligated to physically surrender
devices to meet with those armed groups [55].
Governments may also be able to enact surveillance, leading
to real or perceived threats of monitoring. For example,
undocumented immigrants in the U.S. reported concern about
posting their activities on social media, due to perceived
government monitoring [40]. More generally, residents of sev-
eral countries with government-controlled internet surveillance
have reported modifying their behavior [46, 89, 109].
Because of the power diﬀerential, threats associated with
this factor may also escalate into oﬄine harms, such as detain-
ment, incarceration, or deportation [25, 40]. These harms may
also have wide-ranging societal impacts, including restricted
or self-censored speech [49, 101] or lasting damage to trust in
public institutions or ﬁgures [21, 68]. For example, attacks on
people involved with U.S. political campaigns were described
as intending to undermine the institution of U.S. elections [21].
Marginalization. Pervasive negative treatment or exclusion at
a societal level, due to an individual’s identity attributes or life
experiences, may also elevate digital-safety risk.
4We use attacker broadly to refer to anyone who introduces digital-safety
issues for an at-risk user, regardless of the severity or intention.
IV. CONTEXTUAL RISK FACTORS
In our meta-analysis, we identiﬁed 10 contextual risk fac-
tors that augmented or ampliﬁed digital-safety risks. These
risk factors, which form the ﬁrst component of our at-risk
framework, include: three societal factors, inﬂuenced by an at-
risk user’s role in their society and culture; three relationship
factors stemming from who an at-risk user knows or interacts
with; and four personal circumstances dependent on who an
at-risk user is or their personal or professional activities. We
note some common attacks for each risk factor, but do not
consider being the target of a digital attack alone a risk factor.
We capture the presence of these risk factors within the
papers from our dataset in Table I. A black circle ((cid:32)) indicates
32346
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 13:11:21 UTC from IEEE Xplore.  Restrictions apply. 
Societal
factors
Relationships
Personal
circumstances
l
a
c
i
t
i
l
o
p
r
o
l
a
g
e
L
n
o
i
t
a
z
i
l
a
n
i
g
r
a
M
s
m
r
o
n
l
a
i
c
o
S
r
e
k
c
a
t
t
a
e
h
t
h
t
i
w
p
i
h
s
n
o
i
t
a
l
e
R
s
r
e
s
u
k
s
i
r
-
t
a
r
e
h
t
o
o
t
s
s
e
c
c
A
y
t
r
a
p
d
r
i
h
t
a
n
o
e
c
n
a
i
l
e
R
s
d
e
e
n
y
t
i
l
i
b
i
s
s
e
c
c
a
d
e
v
r
e
s
r
e
d
n
U
d
e
n
i
a
r
t
s
n
o
c
e
m
i
t
r
o
e
c
r
u
o
s
e
R
e
c
r
u
o
s
e
r
e
v
i
t
i
s
n
e
s
a
o
t
s
s
e
c
c
A
e
c
n
e
n
i
m
o
r
P
(cid:32)
(cid:32)
(cid:32)
(cid:32)
(cid:32)
(cid:32)
(cid:32)
(cid:32)
(cid:32)
(cid:32)
(cid:32)
(cid:32)
(cid:32)
(cid:32) (cid:32)
(cid:32)
(cid:32)
(cid:32) (cid:32) (cid:32)
(cid:32) (cid:32)
(cid:32)
(cid:32)
(cid:32) (cid:32)
(cid:32)
(cid:32)
(cid:32) (cid:32)
(cid:32)
(cid:32) (cid:32)
(cid:32)