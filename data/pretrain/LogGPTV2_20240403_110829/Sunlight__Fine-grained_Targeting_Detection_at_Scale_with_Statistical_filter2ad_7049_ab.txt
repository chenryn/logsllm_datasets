ciated design space.  In web transparency, evaluation is extremely 
challenging because ground truth of targeting effects is unknown. 
Manual assessment is sometimes used in prior work [8, 18], but it 
is, in our experience, extremely prone to error (see §6.6). Inability 
to quantify the accuracy (precision, recall) of an algorithm makes it 
difﬁcult to explore the design space and understand its trade-offs. 
This paper seeks to ﬁll in the preceding gaps by presenting:  (1) 
The ﬁrst generic web transparency methodology that provides both 
scalability and robust statistical conﬁdence for individual inferences. 
(2) An implementation of this methodology in Sunlight. Sunlight’s 
design is inspired by XRay and AdFisher, but improves both in sig­
niﬁcant ways (see §8 for detailed comparison). (3) An approach for 
evaluating the design space of a transparency system like Sunlight. 
We next begin by describing Sunlight’s methodology. 
3  The Sunlight Methodology 
A core contribution in Sunlight is the development of a princi­
pled methodology for web targeting investigations, which follows 
what we believe are important principles to follow when building 
infrastructures for other types of web transparency investigations. 
3.1  Design Principles 
• Design for scale and generality.  The web is big; the number of 
services and third-parties that could be targeting the users is gigan­
tic. The kinds of personal data they could be using as inputs of their 
targeting are many and diverse. The number of service outputs that 
Privacy 
putative 
Investigator 
inputs/outputs 
Data Collection 
training set 
Stage 1: 
Scalable Hyp. 
Generation 
validated 
interpretable 
hypotheses 
+ p-values 
testing set 
targeting 
hypotheses 
(raw form) 
Stage 4: 
Multiple Testing 
Correction 
interpretable 
hypotheses 
+ p-values 
Stage 3: 
Hypothesis 
Testing 
interpretable 
hypotheses 
Stage 2: 
Interpretable 
Hyp.  Formation 
Figure 1:  The Sunlight methodology.  Consists of a four-phase pipeline: 
(1) scalable hypothesis generation, (2) interpretable hypothesis formation, 
(3) hypothesis testing, and (4) multiple test correction. 
could be targeted at the users is immense. Reliability and trust in an 
investigation’s results depend not only on the methodologies used 
but also on the scale at which conclusions are reached.  Sunlight 
must thus support large-scale investigations, both in terms of the 
number of inputs being tracked and in terms of the number of out­
puts, as well as – to the extent possible – in terms of the services 
to which it is applied.  This last goal requires us to minimize the 
assumptions we make about the inspected service(s). 
• Provide robust statistical justiﬁcation for all inferences.  Trust­
worthiness in the results is key to an investigation, hence Sunlight 
must provide robust conﬁdence assessments for its inferences. The 
metrics must be understandable and broadly accepted by the com­
munity.  Where possible, Sunlight should be able to make causal 
claims about its inferences, and not simply correlations, which are 
more difﬁcult to reason about.  Enforcing high conﬁdence for all 
ﬁndings may result in missing some.  We believe that correct ﬁnd­
ings are preferable to complete ﬁndings.  Sunlight hence attempts 
to limit such effects, but given a choice favors precision over recall. 
• Ensure interpretability of inferences. A key challenge with many 
machine learning or statistics mechanisms is that their inferences 
are often not easily interpretable, and post hoc interpretations may 
not have been statistically validated.  Interpretability is a critical 
aspect of a transparency system as people are the consumers of the 
system’s output.  Sunlight explicitly integrates a rudimentary but 
effective  technique  to  ensure  that  its  inferences  are  interpretable 
and statistically validated in these interpretable forms. 
To  the  best  of  our  knowledge,  Sunlight  is  the  ﬁrst  web  trans­
parency system to closely follow all these principles.  It can cur­
rently run on hundreds of virtual machines to process data from 
targeting  experiments,  and  precisely  detects  targeting  of  tens  of 
thousands of Gmail and web ads, testing hundreds of inputs simul­
taneously. It minimizes the assumptions it makes about the services 
and provides statistically signiﬁcant and interpretable results. 
3.2  Methodology 
Fig.1 shows the Sunlight methodology.  It consists of a pipeline 
with four data analysis stages. Those stages depend on experimen­
tal data from an initial data collection step determined by the inves­
tigator. Data collection begins with the creation of several ﬁctitious 
user proﬁles, each with randomly-assigned input attributes (called 
inputs) which are potentially visible to an ad targeting mechanism. 
For instance, an input may indicate the presence of a particular e­
mail in the user proﬁle’s webmail inbox,  or that the user proﬁle 
was used to visit a particular website.  Then, each user proﬁle is 
used to measure several potential effects of targeting mechanisms 
(outputs), such as speciﬁc ad displays shown on browser visits to 
a news website or webmail service.  The inputs should be speci­
ﬁed a priori, and for various reasons which we discuss later, it will 
be desirable that the random assignment of input values be statisti­
cally independent (across different inputs and across different user 
proﬁles); the outputs may be speciﬁed generically (e.g., all possi­
ble ads displayed in ten refreshes of cnn.com), so that the set of 
outputs is only determined post hoc.  The end result is a data set 
comprised of inputs and output measurements for each proﬁle. 
At its core, the Sunlight methodology analyzes the collected data 
set using a sample-splitting approach (sometimes called the “hold­
out method” in machine learning) to generate and evaluate target­
ing hypotheses. The proﬁles in the data set are randomly split into 
a training set and a testing set.  In Stage 1 (Scalable Hypothesis 
Generation), we apply scalable classiﬁcation and regression meth­
ods to the training set to generate prediction functions that can ex­
plain the output measurements for a user proﬁle (e.g., indicator of 
whether a particular ad was displayed to the user) using the pro­
ﬁle’s input attributes.  We focus on scalable methods that generate 
simple functions of a small number of inputs so that they are readily 
interpretable as targeting hypotheses, and take explicit measures in 
Stage 2 (Interpretable Hypothesis Formation) to ensure this if 
necessary. In addition, we discard any prediction functions that fail 
some simple sanity checks so as to reduce the number of targeting 
hypotheses; this again is performed just using the training set.  At 
the end of Stage 2,  we have a ﬁltered collection of interpretable 
targeting hypotheses generated using only the training set. 
In Stage 3 (Hypothesis Testing), each such hypothesis is then 
evaluated  on  the  testing  set  using  a  statistical  test  to  generate  a 
measure of conﬁdence in the targeting hypothesis—speciﬁcally, a 
p-value.  The p-value computations may make use of the known 
probability distributions used to assign input values in the test set 
proﬁles, and each targeting hypothesis’ p-value should be valid un­
der  minimal  assumptions.  Because  such  statistical  tests  may  be 
conducted for many targeting hypotheses (e.g., possibly several tar­
geted ads), we ﬁnally apply a correction to these conﬁdence scores 
in Stage 4 (Multiple Testing Correction) so that they are simulta­
neously valid.  We may then ﬁlter the targeting hypotheses to just 
those with sufﬁciently high conﬁdence scores, so that the end result 
is a statistically-validated set of interpretable targeting hypotheses. 
3.3  Threat Model and Assumptions 
Like all prior transparency systems of which we are aware, we 
assume that Web services, advertisers, trackers, and any other par­
ties involved in the web data ecosystem, do not attempt to frustrate 
Sunlight’s targeting detection. In the future, we believe that robust­
ness  against  malicious  adversaries  should  become  a  core  design 
principle, but this paper does not provide such progress. Moreover, 
we assume that the users leveraging Sunlight are tech-savvy and 
capable of developing the measurement data collection necessary 
to collect the data.  Sunlight enables targeting detection given the 
experimental datasets obtained through independent means. 
While Sunlight can establish correlation and even causation in 
some circumstances between particular inputs and targeted outputs 
(within some conﬁdence level), it cannot attribute targeting deci­
sions to particular parties (e.g., advertisers, ad networks, trackers, 
etc.), nor can it distinguish between intentional targeting (e.g., ad­
vertisers choosing to target users in a particular category) versus 
algorithmic decisions (e.g.  an unsupervised algorithm decides to 
target a particular population of users based on patterns of prior 
ad clicks).  Moreover, because Sunlight’s correlations and causa­
tions are obtained from controlled experiments with synthetic user 
proﬁles, its ﬁndings are not guaranteed to be representative of the 
targeting on the real population. Finally, while Sunlight can detect 
certain combined-input targeting, it cannot detect all forms of tar­
geting, but rather only targeting on disjunctive (OR) combinations 
of a limited number of controlled inputs. 
Given all of these constraints, Sunlight is best used in contexts 
where its results inform and provide believable justiﬁcation for sub­
sequent investigations through independent means aimed at estab­
lishing the “truth.” Our scenarios in §2.1 fall into this category. 
hypotheses; our focus on this class here serves as a starting point 
for building up techniques for other hypothesis classes. 
Even with the restriction to the simple class of disjunction for­
mulae, we face formidable computational challenges.  Finding the 
most accurate such disjunction on an arbitrary training set is gen­
erally computationally intractable in very strong senses [11], with 
brute force enumeration requiring ⌦(dk) time for d inputs. There­
fore, we can only hope to ﬁnd accurate small disjunction hypothe­
ses that have additional special structure.  In some cases, we can 
use a two-step greedy approach to ﬁnd such disjunction hypothe­
ses:  (i) we ﬁrst use scalable classiﬁcation and regression methods 
to order the inputs by some measure of relevance—e.g., by their av­
erage correlation with the output across user proﬁles in the training 
set (this stage); then (ii) we use this ordering over inputs to greed­
ily construct a disjunction with sufﬁciently high accuracy on the 
training set (Stage 2).  Under other conditions, it may be possible 
to directly form small disjunction hypotheses. We discuss some of 
these approaches in more detail below. 
Sparse regression. Our ﬁrst technique for ordering inputs is based 
on  linear  regression.  In  our  application,  each  of  the  d  inputs  is 
regarded as a (boolean) predictive variable, and our goal is to ﬁnd a 
linear combination of these d variables x  = (x1, x2, . . . , xd) that 
predicts an associated output measurement.  The coefﬁcients w  = 
(w1, w2, . . . , wd) used to form the linear combination hw, xi  = 
Pd
i=1 wixi  are called the regression coefﬁcients, and these can be 
regarded as a measure of association between the inputs and the 
output.  These  coefﬁcients  are  estimated  from  a  collection  of  d-
dimensional data vectors,  which in our setting are the vectors of 
input attributes for each proﬁle in the training set. 
We use a sparse linear regression method called Lasso [26] to es­
timate the regression coefﬁcients w. Lasso is speciﬁcally designed 
to handle the setting where the number of inputs may exceed the 
number n of data vectors (i.e., user proﬁles) in the training set, as 
long as the number of non-zero regression coefﬁcients is expected 
to be small—i.e., the coefﬁcient vector is sparse.  This sparsity as­
sumption entails that only a few inputs are,  in combination,  cor­
related  with  the  output.  Under  certain  conditions  on  the  n  data 
vectors (which we ensure are likely to be satisﬁed by construction 
of our user proﬁles), Lasso accurately estimates the coefﬁcients as 
long as n 2 O(k log d), where k is the number of non-zero coefﬁ­
cients [4]—i.e., the number of input variables potentially correlated 
with the output. In fact, this collection of O(k log d) input vectors 
supports the simultaneous estimation of multiple coefﬁcient vec­
tors for different outputs (e.g., different ads), a consequence of the 
same phenomenon that underlies compressed sensing [9]. 
Linear regression permits the use of additional variables for un­
controlled factors (e.g.,  time-of-day,  IP address of machine used 
to collect data) to help guard against erroneous input/output asso­
ciations  that  could  otherwise  be  explained  by  these  factors.  For 
instance, some ads may be shown more during work hours to target 
ofﬁce workers, but the time-of-day in which data is collected for 
certain proﬁles could inadvertently be correlated with some inputs. 
Including time-of-day as a variable in the regression model helps 
suppress these unwanted associations. 
We also consider the use of a generalized linear model called 
logistic regression,  which is especially suited for binary outputs. 
This model posits that Pr[output = 1] = g(hx, wi), where g(z) = 
1/(1 + e-z ).  To  estimate  regression  coefﬁcients  in  this  model, 
we  use  a  variant  of  Lasso  called  L1-regularized  logistic  regres­
sion [23], whose effectiveness has been established in several em­
pirical studies across multiple domains (e.g., [5, 28]). As in Lasso, 
we are able to regard the inputs with large estimated coefﬁcients as 
likely to be relevant in predicting the output (and this would not be 
Figure 2:  The Sunlight modular pipeline.  Grey boxes show the default 
pipeline,  which in our experience strikes a good balance between results 
conﬁdence and interpretability versus support for large-scale investigations. 
4  The Sunlight System 
Sunlight instantiates the preceding methodology to detect, val­
idate, and report the likely causes of targeting phenomena on the 
web.  This raises three signiﬁcant challenges.  First, at each stage, 
unique aspects of our domain require careful modeling of the prob­
lem to map them onto appropriate statistical mechanisms. Second, 
across stages, mechanisms may interact in subtle ways and require 
careful and challenging co-designs.  For example, as §6 shows, a 
design  choice  to  use  a  permissive  classiﬁcation  at  Stage  1  (high 
recall but low precision, as proposed in XRay [18]) results in sig­
niﬁcant penalty due to correction in Stage 4 and failure to validate 
many true hypotheses (i.e., poor recall at the end of the Sunlight 
pipeline).  In  contrast,  a  stricter  Stage  1  method  that  we  devel­
oped for Sunlight (§4.1), which has comparatively lower recall but 
higher precision in it of itself results in better recall at the end of 
the Sunlight pipeline. Thus, a second key contribution in this paper 
is to identify the key requirements that must be met by the mech­
anisms we use at each stage of the pipeline and combine them in 
ways that provide scalability, conﬁdence, and interpretability. 
To  address  these  challenges,  we  have  designed  Sunlight  to  be 
modular.  It allows both the instantiation of multiple pipelines and 
the evaluation and comparison at different levels of the pipeline. 
This provides two beneﬁts. First, it lets us explore the design space 
and choose the best combination of mechanisms for our problem. 
Second,  it  lets  our  users  –  researchers  and  investigators  –  adapt 
Sunlight to their own needs.  For example, some mechanisms pro­
vide  conﬁdence  at  scale  while  others  provide  superior  statistical 
guarantees; with Sunlight users can make the choices they prefer. 
Fig.2 lists the mechanisms we currently support at each stage, some 
of them which we imported from prior literature, others we devel­
oped to address limitations of prior mechanisms. We next describe 
the mechanisms at each stage. 
4.1  Stage 1: Scalable Hypothesis Generation 
We generate interpretable targeting hypotheses by applying clas­
siﬁcation and regression methods to the training set; the hypothe­
ses  are  formulated  as  interpretable  functions  of  a  proﬁles’  input 
attributes that can explain the corresponding output measurements. 
In  machine  learning  parlance,  we  train  predictors  of  the  outputs 
based on the inputs (as input variables). To ensure that the hypothe­
ses are interpretable, we explicitly seek predictors that only depend 
on a few inputs, and that only have a simple functional form. To this 
end, we restrict attention to hypotheses about the output that can be 
represented as a disjunction formula over at most k inputs for some 
small integer number k (here we also assume for simplicity that in­
puts and outputs are binary-valued). This class of small disjunction 
formulae is one of the simplest classes of natural and interpretable 
  Stage 1:ScalableHypothesisGenerationStage 2:InterpretableHypothesisFormationStage 3:HypothesisTestingStage 4:MultipleTestingCorrectionlogisticregression(logit)linearregression(lm)set intersectionalgo(from XRay)bayesianalgo(from XRay)logicalcombinationsexactsignificancetestrandompermutationtestBenjamini-Yekutieli(BY)Holm-Bonferroni(Holm)Figure 3:  Interpretable vs.  raw hypothesis.  (Left) Targeting hypothe­
sis formulated as disjunction of inputs.  (Right) Raw hypothesis based on 
logistic regression parameters. 
the case if we used unregularized or L2-regularized logistic regres­
sion, at least in this n ⌧ d regime). 
Methods from XRay [18].  For direct comparison to prior art, we 
also implement two algorithms used in XRay [18] to identify in­
puts that may be triggering targeting outputs. While the algorithms 
are shown to be asymptotically exact, the system provides no sta­
tistical conﬁdence or guarantee for individual inferences.  The ﬁrst 
algorithm is Set Intersection, which orders inputs by the fraction 
of proﬁles where the output is present they are covering.  In other 
words, the best candidates for targeted inputs are the one present in 
the largest fraction of the proﬁles with the output. The second algo­
rithm from XRay is a Bayesian algorithm, which uses a particular 
generative model for the targeting to compute posterior probabili­
ties that each input is targeted by an output.  The algorithm orders 
the inputs by these probabilities. 
4.2  Stage 2: Interpretable Hypothesis Formation 
Given an ordering over the inputs, we form disjunctions of inputs 
in a greedy fashion.  Speciﬁcally, we ﬁrst consider a singleton dis­
junction with the ﬁrst input on the list, then a disjunction of the ﬁrst 
two inputs on the list, and so on. We proceed as long as the training 
accuracy of the disjunction (in predicting the output for proﬁles in 
the training set) is sufﬁciently high; the criterion we use to deter­
mine this threshold is just a heuristic, but is similar to the hypoth­
esis test used in the testing stage (§4.3).  The largest sufﬁciently 
accurate disjunction is then taken (together with the associated out­
put) as a targeting hypothesis. For some outputs, it is possible that 
even the singleton disjunction lacks high-enough accuracy; in such 
cases no hypothesis is formed. 
Fig.3 shows an example of this transformation for a hypothesis 
based on logistic regression. The leftside hypothesis says a proﬁle 
is targeted if it has at least one of the shown inputs; the rightside 
hypothesis says a proﬁle is targeted if the sum of coefﬁcients for the 
inputs in the proﬁle is greater than zero.  The latter appears more 
difﬁcult to interpret than the former. 
An alternative is to forgo interpretability and seek out out any 
kind of potential association between inputs and outputs.  For in­
stance, we could look for associations between arbitrary functions 
of inputs and outputs by using richer classes of prediction functions 
beyond  simple  disjunctions  (e.g.,  arbitrary  linear  threshold  func­
tions),  as well as by using other ﬂexible measures of association 
(e.g., [14]).  Such associations may be much easier to detect and 
statistically validate, but they may not be readily interpretable nor 
easy to reason about in a follow-up studies. 
An important and subtle note is that if interpretability is impor­
tant,  then any transformation needed for interpretation should be 
applied at this stage.  For example, an intuitive but incorrect way 
of interpreting a result from Sunlight would be to generate raw hy­