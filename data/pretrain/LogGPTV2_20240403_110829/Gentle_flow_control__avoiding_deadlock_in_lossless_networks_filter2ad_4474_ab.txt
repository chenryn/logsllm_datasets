network devices to generate probing packets and support special
protocols processing them. In addition, after detecting the existing
loop, dropping packets and heuristic rerouting are main recovering
solutions [2, 3, 36, 38, 52], which are very disruptive [24].
Compared with recovery, avoidance is a much more proactive
and efficient approach since it can eradicate the root cause of dead-
lock.
3.2 Why avoiding hold and wait?
To avoid deadlock, one of its necessary conditions needs to be bro-
ken. As aforementioned, there are totally four necessary conditions.
Both mutual exclusion and no preemption are unbreakable in lossless
networks: buffer resource is inherently mutual exclusive and the
lossless requirement enforces the no preemption condition must be
satisfied.
Existing deadlock avoidance solutions mainly focus on breaking
the circular wait condition. Many CBD-free routing solutions have
been proposed [7, 13–15, 17, 18, 21, 50, 54–56, 58]. The basic idea
is restricting routings to guarantee no combination of flows could
form CBD. However, these solutions introduce great limitations
to network configurations and disable some advantages (e.g., bal-
ancing load through intrinsic multiple paths). Another approach
is to isolate CBD-prone flows into different virtual channels and
employ independent queues to serve them [6, 20, 35]. However, the
required number of priority queues increases with network scale,
which greatly affects the scalability. Tagger [25] follows the similar
idea but requires less priority queues. Nevertheless, its dynamic
management of packet priority is complex and packets would be
dropped when priority queues are not enough. To decrease the
required resources, other dynamic deadlock avoidance solutions
are also developed [16, 46]. They have no restrictions on network
when running normally. However, when the buffer is full, strict
restrictions are still imposed for avoiding the occurrence of CBD.
Once system enters the deadlock avoidance status, the performance
decreases drastically and it takes a long time to recover back.
We attempt to work out a brand-new solution to break the hold
and wait condition, which, to the best of our knowledge, is an
unexplored approach to overcome network deadlock.
Feasibility: Primarily, is eliminating hold and wait condition
feasible? The answer is positive. Existing flow control mechanisms
manage port rate in a coarse way (ON/OF F) to achieve the match-
ing between input rate and draining rate. It is the root cause of
frequent occurrences of hold and wait. For each port, as long as
the input rate is elaborately controlled to match its draining rate,
all flows can continuously pass through the network even if CBD
exists. In this situation, all flows maintain proper sending rates. The
queue length in each port will keep steady and never trigger hold
and wait. For example, we consider again the deadlock scenario
in Figure 1. Assume the line rate is 10Gbps, as long as all hosts
keep sending packets at 5Gbps, every flow can continuously pass
through the network. The queue length in each port is steady and
no hold and wait occurs. Therefore, the key to avoiding hold and
wait is designing a novel flow control mechanism, which can gently
match the sending rate of upstream port with the draining rate of
downstream port.
4 DESIGN
The basic idea is to design a flow control scheme which adjusts the
sending rate at a fine granularity. Thus packets can consecutively
flow and further hold and wait is eliminated.
This section first presents the conceptual design of GFC, and
demonstrates it can completely avoid the occurrence of hold and
wait. However, the conceptual scheme assumes feedback messages
can be generated continuously, which is impractical. We further
propose the practical design of GFC that occupies only a little
bandwidth resource while eliminating hold and wait.
4.1 Conceptual Design
Figure 4(a) presents our conceptual scheme, which contains two
main functional components: Message Generator and Rate Adjuster.
Message Generator monitors the instantaneous ingress queue length
and generates feedback messages carrying the related information
back to upstream ports. We first assume that flow control messages
can be generated continuously (this constraint will be removed in
the subsequent practical design). Rate Adjuster in the upstream
port receives feedback messages, parses queue length information,
and calculates the sending rate according to the given mapping
function. Then the upstream port will send packets in line with this
rate. An illustrative mapping function is depicted in Figure 4(b),
where B is the input queue buffer size and Bm ≤ B. Initially, the
sender is allowed to transmit packets at line rate. When the ingress
queue length in the downstream port exceeds the threshold B0, the
upstream port begins to decrease its sending rate. The rate decre-
ment is proportional to the downstream port queue length. So with
queue length increasing, the gap between sending rate and draining
rate becomes smaller. Eventually, the system enters a steady state
where the sending rate matches the draining rate and the ingress
queue length keeps unchanged. Leveraging this fine-grained rate
adjustment, switches can prevent packet loss without triggering
hold and wait. Essentially, the basic operation in GFC is still match-
ing the sending rate with the draining rate, which is the same as
existing hop-by-hop flow controls (PFC and CBFC). Thus, in the
long time scale, GFC would not waste forward available bandwidth.
Firstly, we use a simple example to demonstrate how conceptual
GFC works to avoid hold and wait. Consider a 2-to-1 case where
two flows from different input ports compete for the same output
port, a general congestion situation where sending rate > draining
rate. The link capacity is 10Gbps so the draining rate of each ingress
queue is 5Gbps. The feedback latency τ (the time interval between
generating a feedback message and receiver perceiving the input
rate changing accordingly) is 25µs. The maximum buffer size Bm
and B0 are 100KB and 50KB, respectively. We employ PFC as the
baseline comparison (results of CBFC are similar). XOF F is 80KB,
and XON is 77KB (the recommended interval between XOF F and
XON is 2MTU [59]). Figure 5(a) shows the simulation results. Under
PFC, the ingress queue length first directly exceeds XOF F and
then fluctuates near XON and XOF F. The sending rate alternates
between zero and line rate accordingly. After the system enters the
steady state, the intervals between ceasing and full-rate sending
are identical, so PFC regulates the sending rate to the draining
rate in the long term. Obviously, the upstream port goes into the
cease status frequently. Thus, packets in the upstream egress queue
78
Gentle Flow Control: Avoiding Deadlock in Lossless Networks
SIGCOMM ’19, August 19–23, 2019, Beijing, China
(a) Conceptual GFC
(b) Mapping function
Figure 4: Conceptual design.
and its maximum value △B = τ( ¯Ri − ¯Rd) ≤ τ ¯Ri, where ¯Ri and
¯Rd denote the average input rate and draining rate in the interval
τ, respectively. According to the mapping function, if remaining
buffer (Bm − Bs) is small, then ¯Ri would be small, and vice versa
(i.e., ¯Ri ∝ Bm − Bs). So the worst-case value of ∆B is positively
correlated with τ(Bm − Bs) under the linear mapping function. In
hence, as long as we can set the slope of mapping function (i.e.,
) small enough, then overshoot (△B) can always be absorbed
Bm−B0
by the remaining buffer (Bm −Bs). It means that queue length never
reaches Bm and input rate never goes to zero. In this way, hold and
wait is completely eliminated.
Employing some mathematical methods, we give Theorem 4.1 to
determine the strict constraint for eliminating hold and wait. The
detailed deduction can be found in Appendix A.
C
Theorem 4.1. In conceptual GFC, if B0 ≤ Bm − 4Cτ , hold and
wait can be avoided.
Setting mapping function strictly following Theorem 4.1, sending
rate would never reach zero and the ingress queue length never
reach Bm. So Bm can be directly set equal to the buffer size B.
This conceptual design is impractical because sending feedback
messages too frequently will greatly waste backward bandwidth.
In the following part, we propose the practical GFC, which only
occupies a small portion of bandwidth.
4.2 Practical Design
In order to suppress excessive feedback messages, we change the
continuous mapping function to the step function, as shown in
Figure 6. Thus the receiver only sends feedback messages when
the queue length changes from one stage to another. Message Gen-
erator monitors the ingress queue length. When the queue length
steps into a new stage (e.g., the ith stage), it generates a new feed-
back message carrying the stage ID i back to the sender. On the
sender side, when Rate Adjuster receives a feedback message, it
parses out i, maps it to the target rate, and changes the sending
rate correspondingly.
Intuitively, decreasing the frequency of message generation leads
to coarse-grained feedback and may further aggravate the buffer
overshoot. So the design of stage mapping function is crucial for
avoiding hold and wait. Next, we discuss how to fix the stage map-
ping function. There are three key parameters: the queue length at
the start of the nth stage Bn, the corresponding sending rate of the
nth stage Rn, and the total number of stages N .
(a) PFC
(b) GFC
Figure 5: Evolutions of input rate and queue length.
experience the hold and wait situation. If increasing the gap between
XOF F and XON , the fluctuation period will increase and so will
the duration of each hold and wait phase, which is more prone to
deadlock. The results of GFC are shown in Figure 5(b). When the
ingress queue length exceeds B0, the sender is notified to decrease
rate accordingly. The gap between sending rate and draining rate
decreases so the ingress queue length increases slower. Finally, the
ingress queue length stays at the steady-state value Bs (Bs = 75KB
in this case), where the sending rate equals the draining rate.
Ideally, if the feedback delay τ = 0, the input rate changes strictly
in line with the mapping function. Then the ingress queue length
will directly converge to the stable point where the sending rate
equals to the draining rate. So packets can continuously transmitted
without triggering hold and wait and there is further no deadlock.
However, τ is nonnegligible in practice. It postpones the reactions
to feedback messages, which may lead to queue length overshoot
and introduces the overflow risk. In order to totally avoid hold and
wait, the mapping function should be carefully settled.
If Bm−B0 is large, abundant buffer room is reserved for absorbing
overshoot. However, it also means more buffer space is required.
In the practical network, the switch buffer is shallow and precious.
Therefore, it is an important task to determine the proper value
of B0. Next, we will theoretically find out the bound of B0, and
demonstrate it can completely avoid hold and wait in the flow
control procedures.
Eliminating hold and wait: We first give an intuitive explana-
tion why our proposed conceptual design can eliminate hold and
wait. Then the strict condition for eliminating hold and wait is
provided. Generally, overshoot starts when ingress queue length
increases to Bs. The Message Generator sends a message containing
Bs to the upstream port. However, it needs τ to make input rate
Ri decrease to Rd. So overshoot accumulates during this interval,
79
MessageGeneratorQueueLengthRate AdjusterDatagramSending Rate (Rs) Input Rate(Ri) Draining Rate(Rd) Upstream Port(Sender)Downstream Port(Receiver)QLFeedback MessageRateQueuelengthBmB0BC 0 2 4 6 8 10 0 100 200 300 400 500 0 20 40 60 80 100Rate (Gbps)Length (KB)Time (us)Queue lengthInput rate Hold and wait XOFF 0 2 4 6 8 10 0 200 400 600 800 0 20 40 60 80 100 Overshoot BsRate (Gbps)Length (KB)Time (us)Queue lengthInput rateSIGCOMM ’19, August 19–23, 2019, Beijing, China
Kun Qian, Wenxue Cheng, Tong Zhang, Fengyuan Ren
Figure 6: Multi-stage mapping function.
Bn and Rn: The length of each stage plays an important role
in avoiding hold and wait. If the lengths of stages are too small,
the input buffer may be quickly exhausted before triggering the
upstream port decreasing the sending rate. On the other hand,
limited buffer resource disallows setting oversize stages.
In practical GFC, we propose a safe way to determine the length
of each stage: for any k ≥ 1, before the ingress queue length exceeds
the kth stage, the input rate should have already changed to Rk.
To achieve this goal, the length of a stage should be large enough
for the feedback message to take effect. Therefore, the relationship
between Bk and Rk should be
(1)
To keep accordance with the linear decreasing, the stage function
needs to satisfy
Bk +1 − Bk ≥ Rk−1τ
Bk − Bk−1
Rk−1 − Rk
Combining (1) and (2), we have:
1 −
(cid:18)
Rk ≤
= Bm − B0
(cid:19)
C
Cτ
Bm − B0
Rk−1
(2)
(3)
According to Theorem 4.1, the constraint for eliminating hold and
wait is B0 ≤ Bm −4Cτ. Substituting it into (3), we have Rk ≤ 3
4 Rk−1.
We select
1
2 Rk−1 =
1
2k C
(4)
Rk =
Combining (2), we also have
1
Bm − Bk =
2k
(Bm − B0) ≥ 22−kCτ
(5)
Note that the stage 0 [B0, B1) has the same function as when the
queue length is below B0, thus we remove the stage 0. In other
words, the buffer length should be larger than Bm − B1. According
to (5), Bm−B1 ≥ 2Cτ, thus the buffer size just needs to be larger than
2Cτ. Notice that the required headroom in PFC is at least Cτ [27],
so 2Cτ of buffer length is an attainable constraint in practice.
N : According to Equation (4), Rn will infinitely approach but
never reach zero. So the number of stages should be infinite in
this step function. However, in real design, it is unnecessary and
impractical to set very small rates. Each time when Rn halves, the
remaining buffer halves too. In practice, the buffer is consumed
in unit of 8-bit. So once Bn − Bn−1 ≤ 8b, the following stages are
omissible.
Occupied bandwidth: By changing into multi-stage mapping
function, one may ask how much bandwidth expenditure is intro-
duced. Here we give a brief analysis. In the worst case, as discussed
in deducing Equation (1), feedback messages are generated every τ
Figure 7: PFC message type.
time. So the occupied bandwidth is m
, where m is the size of feed-
τ
back message. However, this worst-case situation is only a transient.
In steady status, the worst-case occupied bandwidth is only m8τ
. The
calculating details are omitted due to limited space. Taking 10GbE
as an example, m = 64B and τ = 7.4µs (detailed calculation of τ can
be found in Section 5.4), then the occupied bandwidth is 69Mbps
(0.69%) in the worst case and 8.6Mbps (0.086%) in the steady case,
which is very small.
5 IMPLEMENTATION
As introduced in Section 2.2, mainstream lossless networks have im-
plemented their own flow control frameworks. This section presents
how to implement GFC on the basis of these frameworks with
moderate modifications. Primarily, existing flow controls employ
different mechanisms to trigger the generation of feedback mes-
sages. (1) PFC generates a feedback message when the queue length
reaches the predefined threshold (buffer-based). (2) CBFC generates
messages periodically (time-based). We will present how to im-
plement GFC’s Message Generator and Rate Adjuster under these
two interaction modes, respectively. Next, compared with exist-
ing lossless flow controls, GFC requires a new component: Rate
Limiter. We show how to implement it with low overhead. The
whole processes of GFC can be implemented through updating the
firmware in commercial switches. Finally, the parameter settings