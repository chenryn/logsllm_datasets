and its own state to decide the action such as consume how many
bits and jump to which next state.
The complexity of the header directly affects the number of
entries in the parserâ€™s TCAM table. In a nutshell, the more headers
or the more transitions between the parser nodes, the more entries
in the TCAM table. For each header â„, Lyra can compute the entries
required to parse the header. For example, the TCP header requires
an entry that matches the ethernet.ether_type field. Because one
table entry ğ‘’ may be required by multiple headers, whether it should
be in the TCAM is decided by all related headerâ€™s validity. The above
entry is required by both TCP header and UDP header, so as long
as one header is valid, the entry should be deployed in the TCAM.
As a result, the deployment of an entry ğ·ğ‘’ is encoded as:
ğ·ğ‘’ =
ğ‘‰â„
(7)

â„âˆˆSğ‘’

ğ‘’
where Sğ‘’ denotes the set of headers that requires entry ğ‘’ to be
deployed in the TCAM. And we can compute the total number of
entries in the TCAM table by summing all ğ·ğ‘’ up:
ğ‘parser =
ğ·ğ‘’
(8)
In RMT [17], the maximum number of entries is 256, so ğ‘parser â‰¤
256. In reality, Lyra can skip this encoding when it figures out that
the header is not complex enough that even all headers are valid,
the encoded entries cannot overflow the TCAM table.
A.3 Packet Header Vector
Packet header vector (PHV) acts as the bus that transmitting the
data between the physical stages. It takes the data generated by
the parser and contains the fields used for matching and actionsâ€™
output. The basic component of PHV is called word. In RMT, there
are 64, 96, 64 words with 8, 16, and 32-bit width respectively. In
total, the width of the PHV is 4Kb.
How the fields are stored in the PHV is also interesting. Multiple
units of small words can be combined together to act as a larger
word. For example, to host a 48b source MAC address, RMT can
use either six 8-bit words, three 16-bit words, one 32-bit word, and
one 16-bit word, and so on.
Given a field ğ‘“ with length ğ‘™ğ‘“ , we can calculate all packing
strategies ğ¶ğ‘“ by dynamic programming. Each strategy ğ‘ is a three-
element tuple ğ‘ = (ğ‘0, ğ‘1, ğ‘2) that represents the number of words
used to hold the field. Because only one strategy is valid, we intro-
duce a Boolean variable ğµğ‘,ğ‘“ for each strategy and add the constraint
that only one of the Boolean variables can be true:

ğ‘âˆˆğ¶ğ‘“
(1 Â· ğµğ‘,ğ‘“ ) = 1
(9)
So take the 8-bit word as an example, the total PHV usage can
be encoded as:


ğ‘“ âˆˆF
ğ‘âˆˆğ¶ğ‘“
(cid:169)(cid:173)(cid:171)
ğ‘[0] Â· ğµğ‘,ğ‘“ Â· ğ‘‰ğ‘“(cid:170)(cid:174)(cid:172)
ğ‘8ğ‘ =
(10)
where F denotes all the fields including header fields and internal
variables, ğ‘‰ğ‘“ denotes the validity of the field ğ‘“ . If field ğ‘“ is an
internal variable, then ğ‘‰ğ‘“ = ğ‘‰ğ‘–, if it is a header field, then the
validity equals the validity of header â„, ğ‘‰ğ‘“ = ğ‘‰â„. Similarly, we can
encode the usage of 16 and 32-bit words. The total usage should
not exceed what is available in the RMT architecture.
A.4 Memory Block
All the table entries, action parameters, and stateful objects take
memory space. In RMT, the memory is counted in block: each stage
has 106 SRAM blocks of 1K entries with 80b width, 16 TCAM blocks
of 2K entries with 40b width.
To improve memory allocation efficiency, RMT introduces an ar-
chitectural trick called word-packing. The packing allows multiple
table entries packed together horizontally. For example, for a 48-bit
MAC address, one 80-bit-wide entry in the SRAM block can only
fit one entry, if we pack two memory blocks together and form a
160-bit wide, 1K entry packing unit, each entry can fit three 48-bit
MAC addresses.
RMT does not mention the maximum block packing capability;
thus, Lyra assumes it can pack as many blocks as possible. Suppose a
table requires ğ‘¤ bits match width and â„ entries, while each memory
block is ğ‘¤ğ‘š wide and has â„ğ‘š entries, the minimum number of
memory blocks can be computed as:
âŒˆ â„
âŒ‰ Â· ğ‘¤
â„ğ‘š
ğ‘¤ğ‘š
ğ‘memory = âŒˆ
(11)
âŒ‰
Without word-packing, the number of memory blocks is:
ğ‘memory = âŒˆ â„
â„ğ‘š
âŒ‰ Â· âŒˆ ğ‘¤
ğ‘¤ğ‘š
âŒ‰
(12)
For the assignment overhead, such as action parameters and
registers, Lyra uses the method introduced in Jose et al. [26] to
compensate for the overhead. As shown in RMT architecture [17,
26], if a table requires more blocks than a stage is able to provide,
it could expand to multiple stages to meet the requirement. The
memory block constraint is encoded along with the table constraint
introduced in Â§A.6.
A.5 Stateful Operations
RMT does not explain how to implement a stateful operation except
the counters and meters. So Lyra uses the solution introduced in
Domino [37] called atom. In a nutshell, an atom is a collection
of hardware circuits that able to perform comparison, arithmetic
operations, read and write in a single clock cycle. There are many
SIGCOMM â€™20, August 10â€“14, 2020, Virtual Event, NY, USA
types of atoms introduced in Domino [37], Lyra uses the most
powerful one called Pairs.
In a Lyra program, the global variable is the only component
that is stateful. When compiling to an RMT switch, Lyra uses the
algorithm introduced in Domino [37] to check if the algorithm can
fit into the atom. If not, then all the related instructions cannot be
deployed in this switch, Lyra has to find other switches to deploy
them. If so, replace all related instructions with an atom call. Note
that this computation is done before the preparation step because
it affects predicate block computations.
A.6 Table and Pipeline
Table is the core component of the RMT architecture and imple-
ments the logic of the data plane program. The RMT requires that
if one table ğ‘‡ğ‘ reads the output of another table ğ‘‡ğ‘, ğ‘‡ğ‘ must be
deployed in a stage after ğ‘‡ğ‘. On the other side, RMT has only 32
stages in the ingress and egress pipeline, and according to Jose et
al. [26], RMT only allows 8 tables per stage. So we have to deploy
the tables wisely.
As we stated earlier, each synthesized predicate block is a table
if it is deployed in the switch. Thus the tablesâ€™ dependency rela-
tionship is already encoded in the predicate blockâ€™s dependency
graph. For each predicate block, based on the content and each in-
structionâ€™s validity, we can compute the properties of the predicate
block, such as the total number of entries ğ¸ğµ, the width ğ‘Šğµ.
The table and pipeline constraint can be encoded with the fol-
lowing steps: Firstly, because each table could be deployed across
many stages, for each predicate block ğµğ‘–, Lyra creates two inte-
gers ğœ‰ğµğ‘–,ğ‘ ğ‘¡ğ‘ğ‘Ÿğ‘¡ and ğœ‰ğµğ‘–,ğ‘’ğ‘›ğ‘‘ indicating the start and end stage of the
predicate block. If ğœ‰ğµğ‘–,ğ‘ ğ‘¡ğ‘ğ‘Ÿğ‘¡ = ğœ‰ğµğ‘–,ğ‘’ğ‘›ğ‘‘, the predicate block is only
deployed in one stage.
Secondly, let ğ‘† denotes the number of stages in RMT, for each
predicate block ğµğ‘–, Lyra creates ğ‘† integers, each integer ğ¸ğµğ‘–,ğ‘  de-
notes the total number of entries ğµğ‘– deploys on stage ğ‘ . So we have
the following constraints:

ğ¸ğµğ‘– ,ğ‘  = 0, 
ğ¸ğµğ‘– ,ğ‘  = 0,

ğ‘ ğœ‰ğµğ‘– ,ğ‘’ğ‘›ğ‘‘
ğœ‰ğµğ‘– ,ğ‘ ğ‘¡ğ‘ğ‘Ÿğ‘¡ â‰¤ğ‘ â‰¤ğœ‰ğµğ‘– ,ğ‘’ğ‘›ğ‘‘
Thirdly, we encode the dependency relationship between the
tables, if predicate block ğµğ‘– depends on ğµ ğ‘—, then we have:
ğ¸ğµğ‘– ,ğ‘  â‰¥ ğ¸ğµğ‘–
(13)
(14)
Finally, Lyra encodes the memory constraint. For each stage ğ‘ ,
ğ‘‰ğµğ‘– âˆ§ ğ‘‰ğµ ğ‘— â‡’ ğ‘†ğµğ‘–,ğ‘“ > ğ‘†ğµ ğ‘— ,ğ‘™
there are ğ‘€ memory blocks, so we have:

ğµğ‘– âˆˆB
âŒˆ ğ¸ğµğ‘– ,ğ‘ 
â„ğ‘š
âŒ‰ Â· ğ‘Šğµğ‘–
ğ‘¤ğ‘š
âŒˆ
âŒ‰ âˆ— ğ‘‰ğµğ‘– â‰¤ ğ‘€
(15)
A.7 Other Constraints
Besides the above constraints mentioned in the RMT architecture,
Lyra can encode other constraints using similar techniques. Such
as total number of atoms per stage, number of atoms per table,
number of actions per stage, power consumption limitation, etc.
SIGCOMM â€™20, August 10â€“14, 2020, Virtual Event, NY, USA
Gao et al.
B EXTERNAL & GLOBAL VARIABLES
ENCODING
We have presented how to encode deployment constraints in Â§5.5.
This section further shows how do we encode external variable
constraints (Â§B.1) and global variable constraints (Â§B.2).
B.1 Encoding External Variable Constraints
An external variable can be split and deployed on multiple switches
due to the memory constraint. Each external variable ğ‘’ should co-
exist with all the instructions that read ğ‘’. Also on each possible
path ğ‘ in the scope, there are no duplicated or missing elements
of ğ‘’. Let Eğ‘’ denotes the total size of ğ‘’, Eğ‘  denotes the number of
elements deployed on switch ğ‘ , ğ¼ğ‘’ denotes all the instructions that
read ğ‘’, thus we have:
Eğ‘  = Eğ‘’,
If (
ğ‘–âˆˆğ¼ğ‘’
ğ‘ âˆˆğ‘
ğ‘ âˆˆğ‘
ğ‘“ğ‘ (ğ‘–), Eğ‘  > 0, Eğ‘  = 0)
(16)
B.2 Encoding Global Variable Constraints
The global variable is special, because its value is maintained over
the entire data plane, and any packet on different paths should
be able to read and write this shared information. We encode a
constraint that all the write operations and read operations that
occurred earlier than the last write operation with respect to the
global variable must co-exist on the same switch.
C OPTIMIZATIONS
We put more details about our Lyraâ€™s optimizations.
C.1 Reducing P4 Tables
Reducing the number of P4 tables. The first optimization aims
to reduce the number of tables in the synthesized P4 programs. In
one of the P4 features, the metadata in packet header can be set by
set_metadata(dst_v, src_v) during the packet header parsing;
thus, in the conditional implementation synthesis (Â§5.2), we tra-
verse each extracted predicate block to identify the set_metadata.
For each set_metadata, we backtrack the dependency of its dst_v
to check whether the dst_v was read in somewhere. If not, we move
this set_metadata to the parser body, preventing the set_metadata
from being enveloped as a table. In other words, we do the best
to reduce the chance of set_metadata generating tables. This op-
timization can yield a 50% reduction to the number of generated
tables in our P4 INT program.
C.2 Optimizing Results via Metrics
Lyra further offers the network programmers with options that
allow them to specify a requirement for optimizing the generated
chip code. Such a requirement could be maximizing the usage of
a certain switch or compacting the Lyra program to minimize the
number of programmed switches in each scope. To achieve this
optimization, we implement the constraints specific to each option.
For example, we can minimize the number of switches hosting the
generated tables by minimizingğ¼ âˆˆğ¼ğ‘,ğ‘ âˆˆğ‘ If (ğ‘“ğ‘ (ğ¼), 1, 0). For another
example, we can maximize the number of tables on a specified
switch, by assigning a much bigger weight for that specified switch
and minimizing the final result.
D MORE DISCUSSIONS
This section discusses more details about Lyraâ€™s implementation,
including unifying different ASIC libraries and the expressiveness
of Lyra model.
Unifying different ASIC libraries. Given that programmable
ASICs from different vendors offer different chip-specific libraries,
in Lyra compiler, we hard-code a collection of mapping functions
that convert chip-specific libraries into common IR representa-
tion. In our experience, we met two types of mapping. First, li-
braries from different ASICs offer the same functions but with dif-
ferent APIs. For example, in P4, a CRC hash calculation is realized
through a combination of field_list, field_list_calculation,
and modify_field_with_hash_based_offset; while in NPL, the
CRC hash calculation is implemented as a special function call.
For this type, Lyra compiler provides a predefined library-function,
called crc_hash(), which hard-codes the CRC hash calculation
APIs in different programmable ASICs.
The second type is: some of the chip-specific libraries only ex-
ist on their own ASICs. For example, ASIC ğ´ may support range
matching tables, ASIC ğµ may only provide TCAM matching tables.
In this case, Lyra also hard-codes mapping functions to unify the
chip-specific features across different ASICs, such as converting the
range matching rules (for ASIC ğ´) into multiple TCAM matching
rules (for ASIC ğµ). For multi-switch case, Lyra would also search
a solution across the ASICs defined in the given scope. If there is
no mapping function and cannot find an alternative ASIC, Lyra
compiler would report a compilation error.
The expressiveness of Lyra model. Lyraâ€™s constraint solving
is built on the SMT solver; thus, our synthesis capability heavily
relies on the expressiveness of SMT solver. Although our experience
observed that many constraints are hard to encode, we have not
seen any of resource constraints that cannot be encoded into SMT
model yet. By far, while we are not aware of cases that can not be
encoded by Lyra, we cannot exclude such possibility.