make it explicit that it corresponds to IMP-source, in the following we will refer to it as IMP-SSA. This is the
syntax of our intermediate representation. (Note that this is also the representation that Shimple [Val+99]
produces when executed on IMP-source code.)
For readers unfamiliar with SSA we discuss the basic features of the IMP-SSA representations. The IMP-
SSA program is a sequence of statements, where each statement is either (1) a copy propagation assignment,
e.g., x = y, (2) a three-address assignment, e.g., x = y+z (3) a for-loop statement, or (4) an if-then-else
statement. An if-statement is immediately followed by one or more φ-nodes, as is standard SSA form. (One
may need more than one φ nodes when more than one variables are assigned along one or both branches of the
if-then-else.) In the running example in Fig. 1(b) lines 11-24 show the IMP-SSA translation of method rem,
where rem is inlined into gcd. As it is standard in SSA, each assignment yields a new version of the variable
on the left-hand-side, e.g., we have rem2, rem3, rem4. Control ﬂow merge at the end of the if-statement
entails φ-nodes. In our running example, rem5 = φ(rem4,rem3) at line 22 in Fig. 1(b) entails that if control
took the then-arm of the if-statement, rem has the value of rem4, otherwise, rem has the value of rem3. We
assume that the ﬁrst argument of a φ node carries the value along the then-arm of the if-statement, and the
second argument carries the value along the else-arm.
C.2 Translation to MPC-source
We next discuss how our intermediate representation of IMP-SSA is translated to the representation that
we use for deﬁning our compact integer program, which we call MPC-source.
s
::= s; s
| x = y
| x = y aop z
| a[i] = x
| x = a[i]
| for (i = 0; i ≤ n; i ++) { s }
| if (x bop y) { s } else { s } z = φ(z1, z2)
aop ::= + | − | ∗ | /
bop ::= == | ! = | < | ≤
statement
arithmetic operator
comparison operator
Figure 8. IMP-SSA syntax. s represents a sequence of statements. x, y, and z denote variables, including constants,
local variables, and parameters that hold shares. i and n denote variables in plain text. Note that each if-then-else
statement is immediately followed by a φ-node, as is customary in SSA.
Fig. 2 deﬁnes an attribute grammar (also known as syntax directed translation) over the syntax in Fig. 8
that translates the IMP-SSA program into an MPC-source program. (An attribute grammar is a standard
static analysis technique [Aho+06, Chapter 5], [Sco15, Chapter 4]; an attribute grammar is deﬁned over the
syntax of the program and performs semantic analysis or transformation. ) In our case, this is a standard
attribute grammar. The only interesting case arises at if-statements which are dealt with using standard MPC
techniques: the MPC-source code for an if-statement is produced by appending the straight-line (MPC) code
for the else-arm onto the straight-line (MPC) code for the then-arm, then adding the conditional, and the
multiplexer to select the correct values. This is straight-forward given SSA: due to single assignment, variables
used at the if-statement test are unmodiﬁed, and are referenced in the comparison expression (CMP) that
31
precedes MUX, where the φ nodes capture exactly the arguments of MUX. 11 For example, consider the if-
statement in lines 9-31 in Fig. 1(b). The φ nodes capture the values of x and y; if control took the then-arm,
then x and y would be x2 and y2 respectively, otherwise x and y would be x1 and y1.
In our example, the resulting MPC-source program is shown in Fig. 1(c). We point out that MPC-source
can be mapped one-to-one to standard straight-line MPC; the only diﬀerence is that when a block is repeated
multiple times in straight-line MPC, it is replaced by a for-loop in MPC-source. Following standard MPC
compilers methodology, e.g., [BNP08; Fra+14], the actual MPC program unrolls all loops, and loop induction
variables become constants.
To make the above mapping explicit, we use pseudo φ-nodes. To better understand the use of these notes,
let’s focus on lines 5, 6 and 12 in Fig. 1(c) at the beginning of each one of the loops; these lines do not
encapsulate an if-then-else construct. Instead, they select variable values—at the ﬁrst iteration, the value
comes from outside the loop, and at every subsequent iteration the value comes from the previous iteration
of the loop. When translated into straight-line code, these lines disappear because corresponding values are
directly used as inputs to the gates. To highlight that these lines are only here to enable loops, and, that
these do not get translated into a MUX, we refer to them as pseudo φ-nodes in text and denote them with
? : instead of φ.
Looking ahead (cf. Section 4) the beneﬁt of doing the analysis over MPC-source rather than straight-line
code will be that there are signiﬁcantly fewer variables in the resulting integer/linear program.
D Proofs for §5
D.1 Proof for Theorem 2
Before proving the theorem, let us ﬁrst recall a results by Camion [Cam65] which we are using.
Deﬁnition 4. A matrix M is said to be Eulerian, if the sum of the elements in each row of M is even, and
the sum of the elements in each column of M is even.
J :(cid:80)
Theorem 5. (Camion [Cam65]) Matrix M is totally unimodular if and only if for every square Eulerian
submatrix of M M I
i ≡ 0 (mod 4).
i∈I,j∈J M j
In words, the above theorem states that a matrix is totally unimodular if and only if the sum of the elements
of every square Eulerian submatrix is divisible by 4.
We return to our constraint matrix A. There are two kinds of rows in A:
1. Rows
1 1 0 0 0 0 . . .
0 0 1 1 0 0 . . .
0 0 0 0 1 1 . . .
. . .
that reﬂect constraints an + yn ≥ 1. We use the term ﬁrst-kind rows in the remainder of this section to
describe these rows.
2. Rows
−1 0 . . . 1 0 . . . 1 . . .
0 −1 . . . 0 1 . . . 0 1 . . .
. . .
+ ··· + xd
≥ au − ad ≡ −ad + au + xd
+ ··· + xd
reﬂect constraints xd
e1
entries in a row, a −1 and 1, reﬂect −au and ad; the remaining 1 entries reﬂect the xd
of a and xd
use the term second-kind rows in the remainder of this section.
e-constraints (formula (2)), there is analogous row of y and zd
ek
e1
ek
≥ 0. The ﬁrst two non-zero
e’s. For each row
e -constraints (formula (3)). We
11 MUX is the multiplexer gate that is common in MPC compilers: on input of values (v0, v1) and a selection bit
b ∈ {0, 1}, it returns vb. In our case b is result of the CMP and (v0, v1) are arguments of φ node.
32
We are now ready to prove the theorem. We ﬁrst prove the following useful lemmas:
Lemma 1. The representative edges of forward def-use chains are totally ordered by subsumption: e1 ⊇ e2 ⊇
··· ⊇ ek.
Proof. Suppose there exist two forward def-use chains (d, u) and (d, u(cid:48)) with representatives e and e(cid:48), such
that neither subsumes the other. Without loss of generality, we say that u precedes u(cid:48). By deﬁnition, e lies
on the chain of forward edges from d to u and therefore, it dominates u(cid:48) as well, meaning that e subsumes
e(cid:48).
Lemma 2. Let (d, u) be a backward def-use chain. We have
1. (d, u) does not subsume any other def-use chain
2. A forward chain (d, u(cid:48)) may subsume (d, u)
Proof. As stated by Remark 2 in §3.6, each deﬁnition d gives rise to at most one backward def-use chain,
where u is a pseudo-φ node in u’s enclosing block. Also, as established in §3.6 (d, u)’s representative edge e
is the backward edge of u’s enclosing block. Assume then that (d, u) subsumes some forward chain (d, u(cid:48)).
There is an immediate contradiction because the chain of forward edges from u through d to u(cid:48) does not
pass through e. Therefore, (d, u) subsumes no other chain.
On the other hand, if e(cid:48) = min cut(d, u(cid:48)) is in d’s enclosing loop block, then execution always passes
through e(cid:48), then e to reach u. Therefore, a forward (d, u(cid:48)) may subsume (d, u).
Proof. Suppose there exists an Eulerian submatrix of A, M , such that the sum of its elements is not divisible
by 4. We prove the theorem for all Eulerian submatrices, and it follows for each square Eulerian submatrix.
Matrix M can be broken into two parts, submatrix M(cid:48) which consists entirely of ﬁrst-kind rows, and
submatrix M(cid:48)(cid:48) which consists of second-kind rows. We have M ≡ 2 mod 4 only if one of the following is true:
(1) M(cid:48) ≡ 2 mod 4 and M(cid:48)(cid:48) ≡ 0 mod 4, or (2) M(cid:48) ≡ 0 mod 4 and M(cid:48)(cid:48) ≡ 2 mod 4. (Here shortcut notation
M ≡ 2 mod 4 denotes that the sum of the elements of M gives remainder 2 modulo 4.)
Consider case (1). If M(cid:48) ≡ 2 mod 4, we must have an odd number of ﬁrst-kind rows in M (Since each
ﬁrst-kind row has two 1 entries and an even number of rows would have given M(cid:48) ≡ 0 mod 4). Consider the
part consisting of an-entry 1’s in M(cid:48). There is an odd number of these 1’s. Since M is a Eulerian submatrix
this means that each one of these 1’s must be matched (i.e., evened out) in columns by entries from M(cid:48)(cid:48).
e + ··· ≥ 0.
Let aM(cid:48)(cid:48) be the submatrix which consists of a-rows, i.e., rows due to constraints: −au + ad + xd
e +··· ≥ 0.
The remainder of M(cid:48)(cid:48), which we denote by yM(cid:48)(cid:48) consists of rows due to constraints: −yu + yd + xd
There is an odd number of columns in aM(cid:48)(cid:48) with odd sum each. (These must match the anentries.) However,
the remaining columns of aM(cid:48)(cid:48) must have even sum each, since those columns are matched only within aM(cid:48)(cid:48).
This implies that the sum of all elements of aM(cid:48)(cid:48) is odd (odd*odd + even). However, since M(cid:48)(cid:48) is Eulerian,
meaning that each row in aM(cid:48)(cid:48) has even sum, it follows that the sum of all elements of aM(cid:48)(cid:48) is even, which
leads to a contradiction. Therefore case (1) is impossible.
Consider case (2). We show that there is even number of rows in M(cid:48)(cid:48) with non-zero entries at xd
e positions.
If this is the case, then since each row has an even sum, the total sum of these rows is divisible by 4. There
may be additional rows in M(cid:48)(cid:48) with entries at ad and au positions, however since the ad entry is 1 and the
au entry is −1, these rows contribute 0 to the total sum of M(cid:48)(cid:48). By the same argument the sum of y (Yao)
rows is divisible by 4, which entails that the sum of entries in M(cid:48)(cid:48) is divisible by 4, which contradicts the
statement that M(cid:48)(cid:48) ≡ 2 mod 4.
We now argue that there is even number of rows in M(cid:48)(cid:48) with non-zero entries at xd
e in M(cid:48)(cid:48). As argued earlier, the forward def-use chains are ordered by subsumption: xd
e positions. Consider
⊇ ··· ⊇ xd
all xd
.
ek
(since M(cid:48)(cid:48) must have columns with even sum). Each
There is an even number of rows with 1 at position xd
ek
of these rows has 1 at each position xd
, therefore contributing
ej
an even number to each xd
column. Therefore, there must be an additional even number of rows with 1
ej
at position xd
contributing an even number of rows. Now
consider a backward chain with representative back edge en. There must be even number of rows with 1’s
at position xd
en(cid:48) . Each backward
en
def-use chain contributes an even number of rows as well.
, and these rows do not contain 1’s at any other backward edge position xd
, j < k as well, since each xd
ej
subsumes xd
ek
e1
ek−1
(but 0 at position xd
ek
), and so on, each xd
ej
33
The proof of unimodularity of the constraint matrix of LP Linear(S) follows by analogous arguments and
is therefore omitted.
D.2 Proof for Theorem 3
Without loss of generality we consider the assignment of variables x and show correspondence between the
x-assignment in IP Linear(S) and the x-assignments in IP CMPC(S).
Also without loss of generality, we focus on a single deﬁnition in d ∈ CMPC(S) and the constraints
associated with d in both IP Linear(S) and IP CMPC(S). We assume that the problem presents the following
constraints, grouped by (d, u) chains in categories (I) to (IV). Lemmas 1 and 2 in §5.1 entail that categories
(I) to (IV) abstract away the structure of the system, and one can trivially generalize to an arbitrary number
of (d, u) chains, i.e., categories.
Here (d, u) ⊇ (d, u(cid:48)) ⊇ (d, u(cid:48)(cid:48)) (also written as e ⊇ e(cid:48) ⊇ e(cid:48)(cid:48), where e, e(cid:48), and e(cid:48)(cid:48) are the corresponding
representative edges), are forward def-use chains. (d, ub) is a backward def-use chain, and we have that e(cid:48)
subsumes eb, but e(cid:48)(cid:48) does not subsume eb.
(I) xstd ≥ au − ad xd
(II) xstd ≥ au(cid:48) − ad xd
(III) xstd ≥ au(cid:48)(cid:48) − ad xd
(IV) xstd ≥ aub − ad xd
IP CMPC(S)
e ≥ au − ad
e + xd
e + xd
e + xd
IP Linear(S)
e(cid:48) ≥ au(cid:48) − ad
e(cid:48) + xd
e(cid:48) + xd
e(cid:48)(cid:48) ≥ au(cid:48)(cid:48) − ad
eb ≥ aub − ad
Note that each category contains multiple constraints in the IP Linear(S), where the xstd ’s are distinct. Each
category contains a single constraint in the IP CMPC(S), as shown.
Again, we prove the following useful lemmas before proof of the theorem. We give proofs sketches by
considering a single illustrative case. The full proof is established by case-by-case analysis.
Lemma 3. For each (d, u) ∈ IP CMPC(S), there are exactly we distinct xstd ≥ au−ad constraints in IP Linear(S),
where e = min cut(d, u).
Proof. The above lemma states that for each def-use (d, u) there are exactly we constraints, where we is the
weight of the min-cut edge of (d, u). Clearly, the number of constraints is given by min(|{ std | α(std) =
d }|,|{ stu | α(stu) = u }|). and the min-cut edge measures exactly that.
Lemma 4. (d, u) ⊇ (d, u(cid:48)) ⇒ γ((d, u)) ⊇ γ((d, u(cid:48))).
Proof. The second lemma states that when (d, u) subsumes (d, u(cid:48)) the set of std’s associated with (d, u)
includes all std’s associated with (d, u(cid:48)). As an informal argument, consider block B1 immediately enclosed