(le(cid:133) side) and machine-windows (right side). (cid:135)e values in-
side the security event nodes are their con(cid:128)dence scores,
which indicate the strength of their association with prior
incidents. (cid:135)e con(cid:128)dence scores are used to assign nor-
malized weights to the edges to reduce false alarms and
for adversarial resistance. Our Smoke Detector algorithm
employs Random Walk with Restart on this graph to rank
the unknown machine-windows (bottom two in the (cid:128)gure)
based on their relevance to the known security incidents for
analyst review towards undiscovering new incidents.
the event volume is dominated by background noise. Accordingly,
in obtaining a dataset from a leading MSSP we requested that the
length of each machine-window be set to 1 day as providing us with
a good tradeo(cid:130). Table 2 reports this and other summary statistics
of the anonymized dataset that we obtained.
4 INCIDENT RANKING & PRIORITIZATION
Given millions of unknown machine-windows, most of which con-
tain no primary indicators, how can an analyst identify the tiny
fraction of them that represent undetected security incidents? In
this section, we discuss our core methods for ranking and prioritiz-
ing the unknown machine-windows based on their likelihood of
containing an undiscovered incident. Toward this goal, we aimed
for a technique that can (i) operate in an one-class se(cid:138)ing like
ours where the only class we have is that of known security in-
cidents (i.e., the unknown machine-windows do not constitute a
class of their own, as each might well contain an incident), (ii)
capture high-order, indirect relationships between security events
and machine-windows, such as that between the top and bo(cid:138)om
machine-windows in Figure 2, (iii) produce a ranking of potential
incidents based on intuitive principles that can be easily consumed
by the analysts, and (iv) scale to large amounts of data. We con-
sidered a number of machine learning approaches, ranging from
202traditional classi(cid:128)cation and regression techniques to more complex
deep learning techniques. While some traditional machine learning
methods perform single-class classi(cid:128)cation, output interpretable
results, and are scalable, they typically consider each data point
in isolation and hence cannot easily capture high-order relation-
ships. Deep learning techniques, on the other hand, can handle
a single class and capture high-order relationships, but they pro-
duce results that are o(cid:137)en hard to interpret [12, 15] and scaling
these techniques to large amounts of data is still an active area of
research [6, 7, 13, 32].
(cid:140)ese considerations led us to pursue a graph-based approach
as a method that satis(cid:128)es our solution criteria and provides e(cid:130)ec-
tive solutions. Accordingly, we model the relationships between
security events and machine-windows as a bipartite graph, and
use scalable algorithms to propagate information from machine
windows that contain security incidents to the rest of the graph.
(cid:140)is formulation allows us to identify and rank unknown machine-
windows that are likely to contain a security incident. Our bipartite
graph represents each security event and machine-window as a
node, and contains directed edges between those security events
and machine-windows that appear together in the same record in
our dataset (one edge in each direction, see Figure 2).1 Overall, our
graph has 53,302,900 nodes and 183,610,432 edges.
(cid:140)e intuition behind our approach is that the unknown machine-
windows in the graph that have the closest relationships to machine-
windows with known security incidents are most likely to contain
security incidents themselves. By adopting algorithms that measure
the relevance of machine-windows to known security incidents, we
are able to rank undiscovered incidents highly. More precisely, we
employ the Random Walk with Restart algorithm [9, 21] to identify
undiscovered incidents from among tens of millions of unknown-
machine-windows. To the best of our knowledge, the application
of this algorithm to incident ranking and prioritization is novel.
4.1 Random Walk with Restart
Informally, a random walk with restart (RWR) over a graph can be
described as follows [28]. Consider a random particle that starts
from node i in the graph. (cid:140)e particle iteratively transmits to its
neighboring nodes with a probability proportional to the corre-
sponding edge weights. Additionally, at each step, there is a chance
that the particle transports back to node i with probability c. (cid:140)e
RWR score of node j with respect to node i is de(cid:128)ned as the steady-
state probability that the particle will be found at node j. (cid:140)e RWR
score of node j indicates its relevance to node i. For graphs with
multiple start nodes, the relevance scores of the nodes in the graph
are computed with respect to all the start nodes. (cid:140)e restart mecha-
nism used by RWR ensures that the nodes that are most proximate
to start nodes have higher rank than distant nodes.
Formally, RWR can be de(cid:128)ned as the following linear system:
(cid:174)r = (1 − c) ˜W (cid:174)r + c(cid:174)e
(4.1)
where, assuming that the graph has n nodes, (cid:174)r is the 1 × n RWR
˜W is
vector that contains the relevance scores for all the nodes,
the column-normalized n × n adjacency matrix that contains the
1We generate two directed edges between a pair of security event and machine-window
to be able to assign di(cid:130)erent edge weights depending on the source node (see Section 4).
weights of the edges between the nodes, c is the restart probability,
and (cid:174)e is the 1 × n starting vector with 1’s for the start nodes and
0’s for the remaining nodes. Directly solving Equation 4.1 involves
an expensive matrix inversion, with a total time complexity of
O(n
3) [36]. In practice, the solution is approximated with the power
iteration method, where Equation 4.1 is initialized with an RWR
vector of all 1’s and solved iteratively with the RWR vector from
the (t − 1)th iteration used to update the RWR vector in the tth
iteration. For t iterations, this method costs O(tm), where m is the
number of edges in the graph [36], improving the scalability of the
approach when it is run for a small number of iterations.
In our application of RWR to cross-product intrusion detection,
we select those machine-windows that correspond to known secu-
rity incidents as our start nodes, and we calculate the relevance of
all other unknown-machine windows and security events to these
start nodes. (cid:140)ese relevance scores form a natural ranking over
the 52 million unknown machine-windows in our dataset, the most
relevant of which are highly likely to represent previously undis-
covered security incidents. Detection systems cannot be tuned to
suppress false-alarms cause frustration and are likely to cease to
be used. In designing Smoke Detector, therefore, it is vital that our
system be responsive to feedback from security analysts, but how
to do so? (cid:140)e structure of the graph is entirely determined by event
data and should not be tampered with, and RWR measures rele-
vance to a single class of true positive nodes, with all other nodes
unknown. Neither does it make sense to associate a negative class
with false positives, as these will have been selected from among
the most suspicious machine-windows and are not as negative in
their nature as the average unknown machine-window.
(cid:140)e way to achieve a tunable system lies in RWR’s use of edge-
weights. As mentioned above, when a random particle leaves a
machine-window, it selects an outbound edge to an a(cid:138)ached se-
curity event with probability proportionate to the edge’s weight.
Future false-positive detections can therefore be prevented by ad-
justing edge weights in response to False Positive reports and other
forms of analyst feedback. For relevance scores to have a prob-
abilistic interpretation, RWR assumes that the adjacency matrix
of the input graph is column-normalized, meaning that the sum
of the weights of each node’s outgoing edges is 1. (cid:140)en, the sim-
plest initial policy for se(cid:138)ing the edge weights is to assign them
uniformly (i.e., each outgoing edge of a node with o out-neighbors
receives the weight 1/o), and while this choice does produce good
results, it is possible to do be(cid:138)er by associating edge weights with
measurements of security-event quality. Accordingly, we assign
the edge weights associated with a security event based on the
conditional probability that a security incident will be raised if that
the event is observed in a machine-window, which we refer to as
the con(cid:128)dence score for the event and describe in Section 5. An
example application of this edge weighting policy can be seen in
Figure 2, where, for each security event node, we set the weights of
all the outgoing edges to the con(cid:128)dence score for the event, which
are then normalized, and for each machine-window node, we sum
the con(cid:128)dence scores of all the in-neighbor events, which is then
distributed among the outgoing edges with weights in proportional
to the in-neighbor events’ scores.
2035 CONFIDENCE SCORING
Smoke Detector provides con(cid:128)dence scores for security events, which
represent the conditional probability that a machine-window con-
tains a security incident given that the event was observed in rela-
tion to it. We seek to ful(cid:128)ll three goals in providing these con(cid:128)dence
scores. First, since novel security incidents identi(cid:128)ed by Smoke De-
tector may consist of many events, these scores serve to bring the
most important events to the a(cid:138)ention of the analyst. Second, these
conditional probabilities have a clear interpretation that analysts
can readily understand. (cid:140)ird, these scores provide an intuitive
means by which the RWR algorithm can be tuned, and are used as
edge-weights in that algorithm.
While RWR can score the importance of security events in the
graph, its “relevance” scores do not ful(cid:128)ll the three goals listed
above. Since RWR’s relevance score for an event is the steady-
state probability of a particle being found at the event in question,
these scores are extremely low and are furthermore, they have
a skewed distribution, bearing hardly any relation to the more
intuitive conditional probabilities that we provide as con(cid:128)dence
scores through the techniques of this section.
model. (cid:140)is ensures a low false positive rate, and that high con(cid:128)-
dence scores are earned on the basis of su(cid:129)cient evidence, which
promotes trust on the part of incident responders.
We model each event’s instances as a Bernoulli random variable.
An individual instance can be thought of as a trial, where a suc-
cessful trial is one that occurs within a compromise-related context.
We can formalize as:
θ ∼ Beta(α, β)
yevent ∼ Bern(θ)
(5.1)
(5.2)
(cid:140)erefore, θ is drawn from skeptical prior belief of the distribu-
tion of event con(cid:128)dence, which in turn in(cid:131)uences the likelihood of
the event occurring in a compromise-related context. But how do
we choose α and β?
5.1 Modeling Event Con(cid:128)dence on Correlation
with Primary Indicators
To measure the conditional probability with which an event in-
dicates a serious compromise, we measure each security event’s
correlation with primary indicators. As de(cid:128)ned in Section 3 pri-
mary indicators are those security events that should warrant the
raising of a security incident whenever they are observed. A set
of reliable primary indicators is typically easily obtained from any
MSSP or SIEM, as it these are fundamental to their incident detec-
tion methods [19]. Should such a set not be available, an adequate
set of primary indicators can be identi(cid:128)ed with some manual e(cid:130)ort
thanks to the naming conventions used by many security vendors
for high-(cid:128)delity events, and through the numeric severity scores
that many of them provide. Since primary indicators trigger only
in the context of serious security issues, any instance of a security
event that happens in the same machine-window as a primary indi-
cator is likely to have triggered in response to malicious behavior.
Measuring con(cid:128)dence on the basis of co-occurrence with primary
indicators is appealing because high scores can be explained and
justi(cid:128)ed on the basis of primary indicators of known reliability.
More precisely, we score events based on the fraction of the time
in which they appear in the same machine-window as at least
one primary indicator. (cid:140)e selection of machine-windows that are
24-hours in length o(cid:130)er a good trade-o(cid:130) between capturing the
majority of incidents associated with the incident and eliminating
background noise, as seen in Figure 1.
5.2 Con(cid:128)dence Estimation With a Prior
Distribution
While MSSPs may record trillions of event instances per month,
rare event types may be observed only a handful of times. To en-
sure that we do not overestimate the con(cid:128)dence of rare events, we
apply a skeptical prior belief of event con(cid:128)dence into our scoring
Figure 3: We plot a histogram of con(cid:128)dence scores measured
via maximum likelihood estimation for events that appear
10 or more times, and (cid:128)t a beta distribution to the data (the
red curve). As this distribution is insu(cid:129)ciently skeptical for
use as a prior probability distribution, we (cid:128)t a second beta
distribution to the data, constraining its minimum value to
occur at con(cid:128)dence = 0.9 (the blue curve).
We adapt Empirical Bayes techniques [4] to our purposes, model-
ing the prior probability distribution based on the data, and applying
Bayesian inference to arrive at the posterior probability distribution.
Our prior is a Beta distribution that we (cid:128)t to events that have been
observed at least ten times. Since we desire our prior distribution
to be skeptical, rather than applying the best-(cid:128)t Beta prior, which
is shown as the red curve in Figure 3 and has a minimum value at
roughly 60%, we solve for a more skeptical prior with minimum
value of 0.9, resulting a beta distribution prior with parameters
α = 0.0499 and β = 0.8944, which is shown as the blue curve in the
same (cid:128)gure.(cid:140)e resulting empirically motivated prior distribution
is generally skeptical about the con(cid:128)dence of most events, but does
not rule out the existence of a small but important minority of
events that are highly indicative of machine compromise.
204Figure 4: Partial display of events and metadata contribut-
ing to an incident detected by Smoke Detector. (cid:135)e analyst
has clicked on an event to cause its con(cid:128)dence score to be
explained in terms of its correlated ground-truth events.
5.3 Feedback (cid:135)rough Transparency
By basing Smoke Detector’s con(cid:128)dence scoring on correlation with
primary-indicator events, we are able provide intuition and trans-
parency into the relationship-based nature of our overall approach
and to prevent the mistrust that opaque models tend to engender.
Figure 4 shows how this transparency can be used in presenting
a Smoke Detector incident to an incident responder. To facilitate
feedback, we explain the con(cid:128)dence of an event by exposing the
degree of support that each primary indicator contributes to its
score, based on its co-occurrence rate. In this particular case, the
“Unknown IP Protocol” event is shown to bear strong relation to
primary indicators that are more obviously severe.
(cid:140)is window into our algorithm provides insight into the context
in which the event typically triggers, which may hint at the possi-
bility of a more serious underlying problem. (cid:140)ird, when trained in
an MSSP, Smoke Detector a customer with few security products
can learn of alerts that non-deployed product likely would have
identi(cid:128)ed had it been deployed. Finally, this transparency allows
analyst to reduce false positives by removing unreliable events that
should not be considered primary indicators for purposes of con-
(cid:128)dence scoring. Similarly analysts may increase true positives by
identifying events that should re-classi(cid:128)ed as primary indicators.
6 IMPLEMENTATION
Smoke Detector consists of two parts: incident detection based
on RWR and con(cid:128)dence scoring. We focus the implementation
description of this section on the RWR algorithm, which dominates
the performance cost, since con(cid:128)dence-score computations need to
be frequently computed and can be e(cid:129)ciently calculated over the
RWR graph using the algorithm of Section 5.
To scale with the size of our workloads (upwards of 150 billion
events daily), we implemented RWR in Apache Spark, a framework
for running distributed computation on multi-node clusters, with
the aim of facilitating horizontal scaling [35].
Figure 5: Performance characteristics of our RWR imple-
mentation on both our con(cid:128)dence-weighted and synthetic
graphs.
In implementing RWR, we perform the power iteration method
for 10 iterations, which is su(cid:129)cient to achieve an accurate estima-
tion of steady-state probabilities [11]. We set its restart probability
c to 0.15, a value commonly used in practice [27].
As discussed in Section 4, the power-iteration method has a time