s
p
b
M
(
t
u
p
h
g
u
o
r
h
T
)
s
p
b
M
(
t
u
p
h
g
u
o
r
h
T
60
50
40
30
20
10
0
60
50
40
30
20
10
0
s
e
l
p
m
a
s
f
o
.
o
N
140
120
100
80
60
40
20
0
6
12
18
24
Time of day (local)
6
12
18
24
Time of day (local)
(a) GTT server in Atlanta to AT&T customers. (May 2015)
s
e
l
p
m
a
s
f
o
.
o
N
250
200
150
100
50
0
6
12
18
24
Time of day (local)
6
12
18
24
Time of day (local)
(b) GTT server in Atlanta to Comcast customers. (May 2015)
Figure 5: Diurnal throughput (left) and number of samples (right) using NDT tests from a M-Lab server in GTT to clients in AT&T
(a) and Comcast (b). AT&T users see a drop in throughput to less than 1 Mbps during peak hours. Comcast users see a drop as well,
but not to the same extent. The number of samples are also much fewer during off-peak hours.
fall into three categories: the complexity and opaqueness of the In-
ternet’s topology; visibility of interconnections used to access popu-
lar content; and statistical issues associated with crowdsourced sam-
pling of performance measurements. Overcoming each challenge
with available data requires making several assumptions, and we
used this broad set of measurements to assess the degree to which
these assumptions hold on today’s Internet.
First, pinpointing the location of congestion using end-to-end
measurement requires application of network tomographic tech-
niques to detailed router-level path information in both directions
taken at the time of the end-to-end measurements. Obtaining such
information is an open research and policy challenge. An alternative
is to use coarser-grained, i.e., AS-level tomography, and to further
simplify the tomography with three assumptions: there is no con-
gestion internal to ASes, only at interconnects; the two endpoints of
the measurement are in directly connected ASes; and there is only
one physical link connecting them which the measurement trafﬁc
traverses. The ﬁrst assumption is consistent with comments from
many industry players we have seen in discussions on NANOG and
received via personal communication; we did not have data to in-
vestigate it in this study. With respect to the second assumption, our
analysis of data from M-Lab’s study [27] revealed that although
most clients are usually one AS hop away from M-Lab’s testing
server, most tests between some AS pairs traverse multiple AS hops.
Having more than one AS hop between the server and client sheds
doubt on congestion inferences, because any interdomain link in the
path could be the point of congestion (assuming also that congestion
is more likely at interdomain links than internal to networks).
The third assumption is more problematic: the limited path infor-
mation available from the M-Lab study shows that the interconnec-
tions between the same two pair of ISPs are often not crossing the
same IP link. This is consistent with recent studies that show that
larger ASes tend to interconnect with each other in many locations,
and congestion on these interconnections can often have regional
effects [14].
Second, what we can currently measure with existing server-side
measurement infrastructure is only a small subset of the intercon-
nection landscape, and may not provide visibility of paths that carry
Challenges in Inferring Internet Congestion
IMC ’17, November 1–3, 2017, London, United Kingdom
popular content. Our analysis revealed that the set of interdomain
interconnections, both at the router and AS-level, testable using M-
Lab or Speedtest.net infrastructure typically had low overlap with
those traversed on the paths to popular web content.
Finally, crowdsourcing methods have advantages in the poten-
tial for sampling breadth across geographical regions, ISPs, service
plans, and home network conditions. However, in practice, crowd-
sourced measurements can yield exactly the opposite: an uneven
distribution of samples across time of day, access link speeds, and
home network qualities. Another statistical challenge is selection of
a threshold drop in throughput to constitute evidence of congestion.
Recommendations
Our methodology and analysis offers opportunities for measure-
ment platforms to tune the deployment of their measurement servers
to improve the coverage of relevant interdomain interconnects. We
offer several suggestions to mitigate the impact of these issues and
enable more rigorous inference of congestion: Most critical, every
throughput-based test must include a traceroute taken as close as
possible in time to the test, preferably in both directions. Deploying
a router-level interconnection inference tool such as bdrmap [26] on
a server-side infrastructure such as M-Lab would greatly increase
situational awareness of the topology state during measurements by
allowing inference of which router-level interconnects a given test
traverses. To limit the potential of interference from multiple points
of interconnection, measurement projects could strategically deploy
servers to increase the fraction of one-hop tests, modifying server
selection logic to select only directly connected servers, and using
path information to discard tests that traverse more than one AS
hop. In any case, analysis of throughput measurements should not
aggregate across router-level links (particularly if the router-level
links are in separate geographical regions). Doing so may aggre-
gate across links with dissimilar performance characteristics [14].
To ensure that congestion inferences reﬂect performance that users
actually experience, measurement platforms should incorporate reg-
ular measurements of paths to popular content. Otherwise, claims
about congestion at interconnects should acknowledge that those in-
terconnects may not be on the path from the most popular content
to users. Finally, the community could mitigate the statistical lim-
itations of crowdsourcing by using other measurement platforms
to run periodic tests that complement the crowdsourced tests. Ark,
BISmark, and RIPE Atlas are a few examples of platforms that
support repeated longitudinal measurements. These other platforms
are not provisioned to support the bandwidth requirements of NDT
throughput measurements, but they, as well as M-Lab, could sup-
port lower-impact techniques such as TSLP [25] to provide addi-
tional insight into the presence and location of congestion.
Future work
We hope that these recommendations will lead to improvements in
measurement platforms to better support the inference and localiza-
tion of congestion. With regard to the analysis of existing data, a
focus of our ongoing work is to use the insights we have gleaned
from the analysis of router-level interconnection (Section 4) to more
rigorously analyze the M-Lab data. In particular, we are using the
NDT tests in conjunction with Paris traceroutes and MAP-IT infer-
ences to identify the speciﬁc IP-level interconnection traversed by
each test. By doing so, we will be able to analyze the performance
of tests traversing each individual IP-level interconnect between a
given source and client AS, and to make inferences about whether
speciﬁc IP-level interconnection links are congested.
In general, being able to detect the presence and type of con-
gestion is an still open problem. It would be useful if speed tests
such as those conducted by M-Lab, various speed test sites, and
the FCC Measuring Broadband America infrastructure could reveal
more information about the path than simply achievable throughput.
We have taken some steps in this direction with recent work [37]
that uses RTT signatures extracted from speed tests to determine
whether a TCP ﬂow was limited by an already congested link in the
path, or whether it started on an initially unconstrained path, thus
driving buffer behavior. While this method cannot by itself pinpoint
the location of the congested link, we believe that it can provide
additional information useful for interpreting the results of speed
tests. Our focus in the near future will be on getting this capability
deployed on the M-Lab and FCC Measuring Broadband America
infrastructure.
ACKNOWLEDGEMENTS
We would like to thank our shepherd, David Choffnes, and the
anonymous reviewers for their valuable feedback. This work was
supported by NSF CNS-1414177 and a grant from Google, but this
paper represents only the position of the authors.
REFERENCES
[1] Internet Health Test. http://internethealthtest.org, 2015.
[2] Internet in the United States, 2017. https://en.wikipedia.org/wiki/Internet_in_
the_United_States.
[3] Alexa. Top Sites in United States. http://www.alexa.com/topsites/countries/US,
2017.
[4] C. Anderson. New Opportunities for Test Deployment and Continued Anal-
http://www.measurementlab.net/blog/
ysis of Interconnection Performance.
interconnection_and_measurement_update, 2015.
[5] B. Augustin, X. Cuvellier, B. Orgogozo, F. Viger, T. Friedman, M. Latapy,
C. Magnien, and R. Teixeira. Avoiding Traceroute Anomalies with Paris Tracer-
oute.
In Proceedings of ACM SIGCOMM Internet Measurement Conference
(IMC), Oct. 2006.
[6] S. Bauer, D. Clark, and W. Lehr. Understanding Broadband Speed Measurements.
In Telecommunications Policy Research Conference (TPRC), Oct. 2010.
[7] BISMark: Broadband Internet Service Benchmark, 2017. http://projectbismark.
net/.
[8] J. Brodkin.
Super HD Demands.
Time Warner, Net Neutrality Foes Cry Foul Over Net-
http://arstechnica.com/business/2013/01/
ﬂix
timewarner-net-neutrality-foes-cry-foul-netﬂix-requirements-for-super-hd/ ,
2013.
[9] J. Brodkin. Why YouTube Buffers: The Secret Deals that Make-and-break Online
Video. Ars Technica, July 2013.
[10] S. Buckley. France Telecom and Google entangled in peering ﬁght. Fierce Tele-
com, 2013.
[11] CAIDA. Archipelago (Ark) Measurement Infrastructure. http://www.caida.org/
projects/ark/, 2017.
[12] CAIDA. AS Relationships. http://www.caida.org/data/as-relationships/, 2017.
[13] CAIDA. Inferred AS to Organization Mapping Dataset. https://www.caida.org/
data/as-organizations/, 2017.
[14] k. claffy, D. Clark, S. Bauer, and A. Dhamdhere. Policy Challenges in Mapping
Internet Interdomain Congestion. In Telecommunications Policy Research Con-
ference (TPRC), Oct 2016.
[15] Cogent Communications Inc. Ex Parte Filing from Cogent, DISH, Free Press,
Open Technology Institute, Public Knowledge related to ATT DirecTV Merger,
May 2015. "http://apps.fcc.gov/ecfs/comment/view?id=60001031493", 2015.
[16] I. Cunha, P. Marchetta, M. Calder, Y.-C. Chiu, B. Schlinker, B. V. A. Machado,
A. Pescapè, V. Giotsas, H. V. A. Madhyastha, and E. Katz-Bassett. Sibyl: A
Practical Internet Route Oracle.
In Proceedings of the Usenix Conference on
Networked Systems Design and Implementation (NSDI), 2016.
IMC ’17, November 1–3, 2017, London, United Kingdom
Sundaresan et al.
[17] S.
Dent.
Google
is
from
google-is-testing-internet-speeds-straight-from-search/, 2016.
Search.
Testing
Straight
https://www.engadget.com/2016/06/29/
Internet
Speeds
[31] Ookla. How Does the Test Itself Work? https://support.speedtest.net/hc/en-us/
articles/203845400-How-does-the-test-itself-work-How-is-the-result-calculated- ,
2012.
[18] N. G. Dufﬁeld. Network Tomography of Binary Network Performance Charac-
[32] Packet Clearing House. Full Exchange Point Dataset. https://preﬁx.pch.net/
teristics. IEEE Transactions on Information Theory, Dec. 2006.
applications/ixpdir/menu_download.php, 2017.
[19] J.
Engebretson.
Settlement,
ing
behind-the-level-3-comcast-peering-settlement/.
July
Behind
2013.
the
Level
Peer-
http://www.telecompetitor.com/
3-Comcast
[20] FCC. Measuring Broadband America Report 2014. https://www.fcc.gov/reports/
measuring-broadband-america-2014.
[21] Y. Huang, N. Feamster, and R. Teixeira. Practical Issues with Using Network
Tomography for Fault Diagnosis. ACM SIGCOMM Computer Communincation
Review (CCR), 2008.
[22] Hurricane Electric. BGP Toolkit, 2017. http://bgp.he.net.
[23] E. Katz-Bassett, H. V. Madhyastha, V. K. Adhikari, C. Scott, J. Sherry, P. Van We-
sep, T. Anderson, and A. Krishnamurthy. Reverse traceroute.
In Proceedings
of the USENIX Conference on Networked Systems Design and Implementation
(NSDI), 2010.
[24] D. H. Lee.
Relation Between NDT and Paris Traceroute Tests on M-
https://groups.google.com/a/measurementlab.net/forum/#!topic/discuss/
Lab.
YxI4Z_IBb9Y, 2015.
[25] M. Luckie, A. Dhamdhere, D. Clark, B. Huffaker, and kc claffy. Challenges in
Inferring Internet Interdomain Congestion. In Proceedings of ACM SIGCOMM
Internet Measurement Conference (IMC), Nov. 2014.
[26] M. Luckie, A. Dhamdhere, B. Huffaker, D. Clark, and k. claffy. bdrmap: In-
ference of Borders Between IP Networks. In Proceedings of ACM SIGCOMM
Internet Measurement Conference (IMC), Nov 2016.
[27] M-Lab Research Team. ISP Interconnection and its Impact on Consumer Internet
Performance - A Measurement Lab Consortium Technical Report. http://www.
measurementlab.net/publications, 2014.
[28] A. Marder and J. M. Smith. MAP-IT: Multipass Accurate Passive Inferences
from Traceroute. In Proceedings of ACM SIGCOMM Internet Measurement Con-
ference (IMC), 2016.
[33] J. Padhye, V. Firoiu, D. F. Towsley, and J. F. Kurose. Modeling TCP Reno Perfor-
mance: A Simple Model and its Empirical Validation. IEEE/ACM Transactions
on Networking, 2000.
[34] PeeringDB, 2017. http://www.peeringdb.com.
[35] C. Ritzo. Paris Traceroute Brownout. https://www.measurementlab.net/blog/
paris-traceroute-brownout/, Apr. 2017.
[36] M. A. Sánchez, J. S. Otto, Z. S. Bischof, D. R. Choffnes, F. E. Bustamante, B. Kr-
ishnamurthy, and W. Willinger. Dasu: Pushing experiments to the internet’s edge.
In Proceedings of the USENIX Conference on Networked Systems Design and
Implementation (NSDI), 2013.
[37] S. Sundaresan, A. Dhamdhere, M. Allman, and kc claffy. TCP Congestion Sig-
natures. In Proceedings of ACM SIGCOMM Internet Measurement Conference
(IMC), Nov. 2017.
[38] S. Sundaresan, N. Feamster, and R. Teixeira. Measuring the Performance of User
Trafﬁc in Home Wireless Networks. In Proceedings of the Passive and Active
Measurement Conference (PAM), 2015.
[39] S. Sundaresan, N. Feamster, and R. Teixeira. Home Network or Access Link?
Locating Last-Mile Downstream Throughput Bottlenecks. In Proceedings of the
Passive and Active Measurement Conference (PAM), 2016.
[40] M. Taylor. Observations of an Internet Middleman, May 2014. http://blog.level3.
com/global-connectivity/observations-internet-middleman/.
[41] Various Authors. Email thread “Comments on ISP Interconnection and its Im-
pact on Consumer Internet Performance", 2014. https://groups.google.com/a/
measurementlab.net/forum/#!msg/discuss/lwVmPrbRg0w/1CTgbNcgInIJ.
[42] Various Authors.
Email
thread “BattlefortheNet study", 2015.
https://
groups.google.com/a/measurementlab.net/d/msg/discuss/RbPb18fY_VA/
P7Eil4lcgLMJ.
[43] Verizon. Unbalanced Peering, and the Real Story Behind the Verizon/Cogent
[29] Measurement Labs. M-Lab Dataset. https://cloud.google.com/bigquery/docs/
Dispute, June 2013. http://publicpolicy.verizon.com/blog/.
dataset-mlab, 2017.
[44] D. Vorhaus. A New Way to Measure Broadband in America.
http://blog.
[30] Measurement Labs. NDT Data Format.
https://code.google.com/p/ndt/wiki/
broadband.gov/?entryId=359987, Apr. 2010.
NDTDataFormat, 2017.