```
如果您还没有看到基巴纳，请稍等片刻并刷新屏幕。
你应该会看到*欢迎*画面。点击“我自己探索”链接，忽略尝试他们的样本数据的提议。您将看到允许您添加数据的屏幕。
![](img/f1a8a6ea-94ef-40e8-861b-d7d04f0a6dc5.png)
Figure 7-8: Kibana's home screen
我们需要做的第一件事是创建一个新的弹性搜索索引，该索引将与 Fluentd 创建的索引相匹配。我们正在运行的版本已经在将数据推送到 Elasticsearch，它通过使用 LogStash 索引模式来简化事情，因为这是 Kibana 期望看到的。
单击左侧菜单中的管理项目，然后单击索引模式链接。
Fluentd 发送到 Elasticsearch 的所有日志都是带有日期前缀的*日志存储*的索引。由于我们希望基巴纳检索所有日志，因此在索引模式字段中键入`logstash-*`，然后单击>下一步按钮。
接下来，我们需要指定哪个字段包含时间戳。这是一个简单的选择。从时间过滤器字段名称中选择@timestamp，然后单击创建索引模式按钮。
![](img/884ab586-e6e9-4fa6-bc02-d15e6a91b682.png)
Figure 7-9: Kibana's Create index pattern screen
就这样。我们现在要做的就是等待一会儿，直到创建了索引，并浏览从整个集群中收集的日志。
请单击左侧菜单中的“发现”项目。
您眼前看到的是过去十五分钟内生成的所有日志(可以扩展到任何时间段)。左侧提供了字段列表。
顶部有一个愚蠢的(也是无用的)图表，日志本身在屏幕的主体部分。
![](img/20ca4884-36f5-465c-8fe2-f1f2af4b5abe.png)
Figure 7-10: Kibana's Discover screen
就像 Papertrail 一样，我们不会讨论基巴纳的所有可用选项。我相信你能自己解决。我们将进行一些基本操作，以防这是你第一次接触基巴纳。
我们的场景和以前一样。我们将尝试查找从`random-logger`应用生成的所有日志条目。
请在搜索栏中输入`kubernetes.pod_name: "random-logger"`并点击右侧的刷新(或更新)按钮。
通常，我们希望自定义默认显示的字段。例如，只查看日志条目比查看完整的源更有用。
点击日志字段旁边的添加按钮，将替换默认的 *_source* 列。
如果您想查看包含所有字段的条目，请单击该行左侧的箭头展开一个字段。
![](img/20ca4884-36f5-465c-8fe2-f1f2af4b5abe.png)
Figure 7-11: Kibana's Discover screen with filtered entries
我会让你独自探索基巴纳的其他地方。但是，在你这么做之前，有一个警告。不要被所有华而不实的选择所迷惑。如果我们所拥有的只是日志，那么创建可视化、仪表板、时间表和其他好看但无用的日志就没有意义了。这些可能对度量有用，但是我们没有。目前，他们在普罗米修斯。稍后，我们将讨论将指标推送到弹性搜索而不是从普罗米修斯那里提取指标的选项。
现在，慢慢来，看看你还能在基巴纳做什么，至少在*发现*屏幕内。
我们已经完成了 EFK 栈，鉴于我们还没有决定使用哪个解决方案，我们将从系统中清除它。稍后，如果你选择了 EFK，在你的“真实”集群中创建它应该不会有任何问题。
```
 1  helm delete kibana --purge
 2
 3  helm delete fluentd --purge
 4
 5  helm delete elasticsearch --purge
 6
 7  kubectl -n logging \
 8      delete pvc \
 9      -l release=elasticsearch,component=data
10
11  kubectl -n logging \
12      delete pvc \
13      -l release=elasticsearch,component=master
```
# 切换到弹性搜索来存储指标
既然我们的集群中运行了 Elasticsearch，并且知道它可以处理几乎任何数据类型，那么一个合乎逻辑的问题是，除了日志之外，我们是否可以使用它来存储我们的度量。如果你探索 elastic.co(T2)https://www.elastic.co/(T3)，你会发现指标确实是他们宣传的东西。如果它能取代普罗米修斯，那么拥有一个不仅能处理日志，还能处理度量的单一工具无疑是有益的。除此之外，我们可以抛弃 Grafana，保留 Kibana 作为两种数据类型的单一用户界面。
然而，我强烈建议不要使用弹性搜索来度量。这是一个通用的自由文本无 SQL 数据库。这意味着它可以处理几乎任何数据，但同时，它在任何特定的格式上并不出色。另一方面，普罗米修斯被设计成存储时间序列数据，这是暴露度量的首选方式。因此，它的作用更加有限。但是，它比弹性搜索更好地处理指标。我相信，使用合适的工具来完成工作比拥有一个做太多事情的工具要好，如果你也这么认为，普罗米修斯是一个更好的度量选择。
与弹性搜索(Elasticsearch)相比，普罗米修斯只专注于度量，它需要的资源要少得多(正如您已经注意到的)，速度更快，查询语言也更好。考虑到这两个工具都很棒，这并不奇怪，但只有普罗米修斯被设计成专门处理度量。维护一个额外工具的增加的成本通过拥有一个更好的(和更集中的)解决方案得到了很好的回报。
我有没有提到通过普罗米修斯和警报管理器生成的通知比通过弹性搜索生成的通知更好？
还有一件事需要注意。普罗米修斯与 Kubernetes 的集成比 Elasticsearch 提供的要好得多。这并不奇怪，因为普罗米修斯基于与 Kubernetes 相同的云原生原则，并且都属于*云原生计算基金会*([https://www.cncf.io/](https://www.cncf.io/))。另一方面，Elasticsearch 来自更传统的背景。
Elasticsearch is excellent, but it does too much. Its lack of focus makes it inferior to Prometheus for storing and querying metrics, as well as sending alerts based on such data.
如果用 Elasticsearch 替换 Prometheus 不是一个好主意，我们能把问题反过来吗？我们能用普罗米修斯做原木吗？答案肯定是否定的。如前所述，普罗米修斯只关注度量。如果您采用了它，您需要一个不同的工具来存储日志。这可以是弹性搜索、Papertrail 或任何其他适合您需求的解决方案。
基巴纳怎么样？我们能为了格拉夫娜放弃它吗？答案是肯定的，但不要这样做。虽然我们可以在 Grafana 中创建一个表，并将其作为数据源附加到 Elasticsearch，但它显示和过滤日志的能力较差。另一方面，在显示基于指标的图表方面，Grafana 比 Kibana 灵活得多。因此，答案类似于弹性搜索对普罗米修斯的困境。如果您选择将 Grafana 存储在 Elasticsearch 中，请保留 Grafana 作为度量标准，并使用 Kibana 作为日志。
您应该在 Grafana 中添加 Elasticsearch 作为另一个数据源吗？如果您采纳了之前的建议，答案很可能是否定的。将日志显示为图表没有太大价值。在我看来，即使是基巴纳的*探索*部分提供的预定义图形也是浪费空间。没有必要显示我们总共有多少日志条目，甚至有多少是错误条目。我们用标准来衡量。
Logs themselves are too expensive to parse, and most of the time they do not provide enough data to act as metrics.
我们看到了几个正在运行的工具，但是我们还没有讨论我们真正需要的集中式日志解决方案。接下来我们将更详细地探讨这一点。
# 我们应该从集中日志中期待什么？
我们探索了几种可用于集中日志记录的产品。如您所见，所有解决方案都非常相似，我们可以假设大多数其他解决方案遵循相同的原则。我们需要跨集群收集日志。我们为此使用了 Fluentd，这是最广泛接受的解决方案，无论哪个数据库接收到这些日志，您都可能使用它(Azure 是一个例外)。
用 Fluentd 收集的日志条目被发送到一个数据库中，在我们的例子中，该数据库是 Papertrail、Elasticsearch 或托管供应商提供的解决方案之一。最后，所有解决方案都提供了一个用户界面，允许我们浏览日志。
我通常为一个问题提供一个单一的解决方案，但是，在这种情况下，有相当多的候选方案可以满足您对集中式日志记录的需求。你应该选择哪一个？会是 Papertrail、elastic search-fluent-Kibana 栈(EFK)、AWS CloudWatch、GCP Stackdriver、Azure 日志分析还是其他什么？
如果可能且可行，我更喜欢作为服务提供的集中式日志解决方案，而不是在我的集群中运行它。当别人确保一切正常时，很多事情就变得容易了。如果我们使用赫尔姆安装 EFK，这可能看起来是一个简单的设置。然而，维护绝非小事。弹性搜索需要大量资源。对于较小的集群，单独运行 Elasticsearch 所需的计算可能高于 Papertrail 或类似解决方案的价格。如果我能以与在自己的集群中运行替代服务相同的价格获得由他人管理的服务，那么服务在大多数情况下都会胜出。但是，也有一些例外。
我不想将我的业务锁定在服务提供商身上。或者，更准确地说，我认为核心组件由我控制是至关重要的，而其余的大部分都给了别人。虚拟机就是一个很好的例子。只要价格有竞争力，服务可靠，我不在乎是谁创造的。我可以轻松地将我的虚拟机从内部移动到 AWS，再从 AWS 移动到 Azure。我甚至可以回到现场。虚拟机的创建和维护没有太多逻辑。或者，至少，不应该有。
我真正关心的是我的申请。只要它们在运行，它们就是容错的，它们是高度可用的，并且它们的维护并不昂贵，它们运行在哪里并不重要。但是，我需要确保系统以一种允许我从一个提供者切换到另一个提供者的方式完成，而不需要花费几个月的时间进行重构。这是 Kubernetes 被如此广泛采用的重要原因之一。它抽象了它下面的所有东西，因此允许我们在(几乎)任何 Kubernetes 集群中运行我们的应用。我相信同样的道理也适用于原木。我们需要明确我们的期望，任何满足我们要求的解决方案都和其他解决方案一样好。那么，我们需要从日志解决方案中得到什么呢？
We need logs centralized in a single location so that we can explore logs from any part of the system. We need a query language that will allow us to filter the results. We need the solution to be fast.
我们探索的所有解决方案都符合这些要求。Papertrail、EFK、AWS CloudWatch、GCP Stackdriver 和 Azure 日志分析都满足了这些要求。Kibana 可能更漂亮一点，Elasticsearch 的查询语言可能比其他解决方案提供的查询语言更丰富一点。漂亮的重要性由你来确定。至于弹性搜索的查询语言更强大...这并不重要。大多数时候，我们需要对日志进行简单的操作。给我找到所有有特定关键词的条目。返回该应用的所有日志。将结果限制在最后三十分钟。
When possible and practical, logging-as-a-service provided by a third party like Papertrail, AWS, GCP, or Azure is a better option than to host it inside our clusters.
有了服务，我们实现了相同的目标，同时摆脱了我们需要担心的事情之一。这种说法背后的推理与让我相信托管 Kubernetes 服务(例如，EKS、AKS、GKE)是比我们维护的 Kubernetes 更好的选择的逻辑类似。然而，使用第三方“某物即服务”解决方案是不可能的，原因可能有很多。法规可能不允许我们走出内部网络。延迟可能太大。决策者很固执。不管什么原因，当我们不能使用某样东西作为服务时，我们必须自己托管那种东西。在这种情况下，EFK 可能是最好的解决方案，不包括本书范围之外的企业产品。
如果 EFK 可能是自托管集中式日志记录的最佳解决方案之一，那么当我们可以使用日志记录即服务时，我们应该选择哪一种？Papertrail 是个好选择吗？
如果我们的集群在其中一个云提供商内部运行，它可能已经提供了一个很好的解决方案。例如，EKS 有 AWS CloudWatch，GKE 有 GCP Stackdriver，AKS 有 Azure 日志分析。使用其中一个非常有意义。它已经在那里了，很可能已经与您正在运行的集群集成在一起了，您所要做的就是说是。当集群与云提供商之一一起运行时，选择其他解决方案的唯一原因可能是价格。
Use a service provided by your Cloud provider, unless it is more expensive than alternatives. If your cluster is on-prem, use a third-party service like Papertrail, unless there are rules that prevent you from sending logs outside your internal network. If everything else fails, use EFK.
此时，您可能会想，为什么我建议使用日志服务，而我建议我们的指标应该托管在我们的集群中。这不矛盾吗？按照这个逻辑，我们难道不应该也使用度量即服务吗？
我们的系统不需要与我们的日志存储交互。系统需要发送日志，但不需要检索日志。例如，HorizontalPodAutoscaler 不需要挂钩到 Elasticsearch 并使用日志来决定是否扩展 Pods 的数量。如果系统不需要日志来做决策，我们能对人类说同样的话吗？我们需要日志做什么？我们需要日志进行调试。我们需要他们找到问题的原因。我们不需要基于日志的警报。日志不能帮助我们发现问题，但可以通过基于指标的警报找到问题的原因。
等一下！当带有单词 *ERROR* 的日志条目数量超过某个阈值时，我们不应该创建一个警报吗？答案是否定的。我们可以(也应该)通过指标来实现同样的目标。我们已经探索了如何从出口商以及通过仪器获取错误。
当我们通过基于指标的通知检测到有问题时会发生什么？是不是该开始探索原木了？大多数情况下，找到问题原因的第一步不在于探索日志，而在于查询度量。应用关闭了吗？它有内存泄漏吗？网络有问题吗？是否有大量的错误响应？这些问题和无数其他问题都是通过指标来回答的。有时，度量揭示了问题的原因，在其他情况下，它们帮助我们将其缩小到系统的特定部分。只有在后一种情况下，日志才变得有用。
We should start exploring logs only when metrics reveal the culprit, but not the cause of the issue.
如果我们确实有全面的指标，并且它们确实揭示了我们解决问题所需的大部分(如果不是全部的话)信息，那么我们就不需要日志解决方案提供太多信息。我们需要将日志集中起来，这样我们就可以在一个地方找到它们，我们需要能够按应用或特定的副本过滤它们，我们需要能够将范围缩小到特定的时间范围，我们还需要能够搜索特定的关键字。
这就是我们所需要的。碰巧的是，几乎所有的解决方案都提供了这些功能。因此，选择应该基于简单性和拥有成本。
无论你选择什么，都不要陷入对你不会使用的闪亮功能印象深刻的陷阱。我更喜欢易于使用和管理的解决方案。Papertrail 满足所有要求，而且价格便宜。它是内部集群和云集群的完美选择。云观察(AWS)、Stackdriver (GCP)和日志分析(Azure)也是如此。尽管我对 Papertrail 有一点偏好，但这三个人或多或少做着同样的工作，而且他们已经是报价的一部分。
如果不允许您将数据存储在集群之外，或者您对其中一种解决方案有其他障碍，EFK 是一个不错的选择。只是要意识到它早餐会吃掉你的资源，还在抱怨它饿了。仅弹性搜索就至少需要几 GB 的内存，您可能需要更多。当然，如果您已经将弹性搜索用于其他目的，这并不重要。如果是这样的话，EFK 是个没脑子的人。它已经在那里了，所以使用它。
# 现在怎么办？
你知道该怎么做。如果您专门为本章创建了群集，请将其销毁。
在你离开之前，你可能要复习一下本章的要点。
*   对于除了最小的系统之外的任何系统，从一个资源到另一个资源，从一个节点到另一个节点去寻找问题的原因是不实际的、不可靠的和不快速的。
*   `kubectl logs`命令通常没有为我们提供足够的选项来执行除最简单的日志检索之外的任何操作。
*   Elasticsearch 很优秀，但做得太多了。在存储和查询指标以及根据这些数据发送警报方面，它缺乏专注度，因此不如普罗米修斯。
*   日志本身解析起来太昂贵，而且大多数时候它们没有提供足够的数据来充当度量标准。
*   我们需要将日志集中在一个位置，这样我们就可以从系统的任何部分浏览日志。
*   我们需要一种能够过滤结果的查询语言。
*   我们需要快速解决方案。
*   使用云提供商提供的服务，除非比其他服务更贵。如果您的群集在本地，请使用第三方服务，如 Papertrail，除非有规则阻止您将日志发送到内部网络之外。如果其他都失败了，就用 EFK。
*   只有当度量揭示了罪魁祸首，而不是问题的原因时，我们才应该开始探索日志。