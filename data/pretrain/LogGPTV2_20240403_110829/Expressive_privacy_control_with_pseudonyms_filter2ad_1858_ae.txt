0.18/16
0.00/0
33983
0.04/5
0.00/114
79321
0.00/0
0.00/0
350
1.40/23
0.35/5
Table 3: Trace study results under different privacy policies. The numbers show average/maximum over all pseudonyms.
Pseudonyms shows the number of pseudonyms created. Activities shows the number of observed page views by third-party trackers.
Collections shows the number of page views and links followed, as observed by ﬁrst-party trackers.
times from a desktop Linux machine for each website with and
without our system. When using our system, the gateway is lo-
cated within the local network and the tunnel broker is in the same
city. For each iteration, we clear the browser cache and close all
open connections. Figure 10 shows a CDF of median page load
time over 10 iterations of this measurement. We can see that our
implementation adds only small overhead. Median and 90th per-
centile page load time of the top 100 sites increased from 237ms to
367ms, and from 3.6s to 4.3s, respectively.
OS-Level Performance: The number of pseudonyms supported
by our system is limited by the number of IP addresses we can
assign concurrently to a network interface without performance
degradation. For example, the Linux operating system enforces a
conﬁgurable9 default limit of 4096 addresses.
We determine the number of pseudonyms that would be required
under the different privacy policies and compare this to the maxi-
mum number of pseudonyms. The results are shown in the Pseudo-
nyms row in Table 3 and we see that only in the restrictive cases of
policies 4 and 5 do we exceed the default limit. The average num-
ber of pseudonyms is typically below 1000 for the other policies.
Assigning a large number of addresses to each network interface
is feasible today without modiﬁcation to the Linux kernel. Linux
can already assign and utilize 4096 addresses on a single interface
with negligible slowdown in performance. There is no reason to
believe that a very large number of pseudonyms cannot be used
concurrently.
We evaluated the performance of socket operations when a large
number of addresses is allocated to a network interface and found
no slowdown for most socket operations, including socket creation,
9Via /proc/sys/net/ipv6/route/max_size.
connection setup, and sending data (via connect(), accept(),
and send()). Binding the socket to an address using the bind()
system call, however, incurred linear slowdown of up to 8x, de-
pending on the address being bound. Binding addresses took 1
microsecond in the best case and 8 microseconds in the worst case.
This is due to the data structure used to store assigned IP addresses.
Linux uses a linear list of all IP addresses and a hash of the IP ad-
dress as an index into the list. The hash only takes the upper 64 bits
of an address into account and the list has to be searched linearly
for IP addresses that change only the lower 64 bits. With a sufﬁ-
ciently large address pool, traversing the list can incur signiﬁcant
overhead. This can be ﬁxed simply by changing the hash function
to incorporate all bits of the IP address. Further tests on an un-
modiﬁed Linux kernel revealed that OS-level routing tables are not
affected by an increase in addresses, and only the data structure that
holds the list of valid addresses is affected.
Router Performance: Another potential performance issue is
that we add a decryption step for every packet at each router. Al-
though this does increase the complexity of routers, we view this
as an acceptable tradeoff for ﬁne-grained privacy control. Recent
research shows that encrypting and decrypting entire packets at line
speed is possible [10, 12]. Our proposed changes are less extreme
in that we only encrypt a portion of the address. From our mi-
crobenchmarks, our current TDES implementation decrypts at 2.24
million packets per second with one core of an Intel Xeon E5620
2.40 GHz CPU. This scales to 17.92 million packets with 8 cores,
and assuming 1500 bytes per packet, results in over 200 Gbps.
7.2 Privacy Preservation
To investigate how much privacy can be preserved by our sys-
tem, we analyze how much information a web tracker can collect
300about each user in the trace study under each of the privacy policies
presented in Table 2 except d private browsing, which was not used
by any user in our trace study.
To do so, we use collusion graphs [1] that describe page visits
among web domains. Nodes in a collusion graph represent domains
and directed edges from node a to node b represent HTTP requests
made by the browser to domain b due to an action carried out on a
page of domain a, such as following a hyperlink.
Figure 11 shows an example collusion graph of a single web
session extracted from our traces. It includes a lookup of technical
documentation on Google and navigating to a corresponding page
(us.pycon.org). The page in question uses Google Analytics to
track page visits, which accesses several sub-domains to display
active content.
Each privacy policy results in a different number of generated
pseudonyms. We create a collusion graph for each pseudonym and
subsequently evaluate how many different page views a third-party
tracker is able to observe. The Activities row in Table 3 shows
this number for the investigated policies. We see that a separate
pseudonym per browsing session can drastically reduce the amount
of information third-party trackers are able to collect about a user
over a vanilla web browser (trivial) and that narrowing this policy
does little to reduce the amount of information any further (e.g.,
per page). First-party trackers can be limited with a more restric-
tive policy. A pseudonym per request, for example, eliminates all
third-party and most ﬁrst-party tracking, but these policies can also
detrimentally impact the browsing experience. The domain-based
policy (per 1st-party) can provide for a better browsing experi-
ence than the policy of a pseudonym per browsing session because
it allows ﬁrst-party sites to generate personalized proﬁles (e.g., a
Google search proﬁle).
Anonymizers, such as Tor+Torbutton, which use a timeout-based
approach to anonymity and change pseudonyms every 10 minutes
(equivalent to our time-based policy), are less effective in combat-
ing third-party trackers than our simple policy of changing pseudonyms
upon every newly entered URL (i.e., per browsing session). How-
ever, the difference is small and the amount of information gathered
by ﬁrst-party tracking is almost identical. This is because users typ-
ically conduct multiple activities in a relatively short time span on
a website, such as entering multiple search terms, before manually
navigating on to a new site.
In the case of user #5, time-based
anonymization is, on average, even more effective than the policy
of a pseudonym per browsing session. This particular user con-
ducted long web sessions with little activity, such as reading tech-
nical manuals and watching online movies.
7.3 Summary
Our results show that our system is practical and can be deployed
today. Furthermore, it is evident that conﬁgurable privacy policies
are desirable. Because users have differing expectations for privacy
and functionality (e.g., suggestions or directed advertising), there
is no one-size-ﬁts-all policy. Even browsing behavior affects this
choice, as a slower-paced browsing session can beneﬁt just as much
from a timeout-based privacy policy as from a domain-based or
a link-based policy. Thus, a system that allows for more privacy
control is beneﬁcial.
8. DISCUSSION
Without Application Cooperation: For much of this paper,
we rely on applications to create and enforce policies for connec-
tions that they generate. Unfortunately, legacy applications do not
provide this support and may allow tracking. To ﬁx this, we can
sandbox the entire application. This sandboxing can be done with
minimal OS-level support, or can be done by adding pseudonym
support to VM software and running applications within a VM. Al-
ternatively, we can intercept trafﬁc from the application and clas-
sify it at a lower level, but this potentially requires application-
speciﬁc knowledge and cannot handle encrypted communication.
Browser Extension Usability: There are still plenty of im-
provements we can make to our browser extension that would im-
prove the usability of our system. These might include an indi-
cation of what pseudonym is being used for a particular resource
or website and a way to change the pseudonym and reload the
page. Though a user may have many pseudonyms, we can make
management and reuse easier by allowing users to name impor-
tant pseudonyms or by suggesting pseudonyms if they have pre-
viously logged into the website. We can also decrease the need
for manual exceptions and unnecessarily restrictive policies with
whitelists/blacklists. These concerns are left for future work.
9. RELATED WORK
There have been a number of studies that characterize web track-
ing [14, 15, 23]. Additionally, Eckersley [7], Yen et al. [27], and
Nikiforakis et al. [20] point out that implicit information, such as
user-agent or system fonts information, along with IP address can
effectively ﬁngerprint hosts.
As privacy concerns get more attention, many privacy-protecting
mechanisms are being proposed and deployed. Modern browsers
have private browsing modes, but these are not very effective at
mitigating web tracking [4]. Chrome and Firefox support multiple
proﬁles to separate identities, but require manual control and still
leak implicit information. In addition to these, privacy-protecting
extensions have also been proposed. For example, Milk [25] pre-
vents third-party trackers from building user proﬁles across web
sites, and ShareMeNot [23] and Kontaxis et al. [11] provide protec-
tion against tracking using social media widgets. The above mech-
anisms are somewhat effective within their threat models, however,
they cannot prevent adversaries from tracking using IP addresses
as they are all application-layer solutions.
Also related to this work, there are network- and overlay-layer
systems that provide anonymity using onion routing [6, 16]. These
proposals are orthogonal to our work as they do not address applica-
tion-layer privacy and attacks. Our network-layer mechanism pro-
vides a subset of the properties provided by these proposals, but
is simpler and more efﬁcient. Additionally, our solution focuses
on creating unlinkable pseudonyms and giving users more contol
over linkability, which is difﬁcult to achieve with Tor as it uses a
limited number of exposed IP addresses (one from the current Tor
exit node at a given time). Torbutton [21] is a browser extension
that addresses application-level security and privacy concerns, such
as separating the cookie store between Tor and non-Tor sessions,
but provides only limited control over linkability. Privoxy [3] is a
web proxy with comprehensive ﬁltering capabilities and can mod-
ify web requests based on user conﬁguration. Unfortunately, since
it is not attached to the browser, it cannot track activities closely.
Moreover, Privoxy cannot handle HTTPS requests as the connec-
tions are encrypted. Our system can potentially include most fea-
tures of Privoxy in our gateway service. The Address Hiding Proto-
col [22] proposes to assign a random IP address (still from the same
ISP) to hide the original source from the destination. RFC 3041
proposes a privacy extension to stateless IPv6 address autoconﬁgu-
ration that lets hosts generate temporary IPv6 addresses by hashing
interface identiﬁers. These schemes do not address application-
301Figure 11: Example collusion graph generated from a single web session. Nodes represent domains. Edges show which domains
caused HTTP requests to which other domains. Edge labels denote the type of request. Red nodes are web trackers.
layer issues nor do they provide for efﬁcient routing of packets to
randomly assigned addresses [18].
10. CONCLUSION
This paper presents an abstraction called a pseudonym, where
each device and therefore users are able to control and use many,
indistinguishable identities. The pseudonym abstraction gives users
control over which activities can be linked at remote services and
which cannot. We have designed a cross-layer architecture that
exploits the ample IPv6 address space and provides application-
layer mechanisms for management.
In particular, we dive into
the design/implementation of pseudonyms in an especially impor-
tant application: the web browser. Our design provides the abil-
ity for users to choose expressive policies for controlling the pri-
vacy/functionality tradeoff on the web. Our prototype system con-
sists of a browser extension and a gateway proxy and it proves the
feasibility of our concept.
11. ACKNOWLEDGEMENTS
We gratefully acknowledge our shepherd John C.S. Lui and the
anonymous SIGCOMM reviewers. We thank Franzi Roesner and
Tadayoshi Kohno for their thoughtful comments. This work was
partially funded by Cisco and NSF Grant CNS-1040663.
12. REFERENCES
[1] Collusion. http://bit.ly/XZgEM6.
[2] Cookiepie. http://bit.ly/11e3HFE.
[3] Privoxy. http://privoxy.org.
[4] AGGRAWAL, G., BURSZTEIN, E., JACKSON, C., AND
BONEH, D. An analysis of private browsing modes in
modern browsers. In Usenix Security (2010).
[5] CARPENTER, B. Internet transparency. RFC 2775, 2000.
[6] DINGLEDINE, R., MATHEWSON, N., AND SYERSON, P.
Tor: The second-generation onion router. In USENIX
Security (2004).
[7] ECKERSLEY, P. How unique is your web browser? In
Symposium on Privacy Enhancing Technologies (2010).
[8] GOEL, S., ROBSON, M., POLTE, M., AND SIRER, E. G.
Herbivore: A scalable and efﬁcient protocol for anonymous
communication. Cornell University Computing and
Information Science TR2003-1890, 2003.
[9] HSIAO, H.-C., KIM, T. H.-J., PERRIG, A., YAMADA, A.,
NELSON, S. C., GRUTESER, M., AND MENG, W. LAP:
Lightweight anonymity and privacy. In IEEE Symposium on
Security and Privacy (2012).
[10] JANG, K., HAN, S., HAN, S., MOON, S., AND PARK, K.
SSLShader: cheap SSL acceleration with commodity
processors. In NSDI (2011).
[11] KONTAXIS, G., POLYCHRONAKIS, M., KEROMYTIS,
A. D., AND MARKATOS, E. P. Privacy-preserving social
plugins. In USENIX Security (2012).
[12] KOUNAVIS, M. E., KANG, X., GREWAL, K., ESZENYI,
M., GUERON, S., AND DURHAM, D. Encrypting the
internet. In SIGCOMM (2010).
[13] KRISHNAMURTHY, B., NARYSHKIN, K., AND WILLS,
C. E. Privacy leakage vs. protection measures: the growing
disconnect. In WPES (2011).
[14] KRISHNAMURTHY, B., AND WILLS, C. E. Generating a
privacy footprint on the internet. In IMC (2006).
[15] KRISHNAMURTHY, B., AND WILLS, C. E. Privacy diffusion
on the web: a longitudinal perspective. In WWW (2009).
[16] LIU, V., HAN, S., KRISHNAMURTHY, A., AND
ANDERSON, T. Tor instead of IP. In HotNets (2011).
[17] MIKIANS, J., GYARMATI, L., ERRAMILLI, V., AND
LAOUTARIS, N. Detecting price and search discrimination
on the Internet. In HotNets (2012).
[18] NARTEN, T., DRAVES, R., AND KRISHNAN, S. Privacy
extensions for stateless address autoconﬁguration in IPv6.
RFC 4941, 2007.
[19] NARTEN, T., HUSTON, G., AND ROBERTS, L. IPv6 address
assignment to end sites. RFC 6177, 2011.
[20] NIKIFORAKIS, N., KAPRAVELOSY, A., JOOSEN, W.,
KRUEGELY, C., PIESSENS, F., AND VIGNAY, G. Cookieless
monster: Exploring the ecosystem of web-based device
ﬁngerprinting. In IEEE Symposium on Security and Privacy
(2013).
[27] YEN, T.-F., XIE, Y., YU, F., YU, R. P., AND ABADI, M.
Host ﬁngerprinting and tracking on the web: Privacy and
security implications. In NDSS (2012).
[21] PERRY, M. Torbutton design documentation.
https://www.torproject.org/torbutton/en/design/index.html.en,
2011.
[22] RAGHAVAN, B., KOHNO, T., SNOEREN, A. C., AND
WETHERALL, D. Enlisting ISPs to improve online privacy:
IP address mixing by default. In Symposium on Privacy
Enhancing Technologies (2009).
[23] ROESNER, F., KOHNO, T., AND WETHERALL, D.
Detecting and defending against third-party tracking on the
web. In NSDI (2012).
[24] SAVOLA, P. Mtu and fragmentation issues with
in-the-network tunneling. RFC 4459, 2006.
[25] WALLS, R. J., CLARK, S. S., AND LEVINE, B. N.
Functional privacy or why cookies are better with milk. In
HotSec (2012).
[26] WILLS, C. E., AND TATAR, C. Understanding what they do
with what they know. In WPES (2012).
encrypted-tbn0.gstatic.comfonts.googleapis.comajax.googleapis.comwww.google.comimagemain_framelh3.googleusercontent.comimagessl.gstatic.comimageplus.google.comxmlhttprequestus.pycon.orgmain_frameid.google.comimageapis.google.comscriptstylesheetscriptssl.google-analytics.comstylesheetscriptscriptstylesheet302