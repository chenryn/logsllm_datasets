while True do
to members of committee i
end for
return True
34:
35:
end if
36:
end while
37:
38: end procedure
(cid:46) Done by directories
w ← ReceivePoW() (cid:46) Accept all PoWs in last round
i ← GetCommitteeNo(w)
if len(commList[i])  2λ + c − log(c)/2), the advantage of the adversary is
negligible in λ.
4. SECURITY ANALYSIS
In this section, we provide security analysis for how ELASTICO
prevents potential threats and works securely. We also discuss how
byzantine adversary gain no signiﬁcant advantage.
We begin by clarifying several assumptions. First, we assume
that the network is partially synchronous: any message can reach
the destination with a maximum delay of δt, thus network protocol
can be assumed to happen in rounds, each lasts for δt time. All
our claims for an epoch depend on there being sufﬁciently random
strings generated in the previous epoch.
Deﬁnition 1 (Good randomness). We say that an epoch has a
good randomness if:
(i) every user has a publicly random string of r bits, veriﬁably
generated in the previous epoch;
(ii) no user has access to such a veriﬁable random string more
than δt prior to the beginning of the epoch;
(iii) malicious users can bias the randomness with negligible prob-
ability.
We now prove the security properties of ELASTICO. In particu-
lar, we start with S1, which states honest identities take a dominate
portion in all the generated identities.
Lemma 2 (S1: Good Majority). In every epoch with good ran-
domness, for every sufﬁciently large integer n(cid:48) ≥ n0: among the
ﬁrst n(cid:48) identities created, at most n(cid:48)/3 − 1 are controlled by the
adversary w.h.p.
Proof. If all the users start at the same time, each solution gener-
ated has a probability 1 − f = 3/4 of being taken by the honest
processors. Now, let Xi be an indicator random variable which
takes value one if the ith identity is generated by an honest proces-
i=1 Xi. Then, X follows a binomial distribution.
sor. Let X =(cid:80)n(cid:48)
Thus we have:
Pr(cid:2)X ≤ 2n
(cid:48)
/3(cid:3) =
=
(cid:100)2n(cid:48)/3(cid:101)(cid:88)
(cid:100)2n(cid:48)/3(cid:101)(cid:88)
k=0
k=0
Pr[X = k]
(cid:32)
(cid:33)
n(cid:48)
k
f n(cid:48)−k(1 − f )k
This probability decreases exponentially in n(cid:48). Given a security pa-
rameter λ, we can ﬁnd n0 such that Pr [X ≤ 2n(cid:48)/3] ≤ 2−λ,∀n(cid:48) ≥
n0.
The committee size c is at least n0 to guarantee that the fraction
of malicious members in a committee is bounded by 1/3, with re-
gard to the security parameter λ. The value of n0 depends on the
security parameter λ. For example, if λ = 20, or the probabil-
ity that something bad happens is once every 1 million epochs, we
have n0 ≈ 600.
Lemma 3 (S2: Good views with bounded inconsistency). In every
epoch with good randomness, if the directory size is c, then for
each committee, with high probability, we guarantee the following
properties.
(i) Each member has their own view of who are in the commit-
tee. Two views of two honest members differ by at most 1/3
of the committee size;
(ii) All honest members have identities of other honest members
in their views;
(iii) The total number of unique identities in all views is at most
3c/2 of which less than 1/3 fraction are malicious.
Proof sketch. The inconsistency between views of member set is
because of two reasons: network latency and byzantine behaviors.
We calculate the difference in views caused by each source.
Since the network delay and the probability in ﬁnding a PoW so-
lution, e.g., it is hard to tell who are the last committee members.
Since honest directories accept all valid PoWs in the last round
(before the committee gets ﬁlled by at least c members), all hon-
est committee members will have other honest identities in their
view. This leaves the malicious behaviors the main source of the
discrepancy.
Malicious processors can decide to withhold their identities and
only publish them in some particular time to cause the maximum
discrepancy between views of member set of honest members. How-
ever, honest members always share the same view of honest identi-
ties, thus the maximum discrepancy that an adversary can cause is
the number of identities that he/she can create. As per Lemma 2,
this amount is always less than 1/3 of the total number of commit-
tee members w.h.p.
We next prove that the maximum number of identities in all
views is 3c/2 and less than c/2 identities are malicious. An ad-
versary can wait until right before the last identity in a committee
is found to publish all his/her identities. According to Lemma 2,
the maximum number of malicious identities can be created before
honest processors ﬁnd all c identities is c/2. Thus, the total num-
ber of identities is bounded by 3c/2 and at most c/2 identities are
(cid:3)
malicious w.h.p.
We now show S3, S4 which argue that a committee (including
the ﬁnal committee and other commitees) correctly decides a single
value (or a set of transactions Xi).
Lemma 4 (S3, S4: Consensus). In every epoch with good random-
ness, the honest members agree on a unique set Xi with at least
c/2 + 1 signatures, with high probability.
Proof. Although committee members have different views of mem-
ber set, we can tolerate the inconsistency by considering a broader
committee of size up to 3c/2. As we have established above, the
fraction of malicious identities is bounded by 1/3 in any view, and
honest members have other honest members in their view. Thus,
any Byzantine consensus protocol (e.g., POLYBYZ, PBFT) which
can tolerate up to 1/3 malicious fraction can guarantee agreement
in the committee, i.e., only one value selected.
Since our network is synchronous, the liveness property is al-
ways achieved in these consensus protocols, i.e., the committee al-
ways reaches consensus in polynomial time. The committee then
collects enough number of signatures (e.g., c/2 + 1) to guarantee
that at least one honest member has signed the chosen value.
Lastly, we show Lemma 5 and S5, i.e., the shared randomness
generated is sufﬁciently random. Speciﬁcally, we derive the fol-
lowing deﬁnition from the standard deﬁnitions of bias [28].
Deﬁnition 1. Let F : {R0, R1, .., Rc} (cid:55)→ {0, 1}r, computed over
the set of r-bit input strings. For all choices of set S ⊆ {0, 1}r, let
EF (S) be the expected number of R values that the adversary can
generate such that R ∈ S. Assuming the adversary controls some
of the inputs, the bias β(F ) is deﬁned as:
(cid:26) EF (S)
E(S)
,
E(S)
EF (S)
(cid:27)(cid:33)
,
(cid:32)
β(F ) = log
S ⊆ {0, 1}r
max
max
in which E(S) = |S|/2r — the value of EF (S) if the adversary
does not control any inputs.
Lemma 5 (Bounded Bias to Randomness). Given a set of c > 3
random r-bit strings of which at most (cid:98)c/2(cid:99) strings are known and
generated by the adversary, the computation of R = ⊕Ri has a
bias bounded by c − log(c)/2.
Proof. We deﬁne F : {R0, R1, .., Rc} (cid:55)→ {0, 1}r as a function
which selects c/2 + 1 strings Ri from c strings and compute R =
⊕Ri. The computation of R can be decomposed into F = Fh ⊕
Fd, in which Fd is computed over the set of inputs controlled by
the adversary, and Fh is computed over the set of inputs Rh from
honest users which the adversary does not know.
The bias of Fd, by deﬁnition of bias is c−log(c)/2. This follows
from the fact that the adversary can pick (cid:0) c
(cid:1) combinations of
c/2 strings Ri to decide Rd. This number has an upper bound of
2c−log(c)/2 computed based on Stirling’s approximation. Thus, we
have
β(Fd) < c − log(c)/2.
On the other hand, Rh is not generated by the adversary, so bias of
Fh is 0 because EFh (S) = E(S). By composition, the total bias
is c − log(c)/2.
c/2
Lemma 6 (S5: Good Randomness). In every epoch with good ran-
domness, with high probability, at the end of the epoch every user
computes a random string of r bits that:
(i) can be predicted with a negligible probability;
(ii) can be veriﬁed as validly generated in that epoch.