ence the contents of an arbitrary partition p after n transitions
have occurred from an arbitrary reachable state s are PSched
and those in sources n s p. This condition is phrased by
considering the counterfactual case in which the state s
is modiﬁed to produce a new reachable state t such that
sources n s p≈
t and s PSched∼ t, and then asserting that s(cid:2) p∼ t(cid:2)
s
for all states s(cid:2) and t (cid:2) reached after performing n transitions
from s and t respectively, abbreviated s p∼n t.
nonleakage ≡ ∀ n s t p. reachable s ∧ reachable t ∧ s PSched∼ t
∧ s
t −→ s p∼n t
sources n s p≈
This deﬁnition considers pairs of ﬁnite executions of
identical length n, in line with the observation above that
purge-based deﬁnitions are not appropriate in our setting.
This deﬁnition is also entirely termination insensitive,
because it is trivially satisﬁed when non-termination occurs.
However, the functional correctness proof for seL4 proves
that its execution is always deﬁned, implying that all transi-
tions for the transition system depicted in Figure 4(a) always
terminate. Under the assumption that the interrupt oracle
delivers an inﬁnite stream of timer interrupts, it is relatively
straightforward to prove that the coalesced transitions of the
transition system depicted in Figure 4(b) always terminate
too—since a timer interrupt will always arrive that then
causes the scheduling partition to take over. Hence, non-
termination is not an issue and a termination insensitive
formulation of information ﬂow security is appropriate here.
D. Information Flow Theorem
Let MA be the automaton for the seL4 abstract speciﬁca-
tion, and nonleakageA denote nonleakage applied to MA.
The top-level information ﬂow theorem we prove for MA,
simpliﬁed for presentation, is the following.
Theorem 1: seL4’s abstract speciﬁcation enforces in-
formation ﬂow security. Let s0 denote the initial state of
the system, after conﬁguration, and pas be an access control
policy, and (cid:2) the corresponding information ﬂow policy.
Then if s0 satisﬁes the kernel invariants, pas is consistent
with s0 and wellformed for all subjects, and all interrupts
other than the timer interrupt are disabled in s0, and all
subject-crossing capabilities are safe in the sense described
below in Section IV-E, then nonleakage is enforced:
invs s0 ∧ pas-reﬁned-wellformed pas s0 ∧ only-timer-irq s0 ∧
sscc pas s0 −→ nonleakageA
Here, sscc is a condition on capabilities that cross parti-
tion boundaries, described later in Section IV-E. Intuitively,
it ensures that partition-crossing communication channels
can never be destroyed, as destroying an otherwise uni-
directional channel signals to both sender and receiver.
Letting MC be the corresponding automaton for the seL4
C implementation, and nonleakageC denote nonleakage ap-
plied to MC, the functional correctness proof [27] implies
that: MA (cid:2) MC. We then have that because nonleakage
is preserved by reﬁnement: MA (cid:2) MC ∧ nonleakageA
−→ nonleakageC. Information ﬂow security for seL4’s C
implementation then follows trivially.
Theorem 2: seL4’s C implementation enforces infor-
mation ﬂow security. Let s0 denote the initial state of the
system, after conﬁguration, and pas be an access control
policy, and (cid:2) the corresponding information ﬂow policy.
Then:
invs s0 ∧ pas-reﬁned-wellformed pas s0 ∧ only-timer-irq s0 ∧
sscc pas s0 −→ nonleakageC
422
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:53:26 UTC from IEEE Xplore.  Restrictions apply. 
E. Proving Information Flow Security
Like other noninterference variants, nonleakage is proved
by discharging proof obligations called unwinding condi-
tions that examine individual execution steps. The following
unwinding condition, called conﬁdentiality-u, is sound and
complete for (i.e. is equivalent to) nonleakage [36].
conﬁdentiality-u ≡ ∀ p s t. reachable s ∧ reachable t ∧ s p∼ t
∧ s PSched∼ t ∧ (part s (cid:2) p −→ s part s∼ t) −→ s p∼1 t
It says that the contents of each partition p after each step
can depend only on the contents of the following partitions
before the step: p, PSched and the currently running parti-
tion part s when it is allowed to send information to p. In
other words, information may ﬂow to p only from PSched
and the current partition in accordance with the information
ﬂow policy (cid:2).
To prove this condition for the execution steps of our
transition system (depicted in Figure 4(b)), we consider the
following cases.
Case 1 — part s (cid:2) p: In this case conﬁdentiality-u
collapses to the following property, noting that part s (cid:2)
p ∧ p = PSched −→ part s = PSched because, (cid:2) is
purposefully constructed so that ∀ p(cid:2). p(cid:2) (cid:2) PSched −→ p(cid:2)
= PSched:
∀ p s t. reachable s ∧ reachable t ∧ s p∼ t ∧ s PSched∼ t
∧ part s (cid:2) p ∧ s part s∼ t ∧ (p = PSched −→ part s
= PSched) −→ s p∼1 t
This property we discharge using a relational proof
calculus [36], similar in style to the seminal work of
Benton [10] and other reasoning systems for conﬁdentiality
properties [4], [5], with an automated veriﬁcation condition
generator [14].
(1)
We prove Property 1 for each of the small transitions of
Figure 4(a) to conclude it holds for the coalesced transitions
of Figure 4(b).
Case 2 — part s (cid:11)(cid:2) p: In this case, we consider two
sub-cases.
a) p = PSched
(2.a)
In this case, we prove the following condition, noting
that part s (cid:11)(cid:2) p ∧ p = PSched −→ part s (cid:11)= PSched
because (cid:2) is reﬂexive:
∀ s t. reachable s ∧ reachable t ∧ s PSched∼ t ∧
part s (cid:11)= PSched −→ s PSched∼ 1 t
This requires us to show that the scheduling partition’s
contents after a transition of another partition depends
only on its contents beforehand. All of PSched’s con-
tents remains unchanged during the execution of other
partitions except the current position of the interrupt
oracle (Section IV-B). As explained earlier, however,
the transition system of Figure 4(b) is purposefully
constructed to reﬂect the reality that the oracle position
after the execution of a non-scheduling partition will
timer
always be precisely the position of the next
interrupt in the stream. The location of all timer in-
terrupts in the oracle stream and the current oracle
position are included in PSched’s contents, under the
assumption that all partitions are allowed to learn about
the passage of global time. Hence, Property 2.a above
follows easily.
b) p (cid:11)= PSched
In this ﬁnal case we use Sewell et al.’s integrity theo-
rem [51] for seL4 (Section III-D) to prove the following
property, which says that the current transition may
not alter p at all. conﬁdentiality-u then follows from
symmetry and transitivity.
∀ p s s(cid:2). reachable s ∧ p (cid:11)= PSched ∧ part s
(cid:11)(cid:2) p ∧ (s, s(cid:2)) ∈ Step −→ s p∼ s(cid:2)
Integrity holds for all of the small transitions of Fig-
ure 4(a), and thus holds for the coalesced transitions of
Figure 4(b), and so implies Property 2.b.
(2.b)
Of these cases, Case 1 is the most interesting and con-
sumed the bulk of the work. We brieﬂy describe the most
illuminating aspects of this effort.
As mentioned above,
to prove Property 1 across the
compound transitions of Figure 4(b), we proved it across
each of the individual component transitions of Figure 4(a).
There are essentially two distinct sets of transitions to
consider here, namely those for the scheduling partition and
those for non-scheduling partitions.
The proofs for the scheduling partition necessarily cover
the case where the scheduler does a partition switch when
the timeslice of the current partition expires. In this case,
proving Property 1 for the situation in which p is the
new partition being scheduled involves showing that the
partition switch leaves no residual information behind from
the old partition that was previously running. The ARM
implementation of seL4 maintains a ﬁxed page of memory,
called the globals frame, that is shared between all threads
and at any point in time contains information relevant to
the currently running thread. When scheduling a thread, the
kernel writes new data to this page for the now active thread.
Part of proving Property 1 therefore involved proving that the
globals frame, which essentially moves between partitions
on each partition switch, contains no residual information
after a partition switch and so cannot serve as a covert
storage channel. The same also had to be done for the
machine context, which includes the CPU registers that are
saved and restored on kernel entry and exit respectively, as
well as all other global resources that are shared between
partitions like the system idle thread.
The proofs for Property 1 for non-scheduling transitions
mostly involve reasoning that the state read by the kernel
when performing a system call for the currently active parti-
tion is contained within the extent of the current partition—
i.e. that the kernel reads only state that it is permitted to
423
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:53:26 UTC from IEEE Xplore.  Restrictions apply. 
reveal to the current partition. These proofs were relatively
straightforward, and beneﬁted from substantial automation.
The exceptions to this rule, however, are system calls
that facilitate communication between partitions. One such
system call is that for sending a message on an asynchronous
endpoint, send-async-ipc. Proving Property 1 for this system
call requires considering the case in which p is the current
partition who is sending on the asynchronous endpoint. In
this case, we must prove that p’s contents after the system
call do not depend on the contents of the asynchronous
endpoint being sent on (which necessarily lives outside of p’s
extent) nor the contents of any partition who is waiting on
the endpoint in question and so who will receive the message
being sent. In other words, proving Property 1 involves
proving that the kernel’s implementation of asynchronous
endpoints has no covert storage back-channels.
The kernel necessarily reads the internal state of the
endpoint being sent on, so we must prove that the kernel
reveals none of this read state to p. This involves considering
all possible internal states that the endpoint being sent on
might be in, and proving that the effects of send-async-ipc as
observed by the sending partition are identical in all cases.
These proofs had to be performed more manually, and were
amongst the most challenging for the entire effort.
Besides the kernel’s primitive facility for interrupt deliv-
ery, which we exclude by assuming that all non-timer IRQs
are disabled, the only other problematic kernel behaviour
that we encountered during the proof was object deletion.
Speciﬁcally, seL4 deletes an object when the last capability
to that object is deleted. This capability is called ﬁnal. Thus
the behaviour of the kernel, when a capability is deleted,
depends on which other partitions possess a capability to
the same object. This opens up a potential storage channel.
As with interrupt delivery, we avoided this problem by
placing an assumption on the initial conﬁguration of the
system. We assume that when the partitions were set up that
an extra inert CNode was also created, to which no partition
was granted access, and that a copy of every subject-crossing
capability was placed into this inert CNode. A subject-
crossing capability is one that refers to a subject that is dif-
ferent from the one that possess the capability, with subject
boundaries deﬁned with reference to the access control pol-
icy pas. Since these copies can never be deleted (because no
subject has access to the inert CNode that holds them), this
ensures that only non-subject-crossing capabilities can ever
become ﬁnal. This assumption is formalised by the property
sscc, which stands for safe subject-crossing capabilities.
It is relatively easy to prove that sscc is invariant. Under
sscc,
the behaviour when deleting a capability depends
only on the currently running partition, and so ensures that
conﬁdentiality is not violated. Intuitively,
this restriction
enforces that communication interfaces between partitions
should be static, because any change in that interface causes
a bidirectional information ﬂow.
V. DISCUSSION
Having presented our proof and statement of information
ﬂow security for seL4, we now analyse its strengths and
limitations, and relate the result to its practical signiﬁcance.
The history of computer security is littered with published
security proofs that were later broken by novel exploits and
attacks. This happens when: (1) the proof is incorrect, i.e. not
logically valid, (2) the proof’s assumptions are not realistic,
or (3) the property proved was not strong enough or does
not mean what we thought it did. We consider each in turn.
A. Proof Correctness
Our proof for seL4 is machine-checked, and carried out in
the interactive theorem prover Isabelle/HOL [38], which is
a prover for higher-order logic in the so-called LCF family
with strong soundness properties: all derivations must pass
through a small proof kernel. While a defect in the Isabelle
proof kernel may permit errors in our proof, this possibility
can be made arbitrarily small by extracting the proof term
from Isabelle and running it
through a series of small,
independently written proof-checking programs. Errors in
the proof itself are therefore a non-issue in practice [21].
B. Assumptions
it assumes that
The assumptions on which our proof rests are realistic,
and amenable to validation. Our proof makes three ex-
plicit assumptions about the seL4 conﬁgurations to which
it applies. Firstly,
the system has been
correctly conﬁgured to enforce information ﬂow control,
by asserting that
the access control policy is consistent
with the initial state and wellformed. Secondly, it assumes
that only the timer interrupt, used by the kernel to control
scheduling, is enabled. Thirdly, it assumes that there exist
inert copies of all subject-crossing capabilities to prevent
any such capability from becoming ﬁnal (see Section IV-E).
The ﬁrst of these is an obvious requirement. The second and
third are required to ensure that kernel functionality that is
potentially problematic for separation is never invoked. Each
of these assumptions is easily ensured by careful system ini-
tialisation, which itself is amenable to formal veriﬁcation [6].
Only the latter two place limitations on the kinds of systems
that can be constructed, by forcing device drivers to poll