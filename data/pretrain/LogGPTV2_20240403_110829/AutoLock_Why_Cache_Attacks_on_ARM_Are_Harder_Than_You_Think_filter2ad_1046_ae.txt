-
-
-




-

Surge S1
core, cross-core, and cross-CPU. A ‘’ or ‘*’ signi-
ﬁes that an attack can be mounted, whereas a ‘’ indi-
cates that AutoLock fundamentally interferes with the
attack. Given the nature of AutoLock, all same-core at-
tacks remain possible, as the adversary can evict target
memory from all core-private cache levels. All attacks
based on a full-hierarchy ﬂush instruction are also not af-
fected by AutoLock. However, said ﬂush instruction, un-
like on x86 processors, is not available on any ARMv7-
A compliant processor and must be enabled in control
registers on ARMv8-A compliant processors. Access
to these control registers is limited to privileged, i.e.,
kernel or hypervisor code. These ﬂush based attacks,
namely Flush+Reload and Flush+Flush, are there-
fore denoted with ‘*’.
In contrast to these attacks, all
techniques that rely on evicting a cache line, namely
Evict+Time, Prime+Probe, and Evict+Reload, are
impaired by AutoLock in cross-core scenarios.
While it’s possible to state AutoLock’s fundamental
impact on state of the art attack techniques, its effect
and presence on actual devices is more difﬁcult to asses.
Based on our experiments, we currently assume that
AutoLock is primarily implemented on Cortex-A cores
designed by ARM itself. As the concept is protected
by US patent [50], ARMv7-A and ARMv8-A compli-
ant cores, such as Qualcomm’s Krait 450, would have
to pay royalties to implement AutoLock. We therefore
assume that compliant cores refrain from implementing
AutoLock. Based on these assumptions, Table 5 tries to
illustrate the impact of AutoLock on recent smartphones.
It lists devices from major manufacturers that have high
global market shares [16]. For each of them, we select
smartphones that have recently been introduced or an-
nounced. For every device, the corresponding SoC and
processor cores are shown. In addition, the table states
whether we expect AutoLock to be implemented (indi-
cated by a ‘’) or whether a device’s exposure remains
unknown (indicated by a ‘-’). A signiﬁcant fraction of
devices shown in Table 5 feature an ARM Cortex-A53,
which we found to implement AutoLock. While newer
cores such as the Cortex-A72 and A73 might be affected
as well, it remains unclear whether this also holds for the
ARM-compliant cores, such as the Kryo (the successor
of the Krait), the Mongoose (M1, M2), as well as the
cores integrated into the Apple SoCs.
If a device implements AutoLock, adversaries must
ﬁnd and employ circumvention strategies to leverage the
full potential of eviction based cache attacks. In general,
such strategies can also be used to target non-inclusive
LLCs, where cross-core evictions are not possible, ei-
ther. In the upcoming section, we discuss circumvention
strategies and demonstrate that the attack proposed by
Irazoqui et al. [29] can still be mounted in a cross-core
Evict+Reload scenario with an inclusive LLC imple-
menting AutoLock.
7 Circumventing AutoLock
Despite the restrictions that Automatic Lockdown
poses to eviction based cache attacks, its effects can be
alleviated with the following strategies:
• Pre-select Target SoCs: Our ﬁndings suggest that
AutoLock is present on Cortex-A cores designed
by ARM itself, while it is not implemented by
ARM compliant cores, such as Qualcomm’s Krait
450. As previously stated, this might be due to
the protection of the concept by US patent [50].
By exclusively targeting Cortex-A compliant pro-
cessors not implemented by ARM, chances of not
encountering AutoLock might increase. Alterna-
tively, Flush+Reload or Flush+Flush based at-
tacks can still be mounted on ARMv8-A SoCs that
offer the cache ﬂush instruction in userspace, i.e.
the Samsung Galaxy S6 [37].
• Achieve Same-core Scenario: Certain attack sce-
narios realistically allow the adversary to execute
code on the same core as the target program. Since
same-core attacks are not affected by AutoLock,
this entirely removes its impact. ARM TrustZone,
e.g., enables the secure execution of trusted code
1086    26th USENIX Security Symposium
USENIX Association
on an untrusted operating system. Given that the
untrusted OS is compromised by the adversary, the
trusted code can be scheduled to run on any given
processor core. By matching the core afﬁnity of the
attacking process to the one of the respective trusted
target, the attack is reduced to a same-core setting
and can successfully be mounted, even across TEE
boundaries [54].
• Trigger Self-evictions: When AutoLock is active,
a cache line can only be evicted from the inclusive
LLC if no higher cache level contains a copy of it.
If the target program offers services to the rest of
the system, the adversary can try to issue requests
such that the core-private cache of the target is suf-
ﬁciently polluted and the cache line under attack is
evicted. The target program essentially performs
a ‘self-eviction’ and thus re-enables LLC evictions
and consequently cross-core attacks.
• Increase Load and Waiting Time:
Inclusive
caches with AutoLock require that the number of
ways in lower levels are greater or equal than the
sum of ways in all higher cache levels. This limits
the associativity of core-private caches, which the
LLC is inclusive to, especially on multi-core sys-
tems. If the attack allows, an adversary can take ad-
vantage of the low associativity and simply prolong
the waiting time between reloads such that the target
line will automatically be evicted from core-private
caches by other system activity scheduled on the re-
spective core. To amplify the effect, the adversary
can also try to increase overall system load, e.g.,
by issuing requests to the OS aiming at increasing
background activity in the targeted core.
• Target Large Data Structures: Self-evictions,
high system load, and prolonged waiting times all
increase the chances that a cache line is evicted by
itself from core-private caches. The success rate
of an attack is further improved, if multiple cache
lines can be targeted. The more lines that are ex-
ploitable, the higher the chances that at least one
of them is automatically evicted from core-private
caches. For example, the transformation tables (T-
tables) of AES software implementations span mul-
tiple cache lines due to their size of several kilo-
bytes. The attack proposed by Irazoqui et al. [29]
observes the ﬁrst line per table to recover an entire
AES key. The authors note that “any memory line of
the T table would work equally well.” In the upcom-
ing section, we pick up this idea and demonstrate
how the attack can be extended to exploit multiple
cache lines to successfully circumvent AutoLock.
Note that all of the presented strategies increase the
chances of successful attacks not only on inclusive
caches implementing AutoLock, but also on non-
inclusive caches.
7.1 Attack on AES
Irazoqui et al. [29] propose an attack on table based im-
plementations of AES using Flush+Reload. The basic
strategy is to ﬂush one cache line per table before an en-
cryption and reload it afterwards.
If any lookup table
value stored on the observed cache line is used during en-
cryption, the adversary will encounter fast reload times.
If said line is not accessed, it will be fetched from exter-
nal memory and reload times will be slow. With all table
lookups dependent on the secret key, the adversary can
infer bits of the key from the observed reload times.
In table based implementations of AES, each cache
line has a certain probability with which it is not used
during en- or decryption. This probability depends on
the size and the number of the tables as well as the size
(cid:16)
of the cache lines. It is deﬁned as
1− t
256
(cid:17)n
Pna =
.
(1)
Variable t denotes the number of table entries stored on
a cache line. For 4-byte entries and a 64-byte cache line,
t = 16. Variable n deﬁnes the number of accesses to the
table that a cache line is part of. Given an AES-128 im-
plementation that uses four 1 kiB T-tables and performs
160 lookups per encryption, which evenly spread over
the four tables, n = 40. With t = 16, this yields a no-
access probability of Pna = 0.0757. Note that the attack
exploits observations of not accessed cache lines. As a
result, the number of required observations increases, as
Pna gets smaller.
The attack targets the last round of AES, i.e., the 10th
round. It is shown in Equation 2. The ciphertext is de-
noted as ci (i = 0..15). The 10th round key is given as
k10
, whereas the state of AES is deﬁned as si. The target
i
lookup table used in the last round is denoted as T . For
each encryption, the adversary keeps track of the reload
times and the ciphertext. If successful, the attack recov-
ers the last round key. For the recovery phase, the last
round is re-written as
ci = k10
i ⊕ T [si] → k10
i = ci ⊕ T [si] .
(2)
Improvements The original attack targets one cache
line per table. If the observations of said line are of poor
quality, the attack is prolonged or fails. This can hap-
pen on a processor that implements AutoLock or non-
inclusive caches.
If LLC evictions fail, the adversary
cannot determine whether the selected cache line has
USENIX Association
26th USENIX Security Symposium    1087
been used during encryption. Irazoqui et al. [29] state
that the attack works equally well with all cache lines
carrying lookup table entries. As discussed in the previ-
ous section, it is likely in practice that some of them are
automatically evicted from core-private caches, hence
re-enabling the attack despite AutoLock. To leverage
observations from all available cache lines, we propose
three improvements to the original attack:
1. Majority vote: All available cache lines l are at-
tacked (l = 0..L). This yields L recovered keys. For
each key byte, a majority vote is done over all L re-
covered values. The value with the most frequent
occurrence is assumed to be the correct one. If two
or more values occur equally frequently, the lowest
one is chosen. The majority vote ensures that wrong
hypotheses from noisy cache lines are compensated
for as long as the majority of lines yield correct re-
sults.
2. Probability ﬁlter: The reload times allow to calcu-
late the actual no-access probability for each cache
line, ˜Pl
na. For each table, the line closest to the ex-
pected theoretic probability, Pna, is taken and used
in the attack. Lines showing distorted usage statis-
tics due to noise and interference are discarded.
of the no-access probabilities, dl = abs(cid:0)Pna − ˜Pl
3. Weighted counting: Every cache line is assigned
an individual score Sl that is counted each time a
key byte hypothesis is derived from the line’s reload
times. The score is based on the absolute difference
na
It is deﬁned as Sl = 1− dl
1−Pna . After all scores have
been added for all hypotheses, the recovery phase
proceeds as proposed.
(cid:1).
We implement the original attack and all improve-
ments using Evict+Reload on a multi-core ARM
Cortex-A15 processor featuring a data-inclusive LLC
with AutoLock. We employ sliding window eviction
with parameters 36-6-2 (see Table 1). The targeted AES
implementation uses four 1 kiB T-tables. The adver-
sary and target processes are running on top of a full-
scale Linux operating system. In total, we perform ﬁve
different attacks. First, we implement the original at-
tack with adversary and target on the same core and
then on separate cores. This illustrates the impact of
AutoLock, which only affects cross-core attacks. The
rest of the attacks are conducted with adversary and tar-
get on separate cores and each demonstrate one of the
proposed improvements. The results are illustrated in
Figure 4. Each attack is repeated for 100 random keys
and the average number of correctly recovered key bytes
is shown over an increasing number of encryptions. It
Figure 4: Evict+Reload attacks on an ARM Cortex-
A15 with AutoLock; performed for 100 random keys.
The number of key bytes recovered on average are dis-
played for an increasing number of encryptions.
can clearly be seen that AutoLock impairs the origi-
nal cross-core attack (orig_cross). After 400,000 en-
cryptions no more than 5 key bytes are correctly recov-
ered. The fact that at least some key bytes are correct
is owed to sporadic and automatic evictions of the ob-
served cache lines from the target’s core-private cache.
These evictions can be caused by stack and heap data ac-
cesses (such as AES state and key arrays as well as their
pointers), and possibly by unrelated processes sched-
uled on the same core. Attacks in the same-core set-
ting (orig_same) are not affected by AutoLock and al-
low full-key recovery. Our improvements clearly demon-
strate that cross-core attacks are still possible, if multiple
cache lines can be observed. Both majority vote (major-
ity) and weighted counting (weighted) recover the entire
key with less than 100,000 encryptions and therefore of-
fer similar success rates as the same-core attack. The
probability ﬁlter (prob_ﬁlter) still allows full-key recov-
ery within 100,000 encryptions, if a brute-force search
with complexity < 232 is added.
The results illustrate that even on processors imple-
menting AutoLock cache attacks can still be successful
in practice, if multiple cache lines are monitored. Note
that the proposed improvements are also beneﬁcial on
processors without AutoLock or on systems with non-
inclusive caches. If attacks rely on observing a speciﬁc
cache line, the chances of success are signiﬁcantly re-
duced on processors implementing AutoLock.
1088    26th USENIX Security Symposium
USENIX Association
0100200300400Encryptions (¢103)0246810121416Recovered key bytesorig_crossorig_samemajorityprob_filterweighted8 Conclusion
The licensing ecosystem of ARM drives an increasingly
heterogeneous market of processors with signiﬁcant mi-
croarchitectural differences. Paired with a limited under-
standing of how ARM’s cache architectures function in-
ternally, this makes assessing the practical threat of ﬂush
and eviction based cache attacks on ARM a challenging
task. Although the feasibility of state of the art attacks
has been demonstrated, their requirements are far from
being fulﬁlled on all ARM processors. Flush instruc-
tions are supported only by the latest architecture ver-
sion and must explicitly be enabled for userspace appli-
cations. This limits the practical utility of ﬂush based at-
tacks. Last-level caches can be non-inclusive, impeding
practical cross-core eviction attacks that require LLCs
to be inclusive. Our work shows that these attacks can
still fail even on inclusive LLCs, if AutoLock is im-
plemented. On the contrary, more sophisticated attack
techniques seem to overcome both AutoLock and non-
inclusive cache hierarchies. We therefore believe that a
fair and comprehensive assessment of ARM’s security
against cache attacks requires a better understanding of
the implemented cache architectures as well as rigorous
testing across a broad range of ARM and thereto compli-
ant processors.
Acknowledgments