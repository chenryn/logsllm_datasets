enue for using stale bid information; even in the most conservative cases, the
revenue is within ±0.1% of today. For advertisers, while stale bids affect their
auction rankings, they do so in a balanced manner with cases of higher-than-
40
)
%
(
e
u
n
e
v
e
r
r
e
k
o
r
B
n
i
e
g
n
a
h
C
 0.15
 0.1
 0.05
 0
-0.05
-0.1
-0.15
1m 2m 5m 15m 30m 1h
2h
3h
6h
12h
1d
36h
2d
Staleness
Figure 5.1: Change in broker’s revenue
today rank canceling out cases of lower-than-today rank resulting in zero net
change.
Figure 5.1 plots the change in broker revenue compared to today as a func-
tion of the staleness of information used and the user model. The x-axis varies
the stateless of bids from 1 minute to 2 days. The box-and-whisker plot varies
the user model with the top whisker showing the outcome where the user clicks
the same position, and the bottom whisker showing when the user clicks the
same ad; the top edge of the box shows 75% same position and 25% same ad,
and vice versa for the bottom edge of the box; the line in the middle shows the
50%-50% case.
The ﬁrst observation we make from Figure 5.1 is that under a 50-50 user
model, change in revenue is practically 0% even with bid information as stale
as up to 12 hours. Under the 75-25 and 25-75 models, the change is almost
41
always between ±0.05%, and only in the extreme cases 100-0 or 0-100 does it
pass ±0.1%. More importantly, the change increases very gradually. This is good
news since it means a private advertising system would not have a hard delay
deadline beyond which there would be disproportionate change in revenue.
Instead the system can strive to do the best it can, and reduce revenue change
proportionally. The extremely gradual rate of change also means that system
design trade-offs can be biased towards scalability and other engineering goals
without much concern to revenue since it changes very little in the ﬁrst place.
At ﬁrst blush the effect of the “same-ad” user-model appears to be to reduce
the revenue, but this is deceptive. As mentioned earlier, the more the user clicks
on the same-ad (going from 0% to 100% from the top whisker to bottom), the
more biased the simulation is towards fewer clicks and therefore less revenue.
Recall that only the top-whisker is unaffected by this simulation bias.
The second observation we make from Figure 5.1 is the slight upwards trend
of the top-whisker signifying higher revenues as more stale information is used.
This suggests a consistent trend of advertisers (as a whole) reducing their bids
over time. We do not know the cause of this trend.
Next we turn to the advertiser perspective. We compute for each ad the frac-
tion of auctions where the user-visible simulated ranking increased or decreased
compared to the trace, and whether the ad became visible or invisible due to be-
ing ranked high-enough or too-low as compared to the trace. Figure 5.2 plots
the average of these numbers across all ads as a function of the staleness of bid
information used.
42
)
%
(
r
e
s
i
t
r
e
v
d
a
r
o
f
d
e
t
c
e
f
f
a
s
n
o
i
t
c
u
a
f
o
n
o
i
t
c
a
r
f
e
g
a
r
e
v
A
Rank increased
Rank decreased
Became visible
Became invisible
 20
 18
 16
 14
 12
 10
 8
 6
 4
 2
 0
1m 2m 5m 15m 30m 1h
2h
3h
6h
12h
1d
36h
2d
Staleness
Figure 5.2: Fraction of auctions with modiﬁed rankings
We ﬁrst observe that both increased ranks and decreased ranks are roughly
equal, and so average to nearly zero. The same is true for ads becoming visi-
ble or invisible. While this is consistent with the revenue change in Figure 5.1
averaging out to zero, we note that there are other ways the revenue could aver-
age out to zero while being unfair to advertisers. For instance, fewer increased
ranks could have been compensated by more cases where the ad became visible
thus still resulting in zero revenue change while being unfair to the advertiser;
luckily, this is not the case.
We observe next that there is a very small impact of staleness on change
in ranks; it begins with around 12% of auctions for 1 minute stale data, and
quickly converges to around 16%. The reason this number is high is because of
the cascade effect — if a single ad jumps from a low rank to a high rank, it causes
all the ads in between to register a “change” in rank; thus a single change in bid
can affect up to ten ads. The impact, however, is very little; the ad jumping from
43
low to high might register a change of 10 ranks, however, the other 10 ads would
register a change of only 1 rank each (not captured in the graph). Overall we
found a median net change of 1 rank for every 820 auctions the ad participates
in.
To summarize, based on extensive simulations across varying degrees of
staleness and different user-models, there is little impact on broker revenue as
compared to today, and little impact on advertiser fairness as compared to to-
day.
44
Part II
Private-by-Design Advertising and
Analytics Meet the Real World
45
CHAPTER 6
BACKGROUND AND RELATED WORK
As described in Section 1.2, several research projects have proposed an al-
ternative “private-by-design” advertising model in an attempt to reconcile be-
havioral targeting and user privacy. Each of the proposed systems claims to be
practical in that they provide both good privacy and high utility at reasonable
cost. In this part of the thesis, we attempt to answer one simple question: “Is
private-by-design advertising really practical?”. To do so, we built, deployed,
and evaluated a fully functional prototype of a private-by-design ad system
based on the Privad design. Our deployment delivered functional ads in the
sense that the ads were targeted to user interests, displayed on publisher web-
pages, linked to real shopping websites, and in fact led to actual purchases.
Side-by-side with Privad, we also deployed a distributed differentially-private
user analytics system, PDDP [19], that served as our primary means of gather-
ing experimental data.
By bundling our system with a popular Firefox addon, we deployed it to
over 13K opted-in users. Over a period of two months, the system was used
daily by over 4800 active users on average, with more than 2000 users online
at peak.
In October 2013 alone, our backend received 1.1M ad requests and
generated 9.5M ads. During that time, we registered 790K ads views, 417 ad
clicks, and 4 product purchases. While minuscule by commercial standards,
our deployment was big enough to allow us to preliminarily answer a number
of important questions.
The lessons learned from this experiment contain both good news and bad
news. Perhaps the most surprising of the good news is that our system pro-
46
duced click-through rates (CTR) on par with Google display ads. This is espe-
cially impressive given that ad generation in our system was fully automated,
in contrast to Google where ads are designed by hand and ﬁne-tuned over time.
Among the bad news, our experience suggests that differential privacy was
a poor model for understanding actual privacy loss in our experiment. Based
on the relatively small number of queries we made to our system (159 dis-
tinct queries generating 790K answers from 9395 unique clients), differential
privacy’s worst-case stance would suggest that a substantial proportion of our
user base could have experienced privacy loss. In reality, no individual user
information whatsoever was leaked through PDDP. Moreover, even if we had
generated malicious queries, at best we could have learned one or two things
about one or two users (assuming we had auxiliary information). This large
discrepancy between the differential private model of privacy loss and actual
privacy loss needs to be addressed by the privacy research community.
The high-level take-away, however, is that the system does appear practical.
We could deliver effective targeted ads, obtain the information needed to pay
publishers and bill advertisers, and gather statistical data giving us visibility
into system operation and user behavior. The main limitation in our experi-
ment is that we did not implement auctions or click-fraud defense. However,
integrating with existing auction systems or ad exchanges does not appear fea-
sible in the context of a small-scale academic research experiment.
In the rest of this chapter, we give a broad overview of the Privad architec-
ture underpinning our prototype implementation and discuss the privacy guar-
antees provided by the system. We then outline the design of the PDDP system
that leverages the same fundamental architecture to enable differentially private
47
data collection in distributed settings. Finally, we describe previous attempts at
building and deploying a private-by-design advertising system.
6.1 Privad Model
A number of components in the Privad architecture play the same role as they
do in today’s ad deployments. These include users, publishers, advertisers, and a
broker (ad network): users browse publisher webpages, and advertisers provide
ads to brokers for display on those webpages. Privad deﬁnes two new compo-
nents, the client and the dealer, and substantially modiﬁes the role of the broker:
user proﬁling and ad serving are delegated to the client software, which runs on
the user’s device, rather than in the cloud (i.e., at the broker) as it is done in to-
day’s deployments. The client monitors user behavior (i.e., the user’s searching,
browsing, purchases, and so on) and over time builds up a user proﬁle. It then
uses this behavioral proﬁle to privately fetch ads from the broker and locally
decide which ads should be presented to the user. Finally, the dealer is placed
in between the clients and the broker to anonymously relay all communication
and also help downscale click-fraud attacks.
The fundamental design principle in Privad is that private information about
each user is kept on that user’s computer, not in the cloud [34]. In a sense, users
are still tracked. However, the tracking is done by a software agent running on
the user’s machine, and the information it gathers (the user proﬁle) never leaves
the user’s machine. The challenge is to utilize the user proﬁle to deliver targeted
ad content while revealing the minimum amount of information from the user
proﬁle. Concretely, the privacy goals of the Privad system are formulated as
follows [32]:
48
Figure 6.1: The Privad architecture. [x] denotes encryption of x.
• Anonymity: the broker cannot associate any unit of learned information
with any user Personally Identiﬁable Information (including network ad-
dress), and
• Unlinkability: the broker cannot associate separate units of learned infor-
mation with a single (anonymous) client. This prevents the broker from
building up a user proﬁle, and then associating it with a known user us-
ing externally gathered knowledge.
Privad Operation
Figure 6.1 illustrates the basic Privad architecture and message exchanges be-
tween principal components. The client and the broker are separated by a
proxy-like dealer, which strips away the network layer address of all clients’
messages. The dealer can also coordinate with the broker to identify and dis-
count fraudulent clicks as well as block clients suspected of click-fraud. The
broker in Privad is assumed to be honest-but-curious. While this may be close to
reality (brokers like Google can generally be trusted to do what they claim they
49
AdboxPublishersPage ViewServeProfileDealerBrokerAds Request: [interest]AdvertisersClick/View: [id, URL]Ads: [Ad, id, target]Submit AdsUser ProfileRelevant AdsAll AdsClientClick fraud defenseare doing), the system design nevertheless strives to prevent the broker from
obtaining high-value information through simple but hard-to-detect cheating.
All message exchanges in Privad follow the same basic protocol: the client’s
request is encrypted with the broker’s public key and contains a one-off sym-
metric key generated by the client, which is later used to encrypt the broker’s
response (e.g., the stream of ads sent to a client). Since the encryption is opaque
for the dealer, it blindly forwards the messages without learning anything about
the clients. As long as the broker and the dealer do not collude the system
can offer privacy guarantees: the dealer prevents the broker from learning the
client’s identity or from linking separate messages from the same client.
User proﬁling software runs at the client. This software monitors the user’s
activity (e.g., search terms, browsing behavior, purchases made) and uses col-
lected information to infer both the interests and demographics of the user. Inter-
ests reﬂect largely short-term user attributes (for instance, interest in products
or services like sports.equipment.tennis or outdoor.lawn-care). Demographics in-
corporate long-term attributes such as gender, age, salary, and location. When
the proﬁling software identiﬁes a user interest, it anonymously requests a set of
ads for the given interest category type (i.e., ads for products or services match-
ing the user interest). The request must be generic enough that a substantial
set of clients can have legitimately made the request (as described later, this is
done by using a pre-deﬁned interests categories). A set of ads matching the
user request, each with an identiﬁer id and associated targeting information, are
transmitted to the client. The client software then ﬁlters out ads that do not
match the proﬁle and locally stores the rest.
50
One of the main requirements for an ad system is good targeting. The de-
sign of the Privad system reﬂects the view that an endhost client can achieve
deep insight into a particular user as opposed to the shallow view into the