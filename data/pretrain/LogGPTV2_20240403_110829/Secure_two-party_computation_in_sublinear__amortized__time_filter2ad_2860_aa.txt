title:Secure two-party computation in sublinear (amortized) time
author:S. Dov Gordon and
Jonathan Katz and
Vladimir Kolesnikov and
Fernando Krell and
Tal Malkin and
Mariana Raykova and
Yevgeniy Vahlis
Secure Two-Party Computation in
Sublinear (Amortized) Time
S. Dov Gordon
Columbia University
PI:EMAIL
Jonathan Katz
University of Maryland
PI:EMAIL
Vladimir Kolesnikov
Alcatel-Lucent Bell Labs
kolesnikov@research.bell-
labs.com
Fernando Krell
Columbia University
PI:EMAIL
Mariana Raykova
Columbia University
PI:EMAIL
ABSTRACT
Traditional approaches to generic secure computation begin
by representing the function f being computed as a circuit.
If f depends on each of its input bits, this implies a protocol
with complexity at least linear in the input size. In fact, lin-
ear running time is inherent for non-trivial functions since
each party must “touch” every bit of their input lest infor-
mation about the other party’s input be leaked. This seems
to rule out many applications of secure computation (e.g.,
database search) in scenarios where inputs are huge.
Adapting and extending an idea of Ostrovsky and Shoup,
we present an approach to secure two-party computation
that yields protocols running in sublinear time, in an amor-
tized sense, for functions that can be computed in sublin-
ear time on a random-access machine (RAM). Moreover,
each party is required to maintain state that is only (essen-
tially) linear in its own input size. Our approach combines
generic secure two-party computation with oblivious RAM
(ORAM) protocols. We present an optimized version of our
approach using Yao’s garbled-circuit protocol and a recent
ORAM construction of Shi et al.
We describe an implementation of our resulting proto-
col, and evaluate its performance for obliviously searching
a database with over 1 million entries. Our implementation
outperforms oﬀ-the-shelf secure-computation protocols for
databases containing more than 218 entries.
Categories and Subject Descriptors
C.2.0 [Computer-Communication Networks]: General–
security and protection
Tal Malkin
Columbia University
PI:EMAIL
Yevgeniy Vahlis
AT&T Security Research
Center
PI:EMAIL
Keywords
Theory, Security, Cryptography, Secure Computation
1.
INTRODUCTION
Consider the task of searching over a sorted database of n
items. Using binary search, this can be done in time O(log n).
Now consider a secure version of this task where a client
wishes to learn whether an item is in a database held by
a server, with neither party learning anything more. Ap-
plying generic secure computation [23, 6] to this task, we
would begin by expressing the computation as a (binary or
arithmetic) circuit of size at least n, resulting in a protocol
of complexity Ω(n). Moreover, (at least) linear complex-
ity is inherent: in any secure protocol for this problem the
server must “touch” every entry of the database; otherwise,
the server learns information about the client’s input by ob-
serving which entries of its database were never accessed.
This linear lower bound seems to rule out the possibility of
ever performing practical secure computation over very large
datasets. However, tracing the sources of the ineﬃciency,
one may notice two opportunities for improvement:
• Many interesting functions (such as binary search) can
be computed in sublinear time on a random-access ma-
chine (RAM). Thus, it would be nice to have proto-
cols for generic secure computation that use RAMs —
rather than circuits — as their starting point.
• The fact that linear work is inherent for secure compu-
tation of any non-trivial function f only applies when
f is computed once. However, it does not rule out the
possibility of doing better, in an amortized sense, when
the parties compute the same function multiple times.
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
CCS’12, October 16–18, 2012, Raleigh, North Carolina, USA.
Copyright 2012 ACM 978-1-4503-1651-4/12/10 ...$15.00.
Inspired by the above, we explore scenarios where secure
computation with sublinear amortized work is possible. We
focus on a setting where a client and server repeatedly eval-
uate a function f , maintaining state across these executions,
with the server’s (huge) input D changing only a little be-
tween executions, and the client’s (small) input x chosen
anew each time f is evaluated.
(It is useful to keep in
mind the concrete application of a client making several
513read/write requests to a large database D, though our re-
sults are more general.) Our main result is:
Theorem 1. Suppose f can be computed in time t and
space s in the RAM model of computation. Then there is a
secure two-party protocol for f in which the client and server
run in amortized time O(t)· polylog(s), the client uses space
O(log(s)), and the server uses space s · polylog(s).
The above holds in the semi-honest adversarial model.
We show a generic protocol achieving the above bounds
by applying any protocol for secure two-party computation
in a particular way to any oblivious RAM (ORAM) con-
struction [7]. This demonstrates the feasibility of secure
computation with sublinear amortized complexity. We then
explore a concrete, optimized instantiation of our protocol
based on the recent ORAM construction of Shi et al. [19],
and using Yao’s garbled-circuit approach [23] for the secure
two-party computation. We chose the ORAM construction
of Shi et al. since it is the simplest scheme we know of, it
has poly-logarithmic worst-case complexity (as opposed to
other schemes that only achieve this in an amortized sense),
it requires small client state, and its time complexity in prac-
tice (i.e., taking constant factors into account) is among the
best known. (In Section 6 we brieﬂy discuss why we expect
other schemes to yield worse overall performance for our
application.) We chose Yao’s garbled-circuit approach for
secure computation since several recent results [10, 15] show
that it is both quite eﬃcient and can scale to handle circuits
with tens of millions of gates. When combining these two
schemes, we apply a number of optimizations to reduce the
sizes of the circuits that need to be evaluated using generic
secure computation.
We implemented the optimized protocol described above,
and evaluated it for the task of database search. For small
databases our protocol is slower than standard protocols for
secure computation, but our protocol outperforms the latter
for databases containing more than 218 entries.
1.1 Technical Overview
Our starting point is the ORAM primitive, introduced
in [7], which allows a client (with a small memory) to per-
form RAM computations using the (large) memory of a re-
mote untrusted server. At a high level, the client stores
encrypted entries on the server, and then emulates a RAM
computation of some function by replacing each read/write
access of the original RAM computation with a series of
read/write accesses such that the actual access pattern of
the client remains hidden from the server. Existing ORAM
constructions have the following complexity for an array of
length s: the server’s storage is s · polylog(s); the client’s
storage is O(log s); and the (amortized) work required to
read/write one entry of the array is polylog(s).
The above suggests a method for computing f (x, D) for
any function f deﬁned in the random-access model of com-
putation, where the client holds (small) input x and the
server holds (large) input D: store the memory array used
during the computation on the server, and have the client
access this array using an ORAM scheme. This requires
an (expensive) pre-processing phase during which the client
and server initialize the ORAM data structure with D; af-
ter this, however, the client and server can repeatedly evalu-
ate f (xi, D) (on diﬀerent inputs x1, . . . of the client’s choice)
very eﬃciently. Speciﬁcally, if f can be evaluated in time t
and space s on a RAM, then each evaluation of f in this
client/server model now takes (amortized) time t·polylog(s).
The above approach, however, only provides “one-sided se-
curity,” in that it ensures privacy of the client’s input against
the server; it provides no security guarantees for the server
against the client! We can address this by having the parties
compute the next ORAM instruction “inside” a (standard)
secure two-party computation protocol, with the intermedi-
ate state being shared between the client and server. The
resulting ORAM instruction is output to the server, who can
then read/write the appropriate entry in the ORAM data
structure that it stores, and incorporate the result (in case of
a read operation) in the shared state. The key observations
here are that (1) it is ok to output the ORAM instructions
to the server, since the ORAM itself ensures privacy for the
client; thus, secure computation is needed only to determine
the next instruction that should be executed. Moreover,
(2) each computation of this “next-instruction function” is
performed on small
inputs whose lengths are logarithmic
in s and independent of t: speciﬁcally, the inputs are just
(shares of) the current state for the RAM computation of f
(which we assume to have size O(log s), as is typically the
case) and (shares of) the current state for the ORAM itself
(which has size O(log s)). Thus, the asymptotic work for
the secure computation of f remains unchanged.
For our optimized construction, we rely on the speciﬁc
ORAM construction of Shi et al. [19], and optimized versions
of Yao’s garbled-circuit protocol. We develop our concrete
protocol with the aim of minimizing our reliance on garbled
circuits for complex functionalities. Instead, we perform lo-
cal computations whenever we can do so without losing se-
curity. For example, we carefully use encryption scheme
where block-cipher computations can be done locally, with
just an XOR computed via secure computation. For the
parts of our protocol that do utilize generic secure computa-
tion, we rely on garbled-circuit optimization techniques such
as the free-XOR approach [12, 2], oblivious-transfer exten-
sion [11], and pipelined circuit execution [10]. Wee also use
precomputation (e.g., [1]) to push expensive computations
to a preprocessing stage. Our resulting scheme only requires
simple XOR operations for oblivious-transfer computations
in an on-line stage, while exponentiations and even hashing
can be done as part of preprocessing.
1.2 Related Work
Ostrovsky and Shoup [17] also observed that ORAM and
secure computation can be combined, though in a diﬀerent
context and using a diﬀerent approach. Speciﬁcally, they
consider a (stateless) client storing data on two servers that
are assumed not to collude. They focus on private storage of
the data belonging to the client, rather than secure compu-
tation of a function over inputs held by a client and server
as we do here. Finally, they do not evaluate the concrete
eﬃciency of their approach.
Damg˚ard et al. [3] also observe that ORAM can be used
for secure computation. In their approach, which they only
brieﬂy sketch, players share the entire (super-linear) state
of the ORAM, in contrast to our protocol where the client
maintains only logarithmic state. They make no attempt to
optimize the concrete eﬃciency of their protocol, nor do they
oﬀer any implementation or evaluation of their approach.
Though the above two works have a ﬂavor similar to our
own, our work is the ﬁrst to explicitly point out that ORAM
514can be used to achieve secure two-party computation with
sublinear complexity (for functions that can be computed in
sublinear time on a RAM).
Oblivious RAM was introduced in [7], and in the past
few years several improved constructions have been proposed
(c.f. [21, 22, 18, 8, 9, 13, 19, 20]). Due to space limitations,
we refer the reader to [19, 20] for further discussion and
pointers to the sizeable literature on this topic.
2. DEFINITIONS
2.1 Random Access Machines
In this work, we focus on RAM programs for computing
a function f (x, D), where x is a “small” input that can be
read in its entirety and D is a (potentially) large input that
is viewed as being stored in a memory array that we also de-
note by D and that is accessed via a sequence of read/write
instructions. Any such instruction I ∈ ({read, write} × N ×
{0, 1}(cid:2)) takes the form (write, v, d) (“write data element d in
location/address v”) or (read, v,⊥) (“read the data element
stored at location v”). We also assume a designated “stop”
instruction of the form (stop, z) that indicates termination
of the RAM protocol with output z.
Formally, a RAM program is deﬁned by a “next instruc-
tion” function Π which, given its current state and a value d
(that will always be equal to the last-read element), outputs
the next instruction and an updated state. Thus if D is an
array of n entries, each (cid:2) bits long, we can view execution
of a RAM program as follows:
• Set stateΠ = (1log n, 1(cid:2), start, x) and d = 0(cid:2). Then until
termination do:
(cid:2)
1. Compute (I, state
Π) = Π(stateΠ, d). Set stateΠ =
(cid:2)
state
Π.
2. If I = (stop, z) then terminate with output z.
(cid:2)
3. If I = (write, v, d
) then setD [v] = d
4. If I = (read, v,⊥) then setd = D[v].
(cid:2)
.
(We stress that the contents of D may change during the
course of the execution.) To make things non-trivial, we
require that the size of stateΠ, and the space required to
compute Π, is polynomial in log n, (cid:2), and |x|. (Thus, if we
view a client running Π and issuing instructions to a server
storing D, the space used by the client is small.)
We allow the possibility for D to grow beyond n entries,
so the RAM program may issue write (and then read) in-
structions for indices greater than n. The space complexity
of a RAM program on initial inputs x, D is the maximum
number of entries used by the memory array D during the
course of the execution. The time complexity is the number
of instructions issued in the execution as described above.
For our application, we do not want the running time of a
RAM program to reveal anything about the inputs. Thus,
we will assume that any RAM program has associated with
it a polynomial t such that the running time on x, D is ex-
actly t(log n, (cid:2),|x|).
2.2 Oblivious RAM
We view an oblivious-RAM (ORAM) construction as a
mechanism that simulates read/write access to an underly-
ing (virtual) array D via accesses to some (real) array ˜D;
“obliviousness” means that no information about the virtual
accesses to D is leaked by observation of the real accesses
to ˜D. An ORAM construction can be used to compile any
RAM program into an oblivious version of that program.