For additional details about PostgreSQL Error Codes:
https://www.postgresql.org/docs/9.6/static/errcodes-appendix.html
Example
Access the PostgreSQL error log using the Amazon RDS/Aurora Management Console:
• Navigate to: Services > RDS > Instances > Select Instance
• Click Logs.
• Select a specific PostgreSQL log file and select View to review a static version of log file.
Optionally, select Watch for a dynamic (updating) view of log file.
304
Notes
1. You can use the search box to search for a specific log file.
2. You can click on the download button to download the log file to your local machine.
Partial contents of a PostgreSQL database error log as viewed from the Amazon RDS Management
Console:
PostgreSQL error log configuration
Several parameters control how and where PostgreSQL log and errors files will be placed:
Common Amazon Aurora configuration options
Oracle PostgreSQL
log_filename Sets the file name pattern for log files.
Modifiable via an Aurora Database Parameter Group
log_rotation_age (min) Automatic log file rotation will occur after N minutes.
Modifiable via an Aurora Database Parameter Group
log_rotation_size (kB) Automatic log file rotation will occur after N kilobytes.
Modifiable via an Aurora Database Parameter Group
log_min_messages Sets the message levels that are logged ( DEBUG, ERROR, INFO, etc.…).
Modifiable via an Aurora Database Parameter Group
305
log_min_error_sta Causes all statements generating error at or above this level to be logged
tement ( DEBUG, ERROR, INFO, etc.…).
Modifiable via an Aurora Database Parameter Group
log_min_duration_ Sets the minimum execution time above which statements will be logged (ms).
statement Modifiable via an Aurora Database Parameter Group
Note
Modifications to certain parameters, such as which sets the destination directory for
log_directory(
log files) (which start a subprocess to capture output and/or
or logging_collector stderr
into log files) are disabled for Aurora PostgreSQL instance
csvlogs
Log severity levels supported by PostgreSQL:
Severity Usage
DEBUG1…DEBUG5 Provides successively-more-detailed information for use by developers
INFO Provides information implicitly requested by the user
NOTICE Provides information that might be helpful to users
WARNING Provides warnings of likely problems
ERROR Reports an error that caused the current command to abort
LOG Reports information of interest to administrators
FATAL Reports an error that caused the current session to abort
PANIC Reports an error that caused all database sessions to abort
For additional details about PostgreSQL Error Reporting and Logging:
https://www.postgresql.org/docs/9.6/static/runtime-config-logging.html
306
Migrating from: Oracle Table Statistics
[Back to TOC]
Overview
Table statistics are one of the important aspects that can affect SQL query performance. Table Statistics allow
the query optimizer to make informed assumptions when deciding how to generate the execution plan for
each query. Oracle provides the package to manage and control the table statistics which can
DBMS_STATS
be collected automatically or manually.
The following statistics are usually collected on database tables and indexes:
• Number of table rows.
• Number of table blocks.
• Number of distinct values or nulls.
• Data distribution histograms.
Automatic Optimizer Statistics Collection
By default, Oracle will collect table and index statistics by using automated maintenance tasks leveraging the
database scheduler to automatically collect statistics at predefined maintenance windows. Using the data
modification monitoring feature in Oracle, which is responsible for tracking the approximate number of
INSERTs, UPDATEs, and DELETEs for that table, the automatic statistics collection mechanism knows which
table statistics should be collected.
Manual Optimizer Statistics Collection
When the automatic statistics collection is not suitable for a particular use-case, the optimizer statistics
collection can be performed manually, at several levels:
Index statistics
1. GATHER_INDEX_STATS
Table, column, and index statistics
2. GATHER_TABLE_STATS
Statistics for all objects in a schema
3. GATHER_SCHEMA_STATS
Statistics for all dictionary objects
4. GATHER_DICTIONARY_STATS
Statistics for all objects in a database
5. GATHER_DATABASE_STATS
Example
1. Collecting statistics at the table level (schema - , table - ):
HR EMPLOYEES
SQL> BEGIN
DBMS_STATS.GATHER_TABLE_STATS('HR','EMPLOYEES');
END;
/
PL/SQL procedure successfully completed.
307
2. Collecting statistics at a specific column-level (schema - , table - , column -
HR EMPLOYEES
):
DEPARTMENT_ID
SQL> BEGIN
DBMS_STATS.GATHER_TABLE_STATS('HR','EMPLOYEES',
METHOD_OPT=>'FOR COLUMNS department_id');
END;
/
PL/SQL procedure successfully completed.
For additional information on Oracle Collecting Table Statistics:
http://docs.oracle.com/cd/E25054_01/server.1111/e16638/stats.htm#i41448
https://docs.oracle.com/database/121/TGSQL/tgsql_stats.htm#TGSQL390
Migration to: PostgreSQL Table Statistics
[Back to TOC]
Overview
Use the command to collect statistics about a database, a table or a specific table column. The
ANALYZE
PostgreSQL command collects table statistics which support generation of efficient query execution
ANALYZE
plans by the query planner.
1. Histograms - will collect statistics on table columns values and create a histogram of the
ANALYZE
approximate data distribution in each column.
2. Pages and rows - will collect statistics on the number of database pages and rows from which
ANALYZE
each table is comprised.
3. Data sampling - for large tables, the command will take random samples of values rather than
ANALYZE
examining each and every single row. This allows the command to scan very large tables in a
ANALYZE
relatively small amount of time.
3. Statistic collection granularity - executing the command without any parameter will instruct
ANALYZE
PostgreSQL to examine every table in the current schema. Supplying the table name or column name to
the , will instruct the database to examine a specific table or table column.
ANALYZE
Automatic Statistics Collection
By default, PostgreSQL is configured with an “autovacuum daemon” which automates the execution of
statistics collection via the commands (in addition to automation of the command).
ANALYZE VACUUM
The “autovacuum daemon” scans for tables which show signs of large modifications in data to collect the
current statistics. Autovacuum is controlled by several parameters.
For additional details:
https://www.postgresql.org/docs/9.6/static/runtime-config-autovacuum.html
308
Manual Statistics Collection
PostgreSQL allows collecting statistics on-demand using the command at a database level, table-
ANALYZE
level or table column-level.
1. on indexes is not currently supported.
ANALYZE
2. requires only a read-lock on the target table, so it can run in parallel with other activity on the
ANALYZE
table.
3. For large tables, takes a random sample of the table contents. Configured via the show
ANALYZE
parameter. The default value is 100 entries. Raising the limit might
default_statistics_target
allow more accurate planner estimates to be made at the price of consuming more space in
the table
pg_statistic .
Examples
1. Gather statistics for the entire database:
psql=> ANALYZE;
2. Gather statistics for a specific table. The keyword displays progress.
VERBOSE
psql=> ANALYZE VERBOSE EMPLOYEES;
3. Gather statistics for a specific column:
psql=> ANALYZE EMPLOYEES (HIRE_DATE);
4. Specify the parameter for an individual table column and reset it
default_statistics_target
back to default:
psql=> ALTER TABLE EMPLOYEES ALTER COLUMN SALARY SET STATISTICS 150;
psql=> ALTER TABLE EMPLOYEES ALTER COLUMN SALARY SET STATISTICS -1;
Larger values will increase the time needed to complete an , but, will improve the quality of the
ANALYZE
collected planner's statistics which can potentially lead to better execution plans.
5. View the current (session / global) , modify it to 150 and analyze the
default_statistics_target
table:
EMPLOYEES
psql=> SHOW default_statistics_target ;
psql=> SET default_statistics_target to 150;
psql=> ANALYZE EMPLOYEES ;
6. View the last time statistics were collected for a table:
select relname, last_analyze from pg_stat_all_tables;
309
Comparing Oracle and PostgreSQL Statistics Collection
Feature Oracle PostgreSQL
Analyze a specific BEGIN ANALYZE EMPLOYEES;
database table dbms_stats.gather_tabl
e_stats(ownname
=>'hr', tabname =>
'employees' , …
);
END;
Analyze a database Configure via percentage of Configure via number of entries
table while only table rows to sample: for the table:
sampling certain rows
BEGIN
dbms_stats.gather_tabk SET
e_stats( default_statistics_tar
ownname=>'HR', get to 150;
… ANALYZE EMPLOYEES ;
ESTIMATE_PERCENT=>100)
;
END;
Collect statistics for a BEGIN ANALYZE;
schema EXECUTE
DBMS_STATS.GATHER_SCHE
MA_STATS(ownname =>
'HR');
END
View last time select select relname,
statistics were owner,table_name,last_ last_analyze from
collected analyzed; pg_stat_all_tables;
For additional information on PostgreSQL Collecting Table Statistics:
https://www.postgresql.org/docs/9.6/static/sql-analyze.html
https://www.postgresql.org/docs/9.6/static/routine-vacuuming.html#AUTOVACUUM
310
Migrating from: Viewing Oracle Execution Plans
[Back to TOC]
Overview
Execution plans represent the choices made by the query optimizer of which actions to perform in order to
access data in the database. Execution Plans are generated by the database optimizer for , ,
SELECT INSERT
and statements.
UPDATE DELETES
Users and DBAs can request the database to present the execution plan for any specific query or DML
operation providing an extensive view on the optimizer’s method of accessing data. Execution Plans are
especially useful for performance tuning of queries, including deciding if new indexes should be created.
Execution plans can be affected by data volumes, data statistics and instance parameters (global or session
parameters).
Execution plans are displayed as a structured tree that presents the following information:
1. Tables access by the SQL statement and the referenced order for each table.
2. Access method for each table in the statement (full table scan vs. index access).
3. Algorithms used for joins operations between tables (hash vs. nested loop joins).
4. Operations that are performed on retrieved data as filtering, sorting and aggregations.
5. Information about rows begin processed (cardinality) and the cost for each operation.
6. Table partitions begin accessed.
7. Information about parallel executions.
Examples
1. Review the potential execution plan for a query using the statement:
EXPLAIN PLAN
SQL> SET AUTOT TRACE EXP
SQL> SELECT EMPLOYEE_ID, LAST_NAME, FIRST_NAME FROM EMPLOYEES
WHERE LAST_NAME='King' AND FIRST_NAME='Steven';
Execution Plan
----------------------------------------------------------
Plan hash value: 2077747057
-------------------------------------------------------------------------------------------
| Id | Operation | Name | Rows | Bytes | Cost (%CPU)| Time |
-------------------------------------------------------------------------------------------
| 0 | SELECT STATEMENT | | 1 | 16 | 2 (0)| 00:00:01 |
| 1 | TABLE ACCESS BY INDEX ROWID| EMPLOYEES | 1 | 16 | 2 (0)| 00:00:01 |
|* 2 | INDEX RANGE SCAN | EMP_NAME_IX | 1 | | 1 (0)| 00:00:01 |
-------------------------------------------------------------------------------------------
Predicate Information (identified by operation id):
---------------------------------------------------
2 - access("LAST_NAME"='King' AND "FIRST_NAME"='Steven')
instructs SQL*PLUS to show the execution plan without actually
* SET AUTOT TRACE EXP
running the query itself.
311
The tables contains indexes for both the and the
EMPLOYEES LAST_NAME FIRST_NAME
columns, we can see that in step 2 of the execution plan above, the optimizer is performing an
in order to retrieve the filtered employee name.
INDEX RANGE SCAN
2. View a different execution plan, this time showing a :
FULL TABLE SCAN
SQL> SET AUTOT TRACE EXP
SQL> SELECT EMPLOYEE_ID, LAST_NAME, FIRST_NAME FROM EMPLOYEES
WHERE SALARY > 10000;
Execution Plan
----------------------------------------------------------
Plan hash value: 1445457117
-------------------------------------------------------------------------------
| Id | Operation | Name | Rows | Bytes | Cost (%CPU)| Time |
-------------------------------------------------------------------------------
| 0 | SELECT STATEMENT | | 72 | 1368 | 3 (0)| 00:00:01 |
|* 1 | TABLE ACCESS FULL| EMPLOYEES | 72 | 1368 | 3 (0)| 00:00:01 |
---------------------------------------------------------------
Predicate Information (identified by operation id):
---------------------------------------------------
1 - filter("SALARY">10000)
For additional details:
http://docs.oracle.com/cd/E25178_01/server.1111/e16638/ex_plan.htm
https://docs.oracle.com/database/121/TGSQL/tgsql_genplan.htm#TGSQL271
312
Migration to: Viewing PostgreSQL Execution Plans
[Back to TOC]
Overview
The PostgreSQL equivalent to in the Oracle database is the keyword which is
EXPLAIN PLAN EXPLAIN
used to display the execution plan for a supplied SQL statement. In similar manner to Oracle, the query
planner in PostgreSQL will generate the estimated execution plan for actions such as: , ,
SELECT INSERT
and and will build a structured tree of plan nodes representing the different actions taken
UPDATE DELETE
(the sign “ ” represent a root line in the PostgreSQL execution plan). In addition, the statement
-> EXPLAIN
will provide statistical information regarding each action such as: cost, rows, time and loops.
When using the command as part of a SQL statement, the statement will not execute and the
EXPLAIN
execution plan would be an estimation. However, by using the command, the
EXPLAIN ANALYZE
statement will actually be executed in addition to displaying the execution plan itself.
PostgreSQL Synopsis:
EXPLAIN
EXPLAIN [ ( option [, ...] ) ] statement
EXPLAIN [ ANALYZE ] [ VERBOSE ] statement
whe re option can be one of:
ANALYZE [ boolean ]
VERBOSE [ boolean ]
COSTS [ boolean ]
BUFFERS [ boolean ]
TIMING [ boolean ]
FORMAT { TEXT | XML | JSON | YAML }
Examples
1. Displaying the execution plan of a SQL statement using the command:
EXPLAIN
psql=> EXPLAIN
SELECT EMPLOYEE_ID, LAST_NAME, FIRST_NAME FROM EMPLOYEES
WHERE LAST_NAME='King' AND FIRST_NAME='Steven';
------------------------------------------------------------------------------------------
Index Scan using idx_emp_name on employees (cost=0.14..8.16 rows=1 width=18)
I ndex Cond: (((last_name)::text = 'King'::text) AND ((first_name)::text =
'Steven'::text))
(2 r ows)
2. Running the same statement with the keyword:
ANALYZE
313
psq l=> EXPLAIN ANALYZE
SELECT EMPLOYEE_ID, LAST_NAME, FIRST_NAME FROM EMPLOYEES
WHERE LAST_NAME='King' AND FIRST_NAME='Steven';
---- --------------------------------------------------------------------------------------
Seq Scan on employees (cost=0.00..3.60 rows=1 width=18) (actual
time=0.012..0.024 rows=1 loops=1)
Filter: (((last_name)::text = 'King'::text) AND ((first_name)::text =
'Steven'::text))
Rows Removed by Filter: 106
Pl anning time: 0.073 ms
Execution time: 0.037 ms
(5 rows)
By adding the keyword and executing the statement, we get additional information in
ANALYZE
addition to the execution plan.
3. Viewing a PostgreSQL execution plan showing a :
FULL TABLE SCAN
psql=> EXPLAIN ANALYZE
SELECT EMPLOYEE_ID, LAST_NAME, FIRST_NAME FROM EMPLOYEES
WHERE SALARY > 10000;
--------------------------------------------------------------------------------------------
Seq Scan on employees (cost=0.00..3.34 rows=15 width=18) (actual time=0.012..0.036 rows=15
loops=1)
Filter: (salary > '10000'::numeric)
Rows Removed by Filter: 92
Planning time: 0.069 ms
Execution time: 0.052 ms
(5 rows)
PostgreSQL can perform several scan types for processing and retrieving data from tables including:
sequential scans, index scans, and bitmap index scans. The sequential scan (“ ”) is
Seq Scan
PostgreSQL equivalent for Oracle “ ” (full table scan).
Table access full
For additional information on PostgreSQL Execution Plans:
https://www.postgresql.org/docs/9.6/static/sql-explain.html
314
Migrating from: Oracle SecureFile LOBs
[Back to TOC]
Overview
LOBs – or Large Objects is a mechanism for storing binary data inside the Oracle database. Oracle 11g
introduced a new data type for storing Large Objects (LOBs) binary files directly inside the database using
more efficient storage. This feature is known as Secure File Lobs and implemented using the
SECUREFILE
keyword as part of the statement
CREATETABLE
Primary benefits of using lobs include:
SECUREFILE
• Compression
With Oracle advanced compression utilized to analyze the SecureFiles LOB data to save disk
space.
• De-Duplication
Automatically detect duplicate LOB data within a LOB column or partition and by removing
duplicates of repeating binary data, reduce storage space.
• Encryption
Combined with Transparent Data Encryption (TDE).
Examples
1. Create a table using a SecureFiles LOB column:
SQL> CREATE TABLE sf_tab (
COL1 NUMBER,
COL2_CLOB CLOB)
LOB(COL2_CLOB) STORE AS SECUREFILE;
2. Provide additional options for LOB compression during table creation:
SQL> CREATE TABLE sf_tab (
COL1 NUMBER,
COL2_CLOB CLOB)
LOB(COL2_CLOB) STORE AS SECUREFILE COMPRESS_LOB(COMPRESS HIGH);
For additional details:
https://docs.oracle.com/cd/E11882_01/appdev.112/e18294/adlob_smart.htm#ADLOB45944
https://docs.oracle.com/database/121/ADLOB/adlob_smart.htm#ADLOB4444
315
Migration to: PostgreSQL LOBs
[Back to TOC]
Overview
PostgreSQL does not support the advanced storage, security, and encryption options of Oracle SecureFile
LOBs. Regular Large Objects datatypes (LOBs) are supported by PostgreSQL and provides stream-style access.
Although not designed specifically from LOB columns, for compression PostgreSQL utilizes an internal TOAST
mechanism (The Oversized-Attribute Storage Technique).
For more details about PostgreSQL please use the following link:
https://www.postgresql.org/docs/9.4/static/storage-toast.html
Supported large objected Data Types by PostgreSQL are:
• BYTEA
- Stores a LOB within the table limited to 1GB.
- The storage is octal and supports non printable characters.
- The input / output format is HEX.
- Can be used to store a URL references to an AWS S3 objects used by the database. For
example: storing the URL for pictures stored on AWS S3 on a database table.
• TEXT
- Data type for storing strings with unlimited length.
- When not specifying the (n) integer for specifying the varchar data type, the datatype
TEXT
behaves as the text data type.
For data encryption purposes (not only for LOB columns), consider using AWS KMS:
https://aws.amazon.com/kms/
For additional information on PostgreSQL LOB Support:
https://www.postgresql.org/docs/current/static/largeobjects.html
316
317