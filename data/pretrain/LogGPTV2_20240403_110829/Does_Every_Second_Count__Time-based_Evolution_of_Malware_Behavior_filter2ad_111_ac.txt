### Enhanced Text

#### Detection and Restart Mechanism
Our system identifies samples that generate new processes based on files they have previously written to the disk. In such cases, we reset our timer when a dropped file is executed. In a real-world scenario, these dropped files could be collected and analyzed separately, which is functionally equivalent to our approach of restarting the timer for dropped files. Overall, our recording system is similar to the one used by Malrec [87], but we have adapted it for PANDA version 2, while the current Malrec dataset is only available for PANDA 1.

#### Replay and Data Collection
We then replayed the recorded execution while running several plugins dedicated to collecting the data required for our analysis. These plugins capture all system calls occurring in the context of the monitored processes, all basic blocks (BBs) translated and executed by the emulator, and a complete memory dump whenever one of the monitored processes is about to terminate. From the memory dumps, we extract the content of the process' memory and all its executable basic blocks.

#### System Calls Collection
One of our primary goals is to collect all system calls invoked by the malware sample under analysis. PANDA includes the `syscalls2` plugin [4], which provides callbacks triggered when a system call is called or returns. Based on these callbacks, we implemented a custom plugin that hooks every system call during the execution of the malware sample. The plugin logs all system calls along with their timestamps, the process ID (PID) of the process in whose context the call occurs, and all syscall parameters. However, PANDA only allows us to monitor system calls from outside the OS and does not provide high-level information. Therefore, each argument or return value is represented as a generic `uint32_t` value. While this is sufficient for integer values, many arguments to system calls are pointers to structures. If higher-level information is required for further analysis, we need to parse the memory to retrieve additional information. Unfortunately, large parts of the Windows OS internals are not well-documented.

To partially address this issue, we extracted information from Volatility's offset-tables for Windows 7 Service Pack 1 [39] and used the description provided by Petritsch [76] on how to retrieve network packets from system calls. Additionally, PANDA’s `win7proc` plugin [5] infers high-level information from several system calls related to processes, registry, file system, and shared memory. By combining the information from these sources, our system can lift data for all system calls related to the interaction with the file system, the registry, as well as for processes, memory management, and network-related operations.

#### Basic Blocks
The `PANDA_CB_AFTER_BLOCK_TRANSLATE` callback provides a way to instrument the BB translation, an operation the emulator performs right before the first execution of each BB. Using this method, we collect all BBs when they are executed for the first time in the context of a process we observe.

To estimate the code coverage achieved by a given execution, we also need to extract all executable BBs belonging to the malware sample. Due to packing and obfuscation techniques, it is often impossible to retrieve the program code statically. Therefore, we extract the BBs from the process' memory image. It is reasonable to assume that the maximum amount of code is present in memory right before the process terminates. While this might not be the case for packers of type VI (according to the classification of Ugarte-Pedrero et al. [96]), these are extreme and very inefficient forms of packing used in only 0.2% – 1.8% of the samples. Moreover, it is important to note that we only report the absolute coverage for completeness, while all our measurements rely on relative metrics, which are not impacted by packing as they only measure those basic blocks that are actually executed by the program.

To dump the memory at the end of the process' execution, hooking the `NtTerminateProcess` call was insufficient. Instead, we found that for all possible ways a process can terminate, the `ProcessDelete` bit (the 3rd bit of Byte 0x270 of the EPROCESS structure) is set to 1 right before the memory of the process is freed by the Windows kernel. In contrast, all other bits and timestamps are set after the memory space has already been freed. Hence, our system checks if this bit is set when the process context changes, thus dumping the memory before it is freed by the operating system.

We then use the Rekall [6] memory forensics framework to extract the memory image of the process and analyze the virtual address descriptor tree of the process' memory content. By parsing its output, we can extract all regions marked as executable but do not belong to any named module (e.g., a shared library). Each of these regions is then processed by SMDA [7], an open-source recursive disassembler optimized for recovering code from memory dumps. SMDA is based on Nucleus [14], which can detect more functions in a binary than traditional disassemblers. We also extended SMDA to better guide it through the code regions within the address boundaries that have been executed in PANDA, thus increasing the disassembler's ability to explore the code.

#### Time Information Recovery
During our analysis, we needed a way to retrieve timing information according to the malware recording. Specifically, we wanted to know exactly when a given system call or basic block was executed during the sample recording, not during the slower replay. To achieve this, we exploited the `KUSER_SHARED_DATA` structure and its `SystemTime` field at offset 0x14. This field stores the current system time (expressed as an offset since January 1st, 1601 00:00:00 in 100 nanosecond ticks) and is regularly updated. As PANDA records all memory writes, any update to `SystemTime` is also recorded. This allows us to recover the exact timestamp when each event was performed during the recording, thus removing the overhead of our system from the results of our analysis.

#### Windows API Hooks
Several malware samples intentionally delay their malicious activity by sleeping for a certain amount of time, bypassing traditional dynamic analysis sandboxes. Therefore, we decided to hook the `Sleep` and `SleepEx` functions in `Kernel32.dll` to detect such cases. Whenever one of these functions is called, we add the sleep time to the system time but return immediately. This allows us to bypass sandbox evasion tricks based on the system time.

Furthermore, we hook the `CreateProcessWithLogonW`, `CreateProcessInternalW`, and `CreateProcessWithTokenW` functions to inject our DLL and install the hooks into child processes. If a file is dropped by the malware and later executed, we extend the time of our analysis. We collect all written files by hooking `NtCreateFile`.

All events recorded through the API hooking are immediately transmitted to our analysis framework while the malware is still running. We collect the time the malware sample sleeps and the child processes spawned by the sample. We implemented a simple client/server mechanism to share this information. The client is included in the injected DLL and sends messages containing the timestamp, the PID, and the event information to the server running outside PANDA, which logs the information for subsequent analysis.

#### Dataset Overview
According to AVClass [86], our dataset contains 806 different malware families and 6,989 samples classified as singletons (i.e., for which it was not possible to recognize a common label). Even though some families are present with higher frequency than others (Table II reports a ranking of the top 10 families present in the dataset), no family was predominant, and even the largest accounted for only 4K samples, resulting in a well-balanced dataset.

Our experiments were conducted in a sandbox running the 32-bit version of Windows 7 Service Pack 1. We configured the sandbox to have an internet connection and simulate basic user interaction to enable a realistic execution of the samples.

As discussed in Section II, each sample was executed for up to 15 minutes. Then, the execution was replayed using our PANDA plugins to collect the required information. On average, the complete analysis of one sample took around one hour, resulting in over 4100 days of CPU time, distributed over 80 parallel virtual machines.

Overall, in our experiments, we performed 5.9M minutes of malware execution, collecting 205M system calls and 84M unique basic blocks.

#### Filtering
As expected, some samples implement tricks to detect the presence of the analysis environment or that they were executed inside an emulator. While the actual amount of samples that adopt anti-analysis techniques is not known, one of the last experiments to measure its adoption was performed by Symantec in 2014. The authors found that anti-VM techniques were in decline, with only 18% of the samples refusing to run in a virtual environment [103]. Additionally, some programs failed to run due to lack of parameters or missing dependencies.

From one perspective, since our goal is to put ourselves in the position of a security company that needs to analyze unknown samples collected by their infrastructure, one may see these samples that failed to execute properly as "part of the game." Since these executables cannot be easily removed without first executing them, the tuning of the sandbox needs to take them into account. On the other hand, we wanted to avoid polluting our findings with these cases, as their actual number may vary depending on the sophistication of the sandbox and the realism of the analysis environment. Clearly, to obtain a more accurate picture of the malware analysis, we need to discuss only the running samples, excluding broken binaries, programs that exit due to wrong parameters or missing dependencies, or malware that detected the presence of our analysis environment. Therefore, we decided to conservatively filter out samples that did not show a sufficient amount of activity during their execution. This has an important implication for our results, as when we conclude that a certain percentage of malware shows a certain distribution in its runtime behavior, we always mean "a percentage of the malware that successfully executes." This needs to be kept in mind when interpreting the results of our analysis.

From a practical standpoint, we applied two conservative thresholds to the collected data: the first over the number of invoked syscalls, and the second over the number of executed basic blocks. Specifically, for the syscalls, we defined a set of functions that capture signs of meaningful activity (e.g., disk operation or network-related activity) and required that at least 50 of these functions were invoked. For the basic blocks, we adopted 4,000 basic blocks as a minimum threshold for a successful execution. While these values are somewhat arbitrary, our sole goal here is to be conservative enough to remove samples that did not execute correctly. In our dataset, these thresholds discarded 8,402 (10.5%) of the malicious samples and 1,456 (10.9%) of the benign ones. Among the remaining samples, the minimum execution time before a malicious sample terminated was 28 seconds, which is certainly sufficient for a program to show some of its runtime behavior.

#### Execution Time
The first interesting result we observed in our experiments is that most malware samples terminate their execution before reaching the sandbox threshold. This is very important because it means that even if a sandbox is configured to execute malware for ten minutes, 81% of the samples that successfully executed will not reach this threshold, and over half of them will terminate within the first minute. The full cumulative distribution of the execution time is reported in Figure 2 for both the benign and the malicious files. It is interesting to note that the two curves are remarkably similar, and both show that either a program terminates in the first three minutes, or it continues to run for more than thirteen. A complete breakdown of the entire dataset, divided according to the samples' termination time, is presented in Table III.

This result could be explained by the fact that either a program performs some actions (e.g., it downloads a second-stage binary or manipulates some data) and then terminates, or it remains active potentially indefinitely (as in the case of a botnet or an application that requires user interaction). By closely examining the samples that terminated in the first minute, we fetched the system calls related to network operations (e.g., `NtDeviceIOControlFile/DeviceControl`) and analyzed their input parameters to understand if the samples were opening a new connection, downloading data, or sending data. We noted that 51% of the malicious and 67% of the benign samples exhibited signs of network activity, suggesting that the samples did not simply detect the presence of the VM. Moreover, the top families reported in Table II were more prevalent among these short-lived samples.