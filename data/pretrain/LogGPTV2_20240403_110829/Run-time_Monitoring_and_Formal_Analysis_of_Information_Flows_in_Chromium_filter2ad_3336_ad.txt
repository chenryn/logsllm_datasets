from the second set to the attacker in Section IV-D.
Not all actions are observable to the attacker. Formally,
any action whose label is not lower than or equal to κA is not
visible to the attacker. The observable behavior of the attacker
is a projection of the trace that contains only actions whose
labels are lower than or equal to κA. The attacker’s goal is to
guess secrets based on the trace it has observed so far.
Declassiﬁcation steps A declassiﬁcation step is one where
a component that contains a secret reveals information about
the secret by generating an element, which can be an event or
a node or a content script, that is observable to the attacker
(i.e., has a label lower than or equal to the attacker’s label).
For instance, when a cnn.com page loads a script from ad.com,
the request is observable to ad.com. In the worst case, the URL
could contain secrets that belong to cnn.com. If cnn.com allows
loading of scripts from ad.com (by specifying a reclassiﬁcation
policy cnn.com→ad.com), this is a declassiﬁcation step explic-
itly allowed by the policy.
Declassiﬁcation steps are necessary for the browser to
carry out certain functionality. The ﬁrst kind of declassiﬁcation
directly uses an entity’s declassiﬁcation capabilities. Such
declassiﬁcation happens when an entity generates an event,
makes an API call, and sends an event. Other declassiﬁcation
steps allowed in our model are at places where labels are com-
puted for new entities based on policy composition rules: (1)
requesting external sources, (2) generating a new DOM node
based on data received from external sources, (3) injecting
content scripts from extensions, and (4) embedding a page in
an iframe.
Declassiﬁcation is only allowed according to policy. Sep-
arating declassiﬁcation from other parts of the policy helps to
enforce least privilege. In practice, one would want to validate
the legitimacy of components that request declassiﬁcation
labels carefully to ensure that their declassiﬁcation capabilities
are justiﬁed.
Equivalent states We deﬁne system conﬁgurations that are
equivalent from the attacker’s perspective based on a set of
projection rules. The projection operation (↓κA) is deﬁned
for each entity in a conﬁguration. It removes components not
visible to the attacker (i.e., components with labels not lower
than or equal to κA). For instance, the projection rules for
bookmarks are deﬁned as follows: If the bookmark’s label is
not lower or equal to κA, then the projection removes that
bookmark, as it is not observable to an attacker with label κA.
κB (cid:118) κA
(Bookmarks, κB)↓κA = (Bookmarks, κB)
MBOOKMARK1
κB (cid:54)(cid:118) κA
(Bookmarks, κB)↓κA = · MBOOKMARK2
say
that
two
(Ξ1, Σ1,E1)
We
and
conﬁgurations
(Ξ2, Σ2,E2) are equivalent at label κA if Ξ1↓κA = Ξ2↓κA,
Σ1↓κA = Σ2↓κA, and E1↓κA = E2↓κA.
Noninterference theorem We prove the following theorem
=⇒
ρ
to demonstrate the correctness of our design. We write C
to mean that ρ is the trace generated by executing from the
conﬁguration C.
two
Theorem 1 (Noninterference): If
conﬁgurations
(Ξ1, Σ1,E1) and (Ξ2, Σ2,E2) are equivalent at label κ then
=⇒ and the transitions do not have
• forall ρ s.t. Ξ1; Σ1;E1
declassiﬁcation steps there exists ρ(cid:48) such that ρ ≡κ ρ(cid:48) and
Ξ2; Σ2;E2
ρ(cid:48)
=⇒
ρ
ρ
ρ(cid:48)
=⇒
• forall ρ s.t. Ξ2; Σ2;E2
=⇒ and the transitions do not have
declassiﬁcation steps there exists ρ(cid:48) such that ρ ≡κ ρ(cid:48) and
Ξ1; Σ1;E1
The theorem states that if Ξ1; Σ1;E1 and Ξ2; Σ2;E2 differ
only in the secrets they contain, then they behave the same
from the attacker’s perspective, provided that the attacker can
only observe portions of the traces. To put it another way:
the attacker cannot guess the secrets in the initial conﬁg-
uration, because the trace that
the attacker sees does not
depend on those secrets. Even though the theorem does not
allow declassiﬁcation during transitions, the initial states can
be ones produced as a result of using declassiﬁcation. This
means that after initial declassiﬁcation, if there is no further
declassiﬁcation, then the attacker cannot learn more secrets
than what was revealed earlier.
C. Implications for Browser Design
Our analysis exposed several implication for browser design.
Blocking event handlers Chromium has events for which
an extension core can register a blocking event handler; the
browser waits until all blocking handlers for an event ﬁnish
before proceeding based on the values returned by the handlers.
Ordinarily we would allow an event e to be processed by an
event handler if e’s label is lower than or equal to the handler’s
label. This follows the principle that less-secret information
can ﬂow to components that are allowed to learn more-secret
information. However, for blocking event handlers, tainting the
handler in this way leaks information. Consider the following
scenario: An extension A knows a secret (0 or 1). If the secret
is 0, A registers a blocking handler to redirect the web request
from cnn.com to nytimes.com; otherwise, A does not register
that handler. Here, the request to load cnn.com is an event
observable to the attacker. After A handles the blocking event,
the request to nytimes.com will not be observable to the attacker.
When the attacker observes that cnn.com is loaded, it know
that the secret is 1. This leak will be prevented if blocking
handlers accept only those events that have the same secrecy
label as the handler. Enforcing this would prevent extension A
from registering the handler and subsequently using it to leak
a secret to the attacker.
Synchronous DOM reads Chrome’s DOM APIs are syn-
chronous, so when a script calls the read API, the API always
returns a result, even when the target doesn’t exist. The
synchronous read can be used to leak information. Suppose
a content script A has a secret (0 or 1). If the secret is 1, A
taints a speciﬁc DOM node. An attacker B attempts to read the
DOM node; if the return value is an error code, it knows A’s
secret is 1. The only way to ﬁx this problem (while retaining
ﬂoating labels) is to implement synchronous DOM access APIs
that do not return in case of a violation.
Multi-level bookmarks
Like the DOM, bookmarks have
a tree structure. Operations on bookmarks include insertion,
deletion, and mutation of nodes and subtrees. As with the
DOM, we could allow each node to be tainted with the label of
the entity that updates the data structure. The drawback is that
to prevent information leakage, many simple operations are
9
prohibited. For instance, if a script with many secrets wrote
to the root of the bookmark tree, then no entities that are
allowed fewer secrets can read any bookmark. Since book-
marks have a long life cycle, this is too prohibitive. Instead,
we borrow ideas from multi-level secure execution [20], and
keep multiple copies of the bookmarks, one at each active
security level. Given an update to a bookmark at label κ, if
there is no bookmark with label κ, we select one from the set
of bookmarks such that its label κ(cid:48) (cid:118) κ, copy this bookmark to
label κ, and apply the update to this bookmark. This approach
provides noninterference and allows more ﬂexible operations
on bookmarks.
Cookies and history
Cookies and history are similar to
bookmarks in that they are long lived; tainting them would
interfere with normal functionality. Hence, we label each
with a simple label κ. For cookies, the label corresponds to
the cookie’s domain, so web sites can set and retrieve their
cookies, which is the main functionality of the cookies. For
history, it is the secrecy and integrity label of the entity that
caused the history entry to be created.
To operate on cookies, an entity needs to reclassify to the
secrecy label of a cookie’s domain, which is consistent with
having the ability to access content from that domain.
When querying history, an entity with label (cid:96) is given
results composed of entries whose label is lower than or equal
to (cid:96). When deleting history entries, only entries with label
equal to or higher than (cid:96) are removed.
D. Limitations (Implicit Flows)
Our enforcement mechanism is a form of policy-based
dynamic taint tracking; and, therefore, provides similar se-
curity guarantees as those methods. In particular, trace-based
noninterference assumes that an attacker can only observe
sequences of actions. Our enforcement mechanism cannot
prevent attacks where the attacker has more knowledge than
just traces; e.g., behavior of the scheduler, timing channels.
More concretely, our implemented enforcement mechanism
allows subtle implicit ﬂows resulting from scripts branching
on secrets, and then ﬂoating the label of an entity only in one
of the branches. To explain this apparent conﬂicts between
the noninterference theorem and implicit ﬂows, we use the
following example. Let x, y, and z represent DOM nodes. eh,
eh1 , and eh2 are event handlers processing different types of
events. x is public, y can ﬂoat, and z contains the value of a
secret, which is either true ((cid:62)), or false (⊥).
x = ⊥L, y = ⊥F (L,H), z =?H
eh() = {trigger eh1 (); trigger eh2 (); read x }
eh1 () = {read z; if (¬z) y := (cid:62)}
eh2 () = {read y; if (¬y) x := (cid:62)}
Initially, an event triggers eh. When the secret value z
is (cid:62), the following trace is observed by the attacker if the
programs are run sequentially: read y, write x (cid:62), with x = (cid:62)
in the end. If the attacker observes this trace, he cannot,
without knowledge of the scheduler, be certain that z = (cid:62).
This is because, if eh 2 is scheduled before eh 1, the attacker
would observes the same trace regardless of z’s value. This
scheduling is reasonable because these event handlers are
called asynchronously.
When z = ⊥, y is tainted to secret, and the trace of
sequential execution observable to an attacker is read x, with
x = ⊥ in the end. Similarly, in this case the attacker cannot
be certain that z = ⊥: when z = (cid:62), x could be read before
eh 1 and eh 2 execute, which would generate the same trace.
In other words, the attacker cannot know whether z = ⊥, or
z = (cid:62) and eh 2 has not been triggered.
In both cases, security relies on the attacker’s lack of
knowledge of the scheduler. The ﬁrst relies on the fact that
event handlers can be scheduled out of order. The second
relies on the fact that the scheduler does not guarantee that
asynchronous calls will execute in a timely manner. How-
ever, neither assumption is true for most implementations of
JavaScript schedulers. In the ﬁrst case, it is almost certain that
eh 1 executes before eh 2, thus invalidating the possibility that
z = ⊥. For the second case, the scheduler will schedule calls
soon after they are made, and, hence, the attacker that waits
longer will see the action of reading y and will be able to
eliminate the possibility that z = (cid:62).
There are several ways to mitigate this problem. One is to
modify the scheduler to make it less predictable, and hence
make it harder or impossible for the attacker to guess the
secret. Another approach is to modify the JavaScript interpreter
and implement ﬁner-grained enforcement mechanisms that
implement the no-sensitive-update strategy [2], [5], as is done
in several projects [13], [27], [28]. However, this approach
may be too restrictive, and still only partially solves the
problem. These mechanisms rely on halting the entire program
to prevent attackers from getting more information if an entity
is about to be ﬂoated in a branch conditioned on secrets. How-
ever, this only works for a stand-alone program. In the browser
setting, attackers can collaborate with remote servers, which
the reference monitor implemented in the browser cannot stop.
The attacker can thus observe that the browser is halted (e.g.,
no more requests are sent to the server). We believe adding
non-determinism or probabilistic execution to the JavaScript
interpreter, or using Secure Multi-Execution (SME) are the
only ways to achieve stronger formal security guarantees. Our
approach prevents direct transfer of secrets to the attacker, and
the methods for circumventing it require attackers to engage
in behaviors (e.g., polling on shared variables) that are likely
to be detectable through run-time behavioral proﬁling.
Stronger notions of noninterference exist to rule out some
of the subtle leaks. For instance, by using bi-simulation as
the notion of behavioral equivalence, reasoning about non-
interference will encompass certain timing-based attacks and
implicitly leaks. Such an adversary model allows the adversary
to distinguish between two states that are reached from the
same initial state through two different execution paths, even
when those paths have equivalent
traces. Several browser
features, mainly synchronous calls and ﬂoating labels, prevent
us from achieving this stronger notion of noninterference. Sim-
ilarly, when an attacker can measure other system state (e.g.,
power consumption), even stronger notions of noninterference
are needed. However, the majority and most damaging web
attacks are not that sophisticated, and our proposed mechanism
(provably) can defend against them.
10
that point. To obtain an end-to-end trace of control ﬂow, from
mouse click to outgoing network activity, required multiple
backtraces. If the IPC message was speciﬁc to the action under
analysis, the process became easier by indicating the origin of
an IPC within the code. Similarly, a signiﬁcant implementation
challenge was locating the places where labels needed to be
checked, which span the modules and processes that comprise
Chromium. E.g., Chromium’s APIs are executed in the browser
process but are accessed by extensions running in a renderer
process. Hence, labels that would naturally be attached to
data structures that
live only within speciﬁc processes or
components need to be marshalled across process boundaries.
To achieve this, Chromium’s IPC layer was modiﬁed to carry
labels between processes.
JavaScript calls The V8 JavaScript engine controls its own
internal control ﬂow, and does not follow calling conventions
such as cdecl, which would support traversal with a debugger.
Therefore, the V8 subsystem is a black box to our analysis,
and we only regain control once control transfers to the binding
layer between WebKit and V8. Fortunately, we had the ability
to attach the label to the script execution context, and we are
able to then check against it inside the binding code.
C. Examples of Implementation Details
We next show several examples of how our implementation
initializes, propagates, and checks labels. The examples are
representative of information-ﬂow paths through browsers.
An extension core calls a Chrome API
Chrome APIs