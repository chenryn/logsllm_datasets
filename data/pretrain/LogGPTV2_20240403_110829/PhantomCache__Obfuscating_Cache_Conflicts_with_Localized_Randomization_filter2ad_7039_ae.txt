c . To form an initial E including m relevant addresses,
TABLE II.
TIME FOR EVICTION SET MINIMIZATION UNDER
PHANTOMCACHE USING r CANDIDATE CACHE SETS.
r
2
4
6
8
O(|E|2) algorithm
13
584
170,682
9,583,986
days
years
years
years
O(|E|) algorithm
0.7
6.5
7.8
584
seconds
days
years
years
the attacker needs c
r × m addresses on average 4.
Before removing one or more addresses from the initial
set E, the attacker needs to test if the remaining addresses
are still sufﬁcient to ﬁll up sx. In other words, there are still
at least m addresses remained whose candidate sets include
sx. In traditional caches, the attacker only needs to test once.
Speciﬁcally, it ﬁrst accesses x together with all the remaining
addresses. Then it reloads x and measures latency. If x is
observed to be evicted, then the remaining addresses are
sufﬁcient to ﬁll up sx.
PhantomCache drastically increases the difﬁculty of the
preceding tests of address removal. Because every address may
map to one of r candidate sets, the probability that all the
m partially-congruent addresses map to the same target cache
set sx is only 1
rm . If one or more of them do not map to
the target cache set, x cannot be evicted. This means that the
attacker needs to repeat the test for at least rm times to avoid
removing addresses that should be retained. To summarize,
PhantomCache brings an O(rm) blowup to the complexity
of existing minimization algorithms (both O(|E|2) [33] and
O(|E|) [35], [40]).
We now calculate the number of memory accesses by
both types of algorithms to minimize an eviction set
in
PhantomCache. We start with the well-investigated and widely
exploited minimization algorithm with an O(|E|2) complexity
r × m addresses in the initial
[26], [30], [33], [40]. Given c
eviction set E, the attacker removes one address after accessing
the remaining addresses for rm times per iteration. The iterative
address-removal process ceases upon the completion of the
iteration with only m addresses left. We accordingly calculate
r × m − m + 1
the total number of memory accesses in the c
iterations as follows.
rm×i =
×(
1
2
c × m
r
+m)×(
c × m
r
−m+1)×rm. (6)
r ×m(cid:88)
c
i=m
For the O(|E|) algorithm, although the complexity is linear
with respect to |E|, the constant coefﬁcient varies. So far,
the best result is achieved in [35], that is, 37 × |E|. In our
calculation, we consider an extreme case with the coefﬁcient
as only one in favor of the attacker. Then the total number of
memory accesses approximates as the follows.
c × m
r
× rm.
(7)
Table II provides the time cost for the attacker to ﬁnd a
minimal eviction set on an Intel Xeon E5-4620 CPU with
a 16-way 16 MB LLC. In this case we have m = 16 and
4The attacker can also start with more addresses, but that will only take it
more time to minimize the eviction set because ﬁnally only m addresses are
needed.
10
c = 16,384. We lower bound the memory access time by L1-
cache access time, that is, approximately 2 ns. When we set
r as 4, the O(|E|2) algorithm costs the attacker more than
500 years. For the O(|E|) algorithm, r = 8 sufﬁces to take
the attacker 500+ years for ﬁnding a minimal eviction set. In
comparison with global randomization across all the c = 16,384
sets, PhantomCache uses only a limited randomization space
to achieve a strong security guarantee.
However, we have only proved the security of Phantom-
Cache against existing minimization algorithms with a remove-
and-test style [40]. It is possible that new attacks with less
complexity than state-of-the-art O(|E|) or new minimization
style other than remove-and-test will emerge. Such attacks may
break the defense of PhantomCache as well as related schemes
[34], [35], [45]. To the best of our knowledge, a general lower
bound for remove-and-test algorithms or even all minimization
algorithms still remains an open question. This is also why we
cannot provide a further analysis or proof besides the current
ﬁndings over the state-of-the-art O(|E|) algorithm.
E. Hardness of Salt Cracking
If the attacker usurps a privilege of directly using physical
addresses to access memory, the secrecy of salts becomes
critical. Otherwise, the attacker can bypass the hard minimiza-
tion process. This is because that it can easily ﬁnd a minimal
eviction set by computing the candidate sets of each physical
address. Therefore, salts should be robust against cracking. To
further increase the attacker’s leverage, we assume that the
attacker can compute indices of candidate sets fairly fast and
omit so caused time cost in the following analysis. Since a
salt consists of two parts respectively for XORing with the tag
ﬁeld and index bits (Section IV-B), the length of a salt is equal
to that of both ﬁelds. Given that typical modern processors
use 64-bit physical addresses and 64-byte data blocks, the
length of a salt is 64 − log2 64 = 58 bits. Through a brute-
force attack, the attacker needs to test 257
salts on average
r
to ﬁnd a correct salt among r ones. A simple way to test a
salt is using the salt to calculate a group of addresses with
a common candidate set, and then accessing them to check
whether the common candidate set can be primed. At least
m such addresses are required to prime an m-way cache set.
Therefore, testing a salt requires at least m memory accesses5.
Because using different salts likely computes different group
of addresses, most memory accesses during salt testing lead
to main-memory accesses. Considering that the attacker can
parallelize memory accesses in a multi-bank memory with b
channels, the total number of memory accesses to crack one
salt is m × 257
r × 1
b .
Consider a system with a 16-way LLC, a 4-channel memory,
and a typical main memory access latency of 60 ns [21]. When
we conﬁgure a highly secure r = 8 (Section V-D), the attacker
need take more than 136 years to crack a salt. Given that
the r salts are randomly initialized upon machine booting,
it is impractical for the attacker to bypass the eviction set
minimization process by cracking the salts.
We may also increase the salt cracking hardness by
introducing the salt randomness upon the addresses. Currently,
5In fact, m memory accesses can only prime the cache set with a
probability. A reliable test needs much more than m accesses.
1
rm
each salt is divided into two parts, saltlef t and saltright with
the same size as that of tag bits and index bits, respectively.
Given a speciﬁc salt, then it splits into the same two parts to
XOR with different addresses. If we use longer salts, we can
perform some address-speciﬁc computation over a long salt
such that different addresses may generate different saltlef t
and saltright from the same salt. This way, we can further
randomize the inputs and therefore increase the randomness of
address mapping. This surely will increase the hardness of salt
cracking by learning the address mapping pattern.
F. Global Protection versus Selective Protection
Selective protection has been explored to ﬁnd a trade-
off between security and efﬁciency. In contrast with global
protection that enforces protection on all cache accesses,
selective protection enforces protection on only data of security
interest and leaves other data simply following traditional cache
accesses. For example, PLcache can assign cache partitions to
data worthy of protection [42]. Corresponding processes access
these data using proprietary locks granted to them. Selective
protection is usually considered as a straightforward extension.
However, we ﬁnd that selective protection is infeasible for
PhantomCache due to security breach. Speciﬁcally, Phantom-
Cache uses localized randomization that 1) deterministically
chooses r candidate sets for an address to map and 2) randomly
maps the address to one of the r sets. According to the security
analysis in Section V-C, PhantomCache enforces an rm blowup
for the number of memory accesses to the attacker, where
m represents set associativity. When selective protection is
used, localized randomization applies to only data of security
interest. Consider a victim address under protection for example.
The attacker is not enforced with localized randomization and
thus its accesses still follow deterministic mapping. If this
is the case, the attacker can again use existing eviction set
minimization algorithms to form an eviction set for a speciﬁc
cache set fairly fast. Since the victim address has r candidate
sets in PhantomCache, the attacker only needs to repeat the
testing step in the algorithm for r times. That is, under selective
protection, the attack overhead is subject to an r blowup, which
is marginal in comparison with the rm scale by global protection
of PhantomCache and therefore much less secure. For example,
given a 16-way 16 MB LLC with 16,384 sets and r = 8
candidate sets for PhantomCache address mapping (Table II),
selective protection can drastically degenerate security in that
a minimal eviction set found in at least 9,583,986 years under
global protection can be found in only 0.024 seconds. Therefore,
we do not suggest to use selective protection for PhantomCache;
we consider only the global protection mode in what follows.
VI.
IMPLEMENTATION
We implement PhantomCache using ChampSim [1], a trace-
based microarchitecture simulator. It models a full-ﬂedged CPU
of out-of-order cores with a 3-level on-chip cache hierarchy.
This makes ChampSim well accepted in academia for evaluating
cache performance. For example, it is the designated simulator
for the Cache Replacement Championship at ISCA ’17 and the
Data Prefetching Championship at ISCA ’19. PhantomCache
implementation enforces our localized randomization technique
over the conventional cache access management in ChampSim.
As discussed in Sections III and IV, key components include
11
TABLE III.
EXPERIMENT SETUP.
Module
Processor
Private L1 I/D cache
Private L2 cache
Shared LLC
Memory
Conﬁguration
1∼8 cores, 3.2 GHz,
out-of-order 256-entry ROB
64-set, 8-way, 32 KB
512-set, 8-way, 256 KB
2∼16 MB, 8-bank, 16-way, 20 cycles
800 MHz (DDR 1.6GHz),
1∼2 channels,
8-Banks each, 2 KB row buffers,
tCAS-tRCD-tRP: 11-11-11
the set index calculation unit, the cache search unit, and
the cache replacement unit. Since ChampSim features a non-
inclusive cache by default, it should be ﬁrst modiﬁed to support
inclusion. To this end, we add a back_invalidate func-
tion and modify handle_fill and handle_writeback
procedures in the cache module. When a data block is replaced,
back_invalidate is invoked to evict the data block in
higher-level caches as well if it exists therein.
As with hardware-only randomized mapping solutions (e.g.,
NewCache [25] and CEASER [34]), our modiﬁcation over the
inclusion-enabled ChampSim touches only the LLC module.
It remains as a transparent layer between the L2 cache6
and memory controller. To handle a memory access request,
ChampSim searches the addressed data block through higher-
level caches to lower-level caches until a cache hit returns. If
all of the L1 cache, L2 cache, and LLC return cache misses, the
memory access request is directed to memory. The addressed
data block is then fetched from memory to each level of
the cache hierarchy. To keep the interfaces for L2-LLC and
LLC-memory communication intact, PhantomCache modiﬁes
the read and write procedures inside the LLC module. The
modiﬁcation for both procedures lies mainly in the handling
of cache search and cache replacement. For the search process,
we add the single–clock-cycle hash function (Section IV-C)
and call it in the get_set function. This function returns
the indices of a set of candidate sets rather than a single
set
index determined by the index bits of the requested
address. To perform cache search and invalidation over all
these candidate sets, we also modify the check_hit and
invalidate_entry functions. A cache miss triggers the
replacement process by randomly selecting one of the candidate
sets. The data block fetched from memory is then placed into
the selected cache following LRU.
VII. EVALUATION
Workloads. We evaluate PhantomCache performance by run-
ning workloads from the SPEC CPU 2017 benchmark package