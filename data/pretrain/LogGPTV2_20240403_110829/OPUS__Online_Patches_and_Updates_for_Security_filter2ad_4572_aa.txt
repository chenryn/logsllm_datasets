title:OPUS: Online Patches and Updates for Security
author:Gautam Altekar and
Ilya Bagrak and
Paul Burstein and
Andrew Schultz
OPUS: Online Patches and Updates for Security
Gautam Altekar
Ilya Bagrak
Paul Burstein
Andrew Schultz
{galtekar,ibagrak,burst,alschult}@cs.berkeley.edu
University of California, Berkeley
Abstract
We present OPUS, a tool for dynamic software patch-
ing capable of applying ﬁxes to a C program at run-
time. OPUS’s primary goal is to enable application of
security patches to interactive applications that are a fre-
quent target of security exploits. By restricting the type
of patches admitted by our system, we are able to sig-
niﬁcantly reduce any additional burden on the program-
mer beyond what would normally be required in develop-
ing and testing a conventional stop-and-restart patch. We
hand-tested 26 real CERT [1] vulnerabilities, of which 22
were dynamically patched with our current OPUS proto-
type, doing so with negligible runtime overhead and no
prior knowledge of the tool’s existence on the patch pro-
grammer’s part.
1
Introduction
Security holes are being discovered at an alarming rate:
the CERT Coordination Center has reported a 2,099 per-
cent rise in the number of security vulnerabilities re-
ported from 1998 through 2002 [27]. The onslaught of
security violations seems unlikely to abate in the near
future as opportunistic hackers focus their attention on
exploiting known application vulnerabilities [3].
Software patching is the traditional method for closing
known application vulnerabilities. After a vulnerability
has been disclosed, vendors expediently create and dis-
tribute reparative patches for their applications with the
hope that administrators will download and install them
on their systems. However, experience indicates that ad-
ministrators often opt to delay installing patches and in
some cases, to not install them at all [23].
Administrators forego patch installation for several
reasons. At the very least, applying a conventional patch
requires an application restart, if not a full system restart.
For many applications, the resulting disruption is often
too great [5]. Perhaps more problematic, patches have
become extremely unreliable due to shortened testing cy-
cles and developers’ tendency to bundle security ﬁxes
with feature updates. These unreliable patches can se-
riously debilitate a system, leaving administrators with
no reliable method of undoing the damage [23]. Never-
theless, the industry’s recognition of the need for small,
feature-less security patches [27] and renewed emphasis
on patch testing [11] promises to mitigate irreversibility
and unreliability concerns. But even with these practices
in place, the call for disruption-free security patches re-
mains unanswered.
We believe that the disruption imposed by conven-
tional patching is and will continue to be a strong
deterrent to the quick installation of security patches.
While resource-rich organizations combat the disrup-
tion through the use of redundant hardware, rolling up-
grades, and application-speciﬁc schemes [6], many home
and small-business administrators lack similar resources
and consequently, they are forced to tradeoff applica-
tion work-ﬂow for system security. As the number of
issued security patches continues to increase, the lack of
transparency inherent in conventional patching becomes
more evident, serving only to further dissuade users from
patching.
Home and small-business administrators need a non-
disruptive alternative to conventional security patching.
Toward that goal, we introduce OPUS–a system for con-
structing and applying dynamic security patches. Dy-
namic security patches are small, feature-less program
ﬁxes that can be applied to a program at runtime. Many
types of vulnerabilities are amenable to dynamic patch-
ing: buffer overﬂow, format string, memory leaks, failed
input checks, double frees, and even bugs in core appli-
cation logic (e.g., a script interpreter bug). Our survey of
CERT vulnerabilities over the past 3 years has conﬁrmed
this to be the case.
Applying dynamic patches to running programs intro-
duces additional complexity and implies fewer guaran-
tees of the patch’s correctness. In fact, determining the
USENIX Association
14th USENIX Security Symposium
287
correctness of dynamic patches has been proven unde-
cidable in the general case [15]. OPUS addresses this
theoretical limitation by supplying the programmer with
warnings of program modiﬁcations that are likely to re-
sult in an unsafe dynamic patch. We derive these warn-
ings from the static analysis of patched and unpatched
code. Once the programmer is conﬁdent with the patch’s
safety, OPUS produces a dynamic patch that can be dis-
seminated to end-users who in turn can immediately ap-
ply the patch using the OPUS patch application tool.
Despite expectations, our preliminary experience us-
ing OPUS on dozens of real security patches and real
applications free of instrumentation reveals that the pro-
cess is surprisingly safe and easy. We attribute this result
primarily to the small, isolated, and feature-less nature
of security patches, and secondarily to OPUS’s support
for the C programming language and seamless integra-
tion with a widely used development environment (GCC
and the Make system). While we hypothesized that static
analysis would signiﬁcantly aid the programmer in con-
structing safer patches, security patches proved to be so
simple in practice that programmer intuition often suf-
ﬁced.
The rest of the paper is organized as follows. We ﬁrst
describe the basic design goals of OPUS in section 2.
Then we describe the abstract patch model assumed by
OPUS in section 3. Section 4 ﬂeshes out all major com-
ponents of the OPUS architecture, while section 5 relates
noteworthy implementation challenges. Experience and
evaluation are described in section 6. Related work in
the general area of vulnerability defense is highlighted
in section 7. Finally, we propose some future work in
section 8 and conclude in section 9.
2 Design considerations
The key observation behind OPUS is that most security
patches are small,
isolated, and feature-less program
ﬁxes. This observation motivates our goal of building
a widely applicable dynamic security patching sys-
tem rather than a generic dynamic software upgrade
mechanism. The following design decisions reﬂect the
practical nature of our approach:
Support the C programming language. Given the
signiﬁcant amount of work done in type-safe dynamic
software updating [10, 16], it would be ideal if programs
were written in type-safe languages that preclude
many security bugs.
However, programmers have
been reluctant in making the transition, often citing
the cost of porting to a safe language as a justiﬁcation
for inaction. By supporting C as the ubiquitous unsafe
programming language, OPUS is able to accommodate
legacy code without monumental effort on the part of
the programmer.
Integrate with existing development environment. No
system is entirely practical if it intrudes on the software
development and deployment
infrastructure. OPUS
works transparently with standard Unix build tools
(GCC and Makeﬁles). Moreover, it integrates smoothly
with large-scale software projects engineered with little
foresight of our tool.
it
In general,
Estimate dynamic patch safety.
is
impossible to guarantee that dynamically and statically
applied versions of the same program change will
exhibit identical program behavior [15]. To mitigate
(but not eliminate) the danger of producing an un-
safe dynamic patch, OPUS employs static analysis to
point out potentially dangerous program changes.
In
particular, we assume that unsafe dynamic patches
arise from modiﬁcation of state that is not local to the
function being patched and provide warnings for all such
instances.
Require no code annotations. Many existing dynamic
update techniques provide programmer generated anno-
tations or transition functions to assist in patch analysis
and application (e.g.,
[16, 26]). While these systems
are very ﬂexible with respect to the types of patches
they admit,
the annotation features they provide are
rarely necessary in the constrained domain of security
patching. By not supporting such features in OPUS, we
were able to simplify its design and enforce our policy
of admitting only isolated and feature-less program
modiﬁcations.
Patch at function granularity. In OPUS, the smallest
possible patch still replaces a whole function deﬁnition.
Patch modiﬁcations that spread over multiple functions
will result in a patch containing the new deﬁnitions for
all functions affected. The new code is invoked when
control passes to the updated function’s body. Our deci-
sion to patch at function granularity not only simpliﬁed
reasoning about patch safety, but also eased implemen-
tation. The alternative, that of patching at sub-function
granularity, is too cumbersome to implement and results
in no appreciable beneﬁt to the user.
3 Patch model
In abstract terms independent of the implementation
speciﬁcs, the patch model is intended to answer two
questions:
1. What kinds of patches don’t work with OPUS?
288
14th USENIX Security Symposium
USENIX Association
2. What kinds of patches may not be safe when used
with OPUS?
To answer the ﬁrst question, we present detailed descrip-
tions of inadmissible patches (i.e., patches that OPUS
outright rejects). We then answer the second question
by deﬁning our notion of dynamic patch safety.
Inadmissible patches
3.1
Inadmissible patches are classiﬁed into two types: those
that are prohibited due to fundamentally hard limitations
of dynamic patching and those that are excluded to ease
our initial implementation. While it is unlikely that we
can overcome the fundamentally hard limitations, future
versions of OPUS will eliminate many of the current
implementation-related limitations.
3.1.1 Fundamental limitations
No patching top-level functions. A dynamic patch
is useful only if the patched function is bound to be
called again at some future point in the execution of the
program.
If top-level functions such as C’s main are
patched, the modiﬁcations will never take effect. This
is also true for functions that run once before the patch
is applied and, due to the structure of the program, will
never run again.
No changes to initial values of globals. All glob-
als are initialized when the program is loaded into
memory. Thus, all initialization is complete before the
patch is ever applied and as a result, modiﬁcations to
global initial values will never take effect.
3.1.2
Implementation limitations
No function signature changes.
In C, a function
signature is deﬁned by its name, the type of each of its
arguments, and the type of its return value (argument
name changes are allowed). A straightforward way to
handle altered function signatures is to consider it as a
newly added function and then patch all the functions
invoking it. In practice, however, we rarely encountered
security patches that alter
function signatures and
therefore, we decided not to support them in our initial
implementation. Thus, all modiﬁcations introduced by a
patch must be conﬁned to function bodies.
No patching inlined functions. C supports explicit
inlining through macro functions and GCC supports
implicit inlining as an optimization. In principle, a patch
for a macro function can be considered as a patch for
all the invoking functions. However, it’s more difﬁcult
to determine if GCC has implicitly inlined a function.
Since we rarely encountered patched inline functions
in our evaluation and because we wanted to keep our
prototype implementation simple, we chose to prohibit
inlining all together.
3.2 Patch safety
A dynamic patch is safe if and only if its application re-
sults in identical program execution to that of a statically
applied version of the patch. More precisely, a safe patch
does not violate the program invariants of any function
other than the one in which the change was made.
Without programmer assistance, the problem of static
invariant checking is undecidable. Therefore, OPUS
adopts a conservative model of patch safety. We say that
a patch is conservatively safe if and only if the function
changes involved do not make additional writes to non-
local program state and do not alter the outcome of the
function’s return value. By non-local state, we mean any
program state other than that of the patched function’s
stack frame. Examples include global and heap data, data
in another function’s stack frame, ﬁles, and sockets.
A conservatively safe patch does not change the pro-
gram invariants of unpatched functions (assuming a con-
ventional application). Thus, conservative patch safety
implies safety as deﬁned above. The converse, however,
is not true and therefore, a problem with the conserva-
tive safety model is that it is subject to false positives:
it labels many patches as dangerous when they are in
fact safe. For example, consider the following patch for
BIND 8.2.2-P6’s zone-transfer bug [29]:
*** 2195,2201 ***
zp->z_origin, zp_finish.z_serial);
}
soa_cnt++;
if ((methode == ISIXFR)
|| (soa_cnt > 2)) {
return (result);
-->
}
} else {
*** 2195,2201 ***
zp->z_origin, zp_finish.z_serial);
}
soa_cnt++;
if ((methode == ISIXFR)
|| (soa_cnt >= 2)) {
return (result);
-->
}
} else {
USENIX Association
14th USENIX Security Symposium
289
Although the patch is safe (as veriﬁed by the program-
mer), it is not conservatively safe due to its alteration of
the return value: the function now returns result when
soa cnt equals 2. Unfortunately, most security patches
alter the function return value in a similar manner, imply-
ing that strict adherence to the conservative patch model
will preclude a majority of patches in our domain.
Since we believe (and have veriﬁed to some extent)
that most security patches are safe in practice, a key goal
of OPUS is to admit as many security patches as possible.
Therefore, if a patch doesn’t meet the conservative patch
model, OPUS does not reject it. Rather, it informs the
programmer about the violation, thereby allowing him or
her to invoke intimate knowledge of the program before
making the decision to accept or reject the patch.
4 Architecture
4.1 Overview
OPUS combines three processing stages: (1) patch anal-
ysis, (2) patch generation, and (3) patch application. The
interconnection between these stages is governed by sim-
ple annotations that serve as a way to maintain interme-
diate state and hand off information from one stage to
the next. This allows for greater ﬂexibility in terms of
the architecture’s future evolution and keeps the pieces
in relative isolation from each other, making them easier
to compose. The high-level architecture is presented in
Figure 1.
The OPUS architecture is motivated by two high-level
usability requirements: (1) user interaction with the sys-
tem should appear natural to a programmer, and (2) the
system should ﬁt seamlessly on top of an existing soft-
ware build environment developed with no foresight of
OPUS. We meet these design goals by augmenting the
standard C compiler and substituting it for the default
one, which simultaneously suits our analysis needs and
preserves the native build environment of the patched ap-
plication (assuming that it is normally built with the de-
fault compiler).
The programmer interacts with the OPUS front-end
similar to the way a programmer would interact with a
regular C compiler. Compile time errors are still handled
by the compiler proper with OPUS generating additional
compiler-like warnings and errors speciﬁc to the differ-
ences found in a given patch. The programmer invokes
the annotation analysis on the patched source, acts on any
warning or errors, and ﬁnally invokes the patch genera-
tion to compile the dynamic security patch. The patch
injector then picks up the dynamic patch and applies it
into a running process.
4.2 Annotations and interface languages
The preamble to the patch analysis is a script that per-
forms a diff of the changed and the unchanged source
trees and invokes the appropriate build target in the
project’s master Makeﬁle to initiate the build process.
Using the diff information, OPUS generates a series of
.opus ﬁles, one in every directory that has a changed
source ﬁle. The purpose of the .opus ﬁles is to notify
the instrumented C compiler which ﬁles have changed
and will require static analysis (described below).
The instrumented C compiler parses .opus ﬁles when
invoked from the project’s Makeﬁle. If the ﬁle is present,
then a new set of annotations is generated for the ﬁle
by the compiler (“Source annotations” in Figure 1). The
line ranges found in .opus annotations are useful as an
aid to the programmer because they restrict the warnings
and errors the patch analysis produces to only the line
ranges associated with the patch (we obtain line ranges
from the textual diff, but other more sophisticated ap-
proaches are also possible [17]). The policy is reasonable
since only the changed lines are considered problematic
as far as patch safety is concerned (see section 3); the
unmodiﬁed code is assumed to work correctly.
Ideally, the old and the new source trees would be pro-
cessed in parallel obviating the need for external state
in the form of annotations. The established build envi-
ronment, however, prevents us from invoking the com-
piler in the order most convenient to us. To circumvent
this practical limitation, static analysis, which uses only
the local (per ﬁle) information, is handled by the instru-
mented compiler, while the rest of the cross-tree analysis
is deferred to the annotation analysis.
The source annotations produced by the instrumented
compiler contain tags specifying which function deﬁni-
tions were changed by the patch. Similarly, the annota-
tions include hashes of function prototypes for cross-tree
comparison by our patch analysis. We also include in the
annotations a list of globals so that addition of new glob-
als is detected across the patched and unpatched source
trees.
4.3 Static analysis
The static analysis portion of the system has two goals.
One is to determine whether the patch is admissible as
described in section 3.1. The other is to determine if the
patch satisﬁes our deﬁnition of conservative safety de-
scribed in section 3.2.
We address the ﬁrst goal by generating source annota-
tions that are fed into the annotation analysis, which then
alerts the programmer if the patch meets one of the inad-
missible criteria. For instance, if the annotations indicate
that the signature for a given function has changed, an
290
14th USENIX Security Symposium
USENIX Association
Figure 1 OPUS high-level architecture
error message is returned to the user. The error message
denotes explicit rejection of the patch.
We address the second goal using static analysis. The
goal of static analysis is to direct the patch writer’s atten-
tion to program changes likely to result in an unsafe dy-
namic patch as deﬁned by our conservative safety model.
The current implementation of static analysis checks for
only one component of our conservative safety model.
In particular, it checks if there are any new writes to non-
local state (e.g., global variables, data in another func-
tion’s stack frame) within the patched function, and if
there are, it marks those writes as harmful. Our current
implementation does not check for altered return values
(the other component of the conservative safety model):
such functionality requires program slicing, which we
haven’t fully implemented yet.
Given that our current implementation focuses only on
identifying new writes to non-local state, the chief dif-
ﬁculty is that the set of C variables that can be refer-
enced/dereferenced to affect the non-local state is a dy-
namic property of a program. To address this difﬁculty,
we employ a conservative static analysis algorithm that
computes a set of all local variables that could be used
to point and write to data outside of the function’s stack
frame. In effect, our analysis is similar to the static analy-
sis designed to catch format string vulnerabilities, except
in the format string case the tainted set of expressions is
the set whose values may have arrived over an untrusted
network [25].
4.3.1 Bootstrapping static analysis
Success of the static analysis depends on a crude over-
estimation of the set of variables determined to refer to
non-local state. We call this set the tainted set, and the
variables in it — tainted variables.
For any given function, the set of function arguments
of pointer type (as determined by the pointer_type_p
predicate) is considered tainted by default. Since neither
the content nor origin of these pointers is known in gen-
eral, we assume they point to non-local state. Currently,
we do not perform inter-procedural static analysis. How-
ever, we would like the tainting to be conservative, and
therefore the analysis also taints any pointer variable as-
signed as a return value of a callee.
4.3.2 Taint ﬂow propagation rules
Figure 2 contains a subset of rules for computing the
tainted set. In our notation R stands for a set of tainted
expressions, and e is a string of C source denoting some
expression. The statement “given a set of tainted expres-
sions R, running the taint ﬂow algorithm on expression e
results in a new set of tainted expressions R(cid:1)” is written
as R (cid:1) e ⇒ R(cid:1).
FUNCTION rule captures our assumption in regard
to pointer type function arguments. IF speciﬁes that each
USENIX Association
14th USENIX Security Symposium
291
 



















