title:OPUS: Online Patches and Updates for Security
author:Gautam Altekar and
Ilya Bagrak and
Paul Burstein and
Andrew Schultz
OPUS: Online Patches and Updates for Security
Gautam Altekar
Ilya Bagrak
Paul Burstein
Andrew Schultz
{galtekar,ibagrak,burst,alschult}@cs.berkeley.edu
University of California, Berkeley
Abstract
We present OPUS, a tool for dynamic software patch-
ing capable of applying Ô¨Åxes to a C program at run-
time. OPUS‚Äôs primary goal is to enable application of
security patches to interactive applications that are a fre-
quent target of security exploits. By restricting the type
of patches admitted by our system, we are able to sig-
niÔ¨Åcantly reduce any additional burden on the program-
mer beyond what would normally be required in develop-
ing and testing a conventional stop-and-restart patch. We
hand-tested 26 real CERT [1] vulnerabilities, of which 22
were dynamically patched with our current OPUS proto-
type, doing so with negligible runtime overhead and no
prior knowledge of the tool‚Äôs existence on the patch pro-
grammer‚Äôs part.
1
Introduction
Security holes are being discovered at an alarming rate:
the CERT Coordination Center has reported a 2,099 per-
cent rise in the number of security vulnerabilities re-
ported from 1998 through 2002 [27]. The onslaught of
security violations seems unlikely to abate in the near
future as opportunistic hackers focus their attention on
exploiting known application vulnerabilities [3].
Software patching is the traditional method for closing
known application vulnerabilities. After a vulnerability
has been disclosed, vendors expediently create and dis-
tribute reparative patches for their applications with the
hope that administrators will download and install them
on their systems. However, experience indicates that ad-
ministrators often opt to delay installing patches and in
some cases, to not install them at all [23].
Administrators forego patch installation for several
reasons. At the very least, applying a conventional patch
requires an application restart, if not a full system restart.
For many applications, the resulting disruption is often
too great [5]. Perhaps more problematic, patches have
become extremely unreliable due to shortened testing cy-
cles and developers‚Äô tendency to bundle security Ô¨Åxes
with feature updates. These unreliable patches can se-
riously debilitate a system, leaving administrators with
no reliable method of undoing the damage [23]. Never-
theless, the industry‚Äôs recognition of the need for small,
feature-less security patches [27] and renewed emphasis
on patch testing [11] promises to mitigate irreversibility
and unreliability concerns. But even with these practices
in place, the call for disruption-free security patches re-
mains unanswered.
We believe that the disruption imposed by conven-
tional patching is and will continue to be a strong
deterrent to the quick installation of security patches.
While resource-rich organizations combat the disrup-
tion through the use of redundant hardware, rolling up-
grades, and application-speciÔ¨Åc schemes [6], many home
and small-business administrators lack similar resources
and consequently, they are forced to tradeoff applica-
tion work-Ô¨Çow for system security. As the number of
issued security patches continues to increase, the lack of
transparency inherent in conventional patching becomes
more evident, serving only to further dissuade users from
patching.
Home and small-business administrators need a non-
disruptive alternative to conventional security patching.
Toward that goal, we introduce OPUS‚Äìa system for con-
structing and applying dynamic security patches. Dy-
namic security patches are small, feature-less program
Ô¨Åxes that can be applied to a program at runtime. Many
types of vulnerabilities are amenable to dynamic patch-
ing: buffer overÔ¨Çow, format string, memory leaks, failed
input checks, double frees, and even bugs in core appli-
cation logic (e.g., a script interpreter bug). Our survey of
CERT vulnerabilities over the past 3 years has conÔ¨Årmed
this to be the case.
Applying dynamic patches to running programs intro-
duces additional complexity and implies fewer guaran-
tees of the patch‚Äôs correctness. In fact, determining the
USENIX Association
14th USENIX Security Symposium
287
correctness of dynamic patches has been proven unde-
cidable in the general case [15]. OPUS addresses this
theoretical limitation by supplying the programmer with
warnings of program modiÔ¨Åcations that are likely to re-
sult in an unsafe dynamic patch. We derive these warn-
ings from the static analysis of patched and unpatched
code. Once the programmer is conÔ¨Ådent with the patch‚Äôs
safety, OPUS produces a dynamic patch that can be dis-
seminated to end-users who in turn can immediately ap-
ply the patch using the OPUS patch application tool.
Despite expectations, our preliminary experience us-
ing OPUS on dozens of real security patches and real
applications free of instrumentation reveals that the pro-
cess is surprisingly safe and easy. We attribute this result
primarily to the small, isolated, and feature-less nature
of security patches, and secondarily to OPUS‚Äôs support
for the C programming language and seamless integra-
tion with a widely used development environment (GCC
and the Make system). While we hypothesized that static
analysis would signiÔ¨Åcantly aid the programmer in con-
structing safer patches, security patches proved to be so
simple in practice that programmer intuition often suf-
Ô¨Åced.
The rest of the paper is organized as follows. We Ô¨Årst
describe the basic design goals of OPUS in section 2.
Then we describe the abstract patch model assumed by
OPUS in section 3. Section 4 Ô¨Çeshes out all major com-
ponents of the OPUS architecture, while section 5 relates
noteworthy implementation challenges. Experience and
evaluation are described in section 6. Related work in
the general area of vulnerability defense is highlighted
in section 7. Finally, we propose some future work in
section 8 and conclude in section 9.
2 Design considerations
The key observation behind OPUS is that most security
patches are small,
isolated, and feature-less program
Ô¨Åxes. This observation motivates our goal of building
a widely applicable dynamic security patching sys-
tem rather than a generic dynamic software upgrade
mechanism. The following design decisions reÔ¨Çect the
practical nature of our approach:
Support the C programming language. Given the
signiÔ¨Åcant amount of work done in type-safe dynamic
software updating [10, 16], it would be ideal if programs
were written in type-safe languages that preclude
many security bugs.
However, programmers have
been reluctant in making the transition, often citing
the cost of porting to a safe language as a justiÔ¨Åcation
for inaction. By supporting C as the ubiquitous unsafe
programming language, OPUS is able to accommodate
legacy code without monumental effort on the part of
the programmer.
Integrate with existing development environment. No
system is entirely practical if it intrudes on the software
development and deployment
infrastructure. OPUS
works transparently with standard Unix build tools
(GCC and MakeÔ¨Åles). Moreover, it integrates smoothly
with large-scale software projects engineered with little
foresight of our tool.
it
In general,
Estimate dynamic patch safety.
is
impossible to guarantee that dynamically and statically
applied versions of the same program change will
exhibit identical program behavior [15]. To mitigate
(but not eliminate) the danger of producing an un-
safe dynamic patch, OPUS employs static analysis to
point out potentially dangerous program changes.
In
particular, we assume that unsafe dynamic patches
arise from modiÔ¨Åcation of state that is not local to the
function being patched and provide warnings for all such
instances.
Require no code annotations. Many existing dynamic
update techniques provide programmer generated anno-
tations or transition functions to assist in patch analysis
and application (e.g.,
[16, 26]). While these systems
are very Ô¨Çexible with respect to the types of patches
they admit,
the annotation features they provide are
rarely necessary in the constrained domain of security
patching. By not supporting such features in OPUS, we
were able to simplify its design and enforce our policy
of admitting only isolated and feature-less program
modiÔ¨Åcations.
Patch at function granularity. In OPUS, the smallest
possible patch still replaces a whole function deÔ¨Ånition.
Patch modiÔ¨Åcations that spread over multiple functions
will result in a patch containing the new deÔ¨Ånitions for
all functions affected. The new code is invoked when
control passes to the updated function‚Äôs body. Our deci-
sion to patch at function granularity not only simpliÔ¨Åed
reasoning about patch safety, but also eased implemen-
tation. The alternative, that of patching at sub-function
granularity, is too cumbersome to implement and results
in no appreciable beneÔ¨Åt to the user.
3 Patch model
In abstract terms independent of the implementation
speciÔ¨Åcs, the patch model is intended to answer two
questions:
1. What kinds of patches don‚Äôt work with OPUS?
288
14th USENIX Security Symposium
USENIX Association
2. What kinds of patches may not be safe when used
with OPUS?
To answer the Ô¨Årst question, we present detailed descrip-
tions of inadmissible patches (i.e., patches that OPUS
outright rejects). We then answer the second question
by deÔ¨Åning our notion of dynamic patch safety.
Inadmissible patches
3.1
Inadmissible patches are classiÔ¨Åed into two types: those
that are prohibited due to fundamentally hard limitations
of dynamic patching and those that are excluded to ease
our initial implementation. While it is unlikely that we
can overcome the fundamentally hard limitations, future
versions of OPUS will eliminate many of the current
implementation-related limitations.
3.1.1 Fundamental limitations
No patching top-level functions. A dynamic patch
is useful only if the patched function is bound to be
called again at some future point in the execution of the
program.
If top-level functions such as C‚Äôs main are
patched, the modiÔ¨Åcations will never take effect. This
is also true for functions that run once before the patch
is applied and, due to the structure of the program, will
never run again.
No changes to initial values of globals. All glob-
als are initialized when the program is loaded into
memory. Thus, all initialization is complete before the
patch is ever applied and as a result, modiÔ¨Åcations to
global initial values will never take effect.
3.1.2
Implementation limitations
No function signature changes.
In C, a function
signature is deÔ¨Åned by its name, the type of each of its
arguments, and the type of its return value (argument
name changes are allowed). A straightforward way to
handle altered function signatures is to consider it as a
newly added function and then patch all the functions
invoking it. In practice, however, we rarely encountered
security patches that alter
function signatures and
therefore, we decided not to support them in our initial
implementation. Thus, all modiÔ¨Åcations introduced by a
patch must be conÔ¨Åned to function bodies.
No patching inlined functions. C supports explicit
inlining through macro functions and GCC supports
implicit inlining as an optimization. In principle, a patch
for a macro function can be considered as a patch for
all the invoking functions. However, it‚Äôs more difÔ¨Åcult
to determine if GCC has implicitly inlined a function.
Since we rarely encountered patched inline functions
in our evaluation and because we wanted to keep our
prototype implementation simple, we chose to prohibit
inlining all together.
3.2 Patch safety
A dynamic patch is safe if and only if its application re-
sults in identical program execution to that of a statically
applied version of the patch. More precisely, a safe patch
does not violate the program invariants of any function
other than the one in which the change was made.
Without programmer assistance, the problem of static
invariant checking is undecidable. Therefore, OPUS
adopts a conservative model of patch safety. We say that
a patch is conservatively safe if and only if the function
changes involved do not make additional writes to non-
local program state and do not alter the outcome of the
function‚Äôs return value. By non-local state, we mean any
program state other than that of the patched function‚Äôs
stack frame. Examples include global and heap data, data
in another function‚Äôs stack frame, Ô¨Åles, and sockets.
A conservatively safe patch does not change the pro-
gram invariants of unpatched functions (assuming a con-
ventional application). Thus, conservative patch safety
implies safety as deÔ¨Åned above. The converse, however,
is not true and therefore, a problem with the conserva-
tive safety model is that it is subject to false positives:
it labels many patches as dangerous when they are in
fact safe. For example, consider the following patch for
BIND 8.2.2-P6‚Äôs zone-transfer bug [29]:
*** 2195,2201 ***
zp->z_origin, zp_finish.z_serial);
}
soa_cnt++;
if ((methode == ISIXFR)
|| (soa_cnt > 2)) {
return (result);
-->
}
} else {
*** 2195,2201 ***
zp->z_origin, zp_finish.z_serial);
}
soa_cnt++;
if ((methode == ISIXFR)
|| (soa_cnt >= 2)) {
return (result);
-->
}
} else {
USENIX Association
14th USENIX Security Symposium
289
Although the patch is safe (as veriÔ¨Åed by the program-
mer), it is not conservatively safe due to its alteration of
the return value: the function now returns result when
soa cnt equals 2. Unfortunately, most security patches
alter the function return value in a similar manner, imply-
ing that strict adherence to the conservative patch model
will preclude a majority of patches in our domain.
Since we believe (and have veriÔ¨Åed to some extent)
that most security patches are safe in practice, a key goal
of OPUS is to admit as many security patches as possible.
Therefore, if a patch doesn‚Äôt meet the conservative patch
model, OPUS does not reject it. Rather, it informs the
programmer about the violation, thereby allowing him or
her to invoke intimate knowledge of the program before
making the decision to accept or reject the patch.
4 Architecture
4.1 Overview
OPUS combines three processing stages: (1) patch anal-
ysis, (2) patch generation, and (3) patch application. The
interconnection between these stages is governed by sim-
ple annotations that serve as a way to maintain interme-
diate state and hand off information from one stage to
the next. This allows for greater Ô¨Çexibility in terms of
the architecture‚Äôs future evolution and keeps the pieces
in relative isolation from each other, making them easier
to compose. The high-level architecture is presented in
Figure 1.
The OPUS architecture is motivated by two high-level
usability requirements: (1) user interaction with the sys-
tem should appear natural to a programmer, and (2) the
system should Ô¨Åt seamlessly on top of an existing soft-
ware build environment developed with no foresight of
OPUS. We meet these design goals by augmenting the
standard C compiler and substituting it for the default
one, which simultaneously suits our analysis needs and
preserves the native build environment of the patched ap-
plication (assuming that it is normally built with the de-
fault compiler).
The programmer interacts with the OPUS front-end
similar to the way a programmer would interact with a
regular C compiler. Compile time errors are still handled
by the compiler proper with OPUS generating additional
compiler-like warnings and errors speciÔ¨Åc to the differ-
ences found in a given patch. The programmer invokes
the annotation analysis on the patched source, acts on any
warning or errors, and Ô¨Ånally invokes the patch genera-
tion to compile the dynamic security patch. The patch
injector then picks up the dynamic patch and applies it
into a running process.
4.2 Annotations and interface languages
The preamble to the patch analysis is a script that per-
forms a diff of the changed and the unchanged source
trees and invokes the appropriate build target in the
project‚Äôs master MakeÔ¨Åle to initiate the build process.
Using the diff information, OPUS generates a series of
.opus Ô¨Åles, one in every directory that has a changed
source Ô¨Åle. The purpose of the .opus Ô¨Åles is to notify
the instrumented C compiler which Ô¨Åles have changed
and will require static analysis (described below).
The instrumented C compiler parses .opus Ô¨Åles when
invoked from the project‚Äôs MakeÔ¨Åle. If the Ô¨Åle is present,
then a new set of annotations is generated for the Ô¨Åle
by the compiler (‚ÄúSource annotations‚Äù in Figure 1). The
line ranges found in .opus annotations are useful as an
aid to the programmer because they restrict the warnings
and errors the patch analysis produces to only the line
ranges associated with the patch (we obtain line ranges
from the textual diff, but other more sophisticated ap-
proaches are also possible [17]). The policy is reasonable
since only the changed lines are considered problematic
as far as patch safety is concerned (see section 3); the
unmodiÔ¨Åed code is assumed to work correctly.
Ideally, the old and the new source trees would be pro-
cessed in parallel obviating the need for external state
in the form of annotations. The established build envi-
ronment, however, prevents us from invoking the com-
piler in the order most convenient to us. To circumvent
this practical limitation, static analysis, which uses only
the local (per Ô¨Åle) information, is handled by the instru-
mented compiler, while the rest of the cross-tree analysis
is deferred to the annotation analysis.
The source annotations produced by the instrumented
compiler contain tags specifying which function deÔ¨Åni-
tions were changed by the patch. Similarly, the annota-
tions include hashes of function prototypes for cross-tree
comparison by our patch analysis. We also include in the
annotations a list of globals so that addition of new glob-
als is detected across the patched and unpatched source
trees.
4.3 Static analysis
The static analysis portion of the system has two goals.
One is to determine whether the patch is admissible as
described in section 3.1. The other is to determine if the
patch satisÔ¨Åes our deÔ¨Ånition of conservative safety de-
scribed in section 3.2.
We address the Ô¨Årst goal by generating source annota-
tions that are fed into the annotation analysis, which then
alerts the programmer if the patch meets one of the inad-
missible criteria. For instance, if the annotations indicate
that the signature for a given function has changed, an
290
14th USENIX Security Symposium
USENIX Association
Figure 1 OPUS high-level architecture
error message is returned to the user. The error message
denotes explicit rejection of the patch.
We address the second goal using static analysis. The
goal of static analysis is to direct the patch writer‚Äôs atten-
tion to program changes likely to result in an unsafe dy-
namic patch as deÔ¨Åned by our conservative safety model.
The current implementation of static analysis checks for
only one component of our conservative safety model.
In particular, it checks if there are any new writes to non-
local state (e.g., global variables, data in another func-
tion‚Äôs stack frame) within the patched function, and if
there are, it marks those writes as harmful. Our current
implementation does not check for altered return values
(the other component of the conservative safety model):
such functionality requires program slicing, which we
haven‚Äôt fully implemented yet.
Given that our current implementation focuses only on
identifying new writes to non-local state, the chief dif-
Ô¨Åculty is that the set of C variables that can be refer-
enced/dereferenced to affect the non-local state is a dy-
namic property of a program. To address this difÔ¨Åculty,
we employ a conservative static analysis algorithm that
computes a set of all local variables that could be used
to point and write to data outside of the function‚Äôs stack
frame. In effect, our analysis is similar to the static analy-
sis designed to catch format string vulnerabilities, except
in the format string case the tainted set of expressions is
the set whose values may have arrived over an untrusted
network [25].
4.3.1 Bootstrapping static analysis
Success of the static analysis depends on a crude over-
estimation of the set of variables determined to refer to
non-local state. We call this set the tainted set, and the
variables in it ‚Äî tainted variables.
For any given function, the set of function arguments
of pointer type (as determined by the pointer_type_p
predicate) is considered tainted by default. Since neither
the content nor origin of these pointers is known in gen-
eral, we assume they point to non-local state. Currently,
we do not perform inter-procedural static analysis. How-
ever, we would like the tainting to be conservative, and
therefore the analysis also taints any pointer variable as-
signed as a return value of a callee.
4.3.2 Taint Ô¨Çow propagation rules
Figure 2 contains a subset of rules for computing the
tainted set. In our notation R stands for a set of tainted
expressions, and e is a string of C source denoting some
expression. The statement ‚Äúgiven a set of tainted expres-
sions R, running the taint Ô¨Çow algorithm on expression e
results in a new set of tainted expressions R(cid:1)‚Äù is written
as R (cid:1) e ‚áí R(cid:1).
FUNCTION rule captures our assumption in regard
to pointer type function arguments. IF speciÔ¨Åes that each
USENIX Association
14th USENIX Security Symposium
291
 



















