Regarding evaluation, TrojanZOO [36] provides different attacks as
an evaluation framework. Therefore, it considers different attacker
strategies whereas we consider different trigger types (with the
most comprehensive coverage of those) under a specific attacker
model. Most of the triggers considered in TrojanZOO (including
CLB [51] and HTB [39]) fall into the broad category of patch-based
triggers. Moreover, TrojanZOO doesn’t include Instagram filters
(Transformation-based explained in Section 2) and smooth triggers
(Image-based). As mentioned in Section 1, the trigger is chosen by
the attacker and can be any perturbation that results in a high ASR.
Therefore, evaluating on a small range of triggers that are localized
is not sufficient for an online defense. We discuss and show why
other methods fail to identify triggers that are not localized or
triggers that are injected into the main part of the image. Examples
for each trigger type are illustrated in Fig. 4. For localized triggers
we use sizes of 3x3, 5x5, 8x8 and locations at the top middle, center
middle, bottom middle, and bottom right of the image.
Evaluation Metrics. We use the True Positive Rate (TPR) and the
False Positive Rate (FPR) to evaluate our online detection approach
in the following way:
• SVM TPR: the percentage of Trojaned images identified as
Trojaned by the SVM.
• SVM FPR: the percentage of clean images identified as Tro-
• Final TPR: the percentage of Trojaned iamges identified as
Trojaned after the extract-and-evaluate step.
• Final FPR: the percentage of clean images identified as Tro-
janed by the SVM.
janed after the extract-and-evaluate step.
In general, achieving low Final FPR and high Final TPR is desired
so that a method can identify both clean and Trojaned images with
high accuracy. Our method prioritizes on achieving a high Final
TPR to ensure the detection of most if not all Trojaned instances.
4.2 Comparison with State-of-the-Art
We compare our method against STRIP [13], the state-of-the-art
online detection method. This section presents the results of our
approach averaged over all static and dynamic models when using
the default thresholds for both methods, i.e., 1% for STRIP and 50%
for our method. Our results are presented in Table 2 in the form of
‘mean± standard deviation’ for Final TPR (or Final FPR). We observe
that our method detects Trojans with an overall accuracy of 97%
and 98.7% for static and dynamic triggers, respectively. Additionally,
the False Positive Rate is 15.5% and 13.8% for static and dynamic
triggers, respectively. Our method’s run-time per input image is
on average 92.9 ms, 125.3 ms, 289.8 ms, and 212.6 ms for MNIST,
Fashion MNIST, and CIFAR10, and GTSRB, respectively. Due to the
relatively more expensive computation of attributions, our method’s
run-time based on the Neural Network architectures used in this
paper is ∼ 91 times slower than the inference-time while STRIP is
1.32 times slower.
Table 2: Results against STRIP using dynamic and static trig-
gers. For STRIP we use the suggested threshold of 1% and
for our method we use the suggested threshold of 50%. We
present the results as the mean ± one standard deviation.
MNIST
Fashion
MNIST
CIFAR10
GTSRB
MNIST
Fashion
MNIST
CIFAR10
GTSRB
Final TPR
Final FPR
Final TPR
Final FPR
Final TPR
Final FPR
Final TPR
Final FPR
Final TPR
Final FPR
Final TPR
Final FPR
Final TPR
Final FPR
Final TPR
Final FPR
c
i
t
a
t
S
c
i
m
a
n
y
D
STRIP
49.8 ± 33.0
1.8 ± 1.2
71.9 ± 36.1
0.6 ± 0.7
87.8 ± 24.1
3.0 ± 0.7
26.2 ± 37.4
0.0 ± 0.1
89.9 ± 2.9
2.2 ± 0.6
88.2 ± 7.1
2.0 ± 0.9
96.6 ± 2.3
3.0 ± 0.5
16.5 ± 26.9
0.0 ± 0.0
MISA
90.8 ± 23.8
0.5 ± 0.4
97.6 ± 4.1
27.7 ± 5.0
98.6 ± 6.4
15.0 ± 6.2
99.3 ± 2.9
18.7 ± 3.7
96.4 ± 1.8
0.4 ± 0.3
98.5 ± 1.1
21.2 ± 3.3
100.0 ± 0.0
14.4 ± 3.6
99.9 ± 0.1
19.1 ± 2.1
Overall, our method significantly outperforms STRIP, as MISA
has a much higher Final TPR in all cases of static and dynamic
triggers. From Table 2, we observe that STRIP classifies ∼ 50% or
more of the Trojaned images as clean which is evidenced by the
lower TPR and its higher standard deviation. Moreover, we examine
the cases of different thresholds for both methods and present the
ROC curve in Fig. 5. Our method has an overall AUC of 96% where
the suggested threshold corresponds to the best results across the
different choices for our threshold. On the contrary, STRIP has a
Random triggerSquare triggerNoise triggerSpread-out triggerInstagram Filteron an imageSmooth trigger010020001002002010010010020001002000.00.10.2575MISA: Online Defense of Trojaned Models using Misattributions
ACSAC ’21, December 6–10, 2021, Virtual Event, USA
Figure 5: ROC Curve over all Trojaned models for our
method (MISA) and STRIP. We mark the points that cor-
respond to the use of the suggested thresholds for each
method.
images are classified as the target label. Hence, the entropy of the
predicted labels for a set of Trojaned images is smaller than the
entropy of the predicted labels for a set of clean images. However,
we make the following observations. We find that (1) the resulted
images are not necessarily Trojaned. In addition, our experiments
show that (2) the entropy distributions can significantly overlap
for trigger types such as triggers injected near the main part of the
image, Instagram filters, spread-out triggers, and dynamic triggers.
Finally, we find that (3) STRIP cannot reliably detect triggers from
the rest of the categories.
Figure 7: MNIST: Example of Trojaned models where the en-
tropy distributions produced by STRIP overlap significantly.
Next, we illustrate Trojaned images from the superimposing
step of STRIP. Figures 6 and 8 show cases where the resulting Tro-
janed images from the addition of a Trojaned and a clean image
are not recognized as Trojaned by the neural network. In partic-
ular, in Fig. 6, the trigger is a random gray pattern at the top of
the image, and the target label is 0. The first two rows of Fig 6
Figure 6: Example of STRIP’s procedure of adding a Tro-
janed image (left) to a clean image (middle). The resulting
image (right) is classified as a different label than the target
label. The target label is the class 0. The last row corresponds
to our approach for this image.
lower overall AUC where the suggested threshold favors keeping
the False Positives low. Additionally, a higher threshold will still
keep STRIP’s TPR lower than MISA’s TPR as shown in Fig. 5.
4.2.1 Discussion of the Results. STRIP detects a run-time Trojaned
image by first superimposing (adding) the run-time image with
images from the evaluation set. Then, the resulting images are as-
sumed to remain Trojaned and are fed to the neural network. Their
main idea is that the entropy distribution of the predicted labels of
the resulting Trojaned images will be significantly different from
clean images. This assumption is based on the fact that Trojaned
Figure 8: Example of STRIP’s procedure of adding a Tro-
janed image (left) to a clean image (middle). The resulting
image (right) is classified as the label of the clean image be-
cause the trigger is added on a white background and its ef-
fect is diminished. The target label is ‘Speed limit (100km/h)’.
The last row corresponds to our approach for this image.
0.00.20.40.60.81.0False Positive Rate0.00.20.40.60.81.0True Positive RateROC CurveMISA (AUC:0.96)STRIP (AUC:0.92)True label:1Predicted label:0True label:9Predicted label:9Predicted label:8True label:1Predicted label:0True label:7Predicted label:7Predicted label:7Attribution mapMin:-0.4712 Max:0.5804Extracted maskPredicted label:00100200010020001002000100200010020001002000.500.250.000.250.500.00.20.40.60.81.001002000.00.50.000.050.10Probability (%)MNISTnormalized entropy(Trigger at the top)without trojanwith trojan0.00.20.40.000.050.10Probability (%)MNISTnormalized entropy(Trigger in the center)without trojanwith trojan0.00.20.40.00.1Probability (%)MNISTnormalized entropy(Trigger at the bottom)without trojanwith trojanTrue label:Keep rightPredicted label:Speed limit (100km/h)True label:No passingPredicted label:No passingPredicted label:No passingTrue label:Keep rightPredicted label:Speed limit (100km/h)True label:Turn right aheadPredicted label:Turn right aheadPredicted label:Turn left aheadAttribution mapMin:-0.6384 Max:2.1666Extracted maskPredicted label:Speed limit (100km/h)010020010020010015020025001002001002001002002020.000.250.500.751.000100200576ACSAC ’21, December 6–10, 2021, Virtual Event, USA
Panagiota Kiourti, Wenchao Li, Anirban Roy, Karan Sikka, and Susmit Jha
show examples of adding a Trojaned image (left) to a clean image
(center). The resulting image (right) is not classified as the target
label. The addition results in out-of-distribution images. For the
same Trojaned image, our method computes the attribution map in
the input layer as shown in the last row of Fig. 6. We then extract
the high-attributed values as the trigger’s mask and evaluate the
trigger by injecting it into the same clean images from the first two
rows. Compared to the superimposing step of STRIP, our method
can reliably detect Trojaned images by first extracting the trigger
and then injecting it into clean images.
A similar issue is observed when using RGB images. In Fig. 8 we
show that the trigger is canceled out when the run-time Trojaned
image is added to a clean image with white-colored pixels at the
location of the trigger (1st row). We also observe that the resulting
image can be classified as a different category than the target label
or the labels of the original images (2nd row). For this example, we
present the results of our approach using the same images.
Figure 9: GTSRB: Example of Trojaned models where the en-
tropy distributions produced by STRIP overlap significantly.
The illustrations of Fig. 6 and 8 can explain why the entropy
distributions of the predicted labels of Trojaned and clean images
cannot be separated with the same threshold and that such a thresh-
old might not exist. Figures 7, 9, and 10 show examples where en-
tropy distributions of the predictions of clean and Trojaned images
overlap for a range of different trigger types. Triggers injected in
the main part of the image can result in a higher entropy than the
entropy from clean labels, as shown in the top row of Fig 9. This is
the opposite of what STRIP expects before applying the threshold.
The results are evidenced by the high standard deviation of the
Final TPR in Table 2 and the lower Final TPR.
(a)
(b)
Figure 11: ROC curve across all MNIST/GTSRB models: (a)
ROC curve of MNIST; (b) ROC curve of GTSRB.
Finally, we present the ROC curves of MNIST and GTSRB in
Fig. 11. The curves justify that a better threshold does not exist for
separating the entropy distributions.
4.3 Advantage of using Intermediate-layer
Attributions
In this section, we further study our results over Trojaned models
of the same trigger type and show the limitations of using the input
layer’s attributions on detecting large or not localized triggers. We
motivate the use of intermediate-layer attributions for detecting a
range of different triggers. We show how input-layer attributions
are inadequate for large triggers, triggers overlapping with the main
part of the image, and triggers that are not patched-based, such as
Instagram filters (Transformation-based triggers as explained in
Section 2), smooth and noise triggers (Image-based triggers). Table 3
Table 3: Results for different trigger types using the default
threshold of 50% and activation layers.
Trigger
3x3
5x5
8x8
Dynamic
Top
Center
Bottom
Spread-out
Noise
Instagram
Smooth
Clean
Final TPR
Intermediate
Layer
99.37
96.91
94.04
98.52
98.73
89.11
99.28
97.62
89.27
93.98
98.84
N/A
Input
Layer
93.55
85.12
74.27
96.41
89.26
68.09
93.01
67.8
85.42
0.34
0.0
N/A
Input
Layer
2.92
2.39
2.16
4.46
2.56
2.91