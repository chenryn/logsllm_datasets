authentication and system logs as applicable to provide a full view of the actions taken 
throughout the environment for use by security auditors and incident responders. 
Within the Kubernetes environment, administrators should monitor/log the following: 
 API request history 
 Performance metrics 
 Deployments 
 Resource consumption 
 Operating system calls 
 Protocols, permission changes 
 Network traffic 
Key points 
 Establish Pod baselines at creation to enable anomalous activity identification. 
 Perform logging at the host level, application level, and on the cloud if applicable. 
 Integrate existing network security tools for aggregate scans, monitoring, alerts, 
and analysis. 
 Set up local log storage to prevent loss in case of a communication failure. 
U/OO/168286-21 | PP-21-1104 | August 2021 Ver. 1.0 
23 
National 
Security 
Agency 
Cybersecurity 
and Infrastructure 
Security Agency 
Kubernetes Hardening Guidance 
National 
Security 
Agency 
 Pod scaling 
When a Pod is created or updated, administrators should capture detailed logs of the 
network communications, response times, requests, resource consumption, and any 
other relevant metrics to establish a baseline. As detailed in the previous section, 
anonymous accounts should be disabled, but logging policies should still record actions 
taken by anonymous accounts to identify anomalous activity. 
RBAC policy configurations should be audited periodically and whenever changes occur 
to the organization’s system administrators. Doing so ensures access controls are 
adjusted in compliance with the RBAC policy-hardening guidance outlined in the role-
based access control section.  
Audits should include comparisons of current logs to the baseline measurements of 
normal activities to identify significant changes in any of the logged metrics and events. 
System administrators should investigate significant changes—e.g., a change in 
application usage or installation of malicious processes such as a cryptominer—to 
determine the root cause. Audits of internal and external traffic logs should be 
conducted to ensure all intended security constraints on connections have been 
configured properly and are working as intended. 
Administrators can also use these audits as 
systems evolve to identify when external access 
may no longer be needed and can be restricted.  
Logs can be streamed to an external logging 
service to ensure availability to security 
professionals outside of the cluster, identify 
abnormalities as close to real time as possible, 
and protect logs from being deleted if a 
compromise occurs. If using this method, logs 
should be encrypted during transit with TLS 1.2 or 1.3 to ensure cyber actors cannot 
access the logs in transit and gain valuable information about the environment. Another 
precaution to take when utilizing an external log server is to configure the log forwarder 
within Kubernetes with append-only access to the external storage. This helps protect 
the externally stored logs from being deleted or overwritten from within the cluster.  
Kubernetes auditing 
capabilities are 
disabled by default, so 
if no audit policy has 
been written, nothing 
is logged. 
U/OO/168286-21 | PP-21-1104 | August 2021 Ver. 1.0 
24 
National 
Security 
Agency 
Cybersecurity 
and Infrastructure 
Security Agency 
Kubernetes Hardening Guidance 
National 
Security 
Agency 
Kubernetes native audit logging configuration  
The kube-apiserver resides on the Kubernetes control plane and acts as the front 
end, handling internal and external requests for a cluster. Each request, whether 
generated by a user, an application, or the control plane, produces an audit event at 
each stage in its execution. When an audit event registers, the kube-apiserver 
checks for an audit policy file and applicable rule. If such a rule exists, the server logs 
the event at the level defined by the first matched rule. Kubernetes’ built-in auditing 
capabilities are not enabled by default, so if no audit policy has been written, nothing is 
logged.  
Cluster administrators must write an audit policy YAML file to establish the rules and 
specify the desired audit level at which to log each type of audit event. This audit policy 
file is then passed to the kube-apiserver with the appropriate flags. For a rule to be 
considered valid, it must specify one of the four audit levels: None, Metadata, 
Request, or RequestResponse. Appendix L: Audit Policy shows the contents of an 
audit policy file that logs all events at the RequestResponse level. Appendix M: 
Example flags with which to submit Audit Policy file to kube-apiserver shows 
where the kube-apiserver configuration file is located and provides an example of 
the flags by which the audit policy file can be passed to the kube-apiserver. 
Appendix M also provides directions for how to mount the volumes and configure the 
host path if necessary. 
The kube-apiserver includes configurable logging and webhook backends for audit 
logging. The logging backend writes the audit events specified to a log file, and the 
webhook backend can be configured to send the file to an external HTTP API. The --
audit-log-path and --audit-log-maxage flags, set in the example in Appendix 
M, are two examples of the flags that can be used to configure the log backend, which 
writes audit events to a file. The log-path flag is the minimum configuration required 
to enable logging and the only configuration necessary for the logging backend. The 
default format for these log files is JSON, though this can also be changed if necessary. 
Additional configuration options for the logging backend can be found in the Kubernetes 
documentation.  
To push the audit logs to the organization’s SIEM platform, a webhook backend can be 
manually configured via a YAML file submitted to the kube-apiserver. An example 
webhook configuration file and the flags needed to pass the file to the kube-
U/OO/168286-21 | PP-21-1104 | August 2021 Ver. 1.0 
25 
National 
Security 
Agency 
Cybersecurity 
and Infrastructure 
Security Agency 
Kubernetes Hardening Guidance 
National 
Security 
Agency 
apiserver to attach the webhook backend are located in Appendix N: Webhook 
configuration. An exhaustive list of the configuration options, which can be set in the 
kube-apiserver for the webhook backend, can be found in the Kubernetes 
documentation. 
Worker node and container logging 
There are many ways for logging capabilities to be configured within a Kubernetes 
architecture. In the built-in method of log management, the kubelet on each node is 
responsible for managing logs. It stores and rotates log files locally based on its policies 
for individual file length, storage duration, and storage capacity. These logs are 
controlled by the kubelet and can be accessed from the command line. The following 
command prints the logs of a container within a Pod: 
kubectl logs [-f] [-p] POD [-c CONTAINER] 
The -f flag may be used if the logs are to be streamed, the -p flag may be used if logs 
from previous instances of a container exist and are desired, and the -c flag can be 
used to specify a container if there are more than one in the Pod. If an error occurs that 
causes a container, Pod, or node to die, the native logging solution in Kubernetes does 
not provide a method to preserve logs stored in the failed object. NSA and CISA 
recommend configuring a remote logging solution to preserve logs should a node fail. 
Options for remote logging include:  
Remote logging option 
Reason to use 
Configuration implementation 
Running a logging agent on 
every node to push logs to 
a backend 
Gives the node the ability to 
expose logs or push logs to a 
backend, preserving them outside 
of the node in the case of a 
failure. 
Configure an independent container 
in a Pod to run as a logging agent, 
giving it access to the node’s 
application log files and configuring 
it to forward logs to the 
organization’s SIEM. 
Using a sidecar container in 
each Pod to push logs to 
an output stream 
Used to push logs to separate 
output streams. This can be a 
useful option when application 
containers write multiple log files 
of different formats. 
Configure sidecar container for 
each log type and use to redirect 
these log files to their individual 
output streams, where they can be 
handled by the kubelet. The 
node-level logging agent can then 
forward these logs onto the SIEM or 
other backend. 
U/OO/168286-21 | PP-21-1104 | August 2021 Ver. 1.0 
26 
National 
Security 
Agency 
Cybersecurity 
and Infrastructure 
Security Agency 
Kubernetes Hardening Guidance 
National 
Security 
Agency 
Using a logging agent 
sidecar in each Pod to push 
logs to a backend 
When more flexibility is needed 
than the node-level logging agent 
can provide. 
Configure for each Pod to push logs 
directly to the backend. This is a 
common method for attaching third-
party logging agents and backends. 
Pushing logs directly to a 
backend from within an 
application 
Capture application logs. 
Kubernetes does not have built-in 
mechanisms for exposing or 
pushing logs to a backend 
directly. 
Organizations will need to either 
build this functionality into their 
application or attach a reputable 
third-party tool to enable this. 
A sidecar container is run in a Pod with other containers and can be configured to 
stream logs to a log file or logging backend. A sidecar container can also be configured 
to act as a traffic proxy for another standard functionality container with which it is 
packaged and deployed.  
In order to ensure continuity of these logging agents across worker nodes, it is common 
to run them as a DaemonSet. Configuring a DaemonSet for this method ensures that 
there is a copy of the logging agent on every node at all times and that any changes 
made to the logging agent are consistent across the cluster. 
Seccomp: audit mode 
In addition to the node and container logging described above, it can be highly 
beneficial to log system calls. One method for auditing container system calls in 
Kubernetes is to use the Secure Compute Mode (seccomp) tool. This tool is disabled by 
default but can be used to limit a container’s system call abilities, thereby lowering the 
kernel’s attack surface. Seccomp can also log what calls are being made by using an 
audit profile.  
A custom seccomp profile is used to define which system calls are allowed and default 
actions for calls not specified. To enable a custom seccomp profile within a Pod, 
Kubernetes admins can write their seccomp profile JSON file to the 
/var/lib/kubelet/seccomp/ directory and add a seccompProfile to the Pod’s 
securityContext. A custom seccompProfile should also include two fields: 
Type: Localhost and localhostProfile: myseccomppolicy.json. Logging 
all system calls can help administrators know what system calls are needed for 
standard operations allowing them to restrict the seccomp profile further without losing 
system functionality.  
U/OO/168286-21 | PP-21-1104 | August 2021 Ver. 1.0 
27 
National 
Security 
Agency 
Cybersecurity 
and Infrastructure 
Security Agency 
Kubernetes Hardening Guidance 
National 
Security 
Agency 
SYSLOG 
Kubernetes, by default, writes kubelet logs and container runtime logs to journald if 
the service is available. If organizations wish to utilize syslog utilities for systems that do 
not use them by default—or to collect logs from across the cluster and forward them to 
a syslog server or other log storage and aggregation platform—they can configure that 
capability manually. Syslog protocol defines a log message-formatting standard. Syslog 
messages include a header—consisting of a timestamp, hostname, application name, 
and process ID (PID)—and a message written in plaintext. Syslog services such as 
syslog-ng® and rsyslog are capable of collecting and aggregating logs from across a 
system in a unified format. Many Linux operating systems by default use rsyslog or 
journald—an event logging daemon, which optimizes log storage and output logs in 
syslog format via journalctl. The syslog utility, on nodes running certain Linux 
distributions logs events, by default, at the operating system level. Containers running 
these Linux distributions will, by default, collect logs using syslog as well. The logs that 
are collected by syslog utilities are stored in the local file system on each applicable 
node or container unless a log aggregation platform is configured to collect them.  
SIEM platforms 
Security Information and Event Management (SIEM) software collects logs from across 
an organization’s network. SIEM software brings together firewall logs, application logs, 
and more; parsing them out to provide a centralized platform from which analysts can 
monitor system security. SIEM tools have variations in their capabilities. Generally, 
these platforms provide log collection, threat detection, and alerting capabilities. Some 
include machine learning capabilities, which can better predict system behavior and 
help to reduce false alerts. Organizations using these platforms in their environment can 
integrate them with Kubernetes to better monitor and secure clusters. Open source 
platforms for managing logs from a Kubernetes environment exist as an alternative to 
SIEM platforms. 
Containerized environments have many interdependencies between nodes, Pods, 
containers, and services. In these environments, Pods and containers are constantly 
being taken down and restarted on different nodes. This presents an extra challenge for 
traditional SIEMs, which typically use IP addresses to correlate logs. Even next-gen 
SIEM platforms may not always be suited to the complex Kubernetes environment. 
However, as Kubernetes has emerged as the most widely used container orchestration 
U/OO/168286-21 | PP-21-1104 | August 2021 Ver. 1.0 
28 
National 
Security 
Agency 
Cybersecurity 
and Infrastructure 
Security Agency 
Kubernetes Hardening Guidance 
National 
Security 
Agency 
platform, many of the organizations developing SIEM tools have developed variations of 
their products specifically designed to work with the Kubernetes environment, providing 
full monitoring solutions for these containerized environments. Administrators should be 
aware of their platform’s capabilities and ensure that their logging sufficiently captures 
the environment to support future incident responses.  
Alerting 
Kubernetes does not natively support alerting; however, several monitoring tools with 
alerting capabilities are compatible with Kubernetes. If Kubernetes administrators 
choose to configure an alerting tool to work within a Kubernetes environment, there are 
several metrics for which administrators should monitor and configure alerts.  
Examples of cases that could trigger alerts include but are not limited to: 
 low disk space on any of the machines in the environment, 
 available storage space on a logging volume running low, 
 external logging service going offline, 
 a Pod or application running with root permissions, 
 requests being made by an account for resources they do not have permission 
for, 
 an anonymous account being used or gaining privileges, 
 Pod or Worker Node IP addresses being listed as the source ID of a Pod creation 
request, 
 unusual system calls or failed API calls, 
 user/admin behavior that is abnormal (i.e. at unusual times or from an unusual 
location), and 
 significant deviations from the standard operation metrics baseline. 
Alerting when storage is low can help avoid performance issues and log loss due to 
limited resources and help identify malicious cryptojacking attempts. Cases of privileged 
Pod execution can be investigated to determine if an administrator made a mistake, an 
authentic use case necessitates escalated privileges, or a malicious actor deployed a 
privileged Pod. Suspicious Pod creation source IP addresses could indicate that a 
malicious cyber actor has broken out of a container and is attempting to create a 
malicious Pod.  
U/OO/168286-21 | PP-21-1104 | August 2021 Ver. 1.0 
29 
National 
Security 
Agency 
Cybersecurity 
and Infrastructure 
Security Agency 
Kubernetes Hardening Guidance 
National 
Security 
Agency 
Integrating Kubernetes with an organization’s existing SIEM platform, especially those 
with machine learning/big data capabilities, can be useful in identifying irregularities in 
audit logs and cutting down on false alerts. If configuring such a tool to work with 
Kubernetes, it should be configured so that these cases and any others applicable to 
the use case are configured to trigger alerts. 
Systems capable of acting automatically when suspected intrusions occur could 
potentially be configured to take steps to mitigate compromises while administrators 
respond to alerts. In the case of a Pod IP being listed as the source ID of a Pod creation 
request, one mitigation that could be implemented to keep the application available but 
temporarily stop any compromises of the cluster would be to automatically evict the 
Pod. Doing so would allow a clean version of the Pod to be rescheduled onto one of the 
nodes. Investigators can then examine the logs to determine if a breach occurred and, if 
so, how the malicious actors executed the compromise so that a patch can be 
deployed.  
Service meshes 
Service meshes are platforms that streamline microservice communications within an 
application by allowing for the logic of these communications to be coded into the 
service mesh rather than within each microservice. Coding this communication logic into 
individual microservices is difficult to scale, difficult to debug as failures occur, and 
difficult to secure. Using a service mesh can simplify this for developers. The mesh can:  
 redirect traffic when a service is down, 
 gather performance metrics for optimizing communications, 
 allow management of service-to-service communication encryption, 
 collect logs for service-to-service communication,  
 collect logs from each service, and  
 help developers diagnose problems and failures of microservices or 
communication mechanisms. 
Service meshes can also help with migrating services to hybrid or multi-cloud 
environments. While service meshes are not necessary, they are an option that is highly 
suitable to the Kubernetes environment. Managed Kubernetes services often include 
their own service mesh. However, several other platforms are also available and, if 
desired, are highly customizable. Some of these include a Certificate Authority that 
generates and rotates certificates, allowing for secure TLS authentication between 
U/OO/168286-21 | PP-21-1104 | August 2021 Ver. 1.0 
30 
National 
Security 
Agency 
Cybersecurity 
and Infrastructure 
Security Agency 
Kubernetes Hardening Guidance 
National 
Security 
Agency 
services. Administrators should consider using service meshes to harden Kubernetes 
cluster security. 
Figure 5: Cluster leveraging service mesh to integrate logging with network security 
Fault tolerance 
Fault tolerance policies should be put in place to ensure logging service availability. 
These policies could differ depending on the specific Kubernetes use case. One policy 
that can be put in place is to allow new logs to overwrite the oldest log files if absolutely 
necessary in the event of storage capacity being exceeded.  
U/OO/168286-21 | PP-21-1104 | August 2021 Ver. 1.0 
31 
National 
Security 
Agency 
Cybersecurity 
and Infrastructure 
Security Agency 
Kubernetes Hardening Guidance 