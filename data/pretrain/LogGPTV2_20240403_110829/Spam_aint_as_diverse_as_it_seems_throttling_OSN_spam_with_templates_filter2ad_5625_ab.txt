edge of spam categorization (Section 2.3) as input. It only
needs the stream of raw messages, plus a small number of
labeled tweets for noise labeling as described in Section 3.4.
3.1 System Design Overview
Tangram builds template-based spam detection on top
of existing detection methods toward higher accuracy and
speed.
It generates the underlying templates of spam de-
tected by various existing methods. It then uses the tem-
plates to accurately, quickly match and detect spam. Fig-
ure 1 depicts the Tangram workﬂow. It takes a stream of
raw messages as input, and classiﬁes them as either spam or
legitimate online. After the classiﬁcation, spam is ﬁltered,
while legitimate messages pass through. Two components
can classify messages: the template matching module and
the auxiliary spam ﬁlter. The template matching module,
along with the template generation technique, is our major
contribution. The auxiliary spam ﬁlter, on the other hand,
supplies training spam messages.
It can be any deployed
spam ﬁlter, e.g., a blacklist spam ﬁlter. We further discuss
the dependence on the auxiliary spam ﬁlter in Section 5.
Template Matching and Template Generation. We
deﬁne a template to be a sequence of macros of two types,
dictionary and noise (Section 2.2). We represent a dictionary
macro as a set of values separated by “|” and a noise macro
as “.*”. Thus, templates produced by Tangram are natu-
rally encoded as regular expressions, speciﬁcally concatena-
tions of “|” clauses and “.*”s. Template matching matches a
given message against the corresponding regular expression.
A successful template match implies the tested message in-
stantiates the template, and should be ﬂagged as spam. We
deﬁne template generation as the task of inferring the tem-
plate’s regular expression representation from a set of ob-
served spam instances.
Initially the template matching module is not equipped
with any template, so all messages will pass through. How-
ever, if a message is blocked by the auxiliary spam ﬁlter, it
is treated as an instantiation of an unforeseen template, and
is saved in the spam buﬀer. Once the number of messages
in the spam buﬀer exceeds a predeﬁned window size thresh-
old t, the system invokes the template generation procedure,
and deploys the newly generated templates in the template
matching module. The system input is a mixture of spam
instantiating diﬀerent templates and spam without underly-
ing templates. This diﬀerentiates our system from previous
spam template generation work [22].
The template generation ﬁrst identiﬁes the subset of spam
messages believed to share the same template (Section 3.3).
These messages are tokenized into sequences of words. After
executing noise detection (Section 3.4), we are left with spam
content generated by dictionary macros. We divide every
message into the same number of segments. Each segment,
containing zero or more tokens, corresponds to one macro in
the template. We then construct the macro by combining
the segment’s unique strings across messages with “|”. The
concatenation of the macros for all segments constitutes the
complete template.
Inferring the number of segments and which tokens belong
to which segment are key challenges in template generation2.
We use the heuristic of preferring more compact templates
(i.e., shorter regular expressions) that match all of the in-
put spam messages without using wild cards. This heuristic
follows the traditional approach of preferring simpler de-
scriptions to more complex ones; our experiments validate
its eﬀectiveness. Furthermore, ﬁnding the shortest template
for a set of messages is an NP-hard problem (Appendix A).
We develop approximate techniques that work well in prac-
tice, as described below.
3.2 Single Campaign Template Generation
For ease of presentation, we ﬁrst introduce the approach to
generate a single template given spam instantiating the same
underlying template. It is the basis of Tangram. We use the
template generation process of the campaign in Table 1 as
a running example to elaborate our approach. We expand
the approach to generate templates on a mixture of spam
instantiating multiple templates in Section 3.3.
A strength of our approach is generating templates with-
out any invariant substring. However, we do expect that
some non-trivial subset of a campaign will share a common
substring, because the dictionary macro may instantiate to
the same textual content when multiple spam messages are
generated. This property helps us infer the correspondence
of segments between messages. For example, if we observe
the ﬁrst two messages in Table 1 from a campaign, it strongly
2Common techniques for segmenting text into chunks from
Natural Language Processing (NLP) cannot easily apply to
our segmentation task because 1) it is diﬃcult to use stan-
dard NLP tools on OSN text [23] and 2) our segments often
do not correspond to typical NLP segments such as noun
phrases.
indicates that “Big Name A” and “Celebrity B” are two in-
stantiations of the same macro. This indication holds for the
campaign even if some messages do not have the substring
“an eye-catching action -”.
We systematically exploit such substrings shared by sub-
sets of a campaign in three steps, common supersequence
computation, column concatenation, and regular expression
representation.
Common Supersequence Computation. The ﬁrst
step is to compute the messages’ common supersequence.
Shortest common supersequence is an NP-hard problem (Ap-
pendix A). We use an approximation algorithm named
Majority-Merge [10] because of its simplicity.
It takes n
sequences as input, and initializes the supersequence, s, as
an empty string. Next, it iteratively chooses the majority
of the leftmost tokens of the input sequences, denoted as a,
and appends a to s. Meanwhile, the leftmost a are deleted
from the input sequences. It repeats this step until all se-
quences are empty, and outputs s. Each token in the output
supersequence is trivially a substring shared by some sub-
set of the campaign. Desirable substrings are i) shared by
large subsets and ii) long. We achieve goal i) by producing
a shorter supersequence.
We build a matrix during the execution of Majority-Merge
algorithm. Table 3 shows an excerpt (due to page width
limit) of such a table for the example campaign. The header
row is the supersequence output by the Majority-Merge al-
gorithm. The rest of the rows represent the input sequences,
one row for each sequence. We label the jth column using
the token that is chosen in the jth step of the Majority-
Merge algorithm. The cell at row i, column j will be as-
signed the column label if the ith sequence is picked in step
j. Otherwise it will be an empty string, ε. Naturally, the
concatenation of each row is exactly the corresponding in-
put sequence. We denote this property as the supersequence
property.
To produce a shorter supersequence, we need to merge
columns that shares the same label, while maintaining the
supersequence property. After merging, the cell will be as-
signed the column label if either cell before merging has
been assigned so. Without loss of generality, we state the
three suﬃcient conditions that determine whether column k
can be merged into column j without aﬀecting the super-
sequence property (Appendix B). Note that the merging is
directional, after which column j is kept while column k is
deleted. Condition i) column j and column k have identical
label; Condition ii) in any row at least one column is ε; and
Condition iii) if the cell at row i, column k is not ε, all
cells in row i, between column j and column k must be ε.
Table 4 excerpts the column merging result. Noticeably, the
repeated columns of “oﬀensive content, look at this video”
is gone after the merging, yielding a more compact matrix
representation.
Column Concatenation. To achieve goal ii) for ob-
taining long substrings shared by subsets of campaigns, we
further concatenate the matrix columns obtained from the
previous step. Column concatenation also operates on a col-
umn pair, after which each cell becomes the concatenation of
the two corresponding cells. Diﬀerent from column merging,
column concatenation does not require the target columns
to share identical label. It only requires that the value of
the corresponding, non-ε cells in the two columns has 1-1
mapping. For example, the ﬁrst two columns in Table 4 are
Big Name A Celebrity B an
Big Name A
an
Celebrity B an
ε
Big Name A
ε
ε
ε
ε
ε
ε
ε
ε
ε
ε
ε
Celebrity B
ε
ε
ε
ε
ε
ε
eye-catching
eye-catching
eye-catching
action
action
action
oﬀensive
content
ε
ε
ε
ε
ε
ε
ε
ε
ε
ε
oﬀensive
oﬀensive
ε
content
content
ε
,
ε
ε
,
,
ε
look
ε
ε
look
look
ε
at
ε
ε
at
at
ε
this
ε
ε
this
this
ε
ε
ε
ε
video U RL ...
...
...
video U RL ...
video U RL ...
...
ε
ε
ε
Table 3: Excerpt of the initial matrix built by the common supersequence computation process. The header
row is the computed supersequence. Each remaining row corresponds to one input sentence.
Big Name A Celebrity B an
Big Name A
an
ε Celebrity B an
ε
Big Name A
ε
ε
ε
ε
ε
ε
ε Celebrity B
ε
ε
ε
ε
ε
ε
ε
ε
ε
eye-catching
eye-catching
eye-catching
action
action
action
ε
ε
ε
ε
ε
ε
ε
ε
ε
ε
- RIP Celeb C ...
...
-
...
-
...
ε
...
ε
ε RIP Celeb C ...
ε
ε
ε
ε
ε
ε
ε
ε
Table 4: Excerpt of the intermediate matrix after the matrix column reduction step. The header row is a
shorter supersequence.
concatenated because “Big” always maps to “Name”, but the
5th and the 6th columns in Table 4 cannot be concatenated
because “B” maps to two values, “an” and ε.
The eﬀect of column concatenation is two-fold. First,
it moves multiple tokens into one cell, which helps reveal
the true template by assembling tokens (words) into word
phrases. For example, the three separate columns “Big”,
“Name”, and “A” in Table 4 become one celebrity name.
Second, the cells on the same column after column concate-
nation may have diﬀerent contents. This maps to the dictio-
nary macro case, where diﬀerent cell contents are diﬀerent
instantiation of the dictionary macro.
Regular Expression Representation converts the ma-
trix into a regular expression to represent the generated tem-
plate. We initialize the regular expression representation to
be an empty string, s. Then we iterate through each col-
umn. If all the cells in the column share an identical value,
we append the value to s. Otherwise, we make a “|” clause
by concatenating all the unique values with “|”, and append
the clause to s. The generated regular expression representa-
tion from Table 4 is ˆ(Big Name A | Celebrity B | RIP Celeb
C) (oﬀensive content , look at this video | an eye-catching
content - ) URL$, where “ˆ” and “$” respectively mark the
beginning and the ending of a message. The output regu-
lar expression matches all input sequences that build this
matrix.
3.3 Multi-campaign Template Generation
We now expand single campaign template generation to
multi-campaign template generation over spam instantiating
diﬀerent templates or even without underlying templates.
An intuitive solution is to ﬁrst separate the spam into dis-
tinct campaigns automatically, then invoke the single cam-
paign template generation procedure on each one of them.
We use a clustering and reﬁning approach to this task.
We ﬁrst use single-linkage clustering to group messages
that share at least k consecutive identical tokens, k being a
system parameter. The goal is to put semantically similar
messages in the same cluster, while separating semantically
diﬀerent messages into diﬀerent clusters. The transitive clo-
sure of these links forms our initial clustering. This clus-
tering does not require every message pair in the cluster to
share an invariant substring. We use a small training set of
collected spam tweets to choose the value of k experimen-
tally, before applying the system on the much larger dataset.
The value of k is not sensitive to the training set size. For ex-
ample, we test with size 10,000, 5,000 and 2,000 and obtain
consistent results. With a training set of size 10,000, a loose
threshold (e.g., k = 3) results in a big cluster containing
42% of the spam, while spam messages in this cluster have
diﬀerent semantic meanings like Lady Gaga, Apple product
and so on. A tight threshold (e.g., k >= 5) results in a large
number of small clusters, where multiple clusters share the
same semantic meaning. For example, 9 out of the 20 largest
clusters in the experiment should be merged. In comparison,
k = 4 produces the best result in our experiments.
We then reﬁne the clusters using the single campaign tem-