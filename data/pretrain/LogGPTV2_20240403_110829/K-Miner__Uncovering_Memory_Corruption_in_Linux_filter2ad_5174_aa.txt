title:K-Miner: Uncovering Memory Corruption in Linux
author:David Gens and
Simon Schmitt and
Lucas Davi and
Ahmad-Reza Sadeghi
K-Miner: Uncovering Memory Corruption in Linux
David Gens,∗ Simon Schmitt,∗ Lucas Davi,† Ahmad-Reza Sadeghi∗
∗CYSEC/Technische Universit¨at Darmstadt, Germany.
{david.gens,simon.schmitt,ahmad.sadeghi}@trust.tu-darmstadt.de
†University of Duisburg-Essen, Germany. PI:EMAIL
Abstract—Operating system kernels are appealing attack tar-
gets: compromising the kernel usually allows attackers to bypass
all deployed security mechanisms and take control over the
entire system. Commodity kernels, like Linux, are written in
low-level programming languages that offer only limited type
and memory-safety guarantees, enabling adversaries to launch
sophisticated run-time attacks against the kernel by exploiting
memory-corruption vulnerabilities.
Many defenses have been proposed to protect operating
systems at run time, such as control-ﬂow integrity (CFI). However,
the goal of these run-time monitors is to prevent exploitation as
a symptom of memory corruption, rather than eliminating the
underlying root cause, i.e., bugs in the kernel code. While ﬁnding
bugs can be automated, e.g., using static analysis, all existing
approaches are limited to local, intra-procedural checks, and face
severe scalability challenges due to the large kernel code base.
Consequently, there currently exist no tools for conducting global
static analysis of operating system kernels.
In this paper, we present K-Miner, a new framework to
efﬁciently analyze large, commodity operating system kernels
like Linux. Our novel approach exploits the highly standard-
ized interface structure of the kernel code to enable scalable
pointer analysis and conduct global, context-sensitive analysis.
Through our inter-procedural analysis we show that K-Miner
systematically and reliably uncovers several different classes of
memory-corruption vulnerabilities, such as dangling pointers,
user-after-free, double-free, and double-lock vulnerabilities. We
thoroughly evaluate our extensible analysis framework, which
leverages the popular and widely used LLVM compiler suite, for
the current Linux kernel and demonstrate its effectiveness by
reporting several memory-corruption vulnerabilities.
I.
INTRODUCTION
Operating system kernels form the foundation of practically
all modern software platforms. The kernel features many
important services and provides the interfaces towards user
applications. It
is usually isolated from these applications
through hardware mechanisms such as memory protection and
different privilege levels in the processor. However, memory-
corruption vulnerabilities in the kernel code open up the
possibility for unprivileged users to subvert control ﬂow or
data structures and take control over the entire system [32],
[70], [72], [47]. For this reason, many defenses have been
Network  and  Distributed  Systems  Security  (NDSS)  Symposium  2018 
18-21  February  2018,  San  Diego,  CA,  USA
ISBN  1-891562-49-5
http://dx.doi.org/10.14722/ndss.2018.23326
www.ndss-symposium.org
proposed in the past [25], [37], [49], [16], [57], [5], [23],
[63], [20]. These defenses are designed speciﬁcally for run-
time protection of operating system kernels. Their goal is to
provide countermeasures and secure the kernel against attacks
exploiting memory corruption. Most of these approaches can
be loosely categorized as run-time monitors [49], [16], [57],
[5], [23], [63], [19].
Run-time Monitors vs. Compile-time Veriﬁcation.
Typically, adversaries are modeled according to their capa-
bilities, and reference monitors are then designed to defend
against a speciﬁc class of attacks. For instance, control-
ﬂow integrity (CFI) is tailored towards control-ﬂow hijacking
attacks. However, CFI is not designed to protect against data-
only adversaries resulting in a protection gap that allows for
crucial attacks despite the presence of run-time monitors,
such as CFI, in the kernel [11], [32], [70], [20]. Thus, a
combination of many different defenses is required to protect
the kernel against multiple classes of adversaries. Conse-
quently, commodity operating systems will remain vulnerable
to new types of software attacks as long as memory-corruption
vulnerabilities are present in the code [60].
An alternative approach to employing run-time monitors is
to ensure the absence of memory-corruption vulnerabilities by
analyzing the system before deployment. This was shown to be
feasible for small microkernels with less than 10,000 lines of
code [6], [44], [64], by building a formal model of the entire
kernel and (manually) proving the correctness of the imple-
mentation with respect to this model. The invariants that hold
for the formal model then also hold for the implementation.
However, the formal correctness approach is impractical for
commodity monolithic kernels due to their size and extensive
use of machine-level code [43], which provides no safety
guarantees. Even for small microkernels formulating such a
model and proving its correctness requires more than 10 person
years of work [44], [6]. While dynamic analyses are used to
detect vulnerabilities in OS kernels rather successfully [34],
[35], [22], static approaches have a major advantage: sound
static analysis safely over-approximates program execution,
allowing for strong statements in the case of negative analysis
results. In particular, if no report is generated for a certain
code path by a sound analysis, one can assert that no memory-
corruption vulnerability is present. Hence, static analysis is
also a practical and pragmatic alternative to formal veriﬁcation,
as it is able to offer similar assurances for real-world software
by means of automated compile-time checks [15].
Static analysis of commodity kernels.
However, static analysis faces severe scalability challenges,
and hence, all analysis frameworks for kernel code are limited
to intra-procedural analysis, i.e., local checks per function.
In particular, there are ﬁve popular analysis frameworks tar-
geting Linux: Coccinelle [52], Smatch [9], TypeChef [38],
APISAN [74], and EBA [1]. None of these support inter-
procedural data-ﬂow analyses, which are required to conser-
vatively approximate program behavior, and reliably uncover
memory corruption caused by global pointer relationships. The
main reason why precise data-ﬂow analysis for kernel code
represents a huge challenge for all existing approaches, is
the huge size and complexity of its monolithic code base:
currently, Linux comprises over 24 million lines of code [14].
Just compiling a common distribution kernel takes several
hours, even on top-of-the-line hardware. While some of the
existing tools allow for the static analysis of kernel code, these
are conceptually limited to local intra-procedural (i.e., per-
function) or simple ﬁle-based analysis. This limitation is due to
the fact that the number of possible paths grows exponentially
with the code size, and hence, static analysis approaches face
severe scalability problems [29], [28], [65]. At the same time,
analysis methods have to take all paths and states into account
to remain sound, and hence, pruning or skipping certain parts
of the code would lead to unreliable results. This is why
the resource requirements for conducting such analyses in the
Linux kernel quickly outgrows any realistic thresholds. As a
result, global and inter-procedural analyses, which are required
to uncover memory corruption reliably, remain out of reach of
these existing approaches.
Goals and Contribution.
In this paper, we propose to exploit a distinct and unique
property of kernel software: its interface to user space is highly
standardized [33]. Our idea is to partition the kernel code
along separate execution paths using the system call interface
as a starting point. We show that this signiﬁcantly reduces
the number of relevant paths, allowing us to conduct even
complex, inter-procedural data-ﬂow analysis in the kernel. To
this end, we present the design and implementation of K-
Miner, the ﬁrst static analysis framework that enables complex
data-ﬂow analysis for Linux to reliably detect vulnerabilities
in kernel code.
Partitioning the kernel code comes with a number of
challenges, such as the frequent reuse of global data structures,
the synchronization between the per-system call and global
memory states (contexts), and complicated and deeply nested
aliasing relationships of pointers. As we will show, our frame-
work tackles all of these challenges, providing a number of
different analysis passes that analyze system calls simultane-
ously, and reporting a number of real-world vulnerabilities.
Further, scalable static analysis designed for user space
programs cannot simply be applied in kernel setting: data-
ﬂow analysis expects an initial state from which analysis
passes propagate value ﬂows, which is naturally satisﬁed by
a program’s main function in user space. K-Miner is tailored
towards this requirement and enables data-ﬂow analysis in the
kernel setting.
To summarize our contributions are as follows:
• Enable global static analysis for kernel code: we present
K-Miner, a novel approach to conduct global static analyses
of the Linux kernel. Our framework allows to systematically
analyze the kernel’s user-space interface and detect possible
memory corruption. To enable precise inter-procedural static
analysis of modern OS kernels we tackle a number of
challenges, such as dealing with the large code base, com-
plex inter-dependencies, and aliasing relationships between
global kernel pointers and memory objects.
• Prototype framework implementation: we provide mul-
tiple analyses for ﬁnding classes of vulnerabilities in the
Linux kernel that are typically exploited, and demonstrate
their effectiveness in analyzing many different kernel ver-
sions, using different conﬁgurations. Our presented frame-
work is extensible and adding additional analysis passes is
straightforward. K-Miner includes a web-based user inter-
face to ease reporting and collaboration. It also provides
extensive graph-based analysis overviews and statistics on
the number of alerts and performance. We release our
implementation of K-Miner as an open source project [24]
that is built on top of LLVM [46].
• Extensive evaluation: we rigorously evaluate our static
analysis framework implemenation for the Linux kernel
by applying it to all system calls across many different
Linux versions and highlight the effectiveness of our frame-
work through detailed reports and statistics. We demon-
strate the importance of automated and scalable analysis
of commodity kernel code by reliably uncovering several
known memory-corruption vulnerabilities, which previously
required manual
inspection of the code, and were used
to conduct real-world kernel exploits against dissidents
and activists [50], [62]. Using K-Miner these bug classes
can now be found automatically through our precise and
reliable static analysis passes. We reported two use-after-
return vulnerabilities that K-Miner uncovered in the kernel.
II. BACKGROUND
In this section we explain the concepts behind static data-
ﬂow analysis and present a classiﬁcation of memory-corruption
vulnerabilities.
A. Data-Flow Analysis
The general idea of static analysis is to take a program and
a list of pre-compiled properties as input, and ﬁnd all the paths
for which a given property is true. Examples of such properties
are liveness analysis, dead-code analysis, typestate analysis,
or nullness analysis [41]. For instance, a nullness analysis for
the program a) in Figure 1 could be answered by looking at
its pointer-assignment graph (PAG) depicted in c): since there
is a path in which variable b is assigned a NULL value (b
points to NULL in the PAG) a report will be issued. Another
commonly used data structure is the inter-procedural control-
ﬂow graph (ICFG) in b) — limited to the procedures main
and f for brevity — which propagates control ﬂow globally.
This can be used to conduct path-sensitive analysis. Finally,
taint and source-sink analysis may track individual memory
objects through their associated value-ﬂow graph (VFG) in d).
Static analysis for tracking individual values in a program is
called data-ﬂow analysis. Most data-ﬂow analysis approaches
follow a general concept, or framework, to analyze programs
systematically. The naive approach is to enumerate all possible
program paths and test each graph for a given property. This
is commonly referred to as the Meet Over all Paths (MOP).
In Figure 1,
the MOP would be calculated by testing a
2
Figure 1: Data-ﬂow analyses utilize graphs to reason about program behavior at compile time.
property against the two alternative program paths p1 and p2.
Unfortunately, in the general case the MOP solution was shown
to be undecidable by reduction to the post correspondence
problem [36].
However, the MOP can be approximated through a so-
called Monotone Framework, which is a set of mathematically
deﬁned objects and rules to analyze program behavior. At the
heart of the monotone framework is a lattice, i.e., a partial
order with a unique least upper bound that must be deﬁned over
the domain of all possible values during program execution.
Further, the analysis framework must specify monotone ﬂow
functions that deﬁne how program statements effect lattice
elements (the monotony requirement ensures termination of
the analysis). Finally, sets of domain elements (i.e., values)
must be combined using a merge operator. A commonly
used deﬁnition for points-to analysis is the domain of points-
to sets for all pointers in a program. The ﬂow functions
then select all program statements, which potentially modify
any pointer relations and specify their target transitions in
the lattice. The merge operator deﬁnes how to combine the
resulting points-to sets for such a transition. The notion of the
monotone framework is signiﬁcant for static program analysis:
for any monotone framework, there exists a Maximum Fixed
Point (MFP) solution, which safely approximates the MOP
solution [36]. If the ﬂow functions are distributive under the
merge operator that is deﬁned by the lattice, the MFP solution
is identical to the MOP solution. The montone framework is
then called a distributive framework, and data-ﬂow analysis
problems can be solved efﬁciently by solving a corresponding
graph reachability problem [54].
B. Memory-corruption vulnerabilities
Memory-corruption vulnerabilities represent a vast num-
ber of security relevant bugs for operating system software
(e.g., [12], [10]). Run-time attacks exploit such bugs to inject
malicious code, reuse existing code with a malicious input,
or corrupt integral data structures to obtain higher privileges.
Memory-corruption vulnerabilities are often classiﬁed accord-
ing to their root defect:
integer overﬂows (IO), use-after-
free (UAF), dangling pointers (DP), double free (DF), buffer
overﬂow (BO), missing pointer checks (MPC), uninitialized
data (UD), type errors (TE), or synchronization errors (SE) are
commonly listed classes of memory corruption [11], [60]. Any
instance of memory corruption leaves the program vulnerable
to run-time attacks: each class represents a violation of well-
deﬁned program behavior as speciﬁed by the programming-
language standard or the compiler, and hence, the violating
program can exhibit arbitrary behavior at run time. For this
reason an adversary with knowledge about any such vulner-
ability can exploit the program by deliberately triggering the
error to achieve unintended, malicious behavior.
For an operating system, the main interface which exposes
kernel code to a user space adversary are system calls [61].
In our approach we combine different data-ﬂow analysis
passes for the classes listed above to report potential bugs in
kernel code, which are accessible to a user space program
through the system call interface. Since memory-corruption
vulnerabilities account for many real-world exploits [60], we
focus on reporting instances of dangling pointers (DP), user-
after-free (UAF), and double free (DF) in our proof-of-concept
implementation. For instance, dangling-pointer vulnerabilities
occur when a memory address is assigned to a pointer vari-
able, and the memory belonging to that address subsequently
becomes unavailable, or invalid. For heap allocations this can
happen, e.g., when a memory location is freed but the pointer
is still accessible. For stack-based allocations this happens
when the stack frame containing the allocated object becomes