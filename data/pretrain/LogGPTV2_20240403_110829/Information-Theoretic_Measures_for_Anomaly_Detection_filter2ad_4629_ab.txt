we include more informanon, we not only increase the data 
processing  time, we often increase the model complexities 
as  well  Therefore,  there  needs  to  be  a  trade-off  between 
detection  performance and  cost.  For example,  the  simple 
measure Accuracy/Cost may  be used to determine the “op- 
timal” amount of information to he used in the model. 
2.6  Application in Anomaly Detection 
The information-theoretic measures we define here can 
be used for anomaly detection in  the following general ap- 
proach: 
0  Measure regularity of audit data and perform appropri- 
ate data transformation. Iterate this step if necessary so 
that the dataset used for modeling has high regularity. 
Determine how  the  model  should  be  built,  i.e.,  how 
to achieve the best performance or the optimal perfor- 
mancekost trade-off, according to the regularity mea- 
sure. 
0  Use relative entropy to determine whether a model is 
suitable  for a new dataset  (e.g.,  from a  new  environ- 
ment). 
In Section 3, we present several case studies to illustrate 
this approach in details. 
3  Case Studies 
In this section, we describe our experiments on the Uni- 
versity  of New Mexico (UNM) sendmaif system call data, 
MIT Lincoln Lab (DARPA Evaluation) sendmail BSM data, 
and  MIT Lincoln  Lab  tcpdump  data to  show  how  to  use 
the  information-theoretic measures defined earlier to build 
anomaly detection models. These case studies are presented 
in the order of simpler to more complex in terms of the au- 
dit data used. With UNM system call’ data, we. demonstrate 
how  to use  conditional entropy to determine the appropri- 
ate length used for sequencing the system calls to construct 
anomaly detection models. With Lincoln Lab BSM data, we 
show how to use conditional entropy to determine whether 
including additional  information, e.g., obname, will  likely 
to improve detection performance.  With Lincoln  Lab tcp- 
dump data, we show how to use entropy to partition network 
data into more regular subsets, and how  to use conditional 
entropy to determine the  time  window size by  which tem- 
poral and statistical features can be computed and included 
in anomaly dktection: models:. 
3.1  UNM sendmail System Call, Data 
In a. ground.-bseal;rijlg:stud~,, Fixrest et ali. 16.4’ discovered 
that the short sequences of’(consecutive) system calls made 
by  a program during its normal executions are very consis- 
tent. More importantly, the sequences are different from the 
sequences of its abnormal (exploited) executions as well as 
the executions of other programs. Therefore, a very concise 
database containing these normal sequences can be used as 
the  “self” definition  of  the  normal  behavior  of a  program 
and as the basis  to detect anomalies.  A  number of follow- 
on studies, for example,  [S, 7, 16, 29, 301, attempted alter- 
native models,  e.g., variable-length  patterns,  classification 
rules, Neural Nets, Hidden Markov Model, etc., instead of 
the original simplistic model of database look-up of fixed- 
length sequences. These alternative and more sophisticated 
models do not  have significant  performance improvement 
over the original model. It is thus believed that the sendmail 
system call data is highly regular and hence a simple model 
would suffice.  However, we have seen no attempt to study 
how  to measure the  regularity  and  exploit it  in the  model 
building  process.  Most  noticeably,  the  original  study  by 
133 
i 
0.6 
0.4 
O '
I
-8 bounce.int 
--c  queue im 
4 sandmall.int 
-A-  mean 
(a) Conditional entropy of training data. 
0 
(b) Misclassification rate of training data. 
0 
(d) Misclassification rate of testing data. 
1 
0. a3 
O 
(0 Real and estimated accuracykost trade-off. 
0 
(e)  Relative  conditional entropy  between  training  and  testing 
normal data. 
Figure 1. Results on UNM sendnzail data. 
134 
Forrest et al.  did not suggest a means to determine the ap- 
propriate sequence length, rather, an ad hoc trial-and-error 
approach was used.  The follow-on studies simply used the 
sequence length given by Forrest et al. 
.In this case study, we did not attempt to suggest yet an- 
other model.  Rather,  we  studied  how  to measure the data 
regularity and use  it to determine the sequence length, i.e., 
how should the model be built, and explain the performance 
of the anomaly detection model, i.e., why  it works. We ob- 
tained a set of sendmail system call traces from UNM. The 
iletails  of  the  data  gathering  process,  experiments  on  the 
data, and results are in  161.  Each trace contains the (entire 
sequence(s) of)  consecutive system calls made by  the run- 
time ,process(es). Using a sliding window of  size n, we can 
process a system call trace into a set of length-n sequences. 
This set is used as our dataset, i.e., each sequence is a data 
point. We can then compute the conditional entropy, a mea- 
sure of regulatory, of  the dataset.  Let X  represent  the set 
of length-n  sequences, and Y  be the set of (prefix) subse- 
quences of the length n-1, the conditional entropy H ( X ( Y )  
then  measures  the  regularity  of  how  the first  n-1  system 
calls determines the nth  system  call.  In  more details, for 
each unique x E X ,  1x1 is the number of occurrences of 2 
in X;and  y(x) is the length n-1 subsequence of x (i.e., if 
z = (sIs:!. . . sn-lsn), then y(x) = (sls:!. . .sn-:!sn-1)), 
then H ( X I Y )  = CIEX /$, log w. 
Figure  1 (a) shows the conditional entropy for each nor- 
mal .trace type  when  sequence  length  varies  from 3 to  19 
with  an  increment  of  I .   Each  type  here  (e.g.,  “plus.int”, 
“queue.int”,  etc.)  represents a particular  kind  (or configu- 
ration) of normal sendmail runs [6], hence we model each 
type separately. For each normal trace type, we used the first 
80% traces as the training data and the last 20% as part of 
the testing data.  We also put all traces of all types together 
to form the “total” dataset and compute a model. “mean” is 
simply the average of the results from all traces. We can see 
that conditional entropy drops as sequence length increases, 
intuitively, because  the  more  information  is  included,  the 
more deterministic (i.g., regular) the dataset becomes.  We 
can  also  see that  conditional entropy  drops to  very  small 
values after sequence length reaches 6 or 7  (Forrest  et al. 
used length 6 in their original study). 
The  small  conditional  entropy  values  suggest  that  for 
sendmaif system  call  data,  the  nth  system  call  is  highly 
deterministic given  the  first  n- 1  system calls.  According 
to the  discussion  in  Section  2.4, we  can  build  a classifier 
where  the  first  n-1  system  calls  are  the  features  and  the 
nth system call  is  the class.  We  can  expect  this anomaly 
detection  model  to have good detection performance.  We 
applied  RIPPER  [3],  a  (typical) classification  rule  induc- 
tion  program,  to  the  training  data to  compute a  classifier 
and’then tested  it  on the testing  data and  intrusion traces. 
To verify the direct connection between conditional entropy 
and detection  performance (see Section  2.4),  we  built the 
classifiers using n from 3 to 19. 
Figure  l(b)  shows the misclassification  rate on  training 
data.  Figure  l(c) shows the comparison of  misclassifica- 
tion rate on the training data and conditional entropy when 
the values are all scaled into  1 to 2 range.  A misclassifica- 
tion is the situation where the classifier predicts an item to 
be in  class i  while  the  actual  class  is j .  Misclassification 
rate  is  computed as  the  percentage  of  misclassification  in 
the whole dataset.  Since the  classifier here  specifies what 
is normally  the nth system  call (given the first  n-1 system 
calls), when it is tested on normal data the misclassification 
rate should be as low as possible, and when it is tested on 
intrusion data the misclassification rate should be as high as 
possible.  That is, we can use misclassification rate to mea- 
sure anomaly detection performance. We see in Figure  1 (c) 
that, for normal data, the trend of misclassification rate co- 
incides with the trend of  conditional entropy.  This is what 
we expected according to the discussion in Section 2.4. Be- 
cause of this phenomenon, we can use the conditional en- 
tropy  plot, which can be considered as the estimated trend 
of misclassification rate, to select a sequence length for the 
detection model.  For example, if  detection performance is 
all we care about, then we know that length 6 is better than 
4, and  14 is better than 6. 
Figure  l(d) shows the  misclassification  rate  on  testing 
data, which includes 20% of the normal traces of each type 
and  all  the  intrusion  traces  (i.e.,  “sm- 10763.int”,  “syslog- 
local- 1 .int”, and the  “fwd-loops” traces).  We  can  see that 
the misclassification rates for the intrusion traces are much 
higher.  In  fact, beyond sequence length 6, they  are in dif- 
ferent ranges.  This suggests that we  can  use  the range of 
the misclassification rate as the indicator of whether a given 
trace is normal or abnormal (intrusion). That is, in practice, 
the IDS reports an anomaly only when the misclassification 
rate  (for the  whole  trace)  is  high,  not  when a system  call 
is misclassified.  Figure  1 (e) shows the relative conditional 
entropy between  training and testing normal data.  We  can 
see that  when the  relative entropy  is  larger, i.e., when  the 
training  and testing  normal  datasets differs more (see dis- 
cussion  in  Section  2.3), then  the  misclassification  rate  on 
testing  normal  data is also higher.  This phenomenon sug- 
gests that we should use relative conditional entropy (or rel- 
ative entropy) between  the  training  and the  testing  sets to 
either understand why the detection performance is satisfac- 
tory or discover that the testing set has different regularity 
and hence the model is not suitable. 
From Figures  l(b) and  l(d), we can  see that the longer 
the sequence length, the better  the detection performance. 
However, as discussed  in Section 2.5,  we need to consider 
information cost. We define information cost as the average 
time required for processing  an  audit record  and checking 
against the detection model. The results from our time mea- 
135 
surement experiments verified the paper-and-pencil  analy- 
sis that the cost is a linear function of the sequence length. 
That is, we can estimate the cost, without building and run- 
ning  a model, if  we know the data and the algorithm used 
in the model. Suppose we wish to select a sequence length 
to build a model that has the optimal accuracy per cost unit. 
We can first estimate accuracy as one minus conditional en- 
tropy because we have established  that conditional entropy 
agrees  with  misclassification  rate, and  accuracy  is simply 
one minus  misclassification  rate.  We  can  then  study  the 
ratio  between  estimated accuracy  and cost for a given  se- 
quence length.  Figure  I(f)  shows the  ratios  between  real 
and estimated  accuracy  and  cost.  The plots on  estimated 
accuracykost versus sequence length match the trend of the 
real  accuracykost, and can thus be used  to select  the best 
sequence length  if  we want to optimize accuracy  per cost 
unit. 
3.2  MIT Lincoln Lab sendmaif BSM Data 
The  UNM  sendniail  data  only  contains  system  call 
names.  An  interesting question  in  building  anomaly  de- 
tection  for sendmaif (or  other programs) is  whether  there 
can be detection  performance gain by  including  additional 
information,  i.e., arguments, object names,  etc.  Here  we 
studied whether we can use the regularity of data to find the 
answer  instead  of  the  expensive  trial-and-error  process of 
building and testing many models. 
We used the BSM data developed and distributed by MIT 
Lincoln Lab for the  1999 DARPA evaluation in our exper- 
iments.  We  processed  a  week’s  BSM  data and  extracted 
audit  records  of  all  sendniail  sessions.  Each audit record 
corresponds to a system call made by sendmail. In addition 
to system call name, each audit record  contains additional 
information such as the (real and effective) user and group 
IDS, the obname (i.e., the name of the object accessed by the 
system call), and arguments, etc.  That is, a setidmail  BSM 
trace from a session is (, , 
. . . , ), instead of (SI,  ~ 2 ,
. . , sl). Here, si, 
.
oi. and ai represent  a system call name, obname, and argu- 
ment, respectively. 
From  the experiments on UNM data, we know  that  for 
sendmail,  conditional entropy  directly  influences  the  de- 
tection  performance.  Thus,  to  find  out  whether  includ- 
ing  additional  information  will  help  improve  the  detec- 
tion  performance, we just  need  to  test  whether  it  results 
in  smaller  conditional entropy.  We  tested  two alternative 
methods  of  including  obname. 
In  the  first,  denoted  as 
so, the trace  now  becomes  (SI-01, s2-02,  . . . , sl-01).  That 
is,  obnames  are  simply  appended  to  system  call  names. 
In  the  second,  denoted  as  s-0, the  trace  now  becomes 
(sl, ol, ~ 2 , 0 1 2 , .  . . , S L ,  00. That is, obnames are treated  as 
equally important as system call names in the sequence. We 
also changed the value of an obname to either “system” (in- 
dicating that the object is in a system directory), “user” (in- 
dicating that the object is in a user’s directory), or “other”. 
This transformation  is necessary because if  we use the full 
obname, which  is often  the name of  a temporary  file in  a 
system or user directory, the data will be very irregular. 
In our experiments, we used the first 80% of all the send- 
mail traces for computing conditional  entropy and training 
classifiers, and the remaining  20% for testing.  Since there 
are two directions in sendmail runs, i.e., in-bound and out- 
bound, we used the data from the two directions in separate 
experiments.  There is  no  exploit  against  sendmail in  the 
data, thus, we only compare the detection models on normal 
testing data.  In Figure 2, the legends “s-in/out” denote sys- 
tem call only data, “so-idout” refer to datasets with system 
call  combined with  obname in  so  mode, and  “s-o-idout” 
denote data sets with system call followed by obname in s- 
o mode.  A “80’ appendix refers to training  datasets and a 
“20” refers to testing datasets. 
From Figure 2(a), we can  see that  conditional entropy 
decreases as the sequence length increases, as in the case of 
UNM data.  In addition, datasets with system call only have 
slightly larger conditional entropy than those with added ob- 
name, and that s-o datasets have slightly smaller conditional 
entropy  than  so  datasets.  Figures 2(b) and  2(c) show that 
detection models computed using datasets with added oh- 
name have slightly  lower misclassification  rate (hence bet- 
ter detection  performance) and that detection models from 
s-o datasets  slightly  outperform models  from so  datasets. 
This again confirms that there is direct connection between 
conditional entropy and detection performance. Comparing 
Figures 2(b) and 2(c), we can see that for in-bound mails the 
testing data have clearly higher misclassification rates than 
the training data, whereas out-bound mails do not have such 
phenomenon. Figure 2(d) shows the relative conditional en- 
tropy between training and testing datasets. We can see that 
out-bound mails have much smaller relative conditional en- 
tropy than in-bound mails. This again confirms that relative 
conditional entropy  is indicative of  detection  performance 
on test data sets. 
We computed information cost in the same way as in the 
experiments on UNM  data (that  is, the cost here  is  also  a 
linear  function of  sequence length n  where  the  sequence 
contains both  system  call  names and  obnames).  The esti- 
mated accuracy/cost  plots in Figure 2(f) match the trend of 
the real accuracykost plots  in Figure 2(e), and can thus be 
used  to  select not only the best  sequence length for a par- 
ticular kind of model  but also the best model  overall.  The 
plots suggest that although including the additional obname 
has shown to improve the detection performance, when the 
trade-off of accuracykost is considered, it is actually better 
to use system call name only. 
136 
30 
25 
20 
15 
10 
I
20 
l
5 
2 
4 
I
'2 
I
4 
I
6 