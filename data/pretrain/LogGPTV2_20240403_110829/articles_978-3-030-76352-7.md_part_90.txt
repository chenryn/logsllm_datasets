several times during this exercise. We use these accumulated results to produce
a histogram similar to Fig.3.
We use the Wasserstein2 distance to assess the similarity between this his-
togram and the one from Fig.3, making the reasonable assumption that the
values of the produced histogram are derived from the real one by small and
non-uniform perturbations.
We have no reason to believe that the drawing is done every day instead of
every 2 days or 3 days or more. We thus repeat the process with other window
sizes s (2 to 10), but we proceed with a drawing with replacement. We impose
an additional constraint though. A given value cannot be drawn more than s
times,i.e., onceperday.Onceavaluehasbeendrawnstimes,itisnotreplaced
in the pool anymore.
2 Thisdistanceisknownastheearthmover’sdistance,sinceitcanbeseenasthemin-
imum amount of “work” required to transform one histogram into another, where
“work”ismeasuredastheamountofdistributionweightthatmustbemoved,mul-
tiplied by the distance it has to be moved [11].
604 E. Chiapponi et al.
Weusedifferentprobabilitydistributionfunctionstoensurethattheydonot
producedrasticallydifferentsizes.Variousotherfunctionscouldhavebeenused.
Ourgoalisnottofindthebestonebuttoshowthatseveral“goodenough”ones
deliver the same ballpark figure for P.
Algorithm Used. WestudiedthedistributionoftheIPsforsubgroupsofdays
of size s ranging from 1 to 10. To group the days, we have used juxtaposed
windows (as opposed to sliding windows) to ensure that our final histogram
contained the same amount of values as the one in Fig.3. We chose juxtaposed
windows to not count twice the IPs of a singular day and reproduce thus a
coherent replica of the observed data.
We have run simulations with different population sizes P. We have incre-
mented P by 10,000, starting with the initial value of 10,000 up to 100,000.
Moreover, we have tested values from 100,000 to 200,000 with an increment of
20,000. For a given time window, we have produced as many histograms as dis-
tinct population sizes. Each histogram is obtained thanks to 100 simulations.
Each simulation produces its own histogram and we compute the Wasserstein
distance between this histogram and the empirical one. An average Wasserstein
distance value is then obtained from these 100 simulations. The lowest value
of this average distance corresponds to the size P which best represents the
observed data. For each window size, for each population size, for each simu-
lation, we have plotted the distances obtained using a boxplot representation.
This algorithm has been applied using three distinct probability distribution
functions, as explained here below.
Fig.5.Uniformdistribution:foreachpopulationsizeonthexaxis,agroupofboxplots
displays the Wasserstein Distances (y axis) obtained in the 100 experiment for that
population size. Each color represents the window size used for the simulation.
Botnet Sizes: When Maths Meet Myths 605
Uniform Distribution. The simplest model is the one where all IPs, every
day, have thesame probability of being assigned to a bot. To model this, we use
a uniform distribution as the probability distribution function in our drawing
process. Figure5 shows for each window size (colored legend) and for each pop-
ulationsize(X-axis),theboxplotsofWassersteinDistances(Y-axis)obtainedin
all the experiments. We clearly see that for P bigger than 30K, the bigger its
value, the more different is the obtained histogram with respect to Fig.3. The
best distances are obtained for the low value of P of 20K, for all time window
sizes. The Wasserstein distance is quite high though, around 1,000 and we have
looked for other distributions with the hope of obtaining smaller distances.
Fig.6.Gaussiandistribution:foreachpopulationsizeonthexaxis,agroupofboxplots
displays the Wasserstein Distances (y axis) obtained in the 100 experiment for that
population size. Each color represents the window size used for the simulation.
Gaussian Distribution (aka normal). It is reasonable to imagine the exis-
tenceofabiasintheIPassignmentprocessthatwouldleadsomeIPstobemore
frequently used whereas others would be rarely picked. This could be due, for
instance, to the simple fact that some residential IPs might be more frequently
available (online) than others. Another reason could be that proxies, to ensure
a better quality of service, assign preferably IPs “close” to their customers. Our
goal is not to identify the causes of these biases but, simply, to assume that
they could exist and, thus, model this possibility. To do so, we have run our
algorithm with a Gaussian distribution. For the sake of concision, the results
presented here correspond to the parameters mu=0.5 and sigma=0.1. Other
choices lead to the same lessons learned and this combination offers the best
distances. We offer in Fig.6 a similar representation as in Fig.5. This model
seems to be a better approximation since the best Wasserstein distance is now
half of the one obtained for the uniform distribution. As expected, the size P
does grow since a number of IPs are now very rarely chosen. Its value, around
60K, is still three orders of magnitude below the claimed 70M.
606 E. Chiapponi et al.
Fig.7. Beta distribution: for each population size on the x axis, a group of boxplots
displays the Wasserstein Distances (y axis) obtained in the 100 experiment for that
population size. Each color represents the window size used for the simulation.
Beta Distribution. Last but not least, we present also the results obtained
with the Beta distribution, with alpha = 1 and beta = 5; which enables us to
representadifferentformofbiasinthechoicebuttheresultsareveryconsistent
withanoptimalsizeP of60KandaWassersteindistancebelow500.Theresults
are represented in Fig.7.
6.3 Fitting Curve
As explained before, a distinct approach to get an informed estimate of the size
P consists in starting from the values observed in Fig.4, in finding a fitting
function and in extrapolating its values.
To do so, after having looked at the data at our disposal, we have observed
that, roughly speaking, the amount of new IPs (i.e., never seen so far) observed
on a daily basis was decreasing linearly over time. We were thus hoping to be
able to find a good fitting function [18], thanks to an exponentially decaying
one. We found out by means of simulations that the best fit was achieved with
the following function:
a∗(1−e−(x−b)/c
) (1)
The parameters that provide the best fit are:
a=2.77313369e+04
b=−4.77879543e−01
c=8.04885708e+01
ThefittedcurveisrepresentedinFig.8.Toassesstheirsimilarities,wecalcu-
latethePearsoncorrelationfactor[21]andobtainthevalue1.000whichindicates
Botnet Sizes: When Maths Meet Myths 607
atotalpositivelinearcorrelation,confirmingtheadequacyofourfittingfunction
which is visible by the quasi superposition of both curves in Fig.8
We can now use that fitting function to extrapolate the total amount of
distinct IPs we would have seen, had we been able to run the experiment for
3 years. Figure9 shows how the curve reaches a plateau after a bit more than
a year. Thus, according to this distinct approach, the bots we have observed
only have a couple of tens of thousands of IPs at their disposal, a value which is
consistent with the ones found with the first approach.
Fig.8.Projectionoftherealdataonthe Fig.9. 3 years prediction of the num-
fitting curve values berofdifferentIPsthatwouldhavebeen
seen in the honeypot
7 Complementary Results
InthisSection,wepresentadditionalpiecesofevidencetothosealreadyprovided
in [2], which confirm that the IPs we have analysed are, indeed, quite likely
provided by proxy services.
These IPs are supposed to be residential IPs; i.e., they belong to legit users
who could, possibly, be interested in buying tickets. To verify this, we have
looked for the presence of these IPs in the logs of 17 other airlines. We found
out that during the experiment, five bookings have been realised by 5 of our
IPs. In Table1 we indicate when the booking was done vs. when the same IP
was seen in our honeypot logs. As expected, the dates differ greatly. Moreover,
none of these requests had the bot signature associated with them. They look
perfectly legit. This confirms two things i) some of these IPs are likely used by
legitusers,ii)theriskofblockinglegitcustomerswhenblockingidentifiedproxy
IPs remains extremely small.
On the other hand, the simplest way to implement a proxy is to open some
portsandhaveaproxyserverlisteningbehindit.Thisshouldthusbedetectable
bythevariousactorswhoscantheInternetcontinuously,lookingforthreatsand,
or, vulnerabilities. We have used two such systems to see if they had identified
our IPs as behaving like proxies. First, we have used IPInfo.io [7] which pro-
vides a boolean value for each IP in the categories “VPN”, “Proxy”, “Hosting”.
According to the provider of that service, VPNs are usually encrypted traffic
endpoints so typically, if there is a VPN operating on an IP address, there will
608 E. Chiapponi et al.
Table 1. Timestamp of the bookings and the Table 2.Distributionofthefraud
honeypot requests made by the same IPs. score of IPQualityScore
Bookingtime Requesttime Score(S) %ofIPs #ofIPs
2020-01-17 2020-02-01 S<75 28% 3958
2020-02-05 S∈[75,85] 46% 6371
2020-02-14 S(cid:2)85 26% 3568
2020-02-26 2020-01-10
2020-01-23
2020-02-29 2020-02-01
2020-02-06 2020-02-23
2020-02-07 2020-01-24
2020-02-02
2020-02-19
be either encrypted traffic or ports open which will obviously show a VPN is
being used. Proxies are usually just a “HTTP forwarding” service and redirect
traffic to somewhere else (internal domains, other servers, etc.) [8].“Hosting”
category specifies if the IP belongs to hosting providers.
Table3showsthatacoupleofIPshavebeencategorizedasinvolvedinsuspi-
ciousactivitiesbutnotasmanyasexpected.However,theresultsobtainedwith
IPQualityScore [9] are much more aligned with our expectations. As explained
in their documentation, this service tells if an IP has been used in “automatic
fraudulent behavior” in the “Bot status” category, while indicating a positive
valueof“RecentAbuse”iftheIPhasbeeninvolvedina“recentlyverifiedabuse
acrosstheirnetwork”.Theabusebehaviorincludeschargingback,compromised
devices, fake app installation. Moreover, the “VPN” category indicates server
or data center IPs which allow tunneling. Finally, the “Proxy”3 category, iden-
tifies a device being infected by malware, a user selling bandwidth from their
connection or other types of proxy like SOCKS, Elite, Anonymous, Tor, etc.
With this service, we can notice that the number of IPs involved in malicious
activity is much higher in comparison to the first one. Furthermore, this service
provides a general fraud score for the IP: this value ranges form 0 to 100, indi-
cating a suspicious activity when higher than 75 and an high risk when greater
than 85. Table2 tells that around 72% of the IPs show a suspicious behavior, of
which 28% are classified as high risk. This is quite consistent with the idea that
malicious actors are hiding behind them, ruining the reputation of these IPS.
To dig deeper into the analysis of the malicious behaviors associated with
these IPs, we looked for their presence in anti-spam DNS blocklists. Using the
Python library Pydnsbl we checked multiple blocklists and we found out that
76% of the IPs were blocked at least in one of them at the time of our analysis
3 A “VPN” is automatically a “Proxy” according to their definitions.
Botnet Sizes: When Maths Meet Myths 609
Table 3.IPInfo.ioclassificationof Table 4. IPQualityScore classification of the
the IPs IPs (*From the total number of positive
matches, 10213, we subtracted the number of
Type NumberofIps Percentage positive values of VPN)
VPN 180 0.013
Proxy 59 0.004 Type NumberofIps Percentage
Hosting 1733 0.125 VPN 9138 0.658
Proxy* 1075 0.077
Recentabuse 3878 0.279
Botstatus 2780 0.200
(July2020).Hence,wehadtheconfirmationthattheseIPsweredoingmalicious
activity also outside of our environment.
8 Discussion
The whole point of our experiment was to obtain, over a long period of time, a
meaningful set of IPs that we could confidently say were behaving as they were
members of the very same botnet. The very strong correlation in their activity
patterns, detailed in [2], is as close as a ground truth one could hope for. The
anti-bot detection solution identifies many more IPs as behaving like bots but
ourexperienceinlookingatthelogsgivesusnoassurancethatIPsflaggedwith
a given signature belong to the same botnet. Indeed, the goal of each signature
is to fingerprint “a bot”, not “the bot from botnet X, Y or Z”. The analysis we
have carried out in this paper required a clean dataset in order to be able to
derive meaningful conclusions. We are very well aware though that, compared
to all the bots that are out there, our dataset is relatively small and we do not
pretend that our conclusions can, or should, be extended to all botnets that are
in activity. Our results do only apply to the botnet we have studied. Having
said so, all elements at our disposal, explained in the previous pages, indicate
that this botnet is a perfect example of so called APBs, Advanced Persistent
Bots, and is thus representative of the many others that are scraping websites.
Therefore, we have good reasons to believe that our results could probably be
generalized to many other botnets, without having, at the moment the data to
support this claim.
If true, this would mean that large websites victims of web scraping bots
would see the same IPs coming back regularly and that the grand total of IPs
they would have to watch for would remain manageable (in the order of tens of
thousands instead of tens of millions). An IP blocking strategy could thus be
rejuvenated:seedingtheirsetsofIPswiththeonesclearlyidentifiedasbehaving
asbots,thatstrategycouldenablethemtocatchthemostevasivebotswhenthey
show up with a known bad IP. Redirecting these IPs to a fake web site instead
of blocking them would also enable them to keep watching their behavior and,
610 E. Chiapponi et al.
possibly, redirect them to the real web site if their requests are not consistent
with those of known bots (i.e., in the case of a false positive).
Theresultspresentedinthispaperhavehelpedusinconvincingourpartner,
the major IT provider, to move forward into building such an environment and
theworkisunderway.Wefeltitwasimportanttosharealreadynowourprelim-
inary results with the community not only in order to let other benefit from the
gained insights but also, possibly, to obtain feedback on important elements we
could have missed. We do hope our contributions will participate in diminishing
the negative impact created by these bots on the global Internet ecosystem.
9 Conclusion
In this paper, we have studied in detail a specific web scraping botnet that is
representative of the plague most airline websites are suffering from.
Thanks to two distinct mathematical models, we have shown that the total
amount of IPs at the disposal of this botnet was most likely in the low tens of
thousands. We have also given pieces of evidence that these IPs were provided
by proxy services, thought to be able to provide tens of millions of IPs to their
customers.Ifourfindingapplies,aswethinkitdoes,tootherbotnetsthenanIP-
blockingstrategycouldbeapplied,contrarytothecommonbelief.Weencourage
others to carry out similar experiments to confirm, or deny, our findings while
we are in the process of testing our conjecture in a new large scale experiment.
References
1. AminAzad,B.,Starov,O.,Laperdrix,P.,Nikiforakis,N.:Webrunner2049:evalu-
atingthird-partyanti-botservices.In:17thConferenceonDetectionofIntrusions
andMalware&VulnerabilityAssessment(DIMVA2020),Lisboa,Portugal(2020)
2. Chiapponi, E., Catakoglu, O., Thonnard, O., Dacier, M.: HoPLA: a honeypot
platform to lure attackers. In: C&ESAR 2020, Computer & Electronics Security
ApplicationsRendez-vous,DeceptiveSecurityConference,PartofEuropeanCyber
Week, Rennes, France (2020). http://www.eurecom.fr/publication/6366
3. Dietrich, S., Long, N., Dittrich, D.: Analyzing distributed denial of service tools:
theshaftcase.In:Proceedingsofthe14thUSENIXConferenceonSystemAdmin-
istration, pp. 329–339. New Orleans, Louisiana, USA (2000)
4. Haque, A., Singh, S.: Anti-scraping application development. In: 2015 Interna-
tional Conference on Advances in Computing, Communications andInformatics
(ICACCI), pp. 869–874, Kochi, India (2015)
5. Imperva: Imperva bad bot report (2020). https://www.imperva.com/resources/
resource-library/reports/2020-bad-bot-report/
6. Imperva: how bots affect airlines (2019). https://www.imperva.com/resources/