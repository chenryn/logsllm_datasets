# 29 \| GroupMetadataManager：组元数据管理器是个什么东西？你好，我是胡夕。今天，我们学习 GroupMetadataManager类的源码。从名字上来看，它是组元数据管理器，但是，从它提供的功能来看，我更愿意将它称作消费者组管理器，因为它定义的方法，提供的都是添加消费者组、移除组、查询组这样组级别的基础功能。不过，这个类的知名度不像 KafkaController、GroupCoordinator那么高，你之前可能都没有听说过它。但是，它其实是非常重要的消费者组管理类。GroupMetadataManager 类是在消费者组 Coordinator组件被创建时被实例化的。这就是说，每个 Broker在启动过程中，都会创建并维持一个 GroupMetadataManager 实例，以实现对该Broker负责的消费者组进行管理。更重要的是，生产环境输出日志中的与消费者组相关的大多数信息，都和它息息相关。我举一个简单的例子。你应该见过这样的日志输出：    Removed ××× expired offsets in ××× milliseconds.这条日志每 10分钟打印一次。你有没有想过，它为什么要这么操作呢？其实，这是由GroupMetadataManager 类创建的定时任务引发的。如果你不清楚GroupMetadataManager的原理，虽然暂时不会影响你使用，但是，一旦你在实际环境中看到了有关消费者组的错误日志，仅凭日志输出，你是无法定位错误原因的。要解决这个问题，就只有一个办法：**通过阅读源码，彻底搞懂底层实现原理，做到以不变应万变**。关于这个类，最重要的就是要掌握它是如何管理消费者组的，以及它对内部位移主题的操作方法。这两个都是重磅功能，我们必须要吃透它们的原理，这也是我们这三节课的学习重点。今天，我们先学习它的类定义和管理消费者组的方法。类定义与字段GroupMetadataManager 类定义在 coordinator.group 包下的同名 scala文件中。这个类的代码将近 1000行，逐行分析的话，显然效率不高，也没有必要。所以，我从类定义和字段、重要方法两个维度给出主要逻辑的代码分析。下面的代码是该类的定义，以及我选取的重要字段信息。    // brokerId：所在Broker的Id    // interBrokerProtocolVersion：Broker端参数inter.broker.protocol.version值    // config: 内部位移主题配置类    // replicaManager: 副本管理器类    // zkClient: ZooKeeper客户端    class GroupMetadataManager(      brokerId: Int,       interBrokerProtocolVersion: ApiVersion,      config: OffsetConfig,       replicaManager: ReplicaManager,       zkClient: KafkaZkClient,       time: Time,      metrics: Metrics) extends Logging with KafkaMetricsGroup {      // 压缩器类型。向位移主题写入消息时执行压缩操作      private val compressionType: CompressionType = CompressionType.forId(config.offsetsTopicCompressionCodec.codec)      // 消费者组元数据容器，保存Broker管理的所有消费者组的数据      private val groupMetadataCache = new Pool[String, GroupMetadata      // 位移主题下正在执行加载操作的分区      private val loadingPartitions: mutable.Set[Int] = mutable.Set()      // 位移主题下完成加载操作的分区      private val ownedPartitions: mutable.Set[Int] = mutable.Set()      // 位移主题总分区数      private val groupMetadataTopicPartitionCount = getGroupMetadataTopicPartitionCount      ......    }这个类的构造函数需要 7 个参数，后面的 time 和 metrics只是起辅助作用，因此，我重点解释一下前 5个参数的含义。1.  brokerId：这个参数我们已经无比熟悉了。它是所在 Broker 的 ID    值，也就是 broker.id    参数值。        2.  interBrokerProtocolVersion：保存 Broker    间通讯使用的请求版本。它是 Broker 端参数    inter.broker.protocol.version    值。这个参数的主要用途是        **确定位移主题消息格式的版本**        。        3.  config：这是一个 OffsetConfig    类型。该类型定义了与位移管理相关的重要参数，比如位移主题日志段大小设置、位移主题备份因子、位移主题分区数配置等。        4.  replicaManager：副本管理器类。GroupMetadataManager    类使用该字段实现获取分区对象、日志对象以及写入分区消息的目的。        5.  zkClient：ZooKeeper 客户端。该类中的此字段只有一个目的：从    ZooKeeper    中获取位移主题的分区数。        除了构造函数所需的字段，该类还定义了其他关键字段，我给你介绍几个非常重要的。**1.compressionType****压缩器类型**。Kafka向位移主题写入消息前，可以选择对消息执行压缩操作。是否压缩，取决于Broker 端参数 offsets.topic.compression.codec值，默认是不进行压缩。如果你的位移主题占用的磁盘空间比较多的话，可以考虑启用压缩，以节省资源。**2.groupMetadataCache****该字段是 GroupMetadataManager类上最重要的属性，它****保存这个 Broker 上 GroupCoordinator组件管理的所有消费者组元数据。**它的 Key 是消费者组名称，Value 是消费者组元数据，也就是GroupMetadata。源码通过该字段实现对消费者组的添加、删除和遍历操作。**3.loadingPartitions****位移主题下正在执行加载操作的分区号集合**。这里需要注意两点：首先，这些分区都是位移主题分区，也就是\_\_consumer_offsets主题下的分区；其次，所谓的加载，是指读取位移主题消息数据，填充GroupMetadataCache 字段的操作。**4.ownedPartitions****位移主题下完成加载操作的分区号集合**。与 loadingPartitions类似的是，该字段保存的分区也是位移主题下的分区。和 loadingPartitions不同的是，它保存的分区都是**已经完成加载操作**的分区。**5.groupMetadataTopicPartitionCount****位移主题的分区数**。它是 Broker 端参数 offsets.topic.num.partitions的值，默认是 50个分区。若要修改分区数，除了变更该参数值之外，你也可以手动创建位移主题，并指定不同的分区数。在这些字段中，groupMetadataCache 是最重要的，GroupMetadataManager类大量使用该字段实现对消费者组的管理。接下来，我们就重点学习一下该类是如何管理消费者组的。重要方法管理消费者组包含两个方面，对消费者组元数据的管理以及对消费者组位移的管理。组元数据和组位移都是Coordinator端重要的消费者组管理对象。消费者组元数据管理消费者组元数据管理分为查询获取组信息、添加组、移除组和加载组信息。从代码复杂度来讲，查询获取、移除和添加的逻辑相对简单，加载的过程稍微费事些。我们先说说查询获取。查询获取消费者组元数据GroupMetadataManager类中查询及获取组数据的方法有很多。大多逻辑简单，你一看就能明白，比如下面的getGroup 方法和 getOrMaybeCreateGroup方法：     // getGroup方法：返回给定消费者组的元数据信息。    // 若该组信息不存在，返回None    def getGroup(groupId: String): Option[GroupMetadata] = {      Option(groupMetadataCache.get(groupId))    }    // getOrMaybeCreateGroup方法：返回给定消费者组的元数据信息。    // 若不存在，则视createIfNotExist参数值决定是否需要添加该消费者组    def getOrMaybeCreateGroup(groupId: String, createIfNotExist: Boolean): Option[GroupMetadata] = {      if (createIfNotExist)        // 若不存在且允许添加，则添加一个状态是Empty的消费者组元数据对象        Option(groupMetadataCache.getAndMaybePut(groupId, new GroupMetadata(groupId, Empty, time)))      else        Option(groupMetadataCache.get(groupId))    }GroupMetadataManager 类的上层组件 GroupCoordinator会大量使用这两个方法来获取给定消费者组的数据。这两个方法都会返回给定消费者组的元数据信息，但是它们之间是有区别的。对于 getGroup 方法而言，如果该组信息不存在，就返回None，而这通常表明，消费者组确实不存在，或者是，该组对应的 Coordinator组件变更到其他 Broker 上了。而对于 getOrMaybeCreateGroup 方法而言，若组信息不存在，就根据createIfNotExist参数值决定是否需要添加该消费者组。而且，getOrMaybeCreateGroup方法是在消费者组第一个成员加入组时被调用的，用于把组创建出来。在 GroupMetadataManager类中，还有一些地方也散落着组查询获取的逻辑。不过它们与这两个方法中的代码大同小异，很容易理解，课下你可以自己阅读下。移除消费者组元数据接下来，我们看下如何移除消费者组信息。当 Broker 卸任某些消费者组的Coordinator 角色时，它需要将这些消费者组从 groupMetadataCache中全部移除掉，这就是 removeGroupsForPartition方法要做的事情。我们看下它的源码：    def removeGroupsForPartition(offsetsPartition: Int,                                 onGroupUnloaded: GroupMetadata => Unit): Unit = {      // 位移主题分区      val topicPartition = new TopicPartition(Topic.GROUP_METADATA_TOPIC_NAME, offsetsPartition)      info(s"Scheduling unloading of offsets and group metadata from $topicPartition")      // 创建异步任务，移除组信息和位移信息      scheduler.schedule(topicPartition.toString, () => removeGroupsAndOffsets)      // 内部方法，用于移除组信息和位移信息      def removeGroupsAndOffsets(): Unit = {        var numOffsetsRemoved = 0        var numGroupsRemoved = 0        inLock(partitionLock) {          // 移除ownedPartitions中特定位移主题分区记录          ownedPartitions.remove(offsetsPartition)          // 遍历所有消费者组信息          for (group  Unit,      producerId: Long = RecordBatch.NO_PRODUCER_ID,      producerEpoch: Short = RecordBatch.NO_PRODUCER_EPOCH): Unit = {      ......    }这个方法接收 6个参数，它们的含义我都用注释的方式标注出来了。producerId 和producerEpoch 这两个参数是与 Kafka事务相关的，你简单了解下就行。我们要重点掌握前面 4个参数的含义。1.  group：消费者组元数据信息。该字段的类型就是我们之前学到的    GroupMetadata 类。        2.  consumerId：消费者组成员 ID，仅用于 DEBUG    调试。    3.  offsetMetadata：待保存的位移值，按照分区分组。        4.  responseCallback：位移保存完成后需要执行的回调函数。        接下来，我们看下 storeOffsets 的代码。为了便于你理解，我删除了与Kafka 事务操作相关的部分。    // 过滤出满足特定条件的待保存位移数据    val filteredOffsetMetadata = offsetMetadata.filter { case (_, offsetAndMetadata) =>      validateOffsetMetadataLength(offsetAndMetadata.metadata)    }    ......    val isTxnOffsetCommit = producerId != RecordBatch.NO_PRODUCER_ID    // 如果没有任何分区的待保存位移满足特定条件    if (filteredOffsetMetadata.isEmpty) {      // 构造OFFSET_METADATA_TOO_LARGE异常并调用responseCallback返回      val commitStatus = offsetMetadata.map { case (k, _) => k -> Errors.OFFSET_METADATA_TOO_LARGE }      responseCallback(commitStatus)      None    } else {      // 查看当前Broker是否为给定消费者组的Coordinator      getMagic(partitionFor(group.groupId)) match {        // 如果是Coordinator        case Some(magicValue) =>          val timestampType = TimestampType.CREATE_TIME          val timestamp = time.milliseconds()          // 构造位移主题的位移提交消息          val records = filteredOffsetMetadata.map { case (topicPartition, offsetAndMetadata) =>            val key = GroupMetadataManager.offsetCommitKey(group.groupId, topicPartition)            val value = GroupMetadataManager.offsetCommitValue(offsetAndMetadata, interBrokerProtocolVersion)            new SimpleRecord(timestamp, key, value)          }          val offsetTopicPartition = new TopicPartition(Topic.GROUP_METADATA_TOPIC_NAME, partitionFor(group.groupId))          // 为写入消息创建内存Buffer          val buffer = ByteBuffer.allocate(AbstractRecords.estimateSizeInBytes(magicValue, compressionType, records.asJava))          if (isTxnOffsetCommit && magicValue  builder.build())          // putCacheCallback函数定义......          if (isTxnOffsetCommit) {            ......          } else {            group.inLock {              group.prepareOffsetCommit(offsetMetadata)            }          }          // 写入消息到位移主题，同时调用putCacheCallback方法更新消费者元数据          appendForGroup(group, entries, putCacheCallback)        // 如果是Coordinator        case None =>          // 构造NOT_COORDINATOR异常并提交给responseCallback方法          val commitStatus = offsetMetadata.map {            case (topicPartition, _) =>              (topicPartition, Errors.NOT_COORDINATOR)          }          responseCallback(commitStatus)          None      }    }我为方法的关键步骤都标注了注释，具体流程前面我也介绍过了，应该很容易理解。不过，这里还需要注意两点，也就是appendForGroup 和 putCacheCallback方法。前者是向位移主题写入消息；后者是填充元数据缓存的。我们结合代码来学习下。appendForGroup 方法负责写入消息到位移主题，同时传入 putCacheCallback方法，更新消费者元数据。以下是它的代码：    private def appendForGroup(      group: GroupMetadata,      records: Map[TopicPartition, MemoryRecords],      callback: Map[TopicPartition, PartitionResponse] => Unit): Unit = {      replicaManager.appendRecords(        timeout = config.offsetCommitTimeoutMs.toLong,        requiredAcks = config.offsetCommitRequiredAcks,        internalTopicsAllowed = true,        origin = AppendOrigin.Coordinator,        entriesPerPartition = records,        delayedProduceLock = Some(group.lock),        responseCallback = callback)    }可以看到，该方法就是调用 ReplicaManager 的 appendRecords方法，将消息写入到位移主题中。下面，我们再关注一下 putCacheCallback方法的实现，也就是将写入的位移值填充到缓存中。我先画一张图来展示下putCacheCallback 的逻辑。![](Images/6ecc85692ed8a4d549bed5e1b90250e0.png)savepage-src="https://static001.geekbang.org/resource/image/bc/42/bc2fcf199a685a5cc6d32846c53c3042.jpg"}现在，我们结合代码，学习下它的逻辑实现。    def putCacheCallback(responseStatus: Map[TopicPartition, PartitionResponse]): Unit = {      // 确保消息写入到指定位移主题分区，否则抛出异常      if (responseStatus.size != 1 || !responseStatus.contains(offsetTopicPartition))        throw new IllegalStateException("Append status %s should only have one partition %s"          .format(responseStatus, offsetTopicPartition))      // 更新已提交位移数指标      offsetCommitsSensor.record(records.size)      val status = responseStatus(offsetTopicPartition)      val responseError = group.inLock {        // 写入结果没有错误        if (status.error == Errors.NONE) {          // 如果不是Dead状态          if (!group.is(Dead)) {            filteredOffsetMetadata.foreach { case (topicPartition, offsetAndMetadata) =>              if (isTxnOffsetCommit)                ......              else                // 调用GroupMetadata的onOffsetCommitAppend方法填充元数据                group.onOffsetCommitAppend(topicPartition, CommitRecordMetadataAndOffset(Some(status.baseOffset), offsetAndMetadata))            }          }          Errors.NONE        // 写入结果有错误        } else {          if (!group.is(Dead)) {            ......            filteredOffsetMetadata.foreach { case (topicPartition, offsetAndMetadata) =>              if (isTxnOffsetCommit)                group.failPendingTxnOffsetCommit(producerId, topicPartition)              else                // 取消未完成的位移消息写入                group.failPendingOffsetWrite(topicPartition, offsetAndMetadata)            }          }          ......          // 确认异常类型          status.error match {            case Errors.UNKNOWN_TOPIC_OR_PARTITION                 | Errors.NOT_ENOUGH_REPLICAS                 | Errors.NOT_ENOUGH_REPLICAS_AFTER_APPEND =>              Errors.COORDINATOR_NOT_AVAILABLE            case Errors.NOT_LEADER_FOR_PARTITION                 | Errors.KAFKA_STORAGE_ERROR =>              Errors.NOT_COORDINATOR            case Errors.MESSAGE_TOO_LARGE                 | Errors.RECORD_LIST_TOO_LARGE                 | Errors.INVALID_FETCH_SIZE =>              Errors.INVALID_COMMIT_OFFSET_SIZE            case other => other          }        }      }      // 利用异常类型构建提交返回状态      val commitStatus = offsetMetadata.map { case (topicPartition, offsetAndMetadata) =>        if (validateOffsetMetadataLength(offsetAndMetadata.metadata))          (topicPartition, responseError)        else          (topicPartition, Errors.OFFSET_METADATA_TOO_LARGE)      }      // 调用回调函数      responseCallback(commitStatus)    }putCacheCallback 方法的主要目的，是将多个消费者组位移值填充到GroupMetadata 的 offsets元数据缓存中。**首先**，该方法要确保位移消息写入到指定位移主题分区，否则就抛出异常。**之后**，更新已提交位移数指标，然后判断写入结果是否有错误。如果没有错误，只要组状态不是 Dead 状态，就调用 GroupMetadata 的onOffsetCommitAppend 方法填充元数据。onOffsetCommitAppend方法的主体逻辑，是将消费者组订阅分区的位移值写入到 offsets字段保存的集合中。当然，如果状态是Dead，则什么都不做。如果刚才的写入结果有错误，那么，就通过 failPendingOffsetWrite方法取消未完成的位移消息写入。**接下来**，代码要将日志写入的异常类型转换成表征提交状态错误的异常类型。具体来说，就是将UNKNOWN_TOPIC_OR_PARTITION、NOT_LEADER_FOR_PARTITION 和MESSAGE_TOO_LARGE 这样的异常，转换到 COORDINATOR_NOT_AVAILABLE 和NOT_COORDINATOR 这样的异常。之后，再将这些转换后的异常封装进commitStatus字段中传给回调函数。**最后**，调用回调函数返回。至此，方法结束。好了，保存消费者组位移信息的 storeOffsets方法，我们就学完了，它的关键逻辑，是构造位移主题消息并写入到位移主题，然后将位移值填充到消费者组元数据中。查询消费者组位移现在，我再说说查询消费者组位移，也就是 getOffsets方法的代码实现。比起storeOffsets，这个方法要更容易理解。我们看下它的源码：    def getOffsets(      groupId: String,       requireStable: Boolean,       topicPartitionsOpt: Option[Seq[TopicPartition]]): Map[TopicPartition, PartitionData] = {      ......      // 从groupMetadataCache字段中获取指定消费者组的元数据      val group = groupMetadataCache.get(groupId)      // 如果没有组数据，返回空数据      if (group == null) {        topicPartitionsOpt.getOrElse(Seq.empty[TopicPartition]).map { topicPartition =>          val partitionData = new PartitionData(OffsetFetchResponse.INVALID_OFFSET,            Optional.empty(), "", Errors.NONE)          topicPartition -> partitionData        }.toMap      // 如果存在组数据      } else {        group.inLock {          // 如果组处于Dead状态，则返回空数据          if (group.is(Dead)) {            topicPartitionsOpt.getOrElse(Seq.empty[TopicPartition]).map { topicPartition =>              val partitionData = new PartitionData(OffsetFetchResponse.INVALID_OFFSET,                Optional.empty(), "", Errors.NONE)              topicPartition -> partitionData            }.toMap          } else {            val topicPartitions = topicPartitionsOpt.getOrElse(group.allOffsets.keySet)            topicPartitions.map { topicPartition =>              if (requireStable && group.hasPendingOffsetCommitsForTopicPartition(topicPartition)) {                topicPartition -> new PartitionData(OffsetFetchResponse.INVALID_OFFSET,                  Optional.empty(), "", Errors.UNSTABLE_OFFSET_COMMIT)              } else {                val partitionData = group.offset(topicPartition) match {                  // 如果没有该分区位移数据，返回空数据                  case None =>                    new PartitionData(OffsetFetchResponse.INVALID_OFFSET,                      Optional.empty(), "", Errors.NONE)                  // 从消费者组元数据中返回指定分区的位移数据                  case Some(offsetAndMetadata) =>                    new PartitionData(offsetAndMetadata.offset,                      offsetAndMetadata.leaderEpoch, offsetAndMetadata.metadata, Errors.NONE)                }                topicPartition -> partitionData              }            }.toMap          }        }      }    }getOffsets 方法首先会读取 groupMetadataCache中的组元数据，如果不存在对应的记录，则返回空数据集，如果存在，就接着判断组是否处于Dead 状态。 如果是 Dead状态，就说明消费者组已经被销毁了，位移数据也被视为不可用了，依然返回空数据集；若状态不是Dead，就提取出消费者组订阅的分区信息，再依次为它们获取对应的位移数据并返回。至此，方法结束。总结今天，我们学习了 GroupMetadataManager类的源码。作为消费者组管理器，它负责管理消费者组的方方面面。其中，非常重要的两个管理功能是消费者组元数据管理和消费者组位移管理，分别包括查询获取、移除、添加和加载消费者组元数据，以及保存和查询消费者组位移，这些方法是上层组件GroupCoordinator倚重的重量级功能载体，你一定要彻底掌握它们。我画了一张思维导图，帮助你复习一下今天的重点内容。![](Images/5b40755ca328b0c448e8c367296bffd0.png)savepage-src="https://static001.geekbang.org/resource/image/eb/5a/eb8fe45e1d152e2ac9cb52c81390265a.jpg"}实际上，GroupMetadataManager 类的地位举足轻重。虽然它在 Coordinator组件中不显山不露水，但却是一些线上问题的根源所在。我再跟你分享一个小案例。之前，我碰到过一个问题：在消费者组成员超多的情况下，无法完成位移加载，这导致Consumer 端总是接收到 Marking the coordinator dead的错误。 当时，我查遍各种资料，都无法定位问题，最终，还是通过阅读源码，发现是这个类的doLoadGroupsAndOffsets 方法中创建的 buffer 过小导致的。后来，通过调大offsets.load.buffer.size参数值，我们顺利地解决了问题。试想一下，如果当时没有阅读这部分的源码，仅凭日志，我们肯定无法解决这个问题。因此，我们花三节课的时间，专门阅读GroupMetadataManager 类源码，是非常值得的。下节课，我将带你继续研读GroupMetadataManager源码，去探寻有关位移主题的那些代码片段。课后讨论请思考这样一个问题：在什么场景下，需要移除 GroupMetadataManager中保存的消费者组记录？欢迎在留言区写下你的思考和答案，跟我交流讨论，也欢迎你把今天的内容分享给你的朋友。