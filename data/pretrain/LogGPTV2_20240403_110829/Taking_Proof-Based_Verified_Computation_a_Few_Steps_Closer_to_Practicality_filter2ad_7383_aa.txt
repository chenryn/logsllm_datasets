title:Taking Proof-Based Verified Computation a Few Steps Closer to Practicality
author:Srinath T. V. Setty and
Victor Vu and
Nikhil Panpalia and
Benjamin Braun and
Andrew J. Blumberg and
Michael Walfish
Taking proof-based veriﬁed computation a few steps closer to practicality
Srinath Setty, Victor Vu, Nikhil Panpalia, Benjamin Braun, Andrew J. Blumberg, and Michael Walﬁsh
The University of Texas at Austin
Abstract. We describe GINGER, a built system for un-
conditional, general-purpose, and nearly practical veriﬁ-
cation of outsourced computation. GINGER is based on
PEPPER, which uses the PCP theorem and cryptographic
techniques to implement an efﬁcient argument system (a
kind of interactive protocol). GINGER slashes the query
size and costs via theoretical reﬁnements that are of in-
dependent interest; broadens the computational model
to include (primitive) ﬂoating-point fractions, inequality
comparisons, logical operations, and conditional control
ﬂow; and includes a parallel GPU-based implementation
that dramatically reduces latency.
1
We are motivated by outsourced computing: cloud com-
puting (in which clients outsource computations to re-
mote computers), peer-to-peer computing (in which
peers outsource storage and computation to each other),
volunteer computing (in which projects outsource com-
putations to volunteers’ desktops), etc.
Introduction
Our goal is to build a system that lets a client outsource
computation veriﬁably. The client should be able to send
a description of a computation and the input to a server,
and receive back the result together with some auxiliary
information that lets the client verify that the result is cor-
rect. For this to be sensible, the veriﬁcation must be faster
than executing the computation locally.
Ideally, we would like such a system to be uncondi-
tional, general-purpose, and practical. That is, we don’t
want to make assumptions about the server (trusted hard-
ware, independent failures of replicas, etc.), we want a
setup that works for a broad range of computations, and
we want the system to be usable by real people for real
computations in the near future.
the ﬁrst
In principle,
two properties above have
been achievable for almost thirty years, using powerful
tools from complexity theory and cryptography. Interac-
tive proofs (IPs) and probabilistically checkable proofs
(PCPs) show how one entity (usually called the veri-
ﬁer) can be convinced by another (usually called the
prover) of a given mathematical assertion—without the
veriﬁer having to fully inspect a proof [5, 6, 19, 32]. In
our context, the mathematical assertion is that a given
computation was carried out correctly; though the proof
is as long as the computation, the theory implies—
surprisingly—that
the
proof in a small number of randomly-chosen locations
or query the prover a relatively small number of times.
the veriﬁer need only inspect
The rub has been the third property: practicality. These
protocols have required expensive encoding of compu-
tations, monstrously large proofs, high error bounds,
prohibitive overhead for the prover, and intricate con-
structions that make the asymptotically efﬁcient schemes
challenging to implement correctly.
However, a line of recent work indicates that ap-
proaches based on IPs and PCPs are closer to practicality
than previously thought [21, 44, 45, 49]. More generally,
there has been a groundswell of work that aims for poten-
tially practical veriﬁable outsourced computation, using
theoretical tools [11, 12, 20, 24, 25].
Nonetheless, these works have notable limitations.
Only a handful [21, 44, 45, 49] have produced work-
ing implementations, all of which impose high costs on
the veriﬁer and prover. Moreover, their model of com-
putation is arithmetic circuits over ﬁnite ﬁelds, which
represent non-integers awkwardly, control ﬂow inefﬁ-
ciently, and comparisons and logical operations only by
degenerating to verbose Boolean circuits. Arithmetic cir-
cuits are well-suited to integer computations and numeri-
cal straight line computations (e.g., multiplying matrices
and computing second moments), but the intersection of
these two domains leaves few realistic applications.
This paper describes a built system, called GINGER,
that addresses these problems, thereby taking general-
purpose proof-based veriﬁed computation several steps
closer to practicality. GINGER is an efﬁcient argument
system [37, 38]: an interactive proof system that assumes
the prover to be computationally bounded. Its starting
point is the PEPPER protocol [45] (which is summarized
in Section 2). GINGER’s contributions are as follows.
(1) GINGER demonstrates the strength of linear com-
mitment (§3). This paper proves that PEPPER’s com-
mitment primitive [45], which generalizes the commit-
ment primitive of Ishai et al. [35], is surprisingly pow-
erful: it not only commits an untrusted entity to a func-
tion and extracts evaluations of that function (as previ-
ously shown) but also ensures that the function is linear.
(The primitive embeds a strong linearity test.) This re-
sult sharply reduces the required number of queries (from
500 to 3) and a key error bound, and hence overhead.
(2) GINGER supports a general-purpose programming
model (§4). Although the model does not handle looping
concisely, it includes primitive ﬂoating-point quantities,
inequality comparisons, logical expressions, and condi-
tional control ﬂow. Moreover, we have a compiler (de-
rived from Fairplay [39]) that transforms computations
expressed in a general-purpose language to an executable
veriﬁer and prover. The core technical challenge is rep-
resenting computations as additions and multiplications
over a ﬁnite ﬁeld (as required by the veriﬁcation proto-
1
col); for instance, “not equal” and “if/else” do not obvi-
ously map to this formalism, inequalities are problematic
because ﬁnite ﬁelds are not ordered, and fractions com-
pound the difﬁculties. GINGER overcomes these chal-
lenges with techniques that, while not deep, require care
and detail.1 These techniques should apply to other pro-
tocols that use arithmetic constraints or circuits.
(3) GINGER exploits parallelism to slash latency (§5).
The prover can be distributed across machines, and some
of its functions are implemented in graphics hardware
(GPUs). Moreover, GINGER’s veriﬁer can use a GPU
for its cryptographic operations. Allowing the veriﬁer to
have a GPU models the present (many computers have
GPUs) and a plausible future in which specialized hard-
ware for cryptographic operations is common.2
We have implemented and evaluated GINGER (§6).
Compared to PEPPER [45], its base, GINGER lowers net-
work costs by 1–2 orders of magnitude (to hundreds
of KB or less in our experiments). The veriﬁer’s costs
drop by multiples and possibly orders of magnitude, de-
pending on the cost of encryption; if we model encryp-
tion as free, the veriﬁer can gain from outsourcing when
batch-verifying as few as 20 computations (down from
3900 in PEPPER). The prover’s CPU costs drop by 10–
15%, which is not much, but our parallel implementa-
tion reduces latency with near-linear speedup. Comput-
ing with rational numbers in GINGER is roughly three
times more expensive than computing with integers, and
arithmetic constraints permit far smaller representations
than a naive use of Boolean or arithmetic circuits.
Despite all of the above, GINGER is not quite ready
for the big leagues. However, PEPPER and GINGER have
made argument systems far more practical (in some cases
improving costs by 23 orders of magnitude over a naive
implementation). We are thus optimistic about ultimately
achieving true practicality.
2 Problem statement and background
Problem statement. A computer V, known as the veri-
ﬁer, has a computation Ψ and some desired input x that
it wants a computer P, known as the prover, to perform.
P returns y, the purported output of the computation, and
then V and P conduct an efﬁcient interaction. This in-
teraction should be cheaper for V than locally comput-
ing Ψ(x). Furthermore, if P returned the correct answer,
it should be able to convince V of that fact; otherwise,
V should be able to reject the answer as incorrect, with
high probability. (The converse will not hold: rejection
does not imply that P returned incorrect output, only that
1We elide some of these details for space; they are documented in a
longer version of this paper [46].
2One may wonder why, if the veriﬁer has this hardware, it needs to
outsource. GPUs are amenable only to certain computations (which
include the cryptographic underpinnings of GINGER).
2
it misbehaved somehow.) Our goal is that this guarantee
be unconditional: it should hold regardless of whether
P obeys the protocol (given standard cryptographic as-
sumptions about P’s computational power). If P deviates
from the protocol at any point (computing incorrectly,
proving incorrectly, etc.), we call it malicious.
2.1 Tools
In principle, we can meet our goal using PCPs. The PCP
theorem [5, 6] says that if a set of constraints is satisﬁ-
able (see below), there exists a probabilistically check-
able proof (a PCP) and a veriﬁcation procedure that ac-
cepts the proof after querying it in only a small number
of locations. On the other hand, if the constraints cannot
be satisﬁed, then the veriﬁcation procedure rejects any
purported proof, with probability at least 1 − .
To apply the theorem, we represent the computation
as a set of quadratic constraints over a ﬁnite ﬁeld. A
quadratic constraint is an equation of degree 2 that uses
additions and multiplications (e.g., A·Z1 +Z2−Z3·Z4 =
0). A set of constraints is satisﬁable if the variables can
be set to make all of the equations hold simultaneously;
such an assignment is called a satisfying assignment. In
our context, a set of constraints C will have a designated
input variable X and output variable Y (this generalizes
to multiple inputs and outputs), and C(X = x, Y = y)
denotes C with variable X bound to x and Y bound to y.
We say that a set of constraints C is equivalent to a
desired computation Ψ if: for all x, y, C(X = x, Y = y) is
satisﬁable if and only if y = Ψ(x). As a simple example,
increment-by-1 is equivalent to the constraint set {Y =
Z + 1, Z = X}. (For convenience, we will sometimes
refer to a given input x and purported output y implicitly
in statements such as, “If constraints C are satisﬁable,
then Ψ executed correctly”.) To verify a computation y =
Ψ(x), one could in principle apply the PCP theorem to
the constraints C(X = x, Y = y).
Unfortunately, PCPs are too large to be transferred.
However, if we assume a computational bound on the
prover P, then efﬁcient arguments apply [37, 38]: V is-
sues its PCP queries to P (so V need not receive the entire
PCP). For this to work, P must commit to the PCP be-
fore seeing V’s queries, thereby simulating a ﬁxed proof
whose contents are independent of the queries. V thus ex-
tracts a cryptographic commitment to the PCP (e.g., with
a collision-resistant hash tree [40]) and veriﬁes that P’s
query responses are consistent with the commitment.
This approach can be taken a step further: not even
P has to materialize the entire PCP. As Ishai et al. [35]
observe, in some PCP constructions, which they call lin-
ear PCPs, the PCP itself is a linear function: the veriﬁer
submits queries to the function, and the function’s out-
puts serve as the PCP responses. Ishai et al. thus design
a linear commitment primitive in which P can commit to
a linear function (the PCP) and V can submit function
inputs (the PCP queries) to P, getting back outputs (the
PCP responses) as if P itself were a ﬁxed function.
PEPPER [45] reﬁnes and implements the outline
above. In the rest of the section, we summarize the lin-
ear PCPs that PEPPER incorporates, give an overview of
PEPPER, and provide formal deﬁnitions. Additional de-
tails are in Appendix A.1.
2.2 Linear PCPs, applied to verifying computations
Imagine that V has a desired computation Ψ and desired
input x, and somehow obtains purported output y. To use
PCP machinery to check whether y = Ψ(x), V compiles
Ψ into equivalent constraints C, and then asks whether
C(X = x, Y = y) is satisﬁable, by consulting an oracle
π: a ﬁxed function (that depends on C, x, y) that V can
query. A correct oracle π is the proof (or PCP); V should
accept a correct oracle and reject an incorrect one.
A correct oracle π has three properties. First, π is a
linear function, meaning that π(a) + π(b) = π(a +b) for
all a, b in the domain of π. A linear function π : Fn → F
is determined by a vector w; i.e., π(a) = (cid:104)a, w(cid:105) for all
a ∈ Fn. Here, F is a ﬁnite ﬁeld, and (cid:104)a, b(cid:105) denotes the
inner (dot) product of two vectors a and b. The parameter
n is the size of w; in general, n is quadratic in the number
of variables in C [5], but we can sometimes tailor the
encoding of w to make n smaller [45].
Second, one set of the entries in w must be a redundant
encoding of the other entries. Third, w encodes the actual
satisfying assignment to C(X = x, Y = y).
A surprising aspect of PCPs is that each of these prop-
erties can be tested by making a small number of queries
to π; if π is constructed incorrectly, the probability that
the tests pass is upper-bounded by  > 0. A key test for
us—we return to it in Section 3—is the linearity test [16]:
V randomly selects q1 and q2 from Fn and checks if
π(q1) + π(q2) = π(q1 + q2). The other two PCP tests
are the quadratic correction test and the circuit test.
The completeness and soundness properties of linear
PCPs are deﬁned in Section 2.4. A detailed explanation
of why the mechanics above satisfy those properties is
outside our scope but can be found in [5, 13, 35, 45].
2.3 Our base: PEPPER
We now walk through the three phases of PEPPER [45],
which is depicted in Figure 1. The approach is to com-