Note, however,
it may be hard to distinguish events
triggered by adversary actions vs.
legitimate users. Rather
than introduce ad hoc anomaly detection algorithms to try
and differentiate legitimate vs. adversary-induced events, we
exploit the fact that the PSI design allows us to logically
partition the event handling across different trafﬁc classes. That
is, we can simply horizontally scale the PSI controller and add
more instances as needed depending on the offered load [32],
[45]. This is especially easy because the different trafﬁc classes
are independent and do not introduce any synchronization
bottlenecks at the controller.
that
We design a scale-out mechanism similar to elastic scaling
solutions in cloud deployments [4], [32]. While the elastic
scaling solutions only migrates switches states, PSI’s scale-
out mechanism migrates device attributes, security states and
policy speciﬁcations within the predicates, ψFSM and ψDAG
structures. A simple runtime monitor inspects the response
time for each controller instance. If the response time is
starting to increase more than a preset threshold, it invokes
an elastic scaling routine that adds an extra control instance
and splits the trafﬁc classes currently handled by the over-
loaded instance across the added instances, and migrate the
corresponding structures.
8
Reac%ve	Controller	port	2(cid:1)(a)	reac%ve(cid:1)L-IPS	H-IPS	Egress(cid:1)port	(cid:2)(cid:1)PSI	Controller	port	2(cid:1)(b)	proac%ve(cid:1)L-IPS	H-IPS	port	(cid:2)(cid:1)Pkt1	normal		Pkt2	unknownIP(cid:1)Pkt1	port1	Pkt2	port2(cid:1)alert	tcp	any->	unknownIP-list	context(cid:1)tag(cid:1)normal(cid:1)(cid:2)(cid:1)unknownIP(cid:1) (cid:1)tag(cid:1)next-hop(cid:1)(cid:2)(cid:1)port	1(cid:1)2(cid:1)port	2(cid:1)alert	tcp	(content=<meta	";		content:"content=|22|IE=EmulateIE7|22|";	)	Egress(cid:1)(a) Stanford backbone network,
each oz is connected with 4 devices.
(b) A enterprise network that
suffers from a ﬁve-year RAT
APT [10].
Fig. 11: The dynamic scrutiny policy expressed via PSI
GUI.
4. ψmbox control channel: We also implement custom control
channels between the PSI controller and the individual
ψmboxes. These serve two purposes. First, they implement
ψmbox-speciﬁc messages for reconﬁguring policies; e.g.,
installing and updating ψmbox-speciﬁc conﬁgurations. Sec-
ond, these control the tagging behavior of the ψmbox to
enable the proactive tag-based forwarding scheme described
earlier.
5. Runtime scale-out: We implemented simple Java runtime
monitors to inspect the response time on each controller
instance. Once the response time exceeds a threshold, we
scale out the instance as follows. Suppose the stressed con-
troller instance is C1 , the corresponding runtime monitor
RM1 then: 1) launch a new instance C2 ; 2) ofﬂoad half
of the trafﬁc classes, and their F SM, N F DAG with the
F SM current state into a policy conﬁguration ﬁle and
send to C2 in a notify message. C2 then inputs the policy
conﬁguration ﬁle from RM1, and setup connections with the
related NFs and switches. Finally, C2 send a ACK message
to C1 and C1 closes the socket connections with the related
NFs and switches.
6. Composing ψFSM and scoping ψmbox instances: We
implemented an ψFSM composition module that can input
all policy intents that applies to a device and compose
the policy ψFSM by calculating the cross product of the
states, the union of events and the new transitions. To scope
ψmbox instances, we implemented a scoping scheme that
inputs the natural scoping order (a sequence of scope IDs)
from the administrator, assigning each ψmbox instance with
a corresponding scope ID, and steering all the trafﬁc in
scope through the instance, following the scoping order.
PSI data plane: To realize each ψmbox, we use virtual
machines. We chose this over alternatives like containers (e.g.,
Docker) as it offers stronger performance isolation across
different trafﬁc classes. We currently support several open
source security functions; e.g., NAT/ﬁrewalls using iptables,
IDS/IPS using Snort [57], proxies using Squid [23], and load
balancers using Balance [7]. Each ψmbox runs inside a VM;
we use Centos 6.5 as the host OS running the KVM hypervisor.
We set up simple tunnel-based forwarding rules at the ingress
(c) Enterprise with cisco PIX ﬁrewall.
Fig. 12: Evaluation topologies.
switch to steer the trafﬁc to the ψcluster. These ψmboxes need
two minimal extensions to integrate with PSI. First, we extend
the ψmbox implementations to support the addition of tags
to outgoing packets to enable the tag-based forwarding [36].
Second, we need to forward events/alerts to the PSI controller.
We implement this by having a light-weight PSI client program
that parses these alerts (e.g., Snort alerts) and forwards them to
the controller. This alert parsing program is conﬁgurable and
can be customized to only forward relevant events to reduce
the control plane load.
VII. EVALUATION
In this section, we evaluate PSI to show that:
• Security beneﬁts: When working against stealthy attacks,
PSI identiﬁes and mitigates 35% more attacks than a dis-
tributed Firewall/IPS solution. PSI is able to more effectively
implement complex distributed solutions. PSI eliminates the
logical interference and reduces the performance interfer-
ence damage by 85%.
• Scalability,
responsiveness and resilience: Proactive
context-based forwarding reduces the end-to-end latency by
at least 10X over the baseline performance. PSI’s ψDAG
prefetching mechanism reduces security downtime during
ψFSM transitions from seconds scale to zero. With the
optimizations, a single PSI controller can support a network
with 100K devices, and can support complex policies with
up to 10 states with a size-10 DAG for each state. Our scale-
out scheme cuts the response time down to 10ms even in
the presence of an adversary.
Since PSI is an enabler for existing/emerging security tools,
not a new detection algorithm for a speciﬁc attack, we evaluate
the beneﬁts for a whole enterprise network (coverage over
attack paths, collateral damage) rather than show the ROC
(receiver operating characteristic) curve (FP vs. FN) for a
particular end-point.
Experimental Testbed: Our experiments run on a cluster
of 12 Dell R720 machines, each with 20-core 2.8 GHz Xeon
9
ψFSM	ψDAG	Predicate	sip:10.2.0.1,	sport:any,	sMAC:	any,		dip:$EXT,	dport:80,	dMAC:	any,	proto:6		1/29/2016Cy3 Import Demofile:///Users/tianlongyu/Documents/Projects/PSI/github/Topology/Topology/index.html1/1 #Enforcement r1 r2r1 s1r1 s2r1 s3r1 s4r1 s5r2 s6r2 s7r2 s8r2 s9r2 s10 s1 oz1b s1 oz5b s2 oz3a s2 oz4b s3 oz3b s3 oz6b s4 oz1a s4 oz2a s4 oz5a s4 oz7a s5 oz2b s5 oz2b s5 oz7b s6 oz1a s6 oz5b s7 oz3a s7 oz6a s8 oz3b s8 oz6b s8 oz6b s9 oz2a s9 oz7a s10 oz2b s10 oz7b1/30/2016Cy3 Import Demofile:///Users/tianlongyu/Documents/Projects/PSI/github/Topology/Topology/index.html1/1 #Enforcement Internet s5 s5 s1s5 s4s5 s6s1 host1 s1 host2 s1 host3 s4 s2s4 s3s6 host5 s6 host6 s2 host4 s2 server1s2 server3s2 APAP laptop AP Mobile s3 server1s3 server2s3 server3s3 server41/30/2016Cy3 Import Demofile:///Users/tianlongyu/Documents/Projects/PSI/github/Topology/Topology/index.html1/1 #Enforcement ISP1 r1 ISP2 r2 r1 r2r1 PIX1 r1 PIX2 r2 PIX1 r2 PIX2 PIX1 PIX2 PIX1 s1 PIX1 s2 PIX1 s3 PIX1 AP s1 host1 s1 host2 s2 host2 s2 server1s2 server2s2 server3s3 server3s3 server4AP laptop AP mobile PIX2 s2 PIX2 s3 PIX2 s4 s4 s5s4 server7s4 server8s4 s5s5 server5s5 server6CPUs and 128GB of RAM. A single PSI controller is running
on a VM with CentOs 6.5, assigned with 4 cores and 8GB
RAM. On the testbed, we setup three typical enterprise/campus
topologies as shown in Figure 12, details about the topologies
are given in Table I. We use 1 Dell R720 machine as the PSI
ψcluster. To stress test our setup (controller scalability/over-
loading from adversary), we extended the cbench tool [68]
to emulate IDS/IPS alerts in large enterprise-like settings.5
Topology
mini-stanford [42]
apt-mcafee [10]
pix-cisco [22]
Devices
Switches
Information
Stanford backbone network
Enterprise
network with
APT, reported by McAfee
Enterprise
Cisco PIX ﬁrewall
TABLE I: Experiment topologies.
network with
56
12
14
12
6
8
A. Security Beneﬁts for Network Structure
We now show how PSI’s context-aware, dynamic and
isolated approach can mitigate stealthy attacks and reduce the
collateral damage caused by logic&performance interference.
Here a stealthy attack is one where the attacker can exploit
a blind spot in network design to circumvent defenses. For
example, an insider threat that originates within a network,
evading all outward-facing defenses. In this section, we con-
duct two analyses. First, we compare PSI against distributed
Firewall/IPS approach by evaluating their capabilities to pre-
vent potential insider threats and APT (Advanced Persistent
Threats) in three sample enterprise networks. Second, we use
real enterprise policy and manipulated enterprise trafﬁc to
show how PSI’s isolation mechanism can effectively reduce the
collateral damage caused by logic/performance interference.
Coverage over stealthy attacks: We now evaluate PSI’s
ability to deal with stealthy attacks. To do so, we conduct an
attack graph analysis against two example stealthy attacks: an
example insider threat attack and an example APT. We com-
pare distributed Firewall/IPS’s and PSI’s ability to detect and
mitigate both attacks over three different network topologies
shown in Table I. Through this analysis, we show that PSI
is capable of identifying and mitigating 35% more potential
stealthy attacks than a distributed Firewall/IPS approach, as
demonstrated in Table II. These results are due to topological
blind spots that PSI is designed to address, and which are
common on live enterprise networks such as the examples in
Table I.
integrates the structural
Attack graph analysis [61] evaluates defensive systems via
graph coverage. Each attack is expanded to a graph showing
the potential routes the attacker can use to achieve their goals,
and defenses are evaluated by comparing the number of paths
each defense cuts off from the attack. We chose attack graph
analysis because it
impact of the
network’s design on the attack’s effectiveness, and enables us
to identify the cause of defensive failure. Our attack graphs
consist of a tree, G, where each node is a device on the
network, and each edge is an attack step. In G, an attack
is a path from the root device (the source of the attack) to
the leaf (target), e.g., an malware exploit from a laptop to a
server through a local switch. An attack is prevented if one
step of the attack is detected and prevented by the defense
system, e.g., a IPS connected to the switch detects and blocks
5cbench only supports simple OpenFlow messages by default.
the malware trafﬁc. This yields a coverage metric of the form:
coverage = num. of prevented attacks
num. of all possible attacks. This coverage metric
evaluates how many potential attacks are prevented in a given
network topology.
distributed Firewall/IPS Coverage
Topology
mini-stanford [42]
apt-mcafee [10]
pix-cisco [22]
all
92%
91%
89%
91%
TABLE II: Coverage over stealthy attacks.
52%
59%
56%
56%
PSI Coverage
In our evaluation, we instantiate the three enterprise net-
works in Table I in our testbed and install distributed Fire-
wall/IPS and PSI respectively. For distributed Firewall/IPS,
we assume there are no resource constraints and deploy a
distributed instance at every switch in the topology. To setup
insider threats in each enterprise network, each time a device
is set as an insider and it exﬁltrate data from all other devices
using ftp-based exﬁltration or DNS-based exﬁltration [2]. For
APT, we setup a device in external network as an attacker,
and assume it can always break-in with a zero-day attack. We,
then, use two pcap traces (Angler EK and Magnitude EK [15])
to emulate the following port-scanning and exploits phases of
the APT attack and see if the exploit trafﬁc can reach another
device (if yes, the APT attack on the device is valid).
Fig. 13: Detailed results about coverage for insider threats
and APT in each enterprise network.
The detailed evaluation results are presented in Figure 13
and Table II. In summary, out of 428 potential attack paths,
distributed Firewall/IPS mitigates 240 paths (56% coverage),
while PSI mitigates 392 potential paths (91% coverage). We
analyzed the 152 paths that PSI mitigated but distributed
Firewall/IPS did not—all of them are caused by one or more
fundamental topology constraints that distributed Firewall/IPS
cannot address. Speciﬁcally, 103 paths involve NAT/DHCP;
75 paths involve devices connected to multiple switches (e.g.,
For high bandwidth or failure tolerance [20]); and 54 paths
involve dumb, unmanaged switches. PSI cannot provide perfect
coverage because ﬁrst step, a zero-day attack, is undetectable.
In summary, PSI improves the coverage for stealthy attacks by
35%.
Logical interference: Now, we evaluate the defense system’s
ability to reduce logical interference. To do so, we take real
ACL policies [22] from enterprise/campus networks and see if
distributed Firewall/IPS conﬁguration or PSI policy language
causes any logical interference when expressing them. The
ACL policies are already expressed as distributed Firewall/IPS
conﬁgurations by the administrator; 249 are expressed using
Cisco PIX, 65 policies using Juniper SRX, and 34 using
iptables. We use Springbok [22], an automated ﬁrewall miscon-
ﬁguration checking tool using the mechanisms in Fireman [74],
10
mini-stanfordapt-macafeepix-ciscoMitigated Path Num.050100150Distributed Firewall/IPSPSITotal Path Num.APTInsiderInsiderAPTInsiderAPTto check the logical interference in the distributed Firewall/IPS
conﬁgurations. Springbok checks for three types of logical
interferences: shadowing, redundancy and correlation; in each
case a packet is speciﬁed with two interfering actions (pass/-
drop). Then, we express all 348 policies using PSI policy
abstraction and check the logical interference with a Springbok
implementation extended to support PSI policies.
System
Cisco PIX
Jupiter SRX
Iptable
PSI
policies
249
65
34
348
Shadowing
8
5
4
0
Redundancy
14
5