arc-injection or ROP attacks must jump to the start of an
instruction, and not bytes located within an instruction.
C. Running an ILR-protected Program
To apply the rewrite rules generated by the static analysis
steps, ILR uses a speciﬁc ILR VM. We believe that a
per-process virtual machine (PVM) is the best choice for
the ILR VM since it can be easily deployed and has low
performance and runtime overheads [11, 18, 19]. Figure 5
shows a typical PVM augmented with ILR extensions. The
following paragraphs provide a brief introduction to typical
PVM operation, and describe those extensions.
PVMs dynamically load an application and mediate ap-
plication execution by examining and translating an applica-
tion’s instructions before they execute on the host CPU. Most
PVMs operate as co-routines with the application that they
are protecting. Translated application instructions are held in
a PVM-managed cache called a fragment cache. The PVM is
ﬁrst entered by capturing and saving the application context
(e.g., program counter (PC), condition codes, registers, etc.)
Following context capture,
the PVM processes the next
application instruction. If a translation for this instruction
has been previously cached, the PVM transfers control to
the cached translated instructions.
If there is no cached translation for the next application
instruction, the PVM allocates storage in the fragment cache
for a new fragment of translated instructions. The PVM then
populates the fragment by fetching, decoding, and translating
application instructions one-by-one until an end-of-fragment
condition is met. As the application executes under the
PVM’s control, more and more of the application’s working
set of instructions materialize in the fragment cache.
Implementation of ILR within a PVM requires several
simple extensions to a typical PVM. First, we must modify
the PVM startup code to read the ILR rewrite rules (not
pictured). Next, we need to override the PVM’s instruction
fetching mechanism to ﬁrst check,
then read from ILR
rewrite rules as appropriate. Lastly, we need to modify the
next-PC operation to obey the fallthrough map that ILR
provides in the rewrite rules.
to allow the program to attempt
One further extension is necessary for security. The
PVM must take steps to protect itself and its code cache
from being compromised by a program that an attacker
is attempting to control. Since the PVM typically shares
an address space with the program, the PVM must take
care not
to jump into
the PVM’s code. Further,
the
randomized instruction addresses from being leaked to the
user. Such protections can be accomplished by making the
PVM’s code and data unaccessible via standard memory
protection mechanisms whenever the untrusted application
code is executing. We discuss the technical details of one
mechanism in Section V-A.
the PVM should prevent
IV. EVALUATION
A. Prototype Implementation
Our development and evaluation system were based on
a Linux kernel version 2.6.32-34-generic as part of our
Ubuntu 10.04.03 LTS release conﬁgured with gcc 4.4.3.
We used IDA Pro version 6.1, and objdump version
2.20.1-system.20100303 [17].
As the static analyzer components need to store in-
structions, functions, and indirect branch targets, we used
a Postgres database. This choice turned out
to be wise
considering some programs we evaluated contained almost
half a million instructions. Each instruction is marked as
being part of a function, and whether is has been detected
as a possible indirect branch target.
575
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:49:42 UTC from IEEE Xplore.  Restrictions apply. 
We implemented the disassembly validator, call site anal-
ysis, indirect branch target analysis and reassembly engine
to access the database and deposit their information back to
the database. This modular design turned out to be useful
for implementing, debugging, and deploying the system.
Our implementation of the reassembly engine is split
into two phases. The ﬁrst phase reads the database and
emits a symbolic, relocatable, assembly version of the ILR
rewrite rules to a ﬁle on the ﬁle system. The second step
performs the randomization, and binds the assembly version
of instructions to a machine code form. Splitting the tool into
two portions aids in re-randomization (as the full database
of instructions is no longer necessary) and run time (as the
database need not be accessed at runtime).
Our ILR VM is based on Strata [11]. The modiﬁcations
for ILR required about only 1K lines of code.
While our prototype implementation is based on the tools
and operating system above, we believe our techniques are
general, and can be easily applied to any hardware, operating
system, PVM, or executable format.
B. Experimental Setup
We evaluated the effectiveness and performance of
the ILR prototype using the SPEC CPU2006 benchmark
suite [16]. These benchmarks are state-of-the-art, industry-
standardized benchmarks designed to stress a system. The
benchmarks are processor, memory and compiler stressing.
The benchmarks are provided as source, and we compiled
them with gcc, g++, or gfortran (as dictated by the pro-
gram’s source code) version 4.4.3 before applying our ILR
technique. The benchmarks are compiled at optimization
level -O2, and use static linking. We used static linking
to thoroughly demonstrate the effectiveness of our system
at randomizing large bodies of code, and to fully test
the system using all the odd, compiler-speciﬁc, language-
speciﬁc, hand-coded, or otherwise abnormal code that is
often found in libraries. Furthermore, having all the code
packaged into one executable increases the attack surface
making it easier to locate an ROP gadget. Thus, we believe
our evaluation is a worst-case analysis for these benchmarks.
We run our experiments on a system with a 4-core, AMD
Phenom II B55 processor, running at 3.2 GHz. The machine
has 512KB of L1 cache, 2MB of L2 cache, 6MB of L3
cache, and 4GB of main memory. Performance numbers are
gathered by averaging 3 runs of each benchmark. Unless
otherwise noted, the performance of a protected binary is
reported by normalizing its run time to the run time of the
corresponding original binary produced by the compiler.
C. Security-Related Experiments
To verify that our technique stops attacks that are suc-
cessful against ASLR and W⊕X protected systems, we
performed a number of tests on vulnerable programs. For
each test, ASLR and W⊕X were enabled.
In the ﬁrst test, we used a small program (44 lines of
code) that had a simple stack-based buffer overﬂow. The
program assigns grades to students based on the program’s
input, the student’s name. A malicious input can cause a
buffer overﬂow enabling an attack.
We created a simple arc-injection attack which causes
the program to print out a grade of B when the student
should receive a D. It was trivial to perform the arc-injection.
ASLR was ineffective because no randomized addresses
were used—only the unrandomized addresses in the main
program. Similarly, W⊕X was ineffective because the attack
only relied on instructions that were already part of the
program. We also used a tool called ROPgadget [20] to craft
an ROP attack that causes the program to start a shell which
can execute an arbitrary command. Again, ASLR and W⊕X
were ineffective. ILR, however, thwarted the attack.
We next veriﬁed our technique against a vulnerability
in a realistic program: a Linux PDF viewer, xpdf. We
seeded a vulnerability in the input processing routines. An
appropriately long input can trigger a stack overﬂow. In this
case, we were able to use ROPgadget to craft an attack to
create a shell. ILR was again able to prevent the attack.
Lastly, we used version 9.3.0 of Adobe’s PDF viewer,
acroread,
that we downloaded from Adobe’s website
in binary form. The program has a well-documented vul-
nerability when parsing image ﬁles (see CVE-2006-3459)
that allows arc-injection and ROP attacks [21]. Again, we
used ROPgadget to craft an ROP attack payload for this
vulnerability to start a shell program. Because exploiting the
vulnerability is more complicated, it took additional effort
to adapt the attack. Using information from Security Focus’s
website, we were able to create a malicious PDF ﬁle that
effected the ROP attack [21]. ILR successfully processes and
randomizes the 24MB executable, and thwarts the attack.
Section IV-E discusses ILR’s effect on the use of such
tools as ROPgadget, and Section V-B describes how ran-
domized addresses needed for the attack are protected from
exﬁltration by the ILR VM. Consequently, we believe attacks
using programs such as ROPgadget are not possible with
ILR.
D. Effectiveness of ILR Components
1) Disassembly Engine: The goal of the Disassembly
Engine is to locate any instruction which might be exe-
cuted, so that the instruction can be relocated later. For
our benchmarks, we found that
the disassembly engine
successfully located 100% of the executed instructions for
all benchmarks. The Disassembly Engine has met its ﬁrst
goal. We omit further discussion on disassembly as such
techniques are well studied [22–24].
A secondary goal of the Disassembly Engine is to intro-
duce few conﬂicting facts about instruction locations into
the database. We measured the fraction of bytes in the exe-
cutable segments that belonged to more than one instruction.
576
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:49:42 UTC from IEEE Xplore.  Restrictions apply. 
On average, only 0.005% of bytes were represented as part
of more than one instruction with the worst-case having
only 0.012% of bytes in conﬂict. Thus, we believe that the
disassembly engine has met its second goal.
2) Call Site Analysis: Figure 6 shows the percentage of
call sites marked as safe to randomize their return addresses.
The ﬁrst bar shows that our technique works well for some
benchmarks. 403.gcc, for example, has 91% of the return
addresses randomized while 416.gamess reaches 97%.
Other benchmarks do not perform as well; 447.dealII
and 483.xalancbmk only manage to identify 5% and 3%
of return addresses as randomizable. The C++ benchmarks
(447.dealII, 450.soplex, 453.povray, 470.lbm,
and 471.omnetpp) do especially poorly. Only 10% of
calls can use a randomized return address.
To understand why the call site analysis phase was less
effective on some benchmarks, we examined the reasons
that the call site analysis indicated that a randomized return
address could not be used. Figure 7 shows the results as a
fraction of all call instructions. We ﬁnd that indirect calls
(which cannot use a randomized return address because
our analysis does not attempt to determine possible targets)
result in a small fraction of unrandomized return addresses,
resulting in 5% of calls on average. Possible non-standard
uses of the return address, such as thunks, result in only
7.6% of return addresses. Interestingly, we ﬁnd that direct
call instructions to targets that we were not able to include in
our disassembly result in 1.2% of the total call instructions.
Closer inspection indicates that
the compiler is actually
emitting a call 0x0 instruction in many library functions.
If this type of call
it
would cause a fault in the program, but the call instruction
is (dynamically) unreachable code. The compiler cannot
detect this fact, and so cannot eliminate the call. A minor
improvement would randomize the return address for this
type of call, knowing that the return address cannot be used
if the call instruction causes a fault. Together, these causes
represent only 21% of all unrandomized call instructions.
instruction were to ever execute,
The top bar in the ﬁgure shows the real cause of the poor
performance, especially in C++ programs. More than 32% of
call instructions are marked as not being able to randomize
the return address because of the exception handling tables
used in the ELF ﬁle. In the C++ programs, this number
jumps up to an average of 79%! In C++ programs, the
compiler typically cannot calculate when a function, f,
makes a call, whether the called function will throw an
exception and need to clean up f’s stack. Consequently, the
C++ compiler emits cleanup code into f, and adds to the
.eh_frame and .gcc_except_table ELF sections
to drive the exception handling routines. Because most
functions with a call site ﬁt this form, most call instructions
cannot have a randomized return instruction.
It is interesting that even the C and Fortran benchmarks
use the exception handling table. The C/Fortran benchmarks’
application code does not seem to directly add to these
tables. Instead, the table entries come from library routines
that are compiled to work with C++ source.
We believe that modifying the ILR toolchain to edit the
exception handling tables to reﬂect the randomization would
be feasible. The tables are in a ﬁxed, known format and
can easily be rewritten with randomized addresses. Other
solutions are possible as well. For example, detecting if
C++ exception handling is actually used in the program or
a portion of the program would allow return address ran-
domization to be selectively applied. While fully exploring
this idea is beyond the scope of this paper, we were able to
modify our ILR toolchain to ignore the exception handling
tables when calculating safe calls. We term the ILR toolchain
with this modiﬁcations ILR+. ILR+ represents a very close
approximation to a system that could easily be achieved by
rewriting the exception handling tables in a binary.
With ILR+, the call site analysis performs well across all
benchmarks. As Figure 6 shows, 93% of all calls are marked
as using a randomized return address.
3) Indirect Branch Target Analysis: We continue our
evaluation of ILR by measuring the effectiveness of the
analysis of indirect branch targets (including return ad-
dresses). Figure 8 shows the fraction of instructions detected
as possible indirect branch targets. On average, only 2.2%
and 0.60% of the instructions are marked as indirect branch
targets for ILR and ILR+, respectively. Consequently, we
believe our scheme for detecting possible IBTs is not too ag-
gressive in marking instructions as possible indirect branch
targets.
4) Moved Instructions: Because we emit rewrites for
every byte of the executable segment, technically all instruc-
tions are moved. However, IBTs get a rule that maps the
unrandomized address to the relocated instruction. Despite
technically being moved, we consider this an unmoved (or
pinned) instruction because if an attacker were to inject an
arc or locate an ROP gadget at the unrandomized address,
they could still exploit that information in the randomized
program.
Figure 9 shows the percentage of instructions moved
for our benchmarks. The ﬁrst bar shows the effectiveness
of ILR without call site analysis; approximately 95.0% of
instructions were successfully and safely located at random-
ized addresses. The second bar shows call site analysis for
standard ILR; 97.4% of instructions are moved. The last bar
shows the results for ILR+, almost all instructions (99.1%)
are assigned to a randomized location in memory. This
randomization represents a two order of magnitude reduction
in the attack surface for arc-injection and ROP attacks.
E. ILR Security
To assess the security of ILR, we ﬁrst note that up to
99.7% of the instructions can be randomized. Furthermore,
all of the executable bytes of a program that do not make
577
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:49:42 UTC from IEEE Xplore.  Restrictions apply. 

Ĩ
Ž

Ɛ
Ğ
Ő
Ă
ƚ
Ŷ
Ğ
Đ
ƌ
Ğ
W

Ɛ
Ŷ
Ž
ŝ
ƚ
Đ
Ƶ
ƌ
ƚ
Ɛ
Ŷ
/

ů
ů
Ă

ϭϬϬй
ϵϬй
ϴϬй
ϳϬй
ϲϬй
ϱϬй
ϰϬй
ϯϬй
ϮϬй
ϭϬй
Ϭй
Đ
Đ
Ő
͘
ϯ
Ϭ
ϰ
Ϯ
Ɖ
ŝ
ǌ
ď
ϭ
Ϭ
ϰ
͘
Ɛ
Ğ
ǀ
Ă
ǁ
ď
Ϭ
ϭ
ϰ
͘
Ɛ
Ɛ
Ğ
ŵ
Ă
Ő
͘
ϲ
ϭ
ϰ
Ĩ
Đ
ŵ
ϵ
Ϯ
ϰ
͘
Đ
ů
ŝ
͘
ŵ
ϯ
ϯ
ϰ
Ɖ
ŵ
Ɛ
Ƶ
Ğ
ǌ
͘
ϰ
ϯ
ϰ
Ɛ
Đ
Ă
ŵ
Ž
ƌ
Ő
͘
ϱ
ϯ
ϰ
Ś
Đ
Ŷ
Ğ
ď
ů
ƌ
Ğ
Ɖ
Ϭ
Ϭ
ϰ
͘
D


Ɛ
Ƶ
ƚ
Đ
Ă
Đ
͘
ϲ
ϯ
ϰ
Ě
ϯ
Ğ
ŝ
ů
Ɛ
Ğ
ů
͘
ϳ
ϯ
ϰ
Ě
ŵ
Ă
Ŷ
ϰ
ϰ
ϰ
͘
Ŭ
ŵ
ď
Ž
Ő
͘
ϱ
ϰ
ϰ
/
/
ů
Ă
Ğ
Ě
ϳ
ϰ
ϰ
͘
ů
ǆ
Ğ
Ɖ
Ž
Ɛ
͘
Ϭ
ϱ
ϰ
Ǉ
Ă
ƌ
ǀ
Ž
Ɖ
ϯ
ϱ
ϰ
͘
ǆ
ŝ
ů
Ƶ
Đ
ů
Ă
Đ
͘
ϰ
ϱ
ϰ
ƌ
Ğ
ŵ
ŵ
Ś
ϲ
ϱ
ϰ
͘
Ő
Ŷ
Ğ
ũ