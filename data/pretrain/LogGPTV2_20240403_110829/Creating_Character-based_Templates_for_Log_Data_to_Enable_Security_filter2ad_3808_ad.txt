merge last change
length last change
original maxfirst maxdist mindist
96.47%
96.38%
96.24%
96.26%
96.44%
96.37%
96.38%
95.18%
93.55%
82.76%
82.06%
92.93%
93.06%
82.21%
70.87%
78.63%
96.43%
96.40%
96.41%
96.37%
71.35%
70.57%
70.66%
67.25%
96.44%
96.41%
96.42%
96.38%
76.20%
74.96%
74.94%
67.84%
Therefore, we changed the order of the log lines in the clusters as
follows:
(i) The original order (original),
(ii) starting with the two lines that have the maximum LV-distance
in the whole cluster and the following lines have the original
order (maxfirst),
(iii) ordering the lines by the LV-distance to each other start-
ing with the line that has the largest distance to the others
(maxdist),
(iv) ordering the lines by the LV-distance to each other starting
with the line that has the smallest distance to the others
(mindist).
Table 5 summarizes the results of the cluster arrangement evalu-
ation carried out on the first 10.000 lines of the data set DS-A. The
lower part of the Table shows after processing which percentage of
log lines in a cluster the template does not change any more. Our
evaluation proves, that the order has impact on the number of pro-
cessed log lines after which the template does not change anymore
and therefore on the runtime. Ordering the lines by the LV-distance
to each other starting with the line that has the largest distance to
the others (maxdist) showed the best results, closely followed by
starting with the two lines that have the maximum LV-distance and
the following lines have the original order (maxfirst). Those two
approaches improve the runtime in opposite to keeping the origi-
nal order, while using the mindist approach increases the runtime.
However, there was virtually no impact on the Sim-Score as the
upper part of Tab. 5 points out. Since ordering the lines within a
cluster by their LV-distance is computational expensive with O(nn),
where n is the number of lines, the runtime improvement can only
be realized when the lines are already in the correct order.
Additionally, Fig. 9 visualizes the progression of the change in
the number of characters the template of a representative cluster
consists of. Therefore, we plotted the number of characters the
current template exists of over the number of processed lines for the
four different cluster arrangements. The figure demonstrates that
for the maxfirst and maxdist arrangement the template gets stable
after a few lines, while the mindist arrangement, requires major
changes in the template towards the end. The original arrangement
lies between the others.
5.5 Cluster arrangement
We also investigated the impact of the order of the log lines in a
cluster on the resulting template and the process of generating it.
5.6 Evaluation of different data set sizes
In this section, we evaluate the influence of the data set size on the
resulting templates. Therefore, we compared the Sim-Score of the
(a) Merge algorithm
(b) Length algorithm
(c) Equalmerge algorithm
(d) Token_char algorithm
Figure 8: Runtime comparison.
5.7 Robustness
Furthermore, we evaluated the robustness of the algorithms, which
is especially important for the length and the equalmerge algo-
rithm. Since these two algorithms first mark parts of the template
that equally occur in the currently processed log line, they imitate
longest common subsequence [1]. This might cause problems, if
the lines within a cluster are different, but substrings in different
positions are marked as equal, due to the fact that there are many
variable parts in the log lines. Considering the strings ayyaa, aayya,
aaa, the optimal template would be a[*]a[*]a, but because the
first created template would be [*]ayya[*], the final template be-
comes [*]a[*]a[*], which leads to a lower similarity between the
strings and the template.
Additionally, the localizing step in the length and equalmerge
algorithm could be erratic, when the template includes two equal
blocks, that only occur once in the currently processed log line.
Therefore, a false marking can happen. For example, considering
the strings stringstring, string string and tring string.
The first two yield the template string[*]string, but because the
algorithm localizes the first block in the rearmost part of the log line,
the second block is marked with the empty string. Thus, the created
template would be [*]string[*], although [*]tring[*]string
would be the the optimal one.
Hence, we ran the algorithms on the first 10k lines of data set DS-
A, which was clustered using different similarity thresholds. The
lower the threshold during clustering, the more dissimilar are the
log lines within a cluster. In this way we can evaluate the effects of
the marking step in the length and equalmerge algorithm, because
which blocks are marked as substrings in the log line depends on
the similarity of the log lines in a cluster. The effects can be seen
when comparing the Sim-Score of the length and the equalmerge
algorithm with the results of the merge algorithm, which does not
include the marking step.
Table 7 demonstrates that there is no extensive decrease of the
Sim-Score in either of the algorithms, which is only the case if the
marking had a severe impact. Therefore, all of the algorithms can
be considered robust.
Figure 9: Progression of cluster template character number
Table 6: Evaluation of different datasets.
data size
merge Sim-Score
length Sim-Score
equalmerge Sim-Score
token char Sim-Score
50K
10K
1600K
96.38% 95.79% 94.99%
96.24% 95.44% 94.40%
96.37% 95.71% 94.73%
95.18% 93.53% 93.26%
whole data set DS-A, a subset consisting of the first 10.000 lines and
a subset of the first 50.000 lines. The results, summarized in Tab. 6,
indicate a small decline in the Sim-Score with increasing data set
size. This can be explained as follows: The larger the data set, the
more log lines are assigned to each cluster. Therefore, the similarity
of the log lines within a cluster decreases, which as described in
Sec. 5.4, affects the Sim-Score of the template. But, the lower Sim-
Scores do not refer to templates of lower quality. Indeed, while the
Sim-Score only slightly decreases, over-fitting is reduced. Hence,
the quality of the templates actually increases, because of the more
diverse set of log lines, which more accurately reflects the system
behavior. Finally, we can conclude that the data set size does not
strongly affect the quality of the resulting template.
Table 7: Robustness evaluation for different minimum sim-
ilarities between log lines within a cluster.
similarity
merge
length
equalmerge
token_char
0.9
0.8
0.7
0.6
0.5
96.38% 91.14% 82.76% 74.97% 71.09%
96.24% 90.48% 81.25% 73.76% 68.49%
96.37% 90.98% 82.34% 74.31% 70.64%
95.18% 90.47% 82.04% 73.85% 69.41%
Table 9: Comparison of performance and accuracy.
Algorithm Performance Accuracy
merge
length
equalmerge
token_char
token
- -
+
+
âˆ¼
++
++
+
++
+
- -
Table 8: Test against character-based ground truth: H F-score
is the F-score for the Hadoop data set and TB F-score the F-
score for the thunderbird data set.
H F -score
TB F -score
merge
0.9910
0.9958
length
0.9902
0.9941
equalmerge
0.9910
0.9958
token_char
0.9910
0.9958
token GT
0.8853
0.9296
5.8 F-score evaluation
Since the F-score requires a ground truth, we chose data sets from
Hadoop and Thunderbird available on the Internet [7], where these
data sets each have 2000 lines and the corresponding token-based
ground truths are also available. We created the character-base
ground truths, which are the optimal template, based on the token-
based ground truths.
The F-score was calculated for each algorithm as described in
Sec. 5.2. Furthermore, we also tested the token-based ground truth
against the character-based one. Since the token-based ground truth
(token GT) is the optimum which token-based template generators
can achieve, the resulting F-Score is the maximum any token-based
approach can reach.
Table 8 presents the results of the F-score evaluation. The evalua-
tion proves that all character-based algorithms yield more accurate
templates than a token-based ever could. Merge, equalmerge and to-
ken_char provide the best F-score, followed by the length algorithm
and the token ground truth. The F-scores of merge and equalmerge
are the same, because they both created the same templates for
these sets of log data. The token_char algorithm also had the same
F-score, but yielded different templates, because it placed the gaps
differently.
5.9 Feature Analysis
Finally, we assess the features of the different algorithms with re-
spect to performance and accuracy, which are summarized in Tab.
9. The merge algorithm provides the most accurate template ac-
cording to Sim-Score and F-score. However, it lacks performance
and therefore should not be applied for time critical tasks. The
length algorithm provides comparable accurate templates, while
optimizing performance in opposite to the merge algorithm. The
performance boost is achieved by marking blocks of the current
template that occur as substrings in the log line. Therefore, the
length of the strings for which the LV-distance has to be calculated,
can be significantly reduced. The equalmerge algorithm combines
the length and the merge algorithm and performs almost as good
as the length algorithm, while providing templates that are almost
as accurate as the ones computed by the merge algorithm. The
token_char algorithm performs slightly better than the merge al-
gorithm, but is surpassed by the performance of the length and
equalmerge algorithms. Moreover, the templates provided by the
pure character-based approach are more accurate. Hence, we rec-
ommend for any application to apply the equalmerge algorithm
instead of the token_char approach. The pure token-based approach
shows the best performance, while providing the least accurate tem-
plates. Additionally, all the disadvantages mentioned in the Sec. 1
have to be considered when applying token-based approaches for
generating templates.
6 CONCLUSION AND FUTURE WORK
In this paper we introduced a novel approach for generating charac-
ter-based templates for computer log data. The goal was to provide
meaningful cluster descriptions that support further manual and au-
tomatic analysis of clustered log data, such as review of the current
system behavior by a system administrator and parser generation
to enable, for example, anomaly detection. Hence, to achieve this
goal, we had to develop a method to calculate multi-line alignments
for any group of strings. For this purpose, we designed four differ-
ent algorithms that combine comparison-based procedures with
heuristics to compute approximations of the optimal multi-line
alignments.
In a detailed evaluation carried out on three different log data
sets, we calculated a newly defined Sim-Score and the F-Score for
the four different approaches. The results show the high quality of
the character-based templates. All algorithms reached an F-Score
higher than 0.99. Furthermore, we demonstrated linear scalability
with respect to the number of lines within a cluster and showed
the robustness of our algorithms. We also analyzed the influence
of the length of the data sets and the processing order of the log
lines. Finally, we conclude that the equalmerge approach yielded
the best results regarding performance and accuracy.
In the future, we plan to apply the proposed approach for gener-
ating character-based templates for log clusters, with purpose of
improving the generation of log data parsers and to enhance time
series analysis carried out on log data.
ACKNOWLEDGMENTS
This work was partly funded the EU H2020 project GUARD (833456)
and by the FFG projects DECEPT (873980) and INDICAETING
(868306).
REFERENCES
[1] Wael H Gomaa and Aly A Fahmy. 2013. A survey of text similarity approaches.
International Journal of Computer Applications 68, 13 (2013), 13â€“18.
[2] P. He, J. Zhu, S. He, J. Li, and M. R. Lyu. 2016. An Evaluation Study on Log
Parsing and Its Use in Log Mining. In DSNâ€™16: Proc. of the 46th Annual IEEE/IFIP
International Conference on Dependable Systems and Networks.
[3] Pinjia He, Jieming Zhu, Zibin Zheng, and Michael R Lyu. 2017. Drain: An online
log parsing approach with fixed depth tree. In 2017 IEEE International Conference
on Web Services (ICWS). IEEE, 33â€“40.
[4] D. Jurafsky and J.H. Martin. 2009. Speech and Language Processing: An Introduction
to Natural Language Processing, Computational Linguistics, and Speech Recognition.
Prentice Hall.
[5] Max Landauer, Florian Skopik, Markus Wurzenberger, and Andreas Rauber.
2020. System log clustering approaches for cyber security applications: A survey.
Computers & Security 92 (2020), 101739. https://doi.org/10.1016/j.cose.2020.
101739
[6] Max Landauer, Markus Wurzenberger, Florian Skopik, Giuseppe Settanni, and Pe-
ter Filzmoser. 2018. Dynamic log file analysis: an unsupervised cluster evolution
approach for anomaly detection. computers & security 79 (2018), 94â€“116.
https://github.com/logpai/logparser
[7] LogPAI. 2019. Log Analytics Powered by AI. Retrieved June 26, 2019 from
[8] Adetokunbo AO Makanju, A Nur Zincir-Heywood, and Evangelos E Milios. 2009.
Clustering event logs using iterative partitioning. In Proceedings of the 15th ACM
SIGKDD international conference on Knowledge discovery and data mining. ACM,
1255â€“1264.
[9] CÃ©dric Notredame. 2007. Recent evolutions of multiple sequence alignment
algorithms. PLoS computational biology 3, 8 (2007), e123.
[10] Risto Vaarandi. 2003. A data clustering algorithm for mining patterns from event
logs. In Proceedings of the 3rd IEEE Workshop on IP Operations & Management
(IPOM 2003)(IEEE Cat. No. 03EX764). IEEE, 119â€“126.
[11] Markus Wurzenberger, Max Landauer, Florian Skopik, and Wolfgang Kastner.
2019. AECID-PG: A Tree-Based Log Parser Generator To Enable Log Analysis.
In 2019 IFIP/IEEE Symposium on Integrated Network and Service Management (IM).
IEEE, 7â€“12.
[12] Markus Wurzenberger, Florian Skopik, Max Landauer, Philipp Greitbauer, Roman
Fiedler, and Wolfgang Kastner. 2017. Incremental clustering for semi-supervised
anomaly detection applied on log data. In Proceedings of the 12th International
Conference on Availability, Reliability and Security. ACM, 31.
[13] Wei Xu, Ling Huang, Armando Fox, David Patterson, and Michael I Jor dan. 2009.
Detecting large-scale system problems by mining console logs. In Proceedings of
the ACM SIGOPS 22nd symposium on Operating systems principles. ACM, 117â€“132.