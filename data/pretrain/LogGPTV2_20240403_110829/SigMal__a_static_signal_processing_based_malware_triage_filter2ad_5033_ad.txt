represents the mean values of the daily results and
the standard error.
dow experiments are presented in Fig. 10. We can see that
at t = 0.33, more than 50% of the recent daily samples can
be accurately detected as malicious or benign with a preci-
sion of 99.5% (standard error 0.000835). This can essentially
reduce about 50% of the resource requirements of a triage
system by avoiding further, more expensive, analysis.
Fig. 11 presents the detection results of all methods, when
applied to the sliding window dataset (i.e., samples from the
month of November 2012 as the training set, and the samples
from December 1st 2012 as the testing set). One can see that
the performance of other methods is less impressive in terms
of precision. The PE-heuristics-based method and CFG-
based method have a relatively larger recall. However, they
do not produce high precision results. In case of the CFG-
based method, its computation cost is another critical factor
that makes it unsuitable for large-scale malware triage.
5.5.3 Evaluation with the current AV labels
Notice that the detection results were checked with the
VirusTotal results obtained at the time of the submission to
Anubis. However, there is a possibility that some malware
may not have been detected by the majority of antivirus
vendors at that time. Moreover, antivirus vendors may not
eventually detect all malware. Hence, an accurate analysis of
such false positives is diﬃcult. Here, we are only interested
in how many malware samples SigMal could have detected
that AV vendors missed at the time of submission, but later
identiﬁed them as malware. We used an old dataset observed
in 2011, for which we have old antivirus labels retrieved from
VirusTotal during the time of the submission to Anubis. We
retrieved the latest antivirus labels for these samples. We
performed a simulated daily sliding-window experiment on
this dataset and re-evaluated our results with the updated
antivirus labels. We found out that SigMal could have de-
tected, on average, 70 malware samples per day before any
antivirus vendor detected them as malicious.
5.6 Limitations
In this section, we discuss the limitations of our approach.
Because our approach relies on instance-based learning, its
main limitation is that it can only detect malware similar to
what has already been observed. It cannot detect a zero-day
malware that is structurally dissimilar from the previously-
seen malware. This is a generic problem with any similarity-
Moving Database of Past Malware SampelsFeature Extractiono DSP featureso N-gramso PE-featureso CFGMachine Learning ClassifierMalwareBenignUnknownMalware fromlast w daysConstant Database of Benign SamplesNew unknown samplesfrom day nIncoming samples (in days)n-w                                    n-3        n-2        n-1         n          n+1       n+2      n+3                               n+w…..…..0.00.10.20.30.40.50.00.20.40.60.81.0Threshold (t)Precision and RecallPrecisionRecallmalware visualization method proposed in [20]. However,
our method diﬀers in the way we extract signals from the
sample using heuristics based on its PE structure. There
are several signal similarity features depending on the type
of signal (speech, image, video, seismic, and others). We re-
strict ourselves to image similarity features within the scope
of this paper. Some of the common image similarity fea-
tures are the Homogeneous Texture Descriptor (HTD) [28]
and the Color Layout Descriptor (CLD) [28]. The HTD is
a 96-dimensional texture-based image similarity descriptor,
where an image is ﬁltered over 48 sub-bands after which
the mean and standard deviation on each ﬁltered image are
grouped to form the feature vector. The CLD, on the other
hand, is a layout-based descriptor. The image is divided
into an 8x8 grid and the mean value of every grid block is
computed to obtain an 8x8 matrix. The Discrete Cosine
Transform is then computed and the top energy coeﬃcients
form the feature vector.
6.2 Static malware similarity
Diﬀerent approaches to static-feature-based malware anal-
ysis and triage systems have been proposed in the past. Most
of them use N-gram-based feature extraction [3, 9, 10, 13, 23,
29]. The recent work from Jacob et al. [9] studied the pre-
served statistical similarity over packed binaries and pro-
posed a packer-agnostic bigram-based similarity measure.
N-gram-based approaches are less scalable because of the
computationally expensive feature matching operation over
relatively large dimensionality of the N-gram feature space.
Jang et al. [10] proposed feature hashing to reduce the high-
dimensional feature space in malware analysis and imple-
mented feature hashing on N-gram based features. However,
its evaluation was performed on the clustering of an un-
packed malware dataset, and no benign samples were used
to test the accuracy of the system. A malware phylogeny
generation technique was proposed using N-perms to match
every possible permuted code [11]. Other packer-agnostic
approaches include the detection method based on features
extracted from the PE ﬁle structure [24, 26, 30, 31, 35]. Al-
though this approach is time eﬃcient, results show that
achieving high accuracy is diﬃcult.
Other work on static-features-based detection requires un-
packed code [5, 8, 10, 15]. With unpacked code, static fea-
tures can be extracted from the disassembled code. Hu et
al. [8] proposed function call graphs to implement an eﬃ-
cient nearest-neighbor search on a large graph database of
malware. Kruegel et al. [15] proposed extracting control-
ﬂow-graph from network streams to detect worms. We have
used CFG-based methods from [15] for the comparison of
approaches in our evaluation.
7. CONCLUSIONS
In this paper, we presented SigMal, a fast signal processing-
based malware similarity detection framework. It can op-
erate on both packed and unpacked samples, avoiding the
resource intensive unpacking process. We used heuristics
based on PE structure information to improve the signal
processing-based features. Our results showed that SigMal
outperforms all existing static malware detection methods in
terms of precision. Large-scale experiments on 1.2 million
recent samples, both packed and unpacked, observed over
three months demonstrated that our method can classify
50% of the incoming samples with above 99% precision.
Figure 11: Comparison of malware detection meth-
ods with a live malware feed (2012-12-01).
based malware detection system.
Malware can infect a benign executable by patching and
embedding malicious code into it. If the embedded content
is very small relative to the actual benign ﬁle-size, then the
infected ﬁle is likely to be considered similar to the benign
ﬁle. When we manually analyzed the false negatives, we
found that the majority of them were a patched system bi-
nary. For example, we found instances of TDSS rootkit that
embeds its code into a small existing .rsrc section of Win-
dows driver ﬁles, such as netbt.sys. We also found false
positive cases of benign input ﬁles, which were not present
in the benign dataset, but its infected version was present
in the malware dataset. These problems are also generic to
ﬁle-similarity based detection techniques. One countermea-
sure can be ﬂagging an input ﬁle as suspicious, if it is very
similar to a system ﬁle, but not exactly the same ﬁle.
If some strong cryptographic methods, such as AES, are
used by packers, it will be hard to ﬁnd statistical similar-
ity among such encrypted samples. If the block chaining is
enabled, this problem becomes almost impossible. Our ap-
proach is unable to identify similarity in such cases. How-
ever, the use of strong encryption itself can be considered
suspicious, which malware writers would want to avoid. In
fact, our experiment showed that the majority of antivirus
vendors mark packed executables as suspicious or malicious,
even if the original executables were benign.
As a targeted attack to our system, an adversary could
insert large unused sections with random data into an ex-
ecutable. This may cause our heuristics to select wrong
sections as important sections. Since it is likely that no pre-
vious sample matches with the random data, such samples
will be considered unknown. In a more crafted attack, an
adversary could embed code section of a benign executable
as its largest section. This will generate the exact same
feature vectors corresponding to those sections. However,
the malicious code still needs to be embedded in the ﬁle to
make the crafted executable malicious. Because of this, the
part of the feature vector generated from the entire ﬁle will
still be dissimilar from the feature vector of the actual be-
nign executable. Hence, the crafted attack will not match
completely with the benign executable.
6. RELATED WORK
6.1 Signal processing
The SigMal feature extraction method is similar to the
0.40.50.60.70.80.91.00.700.750.800.850.900.951.00RecallPrecisionlllllllllllllllllllllllllllllllllllllll0.700.750.800.850.900.951.00lSigMalNgram−basedPE−Heuristics−basedContro−flow−graph−based8. ACKNOWLEDGMENTS
This work is supported by the Oﬃce of Naval Research
(ONR) under grant N00014-11-10111, the Army Research
Oﬃce (ARO) under grant W911NF0910553, and the Na-
tional Science Foundation (NSF) under grants CNS-0845559
and CNS-0905537.
9. REFERENCES
[1] Anubis. http://anubis.iseclab.org.
[2] VirusTotal. http://www.virustotal.com.
[3] T. Abou-Assaleh, N. Cercone, V. Keselj, and
R. Sweidan. N-gram-based detection of new malicious
code. In Proc. of COMPSAC’04. IEEE, 2004.
[4] U. Bayer, P. Comparetti, C. Hlauschek, C. Kruegel,
and E. Kirda. Scalable, behavior-based malware
clustering. In Proc. of NDSS’09. Citeseer, 2009.
[5] E. Carrera and G. Erd´elyi. Digital genome
mapping–advanced binary malware analysis. In Virus
Bulletin Conference, 2004.
[6] J. G. Daugman. Complete discrete 2-d gabor
transforms by neural networks for image analysis and
compression. IEEE Transactions on ASSP, 1988.
[7] M. Douze, H. J´egou, H. Sandhawalia, L. Amsaleg, and
C. Schmid. Evaluation of gist descriptors for web-scale
image search. In ACM International Conference on
Image and Video Retrieval. ACM, 2009.
[8] X. Hu, T. Chiueh, and K. Shin. Large-scale malware
indexing using function-call graphs. In Proc. of
CCS’09. ACM, 2009.
[9] G. Jacob, P. M. Comparetti, M. Neugschwandtner,
C. Kruegel, and G. Vigna. A static, packer-agnostic
ﬁlter to detect similar malware samples. In Proc. of
DIMVA’13. Springer, 2013.
[10] J. Jang, D. Brumley, and S. Venkataraman. Bitshred:
feature hashing malware for scalable triage and
semantic analysis. In Proc. of CCS’11. ACM, 2011.
[11] M. Karim, A. Walenstein, A. Lakhotia, and L. Parida.
Malware phylogeny generation using permutations of
code. Journal in Computer Virology, 1(1), 2005.
[12] A. Karnik, S. Goswami, and R. Guha. Detecting
obfuscated viruses using cosine similarity analysis. In
Proc. of AMS’07, pages 165–170. IEEE, 2007.
[13] J. Kolter and M. Maloof. Learning to detect and
classify malicious executables in the wild. The Journal
of Machine Learning Research, 7:2721–2744, 2006.
[14] J. Kornblum. Identifying almost identical ﬁles using
context triggered piecewise hashing. Digital
investigation, 3:91–97, 2006.
[15] C. Kruegel, E. Kirda, D. Mutz, W. Robertson, and
G. Vigna. Polymorphic worm detection using
structural information of executables. In Proc. of
RAID’06. Springer, 2006.
[16] M. Labs. Mcafee threats report: Second quarter 2013.
Technical report, McAfee, 2013.
[17] P. Li, L. Liu, D. Gao, and M. K. Reiter. On challenges
in evaluating malware clustering. In Proc. of RAID’10.
Springer, 2010.
[18] B. S. Manjunath and W. Ma. Texture features for
browsing and retrieval of image data. IEEE Trans. on
Pattern Analysis and Machine Intelligence (PAMI),
18(8), Aug 1996.
[19] R. Moskovitch, D. Stopel, C. Feher, N. Nissim,
N. Japkowicz, and Y. Elovici. Unknown malcode
detection and the imbalance problem. J. Computer
Virology, 5(4):295–308, 2009.
[20] L. Nataraj, S. Karthikeyan, G. Jacob, and B. S.
Manjunath. Malware images: visualization and
automatic classiﬁcation. In Proc. of VizSec’11, VizSec
’11. ACM, 2011.
[21] A. Olivia and A. Torralba. Modeling the shape of a
scene: a holistic representation of the spatial envelope.
Intl. Journal of Computer Vision, 42(3):145–175, 2001.
[22] S. M. Omohundro. Five balltree construction
algorithms. Technical report, International Computer
Science Institute Berkeley, 1989.
[23] R. Perdisci and A. Lanzi. McBoost: Boosting
scalability in malware collection and analysis using
statistical classiﬁcation of executables. Computer
Security Applications, pages 301–310, Dec. 2008.
[24] R. Perdisci, A. Lanzi, and W. Lee. Classiﬁcation of
packed executables for accurate computer virus
detection. Pattern Recognition Letters, 29(14), 2008.
[25] R. Perdisci, W. Lee, and N. Feamster. Behavioral
clustering of http-based malware and signature
generation using malicious network traces. In Proc. of
NSDI, 2010.
[26] K. Raman. Selecting features to classify malware. In
InfoSec Southwest, 2012.
[27] C. Rossow, C. J. Dietrich, C. Grier, C. Kreibich,
V. Paxson, N. Pohlmann, H. Bos, and M. van Steen.
Prudent practices for designing malware experiments:
Status quo and outlook. In Proc of SP’12, pages
65–79. IEEE, 2012.
[28] P. Salembier and T. Sikora. Introduction to MPEG-7:
Multimedia Content Description Interface. John Wiley
& Sons, Inc., New York, NY, USA, 2002.
[29] I. Santos, Y. Penya, J. Devesa, and P. Bringas.
N-grams-based ﬁle signatures for malware detection.
In Proc. of ICEIS’09, 2009.
[30] M. Schultz, E. Eskin, F. Zadok, and S. Stolfo. Data
mining methods for detection of new malicious
executables. In Proc of SP’01. IEEE, 2001.
[31] M. Shaﬁq, S. Tabish, F. Mirza, and M. Farooq.
Pe-miner: Mining structural information to detect
malicious executables in realtime. In Proc. of
RAID’09. Springer, 2009.
[32] S. M. Tabish, M. Z. Shaﬁq, and M. Farooq. Malware
detection using statistical analysis of byte-level ﬁle
content. In ACM SIGKDD Workshop CyberSecurity
and Intelligence Informatics, 2009.
[33] A. Torralba, K. Murphy, W. Freeman, and M. Rubin.
Context-based vision systems for place and object
recognition. In Proceedings of ICCV, 2003.
[34] A. Walenstein, M. Venable, M. Hayes, C. Thompson,
and A. Lakhotia. Exploiting similarity between
variants to defeat malware. In Proc. BlackHat DC
Conf., 2007.
[35] G. Wicherski. pehash: A novel approach to fast
malware clustering. In USENIX Workshop on
Large-Scale Exploits and Emergent Threats (LEET),
2009.