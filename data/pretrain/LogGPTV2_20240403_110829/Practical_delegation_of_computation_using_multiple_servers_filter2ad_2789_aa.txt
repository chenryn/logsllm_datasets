title:Practical delegation of computation using multiple servers
author:Ran Canetti and
Ben Riva and
Guy N. Rothblum
Practical Delegation of Computation using Multiple
Servers
∗
Ran Canetti
Tel Aviv University & Boston
University
PI:EMAIL
∗
Ben Riva
Tel Aviv University
PI:EMAIL
†
Guy N. Rothblum
Microsoft Research, Silicon
Valley Campus
PI:EMAIL
ABSTRACT
The current move to Cloud Computing raises the need for veriﬁ-
able delegation of computations, where a weak client delegates his
computation to a powerful server, while maintaining the ability to
verify that the result is correct. Although there are prior solutions
to this problem, none of them is yet both general and practical for
real-world use.
We demonstrate a relatively efﬁcient and general solution where
the client delegates the computation to several servers, and is guar-
anteed to determine the correct answer as long as even a single
server is honest. We show:
• A protocol for any efﬁciently computable function, with log-
arithmically many rounds, based on any collision-resistant
hash family. The protocol is set in terms of Turing Machines
but can be adapted to other computation models.
• An adaptation of the protocol for the X86 computation model
and a prototype implementation, called Quin, for Windows
executables. We describe the architecture of Quin and exper-
iment with several parameters on live clouds. We show that
the protocol is practical, can work with nowadays clouds, and
is efﬁcient both for the servers and for the client.
Categories and Subject Descriptors
K.6.5 [Management of Computing and Information Systems]:
Security and Protection
General Terms
Algorithms, Experimentation, Security
∗Research supported by the Check Point Institute for Information
Security.
†Most of this work was done while the author was at the Depart-
ment of Computer Science at Princeton University and Supported
by NSF Grant CCF-0832797 and by a Computing Innovation Fel-
lowship.
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
CCS’11, October 17–21, 2011, Chicago, Illinois, USA.
Copyright 2011 ACM 978-1-4503-0948-6/11/10 ...$10.00.
Keywords
Veriﬁable Computation, Cloud Computing
1.
INTRODUCTION
These days, the IT world is moving towards the pay-per-use
paradigm (aka Cloud Computing). Companies of all sizes reduce
their computing assets and shift to a use of computing resources in
the clouds. This shift is predicted to increase in the near future and
become a signiﬁcant portion of the IT market. One consequence of
this shift is that the IT world outside the clouds is moving to a use of
weaker and smaller computer devices, like Virtualized Thin Desk-
tops, Tablet PCs and Smartphones. Whenever stronger resources
are needed, those devices will use the cloud.
Since cloud services are often given by an outside entity with
different interests than those of the client, this model carries within
it many security problems. One problem, however, stands out as
an inherent and very basic one: How can the client verify the cor-
rectness of the cloud’s computation? This question is not easily
answered by the existing tools of security and cryptography.
There are many possible reasons for a cloud to answer incor-
rectly. For instance, a cloud would like to improve its revenue by
investing less resources while charging for more. Or, a cloud might
beneﬁt somehow from certain outputs of the computation, thus it
can try to maximize speciﬁc results. Or, a disgruntled employee
of the cloud provider could modify the executed program. Con-
sequently, the client must be able to verify the correctness of that
result. To be effective, we would like the veriﬁcation process to use
considerably less resources than those required to actually perform
the computation from scratch.
This problem has been considered extensively in the theoretical
computer science community, most notably by using Probabilisti-
cally Checkable Proofs (e.g., [15, 20]). (See Section 1.2.) However,
although those solutions are very efﬁcient in terms of asymptotic
complexity, they are currently impractical.
A natural idea, pursued in this work, is to take the basic concept
behind cloud computing, the pay-per-use paradigm, and extend it
also for integrity. If a client wants to get better assurance of the
integrity of his cloud computations, he can pay a little more to get
such assurance. And if he already pays a little more, why should
it be to the same cloud? He can split his payment among several
clouds as they are all accessible on the net anyhow.
One simple way of achieving this goal could be to use a number
of clouds, and then have the client execute the program by himself
in case of inconsistency. However, what about the case where it is
impossible or impractical for the client to execute the program even
in case of inconsistency?
For this case, the following idea has been proposed: Instead of
executing his program on one speciﬁc cloud provider, the client
445picks N different cloud providers. Next, the client asks each of
those cloud providers to execute his program and return the out-
put. Now, the client takes the plurality value of those answers to be
the correct answer. As long as there is a majority of honest cloud
providers (even if the client does not know which ones), the client
gets the correct answer. Indeed, this approach is used in Grid Com-
puting, e.g., BOINC [1].
The main downside of this approach is, of course, the need for
an honest majority of clouds. In particular, this method requires at
least three clouds to be viable. Can one do better? In particular,
can we get practical efﬁciency improvements over the single cloud
case, with access to only two clouds, only one of which is honest
and for a client that cannot compute the function by himself?
We provide a positive answer to this question. Speciﬁcally, we
are interested in the following model: The client asks for the re-
sult of the function f (x) from two (or more) cloud servers. In case
they make contradictory claims about f (x), the client engages in
a protocol with each of the servers, at the end of which the client
can efﬁciently determine the true claim as long as there is at least
one honest server. As for efﬁciency, we require that the computa-
tional requirements from an honest server are not much more than
those required to compute the function in the ﬁrst place, and that
the client’s running time is much smaller than the time required to
compute the function. We call this model Refereed Delegation of
Computation (RDoC) since the client acts like a referee.
Our model is closely related to the Refereed Games (RG) model
of Feige and Kilian [10] where they focus on two unbounded com-
peting servers and polynomial time referee/client. However, we are
faced with the additional challenges of building protocols with efﬁ-
cient honest servers, with a super-efﬁcient client and for any num-
ber of servers. In fact, our model can be also considered as refereed
games with multiple efﬁcient servers and super-efﬁcient clients.
We remark that although our main motivation is a solution for
the setting of cloud computing, our results are also useful for other
client-server applications. E.g., Grid computing, or when using
several processors for redundancy in realtime systems. (Indeed in
the latter case there is a need to determine the identities of the faulty
processors.)
1.1 Our Contributions
For the description here we restrict attention to the case when
there are exactly two servers, one honest and one malicious (but
the client does not know which is honest). We later show how to
extend our protocol for more than two servers. We show an efﬁ-
cient and full-information RDoC protocol for any efﬁciently com-
putable function, with logarithmically many rounds, based on any
collision-resistant hash function family. Here, by full information
we mean that the servers can see the full internal state of the client
and the communication between the client and the servers is pub-
lic. The honest servers’ work grows only quasi-linearly with the
complexity of the computation. This protocol is highly generic and
can work with any reasonable computation model.
Previously, Feige and Kilian [10] gave a private information but
unconditionally sound protocol with similar parameters.
It also
follows from their results that it is unlikely that an information-
theoretically sound full-information protocol with similar perfor-
mance can be obtained (in particular, this is impossible unless all
of P can be computed in poly-logarithmic space).
Our protocol, which builds directly on the protocol of Feige and
Kilian, is qualitatively more practical than known techniques for
delegating computation in the single-server setting. In particular,
all known protocols rely either on arithmetization and PCP tech-
niques [20, 12], or provide only amortized performance advan-
tages and rely on fully homomorphic encryption [11, 9]. Neither
approach is currently viable in practice. Moreover, all known pro-
tocols work with the (arguably less practical) circuit representation
of the computation.
At high level, in this protocol the client searches (using binary
search) for inconsistencies between the intermediate states of the
two servers’ computations. On ﬁnding an inconsistency, the client
can detect the cheater by performing only a single step of the dele-
gated computation. The collision-resistant hash functions are used
to allow the servers to “commit” to the (large) intermediate internal
states of the computation using small commitments.
In addition, in contrast with prior protocols, our protocol is full-
information (or public coins). This means that, in a setting where
messages between clients and servers are digitally signed, the pro-
tocol guarantees that as soon as a server cheats, the client detects
the cheating and obtains a publicly veriﬁable proof of this fact. This
is a strong guarantee: we view the servers as rational self-interested
parties (say cloud computing service providers). An honest server
can convince even third parties that all of the cheating servers are
cheaters. Assuming that pointing out cheaters is rewarded and
cheating is penalized, playing honestly becomes (always) a dom-
inant strategy for rational servers.
We stress that in case all servers agree upon the result, there are
no overheads for the servers, nor for the client. The overhead kicks
in only in case the servers do not agree. In this case, the overhead
is only poly-logarithmic in the size of the computation.
Quin. We adapt the protocol for the X86 computation model. A
simplistic adaptation would be to simply run a Turing Machine sim-
ulator for X86; but this would result in highly inefﬁcient code. In-
stead, we adapt the protocol to the X86 computation model: Instead
of Turing Machine transitions we have assembly instructions, and
instead of working tapes we have the machine’s stack and heap
memories. This highly improves the practicality of the protocol,
and shows its ﬂexibility.
We present a prototype implementation of this adaptation for the
Windows environment. Our implementation, which we call Quin,
works directly with X86 assembly instructions. However, we do
not require the programmer to write his code in assembly. The pro-
grammer can write his code in C language and later on build the
program to run with our framework. This is an important feature
since it makes the implementation almost transparent for the ap-
plication programmer. Moreover, with small modiﬁcations to our
prototype, it allows future support for other languages that compile
to X86 assembly.
Since our protocol requires the ability to execute a program for a
given number of steps, stop its execution and store its state to a ﬁle,
and later on, be able to resume execution from a stored state, we use
a binary instrumentation framework, Intel’s PIN [17], to add assem-
bly instructions for counting the number of executed instructions
and comparing it to a given threshold. Then, we combine several
low-level techniques that work directly with the process memory in
order to efﬁciently dump/restore a state to/from a ﬁle.
Another requirement of our protocol is that the client should be
able to simulate one step of the computation by himself, given only
a small part of some stored state. While for Turing Machines this
seems easy, for high-level languages it can be complicated (e.g.,
in Java, a single step can be a heavy computation that depends on
many variables). However, focusing only on X86 instructions that
are more “simple” and depend on a small number of variables (or
memory), we can meet this requirement by using an X86 emula-
tor that we feed with the required registers and memory data. We
extend the Python X86 emulator PyEmu [3] to support emulation
446of instructions given only a remote access to the process memory
(since we do not want to transfer the entire memory to the client).
Last, our protocol assumes that each execution of the delegated
program is fully deterministic (i.e.
for a ﬁxed input, the Turing
Machine’s tableau must be the same for each execution of the ma-
chine on this input), and therefore, the delegated program has to
use only deterministic system calls. However, useful library calls
like malloc() are not deterministic and depend on the state of
the operating system. We overcome this problem by implementing
deterministic versions of malloc() and free() that use pre-
allocated memory that is allocated in a nearly deterministic address.
We suggest how to extend the idea of function stubs for other sys-
tem/library calls.
We experiment with this prototype on live clouds and show that
the overhead is almost reasonable for real-world applications. For
some parameters we get a slowdown factor of “only” 8, compared
to the original application. Furthermore, the result implies that a
large portion of the overhead is due to implementation issues. Thus,
a product-level implementation of the protocol could achieve much
smaller overheads. See Section 4.4 for further details regarding the
overheads.
1.2 Related Work
Prior work has studied the question of proving the correctness of
general computations. (Most previous works focused on interactive
proofs between a veriﬁer and a prover. However, the problems are
closely related: Given an interactive protocol for proving the cor-
rectness of a computation of f, one can easily get veriﬁable delega-
tion of computation by asking the server for y = f (x) and a proof
that y is the correct result.) Babai et al. [7] consider this question in
a setting where the prover is a non-adaptive oracle. Kilian [15] and
Micali [20] build on their techniques and show efﬁcient computa-
tionally sound protocols, whose security is based on cryptographic
assumptions and where soundness holds only against computation-
ally bounded cheating provers. Micali gets a non-interactive com-
putationally sound proof based on the existence of a Random Or-
acle whereas Kilian gets a four-message interactive computation-
ally sound proof assuming the existence of collision resistance hash
family. Goldwasser et. al. [12] present an information theoretically
sound interactive proof protocol for veriﬁable computation for any
language in L-uniform NC.
We note that, with the exception of [12], the above works are
based on Probabilistic Checkable Proofs (PCP) [6]. Although con-
structions of PCP are very efﬁcient by means of asymptotic com-
plexity, they are far from being practical.
Gennaro et al. [11], Chung et. al. [9] and Applebaum et al. [5]
consider a model with a pre-processing stage. Based on the exis-
tence of a fully homomorphic encryption, they construct computa-
tionally sound protocols, where in an ofﬂine pre-processing stage
the veriﬁer runs in time proportional to the size of the computa-
tion. Afterwards, in a one-round online stage, the veriﬁer (using
the result of the pre-processing stage) runs in time proportional to
the size of its inputs and the computation results. In these works, as
long as the veriﬁer does not encounter cheating provers, the same
pre-processing information can be used in multiple rounds, yield-
ing improved amortized complexity.
We remark that in all the above works, the veriﬁer has to know
all the inputs, including any randomness that the server uses for the
computation (our protocol also shares this requirement).
A related proof model with several provers is the model of Multi-
Prover Interactive Proofs, suggested by Ben-Or et al. [8]. In this
model, even if all of the provers cheat, the veriﬁer will detect that
they are cheating. However, soundness is guaranteed assuming that
malicious provers cannot communicate or coordinate their strate-
gies during the protocol. This is in contrast to the refereed games
of Feige and Kilian [10] and to our model, where soundness is guar-
anteed as long as one server is honest, even if all malicious servers
communicate during the protocol. In addition, the client learns who
are the cheating provers.
As for more applied prior work, there are works that in some
sense restrict the computation type (e.g. [21] for computations that
have short intermediate states, or, [13] for functions with easy to
sample domains) and there are several works that use trusted hard-