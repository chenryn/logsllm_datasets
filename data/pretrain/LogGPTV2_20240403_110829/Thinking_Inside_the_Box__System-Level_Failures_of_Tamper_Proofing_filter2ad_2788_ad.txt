This will provide a list of scenarios that designers must
check, and by making explicit the combinational complex-
ity of options, help push back on their proliferation. Pro-
tocol options, and their negotiation procedures, are a sig-
niﬁcant factor behind the system ﬂaws we found.
(Sim-
ilar problems have been found in other security applica-
tions, such as the cipher-suite and version negotiation of
SSL [43].) Even though the EMV speciﬁcation ﬁnds com-
pact ways to describe the plethora of options, a security
evaluation must consider every relevant combination.
4.4 Analysis of PED security
Given the above methodology, we now present an exam-
ple of applying it to EMV PED security, by constraining our
analysis to the suite of options used in the UK: no PIN en-
cryption, ubiquitous magnetic strip fallback and no iCVV
option. There are four top-level tamper-proof boundaries,
shown in Figure 5:
the merchant, the PED, the card and
the customer. We do not need to discuss the CPU protec-
tion, since that is wholly enclosed by the PED, and the bank
HSM is outside the scope of this paper. The assets to be
protected are as follows:
Card details: Stored by card, sent from card to PED;
290
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 03:13:41 UTC from IEEE Xplore.  Restrictions apply. 
PIN: Stored by card, entered by customer into PED and sent
from PED to card;
Item value: Displayed on PED screen, for customer.
With the card details and PIN, a fake magnetic-strip card
can be produced, so the conﬁdentiality of these must be
maintained. Also, if the value displayed on the PED screen
does not match that processed by the card, the customer
may be defrauded. Here, we only cover the system issues
that result from information crossing tamper boundaries.
We do not discuss issues such as protecting PED code or
root-certiﬁcate integrity, since they are internal to the PED
system and would be discussed in its documentation.
Given these deﬁnitions, it becomes clear where the ﬂaws
in EMV lie. The PIN is protected by the smartcard; given
a tamper-resistant chip which will lock up after too many
incorrect attempts, it cannot be directly retrieved from the
card. But the PIN and card details are transmitted through
the PED, which may or may not protect one or both of
them. Card and PIN data may leak at the card–PED in-
terface, and card data may also leak if the PED–bank link
isn’t encrypted. Finally, since the customer cannot trust the
terminal display, she is vulnerable to relay attacks.
We can also examine defenses.
If encrypted PIN ver-
iﬁcation is used, and unencrypted transmission cannot be
forced, we can drop the requirement that the card–PED
interface physically protect PIN conﬁdentiality. And if
magnetic-strip fallback is not permitted, or the iCVV option
is used, the interface need no longer protect card details.
But if some banks don’t use encrypted PIN and iCVV, then
either PEDs have to be robust against shims (perhaps us-
ing a full metal enclosure and card-handling machinery, like
ATMs) or their customers should be indemniﬁed against
the costs of the resulting fraud. And regardless of whether
physical or cryptographic security protects the card data and
PIN, the trusted interface problem remains. Some combi-
nation of technical measures and indemnity must be used to
deal with relay attacks.
5 The certiﬁcation process
The exercise described in this paper has been particularly
instructive in teaching us about the weaknesses of Common
Criteria evaluations.
Until about a year ago, it was possible for market forces
to exercise some discipline on vendors. For example, in
2006, Shell withdrew EMV terminals from its UK fuel sta-
tions following a fraud that involved PED tampering, and
fell back for some months on magnetic-strip processing [9].
Their PED vendor, Trintech, sold its terminal business to
VeriFone and left the market [37]. But since then there has
been rapid consolidation, with Ingenico and VeriFone now
appearing to control most of the market. In addition, all but
the largest merchants tend to get their terminals from their
bank; many banks only offer one make of terminal; and the
banks have been found guilty in both 1989 and 2005 of in-
sufﬁcient competition on the provision of credit card ser-
vices to merchants [32, 33].
So customers, and now also merchants, depend critically
on the certiﬁcation of terminals, PEDs, smartcards and other
system components used in the EMV system. Some certiﬁ-
cation schemes merely ensure compatibility, such as EMV
Level 1 [22], but there are also extensive security evalua-
tions. Both PEDs we examined are certiﬁed under the Visa
PED approval scheme [42], and the Ingenico PED passed
the APACS PED ‘Common Criteria’ Evaluation [7] despite
the vulnerabilities we identiﬁed.
The survey of Yang et al. [46], apparently done mostly
in 2005, identiﬁed the classes of vulnerabilities we have
found and also suggested physical mitigation techniques.
We found it surprising since their paper acknowledges the
co-operation of Ingenico engineers, yet these ﬂaws still ex-
ist. But while they talk about points of failure in the ab-
stract, we have shown that these and other failures do exist,
can break EMV as deployed, and are easy to ﬁnd in real
PEDs, including Ingenico’s. What does that tell us about
the evaluation and certiﬁcation process?
5.1 Why evaluations fail
A security failure in an evaluated product can have a
number of causes. The Common Criteria (or other frame-
work) might be defective; the protection proﬁle might not
specify adequate protection; the evaluator might miss at-
tacks, or estimate their cost and complexity as too high.
One known problem with the Common Criteria is the
proliferation of protection proﬁles. Anyone can propose a
protection proﬁle for any purpose and get a lab to evaluate
it. The result is a large number of proﬁles giving little as-
surance of anything: for example, the proﬁle for ATMs is
written in management-speak, complete with clip art, states
that it ‘has elected not to include any security policy’ and
misses many of the problems that were well known when it
was written in 1999. Indeed it states that it relies on the de-
veloper to document vulnerabilities and includes the vague
statement that ‘the evaluator shall determine that the [Target
of Evaluation] is resistant to penetration attacks performed
by an attacker possessing a moderate attack potential’ [16].
A deeper problem in the security evaluation process is
the economics involved. Since the demise of the philos-
ophy behind the Orange Book [14], evaluation is now per-
formed by a laboratory selected and paid by the device man-
ufacturer. The vendor will naturally select the lab that will
give his product the easiest ride and charge the least money.
What’s more, the same process applies to the protection pro-
ﬁles against which the product is evaluated.
291
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 03:13:41 UTC from IEEE Xplore.  Restrictions apply. 
Market competition may help reduce evaluation costs,
but it promotes a race to the bottom between the labs. To
mitigate this, approved labs must be used, selected by Visa
in the case of PED approval, or by a national body such
as NIST in the USA or GCHQ in Britain for the Common
Criteria. In principle, this might provide some quality con-
trol, but in practice the agencies appear never to have de-
approved a licensed lab, for fear of undermining conﬁdence
in ‘the system’. Government agencies may also feel reluc-
tant to drive evaluation work abroad. These concerns were
expressed by Anderson [3] who describes a number of cases
in the 1990s of clearly mistaken evaluations. The vulnera-
bilities described in this paper provide a further such case.
Was this evaluation failure systemic, or the fault of an indi-
vidual evaluator?
5.2 Government and industry response
We therefore wrote to GCHQ, Visa, APACS, Ingenico
and VeriFone (Dione) in November 2007 with an early draft
of this paper and asked them for comments. In February
2008, the BBC’s ‘Newsnight’ programme ﬁlmed our re-
search, including an attack that we conducted on a real ter-
minal in a real store and that yielded a journalist’s card de-
tails and PIN (this was done with consent of both the store
owner and the journalist). The imminent broadcast of the
programme (26 February 2008) prompted responses from
GCHQ, APACS and VeriFone. Ingenico did not respond to
our questions and Visa did not even acknowledge receipt of
our original disclosure three months earlier (although they
did download our paper following our email to them, and
one evaluation lab downloaded it from the URL we sup-
plied to Visa). We asked for copies of the evaluation re-
ports, why these reports weren’t public, whether the inse-
cure PEDs would be decertiﬁed, whether the labs that neg-
ligently certiﬁed them as secure would lose their licenses,
and whether the evaluation system should be changed.
VeriFone’s response was evasive, pushing responsibility
to APACS, Visa and GCHQ, but the reply from APACS
and GCHQ were more instructive. APACS, the bankers’
trade association, claimed that previous evaluations “did
not identify any speciﬁc vulnerabilities in the devices that
required additional mitigation”; they denied that the evalu-
ations were defective; they said that the devices would not
be withdrawn from use as they disagreed with our risk as-
sessment – they said that the attack was harder than we de-
scribed, and that there were simpler fraud methods.
APACS claimed that “The numbers of PED compromise
that have taken place in the UK are minimal, however, and
the banking industry’s standard fraud prevention measures
have meant that these frauds and their location were de-
tected quickly.” (In two current criminal cases of which we
are aware, defendants are accused of stealing eight-ﬁgure
sums using tampered PEDs.) APACS refused to name the
evaluation labs and insisted that the evaluations had to be
carried out under non-disclosure agreements. They said,
“we are not aware of any widely recognised and credible
evaluation methodology process, in security or otherwise,
which makes evaluation reports publicly available.”
GCHQ’s response was equally uncompromising but to-
tally different. They informed us that evaluation reports for
Common Criteria certiﬁed devices must be made public, as
a condition of the mutual recognition arrangement. It tran-
spired that the Ingenico device was merely ‘evaluated’ un-
der Common Criteria, not ‘certiﬁed’ and hence not subject
to oversight by GCHQ or any other country’s Certiﬁcation
Body (CB). All certiﬁed products are listed on the Common
Criteria Portal [15], although under the confusingly titled
“List of evaluated products”. As of February 2008 no PEDs
are present on this list.
In fact, the certiﬁcation for the Ingenico PED was per-
formed by APACS, on the basis of a secret report by an
undisclosed laboratory. This laboratory is licensed by a CB
to perform certiﬁcations, but APACS refused to identify the
country in which the lab was registered, and hence which
CB was responsible. Had the devices been through certiﬁ-
cation, it would have been the CB’s job to ensure that the
security target was appropriate and that proper testing had
been carried out. APACS said that the decision of whether
the laboratory’s license is to be revoked is responsibility of
the CB that registered it. But since the PED evaluation was
done outside the Common Criteria system, and as far as we
know without knowledge of any CB, it is unclear how the
errant lab could be disciplined.
As a Certiﬁcation Body, GCHQ does not object to any-
one calling any device ‘Common Criteria Evaluated’, and
will merely object if a false claim is made that a device is
‘Common Criteria Certiﬁed’. This undermines their brand;
it enables organisations such as APACS to free-ride by ex-
ploiting the ‘Common Criteria’ name without either eval-
uating their products rigorously or publishing the results.
GCHQ admits that as the licensing authority it has an inter-
est: “The CB then has a direct involvement in maintaining
the quality of each of the individual evaluations for certiﬁ-
cation. These mechanisms counter any tendency for such a
‘race to the bottom’.” Regrettably, their conﬁdence is not
consistent with the research reported in this paper.
For both of these devices, the proximate cause of evalua-
tion failure was that the equipment just didn’t meet the pro-
tection goals set out in either the Visa certiﬁcation require-
ments or the APACS ‘Common Criteria’ protection proﬁle.
A deeper cause was that these requirements were unrealis-
tic; given the shim attack, it’s just not clear that any com-
pact low-cost device can be constructed that meets either
of them, and so the labs may have been faced with an im-
possible task. We’d argue that the protection proﬁle should
292
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 03:13:41 UTC from IEEE Xplore.  Restrictions apply. 
never have assumed that the card–PED interface could be
protected at all.
The banks clearly had an incentive to pretend that it
could be; by using cheap SDA cards rather than the more
expensive DDA/CDA cards, they saved perhaps $1 per card
over 70 million accounts. The failure of the CC CB to pro-
tect its brand gave them the opportunity to describe inse-
cure terminals as ‘Common Criteria Evaluated’ without le-
gal penalty. (Indeed one of us has seen banking industry
expert witnesses relying on the fact that a terminal was ‘cer-
tiﬁed’ in testimony in a case currently before the courts.)
The failure of EMV was multi-factorial: too many pro-
tocol options, liability dumping, an over-optimistic protec-
tion proﬁle, ‘evaluations’ funded by vendors, and failures
of both markets and regulation at a number of levels. What
should be done about it?
5.3 Fixing the evaluation process
Unfortunately, Common Criteria evaluations seem to be
most prevalent where incentives are skewed – where one
principal operates a system but others bear the costs of
failure. This tempts the operator to be careless – a phe-
nomenon known to economists as ‘moral hazard’. It’s now
well known that moral hazard is a major cause of security
failure; and evaluation may be sought as a way of avoiding
blame for failures by demonstrating due diligence [3].
We believe that the certiﬁcation process should be re-
engineered to take heed of incentives and accountability. In