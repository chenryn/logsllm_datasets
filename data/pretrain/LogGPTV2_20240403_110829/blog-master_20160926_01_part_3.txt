NULL<>NULL 的返回结果是NULL，不是false。   
NULL=NULL的返回结果也是NULL，不是true。  
NULL值与任何值的比较都为NULL，即NULL<>1，返回的是NULL，而不是true。  
【强制】除非是ETL程序，否则应该尽量避免向客户端返回大数据量，若数据量过大，应该考虑相应需求是否合理。  
【强制】任何地方都不要使用 select ```*``` from t ，用具体的字段列表代替```*```，不要返回用不到的任何字段。另外表结构发生变化也容易出现问题。    
### 管理规范
【强制】数据订正时，删除和修改记录时，要先select，避免出现误删除，确认无误才能提交执行。  
【强制】DDL操作(以及类似的可能获取大锁的操作，譬如vacuum full, create index等)必须设置锁等待，可以防止堵塞所有其他与该DDL锁对象相关的QUERY。    
例如  
```
begin;  
set local lock_timeout = '10s';  
-- DDL query;  
end;  
```
【强制】用户可以使用explain analyze查看实际的执行计划，但是如果需要查看的执行计划设计数据的变更，必须在事务中执行explain analyze，然后回滚。  
例如  
```
begin;  
explain analyze query;  
rollback;  
```
【强制】如何并行创建索引，不堵塞表的DML，创建索引时加CONCURRENTLY关键字，就可以并行创建，不会堵塞DML操作，否则会堵塞DML操作。  
例如  
```
create index CONCURRENTLY idx on tbl(id);  
```
【强制】为数据库访问账号设置复杂密码。  
说明：密码由小写字母，数字、下划线组成、字母开头，字母或数字结尾，禁止123456，hello123等简单密码。 
【强制】业务系统，开发测试账号，不要使用数据库超级用户。非常危险。  
【强制】如果数据库开启了archive_mode，一定要设置archive_command，同时监控pg_xlog的空间使用情况，避免因为归档失败，导致xlog不断堆积，甚至导致空间占满。  
【强制】如果数据库配置了standby，并且使用了slot，必须监控备机的延迟，监控slot的状态（延迟），否则可能导致主库XLOG文件堆积的问题，甚至导致空间占满。  
【推荐】多个业务共用一个PG集群时，建议为每个业务创建一个数据库。  如果业务之间有数据交集，或者事务相关的处理，强烈建议在程序层处理数据的交互。  
不能在程序中处理时，可以将多个业务合并到一个库，但是使用不同的schema将多个业务的对象分开来。  
【推荐】应该为每个业务分配不同的数据库账号，禁止多个业务共用一个数据库账号。  
【推荐】在发生主备切换后，新的主库在开放给应用程序使用前，建议使用pg_prewarm预热之前的主库shared buffer里的热数据。  
【推荐】快速的装载数据的方法，关闭autovacuum, 删除索引，数据导入后，对表进行analyze同时创建索引。    
【推荐】如何加快创建索引的速度，调大maintenance_work_mem，可以提升创建索引的速度，但是需要考虑实际的可用内存。    
例如  
```
begin;  
set local maintenance_work_mem='2GB';  
create index idx on tbl(id);  
end;  
```
【推荐】如何防止长连接，占用过多的relcache, syscache。  
当系统中有很多张表时，元数据会比较庞大，例如1万张表可能有上百MB的元数据，如果一个长连接的会话，访问到了所有的对象，则可能会长期占用这些syscache和relcache。    
建议遇到这种情况时，定期释放长连接，重新建立连接，例如每个小时释放一次长连接。    
PS  
阿里云的RDS PGSQL版本提供了主动释放syscache和 relcache的接口，不需要断开连接。    
【推荐】大批量数据入库的优化，如果有大批量的数据入库，建议使用copy语法，或者 insert into table values (),(),...(); 的方式。  提高写入速度。    
【推荐】大批量数据入库、大批量数据更新、大批量数据删除后，如果没有开启autovacuum进程，或者表级层面关闭了autovacuum，那么建议人为执行一下vacuum verbose analyze table;   
【推荐】大批量删除和更新数据时，不建议一个事务中完成，建议分批次操作，以免一次产生较多垃圾。当然如果一定要大批量操作的话，在操作完后，建议使用pg_repack重组表。  建议操作前检查膨胀率。   
### 稳定性与性能规范
【强制】在代码中写分页查询逻辑时，若count为0应直接返回，避免执行后面的分页语句。   
【强制】游标使用后要及时关闭。    
【强制】两阶段提交的事务，要及时提交或回滚，否则可能导致数据库膨胀。  
【强制】不要使用delete 全表，性能很差，请使用truncate代替，（truncate是DDL语句，注意加锁等待超时）。  
【强制】应用程序一定要开启autocommit，同时避免应用程序自动begin事务，并且不进行任何操作的情况发生，某些框架可能会有这样的问题。    
【强制】高并发的应用场合，务必使用绑定变量(prepared statement)，防止数据库硬解析消耗过多的CPU资源。    
【强制】不要使用hash index，目前hash index不写REDO，在备库只有结构，没有数据，并且数据库crash后无法恢复。  
同时不建议使用unlogged table ，道理同上，但是如果你的数据不需要持久化，则可以考虑使用unlogged table来提升数据的写入和修改性能。    
注意： pg 10开始hash index也支持写redo log了， 所以pg 10以后， 随便使用hash index。不受此条限制。   
【强制】秒杀场景，一定要使用 advisory_lock先对记录的唯一ID进行锁定，拿到AD锁再去对数据进行更新操作。  拿不到锁时，可以尝试重试拿锁。    
例如  
```
CREATE OR REPLACE FUNCTION public.f(i_id integer)    
 RETURNS void    
 LANGUAGE plpgsql    
AS $function$   
declare   
  a_lock boolean := false;  
begin   
  select pg_try_advisory_xact_lock(i_id) into a_lock;  
  拿到锁，更新  
  if a_lock then  
    update t1 set count=count-1 where id=i_id;   
  end if;  
  exception when others then    
    return;   
end;   
$function$;    
select f(id) from tbl where id=? and count>0;  
```
可以再根据实际情况设计，原理如上即可。  
函数可以如返回布尔，或者唯一ID，或者数字等。    
【强制】在函数中，或程序中，不要使用count(```*```)判断是否有数据，很慢。 建议的方法是limit 1;  
例如  
```
select 1 from tbl where xxx limit 1;  
if found -- 存在  
else  -- 不存在  
```
【强制】对于高并发的应用场景，务必使用程序的连接池，否则性能会很低下。    
如果程序没有连接池，建议在应用层和数据库之间架设连接池，例如使用pgbouncer或者pgpool-II作为连接池。    
【强制】程序务必有重连机制，如果没有重连机制，一个长期空闲的连接可能会被网络层设备当成无效会话强制中断掉。即使设置tcp_keepalives_idle,tcp_keepalives_interval,tcp_keepalives_count等较短的TCP心跳，也不一定能覆盖所有场景。  
建议有重连机制，建议在使用长时间未被使用的连接前使用select 1;探测一下是否连接正常，如果不正常，则重连。建议使用select 1;作为连接的定期心跳。  
【强制】当业务有近邻查询的需求时，务必对字段建立GIST或SP-GIST索引，加速近邻查询的需求。  
例如  
```
create index idx on tbl using gist(col);  
select * from tbl order by col  '(0,100)';  
```
【强制】避免频繁创建和删除临时表，以减少系统表资源的消耗，因为创建临时表会产生元数据，频繁创建，元数据可能会出现碎片。    
【强制】必须选择合适的事务隔离级别，不要使用越级的隔离级别，例如READ COMMITTED可以满足时，就不要使用repeatable read和serializable隔离级别。  
【推荐】高峰期对大表添加包含默认值的字段，会导致表的rewrite，建议只添加不包含默认值的字段，业务逻辑层面后期处理默认值。    
【推荐】在使用空间查询时，点面包含、相交等查询，为了提升效率，尽量使用有效面积大的多边形，如果做不到，可以先对多边形进行split，同时使用union all合并结果。   
[《PostgreSQL 空间切割(st_split)功能扩展 - 空间对象网格化 (多边形GiST优化)》](../201710/20171005_01.md)    
[《PostgreSQL 空间st_contains，st_within空间包含搜索优化 - 降IO和降CPU(bound box) (多边形GiST优化)》](../201710/20171004_01.md)    
[《PostgreSQL 黑科技 - 空间聚集存储, 内窥GIN, GiST, SP-GiST索引》](../201709/20170905_01.md)    
[《PostgreSQL multipolygon 空间索引查询过滤精简优化 - IO，CPU放大优化》](../201711/20171122_03.md)   
【推荐】分页评估，不需要精确分页数时，请使用快速评估分页数的方法。    
https://yq.aliyun.com/articles/39682  
例如    
```
CREATE OR REPLACE FUNCTION countit(text)                    
RETURNS float4           
LANGUAGE plpgsql AS          
$$DECLARE               
    v_plan json;                
BEGIN                      
    EXECUTE 'EXPLAIN (FORMAT JSON) '||$1                                
        INTO v_plan;                                                                       
    RETURN v_plan #>> '{0,Plan,"Plan Rows"}';  
END;  
$$;  
postgres=# create table t1234(id int, info text);  
CREATE TABLE  
postgres=# insert into t1234 select generate_series(1,1000000),'test';  
INSERT 0 1000000  
postgres=# analyze t1234;  
ANALYZE  
postgres=# select countit('select * from t1234 where id<1000');  
 countit   
---------  
     954  
(1 row)  
postgres=# select countit('select * from t1234 where id between 1 and 1000 or (id between 100000 and 101000)');  
 countit   
---------  
    1931  
(1 row)  
```
【推荐】分页优化，建议通过游标返回分页结果，避免越后面的页返回越慢的情况。    
例如    
```
postgres=# declare cur1 cursor for select * from sbtest1 where id between 100 and 1000000 order by id;  
DECLARE CURSOR  
Time: 0.422 ms  
```
获取数据    
```
postgres=# fetch 100 from cur1;  
。。。  
```
如果要前滚页，加SCROLL打开游标      
```
declare cur1 SCROLL cursor for select * from sbtest1 where id between 100 and 1000000 order by id;  
```
【推荐】可以预估SQL执行时间的操作，建议设置语句级别的超时，可以防止雪崩，也可以防止长时间持锁。    
例如设置事务中执行的每条SQL超时时间为10秒    
```
begin;  
set local statement_timeout = '10s';  
-- query;  
end;  
```
【推荐】TRUNCATE TABLE 在功能上与不带 WHERE 子句的 DELETE 语句相同：二者均删除表中的全部行。但 TRUNCATE TABLE 比 DELETE 速度快，且使用的系统和事务日志资源少，但是TRUNCATE是DDL，锁粒度很大，故不建议在开发代码中使用DDL语句，除非加了lock_timeout锁超时的会话参数或事务参数。    
【推荐】PostgreSQL支持DDL事务，支持回滚DDL，建议将DDL封装在事务中执行，必要时可以回滚，但是需要注意事务的长度，避免长时间堵塞DDL对象的读操作。    
【推荐】如果用户需要在插入数据和，删除数据前，或者修改数据后马上拿到插入或被删除或修改后的数据，建议使用insert into .. returning ..; delete .. returning ..或update .. returning ..; 语法。减少数据库交互次数。    
例如  
```
postgres=# create table tbl4(id serial, info text);  
CREATE TABLE  
postgres=# insert into tbl4 (info) values ('test') returning *;  
 id | info   
----+------  
  1 | test  
(1 row)  
INSERT 0 1  
postgres=# update tbl4 set info='abc' returning *;  
 id | info   
----+------  
  1 | abc  
(1 row)  
UPDATE 1  
postgres=# delete from tbl4 returning *;  
 id | info   
----+------  
  1 | abc  
(1 row)  
DELETE 1  
```
【推荐】自增字段建议使用序列，序列分为2字节，4字节，8字节几种(serial2,serial4,serial8)。按实际情况选择。  禁止使用触发器产生序列值。    
例如  
```
postgres=# create table tbl4(id serial, info text);  
CREATE TABLE  
```
【推荐】如果对全表的很多字段有任意字段匹配的查询需求，建议使用行级别全文索引，或行转数组的数组级别索引。    
例如  
```
select * from t where phonenum='digoal' or info ~ 'digoal' or c1='digoal' or ......;  
```