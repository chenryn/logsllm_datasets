### Improved Text

#### Secrecy in Plutus

The set of readers may lead to the unintended declassification of secrets. Given these observations, we need to modify our specification of secrecy.

**Definition 4.3 (Secrecy).** In Plutus, secrecy is preserved if, for all groups \( g \) and versions \( v \), any secret \( m \) written by an honest writer for \( g \) using keys for \( v \) is only leaked if a reader or writer for \( g \) is corrupt at some version \( v' \geq v \). Formally, the process modeling Plutus satisfies the following correspondence:

\[
\text{puts}(w, m, g, v) \land \text{attacker}(m) \implies \exists v' \geq v : \text{corrupt}(a, g, v') \land (\text{isreader}(a, g, v') \lor \text{iswriter}(a, g, v'))
\]

**Theorem 4.4.** Secrecy is preserved in Plutus.

**Proof.** Let \( m[g = G, v = V] \) denote the name \( m \) created in line 49 when the variables \( g \) and \( v \) in lines 45 and 47 are bound to the terms \( G \) and \( V \), respectively. ProVerif automatically proves the following correspondence:

\[
\text{attacker}(m[g = xg, v = xv]) \implies \exists v' \geq xv : \text{corrupt}(a, xg, v') \land (\text{isreader}(a, xg, v') \lor \text{iswriter}(a, xg, v'))
\]

By the semantics of the input language, for any terms \( W, M, G, \) and \( V \), if \( \text{puts}(W, M, G, V) \) is executed, then \( M = m[g = G, v = V] \). Thus, for all substitutions \( \sigma \), if a trace \( T \) satisfies \( \sigma \text{puts}(w, xm, xg, xv) \) and \( \sigma \text{attacker}(xm) \), then \( \sigma xm = \sigma m[g = xg, v = xv] \). Therefore, \( T \) satisfies \( \sigma \text{attacker}(m[g = xg, v = xv]) \), and by the above correspondence, \( T \) satisfies \( \sigma' (v' \geq xv \land \text{corrupt}(a, xg, v') \land (\text{isreader}(a, xg, v') \lor \text{iswriter}(a, xg, v'))) \) for some substitution \( \sigma' \) such that \( \sigma'xg = \sigma xg \) and \( \sigma'xv = \sigma xv \). Hence, the required correspondence is satisfied. 

#### Integrity in Plutus

Next, we specify an integrity property. Specifically, we are interested in the integrity of data \( x \) read by an honest reader \( r \) for group \( g \) using keys for version \( v \). We expect \( x \) to come from the adversary if a dishonest writer for \( g \) at \( v \) colludes with the adversary at \( v \); otherwise, we expect \( x \) to be written by an honest writer \( w \) for \( g \) using keys for version \( v \). Moreover, such \( w \) must be a writer for \( g \) at \( v \).

**Definition 4.5 (Integrity).** Integrity is preserved in Plutus if, for all groups \( g \) and versions \( v \), any data \( x \) read by an honest reader for \( g \) using keys for \( v \) is written by an honest writer for \( g \) using keys for \( v \) unless a writer for \( g \) is corrupt at \( v \). Formally, the process modeling Plutus satisfies the following correspondence:

\[
\text{gets}(r, x, g, v) \implies \text{iswriter}(w, g, v) \land (\text{puts}(w, x, g, v) \lor \text{corrupt}(w, g, v))
\]

Unfortunately, ProVerif cannot prove the required correspondence for this model. Manual inspection of the derivation output by ProVerif reveals an attack where the adversary can send data to an honest reader for group \( g \) at version 0 without corrupting a writer for \( g \) at 0.

**Theorem 4.6.** Integrity is not preserved in Plutus, i.e., the correspondence (3) is not satisfied.

**Proof.** When ProVerif is given the query (3), it cannot prove this query and outputs a derivation of \( \text{gets}(r, m, g, 0) \) from facts that do not include \( \text{puts}(w, m, g, 0) \) or \( \text{corrupt}(w, g, 0) \) for any \( w \). This derivation corresponds to an attack. Briefly, a reader for \( g \) is corrupted at version 0, and a writer for \( g \) is corrupted at version 1. The adversary then constructs a bogus write key for version 0 and writes content that can be read by \( r \) using the read key for version 0. In more detail:

1. A reader for group \( g \) is corrupted at version 0 to get the lockbox key \( \text{lk0} \) for version 0.
2. Next, a writer for \( g \) is corrupted at version 1 to get the lockbox key \( \text{lk1} \), the sign key \( (d(s1, \text{lk1}), N(s1)) \), and the owner-signed modulus \( \text{sn1} = \exp(\text{hash}(N(s1)), \text{ownerprivkey}) \) for version 1 (where \( s1 \) is the RSA seed for version 1 and \( \text{ownerprivkey} \) is the private key of the owner).
3. The exponent \( e(s1, \text{lk1}) \) is computed as \( \text{genExp}(N(s1), \text{lk1}) \).
4. Next, the RSA seed \( s1 \) is computed as \( \text{crack}(e(s1, \text{lk1}), d(s1, \text{lk1}), N(s1)) \).
5. Now a bogus sign key \( \text{sk0} \) is constructed as \( (d(s1, \text{lk0}), N(s1)) \).
6. Choosing some fresh data \( m \), the following content is then sent to the file system, where \( M = \text{enc}(m, \text{lk0}) \):
   \[
   (g, 0, \text{sn1}, N(s1), M, \exp(\text{hash}(M), \text{sk0}))
   \]
7. An honest reader \( r \) for \( g \) reads \( m \) using keys for version 0, without detecting that the modulus in the sign key is not the correct one!

Note that corrupting a reader for \( g \) at version 0 to obtain \( \text{lk0} \) is not a necessary step in the above attack; the adversary can instead compute \( \text{lk0} \) from \( \text{lk1} \) by unwinding. Orthogonally, the adversary can collude with a writer for a different group at version 0, instead of corrupting a writer for group \( g \) at version 1. In each case, a bogus sign key for the target group and version may be constructed from an unrelated modulus because the correct group and version of that modulus are not verified in this model.

The above attack can have serious consequences, as it implies that a writer for an arbitrary group can act as a legitimate writer for a target group simply by colluding with a reader for that group. Here, we consider a model without server-verified writes, assuming the server is compromised and colludes with the adversary. As argued in [28, 34], server compromise is a realistic possibility, so the above attack can be quite damaging. Worse, integrity is not preserved even in a model extended with server-verified writes. However, with server-verified writes, the consequences are less serious—in order to write data for a group, the adversary needs to obtain the current write token for that group, for which it needs to corrupt a current writer for that group. Still, the attack has the same undesirable effect as allowing rotation of write keys. Specifically, it allows a corrupt writer at a later version to modify data in such a way that readers date the modified data back to an earlier version; in other words, the modified data appears to be older than it actually is to readers. This situation can be dangerous. Suppose that a reader trusts all writers at version 0 but not some writer at version 1 (say because the corruption of that writer at version 1 has been detected and communicated to the reader). The reader may still trust data written at version 0. However, the above attack shows that such data cannot be trusted: that data may, in fact, come from a corrupt writer at version 1.

We propose a simple fix \( F \) to correct the protocol: owners must sign each modulus with its correct group and version. More concretely, the term bound to \( \text{sn} \) at line 38 of the code for owners must be \( \exp(\text{hash}(n, g, v), \text{ownerprivkey}) \), and conversely, line 68 of the code for readers must check that \( \text{hash}(n, g, v) = \exp(\text{sn}, \text{ownerpubkey}) \). The corrected model preserves integrity as shown by Theorem 4.7 below. (Moreover, Theorem 4.4 continues to hold for the corrected model, with an unchanged proof.)

While Definition 4.5 restricts the source of data read by honest readers, it still allows the adversary to replay stale data from a cache; in particular, content written by a writer at version \( v \) may be cached and replayed by the adversary at a later version \( v' \), when that writer is revoked. Unfortunately, in the model above, we cannot associate contents that are read from the file system with the versions at which they are written to the file system. Such associations are possible only if the file system is (at least partially) trusted, as with server-verified writes.

**Definition 4.8 (Strong Integrity).** Strong integrity is preserved in Plutus if, for all groups \( g \) and versions \( v \), any data \( x \) read by an honest reader for \( g \) using keys for \( v \) is written by an honest writer for \( g \) using keys for \( v \), unless a writer for \( g \) is corrupt at \( v \); and further, such data is written either at \( v \) or at some version \( v' \geq v \) at which a writer is corrupt. Formally, the process modeling Plutus satisfies the following correspondence:

\[
\text{gets}(r, x, g, v, v') \implies \text{iswriter}(w, g, v) \land (\text{puts}(w, x, g, v) \lor \text{corrupt}(w, g, v)) \land (v' = v \lor (v' \geq v \land \text{iswriter}(w', g, v') \land \text{corrupt}(w', g, v')))
\]

**Theorem 4.9.** Strong integrity is preserved in Plutus with server-verified writes and fix \( F \).

**Proof.** Under the given conditions, ProVerif automatically proves the correspondence (4).

Further, we show (using a correspondence omitted here) the correctness of server-verified writes: for any group \( g \), only writers for \( g \) at the current version \( v \) can write data for \( g \) at \( v \). (Such writes must be authorized by the current write token for \( g \), which is distributed only to the current writers for \( g \).) Consequently, server-verified writes prevent at least two kinds of attacks:

- Unauthorized writers cannot destroy data by writing unreadable junk over such data.
- Revoked writers cannot roll back new data by writing data with old keys over such data.

**Figure 4. Running times of ProVerif**

Figure 4 presents the running times of ProVerif 1.14pl4 for the scripts above, in "minutes:seconds" format, on a 2.6 GHz AMD machine with 8 GB memory. We test models with or without fix \( F \), and with or without server-verified writes. We already find attacks assuming \( \text{maxrev} = 1 \) for models without fix \( F \). On the other hand, models with fix \( F \) are tested assuming \( \text{maxrev} \leq 5 \), so our security proofs apply only to those models (although we expect them to hold with larger values of \( \text{maxrev} \) as well). Memory usage increases significantly with server-verified writes; for example, the script with \( \text{maxrev} = 5 \), fix \( F \), and server-verified writes takes around 2.2 GB of memory. For \( \text{maxrev} = 6 \), ProVerif runs out of memory on this 8 GB machine.

#### Analysis of Some Design Details

Next, using ProVerif, we clarify some design details of Plutus.

**4.3.1. Why Should a New Modulus Be Created for Each Version?**

The following explanation is offered by [32]:

"The reason for changing the modulus after every revocation is to thwart a subtle collusion attack... a revoked writer can collude with a reader to become a valid writer..."

We formalize this attack as a violation of integrity in Plutus: if the modulus for version 1 is the same as that for version 0, the adversary is able to send data to an honest reader for group \( g \) at version 1 without corrupting a writer for \( g \) at 1. We manually reconstruct the attack.

1. A writer for \( g \) is corrupted at version 0, and a reader for \( g \) is corrupted at version 1. Thus, the adversary obtains the lockbox key \( \text{lk0} \) and sign key \( (d0, n) \) for version 0, and the lockbox key \( \text{lk1} \) for version 1. We may assume that the writer corrupted at 0 is revoked at 1. Let there be another writer for \( g \) at version 1 that publishes some content, so that the adversary also knows the owner-signed header \( \text{sn1} \) for version 1.
2. The adversary computes the exponent \( e0 = \text{genExp}(n, \text{lk0}) \), the RSA seed \( s = \text{crack}(e0, d0, n) \), and the sign key \( \text{sk1} = (d(s, \text{lk1}), N(s)) \) for version 1. (Since the modulus \( n \) is unchanged, the RSA seed \( s \) is the same for versions 0 and 1.) Finally, choosing some fresh data \( m \), the adversary sends the following content to the file system, where \( M = \text{enc}(m, \text{lk1}) \):
   \[
   (g, 1, \text{sn1}, n, M, \exp(\text{hash}(M), \text{sk1}))
   \]
3. An honest reader for \( g \) reads \( m \) using keys for version 1.

However, we have two comments on this attack:

- With server-verified writes, the sentence of [32] quoted above is not quite true: in order to become a valid writer, one additionally needs to obtain a write token at some version \( v \geq 1 \), which can be done only by corrupting a writer at some version \( v \geq 1 \).
- But by corrupting a writer at version \( v \geq 1 \), the adversary can mount a much simpler attack. Indeed, the adversary can compute the RSA seed \( s \) and all keys for version 1 from the keys for such \( v \)—without corrupting a writer at version 0 or a reader at version 1. We reconstruct a simple attack along these lines by modifying the ProVerif script so that the modulus is not changed between versions and inspecting the derivation output by ProVerif. Here the adversary is able to send data to an honest reader for group \( g \) at version 0 without corrupting a writer for \( g \) at 0.

1. A writer for \( g \) is corrupted at version 1. Thus, the adversary obtains the lockbox key \( \text{lk1} \), and the sign key \( (d1, n) \) for version 1. Let there be another writer for \( g \) at version 0 that publishes some content, so that the adversary also knows the owner-signed header \( \text{sn0} \) for version 0.
2. The adversary computes the lockbox key \( \text{lk0} \) by unwinding \( \text{lk1} \), the exponent \( e1 = \text{genExp}(n, \text{lk1}) \), the RSA seed \( s = \text{crack}(e1, d1, n) \), and the sign key \( \text{sk0} = (d(s, \text{lk0}), N(s)) \) for version 0. Finally, choosing some fresh data \( m \), the adversary sends the following content to the file system, where \( M = \text{enc}(m, \text{lk0}) \):
   \[
   (g, 0, \text{sn0}, n, M, \exp(\text{hash}(M), \text{sk0}))
   \]

This concludes the detailed analysis of the design and security properties of Plutus.