tions as AFL-Ins. AFL-Ins provides coverage feedback during
the dynamic fuzzing phase to explore more paths. During re-
peated execution (line 8 in Algorithm 1), AFL labels a value
to each transition that connects the deputies of two consec-
utively executed basicblocks [63]. By maintaining a set of
transitions for queued seeds, AFL-Ins tracks the “coverage”
of the target program. cov_new_trace (line 11 in Algorithm 1)
checks whether a transition indicates a new path/state.
Figure 2b depicts the transitions upon executing the func-
tions compute and modify in Figure 1. For brevity, we use
source code to illustrate the problem and use statements to
represent instructions in assembly or LLVM IR [28].
AFL-Ins works perfectly on single-threaded programs: the
USENIX Association
29th USENIX Security Symposium    2327
like the fuzzer to observe as many distinct interleavings as
possible during repeated execution since that marks the po-
tential states a seed can exercise. In the case of statements 1
and 2 , we hope schedules i), ii), iii) can all occur. Therefore,
it is favorable to provide schedule interventions to diversify
the actual schedules.
3 System Overview
Figure 3 depicts the system overview of MUZZ. It con-
tains four major components: A static thread-aware analysis
guided instrumentations, B dynamic fuzzing, C vulnerabil-
ity analysis, D concurrency-bug revealing.
During A :instrumentation (§4), for a multithreaded
program Po, MUZZ ﬁrstly computes thread-aware inter-
procedural control ﬂow graph (ICFG) and the code seg-
ments that are likely to interleave with others during exe-
cution [11,45], namely suspicious interleaving scope, in §4.1.
Based on these results, it performs three instrumentations
inspired by §2.3.
1) Coverage-oriented instrumentation (§4.2) is one kind of
stratiﬁed instrumentation that assigns more deputies to sus-
picious interleaving scope. It is the major instrumentation
to track thread-interleaving induced coverage.
2) Thread-context
instrumentation (§4.3) is a type of
lightweight instrumentation that distinguishes different
thread identities by tracking the context of threading func-
tions for thread-forks, locks, unlocks, joins, etc.
3) Schedule-intervention instrumentation (§4.4) is a type of
lightweight instrumentation at the entry of a thread-fork
routine that dynamically adjusts each thread’s priority.
This complementary instrumentation aims to diversify
interleavings by intervening in the thread schedules.
During
B :dynamic fuzzing (§5), MUZZ optimizes
seed selection and repeated execution to generate more
multithreading-relevant seeds. For seed selection (§5.1), in ad-
dition to the new coverage information provided by coverage-
oriented instrumentation, MUZZ also prioritizes those seeds
that cover new thread-context based on the feedback provided
by thread-context instrumentation. For repeated execution
(§5.2), owing to the schedule-intervention instrumentation,
MUZZ adjusts the repeating times Nc, to maximize the beneﬁt
of repetitions and track the interleaved execution states.
C :Vulnerability analysis is applied to the crashing seeds
found by dynamic fuzzing, which reveals vulnerabilities
(including Vm). D :concurrency-bug revealing component
reveals Bm with the help of concurrency-bug detectors (e.g.,
TSan [42], Helgrind [49]). These two components will be
explained in the evaluation section (§6).
4 Static Analysis Guided Instrumentation
This component includes the thread-aware static analysis and
the instrumentations based on it.
(a)
(b)
Figure 2: (a) thread-aware callgraph of Figure 1; (b) its edge
transitions across compute and modify. In (b), the arrows
denote the transitions between statements. The pentagons
denote basicblocks’ entry statements; the other statements are
represented by rectangles. Their colors are consistent with
function nodes in (a). Since AFL-Ins only tracks branches’
entry statements, only branching edges ( 3 → 4 and 3 → 5 )
and function call edges ( 4 → 9 and 6 → 9 ) are recorded —
these transitions are marked as solid arrows.
kept transitions can reﬂect both branching conditions (e.g.,
4 → 9 and
3 → 4 and 3 → 5 ) and function calls (e.g.,
6 → 9 ). However, AFL-Ins cannot capture these differences
among schedules i), ii) and iii) (c.f. §2.2). In fact, it can only
observe there is a transition 1 → 1 ; thus it will not prioritize
this path for subsequent mutations, compared to other paths
that do not even execute compute. The root cause of this
defect lies in that AFL only tracks entry statements of basic-
blocks evenly, and does not record thread identities. Therefore,
we can add more deputy instructions within multithreading-
relevant basicblocks to provide more interleaving feedback,
and add thread-context information to distinguish different
threads.
2.3.2 Schedule-intervention Across Executions
During a GBF’s repeated execution procedure (line 8 in Al-
gorithm 1), a seed may exhibit non-deterministic behaviors:
it executes different paths of the target program across exe-
cutions due to randomness. In this scenario, AFL (and other
GBFs) will execute against such a seed more times than a seed
with deterministic behaviors [63]. For the non-deterministic
behaviors caused by scheduling-interleaving in multithreaded
programs, since the execution is continuously repeated Nc
times, the system level environment (e.g., CPU usage, mem-
ory consumption, I/O status) is prone to be similar [23, 26].
This will decrease the diversities of schedules, and conse-
quently reduce the overall effectiveness. For example, during
a repeated execution with Nc = 40, schedules i) and iii) might
occur 10 and 30 times respectively, while schedule ii) do not
occur at all; in this scenario, the execution states correspond-
ing to ii) will not be observed by the fuzzer. Ideally, we would
2328    29th USENIX Security Symposium
USENIX Association
checkmaincomputemodifyL22L6L13L15L24L25g_var += 1if ((int*)(s_var)[0] < 0)pthread_mutex_lock(&m)modify(&g_var)pthread_mutex_unlock(&m)return (char*)s_var*pv -= 2modify((int*)s_var)g_var *= 2123456789Figure 3: Overview of MUZZ. Inputs are the original program and initial seeds (in seed queue); outputs are the seeds with
vulnerabilities or concurrency-bugs. It contains four components. A (left area) does static analysis and applies thread-aware
instrumentations; B (center area) contains the ﬂows that proceed with dynamic fuzzing (seed scheduling and seed mutation [34]
are the same as typical GBF ﬂows, thus are marked dashed); C (right-bottom) denotes the vulnerability analysis applied on
vulnerable seeds; and D (right-top) is the replaying component used to reveal concurrency-bugs from the seed queue.
4.1 Thread-aware Static Analysis
The static analysis aims to provide lightweight thread-aware
information for instrumentation and runtime feedback.
4.1.1 Thread-aware ICFG Generation
We ﬁrstly apply an inclusion-based pointer analysis [1] on the
target program. The points-to results are used to resolve the
def-use ﬂow of thread-sharing variables and indirect calls to
reconstruct the ICFG. By taking into account the semantics of
threading APIs (e.g., POSIX standard Pthread, the OpenMP
library), we get an ICFG that is aware of the following multi-
threading information:
1) TFork is the set of program sites that call thread-fork func-
tions. This includes the explicit call to pthread_create, the
std::thread constructor that internally uses pthread_create,
or the “parallel pragma” in OpenMP. The called functions,
denoted as Ff ork, are extracted from the semantics of these
forking sites.
2) TJoin contains call sites for functions that mark the end of
a multithreading context. It includes the call sites of the
pthread APIs such as pthread_join, pthread_exit, etc.
3) TLock is the set of sites that call thread-lock functions
such as pthread_mutex_lock, omp_set_lock, etc.
4) TUnLock is the set of sites that call thread-unlock functions
like pthread_mutex_unlock, omp_unset_lock, etc.
5) TShareVar is the set of variables shared among different
threads. This includes global variables and those variables
that are passed from thread-fork sites (e.g., TFork).
4.1.2 Suspicious Interleaving Scope Extraction
Given a program that may run simultaneously with multi-
ple threads, we hope the instrumentation to collect execution
states to reﬂect the interleavings. However, instrumentation in-
troduces considerable overhead to the original program, espe-
cially when it is applied intensively throughout the whole pro-
gram. Fortunately, with the static information provided by the
thread-aware ICFG, we know that thread-interleavings may
only happen on some speciﬁc program statements; therefore,
the instrumentation can stress these statements. We hereby
use Lm to denote the set of these statements and term it as
suspicious interleaving scope. Lm is determined according to
the following three conditions.
C1 The statements should be executed after one of TFork,
while TJoin is not encountered yet.
C2 The statements can only be executed before the invoca-
tion of TLock and after the invocation of TUnLock.
C3 The statements should read or write at least one of the
shared variables by different threads.
C1 excludes the statements irrelevant to multithreading.
These statements can be prologue code that does the validity
check (e.g., check in Figure 1), or the epilogue that post-
processes the inputs or deals with error handlings. C2 pre-
vents the statements that are protected by certain locks from
being put into Lm. C3 is necessary since the interleavings will
not affect the shared states if the segment involves no shared
variables. This condition is determined by observing whether
the investigated statement contains a variable data dependent
on TShareVar (based on pointer analysis). We provide a sep-
arate preprocessing procedure to exclude cases where there
are only read operations on shared variables.
Note that Lm is used to emphasize multithreading-relevant
paths via instrumentations for state exploration during fuzzing.
Therefore the conditions are different from the constraints
required by static models (e.g., may-happen-in-parallel [11,
45]) or dynamic concurrency-bug detection algorithms (e.g.,
happens-before [12] or lockset [41]).
In Figure 1, according to the call pthread_create at
Lines 24 and 25, Ff ork = {compute}. MUZZ then gets all
the functions that may be called by functions inside Ff ork,
i.e., {modify,compute} and according to C1 the scope Lm
comes from Lines 1, 2, 10−17. Inside these functions, we
check the statements that are outside pthread_mutex_lock
USENIX Association
29th USENIX Security Symposium    2329
Original ProgramCoverage-oriented InstrumentationSchedule-intervention InstrumentationThread-context InstrumentationSeed QueueSeed SelectionSeed MutationSeed SchedulingRepeated ExecutionVul SeedsThread-aware ICFGInterleaving ScopeInstrumented ProgramT-Sanitizer InstrumentationT-SanitizedProgramBm SeedsBCDAand pthread_mutex_unlock based on C2: Line 15 should
be excluded from Lm. According to C3, we exclude the
statements that do not access or modify the shared vari-
ables g_var, s_var, which means Lines 14 and 16 should
also be excluded. In the end, the scope is determined as
Lm = {1,2,10,11,12,13,17}. Note that although modify can
be called in a single-threading site inside check (Line 6),
we still conservatively include it in Lm. The reason is that
it might be called within multithreading contexts (Line 13
and Line 15) — modify is protected by mutex m at Line 15
while unprotected at Line 13. It is worth noting that line 15,
although protected by m, may still happen-in-parallel [11, 45]
with lines 10 and 11. However, since lines 10 and 11 have
already been put in Lm, we consider it sufﬁcient to help pro-
vide more feedback to track thread-interleavings, with line 15
excluded from Lm.
Overall, the static analysis is lightweight. For example, the
pointer analysis is ﬂow- and context-insensitive; extraction
of thread-aware results such as Ff ork (in C1) and TShareVar
(in C3) are over-approximated in that the statically calculated
sets may be larger than the actual sets; C2 may aggressively
exclude several statements that involve interleavings. The
beneﬁt, however, is that it makes our analysis scalable to
large-scale real-world programs.
4.2 Coverage-oriented Instrumentation
With the knowledge of Lm, we can instrument more deputy
instructions (corresponding to statements in source code) in-
side the scope than the others, for exploring new transitions.
However, it is still costly to instrument on each instruction
inside Lm since this may signiﬁcantly reduce the overall ex-
ecution speed of the target programs. It is also unnecessary
to do so — although theoretically, interleavings may happen
everywhere inside Lm, many interleavings are not important
because they do not change the values of shared variables
in practice. This means that we can skip some instructions
for instrumentation, or equivalently instrument them with a
probability. We still instrument, despite less, on segments
outside Lm for exploration purposes [34]. For example, in
Figure 1, we apply instrumentation on check, just in case the
initial seeds are all rejected by the validity check and no inter-
mediate feedback are available at all, making the executions
extremely difﬁcult to even enter compute. Similarly, we can
also selectively instrument some instructions outside Lm.
4.2.1 Instrumentation Probability Calculation
The goal of calculating instrumentation probabilities is to
strike a balance between execution overhead and feedback
effectiveness by investigating code segments’ complexity of
the target programs. First of all, MUZZ calculates a base
instrumentation probability according to cyclomatic com-
plexity [35], based on the fact that bugs or vulnerabilities
usually come from functions with higher cyclomatic complex-
ity [9, 43]. For each function f , we calculate the complexity
value: Mc( f ) = E( f ) − N( f ) + 2 where N( f ) is the num-
ber of nodes (basicblocks) and E( f ) is the number of edges
in the function’s control ﬂow graph. Intuitively, this value
determines the complexity of the function across its basic-
blocks. As 10 is considered to be the preferred upper bound
of Mc [35], we determine the base probability as:
Pe( f ) = min(cid:8) E( f )− N( f ) + 2
, 1.0(cid:9)
(1)
10
We use Ps as the probability to selectively instrument on
the entry instruction of a basicblock that is entirely outside
suspicious interleaving scope, i.e., none of the instructions
inside the basicblock belong to Lm. Here, Ps is calculated as:
Ps( f ) = min(cid:8)Pe( f ), Ps0
(cid:9)
(2)
where 0 < Ps0 < 1. Empirically, MUZZ sets Ps0 = 0.5.
Further, for each basicblock b inside the given function f ,
we calculate the total number of instructions N(b), and the
total number of memory operation instructions Nm(b) (e.g.,
load/store, memcpy, free). Then for the instructions within Lm,
the instrumentation probability is calculated as:
Pm( f ,b) = min(cid:8)Pe( f )· Nm(b)
(cid:9)
, Pm0
N(b)
(3)
where Pm0 is a factor satisfying 0 < Pm0 < 1 and defaults to
0.33. The rationale of Nm(b)
is that vulnerabilities usually re-
N(b)
sult from memory operation instructions [34], and executions
on more such operations deserve more attention.
4.2.2
Instrumentation Algorithm
The coverage-oriented instrumentation algorithm is described
in Algorithm 2. It traverses functions in the target program
P. For each basicblock b in function f , MUZZ ﬁrstly gets the
intersection of the instructions inside both b and Lm. If this in-
tersection Lm(b) is empty, it instruments the entry instruction
of b with a probability of Ps ( f ). Otherwise, 1) for the entry
instruction in b, MUZZ always instruments it (i.e., with prob-
ability 1.0); 2) for the other instructions, if they are inside Lm,
MUZZ instruments them with a probability of Pm( f ,b). We
will refer to our selection strategy over deputy instructions as
M-Ins. As a comparison, AFL-Ins always instruments evenly
at the entry instructions of all the basicblocks.
For the example in Figure 1, since the lines 21-25 and
line 5 are out of Lm, we can expect M-Ins to instrument fewer
entry statements on their corresponding basicblocks. Mean-
while, for the statements inside Lm, M-Ins may instrument
other statements besides the entry statements. For example,
1 is the entry statement thus it must be instrumented; state-
ment 2 may also be instrumented (with a probability) — if
so, transition 1 → 2 can be tracked.
2330    29th USENIX Security Symposium
USENIX Association
Algorithm 2: Coverage-oriented Instrumentation
input
output :program P instrumented with M-Ins deputies
:target program P, and suspicious interleaving scope Lm
Lm(b) = Lm ∩ b;
if Lm(b) ! = /0 then
for i ∈ b do
for b ∈ f do
1 for f ∈ P do
2
3
4
5
6
7
8
9
P ← instrument_cov(P, i, 1.0);
if is_entry_instr(i, b) then
else if i ∈ Lm then
P ← instrument_cov(cid:0)P, i, Pm( f ,b)(cid:1);
P ← instrument_cov(cid:0)P, i, Ps( f )(cid:1);
i = get_entry_instr(b);
for b ∈ f do
else
10
11
12
13
4.3 Threading-context Instrumentation
We apply threading-context instrumentation to distinguish
thread identities for additional feedback. This complements
coverage-oriented instrumentation since the latter is unaware
of thread IDs. The context is collected at the call sites of Fctx =
{TLock,TUnLock,TJoin}, each of which has the form TC =
(cid:104)Loc,Nctx(cid:105), where Loc is the labeling value of deputy instruc-
tion executed before this call site, and Nctx is obtained by get-
ting the value of the key identiﬁed by current thread ID from
the “thread ID map” collected by the instrumented function FS
(to be explained in §4.4). Given an item F in Fctx, we keep a se-
quence of context (cid:104)TC1(F), . . . ,TCn(F)(cid:105),F ∈ Fctx. At the end
of each execution, we calculate a hash value H(F) for item
F. The tuple Sctx =(cid:10)H(TLock),H(TUnLock),H(TJoin)(cid:11) is
a context-signature that determines the overall thread-context
of a speciﬁc execution. Essentially, this is a sampling on
threading-relevant APIs to track the thread-context of a spe-
ciﬁc execution. As we shall see in §5.1, the occurrence of
Sctx determines the results of cov_new_mt_ctx during seed
selection.
In Figure 1, each time when pthread_mutex_lock∈
TLock is called, MUZZ collects the deputy instruction prior
to the corresponding call site (e.g.,
3 ) and the thread ID la-
bel (e.g., T1) to form the tuple (e.g., (cid:104) 3 ,T 1(cid:105)); these tuples
form a sequence for TLock, and a hash value H(TLock) will
be calculated eventually. Similar calculations are applied for
pthread_mutex_unlock and pthread_join.
Algorithm 3: select_next_seed Strategy
input
:seed queue QS, seed t at queue front
output :whether t will be selected in this round
if cov_new_mt_ctx(t) then
return true;
else if cov_new_trace(t) then
1 if has_new_mt_ctx(QS) or has_new_trace(QS) then
2
3
4
5
6
7
8 else
9