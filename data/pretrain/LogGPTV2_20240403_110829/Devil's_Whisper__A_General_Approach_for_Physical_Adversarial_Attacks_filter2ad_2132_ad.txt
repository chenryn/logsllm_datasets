different IVC devices are shown in Table 11 in Appendix G.
As we can see, some of those commands can cause safety or
privacy issues, e.g., “Okay Google, navigate to my home”,
“Okay Google, take a picture”, “Echo, open my door”, etc.
Table 2: The overall SRoC results on IVC devices.
Black
-box
TBA
AGA
SNR
(dB)
Google
Assistant
4/10
10/10
9.03
Home
4/10
9/10
8.81
Microsoft
Cortana
2/10
10/10
10.55
Amazon
Echo
0/10
10/10
12.10
IBM
WAA
3/10
10/10
7.86
Note: (1) “WAA” is used to represent “Wav-Air-API” attack. (2) The results
were all based on the tests conducted in October 2019.
We used a digital sound level meter “SMART SENSOR
AS824” to measure the volume of AEs. The background noise
was about 50 dB, and the played audios were about 65~75 dB,
compared to some special cases of the sound level presented
in [7, 17], e.g., talking at 3 feet (65 dB), living room music
(76 dB). We also conducted experiments to test our AEs in
realistic distance. For example, the AE with the command
“Echo, turn off the light” can successfully attack Echo as far
as 200 centimeters away, and the AE with the command “Hey
Cortana, open the website” can successfully attack Microsoft
Cortana as far as 50 centimeters away.
Robustness of the attack. To evaluate the robustness of our
attack, we deﬁne the success rate of AE (SRoA) as the ratio
of the number of successful tests to the total number of tests
if an AE has been repeatedly played. Table 11 shows SRoA
measured over 30 tests for each target command. The results
show 76% (38/50) of the commands have SRoAs over 1/3,
showing that our attack is quite robust.
6.3 Attacking Other Platforms
Over-the-air attack against IBM Speech to Text API. As
stated in Section 5.1, we use “Wav-Air-API” (WAA) to simu-
late the IVC device of IBM. The results are shown in Table 2.
Overall, such WAA attack demonstrates similar performance
as other IVC devices, which further indicates the effectiveness
and generality of our proposed approach.
AEs attack against Apple Siri. Since there is no online
speech-to-text API service available from Apple, we tried two
methods to attack Apple Siri: (1) we generate AEs directly
using the transferability based approach; (2) we “borrow” the
AEs demonstrating good performance on the other IVC de-
vices. As shown in Table 9 in Appendix F, only the command
“What is the weather?” generated from TBA can attack Apple
Siri successfully. For the other commands, we rely on the
help from AEs generated from AGA for other IVC devices13.
From Table 9, we ﬁnd all the seven AEs can successfully
attack Siri, which demonstrates the transferability of AGA14.
6.4 Evaluation of Possibly Simple Approaches
Local model approximation with a larger corpus. Appar-
ently, if the local model is trained by a larger corpus of tuned
TTS audio clips, it could approximate the target black-box
model better (Certainly a larger corpus means a larger amount
of queries to the online API service, which could be suspi-
cious.). Below we describe a preliminary evaluation of the
AEs generated by such local model.
We choose Google command_and_search model as our
target system. Then we pick up four commands that the AEs
generated by our approach can be decoded by Google com-
mand_and_search model with 100% SRoC. The details of
the commands are shown in Table 7 in Appendix C. As in
Section 4.2.1, we use TTS to generate regular speech of those
commands, and extend the corpus by tuning TTS audio clips.
Finally the corpus is ﬁltered out by the labeling from Google
command_and_search model with the same conﬁdence level
as that in our approach. Hence, we obtain a corpus of about
23.86 hours (5100 oracle queries), almost 5.17 times larger
than that used in our approach. After the local model is trained
with the larger corpus, we use the “MI_FGM” algorithm to
generate AEs and evaluate them on the target.
The results show only one command “OK Google, turn
off the light” succeeds on Google command_and_search
model, but still fails on Google Home. The other commands
do not have any successful AEs generated for Google com-
mand_and_search model and Google Home/Assistant. Based
on the results of the preliminary testing, even if the adversary
could afford the cost of preparing larger corpus and a larger
amount of queries, the AEs generated from such simpliﬁed
13When testing AEs from the other IVC devices on Apple Siri, we ignore
the wake up words, e.g., “OK Google, play music” should be truncated to
“Play music”.
14The test was conducted in January 2019. However, we found that the
AEs cannot work on Apple Siri since July 2019 (details in Section 7.3).
2676    29th USENIX Security Symposium
USENIX Association
Table 3: Results of the comparison tests with different approaches.
Original song + TTS
SRoA of
Group2
SRoA of
Group1
Black
-box
Google
Assistant
Google
Home
Microsoft
Cortana
Amazon
Echo
Target command
Okay Google, take a picture.
Okay Google, navigate to my home.
Okay Google, turn off the light.
Okay Google, play music.
Hey Cortana, open the website.
Hey Cortana, make it warmer.
Echo, turn off the computer.
Echo, call my wife.
Plain
TTS
10/10
10/10
10/10
10/10
10/10
10/10
10/10
10/10
Command
-erSong
0/10
0/10
0/10
0/10
0/10
0/10
0/10
0/10
6/10
3/10
6/10
2/10
6/10
9/10
6/10
4/10
SNR
(dB)
7.15
4.08
4.05
4.53
0.21
3.38
3.39
-0.78
9/10
0/10
0/10
0/10
0/10
0/10
0/10
0/10
SNR
(dB)
6.45
11.98
10.75
11.63
12.01
9.38
14.29
10.78
Devil’s Whisper
SNR
SRoA
(dB)
6.45
12.02
10.73
11.61
12.03
9.34
14.28
10.88
5/10
4/10
7/10
3/10
8/10
9/10
7/10
3/10
Note: (1) The success rate “A/B” indicates that there are A tests success to trigger the command on the black-box platforms in B tests. (2) The results were all
based on the tests conducted in July 2019. (3) Hardware settings: we used ASUS P453U as the audio source and JBL Clip 2 as the speaker for all test cases.
Google Assistant and Microsoft Cortana were tested on Samsung C7100. Amazon Echo and Google Home were tested on Echo 1st gen and Google Home Mini.
Volume of AEs is about 70 dB and distance ranges 5~15 centimeters.
approach is not as effective as our proposed alternate models
based generation with approximation approach.
Alternate models based generation without approxima-
tion. Another intuitive approach is based on the assumption
that if one AE works on multiple models, it is highly possible
that it works on the target model, without the need to approx-
imate the target. We kept the ASpIRE Chain model as the
base model, and trained the Mini Librispeech model without
the tuned TTS corpus. Speciﬁcally, we selected four target
commands from Table 10 in Appendix G to attack Google
command_and_search model and Google Assistant/Home.
We ran the proposed alternate models based generation ap-
proach based on those two models (ASpIRE Chain model and
Mini Librispeech model) to craft AEs. However, as shown
in Table 8 in Appendix D, only one out of four commands
works on Google command_and_search model and Google
Assistant, while all the four commands fail on Google Home.
Other straightforward approaches. We conducted exper-
iments to compare our Devil’s Whisper attack with other
straightforward approaches, i.e., “Plain TTS”, the AEs of
CommanderSong, the “Original song + TTS”. Speciﬁcally, we
selected eight target commands frequently used on four IVC
devices, as shown in Table 3. Each command was covered by
the same original song for different cases. Particularly, sam-
ples in “Original song + TTS” were generated by combining
the song and the TTS command with Adobe Audition soft-
ware [1]. Note that for such a simple combination, whether
the injected command can be clearly heard and therefore in-
terpreted by the IVC depends heavily on the strength of the
signal from the song (in terms of its volume) vs. that of the
command in the TTS audio. To evaluate the perturbation of
the TTS audio on the original song, we calculated the SNR of
the combinations by treating the TTS audio (the command)
as noise and the song as signal.
The results of our experiment are shown in Table 3. Over-
all, the AEs from the Devil’s Whisper attack can effectively
attack the target IVC devices using those commands. Without
any surprise, the “Plain TTS” audios triggered the devices
to act on those commands each time. The AEs produced by
CommanderSong, which is not designed for the black-box
attack, failed to achieve a single success on these devices. As
stated in Section 4.1 under “Initial try”, sometimes Comman-
derSong AEs can be partially recognized as “Hey Google”,
thus waking up Google Assistant/Home. Occasionally, part of
the commands can be recognized by a woken Google Assis-
tant or a Microsoft Cortana. However, none of the AEs (with
the SNR between 2 and 14) could cause the IVC devices to
act on the injected commands.
To produce the samples of “Original song + TTS” case,
we set the volume of each TTS audio clip (the command) to
the same level as in “Plain TTS” case, while adjusting the
volume of the song as follows: (1) to achieve a similar success
rate (SRoA) as our attack AEs (see the column in Table 3
under Group 1), and (2) to keep a similar SNR level as the
AEs (Group 2). As we can see from the table, under a similar
SRoA, all except one combined audio clips (Group 1) have
much lower SNR levels compared with our AEs, indicating
that the commands they include are likely to be much more
perceivable and thus much less stealthy, which has been con-
ﬁrmed in our user study (see Section 6.5, Table 4). The only
exception is featured by a similar SNR as our AE. When tun-
ing the SNR to a level of our AEs, we can see that the SRoA
of most samples (all except one) go down to zero (Group 2).
Also interestingly, even though the SRoA of our AE appar-
ently is below that of the “Original song + TTS” audio clip
for the command “Ok Google, take a picture”, we found that
60% of human users in our study could identify the hidden
command, compared with 0% for our AE.
6.5 Human Perception.
SNR describes the relative strengths between signal and noise,
which is traditionally used to measure the perturbation to data
(e.g., an image) [22]. Naturally, it can also model the distor-
tion to the song caused by an AE (with the song being signal
and the command being noise), and therefore gives an intu-
itive and rough estimate of the AE’s stealthiness: the smaller
SNR is, the larger distortion to the song is imposed, so the
USENIX Association
29th USENIX Security Symposium    2677
Table 4: Results of the human perception evaluation on Devil’s Whisper and original song combined with TTS command.
Twice-recognize (%)
Black-box
Talking (%) Once-recognize (%)
Normal (%)
Approach
Noise (%)
Google
Assistant
Google
Home
Microsoft
Cortana
Amazon
Echo
Average
Devil’s Whisper
Song & TTS
Devil’s Whisper
Song & TTS
Devil’s Whisper
Song & TTS
Devil’s Whisper
Song & TTS
Devil’s Whisper
Song & TTS
14.3
7.1
14.3
1.4
15.7
2.9
25.7
0
17.5
2.9
74.3
2.9
65.7
2.9
64.3
1.4
61.4
5.7
66.4
3.2
11.4
90
20
95.7
20
95.7
12.9
94.3
16.1
93.9