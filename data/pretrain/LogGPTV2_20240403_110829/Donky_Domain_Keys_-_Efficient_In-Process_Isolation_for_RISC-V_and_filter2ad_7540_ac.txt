22
11
SW
Slot 3
Slot 2
Slot 1
Slot 0
10-bit Protection Key
0
22
Figure 3: Donky uses reserved top 10 bits of RISC-V
page-table entries for protection keys.
Signals. Donky is compatible with POSIX signals. It in-
stalls a self-protected signal handler for all signals, and regis-
ters its own protected signal stack (e.g., using sigaction and
sigaltstack). Moreover, Donky Monitor interposes signal-
related system calls to protect its own handler and to allow
domains to register their own signal handlers. Donky Monitor
dispatches arriving signals to the domain that registered the
corresponding handler, if any, and prepares the protection key
policy register and the signal stack accordingly. Normally,
Donky Monitor retrieves the stack pointer from the context
information given to its signal handler. If interrupted in a
domain different from the one registering the handler, Donky
Monitor obtains the stack pointer from its internal bookkeep-
ing data. If no stack exists yet, Donky Monitor allocates a
new stack, similarly to dcalls (cf. Section 4). Donky Monitor
also pushes signal-speciﬁc arguments onto the stack, ensuring
correct operation of domain signal handlers.
5 Hardware Design of Donky
In this section, we present our hardware implementation of
Donky on RISC-V. We design memory protection keys from
the ground up on RISC-V and repurpose the RISC-V N ex-
tension to implement secure call gates in userspace. Further-
more, we describe minimal hardware changes required for
Intel MPK to fully support Donky on x86.
5.1 Donky for RISC-V
To evaluate and fully implement Donky on a hardware level,
we use the Ariane RISC-V core, a 6-stage, single issue, in-
order CPU supporting the RV64IMAC instruction set.
We design memory protection keys for RISC-V, including
our protection key policy register and permission checks in
the MMU. Furthermore, we augment the Ariane CPU with
the N extension and repurpose it to support secure hardware
call gates in userspace. As of now, N extension has only been
used for securing embedded systems [65] (cf. Section 2). To
our knowledge, we are the ﬁrst to implement and utilize it
for securing a non-embedded system. Our Donky exception
mechanism not only guarantees the security of memory pro-
tection keys itself. It additionally enables lazy scheduling of
protection keys, system call ﬁltering in userspace, as well as
virtualization of Donky and the N extension.
Memory Protection Keys. Protection keys are conﬁgured
in the page-table entries (PTE) of a process. RISC-V currently
Figure 4: Our RISC-V Donky userspace register (DKRU)
has four protection key slots with optional write-disable
(WD), a monitor bit, and software-deﬁned (SW) space.
deﬁnes two 64-bit virtual memory systems: Sv39 and Sv48,
with 39 and 48-bit address spaces, respectively. As shown in
Figure 3, both have the upmost 10 bits of a PTE reserved for
possible future extensions and to facilitate research experi-
mentation [27]. For Donky, we use these 10 bits for memory
protection keys, allowing 1024 different protection keys.
Policy register.
Intel MPK keeps the permissions for their
16 protection keys in a single 32-bit register. However, as
Donky supports a much higher number of 1024 keys, this is
not possible. Instead, we implement key slots, allowing for
four simultaneously loaded protection keys in our 64-bit DKRU
register (cf. Figure 4). Each key slot holds a 10-bit protection
key. Only if a protection key is loaded, its associated memory
pages can be read or written. Furthermore, each slot has a
write-disable bit in the upmost slot bit to enforce read-only
memory. While previous architectures [22, 63] also supported
large keys, Donky only uses a single register and allows pure
userspace management of the DKRU register.
We add the DKRU register as a user-mode control and status
register (CSR). Thus, DKRU can be, in principle, conﬁgured
with standard CSR instructions from all privilege levels. The
upmost bit of the DKRU register is the so-called monitor bit.
If cleared, any access to DKRU is disallowed from user mode
(see Figure 4). Thus, by clearing this monitor bit, Donky
Monitor can prevent unauthorized alteration of the protection
key policy. The monitor bit can only be set again by privileged
software or by triggering the hardware call gate into Donky
Monitor. Finally, DKRU offers 19 software-deﬁned bits (SW),
which Donky Monitor can freely use to store metadata, such
as the domain ID. To support multicore systems, DKRU is
core-local, as is PKRU for x86.
Donky CPU exception. We deﬁne a new CPU exception
called Donky exception. It is raised whenever Donky detects
a security violation while the monitor bit in DKRU is cleared.
This includes memory access checks as well as illegal access
to DKRU or CSR’s deﬁned by the N extension. We extend
the memory management unit (MMU) of the Ariane core
to verify that for any data access, the protection key in the
corresponding PTE matches at least one key loaded in DKRU.
For store operations, the MMU also checks the corresponding
write-disable bits in DKRU. For backward compatibility, we
exempt protection key zero, which is the default value of
PTEs, from the above checks.
Hardware call gate and the N extension. The N extension
allows the kernel to delegate interrupts and exceptions to a
USENIX Association
29th USENIX Security Symposium    1683
user mode exception handler via the sedeleg CSR. This user
handler can be speciﬁed via utvec. A separate uscratch
register offers scratch space for setting up an exception stack.
We integrate our Donky hardware call gate into the N exten-
sion as follows: First, the utvec and uscratch CSRs cannot
be accessed if the monitor bit in the DKRU register is cleared.
Second, for any delegated user exception, the CPU sets the
monitor bit, disabling Donky protection. Third, when return-
ing from the user handler with uret, the CPU automatically
clears the monitor bit, enforcing protection again. This call
gate mechanism ensures the security of Donky Monitor. At
initialization, Donky Monitor conﬁgures utvec to point to
its entry point and clears the monitor bit. Since Donky Mon-
itor protects its own memory using protection keys, Donky
Monitor can only be invoked at this well-deﬁned entry point
by triggering, e.g., a Donky exception. Any other attempt to
divert code execution into Donky Monitor will keep the mon-
itor bit cleared and, thus, prevent manipulation of DKRU and,
consequently, Donky Monitor data.
Scheduling of protection keys.
If a domain accesses mem-
ory for which no protection key is loaded, a Donky exception
is triggered that invokes Donky Monitor. Donky Monitor val-
idates whether the access is allowed, and loads the missing
protection key into DKRU. This happens completely transpar-
ent to the domain. To decide which slot to use for the new key,
Donky Monitor currently uses a round-robin based technique
on key slots 1-3. Slot 0 is always reserved for the domain’s
default key. Of course, more sophisticated key scheduling
methods can be implemented as well. As our scheduling
mechanism purely operates on userspace data structures, it
does not need expensive kernel invocations to schedule keys
and permissions in the PTEs [64].
Syscall ﬁltering in userspace. Donky supports lightweight
system call ﬁltering entirely in userspace. On RISC-V, system
calls are triggered via the ecall instruction, which throws
a dedicated exception. We use the same N extension dele-
gation mechanism (sedeleg) to delegate these system call
exceptions directly to Donky Monitor. If the monitor bit is
set, however, the system call is forwarded to the kernel. This
allows Donky Monitor to do actual system calls.
Note that, while part of our design, our proof-of-concept
prototype does not use system call delegation but instead uses
a small kernel module to enforce system call interposition.
This simpliﬁes the evaluation of our x86 emulation mode.
Virtualization. Donky supports virtualization of the DKRU
and the N extension CSRs. As long as the monitor bit is
cleared, all accesses to the corresponding CSRs are blocked.
Instead, they raise a Donky exception that traps to Donky
Monitor, allowing it to emulate the desired behavior of both,
DKRU and the N extension. This is in line with RISC-V’s trap-
and-emulate approach to, e.g., implement missing hardware
extensions in software. Hence, other schemes can utilize the
N extension or protection keys for their own purposes without
knowledge of Donky, e.g., to achieve CFI [41].
Linux support. The Linux kernel already supports the
RISC-V ISA. However, it does not support its N extension
yet. We extended the Linux kernel 5.1 with our modiﬁed N
extension and have ported the memory protection key fea-
ture, which already existed for other architectures. For this,
we added all registers necessary for the N extension, as well
as DKRU, to the relevant per-thread kernel structs used during
context-switch. The kernel also delegates Donky exceptions
to the userspace by conﬁguring sedeleg. In total, 700 LoC
were changed to support Donky on RISC-V.
Hardware Utilization. The total utilization of our modiﬁed
Ariane RISC-V CPU on our evaluation board is 69 321 LUTs
(+1.85 %) and 51 395 FFs (+0.94 %) to the unmodiﬁed CPU.
The increase is due to the CSRs of the N extension as well as
our DKRU CSR, and the corresponding control logic.
5.2 Extension to Intel MPK
Intel MPK lacks a mechanism for safeguarding its protection
key policy register. The PKRU register can be changed by
anyone via the unprivileged WRPKRU instruction. Thus, MPK
does not provide the same security as Donky, and schemes
using it impose limitations (CFI, W⊕X, and binary scanning).
We propose the following adaptations to make MPK beneﬁt
from Donky. Similar to RISC-V, we propose a secure hard-
ware call gate to a trusted handler (Donky Monitor), which
safeguards access to PKRU. This can be achieved by having
one additional Donky Handler Register (DKHR), similar to
utvec, specifying the handler address. Two new instructions
allow entering and exiting the handler. The DENTER instruc-
tion acts similarly to SYSENTER. It enables write access to the
PKRU and jumps to the address in DKHR. The register rcx will
contain the return address (i.e., the address following DENTER).
Similar to SYSRET, DRET returns to the previous code (stored
in rcx, and disables write access to PKRU.
We propose using the top-most bit of DKHR as the monitor
bit to control write access to PKRU as well as DKHR. It is set and
cleared by DENTER and DRET, respectively. The monitor bit
also decides if MPK access violations should be triggered and
delegated to DKHR. This is required to permit Donky Monitor
to access all application memory. DKHR exists per core, and
the operating system saves and restores it at context switches.
New processes automatically have the top-most bit set, so that
they can set up DKHR themselves. This also provides backward
compatibility for programs unaware of DKHR.
While x86 does not have a native system call delegation
feature like RISC-V, it could be implemented via a hypervisor.
However, for better performance, we envision a lightweight
hardware extension similar to our RISC-V design: while the
monitor bit is set, syscalls should be delegated to the monitor.
More keys. MPK currently only uses 4 PTE bits, supporting
16 protection keys. Since PTE bits 46-51 are reserved for
future use, they could be repurposed to support 1024 keys.
The same key slotting, as in Figure 4, could be used for PKRU.
1684    29th USENIX Security Symposium
USENIX Association
6 Security and Performance Evaluation
In this section, we evaluate both the security of Donky, as well
as its performance using both micro and macro benchmarks.
6.1 Security Evaluation
The security of Donky is built on several layers. First, the
security of its building blocks, i.e., memory isolation, call
gates, and kernel interaction via system calls and signals.
Second, the security of Donky Monitor, its API, and dcalls.
And third, the security of a concrete application leveraging
Donky. We defer the latter to our case studies in Section 7.
Hardware Call Gates. We prevent code-reuse attacks on
Donky Monitor as it can only be legitimately entered via a
hardware call gate. Donky exceptions are delivered to this
call gate, and the CPU enables the monitor bit inside DKRU.
Note that for Donky and Intel MPK, code fetches are not
subject to protection key checks, as opposed to read and write
data accesses. However, this is not a security issue. If a domain
jumps into Donky Monitor code, it cannot manipulate DKRU,
utvec, and uscratch since the monitor bit in DKRU is still
cleared. Moreover, it cannot access Donky Monitor data since
it uses a different protection key. Exempting code fetches from
protection key checks simpliﬁes code sharing across domains
and also allows implementing execute-only memory [97]. As
our threat model already considers arbitrary code execution,
access to more code does not weaken our security guarantees.
System Calls and Signals. A third building block is to safe-
guard kernel functionality, i.e., system calls and signals that
allow bypassing Donky. Donky interposes system calls by
redirecting them to Donky Monitor such that a malicious
domain cannot bypass it. For our prototype, we implement
a traditional approach, blacklisting dangerous system calls
directly in the kernel unless issued by Donky Monitor. For
RISC-V, we describe a hardware mechanism to interpose sys-
tem calls without kernel involvement. Donky Monitor ﬁlters
system calls based on two criteria. First, it constrains syscalls
to uphold domain isolation. Second, an application can install
arbitrary domain-speciﬁc system call ﬁlters, similar to sec-
comp. Deﬁnition of appropriate ﬁlter rules is crucial for any
domain isolation scheme, yet an orthogonal problem to study
(e.g., boomerang attacks [52]). To demonstrate feasibility, our
prototype ﬁlters memory-related system calls (e.g., mmap,
mprotect) to only operate on memory of the current domain.
Our prototype does not yet implement signal handling, as
this is merely an engineering effort. Since our use case studies
do not strictly demand signals, this has no effect on perfor-
mance. Nevertheless, we argue why signal handling with
Donky can be implemented securely. First, Donky Monitor
can protect the signal origin by only accepting signals from
the kernel, discarding fake ones (i.e., induced by malicious
code jumping into the monitor’s signal handler). Since Linux
drops PKRU privileges to protection key zero during signal
dispatch, which malicious domains cannot achieve, this boils
down to a simple PKRU check. Second, signal delivery is safe-
guarded by interposing the registration of signal handlers and
loading the correct stack and protection key policy register.
Third, interruption of Donky Monitor itself (e.g., via asyn-
chronous signals) is not a security issue when using its own
protected signal stack and blocking normal Donky API calls
and dcalls for the interrupted thread until signal handling is
ﬁnished.
Donky Monitor. The above building blocks guarantee the
security of Donky Monitor, which is the base for all security
services offered by the Donky API. For domains, Donky Mon-
itor stores critical domain metadata in its internal protected
data structures, and per-thread information is kept in protected
thread-local storage. Donky Monitor carefully validates all
untrusted input given to Donky API to avoid confused deputy
or corruption attacks [12, 36]. Furthermore, we ensure that
stack pointers are within a domain’s memory before accessing
it inside Donky Monitor.
Donky API. The expressiveness of Donky API allows to
represent a variety of protection models, e.g., hierarchical
sandboxing, vaults, shared memory, and mutual distrust. To
study the concrete security guarantees of a program using
Donky is a research ﬁeld on its own, and a general statement
cannot be made. One could, for example, analyze concrete
security properties as a sequence of graphs via the take-grant
model [49]. Since this is orthogonal to our work, we will focus
on the security of our use case scenarios from a programmer’s
perspective instead, which we defer to Section 7.
We informally describe Donky API rules in terms of the
take-grant model. Donky API is designed such that domains
can only handle their own resources. These resources include
a domain’s memory, protection keys, call gates as well as its
child domains. A domain can request new resources (create
rule), constrain their usage (remove rule), grant permission to
other domains (grant rule), but not access foreign resources
(limited take rule). The grant rule allows domains to open
up its call gates to other domains, or share their protection
keys. The remove rule fosters the concept of least privilege
by dropping ownership of protection keys, reducing their us-
age rights, or releasing a parent-child relationship. Unless
released, a parent domain can always act on behalf of its child
domains. The limited take rule only allows elevating privi-
leges on resources for which a domain already has ownership.
For example, if a domain owns a protection key, it is eligible
to reprotect the associated memory, e.g., from read-only to
read-write (mprotect system call). For granting another do-
main read-only access to its memory, a domain would create
a copy of the associated protection key without ownership.
Secure dcalls. Domain transitions via dcalls demand proper
stack management and handling of CPU registers. On the
one hand, DonkyLib maintains the call stack abstraction to
prevent domains from returning from a dcall that has not
been called [12]. We do so by pushing metadata on the caller
USENIX Association