title:BwE: Flexible, Hierarchical Bandwidth Allocation for WAN Distributed
Computing
author:Alok Kumar and
Sushant Jain and
Uday Naik and
Anand Raghuraman and
Nikhil Kasinadhuni and
Enrique Cauich Zermeno and
C. Stephen Gunn and
Jing Ai and
Bj&quot;orn Carlin and
Mihai Amarandei-Stavila and
Mathieu Robin and
Aspi Siganporia and
Stephen Stuart and
Amin Vahdat
BwE: Flexible, Hierarchical Bandwidth Allocation for
WAN Distributed Computing
Alok Kumar
Björn Carlin
Nikhil Kasinadhuni Enrique Cauich Zermeno C. Stephen Gunn
Mihai Amarandei-Stavila
Stephen Stuart
Mathieu Robin
Amin Vahdat
Sushant Jain
Uday Naik
Anand Raghuraman
Jing Ai
Aspi Siganporia
Google Inc.
PI:EMAIL
ABSTRACT
WAN bandwidth remains a constrained resource that is eco-
nomically infeasible to substantially overprovision. Hence,
it is important to allocate capacity according to service pri-
ority and based on the incremental value of additional allo-
cation. For example, it may be the highest priority for one
service to receive ˇ«Gb/s of bandwidth but upon reaching
such an allocation, incremental priority may drop sharply
favoring allocation to other services. Motivated by the ob-
servation that individual (cid:6)ows with ßxed priority may not
be the ideal basis for bandwidth allocation, we present the
design and implementation of Bandwidth Enforcer (BwE),
a global, hierarchical bandwidth allocation infrastructure.
BwE supports: i) service-level bandwidth allocation follow-
ing prioritized bandwidth functions where a service can rep-
resent an arbitrary collection of (cid:6)ows, ii) independent alloca-
tion and delegation policies according to user-deßned hier-
archy, all accounting for a global view of bandwidth and fail-
ure conditions, iii) multi-path forwarding common in traıc-
engineered networks, and iv) a central administrative point
to override (perhaps faulty) policy during exceptional con-
ditions. BwE has delivered more service-eıcient bandwidth
utilization and simpler management in production for mul-
tiple years.
CCS Concepts
•Networks→ Network resources allocation; Network man-
agement;
Permission to make digital or hard copies of part or all of this work for personal
or classroom use is granted without fee provided that copies are not made or
distributed for proﬁt or commercial advantage and that copies bear this notice
and the full citation on the ﬁrst page. Copyrights for third-party components of
this work must be honored. For all other uses, contact the owner/author(s).
SIGCOMM ’15 August 17-21, 2015, London, United Kingdom
© 2015 Copyright held by the owner/author(s).
ACM ISBN 978-1-4503-3542-3/15/08.
DOI: http://dx.doi.org/ˇ«.ˇˇ(cid:16)(cid:1)/(cid:134);˚(cid:1)(cid:149)(cid:1)E.(cid:134);˚;(cid:16);˚
Keywords
Bandwidth Allocation; Wide-Area Networks; So(cid:22)ware-
Deßned Network; Max-Min Fair
1.
INTRODUCTION
TCP-based bandwidth allocation to individual (cid:6)ows con-
tending for bandwidth on bottleneck links has served the In-
ternet well for decades. However, this model of bandwidth
allocation assumes all (cid:6)ows are of equal priority and that all
(cid:6)ows beneßt equally from any incremental share of available
bandwidth. It implicitly assumes a client-server communi-
cation model where a TCP (cid:6)ow captures the communication
needs of an application communicating across the Internet.
his paper re-examines bandwidth allocation for an im-
portant, emerging trend, distributed computing running
across dedicated private WANs in support of cloud comput-
ing and service providers. housands of simultaneous such
applications run across multiple global data centers, with
thousands of processes in each data center, each potentially
maintaining thousands of individual active connections to
remote servers. WAN traıc engineering means that site-pair
communication follows di(cid:242)erent network paths, each with
di(cid:242)erent bottlenecks. Individual services have vastly di(cid:242)er-
ent bandwidth, latency, and loss requirements.
We present a new WAN bandwidth allocation mechanism
supporting distributed computing and data transfer. BwE
provides work-conserving bandwidth allocation, hierarchi-
cal fairness with (cid:6)exible policy among competing services,
and Service Level Objective (SLO) targets that independently
account for bandwidth, latency, and loss.
BwE’s key insight is that routers are the wrong place to map
policy designs about bandwidth allocation onto per-packet
behavior. Routers cannot support the scale and complex-
ity of the necessary mappings, o(cid:22)en because the semantics
of these mappings cannot be captured in individual packets.
Instead, following the End-to-End Argument[(cid:134)˚], we push
all such mapping to the source host machines. Hosts rate
limit their outgoing traıc and mark packets using the DSCP
ßeld. Routers use the DSCP marking to determine which
1path to use for a packet and which packets to drop when
congested. We use global knowledge of network topology
and link utilization as input to a hierarchy of bandwidth en-
forcers, ranging from a global enforcer down to enforcers on
each host. Bandwidth allocations and packet marking pol-
icy (cid:6)ows down the hierarchy while measures of demand (cid:6)ow
up, starting with end hosts. he architecture allows us to de-
couple the aggregate bandwidth allocated to a (cid:6)ow from the
handling of the (cid:6)ow at the routers.
BwE allocates bandwidth to competing applications based
on (cid:6)exible policy conßgured by bandwidth functions cap-
turing application priority and incremental utility from ad-
ditional bandwidth in di(cid:242)erent bandwidth regions. BwE
supports hierarchical bandwidth allocation and delegation
among services while simultaneously accounting for multi-
path WAN communication. BwE is the principal bandwidth
allocation mechanism for one of the largest private WANs
and has run in production for multiple years across hundreds
of thousands of end points. he systems contributions of our
work include:
● Leveraging concepts from So(cid:22)ware Deßned Network-
ing, we build a unißed, hierarchical control plane for
bandwidth management extending to all end hosts. In
particular, hosts report per-user and per-task demands
to the control plane and rate shape a subset of (cid:6)ows.
● We integrate BwE into existing WAN traıc engineer-
ing (TE) [ˇ;, ˇˇ, ˇ(cid:134)] mechanisms including MPLS Auto-
Bandwidth [(cid:134)(cid:134)] and a custom SDN infrastructure. BwE
takes WAN pathing decisions made by a TE service
and re-allocates the available site-to-site capacity, split
across multiple paths, among competing applications.
At the same time, we beneßt from the reverse integra-
tion: using BwE measures of prioritized application de-
mand as input to TE pathing algorithms (Section (cid:1).t.ˇ).
● We implement hierarchical max-min fair bandwidth al-
location to (cid:6)exibly-deßned FlowGroups contending for
resources across multiple paths and at di(cid:242)erent levels of
network abstraction. he bandwidth allocation mech-
anism is both work-conserving and (cid:6)exible enough to
implement a range of network sharing policies.
In sum, BwE delivers a number of compelling advantages.
First, it provides isolation among competing services, deliv-
ering plentiful capacity in the common case while maintain-
ing required capacity under failure and maintenance scenar-
ios. Capacity available to one service is largely independent of
the behavior of other services. Second, administrators have a
single point for specifying allocation policy. While pathing,
RTT, and capacity can shi(cid:22) substantially, BwE continues to
allocate bandwidth according to policy. Finally, BwE enables
the WAN to run at higher levels of utilization. By tightly inte-
grating loss-insensitive ßle transfer protocols running at low
priority with BwE, we run many of our WAN links at (cid:149)«(cid:236)
utilization.
Figure ˇ: WAN Network Model.
2. BACKGROUND
ˇ and C(cid:134)
We begin by describing our WAN environment and high-
light the challenges we faced with existing bandwidth alloca-
tion mechanisms. housands of individual applications and
services run across dozens of wide area sites each containing
multiple clusters. Host machines within a cluster share a com-
mon LAN. Figure ˇ shows an example WAN with sites Sˇ, S(cid:134)
and St; Cˇ
ˇ are clusters within site Sˇ.
We host a combination of interactive web services, e.g.
search and web mail, streaming video, batch-style data pro-
cessing, e.g., MapReduce [ˇt], and large-scale data transfer
services, e.g., index copy from one site to another. Cluster
management so(cid:22)ware maps services to hosts independently;
we cannot leverage IP address aggregation/preßx to identify
a service. However, we can install control so(cid:22)ware on hosts
and leverage a control protocol running outside of routers.
We started with traditional mechanisms for bandwidth al-
location such as TCP, QoS and MPLS tunnels. However these
proved inadequate for a variety of reasons:
● Granularity and Scale: Our network and service capac-
ity planners need to reason with bandwidth allocations
at di(cid:242)erent aggregation levels. For example, a prod-
uct group may need a specißed minimum of site-to-site
bandwidth across all services within the product area.
In other cases, individual users or services may require
a bandwidth guarantee between a specißc pair of clus-
ters. We need to scale bandwidth management to thou-
sands of individual services, and product groups across
dozens of sites each containing multiple clusters. We
need a way to classify and aggregate individual (cid:6)ows
into arbitrary groups based on conßgured policy. TCP
fairness is at a (cid:1)-tuple (cid:6)ow granularity. On a congested
link, an application gets bandwidth proportional to the
number of active (cid:6)ows it sends across the links. Our
services require guaranteed bandwidth allocation inde-
pendent of the number of active TCP (cid:6)ows. Router QoS
and MPLS tunnels do not scale to the number of service
classes we must support and they do not provide suı-
cient (cid:6)exibility in allocation policy (see below).
● Multipath Forwarding: For eıciency, wide area packet
forwarding follows multiple paths through the net-
work, possibly with each path of varying capac-
ity. Routers hash individual service (cid:6)ows to one of
the available paths based on packet header content.
2Any bandwidth allocation from one site to another
must simultaneously account for multiple source/des-
tination paths whereas existing bandwidth allocation
mechanisms—TCP, router QoS, MPLS tunnels—focus
on di(cid:242)erent granularity ((cid:6)ows, links, single paths re-
spectively).
● Flexible and Hierarchical Allocation Policy: We found
simple weighted bandwidth allocation to be inade-
quate. For example, we may want to give a high pri-
ority user a weight of ˇ«.« until it has been allocated ˇ
Gb/s, a weight of ˇ.« until it is allocated (cid:134) Gb/s and a
weight of «.ˇ for all bandwidth beyond that. Further,
bandwidth allocation should be hierarchical such that
bandwidth allocated to a single product group can be
subdivided to multiple users, which in turn may be hi-
erarchically allocated to applications, individual hosts
and ßnally (cid:6)ows. Di(cid:242)erent allocation policies should
be available at each level of the hierarchy.
● Delegation or Attribution: Applications increasingly
leverage computation and communication from a vari-
ety of infrastructure services. Consider the case where
a service writes data to a storage service, which in
turn replicates the content to multiple WAN sites for
availability. Since the storage service acts on behalf of
thousands of other services, its bandwidth should be
charged to the originating user. Bandwidth delegation
provides di(cid:242)erential treatment across users sharing a
service, avoids head of line blocking across traıc for
di(cid:242)erent users, and ensures that the same policies are
applied across the network for a user’s traıc.
We designed BwE to address the challenges and require-
ments described above around the principle that bandwidth
allocation should be extended all the way to end hosts. While
historically we have looked to routers with increasingly so-
phisticated ASICs and control protocols for WAN bandwidth
allocation, we argue that this design point has resulted sim-
ply from lack of control over end hosts on the part of net-
work service providers. Assuming such access is available, we
ßnd that the following functionality can be supported with
a hierarchical control infrastructure extending to end hosts:
i) mapping WAN communication back to thousands of (cid:6)ow
groups, ii) (cid:6)exibly sub-dividing aggregate bandwidth alloca-
tions back to individual (cid:6)ows, iii) accounting for delegation
of resource charging from one service to another, and iv) ex-
pressing and enforcing (cid:6)exible max-min bandwidth sharing
policies. On the contrary, existing routers must inherently
leverage limited information available only in packet headers
to map packets to one of a small number of service classes or
tunnels.
Figure (cid:134) shows an instance of very high loss in multiple
QoS classes during a capacity reduction on our network. TCP
congestion control was not e(cid:242)ective and the loss remained