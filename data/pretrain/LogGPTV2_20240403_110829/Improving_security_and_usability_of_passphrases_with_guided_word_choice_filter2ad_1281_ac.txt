significant impact on overall success rate in either group, with a
small decrease in misses and a increase in false words (p > 0.05).
We can also restrict the analysis to those who remembered the
passphrase correctly just after making it in the first exercise (the
one asking them to type the first two letters of each word). This is
shown in Table 9.
Remarks. The preceding error tables do not take into account
four anomalous behaviours. Two participants (one in each group)
2In the table, there is one more participant per group in the second section than there
should be. This is due to one participant in group 100 double-clicking the submit
button and getting directly to the second section, and one participant in group 20
writing nonsense in the first section but getting five correct words in the second.
made a typo in their original passphrase (phrases were only counted
as correct when typed without the typo). One participant, when
asked for the first two letters for each word in their passphrase,
typed random letters on their keyboard, and one typed something
that looked like the requested twelve-character string with lots of
mistakes. Both of those were in group 20 and were not counted
in the analysis. One participant in group 100 also double-clicked
on the next button and was taken directly to the second try and
shown their array of words. Finally, four participants in the control
group showed no attempt to recall their passphrase, responding
with random words (and in one case not even filling the 6 phrase
positions), and were removed from the dataset. Including these
would have only strengthened the results that guided choice helps.
Language. People that identified their primary language as Eng-
lish were balanced between the two groups (25 of 51 in group 100
and 26 of 47 in the other). Language did not show a statistically
significant effect: 21 out of 51 people who indicated English as their
primary language were correct on the first try, as were 23 out of the
48 who indicated another language. Primary English speakers had
more misses (29 against 13) and an equal share of wrong words.
Time. No statistically significant advantage was shown for par-
ticipants who spent more time designing their passphrase. People
who recalled their words perfectly appeared to take 5-10% longer
on average, but 10-15% less time for the median, showing no clear
effect.
Some of the participants disabled the JavaScript functions needed
to record the time taken3.
4.3 Guessing
Most participants only tried to guess a single other passphrase, but
21 participants tried to guess between 2 and 4 passphrases. Words
that were in the original passphrase with a minor modification
(such as a typo) were counted as correct in this exercise, like those
that were only in the wrong place.
On average, participants succeeded at guessing 0.85 out of 6
words chosen by another person from 100 word arrays, and 2.15
out of 6 words from 20 word arrays. This is significantly higher than
a random guess (which would on average get 0.36 and 1.80 words
correct), but not better than an educated guess focusing on common
words or positions. With access to the array, positional guessing
would get respectively 0.63 and 2.21 words correct. Purely semantic
guessing would get respectively 1.40 and 2.93 words correct.
3These are disabled by default on most Apple iPhones.
Improving security and usability of passphrases with guided word choice
Conference’17, July 2017, Washington, DC, USA
Figure 10: Cumulative distribution function of indices of words chosen for both groups and 6 models
5 STATISTICAL MODELLING
5.1 Strategies and entropy
The effect of participant choice on the entropy of passphrases was
tested. Models simulated in Python were used to analyse the word
choice of participants when presented with arrays of words, with
three main strategies:
The Smallest(n) strategy corresponded to picking the six most
frequent words presented in the array of n words.
The Uniform(n) strategy being equivalent to sampling random
words uniformly from a dictionary of size n, entropy was computed
exactly. The table in Figure 11 shows the entropy per word for each
of the described strategies, as well as a few others. The 87691 here
corresponds to our described dictionary of 87691 words, and 300000
to Norvig’s more complete dictionary of 300000 words.
Finally, the Corpus(n) strategy corresponded to picking each
word from an array of n words according to a distribution where the
probability to pick each word w is a function of f (w), its frequency
in the language. This corresponds to models for how the distribution
of words in the English language – among others – is biased in
many different corpora of texts. The model used here is Zipf’s
law[Ha et al. 2002], stating that the probability of choosing a word
p(w), is inversely proportional to its rank in the frequency list:
p(w) ∝
1
rank(w)
Informally, the 100th most used word is chosen with a frequency
about twice the frequency of the 200th most used word.
109 simulations were run for both 20-word and 100-word arrays
with each strategy to estimate the probabilities – and the entropy4.
For entropy E, the formula to compute it is:
piln(pi)
E = −
i
In this formula, pi is the position in an ordering of word frequency
that the word occupies in the array of words.
A much bigger sample would be needed to exactly compute the
entropies of user behaviours. However, experimental entropy can
be bounded by using distributions for known entropies. As such,
the cumulative distribution functions for the experimental groups
and models were computed. Although they do not make direct
strategic sense, we included Corpus(17) and Corpus(13) in Figure 10,
as they bound the observed curve for group 20.
Experimental values for group 20 are slightly above Corpus(17)
around the 50000th word. An upper bound of Corpus(20) could be
chosen, but there is a strong argument for using Corpus(17). This is
more affected by the values of the high pi, as the function changes
less as it gets to the least common words (making it concave). As
the pis shown in Figure 10 are also sorted in decreasing order, it
means a small bump in word choice in the first part of the curve is
4The error bounds due to the simulations are quite smaller than 0.01 bits.
020000400006000080000Rank of n in the dictiona y (so ted by dec easing f equency)0.00.20.40.60.81.0P(X≤n)Smallest(20)Co pus(100)Co pus(30)Co pus(20)Co pus(17)Co pus(13)G oup 20G oup 100Conference’17, July 2017, Washington, DC, USA
Nikola K. Blanchard, Clément Malaingre, Ted Selker
Figure 11: Strategies and entropy
Strategy
Uniform(87691)
Corpus(13)
Corpus(17)
Corpus(20)
Corpus(30)
Corpus(100)
Uniform(10000)
Smallest(20)
Uniform(5000)
Uniform(2000)
Smallest(100)
Corpus(300000)
Corpus(87691)
Entropy (bits)
16.42
16.25
16.15
16.10
15.92
15.32
13.29
12.55
12.29
10.97
10.69
8.94
8.20
p(w) ∝
1
(rank(w))β
more than compensated by the lack of a bump in the second part.
As such, it is reasonable to infer that the entropy corresponding to
participants’ behaviours in this group is between Corpus(13) and
Corpus(17).
A slightly tighter fit can be obtained by taking not the simplest
Zipf’s formula but the more general one, with, for β > 1:
In such a case, setting β = 1.35 makes Corpus-Zipf (13) a tighter fit
than previous curves, giving an entropy of 16.19 bits5. However,
the presence of noise in the data means that a search for a more
accurate model would be premature.
All in all, this shows that six-word passphrases generated with
the method proposed and a 100-word array have at least 95 bits of
entropy, and ones created with a 20-word array have nearly 97 bits
of entropy.
5.2 Semantic aspects
This section has focused on the frequency of words as a proxy for
their familiarity. This ignores other possibilities such as emotional
attachment to certain words, linked to the particularities of each
user. For example, a dog owner would most probably choose the
word dog if it appeared in the array. We can show here that the
magnitude of such an effect should be quite low.
Let’s suppose that each user has a list of 100 words that they
will automatically choose whenever they appear. They have the
opportunity of choosing such a word with probability at most
1 − (1 − 100
87685)100 ≈ 11%
An adversary with the word list could, for each position, try this list
of words and fill the rest with a dictionary6, lowering the number of
possibilities to test. With probability 0.11, such an adversary could
then reduce the total entropy from 95 bits to 89 bits.
Moreover, many emotionally-loaded words such as "dog", "love"
or "president" are already among the most frequent words (the ones
given are all in the top 1000). As such, most people would choose
them with a high probability, no matter their individual preferences,
so the marginal information – and the corresponding entropy loss
– should be even lower than the bound already given.
6 LIMITATIONS
6.1 Ecological validity
As this was an online study which did not happen in a controlled
laboratory environment, anomalous participant behaviour could
not be detected. The main risk we can think of comes from users
writing down their passwords somewhere, affecting the memorabil-
ity results. Two arguments make it probable that this had little to
no impact on the results. The first comes from the fact that writing
down one’s passphrase should take a certain amount of time, and
there was no demonstrated correlation between the speed during
the creation and the ability to remember one’s passphrase correctly.
The second comes from [Yang et al. 2016], where participants in
the study were encouraged to create passphrases and use any tech-
nique they generally used to remember passwords and passphrases.
Despite knowing in advance that they would have to remember
the passphrase for a week, over 80% of participants reported not
having written down their passphrase.
6.2 Short-term and long-term memory
As the users were not asked any identifying information, it was not
possible to ask them to return to the experiment, to estimate the
effects of the method on long-term memorability of passphrases.
The main reason we added the distractor task in the experimental
protocol was to affect the participant’s short-term memory to look
at long-term memory effects. We compared our recall rates with
the long-term recall rates for the variety of passphrase creation
strategies shown in [Yang et al. 2016]. The after-distractor mem-
orability observed here is closer to the long-term memorability
they observed. This is consistent with the fact that no variation in
recall rates between strategies was observed in their short-term
experiment, unlike their long-term experiment and our data.
6.3 Free choice of words
This study did not include a fourth group who were free to choose
words in any way they wanted. This could have been interesting
in the goal of comparing memorability but two factors motivated
the absence of this second sort of control group. The first is that
we could not ensure that people would pick new sentences and not
ones they were already trained on, which would skew the results.
More importantly, we believe that the behaviours observed in [Yang
et al. 2016] indicate that free word choice is too much of a security
concern, and not a viable option.
5One could also use a Zipf-Mandelbrot model [Oldfield 1968], but the additional
parameter would be hard to validate accurately without having a sample of at least
10000 participants
6Getting a single word from the list is already a low-probability event, and getting
more than one happens with probability at most 2 ∗ 10−4.
Improving security and usability of passphrases with guided word choice
Conference’17, July 2017, Washington, DC, USA
7 DISCUSSION
The above results demonstrate that passphrases created by choos-
ing words from an array of random words are more memorable
than automatically generated ones. While past studies have shown
that choosing familiar words for passphrases led to huge entropy
reductions, our technique obviated this. The entropy cost due to
the choice in our system is negligible, staying between 1% and 3%
depending on array size. The method also allows the use of a larger
dictionary to choose known words from, leading to much higher
entropy per word in the end.
Multiple surprising behaviours were observed, confirming cer-
tain hypotheses and refuting others. Firstly, the participants’ choices
were influenced by the positions of the words in the arrays pre-
sented to them. In group 20, this led 41% of them to choose the word
in the upper left corner, instead of the expected 30%. Variations of a
factor two between different lines of the array were found in group
100. There was a significant bias in favour of the last lines, and a
smaller one for the top line, with no significant horizontal effect7.
The tendency to choose familiar words was stronger than the
positional bias, although the linguistic bias was still weaker than
the one in the English language (as predicted by Zipf’s law). We
observed that Corpus(13-17) might be better fits than Corpus(20)