designs with a secure reinitialization process, as ﬁrst pro-
posed in [28] and further detailed in [35]. But these solu-
tions and, in fact, any leakage-resilient reinitialization pro-
cess in a stateless device (i.e., a device that does not save
any part of its state between two reinitializations), would
be incompatible with an adaptive selection of the leakage
function. Indeed, if the adversary is allowed to obtain a dif-
ferent leakage function of the ﬁrst round internal state after
every reinitialization of the cipher, then leakage functions
that output one single bit of the key are again suﬃcient to
get the full secret key after a few dozen of reinitializations.
Therefore, at least, one should require that when reinitial-
izing a device to the same state (e.g., with the same IV), the
leakage function cannot be modiﬁed adaptively. But from
an operational point of view, the adaptivity of the leakage
function relates to the ability to change the measurement
conditions during a side-channel attack (e.g., the antenna’s
position in an electromagnetic analysis). Hence, whatever
modiﬁcation of the setup that an adversary can do when
reinitilizing to a new state can also be done when reinitial-
izing to a constant state. These observations suggest that
considering adaptively selected leakage functions provides an
overly strong model. We will therefore consider static leak-
ages functions determined before an execution starts, which
are reused after each resynchronization. This will provide
the important beneﬁt of making it possible to avoid the al-
ternating structure in our construction of Section 4.
We note that this assumption corresponds to the way side-
channel attacks are often conducted in practice, i.e.
in a
setting where the leakage function is determined in advance
by the analyzed device and measurement equipment, and
not adaptively chosen by the adversary during the measure-
ments. It is also done without loss of generality. In order
to reﬂect the possible adaptivity of the measurement condi-
tions, we can include it in the adversary’s abilities and quan-
tify it directly in the bounded leakage assumption (i.e., adap-
tive leakage functions imply slightly more leakage). This is,
in fact, how an actual security evaluation would proceed, i.e.
by ﬁnding the best probe(s) position(s) and evaluating the
resulting leakage as a function of the data complexity.
3. STATEFUL STREAM CIPHERS
3.1 Motivation
Generating pseudorandom streams by following the gen-
eral idea of a stateful scheme, as pictured in Figure 1b, is
intuitively appealing: such a construction guarantees that
each key is only used in the system for a very limited amount
of rounds – two, actually: in the round where the key is pro-
duced and in the round where it is used. This appears to be
fairly minimal, and suggests that the implementation of this
construction should only guarantee the secrecy of keys that
are involved in the measurements that could be performed
during only two rounds. Such a construction can however
not be proven secure in the model proposed by Dziembowski
and Pietrzak (which we will refer to as the DP model) [9].
Indeed, the DP model states that, in each round, a leak-
age occurs that can be any adversarially chosen polynomial
time function that does not decreases too much the (HILL
pseudo-) entropy of the output (say, the leakage cannot make
the entropy of the key decrease by more than λ bits). There-
fore, the adversary might perform a so-called “future com-
putation attack”, by requiring the leakage at round i to be
the i-th bit of the key that will be used in the (n + 1)-th
round: the full information on that bit is already part of the
state at round i. As a result, even though the leakage func-
tions only provides one single bit of information, the full key
of the (n + 1)-th round is obtained by the adversary at the
end of the n-th round, and the adversary can, from then on,
compute the outputs of all future rounds of this construction
The use of an alternating structure, of the kind depicted
in Figure 2, provides a solution to this problem: if one as-
sumes that each of the boxes depicted leak independently,
no leakage occurring in one box can be used to compute bits
that will be manipulated in future boxes. For instance, fol-
lowing the notations of Fig. 2, leaking about k0 and x0 will
not allow computing bits of k4, because k4 depends on k1
too.
It however appears unrealistic that such a “future compu-
tation attack” has any relation to practice: a circuit will leak
about its current state, but will not leak something related
143k0
x0
k2
k4
x1
x2
x3
k1
k3
x4
k5
Figure 2: A stream cipher based on an alternating structure.
to what it will only compute in a dozen of rounds. Besides,
the use of this alternating structure has several side eﬀects:
1. The key size is doubled (one needs to initialize the gen-
erator with k0 and k1) but, independently of leakages,
the quality of the randomness produced by the gener-
ator corresponds to the use of only one of the keys.
2. It is assumed that the upper and lower parts of the
alternating structure leak independently. Still, while
one side of the structure is active, the state of the
other part must be saved for future use. While it is
probably possible to design circuits in such a way that
this assumption is satisﬁed, this would require special
care, e.g. splitting the circuit into two insulated parts
to avoid coupling eﬀects discussed, e.g. in [2, 35].
The concerns above provide motivation for paying atten-
tion to the simple stateful construction that we discussed
above:
1. Such constructions should provide randomness of qual-
ity directly related to the length of the keys.
2. The requirement about independent leakages can be
strongly mitigated: while one would still need to as-
sume that the diﬀerent rounds leak independently, this
appears to be much more natural since the state of past
rounds can be erased (explicitly, if needed), and future
rounds are not computed nor stored yet.
3. Finally, the insecurity of these constructions in the DP
model appears to be the result of an overly strong se-
curity model (allowing “future computation attacks”)
rather than of realistic physical concerns.
3.2 Model and construction
We consider an experiment PredA,L(n) to deﬁne the secu-
rity of our stateful PRG. It has three parameters: an ad-
versary A, a vector of leakage functions L that contains one
leakage function per PRG round, and a security parameter
n. The goal of the adversary in this experiment is to distin-
guish the output of the stateful PRG at round q + 1 from
a uniformly distributed random value, while given the out-
puts and leakages of the ﬁrst q rounds. We then say that
a stateful PRG is physically unpredictable if the probabil-
ity of success of any PPT adversary in this experiment is
negligible.
Note that, contrary to what is proposed in the DP model
for instance, the leakage functions are a parameter of the ex-
periment: these functions are determined before the experi-
ment starts rather than being determined by the adversary
during the experiment – this is what we call non adaptive
leakages (see discussion in Section 2). In the following deﬁ-
nition, we denote the computation occurring in each box of
Figure 1b by the 2PRG function. More precisely, we have:
Experiment PredA,L(n):
1. A key k0 is selected uniformly at random in the set
{0, 1}n, and a counter i is set to 0.
2. On input 1n, adversary A starts sending request queries.
On each request query, the counter i is incremented,
the pair (ki, xi) is computed as 2PRG(ki−1), and the
leakage Li(ki−1) is returned to A, together with xi.
3. When A outputs a test query, a bit b ∈ {0, 1} and a
value r ∈ {0, 1}n are chosen uniformly at random, and
r is given to A if b = 0 or xi+1 is given otherwise,
computed as (ki+1, xi+1) := 2PRG(ki).
4. A outputs a bit b(cid:48), and PredA,L(n) is set to 1 iﬀ b = b(cid:48).
Definition 1. A stateful PRG is physically unpredictable
for the family of leakage functions L if, for every PPT ad-
versary A, there is a negligible function negl such that:
PredA,L(n) =
1
2
+ negl(n).
Obviously, no PRG can be physically unpredictable if we
do not place any restriction on the leakage functions: these
could simply leak the full key, or be used to perform a “future
computation attack”. Therefore, we introduce two restric-
tions: the ﬁrst one prevents “future computation attacks”,
while the second one ensures that the leakages occurring in
two consecutive rounds do not leak information that would
allow a full recovery of the key involved in these rounds.
Preventing future computation attacks.
In order to prevent leakage functions from providing unre-
alistic information on future computations, we model 2PRG :
ki → (ki+1, xi+1) as a random oracle that cannot be queried
by the leakage function (note however that we do not pre-
vent the adversary from querying the oracle). This ensures
that the leakage functions will be able to leak information
about the round input and output, but not about values that
will be computed in further (or have been computed in past)
rounds, since computing this information would require ora-
cle queries. More precisely, we consider leakage functions of
the following form: Li(ki−1) := (Li
i (ki, xi)).1 The
function Li
i leaks about the input of round i, while the func-
tion Lo
i leaks about the output of that round, none of these
two functions being allowed to query the random oracle.
i(ki−1), Lo
Importantly, the use we make of this random oracle sub-
stantially diﬀers from the “standard” random oracle model.
While we restrict the leakages functions by preventing them
to include random oracle queries, we also make a very mild
use of this oracle in our proof. Namely, we do not use the
programmability of the oracle, which is known to provide
a strictly weaker model that the random oracle model [26].
So, it is not clear how our model compares with the random
oracle model (nor whether the two models are comparable).
Besides, our model appears to have a natural correspon-
dence to attacks on circuits implementing block ciphers (i.e.,
for block cipher based PRGs in our case), where the mea-
sured leakages can be interpreted as a simple function of the
block cipher input and key during the ﬁrst few rounds of the
computation, and/or as a simple function of the block cipher
output and key during the last few rounds of the computa-
tion, but where any useful function of the block cipher input
and output remains elusive (or is the sign of a completely
broken implementation, as shown, e.g. in [31, 32]).
Note that, as the third section of this paper will be devoted
to the security analysis of a construction that can be proven
1ki and xi are computed through an oracle call. Considering
this single call is however important, since it corresponds to
the computation performed in the currently leaking round.
144leakage-resilient in the standard model, one can wonder why
a security analysis using random oracles still makes sense.
As previously mentioned, we believe that this is a useful
methodological contribution because it directly corresponds
to the engineering intuition that a stateful PRG should have
good resistance against side-channel attacks. And although
the constructions in the next section do not suﬀer of the
need of an alternating structure anymore, it remains that the
small performance overheads that they imply are caused by
proof technicalities. In other words, while the constructions
in Section 4 may be perfectly convenient to use in a practical
setting, and bring the security guarantees of a proof in the
standard model, it remains that the modeling of the leak-
age function is imperfect. Namely, we still need to rule out
the “future computation attacks” by design rather than by
a sound restriction of the physical leakage (e.g., taking into
account the fact that they only compute “simple” functions
of a devices’ state). It is also worth mentioning that making
our security analysis rely on random oracles does not simply
lead to trivial results. For example, it allows discriminating
the two PRGs of Fig. 1, which conﬁrms that it captures at
least a part of the intuition about leakage-resilience. Besides,
our random oracle-based approach can be used to analyze
the physical security of a construction that is secure in the
standard model when side-channel attacks are left out of
the analysis. Therefore, we believe that the proof technique
proposed in this section could be applied to other construc-
tions, either as a preliminary step in the analysis of their
leakage resilience, or in the absence of better solutions, e.g.
if implementation eﬃciency is a critical concern.
Eventually, we observe that more standard variants of our
random oracle approach could be considered, that could
probably provide similar results. For instance, one could
model 2PRG as a PRF F with a perfectly secret key k:
in this case, 2PRG(ki−1) could be computed as (ki, xi) :=
(Fk(ki−1), Fk(ki−1⊕1)) and the leakage functions would still
only take ki−1, ki and xi as inputs. The locality of the leak-
ages would then be guaranteed by the fact that k is not part
of the leakage function inputs. We will however use this
random oracle based model for now, for simplicity.
Bounded leakage per iteration.
We require that the leakages given to the adversary pre-
serve the secrecy of the PRG seed in the following sense: the
probability that an adversary recovers the seed used as in-
put or provided as output during two iterations of the PRG
construction should be small. Considering two iterations is
minimal since half of the output of an iteration is the input
of the next iteration, and there are therefore two leakages
taken on each secret variable.
This is formalized through the following deﬁnition.
Definition 2. Let (Lo, Li) be a pair of functions, A2PRG
an algorithm representing the side-channel adversary with
oracle access to 2PRG, n a ﬁxed integer, and PrGuess(n) the
following probability: Pr[A2PRG(Lo(k1, x1), x1, Li(k1)) = k1 :
k0 ← {0, 1}n; (k1, x1) := 2PRG(k0)]. The pair (Lo, Li) is
said to be -seed-preserving for security parameter n and
A2PRG if PrGuess(n) ≤ .
A pair of functions (Lo, Li) is said to be seed-preserving if,
for every PPT A2PRG, there is a negligible function  such
that (Lo, Li) is (n)-seed-preserving for every security param-
eter n and A2PRG running on input 1n.
A sequence of pairs of functions (Lo
1, Li
1), . . . , (Lo
l) is said
l , Li
to be uniformly seed-preserving if, for every PPT A2PRG,
there is a negligible function  such that each pair of this se-
quence is (n)-seed-preserving for every security parameter
n and A2PRG running on input 1n.
Assuming that adversaries only receive outputs of seed-
preserving functions is reminiscent of the assumptions in the