title:Burst ORAM: Minimizing ORAM Response Times for Bursty Access Patterns
author:Jonathan L. Dautrich Jr. and
Emil Stefanov and
Elaine Shi
Burst ORAM: Minimizing ORAM Response Times 
for Bursty Access Patterns
Jonathan Dautrich, University of California, Riverside; Emil Stefanov, University of California, 
Berkeley;  Elaine Shi, University of Maryland, College Park
https://www.usenix.org/conference/usenixsecurity14/technical-sessions/presentation/dautrich
This paper is included in the Proceedings of the 23rd USENIX Security Symposium.August 20–22, 2014 • San Diego, CAISBN 978-1-931971-15-7Open access to the Proceedings of  the 23rd USENIX Security Symposium is sponsored by USENIXBurst ORAM: Minimizing ORAM Response
Times for Bursty Access Patterns
Jonathan Dautrich
University of California, Riverside
Emil Stefanov
University of California, Berkeley
Elaine Shi
University of Maryland, College Park
Abstract
We present Burst ORAM, the ﬁrst oblivious cloud stor-
age system to achieve both practical response times
and low total bandwidth consumption for bursty work-
loads. For real-world workloads, Burst ORAM can at-
tain response times that are nearly optimal and orders
of magnitude lower than the best existing ORAM sys-
tems by reducing online bandwidth costs and aggres-
sively rescheduling shufﬂing work to delay the bulk of
the IO until idle periods.
We evaluate our design on an enterprise ﬁle system
trace with about 7,500 clients over a 15 day period,
comparing to an insecure baseline encrypted block store
without ORAM. We show that when baseline response
times are low, Burst ORAM response times are compa-
rably low. In a 32TB ORAM with 50ms network latency
and sufﬁcient bandwidth capacity to ensure 90% of re-
quests have baseline response times under 53ms, 90% of
Burst ORAM requests have response times under 63ms,
while requiring only 30 times the total bandwidth con-
sumption of the insecure baseline. Similarly, with sufﬁ-
cient bandwidth to ensure 99.9% of requests have base-
line responses under 70ms, 99.9% of Burst ORAM re-
quests have response times under 76ms.
1
Cloud computing allows customers to outsource the bur-
den of data management and beneﬁt from economy of
scale, but privacy concerns hinder its growth [3]. En-
cryption alone is insufﬁcient to ensure privacy in storage
outsourcing applications, as information about the con-
tents of encrypted records may still leak via data access
patterns. Existing work has shown that access patterns
on an encrypted email repository may leak sensitive key-
word search queries [12], and that accesses to encrypted
database tuples may reveal ordering information [5].
Introduction
Oblivious RAM (ORAM), ﬁrst proposed in a ground-
breaking work by Goldreich and Ostrovsky [8, 9], is a
cryptographic protocol that allows a client to provably
hide access patterns from an untrusted storage server.
Recently, the research community has focused on mak-
ing ORAM schemes practical for real-world applica-
tions [7, 11, 21, 23–25, 27]. Unfortunately, even with re-
cent improvements, ORAMs still incur substantial band-
width and response time costs.
Many prior ORAM works focus on minimizing band-
width consumption. Several recent works on cloud-
based ORAMs achieve low bandwidth costs using a large
amount of client-side storage [11, 23, 24]. Others rely on
expensive primitives like PIR [17] or additional assump-
tions such as trusted hardware [15] or non-colluding
servers [22] to reduce bandwidth costs.
To be practical, ORAM must also minimize response
times observed by clients for each request. We propose
Burst ORAM, a novel ORAM that dramatically reduces
response times for realistic workloads with bursty char-
acteristics. Burst ORAM is based on ObliviStore [23],
the most bandwidth-efﬁcient existing ORAM.
Burst ORAM uses novel techniques to minimize the
online work of serving requests and delay ofﬂine block
shufﬂing until idle periods. Under realistic bursty loads,
Burst ORAM achieves orders of magnitude shorter re-
sponse times than existing ORAMs, while retaining total
bandwidth costs less than 50% higher than ObliviStore’s.
During long bursts, Burst ORAM’s behavior automat-
ically and gracefully degrades to be similar to that of
ObliviStore. Thus, even in a worst-case workload, Burst
ORAM’s response times and bandwidth costs are com-
petitive with those of existing ORAMs.
We simulate Burst ORAM on a real-world corporate
data access workload (7,500 clients and 15 days) to show
that it can be used practically in a corporate cloud stor-
age environment. We compare against an insecure base-
line encrypted block store without ORAM and show that
when baseline response times are low, Burst ORAM re-
sponse times are also low. In a 32TB ORAM with 50ms
network latency and sufﬁcient bandwidth capacity to en-
sure 90% of requests have baseline response times un-
USENIX Association  
23rd USENIX Security Symposium  749
der 53ms, 90% of Burst ORAM requests have response
times under 63ms. Similarly, with sufﬁcient bandwidth
to ensure 99.9% of requests have baseline responses un-
der 70ms, 99.9% of Burst ORAM requests have response
times under 76ms. Existing works exhibit response times
on the order of seconds or higher, due to high bandwidth
[11, 23, 25, 28] or computation [17] requirements. To
our knowledge, our work is the ﬁrst to evaluate ORAM
response times on a realistic, bursty workload.
As in previous ORAM schemes, we do not seek to hide
the timing of data requests. Thus, we assume request
start times and durations are known. To ensure security,
we do not allow the IO scheduler to make use of the data
access sequence or other sensitive information. We an-
alyze Burst ORAM security in Section 6.4.
1.1 Burst ORAM Contributions
Burst ORAM introduces several techniques for reducing
response times and keeping bandwidth costs low that dis-
tinguish it from ObliviStore and other predecessors.
Novel scheduling policies. Burst ORAM prioritizes the
online work that must be complete before requests are
satisﬁed. If possible, our scheduler delays shufﬂe work
until off-peak times. Delaying shufﬂe work consumes
client-side storage, so if a burst is sufﬁciently long, client
space will ﬁll, forcing shufﬂing to resume. By this time,
there are typically multiple shufﬂe jobs pending.
We use a greedy strategy to prioritize jobs that free the
most client-side space per unit of shufﬂing bandwidth
consumed. This strategy allows us to sustain lower re-
sponse times for longer during an extended burst.
Reduced online bandwidth costs. We propose a new
XOR technique that reduces the online bandwidth cost
from O(logN) blocks per request in ObliviStore to nearly
1, where N is the outsourced block count. The XOR tech-
nique can also be applied to other ORAM implementa-
tions such as SR-ORAM [26] (see Appendix B).
Level caching. We propose a new technique for us-
ing additional available client space to store small levels
from each partition. By caching these levels on the client,
we are able to reduce total bandwidth cost substantially.
1.2 Related Work
Oblivious RAM was ﬁrst proposed in a seminal work by
Goldreich and Ostrovsky [9]. Since then, a fair amount
of theoretic work has focused on improving its asymp-
totic performance [1, 4, 10, 11, 13, 18, 19, 21, 24, 27].
Recently, there has been much work designing and opti-
mizing ORAM for cloud-based storage outsourcing set-
tings, as noted below. Different ORAMs provide varying
trade-offs between bandwidth cost, client/server storage,
round complexity, and computation.
ORAM has been shown to be feasible for secure (co-)
processor prototypes, which prevent information leakage
due to physical tampering [6, 15, 16, 20]. Since on-chip
trusted cache is expensive, such ORAM schemes need
constant or logarithmic client-side storage, such as the
binary-tree ORAM [21] and its variants [7, 17, 25].
In cloud-based ORAMs, the client typically has more
space, capable of storing O(√N) blocks or a small
amount of per-block metadata [10, 23, 24, 28] that can
be used to reduce ORAM bandwidth costs. Burst ORAM
also makes such client space assumptions.
Online and ofﬂine costs for ORAM were ﬁrst made
explicit by Boneh et al. [1] They propose a construc-
tion that has O(1) online but O(√N) overall bandwidth
cost. The recent Path-PIR work by Mayberry et al. [17]
mixes ORAM and PIR to achieve O(1) online band-
width cost with an overall bandwidth cost of O(log2 N)
with constant client memory. Unfortunately, the PIR is
still computationally expensive, so their scheme requires
more than 40 seconds for a read from a 1TB database
[17]. Burst ORAM has O(1) online and O(logN) overall
bandwidth cost, without the added overhead of PIR.
Other ORAMs that do not rely on trusted hardware or
non-colluding servers have Ω(logN) online bandwidth
cost including works by Williams, Sion, et al. [27, 28];
by Goodrich, Mitzenmacher, Ohrimenko, and Tamassia
[10, 11]; by Kushilevitz et al. [13]; and by Stefonov, Shi,
et al. [21, 23–25]. Burst ORAM handles bursts much
more effectively by reducing the online cost to nearly 1
block transfer per block request during a burst, greatly
reducing response times.
2 Preliminaries
2.1 Bandwidth Costs
Bandwidth consumption is the primary cost in many
modern ORAMs, so it is important to deﬁne how we
measure its different aspects. Each block transferred be-
tween the client and server is a single unit of IO. We as-
sume that blocks are large in practice (at least 1KB), so
transferred meta-data (block IDs) have negligible size.
Deﬁnition 1 The bandwidth cost of a storage scheme is
given by the average number of blocks transferred in or-
der to read or write a single block.
We identify bandwidth costs by appending X to the num-
ber. A bandwidth cost of 2X indicates two blocks trans-
ferred per request, which is twice the cost of an unpro-
tected scheme. We consider online, ofﬂine, effective, and
overall IO and bandwidth costs, where each cost is given
by the average amount of the corresponding type of IO.
Online IO consists of the block transfers needed before
a request can be safely marked as satisﬁed, assuming the
scheme starts with no pending IO. The online bandwidth
cost of a storage scheme without ORAM is just 1X — the
750  23rd USENIX Security Symposium 
USENIX Association
2
Effective IO 
R1 
R2 
R3 
Request R1: 
Request R2: 
Request R3: 
Legend 
Online IO 
Offline IO 
Time 
R1 
Satisfied 
R2 
Satisfied 
R3 
Satisfied 
Figure 1: Simpliﬁed scheme with sequential IO and con-
trived capacity for delaying ofﬂine IO. 3 requests require
same online (2), ofﬂine (5), and overall (7) IO. Online
IO for R1 is handled immediately, so R1’s effective IO is
only 2. R2 waits for 2 units of ofﬂine IO from R1, so its
effective IO is 4. R3 waits for the rest of R1’s ofﬂine IO,
plus one unit of R2’s ofﬂine IO, so its effective IO is 6.
IO cost of downloading the desired block. In ORAM it
may be higher, as additional blocks may be downloaded
to hide the requested block’s identity.
Ofﬂine IO consists of transfers needed to prepare for
subsequent requests, but which may be performed after
the request is satisﬁed. Without ORAM, the ofﬂine band-
width cost is 0X. In ORAM it is generally higher, as addi-
tional shufﬂe IO is needed to obliviously permute blocks
in order to guarantee privacy for future requests.
Overall IO / bandwidth cost is just the sum of the on-
line and ofﬂine IO / bandwidth costs, respectively.
Effective IO consists of all online IO plus any pend-
ing ofﬂine IO from previous requests that must be is-
sued before the next request can be satisﬁed. Without
ORAM, effective IO and online IO are equal.
In tra-
ditional ORAMs, ofﬂine IO is issued immediately after
each request’s online IO, so effective and overall IO are
equal. In Burst ORAM, we delay some ofﬂine IO, reduc-
ing each request’s effective IO as illustrated in Figure 1.
Smaller effective costs mean less IO between requests,
and ultimately shorter response times.
ORAM reads and writes are indistinguishable, so
writes have the same bandwidth costs as reads.
2.2 Response Time
The response time of a block request (ORAM read/write
operation) is deﬁned as the lapse of wall-clock time be-
tween when the request is ﬁrst issued by the client and
when the client receives a response. The minimum re-
sponse time is the time needed to perform all online IO.
Response times increase when ofﬂine IO is needed be-
tween requests, increasing effective IO, or when requests
are issued rapidly in a burst, delaying later requests.
2.3 ObliviStore ORAM
Burst ORAM builds on ObliviStore [23], so we give an
overview of the scheme here. A full description of the
ObliviStore system and its ORAM algorithm spans about
55 pages [23, 24], so we describe it at a high level, fo-
cusing only on components relevant to Burst ORAM.
Partitions and levels. ObliviStore stores N logical data
blocks. Each block is encrypted using a standard sym-
metric key encryption scheme before it is stored on the
server. Every time a block is uploaded by the client, it is
re-encrypted using a new nonce to prevent linking.
ObliviStore securely splits blocks into O(√N) parti-
tions of O(√N) blocks each. Each partition is an ORAM
consisting of O(logN) levels with 2,4,8, . . . ,O(√N)
blocks each. Newly created levels are ﬁlled with half
encrypted real blocks and half encrypted dummies, ran-
domly permuted so that reals and dummies are indistin-
guishable to the server. Each level is occupied only half
the time on average. The client has space to store O(√N)
blocks and the locations of all N blocks.
Requests. When the client makes a block request,
whether a read or write, the block must ﬁrst be down-
loaded from the appropriate partition. To maintain obliv-
iousness, ObliviStore must fetch one block from every
non-empty level in the target partition (O(logN) blocks
of online IO). Only one fetched block is real, and the rest
are dummies, except in the case of early shufﬂe reads de-
scribed below. Once a dummy is fetched, it is discarded,
and new dummies are created later as needed. ObliviS-
tore securely processes multiple requests in parallel, en-
abling full utilization of available bandwidth capacity.
Eviction. Once the real block is fetched, it is updated
or returned to the client as necessary, then ranodmly as-
signed to a new partition p. The block is not immediately
uploaded, but is scheduled for eviction to p and stored in
a client-side data cache. An independent eviction pro-
cess later obliviously evicts the block from the cache to
p. The eviction triggers a write operation on p’s ORAM,
which creates or enlarges a shufﬂing job for p.
Shufﬂing Jobs. Each partition p has at most one pending
shufﬂe job. A job consists of downloading up to O(√N)
blocks from p, permuting them on the client with recent
evictions and new dummies, and uploading. Shufﬂe jobs
incur ofﬂine IO, and vary in size (amount of IO) from
O(1) to O(√N).
Intuitively, to ensure that non-empty
levels have at least one dummy left, we must re-shufﬂe
a level once half its blocks have been removed. Larger
levels need shufﬂing less often, so larger jobs occur less
frequently, keeping ofﬂine bandwidth costs at O(logN).
Shufﬂe IO scheduling. A ﬁxed amount of O(logN)
shufﬂe IO is performed after each request to amortize the
work required for large jobs. The IO for jobs from multi-
USENIX Association  
23rd USENIX Security Symposium  751
3
ple partitions may be executed in parallel: while waiting
on reads for one partition, we may issue reads or writes
for another. Jobs are started in the order they are created.
Early shufﬂe reads. Early shufﬂe reads, referred to as
early cache-ins or real cache-ins in ObliviStore, occur
when a request needs to fetch a block from a level, but at
least half the level’s original blocks have been removed.
In this case, we cannot guarantee that any dummies re-
main. Thus, early shufﬂe reads must be treated as real
blocks and stored separately by the client until they are
returned to the server as part of a shufﬂe job. We call such
reads early shufﬂe reads since the blocks would have
eventually been read during a shufﬂe job. Early shufﬂe
reads are infrequent, but made possible since ObliviStore
performs requests while shufﬂing is in progress.
Level compression. ObliviStore uses a technique called
level compression [24] to compress blocks uploaded dur-
ing shufﬂing. It allows the client to upload k real and k
dummy blocks using only k blocks of bandwidth with-
out revealing which k are dummies. Level compression
reduces only the ofﬂine (shufﬂing) bandwidth cost.
3 Overview of our Approach
Traditional ORAMs focus on reducing average and
worst-case overall bandwidth costs (per-request over-
all IO). However, even the most bandwidth-efﬁcient
schemes [23, 24] suffer from a 20X–35X bandwidth cost.
In this paper, we instead focus on reducing effective
IO by reducing online IO and delaying ofﬂine IO. We
can then satisfy bursts of requests quickly, delaying most
IO until idle periods. Figure 2 illustrates this concept.
Our approach allows many bursts to be satisﬁed with
nearly a 1X effective bandwidth cost. That is, during
the burst, we transfer just over one block for every block
requested. After the burst we do extra IO to catch up on
shufﬂing and prepare for future requests. Our approach
maintains an overall bandwidth cost less than 50% higher
than [23, 24] in practice (see Figure 12 in Section 7).
Bursts. Intuitively, a burst is a period of frequent block
requests from the client preceded and followed by rela-
tively idle periods. Many real-world workloads exhibit
bursty patterns (e.g. [2, 14]). Often, bursts are not dis-
crete events, such as when multiple network ﬁle system
users are operating concurrently. Thus we handle bursts
ﬂuidly: the more requests issued at once, the more Burst
ORAM tries to delay ofﬂine IO until idle periods.
Challenges. We are faced with two key challenges when
building a burst-friendly ORAM system. The ﬁrst is en-
suring that we maintain security. A naive approach to