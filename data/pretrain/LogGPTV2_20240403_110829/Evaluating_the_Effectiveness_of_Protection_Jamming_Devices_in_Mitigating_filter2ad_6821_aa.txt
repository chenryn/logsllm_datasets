title:Evaluating the Effectiveness of Protection Jamming Devices in Mitigating
Smart Speaker Eavesdropping Attacks Using Gaussian White Noise
author:Payton Walker and
Nitesh Saxena
Evaluating the Effectiveness of Protection Jamming Devices in
Mitigating Smart Speaker Eavesdropping Attacks Using
Gaussian White Noise
Payton Walker
Texas A&M University
College Station, Texas, USA
Nitesh Saxena
Texas A&M University
College Station, Texas, USA
PI:EMAIL
PI:EMAIL
ABSTRACT
Protection Jamming Devices (PJD) are specialized tools designed
to sit on top of virtual assistant (VA) smart speakers and hinder
them from “hearing” nearby user speech. PJDs aim to protect you
from eavesdropping attacks by injecting a jamming signal directly
into the microphones of the smart speaker. However, current signal
processing routines can be used to reduce noise and enhance speech
contained in noisy audio samples. Therefore, we identify a potential
vulnerability for speech eavesdropping via smart speaker record-
ings, even when a PJD is being used. If an attacker can gain access to
or facilitate smart speaker recordings they may be able to compro-
mise a user’s speech with successful noise cancellation. Specifically,
we are interested in the potential for Gaussian white noise (GWN)
to be an effective jamming signal for a PJD. To our knowledge, the
effectiveness of white noise and PJDs to protect against eavesdrop-
ping attacks has yet to receive a systematic evaluation that includes
physical experiments with an actual PJD implementation.
In this work we construct our own PJD, specialized for consistent
experimentation, to simulate an attack scenario where recordings
from a smart speaker, in the presence of normal speech and the
PJDs jamming signal, are recovered. We perform substantial data
collection under different settings to build a repository of 1500
recovered audio samples. We applied post-processing on our dataset
and conducted an extensive signal/speech quality analysis including
both time and frequency domain inspection, and evaluation of
metrics including cross-correlation, SNR, and PESQ. Lastly, we
performed feature extraction (MFCC) and built machine learning
classifiers for tasks including speech (digit) recognition, speaker
identification, and gender recognition. We also attempted song
recognition using the Shazam app. For all speech recognition tasks
that we attempted, we were able to achieve classification accuracies
above that of random guessing (46% for digit recognition, 51% for
speaker identification, 80% for gender identification), as well as
demonstrate successful song recognition. These results highlight
the real potential for attackers to compromise user speech, to some
extent, using smart speaker recordings; even if the smart speaker
is protected by a PJD.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior specific permission and/or a
fee. Request permissions from permissions@acm.org.
ACSAC ’21, December 6–10, 2021, Virtual Event, USA
© 2021 Association for Computing Machinery.
ACM ISBN 978-1-4503-8579-4/21/12...$15.00
https://doi.org/10.1145/3485832.3485896
CCS CONCEPTS
• Security and privacy→ Privacy protections; Privacy-preserving
protocols; Hardware-based security protocols;
KEYWORDS
speech masking, jamming, eavesdropping, white noise
ACM Reference Format:
Payton Walker and Nitesh Saxena. 2021. Evaluating the Effectiveness of
Protection Jamming Devices in Mitigating Smart Speaker Eavesdropping At-
tacks Using Gaussian White Noise. In Annual Computer Security Applications
Conference (ACSAC ’21), December 6–10, 2021, Virtual Event, USA. ACM, New
York, NY, USA, 11 pages. https://doi.org/10.1145/3485832.3485896
1 INTRODUCTION
Voice Controllable Systems (VCS), and specifically smart speaker
devices, have gained significant popularity in home and business
environments throughout recent years. Today, at least 35% of the
U.S. population (18+) owns a smart speaker; and that number is
expected to increase to 75% by 2025 [30]. The study, conducted by
NPR and Edison Research, also found the average smart speaker
household had multiple (2.6) devices [7]. These smart speakers
can be fully interfaced via vocal commands which introduces a
new form of accessibility. This allows certain user groups to utilize
functions that otherwise may not be possible for them (i.e., due
to physical disability). Major companies like Amazon and Google
have released different versions of their own standalone VCS smart
speakers, many being relatively inexpensive. Models such as the
Amazon Echo Dot [3] and Google Home Mini [4] are becoming a
common commodity because of their low cost and their ability to
connect other smart devices (i.e., thermostats, locks, etc.).
Due to their amassed popularity, the security and privacy of user
data, particularly their speech, has become a major concern. Many
people believe that these smart speaker devices can be used by mali-
cious attackers, the government, or even the companies selling the
speakers to eavesdrop on their users at any point. These concerns
have led to significant news and media coverage describing the
potential for such attacks [5, 22, 23, 28, 31]. The implications of
smart speaker eavesdropping could be devastating if we consider
the sensitive environments they could be placed in (i.e., home, of-
fice, etc.). In these settings there may be a lot of confidential speech
from the user that should remain private. And at face value, the po-
tential for smart speaker eavesdropping may seem high because of
the “always on” nature of the microphones for detecting the wake
word. Although Google and Amazon report that their devices do
414ACSAC ’21, December 6–10, 2021, Virtual Event, USA
Payton Walker and Nitesh Saxena
not record user conversations [2, 6], many people are not convinced
and believe the threat is real.
In response, recent studies and projects have begun to explore
defensive techniques (namely microphone jamming) to mitigate
these eavesdropping attacks. These works implement microphone
jamming in what is called Protection Jamming Devices (PJD). PJDs
use tiny speakers housed in a mount, and are designed to rest on top
of the user’s smart speaker device. The jamming device will play
some type of noise (i.e., white noise, chatter, ultrasonic) through the
tiny speakers, directly into the microphones of the smart speaker, in
order to block any speech in the surrounding area. These devices are
always on and continue to jam the audio input of a smart speaker
until a wake word unique to the PJD is detected (using its own
inbuilt microphone). When the new wake word is detected the PJD
activates the smart speaker and stops jamming its microphones so
the user’s command can be processed.
In recent years we have seen new attention given to this type
of solution. New PJDs like Project Alias [14] and Paranoid’s Home
Wave [8] are currently on the market and available to the public. Ad-
ditionally, MicShield [41] is an academic paper that presents a PJD
solution using ultrasonic noise for jamming. These products and
research demonstrate a new defense against smart speaker eaves-
dropping. If this approach can be verified as completely effective at
stopping eavesdropping attacks, it could introduce a new sense of
security and protection for current and new smart speaker users.
Further, these devices are not expensive meaning they could easily
be adopted by existing users, or the jamming technology could po-
tentially be integrated in future models of the popular smart speaker
brands. However, this all depends on the PJD’s ability to produce a
jamming signal that can 1) interfere with the microphone’s ability
to detect nearby speech, and 2) does not bother or annoy the user
(e.g., transparent to them). Jamming using ultrasonic noise has the
benefit of being inherently undetectable by the human ear, and
it can mechanically hinder a microphone from recording. But in
the case of audible noise as the jamming signal (white or chatter),
finding an adequate loudness for the noise can be a delicate task.
Chatter noise in particular faces additional challenges because the
noise contains a more dynamic and recognizable combination of
sounds that would be more distracting than a static white noise.
Additionally, ultrasonic jamming does not stop the microphone
from recording, but rather obfuscates the speech that is recorded
beyond the point of recognition. Therefore, the potential for speech
recovery still exists because of signal processing techniques that
could potentially remove the injected jamming noise and reveal the
original speech. While chatter type noise has been successfully im-
plemented in the Project Alias PJD solution, we chose to investigate
white noise in this initial study because of its popularity in other
current speech masking solutions [1, 9, 11]. Further, to our knowl-
edge the effectiveness of white noise injected in the foreground of
audio recordings, for masking speech, has yet to be explored with
physical experiments ([41] only simulated white noise jamming).
In this work we study the efficacy of Protection Jamming Devices
that use audible Gaussian White noise for the jamming signal for
mitigating smart speaker eavesdropping attacks. We build our own
PJD implementation (designed for experimentation) and conduct
experiments that expose a smart speaker (Amazon Echo Dot) to
speech audio and the jamming noise. The recordings were saved
from the Alexa Voice History and processed using off-the-shelf
noise cancellation and speech enhancement routines. We extracted
different features from our samples and built classifiers to attempt
speech, speaker, and gender recognition. This attack model is de-
signed to simulate a less-sophisticated, real-world attacker in order
to observe a baseline for attack success. Also, using off-the-shelf
techniques makes the attack model more practical and accessible
to even low-capability attackers. Our results suggest that speech
contained in smart speaker recordings, during active GWN jam-
ming, can be compromised. Further, we believe attack success can
increase with more sophisticated and skilled attackers.
Contributions: The main contributions made in this work are
summarized below:
(1) We provide an overview of existing PJD implementations
and other related works (Section 2).
(2) We build our own PJD device modeled after existing im-
plementations and conduct experiments to build a dataset
of smart speaker recordings of speech in the presence of a
jamming signal (Section 4).
(3) We performed an extensive signal/speech quality analysis
including time and frequency domain inspection, and using
quality metrics such as cross-correlation, SNR, and PESQ
(Section 6).
(4) Lastly, we used machine learning to attempt speech (digit)
recognition, speaker and gender identification; as well as
attempt song recognition. We achieve classification accura-
cies better than random guessing (46% for digit recognition,
51% for speaker identification, 80% for gender identification);
and demonstrate successful song recognition. Our results
highlight a potential point of vulnerability in PJDs that use
acoustic jamming signals (Section 7).
The significance of this study is that it systematically confirms,
in an academic setting, that standard jamming noises such as white
noise are not effective at protecting user speech from even unso-
phisticated attackers that only use standard off-the-shelf signal
processing techniques. Existing PJDs such as Project Alias [14] and
Home Wave [8] do not use the standard white noise giving them
more success at masking user speech, and at the least they signifi-
cantly decrease the level at which speech can be compromised by
an attacker (increasing the difficulty of the attack). However, we
show that compromising user speech may be successful to some
extent with effective noise cancellation and speech enhancement
routines for processing the noisy audio. Therefore, as signal pro-
cessing techniques continue to improve, PJD devices must continue
to accommodate for an attacker’s increased ability in order to re-
main an effective defensive strategy. This work makes no claims
about the effectiveness of the existing PJD solutions that do not use
Gaussian white noise [8, 14, 41]. They are only used to inform the
design of our own jamming device (hardware and software).
2 BACKGROUND
Protection Jamming Device: Recent projects by researchers and
independent developers have produced a new mechanism to protect
against smart speaker eavesdropping, called Protection Jamming
Devices (PJD). They use tiny speakers housed in a mount, and
are designed to rest on top of the user’s smart speaker device.
415Evaluating the Effectiveness of PJDs in Mitigating Smart Speaker Eavesdropping Attacks Using GWN
ACSAC ’21, December 6–10, 2021, Virtual Event, USA
Figure 1: Depiction of how a PJD functions to mask sensitive user speech; and how a remote attacker could potentially eavesdrop
by removing the injected noise to recover the original speech.
The PJD will play some type of jamming signal, directly into the
smart speaker microphones, in order to block any speech in the
surrounding area. Figure 1 illustrates the basic function of a PJD,
as well as the potential threat faced if an attacker can compromise
the smart speaker’s recordings. These devices are always on and
continue to jam the audio input of a smart speaker until a wake
word unique to the PJD is detected. When it hears the new wake
word, the PJD activates the smart speaker and stops jamming so
the user’s command can be heard and processed.
In the market, we have seen a few PJD products become available
in recent years. Project Alias [14] is a device that was created in
an independent project by Bjorn Karmann, and made open-source
to the public. Home Wave [8] was created by the company Para-
noid Inc. and is available for purchase on their website. Both of
these devices have similar setups using tiny speakers attached to
a housing that rests on top of a smart speaker. The speakers play
an acoustic jamming signal (at a low loudness that remains unde-
tectable to the user). Additionally, both devices are equipped with
their own microphone for detecting a unique wake word. Project
Alias can be trained to respond to any word, and the Home Wave
device recognizes “Paranoid” as the wake word. These new devices
have already been featured many times in news and media (Project
Alias - [24, 36, 38], Home Wave - [12, 16, 20]) demonstrating the
popularity of devices that can offer increased privacy.
Acoustic vs. Ultrasonic Noise: Although jamming with ultra-
sonic noise can be very effective at blocking any snooping devices
from eavesdropping in a specific area, solutions using acoustic jam-
ming noises ([8, 14]) are more cost effective for the average user.
Additionally, research has shown that prolonged exposure to ultra-
sonic noise can have harmful effects on humans including noise
induced hearing loss [39] and loss of concentration [26]. Therefore,
smart speaker jamming devices that utilize ultrasonic noise may not
be viable as a long-term, in-home solution for many users. Because
of this, we feel it is still important to understand the limitations of
jamming solutions that use audible noise.
Additionally, in a more generalized study by Cheng et al. [19],
the authors evaluate the effectiveness of different jamming signals
and the effect of wake word and noise overlap on jamming suc-
cess. Their work demonstrated that Gaussian white noise can be
used for successful jamming under certain conditions (e.g., with a
strong audio signal (10dB SNR)). However, their evaluation used
programmatic signal injection to simulate a speech masking sce-
nario. Additionally, the normal speech and jamming signal were
combined into one signal before being fed to ASR in their exper-
iments. Our work differs because it looks to assess the masking
potential of GWN in a physical PJD implementation. This allows
us to observe the real-world limitations, if any, of injecting noise
into a smart speaker device for blocking nearby speech.
Noise Cancellation: In order to increase speech recognition po-
tential, current smart speakers will instantly process audio input to
try and enhance any contained speech. Specifically, intricate noise
cancellation may be applied to remove any unnecessary sounds
from the audio file, before running it through automatic speech
recognition. For example, when the Echo Dot 2 (used in our study)
receives audio input, it immediately transmits it to the Alexa Voice
Service (AVS) on the internet. Available research from the Amazon
Group reveal that processes such as adaptive linear filtering and
acoustical echo cancellation [47], adaptive beamforming [46], and
spacial localization [42] utilizing the multi-microphone array are
occurring during this time. Uniquely, the noise injection technique
of the PJD can introduce challenges for the existing noise cancel-
lation routines, reflecting their potential for success. The existing
signal processing techniques are not equipped to handle audio input
where the noise source is in the foreground, and the normal speech
is farther away. This is what allows PJD devices to be successful
at hindering the ASR function of a smart speaker. However, if we
consider the potential a human attacker could have with ample
time and access, and improved signal processing techniques, it is
unlikely a foreground injected jamming signal can remain effective.
Related Works: A device that similarly uses speakers at a close
distance to the smart speaker microphones, for jamming signal
injection, is MicShield [41] that was presented in an academic work
by Sub et al. This device differs from the first two in that it uses
Built-inMicrophonePersonal JammingDevice (PJD)“My appointmentis later today at…”Nearby Sensitive Audio(i.e., music, user speech)JammingSignalSpeechCommandAudio Heardby Smart SpeakerNormal speech is masked by the PJD’s signal and becomes unintelligibleRemote Attackeracquired smart speaker recording SignalProcessing416ACSAC ’21, December 6–10, 2021, Virtual Event, USA
Payton Walker and Nitesh Saxena
Figure 2: Diagram depicting an attack model that can be used to target our defined threat model.
ultrasonic sounds for the jamming signal which affects the opera-
tions of the microphone, as opposed to simply masking the recorded
audio in noise. The authors performed some preliminary testing
using white noise and found that a very low SNR (-15dB) can be
effective for the PJD setup. They determined speech at 75 dB could
be jammed with a white noise signal at 90 dB; which is not a viable
loudness for a PJD using an audible jamming noise (because of user
disturbance). Our work further develops this insight to assess the
effectiveness of white noise jamming at loudness levels acceptable
to a user, through a formal academic study.
The use of ultrasonic noise is also seen in other defenses such
as the Patronus system [34]. Patronus generates low-frequency
noise called a “scramble” that exploits the nonlinear effects of smart
speaker microphones to prevent unauthorized recordings and im-
prove the quality of authorized recordings. Another work by Chen
et al. [18] presents a wearable bracelet composed of ultrasonic
speakers that can disable microphones that are near the user wear-
ing it. Rather than targeting a specific VCS device, this bracelet is
intended to disrupt recording from all microphones close to the
user (i.e., smartphones, smartwatches, etc.). We have even seen an
artistic, non-technical defense approach similar to a physical barrier.
May Safwat designed and constructed a bust of the whistleblower
Edward Snowden that contains a hollow copper tube. The bust is
simply meant to sit over a smart speaker (completely covering the