### Unavailability of PMU Functionality on ARM Platforms

Unfortunately, Performance Monitoring Unit (PMU) functionalities are not available on ARM platforms. As a result, detecting Rowhammer events is extremely challenging and, if possible at all, very costly. Given the severity of this vulnerability and the fact that we were able to trigger bit flips in the browser on all three tested phones, there is an urgent need for software-based defenses against GPU-accelerated attacks.

### Mitigating Rowhammer Attacks

As discussed in Section VIII, to exploit Rowhammer bit flips, an attacker must ensure that the victim rows are reused to store sensitive data (e.g., pointers). To prevent this, we can enforce stricter policies for memory reuse. One potential solution is to enhance the physical compartmentalization initiated by CATT [8] for user-space applications. For example, a page tagging mechanism could be implemented to prevent the reuse of pages tagged by an active WebGL context. By isolating these pages using guard rows [8], we can protect the rest of the browser from potential bit flips caused by these contexts.

### Trade-offs and Future Work

Implementing such a solution involves trade-offs in terms of complexity, performance, and capacity. A basic version with statically-sized partitions for WebGL contexts is straightforward but inflexible, as it may waste memory for contexts that do not use all the allocated pages. Dynamically allocating isolated pages increases complexity and has performance implications. We plan to explore these trade-offs in our future work.

### Related Work

#### Integrated Accelerators Threats

Olson et al. [37] provide a taxonomy of potential integrated accelerator threats, classified based on confidentiality, integrity, and availability. They discuss how side-channel and fault attacks can compromise system security. To the best of our knowledge, the attacks presented in this paper are the first to leverage timing information and Rowhammer from integrated GPUs to compromise a mobile phone. While some follow-up work has focused on shielding invalid memory accesses from accelerators [36], further research is necessary to protect against microarchitectural attacks.

#### Side-Channel Attacks

Side-channel attacks have been extensively studied when executed natively from the CPU [6], [18], [30], [35], [39], [40], [52]. In recent years, researchers have demonstrated remote attacks from malicious JavaScript-enabled websites [18], [38]. However, these instances are primarily CPU-based attacks.

Recent work has shown the possibility of executing microarchitectural attacks from the GPU, but they target niche settings with limited practical impact. Jiang et al. [24], [25] present attacks breaking AES on GPGPUs, assuming both the attacker and the victim are executing on a shared GPU. Naghibijouybari et al. [34] demonstrate the possibility of building covert channels between two cooperating processes running on the GPU. These attacks focus on general-purpose discrete GPUs, typically found in cloud systems, whereas our work targets integrated GPUs on commodity hardware.

#### Rowhammer

Since Kim et al. [27] initially studied Rowhammer, various implementations and exploitation techniques have been proposed. Seaborn and Dullien [45] first exploited this hardware vulnerability to gain kernel privileges by triggering bit flips on page table entries. Drammer uses a similar technique to root ARM Android devices [48]. These implementations rely on accessing memory by bypassing caches, either using the CLFLUSH instruction on x86_64 or by exploiting DMA memory [48]. Our technique does not require these methods.

Dedup Est Machina [7] and Rowhammer.js [20] show how Rowhammer can be exploited to escape the JavaScript sandbox. These attacks rely on evicting CPU caches to reach DRAM. On ARM architecture, eviction-based Rowhammer is too slow to trigger bit flips, even natively, due to large general-purpose CPU caches. We demonstrated for the first time that GPU acceleration allows us to trigger bit flips by evicting GPU caches, enabling bit flips from JavaScript on mobile devices.

### Conclusions

We have shown that advanced microarchitectural attacks can be performed directly from integrated GPUs found in almost all mobile devices. These attacks are powerful, allowing the circumvention of state-of-the-art defenses and advancing existing CPU-based attacks. More alarmingly, these attacks can be launched from the browser. For example, we demonstrated for the first time that an attacker can fully compromise a browser running on a mobile phone in less than 2 minutes using microarchitectural attacks from the GPU. While we have plans for mitigations, we hope our efforts will make processor vendors more cautious when embedding specialized units into commodity processors.

### Disclosure

We are coordinating with the Dutch Cyber Security Centrum (NCSC) to address some of the issues raised in this paper.

### Acknowledgements

We would like to thank our shepherd Simha Sethumadhavan and our anonymous reviewers for their valuable feedback. Additionally, we want to thank Rob Clark for his insights throughout the research. This work was supported by the European Commission through project H2020 ICT-32-2014 SHARCS under Grant Agreement No. 644571 and by the Netherlands Organisation for Scientific Research through grant NWO 639.023.309 VICI Dowsing.

### References

[1] “Actions required to mitigate Speculative Side-Channel Attack techniques,” https://www.chromium.org/Home/chromium-security/ssca, Accessed on 20.01.2018.
[33] I. Malchev, “KGSL page allocation,” https://android.googlesource.com/kernel/msm.git/+/android-msm-hammerhead-3.4-marshmallow-mr3/drivers/gpu/msm/kgsl_sharedmem.c#621, Accessed on 30.12.2017.
[34] H. Naghibijouybari, K. Khasawneh, and N. Abu-Ghazaleh, “Constructing and Characterizing Covert Channels on GPGPUs,” in MICRO-50.
[2] “Value.h,” https://dxr.mozilla.org/mozilla-central/source/js/public/Value.h, Accessed on 30.12.2017.
[35] M. Oliverio, K. Razavi, H. Bos, and C. Giuffrida, “Secure Page Fusion with VUsion,” in SOSP’17.
[3] “WebGL current support,” http://caniuse.com/#feat=webgl, Accessed on 30.12.2017.
[36] L. E. Olson, J. Power, M. D. Hill, and D. A. Wood, “Border Control: Sandboxing accelerators,” in MICRO-48.
[37] L. E. Olson, S. Sethumadhavan, and M. D. Hill, “Security implications of third-party accelerators,” in IEEE Computer Architecture Letters 2016.
[38] Y. Oren, V. P. Kemerlis, S. Sethumadhavan, and A. D. Keromytis, “The Spy in the Sandbox: Practical Cache Attacks in JavaScript and their implications,” in CCS’15.
[39] D. A. Osvik, A. Shamir, and E. Tromer, “Cache attacks and countermeasures: the case of AES,” in RSA’06.
[40] P. Pessl, D. Gruss, C. Maurice, M. Schwarz, and S. Mangard, “DRAMA: Exploiting DRAM Addressing for Cross-CPU Attacks.” in SEC’16.
[41] F. Pizlo, “What Spectre and Meltdown Mean For WebKit,” https://webkit.org/blog/8048/what-spectre-and-meltdown-mean-for-webkit/, Accessed on 20.01.2018.
[42] K. Razavi, B. Gras, E. Bosman, B. Preneel, C. Giuffrida, and H. Bos, “Flip Feng Shui: Hammering a Needle in the Software Stack,” in SEC’16.
[43] K. Sato, C. Young, and D. Patterson, “Google Tensor Processing Unit (TPU),” https://cloud.google.com/blog/big-data/2017/05/an-in-depth-look-at-googles-first-tensor-processing-unit-tpu, Accessed on 30.12.2017.
[44] M. Schwarz, M. Lipp, and D. Gruss, “JavaScript Zero: Real JavaScript and Zero Side-Channel Attacks,” in NDSS’18.
[45] M. Seaborn and T. Dullien, “Exploiting the DRAM rowhammer bug to gain kernel privileges,” in Black Hat 2015.
[46] V. Shimanskiy, “EXT disjoint timer query,” https://www.khronos.org/registry/OpenGL/extensions/EXT/EXT_disjoint_timer_query.txt, Accessed on 30.12.2017.
[47] M. E. Team, “Mitigating speculative execution attacks in Microsoft Edge and Internet Explorer,” https://blogs.windows.com/msedgedev/2018/01/03/speculative-execution-mitigations-microsoft-edge-internet-explorer/#b8Y70MtqGTVR7mSC.97, Accessed on 20.01.2018.
[48] V. van der Veen, Y. Fratantonio, M. Lindorfer, D. Gruss, C. Maurice, G. Vigna, H. Bos, K. Razavi, and C. Giuffrida, “Drammer: Deterministic Rowhammer Attacks on Mobile Platforms,” in CCS’16.
[49] G. Venkatesh, J. Sampson, N. Goulding, S. Garcia, V. Bryksin, J. Lugo-Martinez, S. Swanson, and M. B. Taylor, “Conservation Cores: Reducing the Energy of Mature Computations,” in ASPLOS’10.
[50] L. Wagner, “Mitigations landing for a new class of timing attack,” https://blog.mozilla.org/security/2018/01/03/mitigations-landing-new-class-timing-attack/, Accessed on 20.01.2018.
[51] Y. Xiao, X. Zhang, Y. Zhang, and R. Teodorescu, “One bit flips, one cloud flops: Cross-VM row hammer attacks and privilege escalation.” in SEC’16.
[52] Y. Yarom and K. Falkner, “FLUSH+ RELOAD: A High Resolution, Low Noise, L3 Cache Side-Channel Attack,” in SEC’14.
[53] B. Zbarsky, “Clamp the resolution of performance.now() calls to 5us,” https://hg.mozilla.org/integration/mozilla-inbound/rev/48ae8b5e62ab, Accessed on 30.12.2017.

### Appendix A: Snapdragon 800/801 DRAM Mapping

In Section VII-C, we explained that contiguity differs from adjacency. However, we also stated that we could assume the congruency between these two attributes for the Snapdragon 800/801 SoCs. Here, we show how we can relax that assumption.

As explained in Section VII-A, DRAM is organized into channels, DIMMs, ranks, banks, rows, and columns. The CPU/GPU only access DRAM using virtual addresses. After translating a virtual address to its physical address, the memory controller converts the physical address to a DRAM address consisting of the elements mentioned above. This mapping of physical addresses to DRAM addresses is undocumented but has been reverse-engineered for many architectures, including Snapdragon 800/801 [40], as shown in Table V.

Snapdragon 800/801 does not employ multiple channels or DIMMs, so no bits in the physical addresses are assigned to their selection. Within the DIMM, there are two ranks and eight banks within each rank. Bit ten of a physical address is responsible for choosing the ranks, while bits [13-15] are responsible for choosing the banks. As shown in Figure 8, this configuration translates to 1 KB aligned areas of the physical address space shuffled over the two different ranks (2^10 = 1 KB) and a change of bank every 8 KB (2^13 = 8 KB). Since the division among the ranks happens at a smaller granularity than a page, each row (within a bank) is 4 KB large and stores 2 half-pages, as shown in Figure 8.

Given the assumption made in Section VII-C, it should now be clear why we can simplify our model to consider two pages per row. Since we are only interested in touching memory at the page level, due to the stride imposed by the UCHE cache (i.e., 4 KB), we can build our model without considering the ranks, thus treating rows as 8 KB.