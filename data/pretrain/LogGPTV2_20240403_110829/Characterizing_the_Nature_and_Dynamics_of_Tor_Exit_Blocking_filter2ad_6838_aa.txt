title:Characterizing the Nature and Dynamics of Tor Exit Blocking
author:Rachee Singh and
Rishab Nithyanand and
Sadia Afroz and
Paul Pearce and
Michael Carl Tschantz and
Phillipa Gill and
Vern Paxson
Characterizing the Nature and Dynamics  
of Tor Exit Blocking
Rachee Singh, University of Massachusetts – Amherst; Rishab Nithyanand, Stony Brook 
University; Sadia Afroz, University of California, Berkeley and International Computer Science 
Institute; Paul Pearce, UC Berkeley; Michael Carl Tschantz, International Computer Science 
Institute; Phillipa Gill, University of Massachusetts – Amherst; Vern Paxson, University of 
California, Berkeley and International Computer Science Institute
https://www.usenix.org/conference/usenixsecurity17/technical-sessions/presentation/singh
This paper is included in the Proceedings of the 
26th USENIX Security Symposium
August 16–18, 2017 • Vancouver, BC, Canada
ISBN 978-1-931971-40-9
Open access to the Proceedings of the 26th USENIX Security Symposium is sponsored by USENIXCharacterizing the Nature and Dynamics of Tor Exit Blocking
Rachee Singh1, Rishab Nithyanand2, Sadia Afroz3,4
Paul Pearce3, Michael Carl Tschantz4, Phillipa Gill1, Vern Paxson3,4
1University of Massachusetts – Amherst, 2Stony Brook University,
3University of California – Berkeley, 4International Computer Science Institute
Abstract
Facing abusive trafﬁc from the Tor anonymity network,
online service providers discriminate against Tor users.
In this study, we characterize not only the extent of such
discrimination but also the nature of the undesired traf-
ﬁc originating from the Tor network—a task compli-
cated by Tor’s need to maintain user anonymity. We
address this challenge by leveraging multiple indepen-
dent data sources: email complaints sent to exit opera-
tors, commercial IP blacklists, webpage crawls via Tor,
and privacy-sensitive measurements of our own Tor exit
nodes. As part of our study, we also develop methods for
classifying email complaints and an interactive crawler
to ﬁnd subtle forms of discrimination, and deploy our
own exits in various conﬁgurations to understand which
are prone to discrimination. We ﬁnd that conservative
exit policies are ineffective in preventing the blacklisting
of exit relays. However, a majority of the attacks origi-
nating from Tor generate high trafﬁc volume, suggesting
the possibility of detection and prevention without vio-
lating Tor users’ privacy.
1
Introduction
Anonymity systems like Tor provide a useful service to
users who wish to access the Internet without reveal-
ing their intended destination to any local monitoring,
or their network-layer identity to the ﬁnal destination.
However, as Tor has increased in scale and usage, ten-
sions have emerged between Tor users and online service
providers. Speciﬁcally, service providers claim that the
anonymity provided by Tor is often used maliciously for
spamming, vulnerability scanning, scraping, and other
undesired behavior (e.g., [1]). As a result, Tor users
now face differential treatment (e.g., needing to solve
CAPTCHAs before receiving services) and even outright
blocking [2].
At its core, the problem is that in return for anonymity,
each Tor user shares their reputation with other users.
As a result, the malicious actions of a single Tor user
can lead IP abuse blacklists to include IP addresses used
by Tor exit relays. Consequently, websites and content
providers treat even benign Tor users as malicious.
In
this paper, we characterize aspects of the conﬂict be-
tween users desiring anonymity and websites aiming to
protect themselves against malicious Tor trafﬁc. We in-
vestigate the nature of trafﬁc that exits the Tor network
and is undesired by online service providers. We also
actively measure various forms of discrimination per-
formed against Tor users.
Challenges. We grapple with two key challenges: First,
measuring Tor trafﬁc is antithetical to the goals of the
anonymity system and poses ethical challenges. Second,
deﬁning and identifying undesired or abusive network
trafﬁc is hard as opinions vary and encryption can render
inspection of trafﬁc infeasible. We address both chal-
lenges by focusing on the receivers’ reactions to Tor traf-
ﬁc rather than the trafﬁc itself. We consider email com-
plaints sent to Tor relay operators (§4) and blacklisting
of Tor-related IP addresses (§5), and take measurements
of server responses to Tor trafﬁc, both synthetic (§6) and
user-driven (§7). These datasets not only allow us to ob-
serve the effects of undesired trafﬁc without measuring
it, but also provide an operational deﬁnition of undesired
trafﬁc: the trafﬁc that leads to complaints, blacklisting,
or rejecting of Tor users. This operationalization allows
us to sidestep debates over what constitutes abuse and
to focus on the subset of undesired Tor trafﬁc that has
affected operators and users.
Additionally, collecting and analyzing each of these
four datasets presented technical challenges. Analyzing
3 million email complaints received by Tor relay opera-
tors since June 2010 required us to construct automated
processing methods (§4). Understanding the inclusion
of Tor-related IP addresses in IP blacklists required us to
develop methods for teasing apart reactive blacklisting—
i.e., blacklisting triggered by abuse—from proactive
blacklisting—i.e., blacklisting due to Tor’s pre-existing
USENIX Association
26th USENIX Security Symposium    325
reputation (§5). Measuring the prevalence of discrimina-
tion faced by users required exercising multiple aspects
of websites and inspecting them for subtle forms of dis-
crimination (e.g., CAPTCHAs and interaction-based dis-
crimination) in addition to outright blocking. To address
this issue and accurately measure discrimination against
users, we go beyond the prior work of Khattak et al.
and develop a crawler capable of exercising the search
and login features of websites. Taking measurements of
real Tor trafﬁc required the creation and deployment of a
privacy-sensitive logging approach for our own Tor exit
relays. We also consider aspects of Tor exit relays that
make them more susceptible to complaints, IP blacklist-
ing, or blocking. We augment this analysis by deploying
several Tor exits with varied conﬁgurations and monitor-
ing the reactions they produced.
Key Findings. One major takeaway from our analysis
is that many of the attacks originating from Tor generate
high trafﬁc volume (e.g., DDoS attacks, port scanning),
raising the possibility of blocking them using privacy-
sensitive techniques (§8). We believe developing, im-
plementing, and deploying such techniques may provide
online service operators a more effective means of curb-
ing abuse than IP blacklisting while also preventing lost
utility to Tor from blocking.
Our analysis of email complaints shows that, histori-
cally, the most vocal complainants about Tor trafﬁc were
a small number of copyright enforcement ﬁrms. This is
no longer be the case, possibly due to Tor blocking Bit-
Torrent’s standard ports by default (Table 2 in §4). The
most common non-copyright complaints were about net-
work abuse and attempts to gain unauthorized access (Ta-
ble 3 in §4).
From our analysis of commercial IP blacklists, we ﬁnd
that 7% of the commercial IP blacklists we analyze en-
gage in proactive blocking of Tor users—i.e., blacklist-
ing Tor exit relays soon after they are listed in the con-
sensus. This is indicative of blacklists performing dis-
crimination against Tor exit relays as a matter of policy,
rather than based on undesired trafﬁc (§5). Currently,
88% of Tor relays are blacklisted on one or more of the
blacklists, compared to 9% and 69% of the endpoints of
the VPNGate and HMA VPN services, respectively (Fig-
ure 4 in §5). We also ﬁnd that conservative exit policies
do not reduce Tor exit relays’ susceptibility to getting
blacklisted, which appears to reﬂect that such policies
still allow for Web access, the channel most extensively
used for abuse.
Finally, we ﬁnd discrimination to be a pressing con-
cern. Our synthetic experiments show that discrimina-
tion occurs on 20% of all Alexa Top 500 website front-
page loads through a subset of Tor exits. Focusing on
the search and login functionalities of the Alexa Top 500
websites, we see a 3.9% and 7.5% increase in observed
discrimination (compared to front-page load discrimina-
tion), respectively (Table 6 in §6). We also ﬁnd that
real Tor users experience high fractions of failed HTTP
requests (15.8–33.4%) and HTTPS handshakes (35.0–
49.6%) while browsing the Alexa Top 1M websites using
our deployed relays (Table 8 in §7).
2 Background and Related Work
Tensions between Tor and online services. Tor is a
low-latency onion routing network with over 2M daily
users and over 7K supporting servers [3]. While propo-
nents of Internet freedom laud the anonymity provided
by Tor, it can also provide a cloak for malicious net-
work activities. Indeed, CloudFlare reported that 94% of
the requests from the Tor network are “malicious”, con-
sisting of comment spam, scanning, and content scrap-
ing [1]. According to a report published by Distill net-
works, 48% of Tor requests are malicious, higher than
non-Tor requests (38%) [4]. A study of the Sqreen appli-
cation protection service found that connections through
Tor are responsible for ≈30% of all attacks on their cus-
tomers, including password brute force attacks, account
enumerations, and fraudsters [5]. As per Akamai’s State
of the Internet report, an HTTP request from a Tor IP ad-
dress is 30 times more likely to be a malicious attack than
one from a non-Tor IP address [6]. Imperva-Incapsula
found that in a period of 2.5 weeks, 48.53% of the attack
requests came from Tor [7]. However, the majority of
these attack sessions were originated from well-known
DDoS bots and bad clients, which can be identiﬁed us-
ing approaches other than IP reputation. Not counting
the attacks from well-known attackers, the fraction of at-
tack sessions originating from Tor went down to 6.78%,
which is comparable to the attacks coming from the rest
of the Internet population in Ireland (5.45%).
Different services have reported similar types of at-
tacks from Tor. The three most common attacks from
Tor to Akamai’s services were automated scanning (path
scanning and vulnerability scanning), SQL injection, and
cross-site scripting attacks [6].
IBM reports that SQL
injection, automated scanning, and DDoS are the most
common attacks from Tor [8]. Sqreen found authen-
tication attacks (brute force attack on a speciﬁc user
account, or accounts enumeration), path scanning, and
SQL/NoSQL injections [9] are likely to originate from
Tor [5]. Our analysis of the abuse complaints to a num-
ber of Tor exit relays reﬂects similar proportions of attack
trafﬁc (Section 4).
Despite reports claiming a higher likelihood of ma-
licious trafﬁc from Tor, there have been debates about
the correctness of their inference methods.
For in-
stance, Perry, writing for the Tor Project’s blog, ques-
326    26th USENIX Security Symposium
USENIX Association
tions whether CloudFlare’s methods considered as ma-
licious all trafﬁc from an exit relay that ever sent any
malicious trafﬁc [10].
While websites might be tempted to blacklist all Tor
IPs in a proactive attempt at security, doing so could
cause a loss in revenue. Akamai’s report highlights that
Tor users are just as likely to make purchases from rev-
enue generating websites as non-Tor users [6].
Blocking and Filtering of Tor. Many government cen-
sors around the world block access to Tor [11], the sub-
ject of numerous measurement studies [12–16]. How-
ever, such government censorship blocks access to the
Tor entry nodes, which is different from server-side Tor
blocking, which blocks access from the Tor exit nodes.
Khattak et al. is the only systematic measurement
study of server-side Tor blocking [2]. They showed that
in 2015 at least 1.3 million IP addresses blocked Tor at
the TCP/IP layer, and 3.6% of the Alexa Top 1,000 web-
sites blocked Tor at the HTTP layer. At the TCP/IP layer,
the hosting services GoDaddy and Dreamhost are among
the top ﬁve Tor blockers. CloudFlare blocks access at the
HTTP layer. Our work extends the work of Khattak et
al. by additionally measuring the blocking of login and
search functionality. We ﬁnd a higher rate of blocking
(20.03%) than Khattak et al. (3.6%). We demonstrate
that Khattak et al.’s headless crawler underestimates the
blocking rate (Figure 12).
To understand the impact of blocking on Tor users, we
measure the number of failed requests to Alexa Top 1M
web pages at the exit level using privacy-sensitive log-
ging on our exits.
3 Our Deployed Exits
To aid our studies of complaint emails, IP blacklisting,
and discrimination, we deployed and used data from ten
of our own exits in addition to current and historical
records about pre-existing Tor exits.
Large-Default
Medium-Default
Medium-RR
Small-Default
Small-RR
Max. BW Exit Policy Num.
61 MBps∗ Default
10 MBps
Default
RR
10 MBps
Default
2 MBps
2 MBps
RR
2
2
2
2
2
Table 1: Conﬁgurations of our deployed exit relays.
∗The large exits’ policy allows for unlimited bandwidth
usage. We provide the maximum bandwidth achieved
during the study period.
We vary the bandwidth and exit policy of our exits
in order to understand the impact of relay characteris-
tics on email complaints, blacklisting, and discrimina-
tion. We used bandwidth allocations for the relays of 2
MBps (small exits), 10 MBps (medium exits), and un-
limited (huge exits). In total, our deployed relays han-
dled over 3% of all Tor exit trafﬁc during their deploy-
ment. The exit policies were varied to either be the Tor
default policy or the “Reduced-Reduced” policy. The de-
fault policy [17] allows all ports except those misused for
email and news spam (25, 119), network attacks (135–
139, 445, 563), or peer-to-peer ﬁle sharing (1214, 4661–
4666, 6346–6348, 6699, 6881–6999, plus the adjacent
ports 6349–6429). The Reduced-Reduced (RR) exit pol-
icy, designed to avoid blacklisting, additionally blocks
ports associated with SSH, Telnet, IRC(S), and other pro-
tocols [18]. We summarize our relay conﬁgurations in
Table 1.
Analyzing the usage statistics of ports on our exit
relays, we see that web-trafﬁc accounts for 98.88%
of all connections made through the RR policy exits.
In contrast, trafﬁc though the default policy exits has
higher application/port diversity, with only 31.36% of
observed trafﬁc being HTTP(S). We measure this using
our privacy-sensitive logging described in Section 7.
4 Email Complaints about Abuse
In this section, we look at the abuse complaints received
by exit operators. We use these complaints as a proxy
for understanding the type and frequency of undesired
incidents happening through Tor exit relays.
4.1 The Email Corpus
In addition to our own exits, we obtained access to
abuse complaints emailed to four exit relay operators,
(Table 2).
The largest email corpus, consisting of
≈3M emails, came from a subset of exits operated by
Torservers.net (https://torservers.net/). Using
whois queries on exit IP addresses and counting the num-
ber of exits that use Torservers.net as their abuse contact,
we estimate that they run 10 to 20 exits, with the uncer-
tainty coming from fuzzy matches.1 According to the
latest Tor consensus, Torservers is one of the largest exit
operators in terms of overall bandwidth capacity. The
apx exit family includes three exits: apx1 [19], apx2 [20]
and apx3 [21]. The other two exits are TorLand1 [22]
and jahjah [23]. TorLand1 was one of the oldest Tor ex-
its, running since 2011 until February 2017.
Our complaints dataset lacks any complaints sent by
fax or mail, or those sent to only the abuse contact of the
associated autonomous system. Also, some email com-
plaints might have been lost or deleted. For example, the
1The current operators of Torservers were unable to answer the ex-
act number of exits they ran over time.
USENIX Association