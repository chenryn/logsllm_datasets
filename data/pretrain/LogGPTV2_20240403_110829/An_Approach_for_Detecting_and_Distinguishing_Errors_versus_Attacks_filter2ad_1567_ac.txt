d
m
u
H
i
100
90
80
70
60
50
40
30
20
10
0
9
9.2
9.4
9.6
Time [day]
9.8
10
Figure 6. Humidity and temperature variation
for July 9th.
Parameter
K
M
w
α
β
γ
Description
Number of sensors
Number of initial model states
Observation window size
Learning factor used to estimate model states
Learning factor used to estimate state transi-
tion probability A
Learning factor used to estimate observation
symbol probability B
Value
10
6
12
0.10
0.90
0.90
Table 1. Parameters used in the experimental
setup.
4.1 Fault Classiﬁcation
This section analyzes the GDI data for the whole month
of July 2003. Figure 6 shows the variation of temperature
and humidity respectively for one complete day, July 9th. We
can clearly observe that the temperature and humidity change
continuously during the day. A similar trend is observed for
the whole month.
Table 1 lists the experimental setup used in determining
the Markov Models using the procedure discussed in § 3.1.
The Model State Identiﬁcation module requires an initial es-
timate for the set of model states. This initial estimate can
be completely random or based on historical data. The re-
sults discussed in the paper are based on an initial set estimate
of 6 states that is determined by running an off-line cluster-
ing algorithm on the entire data.5 As mentioned earlier, the
observation window size is also an important input to the sys-
tem. Since the sensors in our setup sample data every 5 min-
utes, we use a window size of 12 samples, which enables us to
capture variations in the environment attributes with sufﬁcient
time accuracy (one hour accuracy) and statistical signiﬁcance
(about a hundred sensor readings in average, as not all sensor
data can be used due to missed or corrupted packets).
Figure 7 depicts the correct Markov Model MC of the en-
vironment, as estimated by the procedure delineated in § 3
(see Fig. 1). Four main states of the system can be identiﬁed,
namely (12,94), (17,84), (24,70) and (31,56), where each state
is represented by a (temperature value, humidity value) tuple.
An additional state (16,27) results from ﬂuctuations within the
5The proposed methodology worked equally well when a set of random
initial states was provided to the Model State Identiﬁcation module.
Proceedings of the 2006 International Conference on Dependable Systems and Networks (DSN’06) 
0-7695-2607-1/06 $20.00 © 2006 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 12:29:25 UTC from IEEE Xplore.  Restrictions apply. 
Figure 7. Correct Markov Model MC of the en-
vironment.
i
]
s
u
s
e
c
[
l
e
r
u
t
a
r
e
p
m
e
T
50
40
30
20
10
0
]
%
[
y
t
i
i
d
m
u
H
100
80
60
40
20
0
Sensor 6
Sensor 7
Sensor 9
(a) MCO.
5
10
15
Time [day]
20
25
30
Sensor 6
Sensor 7
Sensor 9
5
10
15
Time [day]
20
25
30
(b) MCE.
Figure 8. Humidity and temperature variation in
a week for sensors 6, 7, and 9.
readings. The transition to this state has a very low probabil-
ity, and hence, this state is not further considered as one of the
key states of the system.
By applying the proposed methodology to the GDI data,
we discover two sensor nodes to be consistently faulty,
namely sensor 6 and sensor 7. Figure 8 depicts the humidity
values reported by the two sensors as compared with a non-
faulty sensor 9. As seen in the ﬁgure, sensor 6 starts reporting
a continuously decreasing value of the humidity that eventu-
ally leads in an almost-zero value, whereas sensor 7 reports,
on average, a value about 10% higher than the correct sensors.
Figure 9 depicts the two Hidden Markov Models MCO
and MCE learned for sensor 6. Table 2 and Table 3 re-
port the corresponding state transition probability matrix (A)
and observation symbol probability matrix (BCO and BCE).
The additional state (⊥) introduced in BCE (see Table 3)
models the scenario when the faulty sensor does not produce
faulty data. This ﬁctitious state is not taken into account dur-
ing classiﬁcation. Based on the relations described in § 3.4,
we observe that the rows and the columns of BCO are ap-
(cid:3)
jk  0.8 for i = j). Also, Table 3 shows that matrix
k bco
BCE has all columns approximately null apart from a single
ikbco
(cid:3)
k bco
ikbco
Figure 9. HMMs for faulty sensor 6 (stuck-at-
value fault).
column (corresponding to state (15,1)) of approximately all
ones. This leads to (correctly) classifying sensor 6 to be in a
stuck-at state (15,1).
i ↓, j → (12,94)
(12,94)
(31,56)
(16,27)
(24,70)
(17,84)
1
0
0
0
0
(31,56)
(16,27)
(24,70)
(17,84)
0
1
0
0.11
0
0
0
1
0
0
0
0
0
0.89
0.17
0
0
0
0
0.83
Table 2. BCO matrix for faulty sensor 6 (stuck-
at-value fault).
i ↓, j → (16,27)
(12,94)
(31,56)
(16,27)
(24,70)
(17,84)
0.33
0.01
0
0
0
(15,1)
1
1
0.9
0.67
0.99
⊥
0
0
0.1
0
0
Table 3. BCE matrix for faulty sensor 6 (stuck-
at-value fault).
A similar analysis can be conducted for sensor 7, where
Table 4 and Table 5 show the resulting observation symbol
probability matrices, BCO and BCE. Both matrices are ap-
Proceedings of the 2006 International Conference on Dependable Systems and Networks (DSN’06) 
0-7695-2607-1/06 $20.00 © 2006 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 12:29:25 UTC from IEEE Xplore.  Restrictions apply. 
0.98
i ↓, j → (22,80)
(22,80)
(17,88)
(13,96)
(27,68)
(32,56)
0.001
0
0
0
(17,88)
(13,96)
(27,68)
(32,56)
0.02
0.8
0
0
0
0
0.2
1
0
0
0
0
0
0.999
0.001
0
0
0
0
0.999
Table 4. BCO matrix for faulty sensor 7 (calibra-
tion fault).
i ↓ j → (22,80)
(22,80)
(17,88)
(13,96)
(27,68)
(32,56)
0.87
0
0
0
0
(17,88)
(13,96)
(27,68)
(32,56)
0.86
0
0
0
0
0
0.85
0
0
0
0
0
0
0
0.46
0
0
0
0
0
⊥
0.14
0.15
1
0.13
0.54
Table 5. BCE matrix for faulty sensor 7 (calibra-
tion fault).
i /xe
i and the differences xc
proximately orthogonal. Furthermore, when computing the
ratios xc
i between the attributes
of corresponding model states,6 we obtain ratios with average
(1.24, 1.16) and low variance (0.006,0.007), and differences
with average (5,10) and high variance (0,8). This leads us to
(correctly) classify sensor 7 as affected by a calibration fault.
i −xe
4.2 Attack Classiﬁcation
To evaluate the proposed methodology under attack sce-
narios, we injected malicious behavior into the system (the
original data did not contain malicious attacks). In the mod-
eled attacks, the malicious nodes try to force the system into
a new state (Dynamic Creation) or to delete a valid state (Dy-
namic Deletion). Malicious behavior is injected in one-third
of the available sensors.
In the scenario shown in Fig. 10(a), the malicious attack
deletes a correct environment state (29,56) by reporting tem-
perature values lower than other sensors, hence keeping the
overall, observed value of the temperature constant at 24. The
malicious sensor also keeps the humidity value approximately
constant at 70 during that period. (Note that forcing the over-
all humidity to a precise 70 value would require malicious
humidity values greater than 100, which could be easily de-
tected with range checking. In this study, we have decided
to maintain malicious values within their admissible range,
e.g., [0, 100] for humidity.) As discussed in § 3.4, attacks can
be classiﬁed by analyzing the observation symbol probability
distribution, BCO. Table 6 depicts matrix BCO for malicious
sensor 7. It can be seen that the row probabilities are not or-
thogonal (see row (29,56) and row (20,71)). According to our
methodology, this indicates that an adversary has deleted an
environment state (state (29,56) in the example) from the ob-
servations. In fact, the considered attack has effectively elimi-
nated a transition from state (20,71) to state (29,56) by forcing
6Based on Table 5, we associate model states as follows:
(22,80) to
(17,88), (17,88) to (13,96), (27,68) to (22,80), and (32,56) to (27,68).
i
]
s
u
s
e
c
[
l
e
r
u
t
a
r
e
p
m
e
T
50
45
40
35
30
25
20
15
10
5
0
9
Faulty
Observed