it does not specify when or in what order are network messages de-
livered. It is up to the code generator to select how to pack values
into network messages and when to send them. While it is def-
initely true that a programmer can easily construct more eﬃcient
networking schemes for small protocols, our experience shows that
doing so for medium sized and large protocols is an extremely time-
consuming and labor intensive task. The Sharemind’s architecture
allows us to select between hand-tuned and generated protocols.
Sometimes it is useful to reshare a value in such a way that one
of the parties holds 0 as its share. Such resharing protocol is given
In this protocol, given the shares of an input u =
in Listing 2.
(u1, u2, u3), the ﬁrst computing party generates a random value r2,
sends it to the second computing party and sends r3 = u1 − r2 to the
third computing party. The second and third computing parties add
the received values to their input shares. The resulting shares are
(0, u2 + r2, u3 + (u1 − r2)) which sum to the original value u.
The protocol in Listing 2 demonstrates various features of the
language: the ability to perform computation and to deﬁne values
for only some subset of parties, the ability to branch the compu-
tation depending on the evaluating party and ﬁnally the ability to
receive values from certain ﬁxed parties. The variables r2 and r3
are only deﬁned by the ﬁrst computing party. The result of the
function body is computed diﬀerently depending on the computing
party: the ﬁrst computing party always returns 0, while the second
[resp. third] computing party adds r2 [resp. r3] received from the
ﬁrst party to its input share.
2.2 Multiplication protocol
multiplication over addition: (u1 +u2 +u3)(v1 +v2 +v3) =(cid:80)3,3
The algorithm for multiplying two additively shared numbers
u, v ∈ Z2n is based on a simple equality given by distributivity of
= (cid:80)3
i, j=1,1 uiv j
i=1(uivi + uivp(i) + up(i)vi), where p(i) denotes the previous in-
dex (p maps 2 (cid:55)→ 1, 3 (cid:55)→ 2 and 1 (cid:55)→ 3). This equation is directly
mapped to code in Listing 3 by letting the i-th party compute the
term wi = uivi + uivp(i) + up(i)vi. To achieve security and privacy
the algorithm reshares both of the inputs and the output. Notice the
let-expression overshadowing input variables u and v with same
names. We can see the similarity to Algorithm 2 in [8] but again,
the presentation is much more concise.
Textually the resharing call on the output occurs after the rest
of the code but notice that there are no data dependencies that for-
bid us from performing the network communication of all the re-
share calls in parallel during the ﬁrst communication round. This
is exactly what happens in practice where we try to minimize the
number of communication rounds required by the protocol. The
let
u = reshare u
v = reshare v
w = u * v + u * (v from Prev) + (u from Prev) * v
in reshare w
Listing 3: Multiplication protocol
simplest approach to achieve this is to greedily send values with
messages in the earliest communication round possible. We will
see in Sec. 3.5 that during automatic optimizations the round count
of multiplication protocol is reduced to one.
Usually we specify the protocols for integers of arbitrary bit-
width n, such as the multiplication protocol here, but in the concrete
system the protocol implementations are instantiated to bit-widths
that computers support natively. In most cases protocols are spe-
cialized to operate on 8-, 16-, 32- and 64-bit integers but in general
the bit-widths we specialized the protocols to are not restricted.
The only limitation is that we do not allow the choice of bit-width
happen dynamically; it always has to be ﬁxed before executing the
code, during compilation of protocols. Support for arbitrarily large
integers has turned out to be extremely useful. For example, inte-
ger division protocol internally uses larger than 128-bit integers. In
addition to that, as we will later see, ﬁxed-point computations (that
are used to implement ﬂoating-point operations as in [28]) can be
sped up by starting operations on large integers and gradually cut-
ting back during the protocol.
2.3 Bit-level protocols
Many of the high-level protocols in Sharemind are implemented
in terms of bit-level operations. Accessing bits of additively shared
values is a non-trivial task. For example, to extract the highest
(most signiﬁcant) bit of a 2-bit number we not only have to consider
the highest bits of the shares but also have to take into account
the possibility that the sum of the lowest bits of the shares may
overﬂow and inﬂuence the value of the highest bit.
Consider the special case of additive secret sharing over the ring
Z2. The multiplication over Z2 acts as boolean conjunction ∧ and
the addition operation as the XOR operation ⊕. We can extend this
to bitwise additive secret sharing over the ring Zn
2 where the bitwise
XOR of two private values can be computed as the bitwise XOR
of respective shares and the bitwise conjunction can be computed
with a protocol similar to Listing 3. Bitwise negation is computed
by an odd number of parties negating their shares, and disjunction
is computed using conjunction and negation via De Morgan’s laws.
We call this kind of bitwise additive secret sharing XOR sharing.
Preﬁx-or is a primitive bit-level protocol that is often used inside
higher-level operations. The preﬁx-or of a value (cid:126)u ∈ Zn
2 is obtained
by propagating its most signiﬁcant 1 bit downwards. For example,
the preﬁx-or of the 8-bit number 001011002 is 001111112. If ui is
the i-th bit of (cid:126)u, then the preﬁx-or of (cid:126)u is (cid:126)v, where vi =(cid:87)n
The implementation of preﬁx-or is shown in Listing 4. We use
the disjBit protocol for computing disjunction of a XOR shared
number and a bit, and a built-in function ++ for array concatena-
tion. Our DSL allows to manipulate integers as bit-arrays where
lower indices denote less signiﬁcant bits. The prefixOR function is
deﬁned recursively: we split the input into two roughly equal parts
(u[m .. n] denotes the slice of the array u from index m until the
index n − 1) and recursively compute the preﬁx-or of the parts. We
concatenate the resulting parts, but if the lowest bit of the higher
half is set, then every bit of the lower half of the result must be set
j=i (cid:126)ui.
def disjBit : uint[n] -> bit -> uint[n]
def ++ : arr[a,n] -> arr[a,m] -> arr[a,n+m]
def prefixOR : uint[n] -> uint[n] = \u ->
if (n  uint[n] -> uint[n]
def bitextr : uint[n] -> uint[n] = \u ->
let
v = reshareToTwo u
x = case: 2 -> v | {1,3} -> 0
y = case: 3 -> v | {1,2} -> 0
in addXor x y
Listing 5: Bit extraction
as well. Preﬁx-or of a 0- or 1-bit number is the number itself; this
is the recursion base.
The implementation of preﬁx-or in Listing 4 demonstrates recur-
sion over type level naturals: the if-check is over a type predicate
n = n => uint[m] -> uint[n] -> uint[m]
def chVector : m >= n > 0 => uint[n] -> uint[m] = \u ->
let
u = reshare u
c = case:
1 -> rol (1, u)
{2, 3} -> 0
c = xorReshareToTwo c
in case:
1 -> 0
{2, 3} -> rol (c, u from 2 + u from 3)
Listing 6: Characteristic vector
def countUp : uint[n] -> arr[uint[n],m]
def conjBit : uint[n] -> bit -> uint[n]
def shiftr : n >= m > 0 => uint[n] -> uint[m] -> uint[n] =
\u s -> let
u = bitextr u
v = map (\i -> u >> i) (countUp 0)
bs : uint[n] = chVector s
rs = zipWith conjBit v bs
r = foldl (\x y -> x ^ y) 0 rs
in xorToAdditive r
Listing 7: Private shift right
function rol) by u1 and XOR shares the resulting value between
parties 2 and 3. The receiving parties sum the input shares u2 and
u3 and rotate the received values by the sum to produce the result.
As a result we have rotated 1 ∈ Zm
2 by u positions (ﬁrst party rotat-
ing it by u1 and the rest rotating it by u2 +u3). Because the shares of
u can be larger than m the rotations are performed modulo m. This
protocol takes constant number of communication rounds regard-
less of the number of input or output bits. It could be converted to a
bit extraction protocol (the one in Listing 5 takes O(log n) rounds)
using no further communication, but its network communication
scales linearly with the bound m.
2.4 High-level protocols
One of the simplest high-level protocols that Sharemind imple-
ments is a bit-shift right on additively shared data (Listing 7). This
protocol is often used to implement ﬂoating-point operations but is
also useful as a stand-alone protocol. To shift an additively shared
u ∈ Z2n right by an additively shared s ∈ Z2m we ﬁrst convert u to
XOR shared integer (cid:126)u. The XOR shared representation allows us to
calculate all possible shifts vi = (cid:126)u (cid:29) i by public values 0 ≤ i < m.
(cid:76)n−1
As the result we pick the correct one out of all the possible shifts
i=0 vi ∧ (s = i). The protocol conjBit is
by computing r as
applied pointwise to elements of v and b using higher-order func-
tion zipWith and all of the invocations of the argument protocol are
executed in parallel. Listing 7 also demonstrates the parallel com-
position of previously deﬁned non-trivial protocols: bitextr and
chVector. The meaning of higher-order functions map, zipWith and
foldl is standard (see e.g. [32]).
We have used the protocol DSL to implement ﬂoating-point arith-
metic and most of the primitive operations from [23]. Brieﬂy, in
Sharemind a ﬂoating-point number N is composed of three parts:
sign bit s, signiﬁcand f , and exponent e such that N = (−1)s · f · 2e
where the signiﬁcand is always in the range 1/2 ≤ f < 1.
In
the protocol DSL we represent the sign bit, exponent and single-
precision fractional part with 1-, m- and n-bit unsigned integers
respectively (for single- [resp. double-]precision ﬂoats we have
m = 16 and n = 32 [resp. n = 64]).
The fractional part f is represented as an unsigned integer where
the most signiﬁcant bit denotes 1/2, the second highest one 1/4 and
so on. This lets us approximate real values in the range [1/2, 1). We
require that the representation is normalized, meaning that the most
signiﬁcant bit is always 1. The only exception to that is when we
want to represent zero, in which case f = 0. Unlike IEEE ﬂoating-
point numbers we explicitly store the highest bit.
As a ﬁnal example we demonstrate a protocol for computing the
inverse of a ﬂoating-point number. The intuitive idea is that for a
ﬂoating-point number N = (−1)s · f · 2e we have
= (−1)s · 1
2 f
= (−1)s 1
f 2e
= (−1)s 1
2 f
· 21−e .
1
2e−1
1
N
i=0
(cid:17)
(cid:16)