### Description
I am performing a GridSearch for the Gradient Boosting algorithm, and for certain parameter combinations, the process hangs after 10-15 minutes on my laptop. Initially, the number of Python processes matches the number of CPU cores (8 in my case), and they show visible activity. However, after some time, the processes disappear, and no further progress is reported. I found a similar issue related to `GridSearchCV` processes hanging with `n_jobs`, but it was closed, so I decided to open a new issue.

### Steps/Code to Reproduce

#### Data Setup
- **Dataset**: Census data from the UCI repository.
- **Original Features**:
  - `RangeIndex`: 45222 entries, 0 to 45221
  - `Data columns` (total 14 columns):
    - `age`: 45222 non-null int64
    - `workclass`: 45222 non-null object
    - `education_level`: 45222 non-null object
    - `education-num`: 45222 non-null float64
    - `marital-status`: 45222 non-null object
    - `occupation`: 45222 non-null object
    - `relationship`: 45222 non-null object
    - `race`: 45222 non-null object
    - `sex`: 45222 non-null object
    - `capital-gain`: 45222 non-null float64
    - `capital-loss`: 45222 non-null float64
    - `hours-per-week`: 45222 non-null float64
    - `native-country`: 45222 non-null object
    - `income`: 45222 non-null object
  - `dtypes`: float64(4), int64(1), object(9)
  - `memory usage`: 4.8+ MB
- **After One-Hot Encoding**: 103 total features.

#### Code
```python
from sklearn.grid_search import GridSearchCV
from sklearn.metrics import fbeta_score, make_scorer, accuracy_score
from sklearn.ensemble import GradientBoostingClassifier

# Initialize the classifier
clf = GradientBoostingClassifier()

# Define the parameter grid
parameters = {
    'loss': ['deviance', 'exponential'],
    'warm_start': [True, False],
    'max_depth': [4, 5, 6, 7],
    'n_estimators': [100, 200, 300]
}

# Create the scorer
scorer = make_scorer(fbeta_score, beta=0.5)

# Initialize GridSearchCV
grid_obj = GridSearchCV(
    clf,
    param_grid=parameters,
    scoring=scorer,
    n_jobs=-1,
    verbose=10
)

# Fit the model
grid_fit = grid_obj.fit(X_train, y_train)

# Get the best estimator
best_clf = grid_fit.best_estimator_
```

### Versions
- **Operating System**: Darwin-16.7.0-x86_64-i386-64bit
- **Python**: 2.7.10 (default, Sep 23 2015, 04:34:14) \n[GCC 4.2.1 Compatible Apple LLVM 7.0.0 (clang-700.0.72)]
- **NumPy**: 1.13.3
- **SciPy**: 1.0.0
- **Scikit-Learn**: 0.19.1

### Actual Results
The output of the incomplete process after 3 hours of running:

```
Fitting 3 folds for each of 48 candidates, totalling 144 fits
[CV] n_estimators=100, loss=deviance, warm_start=True, max_depth=4 ...
[CV] n_estimators=100, loss=deviance, warm_start=True, max_depth=4 ...
[CV] n_estimators=100, loss=deviance, warm_start=True, max_depth=4 ...
[CV] n_estimators=100, loss=deviance, warm_start=False, max_depth=4 ..
[CV] n_estimators=100, loss=deviance, warm_start=False, max_depth=4 ..
[CV] n_estimators=100, loss=deviance, warm_start=False, max_depth=4 ..
[CV] n_estimators=200, loss=deviance, warm_start=True, max_depth=4 ...
[CV] n_estimators=200, loss=deviance, warm_start=True, max_depth=4 ...
[CV]  n_estimators=100, loss=deviance, warm_start=True, max_depth=4, score=0.748376 - 1.1min
[CV] n_estimators=200, loss=deviance, warm_start=True, max_depth=4 ...
[CV]  n_estimators=100, loss=deviance, warm_start=True, max_depth=4, score=0.744681 - 1.1min
[CV]  n_estimators=100, loss=deviance, warm_start=False, max_depth=4, score=0.748376 - 1.1min
[CV] n_estimators=200, loss=deviance, warm_start=False, max_depth=4 ..
[CV] n_estimators=200, loss=deviance, warm_start=False, max_depth=4 ..
[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:  1.1min
[CV]  n_estimators=100, loss=deviance, warm_start=True, max_depth=4, score=0.755791 - 1.1min
[CV] n_estimators=200, loss=deviance, warm_start=False, max_depth=4 ..
[CV]  n_estimators=100, loss=deviance, warm_start=False, max_depth=4, score=0.744681 - 1.1min
[CV] n_estimators=300, loss=deviance, warm_start=True, max_depth=4 ...
[CV]  n_estimators=100, loss=deviance, warm_start=False, max_depth=4, score=0.755791 - 1.1min
[CV] n_estimators=300, loss=deviance, warm_start=True, max_depth=4 ...
[CV]  n_estimators=200, loss=deviance, warm_start=True, max_depth=4, score=0.755238 - 2.0min
[CV] n_estimators=300, loss=deviance, warm_start=True, max_depth=4 ...
[CV]  n_estimators=200, loss=deviance, warm_start=True, max_depth=4, score=0.748726 - 2.0min
[CV] n_estimators=300, loss=deviance, warm_start=False, max_depth=4 ..
[CV]  n_estimators=200, loss=deviance, warm_start=False, max_depth=4, score=0.755390 - 2.3min
[CV] n_estimators=300, loss=deviance, warm_start=False, max_depth=4 ..
[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  3.4min
[CV]  n_estimators=200, loss=deviance, warm_start=False, max_depth=4, score=0.748651 - 2.3min
[CV] n_estimators=300, loss=deviance, warm_start=False, max_depth=4 ..
```

The process appears to hang without any further progress or errors.