ﬁguring out the level of obfuscation necessary to thwart
attackers may be tricky. Simple instruction replacement,
e.g., multiplications by 2 with left shifts, may thwart
EBDS but not a more sophisticated tool that focused
on semantic, not assembly-level syntactic differences.
Another problem is the effects of obfuscation should be
transparent to legitimate users, e.g., obfuscation that de-
grades performance is likely unacceptable.
Patch Encryption. We could initially encrypt patches
so that simply having the patch leaks no information.
Then, after a suitable time period, a short decryption
key (e.g., 128-bits) is broadcast. This scheme allows all
users who have the patch and receive the key to apply
it simultaneously. Others have independently arrived at
similar ideas [32].
Patch encryption allows vendors to use essentially the
same staggered patch distribution architecture while de-
fending against automatic patch-based exploit genera-
tion. Simultaneously (or near simultaneously) distribut-
ing the decryption key is possible since the key is very
small, e.g., 64-bits. Therefore, this scheme is potentially
fair in the security sense: everyone has the same op-
portunity to apply the patch before anyone could poten-
tially derive an exploit. However, one potential prob-
lem is how to handle off-line hosts. A second problem
is the actual ﬁxes are delayed from the users perspec-
tive, which raises a number of policy issues. There are
security-related policy choices, e.g., should patches be
encrypted when a zero-day exploit is available to a few
attackers, but not all attackers. There are also human-
related choices, e.g., people may not like the idea of
having a patch that they cannot apply. Further research
is needed to answer such questions.
Fast Patch Distribution. It may be possible to change
patch distribution so everyone receives the patch at
about the same time. For example, Gkantsidis et al.
propose using a peer-to-peer network for patch distri-
bution in order to reduce the load on patch distribution
servers [18]. Such a peer-to-peer system could poten-
tially also distribute patches faster than the centralized
model. However, such as scheme would still need to ad-
dress off-line hosts.
It is also unclear whether such a
scheme is fast enough to combat APEG.
6 Discussion
Generating Speciﬁc Exploits. The techniques we de-
scribe generate an exploit from the universe of all ex-
ploits for a patched vulnerability. At a high level, the
solver gets to pick any exploit that satisﬁes the generated
formula. We can make the formula speciﬁc to achieve a
particular attack purpose, e.g., a control hijack attack.
Note that since initially we do not know what vulner-
ability is patched, it does not make sense to try to create
a speciﬁc type of exploit a priori. For example, if the
unknown vulnerability is an information disclosure vul-
nerability, it makes no sense to try to create a control
hijack exploit.
However, once we know what vulnerability can be
exploited, we can extend our approach to generate spe-
ciﬁc kinds of attacks, as long as we can write the condi-
tions necessary in the modeling language. Vine allows
us to specify meta-properties we would like to hold on
the x86 program. Thus, we can state a meta-property
such as asserting a store instruction overwrites the re-
turn address. For example, the x86 call instruction is
modeled as ﬁrst storing the return address on the stack,
then jumping to the designated program location. An
x86 return instruction can be modeled as loading a 32-
bit number from the stack, then jumping to the given
address in Vine. In the modeling language, we can add
checks about the x86 program such as the return is to the
same address stored by the call instruction. Overwriting
the stack pointer is just one example: we could monitor
the initial exploit to garner more information about what
sensitive data structures are possible to overwrite. We
leave exploring this as future work.
Dealing with Multiple Checks. The patch for a single
vulnerability may have many new checks in the patched
version. In some cases, our techniques will still work
as in the GDI vulnerability. In other cases, it is not so
clear. Recall that the model is generated with respect
to the patched program. Consider the case where an in-
put has to fail two new checks a and b in sequence to
exploit the unpatched version. Initial exploit generation
for a may generate an exploit, but veriﬁcation will fail
since by assumption the program is not exploitable when
check a fails alone. We then consider b. Since we are
building a model over the patched program, the model
155
represents all potential paths through a and b, e.g., the
case where they fail together, but also the case where a
succeeds but b fails. By default the formula generated
by our techniques considers each check independently.
Since the set of inputs which fail b and a is a subset of
those that just fail b, we may get lucky and the deci-
sion procedure returns an input which fails both a and
b. From the security standpoint, it is usually prudent to
assume attackers are lucky. However, we may also get
back an answer where b fails but a does not, since that is
all the formula required. This can be solved by querying
for various combinations of new checks. Since consider-
ing each combination is undesirable, this problem would
beneﬁt from further research.
Note an independent problem is if an update ad-
dresses multiple vulnerabilities. Since our current ap-
proach is considers each check individually, it would
simply be iterated over all checks irrespective of how
many vulnerabilities are patched.
Other Applications of Our Techniques. Our tech-
niques have applications in other areas. For example, au-
tomatic deviation detection is concerned with the prob-
lem of ﬁnding any input i for programs P1 and P2 such
that the behavior of P1(i) is different than P2(i). In our
scenario, P1 = P and P2 = P ′, and the deviation input
i = e such that P1 is exploited but P2 is not. Previ-
ous work focused on deviation detection from a single
dynamic trace [4]; we consider multiple paths.
We expect our techniques, especially combined dy-
namic and static formula generation, will be applicable
to many similar problems that require modeling multi-
ple program paths. Most previous work that requires
generating a formula to represent a program path only
focus on a single path for scalability reasons. Our work
shows for the ﬁrst time that scaling up to multiple paths
is possible. In particular, applying the combined static
and dynamic approach to other settings is an interesting
avenue to explore.
7 Related Work
Fuzzing to ﬁnd inputs which crash programs essen-
tially tries random or guided semi-random inputs on a
program [15, 20, 24–26]. Fuzzing tools have recently
become popular as a way of ﬁnding exploits for pro-
grams, e.g., fuzzing found numerous vulnerabilities in
the Month of Browser Bugs [1]. Recently, fuzzing tech-
niques have been augmented to produce particular kinds
of exploits, e.g., control-hijack exploits for buffer over-
ﬂow vulnerabilities [24]. Unlike fuzzing, our approach
is goal-oriented: we ﬁnd an input that reach a speciﬁc
line of code (the new check). Instead of searching for
vulnerabilities at random, we use the patch as a guide to
generate exploits. Fuzzing and similar techniques also
only consider P , thus do not address generating exploits
from patches.
We use an off-the-differencer to identify changes.
Research in ﬁnding semantic differences, such as Bin-
Hunt [17], would help winnow down the number of new
checks for which we try exploit generation.
Our techniques are closely related to automatic test
case generation, which has a long history (e.g., [3, 21–
23]). Our techniques are most closely related to goal-
based test generation (e.g., [21]) where inputs are auto-
matically generated that will execute a given goal state-
ment in the program. Test case generation does not ad-
dress the problem of creating exploits from patches, and
therefore does not address the security ramiﬁcations.
Similar techniques for generating formulas in the
static and dynamic approaches have previously been ap-
plied to signature generation [5,6,8,9]. We use the chop-
ping algorithm from our previous work [5], and generate
formulas using the efﬁcient method from [6].
8 Conclusion
We have demonstrated that automatic patch-based ex-
ploit generation is possible in several real-world cases.
In our evaluation, we are able to automatically gener-
ate an exploit given just the unpatched and patched pro-
gram usually within a few minutes. In order to achieve
our results, we developed novel techniques for analyzing
potential exploitable paths to a new sanitization check.
Since best security practices dictate that we conserva-
tively estimate the power of an attacker, our results im-
ply that in security critical scenarios automatic patch-
based exploit generation should be considered practical.
One immediate consequence we suggest is that the cur-
rent patch distribution schemes are insecure, and should
be redesigned to more fully defend against automatic
patch-based exploit generation.
Acknowledgements
The authors would like to thank the anonymous refer-
ees, Ivan Jager, James Newsome, Steven Rudich, Vyas
Sekar, and Shobha Venkataraman for their feedback in
preparing this paper.
References
[1] Month
of
browser
bugs website.
http:
//browserfun.blogspot.com, 2006.
[2] The BitBlaze binary analysis project.
http://
bitblaze.cs.berkeley.edu, 2007.
[3] C. Boyapati, S. Khurshid, and D. Marinov. Korat: Auto-
mated testing based on java predicates. In ACM Interna-
tion Symposium on Software Testing and Analysis, pages
123–133, July 2002.
156
[4] D. Brumley, J. Caballero, Z. Liang, J. Newsome, and
D. Song. Towards automatic discovery of deviations in
binary implementations with applications to error detec-
tion and ﬁngerprint generation.
In Proceedings of the
USENIX Security Symposium, Boston, MA, Aug. 2007.
[5] D. Brumley, J. Newsome, D. Song, H. Wang, and S. Jha.
Towards automatic generation of vulnerability-based sig-
natures. In Proceedings of the IEEE Symposium on Se-
curity and Privacy, pages 2–16, 2006.
[6] D. Brumley, H. Wang, S. Jha, and D. Song. Creating
vulnerability signatures using weakest pre-conditions. In
Proceedings of the IEEE Computer Security Foundations
Symposium, 2007.
[7] C. Cadar, V. Ganesh, P. Pawlowski, D. Dill, and D. En-
gler. EXE: A system for automatically generating inputs
of death using symbolic execution. In Proceedings of the
ACM Conference on Computer and Communications Se-
curity, Oct. 2006.
[8] M. Costa, M. Castro, L. Zhou, L. Zhang, and M. Peinado.
Bouncer: Securing software by blocking bad input.
In
Proceedings of the ACM Symposium on Operating Sys-
tem Principles, oct 2007.
[9] M. Costa, J. Crowcroft, M. Castro, A. Rowstron,
L. Zhou, L. Zhang, and P. Barham. Vigilante: End-to-
end containment of internet worms. In Proceedings of the
ACM Symposium on Operating System Principles, 2005.
[10] A. Crosswell. Igmp v3 tcpdump trace. http://www.
columbia.edu/∼alan/igmp/ex1b/.
[11] E. Dijkstra. A Discipline of Programming. Prentice Hall,
Englewood Cliffs, NJ, 1976.
[12] T. Dullein and R. Rolles. Graph-based comparison of ex-
ecutable objects. In Proceedings of the Symposium sur la
Securite des Technologies de L’information et des com-
munications, 2005.
[13] eEyE Security.
eEye binary difﬁng suite (EBDS).
http://research.eeye.com/html/tools/
RT20060801-1.html. Version 1.0.5.
[14] H. Flake. Structural comparison of executable objects. In
Proceedings of the IEEE Conference on Detection of In-
trusions, Malware, and Vulnerability Assessment, 2004.
[15] J. Forrester and B. Miller. An empirical study of the ro-
bustness of windows nt applications using random test-
ing. In 4th USENIX Windows Systems Symposium, 2000.
[16] V. Ganesh and D. L. Dill. A decision procedure for bit-
vectors and arrays. In W. Damm and H. Hermanns, edi-
tors, Proceedings on the Conference on Computer Aided
Veriﬁcation, volume 4590 of Lecture Notes in Computer
Science, pages 524–536, Berlin, Germany, July 2007.
Springer-Verlag.
[17] D. Gao, M. K. Reiter, and D. Song. Binhunt: Automat-
ically ﬁnding semantic differences in binary programs.
Technical report, School of Information Sciences, Singa-
pore Management University, February 2008.
[18] C. Gkantsidis, T. Karagiannis, P. Rodriguez, and M. Vo-
jnovic. Planet scale software updates.
In Proceedings
of the ACM Special Interest Group on Data Communica-
tion, 2006.
[19] P. Godefroid, N. Klarlund, and K. Sen. DART: Directed
automated random testing. In Proceedings of the ACM
Conference on Programming Language Design and Im-
plementation, 2005.
[20] P. Godefroid, M. Levin, and D. Molnar. Automated
[21] A. Gotlieb, B. Botella, and M. Rueher.
whitebox fuzz testing.
In Proceedings of the Network
and Distributed System Security Symposium, Feb. 2008.
Auto-
matic test data generation using constraint solving tech-
niques. ACM SIGSOFT Software Engineering Notes,
23(2):1998, 1998.
[22] N. Gupta, A. Mathur, and M. L. Soffa. Automated
test data generation using an iterative relaxation method.
ACM SIGSOFT Software Engineering Notes, 23(6):231–
244, Nov. 1998.
[23] B. Korel. Automated test data generation. IEEE Trans-
actions on Software Engineering, 16(8):870–879, 1990.
path-based test set generation.
[24] J. Medeiros. Automated expoit development: The future
http://toorcon.org/
of exploitation is here.
2007/talks/19/toorcon whitepaper.pdf,
2007.
[25] B. Miller, G. Cooksey, and F. Moore. An empirical study
of the robustness of macos applications using random
testing.
In Proceedings of the International Workshop
on Random Testing, 2006.
[26] B. Miller, L. Fredriksen, and B. So. An empirical study
of the reliability of UNIX utilities. Communications of
the Association for Computing Machinery, 33(12):32–
44, 1990.
[27] D. Moore, V. Paxson, S. Savage, C. Shannon, S. Stani-
ford, and N. Weaver. Inside the slammer worm. In Pro-
ceedings of the IEEE Symposium on Security and Pri-
vacy, volume 1, 2003.
[28] S. Muchnick. Advanced Compiler Design and Implemen-
tation. Academic Press, 1997.
[29] R. Naraine.
Crime rings target
ie ’setslice’ ﬂaw.
http://www.eweek.com/article2/0%
2C1759%2C2022805%2C00.asp, 2006.
[30] J. Newsome, D. Brumley, J. Franklin, and D. Song. Re-
player: Automatic protocol replay by binary analysis. In
R. Write, S. D. C. di Vimercati, and V. Shmatikov, edi-
tors, Proceedings of the ACM Conference on Computer
and Communications Security, pages 311–321, 2006.
[31] A. Protas and S. Manzuik.
in mi-
BlackHat Europe 2006: http:
Skeletons
crosoft’s closet.
//www.blackhat.com/presentations/
bh-europe-06/bh-eu-06-Manzuik.pdf.
[32] J. Roskind. Attacks against the netscape browser plus
security response philosophy and methods. Private com-
munication and seminar talk.
[33] Sabre Security.
Bindiff.
http://www.
sabre-security.com/products/bindiff.
html.
[34] F. B. Schneider. Enforceable security policies. ACM
Transactions on Information and System Security,
3(1):30–50, February 2000.
[35] Secure Science Corporation. Analysis of the WebView-
FolderIcon ActiveX integer overﬂow (setSlice). http:
//www.mnin.org, 2006.
157