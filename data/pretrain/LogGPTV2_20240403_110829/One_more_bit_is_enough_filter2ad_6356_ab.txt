ing one bottleneck link. Clearly, VCP is successful in track-
ing the bandwidth changes by using MIMD, and achieve fair
allocation when the second ﬂow arrives, by using AIMD.
The Internet, however, is much more complex than this
simpliﬁed example across many dimensions: the link capac-
ities and router buﬀer sizes are highly heterogeneous, the
RTT of ﬂows may diﬀer signiﬁcantly, and the number of
ﬂows is unknown and changes over time. We next describe
the details of the VCP protocol, which will be able to handle
more realistic environments.
3. THE VCP PROTOCOL
In this section, we provide a detailed description of VCP.
We begin by presenting three key issues that need to be
addressed in the design of VCP. Then, we describe how we
address each of these issues in turn.
3.1 Key Design Issues
To make VCP a practical approach for the Internet-like
environments with signiﬁcant heterogeneity in link capaci-
ties, end-to-end RTTs, router buﬀer sizes and variable traﬃc
characteristics, we need to address the following three key
issues.
Load factor transition point: VCP separates the net-
work load condition into three regions: low-load, high-load
and overload. The load factor transition point in VCP rep-
resents the boundary between the low-load and high-load
regions, which is also the demarcation between applying MI
and AI algorithms. The choice of the transition point repre-
sents a trade-oﬀ between achieving high link utilization and
responsiveness to congestion. Achieving high network uti-
lization requires a high value for the transition point. But
this choice negatively impacts responsiveness to congestion,
which in turn aﬀects the convergence time to achieve fair-
ness. Additionally, given that Internet traﬃc is inherently
bursty [46][56], we require a reliable estimation algorithm of
the load factor. We discuss the issue of load factor estima-
tion in Section 3.2.
Setting of congestion control parameters: Using MI
for congestion control is often fraught with the danger of in-
stability due to its large variations over short time scales.
To maintain stability and avoid large queues at routers, we
need to make sure that the aggregate rate of the VCP ﬂows
using MI does not overshoot the link capacity. Similarly, to
achieve fairness, we need to make sure that a ﬂow enters the
AI phase before the link gets congested.
In order to sat-
isfy these criteria, we need an appropriate choice of MI, AI
and MD parameters that can achieve high utilization while
maintaining stability, fairness and small persistent queues.
To better understand these issues, we ﬁrst describe our pa-
rameter settings for a simpliﬁed network model, where all
ﬂows have the same RTT and observe the same state of
the network load condition, i.e., all ﬂows obtain the same
load factor feedback (Section 3.3). We then generalize our
parameter choice for ﬂows with heterogeneous RTTs.
Heterogeneous RTTs: When ﬂows have heterogeneous
RTTs, diﬀerent ﬂows can run diﬀerent algorithms (i.e., MI,
AI, or MD) at a given time. This may lead to unpredictable
behavior. The RTT heterogeneity can have a signiﬁcant
impact even when all ﬂows run the same algorithm, if this
algorithm is MI. In this case, a ﬂow with a lower RTT can
claim much more bandwidth than a ﬂow with a higher RTT.
To address this problem, end-hosts need to adjust their MI
parameters according to their observed RTTs, as discussed
in Section 3.4.
 0 5 10 15 20 0 50 100 150 200 250Flow Throughput (Mbps)Time (sec)capacity1st flow2nd flowFigure 2: The quantized load factor ˆρl at a link l is a
non-decreasing function of the raw load factor ρl and can
be represented by a two-bit code ˆρc
l .
We now discuss these three design issues in greater detail.
3.2 Load Factor Transition Point
Consider a simple scenario involving a ﬁxed set of long-
lived ﬂows. The goal of VCP is to reach a steady state
where the system is near full utilization, and the ﬂows use
AIMD for congestion control. To achieve this steady state,
the choice of the load factor transition point should satisfy
three constraints:
• The transition point should be suﬃciently high to en-
able the system to obtain high overall utilization;
• After the ﬂows perform an MD from an overloaded
state, the MD step should force the system to always
enter the high-load state, not the low-load state;
• If the utilization is marginally lower than the transition
point, a single MI step should only lift the system into
the high-load state, but not the overload state.
Let β  0.95, and it takes VCP about 14
RTTs to halve the congestion window. At the other end, if
we chose β = 0.5 (as in TCP [25]), the transition point can
be at most 50%, which reduces the overall network utiliza-
tion. To balance these conﬂicting requirements, we chose
β = 0.875, the same value used in the DECbit scheme [58].
Given β, we set the load factor transition point to 80%.
This gives us a “safety margin” of 7.5%, which allows the
system to operate in the AIMD mode in steady state. In
summary, we choose the following three ranges to encode
the load factor ρl (see Figure 2):
• Low-load region: ˆρl = 80% when ρl ∈ [0%, 80%);
• High-load region: ˆρl = 100% when ρl ∈ [80%, 100%);
• Overload region: ˆρl > 100% when ρl ∈ [100%,∞).
l , i.e., ˆρc
Thus, the quantized load factor ˆρl can be represented us-
ing a two-bit code ˆρc
l = (01)2, (10)2 and (11)2 for
ˆρl = 80%, ˆρl = 100% and ˆρl > 100%, respectively. The
code (00)2 is reserved for ECN-unaware source hosts to sig-
nal “not-ECN-capable-transport” to ECN-capable routers,
which is essential for incremental deployment [57]. The en-
coded load factor is embedded in the two-bit ECN ﬁeld in
the IP header.
Estimation of the load factor: Due to the bursty na-
ture of the Internet traﬃc, we need to estimate the load
factor over an appropriate time interval, tρ. When choos-
ing tρ we need to balance two conﬂicting requirements. On
one hand, tρ should be larger than the RTTs experienced by
most ﬂows to factor out the burstiness induced by the ﬂows’
responses to congestion. On the other hand, tρ should be
small enough to avoid queue buildup.
Internet measure-
ments [55, 30] report that roughly 75%∼90% of ﬂows have
RTTs less than 200 ms. Hence, we set tρ = 200ms. During
every time interval tρ, each router estimates a load factor ρl
for each of its output links l as [27, 34, 18, 2, 42]:
λl + κq ·(cid:101)ql
Here, λl is the amount of input traﬃc during the period tρ,(cid:101)ql
γl · Cl · tρ
ρl =
(1)
.
is the persistent queue length during this period, κq controls
how fast the persistent queue drains [18, 2] (we set κq = 0.5),
γl is the target utilization [42] (set to a value close to 1), and
Cl is the link capacity. The input traﬃc λl is measured using
a packet counter. To measure the persistent queue(cid:101)ql, we use
a low-pass ﬁlter that samples the instantaneous queue size,
q(t), every tq (cid:191) tρ (we chose tq = 10ms).
3.3 Congestion Control Parameter Setting
In this section, we discuss the choice of parameters used by
VCP to implement the MI/AI/MD algorithms. To simplify
the discussion, we consider a single link shared by ﬂows,
whose RTTs are equal to the link load factor estimation
period, i.e., rtt = tρ. Hence, the ﬂows have synchronous
feedback and their control intervals are also in sync with
the link load factor estimation. We will discuss the case of
heterogeneous RTTs in Section 3.4.
At any time t, a VCP sender performs one of the three
actions based on the value of the encoded load factor sent
by the network:
(2)
(3)
MI :
AI :
cwnd(t + rtt) = cwnd(t) × ( 1 + ξ )
cwnd(t + rtt) = cwnd(t) + α
cwnd(t + δt) = cwnd(t) × β
MD :
(4)
where rtt = tρ, δt → 0+, ξ > 0, α > 0 and 0 100%(10)280%100%80%100%: (01)2codeload: lowhighoverhosts only obtain feedback on the utilization region as op-
posed to the exact value of the load factor, they need to
make a conservative assumption that the network load is
near the transition point. Thus, the end-hosts use the value
of ξ(80%) = 0.0625 in the MI phase.
3.4 Handling RTT Heterogeneity with
Parameter Scaling
Until now, we have considered the case where competing
ﬂows have the same RTT, and this RTT is also equal to the
load factor estimation interval, tρ. In this section, we relax
these assumptions by considering ﬂows with heterogeneous
RTTs. To oﬀset the impact of the RTT heterogeneity, we
need to scale the congestion control parameters used by the
end-hosts according to their RTTs.
Scaling the MI/AI parameters: Consider a ﬂow with
a round trip time rtt, and assume that all the routers use the
same interval, tρ, to estimate the load factor on each link.
Let ξ and α represent the unscaled MI and AI parameters
as described in Section 3.3, where all ﬂows have an identical
RTT (= tρ). To handle the case of ﬂows with diﬀerent RTTs,
we set the scaled MI/AI parameters ξs and αs as follows: 1
For MI :
For AI :
ξs ← (1 + ξ)
αs ← α · rtt
tρ
rtt
tρ − 1 ,
.
(6)
(7)
An end-host uses the scaled parameters ξs and αs in (2)
and (3) to adjust the congestion window after each RTT.
The scaling of these parameters emulates the behavior of all
ﬂows having an identical RTT, which is equal to tρ. The
net result is that over any time period, the window increase
under either MI or AI is independent of the ﬂows’ RTTs.
Thus, unlike TCP, VCP ﬂow’s throughput is not aﬀected by
the RTT heterogeneity [44, 53, 16].
Handling MD: MD is an impulse-like operation that is
not aﬀected by the length of the RTT. Hence, the value of
β in (4) needs not to be scaled with the RTT of the ﬂow.
However, to avoid over reaction to the congestion signal, a
ﬂow should perform an MD at most once during an estima-
tion interval tρ. Upon getting the ﬁrst load factor feedback
that signals congestion (i.e., ˆρc
l = (11)2), the sender imme-
diately reduces its congestion window cwnd using MD, and
then freezes the cwnd for a time period of tρ. After this
period, the end-host runs AI for one RTT in order to obtain
the new load factor.
Scaling for fair rate allocation: RTT-based parameter
scaling, as described above, only ensures that the congestion
windows of two ﬂows with diﬀerent RTTs converge to the
same value in steady state. However, this does not guarantee
fairness as the rate of the ﬂow is still inversely proportional
to its RTT, i.e., rate = cwnd/rtt. To achieve fair rate
allocation, we need to add an additional scaling factor to the
AI algorithm. To illustrate why this is the case, consider the
simple AIMD control mechanism applied to two competing
ﬂows where each ﬂow i (= 1, 2) uses a separate AI parameter
αi but a common MD parameter β. At the end of the M -th
tρ
1Equation (6) is the solution for 1 + ξ = (1 + ξs)
rtt where the
right-hand side is the MI amount of a ﬂow with the RTT value
rtt, during a time interval tρ. Similarly, Equation (7) is obtained
by solving 1 + α = 1 + tρ
rtt αs.
Table 1: VCP Parameter Setting
Value
Meaning
Para
tρ
tq
γl
κq
κ
α
β
200 ms
10 ms
0.98
0.5
0.25
1.0
0.875
the link load factor measurement interval
the link queue sampling interval
the link target utilization
how fast to drain the link steady queue
how fast to probe the available bw (MI)