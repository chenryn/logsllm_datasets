### Proceedings of the 2006 IEEE Symposium on Security and Privacy (S&P’06)
**1081-6011/06 $20.00 © 2006 IEEE**
*Authorized licensed use limited to: Tsinghua University. Downloaded on March 19, 2021 at 02:50:34 UTC from IEEE Xplore. Restrictions apply.*

---

### Figure 1: Implications and Separations Between Various Security Notions
The figure below illustrates the relationships and separations between different security notions. We adopt the taxonomy from [32], which includes the concept of (polynomially bounded) general composability, meaning both simple composability and polynomially bounded concurrent composability hold.

| **Security Notion** | **References** |
|---------------------|----------------|
| Perfect Univeral Simulatability | [32, 10, 29] |
| Perfect General Composability | [32, 10, 29] |
| Perfect Standard Simulatability | [32, 10, 29] |
| Statistical Universal Simulatability | [10] / [29] |
| Computational Universal Simulatability | [15] / [29] |
| Statistical General Composability | [32] |
| Computational General Composability | This work / [32] |
| Statistical Standard Simulatability | [32] |
| Computational Standard Simulatability | [32] |
| Perfect Simple Composability | [32] |
| Statistical Simple Composability | [32] |
| Computational Simple Composability | [32] |

The references next to the arrows indicate where the corresponding implications or separations were proven. The results from this paper are indicated by bold arrows.

---

### Machine Activation and Scheduling
In our model, when a machine sends a message, the receiving machine is activated with that message. At the start of a run, a designated machine called the master scheduler is activated. This machine is either the honest user or the adversary. Subsequently, the next machine to be activated is determined by the message sent by the current machine. If the current machine decides not to send a message, the master scheduler is reactivated. The transcript of all communication and internal states of the machines in such a run forms a random variable, which we call the "run." By restricting the run to the internal states and communication of a specific machine H, we obtain the "view" of machine H. We denote this as \( \text{view}_{\hat{M},k}(H) \), where \( k \) is the security parameter. If \( k \) is omitted, it refers to the family of all random variables \( \text{view}_{\hat{M},k}(H) \).

A protocol is a set of machines (e.g., protocol parties, trusted hosts) along with a specification of the connections an honest user can use to communicate with the protocol. This specification is important because it excludes internal communication channels that should not be directly accessible to the honest user. A protocol cannot run independently; it requires an honest user and an adversary to function.

---

### Formal Definition of Security
Given the definitions above, we can now formally define security. Let \( \hat{M}_1 \) and \( \hat{M}_2 \) be protocols. We say that \( \hat{M}_1 \) is as secure as \( \hat{M}_2 \) if for any adversary \( A \) and any honest user \( H \), there exists a simulator \( S \) such that the views \( \text{view}_{H,A,\hat{M}_1}(H) \) and \( \text{view}_{H,S,\hat{M}_2}(H) \) are indistinguishable.

- **Perfect Security**: The views must be identically distributed.
- **Statistical Security**: The statistical distance between the views must be negligible in the security parameter \( k \).
- **Computational Security**: The views must be computationally indistinguishable by polynomial-time algorithms. In this case, only polynomial-time users, adversaries, and simulators are considered.

The order of quantifiers is also significant. In the standard order, the simulator \( S \) can depend on the honest user \( H \). This is referred to as standard simulatability. Another possibility is to choose \( H \) after \( S \), meaning \( H \) can depend on \( S \). In this case, the simulator \( S \) must be universal for all honest users \( H \), leading to universal simulatability. Black-box simulatability requires the existence of an \( S \) that is independent of \( A \) but may use \( A \) as a black box.

---

### Composition
A major advantage of defining security through simulatability is the ability to compose protocols. There are two main types of composability: simple composability and polynomially bounded concurrent composability.

- **Simple Composability**: Consider a large protocol \( \hat{N} \) that uses one instance of another protocol \( \hat{M}_1 \) as a subprotocol. Simple composability means that in any such \( \hat{N} \), any secure realization \( \hat{M}_2 \) of \( \hat{M}_1 \) can substitute \( \hat{M}_1 \) without losing security. More precisely, if \( \hat{M}_2 \) is as secure as \( \hat{M}_1 \), then \( \hat{N} \) using \( \hat{M}_2 \) is as secure as \( \hat{N} \) using \( \hat{M}_1 \). Both standard and universal simulatability have this property.

- **Polynomially Bounded Concurrent Composability**: This extends simple composability to multiple instances of a subprotocol. Specifically, if \( \hat{N} \) uses several instances of \( \hat{M}_1 \), the same property holds. This stronger notion has been used, for example, to modularize the security proof of the general protocol construction for secure function evaluation [21]. Given that simple composition holds, this can be reduced to polynomially bounded concurrent composability, meaning that \( \hat{M}_2^p \) (i.e., \( p \) copies of \( \hat{M}_2 \) run concurrently) is as secure as \( \hat{M}_1^p \) whenever \( \hat{M}_2 \) is as secure as \( \hat{M}_1 \). Typically, \( p \) is restricted to be polynomial in the security parameter.

It is known that universal simulatability already has the feature of polynomially bounded concurrent composability [15, 10]. In this contribution, we investigate whether this also holds for standard simulatability.

To formalize polynomially bounded concurrent composability, we need a definition for the "concurrent composition" \( \hat{M}^p \) of a protocol \( \hat{M} \). Intuitively, when \( \hat{M} \) is a protocol and \( p = p(k) \) is a polynomial in the security parameter, \( \hat{M}^p \) is the protocol where each machine is replaced by \( p \) copies of the original machine. To avoid complicated definitions, instead of \( p \) copies, we introduce a single machine that simulates \( p \) copies, accessed by a session ID preceding each message.

**Definition 2.1 (Polynomially Bounded Concurrent Composability)**: Let \( M \) be a machine and \( p = p(k) \) be a polynomial in the security parameter. Then \( M^p \) simulates \( p \) copies \( M_1, \ldots, M_p \) of \( M \). Upon receiving a message \( (\text{sid}, m) \) with \( 1 \leq \text{sid} \leq p \), \( M^p \) hands \( m \) to \( M_{\text{sid}} \). When a simulated \( M_{\text{sid}} \) sends a message \( m \), then \( M^p \) sends \( (\text{sid}, m) \).

Given this definition, we can now state polynomially bounded concurrent composability: if \( \hat{M}_1 \) is as secure as \( \hat{M}_2 \), then \( \hat{M}_1^p \) should be as secure as \( \hat{M}_2^p \) for any given polynomial \( p \) in the security parameter.

---

### The Computational Case
We consider the case of computational standard simulatability. We provide protocols \( \hat{M}_1 \) and \( \hat{M}_2 \) such that \( \hat{M}_1 \) is as secure as \( \hat{M}_2 \), but the \( k \)-fold concurrent composition \( \hat{M}_1^k \) is not as secure as \( \hat{M}_2^k \).

#### 3.1 Time-lock Puzzles
As a tool for our construction, we use time-lock puzzles [39, 29]. Solving a time-lock puzzle \( t \) of hardness \( s \in \mathbb{N} \) is a strong indication that a machine has performed computational work polynomial in \( s \).

A time-lock puzzle consists of:
- **Puzzle Generation Algorithm \( G \)**: Takes a number \( s \) (the hardness of the puzzle) as input and outputs a puzzle \( q \) and auxiliary information \( a \) for the solution verification algorithm.
- **Solution Verification Algorithm \( V \)**: Takes a supposed solution \( t \) and decides (possibly using the auxiliary information \( a \)) whether the solution is correct.

To ensure that \( s \) represents the hardness of the puzzle \( q \), we require:
- **Hardness Condition**: For any polynomial-time algorithm \( B \), there is a polynomial \( p \) such that \( B \) never solves puzzles of hardness \( \geq p(k) \).
- **Easiness Condition**: For any polynomial \( p \), there is a polynomial-time algorithm \( C \) that solves all puzzles of hardness \( \leq p(k) \).

Time-lock puzzles allow us to perform "contests of computational strength" between polynomial-time machines, as the machine that can solve larger time-lock puzzles is more powerful. This idea has been used in [29] to separate universal and standard simulatability in the computational case and will be useful in constructing our counterexample.

#### 3.2 The General Idea
Our example involves two protocols \( \hat{M}_1 \) and \( \hat{M}_2 \), each consisting of a single machine \( M_1 \) (resp. \( M_2 \)) that participates in a \( k \)-party secure function evaluation (SFE) of a specific function \( f \). Here, \( k \) is the security parameter, so the number of parties increases with larger security parameters. Such a secure \( k \)-party function evaluation is possible under reasonable computational assumptions (e.g., the existence of enhanced trapdoor permutations) using the construction of [26, 23, 24].

The machine \( M_1 \) differs from \( M_2 \) in how it chooses inputs for the function evaluation. Specifically, \( M_1 \) chooses all its inputs, while \( M_2 \) chooses some inputs and lets the simulator \( S \) decide the remaining inputs. The specific choice of \( f \) ensures that a simulator \( S \) fixed after the protocol user \( H \) can deliver inputs to \( M_2 \) such that the function output of \( f \) is the same in the real and ideal models. Using the secrecy property of the function evaluation, this means that \( \hat{M}_1 \) and \( \hat{M}_2 \) are indistinguishable from the point of view of \( H \).

However, when considering \( \hat{M}_1^k \) and \( \hat{M}_2^k \), a suitable protocol user \( H \) can "intermediate" between the function evaluation parties. In the real model, \( H \) forces a secure function evaluation with \( k \) copies of \( M_1 \), and in the ideal model, it forces a secure function evaluation with \( k \) copies of \( M_2 \). Because there are now \( k \) different function evaluation parties giving different inputs in the real and ideal models, the choice of \( f \) ensures that the simulator \( S \) is unable to enforce indistinguishable function outputs.

#### 3.3 The Evaluated Function
The choice of the function \( f \) is crucial. The function \( f \) proceeds in two rounds:
1. **First Round**: Each party \( i = 1, \ldots, k \) provides input \( (b_i, s_i) \) with \( b_i \in \{\text{real, ideal}\} \) and \( s_i \in \mathbb{N} \). Time-lock puzzles \( q_i \) of hardness \( s_i \) are chosen, and the output to party \( i \) is \( q_i \).
2. **Second Round**: Each party \( i \) provides a solution \( t_i \) to the puzzle \( q_i \). The final output \( \text{out} \) of \( f \) is calculated as follows:
   - Sort all \( s_i \) with \( b_i = \text{ideal} \) in ascending order into a list \( s_{i_1}, s_{i_2}, \ldots, s_{i_n} \) such that \( s_{i_j} \leq s_{i_{j+1}} \) for all \( j \).
   - Let \( \text{out} := \text{true} \) if the predicate
     \[
     \forall j = 1, \ldots, n : s_{i_j} \geq 2j \text{ and } t_{i_j} \text{ is a correct solution for } q_{i_j}
     \]
     holds, and let \( \text{out} := \text{false} \) otherwise.

Only the set of values \( (s_i, t_i) \) with \( b_i = \text{ideal} \) is relevant for the output of \( f \). Specifically, \( \text{out} = \text{true} \) implies that a time-lock puzzle with exponential hardness in the number of inputs with \( b_i = \text{ideal} \) has been solved. No polynomial machine can give inputs such that \( b_i = \text{ideal} \) for all \( i \) and achieve \( \text{out} = \text{true} \) with non-negligible probability.

#### 3.4 The Protocols
Using the construction of [26, 23, 24], denote by \( P_1, \ldots, P_k \) the parties that securely evaluate \( f \) in a \( k \)-party function.