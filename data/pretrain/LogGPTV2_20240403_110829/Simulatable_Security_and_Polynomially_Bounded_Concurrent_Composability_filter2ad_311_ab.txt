sages through connections to each other. Whenever a ma-
Proceedings of the 2006 IEEE Symposium on Security and Privacy (S&P’06) 
1081-6011/06 $20.00 © 2006 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 02:50:34 UTC from IEEE Xplore.  Restrictions apply. 
perfect univ.
simulatability
[32, 10, 29]
perfect general
composability
[32, 10, 29]
perfect standard
simulatability
stat. univ.
simulatability
comp. univ.
simulatability
[10]
/
[29]
[15]
/
[29]
stat. general
composability
comp. general
composability
[32]
this work
[32]
/
this work
stat. standard
simulatability
comp. standard
simulatability
[32]
[32]
[32]
perfect simple
composability
stat. simple
composability
comp. simple
composability
Figure 1. Implications and separations between the various security notions. For the presentation
of these relations, we adopt the taxonomy of [32] who additionally has the notion of (polynomi-
ally bounded) general composability, which means that both simple composability and polynomially
bounded concurrent composability hold.
The references next to the arrows indicate where this
was proven. The results from this paper are given by bold arrows.
chine sends a message, the receiving machine is activated
with that message.2
At the start of a run of these machines, a designated ma-
chine called the master scheduler is activated. This machine
is always the honest user or the adversary. Afterwards, the
next machine to be activated is determined by the message
sent by the current machine as described above. If the cur-
rent machine decides not to send a message, the master
scheduler is activated again. The transcript of all commu-
nication and all internal states of the machines in such a
run gives us a random variable which we call simply the
run. By restricting the run to the internal states of and the
communication sent or received by a machine H, we get the
view of the machine H. We write view ˆM,k(H) for the view
of H given security parameter k. The index k can be omit-
ted, then we mean the family consisting of all the random
variables view ˆM,k(H).
A protocol is simply a set of machines (e.g., protocol par-
ties, trusted hosts) together with a speciﬁcation over which
connections an honest user can talk to the protocol. The lat-
ter is important, because there usually are connections that
reﬂect the internal communication of the protocol which
should not be accessible directly by the honest user. A pro-
2In the model of [11] there is additionally the concept of so-called
clock-ports. These allow to model asynchronous communication. We have
opted to omit these clock-ports here and to assume that all messages are
delivered immediately (or sent to the adversary in case of an insecure con-
nection). This greatly simpliﬁes the presentation and does not principally
restrict the expressibility of the model, since asynchronous communica-
tion can also be modelled by introducing functionalities for communica-
tion which deliver messages only upon request by the adversary. However,
all our results can also be stated in the more general setting of [11].
tocol cannot run by itself, it can only run together with an
honest user and an adversary.
Given the above deﬁnitions, we can now state the deﬁ-
nition of security more formally: Let ˆM1 and ˆM2 be pro-
tocols. We say that ˆM1 is as secure as ˆM2 if for any ad-
versary A and any honest user H there is a simulator S
s.t. view H,A, ˆM1
(H) are indistinguish-
able.
(H) and view H,S, ˆM2
The meaning of “indistinguishable” depends on the ex-
act notion of security. For perfect security, the views must
be identically distributed. For statistical security, their sta-
tistical distance must be negligible (in the security param-
eter k). For computational security, they must be compu-
tationally indistinguishable by polynomial-time algorithms;
in that case, also only polynomial-time users and adver-
saries/simulators are considered.
A further interesting point is the order of quantiﬁers. In
the above deﬁnition we have allowed the simulator S to de-
pend on the honest user H. We call this the standard order of
quantiﬁers (because it is the default order in the RS frame-
work) and speak of standard simulatability. Another possi-
bility is to choose H after S, i.e., H may depend on S. Since
in this case the simulator S has to be universal for all honest
users H we speak of universal simulatability. Yet another
possibility black-box simulatability, which demands the ex-
istence of an S that is even independent of A (but may use
A as a black box).
Composition. A major advantage of a security deﬁnition
by simulatability is the possibility of composition. There are
two major ﬂavours of composability, namely simple com-
Proceedings of the 2006 IEEE Symposium on Security and Privacy (S&P’06) 
1081-6011/06 $20.00 © 2006 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 02:50:34 UTC from IEEE Xplore.  Restrictions apply. 
posability and polynomially bounded concurrent compos-
ability . To sketch simple composability, let ˆN ˆM1 be an
arbitrary large protocol that uses (one instance of) another
protocol ˆM1 as subprotocol. Simple composability means
that in any such ˆN ˆM1, any secure realisation ˆM2 of ˆM1 can
substitute ˆM1 without losing security. More precisely, if
ˆM2 is as secure as ˆM1, then ˆN ˆM2 (in which ˆM1 has been
replaced by ˆM2) is as secure as ˆN ˆM1. Both standard and
universal have this property of simple composability. Sim-
ple composition could be used, e.g., to modularise the proof
of protocols for secure message transmission using public-
key [37, 15] or secret-key encryption schemes [38].
A natural extension is to consider substituting multiple
instances of one subprotocol at once. In other words, one
can ask for the same property as above even if ˆN ˆM1 uses
several instances of ˆM1. This stronger notion has been used,
e.g., to modularise the security proof of the general proto-
col construction [21] for secure function evaluation. Given
that simple composition holds, this concept can be reduced
to what is known as polynomially bounded concurrent com-
posability : roughly, this means that ˆM p
2 (i.e., p copies of
ˆM2 run concurrently) is as secure as ˆM p
1 whenever ˆM2 is
as secure as ˆM1. (Commonly, the number p of allowed in-
stances is restricted to be polynomial in the security param-
eter, since this is usually sufﬁcient for many applications—
in particular, for the important class of polynomial-time
protocols—and, in particular for statistical security, often
the best one can hope for.)
As sketched in the introduction, it is known that uni-
versal simulatability already has the feature of polynomi-
ally bounded concurrent composability (cf. [15, 10]).
In
this contribution, we are interested whether this also holds
for standard simulatability. Thus, to express polynomially
bounded concurrent composability formally, we need a def-
inition for the “concurrent composition” ˆM p of a protocol
ˆM.
Intuitively, when ˆM is a protocol and p = p(k) a poly-
nomial in the security parameter, then ˆM p is the protocol
where each machine has been replaced by p copies of the
original machine. To avoid complicated deﬁnitions, instead
of p copies we will introduce a single machine that simu-
lates p copies which are accessed by a session ID that pre-
cedes each message.3
Deﬁnition 2.1 (Polynomially Bounded Concurrent Com-
posability). Let M be a machine and p = p(k) be a polyno-
mial in the security parameter. Then Mp simulates p copies
M1, . . . , Mp of M. Upon receiving a message (sid , m) with
1 ≤ sid ≤ p, Mp hands m to Msid . When a simulated Msid
sends a message m, then Mp sends (sid , m).
3A more general methodology can be found in [10], where
parametrised families of protocols are used to formulate a variable number
of machines. The results given here can also be stated in their formalism.
For a protocol ˆM, the protocol ˆM p consists of all ma-
chines Mp with M ∈ ˆM .
Given this deﬁnition, we can now formulate polynomi-
ally bounded concurrent composability: say that ˆM1 is as
secure as ˆM2. Then ˆM p
2 for any
given polynomial p in the security parameter.
1 should be as secure as ˆM p
3 The Computational Case
Consider the case of computational standard simulatabil-
ity. We give protocols ˆM1 and ˆM2 such that ˆM1 is as secure
as ˆM2, but the k-fold concurrent composition ˆM k
1 is not as
secure as ˆM k
2 . (As usual, k denotes the security parameter.)
3.1 Time-lock puzzles
As a tool for our construction, we need means for a ma-
chine to prove its computational strength. Such a tool is
provided by time-lock puzzles [39, 29]. Intuitively, solving
a time-lock puzzle t of hardness s ∈ is a strong indication
that a machine has done computational work polynomial in
s.
More precisely, a time-lock puzzle consists of a puzzle
generation algorithm G and a solution veriﬁcation algorithm
V. The solution generation algorithm G that takes some
number s (the hardness of the puzzle) as input and then
outputs a puzzle q and some auxiliary information a for the
solution veriﬁcation algorithm. The solution veriﬁcation al-
gorithm V takes an supposed solution t and decides (possi-
bly using the auxiliary information a) whether the solution
is correct.
To ensure that s indeed represents the hardness of the
puzzle q, we require the following two properties for G and
V to represent a system for time-lock puzzles:
• Hardness condition: For any algorithm B that is poly-
nomial in the security parameter k, there is a polyno-
mial p, s.t. the algorithm B never solves puzzles of
hardness ≥ p(k). More concretely, when choosing
s ≥ p(k) and generating a puzzle q of hardness s, the
probability is negligible that B upon input q outputs a
solution t that is accepted by V.
• Easiness condition: For any polynomial p there is
an algorithm C polynomial in the security parame-
ter k, s.t. the algorithm solves all puzzles of hardness
≤ p(k). More concretely, when choosing s ≤ p(k)
and generating a puzzle q of hardness s, the probability
is overwhelming that B upon input q outputs a solution
t that is accepted by V. (Note that in both cases, B and
C do not have access to the auxiliary information a.)
A formal deﬁnition and more details can be found in [29] or
in the full version of this paper.
Proceedings of the 2006 IEEE Symposium on Security and Privacy (S&P’06) 
1081-6011/06 $20.00 © 2006 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 02:50:34 UTC from IEEE Xplore.  Restrictions apply. 
Time-lock puzzles will allow us to perform “contests
of computational strength” between polynomial-time ma-
chines, because whichever machine can solve the larger
time-lock puzzles is the more powerful. This idea of a “con-
test” has already been used in [29] to separate universal and
standard simulatability in the computational case, and will
also be useful to construct our counterexample.
3.2 The General Idea
The idea behind our example is as follows. Both proto-
cols ˆM1 and ˆM2 consist only of one machine M1 (resp. M2)
that expects to take part in a k-party secure function evalu-
ation (SFE) of a speciﬁc function f . Here, k is the security
parameter, so the number of parties actually increases for
larger security parameters. Such a secure k-party function
evaluation is possible under reasonable computational as-
sumptions (namely, the existence of enhanced trapdoor per-
mutations) using the construction of [26, 23, 24]. Since M1
executes the program of only one party of the SFE, all inter-
nal messages of the SFE are sent to and expected from the
honest user H.
The machine M1 differs from M2 only in its way of
choosing the inputs to the function evaluation. More specif-
ically, M1 chooses all of its inputs on its own, whereas M2
chooses only some inputs on its own (in a different way than
M1) and lets the simulator S decide upon the remaining in-
puts. The speciﬁc choice of f ensures that a simulator S that
is ﬁxed after the protocol user H is able to deliver inputs to
M2 such that the function output of f is the same in real
and ideal model. Using the secrecy property of the function
evaluation construction, this means that ˆM1 and ˆM2 are in-
distinguishable from the point of view of H, even though H
sees the internal messages of the SFE.
1 and ˆM k
However, when considering ˆM k
2 , a suitable pro-
tocol user H can simply “intermediate” between the func-
tion evaluation parties (i.e., the k copies of M1, resp. M2).
Thus, in the real model, H forces a secure function evalua-
tion with k copies of M1, and in the ideal model, it forces a
secure function evaluation with k copies of M2. Because
there are now k different function evaluation parties that
give all different inputs in the real, resp. the ideal model, the
choice of f guarantees that now the simulator S is unable
to enforce indistinguishable function outputs in the real,
resp. ideal model.
3.3 The Evaluated Function
Of course, the choice of the function f is crucial, so we
will begin by presenting f . The function f proceeds in two
rounds. In the ﬁrst round, f expects input (bi, si) with bi ∈
{real, ideal}, si ∈
from each party i = 1, . . . , k (we
will call these the ﬁrst inputs). Then time-lock puzzles qi
of hardness si are (independently) chosen, and the output to
party i is qi (we call these the ﬁrst outputs). The information
for checking the solution is stored. In the second round, f
expects a solution ti to the puzzle qi from each party i. The
ﬁnal output out of f (which is the same for all parties) is
then calculated as follows:
1. Sort all si with bi = ideal in order of ascending si
into a list si1 , si2 , . . . , sin such that sij ≤ sij+1 for all
j.
2. Let out := true if the predicate
∀j = 1, . . . , n : sij ≥ 2j and
tij is a correct solution for qij
holds, and let out := false otherwise.
Obviously, only the set of values (si, ti) with bi = ideal
is relevant for the output of f . In particular, out = true
implies that a time-lock puzzle has been solved that has a
hardness that is exponential in the number of inputs with
bi = ideal. Or, put differently, no polynomial machine
can give inputs such that bi = ideal for all i and hope to
achieve an evaluation to out = true with non-negligible
probability.
3.4 The Protocols
Using the construction of [26, 23, 24], denote by
P1, . . . Pk parties that securely evaluate f in a k-party func-