### 5.3 Robotic Attack Results

In this section, we present the results of the robotic attack. To ensure a thorough performance evaluation while avoiding redundancy, we focus on portrait strokes, as landscape strokes did not provide significant new insights. Performance highlights for landscape strokes are provided in Appendix 2.

#### 5.3.1 Rationale Behind the "Failure to Enroll" Policy

For behavioral biometric modalities, some users exhibit such inconsistent biometric footprints that even a zero-effort attack can achieve very high penetration rates. Demonstrating the success of an algorithmic attack against these users is less meaningful than demonstrating it against the most consistent users. Therefore, we implemented a "failure to enroll" policy, enrolling only users with EERs below a certain threshold (denoted as \(\alpha\)) for both classifiers. We evaluated attack performance at \(\alpha\) values ranging from 0.2 to 0.08. An upper bound of \(\alpha = 0.2\) was chosen because users with higher EERs are unlikely to use the technology. The lower bound of \(\alpha = 0.08\) was set because fewer users could enroll at lower \(\alpha\) values.

#### 5.3.2 Mean Impact of the Attack

We computed the mean EER and its standard deviation across the population before and after the robotic impostor attack for different \(\alpha\) values. Figures 5 and 6 summarize these results for horizontal and vertical touch strokes, respectively. The bottom axis shows the different EER thresholds (\(\alpha\)), while the top axis indicates the number of users who could enroll at each \(\alpha\) value.

Before the robotic attack, EERs ranged from 0.13 to 0.035 (see Figures 5 and 6, left side). These EERs are higher than those reported in [17] but comparable to those in [27] when users did not wear digital sensor gloves. With our baseline EERs similar to those in the literature, we proceeded to evaluate the impact of the robotic attack.

Figures 5(b), 5(d), 6(b), and 6(d) show that the attack significantly increased both the mean EERs and their standard deviations for both vertical and horizontal strokes. High mean EERs indicate that users experience very high False Reject Rates (FRRs), while impostors see equally high False Acceptance Rates (FARs). The high variance in EERs implies that system performance becomes highly unreliable and unpredictable due to the attack. Notably, the elevated EERs and standard deviations persist even for the best-performing users (\(\alpha = 0.08\)), suggesting that excluding poor users from enrollment would not effectively mitigate the attack.

Table 2 provides a more precise view of the impact on mean EERs, showing the percentage change in mean system EER for each verification algorithm. Regardless of the verification algorithm or failure-to-enroll threshold, the percentage change in mean EER exceeds 200% in all cases and over 900% in the most extreme case. These results confirm the significant degradation in performance caused by the robotic attack.

#### 5.3.3 Impact of the Attack on Each User

To better understand the dynamics of the mean EER and EER variability, we analyzed the impact of the attack on individual users. Figure 7 summarizes these results for \(\alpha = 0.2\) and \(\alpha = 0.08\), as other \(\alpha\) values did not provide new insights. The analysis reveals two key features:

1. **Negative EER Changes**: Between 20% to 40% of the population experienced negative EER changes (Figures 7(a), 7(c), and 7(d)). For these users, the robotic attack performed worse (i.e., caused lower EERs) than the zero-effort attack. This trend suggests that about 20-40% of users had a touch gesture biometric footprint distinct from the majority.

2. **Extremely High EER Changes**: A proportion of users experienced extremely high EER changes (close to 1). These users likely had touch biometric patterns very similar to the mean behavior across the population.

These features explain the high variance seen in Figures 5(b), 5(d), 6(b), and 6(d), as the combination of users with decrements and increments in EER resulted in overall high variability in EER.

#### Statistical Significance Testing

To rule out the impact of random effects, we used the Wilcoxon signed-rank test [14] to determine the statistical significance of the attack's effect. For example, for the enrollment threshold \(\alpha\), let \(V_{knn1}\) denote the vector of EERs obtained across the population for the k-NN verifier (for horizontal strokes in portrait mode) before the robotic attack, and \(V_{knn2}\) denote the corresponding vector after the attack. The null hypothesis was that the difference in EER before and after the attack was insignificant. The alternative hypothesis was that the EERs under the robotic attack were higher.

For all verifiers, enrollment thresholds, and stroke types, we rejected the null hypothesis at the 5% significance level (see P values in Table 4â€”Appendix 3). Based on these results, we concluded that the attack significantly degraded the performance of the two classification algorithms.

### 6. Conclusions

In this paper, we evaluated the impact of a robotic attack on touch-based authentication. Using the best verification algorithms in the domain, we demonstrated that the attack significantly degrades classification performance. Several aspects of our attack warrant further research. First, our data collection was based on a small number of specialized applications, which may not represent the wide range of applications used in practice. It would be interesting to determine how the attack scales to a larger number of applications.

Another area for investigation is whether touch strokes can be decomposed into features more resilient to such attacks. Our feature set, while capturing key statistical attributes, may not be universally resistant. Determining the resilience of other feature sets to the attack is an important next step.

Despite these factors, our attack highlights a previously unknown threat to touch-based authentication.