impostor attack in this case as the robotic impostor attack
or robotic attack. We used 600 strokes generated by the
robot to carry out this attack against each user. Like we did
in the zero-eﬀort tests (Section 5.2.1), we again generated
four DET curves for each user, and calculated the EER from
each of the curves.
5.3 Robotic Attack Results
In this section we present the attack results.
In order
to make a thorough performance evaluation while avoid-
ing duplication, we focus on the portrait strokes since the
landscape strokes did not provide any major new insights.
We present some performance highlights of the landscape
strokes in Appendix 2.
5.3.1 Rationale Behind Failure to Enroll Policy
For behavioral biometric modalities, there are certain user-
s whose biometric footprint is so inconsistent that even a
zero-eﬀort attack can attain very high penetration rates. To
demonstrate the success of an algorithmic attack against
such users is not as meaningful as, for instance, demonstrat-
ing it against the most consistent users on the system. For
this reason, we employed a “failure to enroll” policy, in which
we only enrolled users whose EERs were less than a certain
EER threshold ((cid:11)) for both classiﬁers. Our attack perfor-
mance evaluation was done at values of (cid:11) ranging from 0.2 to
0.08. We chose an upper bound of (cid:11)=0.2 because we believe
that a user with an EER higher than that would probably
not use the technology anyway. For the lower bound we
decided to use (cid:11)=0.08 because the number of users able to
enroll on the system became too small for values of (cid:11) less
than that.
5.3.2 Mean Impact of the Attack
For diﬀerent values of (cid:11), we computed the mean EER
and standard deviation of the EERs across the population
before and after the robotic impostor attack. Figures 5 and
6 respectively summarize these results for the horizontal and
vertical touch strokes. The bottom (horizontal) axis shows
the diﬀerent EER thresholds ((cid:11)), while the top (horizontal)
axis shows the number of users who were able to enroll onto
the system at each value of (cid:11).
Before the robotic attack was launched we obtained EERs
of between 0.13 and 0.035 (see plots on the left side of Fig-
ures 5 and 6)3. These EERs are higher than the EERs
reported in [17], but comparable to those reported in [27]
during the sub-set of experiments in which the users did not
wear a digital sensor glove. With our baseline EERs (i.e.,
before attack) being comparable to the EERs reported in
the literature, we proceeded to evaluate the impact of the
robotic attack.
Observe (Figures 5(b), 5(d), 6(b), 6(d)) that for both the
vertical and horizontal strokes, the attack drastically in-
creased both the mean EERs and the standard deviation
of the EERs. The high mean EERs indicate that users be-
gin to see very high False Reject Rates (FRRs), while im-
postors see equally high False Acceptance Rates (FARs).
Also, the high variance in EERs implies that system perfor-
5.2.2 Robotic Testing
The robotic testing process was the same as that described
in Section 5.2.1, except that the impostor attack was based
3While our vertical scale for the left side plots makes it hard
to view the EERs precisely, we decided to use it (this scale)
because it eases comparison with the plots to the right (i.e..
the post-attack plots)
606(a) Mean and standard de-
viation of EERs obtained
for the SVM veriﬁer before
the robotic attack.
(b) Mean and standard de-
viation of EERs obtained
for the SVM veriﬁer after
the robotic attack.
(a) Mean and standard de-
viation of EERs obtained
for the SVM veriﬁer before
the robotic attack.
(b) Mean and standard de-
viation of EERs obtained
for the SVM veriﬁer after
the robotic attack.
(c) Mean and standard de-
viation of EERs obtained
for the k-NN veriﬁer before
the robotic attack.
(d) Mean and standard de-
viation of EERs obtained
for the k-NN veriﬁer after
the robotic attack.
(c) Mean and standard de-
viation of EERs obtained
for the k-NN veriﬁer before
the robotic attack.
(d) Mean and standard de-
viation of EERs obtained
for the k-NN veriﬁer after
the robotic attack.
Figure 5:
Impact of the robotic attack on the
horizontal strokes generated in portrait mode. The
error bars indicate one standard deviation from the
mean EER. The bottom axis shows the failure to enroll
thresholds, (cid:11), while the top axis shows the number
of users who are able to enroll for each value of (cid:11).
Figure 6: Impact of the robotic attack on the vertical
strokes generated in portrait mode. The error bars
indicate one standard deviation from the mean EER.
The bottom axis shows the failure to enroll thresholds,
(cid:11), while the top axis shows the number of users who
are able to enroll for each value of (cid:11).
mance becomes very unreliable/unpredictable as a result of
the attack. It is noteworthy that the heightened EERs and
standard deviations persist for both veriﬁcation algorithms
even when the system is used only by the best performing
users (i.e., (cid:11)=0.08). This implies that a defence mechanism
centered around barring the poor users from enrolling onto
the system would not thwart the attack.
Table 2 gives a more precise view of the impact of the
attack on the mean EERs. The table shows the percent-
age change in mean system EER seen by each veriﬁcation
algorithm as a result of the attack. Regardless of the veriﬁ-
cation algorithm or failure to enroll threshold, the percent-
age change in mean EER is beyond 200% in all cases, and
over 900% in the most extreme case. These results conﬁr-
m why the robotic attack would signiﬁcantly degrade the
performance of a touch-based authentication system.
5.3.3 Impact of the Attack on each User
To better explain the dynamics of the mean EER and EER
variability seen in Figures 5 and 6, we studied the impact of
the attack on each user. For this analysis we only present
results for (cid:11)=0.2 and (cid:11)=0.08 since the other values of (cid:11)
did not give us any new insights. Figure 7 summarizes these
results for both veriﬁcation algorithms. The plot reveals two
salient features:
1. There was a proportion of between 20% to 40% of the
population whose EER changes were negative (Figures
7(a), 7(c) and 7(d)). For these kinds of users, the
robotic attack actually performed worse (i.e., caused
lower EERs) than the zero-eﬀort attack. Since our
attack was designed based on data gleaned from the
population, this trend suggests that about 20-40% of
the users had a touch gesture biometric footprint that
was very distinct from that of the majority of the users.
2. There was a proportion of users who had EER changes
that were extremely high (close to 1). These types
of users likely had their touch biometric patterns very
similar to the mean behavior exhibited across the pop-
ulation.
These two features to some extent explain the high vari-
ance seen in Figures 5(b), 5(d), 6(b) and 6(d), since a combi-
nation of users seeing decrements in EER and others seeing
very drastic increments in EER must have resulted into a
population having very high variability in EER overall.
Despite the results presented up to this point already
showing evidence for a highly successful attack, rigorous
performance evaluation calls for statistical signiﬁcance test-
ing to rule out the impact of random eﬀects. We used the
Wilcoxon signed-rank test [14] to determine whether the ef-
fect of the attack was statistically signiﬁcant. For instance,
for the enrollment threshold (cid:11), let Vknn1 denote the vector
of EERs obtained across the population for the k-NN veri-
ﬁer (i.e., for horizontal strokes in portrait mode) before the
robotic attack, and Vknn2 denote the corresponding vector
obtained after the robotic attack. The two vectors are such
0.20.180.160.140.120.10.08−0.100.10.20.30.40.50.60.70.80.9EER Threshold: αMean EER# of Users736963585039350.20.180.160.140.120.10.08−0.100.10.20.30.40.50.60.70.80.9EER Threshold: αMean EER# of Users736963585039350.20.180.160.140.120.10.08−0.100.10.20.30.40.50.60.70.80.9EER Threshold: αMean EER# of Users736963585039350.20.180.160.140.120.10.08−0.100.10.20.30.40.50.60.70.80.9EER Threshold: αMean EER# of Users736963585039350.20.180.160.140.120.10.0800.10.20.30.40.50.60.70.80.91EER Threshold: αMean EER# of Users514741352522150.20.180.160.140.120.10.0800.10.20.30.40.50.60.70.80.91EER Threshold: αMean EER# of Users514741352522150.20.180.160.140.120.10.0800.10.20.30.40.50.60.70.80.91EER Threshold: αMean EER# of Users514741352522150.20.180.160.140.120.10.0800.10.20.30.40.50.60.70.80.91EER Threshold: αMean EER# of Users51474135252215607(cid:11)
0.2
0.18
0.16
0.14
0.12
0.1
0.08
SVM
k-NN
Horizontal Vertical Horizontal Vertical
392%
428%
486%
520%
546%
636%
675%
686%
721%
726%
722%
848%
861%
921%
430%
460%
465%
511%
567%
668%
714%
339%
339%
373%
398%
416%
430%
411%
Table 2: Percentage increment in mean EER due to
the robotic impostor attack on the portrait strokes.
For each stroke type and enrollment threshold (cid:11), the
increment in mean EER is expressed as a percentage
of the mean EER obtained during the zero-eﬀort
attack.
that if the EER located in position j for the vector Vknn1
belongs to the user j, then the EER located in position j for
the vector Vknn2 also belongs to user j. We run the Wilcox-
on signed-rank test on the diﬀerences vector Vknn1 -Vknn2 to
determine whether the attack signiﬁcantly aﬀected the k-
NN veriﬁer’s classiﬁcation performance. For both veriﬁers
and all stroke types and enrollment thresholds, we under-
took a similar process. As was done in [26][15], we zeroed
on this test after ﬁnding that the diﬀerences vectors in all
the scenarios evaluated were far from Gaussian (based on ob-
servations of Q-Q plots and results of Kolmogorov Smirnov
(K-S) normality tests [19]).
Formally, the null hypothesis was that the diﬀerence in
EER before and after the robotic attack was insigniﬁcan-
t. The alternative hypothesis was that the EERs under
the robotic attack were higher. For all veriﬁers, enrollment
thresholds and stroke types, we rejected the null hypothe-
sis at the 5% signiﬁcance level (see highlight of P values in
Table 4—Appendix 3). Based on these results, we conclud-
ed that the attack signiﬁcantly degraded the performance of
the two classiﬁcation algorithms.
6. CONCLUSIONS
In this paper we have evaluated the impact of a robotic
attack against touch-based authentication. Using the best
veriﬁcation algorithms in the domain, we have shown the
attack to signiﬁcantly degrade classiﬁcation performance.
There are several aspects of our attack that might need fur-
ther research. First, like most past studies in this area (e.g.,
see [17], [27]), our data collection was based on a group of
users who used a small number of specialized application-
s (two applications in our case). In practice, people use a
wide range of applications, some of which are designed for
tasks which could prompt “touch signatures” (e.g., with re-
gard to regions of the phone that people touch) that are very
distinct from those seen with the common applications. It
would be interesting to determine how the attack scales to
a large number of applications.
Another area worthy of investigation is whether a touch
stroke could be decomposed into a set of features that are
more resilient to this kind of attack than our features. Be-
cause touch-based authentication does not yet have a stan-
dard set of features universally used by all researchers, we
deﬁned a set of 28 features that captured the key statistical
(a) SVM performance with
the horizontal strokes.
(b) SVM performance with
the vertical strokes.
(c) k-NN performance with
the horizontal strokes.
(d) k-NN performance with
the vertical strokes.
Figure 7: Impact of the attack on each user’s por-
trait strokes. For each user, we subtracted the EER
seen under the zero-eﬀort attack from that seen un-
der the robotic attack and then plotted the CDFs of
these changes in EER for each of the two extreme
failure-to-enroll thresholds.
attributes exhibited along a stroke. The underlying philos-
ophy behind our feature deﬁnitions is not so diﬀerent from
that of the features used in past work (e.g., see [17][16]),
however, this does not guarantee that all feature-sets will
succumb to the attack in exactly the same way. It is thus
interesting to determine how much less or how much more
the other features are aﬀected by the attack.
The above factors notwithstanding, our attack highlight-
s a previously unknown threat to touch-based authentica-