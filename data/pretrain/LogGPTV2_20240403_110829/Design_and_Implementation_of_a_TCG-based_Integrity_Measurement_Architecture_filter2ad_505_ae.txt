this SHA1 ﬁngerprint is already in the measurement list using
the SHA1-keyed hash table over all existing measurements.
If it is known, then we return form the measure call.
If
not, then we extract the module name from its ELF headers,
which are located at the beginning of the memory area, add
the measurement as a new measurement to the measurement
list, and ﬁnally extend the TPM register to reﬂect the updated
measurement list. Kernel modules must always be measured
because we do not have any information easily available to
indicate a dirty ﬂag state. However, there are usually only a
few kernel modules loaded. Alternatively, the user level ap-
plications insmod and modprobe can measure the ﬁles when
loading kernel modules into memory. In this case, their mea-
surement follows the ﬁle measurement procedures described
before.
5.3 Measurement Bypass-Protection
Whenever we encounter a situation in which our measure-
ment architecture cannot provide correct measurements or is
potentially being bypassed, we invalidate the TPM aggregate
by extending it with random values without extending the
measurement list and deleting the random value to protect
it from later use. Thus, from this time on, validations of the
aggregate will fail against the measurement list. We do not in-
terfere with the system (non-intrusive) but we disable such a
system from successful attestation until it reboots. In our ex-
periments, none of these mechanisms was triggered through-
out normal system usage but only by malicious or very un-
usual behavior.
Although we assume there are no hardware attacks against
the TPM, we design the system such that a compromised
system cannot change the measurement list undetected be-
cause it cannot manipulate the TPM successfully to cover
such attacks in software. Thus, supporting our architecture
with TPM hardware is useful and necessary even in the (as-
sumed) absence of physical attacks in order to discover cheat-
ing systems. However, anybody with root identity could try to
change the system through less known interfaces in a way that
circumvents our measurement hooks and thus breaks the mea-
surements’ validity. Therefore, we implemented some fail-
safe mechanisms that catch such efforts and invalidate (pes-
simistically) the TPM aggregate. We discuss some of them
below.
Time-of-measurement Time-of-use race conditions: File
contents could theoretically be changed between the time
they are measured and the time they are actually loaded.
Linux does protect memory-mapped ﬁles, but not ﬁles that
are normally loaded (e.g., script ﬁles, conﬁguration ﬁles).
Therefore, we have implemented a counter measure count
in the inode of a measured ﬁle that keeps track of the num-
ber of open ﬁle descriptors pointing to this inode on which
a measure call was induced. We increase the counter be-
fore calling the measure call (in the sysfs write implemen-
tation of the /sys/security/measure node) and de-
crease the counter when a ﬁle descriptor that was measured
is closed (using the file_free_security LSM hook).
We add a check into the inode_permission LSM hook
that catches requests for write or append permission on ﬁles
whose related inode has a measure count > 0. In this case,
we invalidate the TPM aggregate because the measurements
might not reﬂect the ﬁle contents that were actually loaded,
but we choose not to interfere with the request. We assume
any such behavior is malicious.
Bypassing user-level measurements.
To ensure that
measure requests issued by applications actually result in
measurements in the kernel, we must ensure that
the
/sys/security/measure node is actually the one that
issues measurements on write. The only way to circumvent
this without leaving a suspicious ﬁngerprint in the measure-
ment list is to prevent the system from mounting the sysfs ﬁle
system in the ﬁrst place or to unmount it after it is mounted
by using unsuspicious programs (commands). We prevent the
ﬁrst by ensuring that the sysfs is mounted before init is started
(in the kernel startup) and the second by keeping the sysfs in
a busy state (lock it) so it can’t be unmounted by root.
Bypassing dirty ﬂagging. Processes running as root could
try to circumvent dirty-ﬂagging and thus change ﬁle con-
tent between measurement and loading or try to change –
otherwise non-vulnerable and thus trusted– applications or
the kernel in memory by accessing the special storage con-
trol interfaces (e.g. /dev/hda) or the memory interface
/dev/kmem. We catch such special cases and invalidate the
TPM aggregate as described above. This is necessary to pre-
vent the kernel from being changed without this change being
measured. Such suspicious cases are rarely necessary or ob-
served in normal systems.
Unmounting ﬁle systems. We dirty-ﬂag any measurement
that belongs to a ﬁle system that is being unmounted because
we don’t have control over changes on this ﬁle system any
longer. Hot-pluggable hard-drives could be changed and re-
inserted with changed ﬁles. For this purpose, we keep the su-
perblock pointer of a ﬁle in the ﬁle’s measurement structure.
Walking through the whole measurement list to dirty-ﬂag en-
tries related to the mount point imposes overhead, but this
happens rarely (e.g., on shutdown) on most correctly setup
and conﬁgured systems and the measurement lists are usually
not very large (<<1000 entries).
Run-time Errors among the measurement functions.
In
case of any error throughout the recording of measurements,
e.g., caused by out-of-memory errors when allocating a new
measurement structure or other unexpected events preventing
us from measuring correctly, we invalidate the TPM aggre-
gate.
In summary, the measurement functions use the pseudo
ﬁle system sysfs, the kernel LSM hook file_mmap, and
an inserted measure call in the load_module kernel rou-
tine to instrument the system with measurement points. We
use the LSM hooks inode_permission, sb_umount,
inode_free_security, and file_free_security
to implement the dirty ﬂagging and to protect against ToM-
ToU race conditions (usually malicious). We use LSM secu-
rity substructures in the file and inode kernel structures to
store state information, such as dirty ﬂag and measure count.
5.4 Validating Measurements
Our architecture uses the TPM’s protected storage to protect
the integrity of the measurement list. Once a measurement is
taken, it cannot be changed or deleted without causing the ag-
gregate hash of the measurement list to differ from the TPM
aggregate. However, the challenging party must also ensure
that the attesting system has the measurement architecture
correctly in place so that all necessary measurements are ac-
tually initiated and carried out. As our architectural compo-
nents are measured as well when they are executed, challeng-
ing parties can determine whether the architecture is in place
by inspecting these measurements.
The major portion of the measurement architecture is in
the static kernel. Thus, the challenging party trusts only such
kernels that implement the kernel part of our measurement ar-
chitecture. Other kernels will be unacceptable to challenging
parties because they can skip important measurements.
If instrumented insmod and modprobe programs measure
kernel modules before they are loaded into the kernel, then
only kernel module loaders instrumented with the measure
call are acceptable. If a ﬁngerprint of any other program with
insmod functionality is seen, then it must not be trusted and
thus the validation fails. This does not apply in our case be-
cause we measure kernel modules in the kernel. If we require
shell programs to measure script and source ﬁles before they
are loaded or executed, then discovering a ﬁngerprint of a
shell that is not instrumented with measure calls must not be
trusted. Known ﬁngerprints of any other part of the system
can be trusted according to known vulnerabilities of corre-
sponding executables as described in Section 4.4. Unknown
ﬁngerprints could result from changed user level programs
that are assumed to measure their input (e.g., bash), or unac-
ceptable input ﬁles and cannot be trusted as their correspond-
ing program’s functionality is potentially malicious and might
violate security assumptions.
6 Results
6.1 Experiments
To test our system’s ability to detect possible attacks, we
construct a small experiment using lrk5, a popular Linux
rootkit. We start with a perfectly good target system and take
measurements of this system. Then, we launch a rootkit at-
tack against the target system and take measurements again
after the attack. Figure 4(a) shows a (partial) list of mea-
surements for the good system, and Figure 4(b) shows the
corresponding list of the same system that is compromised
by a rootkit. The italicized entries show that after the attack,
the signature of the syslogd program is different, indicat-
ing that the rootkit had replaced the original syslogd with
a Trojan version. This example illustrates how such attacks
can be discovered reliably using our system.
6.2 Performance Evaluation
examine
the performance of measure
in-
We
(i) the kernel file_mmap LSM hook,
voked through:
and (iii)
(ii)
user space applications writing measure requests into
/sys/security/measure.
the kernel load_module function,
calls
#000: D6DC07881A7EFD58EB8E9184CCA723AF4212D3DB boot_aggregate
#001: CD554B285123353BDA1794D9ABA48D69B2F74D73 linuxrc
#002: 9F860256709F1CD35037563DCDF798054F878705 nash
#003: 84ABD2960414CA4A448E0D2C9364B4E1725BDA4F init
#004: 194D956F288B36FB46E46A124E59D466DE7C73B6 ld-2.3.2.so
#005: 7DF33561E2A467A87CDD4BB8F68880517D3CAECB libc-2.3.2.so
...
#110: F969BD9D27C2CC16BC668374A9FBA9D35B3E1AA2 syslogd
...
(a)
...
#110: F969BD9D27C2CC16BC668374A9FBA9D35B3E1AA2 syslogd
...
#525: 4CA3918834E48694187F5A4DAB4EECD540AA8EA2 syslogd
...
(b)
Figure 4: Detecting a Rootkit Attack.
We ﬁrst examine the overhead of the file_mmap LSM
security hook, which measures all executable content and dy-
namic libraries. This is by far the most frequently called
and most performance-sensitive measure hook. To deter-
mine the latencies of the file_mmap LSM measurement
hook, we measure the latencies of the mmap system call from
user level, which calls this file_mmap LSM hook. Our la-
tency measurement (including both mapping and unmapping)
considers three different cases, namely no_SHA1, SHA1,
and SHA1+extend. no_SHA1 represents the case when
file_mmap ﬁnds the target in the cache as clean. In the very
rarely observed SHA1 case, the target ﬁle is remeasured and
the SHA1 ﬁngerprint is recalculated. However, the TPM is
not extended because the ﬁngerprint is found to be already in
the cache. SHA1+extend represents the case when a brand
new ﬁle is measured and the resulting ﬁngerprint needs to
be extended into the TPM chip. This happens more often at
system start or after system updates, for example. Since the
goal is to measure the latency, we use a test ﬁle size of 2
bytes. Implementation of the micro-benchmarks is based on
the HBench framework [16]. Table 1 shows the results.
mmap type
no SHA1
SHA1
SHA1+extend
reference
mmap latency (stdev)
1.73 µs (0.0)
4.21 µs (0.0)
5430 µs (1.3)
1.65 µs (0.0)
ﬁle mmap LSM
0.08 µs
2.56 µs
5430 µs
n/a
Table 1: Latency of the ﬁle mmap LSM hook (ﬁle size 2
bytes).
For reference purposes, we include the running time of an
mmap system call without invoking the file_mmap LSM
measurement hook. It is clear from the table that the over-
head for the file_mmap LSM hook in the case of a clean
cache hit (no_SHA1) is minimal - it takes 0.08 (1.73 - 1.65)
µs to run. It does little more than reading the dirty-ﬂag infor-
mation from the inode of the ﬁle to be mapped. Fortunately,
our experiences indicate that this is the majority case, even
for servers that tend to run for a long time, accounting for
more than 99.9% of all measure calls.
When the ﬁle is remeasured (SHA1), the mmap system call
takes about 4.21 µs, an overhead of about 2.5 µs against the
reference value. This case shows the overhead of setting up
the ﬁle for measurement and searching the hash table for a
matching ﬁngerprint. Notice that this case does not measure
the overhead of the ﬁngerprinting itself, since the ﬁle size is
only 2 bytes. Fingerprinting performance will be discussed
later. The extend operation is clearly the most expensive,
taking about 5 milliseconds to execute. This is understand-
able, because the extend operation interacts with the TPM
chip as well as creates a new measurement list entry. As
mentioned before, these two cases together represent less than
0.1% of all measure calls. Thus, we are conﬁdent –and our
experiences conﬁrm– that the performance penalty our sys-
tem imposes for measuring executable upon the user will be
negligible.
Invoking
(i)
com-
prises
/sys/security/measure,
(ii) writing the measure
closing
/sys/security/measure. This method applies to mea-
suring conﬁguration ﬁles or interpreted script ﬁles (e.g., bash
scripts or source ﬁles). As with the file_mmap LSM hook,
we distinguish also here the three cases no_SHA1, SHA1,
and SHA1+extend. The results are shown in Table 2. The
from user-level
request,
and (iii)
a measurement
opening
Measurements via sysfs
measure