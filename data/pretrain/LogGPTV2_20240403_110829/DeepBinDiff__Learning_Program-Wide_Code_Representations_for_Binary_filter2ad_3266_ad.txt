0.311
0.666
0.975
0.391
0.703
0.949
0.391
0.672
0.946
0.305
0.679
0.915
0.292
0.602
0.956
0.65
0.421
0.833
0.981
0.379
0.825
0.939
0.355
0.761
0.933
0.373
0.871
0.962
0.719
0.314
0.791
0.981
0.295
0.83
0.945
0.292
0.761
0.957
0.685
BinDiff
0.291
0.638
0.944
0.262
0.646
0.947
0.331
0.674
0.942
0.334
0.677
0.942
0.285
0.620
0.954
0.632
0.454
0.713
0.953
0.251
0.655
0.966
0.271
0.708
0.953
0.247
0.815
0.964
0.663
0.225
0.768
0.968
0.133
0.731
0.964
0.132
0.633
0.932
0.609
ASM2VEC+k-HOP
0.211
0.544
0.859
0.235
0.563
0.851
0.291
0.599
0.861
0.291
0.612
0.828
0.275
0.493
0.843
0.557
0.392
0.751
0.939
0.217
0.652
0.921
0.233
0.681
0.941
0.215
0.817
0.925
0.64
0.211
0.621
0.936
0.135
0.692
0.952
0.172
0.727
0.914
0.596
Precision
DEEPBINDIFF-CTX
0.235
0.515
0.813
0.218
0.579
0.852
0.277
0.633
0.855
0.287
0.621
0.833
0.261
0.471
0.853
0.553
0.381
0.765
0.927
0.239
0.641
0.936
0.249
0.697
0.956
0.227
0.831
0.921
0.648
0.207
0.633
0.927
0.145
0.678
0.961
0.185
0.705
0.921
0.598
DEEPBINDIFF
0.315
0.681
0.955
0.301
0.709
0.953
0.40
0.761
0.941
0.351
0.721
0.912
0.315
0.665
0.908
0.659
0.575
0.831
0.971
0.314
0.771
0.967
0.336
0.715
0.967
0.292
0.861
0.949
0.712
0.249
0.787
0.985
0.242
0.885
0.962
0.315
0.806
0.957
0.688
be able to extract more useful contextual information from the
ICFG. To evaluate this, we use all the O1 and O3 binaries in
our dataset to perform difﬁng, and record the results.
Figure 7 shows the relationship between binary size and
accuracy. As shown in the ﬁgure, DEEPBINDIFF can perform
quite stably regardless of the binary size. For example, DEEP-
BINDIFF can achieve an average F1-score of 0.7 for binaries
with sizes of 60KB, and it can still achieve an average score
of 0.65 for binaries that are larger than 400KB.
D. Parameter Selection
Parameter selection, which contains hyperparameters in
embedding generation and parameters in k-hop greedy match-
ing, is of great importance to the effectiveness of our system.
Hyperparameters such as the number of latent dimensions,
the number of walks started per vertex, and the harmonic
factor λ have been extensively discussed in DeepWalk [48]
and TADW [56]. Therefore, we simply use the default values.
For k-hop greedy matching, we need to tune two important
parameters: the number of hops k and the threshold t for
ﬁltering matched pairs in F indM axU nmatched(). In par-
ticular, we choose different values for these parameters and
use DEEPBINDIFF to perform binary difﬁng for 95 binaries
in CoreUtils version 6.4 and version 8.30 to understand the
impact.
Number of Hops. To see how the effectiveness of DEEPBIN-
DIFF can be affected by the number of hops during matching,
(a) k selection
(b) threshold selection
Fig. 8: Parameter Selection
we choose k to be 2, 3, 4 and 5 (with a ﬁxed threshold=0.6),
and check the matching results respectively. The F1-score
CDF is displayed in Figure 8a. Results show that the average
F1-score steadily increases when a bigger k is chosen, and
becomes the highest when k=4. This means that when we
enlarge the search space up to 4 hops for matching basic block
pairs, the chance of ﬁnding the right match increases. However,
if we try to search within very large space (too many hops),
DEEPBINDIFF may incorrectly match unrelated but somehow
similar basic blocks. Also, more runtime overhead can be
introduced.
Threshold. We then evaluate how threshold, which is to
guarantee that every pair of matching blocks should be similar
enough to certain degree, could affect the matching results. It
10
0.00.20.40.60.81.0F1-score0.00.20.40.60.81.0Percentagek=2k=3k=4k=50.00.20.40.60.81.0F1-Score0.00.20.40.60.81.0Percentagethreshold=0.4threshold=0.5threshold=0.6threshold=0.7is distinctly useful when dealing with basic block deletions as
it ensures that DEEPBINDIFF will not match two basic blocks
that are dissimilar but share the same context. Figure 8b illus-
trates the F1-score CDF when choosing different threshold.
More speciﬁcally, we set threshold to be 0.4, 0.5, 0.6 and
0.7 (with a ﬁxed k=4). As we can observe, the average F1-
score reaches the highest when threshold=0.6, but starts to
decline when choosing 0.7. This indicates that there exist some
matched basic block pairs that are transformed by compilers
and become less similar to each other. DEEPBINDIFF is able
to tolerate these cases by selecting a proper threshold.
E. Efﬁciency
We then evaluate the efﬁciency of DEEPBINDIFF, which
training time, preprocessing time,
can be split
embedding generation time and matching time.
into four:
Training Time. Training is a one-time effort. We train our
token embedding generation model with the binaries in our
dataset. We stop the training for each binary when loss
converges or it hits 10000 steps. In total, It takes about 16
hours to ﬁnish the whole training process. ASM2VEC+k-HOP
also needs to train its model, while BinDiff does not need
any training time. Note that the training process could be
signiﬁcantly accelerated if GPUs are used.
Preprocessing Time. DEEPBINDIFF takes only an average of
8.2s to ﬁnish the graph generation on one binary using IDA
pro. Then, it applies the pre-trained model to generate token
embeddings and calculates the feature vectors for each basic
block. These two steps take less than 100ms for one binary.
Embedding Generation. The most heavy part of DEEPBIN-
DIFF is the embedding generation, which utilizes TADW to
factorize a matrix. On average, it takes 591s to ﬁnish one
binary difﬁng. One way to accelerate the process is to use
a more efﬁcient algorithm instead of the ALS algorithm used
in TADW. For example, CCD++ [57] is demonstrated to be 40
times faster than ALS.
Matching Time. k-hop greedy matching algorithm is efﬁcient
in that it limits the search space by searching only within the
k-hop neighbors for the two matched basic blocks. On average,
it takes about 42s to ﬁnish the matching on average.
Binary Size vs. Runtime. The runtime overhead of DEEP-
BINDIFF has a high positive correlation to binary size. This
is due the to fact that the two most time-consuming steps in
DEEPBINDIFF, namely embedding generation and matching,
are all directly bounded by the sizes of the ICFG, which are
largely decided by the binary sizes.
Figure 9 delineates how the binary size can affect the
runtime overhead in DEEPBINDIFF. As we can see,
the
relationship between binary size and runtime overhead is
somewhat linear. For example, it takes less than 100s for
difﬁng two binaries with sizes around 60kb. And for binaries
with sizes of 400kb, DEEPBINDIFF needs about 1000s to
ﬁnish. Therefore, considering the linear relationship, we can
draw a conclusion that DEEPBINDIFF scales reasonably well
with respect to the runtime overhead. Note that the embedding
generation component, which is responsible for the majority
11
Fig. 9: Binary Size vs. Runtime
of runtime overhead, can be signiﬁcantly accelerated if GPUs
are used.
F. Comparison with INNEREYE+k-HOP
InnerEye [58] is a recent research work that also leverages
deep learning technique to perform binary code similarity
comparison. To evaluate the performance improvement of
DEEPBINDIFF, we compare our system with INNEREYE+k-
HOP, which is an InnerEye variant that incorporates k-hop
greedy matching algorithm for optimal basic block matching.
We directly leverage the instruction embedding model and
similarity calculation model provided by InnerEye authors [7].
As discussed in Section I, InnerEye has serious scalability
issues for whole program binary difﬁng. Hence, we only select
10 small binaries listed in Table III for testing.
More speciﬁcally, we use the tools to perform both cross-
version and cross-optimization-level difﬁng for the selected
binaries. The results show that DEEPBINDIFF can outperform
INNEREYE+k-HOP in all settings for both recall and precision.
For example, our system can achieve an average recall rate of
0.553 for cross-version difﬁng, while INNEREYE+k-HOP can
only reach an average recall rate of 0.384. We further compare
the two tools from an efﬁciency perspective. On average, it
takes INNEREYE+k-HOP 1953 seconds to ﬁnish one binary
difﬁng, whereas DEEPBINDIFF only needs an average time of
62 seconds to ﬁnish the difﬁng.
We carefully investigate the results and observe two major
reasons. First, as mentioned in Section I, INNEREYE+k-HOP
suffers from a serious out-of-vocabulary (OOV) problem. In
our experiment, it can only model 85.15% of the instructions
correctly, and will simply assign 0 to the embeddings of the
unmodeled instructions. Therefore, semantic information of a
large number of instructions is missing. Second, the pre-trained
model provided by the authors is trained speciﬁcally to handle
similarity detection between X86 and ARM basic blocks. It is
not suitable to perform cross-version and cross-optimization-
level binary difﬁng.
In a nutshell, the scalability issue and OOV problem render
InnerEye unsuitable for common binary difﬁng scenarios. The
usage of supervised learning also makes it hard to have
balanced and representative dataset and generate a well-trained
model for different test settings.
G. C++ Programs Testing
As aforementioned, DEEPBINDIFF relies on IDA Pro for
inter-procedural CFG generation. However, C++ programs
020040060080010001200618886604068272755207912081360832728552887568921929588098784104168107920112528120344133040140752148048164192175640188448205720216656267552346008405184Runtime (seconds)Binary Size (bytes)TABLE III: Effectiveness Comparison with INNEREYE+k-HOP
Cross-version (Coreutils v5.93 - v.830)
Cross-optimization-level (Coreutils v5.93O1 - v5.93O3)
Recall
INNEREYE+k-HOP
Precision
INNEREYE+k-HOP
Recall
INNEREYE+k-HOP
Precision
INNEREYE+k-HOP
env
false
hostid
printenv
rmdir
sync
true
tty
uname
yes
Average
0.360
0.397
0.371
0.405
0.398
0.348
0.412
0.316
0.471
0.377
0.384
DEEPBINDIFF
0.479
0.477
0.533
0.443
0.675
0.499
0.829
0.605
0.497
0.616
0.553