additively or decreases it multiplicatively, depending on the partic-
ular mon feedback it receives (§ 4.3.4). We use AIMD to control
the rate limit because it has long been shown to converge onto ef-
ﬁciency and fairness [11]. Other design choices exist; they have
different cost-performance tradeoffs, and are discussed in [28].
When no attack is detected, a downstream router will not modify
the nop feedback stamped by an access router. When the sender
obtains the nop feedback and presents it back to its access router
in a packet, the packet will not be rate-limited. That is, when no
attack happens, NetFence stays in idle state. The overhead during
such idle periods is low, because 1) the NetFence header is short
(20 bytes) (§ 6.1); 2) the bottleneck attack detection mechanism
only involves a packet counter and a queue sampler; and 3) an ac-
cess router only needs to stamp and validate (not rate limit) the
NetFence header for each packet. Only when an attack is detected
at a bottleneck link, does NetFence activate its policing functions,
which add additional processing overhead at bottleneck and access
routers. We show the overhead benchmarking results in § 6.2.
3.2 Unforgeable Congestion Policing Feedback
Congestion policing feedback must be made unforgeable so that
malicious nodes cannot evade NetFence’s trafﬁc policing functions.
NetFence achieves this goal using efﬁcient symmetric key cryptog-
raphy. An access router inserts a periodically changing secret in a
packet’s NetFence header. A bottleneck router uses this secret to
protect its congestion policing feedback, and then erases the secret.
The access router, knowing the secret, can validate the returned
feedback. We describe the details of this design in § 4.4, and dis-
cuss how to limit the effect of compromised access routers in § 4.5.
3.3 Congestion Feedback as Capability
If a DoS victim can identify and desires to bar attack trafﬁc, Net-
Fence’s unspoofable congestion policing feedback also serves as a
capability token: a receiver can return no feedback to a malicious
sender. Because the malicious sender cannot forge valid feedback,
it cannot send valid regular packets. It can at most ﬂood request
packets to a destination, but an access router will use a priority-
based policing scheme to strictly limit a sender’s request trafﬁc rate
(§ 4.2). Alternatively, it can simply ﬂood to congest its local area
network, but this attack is easy to detect and the damage is conﬁned
to the local area network.
3.4 Fair Share Guarantee
With the above-described closed-loop network architecture, we
are able to prove that NetFence achieves per-sender fairness for
single bottleneck scenarios.
Theorem: Given G legitimate and B malicious senders sharing
a bottleneck link of capacity C, regardless of the attack strategies,
any legitimate sender g with sufﬁcient demand eventually obtains a
νg ρ C
G+B , where 0 < νg ≤ 1 is a parameter deter-
capacity fair share
mined by how efﬁcient the sender g’s transport protocol (e.g., TCP)
utilizes the rate limit allocated to it, and ρ is a parameter close to
1, determined by NetFence’s implementation-dependent AIMD and
attack detection parameters.
Due to lack of space, we brieﬂy describe why this theorem holds,
but leave a detailed proof in the technical report [28].
Proof sketch: In NetFence, an access router keeps one rate lim-
iter for each sender-bottleneck pair when a monitoring cycle is
triggered during attack times. Based on the unspoofable conges-
tion feedback from the bottleneck, the access router dynamically
adjusts the rate limits using a robust AIMD algorithm (§ 4.3.4).
Since AIMD has been shown to converge onto efﬁciency and fair-
ness [11], all the rate limits will eventually converge to the fair
share of the bottleneck capacity. Thus, any sender, whether legiti-
mate or malicious, can send at most as fast as its fair share rate.
4. DESIGN DETAILS
In this section, we show the design details of NetFence. For
clarity, we ﬁrst present the design assuming unforgeable congestion
257policing feedback and non-compromised routers. We then describe
how to make congestion policing feedback unforgeable and how to
handle compromised routers. Key notations used to describe the
design are summarized in Figure 3.
4.1 Congestion Policing Feedback
NetFence uses three types of congestion policing feedback:
• nop, indicating no policing action is needed;
• L↓, indicating the link L is overloaded, and an access router
should reduce the trafﬁc traversing L;
• L↑, indicating the link L is underloaded, and an access router
can allow more trafﬁc traversing L.
We refer to L↑ and L↓ as the mon feedback. Each congestion
policing feedback includes a timestamp to indicate its freshness.
4.2 Protecting the Request Channel
Attackers may simply ﬂood request packets to congest down-
stream links. NetFence mitigates this attack with two mechanisms.
First, it limits the request channel on any link to a small fraction
(5%) of the link’s capacity, as in [48, 35]. This prevents request
packets from starving regular packets. Second, it combines packet
prioritization and priority-based rate limiting to ensure that a legit-
imate sender can always successfully transmit a request packet if it
waits long enough to send the packet with high priority. This mech-
anism ensures that a legitimate user can obtain the valid congestion
policing feedback needed for sending regular packets.
In NetFence, a sender can assign different priority levels to its
request packets. Routers forward a level-k packet with higher pri-
ority than lower-level packets, but the sender is limited to send
level-k packets at half of the rate of level-(k-1) packets. An ac-
cess router installs per-sender token-based rate limiters to impose
this rate limit. It removes 2k−1 tokens from a request packet rate
limiter when admitting a level-k packet. Level-0 packets are not
rate-limited, but they have the lowest priority.
This request channel policing algorithm guarantees that a legiti-
mate sender can eventually send a request packet to a receiver re-
gardless of the number of attackers [35]. It holds because the ar-
rival rate of request packets decreases exponentially as their priority
level increases. Thus, the arrival rate of high priority request pack-
ets will eventually be smaller than the request channel capacity.
NetFence does not use computational puzzles as in [35]. This is
because computational resources may be scarce [13], especially in
busy servers and handheld devices. In addition, NetFence’s design
has the ﬂexibility that an access router can conﬁgure different token
reﬁll rates for different hosts on its subnet. Legitimate servers could
be given a higher rate to send more high priority request packets
without purchasing additional CPU power.
When an access router forwards a request packet to the next hop,
it stamps the nop feedback into the packet, ensuring that a sender
can obtain valid feedback if the receiver desires to receive from it.
4.3 Protecting the Regular Channel
Malicious senders may ﬂood regular packets when they can ob-
tain valid congestion policing feedback from their colluding re-
ceivers. We describe how to mitigate this attack.
4.3.1 A Monitoring Cycle
When a router suspects that its outgoing link L is under attack,
it starts a monitoring cycle for L. That is, it marks L as in the
mon state and starts updating the congestion policing feedback in
packets that traverse L (§ 4.3.2). Once a sender’s access router
receives such feedback, it will start rate limiting the sender’s regular
packets that will traverse the link L (§ 4.3.3).
Name Value
1 ms
l1
Ilim 2 s
w 4 s
∆ 12 kbps
δ
pth
0.1
2%
Meaning
level-1 request packet rate limit
Rate limiter ctrl interval length
Feedback expiration time
Rate limiter additive incr
Rate limiter multiplicative decr
Packet loss rate threshold
Qlim 0.2s × link bw Max queue length
minthresh
maxthresh
wq
0.5 Qlim
0.75 Qlim
0.1
RED algorithm parameter
RED algorithm parameter
EWMA weight for avg queue length
Figure 3: Key parameters and their values in our implementation.
It is difﬁcult to detect if L is under an attack because the at-
tack trafﬁc may be indistinguishable from legitimate trafﬁc. In Net-
Fence, L’s router infers an attack based on L’s utilization and the
loss rate of regular packets. If L is well-provisioned and its normal
utilization is low (a common case in practice), it can be consid-
ered as under an attack when its average utilization becomes high
(e.g., 95%); if L always operates at or near full capacity, its router
can infer an attack when the regular packets’ average loss rate p
exceeds a threshold pth. A link’s average utilization and p can be
calculated using the standard Exponentially Weighted Moving Av-
erage (EWMA) algorithm [18]. The threshold pth is a local policy
decision of L’s router, but it should be sufﬁciently small so that
loss-sensitive protocols such as TCP can function well when no at-
tack is detected. Attackers may launch a mild attack and evade the
detection by keeping p below pth, but the damage is also limited.
When the attack detection is based on the packet loss rate p, a
ﬂash crowd may also be considered as an attack. We do not distin-
guish these two because it is too difﬁcult to do so. As shown by our
simulation results (§ 6), starting a monitoring cycle for a link does
not have much negative impact on a legitimate sender.
It is undesirable to inﬁnitely keep a monitoring cycle due to the
added overhead. Thus, a NetFence router terminates a link L’s
monitoring cycle when L is no longer under attack (e.g., p < pth)
for a sufﬁciently long period of time Tb. The router will mark L as
in the nop state and stop updating the congestion policing feedback
in packets traversing L. Similarly, an access router will terminate
a rate limiter (src, L) if it has not received any packet with the L↓
feedback and the rate limiter has not discarded any packet for Ta
seconds.
Routers should set Ta and Tb to be signiﬁcantly longer (e.g., a
few hours) than the time it takes to detect an attack (Td). This is
because attackers may ﬂood the network again after Ta (or Tb) sec-
onds. By increasing the ratio of the monitored period min(Ta, Tb)
to the unprotected period Td, we reduce the network disruption
time. Network disruption during an attack detection period can-
not be eliminated unless compromised senders are patched up, but
we do not assume routers have this ability.
4.3.2 Updating Congestion Policing Feedback
When a link L is in the mon state, its router Rb uses the follow-
ing ordered rules to update the congestion policing feedback in any
request/regular packet traversing L:
1. If the packet carries nop, stamp L↓;
2. Otherwise, if the packet carries L′↓ stamped by an upstream
link L′, do nothing;
3. Otherwise, if L is overloaded, stamp L↓.
The router Rb never stamps the L↑ feedback. As we will see in
§ 4.3.3, only an access router stamps L↑ when forwarding a packet.
If the L↑ feedback reaches the receiver of the packet, it indicates
that the link L is not overloaded, because otherwise the router Rb
would replace the L↑ feedback with the L↓ feedback.
258monitors L’s congestion status using a load-based [46] or a loss-
based algorithm such as Random Early Detection (RED) [18]. If
Rb detects congestion between time t and t1, it will stamp the L↓
feedback into all packets traversing L from time t until two control
intervals after t1: t1 + 2Ilim, even if it has considered the link not
congested after t1. This hysteresis ensures that if a sender congests
a link L during one control interval, it will only receive the L↓
feedback in the following control interval, as shown in Figure 4.
For each rate limiter (src, L), the access router Ra keeps two
state variables: ts and hasIncr, to track the feedback it has re-
ceived. The variable ts records the start time of the rate limiter’s
current control interval, and hasIncr records whether the rate lim-
iter has seen the L↑ feedback with a timestamp newer than ts.
At the end of each control interval, Ra adjusts the rate limiter
(src, L)’s rate limit rlim as follows:
1. If hasIncr is true, Ra compares the throughput of the rate
limiter with 1
2 rlim. If the former is larger, rlim will be in-
creased by ∆; otherwise, rlim will remain unchanged. Check-
ing the rate limiter’s current throughput prevents a malicious
sender from inﬂating its rate limit by sending slowly for a
long period of time.
2. Otherwise, Ra will decrease rlim to (1 − δ)rlim.
We discuss how to set the parameters ∆, δ, etc. in § 4.6.
We now explain why this AIMD algorithm is robust, i.e., a ma-
licious sender cannot gain unfair bandwidth share by hiding the
L↓ feedback: if a sender has sent a packet when a link L suffers
congestion, the sender’s rate limit for L will be decreased. Sup-
pose L’s router Rb detects congestion and starts stamping the L↓
feedback at time t, and let te denote the ﬁnishing time of an ac-
cess router’s control interval that includes the time t, as shown in
Figure 4. Rb will stamp the L↓ feedback between [t, t1 + 2Ilim].
Since te ∈ [t, t + Ilim], a sender will only receive the L↓ feedback
for packets sent during the control interval [te, te + Ilim], because
te ≥ t and te + Ilim < t1 + 2Ilim. It can either present the L↓
feedback newer than te to its access router, or present one older
than te, or not send a packet. All these actions will cause its rate
limit to decrease according to the second rule above.
A legitimate sender should always present L↑ feedback to its
access router as long as the feedback has not expired, even if it has
received newer L↓ feedback. This design makes a legitimate sender
mimic an aggressive sender’s strategy and ensures fairness among
all senders.
4.3.5 Handling Multiple Bottlenecks
When a ﬂow traverses multiple links in the mon state, the ﬂow’s
access router will instantiate multiple per-(sender, bottleneck link)
rate limiters for the sender. The present NetFence design sends a
regular packet to only one rate limiter for simplicity, but it may
overly limit a sender’s sending rate in some cases. This is be-
cause when a sender’s packets carry the congestion policing feed-
back from one of the bottleneck links, all other rate limiters stay
idle. The sender’s access router will reduce their rate limits, if
they are idle for longer than a full control interval, as described
above (§ 4.3.4). Consequently, the idle rate limiters’ rate limits
may become smaller than a sender’s fair share rates at those bottle-
neck links. When a sender’s bottleneck link changes, it may obtain
less than fair share bandwidth at the new bottleneck initially, until
its rate limit for the new bottleneck converges. Additionally, if a
sender’s bottleneck link changes frequently due to congestion dy-
namics, its packets may switch between different rate limiters. If
those rate limiters’ rate limits differ greatly, it may be difﬁcult for