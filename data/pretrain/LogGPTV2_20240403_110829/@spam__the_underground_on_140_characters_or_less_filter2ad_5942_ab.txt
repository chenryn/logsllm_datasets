Our data collection spans one month of Twitter activity from Jan-
uary to February, 2010. During this time we gathered over 200
million tweets from the stream and crawled 25 million URLs. Over
three million tweets were identiﬁed as spam. Of the URLs crawled,
two million were identiﬁed as spam by blacklists, 8% of all unique
links. Of these blacklisted URLs, 5% were malware and phishing,
while the remaining 95% directed users towards scams. To un-
derstand blacklist performance, we manually inspected a random
sample of distinct URLs from tweets, ﬁnding that 26% of URLs
pointed to spam content, with an error margin of 5% at 95% conﬁ-
dence. To manually classify tweets, one of the authors clicks on the
URL in a tweet and decides if the URL is spam based on the con-
tent of the web page. Compared to the 8% detected by blacklists,
a signiﬁcant proportion of spam URLs are never seen in blacklists,
a challenge discussed in greater detail in Section 6. Over 90% of
Twitter users have public accounts [15], and we also collect the
complete history for over 120,000 users with public accounts, half
of which have sent spam identiﬁed by our blacklists; the history is
an additional 150 million tweets sent by these users.
In the event bit.ly or an afﬁliated service is used to shorten a spam
URL, we use the bit.ly API2 to download clickthrough statistics
and click stream data which allows us to identify highly successful
spam pages and the rate of trafﬁc. Of the spam links recovered,
245,000 had associated clickthrough data, totaling over 1.6 million
clicks. Using all of the links recovered during crawling, we present
an analysis of the techniques employed by spammers, using click-
through statistics when available, to measure effectiveness.
4. SPAM ON TWITTER
With over 3 million tweets posted to Twitter directing users to
spam detected by popular blacklists, we present an analysis of the
categories of spam appearing on Twitter and what techniques are
2http://code.google.com/p/bitly-api/wiki/ApiDocumentation
29Category
Free music, games, books, downloads
Jewelery, electronics, vehicles
Contest, gambling, prizes
Finance, loans, realty
Increase Twitter following
Diet
Adult
Charity, donation scams
Pharmacutical
Antivirus
Fraction of spam
29.82%
22.22%
15.72%
13.07%
11.18%
3.10%
2.83%
1.65%
0.27%
0.14%
Table 1: Breakdown of spam categories for spam on Twitter, based
on tweet text.
being employed to reach audiences. To measure the success of
Twitter spam, we analyze clickthrough statistics for spam URLs,
estimating the likelihood a spam tweet will be clicked by a follower.
Finally, as spammers must coerce Twitter members into following
spam accounts, we analyze tweeting behavior to differentiate be-
tween automated spamming bots and compromised accounts that
have been used to send spam, ﬁnding the vast majority of spam-
mers appear to be compromised accounts or unwitting participants
in spam distribution.
4.1 Spam breakdown
Aggregating all of the spam tweets identiﬁed by our system, we
generate a list of the most frequent terms. We then manually clas-
sify each term into a spam category when a clear distinction is pos-
sible, in turn using the terms to classify all of our spam tweets.
Roughly 50% of spam was uncategorized due to using random
terms; the breakdown of the remaining 50% of tweets is shown
in Table 1. While the typical assortment of scams present in email
carry over to Twitter, we also identify Twitter-speciﬁc advertise-
ments that sell Twitter followers or purport to give an account free
followers. This unique category makes up over 11% of categorized
Twitter spam, while the remainder of spam is dominated by ﬁnan-
cial scams, games, sale advertisements, and free downloads.
With only 140 characters for spammers to present a message, we
analyze what Twitter-speciﬁc features appear in tweets with black-
listed URLs compared to those of regular users. To act as a control,
we select two samples of 60,000 tweets, one made up of any tweet
appearing in our stream, while the second sample is generated from
only tweets containing URLs. Each tweet is parsed for mentions,
retweets, and hashtags, the results of which can be seen in Table 2.
The random sample of tweets is dominated by conversations be-
tween users, as indicated by 41% of sample tweets containing men-
tions. Compared to the sample of tweets containing URLs, spam
tweets are only slightly less likely to use Twitter features, with the
exception of malware and phishing tweets, where hashtags make up
70% of spam. To understand the motivation for spammers to use
these features, we present an analysis of how hashtags, retweets,
and mentions are being used by spammers.
Call outs: Mentions are used by spammers to personalize mes-
sages in an attempt to increase the likelihood a victim follows a
spam link. Mentions can also be used to communicate with users
that do not follow a spammer. In our data set, 3.5-10% of spam
tweets rely on mentions to personalize messages, the least popular
feature compared to hashtags and retweets.
Example: Win an iTouch AND a $150 Apple gift card @victim!
http://spam.com
Source
Google
Joewein
URIBL
Tweet
Tweet, URL
RT
@
3.5%
3.7%
#
#,@ #,RT
70.1%
1.8% 0.1% 0.3%
5.5%
6.5% 0.2% 0.5%
18.2% 10.6% 11.4% 1.5% 1.3%
13.3% 41.1% 13.6% 1.8% 2.3%
22.4% 14.1% 16.9% 1.6% 2.4%
Table 2: Feature frequency by blacklist for mentions (@), retweets
(RT), and hashtags (#), compared to a random sample of tweets and
a random sample of tweets containing URLs.
Retweets: Of the spam tweets we observe, roughly 1.8-11.4% are
retweets of blacklisted URLs. We identify four sources of spam
retweets: retweets purchased by spammers from respected Twitter
members, spam accounts retweeting other spam, hijacked retweets,
and users unwittingly retweeting spam. Of the sources, we are able
to differentiate instances of purchased tweets, discussed further in
Section 5, and hijacked retweets which we discuss next.
Example: RT @scammer: check out the Ipads there having a give-
away http://spam.com
Tweet hijacking: Rather than coercing another account to retweet
spam, spammers can hijack tweets posted by other users and
retweet them, prepending the tweet with spam URLs. Currently,
there are no restrictions on Twitter on who can retweet a message,
allowing spammers to take tweets posted by prominent members,
modify them, and repost with spam URLs. By hijacking tweets
from prominent Twitter users, spammers can exploit user trust in
retweets. Analyzing retweets for prepended text, we ﬁnd hijack-
ing constituted 23% of phishing and malware retweets, compared
to 1% of scam retweets.
Example: http://spam.com RT @barackobama A great battle is
ahead of us
Trend setting: Hashtags are used to simplify searches for content,
and if enough users tweet the same hashtag, it becomes a trending
topic. The anomaly of 70% of phishing and malware spam contain-
ing hashtags can be explained by spammers attempting to create a
trending topic, generating over 52,000 tweets containing a single
tag. Searching for hashtags that exclusively appear in spam tweets,
we identify attempts to initiate a trend. Of the total trends we iden-
tify, roughly 14% appear to be generated exclusively by spammers.
Example: Buy more followers! http://spam.com #fwlr
Trend hijacking: Rather than generating a unique topic, spammers
can append currently trending topics to their own spam. Anyone
who searches for the topic will then encounter the spam message,
interspersed with other non-spam generated by Twitter users. Us-
ing this technique, spammers no longer need to obtain followers
and instead ride on the success of other topics. Analyzing the list
of trending topics from a set of random tweets, we ﬁnd that roughly
86% of trends used by spammers also appear in benign tweets, with
popular trends at the time including #haiti, #iranelection, #glee, and
the #olympics.
Example: Help donate to #haiti relief: http://spam.com
4.2 Spam Clickthrough
In the event an account spams URLs shortened with bit.ly, we
can recover clickthrough statistics for the link and analyze the lin-
ear correlation of clickthrough with other features such as follow-
ers and tweet behavior. Of the blacklisted domains we identify, we
observe the clickthrough data for nearly 245,000 URLs. Roughly
97.7% of URLs receive no clicks, but those that do accumulate
30is repeated using the entire history of 50,000 accounts, ﬁnding on
average a tweet will appear 1.24 times, with 93% of tweets being
unique. This adjustment is factored into the reach of our earlier
calculations, but we still caution our estimate of tweet clickthrough
as a rough prediction.
Twitter’s improved clickthrough rate compared to email has a
number of explanations. First, users are faced with only 140 char-
acters in which to base their decision whether a URL is spam.
Paired with an implicit trust for accounts users befriend, increased
clickthrough potentially results from a mixture of naivety and lack
of information. Alternatively, previous estimates of email click-
through implicitly expect all emails to be viewed. In practice, this
may not be the case, resulting in users never being presented the
option to click on spam. This same challenge exists in identify-
ing whether a tweet is viewed, but the rates that users view tweets
versus emails may differ.
Regardless the underlying cause, Twitter’s clickthrough rate
makes the social network an attractive target for spammers; with
only loose spam ﬁltering in place, spammers are free to solicit
throughout the Twittersphere. Furthermore, the computational time
of broadcasting tweets is pushed off on Twitter’s servers compared
to email spam which requires access to large quantities of bots. Af-
ter a spammer generates a Twitter following, messages can easily
be distributed to thousands of followers with a minimal amount of
effort.
4.3 Spam Accounts
Without Twitter accounts, spammers are incapable of promoting
their landing pages. To understand the types of accounts involved in
spamming, we deﬁne two categories for users ﬂagged as tweeting
blacklisted links. The ﬁrst is the career spamming account created
with the express purpose of promoting spam. In contrast, a compro-
mised account was created by a legitimate user and at some point
in time compromised through the use of phishing attacks, malware,
or simple password guessing. To differentiate between the two, we
develop an array of tests that analyze an account’s entire tweet his-
tory, ﬁnding that the majority of spam on Twitter originates from
compromised accounts, not career spammers.
It is important to
note these tests are not designed to detect spamming accounts and
replace blacklists as they can easily be evaded by an adversary. In-
stead, we rely on these classiﬁcation techniques solely to help us
understand the ecosystem of spam on Twitter.
4.3.1 Career spamming accounts
We develop two tests that indicate if an account is a career spam-
mer, manually verifying the accuracy of each test on a random sam-
ple of both spam and likely non-spam accounts. The ﬁrst test ana-
lyzes tweet timing, based on the assumption that legitimate account
tweets overall reﬂect a uniform (Poisson) process. The second test
measures the entropy of an account’s tweets, identifying users that
consistently tweet the same text or link.
χ2 test on timestamp: Our ﬁrst test examines tweet timestamps
to identify patterns in the minutes and seconds for when a tweet
was posted. We represent timestamps for an individual account us-
ing vectors corresponding to the seconds value of each hour and
seconds value of each minute. We then use a χ2 test to compute
the p-value for these vectors for their consistency with an underly-
ing uniform distribution. For example, a p-value of less than 0.001
indicates less than 0.1% chance that a user posting as a Poisson pro-
cess generated the sequence. For our evaluation, we treat a p-value
of less than 0.001 for either vector as evidence that the user has
demonstrably failed the test. Such user tweet patterns very likely
reﬂect automation, leading to postings at regularized times. We
Figure 1: Clickthrough for spam URLs posted to Twitter. Only the
2.3% of URLs that generated any trafﬁc are shown.
over 1.6 million visitors, indicating that spam on Twitter is by no
means unsuccessful. Of links that generate any trafﬁc, 50% of the
URLs receive fewer than 10 clicks, as shown in Figure 1, while the
upper 10% of URLs account for 85% of the 1.6 million clicks we
observe. These highly successful URLs are dominated by phish-
ing scams that have pervaded Twitter in recent months [8], and we
discuss this further in Section 5.
Using the 2.3% of URLs that receive any trafﬁc, we calculate the
linear correlation for clicks and the number of accounts tweeting a
link, the aggregate followers that could view the link, and lastly the
number of times the link was tweeted, broken down into disjoint
combinations of features (RT, @, #). Unsurprisingly, the features
with the largest coefﬁcient of correlation (ρ > 0.7) are the num-
ber of accounts involved in spamming and the number of followers
that receive a link, both of which directly impact the overall num-
ber of potential impressions. In addition to audience volume, we
found that the use of hashtags (ρ = .74) and retweets with hashtags
(ρ = .55) is correlated with higher clickthrough rates. In practice,
the use of such features is rare, as previously shown in Table 2, but
their dominance amongst 70% of phishing and malware tweets bol-
sters their correlation to successful clickthrough. Surprisingly, the
number of times spam is tweeted shows a low coefﬁcient of corre-
lation to clickthrough (ρ = .28), indicating that repeatedly posting
a link does little to increase trafﬁc.
To understand the effectiveness of tweeting to entice a follower
into visiting a spam URL, we measure the ratio of clicks a link
receives compared to the number of tweets sent. Given the broad-
cast nature of tweeting, we measure reach as a function of both
the total tweets sent t and the followers exposed to each tweet f,
where reach equals t × f. In the event multiple accounts with po-
tentially variable number of followers all participate in tweeting
a single URL, we measure total reach as the sum of each indi-
vidual account’s reach. Averaging the ratio of clicks to reach for
each of the 245,000 URLs in our bit.ly data set, we ﬁnd roughly
0.13% of spam tweets generate a visit, orders of magnitude higher
when compared to clickthrough rates of 0.003%–0.006% reported
for spam email [11].
There are a number of factors which may degrade the quality
of this estimate. First, our data set exclusively targets bit.ly URLs
which may carry an inherent bias of trust as the most popular URL
shortening service [20]. Secondly, click data from bit.ly includes
the entire history of a link, while our observation of a link’s us-
age only account for one month of Twitter activity.
If a link is
tweeted prior to our study, or all repeated tweets do not appear in
our 10% sample, reach may be underestimated. We attempt to cor-
rect for this possibility by measuring the number of times a tweet
05010015020000.20.40.60.81Number of clicksFraction of unique URLs31(a)
(b)
(c)
Figure 2: Scatter plots of times of tweets for three users deemed to not post uniformly. The x-axis gives the minutes value of each hour and
y-axis gives seconds. In (a), the user posts at regular intervals – approximately every ﬁve minutes. The account in (b) tends to tweet toward
the begining of each minute, indicated by the prevalence of points low on the y-axis. For (c), the pattern is less obvious but still caught by
the χ2 test as indicating regularized tweeting with respect to the hour (x-axis).
deem such accounts as likely career spammers. Figure 2 shows ex-
amples of the minutes and seconds for three accounts that fail the
test. We manually assessed dozens of accounts that both passed
and failed this test, including both inspecting the contents of their
tweets and their tweeting patterns over time, ﬁnding that it is highly
accurate in ﬁnding what appear to be career spammers.
Tweet text and link entropy: For each spam account, we exam-
ine the account’s tweets history to identify instances where the text
and links posted are dominated by repetition, which we measure by
calculating entropy. The test begins by binning the text and URLs
posted by an account into distinct bins and calculating the entropy
of the resulting distribution for the text and URL. If there is no rep-
etition, then the entropy is equivalent to a uniformly random set of
the same size. We then calculate relative entropy as the ratio of
observed entropy to the entropy of a uniformly random set of the
same size, ﬁnding that a relative entropy value less than 0.5 indi-
cates strong repetition. For users that do not repeatedly post the
same tweet, relative entropy is close to one.
Using the entire tweet history of a sample of 43,000 spam ac-