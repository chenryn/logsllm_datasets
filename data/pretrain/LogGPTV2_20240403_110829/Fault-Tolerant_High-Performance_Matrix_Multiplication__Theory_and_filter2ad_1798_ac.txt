or B), and its magnitude are randomly determined. 
We do not analyze the case in which the error appears in 
C since, as stated in our theory (see Table l), that error will 
always be detected using  any of  the detection methods, (at 
least, as long as it makes a non-negligible difference in the 
result). 
The  error  detection  mechanisms  performed exactly  as 
expected.  All  errors  of  significance  that  were  introduced 
in matrix  A were  detected by  the left-sided and two-sided 
detection methods.  Similarly, all errors of significance that 
were  introduced  in  matrix  B  were  detected  by  the  right- 
sided  and  two-sided  detection  methods.  In  practice  both 
left- and right-sided methods detected errors of significance 
introduced in either A or B. As predicted, whenever we cre- 
ated a matrix A such that the elements in individual columns 
added to zero, the left-sided  detection method had  trouble 
detecting errors introduced  in  B.  Whenever we created  a 
matrix B such that the elements in individual rows added to 
zero, the right-sided detection method had trouble detecting 
errors introduced in A. 
6.2  Performance evaluation 
Next, we evaluated  the overhead introduced in  practice 
by our error detection/correction techniques.  We added the 
error detection and correction mechanisms described in the 
previous  sections  to  the  implementation  of  matrix-matrix 
multiplication described in ITXGEMM. In  [8, 91 we show 
that  this  implementation  (without error detection  and  cor- 
rection)  is highly competitive with  other efforts (e.g.  [ 161, 
which does not address fault-tolerance) in providing high- 
performance matrix-matrix multiplication for the Intel Pen- 
tium (R) I11 processor. 
We report results for the following fault-tolerant matrix- 
matrix multiplication implementations: 
- L/R/2-sided  detect:  ITXGEMM-based  implementa- 
tion with left/right/two-sided detection. 
- L/R/2-sided  correct:  ITXGEMM-based  implementa- 
tion with lefthighthwo-sided detection and correction. 
Specifically, the error detection  and and correction mecha- 
nisms were added to matrix-matrix multiplication algorithm 
MPP-MMP-MPM described  in  [8].  A  significant error was 
introduced in matrix A as described in the previous subsec- 
tion.  The error  was  always  detected and, if  desired, cor- 
rected. 
Figure 2 shows the performance achieved by  the differ- 
ent matrix-matrix multiplication implementations for rank- 
k updates  (m = n, IC  = 128) and general  square matrix- 
matrix  multiplication  (m = n  = IC).  For  this  prototype 
implementation, the error detection methods reduce perfor- 
mance by  20-2570 even  if  no error is  introduced.  When a 
53 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 04:04:59 UTC from IEEE Xplore.  Restrictions apply. 
Overhead 
(mi = k,  = 128, nj  = 512, b = 8) 
m = n = 512,k = 128 
Detection  Correction  Detection  Correction 
m = n = k = 512 
2.2% 
2.2% 
4.4% 
1 
I 
25 % 
0.4% 
0.4% 
2.2% 
2.2% 
4.4% 
I 
I 
6% 
0.1% 
0.1% 
1) 
I 1  
Method 
right-sided 
left-sided 
two-sided 
I, 
Table 2. Theoretical overhead for error detection and correction. 
- 
4M) 
~ 
I  a 
A 
U 3 350 t 
9300- 
0‘ 
LL 1250- 
A 
- 
200 
- 
150 
0 - 
200 
Matrix size (m=n) with k=128 
- 
100 
- 
50 
(4 
400 
100 
200 
0
0
D 
0 
100 
300 
500 
e - - + _ - w - 4 - - - 0 - - - o  
a 
* 
a 
D 
r?i 
0 
A 
O
A 
D
300 
400 
500 
100 
200 
Matrix size (m=n=k) 
300 
400 
500 
100 
200 
Matrix size (m=n=k) 
300 
400 
500 
(c) 
( 4  
loo[ 50 
Figure 2. Performance of the matrix-matrix multiplication kernels. 
54 
500 1 
200- 
A 
150- 
- 
100 
- 
50 
O; 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 04:04:59 UTC from IEEE Xplore.  Restrictions apply. 
single error is introduced and corrected, the performance of 
the right-sided detection  and correction  method  is  signifi- 
cantly worse.  The performance of the left-sided method is 
not  significantly  affected.  This supports  the  observations 
made  in  Section  4.2.  Since the  left-sided  error  detection 
and correction methods also detects and corrects virtually 
all errors introduced in B, the two-sided method is also not 
significantly affected. 
It should be noted that we expect to reduce overhead sig- 
nificantly  by  carefully  amortizing  the  required  additional 
computations.  Furthermore,  while  we  currently  tie  the 
blocking used for the error detection and correction mecha- 
nisms to the blocking used by  ITXGEMM for moving data 
into the  L2 cache,  overhead  for the  detection  mechanism 
can  be reduced  if  a coarser  blocking  were  allowed.  This 
would be at the expense of additional memory required for 
the roll-back mechanism as well as a higher computational 
overhead if a correction becomes necessary. 
7  Status 
We  currently  have  a  complete  implementation  of  the 
above ideas for the operations 
C  t aAB+,BC 
c t ~ A ~ B + , B C  
c t a
T
c  t C V A ~ B ~ + P C  
~
~
+
~
~
Using  similar  techniques,  we  have  also  created  fault- 
tolerant  implementations  for  all  the  level  3  BLAS  oper- 
ations  using  our  Formal  Linear  Algebra  Methods  Envi- 
ronment  [9,  101.  While we  currently  only  target  double- 
precisions real  arithmetic, and  only  have  implementations 
for the Intel Pentium  (R) I11 processor, the techniques are 
easily  extended  to  single-precision  or  complex arithmetic 
and to other architectures. 
The ultimate goal is to create an environment for devel- 
oping fault-tolerant linear algebra libraries, the Formal Lin- 
ear Algebra Recovery  Environment (FLARE), which  may 
eventually  include  fault-tolerant  implementations  for  the 
major operations included in LAPACK. 
8  Conclusion 
In  this  paper,  we  have  significantly  extended  the  the- 
ory behind and practice of algorithmic fault-tolerant matrix- 
matrix multiplication. In particular, we have expanded upon 
existing  results  relevant  to  the  detection  of  errors  in  the 
computation  C  =  AB.  Based  on  these  theoretical  re- 
sults,  we  have  provided  a  practical,  fault-tolerant,  high- 
performance implementation  of the matrix-matrix multipli- 
cation operation. It should be obvious that the results extend 
55 
to all cases of matrix-matrix multiplication. that are part  of 
the  BLAS. The experimental  results  demonstrate  that  our 
methods introduce, in practice, an acceptable level of over- 
head  (about  20%  for  the  error  detection  mechanism  and 
an insignificant additional amount when a correction is re- 
quired)  relative to  high-performance  implementations that 
do not include algorithmic fault-tolerance. 
Additional Information 
For additional information: 
www.cs.utexas.edu/users/flame/FLARE/. 
References 
[ 13  Remote  Exploration  and  Experimentation  Project 
Plan, July2000.  h t t p :  //ree.jpl.nasa.gov/. 
[2]  E.  Anderson,  Z.  Bai,  J.  Demmel,  J.  E.  Dongarra, 
J.  DuCroz,  A.  Greenbaum,  S.  Hammarling,  A.  E. 
McKenney, S. Ostrouchov, and D. Sorensen. LAPACK 
Users’ Guide. SIAM, Philadelphia, 1992. 
[3]  E. Barragy  and R. van de Geijn.  BLAS performance 
for selected  segments of a high p EBE finite element 
code. International Journal on Numerical Methods in 
Engineering, 38: 1327-1340,  1995. 
[4]  E  Chen,  L.  Craymer,  J.  Deifik,  A.  J.  Fogel,  D.  S. 
Katz,  A.  G.  Silliman,  Jr.,  R.  R.  Some,  S.  A.  Up- 
church, and K. Whisnant.  Demonstration of the  Re- 
mote  Exploration  and  Experimentation  (REE)  fault- 
tolerant parallel-processing supercomputer for space- 
craft onboard scientific data processing.  In Proceed- 
ings of the IEEE International Conference on Depend- 
able Systems and Networks, pages 367-372,2000. 
[5]  Jack J. Dongarra, Jeremy Du Croz, Sven Hammarling, 
and Iain  Duff.  A  set of  level  3  basic  linear  algebra 
subprograms.  ACM  Trans.  Math.  Soft.,  16( l):l-l7, 
March  1990. 
[6]  Jack  J.  Dongarra,  Iain  S. Duff,  Danny  C.  Sorensen, 
and Henk A. van  der Vorst.  Solving  Linear Systems 
on  Vector and  Shared  Memory  Computers.  SIAM, 
Philadelphia, PA, 199 1 .  
[7] Gene H. Golub and Charles F. Van Loan. Matrix Com- 
pututions. The Johns Hopkins University Press, Balti- 
more, 2nd edition, 1989. 
[8]  J. A. Gunnels, G. M. Henry, and R. A. van de Geijn. A 
family of high-performance  matrix  multiplication  al- 
gorithms.  Submitted to The 2001 lnternational Con- 
ference on Computer Science (ICCS2001), May 2001. 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 04:04:59 UTC from IEEE Xplore.  Restrictions apply. 
[9] John  A.  Gunnels,  Greg  M.  Henry,  and  Robert  A. 
van  de Geijn.  Formal  Linear  Algebra Methods En- 
vironment (FLAME): Overview.  FLAME  Working 
Note #I  CS-TR-00-28, Department of Computer Sci- 
ences, The University of Texas at Austin, Nov. 2000. 
[IO]  John A. Gunnels and Robert A. van de Geijn.  Formal 
methods for high-performance linear algebra libraries. 
In  Ronald  E Boisvert  and Ping Tak  Peter Tang, edi- 
tors,  The Architecture of  ScientiJc  Sofmare. Kluwer 
Academic Press, 200 1. 
[ 1 I ]   K. Huang and J.A. Abraham.  Algorithm-based  fault 
tolerance for matrix operations. IEEE Trans. on Com- 
puters, 33(6):5 18-528,  1984. 
[ 121  B. Kiigstrom, P. Ling, and C. Van Loan. GEMM-based 
level 3 BLAS: High performance model implementa- 
tions and performance evaluation benchmark.  TOMS, 
24(3):268-302,  1998. 
[ 131  Paula Prata and JoHo Gabriel Silva.  Algorithm based 
fault tolerance versus result-checking for matrix com- 
putations.  In Proceedings of  the Twenty-Ninth Annual 
International  Synzposiuni on Fault-Tolerant Coniput- 
ing, pages 4-1  1,  1999. 
[I41 M.  Turmon,  R.  Granat,  and  D.  Katz.  Software- 
implemented  fault  detection  for  high-performance 
space applications.  In  Proceedings  of  the IEEE Int. 
Conj on Dependable  Systems  and Networks,  pages 
107-1  16,2000. 
[I51  H.  Wasserman  and  M. Blum.  Software  reliability 
via  run-time  result-checking.  Journal  of  the ACM, 
44(6):826-849,  1997. 
[I61 R.  Clint  Whaley  and  Jack  J.  Dongarra.  Automati- 
cally  tuned  linear  algebra  software.  In  Proceedings 
of  SC’98, 1998. 
56 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 04:04:59 UTC from IEEE Xplore.  Restrictions apply.