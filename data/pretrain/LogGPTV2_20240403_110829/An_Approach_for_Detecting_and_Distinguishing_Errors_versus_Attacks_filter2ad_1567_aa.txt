title:An Approach for Detecting and Distinguishing Errors versus Attacks
in Sensor Networks
author:Claudio Basile and
Meeta Gupta and
Zbigniew Kalbarczyk and
Ravi K. Iyer
An Approach for Detecting and Distinguishing Errors versus Attacks
in Sensor Networks
Claudio Basile∗, Meeta Gupta†, Zbigniew Kalbarczyk, Ravi K. Iyer
Center for Reliable and High-Performance Computing
University of Illinois at Urbana-Champaign, IL 61801
{basilecl,mgupta2,kalbar,iyer}@crhc.uiuc.edu
Abstract
Distributed sensor networks are highly prone to acciden-
tal errors and malicious activities, owing to their limited re-
sources and tight interaction with the environment. Yet only a
few studies have analyzed and coped with the effects of cor-
rupted sensor data. This paper contributes with the proposal
of an on-the-ﬂy statistical technique that can detect and dis-
tinguish faulty data from malicious data in a distributed sen-
sor network. Detecting faults and attacks is essential to en-
sure the correct semantic of the network, while distinguishing
faults from attacks is necessary to initiate a correct recovery
action. The approach uses Hidden Markov Models (HMMs)
to capture the error/attack-free dynamics of the environment
and the dynamics of error/attack data.
It then performs a
structural analysis of these HMMs to determine the type of er-
ror/attack affecting sensor observations. The methodology is
demonstrated with real data traces collected over one month
of observation from motes deployed on the Great Duck Island.
1. Introduction
Distributed sensor networks are being deployed for a wide
range of applications, such as surveillance, habitat monitor-
ing, and health care. Owing to their limited resources and
tight interaction with the environment, sensor nodes can re-
port corrupt readings due to environmental disturbances, acci-
dental faults in the sensor hardware or software, or malicious
activities, such as an adversary capturing and reprogramming
a number of sensor nodes. Field studies indicate that a ma-
jor cause of failure are the errors originating in degraded sen-
sor devices, which directly interact with the environment and
are thus subjected to a variety of physical, chemical, and bi-
ological forces. Interestingly, these sensor errors are likely to
manifest days before the sensor electronics actually fail [1].
The need for reliable and secure operation in critical sen-
sor applications is compelling. While most research focuses
on protecting a sensor network from network-level errors and
attacks (e.g., denial-of-service [2], malicious message routing
∗C. Basile is currently with Bell Laboratories, Holmdel, NJ 07733, and
can be reached at cbasile@lucent.com.
†M. Gupta is currently with the Division of Engineering and Applied Sci-
ences at Harvard University, Cambridge, MA 02138, and can be reached at
meeta@eecs.harvard.edu.
and forwarding [3]), few studies have analyzed and proposed
solutions to cope with the effects of corrupted/malicious sen-
sor data [4]. This paper contributes with an on-the-ﬂy sta-
tistical technique that not only can detect anomalous sensor
data but also can distinguish faulty data from malicious data
in a distributed sensor network. Detecting faults and attacks
is essential to ensure the correct semantic of a network, while
distinguishing faults from attacks is necessary to diagnose the
detected anomaly and initiate a correct recovery action.
The proposed approach employs Hidden Markov Mod-
els (HMMs). HMMs have been widely used in the areas
of speech recognition, gesture recognition, and gene ﬁnding.
More recently, HHMs have been applied in the domain of
host-based intrusion detection [5,6]. In this work, we propose
using HMMs for anomaly detection, but we take an entirely
new direction. First, we target distributed networked systems,
sensor networks in the current paper, and we leverage the in-
trinsic redundancy that these systems provide to overcome the
complexity of the classical HMM identiﬁcation problem. At
each time step of our algorithm, multiple, correlated obser-
vations are available from multiple sources. Assuming that
the errors or the adversary have not compromised (yet) a ma-
jority of the sources, we can use a statistical clustering-based
technique to (statistically) separate correct observations from
faulty/malicious observations. Thus, we can efﬁciently iden-
tify the HMM MCO capturing the correspondence between
the hidden and correct dynamics of the sensed phenomenon P
(derived using only data from correct sources) and the observ-
able dynamics of P (derived using all collected data). Impor-
tantly, we do not require a separate training phase in which the
system is left vulnerable to incoming errors and attacks, be-
cause at no point in time do we require all incoming data to be
error/attack-free. Second, while prior work has used HMMs
merely to detect anomalies, we use these powerful mathemat-
ical models also to diagnose and characterize the nature of
the detected anomalies, i.e., to distinguish errors versus at-
tacks and to determine the type of error or the type of attack
that affects the system. We accomplish this goal by tracking
the error/attack behavior with an additional HMM MCE that
captures the correspondence between the hidden dynamics of
P and the dynamics of error/attack data, and by performing
a structural analysis of the two HMMs. We demonstrate our
methodology with an experimental study that uses real data
Proceedings of the 2006 International Conference on Dependable Systems and Networks (DSN’06) 
0-7695-2607-1/06 $20.00 © 2006 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 12:29:25 UTC from IEEE Xplore.  Restrictions apply. 
traces collected over one month of observation from motes
deployed on the Great Duck Island [7].
2. Overview of Hidden Markov Models
A Hidden Markov Model (HMM) [8] captures a hidden
stochastic process that is inferred through a sequence of ob-
servations, which are stochastically related to the state of the
hidden process. Mathematically, an HMM is characterized
by: (1) a set of hidden states S1, . . . , SM ; (2) a set of ob-
servation symbols V1, . . . , VN ; (3) a state transition proba-
bility distribution A = {aij}ij, where aij = P r{st+1 =
Sj|st = Si} and st is the hidden state at time t; (4) an ob-
servation symbol probability distribution B = {bik}ik, where
bik = P r{vt = Vk|st = Si} and vt is the observation symbol
at time t; and (5) an initial state distribution π = {πi}i, where
πi = P r{so = Si} and so is the initial hidden state.
HMMs have recently been used to detect malicious intru-
sions in a single-host computer system by tracing the sys-
tem calls invoked by a monitored application run on the sys-
tem [5, 6]. In an initial attack-free learning phase, an HMM λ
is identiﬁed to capture the correct behavior of the application.
The approach in [5] assumes a hidden state for each system
call (around 40 in the reported experiments), which leads to a
large training time (about 2 weeks) due to the high complexity
of the standard HMM identiﬁcation problem. In a subsequent
testing phase, the probability P r{O|λ} that the observed ap-
plication behavior O is produced by model λ is computed, and
an anomaly is detected if this probability is less than a given
threshold η. This simple method suffers from a series of lim-
itations: (1) The choice of the hidden states of the HMM is
arbitrary, difﬁcult to justify, and brings about states that have
no physical interpretation. (2) The required assumption of an
attack-free training phase and long training time are unpracti-
cal for real-world applications, where the intrusion detection
system must be periodically re-tuned to account for natural
variations in the monitored system’s behavior.
(3) The ap-
proach is not designed for distributed environments. By ex-
ploiting the redundancy naturally present in sensor networks,
this paper uses HMMs in an entirely new way and, thus, over-
comes the limitations mentioned above.
3. Proposed Methodology
This section discusses the proposed methodology for de-
tecting, diagnosing and classifying errors and attacks in a dis-
tributed network. Before introducing the technical details of
the methodology, we outline its basic steps. Data streams
from sensors deployed in a region of interest R are used as
the input to the analysis procedure (see Fig. 1). The proposed
procedure executes on a single data collector node (e.g., a base
station or a cluster head) and operates as follows:
1. Collect sensor observations and group them according to
a predeﬁned time window w.
2. From the observations collected in each time window
and a set of potential states of the environment (obtained
as discussed below) generate: (i) a sequence oi of the
observable states of the sensed environment (derived us-
ing all the collected data regardless of their correctness),
(ii) a sequence ci of the hidden states of the environ-
ment (i.e., actual, unknown states traversed by the en-
vironment, e.g., error-free temperature values), and (iii)
a sequence ei of the erroneous states traversed by the ob-
servations that are (potentially) corrupted by accidental
errors or malicious attacks.
3. Build an HMM MCO that relates the hidden states of the
environment (indicated by ci) with observable states of
the environment (indicated by oi), and an HMM MCE
that relates the hidden states of the environment with the
error/attack states (indicated by ei).
4. Analyze the two HMMs and, based on a library of known
error/attack models, classify the type of error/attack that
has affected the original observations.
5. Extract a Markov Model MC to provide the user with
an error/attack-free description of the dynamics of the
environment.
3.1. Data Collection and Preprocessing
Figure 1 depicts the key steps (represented as rectangles in
the ﬁgure) of the proposed methodology. We assume that sen-
sors are multimodal, i.e., they can measure different types of
physical attributes, such as temperature, pressure, and humid-
ity. We model the value of the environment attributes moni-
tored by sensors in the region of interest R as a multidimen-
sional, unknown parameter Θ(t) that changes with time. We
assume that each sensor periodically sends a message (cid:2)t, p(cid:3)
to a single collector node, where t is the time in which the
readings are taken and p = (cid:2)x1, . . . , xn(cid:3) is the vector of n
environment attributes sampled at time t. We assume that
the signal pj sensed by a correct sensor j can be modeled as
pj = Θ(t) + Nj, where Nj is a zero-mean, random measure-
ment noise.1 Note that in contrast with classical estimation
theory, we let a number of these sensor observations be arbi-
trarily corrupted, owing to faults/attacks.
Given a set of collected sensor observations O = {(cid:2)t, p(cid:3)},
the collector node partitions these observations into time in-
tervals of duration w so as to build a sequence of observation
sets {Oi} such that:
Oi = {p|(cid:2)t, p(cid:3) ∈ O ∧ w · (i − 1) ≤ t ≤ w · i}.
(1)
Parameter w must be large enough to create nonempty sets Oi
yet small enough to enable us to accurately sample changes in
the environment attributes Θ(t) (e.g., Θ(t) should be approx-
imately constant in an observation window w).
1More complex environment estimation problems are the object of future
extensions.
Proceedings of the 2006 International Conference on Dependable Systems and Networks (DSN’06) 
0-7695-2607-1/06 $20.00 © 2006 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 12:29:25 UTC from IEEE Xplore.  Restrictions apply. 
o1
oi
oT
O
w
w
O
i
t
oi
Observable State
Identification
ci
Correct State
Identification
1
ai
T
ai
Alarm
Generation
lj
Observation
to State
Mapping
S
Model States
Identification
(on-line Clustering)
Alarm
Filtering
1
bi
T
bi
Error/Attack
Track
Management
1
ei
k
ei
HMM
Estimation
M
CO
Hidden Model
Extraction
M
CE
1
HMM
Estimation
Error/Attack
Track
Classifier
HMM
Estimation
M
CE
k
Error/Attack
Track
Classifier
Error/Attack
Classifier
M
C
type1
typek
Figure 1. Methodology for error/attack detection and classiﬁcation.
A Model State Identiﬁcation module uses an on-line sta-
tistical clustering algorithm to identify the possible states
S = {s1, . . . , sM } of the environment, which we use to syn-
thetically describe the physical conditions traversed by the
sensed phenomenon and by error/attack data. Figure 2 depicts
an execution scenario where eight states sj are identiﬁed. For
clarity of presentation, the operation of the Model State Iden-
tiﬁcation module is discussed at the end of this section.
An Observable State Identiﬁcation module uses a current
observation set Oi to determine the current observable state
of the environment oi, i.e., the state that best describes the
totality of the observations p1,. . . ,pN in Oi:
N(cid:2)
oi = arg min
1≤k≤M
(cid:7)sk − 1
N
pj(cid:7).
j=1
(2)
Figure 3 depicts an execution scenario where an observation
set Oi of six observations pj is mapped to the observable state
s2 (hence, oi = 2), since s2 is the closest state to the mean
value calculated across all observations.
An Observation to State Mapping module maps each ob-
servation pj in Oi to the model state that best represents pj.
Formally, the module computes:
lj = arg min
1≤k≤M
(cid:7)sk − pj(cid:7).
(3)
In Fig. 4, observations p1 to p4 are closest to state s1; thus,
l1 = l2 = l3 = l4 = 1. On the other hand, observations
p5 and p6 are closest to states s4 and s5, respectively; hence,
l5 = 4 and l6 = 5.
A Correct State Identiﬁcation module determines the cor-
rect environment state ci, i.e., the state that best describes the
largest group of observations in Oi that cluster together:
ci = arg max
1≤k≤N
|{pj ∈ Oi|lj = k}|
(4)
In the example of Fig. 4, the correct state is s1 (hence, c = 1),
since it is associated with the largest subset of observations
pj. To guarantee valid operation of this module, it is assumed
that the largest set of observations that cluster together always
includes a majority of correct observations. Intuitively, this
corresponds to saying that correct observations both behave
alike (i.e., are not split into a number of small-size clusters)
and exceed faulty/malicious observations. While it is possi-
ble to craft pathological scenarios in which the assumption is
violated, the remainder of this paper assumes that the system
parameters are properly tuned (e.g., the Model State Identiﬁ-
cation module does not generate too many model states) and
that a majority of sensors have not been compromised (yet)
by errors and attacks.
An Alarm Generation module checks whether a sensor j
belongs to the correct state c and generates a (raw) alarm aj
if the reading from that sensor does not belong to the correct
state. In the example of Fig. 4, two alarms are generated for
sensors 5 and 6.
An Alarm Filtering module ﬁlters the generated alarms to
reduce the false-alarm probability. A simple approach is to
generate a ﬁltered alarm only after receiving k raw alarms in
the last n time steps (with k ≤ n). Sophisticated approaches
can leverage change detection schemes such as Sequential
Probability Ratio Test (SPRT) and Cumulative Sum (CUM-
SUM) procedure [9].
Filtered alarms are passed to an Error/Attack Track Man-
agement module. Since different sensors may be affected by
different types of errors/attacks, we maintain a separate er-
ror/attack track e for each of the sensors.
In the proposed
mechanism, if a ﬁltered alarm bj is raised and there is no
currently active error/attack track for sensor j, then a new
track et+1 is open for that sensor (where t is the number of
tracks that were previously active). If a ﬁltered alarm bj is
cleared, then the error/attack track associated with the sensor
j is closed. For each sensor j for which there is an active er-
ror/attack track ek, the Error/Attack Track Management mod-
ule sets ek
i = lk if at time i sensor value pk is not mapped
Proceedings of the 2006 International Conference on Dependable Systems and Networks (DSN’06) 
0-7695-2607-1/06 $20.00 © 2006 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 12:29:25 UTC from IEEE Xplore.  Restrictions apply. 
s3
s2
s1
s4
s5
s7
s6
s8
s3
p4
s2
s1
p3
p2
p1
s4
p6
s5
s7
s6
s8
s4
p5
s3
p4
s2
s1
p3
p2
p1
p6
s5
s7
s6
s8
Figure 2. Identiﬁcation of the
model states.
Figure 3. Identiﬁcation of the
observable environment state.
Figure 4. Identiﬁcation of the
correct environment state and
the error/attack states.
to the correct state (i.e., lk (cid:8)= ci), or ek
i =⊥ otherwise. State
⊥ is a ﬁctitious state that is used to model the cases in which
a sensor for which there is an open error/attack track gener-
ates data in agreement with correct sensors. In the example
of Fig. 4, sensor 5 and sensor 6 are mapped to the error/attack