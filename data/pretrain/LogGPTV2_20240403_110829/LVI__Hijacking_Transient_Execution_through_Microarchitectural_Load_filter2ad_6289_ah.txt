Allow
fail
Page fault
yes
yes
vadrs in
enclave?
no
Abort page
yes
fail
yes
padrs in
EPC?
EPCM
checks?
ok
Fig. 10. Access control checks (page faults) in the SGX page table walk for
a virtual address vadrs that maps to a physical address padrs.
LVI-NM-FPU
LVI-PF
LVI-type
LVI-US
LVI-PPN
LVI-P
LVI-MCA
LVI-AD
LVI-US-NULL
LVI-US-LFB
LVI-US-SB
LVI-US-LP
LVI-PPN-NULL
LVI-PPN-L1D
LVI-P-NULL
LVI-P-L1D
LVI-P-LFB
LVI-P-SB
LVI-P-LP
LVI-AD-LFB
LVI-AD-SB
LVI-AD-LP
Fig. 11. Extensible LVI classiﬁcation tree (generated using https://transient.
fail/) with possible attack variants (red, bold), and neutralized variants that
are already prevented by current software and microcode mitigations (green,
dashed).
APPENDIX B
LVI CLASSIFICATION TREE
In this appendix, we propose an unambiguous naming
scheme to reason about and distinguish LVI variants, following
the (extended) transient-execution attack classiﬁcation tree by
Canella et al. [10]. Particularly, in a ﬁrst level, we distinguish
the fault or assist type triggering the transient execution, and at
a second level we specify the microarchitectural buffer which
is used as the injection source. Figure 11 shows the resulting
two-level LVI classiﬁcation tree. Note that, much like in the
perpendicular Spectre class of attacks [10], not all CPUs from
all vendors might be susceptible to all of these variants.
a) Applicability to Intel SGX: We remark that some of
the fault types that may trigger LVI in Figure 11 are speciﬁc to
Intel SGX’s root attacker model. Particularly, LVI-US generates
supervisor-mode page faults by clearing the user-accessible bit
in the untrusted page table entry mapping a trusted enclave
memory location. The user-accessible bit can only be modiﬁed
by root attackers that control the untrusted OS, and hence
does not apply in a user-to-kernel or user-to-user LVI scenario.
Furthermore, LVI-PPN generates SGX-speciﬁc EPCM page
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 10:02:52 UTC from IEEE Xplore.  Restrictions apply. 
faults by supplying a rogue physical page number in a page-
table entry mapping trusted enclave memory (cf. Section VI-A).
This variant is speciﬁc to Intel SGX’s EPCM memory access
control model.
Finally, as explored in Section VIII, LVI-P and LVI-AD are
not speciﬁc to Intel SGX, and might apply to traditional kernel
and process isolation as well.
b) Neutralized variants:
Interestingly, as part of our
analysis, we found that some LVI variants are in principle
feasible on unpatched systems, but are already properly
prevented as an unintended side-effect of software mitigations
that have been widely deployed in response to Meltdown-type
cross-domain leakage attacks.
We considered whether virtual machine or OS process
Foreshadow variants [70] may also be reversely exploited
through an injection-based LVI methodology, but we concluded
that no additional mitigations are required. In the case of virtual
machines, the untrusted kernel can only provoke non-present
page faults (and hence LVI-P-L1D injection) for less-privileged
applications, and never for more privileged hypervisor software.
Alternatively, we ﬁnd that cross-process LVI-P-L1D is possible
in demand-paging scenarios when the kernel does not properly
invalidate the PPN ﬁeld when unmapping a victim page and
assigning the underlying physical memory to another process.
The next page dereference in the victim process provokes a
page fault leading to the L1TF condition and causing the L1D
cache to inject potentially poisoned data from the attacker
process into the victim’s transient data stream. However, while
this attack is indeed feasible on unpatched systems, we found
that it is already properly prevented by the recommended PTE
inversion [12] countermeasure which has been widely deployed
in all major operating systems in response to Foreshadow.
Secondly, we considered that some processors transiently
compute on unauthorized values from the FPU register ﬁle
before delivering a device-not-available exception (#NM) [57].
This may be abused in a “reverse LazyFP” LVI-NM-FPU attack
to inject attacker-controlled FPU register contents into a victim
application’s transient data stream. However, we concluded
that no additional mitigations are required for this variant as
all major operating systems inhibit the #NM trigger completely
by unconditionally applying the recommended eager FPU
switching mitigation. Likewise, Intel conﬁrmed that for every
enclave (re-)entry SGX catches and signals the #NM exception
before any enclave code can run.
Finally, we concluded that the original Meltdown [42] attack
to read (cached) kernel memory from user space cannot be
inverted into an LVI-L1D equivalent. The reasoning here is that
the user-accessible page-table entry attribute is only enforced
in privilege ring 3, and a benign victim process would never
dereference kernel memory.
APPENDIX C
INTEL SGX QUOTE LAYOUT
We ﬁrst provide the C data structure layout representing
a quote in Listing 5. Note that the report_data ﬁeld in
the sgx_report_body_t; is part of the (untrusted) input
uint8_t
...
/* (320) Data provided by the user */
report_data;
sgx_report_data_t
1 typedef struct _sgx_report_data_t {
d[64];
2
3 } sgx_report_data_t;
4
5 typedef struct _report_body_t {
6
7
8
9 } sgx_report_body_t;
10
11 typedef struct _quote_t {
12
13
14
15
16
17
18
19
20
21
22 } sgx_quote_t;
uint16_t
uint16_t
sgx_epid_group_id_t epid_group_id;
sgx_isv_svn_t
sgx_isv_svn_t
uint32_t
sgx_basename_t
sgx_report_body_t
uint32_t
uint8_t
qe_svn;
pce_svn;
xeid;
basename;
report_body;
signature_len;
signature[];
version;
sign_type;
/* 0
*/
/* 2
*/
/* 4
*/
/* 8
*/
/* 10 */
/* 12 */
/* 16 */
/* 48 */
/* 432 */
/* 436 */
Listing 5: https://github.com/intel/linux-sgx/blob/master/common/inc/sgx
quote.h#L87
buffer outside enclave.
(without the actual signature).
emp_quote,
/* fill in signature */
&quote_body, /* fill in metadata */
(uint32_t)sign_size);
*
* quote_body: sgx_quote_t holding quote metadata
*
*/
1 /* emp_quote: Untrusted pointer to quote output
2
3
4
5
6 ret = qe_epid_sign(...
7
8
9
10 ...
11
12 /* now copy sgx_quote_t metadata (including user-
13
14 memcpy(emp_quote, &quote_body, sizeof(sgx_quote_t));
15
16 /* now erase enclave secrets (EPID private key) */
17 CLEANUP:
18
19
20
21 }
provided report_data) into untrusted output buffer*/
epid_member_delete(&p_epid_context);
if(p_epid_context)
return ret;
Listing 6: https://github.com/intel/linux-sgx/blob/master/psw/ae/qe/quoting
enclave.cpp#L1139
provided as part of the QE invocation. The only requirement on
this data is that it needs to have a valid SGX report checksum,
and hence needs to be ﬁlled in by a genuine enclave running
on the target system (but this can also be for instance an
attacker-controlled debug enclave).
Furthermore, Listing 7 provides the get_quote entry
point in Intel SGX-SDK Enclave Deﬁnition Language (EDL)
speciﬁcation. Note that the quote data structure holding the
asymmetric cryptographic signature is relatively big, and hence
is not transparently cloned into enclave memory. Instead this
pointer is declared as user_check and explicitly veriﬁed to
lie outside the enclave in the QE implementation, allowing to
directly read from and write to this pointer from the trusted
enclave code.
Listing 6 ﬁnally provides the C code fragment including the
memcpy invocation discussed in Section VII-A.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 10:02:52 UTC from IEEE Xplore.  Restrictions apply. 
71
TABLE III. Number of lfences inserted by different compiler and assembler mitigations for the OpenSSL and SPEC benchmarks (cf. Figures 8 and 9).
Optimized compiler (Intel)
Unoptimized LLVM intermediate (ours)
c l a n g - f u l l
c l a n g - r e t
l o a d + r e t
r e t - o n l y
24 710
5248
32 764
148 069
266
36 940
110 353
5582
545
1669
1534
5608
1615
2584
17 198
44
5578
10 750
528
118
340
419
39 368
10 228
-
-
-
-
-
-
-
-
-
5119
1415
-
-
-
-
-
-
-
-
-
Benchmark
Unoptimized assembler (Intel)
g c c - p l a i n
g c c - l f e n c e
c l a n g - p l a i n
OpenSSL (libcrypto.a)
OpenSSL (libssl.a)
600.perlbench
602.gcc
605.mcf
620.omnetpp
623.xalancbmk
625.x264
631.deepsjeng
641.leela
657.xz
0
0
0
10
0
0
2
0
0
0
0
73 998
15 034
104 475
458 799
1191
78 968
252 080
31 748
4315
8997
7820
0
0
0
1
0
0
0
0
0
0
0
1 public uint32_t get_quote(
2
3
4
5
6
7
8
9
10
11
12
13
14
[size = blob_size, in, out] uint8_t *p_blob,
uint32_t blob_size,
[in] const sgx_report_t *p_report,
sgx_quote_sign_type_t quote_type,
[in] const sgx_spid_t *p_spid,
[in] const sgx_quote_nonce_t *p_nonce,
// SigRL is big, so we cannot copy it into EPC
[user_check] const uint8_t *p_sig_rl,
uint32_t sig_rl_size,
[out] sgx_report_t *qe_report,
// Quote is big, we should output it in piece meal.
[user_check] uint8_t *p_quote,
uint32_t quote_size, sgx_isv_svn_t pce_isvnsvn);
Listing 7: https://github.com/intel/linux-sgx/blob/master/psw/ae/qe/quoting
enclave.edl#L43
LFENCE COUNTS FOR COMPILER MITIGATIONS
APPENDIX D
Table III additionally provides the number of lfence
instructions inserted by the various compiler and assembler
mitigations introduced in Section IX-B for the OpenSSL and
SPEC2017 benchmarks.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 10:02:52 UTC from IEEE Xplore.  Restrictions apply. 
72