P (JI =(L,L))+P (JI =(H,H))
(3) If EI is I(s) > I(o), then,
P (JI = (H, L)|EI) = 1; otherwise, 0.
(3)
Probabilistic Generative Model for Access Behavior. An access event is
an observed access behavior. We refer to system call events related to ﬁles or
registries as access events. Each access event involves a subject and an object,
and we divide all access events into two types, read and write, according to their
information ﬂows [13].
One execution of a program s consists of a set of access events. In each
execution, there are three possible access behaviors between a subject s and an
object o, i.e., Read-only (r), Write-only (w), Read & W rite (r & w) [13]. Thus,
once s accesses o, we represent the access behavior of s on o as a random variable
with three possible values, and s takes one of three possible access behaviors on
o in each execution. We denote the probabilities that s reads-only, writes-only,
and reads & writes o as Pr(s, o), Pw(s, o), and Pr&w(s, o).
Furthermore, for a program s with diﬀerent executions, we assume the access
behavior of s in one execution is independent of its behavior in other exe-
cutions. We deﬁne Acc(s, o) to be the access behavior of s on o among all
executions, consisting of Nr,(s,o), Nw,(s,o) and Nr&w,(s,o), which are the num-
ber of executions that s reads-only, writes-only and reads & writes, and they
obey a multinomial distribution, i.e., Acc(s, o) = (Nr,(s,o), Nw,(s,o), Nr&w,(s,o)) ∼
Multi(N(s,o), Pr(s, o), Pw(s, o), Pr&w(s, o)), where N(s,o) is the total number of
executions of program s that accesses object o.
With our second primary assumption, the relationship between the access
behavior of s on o and their integrity levels can be interpreted as follows: If I(s) 
I(o), then s writes-only o, i.e., Pw(s, o) = 1 and Pr(s, o), Pr&w(s, o) = 0; if I(s) =
I(o), then s can perform any of behaviors, i.e., 0  I(o) are d1, d2, and d3 respectively.
Before presenting the multinomial distribution of access behaviors with para-
meters t1, t2, and t3 in Eq. (7), Eq. (6) presents the prior T of this multinomial
distribution conditioning on the integrity ordering, which aims to model access
behaviors by combining both the security policies, i.e., NRD and NWU, and
potential violations in commercial operating systems. Combining with the rela-
tionship between EI and JI as shown in Eqs. (1)–(3), this generative model pro-
vides a way to model the access behavior with joint integrity level of subjects and
objects. Moreover, it oﬀers a way to infer the joint integrity level JI(s, o) given
observations of access behaviors, which is presented in the following subsection.
T = (t1, t2, t3)|EI ∼
⎧
⎪⎨
D = (d1, d2, d3) ∼ Dir(α1, α2, α3),
EI|D ∼ Cat(3, d1, d2, d3),
Dir(1 + β1, β2, β3),
Dir(β1, β2, β3),
Dir(β1, 1 + β2, β3),
Acc|T ∼ Multi(N, t1, t2, t3).
⎪⎩
if I(s)  I(o),
(4)
(5)
(6)
(7)
Probabilistic Graphical Model on Integrity. Our goal is to characterize the
integrity level of each subject and object by marginal distributions, i.e., P (I(s))
and P (I(o)). To achieve this goal, we need to aggregate the joint integrity levels
of all pairs of subjects and objects, and calculate the marginal integrity distribu-
tion for subjects and objects. We achieve this goal using a probabilistic graphical
model, or more accurately, pairwise Markov network (pMN). Pairwise Markov
networks are the simplest subclass of Markov networks. A pMN is an undirected
Probabilistic Inference on Integrity for Access Behavior
163
probabilistic graphical model G(V, E, Ψ), where V is a set of nodes representing
random variables, E is a set of edges representing relationships between nodes
with factors deﬁned in Ψ, each edge is associated with a factor over a pair of
nodes [14]. In our problem, the pMN is a bipartite graph, where each node rep-
resents the integrity level of a subject or object, a subject is connected with an
object if there exists an observed access event associated with them. There is
no edge between two subjects or two objects. Meanwhile, we encode the joint
integrity level JI for each pair of subject and object into each edge, the factor on
each edge is joint integrity level JI. Figure 3 illustrates an example of a pMN con-
sisting of four pairs of subjects and objects. Since the bipartite graph constructed
from a real data set contains loops, we compute an approximate inference on the
integrity level of each subject and object as shown in the following subsection.
F1
JI(P1, F1)
P1
JI(P1, F2)
F2
JI(P2, F2)
P2
JI(P2, R1)
R1
Fig. 3. An example of pairwise Markov network
3.3 Probabilistic Inference
Inference on Joint Integrity Level of Each Pair. Under the generative
model shown in Fig. 2, the Bayes estimator ˆPE for the integrity ordering given
access events is
ˆPE = P (EI|Acc) =
(cid:6)
P (EI , D, T|Acc),∝ (cid:6)
P (Acc|T )P (T|EI)
(cid:6)
D,T
P (Acc|T )P (T|EI)P (EI|D)P (D),
P (EI|D)P (D).
(8)
=
D,T
(cid:6)
T
D
More speciﬁcally, the probabilities of all possible orderings are
ˆPEI () = P (> |Acc) =
α1
α1 + α2 + α3
α2
α1 + α2 + α3
α3
(β1 + β2 + β3)(Nr + β1)
β1(N + β1 + β2 + β3)
/Σ,
(9)
/Σ,
(β1 + β2 + β3)(Nw + β2)
(10)
/Σ,
(11)
α1 + α2 + α3
β2(N + β1 + β2 + β3)
where Σ =
α3
More details of the derivation are presented in Appendix.
β1(N +β1+β2+β3) +
α1+α2+α3 +
(β1+β2+β3)(Nr+β1)
α1+α2+α3
α2
α1
α1+α2+α3
(β1+β2+β3)(Nw+β2)
β2(N +β1+β2+β3)
.
Our estimator ˆP (JI(s, o)) for the joint distribution of integrity levels is,
P (JI(s, o)|EI(s, o))P (EI(s, o)|Acc).
ˆP (JI(s, o)) = P (JI(s, o)|Acc) =
(cid:6)
EI (s,o)
(12)
164
W. Mao et al.
Inference on Integrity Level of Subject and Object. There exist loops in
our pairwise Markov network. Hence, the estimation of marginal distributions
for such graphs is known to be NP-complete. Loopy belief propagation provides
an approximate and eﬃcient way of inference based on message passing. It has
proven to be a successful at inferring on marginal distributions over loopy graph
in various domains, such as object tracking in computer vision, error-correcting
code, etc [14]. In particular, researchers have applied loopy belief propagation to
solve problems in security area by modeling them as classiﬁcation problems [18,
29]. We apply this method to our problem to infer the probabilistic integrity
level of each subject and object.
mF1P1(I(P1))
mP1F2(I(F2))
mF2P2(I(P2))
mP2R1(I(R1))
F1
P1
F2
P2
R1
mP1F1(I(F1))
mF2P1(I(P1))
mP2F2(I(F2))
mR1P2(I(P2))
Fig. 4. Message passing of loop belief propagation on the pMN shown in Fig. 3
The loopy belief propagation works as follows. Each node sends messages to
(cid:7)
k∈N (i)\j
mki(xi),
(13)
its adjacent nodes, as shown in Fig. 4, according to
πi(xi)Ψij(xj|xi)
mij(xj) =
(cid:6)
xi∈{low,high}
where mij(xj), i ∈ N(j) indicates the message from adjacent nodes of node j,
πi(xi) is the prior of node i. Ψij(xi|xj) is the conditional probability of integrity
level of xi given that of xj, which is derived as follows.
Ψij (xi|xj ) ∝ P (xi, xj ) = ˆP (JI (xi, xj )) =
(cid:2)
EI (xi,xj )
P (J(xi, xj )|EI (xi, xj ))P (EI (xi, xj )|Acc).
(14)
Substituting Eqs. (1)–(3), (9)–(11) into Eq. (14), we can easily derive the con-
ditional probability Ψij(xi|xj). The message mij(xj) reveals that how the node
i thinks about the level of node j. In each iteration, the message of all nodes
will be updated. The order of message updating is not important. The iteration
stops when the message of nodes converge, i.e., there is no signiﬁcant changes of
messages between iterations, or when a suﬃcient number of iterations is reached.
Then, we compute the marginal distribution of integrity for each node, a.k.a. the
belief of node, as follows.
bi(xi) = Cπi(xi)
(cid:7)
k∈N (i)
mki(xi),
(15)
where C is a normalization constant to ensure that the integrity probabilities add
xi∈{L,H} bi(xi) = 1. Here, bi(L) and bi(H) indicate probabilities
up to 1, i.e.,
that i has low and high integrity level respectively.
(cid:8)
Probabilistic Inference on Integrity for Access Behavior
165
3.4 Malware Detection
There exist violations in commercial modern operating systems under NRD and
NWU security policies [21]. In order to accommodate violations, we employ a
statistical learning technique to extract more adaptive security policies for mal-
ware detection. Before we describe this technique, we ﬁrst show how to recover
the integrity level of subjects and objects under the probabilistic notation.
Integrity Level. The integrity levels of subjects and objects are recovered by
taking into account the probability that the subject/object has high integrity,
i.e., P (I(i) = H), which is the belief of a subject/object bi(H). We sort subjects
and objects by their beliefs of bi(H) in decreasing order, and assign the integrity
level to all subjects and objects from the highest to the lowest. We treat the
subjects and objects with same beliefs as having the same integrity level. The
ranking positions under the sort are treated as the integrity levels of subjects
and objects.
Malware Detection. For program i, we create a feature vector Xi for it. The
feature vector is similar to [20], but with column normalization. More speciﬁcally,
Xi is
(cid:10)
(cid:9)
Xi =
, x(ﬁle,write)
x(ﬁle,read)
i
(cid:9)
x(k,l)
i
=
i1
, x(reg,read)
i
, x(reg,write)
i
,
(16)
(cid:10)
.
ir
ir
x(k,l)
i
, ..., x(k,l)
(17)
is the fraction of objects of type k ∈ {ﬁle, registry} accessed under
Here x(k,l)
operation l ∈ {read, write} at integrity level r. x(k,l)
is the vector of these frac-
tions at all integrity levels. L(k) is the total number of integrity levels of objects
of type k.
, ..., x(k,l)
iL(k)
Once we create feature vectors for both benign and malicious processes,
we train a statistical classiﬁer to build an access behavior model for malware
detection.
i
3.5 Time Complexity
The main time complexity of malware detection model consists of two parts:
(1) Integrity determination. (2) Malware classiﬁcation.
To analyze the time complexity of the ﬁrst part, we assume the number of
edges is E in our pairwise Markov network, which corresponds to the number
of subject-object pairs. Our model employ loopy belief propagation, which is a
iterative algorithm running in O(4E(s + 1)), where s is the number of iterations.
In each iteration, we need to calculate messages on both directions of each edge,
and each direction contains two types of messages, i.e., L and H. That is the
reason of the constant before the number of edges. We observe s (cid:5) E1. Hence,
1 In fact, we ﬁnd s is about 7 in our experiments.
166
W. Mao et al.
we can say, our probabilistic integrity model run in the linear time to the number
of edges in our pairwise Markov network, i.e., O(E).
The time complexity of malware classiﬁcation depends on the statistical clas-
siﬁer we employ, we analyze it in our experimental results.
4 Experimental Evaluation
4.1 Evaluation Methodology
To evaluate our model, we design a set of experiments to empirically answer three
questions: (1) Do the determined integrity levels support malware detection from
a perspective of security policies? (2) What is the performance of our malware
detection model? (3) What is the running time of our probabilistic integrity
model in experiments?
Experimental Settings. Benign programs: We employ Process Monitor [22]
to collect the access behaviors of programs under eight diﬀerent users’ normal
usages without interfering with their daily usages, which run on systems run-
ning Microsoft Windows XP SP3. Among eight users, two of them are male
undergraduates who were working on their ﬁnal year projects, and six others are
graduates consisting of one female student and ﬁve male students, whose behav-
iors include writing, programing, web surﬁng, etc. The data collection takes place
over periods of 7 to 16 days, and we ﬁnally obtain access behaviors of 27,840
executions from 534 benign programs.