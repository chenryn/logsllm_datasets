keys are hard-coded into the Mylar application.
Mylar also includes integrity protections and code veriﬁ-
cation, but we omit them for brevity. Our attacks do not
involve breaking these protections.
Sharing and searching encrypted data.
If Alice wants
to share encrypted data with Bob, she needs to give him
the keys of the corresponding principal. To do this, Alice
encrypts these keys with Bob’s public key and uploads the
resulting wrapped keys to the database. By downloading and
decrypting them, Bob gains access to the principal.
A user may have access to multiple principals, thus Mylar
needs to support keyword search over documents encrypted
with diﬀerent keys. A straightforward approach is to have
the user submit a separate search token for each principal it
has access to, but this is expensive with many principals.
For eﬃciency, Mylar relies on the server to generate tokens
for searching over multiple principals. The user submits a
single token, for documents encrypted with the user’s prin-
cipal. The server then uses a client-generated delta value to
convert this token to another token for documents encrypted
with a diﬀerent principal. Whenever a user is given access
to a new principal, their client automatically sends the delta
associated with that principal to the server.
Threat model. Mylar claims to protect conﬁdentiality of
users’ data and queries against actively malicious servers,
including servers that collude with malicious users, under
the assumption that honest users never have access to any
document controlled by the adversary. As we explain in
Section 8, this assumption is not enforced by the reference
implementation of Mylar, nor do we believe that it can be
enforced in realistic collaborative applications.
Mylar explicitly does not hide access or timing patterns,
even though in any real-world deployment they are visible
to an adversarial server. In Section 7, we show what these
patterns reveal to a persistent passive attacker. In Section 8,
we show how an active attacker can break the conﬁdentiality
of Mylar-protected data without exploiting access patterns.
3. SECURITY MODEL FOR MKSE
Mylar is based on a multi-key searchable encryption (MKSE)
scheme invented by Popa and Zeldovich [49]. In [48], Popa
et al. argue that Mylar is secure by appealing to the cryp-
tographic proofs of security for this scheme.
In this section, we show that the theoretical deﬁnitions
of security for MKSE proposed by Popa and Zeldovich [49]
fail to model security even against a passive adversary. To
this end, we construct an artiﬁcial scheme that satisﬁes their
deﬁnition but trivially leaks all keywords queried by a user,
which also reveals the corresponding plaintexts.
This shows that the proofs in [48, 49] are not useful for
arguing any meaningful level of security. It does not (yet)
imply that the Mylar MKSE scheme is vulnerable to attack.
In the rest of this paper, we demonstrate practical attacks
on Mylar when using this MKSE scheme as designed and
implemented by Popa et al.
3.1 Mylar MKSE
A multi-key searchable encryption scheme (MKSE) allows
eﬃcient keyword search over encrypted keywords. We focus
here on the construction by Popa and Zeldovich [49]. For
simplicity assume that all keywords are of the same length,
call it (cid:96) bits. The scheme relies on bilinear pairings. Let
G1, G2, GT be groups, all of the same order p. Let n ∈ N
be a security parameter. We associate to these groups an
eﬃciently computable pairing function e : G1 × G2 → GT
that enjoys the property that for all g1 ∈ G1, g2 ∈ G2, gT ∈
GT and any α, β ∈ Zp it holds that e(gα
T . The
scheme also uses hash functions H : {0, 1}∗ → G1 and
H2 : {0, 1}n × GT → {0, 1}(cid:96)+n, modeled as random oracles.
Figure 1 shows the details of the scheme. After generat-
ing parameters and keys (MK.Setup and MK.Kg), the client
uses MK.Enc to (separately) encrypt each keyword of a doc-
ument. To enable the server to convert search tokens for
documents encrypted under diﬀerent keys, the client gen-
erates an appropriate delta value (MK.Delta) and sends it
to the server. To perform keyword search over encrypted
documents, the client generates a token (MK.Token) and
sends it to the server. The server uses the delta value to ad-
just the token (MK.Adjust) and determines if an encrypted
document matches the keyword (MK.Match).
2 ) = gαβ
1 , gβ
Note that MK.Match assumes an adjusted token. One
can run MK.Delta on k1 = k2, allowing one to “adjust” a
token generated for one key into an “adjusted” token for the
same key. Correctness requires that: (1) for all keywords w,
MK.Match(tk(cid:48), c) returns 1 with probability overwhelmingly
close to one if tk(cid:48) is a search token for w and c is an encryp-
tion of w, and (2) for all keywords w (cid:54)= w(cid:48), MK.Match(tk(cid:48), c)
returns 0 with probability overwhelmingly close to one if tk(cid:48)
is a search token for w(cid:48) but c is an encryption of w.
The scheme implemented in Mylar is a variant of the one
described above, in which the same randomness r is reused
for all keywords from the same document. Only one cipher-
text is generated for each unique keyword, and ciphertexts
are stored in the order in which the keywords appear in
the document. This reuse of randomness does not seem to
impact security relative to the Popa-Zeldovich deﬁnitions,
although analysis would require some change in semantics
to accommodate encrypting whole documents at once rather
than individual keywords. We omit the details and focus on
the simpler scheme shown in the ﬁgure. All attacks in the
rest of the paper work regardless of which version of the
scheme is used, except where mentioned otherwise.
Security deﬁnitions. Popa and Zeldovich introduced two
notions of security for MKSE: data hiding and token hiding.
We will only sketch them informally and refer the interested
reader to the whitepaper [49] for the formal deﬁnitions.
• MK.Setup(1n):
return pars = (n, p, G1, G2, GT , e, g1, g2, gT )
• MK.Kg(pars): return k ← Zp
• MK.Delta(k1, k2): return ∆ = gk2/k1
• MK.Token(k, w): return H(w)k ∈ G1
• MK.Enc(k, w): Draw a random r ← {0, 1}n. Compute
∈ G2
2
c(cid:48) = H2(r, e(H(w), g2)k). Output c = (cid:104)r, c(cid:48)(cid:105).
• MK.Adjust(tk, ∆): return tk(cid:48) = e(tk, ∆) ∈ GT .
• MK.Match(tk(cid:48), c): Let c = (cid:104)r, c(cid:48)(cid:105). Return 1 if H2(r, tk(cid:48)) =
c(cid:48) and 0 otherwise.
Figure 1: The MKSE scheme analyzed in [49].
Data hiding is formalized via a game involving a challenger
Ch and an adversary A. The game starts by having Ch run
parameter generation. A then chooses an access graph that
speciﬁes which keys can have their search tokens converted
to which other keys; A can choose any keys except one dis-
tinguished key k0 generated honestly by Ch. Ch generates
an adjustment delta for each edge in the graph, and gives
these values to A. Then A picks two keywords w0, w1, gives
them to Ch and receives back encryption MK.Enc(k0, wb)
for randomly chosen b. A can make adaptive queries to an
encryption oracle (that uses k0) and a search token oracle
(for any key).
It cannot, however, make a query to the
search token oracle for w0 or w1 if it is for a key with an
edge to k0 in the access graph. This restriction is critical,
as removing it leads to a vacuous deﬁnition (no scheme can
meet it), but our counter-example below exploits it. The
adversary outputs a guess b(cid:48) and wins if it equals b.
Token hiding attempts to capture the desired security for
keyword queries. The adversary A again generates an access
graph with a special challenge user with key k0. A picks all
other keys. The challenger Ch then generates delta values
for all edges in the graph and gives them to A. Then A can
make adaptive queries to an encryption oracle and search
token oracle for any of the keys, as well as output a pair
w0, w1 of keywords for which Ch returns MK.Token(k0, wb)
for randomly chosen b. Throughout the game A cannot
make an encryption query or search token query on w0 or
w1 for keys that do not have a path to them from k0. In
words, the adversary can either perform queries on keywords
unrelated to the challenge pair, or can query them but only
for keys unrelated to k0 via delta values. Finally, A outputs
b(cid:48) and wins if b(cid:48) = b.
3.2 Counterexample
Popa and Zeldovich assume that if a scheme is both data-
hiding and token-hiding, then no eﬃcient adversary can dis-
tinguish encryptions of keywords or distinguish tokens of
keywords (i.e., the outputs of MK.Enc and MK.Token, re-
spectively) non-negligibly better than a random guess. In
this section, we show that this is false.
The Popa-Zeldovich approach of using two distinct no-
tions for data hiding and token hiding was previously consid-
ered for single-key symmetric searchable encryption (SSE)
by Curtmola et al. in 2006 [17], building on a data-hiding
deﬁnition from [23]. Curtmola et al. showed that achieving
both data hiding and token hiding does not imply that a
single-key SSE scheme hides queries. We adapt their coun-
terexample in a straightforward way to the MKSE setting.
The counterexample version of the Mylar MKSE scheme
has the same MK.Setup, MK.Kg, MK.Token and MK.Adjust
algorithms. We modify encryption and matching as follows:
• MK.Enc(cid:48)(k, w): Draw a random r ← {0, 1}n. Com-
pute c(cid:48) = H2(r, e(H(w), g2)k) ⊕ (w(cid:107)0n). Output c =
(cid:104)r, c(cid:48)(cid:105).
• MK.Match(cid:48)(tk(cid:48), c): Let c = (cid:104)r, c(cid:48)(cid:105). Return 1 if the bit
string H2(r, tk(cid:48)) ⊕ c(cid:48) ends with (cid:96) zeros and return 0
otherwise.
Below, we prove that this scheme is secure according to
the Popa-Zeldovich deﬁnitions. Yet, given a search token
H(w)k and an encryption c = (cid:104)r, c(cid:48)(cid:105) of a keyword (where
c(cid:48) = H2(r, e(H(w), g2)pr) ⊕ (w||0(cid:96))), the malicious server
can remove the pseudorandom pad and reveal the word w.
We conclude that the proofs of security for Mylar based
on the Popa-Zeldovich MKSE model do not imply anything
about the actual security of Mylar.
Correctness. The probability that MK.Match(cid:48)(tk(cid:48), c) = 1
is one when tk(cid:48) is a token for a keyword w and c is an
encryption of w. Now consider the probability of an in-
correct match, where tk(cid:48) = e(H(w(cid:48)), g2)k but c = (cid:104)r, c(cid:48)(cid:105)
with c(cid:48) = H2(r, e(H(w), g2)k) ⊕ (w(cid:107)0n).
If H is collision
resistant, then H(w(cid:48)) (cid:54)= H(w) with all but negligible prob-
ability and, in turn, the probability that the low n bits of
H2(r, e(H(w(cid:48)), g2)k)⊕c(cid:48) are all zero is at most 2−n assuming
H2 is a random oracle.
Data hiding.
Intuitively, the modiﬁed Mylar scheme is
data-hiding because H2 is a random oracle, so the value c(cid:48)
that is XORed with w||0n acts like a pseudorandom one-time
pad. Therefore, the only way to distinguish the two chal-
lenge keywords is to run MK.Match and see which challenge
keyword-ciphertext it matches. According to the Popa-Zeldovich
data-hiding deﬁnition, however, the adversary cannot query
to obtain a token for either of the challenge keywords be-
cause of the restrictions on queries in the game. Thus, the
adversary cannot distinguish the challenge keywords.
We now sketch a more detailed proof. Given a data-hiding
adversary A against the counterexample scheme, we con-
struct a data-hiding adversary B against the original Mylar
scheme. B proceeds through the ﬁve stages of the data-
hiding game as follows. (1) It runs A and outputs in the
ﬁrst stage the same access graph G as output by A. (2) B
gets a list of delta values, which it gives to A. (3) When A
outputs two challenge keywords (w0, w1), B chooses a bit d
at random and outputs as its challenge (U, wd) for U drawn
uniformly from the message space. It gets back a ciphertext
(cid:104)r, c(cid:48)(cid:105) and gives back to A the ciphertext (cid:104)r, c(cid:48) ⊕ (wd(cid:107)0n)(cid:105).
(4) B answers oracle queries by A using its own oracles.
Note that any token queries by A cannot be on w0 or w1
for a user u for which (u, 0) ∈ G (i.e., for which the delta
between user u and 0 is in the graph). Thus B will never
make such a token query on wd. The probability that one of
A’s token queries is on U is negligible for suﬃciently large
|U|. Thus B satisﬁes the query restrictions of the game with
all but negligible probability. (5) Finally, A outputs bit b(cid:48),
and B checks if b(cid:48) = d. If so, it outputs 1 and otherwise it
outputs 0.
To complete the proof, it suﬃces to show that B’s success
If B’s challenge is b = 1, then
upper bounds that of A.
the environment that B simulates for A is exactly the data-
hiding game for the modiﬁed Mylar scheme. If B’s challenge
is b = 0, then the probability that A outputs d is 1
2 be-
cause A receives no information about d. Thus twice B’s
advantage is an upper bound on A’s advantage.
Combining this with the data-hiding proofs for the origi-
nal scheme [49] implies the data-hiding security of the mod-
iﬁed scheme under the same bilinear pairing assumptions.
Token hiding.
Intuitively, token-hiding is satisﬁed be-
cause the adversary receives a token for user key k0 of ex-
actly one of the challenge keywords and can never request
the token of either keyword under k0 or any other “non-free”
user key, meaning the adversary has a delta which can ad-
just the search token to search over a document whose key it
speciﬁed in setup. It can also never receive an encryption of
either of the challenge keywords under any “non-free” doc-
ument key, which is a key to a document that is accessible
by k0 or any users that can access any documents also ac-
cessible to k0. Without either of these values, it cannot run
MK.Match and distinguish the challenge token.
As with data hiding, we can reduce the token-hiding se-
curity of the modiﬁed Mylar MKSE scheme to the original
one. Because token generation is the same in both games,
the reduction simply simulates encryption query responses
appropriately (by xor-ing in w(cid:107)0n to values).
3.3 Limitations of formal models
Our counterexample highlights a critical problem with the
Popa-Zeldovich formal model for MKSE. In the literature on