### Error Correction Procedure and Theorem for Extended Vasil’ev Codes

**Authorized Use:**
- **Licensee:** Tsinghua University
- **Download Date:** March 20, 2021
- **Time:** 09:58:41 UTC
- **Source:** IEEE Xplore
- **Restrictions Apply.**

The entire error correction procedure for extended Vasil’ev codes is illustrated in Figure 2. The sizes of \( K_d \) and \( K_c \) can be computed using the following theorem.

**Theorem 5.1:**
For an \((a + m + 2, a + k_V, 4)\) extended Vasil’ev code, where \( k_V = m - \lceil \log_2(m + 1) \rceil \), let \( t = \min\{a, k_V\} \). There are \( 2^a \) undetectable errors and \( 2^{a+1}(2^{k_V} - 1) \) conditionally detectable errors. If only errors occurring in the information part of the code are corrected, the number of miscorrected errors is given by:
\[ 2t(2^{a + k_V - 1}) + (2t - 1)|a - k_V| \]
The number of conditionally miscorrected errors is:
\[ 2|a - k_V|(2^{a + k_V - 2t}) \]

The probability of error masking for conditionally detectable errors and the probability of miscorrection for conditionally miscorrected errors are bounded by \( P_f \), which is the nonlinearity of \( f \) defined by (4) (see Theorem 4.4).

**Proof:**
The syndrome of the code can be rewritten as follows:
\[ S_1 = H((\tilde{c}_1, 0) + \tilde{c}_2) = H((e_1, 0) + e_2) \]
\[ S_2 = p(\tilde{c}_1) + f(\tilde{y}) + \tilde{c}_3 = f(\tilde{y}) + f(y) + p(e_1) + e_3 \]
\[ S_3 = p(\tilde{c}_1) + p(\tilde{c}_2) + p(\tilde{c}_3) + p(\tilde{c}_4) = p(e_1) + p(e_2) + p(e_3) + p(e_4) \]

1. **Detection Kernel \( K_d \):**
   \[ K_d = \{ e | S_1 = 0 \in \text{GF}(2^{\lceil \log_2(m + 1) \rceil}), S_2 = S_3 = 0 \in \text{GF}(2), \forall x \in C \} \]
   \[ S_1 = H((e_1, 0) + e_2) = 0 \Rightarrow (e_1, 0) + e_2 \text{ is a codeword of the linear code } V. \]
   Since \( f: \text{GF}(2^{k_V}) \) is a nonlinear function, the only possibility to guarantee \( S_2 = 0, \forall x \in C \) is that \( (e_1, 0) = e_2, p(e_1) = e_3 \).
   \[ S_3 = 0 \Rightarrow e_4 = e_3 = p(e_1) \]
   Therefore, the detection kernel contains all error vectors \( e = (e_1, e_2, e_3, e_4) \) such that \( (e_1, 0) = e_2, e_3 = e_4 = p(e_1) \). The number of errors in this class is \( 2^a \).

2. **Conditionally Detectable Errors:**
   If \( (e_1, 0) + e_2 \) is a nonzero codeword of \( V \) and \( e_4 = p(e_1) + p(e_2) + p(e_3) \), then \( S_1 = 0, S_3 = 0, \forall x \in C \). \( S_2 \) can be either 1 or 0 depending on the information part of the code. These errors will be conditionally detected. The error masking probability is bounded by \( P_f \). If \( f \) is a perfect nonlinear function, these errors will be detected with probability 0.5. The number of errors in this class is \( 2^{a+1}(2^{k_V} - 1) \).

3. **Miscorrected Errors:**
   Multi-bit errors will be miscorrected as single-bit errors occurring in the information part of the code if and only if \( S_3 = 1, S_1 = h_i, 1 \leq i \leq \max\{a, k_V\} \). Let \( t = \min\{a, k_V\} \).
   - If \( 1 \leq i \leq t \), \( e \) will always be miscorrected as a single error in the \( i \)-th bit of either \( c_1 \) or \( c_2 \). The number of pairs \( (e_1, e_2) \) satisfying \( S_1 = H((e_1, 0), e_2) = h_i, 1 \leq i \leq t \) is \( t \cdot 2^{a + k_V} \). \( e_3 \) can be either 1 or 0. \( e_4 = p(e_1) + p(e_2) + p(e_3) + 1 \). Therefore, there are \( 2t \cdot 2^{a + k_V} \) errors that satisfy \( S_3 = 1, S_1 = h_i, 1 \leq i \leq t \). Half of them are correctly corrected. The number of miscorrected errors in this class is \( 2t(2^{a + k_V - 1}) \).
   - If \( t < i \leq \max\{a, k_V\} \), the number of errors satisfying \( S_3 = 1, S_1 = h_i \) is \( 2|a - k_V| \cdot 2^{a + k_V} \). After flipping the \( i \)-th bit of either \( \tilde{c}_1 \) or \( \tilde{c}_2 \), \( S_1 \) and \( S_3 \) become zero. Denote by \( e^*_1, e^*_2 \) the new error vectors after flipping the bit for the first two parts of the codewords.
     - If \( (e^*_1, 0) + e^*_2 = 0 \) and \( e_3 = p(e^*_1) \), \( S_2 \) is always zero. The number of errors in this class is \( 2t \cdot |a - k_V| \) and \( |a - k_V| \) of them are correctly corrected. The number of miscorrected errors is \( (2t - 1) \cdot |a - k_V| \).
     - If \( (e^*_1, 0) + e^*_2 = 0 \) and \( e_3 \neq p(e^*_1) \), \( S_2 \) is always one. Errors in this class are always detectable. The number of such errors is \( 2t \cdot |a - k_V| \).
     - If \( (e^*_1, 0) + e^*_2 \neq 0 \), then \( S_2 \) can be either 0 or 1 depending on the information bits of the code. Errors in this class will be conditionally miscorrected. The probability of miscorrection is bounded by \( P_f \). If \( f \) is a perfect nonlinear function, the probability of miscorrection is 0.5. The number of errors in this class is \( 2|a - k_V|(2^{a + k_V - 2t}) \).

**Sizes of \( K_d \) and \( K_c \):**
The sizes of \( K_d \) and \( K_c \) are functions of \( a \) and \( m \). For any \((n, k, 4)\) extended Vasil’ev code, we have:
\[ k = a + k_V = a + m - \lceil \log_2(m + 1) \rceil, \quad n = a + m + 2, \quad a \leq m \]
Thus,
\[ n - 2 \leq a \leq \left\lfloor \frac{n - 2}{2} \right\rfloor \]
For \( n = 39, k = 32 \), \( 6 \leq a \leq 18 \). Figure 3 shows \( |K_d| \) and \( |K_c| \) of \((39, 32, 4)\) extended Vasil’ev codes for different values of \( a \). The minimum values of \( |K_d| \) and \( |K_c| \) are 26 and \( 12(2^{32} - 1) + 20(2^6 - 1) \) respectively, both of which are achieved when \( a = 6 \).

**Comparison with Extended Hamming Codes:**
Extended Hamming codes and extended Vasil’ev codes can correct all single-bit errors and detect all double-bit errors. Assuming all errors with higher multiplicities are equiprobable, extended Vasil’ev codes provide better error protection than extended Hamming codes. Table 2 shows the number of undetectable/miscorrected errors with multiplicities 3 to 6 for \((39, 32, 4)\) extended Hamming and Vasil’ev codes (\( a = 6 \)).

**Hardware Overheads:**
The encoders and error correction circuits of both extended Hamming and Vasil’ev codes (with \( a = 6 \)) were synthesized in Synopsys Design Compiler. For \((39, 32, 4)\) extended Hamming code, the encoder performs matrix multiplication over GF(2) and can be implemented using 72 2-input XOR gates. The decoder can be implemented using 450 2-input logic cells and inverters. The hardware overhead for extended Vasil’ev code is slightly higher, requiring 106 and 538 2-input cells and inverters for the encoder and decoder, respectively. The small difference in overheads between the two codes is often not significant due to the small portion of the total device dedicated to memory protection circuits.

**Conclusion:**
A partially robust code with a minimum distance of 4 is proposed to replace traditional linear extended Hamming codes for protecting memories in situations where the likelihood of multi-bit upsets is high or errors tend to repeat. The numbers of undetectable and miscorrected multi-bit errors for the proposed code are much smaller than for traditional linear error-correcting codes. In the presence of multiple bit distortions, our codes provide much better protection against soft errors with only a small increase in hardware overhead. Unlike linear codes, robust and partially robust codes have conditionally undetectable/miscorrected errors, making them useful for detecting/correcting repeating errors, such as hard errors caused by permanent faults. The proposed protection scheme is not targeted at any specific memory architecture and can be applied to nearly all types of memories, including RAM, ROM, FLASH, and disk memories.

**References:**
[1] H. Baucer, B. Ganter, and F. Hergert. Algebraic techniques for nonlinear codes. In Combinatoria, volume 3, pages 21–33, 1983.
[2] D. Bhattacharryya and S. Nandi. An efficient class of SEC-DED-AUED codes. In Third International Symposium on Parallel Architectures, Algorithms, and Networks, 1997.
[3] C. Carlet and C. Ding. Highly nonlinear mappings. Journal of Complexity, 20(2-3), 2004.
[4] C. L. Chen. Error-correcting codes with byte error-detection capability. Computers, IEEE Transactions on, C-32:615–621, July 1983.
[5] C. L. Chen. Symbol error correcting codes for memory applications. In Proceedings of the The Twenty-Sixth Annual International Symposium on Fault-Tolerant Computing (FTCS’96), 1996.
[6] L. A. Dunning. SEC-BED-DED codes for error control in byte-organized memory systems. IEEE Transaction on Computer, 34:557–562, 1985.
[7] A. Dutta and N. A. Touba. Multiple bit upset tolerant memory using a selective cycle avoidance based SEC-DED-DAEC code. In 25th IEEE VLSI Test Symposium (VTS’07), 2007.
[8] A. Eto, M. Hidaka, Y. Okuyama, K. Kimura, and M. Hosono. Impact of neutron flux on soft errors in MOS memories. In Electron Devices Meeting, 1998.
[9] T. Etzion and A. Vardy. Perfect binary codes: Constructions, properties, and enumeration. In IEEE Trans. on Information Theory, volume 40, pages 754–763, 1994.
[10] G. Gaubatz, B. Sunar, and M. G. Karpovsky. Non-linear residue codes for robust public-key arithmetic. In Workshop on Fault Diagnosis and Tolerance in Cryptography (FDTC’06), 2006.
[11] G. Georgakos, P. Huber, M. Ostermayr, E. Amirante, and F. Ruckerbauer. Investigation of increased multi-bit failure rate due to neutron induced SEU in advanced embedded SRAMs. In Symposium on VLSI Circuits Digest of Technical Paper, 2007.
[12] T. R. Halfhil. Z-RAM shrinks embedded memory. Technical report, Microprocessor Report, Oct 2005.
[13] R. W. Hamming. Error correcting and error detecting codes. The Bell System Technical Journal, 1950.
[14] M. Y. Hsiao. A class of optimal minimum odd-weight-column SEC-DED codes. IBM Journal of Research and Development, 14:395–401, 1970.
[15] A. H. Johnston. Scaling and technology issues for soft error rates. 4th Annual Research Conference on Reliability, 2000.
[16] M. G. Karpovsky, K. Kulikowski, and A. Taubin. Differential fault analysis attack resistant architectures for the advanced encryption standard. Proc. IFIP World Computing Congress, Cardis, pages 177–193, Aug 2004.
[17] M. G. Karpovsky, K. Kulikowski, and A. Taubin. Robust protection against fault-injection attacks on smart cards implementing the advanced encryption standard. Proc. Int. Conference on Dependable Systems and Networks (DSN2004), July 2004.
[18] M. G. Karpovsky, K. Kulikowski, and Z. Wang. Robust error detection in communication and computation channels. In Int. Workshop on Spectral Techniques, 2007.
[19] M. G. Karpovsky and A. Taubin. A new class of nonlinear systematic error detecting codes. IEEE Trans. Info. Theory, 50(8):1818–1820, 2004.
[20] K. Kulikowski, Z. Wang, and M. G. Karpovsky. Comparative analysis of fault attack resistant architectures for private and public key cryptosystems. In Proc. of Int. Workshop on Fault-tolerant Cryptographic Devices, 2008.
[21] P. K. Lala. An adaptive double error correction scheme for semiconductor memory systems. Digital processes, 4:237–243, 1978.
[22] P. K. Lala. A single error correcting and double error detecting coding scheme for computer memory systems. In Proceedings of the 18th IEEE International Symposium on Defect and Fault Tolerance in VLSI Systems, 2003.
[23] J. Maiz, S. Hareland, K. Zhang, and P. Armstrong. Characterization of multi-bit soft error events in advanced SRAMs. In IEEE Int’l Electronic Device Meeting, pages 519–522, December 2003.
[24] M. Mollard. A generalized parity function and its use in the construction of perfect codes. In SIAM J. Alg. Disc. Meth., volume 7, pages 113–115, 1986.
[25] S. K. Moore. Masters of memory. IEEE Spectrum, 44(1):45–49, Jan 2007.
[26] L. Penzo, D. Sciuto, and C. Silvano. Construction techniques for systematic SEC-DED codes with single byte error detection and partial correction capability for computer memory systems. IEEE Transactions on Information Theory, 41(2), March 1995.
[27] K. T. Phelps. A combinatorial construction of perfect codes. In SIAM J. Alg. disc. Meth., volume 4, pages 398–403, 1983.
[28] K. T. Phelps. A general product construction for error-correcting codes. In SIAM J. Alg. disc. Meth., volume 5, pages 224–228, 1984.
[29] K. T. Phelps and M. Levan. Kernels of nonlinear Hamming codes. Designs, Codes and Cryptography, 6, 1995.
[30] S. M. Reddy. A class of linear codes for error control in byte-per-card organized digital systems. Computer, IEEE Transanction on, C-27:455–459, May 1978.
[31] S. Satoh, Y. Tosaka, and S. A. Wender. Geometrical effect of multiple-bit soft errors induced by cosmic ray neutrons on DRAMs, June 2000.
[32] F. I. Solov’eva. On binary nongroup codes. In Methodi Diskr. Analiza, volume 37, pages 65–76, 1981.
[33] G. M. Swift. In-flight observations of multiple-bit upset in DRAMs. IEEE Trans. Nuclear Science, 47, 2001.
[34] S. Tam. Application Note: Single Error Correction and Double Error Detection. XILINX, 2006.
[35] J. L. Vasil’ev. On nongroup close-packed codes. In Probl. Kibernet., volume 8, pages 375–378, 1962.
[36] S. R. Whitaker, K. Cameron, G. Maki, J. Canaris, and P. Owsley. VLSI Reed-Solomon processor for the Hubble Space Telescope. In VLSI Signal Processing IV, IEEE Press, 1991.