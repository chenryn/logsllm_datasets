distinction 
the 
three-way 
group incompatible, 
two. This results 
is when a newly occurring 
fault threshold 
fault surpasses 
the already 
in  the need for configuring 
where we downgrade 
and renders 
the group size to 
the  memory 
existing 
controller  to  monitor 
to faulty PCM page and MAPPDR tables to handle the 
relevant group 
size information. 
for the group sizes corresponding 
On a read to a main memory page kl' we first determine 
whether the target page is faulty or not. If kl is not faulty, 
as usual. If it is  faulty,  we 
we obtain the corresponding 
on 
we use 
proceeds 
Upon reading 
As the result, 
for the corresponding 
ECC parity bits) to determine 
of faulty bytes. Once the memory requests 
are issued by the memory 
group blocks depending 
the blocks, 
the memory request 
whether kl is in MAPPDR or in MAPMDR. The 
determine 
accesses to MAPPDR and MAPMDR can be performed 
in parallel. 
on this group of blocks k2, k3, and P for PDR, 
information 
, the information about the group block, k2 
or alternatively
for MDR. Extra memory requests 
controller 
the PDRlMDR mapping. 
the faulty byte vector (reused 
the locations 
satisfied, 
PDR parity or the MDR mirror. 
requests 
by saturating 
are on the critical 
overheads, 
read buffer that stores  reconstructed 
be used.  Such  optinrizations 
to otherwise 
be taken to ensure  that 
actual PCM and parity blocks, 
all times. To ensure 
should make sure to invalidate 
such as a temporary 
memory blocks shall 
can offer faster read accesses 
however, care should 
block for kl is reconstructed 
keeping them consistent 
data consistency, every write operation 
are 
based on the 
or update the appropriate 
lead to a performance 
write accesses properly 
faulty memory blocks, 
We note that these extra 
could potentially 
optimizations 
the bus bandwidth 
path. In order to reduce the performance 
and delaying 
additional 
the reads that 
bottleneck 
the  data 
update  the 
read 
at 
buffer  entr
path, lazy invalidate 
buffer entries. 
ies. Since writes are off the performance-critical 
mapping cache depending 
on 
or update schemes can be used for read 
scheme under which the 
requested 
On a write to a main memory page kl' we also determine 
whether the target page is faulty or not.  If 
the corresponding 
In case of MDR, we issue two memory requests 
group blocks from the mapping tables. 
k2. For PDR, we need to update only kl and corresponding 
to kl and 
faulty, 
we find 
P. Therefore, 
parity, 
for a write under RePRAM is always two, instead 
memory requests 
the number of memory requests 
of (n+ 1) 
needed for a read. 
needed 
B. Hardware Implementation 
may remove an entry from the mapping 
( 1 )  when one of the PCM 
(more than 160 bit 
or (2) when PDR to 
failure 
reasons: 
in  the corresponding 
created 
the dynamic redundancy 
page is mapped. We 
caches for the following 
pages has suffered permanent 
errors) and needs decommissioning, 
MDR remapping  needs to 
complexity 
2, we would continue 
different 
from three to two, previously 
reorganized 
entries from 
and would require 
CACHEpDR. 
separate 
We  use  a 
be done due to increased 
associated with PDR. Note that, under Dim-
matching 
group sizes. However, due to decreasing 
to remain in PDR mode, but with 
group size 
DRAM buffer to  store 
the parity for 
formed groups may need to be 
us to flush the corresponding 
The primary goal for  RePRAM 
implementation 
of hardware 
design. 
impact  resulting  from 
our proposed 
affect the  normal 
lower the cost and complexity 
performance 
changes should not adversely 
performance. Figure 2 shows the hardware 
are needed to implement 
effective 
that 
the RePRAM scheme in a cost­
manner with low performance 
overheads. 
structures 
is to 
Also, the 
hardware 
processor 
The first task is to find out whether a page is pristine 
or has 
faulty pages 
is to make 
to detecting 
perform additional 
readback 
whether the write  succeeded 
after a write 
[9]. However, 
during every 
requests 
can be time consuming 
and hence, we use 
such as Bloom Filters 
[2] to record 
about the faulty pages. Once we determine 
the 
repeated 
read-after-write 
status of the  page, 
faults.  A naive approach 
memory controller 
to determine 
performing 
write operation 
compact structures 
information 
faulty/pristine 
(fault-free) 
while the faulty pages can be directed 
MAP structure
Bloom Filters 
i.e., 
does not have faults. Fortunately
negligible 
be addressed 
by checking 
of the MAP tables  or 
vector associated with the 
by directly 
PCM page. 
a page may be reported 
rate of false alarms, 
pages to directly 
, our experiments 
such cases can 
if the page has an entry in one 
and usually 
show a 
reading  the 
faulty byte 
access the memory as  usual, 
to lookup one of the 
as 
for false 
a potential 
positives, 
is that they have 
to be faulty when it actually 
we  can allow  the 
pristine 
by two 
to PCM in this regard. 
for parity. 
than data itself 
on additional 
Note that the parity 
needs to be accurate 
and cannot have errors in 
than simply investing 
This is mainly motivated 
processor, which we believe 
the data from faulty PCM block. DRAM 
So,  DRAM buffer can be a lot smaller 
fast data access and  does  not 
problem. 
faster access by the multi-core 
is more cost-effective 
PCM capacity 
facts: ( 1 )  DRAM provides 
suffer from write endurance 
information 
order to recover 
buffer offers a much better alternative 
(2) The parity information is much smaller 
-
for a group of n data pages, there is only one corresponding 
parity  page. 
the actual PCM-based 
parity  information 
DRAM buffer only offers volatile 
problem, 
proposed 
to store the contents 
evaluation 
of using 
DRAM buffers can easily outweigh 
DRAM buffer (that can be handled through  other 
low-cost 
mechanisms). In this work, we use off-the-shelf 
components 
in our hardware 
modifications 
the hardware 
pages would share the lower level disk for backup storage. 
than 
is that 
however, 
power failure 
this 
such as Brant et al. [3] have 
of DRAM. As we will observe in our 
(Section IV), fast accesses to parity offered 
prior techniques 
a low cost, battery-powered 
extensive 
es. We note that both 
Flash RAM  backup 
could be lost  during 
RAM. A caveat, 
the data and parity 
design without 
To  counter 
the demerits 
storage. 
structur
as 
by 
to 
s. One caveat with using  structures  such 
Finally, we would need to discard 
pages that have 
more 
Once the pages are determined 
to be faulty, 
the next 
to the faulty PCM 
necessary parity 
is managed by the OS and 
of the OS for mapping lookups 
data page for a read or update  the 
on a write corresponding 
step is to check the associated mapping under MAPPDR 
(and MAPMDR too for Dim-I). This is to reconstruct 
the 
original 
information 
page. The mapping information 
frequent invocation 
in expensive 
use limited-entry 
caches, 
to temporarily 
In our current 
buffer caches to store the mappings. 
similar 
miss in both the mapping  caches, 
is invoked and a mapping lookup is performed. An entry  is 
we 
CACHEpDR and CACHEMDR 
store MAPPDR and M APMDR respectively. 
implementation, 
overheads. Hence, to speedup this process, 
we use two small 1024-entry 
This organization 
to Translation 
Buffers (TLB). Upon a 
the OS service 
Lookaside 
can result 
routine 
is 
these pages for per­
To do so, during rematching 
of pages (when 
than 160 bit errors and decommission 
manent failure. 
pages become incompatible 
same byte position), 
have more than 1 60 bit errors. We 
pages for removal, 
reconstitute 
page under MDR or PDR. 
we determine 
upon errors 
and invoke the remapping 
algorithm 
the other group pages associated with the failed 
to 
in the corresponding 
if the candidate 
permanently 
pages 
mark such 
C. Software Support for RePRAM 
In RePRAM, the OS is responsible 
for managing the 
mapping of faulty PCM pages, as well as parity pages. 
The  OS  maintains 
buffer, and the candidate 
beginning, 
the free  list 
list for faulty PCM pages. In the 
all the pages in  the 
two lists, 
contains 
the free list for DRAM parity 
DRAM 
new group of compatible faulty 
PCM 
parity and this information 
buffer. Upon forming a 
pages, one entry from DRAM buffer free list is allocated 
storing 
When the group is disbanded 
the pages, the OS will put the corresponding 
back into the free list. When the free list is empty, the OS 
will stop the matching 
for 
in  the OS. 
due to incompatibility 
among 
is maintained 
process. 
parity  page 
into the candidate 
list 
The OS performs 
The OS invokes 
the matching 
detects 
algorithm 
every time when 
a new faulty page or if 
with its group pages. This 
pages can be paired. 
from the candidate 
the memory controller 
a page becomes incompatible 
new faulty PCM page is inserted 
where compatible 
random selection 
group of the compatible 
matched, 
that our experiments 
incompatibility between 
Remapping 
faults occurring 
overhead 
for page remapping. 
happens far less frequently 
in pages, which greatly 
pages.  After a 
page is successfully 
list. Note 
show that not every fault result in 
IV-D). 
the group pages (see Section 
it will be removed from the candidate 
list to quickly 
form a 
than the number 
of 
reduces the OS 
The OS manages the mapping between faulty PCM pages 
that we need to maintain 
area of the 
overhead 
for every page, the worst case 
for a 4GB PRAM  with 4KB pages would 
Also, that 
is stored in a reserved 
Assuming 
using a hash table  that 
memory  address  space. 
the mapping information 
storage 
only be 2.5MB (20 bits per page for 1M pages). 
the OS intervent
information 
performance 
the help of mapping  caches 
RePRAM is able to minimize 
wide range of the benchmarks. 
should be kept minimal in order to avoid high 
overheads. As  we show in Section 
IV, with 
and dynamic redundancy 
ions for accessing 
performance 
and updating 
impacts on a 
the mapping 
levels, 
0.' I-------------\Jr__--A\+_ 
\  ,i 
-1-Tl-· 
- 11-\- --
0.81------------
l lL 
.f07 1-------------+-1-\ ----..'1 
[0.6 
\.  'i­
1---------
--\---'_,- j 
 0.5 -FAILSTOP 
>  ..... DRM 
0.4 
L 
i 
c_  i-
w  0.3  _ -ECP 
i 
r 
0.1 1--------------I--'r--l'J-
+-. 
0.2 ······Dim-2 
-6-Dim-l 
a 
w 
w 
.. 
m 
M 
0.' 
0.8 
-6-Dim-l 
0.2 ······Dim-2 
    lW      1 1  
(a) variance=O.l 
a-----j-H-
Writes 
to PCM memory (trillions) 
l 
\""'\,---------- \  i 
-I-I-i-
,--'\- -------
\ \. 
0.7 1- --- -\--'\---------4--' -
Ii 
-"  \ \ 
,i 
- ---I:---+  ..... DRM  \ 
I---I---- - -l-----
I-'--
"'B 0.4 
Ii, 
!i 0.3  --ECP 
I,L. 
. Ii 
0.1 I-------
I------
Ii 
Writes 
to PCM memory (trillions) 
r----------,._ ::_ .... -,- ...... -.., .. 
 --------
0.7 
U a. 0.6  GI O.S 
 1'-
I ------
> tl 0.4  0.3 
,-1--
r--
(b) variance=O.2 
\ 
--
\ 
-\- -\4\-  -
. 
\  '. 
- +\--\-r--.l I  i 
.,  I i 
LJI-­, i 
Ir-\ 
\ 
STOP 
FAIL 
I--r----
-6-Dim-l --ECP 
I---\-----
······Oim-2 
Writes 
to PCM memory (trillions) 
ro  15  20  25    3S        
..... DRM 
0.' 
0.1 
0.2 
0.8 
(c) variance=O.3 
capacity 
versus the total number of writes issued to 
IV. EVALUATION 
We first perform the experiments 
to analyze 
the extended 
through RePRAM, and next 
Finally, we present the 
impact arising 
from our proposed 
studies 
of our system under various 
sensitivity 
changes. 
that can be achieved 
lifetime 
study the performance 
hardware 
that show the performance 
configurations. 
schemes, 
derived 
from  earlier 
our configuration 
To present 
fair comparison 
results 
with prior 
parameters  are 
similar 
works such as DRM  [9]  and 
to, and 
ECP [24]. 
Figure 3. Effective 
the PCM main memory. 
A. Lifetime 
Figure 3 compares 
the lifetime  (measured 
as the total 
effective 
We show the results  corresponding 
capacity  left 
in  the PCM 
to both Dim-
number of writes that can be performed to the PCM) along 
with the diminishing 
device. 
1 and Dim-2 design choices, 
them with prior 
schemes such as Fail_Stop (that does not have any Error 
Correction 
the first fault occurs), 
a baseline of 4GB PCM memory with 
write operations  happen 
and discards 
DRM  and ECP schemes. 
on a granularity 
a PCM block as soon as 
of 64Byte blocks. 
capabilities 
4KB page size, and 
and contrast 
We assume 
would flip a particular 
we assume a 50% probability 
In addition, 
write operation 
PCM cell lifetime to follow a normal distribution 
mean of 108 and three different process variation 