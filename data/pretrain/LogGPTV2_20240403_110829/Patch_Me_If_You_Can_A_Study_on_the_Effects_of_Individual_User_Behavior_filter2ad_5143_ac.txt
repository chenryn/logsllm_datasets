First quartile
Third quartile
60
80
40
20
Patch delay (days)
40
20
Patch delay (days)
60
(a)
(b)
Fig. 3. Scatter plot (left) and mean, and ﬁrst and third quartiles (right) for exploited
vulnerabilities of Flash Player.
Patch Me If You Can: A Study on the Eﬀects of Individual User Behavior
121
3.4 Factors that Impact User Behavior
Version-speciﬁc factors. Suppose we take an interval of size 2T and look at
the total number of updating events that occur within the ﬁrst and second half
of the interval, across all users and for a speciﬁc subset of releases of a given
product, and denote these by N1 and N2, respectively. We can then deﬁne a
population-wide willingness to update as W = 1 − (N2/N1)1/T . When looking
at a period immediately following a release, if more users consider a new patch
important and apply the patch promptly, then W tends to be high. Conversely,
if more users hesitate to install the new patch, then more patching events occur
at the second half of observation period resulting in a lower W .
For Firefox and Flash Player, we extract four features Ivulns, Ibugs, If eats,
and ImajV er, as described in Sect. 2. For each feature, we split the versions into
two groups: those that have the feature and those that do not, and measure
W within each group. We then conduct a statistical hypothesis test to deter-
mine if the updates from one group are deployed faster than the ones from the
other group. Speciﬁcally, we perform a T-test between two groups with the null
hypothesis “There is no diﬀerence in the mean of W ”. Low p-values from the
T-test indicate that the factor aﬀects the user’s behavior. Here, we choose the
signiﬁcance level α = 0.05. As we perform multiple hypothesis tests on the same
data set, increasing the likelihood that we will ﬁnd a signiﬁcant result by pure
chance, we apply the Bonferroni correction [1], by dividing α by the number of
hypotheses tested. The adjusted α is 0.0125. The results are shown in Table 3.
ImajV er for Firefox is the only factor with p-value below 0.05. However, this is
not statistically signiﬁcant after applying Bonferroni correction. This indicates
that changes in versions have no statistically signiﬁcant eﬀect on user behavior.
Note that our results do not necessarily reﬂect users’ indiﬀerence to these
categorizations. In a recent user study [15], 80% of users state that update cate-
gories can inﬂuence their decision on applying a software update, and two-thirds
react positively to a prototype that tags each update with one of ﬁve categories.
Our results indicate that for the examined products, this information may not
be readily available (we had to manually tag the release notes ourselves), which
in turn causes users to behave independently of the update’s intent.
Diﬀerent countries and patch delivery. Table 4 shows the average time to
patch for the top 10 countries with the largest numbers of users. Note that
Chrome uses silent updates, and therefore has the lowest patch times. Firefox
and Thunderbird versions prior to 15.0, and 16.0 (released 2012-08-28, and 2012-
10-09, respectively) download updates in the background and prompt users for
installation. Flash Player versions prior to 11.2 (released 2012-03-28) prompt
users to download and install updates, and consequently exhibit the longest
patch times. All three products switch to silent updates after the indicated dates;
however these changes do not apply to the majority of our samples. For all four
products, patching behavior is remarkably consistent, suggesting that cultural
diﬀerences among these countries do not play a signiﬁcant role in user behavior.
122
A. Sarabi et al.
Table 3. p-values from T-test on version-
speciﬁc factors.
Application
Ivulns
Flash Player 0.860
Ibugs
0.416
If eats
0.736
ImajV er
0.419
Firefox
0.109
0.226
0.126
0.027
Table 4. Average patch times by country.
Country Chrome Firefox Flash Thunderbird
All
AU
CA
DE
FR
IT
JP
NL
PL
UK
US
9.9
10.6
10.4
10.9
10.4
8.8
13.0
10.4
8.2
9.2
10.5
15.6
16.3
15.6
15.3
16.2
15.9
14.2
15.2
13.8
15.7
15.5
29.7
30.1
30.7
24.9
28.8
26.1
26.6
28.5
26.9
28.3
32.1
15.2
15.1
14.6
14.7
14.4
13.5
16.3
14.7
14.2
13.9
15.4
4 Related Work
Rescorla [23] studied a 2002 OpenSSL vulnerability and observed two waves of
patching: one in response to the vulnerability disclosure and one after the release
of the Slapper worm exploit. Ramos [21] analyzed several remotely-exploitable
vulnerabilities and reported a slow decay rate in some cases and some vulner-
abilities that did not decay at all. Yilek et al. [30] scanned OpenSSL servers
aﬀected by a 2008 key generation vulnerability in Debian Linux and found a
high patch rate in the ﬁrst 30 days, followed by patching waves for the next six
months. Durumeric et al. [11] showed that more than 50% of servers aﬀected
by the recent Heartbleed vulnerability in OpenSSL remained vulnerable after
three months. Zhang et al. [31] showed that, even after patching OpenSSL, most
websites remained vulnerable because they had not revoked certiﬁcates that may
have been compromised owing to Heartbleed. The rate of updating is consider-
ably higher for systems that employ automated updates [9,13]. Gkantsidis et al.
[13] concluded that 80% of Windows Update users receive patches within 24 h
after their release. D¨ubendorfer et al. [9] suggested that Google Chrome’s silent
update mechanism is able to update 97% of active browser instances within 21
days. Nappa et al. [17], measured vulnerability decay in 10 client-side applica-
tions and identiﬁed security threats presented by multiple installations of the
same program and by shared libraries distributed with several applications.
Alhazmi and Malaiya [2] examined ﬁve diﬀerent vulnerability discovery mod-
els, ﬁtting the models using data from three operating systems.
On factors that may aﬀect vulnerability patching and user behavior, Schneider
and Schneider [16] proposed several hypotheses, including an under-appreciation
of risks and a fear of destabilizing other software. Vaniea et al. [29] suggested
that negative experiences with past updates aﬀect the users’ willingness to deploy
patches. Mathur et al. [15] study 30 users’ updating practices, and design and eval-
uate a prototype updating interface based on their feedback.
Patch Me If You Can: A Study on the Eﬀects of Individual User Behavior
123
5 Conclusions
In this paper we have conducted an in-depth analysis of the dynamics between
vendors and consumers when it comes to software security. To the best of our
knowledge, this is the ﬁrst study on how individual behavior can inﬂuence the
security state of a user’s machine over long periods, where the continuous dis-
covery of vulnerabilities, patch deployment by vendors, and the installation of
patches create windows of opportunities for malicious entities to exploit open
vulnerabilities on the machine. We have shown that frequent updating, and
steps taken by vendors to speed up the installation of patches, provide marginal
beneﬁts when the rate at which new vulnerabilities are introduced into the prod-
uct’s code is high. Consequently, developers’ should exercise due diligence when
shipping new products to end-users, as the detrimental eﬀects of releasing vul-
nerable applications to the public often cannot be eliminated by prompt patch
deployment.
Our results also represent a ﬁrst step toward understanding the deployment-
speciﬁc barriers for updating software. We observe that user behavior can
be modeled well using a simple and elegant mathematical model. We do not
observe clusters of users with respect to the patching delay or the vulnerability
state. Moreover, users do not make patching decisions depending on the type of
improvements introduced with each new release (possibly due to how this infor-
mation is presented), and the willingness to patch does not vary signiﬁcantly
across diﬀerent countries. However, users seem to exhibit diﬀerent behavior for
diﬀerent products, suggesting that vendors may be able to inﬂuence the users’
patching delays. For example, Fig. 2 suggests that the vulnerability duration for
Flash Player exhibits a lower variability than for Chrome and Firefox, despite
the lack of a silent updating mechanism. This consistency may result from the
fact that users are compelled to upgrade when sites remove backward compat-
ibility for older Flash versions. A deeper understanding of these barriers could
enable improvements in the software updating process.
Although we have shown that users’ behavior can eﬀectively be explained
using a simple model, we are not able to build similar proﬁles for vendors. This
is partly due to lack of a large data set on software vulnerability cycles. The
set of unique vulnerability disclosures and patch deployments concerning the
products under examination was too small to carry out a comprehensive study
on product behavior. Such an analysis could close the loop when assessing the
security posture of an end-user, by predicting the host’s vulnerability state across
diﬀerent products, or for new products entering the market. Finally, leveraging
additional data sources that can reveal the whole extent of user behavior, such
as extending the study to other operating systems, and measuring periods of
time where the system or a speciﬁc application are not used (this would lead to
an overestimation of the vulnerability window in our current analysis) are other
possible directions for future work.
124
A. Sarabi et al.
References
1. Abdi, H.: Bonferroni and ˇSid´ak corrections for multiple comparisons. Sage (2007)
2. Alhazmi, O., Malaiya, Y.: Modeling the vulnerability discovery process. In: Inter-
national Symposium on Software Reliability Engineering (2005)
3. Alhazmi, O., Malaiya, Y., Ray, I.: Measuring, analyzing and predicting security
vulnerabilities in software systems. Comput. Secur. 26(3), 219–228 (2007)
4. Arbaugh, W., Fithen, W., McHugh, J.: Windows of vulnerability: a case study
analysis. IEEE Comput. 33(12), 52–59 (2000)
5. Arora, A., Krishnan, R., Nandkumar, A., Telang, R., Yang, Y.: Impact of vulner-
ability disclosure and patch availability - an empirical analysis. In: Workshop on
the Economics of Information Security (2004)
6. Bilge, L., Dumitra¸s, T.: Before we knew it: an empirical study of zero-day attacks
in the real world. In: ACM Conference on Computer and Communications Security
(2012)
7. Cavusoglu, H., Cavusoglu, H., Raghunathan, S.: Emerging issues in responsible
vulnerability disclosure. In: Workshop on Information Technology and Systems
(2004)
8. Clark, S., Collis, M., Blaze, M., Smith, J.: Moving targets: security and rapid-
release in Firefox. In: ACM SIGSAC Conference on Computer and Communica-
tions Security (2014)
9. Duebendorfer, T., Frei, S.: Web browser security update eﬀectiveness. In: Rome,
E., Bloomﬁeld, R. (eds.) CRITIS 2009. LNCS, vol. 6027, pp. 124–137. Springer,
Heidelberg (2010). doi:10.1007/978-3-642-14379-3 11
10. Dumitra¸s, T., Shou, D.: Toward a standard benchmark for computer security
research: the worldwide intelligence network environment (WINE). In: Workshop
on Building Analysis Datasets and Gathering Experience Returns for Security
(2011)
11. Durumeric, Z., Kasten, J., Adrian, D., Halderman, J.A., Bailey, M., et al.: The
matter of heartbleed. In: Internet Measurement Conference (2014)
12. Exploit kits. http://contagiodump.blogspot.com
13. Gkantsidis, C., Karagiannis, T., Rodriguez, P., Vojnovic, M.: Planet scale software
updates. In: ACM SIGCOMM Computer Communication Review (2006)
14. Grier, C., Ballard, L., Caballero, J., Chachra, N., Dietrich, C., et al.: Manufac-
turing compromise: the emergence of exploit-as-a-service. In: ACM Conference on
Computer and Communications Security (2012)
15. Mathur, A., Engel, J., Sobti, S., Chang, V., Chetty, M.: “They keep coming back
like zombies”: improving software updating interfaces. In: Symposium on Usable
Privacy and Security (2016)
16. Mulligan, D., Schneider, F.: Doctrine for cybersecurity. Daedalus, J. Am. Acad.
Arts Sci. 140(4), 70–92 (2011)
17. Nappa, A., Johnson, R., Bilge, L., Caballero, J., Dumitra¸s, T.: The attack of the
clones: a study of the impact of shared code on vulnerability patching. In: IEEE
Symposium on Security and Privacy (2015)
18. Neuhaus, S., Zimmermann, T., Holler, C., Zeller, A.: Predicting vulnerable software
components. In: ACM Conference on Computer and Communications Security
(2007)
19. NIST: National Vulnerability Database. https://nvd.nist.gov
20. Ozment, A., Schechter, S.: Milk or wine: does software security improve with age?
In: USENIX Security Symposium (2006)
Patch Me If You Can: A Study on the Eﬀects of Individual User Behavior
125
21. Ramos, T.: The laws of vulnerabilities. In: RSA Conference (2006)
22. Rescorla, E.: Is ﬁnding security holes a good idea? In: IEEE Security and Privacy
(2005)
23. Rescorla, E.: Security holes. . . who cares. In: USENIX Security Symposium (2003)
24. Sabottke, C., Suciu, O., Dumitra¸s, T.: Vulnerability disclosure in the age of social
media: exploiting Twitter for predicting real-world exploits. In: USENIX Security
Symposium (2015)
25. Shahzad, M., Shaﬁq, M., Liu, A.: A large scale exploratory analysis of software vul-
nerability life cycles. In: International Conference on Software Engineering (2012)
26. Shankland, S.: Heartbleed bug undoes web encryption, reveals Yahoo passwords
(2014). http://www.cnet.com/news/heartbleed-bug-undoes-web-encryption-
reveals-user-passwords
27. Software release dates. http://bit.ly/2jKrMPj
28. Symantec Corporation: Symantec threat explorer (2012). http://www.symantec.
com/security response/threatexplorer/azlisting.jsp
29. Vaniea, K., Rader, E., Wash, R.: Betrayed by updates: how negative experiences
aﬀect future security. In: ACM Conference on Human Factors in Computing (2014)
30. Yilek, S., Rescorla, E., Shacham, H., Enright, B., Savage, S.: When private keys
are public: results from the 2008 Debian OpenSSL vulnerability. In: Internet Mea-
surement Conference (2009)
31. Zhang, L., Choﬀnes, D., Dumitra¸s, T., Levin, D., Mislove, A., et al.: Analysis of
SSL certiﬁcate reissues and revocations in the wake of Heartbleed. In: Internet
Measurement Conference (2014)