# Patch Me If You Can: A Study on the Effects of Individual User Behavior

## 3.4 Factors that Impact User Behavior

### Version-Specific Factors
To analyze version-specific factors, we consider an interval of size \(2T\) and examine the total number of updating events in the first and second halves of this interval, denoted as \(N1\) and \(N2\), respectively. We define a population-wide willingness to update, \(W\), as:
\[ W = 1 - \left(\frac{N2}{N1}\right)^{1/T} \]

If more users promptly apply a new patch, \(W\) will be high. Conversely, if users hesitate, more patching events will occur in the second half, resulting in a lower \(W\).

For Firefox and Flash Player, we extracted four features: \(Ivulns\), \(Ibugs\), \(Ifreats\), and \(ImajVer\). We split the versions into two groups (those with the feature and those without) and measured \(W\) within each group. We then conducted a T-test with the null hypothesis: "There is no difference in the mean of \(W\)." Low p-values indicate that the factor affects user behavior. We set the significance level \(\alpha = 0.05\). To account for multiple hypothesis tests, we applied the Bonferroni correction, adjusting \(\alpha\) to 0.0125. The results are shown in Table 3.

**Table 3: p-values from T-test on version-specific factors.**

| Application | Ivulns | Ibugs | Ifreats | ImajVer |
|-------------|--------|-------|---------|---------|
| Flash Player | 0.860 | 0.416 | 0.736 | 0.419 |
| Firefox | 0.109 | 0.226 | 0.126 | 0.027 |

Only \(ImajVer\) for Firefox had a p-value below 0.05, but it was not statistically significant after Bonferroni correction. This suggests that version changes do not significantly affect user behavior.

### Different Countries and Patch Delivery
Table 4 shows the average time to patch for the top 10 countries with the largest numbers of users. Chrome, which uses silent updates, has the lowest patch times. Firefox and Thunderbird versions prior to 15.0 and 16.0, respectively, download updates in the background and prompt users for installation. Flash Player versions prior to 11.2 prompt users to download and install updates, leading to the longest patch times. All three products switched to silent updates after the indicated dates, but these changes did not apply to most of our samples. The consistency in patching behavior across countries suggests that cultural differences do not significantly impact user behavior.

**Table 4: Average patch times by country.**

| Country | Chrome | Firefox | Flash | Thunderbird |
|---------|--------|---------|-------|-------------|
| AU      | 9.9    | 10.6    | 15.5  | 15.2        |
| CA      | 10.4   | 16.3    | 29.7  | 14.6        |
| DE      | 10.9   | 15.6    | 30.1  | 14.7        |
| FR      | 10.4   | 15.3    | 30.7  | 14.4        |
| IT      | 8.8    | 16.2    | 24.9  | 13.5        |
| JP      | 13.0   | 15.9    | 28.8  | 16.3        |
| NL      | 10.4   | 14.2    | 26.1  | 14.7        |
| PL      | 8.2    | 15.2    | 28.5  | 14.2        |
| UK      | 9.2    | 13.8    | 26.9  | 13.9        |
| US      | 10.5   | 15.7    | 28.3  | 15.4        |
| All     | 9.9    | 15.6    | 29.7  | 15.2        |

## 4 Related Work

- **Rescorla [23]** studied a 2002 OpenSSL vulnerability and observed two waves of patching: one after the vulnerability disclosure and one after the release of the Slapper worm exploit.
- **Ramos [21]** analyzed several remotely-exploitable vulnerabilities and reported a slow decay rate in some cases and some vulnerabilities that did not decay at all.
- **Yilek et al. [30]** scanned OpenSSL servers affected by a 2008 key generation vulnerability in Debian Linux and found a high patch rate in the first 30 days, followed by patching waves for the next six months.
- **Durumeric et al. [11]** showed that more than 50% of servers affected by the Heartbleed vulnerability in OpenSSL remained vulnerable after three months.
- **Zhang et al. [31]** showed that even after patching OpenSSL, most websites remained vulnerable due to unrevoked certificates potentially compromised by Heartbleed.
- **Gkantsidis et al. [13]** concluded that 80% of Windows Update users receive patches within 24 hours after their release.
- **Dübendorfer et al. [9]** suggested that Google Chrome’s silent update mechanism can update 97% of active browser instances within 21 days.
- **Nappa et al. [17]** measured vulnerability decay in 10 client-side applications and identified security threats presented by multiple installations of the same program and shared libraries distributed with several applications.
- **Alhazmi and Malaiya [2]** examined five different vulnerability discovery models, fitting the models using data from three operating systems.
- **Schneider and Schneider [16]** proposed several hypotheses, including an under-appreciation of risks and a fear of destabilizing other software.
- **Vaniea et al. [29]** suggested that negative experiences with past updates affect the users’ willingness to deploy patches.
- **Mathur et al. [15]** studied 30 users' updating practices and designed and evaluated a prototype updating interface based on their feedback.

## 5 Conclusions

This study provides an in-depth analysis of the dynamics between vendors and consumers in software security. We show that frequent updating and steps taken by vendors to speed up patch installation provide marginal benefits when the rate of introducing new vulnerabilities is high. Developers should exercise due diligence when releasing new products, as the detrimental effects of releasing vulnerable applications cannot be fully mitigated by prompt patch deployment.

Our results also highlight the deployment-specific barriers for updating software. We observe that user behavior can be modeled using a simple mathematical model. Users do not cluster based on patching delay or vulnerability state, and their willingness to patch does not vary significantly across different countries. However, users exhibit different behaviors for different products, suggesting that vendors may influence patching delays. For example, Flash Player's vulnerability duration is more consistent than Chrome and Firefox, possibly because users are compelled to upgrade when sites remove backward compatibility for older versions.

While we have shown that user behavior can be effectively explained using a simple model, we cannot build similar profiles for vendors due to a lack of large datasets on software vulnerability cycles. Future work could include extending the study to other operating systems and measuring periods where the system or specific applications are not used.

## References

1. Abdi, H.: Bonferroni and Šidák corrections for multiple comparisons. Sage (2007)
2. Alhazmi, O., Malaiya, Y.: Modeling the vulnerability discovery process. In: International Symposium on Software Reliability Engineering (2005)
3. Alhazmi, O., Malaiya, Y., Ray, I.: Measuring, analyzing and predicting security vulnerabilities in software systems. Comput. Secur. 26(3), 219–228 (2007)
4. Arbaugh, W., Fithen, W., McHugh, J.: Windows of vulnerability: a case study analysis. IEEE Comput. 33(12), 52–59 (2000)
5. Arora, A., Krishnan, R., Nandkumar, A., Telang, R., Yang, Y.: Impact of vulnerability disclosure and patch availability - an empirical analysis. In: Workshop on the Economics of Information Security (2004)
6. Bilge, L., Dumitraş, T.: Before we knew it: an empirical study of zero-day attacks in the real world. In: ACM Conference on Computer and Communications Security (2012)
7. Cavusoglu, H., Cavusoglu, H., Raghunathan, S.: Emerging issues in responsible vulnerability disclosure. In: Workshop on Information Technology and Systems (2004)
8. Clark, S., Collis, M., Blaze, M., Smith, J.: Moving targets: security and rapid-release in Firefox. In: ACM SIGSAC Conference on Computer and Communications Security (2014)
9. Dübendorfer, T., Frei, S.: Web browser security update effectiveness. In: Rome, E., Bloomfield, R. (eds.) CRITIS 2009. LNCS, vol. 6027, pp. 124–137. Springer, Heidelberg (2010). doi:10.1007/978-3-642-14379-3_11
10. Dumitraş, T., Shou, D.: Toward a standard benchmark for computer security research: the worldwide intelligence network environment (WINE). In: Workshop on Building Analysis Datasets and Gathering Experience Returns for Security (2011)
11. Durumeric, Z., Kasten, J., Adrian, D., Halderman, J.A., Bailey, M., et al.: The matter of heartbleed. In: Internet Measurement Conference (2014)
12. Exploit kits. http://contagiodump.blogspot.com
13. Gkantsidis, C., Karagiannis, T., Rodriguez, P., Vojnovic, M.: Planet scale software updates. In: ACM SIGCOMM Computer Communication Review (2006)
14. Grier, C., Ballard, L., Caballero, J., Chachra, N., Dietrich, C., et al.: Manufacturing compromise: the emergence of exploit-as-a-service. In: ACM Conference on Computer and Communications Security (2012)
15. Mathur, A., Engel, J., Sobti, S., Chang, V., Chetty, M.: “They keep coming back like zombies”: improving software updating interfaces. In: Symposium on Usable Privacy and Security (2016)
16. Mulligan, D., Schneider, F.: Doctrine for cybersecurity. Daedalus, J. Am. Acad. Arts Sci. 140(4), 70–92 (2011)
17. Nappa, A., Johnson, R., Bilge, L., Caballero, J., Dumitraş, T.: The attack of the clones: a study of the impact of shared code on vulnerability patching. In: IEEE Symposium on Security and Privacy (2015)
18. Neuhaus, S., Zimmermann, T., Holler, C., Zeller, A.: Predicting vulnerable software components. In: ACM Conference on Computer and Communications Security (2007)
19. NIST: National Vulnerability Database. https://nvd.nist.gov
20. Ozment, A., Schechter, S.: Milk or wine: does software security improve with age? In: USENIX Security Symposium (2006)
21. Ramos, T.: The laws of vulnerabilities. In: RSA Conference (2006)
22. Rescorla, E.: Is finding security holes a good idea? In: IEEE Security and Privacy (2005)
23. Rescorla, E.: Security holes... who cares. In: USENIX Security Symposium (2003)
24. Sabottke, C., Suciu, O., Dumitraş, T.: Vulnerability disclosure in the age of social media: exploiting Twitter for predicting real-world exploits. In: USENIX Security Symposium (2015)
25. Shahzad, M., Shaﬁq, M., Liu, A.: A large scale exploratory analysis of software vulnerability life cycles. In: International Conference on Software Engineering (2012)
26. Shankland, S.: Heartbleed bug undoes web encryption, reveals Yahoo passwords (2014). http://www.cnet.com/news/heartbleed-bug-undoes-web-encryption-reveals-user-passwords
27. Software release dates. http://bit.ly/2jKrMPj
28. Symantec Corporation: Symantec threat explorer (2012). http://www.symantec.com/security_response/threatexplorer/azlisting.jsp
29. Vaniea, K., Rader, E., Wash, R.: Betrayed by updates: how negative experiences affect future security. In: ACM Conference on Human Factors in Computing (2014)
30. Yilek, S., Rescorla, E., Shacham, H., Enright, B., Savage, S.: When private keys are public: results from the 2008 Debian OpenSSL vulnerability. In: Internet Measurement Conference (2009)
31. Zhang, L., Choﬀnes, D., Dumitraş, T., Levin, D., Mislove, A., et al.: Analysis of SSL certificate reissues and revocations in the wake of Heartbleed. In: Internet Measurement Conference (2014)