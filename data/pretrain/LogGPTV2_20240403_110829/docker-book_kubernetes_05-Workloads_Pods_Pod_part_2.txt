## 容器探针
 [Probe](https://kubernetes.io/docs/resources-reference/v1.8/#probe-v1-core) 是由[kubelet](https://kubernetes.io/docs/admin/kubelet/) 对容器定期执行的诊断。要执行诊断，Kubelet调用由Container实现的[Handler](https://godoc.org/k8s.io/kubernetes/pkg/api/v1#Handler) 。 有三种类型的handler：
- [ExecAction](https://kubernetes.io/docs/resources-reference/v1.8/#execaction-v1-core)：在Container中执行指定的命令。 如果命令退出的状态码为0，则认为诊断成功。
- [TCPSocketAction](https://kubernetes.io/docs/resources-reference/v1.8/#tcpsocketaction-v1-core) ：对容器IP的指定端口执行TCP检查。如果端口打开，则认为诊断成功。
- [HTTPGetAction](https://kubernetes.io/docs/resources-reference/v1.8/#httpgetaction-v1-core) ：对容器IP的指定端口和路径执行HTTP Get请求。如果响应的状态码大于等于200且小于400，则认为诊断成功。
每个探针都有三个结果之一：
- Success：容器已通过诊断。
- Failure：容器未通过诊断。
- Unknown：诊断失败，因此不会采取任何行动。
kubelet可以选择对运行容器上的两种探针执行和反应：
- `livenessProbe` （活动探针）：指示容器是否正在运行。如活动探测失败，那么kubelet就会杀死容器，并且容器将受到其 [重启策略](https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#restart-policy) 的影响。 如容器不提供活动探针，则默认状态为 `Success` 。
- `readinessProbe` （就绪探针）：指示容器是否准备好服务请求。 如就绪探测失败，Endpoint Controller将会从与Pod匹配的所有Service的端点中删除该Pod的IP地址。初始延迟之前的就绪状态默认为`Failure` 。 如果容器不提供就绪探针，则默认状态为`Success` 。
### 什么时候应该使用活动探针或就绪探针？
如果容器中的进程能够在遇到问题或不健康的情况下自行崩溃，则**不一定需要活动探针**；kubelet将根据Pod的`restartPolicy`自动执行正确的操作。
如果您希望容器在探测失败时被杀死并重新启动，那么请指定一个**活动探针**，并指定`restartPolicy` 为Always或OnFailure。
如果要仅在探测成功时才开始向Pod发送流量，请指定**就绪探针**。在这种情况下，就绪探针可能与活动探针相同，但是spec中存在就绪探针，就意味着Pod会在没有接收到任何流量的情况下启动，并且只在探针探测成功后才开始接收流量。
如果您希望容器能够自己维护，可指定一个**就绪探针**，该探针检查的端点与活动探针不同。
请注意，如果您只想在Pod被删除时排除请求，则**不一定需要就绪探针**；在删除时，Pod会自动将自身置于未完成状态，无论就绪探针是否存在。在等待Pod中的容器停止的过程中，Pod仍处于未完成状态。
## Pod及容器状态
有关Pod容器状态的详细信息，请参阅 [PodStatus](https://kubernetes.io/docs/resources-reference/v1.8/#podstatus-v1-core) 和 [ContainerStatus](https://kubernetes.io/docs/resources-reference/v1.8/#containerstatus-v1-core) 。 请注意，作为Pod状态报告的信息取决于当前的 [ContainerState](https://kubernetes.io/docs/resources-reference/v1.8/#containerstatus-v1-core) 。
## 重启策略
PodSpec有一个`restartPolicy` 字段，可能的值为Always，OnFailure和Never，默认值为Always。 `restartPolicy`适用于Pod中的所有容器。 `restartPolicy` 仅指同一Node上kubelet重启容器时所使用的策略。 失败的容器由kubelet重启，以五分钟上限的指数退避延迟（10秒，20秒，40秒...），并在成功执行十分钟后重置。 如 [Pods document](https://kubernetes.io/docs/user-guide/pods/#durability-of-pods-or-lack-thereof) 中所述，一旦绑定到一个Node，Pod将永远不会重新绑定到另一个Node。
## Pod的寿命
一般来说，Pod不会消失，直到有人销毁它们——可能是人工或Controller去销毁Pod。 这个规则的唯一例外是Pod的`phase` 成功或失败超过一段时间（由Master确定）的Pod将过期并被自动销毁。
有三种类型的Controller可用：
- [Job](https://kubernetes.io/docs/concepts/jobs/run-to-completion-finite-workloads/) ，Pod预期会终止，例如批量计算。Job仅适用于`restartPolicy` 为OnFailure或Never的Pod。
- [ReplicationController](https://kubernetes.io/docs/concepts/workloads/controllers/replicationcontroller/) 、 [ReplicaSet](https://kubernetes.io/docs/concepts/workloads/controllers/replicaset/) 以及 [Deployment](https://kubernetes.io/docs/concepts/workloads/controllers/deployment/) ，Pod预期不会终止，例如Web服务器。 ReplicationController仅适用于`restartPolicy` 为Always的Pod。
- [DaemonSet](https://kubernetes.io/docs/concepts/workloads/controllers/daemonset/) ，每台机器都需要运行一个Pod，因为它们提供特定于机器的系统服务。
以上三种类型的Controller都包含一个PodTemplate。建议创建适当的Controller，让Controller创建Pod，而非直接创建Pod。这是因为单独的Pod在机器故障发生时无法自我修复，而Controller可以。
如果Node挂掉或与集群断开，那么Kubernetes应用一种策略，将故障Node上的所有Pod的`phase`设为Failed。
## 示例
### 高级活动探针示例
活动探测由kubelet执行，因此所有请求都会在kubelet网络命名空间中进行。
```yaml
apiVersion: v1
kind: Pod
metadata:
  labels:
    test: liveness
  name: liveness-http
spec:
  containers:
  - args:
    - /server
    image: gcr.io/google_containers/liveness
    livenessProbe:
      httpGet:
        # when "host" is not defined, "PodIP" will be used
        # host: my-host
        # when "scheme" is not defined, "HTTP" scheme will be used. Only "HTTP" and "HTTPS" are allowed
        # scheme: HTTPS
        path: /healthz
        port: 8080
        httpHeaders:
          - name: X-Custom-Header
            value: Awesome
      initialDelaySeconds: 15
      timeoutSeconds: 1
    name: liveness
```
容器的源码：
```go
http.HandleFunc("/healthz", func(w http.ResponseWriter, r *http.Request) {
    duration := time.Now().Sub(started)
    if duration.Seconds() > 10 {
        w.WriteHeader(500)
        w.Write([]byte(fmt.Sprintf("error: %v", duration.Seconds())))
    } else {
        w.WriteHeader(200)
        w.Write([]byte("ok"))
    }})
```
参考：
### 状态示例
- Pod正在运行，并只有一个容器。容器退出成功。
  - 记录完成事件
  - 如果`restartPolicy`是：
    - Always: 重启容器，Pod的`phase` 保持Running
    - OnFailure: Pod的`phase` 变成Succeeded.
    - Never: Pod的`phase` 变成Succeeded.
- Pod正在运行，并只有一个容器。容器退出失败。
  - 记录失败事件
  - 如果`restartPolicy` 是：
    - Always: 重启容器，Pod的`phase` 保持Running.
    - OnFailure: 重启容器，Pod的`phase` 保持Running.
    - Never: Pod的`phase` 变成Failed.
- Pod正在运行，并且有两个容器，Container 1退出失败。
  - 记录失败事件
  - 如果`restartPolicy` 是：
    - Always：重启容器，Pod的`phase` 保持Running.
    - OnFailure：重启容器; Pod的`phase` 保持Running.
    - Never：不会重启容器，Pod的`phase` 保持Running.
  - 如果Container 1不在运行，Container退出
    - 记录失败事件
    - 如果`restartPolicy` 是：
      - Always：重启容器，Pod的`phase` 保持Running.
      - OnFailure：重启容器，Pod的`phase` 保持Running.
      - Never：Pod的`phase` 变成Failed.
- Pod正在运行，并且只有一个容器，容器内存溢出：
  - 容器失败并终止
  - 记录OOM事件
  - 如果`restartPolicy` 是：
    - Always: 重启容器，Pod的`phase` 保持Running.
    - OnFailure: 重启容器，Pod `phase` 保持Running.
    - Never: 记录失败事件，Pod `phase` 变成Failed.
- Pod正在运行，磁盘损坏：
  - 杀死所有容器
  - 记录适当事件
  - Pod的`phase` 变成Failed
  - 如果Pod是用Controller创建的，Pod将在别处重建
- Pod正在运行，Node被分段
  - Node Controller等待，直到超时
  - Node Controller将Pod的`phase` 设为Failed
  - 如果Pod是用Controller创建的，Pod将在别处重建