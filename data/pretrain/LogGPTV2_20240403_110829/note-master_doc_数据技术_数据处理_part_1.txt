# 数据处理
## 数据集成
首先要有可靠、完整的数据流，后续才能谈得上在上层对这些数据进行存储、可视化、分析
- ETL：提取 (Extract)——转换 (Transform)——加载 (Load)，在数据源抽取后首先进行转换，然后将转换的结果写入目的地
- ELT：提取 (Extract)——加载 (Load)——变换 (Transform)，在抽取后将结果先写入目的地，然后利用数据库的聚合分析能力或者外部计算框架在最后对数据做转换
ELT相比ETL，因为转换是在目的地，所以可以根据后续使用的情况做调整，比较灵活
### 数据清洗
需要一些清洗规则帮助确保数据质量和一致性，减少数据中的错误、不完整、重复等问题，使得数据标准、干净、连续
### 数据变换
- 数据变换是[数据分析](/数据技术/数据分析.md)必须的预处理步骤
1. 数据平滑：去除数据中的噪声，将连续数据离散化
2. 数据聚集：对数据进行汇总
3. 数据概化：将数据由较低的概念抽象成为较高的概念，减少数据复杂度，即用更高的概念替代更低的概念。比如说上海、杭州、深圳、北京可以概化为中国
4. 数据规范化：使属性数据按比例缩放，这样就将原来的数值映射到一个新的特定区域中
   1. Min-max 规范化：将原始数据变换到[0,1]的空间中
   2. Z-Score 规范化：新数值 =（原数值 - 均值）/ 标准差
   3. 小数定标规范化：移动小数点的位置来进行规范化。小数点移动多少位取决于属性 A 的取值中的最大绝对值
5. 属性构造：构造出新的属性并添加到属性集中
## 批处理
- 输入数据是有界且不可变的
- 除了输出 其他操作都没有副作用
#### UNIX的管道
#### [MapReduce](/数据技术/Hadoop.md#MapReduce)的不足
- 抽象层次不足，太原始
- 维护成本：每一步的 MapReduce 都有可能出错，为了这些异常处理，就需要协调系统，协调系统又是一个复杂度的来源
- 时间性能：对 MapReduce 的配置细节不理解，难以发挥其高性能，每一步计算都要进行硬盘的读取和写入
- 只支持批处理
需要的：
1. 一种技术抽象让多步骤数据处理变得易于维护
2. 不要复杂的配置，需要能自动进行性能优化
3. 要能把数据处理的描述语言，与背后的运行引擎解耦合开来
4. 要统一批处理和流处理的编程模型
5. 要在架构层面提供异常处理和数据监控的能力
```mermaid
stateDiagram-v2
  state 前端/用户端 {
    统一批处理/流处理的的描述语法 --> 有向图编译系统
  }
  有向图编译系统 --> 后端/计算引擎: DAG
  state 后端/计算引擎 {
    基于有向图的优化系统
    计算资源自动分配系统
    自动监控和错误追踪
  }
```
#### 分布式批处理需要解决的问题
1. 如何将输入数据分区
2. 容错：任务可能随时会失败
## 流处理
- 复杂事件处理（CEP）：存储一个搜索模式，在流数据流经时判断是否符合这样的模式
- 流分析：对一定窗口期内的数据进行计算、分析
- 通过流来进行RPC
### [消息系统](/中间件/消息队列/消息队列.md)
早期使用消息队列来实现流处理：
```mermaid
stateDiagram
  direction LR
  数据源 --> 消息队列1
  消息队列1 --> 处理逻辑1
  处理逻辑1 --> 消息队列2
  消息队列2 --> 处理逻辑3
  消息队列2 --> 处理逻辑4
  处理逻辑3 --> 消息队列3
  处理逻辑4 --> 消息队列3
```
消息系统与传统的数据库有着本质的区别：数据临时与永久之分
分区日志消息系统：结合了传统消息系统与数据库：既是流，又能存
![每个逻辑数据源都可以建模为它自己的日志](/assets/2022527112653.png)
![以日志为中心的基础设施栈](/assets/202252715123.png)
### 流与数据库
- 数据库的变更通过流与系统异构存储保持同步
- 变更数据捕获（CDC）：初始快照 + 后续变更操作
- 事件溯源：回放所有日志得到数据的最终状态
本质上就是[状态复制机](/软件工程/架构/系统设计/分布式/分布式数据.md#复制)的实现
本质上数据库的日志就是流，数据库里的数据就是当前流重放的快照
### DataFlow模型
核心概念：
- ParDo，地位相当于 MapReduce 里的 Map 阶段。所有的输入数据，都会被一个 DoFn，也就是处理函数处理
- GroupByKey，地位则是 MapReduce 里的 Shuffle 操作。把相同的 Key 汇总到一起，然后再通过一个 ParDo 下的 DoFn 进行处理
![](/assets/202358143043.webp)
### 时间问题
流处理依赖于本地时间戳，时钟是不可靠的，同时考虑消息堆积、软件错误等问题，基于时间戳的流分析可能不准
### 窗口类型
1. 轮转窗口：固定长度，相互之间没有重叠且紧邻 [1,3] [4,6]
2. 跳跃窗口：固定长度，允许之间重叠以进行平滑过度 [1,3] [2,4]
3. 滑动窗口
4. 会话窗口：没有固定时间，将同一用户的事件组合在一起
### 容错
- 微批处理：将流切成固定大小的块，如果这个块发生错误，则丢弃这个块的所有输出
- 校验点：定期生成检查点，如果流处理发生错误，就回到上一个检查点重新跑
这需要消费端保证幂等性，否则为了容错会输出不止一次导致副作用
## 特征工程
利用工程手段从“用户信息”“物品信息”“场景信息”中提取特征的过程，在已有的、可获得的数据基础上，“尽量”保留有用信息是现实中构建特征工程的原则
### 常用特征
1. 用户行为数据：区分隐式反馈与显式反馈，对用户行为数据的采集与使用与业务强相关
2. 用户关系数据：人与人之间连接的记录，区分强关系（主动建立连接）与弱关系（间接的关系导致的连接）
3. 属性、标签类数据：物品属性、人口属性、主动打的标签等
4. 内容类数据：描述型文字、图片，甚至视频，需要进一步通过NLP、图像识别等转为结构化信息才能作为特征使用
5. 场景信息：描述的是用户所处的客观的推荐环境，常见的有所处于什么时空
### 特征处理
进行特征处理的目的，是把所有的特征全部转换成一个数值型的特征向量
类别特征处理：
One-hot 编码（也被称为独热编码），它是将类别、ID 型特征转换成数值向量的一种最典型的编码方式。它通过把所有其他维度置为 0，单独将当前类别或者 ID 对应的维度置为 1 的方式生成特征向量
```
周二 => [0,1,0,0,0,0,0] -- 将一周7天视为7个维度，将周二所在的维度设为1
```
数值类特征处理：
1. [归一化](/数学/概率论与数理统计.md#特征变化)
2. 分桶：将样本按照某特征的值从高到低排序，然后按照桶的数量找到分位数，将样本分到各自的桶中，再用桶 ID 作为特征值
```
分桶：
[1,1,1,1,1,1,5,8,10] => [(1,5),(5,10)]
```
### Embedding
用一个数值向量“表示”一个对象（Object）的方法
词 Embedding：
![生成 Skip-gram 模型结构的训练数据](/assets/202391820926.webp)
在通过神经网络训练得到模型，一个词就可以通过模型推断，转为向量
图 Embedding：
1. Deep Walk：在由物品组成的图结构上进行随机游走，产生大量物品序列，然后将这些物品序列作为训练样本输入 Word2vec 进行训练，最终得到物品的 Embedding
2. Node2vec：通过调整随机游走跳转概率的方法，让 Graph Embedding 的结果在网络的同质性（Homophily）和结构性（Structural Equivalence）中进行权衡。同质性指的是距离相近节点的 Embedding 应该尽量近似，结构性指的是结构上相似的节点的 Embedding 应该尽量接近
   1. 为了使 Graph Embedding 的结果能够表达网络的“结构性”，在随机游走的过程中，需要让游走的过程更倾向于 BFS（Breadth First Search，广度优先搜索），因为 BFS 会更多地在当前节点的邻域中进行游走遍历，相当于对当前节点周边的网络结构进行一次“微观扫描”。当前节点是“局部中心节点”，还是“边缘节点”，亦或是“连接性节点”，其生成的序列包含的节点数量和顺序必然是不同的，从而让最终的 Embedding 抓取到更多结构性信息
   2. 而为了表达“同质性”，随机游走要更倾向于 DFS（Depth First Search，深度优先搜索）才行，因为 DFS 更有可能通过多次跳转，游走到远方的节点上。但无论怎样，DFS 的游走更大概率会在一个大的集团内部进行，这就使得一个集团或者社区内部节点的 Embedding 更为相似，从而更多地表达网络的“同质性”
Embedding 可以直接使用，在到 Embedding 向量之后，直接利用 Embedding 向量的相似性实现某些推荐系统的功能。也可以预先训练好物品和用户的 Embedding 之后，不直接应用，而是把这些 Embedding 向量作为特征向量的一部分，跟其余的特征向量拼接起来，作为推荐模型的输入参与训练。最后是一种 E2E 的应用，即不预先训练 Embedding，而是把 Embedding 的训练与深度学习推荐模型结合起来，采用统一的、端到端的方式一起训练，直接得到包含 Embedding 层的推荐模型。
#### 非负矩阵因式分解
输入多个样本数据，每个样本数据都是一个m维数值向量，首先把我们的数据集用矩阵的形式写出来，每一列是一个数据，而每一行是这些数据对应维度的数值。于是我们就有了一个大小为m*n的输入矩阵。而算法的目标就是将这个矩阵分解为另外两个非负矩阵的积
## 模式
### Workflow
#### 复制模式
```mermaid
flowchart
  数据集 --> 复制器
  复制器 --> 工作流1
  复制器 --> 工作流2
  复制器 --> 工作流3
```
#### 过滤模式
```mermaid
flowchart
  数据集(1,2,3) --> 过滤器
  过滤器 --> 工作流(1,2)
```
#### 分离模式
```mermaid
flowchart
  数据集(1,2,3) --> 分离器
  分离器 --> 工作流1(1,2)
  分离器 --> 工作流2(2,3)
```
#### 合并模式
```mermaid
flowchart
  数据集1(1,2) --> 合并器
  数据集2(2,3) --> 合并器
  合并器 --> 工作流(1,2,3)
```
### [发布订阅](/软件工程/设计模式/行为模式.md#观察者)
## 架构
### Lambda
完整的数据集 = λ (实时数据) * λ (历史数据)
```mermaid