title:CarSpeak: a content-centric network for autonomous driving
author:Swarun Kumar and
Lixin Shi and
Nabeel Ahmed and
Stephanie Gil and
Dina Katabi and
Daniela Rus
CarSpeak: A Content-Centric Network for Autonomous
Driving
Swarun Kumar, Lixin Shi, Nabeel Ahmed, Stephanie Gil, Dina Katabi and Daniela Rus
Massachusetts Institute of Technology
{swarun, lixshi, n3ahmed, sgil, dk, rus}@mit.edu
ABSTRACT
This paper introduces CarSpeak, a communication system for au-
tonomous driving. CarSpeak enables a car to query and access sen-
sory information captured by other cars in a manner similar to how
it accesses information from its local sensors. CarSpeak adopts a
content-centric approach where information objects – i.e., regions
along the road – are ﬁrst class citizens. It names and accesses road
regions using a multi-resolution system, which allows it to scale the
amount of transmitted data with the available bandwidth. CarSpeak
also changes the MAC protocol so that, instead of having nodes
contend for the medium, contention is between road regions, and
the medium share assigned to any region depends on the number of
cars interested in that region.
CarSpeak is implemented in a state-of-the-art autonomous driv-
ing system and tested on indoor and outdoor hardware testbeds in-
cluding an autonomous golf car and 10 iRobot Create robots. In
comparison with a baseline that directly uses 802.11, CarSpeak re-
duces the time for navigating around obstacles by 2.4×, and re-
duces the probability of a collision due to limited visibility by 14×.
Categories and Subject Descriptors C.2.2 [Computer
Systems Organization]: Computer-Communications Networks
Keywords Autonomous Vehicles, Content-Centric, Wireless
1.
INTRODUCTION
Autonomous vehicles have been the topic of much recent re-
search [5, 31, 18]. The goal of these systems is to drive from point A
to point B in an efﬁcient and safe manner, while dealing with con-
tinuous changes in the environment due to pedestrian and object
movements, and the potential of unexpected events, such as road-
work and accidents. To achieve their goal, autonomous vehicles
need detailed realtime information about their surroundings [22].
They typically use laser rangeﬁnder sensors to discover the sur-
faces of nearby objects and represent this information as a 3D-point
cloud similar to that shown in Fig. 1. Using only the car’s on-board
sensors, however, prevents autonomous vehicles from uncovering
hidden objects that are not directly in their line-of-sight, e.g., a kid
running around the corner, or a car pulling out of an occluded drive-
way. These sensors also cannot deliver long-range data with sufﬁ-
cient accuracy, which limits the car’s ability to plan ahead [31].
Further, they are costly (e.g., the sensors alone on an autonomous
vehicle can cost several hundred thousand US dollars [17, 18]). For
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
SIGCOMM’12, August 13–17, 2012, Helsinki, Finland.
Copyright 2012 ACM 978-1-4503-1419-0/12/08 ...$15.00.
Figure 1—Example of sensory information used in autonomous
driving. The ﬁgure shows a 3D-point cloud of a road obtained by
a Velodyne laser sensor, where colors refer to elevation from the
ground. Note that a 3D-point cloud provides the (x, y, z) coordinates
of points lying on the surface of obstacles.
these reasons, the report from the recent DARPA Urban Challenge
identiﬁes the need for information sharing between autonomous ve-
hicles as a key lesson learned from the contest [3]. However, 802.11
is ill-suited for this application. Navigation sensors can generate re-
altime streams at Gb/s from each car, leading to a scenario where
there is always more data than bandwidth to send it. Furthermore,
a communication protocol that cannot capture the importance of
different pieces of information for the application will end up in-
undating the medium with irrelevant or stale data, and potentially
denying access to important and urgent information.
This paper introduces CarSpeak, a communication system that
addresses the needs of autonomous vehicles. CarSpeak enables cars
to request and access sensory information from other cars, as well
as static infrastructure sensors, in a manner similar to how they ac-
cess their own sensory information. To achieve its goal, CarSpeak
adopts a content-centric design, where information objects are ﬁrst
class citizens. CarSpeak’s information objects are regions in the
car’s environment (e.g., a cube of 1 m3). In CarSpeak, a car can
request a realtime stream of a 3D-point cloud data from a particular
region along the road. It can also zoom in to get a more detailed
description, or zoom out for a wider view.
CarSpeak delivers its design via three components that address
the main challenges in sharing navigation sensor data:
• How does a car describe the information it wants, at a particular
resolution, if that information describes a region along the road?
In order to name and ﬁnd road regions, CarSpeak divides the
world recursively into cubes; smaller cubes provide a ﬁner de-
scription of the encompassing cube. Each cube refers to a re-
gion. To efﬁciently represent this data, CarSpeak uses an Octree,
a data structure commonly used in graphics to represent 3D ob-
jects [28, 11]. Each node in the Octree refers to a cube, and the
sub-tree rooted at that node refers to ﬁner details inside that cube,
as shown in Fig. 2. The Octree representation allows CarSpeak
to name regions at different resolution and according to their lo-
outdoor testbed composed of an autonomous Yamaha G22E golf
car mounted with Hokuyo laser range sensors, and exchanging sen-
sory information with the Create robots. We compared CarSpeak
with a baseline inter-vehicle communication protocol that directly
uses the existing 802.11 protocol.
Experiments from the indoor testbed show that compared to the
802.11 baseline, CarSpeak reduces the time taken to navigate an en-
vironment with obstacles by 2.4×, and the probability of a collision
due to limited visibility by 14×.
Outdoor experiments with the a Yamaha golf car tests the role of
communication in enabling cars to react safely to pedestrians who
suddenly exit a blind spot and cross the car’s path. Empirical results
show that use of CarSpeak allows for the receiver on the golf car to
issue a stop command with a maximum average delay of 0.45 sec-
onds which is 4.75× smaller than the minimum delay of 2.14 sec-
onds using 802.11. These relatively small delays using CarSpeak
allow the vehicle to safely stop before the crosswalk if the pedes-
trian appears at distances as small as 1.4 meters on average, even
when the vehicle is traveling at its maximum velocity of 2 meters
per second. In contrast, using 802.11 the vehicle is unable to stop
before reaching the crosswalk if the pedestrian appears when the
vehicle is closer than four meters from the crosswalk on average.
Contributions: To our knowledge, CarSpeak is the ﬁrst commu-
nication system for multiple autonomous vehicles that focuses on
maximizing the utility of information for this application, and that
is fully integrated with autonomous vehicle systems. It is evaluated
on a testbed of autonomous vehicles, and demonstrated to reduce
path length and the probability of collisions. Its content-centric de-
sign that operates on realtime rich sensory data sets it apart from
past work on VANET. This design is delivered via three compo-
nents including a multi-resolution naming and addressing scheme,
a content-centric MAC, and a new approach to compressing rich
sensory data that is suitable for lossy and dynamic environments.
2. RELATED WORK
Recent years have witnessed major advances in designing and
building autonomous vehicles to realize safer and more fuel efﬁ-
cient future cars [5, 31, 18]. Past work in this domain [14, 8, 17], in-
cluding the DARPA Urban Challenge and the Google autonomous
car, focuses on issues related to perception, efﬁcient path planning,
obstacle detection, etc. In contrast, this paper focuses on designing
a communication protocol that is most suitable for sharing sensory
data between autonomous vehicles.
Our work is related to a broad area in robotics that studies net-
works of robots. Past work in this area can be divided into two
categories: The ﬁrst category uses communication as a black-box,
and focuses on algorithms that enable robots to collaborate on a
desired task, for instance, cooperative exploration [23] or pursuit
evasion [15]. The second category considers the application as a
black-box and focuses on harvesting robot mobility to improve net-
work connectivity or throughput [24, 9]. In contrast, our work is
based on designing the communication protocols around the needs
of the application, and takes neither as a black box.
A large number of research papers have focused on the problem
of Vehicular ad-hoc networks (VANETs). Work in this area focuses
on efﬁcient routing [19, 27, 30], delay tolerant networks [20], reli-
able delivery of emergency messages [2, 6], or speciﬁc applications
such as detecting accidents [13]. None of these papers, however,
present a content-centric architecture or design a MAC protocol
where information objects contend for the medium. Also, none of
them present a solution that is particularly suitable for autonomous
driving.
Our work builds on past work on content-centric networking.
Figure 2—Representation of regions using Octree.
cation in the world. Speciﬁcally CarSpeak names a region by
referring to the root of the region’s sub-tree; it expresses the res-
olution of the region using the depth from the root of the region’s
sub-tree. The Octree also enables a car to store its data efﬁciently
because, though the world is huge, each car needs to only expand
the part of the Octree in its neighborhood.
• How does the system allocate the wireless bandwidth to the most
recent data from the region, given that multiple cars may sense
the same region and each car does not know what information
other cars know?
CarSpeak adopts a content-centric MAC where information ob-
jects, as opposed to senders, contend for medium access. Further,
each information object (i.e., 3D-point cloud stream) obtains a
share of the medium proportional to the number of requests it
receives.
CarSpeak implements this abstraction using a distributed proto-
col, where nodes that sense a region contend on its behalf. Re-
quests for region data are broadcast on the medium. Nodes com-
pute a summary value of the quality of the information they have
of each region (which is a measure of the timeliness and com-
pleteness of this information). CarSpeak uses a low overhead
protocol to share this information among the nodes as annota-
tions on their transmitted data packets. Each car uses these an-
notations to compute how much sensory data it should transmit
so that its contribution to each stream is proportional to the com-
pleteness and freshness of the data it has from the corresponding
region. CarSpeak then enforces this allocation by controlling the
802.11 contention window appropriately.
• How does the system compress the redundancy in the transmitted
sensor data while being resilient to packet loss?
CarSpeak makes each packet self-contained by assigning it an in-
dependent set of branches in the Octree that are derived from the
root. As a result, each received packet can be correctly inserted
into the tree independent of other packets. CarSpeak also reduces
the overlap between data transmitted by cars that sense the same
region. Recall that each region is a cube that encompasses many
smaller cubes, whose values keep changing in realtime due to the
arrival of new sensor data. In CarSpeak even if multiple cars re-
ceive a request for the same region (i.e., the same encompassing
cube), each of them will pick a different permutation according
to which they transmit the sub-cubes in the region. Thus, if only
one car has sensor data about the region, it will eventually trans-
mit all the sub-cubes from the region. However, if multiple cars
have data about the same region, then they are likely to cover all
sub-cubes in the region, while limiting the overlap in their trans-
missions.
We built a prototype of CarSpeak in ROS, the Robot OS [26]
and integrated it with a state of the art path planner, whose earlier
version was used in the DARPA Urban Challenge. We evaluated
CarSpeak on two testbeds: 1) an indoor testbed of iRobot Create
programmable robots connected to netbooks with Atheros AR9285
cards and gathering sensor data from Xbox 360 Kinects, and 2) an
Building an OctreeOctreeFigure 3—High-Level Architecture of Autonomous Vehicular
Systems. The path planner module uses information from various
sensors to compute a safe path for the vehicle.
Past work in this domain is mostly focused on the Internet [12, 16].
The few papers that apply this concept in the wireless domain are
focused on storage or routing information content [25, 29, 4]. Our
work differs from all these papers in that it is focused on resource
sharing at the MAC layer. Also, it uses a multi-resolution naming
system and is fully integrated with an autonomous driving in terms
of design, implementation and evaluation.
3. PRIMER ON AUTONOMOUS VEHICLES
In this section, we provide a quick background of autonomous
driving software so that it is clearer how CarSpeak interfaces with
these systems. Successful performance of autonomous vehicles re-
lies on their ability to sense and process information about the en-
vironment around them. To obtain this information, autonomous
vehicles and robots are typically equipped with ranging sensors,
which deliver realtime measurements of the distance of the vehicle
to the surrounding 3D objects. The vehicle may use laser scanners,
ultrasonic range ﬁnders for outdoor settings and Kinect for indoor
settings [31, 5, 18, 10]. Other sensors like cameras and light detec-
tors are also used for additional information.
Most autonomous vehicles use the Robot Operating System
(ROS) framework [26]. ROS provides a publish/subscribe archi-
tecture, where a module (e.g., sensor) publishes a topic (e.g., /sen-
sor_data) that can be subscribed to by multiple modules. We dis-
cuss the commonly deﬁned high-level modules below (Figure 3):
• Sensor Infrastructure: Each sensor attached to the autonomous
vehicle has an associated module which converts raw sensor in-
formation obtained from the driver into a generic sensor format.
The most widely used format is a 3D-point cloud which provides
the 3-D (x, y, z) coordinates of points lying on the surface of ob-
stacles. The point cloud, along with a timestamp t denoting the
time of retrieval of sensor data, is published by each sensor mod-
ule.
• Planner: The planner’s goal is to use sensory information to
plan an obstacle-free path for the vehicle to navigate along. The
planner typically has access to a detailed global map of the envi-
ronment. The planner is sub-divided into four modules:
◦ Perception module subscribes to point cloud information from
the sensors and applies complex obstacle detection algorithms to
recognize obstacles in the frame of reference of the vehicle. It
publishes a map of these obstacles.
◦ Localization module publishes the vehicle’s position within the
global map based on GPS, odometry or more advanced sensory
infrastructure, some of which can be as accurate as a few cen-
timeters [18].
◦ Mapper subscribes to information from the localization and