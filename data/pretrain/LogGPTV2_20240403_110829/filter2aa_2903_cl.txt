存储到普通内存中
STG
存储到全局内存中
STL
存储到局部或者共享内存窗口中
STS
存储到局部或者共享内存窗口中
MATCH
在线程组范围内匹配寄存器的值
QSPC
查询空间（Query Space）
ATOM
针对普通内存的原子操作
加载和存储指令
ATOMS
针对共享内存的原子操作
ATOMG
针对全局内存的原子操作
RED
针对普通内存的整合操作（Reduction Operation）
CCTL
缓存控制
CCTLL
本地缓存控制，最后一个L是Local（本地）的缩写
ERRBAR
错误屏障（Error Barrier）
MEMBAR
内存屏障（Memory Barrier）
CCTLT
纹理缓存控制
纹理指令
TEX
纹理获取（Texture Fetch）
TLD
纹理加载（Texture Load）
TLD4
纹理加载4（Texture Load 4）
TMML
当访问逐级递减纹理图时要设置访问级别
TXD
读取带导数的纹理信息（Texture Fetch With Derivatives）
TXQ
纹理查询（Texture Query）
表面指令
SUATOM
表面整合（Surface Reduction）
SULD
表面加载（Surface Load）
SURED
针对表面内存的原子整合（Atomic Reduction）
SUST
存储表面
控制指令
BMOV
移动CBU状态
BPT
断点和陷阱（BreakPoint/Trap）
BRA
相对跳转（Relative Branch）
BREAK
跳出指定的聚合屏障（Convergence Barrier）
BRX
间接的相对跳转（Relative Branch Indirect）
BSSY
设置聚合屏障和同步点
BSYNC
在聚合屏障（Convergence Barrier）中同步线程
CALL
调用函数
控制指令
EXIT
退出程序
IDE
中断启用和禁止（Interrupt Enable/Disable）
JMP
绝对跳转（Absolute Jump）
JMX
间接的绝对跳转（Absolute Jump Indirect）
KILL
终止线程（Kill Thread）
NANOSLEEP
暂停执行（Suspend Execution）
RET
从子例程返回（Return From Subroutine）
RPCMOV
给程序计数器寄存器（PC Register）赋值
RTT
从陷阱返回
WARPSYNC
在Warp中同步线程
YIELD
放弃控制（Yield Control）
杂项指令
B2R
将屏障赋值给寄存器（Move Barrier To Register）
BAR
屏障同步（Barrier Synchronization）
CS2R
把特殊寄存器赋值给普通寄存器
CSMTEST
测试和更新剪切状态机（Clip State Machine）
DEPBAR
依赖屏障（Dependency Barrier）
GETLMEMBASE
取局部内存的基地址（Local Memory Base Address）
LEPC
加载有效的程序计数器（Load Effective PC）
NOP
空操作（No Operation）
PMTRIG
触发性能监视器
R2B
把寄存器赋值给屏障（Move Register to Barrier）
S2R
把特殊寄存器赋值给普通寄存器
SETCTAID
设置协作线程组（CTA）的ID
SETLMEMBASE
设置局部内存基地址（Set Local Memory Base Address）
VOTE
在SIMD线程组范围内投票（Vote Across SIMD Thread Group）
VOTE_VTG
测试和更新剪切状态机（Clip State Machine）
特斯拉架构和伏特微架构的发布时间相隔11年，比较二者的指令
集，可以看到很多变化。首先，指令数量明显增加，后者（伏特微架
构）大约是前者（特斯拉微架构）的2倍。在新增的指令中，除了针对
双精度浮点、半精度浮点、纹理、表面等新的数据类型外，还有缓存控
制、断点和陷阱以及线程控制等高级指令。这代表着GPU上的代码也日
趋复杂，不仅是算术运算。
细心的读者还会发现，变化不只是增加，也有减少，比如特斯拉微
架构中的复杂数学函数指令（正余弦、对数等）在伏特微架构中都不见
了。不过，不是真的不再支持这些操作，而是指令的格式改变了。如果
在汇编指令级单步跟踪调用正弦函数的语句，就会发现使用的是表9-5
中的MUFU指令。
0x000cf6d8  [0471] sin.approx.f32     %f2, %f1;  
0x000cf6d8              5c90000000070000         RRO.SINCOS R0, R0;  
0x000cf6e0              0000000000000000         NOP;  
0x000cf6e8              5080000000170000         MUFU.SIN R0, R0;
看来，MUFU.SIN取代了以前的SIN指令，而且通过不同的指令后
缀可以支持多种数学函数，这样原本的多条指令被合并为1条指令。这
背后的原因是SASS汇编的机器码很长，一般都是8字节。为了充分利用
指令的每一个位域，我们会发现SASS指令大多都很长，除了一个主操
作外，再用点（.）跟随一个子操作，比如MUFU.SIN。在GPU领域，多
种GPU都使用“超常指令字”（Very Long Instruction Word，VLIW）。后
面要介绍的英特尔和AMD的某些GPU指令都属于此类，虽然Nvidia的
GPU指令不属于VLIW，但也是受其影响的。
值得说明的是，当在CUDA程序中直接调用sin函数时，编译器并不
会使用上面的MUFU指令，而是调用一个更复杂的软件实现。原因是
MUFU指令是通过硬件里的SFU进行快速计算的，但是结果不够精确，
所以默认不会使用。如果一定要用，那么可以可以调用CUDA的内部函
数（intrinsics）__sinf()。
整理表9-5花了作者很多时间（少半个春节假期）。有些读者可能
会问：“为什么要花这个时间呢？”答案是，这些指令是根本，是软硬件
之间交互的根本纲领和基本法则。通过这些指令，我们可以感知GPU内
部的硬件结构，了解它最擅长的功能。了解这些，对写代码、调试和优
化都善莫大焉。
 老雷评点 
君子务本，本立而道生。
9.4 PTX指令集
根据上一节对GPU硬件指令的介绍，我们知道不同微架构的指令是
有较大差异的。这意味着，如果把GPU程序直接按某一微架构的机器码
进行编译和链接，那么产生的二进制代码在其他微架构的GPU上执行时
很可能会有问题。为了解决这个问题，并避免顶层软件直接依赖底层硬
件，Nvidia定义了一个虚拟环境，取名为并行线程执行（Parallel Thread
eXecution，PTX）环境。然后针对这个虚拟机定义了一套指令集，称为
PTX指令集（ISA）。
有了PTX后，顶层软件只要保证与PTX兼容即可（见图9-11）。在
编译程序时，可以只产生PTX指令，当实际执行时，再使用即时编译
（JIT）技术产生实际的机器码。这与Java和.NET等编程语言使用的中
间表示（IR）技术很类似。
图9-11 PTX的重要角色
与SASS没有公开文档不同，PTX指令集的应用指南（Parallel
Thread eXecution ISA Application Guide）非常详细，有在线版本，
CUDA工具包中也有。CUDA 9.1版本的文件名为ptx_isa_6.1.pdf，长达
300余页。建议读者阅读本节内容时，同时参照这个文档。
9.4.1 汇编和反汇编
手工写一段PTX汇编程序并不像想象的那么困难。清单9-1是作者
编写的一个简单例子。
清单9-1 调用正弦指令的PTX汇编函数
/*
Manual PTX assembly code by Raymond for the SWDBG 2nd edition.
All rights reserved. 2018 
*/
.version 6.1
.target sm_30
.address_size 64
.global .u32 gOptions = 0;
.visible .entry doSin(.param .u64 A, .param .u64 B,    .param .u32 nNum)
{
    .reg .f32     %fA, %fB;
    .reg .b64     %pA, %pB, %u64Offset;
    .reg .pred     %p;
    .reg .b32     %nTotal,%nIndex,%nBlockDim,%nBlockID,%nTid;
    ld.param.u64     %pA, [A];
    ld.param.u64     %pB, [B];    
    ld.param.u32     %nTotal, [nNum];
    mov.u32     %nBlockDim, %ntid.x;
    mov.u32     %nBlockID, %ctaid.x;
    mov.u32     %nTid, %tid.x;