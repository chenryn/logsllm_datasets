perfectly de-anonymizable and when ℘ = 0.7, the ﬁrst 137
users in Google+ are perfectly de-anonymizable. According
to ODA, the identiﬁed landmarks can serve as references for
future DA.
L = U u
From Fig. 2 (a), when the recall increases, there are more
common edges between Ga and Gu, which implies it is eas-
ier to identify the high degree users based on the increased
structural information and thus more landmarks can be i-
dentiﬁed. Because of a similar reason, we can see from Fig.
2 (b) that more landmarks can be identiﬁed in Google+ for
large ℘ due to more edge overlap between Ga and Gu.
DA Results. By taking the users identiﬁed in Fig. 2
as landmarks, we employ ODA to de-anonymize Gowalla
(M 1, M 2, M 3, M 4) and Google+ (Ga with diﬀerent ℘)
as shown in Fig. 3, where the x-axis represents the accu-
mulated percentage of users de-anonymized and the y-axis
represents the accumulated percentage of users successfully
de-anonymized. From Fig. 3, we can see that the success-
ful DA rate is higher for large-degree users than that of
60757694M1M2M3M4020406080100Landmarks1291301371521790.50.60.70.80.9020406080100120140160180Landmarksperfect DA. Therefore, for secure data publication, besides
the data itself, the information carried by the data’s struc-
ture is also essential and deserves dedicated consideration
before released.
The fact is that we still have a long way to go
to achieve secure data publishing. From our large
scale study on 26 real world datasets, most of the exist-
ing structural datasets are de-anonymizable based only on
their structural information. On the other hand, existing
anonymization techniques are vulnerable to structure based
DA attacks. Therefore, new anonymization techniques should
be developed. Meanwhile, since structural data release, shar-
ing, or transferring has signiﬁcant business and social val-
ue, the data utility should be preserved in the new developed
anonymization schemes. In summary, new secure data pub-
lishing schemes that properly achieve a balance between data
privacy protection and data utility preservation must be de-
veloped.
Suggestions for secure data publishing. Secure da-
ta publishing is important for businesses, research, and the
society. However, with the wide availability of rich auxil-
iary information, especially with the emergence of Collabora-
tive Information Seeking (CIS) systems and data/knowledge
brokers [28][29], the privacy of people, businesses, govern-
ments, etc. will increasingly be compromised. For secure
data publishing, some general suggestions are as follows. (i)
Carefully share data with or transfer data to third parties
and partners. Before sharing the data, the data owner-
s should examine the dedicated applications to see if the
data sharing is necessary. Based on the requirements of
applications, the data could be shared in diﬀerent granular-
ity levels: digest level : share/transfer a digest/summary of
the data to third parties or partners; partial and density-
controlled level : based on our quantiﬁcation, controlling the
graph density could increase the diﬃculty of DA. Therefore,
in this level, only a density-controlled anonymized version
(e.g., by sampling) of a subset of the data (e.g., a communi-
ty) is shared/transferred; density-controlled level : a density-
controlled anonymized version of the data is shared or trans-
ferred; full level : an anonymized version of the full dataset
is shared or transferred. (ii) Evaluate the potential vulnera-
bility of the dataset before actual publishing. Before actually
publishing the data, the data owners can evaluate the vul-
nerability of the data. For instance, the data (structural)
can be evaluated using our quantiﬁcation as in Section 5.
(iii) Develop proper policy on data collection. Many struc-
tural data owners allow public data collection, e.g., Twitter,
Facebook allow crawlers and other automatic programs to
collect users’ information online. This could increase the
data DA risk by providing auxiliary information to adver-
saries. Therefore, it is better for data owners to develop
proper policies to limit such public data collection.
8. CONCLUSION AND FUTURE WORK
In this paper, we study the quantiﬁcation, practice, and
implications of structural data DA. First, for the ﬁrst time,
we address several fundamental open problems in data DA
research by quantifying the conditions for perfect DA and
(1− ϵ)-perfect DA under a general data model. This bridges
the gap between structural data DA practice and theory.
Second, we conduct a large scale study on the de-anonymizability
of 26 diverse real world structural datasets, which turn out
to be de-anonymizable partially or perfectly. Third, follow-
(a) De-anonymize Gowalla
(b) De-anonymize Google+
Figure 3: De-anonymize Gowalla and Google+.
c1, c2 ∈ [0, 0.2], c3 + c4 ∈ [0.4, 1], α ∈ [10, 30], γ ∈ [2, 10].
small-degree users, i.e., when x increases, the percentage of
successfully deanonymized users generally show a decreas-
ing trend. The reason is that large-degree users carry more
structural information, which can thus be more accurate-
ly de-anonymizable. This can also be seen from our quan-
tiﬁcation. For Gowalla, we observe from Fig. 3(a) that
although recall dominates the landmark identiﬁcation pro-
cess, the large-scale DA performance is impacted more by
precision. Generally, a high precision implies this dataset
is more de-anonymizable, e.g. M 4. This is because a high
precision implies a low false positive, which can be viewed as
noise in practice, and thus the DA accuracy is better. For
Google+, we see from Fig. 3 (b) that the Ga projected with
a large ℘, e.g., ℘ = 0.9, is more de-anonymizable. As shown
in our quantiﬁcation, this is because a large ℘ implies more
similarity between Ga and Gu and thus more users can be
successfully de-anonymized.
From Fig. 3, we also see that the DA performance of O-
DA on Gowalla and Google+ is better than the evaluation
results shown in Tab. 3, e.g., when ℘ = 0.9, Tab. 3 indicates
91.2% of the users in Google+ are a.a.s. de-anonymizable
while ODA successfully de-anonymizes 95.5% of the users.
This is because the values shown in Tab. 3 are the low-
er bounds on de-anonymizable users.
In summary, about
77.7%− 83.3% of the users in Gowalla and 86.9%− 95.5% of
the users in Google+ are de-anonymizable. Thus, structure
based DA is implementable and powerful in practice.
Time Consumption. We calculate the time consump-
tion on de-anonymizing Gowalla and Google+. On average,
the initialization time (used for initializations), execution
time (used for executing the iterations in ODA), and total
time are 1.79 mins, 1.6 mins, and 3.39 mins for Gowalla and
0.88 hours, 5.61 hours, and 6.49 hours for Google+, respec-
tively.
7.
IMPLICATIONS AND DISCUSSION
Based on our DA quantiﬁcation, evaluation on real world
datasets, and our implemented DA scheme ODA, we provide
some implications of this paper in this section. We also
discuss the impacts of our ﬁndings to secure data publishing
in practice and provide guidelines for future data publishing.
Structural information may induce privacy leak-
age. Although we have some previous work that show struc-
ture based DA is possible, in this paper, we theoretically
demonstrate the reasons by providing rigorous quantiﬁcation
under a general data model. From the quantiﬁcation, struc-
tural information can enable large-scale perfect or (1 − ϵ)-
0.00.10.20.30.40.50.60.70.80.91.00.780.800.820.840.860.880.900.920.940.960.981.00% of Sucessfully De-anonymized Users% of De-anonymized Users M1 M2 M3 M40.00.10.20.30.40.50.60.70.80.91.00.860.870.880.890.900.910.920.930.940.950.960.970.980.991.00% of Successfully De-anonymized Users% of De-anonymized Users 0.5 0.6 0.7 0.8 0.9ing our quantiﬁcation, we propose a cold start single-phase
Optimization based DA (ODA) attack. We also analyze O-
DA theoretically and experimentally. The experimental re-
sults show that 77.7% − 83.3% of the users in Gowalla (.2M
users, 1M edges) and 86.9%− 95.5% of the users in Google+
(4.7M users, 90.8M edges) can be de-anonymized, which im-
plies structure based DA is implementable and powerful in
practice. Finally, we conclude with some implications from
our ﬁndings and provide some general suggestions for future
secure data publishing.
Our future work will focus on the following: (i) We will
evaluate our quantiﬁcation on more structural datasets to
further examine its generality. We also plan to improve O-
DA to make it more eﬃcient and robust; (ii) Since existing
anonymization techniques are vulnerable to structure based
DA attacks, we propose to develop application based eﬀec-
tive schemes against such attacks; (iii) Data utility is an-
other important concern. We plan to study how to quantify
the tradeoﬀ between privacy and utility followed by propos-
ing privacy protection schemes with utility preservation; and
(iv) Finally, due to the importance of secure data publish-
ing, we propose to develop a secure data publishing platform
in the future, which is expected to be invulnerable to both
semantics based and structure based DA attacks.
Acknowledgments
The authors are very grateful to Nana Li and Jing S. He
for helpful discussions on graph theory, to Huy Pham who
helped us to process the Gowalla mobility trace (Huy Pham
also shared a social strength graph obtained from the mo-
bility trace of Gowalla users at Texas), and to Neil Z. Gong
who shared the Google+ dataset with us.
This work was partly supported by NSF-CAREER-CNS-
0545667. Mudhakar Srivatsa’s research was sponsored by US
Army Research laboratory and the UK Ministry of Defence
and was accomplished under Agreement Number W911NF-
06-3-0001. The views and conclusions contained in this doc-
ument are those of the authors and should not be inter-
preted as representing the oﬃcial policies, either expressed
or implied, of the US Army Research Laboratory, the U.S.
Government, the UK Ministry of Defense, or the UK Gov-
ernment. The US and UK Governments are authorized to
reproduce and distribute reprints for Government purposes
notwithstanding any copyright notation hereon.
9. REFERENCES
[1] L. Backstrom, C. Dwork, and J. Kleinberg, Wherefore Art
Thou R3579X? Anonymized Social Networks, Hidden
Patterns, and Structural Steganography, WWW 2007.
[2] A. Narayanan and V. Shmatikov, De-anonymizing Social
Networks, S&P 2009.
[3] M. Srivatsa and M. Hicks, Deanonymizing Mobility Traces:
Using Social Networks as a Side-Channel, CCS 2012.
[4] G. Wondracek, T. Holz, E. Kirda, and C. Kruegel, A
Practical Attack to De-Anonymize Social Network Users,
S&P 2010.
[5] P. Pedarsani and M. Grossglauser, On the Privacy of
Anonymized Networks, KDD 2011.
[6] M. Hay, G. Miklau, D. Jensen, D. Towsley, and P. Weis,
Resisting Structural Re-identiﬁcation in Anonymized Social
Networks, VLDB 2008.
[7] K. Liu and E. Terzi, Towards Identity Anonymization on
Graphs, SIGMOD 2008.
[8] N. Li, W. Qardaji, and D. Su, On Sampling,
Anonymization, and Diﬀerential Privacy Or,
K-Anonymization Meets Diﬀerential Privacy, ASIACCS
2012.
[9] C. Dwork, Diﬀerential Privacy, ICALP 2006.
[10] A. Korolova, R. Motwani, S. U. Nabar, and Y. Xu, Link
Privacy in Social Networks, CIKM 2008.
[11] E. Zheleva and L. Getoor, To Join or Not to Join: The
Illusion of Privacy in Social Networks with Mixed Public
and Private User Proﬁles, WWW 2009.
[12] J. Pang, B. Greenstein, R. Gummadi, S. Seshan, and D.
Wetherall, 802.11 User Fingerprinting, Mobicom 2007.
[13] L. Backstrom, E. Sun, and C. Marlow, Find me If You
Can: Improving Geographical Prediction with Social and
Spatial Proximity, WWW 2010.
[14] S. Han, V. Liu, Q. Pu, S. Peter, T. Anderson, A.
Krishnamurthy, and D. Wetherall, Expressive Privacy
Control with Pseudonyms, Sigcomm 2013.
[15] P. Mittal, M. Wright, and N. Borisov, Pisces: Anonymous
Communication Using Social Networks, NDSS 2013.
[16] J. Kannan, G. Altekar, P. Maniatis, and B.-G. Chun
Making programs forget: Enforcing Lifetime for Sensitive
Data, USENIX 2013.
[17] M. Egele, G. Stringhini, C. Krugel, and G. Vigna, COMPA:
Detecting Compromised Accounts on Social Networks,
NDSS 2013.
[18] K. Singh, S. Bhola, and W. Lee, xBook: Redesigning
Privacy Control in Social Networking Pl atforms, USENIX
2009.
[19] R. Shokri, G. Theodorakopoulos, J.-Y. L. Boudec, and J.-P.
Hubaux, Quantifying Location Privacy, S&P 2011.
[20] R. Shokri, G. Theodorakopoulos, C. Troncoso, J.-P.
Hubaux, and J.-Y. L. Boudec, Protecting Location Privacy:
Optimal Strategy against Localization Attacks, CCS 2012.
[21] M. E. J. Newman, Networks: An Introduction, Oxford
University Press, 2010.
[22] M. E. J. Newman, The Structure and Function of Complex
Networks, SIAM Review, No. 45, pp. 167-256, 2003.
[23] B. Bollob(cid:19)as, Random Graphs (Second Edition), Cambridge
University Press, 2001.
[24] J. Riordan, An Introduction to Combinatorial Analysis,
Wiley, 1958.
[25] N. Z. Gong, W. Xu, L. Huang, P. Mittal, E. Stefanov, V.
Sekar and D. Song, Evolution of Social-Attribute Networks:
Measurements, Modeling, and Implications using Google+,
IMC 2012.
[26] http://snap.stanford.edu/data/
[27] H. Pham, C. Shahabi, and Yan Liu, EBM - An
Entropy-Based Model to Infer Social Strength from