Serial device with no bulk-in or interrupt-in endpoint
Serial device without two interrupt-in endpoints
Serial device without both in and out interrupt endpoints
Communication device without both control and data endpoints
Drawing tablet with invalid USB descriptor
Serial converter device with invalid USB descriptor
Communication device with invalid descriptor and payload
Assertion Policy
Assertion Policy
Assertion Policy
Assertion Policy
Assertion Policy
Assertion Policy
Assertion Policy
Assertion Policy
Assertion Policy
Assertion Policy
Assertion Policy
Assertion Policy
Compliance Policy
⋆Exploit can be prevented with the compliance Policy, but we have not yet incorporated the necessary class specification (Audio) into Cinch.
FIGURE 3—Exploits for known-signature exercise (§7.1). Windows exploits were found by Boteanu and Fowler [79] with umap [88];
the reported identifier can be passed to umap using the “-s” flag to reproduce the exploit. We implemented the Linux exploits to
target all USB-related CVEs from January–June 2016. The last column describes which Policy (§5) of Cinch prevents the exploit.
6.3 Proof-of-concept USB crypto adapter
We implement the crypto adapter (§5.4) using a Beagle-
Bone Black [9] single-board computer that has a 1 GHz
ARM Cortex-A8 processor and 512 MB RAM. For au-
thentication, we generate a CA certificate and install it
on the Gateway and crypto adapter. We use that CA cer-
tificate to sign certificates for the Gateway and crypto
adapter, which mutually authenticate during the TLS
handshake. The crypto adapter runs a version of usbredir
that we augmented with support for TLS 1.2 [90] using
OpenSSL [40]; these changes comprise less than 200 lines
of code. The Gateway’s crypto module uses stunnel [49]
to listen for TLS connections.
7 Evaluation
Our evaluation of Cinch answers the following questions:
• How effectively does Cinch defend against attacks? We
subject Cinch to known exploits (§7.1), fuzzing (§7.2),
and a red team exercise (§7.3).
• Can new functionality be developed and deployed on
Cinch with ease? We answer this question qualitatively,
by relating our experiences (§7.4).
• What is Cinch’s performance overhead? We examine
latency and throughput (§7.5).
Experimental hardware and OSes. All of our exper-
iments run on a single machine with a 3.3 GHz Intel
i5-4590 and 16 GB of RAM. The hypervisor is Debian
Jessie running Linux 4.2.0 with KVM enabled. The red
machine’s OS is also Debian Jessie running Linux 4.2.0.
The blue machine’s OS depends on the experiment and is
either Windows 7 Ultimate SP1 (build 7601), Windows
8.1 Professional (build 9600), Debian Jessie with Linux
4.2.0, or Ubuntu 14.04 with a modified 4.2.0 kernel.
7.1 Known-signature attacks
We begin our evaluation of Cinch by subjecting it to syn-
thetic attacks, based on documented vulnerabilities. For
the attacks that succeed, we specify a “rematch” protocol,
in which the operator can install a signature (§5.1) and
then retry. This exercise is intended to address a coun-
terfactual hypothetical: if Cinch had been deployed at
the time of these vulnerabilities, would it have protected
against their exploitation? And, if not, would a subsequent
defensive reaction have been effective?
Method and experiment. We filter
the CVE
database [14] to select all
the USB-related vulner-
abilities reported from January to June of 2016. The
resulting 13 CVEs apply to Linux 4.5 and earlier. For
each CVE, we construct a payload that exploits it. We
also include five exploits, disclosed by Boteanu and
Fowler [79], that affect the most recent version of
Windows 8.1; the targeted vulnerabilities are not in the
CVE database.
Figure 3 summarizes the exploits. We confirm that
each exploit successfully compromises the blue machine
(Debian Jessie with Linux 4.2.0 or Windows 8.1) in the
absence of Cinch. Once Cinch is enabled, we consider
an attack successful if it compromises either the blue
machine’s kernel or the Gateway.
On the offensive side, we mount the attacks using a
Facedancer [98]—a custom USB microcontroller that can
masquerade as any USB device and issue arbitrary pay-
loads when connected to the target machine. We program
USENIX Association  
25th USENIX Security Symposium  405
9
exploits prevented
match phase
rematch phase
3 / 5
13 / 13
10,000 / 10,000
13 / 13
Known exploits (§7.1)
Windows 8.1
Linux 4.2.0
vUSBf [136, 137] payloads (§7.2)
randomized devices
sample exploits
red team round 1 (§7.3)
Windows 7
Linux 4.2.0
red team round 2 (§7.3)
Windows 7
Linux 4.2.0
red team round 3 (§7.3)
Windows 7
Linux 4.2.0
2 / 2
3 / 5
3 / 3
11 / 16
3 / 3
15 / 20
5 / 5
13 / 13
N/A
N/A
2 / 2
5 / 5
3 / 3
13 / 16
3 / 3
16 / 20
FIGURE 4—Summary of Cinch’s security evaluation.
and control the Facedancer through a Python interface,
using the GoodFET [99] and umap [88] tools.
On the defensive side, we configure Cinch with the sig-
nature, assertion, compliance, and logging Policies (§5).
For the assertion Policy, we install 12 driver-specific con-
figuration restrictions; these fix buggy or nonexistent
checks, identified by the CVEs. For the signature Pol-
icy, we start with an empty signature database and check
whether each attack succeeds; if it does, we craft a signa-
ture based on the payload and associated metadata, then
conduct a rematch.
Results are summarized in Figure 4 (“Known exploits”);
for each exploit, the mechanism that prevented it is listed
in Figure 3. Cinch successfully detects and drops 16 of-
fending payloads with no additional configuration. Two
of the payloads were successful on their first try, but were
blocked in the rematch phase; these payloads targeted
vulnerabilities in the USB Audio class, which we have
not yet included in Cinch’s compliance Policy.
7.2 Fuzzing
Next, we assess the robustness of Cinch’s compliance
Policy (§5.2), via fuzz testing. We limit this exercise to
attacks that target device enumeration, as implemented in
the core and class drivers (§2). On the one hand, this is
not a comprehensive exercise. At the same time, device
enumeration is a common and well-studied source of
vulnerabilities [137], accounting for about half of all USB-
related entries in the CVE database.
In enumerating devices, USB core processes each de-
vice’s USB descriptors: records, generated by the device,
that identify its manufacturer, function, USB version, ca-
pabilities, etc. This process is complex because of the
wide range of possible device configurations. Further-
more, the attack surface includes class driver initialization
functions, since USB core passes descriptors to those func-
tions; Schumilo et al. [137] demonstrate that many OSes
and drivers do not handle device enumeration properly,
especially when the device information is inconsistent or
maliciously crafted.
Method and experiment. On the offensive side, we use
vUSBf [136], a fuzzing tool that generates a random set of
device descriptors and then emulates a device attach event.
We update vUSBf to work with the most recent version of
usbredir (v0.7.1), and we replace the red machine with an
instance of vUSBf (that is, vUSBf communicates directly
with the Gateway). In this setup, vUSBf can emulate
hundreds of randomized devices per minute.
We run two experiments. In the first, we use vUSBf to
emulate 10,000 randomly-generated devices. In the sec-
ond, we use vUSBf to emulate 13 specific configurations
identified by the vUSBf authors (after millions of trials)
that crash some (older) systems.
On the defensive side, we run Cinch, configured with
compliance (§5.2) and logging (§5.5) Policies. If Cinch
allows the emulated device to communicate with the blue
machine, we account this a failure.
We expect that the overwhelming majority of test cases
will not obey the USB specification, and that Cinch’s
compliance Policy will detect and prevent these cases. As
a baseline, we also present the same 10,000 inputs to a
system that is not running Cinch.
Results are summarized in Figure 4 (“vUSBf”). Cinch’s
compliance module prevents all emulated devices from
connecting to the blue machine. The three most commonly
detected violations are: (1) improperly formatted strings,
(2) invalid device classes, and (3) invalid or inconsistent
number of functions. On the one hand, these results could
be argued to be inconclusive because none of these inputs
were successful against the baseline setup without Cinch.
On the other hand, Cinch detected and blocked even the
13 configurations known to crash older systems.
7.3 Red team exercise
Our next set of exercises evaluates Cinch against attacks
that were not known to us a priori. This is intended to
assess Cinch’s effectiveness and to avoid some of the
bias that may arise when developers choose the attack
experiments (as above).
Specifically, we set up a red team that was charged with
developing new USB exploits to compromise blue ma-
chines; this activity included crafting new vulnerabilities
in the blue machine’s OS, which was meant to emulate
the ongoing process of discovering and patching bugs. In
our case, the red team comprised a subset of the authors
who were kept separate from the developers of Cinch and
406  25th USENIX Security Symposium 
USENIX Association
10
Protocol
Attacker
knowledge
Developer
ability
There are three rounds, each of which has a setup, match and rematch phase.
Setup: Red team chooses an OS (which they can modify arbitrarily) and develops exploits that crash the OS.
Match: Cinch developers configure Cinch to run the OS provided by the red team as the blue machine; both teams
confirm that the exploits crash the OS when Cinch is not present. The Cinch developers deploy Cinch, and the red
team mounts its exploits. The Cinch developers collect traces, and both teams document the outcome of the exercise.
Rematch: Cinch developers get the traces, and are given the opportunity to analyze and react to them. Then the
match phase is rerun.
Round 1: The red team is given access to a technical report that documents an earlier version of Cinch. This models
an attacker with limited knowledge of Cinch.
Round 2: The red team is given access to a machine that is running Cinch. This models an attacker with black-box
access to Cinch, or an attacker that possesses Cinch’s binaries.
Round 3: The red team is given access to Cinch’s source code. This models an attacker with full knowledge of
Cinch’s logic (but not its configuration).
Cinch developers freeze Cinch’s code prior to the match phase of round 1. After that, Cinch developers may apply
configuration-only changes: new signatures, etc.
FIGURE 5—Summary of the protocol for the red team exercise. This protocol was codified before the exercise began.
worked independently. Interactions between the red team
and the developers were tightly controlled, following an
evaluation protocol that was documented in advance. Fig-
ure 5 summarizes the protocol.
Summary of red team exploits. The red team devel-
oped 3 exploits for Windows and 20 exploits for Linux
across the three rounds of the protocol. Some exploits
shared the same attack vector but used different payloads.
The Windows exploits attacked a fresh copy of Win-
dows 7; the red team did not install updates because the
vulnerabilities their exploits targeted have been patched.
Since red team members did not have access or visibility
into the Windows USB stack, these exploits were found
primarily through fuzzing, guided by past CVEs.
For Linux, the red team installed a modified version
of kernel 4.2.0 on a fresh copy of Ubuntu 14.04. In par-
ticular, the red team modified a function within HCI that
processes USB request blocks (the data structure repre-
senting a message in the USB subsystem) to trigger a
kernel crash on certain device payloads; introduced a bug
in USB core that causes the kernel to crash whenever a
device with a certain configuration is connected; inserted
a bug in Linux’s HID input subsystem (drivers/input/
input.c) that leads to a null pointer dereference when
it receives a specific sequence of input events; and intro-
duced buggy drivers for a USB printer, camera, audio,
and HID device.
Finally, the red team noticed that the VFAT filesystem
driver in Linux 4.2 does not correctly validate the BIOS
Parameter Block (BPB). While they were unable to ex-
ploit this bug directly, it can result in an invalid filesystem
being mounted. To “enhance” this bug, the red team intro-
duced a null pointer dereference in the BPB handling rou-
tine (fs/fat/inode.c), triggered by a filesystem with
an invalid BPB.
Results are summarized in the last 3 sections of Figure 4.
First round. The red team developed 7 exploits for this
round (2 for Windows and 5 for Linux). In the match
phase, Cinch prevented both Windows exploits and 3
out of the 5 Linux exploits. The Windows exploits were
prevented by Cinch’s architecture rather than by any of its
Policies. Specifically, the red machine runs a Linux kernel;
that kernel is not vulnerable to either of the Windows
exploits and recognizes both connected devices as invalid.
As a result, Cinch does not export these devices in the
first place, protecting the Windows blue machine.
The two Linux exploits that Cinch was unable to pre-
vent occurred at layers that were outside of its semantic
knowledge (VFAT and the input subsystem). Using the
traces—collected with Cinch’s logging module (§5.5)—
the Cinch developers derived signatures. In the rematch
phase, these signatures prevented the exploits.
Second round. In the match phase, Cinch prevented 14
out of 19 attacks, including attacks from the first round.
The rematch phase again relied on signatures; of the re-
maining five exploits, signatures blocked two. The remain-
ing three succeeded because they are polymorphic: they
alter their payload to evade detection.
Third round. In the match phase, Cinch prevented 18
out of 23 attacks, including attacks from prior rounds for
which signatures were available. In the rematch phase,
Cinch was able to defend against an additional exploit
using a signature that prevents a particular sequence of