81.8%
62.6%
0.0%
33.3%
N/A
96.1%
0.0%
N/A
69.2%
N/A
N/A
N/A
97.1%
N/A
N/A
25.0%
N/A
50.0%
N/A
82.4%
N/A
N/A
37.5%
50.0%
N/A
33.3%
50.0%
N/A
N/A
50.0%
62.1%
50.0%
0.0%
N/A
72.5%
88.4% 97.5%
N/A 57.7%
73.3% 79.7%
N/A 59.4%
N/A 78.6%
55.8% 56.2%
N/A 96.8%
N/A 67.2%
N/A 61.1%
72.7% 78.1%
N/A 21.4%
58.7% 65.3%
N/A 38.5%
N/A 70.9%
N/A 96.9%
N/A 61.9%
N/A 58.9%
46.5% 46.2%
N/A 56.2%
60.0% 72.5%
N/A 56.2%
N/A 76.7%
N/A 41.9%
N/A 23.1%
46.5% 55.0%
N/A 78.1%
60.0% 79.2%
N/A 41.9%
N/A 21.4%
N/A 23.1%
N/A 94.4%
Table 5: Memory overhead (KB) comparison.
Application Set
a) Coreutils
b) SPEC
c) Nginx
d) MySQL
a) + b) + c) + d)
Nibbler
Max. Total
1900 KB
1148 KB
1668 KB
2108 KB
3256 KB
Piece-wise [53]
Estimate per execution
1024 KB
580 KB
1292 KB
1248 KB
1816 KB
library is also in use, then two versions of the same library will be
present in memory (i.e., vanilla and thinned library). Calculating
exactly how much memory overhead the thinned library will im-
pose is not straightforward, as the OS dynamically pages-in code
pages used by applications. We can calculate, however, the addi-
tional memory required when all library code is used (worst case
analysis). This corresponds to all code pages (of the thinned library)
that have at least one byte of code that was not erased.
On the other hand, Piece-wise [53] keeps a single version of each
library on disk, and removes code at load time. As a result, each
memory page that has code erased—but not removed entirely—is
no longer shared with any other executing application that uses
the same library, due to copy-on-write (COW).
Consequently, the overhead increases as more applications exe-
cute concurrently. This includes multiple invocations of the same
application, but not multiple processes resulting from a fork()
system call. As a reference, there are approximately 39 distinct ap-
plications running in a fresh installation of Debian v9. Comparison
of memory overheads are shown in Table 5. We estimate the per-
invocation overhead of Piece-wise using the code-reduction num-
bers of Nibbler (more code removed likely means higher overhead
for Piece-wise). Our approach incurs lower and more predictable
memory overhead.
Load Time. Nibbler does not incur any load-time overhead. In
contrast, previous work [53], which only removes code at load time,
reported a 20x slowdown on average with the small programs in
Coreutils (20ms on average, for a process usually taking under 2ms).
Analysis Time. Processing the 104 programs in Coreutils and
their libraries took ≈2 hours with Nibbler. Timings were collected
on a VM running Debian 9 (using VMware Workstation 12 Pro),
hosted on top of Windows 10 on a mid-range workstation featuring
a 3.5GHz AMD FX-6300 CPU and 16GB RAM. Our experiment
indicated that processing time is primarily influenced by code size;
a secondary factor is the number of relocation entries. While the
speed of the analysis is not critical, Nibbler is a prototype, so we
are confident there is room for improvement.
ACSAC ’19, December 9–13, 2019, San Juan, PR, USA
I. Agadakos, D. Jin, D. Williams-King, V. P. Kemerlis, and G. Portokalidis
6 LIMITATIONS
Exploit Disruption. In App. D we evaluate Nibbler against pre-
compiled, real-world core-reuse exploits. In all cases, Nibbler dis-
rupts the exploits; however, attackers can modify them to use other
gadgets and potentially restore their capabilities. Debloating, even
when combined with CFI, cannot block all code-reuse attacks, but it
does make libraries a less fertile ground for gadget harvesting. Note
that compiler-based approaches [53] performing the same type of
debloating have a similar limitation. Exploits are more likely to be
prevented by combining Nibbler with a system like Shuffler [76].
Attack Surface Reduction. Previous work [53] suggested that
debloating can reduce the attack surface by removing vulnerabilities
contained in the erased library code. Nibbler performs a similar
type of debloating on binary code. However, we did not reach the
same conclusion. By design, both works remove code only when
there is no viable execution path to that code for a given application.
Consequently, any code removed is essentially unreachable code, so
vulnerabilities contained within are not relevant because they can
never be triggered by external input(s). We do agree, however, that
such vulnerabilities can potentially be used by multistage exploits,
where later stage exploit components (ab)use vulnerabilities in
unused code to escape sandboxing or further elevate privileges [15].
7 RELATED WORK
7.1 Code Reduction
Recent work from Quach et al. [53] proposes a compiler-based
framework for debloating applications when source code is avail-
able, while Nibbler targets binary-only software. Other differences
with Nibbler include the following: (i) their approach is unable to
work with (one of) the most commonly used libraries, GNU libc
(glibc), which requires the GNU C compiler, while Nibbler is
compiler-agnostic, (ii) their approach opts to debloat each applica-
tion individually, which incurs significant memory overhead when
applied to numerous applications, as it breaks the sharing of mem-
ory pages that include erased code per-application instantiation,
(iii) they choose to debloat applications at load time, which incurs a
slowdown of 20x, and, even though the overhead for launching one
application is negligible in absolute terms, it compounds in appli-
cations that spawn others (e.g., shell scripts), and (iv) Nibbler goes
beyond CFI by demonstrating one of the key benefits of debloating
by integrating it with continuous code re-randomization.
CodeFreeze [46] aims to reduce the attack surface of Windows
binaries by removing unused code in shared libraries (DLLs). It
utilizes bounded address tracking [34] to resolve function pointers,
which leads to over-restrictive CFGs. As a result, while it is more
aggressive at removing code, it can erroneously remove needed
functions (e.g., constructors) and it depends on whitelisting to avoid
crashes. Instead, Nibbler’s analysis is conservative and attempts to
err on the safe side by over-approximating. Our evaluation shows
that we can correctly trim libraries without the need for a whitelist.
Perses [65] and C-Reduce [55] are state-of-the-art program re-
duction tools that build upon the concept of (hierarchical) delta
debugging [44, 80]. Specifically, by specifying a program to be min-
imized and an arbitrary property test function, both these tools
return a minimized version of the input program that is also correct
with respect to the given property. Chisel [27] further improves this
approach, by leveraging reinforcement learning. In particular, via
repeated trial and error, Chisel builds (and further rectifies) a model
that determines the likelihood of a candidate (minimal) program to
pass the property test.
In antithesis to tools like the above, Nibbler does not require
any high-level specification regarding the functionality of the in-
put program/library. Our thinned libraries are guaranteed to be
correct under any given input to the set of applications that uses
them. Kurmus et al. [36] focus on reducing the attack surface of
the Linux kernel by removing unnecessary features. Unlike Nibbler,
they develop a tool-assisted approach for identifying and remov-
ing unnecessary features during the kernel’s configuration phase,
hence, omitting code during compilation.
A series of works [31, 32, 72] have focused on reducing bloat
in Java programs and the Java Virtual Machine (JVM). JRed [31]
employs static analysis to extract the FCG of applications and iden-
tify, and remove, the bytecode that corresponds to unused classes
and methods from the Java runtime. Similarly, Wagner et al. [72]
propose “slimming” the JVM by removing code that does not ex-
ecute frequently and dynamically fetching it from a server only
when it is required. The goal is to reduce the amount of code that
needs to be deployed in thin clients, such as embedded systems, by
dynamically deploying what is required.
Jiang et al. [32], instead of targeting the JVM, aim to cut specific
features that are not needed from Java programs. Starting from a
small set of methods responsible for implementing a feature, they
use static analysis and backwards slicing to identify and remove all
the code corresponding to the feature. While these approaches also
utilize static analysis, decompiling and reconstructing the FCG of
Java programs is less challenging than that of binaries [26].
Landsborough et al. [37] also propose removing unused fea-
tures from programs to reduce their attack surface. Their approach
involves manually disabling features in binaries and a genetic al-
gorithm that is applied in toy programs. Malecha et al. propose
software winnowing [41], an approach that uses partial evalua-
tion of function arguments during compilation to “specialize” code,
eliminating some unused code in the process.
In the same vein, TRIMMER [61] specializes program code, and
debloats applications, by leveraging user-defined configurations,
while Shredder [45] further introduces constant propagation analy-
ses to specialize system API functions. Lastly, Koo et al. [35] propose
the concept of configuration-based software debloating: i.e., the
removal of feature-specific code, which is exclusively used only
when certain configuration directives are specified/enabled. These
approaches are orthogonal to Nibbler, looking at software thinning
from a different perspective, while most of them (with the exception
of Shredder) require source code.
Other works approach debloating from a performance angle,
focusing on reducing memory consumption [9, 49, 79]. Despite
the similarity in name, slim binaries [23], proposed by Franz et al.,
refer to programs that are represented in an way that allows their
translation to multiple architectures.
Nibbler: Debloating Binary Shared Libraries
ACSAC ’19, December 9–13, 2019, San Juan, PR, USA
7.2 FCG Extraction
Sound and complete extraction of the FCG from binaries is an open
problem. Murphy et al. [47] perform an empirical analysis of static
call-graph extractors that operate on source code or at compile time.
Their findings indicate that there is significant variance, based on
the tool, and the potential for false negatives. The latter correspond
to undiscovered but existing call edges, which would be problematic
for our approach, as removal of used code can be catastrophic. As
existing FCG extraction methods are insufficient, we developed our
own method that is complete.
There are also various promising binary analysis and augmen-
tation frameworks [3, 7, 8] that reconstruct the FCG of binaries.
Even though these tools keep improving, errors are still possible
per their authors, as well as other researchers [5]. As such, their
analyses are not appropriate for Nibbler. Instead, the methods de-
scribed in control-flow integrity works for binaries [81, 82] are
more related to our approach. Unlike them though, we introduce a
novel methodology for eliminating AT functions—thereby deleting
extraneous CFG edges—and reconstruct a complete FCG that also
includes directs calls within and across modules.
8 CONCLUSION
In this paper, we presented Nibbler, a system which demonstrates
that debloating binary-only applications is possible and practical.
Nibbler identifies unused code in shared libraries and erases it. We
use a conservative FCG reconstruction algorithm to initially only
remove functions without pointers to them, which we refine by
introducing an optimization for eliminating functions with unused
pointers. We evaluated the debloating capabilities of Nibbler with
real-world binaries and the SPEC CINT2006 suite, where we elim-
inate 56% and 82% of functions and code, respectively, from used
libraries. Nibbler is able to correctly analyze binary software, by
only leveraging symbol and relocation information produced by
existing compilers.
Nibbler, and debloating generally, improves security of software
indirectly, by benefiting defenses. Continuous code re-randomization
systems get a performance boost, which we demonstrated by in-
tegrating Nibbler with Shuffler to lower overhead by 20%. Lower
overheads make such defenses more attractive for deployment on
production systems, or can be used to provide stricter security
guarantees (e.g., by raising re-randomization frequency) in criti-
cal systems. Control-flow integrity defenses also benefit, because
we remove code involved in allowable control-flows. Our evalua-
tion shows that Nibbler reduces the number of gadgets reachable
through returns and indirect calls by 75% and 49% on average.
ACKNOWLEDGMENTS
We thank the anonymous reviewers and Maverick Woo, our shep-
herd, for their valuable comments. This work was supported by the
Office of Naval Research (ONR) under awards N00014-16-1-2261
and N00014-17-1-2788. Any opinions, findings, and conclusions or
recommendations expressed herein are those of the authors and do
not necessarily reflect the views of the US government or ONR.
REFERENCES
[1] Martín Abadi, Mihai Budiu, Úlfar Erlingsson, and Jay Ligatti. 2005. Control-Flow
Integrity. In Proc. of ACM CCS. 340–353.
[2] Alexa. 2018. The top 500 sites on the web. https://www.alexa.com/topsites.
[3] Kapil Anand, Matthew Smithson, Khaled Elwazeer, Aparna Kotha, Jim Gruen,
Nathan Giles, and Rajeev Barua. 2013. A Compiler-level Intermediate Represen-
tation Based Binary Analysis and Rewriting System. In Proc. of EuroSys. 295–308.
[4] Starr Andersen and Vincent Abella. 2004. Changes to Functionality in Microsoft
Windows XP Service Pack 2, Part 3: Memory Protection Technologies, Data
Execution Prevention. Microsoft TechNet Library. http://technet.microsoft.com/
en-us/library/bb457155.aspx
[5] Dennis Andriesse, Xi Chen, Victor van der Veen, Asia Slowinska, and Herbert
Bos. 2016. An In-Depth Analysis of Disassembly on Full-Scale x86/x64 Binaries.
In Proc. of USENIX SEC. 583–600.
[6] David Bigelow, Thomas Hobson, Robert Rudd, William Streilein, and Hamed
Okhravi. 2015. Timely Rerandomization for Mitigating Memory Disclosures. In
Proc. of ACM CCS. 268–279.
[7] David Brumley, Ivan Jager, Thanassis Avgerinos, and Edward J. Schwartz. 2011.
BAP: A Binary Analysis Platform. In Proc. of CAV. 463–469.
[8] David Brumley, JongHyup Lee, Edward J. Schwartz, and Maverick Woo. 2013.
Native x86 Decompilation Using Semantics-Preserving Structural Analysis and
Iterative Control-Flow Structuring. In Proc. of USENIX SEC. 353–368.
[9] Yingyi Bu, Vinayak Borkar, Guoqing Xu, and Michael J. Carey. 2013. A Bloat-
aware Design for Big Data Applications. In Proc. of ISMM. 119–130.
[10] Amat Cama. 2014. Tool to generate ROP gadgets for ARM, AARCH64, x86, MIPS,
PPC, RISCV, SH4 and SPARC. https://github.com/acama/xrop.
[11] Nicolas Carlini, Antonio Barresi, Mathias Payer, David Wagner, and Thomas R.
Gross. 2015. Control-Flow Bending: On the Effectiveness of Control-Flow In-
tegrity. In Proc. of USENIX SEC. 161–176.
[12] Sang Kil Cha, Thanassis Avgerinos, Alexandre Rebert, and David Brumley. 2012.
Unleashing Mayhem on Binary Code. In Proceedings of the 2012 IEEE Symposium
on Security and Privacy. 380–394.
[13] Stephen Checkoway, Lucas Davi, Alexandra Dmitrienko, Ahmad-Reza Sadeghi,
Hovav Shacham, and Marcel Winandy. 2010. Return-Oriented Programming
Without Returns. In Proc. of ACM CCS. 559–572.
[14] Xi Chen, Herbert Bos, and Cristiano Giuffrida. 2017. CodeArmor: Virtualizing the
Code Space to Counter Disclosure Attacks. In Proc. of IEEE EuroS&P. 514–529.
[15] Chromium Blog . 2012. A Tale of Two Pwnies. https://blog.chromium.org/2012/
05/tale-of-two-pwnies-part-1.html.
[16] Corelan. 2011. Corelan Repository for mona.py. https://github.com/corelan/
[17] Stephen Crane, Per Larsen, Stefan Brunthaler, and Michael Franz. 2013. Booby
Trapping Software. In Proc. of NSPW. 95–106.
[18] National Vulnerability Database. 2019. BlueKeep Vulnerability (CVE-2019-0708).
NIST. https://nvd.nist.gov/vuln/detail/CVE-2019-0708
[19] Bruce Dawson. 2013. Symbols on Linux update: Fedora Fixes. https://randomascii.
wordpress.com/2013/03/05/symbols-on-linux-update-fedora-fixes/
[20] Solar Designer. 1997. Getting around non-executable stack (and fix). BugTraq.
https://seclists.org/bugtraq/1997/Aug/63