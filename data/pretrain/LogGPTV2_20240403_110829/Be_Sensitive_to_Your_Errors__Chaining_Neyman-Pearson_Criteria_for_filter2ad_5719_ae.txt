Measure
False positive rate
Detection rate
Precision
Recall
F1 Score
Lmir
Ldpinch
0.063% 0.16%
88.6%
75.0%
0.861
0.923
0.886
0.750
0.828
0.873
With a lower false positive rate threshold, the classiﬁer
trained by our framework reduces the false positive rate, and
thus leads to a higher precision measure. Under this lower
false positive rate threshold, the majority of the samples
labeled as positive by the classiﬁers indeed belong to the
malware families under study. For the Lmir family, although
a false positive rate threshold of 0.5% is used, the detection
rate is even higher than what we have observed when the
false positive rate threshold is 5%. This results from the
ﬂuctuations due to randomness in searching for the optimal
conﬁgurations by the genetic algorithm and the randomness
in partitioning the dataset for training and testing.
An alternative way of training a classiﬁer ensemble with
a high precision measure is to slightly modify the chain
Neyman-Pearson criterion: rather than ensuring that the
accumulative false positive rate is no greater than a certain
threshold, we search for conﬁgurations with the highest de-
tection rates under the constraint that the precision measure
should be no smaller than a predeﬁned threshold. If such
a threshold is set to be, say, 0.8, we expect the classiﬁer to
produce positive labels among which at least 80% of them
are true positives.
129(1) False positive rate
(2) Detection rate
(3) F1 score
Figure 10: Performances of the classiﬁers trained under the chain Neyman-Pearson criterion
6.2 Performance Comparison
In the previous subsection, we have demonstrated the clas-
siﬁcation performance using the chain Neyman-Pearson cri-
terion. Next we show how it compares against existing en-
semble learning techniques. For the sake of performance
comparison, we consider the following methods.
(1) Im-
puted : We combine all the features used in the previous
subsection together, and use the means of available values
to impute those missing ones. We further use three stan-
dard classiﬁers, kNN, SVM, and decision trees (C4.5) to
train classiﬁers from a subset of the imputed dataset. (2)
Boosting: Using each of the three classiﬁers from (1) as the
base learner, we further use the boosting method as the
ensemble classiﬁer.
(3) Bagging: Using each of the three
classiﬁers from (1) as the base learner, we further use the
bagging method as the ensemble classiﬁer.
(4) Stacking:
We stack all the three classiﬁers from (1) as the base learn-
ers together to create an ensemble classiﬁer. Due to space
limitation, we omit the details of these methods here and
refer interested readers to the existing literature (e.g., [29,
8, 24]). For fair comparison, we use the implementations of
these methods from a third-party machine learning software,
Orange [23]. In order for other researchers to reproduce our
results, we use the default settings in Orange in all the ex-
periments, except that for the stacking scheme, we use kNN
rather than Naive Bayes as the meta learner. Using the lat-
ter leads to very poor performance for malware classiﬁcation
(not shown here due to space limitation), and this has also
been observed in our earlier work [40].
In a new set of experiments, 80% of samples are labeled
and used to train the classiﬁer and the remaining 20% are
used for testing. Note that in the experiments, all the sam-
ples in the training dataset are labeled. The classiﬁcation
results are shown in Table 2. It is observed that none of the
standard approaches is able to produce false positive rates
below 5% for all the families: for each of these schemes, at
least ﬁve families have false positive rates higher than 5%.
Even with more labeled samples for training, the number of
malware families with a detection rate below 80% varies from
one to four among existing approaches, the best compara-
ble to our proposed scheme. These results suggest that the
ensemble classiﬁer trained based upon the chain Neyman-
Pearson criterion outperforms the existing methods.
The superior performance of our scheme is explained as
follows. First, the implementation by Orange, the software
we use for the standard methods, is not necessarily optimal.
Second, our method aggressively searches the best parame-
ter settings of the individual classiﬁers under the Neyman-
Figure 11: Execution time per instance
Pearson criterion, but the standard solutions do not. Last
but not least, our approach seeks to optimize the collective
performance of the entire classiﬁer ensemble in a sequential
manner, which is not done by the existing methods.
6.3 Execution Time for Online Classiﬁcation
As our goal is to automate the process of malware clas-
siﬁcation, one may wonder whether our proposed malware
classiﬁcation framework is suitable for online malware clas-
siﬁcation. We thus perform another set of experiments to
examine the average execution time spent on each malware
instance in the test dataset. We run our method on a Linux
workstation with 12 1.6Hz cores and 64G memory.
In our experiments, we only consider the execution time
spent on malware classiﬁcation. Hence, the time spent on
collecting the features that are necessary for classiﬁcation is
not counted in the execution time we show here. The test
dataset contains 3199 malware instances, which is fed to each
of the 12 classiﬁer ensembles we have trained in Table 1. For
each classiﬁer ensemble, we perform malware classiﬁcation
over the entire test dataset for 20 times. The mean execution
time per family is shown in Figure 11, together with its
standard deviation over these 20 runs.
Over all the 12 classiﬁer ensembles, the mean execution
time per malware instance is merely 0.2779 second, which
suggests that when we apply our malware classiﬁcation frame-
work on a new malware variant to test whether it belongs to
a speciﬁc family, the majority of the time would be spent on
collecting necessary features that are used for classiﬁcation,
rather than the classiﬁcation process itself. However, if we
want to test whether a new malware variant belongs to any
of existing families, we would have to test it against each
of the classiﬁer ensembles trained for these families. Still,
even though we have to test the malware variant against the
ensemble classiﬁers for 100 families, the total execution time
 0 0.005 0.01 0.015 0.02 0.025 0.03 0.035 0.04BagleBifroseHupigonKoobfaceLdpinchLmirRbotSdbotSwizzorVundoZbotZlobFalse positive rateMalware family 0.5 0.55 0.6 0.65 0.7 0.75 0.8 0.85 0.9 0.95 1BagleBifroseHupigonKoobfaceLdpinchLmirRbotSdbotSwizzorVundoZbotZlobDetection rateMalware family 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1BagleBifroseHupigonKoobfaceLdpinchLmirRbotSdbotSwizzorVundoZbotZlobPrecision, recall, and F1Malware familyPrecisionRecallF1 score 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9BagleBifroseHupigonKoobfaceLdpinchLmirRbotSdbotSwizzorVundoZbotZlobSeconds per instanceMalware family130Table 2: Performance comparison. The experiments use 80% of labeled samples for training, and the other
20% for testing. All numbers are in percentage. False positive rates (FPR) higher than 5% and detection
rates (DR) below 80% are shown in bold.
Family
Bagle
Bifrose
Hupigon
Koobface
Ldpinch
Lmir
Rbot
Sdbot
Swizzor
Vundo
Zbot
Zlob
KNN
Imputed
Tree
SVM
KNN
Boosting
Tree
SVM
KNN
Bagging
Tree
SVM
Stacking
FPR
13.2
6.5
2.0
6.8
17.9
7.6
31.8
18.3
3.9
3.1
2.8
7.8
DR
60.6
90.6
97.4
98.6
65.9
52.2
90.0
36.7
97.9
97.6
87.6
98.3
FPR
10.8
5.3
1.1
3.7
15.4
15.8
7.4
23.9
0.9
1.7
4.2
1.4
DR
89.7
95.0
98.9
97.9
79.6
82.8
93.9
73.2
99.0
98.4
95.4
98.5
FPR
6.7
8.0
2.6
1.2
19.3
8.8
23.3
22.4
2.8
1.4
3.7
3.0
DR
9.0
94.7
97.8
98.1
74.2
80.7
93.2
45.8
96.9
98.9
95.0
98.2
FPR
9.1
6.4
1.0
5.6
12.5
10.4
25.8
33.6
1.4
1.3
3.7
4.1
DR
84.0
93.9
97.7
94.1
69.2
80.1
91.5
50.3
98.3
98.1
91.3
98.5
FPR
10.8
5.3
1.1
3.7
15.4
15.8
7.4
23.9
0.9
1.7
4.2
1.4
DR
89.7
95.0
98.9
97.9
79.6
82.8
93.9
73.2
99.0
98.4
95.4
98.5
FPR
6.7
8.0
2.6
1.2
19.3
8.8
23.3
22.4
2.8
1.4
3.7
3.0
DR
9.0
94.7
97.8
98.1
74.2
80.7
93.2
45.8
96.9
98.9
95.0
98.2
FPR
12.0
6.7
2.1
6.3
14.9
8.4
32.5
9.5
3.3
3.1
1.8
7.4
DR
61.3
90.7
97.4
98.1
65.1
50.1
92.1