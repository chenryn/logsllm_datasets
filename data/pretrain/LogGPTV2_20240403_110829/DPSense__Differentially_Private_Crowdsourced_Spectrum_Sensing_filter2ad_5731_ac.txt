Compute divi∗,κ∗
divj = divj − divi∗,κ∗
j,k∗ ;
P ← P \ {i∗};
Sj ← Sj \ {Sj,k∗};
14:
15:
16:
17:
18:
end while
19:
20: end for
21: return {bi,κ
j,k}1≤i≤N,1≤j≤M,1≤k≤nj ,(cid:5)μ/2(cid:6)+1≤κ≤γ−(cid:5)μ/2(cid:6).
j,k∗ as in Eq. (6).
, ls
(lh
i,κoi
i,κ, ls
i,κ, ls
i,κ, ls
i,κ, ls
j,k) equal dist∗
j,k). Otherwise,(cid:10)dist(lh
(cid:10)dist(lh
let(cid:10)dist(lh
is ∞. Then we set to obtain the minimum(cid:10)dist(lh
value by(cid:10)dist(lh
they meet the fourth constraint in sensing time. Hence, we can in-
corporate the time constraint into participant i’s new travel distance
j,k). When participants satisfy the fourth constraint, we
i,κ, ls
j,k)
j,k) for each
participant among all the timestamps in [1, γ], and we denote this
j,k), where κoi is the best timestamp for par-
ticipant i to leave for sensing location ls
j,k to achieve the lowest
travel cost. Hence, the optimization objective can be changed to
j,k).
the minimization of
So now if we focus on a single sensing task j ∈ [1, M ], the prob-
lem has already been reduced to the k-partial set cover problem
as deﬁned above. In the deﬁnition, B corresponds to the subtask
set {Sj,k|1 ≤ k ≤ nj}. The collection of S corresponds to the
task assignment: participant i to fulﬁll subtask Sj,k for all i and
k. The cost function c maps S to B by the cost we deﬁned using
j . So the op-
timization problem is now a k-partial set cover problem. We then
need to solve this problem for all j ∈ [1, M ].
j,k). k is the diversity order constraint div∗
, ls
·(cid:10)dist(lh
(cid:10)dist(lh
(cid:3)nj
(cid:3)M
(cid:3)N
k=1 bi,κoi
i,κoi
i,κoi
, ls
j=1
i=1
j,k
Since the special problem is NP-hard, we now conclude that the
original problem deﬁned in Eq. 8 is NP-hard.
Note that there are alternative ways to formulate the optimiza-
tion. For example, it is possible to minimize the expected total
synthetic travel distance or the maximum synthetic travel distance.
These alternatives are left as future work.
5.6 A Heuristic Solution
We now introduce a heuristic approach to assign subtasks to par-
ticipants based on their smoothed location traces.
The overall assignment process is summarized in Algorithm 2.
301i}N
The intuition is to sequentially assign every subtask of one sens-
ing task to each participant with the smallest synthetic travel dis-
tance until the total expected diversity order exceeds the required
threshold. Speciﬁcally, the algorithm takes the sensing tasks T ,
subtask set {Sj,k}1≤j≤N,1≤k≤nj , participant set P, and PIM trace
set {Lo
i=1 as input and outputs all subtask assignments. Line 1
smooths all the PIM traces using Algorithm 1. Lines 2 to 10 com-
pute the synthetic travel distance for every participant with ev-
ery possible departing location and every subtask {Sj,k}nj
k=1. The
WHILE loop in Lines 12 to 19 assigns one subtask to one partici-
pant, whose synthetic travel distance is the smallest among all. The
WHILE loop terminates when the accumulative expected diversity
order exceeds the diversity order required for the sensing task Tj.
5.7 Participant Response
The SSP informs every selected participant about the subtask he
is assigned to. On receiving the subtask assignment, each partici-
pant calculates the true physical and synthetic travel distance using
his true predicted locations and then informs the SSP whether he
accepts the assignment based on the task acceptance model in Sec-
tion 5.4. If the participant agrees to fulﬁll a certain task, he will
need to be at the sensing location in the speciﬁed time to perform
spectrum sensing. Since the participants win the opportunity to per-
form the task based on the expected mobility traces, the payments
or rewards made by the SSP to the participants should be propor-
tional to the travel distances calculated using the expected mobility
traces as well. It is possible that the expected mobility traces pro-
vided by the participants differ from the real mobility traces. In
such cases, participants still need to make sure that they can perfor-
m spectrum sensing in a timely manner. The SSP can set up various
types of mechanisms to handle the cases when participants fail to
fulﬁll the sensing tasks they previously agreed to fulﬁll. For exam-
ple, a reputation system can be constructed to model the reliability
of each participant. When participants fail to perform certain tasks,
their reputations in the system decrease, and so do their payments
received for performing the sensing tasks. In addition, since partic-
ipants’ failure to perform sensing tasks could possibly lead to un-
satisﬁed diversity requirement, the SSP could assign a discounted
diversity gain when certain participants with bad history are select-
ed. How to design a fully workable reputation system remains as
our future work.
6. SIMULATION RESULTS
In this section, we present the experimental evaluation results of
DPSense. We adopt the knowledge construction module in [22] to
build the Markov transition matrix, which is implemented in C++.
All other modules are implemented in MATLAB on a PC with 2.67
GHz Intel i7 CPU and 9 GB memory.
6.1 Mobility Trace Dataset
We use the CRAWDAD dataset roma/taxi [2, 3] for our simu-
lations. The dataset contains the mobility traces of approximately
320 taxis collected over 30 days in Rome, Italy. Each mobility
trace consists of a sequence of GPS coordinates collected roughly
every seven seconds along with corresponding timestamps. In addi-
tion, the taxis in the dataset are not always moving at a high speed.
Those idling at one location or moving within a small region can be
used to simulate the static participants or the participants with very
limited moving regions. In our simulations, the time difference be-
tween two consecutive timestamp is 20 seconds.
The mobility traces within the center of Rome city are extracted.
We consider an area of 11.66 × 11.66 [km × km] as illustrated in
Fig. 5. We divide the area into a 35 × 35 grids of equal size. We
Figure 5: The city area where the mobility traces are extracted.
Figure 6: Sampled taxi mobility traces from dataset [2, 3].
then extract 2700 mobility traces in total, each of which contain-
s 150 timestamps. The 2700 mobility traces are shown in Fig. 6.
We quantize each GPS coordinate by mapping them into one of the
35×35 cells. As we can see, most of the traces are clustered in
the center area, resulting in a very dynamic and diverse transition.
The density of mobility traces in the four corners is much lower
than that in the center area, making it challenging to correctly track
the true locations using the PIM scheme. Out of the 2700 mobility
traces, 2000 are used to build the Markov transition matrix, and the
remaining 700 are used to represent the participants’ input traces in
our system. The division of the mobility trace dataset is to emulate
the practical application scenarios where the SSP can only obtain
the historical mobility data based on some large-scale generic loca-
tion traces which can be totally unrelated to the participants of our
system. Therefore, the construction of the transition matrix does
not adversely affect participants’ location privacy.
6.2 Simulation Setting
We consider a time period of 50 minutes. The sensing tasks are
all scheduled at the later half of the 50 minutes because it takes time
for participants to arrive at the designated sensing locations. Since
the timestamps are in the granularity of 20 seconds, each sensing
task is scheduled at a random one of the last 75 timestamps.
302)
m
k
(
r
o
r
r
e
e
c
n
a
t
s
i
D
6
5
4
3
2
1
0
0
)
m
k
(
r
o
r
r
e
e
c
n
a
t
s
i
D
3.5
3
2.5
2
1.5
1
0.5
0
0
50
100
Timestamp index
150
50
100
Timestamp index
150
(a) Distance between the original trace and the
PIM trace ( = 1).
(b) Distance between the original trace and the
smoothed PIM trace using the sliding window
( = 1).
)
m
k
(
r
o
r
r
e
e
c
n
a
t
s
i
D
4
3
2
1
0
0
1.2
1
0.8
0.6
0.4
0.2
)
m
k
(
r
o
r
r
e
e
c
n
a
t
s
i
D
0
0
50
100
Timestamp index
150
50
100
Timestamp index
150
e
z
i
s
X
Δ
e
z
i
s
X
Δ
14
12
10
8
6
4
2
14
12
10
8
6
4
2
0
0
(d) Distance between the original trace and the
PIM trace ( = 2).
(e) Distance between the original trace and the
smoothed PIM trace using the sliding window
( = 2).
Figure 9: Performance comparison using a single trace.
50
100
Timestamp index
(c) ΔX size ( = 1).
150
50
100
Timestamp index
(f) ΔX size ( = 2).
150
)
m
k
(
y
10
8
6
4
2
0
0
2
4
6
x (km)
)
m
k
(
y
10
8
6
4
2
0
0
2
4
PIM trace
Original trace
8
10
PIM trace
Original trace
8
10
6
x (km)
Figure 7: The original trace and the PIM trace ( = 1).
Figure 8: The original trace and the PIM trace ( = 2).
We set the simulation parameters as follows. The numbers in
bold are the default values if not mentioned otherwise. For the
generation of PIM traces,  is chosen among [1,2,3,4], and δ is in
the range of [0.01,0.02,0.03,0.04]. The number of participants N
is [400,500,600,700]. For the spectrum-sensing task assignment,
the size of the sliding window μ is chosen from [1,3,5,7,9], where
μ = 1 corresponds to the case where no sliding window is used.
In addition, we assume that all the participants have the same trav-
eling speed v=30 km/h. We expect that higher moving speed will
deliver better results because participants can travel a longer dis-
tance. Other parameters are set as follows. The maximum travel
distance MTD is 15 km. The number of sensing tasks M is cho-
sen from [4,6,8,10] with the number of subtasks nj=10 for every
sensing tasks. The minimum separation distance between sensing
locations d0 is 20 m. The sensing region for every sensing task
is a circle with radius R=300 m. The sensing tasks are randomly
generated with the diversity order requirement div∗
chosen from
[4,5,6,7]. The system parameter α is in the range of [0.8, 0.9, 1],
and the parameter β is chosen from [1, 1.2, 1.4, 1.6].
In our results, each data point represents the average of 100 run-
s. We use ΔX to represent the δ-location set. We also compare
DPSense with the baseline scheme which does not consider loca-
tion privacy and use raw mobility traces.
6.3 Performance Metrics
For the generation of PIM traces, we compare the distance error
(i.e., the Euclidean distance between the original trace and the PIM