### 7.2 Impatience

In a real network, when demand exceeds capacity, the number of active flows does not increase indefinitely. As per-flow throughput decreases, some flows or sessions will be interrupted due to user impatience or aborts by TCP or higher-layer protocols. We use the term "impatience" to encompass all causes of premature abandonment.

We are unaware of any published statistics on user impatience. This phenomenon is difficult to observe in practice because not all flow aborts are in response to excessive response times, and most impatience is manifested by session interruptions that may not be detectable as abnormal events. However, to gain some insight into this phenomenon, we propose a simple hypothetical model.

We assume that a flow of size \( s \) will be interrupted if its response time exceeds a patience duration \( \delta(s) \). It is natural to assume that \( \delta \) is an increasing but concave function of \( s \), as users' expected response times increase with flow size, but they require proportionally more throughput. Our simulations show that such impatience causes the number of active flows on a high-capacity link to stabilize and fluctuate slightly around a mean value. For simplicity, we assume that the number of flows is exactly constant, so each flow receives the same bandwidth share \( \theta \). A flow of size \( s \) is completed if and only if \( s \leq \theta \delta(s) \).

From the concavity of \( \delta \), there exists a critical flow size \( s^* \) such that \( s^* = \theta \delta(s^*) \). Flows smaller than \( s^* \) are completed, while larger flows are aborted. Given that the link is always saturated, we have:

\[
C = \lambda \int_0^\infty \min(s, \theta \delta(s)) dF(s)
\]

where \( F(s) \) is the flow size distribution. For Pareto-distributed flow sizes and constant patience duration \( \delta(s) = \delta \), the following closed-form formula can be derived:

\[
\theta = \frac{k \delta}{\beta - 1} \left( \frac{\rho}{\beta (\rho - 1)} \right)^{\frac{1}{\beta - 1}}
\]

The link goodput \( U \), which is the fraction of link capacity used by completed flows, is given by:

\[
U = 1 - \frac{(\beta - 1)(\rho - 1)}{\rho}
\]

Note that the link goodput can be zero, meaning all flows are interrupted, in the extreme case where the overload exceeds \( \frac{1}{\beta - 1} \times 100\% \).

This model provides insights into the impact of congestion. The results for constant patience are qualitatively representative of evaluations with different patience functions \( \delta(s) \). Both realized throughput and link goodput deteriorate with increasing load but are otherwise independent of link capacity. Realized throughput decreases as users become more patient, while goodput remains the same. Confirming the positive impact of a heavy-tailed size distribution noted in Section 7.1, both throughput and goodput improve as \( \beta \) decreases from 2 to 1. This is because impatience discriminates against large flows (elephants) and interrupts them after only a small fraction of their data has been transferred.

### 7.3 Reattempts

Aborted flows are not generally abandoned immediately; users often make repeat attempts. This behavior exacerbates the loss of goodput due to impatience, as reattempts are also likely to be interrupted. Consider the following simple model:

User behavior is modeled by a size-dependent patience duration as introduced in the previous section. If a user aborts, they reattempt with a fixed probability \( p \). Reasoning as above, the maximum completed flow size \( s^* \) now satisfies:

\[
C = \lambda \int_0^{s^*} s \, dF(s) + \lambda \int_{s^*}^\infty \frac{1 - p}{\theta \delta(s)} \, dF(s)
\]

Figure 12 plots goodput \( U \) against \( p \) in the case of a 20% overload, assuming constant patience duration and a Pareto size distribution.

![Impact of reattempts on link goodput](figure12.png)

The figure shows that the loss of goodput can be considerable. While the model is overly simple, it illustrates the negative impact of user behavior during overload. Network efficiency would benefit from a more proactive reaction to congestion.

### 7.4 Admission Control

An alternative to allowing an overloaded link to stabilize through impatience is to perform admission control [23]. If flows arriving when the achievable bandwidth is below an acceptable threshold are rejected immediately, there would be no cause for impatience. The advantage is that goodput is maintained close to 100% and is unaffected by reattempts. However, admission control increases the proportion of uncompleted flows, as it applies equally to both small and large flows. Since large flows (elephants) may be more important, this is not necessarily a disadvantage.

One advantage of admission control is that it can be applied selectively, with different admission thresholds for different traffic classes (see [3]).

### 8. Conclusions

To evaluate the throughput performance of elastic transfers, it is necessary to account for the dynamic nature of traffic. Traffic variations are most naturally modeled in terms of flows and sessions rather than packets, whose complex arrival process is largely determined by the closed-loop control of TCP connections. We have demonstrated that fluid flow statistical bandwidth sharing models can accurately predict the results of ns packet-level simulations.

Using results from the theory of stochastic networks, we have shown that in several ideally fair bandwidth sharing scenarios, the distribution of the number of active flows and the expected flow throughput have simple expressions valid under a wide range of realistic traffic assumptions. These expressions depend primarily on expected demand and are independent of characteristics such as the heavy-tailed flow size distribution or the self-similar flow arrival process. Further evaluations lead us to believe that the broad conclusions derived under an assumption of ideal fair sharing remain true under moderate discrimination due to different round-trip times (RTTs).

The expected flow throughput achieved on a link of capacity \( C \) bits/s with utilization \( \rho \) is roughly equal to the minimum of the residual capacity \( C(1 - \rho) \) and any rate limit arising from external factors such as the bandwidth available on other links, the user's modem speed, or the size of the advertised TCP receive window. Performance is generally satisfactory as long as demand is somewhat less than capacity, justifying usual provisioning procedures based on limiting utilization in the busiest period. However, currently used limits of 60%, for example, may be overly conservative.

Stochastic network models are unstable when demand exceeds capacity, as the number of active flows would grow indefinitely. In practice, network utilization stabilizes through user impatience and other reasons for aborting sessions or flows. Incomplete user transactions generally imply bandwidth wastage, leading to goodput significantly lower than capacity. According to a simple model of user behavior, overload also brings discrimination against larger flows, which are less likely to sustain the resulting low throughput.

We suggest that the key to quality of service is to apply adequate provisioning procedures coupled with traffic routing strategies designed to avoid demand overload. There appears to be little scope for service differentiation beyond the two broad categories of "good enough" and "too bad." Rather than relying on impatience to stabilize an overloaded link, it would be preferable to perform admission control at the flow or session level, maintaining sufficient throughput for admitted flows and avoiding bandwidth wastage on incomplete transactions.

### 9. References

[1] E. Altman, C. Barakat, and K. Avrachenkov. A stochastic model of TCP/IP with stationary random losses. In Proc. of ACM SIGCOMM’00, 2000.
[2] F. Baskett, K.M. Chandy, R.R. Muntz, and F.G. Pallacios. Open, closed and mixed networks of queues with different classes of customers. Journal of ACM 22, pages 248–260, 1975.
[3] S. Ben Fredj, S. Oueslati-Boulahia, and J.W. Roberts. Measurement-based admission control for elastic traffic. In Proceedings of ITC17, September 2001.
[4] A. Berger and Y. Kogan. Dimensioning bandwidth for elastic traffic in high-speed data networks. IEEE/ACM Trans Networks, 8(5):643–654, October 2000.
[5] D. Bertsekas and R. Gallager. Data Networks. Prentice-Hall International, 1992.
[6] T. Bonald and L. Massoulié. Impact of fairness on internet performance. In Proceedings of ACM SIGMETRICS’01, 2001.
[7] T. Bonald, A. Proutière, G. Régnie, and J.W. Roberts. Insensitivity results in statistical bandwidth sharing. In Proceedings of ITC17, September 2001.
[8] T. Bu and D. Towsley. Fixed point approximations for TCP behavior in an AQM network. In Proceedings of ACM SIGMETRICS’01, 2001.
[9] J.W. Cohen. The multiple phase service network with generalized processor sharing. In Acta Informatica 12, pages 245–284, 1979.
[10] M. Crovella and A. Bestavros. Self-similarity in world wide web traffic: Evidence and possible cause. In Proceedings of ACM SIGMETRICS’96, 1996.
[11] G. De Veciana, T.J. Lee, and T. Konstantopoulos. Stability and performance analysis of networks supporting services with rate control - could the internet be unstable? In Proceedings of IEEE INFOCOM’99, 1999.
[12] D.P. Heyman, T.V. Lakshman, and A.L. Neidhardt. New method for analyzing feedback protocols with applications to engineering web traffic over the internet. In Proceedings of ACM SIGMETRICS’97, 1997.
[13] G. Fayolle, A. de la Fortelle, J-M. Lasgouttes, L. Massoulié, and J.W. Roberts. Best-effort networks: modeling and performance analysis via large networks asymptotics. In Proceedings of IEEE INFOCOM’01, 2001.
[14] G. Fayolle, I. Mitrani, and R. Iasnogorodski. Sharing a processor among many classes. Journal of the ACM, 27:519–532, 1980.
[15] A. Feldman. Characteristics of TCP connection arrivals. K. Park, W. Willinger, editors, Self-similar network traffic and performance evaluation, J. Wiley & Sons, 2000.
[16] A. Feldman, A. Gilbert, P. Huang, and W. Willinger. Data networks as cascades: Explaining the multifractal nature of internet WAN traffic. In Proceedings of ACM SIGCOMM’98, 1998.
[17] A. Feldman, A. Gilbert, P. Huang, and W. Willinger. Dynamics of IP traffic: A study of the role of variability and the impact of control. In Proceedings of ACM SIGCOMM’99, 1999.
[18] A. Jean-Marie and P. Robert. On the transient behavior of the processor sharing queue. Queueing Systems Theory and Applications, 17:129–136, 1994.
[19] F.P. Kelly. Reversibility and Stochastic Networks. J. Wiley & Sons, 1979.
[20] F.P. Kelly, A. Maulloo, and D. Tan. Rate control for communication networks: shadow prices, proportional fairness and stability. Journal of the Operational Research Society, 49, 1998.
[21] A.A. Kherani and A. Kumar. Performance analysis of TCP with nonpersistent sessions. Preprint available at http://ece.iisc.ernet.in/~anurag/Anurag Kumar.html, 2000.
[22] L. Kleinrock. Queueing Systems, Volume 2. J. Wiley & Sons, 1975.
[23] L. Massoulié and J.W. Roberts. Arguments in favor of admission control for TCP flows. In P. Key and D. Smith, editors, Teletraffic Engineering in a Competitive World, Proceedings of ITC 16, pages 33–44. Elsevier, 1999.
[24] L. Massoulié and J.W. Roberts. Bandwidth sharing: objectives and algorithms. In Proceedings of IEEE INFOCOM’99, 1999.
[25] L. Massoulié and J.W. Roberts. Bandwidth sharing and admission control for elastic traffic. Telecommunication Systems, 15:185–201, 2000.
[26] J. Mo and J. Walrand. Fair end-to-end window-based congestion control. In Proceedings of SPIE’98 International Symposium on Voice, Video and Data Communications, 1998.
[27] C.J. Nuzman, I. Saniee, W. Sweldens, and A. Weiss. A compound model of TCP arrivals. In Proceedings of ITC Seminar on IP Traffic Modeling, Monterey, 2000.
[28] V. Paxson and S. Floyd. Wide-area traffic: The failure of Poisson modeling. IEEE/ACM Trans. Networking, 3(3):226–255, 1995.
[29] J.W. Roberts and S. Oueslati-Boulahia. Quality of service by flow-aware networking. Phil. Trans. R. Soc. London A, 358:2197–2207, 2000.
[30] M. Vojnovic, J.-Y. Le Boudec, and C. Boutremans. Global fairness of additive-increase and multiplicative-decrease with heterogeneous round-trip times. In Proceedings of IEEE INFOCOM’00, 2000.