title:Efficient High Hamming Distance CRCs for Embedded Networks
author:Justin Ray and
Philip Koopman
Efﬁcient High Hamming Distance CRCs for Embedded Networks
Justin Ray, Philip Koopman
Department of Electrical and Computer Engineering
Carnegie Mellon University
Pittsburgh, PA 15217
Email: {justinr2, koopman}@ece.cmu.edu
Abstract
Cyclic redundancy codes (CRCs) are widely used in
network transmission and data storage applications be-
cause they provide better error detection than lighter weight
checksum techniques. 24- and 32-bit CRC computations
are becoming necessary to provide sufﬁcient error detec-
tion capability (Hamming distance) for critical embedded
network applications. However, the computational cost of
such CRCs can be too high for resource-constrained em-
bedded systems, which are predominantly equipped with 8-
bit microcontrollers that have limited computing power and
small memory size. We evaluate the options for speeding
up CRC computations on 8-bit processors, including com-
paring variants of table lookup approaches for memory cost
and speed. We also evaluate classes of CRC generator poly-
nomials which have the same computational cost as 24- or
16-bit CRCs, but provide 32-bit CRC levels of error detec-
tion, and recommend good polynomials within those classes
for data word lengths typical of embedded networking ap-
plications.
1 Introduction
Using cyclic redundancy codes (CRCs) for error detec-
tion in embedded systems involves a tradeoff among speed,
memory consumption, and error detection effectiveness.
Because many embedded systems have signiﬁcant resource
constraints, it is important to understand the available trade-
off options and, if possible, ﬁnd ways to attain better error
detection at lower computational cost. In this paper we an-
alyze existing algorithm tradeoffs to quantify typical trade-
off parameters for embedded applications. Additionally, we
identify two new classes of 32-bit CRCs that can be calcu-
lated with the same computational cost as existing 16- and
24-bit CRCs while providing improved error detection ef-
fectiveness. For these special case polynomials, we have
computed the bound for error detection and provided a list
of polynomials with good error detection performance.
In general, codes that provide better error detection re-
quire greater effort to compute. The primary drawback to
the CRC is its computational cost, which is much higher
than simpler error codes such as the Fletcher checksum or
other addition-based checksums [7]. For the embedded do-
main, computational cost can be a major design factor be-
cause of the severe cost constraints on many systems. How-
ever, for those applications that must attain high levels of er-
ror detection, CRCs are the only practical alternative proven
in ﬁeld use.
CRCs are commonly used in enterprise, desktop,
and high-end embedded applications, including standards
such as Ethernet [12], ATM networks [4], and IEEE
1394(FirewireTM) [10]. More recently, CRCs with high
Hamming distances have become increasingly important for
deeply embedded systems. The Hamming distance (HD)
of an error code is the minimum number of bit errors that
must be present to potentially be undetected. For example,
a Hamming distance 6 code (HD=6) guarantees detection
of up to 5 bit errors in a single network message, but fails to
detect some fraction of possible 6-bit errors.
Safety critical embedded applications in particular re-
quire high Hamming distances. Applications such as au-
tomotive X-by-Wire protocols [8, 26] and train control net-
works typically require HD=6 at all message lengths. High
HD CRCs are also employed as auxiliary protection mecha-
nisms, often called “safety CRCs,” to provide additional er-
ror detection beyond the capability of ordinary network pro-
tocols. For example, the Multifunction Vehicle Bus (MVB)
train network uses an 8-bit CRC for each 64-bit packet of
data transmitted at the link layer. But the MVB logical
frame format (which can be as long as 256 bytes) uses a
32-bit CRC, called a “safety code” [16] to provide HD=6
protection for critical messages. Another rail example of
this is the “vital CRC” given in [11].
A particularly demanding constraint is that embedded
networks usually have a mix of high-end and low-end
nodes, and even the lowest cost node on a system must be
able to compute CRC values quickly enough to keep up with
Proceedings of the 2006 International Conference on Dependable Systems and Networks (DSN’06) 
0-7695-2607-1/06 $20.00 © 2006 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 12:11:24 UTC from IEEE Xplore.  Restrictions apply. 
network trafﬁc. This requirement becomes even more difﬁ-
cult if high-level services such as a protocol’s group mem-
bership approach require the active participation of all net-
work nodes. Because of this, we focus this paper on under-
standing CRCs performance tradeoffs for 8-bit microcon-
trollers, because they are by far the most prevalent devices
being used in embedded systems [27].
While CRCs have been in use for decades, it is difﬁcult
to ﬁnd engineering guidance for them, and even harder to
ﬁnd comprehensive design tradeoff information. In order to
explore the CRC computation in the embedded domain, we
have implemented various known CRC algorithms in mod-
ern 8-bit processors and have analyzed performance and re-
source requirements. In the process of implementing these
algorithms, we have identiﬁed some discrepancies in the ex-
isting literature, including confusion about what constitutes
a “correct” software implementation, incorrect check val-
ues, and problems with data processing order.
In addition to studying existing algorithms, we have de-
veloped and evaluated techniques which are optimized for
a special class of 32-bit CRC checksums that speed up cal-
culations and reduce memory requirements while achiev-
ing good error detection performance. We also present the
result of an exhaustive search of the space of these spe-
cial polynomials wherein we deﬁne the Hamming distance
bound and identify a list of “good” polynomials.
The remainder of this paper will focus on analyzing the
algorithms for and performance of correct, efﬁcient imple-
mentations of the CRC algorithm in the embedded domain.
Section 2 discusses the background and related work in this
area. Section 3 explores the tradeoffs among various al-
gorithms when implementation in low-end processors. Sec-
tion 4 describes a novel class of CRC generator polynomials
and how they may be used to achieve better performance
and error detection. Section 5 describes the experiments
we performed to measure the tradeoffs of various imple-
mentations. Section 6 compares the performance of new
and existing algorithms. Section 7 describes the correct im-
plementation of the core CRC computation and identiﬁes
known implementation issues. Section 8 summarizes the
paper and provides recommendations for system designers.
2 Background and Related Work
CRCs are widely used for error detection in a variety of
applications. Despite their prevalence, there are signiﬁcant
gaps in understanding the engineering tradeoffs in their use.
Commonly, there are even larger gaps between known best
approaches and common engineering practices.
2.1 Terminology
Some terms used in the following discussion are:
data word — the data that is fed into the CRC computa-
tion to produce the checksum.
Table 1. Bitwise Left-Shift CRC Algorithm
for (i=0; i<sizeof(data); i++) {
if (msb(data) ˆ msb(crc)) {
crc = (crc << 1) ˆ (poly);
} else {
crc = (crc << 1);
}
data <<= 1;
}
frame check sequence (FCS) — the value produced by
the CRC computation. This digest or checksum provides
the redundant information necessary for error detection.
code word — the data word with the FCS appended
undetected error — result of an error which happens to
corrupt bits in the code word in such a way that it produces
another valid code word. It is important to note that corrup-
tions can and often do occur in both the data word and FCS
portions of a code word.
burst error — an error pattern stated in terms of a length
m (i.e. an m-bit burst error) where two up to m bit errors
may occur exclusively in an m bit range.
Hamming distance (HD) — in the context of error de-
tection, the minimum number of bits in the code word that
must be independently corrupted in order to cause an unde-
tected error. For a CRC, the HD depends on the data word
length, the FCS length, and the generator polynomial used.
For example, the polynomial x8 + x5 + x2 + x1 + x0, which
has HD=4 for data words of 18 to 55 bits, will detect all 1-,
2-, and 3-bit errors for those lengths.
2.2 Mathematical Foundation
(cid:1)
(cid:2)
Mathematically, the CRC algorithm used to generate the
FCS can be described as modulo-two polynomial division.
Binary data can be represented as a polynomial where the
bit values are the coefﬁcients of various powers of x. In
other words, the data byte “01001001” can be represented
as “0·x7+1·x6+0·x5+0·x4+1·x3+0·x2+0·x1+1·x0”.
The CRC checksum is deﬁned by the equation:
mod g(x)
data(x) · xk
crc(x) =
where g(x) is the ”generator polynomial” of order k. A
more detailed description can be found in [24].
A C implementation of the CRC is given in Table 1.
For clarity, we will refer to this as the “left-shift algo-
rithm.” This algorithm processes the data most signiﬁcant
bit (MSB) ﬁrst, so the data is left-shifted through the regis-
ter, hence the name.
A polynomial of a given order m has m + 1 terms (from
xm term to the x0 term). In the software implementation,
the generator polynomial is an m-bit binary representation
of the CRC polynomial, where the most signiﬁcant term
(xm) is not actually present, but is implicitly understood to
be present. For example, the CCITT-16 polynomial (given
Proceedings of the 2006 International Conference on Dependable Systems and Networks (DSN’06) 
0-7695-2607-1/06 $20.00 © 2006 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 12:11:24 UTC from IEEE Xplore.  Restrictions apply. 
in [24] as x16 + x12 + x5 + 1) should be represented as
0x1021. Polynomials discussed in [14] have a binary ex-
pression which includes most signiﬁcant term (xm) but has
an implicit lowest order term (x0). Either form can be
used, depending on the implementation, but when speci-
fying polynomials, it is important to specify which form is
being used. The polynomial representation is unambiguous.
While arithmetic checksum codes can only provide
HD=2 or HD=3 for most data lengths, CRCs can give much
higher HD for the same FCS length. In addition, they detect
all burst errors up to the length of the FCS, and greater than
99% of burst errors longer than the FCS length [2]. As pre-
viously mentioned, critical embedded applications usually
have a high HD requirement of HD=6.
There are ﬁve basic parameters that affect the FCS out-
put by the CRC implementations in real systems: 1) CRC
polynomial, 2) initial CRC value, 3) ﬁnal value which is
XORed in the CRC register, 4) order in which data bits are
processed, and 5) order in which CRC bits are placed into
the FCS ﬁeld.
A partial list of these parameters for various standards
can be found in [1, 28]. A change in any of these parameters
will affect the ﬁnal FCS value. The orders of bit processing
and in which bits are placed into the FCS must be consistent
to preserve burst error properties (this is discussed further in
a Section 7). Having a non-zero initial value can be useful
for detecting bit-slip errors in data with a series of leading 0
bits. The initial and ﬁnal values do not affect HD; only the
CRC polynomial and data word length affect HD.
Given a maximum message length and required HD per-
formance, the art of selecting a CRC is choosing a good
generator polynomial, g(x), which determines the error de-
tecting performance of the CRC checksum [14, 5]. Conven-
tional wisdom suggests picking one of the “standard” poly-
nomials is safer than choosing one at random (e.g., [1]).
However, many “standard” polynomials have poor perfor-
mance, or suboptimal performance compared to identiﬁed
“good” polynomials [14]. As we will discuss later, there
are some special case situations where other polynomials
may be chosen to achieve more efﬁcient implementation.
In the discussion that follows, we use the notation
CRC32, CRC24, and CRC16 to refer to a generic (i.e.
no speciﬁc generator polynomial) CRC implementations
which have a 32-, 24- and 16-bit FCS sizes, respectively.
Any reference to a particular standard, such as the CRC32
standard, will be named speciﬁcally.
2.3 Related Work
There are a number of algorithms for producing an FCS
with desirable error detection properties, including arith-
metic checksums (e.g. Fletcher checksum), weighted sum
codes (WSC), and cyclic redundancy codes (CRC). Arith-
metic checksums are employed in TCP because they can be
computed very efﬁciently [3], but safety-critical and high-
reliability systems typically require error codes with HD of
six or greater [26, 8]. CRCs can achieve this, but at a higher
computational cost [18] than other checksum approaches.
Error detecting codes in general and cyclic redundancy
codes in particular have been studied for many years.
Castagnoli et al. [5], Lin et al. [17], and Peterson et al.
[23] are standard references in the ﬁeld. However, until
recently the difﬁcult problem of ﬁnding optimal codes re-
mained unsolved because of the signiﬁcant amount of com-
puting power required to examine all possible codes. Re-
cent advances enabled exhaustive searches for optimal poly-
nomials for CRC3 up to CRC16 to identify the optimal HD
bound [14].
[13] also presents the results for exhaustive
search for HD=6 polynomials for data words lengths up to
and beyond the Ethernet MTU size.
There is a signiﬁcant amount of research into improv-
ing CRC performance by using optimized or parallel imple-
mentations in special purpose hardware (e.g. VLSI [21] and
FPGA [20]). While this approach is essential for some high-
speed applications, there is still a need for software-based
implementations to support the common situation where
off-the-shelf components are used to reduce costs and im-
prove time to market.
Software implementations of the CRC take various
forms and have been published in [1, 6, 22, 24, 25, 28].
They detail various algorithms which we will discuss in
Section 3. Research addressing the relative speed of various
algorithms has been presented by [7, 15]. Generally, perfor-
mance studies deal with the effects of memory caching and
number of instructions for various algorithms on high-end
processors with large memory caches. However, deeply em-
bedded system designers need to understand performance
on processors that usually have no cache memory and have
different instruction sets.
We are aware of occasional instances where specialized
CRC polynomials such as the ones we discuss to speed
up computations have been considered for use in indus-
try projects. However, we have not been able to ﬁnd any
discussion of this topic in the academic literature, nor any
published analysis of performance tradeoffs or discussion
of which polynomials perform well in such situations.
3 CRC Implementations
for Embedded
Processors
A key tradeoff in implementing CRC error detection is
the memory space versus computation time tradeoff of the
algorithm used to compute the checksum. In this section we
examine different algorithms that use varying amounts of
memory to speed up CRC computations beyond the simple,
but slow, left-shift algorithm already described.
8-bit processors are sensitive to this tradeoff because
they often have relatively slow clocks and limited instruc-
Proceedings of the 2006 International Conference on Dependable Systems and Networks (DSN’06) 
0-7695-2607-1/06 $20.00 © 2006 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 12:11:24 UTC from IEEE Xplore.  Restrictions apply. 