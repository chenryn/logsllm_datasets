which utilizes invisible IR light to alter the environment perception
results of AV. Since AV’s camera can detect the IR light, it considers
the invisible lights as real objects without the human driver’s notice.
As a result, the human driver defense strategy is not working, which
introduces severe security risks to current AV.
Potential Defense Strategies. According to the existing security
risks, lots of work has been proposed to secure AV and defend
against potential attacks [40, 43, 59, 69, 73]. For example, SAVIOR
mainly leverage the physical invariants to validate the data gath-
ered from GPS/IMU sensors [59]. PyCRA utilizes the random probes
transmitted by the sensor and validate the received signal to detect
the potential attacks [69] while PGFUZZ provides a framework
to locate the bugs in robotic vehicle’s control software. In order
to defend against attacks on computer vision, the most common
solution is to utilize machine learning (ML) techniques to identify
the adversarial attacks [29, 49, 74]. The researcher can either utilize
adversarial training [63], modifying existing ML networks [45, 64]
or propose new models [52, 76] to defend against potential attacks.
For example, the author proposes a novel detection module includ-
ing context model, surface model and light model to validate the
frame captured by the camera [52]. However, these approaches
mainly focus on the visible light. Since IR light and visible magenta
light appear the same to the camera, tradition approaches cannot
work to defend against the ICSL Attack.
Different from their works, we leverage a unique feature of IR
light to defend against ICSL Attack. By analyzing the reflections
from objects, we can distinguish the IR light from visible light with
high accuracy.
9 CONCLUSION
In this paper, we propose the first work that explores the threat of
IR light to autonomous vehicles (AV) and introduce the I-Can-See-
the-Light Attack (ICSL Attack), which can effectively i) generate
invisible traffic lights, ii) create fake objects, iii) ruin the in-car
user experience, and iv) introduce SLAM errors to the autonomous
vehicle without human notice. To defend against the ICSL Attack,
we explore the features of IR light and introduce a novel lightweight
software-based detection module to secure the autonomous vehicle.
We also believe that it is easy for the attacker to implement the IR
light related attack, which requires the AV company to be aware of
the threat of the IR light.
10 ACKNOWLEDGEMENT
This project is partially supported by NSF grants CNS-1652669 and
CNS-1824491
Session 6C: Audio Systems and Autonomous Driving CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea1942https://hci.iwr.uni-heidelberg.de/content/bosch-small-traffic-lights-
[8] 2021. https://hub.hamamatsu.com/jp/en/technical-note/WITS-guide-detector-
dataset.
selection/index.html.
REFERENCES
[1] 2021. https://cleantechnica.com/tesla-sales/.
[2] 2021. https://en.wikipedia.org/wiki/Automotive_paint.
[3] 2021. https://en.wikipedia.org/wiki/Extended_Kalman_filter.
[4] 2021. https://en.wikipedia.org/wiki/Infrared.
[5] 2021. https://github.com/raulmur/ORB_SLAM2.
[6] 2021. https://github.com/ultralytics/yolov5.
[7] 2021.
[9] 2021. https://science.nasa.gov/ems/09_visiblelight.
[10] 2021. https://science.nasa.gov/ems/09_visiblelight.
[11] 2021. https://www.bosch.com/stories/automated-valet-parking/.
[12] 2021. https://www.daimler.com/innovation/case/autonomous/driverless-parking.
html.
1842.html.
[13] 2021. https://www.dji.com/robomaster-s1.
[14] 2021. https://www.edmundoptics.com/knowledge-center/application-notes/
optics/the-correct-material-for-infrared-applications/.
[15] 2021. https://www.engineeringtoolbox.com/light-material-reflecting-factor-d_
[16] 2021. https://www.gartner.com/en/newsroom/press-releases.
[17] 2021. https://www.globenewswire.com/news-release/2020/12/07/2140428/0/en/.
[18] 2021. https://www.mouser.com/ProductDetail/FRAMOS/Depth-Camera-D455e-
Starter-Kit?qs=QNEnbhJQKvZvXjcsxT4qKw%3D%3D.
[19] 2021.
https://www.perkinelmer.com/lab-solutions/resources/docs/TCH_
reflection-Measurements.pdf.
[20] 2021. https://www.redsun.bg/en/infraredheating/infrared-heat-waves/.
[21] 2021. https://www.robotshop.com/en/m8-1-ultra-lidar-sensor.html.
[22] 2021. https://www.sony-semicon.co.jp/e/products/IS/camera/.
[23] 2021. https://www.statista.com/chart/17144/test-miles-and-reportable-miles-
[24] 2021. https://www.tesla.com/autopilot.
[25] 2021.
https://www.therobotreport.com/cruise-waymo-lead-way-calif-
[26] 2021. https://www.uqgoptics.com/catalogue/filters/cut-off-blocking-filters/ir-
per-disengagement/.
autonomous-vehicle-tests/.
cut-off-filters/.
[27] 2021. https://www.wipro.com/engineeringNXT/.
[28] 2021. http://www.cvlibs.net/datasets/kitti/.
[29] Naveed Akhtar and Ajmal Mian. 2018. Threat of adversarial attacks on deep
learning in computer vision: A survey. Ieee Access 6 (2018), 14410–14430.
[30] Mithun Babu, Yash Oza, Arun Kumar Singh, K Madhava Krishna, and Shanti
Medasani. 2018. Model predictive control for autonomous driving based on time
scaled collision cone. In 2018 European Control Conference (ECC).
[31] Radhesh Bhat et al. 2019. Learning based demosaicing and color correction for
RGB-IR patterned image sensors. Electronic Imaging (2019).
[32] Adith Boloor, Karthik Garimella, Xin He, Christopher Gill, Yevgeniy Vorobey-
chik, and Xuan Zhang. 2020. Attacking vision-based perception in end-to-end
autonomous driving models. (2020), 101766.
[33] Carlos Campos, Richard Elvira, Juan J Gómez Rodríguez, José MM Montiel, and
Juan D Tardós. 2020. ORB-SLAM3: An accurate open-source library for visual,
visual-inertial and multi-map SLAM. arXiv preprint arXiv:2007.11898 (2020).
[34] Yulong Cao, Chaowei Xiao, Benjamin Cyr, Yimeng Zhou, Won Park, Sara Ram-
pazzi, Qi Alfred Chen, Kevin Fu, and Z Morley Mao. 2019. Adversarial sensor
attack on lidar-based perception in autonomous driving. In Proceedings of the
2019 ACM SIGSAC Conference on Computer and Communications Security.
[35] Shang-Tse Chen, Cory Cornelius, Jason Martin, and Duen Horng Polo Chau. 2018.
Shapeshifter: Robust physical adversarial attack on faster r-cnn object detector.
In Joint European Conference on Machine Learning and Knowledge Discovery
in Databases. Springer.
[36] Valentin Deschaintre, Miika Aittala, Fredo Durand, George Drettakis, and Adrien
Bousseau. 2018. Single-image svbrdf capture with a rendering-aware deep net-
work. ACM Transactions on Graphics (ToG) (2018).
[37] Raj Gautam Dutta, Xiaolong Guo, Teng Zhang, Kevin Kwiat, Charles Kamhoua,
Laurent Njilla, and Yier Jin. 2017. Estimation of safe sensor measurements of
autonomous system under attack. In Proceedings of the 54th Annual Design
Automation Conference 2017.
[38] Ivan Evtimov, Kevin Eykholt, Earlence Fernandes, Tadayoshi Kohno, Bo Li, Atul
Prakash, Amir Rahmati, and Dawn Song. 2017. Robust physical-world attacks on
machine learning models. arXiv preprint arXiv:1707.08945 (2017).
[39] Qingnan Fan, Jiaolong Yang, Gang Hua, Baoquan Chen, and David Wipf. 2017. A
generic deep architecture for single image reflection removal and image smooth-
ing. In Proceedings of the IEEE International Conference on Computer Vision.
3238–3247.
[40] Aidin Ferdowsi, Ursula Challita, Walid Saad, and Narayan B Mandayam. 2018.
Robust deep reinforcement learning for security and safety in autonomous vehicle
systems. In 2018 21st International Conference on Intelligent Transportation
[41] Clément Fredembach and Sabine Süsstrunk. 2008. Colouring the near-infrared.
Systems (ITSC). IEEE, 307–312.
In Color and Imaging Conference.
[42] Jianjun Hu, Songsong Xiong, Junlin Zha, and Chunyun Fu. 2020. Lane detection
and trajectory tracking control of autonomous vehicle based on model predictive
control. International journal of automotive technology (2020).
[43] Hyungsub Kim, Muslum Ozgur Ozmen, Antonio Bianchi, Z Berkay Celik, and
Dongyan Xu. [n.d.]. PGFUZZ: Policy-Guided Fuzzing for Robotic Vehicles.
([n. d.]).
[44] Juncheng Li, Frank Schmidt, and Zico Kolter. 2019. Adversarial camera stick-
ers: A physical camera-based attack on deep learning systems. In International
Conference on Machine Learning.
[45] Chunchuan Lyu, Kaizhu Huang, and Hai-Ning Liang. 2015. A unified gradi-
ent regularization family for adversarial examples. In 2015 IEEE international
conference on data mining. IEEE, 301–309.
[46] Francesco Marra, Diego Gragnaniello, and Luisa Verdoliva. 2018. On the vulner-
ability of deep learning to adversarial attacks for camera model identification.
Signal Processing: Image Communication (2018).
[47] Mark J Mears. 2005. Cooperative electronic attack using unmanned air vehicles.
In Proceedings of the 2005, American Control Conference, 2005.
[48] Noriyuki Miura, Tatsuya Machida, Kohei Matsuda, Makoto Nagata, Shoei
Nashimoto, and Daisuke Suzuki. 2019. A Low-Cost Replica-Based Distance-
Spoofing Attack on mmWave FMCW Radar. In Proceedings of the 3rd ACM
Workshop on Attacks and Solutions in Hardware Security Workshop.
[49] Seyed-Mohsen Moosavi-Dezfooli, Alhussein Fawzi, and Pascal Frossard. 2016.
Deepfool: a simple and accurate method to fool deep neural networks. In
Proceedings of the IEEE conference on computer vision and pattern recognition.
2574–2582.
[50] Nir Morgulis, Alexander Kreines, Shachar Mendelowitz, and Yuval Weisglass.
arXiv preprint
Fooling a real car with adversarial traffic signs.
2019.
arXiv:1907.00374 (2019).
[51] Raul Mur-Artal and Juan D Tardós. 2017. Orb-slam2: An open-source slam system
for monocular, stereo, and rgb-d cameras. IEEE Transactions on Robotics (2017).
[52] Ben Nassi, Dudi Nassi, Raz Ben-Netanel, Yisroel Mirsky, Oleg Drokin, and Yuval
Elovici. 2020. Phantom of the ADAS: Phantom Attacks on Driver-Assistance
Systems. IACR Cryptol. ePrint Arch. 2020 (2020).
[53] Sen Nie, Ling Liu, and Yuefeng Du. 2017. Free-fall: Hacking tesla from wireless
to can bus. Briefing, Black Hat USA (2017).
[54] Grazyna Palczewska, Frans Vinberg, Patrycjusz Stremplewski, Martin P Bircher,
David Salom, Katarzyna Komar, Jianye Zhang, Michele Cascella, Maciej Wo-
jtkowski, Vladimir J Kefalov, et al. 2014. Human infrared vision is triggered by
two-photon chromophore isomerization. Proceedings of the National Academy
of Sciences.
[55] W Scott Pegau, Deric Gray, and J Ronald V Zaneveld. 1997. Absorption and at-
tenuation of visible and near-infrared light in water: dependence on temperature
and salinity. Applied optics (1997).
[56] Jonathan Petit and Steven E Shladover. 2014. Potential cyberattacks on automated
vehicles. IEEE Transactions on Intelligent transportation systems (2014).
[57] J. Petit, Bas Stottelaar, and M. Feiri. 2015. Remote Attacks on Automated Vehicles
Sensors : Experiments on Camera and LiDAR.
[58] Jonathan Petit, Bas Stottelaar, Michael Feiri, and Frank Kargl. 2015. Remote
attacks on automated vehicles sensors: Experiments on camera and lidar. Black
Hat Europe 11 (2015).
[59] Raul Quinonez, Jairo Giraldo, Luis Salazar, Erick Bauman, Alvaro Cardenas, and
Zhiqiang Lin. 2020. {SAVIOR}: Securing Autonomous Vehicles with Robust Phys-
ical Invariants. In 29th {USENIX} Security Symposium ({USENIX} Security 20).
895–912.
[60] Joseph Redmon, Santosh Divvala, Ross Girshick, and Ali Farhadi. 2016. You
only look once: Unified, real-time object detection. In Proceedings of the IEEE
conference on computer vision and pattern recognition.
[61] Edward Rosten and Tom Drummond. 2006. Machine learning for high-speed
corner detection. In European conference on computer vision. 430–443.
[62] Ethan Rublee, Vincent Rabaud, Kurt Konolige, and Gary Bradski. 2011. ORB:
An efficient alternative to SIFT or SURF. In 2011 International conference on
computer vision. 2564–2571.
[63] Swami Sankaranarayanan, Arpit Jain, Rama Chellappa, and Ser Nam Lim. 2018.
Regularizing deep networks using efficient layerwise adversarial training. In
Proceedings of the AAAI Conference on Artificial Intelligence.
[64] Uri Shaham, Yutaro Yamada, and Sahand Negahban. 2015. Understanding adver-
sarial training: Increasing local stability of neural nets through robust optimiza-
tion. arXiv preprint arXiv:1511.05432 (2015).
[65] Prinkle Sharma, David Austin, and Hong Liu. 2019. Attacks on Machine Learning:
Adversarial Examples in Connected and Autonomous Vehicles. In 2019 IEEE
International Symposium on Technologies for Homeland Security (HST).
[66] Junjie Shen, Jun Yeon Won, Zeyuan Chen, and Qi Alfred Chen. 2020. Drift
with Devil: Security of Multi-Sensor Fusion based Localization in High-Level
Autonomous Driving under {GPS} Spoofing. In 29th {USENIX} Security
Session 6C: Audio Systems and Autonomous Driving CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea1943Symposium ({USENIX} Security 20). 931–948.
[67] Hocheol Shin, Dohyun Kim, Yujin Kwon, and Yongdae Kim. 2017. Illusion and
dazzle: Adversarial optical channel exploits against lidars for automotive applica-
tions. In International Conference on Cryptographic Hardware and Embedded
Systems. 445–467.
[68] Yasser Shoukry, Paul Martin, Paulo Tabuada, and Mani Srivastava. 2013.
Non-invasive spoofing attacks for anti-lock braking systems. In International
Workshop on Cryptographic Hardware and Embedded Systems.
[69] Yasser Shoukry, Paul Martin, Yair Yona, Suhas Diggavi, and Mani Srivastava.
2015. Pycra: Physical challenge-response authentication for active sensors un-
der spoofing attacks. In Proceedings of the 22nd ACM SIGSAC Conference on
Computer and Communications Security. 1004–1015.
[70] Chawin Sitawarin, Arjun Nitin Bhagoji, Arsalan Mosenia, Mung Chiang, and
Prateek Mittal. 2018. Darts: Deceiving autonomous cars with toxic signs. arXiv
preprint arXiv:1802.06430.
[71] Huixuan Tang, Xiaopeng Zhang, Shaojie Zhuo, Feng Chen, Kiriakos N Kutulakos,
and Liang Shen. 2015. High resolution photography with an RGB-infrared camera.
In 2015 IEEE International Conference on Computational Photography (ICCP).
[72] Emma Thilén. 2017. Robust model predictive control for autonomous driving.
[73] Vrizlynn LL Thing and Jiaxi Wu. 2016. Autonomous vehicle security: A taxon-
omy of attacks and defenses. In 2016 ieee international conference on internet
of things (ithings) and ieee green computing and communications (greencom)
and ieee cyber, physical and social computing (cpscom) and ieee smart data
(smartdata). IEEE.
[74] Qinglong Wang, Wenbo Guo, Alexander G Ororbia II, Xinyu Xing, Lin Lin, C Lee
Giles, Xue Liu, Peng Liu, and Gang Xiong. 2016. Using non-invertible data
transformations to build adversarial-robust neural networks. arXiv preprint
arXiv:1610.01934 (2016).
[75] Shu Wang, Jiahao Cao, Kun Sun, and Qi Li. 2020. {SIEVE}: Secure In-Vehicle
Automatic Speech Recognition Systems. In 23rd International Symposium on
Research in Attacks, Intrusions and Defenses ({RAID} 2020). 365–379.
[76] Weilin Xu, David Evans, and Yanjun Qi. 2017. Feature squeezing: Detecting
adversarial examples in deep neural networks. arXiv preprint arXiv:1704.01155
(2017).
[77] Chen Yan, Wenyuan Xu, and Jianhao Liu. 2016. Can you trust autonomous
vehicles: Contactless attacks against sensors of self-driving vehicle. DEF CON
24 (2016).
Session 6C: Audio Systems and Autonomous Driving CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea1944