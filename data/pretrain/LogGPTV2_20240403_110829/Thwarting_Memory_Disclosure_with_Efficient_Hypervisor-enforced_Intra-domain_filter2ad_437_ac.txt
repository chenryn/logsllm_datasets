ory, a VMExit happens due to EPT violation. Hypervisor
is then notiﬁed to checks the access pattern. If the access
request is originated from the main compartment code to
the secrets, and the corresponding function is not included
in the extracted functions from static analysis, an attack
attempt may happen.
In this case, the hypervisor should
stop the application execution and inform the user of the
abnormal access request. If this access request is complied
with the predeﬁned policies according to the result of static
analysis and the execution context, the hypervisor will then
include the corresponding function to the sensitive functions
closure in the secret compartment.
Termination. When the application is terminated, se-
crets should also be wiped out. If the application exits nor-
mally, it issues the SECAGE RESTORE hypercall, so that
Data
Code
Secret
Sensitive Functions
Potential Sensitive Functions
Application
Mark
Application
Application
Dynamic 
Analyse
(a)
Automatic 
Decompose
(e)
Main 
Compartment
Secret 
Compartment
Code
Data
Code
Data
Code
Data
Static 
Analyse
(b)
Application
Deploy
(f)
Function 
Extraction
(c)
Runtime Check
RUNTIME
(d)
Code
Data
Static Extracted
 Potential Sensitive Functions
Figure 6: The general process of application analysis
and decomposition
Figure 6 shows the process of the application analysis and
decomposition. Given an application and the user-deﬁned
secrets, we need to analyze the data ﬂow of the secrets, as
well as the sensitive functions that are possible to access the
secret data. While the static analysis can give a comprehen-
sive analysis on all possible execution paths of the program,
it has precision issues and may lead to larger TCB and over-
head. We observe that in most cases, the execution ﬂow of
secrets manipulation is relatively ﬁxed.
Based on this observation, We use a hybrid approach to
extracting the secret closure. Speciﬁcally, we adopt the dy-
namic approach to achieving a ﬂexible information ﬂow con-
trol (IFC) analysis to get the most common but possibly
incomplete secret closure (step (a)), and we also rely on the
comprehensive results of static analysis to avoid these corner
cases during runtime (step (b)(c)(d)). On the other hand, it
provides a series of mechanisms to automatically decompose
application during compilation time. Then, SeCage decou-
ples these secrets and sensitive functions into an isolated
secret compartment, which can be protected separately by
the hypervisor (step (e)(f)).
4.1 Hybrid Secret Closure Extraction
Static taint analysis. We leverage CIL to carry out
static taint analysis on the intermediate representation of
the application. We denote the set of secret data as {s}, and
the set of references to the secrets is donated as {sref }. Our
target is to ﬁnd all possible instructions, which is denoted
as sink, that dereference variable x ∈ {sref }. We deﬁne the
taint rules as follows:
n → m, y := x, x ∈ {sref }
{sref } := y :: {sref }
n → m, f(y1, ... yi, ... yn), yi ∈ {sref }
{sref } := argi :: {sref }
n → m, y := f (y1, ...yi, ...yn), retf ∈ {sref }
{sref } := y :: {sref }
(1)
(2)
(3)
1612n → m, y := sink(x), x ∈ {sref }
{s} := y :: {s}, {sref } := yref :: {sref }
(4)
When a program transmits from n to m, the data ﬂow
is tracked. Rule (1) says that the propagation of references
to secrets should be tracked. Rule (2) and rule (3) deﬁne
the rules of function calls, which mean that the propagation
of references to secrets through function parameters and re-
turn values should also be tracked. Finally, rule (4) indi-
cates that, upon any dereference of references to secrets, the
secret and its reference need to be tracked, and the sink in-
struction should be also recorded. According to polyvariant
analysis [7], the functions are analyzed multiple times. In
our approach, the {s} and {sref } keep changing during the
iterations and we stop the analysis when the program comes
to a ﬁxed point, where the secret and its reference set does
not change anymore. Through this taint analysis, we can
ﬁnally get a large number of potential sensitive functions.
Application.text
    mprotect(paddr, NONE)
    ...
    (cid:258)
    ...
    addr(i):        access paddr
    addr(i+1):     (cid:258)(cid:258)   
    ... 
1
4
2
Segfault_Handler
{
    log(addr(i))
    ioctl(fd, BP, addr(i+1))
    mprotect(paddr, RW)        
}
DB_Exception_Handler
{
    mprotect(paddr, NONE)      
}
3
SeCage_Module
{
switch ioctl
    case BP: set_breakpoint(DR0, addr(i+1))
}
Sink Instructions
...
addr(i)
...
itive Func
Sensitive Functions
...
func.2
...
User
Kernel
the sensitive functions set {fs}, and we do not ﬁnd any EPT
violation during the runtime. Nevertheless, we still decom-
pose the potential sensitive functions which are not included
in the dynamically extracted set to several separate mem-
ory sections, so that if any corner case happens, hypervisor
can dynamically add them to the secret compartment in the
runtime according to the predeﬁned policies. When the hy-
pervisor is required to add a potential sensitive function to
the secret compartment, SeCage will collect as much infor-
mation as possible to distinguish between legal and illegal
accesses. For example, it uses the trapped instruction to
check whether this is the sink instruction found in the static
analysis; it is also required to check whether this potential
sensitive function is modiﬁed, and whether the call-trace is
forged, etc. If there is any predeﬁned policy violated, SeCage
aborts the execution and sends the abnormal information to
the user to make decision.
4.2 Automatic Application Decomposition
Since the sensitive functions in {fs} are not self-contained,
SeCage uses the trampoline mechanism to enable communi-
cations between {fs} and the functions in the main com-
partment, which is deﬁned as {fn}. For each function call
f, we notate fcaller and fcallee as its caller and callee func-
tions.
If and only if one of the fcaller and fcallee belongs
to {fs}, it is required to deﬁne a corresponding trampoline
function t(f ), which is used to replace f in the next phase.
The formal deﬁnition is as follows:
Ps(func) = true ⇐⇒ func ∈ {fs}
Figure 7: Combining mprotect and debug exception
to dynamically extract sink instructions
∀f, ∃t(f ) =
Ps(fcallee) ∧ ¬Ps(fcaller)
fin
fout Ps(fcaller) ∧ ¬Ps(fcallee)
f
else
Dynamic closure extraction. To get the compact se-
cret closure, we adopt a simple but precise dynamic anal-
ysis by an innovative combination of mprotect and debug
exception techniques. Figure 7 shows the process of dy-
namic sensitive functions extraction. At the very begin-
ning, the application is instrumented to use secure malloc
to allocate memory for secret data. Then we use mpro-
tect system call to protect the secure memory (paddr ), and
register a user mode handler to handle the corresponding
segmentation fault upon violation. Anytime a sink instruc-
tion accesses the protected memory, it traps into the segfault
handler ( 1(cid:13)). This handler records the fault address of the
sink instruction ( 2(cid:13)), and issues one IOCTL system call to
the kernel module ( 3(cid:13)), which set up the breakpoint to the
next instruction in debug register 0 (DR0). After that, the
handler revokes the mprotect to the paddr to make forward
progress. Then, the sink instruction can successfully ac-
cess the memory after the segfault handler returns; but the
program traps to the predeﬁned debug exception handler
immediately in the next instruction ( 4(cid:13)), and in that case,
the exception handler can setup the mprotect to the paddr
again. We run the application several times with diﬀerent
workloads. For example, for Nginx server case, we can send
diﬀerent kinds of requests, until the set of sink instructions
is ﬁxed. Then we can get most of the sink instructions, as
well as their corresponding sensitive functions.
For the OpenSSL case, we totally get 242 sensitive func-
tions from static analysis and 20 from dynamic analysis. In
our experiment, we select the dynamically extracted ones as
If there is any function call from {fn} to {fs}, we deﬁne
a trampoline function fin. Similarly, a springboard function
fout is deﬁned for each function call from {fs} to {fn}. We
notate {ft} as the union of fin and fout sets.
Then we decompose an application to secret and main
compartments for SeCage protection. There are totally three
steps involved. First, 3 hypercalls are added to the applica-
tion accordingly (Section 3.4). Second, an automated script
is used to generate a ﬁle with deﬁnition and declaration of
trampoline functions {ft}, and modify the deﬁnition of sen-
sitive functions sfunc in {fs} and trampoline functions tfunc
in {ft} with GCC section attribute:
a t t r i b u t e
a t t r i b u t e
( ( s e c t i o n ( . s e ) ) )
( ( s e c t i o n ( . t r ) ) )
s f u n c ;
t f u n c ;
Normally, the GCC compiler organizes the code into the
.text section. The additional section attributes specify that
sfunc and tfunc live in two particular .se and .tr sections’
memory region which are isolated from memory of {fn}.
Thus, SeCage can protect them in the page granularity.
Finally, during the compilation phase, the CIL parses the
whole application, and replaces the {fs} involved function
calls with their respective trampoline function calls in {ft}.
SeCage also needs to modify the linker, to link the newly
created .se and .tr sections to the predeﬁned memory lo-
cation, so that the SECAGE INIT hypercall can pass the
appropriate memory addresses as the secret compartment
memory for the hypervisor to protect.
16135. USAGE SCENARIOS
We have implemented the compartment isolation part of
SeCage based on KVM. The hypervisor is mainly responsi-
ble for compartment memory initialization, EPT violation
and interrupt handling.
In total, SeCage adds 1,019 lines
of C code to the KVM, and the application decomposition
framework consists of 167 lines of C code, 391 Bash code
and 1,293 OCaml code to the CIL framework [1].
In this section, we present our case studies by applying
SeCage to three representative examples: protecting keys of
Nginx server with OpenSSL support from infamous Heart-
Bleed attack, protecting keys of OpenSSH server from a
malicious OS, and protecting CryptoLoop from kernel-level
memory disclosure.
5.1 Protecting Nginx from HeartBleed
The HeartBleed attack allows attackers to persistently
over-read 64KB memory data, which can lead to leakage
of private keys [4]. We use one of the PoCs [6] to reproduce
RSA private keys disclosure attack targeted on the Nginx
server with a vulnerable OpenSSL version 1.0.1f.
In our case, OpenSSL uses RSA as its cryptographic scheme.
In short, two large prime numbers (p and q) are chosen as
secrets in RSA, while their production N (N = p × q) is
referred to as the public key. When a client connects to the
server, the server uses p and q as private keys to encrypt
data (e.g., certiﬁcate), so that the client can use the corre-
sponding public key N to decrypt them. To steal the private
keys, an attacker can search the memory data returned in
HeartBleed messages for prime numbers. Since the N and
the length of the prime numbers (in bits) are known, it is
pretty simple to ﬁnd p or q by iteratively searching the ex-
act (e.g., 1024) number of bits and checking if they can be
divided by N as a prime. Once the attacker gets either of p
or q, the other is just the result of dividing N by the known
prime. In addition, there is a private key exponent called d
which is another prime number we need to protect.
To defend against HeartBleed attack using SeCage, we
ﬁrst mark the secrets to protect. In the OpenSSL case, the
exact prime numbers are stored in the memory pointed by
d ﬁeld in BIGNUM structure p, q and d. During the ap-
plication decomposition phase, we get all of sensitive and
trampoline functions as illustrated in section 4. The se-
cure malloc function is added to replace OPENSSL malloc
in some cases. OpenSSL uses BIGNUM memory pools to
manage BIGNUM allocation, SeCage adds another secure
pool which is used to allocate BIGNUM when it is protected
one. The CILLY engine then delivers the modiﬁed interme-
diate code to GCC, which compiles it to the ﬁnal executable
binary. Besides, the private keys stored in the conﬁguration
ﬁle should be replaced by the same length of dummy data.
After that, the hypervisor pushes the generated binary and
conﬁguration ﬁle to the guest VM, and starts the Nginx.
5.2 Protecting OpenSSH from Rootkit
In this scenario, we assume that the kernel is untrusted,
e.g., there is a malicious rootkit4 acting as part of operat-
ing system to arbitrarily access system memory, so that the
secret is exposed to the light of day. We simulate this sce-
nario by manually installing a rootkit that simply scans the
system’s memory and tries to ﬁnd out secret in applications.
4Rootkits are mostly written as loadable kernel module that
can do whatever kernel can do.
We run the OpenSSH server in this untrusted environ-
ment. During the authentication of OpenSSH server, the
client uses the host key and server key as server’s public keys
to encrypt the session key, and the private keys are used by
OpenSSH server for session key decryption. The server is
also required to send the acknowledge encrypted using the
session key to the client for authentication. Thus the pri-
vate keys are of vital importance such that the disclosure
of them can lead to the leakage of all network traﬃc, and
the attacker can pretend as server to deceive clients. Sim-
ilar to the Nginx server protection, we leverage the appli-
cation decomposition framework to analyze and decompose
OpenSSH, since OpenSSH uses OpenSSL with RSA crypto-
graphic schema as well, the process is quite similar with the
previous example.
5.3 Protecting CryptoLoop from Kernel
Memory Disclosure
As shown in Table 1, about half of the vulnerabilities are
kernel-level memory disclosure. Diﬀerent from application-
level memory disclosure, one successful exploit of these vul-
nerabilities can put the whole kernel memory data at risk of
being disclosed. In this scenario, we choose to enhance the
Linux kernel’s disk encryption module, CryptoLoop, which
is used to create and manipulate encrypted ﬁle systems by
making use of loop devices. CryptoLoop relies on the Crypto
API in kernel, which provides multiple transformation algo-
rithms. In our case, it uses the CBC-AES cipher algorithm
to do the cryptographic operations.
In this case, we deﬁne the AES cryptographic keys as se-
crets. The sensitive functions extraction framework is a little
diﬀerent, but the overall principle is the same: we allocate
a new page for the AES keys, and set the corresponding
page table entry as non-present. After that, we combine the
page fault with the debug exception to track and record the
secrets related functions. Diﬀerent from the cases of Ng-
inx and OpenSSH, the AES keys are originated from user-
provided password with hash transformation, thus the user
has to provide a dummy password, and calculate the real
hash value oﬄine, so that SeCage can replace the dummy
AES keys with the real ones.
6. SECURITY EVALUATION
6.1 Empirical Evaluation
Secrets exposure elimination. We evaluate to what
extent can SeCage achieve the goal of exposing secrets to ad-
versaries. To achieve this, we write a tool to scan the whole
VM memory and ﬁnd targeted secrets in it when running
Nginx and OpenSSH server. Figure 8 shows the heap mem-
ory 5 of related processes, for the software without SeCage
protection ((a) and (b)), there are several targeted secrets
found in the heap.
In contrast, for the SeCage protected
ones ((c) and (d)), we cannot ﬁnd any fragment of the se-
crets. For the CryptoLoop case, we run the ﬁo benchmark
to constantly do I/O operations in the encrypted ﬁle system,
and traverse the kernel page tables to dump the valid kernel
memory pages in a kernel module. With SeCage protection,
we ﬁnd no AES keys within the dumped kernel memory.
While without SeCage protection, we can ﬁnd 6 AES keys.
5we also dumped the stack memory, and found no secret at
all