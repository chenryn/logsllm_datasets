A garbling scheme is a five-tuple of algorithms:
(ev, En, Gb, Ev, De)
These five algorithms specify the actions taken by 𝐺 and 𝐸 when
executing the protocol. Informally, (1) En describes how cleartext
inputs are encoded as garbled shares, (2) Gb describes how 𝐺 con-
structs the garbled circuit, (3) Ev describes how 𝐸 uses input shares
and the garbled circuit to compute output shares, (4) De describes
how output shares are decoded to cleartext outputs, and (5) ev
provides a cleartext specification of the circuit semantics. Loosely
speaking, En, Gb, Ev, and De should together perform the same
task as ev while preventing 𝐸 from learning 𝐺’s inputs.
Construction 1 (OneHot Garbling Scheme). OneHot is the
tuple of algorithms defined in Figure 4 by reference to Figure 3.
Our scheme is a straightforward formalization of the high level
intuition given in Section 4.
OneHot satisfies the [BHR12] definitions of correctness, oblivi-
ousness, privacy, and authenticity. We include definitions and ex-
planations of each of these properties. Full formal proof of each
theorem is presented in Appendix A due to a lack of space.
Definition 5.2 (Correctness). A garbling scheme is correct if for
all circuits C and all inputs 𝑥:
De(𝑑, Ev(C, 𝑀, En(𝑒, 𝑥))) = ev(C, 𝑥)
where (𝑀, 𝑒, 𝑑) ← Gb(1𝜅, C).
Correctness requires the scheme to realize the semantics speci-
fied by ev. That is, the implementation matches the specification.
Theorem 5.3. OneHot is correct.
Correctness is mostly trivial, save the correctness of one-hot
gates. One-hot gate correctness can be inferred from discussion in
Section 4. See Appendix A for a full proof.
Definition 5.4 (Obliviousness). A garbling scheme is oblivious if
there exists a simulator Sobv such that for any circuit C and all
inputs 𝑥, the following are indistinguishable:
= Sobv(1𝜅, C)
(C, 𝑀, 𝑋) 𝑐
where (𝑀, 𝑒, ·) ← Gb(1𝜅, C) and 𝑋 ← En(𝑒, 𝑥).
Informally, obliviousness ensures that the material 𝑀 and en-
coded input shares 𝑋 reveal no information about the input 𝑥 or
about the output ev(C, 𝑥).
Theorem 5.5. If 𝐻 is a circular correlation robust hash function,
then OneHot is oblivious.
In short, because of the properties of 𝐻 we can simulate most
values by uniform bits. For Reveal gates, we instead simulate values
by sampling from each such gate’s specified distribution; this is
valid due to Requirement 2. See Appendix A for a full proof.
Definition 5.6 (Privacy). A garbling scheme is private if there
exists a simulator Sprv such that for any circuit C and all inputs 𝑥,
the following are computationally indistinguishable:
(𝑀, 𝑋, 𝑑) 𝑐
= Sprv(1𝜅, C, 𝑦),
where (𝑀, 𝑒, 𝑑) ← Gb(1𝜅, C), 𝑋 ← En(𝑒, 𝑥), and 𝑦 ← ev(C, 𝑥).
Privacy ensures that 𝐸, who is given (𝑀, 𝑋, 𝑑), learns nothing
about the input 𝑥 except what can be learned from the output 𝑦.
Theorem 5.7. If 𝐻 is a circular correlation robust hash function,
then OneHot is private.
The privacy simulator follows relatively trivially from the obliv-
iousness simulator and from our choice of output decoding string
𝑑 (Figure 4). See Appendix A for a full proof.
Definition 5.8 (Authenticity). A garbling scheme is authentic if
for all circuits C, all inputs 𝑥, and all poly-time adversaries A the
following probability is negligible in 𝜅:
Pr(cid:0)𝑌 ′ ≠ Ev(C, 𝑀, 𝑋) ∧ De(𝑑, 𝑌 ′) ≠ ⊥(cid:1)
where (𝑀, 𝑒, 𝑑) = Gb(1𝜅, C), 𝑋 = En(𝑒, 𝑥), and 𝑌 ′ = A(C, 𝑀, 𝑋).
Authenticity ensures that even an adversarial 𝐸 cannot construct
shares that successfully decode except by running Ev as intended.
Theorem 5.9. If 𝐻 is a circular correlation robust hash function,
then OneHot is authentic.
Authenticity is nontrivial only for one-hot gates. One-hot gates
can be shown authentic due to the properties of 𝐻. See Appendix A
for a full proof.
5.5.1 Compatibility with Stacked Garbling. As mentioned in Sec-
tion 2, stacked garbling (SGC) is a state-of-the-art GC improvement
for conditional branching [HK20a, HK21]. SGC is parameterized
over an underlying garbling scheme which it leverages to handle
each conditional branch. OneHot can, in a slightly limited sense,
be used as this underlying scheme.
SGC requires that the underlying scheme produces garbled mate-
rial 𝑀 and inputs shares 𝑋 that are indistinguishable from uniform
strings. Our scheme satisfies this, with the notable exception of
Reveal gates. OneHot can be ‘stacked’ so long as all Reveal gates
use uniform binary strings as their output distribution Dout.
In Appendix A, we prove that, under this condition, OneHot is
strongly stackable [HK21] and can be the SGC underlying scheme.
6 EXPERIMENTAL SETUP
In the following section, we give experimental findings of the per-
formance of our technique as compared to standard Boolean circuits.
We record details of our experimental setup here.
Implementation Details. We implemented our technique and
benchmarks in ∼ 2000 lines of C++. Our implementation uses our
garbling scheme to instantiate a semi-honest 2PC protocol. Garbled
shares are 128 bits long. Hence our security parameter 𝜅 = 127; the
128th bit is reserved for share color.
We compare our implementation against half-gates [ZRE15]. We
refer to half-gates based implementations of our experiments sim-
ply as ‘standard’. We do not compare in detail to the concurrent
Session 2D: Secure Multiparty ComputationCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea583Procedure:
and 𝑏 ∈ {0, 1}𝑚.
• Parties reveal to 𝐸 𝑎 ⊕ 𝛼 and 𝑏 ⊕ 𝛽 for uniform 𝛼 ∈
{0, 1}𝑛, 𝛽 ∈ {0, 1}𝑚 via Color gates. Notably, the Color
Input: Parties input shared bitstrings(cid:74)𝑎(cid:75),(cid:74)𝑏(cid:75) where 𝑎 ∈ {0, 1}𝑛
Output: Parties output a shared matrix(cid:74)𝑎 ⊗ 𝑏(cid:75).
gates output(cid:74)𝑎 ⊕ 𝛼(cid:75),(cid:74)𝑏 ⊕ 𝛽(cid:75), and(cid:74)𝛼(cid:75).
• Parties compute(cid:74)H(𝑎 ⊕ 𝛼) ⊗ 𝑏(cid:75) via a one-hot gate.
• Parties compute(cid:74)H(𝑏 ⊕ 𝛽) ⊗ 𝛼(cid:75) via a one-hot gate.
T (id)⊺ ·(cid:74)H(𝑎 ⊕ 𝛼) ⊗ 𝑏(cid:75) =(cid:74)(𝑎 ⊕ 𝛼) ⊗ 𝑏(cid:75)
T (id)⊺ ·(cid:74)H(𝑏 ⊕ 𝛽) ⊗ 𝛼(cid:75) =(cid:74)(𝑏 ⊕ 𝛽) ⊗ 𝛼(cid:75)
• 𝐺 locally computes 𝛼 ⊗ 𝛽. He injects(cid:74)𝛼 ⊗ 𝛽(cid:75) as a constant.
(cid:74)(𝑎 ⊕ 𝛼) ⊗ 𝑏(cid:75) ⊕(cid:74)(𝑏 ⊕ 𝛽) ⊗ 𝛼(cid:75)⊺ ⊕(cid:74)𝛼 ⊗ 𝛽(cid:75) =(cid:74)𝑎 ⊗ 𝑏(cid:75)
• Parties compute the following two outer products:
• Parties compute and output:
Lemma 4.1
Lemma 4.1
See Section 4.3 for a correctness argument.
Figure 5: Efficient small domain outer product module. The
module implements the function 𝑎, 𝑏 ↦→ 𝑎 ⊗ 𝑏.
work [RR21]; moreover their technique has not yet been imple-
mented. For many of our applications, our improvement will be
slightly diminished given a fast [RR21] implementation. In particu-
lar, our work improves over [RR21] for all considered applications,
except for AES S-Box.
Computation Setup. For each experiment, we ran both 𝐺 and 𝐸
on a single commodity laptop: a MacBook Pro with an Intel Quad-
Core i7 2.3GHz processor and 16GB of RAM. The two parties run
in parallel on separate processes on the same machine.
Communication Setup. 𝐺 and 𝐸 communicate over a simulated
100Mbps WAN. (For completeness we configure the network with
30ms latency, though this is largely irrelevant in our experiments
which do not incur multiple rounds of interaction.)
In our experiments, we record bandwidth consumption and wall
clock time. For each experiment, we build a top-level circuit that
repeatedly uses the target module 1000 times; our presented mea-
surements divide total communication/total wall clock time by 1000
to approximate the cost of a single module instance.
7 APPLICATIONS
In this section, we instantiate applications of our approach. Each
application is formalized in our framework (see Section 5); when
necessary, we implement a module.
We mention that all of the following modules, with the excep-
tion of our binary field inverse and our modular reduction, are
compatible with stacked garbling.
7.1 Small Domain Binary Outer Products
Our first module follows naturally from our one-hot primitive.
Let 𝑎 ∈ {0, 1}𝑛 and 𝑏 ∈ {0, 1}𝑚 be two bitstrings and let 𝑛, 𝑚 be
small (formally, at most logarithmic in the overall circuit input size).
Figure 6: Communication consumption (top) and wall clock
time (bottom) when computing the outer product of two 𝑛-
bit vectors. We varied 𝑛 from 1 to 9. The standard method
computes the outer product using AND gates. Our technique’s
computation scales exponentially in the vector sizes, but is
more efficient for vectors between lengths 4 and 8.
The module maps two input garbled sharings(cid:74)𝑎(cid:75),(cid:74)𝑏(cid:75) to the outer
product(cid:74)𝑎 ⊗ 𝑏(cid:75).
This module was explained in Section 4 and is formalized in
Figure 5. Because we need XOR-based masks, we use Color gates.
The full construction consumes only 3(𝑛 + 𝑚) − 4 ciphertexts,
a significant improvement from the 2𝑛𝑚 ciphertexts needed to
compute the outer product via AND gates.
We implemented our module and experimented with its perfor-
mance. Figure 6 plots the results.
7.2 General Binary Outer Products
We have shown how to compute the outer product of two short
vectors. We are, so far, limited to short vectors because of the
exponential computation scaling of our one-hot technique.
It is interesting to compute the outer product of vectors of all
sizes, not just short ones. Here, we give an efficient construction of
general outer products.
In Section 7.1 we decomposed 𝑎 ⊗ 𝑏 into three summands:
(𝑎 ⊗ 𝑏) = ((𝑎 ⊕ 𝛼) ⊗ 𝑏) ⊕ ((𝑏 ⊕ 𝛽) ⊗ 𝛼)⊺ ⊕ (𝛼 ⊗ 𝛽)
The third term is known to 𝐺 and is free. The other two terms must
be computed inside the GC. Consider the term (𝑎 ⊕ 𝛼) ⊗ 𝑏.
In Section 7.1 we insisted that this outer product be computed by
a single one-hot gate. More generally, we can tile together multiple
one-hot outer products. We ensure the tiles are small enough that
computation remains polynomial in the input size.
Each tile computes the outer product of a 𝑘-bit chunk of 𝑎 ⊕ 𝛼
with 𝑏, yielding a 𝑘×𝑚 submatrix of the full outer product (𝑎⊕𝛼)⊗𝑏.
Vertically concatenating the ⌈𝑛/𝑘⌉ submatrices yields the correct
Session 2D: Secure Multiparty ComputationCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea584Comm. (KB)
Time (ms)
Standard Ours
21.3
2.32
32.0
3.20
Improvement
1.51×
1.38×
As compared to outer products and matrix multiplication, our im-
provement here is less substantial: after the outer product is com-
puted, our technique still must add together values in the standard
manner. Still, we achieve improvement to an important primitive.
In the GC setting, the Karatsuba fast multiplication method
improves over standard multiplication even for small 20-bit in-
tegers [HKS+10]. Karatsuba is a recursive divide-and-conquer al-
gorithm. At the leaves of the recursion (i.e. for 19-bit numbers or
less), it is best to use standard multiplication. We thus can use our
improved standard multiplication method to accelerate Karatsuba-
based multiplication.
7.5 Binary Field Multiplication
Consider an arbitrary binary field GF(2𝑛). In such fields, multiplica-
tion can be understood as polynomial multiplication modulo an ir-
reducible polynomial 𝑝(𝑥). By representing elements 𝑎, 𝑏 ∈ GF(2𝑛)
as vectors of bits, we can easily compute the product of the two poly-
nomials from the vector outer product. Once computed, the product
can be reduced modulo 𝑝(𝑥) by a linear function [GKPP06]. Thus,
our outer product construction improves binary field multiplication
by the “chunking factor” 𝑘 (see Section 7.2).
Because this multiplication only uses a black box outer product
followed by XORs, we do not need to formalize a module.
We implemented both our approach and a standard circuit for
GF(28) (modulo 𝑥8 + 𝑥4 + 𝑥3 + 𝑥 + 1). We used the best available
standard circuit for this field [BDP+20]. We ran our version with
chunking factor 𝑘 = 4 and 𝑘 = 8. We list communication, wall clock
time, and corresponding improvement over standard:
Comm. (Bytes)
Time (𝜇s)
Standard
1536
146
𝑘 = 4
𝑘 = 8
896
80
1.71× 704
1.82× 111
2.18×
1.3×
Despite the fact efficient hand-tuned circuits are available, we im-
prove communication consumption by more than 2×.
7.6 Binary Field Inverses and the AES S-Box
Our technique can compute binary field inverses using less commu-
nication than the state-of-the-art. Consider a field GF(2𝑛) where 𝑛 is
small (formally, logarithmic in the circuit input size). Let 𝑎 ∈ GF(2𝑛)
be a field element and suppose 𝑎 ≠ 0 (we handle this separately).
Our module follows from a technique given by [BIB89]. Namely,
for non-zero input 𝑎, we first compute 𝑎 · 𝛼 for uniform non-zero
mask 𝛼. Then, we reveal 𝑎 · 𝛼 to 𝐸. With this done, we use a one-hot