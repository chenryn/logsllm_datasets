Our survey results highlight why domain impersonation poses a
major threat to the web’s PKI. The fundamental role of the PKI
is to vet websites’ identities. The PKI and users both use domain
names to represent identity. Since the PKI is largely automated,
it correctly differentiates between google.com-signin.com and
google.com—and expects users to be able to do the same. To many
users, however, google.com-signin.com is google.com.
If an attacker can obtain a certificate for a domain d that appears
to be another domain d(cid:48), then in the eyes of users, the attacker is
effectively obtaining a certificate for a target website they do not own.
In other words, we view this form of domain impersonation as a
protocol-compliant attack on the fundamental role of the PKI.
Motivated by this conflict, we now measure the prevalence of
domain impersonation in the web’s PKI.
4 WIDE-SCALE ANALYSIS METHODOLOGY
In the remainder of this paper we evaluate how prevalent target-
embedded certificates are in the web today, who is doing the target-
ing, and who is being targeted. We start by introducing the datasets
we use and our approach to identify target embedded domains.
Nomenclature Before presenting our methodology, we briefly
overview the nomenclature used in the remainder of the paper. Con-
sider the domain appleid.apple.com-login.pw (a real target
embedding domain we observed in the wild), which we refer to as
the fully-qualified domain name (FQDN). We refer to apple.com as
the target domain and com-login.pw as the actual domain (where
the “domain” refers to the effective 2nd level domain plus suﬃx).
4.1 Certificate dataset
Our primary dataset comprises all certificates collected by Cen-
sys [12] up to May 18, 2019. Censys’s dataset includes a combina-
tion of active scans (they scan all IPv4 addresses and popular TLDs’
zone files) and Certificate Transparency (CT) logs. VanderSloot et
al. estimate that this combined dataset captures over 99% of ob-
served certificates [44]. Accordingly, we believe this to be a highly
accurate representation of all certificates on the web.
From this set, we obtain a total of 1,499,347,402 certificates, con-
taining a total of 529,515,677 unique FQDNs. We use this dataset to
evaluate the prevalence of target-embedding, combosquatting, and
typosquatting domains that appear on TLS certificates.
4.2 Identifying target embedding
We now describe our methodology for identifying target embedding
domains, and for filtering out false positives.
Step 1: Exact match Target embedding involves an exact match
of the target by using a subdomain, followed by a dot (for instance,
apple.com.ilogin.email) or a dash (amazon.com-buy.site)
and preceded by nothing, a dot (www.ebay.com--login.com), or
a dash (secure-paypal.com.tatpk.ru). This permits a straight-
forward initial filter: given a set of targets, one need only perform
a simple regular expression ([-\.]?t\.tld[-\.]) for each target
t.tld. Applied to our dataset, this step resulted in 468,184 unique
FQDNs.
This initial exact-match pass results in domains that have a tar-
get domain t and an actual domain a. However, not all of these
are necessarily impersonation. For instance, embedding should be
permitted when the target is owned by the actual domain (e.g.,
imdb.com.amazon.com) or when the target is identical to the ac-
tual domain (e.g., google.com.google.com).
Step 2: Filter target ownership In the next step, we filter out
all FQDNs for which it could reasonably be proved to a CA that
the actual domain a has ownership or control over the target t.
To infer ownership, we apply the same techniques as Cangialosi et
al. [9] to determine if two domains are managed by the same entity.
This involves obtaining WHOIS data for all t and a, extracting the
administrator email addresses from the WHOIS records, filtering
out privacy-preserving email addresses, and comparing the domains
in the email addresses. The 468,184 FQDNs from step 1 contained
131,218 unique (t, a) pairs. We successfully obtained WHOIS data
on 66,281 of these pairs, and used these to filter out 3,349 FQDNs.
Automated CAs like Let’s Encrypt do not require ownership of
domains to obtain a certificate; it suﬃces to demonstrate control
over the domain’s name server. To infer whether a has control over
t, we compare the authoritative DNS name servers for both a and t,
and filter out the FQDN if the name servers are “equivalent.” We take
a liberal approach: we consider them to be equivalent if even one of
their name servers shares the same e2LD (e.g., ns1.example.com
and ns2.example.com), or if they both have a name server in-
cluding the substring awsdns (e.g., ns-750.awsdns-29.net and
ns-510.awsdns-63.com). In so doing, we are likely obtaining a
lower bound on the number of target embeddings. Following this
process, we filtered out another 47,247 FQDNs. We note that an
automated CA would not have to make the same approximations
that we are: they could easily extend their ACME challenges to
actively prove control over both a and t (and any other targets
included in the domain).
The remaining FQDNs cannot be ruled out by the automated mecha-
nisms that many popular CAs take today. The CA/Browser baseline
requirements for issuance [8] would define the remaining FQDNs
as High Risk Certificate Requests, as they “may include names at
higher risk for phishing or other fraudulent usage.” It further re-
quires CAs to perform “additional verification activity for High Risk
Certificate Requests prior to the Certificate’s approval”. In an effort to
emulate what CAs would be required to do as a means of additional
verification, we perform two additional steps:
Session 10E: CertificatesCCS ’19, November 11–15, 2019, London, United Kingdom2492Step 3: Filter common subdomains Some of the Alexa top-100K
websites have e2LDs that are also common subdomains. Consider,
for example, if www.com were a top Alexa domain: this would mean
that every domain starting with com- would be considered target
embedding if it used the common subdomain www. We identified
20 domains in the Alexa top-100K whose e2LDs are also popular
subdomains. These include cpanel.com, mail.com, and mail.ru.
The popular cPanel web administration tool automatically adds the
subdomains cpanel and mail to websites that it manages. We filter
out all FQDNs that begin with these target domains, as they are
likely being used in conjunction with cPanel software. This, along
with the entire set of 20 target domains, filtered out an additional
24,099 FQDNs.
Step 4: Filter out web hosting providers Finally, we must ac-
count for the fact that some websites delegate certificate manage-
ment to third parties [9]. Cangialosi et al. [9] showed that popular
content delivery networks (CDNs) manage their customers’ certifi-
cates and often even generate their public-private key pairs. We
follow their methodology in identifying which actual domains a
are likely the hosting providers for the targets t: in particular, like
them, we identify the 100 most common a’s (both by unique FQDNs
and unique targets) and manually verify that they are services that
are likely in a business relationship with one another. We note that
CAs already perform this manual processing step: they establish
business relationships with popular providers to allow them to
purchase bulk certificates on others’ behalves. This filters another
137,625 FQDNs.
Final dataset After the above filtering, we obtained 256,045 unique
FQDNs, comprising 112,262 unique actual domains, 7,581 unique
target domains, and spanning 435,717 certificates.
Ethical considerations None of this data collection involved hu-
man subjects (excluding the user study in §3), nor did it involve
active probing of the web servers themselves (only queries to au-
thoritatively resolve their name servers). We conformed to the
terms and services of all of the services we used.
4.3 Comparing to prior impersonation schemes
We compare target embedding with typosquatting and combosquat-
ting by replicating prior detection techniques on our certificate
dataset:
Typosquatting We use the same methodology for identifying
typosquatting as used by Agten et al. [5]. They define typosquatting
as one of five mutations: add a character, delete a character, swap
two adjacent characters, fat-finger replace one character, or remove
the dot on a “www.” subdomain.
Combosquatting We follow the same methodology as Kintis et
al. [22] for detecting combosquatting. Given a set of target do-
mains, combosquatting involves checking whether the target’s
e2LD (e.g., “example” in example.com) is a strict substring of the
domain in question’s e2LD. For example, youtubevideos.com and
watch-youtube.ru are both examples of combosquatting with
youtube.com as the target. By definition, a domain that can be
considered typosquatting is not combosquatting. Filtering the set
of applicable target domains is a challenge when applying com-
bosquatting; we explain our method next.
Target domains Unfortunately, typosquatting and combosquat-
ting are limited in the set of target domains to which they can be
applied. To bound the number of false positives, prior typosquatting
work has limited analysis to target domains of at least five charac-
ters [32] and limited the number of targets to the 500–10,000 most
popular websites [5, 32, 41]. Similarly, prior combosquatting work
has limited their study to the Alexa top-500 most popular domains.
Worse yet, detecting combosquatting requires ignoring target do-
mains whose brands are substrings of common English words,
such as apple.com, att.com (because of words like “attorney”),
citi.com (“cities”), and so on [22].
To perform a fair apples-to-apples comparison, we replicate the
procedure used by Kintis et al. [22]. Unfortunately, several key de-
tails are elided from their paper; we describe here our good-faith
effort to replicate them. Like them, we begin with the Alexa top-500
most popular sites, and remove all e2LDs of length less than four
(their paper did not report on any targets of that size). We use
the standard Linux dictionary in /usr/share/dict/words to re-
move all targets whose e2LDs are equal to or substrings of the
dictionary’s 102,305 common English words. We then add back
domains that are in the Linux dictionary but also reported in their
paper: google, amazon, and yahoo. All together, this results in 320
e2LDs, which correspond to 407 Alexa top-500 domains1 (some do-
mains have the same e2LD but different TLDs, such as google.com
and google.co.uk). We use these 320 target e2LDs to determine
whether a domain is typosquatting and combosquatting.
Fortunately, target embedding is not subject to the same lim-
itations. In our analysis, we use the entire Alexa top-100K most
popular websites: 1–3 orders of magnitude more target domains
than could be studied in previous impersonation work [5, 7, 17, 20,
22, 32, 41, 43, 45]. As we will demonstrate, there are impersonating
domains well into the least-popular websites, which other imper-
sonation analyses could not detect. However, for this head-to-head
comparison with typosquatting and combosquatting, we limit it
to the 407 target domains with the same 320 e2LDs used in our
typosquatting and combosquatting analysis. Also, to yield a fair
comparison, we do not perform our additional filtering steps (after
step 1) for this smaller set of domains.
Google Safe Browsing To analyze the extent to which various
impersonation attacks are correlated with malicious activity, we
run all of domains we identify to have performed typosquatting,
combosquatting, or target embedding through Google Safe Brows-
ing [18]. Google Safe Browsing provides a binary classification—
safe or not—based on a combination of analysis by Google and
user reports. When loaded in Chrome, domains flagged by Google
Safe Browsing provide red-screen warnings to users. Various prior
studies downloaded website content and performed their own clas-
sification of content into benign, malicious, or phishing, either
manually [22] or through custom machine learning techniques [43].
We chose to instead rely on Safe Browsing’s data because it permits
more repeatable results, it is more scalable, and it can be applied
to websites that are no longer live. This last point is particularly
important, as phishing domains are typically live for only a few
days [30], yet our datasets spans years.
1This list, along with all of our code and data, is publicly available at
https://securepki.org
Session 10E: CertificatesCCS ’19, November 11–15, 2019, London, United Kingdom2493Flagged by
Safe Browsing
Impersonation type (# targets)
(0.72%)
1,635
Typosquatting (407)
14,801
(1.31%)
Combosquatting (407)
7,719
(6.17%)
Target Embedding (407)
Target Embedding (100K)
27,206 (10.63%)
Table 1: Comparison of target embedding to prior imperson-
ation schemes. Target embedding is much more strongly cor-
related with unsafe domains, and scales to handle orders of
magnitude more targets.
FQDNs
225,985
1,134,106
125,199
256,045
One shortcoming of Google Safe Browsing is that, although it has
broad coverage, it has not necessarily classified all of the domains
that we have identified. There are two reasons for this: first, it is
possible that the domains appear on certificates but a corresponding
website never went live. Second, it is possible that the domains were
live, but that users never reported them. Unfortunately, Google Safe
Browsing merely returns whether it has found the website to be
unsafe, and does not note whether it has any data on the site. Thus,
we cannot rely on Safe Browsing data for full coverage, but we
can still use it to compare how strongly the various impersonation
attacks correlate with unsafe sites.
Comparison results We present our comparison results in Ta-
ble 1, from which we make two key observations. First, target
embedding is much more strongly correlated with unsafe domains,
as determined by Google Safe Browsing. When limited to the same
407 target domains as typosquatting and combosquatting, target
embedding has a 8.6× and 4.7× higher ratio of unsafe domains.
The higher apparent false positive rates of prior schemes is in line
with previous studies, as well as our user study in §3: there is sim-
ply much more noise in typosquatting and combosquatting, which
complicates detection and deception. Conversely, target embed-
ding must contain the entire unaltered target domain. This offers
a cleaner signal of intent and, as our user study showed, a more
accurate means of deception. Second, target embedding is able to
scale to a much larger set of target domains, and in so doing, is able
to identify many more unsafe domains than the previous schemes.
When applying target embedding to the Alexa top-100K most pop-
ular websites, we found 16.6× more impersonating domains than
typosquatting and 1.8× more than combosquatting—and with 14.8×
and 8.1× higher fraction of these domains being unsafe.
Taken together, these results show that target embedding is
worthy of study as a unique and effective means of confusing users.
It is more strongly correlated with unsafe webpages and can scale
to more target domains, and thus it is a more effective lens than
prior schemes to study impersonation within the web’s PKI. In
the remainder of this paper, we perform a thorough, longitudinal
analysis of target embedding.
5 LONGITUDINAL STUDY OF TARGET
EMBEDDING
We now examine the use, cause, and risk of target embedding in
the web’s PKI.
Domain
apple.com
paypal.com
icloud.com
runescape.com
facebook.com
google.com
naver.com
amazon.com
starwars.com
ebay.com
163.com
live.com
mail.ru
bankofamerica.com
ebay.co.uk
chase.com
americanexpress.com
tripadvisor.com
banorte.com
amazon.de
Others
Unique Actual Domains Alexa Rank
77
78
408
1,822
3
1
263
12
24,867
36
738
19
44
305
149
183
523
227
17,467
83
69,362
28,449
14,911
7.135
6,179
4,572
3,107
3,084
3,076
2,825
2,528
1,680
1,575
1,513
1,490
1,444