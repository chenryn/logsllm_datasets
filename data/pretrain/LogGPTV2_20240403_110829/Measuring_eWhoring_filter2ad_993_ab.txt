### Optimized Text

#### Extracting Links from Known Image Sharing Sites and Cloud Storage Services
We utilize a whitelist of known image sharing sites (used for sharing previews of the packs) and cloud storage services (hosting the packs) to extract the corresponding links. This whitelist is compiled using a snowball sampling technique: starting with a known set of domains, we parse all URLs extracted from the TOPs and manually analyze a subset of the domains that are not on the whitelist by visiting their landing pages. This process is repeated until the URLs are either unknown or do not belong to cloud storage services or image sharing sites. Finally, the list of links corresponding to previews and packs is fed into a custom crawler, which downloads the images and, if necessary, decompresses the packs into folders. For each link, we also annotate associated metadata (e.g., the post identifier and author).

#### Results
Tables 3 and 4 show the number of links extracted per image sharing site and cloud storage service, respectively. Imgur is the most popular platform for sharing previews, followed by Gyazo and ImageShack. These platforms' terms of service prohibit uploading images containing nudity or violating copyright. Among the cloud storage services, MediaFire is the most used, followed by MEGA, Dropbox, and Oron (a now-defunct site). The terms of service for these platforms also forbid content that violates individual rights or copyright. Oron was shut down after being sued for copyright infringement, including pornographic material [20].

We crawled the links and were able to download 5,788 images from image sharing sites and 111,288 images contained in 1,255 packs. Many files and images had been deleted. After removing duplicates (e.g., 127 images found in at least 20 different packs), there were 53,948 unique files. Given that these packs are offered for free and are likely "saturated" (i.e., they have been used for eWhoring before), we expected to observe duplicate images.

**Table 3: Number of links per image sharing site.**
| Site         | #Links |
|--------------|--------|
| imgur        | 3,297  |
| gyazo        | 1,006  |
| imageshack   | 679    |
| prnt         | 383    |
| photobucket  | 311    |
| imagetwist   | 105    |
| imagezilla   | 97     |
| minus        | 51     |
| postimage    | 47     |
| imagebam     | 44     |
| Others       | 700    |
| **Total**    | 7,314  |

**Table 4: Number of links per cloud storage service.**
| Site          | #Links |
|---------------|--------|
| MediaFire     | 892    |
| mega          | 284    |
| Dropbox       | 130    |
| oron          | 95     |
| depositfiles  | 46     |
| filefactory   | 37     |
| drive.google  | 31     |
| ge.tt         | 28     |
| zippyshare    | 25     |
| filedropper   | 24     |
| Others        | 94     |
| **Total**     | 1,719  |

Not all files downloaded from image sharing sites correspond to actual previews, which will be discussed in Section 4.4.

#### Limitations
Some packs are released to users who reply to a specific thread or pay a fee. Due to ethical concerns, we did neither, limiting our results to openly shared, free packs. Out of 4,137 TOPs, we were able to extract links from 774 threads (18.71%). We used a whitelist of cloud storage and image sharing sites, potentially missing some sites. To mitigate this, we employed a snowball sampling method. When downloading images, we encountered two limitations: we did not download packs from sites requiring registration (e.g., Dropbox or Google Drive) due to Terms of Service violations, and many cloud storage services and image sharing sites are defunct or restrict the lifetime of links for free or trial accounts.

#### Filtering out Child Abuse Material
A potential legal issue in eWhoring is downloading and distributing child abuse material. After discussing with our Research Ethics Board, we contacted the UK Internet Watch Foundation (IWF) for assistance. They granted us access to the PhotoDNA Cloud Service, which computes a hash of a given image and matches it against a database of known child abuse material. Images matching the PhotoDNA list were immediately reported to the IWF and deleted from our servers. We also reported the URLs of other sites where these images were located, obtained from reverse image searches.

**Results:**
- 36 images matched the PhotoDNA hashlist.
- The IWF acted on 61 URLs, 60 related to a single UK victim aged 17, and one related to a 7 to 10-year-old victim.
- Severity: 20 images were Category A, 36 were Category B, and 5 were Category C.
- Hosting location: 1 site in the UK, 30 in North America, and 30 in other European countries.
- Site types: 26 image sharing sites, 9 forums, 3 blogs, 2 social networks, 1 video channel, and 20 regular websites.

Possession of child abuse material is a crime in many jurisdictions, placing actors and customers at risk of criminal charges. In some jurisdictions, these are "strict liability" offenses, meaning intent is not a defense. A defense may be available if the defendant can prove innocence, such as reporting the images to the police and deleting them (as we did).

The images were downloaded from links posted in 36 different threads, replied to by 476 different actors. Most replies expressed gratitude, indicating at least 476 actors are potentially downloading child abuse material. Some users discussed the age of the models, suggesting awareness of the legal risks.

**Limitations:**
The detection of child abuse material is limited by the accuracy of PhotoDNA technology. While offenders might try to evade detection by modifying images, PhotoDNA uses Robust Hashing to detect modified images. The robustness of this tool has not been independently verified, but it is the state-of-the-art technology used by law enforcement and non-profit organizations.

#### Image Classification
To address ethical and legal concerns, we developed an approach to minimize the amount of indecent images viewed by researchers. We developed a Not-Safe-For-Viewing (NSFV) classifier to discern between indecent images and other images containing text, such as screenshots of payment platforms or chats.

**Algorithm:**
```plaintext
Input: Image
Output: True if SFV, False otherwise
NSFW ← openNSFW(image)
OCR ← tesseract(image)
if NSFW < 0.3 then
    return False
else if NSFW > 0.7 then
    return True
else
    return OCR > 20
```

Among the 5,788 images downloaded from image sharing sites, 3,496 were classified as NSFV and included in the set of 'previews'. Other links pointed to error messages or pack directory screenshots.

**Limitations:**
We rely on open-source tools like Yahoo's OpenNSFW and Tesseract OCR. The thresholds and heuristics are established in a semi-automatic process tuned using a small dataset (240 images). We select conservative thresholds to minimize false negatives, increasing the likelihood of false positives. Hard-to-classify pictures include those without nudity but tagged as NSFV due to lack of text and resemblance to human body colors or textures. Adversaries might modify images to prevent detection, but our classifier is effective for discerning model previews from text-heavy images.

#### Reverse Image Search and Domain Classification
To analyze the provenance of eWhoring images, we used TinEye's reverse image search service, comparing images against a database of over 29 billion images. We performed reverse searches for 3,496 preview images and 3,644 images from 1,255 packs. We used domain classification tools (Cisco’s OpenDNS, McAfee’s URL ticketing system, and VirusTotal’s URL reputation service) to gain additional knowledge about the types of sites used to collect material.

**Results:**
- Total matches: 2,675 (74%) for packs and 1,683 (49%) for previews.
- Seen Before Ratio: 55.54% for packs and 39.01% for previews.
- Average matches per image: 12.7 for packs and 17.3 for previews.

From the 1,255 packs analyzed, 203 were zero-match, possibly due to images of actual models, from sites not in the TinEye database, or modified to bypass reverse searches. The reverse image search resulted in 5,917 different domains, with top categories mostly porn-related sites, though the distribution varies by classifier. Images are also taken from various sources, including social networks, online shops, photo sharing services, blogs, and forums.

**Limitations:**
Our results are biased by the effectiveness of TinEye in dealing with image modifications and the completeness of its database. Nonetheless, TinEye claims to handle a broad range of image transformations, making it a reliable tool for our purposes.