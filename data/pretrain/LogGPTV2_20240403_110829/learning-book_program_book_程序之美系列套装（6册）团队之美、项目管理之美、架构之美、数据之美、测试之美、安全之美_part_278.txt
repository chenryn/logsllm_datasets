---
## Page 1577
比如英语文本"choosespain.com"，这是个网站，希望你选择西班牙
作为旅行终点站。但是如果你把名字切分错误，你会得到这样的分
词"choosespain”，这个名字就不那么吸引人了。人工阅读可以通过
几年的经验来做出正确的决策；但是把这种经验编码为计算机算法
将是一项难以完成的任务。但是我们可以采取一种捷径，其效率之
好让人惊讶：在二元表里查询每个词汇。我们发现“chooseSpain"出
现了3210次，而"choosespain"在表里一次都没有出现（这意味着它
在1MB的语料库中出现次数少于40次）。因此，“chooseSpain"出现
至少80次，可以作为正确的分割。
假如我们需要解释短语insufficientnumbers”的含义，如果我们把单
词的大小写加起来，其计数是：
insufficient numbers 20751
in sufficient numbers 32378
“In sufficient numbers"的出现频率高于“insufficient numbers”，但是这
并不具备很强的说服力。这种情况令人沮丧：我们可以猜测，但是
无法确定。对于类似这种不确定问题，没有方法能够确定地给出正
确的值，我们还没有能够确保答案正确的完备模型，实际上人类专
家也没有一个完备的模型，可以不同意该答案。但是，解决不确定
问题有个确定的解决方案。
1.定义概率模型。我们无法定义所有的因子（语义的、语法的、词
汇的和社会的）使得选择"chooseSpain"对于一个域名是一个更佳的
候选。但是我们可以定义一个简化的模型，从而能得到近似概率。
对于"chooseSpain"这种简短的候选，我们可以在语料库数据中查找
n元，并使用该概率。对于更长的候选，我们需要切分为多个部
分，组合这些部分得到结果值。核心是我们定义语言模型一—在该
语言中所有字符串的概率分布一—从语料库数据中学习该模型参
数，然后使用该模型来定义每个候选的概率。
2.枚举候选项。我们无法确定"insufficientnumbers”还是“insufficient
mumbers"更可能是所期望的短语，但是我们可以确定它们都是候选
分割，如"insuficientnumbers"也是候选项，但"helloworld"不是有
效的候选项。在该步骤中，我们不做判断，只是枚举可能的候选项
1576
---
## Page 1578
如果可以，列出所有的候选项，或者列出仔细选择的一个样
本。
3.选择最可能的候选项。对每个候选项应用语言模型来获得它的概
率，选择概率最高的是选项。
如果你更习惯于数学等式表达，如下所示：
best=argmaxcEcandidates P(c)
或者，如果你更习惯于计算机代码表达，则如下：
best=max (c in candidates, key=P)
我们把这种方法用于分割中。定义一个函数、分段，把不包含空格
的字符事作为输入，返回最佳分段的单词列表。
>>>segment ('choosespain*)
['choose', 'spain']
我们从步骤1一—概率语言模型开始。单词序列的概率是每个单词
概率的乘积，假设单词的上下文是：所有上述单词。等式表达如
下：
P(W1: n) =IIk=1: nP(Wk/W1: k-1)
我们没有数据来精确地计算该等式。因此我们可以使用一个更小的
上下文来近似计算。由于数据序列大于五元，我们就采用五元文法
模型，因此N元文法的概率即给定前缀四个单词（不是前缀所有单
词）的每个单词的乘积。
五元文法模型存在三个难题。第一，五元数据大约30G，因此无法
全部装载到内存中。第二，很多五元计数将为0，我们需要一些回
退(bckingoff)策略，使用更短的序列来估计五元文法的概率。第
三，候选项的搜索空间将会很大，因为依赖性扩展到四个单词。这
三个难题花些时间都是可控的。但是，我们首先来考虑解决这三个
1577
---
## Page 1579
问题的一个更简单的语言模型：一元模型，其序列概率即每个单词
自身的概率乘积。在一元模型中，每个单词的概率和其他单词无
关。
P(W1:n) =IIk=1:nP(Wk)
对'wheninrome'进行分割，考虑这些候选项，如wheninrome，然后
计算P(when)xP(in)xP(rome)。如果该候选项的乘积高于任何其他候
选项，那么它就是最佳答案。
n个字符的字符串包含2n-1个不同的分割方式（字符间有n-1个位
置，每个位置都可以作为分割边界）。因此，字符
串'wheninthecourseofhumaneventsitbecomesnecessary包含35T的分割方
式。但是我确定你可以在几秒钟内找到合适的分割方式；显然，你
不可能枚举所有的候选类型。你可能浏览了“w”、“wh"和"whe”，并
作为不可能的单词放弃它们，而接受“when"作为可能的分割方式。
然后继续剩余部分，并找到它们的最佳分段方式。一旦我们简化假
设每个单词和其他的单词是不一样的，那意味着我们不需要考虑单
词的所有组合。
以上简单地给我们描述了segment函数：考虑把文本划分为一个起始
单词和剩余文本的所有方式（可以任意限制单词最大长度，如L=20
个字母）。对于每种可能的划分，找到对剩余文本分词的最佳方
式。在所有的候选项中，乘积P(first)xP(remaining)值最高的即为最
佳方案。
这里我们用一个表格来说明这个问题。表格中包含了第一个单词的
所有候选、该单词的概率、剩余单词的最佳分词概率以及所有的概
率（即第一个单词和剩余单词的概率的乘积）。我们发现，以
“when"开始的分词概率是第二个最佳候选的5万倍。
first
P(first)
P(remaining)
P(first)×P（remaining)
W
2+104
2+10-33
6*10-37
wh
5+10-6
6+10°33
3+10-38
whe
3*10~7
31032
7▪10~39
when
610-4
7*1029
4*10-32
wheni
110-6
3*10-30
31046
whenin
1.107
810-27
810-44
1578
---
## Page 1580
我们可以通过几行Python代码来实现分词：
@memo
def segment (text) :
"Return a list of words that is the best segmentation of
text."
if not text:return[]
candidates= ([first]+segment (rem) for first,rem in
splits (text))
return max (candidates, key=Pwords)
def splits(text,L=20) :
"Return a list of all possible(first,rem) pairs,len (first) <
=L . "
return[(txt[: i+l]， text[i+l: ])
for i in range (min(len(text), L) ) ]
def Pwords (words):
"The Naive Bayes probability of a sequence of words."
return product(Pw (w) for win words)
这是整个程序——包含三个较小的省略部分：product是把数字列表
进行乘积的工具函数；memo是一个装饰器(dcorator)，对函数
product的结果进行缓存，因而这些结果就不需要重新计算；Pw通过
询问单元计数数据来估计一个单词的概率。
没有装饰器memo，对一个包含了n个字符的文本段的调用会导致对
该段的2n次递归调用；有了memo，它就只执行n次调用—memo使
得调用变成一个高效的动态编程算法。对于n次调用，每个都需要
考虑O(L)次的分片，对每个分片乘以O(n)的概率来估算每个分片的
代价，因此整个算法代价是O(n²L）。
1579
---
## Page 1581
对于PW，我们从一个数据文件读取单元计数值。如果一个单词在
语料库中出现，它的估计概率是Count(word)/N，其中N是语料库的
大小。实际上，我没有采用1300万类型的单元数据文件，而是创建
了vocab_common，它有几方面特性：（1）大小写不敏感，因此
“the”、“The"和"THE"的计数值都加在一起，作为一个词条的"the”；
（2）词条是由字母表示的，而不是数字或者标点符号（因此
“+170.002"不能作为词条，同样“can't"也不能：（3）100万单词中
最通用的1/3单词。
Pw唯一较难处理的部分是当一个单词不在语料库中时如何处理更为
合适。即使是在包含了10000亿个单词的语料库中，这种情况有时
也会发生，因此把概率当做0返回是错误的。但是它应该为多少
呢？语料库中的token个数N，几乎有10000亿，vocab_common中最
不经常出现单词有12711个。因此之前没有看见的单词，其概率应
该在0～12711/N。不是所有未见到的单词的概率都是一样的：一个
有20个字母的随机序列是单词的概率要小于一个有6个字母的随机
序列。我们将为概率分布定义一个类Pdist，它加载一个内容是
(ky,count)对的数据文件。默认情况下，一个未知单词的概率是
1/N，但是Pdist的每个实例可以提供一个自定义函数对默认值进行
重载（oerride)。为了避免对于很长的单词概率太高，因此我们确定
（相当随意）了一个起始概率10/N，对于候选单词中的每个字母，
以因子10来递减。我们定义Pw为一个如下的Pdist：
class Pdist (dict) :
"A probability distribution estimated from counts in
datafile."
def__init__(slf, data, N=None, missingfn=None) :
for key,count in data:
self[key]=self.get (key, O) +int (count)
self.N=float (N or sum (self.itervalues () ) )
self.missingfn=missingfn or (lambda k, N: 1 ./N)
def__call__ (s1f, key) :
if key in self:return self[key]/self.N
1580
---
## Page 1582
else:return self.missingfn(key, self.N)
def datafile (name, sep='\t*) :