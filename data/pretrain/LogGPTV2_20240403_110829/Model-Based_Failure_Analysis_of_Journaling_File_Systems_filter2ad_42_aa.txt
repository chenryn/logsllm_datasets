title:Model-Based Failure Analysis of Journaling File Systems
author:Vijayan Prabhakaran and
Andrea C. Arpaci-Dusseau and
Remzi H. Arpaci-Dusseau
Model-Based Failure Analysis of Journaling File Systems
Vijayan Prabhakaran, Andrea C. Arpaci-Dusseau, and Remzi H. Arpaci-Dusseau
University of Wisconsin, Madison
Computer Sciences Department
1210, West Dayton Street, Madison, Wisconsin
Abstract
We propose a novel method to measure the robustness
of journaling ﬁle systems under disk write failures. In our
approach, we build models of how journaling ﬁle systems
order disk writes under different journaling modes and use
these models to inject write failures during ﬁle system up-
dates. Using our technique, we analyze if journaling ﬁle
systems maintain on-disk consistency in the presence of disk
write failures. We apply our technique to three important
Linux journaling ﬁle systems: ext3, Reiserfs, and IBM JFS.
From our analysis, we identify several design ﬂaws and cor-
rectness bugs in these ﬁle systems, which can cause serious
ﬁle system errors ranging from data corruption to unmount-
able ﬁle systems.
1 Introduction
Disks fail. Hence, to ensure ﬁle system integrity and
reliability, modern ﬁle systems and storage systems must
include internal machinery to cope with such failures.
Unfortunately, the way disks fail is changing. Most tra-
ditional systems assume that disks are fail-stop [16]; under
such an assumption, a disk is either working or it is not, and
if not, the failure is easily detectable. However, as disk com-
plexity increases, and as the pressures of time-to-market and
cost increase as well, new disk failure modes are becoming
more common. Speciﬁcally, latent sector faults may oc-
cur [4], in which a speciﬁc block becomes faulty (either
in a transient or permanent manner), rather than the disk
as a whole. Similarly, disks can stutter sometimes, exhibit-
ing transient performance problems [1]. Hence, viewing the
disk as either working or not may no longer be appropriate.
In this paper, we investigate how modern ﬁle systems
cope with this new class of fault on disk writes. Most mod-
ern ﬁle systems are journaling systems [2, 15, 18, 21]. By
logging data in a separate journal before writing them to
their ﬁxed locations, these ﬁle systems maintain ﬁle system
integrity despite the presence of crashes.
To analyze such ﬁle systems, we develop a novel model-
based fault-injection technique. Speciﬁcally, for the ﬁle
system under test, we develop an abstract model of its up-
date behavior, e.g., how it orders writes to disk to maintain
ﬁle system consistency. By using such a model, we can
inject faults at various “interesting” points during a ﬁle sys-
tem transaction, and thus monitor how the system reacts to
such failures. In this paper, we focus only on write failures
because ﬁle system writes are those that change the on-disk
state and can potentially lead to corruption if not properly
handled.
We use this fault-injection methodology to test three
widely used Linux journaling ﬁle systems: ext3 [21], Reis-
erfs [15] and IBM JFS [2]. From our analysis, we ﬁnd sev-
eral design ﬂaws with these ﬁle systems that can catastroph-
ically affect on-disk data.
Speciﬁcally, we ﬁnd that both ext3 and IBM JFS are not
designed to handle sector write failures. Under such fail-
ures, both of these ﬁle systems sometimes commit failed
transactions to disk; doing so can lead to serious problems,
including an unmountable ﬁle system. In contrast, we ﬁnd
that Reiserfs, for the most part, is paranoid about write fail-
ures; speciﬁcally, Reiserfs crashes the system when a write
to the journal fails. By crashing in this manner, Reiserfs en-
sures that ﬁle system integrity is maintained, at the cost of a
(potentially expensive) restart. However, in certain conﬁg-
urations, Reiserfs does not abide by its general policy, and
can be coerced into committing failed transactions and also
can result in a corrupted ﬁle system. Further, Reiserfs as-
sumes such failures are transient; repeated failure of a par-
ticular block will result in repeated crashes and restarts.
The rest of the paper is organized as follows. First,
we give a brief introduction to journaling ﬁle systems (§2).
Following that, we explain our methodology for analyzing
journaling ﬁle systems (§3), and then discuss the results of
our analysis of ext3, Reiserfs, and JFS (§4). We present
related work (§5) and ﬁnally, conclude (§6).
Proceedings of the 2005 International Conference on Dependable Systems and Networks (DSN’05) 
0-7695-2282-3/05 $20.00 © 2005 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 12:10:16 UTC from IEEE Xplore.  Restrictions apply. 
2 Background
When a ﬁle system update takes place, a set of blocks is
written to the disk. Unfortunately, if the system crashes in
the middle of the sequence of writes, the ﬁle system is left
in an inconsistent state. To repair the inconsistency, earlier
systems such as FFS and ext2 scan the entire ﬁle system and
perform integrity checks using fsck [13] before mounting
the ﬁle system again. This scan is a time-consuming process
and can take several hours for large ﬁle systems.
Journaling ﬁle systems avoid this expensive integrity
check by recording some extra information on the disk in
the form of a write-ahead log or a journal [6]. Journal writes
are followed by a commit block write. Once these writes are
successfully committed to the log, they can be transferred
to their ﬁnal, ﬁxed locations on the disk. The process of
transferring the writes from the log to the ﬁxed location on
disk is called checkpointing. If a crash occurs in the middle
of checkpointing, the ﬁle system can recover the data from
the log and write them to their ﬁxed locations. Journaling
ﬁle systems update a special block called the journal super
block periodically to mark the size of the log and the end of
checkpointing.
Many modern ﬁle systems provide different ﬂavors of
journaling, which have subtle differences in their update
behavior to disk. We discuss the three different approaches:
data journaling, ordered journaling, and writeback journal-
ing. These journaling modes differ from each other by the
kind of integrity they provide, by the type of data they write
to the log, and the order in which the data is written.
Data journaling provides the strongest data integrity of
the three. Every block that is written to the disk, irrespective
of whether it is a data or metadata block, is ﬁrst written to
the log. Once the transaction is committed, the journaled
data can be written to their ﬁxed ﬁle system locations.
Writeback journaling logs only the ﬁle system metadata.
However, it does not enforce any ordering between data
writes and journal writes. Hence, while ensuring metadata
consistency, writeback journaling provides no guarantee as
to data consistency. Speciﬁcally, if a ﬁle’s metadata is up-
dated in-place before its data reaches disk, the ﬁle will con-
tain data from the old contents of that data block.
Ordered journaling adds data consistency to writeback
mode.
It does so by enforcing an ordering constraint on
writes, such that the data blocks are written (called ordered
data writes) to their ﬁxed locations before the metadata
blocks are committed. This ordering constraint ensures that
no ﬁle system metadata points to any corrupt data.
3 Methodology
In this section, we describe the overall methodology we
use for testing the reliability of journaling ﬁle systems. Our
basic approach is quite simple: we inject “disk faults” be-
neath the ﬁle system at certain key points during its opera-
tion and observe its resultant behavior.
Our testing framework is shown in Figure 1(a). It con-
sists of two main components; a device driver called the
fault-injection driver and a user-level process labeled the
coordinator. The driver is positioned between the ﬁle sys-
tem and the disk and is used to observe I/O trafﬁc from the
ﬁle system and to inject faults at certain points in the I/O
stream. The coordinator monitors and controls the entire
process by informing the driver as to which speciﬁc fault to
insert, running workloads on top of the ﬁle system, and then
observing the resultant behavior.
A ﬂow diagram of the benchmarking process is shown in
Figure 1(b). We now describe the entire process in detail.
3.1 The Fault-Injection Driver
The fault-injection driver (or just “driver”) is a pseudo-
device driver, and hence appears as a typical block device
to the ﬁle system. Internally, it simply interposes upon all
I/O requests to the real underlying disk.
The driver has three main roles in our system. First, it
must classify each block that is written to disk based on
its type, i.e., what speciﬁc ﬁle-system data structure this
write represents. We have developed techniques to perform
this classiﬁcation elsewhere [14], and simply employ those
techniques herein.
Second, the driver must “model” what the journaling ﬁle
system above is doing. Speciﬁcally, such a model repre-
sents the correct sequence of states that a transaction must
go through in committing to disk. By inserting failures at
speciﬁc points within the transaction sequence, we can ob-
serve how the ﬁle system handles different types of faults
and better judge if it correctly handles the faults we have
injected.
Third, the driver is used to inject faults into the system.
These faults are speciﬁed to occur at various state transi-
tions (as based on the journaling model) in the I/O stream.
3.2 The Coordinator
The coordinator monitors the entire benchmarking pro-
cess. It ﬁrst inserts the fault-injection driver into the Linux
kernel. Then, the coordinator constructs the ﬁle system,
passes a fault speciﬁcation to the driver, spawns a child pro-
cess to run the workload, and looks for errors.
Errors can manifest themselves in numerous locales, so
we must log all such errors and have the coordinator col-
late them. Speciﬁcally, the child process may receive errors
from the ﬁle system, the driver may observe errors in the se-
quence of state transitions, and the coordinator itself must
look through system logs to look for other errors reported
Proceedings of the 2005 International Conference on Dependable Systems and Networks (DSN’05) 
0-7695-2282-3/05 $20.00 © 2005 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 12:10:16 UTC from IEEE Xplore.  Restrictions apply. 
COORDINATOR
WORKLOAD
LOG
Build the journaling
model
Save fault specification
from coordinator
Receive file system
read/write requests
Classify block types
No
Does
the block match the
model ?
Yes
ioctl()
9
.
6
.
2
X
U
N
I
L
VFS LAYER
SYSTEM
LOG
EXT3
REISERFS
JFS
FAULT−INJECTION DRIVER
SCSI
/ IDE
Report error
No
Does the
block match
the fault
specification?
Yes
Pass request
to disk
Inject fault.
Pass error to file system
(a)
(b)
Figure 1: Benchmarking Framework and Algorithm Flow. Figure (a) shows the benchmarking framework we use to measure the fault
tolerance of journaling ﬁle systems to write failures. The two main components in the ﬁgure are the user level process that issues the
fault and the fault-injection driver that classiﬁes blocks and injects faults. Figure (b) shows a simpliﬁed ﬂowchart of our benchmarking
algorithm that is implemented by the fault-injection driver.
by the ﬁle system but not reﬂected to the calling child pro-
cess.
Each of our fault injection experiment proceeds as fol-
lows: The ﬁle system to be tested is freshly created and
the ﬁles and directories needed for the testing are created
in it. Depending on the type of the block to fail, the co-
ordinator constructs a fault speciﬁcation (which contains
the attributes described in §3.4) and passes it to the fault-
injection driver. Then, the coordinator runs a controlled
workload (e.g., creating a ﬁle or directory) as a child pro-
cess that would generate the block write to be failed. When
the expected block is written by the ﬁle system, the driver
injects the fault by failing that block write. The driver also
records any ﬁle system writes that violate the journaling
model.
Our fault injection experiments are not statistical.
Once the fault is injected, the coordinator collects the
error logs from the child process, system log and the driver.
Although all the above process is automated, the error logs
have to be interpreted manually to ﬁgure out the extent to
which the ﬁle system can be damaged by extraneous writes.
In-
stead, we carefully choose the fault injection points. We
inject faults at 5 main points: ordered data writes, journal
writes, commit writes, checkpoint writes and journal su-
perblock writes. Within journal writes, we perform fault
injection to both journal metadata and journal data blocks.
In some of our analysis, we force a system crash after fault
injection to see if the ﬁle system recovers correctly.
3.3 Journaling Models
We now describe how we model journaling ﬁle systems.
As explained in Section 2, there are three different journal-
ing modes. Each of these journaling modes differs from the
other by the type of data it journals and the order in which
it writes the blocks. We build a model for each of the jour-
naling modes based on its functionality. The models rep-