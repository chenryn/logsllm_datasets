For gender classiﬁcation, every cloud has a different re-
sponse format. Following what we have done to ImageNet,
we take the prediction with the higher conﬁdence as the
ﬁnal prediction. Since gender is binary, the misclassiﬁcation
rate and matching rate degenerate into the same one. Thus,
we further examine the Male2Female rate (M2F rate) and
Female2Male rate (F2M rate).
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:56:58 UTC from IEEE Xplore.  Restrictions apply. 
1427
020406080Threshold(%)0.20.40.60.81.0AccuracyAlibabaBaiduAWSGoogleDeﬁnition 2. We deﬁne M2F rate to be the number of
misclassiﬁed male AEs divided by the number of male AEs
sent to the MLaaS system and F2M rate to be the number
of misclassiﬁed female AEs divided by the number of female
AEs sent to the MLaaS system.
V. RESULTS AND ANALYSIS
This section is divided into two parts, discussing two kinds
of inﬂuencing factors respectively. The ﬁrst part
is about
factors concerning the threat setting, i.e., platform factors,
surrogate factors, adversarial algorithm factors and their joint
effects. In this part, we run hierarchical ordinary least squares
(OLS) regressions, on the results obtained from the ImageNet
and the Adience. These regressions show how threat setting
factors inﬂuence the transferability metrics, leading to a bunch
of empirical observations. The reason and implication of using
OLS and correlation analysis is discussed in Appendix X-B
and X-C. The second part is about the factors concerning the
properties of AE. In this part, we consider how the norm
of adversarial perturbation, the adversarial conﬁdence and the
classiﬁcation hardness affect the transferability.
The observations stated in the ﬁrst part, if not explicitly
claimed, are obtained from the ResNet surrogates. They gen-
eralize if we presume the impact of surrogate architecture to
transfer attacks is additively separable5 to the impact of other
discussed factors. For ease of writing, we use subscript for
relations to show the p-value of relation tests and “≈” to
show the null hypothesis that two values are equal cannot
be rejected (p > 0.1). For example, A <p=0.01 B means that
the null hypothesis A ≥ B is rejected with p-value 0.01 and
B ≈ C means that null hypothesis B = C cannot be rejected.
When we write compound inequalities, the “≈” is treated as
equivalence relation and statistical tests are done on each of
them respectively. It means that A <p=0.01 B ≈ C conﬁrms
A <p≤0.01 C as well. In addition, we use the variable name
to refer to its coefﬁcient in the regression.
A. Threat Setting Factors
As discussed in Section IV-A, target models on MLaaS
platforms, surrogates and adversarial algorithms are the main
factors in the threat setting. We use hierarchical regression to
decompose the effect of these factors. Due to the large cost
of adding the architecture dimension to all the experiments,
we cannot run all tests on various surrogate architectures and
thus the OLS regression does not include the architecture
dimension in order to balance the data and avoid biased
conclusions. Instead, we include a separate study of the impact
of the surrogate architecture.
Table III shows the OLS regression result on the ImageNet
dataset. Each column (regression group) is a different OLS
regression with different independent variable (IV) group. For
each column, variables left blank are not
included in the
regression. The table follows a standard representation of
hierarchical regression and readers who are unfamiliar with
5For the deﬁnition of additively separation, please refer to [5].
this representation can ﬁnd more explanations on how to read
this table in Appendix X-D. Detailed codes for conducting
the OLS analysis is included in the released code repository.
Regression A and F decompose the effect of target models,
revealing how well different target MLaaS platforms behave to
defend transfer attacks. Regression B and G further decompose
the effect of pretraining and data enrichment factors, intending
to reveal how surrogate training affects the transferability.
Adversarial algorithm factors’ effect are further decomposed
in regression C and H. In regression D and I, surrogate depth’s
effect is decomposed as well. In the result of these regressions,
data enrichment and surrogate depth are not clearly correlated
to transfer attack, thus regression E and J are designed to
reveal if there are joint effects between surrogate model setting
and training techniques. Table IV shows the result on the
Adience dataset, and is organized similarly.
In the regression, multicollinearity exists among platform
factors, adversarial algorithm factors and surrogate depth fac-
tors. For example, one and only one of the platform factors is
1, which makes their coefﬁcients not unique in the regression.
To avoid this problem, we choose a baseline setting: UAP
attack for adversarial algorithm factors and ResNet-18 for
surrogate depth factors. This means that for the settings
with UAP attack, all indicator variables for the adversarial
algorithms are zero. Similarly, for the settings with ResNet-
18 surrogate, all indicators for the surrogate depth are zero.
No baseline platform is set because the constant term of the
regression can be merged to the platform factors.
1) Platform Factors: Platform factors represent the vulner-
ability of the target model. A larger coefﬁcient for a platform
means that transfer attacks are more likely to succeed on this
platform. However, as we use a restricted range of classes
and a manually designed class mapping to decide whether
a transfer attack is successful (see Section IV-B for details),
the following discussions do not provide any guarantee nor
comparison for the robustness of these platforms when dif-
ferent settings are applied. We are careful not to generalize
our conclusions, and readers are discouraged to compare the
MLaaS systems by their performance in these speciﬁc tasks
and datasets.
Regression A and Regression F decomposes the platform
factors in Table III and Table IV, respectively. Since these two
regressions run on all settings but only include platform factors
in the IV group, the coefﬁcient of the platform factors repre-
sents an average of metric values over all settings. In other
words, if attackers pick their settings uniformly at random,
then they are expecting the coefﬁcient as their metric value.
This provides us with some knowledge about “inexperienced
attackers” and is a good representation of the robustness of
the target model.
By comparing the coefﬁcients, we get the following rela-
tions (lower is better):
(i) In the object classiﬁcation task, Aliyun ≈ AWS
<p<0.001 Baidu <p<0.001 Google on the misclassiﬁcation rate,
and Baidu <p=0.068 AWS <p<0.001 Aliyun ≈ Google on the
matching rate.
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:56:58 UTC from IEEE Xplore.  Restrictions apply. 
1428
Table III: The OLS regression result of misclassiﬁcation rate and matching rate with regard to different groups of factors on
the data obtained from ResNet surrogates in the image classiﬁcation task. For each entry, the ﬁrst number is the regression
coefﬁcient and the second number, presented in parentheses, is the corresponding standard deviation. Variables with “is ” as
preﬁx are boolean virtual variables that take the value 1 iff the corresponding conditions are true. Uninteresting values are
grayed since they do not contain additional information.
misclassiﬁcation rate
matching rate
A
0.232∗∗∗
(0.004)
0.071∗∗∗
(0.004)
0.193∗∗∗
(0.004)
0.064∗∗∗
(0.004)
B
0.236∗∗∗
(0.006)
0.075∗∗∗
(0.006)
0.197∗∗∗
(0.006)
0.068∗∗∗
(0.006)
-0.018∗∗∗
(0.004)
0.010∗
(0.005)
0.004
(0.005)
C
0.235∗∗∗
(0.005)
0.074∗∗∗
(0.005)
0.196∗∗∗
(0.005)
0.067∗∗∗
(0.005)
-0.018∗∗∗
(0.002)
0.010∗
(0.003)
0.004
(0.003)
0.003
(0.005)
0.073∗∗∗
(0.005)
-0.048∗∗∗
(0.005)
-0.047∗∗∗
(0.005)
-0.050∗∗∗
(0.005)
0.078∗∗∗
(0.005)
-0.000
(0.005)
0.002
(0.005)
D
0.190∗∗∗
(0.005)
0.047∗∗∗
(0.005)
0.200∗∗∗
(0.005)
0.102∗∗∗
(0.005)
-0.048∗∗∗
(0.005)
-0.003
(0.006)
0.010
(0.006)
0.003
(0.005)
0.073∗∗∗
(0.005)
-0.048∗∗∗
(0.005)
-0.047∗∗∗
(0.005)
-0.050∗∗∗
(0.005)
0.078∗∗∗
(0.005)
-0.000
(0.005)
0.002
(0.005)
0.002
(0.003)
0.002
(0.003)
Group
IV
is Google
is AWS
is Baidu
is Aliyun
is pretrained
is adversarial
is augmented
is PGD
is FGSM
is BLB
is CW2
is DEEPFOOL
is STEP LLC
is RFGSM
is LLC
is depth 34
is depth 50
is pre×adv
is pre×aug
is pre×depth34
is pre×depth50
is adv×depth34
is adv×depth50
is aug×depth34
is aug×depth50
R2
0.899
0.896
0.899
0.896
Adjusted R2
∗p < .1, ∗∗p < .05, ∗∗∗p < .01. Number of observation is 648.
0.645
0.644
0.656
0.653
E
0.234∗∗∗
(0.006)
0.073∗∗∗
(0.006)
0.194∗∗∗
(0.006)
0.065∗∗∗
(0.006)
-0.014∗∗∗
(0.005)
0.005
(0.006)
0.014∗∗
(0.006)
0.003
(0.005)
0.073∗∗∗
(0.005)
-0.048∗∗∗
(0.005)
-0.047∗∗∗
(0.005)
-0.050∗∗∗
(0.005)
0.078∗∗∗
(0.005)
-0.000
(0.005)
0.002
(0.005)
0.001
(0.006)
-0.003
(0.006)
-0.003
(0.006)
-0.014∗∗
(0.006)
-0.004
(0.006)
-0.010∗
(0.006)
0.012∗
(0.007)
0.007
(0.007)
-0.001
(0.007)
-0.0206
(0.007)
0.902
0.898
F
0.100∗∗∗
(0.003)
0.038∗∗∗
(0.003)
0.029∗∗∗
(0.003)
0.097∗∗∗
(0.003)
G
0.089∗∗∗
(0.004)
0.027∗∗∗
(0.004)
0.019∗∗∗
(0.004)
0.086∗∗∗