network.
Datasets and model architectures: Our experiments rely on
the HAR, MNIST and CIFAR-10 datasets. A multinomial Logistic
Regression (LR) classifier [11] and a shallow convolutional neural
network LeNet [30], and a widely used residual neural network
ResNet20 [23] are employed as the global model respectively. By
default, we set the parties’ dataset independent and identically dis-
tributed (IID). We also simulate Non-IID dataset using the method
of [18] [11]. Details refer to Appendix A.
Evaluated byzantine attacks: We conduct experiments against
both data poisoning attacks and local model poisoning attacks. In
the former case, we utilize the popular label flipping attack [11],
where malicious parties change each sample’s label to an arbitrar-
ily wrong label. In the latter case, we use the same attack setting
as [18], which is the state-of-the-art local model poisoning attack
specific for the Krum aggregation rule.
6.2 SecureFL’s Cryptographic Protocols
In our evaluations, we omit the cost of the base OTs, and generating
the Beaver’s multiplicative triples and the keypair of PLHE, as they
are a one-time expense during the whole protocol execution.
The performance of SecureFL. Figure 4 reports the execution
time and communication cost of SecureFL. From Figures 4(a) and
4(c), we can observe that the execution time of both SP and CS
increases linearly with both the number of parties and the number
of data entries. The difference between CS and SP is small, which
is also reflected in the communication overhead in Figures 4(b)
and 4(d). The main reason is that the protocol of our SecureFL is
executed between CS and SP and realizes O(dn) overhead, where
d denotes the size of gradient and n is the number of parties. This
shows SecureFL has excellent scalability despite a large number of
parties and data entries involved. Note that we omit communication
cost plots for the parties, as they are essentially identical to those
for the vanilla FL setting. This is because parties only communicate
with SP, and additionally utilize PRGs to non-interactively share
secrets (i.e., the sharing of local gradients) with CS. We also re-
port the detailed communication and computational overheads of
SecureFL’s building blocks in Table 4 and Table 5 of Appendix A.
Comparison with prior works. To demonstrate the effective-
ness of SecureFL, we implement state-of-the-art private and robust
5https://github.com/Microsoft/SEAL
6https://github.com/mpc-msri/EzPC/tree/master/SCI
54Efficient, Private and Robust Federated Learning
ACSAC ’21, December 6–10, 2021, Virtual Event, USA
(a) Execution time of CS and SP, as the num-
ber of parties increases.
(b) Communicaiton cost of CS and SP, as
the number of parties increases.
(c) Execution time of CS and SP, as the size
of the data increases.
(d) Communicaiton cost CS and SP, as the
size of the data increases.
Figure 4: Execution Time and Communication Cost of SecureFL. In (a)(b), different lines show different data sizes, and in
(c)(d), different lines show different numbers of parties. Each point in the figures is the average value over 10 runs.
(a) Execution time over the different model
architectures.
(b) Communicaiton cost over the different
model architectures.
(c) Execution time over the different num-
bers of parties.
(d) Communicaiton cost over the different
numbers of parties.
Figure 5: Execution Time and Communication Cost of SecureFL and Prior Works. In (a)(b), the number of parties is fixed as
100. In (c)(d), LR is used to evaluate. Each point in the figures is the average value over 10 runs and the y-axis is in loд scale.
Table 3: The Test Error of Different FL Methods under Different Datasets and Various Attacks. The fraction of malicious
parties is fixed as 20% and the number of parties is fixed as 100.
No attack
LabelFlip attack
LocalModel attack
HAR MNIST CIFAR HAR MNIST CIFAR HAR MNIST CIFAR
0.24
0.03
0.12
0.90
0.18
0.04
0.03
0.19
0.04
0.10
0.04
0.04
0.16
0.54
0.18
0.19
0.17
0.10
0.04
0.03
0.06
0.10
0.04
0.04
0.21
0.56
0.18
0.19
0.03
0.22
0.04
0.04
0.10
0.90
0.04
0.04
FedAvg
Krum
FLTrust
Our SecureFL
(a) Test error under label flipping attack
with different numbers of parties.
(b) Test error under local model poisoning
attack with different numbers of parties.
(c) Test error under label flipping attack
with different fractions of malicious parties.
(d) Test error under local model poisoning
attack with different fractions of malicious
parties.
Figure 6: Impact of the Number of Parties and the Fraction of Malicious Parties on the Test Error. The MNIST dataset is used
to evaluate. In (a)(b), the fraction of malicious parties is fixed as 20% and in (c)(d), the number of parties is fixed as 100.
55ACSAC ’21, December 6–10, 2021, Virtual Event, USA
Meng Hao, et al.
FL methods including privacy-preserving Krum [24] and FLTrust
[11] with generic MPC techniques, as well as secure Cosine dis-
tance based FL (called CosineFL) [29]. We compare them with our
SecureFL in terms of execution time and communication cost in Fig-
ure 5. Note that current implementations of the above FL variants
execute top-k7 under plaintext due to the efficiency issue, but there
are serious privacy risks as discussed in Section 2. For making a
fair comparison, we implement the top-k protocol (Algorithm 1 in
[12]), and utilize it to securely evaluate the above FL variants. In our
evaluation, k is fixed as 10%. In addition, we implement the recip-
rocal squared root protocol in FLTrust by utilizing the CrypTFlow
framework [40], which achieves state-of-the-art optimizations of
math operators.
Figures 5(a) and 5(b) compare the execution time and commu-
nication cost required to securely execute the robust aggregation
of prior works and our SecureFL over three datasets and various
model architectures. We observe that among the three model ar-
chitectures with different parameter scales, SecureFL requires 2-97
× less time to evaluate the privately robust aggregation protocol,
and 2.5-129 × less communication. This is because matrix multipli-
cation preprocessing and specialized validity checking techniques
achieve significant savings in computational overhead and com-
munication cost. Furthermore, Figures 5(c) and 5(d) compare the
execution time and communication cost of four FL methods with
different numbers of parties over the LR model architecture. In both
cases, we observe that as the number of parties increases, the gap
between SecureFL and prior methods grows larger. This is because
our SecureFL achieves O(dn) computation and communication com-
plexity, while prior works require O(dn2) complexity. Actually, the
privacy-preserving FLTrust also achieves O(dn) complexity, but
costly matrix multiplication and reciprocal square root operations
reduce its performance. Overall, among the different numbers of
parties, SecureFL requires 7-214 × less time to evaluate the privately
robust aggregation, and 3-327 × less communication.
6.3 SecureFL’s Byzantine-robust Aggregation
In this evaluation, we report the result of SecureFL’s robustness,
and compare it with existing byzantine-robust FL methods.
Comparison with existing byzantine-robust aggregations.
We compare our SecureFL with prior works, including FedAvg [33],
Krum [9] and FLTrust [11], which are popular aggregation rules in
(robust) FL frameworks. Table 3 shows the test errors of different FL
algorithms under three attack settings and three real-world datasets.
First, we can observe that SecureFL achieves comparable accuracy
to the traditional FedAvg method when there is no attack. Moreover,
SecureFL has test errors similar to the state-of-the-art FLTrust with
and without byzantine attacks, which indicates that our crypto-
friendly variant does not sacrifice robustness and inference accuracy.
Second, SecureFL is byzantine-robust against both the label flipping
attack and the local model poisoning attack. In contrast, existing
methods such as FedAvg and Krum are still vulnerable to advanced
byzantine attacks. This is because our SecureFL considers both the
magnitude and direction of the local gradients to resist existing
attacks.
7SP selects k local gradients that are more likely submitted by honest parties.
Impact of the number of parties. We report the test errors
under different numbers of parties in Figures 6(a) and 6(b). We can
observe that as the number of parties increases, SecureFL achieves
stable test errors under the label flipping and local model poisoning
attacks, which are similar to FedAvg without any attacks. Specifi-
cally, the test errors of SecureFL are close to 0.04 under the above
attacks. However, under different numbers of parties, the Krum
method cannot defend against the label flipping and the local model