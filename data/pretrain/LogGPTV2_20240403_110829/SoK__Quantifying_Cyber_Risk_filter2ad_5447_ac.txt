### Distributions and Trends

- **Power Law**
- **Lognormal (M)**
- **DT Power Law (t)**
- **Skew-Normal**
- **Generalized Pareto (t)**
- **Skew/Lognormal**
- **Lognormal (t)**

**Distribution Characteristics:**
- **Trend Analysis**
- **Moment Calculation**
- **Binomial Distribution**
- **Pareto Distribution**

The presence of these distributions is unsurprising, given that many failures are not malicious. Future work could focus on security failures specifically. Case studies from organizations that aggregate data across multiple firms may provide general insights. For example, Axon et al. [9] analyzed 70 insurance claims from one insurer and found that response services are the most common costs. This is explained by how insurers encourage insureds to use post-incident services [45, 129]. However, Axon et al. [9] did not provide quantitative estimates, likely because insurers view claims data as a competitive advantage [129]. Public sector organizations may be more willing to share such data.

Simpson and Moore analyzed 7,925 attempted wire transfer thefts reported to the FBI’s Internet Crime Complaint Center and found that small thefts succeed less often, while international thefts succeed more often [107].

### Survey Data

In surveys, researchers collect private reports directly. The UK Government commissioned a survey [121] to quantify the frequency and impact of cyber incidents based on firm size and industry, providing simple estimates of expected costs and harm. Heitzenrater and Simpson [58] combined this survey with control effectiveness data to quantify the return on security investment for commercial products like anti-virus software or firewalls.

Numerous consumer surveys on cybercrime exist. Riek et al. [96] identified key surveys in the US and EU [42, 56, 61, 97], which we use to characterize the insights. Self-reported losses are used to indicate compromise [56, 61, 97], while the Eurobarometer [42] focuses on victimization rates. Security information, such as security spending [96], identity theft detection methods [56], and anti-virus installation [42], is collected but not linked to harm outcomes. Estimates of expected harm or frequency of compromise must be made with reference to the population from which the sample was drawn. Solving this issue with representative sampling results in victims comprising a small fraction of the sample [44]. Riek et al. [96] addressed both issues by over-sampling victims and accounting for this with reverse-weighting.

Riek et al. [96] showed that "most victims report no losses, many lose little, and a few lose a lot" [96, p. 13]. Hernandez et al. [61] discovered near-identical victimization rates in the UK compared to a comparable US sample. Survey work emphasizes time costs in dealing with incidents and maintaining security controls [58].

### Observed Externally

Studies that observe publicly accessible systems interacting with organizations can provide unbiased measurements.

#### Legal Cases
Legal systems are reasonably transparent. Studies reveal factors determining the likelihood of breach litigation in the US [99], the costs of regulatory fines in the UK [25], and the evolution of security requirements in FTC prosecutions [19]. Romanosky et al. [99] found no clear trend in the absolute number of litigated data breaches from 2005 to 2010 (RQ3). They identified factors impacting the probability of a reported data breach being litigated, such as the number of records breached. In the UK, only a "small" fraction of public breaches lead to fines [25], averaging £110k out of a £500k limit, now much higher due to GDPR. These estimates are limited to costs assigned by courts and regulators. Additionally, legal cases take years to resolve, introducing logistical difficulties in linking mitigation measures to legal outcomes.

#### Cybercrime Ecosystem
The cybercrime ecosystem can be studied to extract indicators of harm, such as typical ransomware payments. Three studies [79, 92, 110] estimated the rate of compromise related to the CryptoLocker ransomware campaign over time (T). Two studies found significant temporal variance in specific ransomware campaigns (RQ3). Paquet et al. [92] included an additional 34 ransomware families, linking harm to the type of compromise indicated by payment amount and the campaign. Such estimates are difficult to link to the characteristics of the victim or the mitigation measures employed.

Research directly measuring threat actors can estimate aggregate costs of cybercrime. Data breach harms to consumers can be observed when stolen data is sold, such as through monitoring public channels [47, 118] or infiltrating private forums [4]. These markets are noisy, leading to exaggerated cost estimates [59]. Diffuse harms related to spam [75], unlicensed pharmacies [73, 85], or ransomware-at-scale [63] can be more reliably quantified at the source, namely the criminal operation. Interested readers should refer to Anderson et al. [7] for a comprehensive survey.

#### Insurance Prices
A sub-population of insurers file their pricing schemes with a regulator [100]. Woods et al. [130] extracted these prices and showed that cyber insurance premiums trended downwards from 2008 to 2018 (RQ3). They also introduced a method using these prices to quantify expected loss (RQ1). The method, analogous to model stealing [120], infers a loss distribution based on how the quoted premium varies with changes in the amount of insurance.

#### Stock Market Reactions
Stock market reaction studies quantify harm to shareholders as indicated by abnormal returns. All studies control for exposure via victim industry or size. Gordon et al. [53] and Gay [51] provided evidence that market reactions are becoming less negative over time. Figure 4 shows the decreasing effect through a meta-study.

Later studies suggest that corporate leaders learned to mitigate negative stock market reactions after a breach. Board-level incentives mean costlier attacks are less likely to be disclosed [5], and when they are, the negative reaction is offset by the strategic release of positive news [51]. Two studies provide evidence of insider trading [29, 80], undermining the methodology because the abnormal trading following a breach is not concentrated in the event window following public disclosure.

Stock market reactions could lead corporate leaders to divert more resources to security following an incident. A reduced negative shock is associated with breach disclosures that commit to "action-oriented" measures to improve security [125] and faster breach discovery [68]. Victims are more likely to increase board oversight of cyber risk post-incident [68], potentially leading to more resources being assigned to security. Markets reward news about security investments regardless of whether a breach occurred. Displaying cybersecurity awareness [11] or certifying to international standards [33, 93] leads to positive returns.

### Correlated Risk

Focusing on individual losses ignores the extreme aspect of cyber loss correlation across firms. Events impacting popular software and cloud providers may cause losses across many firms. The Morris worm infected up to 10% of the devices connected to the Internet in 1988 [67]. More recently, the NotPetya attack exploited a flaw in Windows to cause an estimated $10 billion in damage across hundreds of companies [28, 54].

An industry report [31] extracted over 800 multi-party cyber incidents causing 5,437 distinct losses from the same proprietary source as [98]. This approach focused on harm premised on a multi-incident party occurring and how this varied by industry. The median and 95th percentile of multi-party incident losses ($1m and $417m) were an order of magnitude larger than for single-party incidents ($77k and $16m), although these figures are not normalized by the number of affected firms. Curiously, their data shows a cluster of three losses at the maximum value in the sample.

### Summary

Data breaches and stock market reactions have received the most research attention. Market reactions became less negative over time [51, 53] (see Figure 4) as firms learned to manipulate announcements [5, 29, 51, 80]. Table II shows many contradictory results about data breaches depending on how the data is sliced and the analysis methodology. Even more worryingly, Eling et al. [41] showed that the distribution of the number of records does not transfer to that of financial costs [41].

A minority of studies [13, 41, 98] quantify financial costs and find that typical cyber risks are smaller and less heavy-tailed than non-cyber losses. Surveys of firms [12, 58] and individuals [96] reveal less alarming harm estimates. The maximum loss in a survey [58] of small UK businesses was £310k ($410k), whereas an operational loss database’s mean was $43m [41]. This points to jurisdictional differences and the most worrying aspect—cyber harm estimates are not consistent across samples or statistical methods.

### Cyber Risk Mitigation Studies

This section covers empirical studies on how security controls affect outcomes in real systems. Inductive security proofs and attack papers that only demonstrate an attack is possible are out of scope.

#### Measuring Security
A measurement model reduces a set of indicators to a lower-dimensional output that can be used to explore structural relationships between latent variables. This subsection covers security measurement models based on single indicators, self-reported indicators, and researcher intervention.

- **Single Indicators**: Certifications are designed to reduce organizational security to a pass-fail test. Cybersecurity certifications were associated with positive stock market reactions [33, 93]. However, no study demonstrates that certification is linked to better risk outcomes. Selection effects are pervasive as market incentives distort seemingly reliable security indicators. Firms look for auditors with the least stringent requirements when certification is mandatory, creating a race to the bottom [6, 74]. Optional certification is no better; websites certified by TRUSTe were shown to be more than twice as likely to be untrustworthy as uncertified sites [35]. Rahman et al. [94] showed that 86% of websites violated at least one of the requirements in the PCI-DSS standard they were certified to.

- **Security Budgets**: One might expect security budgets to function as a crude indicator of security. Higher IT security budgets are associated with greater frequency of data breaches [105]. Security budget likely tracks a hidden variable for risk exposure, such as organization size, since both breach frequency and size "scale with organization size" [128, p. 11]. Even when controlling for firm characteristics in a logistic regression, Biancotti [12] found that defense expenditure in 2016 is positively correlated with the probability of experiencing an incident in 2017. Potential explanations include not controlling for threat, using noisy indicators of exposure, inefficient resource allocation, or accounting tricks like reassigning existing costs under the security budget.

- **Self-Reported Indicators**: Discovering one indicator of security with wide predictive power is unlikely, motivating the collection of multiple indicators. Egelman et al. [38] developed the Security Behavior Intentions Scale (SeBIS) in which a user’s answers to 16 questions map onto four aspects of security behavior with desirable psychometric properties. The sub-scales were shown to predict end-user behavior [39, 103] but were not linked to harm outcomes. Sawaya et al. [103] showed the scale does not "generalize" across cultures. We are not aware of a similar scale for organizational security, though research from information systems uses questionnaire responses to explain security outcomes. Straub [113] used a survey of 1,211 organizations to measure latent factors related to organizational commitment to security. The model showed that organizational commitment to security correlates with better self-reported harm outcomes, such as the frequency and cost of incidents. Adding rival explanations like preventative measures did not improve the model, although the indicator—the number of security software packages in use—was weak. Organizations connecting networks to the Internet since this study enable direct measurements that avoid self-reported data [37, 81, 89, 101].

- **Researcher Intervention**: The preceding studies simply observe security levels, whereas notification studies allow the researcher to randomly assign which subjects receive the intervention. Stock et al. [111] showed that when notifications reach the website owner, the vulnerability has a 40% likelihood of remediation in the best case. The authors do not link the notification to harm or compromise outcomes, which is also true for studies notifying vulnerable name-servers [26], misaligned firewall policies [77], and HTTPS misconfiguration [132]. Notifying subjects who have already been compromised allows researchers to quantify the impact of reactive security. Vasek et al. [123] showed that notifying hosting providers reduces time to clean up malware URLs from 153 days to 101 days. Similarly, Li et al. [78] showed that "direct communication with webmasters increases the likelihood of cleanup by over 50% and reduces infection lengths by at least 62%." The authors additionally controlled for indicators of exposure like site language or popularity and showed that less popular sites are associated with longer infection periods.

**Summary**: Single indicators like security budget or certification should theoretically summarize organizational security and explain security outcomes. In reality, they are vulnerable to selection effects and manipulation. Self-reported indicators successfully explain security outcomes [39, 113] but are costly to collect. Studies collecting technical indicators [37, 81, 89, 101] can be more easily scaled. These studies are described in Section IV-D as they investigate the full causal model. Notification studies allow the researcher to control the security level and more confidently identify causal effects.

#### Measuring Threat
The presence of active adversaries is a unique aspect of security research [60]. We identify approaches to controlling for threat level that vary across time, target, and researcher intervention.

- **Time**: Empirical observations of malicious activity can be aggregated over time to track the changing threat level [70, Fig. 2–3]. Alternatively, expert sentiments can be tracked over time [52]. This provides longitudinal insights but the aggregate index does not speak to heterogeneity across organizations.