?
No
Yes
Power law
Lognormal (M)
DT power law (t)
Skew-normal
Gen Pareto (t)
Skew/Lognormal
Lognormal (t)
Distribution
Trend
Moment
Binomial
?
Pareto
→, (cid:37) (M)
?
→
→
(cid:37)
→
→
?
?
Distribution
?
?
?
is unsurprising given many failures are not malicious, but one
could imagine future work restricted to security failures.
Case studies of organisations who aggregate data across
multiple ﬁrms may provide general insights. Axon et al. [9]
analyse 70 insurance claims from one insurer and show
that response services are the most common costs, which
is explained by how insurers encourage insureds to use
post-incident services [45, 129]. Axon et al. [9] provide no
quantitative estimates, likely because insurers believe claims
data constitutes a competitive advantage [129]. Public sector
organisations may be more willing to share data. Simpson and
Moore analyse 7 925 attempted wire transfer thefts reported to
the FBI’s Internet Crime Complaint Center and ﬁnd results like
“small thefts succeed less often” [107] and international thefts
succeed more often.
Survey data In a survey, the researcher collects private
reports directly. The UK Government commissioned a sur-
vey [121] quantifying the frequency and impact of cyber inci-
dents according to the ﬁrm size and industry, which constitute
simple estimates of Es → C and Ea → H, respectively.
Heitzenrater and Simpson [58] combine the survey [121] with
control effectiveness data to quantify the return on security
investment for commercial products like anti-virus or ﬁrewalls.
Consumer surveys of cybercrime are too numerous to ex-
haustively survey. Riek et al. [96] identify the most important
surveys [42, 56, 61, 97] in the US and the EU, which we
use to characterise the kind of insights to be gleaned. Self-
reported losses are used to indicate compromise [56, 61, 97],
whereas the Eurobarometer [42] focuses on victimisation rates.
Security information is collected, such as security spend-
ing [96], identity theft detection methods [56], or anti-virus
installation [42], but not linked to harm outcomes. Estimates
of expected harm or frequency of compromise C must be made
with reference to the population from which the sample was
drawn. Solving this issue with representative sampling results
in victims comprising a small fraction of the sample [44]. Riek
et al. [96] addressed both issues by over-sampling victims and
accounting for this with a reverse-weighting.
In terms of RQ1, Riek et al. [96] show that “most victims re-
port no losses, many lose little, and a few lose a lot” [96, p. 13].
Interestingly, Hernandez et al. [61] discover near identical
victimisation rates in the UK as compared with a comparable
US sample. Survey work emphasises time costs in dealing with
the incident [96] and also maintaining security controls [58].
C. Observed externally
The remaining studies observe publicly accessible systems
interacting with the organisation, which leads to
without
measurement bias towards what is observable.
Legal cases Legal systems are reasonably transparent. Stud-
ies reveal factors determining the likelihood of breach litiga-
tion in the US [99], the costs of regulatory ﬁnes in the UK [25],
and describe the evolution of the security requirements in the
FTC’s prosecutions [19]. The actual harm is suffered by a
third-party but these studies investigate the defendant’s harm,
in terms of costs assigned by court.
Romanosky et al. [99] discover no clear trend in the absolute
number of litigated data breaches from 2005 to 2010 (RQ3).
They identify a number of factors impacting the probability a
reported data breach will be litigated, such as the number of
records breached. In the UK, only a “small” fraction of public
breaches leads to ﬁnes [25], which average £110k of the £500k
limit that is now much higher due to GDPR. Such estimates
are limited to costs assigned by courts and regulators. Further,
legal cases take years to resolve which introduces logistical
difﬁculties in linking mitigation measures to legal outcomes.
Cybercrime ecosystem can be studied to extract indicators
of harm, such as the typical ransomware payment. Three stud-
ies [79, 92, 110] used this to estimate the rate of compromise
related to the CryptoLocker ransomware campaign varies over
time (T ). Two studies ﬁnd that a speciﬁc ransomware cam-
paign displays signiﬁcant temporal variance (RQ3). Paquet et
al. [92] include an additional 34 ransomware families, which
allows them to link harm to type of compromise indicated by
payment amount and the campaign. Such estimates are difﬁcult
to link to the characteristics of the victim who suffered the loss
or the mitigation measures employed.
Although not speaking to harm to speciﬁc victims, research
directly measuring threat actors can be used to estimate ag-
gregate costs of cybercrime. Data breach harms to consumers
can be observed at the point at which stolen data is sold, such
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:31:54 UTC from IEEE Xplore.  Restrictions apply. 
215
as by monitoring public channels [47, 118] or by inﬁltrating
private forums [4]. These markets are noisy, which may lead
to exaggerated cost estimates [59]. Diffuse harms related to
spam [75], unlicensed pharmacies [73, 85] or ransomware-
at-scale [63] can be more reliably quantiﬁed at the source,
namely the criminal operation. Interested readers should refer
to Anderson et al. [7] for a deﬁnitive survey.
Insurance prices A sub-population of insurers ﬁle their
pricing schemes with a regulator [100]. Woods et al. [130]
extract these prices and show cyber insurance premiums trend
downwards from 2008–2018 (RQ3). They also introduce a
method using these prices to quantify expected loss (RQ1).
The method, which is analogous to model stealing [120], infers
a loss distribution based on how the quoted premium varies
with changes in the amount of insurance.
Stock market reaction studies quantify harm to sharehold-
ers as indicated by abnormal returns. All studies control for
exposure Ea via victim industry or size. In terms of RQ1,
perceptions of the economic impact of data breaches on stock
market value have been characterised as “Much Ado about
this has a temporal dimension (RQ3).
Nothing” [95], but
Both Gordon et al. [53] and Gay [51] provide evidence market
reactions are becoming less negative over time. Figure 4 shows
the decreasing effect by means of a meta-study.
Later studies suggest that corporate leaders learned how to
mitigate the negative stock market reaction after a breach had
occurred. Board-level incentives mean costlier attacks are less
likely to be disclosed [5] and, when they are disclosed, the
negative reaction is offset by the strategic release of positive
news [51]. Two studies provide evidence of insider trading [29,
80], which undermines the methodology because the abnormal
trading following a breach is not concentrated in the event
window following public disclosure.
Stock market reactions could lead corporate leaders to divert
more resources to security following an incident. A reduced
negative shock is associated with breach disclosures that com-
mit to “action-oriented” measures to improve security [125]
and faster breach discovery [68]. Perhaps more importantly,
victims are more likely to increase board oversight of cyber
risk post-incident [68], which may lead more resources to
be assigned to security. Markets reward news about security
investments regardless of whether a breach occurred. Display-
ing cybersecurity awareness [11] or certifying to international
standards [33, 93] leads to positive returns.
D. Correlated risk
Focusing on individual losses ignores what is perhaps the
most extreme aspect of cyber loss-correlation across ﬁrms.
Events impacting popular software and cloud providers may
cause losses across many ﬁrms. The Morris worm infected up
to 10% of the devices connected to the Internet in 1988 [67].
More recently, the NotPetya attack exploited a ﬂaw in Win-
dows to cause an estimated $10 billion of damage across
hundreds of companies [28, 54].
Multi-party incidents An industry report [31] extracted
over 800 multi-party cyber incidents causing 5 437 distinct
losses from the same proprietary source as [98]. This approach
focused on harm premised on a multi-incident party occurring
and how this varied by industry. The median and 95th per-
centile of multi-party incident losses ($1m and $417m) were
an order of magnitude larger than for single-party incidents
($77k and $16m), although these ﬁgures are not normalised
by the number of affected ﬁrms. Curiously, their data shows
a cluster of three losses at the maximum value in the sample.
E. Summary
Data breaches and stock market reactions have received the
most research attention. Market reactions became less negative
over time [51, 53] (see Figure 4) as ﬁrms learned how to
manipulate announcements [5, 29, 51, 80]. Table II shows
many contradictory results about data breaches depending on
how the data is sliced and the analysis methodology. Even
more worryingly for the data breach studies, Eling et al. [41]
show the distribution of number of records does not transfer
to that of ﬁnancial costs [41].
A minority of studies [13, 41, 98] quantify ﬁnancial costs
and ﬁnd typical cyber risks are smaller and less heavy tailed
than non-cyber losses. Surveys of ﬁrms [12, 58] and individ-
uals [96] reveal less alarming harm estimates. The maximum
loss in a survey [58] of small UK businesses was £310k
($410k), whereas an op loss database’s mean was $43m [41].
This points to jurisdictional differences and the most worrying
aspect of this section—cyber harm estimates are not consistent
across samples or statistical methods.
IV. CYBER RISK MITIGATION STUDIES
This section is concerned by empirical studies of how
security controls affect outcomes in real systems. Inductive
security proofs and attack papers that only demonstrate an
attack is possible are out of scope.
We proceed by highlighting promising ways to quantify
latent variables, known as measurement models. Measure-
ment models for threat, security and exposure are covered in
Section IV-B, Section IV-A, and Section IV-C respectively.
Finally, Section IV-D identiﬁes the holy grail—research in-
vestigating the structural links between these variables. We
classify research using the causal model throughout, which is
summarised in Section IV-E and Table III.
A. Measuring security
A measurement model reduces a set of indicators to a
lower dimensional output that can be used to explore structural
relationships between latent variables. This subsection covers
security measurement models based on single indicators, self-
reported indicators, and researcher intervention.
Single indicators Certiﬁcations are designed to reduce or-
ganisational security to a pass-fail test. Cybersecurity certiﬁca-
tions were associated with positive stock market reactions [33,
93]. Yet no study demonstrates that certiﬁcation is linked
to better risk outcomes. Selection effects are pervasive as
market incentives distort seemingly reliable security indicators.
Firms look for auditors with the least stringent requirements
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:31:54 UTC from IEEE Xplore.  Restrictions apply. 
216
Hovav and D’Arcy (2003) [62]
+7.9%, [−1, 1], 1988–2002
Gordon et al. (2011) [53]
−0.03%, [−1, 1]
Wang et al. (2013) [125]
Iyer et al. (2019)[65]
−0.05%, [−1, 1], bond valuation
−0.15%, [−1, 1]
Colivicchi et al. (2019) [29]
−0.23%, [0, 1]
Amir et al. (2018) [5]
Gay (2017) [51]
−0.3%, [−1, 3], risk weighted returns
−0.3%∗, [0, 0], privacy events
Acquisti et al. (2006) [1]
−0.6%∗, [0, 1], privacy events
Kannan et al. (2007) [69]
−0.7%, [−1, 10]
Gatzlaff and McCullough (2010) [50]
Kamiya et al. (2020) [68]
−0.8%∗∗, [−1, 1]
−0.8%∗, [−1, 2], privacy events
Bianchi et al. (2019) [119]
Campbell et al. (2003) [21]
−1.88%, [−1, 1]
Cavusoglu et al. (2004) [24]
Ishiguro et al. (2006) [64]
−1.9%, [−1, 10]
−1.4%∗∗, [−1, 1]
−2.1%∗∗[0, 1]
Gordon et al. (2011) [53]
−2.3%∗∗, [−1, 1]
1994
1996
1998
2000
2002
2004
2006
2008
2010
2012
2014
2016
2018
Fig. 4.
thickness describe sample period and size, event window reported as [Days before, days after], statistical signiﬁcance levels ∗ p ≤ 0.05, ∗∗ p ≤ 0.01.
Impact of security incident disclosure on ﬁrm stock market value. The effect is reported as cumulative abnormal returns (CAR), bar placement and
when certiﬁcation is mandatory, which creates a race to the
bottom [6, 74]. Optional certiﬁcation is no better, websites
certiﬁed by TRUSTe were shown to be more than twice as
likely to be untrustworthy as uncertiﬁed sites [35]. More
recently, Rahman et al. [94] showed that 86% of websites
violated at least one of the requirements in the PCI-DSS
standard they were certiﬁed to.
Looking elsewhere, one might expect security budgets to
function as a crude indicator of security. We already iden-
tiﬁed how higher IT security budgets are associated with
greater frequency of data breaches [105]. Security budget is
likely tracking a hidden variable for risk exposure, such as
organisation size since both breach frequency and size “scale
with organisation size” [128, p. 11]. Even when controlling for
ﬁrm characteristics in a logistic regression, Biancotti [12] ﬁnd
that defense expenditure in 2016 is positively correlated with
the probability of experiencing an incident in 2017. Potential
explanations for this result include: not controlling for threat,
using noisy indicators of exposure, organisations spending
resources inefﬁciently, or accounting tricks like re-assigning
existing costs under the security budget.
Self-reported indicators Discovering one indicator of se-
curity with wide predictive power is unlikely, which motivates
collecting multiple indicators. Egelman et al. [38] developed
the Security Behavior Intentions Scale (SeBIS) in which a
user’s answers to 16 questions map onto four aspects of
security behaviour with desirable psychometric properties. The
sub-scales were shown to predict end-user behaviour [39, 103]
but were not linked to harm outcomes. Sawaya et al. [103]
show the scale does not “generalize” across cultures.
We are not aware of a similar scale for organisational
security, though research from information systems uses ques-
tionnaire responses to explain security outcomes. In a seminal
1990 study, Straub [113] used a survey of 1 211 organisations
to measure latent factors related to organisational commitment
to security. The model showed organisational commitment to
security correlates with better self-reported harm outcomes,
such as the frequency and cost of incidents. Adding rival expla-
nations like preventative measures did not improve the model,
although the indicator—the number of security software pack-
ages in use—was weak. Organisations connecting networks to
the Internet since this study enables direct measurements that
avoid self-reported data [37, 81, 89, 101].
Researcher intervention The preceding studies simply
observe security levels, whereas notiﬁcation studies allow
the researcher to randomly assign which subjects receive the
intervention. Stock et al. [111] show that when notiﬁcations
reach the website owner, the vulnerability has a 40% likelihood
of remediation in the best case. The authors do not link the no-
tiﬁcation to harm or compromise outcomes, which is also true
for studies notifying vulnerable name-servers [26], misaligned
ﬁrewall policies [77], and HTTPS misconﬁguration [132].
Notifying subjects who have already been compromised
allows researchers to quantify the impact of a form of reactive
security Sr. Vasek et al. [123] show that notifying hosting
providers reduces time to clean-up malware URLs from 153
days to 101 days. Similarly, Li et al. show “direct communi-
cation with webmasters increases the likelihood of cleanup by
over 50% and reduces infection lengths by at least 62%” [78].
The authors additionally control for indicators of exposure like
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:31:54 UTC from IEEE Xplore.  Restrictions apply. 
217
site language or popularity and show that less popular sites are
associated with longer infection periods.
Summary Single indicators like security budget or certi-
ﬁcation should in theory summarise organisational security
and hence explain security outcomes. In actuality, they are
vulnerable to selection effects and manipulation. Self-reported
indicators successfully explain security outcomes [39, 113]
but are costly to collect. Studies collecting technical indica-
tors [37, 81, 89, 101] can be more easily scaled. These studies
are described in Section IV-D as they investigate the full causal
model. Notiﬁcation studies allow the researcher to control the
security level and more conﬁdently identify causal effects.
B. Measuring threat
The presence of active adversaries is a unique aspect of
security research [60]. We identify approaches to controlling
for threat level that vary across: time, target, and researcher
intervention.
Time Empirical observations of malicious activity can be
aggregated over time to track the changing threat level [70,
Fig. 2–3]. Alternatively, expert sentiments can be tracked over
time [52]. This provides longitudinal insights but the aggregate
index does not speak to heterogeneity across organisations.