# 海量机器数据实时流处理技术研究
1.  **引言**
随着信息时代的来临，企业的日常运营越来越依赖于IT系统的日常运行。企业对信息系统的依赖越深，系统的复杂度越高，IT运维的难度也随之加大。
大数据是近年来受到广泛关注的新概念，是指通过对大量来源复杂的多种类数据进行高速地捕捉、发现和分析，用经济的方法提取其价值的技术体系或技术架构。机器数据是大数据分类中，由机器直接生成的数据，也是发展最快、最为复杂，同时极具商业价值的大数据组成形式。大数据中90%的数据属于机器数据。除了来自于服务器、存储、网络中的传统IT数据以外，来自移动互联网、物联网中的大量非结构化数据也都属于机器数据。相比数据库数据，机器大数据具有数量大、增长速度快、复杂性高、多样化等特点，但是价值密度略低。借助大数据流式处理技术能够实现对机器数据的深入挖掘，充分利用数据价值，提升数据分析质量，保证IT系统稳定运行。
但因受制于建设时期的技术制约，电力行业在对机器数据的分析处理方面已逐渐无法适应新环境、新运维模式下的管理要求。基于海量数据流式处理技术，技术人员能够对全网范围内的主机、服务器、网络设备、数据库以及各种应用服务系统等产生的各类机器数据，进行规范采集，统一规范机器数据格式，统一持久化存储，统一策略制定，并进行细致分析，通过统一的控制台进行实时可视化的呈现。
**国内外主流技术**
目前国内外对主流的海量机器数据的流式处理技术如下：
1)  **数据摄取技术**
**Flume**：Flume可以从其他应用程序收集机器数据数据，然后将这些数据送入到**Hadoop**：官方网站声称："它功能强大、具有容错性，还拥有可以调整优化的可靠性机制和许多故障切换及恢复机制。"
**Sqoop**：企业经常需要在关系数据库与Hadoop之间传输数据，而Sqoop就是能完成这项任务的一款工具。它可以将数据导入到Hive或HBase，并从Hadoop导出到关系数据库管理系统（RDBMS）。
**Kafka**
：Kafka是一种高吞吐量的分布式发布订阅消息系统，它可以处理消费者规模的网站中的所有动作流数据。
2)  **序列化技术**
**Avpro**：这个Apache项目提供了数据序列化系统，拥有丰富的数据结构和紧凑格式。模式用JSON来定义，它很容易与动态语言整合起来。
**Protocol Buffers**：Protocol Buffers
是一种轻便高效的结构化数据存储格式，可以用于结构化数据串行化，很适合做数据存储或
RPC
数据交换格式。它可用于通讯协议、数据存储等领域的语言无关、平台无关、可扩展的序列化结构数据格式。
3)  **ETL（萃取、转换）技术**
**Crunsh**：Crunch 是一个用 Go 语言开发的基于 Hadoop 的 ETL
和特性抽取工具，特点是速度快。
**Apache Falcon**：Apache
Falcon是一个面向Hadoop的、新的数据处理和管理平台，设计用于数据移动、数据管道协调、生命周期管理和数据发现。它使终端用户可以快速地将他们的数据及其相关的处理和管理任务"上载（onboard）"到Hadoop集群。
**Cascading**：Cascading是一款基于Hadoop的应用程序开发平台。提供商业支持和培训服务。
**Oozie**：这种工作流程调度工具是为了管理Hadoop任务而专门设计的。它能够按照时间或按照数据可用情况触发任务，并与MapReduce、Pig、Hive、Sqoop及其他许多相关工具整合起来。
4)  **元数据技术**
**HCatalog**：Hcatalog是apache开源的对于表和底层数据管理统一服务平台。
分析工具
**Pig**：Apache Pig是一种面向分布式大数据分析的平台。它依赖一种名为Pig
Latin的编程语言，拥有简化的并行编程、优化和可扩展性等优点。
**Hive**：Apache
Hive是面向Hadoop生态系统的数据仓库。它让用户可以使用HiveQL查询和管理大数据，这是一种类似SQL的语言。
**Phoenix**：这是一个Java中间层，可以让开发者在Apache
HBase上执行SQL查询。Phoenix完全使用Java编写，代码位于GitHub上，并且提供了一个客户端可嵌入的JDBC驱动。
5)  **分析类库**
**MLib**：MLlib
是Spark对常用的机器学习算法的实现库,同时包括相关的测试和数据生成器。
**SparkR**：SparkR是一个R语言包,它提供了轻量级的方式使得可以在R语言中使用Apache
Spark。
**Mathout**：Mahout 是 Apache Software Foundation（ASF）
旗下的一个开源项目，提供一些可扩展的机器学习领域经典算法的实现，旨在帮助开发人员更加方便快捷地创建智能应用程序。Mahout包含许多实现，包括聚类、分类、推荐过滤、频繁子项挖掘。此外，通过使用
Apache Hadoop 库，Mahout 可以有效地扩展到云中。
6)  **交互式技术**
**Dremel**：Dremel 是Google
的"交互式"数据分析系统。可以组建成规模上千的集群，处理PB级别的数据。
**Drill**：Apache Drill 在基于 SQL 的数据分析和商业智能（BI）上引入了
JSON
文件模型，这使得用户能查询固定架构，演化架构，以及各种格式和数据存储中的模式无关（schema-free）数据。该体系架构中关系查询引擎和数据库的构建是有先决条件的，即假设所有数据都有一个简单的静态架构。
**Tez**：Tez建立在Apache Hadoop
YARN的基础上，这是"一种应用程序框架，允许为任务构建一种复杂的有向无环图，以便处理数据。"它让Hive和Pig可以简化复杂的任务，而这些任务原本需要多个步骤才能完成。
**Impala**：Impala是Cloudera公司主导开发的新型查询系统，它提供SQL语义，能查询存储在Hadoop的HDFS和HBase中的PB级大数据。已有的Hive系统虽然也提供了SQL语义，但由于Hive底层执行使用的是MapReduce引擎，仍然是一个批处理过程，难以满足查询的交互性。相比之下，Impala的最大特点也是最大卖点就是它的快速。
**Shark**：Shark即Hive on
Spark，本质上是通过Hive的HQL解析，把HQL翻译成Spark上的RDD操作，然后通过Hive的metadata获取数据库里的表信息，实际HDFS上的数据和文件，会由Shark获取并放到Spark上运算。
**Presto**：Presto是一个开源的分布式SQL查询引擎，适用于交互式分析查询，数据量支持GB到PB字节。
**BlinkDB**：BlinkDB 是一个用于在海量数据上运行交互式 SQL
查询的大规模并行查询引擎。它允许用户通过权衡数据精度来提升查询响应时间，其数据的精度被控制在允许的误差范围内。
**Dryad**：Dryad是微软分布式并行计算基础平台，使程序员可以利用数据中心的服务器集群对数据进行并行处理。Dryad程序员在操作数千台机器时，无需关心并行处理的细节。
7)  **流式技术**
**Storm**：Storm现在是一个Apache项目，它提供了实时处理大数据的功能（不像Hadoop只提供批任务处理）。其用户包括推特、美国天气频道、WebMD、阿里巴巴、Yelp、雅虎日本、Spotify、Group、Flipboard及其他许多公司。
**Samza**：samza是一个分布式的流式数据处理框架（streaming
processing），它是基于Kafka消息队列来实现类实时的流式数据处理的。
**Spark Streaming**：Spark
Streaming是一种构建在Spark上的实时计算框架，它扩展了Spark处理大规模流式数据的能力。
8)  **批处理技术**
**MapReduce**：MapReduce是一种编程模型，用于大规模数据集（大于1TB）的并行运算。概念\"Map（映射）\"和\"Reduce（归约）\"，是它们的主要思想，都是从函数式编程语言里借来的，还有从矢量编程语言里借来的特性。它极大地方便了编程人员在不会分布式并行编程的情况下，将自己的程序运行在分布式系统上。
当前的软件实现是指定一个Map（映射）函数，用来把一组键值对映射成一组新的键值对，指定并发的Reduce（归约）函数，用来保证所有映射的键值对中的每一个共享相同的键组。
9)  **迭代式技术**
**Pregel**：Pregel是一个用于分布式图计算的计算框架，主要用于图遍历（BFS）、最短路径（SSSP）、PageRank计算等等。
**Giraph**：Giraph是一个迭代的图计算系统。Giraph计算的输入是由点和直连的边组成的图。
**GraphX**：Spark GraphX是一个分布式图处理框架，Spark
GraphX基于Spark平台提供对图计算和图挖掘简洁易用的而丰富多彩的接口，极大的方便了大家对分布式图处理的需求。
**Hama**：Apache Hama是一个纯BSP（Bulk Synchronous
Parallel）计算框架，模仿了Google的Pregel。用来处理大规模的科学计算，特别是矩阵和图计算。
10) **引擎技术**
**Spark**：Spark是一种数据处理引擎。它声称，用在内存中时，其速度比MapReduce最多快100倍；用在磁盘上时，其速度比MapReduce最多快10倍。它可以与Hadoop和Apache
Mesos一起使用，也可以独立使用。
**Flink**：Apache
Flink是一个可伸缩的开源批处理和流处理平台。其核心模块是一个数据流引擎，该引擎在分布式的流数据处理的基础上提供数据分发、交流、以及容错的功能
11) **数据存储技术**
**ACID**：指数据库事务正确执行的四个基本要素的缩写。包含：原子性（Atomicity）、一致性（Consistency）、隔离性（Isolation）、持久性（Durability）。一个支持事务（Transaction）的数据库，必需要具有这四种特性，否则在事务过程（Transaction
processing）当中无法保证数据的正确性，交易过程极可能达不到交易方的要求。
键值存储
**Dynamo**：Dynamo是亚马逊的key-value模式的存储平台，可用性和扩展性都很好，性能也不错：读写访问中99.9%的响应时间都在300ms内。
**Cassandra**：这种NoSQL数据库最初由Facebook开发，现已被1500多家企业组织使用，包括苹果、欧洲原子核研究组织（CERN）、康卡斯特、电子港湾、GitHub、GoDaddy、Hulu、Instagram、Intuit、Netfilx、Reddit及其他机构。它能支持超大规模集群；比如说，苹果部署的Cassandra系统就包括75000多个节点，拥有的数据量超过10
PB。
**Voldemort**：Voldemort是一个分布式键值存储系统，是Amazon's
Dynamo的一个开源克隆。
2.  **海量机器数据处理的实时流处理技术解决方案**
**目前的海量机器数据处理可以分为如以下三个类型：**
1.  复杂的批量数据处理（batch data
    processing），通常的时间跨度在数十分钟到数小时之间。
2.  基于历史数据的交互式查询（interactive
    query），通常的时间跨度在数十秒到数分钟之间。
3.  基于实时数据流的数据处理（streaming data
    processing），通常的时间跨度在数百毫秒到数秒之间。 
> **Spark Streaming提供了一套高效、可容错的准实时大规模流式处理框架：**
1.  **计算流程**：Spark
    Streaming是将流式计算分解成一系列短小的批处理作业。这里的批处理引擎是Spark，也就是把Spark
    Streaming的输入数据按照batch
    size（如1秒）分成一段一段的数据（Discretized
    Stream），每一段数据都转换成Spark中的RDD（Resilient Distributed
    Dataset），然后将Spark
    Streaming中对DStream的Transformation操作变为针对Spark中对RDD的Transformation操作，将RDD经过操作变成中间结果保存在内存中。整个流式计算根据业务的需求可以对中间的结果进行叠加，或者存储到外部设备。下图显示了Spark
    Streaming的整个流程。
> ![](media/image1.png){width="5.9375in" height="4.552083333333333in"}
>
> **Spark Streaming构架图**
2.  **容错性**：对于流式计算来说，容错性至关重要。每一个RDD都是一个不可变的分布式可重算的数据集，其记录着确定性的操作继承关系（lineage），所以只要输入数据是可容错的，那么任意一个RDD的分区（Partition）出错或不可用，都是可以利用原始输入数据通过转换操作而重新算出的。
> ![](media/image2.png){width="5.9375in" height="3.6354166666666665in"}
>
> **Spark Streaming中RDD的lineage关系图**
对于Spark
Streaming来说，其RDD的传承关系如上图所示，图中的每一个椭圆形表示一个RDD，椭圆形中的每个圆形代表一个RDD中的一个Partition，图中的每一列的多个RDD表示一个DStream（图中有三个DStream），而每一行最后一个RDD则表示每一个Batch
Size所产生的中间结果RDD。图中的每一个RDD都是通过lineage相连接的，由于Spark
Streaming输入数据可以来自于磁盘，例如HDFS（多份拷贝）或是来自于网络的数据流（Spark
Streaming会将网络输入数据的每一个数据流拷贝两份到其他的机器）都能保证容错性。所以RDD中任意的Partition出错，都可以并行地在其他机器上将缺失的Partition计算出来。这个容错恢复方式比连续计算模型（如Storm）的效率更高。 