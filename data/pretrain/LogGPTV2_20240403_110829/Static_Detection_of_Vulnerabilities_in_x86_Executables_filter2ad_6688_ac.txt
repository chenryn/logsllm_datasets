3499
20
36
158
1
62
1
0.01
-
62%
37.4%
100%
100%
93%
Table 1. Test Results.
obtain highly precise program slices, in many cases it
prunes execution paths that are not relevant to our anal-
ysis.
This approach, however, has several limitations. A
fundamental precondition of our slicing technique is that
the complete interprocedural CFG for the program be
available. The presence of indirect jumps or calls makes
it harder to satisfy this requirement. While, in general, it
is impossible to statically resolve all indirect transfers of
control, we implemented some heuristics that handle the
most common cases (see Section 3.1 for more details).
If some of the indirect jumps or calls are not resolved,
no slicing is done and the whole program is analyzed.
5 Evaluation
We performed a series of experiments with our proto-
type tool to evaluate its ability to detect taint-style vul-
nerabilities. The test dataset includes two applications
with known taint-style vulnerabilities (Dropbear scp [6]
and GNU a2ps [11]) and a set of utilities that use the
system() and popen() calls. All experiments were
run on a Fedora Core 4 system, equipped with a 3.60
GHz Pentium 4 processor and 2GB RAM. All executa-
bles were obtained using the gcc 4.0.0 compiler using its
standard conﬁguration and the optimization level O2.
Experimental results are shown in Table 1. The table
reports the size of the binaries in KB and in terms of the
number of basic blocks identiﬁed by our tool before and
after performing simple slicing. The detection time indi-
cates the time required to identify all code points where
tainted data is used in system() or popen() func-
tions. The coverage column reports the percentage of
basic blocks visited at least once during the ﬁrst 30 min-
utes of execution. The detection performance results are
reported in Table 2.
When applied to the presented test set, our tool iden-
tiﬁes all uses of tainted data in sensitive operations,
i.e., the false negatives rate is 0%. The tool generates
one false positive in scp, ppmcolors, and irexec.
False positives occur for different reasons. First, our
tool raises an alarm when user-provided input is, by
design, allowed to reach the system() or popen()
functions. Such alarms can be useful to raise the atten-
tion of an analyst or systems administrator on binaries
whose security could be compromised if their intended
use changed (e.g., if they were made accessible to re-
mote, untrusted users). This is the case of the false
positive generated when analyzing scp and irexec.
Second, our tool does not include any form of type in-
ference analysis and, consequently, generates an alert
also when the type of the input prevents a successful at-
tack. In ppmcolors, for example, user input is ﬁrst
converted to an integer and then used to compose the
command string passed to system(). In this case, an
attacker would not be able to inject a malicious com-
mand in the application. Our tool correctly identiﬁes
autrace as containing no vulnerabilities because the
system() function used in this application does not
utilize any user-provided input.
The symbolic execution technique that underlies our
analysis reconstructs all feasible execution paths in a
program. However, the number of distinct paths in-
creases roughly exponentially with the number of in-
structions and, thus, can be extremely large even in small
programs. Except for the most trivial cases, an exhaus-
tive analysis would then require extremely long execu-
tion time. While this is acceptable in some contexts,
e.g., veriﬁcation, we believe that a more practical ap-
proach is needed for our detection purposes. Therefore,
we ran our experiments setting a timeout of thirty min-
utes and, in our results, we report only vulnerabilities
Proceedings of the 22nd Annual Computer Security Applications Conference (ACSAC'06)0-7695-2716-7/06 $20.00  © 2006Application
scp
a2ps
ppmcolors
irexec
autrace
Number of Calls
Total Vulnerable Detected
False Positives False Negatives
2
2
1
1
2
1
2
0
0
0
2
2
1
1
0
1
0
1
1
0
0
0
0
0
0
Table 2. Analysis Results.
detected during this interval.
7 Acknowledgments
In the current prototype of our tool, we have im-
plemented several strategies to explore execution paths
achieving good path coverage and low memory require-
ments. The depth-ﬁrst search strategy (which consists
of always resuming the last unexplored branch) is op-
timal in terms of memory usage, but can spend signiﬁ-
cant time completely exploring uninteresting paths. The
random selection of unexplored branches has a higher
impact on memory, but covers the search space evenly.
In the reported tests we used a third strategy that com-
bines depth-ﬁrst and breadth-ﬁrst search: the execution
proceeds in a depth-ﬁrst fashion for a given interval of
time. When the time interval elapses, execution resumes
from the branch corresponding to the least executed ba-
sic block in the program and continues in depth-ﬁrst
mode.
6 Conclusions
We have presented a novel adaptation of binary anal-
ysis techniques to statically detect vulnerabilities in x86
executables. We have described a number of techniques
and heuristics that we use to perform this analysis in
practical cases. We have implemented our approach in
a proof-of-concept tool and evaluated its performances
on a number of real-world programs. The results of our
tests show that the approach is practical and achieves
good detection performances.
In the future, we plan to extend our approach in dif-
ferent directions. First, we intend to include more so-
phisticated analysis, e.g., to better model memory ac-
cesses and the abstraction of loops. Second, we want to
explore the idea of complementing static analysis with
dynamic analysis to detect vulnerabilities in executables.
We would like to thank Christopher Kruegel and
William Robertson for providing us with the symbolic
execution engine and useful suggestions throughout this
project.
This research was supported by the Army Research
Ofﬁce, under agreement DAAD19-01-1-0484, and by
the National Science Foundation, under grants CNS-
0209065, CCR-0238492 and CCR-0524853.
References
[1] R. Bagnara, E. Ricci, E. Zaffanella, and P. M. Hill. Possi-
bly Not Closed Convex Polyhedra and the Parma Poly-
hedra Library.
In Proc. of the 9th Intl. Static Analysis
Symp., pages 213–229, 2002.
[2] G. Balakrishnan and T. Reps. Analyzing Memory Ac-
cesses in x86 Executables. In Proc. of the 13th Intl. Conf.
on Compiler Construction, pages 5–23, 2004.
[3] G. Balakrishnan, T. Reps, D. Melski, and T. Teitelbaum.
WYSINWYX: What You See Is Not What You eXecute.
In Proc. of the IFIP Working Conf. on Veriﬁed Software:
Theories, Tools, Experiments, 2005.
[4] J. Bergeron, M. Debbabi, J. Desharnais, M. M. Erhioui,
Y. Lavoie, and N. Tawbi. Static Detection of Malicious
Code in Executable Programs. Int. J. of Req. Eng., 2001.
[5] D. Brumley, J. Newsome, D. Song, H. Wang, and S. Jha.
Towards Automatic Generation of Vulnerability-Based
Signatures. In Proc. of the 2006 IEEE Symp. on Security
and Privacy, pages 2–16, 2006.
[6] BugTraq. OpenSSH, Dropbear: Insecure use of system()
call. http://seclists.org/lists/bugtraq/
2006/Feb/0401.html, Feb 2006.
[7] M. Christodorescu and S. Jha. Static Analysis of Exe-
In Proc. of the
cutables to Detect Malicious Patterns.
12th USENIX Security Symp., 2003.
Proceedings of the 22nd Annual Computer Security Applications Conference (ACSAC'06)0-7695-2716-7/06 $20.00  © 2006[8] M. Christodorescu, S. Jha, S. A. Seshia, D. Song, and
R. E. Bryant. Semantics-Aware Malware Detection. In
Proc. of the 2005 IEEE Symp. on Security and Privacy,
pages 32–46, 2005.
[9] S. Debray, R. Muth, and M. Weippert. Alias Anal-
ysis of Executable Code.
In Proc. of the 25th ACM
SIGPLAN-SIGACT Symp. on Principles Of Program-
ming Languages, pages 12–24, 1998.
[10] S. Forrest, S. Hofmeyr, A. Somayaji, and T. Longstaff. A
Sense of Self for UNIX Processes. In Proc. of the 1996
IEEE Symp. on Security and Privacy, pages 120–128,
1996.
[11] Full-Disclosure. a2ps executing shell commands from
ﬁle name. http://archives.neohapsis.com/
archives/fulldisclosure/2004-08/1026.
html, Aug 2004.
[12] J. T. Gifﬁn, S. Jha, and B. P. Miller. Efﬁcient Context-
Sensitive Intrusion Detection. In Proc. of the 11th Net-
work and Distributed System Security Symp., 2004.
[13] L. C. Harris and B. P. Miller. Practical Analysis of
In Proc. of the 2005 Workshop
Stripped Binary Code.
on Binary Instrumentation and Applications, 2005.
[14] M. Hind. Pointer Analysis: Haven’t We Solved This
Problem Yet?
In Proc. of the 2001 ACM SIGPLAN-
SIGSOFT Workshop on Program Analysis for Software
Tools Engineering, pages 54–61, 2001.
[15] S. Horwitz, T. Reps, and D. Binkley.
Interprocedural
Slicing Using Dependence Graphs. In Proc. of the ACM
SIGPLAN 1988 Conf. on Programming Language De-
sign and Implementation, pages 35–46, 1988.
[16] J. C. King. Symbolic Execution and Program Testing.
Communications of the ACM, 19(7):385–394, 1976.
[17] E. Kirda, C. Kruegel, G. Banks, G. Vigna, and R. Kem-
In Proc. of
merer. Behavior-based spyware detection.
the 15th USENIX Security Symp., 2006.
[18] C. Kruegel, E. Kirda, D. Mutz, W. Robertson, and G. Vi-
gna. Automating Mimicry Attacks Using Static Binary
Analysis. In Proc. of the 14th USENIX Security Symp.,
pages 161–176, 2005.
[19] C. Kruegel, E. Kirda, D. Mutz, W. Robertson, and G. Vi-
gna. Polymorphic Worm Detection Using Structural In-
formation of Executables. In Proc. of the 8th Intl. Symp.
on Recent Advances in Intrusion Detection, pages 207–
226, 2005.
[20] C. Kruegel, W. Robertson, and G. Vigna. Detecting
Kernel-Level Rootkits Through Binary Analysis.
In
Proc. of the Annual Computer Security Applications
Conf. (ACSAC), pages 91–100, Tucson, AZ, December
2004.
[21] B. Livshits and M. Lam. Finding Security Vulnerabili-
ties in Java Applications with Static Analysis. In Proc. of
the 14th USENIX Security Symp., pages 271–286, 2005.
[22] B. P. Miller, L. Fredriksen, and B. So. An Empirical
Study of the Reliability of UNIX Utilities. Communica-
tions of the ACM, 33(12):32–44, 1990.
[23] D. Mutz, F. Valeur, G. Vigna, and C. Kruegel. Anoma-
lous System Call Detection. ACM Transactions on In-
formation and System Security, 9(1), Feb 2006.
[24] N. Nethercote and J. Fitzhardinge. Bounds-Checking
Entire Programs Without Recompiling.
In Informal
Proc. of the 2nd Workshop on Semantics, Program Anal-
ysis, and Computing Environments for Memory Manage-
ment, 2004.
[25] J. Newsome, B. Karp, and D. Song.
Polygraph:
Automatically Generating Signatures for Polymorphic
Worms.
In Proc. of the 2005 IEEE Symp. on Security
and Privacy, pages 226–241, 2005.
[26] J. Newsome and D. Song. Dynamic Taint Analysis for
Automatic Detection, Analysis, and Signature Genera-
tion of Exploits on Commodity Software. In Proc. of the
12th Annual Network and Distributed System Security
Symp. (NDSS’05), 2005.
[27] F. Nielson, H. R. Nielson, and C. Hankin. Principles
of Program Analysis. Springer-Verlag New York, Inc.,
Secaucus, NJ, USA, 1999.
[28] Oulu University Secure Programming Group. PROTOS
Test-Suite: c06-snmpv1. Technical report, University of
Oulu, Electrical and Information Engineering, 2002.
[29] T. Reps, G. Balakrishnan, and J. Lim.
Intermediate-
Representation Recovery from Low-Level Code.
In
Proc. of the 2006 ACM SIGPLAN Symp. on Partial
Evaluation and semantics-based Program Manipula-
tion, pages 100–111. ACM Press, 2006.
[30] T. Reps, G. Balakrishnan, J. Lim, and T. Teitelbaum.
Next-generation platform for analyzing executables. In
Proc. of the 3rd Asian Symp. on Programming Lan-
guages and Systems, pages 212–229, 2005.
[31] B. Schwarz, S. Debray, and G. Andrews. Disassembly of
Executable Code Revisited. In Proc. of the 9th Working
Conf. on Reverse Engineering, pages 45–54, 2002.
[32] V. C. Sreedhar, G. R. Gao, and Y.-F. Lee.
Identify-
ing Loops Using DJ Graphs. ACM Transactions on
Programming Languages and Systems, 18(6):649–658,
November 1996.
[33] R. E. Tarjan. Testing Flow Graph Reducibility. Journal
of Computer and System Sciences, 9(3):355–365, 1974.
[34] D. Wagner, J. S. Foster, E. A. Brewer, and A. Aiken. A
First Step Towards Automated Detection of Buffer Over-
run Vulnerabilities. In Proc. of the Annual Network and
Distributed System Security Symp. (NDSS 2000), 2000.
In Proc. of the 5th Intl.
[35] M. Weiser. Program Slicing.
Conf. on Software Engineering, pages 439–449, 1981.
[36] Y. Xie and A. Aiken. Static Detection of Security Vul-
nerabilities in Scripting Languages. In Proc. of the 15th
USENIX Security Symp., 2006.
Proceedings of the 22nd Annual Computer Security Applications Conference (ACSAC'06)0-7695-2716-7/06 $20.00  © 2006