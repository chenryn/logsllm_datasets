7
8
9
10
11
12
13
14
15
is user = len ( s reqs ) > 0
i f
is bot = bot
i f
is bot :
break
is bot = bot
i f
is bot :
break
like pw ( r2 . domain , r2 .pw, d2)
for r2 in get similar reqs ( ip , r1 , d1 ,
t ) :
is user :
break
tag ip ( ip ,
is bot ,
is user )
contains popular search engine keywords (e.g., “google”), the
IP address will be tagged as a bot
• for each request from a major browser (detected using the
User-Agent header [34]), mark the IP address with bot
or trust depending on whether there is a corresponding
fingerprint for the request
In our dataset, we observe approximately 1M fingerprints
from 52K unique IP addresses. The corresponding tag that
represents these filters in Figure 4 are bot-fingerprint and
user-fingerprint.
b) Request characteristics: Our second major type of traffic
analysis filters rely on suspicious-request characteristics for each
service. For our HTTP(S) service, the filters focus on request paths;
for the credentials-based services (SSH, Telnet, and FTP), the filters
focus on username and password combinations.
Our bot filters for web traffic identify attempts to a) use exploits
(e.g., a path traversal attack [35] or a CVE for a web service),
b) access a backdoor (e.g., /shell.php), c) fingerprint the web
service [33] (e.g., common paths used by BlindElephant [36]),
d) access backups files (e.g., /wp-config.old), and e) make
a login request with HTTP method POST. The content that we serve
does not include a POST login form, so these have to be automated,
credential-stuffing requests. The corresponding IP addresses are
tagged with bot-path in Figure 4.
We also manually categorized the services offered by each domain
on the HTTP(S) protocol, pre-expiration, and assign a confidence level
of low or high. We rely on, in decreasing order of priority, the Wayback
Machine for historical archives, combing Google for references to
the domain, and identifying request patterns in our logs to assign
a category representing the type of service the domain previously
offered. If we could not categorize a domain on the HTTP(S) protocol,
we attempt to use the most popular port to categorize traffic. If the
most popular port for such a domain is a standard port, we include a
breakdown, otherwise we place the domain in the Unknown category.
To identify request patterns, we make use of our database’s
optimized query and aggregation functionality [30]. For each domain
in our dataset, we start with a traffic sample of at most 3 requests
per IP address per data shard [37] and find keywords in request paths
that are significantly more popular within the particular domain as
compared to across all domains [38]. Requests for paths that match
HIGH-LEVEL TRAFFIC VOLUME STATISTICS TO HONEYPOT SERVICES IN
DOMAIN SERVERS.
TABLE I
Service
# Requests
# Unique IPs
# ASNs
HTTP(S)
SSH
Telnet
FTP
Total
421M
195M
34M
279K
651M
5.2M
110K
240K
6K
5.5M
21K
5.4K
8.6K
1.1K
23K
these significantly more popular keywords within the domain are
then aggregated for manual inspection.
In addition to a category label, each domain is also annotated with
a confidence level of: a) low if we can only infer from third-party
references or popular request paths, or b) high if we found an archived
version of the domain no older than six months and the URL structure
of the archived page is similar to the traffic patterns we observed.
For the domains with a high confidence label, we manually compile
a list of residual paths for each domain: paths that used to exist on the
domain pre-expiration. Through inspection of the links on an archived
domain’s homepage, we construct a per-domain set of residual
path patterns. Main navigation links and other prominent endpoints
were prioritized in the set for each domain. If many service-relevant
endpoints were found to have the same request path prefix (e.g.,
/a/b/c, /a/b/d), we subsume them into a wildcard query
record with the longest matching prefix (e.g., /a/b/*) to account
for potential new paths that were added after the archival date. The
residual path patterns for each domain also include traffic patterns
observed in our logs that are of similar structure to the ones in the
archived version. General paths that are common to many domains
and are not service-specific are excluded (e.g., /contact). Client
IP addresses that request any of these residual paths are marked with
the trust filter residual-path in Figure 4.
For our credentials-based services, we rely on credential patterns
to identify suspicious requests. Our main filters match requests with
the following characteristics:
• (Bot) passwords in the 1,000 most popular passwords of the
RockYou database breach [39],
• (Bot) passwords that contain the domain name [33],
• (Bot) username and password combinations that are also
used in traffic to our placebo servers. There is a potential for
false negatives if there are legitimate username and password
combinations that have been guessed by bots.
• (Trust) multiple login attempts with credentials that are nearly
the same (max Levenshtein distance of 1 for username and for
password) within a window of 120 seconds. Listing 1 includes
a more detailed description of the algorithm. We reason that
bots are more likely to attempt logins from credentials lists,
as opposed to brute-force guessing, and these credentials are
a farther distance apart. Repeatedly attempting the same or
very similar credentials yields less potential gain and can be
an indication of human behavior (i.e., trying to log in again
thinking there was a typo in the password).
Our last filter that uses request characteristics identifies suspicious
requests from a packet structure perspective instead of a particular
service’s perspective. We base this filter on prior network monitoring
efforts which identified a characteristic of some Mirai variants that
send TCP SYN probes with the TCP sequence number set to the desti-
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 13:01:51 UTC from IEEE Xplore.  Restrictions apply. 
2135
Fig. 5. Number of unique IP addresses that contact the ten least and most popular
placebo servers and expired domains daily. The popularity of each server was ranked
using the total number of unique IP addresses in its traffic.
nation IP address when displayed byte-by-byte in dotted-decimal nota-
tion (e.g., 0x48c1af41 for 72.193.175.65) [40]. We scan
our TCP header capture files and mark the IP addresses that match
this condition as bots. The corresponding tag in Figure 4 is mirai.
c) IP blocklists: IP blocklists are our sole external bot detection
mechanism. Blocklists are well-established in industry and are
commonly used for routing and firewall rules [41]. We use multiple
DNS blocklist (DNSBL) providers and IP blocklists related to
reputation and cyber crime as aggregated and categorized by
FireHOL [42]. DNS blocklists were created for and typically used to
protect mail servers against spam mail. Although our primary purpose
is not to detect which IP addresses send spam mail, it is likely that
any traffic coming from these addresses are not due to residual trust.
We use 52 DNSBL providers including Spamhaus [43], SORBS [44],
and Barracuda Central [45].
IV. TRAFFIC ANALYSIS
In this section, we report our findings on the data collected from 201
re-registered domains in the time period from August 1, 2019 to De-
cember 1, 2019. Our honeypot services collected a total of 650,737,621
requests to our re-registered domain servers from 5,540,379 unique
IP addresses distributed among 22,744 unique autonomous systems;
see Table I for a breakdown of the number of requests, number of
unique IP addresses, and number of autonomous systems for each
service. We begin by conducting a high-level verification of our
filtering mechanisms and then characterizing the traffic volume and
port popularity of our servers using packet-level and honeypot service
log-level perspectives. We then present the results of using the bot and
trust indicators described in Section III-D and detail the high-level
temporal characteristics of the residual trust traffic for select domains.
A. High-Level Verification of Filtering Mechanisms
Because we conducted our experiment in the wild, we do not have
access to a ground-truth dataset. The closest data point to ground truth
could be the fingerprinting script that was served over HTTP(S), but
this would not capture some valid use cases (e.g., if a domain used to
respond to requests from automated tools that have no need to support
JavaScript). We opted to perform a high-level verification of our
results by considering the blocklist filters (DNSBLs and FireHOL’s IP
blocklists) as a ground truth, comparing the result of using the other
filtering mechanisms with the result of using only the blocklist filters.
The blocklist filters marked 1,866,840 IP addresses as suspicious
(bot-like); all other filtering mechanisms marked 417,282 IP addresses
as suspicious. There are 332,513 IP addresses (79.68% of 417,282)
that were flagged suspicious by both the blocklist filters and another
Fig. 6. Traffic volume levels for all domains. Bucket labels were assigned based on
either the total number of inbound packets or of honeypot service log requests. The
corresponding value for a bucket on a day is the mean of all its domains’ value for
that day. The intervals in each label refer to percentile threshold cutoffs. The low traffic
bucket comprises up to the 50th percentile and medium up to the 90th percentile. Note
the 100th percentile domain is different depending on the grouping strategy.
filter. This suggests that most IP addresses which exhibit suspicious
behavior are likely to already be on a blocklist and that the filtering
mechanisms confirm one another. However, the non-blocklist
filters have their own merit in identifying IP addresses that exhibit
suspicious behavior without the need to resort to a trusted third party
(i.e., the provider of a blocklist).
B. Characterizing Volume and Popularity
a) Stratified traffic volume: Figure 5 shows the distribution
of the number of IP addresses that contact the ten most and least
popular placebo servers and domains. We compare the same number
of servers in each group because we deployed fewer placebo servers
(52) than domain servers (201). We find that the less popular domains
receive traffic from a similar number of IP addresses as our placebo
hosts, but the more popular domains receive substantially more traffic,
more than an order of magnitude more IP addresses compared to
the most popular placebo servers.
Beyond the large difference in traffic volume between the placebo
servers and domain servers, we also see a pronounced difference
in traffic volume within our domain servers. Figure 6 visualizes the
underlying distribution of traffic to our domain servers by grouping
domains depending on both their aggregate packet count and honeypot
service log count using the 50th and 90th percentiles as thresholds.
The packet-level grouping reveals that there is a vast amount of traffic
that is not captured by our service logs — the 100th percentile server
in the packet-level grouping is not the same as the 100th percentile
server in the log-level grouping because of vast amounts of traffic
to ports without running services. For the packet-level grouping, the
highest-volume server is tianxingmeng.com which received
significant traffic to the ports {8000,6600}, whereas, for the log-level
grouping, ipv6tracker.org received the largest number of
service requests as it previously hosted a torrent tracker on port 80.
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 13:01:51 UTC from IEEE Xplore.  Restrictions apply. 
2136
Fig. 7. Similarity heatmap of the five most popular inbound ports (by number of
packets received) for all 253 containers (placebos and domains) in our experiment.
Axis labels correspond to an ID number for each container, temporally ordered by
re-registration date. All placebo containers appear on the axes before containers
associated with re-registered domains (thus comparisons between placebo containers
are in the top-left corner).
We further elaborate on the characteristics of the traffic to these two
domains in Section V.
b) Dissimilar types of traffic: We characterize the type of traffic
received by each server as an ordered tuple of their five most popular
inbound ports (by raw packet count) and disregard the magnitudes.
Hence, using this representation, we compare only the port numbers
and the order of the most popular ports, and not the number of
packets sent to each port. Figure 7 summarizes this in the form of
a heatmap whose values are weighted Jaccard similarity scores of the
five most popular inbound ports for two servers. A high score (dark
color) means that the five most popular inbound ports for one server
are similar to the five most popular inbound ports for another server.
From the dark square region in the upper-left of the heatmap,
we find that the majority of placebo servers receive traffic to the
same ports. There are notable outliers whose most popular ports are
radically different from the rest of the servers and they are visualized
as white rows and columns. Interestingly, we see an outlier placebo
server at A. Whereas the most popular ports for placebo servers
were typically [22,80,23,25,2222], A’s most popular ports were
[23,22,445,80,8089]. We attribute this phenomenon to a one-off
cause as it is unique among all placebos and there would be no reason
for a network scanner to probe only the particular IP address for A
and not others in the network. The other outliers are all from our
domain servers. B corresponds to two domains which previously
functioned as sinkhole DNS name servers for a security company, and
C corresponds to another high-volume DNS server. D corresponds to
two domains that received large amounts of traffic to ports 8000 and
6600. We take a closer look at the traffic to these outliers in Section V.
c) Port popularity: Requests sent to ports that do not have
an associated service listening on them are bound to not receive a
reply. Thus, honeypot services on expired domains might increase
port popularity only if the clients responsible for the traffic value
meaningful replies (i.e. expect replies to be in a certain format).
We find that the lack of interaction and associated service for
non-honeypot ports does not deter certain clients from contacting
Fig. 8. Traffic volume for the ten most popular ports to all domains.
some of our domains, as can be seen in Figure 8. Many of these
are worrisome; we find that the five most popular non-honeypot
ports include both standardized ports for DNS and SMTP and
non-standardized but popular ports for alternative HTTP and
Internet radio/music [46], [47]. Owning a DNS name server enables
controlling all clients who depend on the server for domain resolutions.
Mail server owners are able to eavesdrop on email communications,
regardless if the communication is encrypted with TLS. Controllers
of popular radio and music servers can cherrypick content that will
be absorbed by their listeners. We make these examples concrete in
Section V by discussing particular domains that offered these services.
We also note that there is a distinct popularity ordering among our
honeypot services, with HTTP(S) as the most popular and followed
by SSH, Telnet, and FTP, and suspect that the lack of depth in
interaction provided by our credentials-based honeypot services might
have contributed to this phenomenon. Thus, we present the results of
our residual trust detection pipeline on, mainly, the HTTP(S) service
traffic in the next section.
d) Profiling domains: We report our findings from our manual
domain service profiling for the 201 re-registered domains in detail
in Table II. Of the domains selected by our strategy, approximately
20.90% were previously gambling websites that used real world cur-
rency and 16.42% were related to crime, either offering contrabands,
document forgery, or serving as a command-and-control server.
Many of these services can be abused by an adversary who obtains
ownership of the corresponding domain, particularly if they are high
volume. A malicious actor who closely monitors traffic to each domain
could identify, profile, and then straightforwardly categorize a domain
with residual trust traffic. With a general idea of what the domain pre-
viously offered, they would be able to better tailor their own honeypot
services to gather and exfiltrate personally identifiable information.
C. Pipeline Results for Honeypot Services
We broadly distinguish the HTTP(S) protocol from the credentials-
based services because of the difference in interaction and available
information for each request. Although we serve the same 404
page to all HTTP(S) requests, the requests allow for a higher level
of interaction (and consequently more log information) than the
credentials-based services that only collect login attempts. Clients
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 13:01:51 UTC from IEEE Xplore.  Restrictions apply. 
2137
TABLE II
HTTP(S) SERVICE PROFILING BREAKDOWN FOR EVERY DOMAIN.
PORT H REPRESENTS HTTP AND HTTP(S) ON PORTS 80 AND 443 AND NON-H
POPULAR PORTS INCLUDE {23,25,1443,8000,6600}. TRAFFIC VOLUME LEVELS
WERE ASSIGNED BASED ON THE 50TH AND 90TH PERCENTILE OF TOTAL PACKET
COUNTS TO EACH DOMAIN SERVER.
Category Port
Conf.
Volume Bucket
Total
Low
Conf.
L
M H
Gambling H
Crime H
Streaming H
Adult H
Company H
DNS 53
Non-H
Downloads H
API H
Email 25