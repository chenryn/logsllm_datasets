destroying steganography.
Next, we present our main result in Section 3.2: a generic transformation that destroys steganog-
raphy in randomized algorithms. The basic technique relies on “double-splitting” the randomness
generating procedure coupled with a public immunizing function: speciﬁcally, randomness gener-
ation is expressed as two algorithms RG0,RG1 in conjunction with a public immunizing function Φ.
We prove that with this “extra” split, when the outputs r0 ← RG0, r1 ← RG1 are independently sam-
pled from RGi and mixed with Φ, the new speciﬁcation of the randomness generation algorithm is
indeed stego-free in the random oracle model. Note that all components, including the immunizing
function Φ, are subject to subversion. With randomness generation cleaned in this way, we can
further destroy the subliminal channel in a large class of randomized algorithms. These results
enable us to overcome the major obstacle in designing cryptographic speciﬁcations that satisfy
subversion resistance.
11
Transition to the standard model. Finally, we consider how to achieve stego-freeness without
a random oracle. The main observation is that the watchdog can guarantee that each copy of
a particular RGiimpl provides at least log n bits of (min-)entropy. If we are willing to have more
components for randomness generation, we can accumulate entropy using a simple immunizing
function and stretch the result using a PRG. See Sec. D in the appendix.
3.1 Impossibility of publicly immunizing a single random source
Previous works [BPR14, BJK15] demonstrated that if a (subverted) randomized algorithm is used in
a black-box fashion, a subliminal channel can always be embedded in its output distribution. Here
we point out that a similar attack exists even if we adopt the techniques described in [RTYZ15]
which (i.) split the algorithm G into RG (which generates randomness) and dG (which is determinis-
tic), (ii.) introduce Φ—an “immunizing” function—and, ultimately, (iii.) generate output via the
composition dG ← Φ ← RG. Here Φ is responsible for “cleaning” the randomness produced by
the possibly subverted randomness generator RG. In fact, this approach can fail even in the most
generous setting when Φ is given by a random oracle and the adversary only subverts RG.
The attack is a straightforward adaptation of the techniques from [BPR14, BJK15]: the subverted
implementation RGimpl can evaluate dG and appropriately query the random oracle Φ during the
procedure of rejection sampling. It is easy, then, to arrange for the the output of RGimpl to be biased
in a way only detectable by the adversary. While a generic attack is possible, for concreteness
we present an attack on a subverted public-key cryptosystem which permits the adversary to
eﬀortlessly determine the (plaintext) message bit. This indicates that more advanced non-black-box
techniques are necessary to remove steganographic channels in general.
A detailed description appears in Sec. B.
3.2 Purifying randomness via double splitting
The attacks described above (and by [BPR14, BJK15]) demonstrate a core obstacle to defending
randomized algorithms against subversion: the random coins drawn by the subverted implementa-
tion can be biased—for example, by rejection sampling—even if they are then “immunized” by
a random oracle. On the other hand, the split-program model intuitively oﬀers the watchdog an
opportunity for ﬁne-grained testing: Is the situation really no better than the purely black-box
model? Let us take a closer look from the security analysis point of view.
Intuitively, speciﬁcations of the form (RGspec,dGspec, Φspec) can provide security in a klepto-
graphic setting if the immunization function Φ can suitably interfere with generation of biased
output by the implementation of RGspec. To simplify our presentation, we assume throughout that
RGspec produces at least λ bits of randomness; this does not aﬀect the generality of the results.
(Our techniques can be adapted to a low-entropy setting with some changes to running time of the
watchdog.5) An important feature in this setting is that an oﬄine watchdog W can at least guar-
antee that the output r0 of RGimpl is unpredictable to the adversary A. Otherwise, the distribution
given by RGimpl would have signiﬁcant (non-negligible) collision probability,6 which can be easily
5Observe that if RGspec produces only O(log n) random coins then an oﬄine watchdog, by a suitable regimen of
repeated sampling, can empirically approximate (with high probability) the distribution of RGimpl with high accuracy.
This can be directly compared with RGspec using distance in total variation. Note that such a watchdog requires a
number of samples polynomial in the resulting error.
6Observe that if D is a probability distribution on a set X, the optimal strategy for predicting the result of drawing
12
tested by W who simply draws two samples and rejects if it observes a collision. (As with the other
tests we discuss, the success of this test can be ampliﬁed by repetition.) On the other hand, the
collision probability of RGspec is negligible. This suggests the intuition that Φspec(r0) appears to A
to be a randomly drawn value if Φspec is a random oracle. Unfortunately, A also holds the backdoor
z which may contain information about the ﬁnal output r = Φ(r0) generated by the sampling and
“cleaning” process. In particular, as shown in the attack, the subverted implementation has full
access to Φspec and may thus bias the output r = Φ(r0) as a function of z, which can be noticed by A.
To circumvent the above obstacle, we introduce a new technique that further splits randomness
generation into two random algorithms, RG0
spec, and combines their outputs using an
immunization function Φspec; we shall see that this mechanism can destroy subliminal channels.
In general, in the trusted amalgamation model, (see Deﬁnition A.1 in appendix. A.1) the user runs
RG0
impl independently and passes the joint outputs to Φimpl; the ﬁnal output will have
the form r = Φimpl(r0 ◦ r1) (where ◦ denotes concatenation). The main idea behind this strategy is
that it frustrates attempts by RG0
impl to launch sophisticated rejection-sampling because
the ﬁnal output is not fully determined by either output. (In particular, neither can evaluate
Φimpl(r0 ◦ r1) during the generation of r0 or r1.) In this way, if Φspec is modeled as a random oracle,
the ﬁnal output Φspec(r0 ◦ r1) will be uncorrelated with A’s state (which includes both A’s random
oracle queries and z). Now we can safely claim that r looks uniform even to A.7
impl and RG1
spec and RG1
impl and RG1
We remark on a similarity between the setting above and the topic of randomness extrac-
tors [NZ96]. Recall that an extractor E is a deterministic function which takes as input a number
of imperfect random sources X1, X2, . . . , Xk and produces a nearly uniform output E(X1, . . . , Xk). It
is a fact that extraction is not possible when k = 1—no ﬁxed deterministic function E can produce
clean randomness from a source with bounded min-entropy. On the other hand, it is possible when
k ≥ 2 [CG88, Bou05, CZ15].
With this approach, we demonstrate a qualitative advantage of the split-program methodology.
We ﬁrst describe a stego-free speciﬁcation of randomness generation in Fig. 4, and then proceed to
give an immunization strategy for arbitrary randomized algorithms so long as they have a public
input distribution (or a small input domain). We apply these tools in next section to construct an
IND-CPA public key encryption scheme that retains security under subversion; note that this is
impossible to achieve if randomness generation is used as a black-box (even if it is separated as an
individual component).
RG0
spec
RG1
spec
r0
r1
Φspec
r
Figure 4: A stego-free speciﬁcation for randomness generation.
probability of D, equal to(cid:80)
x D(x)2, is at least 2.
an element of X according to D is simply to guess maxx D(x). If this maximum probability is , then the collision
7We remark that Φimpl can be subverted, but it is a deterministic function with a public input distribution, the
inconsistency can be ensured to be at only a negligible fraction of places due to the watchdog, see Lemma 2.3.
13
Theorem 3.1. Consider a randomness generation algorithm RG with speciﬁcation (RG0
as described in Fig. 4:
spec and RG1
spec, given 1λ, output uniformly random strings of length λ;
• RG0
• Φspec is a hash function so that Φspec(w) has length (cid:100)|w|/2(cid:101); and
• the speciﬁcation for RG(1λ) is the amalgamation Φspec(RG0
spec(1λ),RG1
spec(1λ)).
spec,RG1
spec, Φspec)
impl,RG1
impl and RG1
impl and RG1
Then RGspec is stego-free in the trusted amalgamation model (see Def. A.1 in Sec. A.1 in the appendix) if
Φspec is modeled as a random oracle.
Proof. If the speciﬁcation of Fig. 4 is not stego-free, then for any oﬄine watchdog W there is an
adversary A that can prepare an implementation RGimpl := (RG0
impl, Φimpl) satisfying the
following: (1.) W cannot distinguish RGimpl from RGspec via oracle access; (2.) The adversary
A can distinguish output of RGimpl from RGspec, i.e., she can win the game deﬁned in Figure 11
in supporting material, Sec. A.1. We will then deﬁne an oﬄine watchdog such that these two
conditions cannot hold simultaneously for any adversary.
An oﬄine watchdog. The watchdog W’s strategy is as follows: W ﬁrst draws a constant number
impl; if W observes a collision in either distribution, it rejects the
of samples from RG0
implementation outright (as collisions are negligible in spec). Next, W draws pairs of samples
(again) from RG0
impl and evaluates Φimpl on (the concatenation of) each pair to ensure
that the result is consistent with Φspec. (As usual, this testing involves only O(1) samples and can
be trivially ampliﬁed by repetition.)
Next, we will show, for any ppt adversary A, if the detection probability DetW,A is negligible,
then the advantage AdvA will also be negligible, thus the two conditions cannot hold simultane-
ously.
Game transitions. We will go through the security game part of Def. A.1 step by step. Without loss
of generality, we assume the challenge r contains only one element (i.e., q = 1 in Def. A.1).
In Game-0, the adversary A prepares subverted implementations RGimpl := (RG0
impl, Φimpl);
we let Q be the set of random oracle queries A made during preparation of RGimpl.
The challenger C samples from RG0
impl respectively and receives r0 and r1; then C
evaluates Φimpl at r0◦ r1 and sends the output r as the challenge to A. Let Qb (for b = 0,1) be the set
of random oracle queries made by RGbimpl before outputting rb. All random oracle queries will be
(consistently) answered with randomly chosen values.
Game-1 is identical to Game-0, except that Φimpl is replaced with Φspec; Game-2 is identical to
Game-1, except that the challenger C simply chooses a uniform r and directly sends it to A as the
challenge; Game-3 is identical to Game-2, except that RGimpl is completely replaced with RGspec;
Game-4 is identical to Game-3, except that r is generated as in Game-0, but the challenger uses
RGspec instead.
Probabilistic analysis. We will analyze the gaps of each game transition conditioned on the event
that DetW,A is negligible, we denote this event as DW . All the probability gap would be under the
condition DW . For brevity, we assume the condition DW without mention for the analysis of each
probability gap.
impl and RG1
impl,RG1
First, since Φspec is a deterministic function with a public input distribution (the output
distribution of RG0
(cid:104)
impl × RG1
impl), following Lemma 2.3,
Φimpl(r0 ◦ r1) (cid:44) Φspec(r0 ◦ r1) : r0 ← RG0
Pr
impl, r1 ← RG1
impl
(cid:105) ≤ negl(λ) .
14
Otherwise, the gap is non-negligible and the watchdog W will notice the inconsistency (with
non-negligible probability). It follows that replacing Φimpl with Φspec would incur only a negligible
diﬀerence (conditioned on DW ), thus:
|Pr[bC = 1 in Game-0]− Pr[bC = 1 in Game-1]| ≤ negl(λ).
0. While on the other hand, RG0
Second, we will argue that the probability that r0 ◦ r1 is ever queried (falling in Q ∪ Q0 ∪ Q1) is
negligible, and now we are in Game-1 using Φspec which is a random oracle.
It is easy to see that Pr[r0 ◦ r1 ∈ Q] ≤ negl(λ); otherwise, the watchdog will observe a collision
in RGiimpl with non-negligible probability. To see this, let R0 = {r0 | ∃r1, r0 ◦ r1 ∈ Q}, note that Q, R0
are only polynomially large. If the probability r0 ◦ r1 falls into Q (thus the probability that r0 falls
into R0) is non-negligible, say δ, that means r0 will be generated by RG0
impl with probability at least
δ0 = δ/poly(λ). It follows that the collision probability that RG0
impl produces the same output r0
would be δ2
spec produces uniform bits, the collision probability (that
RG0
impl produces the same uniform output string r0) would be negligible. Thus the watchdog can
easily distinguish RG0
Similarly, we bound the probability for Q0, Q1. Let R0,1 = {r1 | ∃r0, r0 ◦ r1 ∈ Q0}. Since
impl,RG1
RG0
impl are independently run, the probability that r1 falls into the polynomially large
impl outputs r1 with a non-negiligble probability, then W
set R0,1 would be negligible; otherwise, RG1
can notice the diﬀerence between implementations and the speciﬁcations by identifying collisions.
Thus Pr[r0 ◦ r1 ∈ Q0] ≤ Pr[r1 ∈ R0,1] ≤ negl(λ). The same holds for Q1.
The adversary A is holding the set of random oracle queries Q, and a backdoor z. The only
way r may correlate with z is that r0 ◦ r1 is queried during the execution of RG0
impl. If
r0◦r1 (cid:60) Q∪Q0∪Q1, r0◦r1 will be independent with A’s view (Q, z), thus r = Φspec(r0◦r1) = RO(r0◦r1)
looks uniform to A. We can claim that:
impl, or RG1
impl from RG0
spec when drawing, say 2 samples.
|Pr[bC = 1 in Game-1]− Pr[bC = 1 in Game-2]| ≤ negl(λ).
Next, it is easy to see that Pr[bC = 1 in Game-2] = Pr[bC = 1 in Game-3] since the adversary
receives the identical challenge. Also, Pr[bC = 1 in Game-3] = Pr[bC = 1 in Game-4] since querying
RGspec yields a uniform output RO(u0 ◦ u1), where u0, u1 are uniformly chosen.
To conclude, conditioned on DW , we have:
|Pr[bC = 1 in Game-0]− Pr[bC = 1 in Game-4]| ≤ negl(λ) .
Observe that Game-0 corresponds to the case that challenger ﬂips a coin to be 0, i.e., C uses
RGimpl to generate the challenge messages, while Game-4 corresponds to the case that b = 1, when
C uses RGspec. It follows that:
AdvA = |Pr[bC = 1]− 1/2| ≤ negl(λ) .
Combine all above, we can conclude that the RGspec deﬁned in Figure 4 is stego-free.
Implementation considerations. Practical deployment of such splitting and amalgamation—
especially as it requires independence and (for the watchdog) copying internal state—clearly
requires detailed consideration of the particular computational environment. In general, there
are two natural approaches to achieve independence: The most modular approach relies on
modern lightweight virtualization layers such as Docker [Doc13] to insulate individual copies of
15
the adversary’s code; we remark that this also permits state duplication (which may be necessary
for the watchdog in the stateful case). More aggressive complete virtualization is also possible, but
more cumbersome. An alternate approach relies on constraining the source code (or the compiler)
to directly limit I/O and system calls; this has the advantage that the components can be run
eﬃciently in the native environment. Finally, there may also be settings where it is possible to
isolate the program in the architectural/hardware layer or physically separate various components
(e.g., using Intel’s secure isolation gateway, or even move one RGi outside the user’s computer, use
a random beacon, etc.).
Remark 3.2 (Stateful algorithms). The previous construction gives a concrete analysis of how a simple
watchdog can secure a split speciﬁcation. At the end of Section 2, we remarked that our results hold even
if the implementations are stateful, in the sense that they may maintain local state that persists between
executions.
To see this in the example above, we need to ensure that the implementation RGbimpl produces unpre-
dictable outputs (even to the adversary) for polynomially many invocations. Even if the implementation
keeps some internal state, we can recover the same result by adopting a slightly more advanced watchdog
which is permitted to have running time that depends on the adversary. In particular, if the adversary
is permitted to run the implementation k times, the watchdog may, for each 1 ≤ k
(cid:48) ≤ k, (1.) run the
implementation k
times to generate a particular internal state s, and then (2.) run the implementation
a constant number of times with state s to test for collisions. By this process, the watchdog can guar-