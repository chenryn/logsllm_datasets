ing manufacturing, the µTPM producer creates a HEK cer-
tiﬁcate that certiﬁes that the µTPM architecture is imple-
mented correctly.
The FTE provides the following attestation routines:
• FTE FCRRead() returns the ﬁrmware identity C, which
is stored in the Firmware Conﬁguration Register.
• FTE Quote(b) uses the HEK to create a signature on
the blob b and the FCR content:
q = signHEK (b,C)
It is important to note that the attestation feature is not ex-
posed externally over the XIO interface, but only internally
to µTPM processes.
With this functionality, a TPM process can register its
own EK with a privacy CA by doing a quote operation on the
public EK and a fresh nonce. The privacy CA should include
the ﬁrmware identity C as an attribute in the endorsement
credential. Once the TPM process has a valid endorsement
certiﬁcate, the standard TCG protocols can be used to get
Attestation Identity Keys.
3.5
µTPM Software Support
The TCG Software Stack (TSS) has to be augmented to
deal with the externalized ﬁrmware.
It has to store the
disembedded ﬁrmware and load the appropriate TPM mi-
crocode (over the XIO port) before passing the command
parameters over the IO port. The integrity of this ﬁrmware is
protected by the µTPM’s authentication key kAuth, however
availability cannot be guaranteed. If the external ﬁrmware
gets deleted (purposely or involuntary), the corresponding
µTPM process becomes unusable. However this is not a big
concern as other denial of service attacks can be applied on
current TPMs (e.g., deleting part of the TSS or the TPM
driver), and TPMs were never meant to withstand a denial
of service attack.
Likewise, the CRTM (Core Root of Trust for Measure-
ment) has to store the code of a small number of TPM com-
mands used during the platform startup (e.g., TPM Extend).
The CRTM might use another non-volatile storage medium
(e.g., BIOS Flash memory). If the authenticated ﬁrmware
becomes inaccessible, the CRTM can choose to destroy the
121process or re-authenticate the missing microcode; both pre-
vent the chain of trust from being bypassed.
4. SECURITY COMPARISON
Our approach attempts to stick closely to the original
TPM attack model. Nevertheless, the exposure of the inter-
nal TPM data does create small diﬀerences, which in some
applications may require extra care to prevent an attack.
4.1 Denial of Service
In our system, the attacker can destroy the internal state
of the TPM, and even the command set; while it cannot be
replaced by something meaningful, such an attack may dis-
able the TPM or force a reset into its native state. This is a
stronger attack than possible on a normal TPM, where dele-
tion of external data can only destroy key material, but no
state information or functionality. We would argue though
that in practice, there is little diﬀerence between an attack
on a µTPM and an attack on a classical one; if a classical
TPM looses all key blobs, most crucial state information is
lost as well, and an application using this TPM needs to ﬁnd
a way to recover without opening other avenues of attack.
The only setting where a diﬀerence may occur is in a vir-
tualized environment; it must not be possible that one vir-
tual environment can destroy state information of the vir-
tual TPM of another one. This means that each virtual
TPM must have a local copy of its relevant state informa-
tion, and shared information must be stored by a trusted
program (e.g., the hypervisor), where it cannot be deleted
by individual virtual machines (some mechanism like this
would be required anyway to prevent the virtual machines
from disrupting each other).
4.2 Access analysis
While our µTPM implementation protects TPM data from
being read by an attacker, the attacker may be able to see
the encrypted internal state, or – for example, by analyz-
ing the cache of the µTPM or the untrusted storage – ob-
tain information about the last commands submitted to the
µTPM. While this does not endanger security in most set-
tings in which a TPM is used, this increased visibility should
be taken into account, and critical applications may need to
apply additional measures to hide the activity of the µTPM,
for example by adding fake encrypted state blocks and clear-
ing all caches after usage.
4.3 Vendor backdoor
For some implementations of code integrity measurement,
it is possible for the vendor to authorize TPM commands
that are invisible to the user (i.e., not supplied with the
original µTPM on delivery), but used later as a backdoor to
violate TPM security. Thus, in security settings where the
vendor is untrusted, the MAC based binary measurement
should be used rather than the one based on vendor signa-
tures, or the user should use their own veriﬁcation key when
the AssociateKey command is executed, and thus lock the
original vendor out of the TPM.
5. MEMORY EXTERNALIZATION
To allow for several independent processes to run on a
µTPM, and to minimize the amount of memory needed in-
side the µTPM, we require a mechanism that allows for ex-
ternalization of the NVM, and potentially even parts of the
RAM.
There are two major issues with externalized memory. For
one, the memory management may get more complex, espe-
cially if the memory is not suﬃcient for a single process. Sec-
ondly, externalized memory needs an additional protection
against replay attacks, i.e., an attacker presenting passing
an old memory block as a new one.
While we design our solutions to allow for an arbitrary
number of processes, realistically the number of processes
using a single µTPM is relatively low. The only use case we
see for a large number of processes is on a server with many
virtualized operating systems and a large number of applica-
tions; in this case, it is safe to assume that the manufacturer
would choose a µTPM with a large amount of internal mem-
ory and a fast communication bus. In other words, while we
do not want to set an upper limit on the number of pro-
cesses and their memory requirements, we are not trying to
build an architecture that scales eﬃciently to hundreds of
processes if the µTPM has only 1 kbit of memory.
5.1 Memory protection
Whenever memory is externalized to the insecure stor-
age, it needs to be encrypted and authenticated to protect
its conﬁdentiality and integrity. This can simply be done
by using a symmetric cipher in an authenticated encryption
mode such as EAX [1], GCM [10], and OCB [11]. To guar-
antee freshness, whenever externalized memory is updated,
the µTPM needs to make sure that all old versions of that
memory become unavailable. This is done by either adding
a counter value to the externalized memory, or changing the
memory authentication key every time that the memory is
updated. The former solution requires less storage in the
TPM, as one master key can be used for all processes, and
each memory block only needs a counter that can be much
shorter than a cryptographic key.
Ideally, if the amount of virtual memory is limited, the
list of counters ﬁts into the µTPM. If one wants to allow an
arbitrary number of processes, though, the protected NVM
may even be too small for all counter values. In this case,
the counter values themselves need to be externalized to in-
secure storage, and the freshness of the counters protected
by a master counter. Advanced tree-based solutions for the
management of a large number of counters exist [13]; how-
ever, we assume that the number of processes is relatively
low, and a simple list based approach suﬃces.
5.2 Memory management
In a simple setting, we can assume that each process has
its own NVM and RAM, which ﬁts completely into the
µTPM hardware; however, the size of the µTPM’s mem-
ory is insuﬃcient to simultaneously hold the memory of all
processes. Thus, swapping is only required when the pro-
cess is switched.
In this case, management of the exter-
nal memory is relatively simple – as an answer to a pro-
cess creation/switch command, the µTPM returns the (en-
crypted and authenticated) content of the current process,
and expects the content of the new one in return. This does
not necessarily need to be implemented in the µTPM hard-
ware itself; the process can handle the retrieval and clean-
ing of the memory itself (e.g., with the TPM SaveState and
TPM Startup command).
If the NVM or RAM needed for the process exceeds the
122available size of the hardware memory in the µTPM, exter-
nalization gets more complicated.
Ideally, one can design
complete virtual memory management and simulate page
faults as TPM responses to the µTSS. We do, however, feel
that this contradicts the principle of a minimized hardware
unit.
It is possible for the µTPM to communicate to the
µTSS during command execution by using error codes; the
µTPM is a passive device, hence error codes are the only
mechanism to signal the µTSSabout problems. This would
allow us to implement a function that can swap in and out
blocks of internal memory manually while commands are be-
ing processed. However, we do believe that this design is an
abuse of error codes, and that there is little need to support
single commands that exceed the capacity of the µTPM.
5.3 Memory availability
It should be noted that externalization of the NVM allows
for some new forms of denial of service attacks. While the
externalized ﬁrmware can easily be replaced if it got lost,
an attacker may be able to remove the externalized NVM
for good, and the only recovery from such an attack is the
reset of the µTPM to its default setting. While this attack
is not critical in most TPM usage scenarios – to execute
it, the attacker already requires a level of control over the
host platform that allows for many other ways of denial of
service attacks – this is an attack that is not possible for a
normal TPM, and some TPM based protocols may assume
it impossible.
One solution to this issue is for the µTPM to collabo-
rate with secure storage, as speciﬁed by the TCG Storage
Work Group [15]. In this case, the µTPM only releases its
internal memory once it receives an acknowledgement from
its counterpart in the hard disk that the memory content
has successfully been stored in a hard disk section that is
unavailable for the operating system.
6. CONCLUSION
We have shown that many of the current issues with TPM
implementations that stem from complexity and inﬂexibil-
ity can be overcome by redeﬁning the trust boundaries. By
putting the ﬁrmware outside of the secure hardware and se-
curing it cryptographically, our architecture allows for sim-
pliﬁed hardware, while gaining ﬂexibility in the supported
command set and even allowing multiple secure coproces-
sors to share the same hardware. Our architecture is largely
compatible with the current speciﬁcation, provided an ad-
ditional software layer between the classical TSS and the
µTPM; thus allowing for the improved architecture without
having to adapt the TCG speciﬁcation.
7. ACKNOWLEDGEMENTS
The authors would like to thank the anonymous reviewers
for their valuable comments.
This work was supported in part by the IAP Programme
P6/26 BCRYPT of the Belgian State (Belgian Science Pol-
icy), by the FWO project G.0300.07 (Security components
for trusted computer systems), by the IBBT QoE project,
and in part by the European Commission through the IST
Programme under Contract IST-027635 OPEN TC.
8. REFERENCES
[1] M. Bellare, P. Rogaway, and D. Wagner. The EAX
Mode of Operation. In B. K. Roy and W. Meier,
editors, Fast Software Encryption, 11th International
Workshop, FSE 2004, Delhi, India, February 5-7,
2004, Revised Papers, volume 3017 of Lecture Notes in
Computer Science, pages 389–407. Springer-Verlag,
2004.
[2] S. Berger, R. C´aceres, K. A. Goldman, R. Perez,
R. Sailer, and L. van Doorn. vTPM: Virtualizing the
Trusted Platform Module. In Proceedings of the 15th
USENIX Security Symposium, pages 21–21, Berkeley,
CA, USA, 2006. USENIX Association.
[3] BSI. Federal Government’s Comments on the TCG
and NGSCB in the Field of Trusted Computing.
http://www.bsi.bund.de/sichere_plattformen/
trustcomp/stellung/StellungnahmeTCG1_2a_e.pdf.
[4] B. Chevallier-Mames, D. Naccache, P. Paillier, and
D. Pointcheval. How to Disembed a Program? In
M. Joye and J.-J. Quisquater, editors, Cryptographic
Hardware and Embedded Systems - CHES 2004: 6th
International Workshop Cambridge, MA, USA,
August 11-13, 2004. Proceedings, volume 3156 of
Lecture Notes in Computer Science, pages 441–454.
Springer-Verlag, 2004.
[5] B. Chevallier-Mames, D. Naccache, P. Paillier, and
D. Pointcheval. How to Disembed a Program?
Cryptology ePrint Archive, Report 2004/138, 2004.
http://eprint.iacr.org/.
[6] V. Costan, L. F. G. Sarmenta, M. van Dijk, and
S. Devadas. The Trusted Execution Module:
Commodity General-Purpose Trusted Computing. In
G. Grimaud and F.-X. Standaert, editors, Smart Card
Research and Advanced Applications, 8th IFIP WG
8.8/11.2 International Conference, CARDIS 2008,
London, UK, September 8-11, 2008. Proceedings,
volume 5189 of Lecture Notes in Computer Science,
pages 133–148. Springer, 2008.
[7] K. Dietrich. An Integrated Architecture for Trusted
Computing for Java enabled Embedded Devices. In
2nd ACM workshop on Scalable Trusted Computing –
STC ’07, pages 2–6, New York, NY, USA, 2007. ACM.
[8] T. Eisenbarth, T. G¨uneysu, C. Paar, A.-R. Sadeghi,
D. Schellekens, and M. Wolf. Reconﬁgurable Trusted
Computing in Hardware. In 2nd ACM workshop on
Scalable Trusted Computing – STC ’07, pages 15–20,
New York, NY, USA, 2007. ACM.
[9] J.-E. Ekberg and M. Kyl¨anp¨a¨a. Mobile Trusted
Module (MTM) – an introduction, Nov. 2007. http:
//research.nokia.com/files/NRCTR2007015.pdf.
[10] D. A. McGrew and J. Viega. The Security and
Performance of the Galois/Counter Mode (GCM) of
Operation. In A. Canteaut and K. Viswanathan,
editors, Progress in Cryptology - INDOCRYPT 2004,
5th International Conference on Cryptology in India,
Chennai, India, December 20-22, 2004, Proceedings,
volume 3348 of Lecture Notes in Computer Science,
pages 343–355. Springer-Verlag, 2004.
[11] P. Rogaway, M. Bellare, and J. Black. OCB: A
Block-Cipher Mode of Operation for Eﬃcient
Authenticated Encryption. ACM Transactions on
Information and System Security, 6(3):365–403, 2003.
123[12] A.-R. Sadeghi, M. Selhorst, C. St¨uble, C. Wachsmann,
and M. Winandy. TCG inside?: A Note on TPM
Speciﬁcation Compliance. In 1st ACM workshop on
Scalable Trusted Computing – STC ’06, pages 47–56,
New York, NY, USA, 2006. ACM.
[13] L. F. G. Sarmenta, M. van Dijk, C. W. O’Donnell,
J. Rhodes, and S. Devadas. Virtual Monotonic
Counters and Count-Limited Objects using a TPM
without a Trusted OS. In 1st ACM workshop on
Scalable Trusted Computing – STC ’06, pages 27–42,
New York, NY, USA, 2006. ACM.
[14] H. Stamer and M. Strasser. A Software-Based Trusted
Platform Module Emulator. In P. Lipp, A.-R. Sadeghi,
and K.-M. Koch, editors, Trusted Computing -
Challenges and Applications, First International
Conference on Trusted Computing and Trust in
Information Technologies, Trust 2008, Villach,
Austria, March 11-12, 2008, Proceedings, volume 4968
of Lecture Notes in Computer Science, pages 33–47.
Springer, 2008.
[15] Trusted Computing Group. TCG Storage Architecture
Core Speciﬁcation. available at https:
//www.trustedcomputinggroup.org/specs/Storage/.
124