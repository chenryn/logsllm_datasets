when one view “fails,” another may succeed.
4 Evaluation
We evaluate our Fluorescence implementation by testing its
ability to identify VMs that are infected with kernel-resident
malware, picking those VMs out of a mostly healthy herd
of similarly conﬁgured VMs running Linux or Windows 7.
We focus on answering four questions. First, can Fluores-
cence correctly identify the VMs in the herd that are infected
with malware (§4.2)? In our experiments, the answer is yes:
Fluorescence accurately identiﬁed the infected VMs. We
discuss the performance of the autoencoder (§4.2.1) and clus-
tering (§4.2.2) detection methods. Second, is normalization
necessary and effective (§4.3)? We ﬁnd that the answer is
yes: our implemented normalization process can drastically
reduce the number of features that need to be considered
during anomaly detection, and it allows different classes of
VMs to be clustered for identiﬁcation. Third, what is the
run-time performance of ﬁngerprint generation (§4.4)? In
our experiments, ﬁngerprint generation takes 11–13 s, and the
monitored VM is paused for only 0.6 s. Fourth, how does
the run time of Fluorescence scale as the number of mon-
itored VMs increases (§4.5)? We ﬁnd that the run time of
Fluorescence is acceptable even for moderately sized herds:
Fluorescence can process a herd of 200 VMs in about an hour.
Larger herds can be handled by treating them as multiple sub-
herds, each analyzed by a separate instance of Fluorescence.
4.1 Experiment Setup
We deploy herds containing various numbers of VMs running
Linux or Windows. We use Xen 4.9 as the hypervisor and
run Ubuntu 16.04 within dom0. Each Linux VM runs (64-bit)
Ubuntu 16.04 as the guest, with Linux kernel version 4.4.0.
Each Windows VM runs (64-bit) Windows 7. Each VM is
conﬁgured with one virtual CPU and 1 GB RAM. The VMs
are distributed over twenty “d430” physical machines within
the Utah Emulab network testbed [43].4 Each d430 has two
2.4 GHz Intel Xeon E5-2630v3 8-core CPUs and 64 GB RAM.
Each VM-hosting machine runs an instance of the Fluores-
cence agent in its dom0. Fluorescence’s central server, which
performs feature alignment and anomaly detection, is located
on a separate d430 (hosting no VMs) that runs Ubuntu 16.04.
We collected samples of kernel-resident malware to use
in our experiments. We focus on malware that persists in
the kernel by injecting or modifying kernel code, because
that is the type of malware that Fluorescence is designed to
detect. For Windows, we collected samples of Pitou, Rovnix
(a.k.a. Cidox), ZeroAccess (a.k.a Sirefef), Win32/Gapz, and
two variants of TDSS known as TDL3 and TDL4. Some of
these have recently been active in the wild [41]. For Linux,
we collected three rootkit samples: Diamorphine [26], Nu-
rupo [29], and Reptile [1].
For experiments with Linux VMs, we conﬁgured Fluores-
cence to compute all three feature views of every page (§3.2).
For experiments with Windows VMs, we conﬁgured Fluo-
rescence to compute only the original and sub-base views.
We did this because the Windows 7 kernel uses Position In-
dependent Executables (PIE); as a result, most code pages
are unpatched by the kernel-loading process and are already
identical across VMs. We leave sub-base enabled in our Win-
dows 7 experiments to handle the small number of code pages
that do vary across loaded Windows 7 kernels.
4We used Emulab’s “experiment ﬁrewall” feature to block trafﬁc between
the VMs and the Internet.
374          22nd International Symposium on Research in Attacks, Intrusions and DefensesUSENIX AssociationFluorescence transfers VMs’ ﬁngerprints to its central
server for analysis. For the VMs described above, we found
that that size of a Windows VM ﬁngerprint was approxi-
mately 2.7 MB. A Linux VM ﬁngerprint was approximately
1.8 MB. These numbers compare favorably to prior work [3]
that collects and analyzes physical memory dumps.
4.2 Malware Detection
We performed a set of experiments to test Fluorescence’s
ability to identify the VMs in a herd that are infected with
kernel-resident malware. For each test, we set up the herd
as follows. We created 50 VMs, running either Windows
or Linux. To perturb the collection, we randomly selected
ten VMs, logged into them, and performed some activities
manually. On Windows, we opened some ﬁles, played some
small games, and/or used a web browser to download some
ﬁles. On Linux, we ran Apache or nginx and then downloaded
random ﬁles from those servers. We then randomly installed
malware on some of the VMs. For Windows, we chose a
subset of our six samples to inject (1–6 samples); for each
sample, randomly chose the number of instances to inject
(1–4); randomly chose the set of VMs to be infected (one VM
per instance); and then injected the samples. For Linux, we
followed the same process, injecting 1–3 rootkit types, with
1–4 instances each.
After setting up the herd, we ran Fluorescence to test its
ability to discover the infected VMs. For each herd con-
ﬁguration that we selected, we repeated the herd setup and
Fluorescence test ﬁve times to check for repeatability.
In every test we performed, Fluorescence identiﬁed the
infected VMs. The DBSCAN method always found the in-
fected VMs, without false positives or negatives, and properly
clustered the VMs that were infected with a common type
of malware. The autoencoder method was also accurate but
produced false positives at negatives when a large fraction of
the VMs were infected (as discussed below, §4.2.1).
Figure 4 explains this result. It visualizes S, the similarity
matrix (§2.3), for one of our tests involving all six of our
Windows malware samples. Each row represents a VM, and
each column represents a feature, i.e., a “matching page”
across the VMs. We sort the rows and columns for clarity
in the visualization. Each cell is colored according to its
value:
light cells contain high values (i.e., are similar to
the corresponding basis value) and dark cells contain low
values (are dissimilar to the corresponding basis value). In
the visualization, it is clear that the infected VMs present
distinct patterns in S, and each type of malware has a different
signature. These are the patterns that Fluorescence detects.
The ﬁgure is annotated to show the different malware families.
Figure 8 presents a similar visualization for one of our
Linux tests, one involving all three of our Linux rootkits.
Figure 4: Similarity matrix for an experiment involving 50 VMs
running Windows, many infected with malware. In this visualization,
higher similarity scores have lighter colors.
Figure 5: Error scores from the autoencoder-based analysis of an
example herd of 100 VMs, three of which are infected with malware.
The scores of the infected VMs (upper right) are ﬂagged because
they exceed a threshold, as determined by a conﬁdence interval.
4.2.1 Anomaly Detection with Autoencoder
We conducted another set of experiments to better character-
ize the performance of Fluorescence’s autoencoder-based
method for detecting anomalies. Recall that the autoen-
coder method calculates an error score for each monitored
VM (§2.3.1). It models the error score as a Gaussian dis-
tribution; if the error score of a VM lies outside a chosen
conﬁdence interval, Fluorescence ﬂags the VM as anomalous.
Figure 5 illustrates this idea. To generate this example, we
created and processed a ﬁngerprint set for 100 VMs, three of
which were infected with malware. We sorted the resulting
scores and plotted the results. The three points at the right
side of the ﬁgure, with scores above 0.20, correspond to the
infected VMs. For conﬁdence interval choices between 90%
0102030FeatureID01020304049VMIDPitouWin32/GapzZeroAccessRovnixAmixofTDL3andTDL4Uninfected020406080100The #th VM ordered by its anomaly score0.000.050.100.150.20Anomaly scoreconfidence interval: 90%confidence interval: 98%confidence interval: 99.8%USENIX Association        22nd International Symposium on Research in Attacks, Intrusions and Defenses 375Figure 6: Autoencoder performance, with 90% and 99.8% conﬁdence intervals, for different types of Windows kernel malware and rates of
infection in a herd of 100 VMs. Points represent averages over twenty trials.
and 99.8%, all of these VMs are reported to be anomalous,
and there are no false positives or negatives.
To perform a large set of experiments similar to the one
described above, we reused the ﬁngerprints of Windows VMs
that we collected during the experiments described in §4.2.
In each of these new experiments, we simulate a herd of
100 VMs by randomly selecting 100 ﬁngerprints from our
set of previously generated ﬁngerprints. Each experiment
involves one kind of Windows malware, and we vary the
number of infected VMs from zero to ten. (I.e., in each con-
ﬁguration, we choose 0–10 ﬁngerprints of VMs infected with
the chosen malware, and 90–100 ﬁngerprints of clean VMs.)
We then perform anomaly detection over the assembled herd,
using the autoencoder method, and record the number of false
positives and false negatives reported at the 90% and 99.8%
conﬁdence intervals. To account for randomness introduced
by the autoencoder—e.g., randomly initialized parameters—
we repeat the analysis of each herd twenty times. For each
herd, we compute and report the average false positive and
false negative rates over the twenty trials.
Figure 6 presents the results of these experiments. (Note
the varying ranges of the y-axes in the ﬁgure.) We make three
observations about this data. First, if the rate of anomalous
VMs was under 4%—a realistic threshold for large herds
in practice—the autoencoder detected all anomalies without
any false positives or false negatives. Second, when the rate
of anomalous VMs increases beyond 4%, the autoencoder
becomes less effective. Third, the higher conﬁdence inter-
val leads to more false negatives, but also to possibly fewer
false positives. This suggests an incremental strategy to main-
taining a herd: ﬁx reported VMs, thus lowering the rate of
infection, and then repeat analysis with Fluorescence. From
our experiments, we conclude that the autoencoder method
works well when few anomalies are present, which is likely
to be the case in practice. Despite its limitations, it is widely
applicable for detecting unknown anomalies.
4.2.2 Anomaly Detection with DBSCAN
We reuse the simulated herds described in §4.2.1 to test the
performance of Fluorescence’s clustering approach, utilizing
DBSCAN, for detecting anomalies. Recall that each herd is
Figure 7: Visualization of clusters found by DBSCAN within a herd
of 100 Windows VMs. Using principal component analysis (PCA),
the data for each VM was reduced to a 2D coordinate.
represented by the ﬁngerprints of 100 VMs with Windows 7
guests, where 0–10 of those guests have been infected by
one type of malware. In each of these tests, DBSCAN cor-
rectly partitioned the normal and infected VMs into separate
clusters, with no false positive or negatives.
To visualize the reason for DBSCAN’s success in our tests,
we simulated another herd of 100 Windows VMs. In this
herd, we included ﬁngerprints of VMs infected with all of our
Windows malware samples: four instances of each malware
sample, for a total of 24 infected VMs. We analyzed this
herd with Fluorescence—again, all the VMs were properly
classiﬁed and clustered by family—and obtained the simi-
larity matrix S for the herd. We used principal component
analysis (PCA) to reduce the number of features for each VM
to just two. Finally, we used the two values for each VM to
plot the VMs on the X-Y plane.
Figure 7 shows the result. Each color/shape represents
one cluster identiﬁed by DBSCAN. The green-dot and blue-
star clusters are relatively close to each other, but they are
identiﬁed as separate clusters, as shown in a zoom-in view.
The blue-star cluster has the greatest number of VMs among
0246810Percentage of anomalous VMs (%)0.00.51.01.52.02.53.0False positive rate (%)confidence interval: 90%PitouTDL3ZeroAccessRovnixWin32/GapzTDL40246810Percentage of anomalous VMs (%)051015202530False negative rate (%)confidence interval: 90%PitouTDL3ZeroAccessRovnixWin32/GapzTDL40246810Percentage of anomalous VMs (%)0.000.250.500.751.001.251.50False positive rate (%)confidence interval: 99.8%PitouTDL3ZeroAccessRovnixWin32/GapzTDL40246810Percentage of anomalous VMs (%)020406080100False negative rate (%)confidence interval: 99.8%PitouTDL3ZeroAccessRovnixWin32/GapzTDL4Principal component 1Principal component 2TDL3/4PitouUninfectedWin32/GapzZeroAccessRovnix376          22nd International Symposium on Research in Attacks, Intrusions and DefensesUSENIX AssociationStep
Pin kernel code pages
Copy kernel code pages
Compute kernel memory regions
Normalization
Hashing
Total
Windows 7 Linux
N/A
0.6
0.6
7.7
4.2
13.1
6.4
0.6
0.6
0.9
2.7
11.2
Table 2: Time (secs) to generate a ﬁngerprint. The VM being
ﬁngerprinted is paused only while pages are being copied (step 2).
clarity. The visualization makes the different groups of VMs
apparent; each has a pattern that Fluorescence detects.
We removed the sub-base and disassembly feature views
from the ﬁngerprints of this herd—leaving only hashes for
the original page contents—and analyzed the resulting ﬁn-
gerprints to produce another similarity matrix. Figure 9 visu-
alizes this result. (In Figure 9, low values are light and high
values are dark; this is the opposite of the convention used in
Figure 8.) Two things are immediately apparent. First, com-
pared to the original matrix, the number of features per VM
has increased by more than two orders of magnitude. This
happens because Fluorescence is no longer able to remove
content that is ubiquitous across the VMs; normalization is
necessary for ﬁnding such content and is very effective. Sec-
ond, the patterns that are so clear in Figure 8 are not apparent
in Figure 9. This suggests that Fluorescence would have a
difﬁcult time ﬁnding the malware-infected VMs in this data.
4.4 Fingerprint Generation Time
We measured the time needed for the Fluorescence agent to
produce the ﬁngerprint of a VM. We ran the ﬁngerprinting
procedure for a Windows VM and a Linux VM and recorded
the elapsed time for each step of the process. We repeated the
procedure ten times for each VM and computed the average
elapsed times over the trials. Table 2 presents our results.
The VM being ﬁngerprinted is paused only while Fluores-
cence copies its kernel code pages (§2.1). For both Windows 7
and Linux, the pause time is short, less than a second.
For Windows 7, the longest step is the one that uses
DRAKVUF to pin the kernel’s code pages into memory (§3.1).