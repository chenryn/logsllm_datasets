title:Fingerprinting the Fingerprinters: Learning to Detect Browser Fingerprinting
Behaviors
author:Umar Iqbal and
Steven Englehardt and
Zubair Shafiq
2021 IEEE Symposium on Security and Privacy (SP)
Fingerprinting the Fingerprinters:
Learning to Detect Browser Fingerprinting Behaviors
Umar Iqbal
The University of Iowa
Steven Englehardt
Mozilla Corporation
Zubair Shaﬁq
University of California, Davis
7
1
0
0
0
.
1
2
0
2
.
1
0
0
0
4
P
S
/
9
0
1
1
.
0
1
:
I
O
D
|
E
E
E
I
1
2
0
2
©
0
0
.
1
3
$
/
1
2
/
5
-
4
3
9
8
-
1
8
2
7
-
1
-
8
7
9
|
)
P
S
(
y
c
a
v
i
r
P
d
n
a
y
t
i
r
u
c
e
S
n
o
m
u
i
s
o
p
m
y
S
E
E
E
I
1
2
0
2
Abstract—Browser ﬁngerprinting is an invasive and opaque
stateless tracking technique. Browser vendors, academics, and
standards bodies have long struggled to provide meaningful
protections against browser ﬁngerprinting that are both ac-
curate and do not degrade user experience. We propose FP-
INSPECTOR, a machine learning based syntactic-semantic ap-
proach to accurately detect browser ﬁngerprinting. We show
that FP-INSPECTOR performs well, allowing us to detect 26%
more ﬁngerprinting scripts than the state-of-the-art. We show
that an API-level ﬁngerprinting countermeasure, built upon
FP-INSPECTOR, helps reduce website breakage by a factor of
2. We use FP-INSPECTOR to perform a measurement study
of browser ﬁngerprinting on top-100K websites. We ﬁnd that
browser ﬁngerprinting is now present on more than 10% of the
top-100K websites and over a quarter of the top-10K websites. We
also discover previously unreported uses of JavaScript APIs by
ﬁngerprinting scripts suggesting that they are looking to exploit
APIs in new and unexpected ways.
I. INTRODUCTION
Mainstream browsers have started to provide built-in protec-
tion against cross-site tracking. For example, Safari [19] now
blocks all third-party cookies and Firefox [95] blocks third-
party cookies from known trackers by default. As mainstream
browsers implement countermeasures against stateful tracking,
there are concerns that it will encourage trackers to migrate
to more opaque, stateless tracking techniques such as browser
ﬁngerprinting [83]. Thus, mainstream browsers have started to
explore mitigations for browser ﬁngerprinting.
Some browsers and privacy tools have tried to mitigate
browser ﬁngerprinting by changing the JavaScript API surface
exposed by browsers to the web. For example, privacy-oriented
browsers such as the Tor Browser [32], [64] have restricted
access to APIs such as Canvas and WebRTC, that are known
to be abused for browser ﬁngerprinting. However, such blanket
API restriction has the side effect of breaking websites that use
these APIs to implement benign functionality.
Mainstream browsers have so far avoided deployment of
comprehensive API restrictions due to website breakage con-
cerns. As an alternative, some browsers—Firefox in partic-
ular [52]—have tried to mitigate browser ﬁngerprinting by
blocking network requests to browser ﬁngerprinting services
[12]. However, this approach relies heavily on manual analysis
and struggles to restrict ﬁngerprinting scripts that are served
from ﬁrst-party domains or dual-purpose third parties, such
as CDNs. Englehardt and Narayanan [54] manually designed
heuristics to detect ﬁngerprinting scripts based on their exe-
cution behavior. However, this approach relies on hard-coded
heuristics that are narrowly deﬁned to avoid false positives and
must be continually updated to capture evolving ﬁngerprinting
and non-ﬁngerprinting behaviors.
We propose FP-INSPECTOR, a machine learning based
approach to detect browser ﬁngerprinting. FP-INSPECTOR
trains classiﬁers to learn ﬁngerprinting behaviors by extracting
syntactic and semantic features through a combination of static
and dynamic analysis that complement each others’ limita-
tions. More speciﬁcally, static analysis helps FP-INSPECTOR
overcome the coverage issues of dynamic analysis, while
dynamic analysis overcomes the inability of static analysis to
handle obfuscation.
Our evaluation shows that FP-INSPECTOR detects ﬁn-
gerprinting scripts with 99.9% accuracy. We ﬁnd that FP-
INSPECTOR detects 26% more ﬁngerprinting scripts than
manually designed heuristics [54]. Our evaluation shows that
FP-INSPECTOR helps signiﬁcantly reduce website breakage.
We ﬁnd that
leverage FP-
INSPECTOR’s detection reduce breakage by a factor 2 on
websites that are particularly prone to breakage.
targeted countermeasures that
We deploy FP-INSPECTOR to analyze the state of browser
ﬁngerprinting on the web. We ﬁnd that ﬁngerprinting preva-
lence has increased over the years [37], [54], and is now
present on 10.18% of the Alexa top-100K websites. We detect
ﬁngerprinting scripts served from more than two thousand
domains, which include both anti-ad fraud vendors as well
as cross-site trackers. FP-INSPECTOR also helps us uncover
several new APIs that were previously not known to be
used for ﬁngerprinting. We discover that ﬁngerprinting scripts
disproportionately use APIs such as the Permissions and
Performance APIs.
We summarize our key contributions as follows:
1) An ML-based syntactic-semantic approach to detect
browser ﬁngerprinting behaviors by incorporating both
static and dynamic analysis.
2) An evaluation of website breakage caused by differ-
ent mitigation strategies that block network requests or
restrict APIs.
3) A measurement study of browser ﬁngerprinting scripts
on the Alexa top-100K websites.
4) A clustering analysis of JavaScript APIs to uncover
new browser ﬁngerprinting vectors.
Paper Organization: The rest of the paper proceeds as follows.
Section II presents an overview of browser ﬁngerprinting and
limitations of existing countermeasures. Section III describes
the design and implementation of FP-INSPECTOR. Section
IV presents the evaluation of FP-INSPECTOR’s accuracy and
© 2021, Umar Iqbal. Under license to IEEE.
DOI 10.1109/SP40001.2021.00017
1143
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:15:55 UTC from IEEE Xplore.  Restrictions apply. 
website breakage. Section V describes FP-INSPECTOR’s de-
ployment on Alexa top-100K websites. Section VI presents
the analysis of JavaScript APIs used by ﬁngerprinting scripts.
Section VII describes FP-INSPECTOR’s limitations. Section
VIII concludes the paper.
II. BACKGROUND & RELATED WORK
Browser ﬁngerprinting for online tracking. Browser ﬁn-
gerprinting is a stateless tracking technique that uses device
conﬁguration information exposed by the browser through
JavaScript APIs (e.g., Canvas) and HTTP headers (e.g.,
User-Agent). In contrast to traditional stateful tracking,
browser ﬁngerprinting is stateless—the tracker does not need
to store any client-side information (e.g., unique identiﬁers
in cookies or local storage). Browser ﬁngerprinting is widely
recognized by browser vendors [2], [7], [20] and standards
bodies [33], [76] as an abusive practice. Browser ﬁngerprinting
is more intrusive than cookie-based tracking for two reasons:
(1) while cookies are observable in the browser, browser
ﬁngerprints are opaque to users; (2) while users can control
cookies (e.g., disable third-party cookies or delete cookies alto-
gether), they have no such control over browser ﬁngerprinting.
Browser ﬁngerprinting is widely known to be used for
bot detection purposes [23], [49], [70], [73], including by
Google’s reCAPTCHA [44], [86] and during general web
authentication [40], [65]. However, there are concerns that
browser ﬁngerprinting may be used for cross-site tracking
especially as mainstream browsers such as Safari [94] and
Firefox [95] adopt aggressive policies against third-party cook-
ies [83]. For example, browser ﬁngerprints (by themselves or
when combined with IP address) [66] can be used to regenerate
or de-duplicate cookies [30], [85]. In fact, as we show later,
browser ﬁngerprinting is used for both anti-fraud and potential
cross-site tracking.
Origins of browser ﬁngerprinting. Mayer
[71] ﬁrst
showed that “quirkiness” can be exploited using JavaScript
APIs (e.g., navigator, screen, Plugin, and MimeType ob-
jects) to identify users. Later, Eckersley [51] conducted the
Panopticlick experiment to analyze browser ﬁngerprints using
information from various HTTP headers and JavaScript APIs.
As modern web browsers have continued to add functionality
through new JavaScript APIs [88], the browser’s ﬁngerprinting
surface has continued to expand. For example, researchers
have shown that Canvas [72], WebGL [45], [72], fonts
[56], extensions [90], the Audio API [54], the Battery
Status API [77], and even mobile sensors [47] can expose
identifying device information that can be used to build a
browser ﬁngerprint. In fact, many of these APIs have already
been found to be abused in the wild [37], [38], [47], [54],
[75], [78]. Due to these concerns, standards bodies such as
the W3C [34] have provided guidance to take into account the
ﬁngerprinting potential of newly proposed JavaScript APIs.
One such example is the Battery Status API, which was
deprecated by Firefox due to privacy concerns [78].
Does browser ﬁngerprinting provide unique and per-
sistent identiﬁers? A browser ﬁngerprint is a “statistical”
identiﬁer, meaning that it does not deterministically identify
a device. Instead, the identiﬁability of a device depends on
the number of devices that share the same conﬁguration. Past
research has reported widely varying statistics on the unique-
ness of browser ﬁngerprints. Early research by Laperdrix et
al. [67] and Eckersley [51] found that 83% to 90% of devices
have a unique ﬁngerprint. In particular, Laperdrix et al. found
that desktop browser ﬁngerprints are more unique (90% of
devices) than mobile (81% of devices) due to the presence
of plugins and extensions. However, both Eckersley’s and
Laperdrix’s studies are based on data collected from self-
selected audiences—visitors to Panopticlick and AmIUnique,
respectively—which may bias their ﬁndings. In a more recent
study, Boix et al. [59] deployed browser ﬁngerprinting code
on a major French publisher’s website. They found that only
33.6% of the devices in that sample have unique ﬁngerprints.
However, they argued that adding other properties, such as
the IP address, Content language or Timezone, may make the
ﬁngerprint unique.
To be used as a tracking identiﬁer, a browser ﬁngerprint
must either remain stable over time or be linkable with
relatively high conﬁdence. Eckersley measured repeat visits to
the Panopticlick test page and found that 37% of repeat visitors
had more than one ﬁngerprint [51]. However, about 65% of
devices could be re-identiﬁed by linking ﬁngerprints using a
simple heuristic. Similarly, Vastel et al. [93] found that half
of the repeat visits to the AmIUnique test page change their
ﬁngerprints in less than 5 days. They improve on Eckersley’s
linking heuristic and show that their linking technique can
track repeat AmIUnique visitors for an average of 74 days.
Prevalence of browser ﬁngerprinting. A 2013 study of
browser ﬁngerprinting in the wild [75] examined three ﬁn-
gerprinting companies and found only 40 of the Alexa top-
10K websites deploying ﬁngerprinting techniques. That same
year, a large-scale study by Acar et al. [38] found just 404
of the Alexa top 1-million websites deploying ﬁngerprinting
techniques. Following that, a number of studies have measured
the deployment of ﬁngerprinting across the web [37], [47],
[54], [78]. Although these studies use different methods to ﬁn-
gerprinting, their results suggest an overall trend of increased
ﬁngerprinting deployment. Most recently, an October 2019
study by The Washington Post [58] found ﬁngerprinting on
about 37% of the Alexa top-500 US websites. This roughly
aligns with our ﬁndings in Section V, where we discover
ﬁngerprinting scripts on 30.60% of the Alexa top-1K websites.
Despite increased scrutiny by browser vendors and the public
in general, ﬁngerprinting continues to be prevalent.
Browser ﬁngerprinting countermeasures. Existing tools
for ﬁngerprinting protection broadly use three different ap-
proaches.1 One approach randomizes return values of the
JavaScript APIs that can be ﬁngerprinted, the second nor-
1Google has recently proposed a new approach to ﬁngerprinting protection
that doesn’t fall into the categories discussed above. They propose assigning a
“privacy cost” based on the entropy exposed by each API access and enforcing
a “privacy budget” across all API accesses from a given origin [7]. Since this
proposal is only at the ideation stage and does not have any implementations,
we do not discuss it further.
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:15:55 UTC from IEEE Xplore.  Restrictions apply. 
1144
malizes the return values of the JavaScript APIs that can be
ﬁngerprinted, and the third uses heuristics to detect and block
ﬁngerprinting scripts. All of these approaches have different
strengths and weaknesses. Some approaches protect against
active ﬁngerprinting, i.e. scripts that probe for device proper-
ties such as the installed fonts, and others protect against pas-
sive ﬁngerprinting, i.e. servers that collect information that’s
readily included in web requests, such as the User-Agent
request header. Randomization and normalization approaches
can defend against all forms of active ﬁngerprinting and some
forms of passive (e.g., by randomizing User-Agent request
header). Heuristic-based approaches can defend against both
active and passive ﬁngerprinting, e.g., by completely blocking
the network request to resource that ﬁngerprints. We further
discuss these approaches and list their limitations.
1) The randomization approaches, such as Canvas Defender
[5], randomize the return values of the APIs such as
Canvas by adding noise to them. These approaches
not only impact the functional use case of APIs but are
also ineffective at restricting ﬁngerprinting as they are re-
versible [92]. Additionally, the noised outputs themselves
can sometimes serve as a ﬁngerprint, allowing websites to