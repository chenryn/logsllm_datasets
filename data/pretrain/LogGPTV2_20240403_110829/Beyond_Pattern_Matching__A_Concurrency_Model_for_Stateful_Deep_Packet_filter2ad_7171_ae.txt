ously in the literature, with initial efforts focusing on multi-system
setups for sharing the load.
[36, 49] focus on efﬁciently partitioning trafﬁc by ﬂow, and there-
fore lack the notion of analysis-speciﬁc scope. [30] has the notion
of a scheduler that separates the trafﬁc into independent subsets
based on event spaces, manually deﬁned by the IDS operator. The
semantics of event spaces are limited in expressiveness, and ori-
ented to statically deﬁning speciﬁc contexts (e.g., a speciﬁc subnet)
more than scopes. Moreover, the authors only consider signature-
based detection. [31] discusses an IDS load-balancer that dynam-
ically groups ﬂows based on the similarity of header ﬁelds (e.g.,
source address, port). While this approach is simple, such heuristic
correlation is not guaranteed to match the actual detector’s scope.
Other cluster-based approaches are [23, 40], which are built on a
more traditional concurrency model (intra-node synchronization)
and, as [30, 31], do not tackle parallelism within multi-core nodes.
There is another body of work (e.g., [28, 41, 43, 44]) on ac-
celerating packet matching on parallel hardware, including GPUs.
These approaches are restricted to byte-level pattern matching; while
this makes parallelization straightforward—as there is just a single,
static scope—it severely limits detection capabilities. In contrast,
our work aims to parallelize arbitrary stateful analyses.
The work closest to our discussion is [37], which presents a par-
allel IDS design for multi-core architectures. The system incorpo-
rates the notion of per-handler scope; however, scopes need to be
manually deﬁned for each analysis, and they are still limited to sets
of protocol header ﬁelds. Our work can be seen as an extension of
those, presenting a concurrency model which is independent from
the speciﬁcs of the analysis and automatically derives the paral-
lelization strategy.
Variations of scope-based parallelization have been deﬁned out-
side the realm of intrusion detection. Our approach is inspired by
serialization sets [14], a generic parallel programming paradigm.
In serialization sets, each shared object is associated with a seri-
alizer method, which returns an object-speciﬁc key. The runtime
uses the key to serialize computations that access the same shared
object. Our work adapts this approach to the event-driven paradigm
typical of packet processing and contributes efﬁcient scheduling al-
gorithms. Moreover, since our approach is domain-speciﬁc to IDSs
we can leverage the common structure of IDS programs to compute
scheduling functions automatically, without developer interaction.
The networking community has also contributed models aimed
at parallel packet processing. [25] describes a parallel stateful packet
processing system, where a set of processing blocks are composed
in a data ﬂow graph. The system supports a context-ordered mode
Scandetect program text void SignatureMatch (Signature s) {   if (cid:383)s(cid:348)id (cid:688)(cid:688) (cid:361)http-req(cid:362) (cid:374)(cid:374) s(cid:348)id (cid:688)(cid:688) (cid:361)non-http-req(cid:362)(cid:384)(cid:391)     if (s.c.id.orig_h in alarmTable) return;     if (s.c.id.orig_h in hostTable) {       State t = hostTable[s.c.id.orig_h];       if (s.c.id.resp_h in t.dests) {         t.dests[s.c.id.resp_h] += 1;         if (t.dests[s.c.id.resp_h] > v_threshold) {           report_v_scan(s.c.id.orig_h);           alarmTable.add(s.c.id.orig_h);         }       } else {         t.dests[s.c.id.res_h] = 1;         if (len(t.dests) > h_threshold) {           report_h_scan(s.c.id.orig_h);           alarmTable.add(s.c.id.orig_h);         }       }     } else hostTable[s.c.id.resp_h]=CreateEntry();   } }  Scandetect scheduling function void SF(Signature s)      return s.c.id.orig_h; Flowbytes program text void NewPacket(connection c,                packetHeader p) {   int len = c.ip.len;    if (c.ip.p != TCP && c.ip.p != UDP)     return;    if (c.uid in flowTable)     len += flowTable[c.uid];   flowTable[c.uid] = len;    if (len > threshold)       report_flow(c.uid); }   Flowbytes scheduling function void SF (connection c)      return c.uid;  Multistep program text void ProtocolConfirmation(connection c, int proto){   if (proto == SSH && c.id.resp_p == 2222/tcp            && c.id.resp_h == local_subnet) {     if (c.id.resp_h !in hostTable)       hostTable[c.id.resp_h] = CreateEntry(c);   }   else if (proto == IRC &&            c.id.orig_h == local_subnet) {     if (c.id.orig_h in hostTable) {       if (hostTable[c.id.orig_h].state == WAIT_IRC)         report_host(c.id.orig_h);     }   } }  Multistep scheduling function void SF(connection c, int proto) {   if (proto == SSH && c.id.resp_p == 2222/tcp       && c.id.resp_h == local_subnet) {       return c.id.resp_h;   }  else return c.id.orig_h; } (a) (b) (c) where logical blocks can be parallelized by applying serializers
(termed context-designator) to the input stream. The rigid orga-
nization of processing in a pipeline makes the system more suited
to trafﬁc processing/shaping than intrusion detection; moreover, the
developer is still required to manually specify serializers. [24] out-
lines an approach to state manipulation, with the goal of simplify-
ing dynamic provision/consolidation of network appliances. State
is divided in independent units using keys, i.e., combinations of pro-
tocol header ﬁelds. Our deﬁnition of scheduling functions can be
seen as a generalization of this approach to state partitioning. [26]
focuses on mapping IDS workloads to a set of distributed network
nodes. Trafﬁc partitioning is static, similarly to [30], and based on
ofﬂine workload estimates. [22] presents a parallel software router
that optimizes the whole system stack for its speciﬁc application,
yet does not easily generalize to other types of processing. [21]
performs analysis of a pipelined software router using symbolic
execution to derive the semantics of each component, while we use
static analysis to generate precise executable slices.
The literature also presents a number of general-purpose pro-
gramming APIs that take different approaches to parallelization
(e.g., [3, 4, 17]). Our approach does not strive to be a general
layer; instead, limiting the scope to event-driven packet processing
enables us to keep the programming model simple and hide con-
currency issues from the programmer. Architecture-speciﬁc paral-
lel APIs such as CUDA [2] require signiﬁcant application-speciﬁc
effort because of their restricted computational paradigm.
Historically, the HPC community has also investigated the prob-
lem of compiler-based automatic parallelization. This line of work
targets scientiﬁc and numerical computations (see for example [13,
15, 32, 33] and Chapter 11 of [12]). Target workloads typically in-
volve repetitive operations over large arrays; therefore, approaches
focus on loop vectorization and parallelization. More recently, sim-
ilar techniques have been proposed for batch processing workloads
such as compression, machine learning, and text processing [42,
50]. Our work is similar in spirit, as it strives to exploit domain-
speciﬁc program features to extract parallelization. However, IDS
programs present different requirements (real-time stream process-
ing), for which we leverage different program features (state and
computation structured around scopes).
Furthermore, [46] proposes the use of program slicing to parti-
tion a sequential program into parallel slices. This approach uses
slicing to determine instruction- and task-level parallelism. Con-
versely, we use it to infer high-level properties of the program (its
scope), which enable extensive data-level parallelism.
Finally, Parcae [34] and Varuna [39] optimize parallel execution
of multi-threaded programs according to various metrics (time, re-
source consumption). We see these works as orthogonal, as they
could be used to ﬁne-tune the degree of parallelism in our approach.
9. CONCLUSION
Trafﬁc processing presents numerous opportunities for parallelism,
but making IDS scalable and ﬂexible remains notoriously difﬁcult.
In this paper, we propose a domain-speciﬁc concurrency model that
can support a large class of IDS analyses without being tied to a
speciﬁc detection strategy. Our technique partitions the stream of
network events into subsets that the IDS can process independently
and in parallel, while ensuring that each subset contains all events
relevant to a detection scenario. Our partitioning scheme is based
on the concept of detection scope, i.e., the minimum “slice” of traf-
ﬁc that a detector needs to observe in order to perform its func-
tion. As this concept has general applicability, our model can sup-
port both simple, per-ﬂow detection schemes (e.g., pattern/signa-
ture matching) and more complex, high-level detectors. Moreover,
we show that it is possible to use program analysis to determine the
appropriate trafﬁc partitioning automatically and at compile-time,
and enforce it at run-time with a specialized scheduler.
Initial results are promising, and show that indeed our approach
correctly partitions existing sequential IDS analyses without loss
of accuracy, while exploiting the network trafﬁc’s inherent concur-
rency potential for throughput improvements.
Acknowledgments
We thank Drew Davidson, Mohan Dhawan, Aaron Gember-Jacobson,
Bill Harris, and Matthias Vallentin for their suggestions, which
greatly contributed to the paper. Likewise we thank the anonymous
reviewers and our shepherd Michalis Polychronakis.
This work was supported by the US National Science Foundation
under grants CNS-0915667, CNS-1228782 and CNS-1228792, and
by a grant from the Cisco Research Center. Any opinions, ﬁndings,
and conclusions or recommendations expressed in this material are
those of the authors or originators, and do not necessarily reﬂect
the views of the sponsors.
10. REFERENCES
[1] Bro hands-on workshop 2009.
http://www-old.bro-ids.org/bro-workshop-2009-2/, Feb.
2013.
[2] NVIDIA CUDA.
http://www.nvidia.com/object/cuda_home_new.html, Jan.
2013.
[3] OpenMP. http://openmp.org, Jan. 2013.
[4] Threading Building Blocks.
http://threadingbuildingblocks.org/, Jan. 2013.
[5] AMD Opteron 6300 series processors.
http://www.amd.com/en-us/products/server/6000/6300#,
May 2014.
[6] Bro IDS. http://www.bro-ids.org/, May 2014.
[7] Checkpoint security - tales from the crypter.
http://www.checkpoint.com/threatcloud-
central/articles/2014-01-20-Thwarting-Malware-
Obfuscation.html, May 2014.
[8] Errata security: Fun with IDS funtime #3: heartbleed.
http://blog.erratasec.com/2014/04/fun-with-ids-funtime-3-
heartbleed.html, May 2014.
[9] Intel Xeon processor e5-4657l v2.
http://ark.intel.com/products/75290/Intel-Xeon-Processor-
E5-4657L-v2-30M-Cache-2_40-GHz, May 2014.
[10] Snort IDS. http://www.snort.org/, May 2014.
[11] Suricata IDS. http://suricata-ids.org/, May 2014.
[12] A. V. Aho, M. S. Lam, R. Sethi, and J. D. Ullman.
Compilers: Principles, Techniques, and Tools.
Addison-Wesley Longman Publishing Co., Inc., Boston,
MA, USA, 2006.
[13] F. Allen, M. Burke, P. Charles, R. Cytron, and J. Ferrante. An
overview of the PTRAN analysis system for multiprocessing.
In ICS, 1987.
[14] M. D. Allen, S. Sridharan, and G. S. Sohi. Serialization sets:
a dynamic dependence-based parallel execution model. In
PPoPP, 2009.
[15] R. Allen and K. Kennedy. Automatic translation of
FORTRAN programs to vector form. ACM Toplas,
9(4):491–542, 1987.
[16] T. Benson, A. Akella, and D. A. Maltz. Network trafﬁc
characteristics of data centers in the wild. In IMC, 2010.
[17] R. D. Blumofe, C. F. Joerg, B. C. Kuszmaul, C. E. Leiserson,
K. H. Randall, and Y. Zhou. Cilk: an efﬁcient multithreaded
runtime system. In PPoPP, 1995.
[18] S. Bodmer, D. M. Kilger, G. Carpenter, and J. Jones. Reverse
Deception: Organized Cyber Threat Counter-Exploitation.
McGraw-Hill Osborne Media, 1st edition, July 2012.
[19] K. Borders, J. Springer, and M. Burnside. Chimera: a
declarative language for streaming network trafﬁc analysis.
In USENIX, 2012.
[20] R. Cytron, J. Ferrante, B. K. Rosen, M. N. Wegman, and
F. K. Zadeck. Efﬁciently computing static single assignment
form and the control dependence graph. ACM Toplas,
13(4):451–490, 1991.
[21] M. Dobrescu and K. Argyraki. Software dataplane
veriﬁcation. In NSDI, 2014.
[22] K. Fall, G. Iannaccone, M. Manesh, S. Ratnasamy,
K. Argyraki, M. Dobrescu, and N. Egi. RouteBricks:
enabling general purpose network infrastructure. ACM
SIGOPS Operating Systems Review, 45(1):112–125, 2011.
[23] L. Foschini, A. V. Thapliyal, L. Cavallaro, C. Kruegel, and
G. Vigna. A parallel architecture for stateful, high-speed
intrusion detection. In ICISS, 2008.
[24] A. Gember, P. Prabhu, Z. Ghadiyali, and A. Akella. Toward
software-deﬁned middlebox networking. In HotNets, 2012.
[25] H. Gill, D. Lin, T. Kothari, and B. T. Loo. Declarative
multicore programming of software-based stateful packet
processing. In DAMP, 2012.
[26] V. Heorhiadi, M. K. Reiter, and V. Sekar. New opportunities
for load balancing in network-wide intrusion detection
systems. In CoNEXT, 2012.
[27] S. Horwitz, T. Reps, and D. Binkley. Interprocedural slicing
using dependence graphs. ACM TOPLAS, 12(1):26–60, 1990.
[28] M. A. Jamshed, J. Lee, S. Moon, I. Yun, D. Kim, S. Lee,
Y. Yi, and K. Park. Kargus: a highly-scalable software-based
intrusion detection system. In CCS, 2012.
[29] S. Kornexl, V. Paxson, H. Dreger, A. Feldmann, and
R. Sommer. Building a time machine for efﬁcient recording
and retrieval of high-volume network trafﬁc. In IMC, 2005.
[30] C. Kruegel, F. Valeur, G. Vigna, and R. Kemmerer. Stateful
intrusion detection for high-speed networks. In IEEE S&P,
2002.
[31] A. Le, R. Boutaba, and E. Al-Shaer. Correlation-based load
balancing for network intrusion detection and prevention
systems. In SECURECOMM, 2008.
[32] K. McKinley. Automatic and Interactive Parallelization. PhD
thesis, Rice University, Apr. 1992.
[33] D. A. Padua and M. J. Wolfe. Advanced compiler
optimizations for supercomputers. Commun. ACM,
29(12):1184–1201, Dec. 1986.
[34] A. Raman, A. Zaks, J. W. Lee, and D. I. August. Parcae: a
system for ﬂexible parallel execution. In PLDI, 2012.
[35] T. Reps and G. Rosay. Precise interprocedural chopping. In
SIGSOFT, 1995.
[36] L. Schaelicke, K. Wheeler, and C. Freeland. SPANIDS: a
scalable network intrusion detection loadbalancer. In
Computing Frontiers, 2005.
[37] R. Sommer, V. Paxson, and N. Weaver. An architecture for
exploiting multi-core processors to parallelize network
intrusion prevention. Concurr. Comput. : Pract. Exper.,
21(10):1255–1279, July 2009.
[38] R. Sommer, M. Vallentin, L. De Carli, and V. Paxson. HILTI:
An abstract execution environment for deep, stateful network
trafﬁc analysis. In IMC, 2014.
[39] S. Sridharan, G. Gupta, and G. S. Sohi. Adaptive, efﬁcient,
parallel execution of parallel programs. In PLDI, 2014.
[40] M. Vallentin, R. Sommer, J. Lee, C. Leres, V. Paxson, and
B. Tierney. The NIDS cluster: scalable, stateful network
intrusion detection on commodity hardware. In RAID, 2007.
[41] J. van Lunteren and A. Guanella. Hardware-accelerated
regular expression matching at multiple tens of gb/s. In
INFOCOM, 2012.
[42] H. Vandierendonck, S. Rul, and K. De Bosschere. The
paralax infrastructure: automatic parallelization with a
helping hand. In PACT, 2010.
[43] G. Vasiliadis, S. Antonatos, M. Polychronakis, E. P.
Markatos, and S. Ioannidis. Gnort: High performance
network intrusion detection using graphics processors. In
RAID, 2008.
[44] G. Vasiliadis, M. Polychronakis, and S. Ioannidis. MIDeA: a
multi-parallel intrusion detection architecture. In CCS, 2011.
[45] J. Verdu, M. Nemirovsky, and M. Valero. MultiLayer
processing - an execution model for parallel stateful packet
processing. In ANCS, 2008.
[46] C. Wang, Y. Wu, E. Borin, S. Hu, W. Liu, D. Sager, T.-f.
Ngai, and J. Fang. Dynamic parallelization of single-threaded
binary programs using speculative slicing. In ICS, 2009.
[47] M. Weiser. Program slicing. In ICSE, 1981.
[48] B. Wun, P. Crowley, and A. Raghunth. Parallelization of
snort on a multi-core platform. In ANCS, 2009.
[49] K. Xinidis, I. Charitakis, S. Antonatos, K. G. Anagnostakis,
and E. P. Markatos. An active splitter architecture for
intrusion detection and prevention. IEEE Trans. Dependable
Secur. Comput., 3(1):31–44, Jan. 2006.
[50] H. Zhong, M. Mehrara, S. Lieberman, and S. Mahlke.
Uncovering hidden loop level parallelism in sequential
applications. In HPCA, 2008.