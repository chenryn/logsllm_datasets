### System Reliability and Anomaly Testing

In the final five minutes of our testing, we first evaluated the system's reliability by running it continuously for seven hours, during which no anomalies were detected. During this period, two false positive instances, each lasting 10 minutes, were recorded. We then conducted manipulations of the actuators within the system. The summary of the tested anomalies is provided in Table 4, where we replicated anomalies from the WADI dataset.

While these anomalies were occurring, we also initiated unconstrained concealment attacks on the WADI testbed to evaluate their feasibility and effectiveness. Both iterative and learning-based approaches were tested in real-time by simulating sensor value manipulations performed by an attacker. All instances of the anomalies were successfully misclassified. The results of the iterative and learning-based attacks are summarized in the last two columns of Table 4. Notably, our learning-based modifications took an average of 5 milliseconds (ms) to compute, which is significantly faster than the system's sampling rate.

### Related Work

#### Anomaly Detection in Cyber-Physical Systems (CPS)

Detecting stealthy attacks in CPS through process-based anomaly identification without requiring a detailed physical model is an active area of research. Hadžiosmanović et al. [23] use an autoregressive model on time series data extracted from Modbus PLC traffic, evaluating their approach using data from two water treatment plants. Krotofil et al. [34] employ a theoretical information approach to detect sensor spoofing attacks, while Aoudi et al. [4] use model-free techniques based on singular spectrum analysis to identify structural changes in process behavior. In the context of autonomous vehicles, control-based techniques such as Control Invariant [13] and Extended Kalman Filters [7, 45] have been found vulnerable to various stealthy attacks [15, 45, 48].

Additionally, several proposals in this field utilize deep learning techniques, typically by training a model on data gathered during normal operation and statistically comparing sensor readings with the model's predictions at runtime. Wickramasinghe et al. [60] provide an overview of how deep learning can be applied to CPS security. Goh et al. [20] propose an architecture for anomaly detection in a water treatment testbed, using a Recurrent Neural Network (LSTM-RNN) to predict sensor readings and CUSUM to compute the difference between predicted and actual readings. Kravchik et al. [32] suggest using a convolutional neural network for one-step prediction, while Taormina et al. [51] propose an autoencoder-based detector (the target of our attacks). Our approach is the first to systematically model a constrained attacker and identify vulnerabilities that affect detector performance, enabling the attacker to hide physical anomalies that would otherwise be detected. Our experiments demonstrate the feasibility and real-time application of these attacks, rendering prior anomaly detectors ineffective.

#### Adversarial Learning for Classifier Evasion

The effectiveness of adversarial machine learning in evading ML-based classifiers has been demonstrated across various applications, including face recognition [47], voice recognition [62], and malware detection [61]. Table 5 categorizes recent techniques based on the adversary's knowledge of the classifier's algorithm and training dataset. In the iterative scenario, where the adversary has full knowledge of the trained model and training set, Rndic and Laskov [58] present a case study on evading PDFRate, a malicious PDF detector, using a white-box gradient-based evasion method, comparing it to a black-box mimicry attack. Following the seminal paper demonstrating the existence of adversarial examples for neural networks [50], Goodfellow et al. [21] study the cause of these examples and develop a fast gradient method for adversarial perturbations, demonstrating their results in image classification under a perfect-knowledge iterative scenario. Carlini and Wagner [10] defeat a defensive technique known as defensive distillation [44], and white-box techniques have been applied to evade face recognition systems, even through physical object perturbations [47].

In more restrictive scenarios, the adversary only knows the general structure of the model and feature extraction methods. Papernot et al. [43] use this imperfect knowledge to build a surrogate model and demonstrate its effectiveness in source-target misclassification (image recognition). Grosse et al. [22] generalize the adversarial example crafting algorithm to malware detection systems. In other cases, the adversary queries the system under attack as an oracle, such as in attacks against proprietary online learning systems. Xu et al. [61] leverage the classification score output to build a genetic algorithm that morphs adversarial examples into undetected ones. Dang et al. [14] lift the assumption of knowing the classification score, attacking black-box classifiers that output binary labels, while Papernot et al. [42] work similarly in the context of multi-class image classification.

Compared to prior work, our learning-based attack does not rely on querying the classifier as an oracle or building a surrogate learner; instead, we exploit the characteristics of the CPS domain to remove this requirement.

### Conclusions

In this work, we formalized an attacker model for real-world Industrial Control Systems (ICS) and provided a taxonomy for adversarial machine learning (AML) in this context. We presented the first real-time concealment attacks on reconstruction-based anomaly detectors in ICS, addressing four unique challenges with iterative and learning-based attacks. Our white-box attacker uses the iterative approach with a detection oracle, while the black-box attacker uses an autoencoder to hide anomalies.

Using data from two water distribution systems, we demonstrated that our attacks are feasible and outperform replay attacks when the attacker controls less than 95% of the features. For the BATADAL dataset, our novel learning-based attack using an autoencoder reduced detection recall as efficiently as the iterative attack (from 0.60 to 0.14 in both cases). Our results show that the proposed autoencoder-based attack achieves successful concealment without knowledge of the targeted reconstruction-based anomaly detector, the physical model equations, and is computationally efficient (after training).

We implemented our attacks in a real testbed, showing that malicious data could be generated on-the-fly, i.e., between each sampling step (every 10 seconds, with example generation taking an average of 5 ms for iterative attacks). This demonstrates that the proposed attacks enable real-time, constrained concealment attacks on dynamic systems. Prior work typically involves offline manipulation of datasets or assumes precise prediction of data to be manipulated. Our results indicate that reconstruction-based attack detectors proposed in prior work are vulnerable to manipulation despite the unique challenges, and such attacks must be considered in future attack detection schemes. The implementation is available at our online repository [5].

### Acknowledgments

Several authors were supported by the National Research Foundation (NRF), Singapore, under its National Cybersecurity R&D Programme (Award No. NRF2014NCR-NCR001-40). Politecnico di Milano received funding for this project from the European Union’s Horizon 2020 research and innovation programme under the Marie Skłodowska-Curie grant agreement nr. 690972.

### References

[1] Marshall Abrams. 2008. Malicious control system cyber security attack case study–Maroochy Water Services, Australia. (2008).

[2] Chuadhry Mujeeb Ahmed, Venkata Reddy Palleti, and Aditya Mathur. 2017. WADI: A Water Distribution Testbed for Research in the Design of Secure Cyber Physical Systems. In Proceedings of the Workshop on Cyber-Physical Systems for Smart Water Networks. ACM, 25–28. https://doi.org/10.1145/3055366.3055375

[3] S.M. Amin, X. Litrico, S. Sastry, and A.M. Bayen. 2013. Cyber Security of Water