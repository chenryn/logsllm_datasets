model. The biggest distinction is that our micro-policy enforces the
stack discipline on cross-component calls and returns. We first
encountered linear capabilities in the context of the SAFE ma-
chine [50], although the idea seemed folklore. Probably even closer
related to our linear return capabilities are, however, linear contin-
uations [29, 88].
5 RELATED WORK
originally introduced in seminal work
Fully Abstract Compilation,
by Abadi [2], is phrased in terms of protecting two partial program
variants written in a safe source language, when these are com-
piled and linked with a malicious target-level context that tries to
distinguish the two variants. This original attacker model differs
substantially from the one we consider in this paper, which protects
14
the trace properties of multiple mutually-distrustful components
written in an unsafe source language.
In this line of research, Abadi [2] and later Kennedy [48] identi-
fied failures of full abstraction in the Java and C# compilers. Abadi et
al. [3] proved full abstraction of secure channel implementations
using cryptography. Ahmed et al. [10–12, 63] proved the full abstrac-
tion of type-preserving compiler passes for functional languages.
Abadi and Plotkin [5] and Jagadeesan et al. [42] expressed the
protection provided by address space layout randomization as a
probabilistic variant of full abstraction. Fournet et al. [31] devised
a fully abstract compiler from a subset of ML to JavaScript. More
recently, Patrignani et al. [65] studied fully abstract compilation
to machine code, starting from single modules written in simple,
idealized object-oriented and functional languages and targeting a
hardware enclave mechanism similar to Intel SGX [40].
Patrignani et al. [67] sub-
Modular, Fully Abstract Compilation.
sequently proposed a “modular” extension of their compilation
scheme to protecting multiple components from each other. The
attacker model they consider is again different from ours: they fo-
cus on separate compilation of safe languages and aim to protect
linked target-level components that are observationally equiva-
lent to compiled components. This could be useful, for example,
when hand-optimizing assembly produced by a secure compiler. In
another thread of work, Devriese et al. [25] proved modular full
abstraction by approximate back-translation for a compiler from
simply typed to untyped λ-calculus. This work also introduces a
complete Coq formalization for the original (non-modular) full
abstraction proof of Devriese et al. [23].
Beyond Good and Evil. The closest related work is that of Juglaret et
al. [45], who also aim at protecting mutually distrustful components
written in an unsafe language. They adapt fully abstract compilation
to components, but observe that defining observational equivalence
for programs with undefined behavior is highly problematic. For
instance, is the partial program “int buf[5]; return buf[42]”
equivalent to “int buf[5]; return buf[43]”? Both encounter
undefined behavior by accessing a buffer out of bounds, so at the
source level they cannot be distinguished. However, in an unsafe
language, the compiled versions of these programs will likely read
(out of bounds) different values and behave differently. Juglaret et
al. avoid this problem by imposing a strong limitation: a set of com-
ponents is protected only if it cannot encounter undefined behavior
in any context. This amounts to a static model of compromise: all
components that can possibly be compromised during execution
have to be treated as compromised from the start. Our aim here is to
show that, by moving away from full abstraction and by restricting
the temporal scope of undefined behavior, we can support a more
realistic dynamic compromise model. As discussed below, mov-
ing away from full abstraction also makes our secure compilation
criterion easier to achieve in practice and to prove at scale.
Robustly Safe Compilation. Our criterion builds on Robustly Safe
Compilation (RSC), recently proposed by Abate et al. [7], who study
several secure compilation criteria that are similar to fully abstract
compilation, but that are phrased in terms of preserving hyper-
properties [22] (rather than observational equivalence) against an
adversarial context. In particular, RSC is equivalent to preserva-
tion of robust safety, which has been previously employed for the
When Good Components Go Bad
Abate et al.
→ {PC′=tpc}
Nop :{PC=tpc, CI=(_ , c, _), NI=(_ , c, _)}
→ {PC′=tpc, D=⊥}
Const :{PC=tpc, CI=(_ , c, _), NI=(_ , c, _)}
→ {PC′=tpc, D=⊥}
BinOp :{PC=tpc, CI=(_ , c, _), NI=(_ , c, _), S1=_ , S2=_ }
→ {PC′=tpc, S=⊥, D=tv}
Mov :{PC=tpc, CI=(_ , c, _), NI=(_ , c, _), S=tv}
→ {PC′=tpc, M=(⊥, c, _), D=tv}
Load :{PC=tpc, CI=(_ , c, _), NI=(_ , c, _), M=(tv , c, _)}
Load :{PC=tpc, CI=(_ , c, _), NI=(_ , c, _), M=(tv , c′, _)} → {PC′=tpc, M=(tv , c′, _), D=⊥}
Store :{PC=tpc, CI=(_ , c, _), NI=(_ , c, _), M=(_ , c, _), S=tv}→ {PC′=tpc, M=(tv , c, _), S=⊥}
Bnz :{PC=tpc, CI=(_ , c, _), NI=(_ , c, _)}
Jal :{PC=tpc, CI=(_ , c, _), NI=(_ , c, _), P =_ }
Jal :{PC=Level(n), CI=(_ , c, _), NI=(_ , c′, cs ∋ c), P =_ } → {PC′=Level(n+1), RA=Ret(n)}
Jump :{PC=tpc, CI=(_ , c, _), NI=(_ , c, _), P =_ }
Jump :{PC=Level(n+1), CI=(_ , c, _), NI=(_ , c′, _), P =Ret(n)}→ {PC′=Level(n), P =⊥}
→ {PC′=tpc}
→ {PC′=tpc, RA=⊥}
→ {PC′=tpc, RA=⊥}
Figure 11: Compartmentalization micro-policy rules
model checking of open systems [53], the analysis of security pro-
tocols [33], and compositional verification [75].
Though RSC is a bit less extensional than fully abstract compi-
lation (since it is stated in terms of execution traces), it is easier
to achieve. In particular, because it focuses on safety instead of
confidentiality, the code and data of the protected program do not
have to be hidden, allowing for more efficient enforcement, e.g.,
there is no need for fixed padding to hide component sizes, no clean-
ing of registers when passing control to the context (unless they
store capabilities), and no indirection via integer handlers to hide
pointers; cross-component reads can be allowed and can be used
for passing large data. We believe that in the future we can obtain
a more practical notion of data (but not code) confidentiality by
adopting Garg et al.’s robust hypersafety preservation criterion [7].
While RSC serves as a solid base for our work, the challenges
of protecting unsafe components from each other are unique to
our setting, since, like full abstraction, RSC is about protecting
a partial program written in a safe source language against low-
level contexts. Our contribution is extending RSC to reason about
the dynamic compromise of components with undefined behavior,
taking advantage of the execution traces to detect the compromise
of components and to rewind the execution along the same trace.
Proof Techniques. Abate et al. [7] observe that, to prove RSC, it
suffices to back-translate finite execution prefixes, and recently they
propose such a proof for a stronger criterion where multiple such
executions are involved. In recent concurrent work, Patrignani and
Garg [68] also construct such a proof for RSC. The main advantages
of our RSCDC
MD proof are that (1) it applies to unsafe languages with
undefined behavior and (2) it directly reuses a compiler correctness
result à la CompCert. For safe source languages or when proof
reuse is not needed our proof could be further simplified.
Even as it stands though, our proof technique is simple and
scalable compared to previous full abstraction proofs. While many
proof techniques have been previously investigated [3, 5, 11, 12, 25,
31, 42, 63], fully abstract compilation proofs are notoriously difficult,
even for very simple languages, with apparently simple conjectures
surviving for decades before being finally settled [24]. The proofs of
Juglaret et al. [45] are no exception: while their compiler is similar
to the one in §4, their full abstraction-based proof is significantly
more complex than our RSCDC
MD proof. Both proofs give semantics to
15
partial programs in terms of traces, as was proposed by Jeffrey and
Rathke [43] and adapted to low-level target languages by Patrignani
and Clarke [66]. However, in our setting the partial semantics is
given a one line generic definition and is related to the complete one
by two simulation proofs, which is simpler than proving a “trace
semantics” fully abstract.
Recent successes in
Verifying Low-Level Compartmentalization.
formal verification have focused on showing correctness of low-
level compartmentalization mechanisms based on software fault
isolation [60, 89] or tagged hardware [15]. That work only consid-
ers the correctness of low-level mechanisms in isolation, not how a
secure compilation chain makes use of these mechanisms to pro-
vide security reasoning principles for code written in a higher-level
programming language with components. However, more work
in this direction seems underway, with Wilke et al. [85] working
on a variant of CompCert with SFI, based on previous work by
Kroll et al. [52]; we believe RSCC or RSCDC could provide good
top-level theorems for such an SFI compiler. In most work on ver-
ified compartmentalization [15, 60, 89], communication between
low-level compartments is done by jumping to a specified set of
entry points; the model considered here is more structured and
enforces the correct return discipline. Skorstengaard et al. have
also recently investigated a secure stack-based calling convention
for a simple capability machine [74]; they plan to simplify their
calling convention using a notion of linear return capability [73]
that seems similar to the one used in our micro-policy from §4.5.
Attacker Models for Dynamic Compromise. While our model of
dynamic compromise is specific to secure compilation of unsafe lan-
guages, related notions of compromise have been studied in the set-
ting of cryptographic protocols, where, for instance, a participant’s
secret keys could inadvertently be leaked to a malicious adversary,
who could then use them to impersonate the victim [17, 18, 30, 34].
This model is also similar to Byzantine behavior in distributed sys-
tems [20, 55], in which the “Byzantine failure” of a node can cause
it to start behaving in an arbitrary way, including generating arbi-
trary data, sending conflicting information to different parts of the
system, and pretending to be a correct node.
When Good Components Go Bad
Abate et al.
6 CONCLUSION AND FUTURE WORK
We introduced RSCC, a new formal criterion for secure compilation
providing strong security guarantees despite the dynamic compro-
mise of components with undefined behavior. This criterion gives
a precise meaning to informal terms like dynamic compromise and
mutual distrust used by proponents of compartmentalization, and
it offers a solid foundation for reasoning about security of practical
compartmentalized applications and secure compiler chains.
Looking ahead, we
Formally Secure Compartmentalization for C.
hope to apply RSCC to the C language by developing a provably
secure compartmentalizing compiler chain based on the CompCert
compiler. Scaling up to the whole of C will certainly entail further
challenges such as defining a variant of C with components and
efficiently enforcing compartmentalization all the way down. We
believe these can be overcome by building on the solid basis built
by this paper: the RSCC formal security criterion, the scalable proof
technique, and the proof-of-concept secure compilation chain.
A very interesting extension is sharing memory between com-
ponents. Since we already allow arbitrary reads at the lowest level,
it seems appealing to also allow external reads from some of the
components’ memory in the source. The simplest would be to allow
certain static buffers to be shared with all other components, or
only with some if we also extend the interfaces. For this extension
the back-translation would need to set the shared static buffers to
the right values every time a back-translated component gives up
control; for this back-translation needs to look at the read events
forward in the back-translated trace prefix. More ambitious would
be to allow pointers to dynamically allocated memory to be passed
to other components, as a form of read capabilities. This would
make pointers appear in the traces and one would need to accom-
modate the fact that these pointers will vary at the different levels
in our compilation chain. Moreover, each component produced by
the back-translation would need to record all the read capabilities it
receives for later use. Finally, to safety allow write capabilities one
could combine compartmentalization with memory safety [15, 16].
It would also be in-
Verifying Compartmentalized Applications.
teresting to build verification tools based on the source reasoning
principles provided by RSCC and to use these tools to analyze
the security of practical compartmentalized applications. Effective
verification on top of RSCC will, however, require good ways for
reasoning about the exponential number of dynamic compromise
scenarios. One idea is to do our source reasoning with respect to
a variant of our partial semantics, which would use nondetermin-
ism to capture the compromise of components and their possible
successive actions. Correctly designing such a partial semantics
for a complex language is, however, challenging. Fortunately, our
RSCC criterion provides a more basic, low-TCB definition against
which to validate any fancier reasoning tools, like partial semantics,
program logics [44], logical relations [26], etc.
Dynamic Component Creation. Another interesting extension is
supporting dynamic component creation. This would make crucial
use of our dynamic compromise model, since components would
no longer be statically known, and thus static compromise would
not apply, unless one severely restricts component creation to only
a special initialization phase [62, 72]. We hope that our RSCC def-
inition can be adapted to rewind execution to the point at which
the compromised component was created, replace the component’s
code with the result of our back-translation, and then re-execute.
This extension could allow us to also explore moving from our
current “code-based” compartmentalization model to a “data-based”
one [35], e.g., one compartment per incoming network connection.
Dynamic Privilege Notions. Our proof-of-concept compilation
chain used a very simple notion of interface to statically restrict the
privileges of components. This could, however, be extended with
dynamic notions of privilege such as capabilities and history-based
access control [1]. In one of its simplest form, allowing pointers
to be passed between components and then used to write data, as
discussed above, would already constitute a dynamic notion of priv-
ilege, that is not captured by the static interfaces, but nevertheless
needs to be enforced to achieve RSCC, in this case probably using
some form of memory safety.
It would be interesting
Preserving Confidentiality and Hypersafety.
to extend our security criterion and enforcement mechanisms from
robustly preserving safety to confidentiality and hypersafety [7, 22].
For this one needs to control the flow of information at the target
level—e.g., by restricting direct reads and read capabilities, cleaning
registers, etc. This becomes very challenging though, in a realistic
attacker model in which low-level contexts can observe time.
Acknowledgments We thank the anonymous reviewers for their
valuable feedback. Yannis Juglaret first studied with us the com-
partmentalization micro-policy from §4.5 and described it in an
unpublished technical report [46]. Jérémy Thibault helped us cor-
rectly extract the micro-policies back end to OCaml. We are also
grateful to Danel Ahman, Éric Tanter, Steven Schäfer, and William
Bowman, for insightful discussions and thoughtful feedback on
earlier drafts. This work is in part supported by ERC Starting Grant
SECOMP (715753), by NSF award Micro-Policies (1513854), and by
DARPA grant SSITH/HOPE (FA8650-15-C-7558).
A CLASS OF SAFETY PROPERTIES
PRESERVED BY RSCDC
Since RSC corresponds exactly to preserving robust safety prop-
erties [7], one might wonder what properties RSCDC preserves. In
fact, RSCDC corresponds exactly to preserving the following class
ZP against an adversarial context:
Definition A.1. ZP ≜ Safety ∩ Closed≺P , where
Safety ≜ {π | ∀t(cid:60)π . ∃m≤t . ∀t′≥m. t′(cid:60)π}
≜ {π | ∀t∈π . ∀t′. t≺P t′ ⇒ t′∈π}
= {π | ∀t′(cid:60)π . ∀t . t≺P t′ ⇒ t(cid:60)π}
Closed≺P
The class of properties ZP is defined as the intersection of Safety
and the class Closed≺P of properties closed under extension of traces