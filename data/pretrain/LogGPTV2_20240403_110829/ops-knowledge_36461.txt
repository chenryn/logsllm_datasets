User: My question is: which python framework should I use to build my server?
Notes:

This server talks HTTP with it's clients: GET and POST  (via pyAMF)
Clients "submit" "tasks" for processing and, then, sometime later, retrieve the associated "task_result" 
submit and retrieve might be separated by days - different HTTP connections
The "task" is a lump of XML describing a problem to be solved, and a "task_result" is a lump of XML describing an answer. 
When a server gets a "task", it queues it for processing
The server manages this queue and, when tasks get to the top, organises that they are processed. 
the processing is performed by a long running (15 mins?) external program (via subprocess) which is feed the task XML and which produces a "task_result" lump of XML which the server picks up and stores (for later Client retrieval).
it serves a couple of basic HTML pages showing the Queue and processing status (admin purposes only)

I've experimented with twisted.web, using SQLite as the database and threads to handle the long running processes.  
But I can't help feeling that I'm missing a simpler solution.  Am I?  If you were faced with this, what technology mix would you use?
Assistant: It seems any python web framework will suit your needs. I work with a similar system on a daily basis and I can tell you, your solution with threads and SQLite for queue storage is about as simple as you're going to get. 
Assuming order doesn't matter in your queue, then threads should be acceptable. It's important to make sure you don't create race conditions with your queues or, for example, have two of the same job type running simultaneously. If this is the case, I'd suggest a single threaded application to do the items in the queue one by one.