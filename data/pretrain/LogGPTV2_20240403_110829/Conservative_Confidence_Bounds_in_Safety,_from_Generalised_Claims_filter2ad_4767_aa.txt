title:Conservative Confidence Bounds in Safety, from Generalised Claims
of Improvement &amp; Statistical Evidence
author:Kizito Salako and
Lorenzo Strigini and
Xingyu Zhao
5
5
0
0
0
.
1
2
0
2
.
7
8
9
8
4
N
S
D
/
9
0
1
1
.
0
1
:
I
O
D
|
E
E
E
I
1
2
0
2
©
0
0
.
1
3
$
/
1
2
/
7
-
2
7
5
3
-
4
5
6
6
-
1
-
8
7
9
|
)
N
S
D
(
s
k
r
o
w
t
e
N
d
n
a
s
m
e
t
s
y
S
e
l
b
a
d
n
e
p
e
D
n
o
e
c
n
e
r
e
f
n
o
C
l
a
n
o
i
t
a
n
r
e
t
n
I
P
I
F
I
/
E
E
E
I
l
a
u
n
n
A
t
s
1
5
1
2
0
2
2021 51st Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN)
Conservative Conﬁdence Bounds in Safety, from
Generalised Claims of Improvement & Statistical
Evidence
Kizito Salako, Lorenzo Strigini
Centre for Software Reliability
City, University of London
Northampton Square EC1V 0HB, U.K.
{k.o.salako,l.strigini}@city.ac.uk
Xingyu Zhao
Department of Computer Science
University of Liverpool
Ashton Street L69 3BX, U.K.
PI:EMAIL
Abstract—“Proven-in-use”,
“globally-at-least-equivalent”,
“stress-tested”, are concepts that come up in diverse contexts in
acceptance, certiﬁcation or licensing of critical systems. Their
common feature is that dependability claims for a system in
a certain operational environment are supported, in part, by
evidence – viz of successful operation – concerning different,
though related, system[s] and/or environment[s], together with
an auxiliary argument that the target system/environment offers
the same, or improved, safety. We propose a formal probabilistic
(Bayesian) organisation for these arguments. Through speciﬁc
examples of evidence for the “improvement” argument above,
we demonstrate scenarios in which formalising such arguments
substantially increases conﬁdence in the target system, and show
why this is not always the case. Example scenarios concern
vehicles and nuclear plants. Besides supporting stronger claims,
the mathematical formalisation imposes precise statements of
the bases for “improvement” claims: seemingly similar forms
of prior beliefs are sometimes revealed to imply substantial
differences in the claims they can support.
Index Terms—Reliability claims, statistical
testing, safety-
critical systems, ultra-high reliability, conservative Bayesian in-
ference, ﬁeld testing, not worse than existing systems, software
re-use, globally at least equivalent, proven in use.
I. INTRODUCTION
In dependability assessment, it often happens that favourable
evidence is available in the form of experience of dependable
operation. However, this evidence might not exactly match
the situation for which the assessment is sought. For instance,
“proven in use” evidence plays an important, accepted role
[1,2] in assessing many systems. But there is concern whether
this evidence (of past use) is relevant to the claim made. Due
to this concern, standard IEC61508 [1], for example, sets strict
conditions for accepting such experience as valid evidence: it
must concern an identical system, under identical conditions
of use. Good behaviour of a slightly different system version,
or in slightly different conditions, is not admitted as evidence.
One might object, not unreasonably, that this is too Draconian.
A small change in the system, or in its mode of use, does
This work was partly supported by the Intel Collaborative Research Institute
on Safe Automated Vehicles (ICRI-SAVe), and UK DSTL through the project
“Safety Argument for Learning-enabled Autonomous Underwater Vehicles”.
void claims that the previous experience is a sample of the
same stochastic process that the dependability assessment tries
to predict. Yet it is still relevant evidence. True, even small
changes may radically reduce reliability; but this is rare. The
evidence is still relevant, but a little less so; what is hard is
quantifying the effect of this reduced relevance. This neglect
of useful evidence is most disturbing in cases of “ultra-high
reliability” [3–5], where evidence of safe/correct operation is
routinely insufﬁcient.
We noted in previous work [6,7] that a special case of
interest is that in which there is evidence that the change has
been for the better. A general scenario is: dependability (e.g.,
safety) claims are to be supported for a situation (i.e., a system
and an environment it operates in), say B, based on statistical
evidence of good operation in B, and of good operation in
another situation A. We focus on the common cases in which
what changed between A and B is the system and/or its
environment of use. But our mathematical results apply to any
case in which a claim of conﬁdence in improvement (CII) –
from A to B – is justiﬁed.
More precisely, we deﬁne a CII as conﬁdence in a claim of
B being “no worse than” A, rather than “strictly better”. Thus
deﬁned, CII includes “proven in use” (PIU in what follows) ar-
guments: these commonly only claim similar dependability in
the target environment to that experienced in the environment
of past use.
The above abstract scenario generalises the case of PIU
arguments, to include other common cases where CII plays
a role: e.g., 1) the case of stress testing (in the lab or in
the ﬁeld) being claimed to be relevant evidence for reliability
assessment; or 2) analysis-based arguments that a system is
“globally at least equivalent” (GALE) to a previous one [8];
or 3) general claims that the system in B is an improvement
on that in A.
Extending our previous work cited [6,7], in this paper we
focus on the crucial passage of translating informal beliefs in
“B being better than A” into formal statements that faithfully
represent the evidence supporting those beliefs. We show that
different formal statements may sometimes produce substantial
978-1-6654-3572-7/21/$31.00 ©2021 IEEE
DOI 10.1109/DSN48987.2021.00055
451
Authorized licensed use limited to: Tsinghua University. Downloaded on October 11,2021 at 09:23:48 UTC from IEEE Xplore.  Restrictions apply. 
differences in the claims supported for B. These differences
might well be missed in informal safety arguments. To this
aim, we propose new speciﬁc example scenarios of evidence
supporting CII (Sec. IV), propose two mathematical formula-
tions of CII applicable to these scenarios (“PK” statements,
Sec. V) and demonstrate their implications on the claims
that can be supported. Our contribution includes both these