# Conservative Confidence Bounds in Safety, from Generalised Claims of Improvement & Statistical Evidence

## Authors
Kizito Salako, Lorenzo Strigini, Xingyu Zhao

## Affiliations
- **Kizito Salako, Lorenzo Strigini**
  - Centre for Software Reliability
  - City, University of London
  - Northampton Square, EC1V 0HB, U.K.
  - Email: {k.o.salako, l.strigini}@city.ac.uk
- **Xingyu Zhao**
  - Department of Computer Science
  - University of Liverpool
  - Ashton Street, L69 3BX, U.K.
  - Email: xingyu.zhao@liverpool.ac.uk

## Abstract
"Proven-in-use," "globally-at-least-equivalent," and "stress-tested" are concepts that arise in various contexts related to the acceptance, certification, or licensing of critical systems. These concepts share a common feature: dependability claims for a system in a specific operational environment are supported, in part, by evidence of successful operation in different but related systems and/or environments, along with an auxiliary argument that the target system/environment offers the same or improved safety. We propose a formal probabilistic (Bayesian) framework for these arguments. Through specific examples of evidence supporting the "improvement" argument, we demonstrate scenarios where formalizing such arguments significantly increases confidence in the target system and explain why this is not always the case. Example scenarios include vehicles and nuclear plants. Besides supporting stronger claims, the mathematical formalization requires precise statements of the bases for "improvement" claims, revealing that seemingly similar forms of prior beliefs can imply substantial differences in the claims they support.

## Index Terms
Reliability claims, statistical testing, safety-critical systems, ultra-high reliability, conservative Bayesian inference, field testing, not worse than existing systems, software re-use, globally at least equivalent, proven in use.

## I. Introduction

In dependability assessment, it is common to have favorable evidence in the form of experience with dependable operation. However, this evidence may not exactly match the situation for which the assessment is sought. For example, "proven in use" evidence plays a significant and accepted role in assessing many systems [1,2]. However, there is concern about the relevance of past use to the current claim. Standards like IEC61508 [1] set strict conditions for accepting such experience as valid evidence, requiring identical systems under identical conditions of use. Small changes in the system or its mode of use are not admitted as evidence.

One might argue, reasonably, that these conditions are too stringent. A small change in the system or its mode of use does not necessarily invalidate the previous experience as a sample of the same stochastic process. The evidence remains relevant, though perhaps slightly less so. Quantifying the effect of this reduced relevance is challenging, especially in cases of "ultra-high reliability" [3–5], where evidence of safe/correct operation is often insufficient.

In our previous work [6,7], we noted that a special case of interest is when there is evidence that the change has been for the better. A general scenario involves making dependability (e.g., safety) claims for a situation B based on statistical evidence of good operation in B and another situation A. We focus on cases where the change between A and B is in the system and/or its environment of use, but our mathematical results apply to any case where a claim of confidence in improvement (CII) from A to B is justified.

More precisely, we define CII as confidence in B being "no worse than" A, rather than "strictly better." This definition includes "proven in use" (PIU) arguments, which typically claim similar dependability in the target environment to that experienced in the past environment.

The above abstract scenario generalizes PIU arguments to include other common cases where CII plays a role, such as:
1. Stress testing (in the lab or in the field) being claimed as relevant evidence for reliability assessment.
2. Analysis-based arguments that a system is "globally at least equivalent" (GALE) to a previous one [8].
3. General claims that the system in B is an improvement over that in A.

Extending our previous work [6,7], this paper focuses on translating informal beliefs in "B being better than A" into formal statements that accurately represent the supporting evidence. We show that different formal statements can produce substantial differences in the claims supported for B, which might be missed in informal safety arguments. To this end, we propose new specific example scenarios of evidence supporting CII (Section IV), introduce two mathematical formulations of CII applicable to these scenarios ("PK" statements, Section V), and demonstrate their implications on the claims that can be supported. Our contribution includes both these formulations and the demonstration of their practical significance.

---

**Acknowledgments:**
This work was partly supported by the Intel Collaborative Research Institute on Safe Automated Vehicles (ICRI-SAVe) and UK DSTL through the project "Safety Argument for Learning-enabled Autonomous Underwater Vehicles."

**Copyright Information:**
978-1-6654-3572-7/21/$31.00 ©2021 IEEE
DOI 10.1109/DSN48987.2021.00055

**Authorized licensed use limited to: Tsinghua University. Downloaded on October 11, 2021, at 09:23:48 UTC from IEEE Xplore. Restrictions apply.**