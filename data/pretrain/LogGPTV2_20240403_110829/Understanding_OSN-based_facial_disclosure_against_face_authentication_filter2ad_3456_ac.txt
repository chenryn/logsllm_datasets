Horizontal rotation
Vertical rotation
Side illumination
Top/bottom illumination
Bright background
Lighting condition
Dimness
Neutral
Smile without showing teeth
Smile showing teeth
Closed eyes
Open mouth
Other expressions
Occluded forehead
Occluded eyebrow
Occluded eye
Occluded cheek
Occluded mouth
Resolution
Blur
Makeup
Edit
F Exn
F Exs
F Exst
F Exce
F Exm
F Exother
Occf h
Occeb
Occeye
Occchk
Occmh
res
blur
mk
ed
Facial expression
Facial occlusion
Resolution
Blur
Facial makeup
Edit
i is assigned to the positive class if pi ≥ 0.5. Otherwise, i is
assigned to the negative class. The correctness of these assignments
is veriﬁed with the ground truth data collected from the previous
empirical analysis.
For each combination of face authentication system and its se-
curity level, we examine the model ﬁtting of binomial logistic re-
gression and the signiﬁcance of the parameters by using the real
world OSN images and run binomial logistic regression on SAS
software [33]. The likelihood ratio test and wald statistic [15] for
all the face authentication systems are smaller than 0.0001.
Our statistical analysis shows the most inﬂuential attributes are
resolution res, occluded eye Occeye, makeup mk, and illumina-
tion illsd. Resolution res has positive impact on the risk of OS-
NFD. It is because higher resolution contributes to more accurate
facial landmark localization and results in better performance of
face recognition and increases the risk of OSNFD. The occluded
eye Occeye, makeup mk, and illumination illsd have negative im-
pact and lower the risk of OSNFD. In particular, the occluded eye
leads to decrease in the performance of face recognition algorithms,
as accurate localization of eyes is important for the alignment pro-
cess in all major face recognition algorithms [1]. Makeup can sig-
niﬁcantly change the appearance of the face and the facial land-
marks and therefore lowers the performance of face recognition.
The illumination is a prominent attribute which causes difﬁculty in
face recognition since it diminishes facial features.
The parameters related to other attributes, including head pose
and facial expression, are generally not statistically signiﬁcant.
Among the collected OSN images, the variations of head pose
and facial expression are limited since users are usually coopera-
tive when these images are captured and tend to publish the im-
ages from which they are easily recognized. As observed in our
study, the head poses in most OSN images are within the accept-
able head pose ranges of the face authentication systems, which
31396117920585274383146Face UnlockFacelock ProVisidonVerifaceLuxand BlinkFastAccess010203040506070% (Vulnerable Images) % (By Males) % (By Females)78929570306895100100765192Face UnlockFacelock ProVisidonVerifaceLuxand BlinkFastAccess020406080100% (Vulnerable Users) % (By Males) % (By Females)105344171081010Facelock ProVisidonVerifaceLuxand BlinkFastAccess024681012141618% (Vulnerable Images) % (By Males) % (By Females)51221619115938163532Facelock ProVisidonVerifaceLuxand BlinkFastAccess0102030405060 % (Vulnerable Users) % (By Males) % (By Females)419causes the insigniﬁcance due to lack of samples with extreme head
pose. On the other hand, facial expressions observed in most OSN
images are only mild-mannered expressions including neutral ex-
pression, smile without showing teeth, smile showing teeth, closed
eyes, open mouth. These common expressions do not have signif-
icant impact as they have been well handled in current face recog-
nition algorithms [1]. Other extreme facial expressions, such as
making faces, do signiﬁcantly affect the face recognition, but they
are observed in only 5% of the OSN images.
4.3 Model Evaluation
To evaluate the performance of the proposed risk estimation tool,
we use cross-validation method. In each round, for each of the face
authentication systems in a speciﬁc security level, we randomly
choose 80% of the OSN images to train the model and use the
risk estimation tool to automatically classify the rest of the images.
The above process is repeated by 10 rounds. The performance is
measured by standard classiﬁcation evaluation metrics, including
precision, recall, and F1 score [32].
Precision is deﬁned as the percentage of the true positive im-
ages among the images assigned to the positive class by the risk
estimation tool, which can be calculated by tp/(tp + f p) where
tp is the number of true positive images and f p is the number of
false positive images. Recall is deﬁned as the percentage of the
true positive images detected by the risk estimation tool among
the positive images in ground truth, which can be calculated by
tp/(tp + f n) where tp is the number of true positive images
and f n is the number of false negative images. F1 score consid-
ers both the precision and the recall, which can be calculated by
F1 = 2 × precision × recall/(precision + recall).
Table 3 shows the performance evaluation metrics of the risk
estimation tool. On average, the risk estimation tool achieves a
precision of 81%, a recall of 83%, and an F1 score of 82%. The
performance evaluation indicates that the risk estimation tool de-
tects most of the vulnerable images which can lead to successful
OSNFD-based attacks if these images are published in OSNs.
Table 3: Effectiveness of our risk estimation tool
F1 score
System
Security level
Precision
Face Unlock
Facelock Pro
Visidon
Veriface
Luxand Blink
FastAccess
Average
N/A
Low
High
Low
High
Low
High
Low
High
Low
High
N/A
73%
70%
81%
79%
86%
79%
90%
84%
87%
77%
89%
81%
Recall
77%
69%
75%
90%
92%
68%
98%
87%
90%
67%
95%
83%
75%
69%
78%
84%
89%
73%
94%
85%
88%
72%
92%
82%
5. DISCUSSION
5.1 Tradeoff between Security and
Accessibil-ity
Clear tradeoffs between security and accessibility can be ob-
served in our tested systems, which are decided by security settings
and target platforms as analyzed in Section 3.2. The increasing se-
curity strength inevitably decreases the accessibility. We conduct
a follow-up experiment to collect quantitative evidence for the im-
pact of these tradeoffs.
20 participants from the main user study are invited for this
follow-up study. The participants need to enroll their faces in the 6
face authentication systems in low/high security level in a meeting
room with normal lighting, respectively. To mimic the different lo-
gin environment, the experiments are conducted between 2pm-4pm
in a sunny day at four ﬁxed indoor/outdoor locations, including 1)
a meeting room with normal lighting condition, 2) a meeting room
with dim lighting condition, 3) outdoor ground in the sunshine, and
4) shelter of building. This setting simulates a situation when a user
registers in one place, but tries to access the system in many other
places. The participants are asked to login by using each face au-
thentication systems. In this experiment, there are no OSN images,
but only live legitimate users who attempt to access a face authenti-
cation system. Each participant has at most three attempts for each
login before we record it as a false rejection.
Table 4 shows the false rejection rates of the face authentica-
tion systems in low security level are lower than those of the face
authentication systems in high security level in overall. Moreover,
the face authentication systems on mobile platform have lower false
rejection rates than those on traditional platform. The highest ob-
served false rejection rate is 85% for Veriface in high security level.
This accessibility degradation could be a disaster for end users. In
our questionnaire, 91% of the participants believe that it is impor-
tant to log in smartphones and tablets in both indoor and outdoor
environments, while 36% of the participants think that it is impor-
tant to log in laptops in both indoor and outdoor environments. If
a face authentication system is set to high security level in order
to mitigate the OSNFD threat, the system will be less tolerant for
complex environments and violate the users’ need of accessibility.
Table 4: Signiﬁcant increase in false rejection rates when using
high security level settings. The increments of false rejection
rates are more signiﬁcant for traditional platform-based sys-
tems (the last three systems).
System
Security
level
Face Unlock
Facelock Pro
Visidon
Veriface
Luxand Blink
FastAccess
N/A
Low
High
Low
High
Low
High
Low
High
Low
High
Room+
normal
lighting
0%
0%
0%
0%
5%
0%
10%
0%
5%
0%
5%
Room+
dim
lighting
5%
10%
45%
5%
55%
25%
60%
30%
55%
15%
55%
Outdoor
ground
Shelter
10%
10%
60%
5%
65%
35%
85%
50%
70%
30%
65%
0%
0%
25%
0%
50%
20%
60%
45%
55%
15%
55%
5.2 Costs of Liveness Detection
Liveness detection could be a mitigation for OSNFD-based at-
tacks, which is designed to distinguish between a live face and a
facial image in front of the camera. The most common liveness de-
tection mechanisms deployed on popular face authentication sys-
tems are eye-blinking and head rotation detection, as they have
the advantages of no additional hardware support, requiring moder-
ate image quality, and involving relatively low usability cost. This
is important to all consumer-level products that are price-sensitive
and accessibility-ﬁrst. However, these two mechanisms can be eas-
ily bypassed with one or two pre-catched images as shown in [31].
The practicality of these attacks is also veriﬁed by our experiments.
Besides these two simple mechanisms, several sophisticated live-
ness detection techniques have been proposed for face authentica-
420tion. However, all of them are associated with considerable costs
as shown in Table 5 [29]. Their costs include requiring additional
hardware, high quality images, ideal environment that are usually
not universally available, and high user collaborations that may
cause inconvenience. This indicates they may not be suitable for
consumer-level face authentication systems. It still remains a chal-
lenge to deploy reliable and practical liveness detection in face au-
thentication systems that can be used by the public.
Table 5: Costs associated with existing liveness detection mech-
anisms for face authentication. * sign indicates a requirement
involves a signiﬁcant cost for end users or device manufactur-
ers.
Liveness detection
Image quality
Additional hardware
Usability cost
Eye blinking
Mouth movement
Degradation
Head movement
Facial expressions
Facial thermogram