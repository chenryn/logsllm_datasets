when the browser sends a cookie along with an HTTP request, it is
reasonable to assume that the server-side application will check its
value, maybe use it to retrieve the associated user session and load
additional data from the database, or that it will simply execute
a different execution path with respect to a request that does not
contain any cookie (in which case, for example, the application may
execute the routines necessary to create new cookies).
For instance, Figure 1 shows a simple PHP skeleton that em-
pathizes three different possible cases. First, the program checks if
the user already accessed the website before, by testing for the pres-
ence of the consent cookie using the isset function. If the cookie
is not found (either because it is the first time the user access the
website or because it has been deleted), the program takes the path
we named Case A that calls the askConsent function. Otherwise,
the program performs additional checks by looking for some login
information stored in the cookies. If userID is not indicated, Case B
is followed, that calls function saveNavigation, else, the userID
information is first validated, and then the application follows Case
C by calling the getUserData function.
Figure 2 shows a simplified representation of the control-flow of
our toy application, emphasizing the different paths. Our hypothe-
sis is that the time difference among the three cases is sufficient,
even across a network connection, to tell the three behaviors apart
and therefore to accurately identify whether or not cookies are
submitted alongside an HTTP request. In particular, there are two
main tests that make detecting a timing difference possible: the first
to verify if there are cookies at all and the second to analyze them
and load session data. While the comparison themselves are too
ACSAC ’19, December 9–13, 2019, San Juan, PR, USA
Iskander Sanchez-Rola, Davide Balzarotti, and Igor Santos
fast to be identified, the different functions invoked in the three
cases may not be. In our toy scenario, these results in the request
take x seconds to be processed if no cookies are found, y seconds if
they exist but there is not a current active session, and z seconds if
the user is currently logged in.
Our prototype tool, called BakingTimer, performs cross-origin
requests towards a number of target websites. Each request is per-
formed multiple times, with and without cookies. In fact, while
JavaScript code cannot directly test for the existence of cookies
belonging to other domains, it can issue HTTP requests in two
different ways: (i) by letting the browser send cookies (if any exist
for the target domain) or (ii) by forcing the browser to make a
request without cookies. So, in one case the code knows that no
cookie was present in the request, while in the other cookies may
or may not be present depending whether they previously existing
in the user browser. The time difference between the two requests,
issued multiple times to account for small noise effects, is then
used by our tool to detect if the browser already had cookies for
that particular target. Even if some cookies can be created when
performing these requests, our experiments show that in most cases
either the number or type of these cookies differ from what it is
set when the user visits the website. We will discuss this aspect in
more details in Section 4 and Section 7.
3.1 Retrieval Phase
The first phase of our approach is the retrieval phase, in which the
algorithm computes the time required by a server to execute differ-
ent paths, according to hypothetical cookies sent by the browser.
A simplified pseudo-code of the algorithm is presented in Fig-
ure 3. Note that the full implementation is executed performing
asynchronous/non-blocking requests and using onreadystatechange
event handlers. Moreover, even if security policies like Same-Origin
Policy (SOP) or Cross-Origin Resource Sharing (CORS) may limit
the capabilities of interacting with the response of cross-origin re-
quests, the event handler would still be able to correctly catch when
the response arrives to the browser – making our attack possible
in these cases.
To measure the round-trip times (RTTs), we use the User Timing
API [47] implemented in every major browser. The best solution
to get a measure of time independent of the current CPU load of
the server or the current speed and congestion of the network is
to perform a comparison with two different requests sent at the
same time. Both time information are obtained side to side, so the
workload of the network will likely be roughly the same in the two
cases (especially when the experiment is repeated multiple times).
To make it more clear, let us consider a simple example. Imagine
we are timing the execution of certain function of the server that
directly depends on the existence of a specific cookie. Our system
would execute a measurement by executing in parallel two requests,
with and without the cookies. In a first measurement, when the
network workload is low, the system can obtain a value of 30.5ms
when cookies are sent and a value of 20.3ms without cookies —
thus estimating the execution time of the function in 10.2ms. In
a second repetition of the test, when maybe the network load is
higher than before, the same experiment can return two different
values, such as 45.1ms with cookies and 34.7ms without — leading to
Input: n the number of comparisons to perform.
Output: cs an array of arrays of numbers representing the
server request processing schema: each position
are the result of timings with and without cookies.
i ←1;
cs ← f loat[][] of size n×2;
while i ≤ n do
j ← 1;
while j ≤ 2 do
1 Function bakingTimer (n)
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
Request();
end
i ← i + 1;
end
return cs;
startTime ← GetCurrentTime() ;
if j % 2 = 0 then
Request(cookies);
else
end
endTime ← GetCurrentTime();
loдTime ← endTime − startTime;
cs[j][i] ← loдTime;
j ← j + 1;
Figure 3: BakingTimer simplified retrieval pseudo-
code (implemented using asynchronous/non-blocking re-
quests and onreadystatechange event handlers).
a similar (even if not exactly the same) time estimation. In Section 5
we present a number of stability tests, designed to verify to which
extent our technique is robust against external factors that could
tamper the results.
Following the schema presented in Figure 2, if a request requires
x seconds to be processed (as opposed to y or z seconds), a simple
comparison can be used to calculate the actual state of the user in
relation with the website. The first request, the one we named as
Case A, is issued without cookies by using:
xmlHttpRequest.withCredentials = false;
This guarantees that the server would not receive cookies, even
if the browser would have normally sent some for that particular
website. Then, our code repeat the request, this time by setting
xmlHttpRequest.withCredentials = true;.
It is important to remark that the cookies sent in this second
request (if any) are completely invisible for our Javascript code.
However, the code can still measure the time required to receive
an answer, and use this information to infer the previous relation
between the user and the target website: if the cookies were created
in a simple access, the server response time will fall in Case B, but
if some login cookies are stored in the browser the time would be
more consistent with Case C.
BakingTimer: Privacy Analysis of Server-Side Request Processing Time
ACSAC ’19, December 9–13, 2019, San Juan, PR, USA
(a) Time deltas at differentdelays introduced in the server.
(b) P-value (T-test) at different delays introduced in the server.
Figure 4: BakingTimer resolution test.
To summarize:
• Not Accessed: If the user never accessed the website, and we
perform the timings described above, we will obtain a result
close to zero. In fact, the first request will take x seconds,
because we made the request without cookies. However, also
the second request with cookies will take roughly the same
amount of time, as no cookie were available in the browser
for the target. In this situation we can infer than both calls
were the same, indicating no previous access to the website
under inspection.
• Accessed/Logged: If the user accessed the website in the
past or if it is currently logged in into it, the result of the
comparison of the time taken by the two request will be
different from zero. As we are not using absolute values,
but only time differences between consecutive requests, our
technique can compensate for differences due to different
network delays or workloads.
A more fine-grained classification to distinguish between
previous access and current login is also possible if the at-
tacker has information about the different time required for
specific actions. We will investigate this option and provide
more details in the comparison phase section.
The algorithm (see Figure 3) takes one parameter n that indicates
the number of comparisons to perform. As servers can have specific
changes in their workload for many different reasons independent
of our tests, we decided to obtain more than one simple comparison.
Clearly, the more comparisons the attacker is able (or willing) to
perform, the more precise is the model of the server-side compu-
tation she can obtain. Nevertheless, there is an obvious trade-off
between the time spent in fingerprinting a singe website and the
number of websites the attacker wants to test. We will investigate
different options and the impact of the number of comparisons on
the accuracy of the classification in Section 4.
3.2 Comparison Phase
As explained in the previous section, our code performs a number
of measurements by timings different HTTP requests for a target
website. By subtracting each pair of requests, with and without
cookie, we obtain an array of n time deltas.
In order to classify this data, we need to obtain a ground truth
dataset for the selected websites. To this end, we need to retrieve the
computing time information for each of the cases we are interested
to detect. By using this information, we can then statistically test
whether a set of measurements belong to one group or another,
simply by computing a T-test over the two data samples. A T-test
is a two-sided test for the null hypothesis that two samples have
identical average values. The result tells us which of the three
presented cases does a certain experiment belongs to.
3.3 BakingTimer’s Resolution
Before we started our large scale experiments, we wanted to exper-
imentally verify that our hypothesis is correct and that the time
difference among different server functionalities can be successfully
distinguished over a long-distance network connection. For this
reason we implemented a toy service based on web.py [42], a sim-
ple but powerful Python framework that has been used by famous
websites such as Reddit and Yandex. In our example, we controlled
the time spent in each path. All HTTP requests sent to the service
were issued from a browser located in a different country of where
the server was located (Spain and France respectively), to avoid
any possible bias introduced by short-distance connections. The
average ping time among the two machines was 13.6 milliseconds.
The server-side application consist in less than 10 lines of code
with just a single Python function. In this function, we receive the
GET requests, and using the web.cookies method, we are able to
check if the request includes any cookie, and its value. The service
was designed to introduce no delay for requests without cookies,
and a configurable delay (ranging from 1 to 6 milliseconds in our
tests) to the processing of any request containing cookies. The
specific delay was indicated using that same cookie, which was
created with JavaScript thought document.cookie. We were able
to control the introduced delay invoking the function sleep from
the Python time library.
The results of our experiments are summarized in Figure 4. The
graphs show that it is possible to detect the time the server spent
Sheet1Page 1012345610.870.550.330.20.0420.01501234560.010.11Delay (ms)P-valueACSAC ’19, December 9–13, 2019, San Juan, PR, USA
Iskander Sanchez-Rola, Davide Balzarotti, and Igor Santos
processing each request quite precisely (see Figure 4a), despite the
network load. However, with delays below four or five millisec-
onds, the difference among the two sets of requests measured by
the browser is not statistically significant and therefore an attacker
could not conclude whether or not cookies were present in the
browser for the target website (see Figure 4b). Instead, if the differ-
ence between two paths was equal or above five milliseconds, then
even over a long distance connection, it was possible to reliably
tell the difference between the two cases. This indicates that it is
not necessary for a website to perform complex computations to be
vulnerable to our technique and even looking up some data from a
database may be sufficient to make it vulnerable to our attack. Ob-
viously, less optimized servers are more prone to incur into larger
delays that are easier to observe remotely, while high-end servers
may make the path detection more difficult and error prone. We
will analyze all these situations in the following section.
4 EXPERIMENTS
In most of the previous studies on history sniffing, the authors
limited their experiments to just few selected websites. This poor
coverage is mainly due to the fact that existing solutions could
generally only distinguish between two states: currently logged in
or not logged in. As a result, experiments required the authors to
manually create accounts for different services, thus reducing the
number of websites that could be tested.
Our technique allows instead to distinguish among multiple
states, and in particular to differentiate between websites that have
been previously visited by the victim from those that have not.
Therefore, on top of performing a login detection case study (de-
tailed in Section 6), we also conducted a large scale experiment to
measure the percentage of different websites that are vulnerable to
our attack.
The dataset used in our tests consists of two different groups:
(i) highly accessed websites and (ii) websites related to sensitive
information that users may want to keep private. For the first group
we selected websites from the Alexa [3] Top5K list, to verify whether
extremely popular services are also vulnerable to our timing side-
channel attack. The second group is composed instead by websites
that can be used to detect private personal information of the user,
such as medical or religious websites. We used categories defined
as sensitive in various data protection laws [14, 15, 27]. Since many
of the entries in this group are not included in the Alexa Top1M,
we could also check if not highly accessed websites are more or
less vulnerable than highly accessed ones.
4.1 Domain Selection
We first populated our list of personal information websites by
performing various queries obtained through the auto-complete
option offered by different search engines (e.g., “cancer treatment
side effects”). We made five different queries for the following six
categories: medical, legal, financial, sexual identity, political, and
religion. Our tool issues each query on four search engines (Google,
Bing, Yandex, and DuckDuckGO) and retrieved the top 100 results
from each of them.
To avoid an overlapping between the two lists, we removed from
this group domains that also belonged to the Alexa Top10K list.
We also removed any website that appeared in multiple categories,
as we wanted to focus only on specific areas in isolation. Finally,
we obtained a set of 5,243 unique personal information websites.
In order to balance the two groups in the dataset, we selected the
same number of websites from the Alexa top list. The combination
of the two groups resulted in a final dataset of 10,486 websites.
4.2 Methodology
We implemented our BakingTimer proof-of-concept by using a
custom crawler based on the well-known web browser Chrome,
without using any flag that may influence the network connectivity
in any way. We can perform multiple actions using the Chrome
debugging protocol (with the remote-debugging-port parameter),