title:On Safety in Discretionary Access Control
author:Ninghui Li and
Mahesh V. Tripunitara
On Safety in Discretionary Access Control
Ninghui Li
Mahesh V. Tripunitara
Department of Computer Sciences and CERIAS
Purdue University
West Lafayette, IN, USA
{ninghui,tripunit}@cerias.purdue.edu
Abstract
An apparently prevailing myth is that safety is unde-
cidable in Discretionary Access Control (DAC); there-
fore, one needs to invent new DAC schemes in which
safety analysis is decidable. In this paper, we dispel this
myth. We argue that DAC should not be equated with
the Harrison-Ruzzo-Ullman access matrix scheme [10],
in which safety is undecidable. We present an efﬁcient
(running time cubic in its input size) algorithm for decid-
ing safety in the Graham-Denning DAC scheme [8], which
subsumes the DAC schemes used in the literature on com-
paring DAC with other access control models. We also
counter several claims made in recent work by Solworth
and Sloan [27], in which the authors present a new ac-
cess control scheme based on labels and relabelling and
assert that it can implement the full range of DAC models.
We present a precise characterization of their access con-
trol scheme and show that it does not adequately capture
a relatively simple DAC scheme.
1. Introduction
Safety analysis, ﬁrst formulated by Harrison, Ruzzo,
and Ullman [10] for the access matrix model [13, 8], has
been recognized as a fundamental problem in access con-
trol. Safety analysis decides whether rights can be leaked
to unauthorized principals in future states. Safety analysis
was shown to be undecidable in the HRU scheme. Since
then, considerable research effort has gone into designing
access control schemes in which safety analysis is decid-
able [1, 2, 5, 11, 17, 19, 20, 23, 24, 25, 26, 27, 29, 30].
Safety analysis is particularly interesting in DAC [6, 7, 8,
9], in which a subject gets rights to resources at the dis-
cretion of other subjects. Recently, there appears to be re-
newed interest in the topic of safety in DAC, as evidenced
by the work by Solworth and Sloan [27], which was pub-
lished at the IEEE Symposium on Security and Privacy
1
in 2004. In that work, the authors assert that, in general,
safety is undecidable in DAC, and use this assertion as the
motivation for introducing a new access control scheme
based on labels and relabelling that has decidable safety
properties.
Our goals in this paper are to present a clear picture of
safety in DAC and to counter several claims in Solworth
and Sloan [27], that we demonstrate to be erroneous. The
work in Solworth and Sloan [27] is based on the premise
that safety is undecidable in DAC; therefore, one needs
to design new schemes for DAC so that safety analysis is
decidable. We assert that this premise is a myth, and con-
jecture that the basis for this myth is that DAC is some-
times erroneously equated to the HRU scheme [10] (for
instance, in work such as [18, 22]). As we discuss in
Section 3, DAC cannot be equated to the HRU scheme
for the following reasons. First, the HRU scheme can be
used to encode schemes that are not DAC schemes; there-
fore, the fact that safety is undecidable in the HRU scheme
should not lead one to conclude that safety is undecid-
able in DAC. Second, features in DAC cannot always be
encoded in the HRU scheme. For example, some DAC
schemes require that each object be owned by exactly one
subject; thus removal of a subject who has the ownership
of some objects requires the transfer of ownership to some
other subject (often times the owner of the subject being
removed) so that this property is maintained. Both the re-
moval of the subject and the transfer of ownership of ob-
jects it owns occur in a single state-change. A single HRU
command cannot capture these features, because it cannot
loop over all objects owned by a subject.
We dispel the myth that safety is undecidable in DAC
by presenting an efﬁcient algorithm for deciding safety in
the DAC scheme proposed by Graham and Denning [8].
Our algorithm runs in time cubic in the size of the in-
put. The Graham-Denning scheme is, to our knowledge,
the ﬁrst DAC scheme to have been proposed, and sev-
eral other DAC schemes proposed subsequently are ei-
ther subsumed by or are simple extensions of the Graham-
Denning scheme. Examples of such DAC schemes in-
clude those used by Osborn et al. [21] to show that
RBAC can be used to implement DAC. The same schemes
are used by Solworth and Sloan [27] to show that the
Solworth-Sloan scheme can implement DAC. Our algo-
rithm suggests that safety in these DAC schemes can be
efﬁciently decided and there is no need to invent new ac-
cess control schemes with decidable safety as the primary
goal.
Some may hold the view that safety can be trivially de-
cided in DAC schemes. For instance, if the owner of an
object is untrusted, then he can grant rights over the ob-
ject to any other subject. Therefore, if such an owner ex-
ists, then the system will be unsafe for that object. While
it may be easy to identify one or two such conditions that
make a DAC system unsafe, identifying all such condi-
tions may not be trivial. To our knowledge, algorithms for
deciding safety in the Graham-Denning or other derived
DAC schemes have not appeared in the literature. The
proof that our algorithm is correct, which is in our techni-
cal report [15], was not trivial for us.
We observe that the presentation in [27] does not
clearly specify what information is maintained in a state,
how states may change, and the precise construction to im-
plement DAC in the scheme. In this paper we give a pre-
cise characterization of the Solworth-Sloan scheme and an
implementation of the SDCO scheme [21] in it. (Solworth
and Sloan [27] use the word “implement” in this context,
and therefore, we do the same. In previous work in the
comparison of different access control schemes, “simula-
tion” appears to be the preferred terminology.) We be-
lieve that a precise characterization of the Solworth-Sloan
scheme is of interest independent of an assessment of its
effectiveness in implementing other DAC schemes. The
publication of two papers [27, 28] based on this scheme
in recent major security conferences reﬂects that there is
interest in such a access control scheme based on labels
and relabelling.
Our precise characterization enables us to assess how
effectively the Solworth-Sloan scheme implements the
SDCO scheme. We counter several claims from Solworth
and Sloan [27], and demonstrate that the claims are erro-
neous. Solworth and Sloan [27] claim that theirs is the ﬁrst
general access control model which both has a decidable
safety property and is able to implement the full range of
DAC models. We show that the proposed implementation
of DAC schemes in the Solworth-Sloan scheme has signif-
icant deﬁciencies. Two particular limitations that we dis-
cuss are the lack of support for removing subjects and ob-
jects and the inability to ensure that an object has only one
owner, as required by DAC schemes such as Strict DAC
with Change of Ownership (SDCO), which is a simpliﬁed
version of the Graham-Denning scheme. We observe also
that the implementation incurs considerable overhead. Es-
sentially for each new object to be created, a data structure
of the size exponential in the total number of rights needs
to be created.
The remainder of this paper is organized as follows. We
discuss related work in Section 2 and give precise deﬁni-
tions of safety analysis in DAC in Section 3. In Section 4,
we study safety analysis in the Graham-Denning scheme.
We analyze the Solworth-Sloan scheme in Section 5 and
conclude in Section 6.
2. Related Work
There is considerable work on DAC and safety anal-
ysis. To our knowledge, Graham and Denning [8] pro-
posed the ﬁrst DAC scheme. Their scheme is based on the
work by Lampson on the access matrix model [13]. Sub-
sequently, Grifﬁths and Wade proposed their DAC scheme
for relational database systems [9]. Downs et al. [7] dis-
cussed salient aspects of DAC, and their work was sub-
sequently subsumed by the NCSC’s guide to DAC [6].
Lunt [18] examined various issues in DAC as part of
broader work on issues in access control. Samarati and de
Capitani di Vimercati [22] included discussions on DAC
in their treatment of access control. Osborn et al. [21]
discussed several DAC schemes that are sub-cases or vari-
ants of the Graham-Denning scheme in their comparison
of DAC to RBAC. DAC was extended to include temporal
constructs by Bertino et al. [3, 4]. Solworth and Sloan [27]
presented a new DAC scheme based on labels and rela-
belling rules. The same scheme was also used by Solworth
and Sloan in [28].
Safety is a fundamental property that was ﬁrst proposed
in the context of access control by Harrison et al. [10].
Subsequently, there has been considerable work on safety
in various contexts related to security [1, 2, 5, 11, 14, 16,
17, 19, 20, 23, 24, 25, 26, 27, 29, 30]. Recent work by
Li et al. [14, 16] perceived various forms of safety as spe-
cial cases of more general security properties, and safety
analysis is subsumed by security analysis. In this paper,
we adopt this perspective in deﬁning safety analysis in the
next section. To our knowledge, the work by Solworth
and Sloan [27] was the ﬁrst to directly address safety in
DAC. Other work on safety has been on speciﬁc schemes
such as the HRU scheme [10], the ESPM scheme [1] and
a trust management scheme [16]. Furthermore, to our
knowledge, there is no prior work on safety analysis in
the context of speciﬁc DAC schemes such as the Graham-
Denning scheme [8].
3. Deﬁning Safety Analysis in DAC
In this section, we deﬁne access control schemes and
systems, and the general problem of security analysis in
the context of such schemes and systems. We then deﬁne
2
safety analysis as a special case of security analysis. In
our deﬁnitions, we adopt the meta-formalism introduced
by Li et al. [16, 14].
Deﬁnition 1 (Access Control Schemes and Systems)
An access control scheme is a four-tuple hΓ, Ψ, Q,`i,
where Γ is a set of states, Ψ is a set of state-change rules,
Q is a set of queries and `: Γ × Q → {true, false} is the
entailment function, that speciﬁes whether a propositional
logic formula of queries is true or not in a state.
A state-change rule, ψ ∈ Ψ, determines how the access
control system changes state. Given two states γ and γ1
and a state-change rule ψ, we write γ 7→ψ γ1 if the change
from γ to γ1 is allowed by ψ, and γ ∗7→ψ γ1 if a sequence
of zero or more allowed state changes leads from γ to γ1.
An access control system based on a scheme is a state-
transition system speciﬁed by the four-tuple hγ, ψ, Q,`i,
where γ ∈ Γ is the start (or current) state, and ψ ∈ Ψ
speciﬁes how states may change.
We recognize that our formalism for schemes and sys-
tems is fairly abstract. Nonetheless, we need such a for-
malism to be able to represent disparate access control
schemes, such as those based on the access matrix, role-
based access control and trust management approaches.
When we specify a particular access control scheme, we
specify each component precisely, using constructs that
are well-understood.
An example of an access control scheme is the HRU
scheme [10], in which the state consists of a ﬁnite set of
subjects, a ﬁnite set of objects, and an access matrix with
a row for each subject and a column for each object. Each
cell in the access matrix is the set of the rights a subject
has over the corresponding object. Examples of queries,
q1, q2 ∈ Q in the HRU scheme are “q1 = r ∈ M[s, o]”
and “q2 = r0 ∈ M[s, o]”. The queries q1 and q2 ask
whether the subject s has the right r and r0 over the object
o, respectively. Given a state, γ, and a state-change rule,
ψ, in an HRU system, let Sγ be the set of subjects that
exist in the state, γ, Oγ be the set of objects that exist,
Mγ[ ] be the access matrix, and Rψ be the set of rights in
the system. Then, γ ` q1∧¬q2 if and only if s ∈ Sγ ∧ o ∈
Oγ ∧ r ∈ Mγ[s, o] ∧ r0 6∈ Mγ[s, o].
One of the components of our characterizations of se-
curity and safety analysis below warrants some explana-
tion. Each instance of the analysis is associated with a set
T of trusted subjects. The meaning of a trusted subject
is that we preclude state-changes initiated by any subject
from T in our analysis. The intuition is that we expect
these subjects to be “well-behaved”. That is, while such
subjects may effect state-changes, they do so in such a
way that the state that results from the state-changes they
effect satisﬁes desirable properties (e.g., safety). Harri-
son et al. [10] do consider trusted subjects as part of their
safety analysis. Nonetheless, as pointed out previously
by Li et al. [16], the way they deal with trusted sub-
jects is incorrect. They require that we delete the rows
and columns corresponding to trusted subjects prior to the
analysis. While a trusted subject is not allowed to initiate a
state-change, she may be used as an intermediary, and the
way Harrison et al. [10] deal with trusted subjects does
not consider this possibility. In this paper, we require only
that a member of the set of trusted subjects not initiate a
state-change. In all other ways, these subjects continue to
be part of the system.
Deﬁnition 2 (Security Analysis) Given an access con-
trol scheme hΓ, Ψ, Q,`i, a security analysis instance is of
the form hγ, ψ,T , ¤φi, where φ is a propositional logic
formula of queries and ¤ stands for “in the current and all
future states,” and is an operator from temporal logic [12].
Given such an instance, we say that the instance is true if
for all states γ0 such that γ ∗7→ψ γ0, γ0 ` φ. That is, φ
represents a security invariant that must be satisﬁed in all
states reachable from γ under ψ, with no state change ini-
tiated by a user from the set T , for the instance to be true.
Otherwise, the instance is false.
Harrison et al. [10] informally characterize safety as
the condition “that a particular system enables one to keep
one’s own objects ‘under control’ ”. This informal char-
acterization seems to be appropriate as a security property
of interest in DAC systems, as the very purpose of DAC
is that subjects should be able to keep objects that they
own, under their control. More formally, safety analysis is
a special case of security analysis, where the invariant is
that an unauthorized subject should not have a particular