### Generating and Managing Nyms

To generate a new Nym, the servers submit a fresh public key to a verifiable shuffle. From the shuffled output, they randomly select one re-encrypted key to be the new Nym, discarding all other keys. For efficiency, we prefer to generate Nyms in batches, thereby amortizing the cost of the shuffle across multiple lotteries. This ensures that each Nym is assigned independently.

One approach to achieve this is for the servers to mint a batch of e-cash "coins" [10], encrypting each coin to a random key from the shuffle's output. A verifiable DC-nets round [13, 27] is then run, with one slot per coin. The "winner" of each coin can spend it and publish a fresh public Nym key. Further exploration of this method is left for future work.

### Extending Nyms Across Epochs

To enable Nyms to persist beyond a single epoch, clients can use each winning ticket from a Nym lottery either to publish a fresh Nym key or to re-publish an old Nym key, effectively "reviving" the old Nym and providing it with a transmission slot in the new epoch. A lottery winner might also publish another user's public Nym key, delegating the winning ticket's share of bandwidth in the new epoch to an arbitrary Nym whose content the lottery winner finds interesting.

When a client revives its own Nym in a new epoch, it must ensure that the set of users participating in the Nym lottery is consistent with the existing Nym's anonymity policy. For example, the user's buddies should also be online. If some participants go offline during a Nym lottery, the servers must restart the lottery, allowing clients to re-check the new participant set before exposing an old Nym in the new epoch.

### Implementing the Policy Oracle

Implementing the Policy Oracle as a single independent server would require all clients to trust the Policy Oracle to correctly implement their requested attack mitigation policies. Although a malicious Policy Oracle cannot directly de-anonymize users, it could make intersection attacks easier. To mitigate this, Buddies leverages the anytrust server model, running a virtual replica of the Policy Oracle in lock-step on each anonymization server. The servers use standard distributed accountability techniques [28] to cross-check each other's computation of Policy Oracle decisions, halting progress and raising an alarm if any server deviates from the agreed-upon deterministic algorithm.

### Identifying Users to the Policy Oracle

Buddies' Anonymizer shares the set of currently online users with the Policy Oracle, treating these online sets as public information. Revealing actual user identities, such as public keys or IP addresses, risks strengthening a weak adversary into an "omniscient" adversary for intersection attack purposes.

Buddies addresses this by permitting clients to authenticate via linkable ring signatures [24, 35]. Each client generates a cryptographic proof that it holds the private key corresponding to one of a ring of public keys, without revealing which key it holds. Additionally, the client generates and proves the correctness of a linkage tag, which has a 1-to-1 relationship with the clientâ€™s private key but is cryptographically unlinkable to any of the public keys without knowledge of the corresponding private keys. The servers track which clients are online via their linkage tags and provide only the list of online tags to the Policy Oracle, simulating an adversary's intersection attacks without knowing which actual users are online.

### Malicious Users and Sybil Attacks

While Buddies can measure and enforce a lower bound on the number of users in a Nym's possinymity or indinymity set, it cannot guarantee that all those users provide useful anonymity. If a Nym owner specifies a minimum buddy-set size of K, but up to F other clients may be colluding with the adversary, the actual minimum anonymity set size may be as little as K - F. Since users cannot reliably know how many other clients are conspiring against them, F is treated as an unknown variable that users must factor into their choices of possinymity or indinymity lower bounds.

Random buddy-set formation (Section 3.2) may reduce vulnerability to malicious clients by ensuring that malicious users are evenly distributed among buddy-sets. In reputation-based formation schemes, attackers might deliberately exhibit similar reliability to get clustered together in the owner's buddy set. However, this requires the malicious users to be present at the Nym's creation and adjust their reliability profile before too many buddy set splits occur.

Sybil attacks, where an attacker creates many fake user identities, can amplify the number of malicious clients. Buddies addresses this by requiring users to authenticate via linkable ring signatures as owners of "real" identities in a Sybil attack-resistant identity space. The current prototype is defined for closed groups, with a static roster of public keys listing all members. For open-ended groups, Buddies could build on Sybil attack resistance schemes based on social networks [48, 54] or rate-limit Sybil attacks via barriers to entry, such as CAPTCHAs or phone callbacks.

### Evaluation

We evaluate Buddies' utility using data collected from popular public IRC chat rooms on EFnet servers. We first explore "ideal" metrics quantifying achievable anonymity levels under given conditions, independent of specific Buddies policies or loss mitigation algorithms. We then apply these traces to an event-based Buddies simulator to evaluate more realistic policies against these ideals, considering naive anonymous posting, policies enforcing minimum buddy-set sizes, and policies maximizing possinymity.

### Datasets and Simulation Methodology

To evaluate Buddies' utility, we use traces from popular public IRC chat rooms on EFnet servers. Unlike web traffic, IRC logs record participants' online status, which is critical for systems like Buddies. We monitored 100 of the most active EFnet-based IRC rooms over a month, obtaining joins, leaves, nickname changes, and messages for each member. We implemented an event-driven Buddies simulator in Python, called the Anonymity Simulator (AS), which plays the role of users, the Anonymizer, and the Policy Oracle. The AS takes an IRC trace, time between rounds, system-wide buddy and possinymity set sizes, and buddy set formation policies as input.

### Ideal Anonymity Analysis

Using our IRC traces, we explore upper bounds on the anonymity achievable in any system resistant to intersection attacks, independent of specific mechanisms or policies. This analysis deepens our understanding of user behavior in realistic online forums and establishes realistic expectations for what a system like Buddies might achieve in principle. We consider low-latency communication using pseudonyms of varying lifetimes and long-lived pseudonyms in scenarios that can tolerate varying offline times in members of anonymity sets.

For low-latency pseudonyms, we focus on the football dataset, treating each contiguous online period lasting at least time x as a pseudonym with lifetime x. We compute an ideal anonymity set for that pseudonym as the total number of users also contiguously online during that pseudonym's lifetime. Figure 3(a) summarizes the distribution of these ideal anonymity set sizes, showing that substantial resistance to intersection attacks may be achievable for short-lived pseudonyms in large forums. Achievable anonymity falls off rapidly as pseudonym lifetime increases.

For long-lived pseudonyms, applications that demand truly long-lived pseudonyms, even with tolerance for offline periods, face significant challenges in maintaining large anonymity sets.