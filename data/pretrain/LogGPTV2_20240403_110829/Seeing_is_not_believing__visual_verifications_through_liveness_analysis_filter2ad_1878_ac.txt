### Video Motion Analysis and Calibration

**Figure 6: Video Motion Analysis and Calibration**

The Video Motion Analysis (VMA) module has a limited ability to determine the average speed of device motion. To address this, we use the average speed calculated from the inertial sensor motion vector to calibrate the video motion vector. Figure 6 illustrates the effect of calibration on the similarity computation.

- **(a) No Calibration:** The raw data without any calibration.
- **(b) Truncated Mean Calibration:** The ratio of each pair of points in the sensor and video vectors is computed, and the truncated mean (discarding 12.5% from both ends of the distribution) is used for calibration.
- **(c) Curve Fitting Calibration:** Polynomial curve fitting is applied to find the best fit for the data points. The least squares method is used to minimize the error between the data and the fitted polynomial. The calibration factor \( CF \) is computed as the ratio of the average value over the points on the fitted curve for the sensor stream (\( SP_s \)) to the average value of the points on the curve of the video stream (\( SP_v \)):

\[ CF = \frac{SP_s}{SP_v} \]

### Calibration Methods

#### Truncated Mean Calibration
For each pair of points in the sensor and video vectors:
1. Compute their ratio.
2. Add it to a ratio vector.
3. Compute the truncated mean of the ratio vector, discarding 12.5% from both the low and high ends of the distribution.

#### Polynomial Curve Fitting
- **Polynomial Curve Fitting [21]:** Constructs the polynomial that best fits a series of data points.
- **Least Squares Method [21]:** Minimizes the error between the data and the fitted polynomial.
- **Calibration Factor Calculation:**
  - Let \( SP_s \) denote the average value over the points on the fitted curve for the sensor stream.
  - Let \( SP_v \) denote the average value of the points on the curve of the video stream.
  - The calibration factor \( CF \) is computed as:

\[ CF = \frac{SP_s}{SP_v} \]

Figures 6(b) and 6(c) show sample calibration outputs for these two methods, compared to the uncalibrated version in Figure 6(a).

### Example Alignment

To illustrate the need for Dynamic Time Warping (DTW), stretching, and calibration, we provide experimental results using a genuine sample of video and inertial sensor streams captured with Movee (see Section 4 for implementation details).

- **Figure 5(a):** Alignment between the video and inertial sensor streams when only DTW is used.
- **Figure 5(b):** Resulting alignment when DTW and stretching are applied.
- **Figure 5(c):** Alignment achieved when DTW, stretching, and calibration are all applied.

The experiment demonstrates that stretching is essential for achieving good alignment, while calibration further improves the quality of the alignment.

### Classification

The Similarity Computation module generates 14 features that represent the nature of the similarity between the motion information inferred from the video stream and the inertial sensor data. These features include:

1. Movement direction of the target from the center of the screen.
2. Cumulative shift of the video and accelerometer on the x and y axes (4 descriptors).
3. Video motion direction.
4. Sensor motion direction.
5. DTW distance after stretching and calibration steps.
6. Calibration factor, \( CF \).
7. Normalized penalty cost.
8. Ratio of overlap points.
9. Ratio of diagonal moves.
10. Ratio of expansion moves.
11. Ratio of contraction moves.

The Classification module uses trained classifiers to determine if there is sufficient evidence that the video stream is genuine. The classifiers used in our experiments are described in Section 6.2.

### Movee Implementation

We have implemented a Movee client using Android and a server component using C++ and PHP. The OpenCV library is used for video motion analysis. The client allows users to capture movies and simultaneously provide proofs of liveness. Figure 7 shows a snapshot of Movee in action.

- **Initial Screen:** Instructs the user to hold the device firmly before pressing the start button to prevent initial accelerometer reading errors.
- **Target (Bullseye):** Appears once the user presses the start button. The user is instructed to move the camera in the direction of the target.
- **Verification Step:** After 6 seconds, the target disappears, and the verification step begins. During this step, the Movee client captures the video stream and logs the accelerometer data.
- **Post-Verification:** The user can continue capturing the intended scenes. The Movee client only captures data during the verification interval, which is sent to the server.

We chose a 6-second verification interval inspired by Vine, an application that allows users to create and post video clips. This choice keeps the video file size small (around 150 KB on the Samsung Admire Phone), reducing communication overheads.

### Applications

- **Citizen Journalism:** Movee can be used with trusted location and time verification solutions to verify claims made by video uploaders.
- **Smarter Cities, Mobile 311:** Movee can act as a witness to the genuineness of reported cases, eliminating the need to wait for multiple reports.
- **Prototype Verification:** Movee can be used to verify the liveness of footage provided as evidence in promotion videos.

### Evaluation

#### Data Collection
We collected video and accelerometer samples using the Movee application. The Samsung Admire smartphones (Android OS Gingerbread 2.3 with 800MHz CPU) were used, sampling accelerometer readings at 16.67Hz.

#### Experimental Setup
The Classification module uses three classifiers: Multilayer Perceptron (MLP), Decision Tree (C4.5), and Random Forest (RF). We applied 10-fold cross-validation tests to assess the generalization of the results.

#### Metrics
- **Receiver Operating Characteristic (ROC) Curve:** Visual characterization of the trade-off between the False Accept Rate (FAR) and the False Reject Rate (FRR).
- **Equal Error Rate (EER):** The rate at which both accept and reject errors are equal. A lower EER denotes a more accurate solution.
- **Area Under the ROC Curve (AUC):** A measure of the classifier's performance.

### Summary
- **Mixed Dataset:** Contains 50 genuine and 50 fraudulent samples created according to the Random attack.
- **Hard Dataset:** Contains 50 genuine and 50 fraudulent samples created according to the Direction Sync attack.

These datasets and metrics help evaluate the accuracy and robustness of Movee in detecting fraudulent video streams.