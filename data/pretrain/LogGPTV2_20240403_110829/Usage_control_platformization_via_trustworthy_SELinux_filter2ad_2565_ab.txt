same in the policies before and after a transformation.
Requirement 5: Build trust chain for policy enforcement from
246
Usage(cid:13)Control(cid:13)Policies(cid:13)Data/service provider(cid:13)(usage control policy stakeholder)(cid:13)Target platform(cid:13)(usage control enforcement)(cid:13)Object(cid:13)Object(cid:13)Trusted(cid:13)subsystem(cid:13)MAC(cid:13)Policies(cid:13)Policy(cid:13)boot to applications High assurance of a subsystem in a remote
computing platform should origin from a root-of-trust, and then
is extended to other system components through which policy
enforcement mechanism is built. Typically, MAC mechanism
is implemented in the kernel of the operating system (OS) on
a platform. Thus, a trusted subsystem should include a trusted
kernel and any other components booted before kernel, such as
BIOS and boot loader. To obtain the trust of a MAC mechanism
in a trusted subsystem, any other supporting components should
also be trusted, including policy transformation and management,
subject and object attribute acquisition, and the reference monitor
itself. The fundamental goal of this trust chain is to achieve a
trusted runtime environment for object access where the integrity
of all related parts can be veriﬁed by a stakeholder.
Requirement 6: Built trusted subsystem with minimum trusted
computing base Related to above requirement, to build practical
and usable trusted subsystem, minimum trusted computing base
(TCB) is desired. TCB includes all the components in the trust
chain for policy enforcement during runtime. A large component
in this chain results in high cost both on system development
and veriﬁcation since each trusted component requires detailed
veriﬁcation of the software implementation.
Our work follows these principles. Speciﬁcally, we propose
a platform architecture with mandatory and minimum compo-
nents. Our implementation is built with emerging trusted comput-
ing technologies with hardware-based root-of-trust. We leveraged
the MAC mechanism in SELinux for policy enforcement, and we
also develop a policy transformation mechanism from high level
XACML policies to SELinux policies with an extended MAC pol-
icy model. Due to space limit, we just give an high-level view of
our platform architecture in next section.
3. PLATFORM ARCHITECTURE
A trusted subsystem includes a root-of-trust, trust chain, and pol-
icy transformation and enforcement mechanism, and runtime in-
tegrity measurement mechanism. Figure 2 shows a target platform
architecture to enforce usage control policies. The hardware layer
includes a Trusted Platform Module (TPM), a Core Root of Trust
Measurement (CRTM), and other devices. The TPM and CRTM
provide the hardware-based root-of-trust for the whole platform.
Similar to trusted or authenticated boot [11, 21], the booting com-
ponents of the platform, including BIOS, boot loader, and operat-
ing system (OS) kernel, are measured and their integrity values are
stored in particular Platform Conﬁguration Registers (PCRs) of the
TPM. Speciﬁcally, according to TCG speciﬁcation [2], the CRTM
is the ﬁrst component to run when the platform boots. It measures
the integrity of BIOS before BIOS starts, which in turn, measures
the boot loader and then in turn the kernel and kernel modules,
recursively. Along this booting and measurement sequence, partic-
ular PCR(s) are extended with the measured values, and the result
is denoted as P CRboot. TPM guarantees that P CRboot is reset
once the platform re-boots.
Upon a user’s request on the target platform, a client application
(e.g., a healthcare client software) is invoked to communicate with
a data owner/provider to obtain an object. At the same time, a pol-
icy can be downloaded by the client application from a stakeholder,
which can be the same as the data provider or not. For example, a
data provider can delegate its policy speciﬁcation and enforcement
to a security service provider, which is the policy stakeholder when
an object is downloaded and processed in a client platform.
When a usage control policy (e.g., an XACML policy ﬁle) is
Figure 2: Platform architecture for usage con-
trol policy enforcement
downloaded from its stakeholder, it is transformed by the policy
transformation component to MAC policies such that they can be
enforced by the reference monitor. The client application is the
target process that can manipulate the object and is to be protected
by MAC policies. Also, MAC policies should also include the rules
to control accesses to the object from others and any conﬁgurations
for the client application and the overall security system (e.g., local
security policy management).
As aforementioned, usage control policies typically include en-
vironmental authorization factors such as time and location. A sen-
sor is a component that sends these environmental information to
the policies and thus can be considered. For example, in a mobile
application where a service only can be accessed in a particular
location, the sensor reports the physical (e.g., through a cellular
network provider or GPS ) or logical (e.g., through a Wi-ﬁ access
point) location of the device, such as home, ofﬁce, and an airport.
In the kernel level of the platform, the reference monitor cap-
tures every possible access attempt to the object and queries the
MAC policies before allows the access. A fundamental require-
ment for the reference monitor is that it has capture all kinds of
access attempts, from storage in the local ﬁle system to the mem-
ory space of the object. Also, the reference monitor controls the
interactions between the client application and others, locally and
remotely, according to loaded MAC policies.
The integrity measurement service (IMS) is a mandatory com-
ponent in a trusted subsystem, which starts right after the kernel is
booted. The main function of IMS is to measure mandatory compo-
nents which consist of the TCB to enforce usage control policies.
All measured events and the integrity values are stored in a mea-
surement list and corresponding PCRs are extended. Particularly,
• The reference monitor is measured after the kernel is booted.
• The client application, object, and conﬁgurations are mea-
sured right before the client application is invoked.
• The integrity of usage control policy (e.g., XACML policy
ﬁle downloaded from its stakeholder), policy transformation
247
Hardware(cid:13)Kernel(cid:13)Device(cid:13)Device(cid:13)MAC(cid:13)Policies(cid:13)Integrity(cid:13)Measurement(cid:13)Service(cid:13)Configurations(cid:13)Object(cid:13)Client Application(cid:13)Usage Control Policy(cid:13)(e.g., XACML Policy )(cid:13)Policy(cid:13)Transformation(cid:13)Service(cid:13)Sensor(cid:13)Reference(cid:13)Monitor(cid:13)Integrity(cid:13)Verification(cid:13)Service(cid:13)TPM(cid:13)CRTM(cid:13)service, and the sensor are measured when they are invoked
and before run.
• MAC policies are measured when they are loaded, either
when the platform boots or during runtime (i.e., loaded by
the policy transformation service).
• Any other applications or services that communicate with the
client application.
In general, to only allow accesses to a target object from au-
thorized application, and control the information ﬂow between this
application and others, IMS should measure not only the policy
enforcement services such as policy transformation and platform
sensor, but also all applications that interacts with the client appli-
cation running on the same platform.
As part of policy speciﬁcations, integrity veriﬁcation service ver-
iﬁes corresponding integrity values measured by the IMS and gen-
erates inputs to the reference monitor. As a typical example, the
client application only can access the target object when its “cur-
rent” integrity is a known good value, where the current integrity is
the one measured by the IMS.
Note that although we use data objects (e.g., ﬁles) through this
paper, our usage control mechanism is applicable to other types of
objects such as messages and streams. The essential requirement
for the object is that its authenticity and integrity can be veriﬁed
such that, as an input for the application on a client platform, the
initial state of the platform can be trusted.
4. CONCLUSIONS AND FUTURE WORK
Usage control focuses on the problem of enforcing security poli-
cies on a remote client platform with high assurance and veriﬁable
trust. In this paper we identiﬁed general security requirements for
usage control and proposed a general framework for this problem.
The main idea of our approach is to build a trusted subsystem on
an open platform such that a policy stakeholder can deploy sensi-
tive data and services on this subsystem. We propose an architec-
ture with a hardware-based TPM as the root-of-trust and consider
integrity measurement/veriﬁcation and other environmental restric-
tions in our MAC policy model.
We are implementing a prototype system based on a mobile ref-
erence platform. We are also exploring automated policy trans-
formations in mobile computing environment. In addition, as our
architecture is extensible, extra components can be included in the
TCB of a trusted subsystem for increasing security requirements.
Particularly we are investigating how to enforce some kind of obli-
gation policies in our architecture.
5. REFERENCES
[1] Fairplay. http://en.wikipedia.org/wiki/FairPlay.
[2] TCG Speciﬁcation Architecture Overview.
https://www.trustedcomputinggroup.org.
[3] Windows media digital rights management (DRM).
http://www.microsoft.com/windows/windowsmedia
/drm/default.aspx.
[4] M. Abadi, M. Burrows, and B. Lampson. A calculus for
access control in distributed systems. ACM Transactions on
Programming Languages and Systems, 15(4):706–734, 1993.
[5] J. P. Anderson. Computer security technology planning study
volume II, ESD-TR-73-51, vol. II, electronic systems
division, air force systems command, hanscom ﬁeld,
bedford, MA 01730.
http://csrc.nist.gov/publications/history/ande72.pdf, Oct.
1972.
[6] D. E. Bell and L. J. LaPadula. Secure computer systems:
Mathematical foundations and model. Mitre Corp. Report
No.M74-244, Bedford, Mass., 1975.
[7] K. J. Biba. Integrity consideration for secure computer
system. Technical report, Mitre Corp. Report TR-3153,
Bedford, Mass., 1977.
[8] Matt Blaze, Joan Feigenbaum, and Jack Lacy. Decentralized
trust management. In Proceedings of IEEE Symposium on
Security and Privacy, pages 164–173, Oakland, CA, May
1996.
[9] D. E. Denning. A lattice model of secure information ﬂow.
Communications of the ACM, 19(5), May 1976.
[10] Department of Defense National Computer Security Center.
Department of Defense Trusted Computer Systems
Evaluation Criteria, December 1985. DoD 5200.28-STD.
[11] J. Dyer, M. Lindemann, R. Perez, R. Sailer, L. van Doorn,
S. W. Smith, and S. Weingart. Building the ibm 4758 secure
coprocessor. IEEE Computer, (10):57–66, 2001.
[12] M. H. Harrison, W. L. Ruzzo, and J. D. Ullman. Protection in
operating systems. Communication of ACM, 19(8), 1976.
[13] A. Herzberg, Y. Mass, J. Mihaeli, D. Naor, and Y. Ravid.
Access control meets public key infrastructure, or: assigning
roles to strangers. In Proc. of IEEE Symposium on Security
and Privacy, pages 2–14, 2000.
[14] M. Hilty, D. Basin, and A. Pretschner. On obligations. In
Proc. of 10th European Symp. on Research in Computer
Security, September 2005.
[15] B. Lampson. Computer security in the real world. IEEE
Computer, (6):37–46, June 2004.
[16] B.W. Lampson. Protection. In 5th Princeton Symposium on
Information Science and Systems, pages 437–443, 1971.
Reprinted in ACM Operating Systems Review 8(1):18–24,
1974.
[17] N. Li, J. C. Mitchell, and W. H. Winsborough. Design of a
role-based trust-management framework. In Proc. of IEEE
Symposium on Security and Privacy, pages 114–130, 2002.
[18] P. Loscocco, S. Smalley, P. Muckelbauer, R. Taylor,
J. Turner, and J. Farrell. The inevitability of failure: The
ﬂawed assumption of computer security in modern
computing environments. In Proceedings of the National
Information Systems Security Conference, October 1998.
[19] J. Park and R. Sandhu. The UCONabc usage control model.
ACM Transactions on Information and Systems Security,
7(1):128–174, February 2004.
[20] A. Pretschner, M. Hilty, and D. Basin. Distributed usage
control. Communications of the ACM, (9):39–44, September
2006.
[21] R. Sailer, X. Zhang, T. Jaeger, and L. van Doorn. Design and
implementation of a TCG-based integrity measurement
architecture. In USENIX Security Symposium, pages
223–238, 2004.
[22] R. Sandhu. Good-enough security: Toward a pragmatic
business-driven discipline. IEEE Internet Computing,
(1):66–68, January/February 2003.
[23] R. Sandhu, K. Ranganathan, and X. Zhang. Secure
information sharing enabled by trusted computing and PEI
models. In Proceedings of ACM Symposium on Information,
Computer, and Communication Security, Taipei, Taiwan,
March 21-24 2006.
248