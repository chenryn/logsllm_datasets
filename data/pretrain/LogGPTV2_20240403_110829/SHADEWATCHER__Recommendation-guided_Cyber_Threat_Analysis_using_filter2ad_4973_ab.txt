evaluation against both real-life and simulated attack sce-
narios. The results show that SHADEWATCHER achieves
high effectiveness and efﬁciency in cyber threat analysis.
II. BACKGROUND & MOTIVATION
In this section, we use an APT attack to introduce challenges
in existing threat detection solutions. Then, we present our
insights of using recommendations to guide threat analysis.
A. Motivating Example
Browser extension with drakon dropper (Extension Back-
door for short) is an APT attack from the DARPA TC program
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 13:13:26 UTC from IEEE Xplore.  Restrictions apply. 
490
(a) System Provenance Graph
(b) Movie Recommendation
(c) High-order Information in Audit Records
Fig. 1: (a) A simpliﬁed provenance graph of Extension Backdoor, where r1, r2, r3, r4, r5, r6, and r7 denote read, write, load,
send, recv, connect, and exec, and r0 reﬂects system entity interaction. (b) An example of recommending movies for Alice, where
blue, green, and gray nodes stand for users, items, and side information. Solid/dashed blue edges show historical/recommended
user-item interactions. (c) An illustration of system entity interactions with side information to form high-order connectivities.
red team vs. blue team adversarial engagement [35]. The attack
begins with compromising a vulnerable password manager ex-
tension pass mgr in Firefox while visiting malicious websites.
The compromised extension then drops a malicious program
gtcache on disk. During execution, the program exﬁltrates user
information /etc/passwd to a public network. Meanwhile, it
implants ztmp to collect system conﬁgurations and perform a
port scan of target networks for internal reconnaissance.
Figure 1a shows a simpliﬁed provenance graph constructed
from audit records in Extension Backdoor. Nodes in the
graph represent system entities, where rectangles, ovals, and
diamonds indicate processes, ﬁles, and sockets, respectively.
Gray edges denote system calls orientated in the direction of
information ﬂows. To reduce clutter, we use two individual
nodes in lieu of /proc/pid/stat with different process IDs and
128.55.12.73 with different network ports. The provenance
graph provides a promising representation to navigate large-
scale audit records. It enables security analysts to perform
backward and forward information ﬂow tracking to discover
root causes of security incidents and their ramiﬁcations [10].
B. Challenge to Existing Solutions
Provenance-based detection excels at extracting potentially
malicious behaviors from provenance graphs. However, we
identify several inherent limitations of existing approaches.
• Statistics-based detection: Recent studies observe that se-
curity incidents in attack campaigns are usually uncommon
system activities [10]–[12]. Therefore, they quantify audit
records’ degrees of suspicion by their historical frequency.
Though simple and effective, a primary concern is the
number of false positives generated using statistical anal-
ysis. For example, when gtcache ﬁrst reads /proc/27/stat
in Figure 1a, an alarm is raised as this activity has never
been seen before, although it represents a perfectly normal
process status retrieval. From this example, it is easy to
see the key shortfall of statistics-based methods, which
is identifying audit records rare in the history of system
execution but fails to differentiate normal records from
previously unobserved yet semantically relevant activities.
• Speciﬁcation-based detection: Speciﬁcation-based detectors
hunt down cyber threats by matching audit records against
a knowledge base of security policies that describe attack
semantics. While such detection can maintain a low false-
positive rate [13], developing security policies is time-
consuming and inevitably requires domain expertise. Re-
garding our motivating example, RapSheet [14] develops
over ten hand-crafted TTPs (Tactics, Techniques, and Pro-
cedures) queries for kill chain search; Morse [17] initializes
conﬁdentiality and integrity tags of six million system en-
tities for tag propagation; Poirot [19] extracts query graphs
from a six-page cyber threat intelligence report [35] for
graph alignment. We also note that the quality of resultant
policies can be highly varied due to factors such as the
expert’s subjective interpretation of attacks, different levels
of competencies, and even just plain human mistakes.
• Learning-based detection: Current learning-based detectors
mostly train a model of benign behaviors and detect devi-
ations as cyber-attacks [20]–[23]. While these approaches
can achieve high detection accuracy by incorporating the
semantics of audit records into threat analysis, no learning
solutions to date provide explicable results or insights on
the key indicators of an attack, undermining the useful-
ness in practice. Speciﬁcally, extensive manual efforts are
required to review audit records in behavior to locate
particular system activities triggering a detection signal.
For example, as Unicorn [21] analyzes APT attacks upon
a long duration of system execution, analysts need to sift
through thousands of audit records to identify and validate
the indicator of a single detection signal.
C. Threat Detection as Recommendation
System entity interaction serves as the bedrock in our
approach, where we utilize the observation that interaction
with low likelihood can be naturally identiﬁed as a poten-
tial cyber threat. For example, executables downloaded by
browsers (e.g., gtcache) commonly do not run sensitive user
commands (e.g., uname), which otherwise signiﬁes mali-
cious execution [37]. Provenance-based solutions typically use
causal connections in provenance graphs to interpret system
entity interactions. However, such causality is insufﬁcient to
reveal the semantic relationship between two system entities.
In particular, causally disconnected entities (e.g., /proc/pid/stat
with different pid) are not necessarily semantically irrelevant.
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 13:13:26 UTC from IEEE Xplore.  Restrictions apply. 
491
162.66.239.75:80gtcachepass_mgrgtcache146.153.68.151:80/etc/passwd/proc/pid/statsh/tmp/ztmpztmp128.55.12.73uname!!!!!"!"!#!#!$!%!&!%!&!$!'!$!(Iron ManThe AvengersThorLittle WomenMarvel StudiosActionSoundtrackColumbia PicturesAliceBobPossible side information:𝒂𝒂𝟏𝟏: process status info; gtcache/proc/25/stat…𝒂𝒂𝟏𝟏𝒂𝒂𝟐𝟐𝒂𝒂𝟑𝟑𝒂𝒂𝟒𝟒uname𝒂𝒂𝟑𝟑: uncommon network port; 𝒂𝒂𝟐𝟐: local file; 𝒂𝒂𝟒𝟒: user command;……/proc/27/stat128.55.12.73:53We discover that a similar problem has been explored in
the recommendation domain. Figure 1b illustrates a movie
recommendation scenario, where Alice is the target user
to provide recommendations for. The user-item interactions,
Alice→Iron Man and Bob→Iron Man, indicate the behavioral
similarity between Alice and Bob. Based on the assumption
that behaviorally similar users would share preferences on
items [28], earlier recommendation systems predict that Alice
is in favor of Thor as Bob likes it. However, considering
the recommendations of relevant items to a particular user,
user-item interactions are insufﬁcient as they cannot compare
item semantic similarity. To address this issue, the recently
proposed methods [29], [30] leverage item side information,
such as movie genre and studio, to form high-order con-
nectivities that link semantically similar items. For example,
the two-order connections, Iron Man→Action→The Avengers
and Iron Man→Marvel Studios→The Avengers, suggest that
Alice may prefer The Avengers as its side information is
identical to that of Iron Man.
Similarly, an intuitive way to better understand system entity
interactions is to identify side information of system entities
to form high-order connectivity. For example, if /proc/27/stat
were correlated with /proc/25/stat
through side information
(e.g., process status info in Figure 1c), we would determine
that they share the probability of interacting with other system
entities (e.g., gtcache). However, side information is not
explicitly encoded in original provenance graphs. To extract
such knowledge, we take inspiration from a recent study [31],
which infers the semantics of system entities from their usage
contexts. More speciﬁcally, we regard contextual information
as auxiliary knowledge to proﬁle system entities. As such,
causalities of system entities form user-item interactions as
in the recommendation, while system contexts provide side
information to form high-order connectivity. Note that since
contextual information of system entities is reﬂected in their
neighbors in provenance graphs, we capture high-order con-
nectivity as a multi-hop path correlating neighboring entities.
Therefore, we can formulate cyber threat detection as a
recommendation problem, which models the likelihood of in-
teractions between two system entities, predicting interactions
that entities normally do not like as cyber threats. For example,
detecting the attack of Extension Backdoor in Figure 1a
becomes recommending system entities with which gtcache
unlikely interacts in Figure 1c. Motivated by this insight, we
are able to bridge the threat detection and recommendation do-
mains and leverage the advances in recommendation methods
to help comprehend system entity interactions.
III. PROBLEM DEFINITION
We ﬁrst formally deﬁne several basic concepts required to
understand how SHADEWATCHER provides recommendations.
Then, we introduce the problem statement and threat model.
A. Basic Concept
Provenance Graph: Audit records are a set of log entries that
describe the history of a system’s execution. Each record repre-
sents an activity at the granularity of system calls. Typically, it
is formulated as a 3-tuple (src, rel, dst), where src, dst ∈ E =
{process, f ile, socket}, and rel ∈ R = {clone, write, ...}.
For example, a network service scanning activity in Figure 1a
is deﬁned as (ztmp, connect, 128.55.12.73:54). Data prove-
nance organizes audit records in the form of a provenance
graph, a directed acyclic graph composed of (src, rel, dst)
tuples. Formally, we deﬁne a provenance graph as GP =
{(src, rel, dst)| src, dst ∈ E, rel ∈ R}.
System Entity Interaction: Causal connections in a prove-
nance graph reﬂect interactions among system entities. For
example, a chain of edges connecting gtcache and uname in
Figure 1a indicate that they are interactive. In recommendation
scenarios, user-item interactions are commonly presented as
a bipartite graph to preserve the collaborative ﬁltering sig-
nal [38]. We thus also deﬁne system entity interactions as
a bipartite graph, GB = {(e, yee(cid:48), e(cid:48))|e, e(cid:48) ∈ E)}. The link
yee(cid:48) = 1 shows that entity e has interacted with entity e(cid:48), while
yee(cid:48) = 0 the opposite. Note that a system entity interaction
represents not only explicit data dependency but also implicit
control dependency. For example, the aforementioned interac-
tion between gtcache and uname shows a control dependency
where gtcache manipulates ztmp to execute uname.
Order of Connectivity: Here we deﬁne the concept of a
knowledge graph (KG) that encodes system entity contexts and
interactions into a uniﬁed relational graph. More speciﬁcally,
we convert a valid interaction (i.e., yee(cid:48) = 1) in the GB into
a 3-tuple (e, interact, e(cid:48)), where interact stands for an addi-
tional relationship beyond system calls. As both GP and GB are
now deﬁned as entity-relation-entity sets, we can unify them
as a KG, GK = {(h, r, t)|h, t ∈ E, r ∈ R(cid:48)}, where R(cid:48) = R ∪
{interact}. With a KG representing both system entity con-
texts and interactions, we formally deﬁne ﬁrst-order connec-
tivities as one-hop connections (e.g., /etc/passwd r1−→gtcache)
in the KG and high-order connectivities as multi-hop paths
(e.g., /etc/passwd r1−→gtcache r4−→146.153.68.151:80).
B. Problem Statement
Given system entity interactions from audit records, we aim
to learn a recommendation model whose objective is to predict
the probability ˆyht that a system entity h would not interact
with another entity t. Note that ˆyht also indicates the likelihood
of an interaction to be adversarial, which forms the basis for
SHADEWATCHER to analyze cyber threats in audit records.
Threat Model: This work considers an attacker who aims to
manipulate or exﬁltrate information present in a system. For
example, the attacker may install malware or insert a backdoor
to steal sensitive data. Similar to previous studies on system
auditing [11], [14], [17], [21], [39], we assume an OS and
kernel-space auditing frameworks to be our trusted computing
base. Additionally, we do not consider hardware trojans or
side-channel attacks that are invisible in system auditing.
Note that during the APT lifecycle [13], attackers may
escalate privileges to corrupt system auditing, at which point
audit data are no longer reliable for cyber threat analysis.
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 13:13:26 UTC from IEEE Xplore.  Restrictions apply. 
492
However, we can ensure the integrity of historical audit
records by employing secure provenance storage systems [8],
[40] or managing audit data in a remote analysis server. As
such, attackers have no way of manipulating previous audit
records that have tracked the evidence of privilege escala-
tion for SHADEWATCHER to detect malicious system entity
interactions. By further integrating tamper-evident auditing
techniques [41], [42], we can locate when attackers tamper
with audit records to hide their footprints. Finally, system
hardening techniques (e.g., Linux IMA) can be adopted to
increase the complexity of compromising system auditing.
IV. SHADEWATCHER OVERVIEW
Figure 2 presents an overview of the SHADEWATCHER
architecture, which receives audit records collected by the
commodity auditing framework (i.e., Linux Audit [43]) and
produces signals for adversarial system entity interactions.
SHADEWATCHER consists of four major phases: building a
knowledge graph (KG), generating a recommendation model,
detecting cyber threats, and adapting the model.
Our KG builder ﬁrst converts system audit records into a
provenance graph (PG) and extracts system entity interactions
as a bipartite graph (BG). Then, the PG and BG are combined
into a KG, which is subsequently used to learn a recommen-
dation model whose objective is to predict the preferences of
system entities on their interactive entities.
The key idea behind our recommendation is to use different-
order connectivities in a KG to model the likelihood of system
entity interactions, identifying anomalies in system execution
as cyber threats. Full details will be given in § VI, but we
outline the workﬂow here. To explicitly exploit ﬁrst- and high-
order information, we parameterize system entities as embed-
dings (i.e., vectors) via a context-aware embedding module
and then iteratively propagate embeddings from neighbors via
a graph neural network. By aggregating embeddings from
all propagation iterations, SHADEWATCHER determines the
probability of entity-entity interactions to be adversarial.
When system behavior changes, SHADEWATCHER may
raise false alarms for unobserved yet benign system entity
interactions. To keep up with evolving interactions patterns,
SHADEWATCHER provides an option to dynamically update
its recommendation model by adapting to analyst feedback on
false-positive interactions.
In summary, SHADEWATCHER’s functionalities can be sep-
arated into two stages, i.e., training and detection. To perform
anomaly-based detection, we use attack-free audit records
to train the recommendation model. For the newly arrived
audit stream, SHADEWATCHER ﬁrst extracts system entity
interactions and feeds them to the recommendation model ob-
tained from the training stage. Then, SHADEWATCHER detects
interactions as potential threats if their probabilities of being
adversarial are larger than a pre-deﬁned threshold. Note that
SHADEWATCHER is currently designed and implemented to
perform ofﬂine cyber threat analysis. We discuss the potential
of adapting SHADEWATCHER to an online approach and the
corresponding challenge in Appendix A.
Fig. 2: Overview of SHADEWATCHER architecture.
V. KNOWLEDGE GRAPH BUILDER
In this section, we present how to parse audit records into a
knowledge graph (KG), which preserves both ﬁrst- and high-
order information in audit records.
A. Provenance Graph Construction
Given audit records on end hosts, SHADEWATCHER trans-
forms them into a graph structure called a provenance graph
(PG). Nodes in the graph denote system entities with a set
of attributes1, and edges describe causal dependencies among
system entities and the timestamp of record occurrence. As a
common representation of audit records [8], [16], [44], [45],
the PG facilitates reasoning over long-lived attacks as causal
records are closely correlated, albeit temporally distant.
Notice that most audit records are not strictly necessary in
the causal analysis of cyber threats [46]. Even worse, adver-
sarial activities may be crowded out in the noise of normal
and complicated audit records. Accordingly, we implement
several noise reduction strategies from recent work [6], [46],
[47] (explained in Appendix B) to reduce auditing complexity
while preserving attack-relevant information.
B. Interaction Extraction
SHADEWATCHER identiﬁes cyber threats on the basis of
system entity interactions. A na¨ıve approach to extracting
interactions is to pair every two system entities in a PG and ex-
plore their causal dependency. In particular, a pair of causally
connected entities represents a valid interaction. Unfortunately,
traversing all system entity pairs in a PG is infeasible in
practice due to the large size that most PGs have. Case in
point, the PG built upon the DARPA TRACE dataset [48]
consists of over six million system entities, forming 18 trillion
pairs. However, only a tiny portion (much less than 0.01%) of
system entity pairs exhibit valid interactions.
Abstracting behaviors from audit records has been shown
effective in reducing analysis workloads [31]. Speciﬁcally,
each behavior is represented as a provenance subgraph with a
sequence of causal records rooted at a data object (e.g., ﬁle).
Figure 1a illustrates an example of the behavior associated
with Extension Backdoor. The gtcache highlighted with dou-
ble circles denotes the root data object. Working on the level
of behaviors can substantially reduce the scope of interaction
analysis because causally disconnected system entities have
been separated into different behaviors. As such, we decide
to partition a PG into multiple subgraphs, each describing a
1Process attributes: pid, ppid, exe, and args; ﬁle attributes: name, path, and
version; socket attributes: ip and port.
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 13:13:26 UTC from IEEE Xplore.  Restrictions apply. 
493
Recommendation ModelContext-aware EmbeddingProvenance GraphConstructionInteraction ExtractionKG BuilderGraph Neural NetworkThreatDetectionAudit RecordsAuditStreamAdaptorTrainingDetectionFeedbackdirect connections in a knowledge graph (KG) present both
behavioral and semantic similarities among system entities.
To model such ﬁrst-order connectivity, we use KG embedding
methods to parameterize system entities as vectors, where
the distance between two vectorized entities captures their
similarity. TransE [52] is a widely-used method. At its core
is the translation principle: if a tuple (h, r, t) holds in a KG,
the embeddings of system entities h, t and their relation r are
learned by satisfying eh + er ≈ et, where eh, er, et ∈ Rd.
This principle perfectly matches our intuitive understanding
of system entities. Take (ztmp, connect, 128.55.12.73:53) and