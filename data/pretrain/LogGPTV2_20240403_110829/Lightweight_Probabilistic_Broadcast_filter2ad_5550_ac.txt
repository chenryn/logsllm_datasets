ports the simulation results obtained for different values for 
1  in a system of  125 processes.  It conveys a certain depen- 
dency between  1 and the number of gossip rounds required 
for the  successful dissemination  of an  event in TI,  slightly 
contradicting our analysis. This stems from the fact that we 
have presupposed uniform views for the analysis, and have 
considered these as completely  independent of  any “state” 
of  the system.  A more precise analysis would have to take 
into account the exact composition of the view of each pro- 
cess at each round. This would however lead to a very com- 
plex Markov Chain, with an impracticable size.  Given the 
very good correlation  between simulation and analysis, as- 
suming independent and uniform  views seems reasonable. 
5.2.  Measurements 
We present here concrete measurements that attempt to 
capture  the  degree  of  reliability  achieved  with  our  algo- 
rithm, and confirm the results obtained from simulation. 
449 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 04:05:39 UTC from IEEE Xplore.  Restrictions apply. 
400 
350 
:’ 
;: 
n=250, practice 
n=500, theory  - - - - - 
~ = s w ,  practice  . - . - - 
0 
2 
1 
6 
X rounds 
8 
10 
(a) Analysis vs simulation 
J 
l o o t  
80 
0
1
2
3
4
5
X  rounds 
6
7
8
9
(b) Number of rounds necessary to infect  a system with dif- 
ferent values  for 
’ 
Figure 5. Simulation results 
Test  environment.  Our  measurements  involved 
two 
LANs with, respectively 60 and 65 SUN Ultra  10 (Solaris 
2.6, 256 Mb RAM, 9 Gb harddisk) workstations.  The in- 
dividual  stations and the different networks were commu- 
nicating via Fast Ethernet (100Mbit/s).  The measurements 
we present here were obtained with all  125 processes; each 
publishing 40 events per gossip round.  To conform to our 
simulations, F  was fixed to 3. 
Impact of a view size.  Figure 6 shows the impact of 1 on 
the  degree  of  reliability  achieved  by  our  algorithm.  The 
measure of  reliability  is expressed here  by  the  probability 
for any given process to deliver any given notification (1 -0, 
cf. Section 2). The reliability of the system seems to deteri- 
orate slightly with a decreasing value for I .   Intuitively this 
seems understandable, since our simulation results have al- 
ready shown that latency does increase slightly by decreas- 
ing 1.  And with  an increased  latency, the probability  that 
a given message is purged  from all  buffers before  all  pro- 
! 
cesse:; have been infected bekomes higher. 
1 
0 98 
1 
0.82 
0.8 
15 
Rate = 40 m r e u n d ;  Notification  list size= 60 
~ 
20 
25 
View sire 
30 
I 
35 
Figure 6. Measurements: degree of reliability 
6.  Discussion 
This section discusses our lpbcast algorithm with respect 
to “perfectly” uniform views and compares it closer with the 
well-known pbcast algorithm [4], in particular by  combin- 
ing pbcast with our membership approach. 
6.1.  Towards “Perfect” Views 
Simulations performed with  artificially generated  inde- 
pertdent uniform views have shown that there is virtually no 
dependency between latency  of delivery  (and thus  the de- 
gree of reliability) and the size of the individual views. The 
views obtained in  practice  w i t h   lpbcast  t h u s  appear to  not 
be completely uniform and independent. 
Dependency.  One interpretation of the slight dependency 
between  latency  and  1 is  that, despite the random truncat- 
ing of views, there remains a correlation between individual 
views both in time (view, of process p ,  at round T depends 
on view, at round r - 1) and in space (view, of process pi 
depends on wiewj  of  process p ] ) .  Intuitively, such depen- 
dencies negatively affect the latency of delivery of an event: 
since every process appends part of its view to each outgo- 
ing gossip message,  a process pz, which receives a gossip 
message from p j ,  has a certain  probability  of gossiping to 
processes that have received the same gossip message from 
(pi updates its view according to the subs.it received from 
p,, possibly  including processes which  have been gossiped 
to in the same round by p j ) .  
To  avoid  this effect,  we  have  tried  in  a  first  attempt  to 
;educe  the  frequency for the  gossiping of  membership in- 
formation (every k-th  round  only, k  > 1). It has however 
turnedout that this sanction leads to the opposite effect, i.e., 
latency increases (and thus reliability decreases) further. In 
450 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 04:05:39 UTC from IEEE Xplore.  Restrictions apply. 
contrast,  when  the frequency  for membership gossiping is 
increased  (gossiping membership  information  more  often 
that events), the views appear to come closer to ideal views, 
and  the  performance of  our  algorithm  improves.  This is 
however difficult to apply as an optimization, since T is usu- 
ally chosen already very small to ensure a high throughput. 
Weighted  views.  As  already  mentioned,  every  process 
should ideally be known by exactly 1 other processes.  This 
is however difficult to ensure without relying on any form of 
agreement or counting.  We propose an optimization to get 
the distribution of views closer to this ideal case. It consists 
in adding a weight to every entry in the view, which gives a 
measure about how well a given process is known.  Unlike 
the weights used in Directional Gossip [ 141 however, which 
represent the connectivity of processes, weights in our case 
represent the level of awareness for a given process. 
When a process p ,  learns about another process p ,  which 
is in pz's view through the subs attached to an incoming gos- 
sip message, the weight of pJ is increased. When truncating 
the view, a simple heuristic is applied, consisting in remov- 
ing entries with a high weight, since these are more proba- 
ble of being known by many other processes. Furthermore, 
when constructing subs, a process  preferably  adds entries 
from its view with a small weight.  A similar scheme could 
also be applied to events and eventlds. 
6.2.  Comparison with pbcast 
Aside  from  the  membership  scheme, the  main  differ- 
ences between our lpbcast algorithm and pbcast are ( 1 )   that 
the latter algorithm limits the number of hops as well as (2) 
repetitions for a given message, and (3) that our approach 
melts the two phases ofpbcast (dissemination of events and 
exchange of digests) into a single phase. We comment here 
on the integration ofpbcast with our membership approach, 
and compare it with our lpbcast algorithm. 
Membership layer.  We  have presented  our membership 
approach as integral part  of  our  lpbcast algorithm to ease 
presentation.  As  we  have mentioned earlier, our member- 
ship approach  is  nevertheless  not  inherently coupled  with 
our lpbcast algorithm, but can be separated from the event 
dissemination  process.  It  could  thus  be  encapsulated  as 
a  membership layer,  on  top  of  which  many  gossip-based 
algorithms,  like pbcast,  could  be  deployed.  It  would  act 
by  adding  membership  information  to  gossip  messages, 
and would provide quasi-independent uniformly distributed 
views. Since gossip-based protocols require a random sub- 
set of  the  system,  theoretically  the  size  of  the  view  does 
not impact the probability  of infection  and hence through- 
put and  delivery  latency of the broadcast algorithm would 
remain virtually unaffected. 
0 
1 
2 
3 
# rounds 
5 
6 
(a) Comparison:  number  of  infected  processes  in  a given 
round 
0.94 
15 
20 
25 
View size 
30 
35 
(b) Delivery reliability ofpbctisr with a random pmial  view 
Figure 7. Simulations and measurements with phcasi 
Evaluation.  We simulated the behaviour of a pbcast ver- 
sion  instrumented with  our membership approach.  Figure 
7(a) illustrates the process of an event propagation in such a 
partial view membership for pbcast and lpbcast, comparing 
with the original pbcast based on a complete view. The ad- 
vantage of our lpbcast over pbcast can be explained by the 
fact that hops and repetitions are not limited with the former 
algorithm. 
Figure 7(b) presents the reliability degree measured with 
different values for 1 (in every round, each of n. = 125 pro- 
cesses published 40 events).  The results  are similar to  the 
ones obtained  with  lpbcast (Figure 6).  A  direct compari- 
son of the two algorithms is however not a useful measure, 
since there  are different  parameters involved.  In  fact, be- 
cause repetitions and hops are limited in the case ofpbcast, 
a higher fanout is required to obtain similar results than with 
lpbcast ( F  = 5 here  vs F  = 3 in  Figure 6).  In  fact, lpb- 
cast  reaches  a higher reliability  degree  when  simulated  in 
the same setting, since its latency is smaller. 
45 1 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 04:05:39 UTC from IEEE Xplore.  Restrictions apply. 
In practice and at a high load of the system however, per- 
formance can be expected to drop faster with lpbcast, since 
the first phase of pbcast ensures a high  throughput, while 
gossip messages  in lpbcast  will transport large numbers of 
notifications, which might become a bottleneck. 
Acknowledgements 
We are very grateful to Ken Birman and Robert van Re- 
nesse for affording us an insight into the subtle approach of 
probabilistic reliable broadcast. 
References 
[ I ]   M. Aguilera, R. Strom, D. Sturman, M. Astley, and T. Chan- 
dra. Matching events in a content-based subscription system. 
In Proceedings of the 18th ACM Symposium on Principles of 
Distributecl Computing (PODC '99), Nov.  1998. 
[2]  Y.  Amir, D. Dolev, S. Kramer, and D. Mahlki.  Membership 
algoritms for multicast communication groups.  In 6th Intl. 
Workshop on Distributed Algorithms proceedings  ( WDAG), 
pages 292-312,  Nov.  1992. 
[3]  N. Bailey.  The Mathematical  Theory of Infectious Diseases 
and its Applications (second edition). Hafner Press, 1975. 
[4]  K. Birman, M. Hayden, O.Ozkasap, Z. Xiao, M. Budiu, and 
Y.  Minsky.  Bimodal multicast. ACM  Transactions on Com- 
puter Systems, 17(2):41-88,  May  1999. 
[5]  A. Carzaniga. Architectures for an Event Notijcation Service 
Scalable to Wide-area Networks.  PhD thesis, Politecnico di 
Milano, Dec. 1998. 
[6]  S. Deering. Internet multicasting.  In ARPA HPCC94 Sympo- 
sium. Advanced Research Projects Agency  Computing Sys- 
tems Technology Office, Mar.  1994. 
[7]  A.  Demers,  D.  Greene,  C.  Hauser,  W.  Irish,  J.  Larson, 
S. Shenker, H. Sturgis, D. Swinehart, and D. Terry. Epidemic 
algorithms for replicated database maintenance. In Proceed- 
ings of the 6111 Annual ACM Symposium on Principles of Dis- 
tributed Computing (PODC'87), pages  1-12,  Aug.  1987. 
[8]  P. Eugster, R. Guerraoui, and J. Sventek.  Distributed Asyn- 
chronous Collections: Abstractions for publishhubscribe in- 
teraction.  In Proceedings of the  14th European Conference 
on  Object-Oriented  Programming  (ECOOP 2000), pages 
252-276,  June 2000. 
[9]  R.  Golding.  Weak-consistency group  conimunication  and 
membership.  PhD thesis, University of California at Santa 
Cruz. Dec. 1992. 
, I 
I 
! 
1 I ]   V. Hadzilacos and S. Toukg. Distributed Systems, chapter 5: 
Fault-Tolerant  Broadcast;  and Related Problems, pages 97- 
145. Addison-Wesley, 2nd edition, 1993. 
121  M. Hiltunen  and R. Schlichting.  Properties of membership. 
In Proceedings of the 2nd IEEE Symposium on Autonomous 
Decentralized Systems, pages 200-207,  Apr. 1995. 
/ 
[13]  A.-M.  Kermarrec,  L. Massoulie, and A. Ganesh.  Reliable 
probabilistic communication in large-scale information dis- 
semination systems.  Technical Report MSR-TR-2000-105, 
Microsoft Research Cambridge, Oct. 2000. 
[14]  M.-J. Lin and K. Marzullo.  Directional gossip: Gossip in a 
wide area network. Technical Report CS3999-0622, Univer- 
sity of California, San Diego, Computer Science and Engi- 
neering, June 1999. 
[15]  L. Opyrchal, M. Astley, J. Auerbach, G. Banavar, R. Strom, 
and D. Sturman.  Exploiting IP Multicast  in  content-based 
publish-subscribe systems. In Proceedings of  the IFIP/ACM 
International  Conference on Distributed Systems Platforms 
(Middleware 2000), pages  185-207,  Apr. 2000. 
[I61  J. Orlando, L. Rodrigues, and R. Oliveira.  Semantically re- 
liable multicast protocols.  In Proceedings of the 19th IEEE 
Symposium  on  Reliable  Distributed  Systems  (SRDS 2000), 
Oct. 2000. 
[I71  S. Paul, K. Sabnani, J. Lin, and S. Bhattacharyya.  Reliable 
multicast transport protocol  (RMTP).  IEEE Journal  on Se- 
lected Areas in Communications, 15(3):407-42 1,  Apr. 1997. 
[18]  R. Piantoni and C. Stancescu.  Implementing the swiss ex- 
In  Proceedings  of  The  7ivenp- 
change  trading  system. 
Seventh Annual International  Symposium on Fault-Tolerant 
Computing (FTCS '97), pages 309-313,  June 1997. 
191  Q. Sun and D. Sturman. A gossip-based reliable multicast for 
large-scale high-throughput applications,  In Proceedings of 
the IEEE International  Conference on Dependable System 
and Networks (DSN2000), New York, USA, July 2000. 
201  TIBCO. 
TIB/Rendezvous 
White 
Paper. 
http://www.rv.tibco.com/,  1999. 
[21]  R. van  Renesse.  Scalable and secure resource location.  In 
Proceedings  of  the  IEEE Hawaii  International  Conference 
on System Sciences, 2000. 
[22]  Wego.com 
Inc., 
What 
Is 
Gnutella? 
http://gnutella.wego.com/, 2000. 
[IO]  Groove 
Networks, 
Introducing 
http:llwww.groovenetworks.com/,  2000. 
Groove. 
452 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 04:05:39 UTC from IEEE Xplore.  Restrictions apply.