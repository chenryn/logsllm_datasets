apiVersion: v1
data:
  status: |+
    Cluster-autoscaler status at 2018-10-03 ...
    Cluster-wide:
      Health: Healthy (ready=4 ...)
      ...
      ScaleDown: CandidatesPresent (candidates=1)
                 ...
    NodeGroups:
      Name:      ...gke-devops25-default-pool-f4c233dd-grp
      ...
      ScaleDown: CandidatesPresent (candidates=1)
                 LastProbeTime:      2018-10-03 23:06:...
                 LastTransitionTime: 2018-10-03 23:05:...
      ...
```
如果您的输出不包含`ScaleDown: CandidatesPresent`，您可能需要等待一段时间，然后重复前面的命令。
如果我们关注集群范围状态的`Health`部分，所有四个节点仍然准备就绪。
从状态的集群范围来看，我们可以看到`ScaleDown`有一个候选项(在你的情况下可能更多)。如果我们移动到`NodeGroups`，我们可以观察到其中一个在`ScaleDown`部分将`CandidatesPresent`设置为`1`(或者在放大之前的初始值)。
换句话说，其中一个节点是要移除的候选节点。如果保持十分钟，节点将首先被排空，以允许在其内部运行的 Pods 优雅地关闭。之后，它将通过缩放组的操作被物理移除。
![](img/ede07cff-dc03-427e-9205-4facebd4711f.png)
Figure 2-4: Cluster Autoscaler processes of scaling-down
我们应该等十分钟再继续，所以这是一个喝咖啡(或茶)的绝佳机会。
既然已经过了足够的时间，我们再来看看`cluster-autoscaler-status`配置图。
```
 1  kubectl -n kube-system \
 2      get configmap \
 3      cluster-autoscaler-status \
 4      -o yaml
```
输出限于相关部分，如下所示。
```
apiVersion: v1
data:
  status: |+
    Cluster-autoscaler status at 2018-10-03 23:16:24...
    Cluster-wide:
      Health:    Healthy (ready=3 ... registered=4 ...)
                 ...
      ScaleDown: NoCandidates (candidates=0)
                 ...
    NodeGroups:
      Name:      ...gke-devops25-default-pool-f4c233dd-grp
      Health:    Healthy (ready=1 ... registered=2 ...)
                 ...
      ScaleDown: NoCandidates (candidates=0)
                 ...
```
从集群范围的部分，我们可以看到现在有`3`个准备好的节点，但是还有`4`(或者更多)个注册。这意味着其中一个节点被抽干，但仍未被破坏。同样，其中一个节点组显示存在`1`就绪节点，即使`2`已注册(您的号码可能会有所不同)。
从 Kubernetes 的角度来看，我们回到了三个操作工人节点，尽管第四个节点仍然存在。
现在，我们需要再等一会儿，然后检索节点并确认只有三个可用。
```
 1  kubectl get nodes
```
来自 GKE 的输出如下。
```
NAME    STATUS ROLES  AGE VERSION
gke-... Ready   36m v1.9.7-gke.6
gke-... Ready   36m v1.9.7-gke.6
gke-... Ready   36m v1.9.7-gke.6
```
我们可以看到该节点被移除，并且我们已经从过去的经验中知道，Kube Scheduler 将该节点中的 Pods 移动到了那些仍在运行的 Pods 中。现在，您已经体验到了节点的缩减，我们将探索控制该过程的规则。
# 管理节点缩减的规则
集群自动缩放器每 10 秒迭代一次(可通过`--scan-interval`标志配置)。如果不满足向上扩展的条件，它会检查是否有不需要的节点。
当满足以下所有条件时，它将认为某个节点符合删除条件。
*   一个节点上运行的所有 Pods 的 CPU 和内存请求的总和小于该节点可分配资源的 50%(可通过`--scale-down-utilization-threshold`标志配置)。
*   节点上运行的所有 Pods 都可以移动到其他节点。例外情况是那些在所有节点上运行的，比如通过 DaemonSets 创建的节点。
当满足以下条件之一时，Pod 是否不适合重新调度到不同的节点。
*   具有关联规则或反关联规则的 Pod，将它绑定到特定节点。
*   使用本地存储的 Pod。
*   直接创建的 Pod，而不是通过部署、状态集、作业或复制集等控制器创建的 Pod。
所有这些规则可以归结为一个简单的规则。如果节点包含无法安全逐出的 Pod，则它不符合移除条件。
接下来，我们应该谈谈集群扩展边界。
# 我们可以过度扩展还是缩小到零节点？
如果我们让 Cluster Autoscaler 在没有定义任何阈值的情况下发挥它的“魔力”，我们的集群或我们的钱包可能会有风险。
例如，我们可能会错误配置高性能计算，最终将部署或状态集扩展到大量副本。因此，群集自动缩放器可能会向群集添加太多节点。因此，我们最终可能会为数百个节点付费，尽管我们需要的要少得多。幸运的是，AWS、Azure 和 GCP 限制了我们可以拥有的节点数量，因此我们无法扩展到无穷大。然而，我们不应该允许集群自动缩放器超过某些限制。
同样，集群自动缩放器存在缩减到太少节点的危险。拥有零节点几乎是不可能的，因为这将意味着我们在集群中没有 Pods。尽管如此，我们应该保持健康的最小节点数，即使这意味着有时未得到充分利用。
合理的最小节点数是三个。这样，我们在区域的每个区域(数据中心)都有一个工作节点。正如您已经知道的，Kubernetes 需要三个带主节点的区域来维持仲裁。在某些情况下，尤其是在本地，我们可能只有一个低延迟的地理位置相同的数据中心。在这种情况下，一个区域(数据中心)总比没有好。但是，对于云提供商来说，三个区域是推荐的分布，每个区域至少有一个工作节点是有意义的。如果我们使用块存储，情况尤其如此。
就其本质而言，块存储(例如，AWS 中的 EBS、GCP 的持久磁盘和 Azure 中的块 Blob)不能从一个区域移动到另一个区域。这意味着我们必须在每个区域中有一个工作节点，以便(很可能)在存储所在的同一区域中始终有一个位置。当然，我们可能不会使用块存储，在这种情况下，这种说法是没有根据的。
工作节点的最大数量怎么样？这在不同的用例中是不同的。你不必永远坚持同一个最大值。它会随着时间而改变。
根据经验，我建议节点的实际数量最多增加一倍。然而，不要把这条规则当回事。这确实取决于集群的大小。如果只有三个工作节点，则最大大小可能是九个(大三倍)。另一方面，如果您有数百甚至数千个节点，那么将该数量加倍为最大值是没有意义的。那就太多了。只需确保最大节点数反映了潜在的需求增长。
在任何情况下，我相信您都会知道工作节点的最小和最大数量。如果你犯了错误，你可以以后改正。更重要的是如何定义这些阈值。
幸运的是，在 EKS、GKE 和 AKS 设置最小值和最大值很容易。对于 EKS，如果您使用`eksctl`来创建集群，我们所要做的就是向`eksctl create cluster`命令添加`--nodes-min`和`--nodes-max`参数。GKE 在`--min-nodes`和`gcloud container clusters create`命令的`--max-nodes`参数上遵循类似的逻辑。如果两者中的一个是你的偏好，如果你遵循 Gists，你已经使用了这些参数。即使您忘记指定它们，您仍然可以修改自动缩放组(AWS)或实例组(GCP)，因为这是实际应用限制的地方。
Azure 采用了一种稍微不同的方法。我们在`cluster-autoscaler`部署中直接定义了它的限制，只要应用一个新的定义就可以改变它们。
# 集群自动缩放器在 GKE、EKS 和阿克苏进行了比较
集群自动缩放器是不同托管 Kubernetes 产品之间差异的一个主要例子。我们将使用它来比较三个主要的 Kubernetes 即服务提供商。
I'll limit the comparison between the vendors only to the topics related to Cluster Autoscaling.
对于那些可以使用谷歌托管集群的人来说，GKE 是一个显而易见的地方。它是最成熟、功能最丰富的平台。他们比任何人都更早地启动了谷歌 Kubernetes 引擎。当我们将他们的领先优势与他们是 Kubernetes 的主要贡献者并因此拥有最多经验的事实相结合时，他们的产品远远超过其他产品就不足为奇了。
使用 GKE 时，所有东西都被烘焙到集群中。这包括集群自动缩放器。我们不必执行任何额外的命令。它只是开箱即用。只要我们在创建集群时指定`--enable-autoscaling`参数，我们的集群就可以在不需要我们参与的情况下上下扩展。除此之外，GKE 比其他提供商更快地引入新节点并将其加入集群。如果需要扩展群集，一分钟内就会添加新节点。
还有很多其他原因我会推荐 GKE，但这不是现在的主题。尽管如此，集群自动缩放本身就应该证明 GKE 是其他人试图遵循的解决方案。
亚马逊为 Kubernetes( **EKS** )提供的**弹性容器服务**位于中间的某个地方。集群自动缩放可以工作，但它不能被烘焙。就好像亚马逊不认为扩展集群很重要，而把它作为一个可选的附加组件。
EKS 的安装太复杂了(与 GKE 和 AKS 相比)，但多亏了韦弗工厂的员工 eksctl([https://eksctl.io/](https://eksctl.io/))，我们或多或少解决了这个问题。尽管如此，eksctl 还有很多地方需要改进。例如，我们不能用它来升级我们的集群。
我在自动缩放的上下文中提到 eksctl 的原因在于集群自动缩放器的设置。
我不能说在 EKS 设置集群自动缩放器很难。不是的。然而，事情并没有想象的那么简单。我们必须标记自动缩放组，赋予角色额外的权限，并安装集群自动缩放器。那不多。然而，这些步骤比它们应该的要复杂得多。我们可以和 GKE 相比。谷歌明白自动缩放 Kuberentes 集群是必须的，它提供了一个单一的参数(如果你喜欢用户界面，也可以选择复选框)。另一方面，AWS 认为自动缩放不够重要，不足以让我们变得简单。除了 EKS 不必要的设置之外，事实是 AWS 最近才添加了扩展所需的内部组件。度量服务器只能从 2018 年 9 月开始使用。
我怀疑 AWS 没有兴趣让 EKS 变得伟大，他们把改进留给了法盖特。如果是这样的话(我们很快就会发现)，我会将其描述为“偷偷摸摸的生意”Kubernetes 拥有扩展 Pod 和节点所需的所有工具，它们被设计为可扩展的。选择不将集群自动缩放器作为其托管 Kubernetes 服务的一个组成部分是一个很大的不利因素。
关于 AKS 我能说什么？我钦佩微软在 Azure 中所做的改进以及他们对 Kubernetes 的贡献。他们确实认识到需要一个管理良好的 Kubernetes 产品。然而，集群自动缩放器仍处于测试阶段。有时它起作用，但更多时候它不起作用。即使它真的正常工作，它也很慢。等待新节点加入集群是一种耐心的锻炼。
在 AKS 中安装集群自动缩放器所需的步骤有点可笑。我们需要定义大量的参数，这些参数应该已经在集群中可用。它应该知道集群的名称、资源组等等。然而，事实并非如此。至少，在撰写本文时(2018 年 10 月)，情况就是如此。我希望随着时间的推移，流程和体验都会得到改善。就目前而言，从自动缩放的角度来看，AKS 处于包装的尾部。
你可能会说设置的复杂性并不重要。你是对的。重要的是集群自动缩放的可靠性以及向集群添加新节点的速度。尽管如此，情况还是一样。GKE 在可靠性和速度方面领先。EKS 紧随其后，而 AKS 则落后。
# 现在怎么办？
关于集群自动缩放器没什么好说的了。
我们已经探索了自动缩放 Pods 和节点的基本方法。很快，我们将深入更复杂的主题，探索那些没有被“烘焙”成 Kubernetes 星团的事物。我们将超越核心项目，引入一些新的工具和流程。
如果您不打算立即进入下一章，并且您的群集是一次性的(例如，不在裸机上)，这时您应该销毁您的群集。否则，请删除`go-demo-5`命名空间，以删除我们在本章中创建的资源。
```
 1  kubectl delete ns go-demo-5
```
在你离开之前，你可能要复习一下本章的要点。
*   群集自动缩放器的唯一目的是通过添加或删除工作节点来调整群集的大小。当 Pods 由于资源不足而无法调度时，它会添加新节点。同样，当节点在一段时间内未得到充分利用，并且在一个这样的节点上运行的 Pods 可以在其他地方重新调度时，它会消除节点。
*   集群自动缩放器假设集群运行在某种节点组之上。例如，在 AWS 的情况下，这些组是自动缩放组。当需要额外的节点时，集群自动缩放器通过增加节点组的大小来创建新节点。
*   当在一个节点上运行的所有 Pods 的 CPU 和内存请求的总和小于该节点的可分配资源的 50%时，并且当在该节点上运行的所有 Pods 可以被移动到其他节点时(DamonSets 是例外)，集群将被缩小。