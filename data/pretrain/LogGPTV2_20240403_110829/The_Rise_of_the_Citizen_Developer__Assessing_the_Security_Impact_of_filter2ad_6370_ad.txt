data or by delivering the client app’s content to a generated
boilerplate app. Thus, the attack surface of the generated app
inherently increases beyond the app and its network connection
to the web service backend. Consequently, when considering
that a single service’s infrastructure can serve many hundreds
or thousands of generated apps,
the
app generator service not only follows best practices, such
as correctly verifying certiﬁcates, but also that the service’s
infrastructure maintains highest security standards for their
web services. Of particular interest
is here, whether such
services are resilient to remote attackers, i.e., against state-
of-the-art attacks against SSL/TLS [14], [33], [5], [3], [10],
[1] that affect content delivery either to generated apps or app
data to the service.
is paramount
it
that
We extract the domains of the different services’ backend
servers from the generated apps and use available online
analysis sites (e.g., Qualys SSL Labs11) to check the SSL/TLS
security of respective backend servers. This particularly in-
cludes checks for trusted and valid certiﬁcates, support for
outdated and weak ciphers and protocols, resilience against
recent SSL/TLS vulnerabilities, usage of weak keys, and
11https://www.ssllabs.com/ssltest/
641
checks whether any domain contacted by default by generated
apps is known to distribute malware (e.g., using Google’s
SafeBrowsing12 service).
The results of analyzing the communication with the server
backend are alarming. First of all, only Tobit Chayns and
Biznessapps use encryption consistently for any communi-
cation with the backend, while Apps Geyser completely ab-
stains from secure communication (i.e., HTTP only) and the
other services secure their communication only partially. For
instance, both Seattle Cloud and Como send sensitive data
from user input forms like a login form completely in plain
text. Moreover, only three services use a valid and trusted
server certiﬁcate, while, for instance, Appy Pie uses a self-
signed server certiﬁcate and Mobincube uses a certiﬁcate that
expired seven years ago. From a cryptographic point of view,
all of the services are running an outdated version of SSL
libraries that are prone to one or more recent attacks such as
POODLE [33], BEAST [14], LOGJAM [3], or FREAK [10].
Mobincube’s server was even vulnerable against all of the
tested SSL vulnerabilities.
Data leakage and Privacy Violations: OAGs typically offer
modules to connect to third-party services, like Google Maps
or social media platforms like Facebook and Twitter. These
modules include code to connect to these services via service-
speciﬁc APIs. Using these APIs typically requires an API key
(and secret). Since OAGs do not create third-party accounts
on behalf of the application developer, those AppGens provide
their own API key (and secret) to any app created by its
service. Some keys require a fee for business/volume usage,
like Google Maps keys, hence it is of interest if the OAG
protects these keys from (easy) eavesdropping. The combi-
nation of leaked Twitter key and secret, e.g., hard-coded in
boilerplate code of Biznessapps, allows to send arbitrary au-
thorized requests and in particular to tamper with the account
that is shared across all apps generated with this AppGens.
Although those keys are application-only authentication keys
with limited access rights, the Twitter developer documenta-
tion recommends that these "should be considered as sensitive
as passwords, and must not be shared or distributed to
untrusted parties."13 We found keys and secrets for various
different third-party providers unobfuscated in conﬁg ﬁles,
hardcoded in boilerplate code, in the AndroidManifest ﬁle,
and even in the strings.xml. All identiﬁed keys were exactly
the same across all analyzed apps, underlining the security
impact of boilerplate apps. We could not ﬁnd a single attempt
to obfuscate or protect these keys/secrets.
Besides paid-only services, a large number of AppGens
provide their service for free. Similar to normal app devel-
opment they use different approaches to monetize their apps,
such as advertisement and/or tracking. Since the literature
has shown that such third-party libraries often leak sensitive
user data [27], [43], we especially checked outgoing app
trafﬁc and compared our ﬁndings with the privacy policies
12https://developers.google.com/safe-browsing/
13https://dev.twitter.com/oauth/application-only
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:30:14 UTC from IEEE Xplore.  Restrictions apply. 
provided by the online service. The results suggest that none
of the web domains that the tested apps contacted during our
analyses was known for distributing malware. However, four
application generators (Como, Mobincube, Biznessapps, and
Appy Pie) clearly exhibited questionable tracking behavior.
Apps generated with Mobincube sent more than 250 tracking
requests within the ﬁrst minute of execution. In addition,
Mobincube includes the third-party library BeaconsInSpace to
perform user tracking via Bluetooth beacons without the user
noticing it. Although BeaconsInSpace strongly recommends
updating the privacy policy of apps using their library, we
could not ﬁnd any information in Mobincube’s terms and
conditions. Appy Pie apps contacted Google Analytics, Appy
Pie’s backend, and Facebook for tracking. Apps generated by
Como automatically registered with different tracking web-
sites, including Google Analytics, Como-owned servers, and
others. Biznessapps sends device identiﬁer and location to their
backend servers on app launch. While such extensive tracking
behavior is already questionable for the free services of Appy
Pie and Mobincube, one would certainly not expect this for
paid services like Como and Biznessapps.
VI. EVALUATING KNOWN SECURITY ISSUES
In addition to the speciﬁc attack vectors of online services
discussed in Section IV, we further analyzed the generated
apps’ boilerplate code for violations of security best practices
on Android [23] and vulnerabilities identiﬁed by prior research
on Android application security and privacy [2], e.g., testing
the apps’ device-local attack surfaces, such as unprotected
components. Again, we used our set of self-generated apps
as well as the set of generated apps from Google Play for
cross-validation. Whenever feasible we run static tests against
the entire set of generated apps from Google Play. Table 3
provides an overview of the security analysis results, which
we discuss in more detail in the remainder of this section. We
distinguish apps in vulnerable, non vulnerable, and risky. We
say that an app is vulnerable ( ) when we successfully exploit
the ﬂaw. We say that an app is risky ( ) when an exploitation
scenario exists, but we did not (or could not) reproduce it.
Otherwise, we say that the app is not vulnerable ( ).
A. Best-practice Permission Usage (P1–P3)
Apps may request more permissions
than actually
needed [37], [4], which unnecessarily increases the privileges
of third-party code, such as ad libs, that have been shown
to actively exploit such inherited privileges and to exhibit
questionable privacy-violating behavior [26], [11], [40], [43].
The Android security best practices also explicitly recommend
developers to request as few permissions as possible to con-
form to the principle of least privilege.
Moreover, Android apps are by design allowed to engage
in inter-component communication (ICC [16]). However, apps
that (unintentionally) export their components for access by
other applications, but with no or only insufﬁcient protec-
tion, may leak privacy-sensitive data or security-sensitive
methods to unprivileged attacker apps [45], [31], [25]—a
scenario also warned about in the security best practices. In
addition, for certain components, such as Activities or
BroadcastReceivers, the app developer has only very
limited means to identify or authorize the sender app [9].
This opens the opportunity for Intent spooﬁng attacks [12],
[35] and confused deputy attacks [37], where a vulnerable
component acts on behalf of an ICC message from an attacker
app.
Security analysis: To detect whether an application is
overprivileged, we identify the permission-protected API calls
in the application (using PScout’s [4] and Axplorer’s [8]
permission maps) and derive from those the set of required per-
missions. We complement this list with ContentProvider
and Intent permissions necessary for the app to run
properly. We then compare the resulting set with the set of
actually requested permissions in the application’s manifest.
If the latter one is a strict superset of the former one, we call
the application overprivileged.
We further check applications for explicitly exported
Activity, Service, and ContentProvider compo-
nents or potentially accidentally exported components (e.g.,
by setting an intent-ﬁlter without manually setting ﬂag
android:exported to false). If any of those exported
components is not protected with a permission with at least
signature protection level, we consider this app as exposing
an unprotected component. To also detect receivers potentially
prone to Intent spooﬁng attacks, we conduct the same anal-
ysis as above for BroadcastReceivers , but additionally
considering receivers registered dynamically at runtime via the
app’s context.
Results: All AppGens that generate monolithic boilerplate
code create over-privileged apps by design (P1 in Table 3). As
long as an app developer chooses a subset of modules (from
the set of 12–128 modules across AppGens), the resulting app
has, with a high percentage, more permissions than actually
necessary. For instance, the simple Hello World app (App1)
has between 7–21 permissions for monolithic boilerplate apps,
including camera access, write/read contacts, audio recording,
Bluetooth admin, and location access. At
the same time
App1 of Andromo and Appinventor—that generate module-
dependent code—request only a single permission and three
permissions, respectively.
Application generators do not satisfactorily protect gener-
ated apps’ components from illicit access (P2). Except for
Andromo, AppInventor, and Biznessapps, all tested generators
failed to protect one or more components that we identiﬁed
through manual analysis (e.g., using their package and class
name) to be intended as internally-accessible only. This can
potentially lead to severe implications for the end-users’ or
app generator clients’ privacy. For example, apps generated
with the Seattle Cloud or Mobincube service expose unpro-
tected components for an InternalFileContentProv-
ider and AppContentProvider, respectively, through
which an attacker can read all ﬁles to which the app’s
UID has access, including internal ﬁles like databases, pri-
vate shared preferences, or in case of Seattle Cloud the
642
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:30:14 UTC from IEEE Xplore.  Restrictions apply. 
Table 3: Categorization of considered attack vectors against generated apps in the Android ecosystem.
Attack vector
P1. Overprivileged Apps
P2. Unprotected Components
P3. Intent Spooﬁng and Confused Deputies
P4. Cryptographic API Misuse
P5. SSL/TLS Veriﬁcation Errors
P6. Fracking Attacks
P7. Origin Crossing
P8. Code Injection (native / WebView)
Free service
Paid service
r
e
s
y
e
G
s
p
p
A
r
o
t
n
e
v
n
i
p
p
A
o
m
o
r
d
n
A
e
b
u
c
n
i
b
o
M
e
i
P
y
p
p
A
t
e
Y
p
p
A
s
n
y
a
h
C
t
i
b
o
T
e
n
i
h
c
a
m
p
p
A
s
p
p
a
s
s
e
n
z
i
B
d
u
o
l
C
e
l
t
t
a
e
S
r
e
d
l
i
u
B
s
p
p
A