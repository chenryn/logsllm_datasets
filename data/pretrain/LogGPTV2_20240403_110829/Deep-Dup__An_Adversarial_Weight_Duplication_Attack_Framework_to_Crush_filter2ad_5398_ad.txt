NO
Output
Is the Attack  
Successful? 
Yes
Hijacked 
Output
Figure 6: Overview of End-to-End Deep-Dup attack framework integrating P-DES and AWD for White-Box attack
Black-Box Deep Dup Attack Fr amewor k
Training 
P-DES
Mutation 
Proposed      
Index
1
FPGA Accelarator 
Running DNN
 Triggering             
Injecting Fault
Black-Box 
Output
Winner  Attack    
Index at this 
Fitness Function 
Iteration
AWD
2
DNN
3
Evaluation
Repeat Attack 
Iterations Until 
Success
Hijacked 
Output
Repeat for z evolution
One Attack Iteration
Figure 7: Overview of End-to-End Deep-Dup attack framework integrating P-DES and AWD for Black-Box Attack.
Modiﬁcation of P-DES to adapt to Black-Box. For a
black-box attack, the attacker can only access the input and
output scores of the target DNN in victim tenant FPGA, with
no knowledge of DNN architecture (i.e., in P-DES, p refers
to # of layers & q refers to # of weights at each layer) (details
in section 5.2). To adapt the P-DES algorithm to a black-
box attack, instead of using architecture info of p and q (i.e.,
2D vector), we will treat the whole network parameter to
be unwrapped into a 1D vector w, where an attacker tries to
identify each weight with one feature ˆp. Here, ˆp denotes the
weight index to be attacked after ﬂattening and combining
all L layers weights sequentially. As we deﬁned in the threat
model section and AWD triggering section (sec.5.1.4), this
is feasible since the attacker knows which clock cycles are
used to transmit DNN model weights, enabling an attacker to
develop such a 1D weight index vector for the P-DES. This is
the only modiﬁcation needed for P-DES algorithm discussed
in section 5.2 to adapt to black-box attack.
Triggering AWD in Black-Box. Most of the AWD trig-
gering scheme (details in Sec.5.1.4 ) of black-box attack is
similar to that in white-box (i.e., controlled by the attacking
strategy ﬁle), except that it will be triggered much more fre-
quently. The attacking strategy ﬁle (Fig. 4) will be updated
within every search evolution when it receives mutation pro-
posed attack candidate, to trigger a new fault injection in the
designated location for next ﬁtness function evaluation in
FPGA. z evolution is needed for one attack iteration.
Fitness Function Evaluation. As discussed above, in a
black-box setting, the attacker directly feeds a sample input
into the FPGA to evaluate the ﬁtness function in step 3 . As
the attacker can only access the output prediction from FPGA,
he/she can compute the loss function using Eqn.1 and Eqn.2
for un-targeted and targeted attack, respectively. The above
process 1 - 2 - 3 continues for z evolution times to select one
winner candidate to ﬁnish one attack iteration. Then, it goes
to the next iteration until the attack objective is achieved.
6 Experimental Setup
6.1 Dataset and DNN Models
In our experiment, we evaluate three classes of datasets. First,
we use CIFAR-10 [90] and ImageNet [3] for image classiﬁca-
tion tasks. The other application is object detection where we
evaluate the attack on the popular COCO [91] dataset.
For CIFAR-10 dataset, we evaluate the attack against pop-
ular ResNet-20 [4] and VGG-11 [92] networks. We use the
same pre-trained model with exact conﬁguration as [56, 89].
For ImageNet results, we evaluate our attack performance on
MobileNetV2 [93], ResNet-18 and ResNet-50 [4] architec-
tures. For MobileNetV2 and ResNet-18, we directly down-
loaded a pre-trained model from PyTorch Torchvision models
2 and perform an 8-bit post quantization same as previous
attacks [27, 56]. For the ResNet-50, we use Xilinx 8-bit quan-
tized weight trained on ImageNet from [94]. The model we
use to validate the YOLOv2 is the ofﬁcial weight [95], trained
by COCO [91] dataset, and we quantize [96] each weight
value into 16-bits. Our code is also available publicly3.
6.2 FPGA Prototype Conﬁgurations
To validate the real-world performance of Deep-Dup, we de-
velop a multi-tenant FPGA prototype, using a ZCU104 FPGA
evaluation kit with an ultra-scale plus family MPSoC chip,
which has the same FPGA structure as these used in a commer-
cial cloud server (e.g., AWS F1 instance), running the above
2https://pytorch.org/docs/stable/torchvision/models.html
3https://github.com/ASU-ESIC-FAN-Lab/DEEPDUPA
USENIX Association
30th USENIX Security Symposium    1927
accuracy after the attack as Post-Attack TA. For a targeted
attack, we use Attack Success Rate (ASR) to evaluate the per-
formance of the attack; ASR is the percentage of the target
class samples miss-classiﬁed to an incorrect class after an
attack. For the object detection application, we use Mean Av-
erage Precision (mAP) as the evaluation metric that is the
primary metric in the ofﬁcial COCO dataset challenge web-
site4. In P-DES, the attack evolution (z) is set to (500/1000)
(white-box) and 100 (black-box). In our un-targeted attack,
we use a test batch containing 256/25 images for the CIFAR-
10/ImageNet dataset. Our code is available publicly5 with
detailed hyper-parameters .
7 Experimental Validation and Results
7.1 Measured Fault Injection Success Rate
As described in Fig. 2, the AWD attack targets the weight
transmission procedure, and the fault injection may not always
succeed. However, it is infeasible to validate such fault injec-
tion success rate in our black-box attack model, in which the
adversary has no access to the manipulated weight packages.
To measure that, we design another experiment using an AXI4-
based weight transmission with the same YOLOv2 setup, i.e.,
the same memory copy operation. We deﬁne the burst length
of AXI4 as 256. The entire YOLOv2 int16 quantized weight
(99496KB) needs 99496 bursts to ﬁnish the transmission for
one input image inference. To avoid an FPGA system crash,
we only trigger one attack at the middle transmission moment
of a burst. To mimic the practical multi-tenant environment
with the victim DNN model being executed simultaneously,
we run a YOLOv2 in parallel. The available power-plundering
circuits are also the same as that in Sec. 6.2. Using this experi-
mental setup, we measured the success rates of fault injection
by RO and LRO power-plundering circuits are 84.84% and
58.91%, respectively.
FPGA system crash avoidance.
It has been discussed in
prior work [80] that a too-aggressive power attack (i.e., lever-
aging a large power-plundering circuit, or triggering it with
unsuitable frequency and duty-cycle) will possibly cause an
FPGA system crashes. In our case study, we limit the hard-
ware resources available to the adversary. Additionally, to
avoid such system crash, we apply two constraints on the trig-
gering of AWD attacks: 1) A short activation period of each
fault injection and 2) A large enough interval between any
two consecutive fault injections. Specially, our experiment
sets each fault injection period to 50 ns, from which we did
not observe a crash of the FPGA setup. The attacking inter-
val between each two consecutive fault injection is set to be
longer than 600 ns, which is handled by our P-DES algorithm
development, i.e., searching for target attack indexes with a
certain distance in between.
4https://cocodataset.org/#detection-eval
5https://github.com/ASU-ESIC-FAN-Lab/DEEPDUPA
Figure 8: Experimental setup and results of Deep-Dup black-
box attack on YOLOv2, with ‘person’ as target group. After
attack, the fault-injected YoLov2 model fails to recognize the
‘person’.
discussed deep learning applications: image classiﬁcation and
object detection. The 8-bit quantized DNN models are de-
ployed to our FPGA prototype through a high-level synthesis
(HLS) tool, PYNQ frameworks, and CHaiDNN library from
Xilinx [94]. The experimental setup is shown in Fig. 8. For ob-
ject detection (i.e. YOLOv2) FPGA implementation, multiple
types of hardware accelerators (HAs) are used to compute dif-
ferent network layers, such as convolution layer, max-pooling
layer, and reorganization layer. Specially, the region layer and
data cascade are assigned to the ZYNQ’s ARM core. For
image recognition (e.g. ResNet-50) FPGA implementation,
we follow the same design as the Xilinx mapping tool, which
only implements the convolution accelerator in a light version
(DietChai) [94]. Without loss of generality, the FPGA conﬁg-
urations follow the ofﬁcial parameters [97] and [94]. Object
detection network (i.e. YOLOv2) in FPGA execution fre-
quency is 180MHz on Image recognition DNN network (e.g.
ResNet-50) in FPGA execute frequency is 150MHz/300MHz,
where the DSP uses a 300MHz clock source to increase the
throughput and for the other logic we use a 150MHz clock.
To emulate a multi-tenant FPGA environment, we di-
vide the FPGA resources into victim and attacker zones, re-
spectively. The victim zone runs target DNN models, like
YOLOv2 or ResNet-50, while the attacker zone mainly con-
sists of malicious power-plundering circuits. Moreover, to
limit the available resources of attacker, only 13.38% of the
overall FPGA resources are assigned for the power-plundering
circuits.
6.3 Evaluation Metric and Hyper-parameters
For classiﬁcation application, we use Test Accuracy (TA) as
the evaluation metric. Test Accuracy is the percentage of sam-
ples correctly classiﬁed by the network. We denote the test
1928    30th USENIX Security Symposium
USENIX Association
Weight bufferClean          Post-attackPost-attack DNN model person not recognizedClean DNN model person recognizedAttacker zoneVictim zoneTable 1: Summary of the White-Box Attack on CIFAR-10 and ImageNet Dataset. Here, ts denotes the target class which we
randomly selected for each cases. The attack number is the best number out of three test rounds due to randomness.
White-Box Attack on Image Recognition
Un-Targeted Attack
Targeted Attack
Dataset
Network
# of Parameters TA (%)
Post-Attack
# of
Post-Attack
TA (%)
Attacks
TA (%)
Target Class(ts)
CIFAR-10
ResNet-20
VGG-11
MobileNetV2
ImageNet
ReNet-18
ReNet-50
0.27 M
132 M
2.1 M
11 M
23 M
90.77
90.38
70.79
69.35
72.97
10.92
10.94
0.19
0.18
0.19
28
77
1
106
175
21.63
23.68
8.93
34.45
30.57
ASR
(%)
99.2
98.6
# of
Attacks
14
63
1
13
20
Bird
Horse
Lesser Panda
100.0
Ostrich
Ostrich
100.0
100.0
Table 2: Black-Box targeted attack results for ImageNet.
Table 3: Black-Box attack for object detection.
Black-Box Targeted Attack on ResNet-50 using RO cell
Black-Box Un-Targeted Attack on YOLOv2 using RO cell
(ts)
TA(%)
Post-Attack TA(%) ASR (%)
# of Attacks
Target Class (ts) mAP
Post- Attack mAP
# of Attacks
Ostrich
72.97
46.96
100
26
All
0.428
0.06
30
7.2 White-Box Attack Results
Image Classiﬁcation Task. We evaluate the proposed
Deep-Dup white-box attack framework (in Fig. 6) on two
popular Image Classiﬁcation datasets in Tab. 1. First, for
CIFAR-10, our attack achieves close to the target random
guess level accuracy (e.g., 10 % for CIFAR-10) with only
28 attack iterations (un-targeted) on ResNet-20. However, to