ManTrap keeps extensive audit logs of activities in its cages. Since all activity in a 
cage is suspicious (because no legitimate users belong there), as much information as 
possible is logged. Examples of the activities that a running ManTrap will log: 
•  All terminal input and output 
•  All files opened for writing 
•  All device accesses 
•  All processes that are started 
•  All network activity 
198      Brian Hernacki, Jeremy Bennett, and Thomas Lofgren 
The ManTrap logs are meant to provide an (almost) complete view of the activities 
inside  the  cage.  ManTrap  also  allows  the  administrator  to  cryptographically  verify 
that the logs have not been tampered with (see Audit Reliability below). 
Response 
When ManTrap detects cage activity, it is capable of alerting the administrator and/or 
responding automatically. The administrator can configure a response policy includ-
ing: 
•  SMTP (E-mail) alerts 
•  SNMP traps (alerts to network management software)  
•  Integration with other commercial threat management solutions (e.g. NIDS)  
•  Custom responses: administrator-specified scripts or binaries to be run on a particu-
lar event 
These  responses  can  be  used  to  alert  administrators  when  a  cage  is  accessed;  to 
shutdown a cage once the attacker has achieved a certain level of access (e.g. gained 
root), etc. 
Analysis 
The log data that is collected inside a cage is used to provide different types of activ-
ity reports. Reports can be generated on-demand or on a scheduled, regular basis, and 
cover cage activities such as: 
•  File modifications 
•  Successful logins to the cage 
•  Responses triggered by the cage 
•  Attempted connections 
•  Outgoing connections 
•  TCP and/or UDP port activity on the cage 
In addition, the ManTrap administration console allows a user to be able to monitor 
interactive sessions in a terminal window, either while the session is active, or after 
the fact. This gives the ManTrap administrator a unique and realistic view of what the 
intruder saw and did during the attack. 
5.3   Construction Experience 
General Technique 
As mentioned above, ManTrap is an instrumented system. It is constructed primarily 
by means of a kernel module that intercepts systems calls and provides filtering and 
modification. This is backed by a virtualized file system and various coordination and 
supporting administration processes. For example, if a process in a cage attempts to 
call open() to open /etc/passwd, the ManTrap module intercepts this call and redirects 
it so that the cage copy of the file is opened instead. 
Isolation 
ManTraps foremost requirement is that the cages be isolated from the root system and 
from each other. A process within the cage is not allowed to access files, directories, 
or devices except those explicitly exposed to it. A process within the cage is not al-
lowed to interact with a process outside the cage. However, this must all be accom-
Symantec Deception Server Experience with a Commercial Deception System      199 
plished  without  causing  compatibility  problems  for  applications  running  inside  the 
cage.  One  important  feature  of  ManTrap  was  that  the  users  (administrators)  are  al-
lowed  to  run  existing  applications  inside  the  deception  environment  without  any 
modification. This was quite a challenge. While we were not universally successful as 
some applications require raw device support, require conflicting kernel functionality, 
or  present  some  unacceptable  privilege  risk,  in  general  ManTrap  is  able  to  provide 
this isolation while still maintaining compatibility.  
Stealth 
One  of  the  key  requirements  which  differentiate  ManTrap  from  many  existing  host 
virtualization  techniques  (VMware  [5],  Solaris  zones  [6],  etc)  is  stealth.  ManTrap 
required that processes running within the virtualized environment, the cage, not be 
able  to  determine  that  it  was  not  the  “real”  system.  This  required  that  all  traces  of 
monitoring, virtualization and other instrumentation be hidden. It also required that all 
activity in other cages on the same host be hidden. This included local files, running 
process lists, network data and many other things. This also needed to be done with-
out  causing  compatibility  functions  for  applications  running  inside  the  cages  and 
without  doing  anything  that  would  tip  off  an  attacker.  As  there  are  numerous  such 
interfaces  in  the  operating  system,  and  many  of  them  not  well  documented,  this 
proved to be one of the most significant challenges. It is also one in which there exists 
an adversarial pressure. Attackers (and sometimes researchers) would actively attempt 
to  find  ways  in  which  the  cage could be differentiated from the real system. While 
several techniques were eventually discovered nearly all were easily addressed. The 
only remaining ones were those which required root access and relied on accessing 
some hard-to-emulate resources such as /dev/kmem (see below Current Challenges). 
Audit Reliability 
Since  one  of  the  values  of  something  like  ManTrap  is  its  ability  to  collect  detailed 
data for use in analysis or potentially as evidence, the reliability of the data is very 
important. While the prior isolation requirement should provide a guarantee that an 
attacker inside the cage not be able to access or influence the audit trail, ManTrap was 
designed  with  an  additional  integrity  control  in  its  audit  system.  ManTraps  are  de-
ployed with a hardware crypto-token called an iButton [7]. One of the tasks the sys-
tem uses the iButton for is log signing. Periodically, ManTrap will sign its log files 
using functionality embedded in the token. If an attacker later succeeds in accessing 
the log files, any modifications they make can be easily detected since the signature 
validation will later fail. At best, such an attacker could delete the logs or portions of 
them.  
Cage Restoration 
One of the key features added to later version of ManTrap was the ability to easily 
restore a pristine cage image. A problem encountered with early version of ManTrap 
(and other honeypots) is that once an attacker has “compromised” the honeypot and 
made  modifications,  the  cage  is  tainted.  While  it  may  be  useful  to  maintain  it  in  a 
tainted state for some period of time (so an attacker can return to what they believe is 
a compromised system), eventually the administrator may wish to restore the system 
to a clean state and begin again. This would allow them for example to clearly differ-
entiate between what one attacker did and what subsequent attackers may do. It is a 
200      Brian Hernacki, Jeremy Bennett, and Thomas Lofgren 
very difficult task for an administrator to “undo” modifications made by an attacker, 
even  assuming  sufficient  audit  trail  exists  to  reliably  perform  this  task.  While  it  is 
always  possible  to  completely  reload  the  system and perform all customization and 
configuration again, this are very time consuming tasks. ManTrap added functionality 
to allow administrators to easily restore configurations post installation and customi-
zation. Thus restoring to a clean but configured and customized state is mostly a mat-
ter of clicking a button. 
Automated Analysis 
Since  ManTrap  is  intended  to  be  used  by  administrators  with  limited  security  and 
systems expertise, it attempts to provide some level of automated analysis of the data 
it  collects.  In  some  cases  this  is  merely  presentation  or  basic  aggregation  of  lower 
level data. In other cases it is application of a basic knowledge of security impact of 
common  events.  In  the  former  case,  ManTrap  is  able  to  reconstruct  data  from  key-
stroke traces into a session view of the attackers “terminal” for easy observation. In 
the latter case, it is able to make the determination that a root shell has been created 
from a non-root shell (without explicitly authenticating) and that it may possibly indi-
cate  use  of  a  local  privilege  escalation  exploit.  While  this  is  still  a  long  ways  from 
providing an “expert in a box”, it does succeed in lowering the amount expertise re-
quired for use. Improvement in this area is discussed below. 
5.4   Current Challenges 
While we consider the ManTrap product a great success, there are still a number of 
open problems or challenges to be addressed to fully realize our original goals. We 
discuss four of the most significant below. 
Once  an  attacker  has  succeeded  in  obtaining  root  access,  even  emulated,  it  be-
comes difficult to maintain some portions of our functionality; most notably stealth. 
While it is possible to prevent the “root” process in the cage from accessing external 
resources, in some cases this presents a significant signature. For example, consider 
the  situation  in  which  a  root  process  attempts  to  access  /dev/kmem  directly.  If  the 
system disallows the access it presents a property which can be used as a signature. If 
access is allowed the system must virtualize this resource. Allowing access (e.g. via a 
pass-thru to the real /dev/kmem) would allow an intruder to see and possibly modify 
anything  in  memory,  even  things  outside  the  cage.  Unfortunately  virtualizing  some 
resources,  like  kernel  memory,  is  quite  difficult  (maybe  impossible)  and  not  some-
thing we have accomplished yet. 
Another difficulty we encountered in developing ManTrap is that, due to its design, 
it has a very high porting cost. Since many of the modifications performed to instru-
ment  the  system  are  done  using  very  platform  specific  interfaces  and  must emulate 
functionality  which  is  very  specific  to  a  particular  operating  system,  any  port is al-
most a complete rewrite. While administrative components and general design can be 
reused, much of the hard work (and the research necessary to design it) must be done 
for each operating system supported. Additionally some operating systems (e.g. Win-
dows)  differ  enough  in  their  basic  architecture  that  considerable  redesign  must  be 
done. 
One of the original goals was to reduce the expertise required to operate a honey-
pot  to  increase  the  size  of  the  potential  user  base.  While  we  think  the  functionality 
Symantec Deception Server Experience with a Commercial Deception System      201 
provided  in  ManTrap  makes  great  progress  in  this  area,  there  is  still  room  for  im-
provement. While basic maintenance tasks are well automated and data presentation 
is easy to use, the system cannot perform much automated analysis. There would be 
considerable value in a system which could automatically assess attacker intent and 
skill level. Functionality which could automatically assess the nature, risk, and pur-
pose  of  new  files  transferred  onto  the  system  (e.g.  exploit  kits)  would  also  be  very 
valuable. Automated analysis in general is a large and open area for computer security 
research, but there are a number of very honeypot specific tasks in which we envision 
future progress. 
6   Summary and Conclusions 
Our experience developing ManTrap validated our initial concept that it was possible 
to build such a deep instrumented system honeypot. It was possible by modifying the 
operating  system  using  existing  access  points  to  provide  for  the  needed  isolation, 
stealth, and audit functionality. It was also possible to automate enough of the admin-
istrative tasks to create a tool that was usable without considerable honeypot exper-
tise. Our practical experience with the users revealed that most administrators capable 
of administering a Solaris system were also capable of administering a ManTrap. We 
did  however  discover  that  in  many  environments  where  it  was  desirable  to  deploy 
honeypots, even that level of expertise did not exist. We conclude that while we met 
our original design goals, this suggests there is a need to further reduce the adminis-
trative complexity. 
Through numerous incidents, these honeypots proved to be valuable compliments 
to existing security infrastructure. They were able to detect attacks earlier than other 
systems, detect attacks other systems did not, and provide an extremely high level of 
data about the attackers, their methods and intent. We conclude that deception tech-
nologies or honeypots are an important, emerging security technology. They provide 
the  defender  with  both  the  time  and  information  needed  to  effectively  respond  to  a 
wide variety of threats. They are cost effective to deploy and administer and are capa-
ble of detecting threats other detection technologies cannot. They provide a powerful 
defense mechanism that should be a component of any security solution.  
References 
1.  “Symantec Enterprise Solutions. Symantec Corporation”, Retrieved Mar. 2004,  
http://enterprisesecurity.symantec.com/products 
2.  “Honeyd  –  Network  Rhapsody 
Information  Technology 
Integration”,Retrieved Mar 2004,   http://www.citi.umich.edu/u/provos/honeyd/index.html 
for  You.  Center 
for 
3.  “The Honeynet Project“,Retrieved Mar 2004,  
http://project.honeynet.org/misc/project.html 
4.  “Talisker  Host  Intrusion  Detection  System.  Security  Wizardry”,  Retrieved  Feb.  2004, 
http://www.networkintrusion.co.uk/HIDS.htm 
5.  “Vmware”, Retrieved Mar. 2004, http://www.vmware.com  
6.  “Solaris Zones. Sun Microsystems - BigAdmin”, Retrieved Mar. 2004,  
http://www.sun.com/bigadmin/content/zones/index.html  
7.  “iButton Products: iButton Overview”, Retrieved Mar. 2004,  
http://www.ibutton.com/ibuttons/index.html 
202      Brian Hernacki, Jeremy Bennett, and Thomas Lofgren 
8.  C. Stoll, 2000, “Cuckoo’s Egg: Tracking a Spy Through the Maze of Computer Espion-
age”, Pocket Books 
9.  “SecurityFocus HOME Products: Cybercopy Sting”, Retrieved Jun. 2004,   
http://www.securityfocus.com/products/515 
10.  B.  Cheswick,  “An  Evening  with  Berferd  In  Which  a  Cracker  is  Lured,  Endured  and 
Studied”, Proc. Winter USENIX Conference, 1992 
11.  D. Moore, V. Paxson, S. Savage, C. Shannon, S. Staniford, and N. Weaver, “ The Spread 
of the Sapphire/Slammer Worm”, 2003,  
http://www.caida.org/outreach/papers/2003/sapphire/sapphire.html 
12.  L. Spitzner, “Honeypots Definitions and Value of Honeypots”, Retreived Jun. 2004,   
http://www.tracking-hackers.com/papers/honeypots.html