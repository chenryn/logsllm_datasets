175
179
183
171
175
180
356
356
356
335
335
335
317
317
317
4
4
5
3
3
3
0
1
1
40
42
43
37
39
42
34
38
40
67
67
67
63
63
63
59
59
59
5
6
8
4
6
6
1
1
1
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
Table 8. Comparison with existing IP(cid:173)based blacklists (DNSBL).
Blacklist name
FN
FP
Threshold Our FN Our FP
Comb FN Comb FP
Spamhaus
Spamcop
SORBS
11.54% 0.31%
22.32% 0.18%
63.06% 0.10%
0.97
0.98
0.99
8.6%
11.5%
15.3%
0.27%
0.18%
0.17%
5.32%
6.56%
11.34%
0.33%
0.22%
0.20%
son is that these IPs are less frequently used by spam-
mers, thus less likely observed by spam traps to be
blacklisted.
Indeed, we found that more than 75% of
such IPs fall into smaller clusters (with active host size
smaller than 15) which are potentially less likely abused
by spammers given a limited number of likely compro-
mised IPs. And yet since most IPs in the cluster send
spam, the aggregated spam ratio of those clusters are
high enough to identify newly appearing spammer IPs
within the cluster.
7.2 Integration with SpamAssassin
The cluster reputation history collected can be used
as a feature to predict future spam. We attempt to in-
tegrate it with SpamAssassin to quantify how many of
its false negatives we can reduce by using cluster-based
reputation history. As we have previously shown in Fig-
ure 5, about 4% of emails fall into the score range from
two to ﬁve given the threshold of 5 which may contribute
to false negatives. To obtain the ground truth of whether
a particular email is spam, we would need to examine
the email content. Due to privacy concerns, we can only
examine several of our own personal accounts with per-
mission. We also use a honeypot account with all its
emails considered as spam along with the personal ac-
counts to estimate the overall improvement from cluster-
based reputation. SpamAssassin generates a false nega-
tive rate of 16% for the honeypot email account.
We study how much of SpamAssassin’s false nega-
tives can be reduced as well as how much false positives
may be introduced by incorporating the cluster-based
reputation scheme. We assign scores for IP addresses
that fall within bad clusters with varying parameters and
evaluate the accuracy as shown in Table 7. FNR stands
for False Negative Reduced. FPI denotes False Posi-
tive Introduced. Matched indicates how many IP ad-
dresses fall into existing clusters built over 7-month of
training data. The number of matched IPs serves as an
upper bound for emails that can be classiﬁed as spam by
the cluster-based scheme. Spam ratio threshold is the
threshold for determining whether the cluster is consid-
ered bad, and additional score is added for an incoming
email. Score assigned is the score to be added to the
original score assigned by SpamAssassin.
Since we are not blocking emails directly based on
cluster reputation, we relax the spam ratio threshold to
be 0.7, 0.8 and 0.9 respectively with the score assigned
to be 1, 2 and 3 respectively. We can see that for the hon-
eypot account, we are able to detect about 50% of the
missed spam by SpamAssassin when we set the thresh-
old of spam ratio to 0.9 and the score assigned to 3. This
is despite the fact that we only have the history for 60%
of clusters that the spammer’s IP addresses fall into. For
other personal accounts, we observe similar false nega-
tive reduction with a fairly small amount of false posi-
tives introduced. In fact, if we use the spam ratio thresh-
old of 0.9 and assigned score of 3, we only incur at most
one false positive instance for all accounts which trans-
lates into only 0.0036% false positive rate. Upon in-
spection, the particular false positive email is a paper
invitation sent from China (the conference was held in
China) whose IP address falls into a cluster from which
almost all of IP addresses sent purely spam to us. Inter-
estingly, this IP has no reverse DNS name and is listed
on SORBS blacklist which indicates that either the same
machine is compromised at some point or the IP resides
in a dynamic IP range (although we have checked that
this IP is not identiﬁed as dynamic IP by UDMap).
On the other hand, with BGP cluster applied directly
to the same account with spam ratio of 0.9 and assigned
score of 3, although we can still reduce a similar num-
ber of false negatives, we observe 7 false positives intro-
duced, clearly indicating the downside of its inaccurate
administrative boundary. For personal account 3, we do
not observe any false positives for any threshold experi-
mented. However, we cannot reduce any false negatives
either due to the fact there is only one false negative in-
stance out of 11 spam emails by SpamAssassin and the
IP address of this spam happens to fall within a cluster
for which we do not have any history.
8 Concluding remarks
In conclusion, we have studied the characteristics of
different types of network clusters and investigated how
to combine them into a uniform one. We compare the
performance of a combined clustering approach inte-
grating both DNS and preﬁx information with previ-
ously proposed BGP preﬁx clusters and existing widely
used IP-based blacklist (DNSBL) to demonstrate im-
proved spam detection accuracy. We also integrate our
proposed cluster-based reputation into SpamAssassin to
catch 30-50% of the spam that are missed by SpamAs-
sassin at the cost of very small false positive increase.
Our technique is designed to be robust to potential eva-
sion attempts due to the inherent stable properties of the
network information used. Another advantage is that
our system can work well in a single vantage point, thus
can be easily deployed locally without requiring multi-
ple vantage points (presumably much harder to obtain).
We argue that our cluster scheme is robust against
various attacks. The most likely strategies of spam-
mers would be to cause us to construct either too coarse-
grained clusters where good and bad IPs are mixed or
mislead us to construct too ﬁne-grained clusters, which
in the extreme become IP-based blacklists. We consider
next how likely spammers can succeed in such endeav-
ors.
BGP preﬁx information cannot be easily controlled
by spammers unless they perform preﬁx hijacking at-
tacks or own a fairly large preﬁx, both of which are un-
likely due to high cost or overhead. DNS information is
more amenable to modiﬁcation, if spammers own an IP
range and thus control its reverse DNS mapping. Spam-
mers can construct rDNS names in a way that is most
beneﬁcial to them, e.g., by setting rANS to be the same
as that of their neighboring good IP ranges. To be truly
effective, such neighboring IP ranges must belong to the
same preﬁx as spammers’ IP ranges. Furthermore, they
need to make sure the rANS can resolve reverse DNS re-
quests for them. They can also construct their rANS in a
way that every single IP has a different rANS. This will
cause our clustering algorithm to falsely cluster each IP
into a separate cluster. However, this attack would again
require spammers to own IP address ranges, and such
rANS naming pattern itself would be an indication of
malicious activities because constructing rANS in such
a fashion is highly unusual.
IP-based blacklist captures the individual IP’s his-
tory, which includes a sudden behavioral change of an
IP address (e.g., legitimate mail servers become com-
promised to send many spam). It is more difﬁcult for
the cluster-based approach to drastically modify a clus-
ter’s behavior as it must observe behavioral change for
many IP addresses in the cluster. Note that by tracking
history over a sufﬁciently long period of time, our ap-
proach can dynamically adapt to the behavioral changes
in spamming. However, we expect the case where legit-
imate mail servers become compromised for spamming
to be relatively rare (compared to DSL users get com-
promised and abused for spamming). In our data-set, as
previously shown in §5.5, we did not observe much sig-
niﬁcant history changes for clusters. Another point to
note is that our clustering approach attempts to capture
regions of the Internet that “should” not have legitimate
servers with high probability (e.g., DSL clusters). In that
sense, any sending host is potentially bad. The detailed
analysis on the behavioral change of clusters is out of
the scope of this paper and we plan to pursue as future
work.
Acknowledgments
We thank our anonymous reviewers and Feng Qian
for suggestions that improved the quality of this paper.
This work is in part supported by NSF CNS-0643612,
DARPA, and Department of Navy.
References
[1] The
apache
project.
//spamassassin.apache.org/.
spamassassin
http:
[2] Dialup rdns.
http://home.comcast.net/
˜mcwebber/blocking.txt.
[3] Generic regular expressions for popular naming con-
http://www.ddf.net/spam/bad_
ventions.
relays.txt.
[4] Microsoft:
3% of
spam.
e-mail
is
stuff we want;
http://arstechnica.
is
rest
the
com/security/news/2009/04/
microsoft-97-percent-of-all-e-mail-is-
spam.ars.
[25] S. Sinha, M. Bailey, and F. Jahanian. Shades of Grey:
On the Effectiveness of Reputation-based ”Blacklists”.
In Malware 2008, 2008.
[26] S. Sinha, M. Bailey, and F. Jahanian.
Improving spam
blacklisting through dynamic thresholding and specula-
tive aggregation.
In Proc. of the 17th Annual Network
and Distributed System Security Symposium (NDSS),
2010.
[27] V. M. Telecommunications and V. Metsis. Spam ﬁltering
with naive bayes – which naive bayes? In Third Confer-
ence on Email and Anti-Spam (CEAS), 2006.
[28] S. Venkataraman, S. Sen, O. Spatscheck, P. Haffner, and
D. Song. Exploiting network structure for proactive spam
mitigation.
In Proceedings of 16th USENIX Security
Symposium on USENIX Security Symposium, 2007.
[29] Y. Xie, F. Yu, K. Achan, E. Gillum, M. Goldszmidt, and
In SIG-
T. Wobber. How dynamic are ip addresses?
COMM, 2007.
[30] Y. Xie, F. Yu, K. Achan, R. Panigrahy, G. Hulten, and
I. Osipkov. Spamming botnets: Signatures and charac-
teristics. In SIGCOMM, 2008.
[31] L. Zhuang, J. Dunagan, D. R. Simon, H. J. Wang, I. Osip-
kov, G. Hulten, and J. Tygar. Characterizing botnets from
email spam records. In LEET 08: First USENIX Work-
shop on Large-Scale Exploits and Emergent Threats,
2008.
[5] Rfc 4408, sender policy framework (spf) for authorizing
use of domains in e-mail, version 1. http://tools.
ietf.org/html/rfc4408.
[6] Rfc
for
draft,
generic
naming
suggested
unassigned
large
schemes
hosts.
http://tools.ietf.org/id/
draft-msullivan-dnsop-generic-naming-
schemes-00.txt.
networks
dns
and
[7] SORBS. http://www.au.sorbs.net/.
[8] Spamcop. http://www.spamcop.net/.
[9] Spamhaus. http://www.spamhaus.org/.
[10] Whois ip address/domain name lookup.
http://
cqcounter.com/whois/.
[11] D. S. Anderson, C. Fleizach, S. Savage, and G. M.
Voelker. Spamscatter: Characterizing Internet scam host-
ing infrastructure. In 14th conference on USENIX Secu-
rity Symposium, 2007.
[12] K. Chiang and L. Lloyd. A case study of the Rustock
rootkit and spam bot. In The First Workshop in Under-
standing Botnets, 2007.
[13] Dynablock
dynamic
IP list.
http://www.
spamhaus,
by
njabl.org/,
http://www.spamhaus.org/pbl/index.lasso, 2007.
recently
aquired
[14] S. Hao, N. A. Syed, N. Feamster, A. Gray, and
S. Krasser. Detecting Spammers with SNARE: Spatio-
temporal Network-level Automatic Reputation Engine.
In Proceedings of Usenix Security Symposium, March
2009.
[15] T. Holz, C. Gorecki, K. Rieck, and F. Freiling. Measuring
and detecting fast-ﬂux service networks. In Proceedings
of the Network and Distributed System Security Sympo-
sium, 2008.
[16] J. Jung and E. Sit. An empirical study of spam trafﬁc
and the use of dns black lists. In IMC ’04: Proceedings
of the 4th ACM SIGCOMM conference on Internet mea-
surement, 2004.
[17] M. Konte, N. Feamster, and J. Jung. Dynamics of online
scam hosting infrastructure. In Proc. Passive and Actice
Measurement Conference (PAM), 2009.
[18] B. Krishnamurthy and J. Wang. On network-aware clus-
In In Proceedings of ACM SIG-
tering of web clients.
COMM, 2000.
[19] F. Li and M.-H. Hsieh. An empirical study of clustering
behavior of spammers and group-based anti-spam strate-
gies. In CEAS 2006: Proceedings of the 3rd conference
on email and anti-spam, 2006.
[20] B. Medlock. An adaptive, semi-structured language
model approach to spam ﬁltering on a new corpus.
In
CEAS 2006 - Third Conference on Email and Anti-Spam,
July 2006.
[21] A. Ramachandran and N. Feamster. Understanding the
network-level behavior of spammers. In Proceedings of
Sigcomm, 2006.
[22] A. Ramachandran, N. Feamster, and S. Vempala. Filter-
ing spam with behavioral blacklisting. In Proceedings of
the 14th ACM conference on computer and communica-
tions security, 2007.
[23] A. Ramachandran, N. Feamster, and S. Vempala. Fil-
tering spam with behavioral blacklisting.
In CCS ’07:
Proceedings of the 14th ACM conference on Computer
and communications security, 2007.
[24] Route views project. http://www.routeviews.
org.