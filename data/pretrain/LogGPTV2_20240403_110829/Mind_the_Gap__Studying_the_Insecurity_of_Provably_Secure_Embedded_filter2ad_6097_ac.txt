experiments via a cycle-accurate iverilog simulation of the
openMSP430 core.
3) Exploiting missing attacker capabilities: In a third step,
we focus on the assumptions made about the attacker. These
are signiﬁcantly harder to validate: assumptions about the
behavior of the system itself can be validated by running
the system since a full
implementation is available. But
assumptions about the attacker cannot be validated this way:
essentially, we must determine whether the formal attacker
model used in the paper adequately captures the informal
attacker model (i.e., remote code execution on the device,
including control over untrusted DMA peripherals, but no
physical access, cf. Section III-A). For any attack we ﬁnd
against the real system that is not captured by the formal
attacker model, one should ask: is the attack intentionally out
of scope, or is it a shortcoming of the formal attacker model?
Our approach in this paper is to err on the side of security:
in case of doubt, we report the attack and consider the formal
attacker model incomplete. Of course, attacks that are clearly
out of scope (e.g., physical attacks that require the attacker to
open the device) are not reported or even investigated.
For this step, we use domain expertise about openMSP430
and known attacks from the literature to identify potential
attacks abusing features that are not modeled.
This is also inductive research: we try to ﬁnd attacks that
are missed, and if we succeed, this is evidence that the formal
attacker model is incomplete. However, even if we do not
succeed, there might still be attacks that we overlooked.
The outcome of this step includes both the identiﬁcation
of unmodeled attack capabilities and the development of
proof-of-concept attacks using these capabilities. The attack
techniques used can originate from the literature or can be
novel in themselves (cf. Section IV).
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:23:35 UTC from IEEE Xplore.  Restrictions apply. 
1642
4) Exposing deductive errors: Finally, the less rigorous
parts of the deductive arguments in both papers are reviewed,
and reasoning errors are investigated to see if they can inval-
idate the security properties of the system.
The outcome of this step is a list of errors in the formal
proof. Since these are errors in a strictly deductive argument,
in principle, no empirical validation is required to show the
error. However, we still illustrate potential attacks to show that
the deductive error leads to an actual violation of security.
D. Attack classiﬁcation
We classify the attacks found using the above methodology
into the following three categories:
1) Implementation/model mismatches: Attacks that are
successful on the implementation and can be represented
in the model, but fail there. This implies a disconnect
between the formal model and the implementation, either
of which might be considered incorrect depending on the
informal description of the system.
2) Missing attacker capabilities: Attacks that are success-
ful on the implementation but cannot be represented in
the formal model due to missing features or components.
3) Deductive errors: Attacks that can be represented and
are successful within the formal model. This implies a
mistake in the formalization itself, i.e., a ﬂaw in the proof.
IV. A NOVEL DMA CONTENTION SIDE CHANNEL
In this section, we introduce a novel DMA-based side-
channel attack effective on the openMSP430 platform, on
which both SancusV and VRASED are based. This attack
requires the attacker to have control over a DMA-capable pe-
ripheral connected to the system. More precisely, the attacker
needs to be able to read and write the signals that are exposed
to the peripheral from the core. This could happen either by
plugging in a custom untrusted peripheral; or by compromising
the ﬁrmware of an already connected sophisticated peripheral,
constituting a fully remote attack. In this section, we brieﬂy
introduce the idea behind the attack, whereas we will expand
on its impact on the studied systems in the following sections.
A. Security concerns with DMA
On systems with no security measures, DMA requests can
access the entire memory space, thus interfering with sensitive
processes running on the system [41]. Other researchers have
abused DMA to bypass improperly conﬁgured I/O memory
management unit protection and access protected memory
regions [42]–[44]. Even without direct access to secrets, DMA
has been used as a side channel to facilitate other attacks, e.g.,
analyzing write access patterns using memory snapshots [45]
or sampling analog-digital converter data [46] to reconstruct
CPU activity.
In security architectures, DMA is usually more restricted.
On VRASED [15] and the upstream version of Sancus [31],
DMA requests are not allowed to access any memory that
belongs to protected software. The policy is the same on high-
end security architectures, for instance on Intel SGX [47].
B. Attack idea
The key idea of the attack is to measure subtle timing delays
arising from contention between an untrusted DMA device and
the trusted CPU when accessing the shared memory bus.
Transmitting or exﬁltrating data through different compo-
nents of the main memory unit of an architecture is a lively
research ﬁeld [48]–[51], but to the best of our knowledge,
no previous attacks utilized side-channel timing differences
of DMA requests to reconstruct the memory accesses of a
protected program running on the CPU.
CPU
DMA interface
y
r
o
m
e
M
e
n
o
b
k
c
a
b
Memory
Fig. 5. Memory bus contention between CPU and DMA on openMSP430.
On openMSP430, the CPU and DMA-enabled devices are
connected to the same memory bus through the memory
backbone, as shown in Figure 5. One memory request can
be served per clock cycle. In case of concurrent memory
accesses within the same cycle, by default the openMSP430
memory backbone gives priority to the CPU, delaying any
outstanding DMA requests. This resource contention can be
used to infer the exact, cycle-accurate timing of memory
accesses by the CPU. More speciﬁcally, by issuing a DMA
request to unprotected memory and measuring if the request
takes longer than one cycle to complete, a malicious peripheral
can infer whether the memory bus was used by the CPU in
that speciﬁc cycle.
1
2
3
4
1
2
3
4
clk
mem
inst
MOV #N, &ADDR
clk
mem
inst
ADD #N, &ADDR
Fig. 6. Memory traces of mov and add.
To provide a quick glance into the details of the attack, con-
sider the extracted memory traces presented in Figure 6. This
ﬁgure shows the execution of the mov and add instructions
with the same parameters. The execution length of both these
instructions is 4 cycles2, making them indistinguishable to an
instruction-granular Nemesis attacker (cf. Section II-A1). Our
DMA side channel, however, can capture the memory accesses
of the CPU at a cycle-level granularity within the execution of
both instructions. Hence, we can distinguish the instructions in
Figure 6, based on whether a CPU memory access is detected
(i.e., the DMA request is delayed) in the second cycle or not.
V. SECURITY ANALYSIS OF SANCUSV
A. Identifying falsiﬁable assumptions
As explained above, the security argument for SancusV [14]
relies on the main assumption that the implementation follows
2The execution length of a given instruction also depends on its operands.
Later, we will see mov and add instructions with different execution lengths.
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:23:35 UTC from IEEE Xplore.  Restrictions apply. 
1643
the operational semantics deﬁned in the pen-and-paper model.
Because this assumption is very complex and difﬁcult
to
falsify, we decomposed it into multiple sub-assumptions. We
list the ones that we falsiﬁed and found to be exploitable in the
top part of Table I. The bottom part lists exploitable features
that were not modeled in SancusV. Importantly, we did not
ﬁnd any deductive errors in the SancusV proof.
TABLE I. List of falsiﬁed and exploitable assumptions found in SancusV.
IM = Implementation-model mismatch; MA = Missing attacker capability.
V-B1
V-B2
V-B3
V-B4
V-B5
V-B6
V-B7
V-C1
V-C2
Instruction execution time does not depend on the context.
The maximum instruction execution time is T = 6.
Interrupted enclaves can only be resumed once with reti.
Interrupted enclaves cannot be restarted from the ISR.
The system only supports a single enclave.
Enclave software cannot access unprotected memory.
Enclave software cannot manipulate interrupt functionality.
Untrusted DMA peripherals are not modeled.
Interrupts from the watchdog timer are not modeled.
IM
MA
B. Validating the implementation
1) Variable instruction length following reti:
In the
SancusV model, instructions always take the same number
of clock cycles to execute,
independent of the previously
executed instruction.
a) Broken assumption: We found that, in the real-world
openMSP430 implementation, non-jump instructions execut-
ing after a reti instruction take an extra cycle to execute.
To make matters worse, this extra cycle is also added to the
interrupt handling logic if it follows a reti instruction.
b) Attack: This subtle microarchitectural effect can
clearly be abused to differentiate two otherwise contextually
equivalent enclaves: E1 = {add; nop; nop} and E2 =
{nop; nop; jmp}, where nop normally takes 1 cycle, and
add and jmp take 2 cycles. When interrupting both enclaves
after two clock cycles, the ﬁrst nop in E1 gets an extra
cycle, while jmp in E2 does not. Hence, E1’s resume-to-end
execution time will be one cycle longer compared to E2.
Beyond this speciﬁc example, we experimentally showed
that any two instructions with different execution lengths can
be differentiated, even when E1 and E2 do not contain jmp
instructions. This attack scheme is demonstrated in Figure 7,
where we can detect whether the very ﬁrst executed instruction
was a two-cycle add in E1 or a one-cycle nop in E2.
CLK
IRQ
E1
E2
1
2
3
9
10
11
12
13
14
15
16
22
23
24
...
...
ADD
IRQ 8
IRQ 8
NOP IRQ 8
...
IRQ 8
ISR
ISR
RETI r0
IRQ 8
IRQ 8
ISR
RETI r0
NOP
IRQ 8 ...
IRQ 8
ISR
Fig. 7. Second interrupt handler is delayed.
The trick is to cleverly issue two consecutive interrupts.
The ﬁrst interrupt arrives while the target enclave instruction
is executing (cycle 1). Next, SancusV’s hardware-level double
padding defense, described in Section II-A2, balances interrupt
latency to make sure the ISR executes at the same time (cycle
10) in both cases. Furthermore, to ensure constant resume-to-
end timings, the next reti will be padded with the number
of cycles the initial interrupt processing was delayed (1 cycle
in the case of E1, zero for E2). We now schedule the second
interrupt when we expect the longer reti to ﬁnish (cycle 14).
In the case of E1, the interrupt handling logic will immediately
follow reti and will gain the extra cycle. In the case of
E2, however, the next regular instruction will have already
started executing by the time the interrupt comes in, and the
following interrupt handling logic will have the correct number
of clock cycles (as it does not follow the reti directly).
Hence, the attacker-controlled ISR will execute at a different
time, i.e., cycle 23 vs. 24, depending on the initially interrupted
instruction. This means a complete bypass of the defense.
c) Mitigation: This issue highlights the risks of a sep-
arate implementation and pen-and-paper model. Patching it
requires a thorough analysis of the openMSP430 two-stage
pipeline to identify the precise cause of the added delay
and either eliminating it or making sure it applies to every
instruction and the interrupt handling logic itself.
2) Instructions with execution time T > 6: To correctly
calculate the required padding, SancusV needs to know the
maximum instruction execution length. This length is an
explicit parameter in the SancusV model, and is deﬁned to
be T = 6 cycles, as this is the longest length listed in the
openMSP430 documentation [26].
a) Broken assumption: Our analysis revealed two cases
where Sancus-speciﬁc instructions exceed the assumed limit.
First, the real-world Sancus implementation extends the origi-
nal openMSP430 core to also allow writes to program memory.
We found that such writes induce an extra penalty cycle, such
that instructions of the form mov &ram, &rom will take 7
cycles. Second, SancusV does not model the cryptographic in-
structions added by Sancus. These are executed atomically, as
with any other openMSP430 instruction, but can take several
thousands of cycles, depending on the passed parameters [16].
b) Attack: The real-world implementation continuously
decrements a 3-bit padding counter (starting from the value
6) after the interrupt arrives and before the current instruction
ﬁnishes. We experimentally conﬁrmed that when this counter
underﬂows, an incorrect length is calculated for the subsequent
interrupt handling logic. This breaks the padding scheme and
enables attackers to distinguish enclaves that use instructions
exceeding 6 cycles.
c) Mitigation: The implementation should be correctly
parameterized with the real maximum execution bound T .
This is relatively straightforward in the case of 7 cycles for
program memory writes, but less so for unmodeled crypto-
graphic instructions that can take thousands of cycles (with an
impractical upper bound in the order of 216 when hashing
the entire 16-bit address space). Options for cryptographic
operations may include adopting an abandon-restart interrupt
policy [18], or disallowing them altogether inside enclaves,
which would, however, break crucial attestation functionality.
Ideally, to avoid further implementation-model mismatches,
T should be determined from the Verilog code, e.g., using
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:23:35 UTC from IEEE Xplore.  Restrictions apply. 
1644
static analysis to determine the highest possible number of
clock cycles an instruction might spend in execution.
3) Resuming an enclave with reti multiple times:
The SancusV model includes a separate shadow register ﬁle,
referred to as the “backup”,
to securely save and restore
the interrupted enclave’s secret register values. The model
explicitly dictates that the CPU should only ﬁll the backup
when an interrupt arrives in enclave mode, and, upon the next
reti instruction, check whether the backup is non-empty and,
if so, restore the original values from the backup, mark it as
empty, and return control to the interrupted enclave.