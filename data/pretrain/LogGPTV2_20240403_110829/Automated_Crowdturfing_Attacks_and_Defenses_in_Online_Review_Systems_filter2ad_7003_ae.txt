distribution. Based on this observation, we propose a simple policy
for the service provider to further raise the bar for evasion: set a min-
imum review length. Figure 13 shows how detection performance
varies as we increase the minimum review length requirement
against an attack model with 1, 024 hidden units. Note that the
average review length on Yelp Training Data (Section 3.3) is 483
characters. When we increase the minimum length requirement to
300 characters (i.e. still below the average), F-score increases from
0.80 to 0.86, which nullifies the attack success gained by increasing
model size from 512 to 1,024 hidden units (from Figure 12). This
means that the attacker now must aim for training a significantly
larger attack model, at the expense of increased training cost, to
overcome the reduction in attack success.
Evading Detection by Generating Reviews at Different Tem-
peratures. When reviews from a language model are detected
as fake, one would expect the attacker to build a new language
model (thus raising the cost) for the next attack. Instead, the at-
tacker can try to evade further detection by generating new reviews
using the existing model, by changing the temperature parameter
(without re-training). While our scheme can detect reviews at dif-
ferent temperatures when we have ground-truth information at
those temperatures (Figure 10), performance remains unclear when
ground-truth information is unavailable. Put differently: Using a
defense scheme trained on reviews at a specific temperature, can we
detect reviews generated at other temperatures? If this is possible,
it would allow the service provider to defend against such attacks
without having to collect new ground-truth information.
We investigate the above scenario in Figure 14, where we train
the linguistic classifier and our scheme at a specific temperature
(Ttrain) and evaluate detection performance at all other tempera-
tures (Ttest). Both Ttrain and Ttest are from 0.1 to 1. The training
configuration is same as the one used for 2K training samples in
Table 3.
As expected, the linguistic classifier exhibits poor defensive
power at higher temperatures. At low temperatures, we see that a
defense trained at a given temperature maintains effectiveness at
temperatures in the “neighborhood” of that region, possibly due to
similar linguistic characteristics in the temperature neighborhood.
However, the performance drops quickly when Ttrain and Ttest are
far apart.
On the other hand, our approach shows an interesting trend.
Unlike the linguistic classifier, our performance maintains robust-
ness whenever Ttrain > Ttest. This is because a review generated
at a high temperature would include both infrequent and frequent
patterns from the training sequence. As a result, a defense trained
at a higher temperature can capture the frequent sequences present
in the character distribution of a review at a lower temperature.
Hence, our defense scheme maintains high performance even when
Ttrain and Ttest are distant as long as Ttrain ≥ Ttest. It should be
noted that the attacker has an incentive to generate reviews at high
temperatures because they are more likely to deceive users (Sec-
tion 4.2). As such, the service provider can likely obtain some initial
ground-truth information about reviews at high temperatures, and
thus build a robust defense.
6 RELATED WORK
Text Generation. There are a number of natural language genera-
tion techniques based on pre-defined templates [57, 58, 70]. These
systems usually require some domain knowledge and well-designed
rules. Recently, learning-based approaches became popular, i.e.
building a statistical model to learn the language information from
a large corpus. In these cases, the quality of the generated text
Session E4:  Adversarial Social Networking CCS’17, October 30-November 3, 2017, Dallas, TX, USA1153Figure 12: Detection performance against attacks generated
by different models and their training costs.
Figure 13: Detection performance when the minimum review
length is restricted.
detection [8, 25], malware classification [62, 66, 81], and password-
based authentication systems [39].
Similar to our work, a few studies also investigate the feasibil-
ity of attacking online systems using Deep Neural Networks. This
includes proposals to automatically solve CAPTCHAs using Con-
volutional Neural Networks [13, 60], and automatically generate
malware domains using Generative Adversarial Networks [1]. To
the best of our knowledge, our work is the first to explore attacks
on online review systems using Deep Neural Networks.
Crowdturfing and Review Spam Detection. Prior work char-
acterized crowdturfing marketplaces that supply human labor to
enable attacks on a variety of online platforms, such as review sys-
tems, social media, and search engines [29, 73, 74]. In addition, work
by Wang et al. investigates detection of malicious crowdworkers
using machine learning and explores the robustness of machine
learning classifiers against evasive tactics by crowdworkers. Fur-
thermore, researchers have extensively studied detection of opinion
spam or fake reviews in online review systems using features based
on review content [32, 48, 53] and a variety of metadata [10, 19, 20].
We differ from these studies by focusing on automatically gener-
ating fake reviews that can evade detection by advanced machine
learning classifiers and human investigation.
7 DISCUSSION & CONCLUSION
In this work, we focus on the potential for misuse of deep learning
models in the context of attacking online review platforms. Our
work shows how RNNs can generate deceptive yet realistic looking
reviews targeting restaurants on Yelp. An extensive evaluation of
the quality of generated reviews indicates the difficulty in detecting
such reviews using existing algorithmic approaches, and even by
human examination (which serves as an end-to-end test of our
attack).
We propose a novel approach to defend against RNN-based fake
reviews, by leveraging a fundamental limitation of an RNN-based
model: information loss incurred during the training process when fit-
ting a large training dataset to a fixed size statistical model. Due to the
information loss, generated reviews diverge from real reviews when
comparing their character-level distribution, even when higher level
linguistic characteristics are preserved. Our scheme, based on su-
pervised learning, can detect machine-generated reviews with high
accuracy (F-score ranging from 0.8 to 0.98 depending on the amount
(a) Linguistic classifier
(b) Our method
Figure 14: Detection performance (F-score) of training and
then applying at different temperatures.
highly correlates with the model quality. Previous work shows that
well-trained RNN models outperform simpler language models like
N-gram [21] and RNN-based language models have appeared as
a promising approach to generate text [14, 67]. Researchers have
also achieved successful results in generating text for different
domains, including email responses [23], image description [24],
movie dialogues [64] and online social network conversations [65].
Our work is closest to studies by Lipton et al. [33], Hovy [17]
and Lappas [27]. Lipton et al. [33] also studies product review gen-
eration using an RNN, but does not consider an adversarial setting.
Hovy [17] performed a preliminary investigation of n-gram-based
review generation in an adversarial setting. Unlike our research,
they do not consider more sophisticated generative models (RNN)
to evade detection, and do not consider any robust defenses or
countermeasures. Lastly, Lappas [27] analyzes fake reviews from
the attacker’s perspective to determine the factors that enable a
successful attack, but does not consider automatic generation of
reviews.
Neural Networks and Security. Most prior studies on applying
Neural Networks focus on improving existing defenses against
various network and web security vulnerabilities. Work in this
category mainly includes proposals to improve network intrusion
 0.6 0.7 0.8 0.9 1 0 500 1000 1500 2000 2500 0 100 200 300 400Detection F-scoreTraining Time (Hours)Attack Model SizeF-scoreTraining Time 0.6 0.7 0.8 0.9 1 0 150 300 450 600 750 900Detection F-scoreMinimum Review Length (# of characters)0.10.20.30.40.50.60.70.80.91.0Temperature of Training0.10.20.30.40.50.60.70.80.91.0Temperature of Test 0 0.2 0.4 0.6 0.8 10.10.20.30.40.50.60.70.80.91.0Temperature of Training0.10.20.30.40.50.60.70.80.91.0Temperature of Test 0 0.2 0.4 0.6 0.8 1Session E4:  Adversarial Social Networking CCS’17, October 30-November 3, 2017, Dallas, TX, USA1154of available ground-truth) and outperforms existing ML-based fake
review filters.
Future Work. In terms of potential future work, one direction is to
consider the role that user and content metadata can play in both the
attack and defense perspectives. Metadata can be crucial in terms of
deceiving users (e.g., by increasing the number of friends/contacts
on the site) and in assisting defenses [10, 19, 20, 31, 47, 71, 75] (e.g.,
by analyzing the patterns in timestamps of user activites). Orches-
trating the general behavior of user accounts using deep learning
to bypass metadata based defenses could be an interesting research
challenge. Second, while we limit ourselves to the domain of on-
line review systems and fake review attacks, deep learning-based
generative text models can be applied to launch attacks in other
scenarios as well. We highlight two of these possible application
scenarios.
Strengthening Sybil Attacks. Attackers can use our techniques to
generate realistic looking text-based user behavior patterns [4], e.g.,
posting, commenting and messaging. This can help attackers make
Sybil (fake) accounts indistinguishable from legitimate accounts
based on textual content. A special case of this involves launching
an impersonation attack in online social networks [11].
Fake News Generation. Identifying fake news, i.e. “a made-up story
with an intention to deceive” [61], currently remains an open chal-
lenge [9]. The research community has started to explore the possi-
bility of automating the detection process by building an AI-assisted
fact-checking pipeline [41, 72, 76]. We believe that AI can not only
assist fake news detection but also generate fake news. Given the
availability of large-scale news datasets [68], an attacker can poten-
tially generate realistic looking news articles using a deep-learning
approach (RNN). And due to its low economic cost, the attacker
can pollute social media newsfeeds with a large number of fake
articles.
We hope our results will bring more attention to the problem
of malicious attacks based on deep learning language models, par-
ticularly in the context of fake content on online services, and
encourage the exploration and development of new defenses.
A REVIEW CUSTOMIZATION DETAILS
We show the details of review customization process (Section 3.1)
in Algorithm 2.
B MORE EXAMPLES OF THE GENERATED
FAKE REVIEWS
We present examples of generated reviews targeting a specific
restaurant (description shown below). The samples are generated
under different temperatures and from the models trained using
five-star, three-star and one-star Yelp training review corpus.
Target Restaurant Description
Experience MKT, a market-to-table San Francisco restaurant and bar. Taste your
way through ultra-creative handcrafted cocktails, small plates for sharing, and
steaks from the finest California ranches. Meet friends and relax in our retro
urban-chic atmosphere. In the heart of SoMa - with panoramic fifth-floor views
of Market Street and downtown - this is one of San Francisco’s best restaurant
venues for social drinks and dining.
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
B.1 Machine-generated One-Star Reviews
Generated with temperature 0.1
I was so excited to try this place out for the first time and the food was awful. I
ordered the chicken sandwich and it was so salty that I could not eat it. I was so
disappointed that I was so disappointed in the food. I was so disappointed that
I was so disappointed with the service.
Generated with temperature 0.3
I had a drink at this restaurant. I was there for a couple of months. The restau-
rant was clean but the food was not good. The service was very slow and the
service is so bad. I would not recommend this place to anyone.
Generated with temperature 0.5
The worst place I’ve ever been too. I waited for a while and the place was not
available and the service was absolutely terrible. The server was rude and not
apologetic and unprofessional. I will not be going back to this location.
Generated with temperature 0.7
I have been here twice, very expensive for what you get. We stayed here before
at our table and were seated in a line for 15 minutes and the restaurant was
full and the cashier recommended the drinks and they forgot the cookie cover
charge and we were told it was not an issue. I would never recommend this
place to anyone.
Generated with temperature 1.0
DO NOT WASTE YOUR TIME AND MONEY! The absolute worst service I have
ever experienced. This place is a joke. The waitress was rude and said she would
put the manager to come out but never happened. I wish I could give zero star.
B.2 Machine-generated Three-Star Reviews
Generated with temperature 0.1
The food was good but not great. I had the lasagne and the sauce was a little
too sweet for my taste. The salad was good but the sauce was a little too sweet
for my taste. The sauce was a little too salty for my tastes. The sauce was a little
too sweet for my taste.
Generated with temperature 0.3
I’ve had the fried chicken and the chicken breast with chicken soup with sweet
potato fries. I don’t know what a lot of the meat was on the salty side as well.
The sauce was a bit salty and didn’t have much flavor. The salad was tasty and
well presented but the bread was super tasty.
Generated with temperature 0.5
I was here for a weekend brunch and the food was ok. I love the pizza that is
a chain restaurant. I think the service is excellent. I had the spaghetti and they
were very good and the hot dog was good. I got the red velvet chocolate cake
special which was very good but the service was a little slow. The food was
good, but not up to par with other places nearby.
Generated with temperature 0.7
Algorithm 2 Review Customization
▷ input: R-initial review, T-reference review set, C-topic key-
word, MINsim-similarity threshold
1: procedure Review Customization(R, T, C, MINsim)
▷ find nouns in R close to C
P ← ∅
for t ∈ T do
for n ∈ Nouns(t) do
P← P(cid:83) n
if similarity(n, C) > MINsim then
▷ find nouns in R also close to C, replace by sampling from P
for n ∈ Nouns(R) do
if similarity(n, C) > MINsim then
S ← S(cid:83) similarity(n, p)
S ← ∅
for p ∈ P do
z ← softmax(S)
n∗ ← sample from P based on z
replace n by n∗
return R
Session E4:  Adversarial Social Networking CCS’17, October 30-November 3, 2017, Dallas, TX, USA1155The food wasn’t bad. The cupcakes are okay and the service is excellent but the
prices are a bit high. I do like the fresh made salad and drink specials. I would
recommend this place for a place to grab a bite for a couple of times.
Generated with temperature 1.0
Came here for lunch today and the place was pretty empty. The steak was good