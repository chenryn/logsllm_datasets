of 2; (iv) convolution layer: four 2 × 2 convolution kernels with the
stride of 1; (v) fully-connected layer (FC): a 100 × 10 parameter ma-
trix; (vi) output layer: a 10 × 1 prediction vector. Table 1 shows the
execution time of the operations related to the two models. Our ML
encryption protocol provides 17× faster feed forward than E2DM.
As E2DM does not support back propagation, we only measure the
back propagation for our ML encryption protocol. We notice that
back propagation is much faster than feed forward since it does not
involve any cryptographic computation (see Sec 6.1).
Operations
Table 1: Execution Time of CNN models
Execution Time (second)
Ours
E2DM
0.48
0.40
0.14
0.20
2.59
35.88
N/A
0.05
Data Encryption
Model Encryption
Feed Forward
Back Propagation
Specifically, the overheads of model and data encryption are the
shopper-side and seller-side overhead, respectively. The overhead
of feed forward is essentially the cloud-side prediction overhead
in the process of data selection. Additionally, the total overhead of
feed forward and back propagation represents the overhead of a
cloud-side training epoch in the process of data validation.
9 RELATED WORK
Data Marketplaces. A cloud-based data marketplace [3, 9, 18, 21,
23] offers a platform where enterprises or individuals can sell their
digital asset or purchase a dataset. Researchers have proposed a
number of cloud-based data marketplace frameworks that provide
flexible data search and evaluation. For instance, Koutris et al. [21]
propose a back-end for data market, providing various query oper-
ations. Li et al. [23] present a correlation-driven data marketplace
where shoppers can find the most correlated data for correlation
analysis. Although these data marketplaces support shoppers to
purchase expected data for a variety of interests, they fail to con-
sider data privacy in the cloud. Hynes et al. [17] envision the first
privacy-preserving data marketplace that leverages the Trusted
Execution Environment (TEE) to protect data. However, some sen-
sitive information may still be inferred from TEE [4, 34, 40], and
TEE has some memory limits. Additionally, none of the existing
data marketplaces support valuable data evaluation for ML tasks.
Machine Learning Encryption. Prior work has proposed a num-
ber of ML encryption frameworks [7, 14, 16, 19, 27], which are
built on either homomorphic encryption (HE) or secure multiple-
party computation (MPC). Although SIMD [38] can be applied to
optimize HE-based ML frameworks, they still suffer from computa-
tional resource limitations, and the size of ciphertexts explosively
grows with calculation numbers. Moreover, existing HE-based ML
frameworks do not support flexible training operations. Therefore,
data shoppers cannot utilize training operations to examine data
quality. Compared to HE-based ML frameworks, MPC-based ML
frameworks support training operations, and they are more efficient.
However, they incur expensive communication overhead.
10 DISCUSSION
Generalizability. Our machine learning encryption protocol pro-
vides the encryption approaches for fully-connected/convolution
layers and the corresponding input data. As pooling is essentially
convolution, this encryption protocol can also protect pooling lay-
ers. Therefore, our Primal framework can protect various shopper’s
models in the process of data selection and validation, provided
that the models consist of convolution, fully-connected, and pool-
ing layers. Amongst these models, the representative models are
CNN models, which have been widely adopted in various areas,
especially computer vision.
11 CONCLUSION
In this paper, we propose a privacy-preserving and efficient ML
data evaluation framework on a data marketplace, called Primal. It
allows enterprises and individuals to sell their data and purchase
valuable ML data without leaking their data and ML models. To
preserve data privacy and model privacy in the cloud, we present
a privacy-preserving ML protocol based on inner product func-
tional encryption and matrix transformation. With this protocol,
we design a privacy-preserving data selection protocol and data
validation protocol that can provide valuable data for shoppers.
Our security analysis and experiments demonstrate the security,
efficiency, and effectiveness of Primal.
ACKNOWLEDGMENTS
This work was supported in part by the Office of Naval Research
grants N00014-16-1-3214 and N00014-18-2893; in party by the Na-
tional Science Foundation grant CNS-1815650; in part by NSFC
under Grant 62132011 and 61825204; in part by BNRist under Grant
BNR2020RC01013; in part by Beijing Outstanding Young Scientist
Program under grant BJJWZYJH01201910003011; and in part by
the Shuimu Tsinghua Scholar Program. Qi Li and Jiahao Cao are
the corresponding authors.
REFERENCES
[1] Abdalla, Michel et al. 2015. Simple functional encryption schemes for inner
products. In IACR International Workshop on Public Key Cryptography. Springer,
733–751.
[2] Agrawal, Shashank et al. 2015. On the practical security of inner product func-
tional encryption. In IACR International Workshop on Public Key Cryptography.
Springer, 777–798.
[3] Bdex. 2018. First-ever Data Exchange Platform. https://www.bdex.com/
[4] Brasser, Ferdinand et al. 2017. Software Grand Exposure:SGX Cache Attacks Are
[5] Campbell, Colin et al. 2000. Query learning with large margin classifiers. In
Practical. In 11th USENIX Workshop on Offensive Technologies.
ICML, Vol. 20. 0.
[6] Ran Canetti. 2001. Universally composable security: A new paradigm for crypto-
graphic protocols. In Proceedings 2001 IEEE International Conference on Cluster
Computing. IEEE, 136–145.
[7] Chabanne, Hervé et al. 2017. Privacy-preserving classification on deep neural
network. IACR Cryptology ePrint Archive 2017 (2017), 35.
270ACSAC ’21, December 6–10, 2021, Virtual Event, USA
Qiyang Song1, Jiahao Cao2,3, Kun Sun1, Qi Li2,3, and Ke Xu2,3
[8] David Cash et al. 2015. Leakage-Abuse Attacks Against Searchable Encryption. In
Proceedings of the 22nd ACM SIGSAC Conference on Computer and Communications
Security. ACM, 668–679.
[9] Dawex. 2019. Orchestrate data circulation with Data Exchange technology.
https://www.dawex.com/
[10] Du, Simon S et al. 2018. On the power of over-parametrization in neural networks
with quadratic activation. arXiv preprint arXiv:1803.01206 (2018).
[11] An end-to-end open source machine learning platform. 2019.
tensorflow.org/
https://www.
[12] Fredrikson, Matt et al. 2015. Model inversion attacks that exploit confidence
information and basic countermeasures. In Proceedings of the 22nd ACM SIGSAC
Conference on Computer and Communications Security. ACM, 1322–1333.
[13] Freund, Yoav et al. 1997. Selective sampling using the query by committee
algorithm. Machine learning 28, 2-3 (1997), 133–168.
[14] Gilad-Bachrach, Ran et al. 2016. Cryptonets: Applying neural networks to en-
crypted data with high throughput and accuracy. In International Conference on
Machine Learning. 201–210.
[15] Yifan Gong. 1995. Speech recognition in noisy environments: A survey. Speech
communication 16, 3 (1995), 261–291.
[16] Graepel, Thore et al. 2012. ML confidential: Machine learning on encrypted data.
In International Conference on Information Security and Cryptology. Springer.
marketplace. Proceedings of the VLDB Endowment 11, 12 (2018), 2086–2089.
[17] Hynes, Nick et al. 2018. A demonstration of sterling: a privacy-preserving data
[18] IOTA. 2018. making it possible to securely store and sell. https://data.iota.org/
[19] Jiang, Xiaoqian et al. 2018. Secure outsourced matrix computation and applica-
tion to neural networks. In Proceedings of the 2018 ACM SIGSAC Conference on
Computer and Communications Security. ACM, 1209–1222.
[20] Joshi, Ajay J et al. 2009. Multi-class active learning for image classification. In 2009
IEEE Conference on Computer Vision and Pattern Recognition. IEEE, 2372–2379.
[21] Koutris, Paraschos et al. 2013. Toward practical query pricing with QueryMarket.
In proceedings of the 2013 ACM SIGMOD international conference on management
of data. ACM, 613–624.
[22] LeCun, Yann et al. 1998. Gradient-based learning applied to document recognition.
86, 11 (1998), 2278–2324.
[23] Li, Yanying et al. 2018. Cost-efficient data acquisition on online data marketplaces
for correlation analysis. Proceedings of the VLDB Endowment 12, 4 (2018), 362–375.
[24] The GNU Multiple Precision Arithmetic Library. 2018. https://gmplib.org/
[25] The Pairing-Based Cryptography Library. 2018. https://crypto.stanford.edu/pbc/
[26] Livni, Roi et al. 2014. On the computational efficiency of training neural networks.
In Advances in neural information processing systems. 855–863.
[27] Mohassel, Payman et al. 2017. Secureml: A system for scalable privacy-preserving
machine learning. In 2017 IEEE Symposium on Security and Privacy (SP). IEEE,
19–38.
[28] Naveed, Muhammad et al. 2014. Dynamic searchable encryption via blind storage.
[29] Nenkova, Ani et al. 2012. A survey of text summarization techniques. In Mining
[30] THE MNIST DATABASE of handwritten digits. 2013. http://yann.lecun.com/
In 2014 IEEE Symposium on Security and Privacy. IEEE, 639–654.
text data. Springer, 43–76.
exdb/mnist/
[31] Riazi, M Sadegh and Samragh, Mohammad et al. 2019. XONN: XNOR-based
Oblivious Deep Neural Network Inference. IACR Cryptology ePrint Archive 2019
(2019), 171.
[32] Rouhani, Bita Darvish et al. 2018. Deepsecure: Scalable provably-secure deep
learning. In Proceedings of the 55th Annual Design Automation Conference. ACM.
[33] SABRINA DE CAPITANI DI VIMERCATI et al. 2010. Encryption Policies for
Regulating Access to Outsourced Data. ACM Transactions on Database Systems
35, 2 (2010), P.12.1–12.46.
[34] Schwarz, Michael et al. 2017. Malware guard extension: Using SGX to conceal
cache attacks. In International Conference on Detection of Intrusions and Malware,
and Vulnerability Assessment. Springer, 3–24.
[35] Avi Schwarzschild, Micah Goldblum, Arjun Gupta, John P Dickerson, and Tom
Goldstein. 2021.
Just how toxic is data poisoning? a unified benchmark for
backdoor and data poisoning attacks. In International Conference on Machine
Learning. PMLR, 9389–9398.
[36] Sebe, Nicu et al. 2005. Machine learning in computer vision. Vol. 29. Springer
Science & Business Media.
[37] Burr Settles. 2009. Active learning literature survey. Technical Report. University
[38] Smart, Nigel P et al. 2014. Fully homomorphic SIMD operations. Designs, codes
and cryptography 71, 1 (2014), 57–81.
[39] Xi Wu, Matthew Fredrikson, Somesh Jha, and Jeffrey F Naughton. 2016. A
methodology for formalizing model-inversion attacks. In 2016 IEEE 29th Computer
Security Foundations Symposium (CSF). IEEE, 355–370.
[40] Xu, Yuanzhong et al. 2015. Controlled-channel attacks: Deterministic side chan-
nels for untrusted operating systems. In 2015 IEEE Symposium on Security and
Privacy. IEEE, 640–656.
[41] Zheng, Zibin et al. 2013. Service-generated big data and big data-as-a-service: an
overview. In 2013 IEEE international congress on Big Data. IEEE, 403–410.
of Wisconsin-Madison Department of Computer Sciences.
A SECURITY PROOF
We repeat the security theorem for our efficient machine learning
encryption protocol here and provide a proof sketch.
Theorem 1. Our ML encryption protocol securely realizes a given
functionality FP if the random numbers chosen for each layer are
pseudo-random, and the inner-product functional encryption scheme
IFE is secure.
Proof 1. According to Definition 1, the protocol ΠP is said
to securely realize a given functionality FP if for any real-world
adversary A, there exists an ideal-world adversary S such that no
environment Z can tell whether it is interacting with A and parties
running the protocol, or with S and parties that interact with FP in
the ideal world. In our framework, the real-world adversary A can
corrupt the cloud. To prove the security, we describe an ideal-world
adversary S that simulates A. To be precise, S runs A internally
by playing the role of a seller and a shopper as follows.
Playing the role of a shopper in Z. Note that the functions of
Setup and Model Encryption involve a shopper. Here, the ideal-
world adversary S simulates the output of these functions. First,
S chooses a random number mpk∗ and sends it to sellers as a
master public key. In the real world, the master public key mpk is
also randomly chosen, the environment Z cannot distinguish the
simulated mpk∗ from the real mpk.
Second, S simulates the encrypted parameters of the i-th hidden
layer as follows. If i = 1 and the layer is a fully-connected layer, S
∗
fills random numbers in a vector (cid:174)CW
1 as encrypted parameters. If
i > 1 and the layer is a fully-connected layer, or i = 1 and the layer
is a convolution layer, S fills random numbers in a two-dimension
(or CK∗
matrix CW∗
) as encrypted parameters. If i > 1 and the
1
i
layer is a convolution layer, S fills random numbers in a four-
dimension matrix CK∗
as encrypted parameters. Then, S sends the
i
encrypted parameters to A. Here, recall that the real encrypted
parameters (cid:174)CW 1 (or CK1) of the first hidden layer are encrypted by
IFE. Therefore, we can say the environment Z cannot distinguish
the simulated (cid:174)CW
) from the real (cid:174)CW 1 (or CK1) if IFE is
secure. Additionally, recall that the real encrypted parameters of
the i-th (i > 1) hidden layer are transformed by random numbers.
If this layer is a fully-connected layer, and its encrypted parameters
CWi can be presented as follows.
∗
1 (or CK∗
1
CWi[x][y] = Wi[x][y] ∗ (cid:174)Ri[x]/((cid:174)Ri−1[y])2
(12)
where (cid:174)Ri is the random numbers chosen for the i-th hidden layer,
and Wi is the original parameters. Note that each parameter is
randomized by a random number. Therefore, we can say the envi-
ronment Z cannot distinguish the simulated CW∗
from the real
i
CWi if (cid:174)Ri and (cid:174)Ri−1 are pseudo-random in a finite field. If this layer
is a convolution layer, and its encrypted parameters CKi can be
presented as follows.
,
CKi[k][v][:][:] = Ri[k][v]/
i−1[k ∗ s : k ∗ s + |Ki|][v ∗ s : v ∗ s + |Ki|] × Ki,
R2
(13)
where Ri is the random numbers chosen for the i-th hidden layer,
Ki is the original kernel, s is the convolution stride. Note that each
parameter is randomized by a random number. Therefore, we can
271Try before You Buy
ACSAC ’21, December 6–10, 2021, Virtual Event, USA
say the environment Z cannot distinguish the simulated CK∗
from
i
the real CKi if Ri and Ri−1 are pseudo-random in a finite field.
Playing the role of a seller in Z. Note that only the function of
Data Encryption involves a seller. Therefore, S only simulates the
output of Data Encryption. It works as follows. If data (cid:174)x is input in
a fully-connected layer, then S fills random numbers in a vector
(cid:174)C∗
x and sends it to A as the encrypted data. If data X is input in
a convolution layer, then S fills random numbers in a vector C∗
X
and sends it to A as the encrypted data. Recall that both the real
encrypted data (cid:174)Cx and CX are encrypted by IFE. Therefore, we can
from the real (cid:174)Cx or C∗
say that Z cannot distinguish (cid:174)C∗
if
IFE is secure.
□
x or C∗
X
X
272