```    
drop table if exists t_order_q;  
create unlogged table t_order_q (    
  id serial8 primary key,   -- 自增主键    
  order_id uuid unique,     -- 上游传递过来的订单号    
  cts timestamp not null    -- 上游传递过来的订单创建时间     
);     
-- create index on t_order_q (cts); -- 如果按订单时间先后取出处理, 则需要创建时间字段索引.  本实验按自增主键顺序处理, 则不需要时间索引.     
```    
2、取出并处理后的订单状态表     
```    
drop table if exists t_order_u;  
create unlogged table t_order_u (    
  id serial8 primary key,   -- 自增主键    
  order_id uuid unique,     -- 上游传递过来的订单号    
  cts timestamp not null,    -- 上游传递过来的订单创建时间     
  uts timestamp not null,   -- 订单处理时间    
  status int not null       -- 订单处理状态标记     
);      
```    
3、写入100万条订单队列    
```    
truncate t_order_q;  
insert into t_order_q (order_id, cts) select gen_random_uuid(), clock_timestamp() from generate_series(1,1000000);    
```    
#### 传统方法 设计和实验      
1、写pgbench压测脚本, 从t_order_q队列取出一条订单信息, 然后处理这条订单信息, 并将处理结果插入到t_order_u处理结果表.    
```    
vi t1.sql    
begin;    
select id as vid from t_order_q order by id for update limit 1 \gset    
with tmp as     
  (delete from t_order_q where id = :vid returning order_id, cts)    
insert into t_order_u (order_id,cts,uts,status) select tmp.order_id, tmp.cts, now(), 1 from tmp;     
end;    
```    
2、压测256个并发消耗队列, 平均每个连接处理3906个事务.    
```    
select 1000000/256.0;    
3906.2500000000000    
```    
3、压测结果    
```    
pgbench -M extended -f ./t1.sql -n -r -P 1 -c 256 -j 8 -t 3906    
```    
```  
transaction type: ./t1.sql  
scaling factor: 1  
query mode: extended  
number of clients: 256  
number of threads: 8  
number of transactions per client: 3906  
number of transactions actually processed: 999936/999936  
latency average = 111.243 ms  
latency stddev = 125.890 ms  
initial connection time = 234.312 ms  
tps = 2280.326174 (without initial connection time)  
```  
tps: 2280.326174  
#### PolarDB|PG新方法1 设计和实验      
先重新生成测试数据.   
1、写pgbench压测脚本, 从t_order_q队列取出一条订单信息, 使用skip locked跳过被其他会话正在处理的订单, 然后处理这条订单信息, 并将处理结果插入到t_order_u处理结果表.    
```    
vi t2.sql    
begin;    
select id as vid from t_order_q order by id for update skip locked limit 1 \gset    
with tmp as     
  (delete from t_order_q where id = :vid returning order_id, cts)    
insert into t_order_u (order_id,cts,uts,status) select tmp.order_id, tmp.cts, now(), 1 from tmp;     
end;    
```    
2、压测结果    
```    
pgbench -M extended -f ./t2.sql -n -r -P 1 -c 256 -j 8 -t 3906    
```    
```  
transaction type: ./t2.sql  
scaling factor: 1  
query mode: extended  
number of clients: 256  
number of threads: 8  
number of transactions per client: 3906  
number of transactions actually processed: 999936/999936  
latency average = 65.596 ms  
latency stddev = 104.377 ms  
initial connection time = 234.029 ms  
tps = 3795.525190 (without initial connection time)  
```  
tps: 3795.525190  
#### PolarDB|PG新方法2 设计和实验      
先重新生成测试数据.   
1、写pgbench压测脚本, 从t_order_q队列取出1条订单数据(并且使用ad lock对队列ID加事务锁, 判断是否正在处理, 事务结束自动释放ad lock.  ad lock也经常被用于秒杀场景泄压.), 然后处理这条订单信息, 并将处理结果插入到t_order_u处理结果表.      
```    
vi t3.sql    
with tmp as     
  (delete from t_order_q where ctid = (select ctid from t_order_q where pg_try_advisory_xact_lock(id) order by id limit 1) returning order_id, cts)    
insert into t_order_u (order_id,cts,uts,status) select tmp.order_id, tmp.cts, now(), 1 from tmp;  
- 或  
-   
- begin;  
- select id as v_id from t_order_q where pg_try_advisory_xact_lock(id) order by id limit 1 \gset  
- with tmp as (delete from t_order_q where id = :v_id returning order_id, cts)   
-   insert into t_order_u (order_id,cts,uts,status) select tmp.order_id, tmp.cts, now(), 1 from tmp;     
- end;  
-   
- 或(sleep 模拟应用拿到需要处理的订单后的应用端操作增加的耗时.)  
-   
- begin;   
- select id as v_id from t_order_q where pg_try_advisory_xact_lock(id) order by id limit 1 \gset  
- \sleep 10ms  
- with tmp as (delete from t_order_q where id = :v_id returning order_id, cts)   
-   insert into t_order_u (order_id,cts,uts,status) select tmp.order_id, tmp.cts, now(), 1 from tmp;     
- end;   
```    
2、压测结果    
```    
pgbench -M extended -f ./t3.sql -n -r -P 1 -c 256 -j 8 -t 3906    
```    
```    
transaction type: ./t3.sql  
scaling factor: 1  
query mode: extended  
number of clients: 256  
number of threads: 8  
number of transactions per client: 3906  
number of transactions actually processed: 999936/999936  
latency average = 20.404 ms  
latency stddev = 45.780 ms  
initial connection time = 239.823 ms  
tps = 12283.493260 (without initial connection time)  
```    
tps: 12283.493260  
#### PolarDB|PG新方法3 设计和实验      
先重新生成测试数据. 使用分区表, 每次从1个分区队列获取订单, 从物理层面进一步减少IO 和 CPU 浪费.    
1、上游写入订单处理队列表    
```    
drop table if exists t_order_q;  
create unlogged table t_order_q (    
  id serial8 primary key,   -- 自增主键    
  order_id uuid ,     -- 上游传递过来的订单号    
  cts timestamp not null    -- 上游传递过来的订单创建时间     
) PARTITION BY hash (id) ;     
-- create index on t_order_q (cts); -- 如果按订单时间先后取出处理, 则需要创建时间字段索引.  本实验按自增主键顺序处理, 则不需要时间索引.     
do language plpgsql $$  
declare  
  x int := 256;  
begin  
for i in 0..x-1 loop  
  execute format ($_$create unlogged table t_order_q_%s PARTITION OF t_order_q FOR VALUES WITH (MODULUS %s, REMAINDER %s);$_$,   
    i, x, i  
  );  
end loop;  
end  
$$;  