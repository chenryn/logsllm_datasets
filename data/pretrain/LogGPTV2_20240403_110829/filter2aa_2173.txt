# Face Swapping Video Detection with CNN

**Authors:**
- Wang Yang
- Junfeng Xiong
- Liu Yan
- Hao Xin
- Wei Tao

**Institution:**
- Baidu X-Lab

## Overview
This document outlines a method for detecting face-swapped videos using a simple and effective Convolutional Neural Network (CNN). The approach is compared with a face recognition-based method, specifically using FaceNet combined with a Support Vector Machine (SVM) classifier.

## Deepfakes Video
Deepfakes are synthetic media in which a person's likeness is replaced with someone else's. This technology has raised concerns about the potential misuse of such videos, especially in scenarios where they can deceive face recognition systems.

### Vulnerability of Face Recognition Systems
Face recognition systems, such as those provided by Microsoft Azure and Amazon AWS, can be vulnerable to deepfakes. For example:
- **Microsoft Azure:**
  - Real vs. Fake: 86.0% Similarity
  - Real vs. Fake: 70.5% Similarity
- **Amazon AWS:**
  - Real vs. Fake: 95.1% Similarity
  - Real vs. Fake: 87.3% Similarity

## Face Swapping Video Generation
The process of generating face-swapped videos involves:
- **Characteristics:**
  - Independent manipulation of each frame.
  - Not an end-to-end process.
  - Focus on the central face area.
  - Use of autoencoders.
- **Training Phase:**
  - Conversion: Person A Encoder -> Person B Decoder.
- **Generation Phase:**
  - Merging back: Gaussian Blur/Color Average, Poisson Image Editing.

## Face Swapping Video Detection with CNN
### Methodology
- **Deepfakes Video:**
  - A simple and effective CNN for capturing low-level features of the images.
  - A face recognition-based method for capturing high-level features of faces.

### Simple and Effective CNN
#### Design Purpose
- Input includes marginal (background) information.
- Captures low-level features of the images.

#### Training
- **Dataset:**
  - VidTIMIT dataset: 67,600 fake faces and 66,629 real faces.
  - Low and high-quality images.
- **Preprocessing:**
  - Cropped faces using MTCNN face landmark detector.
  - Obtained 1.5 scaled bounding box.
- **Data Augmentation:**
  - Horizontal flipping.
  - Random zooming.
  - Shearing transformations.

#### Characteristics
- 3 convolution layers.
- Accuracy rate: 99%.

### Face Recognition Based Method
#### What is FaceNet?
- **Characteristics:**
  - State-of-the-Art (SOTA) CNN for face recognition.
  - Model structure.
  - Triple Loss.

#### FaceNet: A Unified Embedding for Face Recognition and Clustering
- **A FaceNet based SVM classifier:**
  - Central face area (no margin/background).
  - Dataset from VidTIMIT.

#### Training
- **Central Face Area:**
  - No margin or background.
  - Only face area.

#### Characteristics
- FaceNet used for extracting face features.
- SVM for binary classification.
- Accuracy rate: 94%.

## Summary
- **CNN for Image Classification:**
  - A simple architecture can work well.
  - Catches low-level features such as contours and edges.
- **FaceNet based SVM Classifier:**
  - Uses face recognition to catch features of fake faces.
  - Uses SVM for binary classification.
  - 64% accuracy rate for the misclassification set from the simple CNN-based classifier.

## Thank You!
**Q&A**

---

This revised version provides a more structured and coherent presentation of the research, making it easier to follow and understand.