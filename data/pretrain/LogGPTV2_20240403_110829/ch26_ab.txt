服务发现和主动/被动运行状况检查
分布式系统通常使用多种服务发现和运行状况检查。代理可以实现这些功能，或隐藏它们免受应用程序调用。
高级负载平衡高级负载平衡
具有一致且可靠的重试、超时、熔断、速率限制、阴影、异常值检测等实现对于任何中等大型系统都至关重要。当应用程序可以将这些功能完全卸载到代理时，应用程序代码的编写要简单得多，并且操作员可以放心，每个应用程序都可以访问相同的功能。
可观察性
正如已经多次提到的（稍后会展开讨论），边三轮代理提供的最重要的事情目前就是一致的可观察性。操作员可以访问分布式系统中每个跃点的一致统计信息、日志和跟踪。这种 100% 的覆盖范围可实现每个服务仪表板和警报的自动生成，以及每个服务和整个组织的高度操作一致性。
作为边缘代理的其他用途
事实证明，90% 的边缘代理和边三轮代理都相同。在两个位置使用相同的软件所获得的运营效率是很大的。如果单个组件可以同时执行这两个作业，为什么还要了解如何部署和监视边代理和边三轮代理？
易于部署和升级易于部署和升级
边三轮代理易于部署和升级，因为它没有嵌入到应用程序中。运维人员是否应在几分钟内在所有主机上部署新的二进制或代理配置？可能不是。能否使用过程外解决方案？是的。（进一步考虑部署 TLS 升级以修补每个应用程序中嵌入 TLS 时安全漏洞的示例）。
本章的其余部分介绍了边三轮代理或服务网格体系结构中一些更有趣的细微之处。  
最终一致的服务发现
   在分布式系统中，服务发现是分布式进程相互发现的机制。服务发现有很多种，从静态配置的IP到DNS，再到依赖完全一致的领导者选举协议（如 Zookeeper）的系统。在过去的5到10年中，使用完全一致的领导者选举商店（例如 Zookeeper、etcd 和 Consul）进行服务发现已经相当普遍。完全一致的系统的问题是：虽然某些用例是必需的，但它们极其复杂，需要大量的思考和谨慎才能运行，尤其是在具有大量数据的规模上。大公司有整个团队专门管理 Zookeeper 或 etcd，这种情况并不少见。逻辑告诉我们：除非问题真正需要完全一致性（例如分布式锁），否则不应使用完全一致性！但是，从历史上看，即使服务发现确实是一个最终一致的问题（只要选举肯定可以正确运行，运维人员是否真正关心每个主机是否具有与其他主机相同的网络视图？），很多时候还是使用了完全一致的实现，这许多时候会导致没必要的系统故障。
最佳服务网格设计假定从一开始就使用最终一致的服务发现系统。发现系统的数据与主动和被动运行状况检查交叉检查。主动运行状况检查是向/Healthcheck终点发送专用的 ping 动作（如 HTTP 请求）。被动运行状况检查是监视在线请求/响应数据以确定远程终结点运行状况的行为。例如，连续的三个 HTTP 503 响应可能表示远程终结点不可用。#service_discovery_and_active_health_check显示了边三轮代理如何使用服务发现数据，并结合活动运行状况检查的，共同完成后端主机的总体运行状况状态。主动运行状况检查被认为比服务发现更可靠；这意味着，如果服务发现数据丢失，但活动运行状况检查仍在传递，则代理仍将路由流量。仅当活动运行状况检查失败且后端不在服务发现的情况下，才会清除后端。这会产生高可靠性，因为服务发现数据最终可以一致，并且不会因为后端的自动维护而影响生产环境。
服务发现和活动运行状况检查矩阵
|  |
|
| 
| 
运行主动和被动的状况检查与最终一致的发现存储相结合（例如，每分钟都把主机签入具有生存时间的缓存中），这样可以让整个分布式系统保持最高的组件可靠性。
可观察性和报警机制
正如我已经多次提到的，可观察性最终是边三轮代理和服务网格体系结构提供的最重要的事情。网络层的问题肯定会发生。最重要的是为 SRE 工程师提供工具，以便他们能够识别问题，解决问题并尽快修复。为此，代理提供以下功能：每个跃点的一致统计信息
由于边三轮代理处理系统中每个应用程序的入口和出口流量，因此网格中的每个跃点都由同一组可靠的统计信息覆盖。从相对简单的操作（如每秒请求数、每秒连接数等）到完全动态统计信息（如每秒 HTTP 502 的个数和每个调用站点每秒的 Mongo 更新命令数等）等。
可以在整个系统中联接日志和跟踪的持久请求 ID
代理可以形成跟踪/请求 ID 记录，以便在所有网络跃点系统中保持唯一 ID。这允许生成跟踪、联接日志以及执行一致的采样。（如果采样是在整个系统中完成的，并且捕获整个请求流与完全随机采样，则 1% 的采样日志会更有用）。
每个跃点的一致日志记录
与统计数据一样，如果所有应用程序都输出相同格式的请求日志（不论采用什么语言开发），则人类和工具可以更容易地处理数据并快速理解数据。
整个系统的分布式跟踪整个系统的分布式跟踪
跟踪是可视化分布式系统请求流的一个极其强大的工具。但是，通常情况下，将其引入微服务体系结构非常复杂，因为必须修改每个应用程序以导入跨域编号，并转发上下文等。服务网格可以提供 100% 的跟踪覆盖率，无需任何应用程序参与。
一致的全系统报警
服务网格提供统计信息、日志记录和跟踪，允许为每个服务自动创建基本的警报机制，而不是依赖每个应用程序开发人员围绕服务调用成功率、延迟等设置基本警报。对于 SRE 工程师来说，这是一个非常强大的工具，他们现在可以更轻松地实施和审核系统范围的行为。
使用前面描述的工具，可以构建自定义自动生成的仪表板和工具，以便向工程师公开生成的信息，从而更轻松地对所有内容进行排序并确定问题的根本原因。其中包括“服务到服务”仪表板，允许工程师从下拉列表中选择源和目标服务，并查看该跃点的统计信息、跟踪和日志。UI/UX 是太广的话题，所以应该是其他章节的主题！边三轮性能影响
  到目前为止，很明显边三轮或服务网格设计为开发人员和可靠性工程师提供了巨大的好处。然而，经常出现一个共同的问题：性能怎么样？添加所有这些额外的跃点不会减慢很多速度吗？
确实，向分布式系统添加额外的跃点会导致延迟增加，并利用更多的计算机资源（CPU 和 RAM）。因此，以极其高效的方式编写边三轮代理非常重要。许多代理仍用本机 C/C++ 编写。但是，稍微考察性能问题并探讨详细信息非常重要。
在性能指标中，有两个主要考量是令人感兴趣的：
吞吐量
每单位时间可以推送多少数据（每秒请求数、每秒连接数、每秒事务数等）？
尾部延迟
 随着吞吐量的提升，组件在延迟直方图“尾部”的性能如何？也就是说，与 P99 甚至 P99.9 相比，P50 处的每次事务延迟如何？
虽然吞吐量很重要，但实际上，它只对最大型的公司很重要。这是因为对于较小的公司来说，开发人员的时间几乎总是比基础设施成本更有价值。在考虑总拥有成本（TCO）时，总体吞吐量才真正开始重要。相反，尾部延迟最终成为小型和大型企业最重要的性能指标。这是因为高尾部延迟的原因很难理解，并导致大量的开发人员和操作员认知负载。对于组织来说，工程师时间通常是最宝贵的资源，而调试尾部延迟问题是工程师所做的最耗时的事情之一。
因此，边三轮代理最终成为一把双刃剑。代理为系统添加了大量功能，以至于对于除了性能最密集的应用程序外，只要尾部延迟属性不受代理本身影响。这主要是因为代理的性能，特别是尾部延迟属性如此重要的原因。如果代理构成了观察整个分布式系统的基础，如果代理本身具有很大的可变性，如何信任数据？这就是为什么最好的代理仍然用本机代码编写，其性能目标类似于操作系统和数据库。
精简库和上下文传播
 服务网格可以为应用程序提供的好处非常大，而应用程序无需执行任何操作。然而，本章迄今掩盖了一个不幸的现实，即无论网格不网格，应用程序仍然需要发挥作用，主要是围绕上下文传播。上下文传播是从入口网络调用获取上下文，并可能对其进行修改，然后传递到出口网络调用的行为。如何做到这一点是语言或平台相关的，而不是边三轮代理可以提供的东西。尽管传播的上下文有许多用途，但与服务网格相关的主要用途是请求 ID 和跟踪上下文的传播。对于基于 HTTP 的体系结构，这主要通过 HTTP 头来完成，例如x-request-id 和 Zipkin x-b3-traceid头。服务网格的用户需要提供特定于应用程序和语言的精简库，以使用户能够轻松传播所需的 HTTP 标头。虽然它超出了本章的范围，但我希望看到开发人员在未来几年内为此目的使用的库的一些融合。
精明的读者现在可能会问：“但你说服务网是神奇的！我仍然要做些什么？”
确实，如果需要完整的功能，开发人员仍然需要在应用程序层参与网格。但是，这仍然只能算是极少的代码和功能，否则将需要在每种语言和框架中重复实现。
配置管理（控制平面与数据平面）配置管理（控制平面与数据平面）
  到目前为止，我们已经讨论了服务网格在构建可靠的微服务架构时可以提供的许多功能。我们还没有讨论如何配置整个系统，这可能变得非常复杂。首先，一些定义：
数据平面
 这是系统实际参与转发网络流量的部分。这包括负载平衡、连接池、请求修改和响应修改等。数据平面涉及每个请求和响应的每个字节。
控制平面