Mapping between a MAC address and an IP address
Mapping between a MAC address and an IP address
Network allocation
New connection established
New connection established
Name resolution
Name resolution
Mapping between a MAC address and an IP address
Mapping between a MAC address and an IP address
Application version ﬁngerprint
5 CANVuS
In this section, we describe the implementation of CANVuS, a vulnerability scanning
system, based on our context-aware architecture. It was implemented in Python to con-
nect the network state database and a vulnerability scanner. In our implementation, we
146
Y. Xu et al.
used Nessus [25]. Ideally, if all host conﬁguration changes produce network artifacts,
the need for network vulnerability scanning of these events would be straightforward.
However, not all host changes have network evidence that can be captured by at least
one of the monitors. Thus, CANVuS uses both query and callback interfaces from the
network state database to leverage the context information and to maintain a history of
scanning results in its own vulnerability database.
During the initialization phase, CANVuS queries the database for all available hosts
as scanning candidates. Due to the constraints in hardware and network resources, all
hosts are not scanned concurrently. Instead, candidates are queued for pending scans,
whose size depends on the network conditions, the conﬁgured policies, and the amount
of available physical resources. A scheduling strategy is needed here to select the
next candidate to scan. For example, each candidate could be weighted based on their
triggering events and scheduled accordingly. In the current implementation, a simple
FIFO strategy is applied. At the same time, CANVuS registers a callback function with
database triggers so that a new candidate will be appended to the pending queue when a
change happens, unless the same target is already in the queue. To conduct actual scan-
ning operations, Nessus is used, yet is modiﬁed to change its target pool from a static
conﬁguration ﬁle to the queue discussed above.
Conversely, if a scanned host has no events ﬁred after N seconds since its last scan,
and there is no evidence (including both the context information and former scanning
results) indicating that it becomes unavailable, it will be added to the queue for another
scan. Thus, each host is effectively equipped with its own timer. Once it expires, CAN-
VuS will query the network state database and its vulnerability database to determine
if further scanning is necessary. Clearly, the value of the timer is a conﬁgurable policy
up to the decision of the operators. In addition, when registering callback functions,
instead of simply subscribing all possible changes in the database, CANVuS deﬁnes a
set of event-speciﬁc policies to ﬁlter the ones that are less relevant to host conﬁguration
changes.
The choices of polices involve tradeoffs and depend on the objectives of the admin-
istrators who manage this system. The purpose of our current implementation is not to
provide a reference system for production use. Instead, we aim to ﬁgure out what events
are more effective in detecting changes and what policies are more appropriate with the
given network conditions and administrative requirements. Therefore, the policies used
for our experiment were set to be as aggressive as possible so that an optimal solution
could be determined by ﬁltering unnecessary scans after the experiment was complete.
More speciﬁcally, the default policy is that every single events triggers a scan. The only
exception is the TCP event, since there are too many of them for each host, an active
timeout is enforced to prevent them from overwhelming the system. On the other hand,
if scans are being constantly triggered by inbound connections to ports that scanners fail
to discover, a negative timeout is also enforced to suppress this type of event being ﬁred
over and over again. Further details regarding the revision of our trigger implementation
and policy decisions are presented in the evaluation.
The vulnerability database is the central storage of vulnerability data for all of the
hosts in the network. It keeps track of the result for every scan conducted against each
CANVuS: Context-Aware Network Vulnerability Scanning
147
host. In addition to the raw results generated by our modiﬁed Nessus scanner, each scan
record contains following information:
– The time when this scan is triggered.
– The time when the backend scanner starts and ﬁnishes the scan.
– A list of open ports and the vulnerabilities on each port.
– A map from open ports to services.
– Operating system ﬁngerprint (optional).
– The type of triggering event.
As more results are inserted into the vulnerability database, the information can be used
in policy evaluation for further scans. Additionally, this information may be queried by
administrators at any time for risk assessment or used by other security applications.
6 Evaluation
In this section, we evaluate CANVuS in a large academic network. The basic metrics
used throughout this section is the number of scans conducted, which represents the re-
source consumption or overhead, and the latency of detecting conﬁguration changes,
which represents the system efﬁcacy. Ideally, CANVuS should outperform periodic
scanning with fewer number of scans by implicitly avoiding examining unallocated
IP addresses and unavailable hosts. Moreover, CANVuS should also achieve lower de-
tection latency as many host conﬁguration changes create network evidence that trigger
scans timely in our architecture.
We begin by discussing our experimental methodology. Then we show how CAN-
VuS outperforms existing models in terms of the number of scans required and the de-
tection latency. Next, we explore the impact of timeout values to the CANVuS system.
The following section evaluates the contribution of various data sources to CANVuS
and their correlations with observed changes on the hosts. We conclude the evaluation
by discussing the scalability requirements of the context-aware architecture.
6.1 Experimental Methodology
The target network for the experiment is a college-level academic network with one
/16 and one /17 subnet. There are two measurement points for the experiments. One is
the core router for the entire college network. Because it has the access to the trafﬁc
between the Internet and the college network, there were two monitors built on it:
– TCP connection monitor: records the creation of new TCP connections.
– Application version monitor: records the version strings in protocol headers.
The second measurement point is a departmental network within the college that has
the visibility into both the inbound/outbound trafﬁc and more ﬁne-grained inter-switch
trafﬁc. As result, the following monitors were deployed:
– ARP monitor: records the ARP messages probing for newly assigned IPs.
– DHCP monitor: records DHCP acknowledgment events.
148
Y. Xu et al.
– DNS monitor: records queries to certain software update sites.
– TCP connection monitor: as described above.
– Application version monitor: as described above.
This choice of measurement points and event monitors enables CANVuS to cover the
network stack from the link layer to the application layer. Moreover, it also allows us to
analyze the effectiveness of individual monitors with different visibility.
Based on these event monitors, CANVuS was deployed to scan the college network
using a 12-hour active/inactive timeout and 1-hour negative timeout. In addition, an-
other instance of a Nessus scanner was deployed for comparison purposes. It was con-
ﬁgured to constantly enumerate the entire college network (a.k.a. the loop scanner).
Both scanners were restricted to allow a maximum of 256 concurrent scans. The exper-
iment lasted for 16 days in March, 2010, during which time the loop scanner completed
46 iterations. And it was interrupted by a power outage for a couple of hours at the
end of the ﬁrst week. Since we expect the system to be running long term, occasional
interrupts would not have a major impact to the experiment results.
We performed a direct comparison between CANVuS and the loop scanner across
both dimensions of resource consumption and detection latency. During the current
exceptionally aggressive experiment, the loop scanner took less then 9 hours to ﬁnish
one iteration. In realistic deployments, we envision using larger values and scanning less
aggressively. Thus, the result of the loop scanner is only considered to represent the best
performance that traditional periodic scanning systems can achieve in detection latency.
More realistic values are represented below by sampling multiple 9-hour periods.
Ground truth for the experiments was established by identifying the period in which
an observable network change occurred. Speciﬁcally, the scanning records from both
scanners are ﬁrst grouped together based on the MAC (if available) or IP address of
each target host, and then each group of records are sorted by the time when each
scan started. In each sorted group, a change is deﬁned as two consecutive scan records
(scans of unavailable hosts are ignored) with different sets of open ports. In addition,
we assume that the change always happens immediately after the former scan ﬁnishes.
Subsequent discussions that require the knowledge about ground truth are all based
on this model unless otherwise noted. We approximated the ground truth in this way
because it is infeasible to gain the local access to a large number of hosts in the target
network to collect the real ground truth. As a result, we will not be able to analyze the
true positive rate of CANVuS, and the average latencies for both scanners represent the
upper bound, or the worst case.
6.2 CANVuS Evaluation
Table 2 lists the number of scans conducted by CANVuS with a break down by event
types and the total for the loop scanner. The loop scanner has an order of magnitude
more scans than CANVuS because only about 20% of the IP addresses in the target
network are known to be allocated, and at any instant of time, the number of available
hosts are even less than that. However, the loop scanner has to exhaust the entire IP
blocks unless the address allocation and host availability information can be statically
encoded, which is rarely the case in enterprise networks [10].
CANVuS: Context-Aware Network Vulnerability Scanning
149
Table 2. The numbers of scans conducted by CANVuS and the loop scanner
Total
ARP
DHCP
TCP
DNS
CANVuS Loop Scanner
534,717
1.55%
17.37%
38.33%
10.28%
App. Protocol 0.03%
32.44%
Timeout
4,355,624
N/A
)
s
(
y
c
n
e
t
a
L
110,000
100,000
90,000
80,000
70,000
60,000
50,000
40,000
30,000
20,000
10,000
0
Loop
CANVuS
0
1
2
3
5
4
6
Sampling Rate
7
8
9
10
s
n
a
c
S
f
o
#
4,500,000
4,000,000
3,500,000
3,000,000
2,500,000
2,000,000
1,500,000
1,000,000
500,000
0
Loop
CANVuS
0
1
2
3
5
4
6
Sampling Rate
7
8
9
10
Fig. 2. A comparison of the detection latency
with sampled results for the loop scanner
Fig. 3. A comparison of the number of
scans with sampled results for the loop
scanner
In addition, the average detection latencies for changes discovered by CANVuS is
22,868.751 seconds versus 26,124.391 seconds for the loop scanner. Please recall that
our assumption says the evidence of conﬁguration changes will trigger scans instan-
taneously. However, the latency for CANVuS here is far from zero. This anomaly is
caused by the fact that we used the combined scanning results to approximate the
ground truth and timeout-based scanning was still applied in some situations when no
network network changes occurred.
Moreover, the latency for CANVuS is not signiﬁcantly better than that of the loop
scanner. This is because the conﬁguration for the loop scanner is already very aggres-
sive and represents the best performance that traditional periodic scanning systems can
achieve in detection latency. To make the loop scans less aggressive and to demonstrate
the tradeoff in scanning costs, the data set is sampled with a rate from 1 to 10 to in-
clude both the original case and the case that both scanners have a comparable number
of scans. Figure 2 illustrates the result. The curve for the loop scanner goes up almost
linearly because of the linear sampling, while the curve for CANVuS goes slightly up
and down because the approximated ground truth has been changed after sampling. In
addition, Figure 3 shows the corresponding changes for the number of scans.
6.3 Timeout-Based Scanning In CANVuS
As discussed previously, a timeout-based scanning approach is used along with the
trigger-based scanning as many conﬁguration changes are not observable through
150
Y. Xu et al.
1
0.8
y
t
i
l
i
b
a
b
o
r
P
0.6
0.4
0.2
0
10000
100000
1x106
Change intervals in log scale (seconds)
Fig. 4. The CDF for the intervals of detected changes
network events. However, unlike traditional periodic scanning, which randomly picks
scanning targets in a large pool with ﬁxed cycles, the timeout mechanism in CANVuS
is still context-aware. Speciﬁcally, the system uses the context data to infer IP alloca-
tion information and host availability patterns so that only the hosts that are believed
to be connected to the network will be scanned. These timeouts are assigned per-host
timer and are based on the network state, scanning history, and administrators’ policy
decisions. As a result of these approach, fewer scans are “wasted” on hosts that don’t
exists or are unavailable. Taken another way, given the same number of scans, CANVuS
is more likely to examine a larger number of active hosts and detect host changes with
lower latency than the periodic scanning system.
Figure 4 depicts the distribution of intervals between all detected changes the val-
ues ranging between hours and days. The bias demonstrated in the middle of the graph
is the result of our experimental methodology and the choice of 12 hours for our ac-
tive/inactive timeout.
Thus, in practice, we determining the timeout value based on operators’ administra-
tive requirements. For example, using a timeout value at the order of a week, which
covers the changes on the tail of the curve in Figure 4, would be reasonable. An al-
ternative strategy is to halve the timeout value if a change is detected accordingly, but
otherwise double it adaptively modifying a host’s timeout value. In either case, there is
clearly a tradeoff between the number of scans and the detection latency, which is also
the case for normal periodic scanning.
6.4 Exploring the Impact of Various Data Sources and Triggers
In this subsection, we study the relationship between triggering events and the captured
conﬁguration changes. Speciﬁcally, the study is focused on their temporal correlations
instead of causalities, which requires detailed control over the target hosts.
To do this, two problems need to be addressed. First, since most subnets in the tar-
get network use DHCP to assign IP addresses (despite whether the address mapping
is dynamic or static), the changes witnessed may actually be mapping changes instead
CANVuS: Context-Aware Network Vulnerability Scanning
151
Table 3. Permanent changes categorization
Triggering Event Count With network evidence
ARP
DHCP
TCP
DNS
Timeout
1
15
2
3
4
1
10
2
1
0
of changes in conﬁguration. To eliminate the negative impact of dynamic address as-
signment, which would obscure the analysis results, the discussion in this subsection is
conﬁned to the 535 hosts that were assigned exactly one unique IP address during the
experiment period. They are extracted from the 1,691 scanned IP addresses in the nine
/24 departmental network subnets for which we have complete DHCP message logs.
Among these 535 hosts, 1,985 changes were detected by CANVuS during the ex-
periment. After merging with the results from the loop scanner, the number of detected
changes becomes 2,145, where the increase is an artifact of the method used to generate