### References

1. A. Farina, "Simultaneous measurement of impulse response and distortion with a swept-sine technique," in *AES Convention*, 2000.
2. Y. Ganin and V. Lempitsky, "Unsupervised domain adaptation by backpropagation," in *Proceedings of ICML*, 2015.
3. W. Jiang, C. Miao, F. Ma, S. Yao, Y. Wang, Y. Yuan, H. Xue, C. Song, X. Ma, D. Koutsonikolas et al., "Towards environment-independent device-free human activity recognition," in *Proceedings of ACM MobiCom*, 2018.
4. J. Shen, "Lingvo: A modular and scalable framework for sequence-to-sequence modeling," arXiv preprint arXiv:1902.08295, 2019.
5. D. P. Kingma and J. Ba, "Adam: A method for stochastic optimization," arXiv preprint arXiv:1412.6980, 2014.
6. K. Kinoshita, M. Delcroix, T. Yoshioka, T. Nakatani, A. Sehr, W. Kellermann, and R. Maas, "The REVERB challenge: A common evaluation framework for dereverberation and recognition of reverberant speech," in *Proceedings of IEEE WASPAA*, 2013.
7. F. Kreuk, Y. Adi, M. Cisse, and J. Keshet, "Fooling end-to-end speaker verification with adversarial examples," arXiv preprint arXiv:1801.03339, 2018.
8. A. Kurakin, I. Goodfellow, and S. Bengio, "Adversarial examples in the physical world," in *ICLR Workshop*, 2017.
9. H. Lee, T. H. Kim, J. W. Choi, and S. Choi, "Chirp signal-based aerial acoustic communication for smart devices," in *Proceedings of IEEE INFOCOM*, 2015.
10. X. Liu, K. Wan, and Y. Ding, "Adversarial attack on speech-to-text recognition models," arXiv preprint arXiv:1901.10300, 2019.
11. S. Nakamura, K. Hiyane, F. Asano, T. Nishiura, and T. Yamada, "Acoustical sound database in real environments for sound scene understanding and hands-free speech recognition," in *Proceedings of LREC*, 2000.
12. R. Nandakumar, K. K. Chintalapudi, V. Padmanabhan, and R. Venkatesan, "Dhwani: Secure peer-to-peer acoustic NFC," in *Proceedings of ACM SIGCOMM*, 2013.
13. N. Inoue, R. Furuta, "Cross-domain weakly-supervised object detection through progressive domain adaptation," arXiv preprint arXiv:1803.11365, 2018.
14. A. S. Nittala, X.-D. Yang, S. Bateman, E. Sharlin, and S. Greenberg, "PhoneEar: Interactions for mobile devices that hear high-frequency sound-encoded data," in *Proceedings of ACM SIGCHI*, 2015.
15. D. Povey, A. Ghoshal, G. Boulianne, L. Burget, O. Glembek, N. Goel, M. Hannemann, P. Motlicek, Y. Qian, P. Schwarz et al., "The Kaldi speech recognition toolkit," in *Proceedings of IEEE ASRU*, 2011.
16. Y. Qin, N. Carlini, I. Goodfellow, G. Cottrell, and C. Raffel, "Imperceptible, robust, and targeted adversarial examples for automatic speech recognition," arXiv preprint arXiv:1903.10346, 2019.
17. B. Taori, A. Kamsetty, "Targeted adversarial examples for black box audio systems," arXiv preprint arXiv:1805.07820, 2018.
18. N. Roy, H. Hassanieh, and R. R. Choudhury, "Backdoor: Making microphones hear inaudible sounds," in *Proceedings of ACM MobiSys*, 2017.
19. N. Roy, S. Shen, H. Hassanieh, and R. R. Choudhury, "Inaudible voice commands: The long-range attack and defense," in *Proceedings of USENIX NSDI*, 2018.
20. L. Schönherr, K. Kohls, S. Zeiler, T. Holz, and D. Kolossa, "Adversarial attacks against automatic speech recognition systems via psychoacoustic hiding," arXiv preprint arXiv:1808.05665, 2018.
21. S. Khare, R. Aralikatte, "Adversarial black-box attacks for automatic speech recognition systems using multi-objective genetic optimization," arXiv preprint arXiv:1811.01312, 2018.
22. Apple, "Apple Siri," <https://www.apple.com/siri/>.
23. R. Taori, A. Kamsetty, B. Chu, and N. Vemuri, "Targeted adversarial examples for black box audio systems," arXiv preprint arXiv:1805.07820, 2018.
24. T. Vaidya, Y. Zhang, M. Sherr, and C. Shields, "Cocaine noodles: Exploiting the gap between human and machine speech recognition," in *Proceedings of USENIX WOOT*, 2015.
25. K. Veselý, A. Ghoshal, L. Burget, and D. Povey, "Sequence-discriminative training of deep neural networks," in *Proceedings of Interspeech*, 2013.
26. Q. Wang, K. Ren, M. Zhou, T. Lei, D. Koutsonikolas, and L. Su, "Messages behind the sound: Real-time hidden acoustic signal capture with smartphones," in *Proceedings of ACM MobiCom*, 2016.
27. J. Y. Wen, N. D. Gaubitch, E. A. Habets, T. Myatt, and P. A. Naylor, "Evaluation of speech dereverberation algorithms using the MARDY database," in *Proceedings of IWAENC*, 2006.
28. P. Xie, J. Feng, Z. Cao, and J. Wang, "GeneWave: Fast authentication and key agreement on commodity mobile devices," in *Proceedings of IEEE ICNP*, 2017.
29. Y. Xie, Z. Li, and M. Li, "Precise power delay profiling with commodity WiFi," in *Proceedings of ACM MobiCom*, 2015.
30. H. Yakura and J. Sakuma, "Robust audio adversarial example for a physical attack," arXiv preprint arXiv:1810.11793, 2018.
31. X. Yuan, Y. Chen, Y. Zhao, Y. Long, X. Liu, K. Chen, S. Zhang, H. Huang, X. Wang, and C. A. Gunter, "CommanderSong: A systematic approach for practical adversarial voice recognition," arXiv preprint arXiv:1801.08535, 2018.
32. B. Zhang, Q. Zhan, S. Chen, M. Li, K. Ren, C. Wang, and D. Ma, "PriWhisper: Enabling keyless secure acoustic communication for smartphones," *IEEE Internet of Things Journal*, 2014.
33. G. Zhang, C. Yan, X. Ji, T. Zhang, T. Zhang, and W. Xu, "DolphinAttack: Inaudible voice commands," in *Proceedings of ACM CCS*, 2017.
34. M. Zhao, S. Yue, D. Katabi, T. S. Jaakkola, and M. T. Bianchi, "Learning sleep stages from radio signals: A conditional adversarial architecture," in *Proceedings of ICML*, 2017.
35. Y. Zou, Z. Yu, B. Vijaya Kumar, and J. Wang, "Unsupervised domain adaptation for semantic segmentation via class-balanced self-training," in *Proceedings of ECCV*, 2018.

### Appendix

#### A. Configuration of System Parameters

The final loss function of Metamorph in Equation (10) includes five parameters: α, β, γ, η, and µ. In this subsection, we introduce how these parameters are configured in this paper.

- **Parameter α**: This parameter is based on the audio adversarial example generation method proposed in [17], which aims to balance the audio sound distortion (measured in Decibels, dB) and the attack success rate (measured by the Connectionist Temporal Classification, CTC, loss). Although it is possible to train it directly, a more efficient mechanism is implemented in [2] to avoid direct parameter tuning. In our implementation, we adopt this mechanism without directly tuning α.

- **Parameters β and γ**: These two parameters are introduced in Metamorph to ensure good attack performance after over-the-air transmission of the adversarial example. 
  - **Parameter β** balances the adversarial example generation and the ability to distinguish domains by the domain discriminator. We vary β from 0.005 to 0.5 in Figure 22(a). From the results, we observe that both the transcript success rate (TSR) and character success rate (CSR) at a moderate attack distance of 3 meters can achieve better performance (e.g., > 0.95) when β is 0.05. The audio quality, measured by Mel Cepstral Distortion (MCD), remains relatively stable in this experiment. Therefore, we experimentally adopt 0.05 as the default β setting in the current Metamorph.
  - **Parameter γ** is introduced to reduce overfitting. Through the experiment in Figure 22(b), we observe that when we increase γ, e.g., to 500 or 1000, TSR approaches nearly 100%. The audio quality degrades only slightly. However, when we further increase γ, both TSR/CSR and audio quality drop rapidly. Therefore, we adopt 500 as the default γ setting in the current Metamorph.

- **Parameters η and µ**: These two parameters are introduced in Metamorph to improve the audio quality of the generated adversarial example.
  - **Parameter η** controls the utility of the audio graffiti. In Figure 22(c), we vary η from 1e-5 to 1e-3. The result shows that when η increases, the audio quality (measured by MCD) keeps improving, while CSR and TSR drop significantly when η is greater than 1e-4. Hence, we adopt 1e-4 as the default η setting in the current Metamorph.
  - **Parameter µ** is introduced to reduce the perturbation coverage. Through the experiment in Figure 22(d), we observe that increasing µ also leads to the improvement of the audio quality (MCD), while the CSR and TSR will drop concurrently. As a result, we adopt 1e-12 as the default µ setting in the current Metamorph.

These default parameters are utilized in the experimental evaluations in Section IV.

#### B. User Perceptibility Study Questions

In the first trial of the experiments conducted in the user perceptibility study of Section IV-B, volunteers will sequentially listen to each set of audios following the organization below: "[(one original audio, the adversarial example generated from this audio by Meta-Enha), 60s pause, (the same original audio, the adversarial example generated from this audio by Meta-Qual), 60s pause]". During each pause, the volunteers immediately assess the audio quality of each adversarial example compared with the original audio. Volunteers first select whether each adversarial example has the same audio quality as the original audio (Y or N), including both the noise level and the audio content. If the answer is Y, the assessment of this adversarial example in the first trial is complete; otherwise, volunteers will further select answers for three questions related to:
1. Word (content) change
2. Audio quality level
3. Noise description

The explanations for each question are provided in Table 4.

| Explanation | Y | N |
|-------------|---|---|
| **Word (Content) Change** | Word change perceived | No word (content) change perceived |
| **Quality Level** | Noise is small and audio content is clear | Noise is slightly loud, but it does not impact my hearing of the audio content |
| **Noise Description** | Noise is loud and I cannot hear the audio content occasionally | Noise is annoying and I cannot hear the audio content consistently |

#### C. Adversarial Examples Used in Evaluation

We generate two types of adversarial examples (music and speech) with different source and target transcripts, detailed in Table 5. The source musics are labeled in the table directly, and the speech adversarial examples are generated based on 11 different speech samples from the public Mozilla Common Voice Dataset [6].

| **No.** | **Source Audio Transcripts (Musics)** | **Target Commands** |
|---------|--------------------------------------|---------------------|
| 1       | "[no transcript]"–Bach, Violin       | "hello world"        |
| 2       | "chase your dreams and remember me sweet bravery"–Owl City, To The Sky | "power off"          |
| 3       | "I feel earth move under my feet I feel the sky"–Carole King, I Feel The Earth Move | "pay the money"      |
| 4       | "lyrical acrobat stunts while I’m practicing that I’ll still be able to break a motherfuckin’table over the back of a couple"–Eminem, Rap God | "turn off the light"  |
| 5       | "well the kid is into losin’ sleep and he don’t come home for half the week"–Van Halen, And the Cradle Will Rock | "airplane mode on"   |
| 6       | "[no transcription]"–Van Halen, Guitar | "browse to evil dot com" |
| 7       | "somebody mix my medicine"–The Pretty Reckless, My Medicine | "turn off the cellular network" |
| 8       | "[no transcription]"–Chopin, Piano | "update the phone blacklist" |
| 9       | "I am a mountaineer in the"–Owl City, Hello Seattle | "silence the phone"  |

| **No.** | **Source Audio Transcripts (Speeches)** | **Target Commands** |
|---------|----------------------------------------|---------------------|
| 1       | "hold your nose to keep the smell from disabling your motor functions" | "clear all appointments on calendar" |
| 2       | "your son went to server at a distant place and became a centurion" | "open the door"      |
| 3       | "the shower’s in there"                | "restart"           |
| 4       | "and you know it"                      | "open the camera"   |
| 5       | "this is no place for you"             | "flashlight on"     |
| 6       | "if I had told you you wouldn’t have seem the pyramids" | "play the scary music" |
| 7       | "I told you to have the ice box fixed" | "call nine one one" |
| 8       | "their faces were hidden behind blue veils with only their eyes showing" | "send me your messages" |
| 9       | "we are refugees from the tribal wars and we need money the other figure said" | "log in paypal"      |
| 10      | "isn’t the party also to announce his engagement to joanna" | "show fake traffic information" |
| 11      | "he stood irresolute for a moment and then scrambled out of the pit" | "shut down the power source" |

**Note:** "[no transcription]" means that there is no transcript when the classical music is played. The source musics are labeled in the table, and the source audio for speeches are from the Mozilla Common Voice Dataset.