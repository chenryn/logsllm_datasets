8
939
#Zero-day
Phishing
4
3
6
2
5
623
ing webpages with CertStream. Similar to other phishing
detectors such as URLNet and StackModel, it also assigns
suspicious score based on its predeﬁned rules. Finally, we
also consider EMD and PhishZoo in this experiment as they
are state-of-the-art phishing identiﬁcation approaches. Note,
LogoSENSE is not selected as it can support only a limited
number of brands, leading to unfair comparison.
6.4 Results
Table 9 summarizes the results on discovered phishing web-
pages. All discovered phishing webpages and their reports are
published at [7]. We observe that, compared to other baseline
approaches, Phishpedia reports far more accurate phishing re-
sults. Indeed, among all the reported 1,820 phishing webpages
by Phishpedia, the total number of real phishing webpages is
1,704. Of these identiﬁed by Phishpedia, 1,133 are new real
phishing webpages that are considered as benign by Virus-
Total. These discovered phishing webpages range over 88
brands. Figure 16 shows the top 20 brands phishing webpages.
Following the suggested practice of using VirusTotal [52], we
conducted a postmortem analysis on all discovered real phish-
ing webpages after one week, ﬁnding that 74.6% of them are
still not reported by VirusTotal.
6.4.1 Why does Phishpedia outperform the baselines?
Based on the experiment results, we also have two observa-
tions for Phishpedia’s advantage over the baseline approaches:
Observation 1: Plausible URL/domain is not a strong in-
dicator for phishing. PhishCatcher reports highest num-
3804    30th USENIX Security Symposium
USENIX Association
Figure 16: Top 20 brands from the found phishing webpages
Figure 17: A benign website with suspicious name.
ber of pages as phishing, but
it has very low accu-
racy. We note that, PhishCatcher reports high suspi-
ciousness score for domains containing plausible brand
name, such as “https://www.amazon-voucher.com/” and
“http://amazoninnpousada.com/”. Figure 17 shows an exam-
ple of the latter. Several works in literature [31, 67, 80] make
an assumption that a domain address looking similar to that
of a legitimate website is more prone to be phishing. How-
ever, our phishing discovery experiment does not support this
assumption, and we ﬁnd less correlation between name plau-
sibility and phishing suspiciousness. While such a conclusion
is counter-intuitive, it is statistically sound given that Phish-
Catcher reports very few real phishing webpages.
Observation 2: Overﬁtting or the learned bias is a fatal
drawback of machine learning approaches. We ﬁnd that
machine-learning based approaches do not perform well in
such a real discovery study, even though they tend to show
very accurate results on experimental datasets [36, 80]. Stack-
Model [80] is a tree-based model, which allows us to gen-
erate the feature importance to explain why the model con-
siders a webpage as phishing. Given a benign webpage, say,
“https://www.httpspro-aﬂd-amazon2020.cu.ma”, we ﬁnd that
the StackModel reports it as phishing because it has small
HTML length and low domain occurrence i.e., the frequency
of domain name appearances in the HTML text. We observe
that, in the OpenPhish dataset, those two features (i.e., HTML
Figure 18: A website constructed through Webmail system
(http://webmail.eventgiftshop.com/).
code length, and domain occurrence) are strong indicators for
phishing. Nevertheless, there is no causality between these
two features and the phishing intention. However, the bias
learned by the model causes a large number of false posi-
tives in the phishing discovery experiment. Overall, machine
learning models usually learn more of association than causal-
ity from the dataset, which is risky for their application on
real-world scenario.
6.4.2
Investigating False Positives
Next, we investigate the false positives reported by Phishpedia
during this discovery experiment; these are due to two reasons:
(i) template-based websites and (ii) benign websites with a
logo of some of the biggest and very popular companies such
as Google, Facebook, or LinkedIn.
Template-based websites. We ﬁnd that most false positives
are due to some websites built with templates provided by
web hosting services (e.g., https://www.cpanel.net/). After
setup, the website usually has a secondary web domain such
as “webmail.eventgiftshop.com”. However, the web admin-
istrator preserves the default logo as shown in Figure 18.
Phishpedia reports it as phishing in this experiment. Arguably,
given such a webpage design, even a human user would ﬁnd
it difﬁcult to decide whether it is a phishing page. As a quick
remedy, we could set up a white-list to suppress the warning
of Phishpedia to report webmail-based webpages. However,
such websites may be considered as having a bad UI design
from a security point of view, for provide phishers with a
chance to construct indistinguishable phishing webpages.
Benign websites with logos of big company. We also ob-
serve that Phishpedia sometimes mistakes a benign website
having a logo of a large well-known company such as Google,
Facebook, LinkedIn, etc. We refer to them as plausible web-
sites for Phishpedia. Such logos appear for the purposes of
advertisement or Single Sign-On (SSO) used for convenient
registration. Figure 19 and Figure 20 present two examples.
Given that a plausible website renders a big-company logo on
its screenshot, Phishpedia might interpret the screenshot as a
page of that big company and report it as a phishing webpage.
USENIX Association
30th USENIX Security Symposium    3805
050100150200250300350Table 10: Precision and recall of Phishpedia and baselines on
the URLs ﬁltered by PhishCatcher.
Precision
28.00%
1.00%
1.20%
1.22%
1.30%
87.50%
Solution
VirusTotal
EMD
PhishZoo
URLNet
StackModel
Phishpedia
Recall
43.75%
43.00%
43.75%
93.75%
100.0%
87.50%
Figure 19: A benign website mis-reported by Phishpedia. The
screenshot has only one logo - that of Facebook.
Phishpedia for their precision and recall. The results are given
in Table 10. Phishpedia achieves a good balance between the
precision and the recall, in comparison to other baselines.
7 Discussions
7.1 Webpage semantics
Our vision for Phishpedia is to identify the semantics of a web-
page screenshot so that we can compare its rendered intention
with its real domain. We achieve this by recognizing identity
logos and brands via Faster-RCNN and Siamese model. While
our experiments demonstrate promising results, the semantics
can sometimes go beyond logo-domain inconsistency. For
example, a benign webpage might have a Google icon as its
content, which can causes confuse Phishpedia. In our future
work, we will explore webpage layout information or extract
topic model from a webpage content to infer the identity of a
screenshot in a more conﬁdent way.
7.2 Application and deployment scenarios
Scenario 1: URL access interception. One of the most com-
mon channels for delivering URLs of phishing webpages is
email [32]. Vendors can have multiple options for deploying
e-mail security gateway. i) All URLs in an e-mail are sent to
Phishpedia; and the results are used to classify the mail as
phishing or to deliver to the user. ii) Every URL in an e-mail
is transformed and preﬁxed with a cloud-service link, so that
anytime a user clicks on the link, Phishpedia service in the
cloud analyses the URL. In this case, Phishpedia ﬁts in with
negligible additional delay.
Scenario 2: Complementing phishing detectors. Phishpe-
dia can also be used for providing explanations to existing
phishing detectors. A typical example is an analyst at a SOC
(security operations centre) going through a list of URLs that
have been classiﬁed as phishing by multiple phishing detec-
tors. Phishpedia can then be used to identify the phishing
target and provide visual explanation on webpage screenshot.
Scenario 3: Threat intelligence gathering. With its high
precision, Phishpedia can run as an independent service, to
discover new phishing pages on the Internet. This live threat
intelligence can be used to maintain dynamic black lists for
users to block access to phishing pages.
Figure 20: A benign website correctly reported by Phishpedia,
which aims to report identity logo instead of arbitrary logos.
In order to further evaluate how Phishpedia perform on
these plausible webpages, we additionally collected 131,975
URLs from CertStream, and experimented Phishpedia on the
webpages with logos of Google, Facebook, and LinkedIn.
As a result, we found 47 (0.036%) such webpages, and our
manual validation conﬁrms that four of them are real phishing
webpages. Among the 47 webpages, Phishpedia reports 7 of
them as phishing; the precision is 4
7 and the recall is 4
4.
Intuitively, Phishpedia is robust to such websites because
it recognizes identity logo instead of arbitrary logos. When
Faster-RCNN model reports multiple logos, Phishpedia uses
the logo with highest conﬁdence (see Section 3.1). Neverthe-
less, such webpages may still cause false positives. We will
address them in our future work.
6.4.3
Investigating False Negatives
We also investigate the false negatives of Phishpedia in the
phishing discovery experiment. Note that the metric recall
is hard to obtain as the ground truth can only be validated
manually, which is laborious for large-scale evaluations. In
this experiment, we sample 1,500 CertStream URLs. Our
manual evaluation found no phishing URLs. Therefore, we
further used PhishCatcher to select 1,500 CertStream URLs
and we conﬁrm 16 real phishing webpages among them.
Taking the phishing label of the above 1,500 CertStream
URLs reported by PhishCatcher as ground truth, we com-
pare VirusTotal, EMD, PhishZoo, URLNet, StackModel, and
3806    30th USENIX Security Symposium
USENIX Association
8 Threats to Validity
threat
In our experiments, an internal
is that we re-
implemented all the baseline approaches because their imple-
mentations are not publicly available. While this may result
in not obtaining the best performance of these models, we
emphasize that we experimented the baselines with multi-
ple thresholds. For example, for LogoSENSE, we evaluated
multiple versions and report the results of best performance.
We also publish all our baseline implementations in [7] for
replicating the experiments. An external threat is that, Virus-
Total engines can be adversely affected due to cloaking of
phishing websites. Therefore, it cannot be determined whether
improved detection comes from Phishpedia, or the crawling
infrastructure that Phishpedia runs on.
9 Related Works
Phishing webpage detection. Current phishing detection ap-
proaches can be classiﬁed according to their input, i.e., URL,
HTML content, and visual screenshot. URL features have
proved well on the datasets collected from some open phish-
ing platform such as PhishTank and OpenPish [36, 55, 60, 62].
Rakesh et al. [55] explored features such as URL length,
frequency of suspicious symbols and characters, etc., and
they showed that their selected features have better perfor-
mance on a variety of machine learning models. Guang et
al. [36] proposed URLNet which uses character-level and
token-level convolutional neural network for prediction. Re-
searchers also explored detecting phishing based on HTML
features [10, 17, 27, 31, 38, 50, 69, 80]. Ke et al. [31] used
frequency of keywords appearing in speciﬁc HTML tags and
that of brand names as features, and use three traditional clas-
siﬁers to make the prediction. Other works used both URL
and HTML contents to achieve a better prediction accuracy.
Cantina [27] and Li et al. [80] enhanced traditional URL and
HTML features by introducing IP addresses and top name
domain. Moreover, visual analysis (e.g., OCR technique) is
often used as a complementary technique to extract text in
images to enhance HTML features [31, 62, 63, 82]. We refer
to surveys for more details [32, 61].
Phishing target identiﬁcation. Existing identiﬁcation tech-
niques detected phishing target via search engine [44, 63, 79]
and by employing target brand list [11, 13, 21, 74]. Samuel et
al.’s Know-Your-Phish work [63] is representative for search-
engine based approach. They extracted dominant keywords
from HTML content (including text recognized by OCR) and
applied search engine (e.g., Google) to return the most likely
targets. However, repetitive network connections can incur
huge runtime overhead and it is also a challenge to select
appropriate keyword for search engine.
Fu et al. [21] ﬁrst proposed the idea of using a target brand
list. They compared the screenshot of a suspicious webpage
with that of all websites in the target brand list, subsequently
reporting the phishing target if the similarity is above a thresh-
old. As an alternative to screenshot, Medvet et al. [46] and
Rosiello et al. [59] explored techniques to compare page con-
tent such as text, images, and layout. Following their work,
Afroz et al. and Wang et al. considered logo as a more reliable
invariant to compare, and pioneered logo-based approaches
such as Phishzoo [11] and Verilogo [74], which locate logos
on the screenshot based on SIFT. As discussed above, the
performance of SIFT limits the accuracy of the approach.
10 Conclusion
In this work, we proposed Phishpedia to identify phishing
webpage with visual explanation. Phishpedia well solves the
challenging problems of logo detection and brand recognition.
Our evaluation shows that Phishpedia performs better than
state-of-the-art approaches on experiments using real datasets
as well as the ability to discover new online phishing pages. In
our future work, we will address Phishpedia’s false positive is-
sue in benign webpage with logos of big company. Moreover,
we will extend Phishpedia into an online phishing monitoring
system to collect active phishing kits, on which we will apply
state-of-the-art program analysis techniques [40–43] to gain
more insights into the phishing campaigns.
Acknowledgement
We thank the anonymous reviewers and the shepherd whose
comments helped to improve this work. This research is sup-
ported by the National Research Foundation, Prime Minister’s
Ofﬁce, Singapore under its Corporate Laboratory@University
Scheme, National University of Singapore, and Singapore
Telecommunications Ltd.
References
[1] Alexa Ranking. https://www.alexa.com/siteinfo,
October 2020.
[2] CertStream. https://certstream.calidog.io, Oc-
tober 2020.
[3] Google Transparency Report: Google Safe Brows-
https://transparencyreport.google.com/
ing.
safe-browsing/overview, 2020.