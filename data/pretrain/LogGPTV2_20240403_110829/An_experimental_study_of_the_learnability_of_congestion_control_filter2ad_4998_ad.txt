### Protocols for Simultaneously Achieving Differing Objectives on a Shared Bottleneck Link

We examine two extreme cases: a throughput-sensitive sender that prioritizes throughput over delay (δ = 0.1, Tpt. Sender), and a delay-sensitive sender that prioritizes delay over throughput (δ = 10.0, Del. Sender). 

**Figure 6: Understanding the Network Environment**
To evaluate how well endpoints need to understand their network environment, we measure the throughput of four congestion-control schemes across a simulated two-hop network path. The speed of each link is varied between 10 and 100 Mbps, with a 75 ms delay per hop. A simplified one-bottleneck model (Tao) performs only slightly worse than a protocol designed with full knowledge of the network's two-bottleneck structure. The performance gap is quantified in the figure as the difference between the two Tao protocols. For comparison, results from Cubic and Cubic-over-sfqCoDel are also shown.

These results support the intuition that a comprehensive understanding of the network's complexity may not be essential for effective congestion control.

### Knowledge about Incumbent Endpoints

We explored the implications of designing a congestion-control protocol with the knowledge that some cross-traffic may be generated by existing protocols. This is particularly relevant because new protocols are rarely deployed universally at once. In practice, cross-traffic will often come from traditional loss-triggered TCP congestion-control protocols like NewReno or Cubic. This presents a challenge for new protocols that aim to perform differently or avoid building up standing queues in the network.

Protocols such as Vegas [6] perform well when competing against similar flows but are outperformed by more aggressive traditional TCP traffic. This has led to a lack of adoption for Vegas and other delay-based protocols. Ideally, a new protocol should perform well when interacting with other instances of itself and share the network fairly with incumbent TCP endpoints. However, what are the actual consequences of incorporating "TCP-awareness" into a protocol?

**Figure 7: TCP-Awareness in Tao Protocols**
This figure shows the performance of Tao protocols designed with and without TCP-awareness, competing against themselves or against TCP. The scenario involves two endpoints contending for a 10 Mbps link with a 100 ms RTT, 250 kB buffer capacity (200 ms maximum queueing delay), and almost-continuous offered load. The fair share of throughput is 5 Mbps per endpoint. The ellipses indicate the 1-σ range of results.

**Figure 8: Isolation vs. Competition with TCP**
In isolation, a TCP-aware Tao protocol is more aggressive, leading to higher delays. However, when competing with TCP cross-traffic, the TCP-aware Tao protocol achieves lower queueing delay and higher throughput compared to the TCP-naive Tao protocol.

### Co-Optimization of Congestion-Control Algorithms

We hypothesized that it might be impossible to co-optimize congestion-control algorithms to achieve different objectives while sharing the same bottleneck link. However, our findings show that it is possible to co-optimize these algorithms such that they each pursue different objectives and still coexist effectively. When running together, the delay-sensitive sender experiences lower delay, while the throughput-sensitive sender sees higher throughput. Conversely, when each sender runs homogeneously, the delay-sensitive sender benefits from lower delay, and the throughput-sensitive sender benefits from higher throughput. However, coexistence comes at a cost to the throughput-sensitive sender, which sacrifices some throughput to accommodate the delay-sensitive sender.

**Figure 9: Cost and Benefits of Sender Diversity**
- **(a)** When senders with different preferences run independently, the throughput-sensitive sender's throughput is reduced.
- **(b)** When senders optimized for different preferences run on the same network, the delay-sensitive sender experiences higher delays, but the co-optimized senders allow the delay-sensitive sender to achieve both lower delay and higher throughput.

### Conclusion

This study provides an early step towards a rigorous understanding of the trade-offs and compromises in network protocol design. We asked: how feasible is it to "learn" a network protocol to achieve desired goals, given an imperfect model of the networks where it will be deployed? Our findings suggest that optimization tools can address these questions in the near future.

### Acknowledgments

This work benefited from discussions with many individuals, including Scott Shenker, John Wroclawski, Leslie Kaelbling, Chris Amato, Dina Katabi, Frans Kaashoek, Hariharan Rahul, Jonathan Perry, Eugene Wu, and Arun Chaganty. We thank our shepherd, Aditya Akella, and the anonymous SIGCOMM reviewers for their helpful comments. We also thank Frans Kaashoek, Nickolai Zeldovich, and Li-Shiuan Peh for the use of multicore machines at MIT, and the members of the MIT Center for Wireless Networks and Mobile Computing (Wireless@MIT) for their support. This work was partially supported by NSF grant CNS-1040072.

### References

[1] Aspera - High-speed File Transfer Technology - Asperasoft. http://asperasoft.com/technology/
[2] M. Alizadeh, A. Greenberg, D. A. Maltz, J. Padhye, P. Patel, B. Prabhakar, S. Sengupta, and M. Sridharan. Data Center TCP (DCTCP). In SIGCOMM, 2010.
[3] L. S. Brakmo, S. W. O’Malley, and L. L. Peterson. TCP Vegas: New Techniques for Congestion Detection and Avoidance. In SIGCOMM, 1994.
[4] S. Ha, I. Rhee, and L. Xu. CUBIC: A New TCP-Friendly High-Speed TCP Variant. ACM SIGOPS Operating System Review, 42(5):64–74, July 2008.
[5] V. Jacobson. Congestion Avoidance and Control. In SIGCOMM, 1988.
[6] K. Nichols and V. Jacobson. Controlled Delay Active Queue Management. Technical report, Internet-draft draft-nichols-tsvwg-codel-01, 2013.
[7] K. Winstein and H. Balakrishnan. TCP ex Machina: Computer-Generated Congestion Control. In SIGCOMM, Hong Kong, August 2013.