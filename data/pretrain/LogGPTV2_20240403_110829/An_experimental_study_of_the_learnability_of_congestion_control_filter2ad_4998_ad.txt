protocols to simultaneously achieve differing objectives when con-
tending on the same bottleneck link.
We consider two extreme cases: a throughput-sensitive sender
that weighs throughput ten times over delay (δ = 0.1, Tpt. Sender),
and a delay-sensitive sender that weighs delay ten times over
Figure 6: How well do endpoints need to understand the network
around them? To assess this, we measure the throughput of four
congestion-control schemes across a simulated two-hop network
path, as the speed of each link is swept between 10 and 100 Mbps,
with 75 ms of delay per hop. A tractable attempt at optimal (Tao)
congestion control for a simpliﬁed one-bottleneck model of the net-
work performs only a little worse than a protocol designed with
knowledge of the network’s full two-bottleneck structure.
a small, but quantiﬁable, penalty to its performance, indicated on
the ﬁgure as the gap between the two Tao protocols. Results from
Cubic and Cubic-over-sfqCoDel are shown for comparison.
These results give some rigorous support to a protocol designer’s
intuition that understanding the true network in all its complexity
may not be crucial.
4.5 Knowledge about incumbent endpoints
We investigated the consequences of designing a congestion-
control protocol with the knowledge that some cross-trafﬁc may be
the product of pre-existing incumbent protocols.
This question has considerable practical relevance; in practice,
the developer of a new network protocol will rarely be able to ar-
range a “ﬂag day” when all endpoints switch to the new protocol.4
On the broad Internet today, cross-trafﬁc will typically be the
product of traditional loss-triggered TCP congestion-control proto-
cols, such as NewReno or Cubic. This status quo presents a serious
problem for new protocols that seek to perform differently or that
try to avoid building up standing queues inside the network.
Some protocols, such as Vegas [6], perform well when contend-
ing only against other ﬂows of their own kind, but are “squeezed
out” by the more-aggressive cross-trafﬁc produced by traditional
TCP. Conventional wisdom is that any “delay-based” protocol will
meet a similar fate. This has contributed to a lack of adoption of
Vegas and other delay-based protocols.
Ideally, a newly-designed protocol would perform well (e.g. high
throughput, low delay) when interacting with other endpoints run-
ning the same protocol, and would appropriately share a network
with incumbent endpoints running traditional TCP. But what are the
actual consequences of building this “TCP-awareness” into a pro-
tocol?
4There has not been a “ﬂag day” on the Internet since the switch to
IP in 1983!
123451020306010203040506075100Throughput (Mbps)Speed of the slower link (Mbps)TCP CubicCubic-over-sfqCoDelTao (simplified one-bottleneck model)Tao (full two-bottleneck model)Omniscient protocolfaster link = slower linkfaster link = 100 Mbps486Figure 7: Tao protocols designed with and without TCP-awareness, competing against themselves or against TCP. Shown here, two endpoints
contending for a 10 Mbps link with 100 ms RTT, 250 kB of buffer capacity (200 ms maximum queueing delay), and almost-continuous
offered load. The fair share of throughput is 5 Mbps per endpoint. Ellipses show 1-σ range of results.
Figure 8: In isolation, a TCP-aware Tao protocol is more aggressive than required, leading to higher delays. But when competing with TCP
cross-trafﬁc, the Tao protocol achieves the reverse situation—lower queueing delay, and higher throughput, than the TCP-naive Tao protocol.
throughput (δ = 10.0, Del. Sender). Tables 7a and 7b list the train-
ing and testing scenarios for this experiment.
We suspected that achieving diversity in this manner may not be
possible, reasoning that endpoints that share the same bottleneck
link will necessarily experience the same queueing delay, and there-
fore endpoints that achieve an optimal throughput-to-delay tradeoff
will experience the same overall performance on both throughput
and delay.
However, contrary to this hypothesis, our ﬁndings are that it
is possible to co-optimize congestion-control algorithms such that
they each try to obtain a different objective, and yet—because of
variable duty cycles—are able to coexist. Even when running to-
gether (Figure 9b), the delay-sensitive sender sees lower delay than
the throughput-sensitive sender, while the opposite is true with
throughput. When congestion-control protocols are co-optimized,
but each sender runs homogeneously (Figure 9a), each sender re-
ceives higher throughput or lower delay, as the case they may be.
However, coexistence does come at a price to the throughput-
sensitive sender, which suffers a loss in throughput by being “nice”
to the delay-sensitive sender, both when run with the delay-sensitive
sender and when running by itself . By comparison, the perfor-
mance of the delay-sensitive sender is affected only modestly.
5. CONCLUSION
This study represents an early step towards a rigorous under-
standing of the tradeoffs and compromises of network protocol de-
sign. We asked: how easy is it to “learn” a network protocol to
achieve desired goals, given a necessarily imperfect model of the
networks where it will ultimately be deployed?
45676496128Queueing delay (ms)34567163264128Throughput (Mbps)Queueing delay (ms)Performance on homogenous networkPerformance on mixed networkBetterNewRenoTao[TCP-naive]Tao[TCP-aware]NewRenoNewRenoTao[TCP-aware]Tao[TCP-naive]Cost of TCP-awarenessBenefit of TCP-awarenessEffectofTCP-awareadversaryBetterWhen Tao protocolscompete with themselves,TCP-awareness is a hindrance...... but in a mixed network,TCP only shares fairly withthe TCP-aware Tao protocol.02468101214Time(seconds)050100150200Queuesize(packets)TCP-awareperformance02468101214Time(seconds)050100150200Queuesize(packets)TCP-naiveperformanceTCPonlyTaoonlyBothTCPandTaoPacketdropsPacketdropsLonger queuesin isolation......but shorterqueues with TCP.Shorter queuesin isolation......but longerqueues withTCP.487(a) When senders with different preferences run by themselves, training
to coexist hurts the throughput of the throughput-sensitive sender. The
delay-sensitive sender isn’t materially affected.
(b) When senders that are independently optimized for different prefer-
ences run on the same network, the delay-sensitive sender experiences
much higher delays (compared with the case where it runs by itself). In
contrast, co-optimizing the senders hurts the throughput-sensitive sender,
but allows the delay-sensitive sender to achieve both lower delay and
higher throughput.
Figure 9: The cost and beneﬁts of sender diversity.
Tao
Del.
Sender
Tpt.
Sender
RTT
Link
rates
10 Mbps 100 ms
10 Mbps 100 ms
Senders
0, 1, or 2 of
each type
0, 1, or 2 of
each type
ON/OFF
time
1 sec
ON/OFF
1 sec
ON/OFF
δ
Buffer
10.0 No
0.1
drop
No
drop
(a) Tao protocols for diverse senders: one favors throughput, the other delay
Link
rates
10 Mbps
RTT
Senders
ON/OFF time
Buffer
100 ms
1 Del. Sender
1 Tpt.Sender
1 sec ON/OFF
No
drop
(b) Testing scenarios for “price of sender diversity” experiment
Table 7: Scenarios for “price of sender diversity” experiment
We investigated several questions under this umbrella by using
Remy as a design tool to produce a tractable-attempt-at-optimal
(Tao) protocol under various prior assumptions about the network
environment. We found only weak evidence of a tradeoff between
operating range and performance, even when the operating range
covered a thousand-fold range of link speeds. We found that it may
be acceptable to simplify some characteristics of the network—
such as its topology—when modeling for design purposes. In con-
trast, features such as the degree of multiplexing and the aggres-
siveness of contending endpoints were important to capture.
Much remains to be understood about the protocol-design prob-
lem before computer-generated protocols will be practically de-
ployable across the broad Internet. For example, can we tractably
synthesize a single computer-generated protocol that outperforms
human-generated incumbents over a wide range of topologies, link
speeds, propagation delays, and degrees of multiplexing simultane-
ously? Does such a protocol still perform well on networks more
complicated than the two-hop parking lot? While our experimental
results suggest qualitatively that Remy-generated protocols do not
carry a substantial risk of catastrophic congestion collapse, can a
protocol optimizer maintain and verify this requirement mechanis-
tically, as part of the design process? Our ﬁndings from this study
suggest that optimization tools may be able to tackle these kinds of
questions in the near future.
Our formalization of the protocol-design process rests on ask-
ing the Remy tool to construct a congestion-control scheme, given
stated assumptions about the network and an objective function.
By contrast, for a human-designed protocol (e.g., existing ﬂavors
of TCP), it is usually not possible to describe exactly the implicit
underlying assumptions about the network or the intended objec-
tive. For that reason, it cannot be guaranteed that our conclu-
sions are truly applicable to the problem of protocol design gen-
erally, rather than simply to Remy and similar computer-generated
protocol-design methods.
Nonetheless, we do qualitatively observe that the performance
of human-designed protocols can depend strongly on network pa-
rameters. The single-peaked performance of Cubic-over-sfqCoDel
in Figure 4 and the declining performance in Figure 2 suggest that
this protocol rests on assumptions about the network parameters—
assumptions that may hold more or less well in practice. We there-
fore believe that our results, and our method generally, can provide
useful insights to network protocol designers about what factors are
important to model accurately and what factors may be simpliﬁed
as part of a design process.
In the future, we envision network protocols will be developed
mechanistically from ﬁrst principles: with human designers doc-
umenting the objectives and assumptions that a new protocol will
have, and automatic processes synthesizing the resulting protocol
itself. Such a methodology would allow for a more agile network
1.412.835.6611.3116.91124816326412825651210242048Throughput (Mbits/sec)Queueing delay (ms)BetterTpt. Sender[naive]Tpt. Sender[co-optimized]Del. Sender[naive]Del. Sender[co-optimized]Performance on homogenous networkEffect of playing nice1.412.835.6611.3116.91124816326412825651210242048Throughput (Mbits/sec)Queueing delay (ms)BetterEffect ofplayingniceBenefit of co-optimizationTpt. Sender[naive]Tpt. Sender[co-optimized]Del. Sender[naive]Del. Sender[co-optimized]Performance on mixed network488architecture, because changing requirements or subnetwork behav-
iors could be accommodated simply by changing the inputs to an
automatic process.
While it may have been more straightforward in the past and
present for human designers to create protocols directly, based
on intuitive design guidelines, the experience of other ﬁelds of
engineering—mechanical, electrical, civil—suggests to us that pro-
tocol design will eventually also adopt a more structured founda-
tion. We will need answers to questions like the ones in this study
to make such a transition successful.
6. ACKNOWLEDGMENTS
This work has beneﬁted immensely from discussions with many
people, including Scott Shenker, John Wroclawski, Leslie Kael-
bling, Chris Amato, Dina Katabi, Frans Kaashoek, Hariharan
Rahul, Jonathan Perry, Eugene Wu, and Arun Chaganty. Our shep-
herd, Aditya Akella, and the anonymous SIGCOMM reviewers
gave many helpful comments. We thank Frans Kaashoek, Nickolai
Zeldovich, and Li-Shiuan Peh for the use of multicore machines at
MIT, and the members of the MIT Center for Wireless Networks
and Mobile Computing (Wireless@MIT), including Amazon.com,
Cisco, Google, Intel, Mediatek, Microsoft, ST Microelectronics,
and Telefonica, for their support. This work was also supported in
part by NSF grant CNS-1040072.
REFERENCES
[1] Aspera - High-speed File Transfer Technology - Asperasoft.
http://asperasoft.com/technology/.
sfqCoDel. http://www.pollere.net/Txtdocs/sfqcodel.cc.
[2]
[3] M. Alizadeh, A. Greenberg, D. A. Maltz, J. Padhye, P. Patel,
B. Prabhakar, S. Sengupta, and M. Sridharan. Data Center
TCP (DCTCP). In SIGCOMM, 2010.
[4] D. S. Bernstein, R. Givan, N. Immerman, and S. Zilberstein.
The Complexity of Decentralized Control of Markov
Decision Processes. Mathematics of Operations Research,
27(4):819–840, Nov. 2002.
[5] B. E. Boser, I. M. Guyon, and V. N. Vapnik. A training
algorithm for optimal margin classiﬁers. In Proceedings of
the Fifth Annual Workshop on Computational Learning
Theory, COLT ’92, pages 144–152, New York, NY, USA,
1992. ACM.
[6] L. S. Brakmo, S. W. O’Malley, and L. L. Peterson. TCP
Vegas: New Techniques for Congestion Detection and
Avoidance. In SIGCOMM, 1994.
[7] D.-M. Chiu and R. Jain. Analysis of the Increase and
Decrease Algorithms for Congestion Avoidance in Computer
Networks. Computer Networks and ISDN Systems, 17:1–14,
1989.
[8] N. Dukkipati and N. McKeown. Why ﬂow-completion time
is the right metric for congestion control. SIGCOMM
Comput. Commun. Rev., 36(1):59–62, Jan. 2006.
[9] W. Feng, K. Shin, D. Kandlur, and D. Saha. The BLUE
Active Queue Management Algorithms. IEEE/ACM Trans.
on Networking, Aug. 2002.
[10] S. Floyd. TCP and Explicit Congestion Notiﬁcation. CCR,
24(5), Oct. 1994.
[11] S. Floyd and V. Jacobson. Random Early Detection
Gateways for Congestion Avoidance. IEEE/ACM Trans. on
Networking, 1(4), Aug. 1993.
[12] S. Ha, I. Rhee, and L. Xu. CUBIC: A New TCP-Friendly
High-Speed TCP Variant. ACM SIGOPS Operating System
Review, 42(5):64–74, July 2008.
[13] O. Habachi, Y. Hu, M. van der Schaar, Y. Hayel, and F. Wu.
Mos-based congestion control for conversational services in
wireless environments. Selected Areas in Communications,
IEEE Journal on, 30(7):1225–1236, August 2012.
J. C. Hoe. Improving the Start-up Behavior of a Congestion
Control Scheme for TCP. In SIGCOMM, 1996.
[14]
[15] V. Jacobson. Congestion Avoidance and Control. In
SIGCOMM, 1988.
[16] D. Katabi, M. Handley, and C. Rohrs. Congestion Control
for High Bandwidth-Delay Product Networks. In
SIGCOMM, 2002.
[17] F. P. Kelly, A. Maulloo, and D. Tan. Rate Control in
Communication Networks: Shadow Prices, Proportional
Fairness and Stability. Journal of the Operational Research
Society, 49:237–252, 1998.
[18] S. Kunniyur and R. Srikant. Analysis and Design of an
Adaptive Virtual Queue (AVQ) Algorithm for Active Queue
Management. In SIGCOMM, 2001.
[19] S. Mascolo, C. Casetti, M. Gerla, M. Sanadidi, and R. Wang.
TCP Westwood: Bandwidth Estimation for Enhanced
Transport over Wireless Links. In MobiCom, 2001.
[20] P. E. McKenney. Stochastic Fairness Queueing. In
[22] K. Nichols and V. Jacobson. Controlled Delay Active Queue
Management. Technical report, Internet-draft
draft-nichols-tsvwg-codel-01, 2013.
[23] R. Pan, B. Prabhakar, and K. Psounis. CHOKe—A Stateless
Active Queue Management Scheme for Approximating Fair
Bandwidth Allocation. In INFOCOM, 2000.
[24] K. K. Ramakrishnan and R. Jain. A Binary Feedback
Scheme for Congestion Avoidance in Computer Networks.
ACM Trans. on Comp. Sys., 8(2):158–181, May 1990.
[25] R. E. Schapire. The strength of weak learnability. Machine
learning, 5(2):197–227, 1990.
[26] R. Srikant. The Mathematics of Internet Congestion Control.
Birkhauser, 2004.
[27] K. Tan, J. Song, Q. Zhang, and M. Sridharan. A Compound
TCP Approach for High-speed and Long Distance Networks.
In INFOCOM, 2006.
[28] L. G. Valiant. A Theory of the Learnable. CACM,
27(11):1134–1142, Nov. 1984.
[29] K. Winstein and H. Balakrishnan. TCP ex Machina:
Computer-Generated Congestion Control. In SIGCOMM,
Hong Kong„ August 2013.
J. Wroclawski. TCP ex Machina. http://www.postel.org/
pipermail/end2end-interest/2013-July/008914.html, 2013.
[30]
[31] Y. Yi and M. Chiang. Stochastic Network Utility
Maximisation. European Transactions on
Telecommunications, 19(4):421–442, 2008.
[21] K. Nichols and V. Jacobson. Controlling Queue Delay. ACM
INFOCOM, 1990.
Queue, 10(5), May 2012.
489