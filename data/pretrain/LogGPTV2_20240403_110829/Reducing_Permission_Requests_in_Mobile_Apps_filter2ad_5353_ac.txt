### Permission Removal Analysis

To evaluate the impact of our warnings on permission removal, we compared the statistics of permission removals in three groups: warned apps, and two control groups. 

- **Warned Apps**: 19,000 apps that received our warnings.
- **Control Group-A**: Over one million apps for which our metrics did not detect any unnecessary permissions, and thus did not receive any warnings.
- **Control Group-B**: 12,000 apps where our metrics detected unnecessary permission requests, but the developers did not receive the Pre-Launch Report.

All three groups have similar proportions of popular and less popular apps. Control Group-A is a large group with more than one million apps, and these apps could be removing permissions for any of the five reasons outlined in Section 1. Any changes in APIs or libraries would require all updating apps to incorporate these changes. Since Control Group-A does not remove permissions due to anomalous permissions (as per our definition), it serves as a proxy for permission removal activity occurring for other reasons. We observed that 9% of the apps in Control Group-A removed permissions, suggesting that 9% of the warned apps might also remove permissions for reasons unrelated to our warning.

Control Group-B, with 12,000 apps, exhibits the same anomalous permission behavior as the warned apps but did not receive a warning. In this group, 45% of the apps removed permissions. This higher percentage (compared to 9% in Control Group-A) suggests that developers in this group may be more sensitive to negative press or are aware of the broader issues surrounding potentially unnecessary permission requests. Our warning appears to boost the permission removal activity by an additional 31% beyond what these developers do on their own.

On average, Control Group-A removed 0.3 permissions per app, Control Group-B removed 1.7 permissions per app, and our warned apps removed 2.7 permissions per app. This indicates that even compared to other apps with similar anomalous permission behavior, our warning increases the number of permissions removed per app by 60%.

### Time and Versions Taken to Remove Permissions

For the 5,725 permissions that were warned and later removed, we analyzed the time taken by developers to remove the permissions. The time was calculated from the earliest version of the app flagged by our privacy warning to the first version released without the warned permission. We found that about 5% of the removals happened within a day of the warning, and 50% occurred within a three-month period. Given that permission removals require an app version update, and each developer has their own development cycle, the response time varied significantly. Additionally, 25% of the removals occurred in the immediate next version release, and 70% took fewer than ten version releases.

### Statistical Significance

Figure 6 shows the percentage of apps that removed specific permissions across the three groups. A Kruskal-Wallis test conducted on the number of apps that removed each of the 60 platform permissions across the three groups indicates that the differences are statistically significant (H = 51.2, p < .01). Furthermore, Mann-Whitney U tests show that the pairwise differences between the warned apps and the two control groups (A and B) are also significant (U = 854, p < .01 for warned apps vs. Control Group-A, and U = 1212, p < .01 for warned apps vs. Control Group-B, after applying the Bonferroni correction). This evidence indicates that our privacy warning is effective in encouraging developers to remove more permissions than they would without the warning, and this influence extends beyond the specific permissions warned about, thereby boosting overall redaction activity both directly and indirectly.

### Limitations

Although our warnings affect billions of app installs, we acknowledge that our feedback signal only reaches a small portion of the overall Google Play ecosystem. This is because our conservative threshold discourages the presentation of warnings unless we are strongly confident about them. This approach also indirectly limits false positives, and the high developer response rate suggests that the signal is of good fidelity. If we showed warnings too frequently or with many false positives, developers might become desensitized and ignore them.

### Conclusions and Future Work

Our study shows that even with a conservative approach (3% threshold) to surfacing privacy nudges, our deep learning approach can significantly influence apps towards more privacy-friendly behavior. Overall, 59% of warned apps adhered to our warnings by removing permission requests. This occurred broadly across Google Play, as evidenced by removals from all app categories, across all popularity levels, and for many permission types. Our nudges encourage additional permission removals beyond the ones we warn about, resulting in a 60% increase in the number of permissions removed per app compared to a control group that captures normal background permission removal activity due to other reasons.

Since developers are responsive to nudges, future work could explore the design of other nudges in developer tools such as Android Studio, Gradle, and more. It may also be worthwhile to nudge SDK and library developers, as prior work has shown that a small number of libraries (âˆ¼30) are used by the vast majority of apps. Controlled experimentation and surveys could help further clarify the effectiveness of such nudges, especially in terms of their supplemental effects.

### Acknowledgements

The development and deployment of the privacy warning involved many people. We would like to thank Qiang Yan, Fergus Hurley, Bruno Buss, Olivier Gaillard, Marcin Oczeretko, and Richard Gaywood.

### References

[References listed as provided, with proper formatting and citation style.]

---

This optimized version aims to make the text more clear, coherent, and professional. It reorganizes the information for better flow and readability, and ensures that the statistical and technical details are presented clearly.