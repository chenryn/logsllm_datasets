permissions due to our warning or due to other reasons, we com-
pared the permission removal statistics of our warned apps to that
of apps in two control groups.
• Warned Apps: The 19K apps that received our warnings.
• Control Group-A: Apps for which our metrics did not de-
tect any unnecessary permissions, and therefore did not
receive any warnings.
• Control Group-B: Apps for which our metrics detected un-
necessary permission requests, but which were not notified
since their developers do not receive the Pre-Launch Report
.
All 3 groups have similar proportions of (un)popular apps. Con-
trol group-A has more than a million apps. This group could be
removing permissions for any of the 5 reasons we outlined in Sec-
tion. 1. Note that any changes in APIs, or in a library, would require
all updating apps to incorporate these changes. Since group-A is
removing permissions not due to anomalous permissions (as per
our definition), we view them as a proxy for permission removal
activity that occurs for other reasons. We observed that 9% of apps
in Control Group-A remove permissions. This hints that possibly 9%
of the apps in our warned app set remove permissions for reasons
not related to our warning.
Control group-B only contains 12K apps, that exhibit the same
anomalous permissions behavior as our warned apps, however they
do not receive a warning. In this group, 45% of the apps removed
permissions. Since this is larger than 9%, it could be that developers
in this group are more sensitive to negative press, or may be aware
of the broad issue surrounding potentially unnecessary permission
requests. While we cannot confirm that, we note that nevertheless,
our warning boosts the permission removal activity an additional
31% beyond what these developers do on their own.
We also point out that Group-A removed on average 0.3 permis-
sions/app, Group-B removed 1.7 permissions/app and our warned
apps removed 2.7 permissions per app. So even compared to other
apps with similar anomalous permission behavior, our warning
appears to increase the number of permissions removed per app by
60%.
Figure 6 shows the percentage of apps that removed permissions
across the three app groups, for 20 permissions. These percentages
for each group are calculated based on the number of apps that
Figure 5: Versions taken to remove permissions
Time/Versions Taken to Respond. For the 5725 permissions
that were warned and later removed, we analyzed the time taken
by the developer to remove the permissions. For computing these
metrics, we consider the earliest version of the app that was flagged
by our privacy warning and the first version released later without
the warned permission. We found that about 5% of the removals
happened within a day of surfacing the warning, and 50% occurred
within a 3 month period. Since permission removals require an
app version update, and developers each have their own app de-
velopment cycle, it is natural that the time to respond would vary
significantly. We also looked at the number of app versions taken
to remove the warned permission, and Figure 5 shows the CDF
plot. 25% of removals happen in the immediate version release, and
70% take less than 10 version releases. Many developers have more
than one app version lined up for release next, and the permis-
sion removal change may be included in any one of these release
versions.
264
025507510012345678910111213141516171819202122232425+Versions Taken to Remove Warned Permissions% of RemovalsReducing Permission Requests in Mobile Apps
IMC ’19, October 21–23, 2019, Amsterdam, Netherlands
Figure 6: Percentage of apps that removed permissions (warned apps and control groups; 20 permissions shown)
request the permission in that group. As is clearly seen, many more
apps in the warned group removed each permission type compared
to apps in either of the control groups. A Kruskal-Wallis test con-
ducted on the number of apps that have removed each of the 60
platform permissions across the three groups indicates that the
differences are statistically significant (H = 51.2, p < .01).2 Further-
more, the Mann-Whitney U tests show that the pairwise differences
between the warned apps and the two other control groups (A and
B) are also significant (U = 854, p < .01 for the warned apps vs.
control group A, and U = 1212, p < .01 for the warned apps vs.
control group B, after applying the Bonferroni correction). This
evidence indicates that our privacy warning is effective in nudging
developers towards removing more permissions than they would
without the warning, and this influence extends beyond the specific
permissions warned about, thereby boosting the overall redaction
activity both directly and indirectly.
5 LIMITATIONS
Although changes due to our warning affect billions of app installs,
we acknowledge that our feedback signal only reaches a small por-
tion of the overall Google Play ecosystem in terms of the number
of apps affected. This is because our conservative threshold dis-
courages the presentation of warnings that we are not strongly
confident about. This behavior also indirectly limits false positives;
indeed, we view the high developer response as indicative that the
signal is of good fidelity. If we showed warnings too frequently, or
with many false positives, developers may become desensitized and
ignore them.
As mentioned in Section 2.1, when the majority of apps in the
peer set do request the same permission as a specific developer,
we interpret this as an indication that the permission is genuinely
needed by this type of app. If it should arise that more than 97% of
the apps in a peer set are simultaneously requesting an unnecessary
permission, then our approach does not flag these. Instead dynamic
analysis is more promising for such cases.
6 CONCLUSIONS AND FUTURE WORK
We showed that even with a conservative approach (3% threshold)
to surfacing privacy nudges, our deep learning approach is able to
2The null hypothesis is that the number of apps that remove each of the 60 platform
permissions across the three groups come from the same distribution.
265
influence a significant number of apps towards the more privacy-
friendly behavior of refraining from requesting unnecessary per-
missions. Overall, 59% of warned apps adhered to our warnings
by removing permission requests. Moreover, this occurred not just
for a niche group of developers or apps, but rather broadly across
Google Play—as evidenced by removals from all app categories,
across all popularity levels and many permission types. Our nudges
encourage additional permission removals beyond the ones we
warn about, for example, we observe a boost of 60% in the number
of permissions removed per app, as compared to a control group
that captures normal background permission removal activity due
to other reasons.
Since developers are responsive to nudges, we believe it is promis-
ing to explore the design of other nudges in future work. Warnings
could be surfaced in other developer tools such as Android Studio,
Gradle, and more. It may be worthwhile to explore nudging SDK and
library developers, as prior work has shown that a small number
of libraries (∼30) are used by the vast majority of apps [8]. Find-
ing ways to incentivize this group of developers is a challenge but
would have significant impact. To better understand why interven-
tions such ours have the intended effect, controlled experimentation
could be used to compare multiple variations of the warnings. Sur-
veying developers as to why and when they remove permissions,
and to understand their response to our warnings, could help to
further clarify the effectiveness of nudges such as ours - especially
in terms of their supplemental effects.
7 ACKNOWLEDGEMENTS
Development and deployment of the privacy warning involved
many people. We would like to thank Qiang Yan, Fergus Hurley,
Bruno Buss, Olivier Gaillard, Marcin Oczeretko, and Richard Gay-
wood.
REFERENCES
[1] 2019. Android Studio Project Site: Android Lint Checks. http://tools.android.
com/tips/lint-checks. (2019).
[2] Y. Agarwal and M. Hall. 2013. ProtectMyPrivacy: detecting and mitigating privacy
leaks on iOS devices using crowdsourcing. In Proceedings of MobiSys.
[3] Hazim Almuhimedi, Florian Schaub, Norman Sadeh, Idris Adjerid, Alessandro
Acquisti, Joshua Gluck, Lorrie Faith Cranor, and Yuvraj Agarwal. 2015. Your
Location Has Been Shared 5,398 Times!: A Field Study on Mobile App Privacy
Nudging. In Proceedings of CHI. ACM.
1020304050READ_PROFILEMANAGE_ACCOUNTSREAD_CALENDARWRITE_CALENDARREAD_LOGSWRITE_CONTACTSMOUNT_UNMOUNT_FILESYSTEMSREAD_CONTACTSACCESS_LOCATION_EXTRA_COMMANDSRECORD_VIDEORECORD_AUDIOGET_TASKSCALL_PHONEACCESS_GPSCAMERAPROCESS_OUTGOING_CALLSGET_ACCOUNTSMODIFY_PHONE_STATEACCESS_FINE_LOCATIONACCESS_COARSE_LOCATIONAndroid Platform Permissions (android.permission.*)Percentage of AppsLegendControl Group-AControl Group-BWarned AppsIMC ’19, October 21–23, 2019, Amsterdam, Netherlands
S. Peddinti et al.
[4] Android Developers 2019. App permissions best practices. https://developer.
android.com/training/articles/user-data-permissions.html?hl=en. (2019).
[5] Android Developers [2019]. Google Play Console. https://developer.android.com/
[6] AppCensus 2019. AppCensus: Learn the privacy cost of free apps. https://www.
distribute/console/. ([2019]).
appcensus.mobi/. (2019).
[7] Rebecca Balebako, Abigail Marsh, Jialiu Lin, Jason I Hong, and Lorrie Faith
Cranor. 2014. The privacy and security behaviors of smartphone app developers.
Workshop on Usable Security (USEC) (2014).
[8] Saksham Chitkara, Nishad Gothoskar, Suhas Harish, Jason I. Hong, and Yuvraj
Agarwal. 2017. Does This App Really Need My Location?: Context-Aware Privacy
Management for Smartphones. Proc. ACM Interact. Mob. Wearable Ubiquitous
Technol. 1, 3 (Sept. 2017).
[9] Developer Economics 2019. Slash Data: Developer Economics 2018 Survey.
https://graph.developereconomics.com/?survey=de15. (2019).
[10] Federal
Commission
Trade
Developer
App
sumers.
android-flashlight-app-developer-settles-ftc-charges-it-deceived. (2013).
Flashlight
Con-
https://www.ftc.gov/news-events/press-releases/2013/12/
Android
It
Deceived
Charges
Settles
2013.
FTC
[11] Adrienne Porter Felt, Erika Chin, Steve Hanna, Dawn Song, and David Wagner.
2011. Android Permissions Demystified. In Proceedings of the 18th ACM Conference
on Computer and Communications Security (CCS). ACM, 12.
[12] Tom Fox-Brewster. 2014. Check the permissions: Android flashlight apps crit-
icised over privacy. https://www.theguardian.com/technology/2014/oct/03/
android-flashlight-apps-permissions-privacy. The Guardian (Oct. 2014).
[13] Ian Goodfellow, Yoshua Bengio, and Aaron Courville. 2016. Deep Learning. MIT
Press. http://www.deeplearningbook.org.
[14] Alessandra Gorla, Ilaria Tavecchia, Florian Gross, and Andreas Zeller. 2014.
Checking App Behavior Against App Descriptions. In Proceedings of the 36th
International Conference on Software Engineering (ICSE). ACM, 11.
[15] Marian Harbach, Markus Hettig, Susanne Weber, and Matthew Smith. 2014.
Using Personal Examples to Improve Risk Communication for Security & Privacy
Decisions. In Proceedings of the 32Nd Annual ACM Conference on Human Factors
in Computing Systems (CHI). ACM, 10.
[16] Suman Jana, Úlfar Erlingsson, and Iulia Ion. 2015. Apples and Oranges: Detecting
Least-Privilege Group Analysis. CoRR abs/1510.07308 (2015). arXiv:1510.07308
http://arxiv.org/abs/1510.07308
[17] Jialiu Lin, Shahriyar Amini, Jason I. Hong, Norman Sadeh, Janne Lindqvist, and
Joy Zhang. 2012. Expectation and Purpose: Understanding Users’ Mental Models
of Mobile App Privacy Through Crowdsourcing. In Proceedings of the 2012 ACM
Conference on Ubiquitous Computing (UbiComp). ACM, 10.
[18] Bin Liu, Mads Schaarup Andersen, Florian Schaub, Hazim Almuhimedi,
Shikun (Aerin) Zhang, Norman Sadeh, Yuvraj Agarwal, and Alessandro Acquisti.
2016. Follow My Recommendations: A Personalized Privacy Assistant for Mobile
App Permissions. In Twelfth Symposium on Usable Privacy and Security (SOUPS).
USENIX Association.
[19] Abraham H. Mhaidli, Yixin Zou, and Florian Schaub. 2019. "We Can’t Live Without
Them!" App Developers’ Adoption of Ad Networks and Their Considerations of
Consumer Risks. In Fifteenth Symposium on Usable Privacy and Security (SOUPS
2019). USENIX Association.
[20] Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013. Efficient
Estimation of Word Representations in Vector Space. CoRR abs/1301.3781 (2013).
arXiv:1301.3781 http://arxiv.org/abs/1301.3781
[21] Elleen Pan, Jingjing Ren, Martina Lindorfer, Christo Wilson, and David R.
Choffnes. 2018. Panoptispy: Characterizing Audio and Video Exfiltration from
Android Applications. Proceedings of Privacy Enhancing Technologies Symposium
(PETS) (2018).
[22] Martin Pelikan, Giles Hogben, and Úlfar Erlingsson. 2017. Identifying Intrusive
Mobile Apps Using Peer Group Analysis. https://security.googleblog.com/2017/
07/identifying-intrusive-mobile-apps-using.html. (2017).
[23] PrivacyGrade 2019. PrivacyGrade: Grading The Privacy Of Smartphone Apps.
http://privacygrade.org/. (2019).
[24] Zhengyang Qu, Vaibhav Rastogi, Xinyi Zhang, Yan Chen, Tiantian Zhu, and
Zhong Chen. 2014. AutoCog: Measuring the Description-to-permission Fidelity
in Android Applications. Proceedings of the ACM Conference on Computer and
Communications Security (CCS) (November 2014).
[25] A. Razaghpanah, R. Nithyanand, N. Vallina-Rodriguez, S. Sundaresan, M. Allman,
C. Kreibich, and P. Gill. 2018. Apps, Trackers, Privacy and Regulators: A Mobile
Study of the Global Tracking Ecosystem. In Proceedings of NDSS.
[26] ReCon 2019. ReCon: Bug Fixes, Improvements, ..., and Privacy Leaks: A Longi-
tudinal Study of PII Leaks Across Android App Versions. https://recon.meddle.
mobi/appversions/index.html. (2019).
[27] Jingjing Ren, Martina Lindorfer, Daniel J Dubois, Ashwin Rao, David Choffnes,
and Narseo Vallina-Rodriguez. 2018. Bug Fixes, Improvements, and Privacy Leaks.
A Longitudinal Study of PII Leaks acorss Android App Versions. In NDSS.
[28] F. Shih, I. Liccard, and D. Weitzner. 2015. Privacy tipping points in smartphones
privacy preferences. In ACM CHI.
[29] Anastasia Shuba, Evita bakopoulou, and Athina Markopoulou. 2018. Privacy
Leak Classification on Mobile Devies. In Workshop on Signal Processing Advances
in Wireless Communication (SPAWC). IEEE.
[30] Ben Smith. 2018. Project Strobe: Protecting your data, improving our third-party
APIs, and sunsetting consumer Google+. https://www.blog.google/technology/
safety-security/project-strobe/. (2018).
[31] Welderufael B. Tesfay, Peter Hofmann, Toru Nakamura, Shinsaku Kiyomoto,
and Jetzabel Serna. 2018. PrivacyGuide: Towards an Implementation of the EU
GDPR on Internet Privacy Policy Evaluation. In Proceedings of the Fourth ACM
International Workshop on Security and Privacy Analytics (IWSPA ’18). ACM, New
York, NY, USA, 15–21.
[32] Richard H. Thaler and Cass R. Sunstein. 2008. Nudge - Improving Decisions About
Health, Wealth, and Happiness.
[33] New York Times. 2016.
Keep Tabs on Android App Permis-
https://www.nytimes.com/2016/10/06/technology/personaltech/
sions.
keep-tabs-on-android-app-permissions.html. (October 2016).
[34] Lynn Tsai, Primal Wijesekera, Joel Reardon, Irwin Reyes, Serge Egelman, David
Wagner, Nathan Good, and Jung-Wei Chen. 2017. Turtle Guard: Helping Android
Users Apply Contextual Privacy Preferences. In Symposium on Usable Privacy
and Security (SOUPS).
[35] Timothy Vidas, Nicolas Christin, and Lorrie Cranor. 2011. Curbing android
permission creep. In Proceedings of the Web, Vol. 2. 91–96.
[36] Shomir Wilson, Florian Schaub, Aswarth Abhilash Dara, Frederick Liu, Sushain
Cherivirala, Pedro Giovanni Leon, Mads Schaarup Andersen, Sebastian Zimmeck,
Kanthashree Mysore Sathyendra, N. Cameron Russell, Thomas B. Norton, Eduard
Hovy, Joel Reidenberg, and Norman Sadeh. 2016. The Creation and Analysis of a
Website Privacy Policy Corpus. In Proceedings of the 54th Annual Meeting of the
Association for Computational Linguistics (Volume 1: Long Papers). Association
for Computational Linguistics, 1330–1340.
[37] Wired. 2018. App permissions don’t tell us nearly enough about our apps.
https:https://www.wired.com/story/app-permissions. (April 2018).
266