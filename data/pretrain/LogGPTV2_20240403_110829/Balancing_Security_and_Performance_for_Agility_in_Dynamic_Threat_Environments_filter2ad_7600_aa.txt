title:Balancing Security and Performance for Agility in Dynamic Threat Environments
author:Michael L. Winterrose and
Kevin M. Carter and
Neal Wagner and
William W. Streilein
2016 46th Annual IEEE/IFIP International Conference on Dependable Systems and Networks
Balancing Security and Performance for Agility in
Dynamic Threat Environments
Michael L. Winterrose
MIT Lincoln Laboratory
244 Wood St
Lexington, MA 02420
PI:EMAIL
Kevin M. Carter
Neal Wagner
MIT Lincoln Laboratory
MIT Lincoln Laboratory
244 Wood St
Lexington, MA 02420
PI:EMAIL
244 Wood St
Lexington, MA 02420
PI:EMAIL
William W. Streilein
MIT Lincoln Laboratory
244 Wood St
Lexington, MA 02420
PI:EMAIL
Abstract—In cyber security, achieving the desired balance
between system security and system performance in dynamic
threat environments is a long-standing open challenge for cyber
defenders. Typically an increase in system security comes at the
price of decreased system performance, and vice versa, easily
resulting in systems that are misaligned to operator speciﬁed
requirements for system security and performance as the threat
environment evolves. We develop an online, reinforcement learn-
ing based methodology to automatically discover and maintain
desired operating postures in security-performance space even
as the threat environment changes. We demonstrate the utility of
our approach and discover parameters enabling an agile response
to a dynamic adversary in a simulated security game involving
prototype cyber moving target defenses. 1
I.
INTRODUCTION
Network operators desire the ability to deploy new defen-
sive technologies without impacting system performance. In
reality, technological defensive mitigations typically have neg-
ative impacts on system performance. Achieving the desired
balance between system security and system performance in
dynamic threat environments is a long-standing open challenge
for cyber security practitioners. The task of ﬁnding the optimal
balance is a difﬁcult one for network defenders, and involves
subtasks such as making correct inferences from past histor-
ical experience, balancing complex requirements and criteria
against each other, and accounting for a threat environment that
changes moment to moment and reacts adaptively to defensive
strategies and tactics. These tasks are beyond the scope of
possibility for the majority of cyber defenders. Cascading
consequences and path dependence in the decision space
mean human operators cannot process enough of the relevant
information on their own to come to optimal decisions and so
most security decisions are made on a ad hoc basis, without
the help of a coherent risk framework or rigorous decision
criteria.
Automated decision making is needed both to place the
security-related decisions of network defenders on a more
rigorous and quantitative foundation and to keep pace with
rapidly evolving adversaries. At a high level, it is typically
the case that an increase in system security comes at the price
of decreased system performance, and vice versa. This has
1This work is sponsored by the Department of Defense under Air Force
Contract FA8721-05-C-0002. Opinions, interpretations, conclusions and rec-
ommendations are those of the author and are not necessarily endorsed by the
United States Government.
the consequence that systems can easily become misaligned
to the desired levels of security and performance as the threat
environment evolves.
In recent years the need for frameworks and techniques
to assist operators in balancing security gains against perfor-
mance costs in information security has been recognized and
researchers have begun addressing the challenge. A framework
for adaptively balancing these tradeoffs for combinations of
security services in wireless ad hoc and sensor networks was
proposed in [1]. In [2] a framework for balancing security via
encryption and network throughput in a wireless network envi-
ronment is proposed and demonstrated both with and without
modeled adversaries. A technique for achieving balance be-
tween security and performance in networked control systems
based on a coevolutionary genetic algorithm technique has
been developed in [3], [4]. The security-versus-performance
challenge was addressed for robotic mobile wireless ad hoc
networks in [5] using novel combinations of Petri nets and
queueing networks. We propose a strictly online, light-weight,
and conceptually simple adaptive control framework to auto-
matically balance security gains against performance losses
and demonstrate the proposed technique in the context of a
strategic game of timing.
Despite the speciﬁc, simpliﬁed nature of the scenario
studied in this work, our formulated strategic game captures
several important aspects of the real world challenges cyber
defenders face in optimizing system operations in the face
of security challenges. Our game of timing reﬂects the es-
sential logic of a large class of security scenarios in which
security must be traded against system performance. We map
our abstract game to a real-world prototype Moving Target
technology [6], [7] that requires an explicit decision be made
regarding the degree to which system security or performance
will take precedence in system operations. The essential logic
of our chosen scenario can easily map to a broad range of
scenarios such as virtual machine refresh, policies for the
refreshing of passwords, key rotation in cryptography, and the
FLIPIT scenario [8], among others. Our management system
implements an online, model-free technique to automatically
discover optimal or near-optimal system operating points that
balance security and performance. The major contributions of
this work are as follows:
1) We develop an online, reinforcement learning based
methodology to automatically discover and maintain
978-1-4673-8891-7/16 $31.00 © 2016 IEEE
DOI 10.1109/DSN.2016.61
607
desired operating postures in security-performance
space.
2) We discover model parameters enabling agile re-
sponses to dynamic adversaries.
3) We provide a foundation on which future imple-
mentations of online adaptive control architectures in
cyber security can build.
In the next section we develop our framework for rea-
soning about security decisions in the light of performance
considerations and develop a strategic game scenario capturing
challenges real world network defenders face in solving the se-
curity versus performance dilemma. In Section III we describe
our attacker model and the metrics used to evaluate security
and performance. In Section IV we provide the implementation
details of our reinforcement learning solution methodology.
In Section V we provide a uniﬁed overview of the system
architecture implementing our reinforcement learning solution,
followed by a discussion of experimental setup and model
parameterization in Section VI. A series of simulation results
are also presented and discussed, followed by concluding
remarks in Section VII.
II. STRATEGIC GAME SCENARIO AND TERM DEFINITION
We are interested in developing an automated technique to
balance security and system performance in systems where the
defender must actively elect to take a security enhancing action
at the cost of immediate degradation of system performance.
We develop notation here to capture this situation formally in
a manner that can later be implemented in a computational
engine for optimization and exploration. We deﬁne a beneﬁt
term B that captures the advantage a defender gains through
achieving increased system security as a consequence of the
security-enhancing action they have elected to undertake. We
let a latency term L capture the performance costs that
are incurred by the defended system as a consequence of
the security-enhancing action. The beneﬁt and latency terms
are combined algebraically into an overall reward term R,
expressed as,
R = B − L.
(1)
The objective of the defender is to discover a policy that
will optimize the reward term R, which can be achieved by
maximizing the beneﬁt gained B while minimizing the latency
cost L.
A. Game Scenario
The strategic scenario we study is inspired by a known
attack scenario involving a computer’s memory space. Address
Space Layout Randomization (ASLR) [9] is a cyber moving
target
technique that has been adopted widely in modern
operating systems [6]. In this technique a program is placed
randomly in memory such that an attacker cannot predict the
location of key components of a program’s data. This protects
an application from attacks that rely on detailed knowledge by
the attacker of an applications memory space, such as buffer
overﬂow and return oriented programming (ROP) attacks [6].
A class of attacks have recently received attention that
exploit memory disclosures from a host system to overcome
608
its ASLR defense. A memory disclosure occurs when a valid,
active memory address is leaked from a system. Memory
disclosures allow an attacker to re-map a program’s memory
space and thus circumvent ASLR obfuscation. Once ASLR has
been circumvented and a system compromised, the defender
likely must engage in costly mitigation and restoration steps
to return the system to a secure state.
Preventing all potentially damaging memory disclosures
can be a daunting task. An alternative is to develop techniques
to mitigate memory disclosures before they can be exploited
by an attacker. This was recently demonstrated in [7], where
the authors dynamically re-randomized system memory lay-
out each time a system input followed system outputs. This
scheme makes the strong assumption that all system outputs
are potential memory disclosures on which an adversary may
capitalize.
In reality,
the vast majority of system outputs do not
contain memory disclosures. Consequently there is an oppor-
tunity to improve performance by scanning system outputs
for the presence of active, valid memory addresses. If a
valid address is discovered in a system output, the mitigating
step of re-randomizing the memory layout would then be
taken. However, the act of searching and subsequent mitigating
actions incurs a latency cost, which must be balanced against
performance needs.
B. Latency Costs
We now derive the general conditions under which a
strategy of searching system outputs for memory disclosures
is sound policy for the defender. The simplest defender policy
consists of taking mitigating steps each time there has been
the possibility of a memory disclosure to the attacker, i.e.,
each time there has been a write() system call and a system
output has been generated [7]. In many instances executing a
policy of taking mitigation steps each time a system output is
generated will incur a latency cost that exceeds the maximally
allowed system latency, Ltot. In these instances the following
inequality holds,
O(cid:2)
i=1
Li,m > Ltot,
(2)
with O the total number of system outputs during the period
of interest, and Li,m the latency cost for mitigating memory
disclosure i.
We seek to use a system output searching procedure with an
associated latency cost (Li,s) that is on average much less than
the average latency cost of mitigating the memory disclosures,
(cid:2)Li,s(cid:3)i (cid:4) (cid:2)Li,m(cid:3)i ,
(3)
where (cid:2)(cid:3)i is the average over i. If Eqt. 3 does not hold, then
it would be preferable for the defender to simply mitigate
the consequences of system compromise and dispense with
searching system outputs.
We further note that, even given that Eqt. 3 holds, it can
easily be the case that searching every system output for
memory disclosures, and taking steps to mitigate the threat
to the defended system that result from memory disclosures,
incurs a latency cost that, while being less than the latency
cost inherent in taking mitigation steps each time there is the
possibility for memory disclosure, still exceeds the maximally
desired system latency Ltot,
O(cid:2)
i=1
Li,m >
O(cid:2)
j=1
(Lj,s + δLj,m) > Ltot,
(4)
with δ set to 1 if the output search procedure discovers a
memory disclosure, and 0 otherwise.
Given that the inequality in Eqt. 4 holds, our objective
becomes the discovery of heuristics that selectively execute
the searching of system outputs based on the past history of
memory disclosure attacks such that,
O(cid:2)
i=1
H (Li,s + δLi,m) < Ltot,
(5)
holds, with H representing the set of heuristic rules. The focus
of this study is on the development of techniques for automated
defender policy formulation.
III. ATTACKER AND DEFENDER MODELS
To keep the focus on defender policy development, we
make simplifying assumptions with regards to the attacker
model. We posit an implicit attacker model in which the effect
of the attacker’s actions are accounted for as opposed to the de-
tails of those actions. For the class of attacks we study here the
effect of the attacker’s actions is to cause memory addresses to
be leaked from the system (i.e., memory disclosures). We use
the term implicit because the effect explicitly modeled (i.e.,
memory disclosures) have implicit in them the actions of the
attacker that led to those memory disclosures, though these
detailed attacker actions are not included in our model.
We make an additional modeling assumption that all un-
mitigated memory disclosures harm the defender’s security
stance and advantage the attacker. We term this the efﬁcient
attacker assumption because no memory disclosure fails to
harm the defender. Given the efﬁcient, implicit attacker model
we adopt here, the key property characterizing an attacker
becomes the frequency and temporal clustering of memory
disclosures caused by a given attack.
A. Security and Performance Metrics
We use simple, intuitive notions of security and perfor-
mance to evaluate the defensive system’s performance. We de-
ﬁne security as the ratio of the number of memory disclosures
that have been mitigated by the defender ( Ωmit), and the total
number of memory disclosures (Ωtot) caused by the implicit
attacker’s actions.
Security =
Ωmit
Ωtot
,
(6)
609
We characterize performance by the ratio of system outputs
searched by the defender (Os) to the total number of system
outputs (Otot) that have exited the system,
P erf ormance = 1 − Os
Otot
.
(7)
Our notion of security is deﬁned with an implied assump-
tion regarding the existence of an oracle that is able to inform
the evaluation framework of the number of memory disclosures
that have been missed up to the present round of attacker-
defender interaction. This oracle construct is used strictly in
the evaluation phase of our study. The defender’s strategy
evolution does not access oracle-class information on a policy’s
success. Q-function terms (see Section IV) that would capture
this oracle-class information are explicitly excluded from the
reinforcement learning framework.
We also note here that our deﬁnition of security and
performance in this study assumes what might be termed an
incrementalist approach to security, in which each memory dis-
closure that is not mitigated through re-randomization harms
the defender’s security stance by an equal quantitative amount.
This can be contrasted with the notion of sudden, catastrophic
security failure,
in which a single attacker success leads
to irrevocable compromise of the system’s mission. While
many examples of sudden, catastrophic attacks involving the
neutralization of ASLR defenses can be easily imagined, a
recent example of an incrementalist-style attack is the so called
Blind Return Oriented Programming (BROP) attack outlined
in [10], particularly the third phase of the BROP attack in
which a binary is progressively dumped to the network (see
[10] for details). The generalization of our methodology to
treat the common catastrophic security compromise scenario
encountered in many real world systems is a topic for future
investigations.
B. Model of Statistical Search
To detect memory disclosures in our model the defender
inspects the payloads of system outputs for address signatures