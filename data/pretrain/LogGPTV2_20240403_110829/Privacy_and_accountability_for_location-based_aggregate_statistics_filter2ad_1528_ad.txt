uploading huge numbers that affect the aggregate result. Such proof
is done using the efﬁcient interval zero-knowledge proof of [5]; the
server makes such interval publicly available for each aggregate.
We discuss the degree to which fake tuples can affect the result in
section 9.2.
6.2 A Zero-Knowledge Proof of Knowledge
We require a commitment scheme (such as the one in [31]): recall
that a commitment scheme allows a client Alice to commit to a
value x by computing a ciphertext ciph and giving it to another
client Bob. Bob cannot learn x from ciph. Later, Alice can open
the commitment by providing x and a decommitment key that are
checked by Bob. Alice cannot open the commitment for x = x and
pass Bob’s veriﬁcation check.
Public inputs: id, Tid, PKs, g, h
Client’s input: s, σ = sig(s).
Server’s input: SKs
CONSTRUCTION 1. Proof that Client knows s and σ such that
ids = T and σ is a signature by Server on s.
1. Client computes a Pedersen commitment to s: com = gshr
mod n, where r is random. Client proves to Server that
she knows a signature sig(s) from the server on the value
committed in com using the protocol in [10].
2. Client proves that she knows s and r such that Tid = ids and
com = gshr as follows:
(a) Client picks k1 and k2 at random in Zn. She computes
T1 = gk1 mod n, T2 = hk2 mod n and T3 = idk1
mod n and gives them to the server.
(b) Server picks c a prime number, at random and sends it
to Client.
them to Server.
(c) Client computes r1 = k1 + sc, r2 = k2 + rc and sends
(d) Server checks if comcT1T2
≡ gr1 hr2 mod n and
≡ idr1 mod n. If the check succeeds, it out-
T c
puts “ACCEPT”; else, it outputs “REJECT”.
idT3
?
?
This proof can be made non-interactive using the Fiat-Shamir
heuristic [13] or following the proofs in [5]; due to space limits, we
do not present the protocol here. The idea is that the client computes
c herself using a hash of the values she sends to the server in a way
that is computationally infeasible for the client to cheat.
THEOREM 2. Under the strong RSA-assumption, Construction
1 is a zero-knowledge proof of knowledge that the client knows s and
σ such that ids = Tid mod n and σ is a signature by the server on
s.
Due to space constraints, the proof is presented in a longer ver-
sion of this paper at http://nms.csail.mit.edu/projects/
privacy/.
6.3 Optimization
To avoid performing the accountability check for each tuple up-
loaded, the server can perform this check probabilistically; with a
probability q, it checks each tuple for aggregate id. If the server
notices an attempt to bias the aggregate (a proof failing or a dupli-
cate token), it should then check all proofs for the aggregate from
then on or, if it stored the old proofs it did not verify, it can check
them all now to determine which to disregard from the computation.
Note that the probability of detecting an attempt to violate the up-
load quote, Q, increases exponentially in the number of repeated
uploads, n: Q = 1 − (1 − q)n. For q = 20%, after 10 repeated
uploads, the chance of detection is already 90%. We recommend
using q = 20%, although this value should be adjusted based on the
expected number of clients uploading for an aggregate.
6.4 Generality of Accountability
The accountability protocol is general and not tied to our setting.
It can be used to enable a server to prevent clients from uploading
more than a quota for each of a set of “subjects” while preserving
their anonymity. For example, a class of applications are online
reviews and ratings in which the server does not need to be able to
link uploads from the same user; e.g., course evaluations. Students
would like to preserve their anonymity, while the system needs to
prevent them from uploading more than once for each class.
7. AGGREGATE STATISTICS SUPPORTED
SLP supports any aggregates for which efﬁcient homomorphic
encryption schemes and efﬁcient veriﬁcation or proof of decryption
exist. Additive homomorphic encryption (e.g., Paillier [30]) already
supports many aggregates used in practice, as we explain below.
Note that if veriﬁcation of decryption by the SM is not needed (e.g.,
in a distributed setting), a wider range of schemes are available.
Also note that if the sample value is believed to not leak, arbitrary
aggregates could be supported by simply not encrypting the sample.
Table 1 lists some representative functions of practical interest
supported by PrivStats. Note the generality of sum and average of
functions — F could include conditionals or arbitrary transforma-
tions based on the tuple. When computing the average of functions,
some error is introduced due to the presence of junk tuples because
each sample is weighted by the number of uploads. However, as we
show in §9.2, the error is small (e.g., < 3% for average speed for
CarTel).
Note in Table 1 that count is a special case and we can make some
simpliﬁcations. We do not need the SM at all. The reason is that the
result of the aggregate itself equals the number of tuples generated at
the sample point, so there is not reason to hide this number any more.
Also, since each sample of a client passing through the sample point
is 1, there is no reason to hide this value, so we remove the sample
encryptions. As such, there is no need for the SM any more. Instead
of contacting the SM in the sync. interval (Fig. 3), clients directly
upload to the server at the same random timing.
Additive homomorphic encryption does not support median, min,
and max. For the median, one possible solution is to approximate
it with the mean. One possible solution is to use order-preserving
encryption [4]: for two values a < b, encryption of a will be smaller
than encryption of b. This approach enables the server to directly
compute median, min, and max. However, it has the drawback that
the server learns the order on the values. An alternative that leaks
less information is as follows: To compute the min, a client needs to
upload an additional bit with their data. The bit is 1 if her sample is
smaller than a certain threshold. The server can collect all values
with the bit set and ask the SM to identify and decrypt the minimum.
(Special purpose protocols for other statistics are similar.)
660Aggregation
Summation
functions
Addition of
 F (tuplei)
Average
Standard Deviation
Average of
functions
i=1 F (tuplei)/N
N
Count
Average no. of people in a
certain speed range. Average
speed and delay. This is a gen-
eralization of average.
Trafﬁc congestion: no. of
drivers at an intersection.
Table 1: Table of aggregate statistics supported by PrivStats with example applications and implementation.
of people carpooled
Example Application
No.
through an intersection.
Count of people exceeding
speed limit. This is a gener-
alization of summation.
Average speed or delay.
Standard deviation of delays.
Implementation
Each client uploads encryption of the number of people in the car. Junk tuples are encryptions
of zero.
Each client applies F to her tuple and uploads encryption of the resulting value. Junk tuples
are encryptions of zero.
See average of functions where F (tuple) = sample.
Compute average of functions (see below) where F (tuple) = sample2 and denote the result
Avg1. Separately compute F (tuple) = sample and denote the result Avg2. The server
one would also want to compute average when computing std. deviation.
computesAvg2 − (Avg1)2. This procedure also reveals average to the server, but likely
If count (see below) is also computed for the sample point, computeN
i=1 F (tuplei) as
above instead, and then the server can divide by the count. Otherwise, compute summation
of functions, where junk tuples equal real tuples. The server divides the result by the
corresponding Uid.
The SM is not needed at all for count computation. Clients do not upload any sample value
(uploading simply id is enough to indicate passing through the sample point). There are no
junk tuples.
8. PRIVACY ANALYSIS
We saw that if the clients, smoothing module, and the server
follow the SLP protocol, clients have strong location privacy guar-
antees. We now discuss the protection offered by PrivStats if the
server, SM, or clients maliciously deviate from our strict location
privacy protocol.
Malicious server. The server may attempt to ask the SM to de-
crypt the value of one sample as opposed to the aggregate result.
However, this prevents the server from obtaining the aggregate re-
sult, since the SM will only decrypt once per aggregate id, and we
assume that the server has incentives to compute the correct result.
Nevertheless, to reduce such an attack, the SM could occasionally
audit the server by asking the server to supply all samples it aggre-
gated. The SM checks that there are roughly Uid samples provided
and that their aggregation is indeed the supplied value.
The server may attempt to act as a client and ask the SM for sid
(because the upload is anonymous) to ﬁgure out the total number
of tuples. Note that, if the aggregate is not underpopulated, if the
server asks for sid at time t, it will receive as answer approximately
Uid(t − ts0)/(ts1 − ts0), a value it knew even without asking the
SM. This is one main reason why we used the “growing sid” idea
for the sync. interval (Fig. 3), as opposed to just having the SM
count how many clients plan to upload and then informing each
client of the total number at the end of the sync. interval, so that they
can scale up their uploads to reach Uid. Therefore, to learn useful
information, the server must ask the SM for sid frequently to catch
changes in sid caused by other clients. However, when the server
asks the SM for sid, the helper increases sid as well. Therefore, the
SM will reach the Uid quota early in the sync. interval and not allow
other clients to upload; hence, the server will not get an accurate
aggregate result, which is against its interest.
Malicious SM. Since the server veriﬁes the decryption, the SM
cannot change the result. Even if the SM colludes with clients,
the SM has no effect on the accountability protocol because it is
entirely enforced by the server. If the SM misbehaves, the damage
is limited because clients upload tuples without identiﬁers, network
origin, and our staged timing protocol for upload hides the time
when the tuples were generated even from the SM. A compromised
SM does permit SI attacks based on sample value and number of
tuples; however, if the SM is distributed, we expect the fraction of
aggregates with a compromised SM to be small and hence our SLP
guarantees to hold for most aggregates.
The SM may attempt a DoS attack on an aggregate by telling
clients that Uid tuples have already been uploaded and only allowing
one client with a desired value to upload. However, the server can
easily detect such cheating when getting few uploads.
Malicious clients. Our accountability protocol prevents clients
from uploading too much at an aggregate, too much over all aggre-
gates, and out-of-range values. Therefore, clients cannot affect the
correctness of an aggregate result in this manner. As mentioned in
§2, we do not check if the precise value a client uploads is correct,
but we show in §9.2 that incorrect value in the allowable range likely
will not introduce a signiﬁcant error in the aggregate result.
Colluding clients may attempt to learn the private path of a spe-
ciﬁc other client. However, since our SLP deﬁnition models a
general adversary with access to server data, such clients will not
learn anything beyond the aggregate result and the SI they already
knew (which includes, for example, their own paths). A client may
try a DoS attack by repeatedly contacting the SM so that the SM
thinks Uid tuples have been uploaded. This attack can be prevented
by having the SM also run the check for the total number of tuples a
client can upload; Uid for a popular aggregate should be larger than
the number of aggregates a client can contribute to in a day. For a
more precise, but expensive check, the SM could run a check for the
quota of tuples per aggregate, as the server does.
Aggregate result. In some cases, the aggregate result itself may
reveal something about clients’ paths. However, our goal was to
enable the server to know this result accurately, while not leaking
additional information. As mentioned, clients can choose not to
participate in certain aggregates (see §2).
Differential privacy protocols [11] add noise into the aggregate re-
sult to avoid leaking individual tuples; however, most such protocols
leak all the private paths to the server by the nature of the model.
§3 explains how the SLP and differential privacy models are com-
plementary. A natural question is whether one can add differential
privacy on top of the PrivStats protocol, while retaining PrivStats’
guarantees. At a high level, the SM, upon decrypting the result, may
decide how much noise to add to the result to achieve differential
privacy, also using the number of true uploads it knows (the number
of times it was contacted during the sync. interval). The design
of a concrete protocol for this problem is future work. Related to
this question is the work of Shi et al. [37], who proposed a protocol
combining data hiding from the server with differentially-private
aggregate computation at the server; they consider the different
661End-to-end metric
Setup
Join, Nexus client
Join, laptop client
Upload without account., Nexus
Upload with account., Nexus
Upload with 20% account., Nexus
Upload without account., laptop
Upload with account., laptop
Aggregation (103 samples)
Aggregation (104 samples)
Aggregation (105 samples)
Result
0.16 s
0.92 s
0.42 s
0.29 s
2.0 s
0.6 s
0.094 s
0.84 s
0.2 s
0.46 s
3.1 s
Contact SM
Prepare tuples
Prepare account.
proof
Upload to server and wait reply
 0