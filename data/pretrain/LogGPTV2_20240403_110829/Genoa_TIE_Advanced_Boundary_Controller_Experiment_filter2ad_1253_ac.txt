accuracy  where  lower-level  key-topic  detail  can  be
obtained.
To  assess 
the  performance  of 
the  Felt  and
DataShield filters, the timing data collected for the GT
assessment  provided  the  basis  for  comparison.  The
times collected by the human reviewers are approximate
processing  times  for  each  transaction.  These  times,
recorded in minutes, represent the duration of review of
both  the  request  and  response.  The  corresponding
transaction times for Felt and DataShield were extracted
from the experiment logs, although recorded  with finer
granularity.
to  record 
timing  measures 
the 
two  filters, 
By  utilizing  timing  log  library  routines,  Felt  was
in  microseconds.
able 
DataShield  implemented  a  general-purpose  timing  log
interface that allowed for the inclusion of a time-stamp
recorded only in seconds. In addition to the timing data
generated  by 
the  ARGuE  filter
subsystem  also  created  timing  information  through  the
use  of  the  general-purpose  interface.  The  subsystem
created each timestamp before and after the execution of
the request and response filters. Thus, timing messages
created  by  the  filters  are  encapsulated  within  the  filter
subsystem  messages.  All  of  these  possible  timing
methods  offer  varying  levels  of  precision.  Due  to  the
incompatibility  of 
timing  data
(seconds  vs.  microseconds),  the  subsystem  timing  data
was used  for  comparison  with  the  GT  results.  Because
the  filter-generated 
88%
86%
77%
73%
95%
88%
73%
55%
Felt 
DataShield
100%
90%
80%
70%
60%
50%
40%
30%
20%
10%
0%
Precision
"Product"
Precision
"Topic"
Recall
"Product"
Recall  
"Topic"
Figure 4: Precision and recall ratios
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 07:08:29 UTC from IEEE Xplore.  Restrictions apply. 
assumptions made by the human reviewers were correct,
this  practice  could  have  lead  to  incorrect  assessments.
Due  to  the  mixture  of  sources  used,  there  was  no
guarantee  that  the  products  contained  the  exact  same
data.
Conclusion
Human-in-the-loop  content  analysis  is  a  resource
intensive operation. Due to fatigue, boredom, and other
factors,  human  reviews  can  be  time  consuming  and
error  prone.  Automated 
can
supplement,  and  may  eventually  replace,  manual
content-based reviews as technology advances.
filtering 
content 
found 
to  determine 
Through  Genoa  TIE  efforts,  we 
that
automated  syntactic  and  NLP  capabilities  could  be
measured 
the  filters’  strengths  and
weaknesses.  Metrics  were  recorded  in  both  accuracy
and  performance,  and  based  upon  a  controlled  human
technology
review.  From 
limitations  were 
and 
ideal
configurations could be surmised based on  tradeoffs  in
accuracy,  performance,  and  risk.  While  our  human
review still provided the most accurate assessment, it is
important  to  note  that  it  represented  an  ideal  situation,
these  measures,  current 
recognized 
easily 
Felt 
Datashield
Human
the 
library 
of this fact, the collected times for Felt and DataShield
are slightly inflated (compared to timing data collected
through 
in
microseconds). While the subsystem timing data wasn’t
the  most  accurate  measure,  it  does  provide  consistent
measure  of  the  overhead  incurred  for  filtering  the
request and reply of each transaction.
routines  measuring 
time 
Figure  5  provides  a  graphical  view  of  the  mean
average  transaction  filtering  times  incurred  for  Felt,
DataShield, and human review. All of the timing data is
displayed in seconds and shown on a logarithmic scale.
Due to size constraints, only odd numbered transactions
are shown.
For  each  transaction,  Felt  outperformed  both  the
DataShield  and  human  review  with  markedly  faster
times.  Except  for  transactions  30  and  39,  DataShield
outperformed  the  human  review.  These  anomalies  are
explained  through  inspection  of  the  CIP  data,  where
transactions  29  and  30  as  well  as  38  and  39  contained
the same products. The human review of transactions 30
and  39  were  greatly  reduced  because  of  knowledge
retained  from  the  previous  transactions.  This  same
effect is visible through the gradual decrease in human
review time for the first seven transactions, all of which
contained the same products. Although in this  case  the
10000
1000
100
10
1
1
3
5
7
9 11 13 15 17 19 21 23 25 27 29 31 33 35 37 39 41 43 45 47 49 51 53 55 57 59 61 63 65
Transaction #
Figure 5: Total transaction times
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 07:08:29 UTC from IEEE Xplore.  Restrictions apply. 
with  considerable  processing  effort  and  time  expended
by multiple reviewers.
In  evaluating  the  content  filtering  abilities  of  Felt,
DataShield,  and  the  human  review,  findings  confirm
that  no  one  content  filtering  method  is  a  completely
reliable  solution.  This  fact  is  solidified  by  current  day
implementations  of  guards  within  true  Multi-Level
Security (MLS) environments. In most cases, automatic
downgrading 
classified
environments is not possible, because much of the data
is unstructured. Other issues include the complexity and
conveyance  of  the  English  language,  and  its  numerous
possibilities  for  interpretation.  Transforming  English
policy  into  a  portable,  machine-readable  format  has
proven a formidable task.
sanitization  within 
or 
overprotective system can constrain the effectiveness of
the mission at hand.
Overall,  our  findings  support  that  the  various
filtering  methods  can  be  combined  to  provide  a  better
filter  configuration  than  any  single  solution.  The  NLP
capabilities  of  DataShield  certainly  supplemented  the
abilities  of  the  syntactic  review,  although  each  of  the
filtering  methods  detected  content  violations  that  the
other  methods  did  not.  By  combining  the  strengths  of
Felt syntactic filtering and DataShield NLP capabilities
with  manual  review,  increased  levels  of  accuracy  and
efficiency  could  be  obtained.  Ideally,  tradeoffs  in
accuracy,  performance,  and  risk  can  result  in  an
automated  solution  that  is  more  desirable  than  manual
review.
the 
For the Genoa TIE, a very complex policy set was
instrumented  via  RML.  Although  we  determined  that
RML  was  not suited to support these complex  rules  as
accurately as hoped, its use within the TIE was vital in
collecting 
guard
implementations  do  not  tend  to  institute  such  complex
policies,  and  solutions  for  representing  such  complex,
portable policies without room for interpretation, do not
exist. Continued research in this area may prove useful
in  developing  future  solutions  for  next  generation
policy-based filters.
data.  Current 
presented 
less  accurate 
this  experiment  proved 
The  Felt  syntactic  filtering  system  implemented
within 
than
expected.  Although  Felt  experienced  a  low  False
Positive  rate,  it  also  experienced  a  low,  positive
identification rate  for valid  policy  violations.  Since  the
Felt  filters  rely  solely  on  a  keyword  list  of  specified
key-topic  areas,  its  ability  to  perform  well  has  to  do
with  the  careful  selection  of  those  keywords.  The
keywords  for  this  experiment  were  gathered  from
various  open  source  documents  pertaining  to  the  key-
topic areas, and were not chosen from known CIP data.
A  more  comprehensive  key-word 
list  may  have
provided  better  results,  although  False  Positive  rates
would most likely have increased. Felt was considerably
faster than either DataShield or human review, and Felt
correctly  identified  key-word  instances  that  DataShield
and the human reviews both missed.
MNLP  performed  by  DataShield  was  significantly
better than the syntactic only review performed by Felt.
While not as accurate as the human review, DataShield
was  considerably  more  efficient  at  processing  the
transactions.  DataShield  did  suffer  from  a  degree  of
False Positive detections, although it correctly identified
most  of  the  key-topic  policy  violations  within  the
products. In terms of sensitive information transfer, we
assert  that  it  is  certainly  more  desirable  to  erroneously
withhold information that doesn’t violate the policy than
an
release 
does.  However, 
information 
that 
Within the Genoa environment, the implementation
of  ARGuE  along  with  Felt  and  DataShield  filters  did
provide the capability to perform access control among
enclaves.  Although  several problems did exist  with the
correct  implementation  of  the  policy  due  to  human
misinterpretation,  the  system  was  able  to  accept  an
updated  policy  and  to  the  best  of  the  filters  abilities,
enforce that policy. Experiment data highlights the fact
that Felt and DataShield were able to correctly detect all
previously  identified  violations  within  the  metadata.
This is most likely due to the well-structured nature of
the metadata where less ambiguity is involved. Because
the  syntactic  review  of  the  metadata  was  considerably
faster and was just as accurate as the NLP review, Felt
would be the better choice for filtering CIP and product
metadata.  DataShield 
the
unstructured  product  content,  where  it  excelled  at
interpreting the meanings of the words contained within.
By accepting some level of risk, an efficient, automated
solution  comprised  of  Felt  and  DataShield  could
provide  Genoa  with  the  necessary  access  control  and
content-based  filtering  of  inter-enclave  transactions.
Within  a  high  assurance  environment,  a  hybrid  of
automated  filters  and  manual  processing  could  provide
additional accuracy and increased efficiency to manual-
only reviews.
is  better 
suited 
for 
Within 
this  experiment,  MNLP  surpassed 
the
detection capabilities of the syntactic filters. Could this
technology  be 
implemented  within  other  security
realms?  For 
instance,  current  Intrusion  Detection
Systems  (IDS)  essentially  filter  network  traffic  for
specific, known attack strings and sequences of events.
Could  similar  technologies  be  “trained”  to  analyze
traffic  with  a  higher  degree  of  accuracy,  capable  of
detecting novel attacks?
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 07:08:29 UTC from IEEE Xplore.  Restrictions apply. 
References
[4] J. Guttman, J. Ramsdell, and V. Swarup, Felt: A Security
Filter Compiler, Personal Communication, November 1998.
[1] www.darpa.mil/iso2/project_genoa/project_genoa_white_
paper.html
[5] www.solutions-united.com
[2] www.darpa.mil
[3] www.gospelcom.net/apologeticsindex/a06.html
[6] www.solutions-united.com/products_technology.html
[7]  J.  Epstein,  Architecture  and  Concepts  of  the  ARGuE
Guard,  Proceedings  of  the  15th  Annual  Computer  Security
Applications Conference (ACSAC), December 1999.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 07:08:29 UTC from IEEE Xplore.  Restrictions apply.