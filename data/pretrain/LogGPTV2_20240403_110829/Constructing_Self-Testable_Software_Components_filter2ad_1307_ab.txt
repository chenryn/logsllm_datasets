### Introduction to Built-In Test (BIT) and Observability

The built-in test (BIT) approach is a Design for Inspectability (DFI) technique that incorporates standard test circuits and pins. This allows a card or an Integrated Circuit (IC) to be placed in a test mode, enabling the transmission of test inputs and the capture of outputs. An advanced extension of this approach involves integrating mechanisms within the IC for generating test inputs, thus eliminating the need for external testers. This concept is known as Built-In Self-Test (BIST).

### Enhancing Controllability and Observability

Several authors have proposed using hardware-based approaches to improve software testability. D. Hoffman, for instance, suggests augmenting a moduleâ€™s interface with testing features, similar to the access programs used in BIT approaches in hardware. Additionally, integrating assertions into the source code can enhance controllability and observability. Test suites, which can be reused from previous testing (mainly for regression testing), or manually generated, should be described in a specific notation to facilitate the automatic generation of drivers. The advantage over hardware is that these testing features do not need to be part of the final version; their inclusion can be controlled via compiler directives.

R. Binder adapts this approach to the object-oriented (OO) context by proposing the construction of self-testing classes [Binder94]. A self-testing class consists of the class under test (CUT) augmented with BIT capabilities and a test specification (t-spec). The BIT capabilities allow for accessing test facilities, controlling and observing an object's internal state, and monitoring intermediate results using assertions. The t-spec is used for test generation and as a test oracle.

### Architectures for Self-Testing Classes

Binder proposes different architectures for self-testing classes. In our study, we use the architecture based on a driver generator, which uses the information in the t-spec to generate a specific driver. This driver then activates the CUT, applies the test inputs, and analyzes the test results. Our aim was to demonstrate the feasibility of this approach.

### Proposed Approach

#### 3.1 Methodology

The methodology is divided into two parts: one for the component producer and the other for the component consumer.

**Component Producer Tasks:**
1. Construct the test model.
2. Develop the t-spec from the test model and insert it into the component source code.
3. Instrument the component source code to introduce built-in test mechanisms.

**Component Consumer Tasks:**
1. Generate test cases based on the t-spec.
2. Compile the component in test mode.
3. Execute tests.
4. Analyze the results to determine the extent to which the component provides the specified services.

The Concat tool [33] was developed to provide the built-in test interface and support test generation. Its primary purpose was to demonstrate the feasibility of the proposed approach and validate the test generation strategy.

#### 3.2 Test Specification Construction

In this work, we opted for a specification-based testing technique, where the test model represents the component's specification. This approach offers several advantages:
- Integrating the component's specification improves understandability and testability.
- The specification can serve for both test case generation and oracle development.
- Test selection is, to some extent, independent of the implementation language, allowing for easier incorporation when the component is modified.
- Updating the specification becomes easier when it is integrated with the component.
- The quality of the specification can be improved by detecting and removing incompleteness, ambiguity, and inconsistency.

It is important to note that while we focus on specification-based testing, other types of tests are still valuable. We assume that a component has been extensively validated before deployment. Embedded test facilities are primarily intended to facilitate testing when the component is reused or altered.

According to Beugnard et al. [1, c.5, 31], a component specification should describe its interface and behavior. The interface description includes input and output features and their related value space (domain). In the OO context, this comprises method signatures, including argument types and order, and return types. Behavior description includes expected outputs in response to messages sent to an object, as well as non-functional aspects such as time and space efficiency, safety, and security.

Different types of specifications have been used for OO testing. For example, Doong and Frankl present the ASTOOT approach [13], based on algebraic specifications, where operations on abstract data types are described in terms of axioms. Another commonly used model is based on finite state machines [7, 22, 241], as they are suitable for representing an object's behavior. Barbey et al. used COOPN/2 (Concurrent Object-Oriented Petri Nets), a language based on a combination of Petri nets and algebraic models [2].

These models are useful for describing functional requirements, but less work has been done on non-functional requirements. One notation developed to express such requirements is NoFun [17], which allows the representation of software attributes such as time and space efficiency, reusability, maintainability, reliability, and usability.

In this work, we used the Transaction Flow Model (TFM), defined by B. Beizer for concurrent systems testing [4, 5], to represent functional behavior aspects. A transaction is a unit of work seen from a user's point of view, consisting of a sequence of operations that can be performed by a human, a system, or a device. S. Siege1 adapted this model for unit testing of a class [29, ch.11]: in this case, a transaction describes an allowable sequence of method invocations from creation to destruction. The TFM represents the different ways an object can be created, the tasks it can perform, and the ways it can be destroyed. A TFM is represented as a directed graph, where nodes represent public features (attributes or methods) of the class, and links connect nodes if one task is immediately followed by another. An individual transaction is a path through the TFM from the birth to the death of an object.

This model can be derived from use cases defined during the requirements specification phase, making it useful for validation testing. For objects with a finite set of allowable method sequences, this model is particularly useful. Our main reason for using this model is that it scales better than finite state machine models, which are more commonly used in OO testing. It can be applied to components with multiple objects or sub-components, showing the sequencing of activities performed by several objects. Additionally, it can represent concurrent behavior, though this feature was not considered in our studies yet.

### Example: Class Product

Consider the class `Product` in Figure 1, representing a product in the stock control system of a warehouse. The product is obtained from a `Provider`, another class in the system. The use case scenario for adding a new product to the stock database is as follows:
1. Create a `Product` object.
2. Obtain data about the product from the database.
3. Remove the product from the database.
4. Destroy the object.

Figure 2 shows the TFM for the `Product` class, with the path corresponding to the use case highlighted. After developing the test model, the t-spec representing it is created and integrated into the component under test.

### Test Specification (t-spec) Format

The t-spec format is shown in Figure 3, containing a description of the component's interface. For further details on this model, references [4, ch. 4, 5, ch.6, 29, ch.11] can be consulted. Examples from models created in this project can be found in [32, 42].

### Class Instrumentation

Class instrumentation involves introducing additional software into the class to increase its controllability and observability. This extra software facilitates the testing process by providing the necessary hooks and mechanisms for effective testing.

---

This revised text aims to be more clear, coherent, and professional, with improved structure and flow.