title:A security-preserving compiler for distributed programs: from information-flow
policies to cryptographic mechanisms
author:C&apos;edric Fournet and
Gurvan Le Guernic and
Tamara Rezk
A Security-Preserving Compiler for Distributed Programs
From Information-Flow Policies to Cryptographic Mechanisms
Cédric Fournet
Microsoft Research
Cambridge
United Kingdom
PI:EMAIL
Gurvan Le Guernic
MSR–INRIA Joint Centre
Orsay
France
PI:EMAIL
PI:EMAIL
Tamara Rezk
INRIA Sophia Antipolis
Méditerranée
France
ABSTRACT
We enforce information ﬂow policies in programs that run at mul-
tiple locations, with diverse levels of security.
We build a compiler from a small imperative language with lo-
cality and security annotations down to distributed code linked to
concrete cryptographic libraries. Our compiler splits source pro-
grams into local threads; inserts checks on auxiliary variables to
enforce the source control ﬂow; implements shared distributed vari-
ables using instead a series of local replicas with explicit updates;
and ﬁnally selects cryptographic mechanisms for securing the com-
munication of updates between locations.
We establish computational soundness for our compiler: under
standard assumptions on cryptographic primitives, all conﬁdential-
ity and integrity properties of the source program also hold with
its distributed code, despite the presence of active adversaries that
control all communications and some of the program locations. We
also present performance results for the code obtained by compil-
ing sample programs.
Categories and Subject Descriptors
D.2.0 [Software Engineering]: Protection Mechanisms
General Terms
Security, Design, Languages
1.
INTRODUCTION
The security of distributed systems usually entails the implemen-
tation of protection mechanisms based on cryptography to ensure
the conﬁdentiality and integrity of information. This involves ex-
pert knowledge, as well as attention to many implementation de-
tails. Our goal is to let developers focus on high-level security poli-
cies and properties of their programs, and use a compiler to gen-
erate lower-level protection mechanisms that ensure that the dis-
tributed implementation is at least as secure as the source program.
We take information ﬂow security as our speciﬁcation of security
(for an abstract memory model) and also as our model for cryptog-
raphy in the implementation. In information ﬂow security, policies
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
CCS’09, November 9–13, 2009, Chicago, Illinois, USA.
Copyright 2009 ACM 978-1-60558-352-5/09/11 ...$10.00.
are expressed by annotating variables with labels from a lattice [see
e.g. Myers and Liskov, 2000]. Correct information ﬂow in a pro-
gram means that an adversary with restricted access to program
variables can neither affect the program behavior nor gain knowl-
edge above its security level by interacting with the system. Since
this notion of security depends on the semantics of programs, an
essential difﬁculty is to preserve security properties as programs
get compiled to concrete implementations. In a distributed imple-
mentation, for instance, a network adversary may observe messages
sent between hosts, and it may control their scheduling. Inasmuch
as these side channels are not apparent in source programs, they
must be carefully addressed in the compilation process.
We enforce information ﬂow policies in programs that run at
multiple locations, with diverse levels of security. This involves
cryptographic protection whenever relatively secure locations (e.g.
a client and a server) interact via less secure locations (e.g. an open
network).
ࢫ In source programs, security depends on a global program se-
mantics, with abstract policies for reading and writing shared
memory. These policies enable a simple review of conﬁden-
tiality and integrity properties.
ࢫ In their distributed implementations, shared memory is un-
protected, the adversary controls the scheduling, and security
depends instead on cryptographic protection.
Our compiler is structured into four stages: slicing, control ﬂow,
replication, and cryptography. The ﬁrst stage slices sequential code
with locality annotations into a series of local programs, each meant
to run at a single location. After slicing, the second stage pro-
tects the control ﬂow of the source program against a malicious
scheduler, by generating code that maintains auxiliary variables to
keep track of the program state, based on its integrity policy. The
replication stage transforms a distributed program (still relying on a
global, shared, protected memory) into a program where variables
are implemented as local replicas at each location, with explicit
updates between replicas. Finally, the cryptography stage inserts
cryptographic operations to protect these variable updates, and it
generates an initial protocol for distributing their keys.
Our target notions of security are expressed in a computational
model of cryptography. In this model, adversaries are probabilistic
programs that operate on bitstrings and have limited computational
power. This leads us to reason with polynomial-time hypotheses
and probabilistic semantics. We could have used instead a symbolic
model of cryptography, where adversaries may perform arbitrary
computations on abstract algebraic terms (not bitstrings). How-
ever, this simpler model would have hidden many cryptographic
side channels that are relevant in distributed implementations and
problematic for information security. The relation between sym-
432bolic and computational models is the subject of active research
[see e.g. Abadi and Rogaway, 2002, Backes et al., 2003, Comon-
Lundh and Cortier, 2008, Laud, 2008] but it is unlikely that they
can be reconciled at the level of details handled by our compiler.
Thus, we seek computational soundness directly for information-
ﬂow security, rather than for symbolic cryptography.
In prior work, Fournet and Rezk [2008] design a computation-
ally sound type system for cryptography and give a typed trans-
lation from non-interferent source programs to their cryptographic
implementations. Our theory extends theirs in several directions:
Active Adversaries: Our compiled code is secure against ad-
versaries that control the scheduling between hosts. This reﬂects
a realistic attacker model for distributed programs, where the op-
ponent controls parts of the program (representing for instance the
corrupted parties of a protocol) and also controls all interactions
between the remaining “honest” parts of the program (representing
for instance an open network). In their work, they restrict the con-
trol ﬂow of programs and assume that the compiled code follows
the source control ﬂow.
Information release: Our safety conditions on source programs
are less restrictive and do not require noninterference. Hence, our
compiler accepts programs that selectively leak information, and
our theorems state that, for all safe source programs, if an adversary
can successfully attack our compiled code, then there is also an
adversary that can successfully attack the source program.
Efﬁcient use of cryptography: They formalize only asymmetric
cryptography. In contrast, we use asymmetric cryptography only
for initial key distribution, then rely on symmetric cryptography,
which is much more efﬁcient. We also allocate fewer keys and
perform simple cryptographic optimizations.
Main Contributions
ࢫ We design and implement a compiler from sequential pro-
grams with shared memory to distributed programs at least
as secure as the source. Our tool combines both symmetric
and asymmetric cryptography and yields efﬁcient code.
ࢫ We account for a realistic class of active adversaries, which
control some components of the system (including the net-
work) and schedule the others.
ࢫ We obtain computational soundness theorems for all infor-
mation ﬂows, both for secrecy and for integrity.
(We also
show functional correctness, but only for an adversary that
implements a reliable network.)
ࢫ We report experimental performance results obtained for a
series of sample distributed programs.
Related Work Due to lack of space, we discuss only closely re-
lated work. We refer to Sabelfeld and Myers [2003] for a survey
of information ﬂow security, and to Fournet and Rezk [2008] for a
more complete account of cryptographic information ﬂows.
Computational noninterference: Laud [2001] pioneers work on
information ﬂow relying on concrete cryptographic assumptions.
He introduces computational correctness for encryption in a model
with passive adversaries. Our notions of noninterference generalize
this property to the active case, and also cover integrity properties.
Secure program partitioning: Jif/Split [Zdancewic et al., 2002,
Zheng et al., 2003] is a compiler from information ﬂow typed se-
quential Java programs to distributed systems with mutual distrust
between hosts. Their distributed implementation relies on secure
communications, modelled as private channels. We lift this as-
sumption, implement communications using cryptographic mech-
anisms, and prove them correct under standard cryptographic hy-
potheses. Hence, our compiler can be seen as a cryptographic
back-end for Jif/Split. Unlike Jif/Split, we do not consider code
replication but only data replication.
Robustness: A system is robust when an adversary cannot affect
the security of information ﬂow [Zdancewic and Myers, 2001, My-
ers et al., 2006]. Decentralized robustness generalizes this notion
to conﬁgurations with mutual distrust between principals [Chong
and Myers, 2006]. In this work, we rely on similar robustness con-
ditions on source programs.
Contents Section 2 deﬁnes our source and target languages. Sec-
tion 3 deﬁnes information ﬂow policies and security properties.
Sections 4, 5, 6, and 7 describe the slicing, control-ﬂow, replication,
and cryptographic stages of the compiler. Section 8 reports experi-
mental results. Section 9 concludes. Additional deﬁnitions, exam-
ples, and proofs appear online at http://www.msr-inria.
inria.fr/projects/sec/cflow.
2. LANGUAGES
In this section, we present a core probabilistic imperative lan-
guage and its extension to express distribution. We also deﬁne con-
crete distributed programs with explicit scheduling.
Core Language We use a while-language based on transparent
shared memory, with the following grammar:

     :=  ࢯ  :=        ࢯ skip ࢯ ; 
  ࢯ   
ࢯ
ࢯ
if  then  else  ࢯ while  do 
 := declassify ࡁ
where  and  range over deterministic and probabilistic -ary
functions, respectively, with  ࣙ . Expressions  consist of vari-
ables and operations, including standard boolean and arithmetic
constants and operators. Programs and commands  consist of
variable assignments, using deterministic expressions and proba-
bilistic functions, composed into sequences, tests, and loops. (The
assignment  := declassify ࡁ behaves as  := ; it is explained
in Section 3.) We use curly brackets  for parenthesizing com-
mands. We let ML be the set of variables written by , let HL
be the set of variables read by , and let L be ML Þ HL.
Although our language does not feature procedure calls, we can
use command contexts to range over programs with access to ﬁxed,
privileged procedures (sometimes called “oracles” in cryptogra-
phy) using shared variables for passing their input and output pa-
rameters. An -ary command context, written  _     _ࢤ,
is a term obtained from the grammar of commands extended with
placeholders for commands _ (and, more generally, for command
contexts _     ). For instance,  _ ߰ represents a com-
mand, parameterized by a command context _, that ﬁrst runs 
then runs , which may in turn call  ߰ any number of times.
Probabilistic Semantics The semantics of each probabilistic func-
tion is given by a discrete parametric probability distribution. We
write   for the fair “coin-tossing” function that returns either
  . We use probabilistic functions mainly to
 or  with probability 
model cryptographic algorithms as commands.
Program conﬁgurations are of the form   where  is a pro-
gram and  is a memory, that is, a function from variables to values.
The special program
represents termination. The operational se-
mantics of commands is given as Markov chains between program
conﬁgurations, with probabilistic steps  Û ߰ induced by the
Ý
433conﬁgurations ߰, ߰߰ ࢣ
condition : 2H    E࢐Ýࢣ
probabilistic functions (see the full paper). We lift these reduction
steps to conﬁguration distributions, and write  Û ߰ when, for all
Û߰   . We write Ûࢩ for the
transitive closure of Û. We deﬁne the semantics of a program 
with initial memory  as follows:  is the conﬁguration distribu-
tion such that    ;  Û  for  ࣙ ; and 2H  
is the probability that  completes with a ﬁnal memory that meets
ࢯ . (The limit
exists because the sum increases with  and is bounded by .)
Source Language, with Locations Let      ࢠ Ò be a ﬁnite
set of hosts, intended to represent units of trust (principals) and of
locality (runtime environments). We extend the grammar of the
core language () with locality annotations:
Ý
       ࢯ   
The locality command    states that command  should run
at host . This programming abstraction hides the implementation
details for transferring control between the current host and  be-
fore and after running command . Locality commands can be
nested, as in          . We assume that every source
program has a locality command at top level, setting an initial host.
Since memory is transparently shared between hosts, locality an-
notations do not affect our command semantics.
Target Language, with Explicit Scheduling A distributed pro-
gram is just a series of commands in the core language, each com-
mand intuitively running at a single host. We refer to these com-
mands as threads. (Pragmatically, our compiler groups threads run-
ning at the same host into a single host command that locally sched-
ules its threads.)
To model the intended behavior of a distributed program with 
threads, in particular to state its correctness in the absence of an ad-
versary, we deﬁne an -ary command context  that implements
a round-robin scheduler. This command context uses a global pro-
gram counter variable ANJ that indicates which thread should run
next, with a special value  to indicate the end of the execution.
DEFINITION 1
_     _
(-ARY SCHEDULER).

 while ANJ ࢧ  do _;    ; _
This context may represent a public network, for instance, with
communications between hosts using messages in shared memory.
Finally, we model a compiler  as a function from source pro-
grams   to series of commands          where
 is a distinguished initialization command and  are com-
mands representing threads, meant to be executed as
ANJ := ; ;      
To study the security properties of this compiled program, we will
replace  with some unknown command context  representing
an active adversary that controls the scheduler.