names of all the applications but not see anything
inside any of the apps and give an example, such
as, if you have WhatsApp, we will not see any con-
versation inside.” (P41, Case Manager)
Focus groups also led us to realize that both clients and con-
sultants are consumers of the ISDi UI (see Figure 2). We
therefore avoided language that would be too confusing or
scary to a client. Finally, while we have not yet done a thor-
ough user study of the tool, we have begun some initial user
studies with IPV support organizations (e.g., TECC [2]) in-
terested in integrating ISDi into their own procedures. We
discuss this further in Section 8.
That leaves checking conﬁgurations of common apps that
are often wanted but potentially dangerous, as well as check-
ing built-in system services (e.g., “ﬁnd my phone” features),
account backup mechanisms, and authentication lists (e.g.,
registered ﬁngerprints), all of which may be sources of vulner-
ability. The same holds for online accounts deemed important
by the client (e.g., email and social media accounts). Unfortu-
nately, checking the privacy of these accounts cannot be easily
automated, not only due to lack of device or web interfaces to
support querying this kind of data, but also because one needs
to understand the context and have the client help identify
110    28th USENIX Security Symposium
USENIX Association
dangerous conﬁgurations. For example, in several cases we
saw that the client’s Facebook or GMail accounts had been
accessed by devices the client could conﬁrm as the abuser’s.
To assist the consultant with these manual investigations,
we constructed simple-to-follow guides for popular apps, de-
vice settings, and online service settings. For instance, our
Google privacy conﬁguration guide lists steps to check a
device’s login history, location sharing, photo sharing, and
Google Drive backup settings. On iCloud we check family
sharing, backups to iCloud, and if the abuser still has access
to the account. We continue to expand the list of apps and ser-
vices for which we have guides in response to ongoing work
with clients, and currently cover Android (including Google
maps and GMail), Apple (including iCloud and location shar-
ing), Facebook, Instagram, and Snapchat. Unfortunately such
guides may become out-of-date if software updates change
conﬁguration features. Future work on how to sustainably
keep guides up-to-date will be needed (see Section 8).
Another beneﬁt of performing manual investigations dur-
ing consultations is that they serve as impromptu computer
security training for clients, which prior work indicated is
sorely needed [19]. In fact, many clients we met with did not
know about security conﬁguration features, and we were able
to show them for the ﬁrst time that, for example, they could
tell what devices were logged into their GMail or Apple ac-
counts. Clients often asked followup questions about security
best practices during this part of the consultation, leading into
an open-ended discussion about computer security.
Advising clients on potential next steps. In the ﬁnal phase
of the consultation, the consultant combines information
gleaned from the understanding and investigation phases to
assess the client’s situation and, based on this assessment,
discuss with the client (and professional, if present) what
might be causing tech problems the client is experiencing. If
the investigation phase yields any spyware, risky software,
or privacy problems with the client’s accounts and devices,
these are discussed calmly with the client, including how the
breach may have happened and potential actions that might
remedy the situation. In these cases, the consultant can offer
the client a printout that explains what was found and how it
may be causing problems (see examples in the full version).
Before taking actions or changing any settings, it is essen-
tial that the client discuss their consultation results with a
professional to perform safety planning. Ideally the profes-
sional should be familiar with the client’s situation and abuse
history, since this is necessary to highlight potential safety
issues related to tech abuse. One professional said:
“Safety planning is such an individualized thing. I
can think of some cases where it would be advanta-
geous to leave the spyware on. I can think of some
where we would want it gone immediately. If you
can, just ﬁnd a way to integrate it into the normal
safety planning protocol.” (P37, Paralegal)
If the client’s case manager is not present, the consultant asks
the client if they would like to contact their case manager
and/or receive immediate assistance from another on-site pro-
fessional. Thus, even if the consultation has identiﬁed tech
problems that are the likely causes of the client’s concerns, in
many cases, the client may leave the consultation with their
devices and accounts unchanged. For a few clients we met
with who had complicated scenarios, we encouraged them to
schedule a follow-up consultation via their professional, so
we could help them further after safety planning.
Consultations also provide new opportunities for collecting
forensic digital evidence. The need for clients to document
evidence of tech abuse is an issue that legal professionals
discussed at length in our focus groups. If properly collected,
such evidence may help a client secure an order of protection
or aid a criminal investigation. Although clients may want to
delete suspicious apps or reconﬁgure settings, our protocol
has the consultant discuss with clients the potential beneﬁts of
documenting any discoveries before taking action. We asked
professionals about how to handle forensic evidence, and they
suggested various approaches, such as:
“I would deﬁnitely take photos. Because ultimately
[a detective] will be investigating that report, but I
will deﬁnitely take photos, write down the name of
the app on my report.” (P39, Police Ofﬁcer)
We therefore settled on the expedient approach of having the
client (or a lawyer acting on their behalf) take a photo or
screenshot of any discovered spyware, evidence of compro-
mises, etc. As suggested in the quote above, this is actually
the standard of evidence currently, at least in family court, and
several clients we met with have ongoing court cases in which
they plan to use evidence discovered via our consultations.
In many cases the consultation will not yield any tech prob-
lems or causes for concern, in which case the consultant may
reassure the client that, at least, our approaches did not ﬁnd
any problems. We are careful to not dismiss any problems that
remain unaddressed or unexplained by our consultation. If
additional investigation is warranted, the consultant explains
to the client that they will do more work and follow-up via
the referring professional (as explained in Section 4.1).
Finally, at the end of a consultation, the consultant com-
pletes a case summary that documents (1) the client’s chief
concerns (in their own words), (2) the consultant’s assess-
ment of problems, (3) the results of the ISDi scan and manual
conﬁguration check-ups, and (4) advice or recommendations
discussed with the client. This case summary is for internal
use only4 and provides useful documentation for the consul-
tant (or other consultants) that can be used should the client
request another consultation or need followup.
4In some contexts such written documentation may be ill-advised due to
the potential threat of hostile subpoena by lawyers working for the abuser. In
our work, FJC professionals felt this threat was remote since our consultations
take place within a research study that maintains client anonymity.
USENIX Association
28th USENIX Security Symposium    111
4.3 Replicability
An important question for our consultation protocol is how
to ensure a standard of care that can be maintained across
different locations and by different consultants. Many of the
tools we created help by systematizing the assessment and
investigation of tech problems. To complement these, prior
work in disease diagnosis [15], surgery [42], and aviation
[11] suggests that simple checklists are a valuable tool for
systematizing procedures. Checklists help consultants follow
a systematic procedure despite the complexity of many client
cases, from both an emotional and technological standpoint.
We created three checklists: one each for before, during (see
Appendix of full version), and after the consultation.
We also developed a process for training researchers in-
volved in consultations. We wrote a 13-page training manual
that includes a detailed description of our protocol with ex-
ample situations. It also discusses consultant emotional well-
being and safety considerations (e.g., that consultants not give
their full names until after spyware scans are complete). Train-
ing included reading and understanding this manual, along
with guided introductions to our instruments, including ISDi.
To gain experience in face-to-face consultations before
interacting with clients, we performed mock consultations in
which researchers role-play as clients (including setting up,
beforehand, a realistic scenario possibly involving spyware or
other misconﬁgurations) and others role-play as consultants
(that do not a priori know the scenario). After each mock
consultation, the group analyzes how it went, revealing the
scenario and constructively discussing how to improve. These
are valuable for consultants to gain conﬁdence in their ability
to handle consultations as well as for the research team to
gather feedback on the usability of various instruments.
Although clearly more research can be done to further
reﬁne our instruments, our ﬁeld evaluation, discussed in
Section 6, indicates their immediate practical value. We have
publicly released all training materials, instruments, and open-
source tools as resources that other advocacy organizations
might ﬁnd useful in their work supporting survivors5. We
have already been collaborating with the TECC group in Seat-
tle [2], sharing materials and getting feedback. They have
adopted some TAQ questions for use in their clinical settings,
and we are working towards prototyping ISDi at their clinic.
5 The IPV Spyware Discovery (ISDi) Tool
We now discuss the technical design and testing of ISDi,
our IPV Spyware Discovery tool designed for IPV contexts.
While technologically ISDi currently only uses, relative to
modern anti-virus tools, simpler techniques such as blacklists
and other heuristics, the innovation is in tailoring it to IPV:
(1) ﬂagging apps that in other contexts are not necessarily
5https://www.ipvtechresearch.org/resources
Figure 2: Screen capture of the ISDi tool’s main interface
after scanning an Android testing device.
dangerous and, importantly, (2) mitigating potential discover-
ability by existing IPV spyware. Both issues necessitated a
new tool, as existing ones fail on both accounts.
Regarding (1), in IPV harmful apps may include both spy-
ware and what are called dual-use apps: otherwise legitimate
apps that may be repurposed to act as spyware. We use the
term ‘IPV spyware’ for both types of apps. Prior work showed
how existing tools do not detect dual-use apps [8], whereas
ISDi was designed to ﬂag all spyware apps, including dual-use
apps. Regarding (2), installing an existing anti-virus app is
detected by current spyware, potentially endangering victims,
while ISDi was designed to be more covert.
ISDi is a Python application with a browser-based user
interface (Figure 2) that is used by the consultant to scan a
client’s devices and identify potentially harmful apps. The
tool shows the scan results and serves as a starting point for
discussion with the client about any discovered apps. During
the investigation phase of a consultation, the consultant, with
the client’s permission, helps connect the client’s device via
USB to a laptop running ISDi. A beneﬁt of this design archi-
tecture is that it does not require an app to be installed on the
device, making it minimally invasive and leaving little to no
trace of its execution. We discuss the safety of connecting to
client devices below. Further details about how ISDi works
are provided in Appendix A.
Detectability of ISDi. A key design consideration is that
ISDi does not endanger victims due to being detectable by
abusers. As discussed above, we chose to not make ISDi a
downloadable app since we know some spyware reports any
new apps that are installed. Instead we use the USB interface
to connect the device to a laptop running ISDi.
In theory a sophisticated spyware tool might be able to de-
tect ISDi’s use of USB interfaces on iOS or Android. There-
fore, we conducted additional risk assessments. We installed
six highly capable, overt spyware apps found by Chatterjee
et al. [8] on an iPhone 6 (running iOS 11.4) and also on a
rooted Moto G4 Play phone (running Android 6.0.1). The six
112    28th USENIX Security Symposium
USENIX Association
apps are: mSpy, Cerberus, FlexiSpy, SpyToApp, SpyZie, and
Trackview. We inspected the features and descriptions of the
less sophisticated apps reported on in [8], and decided they
were unlikely to support detection of USB connections.
For each of the six considered spyware apps, we created
an account (simulating the role of an abuser) and manually
investigated capabilities that might allow the app to detect
the scanning process (including those tailored to rooted An-
droid devices). We then simulated normal use of the device
for several minutes (e.g., opening apps, scrolling) and ran
ISDi while network connectivity was enabled. We repeated
this process with network connectivity disabled for the scan
(and then re-enabled), the intuition being that spyware apps
exﬁltrate device activities and data to an external cloud-based
account conﬁgured by the abuser, only some of which may
be monitored in real time. We examined the information that
the abuser obtains in both cases, and found that for ﬁve of the
apps there was no way to infer that ISDi was used.
The remaining app, Cerberus, allows exﬁltrating system
logs on Android, although this capability must be manually
invoked by the abuser. These system logs include entries
about USB connections to the device and that the device
connected to a power source, but nothing beyond that. A
technically sophisticated abuser aware of our tool and who
carefully analyzed these logs might suspect, but would not
have conclusive evidence, that the device was scanned.
Finally, spyware might reveal that the client came to an FJC,
and there have been reports of abusers physically confronting
victims at FJCs or shelters [20]. However, our consultations
and ISDi do not exacerbate this risk given that our clients
already visit FJCs for other reasons.
Data collection. Although it is possible to use ISDi with-
out collecting any data, for research and safety reasons we
choose to store some information, including the list of apps
on a device. Importantly, we do not collect any personally
identiﬁable information or content, such as phone number,
emails, photos, etc. See Appendix A for more details.
6 Field Study
After developing and reﬁning our consultation protocol and
instruments, we performed a six-month ﬁeld evaluation with
IPV survivors. The study was conducted in collaboration with
the ENDGBV, who helped recruit participants, provided safe
space for consultations, and ensured the availability of IPV
professionals to help with safety planning. Before beginning
our study we obtained ethics approval for all procedures from
our university’s IRB and from the ENDGBV.
Recruitment. We distributed ﬂiers to all ﬁve FJC locations
(one in each borough of NYC). These ﬂiers advertised the
study as a way for clients to obtain a tech safety and privacy
consultation, making both clients and professionals aware
of the opportunity. Interested clients were asked to speak
with their case manager who, after consulting with the client,
created a referral and an appointment with our team. Con-
sultations were typically scheduled for days when our team
arranged to be at the FJC, with a minimum of one and a max-
imum of four consultations on a single day. At the suggestion
of ENDGBV staff, we gave participants $10 compensation to
cover the cost of transportation to/from the FJCs.
Procedure. Consultations took place in a private room at one
of the FJCs. Each consultation was done by a team of two
or three researchers: one person focused on communication
with the client, another on the technical parts of the consulta-
tion (ISDi scan, manual privacy checks), and a third (when
available) to take notes. Consultations were done individually.
Clients scheduled for a consultation were advised to bring
any digital devices that they used or that they wished to have
checked. However, two participants did not bring all their
devices to their ﬁrst consultation and therefore made an ap-
pointment to return so as to have additional devices checked.
Thus, two clients participated in two consultations.
Consultations lasted between 30 minutes and two hours.
We began by introducing the team members to the client,
explaining the purpose of the study, outlining the activities
that would be performed, and discussing the data that would
be collected about them and from their devices. We then ob-