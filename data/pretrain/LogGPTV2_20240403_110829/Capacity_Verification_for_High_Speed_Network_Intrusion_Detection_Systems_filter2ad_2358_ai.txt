k0α + N
C
if element i was observed and
P (X = i) =
L − k0 (1 − C)
1
(1)
(2)
if element i was not previously observed. α is a prior count for each element, Ni
is the number of times i was observed, N is the total number of observations,
k0 is the number of diﬀerent elements observed, and L is the total number of
possible elements or the alphabet size. The scaling factor C takes into account
how likely it is to observe a previously observed element versus an unobserved
element. C is computed by
(cid:1)
L(cid:2)
k=k0
C =
k0α + N
kα + N
mk
(cid:3)
(cid:2)
mk
k≥k0
−1
(3)
k!
Γ (kα)
where mk = P (S = k)
Γ (kα+N) and P (S = k) is a prior probability
associated with the size of the subset of elements in the alphabet that have
nonzero probability. Although the computation of C is expensive, it only needs
to be done once for each consistency check at the end of training.
(k−k0)!
The prediction of the probability estimator is derived using a mixture of
Dirichlet estimators each of which represent a diﬀerent subset of elements that
have non-zero probability. Details of the probability estimator and its derivation
are given in [16] and complete details of the anomaly detection algorithm are
given in [14].
Note that this algorithm labels every registry access as either normal or
anomalous. Programs can have anywhere from just a few registry accesses to
several thousand. This means that many attacks will be represented by large
numbers of records where many of those records will be considered anomalous.
Some records are anomalous because they have a value for a feature that is
inconsistent with the normal data. However, some records are anomalous because
they have an inconsistent combination of features although each feature itself
may be normal. Because of this, we examine pairs of features. For example,
let us consider the registry access displayed in Table 1. The basic features for
the normal program aim.exe versus the malicious program aimrecover.exe do
not appear anomalous. However, the fact that the program aimrecover.exe is
accessing a key that is usually associated with aim.exe is in fact an anomaly.
Only by examining the combination of the two raw features can we detect this
anomaly.
Detecting Malicious Software
45
4 Architecture
The basic architecture of the RAD system consists of three components, the
registry auditing module (RegBAM), the model generator, and the real-time
anomaly detector. An overview of the RAD architecture is shown in Figure 1.
Fig. 1. The RAD System Architecture. RegBAM outputs to the data warehouse during
training model and to the anomaly detector during detection mode.
4.1 Registry Basic Auditing Module
The RAD sensor is composed of a Basic Auditing Module (BAM) for the RAD
system which monitors accesses to the registry. BAMs implement an architecture
and interface for sensors across the system. They include a hook into the audit
stream (in this case the registry) and various communication and data-buﬀering
components. BAMs use an XML data representation similar to the IDMEF
standard (of the IETF) for IDS systems [19]. BAMs are described in more detail
in [18].
The Registry BAM (RegBAM) runs in the background on a Windows ma-
chine as it gathers information on registry reads and writes. RegBAM uses Win32
hooks to tap into the registry and log all reads and writes to the registry. Reg-
BAM is akin to a wrapper and uses a similar architecture to that of SysInternal’s
Regmon [27]. After gathering the registry data, RegBAM can be conﬁgured for
two distinct purposes. One use is as the audit data source for model generation.
46
F. Apap et al.
When RegBAM is used as the data source, the output data is sent to a database
where it is stored and later used by the model generator described in Section 4.2
[18]. The second use of RegBAM, is as the data source for the real-time anomaly
detector described in Section 4.3. While in this mode, the output of RegBAM
is sent directly to the anomaly detector where it is processed in real time. An
alternative method to collect the registry accesses is to use the Windows audit-
ing mechanism. All registry accesses can be logged in the Windows Event Log.
Each read or write can generate multiple records in the Event Log. However, this
method is problematic because the event logs are not designed to handle such a
large amount of data. Simple tests demonstrated that by turning on all registry
auditing the Windows Event Logger caused a major resource drain on the host
machine, and in many cases caused the machine to crash. The RegBAM appli-
cation provides an eﬃcient method for monitoring all registry activity, with far
less overhead than the native tools provided by the Windows operating system.
4.2 Model Generation Infrastructure
Similar to the Adaptive Model Generation (AMG) architecture [18], the system
uses RegBAM to collect registry access records. Using this database of collected
records from a training run, the model generator then creates a model of normal
usage.
The model generator uses the algorithm discussed in Section 3 to build a
model that represents normal usage. It utilizes the data stored in the database
which was generated by RegBAM during training. The model itself is comprised
and stored as serialized Java objects. This allows for a single model to be gener-
ated and to be easily distributed to additional machines. Having the model easily
deployed to new machines is a desirable feature, since in a typical network, many
Windows machines have similar usage patterns. This allows the same model to
be used for multiple host machines.
4.3 Real-Time Anomaly Detector
For real time detection, RegBAM feeds live data for analysis by an anomaly
detector. The anomaly detector will load the normal usage model created by
the model generator and begin reading each record from the output data stream
of RegBAM. The algorithm discussed in Section 3 is then applied against each
record of registry activity. The score generated by the anomaly detection algo-
rithm is compared by a user conﬁgurable threshold to determine if the record
should be considered anomalous. A list of anomalous registry accesses are stored
and displayed as part of the detector. A user conﬁgured threshold allows the
user to customize the alarm rate for the particular environment. Lowering the
threshold, will result in more alarms being issued. Although this can raise the
false positive rate, it can also increase the chance of detecting new attacks.
Detecting Malicious Software
47
4.4 Eﬃciency Considerations
In order for a system to detect anomalies in a real time environment it can
not consume excessive system resources. This is especially important in registry
attack detection because of the heavy amount of traﬃc that generated by appli-
cations interacting with the registry. While the amount of traﬃc can vary greatly
from system to system, in our experimental setting (described below) the traﬃc
load was about 50,000 records per hour. Our distributed architecture is designed
to minimize the resources used by the host machine. It is possible to spread the
work load on to several separate machines, so that the only application running
on the host machine is the lightweight RegBAM. However this will increase net-
work load due to the communication between components. These two concerns
can be used to conﬁgure the system to create the proper proportion between host
system load and network load. The RegBAM module is a far more eﬃcient way
of gathering data about registry activity than full auditing with the Windows
Event Log.
5 Evaluation and Results
The system was evaluated by measuring the detection performance over a set
of collected data which contains some attacks. Since there are no other existing
publicly available detection systems that operate on Windows registry data we
were unable to compare our performance to other systems directly.
5.1 Data Generation
In order to evaluate the RAD system, we gathered data by running a registry
sensor on a host machine. Since there are no publicly available data sets contain-
ing registry accesses, we collected our own data. Beyond the normal execution
of standard programs, such as Microsoft Word, Internet Explorer, and Winzip,
the training also included performing housekeeping tasks such as emptying the
Recycling Bin and using the Control Panel. All simulations were done by hand
to simulate a real user. All data used for this experiment is publicly available
online in text format at http://www.cs.columbia.edu/ids/rad. The data in-
cludes a time stamp and frequency of the launched programs in relation to each
other.
The training data collected for our experiment was collected on Windows NT
4.0 over two days of normal usage (in our lab). We informally de.ne “normal”
usage to mean what we believe to be typical use of a Windows platform in a
home setting. For example, we assume all users would log in, check some internet
sites, read some mail, use word processing, then log oﬀ. This type of session is
assumed to be relatively “typical” of many computer users. Normal programs
are those which are bundled with the operating systems, or are in use by most
Windows users. Creating realistic testing environments is a very hard task and
testing the system under a variety of environments is a direction for future work.
48
F. Apap et al.
The simulated home use of Windows generated a clean (attack-free) dataset
of approximately 500,000 records. The system was then tested on a full day of test
data with embedded attacks executed. This data was comprised of approximately
300,000 records most of which were normal program executions interspersed with
attacks. The normal programs run between attacks were intended to simulate an
ordinary Windows session. The programs used were Microsoft Word, Outlook
Express, Internet Explorer, Netscape, AOL Instant Messenger, and others.
The attacks run include publicly available attacks such as aimrecover,
browslist, bok2ss
(back oriﬁce), install.exe xtxp.exe both for back-
door.XTCP, l0phtcrack, runattack, whackmole, and setuptrojan. Attacks were
only run during the one day of testing throughout the day. Among the twelve
attacks that were run, four instances were repetitions of the same attack. Since
some attacks generated multiple processes there are a total of seventeen distinct
processes for each attack. All of the processes (either attack or normal) as well
as the number of registry access records in the test data is shown in Table 3.
The reason for running some of the attacks twice, was to test the eﬀectiveness
of our system. Many programs act diﬀerently when executed a second time within
a windows session. In the experiments reported below our system was less likely
to detect a previously successful attack on the second execution of that attack.
The reason is that a successful attack creates permanent changes to the registry
and hence on subsequent queries the attack no longer appears irregular. Thus
the next time the same attack is launched it is more diﬃcult to detect since it
interacts less with the registry.
We observed that this is common for both malicious and regular applications
since many applications will do a much larger amount of registry writing during
installation or when ﬁrst executed.
5.2 Experiments
The training and testing environments were set up to replicate a simple yet real-
istic model of usage of Windows systems. The system load and the applications
that were run were meant to resemble what one may deem typical in normal
private settings.
We trained the anomaly detection algorithm presented in Section 3 over the
normal data and evaluated each record in the testing set. We evaluate our system
by computing two statistics. We compute the detection rate and the false positive
rate.
The normal way to evaluate the performance of RAD would be to measure
detection performance over processes labeled as either normal or malicious. How-
ever, with only seventeen malicious processes at our disposal in our test set, it is
diﬃcult to obtain a robust evaluation for the system. We do discuss the perfor-
mance of the system in terms of correctly classiﬁed processes, but also measure
the performance in terms of the numbers of records correctly and incorrectly
classiﬁed. Future work on RAD will focus on testing over long periods of time to
measure signiﬁcantly more data and process classiﬁcations as well as alternative
means of alarming on processes. (For example, a process may be declared an
Detecting Malicious Software
49
attack on the basis of one anomalous record it generates, or perhaps on some
number of anomalous records.) There is also an interesting issue to be investi-
gated regarding the decay of the anomaly models that may be exhibited over
time, perhaps requiring regenerating a new model.
The detection rate reported below is the percentage of records generated by
the malicious programs which are labeled correctly as anomalous by the model.
The false positive rate is the percentage of normal records which are mislabeled
anomalous. Each attack or normal process has many records associated with it.
Therefore, it is possible that some records generated by a malicious program will
be mislabeled even when some of the records generated by the attack are accu-
rately detected. This will occur in the event that some of the records associated
with one attack are labeled normal. Each record is given an anomaly score, S,
that is compared to a user deﬁned threshold. If the score is greater than the
threshold, then that particular record is considered malicious. Fig. 2 shows how
varying the threshold aﬀects the output of the detector. The actual recorded
scores plotted in the Figure are displayed in Table 2.
Table 2. Varying the threshold score and its eﬀect on False Positive Rate and Detection
Rate.
Table 3 is sorted in order to show the results for classifying processes. From
the table we can see if the threshold is set at 8.497072, we would label the
processes LOADWC.EXE and ipccrack.exe as malicious and would detect the
Back Oriﬁce and IPCrack attacks. Since none of the normal processes have
scores that high, we would have no false positives. If we lower the threshold to
6.444089, we would have detected several more processes from Back Oriﬁce and
the BrowseList, BackDoor.xtcp, SetupTrojan and AimRecover attacks. However,
50
F. Apap et al.
at this level of threshold, the following processes would be labeled as false pos-
itives: systray.exe, CSRSS.EXE, SPOOLSS.EXE, ttssh.exe, and winmine.exe.
As we have mentioned, our future work on RAD will model and measure a Win-
dows system for a far longer period of time over many more processes in order
to generate a meaningful ROC curve in terms of processes. The measurements
reported next are cast in terms of registry query records.
By varying the threshold for the inconsistency scores on records, we were able
to demonstrate the variability of the the detection rate and false positive rate.
We plot the false positive rate versus the detection rate in an ROC (Receiver
Operator Characteristic) curve shown in Figure 2 and Table 2.
Many of the false positives were from processes that were simply not run
as a part of the training data but were otherwise normal Windows programs. A
thorough analysis of what kinds of processes generate false positives is a direction
for future work.
Part of the reason why the system is successfully able to discriminate between
malicious and normal records is that accesses to the Windows Registry are very
regular, which makes normal registry activity relatively easy to model.
Fig. 2. Figure showing varying the threshold on the data set.
Detecting Malicious Software
51
Table 3. Information about all processes in testing data including the number of
registry accesses and the maximum and minimum score for each record as well as the
classiﬁcation. The top part of the table shows this information for all of the attack
processes and the bottom part of the table shows this information for the normal
processes. The reference number (by the attack processes) give the source for the
attack. Processes that have the same reference number are part of the same attack.
[1] AIMCrack. [2] Back Oriﬁce. [3] Backdoor.xtcp. [4] Browse List. [5] Happy 99. [6]
IPCrack. [7] L0pht Crack. [8] Setup Trojan.
52
F. Apap et al.
6 Conclusions
By using registry activity on a Windows system, we were able to label all pro-
cesses as either attacks or normal, with relatively high accuracy and low false
positive rate, for the experiments performed in this study. We have shown that
registry activity is regular, and described ways in which attacks would generate
anomalies in the registry. Thus, an anomaly detector for registry data may be
an eﬀective intrusion detection system augmenting other host-based detection
systems. It would also improve protection of systems in cases of new attacks that
would otherwise pass by scanners that have not been updated on a timely basis.
We plan on testing the system under a variety of environments and condi-
tions to better understand its performance. Future plans include combining the
RAD system with another detector that evaluates Windows Event Log data.
This will allow for various data correlation algorithms to be used to make more
accurate system behavior models which we believe will provide a more accurate
anomaly detection system with better coverage of attack detection. Part of our
future plans for the RAD system include adding data clustering and aggregation
capabilities. Aggregating alarms will allow for subsets of registry activity records
to be considered malicious as a group initiated from one attack rather than indi-
vidual attacks. We also plan to store the system registry behavior model as part
of the registry itself. The motivation behind this, is to use the anomaly detec-
tor to protect the system behavior model from being maliciously altered, hence
making the model itself secured against attack. These additions to the RAD
system will make the system a more complete and eﬀective tool for detecting
malicious behavior on the Windows platform.
References