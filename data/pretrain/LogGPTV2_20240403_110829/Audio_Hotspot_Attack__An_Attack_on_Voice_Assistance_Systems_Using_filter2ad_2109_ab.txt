### Attacker Requirements and Techniques

An attacker must pre-record speech, including voice commands for both activation and recognition. However, techniques such as speech synthesis and voice conversion can alleviate this limitation. **Speech synthesis** (Text-to-Speech, TTS) is a method to generate natural-sounding speech from text. One example is **WaveNet [17]**, which uses deep learning models to create synthesized voices. **Voice conversion** aims to transform an attacker's voice into the victim's voice in real-time, without the need for prepared text. These techniques enable the generation of synthetic speech that is perceived as being spoken by the target. In [15], the author demonstrated that an attacker can successfully execute a voice impersonation attack using off-the-shelf voice conversion tools, even against state-of-the-art voice verification systems. The study revealed that an attacker can convert their voice with just a few minutes of audio.

While these techniques aim to impersonate the victim's voice, our focus is on a different attack vector: secretly delivering the voice signal to the target voice assistant device. Since our attack is agnostic to the voice content, voice presentation attack techniques can be directly applied to our attack.

### Threat Model and Assumptions

In this section, we describe the Audio Hotspot Attack threat model, making several assumptions to evaluate the threat.

#### Target of the Attack

The attacker's goal is to manipulate the target voice assistance device without being noticed by people. Although the attack can be applied to various voice assistance systems, a smart speaker is used as an example. Smart speakers can control smart home devices, making the attack vector widespread. We evaluated the attack using two smart speakers: Amazon Echo and Google Home. For these devices, the attacker must first activate the device with a wake-up word and then transmit a voice command. We assume the target device is stationary (e.g., placed on a table), which is a reasonable assumption for smart speakers.

#### Attacker’s Equipment

As shown in Figure 1, the Audio Hotspot Attack has two modes: linear attack and cross attack. For the linear attack, the attacker needs to set up a parametric loudspeaker, and for the cross attack, two parametric loudspeakers are required. The parametric loudspeaker is small and portable. The attacker also needs a smartphone to generate malicious voice commands. Figure 4 shows an example of the device setup used by the attacker.

#### Speaker Recognition

Modern devices equipped with voice assistance systems, such as smartphones or smart speakers, increasingly adopt speaker recognition functionality. If this feature is enabled, an attacker may not succeed even if they transmit an inaudible voice command. The attacker can collect voice samples by being in close physical proximity to the target, making a phone call, or searching for clips online. For this work, we assumed the attacker could bypass speaker recognition using voice presentation attacks, as discussed in Section 2.3. As shown in Section 7.2.3, there are methods to detect presentation attacks (PAD methods). We assume the voice assistance systems do not have PAD methods. We confirmed that presentation attacks are successful on practical devices, i.e., Google Home and Amazon Echo, before the experiments.

### Experimental Setup

In this section, we describe the design of our experiments, including details about the devices, equipment, and software used, along with their settings.

#### Materials

##### Experiment Room

Sound wave dynamics depend on the room's material makeup. To ensure the results are valid across environments, we used a room designed for acoustic experimentation, with all wall and ceiling surfaces made of sound-absorbing material (Appendix B, Figure 2). The average sound pressure level (SPL) of the room was around 12 dB(A), where dB(A) denotes A-weighted SPL, which accounts for the human ear's sensitivity to different frequencies.

##### Target Devices

We used Google Home and Amazon Alexa as primary target devices, as they accounted for more than 95% of the smart speaker market share in 2018 [18].

##### Equipment Used for the Experiments

Table 1 lists the equipment used. We adopted the Switch Science Super directional speaker [19] as the primary parametric loudspeaker. The kit includes two printed circuit boards (PCBs): one with an AM circuit, amplifier, audio input, and power input, and another with 49 ultrasonic ceramic transducers. Another parametric loudspeaker, the ACOUSPADE, was used to study the maximum attack distance. The sound level meter measures SPL from 28 to 138 dB(A) for a frequency range of 20 Hz to 20 kHz. The ultrasonic microphone was used to measure the ultrasonic components in the sound waves.

| Equipment | Manufacturer / Model Number |
| --- | --- |
| Parametric Loudspeaker | Switch Science / SSCI-018425 [19] |
| Amplifier | Accuphase / Power Amplifier PRO-15 [20] |
| Dynamic Loudspeaker | YAMAHA / MONITOR SPEAKER MS101 III [22] |
| Sound Level Meter | RION / NL-32 [23] |
| Ultrasonic Microphone | B&K / 4939-A-011 [24] |
| Audio Interface | MOTU / UltraLite mk4 [25] |

#### Voice Generation

To generate malicious voice commands, we used Amazon Polly [26], a cloud service that converts text into natural-sounding speech. The voice named "Ivy" (a female, US English accent) was used, with default voice parameters. All voice assistance systems were tested to check if they accept synthesized voice commands. We plan to make our data available for researchers who wish to replicate or extend our work.

### Evaluation of the Attack

We evaluated the attack feasibility based on maximum successful attack distance, noise tolerance, and the impact of voice commands. For simplicity, we applied a linear attack and used the parameters obtained to evaluate the cross attack. The attack success depends on the type of voice command (activation or recognition). Activation commands are more likely to succeed.

#### Distance versus Attack Success Rate

We aimed to clarify how the distance between the target device and the adversary's parametric loudspeaker affects the attack success rate. The SPL of the output power from the parametric loudspeaker was fixed at 60 dB(A) for audible sound and 100 dB for ultrasound at 3 m. Figure 6 shows the experimental setup. The distance measured was between the parametric loudspeaker and the microphone of the voice assistance systems.

##### Measurement within the Experiment Room

The distance between the target device and the parametric loudspeaker was varied from 0.1 m to 5 m in 50 cm increments. The SPL of the noise in the room was adjusted to 60 dB(A) with error bounds within 1 dB(A). This setting was chosen to conservatively evaluate the attack success rate. For each distance, a pair of activation and recognition voice commands was generated 25 times. The results are shown in Figure 7. The attack was highly successful for both devices, particularly for Google Home, with the longest distance being 3.5 m. Activation commands were more likely to be accepted than recognition commands. Google Home had a higher attack success rate than Amazon Echo, possibly due to differences in their circuits and software.

##### Extended Measurement in Practical Environments

We studied the distances of successful attacks in a hallway, seminar room, and outside. The hallway and room had higher reverberation compared to the experiment room. We used a commercial parametric loudspeaker [21] that emits full-frequency-range speech with an audible SPL of 62–63 dB(A) at 3 m. The average SPL in the hallway was 39.3 dB(A), in the seminar room was 55.2 dB(A), and outside was 52.5 dB(A). The attack was effective at 10+ m in the hallway, 4+ m in the seminar room, and 4+ m outside. These results indicate that the Audio Hotspot Attack is feasible in real-world scenarios and achieves longer distances than state-of-the-art inaudible voice command attacks.

#### Noise Tolerance

We studied how noise affects the attack success rate. The sound generated by the parametric loudspeaker was fixed at 60 dB(A), and the distance was 1.5 m. Using the dynamic speaker, we generated 1/f noise with an adjustable SPL to evaluate the attack's noise tolerance.