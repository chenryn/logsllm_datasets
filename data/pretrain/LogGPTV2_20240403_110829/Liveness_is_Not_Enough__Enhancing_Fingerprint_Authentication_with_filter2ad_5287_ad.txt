0.9656
0.9767
0.9915
0.9871
0.9532
0.9974
0.9789
0.9888
0.9806
0.9975
0.9938
Table 6: Mean BAC (%), FAR (%), FRR (%), and AUC with
non-overlapping subjects in training base CNN and testing.
Feature Set + Classiﬁer
CNF + LOF
UnF + LOF
BAC
95.34
95.59
FAR
4.20
3.35
FRR
5.10
5.47
AUC
0.9805
0.9867
7.2.2 Performance with Non-overlapping Subjects
We also evaluated the performance of FINAUTH when us-
ing non-overlapping subjects in training the base CNN and
evaluating the authentication models. We split these 90 sub-
jects into two groups randomly and evenly. One was used to
train the base CNN as the feature extractor, and the other was
used to evaluate the performance of authentication models.
5-fold cross-validation was used in the testing phase. We used
CNF + LOF and UnF + LOF on the sitting data points in
dataset-1.
Table 6 shows the BAC, FAR, FRR, and AUC with non-
overlapping subjects in training base CNN and testing. The
mean BACs under CNF + LOF and UnF + LOF are 95.34%
(compared with 97.99% in Table 5) and 95.59% (compared
to 98.02%).
7.2.3
Impact of Different Postures
To ﬁnd out how postures and moving affect the performance
of FINAUTH, we used all of the 63,000 data points of dataset-
1. For each user and each posture, we train a classiﬁer using
30 data points in the training dataset. Speciﬁcally, for each
participant, the authentication model was trained with regard
to ﬁve different postures respectively. Next, the model was
leveraged to evaluate the performance of different postures.
Figure 7 shows the BAC when using data points collected
in different postures to train authentication models (x-axis)
and evaluate performance (y-axis). The results indicate that
FINAUTH achieves better performance in stationary postures
(e.g., sitting, standing, and lying) than moving (e.g., walking
and running). Authentication models trained in stationary pos-
2226    29th USENIX Security Symposium
USENIX Association
(a) Time- and frequency-domain features
(b) CNN-based features
(c) The union of two feature sets
Figure 5: ROC curves of different feature sets under different one-class classiﬁers.
(a) Time- and frequency-domain features
(b) CNN-based features
(c) The union of two feature sets
Figure 6: BAC under different classiﬁers and different feature sets at varying training set sizes.
tures can be transferred to other stationary postures without
downgrading obviously. If we ignore ‘running’, which is rare
in real-life, FINAUTH achieves over 94% BAC when proﬁling
a user with 30 data points collected while sitting.
7.2.4 Impact of Training Dataset Sizes
To investigate the impact of training set sizes, we changed the
training set size from 5 to 100 in a step of 5 or 10 to proﬁle
the legitimate users. Figure 6 shows the BAC for different
classiﬁers with different training set sizes. As expected, the
results show that training with more data achieves a higher
BAC. Using CNN-based features or the union of two feature
sets, LOF outperforms the other three classiﬁers. With only 5
training data points and CNN-based features, LOF achieves
the BAC of 96.04%, where its FAR is 1.12% and FRR is
6.80%. With 100 training data points, LOF achieves the BAC
of 99.28%, where its FAR and FRR are 0.045% and 1.39%
respectively.
7.2.5 Consistency Over Time
To ﬁnd out how consistent users’ ﬁngerprint behaviors are
over a long period, we used dataset-2 and the 45,000 sitting
data points of dataset-1. The training data points were se-
lected from dataset-1 (the ﬁrst week of data collection), and
test data points were from dataset-2.
Figure 7: BAC of FINAUTH under different postures.
Figure 8 shows the mean BAC, FAR, and FRR over dif-
ferent weeks with regard to dataset-2A and dataset-2B. As
the results show, behavior variability has an impact on the
usability of FINAUTH, but little impact on security. In particu-
lar, as shown in Figure 8(a), the BAC decreases from 96.34%
to 90.13% under dataset-2A, where its FRR increases from
6.20% to 15.46% in 7 weeks. While in Figure 8(b), the BAC
decreases from 96.19% to 93.96% under dataset-2B, where
its FRR increases from 6.50% to 9.69% in 5 weeks. The
FAR is almost stable in dataset-2A&B. This demonstrates
that FINAUTH is resilient against behavioral variability in a
short period. In particular, we assume that, in real applica-
tions, the problem of behavioral variability can be tackled by
USENIX Association
29th USENIX Security Symposium    2227
Table 8: Mean/standard deviation of FAR (%) and prediction
score under three types of attacks when tested using models
trained with 100 legitimate data points to proﬁle users.
Type
FAR
Score
Artiﬁcial Replica Attack
0.08/0.06
−0.29/0.15
Puppet Attack Mimicry Attack
0.25/0.14
−0.37/0.10
0.12/0.08
−0.62/0.13
‘
7.3 Evaluation of Presentation Attacks
To investigate the defense against presentation attacks, we
utilize dataset-4. We report the FAR under CNF + LOF at
varying training dataset sizes.
Figure 9(a) shows FAR under artiﬁcial replica attack using
dataset-4A with varying training dataset size. The overall
BAC is less than 3%. Speciﬁcally, the FAR is 2.01% when
the model is trained with 10 data points, and it improves to
0.08% using 100 data points.
Figure 9(b) shows the FAR under puppet attack using
dataset-4B with varying training dataset size. The results in-
dicate that FINAUTH resists against puppet attack with mean
FAR below 2%. Speciﬁcally, the mean FAR is 1.93% under
the model trained with only 5 data points, and it is enhanced
to 0.12% under the model trained using 100 data points.
Figure 9(c) shows the FAR under mimicry attack using
dataset-4C. The results show that it is very difﬁcult for attack-
ers to mimic the ﬁngertip-touch behavior of users. The attack
success rate is 3.10% under models trained with 5 data points,
and it improves to 0.25% with 100 data points.
As the results show, FINAUTH is effective in defeating all
three kinds of presentation attacks. Using more legitimate data
points to train the authentication model can strengthen the
defense against various attacks. FAR, and prediction scores
under authentication models trained using 100 data points
are shown in Table 8. In particular, for prediction scores of
all attack data points, the distribution and its kernel density
evaluated under Gaussian kernel are shown in Figure 10.
7.4 System Performance
We analyzed the system performance of FINAUTH on One-
plus 3, Redmi Note 4X, Xperia XZ1, and Vivo X21. On each
device, we performed authentication with the prototype for
50 times to evaluate the authentication delay, memory usage,
and power consumption.
Authentication Delay. The delay is deﬁned as the interval
between the time when the authentication system detects the
ﬁngerprint authentication event to the time when the system
generates the result. It consists of the time for data collection,
data processing, and classiﬁcation. Table 9 shows the delay
of four smartphones. The average delay is 713.34 ms, 722.93
ms, 630.72 ms, and 692.15 ms of our method under the four
smartphones respectively. Figure 11 shows cumulative dis-
(a) Dataset-2A
(b) Dataset-2B
Figure 8: BAC of FINAUTH evaluated in different weeks
using two datasets with different intervals.
Table 7: Mean/standard deviation of BAC (%), FAR (%),
and FRR (%), tested on four smartphones (RAM/Snapdragon
CPU) with the training set size as 30.
Device
Mean/Std BAC
FAR
FRR
Oneplus3 (6G/ 820)
Oneplus5 (6G/ 835)
XperiaXZ1 (4G/ 835)
VivoX21 (6G/ 660AIE)
97.99/0.37
98.41/0.56
96.83/0.52
98.64/0.18
0.87/0.07
0.27/0.04
1.69/0.11
0.58/0.05
3.16/0.74
2.91/1.13
4.65/0.99
2.13/0.36
retraining the authentication model with newly collected data,
namely model updating mechanism, which was adapted in
Face ID [3].
7.2.6
Impact of Different Devices
To ﬁnd out how the ﬁngertip-touch data on different devices
would affect the robustness of FINAUTH, we evaluated with
the 45,000 sitting data points of dataset-1 and dataset-3. As
shown in Table 7, the BAC on Oneplus3, Oneplus5, Xpe-
ria XZ1, and Vivo X21 are 97.99%, 98.41%, 96.83%, and
98.64%, respectively. There exist variances among different
devices in terms of BAC. It achieves the best performance
with a BAC of 98.64%, where its FAR and FRR are 0.58%
and 2.13% respectively. The worst result on Xperia XZ1
achieves the BAC of 96.86%, where its FAR and FRR is
1.69% and 4.65% respectively.
2228    29th USENIX Security Symposium
USENIX Association
(a) Artiﬁcial replica attack
(b) Puppet attack
(c) Mimicry attack
Figure 9: The FAR, i.e., attack success rate, under the authentication trained with different training set sizes.
(a) Artiﬁcial replica attack
(b) Puppet attack
(c) Mimicry attack
Figure 10: The kernel density of attack data points’ prediction score under authentication models trained with 100 data points.
tribution function (CDF) of delay on different smartphones
with and without FINAUTH. For 90% attempts, the delay of
FINAUTH is less than 742.39 ms, 749.83 ms, 643.26 ms, and
714.54 ms for Oneplus 3, Redmi Note 4X, Xperia XZ1, and
Vivo X21, respectively. Overall, FINAUTH only requires an
average delay of 689.79 ms. In addition, the delay of our
method is lower than existing methods on smartphones, such
as PINs, pattern lock, and facial authentication. This implies
that FINAUTH can authenticate users timely.
Memory Usage. We used Trepn Proﬁler 1 and Android
Studio Proﬁler 2 to monitor the memory usage of FINAUTH.
Table 9 shows the memory usage of FINAUTH without con-
sideration of graphics on four smartphones. Speciﬁcally, the
memory usages on four different smartphones are 62.99 MB,
57.82 MB, 48.77 MB, 81.19 MB. The average memory usage
is 62.69 MB, which incurs additional 14.92 MB compared
with the original ﬁngerprint authentication.
Power Consumption. Trepn Proﬁler was employed to pro-
vide mW -level power consumption estimation. Power con-
sumption is measured by subtracting screen power consump-
tion while the screen is on. The average power consumption
overhead is 23.13 mW , which incurs additional 6.90 mW com-
1https://developer.samsung.com/game/trepn
2https://developer.android.com/studio/profile/cpu-
profiler
pared with original ﬁngerprint authentication (Table 9).
To sum up, FINAUTH achieves a low authentication de-
lay of 689.79 ms on commercial smartphones. It requires a
memory usage of 62.69 MB and power consumption of 23.13
mW . Compared with the original ﬁngerprint authentication, it
introduces very little overhead and short delay.
7.5 Other Design Considerations
To verify if our feature extraction is effective, we also at-
tempted to construct another CNN-based feature extractor to
extract features from denoised sensor data directly without
characterizing ﬁngertip-touch behavior. We employed a simi-
lar model structure as shown in Table 2 and pre-trained the
model with power spectral matrices of denoised sensor data
as input to distinguish different users. Then, we implemented
end-to-end feature learning by inputting power spectral matri-
ces of denoised sensor data to the model to extract features.
Figure 12(a) shows ROC curves when implementing end-
to-end feature learning with CNN. Its best BAC is 61.10%
with the training set size as 500. While under our designed
ﬁngertip-touch behavior characterizing method (Section 3.2),
the BAC reaches 93.11% with only 50 training data points
to proﬁling the legitimate user. As the results show, the step
of ﬁngertip-touch behavior characterizing signiﬁcantly elimi-
USENIX Association
29th USENIX Security Symposium    2229
Table 9: Mean authentication delay (ms), memory usage (MB), and battery power consumption (mW ) of FINAUTH on four
different devices (CPU clock rate, GHz).
Device
Oneplus 3 (2.15)
Redmi Note 4X (2.0)
Xperia XZ1 (2.45)
Vivo X21 (2.2)
With FINAUTH
Delay Memory
62.99
713.34
81.19
722.93
630.72
48.77
57.82
692.15
Power
19.35
28.41
18.44
26.32
Without FINAUTH
Delay Memory
47.82
257.36
43.56
342.83
293.14
36.75
62.94
271.16
Power
12.67
19.25
9.83
23.18
Note that, the authentication delays for PIN, pattern lock, facial authentication are 1.25 [81], 3.14 [81], and 1.48 seconds [6].
(a) Original ﬁngerprint authentication
(cid:48)(cid:79)(cid:70)(cid:49)(cid:77)(cid:86)(cid:84)(cid:1)(cid:20)
(cid:51)(cid:70)(cid:69)(cid:78)(cid:74)(cid:1)(cid:47)(cid:80)(cid:85)(cid:70)(cid:21)(cid:57)
(cid:57)(cid:81)(cid:70)(cid:83)(cid:74)(cid:66)(cid:1)(cid:57)(cid:59)(cid:18)
(cid:55)(cid:74)(cid:87)(cid:80)(cid:1)(cid:57)(cid:19)(cid:18)
(cid:48)(cid:87)(cid:70)(cid:83)(cid:66)(cid:77)(cid:77)
(cid:23)(cid:22)(cid:17)
(cid:24)(cid:17)(cid:17)
(cid:34)(cid:86)(cid:85)(cid:73)(cid:70)(cid:79)(cid:85)(cid:74)(cid:68)(cid:66)(cid:85)(cid:74)(cid:80)(cid:79)(cid:1)(cid:69)(cid:70)(cid:77)(cid:66)(cid:90)(cid:1)(cid:9)(cid:78)(cid:84)(cid:10)
(cid:24)(cid:22)(cid:17)
(cid:25)(cid:17)(cid:17)
(cid:39)
(cid:37)
(cid:36)
(cid:18)(cid:15)(cid:17)
(cid:17)(cid:15)(cid:25)
(cid:17)(cid:15)(cid:23)
(cid:17)(cid:15)(cid:21)
(cid:17)(cid:15)(cid:19)
(cid:17)(cid:15)(cid:17)
(cid:23)(cid:17)(cid:17)
(b) FINAUTH
Figure 11: Authentication delay on different devices
nates relying on deeper models and a larger number of training
data points.
We also evaluated an approach that utilizes a deep learning
classiﬁcation model [23]. We utilized the ALOCC model [60],
which was proposed to combine a generative adversary net-
work and an autoencoder to achieve one-class classiﬁcation.
This model combines these two networks to learn the self-
distribution of the input in the training phase. It determines
whether a data point is an outlier by comparing the distance
between its input and output with a threshold. In our experi-
ments, the input of this model is power spectral matrices of
accelerations and rotation angles.