### Table 2: Latency of User-Level Measurements via Sysfs (File Size: 2 Bytes)

| Case          | Overhead (stdev)   |
|---------------|--------------------|
| no SHA1       | 4.32 µs (0.0)      |
| SHA1          | 7.50 µs (0.0)      |
| SHA1+extend   | 5430 µs (1.6)      |
| sys fs        | 4.32 µs (0.0)      |

**User-Level Measurement Latency Analysis:**

- The user-level measurement latency in the `no_SHA1` case is 4.32 µs. This overhead is primarily attributed to file system operations such as opening, writing, and closing the `/sys/security/measure` file.
- In the `no_SHA1` case, the measurement-related overhead is negligible and is overshadowed by the context switching and file system overhead.
- The other measurement values can be interpreted straightforwardly. For example, the `SHA1` case has an overhead of 7.50 µs, while the `SHA1+extend` case has a significantly higher overhead of 5430 µs.

### Kernel Module Measurement

Kernel modules can be measured in two ways:
1. **User-Level Applications:** Using `insmod` and `modprobe`, which transfer the performance into the domain of user-level measurements with the overheads as described in Table 2.
2. **Kernel Function:** By inducing a measurement routine before relocating the kernel module in the `load_module` function called by the `init_module` system call.

- The latency of measuring kernel modules in the `load_module` kernel function is similar to the latency of measuring executable content in the `file_mmap` LSM measurement hook.
- Since kernel modules are already in memory before they are relocated, there is no dirty flagging information, and only the `SHA1` or `SHA1+extend` cases apply.
- Given that kernel module loading is infrequent and less time-critical, we recommend measuring them in the kernel from a security standpoint (see Section 5.1).

### Fingerprinting Performance as a Function of File Sizes

We measured the `mmap` system call's running time in the `SHA1` case, varying the input file sizes. The results include the reference overhead of 1.65 µs for the pure `mmap` system call (Table 1). The results are summarized in Table 3.

**Table 3: Performance of the SHA1 Fingerprinting Operation as a Function of File Sizes**

| File Size (Bytes) | Overhead (stdev)   |
|-------------------|--------------------|
| 2                 | 4.21 µs (0.0)      |
| 512               | 10.3 µs (0.0)      |
| 1K                | 16.3 µs (0.0)      |
| 16K               | 1550 µs (1.1)      |
| 128K              | 12700 µs (16)      |
| 1M                | 197 µs (0.1)       |

- For large files, the fingerprinting overhead becomes significant. For example, measuring a 128 Kilobyte file takes about 1.5 milliseconds.
- The running time increases almost linearly with the file size, resulting in a throughput performance of approximately 80 MB per second.

### In-Memory Kernel Modules

- Measuring in-memory kernel modules should theoretically yield better throughput than measuring files, which first need to be read from disk into memory.
- However, our measurements showed only slightly better performance than the `file_mmap` case (Table 3). This is likely due to the Linux file caching effect, where the file was already in the cache when the measurement started.
- Therefore, the throughput numbers in Table 1 should be considered optimistic for file measurements.

### Experimental Setup

- These experiments were conducted on an IBM Netvista M desktop workstation with an Intel Pentium 2.4 GHz processor and 1 GB of RAM.
- All non-essential services were stopped during the experiments.

### Implementation and Usability Aspects

- Our kernel implementation includes LSM hooks for measurement, dirty flagging, and bypass protection, totaling 4755 lines of code (including comments).
- The code resides in its own `security/measure` kernel directory, making it easy to port to new Linux kernel versions as long as the LSM interface remains unchanged.
- We added 2 lines of code to the `load_module` routine in `kernel/module.c` to measure loading kernel modules.
- To instrument the bash shell, we inserted 2 lines of code at the points where source files are loaded or script files are interpreted.
- Porting the architecture from a 2.6.2 to a 2.6.5 Linux kernel took about 10 minutes.
- Moving from a non-LSM implementation in a 2.4 kernel to an LSM-based version in the 2.6 kernel reduced complexity and increased portability.

### Stacking with SELinux

- We successfully stacked our integrity measurement architecture as an LSM module on top of SELinux, requiring minor modifications to SELinux to call our hooks and share security substructures.
- A standard RedHat 9.0 Linux system, including the Xwindow server and Gnome Desktop, accumulates about 500-600 measurement entries after running for about one week, including 60-100 bash script and source file measurements.
- The overhead introduced by our measurement architecture is negligible, even at boot time when most measurements are recorded and extended into the TPM.

### Discussion

- Our architecture is non-intrusive and does not prevent systems from running malicious programs. However, it can be modified to enforce security by pre-loading the measurement cache with expected fingerprints for trusted programs.
- If a fingerprint does not match any expected ones, the load is aborted, and the illegal fingerprint is reported.
- Our measurement architecture is not limited to executable code. It can be extended to include structured input data, such as configuration files and Java classes, by adding measurement hooks into applications like Apache or the Java classloader.
- Privacy is impacted by our approach, as the attestation protocol releases detailed information about the system. However, the system has full control over the release of this information and can run trusted code to manage it.
- Frequent changes in loaded executable files can cause the measurement list to grow, potentially leading to a denial of service attack. To mitigate this, a maximum length for the measurement list can be configured.

### Conclusions

- We presented the design and implementation of a secure integrity measurement system for Linux, extending TCG trust concepts from the BIOS to the application layer.
- The system includes hooks to measure when the first code is loaded into a process, provide a `sysfs` entry for subsequent measurements, and detect changes to measured inodes.
- The mechanism enables the measurement of dynamic loaders, shared libraries, and kernel modules, and is extensible to applications.
- Our measurements show that the overhead is reasonable, and the system can detect various integrity issues, such as rootkits or vulnerable software.
- The source code of our integrity measurement architecture will be made publicly available as open-source, and efforts are underway to integrate it into the kernel as an optional LSM module.

### Acknowledgments

- We thank the IBM Linux Technology Center for their support, colleagues from the IBM Tokyo Research Lab, and Ronald Perez, Steve Bade, and anonymous referees for their valuable feedback.

### References

[1] W. A. Arbaugh, D. J. Farber, and J. M. Smith, “A Secure and Reliable Bootstrap Architecture,” in IEEE Computer Society Conference on Security and Privacy. IEEE, 1997, pp. 65–71.

[2] “Trusted Computing Group,” http://www.trustedcomputinggroup.org.

[3] K. J. Biba, “Integrity considerations for secure computer systems,” Tech. Rep. MTR-3153, Mitre Corporation, Mitre Corp, Bedford MA, June 1975.

[4] D. D. Clark and D. R. Wilson, “A comparison of commercial and military computer security policies,” IEEE Symposium on Security and Privacy, 1987.

[5] S. W. Smith, “Outgoing authentication for programmable secure coprocessors,” in ESORICS, 2002, pp. 72–89.

[6] M. Bond, “Attacks on cryptoprocessor transaction sets,” in Proceedings of the 2001 Workshop on Cryptographic Hardware and Embedded Systems, May 2001.

[7] P. England, B. Lampson, J. Manferdelli, M. Peinado, and B. Willman, “A Trusted Open Platform,” IEEE Computer, vol. 36, no. 7, pp. 55–62, 2003.

[8] G. Kim and E. Spafford, “Experience with Tripwire: Using Integrity Checkers for Intrusion Detection,” in System Administration, Networking, and Security Conference III. USENIX, 1994.

[9] D. Engler, B. Chelf, A. Chou, and S. Hallem, “Checking systems rules using system-specific, programmer-written compiler extensions,” in Proceedings of the 4th Symposium on Operating Systems Design and Implementation (OSDI 2000), October 2000.

[10] J. Dyer, M. Lindemann, R. Perez, R. Sailer, L. van Doorn, S. W. Smith, and S. Weingart, “Building the IBM 4758 Secure Coprocessor,” IEEE Computer, vol. 34, no. 10, pp. 57–66, 2001.

[11] Trusted Computing Group, Trusted Platform Module Main Specification, Part 1: Design Principles, Part 2: Commands, Version 1.2, Revision 62, October 2003, http://www.trustedcomputinggroup.org.

[12] H. Maruyama, F. Seliger, N. Nagaratnam, T. Ebringer, S. Munetho, and S. Yoshihama, “Trusted Platform on demand (TPod),” in Technical Report, Submitted for Publication, 2004, In submission.

[13] J. Marchesini, S. Smith, O. Wild, and R. MacDonald, “Experimenting with TCPA/TCG Hardware, Or: How I Learned to Stop Worrying and Love the Bear,” in Technical Report TR2003-476, Dartmouth PKI Lab Dartmouth College, Hanover, New Hampshire, USA, December 2003.

[14] T. Garfinkel, B. Pfaff, J. Chow, M. Rosenblum, and D. Boneh, “Terra: A Virtual Machine-Based Platform for Trusted Computing,” in Proc. 9th ACM Symposium on Operating Systems Principles, 2003, pp. 193–206.

[15] CERT Coordinatin Center, “CERT/CC Advisories,” http://www.cert.org/advisories.

[16] A. B. Brown and M. Seltzer, “Operating System Benchmarking in the Wake of Lmbench: A Case Study of the Performance of NetBSD on the Intel x86 Architecture,” in Proceedings of the 1997 ACM SIGMETRICS Conference on Measurement and Modeling of Computer Systems, June 1997, pp. 214–224.

[17] T. Jaeger et al., “Leveraging information flow for integrity verification,” in SUBMITTED for publication, 2004.