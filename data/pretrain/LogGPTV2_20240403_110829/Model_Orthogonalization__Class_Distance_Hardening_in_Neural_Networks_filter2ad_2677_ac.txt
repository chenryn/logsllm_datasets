m,δ
(1)
formalized as follows.
∀x ∈ X, min
T(x, m, δ) = x′ = (1 − m) · x + m · δ,
(2)
where L(·) is the loss function of model M(·); yt is a target
label different from the ground truth of input x; λ adjusts the
weight of the second objective; T(·) is the transformation that
applies the generated backdoor to an input x; m is a mask
matrix whose values range from 0 to 1; δ is the backdoor,
which has the same shape and value range as input x. A
straightforward way for symmetric hardening is to run some
existing backdoor generation method twice. However, this will,
on one hand, introduce an extra optimization step that doubles
the training cost, and on the other hand, fail
to consider
both directions such that the generated backdoors may be too
aggressive in pushing the boundary, causing oscillation. We
hence devise a two-sided backdoor generation method that
generates two backdoors for a class pair at once. Algorithm 1
illustrates our method. Input parameter X denotes a set of
inputs belonging to class a or b and p is an indicator vector of
these inputs, with 1 denoting class a and 0 class b. We initialize
the backdoor variables with the input values if available or
random values otherwise (lines 2-6). In line 7,
the target
labels are set to the opposite of ground truth labels (of the
class pair). During the optimization, backdoors are stamped
on the samples of the corresponding class (lines 10-11). Line
13 computes the loss for both directions together. This is
the key as the backdoor generation along either direction is
constrained by loss from both directions, avoiding any bias to
one side. Attack success rates are computed for individual
classes (line 14). For each backdoor, we check whether it
reaches the desired attack success rate and also has a smaller
size compared to the previous result. If so, we record the best
results and apply random perturbation (ξ = 0.01) to backdoor
variables to avoid local minima (line 16-20).
C. Pair Scheduling
A na¨ıve method is to train each pair to their maximum
this often leads to substantial
distance in turn. However,
accuracy degradation. Another simple method is to do it
iteratively and randomly by selecting a pair in each iteration.
However, this is suboptimal as well because different pairs
have various capacities. For instance, deer and horse are close
by their nature, spending a lot of optimization cycles on this
pair may not be as productive as spending on deer and bird.
As such, we prioritize the promising pairs using a scheduler.
▷ use all x for simplicity
if minit is not None and δinit is not None then
m, δ ← minit, δinit
m, δ ← random init with twice shape of x ∈ X
n = p ·(cid:0)(1 − m[0]) · Xn + m[0] · δ[0](cid:1)
+(1 − p) ·(cid:0)(1 − m[1]) · Xn + m[1] · δ[1](cid:1)
end if
yt = p · b + (1 − p) · a
for step in 0...max steps do
Xn ← a batch of x ∈ X
X′
y′
n = M (X′
n)
minimize the loss defined in Equation 1
acc = [p· equal(y′
for i in {0, 1} do
n, yt)]
if acc[i] >= asr and ∥m[i]∥1  ϵ
, s < ϵ
, with s ∼ U(0, 1),
(5)
where P is the selected class pair. W is the objective func-
tion for selecting the promising class pair. ϵ determines the
level of randomness. Equipped with this ϵ-greedy method,
even if a globally-promising but not locally-promising pair
is not selected in the early stage, it can still be picked up
in the following iterations with a probability of ϵ. We set
ϵ = 0.3. The objective function W is the combination of
two components: prior-selection matrix U and post-selection
matrix V . The prior-selection matrix U stores the loss changes
in the warp-up phase as discussed earlier. The post-selection
matrix V monitors and records the class distance change for
every pair during training. As shown in Figure 8, some pairs
have a large distance increase within a few iterations and
we aim to prioritize those pairs. As such, we select a class
pair that has the largest increase of class distance between
two iterations. From the figure, observe that the class distance
oscillates during training even for a pair with great potential.
It indicates that only looking at the difference between two
iterations, the scheduler will miss class pairs with potential.
We hence consider an accumulated class distance change with
exponential decay for early changes as follows.
s→t − di−1
s→t
q(cid:88)
vs→t =
)q−i · di
(
1
2
i=1
di−1
s→t
,
(6)
where q is the number of times a pair being selected up to
the current iteration; di
s→t is the L1 norm of the backdoor
mask matrix m from a source class s to a target class t
at iteration i, denoting their distance. We use the sizes of
universal backdoors during warm-up phase as the initial d0
s→t.
Entries in the post-selection matrix V are updated every
iteration with Equation 6. The meaning of each entry in V is
similar to U, where rows denote source classes and columns
denote target classes. For instance, V [0, 1] = v0→1 denotes
the accumulated class distance change from class 0 to class 1.
At the early stage of training, since we have not explored many
class pairs, we rely on prior-selection matrix U as guidance for
selecting pairs. With the training iteration grows, more class
pairs are explored, whose distance changes in V represent
Fig. 8: Class distance change
over training iterations
Fig. 9: Attack success rate of
prior backdoors
potential for each source class to a target class. The universal
trigger generation aims to generate a trigger that can flip
samples of all the classes (other than the target class) to the
target class yt. Formally,
M(x′
i) = M(T(xi, m, δ)) = yt ̸= yi,∀xi ∈ X,
(3)
where x′
i is acquired by optimizing Equation 1 and yi is the
ground truth label of input xi. Since the universal trigger
applies to all the source classes, the optimization needs to find
a backdoor that can flip the hardest class, which is far from the
target class. As such, this pair has good potential and should be
prioritized. To measure the level of difficulty of forcing a class
to the target class, we leverage the change of loss during the
optimization. Classes distinct from the target will have large
initial loss values as they are quite different from the target
class. Once the predictions of all the samples are successfully
flipped, the loss values are small for all classes. We use a set
of samples for each source class to approximate their distance
to the target class, which is denoted in the following.
us→t =
1
m
i − lf inal
linit
i
,
(4)
m(cid:88)
i,yi,s̸=yt
i
i
and lf inal
where s and t are the source and target classes; m is the
number of samples; linit
are the initial and final
loss values for sample i, whose label yi,s is different from
the target class yt. Here, a cross entropy loss function is
adopted for calculating the loss value. We set the number of
samples m = 10 unless stated otherwise. The warm-up phase
repeats the above process for each class (i.e., considering it
the target class) and computes a prior-selection matrix. We use
U to denote the matrix. Each entry represents the loss change
computed by Equation 4. For instance, the entry at row 0 and
column 1 of matrix U denotes the loss value change from
class 0 to class 1, i.e., U [0, 1] = u0→1. All the entries on the
diagonal are initialized with −∞. This prior-selection matrix
will be used for pair selection in the later steps.
Scheduling. We introduce a K-arm scheduler [51] for pair
selection. As discussed earlier, we use the variation of distance
to identify promising pairs. Assume there are N classes. We
then create K = N × (N − 1)/2 arms (i.e., all the pairwise
combinations without direction). At each training iteration, the
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 13:03:02 UTC from IEEE Xplore.  Restrictions apply. 
81379
frog-truckdeer-horsebird-horseairplane-automobilebird-catdeer-dogfrog-horseship-trucktheir priority of being selected. Hence, the objective function
W combines these two together as follows.
W = (1 − α) · U + α · V , where α = min(
Parameter α controls how much the scheduler relies on the
information from the two phases; i is the number of training
iterations and n is the number of classes. Since the warm-
up phase goes through n target classes (in n iterations), we
exclude those iterations in the objective function.
D. Speeding-up Training
i − n
1000
, 1). (7)
it
The hardening procedure discussed earlier requires gener-
ating minimal backdoors for stamping on training samples.
Usually,
takes several hundred steps of optimization to
obtain a minimal backdoor for a set of samples. Our scheduler
reduces the number of iterations for training as it proactively
prioritizes promising pairs. However, it still suffers from high
training cost due to the need of generating a minimal backdoor
for each iteration. Recall that the backdoor generation aims
to find a minimal mask m and a pattern δ that can induce
misclassification to the target class for a set of samples (see
Equation 1 and 2 in Section IV-B). There are two objectives
in Equation 1, which are the cross entropy loss and the L1
norm of m. The first objective is to induce misclassification
and the second to obtain a minimal backdoor. If the first
objective can be satisfied, the optimization will then focus
on reducing the size of a backdoor. The common practice of
generating backdoors starts from a randomly initialized mask
m and pattern δ, which usually has low or zero attack success
rate (ASR). It means the backdoor generation needs to spend
time on the first objective to achieve a high ASR, which slows
down the process for minimizing the backdoor size. If there
exists a backdoor that has a reasonable ASR, the optimization
can quickly concentrate on reducing the backdoor size.
We study the ASR of backdoors generated during training.
Particularly, we are interested in the performance of prior
backdoors (backdoors generated in the previous training it-
erations). Figure 9 shows the ASR of backdoors for five class
pairs. The x-axis denotes the training iteration, and the y-axis
denotes the ASR. Each dot in the figure denotes the ASR of
applying a backdoor from the last iteration on samples in the
current batch. The figure on the right shows distributions of
ASR for different pairs. Observe that many dots have higher
than 0.4 ASR. It is clearer from the distribution figure on
the right, where the peaks for different pairs are between 0.4
and 0.6 with pair airplane-automobile having the largest value
0.6. This indicates that leveraging backdoors from previous
iterations can give us a reasonable ASR, which can reduce
the cost of backdoor generation. Based on this observation, we
hence make use of a previous backdoor as the initialization for
generating the current backdoor. We also enlarge the weight λ
in Equation 1 for minimizing the backdoor size as the first
objective is easier to satisfy with backdoor reuse. We set
λ = 0.001 for generating the initial backdoor and λ = 0.2 for
the follow-up ones. In case no successful backdoor is found,
we rollback to the smaller λ for the next iteration.
V. EVALUATION
The evaluation is conducted on various standard datasets
and model structures. We also leverage pre-trained models
from the TrojAI competition [42] with a variety of classifi-
cation tasks and model types in the experiment. For different
design choices discussed earlier, we carry out an ablation study
to understand effects of different components of MOTH. Most
experiments were conducted on a server equipped with two
Intel Xeon Silver 4214 2.20GHz 12-core processors, 256 GB
of RAM, and eight NVIDIA Quadro RTX 6000 GPU cards.
A. Experiment Setup
Datasets and Models. We employ four standard datasets in the
evaluation: CIFAR-10, SVHN, LISA, and GTSRB. We also
conduct experiments on 30 pre-trained models from round 4
of the TrojAI competition [42]. Details of the setup can be
found in Appendix X-A.
Baselines. Three techniques discussed in Section II, namely,
adversarial training, universal adversarial perturbation (UAP),
and directly applying generated backdoors in training (Pair-
wise), are employed as baselines to compare with our harden-
ing approach MOTH. We also include training with universal
backdoors (flipping all classes to the target class) as our
baseline (Universal). Since our technique can be applied to any
trained models in computer vision, we further harden adversar-
ially trained models for evaluation. Please see detailed settings
in Appendix X-A. Note that the Pairwise baseline is already
more sophisticated than simply using generated backdoors in
hardening as it hardens the two directions of a pair together
(which could lead to 30% performance difference as shown
in Section V-D) and uses the speedup methods discussed in
Section IV-D. In addition to the above baselines, we also study
two existing backdoor-erasing approaches, namely, NC [40]
and NAD [39] in hardening class distance. NC first determines
if a model has a backdoor by checking if an exceptionally
small backdoor can be found. If so, it stamps the generated
backdoor on 20% of the available training set for retraining
the model. It is suitable for mitigating injected backdoors
(see Section VI-B). In contrast, MOTH enlarges distances
for all class pairs, aiming at general hardening. Symmetric
hardening, pair scheduling, etc. are hence needed to achieve
our purpose. NAD uses a model finetuned on the poisoned
model as the teacher network, and the poisoned model as
the student network. It then minimizes the internal feature
differences between the teacher and the student networks to