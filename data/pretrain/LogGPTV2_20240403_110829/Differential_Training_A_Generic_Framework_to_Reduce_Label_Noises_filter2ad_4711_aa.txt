title:Differential Training: A Generic Framework to Reduce Label Noises
for Android Malware Detection
author:Jiayun Xu and
Yingjiu Li and
Robert H. Deng
Differential Training: A Generic Framework to
Reduce Label Noises for Android Malware Detection
Jiayun Xu
Singapore Management University
PI:EMAIL
Yingjiu Li
University of Oregon
PI:EMAIL
Robert H. Deng
Singapore Management University
PI:EMAIL
Abstract—A common problem in machine learning-based
malware detection is that training data may contain noisy labels
and it is challenging to make the training data noise-free at a large
scale. To address this problem, we propose a generic framework
to reduce the noise level of training data for the training of
any machine learning-based Android malware detection. Our
framework makes use of all intermediate states of two identical
deep learning classiﬁcation models during their training with
a given noisy training dataset and generate a noise-detection
feature vector for each input sample. Our framework then
applies a set of outlier detection algorithms on all noise-detection
feature vectors to reduce the noise level of the given training
data before feeding it to any machine learning based Android
malware detection approach. In our experiments with three
different Android malware detection approaches, our framework
can detect signiﬁcant portions of wrong labels in different training
datasets at different noise ratios, and improve the performance
of Android malware detection approaches.
I.
INTRODUCTION
Machine learning-based Android malware detection has
been a major research focus in recent years. Both model
training and evaluation rely on a set of sample apps and
their associated labels (i.e., benignware and malware). The
sample apps and their labels can be either collected from
malware detection websites such as VirusTotal [7] or manually
examined and labeled by malware detection experts [50], [51],
[10].
However, the current approach to labelling sample apps is
not perfect due to a couple of reasons. First, the labels provided
by malware detection websites are not always reliable [23]. To
verify this, we randomly chose 50,000 APPs on VirusTotal,
and downloaded their scanning reports twice in 2016.7 and
2018.7, respectively. Among them, over 10% of the samples
(5310/50000) are given different labels in the two reports. On
the other hand, manually labelling is often costly and time-
consuming, and it is difﬁcult to scale up to massive datasets.
The label noises in app datasets may distort Android
malware detection in two main aspects.
•
According to F. A. Breve. et al. [11], the noises in
sample labels worsen the performance of malware
Network and Distributed Systems Security (NDSS) Symposium 2021
21-25  February  2021, Virtual 
ISBN  1-891562-66-5
https://dx.doi.org/10.14722/ndss.2021.24126
www.ndss-symposium.org
•
detection models trained with them, making them less
effective in real-world cases.
The noisy labels used for model testing and veri-
ﬁcation misjudge the real performances of existing
malware detection solutions. In the case study sections
of various research papers on malware detection (e.g.,
[48], [33], [50]), many false positive/negative cases
are reported in fact due to mislabeled samples.
The noisy label problem is intrinsic in malware detection
and challenging to deal with. The situation is worse due
to ever-growing sizes of datasets that are used in machine-
learning based malware detection. It remains challenging to
work with noisy datasets, so as to improve both training of
malware detection models and their evaluations. However, this
problem has not been rigorously addressed, especially in the
malware detection community.
Standard benchmark datasets have been built and widely
used in certain other machine-learning ﬁelds such as image
processing and natural language processing, where the qual-
ity of data labels can be veriﬁed by average human users
through user studies or crowdsourcing. However, it is highly
challenging for domain experts in malware detection (not to
mention average human users) to ensure the correctness of all
data labels in a massive dataset because the techniques for
composing malware are highly complicated and constantly e-
volving. This is one of the reasons that no universal benchmark
dataset has been built for Android malware detection, making
it difﬁcult for the comparison across many malware detection
approaches as they were evaluated on different datasets of
unknown qualities.
Towards addressing the problem of malware detection with
noisy datasets, we propose Differential Training, a novel noisy
label detection framework for machine learning based Android
malware detection. We make a meaningful assumption that the
whole set of apps is noisy (i.e., no individual apps’ labels
are known 100% correct), but a majority of sample apps
are correctly labeled. Differential Training can improve the
performance of any machine learning based Android malware
detection approaches by reducing label noises in their datasets.
In particular, Differential Training makes use of the inter-
mediate states of deep learning classiﬁcation models during
training for noisy label detection. According to Schein, etc.
in [36],
the intermediate states of a classiﬁcation model,
represented by variances of sample losses, can be used as
an effective measurement on the samples’ uncertainty so as
to help identify those that are not predicted properly within
the current model. In other research (e.g.,
[37], [22]), such
samples are paid extra attention in training so as to accelerate
the learning of models.
A fundamental assumption in the previous research men-
tioned above is that all samples’ labels are correct. Therefore,
the mismatching between desired labels and predicted labels
in training is attributed to immature model training. In the case
of noisy labels being present, the wrong labels also contribute
to the mismatching between desired labels and predicted labels
during model training.
Differential Training relies on a new heuristic, which we
call differential training heuristic, to reduce label noises in
a given set of sample apps. The heuristic differentiates be-
tween correctly labeled samples and wrongly labeled samples
according to their loss values in training two deep learning
classiﬁcation models of the same model architecture, where
one model is trained with the entire dataset, and the other is
trained with a randomly down-sampled subset of the given
dataset. A sample’s label is considered to be “wrong” and
thus revised/ﬂipped if its loss values appear to be outliers in
comparison to other samples’ loss values.
This heuristic is based on an observation that correctly
labeled samples tend to behave consistently in training the
two classiﬁcation models, while the wrongly labeled samples
tend to behave differently, and thus can be detected and
revised. Differential Training applies this heuristic iteratively
until a convergency condition is satisﬁed. After this, any
machine learning based malware detection approach can be
trained with the set of all sample apps and their revised
labels. Rigorous experiments on various datasets and malware
detection approaches show that differential training is clearly
effective in noisy reduction and performance improvement for
machine learning based malware detection.
The main contributions of this paper are summarized
below:
• We develop a new generic framework, Differen-
tial Training, to reduce label noises for large-scale
Android malware detection. Differential Training em-
ploys a novel approach to detecting noisy labels in
multiple iterations according to the intermediate states
of two deep learning classiﬁcation models of identical
architecture, one of which is trained on the whole
training set of apps, and the other is trained on a
randomly down-sampled set of apps. A new heuristic
is proposed to distinguish between wrongly-labeled
apps and correctly-labeled apps based on an outlier
detection on their loss values, which are taken from the
intermediate states of the two classiﬁcation models.
Differential Training enjoys high practicality because
it is generic, automated, and independent to correctly-
labeled datasets. Differential Training is generic as it
can work with any machine learning based malware
detection approach for reducing label noises of its
dataset and improving its training and performance
evaluation. Differential Training is fully automated
in the label noise reduction process which requires
neither domain knowledge nor manual inspection. In
addition, Differential Training can operate on noisily-
labeled datasets only. It does not rely on any extra
•
•
•
datasets whose labels are all correct like other noise-
tolerance classiﬁcation approaches such as Mentor-
Net [22] and distilled-based learning model [26].
The effectiveness of Differential Training is evalu-
ated with three different Android malware detection
approaches, including SDAC [47], Drebin [10], and
DeepReﬁner [49], as well as three different datasets,
whose sizes are 69k, 129k, and 110k, respectively.
Applying to these datasets, Differential Training can
reduce the size of wrongly-labeled samples to 12.6%,
17.4%, and 35.3% of its original size, respectively.
Consequently, Differential Training improve the per-
formance of each malware detection approach con-
siderably after noisy reduction is conducted to their
training datasets where the noise level is about 10%.
In terms of F-score measured with ground-truth data,
SDAC is improved from 89.04% to 97.19% (upper
bound 97.71%), Drebin from 73.20% to 84.40% (up-
per bound 93.34%), and DeepReﬁner from 91.37%
to 93.41% (upper bound 93.59%). The improved
performance is relatively close to their upper bound
97.71% for SDAC, 93.34% for Drebin, and 93.59%
for DeepReﬁner which are trained with all correctly-
labeled datasets. A similar trend is also observed at
various noise levels.
Differential Training also outperforms the state-of-the-
art noise-tolerant classiﬁcation solutions, Co-Teaching
and Decoupling, which are designed for training ro-
bust deep neural networks with noisy labels [20],
[27]. Differential Training detects signiﬁcantly more
wrongly-labeled samples than both Co-Teaching and
Decoupling.
II. PRELIMINARIES
A. Machine Learning Based Android Malware Detection
We aim to reduce label noises for machine learning based
Android malware detection that relies on a binary classiﬁcation
model to predict the label, which is either benign or malicious,
for each given Android app. A machine learning based Android
malware detection model is trained by a set of labeled Android
apps (i.e., training set) in two main steps, where the ﬁrst step
transforms each Android app into a numerical feature vector,
and the second step trains the model classiﬁer using the apps’
numeric feature vectors and their corresponding labels. After
training, the model’s performance can be evaluated using a
set of labeled apps (i.e., testing set), based on the differences
between their predicted labels and given labels.
B. Training Noise Detection Models
In the process of noisy label detection, Differential Training
keeps training two identical deep learning classiﬁcation mod-
els, which we call noise detection models. Each of these noise
detection model is trained to classify any given sample app to
be either malware or benignware. The training of each noise
detection model consists of multiple epochs. In each epoch,
each sample and its associated label are taken from a training
dataset and fed into the model through two successive phases:
forward propagation and backward propagation.
2
In the forward propagation phase, the feature vector of a
given sample is taken as input to the noise detection model. A
loss function is used to calculate a loss value for the sample
according to the input vector and the parameters the noise
detection model. Then, a predicted label is generated for the
sample and compared to the given label of the sample.
In the back propagation phase, the gradient of the loss
function with respect to each parameter in the noise detection
model is calculated. Each parameter is then updated according
to the gradient and the loss value in an optimal manner so as
to minimize the average loss value in the next epoch Since the
model parameters are adjusted in the whole training process,
the average loss value for the samples in the whole training
dataset is optimized to decrease from the ﬁrst epoch to the
last. The number of epochs is determined by a convergency
condition under which the average loss value in the last epoch
is considered to be good enough.
C. Underlying Assumption
The underlying assumption made by Differential Training
is that the majority of sample apps in the dataset are correctly
labeled; however, it is unknown whether the label of any
speciﬁc sample is correct or not. Note that it is meaningful to
assume that more than 50% of the sample apps are correctly
labeled since if it is not the case (i.e., the quality of dataset
is even lower than random labelling), a ﬂipping of each and
every label would make this assumption valid.
Differential Training does not rely on any set of individual
apps whose labels are 100% correct, which is different from
other noise-tolerance classiﬁcation approaches such as Mentor-
Net [22] and distilled-based learning model [26]. It requires
no manually checking on any sample apps in Differential
Training, which is fully automatic in reducing label noises for
Android malware detection.
III. DIFFERENTIAL TRAINING HEURISTIC
Differential Training trains two deep learning classiﬁcation
models of identical architecture iteratively for noisy label
detection. We call these two models noise detection models,
which can be any deep learning classiﬁcation models to
classify apps to be either benign or malicious according to
the apps’ feature vectors. The whole process of Differential
Training consists of multiple iterations. In each iteration two
different models are trained where the ﬁrst model is trained
with the whole set of available training apps (and their labels),
while the other is trained with a randomly down-sampled
subset of the whole set. For convenience, we refer to the whole
set of apps as WS, and the down-sampled subset as DS. We
also refer to the ﬁrst noise detection model as WS model, and
the other as DS model.
In each iteration, Differential Training relies on a new
heuristic, named differential training heuristic to reduce label
noises in DS. The heuristic states that the training behaviors
of correctly labeled samples across the two models are sta-
tistically different from those of the wrongly labeled samples
across the two models, where the training behavior of a sample
across the two models is described by the concatenation of the
loss values produced for the sample in all epochs of the two
models. Given the assumption that a majority of sample apps
are correctly labeled, the wrongly labeled apps in DS can be
detected statistically using an outlier detection on the training
behaviors of all apps in DS.
Experimental observation.
The heuristic is enlightened
by our observation in the following experiments. When we
observe a single model, either WS model or DS model, the
differences in training behaviors between correctly-labeled
samples and wrongly-labeled samples are not too signiﬁcant;
however, when we combine training behaviors across the two
models, the differences between the two types of samples
become more apparent.
In the experiments of showing our observation, Differential
Training is applied to a set of sample apps that are randomly
collected from a public Android app sharing project [8]. To
guarantee the correctness of the samples’ labels, we further
check their scanning results from VirusTotal, and remove all
(which is equivalent to around 10%) of the samples whose
scanning results ever changed since August 2016. We use
50,000 samples to build the WS set, and choose 10% of them