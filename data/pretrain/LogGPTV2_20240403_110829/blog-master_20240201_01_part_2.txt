```    
┌───────────────────────────┐                                                              
│         PROJECTION        │                                                              
│   ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─   │                                                              
│         first_name        │                                                              
│         last_name         │                                                              
└─────────────┬─────────────┘                                                                                           
┌─────────────┴─────────────┐                                                              
│         HASH_JOIN         │                                                              
│   ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─   │                                                              
│           INNER           │                                                              
│     film_id = film_id     ├───────────────────────────────────────────┐                  
└─────────────┬─────────────┘                                           │                                               
┌─────────────┴─────────────┐                             ┌─────────────┴─────────────┐    
│         HASH_JOIN         │                             │           FILTER          │    
│   ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─   │                             │   ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─   │    
│           INNER           │                             │ (title = 'ACE GOLDFINGER')│    
│    actor_id = actor_id    ├──────────────┐              │                           │    
└─────────────┬─────────────┘              │              └─────────────┬─────────────┘                                 
┌─────────────┴─────────────┐┌─────────────┴─────────────┐┌─────────────┴─────────────┐    
│        SQLITE_SCAN        ││       POSTGRES_SCAN       ││        MYSQL_SCAN         │    
│   ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─   ││   ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─   ││   ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─   │    
│    sakila.db:film_actor   ││           actor           ││            film           │    
│   ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─   ││   ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─   ││   ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─   │    
│          film_id          ││          actor_id         ││          film_id          │    
│          actor_id         ││         first_name        ││           title           │    
│                           ││         last_name         ││                           │    
└───────────────────────────┘└───────────────────────────┘└───────────────────────────┘     
```    
Several changes have been made to Postgres extension since the last release. Use `FORCE INSTALL postgres` to install the latest version of the extension.    
## Transactions    
All statements executed within DuckDB are executed within a transaction. If an explicit `BEGIN TRANSACTION` is not called, every statement will execute in its own transaction. This also applies to queries that are executed over other storage engines. These storage engines also support explicit `BEGIN`, `COMMIT` and `ROLLBACK` statements.    
For example, we can begin a transaction within our attached SQLite database, make a change, and then roll it back. The original data will be restored.    
```    
BEGIN;    
TRUNCATE film;    
SELECT title, release_year, length FROM film;    
┌─────────┬──────────────┬────────┐    
│  title  │ release_year │ length │    
│ varchar │   varchar    │ int64  │    
├─────────────────────────────────┤    
│             0 rows              │    
└─────────────────────────────────┘    
ROLLBACK;    
SELECT title, release_year, length FROM film LIMIT 5;    
┌──────────────────┬──────────────┬────────┐    
│      title       │ release_year │ length │    
│     varchar      │   varchar    │ int64  │    
├──────────────────┼──────────────┼────────┤    
│ ACADEMY DINOSAUR │ 2006         │     86 │    
│ ACE GOLDFINGER   │ 2006         │     48 │    
│ ADAPTATION HOLES │ 2006         │     50 │    
│ AFFAIR PREJUDICE │ 2006         │    117 │    
│ AFRICAN EGG      │ 2006         │    130 │    
└──────────────────┴──────────────┴────────┘    
```    
## Multi-Database Transactions    
Every storage engine has their own transactions that are stand-alone and managed by the storage engine itself. Opening a transaction in Postgres, for example, calls `BEGIN TRANSACTION` in the Postgres client. The transaction is managed by Postgres itself. Similarly, when the transaction is committed or rolled back, the storage engine handles this by itself.    
Transactions are used both for reading and for `writing` data. For `reading` data, they are used to provide a consistent snapshot of the database. For writing, they are used to ensure all data in a transaction is packed together and written at the same time.    
When executing a transaction that involves multiple attached databases we need to open multiple transactions: one per attached database that is used in the transaction. While this is not a problem when `reading` from the database, it becomes complicated when `writing`. In particular, when we want to `COMMIT` a transaction it is challenging to ensure that either (a) every database has successfully committed, or (b) every database has rolled back.    
For that reason, it is currently not supported to write to multiple attached databases in a single transaction. Instead, an error is thrown when this is attempted:    
```    
BEGIN;    
CREATE TABLE postgres.new_table(i INT);    
CREATE TABLE mysql.new_table(i INT);    
Error: Attempting to write to database "mysql" in a transaction that has    
already modified database "postgres" – a single transaction can only write    
to a single attached database.    
```    
## Copying Data Between Databases    
`CREATE TABLE AS`, `INSERT INTO` and `COPY` can be used to copy data between different attached databases. The dedicated [`COPY FROM DATABASE ... TO`](https://duckdb.org/docs/sql/statements/copy.html#copy-from-database--to) can be used to copy all data from one database to another. This includes all tables and views that are stored in the source database.    
```    
-- attach a Postgres database    
ATTACH 'postgres:dbname=postgresscanner' AS postgres;    
-- attach a DuckDB file    
ATTACH 'database.db' AS ddb;    
-- export all tables and views from the Postgres database to the DuckDB file    
COPY FROM DATABASE postgres TO ddb;    
```    
Note that this statement is currently only available in the development build. It will be available in the next DuckDB release (v0.10).    
## Directly Opening a Database    
The explicit `ATTACH` statement is not required to connect to a different database type. When instantiating a DuckDB instance a connection can be made directly to a different database type using the `{type}:` prefix. For example, to connect to a SQLite file, use `sqlite:file.db`. To connect to a Postgres instance, use `postgres:dbname=postgresscanner`. This can be done in any client, including the CLI. For instance:    
CLI:    
```    
duckdb sqlite:file.db    
```    
Python:    
```    
import duckdb    
con = duckdb.connect('sqlite:file.db')    
```    
This is equivalent to attaching the storage engine and running `USE` afterwards.    
## Conclusion    
DuckDB’s pluggable storage engine architecture enables many use cases. By attaching multiple databases, data can be extracted in a transactionally safe manner for bulk ETL or ELT workloads, as well as for on-the-fly data virtualization workloads. These techniques also work well in combination, for example, by moving data in bulk on a regular cadence, while filling in the last few data points on the fly.    
Pluggable storage engines also unlock new ways to handle concurrent writers in a data platform. Each separate process could write its output to a transactional database, and the results could be combined within DuckDB – all in a transactionally safe manner. Then, data analysis tasks can occur on the centralized DuckDB database for improved performance.    
We look forward to hearing the many creative ways you are able to use this feature!    
## Future Work    
We intend to continue enhancing the performance and capabilities of the existing extensions. In addition, all of these features can be leveraged by the community to connect to other databases.    
#### [期望 PostgreSQL|开源PolarDB 增加什么功能?](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216")
#### [PolarDB 开源数据库](https://openpolardb.com/home "57258f76c37864c6e6d23383d05714ea")
#### [PolarDB 学习图谱](https://www.aliyun.com/database/openpolardb/activity "8642f60e04ed0c814bf9cb9677976bd4")
#### [购买PolarDB云服务折扣活动进行中, 55元起](https://www.aliyun.com/activity/new/polardb-yunparter?userCode=bsb3t4al "e0495c413bedacabb75ff1e880be465a")
#### [PostgreSQL 解决方案集合](../201706/20170601_02.md "40cff096e9ed7122c512b35d8561d9c8")
#### [德哥 / digoal's Github - 公益是一辈子的事.](https://github.com/digoal/blog/blob/master/README.md "22709685feb7cab07d30f30387f0a9ae")
#### [About 德哥](https://github.com/digoal/blog/blob/master/me/readme.md "a37735981e7704886ffd590565582dd0")
![digoal's wechat](../pic/digoal_weixin.jpg "f7ad92eeba24523fd47a6e1a0e691b59")