By running multiple variants of the same program and ﬁlling
newly-allocated heap memory with random values, and pro-
viding all variants with identical input, any deviation in output
was likely to be due to use of uninitialized memory. To obtain
reliability against memory errors, they proposed running sev-
eral variants, and dropping any reporting inconsistent results.
Stack clearing: gcc’s Fortran compiler provides an
-finit-local-zero option, intended only for compatibil-
ity with legacy Fortran code. Several C/C++ compilers provide
options for automatic initialization of function stack frames,
intended only for debugging purposes. As discussed, such
stack frame clearing adds a signiﬁcant performance penalty,
and provides fewer guarantees.
Chen et al. presented StackArmor [9], a binary hardening
system which isolated function frames containing potentially
unsafe buffers using guard pages and random reordering. This
makes it more difﬁcult for attackers to predict which data
may be present in uninitialized portions of frames, providing
probabilistic mitigation of uninitialized data vulnerabilities;
they combined it with analysis to add zero-initialization to
potentially uninitialized portions of non-isolated frames, but
reported high average overhead of 28% on SPEC CPU2006.
Heap clearing: Heap allocation clearing is an option in
some existing allocators, such as jemalloc [20], although
generally intended only for debugging; for example, the je-
malloc documentation warns that it “will impact performance
negatively”. Wang et al. [62] proposed zero-initializing and
padding heap allocations at allocation time, by wrapping
malloc, to protect against buffer overread vulnerabilities.
Araujo and Hamlen [3] suggested just zeroing the ﬁrst byte
of all allocations, giving limited beneﬁts (e.g., for C strings)
but adding almost no overhead.
Heap isolation:
Chow et al. proposed Secure Deallocation [11], which
modiﬁes the system C library to zero heap allocations when
freed, and modiﬁes compiler code generation to clear stack
frames in function epilogues; this provides less comprehen-
sive protection and misses optimization opportunities. They
claimed runtime overhead of <7% for heap clearing, but 10%-
40% overhead for stack clearing, although their approach does
protect against some vulnerabilities outside our threat model.
Isolating all heap allocations mitigates
some classes of memory vulnerabilities, such as overﬂows;
however, this is at best a probabilistic defense, since limited
available address space means memory is inevitably reused
after a certain point. DieHard [5] allocates memory randomly
across an oversized heap, and Archipelago [41] allocates
memory across the entire address space. OpenBSD [46] imple-
mented such a random allocator by default, including moving
metadata out-of-bound, and DieHarder [48] built upon this to
increase entropy at an additional performance cost of 20%,
due to the cost of memory fragmentation.
Information disclosure defenses: Many defenses have been
proposed for protecting sensitive data. TaintEraser [68] uses
tainting to track sensitive user input and prevent
it from
13
escaping to the ﬁlesystem or network. Harrison and Xu [24]
proposed techniques for probabilistically protecting private
cryptographic keys against memory disclosure attacks, and
SWIPE [23] tracks sensitive data using static analysis and
erases it at the end of its lifetime.
may result
in signiﬁcantly better overhead in some cases,
particularly for the heap. We believe similar results could be
obtained by adding knowledge of Linux heap functions and a
Linux-speciﬁc optimization pass to SafeInit; combining both
techniques may also be a promising approach.
Defenses which depend on information hiding to protect
pointers or other metadata are particularly vulnerable to infor-
mation disclosure. Advances such as ﬁne-grained ASLR [25]
are rendered useless if uninitialized memory errors can be used
to disclose pointers. Defenses such as Code-Pointer Integrity
[32], Readactor [15] and ASLR-Guard [39] aim to protect code
pointers against more sophisticated disclosure attacks such as
those proposed by Evans et al. [19] and Schuster et al. [51].
Linux kernel
Uninitialized data vulnerabilities in the Linux kernel have
had increased attention in recent years; as well as obvious
issues of exposing conﬁdential
information, knowledge of
kernel addresses has become important for attackers wishing to
bypass defenses such as stack canaries (using gcc’s StackGuard
[14]) and ASLR (kASLR [13]). In 2011, Chen et al. [8] per-
formed an extensive analysis of kernel vulnerabilities and re-
ported that the most common category were uninitialized data
errors, almost all of which led to information disclosure. More
recently, Peir´o et al. [50] provided more in-depth discussion
of such kernel info disclosure vulnerabilities, and presented a
technique for identifying stack information disclosures using
static analysis. Linux also includes kmemcheck, a dynamic
analysis tool for detecting uses of uninitialized heap memory.
grsecurity/PaX: The PaX project [49], as part of the
hardened grsecurity Linux patches, provides two different
mitigations for potentially uninitialized kernel stack data, using
gcc plugins. One annotates structures which may be disclosed
to userspace, and initializes any such structures on the stack
to prevent accidental information disclosure. The other takes
a more aggressive approach, clearing the kernel stack be-
fore/after system calls. A gcc plugin tracks the maximum stack
depth used for each call, providing efﬁcient protection against
stack re-use between different system calls, although still
theoretically allowing an attacker to exploit such issues within
a single call. Both grsecurity and recent mainline kernels can
also be conﬁgured to initialize and/or clear heap allocations.
UniSan: Concurrently to our work, Lu et al. developed
UniSan[38], a compiler-based approach for mitigating infor-
mation disclosure vulnerabilities caused by uninitialized values
in the Linux kernel. They propose using static data-ﬂow
analysis to trace potential execution paths (after optimizations
have been applied), and initializing any variables which cannot
be proven to be initialized before potentially being disclosed;
they implemented a prototype using LLVM, and manually
inspected their analysis results to ﬁnd and disclose various new
uninitialized value disclosure vulnerabilities (some of which
we used to verify the correctness of our own work).
Our approach mitigates a wider range of potential uninitial-
ized value vulnerabilities on the stack (such as dereferencing
uninitialized pointers [40] or even control-ﬂow-based side-
channel attacks [52]), and SafeInit obtains good performance
without additional data-ﬂow analysis. However, UniSan’s inter-
procedural analysis and speciﬁc knowledge of kernel functions
XI. CONCLUSION
Uninitialized data vulnerabilities continue to pose a secu-
rity problem in modern C/C++ software, and ensuring safety
against the use of uninitialized values is not as easy as it might
seem. Threats ranging from simple information disclosures to
serious issues such as arbitrary memory writes, static analysis
limitations, and compiler optimizations taking advantage of
undeﬁned behavior, combine to make this a difﬁcult problem.
We presented a toolchain-based hardening technique,
SafeInit, which mitigates uses of uninitialized values in C/C++
programs by ensuring that all local variables and stack alloca-
tions are initialized before use. By making use of appropriate
optimizations, we showed that runtime overhead for many
applications can be reduced to a level which makes it practical
to apply as a standard hardening protection, and that this can
be done practically in a modern compiler.
further
To foster
research in this area, we are open
sourcing our SafeInit prototype, which is available at
https://github.com/vusec/safeinit. We hope to
work towards making SafeInit available as a standard compiler
feature, and improving the optimizations it depends upon.
ACKNOWLEDGEMENTS
We would like to thank Kees Cook, Kangjie Lu and the
anonymous reviewers for their comments. This work was
supported by the European Commission through project H2020
ICT-32-2014 SHARCS under Grant Agreement No. 644571
and by the Netherlands Organisation for Scientiﬁc Research
through grant NWO 639.023.309 VICI Dowsing.
REFERENCES
[1]
“CVE-2012-1889: Vulnerability in Microsoft XML core services could
allow remote code execution,” 2012.
[2] P. Akritidis, M. Costa, M. Castro, and S. Hand, “Baggy bounds
checking: An efﬁcient and backwards-compatible defense against out-
of-bounds errors.” in USENIX Security, 2009.
[3] F. Araujo and K. Hamlen, “Compiler-instrumented, dynamic secret-
redaction of legacy processes for attacker deception,” in USENIX
Security, 2015.
[4] M. Auslander and M. Hopkins, “An overview of the PL. 8 compiler,”
in SIGPLAN Symposium on Compiler Construction, 1982.
[5] E. D. Berger and B. G. Zorn, “DieHard: probabilistic memory safety
for unsafe languages,” in PLDI, 2006.
[6] A. Bessey, K. Block, B. Chelf, A. Chou, B. Fulton, S. Hallem, C. Henri-
Gros, A. Kamsky, S. McPeak, and D. Engler, “A few billion lines
of code later: using static analysis to ﬁnd bugs in the real world,”
Communications of the ACM, vol. 53, no. 2, pp. 66–75, 2010.
[7] D. Bruening and Q. Zhao, “Practical memory checking with dr. mem-
ory,” in CGO, 2011.
[8] H. Chen, Y. Mao, X. Wang, D. Zhou, N. Zeldovich, and M. F.
Kaashoek, “Linux kernel vulnerabilities: State-of-the-art defenses and
open problems,” in APSys, 2011.
[9] X. Chen, A. Slowinska, D. Andriesse, H. Bos, and C. Giuffrida,
“StackArmor: Comprehensive protection from stack-based memory
error vulnerabilities for binaries.” in NDSS, 2015.
14
[10]
[11]
J. Chow, B. Pfaff, T. Garﬁnkel, K. Christopher, and M. Rosenblum,
“Understanding data lifetime via whole system simulation,” in USENIX
Security, 2004.
J. Chow, B. Pfaff, T. Garﬁnkel, and M. Rosenblum, “Shredding
your garbage: Reducing data lifetime through secure deallocation.” in
USENIX Security, 2005.
[12] K. Cook, “Kernel exploitation via uninitialized stack,” DEFCON 19,
2011.
[13] ——, “Kernel address space layout randomization,” 2013, Linux Secu-
rity Summit.
[14] C. Cowan, C. Pu, D. Maier, J. Walpole, P. Bakke, S. Beattie, A. Grier,
P. Wagle, Q. Zhang, and H. Hinton, “StackGuard: Automatic adaptive
detection and prevention of buffer-overﬂow attacks,” in USENIX Secu-
rity, 1998.
[15] S. Crane, C. Liebchen, A. Homescu, L. Davi, P. Larsen, A.-R. Sadeghi,
S. Brunthaler, and M. Franz, “Readactor: Practical code randomization
resilient to memory disclosure,” in S&P, 2015.
[16] C. Deng and K. S. Namjoshi, “Securing a compiler transformation,” in
Static Analysis, 2016.
[17] C. Ding and Y. Zhong, “Predicting whole-program locality through
reuse distance analysis,” in PLDI, 2003.
[18] D. Edelsohn, W. Gellerich, M. Hagog, D. Naishlos, M. Namolaru,
E. Pasch, H. Penner, U. Weigand, and A. Zaks, “Contributions to the
GNU compiler collection,” IBM Systems Journal, 2005.
I. Evans, S. Fingeret, J. Gonz´alez, U. Otgonbaatar, T. Tang, H. Shrobe,
S. Sidiroglou-Douskos, M. Rinard, and H. Okhravi, “Missing the point
(er): On the effectiveness of code pointer integrity,” in S&P, 2015.
J. Evans, “A scalable concurrent malloc(3)
FreeBSD,” in BSDCan, 2006.
implementation for
[19]
[20]
[21] H. Flake, “Attacks on uninitialized local variables,” Black Hat Europe,
2006.
[22] S. Ghemawat and P. Menage, “TCMalloc : Thread-caching malloc,”
2007.
[23] K. Gondi, P. Bisht, P. Venkatachari, A. P. Sistla, and V. N. Venkatakr-
ishnan, “SWIPE: Eager erasure of sensitive data in large scale systems
software,” in CODASPY, 2012.
[24] K. Harrison and S. Xu, “Protecting cryptographic keys from memory
disclosure attacks,” in DSN, 2007.
J. Hiser, A. Nguyen-Tuong, M. Co, M. Hall, and J. W. Davidson, “ILR:
Where’d my gadgets go?” in S&P, 2012.
[25]
[27]
[26] G. Hoﬂehner, “LLVM performance improvements and headroom,” in
LLVM Developers’ Meeting, 2015.
J. Hubicka, “Interprocedural optimization framework in GCC,” in GCC
Developers Summit, 2007.
[28] T. Johnson and D. L. Xinliang, “ThinLTO: A ﬁne-grained demand-
driven infrastructure,” in EuroLLVM, 2015.
[29] M. Jurczyk, “Enabling QR codes in Internet Explorer, or a story of a
cross-platform memory disclosure,” 2015.
[30] K. Koning, H. Bos, and C. Giuffrida, “Secure and efﬁcient multi-variant
execution using hardware-assisted process virtualization,” in DSN, 2016.
[31] B. C. Kuszmaul, “SuperMalloc: a super fast multithreaded malloc for
64-bit machines,” in ISMM, 2015.
[32] V. Kuznetsov, L. Szekeres, M. Payer, G. Candea, R. Sekar, and D. Song,
“Code-Pointer Integrity,” in OSDI, 2014.
[33] W. Landi, “Undecidability of static analysis,” ACM Lett. Program. Lang.
Syst., 1992.
[34] C. Lattner, “What every C programmer should know about undeﬁned
behavior,” 2011, LLVM project blog.
[35] C. Lattner and V. Adve, “LLVM: A Compilation Framework for
Lifelong Program Analysis & Transformation,” in CGO, 2004.
[36] X. Leroy, “Formal veriﬁcation of a realistic compiler,” Communications
of the ACM, no. 7, pp. 107–115, 2009.
[37] Linux Foundation, “LLVMLinux project.”
[38] K. Lu, C. Song, T. Kim, and W. Lee, “UniSan: Proactive kernel memory
initialization to eliminate data leakages,” in CCS, 2016.
15
[39] K. Lu, C. Song, B. Lee, S. P. Chung, T. Kim, and W. Lee, “ASLR-
Guard: Stopping address space leakage for code reuse attacks,” in CCS,
2015.
[40] K. Lu, M.-T. Walter, D. Pfaff, N. Stefan, W. Lee, and M. Backes,
“Unleashing use-before-initialization vulnerabilities in the Linux kernel
using targeted stack spraying,” in NDSS, 2017.
[41] V. B. Lvin, G. Novark, E. D. Berger, and B. G. Zorn, “Archipelago:
trading address space for reliability and security,” in ASPLOS, 2008.
[42] V. Makarov, “The integrated register allocator for GCC,” in GCC
Developers Summit, 2007.
[43] L. W. McVoy and C. Staelin, “LMbench: Portable tools for performance
analysis,” in USENIX, 1996.
[44] K. Memarian, J. Matthiesen, J. Lingard, K. Nienhuis, D. Chisnall,
R. N. M. Watson, and P. Sewell, “Into the depths of c: Elaborating
the de facto standards,” in PLDI, 2016.
[45] Microsoft, “MS08-014 : The case of the uninitialized stack variable
vulnerability,” 1998.
[46] O. Moerbeek, “A new malloc (3) for OpenBSD,” in EuroBSDCon, 2009.
[47] A. Nemet and M. Zolotukhin, “Advances in loop analysis frameworks
and optimizations,” in LLVM Developers’ Meeting, 2015.
[48] G. Novark and E. D. Berger, “DieHarder: securing the heap,” in CCS,
2010.
[49] PaX Team, “PaX - gcc plugins galore,” 2013, H2HC.
[50] S. Peir´o, M. Munoz, and A. Crespo, “An analysis on the impact and
detection of kernel stack infoleaks,” Logic Journal of IGPL, 2016.
[51] F. Schuster, T. Tendyck, C. Liebchen, L. Davi, A.-R. Sadeghi, and
T. Holz, “Counterfeit object-oriented programming: On the difﬁculty
of preventing code reuse attacks in c++ applications,” in S&P, 2015.
J. Seibert, H. Okhravi, and E. S¨oderstr¨om, “Information leaks without
memory disclosures: Remote side channel attacks on diversiﬁed code,”
in CCS, 2014.
[52]
[53] F. J. Serna, “The info leak era on software exploitation,” Black Hat
USA, 2012.
J. Seward and N. Nethercote, “Using valgrind to detect undeﬁned value
errors with bit-precision,” in USENIX, 2005.
[54]
[55] H. Shacham, M. Page, B. Pfaff, E.-J. Goh, N. Modadugu, and D. Boneh,
“On the effectiveness of address-space randomization,” in CCS, 2004.
[56] K. Z. Snow, F. Monrose, L. Davi, A. Dmitrienko, C. Liebchen, and
A.-R. Sadeghi, “Just-in-time code reuse: On the effectiveness of ﬁne-
grained address space layout randomization,” in S&P, 2013.
[57] B. Spengler, “Detection, prevention, and containment: A study of
grsecurity,” 2002, libres Software Meeting.
[58] E. Stepanov and K. Serebryany, “MemorySanitizer: fast detector of
uninitialized memory use in c++,” in CGO, 2015.
[59] C. Sun, V. Le, and Z. Su, “Finding and analyzing compiler warning
defects,” in ICSE, 2016.
[60] L. Szekeres, M. Payer, T. Wei, and D. Song, “SoK: Eternal war in
memory,” in S&P, 2013.
[61] R. van Eeden, “Unexpected code execution in smbd,” 2015.
[62]
J. Wang, M. Zhao, Q. Zeng, D. Wu, and P. Liu, “Risk assessment of
buffer “heartbleed” over-read vulnerabilities,” in DSN, 2015.
[63] X. Wang, H. Chen, A. Cheung, Z. Jia, N. Zeldovich, and M. F.
Kaashoek, “Undeﬁned behavior: what happened to my code?” in APSys,
2012.
[64] X. Yang, Y. Chen, E. Eide, and J. Regehr, “Finding and understanding
bugs in c compilers,” in PLDI, 2011.
[65] D. Ye, Y. Sui, and J. Xue, “Accelerating dynamic detection of uses of
undeﬁned values with static value-ﬂow analysis,” in CGO, 2014.
[66] S. Yilek, E. Rescorla, H. Shacham, B. Enright, and S. Savage, “When
private keys are public: results from the 2008 Debian OpenSSL vulner-
ability,” in IMC, 2009.
J. Zhao, S. Nagarakatte, M. M. Martin, and S. Zdancewic, “Formal
veriﬁcation of SSA-based optimizations for LLVM,” in PLDI, 2013.
[67]
[68] D. Y. Zhu, J. Jung, D. Song, T. Kohno, and D. Wetherall, “TaintEraser:
Protecting sensitive data leaks using application-level taint tracking,”
ACM SIGOPS Operating Systems Review, 2011.