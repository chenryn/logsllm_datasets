title:Comparing Video Based Shoulder Surfing with Live Simulation
author:Adam J. Aviv and
Flynn Wolf and
Ravi Kuber
8
1
0
2
p
e
S
3
2
]
C
H
.
s
c
[
1
v
0
4
6
8
0
.
9
0
8
1
:
v
i
X
r
a
Comparing Video Based Shoulder Surﬁng with Live Simulation∗
Adam J. Aviv•†, Flynn Wolf ⋄, and Ravi Kuber ⋄
• United States Naval Academy
⋄ University of Maryland,Baltimore County
PI:EMAIL {flynn.wolf,rkuber}@umbc.edu
September 25, 2018
Abstract
We analyze the claims that video recreations of shoulder surﬁng attacks oﬀer a suitable alternative
and a baseline, as compared to evaluation in a live setting. We recreated a subset of the factors of a prior
video-simulation experiment conducted by Aviv et al.
(ACSAC 2017), and model the same scenario
using live participants (n = 36) instead (i.e., the victim and attacker were both present). The live
experiment conﬁrmed that for Android’s graphical patterns video simulation is consistent with the live
setting for attacker success rates. However, both 4- and 6-digit PINs demonstrate statistically signiﬁcant
diﬀerences in attacker performance, with live attackers performing as much 1.9x better than in the video
simulation. The security beneﬁts gained from removing feedback lines in Android’s graphical patterns are
also greatly diminished in the live setting, particularly under multiple attacker observations, but overall,
the data suggests that video recreations can provide a suitable baseline measure for attacker success rate.
However, we caution that researchers should consider that these baselines may greatly underestimate the
threat of an attacker in live settings.
1
Introduction
Biometric authentication mechanisms oﬀer considerable promise to smartphone users. However, the protec-
tion of unlock authentication still relies on choosing hard to guess passcodes (e.g., PINs and unlock patterns),
while not revealing those passcodes to untrusted parties. A common means of attack for gaining access to the
passcode is via shoulder surﬁng. In a shoulder surﬁng attack, an observer attempts to view a victim in the
process of entering his/her passcode with the intention of recreating that passcode after gaining possession
of the device [26].
The area of shoulder surﬁng has been the subject of a great deal of work [10, 12, 19, 8, 6, 7, 9, 18, 13, 4], for
both understanding the threat and proposing mechanisms to prevent it. Of particular relevance to this study
(termed ”current study”), is the work conducted by Aviv et al. [4] (termed: ”prior study”). The prior study
examined the shoulder surﬁng susceptibility of three commonly used unlock authentication mechanisms:
4- and 6-digit PINs, 4- and 6-length Android graphical patterns, and 4- and 6-length Android graphical
patterns with the feedback display turned oﬀ (lines rendered by the interface between grid points as they are
touched by the user). Due to the diﬃcult nature of evaluating shoulder surﬁng attacks in the ﬁeld, the goal
of the prior study was to establish baselines for shoulder surﬁng vulnerability in controlled settings that can
be used to compare across authentication types and used as baseline for evaluating authentication systems
that are designed to defend against such attacks.
To control the analysis, the prior study was conducted using a video-based methodology where the
researchers recorded a set of videos with highly controlled factors and then asked participants to view
∗This article appears in the proceedings of the 2018 Annual Computer Security Applications Conference.
†Corresponding Author
1
these videos as a simulated shoulder surﬁng scenario. The data was analyzed to determine shoulder-surﬁng
susceptibility under each condition. The attack rate (how eﬀectively the participant could recall the passcode
entered in the video) was the primary metric.
In this paper, we seek to compare the video-based methodology to a similarly controlled live setting. In
particular, we are interested in assessing the prior work’s following ﬁndings relating to the attack success
rate.
• Longer authentication lengths (e.g, 4-digit vs. 6-digit PINs) are less vulnerable.
• PIN authentication is less vulnerable to the attack compared to patterns with and without feedback
lines.
• Removing the feedback lines from patterns decreases the vulnerability to shoulder surﬁng.
• Multiple observations increases vulnerability.
• Video based evaluation provides a baseline for live, in-person shoulder surﬁng vulnerability.
Using the raw results of the prior study, we compare the attacker success rates of the live setting to
a comparable subset of the video study data. Testing for diﬀerences in proportionality, we are unable to
reject the null hypothesis that the attacker success rate are the same for Android patterns as well as in
many of the settings with patterns without feedback lines. This suggests that there is consistency between
the results of the video and live simulations. However, the advantage of removing feedback lines previously
observed in video simulation is considerably lessened in the live setting. For PINs, we observe signiﬁcant
diﬀerence between the video and the live settings, where live attackers performed up to 1.9x better in some
scenarios. Stereo vision seems to greatly improve the reliability of recalling the more complex motions of
entering a PIN. Despite this discrepancy, the claim of Aviv et al. of these results forming a baseline is still
supported: we never observed a situation by which the live simulation performed worse than a video study
when signiﬁcant diﬀerences exist.
We conclude that video studies do provide a reasonable approximation for live simulation of shoulder
surﬁng in settings that involve graphical passwords (but not PINs), like the Android password pattern,
and at least a lower-bound on the attack success rate for all tested authentication types (including PINs).
However, researchers should consider that this lower-bound may be a signiﬁcant underestimation compared
to the true attack rate in live simulations.
2 Related Work
Mobile authentication and observation attacks Threats such as shoulder-surﬁng attacks have been
well documented by researchers [27, 4]. Studies have been conducted examining experiences of users who had
encountered observation attacks [11] where shoulder surﬁng was found to be “casual” and “opportunistic.”
Harbach et al. [14] found that participants only very rarely reported shoulder surﬁng (0.3% of 1134 sampled
events) as an immediate high risk threat when authenticating.
In order to minimize the risk associated with observation attacks, users are known to modify their own
usage behaviors when using a mobile device, hiding the device from sight and performing mobile interactions
in the pocket or bag, or even shielding the screen [1]. Solutions also exist to obscure screens from third
parties [8], to detect the presence of shoulder surfers in a nearby vicinity [20] or to deceive onlookers from
data being entered [24, 17]. Attacks have also been simulated by having observers watch video footage of
victims entering authentication sequences. Examples include [15] where attacks took place from top and
side views. A range of solutions have also been proposed to minimize the likelihood of shoulder-surﬁng when
entering authentication sequences [2]. However, as highlighted by Wiese and Roth [27], it can be diﬃcult to
compare the eﬃcacy of these solutions, as the ways in which these systems are studied varies. Furthermore,
the outcomes can be diﬃcult to compare and interpret.
2
Evaluating resistance from shoulder surﬁng Many evaluation studies have focused on observing un-
lock screen interactions where PINs and patterns are entered [22, 4, 15]. Wiese and Roth [27] suggest that
conducting such studies are challenging because real-world adversaries are not available for study and must
be simulated in one way or another. In contrast to live studies where participants and actors/researchers
perform tasks together in person, video simulations have been used to identify susceptibility of on-screen
threats [21, 2]. Video recordings oﬀer consistency when presented to multiple users [27], and can also be ac-
cessed independent of location. However, research indicates that that the success of adversaries is lower when
performing video observations compared to live settings [23, 27]; we make a similar observation here. Prior
research also recommends that shoulder surﬁng attackers should be allowed a number of observations [27]
as well as viewing interactions from a range of views [21, 4] and diﬀerent properties of passcodes [4]. Addi-
tionally, the hand position [22] and interaction style when entering data into the device [4] should also be
considered. We tested scenarios found to be signiﬁcant in Aviv et al., following similar procedures.
Overview of Aviv et al. [4] Aviv et al. considered the lack of a baseline for comparing common unlock
authentication mechanisms under the threat of shoulder surﬁng. As a method of creating such a baseline, the
authors used a series of controlled video simulations of a victim entering unlock authentications using several
methods. These methods were PINs and Android’s graphical pattern unlock, with and without feedback
lines present. Additional factors were considered, including the angle of observation, number of observations,
the number of recreation attempts by the observer, the hand posture of the victim, phone size, and spatial
layout of the passcodes.
The methodology of that experiment was multi-factorial. Participants were selected into one of a number
of independent factors (phone type, passcode choice, authentication type, hand posture) and then a set
of randomized dependent factors (passcodes, observation angles, number of views, and attempts). For
recruitment, the primary results were based oﬀ participants on Amazon Mechanical Turk (n = 1173) and
participants recruited locally (n = 91), with both groups completing a web survey whereby they viewed
videos of authentication and attempted to recreate the passcodes observed.
Using the results, the authors tested the following hypotheses (the -p indicates a prior work hypothesis):
• H1-p: The type of unlock authentication, PIN pattern with lines, patterns without lines, aﬀects the
shoulder surﬁng vulnerability.
• H2-p: Repeated viewing of user input increases the likelihood of a shoulder surﬁng vulnerability.
• H3-p: Multiple attempts to recreate the input aﬀects the likelihood of a shoulder surﬁng vulnerability.
• H4-p: The angle of observations aﬀects shoulder surﬁng vulnerability.
• H5-p: The properties of the unlock authentication, such as length and visual features, aﬀect shoulder
surﬁng vulnerability.
• H6-p: The phone size aﬀects shoulder surﬁng vulnerability.
• H7-p: The hand position used to hold and interact with a device aﬀects shoulder surﬁng vulnerability.
Of those hypotheses, H1-p, H2-p, H3-p, H4-p, and H6-p were accepted, while H5-p was partially ac-
cepted, and H7-p was rejected. The authors claim that the video studies, generally, can form a reasonable
replacement for live simulation, and that at the very least a video study could provide a baseline for shoulder-
surﬁng vulnerability.
3 Methodology
To investigate the eﬃcacy of video-based recreations for evaluating observation attacks, we recreated the
study conducted by Aviv et al. [4] with live participants in a controlled lab environment. We asked partic-
ipants to position themselves in similar locations to where the cameras were positioned in the prior study.
3
They then attempted to shoulder-surf a victim (played by a proctor). We varied the type and length of
authentication sequences, observation angle, and number of repeated viewing attempts, to determine if these
factors impact the success of the attacker. The results were then compared with Aviv et al.’s ﬁndings using
a comparable subset of the prior data. For simplicity of discussion, we refer to the prior work of Aviv et al.
as the video study and the results here as the live study.
Hypotheses
video based shoulder surﬁng experiments as compared to live settings.
In particular, we are interested in testing the following hypothesis related to the eﬃcacy of
• H1-r: Live shoulder surﬁng conﬁrms accepting prior hypotheses:
– H1-p: The authentication type aﬀects shoulder surﬁng vulnerability
– H2-p: Repeated viewing aﬀects shoulder surﬁng vulnerability
– H4-p: The angle of observation aﬀects shoulder surﬁng vulnerability
– H5-p: The properties of the passcodes aﬀects should surﬁng vulnerability
• H2-r: Video simulation forms a baseline of performance compared to live settings.
3.1 Study Design and Materials
Treatments The study followed a mixed factorial design, similar to the video study. Independent variables
included authentication type (PIN vs pattern) on the Nexus 5 device using the same hand posture/interaction
style (one-handed, right thumb input). For dependent variables, we reduced the observation angle to two
(left or right) as opposed to the ﬁve angles used in prior work. The video study used the variety of angles
to simulate diﬀerent heights, but height variation is naturally present in a live study. We kept the same
variables for observations (single observation from one angle, two observations from the same angle, or two
observations from diﬀerent angles), and we used a lab environment for our live study very similar to the
set-up to capture videos for the video study (Aviv et al.) (see Figure 1).
There were two notable diﬀerences between factors in the video study and the live study. First, we only
allowed each participant a single attempt at recreating the passcode. This choice was motivated by results
of the video study whereby participants, knowing they would have multiple attempts in advance, actually
did worse at the tasks than those that knowingly had one attempt. It was conjectured that participants
attempted to “game” the task knowing that they would have multiple attempts at recreating the passcode.
As such, we only allowed participants to make one recreation attempt, and this fact was communicated
during training.
Another diﬀerence in the live study was that passcode recreation occurred using pen-and-paper, as
opposed to a simulation of the device used in the video study. This choice was made to simplify the data
collection procedures for both proctors and participants.
Finally, as we only tested a subset of the treatments of the prior video study, we only performed our
analytic comparisons on a relevant subset of the video study data.
In particular, we removed data that
included a top angle and reduced the two side angles into a single left or right setting. Additionally, as the
video cannot control for monitor display size, which was a large factor in the prior results, we only used
the most ideal viewing conditions, where the reported y-axis pixels were greater than 1800. We believe this
restriction provided the most fair comparisons possible given the potential uncontrolled factors. We discuss
limitations and realism further in Section 4.
Authentication types We analyzed three authentication types with two diﬀerent length settings, as used
in the video study. These included:
• PIN: 4- or 6-length PINs consisting of a set of numbers.
• PAT: Android unlock patterns consisting of 4 or 6 contact points with the feedback lines present.
4
Auth. id Patterns PINs
0
1
2
3
4
5
6
7
8
9
0145
014763
1346
136785
3157
4572
642580
6745
743521
841257
1328
153525
159428
1955
366792
441791
458090
5962
6702
7272
Table 1: Authentication identiﬁers for patterns and PINs. To the right, the numeric labeling for patterns to
contact points.
• NPAT: Android unlock patterns consisting of 4 or 6 contact points without the feedback lines present.
While the PIN interaction display is as one expects, the presence or absence of grid pattern feedback lines is
less well known. When a pattern is entered with feedback lines (PAT), the display will show connecting lines
on the screen between grid points touched by the user while entering their passcode shape. Alternatively,
the connecting lines are not rendered on screen during passcode entry in the without feedback lines (NPAT)
pattern display, although the user must still contact the appropriate points in the correct order. As identiﬁed
by Aviv et al. [4] and von Zezschwitz et al. [25], the absence of feedback lines can make it more diﬃcult for
an observer to recreate the patterns. As part of H1-r, we will make a similar evaluation.
To maintain consistency, we used the same set of patterns and PINs as in prior work (Table 1 and
Appendix B.1). The patterns were selected from an online study of self-reported patterns [3], and the PINs
were obtained from sequences of digits in leaked password sets, similar to the analysis by Bonneau et al. [5].
Further, the set of passcodes were selected for physical properties, as the layout and sequence of gestures in
entry may aﬀect shoulder surﬁng attack rate. The patterns’ spatial properties might aﬀect surﬁng attacks
because an attacker’s view from some viewing angles might be obscured for some parts of the touchscreen.
Randomization and counterbalancing One of the restrictions for performing the study using live
participants as compared to video recreation is that the same level of randomization is nearly impractical
for the target recruitment size and the set of factors being considered. As such, we designed a two stage
randomization procedure, one for ordering the passcodes and one for ordering the observation angles.
In particular, Table 2 contains three diﬀerent randomized orders across the passcode. These are labeled
Order a, b, and c. Note that the authentication identiﬁers refer to Table 1. In Table 3 are four randomized
orders for observation angles (i, ii, iii, and iv). For each participant, we randomly assigned them a passcode
order and an observation angle, producing 12 diﬀerent randomizations.
At this point, it is important to consider counterbalancing. Selecting randomized orders for passcodes or
observations can weight the data improperly. This leads to an optimization problem, and we used a utility
function to ﬁnd a set of randomized orders that would provide (1) suﬃcient data in each factor for us to
perform statistical tests, (2) a roughly equal ratio of data within each factor being compared (4- vs 6-length,
auth-type, angle), (3) that each passcode only appears once per viewing, and (4) that within each viewing
sequence, per participant, there are roughly an equal number of single and multiple observations. We found
a case that nearly met these criteria, as displayed in Table 2 and 3. The weighting is then displayed based
on 12 participants in Table 4, leaving us with 72 single-view observations and 48 multi-view observations,
24 from the same angle twice and 24 from two diﬀerent angles. Additionally, there is equal weighting across
angles and viewing (Table 3), and nearly equal weighting across passcodes.
We acknowledge that this counterbalancing is not a perfect weighting, and solving this particular op-
timization problem is challenging and may not have a solution. However, the resulting counterbalancing
compares favorably to the subset of relevant video study data. For PINs, there is nearly an equal number
5
Order
Auth. id
a
b
c
8
0
6
1
6
0
0
3
9
7
8
4
9
2
8
2
4
3
6