# Comparing Video-Based Shoulder Surfing with Live Simulation

**Authors:**
- Adam J. Aviv†
- Flynn Wolf⋄
- Ravi Kuber⋄

**Affiliations:**
- † United States Naval Academy
- ⋄ University of Maryland, Baltimore County

**Contact:**
- PI: EMAIL {flynn.wolf, rkuber}@umbc.edu

**Date:**
- September 25, 2018

## Abstract

We evaluate the claim that video recreations of shoulder surfing attacks provide a suitable alternative and baseline compared to live settings. We recreated a subset of the factors from a previous video-simulation experiment by Aviv et al. (ACSAC 2017) and modeled the same scenario using live participants (n = 36). The live experiment confirmed that for Android's graphical patterns, video simulation is consistent with the live setting in terms of attacker success rates. However, for 4- and 6-digit PINs, there were statistically significant differences, with live attackers performing up to 1.9 times better than in the video simulation. The security benefits of removing feedback lines in Android's graphical patterns were also greatly diminished in the live setting, particularly under multiple attacker observations. Overall, the data suggests that video recreations can provide a suitable baseline measure for attacker success rate, but researchers should be cautious as these baselines may underestimate the threat in live settings.

## 1. Introduction

Biometric authentication mechanisms offer significant promise for smartphone users. However, the protection of unlock authentication still relies on choosing hard-to-guess passcodes (e.g., PINs and unlock patterns) while not revealing them to untrusted parties. A common means of attack for gaining access to these passcodes is through shoulder surfing, where an observer attempts to view a victim entering their passcode with the intention of recreating it after gaining possession of the device [26].

The area of shoulder surfing has been extensively studied [10, 12, 19, 8, 6, 7, 9, 18, 13, 4]. This study focuses on the work conducted by Aviv et al. [4], which examined the shoulder surfing susceptibility of three commonly used unlock authentication mechanisms: 4- and 6-digit PINs, 4- and 6-length Android graphical patterns, and 4- and 6-length Android graphical patterns with feedback display turned off. Due to the difficulty of evaluating shoulder surfing attacks in the field, the goal was to establish baselines for shoulder surfing vulnerability in controlled settings that can be used to compare across authentication types and as a baseline for evaluating authentication systems designed to defend against such attacks.

In this paper, we compare the video-based methodology to a similarly controlled live setting. Specifically, we assess the following findings from the prior work:

- Longer authentication lengths (e.g., 4-digit vs. 6-digit PINs) are less vulnerable.
- PIN authentication is less vulnerable to the attack compared to patterns with and without feedback lines.
- Removing the feedback lines from patterns decreases the vulnerability to shoulder surfing.
- Multiple observations increase vulnerability.
- Video-based evaluation provides a baseline for live, in-person shoulder surfing vulnerability.

Using the raw results of the prior study, we compare the attacker success rates in the live setting to a comparable subset of the video study data. Our analysis shows consistency between the results of the video and live simulations for Android patterns and many settings with patterns without feedback lines. However, the advantage of removing feedback lines observed in the video simulation is considerably lessened in the live setting. For PINs, we observe significant differences, with live attackers performing up to 1.9 times better in some scenarios. Despite this discrepancy, the claim that these results form a baseline is supported: we never observed a situation where the live simulation performed worse than the video study when significant differences exist.

We conclude that video studies provide a reasonable approximation for live simulation of shoulder surfing in settings involving graphical passwords (but not PINs), like the Android password pattern, and at least a lower-bound on the attack success rate for all tested authentication types (including PINs). However, researchers should consider that this lower-bound may be a significant underestimation compared to the true attack rate in live simulations.

## 2. Related Work

### Mobile Authentication and Observation Attacks

Threats such as shoulder surfing have been well documented by researchers [27, 4]. Studies have examined user experiences with observation attacks [11], finding that shoulder surfing is often "casual" and "opportunistic." Harbach et al. [14] found that participants rarely reported shoulder surfing (0.3% of 1134 sampled events) as an immediate high-risk threat during authentication.

To minimize the risk associated with observation attacks, users modify their usage behaviors, such as hiding the device from sight, performing mobile interactions in a pocket or bag, or shielding the screen [1]. Solutions also exist to obscure screens from third parties [8], detect the presence of shoulder surfers [20], or deceive onlookers [24, 17]. Attacks have been simulated by having observers watch video footage of victims entering authentication sequences [15]. A range of solutions has been proposed to minimize the likelihood of shoulder surfing [2]. However, comparing the efficacy of these solutions is challenging due to varying study methods and outcomes [27].

### Evaluating Resistance to Shoulder Surfing

Many evaluation studies have focused on observing unlock screen interactions where PINs and patterns are entered [22, 4, 15]. Wiese and Roth [27] suggest that conducting such studies is challenging because real-world adversaries are not available for study and must be simulated. In contrast to live studies, video simulations offer consistency when presented to multiple users [27] and can be accessed independent of location. However, research indicates that the success of adversaries is lower in video observations compared to live settings [23, 27]. Prior research recommends that shoulder surfing attackers should be allowed multiple observations [27] and viewing interactions from various angles [21, 4]. Additionally, hand position [22] and interaction style [4] should be considered.

### Overview of Aviv et al. [4]

Aviv et al. addressed the lack of a baseline for comparing common unlock authentication mechanisms under the threat of shoulder surfing. They used controlled video simulations of a victim entering unlock authentications using several methods, including PINs and Android's graphical pattern unlock, with and without feedback lines. Additional factors included observation angle, number of observations, number of recreation attempts, hand posture, phone size, and spatial layout of passcodes.

The methodology was multi-factorial, with participants selected into one of several independent factors (phone type, passcode choice, authentication type, hand posture) and randomized dependent factors (passcodes, observation angles, number of views, and attempts). Participants were recruited from Amazon Mechanical Turk (n = 1173) and locally (n = 91), completing a web survey where they viewed videos of authentication and attempted to recreate the passcodes.

The authors tested the following hypotheses:

- H1-p: The type of unlock authentication affects shoulder surfing vulnerability.
- H2-p: Repeated viewing of user input increases the likelihood of a shoulder surfing vulnerability.
- H3-p: Multiple attempts to recreate the input affect the likelihood of a shoulder surfing vulnerability.
- H4-p: The angle of observation affects shoulder surfing vulnerability.
- H5-p: The properties of the unlock authentication, such as length and visual features, affect shoulder surfing vulnerability.
- H6-p: The phone size affects shoulder surfing vulnerability.
- H7-p: The hand position used to hold and interact with a device affects shoulder surfing vulnerability.

Hypotheses H1-p, H2-p, H3-p, H4-p, and H6-p were accepted, while H5-p was partially accepted, and H7-p was rejected. The authors claimed that video studies can form a reasonable replacement for live simulation and provide a baseline for shoulder surfing vulnerability.

## 3. Methodology

To investigate the efficacy of video-based recreations for evaluating observation attacks, we recreated the study conducted by Aviv et al. [4] with live participants in a controlled lab environment. Participants positioned themselves in similar locations to where the cameras were positioned in the prior study and attempted to shoulder surf a victim (played by a proctor). We varied the type and length of authentication sequences, observation angle, and number of repeated viewing attempts to determine if these factors impact the success of the attacker. The results were then compared with Aviv et al.’s findings using a comparable subset of the prior data. For simplicity, we refer to the prior work of Aviv et al. as the video study and the results here as the live study.

### Hypotheses

- **H1-r:** Live shoulder surfing confirms the acceptance of prior hypotheses:
  - H1-p: The authentication type affects shoulder surfing vulnerability.
  - H2-p: Repeated viewing affects shoulder surfing vulnerability.
  - H4-p: The angle of observation affects shoulder surfing vulnerability.
  - H5-p: The properties of the passcodes affect shoulder surfing vulnerability.
- **H2-r:** Video simulation forms a baseline of performance compared to live settings.

### 3.1 Study Design and Materials

#### Treatments

The study followed a mixed factorial design, similar to the video study. Independent variables included authentication type (PIN vs. pattern) on the Nexus 5 device using the same hand posture/interaction style (one-handed, right thumb input). Dependent variables included observation angle (left or right), number of observations (single observation from one angle, two observations from the same angle, or two observations from different angles), and a lab environment similar to the setup used to capture videos for the video study (see Figure 1).

There were two notable differences between the video study and the live study:

1. **Single Attempt at Passcode Recreation:** Each participant was only allowed a single attempt at recreating the passcode. This choice was motivated by results from the video study, where participants who knew they would have multiple attempts actually performed worse than those who had only one attempt. It was conjectured that participants attempted to "game" the task knowing they would have multiple attempts. Therefore, we only allowed one recreation attempt, and this fact was communicated during training.
2. **Pen-and-Paper Recreations:** Passcode recreation occurred using pen and paper, as opposed to a simulation of the device used in the video study. This choice simplified the data collection procedures for both proctors and participants.

Finally, as we only tested a subset of the treatments from the prior video study, we only performed our analytic comparisons on a relevant subset of the video study data. We removed data that included a top angle and reduced the two side angles into a single left or right setting. Additionally, as the video cannot control for monitor display size, which was a large factor in the prior results, we only used the most ideal viewing conditions, where the reported y-axis pixels were greater than 1800. We believe this restriction provided the most fair comparisons possible given the potential uncontrolled factors. Limitations and realism are discussed further in Section 4.

#### Authentication Types

We analyzed three authentication types with two different length settings, as used in the video study:

- **PIN:** 4- or 6-length PINs consisting of a set of numbers.
- **PAT:** Android unlock patterns consisting of 4 or 6 contact points with feedback lines present.
- **NPAT:** Android unlock patterns consisting of 4 or 6 contact points without feedback lines present.

While the PIN interaction display is as expected, the presence or absence of grid pattern feedback lines is less well known. When a pattern is entered with feedback lines (PAT), the display shows connecting lines on the screen between grid points touched by the user. Alternatively, the connecting lines are not rendered on screen during passcode entry in the without feedback lines (NPAT) pattern display, although the user must still contact the appropriate points in the correct order. As identified by Aviv et al. [4] and von Zezschwitz et al. [25], the absence of feedback lines can make it more difficult for an observer to recreate the patterns. As part of H1-r, we will make a similar evaluation.

To maintain consistency, we used the same set of patterns and PINs as in prior work (Table 1 and Appendix B.1). The patterns were selected from an online study of self-reported patterns [3], and the PINs were obtained from sequences of digits in leaked password sets, similar to the analysis by Bonneau et al. [5]. The set of passcodes was selected for physical properties, as the layout and sequence of gestures in entry may affect shoulder surfing attack rates. The patterns' spatial properties might affect surfing attacks because an attacker's view from some viewing angles might be obscured for some parts of the touchscreen.

#### Randomization and Counterbalancing

One of the restrictions for performing the study using live participants, compared to video recreation, is that the same level of randomization is nearly impractical for the target recruitment size and the set of factors being considered. Therefore, we designed a two-stage randomization procedure, one for ordering the passcodes and one for ordering the observation angles.

Table 2 contains three different randomized orders across the passcodes, labeled Order a, b, and c. Table 3 includes four randomized orders for observation angles (i, ii, iii, and iv). For each participant, we randomly assigned a passcode order and an observation angle, producing 12 different randomizations.

Counterbalancing is important to avoid weighting the data improperly. We used a utility function to find a set of randomized orders that would provide (1) sufficient data in each factor for statistical tests, (2) a roughly equal ratio of data within each factor being compared (4- vs. 6-length, auth-type, angle), (3) each passcode appearing only once per viewing, and (4) roughly an equal number of single and multiple observations within each viewing sequence per participant. We found a case that nearly met these criteria, as displayed in Tables 2 and 3. The weighting is based on 12 participants, leaving us with 72 single-view observations and 48 multi-view observations, 24 from the same angle twice and 24 from two different angles. Additionally, there is equal weighting across angles and viewing (Table 3), and nearly equal weighting across passcodes.

We acknowledge that this counterbalancing is not perfect, and solving this particular optimization problem is challenging and may not have a solution. However, the resulting counterbalancing compares favorably to the subset of relevant video study data. For PINs, there is nearly an equal number of observations.

| **Order** | **Auth. id** |
|-----------|--------------|
| **a**     | 8            |
|           | 0            |
|           | 6            |
|           | 1            |
| **b**     | 6            |
|           | 0            |
|           | 0            |
|           | 3            |
| **c**     | 9            |
|           | 7            |
|           | 8            |
|           | 4            |
|           | 9            |
|           | 2            |
|           | 8            |
|           | 2            |
|           | 4            |
|           | 3            |
|           | 6            |

**Table 1: Authentication identifiers for patterns and PINs. To the right, the numeric labeling for patterns to contact points.**

**Note:** The remaining tables (Tables 2, 3, and 4) are referenced in the text but not included here. They contain the detailed randomization and counterbalancing information.