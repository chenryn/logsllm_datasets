to print and DACODA discovers no predicate. This causes
DACODA to discover strong equality predicates for that in-
dividual “9” if and only if the value on the stack being eaten,
which for all practical purposes is random, consumes 9 char-
acters when interpreted as a ﬂoating point number without
trailing zeroes. The long tokens discovered for the wu-ftpd
format string attack in Table 5 are not a good signature but
rather represent the fact that a long sequence of data words
on the stack require 9 characters to be printed as ﬂoating
points (including the leading space).
In the Apache exploit the chunked encoding tokens can
use any character allowed by the chunked encoding portion
of the HTTP protocol, but DACODA discovers predicates
because whatever character is used is converted to lower
case and compared with a whole array of characters until it
is found.
For the innd exploit DACODA generates a token “test”
as these letters are individually checked against a d entry
in the directory containing the various newsgroups on that
news server. This token is discovered in the kernel space in
the function d lookup(). The “test” newsgroup is guaran-
teed to be there but there is no requirement that the attacker
post the original message to this group. The attacker might
ﬁrst log into the news server to request a list of newsgroups
on that server and choose a diﬀerent group every time. Thus
the token “test” generated by DACODA is not guaranteed
to be in every exploit for this vulnerability.
One interesting behavior of the Turkey exploit is that it
creates several ﬁles or directories with long ﬁlenames and
then uses these ﬁles or directories in some way. This would
cause DACODA to discover very long tokens for these ﬁle-
names (equality between the ﬁle name used for creation and
the ﬁle name used for accessing), except that we added a
heuristic that DACODA does not include strong, explicit
equality predicates between two labeled symbolic expres-
sions that are both from the attacker.
4.3.7 Lack of a Good Signature for Some Exploits
It is diﬃcult to generalize to a signature for a vulnerability
when there is not even a good signature for the exploit.
For Slammer the only byte string signature not susceptible
to simple polymorphic techniques is the ﬁrst byte in the
UDP packet, “0x04”. This byte is common to all SQL name
resolution requests. The bogus return pointer also has to
be a valid register spring and another pointer must point
to any writable memory location, but these are not strong
predicates. The SQL authentication exploit does not oﬀer
much in terms of a signature, either.
The Apache chunk handling exploit,
like the wu-ftpd
format string exploit, has erroneous predicates in Table 5.
This means that all of the tokens with four bytes or
more, except the chunked encoding token, are actually
not invariant,
leaving mostly dots, slashes, dashes, and
the new line character, all of which are not uncommon
in HTTP traﬃc. This does not oﬀer a very good in-
variant signature for content ﬁltering; only the token
“\x0d\nTransfer-Encoding:\x20chunked\x0d\n\x0d\n”
which would block a valid portion of the HTTP pro-
tocol.
In the ntpd exploit both 4-byte tokens are
“\x00\x00\x00\x00” which is not uncommon content on
any port. The longest token, 8 bytes long, is “stratum=”
which probably is not uncommon for traﬃc on UDP port
123.
We did not test any ASN.1 vulnerabilities, but these serve
as good examples of just how polymorphic  could be. The
ASN.1 library length integer overﬂow [52, bid 9633] basically
has a signature of “\x04\x84\xFF\xFF\xFF”. The rest of 
in this case is identical to any NTLM request over SMB
carrying an ASN.1 encoded security token. In fact, the ﬁrst
445 bytes of all ASN.1 exploits through NTLM [52, bids
9633, 9635, 9743, 10118, 13300] and the Workstation Service
[52, bid 9011] exploit are identical. This initial part of the
exploit vector is not a good signature unless it is desired
that all NTLM requests carrying ASN.1 security tokens be
prevented. Furthermore, the Workstation Service results
from Table 5 show that the longest string of invariant bytes
in this 445-byte sequence is only 23 bytes long. Two other
ASN.1 vulnerabilities [52, bids 9635, 13300] have no byte
string signature at all to describe them.
As far as purely network-based signature generation meth-
ods with no host context, which lack vulnerability informa-
tion for generalizing observed exploits and predicting future
exploits, not a lot of polymorphism is required for a worm
not to be detected. Discounting the very long wu-ftpd for-
mat string and Turkey tokens which are errors, only one of
the 14 exploits has a token of more than 40 bytes. The num-
ber 40 is signiﬁcant since it is the minimum signature size
that the ﬁrst implementation of EarlyBird [37] can discover.
A similar result is shown in Section 4.2 of Kim and Karp [21]
where the ability to generate signatures falls dramatically
when less than 32 bytes of contiguous invariant content are
present, which is true for 10 of the 14 exploits in Table 5.
Thus EarlyBird and Autograph, in their current implemen-
tations, would not be eﬀective against polymorphic versions
of between 10 and 13 of the 14 exploits analyzed in this
paper.
5. POLY/METAMORPHISM
Based on the results in the previous section, we would
now like to formalize polymorphism and metamorphism in
. To be more perspicuous in doing so, and also to guide
future work, we describe a model to encompass complexi-
ties such as multiple processes, multithreading, and kernel
processing of network data by viewing control ﬂow hijacking
attacks “from-the-architecture-up.” In this way interprocess
communication and context switches are viewed simply as
physical data transfers in registers and memory. The Physi-
cal Data Requires-Provides model, or PD-Requires-Provides
model, is a requires-provides model [39] for physical data
transfers where the focus is on primitives, not vulnerabili-
ties, for reasons that will be discussed in this section.
First we wish to confute the idea that there is a single
user-space process that is vulnerable and the attacker opens
a TCP connection directly to this process to carry out the
exploit. Of the 14 exploits analyzed in Section 4, six in-
volve multiple processes, ﬁve involve a signiﬁcant number
of predicates discovered in kernel space, and seven exploit
processes that contain multiple threads and are accessible
through multiple ports.
The purpose of an exploit is to move the system being
attacked from its initial state to a state where control ﬂow
hijacking occurs. The series of states the attacker causes the
system to traverse from the initial state to control ﬂow hi-
jacking is the attack trace. The attacker causes this traversal
of states by sending some set of IP packets that are projected
onto the trace of the vulnerable machine as they are inter-
preted by the protocol implementation on that machine.
The attacker must prevent a satisfactory characterization
of the worm traﬃc by varying bytes in the row spaces of the
three projections that do not have a strong equality predi-
cate required of them (polymorphism) or changing the map-
pings for each infection (metamorphism). In past work [14]
we showed that there is a high degree of polymorphism and
metamorphism available to the attacker for both γ and π,
so we will focus here only on the subject of this paper: .
5.1 What are Poly- and Metamorphism?
What do we mean when we say polymorphism and meta-
morphism in ?
5.1.1 Polymorphism of 
Some bytes mapped by  by deﬁnition are not actually
what one might think of when discussing  but should be
mentioned for completeness. Filler bytes that serve no other
purpose than to take up space, such as the “XXXXXXX...”
string of bytes in Code Red II, are usually in  but have
no strong equality predicate required of them. Usually their
placement in  is only because it is required that they are
not equal to a NULL terminator or an end of line character,
or that they must be printable ASCII characters.
5.1.2 Metamorphism of 
We will discuss two kinds of metamorphism: without mul-
tithreading and with multithreading. Metamorphism is the
more fundamental challenge for DACODA since DACODA
is based on symbolic execution of one attack trace and meta-
morphism in  changes the attack trace.
Without multithreading, there are multiple ways to tra-
verse from the initial state to the control ﬂow hijacking. The
three ways of changing this trace are:
1. Take an equivalent path: In format string attacks “%x”
and “%u” take diﬀerent paths but converge so for prac-
tical purposes the traces are the same. A couple of ex-
amples from the Code Red II exploit are “.ida” versus
“.idq” or the fact that the UNICODE encoding es-
cape sequence “%u” can appear anywhere in the GET
request between “?” and “=”.
2. Add paths that are unnecessary: In the Hannibal attack
for the wu-ftpd format string vulnerability the attacker
can, after logging in but before carrying out the actual
attack, use valid FTP commands that are not useful
except that DACODA will discover predicates for them
as they are parsed. Pipelining in HTTP 1.1 allows
for similar behavior as was pointed out in Vigna et.
al. [42].
3. Changing the order: In addition to adding paths that
are not relevant to the exploit, sometimes paths rele-
vant to the exploit can be arranged in a diﬀerent order.
What we need to understand metamorphism is a partial
ordering on the bytes from the range of . This partial order-
ing could help us determine that, for example, the Code Red
II buﬀer overﬂow is not reachable except through a path in
which the token “%u” is discovered, and that “.ida?” must
come before this token and “=” must come after. It would
also show that “GET” must be “GET” and not “GTE” or “TEG”.
For generating a signature the partial ordering will reveal
which tokens are not necessary for control ﬂow hijacking to
occur, which tokens can be replaced with other tokens (this
will require further analysis such as model checking), and
will identify any ordering constraints on those tokens that
must occur.
The requires-provides model for control ﬂow hijacking at-
tacks could be as simple as a control ﬂow graph for the whole
system. The problem with this is that an attacker with the
ability to corrupt arbitrary memory with two threads in the
same process can subvert the most basic assumptions (for
example, that if a thread sets a local variable to a value it
will have the same value until the thread modiﬁes it again).
We need a model that can handle multithreading, but ﬁrst
we need to try to understand what a vulnerability-speciﬁc
signature would need to encompass. To do this we have to
discuss what a vulnerability is.
5.2 What is a vulnerability?
What causes a sequence of network packets to be a control
ﬂow hijacking attack, the vulnerability, is very subjective.
For buﬀer overﬂow exploits it is the fact that a particular
ﬁeld exceeds a certain length;
in the case of Slammer it
is the length of the UDP packet itself, and for the Turkey
exploit the allowable length is exceeded by only one byte.
For double free() and dangling pointer exploits the exploit is
usually caused because a certain token appears twice when
it should appear once or is nested such as the constructed
bit strings of the ASN.1 dangling pointer vulnerability [52,
bid 13300]. Format string write attacks are caused by the
presence of a token “%n”. Integer overﬂows occur because a
particular integer is negative.
One last example puts this problem in perspective. The
Code Red II buﬀer overﬂow only occurs when at least one
“%u” token is present which expands all of the ASCII char-
acters to 2 bytes, and the “u” character as well as numbers
are certainly acceptable in a normal URI. Changing a single
bit in the ASCII sequence “eu1234” creates “%u1234”, so the
Hamming distance between a valid ASCII GET request of
acceptable length and one with a single UNICODE-encoded
character that causes a buﬀer overﬂow is only one bit! Fur-
thermore, UNICODE encodings in GET requests of normal
length are certainly valid within the HTTP protocol or else
they would not have been implemented.
There are two ways to create a signature that covers
a wide enough set of exploits to be called “vulnerability-
speciﬁc.” One is to add more precision to the signature
and use heuristics within the signature generator to look at
not only tokens but, for example, also the lengths of ﬁelds.
Slammer could be stopped by dropping all UDP packets to
port 1434 that exceed a certain length. Code Red II could
be stopped by dropping all HTTP requests with UNICODE
encodings that exceed a certain length. The problem with
the Code Red II example is that it requires a lot of parsing
of HTTP commands by the network content ﬁlter. This is
even worse in the case of Scalper because the Apache chunk
handling exploit only occurs when a particular integer is
negative.
The second way to generate signatures is to relax the
requirement that no portion of a valid protocol be dropped.
In the Code Red II example above, we could simply
drop all HTTP requests with UNICODE encodings since
normal HTTP traﬃc typically will not use them. For
Scalper we could drop all HTTP traﬃc with the token
“\x0d\nTransfer-Encoding:\x20chunked\x0d\n\x0d\n”
which will not allow any chunked encodings, and is in fact
the rule that Snort [53] uses.
In other words, it may be
acceptable to block a valid portion of a protocol (or even
an entire protocol by blocking its ports) if that portion is
not often used by legitimate traﬃc. Most vulnerabilities
are discovered in code that is not frequently used. These
coarse responses may sometimes be the most eﬀective, but
the challenge is knowing, upon capturing an exploit for an
unknown vulnerability, that the protocol involved or the
speciﬁc part of it where the vulnerability lies is rarely used,
something that would need to be proﬁled over a long period
of time.
The ﬁrst of these alternatives leaves us “on the horns of
a dilemma” [49] in terms of false positives and false nega-
tives without a detailed semantic understanding of how the
exploit works. It also is not amenable to byte string signa-
tures, even those based on small sets of tokens, so something
more semantically rich will have to be devised. This is the
challenge that we hope to address in future work.
The second alternative will create a great number of false
positives if the worm exploits a vulnerability that is in a part
of a protocol that is used often. This is because nearly all
of the tokens in Table 5 are protocol framing and not related
to the actual vulnerability. Buﬀer overﬂows have been found
in Microsoft libraries for both JPEG parsing [50, MS04-028]
and JPEG rendering [50, MS05-038]. If a worm exploited
such vulnerabilities, it would create many false positives if
the worm content ﬁltering mechanism blocked all HTTP
responses containing JPEGs.
5.3 The PD-Requires-Provides Model
Metamorphic techniques that use arbitrary memory cor-
ruption primitives in multithreaded applications to build
complex exploits require a model that views the system from
the same perspective as the attacker will: the raw machine.
This “from-the-architecture-up” view of the system will al-
low us to abstract away system details that lead to assump-
tions that the attacker can invalidate. This is the motivation
behind the PD-Requires-Provides model.
5.3.1 Requirements and What They Provide
An attacker can only cause a state transition along the
attack trace through the execution of a machine instruction
that uses data from the range of . We will assume a Pen-
tium processor and a sequential consistency memory model.
Although the Pentium uses a processor consistency model
and multiprocessing is becoming more and more common,
it may be too pessimistic at this time to assume that the
attacker could exploit a race condition between the mem-
ory and the write buﬀers of two high speed processors.
It should be noted, however, that race conditions between
threads have been demonstrated to permit remote code ex-
ecution [47].
Treating each machine instruction that is executed as an