discomforting to most individuals.
3
Fig. 2: The above ﬁgure shows the different perturbation techniques applied to the original signal (a). Signals (b) to (e) show
the result of applying the perturbation schemes to (a).
We can take advantage of psychoacoustics to better perturb
voice commands. We discuss our use of psychoacoustics more
in Section VII.
III. HYPOTHESIS
Human speech provides a limited set of features for training
and testing ASR models: most aspects of speech are ﬁltered
out during preprocessing or feature extraction algorithms. This
reduced subset of the original input is passed as a feature
vector onto the model for training or testing. This provides
opportunities to introduce acoustic artifacts, via perturbation,
to the audio. Such artifacts are removed during the signal
processing steps. By using knowledge about psychoacoustics
and the physical characteristics of audio, we can develop
attack audio that is agnostic of any particular machine learning
model. While these artifacts will make human interpretability
of the audio difﬁcult, they will have no impact on the ASR’s
recognition ability, leaving ASRs exposed to hidden voice
command attacks.
IV. METHODOLOGY
We develop perturbations to generate attack audio that
is uninterpretable by the user, but correctly inferred by the
VPS. This section describes the attack scenario, the capabilities
required to conduct a successful attack, perturbation schemes
that generate attack audio samples, and the VPSes we tested
the attacks against.
A. Attack Scenario
An adversary wants to execute an unauthorized command
on a VPS (e.g., Amazon Alexa, Google Home Assistant, or
any voice activated device). To do so, the adversary plays
an obfuscated audio command in the direction of the VPS.
The target VPS uses an ASR internally to transcribe the
audio commands in order to execute them. In addition to the
ASR, the VPS can also use a speaker identiﬁcation model to
authenticate the speaker before executing the command. The
obfuscated audio could contain orders for example to initiate a
wire-transfer, unlock door, or generally cause the execution of
functionality available to a legitimate user. The attack audio is
played via a compromised IoT device or directional speaker.
Although the owner of the target VPS may be within audible
range, they will not recognize the attack audio as a voice
command. Hence, the owner will remain unaware that an attack
is in progress.
An attack against these systems will occur based on the
standard exploit development, probe, and attack strategy. That
is, we expect an attacker to develop a corpus of attack audio
that successfully activates one or more models. They will
then probe a potential target, learning which model they are
targeting either through direct information or via probing. The
adversary will then select sample attack audio from its corpus
and execute the attack.
B. Threat Model
We assume no knowledge of the model (i.e., black-box
attack). The attacker does not need to know the type or internal
architecture of the victim model (i.e., the number of layers or
the internal weights). However, the adversary is familiar with
audio and speech processing.
Our attack generates noise-like attack audio that will be
effective against VPSes: in transcription tasks, the perturbed
audio is transcribed the same as original unperturbed audio,
while in identiﬁcation tasks,
identify the
perturbed audio as the voice of the original speaker. The
perturbation methods are designed to exploit assumptions that
VPSes make about acoustic properties.
the system will
In transcription tasks,
the adversary has a sample of
correctly transcribed audio. Similarly, for attacking a speaker
model, the adversary has a voice sample of the victim speaker
that the target VPS will correctly identify. The perturbation
methods are designed to maintain the normal audio sample’s
important acoustic properties while altering its audible per-
ception. If the audio sample is incomprehensible to the target
model without the perturbation, it will remain so with the
perturbation. The threat model is designed to emulate that
4
of previous attack papers, speciﬁcally Carlini et al [24]. The
attacker is not located in the room, but is able to use the
speaker remotely. The victim is in close vicinity of the attack
speakers but is not actively listening for or expecting an attack.
The victim might hear the attack audio, but
is unable to
decipher it, thus would not know that an attack is in progress.
The attacker has no knowledge of the acoustic hardware
used by the victim. We assume that
target ASR is close
to the attack speaker. Homes are being equipped with an
increasing number of speaker enabled IoT devices. This num-
ber is expected to rise in order for users to be able to
continuously interact with the home assistant during their daily
routine throughout the house. These speakers can be exploited
remotely and then used by the attacker to play the attack audio.
Additionally, the victim ASR devices, like Alexa, have an array
of high quality microphones that can detect audio from a wide
variety of locations and angles. In order to accommodate for
the above factors, we assume that the target ASR is one foot
away from the attack speaker.
C. Types of Perturbations
We propose four perturbation techniques. Each resulting
attack sample includes one or more perturbations applied in
succession which can be used against the target VPS. We use
Figure 2 as an exemplar source and show each perturbation
detailed below.
1) Time Domain Inversion (TDI): Most VPSes use FFTs
(Figure 1c) to decompose a signal into its composite frequen-
cies, called a spectrum. The FFT is a many-to-one function.
This means two completely different signals in the time
domain can have similar spectra. Our TDI perturbation method
exploits this property by modifying the audio in the time
domain while preserving its spectrum, by inverting the win-
dowed signal. As shown in Figure 2b, inverting small windows
across the entire signal removes the smoothness. Due to the
principles of psychoacoustics, this perturbed audio is difﬁcult
to understand as the human ear interprets any discontinuous
signal as noisy [42].
2) Random Phase Generation (RPG): For each frequency
in the spectrum, the FFT returns the value in complex form
a0 + b0i, where a0 and b0 deﬁne the phase of a signal. To get
the intensity at each frequency, the magnitude (Figure 1d) of
the complex spectrum is taken to yield a magnitude spectrum
using the equation below:
(cid:113)
magnitudeoriginal = Y =
0 + b2
a2
0i
(1)
Because the magnitude function is many-to-one,
there
are multiple values of a and b that have the same
magnitudeoriginal. Informally, two signals of different phases
can have the same magnitude spectrum. This second perturba-
tion method picks two random numbers an and bn such that:
magnitudeoriginal = Y =(cid:112)a2
n + b2
ni
in Figure 2c. This will introduce similar discontinuities in the
signal, which makes the perturbed audio harder to interpret
due to the fundamentals of psychoacoustics.
3) High Frequency Addition (HFA): During preprocessing,
frequencies beyond the range of the human voice are removed
from the audio using a low-pass ﬁlter (Figure 1a) in order to
improve VPS accuracy. In most cases, this cut-off point is at
least 8000 Hz, for two reasons: the majority of spoken content
is below this level, and speech is typically sampled at 16000
Hz1. The third perturbation method adds high frequencies
to the audio that are ﬁltered out during the preprocessing
stage. We create high frequency sine waves and add it to
the real audio (Figure 2d). If the sine waves have enough
intensity, it has the potential to mask the underlying audio
command to the human ear. The resulting audio may also
become potentially painful to listen to as the human ear is
sensitive to high frequencies. The psychoacoustic reasoning
behind this is further discussed in Section VII.
4) Time Scaling (TS): Speaker and speech recognition
models need to account for the speed of human speech. It
is harder for humans to comprehend words spoken at a faster
rate, relative to the same words spoken at a slower rate [36]. In
the fourth and ﬁnal perturbation, we can accelerate the voice
commands to a point where they are still able to be properly
transcribed. We do so by compressing the audio in the time
domain by discarding unnecessary samples and maintaining
the same sample rate. As a result, the audio is shorter in time,
but retains the same spectrum as the original.
We generate a set of audio ﬁles that contain the same
voice command but vary in the degree of the audio’s speed
(Figure 2e). We then run these ﬁles against all of the speech
recognition models we observe and record the ﬁle with the
highest speed that was still properly transcribed. Though ap-
plying this perturbation by itself may not completely hinder the
ability of a human to comprehend the original voice command,
applying this in conjunction with the other perturbations makes
interpreting the audio difﬁcult.
D. Attack Audio Generation
This section details how the attack audio is generated using
the Perturbation Engine (PE), shown in Figure 3. The PE works
for any model given our black-box assumption.
1) Generic Attack Method: Attack audio generation com-
prises of the following steps: parameter selection, attack audio
generation, model inference, and audio selection. An overview
of this section is illustrated in Figure 3.
First, the attacker selects the parameters with which to
perturb the audio: audio speed, high frequency intensity, and
window size (for TDI and RPG). The attacker does not know
which parameters will give the most distorted attack audio the
VPS will still accept. The PE distorts the audio based on the
input parameters.
Second, the attacker feeds these parameters along with
the normal audio to the PE. The PE generates attack audio
samples, perturbing the entire length of the audio for each
(2)
This outputs a new signal with a different phase, yet with
the same magnitude spectrum as the original signal as shown
1If the system does not have hardware low pass ﬁlters, the audio signal will
alias.
5
Voice Processing System
Azure Veriﬁcation API [4]
Azure Attestation API [3]
Bing Speech API [6]
Google Client Speech API [7]
Houndify Speech API [8]
IBM Speech API [9]
Mozilla DeepSpeech [12]
Intel Neon DeepSpeech [10]
Kaldi [58]
Kaldi-DNN [11]
Sphinx [41]
Wit.ai Speech API [14]
Task
Model Type
Identiﬁcation
Unknown
Identiﬁcation
Unknown
Transcription
Unknown
Transcription
Unknown
Transcription
Unknown
Transcription
Unknown
Transcription
RNN
RNN
Transcription MFSC
HMM-GMM Transcription MFCC
DNN
Transcription MFCC
HMM-GMM Transcription MFCC
Unknown
Transcription
Feature Extraction
Unknown
Unknown
Unknown
Unknown
Unknown
Unknown
End-to-End
Unknown
Phrase ID
D
A,B,C
E,F,G,H
E,F,G,H
E,F,G,H
E,F,G,H
E,F,G,H
I,J,K,L
E,F,G,H
E,F,G,H
E,F
E,F,G,H
Online/Local
Online
Online
Online
Online
Online
Online
Local
Local
Local
Local
Local
Online
TABLE I: The models we tested our perturbation attack scheme against. The Phrase ID is referenced from Table II. The proprietary
VPSes are in bold.
Fig. 3: The workﬂow for our Attack Audio Generation. The
Perturbation Engine takes as input the perturbation parameters
and an audio ﬁle. It generates attack audio samples that that
sound like noise to the human ear, but are transcribed correctly
by the transcription model.
parameter set using the perturbations described in the previous
section. For each set of parameters, the PE will generate a
single audio sample. The TDI and RPG perturbation schemes
take the window size as input. The HFA perturbation scheme
will take as input the frequency one wants to add to the
audio signal. TS perturbation scheme will take as input the
percentage by which to increase the tempo.
The PE will apply the schemes, using the designated input
parameter values, to generate a unique attack audio for each
set of parameters. Generating individual attack audio samples
using our PE takes fractions of a second.
Third, attack audio samples are passed to the target VPS,
via queries. The VPS will not accept all attack audio samples,
as some might be distorted beyond recognition. A trade-off
exists between the degree of distortion and model transcription.
If the audio distortion is high, the VPS might not accept
or incorrectly transcribe the audio. On the other hand, too