Spark
batchesof
ODC
---
## Page 136
定时间间隔内的数据流，如图7-3 所示。
内部实现上，DStream 由一组在时间序列上连续的 RDD 表示，每一个 RDD 都包含了自己在特
这些数据流既可以通过外部输入源来获得，也可以通过现有的 DStream 的转换操作来获得。在
7.2.4
的吞吐量。
的并行度。并且可以对计算结果进行缓存，极大地减小了不必要的资源消耗，提高了数据处理
来说，Spark Streaming不是很好的选择。
据都需要流经有向无环图，最小的 batch time 在秒级，所以对于对实时性要求较高的业务场景
利用原始输入数据通过转换操作而重新算出。
系，所以只要输入数据是可容错的，那么当任意一个 RDD 的分区出错或不可用时，就都可以
机制。每一个 RDD 都是一个不可变的分布式可重算的数据集，其记录着确定性的操作继承关
毕释放所有资源。
运行，同时 SparkContext 将应用程序代码发放给 Executor。④Task 在 Executor 上运行，运行完
发送给TaskScheduler。Executor向 SparkContext 申请Task,TaskScheduler将Task发放给Executor
资源管理器上。③SparkContext 构建成有向无环图，将有向无环图分解成 Stage，并把 Taskset
器分配Executor资源并启动 StandaloneExecutorBackend，Executor运行情况将随着心跳发送到
源管理器（可以是 Standalone、Mesos 或 YARN）注册并申请运行 Executor 资源。②资源管理
吞吐量：Spark 本身就是分布式计算引擎，可以很容易地增加节点和设置Executor、Driver
DStream（Discretized Stream）作为 Spark Streaming 的基础抽象，它代表持续性的数据流。
实时性：由于Spark Streaming 本身的架构设计是采用微批处理方式来处理数据的，所有数
容错性：对于流式计算来说，容错性至关重要。首先我们要明确一下 Spark 中 RDD 的容错
在 DStream 中在时间轴下生成离散的 RDD 序列，如图 7-4 所示。
计算流程：①构建 Spark Application 的运行环境（启动 SparkContext），SparkContext 向资
编程模型
DStream
timeOto1
RDD @ time 1
datafrom
图7-3DStream操作流
RDD@ time 2
dne o
RDD@time3
-
RDD@time4
第7章实时计算框架
109
---
## Page 137
jssc.awaitTermination();
jssc.start();
wordCounts.print();
JavaPairDStream lines = jssc.socketTextStream("localhost", 9999);
=
import scala.Tuple2;
import org.apache.spark.streaming.api.java.*;
import org.apache.spark.api.java.function.*;
importorg.apache.spark.*;
代码7-1
如代码7-1所示。
接下来,以 Spark Streaming 官方提供的WordCount 代码为例来介绍 Spark Streaming 的使用方式,
7.2.5
可以生成新的DStream。
//Print the first ten elements of each RDD generated in this DStream to the console
import
10
Spark Streaming 承袭了 Spark 的编程风格，对于已经了解 Spark 的用户来说能够快速上手。
对 DStream 中数据的各种操作也是映射到内部的 RDD 上来进行的，通过 RDD 的转换操作
org.apache.spark.streaming.*;
智能运维：从O 搭建大规模分布式 AIOps 系统
Spark Streaming 的使用
DStream
words
DStream
lines
这里的执行引擎是Spark。
wordsfrom
linesfrom
// Wait for the computation to terminate
//Startthecomputation
operation
flatMap
图7-4DStream生成RDD序列的过程
time1to2
wordsfrom
time1to2
linesfrom
wordsfrom
time2to3
linesfrom
time3to4
wordsfrom
time3to4
---
## Page 138
换操作。
环图后，
函数）。Spark Streaming 只有在触发动作时才会开始进行转换。
过 reduceByKey对相同的单词进行累加。
例，先对 txt 进行 flatMap 操作拆分单词，然后执行 mapToPair 操作将单词进行映射，接下来通
据源，包括Kafka、Flume等数据源。
Spark Streaming 以 Socket 连接作为数据源读取数据。当然，Spark Streaming 支持多种不同的数
定 Master 名称、批处理时间、运行模式，以及通过广播进行数据共享。
countByValueO
reduce(func)
countO
union(otherStream)
repartition(numPartitions)
filter(func)
flatMap(func)
map(func)
方法
与 RDD 类似，转换允许修改输入 DStream 中的数据。DStream 支持 Spark RDD 的许多转
（5）启动实时流。设置好 Spark Streaming 上下文、输入流，以及设计好整个计算的有向无
（4）触发动作。上面的WordCount 例子是进行单词统计的，然后打印结果数据（调用 printO)
（3）转换DStream。开发人员可以在 DStream 的基础上进行所需的操作，以WordCount为
（2)创建inputStream。Spark Streaming 需要指明数据源，如上例中所示的 socketTextStream，
（1）创建JavaStreamingContext。JavaStreamingContext 是 Spark Streaming 上下文，可以指
一些常见的转换方法如表 7-1所示。
，我们就可以通过 startO函数进行计算了。
表 7-1DStream支持的常见的转换方法
中每个键的值都是其在源 DStream 的每个 RDD 中的频率
当在类型为K的元素的 DStream上调用时，返回一个新的(K,Long)对的 DStream，其
的元素，从而返回一个新的单元素RDD的DStream
通过使用函数func（它接收两个参数并返回一个）来聚合源DStream的每个RDD中
DStream
通过计算源DStream的每个RDD中元素的数量来返回一个新的单元素RDD 的
DStream
通过计算源DStream的每个RDD 中元素的数量来返回一个新的单元素RDD的
通过创建更多或更少的分区来更改DStream中的并行性级别
过滤筛选函数，通过仅选择func 返回 true 的源 DStream 的记录来返回新的 DStream
与 map类似，但每个输入项目可以映射到0个或更多个输出项目上
通过将源DStream的每个元素传递给函数func来返回一个新的DStream
描述
第7章
实时计算框架
111
---
## Page 139
支持的窗口转换方法如表7-2所示。
112
reduceByKeyAndWindow(func,windowLength,slideInterval,
reduceByWindow(func,windowLength,slideInterval)
countByWindow(windowLength,slideInterval)
window(windowLength,slideInterval)
方法
updateStateByKey(func)
transform(func)
cogroup(otherStream, [numTasks])
[numTasks])
join(otherStream, [numTasks])
reduceByKey(func),[numTasks])
方法
Spark Streaming 还提供了窗口计算，允许通过滑动窗口对数据进行转换。
智能运维：从O搭建大规模分布式AIOps系统
表 7-2Spark Streaming
值应用给定函数来更新。这可以用来维护每个键的任意状态数据
返回一个新的“状态”DStream，其中每个键的状态都通过对键的先前状态和键的新
以用来在 DStream上执行任意的 RDD 操作
通过对源DStream的每个RDD 应用RDD-RDD 函数来返回一个新的DStream。这可
当调用(K,V)和(K,W)对的 DStream 时，返回一个新的(K,Seq[V],Seq[W])元组 DStream
与每个键的所有元素对
当在(K,V)和(K,W)对的两个 DStream上调用时，返回一个新的(K,(V,W))对的 DStream
置不同数量的任务
spark.default.parallelism决定）进行分组。你可以传递一个可选的numTasks 参数来设
行任务数（2表示本地模式，而在集群模式下，该值由config属性
值都使用给定的reduce函数进行聚合。注意：在默认情况下，它使用Spark的默认并
当在(K,V)对的 DStream上调用时，返回一个新的(K,V)对的 DStream，其中每个键的
描述
的 numTasks 参数来设置不同数量的任务
spark.default.parallelism决定）进行分组。你可以传递一个可选
（2表示本地模式，而在集群模式下，该值由config 属
聚合。注意：在默认情况下，它使用 Spark 的默认并行任务数
每个键的值在滑动窗口中使用给定的reduce函数func进行批量
在(K,V)对的 DStream上调用时，返回一个新的(K,V)对，其中
元素流
通过使用 func 在滑动窗口间隔中聚合流中的元素来创建新的单
返回流中元素的滑动窗口计数
得出的
返回-
描述
1一个新的DStream，
支持的窗口转换方法
它是根据源DStream的窗口批次计算
。Spark Streaming
续表
弃
---
## Page 140
输出操作允许将 DStream 的数据推送到外部系统，如数据库或文件系统中。由于输出操作实际
次字数来扩展前面的例子。这是通过执行reduceByKeyAndWindow操作完成的。Spark Streaming
间单位进行滑动。这表明任何窗口操作都需要指定两个参数。
口 DStream 的 RDD。在此特定情况下，
[numTasks])
countByValueAndWindow(windowLength,slideInterval,
slideInterval,[numTasks])
reduceByKeyAndWindow(func,invFunc,windowLength,
方法
我们用一个例子来说明窗口操作。比方我们希望通过在过去 30 秒的数据中每 10 秒产生一
〇滑动间隔：执行窗口操作的时间间隔（图7-5中的2)。
每当窗口在源 DStream 上滑动时，落入该窗口内的源 RDD 被组合，并执行操作以产生窗
Spark Streaming 窗口计算示意图如图 7-5 所示。
窗口长度：窗口的持续时间（图7-5中的3)。
DStream
windowed
图7-5Spark Streaming窗口计算示意图
arindow
口
time1
，该操作将应用于最后3个时间单位的数据，并以2个时
time2
口
参数进行配置
reduceByKeyAndWindow一样，reduce任务的数量可通过可选
DStream，其中每个键的值都是滑动窗口内的频率。与
参数进行配置。请注意，必须启用检查点才能进行此操作
reduceByKeyAndWindow一样，reduce 任务的数量可通过可选
向减少”函数的函数（作为参数invFunc）。
例子。但是，它仅适用于“可逆减少函数”，即那些具有相应“反
少进入滑动窗口的新数据并“反向减少”离开窗口的旧数据来
减少值都是使用前一个窗口的减少值递增计算的。这是通过减
上述reduceByKeyAndWindowO的更高效版本。其中每个窗口的
描述
1
time3time4time5
口
window-based
operation
口
-口
第7章实时计算框架
与
续表
113
---
## Page 141
置得太大，则会造成任务的数据处理延时，以及对内存造成压力。理论上，Spark Streaming 的
果时间分片设置得太小，就会造成频繁地提交任务，导致 Spark Streaming 吞吐量降低；如果设
统无法高效地处理外部的数据，因此还需要对 Spark 配置进行分场景优化。
且在容错等扩展方面提供了友好的处理方式。但是很有时候由于业务场景及数据量的不同，
7.2.6
记录保存在 RDD 中。
用它将数据发送到远程系统中。为此可能需要通过 Spark 驱动程序创建连接对象，然后把数据
如何正确有效地使用该原语非常重要。
的操作)。目前，Spark Streaming 支持的输出方法如表 7-3 所示。
上允许外部系统使用转换后的数据,因此它们会触发所有DStream转换的实际执行(类似于RDD
saveAsTextFiles(prefix,[suffix])
printO
方法
114
foreachRDD(func)