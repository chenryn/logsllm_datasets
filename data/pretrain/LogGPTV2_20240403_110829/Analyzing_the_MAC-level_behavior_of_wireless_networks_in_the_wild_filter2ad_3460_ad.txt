centage; the y-values are the averages for the bin. We see that nitWit
adds roughly 10-20% packets when the capture percentages are low
and that directly capturing 80-90% of the packets lets us infer much
of the remaining ones. In this role, nitWit is especially useful when
the monitors hear only one end of the conversation well, as it can
then infer the other end. This simpliﬁes passive monitoring: we can
engineer placements that use fewer monitors to capture one end of
each conversation well, instead of both ends.
We also ran a self-consistency check over real traces to build
conﬁdence that PHY layer losses in real environments do not lead
to signiﬁcantly inaccurate inferences. Speciﬁcally, we infer packet
reception over two traces; the second trace is obtained by merging
the ﬁrst with another trace and has 21% more packets. If realistic
PHY layer loss patterns affect our inferences signiﬁcantly, the in-
ferences over the two traces are likely to differ signiﬁcantly. We
ﬁnd that our packet reception inferences are consistent for 93% of
the packets that are present in both traces. This is encouraging; if
this consistency reﬂects correctness, then nitWit takes us from hav-
ing no reception status information to correct inferences for the vast
majority of the cases, even when many packets are missing from the
input trace.
4.4 Estimating Contenders
To evaluate our estimate of the number of contenders, we run
dimWit on the merged traces of all ten simulated monitors and com-
pare the estimate against the authoritative log. Figure 8 plots the
CDF of error in our estimate at the end of each transmission. Er-
ror is computed as the estimated minus the actual number of con-
tenders. We see that our estimates are quite accurate overall. The
accuracy decreases slightly with grid size because fewer packets
are captured. In the worst case of the 900x900 grid, where 90%
of the packets are captured, dimWit is within ±1 for 87% of the
cases and ±2 for 92% of them. In the 100x100 grid, where 98% of
Figure 9: Effectiveness trends of inference. The x-axis is moni-
tor capture probability. The curves represent different round-trip
reception probabilities. Left: The ability to infer missing packets.
Right: The accuracy of the estimate of reception probability.
the packets are captured, our estimates are within ±1 for 95% of
the cases. Closer inspection of data reveals that high error values
tend to correspond to cases with a high number of contenders (e.g.,
estimating 15 or 25 contenders when there are 20) because the ac-
tual number changes rapidly. This reduces the relative error in our
estimates.
We ﬁnd that our estimates are largely insensitive to the exact
choice of the initial-backoff parameter within a reasonable range.
We varied the parameter value between zero and twice the initial
congestion window and observe that our accuracy is not signiﬁ-
cantly impacted. For instance, with a value of zero, our estimates
are within ±1 for 82% of the cases in the 900x900 grid. This is en-
couraging because most of the approximation in our computation
occurs in the initial backoff phase (because stations’ transmissions
do not reﬂect their choices in this phase). For instance, we approx-
imate that stations defer to all transmissions in the initial phase.
Interestingly, the value of zero approximates the other extreme in
which stations do not defer to any transmission in this phase, and
even then our estimates are reasonably accurate.
4.5
Inference Versus Additional Monitors
Given that both inference and additional monitors help to com-
plete our view of network activity, how should these two methods
be combined in a practical system? To understand this, we study
a simple model that exposes the ability of inference to deal with
incomplete data. We generate artiﬁcial traces in which the monitor
capture probability and the node reception probability are held con-
stant. Clients repeatedly attempt to send data. Each DATA packet,
both original and retried, and ACK is independently logged with
the capture probability. Additionally, we drop packets according
to the speciﬁed round-trip reception probability, divided equally in
each direction. We vary the capture probability from 0.7 to 0.95;
higher values represent setups with more monitors. We vary round-
trip reception probability from 0.1 to 0.9 to cover a range of condi-
tions. This experiment lets us isolate capture and reception proba-
bilities in an understandable setting.
Figure 9 shows the results of running nitWit over the traces. In
both graphs, the x-axis is capture probability, and curves represent
different round-trip reception probabilities. The left graph plots the
percentage of packets that are either captured or inferred. The right
graph plots the ratio of nitWit’s estimate of reception probability to
the actual value. This shows the accuracy of inferences over the
trace. The main conclusion we draw is that merging and inference
are complementary. At low capture probabilities, while nitWit sub-
)
n
o
i
l
l
i
m
(
s
t
e
k
c
a
p
#
250
200
150
100
50
0
0
pre-merge (Ch. 11)
pre-merge (Ch. 1)
post-merge (Ch. 11)
post-merge (Ch. 1)
5
2
1
4
monitor number
3
Figure 10: Monitoring environment at the conference. The lay-
out shows the approximate locations of the APs and the monitors.
Ballroom hosted the main conference and had only limited wire-
less access on the back and left. Parlor acted as the terminal room
and was most active. Galleria hosted the workshops.
stantially adds to the trace, the right course of action is to add mon-
itors to improve the underlying capture probability. Assuming that
the monitors log each packet with an independent probability, addi-
tional monitors in this regime will be highly effective at adding to
the trace. There are diminishing returns as monitors become more
dense and the capture probability is already high. Here, nitWit al-
most completes the trace with missing packets that would be hard to
recover through additional monitors, especially for well-connected
clients. Similarly, while the accuracy of inferences is high over the
entire range of capture probability, it is especially good in the range
that represents good coverage by the monitors. Above 85% capture
probability, the relative error in the estimates is less than 5%, and
the absolute error is even lower.
5. APPLYING Wit TO A LIVE NETWORK
We now report on our experience in applying Wit to analyze a
live wireless network. By necessity, we focus on a few analyses; it
is straightforward to perform many others.
5.1 Monitoring Environment
Our wireless environment is the SIGCOMM 2004 conference
which spanned four days and had roughly 550 attendees. We view
this as a large, busy setting. The layout of the conference ﬂoor
of the hosting hotel is depicted in Figure 10. The ofﬁcial wireless
network of the conference had ﬁve APs. Except for AP D, which
operated on Channels 6 and 8, the APs operated on Channels 1 and
11. Some of the APs switched channels during the conference. In-
ternet connectivity was enabled through four separate DSL access
lines. In addition to the conference network, a number of transient
infrastructure and ad hoc networks were present, and the hotel had
its own, private wireless network on Channel 6. In our view, the
diversity and transience of clients makes it intractable to study this
environment using instrumentation.
We passively monitored this network using ﬁve PCs, each with
three wireless NICs whose external antennae were placed at least a
foot apart. Two NICs of each monitor listened on Channels 1 and
11, and the third listened on Channel 6 or 8. Monitors logged all
observed activity, including control, management and data pack-
ets. Complete MAC headers and PHY information, such as trans-
mission rate, were logged for each packet. All monitors except 4,
which was switched off and stored elsewhere at nights, were active
Figure 11: Cumulative packet counts as monitors are merged.
“Pre-merge” counts the total number of packets, without remov-
ing duplicates. “Post-merge” represents the merged traces.
for the entire duration of the conference. We analyze traces from
Channels 1 and 11.
The SIGCOMM 2004 wireless network had intermittent usabil-
ity problems. We understand that these stemmed from DHCP and
DNS issues and disrupted Internet connectivity for some clients.
We believe that these problems do not affect the underlying MAC
behavior which is our focus. They do, however, lower the average
load on the network during connectivity disruptions.
5.2 Merging with halfWit
We merged the traces from Monitors 1-4 on Channel 1 and from
all ﬁve monitors on Channel 11 to produce a merged trace for each
channel. Monitors were merged in the order of their number. The
Monitor 5 trace of Channel 1 did not have enough references in
common with the merged trace of the other four monitors for it to
be correctly merged. We exclude it from our analysis.
Our experience provides a useful lesson on the placement of
monitors. A natural tendency is to place monitors far apart to max-
imize the capture of unique packets. But this minimizes the overlap
between monitors. Placement that yields too little overlap is a poor
strategy because it hinders merging.
To understand the value of merging in enhancing the view of
wireless activity, we count the number of additional packets and
clients that are present in the merged trace compared to the Monitor
1 trace. We ﬁnd that merging adds 28% packets and 12% clients on
Channel 1 and adds 124% packets and 37% clients on Channel 11.
In addition to more overall activity, the additional packets represent
enhanced views of individual clients: the merged trace has 12% and
60% more packets per client on the two channels.
Figure 11 shows the gains of merging in more detail. It plots the
cumulative number of packets as additional monitors are merged.
The solid curves show the number of packets before duplicates are
removed, and the dashed ones show the merged traces (after remov-
ing duplicates). There is signiﬁcant overlap in what the monitors
hear, yet each additional monitor increases the number of unique
packets in the trace. This is true even when we merge monitors 1
and 2 that sit next to each other. Thus, even a dense array of mon-
itors may miss packets. This motivates the need to infer missing
packets, as we do with nitWit, because capturing this information
through monitoring alone is almost impossible.
5.3
Inference with nitWit
We applied nitWit to the two merged traces. The Channel 1 merge
has 56M packets of which 49M are unicast. nitWit processed 30M
conversations with 26K distinct packet sequences. The top three
sequences were DATA–ACK (51%), BEACON (22%), and DATA–
100
80
60
40
20
s
r
i
a
p
P
A
-
t
n
e
i
l
c
f
o
%
0
-0.8
-0.4
-0.6
-0.0
difference in estimates
-0.2
0.2
Figure 12: The CDF of the difference in the reception probability
estimates of nitWit and the heuristic based on the retry-bit.
DATAretry–ACK (6%). nitWit inferred that 80% of the unicast
packets were received by their destination and inferred an extra
5.5M packets; we estimate from this that the monitors captured
90% of the total packets. The Channel 11 merge has 111M packets
of which 95M are unicast. nitWit inferred that 94% of the unicast
packets were received, and inferred an extra 24M packets with a
corresponding capture estimate of only 79%. Therefore, while the
view of Channel 1 is reasonably complete, the view of Channel 11
is poorer, and we expect the measures we compute for it to be less
accurate.
The traces also let us assess how well nitWit can infer various
properties of the missing packets. For the Channel 1 merge, we
count the inferred packets for which the exact size, transmission
time and transmission rate could be reconstructed. We ﬁnd that
size, time and rate can be inferred for 76%, 64% and 42% of the
packets, respectively, and that all three properties can be inferred
for 34% of the packets. The low percentage of rate inferences is be-
cause the rate of any other packet in the conversation provides little
information about the rate of a missing data packet (which could be
improved by inferring the rate adaptation behavior of clients.)
We observe that nitWit can lead to simpler and likely more ac-
curate estimates. This is because it systematically extracts latent
information from the traces, whereas the heuristics that must other-
wise be used are based on simpler, less complete, models [11, 21].
Consider two cases:
1.
In earlier work, we estimated the reception probability of
packets between clients and APs based on the retry bit [21]. Each
data packet with the retry bit set suggests that the earlier transmis-
sion was lost. As a heuristic, we estimated reception probability as
one minus the fraction of data packets with the retry bit set. Fig-
ure 12 plots the CDF of the difference between this heuristic and
the reception probability computed using nitWit’s reception infer-
ence. There is a data point for both directions of each client-AP
pair that exchange over 100 packets. We see that the heuristic com-
putes signiﬁcantly lower reception probabilities, by 0.20 for 15%
of the cases and by 0.10 for 30% of them. While we cannot be
certain without ground truth, we believe that the Wit estimates are
closer to the correct values based on validation checks with the sim-
ulator. The heuristic is biased by assumptions that do not hold: it
assumes that both monitor capture and reception probability are in-
dependent of factors such as size, rate and type; in practice, data
packets are more likely to be lost than ACKs due to their bigger
size and original data packets are more likely to be lost than retries
due to their higher average transmission rate. There appears to be
no straightforward way to remove these biases from the heuristic.
2. The monitor capture percentage can be estimated with a heu-
ristic based on the DATA-ACK exchange. Each ACK without a
corresponding data packet indicates that a data packet was not cap-
tured. An estimate of the capture ratio is then the number of data
.
b
o
r
p
n
o
i
t
p
e
c
e
r
k
n
i
l
n
w
o
d
1.0
0.8
0.6
0.4
0.2
0.0
0.0 0.2 0.4 0.6 0.8 1.0
uplink reception prob.
Figure 13: The uplink versus downlink reception probability for
clients in the network, computed over the entire Channel 1 trace.
e
m
i
t
f
o
%
50
40
30
20
10
0
0
5
10
# contenders
15
s
t
k
p
f
o
%
50
40
30
20
10
0
0
5