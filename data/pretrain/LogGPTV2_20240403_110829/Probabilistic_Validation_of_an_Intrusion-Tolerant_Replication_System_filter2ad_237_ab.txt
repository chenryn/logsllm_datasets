that is more than enough for most studies.
The next step in the initialization of the model is to start
replicas on hosts. The place replicas to start sys is a bit
Proceedings of the 2003 International Conference on Dependable Systems and Networks (DSN’03) 
0-7695-1959-8/03 $17.00 (c) 2003 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 12:27:53 UTC from IEEE Xplore.  Restrictions apply. 
vector shared across all Replica and Host submodels, and
indicates the applications for which replicas are to be started
by the Host submodels. The high-rate activity start replica
ﬁres once for each Replica submodel, setting the bit corre-
sponding to the identiﬁer of the application to which the
replica belongs (app id) in replica to start sys. When a
host starts some replicas, it puts a bit vector with 1s for all
the applications whose replicas were started in the globally
shared place replica started. For each such application, the
enable rep activities are enabled in all Replica submodels
that correspond to the application’s replicas that have not
yet started, with each activity being equally likely to ﬁre
ﬁrst. The ﬁrst enable rep to ﬁre 1) increments the marking
of replicas running, which is shared across all replicas of
an application and keeps track of the number of currently
running replicas of the application; 2) sets the marking of
has started, which is local to this replica and indicates if
the replica represented by this submodel is active, to one;
and 3) removes the application’s bit from replica started.
Thus when a replica of an application is started on a host,
one of the Replica submodels that belong to the application
is randomly chosen to be the replica started.
Whenever a host becomes corrupt, the Host submodel
puts a bit vector of application identiﬁers of all the repli-
cas running on it in the globally common place repli-
cas affected (since a host, and for some management
schemes an entire domain, can have at most one replica of
a particular application). For each affected application, the
activity prop host corr ﬁres in one of its Replica submodels
that is not already running on a corrupt host, changing the
state of the Replica to indicate that its host is corrupt (local
place host corrupt), and resetting the bit for this application
in replicas affected.
The activity attack rep represents a successful attack
on a replica. The rate of the activity (reciprocal of the
mean time between ﬁrings of the activity when it is en-
abled) is higher if the replica is running on a corrupt host
(host corrupt). We multiply the base rate by a constant to
obtain the higher rate. A multiplier of 2 would imply that
if there is an intrusion into the host on which a replica is
running, the replica becomes twice as vulnerable to attacks
as it originally was. Upon ﬁring of attack rep, the marking
of the local place replica attacked is set to 1 to indicate the
intrusion, and the marking of rep corr undetected, which
is shared for all replicas of the application, is incremented
to indicate the number of yet-undetected corrupt replicas
of the application. The replication group is checked for a
Byzantine failure; if the number of undetected corrupt repli-
cas is a third or more of the total number of application
replicas currently running (replicas running), the marking
of rep grp failure, which is shared across all replicas of the
application and is used to determine the “unreliability” of
the application, is set to 1.
After an intrusion into a replica, the activity valid ID is
enabled. The activity has two cases, which represent suc-
cessful detection and failure to detect, respectively. Upon
successful detection the marking of rep corr undetected is
decremented and the marking of replica detected local is
set to 1. A corrupt replica may exhibit anomalous behav-
ior, which can be detected by other currently running repli-
cas of the application provided that enough of them are
correct. This is captured by activity rep misbehave. Af-
ter a successful intrusion into the replica, the activity is
enabled provided that the value of the marking of repli-
cas running is more than three times the value of the mark-
ing of rep corr undetected (i.e., less than a third of the cur-
rently running replicas are corrupt). The activity false ID
models the false alarms of replica corruption generated
by the intrusion detection system. It is enabled whenever
the replica has been intruded. The results of the ﬁring of
false ID and rep misbehave are similar to those of the ﬁr-
ing of valid ID.
Once a replica is marked as corrupted (via valid intru-
sion detection, false alarm, or detection of misbehavior by
the replication group), the activity prop rep detect conveys
that information to the host on which the replica is running,
setting the replica’s application identiﬁer bit in the glob-
ally shared place rep affected, and copying host corrupt
into the globally shared host affected, to indicate the state
of the host on which the replica is running. When a host
(or domain) is shut down (excluded), all the replicas run-
ning on the host (or domain) are killed. The fact that they
have been killed is conveyed from the Host submodel to
the Replica submodels through the globally shared places
replicas killed, rep kill reason, and reps on corrupt hosts.
The marking of replicas killed is a bit vector indicating
the applications whose replicas were killed; the marking
of rep kill reason is a bit vector indicating the applications
that had compromised replicas on the host (or domain); and
the marking of reps on corrupt hosts is a bit vector indi-
cating the applications whose replicas were running on cor-
rupt hosts in the domain being shut down. The markings of
those places are used to determine the appropriate replicas
to kill. The activity kill replica ﬁres in those Replica sub-
models, decrementing the number of active replicas (repli-
cas running), resetting the markings of various local places
in the Replica submodel so that the submodel can be used
again to start a new replica of the application, and incre-
menting the marking of need recovery to indicate that the
management infrastructure must start a new replica for this
application.
3.3. SAN Model for Management Algorithm
Figure 2(c) shows the SAN representation of the Man-
agement submodel. This SAN models the process of re-
Proceedings of the 2003 International Conference on Dependable Systems and Networks (DSN’03) 
0-7695-1959-8/03 $17.00 (c) 2003 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 12:27:53 UTC from IEEE Xplore.  Restrictions apply. 
covery by the management infrastructure through the start-
ing of new replicas to replace those killed due to domain
and host exclusions. As shown in Figure 2(a), there is one
Management SAN per application. The activity recovery is
enabled whenever there are some replicas to be started for
the application (indicated by the marking of need recovery,
shared with all Replica submodels for the application), and
there are enough good managers in the system to initiate
a recovery (i.e., if the number of undetected corrupt man-
agers is less than a third of the total number of managers
currently running). Upon the ﬁring of need recovery, the
application’s identiﬁer is placed in the replica to start sys
place, which is then used by Host SANs to start the replica.
3.4. SAN Model for a Host
Figure 2(d) shows the SAN representation of the Host
submodel. This SAN models the activities on a single host,
including attacks on the host, detections and false alarms
by the intrusion detection software on the host, starting of
replicas on the host, starting of management entities on the
host, and shutting down of the host and all replicas it is
running, to name a few.
The high-rate activity start manager is responsible for
starting a manager on each host. The high-rate activity
start replica is responsible for starting replicas on hosts.
The activity is enabled whenever there is an application for
which there is a replica to start (indicated by the globally
shared bit vector replica to start sys) and for which there
is not already a replica in the domain, and the domain has
not been excluded yet. Since the identical copies of the ac-
tivity would be enabled in all Host submodels for which
those conditions are met, all of the copies are equally likely
to ﬁre ﬁrst. Hence, to start a replica, we choose a domain
uniformly from among the domains that qualify, and within
the chosen domain, we select a host uniformly from among
the hosts in the domain. Upon the ﬁring of start replica,
replicas for all the applications that had replicas to start and
did not have replicas in the domain are started on the host.
The marking of replica to start sys is updated to reset bits
for all applications whose replicas were just started. The
local place num replicas is updated to represent the number
of replicas (of all applications) running on this host. Infor-
mation identifying the replicas for which applications were
started is conveyed to the appropriate Replica submodels
via the globally shared bit vector replica started. The cor-
ruption state of the host is also conveyed to those replicas
via the globally shared place host is corrupt.
As mentioned in Section 2, the attacker can attack the
host (i.e., the host operating system and services), the man-
agement infrastructure, and the application replicas. The
activity attack host models attacks on the host operating
system and services. As mentioned in Section 2, an attack
on the host can belong to one of three categories, script-
based, more exploratory, and innovative, which are modeled
by three cases for the activity attack host, conﬁgured with
decreasing probability. Upon the ﬁring of attack host, the
marking of host attacked is to be 1, 2, or 3 depending upon
the case chosen.
Information about the intrusion into the host needs to be
conveyed to replicas running on the host, since the intrusion
affects their vulnerability. The activity rep prop is enabled
when the host is intruded, and upon ﬁring of the activity,
the marking of globally shared place replicas affected is set
to a bit vector indicating the applications that have replicas
on this host. It is then used by the Replica SANs as already
described.
As mentioned in Section 2, successful intrusion into a
host increases the vulnerability of other hosts in the sys-
tem, especially the ones in the same security domain. We
model this by including two “propagate” activities: propa-
gate domain, which models the spread of an attack within
a domain, and propagate sys, which models the spread
of an attack across domain boundaries. Both activities
ﬁre exactly once when a host becomes intruded. Upon
the ﬁring of propagate domain, the marking of place at-
tack spread domain, which is shared by all hosts in the
domain, is incremented by a model variable representing
the amount of spread effect. This variable also deter-
mines the rate of the propagate domain activity. The ac-
tivity propagate sys is handled similarly, except that at-
tack spread system is shared across all hosts in all do-
mains. The rate of the activity attack host increases lin-
early with the markings of attack spread domain and at-
tack spread system, increasing the chances of successful in-
trusions into the host operating system and services. The
spread effect variable associated with intra-domain spread
is set to be much larger than the variable associated with
inter-domain spread.
The activity attack mgmt represents attacks against the
manager running on the host. The rate of this activity in-
creases if the host is corrupted. Upon the ﬁring of at-
tack mgmt, the marking of the local place mgmt attacked
is set to 1. The marking of mgr corrupt, which is shared
by all hosts in the domain, is set to 1 if a third or more
of the active managers in the domain have been corrupted.
The marking of undetected corr mgrs, which is shared by
all SANs in the composed model, is also incremented.
activities
valid ID scp,
The
valid ID exp,
and
valid ID inv represent
the detection by the intrusion
detection software of inﬁltration into the host OS and
services for script-based, more exploratory, and innovative
attacks, respectively. Each activity has two cases, which
represent successful detection and failure to detect. In most
studies, the probability of successful detection is set to be
higher for script-based attacks than for more exploratory
Proceedings of the 2003 International Conference on Dependable Systems and Networks (DSN’03) 
0-7695-1959-8/03 $17.00 (c) 2003 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 12:27:53 UTC from IEEE Xplore.  Restrictions apply. 
attacks, which in turn is set to be higher than the value for
innovative attacks. The activity valid ID mgr represents
successful detection by the intrusion detection software of
inﬁltration of the management entity on the host. Upon
ﬁring of any of the detection activities, a response is
initiated provided that the manager on the host and the
manager group of the domain are not corrupt. The domain
containing the corrupt host is excluded by placing a token
in exclude domain that is shared across the domain.
False alarms of inﬁltration into the host OS or host’s
management entity are represented by the activity false ID,
which is enabled as long as there have not been any actual
intrusions. Upon the ﬁring of false id, an action similar to
those taken upon the ﬁrings of various valid detection activ-
ities is taken.
As mentioned in Section 3.2, when either the intru-
sion detection software or replication group members ﬁnd
a replica to be corrupt, the identiﬁer of the application
is put in the globally shared place replica detected, and
host affected is changed to indicate if the host on which the
detected replica was running was corrupt. The activity af-
fect host can ﬁre if the host has a replica of the application
indicated by replica detected and the host’s corruption sta-
tus matches with that conveyed by host affected, and the
ﬁring moves values of replica detected and host affected
into domain-level shared places replica detected local and
host affected local to avoid the possibility of a deadlock in
the model. The activity shut host is enabled if there is some
convicted replica (replica detected local) and either the do-
main’s manager group is not corrupt or there are enough
good managers in the system. The reason for the latter con-
dition is that even if the domain’s manager group is corrupt
and does not report the intrusion and exclude itself, other
managers would know about the corrupt replica from the
other members of the replica’s replication group. If there
are enough good managers (i.e., less than a third are in the
undetected corrupt state), then they will exclude the cor-
rupt manager and its domain. The actual shutting down of
the domain is modeled by the activity prop rep kill, which
sets the markings of replicas killed, rep kill reason, and
reps on corrupt hosts as mentioned earlier in Section 3.2.
We have also modeled an alternative management al-
gorithm that excludes from the system only the host on
which inﬁltration is detected (and kills only the replicas
running on that host), instead of excluding the entire do-
main. The SANs for that approach look almost the same,
but have a few subtle differences from the SANs described
above, with respect to the places that are shared, the lev-
els at which they are shared, and the input predicates and
functions that are used. We brieﬂy summarize the salient
differences. The places exclude domain, rep shutdown,
replica affected local, and host affected local were made
local to the Host SAN. Firing of prop rep kill now sends
information about replicas on the host (if the host was cor-
rupt).
(In the previous model, that information was sent
about the domain.)
4. Results
We used the M¨obius [3] tool to design the SANs, de-
ﬁne the intrusion tolerance measures on the model, and de-
sign studies on the model. M¨obius can solve SANs analyt-
ically by converting them into equivalent continuous time
Markov chains. However, because of the complexity of the
model and the use of non-exponentially distributed ﬁring
times for some activities, we instead used M¨obius to sim-
ulate the model to obtain values for the intrusion tolerance
measures for various studies.
We deﬁned several measures on the model for use in the
studies. We deﬁned the service by an application to be im-
proper if it suffers a Byzantine fault, i.e., a third or more of
the currently active replicas are corrupt. Some of the mea-
sures deﬁned were unavailability for an interval, which is
the fraction of time the service was improper in the inter-
val; unreliability for an interval, which is the probability
that service was improper at least once in the interval; num-
ber of replicas of an application still running at a given time
instant; number of replicas per host or the load on a host at
a given time instant; fraction of corrupt hosts in a domain
when it is excluded; and fraction of excluded domains at a
given time instant.
We now describe the studies we conducted using the
model. To determine the preferable distribution of hosts
into domains, we compared the intrusion tolerance of the
system for different distributions of a constant number of
hosts into domains, as well as for different numbers of
hosts distributed into a ﬁxed number of domains. Another
study compared the relative efﬁcacy of host-exclusion and
domain-exclusion management algorithms. A more de-
tailed analysis, along with a larger set of studies, can be
found in [13].
Unless otherwise speciﬁed, the following values were
used for the parameters of interest in the studies described
in this section (for ease of understanding, consider one time
unit = one hour):
• Cumulative base attack rate on the system was 3 suc-
cessful attacks per time unit. Since the actual attack
rates can increase as a result of various factors, such as
attack spread, corruption of the host on which a replica
or a management entity is running, and other causes,
the actual attack rate will usually be higher than this.
• Cumulative false alarm rate was 2 false alarms per time
• Distribution of attack on a host (OS and services): 80%
script-based, 15% more exploratory, and 5% innova-
tive.
unit.
Proceedings of the 2003 International Conference on Dependable Systems and Networks (DSN’03) 
0-7695-1959-8/03 $17.00 (c) 2003 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 12:27:53 UTC from IEEE Xplore.  Restrictions apply. 
s
t
i
n
u
e
m
i
t
5
t
s
r
i
f
r
o
f
y
t
i
l
i
b
a
l
i
a
v
a
n
U
0.45
0.4
0.35
0.3
0.25
0.2
0.15
0.1
0.05
0
2 applications
4 applications
6 applications
8 applications
0
2
4
6
8
10
12
Hosts per domain
(a) Unavailability
s
t
i
n
u
e
m
i
t
5
t
s
r
i
f
r
o
f
y