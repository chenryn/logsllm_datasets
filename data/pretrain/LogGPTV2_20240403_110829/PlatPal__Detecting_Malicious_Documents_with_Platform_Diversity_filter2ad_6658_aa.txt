title:PlatPal: Detecting Malicious Documents with Platform Diversity
author:Meng Xu and
Taesoo Kim
PlatPal: Detecting Malicious Documents  
with Platform Diversity
Meng Xu and Taesoo Kim, Georgia Institute of Technology
https://www.usenix.org/conference/usenixsecurity17/technical-sessions/presentation/xu-meng
This paper is included in the Proceedings of the 26th USENIX Security SymposiumAugust 16–18, 2017 • Vancouver, BC, CanadaISBN 978-1-931971-40-9Open access to the Proceedings of the 26th USENIX Security Symposium is sponsored by USENIXPLATPAL: Detecting Malicious Documents with Platform Diversity
Meng Xu and Taesoo Kim
Georgia Institute of Technology
Abstract
Due to the continued exploitation of Adobe Reader, mali-
cious document (maldoc) detection has become a pressing
problem. Although many solutions have been proposed,
recent works have highlighted some common drawbacks,
such as parser-confusion and classifier-evasion attacks.
In response to this, we propose a new perspective for
maldoc detection: platform diversity. In particular, we
identify eight factors in OS design and implementation
that could cause behavioral divergences under attack,
ranging from syscall semantics (more obvious) to heap
object metadata structure (more subtle) and further show
how they can thwart attackers from finding bugs, exploit-
ing bugs, or performing malicious activities.
We further prototype PLATPAL to systematically har-
vest platform diversity. PLATPAL hooks into Adobe
Reader to trace internal PDF processing and also uses
sandboxed execution to capture a maldoc’s impact on the
host system. Execution traces on different platforms are
compared, and maldoc detection is based on the obser-
vation that a benign document behaves the same across
platforms, while a maldoc behaves differently during ex-
ploitation. Evaluations show that PLATPAL raises no false
alarms in benign samples, detects a variety of behavioral
discrepancies in malicious samples, and is a scalable and
practical solution.
1
Introduction
Cyber attackers are turning to document-based malware
as users wise up to malicious email attachments and
web links, as suggested by many anti-virus (AV) ven-
dors [39, 50, 54, 57]. Users are generally warned more on
the danger of executable files by browsers, email agents,
or AV products, while documents such as PDFs are treated
with much less caution and scrutiny because of the im-
pression that they are static files and can do little harm.
However, over time, PDF specifications have changed.
The added scripting capability makes it possible for doc-
uments to work in almost the same way as executables,
including the ability to connect to the Internet, run pro-
cesses, and interact with other files/programs. The growth
of content complexity gives attackers more weapons to
launch powerful attacks and more flexibility to hide mali-
cious payload (e.g., encrypted, hidden as images, fonts or
Flash contents) and evade detection.
A maldoc usually exploits one or more vulnerabili-
ties in its interpreter to launch an attack. Fortunately (or
unfortunately), given the increasing complexity of doc-
ument readers and the wide library/system component
dependencies, attackers are presented with a large attack
surface. New vulnerabilities continue to be found, with
137 published CVEs in 2015 and 227 in 2016 for Adobe
Acrobat Reader (AAR) alone. The popularity of AAR
and its large attack surface make it among the top tar-
gets for attackers [25], next to browsers and OS kernels.
After the introduction of a Chrome-like sandboxing mech-
anism [2], a single exploit can worth as high as $70k in
pwn2own contest [21]. The collected malware samples
have shown that many Adobe components have been ex-
ploited, including element parsers and decoders [37], font
managers [28], and the JavaScript engine [22]. System-
wide dependencies such as graphics libraries [23] are also
on attackers’ radar.
The continued exploitation of AAR along with the
ubiquity of the PDF format makes maldoc detection a
pressing problem, and many solutions have been proposed
in recent years to detect documents bearing malicious
payloads. These techniques can be classified into two
broad categories: static and dynamic analysis.
Static analysis, or signature-based detection [14, 27, 31,
33, 34, 36, 46, 52, 59], parses the document and searches
for indications of malicious content, such as shellcode
or similarity with known malware samples. On the other
hand, dynamic analysis, or execution-based detection [45,
48, 58], runs partial or the whole document and traces
for malicious behaviors, such as vulnerable API calls or
return-oriented programming (ROP).
USENIX Association
26th USENIX Security Symposium    271
However, recent works have highlighted some common
drawbacks of these solutions. Carmony et al. [11] show
that the PDF parsers used in these solutions might have
overly simplified assumptions about the PDF specifica-
tions, leading to an incomplete extraction of malicious
payloads and failed analysis. It has also been demon-
strated that machine-learning-based detection could po-
tentially be evaded in principled and automatic ways [35,
53, 65]. In addition, many solutions focus only on the
JavaScript parts and ignore their synergy with other PDF
components in launching attacks. Therefore, even though
modern AV products support PDF-exploit detection, they
cannot quickly adapt to novel obfuscation techniques even
if the latter constitute only minor modifications of existing
exploits [55]. AV products also exhibit problems provid-
ing protection against zero-day attacks, due to the lack of
attack procedures and runtime traces.
In this paper, we propose PLATPAL, a maldoc detec-
tion scheme that analyzes the behavioral discrepancies
of malicious document files on different platforms (e.g.,
Windows or Macintosh (Mac)). Unlike the static and dy-
namic detection schemes that rely on existing malware
samples to construct heuristics, PLATPAL is based on a
completely different set of insights: 1) a benign document
behaves the same (in a certain level) across platforms,
while 2) a malicious document causes diverged behaviors
when launching exploits on different platforms.
The first assumption can be empirically verified by
opening many benign samples that use a variety of PDF
features across platforms. To support the second assump-
tion, we investigated the factors in OS implementation
that could cause behavioral divergences when under at-
tack and identified eight such factors, ranging from syscall
semantics (more obvious) to heap object metadata struc-
ture (more subtle). We further show how they can be used
to thwart attackers in finding bugs, exploiting bugs, or
performing malicious activities.
PLATPAL is based on these insights. To detect whether
a document has malicious payload, PLATPAL opens it
with the same version of AAR instances, but running on
top of different operating systems. PLATPAL records the
runtime traces of AAR while processing the document
and subsequently compares them across platforms. Con-
sensus in execution traces and outputs indicates the health
of the document, while divergences signal an attack.
Although the process sounds simple and intuitive,
two practical questions need to be addressed to make
PLATPAL work: 1) what “behaviors” could be potentially
different on different platforms? and 2) how can they be
universally traced? PLATPAL traces and compares two
types of behaviors. Internal behaviors include critical
functions executed by AAR in the PDF processing cycle,
such as loading, parsing, rendering, and script execution.
External behaviors include filesystem operations, network
activities, and program launches. This aligns with typical
malware analysis tools such as Cuckoo sandbox [44].
It is worth highlighting that PLATPAL should not be
considered as a competitor to current malware analysis
tools such as Cuckoo [44] as they rely on different assump-
tions. Current tools rely heavily on the availability of a
blacklist (or whitelist) of OS-wide activities are already
available such that a sample’s behaviors can be vetted
against the list. This approach works well for known
malware but might lost its advantage against 0-day PDF
exploits. On the other hand, PLATPAL does not require
the such a list to function and only relies on the fact that
it is difficult for an attacker to craft a malicious PDF that
exploits AAR in exactly the same way in both Windows
and Mac platforms.
PLATPAL is evaluated against 1030 benign samples
that use various features in the PDF specifications and re-
ports no discrepancies in their traces, i.e., no false alarms.
For a collection of 320 maldoc samples exploiting 16 dif-
ferent CVEs, PLATPAL can detect divergences in 209 of
them with an additional 34 samples crashing both AAR
instances. The remainder are undetected for various rea-
sons, such as targeting an old and specific version of AAR
or failure to trigger malicious activities. PLATPAL can
finish a scan of the document in no more than 24 seconds
per platform and requires no manual driving.
Paper contribution. In summary, this paper makes the
following contributions:
• We propose to execute a document across different
platforms and use behavioral discrepancies as an
indicator for maldoc detection.
• We perform in-depth analysis and categorization of
platform diversities and show how they can be used
to detect maldoc attacks.
• We prototype PLATPAL based on these insights.
Evaluations prove that PLATPAL is scalable, does
not raise false alarms, and detects a variety of behav-
ioral discrepancies in malicious samples.
We plan to open source PLATPAL to prompt using
platform diversity for maldoc detection and also launch a
PDF maldoc scanning service for public use.
2 Maldoc Detection: A Survey
Existing maldoc detection methods can be classified
broadly into two categories: 1) dynamic analysis, in which
malicious code is executed and examined in a specially in-
strumented environment; and 2) static analysis, in which
the detection is carried out without code execution. A
summary of existing methods is presented in Table 1.
272    26th USENIX Security Symposium
USENIX Association
Category
Static
Dynamic
Focus
JavaScript
JavaScript
JavaScript
JavaScript
Metadata
Metadata
Metadata
Both
Detection Technique
Lexical analysis [27]
Token clustering [59]
API reference classification [14]
Shellcode and opcode signature [31]
Linearized object path [36]
Hierarchical structure [33, 52]
Content meta-features [46]
Many above-mentioned heuristics [34]
Shellcode and opcode signature [58]
Known attack patterns [45]
JavaScript
JavaScript
JavaScript Memory access patterns [48]
JavaScript
Document
Common maldoc behaviors [29]
Violation of memory access invariants [62]
Parser ? ML ?
Yes
Yes
Yes
No
Yes
Yes
Yes
Yes
Yes
Yes
Yes
No
Yes
Yes
Yes
Yes
Yes
Yes
Yes
No
No
No
No
No
No
No
Pattern ?
Evasion / Drawbacks
Yes
Yes
Yes
Yes
Yes
Yes
Yes
Yes
Yes
Yes
Yes
Yes
No
Heavy obfuscation,
Code loading
Mimicry [53],
Reverse mimicry [35]
Incompatible JS engine,
Non-script based attacks
Zero-day exploits
ROP and JIT-Spraying
Table 1: A taxonomy of malicious PDF document detection techniques. This taxonomy is partially based on a systematic survey
paper [40] with the addition of works after 2013 as well as summaries parser, machine learning, and pattern dependencies and
evasion techniques.
2.1 Static Techniques
One line of static analysis work focuses on JavaScript
content for its importance in exploitation, e.g., a majority
(over 90% according to [58]) of maldocs use JavaScript to
complete an attack. PJScan [27] relies on lexical coding
styles like the number of variable names, parenthesis, and
operators to differentiate benign and malicious JavaScript
code. Vatamanu et al. [59] tokenizes JavaScript code
into variables types, function names, operators, etc. and
constructs clusters of tokens as signatures for benign and
malicious documents. Similarly, Lux0r [14] constructs
two sets of API reference patterns found in benign and
malicious documents, respectively, and uses this to clas-
sify maldocs. MPScan [31] differs from other JavaScript
static analyzers in a way that it hooks AAR and dynam-
ically extracts the JavaScript code. However, given that
code analysis is still statically performed, we consider it
a static analysis technique.
A common drawback of these approaches is that they
can be evaded with heavy obfuscation and dynamic code
loading (except for [31] as it hooks into AAR at runtime).
Static parsers extract JavaScript based on pre-defined
rules on where JavaScript code can be placed/hidden.
However, given the flexibility of PDF specifications, it is
up to an attacker’s creativity to hide the code.
The other line of work focuses on examining PDF file
metadata rather than its actual content. This is partially
inspired by the fact that obfuscation techniques tend to
abuse the flexibility in PDF specifications and hide ma-
licious code by altering the normal PDF structure. PDF
Malware Slayer [36] uses the linearized path to specific
PDF elements (e.g., /JS, /Page, etc) to build maldoc clas-
sifiers. Srndic et al. [52] and Maiorca et al. [33] go one
step further and also use the hierarchical structure for
classification. PDFrate [46] includes another set of fea-
tures such as the number of fonts, the average length of
streams, etc. to improve detection. Maiorca et al. [34]
focuses on both JavaScript and metadata and fuses many
of the above-mentioned heuristics into one procedure to
improve evasion resiliency.
All methods are based on the assumption that the nor-
mal PDF element hierarchy is distorted during obfusca-
tion and new paths are created that could not normally
exist in benign documents. However, this assumption
is challenged by two attacks. Mimicus [53] implements
mimicry attacks and modifies existing maldocs to appear
more like benign ones by adding empty structural and
metadata items to the documents with no actual impact on
rendering. Reverse mimicry [35] attack, on the contrary,
attempts to embed malicious content into a benign PDF
by taking care to modify it as little as possible.
2.2 Dynamic Techniques
All surveyed dynamic analysis techniques focus on em-
bedded JavaScript code only instead of the entire doc-
ument. MDScan [58] executes the extracted JavaScript
code on a customized SpiderMonkey interpreter and the in-