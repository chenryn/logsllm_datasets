定义，为功能开发人员创建和迭代自助服务工具和产品。开发人员不再需要使用电子表格规划容量或通过
SSH
到部署服务器来执行安装过程。只需轻点几下按钮，小队就拥有了部署服务所需的容量。
 我们在 2015
年建立了一个最佳实践的堆栈，该堆栈由基础结构团队明确支持和维护，成为如何在
Spotify
开发、部署和监视后端服务的"黄金路径"。我们开始使用"黄金路径"一词来描述由我们的基础架构团队支持、维护和优化的一系列步骤。我们希望使黄金路径易于使用，因而没有理由使用其他方案，而不必将最佳实践作为解决方案强推给其他团队。
黄金路径包括我们给的开发人员的使用指南。包括如何设置他们的环境；如何让创建一个简单的、Docker
化的服务；管理机密；添加存储；准备轮值；最后如何正确弃用服务。我们还构建了
Java
微服务框架[Apollo](https://github.com/spotify/apollo)，它将为开发人员提供许多免费功能，如指标检测、日志记录和服务发现。[Heroic](https://github.com/spotify/heroic)和
Alien
则是我们的时间序列数据库（TSDB）和前端，允许工程师创建预包装的仪表板和警报，自动监控
Apollo
服务。然后，与[Helios](https://github.com/spotify/helios)配对提供了一种支持的方式，以受控方式推出
Docker 部署，实现零停机时间。
## 受益之处
 由于运维任务不断被最小化，小组现在能够更加专注于构建功能。但是，开发人员效率并不是提高基础架构内一致性的唯一好处。这让我们更容易从物理数据中心迁移到
Google
云平台，实现相当无缝的迁移。从开发人员的角度来看，大多数工作都发生在幕后。在
Google
云平台中创建容量与在裸机上创建容量没有什么不同。两者都没有部署或监视服务。从开发人员的角度来看，迁移到新的开发组或临时嵌入开发组变得没有压力，因为大家几乎使用一致的工具。
一致堆栈带来的另一个好处是，它可以防止我们陷入技术时尚来来去去的潜在陷阱。我们还可以对工程师使用的内容有深入的见解，告知我们如何改进自己的产品。运维复杂性和分散性现在大大降低，避免了许多故障处理时候的恶梦。我们能够规定运行服务的最佳实践，并提供持续支持。作为一个基础结构团队，我们决定减少责任，但努力承担好部分责任。
## 权衡
 It was not all easy sailing, though. Standardizing a technology stack
still had its drawbacks. Too restrictive, and we risk losing squad
autonomy and experimentation, hindering development when not all use
cases are addressed. We defined the Golden Path to be an Apollo service,
but hadn't yet provided explicit support for the legacy and internal
Python services, frontend applications, or data pipelines and analytics.
We provided the ability to easily create and destroy capacity, but we
didn't yet generally support autoscaling. These unaddressed use cases
indirectly contributed to the fragmentation that we were confronting as
some teams created their own bespoke tools for workarounds.
在某些情况下，不使用支持的工具。JetBrain 的 TeamCity
曾经是唯一使用的连续集成（CI）系统。对于后端服务开发人员来说，这变得太麻烦了，因此团队推出了自己的
Jenkins 实例。作为团队自主和实验验证的结果，Jenkins
的使用在团队中传播得如此之快，以至于它很快成为事实上的后端服务 CI
工具。我们使用的"小组的运维"模型很有意义，只不过团队缺乏良好的习惯来维持自己的
Jenkins
设置，因此它们往往已经过时、脆弱且不够安全。它迫使我们重新思考构建支持渠道，我们最终开发了明确支持的托管
Jenkins 服务。同样，我们发现开发人员没有维护他们的 Cassandra
群集，尽管我们的团队提供了工具。由于担心潜在的数据丢失，也担心实现维护对于功能团队来说太过沉重，我们通过提供托管
Cassandra 服务和相关支持，将此功能重新引入到我们的运维管理范围中。
尽管我们有很多自助服务工具来辅助功能团队，但 IO
部落仍然成为了落后的一环。2017
年，我们的重点再次转向通过优先考虑短暂性、安全性和可靠性需求来加强我们的整体基础设施。我们构建了启动整个集群受控滚动重启的工具，鼓励开发人员编写弹性服务。我们实现了区域故障转移演习的自动化，揭示了团队在跨区域的服务能力方面的不一致。随着我们在利用
Google
云平台提供的产品和服务方面取得进展，团队现在需要花时间从功能开发中抽出时间，例如迁移到新的云原生存储解决方案（如
Bigtable），但同时收获了便利（他们不再需要维护任何基础设施）。
尽管我们成功地转向了"小组的运维"模型，并在自主性和一致性之间取得平衡，但我们现在专注于消除运维中的摩擦，而且我们还有很长的路要走。
## 关键收获
这一时期的一些主要知识是：
-   黄金路径提供了一种从代码快速进入生产的低摩擦方式。
-   支持一个最佳实践的堆栈，并坚持下去。
-   对于采用最佳实践来说，提供明确的激励至关重要（例如，运维监视、连续部署管道）。  
# 未来：规模化的速度和安全
 在考虑未来时，我们可以想象到一种远景，即功能团队的运维负担已*安全*降至几乎为零。该基础架构支持数百个团队之间的持续部署和快速实验，大多数开发人员在大规模运维其服务时几乎没有顾虑。这是梦想，但我们还没有完全实现。
作为零运维梦想的一部分，有许多技术转变正在实现。对于我们而言，此策略的第一部分是迁移到云。我们可以将问题转移到云服务商身上，并从其规模经济中获益，而不是将时间花在不能给我们带来竞争优势的任务上（例如数据中心管理和硬件配置）。
第二部分是采用云思维，从定制解决方案转向充满活力的开源社区产品。这方面的一个例子是，我们计划从自主研发的容器编排系统
Helios 迁移到一个托管的 Kubernetes 服务（谷歌的 Kubernetes
引擎）。在采用 Kubernetes
而不是进一步投资于我们自己的容器编排系统时，我们可以从开源社区的许多贡献中获益。进行这些转变使运维团队能够专注于组织面临的更高级别问题，从而提供更多价值。
即使云带来了抽象的理念，运维团队仍应掌控平台的稳定运行。 为此，我们需要不断提醒自己，*规模化的速度和安全*或简称为
s^3^。我们希望使 Spotify
能够尽可能快地迭代，且以可靠和安全的方式进行迭代。我们认为迁移到云符合这个思路，但作为基础架构和运维工程师，我们也面临着更微妙的问题。最初，服务、数据中心、网络和硬件都由我们架构、配置和管理；我们理解这些系统运行和支持的复杂性。随着云的采用，而且随着规模不断扩大，我们需要更好的洞察、自动化和沟通渠道，以确保我们能够满足
99.95% 的内部可用性
SLO。因此，我们投资于可靠性作为一个产品，其中包括从混沌工程到黑盒监控服务等一系列领域。
*规模化的速度和安全*的口号，它同样涉及我们如何指导功能团队完成无数的技术产品。我们不能成为创新的障碍，但我们也需要确保平台的可靠性，这意味着我们需要在可靠性是核心问题的情况下保证一致性。这包括构建正确的思维，也就是质量化工程，让工程师使用的强大开发人员平台来寻找适合其需求的产品，以及协调一致的教学和宣传工作。
为此，我们还需要重新评估我们的"小组的运维"模式。虽然这种结构对我们很有用，但我们需要考虑如何进一步减轻功能小队今天面临的运维负担。自实施此变革以来的几年中，我们作为一家公司不断成长和学习，过去采用的成功指标对将来可能并不适用。我们不知道具体会是什么样子，但我们知道，我们将是敏捷的，并继续试验，以找到最好的解决方案。例如，考虑我们的事件管理过程。团队的轮值工程师将对影响其服务的事件进行会审，如果需要将上报
IMOC，从而对影响范围广的问题提供总体事件协调和沟通方面的协助。尽管 IMOC
结构一直是快速解决重大问题的重要机制，但对于我们遍布全球越来越多的员工来说，并不总是了解何时需要上报
IMOC，也并不能普遍了解如何处理团队轮值。在这种情况下，我们需要改进整个组织的运维最佳实践教学，以及我们自己如何做到这一点（我们倡导的运维质量）可能需要调整"小组的运维"背后的思维框架。
 最后，随着技术格局的变化，我们的站点可靠性需求也发生了变化。我们正在探索的一个领域是机器学习。凭借数千个虚拟机实例和系统以及一百多个跨职能团队，我们可能会发现机器学习是理解不断增长的复杂微服务生态系统的有效方法。此外，我们还有机会彻底改变过去基本上属于手动调节的任务，无论是"正确调整"我们的云容量需求，还是在发生下一个重大事件之前预测它；这里的机会是很多的。我们不仅可以预测事件，还可以通过自我修复服务或向受信任状态提供自动故障回退来缓解这些事件。
还有其他基础设施趋势需要考虑；例如，采用无服务器模式会给我们的服务基础架构带来一系列挑战，从我们如何监控到如何部署和操作。我们还看到组织和技术的转变；我们的开发人员越来越多地在后端、数据、移动和机器学习系统中工作。为了支持其端到端交付，我们需要跨越这些领域的无缝接触点。可靠性不能再集中在仅关心后端系统的稳定型上，还必须考虑数据和机器学习引擎网络，这些引擎为我们的生态系统提供了越来越多的价值。
希望你能够了解我们在构建全球运维和基础设施组织方面的成功和失败。尽管我们已经尝试了许多不同的
SRE
风格，而且现在的"小组的运维"模型还能奏效，但我们相信，使我们成功的不是模型本身，而是我们愿意接受变革，同时牢记核心
SRE
原则。随着技术格局的变化，我们还需要不断演变，以确保*音乐永远不会停。*           
# 编者介绍
Daniel Prata Almeida 是 Spotify 的基础设施和运维产品经理。在以前作为 SRE
的日子里，他负责轮值并培育了复杂的分布式系统。他沉迷于追求系统在线时间。
Saunak Jai Chakrabarti 领导美国 Spotify
的基础设施和运维。他对分布式系统充满热情，并且喜欢研究故障或意外工作的所有不同方式。
Jeff Eklund，以前在 Spotify，是一个 SRE
和技术历史学家，对神秘和古怪的事情有热情。他相信每任何电脑问题都能通过坚韧、友爱和拉面来解决。
David Poblador i Garcia，前 SRE 和产品主管，现在在 Spotify
技术平台的工程主管，据传是艰深技术知识和战略方面的老法师。
Niklas Gustavsson 以前是 Spotify 最差服务的所有者，目前担任 Spotify
的首席架构师。
Mattias
Jansson（Spotify）是一位前【开发人员、教师、SRE、经理】，现任敏捷教练。他是一个资深极客，对各种系统充满热情（无论是硅晶片系统还是碳合金系统）。
Drew Michel 是 Spotify 的
SRE，试图在混乱面前保持灯光亮起。在业余时间，他喜欢长跑和遛他的澳大利亚牧羊犬。
Lynn Root 是 Spotify 的
SRE，其历史问题包括使用她的姓氏作为她的用户名，以及常驻 FOSS
传道者。她也是 Pyladies 的全球领导者，也是 Python
软件基金会董事会的前副主席。当她的手不在键盘上时，通常抱着贝斯吉他。
Johannes Russek，Spotify 的正式前任 SRE
和技术产品经理，担任非官方的问题嗅探犬和软件系统考古学家。最喜欢的工具是白板。