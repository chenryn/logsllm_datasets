title:Resource and virtualization costs up in the cloud: Models and design
choices
author:Daniel Gmach and
Jerry Rolia and
Ludmila Cherkasova
Resource and Virtualization Costs up in the Cloud: Models and Design Choices 
Daniel Gmach 
HP Labs 
Palo Alto, CA, USA 
e-mail: PI:EMAIL 
Jerry Rolia 
HP Labs 
Bristol, UK 
e-mail: PI:EMAIL 
Ludmila Cherkasova 
HP Labs 
Palo Alto, CA, USA 
e-mail: PI:EMAIL
Abstract—Virtualization  offers  the  potential  for  cost-effective 
service provisioning. For service providers who make significant 
investments in new virtualized data centers in support of private 
or public clouds, one of the serious challenges is the problem of 
recovering  costs  for  new  server  hardware,  software,  network, 
storage,  management,  etc.  Gaining  visibility  and  accurately 
determining  the  cost  of  shared  resources  used  by  collocated 
services  is  essential  for  implementing  a  proper  chargeback 
approach  in  cloud  environments.  We  introduce  and  compare 
three  different  models  for  apportioning  cost  and  champion  the 
one  that  is  least  sensitive  to  workload  placement  decisions  and 
provides  the  most  robust  and  repeatable  cost  estimates.  A 
detailed  study  involving  312  workloads  from  an  HP  customer 
environment demonstrates the result. Finally, we employ the cost 
model  in  a  case  study  that  evaluates  the  impact  on  the  cost  of 
exploiting  different  virtualization  platform  alternatives  for  the 
312 workloads. For example, some workloads  may cost  more to 
host  using certain virtualization  platforms than  on others or  on 
standalone hosts. We demonstrate different  decision points with 
potential  cost  savings  of  nearly  20%  by  “right-virtualizing”  the 
workloads. 
Keywords-component; Resource Sharing, Workload Placement, 
Virtualization, Burstiness, Cost models 
I. 
INTRODUCTION 
top  of 
through 
Virtualization technologies promise great opportunities for 
server 
reducing  energy  and  hardware  costs 
consolidation. Moreover, virtualization can optimize resource 
sharing  among  applications  hosted 
in  different  virtual 
machines to better meet their resource needs. As a result more 
and  more  computing  can  be  conducted  in  shared  resource 
pools that act as private and public clouds. A new hot topic in 
cloud computing and the virtualized world is how to account 
for shared infrastructure usage and to chargeback the costs of 
running  services  on 
the  underlying  physical 
infrastructure. In the recent past, before the virtualization era, 
the 
and 
straightforward:  the  server  hardware,  its  power  usage,  and 
software  costs  were  directly  associated  with  the  deployed 
application  using  these  resources,  while  the  storage  and 
networking costs were typically apportioned on a usage basis. 
When  multiple  virtual  machines  with  different  resource 
requirements  are  deployed  to  a  resource  pool  and  when  the 
virtual  machines  may  be  frequently  reassigned  to  different 
physical servers, the question becomes more complex: “who is 
responsible for the incurred costs?” and “how to attribute the 
cost recovery”? The focus of this paper is on the notion of cost 
accounting  model  was 
relatively 
simple 
recovery  or  chargeback,  as  opposed  to  pricing  or  what 
customers are willing to bid/pay for resources.  
A  common  sense  approach  for  establishing  the  cost  of 
providing  a  service  is  to  extend  the  usage-based  model,  i.e., 
from  virtualization  layer  monitoring  information  one  can 
derive  average  resource  usage  per  application  for  a  costing 
interval, e.g., three  weeks, and then the physical server costs 
can be split up respectively. Currently, many service providers 
employ  such  simplified  usage–based  accounting  models 
[1─4]. However, the relationship between workloads and costs 
is actually more complex. Some workloads may have a large 
peak  to  mean  ratio  for  demands  upon  server  resources.  We 
refer  to  such  workloads  as  bursty.  For  example,  a  workload 
may  have  a  peak  CPU  demand  of  5  CPU  cores  but  a  mean 
demand of 0.5 of a CPU core. Such ratios may have an impact 
on  shared  resource  pools.  A  pool  that  aims  to  consistently 
satisfy the demands of bursty workloads will have to limit the 
number of workloads assigned to each server. This affects the 
number of servers needed for a resource pool. Thus, burstiness 
affects costs. Further, server resources are rarely fully utilized 
even when workloads are tightly consolidated and all servers 
are  needed  Even  though  many  services  can  be  assigned  to  a 
server, some portion of the resources remain unused over time. 
The  amount  of  unused  resources  may  depend  on  workload 
placement/consolidation  choices  and 
these  choices  may 
change  frequently.  The  costs  of  such  unallocated  resources 
must be apportioned across workloads, but it should be done 
in  a  fair  and  predictable  way.  Even  traditional  cloud  service 
provider pay-per-use models factor in such unusable capacity 
into their pay-per-use pricing.  
in  such  environments,  and  consider 
In  this  paper,  we  discuss  these  issues,  consider  three 
models  for  apportioning  server  costs  among  workloads  that 
share  servers 
the 
implications  of  these  different  choices  in  a  study  with  312 
workloads  from  an  HP  customer  environment.  We  then 
employ our choice of cost model in a case study that evaluates 
the  impact  on  the  cost  of  exploiting  different  virtualization 
platform  alternatives  for  the  312  workloads.  Each  alternative 
has  its  advantages  and  disadvantages;  a  key  differentiator  is 
cost. We demonstrate different decision points  with potential 
cost  savings  of  nearly  20%  by  “right-virtualizing”  the 
workloads. 
This paper is organized as follows. Section II presents the 
background on the workload consolidation approach and tools 
we employ. Section III formally introduces the notion of costs 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 18,2021 at 14:41:31 UTC from IEEE Xplore.  Restrictions apply. 
978-1-4244-9233-6/11/$26.00 ©2011 IEEE395and three models for apportioning costs. Section IV presents a 
workload  characterization  for  a  server  consolidation  exercise 
considered  in  the  paper.  Section  V  presents  a  study  that 
compares 
three  proposed  cost  models.  Section  VI 
demonstrates  the  usefulness  of  the  proposed  cost  model  by 
evaluating  design  choices  for  a  virtualized  environment. 
Finally,  we  present  related  work  and  offer  a  summary, 
conclusions, and a description of our next steps. 
the 
in 
the  costing  method  and 
II.  BACKGROUND: WORKLOAD CONSOLIDATION ENGINE 
This  section  briefly  describes  the  workload  consolidation 
engine  employed 
right-
virtualization  studies.  Its  main  functionality  is  to  find  an 
appropriate workload placement while minimizing the number 
of  servers  used  for  hosting  these  workloads.  The  workload 
consolidation engine has two components [6]. 
•  A  simulator  component  that  emulates  the  assignment  of 
several  application  workloads  on  a  single  server.  It 
traverses  per-workload  historical  time  varying  traces  of 
demand  to  determine  the  peak  of  the  aggregate  demand 
for the combined workloads. If for each capacity attribute, 
e.g., CPU and memory, the peak demand is less than the 
capacity of the attribute for the server then the workloads 
fit on the server. 
•  An  optimizing  search  component  that  examines  many 
alternative  placements  of  workloads  on  servers  and 
reports the best solution found. The optimizing search is 
based on a genetic algorithm [5].  
The consolidation engine supports both consolidation and 
load  leveling  exercises.  Load  leveling  balances  workloads 
across  a  set  of  resources  to  reduce  the  likelihood  of  service 
level violations. The engine offers the controlled overbooking 
of capacity and is capable of supporting a different quality of 
service for each workload [7]. Without loss of generality, this 
paper  considers 
the  highest  quality  of  service,  which 
corresponds to a required capacity for  workloads on a server 
that is the peak of their aggregate demand. The engine can be 
used to support studies on the advantages of consolidation and 
for operational management [16]. 
III.  COSTS AND APPORTIOINING COSTS 
The  total  costs  of  a  resource  pool  include  the  acquisition 
costs for facilities, physical IT equipment and software, power 
costs  for  operating  the  physical  machines  and  facilities,  and 
administration  costs.  Acquisition  costs  are  often  considered 
with  respect  to  a  three  year  time  horizon  and  reclaimed 
according  to  an  assumed  rate  for  each  costing  interval. 
Without  loss  of  generality,  this  paper  focuses  on  server  and 
virtualization software licensing costs only.  
Below,  we  define  three  categories  of  resource  usage  that 
can be tracked separately for each server resource, e.g., CPU, 
memory,  for  each  costing  interval.  To  simplify  the  notation, 
the  equations  that  we  present  consider  only  one  server 
resource  at  a  time,  e.g.,  CPU  or  memory  for  one  costing 
interval.  Then  the  corresponding  costs  over  all  resources  are 
summed up to give a total cost for all server resources for each 
costing  interval.  Final  costs  are  the  sum  of  costs  over  all 
costing intervals. The three categories of resource usage are: 
•  Direct  resource  consumption  by  a  workload:  the 
notation  ds,w  represents 
the  average  physical  server 
utilization of a server s by a workload w. The values of ds,w 
are in [0,100]. Note, that ds,w is 0 if a workload w does not 
use a server s. 
•  Burstiness for a workload and for a server: the notation 
bs,w represents the difference between peak utilization of a 
server  s  by  workload  w  and  its  average  utilization 
represented  by  ds,w.  The  values  of  bs,w  are  in  [0,100]. 
Additionally, bs represents the difference between the peak 
utilization  of  a  server  s  and  its  average  utilization.  The 
values of bs are in [0,100]. 
•  Unallocated  resource  for  a  server:  the  notation  as 
represents  unallocated  (unused)  server  capacity;  it  is 
defined  as  the  difference  between  100  and  the  peak 
utilization of server s. The values of as are in [0,100]. The 
notation a refers to unallocated resource. 
Next, we present 3 different models for apportioning cost. 
We refer to these as server-usage, server-burst, and pool-burst 
models.  
to 
its 
First,  we  consider  a  server-usage  model  that  takes  into 
account only the direct resource consumption by W workloads. 
This  a  traditional  usage-based  approach  applied  by  many 
service  providers  due 
simple  definition  and 
straightforward resource accounting schema. Suppose a server 
s has a cost Cs. The server costs include CAPEX, e.g., fraction 
of  acquisition  costs  based  on  the  length  of  the  considered 
interval,  as  well  as  OPEX,  e.g.,  costs  for  power  associated 
with the server. We define a workload’s server-usage share of 
a server as ∏server-usage
server
ws
,
s,w: 
−
usage
(1) 
=
C
s
∏
ws
,
d
W
∑
d
w
1'
=
ws
,
'
We will demonstrate the outcome of the introduced models 
by  considering  and  comparing  the  costs  of  two  specially 
selected  workloads  in  the  set  of  312  workloads  from  an  HP 
customer environment (this workload set will be described in 
more  detail  in  the  next  Section  IV).  We  consolidate  these 
workloads  using  the  consolidation  engine  described  in  the 
previous  Section  II,  and  then  compute  their  cost  in  the 
produced consolidation scenario c. 
Figure 1 shows CPU demands of two workloads for three 
weeks  (100  shares  correspond  to  one  1GHz  CPU)  and 
demonstrates  the  impact  of  load  burstiness  on  costs.  Both 
workloads  exhibit  similar  average  CPU  demands:  162  CPU 
shares for Workload A and 170 for Workload B. Using Eq. (1) 
for  the  consolidation  scenario  c,  the  CPU  cost  for  hosting 
Workload A  is  $36  whereas  for  Workload B  $39.  However, 
this cost model does not reflect the real hosting costs for the 
two  considered  workloads.  Workload A  has  much  higher 
variability  and  much  higher  peaks  than  Workload B,  1200 
CPU  shares  compared  to  645  CPU  shares,  i.e.,  Workload A 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 18,2021 at 14:41:31 UTC from IEEE Xplore.  Restrictions apply. 
396has  two  times  higher  peaks  than  Workload B.  Burstiness  of 
Workload A actually causes a less dense workload placement 
possible  on  the  server,  and  hence  a  lower  average  server 
utilization,  and  the  need  for  more  servers.  The  server-usage 
approach  does  not  take  into  account  the  impact  of  workload 
burstiness on costs. 
1400
1200
1000
Workload A
Workload B
s
e
r
a
h
S
n
i
d
n
a
m
e
D
U
P
C
800
600
400
200
0
0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21
Figure 1 Example: CPU demands of two workloads 
Day
s,  respectively,  where  Cd
To take into account burstiness and unallocated resources 
we partition server cost Cs based on utilization to get Cd
s, 
Ca
s  corresponds  to  costs  associated 
with  the  average  utilization  of  the  server  s,  and  Cb
s  and  Ca
s 
correspond  to  the  difference  between  peak  and  average 
utilization of the resource, and difference between 100% and 
the peak utilization of the resource, respectively. 
s, Cb
C
d
s
=
uC
s
d
s
C
,
b
s
=
uC
(
s
b
s
−