corruption. Another disadvantage of γk (for k > 0) is the fact that
it does not distinguish between honest votes that are dropped
and those that are turned into different valid votes, although the
impact on the ﬁnal result by the second kind of manipulation
783783
is stronger than the one by the ﬁrst kind. To illustrate this
issue, consider two voting protocols P1 and P2 (with the result
function ρ being the counting function). In P1 the adversary
might not be able to turn votes by honest voters into different
valid votes, e.g., turn a vote for candidate A into a vote for
B. This can be achieved if voters sign their ballots. In this
case, the adversary can only drop ballots of honest voters. In
P2 voters might not sign their ballots, and hence, the adversary
can potentially manipulate honest votes. Now, P1 obviously
offers stronger veriﬁability because in P1 votes of honest voters
can only be dropped, but not changed: while in P2 the adversary
could potentially turn ﬁve honest votes, say for candidate A,
into ﬁve votes for B, in P1 one could at most drop the ﬁve
honest votes, which is less harm. Still both protocols might
achieve the same level of veriﬁability in terms of the parameters
γk and δ. If γk distinguished between dropping of votes and
manipulation, one could distinguish the security levels of P1
and P2.
In Section X we propose a new goal which solves the
mentioned problems.
V. VERIFIABILITY BY BENALOH
In this section, we study the veriﬁability deﬁnition by
Benaloh [12]. This deﬁnition constitutes the ﬁrst formal
veriﬁability deﬁnition proposed in the literature, and hence,
the starting point for the formal treatment of veriﬁability.
This deﬁnition is close in its essence to the one discussed
in Section IV.
A. Model
Following [12], an l-threshold m-teller n-voter election
system (or simply (l,m,n)-election system) E is a synchronous
system of communicating processes (probabilistic Turing ma-
chines) consisting of m tellers T1, . . . , Tm, n voters V1, . . . , Vn
and further participants. Each process of an election system
controls one bulletin board. Each bulletin board can be read
by every other process, but only be written by the owner.
The intended (honest) behavior of the system participants is
speciﬁed by an election schema. An (l,m,n)-election schema
S consists of a collection of programs to be used by the
participants of an (l,m,n)-election system and an efﬁciently
computable function check, which, given the security parameter
(cid:5) and the messages posted to the public bulletin boards, returns
either ”good” or ”bad”. The election schema S describes a
program πT for each teller process and two possible programs
for each voter: πyes to be used to cast a ”yes” vote and program
πno to be used to cast a ”no” vote. At the end of the election,
each teller Tk releases a value τk.
Any process which follows (one of) its program(s) pre-
scribed by S is said to be proper. We say that a voter casts a
valid “yes” vote, if the messages it posts are consistent with the
program πyes, and similarly for a “no” vote. Note that a proper
voter, by deﬁnition, always casts a valid vote; an improper
voter may or may not cast a valid vote, and if it does not cast
a valid vote, that fact may or may not be detectable by others.
The tally of an election is the pair (tyes,tno) where tyes and
tno are the numbers of voters who cast valid ”yes” and ”no”
votes, respectively. Note that this pair expresses the expected
result corresponding to the cast valid votes. The tally of the
election is said to be correct if ρ(τ1, . . . , τm) = (tyes,tno), where
ρ is a pre-determined function. The expression ρ(τ1, . . . , τm)
describes the actual tally, that is the result of the election
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:17:36 UTC from IEEE Xplore.  Restrictions apply. 
as jointly computed by the tellers (and combined using the
function ρ).
B. Veriﬁability
Now, in [12], veriﬁability is deﬁned as follows.
Deﬁnition 3 (Veriﬁability). Let δ be a function of (cid:5). The
(l,m,n)-election schema S is said to be veriﬁable with con-
ﬁdence 1 − δ if, for any election system E, check satisﬁes
the following properties for random runs of E using security
parameter (cid:5):
(1) If at least l tellers are proper in E, then, with probability
at least 1− δ((cid:5)), check returns good and the tally of the
election is correct.
(2) The joint probability that check returns good and the
election tally is not correct is at most δ((cid:5)).
The election schema S is said to be veriﬁable if δ is negligible.
Condition (1) of Deﬁnition 3 expresses a fairness condition
(see Section III-B), where to guarantee the successful (and
correct) run of a protocol, it is enough to only assume that l
tellers are honest.
Condition (2) of Deﬁnition 3 is the core of Deﬁnition 3.
Roughly speaking, it corresponds to Deﬁnition 1 with the goal
γ0 deﬁned by K¨usters et al. (see Section IV-B). As discussed
below, there are, however, subtle differences, resulting in a too
strong deﬁnition.
C. Discussion
As mentioned before, Benaloh’s deﬁnition constitutes the
ﬁrst formal veriﬁability deﬁnition, mainly envisaging an entirely
computer-operated process based on trusted machines and
where, for example, voters were not asked to perform any
kind of veriﬁcation. Given this setting, the deﬁnition has some
limitations from a more modern point of view.
Similarly to the deﬁnition in Section IV, this deﬁnition
is fairly simple and general, except that only yes/no-votes
are allowed, tellers are explicitly required in this deﬁnition,
and every participant has his/her own bulletin board. These
restrictions, however, are not necessary in order to deﬁne
veriﬁability as illustrated in Section IV. This deﬁnition also
focuses on static corruption. The main problem with this
deﬁnition is that it is too strong in settings typically considered
nowadays, and hence, it would exclude most e-voting protocols,
even those that intuitively should be considered veriﬁable.
As already mentioned, Condition (2) of Deﬁnition 3 is
related to the goal γ0. The goal γ0 is, however, typically too
strong because, for example, not all honest voters perform the
veriﬁcation process, e.g., check whether their ballots actual
appear on the bulletin board. Hence, there is a non-negligible
chance that the adversary is not caught when dropping or
manipulating ballots. This is why K¨usters et al. (Section IV)
considered goals γk for k ≥ 0.
Moreover, the goal considered here is even stronger (see also
Section V-D). Condition (2) in Deﬁnition 3 is concerned not
only with honest voters, but also with dishonest ones who post
messages consistent with honest programs. Now, the problem is
that a dishonest voter could simply cast a vote just like an honest
one. The dishonest voter may, however, never complain even if
dishonest tellers (who might even team up with the dishonest
voter) drop or manipulate the ballot of the dishonest voter.
Hence, it cannot be guaranteed that votes of such dishonest
voters are counted, unlike what Condition (2) in Deﬁnition 3
requires. So, Deﬁnition 3 would deem almost all e-voting
protocols in settings typically considered nowadays insecure,
even completely reasonable ones.
Also, Condition (1) of Deﬁnition 3 may be too strong in
many cases. It says that the threshold of l tellers is enough to
guarantee that a protocol run is correct, i.e., in terms of the
KTV framework, the judge would accept the run. It might not
always be possible to resolve disputes, for example, when voters
complain (possibly for no reason). For the sake of generality of
the deﬁnition, it would therefore be better to allow for a more
ﬂexible fairness condition, as the one sketched in Section IV.
D. Casting in the KTV Framework
We now cast Deﬁnition 3 in the KTV Framework. To this
end, we have to deﬁne the class of protocols considered in [12]
in terms of the KTV Framework and the goal γ.
Protocol PB. The set of agents Σ consists of the voters,
the judge J, one bulletin board for each of
the tellers,
these participants, and the remaining participants. Since static
corruption is considered, the agents accept a corrupt message
only at the beginning of an election run. The bulletin boards and
the judge do not accept corrupt message at all. As usual, we
consider an additional honest party, the scheduler. The honest
programs are deﬁned as follows:
– The scheduler behaves in the expected way: it triggers all
the parties in every protocol step. The judge is triggered in
the ﬁnal phase, after the tellers are supposed to output their
(partial) tallying.
– The honest behavior of the bulletin boards is as described
in Section II, with the only difference that a bulletin board
owned by some party accepts messages posted only by this
party; it serves its content to all parties, though.
– When a voter V runs her honest program πV, she ﬁrst expects
”yes” or ”no” as input (if the input is empty, she stops). If
the input is ”yes”, she runs πyes, and otherwise πno. She
sends the result to her bulletin board B(V); πV might later
be triggered again to perform veriﬁcation steps.
– When the judge J runs πJ and is triggered in the ﬁnal
phase, it reads the content of all the bulletin boards and
computes the result of the function check on this content. If
check evaluates to ”good”, it outputs ”accept”, and otherwise
”reject”.
– The honest program πT of T depends on the concrete election
system that is used.
The goal. We deﬁne the goal γ∗
0 to be γ0 (see Deﬁnition 2),
with the difference that, instead of considering the multiset
c1, . . . , cnh of choices of honest voters only, we now consider
the multiset of choices of all voters who cast a valid vote. This,
as explained, includes not only honest voters, but might also
include some dishonest voters.
Veriﬁability. Now, it should be clear that the notion of
veriﬁability deﬁned by Benaloh can be characterized in terms
of Deﬁnition 1 as (γ∗
, δ)-veriﬁability.4 As discussed before,
the goal γ∗
0 is too strong for several reasons.
0
4Recall that here we do not consider the fairness conditions.
784784
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:17:36 UTC from IEEE Xplore.  Restrictions apply. 
VI. E2E VERIFIABILITY BY KIAYIAS ET AL.
In this section, we study the end-to-end veriﬁability deﬁni-
tion by Kiayias et al. [34], [33].
A. Model
According to Kiayias et al., an e-voting scheme Π is a tuple
(Setup, Cast, Tally, Result, Verify) of probabilistic polynomial-
time (ppt) algorithms where Cast and Tally are interactive. The
entities are the election authority EA, the bulletin board B, the
tellers T1, . . . , Tm and the voters. The algorithm Cast is run
interactively between B and a voter Vi where the voter operates
a voter supporting device VSD on the following inputs: public
parameters prmpub, a choice ci, and her credentials credi. Upon
successful termination, Vi obtains a receipt αi. The algorithm
Tally is run between EA, the tellers and B. This computation
updates the public transcript τ. The algorithm Verify(τ , αi)
denotes the individual veriﬁcation of the public transcript τ by
voter Vi, while Verify(τ , sti) denotes the veriﬁcation of τ by
teller Ti on her private state sti; the output of Verify is a bit.
The algorithm Setup is run for setting up an election, and the
algorithm Result, given τ, outputs the result of the election, if
any.
B. E2E Veriﬁability
The E2E-veriﬁability deﬁnition by Kiayias et al. [34], [33]
is given in Figure 1. The adversary can corrupt voters and
tellers, and he controls the EA and the VSDs of voters. The
bulletin board is assumed to be honest, but the adversary can
determine the content τ of it. The set Vcast contains all voters
who successfully terminated their protocol, and hence, obtained
a receipt. However, they might not have veriﬁed their receipts.
The adversary wins the game if (i) |Vcast| ≥ θ, i.e., not too few
voters successfully terminated, and (ii) would all of these voters
verify their receipt, then they would verify successfully, and
(iii) the published result of the election Result(τ ) deviates by
at least k from the actual result ρ(c1, . . . , cn) obtained according
to the actual votes of voters. More speciﬁcally, for the last
condition, i.e., Condition (iii), Kiayias et al. postulates the
existence of a vote extractor algorithm Extr (not necessarily
running in polynomial-time) which is supposed to determine
the votes of all voters not in Vcast, where Extr is given the
transcript and the receipt of voters in Vcast as input. Note that
the adversary wins the game if Extr fails to return these votes
(Condition (iii-b)).
Deﬁnition 4 (E2E-veriﬁability). Let 0  0 and 0 < θ ≤ n. The election protocol Π w.r.t.
election function achieves E2E veriﬁability with error δ, for
a number of at least θ honest successful voters and tally
deviation k, if there exists a vote-extractor Extr such that for
any adversary A controlling less than n− θ voters and t tellers,
(cid:3) ≤ δ.
the EA and all VSD’s holds: Pr
GA,Extr,k,θ(1(cid:5),w,n,t) = 1
(cid:2)
We note that [34] considers a fairness condition (named
perfect correctness) similarly to the one in Section III-B.
C. Discussion
We ﬁrst note that the deﬁnition is too speciﬁc in some
situations due to the use of the extractor in the deﬁnition.
Indeed, it does not seem to apply to voting protocols where
ballots published on the bulletin board hide the choices of
voters information-theoretically, such as [24]. In this case, the
adversary could, for example, corrupt some voters but just
E2E Veriﬁability Game GA,Extr,k,θ(1(cid:5),w,n,t)
1) A chooses a list of choices C = {c1, . . . , cw}, a
set of voters {V1, . . . , Vn}, and a set of tellers
{T1, . . . , Tt}. It provides the challenger Ch with
these sets along with information prmpub and
voter credentials {credi}1≤i≤ n. Throughout the
game, Ch plays the role of B.
2) A and Ch engage in an interaction where A
schedules the Cast protocols of all voters. For
each voter Vi, A can either completely control
the voter or allow Ch operate on Vi’s behalf,
in which case A provides a choice ci to Ch.
Then, Ch engages in the Cast protocol with
the adversary A, so that A plays the roles of
EA and VSD. Provided the protocol terminates
successfully, Ch obtains a receipt αi on behalf
of Vi.
3) Finally, A posts the election transcript τ to B.
The game returns a bit which is 1 if the following
conditions hold true:
i) |Vcast| ≥ θ, (i.e., at least θ honest voters termi-
ii) ∀Vi ∈ Vcast : Verify(τ , αi) = 1 (i.e. the honest
voters that terminated veriﬁed successfully)
and either one of the following two conditions:
← Extr(τ ,{αi}Vi∈Vcast
(iii-a). If ⊥ (cid:11)= (ci)
),
then d1(Result(τ ), ρ(c1, . . . , cn)) ≥ k (d1 is a