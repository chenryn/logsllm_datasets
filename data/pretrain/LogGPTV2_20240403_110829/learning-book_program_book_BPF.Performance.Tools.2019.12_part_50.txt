256 -> 511
: 25
 + +
51.2 -> 1023
: 43
]  ×* t
1024 -> 2047
: 206
2048 > 4095
: 8
4096 -> 8191
: 8
8192 -> 16383
:392
disk = 'nvme0n1*
usec.a
 count
d1str1but.ion
0 > 1
: 0
E  7
: 0
8 -> 15
: 12
16 > 31
: 72
∈9  127
: 1240
128 -> 255
: 74
256 -> 511
: 13
512 -> 1023
: 4
1024 -> 2047
: 23
560  8191
: 63
---
## Page 392
9.3BPF Tools
355
This output shows two very different disk devices: nvme0n1, a flash-memory based disk, with I/O
latency often between 32 and 127 microseconds; and sdb, an external USB storage device, with a
bimodal I/O latency distribution in the milliseconds.
Flags
BCC biolatency(8) also has a F option to print each set of I/O flags differently. For example, with
n for millisecond histograms:
biolatency -Fn
Tracing block device I/0.., Hit Ctr1C to end
^C
[..-]
flags = Bead
nsecs
1count
distribution
0 -> 1
: 180
2 > 3
: 519
4 -> 7
: 60
|****
8 -> 15
: 123
|+********
16 -> 31
: 6B
32 -> 63
: 0
64 -> 127
: 2
128 -> 255
: 12
256 -> 511
: 0
512 -> 1023
:1
flags = Sync-Krite
nsecs
: count
dlstribut.ion
0 > 1
: 8
|***
E  7
: 37
B -> 15
￥ 4. [
: 65
1.6 -> 31
:93
E9  127
:6
| * *
128 -> 255
: 0
25 6 -> 511
:4
| *
512 -> 1023
: 17
| ++*+**+
flags = Flush
nsecs
1 count
distribution
0 -> 1
:2
|++*++++++++ *
---
## Page 393
356
Chapter 9 Disk I/0
flags = Metadata-Resd
nsec.a
count
dlstrlbution
0 -> 1
: 3
E 7
: 0
8 -> 15
: 1
+............
1 6 -> 31
: 1
|***+**++*+**+
Apnqs o sn smoe wuaug Sueuedas taotaap afeaops atq q Aquasap papueuq aq Aeu s8eg asat
them in isolation. The above output shows that synchronous writes are bi-modal, with a slower
mode in the 512- to 1023-millisecond range.
These flags are also visible in the block tracepoints via the rwbs field and one-letter encodings: see
the *rwbs° section, earlier in this chapter, for an explanation of this field.
BCC
Command line usage:
biolatency[optlons][intezval[count[]
Options include:
m: Print output in milliseconds (default is microseconds)
• Q: Include OS queued time
 D: Show each disk separately
fpaqeredas s8eg O/1 po pas qoea mous :#- -
 T: Include a timestamp on the output
Using an interval of one will print per-second histograms. This information can be visualized as
a latency heat map, with a full second as columns, latency ranges as rows, and a color saturation
to show the number of 1/O in that time range [Gregg 10]. See Chapter 17 for an example using
Vectot.
bpftrace
The following is the code for the bpftrace version, which summarizes its core functionality. This
suopdo μuoxddns sou saop uors1an
+1/usr/local/bin/bpftrace
BEGIN
printf (*Tracing block deviee I/0..
kprobe :blk_account_io_starf
---
## Page 394
9.3 BPF Tools
357
Bstart[argo] = nsecs;
kprobe:blk_account_io_done
/ [06xe]xexs8/
Busecs = hlstI (nsecs = @atazt[axgo]] / 1000) ;
delete (estart[arg0]1
END
1
clear (8start) 
This tool needs to store a timestamp at the start of each I/O to record its duration (latency).
However, multiple I/O can be in flight concurrently. A single global timestamp variable would
not work: a timestamp must be associated with each I/O. In many other BPF tools, this is solved
by storing timestamps in a hash with the thread ID as a key. This does not work with disk I/O,
since disk I/O can initiate on one thread and complete on another, in which case the thread ID
changes. The solution used here is to take arg0 of these functions, which is the address of the
struct request for the I/O, and use that memory address as the hash key. So long as the kernel does
not change the memory addres between issue and completion, it is suitable as the unique ID.
Tracepoints
The BCC and bpftrace versions of biolatency(8) should use the block tracepoints where possible,
but there is a challenge: the struct request pointer is not currently available in the tracepoint argu-
ID and sector number. The core of the program can be changed to the follwing (biolatency-tp.bt):
ments, so another key must be used to uniquely identify the I/O. One approach is to use the device
[.--]
tracepoint:block:block_rq_issue
Bstart[args->dev, args=>sector] - nsecs
tracepoint:block:block_rq_conplete
/8start [args=>dev, args=>sectox]/
Busecs = histI (nsecs - @start[args=>der, args=>sector]1 / 1000) :
delete @start[azgs=>dev, args=>sector]1
[. - -]
---
## Page 395
358
Chapter 9Disk I/O
This assumes that there is not multiple concurrent I/O to the same device and sector. This is
measuring the device time, not including the OS queued time.
9.3.2
biosnoop
following shows biosnoop(8) from BCC, running on a Hadoop production instance:
+biosnoep
TIME (s)
COM
PID
DISK
T SECTOR
BYTES
LAT (ns)
0, 000000
java
5136
xvdq
R. 980043184
45056
0 ,35
0., 000060
Java
5136
xvdq
R. 980043272
4505 6
0.40
0, 000083
java
5136
xvdiqg
R 980043360
4096
0 , 42
[..-]
0, 143724
java
5136
xvdy
R 5153784
4505 6
1,08
0 .143755
Java
5136
xvdy
R. 5153872
40960
1.10
0,185374
java
5136
xvdn
R 2007186664 45056
0.34
0 .189267
Java
5136
xvay
R.979232832
4505 6
14 ,00
0,190330
java
5136
xvdy
R. 979232920
45056
15.05
0 .190376
Java
5136
xvdy
R. 979233008
4505 6
15.09
0,190403
java
5136
ApAx
R. 979233096
45056
15 .12
0.190409
ava
5136
Apnx
R. 979233184
4505 6
15 ,.12
0,190441
java
5136
ApAx
R 2007186752 45056
R. 979233272
36864
15.15
0.190176
Java
5136
xvdn
5 .13
0.,190231
java
5136
xvdn
R 2007186840 45056
5 .18
[..-]
This output shows Java with PID 5136 doing reads to different disks. There were six reads with
latency of around 15 milliseconds. If you look closely at the TIME(s) column, which shows the I/O
completion time, these all finished within a fraction of a millisecond and were to the same disk
(xvdy). You can conclude that these were queued together: the latency creeping up from 14.00 to
15.15 milliseconds is another clue to queued I/O being completed in turn. The sector offsets are
also contiguous: 45056 byte reads are 88 × 512-byte sectors.
3 Orign: While I wss a sysadmin at the University of Newcastle, Austraia, in 2000, a shared sever wss suffering
slow disk performance, which wss suspected to be caused by a researcher running a batch job. They refused to move
their workiced unless I could prove that they were causing the hey disk I/0, but no tool could do this. A workaround
concocted either by me or the senior admin, Doug Scot, was to SIGSTOP their process while wstching iostat(1), then
SIGCONT it a few sends later: the dramatic drop in disk I/0 proved that they were responsible. Wanting 8 less irve
sive method, I saw the Sun TNF/prex tracing utility in Adrian Cockeroft's Sun Performance and Tun/ng book [Cockeroft
98], and on 3-Dee-2003 1 created psio(1.M), a utility to print disk I/0 by process [1.85], which also had a mode to trace
perevent disk I/0. 0OTrace wss made savsilatle in beta in the same month, and I eventually rewrote my disk I/0 tracer 85
iosnoop(1M) on 12-Ma2004, initially before there wss an io provider. I wss quoted in 7he Register’s DTrace snnounce
ment talking about this work [Vance 04]. 1 created the BCC version as biosnoop(8) on 16-Sep-2015, and the bpftrace
version on 1.5-Ngv201.7.
---
## Page 396
9.3 BPF Tools
69E
As an example of production use: teams at Netflix that run stateful services routinely use bios-
noop(8) to isolate ssues with read-ahead degrading the performance of I/O-intensive workloads.
Linux tries to intelligently read ahead data into the OS page cache, but this can cause severe
performance issues for data stores running on fast solid-state drives, especially with the default
read ahead settings. After identifying aggressive read-ahead, these teams then perform targeted
anoudtu uatq pue peantq Aq pazqueso Xouape[ pue azis O/1 po stureu8osq SuzA[eue 6q siopejat
performance by using an appropriate madvise option, direct I/O, or changing the default read-
ahead to smaller values such as 16 Kbytes. For histograms of I/O sizes, see vfssize(8) from Chapter
S and bitesize(8) from this chapter; also see the readahead(8) tool in Chapter 8, which was created
more recently for the analysis of this issue.
The biostoop(8) columns are:
● TIME(s): I/O completion time in seconds
• COMM: Process name, if cached
 PID: Process ID, if cached
• DISK: Storage device name
 T: Type: R == reads, W == writes
• SECTOR: Address on disk in units of 512-byte sectors
 BYTES: Size of the I/O
• LAT(ms): Duration of the 1/O from device issue to device completion
This works in the same way as biolatency(8): tracing kernel block I/O functions. A future version
should switch to the block tracepoints. The overhead of this tool is a little higher than biola
ndno quaaa-sad Suuad st #I se (g)oua
OS Queued Time
I/O and the issue to the device: this time is mostly spent on OS queues, but could also include
A Q option to BCC biosnoop(8) can be used to show the time spent between the creation of the
memory allocation and lock acquisition. For example:
: biosnoop -Q
TIME (s)
cksun
COMM
PID
DISK
T SECTOR
BYTES
QUE (ns)LAT (ns)
19. 925329
20405
sdb
R 249631
16384
17.17
19. 933890
1 . 63
cksun
20405
sdb
R 249663
122880
17,81
8.51
19. 942442
cksun
20405
sdb
R. 249903
122880
26.35
B .51
19 . 944161
cksun
20405
sdb
R 250143
16384