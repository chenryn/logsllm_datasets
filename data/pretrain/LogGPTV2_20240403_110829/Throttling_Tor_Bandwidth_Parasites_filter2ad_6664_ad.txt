it may download a large ﬁle and observe the change in
throughput after receiving a burst of β payload bytes.
(a)
(b)
(c)
Figure 4: 4a: Client’s may discover the throttle rate by probing guards. 4b: Information leaked by learning circuit throughputs.
4c: Information leaked by learning guards’ throttle rates.
If the ﬁrst β bytes are received at time t1 and the
download ﬁnishes at time t2 ≥ t1, the throttle rate at any
time t in this interval can be approximated by the mean
throughput leading up to t:
∀t ∈ [t1,t2], αt ≈ ∑t
(λk)
k=t1
t −t1
(2)
Therefore, αt2 approximates the actual throttle rate. Note
that this approximation may under-estimate the actual
throttle rate if the throughput falls below the throttle rate
during the measured interval.
We simulate probing in Shadow [2, 31] to show its ef-
fectiveness against the static throttling algorithm. As ap-
parent in Figure 4a, the throttle rate was conﬁgured at 5
KiB/s and the burst at 2 MiB. With enough resources, an
adversary may probe every guard node to form a com-
plete list of throttle rates.
Testing Circuit Throughput. A web server may deter-
mine the throughput of a connecting client’s circuit by
using a technique similar to that presented by Hopper
et al. [30]. When the server gets an HTTP request from
a client, it may inject either special JavaScript or a large
amount of garbage HTML into a form element included
in the response. The injected code will trigger a second
client request after the original response is received. The
server may adjust the amount of returned data and mea-
sure the time between when it sent the ﬁrst response and
when it received the second request to approximate the
throughput of the circuit.
5.2 Adversarial Attacks
We now explore several adversarial attacks in the con-
text of client throttling algorithms, and how an adversary
may use those attacks to learn information and affect the
anonymity of a client.
Attack 1. In our ﬁrst attack, an adversary obtains a dis-
tribution on throttle rates by probing all Tor guard relays.
10
We assume the adversary has resources to perform such
an attack, e.g. by utilizing a botnet or other distributed
network such as PlanetLab [13]. The adversary then ob-
tains access to a web server and tests the throughput of a
target circuit. With this information, the adversary may
reduce the anonymity set of the circuit’s potential guards
by eliminating those whose throttle rate is inconsistent
with the measured circuit throughput.
This attack is somewhat successful against all of
the throttling algorithms we have described. For bit-
splitting, the anonymity set of possible guard nodes will
consist of those whose bandwidth and number of active
connections would throttle to the throughput of the target
circuit or higher. By running the attack repeatedly over
time, an intersection will narrow the set to those whose
throttle rate is consistent with the target circuit through-
put at all measured times.
The ﬂagging algorithm throttles all ﬂagged connec-
tions to the same rate system-wide.
(We assume here
that the set of possible guards is already narrowed to
those whose bandwidth is consistent with the target cir-
cuit’s throughput irrespective of throttling.) A circuit
whose throughput matches the system-wide rate is either
ﬂagged at some guard or just coincidentally matches the
system-wide rate and is not ﬂagged because its EWMA
has remained below the splitRate (see Algorithm 2)
for its guard long enough to not be ﬂagged or become
unﬂagged. The throttling rate is thus not nearly as infor-
mative as for bit-splitting. If we run the attack repeatedly
however, we can eliminate from the anonymity set any
guard such that the EWMA of the target circuit should
have resulted in a throttling but did not. Also, if the
EWMA drops to the throttling rate at precise times (ig-
noring unusual coincidence), we can eliminate any guard
that would not have throttled at precisely those times.
Note that this determination must be made after the fact
to account for the burst bucket of the target circuit, but it
can still be made precisely.
0102030405060Time(m)0510152025303540Throughput(KiBps)0.00.51.01.52.02.53.0EntropyLost(bits)0.00.20.40.60.81.0CumulativeFractionvanillastaticsplitﬂagthresh0.00.51.01.52.02.53.0EntropyLost(bits)0.00.20.40.60.81.0CumulativeFractionvanillastaticsplitﬂagthreshThe potential for information going to the attacker in
the threshold algorithm is a combination of the potential
in each of the above two algorithms. The timing of when
a circuit gets throttled (or does not when it should have
been) can narrow the anonymity set of entry guards as in
the ﬂagging algorithm. Once the circuit has been throt-
tled, then any ﬂuctuation in the throttling rate that sepa-
rates out the guard nodes can be used to further narrow
the set. Note that if a circuit consistently falls below the
throttling rate of all guards, an attacker can learn nothing
about its possible entry guard from this attack. Attack 2
considerably improves the situation for the adversary.
We simulated this attack in Shadow [2, 31]. An ad-
versary probes all guards and forms a distribution on the
throttle rate at which a connection would become throt-
tled. We then form a distribution on circuit throughputs
over each minute, and remove any guard whose throttle
rate is outside a range of one standard deviation of those
throughputs. Since there are 50 guards, the maximum
entropy is log2(50) ≈ 5.64; the entropy lost by this at-
tack for various throttling algorithms relative to vanilla
Tor is shown in Figure 4b. We can see that the static
algorithm actually loses no information, since all con-
nections are throttled to the same rate, while vanilla Tor
without throttling actually loses more information than
any of the throttling algorithms. Therefore, the distri-
bution on guard bandwidth leaks more information than
throttled circuits’ throughputs.
Attack 2. As in Attack 1, the adversary again obtains
a distribution on throttle rates of all guards in the sys-
tem. However, the adversary slightly modiﬁes its circuit
testing by continuously sending garbage responses. The
adversary adjusts the size of each response so that it may
compute the throughput of the circuit over time and ap-
proximates the rate at which the circuit is throttled. By
comparing the estimated throttle rate to the distribution
on guard throttle rates, the adversary may again reduce
the anonymity set by removing guards whose throttle rate
is inconsistent with the estimated circuit throttle rate.
For bit-splitting, by raising and lowering the rate of
garbage sent, the attacker can match this with the throt-
tled throughput of each guard. The only guards in the
anonymity set would be those that share the same throt-
tling rate that matches the ﬂooded circuit’s throughput
at all times. To maximize what he can learn from ﬂag-
ging, the adversary should raise the EWMA of the target
circuit at a rate that will allow him to maximally differ-
entiate guards with respect to when they would begin to
throttle a circuit. If this does not uniquely identify the
guard, he can also use the rate at which he diminishes
garbage trafﬁc to try to learn more from when the tar-
get circuit stops being throttled. As in Attack 1 from the
threshold algorithm, the adversary can match the signa-
ture of both ﬂuctuations in throttling rate over time and
the timing of when throttling is applied to narrow the set
of possible guards for a target circuit.
We simulated this attack using the same data set as
Attack 1. Figure 4c shows that a connection’s throttle
rate generally leaks slightly more information than its
throughput. As in Attack 1, guards’ bandwidth in our
simulation leaks more information than the throttle rate
of each connection for all but the ﬂagging algorithm.
Attack 3. An adversary controlling two malicious
servers can link streams of a client connecting to each
of them at the same time. The adversary uses the circuit
testing technique to send a response of β
2 bytes in size to
each of two requests. Then, small “test” responses are re-
turned after receiving the clients’ second requests. If the
throughput of each circuit when downloading the “test”
response is consistently throttled, then it is possible that
the requests are coming from the same client. This at-
tack relies on the observation that all trafﬁc on the same
client-to-guard connection will be throttled at the same
time since each connection has a single burst bucket.
This attack is intended to indicate if and when a circuit
is throttled, rather than the throttling rate. It will there-
fore not be effective against bit splitting, but will work
against ﬂagging or threshold throttling.
Attack 4. Our ﬁnal attack is an active denial of service
attack that can be used to conﬁrm a circuit’s entry guard
with high probability.
In this attack, the adversary at-
tempts to adjust the throttle rate of each guard in order
to identify whether it carries a target circuit. An adver-
sary in control of a malicious server may monitor the
throughput of a target circuit over time, and may then
open a large number of connections to each guard node
until a decrease in the target circuit’s throughput is ob-
served. To conﬁrm that a guard is on the target circuit,
the adversary can alternate between opening and closing
guard connections and continue to observe the through-
put of the target circuit. If the throughput is consistent
with the adversary’s behavior, it has found the circuit’s
guard with high probability.
The one thing not controlled by the adversary in
Attack 2 is a guard’s criterion for throttling at a
given time – splitRate for bit splitting and ﬂagging
and selectIndex for threshold throttling (see Algo-
rithms 1, 2, and 3). All of these are controlled by the
number of circuits at the guard, which Attack 4 places
under the control of the adversary. Thus, under Attack 4,
the adversary will have precise control over which cir-
cuits get throttled at which rate at all times and can there-
fore uniquely determine the entry guard.
Note that all of Attacks 1, 2, and 4 are intended to
learn about the possible entry guards for an attacked cir-
cuit. Even if completely successful, this does not fully
de-anonymize the circuit. But since guards themselves
are chosen for persistent use by a client, they can add
11
to pseudonymous proﬁling and can be combined with
other information, such as that uncovered by Attack 3,
to either reduce anonymity of the client or build a richer
pseudonymous proﬁle of it.
5.3 Eluding Throttles
A client may try multiple strategies to avoid being throt-
tled. A client may instrument its downloading applica-
tion and the Tor software to send application data over
multiple Tor circuits. However, these circuits will still be
subject to throttling since each of them uses the same
throttled TCP connection to the guard. A client may
avoid this by attempting to create multiple TCP con-
nections to the guard. In this case, the guard may eas-
ily recognize that the connection requests come from
the same client and can either deny the establishment
of multiple connections or aggregate the accounting of
all connections to that client. A client may use multi-
ple guard nodes and send application data over each sep-
arate guard connection, but the client signiﬁcantly de-
creases its anonymity by subverting the guard mecha-
nism [58, 59]. Finally, the client could run and use its
own guard node and avoid throttling itself. Although this
strategy may actually beneﬁt the network since it reduces
the amount of Tor’s capacity consumed by the client, the
cost of running a guard may be sufﬁcient to prevent its
wide-scale adoption.
Its important to note that the “cheating” techniques
outlined above do not decrease the security or perfor-
mance below what unthrottled Tor provides. At worst,
even if all clients somehow manage to elude the throttles,
performance and security both regress to that of unthrot-
tled Tor. In other words, throttling can only improve the
situation whether or not “cheating” occurs in practice.
6 Related Work
6.1
Improving Tor’s Performance
Recent work on improving Tor’s performance covers a
wide range of topics, which we now enumerate.
Incentives. A recognition that Tor is limited by its band-
width resources has resulted in several proposals for de-
veloping performance incentives for volunteering band-
width as a Tor relay. New relays would provide ad-
ditional resources and improve network performance.
Ngan et al. explore giving better performance to re-
lays that attain the fast and stable relay ﬂags [43].
These relays are marked with a “gold star” in the di-
rectory. Gold star relays may build circuits through
other gold star relays, improving download performance.
This scheme has a severe anonymity problem: any relay
on a gold star circuit can determine with absolute cer-
tainty that the client is also a gold star relay.
Jansen
et al. explore reducing anonymity problems from the
gold star approach by distributing anonymous tickets to
all clients [32]. Relays then collect tickets from clients in
exchange for prioritized service and can prioritize their
own trafﬁc in return. However, a centralized bank lim-
its the allowable number of tickets in circulation, leading
to spending strategies that may reduce anonymity. Fi-
nally, Moore et al. independently explored using static
throttling conﬁgurations as a way to produce incentives
for users to run relays in Tortoise [41]. Tortoise’s throt-
tling conﬁgurations must be monitored as network load
changes, and anonymity with Tortoise is slightly worse
than with the gold star scheme: the intersection attack
is improved since gold star nodes retain their gold stars
for several months after dropping from the consensus,
whereas Tortoise only unthrottles nodes that are in the
current consensus.
Relay Selection. Snader and Borisov [51] suggest an
algorithm where relays opportunistically measure their
peers’ performance, allowing clients to use empirical ag-
gregations to select relays for their circuits. A user-
tunable mechanism for selecting relays is built into the
algorithm: clients may adjust how often the fast re-
lays get chosen, trading off anonymity and performance
while not signiﬁcantly reducing either.
It was shown
that this approach increases accuracy of available band-
width estimates and reduces reaction time to changes
in network load while decreasing vulnerabilities to low-
resource routing attacks. Wang et al.
[57] propose a
congestion-aware path selection algorithm where clients
choose paths based on information gathered during op-
portunistic and active measurements of relays. Clients
use latency as an indication of congestion, and reject con-
gested relays when building circuits. Improvements were
realized for a single client, but its unclear how the new
strategy would affect the network if used by all clients.
Scheduling. Alternative scheduling approaches have re-
cently gained interest. Tang and Goldberg [52] sug-
gest each relay track the number of packets it sched-
ules for each circuit. After a conﬁgurable time-period,
packet counts are exponentially decayed so that data
sent more recently has a greater inﬂuence on the packet
count. For each scheduling decision, the relay ﬂushes
the circuit with the lowest cell count, favoring circuits
that have not sent much data recently while preventing
bursty trafﬁc from signiﬁcantly affecting scheduling pri-
orities. Jansen et al.
[32] investigate new schedulers
based on the proportional differentiation model [21] and
differentiable service classes. Relays track the delay of
each service class and prioritize scheduling so that rel-
ative delays are proportional to conﬁgurable differenti-
ation parameters, but the schedulers require a mecha-
12
nism (tickets) for differentiating trafﬁc into classes. Fi-
nally, Tor’s round-robin TCP read/write schedulers have
recently been noted as a source of unfairness for relays
that have an unbalanced number of circuits per TCP con-
nection [54]. Tschorsch and Scheuermann suggest that a
round-robin scheduler could approximate a max-min al-
gorithm [24] by choosing among all circuits rather than
all TCP connections. More work is required to determine
the suitability of this approach in Tor.
Congestion. Improving performance and reducing con-
gestion has been studied by taking an in-depth look at
Tor’s circuit and stream windows [7]. AlSabah et al. ex-
periment with dynamically adjusting window sizes and
ﬁnd that smaller window sizes effectively reduce queuing
delays, but also decrease bandwidth utilization and there-
fore hurt overall download performance. As a result, they
implement and test an algorithm from ATM networks