study. The remaining services fall in between those ex-
tremes. MR. E reported that his service trains workers
to achieve response times of 10–12 seconds on average,
which is consistent with our measurements of his service.
DeCaptcher and BeatCaptchas have very similar dis-
tributions. We have seen evidence (i.e., error messages
from BeatCaptchas that are identical to ones documented
for the DeCaptcher API) that suggests that BeatCaptchas
uses DeCaptcher as a back end. Antigate returns some
correct responses unusually quickly (a few seconds), for
which we currently do not have an explanation; we have
ruled out caching effects.
Services have an advantage if they have better re-
sponse times than their competition, and the services we
measured differ substantially. We suspect that it is a com-
bination of two factors: software and queueing delay in
the service infrastructure, and worker efﬁciency. Anti-
gate, for instance, appears to have an unusually large la-
bor pool (Section 5.8), which may enable them to keep
queueing delay low. Similarly, ImageToText appears to
have an adaptive, high-quality labor pool (Section 6.4).
We observed additional delays of 5 seconds due to load
(Section 5.9), but load likely affects all services similarly.
We found that accuracy varied with the type of
CAPTCHA. A closely related issue is to what degree re-
sponse time also varies according to CAPTCHA type. The
bottom of Figure 5 shows response times by CAPTCHA
type. Services are listed along the y-axis from slowest
(top) to fastest service (bottom). The area of each circle
is proportional to the median response time of a service
on a particular CAPTCHA type minus ten seconds (for
greater contrast). Shaded circles are times in excess of
ten seconds, unshaded circles are times less than ten sec-
onds. For example, the median response time of Antigate
on PayPal CAPTCHAs—8 seconds—is shown as an un-
shaded circle. Note that CAPTCHA types are still sorted
by accuracy. The right half of Figure 4 aggregates re-
sponse times by service, showing the median response
time of each.
Figure 7: Cumulative distribution of response times for each
service.
Figure 8: Price for 1,000 correctly-solved CAPTCHAs within a
given response time threshold.
We see some variation in response time among
CAPTCHA types. Youku and reCaptcha, for instance,
consistently induce longer response times across ser-
vices, whereas Baidu, eBay, and QQ consistently have
shorter response times. However, the variation in re-
sponse times among the services dominates the varia-
tion due to CAPTCHA type. The fastest CAPTCHAs that
DeCaptcher solves (e.g., Baidu and QQ) are slower on
average than the slowest CAPTCHAs that Antigate and
ImageToText solve.
5.7 Value
CAPTCHA solvers differ in terms of accuracy, response
time, and price. The value of a particular solver to a
customer depends upon the combination of all of these
factors: a customer wants to pay the lowest price for
both fast and accurate CAPTCHAs. For example, sup-
pose that a customer wants to create 1,000 accounts on
an Internet service, and the Internet service requires that
CAPTCHAs be solved within 30 seconds. When using a
CAPTCHA solver, the customer will have to pay to have
at least 1,000 CAPTCHAs solved, and likely more due to
solutions with response times longer than the 30-second
11
00102030405060Response Time (seconds)0%25%50%75%100%AntigateImageToTextCaptchaBotBypassCaptchaCaptchaBypassDecaptcherBeatCaptchasCaptchaGateway0102030405060$1$5$10$50$100AntigateCaptchaBotDecaptcherImageToTextCaptchaGatewayBeatCaptchas, BypassCaptcha, CaptchaBypassRequired Response Time (seconds)Price per 1K Correct SolutionsFigure 9: Load reported by (a) Antigate and (b) DeCaptcher as a function of time-of-day in one-hour increments. For comparison,
we show the percentage of correct responses and rejected requests per hour, as well as the average response time per hour.
threshold (recall that customers do not have to pay for in-
correct solutions). From this perspective, the solver with
the best value may not be the one with the cheapest price.
Figure 8 explores the relationship among accuracy, re-
sponse time, and price for this scenario. The x-axis is
the time threshold T within which a CAPTCHA is useful
to a customer. The y-axis is the adjusted price per bun-
dle of 1,000 CAPTCHAs that are both solved correctly
and solved within time T . Each curve corresponds to a
solver. Each solver charges a price per CAPTCHA solved
(Table 1), but not all solved CAPTCHAs will be useful to
the customer. The adjusted price therefore includes the
overhead of solving CAPTCHAs that take longer than T
and are effectively useless. Consider an example where a
customer wants to have 1,000 correct CAPTCHAs solved
within 30 seconds, a solver charges $2/1,000 CAPTCHAs,
and 70% of the solver’s CAPTCHA responses are cor-
rect and returned within 30 seconds. In this case, the
customer will effectively pay an adjusted price of $2 ×
(1/0.70) = $2.86/1, 000 useful CAPTCHAs.
The results in Figure 8 show that the solver with the
best value depends on the response time threshold. For
high thresholds (more than 25 seconds), both Antigate
and CaptchaBot provide the best value and ImageToText
is the most expensive as suggested by their bulk prices
(Table 1). However, below this threshold the rankings be-
gin to change. Antigate begins to have better value than
CaptchaBot due to having consistently better response
times. In addition, ImageToText starts to overtake the
other services. Even though its bulk price is 5x that of
DeCaptcher, for instance, its service is a better value for
having CAPTCHAs solved within 8 seconds (albeit at a
premium adjusted price).
we also attempted to measure a service’s maximum ca-
pacity using bursts of CAPTCHA requests. Speciﬁcally,
we measured the number and rate of solutions returned
in response to a given offered load, substantially increas-
ing the load in increments until the service appeared
overloaded. We carried out this experiment successfully
for ﬁve of the services. Of them, Antigate had by far
the highest capacity, solving on the order of 27 to 41
CAPTCHAs per second. Even at our highest sustained of-
fered load (1,536 threads submitting CAPTCHAs simulta-
neously, bid set at $3/1,000), our rejection rate was very
low, suggesting that Antigate’s actual capacity may in
fact be higher. Due to ﬁnancial considerations, we did
not attempt higher offered loads.
For the remaining services, we exceeded their avail-
able capacity. We took a non-negligible reject rate to
be an indicator of the service running at full capacity.
Both DeCaptcher and CaptchaBot were able to sustain a
rate of about 14–15 CAPTCHAs per second, with Beat-
Captchas and BypassCaptchas sustaining a solve rate of
eight and four CAPTCHAs per second, respectively.
Based on these rates, we can calculate a rough esti-
mate of the number of workers at these services. Assum-
ing 10–13 seconds per CAPTCHA (based on our inter-
view with MR. E, and consistent with our measured la-
tencies of his service in the 10–20 second range), Anti-
gate would have had at least 400–500 workers avail-
able to service our request. Since we did not exceed
their available capacity, the actual number may be larger.
Both DeCaptcher and CaptchaBot, at a solve rate of 15
CAPTCHAs per second mentioned above, would have had
130–200 workers available.
5.8 Capacity
Another point of differentiation is solver capacity,
namely how many CAPTCHAs a service can solve in a
given unit of time. In addition to low-rate measurements,
5.9 Load and Availability
Customers can poll the transient load on the services and
offer payment over the market rate in exchange for higher
priority access when load is high. During our background
CAPTCHA data collection for these services, we also
12
Hour of DayPercentagellllllllllllllllllllllll02040608010005101520051015202530Response Time (s)lReported LoadCorrect RateReject RateResponse TimeHour of DayPercentagellllllllllllllllllllllll02040608010005101520051015202530Response Time (s)lReported LoadCorrect RateReject RateResponse Timerecorded the transient load that they reported. From these
measurements, we can examine to what extent services
report substantial load, and correlate reported load with
other observable metrics (response time, reject rate) to
evaluate the validity of the load reports. Because De-
Captcher charges the full customer bid independent of
actual load, for instance, it might be motivated to report
a false high load in an attempt to encourage higher bids
from customers.
Figure 9 shows the average reported load as a function
of the time of day (in the US Paciﬁc time zone) for both
services: for each hour, we compute the average of all
load samples taken during that hour for all days of our
data set. Antigate reports a higher nominal background
load than DeCaptcher, but both services clearly report a
pronounced diurnal load effect.
For comparison, we also overlay three other ser-
vice metrics for each hour across all days: average re-
sponse time of solved CAPTCHAs, percentage of submit-
ted CAPTCHAs rejected by the service, and the percent-
age of responses with correct solutions. Response time
correlates with reported load, increasing by 5 seconds
during high load for each service—suggesting that the
high load reports are indeed valid. The percentage of re-
jected requests for DeCaptcher further validates the load
reports. When our bids to DeCaptcher were at the base
price of $2/1,000 at times of high load, DeCaptcher ag-
gressively rejected our work requests. To conﬁrm that a
higher bid resulted in lower rejection rates, we measured
available capacity at 5PM (US Paciﬁc time) at the base
price of $2 and then, a few minutes later, at $5, obtaining
solve rates of 8 and 18 CAPTCHAs per second, respec-
tively. Although not conclusive, this experience suggests
that higher bids may be necessary to achieve a desired
level of service at times of high load. Likewise, Antigate
exhibits better quality of service when bidding $1 over
the base price, though bidding over this amount produced
no noticeable improvement (we tested up to $6/1,000).
As further evidence, recall that for Antigate we had to
offer premium bids before the service would solve our re-
quests (Section 5.2). As a result, even during high loads
Antigate did not reject our requests, presumably priori-
tizing our requests over others with lower bids.
Finally, as expected, accuracy is independent of load:
workers are shielded from load behind work queues,
solving CAPTCHAs to their ability unaffected by the of-
fered load on the system.
6 Workforce
Human CAPTCHA solving services are effectively aggre-
gators. On one hand, they aggregate demand by provid-
ing a singular point for purchasing solving services. At
the same time, they aggregate the labor supply by provid-
13
Figure 10: Portion of a PixProﬁt worker interface displaying a
Microsoft CAPTCHA.
ing a singular point through which workers can depend
on being offered consistent CAPTCHA solving work for
hire. Thus, for each of the publicly-facing retail sites de-
scribed previously, there is typically also a private “job
site” accessed by workers to receive CAPTCHA images
and provide textual solutions. Identifying these job sites
and which retail service they support is an investigative
challenge. For this study, we focused our efforts on two
services for which we feel conﬁdent about the mapping:
Kolotibablo and PixProﬁt. Kolotibablo is a Russian-run
job site that supplies solutions for the retail service Anti-
gate (which, along with CaptchaBot, is the current price
leader).
6.1 Account Creation
For each job site, account creation is similar to the retail
side, but due diligence remains minimal. As a form of
quality control, some job sites will evaluate new work-
ers using a corpus of “test” CAPTCHAs (whose solutions
are known a priori) before they allow them to solve ex-
ternally provided CAPTCHAs. For this reason, we discard
the ﬁrst 30 CAPTCHAs provided by PixProﬁt, which we
learned by experience correspond to test CAPTCHAs.
6.2 Worker Interface
Services provide workers with a Web based interface
that, after logging in, displays CAPTCHAs to be solved
and provides a text box for entering the solution (Fig-
ure 10 shows an example of the interface for PixProﬁt).
Each site also tracks the number of CAPTCHAs solved,
the number that were reported as correct (by customers
of the retail service), and the amount of money earned.
PixProﬁt also assigns each worker a “priority” based
on solution accuracy. Better accuracy results in more
CAPTCHAs to solve during times of lower load. If a
solver’s accuracy decreases too much, services ban the
account. In our experiments, our worker agents always
used fresh accounts with the highest level of priority.
Example
Language
English
Chinese (Simp.)
Chinese (Trad.)
Spanish
Italian
Tagalog
Portuguese
Russian
Tamil
Dutch
Hindi
German
Malay
Vietnamese
Korean
Greek
Arabic
Bengali
Kannada
Klingon
Farsi
AG
51.1
48.4
52.9
1.81
3.65
0.00
3.15
24.1
2.26
4.09
10.5
3.62
0.00
0.46
0.00
0.45
0.00
0.45
0.91
0.00
0.45
BC
37.6
31.0
24.4
13.8
8.45
5.79
10.1
0.00
21.1
1.36
5.38
0.72
1.42
2.07
0.00
0.00
0.00
0.00
0.00
0.00
0.00
BY
4.76
0.00
0.00
0.00
0.00