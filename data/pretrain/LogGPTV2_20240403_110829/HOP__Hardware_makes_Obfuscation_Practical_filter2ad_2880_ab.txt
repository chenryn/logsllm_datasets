can still infer signiﬁcant information about the data [43], [58].
There have been some recent secure processor proposals
that do hide memory access patterns [18], [41], [40], [45].
Ascend [18] is a secure processor architecture that protects
privacy of data against physical attacks when running arbitrary
programs. Phantom [41] similarly achieves memory oblivious-
ness, and has been integrated with GhostRider [40] to perform
program analysis and decide whether to use an encrypted RAM
or Oblivious RAM for different memory regions. They also
employ a scratchpad wherever applicable. Raccoon [45] hides
data access patterns on commodity processors by evaluating
all program paths and using an Oblivious RAM in software.
The primary difference between the above schemes and
HOP is the following. All of the above schemes focused on
protecting input data, while the program is assumed to be
public and known to the adversary. GhostRider [40] even
utilizes public knowledge of program behavior to improve
performance through static analysis. Conversely, obfuscation
and HOP protect the program and the input data is controlled
by the adversary. We remark, however,
that HOP can be
extended to additionally achieve data privacy simply by adding
routines to decrypt the (now private) inputs and encrypt the
ﬁnal outputs before they are sent to the client (now different
from the HOP processor owner). Naturally,
the enhanced
security comes with additional cost. We evaluate this overhead
of additionally providing program-privacy by comparing to
GhostRider in Section VI-E.
Secure computation. There is a line of work addressing
how to build a general purpose MIPS processor for garbled
circuits [51], [56]. When one party provides the program, the
system is capable of performing private function secure func-
tion evaluation (PF-SFE). Similarly, universal circuits [55],
3
[35], [33] in combination with garbled circuits (which can
be evaluated efﬁciently with techniques in [30]) or other
multiparty computation protocols can be used to hide program
functionality from one of the parties. The work of Katz [32]
relies on trusted hardware tokens to circumvent the theoretical
impossibility of UC-secure multi-party computation under
dishonest majority. However, all the above results are in the
context of secure computation, which is inherently interactive
and only allows one-time use, i.e., for every input, both parties
are involved in the computation. On the contrary, obfuscation
requires that a party non-interactively execute the obfuscated
program several times on multiple inputs.
Heuristic approaches to obfuscation. There are heuristic
approaches to code obfuscation for resistance to reverse engi-
neering [58], [31], [47]. These works provide low overheads,
but do not offer any cryptographic security.
Terminology: Hardware Tokens. Trusted hardware is widely
referred to as hardware tokens in the theoretical literature [32],
[27], [17], [15]. Secure tokens are typically assumed to be
minimal trusted hardware that support limited operations (e.g.,
a NAND gate in [27]). However, running programs in practice
requires full-ﬂedged processors. In this paper, we refer to HOP
as “secure hardware” or a “secure processor”. As a processor,
HOP will store a lot more internal state (e.g., a register ﬁle,
etc.). We note that from a theoretic perspective, both HOP and
‘simple’ hardware tokens require a number of gates which is
polylogarithmic in memory size.
Terminology: Stateful vs. Stateless tokens. The literature
further classiﬁes secure tokens as either stateful tokens or
stateless. A stateful token maintains state across invocations.
On the other hand, a stateless token, except for a secret key,
does not maintain any state across invocations. While HOP
maintains state across most invocations for better performance,
we will augment HOP to support on-demand context switching
— giving the receiver the ability to swap out an obfuscated
program for another at any time (Section III-E), which is
common in today’s systems. In an extreme scenario,
the
adversary can context switch after every processor cycle. In
this case, HOP becomes equivalent to a “stateless” token from
a theoretical perspective [27], [15], and our security proof will
assume stateless tokens.
III. OBFUSCATION FROM TRUSTED HARDWARE
In this section, we describe the HOP architecture. We
will start with an overview of a simple (not practical) HOP
processor to introduce some key points. Each subsection after
that introduces additional optimizations (some expose security
issues, which we address) to make the scheme more practical.
We give security intuition where applicable, and formally
prove security for the fully optimized scheme in Section IV.
A. Execution On-Chip
Let us start with the simplest case where the whole obfus-
cated program and its data (working set) ﬁt in a processor’s
on-chip storage. Then, we may architect a HOP processor to
be able to run programs whose working sets don’t exceed
a given size. In the setup phase, ﬁrst, the sender correctly
determines a value T – the amount of time (in processor
cycles) that the program, given any input, runs on HOP. Then,
the sender encrypts (obfuscates) the program together using
an authenticated encryption scheme. T is authenticated along
and included with the program but is public. The obfuscated
program is sent to the receiver. The receiver then sends the
obfuscated program and her own input to the HOP processor.
The HOP processor decrypts and runs the program, and returns
a result after T processor cycles. The HOP processor makes
no external memory requests during its execution since the
program and data ﬁt on chip. Security follows trivially.
B. Adding External Memory
Unfortunately, since on-chip storage is scarce (commercial
processors have a few MegaBytes of on-chip storage), the
above solution can only run programs with small working
sets. To handle this, like any other modern processor, the
HOP processor needs to access an external memory, which
is possibly controlled by the malicious receiver.
When the HOP processor needs to make an access to this
receiver memory, it needs to hide its access patterns. For the
purposes of this discussion, the access pattern indicates the
processor’s memory operations (reads vs. writes), the memory
addresses for each access and the data read/written in each
access. We hide access pattern by using an Oblivious RAM
(ORAM), which makes a polylogarithmic number of physical
memory accesses to serve each logical memory request from
the processor [52]. The ORAM appears to HOP as an on-chip
memory controller that intercepts memory requests from the
HOP processor to the external memory. That is, the ORAM is
a hardware block on the processor and is trusted. (More formal
deﬁnitions for ORAM are given in Section IV-A.)
Each ORAM access can take thousands of processor cy-
cles [19]. Executing instructions – once data is present on-
chip – is still as fast as an insecure machine (e.g., several
cycles). To hide when ORAM accesses are actually needed,
HOP must make accesses at a static program-independent
frequency (more detail below). As before, HOP runs for T
time on all inputs and hence achieves the same privacy as the
scheme in Section III-A.
Generating T and security requirements. When accessing
receiver-controlled memory, we must change T to represent
some amount of work that
is independent of the external
memory’s latency. That is, if T is given in processor cycles,
the adversary can learn the true program termination time by
running the program multiple times and varying the ORAM
access latency each time (causing a different number of logical
instructions to complete each time). To prevent this, we change
T to mean ‘the number of external memory read/writes made
with the receiver.’
Integrity. To ensure authenticity of the encrypted program in-
structions and data during the execution, HOP uses a standard
Merkle tree (or one that is integrated with the ORAM [46])
and stores the root of a Merkle tree internally. The receiver
cannot tamper with or rewind the memory without breaking
the Merkle tree authentication scheme.
Efﬁciency. While the above scheme can handle programs with
large working sets, it is very inefﬁcient. The problem is that
4
each instruction may trigger multiple ORAM accesses. To give
off the impression of running any program, we must provision
for this worst case: running each instruction must incur the cost
of the worst-case number of ORAM accesses. This can result
in ∼ 10, 000× slowdown over an insecure processor.3 The
next two subsections discuss two techniques to securely reduce
this overhead by over two orders of magnitude. These ideas
are based on well-known observations that many programs
have more arithmetic instructions than memory instructions,
and exhibit locality in memory accesses.
C. Adding Instruction Scheduling
The key intuition behind our ﬁrst technique is that many
programs execute multiple arithmetic instructions for every
memory access. For example, an instruction trace may be
the following: ‘A A A A M A A M’, where A, M refer to
arithmetic and memory instructions respectively.
Our optimization is to let the HOP processor follow a ﬁxed
and pre-deﬁned schedule: N arithmetic instructions followed
by one memory access. In the above example, given a schedule
of A4M, the processor would insert two dummy arithmetic
instructions to adhere to the schedule. A dummy arithmetic
instruction can be implemented by executing a nop instruction.
The access trace observable to the adversary would then be:
A A A A M A A A A M
The bold face A letters refer to dummy arithmetic instructions
introduced by the processor.
Likewise, if another part of the program trace contains a
long sequence of arithmetic instructions, the processor will
insert dummy ORAM accesses to adhere to the schedule.
Gains. For most programs in practice, there exists a schedule
with N > 1 that would perform better than our baseline
scheme from Section III-B. For (N + 1) instructions, the base-
line scheme performs (N +1) arithmetic and memory accesses.
With an AN M schedule, our optimized scheme performs only
one memory access which translates to a speedup of N× in
the best case, when the cost of the memory access is much
higher than an arithmetic instruction. To translate this into
performance on HOP - given that HOP must run for T time
- consider the following: If N > 1 does improve performance
for the given program on all inputs, it means the sender can
specify a smaller T for that program, while still having the
guarantee that the program will complete given any input. A
smaller T means better performance.
Setting N and security intuition. We design all HOP proces-
sors to use the same value of N for all programs and all inputs
(i.e., N is set at HOP manufacturing time like the private key).
More concretely, we set
N =
ORAM latency
Arithmetic latency
In other words,
the number of processor cycles spent on
arithmetic instructions and memory instructions are the same.
For typical parameter settings, N > 1000 is expected. While
3Our ORAM latency from Section VI is 3000 cycles. The RISC-V
ISA [12] we adopt can trigger 3 ORAM accesses, one to fetch the instruction,
1 or 2 more to fetch the operand, depending on whether the operand straddles
an ORAM block boundary.
5
this may sound like it will severely hurt performance given
pathological programs, we show that this simple strategy does
“well” on arbitrary programs and data, formalized below.
Claim: For any program and input, the above N results in
≤ 50% of processor cycles performing dummy work.
We refer the reader to Appendix A for a proof of this
claim. We consider this proof to be of independent interest.
The claim implies that
in comparison to a solution that
does not protect the main memory timing channel, our ﬁxed
schedule introduces a maximum overhead of 2× given any
program – whether they are memory or computation intensive.
Said another way, even when more sophisticated heuristics
than a ﬁxed schedule are used for different applications, the
performance gain from those techniques is a factor of 2 at
most.
Security. We note that our instruction scheduling scheme does
not impact security because we use a ﬁxed, public N for all
programs.
D. Adding on-chip Scratchpad Memory
Our second optimization adds a scratchpad: a small unit of
trusted memory (RAM) inside the processor, accesses to which
are not observable by the adversary.4 It is used to temporarily
store a portion of the working set for programs that exhibit
locality in their access patterns.
Running programs with a scratchpad. We brieﬂy cover
how to run programs using a scratchpad here. More
(implementation-speciﬁc) detail
is given in Section V-A.
At a high level, data is loaded into the scratchpad from
ORAM/unloaded to ORAM using special (new) CPU instruc-
tions that are added to the obfuscated program. These instruc-
tions statically determine when to load which data to speciﬁed
offsets in the scratchpad. Now, the scratchpad load/unload
instructions are the only instructions that access ORAM (i.e.,
are the only ‘M’ instructions). Memory instructions in the
original program (e.g., normal loads and stores) merely lookup
the scratchpad inside the processor (these are now considered
‘A’ instructions). We will assume the program is correctly
compiled so that whenever a program memory instruction
looks up the scratchpad, the data in question has been put
there sometime prior by a scratchpad load/unload instruction.
Security intuition. When the program accesses the scratchpad,
it is hidden from the adversary since this is done on-chip. As
before, the only adversary-visible behavior is when ORAM is
accessed and this will be governed by the program-independent
schedule from Section III-C.
Program independence. We note that HOP with a scratchpad
is still program independent. Multiple programs can be written
(and obfuscated) for the same HOP processor. One minor
limitation, however, is that once an obfuscated program is
compiled, it must be compiled with ‘minimum scratchpad size’
speciﬁed as a new parameter and cannot be run on HOP
4We remark that we use a software-managed scratchpad (as opposed to
a conventional processor cache) as it is easier to determine T when using a
scratchpad.
processors that have a smaller scratchpad. This is necessary
because having a smaller scratchpad will increase T by some
unknown amount. If the program is run on a HOP processor
with a larger scratchpad, it will still function but some scratch-
pad space won’t be used.
Gains. In the absence of a scratchpad, the ratio of arithmetic
to memory instructions is on average 5:1 for our workloads.
When using a scratchpad, a larger amount of data is stored
by the processor,
thus decreasing memory accesses. This
effectively decreases the execution time T of the program and
substantially improves performance for programs with high
locality (evaluated in Section VI-C).
E. Adding context switching and stateless tokens
A problem with the proposals discussed so far is that once
a program is started, it cannot be stopped until it returns a
response. But a user may wish to concurrently run multi-
ple obfuscated programs for a practical deployment model.
Therefore, we design the HOP processor to support on-demand
context switch, i.e., the receiver can invoke a context switch at
any point during execution. This, however, introduces security
problems that we need to address.
A context switch means that the current program state
should be swapped out from the HOP processor and replaced
with another program’s state. Since such a context switch can
potentially happen at every invocation, the HOP processor no
longer stores state and is a stateless token. In such a scenario,
we design it to encrypt all its internal state, and send this
encrypted/authenticated state (denoted state) to the receiver
(i.e., the adversary) on a context switch. Whenever the receiver
passes control back to the token, it will pass back the encrypted
state as well, such that the token can “recover” its state upon
every invocation.
Challenges. Although on the surface, this idea sounds easy
to implement, in reality it introduces avenues for new attacks
that we now need to defend against. For the rest of the paper,
and in-line with real processors, we assume the only data
that remains in HOP is the per-chip secret key (Section I).
A notable attack is the rewinding attack. In this attack, instead