Name: xxx.xxx.xxx.104:50010 (host_digoal_03)
Hostname: host_digoal_03
Rack: /dc1/rack3
Decommission Status : Normal
Configured Capacity: 201312493568 (187.49 GB)
DFS Used: 6451277824 (6.01 GB)
Non DFS Used: 239345664 (228.26 MB)
DFS Remaining: 194621870080 (181.26 GB)
DFS Used%: 3.20%
DFS Remaining%: 96.68%
Configured Cache Capacity: 0 (0 B)
Cache Used: 0 (0 B)
Cache Remaining: 0 (0 B)
Cache Used%: 100.00%
Cache Remaining%: 0.00%
Xceivers: 2
Last contact: Fri Sep 16 14:18:24 CST 2016
在各节点查看
[gpadmin@host_digoal_01 hawq]$ df -h
Filesystem      Size  Used Avail Use% Mounted on
/dev/vda1        40G  7.1G   31G  20% /
devtmpfs        3.9G     0  3.9G   0% /dev
tmpfs           3.9G     0  3.9G   0% /dev/shm
tmpfs           3.9G  8.5M  3.9G   1% /run
tmpfs           3.9G     0  3.9G   0% /sys/fs/cgroup
/dev/vdb1        94G  3.3G   91G   4% /data01
/dev/vdc1        94G  3.1G   91G   4% /data02
tmpfs           783M     0  783M   0% /run/user/0
tmpfs           783M     0  783M   0% /run/user/1000
```
## TPCH测试  
参考  
https://github.com/digoal/gp_tpch  
### 生成测试数据
```
SF=100
dbgen -s $SF
for i in `ls *.tbl`; do sed 's/|$//' $i > ${i/tbl/csv}; echo $i; done;
rm -rf dss/queries
mkdir dss/queries
for q in `seq 1 22`
do
    DSS_QUERY=dss/templates ./qgen -s $SF $q > dss/queries/$q.sql
    sed 's/^select/explain select/' dss/queries/$q.sql > dss/queries/$q.explain.sql
done
```
### 建表SQL  
```
        CREATE TABLE PART (
                P_PARTKEY               SERIAL8,
                P_NAME                  VARCHAR(55),
                P_MFGR                  CHAR(25),
                P_BRAND                 CHAR(10),
                P_TYPE                  VARCHAR(25),
                P_SIZE                  INTEGER,
                P_CONTAINER             CHAR(10),
                P_RETAILPRICE   FLOAT8,
                P_COMMENT               VARCHAR(23)
        ) with (APPENDONLY=true,ORIENTATION=PARQUET,OIDS=false) DISTRIBUTED BY (p_partkey);
        CREATE TABLE REGION (
                R_REGIONKEY     SERIAL8,
                R_NAME          CHAR(25),
                R_COMMENT       VARCHAR(152)
        )  with (APPENDONLY=true,ORIENTATION=PARQUET,OIDS=false) DISTRIBUTED BY (r_regionkey);
        CREATE TABLE NATION (
                N_NATIONKEY             SERIAL8,
                N_NAME                  CHAR(25),
                N_REGIONKEY             BIGINT NOT NULL,  -- references R_REGIONKEY
                N_COMMENT               VARCHAR(152)
        )  with (APPENDONLY=true,ORIENTATION=PARQUET,OIDS=false) DISTRIBUTED BY (n_nationkey);
        CREATE TABLE SUPPLIER (
                S_SUPPKEY               SERIAL8,
                S_NAME                  CHAR(25),
                S_ADDRESS               VARCHAR(40),
                S_NATIONKEY             BIGINT NOT NULL, -- references N_NATIONKEY
                S_PHONE                 CHAR(15),
                S_ACCTBAL               FLOAT8,
                S_COMMENT               VARCHAR(101)
        )  with (APPENDONLY=true,ORIENTATION=PARQUET,OIDS=false) DISTRIBUTED BY (s_suppkey);
        CREATE TABLE CUSTOMER (
                C_CUSTKEY               SERIAL8,
                C_NAME                  VARCHAR(25),
                C_ADDRESS               VARCHAR(40),
                C_NATIONKEY             BIGINT NOT NULL, -- references N_NATIONKEY
                C_PHONE                 CHAR(15),
                C_ACCTBAL               FLOAT8,
                C_MKTSEGMENT    CHAR(10),
                C_COMMENT               VARCHAR(117)
        )  with (APPENDONLY=true,ORIENTATION=PARQUET,OIDS=false) DISTRIBUTED BY (c_custkey);
        CREATE TABLE PARTSUPP (
                PS_PARTKEY              BIGINT NOT NULL, -- references P_PARTKEY
                PS_SUPPKEY              BIGINT NOT NULL, -- references S_SUPPKEY
                PS_AVAILQTY             INTEGER,
                PS_SUPPLYCOST   FLOAT8,
                PS_COMMENT              VARCHAR(199)
        )  with (APPENDONLY=true,ORIENTATION=PARQUET,OIDS=false) DISTRIBUTED BY (ps_suppkey);
        CREATE TABLE ORDERS (
                O_ORDERKEY              SERIAL8,
                O_CUSTKEY               BIGINT NOT NULL, -- references C_CUSTKEY
                O_ORDERSTATUS   CHAR(1),
                O_TOTALPRICE    FLOAT8,
                O_ORDERDATE             DATE,
                O_ORDERPRIORITY CHAR(15),
                O_CLERK                 CHAR(15),
                O_SHIPPRIORITY  INTEGER,
                O_COMMENT               VARCHAR(79)
        )  with (APPENDONLY=true,ORIENTATION=PARQUET,OIDS=false) DISTRIBUTED BY (o_orderkey)
           PARTITION BY RANGE (O_ORDERDATE) (START (date '1992-01-01') INCLUSIVE END (date '2000-01-01') EXCLUSIVE EVERY (INTERVAL '1 month' ));
        CREATE TABLE LINEITEM (
                L_ORDERKEY              BIGINT NOT NULL, -- references O_ORDERKEY
                L_PARTKEY               BIGINT NOT NULL, -- references P_PARTKEY (compound fk to PARTSUPP)
                L_SUPPKEY               BIGINT NOT NULL, -- references S_SUPPKEY (compound fk to PARTSUPP)
                L_LINENUMBER    INTEGER,
                L_QUANTITY              FLOAT8,
                L_EXTENDEDPRICE FLOAT8,
                L_DISCOUNT              FLOAT8,
                L_TAX                   FLOAT8,
                L_RETURNFLAG    CHAR(1),
                L_LINESTATUS    CHAR(1),
                L_SHIPDATE              DATE,
                L_COMMITDATE    DATE,
                L_RECEIPTDATE   DATE,
                L_SHIPINSTRUCT  CHAR(25),
                L_SHIPMODE              CHAR(10),
                L_COMMENT               VARCHAR(44)
        )  with (APPENDONLY=true,ORIENTATION=PARQUET,OIDS=false) DISTRIBUTED BY (l_orderkey)
           PARTITION BY RANGE (L_SHIPDATE) (START (date '1992-01-01') INCLUSIVE END (date '2000-01-01') EXCLUSIVE EVERY (INTERVAL '1 month' ));
```
### 数据导入   
因为有个BUG可能导致COPY消耗大量内存，这个BUG在阿里云提供的的Greenplum已修复，目前HAWQ还未修复。  
所以我这里切成小文件再导入，避免触发BUG。  
```
$ vi tpch.sh
#!/bin/bash
func() {
rm -f $dir/${splitsuff}*
split --line-bytes=1G $dir/${1}.csv $dir/${splitsuff}
for file in `ls $dir/${splitsuff}*`
do
  cat $file | psql -h xx公x.xx网x.xxIPx.xx地址x -p 1921 -U gpadmin postgres -c "copy $1 from stdin WITH csv DELIMITER '|'"
done
}
dir="/tmp/dss-data"
splitsuff="tmp.digoal."
func part
func region
func nation
func supplier
func customer
func partsupp
func orders
func lineitem
$ chmod 700 tpch.sh
$ nohup ./tpch.sh >/tmp/load.log 2>&1 &
```
![pic3](20160916_01_pic_003.png)  
一组测试结果  
```
2016-09-18 05:36:17 [1474148177] : preparing TPC-H database
2016-09-18 05:36:17 [1474148177] : running TPC-H benchmark
2016-09-18 05:36:18 [1474148178] : running queries defined in TPC-H benchmark
2016-09-18 05:36:18 [1474148178] :   running query 1
2016-09-18 05:46:17 [1474148777] :     query 1 finished OK (597 seconds)
2016-09-18 05:46:17 [1474148777] :   running query 2
2016-09-18 05:47:33 [1474148853] :     query 2 finished OK (73 seconds)
2016-09-18 05:47:33 [1474148853] :   running query 3
2016-09-18 05:50:38 [1474149038] :     query 3 finished OK (183 seconds)
2016-09-18 05:50:38 [1474149038] :   running query 4
2016-09-18 05:50:39 [1474149039] :     query 4 finished OK (0 seconds)
2016-09-18 05:50:39 [1474149039] :   running query 5
2016-09-18 05:50:41 [1474149041] :     query 5 finished OK (0 seconds)
2016-09-18 05:50:41 [1474149041] :   running query 6
2016-09-18 05:50:42 [1474149042] :     query 6 finished OK (0 seconds)
2016-09-18 05:50:42 [1474149042] :   running query 7
2016-09-18 05:53:58 [1474149238] :     query 7 finished OK (194 seconds)
2016-09-18 05:53:58 [1474149238] :   running query 8
2016-09-18 05:57:52 [1474149472] :     query 8 finished OK (230 seconds)
2016-09-18 05:57:52 [1474149472] :   running query 9
2016-09-18 06:05:33 [1474149933] :     query 9 finished OK (456 seconds)
2016-09-18 06:05:33 [1474149933] :   running query 10
2016-09-18 06:05:34 [1474149934] :     query 10 finished OK (0 seconds)
2016-09-18 06:05:34 [1474149934] :   running query 11
2016-09-18 06:06:15 [1474149975] :     query 11 finished OK (40 seconds)
2016-09-18 06:06:15 [1474149975] :   running query 12
2016-09-18 06:06:16 [1474149976] :     query 12 finished OK (0 seconds)
2016-09-18 06:06:16 [1474149976] :   running query 13
2016-09-18 06:10:08 [1474150208] :     query 13 finished OK (230 seconds)
2016-09-18 06:10:08 [1474150208] :   running query 14
2016-09-18 06:10:09 [1474150209] :     query 14 finished OK (0 seconds)
2016-09-18 06:10:09 [1474150209] :   running query 15
2016-09-18 06:10:12 [1474150212] :     query 15 finished OK (1 seconds)
2016-09-18 06:10:12 [1474150212] :   running query 16
2016-09-18 06:11:38 [1474150298] :     query 16 finished OK (85 seconds)
2016-09-18 06:11:38 [1474150298] :   running query 17
2016-09-18 06:31:41 [1474151501] :     query 17 finished OK (1199 seconds)
2016-09-18 06:31:41 [1474151501] :   running query 18
2016-09-18 06:42:21 [1474152141] :     query 18 finished OK (637 seconds)
2016-09-18 06:42:21 [1474152141] :   running query 19
2016-09-18 06:45:45 [1474152345] :     query 19 finished OK (202 seconds)
2016-09-18 06:45:45 [1474152345] :   running query 20
2016-09-18 06:46:17 [1474152377] :     query 20 finished OK (30 seconds)
2016-09-18 06:46:17 [1474152377] :   running query 21
2016-09-18 06:58:42 [1474153122] :     query 21 finished OK (739 seconds)
2016-09-18 06:58:42 [1474153122] :   running query 22
2016-09-18 07:01:43 [1474153303] :     query 22 finished OK (180 seconds)
2016-09-18 07:01:44 [1474153304] : finished TPC-H benchmark
```
## 未来 
目前本文未涉及的内容如下，在将来的文章中输出。  
HA, 扩容, 缩容, 备份, 最佳实践, 优化。  
#### [PostgreSQL 许愿链接](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216")
您的愿望将传达给PG kernel hacker、数据库厂商等, 帮助提高数据库产品质量和功能, 说不定下一个PG版本就有您提出的功能点. 针对非常好的提议，奖励限量版PG文化衫、纪念品、贴纸、PG热门书籍等，奖品丰富，快来许愿。[开不开森](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216").  
#### [9.9元购买3个月阿里云RDS PostgreSQL实例](https://www.aliyun.com/database/postgresqlactivity "57258f76c37864c6e6d23383d05714ea")
#### [PostgreSQL 解决方案集合](https://yq.aliyun.com/topic/118 "40cff096e9ed7122c512b35d8561d9c8")
#### [德哥 / digoal's github - 公益是一辈子的事.](https://github.com/digoal/blog/blob/master/README.md "22709685feb7cab07d30f30387f0a9ae")
![digoal's wechat](../pic/digoal_weixin.jpg "f7ad92eeba24523fd47a6e1a0e691b59")
#### [PolarDB 学习图谱: 训练营、培训认证、在线互动实验、解决方案、生态合作、写心得拿奖品](https://www.aliyun.com/database/openpolardb/activity "8642f60e04ed0c814bf9cb9677976bd4")
#### [购买PolarDB云服务折扣活动进行中, 55元起](https://www.aliyun.com/activity/new/polardb-yunparter?userCode=bsb3t4al "e0495c413bedacabb75ff1e880be465a")
#### [About 德哥](https://github.com/digoal/blog/blob/master/me/readme.md "a37735981e7704886ffd590565582dd0")