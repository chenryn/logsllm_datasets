# 27 \| 缓存被污染了，该怎么办？你好，我是蒋德钧。我们应用 Redis缓存时，如果能缓存会被反复访问的数据，那就能加速业务应用的访问。但是，如果发生了缓存污染，那么，缓存对业务应用的加速作用就减少了。那什么是缓存污染呢？在一些场景下，有些数据被访问的次数非常少，甚至只会被访问一次。当这些数据服务完访问请求后，如果还继续留存在缓存中的话，就只会白白占用缓存空间。这种情况，就是缓存污染。当缓存污染不严重时，只有少量数据占据缓存空间，此时，对缓存系统的影响不大。但是，缓存污染一旦变得严重后，就会有大量不再访问的数据滞留在缓存中。如果这时数据占满了缓存空间，我们再往缓存中写入新数据时，就需要先把这些数据逐步淘汰出缓存，这就会引入额外的操作时间开销，进而会影响应用的性能。今天，我们就来看看如何解决缓存污染问题。如何解决缓存污染问题？要解决缓存污染，我们也能很容易想到解决方案，那就是得把不会再被访问的数据筛选出来并淘汰掉。这样就不用等到缓存被写满以后，再逐一淘汰旧数据之后，才能写入新数据了。而哪些数据能留存在缓存中，是由缓存的淘汰策略决定的。到这里，你还记得咱们在第 24 讲一起学习的 8种数据淘汰策略吗？它们分别是noeviction、volatile-random、volatile-ttl、volatile-lru、volatile-lfu、allkeys-lru、allkeys-random和 allkeys-lfu 策略。在这 8 种策略中，noeviction策略是不会进行数据淘汰的。所以，它肯定不能用来解决缓存污染问题。其他的 7种策略，都会按照一定的规则来淘汰数据。这里有个关键词是"一定的规则"，那么问题来了，不同的规则对于解决缓存污染问题，是否都有效呢？接下来，我们就一一分析下。因为 LRU算法是我们在缓存数据淘汰策略中广泛应用的算法，所以我们先分析其他策略，然后单独分析淘汰策略使用LRU 算法的情况，最后再学习下 LFU算法用于淘汰策略时，对缓存污染的应对措施。使用 LRU 算法和 LFU算法的策略各有两种（volatile-lru 和 allkeys-lru，以及 volatile-lfu 和allkeys-lfu），为了便于理解，接下来我会统一把它们叫作 LRU 策略和 LFU策略。 首先，我们看下 **volatile-random 和allkeys-random**这两种策略。它们都是采用随机挑选数据的方式，来筛选即将被淘汰的数据。既然是随机挑选，那么 Redis就不会根据数据的访问情况来筛选数据。如果被淘汰的数据又被访问了，就会发生缓存缺失。也就是说，应用需要到后端数据库中访问这些数据，降低了应用的请求响应速度。所以，volatile-random和 allkeys-random策略，在避免缓存污染这个问题上的效果非常有限。我给你举个例子吧。如下图所示，假设我们配置 Redis 缓存使用allkeys-random 淘汰策略，当缓存写满时，allkeys-random 策略随机选择了数据20 进行淘汰。不巧的是，数据 20 紧接着又被访问了，此时，Redis就会发生了缓存缺失。![](Images/37e84d3a7d6e1ef09a4374f9ce4f9d87.png)savepage-src="https://static001.geekbang.org/resource/image/d8/c8/d8e81168d83b411524a91c2f5554e3c8.jpg"}我们继续看 **volatile-ttl** 策略是否能有效应对缓存污染。volatile-ttl针对的是设置了过期时间的数据，把这些数据中剩余存活时间最短的筛选出来并淘汰掉。虽然 volatile-ttl策略不再是随机选择淘汰数据了，但是剩余存活时间并不能直接反映数据再次访问的情况。所以，按照volatile-ttl策略淘汰数据，和按随机方式淘汰数据类似，也可能出现数据被淘汰后，被再次访问导致的缓存缺失问题。这时，你可能会想到一种例外的情况：业务应用在给数据设置过期时间的时候，就明确知道数据被再次访问的情况，并根据访问情况设置过期时间。此时，Redis按照数据的剩余最短存活时间进行筛选，是可以把不会再被访问的数据筛选出来的，进而避免缓存污染。例如，业务部门知道数据被访问的时长就是一个小时，并把数据的过期时间设置为一个小时后。这样一来，被淘汰的数据的确是不会再被访问了。讲到这里，我们先小结下。除了在明确知道数据被再次访问的情况下，volatile-ttl可以有效避免缓存污染。在其他情况下，volatile-random、allkeys-random、volatile-ttl这三种策略并不能应对缓存污染问题。接下来，我们再分别分析下 LRU 策略，以及 Redis 4.0 后实现的 LFU策略。LRU策略会按照数据访问的时效性，来筛选即将被淘汰的数据，应用非常广泛。在第24 讲，我们已经学习了 Redis 是如何实现 LRU策略的，所以接下来我们就重点看下它在解决缓存污染问题上的效果。LRU 缓存策略我们先复习下 LRU策略的核心思想：如果一个数据刚刚被访问，那么这个数据肯定是热数据，还会被再次访问。按照这个核心思想，Redis 中的 LRU 策略，会在每个数据对应的 RedisObject结构体中设置一个 lru字段，用来记录数据的访问时间戳。在进行数据淘汰时，LRU策略会在候选数据集中淘汰掉 lru字段值最小的数据（也就是访问时间最久的数据）。所以，在数据被频繁访问的业务场景中，LRU策略的确能有效留存访问时间最近的数据。而且，因为留存的这些数据还会被再次访问，所以又可以提升业务应用的访问速度。但是，也正是**因为只看数据的访问时间，使用 LRU策略在处理扫描式单次查询操作时，无法解决缓存污染**。所谓的扫描式单次查询操作，就是指应用对大量的数据进行一次全体读取，每个数据都会被读取，而且只会被读取一次。此时，因为这些被查询的数据刚刚被访问过，所以lru 字段值都很大。在使用 LRU策略淘汰数据时，这些数据会留存在缓存中很长一段时间，造成缓存污染。如果查询的数据量很大，这些数据占满了缓存空间，却又不会服务新的缓存请求，此时，再有新数据要写入缓存的话，还是需要先把这些旧数据替换出缓存才行，这会影响缓存的性能。为了方便你理解，我给你举个例子。如下图所示，数据 6 被访问后，被写入Redis 缓存。但是，在此之后，数据 6 一直没有被再次访问，这就导致数据 6滞留在缓存中，造成了污染。![](Images/ffb640dc79ace12906af5ea3b989bd64.png)savepage-src="https://static001.geekbang.org/resource/image/76/75/76909482d30097da81273f7bda18b275.jpg"}所以，对于采用了 LRU 策略的 Redis缓存来说，扫描式单次查询会造成缓存污染。为了应对这类缓存污染问题，Redis从 4.0 版本开始增加了 LFU淘汰策略。 与 LRU 策略相比，LFU策略中会从两个维度来筛选并淘汰数据：一是，数据访问的时效性（访问时间离当前时间的远近）；二是，数据的被访问次数。那 Redis 的 LFU策略是怎么实现的，又是如何解决缓存污染问题的呢？我们来看一下。LFU 缓存策略的优化LFU 缓存策略是在 LRU策略基础上，为每个数据增加了一个计数器，来统计这个数据的访问次数。当使用LFU策略筛选淘汰数据时，首先会根据数据的访问次数进行筛选，把访问次数最低的数据淘汰出缓存。如果两个数据的访问次数相同，LFU策略再比较这两个数据的访问时效性，把距离上一次访问时间更久的数据淘汰出缓存。和那些被频繁访问的数据相比，扫描式单次查询的数据因为不会被再次访问，所以它们的访问次数不会再增加。因此，LFU策略会优先把这些访问次数低的数据淘汰出缓存。这样一来，LFU策略就可以避免这些数据对缓存造成污染了。那么，LFU 策略具体又是如何实现的呢？既然 LFU 策略是在 LRU策略上做的优化，那它们的实现必定有些关系。所以，我们就再复习下第 24讲学习过的 LRU 策略的实现。为了避免操作链表的开销，Redis 在实现 LRU策略时使用了两个近似方法：1.  Redis 是用 RedisObject 结构来保存数据的，RedisObject    结构中设置了一个 lru    字段，用来记录数据的访问时间戳；        2.  Redis    并没有为所有的数据维护一个全局的链表，而是通过随机采样方式，选取一定数量（例如    10 个）的数据放入候选集合，后续在候选集合中根据 lru    字段值的大小进行筛选。        在此基础上，**Redis 在实现 LFU 策略的时候，只是把原来 24bit 大小的 lru字段，又进一步拆分成了两部分**。1.       ldt 值：lru 字段的前    16bit，表示数据的访问时间戳；        2.       counter 值：lru 字段的后    8bit，表示数据的访问次数。        总结一下：当 LFU 策略筛选数据时，Redis 会在候选集合中，根据数据 lru字段的后 8bit 选择访问次数最少的数据进行淘汰。当访问次数相同时，再根据lru 字段的前 16bit值大小，选择访问时间最久远的数据进行淘汰。到这里，还没结束，**Redis 只使用了 8bit 记录数据的访问次数，而 8bit记录的最大值是 255**，这样可以吗？在实际应用中，一个数据可能会被访问成千上万次。如果每被访问一次，counter值就加 1 的话，那么，只要访问次数超过了 255，数据的 counter值就一样了。在进行数据淘汰时，LFU策略就无法很好地区分并筛选这些数据，反而还可能会把不怎么访问的数据留存在了缓存中。我们一起来看个例子。假设第一个数据 A 的累计访问次数是 256，访问时间戳是202010010909，所以它的 counter 值为 255，而第二个数据 B 的累计访问次数是1024，访问时间戳是 202010010810。如果 counter 值只能记录到 255，那么数据B 的 counter 值也是 255。此时，缓存写满了，Redis 使用 LFU 策略进行淘汰。数据 A 和 B 的 counter值都是 255，LFU 策略再比较 A 和 B 的访问时间戳，发现数据 B的上一次访问时间早于 A，就会把 B 淘汰掉。但其实数据 B的访问次数远大于数据 A，很可能会被再次访问。这样一来，使用 LFU策略来淘汰数据就不合适了。的确，Redis也注意到了这个问题。因此，**在实现 LFU 策略时，Redis并没有采用数据每被访问一次，就给对应的 counter 值加 1的计数规则，而是采用了一个更优化的计数规则**。简单来说，LFU策略实现的计数规则是：每当数据被访问一次时，首先，用计数器当前的值乘以配置项lfu_log_factor 再加 1，再取其倒数，得到一个 p 值；然后，把这个 p值和一个取值范围在（0，1）间的随机数 r 值比大小，只有 p 值大于 r值时，计数器才加 1。下面这段 Redis 的部分源码，显示了 LFU策略增加计数器值的计算逻辑。其中，baseval是计数器当前的值。计数器的初始值默认是 5（由代码中的 LFU_INIT_VAL常量设置），而不是0，这样可以避免数据刚被写入缓存，就因为访问次数少而被立即淘汰。    double r = (double)rand()/RAND_MAX;    ...    double p = 1.0/(baseval*server.lfu_log_factor+1);    if (r  20 THEN        ERROR "exceed 20 accesses per second"    ELSE        //如果访问次数不足20次，增加一次访问计数        value = INCR(ip)        //如果是第一次访问，将键值对的过期时间设置为60s后        IF value == 1 THEN            EXPIRE(ip,60)        END        //执行其他操作        DO THINGS    END可以看到，在这个例子中，我们已经使用了 INCR来原子性地增加计数。但是，客户端限流的逻辑不只有计数，还包括**访问次数判断和过期时间设置**。对于这些操作，我们同样需要保证它们的原子性。否则，如果客户端使用多线程访问，访问次数初始值为0，第一个线程执行了 INCR(ip) 操作后，第二个线程紧接着也执行了INCR(ip)，此时，ip 对应的访问次数就被增加到了 2，我们就无法再对这个 ip设置过期时间了。这样就会导致，这个 ip 对应的客户端访问次数达到 20次之后，就无法再进行访问了。即使过了60s，也不能再继续访问，显然不符合业务要求。所以，这个例子中的操作无法用 Redis单个命令来实现，此时，我们就可以使用 Lua脚本来保证并发控制。我们可以把访问次数加 1、判断访问次数是否为1，以及设置过期时间这三个操作写入一个 Lua脚本，如下所示：    local current    current = redis.call("incr",KEYS[1])    if tonumber(current) == 1 then        redis.call("expire",KEYS[1],60)    end假设我们编写的脚本名称为 lua.script，我们接着就可以使用 Redis客户端，带上 eval 选项，来执行该脚本。脚本所需的参数将通过以下命令中的keys 和 args 进行传递。    redis-cli  --eval lua.script  keys , args这样一来，访问次数加 1、判断访问次数是否为1，以及设置过期时间这三个操作就可以原子性地执行了。即使客户端有多个线程同时执行这个脚本，Redis也会依次串行执行脚本代码，避免了并发操作带来的数据错误。小结在并发访问时，并发的 RMW操作会导致数据错误，所以需要进行并发控制。所谓并发控制，就是要保证临界区代码的互斥执行。Redis 提供了两种原子操作的方法来实现并发控制，分别是单命令操作和 Lua脚本。因为原子操作本身不会对太多的资源限制访问，可以维持较高的系统并发性能。但是，单命令原子操作的适用范围较小，并不是所有的 RMW操作都能转变成单命令的原子操作（例如 INCR/DECR命令只能在读取数据后做原子增减），当我们需要对读取的数据做更多判断，或者是我们对数据的修改不是简单的增减时，单命令操作就不适用了。而 Redis 的 Lua脚本可以包含多个操作，这些操作都会以原子性的方式执行，绕开了单命令操作的限制。不过，如果把很多操作都放在Lua 脚本中原子执行，会导致 Redis 执行脚本的时间增加，同样也会降低 Redis的并发性能。所以，我给你一个小建议：**在编写 Lua脚本时，你要避免把不****需要****做并发控制的操作写入脚本中**。当然，加锁也能实现临界区代码的互斥执行，只是如果有多个客户端加锁时，就需要分布式锁的支持了。所以，下节课，我就来和你聊聊分布式锁的实现。每课一问按照惯例，我向你提个小问题，Redis 在执行 Lua脚本时，是可以保证原子性的，那么，在我举的 Lua脚本例子（lua.script）中，你觉得是否需要把读取客户端 ip的访问次数，也就是 GET(ip)，以及判断访问次数是否超过 20的判断逻辑，也加到 Lua脚本中吗？ 欢迎在留言区写下你的思考和答案，我们一起交流讨论。如果你觉得今天的内容对你有所帮助，也欢迎你分享给你的朋友或同事。我们下节课见。