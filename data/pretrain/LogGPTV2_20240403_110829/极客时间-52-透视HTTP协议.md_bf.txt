## 流与多路复用弄清楚了帧结构后我们就来看 HTTP/2 的流与多路复用，它是 HTTP/2最核心的部分。在上一讲里我简单介绍了流的概念，不知道你"悟"得怎么样了？这里我再重复一遍：**流是二进制帧的双向传输序列**。要搞明白流，关键是要理解帧头里的流 ID。在 HTTP/2 连接上，虽然帧是乱序收发的，但只要它们都拥有相同的流ID，就都属于一个流，而且在这个流里帧不是无序的，而是有着严格的先后顺序。比如在这次的 Wireshark抓包里，就有"0、1、3"一共三个流，实际上就是分配了三个流 ID号，把这些帧按编号分组，再排一下队，就成了流。![](Images/241f83dcb0d41a734e61eb40a19eda28.png){savepage-src="https://static001.geekbang.org/resource/image/68/33/688630945be2dd51ca62515ae498db33.png"}在概念上，一个 HTTP/2 的流就等同于一个 HTTP/1 里的"请求 - 应答"。在HTTP/1 里一个"请求 - 响应"报文来回是一次 HTTP 通信，在 HTTP/2里一个流也承载了相同的功能。你还可以对照着 TCP 来理解。TCP 运行在 IP 之上，其实从 MAC 层、IP层的角度来看，TCP 的"连接"概念也是"虚拟"的。但从功能上看，无论是 HTTP/2的流，还是 TCP的连接，都是实际存在的，所以你以后大可不必再纠结于流的"虚拟"性，把它当做是一个真实存在的实体来理解就好。HTTP/2 的流有哪些特点呢？我给你简单列了一下：1.  流是可并发的，一个 HTTP/2    连接上可以同时发出多个流传输数据，也就是并发多请求，实现"多路复用"；2.  客户端和服务器都可以创建流，双方互不干扰；3.  流是双向的，一个流里面客户端和服务器都可以发送或接收数据帧，也就是一个"请求 -    应答"来回；4.  流之间没有固定关系，彼此独立，但流内部的帧是有严格顺序的；5.  流可以设置优先级，让服务器优先处理，比如先传    HTML/CSS，后传图片，优化用户体验；6.  流 ID 不能重用，只能顺序递增，客户端发起的 ID 是奇数，服务器端发起的    ID 是偶数；7.  在流上发送"RST_STREAM"帧可以随时终止流，取消接收或发送；8.  第 0    号流比较特殊，不能关闭，也不能发送数据帧，只能发送控制帧，用于流量控制。这里我又画了一张图，把上次的图略改了一下，显示了连接中无序的帧是如何依据流ID 重组成流的。![](Images/37b3b697a63828347bdac7af69486395.png){savepage-src="https://static001.geekbang.org/resource/image/b4/7e/b49595a5a425c0e67d46ee17cc212e7e.png"}从这些特性中，我们还可以推理出一些深层次的知识点。比如说，HTTP/2在一个连接上使用多个流收发数据，那么它本身默认就会是长连接，所以永远不需要"Connection"头字段（keepalive或 close）。你可以再看一下 Wireshark的抓包，里面发送了两个请求"/31-1"和"/favicon.ico"，始终用的是"56095\8443"这个连接，对比一下[第8讲](https://time.geekbang.org/column/article/100502)，你就能够看出差异了。又比如，下载大文件的时候想取消接收，在 HTTP/1 里只能断开 TCP连接重新"三次握手"，成本很高，而在 HTTP/2里就可以简单地发送一个"RST_STREAM"中断流，而长连接会继续保持。再比如，因为客户端和服务器两端都可以创建流，而流 ID有奇数偶数和上限的区分，所以大多数的流 ID都会是奇数，而且客户端在一个连接里最多只能发出 2\^30，也就是 10亿个请求。所以就要问了：ID用完了该怎么办呢？这个时候可以再发一个控制帧"GOAWAY"，真正关闭 TCP连接。
## 流状态转换流很重要，也很复杂。为了更好地描述运行机制，HTTP/2 借鉴了TCP，根据帧的标志位实现流状态转换。当然，这些状态也是虚拟的，只是为了辅助理解。HTTP/2 的流也有一个状态转换图，虽然比 TCP要简单一点，但也不那么好懂，所以今天我只画了一个简化的图，对应到一个标准的HTTP"请求 - 应答"。![](Images/5a4e37e0cc85ceddd6517dfa75c58829.png){savepage-src="https://static001.geekbang.org/resource/image/d3/b4/d389ac436d8100406a4a488a69563cb4.png"}最开始的时候流都是"**空闲**"（idle）状态，也就是"不存在"，可以理解成是待分配的"号段资源"。当客户端发送 HEADERS 帧后，有了流ID，流就进入了"**打开**"状态，两端都可以收发数据，然后客户端发送一个带"END_STREAM"标志位的帧，流就进入了"**半关闭**"状态。这个"半关闭"状态很重要，意味着客户端的请求数据已经发送完了，需要接受响应数据，而服务器端也知道请求数据接收完毕，之后就要内部处理，再发送响应数据。响应数据发完了之后，也要带上"END_STREAM"标志位，表示数据发送完毕，这样流两端就都进入了"**关闭**"状态，流就结束了。刚才也说过，流 ID 不能重用，所以流的生命周期就是 HTTP/1里的一次完整的"请求 - 应答"，流关闭就是一次通信结束。下一次再发请求就要开一个新流（而不是新连接），流 ID不断增加，直到到达上限，发送"GOAWAY"帧开一个新的 TCP 连接，流 ID就又可以重头计数。你再看看这张图，是不是和 HTTP/1 里的标准"请求 -应答"过程很像，只不过这是发生在虚拟的"流"上，而不是实际的 TCP连接，又因为流可以并发，所以 HTTP/2 就可以实现无阻塞的多路复用。
## 小结HTTP/2的内容实在是太多了，为了方便学习，我砍掉了一些特性，比如流的优先级、依赖关系、流量控制等。但只要你掌握了今天的这些内容，以后再看 RFC 文档都不会有难度了。1.  [HTTP/2    必须先发送一个"连接前言"字符串，然后才能建立正式连接；]{.orange}2.  [HTTP/2    废除了起始行，统一使用头字段，在两端维护字段"Key-Value"的索引表，使用"HPACK"算法压缩头部；]{.orange}3.  [HTTP/2    把报文切分为多种类型的二进制帧，报头里最重要的字段是流标识符，标记帧属于哪个流；]{.orange}4.  [流是 HTTP/2 虚拟的概念，是帧的双向传输序列，相当于 HTTP/1    里的一次"请求 - 应答"；]{.orange}5.  [在一个 HTTP/2 连接上可以并发多个流，也就是多个"请求 -    响应"报文，这就是"多路复用"。]{.orange}
## 课下作业1.  HTTP/2 的动态表维护、流状态转换很复杂，你认为 HTTP/2    还是"无状态"的吗？2.  HTTP/2 的帧最大可以达到 16M，你觉得大帧好还是小帧好？3.  结合这两讲，谈谈 HTTP/2 是如何解决"队头阻塞"问题的。欢迎你把自己的学习体会写在留言区，与我和其他同学一起讨论。如果你觉得有所收获，也欢迎把文章分享给你的朋友。![unpreview](Images/a2482103e137d0c010433e1764306d2c.png){savepage-src="https://static001.geekbang.org/resource/image/3d/49/3dfab162c427fb3a1fa16494456ae449.png"}![unpreview](Images/4913a489805db29b38aefa585223c013.png){savepage-src="https://static001.geekbang.org/resource/image/56/63/56d766fc04654a31536f554b8bde7b63.jpg"}
# 32 \| 未来之路：HTTP/3展望在前面的两讲里，我们一起学习了 HTTP/2，你也应该看到了 HTTP/2做出的许多努力，比如头部压缩、二进制分帧、虚拟的"流"与多路复用，性能方面比HTTP/1 有了很大的提升，"基本上"解决了"队头阻塞"这个"老大难"问题。
## HTTP/2 的"队头阻塞"等等，你可能要发出疑问了：为什么说是"基本上"，而不是"完全"解决了呢？这是因为 HTTP/2虽然使用"帧""流""多路复用"，没有了"队头阻塞"，但这些手段都是在应用层里，而在下层，也就是TCP 协议里，还是会发生"队头阻塞"。这是怎么回事呢？让我们从协议栈的角度来仔细看一下。在 HTTP/2 把多个"请求 -响应"分解成流，交给 TCP 后，TCP 会再拆成更小的包依次发送（其实在 TCP里应该叫 segment，也就是"段"）。在网络良好的情况下，包可以很快送达目的地。但如果网络质量比较差，像手机上网的时候，就有可能会丢包。而TCP为了保证可靠传输，有个特别的"丢包重传"机制，丢失的包必须要等待重新传输确认，其他的包即使已经收到了，也只能放在缓冲区里，上层的应用拿不出来，只能"干着急"。我举个简单的例子：客户端用 TCP发送了三个包，但服务器所在的操作系统只收到了后两个包，第一个包丢了。那么内核里的TCP协议栈就只能把已经收到的包暂存起来，"停下"等着客户端重传那个丢失的包，这样就又出现了"队头阻塞"。``{=html}由于这种"队头阻塞"是 TCP 协议固有的，所以 HTTP/2即使设计出再多的"花样"也无法解决。Google 在推 SPDY的时候就已经意识到了这个问题，于是就又发明了一个新的"QUIC"协议，让 HTTP跑在 QUIC 上而不是 TCP 上。而这个"HTTP over QUIC"就是 HTTP 协议的下一个大版本，**HTTP/3**。它在HTTP/2 的基础上又实现了质的飞跃，真正"完美"地解决了"队头阻塞"问题。不过 HTTP/3目前还处于草案阶段，正式发布前可能会有变动，所以今天我尽量不谈那些不稳定的细节。这里先贴一下 HTTP/3 的协议栈图，让你对它有个大概的了解。![](Images/032a973342682416615290f675d55322.png){savepage-src="https://static001.geekbang.org/resource/image/d2/03/d263202e431c84db0fd6c7e6b1980f03.png"}
## QUIC 协议从这张图里，你可以看到 HTTP/3 有一个关键的改变，那就是它把下层的TCP"抽掉"了，换成了 UDP。因为 UDP是无序的，包之间没有依赖关系，所以就从根本上解决了"队头阻塞"。你一定知道，UDP 是一个简单、不可靠的传输协议，只是对 IP协议的一层很薄的包装，和 TCP 相比，它实际应用的较少。不过正是因为它简单，不需要建连和断连，通信成本低，也就非常灵活、高效，"可塑性"很强。所以，QUIC 就选定了 UDP，在它之上把 TCP的那一套连接管理、拥塞窗口、流量控制等"搬"了过来，"去其糟粕，取其精华"，打造出了一个全新的可靠传输协议，可以认为是"**新时代的TCP**"。![unpreview](Images/9b3e3b1f6499b99ec041eeeb3eb32372.png){savepage-src="https://static001.geekbang.org/resource/image/fd/7a/fd99221ede55272a998760cc6aaa037a.png"}QUIC 最早是由 Google 发明的，被称为 gQUIC。而当前正在由 IETF 标准化的QUIC 被称为 iQUIC。两者的差异非常大，甚至比当年的 SPDY 与 HTTP/2的差异还要大。gQUIC 混合了 UDP、TLS、HTTP，是一个应用层的协议。而 IETF 则对 gQUIC做了"清理"，把应用部分分离出来，形成了 HTTP/3，原来的 UDP部分"下放"到了传输层，所以 iQUIC 有时候也叫"QUIC-transport"。接下来要说的 QUIC 都是指 iQUIC，要记住，它与早期的 gQUIC不同，是一个传输层的协议，和 TCP 是平级的。
## QUIC 的特点QUIC 基于 UDP，而 UDP是"无连接"的，根本就不需要"握手"和"挥手"，所以天生就要比 TCP 快。就像 TCP 在 IP 的基础上实现了可靠传输一样，QUIC 也基于 UDP实现了可靠传输，保证数据一定能够抵达目的地。它还引入了类似 HTTP/2的"流"和"多路复用"，单个"流"是有序的，可能会因为丢包而阻塞，但其他"流"不会受到影响。为了防止网络上的中间设备（Middle Box）识别协议的细节，QUIC全面采用加密通信，可以很好地抵御窜改和"协议僵化"（ossification）。而且，因为 TLS1.3 已经在去年（2018）正式发布，所以 QUIC 就直接应用了TLS1.3，顺便也就获得了 0-RTT、1-RTT 连接的好处。但 QUIC 并不是建立在 TLS 之上，而是内部"包含"了TLS。它使用自己的帧"接管"了 TLS 里的"记录"，握手消息、警报消息都不使用TLS 记录，直接封装成 QUIC 的帧发送，省掉了一次开销。