Most papers on introspection focus on the ﬁrst problem,
which has arguably been solved [40, 44, 80], yet interesting
attacks leverage the second issue, which is still an open
problem, as is reliable introspection under stronger threat
models.
Unfortunately, the literature has not clearly distinguished
these problem variations, and only a close reading will indi-
cate which one a given paper is addressing. This confusion
is only exacerbated when one attempts to place these papers
next to each other in the context of attacks and defenses.
That said, we do believe that the overall path of starting
with a weak attacker and iteratively strengthening the threat
model is a pragmatic approach to research in this area; the
issue is ambiguous nomenclature.
We therefore suggest a clearer nomenclature for the two
sub-problems: the weak and strong semantic gap problems.
The weak semantic gap is the largely solved engineering
challenge of generating VMI tools, and the strong semantic
gap refers to the challenge of defending against an adver-
sarial, untrusted guest OS. A solution to the open strong
semantic gap problem would not make any assumptions
about the guest OS being benign during a training phase or
accept inferences from guest source code as reliable without
runtime validation. The strong semantic gap problem is, to
our knowledge, unsolved, and the ability to review future
work in this space relies on clearer delineation of the level
of trust placed in the guest OS. A solution to the strong
semantic gap problem would also prevent or detect DKSM
attacks.
The weak semantic gap is a solved engineering problem.
The strong semantic gap is an open security problem.
VI. TOWARD AN UNTRUSTED OS
Any solution to the strong semantic gap problem may
need to remove assumptions that
the guest OS can be
trusted to help train an introspection tool. As illustrated
in Section III, most existing introspection tools rely on the
assumption that the guest OS begins in a benign state and its
source code or initial state can be trusted. Over time, several
designs have reduced the degree to which they rely on the
guest OS. It is not clear, however, that continued iterative
reﬁnement will converge on techniques that eliminate trust
in the guest.
Table IV illustrates the space of reasonable trust models
in virtualization-based security. Although a lot of effort in
VMI has gone into the ﬁrst row (the weak semantic gap), the
community should focus on new directions likely to bridge
the strong semantic gap (second row), as well as adopt useful
techniques from research into the other rows.
This section identiﬁes promising approaches to the strong
semantic gap, based on insights from the literature.
A. Paraveriﬁcation
Many VMI systems have the implicit design goal of
working with an unmodiﬁed OS, or limiting modiﬁcations to
the module loader and hooks. The goal of introspecting on an
unmodiﬁed guest OS often induces trust in the guest OS to
simplify this difﬁcult problem. Speciﬁcally, most VMI tools
assume the guest OS is not actively malicious and adheres
to the behavior exhibited during the learning phase.
This subsection observes that, rather than relax the threat
model for VMI, relaxing the requirement of an unmodiﬁed
615
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:01:07 UTC from IEEE Xplore.  Restrictions apply. 
App Guest OS Hypervisor
√
√
√
√
√
√
√
√
Challenge
Weak Semantic Gap
Strong Semantic Gap
Untrusted guest OS
Untrusted cloud hypervisor
Untrusted guest OS and hypervisor
Solutions
Layered Security, VMI. Incrementally reduce trust in the guest OS.
Difﬁcult to solve. Need techniques that can learn from untrusted
sources and detect inconsistencies during VMI.
Paraveriﬁcation. Application trust bridges the semantic gap.
Support from trusted hardware like SGX [7, 70].
Fine grained support from trusted hardware needed.
TRUST MODELS. (
√
Table IV
INDICATES THE LAYERS THAT ARE TRUSTED.)
OS may be a more useful stepping stone toward an untrusted
OS. By analogy, although initial hypervisors went through
heroic efforts to virtualize unmodiﬁed legacy OSes on an
ISA very unsuitable for virtualization [26], most modern
OSes now implement paravirtualization support [25]. Es-
sentially, paravirtualization makes small modiﬁcations to
the guest OS that eliminate the most onerous features to
emulate. For instance, Xen allowed the guest OS to observe
that there were inaccessible physical pages, substantially
reducing the overheads of virtualizing physical memory.
The reason paravirtualization was a success is that it was
easy to adopt, introduced little or no overheads when the
system executes on bare metal, and dramatically improved
performance in a VM.
Thus, we expect that light modiﬁcations to a guest OS
to aid in introspection could be a promising direction.
Speciﬁcally, we observe that the recent InkTag [52] system
introduced the idea of paraveriﬁcation, in which the guest
OS provides the hypervisor with evidence that it is servicing
an application’s request correctly. The evidence offered by
the guest OS is easily checked by the hypervisor without
trusting the guest OS. For instance, a trusted application
may request a memory mapping of a ﬁle, and, in addition
to issuing an mmap system call, also reports the request
to the hypervisor. When the OS modiﬁes the application’s
page tables to implement the mmap system call, the OS also
notiﬁes the hypervisor that this modiﬁcation is in response
to a particular application request. The hypervisor can then
do an end-to-end check that (1) the page table changes are
applied to an appropriate region of the application’s virtual
memory, (2) that the CPU register values used to return
to the application are sensible, and (3) that the contents of
these pages match the expected values read from disk, using
additional metadata storing hashes of ﬁle contents.
We hasten to note that the goals of InkTag are different
from VMI—ensuring a trusted application can safely use
functionality from a malicious OS. This problem has also
been explored in a number of other papers [35, 63]. More-
over, InkTag leverages the trusted application to bridge the
semantic gap—a strategy that would not be suitable for the
types of problems VMI aims to solve. Nonetheless, forcing
an untrusted OS to aid in its own introspection could be
fruitful if the techniques were simple enough to adopt.
Rather than relaxing the threat model for VMI, relax strict
limits on guest modiﬁcations.
B. Hardware support for security
As we observe in §IV-C, Memory protection or other
synchronous notiﬁcation mechanisms appear to be a require-
ment to move from detection to prevention. Unfortunately,
the coarseness of mechanisms in commodity hardware intro-
duce substantial overheads. §IV-B summarizes recent work
on memory monitoring at cache line granularity—a valuable
approach meriting further research.
An interesting direction recently taken by Intel is develop-
ing a mutual distrust model for hardware memory protection,
called Software Guard Extensions (SGX) [21, 50, 70]. SGX
allows an OS or hypervisor to manage virtual-to-physical OS
mappings for an application, but the lower-level software
cannot access memory contents. SGX provides memory
isolation of a trusted application from an untrustworthy soft-
ware stack. Similar memory isolation has been provided by
several software-only systems [35, 52], but at a substantial
performance cost attributable to frequent traps to a trusted
hypervisor. Finally, we note that in order for an application
to safely use system calls on an untrusted OS, a number of
other problems must be addressed [33, 52].
In the context of introspection or the strong semantic
gap, hardware like SGX can also be useful for creating a
ﬁner-grained protection domain for code implanted in the
guest OS III-B. More ﬁne-grained memory protection and
monitoring tools are needed from hardware manufacturers.
Fine-grained memory protection and monitoring hardware
can reduce overheads and trust.
C. Reconstruction from untrusted sources
Current tools that automatically learn data structure sig-
natures assume the OS will behave similarly during training
and classiﬁcation (§V-B). Among the assumptions made in
current VMI tools, this is one that potentially has the best
chance of being incrementally removed. For example, one
approach might train the VMI classiﬁers on the live OS, and
continue incrementally training as the guest OS runs.
Another approach would be to detect
inconsistencies
between the training and classiﬁcation stages of VMI. By
616
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:01:07 UTC from IEEE Xplore.  Restrictions apply. 
analogy, distributed fault tolerance systems are often built
around the abstraction of a proof of misbehavior, where
a faulty participant in the protocol generates signed mes-
sages to different participants that contradict one another
[19, 61]. Similarly, one approach to assuring learning-based
systems is to look for proof of misbehavior in the guest
OS. For instance, Lycosid detected inconsistencies between
the cr3 register and the purported process descriptor’s
cr3 value [55]. A proof of misbehavior may also include
inconsistencies in code paths or data access patterns between
the training and classiﬁcation phases of introspection.
VMI should detect inconsistent behavior over the life of
an OS, not just between training and classiﬁcation.
VII. UNDER-EXPLORED ISSUES
Based on our survey of the literature on VMI, we identify
a few issues that deserve more consideration in future work.
A. Scalability
Many VMI designs are fairly expensive, especially de-
signs that run a sibling VM on a dedicated core for analysis.
For example, one state-of-the-art system reports overheads
ranging from 9.3—500× [44]. There is a reasonable argu-
ment why high VMI overheads might be acceptable: the
average desktop has idle cores anyway, which could be
fruitfully employed to improve system security. However,
this argument does not hold in a cloud environment, where
all cores can be utilized to service additional clients. In a
cloud, customers will not be pleased with doubling their bill,
nor would a provider be pleased with halving revenue.
It is reasonable to expect that VMI would be particularly
useful on a cloud or other multi-VM system. Thus, future
work on VMI must focus not only on novel techniques
or threat models, but also on managing overheads and
scalability with increasing numbers of VMs.
VMI research must measure multi-tenant scalability.
Another strategy to mitigate the costs of asynchronous
scanning is to adjust the frequency of the scans—trading
risk for performance. For instance, a recent system measured
scanning time at 50ms, and could keep overheads at 1%
by only scanning every 5s [51]. Similarly, one may cache
and reuse introspection results to trade risk of stale data
for better scalability [80]. An interesting direction for future
work is identifying techniques that minimize both overheads
and risk.
B. Privacy
system. This effectively leaks information about the pro-
grams run within a VM to an outside observer, undermining
user privacy.
More generally, VMI has the potential for one guest
to observe different cache timings based on the behavior
of another guest. Consider a VMI tool that does periodic
memory scans of multiple VMs on a cloud system, one
after another. The memory scan or snapshot will disrupt
cache timings of the guest under observation by forcing
exclusive cache lines to transition back to a shared, read-
only mode §V-B. Based on its own cache timings, the VM
can observe the frequency of its periodic scans. Because the
length of a scan of another VM can also be a function of
what the VM is doing, changes in time between scans of
one VM can indicate what is happening in another VM on
the same system.
Although it is unclear whether this example side channel
is exploitable in practice, the example raises the larger issue
that VMI projects should be cognizant of potential side
channels in a multi-VM system. Richter et al. [78] present
initial work on privacy-preserving introspection, but more
work is needed. An ideal system would not force the user
to choose between integrity or privacy risks.
VMI designs should evaluate risks of new side channels.
VIII. CONCLUSION
Virtual machine introspection is a relatively mature re-
search topic that has made substantial advances over the last
twelve years since the semantic gap problem was posed.
However, efforts in this space should be refocused on
removing trust from the guest OS in service of the larger
goal of reducing the system’s TCB. Moreover, future VMI
solutions should balance innovative techniques and security
properties with scalability and privacy concerns. We expect
that the lessons from previous work will guide future efforts
to adapt existing techniques or develop new techniques to
bridge the strong semantic gap.
ACKNOWLEDGEMENTS
We thank our shepherd, Virgil Gligor, and the anonymous
reviewers for their insightful comments on earlier versions
of this paper. This research was supported in part by
NSF grants CNS-1149229, NSF CNS-1161541, NSF CNS-
1228839, NSF CNS-1318572, NSF CNS-1223239, NSF
CCF-0937833, by the US ARMY award W911NF-13-1-
0142, the Ofﬁce of the Vice President for Research at Stony
Brook University, and by gifts from Northrop Grumman
Corporation, Parc/Xerox, Microsoft Research, and CA.
VMI has the potential to create new side-channels in cloud
systems. For instance, after reading application binaries,
Patagonix [65] queries the NSRL database with the binary
hash to determine the type of binary that is running on the
REFERENCES
[1] Draugr. Online at https://code.google.com/p/draugr/.
[2] FatKit. Online at http://4tphi.net/fatkit/.
[3] Foriana. Online at http://hysteria.sk/∼niekt0/foriana/.
617
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:01:07 UTC from IEEE Xplore.  Restrictions apply. 
[4] GREPEXEC: Grepping Executive Objects from Pool
Memory). Online at http://uninformed.org/?v=4&a=
2&t=pdf.
[5] idetect. Online at http://forensic.seccure.net/.
[6] Intel 64 and IA-32 Architectures Developer’s Manual:
Vol. 3B.
[7] Intel Software Guard Extensions (Intel SGX) Program-
ming Reference.
object
[8] Kernel
hooking
rootkits
(koh
rootkits).
http://my.opera.com/330205811004483jash520/blog/
show.dml/314125.
[9] Kntlist.
Online
at
http://www.dfrws.org/2005/
challenge/kntlist.shtml.
04/lsproc-released.html.
[10] lsproc. Online at http://windowsir.blogspot.com/2006/
In Black Hat USA 2004, Las Vegas, USA, 2004.
2003.
[26] E. Bugnion, S. Devine, M. Rosenblum, J. Sugerman,