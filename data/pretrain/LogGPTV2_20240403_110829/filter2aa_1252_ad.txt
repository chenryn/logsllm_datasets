0
2
4
Row 1
0
1
2
3
4
5
6
-2
0
2
4
Row 4
0
1
2
3
4
5
6
-2
0
2
4
Row 7
0
1
2
3
4
5
6
Time (ms)
-2
0
2
4
Row 10
  Voltage (mV)
(a) Sequential driven TX signals
0
1
2
3
4
-2
0
2
Column 1
0
1
2
3
4
-2
0
2
Column 2
0
1
2
3
4
-2
0
2
Column 5
0
1
2
3
4
Time (ms)
-2
0
2
Column 6
  Voltage (mV)
(b) Parallel driven TX signals
Fig. 16: TX signals on screens with different driving methods
Our technique consists of three steps: feature extraction,
classifier training, and location prediction. As shown in
Fig. 16b, the boundaries between two code bits can be identi-
fied, which allows us to segment the signals corresponding to
each code bit. For each segment, we can compute descriptive
features for a code bit, which can be the phase, the magnitude,
or the frequency, depending on the specific encoding schemes
used by the screen. Then, we can derive a feature vector for
each TX signal by concatenating these features. Afterward, we
can train a classifier with enough feature vector and location
pairs. This classifier can identify the screen location using the
signal collected at an unknown location.
We can identify different TX electrodes in different lines
using this technique, but we can not distinguish differ-
ent locations on the same TX electrode. Expressed differ-
ently, for any antenna with a known antenna coordinate
(xantenna, yantenna), we can obtain a single dimension screen
coordinate, which may be xscreen or yscreen. To determine
the other dimension, we also need to know at least one
antenna coordinate mapped to the screen boundary to tell
us the unknown dimension. As mentioned above, the screen
boundary can be accurately located by looking for significant
signal strength degradation between two adjacent antennas.
With enough antenna coordinate and screen coordinate pairs,
we can derive the mapping between them. The mapping
between (xscreen, yscreen) and (xantenna, yantenna) can be
seen as a rotation followed by a translation as described in
Equation 15, where θ represents the rotation while xt and yt
represent the translation. After solving this equation, we can
use this transformation matrix to select the closest antenna to
inject the error for any target screen location.
xscreen
yscreen
1
 =
cos(θ)
−sin(θ)
xt
sin(θ)
cos(θ)
yt
0
0
1
xantenna
yantenna
1
(15)
To better demonstrate how the screen locator works, we use
an iPad Pro as an example. From a TX signal on the iPad Pro,
we can obtain a feature vector with 48 feature values using
the magnitude of sinusoidal signals in each segment, which is
correlated to the row number on screen. Signals are collected
from the bottom row to the top row with a step of 1cm.
On each row, signals are collected at 12 different columns.
These signals are used to train a k-nearest neighbors (KNN)
classifier. In the evaluations, we first use signals collected from
7 antennas in a small area to detect the location and orientation
of the tested iPad Pro. Fig. 17a shows the detection results.
The predicted location is pretty close to the actual location,
with maximum prediction error being 0.8cm. Furthermore, if
we use 5 more antennas to collect signals in a larger area, the
prediction result matches perfectly with the actual location.
We tested our screen locator on 5 devices listed in Table IV.
We list the driving methods used by these devices, the sample
rate we use to collect the data, the average prediction error,
and the average computation time. Note that for screens using
SDM, the location is computed using the time stamp read from
an oscilloscope.
0
5
10
15
20
25
X (cm)
-10
-5
0
5
10
15
Y (cm)
predicted location
actual location
prediction error
antennas
(a) Screen location detected using 7
antennas
0
5
10
15
20
25
X (cm)
-10
-5
0
5
10
15
Y (cm)
predicted location
actual location
prediction error
antennas
(b) Screen location detected using 12
antennas
Fig. 17: Screen location detection results of iPad Pro
TABLE IV: Screen Location Detection Results
Device
Driving Method
Sample Rate
Error
Time
Nexus 5X
SDM
50MSa/s
0.42 cm
N/A
Google Pixel 2
SDM
50MSa/s
0.51 cm
N/A
iPhone 11 Pro
PDM
1MSa/s
0.3 cm
0.08s
OnePlus 7 Pro
PDM
2MSa/s
0.06 cm
0.14s
iPad Pro
PDM
1MSa/s
0.18 cm
0.17s
C. The Touch Event Detectors
To perform an attack which requires several touch events
to complete, it is important to know whether the current
touch event injection is successful before proceeding to inject
the next touch event at a different location. In certain cases
injection of a successful touch event may take more time
than expected. As introduced in Section XI, there are multiple
techniques to detect the current screen content out of sight.
However, these techniques can be difficult to use without
significant effort. In our work, instead of detecting if we
have altered the screen content as desired, we detect if our
last touch event injection was successfully applied on the
screen. The key behind such detection is the active scanning
mechanism used by modern touchscreen controllers [27]. To
achieve balance between the power efficiency and scanning
accuracy, touchscreen controllers perform reduced scanning
to preserve the power. Once a touch event is detected on the
touchscreen, the controller changes the scanning mode from
reduced scan to full scan to measure the touched location more
accurately. If there are no more touch events detected, the
controller switches back to reduced scan mode automatically.
Although we do not have a datasheet for a commercial touch-
screen controller, using our IEMI antenna we observed similar
behavior on all tested touchscreen devices. More importantly,
if the touch event is successfully injected on a target device and
recognized by the operating system, the touchscreen controller
takes a longer time to switch back to reduced scan mode. As
shown in Figure 18a, the iPad Pro emits a sparse scanning
signal with 120Hz frequency when no finger or IEMI signal
is present. Figure 18b shows how the touchscreen switches
from full scan mode back to reduced scan mode after we
turn off our IEMI signal. We can also see the touchscreen
recognizes our IEMI signal as a touch event but eliminates it
due to the wrong interference frequency. In Figure 18c, we
apply a correct IEMI signal and successfully trigger a touch
event on screen. The time that the controller takes to switch
back to reduced scan mode is discernibly longer compared
to the previous experiment. Such phenomena is stable and
is exhibited on all our tested devices. Using this technique,
we examine the collected touchscreen emission signal right
before we turn off the IEMI attack and detect if any touch
event was injected in the previous attempt. Our experimental
results show that this approach works every time on our three
main test devices (iPad Pro, iPhone 11 Pro and Oneplus 7
Pro). The touch event detector is implemented as a dedicated
IEMI antenna which connects to an oscilloscope.
0
50
100
150
200
Time (ms)
-5
5 
-5
5 
-5
5 
Voltage (mV)
(c)
(b)
(a)
Fig. 18: Emission signal from iPad Pro (a) reduced scan. (b) failed IEMI
attack. (c) successful IEMI attack.
IX. EVALUATION OF PRACTICAL ATTACKS
A. The Attack Setup
With our antenna array, phone locator and touch event
detector in place as shown in Figure 19, we are ready to
conduct an actual attack that mimics practical scenarios. We
tape our antenna array under the left-bottom corner of an
experimental bench made of MDF with a table thickness of
15mm. A laptop is placed at the left side of the table outside
of the detect/attack range of our antenna array. During the
experiment, we ask ªthe victimº, who has no prior knowledge
of the exact location of our antenna array, to sit in front of
our experimental bench and put our unlocked test target device
facing down. We then use our phone locator to infer the current
position and orientation of our target device, perform the attack
vectors and monitor the injected touch events. Note that we
do not ask ªthe victimº to use their own devices as we may
alter or leak private content of the target device during the
experiments.
B. Attack Evaluation
To evaluate the setup in a practical scenario, we choose three
different touchscreen devices as our target devices: 1) an iPad
Pro 2020; 2) an iPhone 11 Pro; and 3) a Oneplus 7 Pro. These
three devices are pre-installed with our touch event detection
application and remotely mirror their current display onto
another monitor. Note that this application is only installed
to better illustrate the injected touch events during the experi-
ment. Attackers can perform a similar attack without installing
the application ahead-of-time. The test device is unlocked and
Fig. 19: Attack setup for precision evaluation
(a)
(b)
Fig. 20: Attack setup with actual table (a) attack setup on the table (b) antenna