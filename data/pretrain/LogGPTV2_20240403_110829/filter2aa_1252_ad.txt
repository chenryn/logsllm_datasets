### Optimized Text

#### Figure 16: TX Signals on Screens with Different Driving Methods
- **Row 1:**
  - Time (ms): -2, 0, 2, 4
  - Voltage (mV): 0, 1, 2, 3, 4, 5, 6
- **Row 4:**
  - Time (ms): -2, 0, 2, 4
  - Voltage (mV): 0, 1, 2, 3, 4, 5, 6
- **Row 7:**
  - Time (ms): -2, 0, 2, 4
  - Voltage (mV): 0, 1, 2, 3, 4, 5, 6
- **Column 1:**
  - Time (ms): -2, 0, 2, 4
  - Voltage (mV): 0, 1, 2, 3, 4, 5, 6
- **Column 2:**
  - Time (ms): -2, 0, 2, 4
  - Voltage (mV): 0, 1, 2, 3, 4, 5, 6
- **Column 5:**
  - Time (ms): -2, 0, 2, 4
  - Voltage (mV): 0, 1, 2, 3, 4, 5, 6
- **Column 6:**
  - Time (ms): -2, 0, 2, 4
  - Voltage (mV): 0, 1, 2, 3, 4, 5, 6

(a) Sequential driven TX signals

(b) Parallel driven TX signals

Our technique consists of three steps: feature extraction, classifier training, and location prediction. As shown in Fig. 16b, the boundaries between two code bits can be identified, which allows us to segment the signals corresponding to each code bit. For each segment, we compute descriptive features for a code bit, such as phase, magnitude, or frequency, depending on the specific encoding schemes used by the screen. We then derive a feature vector for each TX signal by concatenating these features. Afterward, we train a classifier with a sufficient number of feature vectors and their corresponding location pairs. This classifier can identify the screen location using the signal collected at an unknown location.

We can identify different TX electrodes in different lines using this technique, but we cannot distinguish different locations on the same TX electrode. In other words, for any antenna with a known coordinate \((x_{\text{antenna}}, y_{\text{antenna}})\), we can obtain a single-dimensional screen coordinate, which may be \(x_{\text{screen}}\) or \(y_{\text{screen}}\). To determine the other dimension, we need to know at least one antenna coordinate mapped to the screen boundary to infer the unknown dimension. The screen boundary can be accurately located by identifying significant signal strength degradation between two adjacent antennas. With enough antenna and screen coordinate pairs, we can derive the mapping between them. The mapping between \((x_{\text{screen}}, y_{\text{screen}})\) and \((x_{\text{antenna}}, y_{\text{antenna}})\) can be described as a rotation followed by a translation, as shown in Equation 15, where \(\theta\) represents the rotation and \(x_t\) and \(y_t\) represent the translation. After solving this equation, we can use the transformation matrix to select the closest antenna to inject the error for any target screen location.

\[
\begin{pmatrix}
x_{\text{screen}} \\
y_{\text{screen}} \\
1
\end{pmatrix}
=
\begin{pmatrix}
\cos(\theta) & -\sin(\theta) & x_t \\
\sin(\theta) & \cos(\theta) & y_t \\
0 & 0 & 1
\end{pmatrix}
\begin{pmatrix}
x_{\text{antenna}} \\
y_{\text{antenna}} \\
1
\end{pmatrix}
\]

(15)

To better demonstrate how the screen locator works, we use an iPad Pro as an example. From a TX signal on the iPad Pro, we can obtain a feature vector with 48 feature values using the magnitude of sinusoidal signals in each segment, which is correlated to the row number on the screen. Signals are collected from the bottom row to the top row with a step of 1 cm. On each row, signals are collected at 12 different columns. These signals are used to train a k-nearest neighbors (KNN) classifier. In the evaluations, we first use signals collected from 7 antennas in a small area to detect the location and orientation of the tested iPad Pro. Fig. 17a shows the detection results. The predicted location is very close to the actual location, with a maximum prediction error of 0.8 cm. Furthermore, if we use 5 more antennas to collect signals in a larger area, the prediction result matches perfectly with the actual location.

We tested our screen locator on 5 devices listed in Table IV. We list the driving methods used by these devices, the sample rate we used to collect the data, the average prediction error, and the average computation time. Note that for screens using SDM, the location is computed using the timestamp read from an oscilloscope.

| Device            | Driving Method | Sample Rate  | Error   | Time    |
|-------------------|----------------|--------------|---------|---------|
| Nexus 5X          | SDM            | 50 MSa/s     | 0.42 cm | N/A     |
| Google Pixel 2    | SDM            | 50 MSa/s     | 0.51 cm | N/A     |
| iPhone 11 Pro     | PDM            | 1 MSa/s      | 0.3 cm  | 0.08 s  |
| OnePlus 7 Pro     | PDM            | 2 MSa/s      | 0.06 cm | 0.14 s  |
| iPad Pro          | PDM            | 1 MSa/s      | 0.18 cm | 0.17 s  |

#### C. The Touch Event Detectors
To perform an attack that requires several touch events, it is crucial to know whether the current touch event injection is successful before proceeding to inject the next touch event at a different location. In some cases, the injection of a successful touch event may take more time than expected. As introduced in Section XI, there are multiple techniques to detect the current screen content out of sight. However, these techniques can be challenging to use without significant effort. In our work, instead of detecting if we have altered the screen content as desired, we detect if our last touch event injection was successfully applied to the screen. The key behind such detection is the active scanning mechanism used by modern touchscreen controllers [27]. To balance power efficiency and scanning accuracy, touchscreen controllers perform reduced scanning to preserve power. Once a touch event is detected on the touchscreen, the controller changes the scanning mode from reduced scan to full scan to measure the touched location more accurately. If no more touch events are detected, the controller switches back to reduced scan mode automatically. Although we do not have a datasheet for a commercial touchscreen controller, using our IEMI antenna, we observed similar behavior on all tested touchscreen devices. More importantly, if the touch event is successfully injected on a target device and recognized by the operating system, the touchscreen controller takes a longer time to switch back to reduced scan mode. As shown in Figure 18a, the iPad Pro emits a sparse scanning signal with a 120 Hz frequency when no finger or IEMI signal is present. Figure 18b shows how the touchscreen switches from full scan mode back to reduced scan mode after we turn off our IEMI signal. We can also see that the touchscreen recognizes our IEMI signal as a touch event but eliminates it due to the wrong interference frequency. In Figure 18c, we apply a correct IEMI signal and successfully trigger a touch event on the screen. The time that the controller takes to switch back to reduced scan mode is noticeably longer compared to the previous experiment. This phenomenon is stable and exhibited on all our tested devices. Using this technique, we examine the collected touchscreen emission signal right before we turn off the IEMI attack and detect if any touch event was injected in the previous attempt. Our experimental results show that this approach works every time on our three main test devices (iPad Pro, iPhone 11 Pro, and OnePlus 7 Pro). The touch event detector is implemented as a dedicated IEMI antenna connected to an oscilloscope.

**Figure 18: Emission Signal from iPad Pro**
- (a) Reduced scan
- (b) Failed IEMI attack
- (c) Successful IEMI attack

#### IX. Evaluation of Practical Attacks
**A. The Attack Setup**
With our antenna array, phone locator, and touch event detector in place, as shown in Figure 19, we are ready to conduct an actual attack that mimics practical scenarios. We tape our antenna array under the left-bottom corner of an experimental bench made of MDF with a table thickness of 15 mm. A laptop is placed at the left side of the table outside the detect/attack range of our antenna array. During the experiment, we ask "the victim," who has no prior knowledge of the exact location of our antenna array, to sit in front of our experimental bench and place our unlocked test target device facing down. We then use our phone locator to infer the current position and orientation of our target device, perform the attack vectors, and monitor the injected touch events. Note that we do not ask "the victim" to use their own devices, as we may alter or leak private content of the target device during the experiments.

**B. Attack Evaluation**
To evaluate the setup in a practical scenario, we choose three different touchscreen devices as our target devices: 1) an iPad Pro 2020; 2) an iPhone 11 Pro; and 3) a OnePlus 7 Pro. These three devices are pre-installed with our touch event detection application and remotely mirror their current display onto another monitor. Note that this application is only installed to better illustrate the injected touch events during the experiment. Attackers can perform a similar attack without installing the application ahead of time. The test device is unlocked and placed on the table.

**Figure 19: Attack Setup for Precision Evaluation**
- (a) Attack setup on the table
- (b) Antenna array placement