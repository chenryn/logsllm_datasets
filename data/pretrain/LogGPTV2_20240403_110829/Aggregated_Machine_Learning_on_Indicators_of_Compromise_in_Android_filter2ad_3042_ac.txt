benign and malicious apps allows MAVeRiC to baseline the behaviors of a known malicious 
application. The data for both the benign and malicious apps is collected and run through several 
classification algorithms including  decision trees, support-vector machines, nearest neighbor, and 
Na¨ıve Bayes algorithms. Initially all data is evaluated using MATLAB15® , as it has pre-built 
functions for performing these tests. Each method is evaluated based on its: 
In the case of unsupervised learning model MAVeRiC is utilizing both clustering and anomaly 
detection. The unsupervised learning approach will include k-means clustering, hierarchical 
clustering, and anomaly detection algorithms. In the both the clustering and anomaly detection 
methods the center of the clusters is the value from which all points will be measured. A threshold is 
created, representing the distance from  center point. All points outside of the threshold are identified 
as being potentially malicious. 
In the second approach each IOC is evaluated individually. MAVeRiC analyzes each IOC, 
following the same steps as in the first approach. A feature selection reduction takes place on the 
individual IOC’s, as they may differ than those chosen as a superset in the first approach. Once a set 
of features is selected the data is input into a series of supervised machine learning algorithms in 
order to train the model. 
We expect MAVeRiC’s dynamic analysis approach to show a reduction in both False-Positive 
andFalse-Negatives, when multiple IOC’s are analyzed. Once all the approaches are analyzed we will 
evaluate each based on multiple factors, in order to make a determination on which is best. The 
tradeoff analysis will be based on: accuracy, speed, amount of data to collect, resources utilized on 
Android devices. MAVeRiC will then integrate the selected approach into the framework by 
deploying data collection applications on Android devices and servers to evaluate the data. 
MAVeRiC will also work to develop a method of introducing additional IOCs in the future. We will 
then integrate the selected approach into the framework by deploying data collection applications on 
Android devices and servers to manage the data. MAVeRiC will also work to develop a method of 
introducing additional IOC’s in the future. 
15MATLAB®     is a registered trademark of The MathWorks, Inc. 
15 
16 
This page is intentionally blank. 
5.  CONCLUSION AND FUTUREWORK 
The proliferation of mobile computing platforms, as well as the much-needed applications and 
content to make them useful, continues to accelerate. One of the biggest challenges, as a result of 
this proliferation, are the potential security risks and vulnerabilities that could be found in mobile 
applications. In this paper,  we introduced a new conceptual technology called MAVeRiC, which 
aims at bringing better security solutions to the Android mobile applications arena. Through 
MAVeRiC, we are moving one step closer to providing much more secure platforms and 
applications to users, while ensuring that this security does not  become a road-block. MAVeRiC 
leverages novel approaches in crowd-sourced behavioral analysis and machine learning to take the 
guess work out of determining if an application is malicious or not, and  furthermore, continue to 
monitor it after installation without hindering performance and/or user attention. 
Furthermore, the paper described how the US Navy is moving forward with mobile platforms and 
applications, in order to bring a context to MAVeRiC as well as outline areas of potential future 
collaboration. From the research, to the technological, to the policy perspective, there are multiple 
areas  that while MAVeRiC aims to support in the future, collaborations with industry and academia 
will prove essential to fulfill. 
While the early results described are promising, next steps in MAVeRiC’s development include a 
larger test experiment and demonstration in order to determine scalability issues and usability of 
features to a  larger user audience. In addition, much more diverse malware suite, including both 
legacy and current  threats, will be used. 
18 
This page is intentionally blank.  
REFERENCES 
1.  Kernel space. Available at http://www.linfo.org/kernel_space.html (05 April, 2018),  2005. 
2.  Skygofree — a hollywood-style mobile spy. Available at 
https://www.kaspersky.com/blog/skygofree-smart-trojan/20717/ (06 April,  2018), 2018. 
3.  T. Bower. 1.12. system calls — operating systems study guide. Available at  
http://faculty.salina.k-state.edu/tim/ossg/Introduction/sys_calls.html (05  April, 2018), 2015. 
4.  I. Burguera, U. Zurutuza, and S. Nadjm-Tehrani. Crowdroid: behavior-based malware 
detection  system for android. In Proceedings of the 1st ACM workshop on Security and 
privacy in  smartphones and mobile devices, pages 15–26. ACM, 2011. 
5.  G. Canfora, E. Medvet, F. Mercaldo, and C. A. Visaggio. Detecting android malware using 
sequences  of system calls. In Proceedings of the 3rd International Workshop on Software 
Development  Lifecycle for Mobile, pages 13–20. ACM, 2015. 
6.  L. Caviglione, M. Gaggero, J.-F. Lalande, W. Mazurczyk, and M. Urban´ski. Seeing the unseen: 
revealing mobile malware hidden communications via energy consumption and artificial 
intelligence.  IEEE Transactions on Information Forensics and Security, 11(4):799–810, 2016. 
7.  D. Dasgupta, A. Roy, and D. Ghosh. Multi-user permission strategy to access sensitive 
information. Information Sciences, 423:24–49, 2018. 
8.  T. Fox-Brewster. Google is fighting a massive android malware outbreak — up to 21 million 
victims, 2017. 
9.  A. Ghosh, P. K. Gajar, and S. Rai. Bring your own device (byod): Security risks and 
mitigating  strategies. International Journal of Global Research in Computer Science (UGC 
Approved  Journal), 4(4):62–70, 2013. 
10.  K. Giotopoulos, C. Halkiopoulos, D. Papadopoulos, and H. Antonopoulou. Adoption of bring 
your  own device (byod) policy in marketing. In 5 th International Conference on 
Contemporary  Marketing Issues ICCMI June 21-23, 2017 Thessaloniki, Greece, page 342, 
2017. 
11.  R. A. Hallman and M. Kline. Risk metrics for android (trademark) devices. Technical report, 
Space  and Naval Warfare Systems Center Pacific San Diego United States, 2017. 
12.  J. Hsu. The strava heat map and the end of secrets. Available at https://www.wired.com/ 
story/strava-heat-map-military-bases-fitness-trackers-privacy/(19 April, 2018), 2018. 
13.  U. Kanonov and A. Wool. Secure containers in android: the samsung knox case study. In 
Proceedings of the 6th Workshop on Security and Privacy in Smartphones and Mobile 
Devices, pages 3–12. ACM, 2016. 
14.  T. B. Lee. Facebook’s cambridge analytica scandal, explained. Available at 
https://arstechnica.com/tech-policy/2018/03/facebooks-cambridge-analytica-scandal-explained/ 
(19 April, 2018), 2018. 
15.  H.-Y. Lock and A. Kliarsky. Using ioc (indicators of compromise) in malware 
forensics. SANS Institute InfoSec Reading Room, 2013. 
16.  L. Onwuzurike, M. Almeida, E. Mariconti, J. Blackburn, G. Stringhini, and E. De Cristofaro. 
A family  of droids: Analyzing behavioral model based android malware detection via static 
and dynamic  analysis. arXiv preprint arXiv:1803.03448, 2018. 
17.  J. Perkins and M. Gordon. Droidsafe. Technical report, Massachusetts Institute of 
Technology  Cambridge United States, 2016. 
18.  F. Portela, A. M. da Veiga, and M. F. Santos. Benefits of bring your own device in healthcare. In 
Next-Generation Mobile and Pervasive Healthcare Solutions, pages 32–45. IGI Global, 2018. 
19.  E. Root, A. Polkovnichenko, and B. Melnykov. Expensivewall: A dangerous ‘packed 
malware on  google play that will hit your wallet. Available at 
https://blog.checkpoint.com/2017/09/14/expensivewall-dangerous-packed-malware-
google-play-will-hit-wallet/ (07 April, 2018), 2017. 
20.  A. Shabtai, L. Tenenboim-Chekina, D. Mimran, L. Rokach, B. Shapira, and Y. Elovici. 
Mobile  malware detection through analysis of deviations in application network 
behavior. Computers &  Security, 43:1–18, 2014. 
21.  R. S. Shaji, V. S. Dev, and T. Brindha. A methodological review on attack and defense 
strategies in  cyber warfare. Wireless Networks, pages 1–12, 2018. 
22.  Y. Song and S. C. Kong. Affordances and constraints of byod (bring your own device) for 
learning and  teaching in higher education: Teachers’ perspectives. The Internet and Higher 
Education,  32:39–46, 2017. 
23.  M. Souppaya and K. Scarfone. Users guide to telework and bring your own device (byod) 
security. NIST Special Publication, 800:114, 2016. 
24.  A. Studio. Android debug bridge (adb). Available at 
https://developer.android.com/studio/command-line/adb.html (23 April,  2018), 2018. 
25. A. Studio. Ui/application exerciser monkey. Available at 
https://developer.android.com/studio/test/monkey.html (23 April, 2018), 2018. 
26.  Unified Compliance Framework, 244 Lafayette Circle, Lafayette, CA 94549. Mobile 
Application  Security Requirements Guide, 2014. 
27.  R. Vallee-Rai and L. J. Hendren. Jimple: Simplifying java bytecode for analyses and 
transformations. 1998. 
28.  M. Viveros. The pros and cons of ’bring your own device’. Available at 
https://www.forbes.com/sites/ciocentral/2011/11/16/the-pros-and-cons-of-bring-your-
own-device/\#2a0acb662abe (20 April,  2018), 2011. 
29.  L.-K. Yan and H. Yin. Droidscope: Seamlessly reconstructing the os and dalvik semantic 
views for  dynamic android malware analysis. In USENIX security symposium, pages 569–
584, 2012. 
INITIAL DISTRIBUTION 
84300 
85300 
58230 
58230 
58230 
58230 
58230 
58230 
58230 
Library 
Archive/Stock 
J. San Miguel  
M. Kline 
R. Hallman 
J. Phan 
S. Slayback 
C. Weeden 
J. Robero-Mariona 
Defense Technical Information Center 
Fort Belvoir, VA 22060–6218 
(1) 
(1) 
(1) 
(1) 
(1) 
(1) 
(1) 
(1) 
(1) 
(1) 
This page is intentionally blank.
REPORT DOCUMENTATION PAGE 
Form Approved 
OMB No. 0704-01-0188 
The public reporting burden for this collection of information is estimated to average 1 hour per response, including the time for reviewing instructions, searching existing data sources, gathering and 
maintaining the data needed, and completing and reviewing the collection of information. Send comments regarding this burden estimate or any other aspect of this collection of information, including 
suggestions for reducing the burden to Department of Defense, Washington Headquarters Services Directorate for Information Operations and Reports (0704-0188), 1215 Jefferson Davis Highway, 
Suite 1204, Arlington VA 22202-4302. Respondents should be aware that notwithstanding any other provision of law, no person shall be subject to any penalty for failing to comply with a collection of 
information if it does not display a currently valid OMB control number. 
PLEASE DO NOT RETURN YOUR FORM TO THE ABOVE ADDRESS. 
1. REPORT DATE  (DD-MM-YYYY) 
3.  DATES COVERED  (From - To) 
2.  REPORT TYPE 
July 2019 
4. TITLE AND SUBTITLE 
Final 
Aggregated Machine Learning on  
Indicators of Compromise 
6. AUTHORS 
John M. San Miguel 
Megan E.M. Kline 
Roger A. Hallman 
Johnny Phan 
Scott M. Slayback 
Christopher M. Weeden  
Jose V. Romero-Mariona 
NIWC Pacific 
7. PERFORMING ORGANIZATION NAME(S) AND ADDRESS(ES) 
NIWC Pacific 
53560 Hull Street  
San Diego, CA 92152–5001 
5a. CONTRACT NUMBER 
5b. GRANT NUMBER 
5c. PROGRAM ELEMENT NUMBER 
5d. PROJECT NUMBER 
5e. TASK NUMBER 
5f. WORK UNIT NUMBER 
8. PERFORMING ORGANIZATION  
    REPORT NUMBER 
TD 3390 
9. SPONSORING/MONITORING AGENCY NAME(S) AND ADDRESS(ES) 
10. SPONSOR/MONITOR’S ACRONYM(S) 
Naval Innovative Science and Engineering (NISE) Program (Applied Research) 
NIWC Pacific 
53560 Hull Street 
San Diego, CA 92152–5001 
12. DISTRIBUTION/AVAILABILITY STATEMENT 
NISE 
11. SPONSOR/MONITOR’S REPORT 
      NUMBER(S) 
Distribution Statement A: Approved for public release; distribution is unlimited. 
13. SUPPLEMENTARY NOTES 
This is work of the United States Government and therefore is not copyrighted. This work may be copied and disseminated 
without restriction.  
14. ABSTRACT 
The increasing ubiquity of mobile computing technology has lead to new trends in many different sectors. “Bring Your Own Device” is one 
such growing trend in the workplace, because it allows enterprise organizations to benefit from the power of distributed computing and 
communications equipment that their employees have already purchased. Unfortunately, the integration of a diverse set of mobile devices (e.g., 
smart phones, tablets, etc.) presents enterprise systems with new challenges, including new attack vectors for malware. Malware mitigation for 
mobile technology is a long-standing problem for which there is not yet a good solution. In this paper, we focus on identifying malicious 
applications, and verifying the absence of malicious or vulnerable code in applications that the enterprises and their users seek to utilize. Our 
analysis toolbox includes static analysis and permissions risk scoring, pre-installation vetting techniques designed to insure that malware is never 
installed in devices on an enterprise network. However, dynamic code-loading techniques and changing security requirements mean that apps 
which previously passed the verification process, and have been installed on devices, may no longer meet security standards, and may be 
malicious. To identify these apps, and prevent future installation of them, we propose a crowd-sourced behavioral analysis technique, using 
machine learning to identify malicious activity through anomalies in system calls, network behavior, and power consumption. These techniques 
apply effectively to single user devices over time, and to individual devices within an enterprise network. 
15. SUBJECT TERMS 
MAVeRiC approach to dynamic analysis for mobile-android; application security; MAVeRiC; 
16. SECURITY CLASSIFICATION OF: 
a. REPORT 
b. ABSTRACT  c. THIS PAGE 
17. LIMITATION OF 
     ABSTRACT 
U 
U 
U 
U 
18. NUMBER 
     OF 
     PAGES 
32 
19a. NAME OF RESPONSIBLE PERSON 
Rogert A. Hallman 
19B. TELEPHONE NUMBER  (Include area code) 
1 619-553-7905 
Standard Form 298 (Rev. 10/17) 
Prescribed by ANSI Std. Z39.18 
This page is intentionally blank. 
This page is intentionally blank. 
Distribution Statement A: Approved for public release; distribution is unlimited. 
NIWC Pacific 
San Diego, CA 92152-5001