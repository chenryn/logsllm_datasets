completely, then the entire plan fails, and the agent will try some other means
of achieving his goal, instead of boarding the train with no ticket.5
3.4 Future Enhancements
There are a number of issues in attacker modeling that we did not handle in this
ﬁrst version of our simulator. The ﬁrst is that we allow only a single attacker.
This is not as great a limitation as it sounds, since we do allow multiple sites
of attack. So our current framework is adequate to model multiple, coordinated
attackers. However, for future applications, multiple attackers should be added.
Such models are necessary to allow researchers to experiment with techniques
for attributing attacks to multiple diﬀerent attackers and with disentangling
the concurrent activities of truly threatening attackers from the background
activities of “ankle-biters.”
We also skirted the issue of the duration of actions. The concurrency se-
mantics we use is strictly a matter of interleaving and no attempt is made to
distinguish between actions that consume diﬀerent amounts of time. There is
5 Assuming it is impossible to purchase a ticket on the train.
210
R.P. Goldman
Fig. 3. Pseudo-code deﬁnition of achieve goal. G is an “in” parameter, the goal expres-
sion. S is an “out” parameter, a Boolean value indicating success or failure in achieving
the goal.
already a treatment of actions with variable durations for the situation calcu-
lus, together with a corresponding Golog interpreter [23, Chapter 7]. There-
fore, adding temporally-extended actions will not add any theoretical diﬃculty.
However, it will add substantial complication to the modeling and knowledge-
engineering process for the simulator. We simply do not have good estimates
of the durations of the various actions and processes, and these durations bear
complex relations to the state of the environment (e.g., network and host load).
Nevertheless, if we are to incorporate features like (authorized) background traf-
ﬁc models, we will have to address this issue.
The current system has only deterministic actions. For example, the exploits
will always work if and only if they are executed against a vulnerable target.
Note that even though the actions are deterministic, the simulated attacker is
not. The attacker’s choice of plans, exploits and targets, and its reaction to
failures are all stochastic phenomena, lending a great deal of variance to even
simple scenarios.
Even so, limiting ourselves to deterministic actions is obviously a substan-
tial oversimpliﬁcation. Therefore we must incorporate actions that succeed only
with a certain probability. The formal framework for stochastic actions already
exists [2]. As with action durations, the primary diﬃculty is the challenge of
knowledge acquisition.
Most of the systems for working with the situation calculus and golog as-
sume a ﬁnite domain of entities. The ﬁnite domain is necessary for the practical
inference methods to succeed (cf.
[23, Chapter 9], [8]). This limitation is not at
A Stochastic Model for Intrusions
211
all appropriate to modeling computer intrusion situations. Modeling interactions
with software entities require us to be able to model the construction and (to
a lesser extent) destruction of entities. For example, if we wish to talk about
login sessions, we must be able to talk about their creation by the act of logging
in to a host. One solution would be to create ab initio a ﬁxed pool of potential
sessions, and talk about them being actually there or not [18]. This solution
poses two problems. First, it commits us to a ﬁxed pool, and our simulator will
fail if we guess wrong and overﬂow the preallocated pool. Second, it means that
we will often ﬁnd ourselves quantifying over unnecessarily large domains. For
the moment, we have programmed ourselves out of this problem by restricting
the cases where open domain entities can appear and by making sure we do not
make inappropriate queries about those entities. This is an unsatisfactory state
of aﬀairs, however, and calls for some further technical work. There has been
some preliminary work in the area of “softbots” [6], on exploiting local closed
world knowledge [7]. This is related, but limited to trying to provide intelligent
agents enough knowledge about action eﬀects to predict whether they can act
successfully, not to handle projection for simulation.
The current system has a patchy treatment of agents’ knowledge and be-
liefs. We have put in special-purpose ﬂuents to track the attacker’s knowledge
of key facts like the identity of hosts and user passwords. However, we have not
extended this to a full knowledge model for the attackers. As with stochastic ac-
tions and actions with variable durations, there is already some available theory
for such a model [25], [23, Chapter 11]. However, the current solutions are not
acceptable for our purposes. The problem is that the existing solutions assume
that agents will diﬀer only in their knowledge of the state of the world. They
must agree on the physics of the world — particularly on how all the actions will
aﬀect the state of the world. This is simply not appropriate for simulating com-
puter attackers. Typical attackers — especially the “script kiddies” — will shape
their attacks to the particular tools that they have. Furthermore, one can often
determine useful things about an attacker based on ill-chosen actions. For exam-
ple, one sometimes sees a script kiddie gain access to a Unix host, and attempt
to execute Windows commands there. This is an area for further research.
A ﬁnal area for work is less theoretically interesting, but perhaps the most im-
portant. This is the creation of better tools to work with our attacker simulation
tool. There are two most critical needs. The ﬁrst is for some compile-time and
run-time validation of model components. The indigolog interpreter is written
in Prolog. This is desirable for many reasons, most notably because it permits
a direct implementation of the semantics of the language. On the other hand,
it means that we have a very crude compilation environment with very poor
detection of ill-formed actions or tests. The system badly needs some form of
type-checking or other veriﬁcation. Currently all of these errors must be detected
by the programmer using the debugger. This debugger should also be improved.
Currently, one must use the Prolog debugger, which plunges the programmer
into the details of the interpreter’s implementation. It would be better to build
a special-purpose debugger for the simulator application, that would focus on
the golog semantics and suppress the details of their Prolog implementation.
212
R.P. Goldman
Finally, we have made a number of extensions to the syntax of the language to
make it easier to write. However, further work could certainly be done in this
area.
4 Modeling the Cyber Attack Domain
In this section, we discuss how we model cyber attack domains using our tool.
After that, we present a speciﬁc example, the “Frostbite Falls” scenario. We
then describe a simulated attack, generated by our simulator. This attack will
show how the simulated attacker can use multiple alternative plans and exploits,
to achieve its end. We will see that the attacker adapts to the outcomes, both
success and failure, of earlier actions.
Our modeling of cyber attack domains has been somewhat ad hoc, but our
modeling has a clear rationale, and our modeling decisions should be understood
in the light of this rationale. The ﬁrst component to this rationale is that cyber
attack modeling is being done in order to support more cost-eﬀective intrusion
research. The second component is that we are interested in studying the way
intelligent systems can combine reports from multiple sensors into an overall
situation assessment.
The purpose of the cyber attack modeling tool is to allow more cost-eﬀective
intrusion research, with repeatable tests. We are particularly interested here in
extended attack scenarios: not just the isolated deployment of a given exploit.
There are three obstacles we’d like to overcome. The ﬁrst is the cost of testing an
intrusion scenario. Doing so involves building a test network, and then restoring
the network’s state after any destructive modiﬁcations by the attacker. The
second obstacle is the requirement to have expert humans involved in performing
the intrusions we would like to study. The ﬁnal obstacle is the sheer time cost
of exploring multiple variations of a single attack plan. It’s common for red
teams to develop attack trees that contain many ways of attacking a particular
network. But it is very diﬃcult to explore these at all thoroughly because of the
time needed and the requirement for direct human involvement.
We are not interested in the detailed modeling of individual events. Instead,
we are interested in the way a number of diﬀerent sensors will report on the
same events. We are particularly interested in how those reports can be fused
together in ways that exploit background knowledge.
Our purposes in this project, then, dictate a relatively abstract level of mod-
eling. For example, we have avoided modeling the details of network traﬃc and
network protocols. We have also avoided modeling the details of the ﬁle systems
of the computers that are attacked. The primary consideration in this abstrac-
tion has been to develop a simulation that can be run far more quickly than
a true version of the attacks. Compare this to network simulations intended to
assess the performance of various network protocols, which typically run at only
some fraction of the protocol itself. Further, since we are interested in what at-
tacks will look like through the eyes of sensors, rather than experimenting with
sensor designs, we avoid modeling the exact phenomena that will cause sensors
A Stochastic Model for Intrusions
213
Fig. 4. Frostbite Falls network topology.
to trigger. Of necessity, this will cause some inaccuracies, but we feel the price
we pay is worthwhile, at least for this application.
4.1 The Frostbite Falls Scenario
The Frostbite Falls scenario concerns the attack made by a cracker, whom we’ll
call b0r15, on a network that contains an Oracle database (see Figure 4). b0r15
wants to gain access to the Oracle database (on the host fellini) order to cor-
rupt its contents. However, initially b0r15 only knows the IP address of Frostbite
Falls’ DNS server, he does not know that fellini is the target. Further, b0r15
does not know any exploit that will directly allow him access to fellini; he
will have to gain access indirectly, through another host on the defended net-
work. This means that the attack will go through all of the classic cycles of
reconnaissance, initial foothold, and exploitation and consolidation.
4.2 Attacking Frostbite Falls
The easiest way to use the cyber attack modeling tool is to experiment to with
our Frostbite Falls scenario model and the attached KAs and primitive actions.
Table 3 shows our hacker, b0r15 trying to gain access to the Frostbite Falls
Oracle database in order to insert phony orders.
The transcript in Table 3 was generated by a top-level plan that has three
steps:
214
R.P. Goldman
Table 3. Sample transcript from the Frostbite Falls scenario. Lines preceded by arrows
indicate goal achievement.
1. prepare to attack (this is primarily concerned with getting b0r15 logged into
a workstation he owns so that he can attack);
2. conduct reconnaissance;
3. get access to the oracle database, wherever it is.
The Golog code was as follows:
begin
end
(πsess)start work(sess);
b0ri5 recon;
(πoh)?(known service(oh, oracle); achieve goal(access(oracle, oh)));
A Stochastic Model for Intrusions
215
In Table 3 we see b0r15 ﬁrst login to his own workstation (lines 1-2). Then he
conducts his reconnaissance (3-12). He ﬁrst tries a zone transfer from the DNS
server of the network, then does an IP sweep. Finally, he does portsweeps to see
what services are being run on the individual hosts. b0r15 is not stealthy!
b0r15 has a number of possible means of attack on the Oracle host. In this
transcript he has chosen to attack by attempting to sniﬀ Oracle passwords out
of network traﬃc. This plan requires him ﬁrst to achieve root privilege on some
other host on the network. With root privilege, he can install the sniﬀer and
then log into the oracle host.
b0r15 chooses kubrick as his stepping-stone on the way to attacking
fellini. Recall that his plan calls for him to gain root access to kubrick as a
means to install a sniﬀer. To gain root access, b0r15 chooses to gain local user
level access to kubrick and then escalate his privilege (he could also have tried a
more direct remote-to-root attack). b0r15 ﬁrst tries a simple rlogin to kubrick,
on the oﬀ-chance that the rlogin services have been left unsecured (13). Note
that b0r15 tries this twice (13-14); the simulator provides for the possibility of
persistence.
After two tries, b0r15 gives up on trying to get through an unguarded rlogin,
and adopts session hijacking as an alternative. kubrick trusts lucas for the
purposes of rlogin. b0r15 chooses the “neptune” denial of service attack from
the set of alternatives, and brings down lucas’s TCP stack (15-16), allowing
him to impersonate a legitimate user, and set up an rhosts ﬁle on kubrick (17).
Now that he has user-level access, b0r15 moves on to the goal of being
root_privileged_on kubrick. He ﬁrst tries the dtappgather exploit, mistak-
enly, since kubrick is not vulnerable to it (20-23). Note that in order to try this
exploit he ﬁrst transfers the the exploit code to kubrick via ftp (20). b0r15 gives
up on dtappgather after trying it twice, and seizes on the sadmindex exploit.
This time, instead of ftping the exploit, he decides to use email (24) to achieve
the goal of available(sadmindex) (25).
With root-privilege secured, b0r15 transfers a sniﬀer onto kubrick (29-30).
He does this using “magic_transfer (29), an action which is meant to stand
in for any kind of covert channel the defenders have not yet seen. Thus, to the
defenders this channel is, eﬀectively “magic.” Note that the addition of “magic”
actions like this allow us to experiment with situations where we confront attack-
ers with exploits not previously known to us. With the sniﬀer installed, b0r15
can get the password to Oracle user accounts, so he has achieved his goal of
access(oracle,fellini), and is done (32).
5 Related Work
We have already mentioned some of the most directly relevant work on attack
modeling. Both Cuppens and Ortalo [4] and Templeton and Levitt [29] have de-
veloped modeling langauges based on actions with preconditions and postcondi-
tions. One of our contributions is to marry precondition/postcondition intrusion
modeling with the situation calculus, which provides a rich and sound semantics.
216
R.P. Goldman
At least two groups have used model-checking techniques and attack models
to assess network vulnerabilities [24,28]. This work is similar to ours in projecting
the eﬀects of action sequences. There are two important diﬀerences. First, the
syntax and semantics provided by the model checkers’ temporal logics are less
expressively powerful and modular than the situation calculus. Second, these
researchers are not interested in naturalistic modeling of computer attackers.
Their interest lies in identifying network vulnerabilities, for which it is suﬃcient
to consider the worst case attack, computed by the model-checkers’ exploration
of the attack space. We are interested in modeling the full situation, for which
we must consider not only the most competent attacker, but the full range of
phenomena. These two objectives are complementary, rather than conﬂicting,
and it would be interesting to see whether the diﬀerent eﬀorts could beneﬁt
from each others’ modeling eﬀorts.
6 Conclusions
We have described a comprehensive approach to computer network attack simu-
lation. Computer security researchers need such simulations in order to carry out
large-scale, repeatable experiments in computer security. The situation calculus
and the Golog situation calculus programming language, suitably extended, can
provide a theoretical and practical basis for such simulations. We have provided
a number of Golog extensions, most notably goal-directed procedure invocation,
to better model cyber attackers. Our prototype simulator can simulate a single
attacker, who is able to synthesize full network attacks from a library of plans
and primitive actions, reacting to successes and failures it encounters.
Acknowledgements. Thanks to Maurice Pagnucco for much assistance work-
ing with Indigolog and to Maurice, Hector Levesque, and the University of
Toronto for providing the Indigolog interpreter. Thanks to Keith Golden for
helpful comments based on his experience with softbot planning. Thanks to the
Argus/Scyllarus team, and Dick Kemmerer and Giovanni Vigna for the Frost-
bite Falls scenario. This material is based upon work supported by DARPA/ITO
and the Air Force Research Laboratory under Contract No. F30602-99-C-0017.
The work described here was done while the author was employed at Honeywell
Laboratories.
References
[1] American Association for Artiﬁcial Intelligence, Proceedings of the Seventeenth
National Conference on Artiﬁcial Intelligence, Menlo Park, CA, July 2000. AAAI
Press/MIT Press.
[2] C. Boutilier, R. Reiter, M. Soutchanski, and S. Thrun, “Decision-theoretic, High-
level Agent Programming in the Situation Calculus,”, in Proceedings of the Sev-
enteenth National Conference on Artiﬁcial Intelligence [1], pp. 355–362.
A Stochastic Model for Intrusions
217
[3] M. E. Bratman, “What is Intention?,” in Intentions in Communication, P. Cohen,
J. Morgan, and M. Pollack, editors, chapter 2, pp. 15–31, MIT Press, Cambridge,
MA, 1990.
[4] F. Cuppens and R. Ortalo, “LAMBDA: A Language to Model a Database for
Detection of Attacks,” in RAID, H. Debar, L. M´e, and S. F. Wu, editors, volume
1907 of Lecture Notes in Computer Science, pp. 197–216. Springer, 2000.
[5] DARPA and the IEEE Computer Society, DARPA Information Survivability Con-
ference and Exposition(DISCEX-2001), 2001.
[6] O. Etzioni, “Intelligence without Robots: A Reply to Brooks,” AI Magazine, vol.
14, no. 4, pp. 7–13, 1993.
[7] O. Etzioni, K. Golden, and D. Weld, “Tractable Closed World Reasoning with
Updates,” in Principles of Knowledge Representation and Reasoning:Proceedings
of the Fourth International Conference, J. Doyle, E. Sandewall, and P. Torasso,
editors, pp. 178–189. Morgan Kaufmann Publishers, Inc., 1994.
[8] A. Finzi, F. Pirri, and R. Reiter, “Open World Planning in the Situation Calcu-
lus,”, in Proceedings of the Seventeenth National Conference on Artiﬁcial Intelli-
gence [1], pp. 754–760.
[9] R. J. Firby, “An Investigation in Reactive Planning in Complex Domains,” in
Proceedings of the Sixth National Conference on Artiﬁcial Intelligence, pp. 196–
201. AAAI, Morgan Kaufmann Publishers, Inc., 1987.
[10] C. W. Geib and R. P. Goldman, “Plan recognition in intrusion de-
in DARPA Information Survivability Conference and
tection systems,”,
Exposition(DISCEX-2001) [5], pp. 46–55.
[11] M. Georgeﬀ and A. Lansky, “Procedural Knowledge,” Proceedings of the IEEE,
Special Issue on Knowledge Representation, vol. 74, pp. 1383–1398, October 1986.
[12] M. P. Georgeﬀ and F. F. Ingrand, “Real-Time Reasoning: The Monitoring and
Control of Spacecraft Systems,” in Proceedings of the Sixth Conference on Artiﬁ-
cial Intelligence Application, pp. 198–204, 1990.