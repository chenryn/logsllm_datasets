neuron with F1 Score of ≈97.50%.
After we experiments with different models, the result we ob-
tained is shown in Table 1. We reach to an F1 score of ≈98.13% by
using normal Artificial Neural Network (ANN).
2.3 KDD Variation Datasets Experiments
KDD cup 1999 dataset is one of the most known datasets for NIDS.
Different variations created based on this dataset because of re-
ported problem [5][4]. We will use NSL-KDD and gureKDD datasets.
NSL-KDD is a refined version of KDD [13]. The gureKDD dataset
is generated from a scratch with the same purpose of KDD [6].
Many studies were done by using NSL-KDD dataset. For example,
this paper [7] reported an accuracy of 99% for both binary and
multiclass classification by using SVM. This paper [8] reached 99.6%
with K-NN. This paper [14] reported an accuracy of 97.09% by using
a recurrent neural network (RNN).
After we experiment with different models, the result we ob-
tained is shown in Table 1. For binary classification of both NSL-
KDD and gureKDD, most the models give ≈99% of the F1 score. We
also show that this result can be obtained for the multiclass prob-
lem. To demonstrate that, we used 40 classes of different attacks
including normal traffic label. The result is shown in table 1. You
can notice that the result are around ≈98%-99%.
As you can notice from Table 1, our result matches the current
reported results or, sometimes, exceeded them by using the same
evaluation strategy.
3 A DIFFERENT EVALUATION STRATEGY
As we can see from the from previous, we can reach high accuracy
results. Many models created reach to 99% accuracy. Based on the
current way to assess the NIDS model, does it mean that we can
stop here and used the learned model in NIDS? Does the model
we created represent attack understanding learning? Or is it just
an over-fitting based on the dataset which represents a certain
type of computer network with a particular setting? In order to
address these questions, we propose another evaluation strategy.
We propose to use two different datasets that have the same domain
but a different distribution of traffic. Both of them should share
a same purpose and features, but generated from two different
computer networks. In this way, we will make sure that the model
not learning just the distribution of traffic in the network, but should
generalized the understating of the thing we want to find. In our
problem, we want to learn the abstract behaviour of the attack that
allows us to find the attack in a different network or find a new
zero-day attack with the same understanding.
3.1 Methodology
We will use NSL-KDD and gureKDD. Both datasets represent dif-
ferent computer networks, which will give us different distribution
in the traffic and the same set of features. Also, both datasets are
available for public download. The training will be done in one
dataset and the testing in the other, and vice versa. We take one
dataset as a whole in the training and another as a whole in the
testing. We will follow the same process as before where will use
traditional machine learning and different deep learning models.
The problem will be binary, but the idea can be applied to multiclass
problems as well. The importance of F1 score will show in the result.
So, consider only F1 score as a performance indicator.
Poster PresentationCCS’18, October 15-19, 2018, Toronto, ON, Canada2196Table 2: New Evaluation Strategy - NSL-KDD(training),
gureKDD(testing)
Algorithm
Random Forest
ANN
LSTM
Accuracy
97.65%
80.85%
87.21%
F1 Score
36.08%
9.59%
17.5%
Table 3: New Evaluation Strategy - gureKDD(training), NSL-
KDD(testing)
Algorithm
Random Forest
ANN
LSTM
Accuracy
52.71%
52.16%
52.78%
F1 Score
3.62%
5.19%
7.40%
3.2 Results And Discussion
During the training of the model, all of them reach the accuracy
of ≈99%. But we will only report the accuracy during the testing
phase. Table 2 shows the result when NSL-KDD used for training
and gureKDD used for testing. Table 3 shows the result when we
use gureKDD for training and NSL-KDD for testing.
As you can notice from the result obtained, all models give a very
low F1 score. From the current way to evaluate the performance,
the model is perfect. But when we test it with a different network,
the results are just random guesses. It means that the model didn’t
carry out the real learning of intrusions. This way to measure the
performance of NIDS models will not only benefit the way we
create our model but also about the datasets that we have and the
way we created them. From this angle, the datasets should have
those qualities. It should represent attack/malicious understanding
learning and can adapt to the change in the network traffic. The
general way to use the method is to train in certain dataset and test
in another dataset that has been generated from different network
traffic. But we can also go for more specific scenarios to evaluate
based on this method as follows:
• When we have two datasets that have the same type of
attacks. We want to evaluate if we can find all the attacks or
not. This similar to the problem that we demonstrate before.
• When we have a categories of attack shared and we want to
evaluate the goodness of finding each category of attack.
• Evaluate the quality of the datasets. A high-quality dataset
should facilitate the good learnability of intrusion that can
be transferred to different datasets.
• Evaluating the finding of zero-day attack. Can the model
created in one dataset detect unseen attack from another
dataset?
• Multiple dataset learning: we can also make the model train
from multiple datasets and test in one or more datasets.
We should avoid train and test our model from traffic or infor-
mation on the same computer network. Even if they have differ-
ent names. For example, we cannot train in NSL-KDD and test in
KDD99. Because they are basically the same dataset. If your result
is below 50% of the F1 score, this means your model can not adapt
to the new dataset. If above 50%, it means that your model starts to
learn something about the intrusion.
4 CONCLUSIONS
For a long time, we treated the problem of network intrusion detec-
tion system (NIDS) without the concern with the practicality of the
result in the real world. The researches are done in such a way we
train and test our model in the same dataset and just calculate the
accuracy. But, we argue that this way of thinking is not practical.
So, we spent the first section where we use different datasets with
different models. We showed that it’s not difficult to reach to very
high accuracy. It’s just required some hyperparameters tunning,
which lead up to 99% accuracy. But we argue that those results do
not represent the actual world. So, we spent out the second part
to use another evaluation strategy to measure the performance of
the model. We set up the experiments where the training is done
in one dataset and tested in another dataset and vice versa. And
the result shows that all models perform bad, with less than 40% F1
score and most of them less than 10%. This paper is a call to rethink
the current way to measure the quality of the models and datasets
we have in NIDS.
REFERENCES
[1] Abien Fred M Agarap. 2018. A Neural Network Architecture Combining Gated
Recurrent Unit (GRU) and Support Vector Machine (SVM) for Intrusion Detection
in Network Traffic Data. In Proceedings of the 2018 10th International Conference
on Machine Learning and Computing. ACM, 26–30.
[2] Kaspersky Lab. 2017. Number of the Year: 360,000 Malicious Files Detected Daily
in 2017. (2017).
[3] McAfee Lab. 2017. Threat Report. (2017).
[4] Matthew V Mahoney and Philip K Chan. 2003. An analysis of the 1999
DARPA/Lincoln Laboratory evaluation data for network anomaly detection.
In International Workshop on Recent Advances in Intrusion Detection. Springer,
220–237.
[5] John McHugh. 2000. Testing intrusion detection systems: a critique of the 1998
and 1999 darpa intrusion detection system evaluations as performed by lincoln
laboratory. ACM Transactions on Information and System Security (TISSEC) 3, 4
(2000), 262–294.
[6] Iñigo Perona, Ibai Gurrutxaga, Olatz Arbelaitz, José I Martín, Javier Muguerza,
and Jesús Ma Pérez. 2008. Service-independent payload analysis to improve
intrusion detection in network traffic. In Proceedings of the 7th Australasian Data
Mining Conference-Volume 87. Australian Computer Society, Inc., 171–178.
[7] Muhammad Shakil Pervez and Dewan Md Farid. 2014. Feature selection and
intrusion classification in NSL-KDD cup 99 dataset employing SVMs. In Soft-
ware, Knowledge, Information Management and Applications (SKIMA), 2014 8th
International Conference on. IEEE, 1–6.
[8] B Basaveswara Rao and K Swathi. 2017. Fast kNN Classifiers for Network
Indian Journal of Science and Technology 10, 14
Intrusion Detection System.
(2017).
[9] Raman Singh, Harish Kumar, and RK Singla. 2015. An intrusion detection system
using network traffic profiling and online sequential extreme learning machine.
Expert Systems with Applications 42, 22 (2015), 8609–8624.
[10] Jungsuk Song, Hiroki Takakura, and Yasuo Okabe. 2006. Description of
kyoto university benchmark data. Available at link: http://www. takakura.
com/Kyoto_data/BenchmarkData-Description-v5. pdf [Accessed on 15 March 2016]
(2006).
[11] Jungsuk Song, Hiroki Takakura, Yasuo Okabe, Masashi Eto, Daisuke Inoue, and
Koji Nakao. 2011. Statistical analysis of honeypot data and building of Kyoto
2006+ dataset for NIDS evaluation. In Proceedings of the First Workshop on Building
Analysis Datasets and Gathering Experience Returns for Security. ACM, 29–36.
[12] Symantec. 2017. Internet Security Threat Report. (2017).
[13] Mahbod Tavallaee, Ebrahim Bagheri, Wei Lu, and Ali A Ghorbani. 2009. A
detailed analysis of the KDD CUP 99 data set. In Computational Intelligence for
Security and Defense Applications, 2009. CISDA 2009. IEEE Symposium on. IEEE,
1–6.
[14] Chuanlong Yin, Yuefei Zhu, Jinlong Fei, and Xinzheng He. 2017. A deep learning
approach for intrusion detection using recurrent neural networks. IEEE Access 5
(2017), 21954–21961.
Poster PresentationCCS’18, October 15-19, 2018, Toronto, ON, Canada2197