state, the player continues to ﬁll its buﬀer from the server.
When the buﬀer has a speciﬁed amount of data, the player
enters the play state and the video starts to play again (see
Figure 1). A view can end in three ways: a successful view
ends normally when the video completes; a failed view ends
with a failure or error due to a problem with the server,
network, or content; and, ﬁnally, an abandoned view ends
with the viewer voluntarily abandoning the stream either
before the video starts up or after watching some portion
of it. Note that a viewer may abandon the view by closing
the browser, stopping the stream, or clicking on a diﬀerent
stream. There are other secondary player-initiated events or
viewer-initiated events that are part of the viewing process.
For instance, a viewer could initiate actions such as pausing,
fast-forwarding, or rewinding the video stream. Further, the
player may switch the bitrate of the encoded media in re-
sponse to network conditions, such as reduce the bandwidth
if there is packet loss. We do not explicitly analyze behav-
iors associated with these secondary events in this paper,
though these could be part of future work.
Figure 1: Views and Visits.
Visits. A visit is intended to capture a single session of
a viewer visiting a content provider’s site to view videos. A
visit is a maximal set of contiguous views from a viewer at a
speciﬁc content provider site such that each visit is separated
from the next visit by at least T minutes of inactivity, where
we choose T = 30 minutes2(see Figure 1).
Stream Quality Metrics. At the level of a view, the key
metrics that measure the quality perceived by the viewer are
shown in Figure 2. Failures address the question of whether
In that case, our view starts at the point
media player.
where the actual video is requested.
2Our deﬁnition is similar to the standard notion of a visit
(also called a session) in web analytics where each visit is
a set of page views separated by a period of idleness of at
least 30 minutes (say) from the next visit.
StartupPlayRebufferPlayStatesEventsViewer clicks "play". Buffer ﬁlled.  Play starts.Buffer empty. Play freezes. Buffer ﬁlled. Play resumes.Video ends. Play stops.ViewVisitVisitMore than T minutes of inactivityViews 213Key Metrics
Failures
Deﬁnition
Number (or, percentage) of views that
fail due to problems with the network,
server, or content.
Total time in startup state.
Startup Delay
Average Bitrate The average bitrate at which the video
Normalized Re-
buﬀer Delay
was watched.
Total time in rebuﬀer state divided by
the total duration of the video.
Figure 2: View-level stream quality metrics.
the stream was available or if viewing of the video initiated
by the viewer failed due to a problem with the network or the
server or the content itself (such as a broken link). A failed
view can be frustrating to the viewer as he/she is unable to
watch the video. A second key metric is startup delay which
is the amount of time the viewer waits for the video to start
up. Once the video starts playing, the average bitrate at
which the video was rendered on the viewer’s screen is a mea-
sure of the richness of the presented content. This metric is
somewhat complex since it is a function of how the video was
encoded, the network connectivity between the server and
the client, and the heuristics for bitrate-switching employed
by the player. Finally, a fourth type of metric quantiﬁes
the extent to which the viewer experienced rebuﬀering. Re-
buﬀering is also frustrating for the viewer because the video
stops playing and “freezes”. We can quantify the rebuﬀering
by computing the rebuﬀer delay which is total time spent
in a rebuﬀer state and normalizing it by dividing it by the
duration of the video.
Many of the above view-level metrics can be easily ex-
tended to visit-level or viewer-level metrics. One key visit-
level metric that we examine in this paper is a failed visit
which is a visit that ends with a failed view. A failed visit
could have had successful views prior to the failed view(s).
However, a failed visit is important because the viewer tries
to play a video one or more times but is unable to do so
and leaves the site right after the failure, presumably with
a level of frustration.
In our paper, we use many of the key metrics in Fig-
ure 2 in our evaluation of the impact of quality on viewer
behavior, though these are by no means the only metrics of
stream quality. It should be noted that many of the above
metrics were incorporated into measurement tools within
Akamai and have been in use for more than a decade [24,
1]. The lack of client-side measurements in the early years
led to measurements based on automated “agents” deployed
around the Internet that simulated synthetic viewers [1, 19]
that were then supplemented with server-side logs. In recent
years, there is a broad consensus among content providers,
CDNs, and analytics providers that these metrics or varia-
tions of these metrics matter.
Metrics for Viewer Behavior. Our metrics are focused on
the key aspects of viewer behavior that are often tracked
closely by content providers which we place in three cate-
gories (see Figure 3). The ﬁrst category is abandonment
where a viewer voluntarily decides to stop watching the
video. Here we are primarily concerned with abandonment
where the viewer abandons the video even before it starts
playing. A viewer can also abandon a stream after watching
a portion of the video which results in a smaller play time,
Type
Abandonment Abandonment
Metric
Engagement
Rate
Play time
Repeat View-
ers
Return Rate
Deﬁnition
% views abandoned
during startup.
Total
state (per view).
Prob. of return to site
within time period
in play
time
Figure 3: Key metrics for viewer behavior.
which we account for in the next category of metrics. The
second category is viewer engagement that can be measured
by play time which is simply the amount of video that the
viewer watches. The ﬁnal category speaks to the behavior
of viewers over longer periods of time. A key metric is the
return rate of viewers measured as the probability that a
viewer returns to the content provider’s site over period of
time, say, returning within a day or returning within a week.
3. DATA SETS
The data sets that we use for our analysis are collected
from a large cross section of actual users around the world
who play videos using media players that incorporate the
widely-deployed Akamai’s client-side media analytics plug
in3. When content providers build their media player, they
can choose to incorporate the plugin that provides an ac-
curate means for measuring a variety of stream quality and
viewer behavioral metrics. When the viewer uses the media
player to play a video, the plugin is loaded at the client-side
and it “listens” and records a variety of events that can then
be used to stitch together an accurate picture of the play-
back. For instance, player transitions between the startup,
rebuﬀering, seek, pause, and play states are recorded so
that one may compute the relevant metrics. Properties of
the playback, such as the current bitrate, bitrate switching,
state of the player’s data buﬀer are also recorded. Further,
viewer-initiated action that lead to abandonment such as
closing the browser or browser tab, clicking on a diﬀerent
link, etc can also be accurately captured. Once the metrics
are captured by the plugin, the information is “beaconed”
to an analytics backend that can process huge volumes of
data. From every media player at the beginning and end of
every view, the relevant measurements are sent to the ana-
lytics backend. Further, incremental updates are sent at a
conﬁgurable periodicity even as the video is playing.
3.1 Data Characteristics
While the Akamai platform serves a signiﬁcant amount
of the world’s enterprise streaming content accounting for
several million concurrent views during the day, we choose
a smaller but representative slice of the data from 12 con-
tent providers that include major enterprises in a variety
of verticals including news, entertainment, and movies. We
consider only on-demand videos in this study, leaving live
videos for future work. We tracked the viewers and views
for the chosen content providers for a period of 10 days (see
Figure 4). Our data set is extensive and captures 23 million
3While all our data is from media players that are instru-
mented with Akamai’s client-side plugin, the actual delivery
of the streams could have used any platform and not neces-
sarily just Akamai’s CDN.
214Total
Views
Minutes
Videos
Bytes
23 million
216 million
102 thousand
1431 TB
Avg Per
Visit
2.39
22.48
1.96
148 MB
Avg Per
Viewer
3.42
32.2
2.59
213 MB
Figure 4: Summary of views, minutes watched, dis-
tinct videos, and bytes downloaded for our data set.
Viewer Geography Percent Views
North America
Asia
Europe
Other
78.85%
12.80%
7.75%
0.60%
Figure 5: The geography of viewers in our trace at
the continent-level.
views from 6.7 million unique viewers, where each viewer
on average made 3.42 visits over the period and viewed a
total of 32.2 minutes of video. In each visit, there were on
average 2.39 views but only 1.96 unique videos viewed, indi-
cating that sometimes the viewer saw the same video twice.
The geography of the viewer was mostly concentrated in
North America, Europe and Asia with small contributions
from other continents (see Figure 5). More than half the
views used cable, though ﬁber, mobile, and DSL were signif-
icant. The ﬁber category consisted mostly of AT&T Uverse
and Verizon FiOS that contributed in roughly in equal pro-
portion. The other connection types such as dialup were
negligible (see Figure 6). Video duration is the total length
(in minutes) of the video (See Figure 7). We divide the
videos into short that have a duration of less than 30 min-
utes and long that have a duration of more than 30 minutes.
Examples of short video include news clips, highlight reels
for sports, and short television episodes. The median dura-
tion was 1.8 minutes, though the mean duration was longer
at 5.95 minutes. In contrast, long video consists of long tele-
vision episodes and movies. The median duration for long
videos was 43.2 minutes and the mean was 47.8 minutes.
4. ANALYSIS TECHNIQUES
A key goal is to establish a causal link between a stream
quality metric X and viewer behavior metric Y . The ﬁrst
key step is to establish a correlational link between X and
Y using the statistical tools for correlation and regression.
Next, in accordance with the maxim that “correlation does
not imply causation”, we do a more careful analysis to es-
tablish causation. We adapt the innovative tool of Quasi
Experimental Design (QED) used extensively in the social
and medical sciences to problem domains such as ours.
4.1 Correlational Analysis
To study the impact of a stream quality metric X (say,
startup delay) with a viewer behavioral metric Y (say aban-
donment rate), we start by visually plotting metric X versus
metric Y in the observed data. The visual representations
are a good initial step to estimating whether or not a cor-
relation exist. As a next step, we also quantify the correla-
Figure 6: Connection type as percent of views.
Figure 7: A CDF of the total video duration. The
median duration is 19.92 minutes over all videos, 1.8
minutes for short, and 43.2 minutes for long videos.
tion between X and Y . There are many diﬀerent ways to
calculate the correlation. Primary among them are Pear-
son’s correlation and Kendall’s correlation that is a type
of rank correlation. As observed in [9], Kendall’s correla-
tion is more suitable for a situation such as ours since it
does not assume any particular distributional relationship
between the two variables. Pearson’s correlation is more ap-
propriate when the correlated variables are approximately
linearly related, unlike the relationships that we explore in
our work. Kendall’s correlation measures the whether the
two variables X and Y are statistically dependent (i.e., cor-
related) without assuming any speciﬁc functional form of
their relationship. Kendall’s correlation coeﬃcient τ takes
values in the interval [−1, 1] where τ = 1 meaning that X
and Y are perfectly concordant, i.e., larger values of X are
always associated with larger values for Y , τ = −1 meaning
that X and Y are perfectly discordant, i.e., larger values of
X are always associated with smaller values of Y , and τ near
0 implying that X and Y are independent.
4.2 Causal Analysis
A correlational analysis of stream quality metric X (say,
215Confounding  
Variables
B
C
A
Independent 
Variable X 
(Treatment)
?
Dependent 
Variable Y 
(Outcome)
Figure 8: An example of a QED Model. The con-
founding variables are kept the same while the treat-
ment variable is varied to observe impact on out-
come.
startup delay) and a viewer behavior metric Y (say, aban-
donment rate) could show that X and Y are associated with
each other. A primary threat to a causal conclusion that an
independent variable X causes the dependent variable Y is
the existence of confounding variables that can impact both
X and Y (see Figure 8). To take a recent example from the
medical literature, a study published in Nature [20] made
the causal conclusion that children who sleep with the light
on are more likely to develop myopia later in life. But, as
it turns out, myopic parents tend to leave the light on more
often, as well as pass their genetic predisposition to myopia
to their children. Accounting for the confounding variable
of parent’s myopia, the causal results were subsequently in-
validated or substantially weakened.
More relevant to our own work, lets consider a potential
threat to a causal conclusion that a stream quality metric
X (say, startup delay) results in a viewer behavior Y (say,
abandonment). As a hypothetical example, suppose that