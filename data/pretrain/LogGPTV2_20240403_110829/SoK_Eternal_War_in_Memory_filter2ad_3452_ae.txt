ASLR (PIE on 32 bit)
Stack cookies
Shadow stack
WIT
Abadi CFI
Abadi CFI (w/ shadow stack)
Perf. % (avg/max) Dep. Compatibility
116 / 300 × Binary
67 / 150 × Binary
60 / 127 × —
10 / 25 × Binary/Modularity UAF, sub-obj, read corruption
15 / 30 × Binary/Modularity Information leak
104 / 155 × Binary/Modularity Approximation
Primary attack vectors
—
UAF
UAF, sub-obj
0 / 0 (cid:2) JIT compilation
Code reuse or code injection
0 / 0 (cid:2) JIT compilation
Code reuse
0 / 0 (cid:2) Relocatable code
Information leak
10 / 26 × Relocatable code
Information leak
0 / 5 (cid:2) —
Direct overwrite
5 / 12 × Exceptions
Corrupt function pointer
10 / 25 × Binary/Modularity Approximation
16 / 45 × Binary/Modularity Weak return policy
21 / 56 × Binary/Modularity Approximation
THIS TABLE GROUPS THE DIFFERENT PROTECTION TECHNIQUES ACCORDING TO THEIR POLICY AND COMPARES THE PERFORMANCE IMPACT,
DEPLOYMENT STATUS (DEP.), COMPATIBILITY ISSUES, AND MAIN ATTACK VECTORS THAT CIRCUMVENT THE PROTECTION.
Table II
data. The comparison neither covers overly speciﬁc Data
Integrity protections like heap metadata protection or ca-
nary/redzone/guards based protections, nor too special cases
of Control-ﬂow Integrity, like exception handler validation.
It does not include dynamic binary instrumentation solutions
due to their high performance cost, or others which are not
fully automatic (e.g., needs source code modiﬁcation). The
upper half of the table covers protections aiming to protect
against memory corruption in general and thus mitigate all
four different attacks identiﬁed in Section II. The lower half
covers approaches which aim to protect against control-ﬂow
hijacks only.
The performance is represented as the average and maxi-
mum overhead using either the SPEC CPU 2000 or 2006
benchmarks. We rely on the numbers reported by the
developers of the tools, since several of them are not
publicly available. We stress that since the values represent
measurements in different environments, different conﬁg-
urations, and sometimes with different sets of programs,
they only provide rough estimates. We present some of the
fastest solutions for enforcing Memory Safety and Data-
ﬂow Integrity but even those can double the execution
time. WIT and DSR report much lower overhead then
other general protection techniques and even smaller then
the Abadi CFI system under the hijacking protections. The
deployment status column represents whether a solution is
used in practice. The case of enforcing full ASLR on Linux
shows that even a 10-25% overhead prevents deployment.
This is the overhead that Position Independent Executables
(relocatable executables) cause on 32-bit machines and the
reason why ASLR is enforced only for libraries by default
on most distributions. As the table shows, only solutions
with negligible overhead are adopted in practice.
Not only performance but also compatibility issues pre-
vent the deployment of many proposed techniques. In the ta-
ble, “binary” represents binary compatibility issues, meaning
interfacing with unmodiﬁed binaries (e.g., legacy libraries).
This will not only cause false negatives, but false positives
as well, which contradicts with our practical requirements.
All solutions which build on points-to analysis have “mod-
ularity” issues, because the enforcement of stricter policies
require consideration of the dependencies between modules,
which makes re-usable libraries challenging.
None of the shown policies are perfect regarding robust-
ness, except enforcing complete Memory Safety with pointer
based techniques. Protections enforcing weaker Memory
Safety policies have more attack vectors, like use-after-free
(UAF), corruption of sub-objects (sub-obj) or corrupting
values in registers via read dereferences. DSR and ASLR
provide the most comprehensive solutions as a generic and
hijacking protection respectively, but both of them can be
circumvented by information leaks. The protection level
of DFI (as a generic protection) and CFI (as a hijack
protection) is only bounded by the “approximation” due
the static analysis. This means (i) enforcing a static set
of valid reaching deﬁnitions or jump targets, and not the
single dynamically valid ones, and (ii) the conservativeness
of the analysis establishing those sets. WIT is shown twice
in the table as a generic protection and as a control-ﬂow
hijacking protection. As a generic protection, it enforces
an “approximation” of Memory Safety, i.e., Data Integrity,
which has some weaknesses, but protects against most of
the attacks, including program speciﬁc data-only attacks as
well. As a control-ﬂow hijacking protection, it enforces the
same policy as Abadi CFI with a shadows stack, but with
less overhead. Unfortunately, neither the Abadi CFI nor
the WIT approach has been adopted in practice, although
their overhead can be considered low. We attribute this to
the beforementioned compatibility and modularity problems
raised by points-to analysis.
6060
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:53:16 UTC from IEEE Xplore.  Restrictions apply. 
X. CONCLUSION
REFERENCES
Both academia and industry have been ﬁghting memory
corruption bugs for decades. From time to time, pundits
have proclaimed that the problem had ﬁnally been solved,
only to ﬁnd their assertions falsiﬁed by subsequent attacks.
With the wide deployment and hardware support for Non-
executable Data, research has been focusing on ROP attacks
within hijack protections. The latest solution seemed to be
randomization, such as fully enforced, high entropy, 64-
bit ASLR or other in-place randomization techniques. But
the increased use of JIT compilation limits the usability
of a W⊕X policy, while the prevalence of user scripting
simpliﬁes defeating randomization. The ability of running
attacker provided scripts helps leaking secrets and on-the-
spot dynamic exploit construction. Researchers have to step
back, and instead of focusing on speciﬁc attacks, we need
to look at the big picture. Hopefully, this paper helps in this
regard by setting up its general attack model and by placing
different policy types in this model.
This systematization suggests that stronger policies are
needed, such as Data Integrity; or, when only hijacking
attacks are considered a valid threat, Control-ﬂow Integrity.
While the research direction of enforcing such policies
is promising, existing solutions are still impractical. Our
requirement analysis and the summarization of current tech-
niques show that performance, and especially compatibility
problems, are the main barriers of wide adoption. We remind
researchers in the security area to recognize the signiﬁcance
of these properties in the real world.
There is a pressing need for research, development, and
deployment of better publicly available software protection
techniques, especially built into commonly used compilers,
such as LLVM and GCC. These open-source platforms can
be of great value, where some of the compatibility problems
can be solved by the community so researchers can release
their robust but possibly slow protections to interested users.
Such experiments interacting mutually with real applications
will improve research further, and they might be able to lift
the performance threshold people impose on security. We
hope that this systematization of knowledge will help other
researchers in ﬁnding new ways to make progress in this
area. The war is not over.
Acknowledgments. We thank the anonymous reviwers,
Prof. R. Sekar, Stephen McCamant, and Dan Caselden
for their insightful reviews, helpful comments and proof-
reading. This work was supported in part by ONR grants
N000140710928 and N000140911081; NSF grants CNS-
0831298, 0842695, 0831501 and CCF-0424422; an AFOSR
grant FA9550-09-1-0539; a DARPA award HR0011-12-2-
005; and the National Natural Science Foundation of China
grant No. 61003216.
[1] MITRE, “CWE/SANS Top 25 Most Dangerous Software
Errors,” 2011, http://cwe.mitre.org/top25.
[2] H. Etoh and K. Yoda, “Protecting from stack-smashing at-
tacks,” 2000, http://www.trl.ibm.com/projects/security/ssp.
[3] Microsoft, “/SAFESEH (Safe Exception Handlers),” 2003,
http://msdn2.microsoft.com/en-us/library/9a89h429.aspx.
[4] A. van de Ven and I. Molnar, “Exec shield,” 2004, http://
www.redhat.com/f/pdf/rhel/WHP0006US Execshield.pdf.
[5] T. PaX, “Address
space layout
randomization,” 2001.
[Online]. Available: http://pax.grsecurity.net/docs/aslr.txt
[6] Nergal, “The advanced return-into-lib(c) exploits: PaX case
study,” Phrack, vol. 11, no. 58, Dec 2001.
[7] H. Shacham, “The geometry of innocent ﬂesh on the bone:
return-into-libc without function calls,” in CCS’07.
[8] S. Checkoway, L. Davi, A. Dmitrienko, A.-R. Sadeghi,
H. Shacham, and M. Winandy, “Return-oriented program-
ming without returns,” in CCS’10.
[9] T. Bletsch, X. Jiang, V. W. Freeh, and Z. Liang, “Jump-
oriented programming: a new class of code-reuse attack,” in
ASIACCS’11.
[10] M. Tran, M. Etheridge, T. Bletsch, X. Jiang, V. Freeh, and
P. Ning, “On the expressiveness of return-into-libc attacks,”
in RAID’11.
[11] R. Roemer, E. Buchanan, H. Shacham, and S. Savage,
“Return-oriented programming: Systems, languages, and ap-
plications,” ACM Trans. Inf. Sys. Sec.’12.
[12] R. Strackx, Y. Younan, P. Philippaerts, F. Piessens, S. Lach-
mund, and T. Walter, “Breaking the memory secrecy assump-
tion,” in EUROSEC’09.
[13] F. J. Serna, “CVE-2012-0769, the case of the perfect info
leak,” 2012.
[14] D. Blazakis, “Interpreter exploitation,” in WOOT’10.
[15] U. Erlingsson, Y. Younan, and F. Piessens, “Low-level soft-
ware security by example,” in Handbook of Information and
Communication Security, 2010.
[16] V. van der Veen, N. dutt Sharma, L. Cavallaro, and H. Bos,
“Memory errors: the past, the present, and the future,” in
RAID’12.
[17] Y. Younan, W. Joosen, and F. Piessens, “Runtime countermea-
sures for code injection attacks against C and C++ programs,”
ACM Comp. Surv.’12.
[18] V. P. Kemerlis, G. Portokalidis, and A. D. Keromytis,
“kguard: lightweight kernel protection against return-to-user
attacks,” in USENIX Security’12.
[19] jp, “Advanced Doug Lea’s malloc exploits,” Phrack, vol. 11,
no. 61, Aug 2003.
[20] K. Onarlioglu, L. Bilge, A. Lanzi, D. Balzarotti, and
E. Kirda, “G-Free: defeating return-oriented programming
through gadget-less binaries,” in ACSAC’10.
[21] V. Pappas, M. Polychronakis, and A. D. Keromytis, “Smash-
ing the gadgets: Hindering return-oriented programming using
in-place code randomization,” in IEEE SP’12.
[22] R. Wahbe, S. Lucco, T. E. Anderson, and S. L. Graham,
“Efﬁcient software-based fault isolation,” in SOSP’93.
[23] U. Erlingsson, S. Valley, M. Abadi, M. Vrable, M. Budiu,
and G. C. Necula, “XFI: software guards for system address
spaces,” in OSDI’06.
[24] B. Yee, D. Sehr, G. Dardyk, J. B. Chen, R. Muth, T. Ormandy,
6161
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:53:16 UTC from IEEE Xplore.  Restrictions apply. 
S. Okasaka, N. Narula, and N. Fullagar, “Native Client: A
sandbox for portable, untrusted x86 native code,” in IEEE
SP’09.
[25] S. Chen, J. Xu, E. C. Sezer, P. Gauriar, and R. K. Iyer,
“Non-control-data attacks are realistic threats,” in USENIX
Security’05.
[26] huku and argp, “Exploiting vlc: A case study on jemalloc
heap overﬂows,” Phrack, vol. 14, no. 68, Apr 2012.
[27] E. J. Schwartz, T. Avgerinos, and D. Brumley, “Q: Exploit
hardening made easy,” in USENIX Securty’11.
[28] VUPEN, “Vulnerability research team blog,” 2012, http://
www.vupen.com/blog/.
[29] F. B. Schneider, “Enforceable security policies,” ACM Trans.
Inf. Sys. Sec.’00.
[30] N. Nethercote and J. Seward, “Valgrind: a framework for
heavyweight dynamic binary instrumentation,” in PLDI’07.
[31] C.-K. Luk, R. Cohn, R. Muth, H. Patil, A. Klauser,
G. Lowney, S. Wallace, V. J. Reddi, and K. Hazelwood, “Pin:
building customized program analysis tools with dynamic
instrumentation,” in PLDI’05.
[32] D. Bruening, T. Garnett, and S. Amarasinghe, “An infrastruc-
ture for adaptive dynamic optimization,” in CGO ’03.
[33] M. Payer and T. R. Gross, “Fine-grained user-space security
through virtualization,” in VEE’11.
[34] E. Bosman, A. Slowinska, and H. Bos, “Minemu: the world’s
fastest taint tracker,” in RAID’11.
[35] L. Davi, A.-R. Sadeghi, and M. Winandy, “ROPdefender: a
detection tool to defend against return-oriented programming
attacks,” in ASIACCS’11.
[36] C. D. Spradling, “SPEC CPU2006 benchmark tools,”
SIGARCH Comp. Arch. News’07.
[37] Microsoft, “The BlueHat prize contest ofﬁcial rules,” 2012,
http://www.microsoft.com/security/bluehatprize/rules.aspx.
[38] G. S. Kc, A. D. Keromytis, and V. Prevelakis, “Countering
code-injection attacks with instruction-set randomization,” in
CCS ’03.
[39] M. Chew and D. Song, “Mitigating Buffer Overﬂows by
Operating System Randomization,” Tech. Rep., 2002.
[40] M. Payer, “Too much PIE is bad for performance,” 2012.
[41] H. Shacham, M. Page, B. Pfaff, E.-J. Goh, N. Modadugu, and
D. Boneh, “On the effectiveness of address-space randomiza-
tion,” in CCS’04.
[42] T. Wei, T. Wang, L. Duan, and J. Luo, “Secure dynamic code
generation against spraying,” in CCS’10.
[43] T. Durden, “Bypassing PaX ASLR protection,” Phrack,
vol. 11, no. 59, Jul 2002.
[44] C. Kil, J. Jun, C. Bookholt, J. Xu, and P. Ning, “Address
space layout permutation (ASLP): Towards ﬁne-grained ran-
domization of commodity softwar,” in ACSAC’06.
[45] J. Hiser, A. Nguyen-Tuong, M. Co, M. Hall, and J. W.
Davidson, “ILR: Where’d my gadgets go?” in IEEE SP’12.
[46] R. Wartell, V. Mohan, K. Hamlen, and Z. Lin, “Binary
stirring: Self-randomizing instruction addresses of legacy x86
binary code,” in CCS’12.
[47] C. Cowan, S. Beattie, J. Johansen, and P. Wagle, “Pointguard:
protecting pointers from buffer overﬂow vulnerabilities,” in
USENIX Security’03.
[48] S. Bhatkar and R. Sekar, “Data Space Randomization,” in
DIMVA’08.
[49] G. C. Necula, S. McPeak, and W. Weimer, “CCured: type-safe
retroﬁtting of legacy code,” in POPL’02.
[50] T. Jim, J. G. Morrisett, D. Grossman, M. W. Hicks, J. Cheney,
and Y. Wang, “Cyclone: A safe dialect of C,” in USENIX
ATC’02.
[51] S. Nagarakatte, J. Zhao, M. M. Martin, and S. Zdancewic,
“SoftBound: highly compatible and complete spatial memory
safety for C,” SIGPLAN Not.’09.
[52] R. Jones and P. Kelly, “Backwards-compatible bounds check-
ing for arrays and pointers in C programs,” Auto. and Algo.
Debugging’97.
[53] O. Ruwase and M. S. Lam, “A practical dynamic buffer
overﬂow detector,” in NDSS’04.
[54] D. Dhurjati and V. Adve, “Backwards-compatible array
bounds checking for C with very low overhead,” in ICSE’06.
[55] C. Lattner and V. Adve, “Automatic pool allocation: improv-
ing performance by controlling data structure layout in the
heap,” in PLDI’05.
[56] P. Akritidis, M. Costa, M. Castro, and S. Hand, “Baggy
bounds checking: an efﬁcient and backwards-compatible de-
fense against out-of-bounds errors,” in USENIX Security’09.
[57] Y. Younan, P. Philippaerts, L. Cavallaro, R. Sekar, F. Piessens,
and W. Joosen, “PAriCheck: an efﬁcient pointer arithmetic
checker for C programs,” in ASIACCS’10.
[58] P. Akritidis, “Cling: A memory allocator to mitigate dangling
pointers,” in USENIX Security’10.
[59] K. Serebryany, D. Bruening, A. Potapenko, and D. Vyukov,
“AddressSanitizer: A fast address sanity checker,” in USENIX
ATC’12.
[60] S. Nagarakatte, J. Zhao, M. M. Martin, and S. Zdancewic,
safety for C,” in
“CETS: compiler enforced temporal
ISMM’10.
[61] S. H. Yong and S. Horwitz, “Protecting C programs from
attacks via invalid pointer dereferences,” in ESEC/FSE-11’03.
[62] P. Akritidis, C. Cadar, C. Raiciu, M. Costa, and M. Castro,
“Preventing memory error exploits with WIT,” in IEEE
SP’08.
[63] A. Slowinska, T. Stancescu, and H. Bos, “Body armor for
binaries: preventing buffer overﬂows without recompilation,”
in USENIX ATC’12.
[64] M. Castro, M. Costa, and T. Harris, “Securing software by
enforcing data-ﬂow integrity,” in OSDI’06.
[65] A. One, “Smashing the stack for fun and proﬁt,” Phrack,
vol. 7, no. 49, Nov. 1996.
[66] C. Cowan, C. Pu, D. Maier, H. Hintony, J. Walpole, P. Bakke,
S. Beattie, A. Grier, P. Wagle, and Q. Zhang, “Stack-
Guard: automatic adaptive detection and prevention of buffer-
overﬂow attacks,” in USENIX Security’98.
[67] Vendicator, “Stack Shield: A ”stack smashing” technique
protection tool for linux,” 2000.
[68] T. Chiueh and F.-H. Hsu, “RAD: A compile-time solution to
buffer overﬂow attacks,” in ICDCS’01.
[69] M. Abadi, M. Budiu, U. Erlingsson, and J. Ligatti, “Control-
ﬂow integrity,” in CCS’05.
[70] J. Li, Z. Wang, T. K. Bletsch, D. Srinivasan, M. C. Grace, and
X. Jiang, “Comprehensive and efﬁcient protection of kernel
control data,” IEEE Trans. Inf. Forencics and Sec’11.
[71] Z. Wang and X. Jiang, “HyperSafe: A lightweight approach
to provide lifetime hypervisor control-ﬂow integrity,” in IEEE
SP’10.
6262
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:53:16 UTC from IEEE Xplore.  Restrictions apply.