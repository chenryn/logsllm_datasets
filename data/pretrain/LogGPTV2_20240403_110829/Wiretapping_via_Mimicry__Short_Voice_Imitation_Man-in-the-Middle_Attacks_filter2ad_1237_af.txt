users to auditize words from books (similar in spirit to the idea of
reCAPTCHAs).
Moving forward, we believe that our work also raises a more
broader and general threat of “voice privacy.” The malicious actors
may use various approaches to record someone’s voice samples and
use these samples to compromise the security and privacy in an-
other application (such as Cfones or voice recognition systems).
While people seem quite concerned about their “visual privacy” in
today’s digital world (e.g., someone taking their picture), they may
not consider their voice to be so sensitive (e.g., people often talk
out loud in a restaurant and even talk to strangers). Given that au-
dio sensors are very common and do not require explicit efforts
from an attacker to record audio (unlike camera, for example), we
believe that voice privacy can have several implications that may
need careful attention.
Potential Defenses and Challenges: In light of our attacks against
Cfones, a natural question is what can be done to improve the secu-
rity of the underlying SAS validation process. One possibility is to
rely upon multiple preceptory channels rather than just audio. For
example, users may be asked to pay attention to the video (assum-
ing video is available) while validating verbal SAS. In other words,
if the attacker performs the voice impersonation against SAS, users
may be able to detect this attack by looking at and analyzing the ac-
companying video of the communicating party – the lip movement
of the person stating the SAS would not match with the spoken
SAS. This could serve as a potentially useful defense to our attacks.
However, it may present signiﬁcant challenges in practice. First,
the users may not be in a position to look at the video or may simply
not pay enough attention to spot the lack of audio-visual SAS syn-
chronization. In fact, our voice-audio synchronization test (Section
5), shows that only 2 out of 30 (only 7%) survey participants were
able to detect such an audiovisual synchronization. Second, it is not
hard to imagine that the attacker can manipulate the video packets
in addition to the audio packets so the spoken audio matches with
the video stream. The video impersonation attacks are feasible due
to the same underlying weakness of the VoIP channel with respect
to manipulation as the audio attacks. There exists some prior work
that suggests image/video morphing attacks are feasible [52]. The
need to inﬂuence both audio and visual channels at the same time
may increase the complexity of the attack, however.
Another potential defense to our attacks could be integration
of an automated voice recognition or voice biometrics system to
Cfones. That is, in place of, or addition to, human voice recogni-
tion, a software component may be used to detect potential SAS
forgeries. While voice biometrics is a rich area, achieving robust
detection rates (i.e., low false negatives and low false positives)
is still a challenging problem. In addition, existing voice biomet-
rics system may not work well to thwart active voice imperson-
ation and synthesis attacks [26]. Furthermore, given that the SAS
challenge being authenticated in Cfones application is short (only
few seconds worth of audio sample), it may not provide sufﬁcient
“knowledge” to the biometric system to extract features from the
voice using which detection can take place. Our objective evalua-
tion showed that the MCD distortion level increases with the length
of SAS, which means shorter converted SASs may not be distin-
guishable from the original SASs even at a quantitative level.
Yet another potential solution to thwart the voice impersonation
attacks against Cfones is to perform the SAS validation over an
auxiliary channel that can be more resistant to voice and packet
manipulation. PSTN communication is believed to offer such prop-
erties, and, when available, may be used to secure VoIP communi-
cation. For example, if the communicating devices support both
VoIP capability (Internet connection) and PSTN connectivity (e.g.,
cellular connection), the non-SAS communication can take place
over the former and SAS validation can take place over the lat-
ter. This mechanism is suitable for mobile phones – the Cfone app
switches to a PSTN call when SAS comparison is performed by
the user (Android, e.g., allows making VoIP and cellular calls si-
multaneously). A limitation of this defense mechanism is that it
is only applicable to devices which have PSTN capability (such as
cell phones).
An independent defense could be increasing the dictionary size
to make reordering difﬁcult, and to reduce the efﬁciency of auto-
matic keyword spotting. Moreover, if the dictionary is not ﬁxed,
reordering will be impossible. An idea suggested in [12] is to
choose words from a large dynamic space (e.g., front pages of
today’s newspapers). The dictionary can be chosen by users, or
programmatically during key exchange. However, the security and
user experience of this approach needs further investigation.
Another possibility is to employ the approach proposed by Bal-
asubramaniyan et al. [14], which identiﬁes and characterizes the
network route traversed by the voice signal and creates a detailed
ﬁngerprints for the call source. For VoIP connection, this method
is based on network characteristics, and therefore may only be ef-
fective if the attacker and the victim reside in different networks.
7. CONCLUSIONS
Crypto Phones aim to solve an important problem of establish-
ing end-to-end secure communications on the Internet via a purely
peer-to-peer mechanism. However, their security relies on the as-
sumption that the voice channel, over which short checksums are
validated by the users, provides integrity/authenticity. We chal-
lenged this assumption, and developed two forms of short voice im-
personation attacks, reordering and morphing, that can compromise
the security of Crypto Phones in both two-party and multi-party
settings. Our evaluation demonstrate the effectiveness of these at-
tacks, when contrasted with a trivial attack where the attacker im-
personates with a totally different voice. We suggested potential
ways and associated challenges to improve the security of Crypto
Phones against the voice MITM attacks. A comprehensive future
investigation is needed to develop a viable mechanism to thwart
such attacks.
Acknowledgments
This work was supported in part by a Cisco grant. We would like
to thank Patrick Traynor (our shepherd) and anonymous CCS’14
reviewers for their constructive comments and guidance. We are
grateful to Dhiraj Rajani for his help with our subjective study set-
up. We are also thankful to N. Asokan, Steve Bethard, Raman
Bhati, Jason Britt, Hugo Krawczyk, and all members of the UAB
SPIES lab, for feedback on previous versions of this paper.
8. REFERENCES
[1] Infosecurity - Microsoft Expands Encryption to Foil Government
Snooping. http://www.infosecurity-
magazine.com/view/36034/microsoft-expands-
encryption-to-foil-government-snooping.
[2] Limited Domain Synthesis. http://festvox.org/ldom/.
[3] NSA and All Major Intelligence Agencies Can Listen in to
Encrypted Cell Phone Calls.
http://www.nbcnews.com/tech/security/nsa-can-
listen-encrypted-phone-calls-theyre-not-only-
ones-f2D11744226.
[4] TRANSFORM: Flexible Voice Synthesis Through Articulatory
Voice Transformation .
http://festvox.org/transform/transform.html.
[5] AT&T Labs Text-to-Speech. http:
//www2.research.att.com/~ttsweb/tts/index.php.
[6] ModelTalker Speech Synthesis System.
http://www.modeltalker.com.
[7] Open Whisper Systems. https://whispersystems.org/.
[8] PGPfone - Pretty Good Privacy Phone.
http://www.pgpi.org/products/pgpfone/.
[9] Silent Circle – Private Communications.
https://silentcircle.com/.
[10] The Zfone Project. http://zfoneproject.com/.
[11] ZORG - An Implementation of the ZRTP Protocol.
http://www.zrtp.org/.
[12] N. Asokan, T. Chan, and G. Krishnamurthi. Authenticating Security
Parameters, Feb. 8 2007. US Patent App. 11/672,900.
[13] B. B. Voice Conversion Uning Articulatory Features. Master’s thesis,
International Institute of Information Technology Hyderabad, 2012.
[14] V. A. Balasubramaniyan, A. Poonawalla, M. Ahamad, M. T. Hunter,
and P. Traynor. PinDr0p: Using Single-Ended Audio Features to
Determine Call Provenance. In Proceedings of the 17th ACM
conference on Computer and communications security, pages
109–120. ACM, 2010.
[15] J. Benesty, M. M. Sondhi, and Y. Huang. Springer Handbook of
Speech Processing. 2008.
[16] A. W. Black and K. A. Lenzo. Limited Domain Synthesis. Technical
report, 2000.
[17] M. Cagalj, S. Capkun, and J. Hubaux. Key agreement in peer-to-peer
wireless networks. In Proceedings of the IEEE (Special Issue on
Cryptography and Security), 2006.
[18] J. P. Campbell Jr. Speaker Recognition: A Tutorial. Proceedings of
the IEEE, 85(9), 1997.
[19] M. Chevillet, M. Riesenhuber, and J. P. Rauschecker. Functional
Correlates of the Anterolateral Processing Hierarchy in Human
Auditory Cortex. The Journal of Neuroscience, 31(25), 2011.
[20] S. Desai, E. V. Raghavendra, B. Yegnanarayana, A. W. Black, and
K. Prahallad. Voice Conversion Using Artiﬁcial Neural Networks. In
Acoustics, Speech and Signal Processing, 2009. ICASSP 2009. IEEE
International Conference on, 2009.
[21] A. Ganapathiraju and A. N. Iyer. Method and System for Real-Time
Keyword Spotting for Speech Analytics, July 20 2012. US Patent
App. 13/554,937.
[22] M. T. Goodrich, M. Sirivianos, J. Solis, G. Tsudik, and E. Uzun.
Loud and Clear: Human-Veriﬁable Authentication Based on Audio.
In International Conference on Distributed Computing Systems
(ICDCS), July 2006.
[23] H. Hollien, W. Majewski, and E. T. Doherty. Perceptual Identiﬁcation
of Voices Under Normal, Stress and Disguise Speaking Conditions.
Journal of Phonetics, 1982.
[24] A. W. B. John Kominek. CMU ARCTIC Databases for Speech
Synthesis, 2003.
[25] R. Kainda, I. Flechais, and A. W. Roscoe. Usability and Security of
Out-Of-Band Channels in Secure Device Pairing Protocols. In
SOUPS: Symposium on Usable Privacy and Security, 2009.
[26] T. Kinnunen, Z.-Z. Wu, K.-A. Lee, F. Sedlak, E.-S. Chng, and H. Li.
Vulnerability of Speaker Veriﬁcation Systems Against Voice
Conversion Spooﬁng Attacks: The Case of Telephone Speech. In
Acoustics, Speech and Signal Processing (ICASSP), 2012.
[27] J. Kominek, T. Schultz, and A. W. Black. Synthesizer Voice Quality
of New Languages Calibrated with Mean Mel Cepstral Distortion. In
Proc. Inte. Workshop Spoken Lang. Technol. for Under-Resourced
Lang.(SLTU), 2008.
[28] J. Kreiman and D. Sidtis. Foundations of Voice Studies: An
Interdisciplinary Approach to Voice Production and Perception. John
Wiley & Sons, 2011.
[29] R. F. Kubichek. Mel-Cepstral Distance Measure for Objective Speech
Quality Assessment. In Communications, Computers and Signal
Processing, 1993., IEEE Paciﬁc Rim Conference on, volume 1, 1993.
[30] A. Kumar, N. Saxena, G. Tsudik, and E. Uzun. Caveat Emptor: A
Comparative Study of Secure Device Pairing Methods. In
International Conference on Pervasive Computing and
Communications (PerCom), March 2009.
[31] P. Ladefoged and J. Ladefoged. The Ability of Listeners to Identify
Voices. UCLA Working Papers in Phonetics, 49, 1980.
[32] S. Laur and K. Nyberg. Efﬁcient mutual data authentication using
manually authenticated strings. In Cryptology and Network Security
(CANS), 2006.
[33] S. Laur and S. Pasini. SAS-Based Group Authentication and Key
Agreement Protocols. In Public Key Cryptography, 2008.
[34] R. Nithyanand, N. Saxena, G. Tsudik, and E. Uzun. Groupthink:
Usability of Secure Group Association of Wireless Devices. In
International Conference on Ubiquitous Computing (Ubicomp),
September 2010.
[35] S. Pasini and S. Vaudenay. An Optimal Non-Interactive Message
Authentication Protocol. In CT-RSA, 2006.
[36] Petraschek, Martin and Hoeher, Thomas and Jung, Oliver and
Hlavacs, Helmut and Gansterer, Wilfried N. Security and Usability
Aspects of Man-in-the-Middle Attacks on ZRTP. J. UCS, 14(5),
2008.
[37] I. Rec. P. 800: Methods for Subjective Determination of
Transmission Quality. International Telecommunication Union,
Geneva, 1996.
[38] P. Rose. Forensic Speaker Identiﬁcation. CRC Press, 2003.
[39] Stanislaw Jarecki and Nitesh Saxena. Auhenticated Key Agreement
with Key Re-Use in the Short Authenticated Strings. In Conference
on Security and Cryptography for Networks (SCN), September 2010.
[40] D. Sundermann, H. Hoge, A. Bonafonte, H. Ney, A. Black, and
S. Narayanan. Text-Independent Voice Conversion Based on Unit
Selection. In Acoustics, Speech and Signal Processing (ICASSP),
2006.
[41] D. Sundermann, H. Ney, and H. Hoge. VTLN-Based
Cross-Language Voice Conversion. In Automatic Speech Recognition
and Understanding, 2003. ASRU’03. 2003 IEEE Workshop on, 2003.
[42] I. Szoke, P. Schwarz, P. Matejka, L. Burget, M. Karaﬁát, M. Fapso,
and J. Cernocky. Comparison of Keyword Spotting Approaches for
Informal Continuous Speech. In Workshop on Multimodal
Interaction and Related Machine Learning Algorithms, 2005.
[43] T. Toda, A. W. Black, and K. Tokuda. Acoustic-to-Articulatory
Inversion Mapping with Gaussian Mixture Model. In
INTERSPEECH, 2004.
[44] T. Toda, A. W. Black, and K. Tokuda. Spectral Conversion Based on
Maximum Likelihood Estimation Considering Global Variance of
Converted Parameter. In Proc. ICASSP, volume 1, 2005.
[45] T. Toda, A. W. Black, and K. Tokuda. Voice Conversion Based on
Maximum-Likelihood Estimation of Spectral Parameter Trajectory.
Audio, Speech, and Language Processing, IEEE Transactions on,
15(8), 2007.
[46] T. Toda, A. W. Black, and K. Tokuda. Statistical Mapping Between
Articulatory Movements and Acoustic Spectrum Using a Gaussian
Mixture Model. Speech Communication, 50(3), 2008.
[47] A. R. Toth and A. W. Black. Using Articulatory Position Data in
Voice Transformation. ISCA SSW6, 2007.
[48] H. Tsuboi and Y. Takebayashi. A Real-Time Task-Oriented Speech
Understanding System Using Keyword-Spotting. In Acoustics,
Speech, and Signal Processing, 1992.
[49] E. Uzun, K. Karvonen, and N. Asokan. Usability analysis of secure
pairing methods. In Financial Cryptography and Data Security,
2007.
[50] J. Valkonen, N. Asokan, and K. Nyberg. Ad Hoc Security
Associations for Groups. In Security and Privacy in Ad-Hoc and
Sensor Networks (ESAS), 2006.
[51] S. Vaudenay. Secure Communications over Insecure Channels Based
on Short Authenticated Strings. In Advances in Cryptology -
CRYPTO 2005, 2005.
[52] F. Yang, E. Shechtman, J. Wang, L. Bourdev, and D. Metaxas. Face
Morphing Using 3D-aware Appearance Optimization. In
Proceedings of Graphics Interface 2012, GI ’12, 2012.
[53] H. Ye and S. Young. High Quality Voice Morphing. In Acoustics,
Speech, and Signal Processing, 2004. Proceedings.(ICASSP’04).
IEEE International Conference on, volume 1, 2004.
[54] Zhang, Ruishan and Wang, Xinyuan and Farley, Ryan and Yang,
Xiaohui and Jiang, Xuxian. On The Feasibility of Launching the
Man-in-the-Middle Attacks on VoIP from Remote Attackers. In
International Symposium on Information, Computer, and
Communications Security, ASIACCS, 2009.