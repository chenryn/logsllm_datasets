flexibility in tracing functionality, with the accompanying risk of
more permissive revelation of plaintext content during tracing. De-
ployment of such a policy would require defining actionable policies
about what messages should be considered related; a tricky topic
that requires more research.
Preventing partition attacks by malicious users. If we assume
the existence of effective message-similarity detection software
running on honest clients, one solution to prevent malicious users
from bypassing these checks is trusted hardware; i.e., require all
clients to faithfully execute the detection software. In the absence
of client-side trusted hardware, we can attempt to prevent such
behavior cryptographically using zero-knowledge proofs, albeit
at a far greater cost. Such a solution would require the platform
to maintain, for each user, a set of all ciphertext, tag pairs the
user has received. For each new message a user sends, they would
need to prove in zero-knowledge that their message is unique (or
sufficiently dissimilar) with respect to the set or it is constructed
as a forward of an appropriate message in the set. This is unlikely
to be practical. In any case, both the trusted hardware and zero-
knowledge solutions are susceptible to similarity-evasion attacks in
which the adversary specially crafts a message that evades similarity
detection but continues to carry the malicious intent.
Mitigating abuse of abuse mitigations. Message tracing can be
used to identify the source of malicious or harassing messages. But
the same techniques can be used against whistleblowers or activists.
Robust policy dictating how and when to perform tracing is neces-
sary for protection of users’ privacy expectations. Our proposed
schemes offer one such policy; a single report from a user that has
received a message unlocks the ability for the platform to trace.
Of course, higher level policies within the platform can dictate if
a report is acted on, but this leaves open an interesting question
if it is possible to integrate more expressive reporting and tracing
policies directly into the cryptographic tracing scheme.
Figure 9: Path traceback timing with respect to path length. (Left)
Total time to complete trace. (Right) Traceback rate of time per mes-
sage in trace.
Figure 10: Tree traceback with varying tree structure. (Left) Vary-
ing tree depth with constant branching factor of 3. (Right) Varying
branching factor with constant depth of 3. (Top) Total time to com-
plete trace. (Bottom) Traceback rate of time per message in trace.
Storage and bandwidth overhead. Our tracing schemes intro-
duce extra tracing metadata that needs to be stored and send by
both the client and server. As shown in Figure 8, the absolute size
of the stored trace metadata is small — a 256-bit PRF output and a
few 128-bit block cipher outputs. For client storage and bandwidth,
we expect the overhead induced by < 100B of trace metadata per
message to be dwarfed by the size of the message itself; further-
more, for client storage, when the message is deleted, the associated
trace metadata can be deleted with it. For server storage, however,
in platforms like Signal and WhatsApp, message ciphertexts are
not stored, aside from a temporary staging period until they have
been delivered. In this case, trace metadata incurs the addition of a
new long-term storage cost that potentially represents a significant
infrastructure change. To limit storage costs, if the goal of message
tracing is to combat ongoing misinformation campaigns, it seems
reasonable to store only a sliding window of trace metadata, say
for the current month. In this case, if the platform sees one billion
messages of traffic per day, the data store would be of size ≈ 2TB
for tree traceback and 600GB for path traceback. A data store of this
size can be instantiated with an in-memory data store like Redis
as in our benchmarks, or more cheaply with a database, where the
tradeoff would be slower traceback.
50100150200path length (# msgs)01020time (ms)50100150200path length (# msgs)050100time / msg (s/msg)468050100102103tree size (# msgs)468tree branching factor050100468010002000time (ms)102103104tree size (# msgs)468tree depth050100time / msg (s/msg)One interesting approach is to couple a tracing mechanism with
an anonymous blacklisting scheme [18]. In anonymous blacklisting,
cryptographic material bound to each message can be used to bar
the author from further participation without linking messages
together or identifying the author. One could extend this to tracing
schemes, allowing the platform the ban the source or forwarders of
a message without learning their identities. To be meaningful, this
would require a tracing scheme that did not depend on metadata.
A second interesting approach for tree traceback is threshold
reporting, where a message would need to be reported by many
users before it can be traced. Once a certain threshold of reports is
reached, some part or all of the trace tree could be revealed. Care
would need to be taken to prevent one malicious client from hitting
some reporting threshold q by forwarding the message to q collud-
ing clients. And there are questions of the appropriate threshold
and if it should or could vary with the size of the forwarding tree.
Finally, one could imagine various mechanisms for increasing
the robustness of the tracing authority. We could require multiple
parties to cooperate to recover a trace. Or delegating tracing au-
thority to a separate party. Similarly we could imagine the tracing
authority operating as part of a contractual anonymity system [27],
in which a verifiable third-party mediates between users and the
authority, only giving the authority the ability to de-anonymize if
a user breaks their contract policy.
9 RELATED WORK
Tracing mechanisms. To the best of our knowledge, there are no
works directly addressing tracing of forwards in E2E encrypted
messaging or messaging in general. A number of works, includ-
ing [9, 15, 20] have considered the problem of tracing payments
in electronic cash systems. This is a conceptually related problem.
However, the techniques are not directly applicable. First, these
systems do not deal with binding the content of a message to the
trace. Second most systems assume far more interaction with a
central party (e.g., a bank) than is allowed in our setting.
Another line of work [25, 29, 30] considered IP packet traceback.
But the approaches taken here are probabilistic. The point is not
to trace an individual packet, but to get a trace of a stream of
packets. As such packets are probabilistically marked [25] or kept
in a Bloom filter [29]. They cannot be used to reliably trace an
individual message.
A recent work [28] takes a different approach, supporting privacy-
preserving path validation for a single packet. However, the ap-
proach requires the path to be known in advance so the appropriate
session keys can be generated. It does not work for the ad-hoc paths
that arise as messages are forwarded through a social network.
Secure logging. A sequence of works, including [26] considered
secure logging mechanisms. The goal is to record on a local machine
a log of all activity that both cannot be modified by an attacker
and does not reveal anything without access to a decryption key.
Typically such systems assume a third party who holds a key that
is used to authenticate logs via signatures or hashes. Our tracing
approach is, in a sense, a form of secure log in that we want (1)
confidentiality from the party who stores the log (the messaging
platform) until a key is revealed and (2) integrity from the party
creating the log (the communicating users). However, our “log” has
a richer structure we must obscure, more specific integrity guar-
antees, and the setting requires us to split the roles for preserving
integrity and confidentiality.
Symmetric searchable encryption. A long line of symmetric
searchable encryption (SSE) schemes use “encrypted pointers” sim-
ilar to ours to hide the structure of an index held on an untrusted
server. In particular we use techniques reminiscent of [10, 12] to
construct our tracing mechanism extended to bind message plain-
texts into the pointers and protect against maliciously generated
pointers. Our functionality, confidentiality, and integrity goals are,
however, distinct.
Traitor tracing. Another line of work explores traitor tracing
mechanisms [7, 11] for identifying who within a group leaked
a particular piece of content or a key to an outside party. These
schemes are not directly applicable for a few reasons. First, the
goals of message tracing are not to trace who leaked/reported the
message to the platform (out of the forwarding chain “group”). Sec-
ond, message tracing has very specific restrictions on who is able
to perform tracing. For example, by user trace confidentiality, even
members of the forwarding chain “group” should not be able to
learn the message trace.
Signatures and aggregate signatures. Aggregate signatures were
first proposed by Boneh et al. [8] in part to allow the path of a mes-
sage through a network to be authenticated by an aggregation of
the per-hop signatures and a list of the hops taken. In contrast,
our scheme achieves its results without requiring the message to
contain a linear list of its path-to-date and without disclosing that
path to intermediaries.
Message franking. Message franking [13, 17] is another line of
work that aims to prevent abuse in end-to-end encrypted messag-
ing. While these protocols inspire our work, they cannot be used
to report messages past one hop: a forwarded message can only
be attributed to the last forwarder. One might attempt to employ
message franking to trace further by sequentially interacting with
each previous sender requiring them to either provide the message
franking opening for the previous message (if the message was a
forward) or be identified as the original source for the message.
Such a solution would be impractical in the face of offline users and
large forwarding trees.
Automated moderation systems. Various works have explored
ad-hoc moderation[16] or machine learning to detect abusive con-
tent [24]. We do not provide a exhaustive list here. These works are
promising but require the originators of messages be identified if
they are to be held accountable or prevented from sending further
messages.
10 CONCLUSION
We introduced tracing for E2E encrypted messaging. In this setting,
a messaging platform can recover and cryptographically verify the
path a message took as it was forwarded between users given a
report by one of the recipients. We gave two schemes for tracing
messages with different traceback targets: path to message source
and entire message forwarding tree. Implementation benchmarks
show both schemes are efficient and require the messaging platform
to store less than 100 bytes of additional data per message sent.
ACKNOWLEDGMENTS
This work was supported in part by NSF awards DGE-1650441 and
CNS-1704527.
REFERENCES
[1] 2009. Redis. https://redis.io/
[2] 2013. Signal. https://signal.org/
[3] 2013. Telegram. https://telegram.org/
[4] 2016. Rust Crypto. https://github.com/RustCrypto
[5] 2016. WhatsApp. https://www.whatsapp.com/
[6] Mihir Bellare and Phillip Rogaway. 2006. The Security of Triple Encryption and
[8] Dan Boneh, Craig Gentry, Ben Lynn, and Hovav Shacham. 2003. Aggregate and
[7] Dan Boneh and Matthew K. Franklin. 1999. An Efficient Public Key Traitor
a Framework for Code-Based Game-Playing Proofs. In EUROCRYPT.
Tracing Scheme. In CRYPTO.
Verifiably Encrypted Signatures from Bilinear Maps. In EUROCRYPT.
[9] Jan Camenisch, Ueli M. Maurer, and Markus Stadler. 1997. Digital Payment
Systems With Passive Anonymity-Revoking Trustees. Journal of Computer
Security (1997).
[10] David Cash, Stanislaw Jarecki, Charanjit S. Jutla, Hugo Krawczyk, Marcel-Catalin
Rosu, and Michael Steiner. 2013. Highly-Scalable Searchable Symmetric Encryp-
tion with Support for Boolean Queries. In CRYPTO.
[11] Benny Chor, Amos Fiat, and Moni Naor. 1994. Tracing Traitors. In CRYPTO.
[12] Reza Curtmola, Juan A. Garay, Seny Kamara, and Rafail Ostrovsky. 2006. Search-
able symmetric encryption: improved definitions and efficient constructions. In
CCS. ACM.
[13] Yevgeniy Dodis, Paul Grubbs, Thomas Ristenpart, and Joanne Woodage. 2018.
Fast Message Franking: From Invisible Salamanders to Encryptment. In CRYPTO.
technical
whitepaper.
https://fbnewsroomus.files.wordpress.com/2016/07/
messenger-secret-conversations-technical-whitepaper.pdf.
Secret Conversations
[14] Facebook.
[15] Yair Frankel, Yiannis Tsiounis, and Moti Yung. 1996. "Indirect Discourse Proof":
[16] R Stuart Geiger. 2016. Bot-based collective blocklists in Twitter: the counter-
Information,
[17] Paul Grubbs, Jiahui Lu, and Thomas Ristenpart. 2017. Message Franking via
Achieving Efficient Fair Off-Line E-cash. In ASIACRYPT.
public moderation of harassment in a networked public space.
Communication & Society 19, 6 (2016), 787–803.
Committing Authenticated Encryption. In CRYPTO.
protocols for faster anonymous blacklisting. In WPES. ACM.
[19] Mike Isaac and Kevin Roose. 2018. Disinformation Spreads on WhatsApp
Ahead of Brazilian Election. https://www.nytimes.com/2018/10/19/technology/
whatsapp-brazil-presidential-election.html
[18] Ryan Henry and Ian Goldberg. 2013. Thinking inside the BLAC box: smarter
[20] Dennis Kügler and Holger Vogt. 2002. Offline Payments with Auditable Tracing.
Messenger
2017.
[21] Joshua Lund. 2018. Technology preview: sealed sender for Signal.
https:
In Financial Cryptography (FC).
//signal.org/blog/sealed-sender/
[22] Alexis Madrigal. 2018. India’s Lynching Epidemic and the Problem With Blam-
ing Tech. https://www.theatlantic.com/technology/archive/2018/09/whatsapp/
571276/
[23] Farhad Manjoo. 2018. The Problem With Fixing WhatsApp? Human Nature
https://www.nytimes.com/2018/10/24/technology/
Might Get in the Way.
fixing-whatsapp-disinformation-human-nature.html
[24] Benjamin Mullin. 2017. The New York Times is teaming up with Alpha-
https://www.poynter.org/news/
bet’s Jigsaw to expand its comments.
new-york-times-teaming-alphabets-jigsaw-expand-its-comments
[25] Stefan Savage, David Wetherall, Anna R. Karlin, and Thomas E. Anderson. 2000.
[27] Edward J. Schwartz, David Brumley, and Jonathan M. McCune. 2010. Contractual
[26] Bruce Schneier and John Kelsey. 1999. Secure Audit Logs to Support Computer
Practical network support for IP traceback. In SIGCOMM.
Forensics. ACM Trans. Inf. Syst. Secur. 2, 2 (1999), 159–176.
Anonymity. In NDSS. The Internet Society.
[28] Binanda Sengupta, Yingjiu Li, Kai Bu, and Robert H. Deng. 2019. Privacy-
Preserving Network Path Validation. Cryptology ePrint Archive, Report 2019/407.
https://eprint.iacr.org/2019/407.
[29] Alex C. Snoeren. 2001. Hash-based IP traceback. In SIGCOMM.
[30] Dawn Xiaodong Song and Adrian Perrig. 2001. Advanced and Authenticated
Marking Schemes for IP Traceback. In INFOCOM.
[31] Nirvan Tyagi, Yossi Gilad, Derek Leung, Matei Zaharia, and Nickolai Zeldovich.
2017. Stadium: A Distributed Metadata-Private Messaging System. In SOSP.
ACM.
:
RoR-CPAA,bE,m
(K1, . . . , Km) ←$ KeyGenm
b′ ←$ AFn
return b′
Fn(i, M):
C1 ←$ EncKi (M)
C0 ←$ {0, 1}clen(|M|)
return Cb
Figure 11: Multi-key variant of Real-or-random chosen plaintext se-
curity game.
:
PRFA,1
F ,m
(K1, . . . , Km) ←$ KeyGenm
b′ ←$ AFn
return b′
Fn(i, X):
return FKi (X)
:
PRFA,0
F ,m
(ρ1, . . . ρm) ←$ Func(n, n)m
b′ ←$ AFn
return b′
Fn(i, X):
return ρi(X)
Figure 12: Multi-key variant of PRF security game.
[32] Jelle van den Hooff, David Lazar, Matei Zaharia, and Nickolai Zeldovich. 2015.
Vuvuzela: scalable private messaging resistant to traffic analysis. In SOSP. ACM.
[33] WhatsApp. [n. d.]. https://faq.whatsapp.com/en/android/26000165/
[34] David Isaac Wolinsky, Henry Corrigan-Gibbs, Bryan Ford, and Aaron Johnson.
2012. Dissent in Numbers: Making Strong Anonymity Scale. In OSDI. USENIX.
A CONFIDENTIALITY PROOF
First we recall the standard security notions needed in our proof.
The real-or-random chosen plaintext attack (RoR-CPA) extended
for multiple keys is defined in Figure 11. The adversary is tasked
with determining whether ciphertexts are generated through the
encryption algorithm or as a random bit string. The adversary’s
advantage is defined as
(cid:12)(cid:12)(cid:12)Pr(cid:104) RoR-CPAA,1
(cid:105)
− Pr(cid:104) RoR-CPAA,0
E,m ⇒ true
E,m ⇒ true
Adv
ror-cpa
E,m (A) =
The PRF security game extended for multiple keys is defined in
Figure 12. The adversary is tasked with determining whether it is
interacting with the PRF keyed on key i or a random function ρi.
The adversary’s advantage is defined as
(cid:12)(cid:12)(cid:12)Pr(cid:104) PRFA,1
F,m ⇒ true
(cid:105) − Pr(cid:104) PRFA,0
F,m ⇒ true
Adv
prf
F,m(A) =
(cid:105)(cid:12)(cid:12)(cid:12) .
(cid:105)(cid:12)(cid:12)(cid:12) .
A.1 Platform Trace Confidentiality
Theorem 1. Let MT be the message tracing scheme for path trace-
back defined in Figure 3 using hash function H. Then if H is modeled
as a random oracle, for any PTrCONF adversary A that makes at
most q oracle queries, we give adversary B and C such that
(C)