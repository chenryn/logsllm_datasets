lower than the cost for the naive all-overlay approach and 11% lower than the
all-native solution. This represents signiﬁcant saving, while being ﬂexible enough
to accommodate other constraints.
Table 2. The lowest cost for each strategy when unitN ativeCost = unitOverlayCost
AS # Number of All overlay All native Basis set Combination
overlay
nodes
21
17
32
15
28
1221
1755
3257
3967
6461
420
272
992
210
756
102
112
240
98
224
198
98
500
138
394
(n: native,
o: overlay)
98 (66 n, 32 o)
92 (42 n, 50 o)
222 (142 n, 80 o)
78 (46 n, 32 o)
210 (146 n, 64 o)
Amount of link-level overlap. In this section, we study the eﬀect of overlap
between overlay links over the optimal monitoring solution. As a measure, we
use the average number of overlay links that span a native link in the network.
We call this value the overlap coeﬃcient. For this analysis we use the results
from the ﬁrst experiment.
Table 3 demonstrates how the lowest cost solution, as given by our ILP, varies
with the amount of link-level overlap. In the table, Cost per overlay link rep-
resents the total monitoring cost divided by the number of overlay links. The
rows are sorted by increasing overlap coeﬃcient. We observe that in general, the
monitoring cost per overlay link decreases as overlap increases. However, the cost
per link value for AS 1221 is slightly higher than that of AS 3257 although the
former has a higher overlap coeﬃcient. This may suggest that increasing overlap
can only decrease the cost per link by a limited amount.
Multi-layer Monitoring of Overlay Networks
83
Table 3. Eﬀect of link-level overlap on the lowest total monitoring cost
AS
3967
1755
6461
3257
1221
Overlap coeﬃcient
Lowest total cost # of overlay links
Cost per link
8.59
9.21
12.80
17.08
18.33
78
92
210
222
98
210
272
756
992
420
0.37
0.34
0.28
0.22
0.23
Percentage of overlay nodes. In this experiment, we vary the fraction of
overlay nodes among all nodes in the network. We call this fraction overlay node
density. We examine two Rocketfuel topologies using ﬁve diﬀerent density values
from 0.1 to 0.5, and random overlay node placement. Our ILP gives the results
in Table 4 when unitN ativeCost = unitOverlayCost. This result is consistent
with the eﬀect of link-level overlap. As the overlay node density increases, link-
level overlap also increases, and the cost per overlay link decreases.
Table 4. Eﬀect of overlay node density on the optimal monitoring solution
Overlay node density Cost per link for AS 1755 Cost per link for AS 3967
0.1
0.2
0.3
0.4
0.5
0.75
0.34
0.25
0.15
0.12
0.71
0.37
0.28
0.17
0.13
5 Experimental Evaluation of Inference Errors
Composing an end-to-end measurement from other measurements can introduce
an error in the result. We refer to this as inference error. One source of error may
be packets traversing diﬀerent sequences of router functions. For example, an
end-to-end latency measurement probe may be forwarded along the fast path of
a router, while probes that measure the latency of native links may be forwarded
along the slow path. This makes the latter probe packets susceptible to processor
delays, thereby introducing additional latency. Furthermore, some native link
measurements may be inferred from overlay link measurements using arithmetic
operations. This too introduces estimation error.
We represent the inference error for overlay links by computing the absolute
relative estimation error. We compute this error value as a percentage:
× 100
Abs. Rel. Est. Error Percentage(e(cid:3)
|(cid:5)ρ(e(cid:3)) − ρ(e(cid:3))|
(9)
) =
ρ(e(cid:3))
where ρ(e(cid:3)) is the actual measurement result for e(cid:3) and (cid:5)ρ(e(cid:3)) is the inferred result
obtained through combining a diﬀerent set of measurements.
84
M. Demirci et al.
(a) Topology 1
(b) Topology 2
(c) Topology 3
Fig. 1. Three PlanetLab topologies we use. (a) represents a general AS topology. (b)
has a tree-like structure which can be found on some campus-wide networks such as [2].
(b) can be interpreted as a graph of two interconnected ASes. Native links are assigned
with diﬀerent OSPF costs to avoid multiple shortest paths.
To assess the extent of inference errors, we conducted experiments on Planet-
Lab [5] using three diﬀerent overlay topologies shown in Fig. 1. We implemented
these topologies as virtual networks on PlanetLab using PL-VINI, the VINI
[1] prototype running on PlanetLab. In each experiment, we picked 20 Plan-
etLab nodes from diﬀerent ASes as our native network and ran OSPF on this
network with PL-VINI. Note that we cannot control the inter AS routing of
these PlanetLab nodes. We treated the edges between these nodes on the PL-
VINI network as native links. We picked 8 nodes out of the 20 as our overlay
nodes, and assumed that these 8 nodes are fully connected to form an overlay
network.
For each topology, we ran 4 rounds of measurements at diﬀerent times. In
each round, we measured the delay on all native and all overlay links by simul-
taneously running 100 pings on every link at a frequency of 1 per second. We
calculated the delay from node a to node b as the average round-trip time over
all ping results for native or overlay link a − b.
In order to ﬁnd the optimal combination of links to monitor for these topolo-
gies, we ran our ILP on each of them with the objective of minimizing the total
number of measurements. The output of the ILP gave us a set of overlay and
native links to monitor. Using this output and the measurement results for the
corresponding topology, we ﬁrst inferred the measurements of the links that are
not monitored, and then calculated the errors in these inferences using Eq. 9. The
errors for all-native and basis set solutions are calculated in a similar manner.
Table 5 summarizes the results for all three topologies. The Cost column
represents the lowest possible monitoring cost that can be achieved by each
strategy. Max is the largest inference error observed in a certain strategy. M ni
is the inference error averaged over all inferred overlay links, while M na is the
error averaged over all the overlay links in the network, with the diﬀerence being
that direct overlay link measurements have no errors. Averaging over all overlay
links does not reduce the error in the case of all-native monitoring because in
this case all overlay links are inferred and none are measured directly. However,
Multi-layer Monitoring of Overlay Networks
85
Table 5. Costs and inference errors for diﬀerent monitoring strategies
Topology 1
Topology 2
Topology 3
Cost M ni M na Max Cost M ni M na Max Cost M ni M na Max
56
34 5.01 5.01 21.18 24 1.43 1.43 4.30 30 3.54 3.54 10.75
38 2.68 0.86 20.29 26 0.96 0.51 2.79 26 1.13 0.61 4.95
Combination 26 3.43 2.70 20.12 18 1.58 1.35 3.17 24 2.35 1.68 10.75
All-overlay
All-native
Basis set
56
0
0
0
0
0
0
0
56
0
0
M na < M ni in the basis set and lowest-cost combination strategies because
some overlay links are directly measured and these zero errors bring down M na.
Among the last three strategies, monitoring a combination of native and over-
lay links achieved the lowest cost, and monitoring a basis set of overlay links
resulted in the smallest error. However, we should note that if we use a diﬀerent
cost deﬁnition, such as the total number of native links carrying probe traﬃc,
these results may change signiﬁcantly. For instance in topology 3, the last strat-
egy uses a combination of 8 native and 16 overlay links, spanning a total of 42
native links , while the all-native solution spans 30 links and the basis set solu-
tion spans 52 native links. Our insight from these experiments suggests that in
general, all-native solutions minimize bandwidth consumption, basis overlay set
solutions minimize error, and using a combination of native and overlay links
allows reducing the total number of measurements with comparable errors.
r
o
r
r
E
 0.22
 0.2
 0.18
 0.16
 0.14
 0.12
 0.1
 0.08
 0.06
 0.04
 0.02
 0
r
o
r
r
E
 0.12
 0.1
 0.08
 0.06
 0.04
 0.02
 0
 0  5  10  15  20  25  30  35  40  45
Inferred links
(a) Topology 1
 0  5  10  15  20  25  30  35  40  45
Inferred links
(b) Topology 3
Fig. 2. Error rates of inferred overlay links
For the two topologies whose maximum errors are above 10%, we examine the
error distribution among the inferred overlay links as shown in Fig. 2. We sort the
inference errors from high to low and place them on the graphs from left to right.
It can be seen that in both cases a few inferred links produce high errors that
dominate the rest, increasing the mean error. If the ILP is aware of the overlay
links that incur a high error when they are inferred, it can choose to monitor
them directly and avoid these errors. Thus, adding certain error constraints to
the ILP is a plausible step to improve its performance.
86
M. Demirci et al.
6 Conclusions
In this work we have proposed multi-layer monitoring as a ﬂexible approach
for overlay network measurement. We focused on the speciﬁc issue of determin-
ing the optimal mix of native and overlay link monitoring. We show that the
overall cost of monitoring the network is the least when we allow native link
measurements, as well as end-to-end measurements. We present a novel ILP
formulation that when solved minimizes the cost of network monitoring with
the appropriate combination of end-to-end and native network measurements.
Through simulation studies, we observe that the optimal monitoring solution,
i.e. the set of native and overlay links that minimizes the total monitoring cost
while supplying suﬃcient information, depends on unit monitoring costs as well
as the selection and placement of overlay nodes. We also ﬁnd that the average
monitoring cost per overlay link is lower for topologies where there is a high
overlap between overlay links. Furthermore, we evaluate our approach through
PlanetLab experiments with a focus on the question of inference errors.
Future work in this area should include: 1) applying our approach to multi-
domain scenarios, 2) consideration of monitoring for metrics other than latency,
3) including error minimization as an objective in the optimization problem, 4)
extending multi-layer monitoring to include Layer 2, 5) considering problems of
dynamic monitoring which would allow changes in the monitoring mix over time
in response to changing network conditions or changes in overlay topology.
References
1. Bavier, A., et al.: In VINI veritas: realistic and controlled network experimentation.
In: Proceedings of ACM SIGCOMM, pp. 3–14 (2006)
2. CPR: Campus Wide Network Performance Monitoring and Recovery,
http://www.rnoc.gatech.edu/cpr
3. GNU Linear Programming Kit (GLPK), http://www.gnu.org/software/glpk
4. Madhyastha, H.V., et al.: iPlane: An Information Plane for Distributed Services. In:
OSDI, pp. 367–380 (2006)
5. Planetlab, http://www.planet-lab.org
6. Rocketfuel: An ISP Topology Mapping Engine,
http://www.cs.washington.edu/research/networking/rocketfuel/
7. Seetharaman, S., Ammar, M.: Overlay-friendly Native Network: A Contradiction in
Terms?. In: Proceedings of ACM HotNets-IV (November 2005)
8. Chen, Y., et al.: Algebra-based scalable overlay network monitoring: algorithms,
evaluation, and applications. IEEE/ACM Trans. Netw. 15(5), 1084–1097 (2007)