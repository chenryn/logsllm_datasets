set of user ID and individual liability pairs, and outputs 𝑃𝐷,
the public data committed on the PBB, and 𝑆𝐷, P’s private
data which is kept secret. Note that for each user 𝑢 ∈ U, 𝑖𝑑𝑢
and 𝑙𝑢 denote 𝑢’s ID and P’s liabilities to 𝑢, respectively.
• ProveTot: (𝐿, Π) ← ProveTot(𝐷𝐵, 𝑆𝐷). Executed by P, the
polynomial-time algorithm takes as input the data set 𝐷𝐵
and P’s private data 𝑆𝐷, and outputs P’s total liabilities 𝐿
and its associated proof Π.
Session 12D: Decentralized Cryptographic Protocols CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea3468• VerifyTot: {0, 1} ← VerifyTot(𝑃𝐷, 𝐿, Π). Given the total lia-
bilities 𝐿 and its associated proof Π, anyone can audit the
validity of 𝐿 according to the public data 𝑃𝐷 committed by
P on the PBB. The polynomial-time algorithm returns 1 if
the verification succeeds and 0 otherwise.
• Prove: 𝜋 ← Prove(𝐷𝐵, 𝑆𝐷, 𝑖𝑑). Executed by the prover, the
polynomial-time algorithm takes as input the data set 𝐷𝐵,
P’s private data 𝑆𝐷 and a user ID 𝑖𝑑, and outputs a proof 𝜋
indicating the inclusion of P’s liabilities to the user in the
total liabilities.
• Verify: {0, 1} ← Verify(𝑃𝐷, 𝑖𝑑, 𝑙, 𝜋). Executed by a user, the
polynomial-time algorithm takes as input the public data
𝑃𝐷 committed by P, the user’s ID 𝑖𝑑, P’s liabilities to the
user 𝑙 and the associated inclusion proof 𝜋. It returns 1 if the
verification succeeds and 0 otherwise.
A PoL is a collection of the algorithms as defined above, i.e.,
PoL = (Setup, ProveTot, VerifyTot, Prove, Verify). Note that we de-
fine ProveTot and VerifyTot as above for simplicity and generality.
In some scenarios, it may not be the exact value of P’s total lia-
bilities that is of concern, but the range the total liabilities falls
in or its comparison with another value. Depending on the actual
requirements of a particular application, instead of revealing the
total liabilities for verification, the prover might compute different
verifiable claims about it. For instance, if we are only interested
in solvency but not the exact values of liabilities and assets, the
prover may generate a zero-knowledge proof showing that the total
liabilities are no more than the total assets. We will go into details
of these claims in section 4.4.4.
3.3 Threat Model
A malicious prover potentially corrupting any number of users may
attempt to reduce his/her total liabilities, e.g., via manipulating or
discarding the liabilities to non-corrupted users. However, there
is no motivation for the adversarial prover to increase the total
liabilities. Note that this assumption on incentives is key to PoL,
and it relaxes the security requirements so simpler solutions are
possible. Without this, a valid PoL scheme might be more compli-
cated because it needs to further prevent a prover from raising the
value by inserting or duplicating positive entries.
Users can establish secure communication channels with P and
authenticate their identities. The authentication process is out of
scope for this paper. Meanwhile, users may be corrupted by an
adversary to break privacy, i.e., the adversary attempts to learn
more information than she should from the corrupted users, such
as the number of users or P’s liabilities to non-corrupted users.
The PBB provides a consistent view of the data on it to everyone.
Anyone can read and write data on the PBB and the content cannot
be tampered with. In PoL, the public data 𝑃𝐷 is written on the PBB.
This is necessary to prevent the malicious prover from showing
inconsistent commitments to different users.
3.4 Security Definitions
Definition 3.1. Valid data set. A dataset 𝐷𝐵 = {(𝑖𝑑𝑢, 𝑙𝑢)}𝑢∈U is
(𝑁 , 𝑀𝑎𝑥𝐿)-valid, 𝑁 and 𝑀𝑎𝑥𝐿 being two positive integers, iff the
following conditions are met:
• there are at most 𝑁 users, i.e., 𝑛 = |𝐷𝐵| ≤ 𝑁 ;
• for any two distinct users 𝑢, 𝑢′ ∈ U, 𝑖𝑑𝑢 ≠ 𝑖𝑑𝑢′;
• for any user 𝑢 ∈ U, 0 ≤ 𝑙𝑢 < 𝑀𝑎𝑥𝐿.
Denote by PoL(𝑁 , 𝑀𝑎𝑥𝐿) a PoL protocol targeted for all of the
(𝑁 , 𝑀𝑎𝑥𝐿)-valid data sets. A PoL(𝑁 , 𝑀𝑎𝑥𝐿) is secure iff both com-
pleteness and soundness as defined below are satisfied:
Definition 3.2. Completeness. A PoL(𝑁 , 𝑀𝑎𝑥𝐿) is complete if
for any (𝑁 , 𝑀𝑎𝑥𝐿)-valid data set 𝐷𝐵,
Pr[(𝑃𝐷, 𝑆𝐷) $← Setup(1𝜅, 𝐷𝐵),
(𝐿, Π) ← ProveTot(𝐷𝐵, 𝑆𝐷),
∀𝑢 ∈ U, 𝜋𝑢 ← Prove(𝐷𝐵, 𝑆𝐷, 𝑖𝑑𝑢) :
VerifyTot(𝑃𝐷, 𝐿, Π) = 1∧
∀𝑢 ∈ U : Verify(𝑃𝐷, 𝑖𝑑𝑢, 𝑙𝑢, 𝜋𝑢) = 1∧
𝐿 ≥∑︁
𝑢∈U 𝑙𝑢] = 1
Completeness guarantees that if all parties are honest and follow
the protocol, the verifications should all succeed and the proved to-
tal liabilities should be no less than the sum of the prover’s liabilities
to individual users.
Definition 3.3. Soundness. A PoL(𝑁 , 𝑀𝑎𝑥𝐿) is sound if for any
(𝑁 , 𝑀𝑎𝑥𝐿)-valid data set 𝐷𝐵, for any p.p.t. adversarial prover A∗
potentially corrupting any number of users, there exists a negligible
function 𝜖(·) such that for any subset 𝑉 of non-corrupted users,
Pr[(𝑃𝐷, 𝐿, Π, {𝜋𝑢 }𝑢∈𝑉 ) $← A∗(1𝜅, 𝐷𝐵) :
VerifyTot(𝑃𝐷, 𝐿, Π) = 1∧
∀𝑢 ∈ 𝑉 , Verify(𝑃𝐷, 𝑖𝑑𝑢, 𝑙𝑢, 𝜋𝑢) = 1∧
𝐿 <∑︁
𝑙𝑢] ≤ 𝜖(𝜅)
𝑢∈𝑉
Soundness guarantees that a computationally bounded adversar-
ial prover is not able to cheat on the total liabilities. In particular,
for any subset of non-corrupted users that successfully verify the
inclusion of the prover’s liabilities to them, if the committed total
liabilities is associated with a valid proof, its value is no less than
the sum of the prover’s liabilities to these users.
Note that we define the probability over any subset of honest
users instead of the entire set of them to capture the nature of dis-
tributed auditing. In other words, the amount of P’s total liabilities
is guaranteed with respect to the users that perform the verification.
If we define it over the entire set of honest users instead, the total
liabilities won’t be bounded when some user is given an invalid
proof (i.e., Verify(·) returns 0). A protocol satisfying so-defined
soundness is not useful in practice because this particular user
might never perform verification. In this scenario, other users will
not detect and report a misconduct of the prover even if the amount
of total liabilities committed is an arbitrary value. In contrast, with
our soundness definition, the committed total liabilities is at least
bounded by the total liabilities to users who verify.
PoL falls under the more general category of transparency solu-
tions where a prover trusted for privacy but not honesty maintains
a dataset. The general notion of soundness in most of these works,
e.g., SEEMless [21], is non-equivocation. Our soundness is an ana-
log of non-equivocation, making the values of users that verify
concretely counted in the total amount, thus lower-bounding the
total to the sum of users that verify. We restrict ourselves to non-
equivocation because this is the only known definition achievable
Session 12D: Decentralized Cryptographic Protocols CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea3469without generic SNARKs which would lead to a significant degra-
dation in efficiency and mobile-friendliness.
3.5 Privacy Definitions
We define user privacy against 𝑉 ⊆ U, a subset of users corrupted
by an adversary. The adversary has access to the ID and liability
pairs of users in 𝑉 . She can also send queries to the prover for
inclusion proofs of P’s liabilities to the corrupted users, so pos-
sesses 𝜋𝑢 ← Prove(𝐷𝐵, 𝑆𝐷, 𝑖𝑑𝑢) for all 𝑢 ∈ 𝑉 . We aim to guarantee
that the view of the adversary throughout an execution of PoL
can be simulated by a simulator given limited information. In par-
ticular, in an execution of PoL upon a valid data set 𝐷𝐵, letting
(𝑃𝐷, 𝑆𝐷) $← Setup(1𝜅, 𝐷𝐵) and 𝜋𝑢 ← Prove(𝐷𝐵, 𝑆𝐷, 𝑖𝑑𝑢) for all
𝑢 ∈ 𝑉 , the view of the adversary corrupting 𝑉 ⊆ U is viewuser
=
(𝑃𝐷, 𝐷𝐵[𝑉], {𝜋𝑢}𝑢∈𝑉 ). Note that 𝐷𝐵[𝑉] = {(𝑖𝑑𝑢, 𝑙𝑢)}𝑢∈𝑉 , which
is the data set of user ID and liability pairs of users in 𝑉 ⊆ U. User
privacy against 𝑉 corrupted by an adversary requires that viewuser
can be simulated by a p.p.t. simulator that does not have access to
𝐷𝐵 but only to 1𝜅, 𝐷𝐵[𝑉] and the leakage function Φuser(𝐷𝐵, 𝑉).
More formally:
Definition 3.4. User privacy. A PoL(𝑁 , 𝑀𝑎𝑥𝐿) is Φuser-private
against 𝑉 ⊆ U, a subset of users corrupted by an adversary, if
there exists a p.p.t. simulator S such that for any (𝑁 , 𝑀𝑎𝑥𝐿)-valid
data set 𝐷𝐵, the following two distributions are computationally
indistinguishable:
𝑉
𝑉
• {(𝑃𝐷, 𝑆𝐷) $← Setup(1𝜅, 𝐷𝐵),∀𝑢 ∈ 𝑉 , 𝜋𝑢 ← Prove(𝐷𝐵, 𝑆𝐷,
𝑖𝑑𝑢) : 𝑃𝐷, 𝐷𝐵[𝑉], {𝜋𝑢}𝑢∈𝑉 }
• {S(1𝜅, 𝐷𝐵[𝑉], Φuser(𝐷𝐵, 𝑉))}
We also define auditor privacy against an adversary that has ac-
cess to the output of ProveTot and corrupts a subset of users 𝑉 ⊆ U.
Similarly, in an execution of PoL upon a valid data set 𝐷𝐵, let-
ting (𝑃𝐷, 𝑆𝐷) $← Setup(1𝜅, 𝐷𝐵), (𝐿, Π) ← ProveTot(𝐷𝐵, 𝑆𝐷) and
𝜋𝑢 ← Prove(𝐷𝐵, 𝑆𝐷, 𝑖𝑑𝑢) for all 𝑢 ∈ 𝑉 , the view of the adversary
= (𝑃𝐷, 𝐿, Π, 𝐷𝐵[𝑉], {𝜋𝑢}𝑢∈𝑉 ).
corrupting 𝑉 ⊆ U is viewauditor
Auditor privacy requires that viewauditor
can be simulated by a
p.p.t. simulator that does not have access to 𝐷𝐵 but only to 1𝜅, 𝐿,
𝐷𝐵[𝑉] and the leakage function Φauditor(𝐷𝐵, 𝑉).
Definition 3.5. Auditor privacy. A PoL(𝑁 , 𝑀𝑎𝑥𝐿) is Φauditor-
private against any malicious auditor corrupting any subset of
users 𝑉 ⊆ U, if there exists a p.p.t. simulator S such that for any
(𝑁 , 𝑀𝑎𝑥𝐿)-valid data set 𝐷𝐵, the following two distributions are
computationally indistinguishable:
𝑉
𝑉
$← Setup(1𝜅, 𝐷𝐵), (𝐿, Π) ← ProveTot(𝐷𝐵, 𝑆𝐷),
• {(𝑃𝐷, 𝑆𝐷)
∀𝑢 ∈ 𝑉 , 𝜋𝑢 ← Prove(𝐷𝐵, 𝑆𝐷, 𝑖𝑑𝑢) :
𝑃𝐷, 𝐿, Π, 𝐷𝐵[𝑉], {𝜋𝑢}𝑢∈𝑉 }
• {S(1𝜅, 𝐿, 𝐷𝐵[𝑉], Φauditor(𝐷𝐵, 𝑉))}
Note that the privacy definitions above cover the case where
everything can be public, i.e., 𝐷𝐵 ⊆ Φuser/auditor(𝐷𝐵, 𝑉). For ex-
ample, in charity applications, the donations of each donor might
be public. There are also special voting systems, e.g., parliaments,
where for transparency reasons, all votes should be revealed.
4 DESIGN SPECIFICATIONS
In this section, we present concrete PoL schemes. First, we propose
DAPOL+, a PoL protocol extending DAPOL but fixing its privacy
issue, getting rid of VRF and deterministic mapping as mentioned
in section 2. We then formally prove that DAPOL+ protocol satisfies
the security and privacy properties as defined earlier. Second, we
discuss how to resolve disputes in DAPOL+. Third, we discuss dif-
ferent accumulator variants that can be used in DAPOL+ and their
trade-offs. Fourth, we consider other additional features potentially
desired by different applications and propose solutions.
4.1 DAPOL+
Figure 2: Padded height-3 DAPOL+ tree.
Recall that among existing schemes of PoL [13, 19, 20, 25, 73],
DAPOL aims to provide the strongest security and privacy guaran-
tees. However, there is a privacy issue in their construction of the
SMT, i.e., the padding nodes are distinguishable from tree nodes
of other types in their design, which could leak the number of
users. Moreover, they mentioned utilizing VRFs in the construction
of SMT nodes, although as an alternative, without analyzing the
necessity of such expensive cryptographic primitives. In addition,
each user is deterministically mapped to a leaf node in the SMT in
DAPOL, which requires the height of the SMT to be sufficiently
large to avoid collision.
We propose DAPOL+, by extending DAPOL with the basic idea
of using SMT for privacy and efficiency benefits, and further making
the following improvements:
friendliness;
• fixing the privacy leak in DAPOL;
• getting rid of VRF for efficiency, mobile and post-quantum
• utilizing random mapping instead of deterministic shuffling,
thus allowing smaller SMT heights and proof size (SMT
variants discussed in section 4.3).
DAPOL+ provides provable security and privacy.
Briefly speaking, in DAPOL+, the prover first makes a commit-
ment to the total liabilities on the PBB so that all users have the
same view of the commitment and the prover cannot open to differ-
ent values afterwards. Each user then may check if the amount of
P’s liabilities to him/her is included in the total liabilities to make
sure the prover is not cheating and the amount of total liabilities
is properly bounded. To generate a proof of inclusion, DAPOL+
Session 12D: Decentralized Cryptographic Protocols CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea3470leverages homomorphic Pedersen commitments to hide the exact
values of the prover’s liabilities, and an SMT as an accumulator to
conceal the number of users and minimize usage of the PBB. In
particular, the inclusion proof is a Merkle proof in a summation
Merkle tree together with range proofs for all nodes on the Merkle
path to guarantee no overflow in the sum of the committed values
when multiplying the Pedersen commitments.
Denote by ProtDAPOL+(𝑁 , 𝑀𝑎𝑥𝐿) the main protocol of DAPOL+
targeted for all (𝑁 , 𝑀𝑎𝑥𝐿)-valid data sets. We now present the
details of ProtDAPOL+(𝑁 , 𝑀𝑎𝑥𝐿) in the following flow, with pseu-
docode in appendix D:
(1) Select public protocol parameters.
(2) Set up, i.e., generate the SMT and commitments.
(3) Prove the total liabilities.