set of user ID and individual liability pairs, and outputs ğ‘ƒğ·,
the public data committed on the PBB, and ğ‘†ğ·, Pâ€™s private
data which is kept secret. Note that for each user ğ‘¢ âˆˆ U, ğ‘–ğ‘‘ğ‘¢
and ğ‘™ğ‘¢ denote ğ‘¢â€™s ID and Pâ€™s liabilities to ğ‘¢, respectively.
â€¢ ProveTot: (ğ¿, Î ) â† ProveTot(ğ·ğµ, ğ‘†ğ·). Executed by P, the
polynomial-time algorithm takes as input the data set ğ·ğµ
and Pâ€™s private data ğ‘†ğ·, and outputs Pâ€™s total liabilities ğ¿
and its associated proof Î .
Session 12D: Decentralized Cryptographic Protocols CCS â€™21, November 15â€“19, 2021, Virtual Event, Republic of Korea3468â€¢ VerifyTot: {0, 1} â† VerifyTot(ğ‘ƒğ·, ğ¿, Î ). Given the total lia-
bilities ğ¿ and its associated proof Î , anyone can audit the
validity of ğ¿ according to the public data ğ‘ƒğ· committed by
P on the PBB. The polynomial-time algorithm returns 1 if
the verification succeeds and 0 otherwise.
â€¢ Prove: ğœ‹ â† Prove(ğ·ğµ, ğ‘†ğ·, ğ‘–ğ‘‘). Executed by the prover, the
polynomial-time algorithm takes as input the data set ğ·ğµ,
Pâ€™s private data ğ‘†ğ· and a user ID ğ‘–ğ‘‘, and outputs a proof ğœ‹
indicating the inclusion of Pâ€™s liabilities to the user in the
total liabilities.
â€¢ Verify: {0, 1} â† Verify(ğ‘ƒğ·, ğ‘–ğ‘‘, ğ‘™, ğœ‹). Executed by a user, the
polynomial-time algorithm takes as input the public data
ğ‘ƒğ· committed by P, the userâ€™s ID ğ‘–ğ‘‘, Pâ€™s liabilities to the
user ğ‘™ and the associated inclusion proof ğœ‹. It returns 1 if the
verification succeeds and 0 otherwise.
A PoL is a collection of the algorithms as defined above, i.e.,
PoL = (Setup, ProveTot, VerifyTot, Prove, Verify). Note that we de-
fine ProveTot and VerifyTot as above for simplicity and generality.
In some scenarios, it may not be the exact value of Pâ€™s total lia-
bilities that is of concern, but the range the total liabilities falls
in or its comparison with another value. Depending on the actual
requirements of a particular application, instead of revealing the
total liabilities for verification, the prover might compute different
verifiable claims about it. For instance, if we are only interested
in solvency but not the exact values of liabilities and assets, the
prover may generate a zero-knowledge proof showing that the total
liabilities are no more than the total assets. We will go into details
of these claims in section 4.4.4.
3.3 Threat Model
A malicious prover potentially corrupting any number of users may
attempt to reduce his/her total liabilities, e.g., via manipulating or
discarding the liabilities to non-corrupted users. However, there
is no motivation for the adversarial prover to increase the total
liabilities. Note that this assumption on incentives is key to PoL,
and it relaxes the security requirements so simpler solutions are
possible. Without this, a valid PoL scheme might be more compli-
cated because it needs to further prevent a prover from raising the
value by inserting or duplicating positive entries.
Users can establish secure communication channels with P and
authenticate their identities. The authentication process is out of
scope for this paper. Meanwhile, users may be corrupted by an
adversary to break privacy, i.e., the adversary attempts to learn
more information than she should from the corrupted users, such
as the number of users or Pâ€™s liabilities to non-corrupted users.
The PBB provides a consistent view of the data on it to everyone.
Anyone can read and write data on the PBB and the content cannot
be tampered with. In PoL, the public data ğ‘ƒğ· is written on the PBB.
This is necessary to prevent the malicious prover from showing
inconsistent commitments to different users.
3.4 Security Definitions
Definition 3.1. Valid data set. A dataset ğ·ğµ = {(ğ‘–ğ‘‘ğ‘¢, ğ‘™ğ‘¢)}ğ‘¢âˆˆU is
(ğ‘ , ğ‘€ğ‘ğ‘¥ğ¿)-valid, ğ‘ and ğ‘€ğ‘ğ‘¥ğ¿ being two positive integers, iff the
following conditions are met:
â€¢ there are at most ğ‘ users, i.e., ğ‘› = |ğ·ğµ| â‰¤ ğ‘ ;
â€¢ for any two distinct users ğ‘¢, ğ‘¢â€² âˆˆ U, ğ‘–ğ‘‘ğ‘¢ â‰  ğ‘–ğ‘‘ğ‘¢â€²;
â€¢ for any user ğ‘¢ âˆˆ U, 0 â‰¤ ğ‘™ğ‘¢ < ğ‘€ğ‘ğ‘¥ğ¿.
Denote by PoL(ğ‘ , ğ‘€ğ‘ğ‘¥ğ¿) a PoL protocol targeted for all of the
(ğ‘ , ğ‘€ğ‘ğ‘¥ğ¿)-valid data sets. A PoL(ğ‘ , ğ‘€ğ‘ğ‘¥ğ¿) is secure iff both com-
pleteness and soundness as defined below are satisfied:
Definition 3.2. Completeness. A PoL(ğ‘ , ğ‘€ğ‘ğ‘¥ğ¿) is complete if
for any (ğ‘ , ğ‘€ğ‘ğ‘¥ğ¿)-valid data set ğ·ğµ,
Pr[(ğ‘ƒğ·, ğ‘†ğ·) $â† Setup(1ğœ…, ğ·ğµ),
(ğ¿, Î ) â† ProveTot(ğ·ğµ, ğ‘†ğ·),
âˆ€ğ‘¢ âˆˆ U, ğœ‹ğ‘¢ â† Prove(ğ·ğµ, ğ‘†ğ·, ğ‘–ğ‘‘ğ‘¢) :
VerifyTot(ğ‘ƒğ·, ğ¿, Î ) = 1âˆ§
âˆ€ğ‘¢ âˆˆ U : Verify(ğ‘ƒğ·, ğ‘–ğ‘‘ğ‘¢, ğ‘™ğ‘¢, ğœ‹ğ‘¢) = 1âˆ§
ğ¿ â‰¥âˆ‘ï¸
ğ‘¢âˆˆU ğ‘™ğ‘¢] = 1
Completeness guarantees that if all parties are honest and follow
the protocol, the verifications should all succeed and the proved to-
tal liabilities should be no less than the sum of the proverâ€™s liabilities
to individual users.
Definition 3.3. Soundness. A PoL(ğ‘ , ğ‘€ğ‘ğ‘¥ğ¿) is sound if for any
(ğ‘ , ğ‘€ğ‘ğ‘¥ğ¿)-valid data set ğ·ğµ, for any p.p.t. adversarial prover Aâˆ—
potentially corrupting any number of users, there exists a negligible
function ğœ–(Â·) such that for any subset ğ‘‰ of non-corrupted users,
Pr[(ğ‘ƒğ·, ğ¿, Î , {ğœ‹ğ‘¢ }ğ‘¢âˆˆğ‘‰ ) $â† Aâˆ—(1ğœ…, ğ·ğµ) :
VerifyTot(ğ‘ƒğ·, ğ¿, Î ) = 1âˆ§
âˆ€ğ‘¢ âˆˆ ğ‘‰ , Verify(ğ‘ƒğ·, ğ‘–ğ‘‘ğ‘¢, ğ‘™ğ‘¢, ğœ‹ğ‘¢) = 1âˆ§
ğ¿ <âˆ‘ï¸
ğ‘™ğ‘¢] â‰¤ ğœ–(ğœ…)
ğ‘¢âˆˆğ‘‰
Soundness guarantees that a computationally bounded adversar-
ial prover is not able to cheat on the total liabilities. In particular,
for any subset of non-corrupted users that successfully verify the
inclusion of the proverâ€™s liabilities to them, if the committed total
liabilities is associated with a valid proof, its value is no less than
the sum of the proverâ€™s liabilities to these users.
Note that we define the probability over any subset of honest
users instead of the entire set of them to capture the nature of dis-
tributed auditing. In other words, the amount of Pâ€™s total liabilities
is guaranteed with respect to the users that perform the verification.
If we define it over the entire set of honest users instead, the total
liabilities wonâ€™t be bounded when some user is given an invalid
proof (i.e., Verify(Â·) returns 0). A protocol satisfying so-defined
soundness is not useful in practice because this particular user
might never perform verification. In this scenario, other users will
not detect and report a misconduct of the prover even if the amount
of total liabilities committed is an arbitrary value. In contrast, with
our soundness definition, the committed total liabilities is at least
bounded by the total liabilities to users who verify.
PoL falls under the more general category of transparency solu-
tions where a prover trusted for privacy but not honesty maintains
a dataset. The general notion of soundness in most of these works,
e.g., SEEMless [21], is non-equivocation. Our soundness is an ana-
log of non-equivocation, making the values of users that verify
concretely counted in the total amount, thus lower-bounding the
total to the sum of users that verify. We restrict ourselves to non-
equivocation because this is the only known definition achievable
Session 12D: Decentralized Cryptographic Protocols CCS â€™21, November 15â€“19, 2021, Virtual Event, Republic of Korea3469without generic SNARKs which would lead to a significant degra-
dation in efficiency and mobile-friendliness.
3.5 Privacy Definitions
We define user privacy against ğ‘‰ âŠ† U, a subset of users corrupted
by an adversary. The adversary has access to the ID and liability
pairs of users in ğ‘‰ . She can also send queries to the prover for
inclusion proofs of Pâ€™s liabilities to the corrupted users, so pos-
sesses ğœ‹ğ‘¢ â† Prove(ğ·ğµ, ğ‘†ğ·, ğ‘–ğ‘‘ğ‘¢) for all ğ‘¢ âˆˆ ğ‘‰ . We aim to guarantee
that the view of the adversary throughout an execution of PoL
can be simulated by a simulator given limited information. In par-
ticular, in an execution of PoL upon a valid data set ğ·ğµ, letting
(ğ‘ƒğ·, ğ‘†ğ·) $â† Setup(1ğœ…, ğ·ğµ) and ğœ‹ğ‘¢ â† Prove(ğ·ğµ, ğ‘†ğ·, ğ‘–ğ‘‘ğ‘¢) for all
ğ‘¢ âˆˆ ğ‘‰ , the view of the adversary corrupting ğ‘‰ âŠ† U is viewuser
=
(ğ‘ƒğ·, ğ·ğµ[ğ‘‰], {ğœ‹ğ‘¢}ğ‘¢âˆˆğ‘‰ ). Note that ğ·ğµ[ğ‘‰] = {(ğ‘–ğ‘‘ğ‘¢, ğ‘™ğ‘¢)}ğ‘¢âˆˆğ‘‰ , which
is the data set of user ID and liability pairs of users in ğ‘‰ âŠ† U. User
privacy against ğ‘‰ corrupted by an adversary requires that viewuser
can be simulated by a p.p.t. simulator that does not have access to
ğ·ğµ but only to 1ğœ…, ğ·ğµ[ğ‘‰] and the leakage function Î¦user(ğ·ğµ, ğ‘‰).
More formally:
Definition 3.4. User privacy. A PoL(ğ‘ , ğ‘€ğ‘ğ‘¥ğ¿) is Î¦user-private
against ğ‘‰ âŠ† U, a subset of users corrupted by an adversary, if
there exists a p.p.t. simulator S such that for any (ğ‘ , ğ‘€ğ‘ğ‘¥ğ¿)-valid
data set ğ·ğµ, the following two distributions are computationally
indistinguishable:
ğ‘‰
ğ‘‰
â€¢ {(ğ‘ƒğ·, ğ‘†ğ·) $â† Setup(1ğœ…, ğ·ğµ),âˆ€ğ‘¢ âˆˆ ğ‘‰ , ğœ‹ğ‘¢ â† Prove(ğ·ğµ, ğ‘†ğ·,
ğ‘–ğ‘‘ğ‘¢) : ğ‘ƒğ·, ğ·ğµ[ğ‘‰], {ğœ‹ğ‘¢}ğ‘¢âˆˆğ‘‰ }
â€¢ {S(1ğœ…, ğ·ğµ[ğ‘‰], Î¦user(ğ·ğµ, ğ‘‰))}
We also define auditor privacy against an adversary that has ac-
cess to the output of ProveTot and corrupts a subset of users ğ‘‰ âŠ† U.
Similarly, in an execution of PoL upon a valid data set ğ·ğµ, let-
ting (ğ‘ƒğ·, ğ‘†ğ·) $â† Setup(1ğœ…, ğ·ğµ), (ğ¿, Î ) â† ProveTot(ğ·ğµ, ğ‘†ğ·) and
ğœ‹ğ‘¢ â† Prove(ğ·ğµ, ğ‘†ğ·, ğ‘–ğ‘‘ğ‘¢) for all ğ‘¢ âˆˆ ğ‘‰ , the view of the adversary
= (ğ‘ƒğ·, ğ¿, Î , ğ·ğµ[ğ‘‰], {ğœ‹ğ‘¢}ğ‘¢âˆˆğ‘‰ ).
corrupting ğ‘‰ âŠ† U is viewauditor
Auditor privacy requires that viewauditor
can be simulated by a
p.p.t. simulator that does not have access to ğ·ğµ but only to 1ğœ…, ğ¿,
ğ·ğµ[ğ‘‰] and the leakage function Î¦auditor(ğ·ğµ, ğ‘‰).
Definition 3.5. Auditor privacy. A PoL(ğ‘ , ğ‘€ğ‘ğ‘¥ğ¿) is Î¦auditor-
private against any malicious auditor corrupting any subset of
users ğ‘‰ âŠ† U, if there exists a p.p.t. simulator S such that for any
(ğ‘ , ğ‘€ğ‘ğ‘¥ğ¿)-valid data set ğ·ğµ, the following two distributions are
computationally indistinguishable:
ğ‘‰
ğ‘‰
$â† Setup(1ğœ…, ğ·ğµ), (ğ¿, Î ) â† ProveTot(ğ·ğµ, ğ‘†ğ·),
â€¢ {(ğ‘ƒğ·, ğ‘†ğ·)
âˆ€ğ‘¢ âˆˆ ğ‘‰ , ğœ‹ğ‘¢ â† Prove(ğ·ğµ, ğ‘†ğ·, ğ‘–ğ‘‘ğ‘¢) :
ğ‘ƒğ·, ğ¿, Î , ğ·ğµ[ğ‘‰], {ğœ‹ğ‘¢}ğ‘¢âˆˆğ‘‰ }
â€¢ {S(1ğœ…, ğ¿, ğ·ğµ[ğ‘‰], Î¦auditor(ğ·ğµ, ğ‘‰))}
Note that the privacy definitions above cover the case where
everything can be public, i.e., ğ·ğµ âŠ† Î¦user/auditor(ğ·ğµ, ğ‘‰). For ex-
ample, in charity applications, the donations of each donor might
be public. There are also special voting systems, e.g., parliaments,
where for transparency reasons, all votes should be revealed.
4 DESIGN SPECIFICATIONS
In this section, we present concrete PoL schemes. First, we propose
DAPOL+, a PoL protocol extending DAPOL but fixing its privacy
issue, getting rid of VRF and deterministic mapping as mentioned
in section 2. We then formally prove that DAPOL+ protocol satisfies
the security and privacy properties as defined earlier. Second, we
discuss how to resolve disputes in DAPOL+. Third, we discuss dif-
ferent accumulator variants that can be used in DAPOL+ and their
trade-offs. Fourth, we consider other additional features potentially
desired by different applications and propose solutions.
4.1 DAPOL+
Figure 2: Padded height-3 DAPOL+ tree.
Recall that among existing schemes of PoL [13, 19, 20, 25, 73],
DAPOL aims to provide the strongest security and privacy guaran-
tees. However, there is a privacy issue in their construction of the
SMT, i.e., the padding nodes are distinguishable from tree nodes
of other types in their design, which could leak the number of
users. Moreover, they mentioned utilizing VRFs in the construction
of SMT nodes, although as an alternative, without analyzing the
necessity of such expensive cryptographic primitives. In addition,
each user is deterministically mapped to a leaf node in the SMT in
DAPOL, which requires the height of the SMT to be sufficiently
large to avoid collision.
We propose DAPOL+, by extending DAPOL with the basic idea
of using SMT for privacy and efficiency benefits, and further making
the following improvements:
friendliness;
â€¢ fixing the privacy leak in DAPOL;
â€¢ getting rid of VRF for efficiency, mobile and post-quantum
â€¢ utilizing random mapping instead of deterministic shuffling,
thus allowing smaller SMT heights and proof size (SMT
variants discussed in section 4.3).
DAPOL+ provides provable security and privacy.
Briefly speaking, in DAPOL+, the prover first makes a commit-
ment to the total liabilities on the PBB so that all users have the
same view of the commitment and the prover cannot open to differ-
ent values afterwards. Each user then may check if the amount of
Pâ€™s liabilities to him/her is included in the total liabilities to make
sure the prover is not cheating and the amount of total liabilities
is properly bounded. To generate a proof of inclusion, DAPOL+
Session 12D: Decentralized Cryptographic Protocols CCS â€™21, November 15â€“19, 2021, Virtual Event, Republic of Korea3470leverages homomorphic Pedersen commitments to hide the exact
values of the proverâ€™s liabilities, and an SMT as an accumulator to
conceal the number of users and minimize usage of the PBB. In
particular, the inclusion proof is a Merkle proof in a summation
Merkle tree together with range proofs for all nodes on the Merkle
path to guarantee no overflow in the sum of the committed values
when multiplying the Pedersen commitments.
Denote by ProtDAPOL+(ğ‘ , ğ‘€ğ‘ğ‘¥ğ¿) the main protocol of DAPOL+
targeted for all (ğ‘ , ğ‘€ğ‘ğ‘¥ğ¿)-valid data sets. We now present the
details of ProtDAPOL+(ğ‘ , ğ‘€ğ‘ğ‘¥ğ¿) in the following flow, with pseu-
docode in appendix D:
(1) Select public protocol parameters.
(2) Set up, i.e., generate the SMT and commitments.
(3) Prove the total liabilities.