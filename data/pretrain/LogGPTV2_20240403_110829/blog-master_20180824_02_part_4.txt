1阶段，单条SQL涉及9个shard  
```  
transaction type: ./test.sql  
scaling factor: 1  
query mode: prepared  
number of clients: 128  
number of threads: 128  
duration: 120 s  
number of transactions actually processed: 2449586  
latency average = 6.269 ms  
latency stddev = 4.968 ms  
tps = 20407.507503 (including connections establishing)  
tps = 20412.584813 (excluding connections establishing)  
script statistics:  
 - statement latencies in milliseconds:  
         0.002  \set id random(1,1000000000)  
         6.269  insert into test values (:id),(:id+1),(:id+2),(:id+3),(:id+4),(:id+5),(:id+6),(:id+7),(:id+8);  
```  
1阶段，涉及2个shard。单个QUERY涉及的SHARD越多，效率越低。  
```  
transaction type: ./test.sql  
scaling factor: 1  
query mode: prepared  
number of clients: 128  
number of threads: 128  
duration: 120 s  
number of transactions actually processed: 7894772  
latency average = 1.945 ms  
latency stddev = 2.312 ms  
tps = 65769.534466 (including connections establishing)  
tps = 65784.907845 (excluding connections establishing)  
script statistics:  
 - statement latencies in milliseconds:  
         0.002  \set id random(1,1000000000)  
         1.946  insert into test values (:id),(:id),(:id),(:id),(:id),(:id),(:id),(:id),(:id+8);  
```  
1阶段，涉及1个shard。效率最高。(如果客户端能够拿到分布算法，分布键，键值，并按SHARD将多次写入封装在一条SQL中，可以轻松达到几百万行/s的写入性能。)    
```  
transaction type: ./test.sql  
scaling factor: 1  
query mode: prepared  
number of clients: 128  
number of threads: 128  
duration: 120 s  
number of transactions actually processed: 22410273  
latency average = 0.685 ms  
latency stddev = 8.487 ms  
tps = 186717.144028 (including connections establishing)  
tps = 186761.579753 (excluding connections establishing)  
script statistics:  
 - statement latencies in milliseconds:  
         0.002  \set id random(1,1000000000)  
         0.688  insert into test values (:id),(:id),(:id),(:id),(:id),(:id),(:id),(:id),(:id);  
```  
单个QUERY，单个shard，单条记录。  
```  
transaction type: ./test.sql  
scaling factor: 1  
query mode: prepared  
number of clients: 128  
number of threads: 128  
duration: 120 s  
number of transactions actually processed: 29441284  
latency average = 0.522 ms  
latency stddev = 0.762 ms  
tps = 245299.791043 (including connections establishing)  
tps = 245362.383416 (excluding connections establishing)  
script statistics:  
 - statement latencies in milliseconds:  
         0.001  \set id random(1,1000000000)  
         0.522  insert into test values (:id);  
```  
### OLTP 优化小结  
1、尽量不要使用运算符(包括函数)，建议使用常量。  
因为所有运算符(包括函数)的计算都在coordinator节点完成。  
2、不需要2PC的话尽量不要使用。  
```  
su - postgres -c "echo \"alter system set citus.multi_shard_commit_protocol='1pc'; select pg_reload_conf();\"|psql -f -"  
```  
3、批量使用单条SQL批量操作（多SQL没有意义）。如果客户端能够拿到分布算法，分布键，键值，并按SHARD将多次写入封装在一条SQL中，可以轻松达到几百万行/s的写入性能。     
### CN MX : OLTP 读、写能力扩展
1、读能力扩展，增加coordinator节点。通过物理流复制 可以复制若干个COORDINATOR 节点(TP场景worker节点的资源使用率较低，coordinator节点可以在每个worker节点上放一个。)，只读QUERY可以分摊到不同的coordinator节点执行。  
2、写能力扩展，增加coordinator节点。可以使用mx功能(隐藏功能，实际上读能力也可以使用这种方法扩展)。  
CN节点执行  
```  
su - postgres -c "echo \"alter system set citus.replication_model='streaming'; select pg_reload_conf();\"|psql -f -"  
```  
添加要同步元数据的WORKER  
```  
select * from master_add_node('xxxxx.224',1921);  
select * from master_add_node('xxxxx.230',1921);  
```  
开启同步到元数据。  
```  
select start_metadata_sync_to_node('xxxxx.224',1921);  
select start_metadata_sync_to_node('xxxxx.230',1921);  
```  
包含元数据的节点，hasmetadata标记位TRUE。  
```  
postgres=# select * from pg_dist_node;  
 nodeid | groupid |    nodename    | nodeport | noderack | hasmetadata | isactive | noderole | nodecluster   
--------+---------+----------------+----------+----------+-------------+----------+----------+-------------  
      3 |       3 | xxxxx.231 |     1921 | default  | f           | t        | primary  | default  
      4 |       4 | xxxxx.225 |     1921 | default  | f           | t        | primary  | default  
      5 |       5 | xxxxx.227 |     1921 | default  | f           | t        | primary  | default  
      6 |       6 | xxxxx.232 |     1921 | default  | f           | t        | primary  | default  
      7 |       7 | xxxxx.226 |     1921 | default  | f           | t        | primary  | default  
      8 |       8 | xxxxx.229 |     1921 | default  | f           | t        | primary  | default  
      2 |       2 | xxxxx.230 |     1921 | default  | t           | t        | primary  | default  
      1 |       1 | xxxxx.224 |     1921 | default  | t           | t        | primary  | default  
(8 rows)  
```  
仅针对开启同步后，创建的SHARD表，在worker节点才有元数据，之前已经创建的SHARD表，不会自动把元数据同步过去。  
对应的worker可以当成cn来使用。  
```  
postgres=# explain select * from test5;  
                                    QUERY PLAN                                       
-----------------------------------------------------------------------------------  
 Custom Scan (Citus Real-Time)  (cost=0.00..0.00 rows=0 width=0)  
   Task Count: 128  
   Tasks Shown: One of 128  
   ->  Task  
         Node: host=172.24.211.224 port=1921 dbname=postgres  
         ->  Seq Scan on test5_103740 test5  (cost=0.00..22.70 rows=1270 width=36)  
(6 rows)  
postgres=# explain select * from test6;  
                                    QUERY PLAN                                       
-----------------------------------------------------------------------------------  
 Custom Scan (Citus Real-Time)  (cost=0.00..0.00 rows=0 width=0)  
   Task Count: 128  
   Tasks Shown: One of 128  
   ->  Task  
         Node: host=172.24.211.224 port=1921 dbname=postgres  
         ->  Seq Scan on test6_103868 test6  (cost=0.00..22.70 rows=1270 width=36)  
(6 rows)  
```  
### 启用CN MX后，1+8 的集群，读写能力如何？
(首先启用MX后，实际上所有节点都可以作为写节点，可用性大幅度提升。另一方面，只要做好每个节点的HA，全局视角的可用性可靠性也可以有保障。)  
#### 1 TPC-B (select only)
```
pgbench -M prepared -n -r -P 1 -c 96 -j 96 -T 120 -S
CN tps: 127378  
WORKERs tps: 58473+55709+63161+63510+62721+66301+59628+65486
总 tps: 622367  
worker平均剩余cpu 2.5%
```
#### 2 TPC-B (read write)
```
CN: pgbench -M prepared -n -r -P 1 -c 96 -j 96 -T 120 
WORKER: pgbench -M prepared -n -r -P 1 -c 48 -j 48 -T 120 
CN tps: 18207
WORKERs tps: 7467+7368+7287+7391+7316+7442+7661+7440
总 tps: 77579
worker平均剩余cpu 14%  
``` 
## citus 读写能力扩展架构
1、cn流复制，扩展读能力。   
![pic](20180824_02_pic_001.jpg)  
2、citus MX特性，指定worker节点携带metadata，扩展读写能力。  
![pic](20180824_02_pic_002.jpg)  
3、流复制，异地容灾。使用不同的dns，解决两套集群IP不同的问题。扩展容灾能力。   
![pic](20180824_02_pic_003.jpg)  
## citus reference  
https://docs.citusdata.com/en/v7.5/develop/api.html  
配合haproxy,lvs，citus mx功能(前面已提到如何配置)，可以实现对业务完全透明的读写负载均衡。  
https://severalnines.com/blog/postgresql-load-balancing-using-haproxy-keepalived   
http://docs.citusdata.com/en/stable/cloud/additional_mx.html   
配合jdbc或libpq的mulit-host功能，citus mx功能，可以实现对业务完全透明的读写负载均衡。 
[《PostgreSQL jdbc multi-host 配置与简单HA、Load Balance实现》](../201806/20180614_02.md)  
[《PostgreSQL libpq multi-host 配置与简单HA实现》](../201806/20180614_01.md)  
[《PostgreSQL 10.0 preview 功能增强 - libpq支持多主机连接(failover,LB)让数据库HA和应用配合更紧密》](../201704/20170420_01.md)  
#### [PostgreSQL 许愿链接](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216")
您的愿望将传达给PG kernel hacker、数据库厂商等, 帮助提高数据库产品质量和功能, 说不定下一个PG版本就有您提出的功能点. 针对非常好的提议，奖励限量版PG文化衫、纪念品、贴纸、PG热门书籍等，奖品丰富，快来许愿。[开不开森](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216").  
#### [9.9元购买3个月阿里云RDS PostgreSQL实例](https://www.aliyun.com/database/postgresqlactivity "57258f76c37864c6e6d23383d05714ea")
#### [PostgreSQL 解决方案集合](https://yq.aliyun.com/topic/118 "40cff096e9ed7122c512b35d8561d9c8")
#### [德哥 / digoal's github - 公益是一辈子的事.](https://github.com/digoal/blog/blob/master/README.md "22709685feb7cab07d30f30387f0a9ae")
![digoal's wechat](../pic/digoal_weixin.jpg "f7ad92eeba24523fd47a6e1a0e691b59")
#### [PolarDB 学习图谱: 训练营、培训认证、在线互动实验、解决方案、生态合作、写心得拿奖品](https://www.aliyun.com/database/openpolardb/activity "8642f60e04ed0c814bf9cb9677976bd4")
#### [购买PolarDB云服务折扣活动进行中, 55元起](https://www.aliyun.com/activity/new/polardb-yunparter?userCode=bsb3t4al "e0495c413bedacabb75ff1e880be465a")
#### [About 德哥](https://github.com/digoal/blog/blob/master/me/readme.md "a37735981e7704886ffd590565582dd0")