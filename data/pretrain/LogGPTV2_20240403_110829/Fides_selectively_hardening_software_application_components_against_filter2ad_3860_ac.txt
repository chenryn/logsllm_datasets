Figure 4: Communication protocols between two SPMs.
Figure 5: Layout of the Fides architecture. Hatched
areas represent partially accessible memory regions.
Security of updating modules depends on the ability to
create crytographically signed security reports. Since it can
safely be assumed that only the creator of the initial report
has access to the private key, an attacker is not able to fab-
ricate his own new versions.
4. A PROTOTYPE IMPLEMENTATION
A key element of Fides is the program-counter dependent
memory access control model. Since access rights have to
be checked on each memory access, implementing this com-
pletely in software would have a huge performance cost. Al-
ternatively, modifying hardware, an approach taken by re-
lated research [37, 38, 9], has serious drawbacks.
In this
section, we describe an eﬃcient implementation of the run-
time system and the compiler on readily available hardware.
4.1 The Fides architecture
The key observation is that the memory access control
rules only change when entering and exiting SPMs. In our
implementation, we use a small dynamic hypervisor to iso-
late SPMs from the rest of the system, and we ensure that
the correct memory permissions are set on entering/exiting
SPMs. Hence, there is only an overhead on entering and ex-
iting SPMs, leading to a reasonable performance overhead.
We introduce a minimal hypervisor that runs two virtual
machines, the Secure VM and the Legacy VM (see Fig. 5).
Both VMs have the same guest physical view of host physical
memory, but they have a diﬀerent conﬁguration of memory
access control. Note that there is no duplication of memory,
only two virtual views of the same physical memory.
Our prototype implementation can be loaded and unloaded
when required, avoiding any overhead when no SPMs are in
use. Fides is bootstrapped by loading a device driver in the
legacy kernel to gain supervisor privileges. Then, physical
contiguous memory is allocated to store a hypervisor and
the Secure VM. Next, a dynamic root of trust is started
and the hypervisor and Secure VM are launched. Finally,
the running legacy kernel is pulled in the Legacy VM, and
memory access control of both VMs is conﬁgured [15, 27].
The Legacy VM.
The legacy kernel and user applications continue their op-
eration without any interruption: the only diﬀerence after
the start of Fides is that access to certain parts of memory
is now prohibited in the Legacy VM. More speciﬁcally, the
memory where SPMs and parts of the TCB are stored, is
protected. If the legacy VM accesses this memory (for in-
stance tries to read or write the Secret section of an SPM),
this will trap to the hypervisor and the access attempt is
prevented.
The Fides device driver that was used to bootstrap Fides
also provides an interface to the security architecture, for in-
stance to create and query SPMs. This interface can not be
exploited: no sensitive information is ever returned. How-
ever, given our attacker model, an attacker may change the
returned results before code in the Legacy VM can process
it. Hence, these primitives can only be used securely from
within an SPM thereby avoiding the results to leave the
Secure VM. This problem does not occur when SPMs are
created from unprotected memory: when an attacker inter-
fered with the creation of an SPM, this will be detected by
the authentication protocol and no sensitive information will
be passed to it.
This design ensures excellent compatibility with legacy op-
erating systems: the only change from the OS’s viewpoint is
that certain memory regions (that are unused during normal
operation) are rendered inaccessible.
Hypervisor.
The hypervisor is executing at the most privileged level
and serves three simple purposes. First, it provides coarse-
grained memory isolation of the legacy VM, secure VM and
itself. It also prevents any access to SPMs that is not allowed
from unprotected memory. However, it does not implement
the ﬁne-grained program-counter dependent memory access
control. This is implemented in a separate security kernel
in the secure VM and will be discussed later.
Second, the hypervisor schedules both virtual machines
for execution based on a simple request passing mechanism.
The secure VM is scheduled only when a request is passed
to it (i.e. when an SPM is called), or when it did not yet
ﬁnish executing the previous request. Hence, the Secure VM
consumes no CPU cycles when no SPMs are being executed.
Third, the hypervisor creates a new dynamic root of trust
(DRTM aka late launch) when it is loaded. This allows the
attestation of the correct launch of the security architecture.
It also allows the TPM chip to store sensitive information
based on this measurement, such as the cryptographic keys
used by the Vault. If Fides was compromised before it was
protected in memory and launched or a hypervisor was al-
ready present, the result of this measurement diﬀers and
sensitive data is inaccessible.
Secure VM.
To allow easy access to the unprotected memory, the Se-
cure VM has the same view of physical memory as the
Legacy VM but with diﬀerent access control settings: SPMs
can be accessed but are protected by a security kernel
7Security kernel.
To reduce the size of the TCB, only a minimal amount of
features are used: memory paging, a separation of user and
kernel mode, page fault handling and a few system calls. We
now discuss how these features are used to enforce the ﬁne-
grained access control model and how SPMs can use Fides’
primitive operations.
To ensure isolation, SPMs are executed in user mode.
When a module is invoked, the security kernel receives a re-
quest specifying the virtual address of the entry point called.
This address is translated to a physical address by directly
traversing the (untrusted) page tables in the Legacy VM.
Next the containing module is located. When no module
is found an error is returned to the Legacy VM, else a new
address space is created mapping the entire module. As
modules are always mapped at the same virtual addresses
as in the Legacy VM, it is easy to access unprotected mem-
ory locations. When these are not yet mapped, a page fault
will be generated. At that time the referenced physical page
is located, checked whether it is part of an SPM and checked
against the access rights of the SPM. To prevent an SPM
from receiving unauthorized access to memory locations, the
address space is rebuilt each time an SPM is invoked. Note
that the page tables of the Legacy VM are not trusted: they
are only used to check which physical page was referenced.
The security kernel also ensures that modules are prop-
erly loaded: since the untrusted page tables of the legacy
kernel are used, an attacker may try to only load modules
partially in memory or rearrange the order of its pages. To
mitigate this threat, the security kernel records the order
of the physical pages when a module is created and ensures
that the same order is used when the module is called or its
presence tested using the lytSPM and tstSPM primitives.
TOCTOU attacks are mitigated by preventing concurrent
execution of modules. As modules can only destroy them-
selves, an authenticated module must still be mapped in
memory when it is called. This is however overly restrictive
as only the presence of the called module must be ensured.
Besides passing information between SPMs in registers,
the security kernel also provides support to pass bulk data
using a special shared memory segment that is accessible
only to the currently executing SPM. Hence, the receiver
automatically gains access when it is called. To prevent in-
formation leakage, the called SPM must overwrite the passed
data before execution returns to unprotected code. Access
to this memory segment from the legacy VM is prevented us-
ing Extended Page Tables (EPT), the same hardware mech-
anism used to isolate diﬀerent VMs.
Limitations of the prototype implementation.
To prevent time-of-check-to-time-of-use attacks, SPMs must
not be destroyed after they were authenticated but before
they are called. This would cause sensitive information
stored in registers to leak to untrusted code. Our proto-
type currently handles this by preventing SPMs to be inter-
rupted. However, this is largely a prototype limitation, and
not fundamental. Fides could, for example, support inter-
rupts by suspending and resuming the executing SPM after
the interrupt is handled. Entries to other SPMs are denied
to prevent destruction of already authenticated communica-
tion endpoints by the interrupted module. Non-responsive
modules on the other hand, may be destroyed by the security
kernel without further consideration. Alternatively, support
for multicore processors could also be added and SPMs can
be run on one speciﬁc core. In that case, unprotected code
is able to execute uninterrupted. This may be acceptable,
as it can be expected that SPMs are only responsible for a
small fraction of all computation.
In production systems the use of DMA should be pre-
vented from overwriting an SPM. Just as the prototype cur-
rently prevents the Legacy VM to access SPM locations, the
IOMMU should be conﬁgured to prevent DMA accesses to
modules.
4.2 Automated compilation of modules
We modiﬁed the LLVM3 compiler to compile standard C
source code modules into protected modules. More speciﬁ-
cally, the compiler ensures the following:
(cid:129) Each module implements its own stack.
(cid:129) When returning to unprotected memory, registers and
condition ﬂags are cleared.
(cid:129) Function pointers point to unprotected memory or to
a function in the SPM with a correct signature.
(cid:129) Function call annotations specify that the referenced
module must be authenticated before the function is
called and possibly sensitive information is passed.
(cid:129) The entry point handling returns from callback func-
tions, cannot be exploited. The entry point is only
serviced when a callback actually took place.
We now discuss two notable implementation details: sup-
porting function calls to SPMs and the use of function point-
ers by modules.
Supporting function calls to SPMs.
For each SPM, a wrapper is created to allow easy invoca-
tion. The wrapper serves two purposes. First, it loads and
unloads the SPM when appropriate. Second, it creates a
stub function for each available entry point. Fig. 6 displays
a schematic overview of an invocation. In step 1 untrusted
code accesses a stub in the SPM’s interface as a normal func-
tion. Arguments are passed together with the entry point
to the security kernel via the Fides driver and hypervisor
(step 2). After all consistency checks pass, the SPM is in-
voked (step 3). The SPM’s execution stops when it tries
to execute unprotected memory, either because the SPM’s
service returns or because an external function is called. In
both cases the security kernel returns the contents of all reg-
isters to the stub (steps 4-6). There appropriate action is
taken: returning to its caller or invocation of the function
pointer before re-entering the SPM.
Supporting function pointers.
Support for function pointers dereferenced within a mod-
ule is added in two steps. In the ﬁrst step, an LLVM func-
tion pass replaces every function pointer dereference with a
call to one of two support functions, depending on whether
the call should be made to a trusted module or unprotected
code. The developer of the module should specify the type
of the target of the function pointer by annotating the source
code. These support functions will be compiled as part of the
3
http://llvm.org/
8VMM Secure kernel
1,045
1,947
Shared Total TCB
4,167
7,159
Table 2: The TCB consists of only 7K lines of code.
An important enabler for formal veriﬁcation of the TCB
is to make sure that the size of the TCB is small. Table 2
displays the TCB of Fides for its diﬀerent parts, as mea-
sured by the SLOCCount4 application. Only the hypervisor
(VMM) and the secure kernel are trusted. They contain
1,045 and 1,947 lines of C and assembly code respectively.
This does not include the 4,167 lines of code that is shared
between the parts. The driver (690 LOC) used to support
communication with Fides is not security sensitive and thus
is excluded from the TCB. This totals the size of the TCB
to only 7,159 LOC.
Compilation of SPMs.
Facilities oﬀered by high-level languages such as a private
ﬁeld modiﬁer, allow easy reasoning about an application’s
security guarantees and its veriﬁcation. A low-level attacker,
not bound by these restrictions, may however still exploit a
vulnerability anywhere in the application and break these
security guarantees.
It has been proven [2] that a simpli-
ﬁed version of Fides’ ﬁne-grained access control mechanism,
is able to support fully-abstract compilation of a high-level
language with private ﬁelds: when no source-level attack
against a module exists, it also can’t be exploited after com-
pilation.
To achieve such high security guarantees, modules must be
compiled securely. Each module’s stack, for example, must
be placed in its Secret section. Our modiﬁed compiler is
able to compile standard C source code to modules meeting
these requirements.
5.2 Performance evaluation
We performed three types of performance benchmarks on
our prototype. First, we measure the system-wide perfor-
mance impact of Fides. Next, we measure the cost of local
communication (Section 5.2.2) and ﬁnally we benchmark an
SSL-enabled web server (Section 5.2.3).
All our experiments were performed on a Dell Latitude
E6510, a mid-end consumer laptop equipped with an Intel
Core i5 560M processor running at 2.67 GHz and 4 GiB
of RAM. Due to limitations of our prototype, we disabled
all but one core in the BIOS. An unmodiﬁed version of
KUbuntu 10.10 running the 2.6.35-22-generic x86 64 kernel
was used as the operating system.
5.2.1
System-wide performance cost
To measure the performance impact of Fides on the overall
system, we ran the SPECint 2006 and lmbench benchmarks.
Fig. 7a displays the results of the former. With the exception
of the mcf application (10.36%), all applications have an
overhead of less than 3.28%. We contribute the performance
increase of gcc to cache eﬀects.
Fig. 7b displays the results of 9 important operations of
the lmbench suite: null (null system call), fork, exec, ctxsw
(context switch among 16 processes, each 64 KiB in size),