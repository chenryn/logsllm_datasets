title:Privacy preserving boosting in the cloud with secure half-space queries
author:Shumin Guo and
Keke Chen
POSTER: Privacy Preserving Boosting in the Cloud with
Secure Half-Space Queries
Shumin Guo, Keke Chen
Ohio Center of Excellence in Knowledge Enabled Computing
Department of Computer Science and Engineering
Wright State University, Dayton, OH 45435, USA
PI:EMAIL, PI:EMAIL
ABSTRACT
This poster presents a preliminary study on the PerturBoost ap-
proach that aims to provide efﬁcient and secure classiﬁer learning
in the cloud with both data and model privacy preserved.
Categories and Subject Descriptors
H.2.0 [General]: Security, integrity, and protection
Keywords
Privacy, outsourcing data mining, cloud, RASP perturbation
1.
INTRODUCTION
Most data mining tasks require a good understanding of the min-
ing techniques, time-consuming parameter tuning, algorithm tweak-
ing, and frequently algorithm innovation. They are often resource-
intensive and need the expertise of applying data-mining techniques.
As a result, most data owners, who have no sufﬁcient computing re-
sources or data-mining expertise, cannot mine their data.
The development of cloud computing and services computing
enables at least two solutions. First, if the data owner has the
data-mining expertise but not the computing resources, he/she can
rent public cloud resources to process the data. Second, if the data
owner does not have the expertise, he/she can outsource their data-
mining tasks to data-mining service providers.
The Netﬂix prize is a successful story of outsourced data mining.
The goal of the competition is to develop effective movie recom-
mendation algorithms with the published Netﬂix data. Any inter-
ested person or team can attend the competition. Netﬂix rewards
the winning teams based on the accuracy of their algorithms. In
comparison, if developing in-house algorithms, Netﬂix may spend
much more and possibly get nothing close to the winning algo-
rithms.
In spite of all the beneﬁts, the unprotected outsourcing approach
has at least three drawbacks.
• The published data may contain private information [5], which
actually forced Netﬂix to suspend the Netﬂix prize II compe-
tition1.
• The data ownership is not protected. Once published, the
dataset can be accessed by all the participants.
1http://blog.netﬂix.com/2010/03/this-is-neil-hunt-chief-product-
ofﬁcer.html
Copyright is held by the author/owner(s).
CCS’12, October 16–18, 2012, Raleigh, North Carolina, USA.
ACM 978-1-4503-1651-4/12/10.
• The ownership of the resultant models is not protected. At
least the model developer knows the model and understands
how to use it.
Because the success of modern machine learning and data min-
ing applications has largely depended on the available data, datasets
are now precious properties to the data owners. With unprotected
outsourcing, competitors can freely use the published data and the
resultant models, and possibly derive knowledge against the data
owner’s interests. Data owners will soon realize that, without the
protection on data and model privacy they will have to keep their
data mining tasks in-house.
Proposed Approach. The proposed approach (PerturBoost) aims
to address the above problem with the secure half-space query ap-
proach for classiﬁer learning. Speciﬁcally, we will use secure half-
space queries to mine a classiﬁcation model from the data hosted
in the cloud - the scenario is similar for using data-mining service
providers.
This approach uses our previously developed RASP perturbation
[1] that perturbs the data to protect the conﬁdentiality, while still al-
lowing users to conduct secure half-space queries. We utilize the
boosting framework to build up a strong classiﬁer with good pre-
diction accuracy, based on a bunch of weak classiﬁers that have
slightly better accuracy than random guess. These weak classiﬁers
are constructed with RASP-based secure half-space queries.
In this way, we effectively address the problem of secure data
mining in the cloud. (1) The data is protected with the RASP pertur-
bation. (2) The model is protected in the form of secure half-space
queries.
(3) The accuracy is preserved with the boosting frame-
work.
This approach has a couple of unique features. (1) It is very efﬁ-
cient, with low costs in storage, computation, and communication.
(2) It provides sufﬁcient security, if the user protects the perturba-
tion parameters well.
The preliminary results show that the PerturBoost approach can
learn models with satisfactory accuracy. An ongoing effort is to
further reduce the cost and improve the accuracy of learning.
2. BACKGROUND
2.1 Classiﬁcation Modeling
Classiﬁer learning is to learn a model y = f (x) from a set of
training examples {xi, yi}, where xi ∈ R
k is the k-dimensional
feature vector describing an example, and yi is the label for the
example - if we use ‘+1’ and ‘-1’ to indicate two classes, yi ∈
{−1, +1}. The learning result is a function y = f (x), i.e., given
any known feature vector x, we can predict the label y for the ex-
ample x. The quality of the model is deﬁned as the accuracy of
1031prediction. A random guess to the two-class setting would have an
accuracy around 50%.
Our approach is based on the boosting framework [2] for learn-
ing classiﬁers. A boosting model is a weighted summation of a
number of base classiﬁers, f (x) =
hi(x), where the base
models hi(x) can be any weak learner, e.g., a learner with its ac-
curacy signiﬁcantly higher than 50% for two-class prediction.
(cid:2)
αi
3. PERTURBOOST: PROTECTING BOTH
DATA AND MODEL PRIVACY
In the PerturBoost framework, the client prepares a perturbed
dataset and the parameters, and then outsources them to the cloud.
The PerturBoost algorithm is invoked in the cloud to get a model
for the client.
Weak learner can be in any forms [4], among which a simple one
is linear classiﬁer. It can be represented as decision rules, such as:
Xj
if f(x) Xj
RASP
_
_ +
_ +
+
+
_