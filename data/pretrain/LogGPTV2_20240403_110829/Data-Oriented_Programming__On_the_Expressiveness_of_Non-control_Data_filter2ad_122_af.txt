*addr1 = *addr1 + offset3 
*addr2 = *addr1 
*addr3 = **addr2           (privatekey) 
*addr1 = *addr3  
*addr1 = *addr1 + offset4 
*addr2 = *addr1 
*addr3 = **addr2           (rsa) 
*addr1 = *addr3  
*addr1 = *addr1 + offset5 
*addr2 = *addr1 
*addr3 = **addr2           (d) 
*addr1 = *addr3  
*addr1 = *addr1 + offset6 
*addr2 = *addr1 
*addr3 = **addr2           (d)  
MOV 
ADD 
MOV 
LOAD 
MOV 
ADD 
MOV 
LOAD 
MOV 
ADD 
MOV 
LOAD 
MOV 
ADD 
MOV 
LOAD 
MOV 
ADD 
MOV 
LOAD 
MOV 
ADD 
MOV 
LOAD 
Fig. 3.
Pointer dereference chain and malicious MINDOP program in
attack against ProFTPD. The attack requires 8 memory dereferences from
the deterministic location to the private key. Each dereference is implemented
by 4 gadgets.
DOP is able to successfully construct such an attack. The
key idea is to use a short MINDOP virtual program that starts
from the base pointer (of known location) and dereferences it
7 times within the server’s memory to correctly determine the
randomized location of the private key. The virtual program
needs to perform additions to compute the correct offsets
within structures of intermediate pointers. In total, the virtual
program takes 24 iterations, computing a total of 23 interme-
diate values to obtain the ﬁnal address of the private key. Once
we have the private key buffer’s address, we simply replace
an address used by a public output function, causing it to leak
the private data to the network. We use the vulnerability CVE-
2006-5815 [45] to simulate the malicious MINDOP program
(as shown in Figure 3), and create an interactive DOP program
that corrupts the program memory repeatedly. Each group
of 4 gadgets performs one complete dereference operation.
Note that addr1, addr2 and addr3 are ﬁxed addresses in
the gadgets. Therefore, the MOV between ADD and LOAD is
necessary to deliver operands between operations.
Remark. TASR, a recent improvement in randomization de-
fense, proposes to re-randomize the locations of code pointers
frequently, such as on each network access system call (read
or write) [14]. The primary goal of this defense is to reduce
the susceptibility of commodity ASLR to address disclosure
attacks. DOP can work even in the presence of such timely
re-randomization because of two reasons. Firstly, TASR is
applied to code pointers only, whereas our attack executes
completely in the data-plane. Secondly, non-interactive DOP
attacks can perform all the necessary computation in-place be-
tween two system-calls. For example, given simple programs
X
… ...
2
Trigger
MOV
STORE
Malicious payload
(in Proftpd’s memory)
@fixed_addr
head
dlopen(...) 
{ /* use head */ }
head
@rand_addr
Proftpd’s 
Memory
1
Prepare
payload
MOV
MOV
MOV
…….
MOV
MOV
Fig. 4. Simulating a network bot. There are two steps in this attack: 1(cid:3)
Prepare the payload in Proftpd’s memory; 2(cid:3) Trigger the memory error. Each
step uses many data-oriented gadgets.
in Code 12 and Code 13 (in Appendix B and Appendix C),
TASR cannot defend it against DOP attacks. We refer inter-
ested readers to Appendix for details.
2) Example 2 — Simulating A Network Bot: One con-
sequence of rich expressiveness in DOP exploits is that a
vulnerable program can simulate a remotely-controlled net-
work bot on the victim program. Though conceptually feasible,
executing an end-to-end attack of such expressiveness requires
careful design, which we illustrate in our concrete attack in
ProFTPD.
ProFTPD invokes the dlopen function in its PAM module
to dynamically load libraries. We analyzed dlopen to conﬁrm
that it has all the gadgets to simulate MINDOP (also see
Shapiro et al. [48]). If the memory error allows the attacker
to control a global metadata structure, ProFTPD provides
the Turing-complete computation. In a normal execution, this
metadata is loaded from a local object ﬁle; however, the remote
attacker does not have the ability to create malicious object
ﬁles on the server to misuse dlopen. To circumvent this,
the attacker uses DOP to construct a ﬁrst-stage payload in-
memory and delivers it to dlopen which in turn executes
the payload.
The main challenge in achieving this is ProFTPD’s network
input sanitization logic. It does not allow the attacker to
directly supply the payload metadata object via a remote attack
exploit. ProFTPD imposes several constraints on network
inputs — inputs cannot contain a set of bytes such as zero,
newline, and several other characters. To bypass these restric-
tions we build an interactive virtual program that serves as a
ﬁrst-stage payload. It sends malicious input that respects the
program’s constraints, and constructs the second-stage payload
in the program’s memory. It does so by copying the existing
program memory bytes (instead of network input) to the
payload address using MOV operations (Step 1 in Figure 4). In
our end-to-end exploit, we perform over 700 interactions with
the server to compose the malicious second-stage payload.
Then we use movement and dereference operations to trigger
the memory error (Step 2 in Figure 4). With these steps,
981981
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:14:56 UTC from IEEE Xplore.  Restrictions apply. 
our exploit bypasses all the constraints on network inputs
and enables arbitrary computation in the second-stage of the
exploit. Finally, we force the program to invoke dlopen
and execute the second-stage of the exploit. This simulates a
bot that can repeatedly react to network commands sent to it
remotely. We conﬁrm that the bot performs arbitrary MINDOP
program computation we request.
3) Example 3 — Altering Memory Permissions: Several
control-ﬂow and memory error defenses use memory page
protection mechanisms as an underlying basis for defense. For
instance, CFI defenses use read-only legitimate address tables
to avoid metadata corruption [8] and DEP uses non-executable
memory regions to prevent code injection attacks [16]. How-
ever, some critical functions, such as those in the dynamic
linker, disable all memory protections temporarily to perform
in-place address relocations. This gives the attacker a window
of opportunity to violate the assumptions of the aforemen-
tioned defenses. To construct a successful exploit, the attacker
utilizes the logic of the dynamic linker to corrupt the locations
of its choice at runtime. The expressiveness of DOP is vital
here — we have successfully built a second-stage exploit
for dlopen (using a crafted metadata similar to Example
2 above) that permits arbitrary memory corruption or leakage
of attacker-intended locations. We experimentally conﬁrm that
such exploits can bypass CFI implementations, like binCFI
(utilizing read-only address translation tables [8]) or ﬁxed-
tag based solutions (assuming non-writable code region) [6],
to effect control-hijacking exploits in ProFTPD. We refer
interested readers to Appendix D for details.
D. Immunity against Control-Oriented Defenses
We have experimentally checked that our end-to-end ex-
ploits work when ASLR and DEP are enabled on the victim
system. All 3 attacks work without reporting any error or
warning. The ﬁrst attack successfully sends the server’s private
key to the malicious client. For the second attack, we conﬁrm
that the bot performs arbitrary MINDOP program computation
we request. While for the third attack, we modify the code
section (provided by DEP) to start a shell in the server process.
VI. DISCUSSION
We have shown that DOP exploits can create semantically
expressive payloads without violating the integrity in the
control plane. In this section we discuss their implication,
in particular, the effectiveness in re-enabling control-hijacking
exploits and possible defenses to mitigate them.
A. Re-Enabling Control-Hijacking Attacks
A natural question is whether DOP can undermine control-
ﬂow defenses to re-enable attackers to perform control-
hijacking attacks. First, our results have shown that bypassing
commodity ASLR is feasible, without the need for memory
disclosures. Commodity ASLR implementations randomize
memory segments at the start of the application [15]. Newer
defenses propose to re-randomize the program memory peri-
odically, say at certain I/O system calls, thereby increasing
resistance to disclosed addresses. One such proposal, called
TASR [14], restricts randomization to code pointers. As we
have discussed, it can be bypassed using a non-interactive
DOP attack. Code randomization defenses typically aim to
prevent ROP gadgets from either preventing their occurrence
or randomizing their locations. If these defenses rely on
keeping secret metadata in memory, then DOP offers a way to
bypass protection. However, some randomization techniques
do not make such assumptions [49], and conceptually not
bypassable by DOP attacks.
A number of solutions for enforcing control-ﬂow integrity
have been proposed. Some of them rely on memory page
permission to protect code integrity or metadata integrity. For
example, Abadi et al. uses non-writable target IDs in memory
to identify legitimate control transfer targets [6]. BinCFI relies
on non-writable address translation table to enforce target
checking [8]. DOP attacks can corrupt such non-writable IDs,
or non-writable translation tables, and thus re-enable code
reuse attacks. More seriously, DOP can directly modify non-
writable code region to re-enable code-injection attacks, as we
discuss in Section V-C3. Even if the IDs values are randomized
to avoid effective guessing (an alternative to read-only IDs),
DOP can still read the ID content and reuse it
to build
“legitimate” code blocks.
Furthermore, a class of defenses aims to protect integrity
of code pointers, either via cryptographic techniques or via
memory isolation and segmenting [12], [13]. Code pointer
integrity (CPI) is one such defense, which is based on memory
isolation [13]. CPI is designed to isolate code pointers and data
pointers that eventually point to code into another protected
memory region. Since the defense accounts for data pointers,
one way to bypass it is to break the isolation primitives (e.g.,
SFI [50]). Conceptually, DOP attacks so far have not yet been
able to demonstrate such capability. Cryptographicaly enforced
CFI (CCFI) is another technique which cryptographically
protects code pointers [12]. The authors acknowledge that
protecting data pointers that may point to code pointers is
important for achieving control-ﬂow safety; however, this is
left out of scope of the paper’s proposals. DOP attacks can
easily change data pointers that point to code pointers to
violate CFI if they are left unprotected. We have checked the
possibility for a simple proof-of-concept program against the
CCFI implementation (details in Appendix B).
Finally, we point out that our discussion here pertains to ex-
plicitly subverting the goals of control-ﬂow hijacking defenses.
If subverting control-ﬂow is not the goal, DOP executes in the
presence of all such defenses without disturbing any control-
ﬂow properties or code pointers. We have experimentally
checked for these in Section V-D.
B. Potential Defenses for DOP
1) Memory Safety: Memory safety prevents memory errors
in the ﬁrst place, by detecting any malicious memory corrup-
tion. For example, Cyclone and CCured introduce a safe type
system to the type-unsafe C language [51], [52]. SoftBound
with CETS stores metadata for each pointer inside a disjointed
982982
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:14:56 UTC from IEEE Xplore.  Restrictions apply. 
memory for bound checking and identiﬁer matching to force
a complete memory safety [53], [54]. Cling enforces the
temporal memory safety through type-safe memory reuse [55].
Data-oriented programming utilizes a large number of mem-
ory errors to stitch various data-oriented gadgets. Hence a
complete memory safety enforcement will prevent all possible
exploits, including DOP. However, high performance overhead
prevents the practical deployment of current memory safety
proposals. For example, SoftBound+CETS suffers a 116%
average overhead. Development of practical memory safety
defense is an active research area [56].
2) Data-Flow Integrity: Data-ﬂow integrity (DFI) gener-
ates the static data-ﬂow graph (DFG) before the program
execution [57]. The data-ﬂow graph is a database of deﬁne-use
relationship. DFI instruments the program to check whether
each memory location is deﬁned by legitimate instructions be-
fore read operations. This way DFI prevents malicious deﬁne
behaviors that corrupt program memory. Recent work uses
DFI to protect kernel security-critical data [58]. A complete
enforcement of data ﬂow integrity in all memory regions can
mitigate data-oriented programming. However complete DFI
has a high performance overhead (44% for intraproc DFI and
103% for interproc DFI). Note that selective protection on
security-critical data [58] may work on DOP, as it protects
some pieces of data, but not a panacea for all data.
3) Fine-grained Data-Plane Randomization: We have
shown in Section V-C that coarse-grained randomization or
randomization on code region cannot prevent DOP attacks.
Fine-grained data-plane randomization can mitigate DOP at-
tacks as DOP still needs to get the address of some non-
control data pointers [59], [60]. For example, to stitch one
gadget with another, DOP corrupts the store address of the ﬁrst
gadget or the load address of the second gadget to make them
the same. However, a ﬁne-grained randomization on data-
plane may occur a high performance overhead as all the data
(both control- and non-control- data) should be randomized
frequently. A data-plane randomization with high performance
and strong security guarantee is still an open question.
4) Hardware and Software Fault Isolation: Memory iso-
lation is widely used to prevent unauthorized access to high-
privileged resources. Only legitimate code region has access to
particular variables. This can be used to prevent unexpected
access to security-critical data, like user identity. This way
it can prevent some direct-data-corruption attacks [19], [22].
However DOP does not rely on the availability of security-
critical data – it can corrupt pointers only to stitch data-
oriented gadgets. To prevent such attacks, memory isolation
has to protect all pointers from pure data. However, it is
challenging to accurately identify pointers. Further there are
numerous pointers in the program. Protecting all of them will
introduce high-performance overhead. Therefore isolation only
prevents a part of data-oriented programming attacks when the
program is correctly protected with pointer isolation.
VII. RELATED WORK
In Section VI, we have discussed potential defenses against
control-hijacking attacks and non-control data attacks. In this
section, we focus on the most closely related work.
Non-Control Data Attacks. In Section II-A, we have an
in-depth discussion on non-control data attacks,
including
Chen et al. [19], control-ﬂow bending attack [25] and FLOW-
STITCH [22]. The difference between DOP and previous
work is that DOP does not rely on any speciﬁc security-
critical data or functions, like system call parameters or printf-
like functions. Instead, it only reuses abundant data-oriented
gadgets to build expressive attacks. Due to this feature, it is
more challenging to prevent DOP attacks. Simple defenses
mechanisms can sanitize critical data at particular program lo-
cations with acceptable performance overhead. But protecting
all data pointers will introduce extremely high overhead.
Return-Oriented Programming. ROP technique and its vari-
ants have been extensively explored recently [1]–[5], [23],
[61], [62]. For example, counterfeit object oriented program-
ming (COOP) demonstrates that Turing-complete attacks can
be built with only virtual function calls in C++ [62]. How-
ever, ROP attacks change the control ﬂow of the vulnerable
program, which can be mitigated by rapidly advancing control-
ﬂow integrity solutions [6]–[8], [10], [11], [17], [18]. In
contrast, data-oriented programming manipulates variables in
the data plane and keeps the original control-ﬂow. It works
even when advanced control-ﬂow defenses are deployed.
Turing-Complete Weird Machines. Several work exploits
auxiliary features in software to provide Turing-complete
computation, called weird machines. Shapiro et al. used the
dynamic loader on Linux system to provide such computation
ability [48], which is used by DOP to build further attacks.
Other weird machines can be built with DWARF (Debugging
With Attribute Records Format) bytecode [63], the page fault
handling mechanism [64] or the DMA (direct memory access)
component [65]. DOP demonstrates the Turing-completeness
in the data plane of arbitrary x86 programs.
VIII. CONCLUSION
In this paper, we show that with a single memory error, non-
control data attack can mount Turing-complete computations
using data-oriented programming. Our experiments on 9 real-
world applications show that data-oriented gadgets and gadgets
dispatchers required for DOP are prevalent. We build 3 end-
to-end attacks to demonstrate the practical implications of not
protecting the program’s data-plane.
ACKNOWLEDGMENTS
We thank the anonymous reviewers for their insightful
comments. Thanks to Yaoqi Jia for his help on our exper-
iments. This research is supported in part by the National
Research Foundation, Prime Minister’s Ofﬁce, Singapore un-
der its National Cybersecurity R&D Program (Award No.
NRF2014NCR-NCR001-21) and administered by the National
Cybersecurity R&D Directorate. This work is supported in part
by a research grant from Symantec.
983983
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:14:56 UTC from IEEE Xplore.  Restrictions apply. 
REFERENCES
[1] H. Shacham, “The Geometry of Innocent Flesh on the Bone: Return-
into-libc Without Function Calls (on the x86),” in Proceedings of the
14th ACM Conference on Computer and Communications Security,
2007.
[2] T. Bletsch, X. Jiang, V. W. Freeh, and Z. Liang, “Jump-Oriented Pro-
gramming: A New Class of Code-reuse Attack,” in Proceedings of the
6th ACM Symposium on Information, Computer and Communications
Security, 2011.
[3] S. Checkoway, L. Davi, A. Dmitrienko, A.-R. Sadeghi, H. Shacham,
and M. Winandy, “Return-Oriented Programming Without Returns,” in
Proceedings of the 17th ACM Conference on Computer and Communi-
cations Security, 2010.
[4] E. Bosman and H. Bos, “Framing Signals - A Return to Portable
Shellcode,” in Proceedings of the 35th IEEE Symposium on Security
and Privacy, 2014.
[5] A. Bittau, A. Belay, A. Mashtizadeh, D. Mazi`eres, and D. Boneh,
the 35th IEEE Symposium on
“Hacking Blind,” in Proceedings of
Security and Privacy, 2014.
[6] M. Abadi, M. Budiu, U. Erlingsson, and J. Ligatti, “Control-Flow
Integrity,” in Proceedings of the 12th ACM Conference on Computer
and Communications Security, 2005.
[7] C. Tice, T. Roeder, P. Collingbourne, S. Checkoway, U. Erlingsson,
L. Lozano, and G. Pike, “Enforcing Forward-Edge Control-Flow In-
tegrity in GCC & LLVM,” in Proceedings of the 23rd USENIX Security