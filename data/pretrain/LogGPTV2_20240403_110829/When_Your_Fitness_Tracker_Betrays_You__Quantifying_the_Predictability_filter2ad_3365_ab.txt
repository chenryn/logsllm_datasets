parts of the body are subject to different accelerations (e.g.,
arms, chest, or wrists). On the other hand, the use of ﬁtness
trackers is more popular while running than walking (e.g., to
monitor work-out statistics). Attackers need to consider that
running data looks extremely different from walking due
to the stronger forces generated by the run and the shorter
timing between steps.
3.2. Touch Dynamics
In the case of touchscreen data, there are two main
ways in which the adversary could obtain users’ biometric
data: a malicious mobile application, or a malicious website.
Adversaries could create applications that silently monitor
the touchscreen inputs and trick victims (e.g., through social
engineering) into installing and using these applications on
their smartphones. Similarly,
touchscreen data collection
could be carried out on a website through simple Javascript4.
For touch devices, we focus on the scenario where
victims use at least two phones, where one of them is highly
protected. An example for this scenario is where victims
have a company-issued smartphone that contains company-
sensitive information and is secured with different means
(e.g., trusted modules, touchscreen lock, no installation of
arbitrary apps allowed). In particular, the device contin-
uously authenticates the user using touchscreen biometric
while they are using sensitive applications.
The adversary will try to obtain the user biometric from
a less protected device (e.g., their personal smartphone). In
this case, the ﬁrst factor to account for in the transformation
is the dimension of the touchscreen, as these changes the
span/shape of the swipe gesture. Additionally, the sampling
rate of the touchscreen has a signiﬁcant effect, as less ﬁne-
grained information changes the meaning of features based
on a subset of the swiping gesture (e.g., initial acceleration
of swipe). Other sensor data, such as pressure or area
covered, might also be different in terms of scale, resolution,
precision and granularity.
3.3. ECG
Similarly to gait (Section 3.1), insecurities in the com-
munication channel or the device ﬁrmware can both be
a point of attack for the adversary that is attempting to
obtain ECG data. In addition, computerized medical records
are often handled poorly in terms of their conﬁdentiality.
Reports show that large amounts of sensitive healthcare data
are vulnerable to leakage or theft, or have already been com-
promised because of security lapses at hospitals, insurance
companies or government agencies [26]. Adversaries may
also easily obtain raw ECG signal from photos of ECG
printouts, as has been shown in previous work [2].
It has been previously shown that the type and location
of ECG sensors affect the ECG measurement [2] and there-
fore cause differences in feature distributions. Comparably
to gait, with ﬁtness trackers being more likely to be ex-
ploited, the adversary should also account for the different
4. https://developer.mozilla.org/en-US/docs/Web/API
893
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:35:56 UTC from IEEE Xplore.  Restrictions apply. 
Biometric
Gait
Touch
dynamics
ECG
Eye
movements
Mouse
movements
Factors
Activity
Sensor Location
Input Device
Considered Scenarios
walking, running
arm, chest, hand, pocket, wrist
smartphone, smartwatch, ﬁtness tracker
Input Device
low-, mid-, high-end phone
Sensor Type
Activity
Task
Calibration
mobile monitor, medical monitor, ﬁtness tracker, authenticator
resting, walking, running
reading, watching video, writing, browsing
calibrated, uncalibrated
Input Device
trackpad, mouse
Devices
BLU VIVO 6, Movisens ekgMove,
Garmin Vivoactive HR
TTSim M5 Smart, Motorola MotoG3,
BLU VIVO 6
AliveCor KardiaMobile, Heal Force Prince 180B,
Movisens ekgMove, Nymi Band
SMI RED500
MSI GT72 6QE Dominator Pro G trackpad,
Dell Laser USB mouse
TABLE 2: Factors of feature distribution differences considered for each biometrics and devices used for the measurements.
ECG behavior due to the activity performed by the user dur-
ing the measurement. The ECG signal signiﬁcantly changes
when the user is exercising, both due to the physical exertion
and noise introduced by imperfect electrode connection.
3.4. Eye Movements
The popularity of eye-tracking is increasing and a num-
ber of consumer electronics are equipped with eye trackers.
With more services implementing eye-tracking, adversaries
can use these services to obtain eye movement data (e.g.,
hijacking browsers and using a Web API, or exploiting ap-
plication weaknesses). Additionally, we consider the threat
of the user being tricked into using an attacker-controlled
machine which is equipped with a covert eye tracker.
For eye movements, it has been shown that gaze data
strongly depend on the type of task performed by the user
(e.g., reading, writing, browsing [27]). Since the adversary
can not easily force the user into performing a speciﬁc task,
they might need to adapt the victim’s data to the task that
is used for authentication. Additionally, eye trackers need
to be calibrated before use to provide accurate data. Since
it would be considerably more difﬁcult to trick the user
into calibration (as this procedure would raise suspicion), we
assume that the attacker only possesses data from a device
that is not calibrated for the victim.
3.5. Mouse Movements
As mentioned in Section 3.2, collection of mouse move-
ments data can easily take place on the Web, where it has
been shown that mouse tracking is common-place [28]. In
order to obtain the victim’s data, adversaries may create
websites, or hijack existing ones. It could also be possible
for the adversary to highjack the victims’ browsers (e.g., by
installing malicious extensions [29]).
As users interact (and browse) with an increasing num-
ber of devices,
the adversary needs to account for the
different interactions that happen depending on the device
hardware. Previous work shows that changing the pointing
device hardware causes ﬂuctuations in the measured users
behavior, enough to signiﬁcantly degrade the recognition
performance [17]. Using these observations, we decide to
consider the extreme case where the pointing device is either
a mouse or a trackpad. This ﬁts well the scenario where
mouse data collection happens remotely, that is the most
likely to occur online (as mentioned above).
4. Experimental Design
In order to evaluate the threat model motivated in the
previous section, we conduct a study where we collect
participants’ biometrics for each of the ﬁve biometric modal-
ities. The study is designed to reﬂect the scenarios presented
in the threat model (Section 3). For all biometrics measure-
ments, we stick to state-of-the-art common practices. In the
following, we describe the details of the study and brieﬂy
comment the processing methodologies that we adopt.
4.1. Study Outline
The study consists of two separate but identical sessions
which are at least 5 and not more than 30 days apart. In each
session, participants undergo a series of tasks designed to
collect their biometric traits for a speciﬁc context. A single
session lasts approximately one hour and 45 minutes. In
Table 2 we report all the feature difference factors that we
accounted for in the analysis and the devices used for the
measurements. In the remainder of this section, we present
the details of the study procedure for each biometric.
Mouse Movements. The ﬁrst task is carried out on a laptop
to collect mouse data [30]. Participants are shown a grid of
rectangles and click on the rectangle that contains a picture.
After the user clicks, the picture moves to another rectangle
and users click on this new rectangle. The task ends after
250 total clicks and is repeated with the trackpad.
Eye Movements. The participant is then requested to com-
plete ﬁve different
tasks on a laptop equipped with an
eyetracker. The study is carried out in a lab in controlled
lighting conditions (blinds closed and light switched on). We
take our tasks from the experimental design of [15]: reading,
writing, watching a movie trailer, browsing and watching an
educational video. Each task continues for 3 minutes before
894
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:35:56 UTC from IEEE Xplore.  Restrictions apply. 
the next one automatically starts. Differently from [15],
we include two different videos to account for the number
of scene changes that directly inﬂuence the participant’s
gaze: the movie trailer contains lots of fast-paced scene
changes, while the educational video does not. At the end
of the session, the ﬁve tasks are repeated on an uncalibrated
eyetracker. To account for the users getting used to the tasks
when they repeat them, we randomly swap the order of the
calibrated and uncalibrated tasks.
Touch Dynamics. Afterwards, the participant uses a smart-
phone to complete a “spot the difference” task (similarly
to [3]). The smartphone shows two images which contain
subtle differences between each other and the user attempts
to ﬁnd them. Only one image is shown on the smartphone at
a time and the user swipes (either to the left or to the right)
to see the other image. The task lasts 3 minutes in total and
is repeated three times, each time with a different phone and
a different pair of images. To avoid bias generated by the
selection of images and users acclimating to the task, for
each user we randomize the order of the phones.
ECG. Then, the participants ECG is monitored for a set of
devices: an authenticator, a mobile ECG monitor attached
to a smartphone and a medical ECG monitor. For the ECG
monitor measurement, we collect the palm measurement
using the built-in electrodes and use an external 3-lead ECG
cable with disposable electrodes, to obtain Lead I, Lead
II and Lead III [31]. Additionally, at the beginning of the
session, participants wear a chest-strap ﬁtness tracker that
monitors their ECG and gait data throughout the session.
Gait. Finally, the participant goes for a short walk and a
subsequent run in a nearby park (around 700 meters each).
During this time, ﬁve different sensors monitor the partic-
ipant’s gait pattern: three smartphones (placed on left arm,
right front pocket and held in the left hand), a smartwatch
worn on the left wrist and the ﬁtness tracker mentioned
above. The ﬁtness tracker also monitors ECG during the
walk and the run.
Participant Recruitment. We recruited a total of 30 (11
female, 19 male) participants through local announcements
and social media. Participants were compensated for their
time and inconvenience. This study was reviewed by and
obtained clearance from the Inter-Divisional Research Ethics
Committee of the University of Oxford, reference number
R50977/RE001.
4.2. Feature Extraction
We adopt state-of-the-art common practices for biomet-
ric data processing and feature extraction. Table 3 reports
the papers we used. For ECG and gait we chose to use
preprocessing steps to allow us to isolate the individual
signals (single heartbeat and single gait cycle, respectively),
rather than frequency domain analysis. The rationale behind
this choice is that feature representation based on frequency
domain does not have a direct and understandable meaning,
while providing similar (if not weaker) performance results.
Biometric
Paper(s)
Description
Gait
Touch
dynamics
ECG
Eye
movements
Mouse
movements
M. Frank et al. [3]
M. Derawi et al. [9] magnitude of acceleration fea-
tures (based on cycle detection)
pressure, spatial, speed and
acceleration features
temporal, amplitude, morphol-
ogy features (based on ﬁducial
points)
pupil, temporal and spatial
features
stroke curvature, speed and
acceleration features
N. Zheng et al. [32]
A. Weiss et al. [30]
A. Fratini et al. [7]
S. Eberz et al. [15]
TABLE 3: Description and original paper of the pre-
processing and feature extraction methodologies used for
each biometric.
For gait, we ignore the use of dynamic time warping, as
this is only necessary during template matching and does
not have an effect on the raw signal behavior. Due to
limited space, we report all the individual features and their
importance based on Relative Mutual Information (RMI) in
Appendix A. The details of the feature extraction for each
biometric can be found in the cited papers.
5. Mapping Methodology
In this section, we describe the methodology used to
derive the cross-context mapping and discuss how the map-
ping is combined with feature distinctiveness. Finally, we
discuss the evaluation methodology and how these results
should be interpreted.
5.1. Cross-Context Mapping
We generalize the cross-device mapping approach intro-
duced in [2] to cross-context mappings and transformations
chosen from a parametrized family of functions. Given a
source and target context, for each user we have a set of
feature values computed in the source context and a set of
feature values computed in the target context. Notice that
source and target features are computed independently from
each other (i.e., in different experiments). This is different
from function regression in which inputs and output values
are assumed to be measured in a paired way; rather, we have
a set of input values and a set of output values measured in
independent experiments.
For each pair of the source-target context, we com-
pute a mapping on each biometric feature. Intuitively, this
cross-context mapping works by optimizing the intra-user
statistical similarity between the feature values sampled
from the source context and those sampled from the target
context. More formally, given a context and a feature, we
associate to each user a random variable. The latter models
the experiment of observing speciﬁc feature values, for each
user. The cross-context mapping then transforms each source
context random variable to maximize statistical similarity
895
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:35:56 UTC from IEEE Xplore.  Restrictions apply. 
(s)
ui
(t)
ui,j
(s)
ui,j
}
j=1,...,n
}
j=1,...,n
to its corresponding target context random variable. The
ﬁnal output of the estimation, for a pair of the source-target
context, is a set of functions (one per feature) that maps the
values of features measured in source to the target.
Problem Setting. Let {ui}i=1,...,n be the set of users from
the population for whom we have observations for both
the source s and the target t contexts, which we refer to
and {x
as {x
; and let v be
the victim for whom we have observations only from the
source context s, that is, {x
. For each user
(s)
ui in the population and for the victim v, let X
v
and X
be the random variable associated to a
speciﬁc feature from the source and the target contexts.
∗
respectively. We seek an optimal transformation function f
of the source random variables such that, for i = 1, . . . , n,
∗
(s)
(t)
ui are, statistically speaking, similar. We
ui ) and X
f
(s)
v ) as an estimation of the unknown target
then use f
∗
(t)
v . In other words, f
random variable for the victim, i.e., X
transforms each value of the source feature to be as close as
possible to what would be observed for the target feature.
}
j=1,...,n
(t)
ui , X
(s)
ui , X
(s)
v,j
(t)
v
(X
(X
(t)
ui
(s)
v
∗
Cross-Context Mapping Estimation. As in function re-
gression in ﬁnite dimensional vector spaces, the estimation
∗ is composed of three phases: (i) the deﬁnition of a
of f
parameterized family of functions {fθ}θ∈Θ which to opti-
mize for, (ii) the deﬁnition of an error function for each fθ
and (iii) the solution of an optimization problem in which
the overall error is minimized with respect to the generic
transformation function fθ.
For a generic user u in the population, we evaluate the
dissimilarity between the target random variable X
and
(s)
the transformed source random variable fθ(X
u ) as the
statistical distance between two cumulative density functions
associated with the two random variables5. The rationale
is that, if the two variables have the same distribution,
then they are indistinguishable by the template matching
algorithm. Namely,
be the two
let Ffθ(X
cumulative density functions, we deﬁne the error  that the
function f makes for user u as:
u ) and FX
(cid:3)
(cid:2)
(t)
u
(t)
u
(s)
fθ (u) = d
Ffθ(X
(s)
u ), FX
(t)
u
,
(1)
where d is a generic statistical distance between cumulative
density functions (discussed in the following paragraph).
The optimal function can hence be deﬁned as the trans-
∗ is the vector of parameter
formation function fθ
(cid:2)
values that minimizes the across-users average error, that is:
∗, where θ
(cid:3)
n(cid:4)
∗
θ
= arg min
θ∈Θ
1
n
i=1
d
Ffθ(X
(s)
ui
), FX
(t)
ui
.
(2)
5. Using the set of target observations {x(t)
u,j}
j=1,...,n(s)
and trans-
j=1,...,n(t)
formed source observations {fθ(x(s)
u
we compute the empir-
ical cumulative density function for each random variable using the Kaplan-
Meier estimate.
u,j )}
u
(cid:2)
(cid:5)
(cid:3)
(cid:6)
(cid:2)
R
(cid:3)2
In the following, we reformulate the estimation problem of
Equation 2 using a speciﬁc distance function and Θ.
Optimization Problem. We deﬁne the distance d to be the
L2 distance between functions, that is:
d
Ffθ(X
(s)
u ), FX
(t)
u
=
w
u )(ξ)−FX
(s)
Ffθ(X
(ξ)
(t)
u
dξ.
fθ
(t)
ui
(s)
ui
), FX
(3)
Previous work shows that the precise choice of distance