titleblackhat:us-22 Human or Not: Can You Really Detect the Fake Voices?
Voice is an essential medium for humans to transfer information and build trust, and the trustworthiness of voice is of great importance to humans. With the development of deep learning technologies, attackers have started to use AI techniques to synthesize and even clone human voices. To combat the misuse of such techniques, researchers have proposed a series of AI-synthesized speech detection approaches and achieved very promising detection results in laboratory environments. Can these approaches really be as effective in the real world as they claim to be? This study provides an in-depth analysis of these works, identifies a set of potential problems, and designs a novel voice clone attack framework, SiF-DeepVC, based on these problems. This study first proposes the idea "bypass fake voice detection using speaker-irrelative features" and proves that detecting AI-synthesized speeches is still highly challenging, and existing approaches are not applicable in the real world. In a word, the Red is still far ahead of the Blue.