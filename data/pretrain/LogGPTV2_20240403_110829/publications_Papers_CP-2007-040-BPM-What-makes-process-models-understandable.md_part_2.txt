3.2 Hypothetical Relations between Factors and Understandability
This section discusses the hypothetical relation between the various factors and
understandability. Table 1 gives an overview. In particular, we expect that the
perceived difficulty of a process model (perceived) would be negatively con-
nectedwiththescoreasanoperationalizationofactualunderstandability.The
samepositiveconnectionisassumedwiththeoryandpracticewhilethecount
metrics #node, etc., and the diameter of the process model (i.e. the longest
path) should be related to a lower understandability. The precise formulae for
calculating these and the following metrics are presented in [8]. The sequen-
tiality, i.e. the degree to which the model is constructed of task sequences,
is expected to be positively connected with understandability. The same is ex-
pected for separability, which relates to the degree of articulation points in
a model (i.e. nodes whose deletion separates the process model into multiple
components), and structuredness, which relates to how far a process model
isbuiltbynestingblocksofmatchingjoinandsplitroutingelements.Bothcon-
nectivity and density relate arcs to nodes: the former by dividing #arcs by
#nodes, the latter by dividing #arcs to the maximally possible number of arcs.
The token split metric captures how many new tokens can be introduced by
AND- and OR-splits. It should be negatively connected with understandability.
The average and maximum connector degree refer to the number of in-
put and output arcs of a routing element, which are expected to be negatively
connected with score. The same expectation is there for potential routing el-
ements’ mismatch, also calculated on the basis of their degree and summed
up per routing element; for depth related to the nesting of structured blocks;
for the control flow complexity metric as the number of choices that can
be made at splits in the model; and for connector heterogeneity as the
degree to which routing elements of different types appear in a model. In the
subsequent section we contrast these hypothetical connections with the results
of the questionnaire.
4 Results
This section presents the results of the questionnaire and interviews. We first
analyze the distribution of score in Section 4.1 and discuss its connection with
perceiveddifficultyinSection4.2.Then,weanalyzepersonalfactorsandtheir
connectionwithscoreinSection4.3.InSection4.4weconsidertheconnection
7
Table 1. Hypothetical relation between factors and understandability
factor scorefactor score
perceived + connectivity –
theory + density –
practice + token splits –
#nodes – av. connector degree –
#arcs – max. connector degree –
#tasks – mismatch –
#connector – separability +
#and (join, split) – depth –
#xor (join, split) – structuredness +
#or (join, split) – control flow complexity –
diameter – connector heterogeneity –
sequentiality +
of model-related factors operationalized by the set of metrics. The final part of
this section is devoted to our interviews with modeling experts.
4.1 Distribution of Score
Ifweapplyastandardgradingschemewith10%intervals1therewouldhavebeen
8studentshavinganA,27havingaB,21withaC,8withaD,and9withanE.
Beyond that, the mean score for all but one of the models ranges between 6.8
and 7.4 with 9 being the maximum, while one model has only a mean score of
5.5. To further examine the distribution of score across the models we applied
bothKruskal-WallisandMood’smediantestsat95%confidencelevels[31].Both
non-parametric tests focus on medians to determine differences between distri-
butions,whichisappropriateherebecausescoredisplayssignificantdeviations
from a normal distribution. Interestingly, both test results point to the model
with the low mean score being different from the other models (P-values (cid:191)
0.05). It is model L, which was already shown in Figure 1. When all models are
compared with these tests excluding model L, no significant differences between
the models can be observed with respect to score (P-values > 0.25).
If we take a closer look at model L, it seems a little odd that this model
has such a low score value. As we described in Section 3.1, the questionnaire
includes four sets of models and each of these sets includes three slightly dif-
ferent models. Models in the same group differ only with respect to the type of
routing elements. But each model in the group that L belongs to has only six
routing elements, while the models in other groups contain two or three times
this number. Also, the number of arcs in the L model group (37) is lower than
that of the other groups (48, 57, and 59). So, L seems to come from a group
of models that would be relatively easy to see through. Now the question rises
why the other models in the same group as L do not show such a comparably
1 A’s for 90% score or better, B’s for 80%-90%, etc.; E’s for less than 60%.
8
low score value. In Figure 2 we display all three models. Note that only model
fragmentsaredisplayedforeaseofvisualization.Observedfromthetopdown,it
is the type of the second logical routing element that actually distinguishes the
threemodelsfromeachother.FormodelLthisisanXOR-splitroutingelement,
for the other models an AND-split and OR-split respectively.
XOR XOR XOR
AND OR XOR
O O O
P Q P Q P Q
S S S
T U T U T U
W W W
OR M OR M OR M
XOR XOR XOR
End End End
Fig.2. Fragments of model variants J, K, and L (from left to right)
Whenconsideringtheanswersoftherespondentsonadetaillevel,twoques-
tions stand out as they received few correct answers for model L ((cid:191) 20) and
many correct answers (>20) for the other two models. These questions are:
– “If T is executed for a case, can U be executed for the same case?”, and
– “Can T, M, and O all be executed for the same case?”
Itiscleartoseethatthedistinguishingconnectorsinthetwoleftmostmodels,
i.e. the AND-split and OR-split respectively, directly allow for the interleaved
execution of T and U. But even for L – the rightmost model in Figure 2 – it
is possible that T and U will be executed for the same case. However, this can
only happen after a cycle through M. This is presumably overlooked by many
respondents. Similarly with respect to the second question, many respondents
failedtoseethatT,M,andOcanbeexecutedintherightmostmodel(justasthis
ispossibleintheothertwomodelsofcourse).So,thereisnosignificantdifference
in score across the models; the exception is model L which generated a low
score value because of the interplay between connector and model structure
elements.
4.2 Relation between Perceived and Score
Inadditiontoscorewealsoanalyzedthedistributionof perceived.Inpartic-
ular, we used Kendall’s coefficient of agreement u [32,31] to determine whether
a ranking can be established by the perception of all participants. Interestingly,
9
for each of the four groups of variants a total ordering emerges from the re-
spondents’ answers that is significant at a 95% confidence level. This result is
confirmed by another part of our questionnaire in which we explicitly asked the
respondents to rate the relative differences in understandability between three
models from different groups. So, despite the fact that it was allowed to rate
modelsasequallydifficulttounderstand,respondentsdoseedistinctdifferences
in the understandability of models within each set and even across the sets.
By now, we see different patterns emerging from the distributions of per-
ceivedandscore.Whilemodelsareperceivedasdistinctlydifferentfromeach
other, the actual numbers of correct answers they generate do not differ signifi-
cantly. There is the notable exception of model L, with a very low score value
and,indeed,modelLisalsoperceivedasthemostdifficultmodeltounderstand
withinitsgroup.Toinvestigatethe(absenceofthe)relationbetweenperceived
andscorecloser,wedeterminedthePearsoncorrelationcoefficientbetweenthe
variables for all complete 847 model evaluations we gathered. The correlation
coefficient equals 0.234 with a P-value (cid:191) 0.05, which indicates a significant but
relatively weak correlation at a 95% confidence interval.
The insight that we derive from this part of our analysis is that there is
a rather loose relation between perceived and score. Despite a significant
statistical relation, respondents tend to exaggerate the differences in model un-
derstandability for models for which they do not produce significantly different
numbersofcorrectanswers.Thevariationsinscorealsogivesustwoadditional
insights. First of all, as all models have the same number of tasks, the lack of
significantdifferencesinscoreacrossmostmodelspotentiallypointstothefact
thatmodelsizeistheprimaryfactorthatimpactsmodelunderstandability.Ifso,
it would be reasonable that models with equal numbers of tasks appear equally
difficult to understand. For the remainder of the analysis we assume that the
other factors under investigation (see Section 3.2) are indeed to be considered
as of secondary importance. Secondly, it follows from our detailed analysis of
model L that a single change in a model element can have a significant impact
on a model’s understandability. So, despite the potentially dominant impact of
size, the search for the additional impact factors is indeed relevant.
4.3 Personal Factors and Score
Before we undertook our experiment, we had no reason to expect differences
in score between respondents with different university backgrounds. All re-
spondents had received at least a basic training in the use of process modeling
techniques at the time they took the questionnaire. Also, the exposure to pro-
cess modeling in practice would be negligible for all involved respondents. To
test the absence of such a difference, we computed the total score over the 12
models. For each respondent, this figure lies between 0 and 108, the latter being
the theoretical maximum in case of answering all 9 questions for each of the 12
models correctly. For our respondents, total score ranges between 11 and 103
with an average value of 81.2. In Figure 3, total score is shown for all students
in ascending order.
10
100
80
erocS
60
latoT
40
20
0
1 4 7 10131619222528313437404346495255586164677073
Respondent nr.
Fig.3. Total score for respondents
If no difference would exist between the three distributions of total score,
students can be assumed to perform similarly across the three universities. To
test this, we again applied the non-parametric Kruskal-Wallis test, because ap-
plication of the Shapiro-Wilk W test indicates that with a 95% confidence total
score is not normally distributed for any university.
Contrary to expectations, the application of the Kruskal-Wallis test does in-
dicate that there is a statistically significant difference among the medians at
a 95% confidence level (P-value (cid:191) 0.05). In other words, differences exist in
the ability of respondents to answer questions correctly across the three univer-
sities. Additional pairwise Mann-Whitney tests [31] indicate that respondents
from Eindhoven perform significantly better than respondents from each of the
othertwouniversities(P-values(cid:191)0.05),althoughthedifferencebetweenthere-
spondentsfromtheuniversitiesofViennaandMadeiraisnotsignificant(P-value
= 0.061). In Figure 4, box plots are shown for TUe and non-TUe students.
A retrospective analysis of the courses offered at the various universities re-
vealed that the hours spent on actual modeling is the highest in Eindhoven,
which may explain the noted difference. In particular, Eindhoven students have
been explicitly and thoroughly taught about ‘soundness’ [33], a general correct-
ness criterion for workflow nets. An alternative explanation is that Eindhoven
studentsaregraduatestudentswherethestudentsfromMadeiraandViennaare
stillintheir3rdyearofundergraduatestudies.Interestingly,acrossthedifferent
universities different modeling techniques are taught. The Eindhoven students
were trained in workflow nets (based on the Petri net formalism), the Vienna
studentsinEPCs,andtheMadeirastudentshadknowledgeofboththePetrinet
formalismandEPCs.So,thechoiceofourEPC-likenotationdoesnotobviously
favor students who are familiar with EPCs.
Asearchforotherdifferenceswithintherespondentpopulationdidnotreveal
any convincing factors. In particular, both the variables theory (0.203) and
11
non TUe
TUe
0 10 20 30 40 50 60 70 80 90 100110
Fig.4. Total score for TUe and non-TUe respondents
practice (0.070) do correlate weakly with total score, but these correlations
are not significant at the 95% confidence level. The variables are neither very
useful in the identification of clusters with differing total score performances.
For example, the clearest identification of two different clusters that resulted
fromtheapplicationofvariousagglomerativeclusteringalgorithms(e.g.nearest
neighbor, media, Ward’s method) is shown in Figure 5. Here, the group average
distancebetweenclustersisused.Itcanbeseenthatmostclustersextendacross
almost the entire range of theory and practice. So, these values have little
relation with score. It suggests that, in the context of this study, students’
self-assessments are not valid.
Cluster Scatterplot Cluster Scatterplot
Group Average Method,Squared Euclidean Group Average Method,Squared Euclidean
110 Cluster 110 Cluster
100 1 100 1
90 2 90 2
80 Centroids 80 Centroids
70 70 erocs erocs
60 60
50 50 latoT latoT
40 40
30 30
20 20