gramming provides the framework for the use of background knowledge, repre-
sented in the form of logic predicates and ﬁrst-order rules, whereas attribute-
value learners exclusively learn from training examples. Moreover, training ex-
amples for attribute-value learners are limited to a ﬁxed number of attributes.
The inductive logic programming framework can easily handle the back-
ground knowledge introduced in Sect. 2.1, including alert context as well as
arbitrary Prolog clauses. As the search space is much bigger than in other ma-
chine learning techniques, such as rule and decision tree learners, the size of prob-
lems that can be solved eﬃciently by inductive logic programming is smaller and
these learners are much less eﬃcient. This may make such a system unsuitable
for real-time learning.
On the other hand, attribute-value learners can use a limited form of back-
ground knowledge using so-called feature construction (also known as proposi-
tionalization [16]) by creating additional attributes based on values of existing
attributes or existing background knowledge.
Given that most background knowledge for intrusion detection can be con-
verted to additional features using feature construction, and considering the run-
time requirement, symbolic attribute-value learners seem to be a good choice for
alert classiﬁcation.
Conﬁdence of Classiﬁcation. Symbolic attribute-value learners are decision tree
learners (e.g., C4.5 [30]) and rule learners (e.g., AQ [26], C4.5rules [30], RIP-
PER [4]). Both of these techniques can estimate the conﬁdence of a classiﬁca-
tion based on its performance on training examples. However, it has been shown
that rules are much more comprehensible to humans than decision trees [27, 30].
Hence, rule learners are particularly advantageous in our context.
We analyzed the characteristics of available rule learners, as well as published
results from applications in intrusion detection and related domains. We have not
found a good and publicly available rule learner that fulﬁlls all our requirements,
in particular cost-sensitivity and incremental learning.
Of the techniques that best fulﬁll the remaining requirements, we chose RIP-
PER [4] – a fast and eﬀective rule learner. It has been successfully used in intru-
sion detection (e.g., on system call sequences and network connection data [17,
18]) as well as related domains and it has proved to produce concise and intuitive
rules. As reported by Lee [17], RIPPER rules have two very desirable conditions
for intrusion detection: a good generalization accuracy and concise conditions.
Another advantage of RIPPER is its eﬃciency with noisy data sets.
RIPPER has been well documented in the literature and its description is
beyond the scope of this paper. However, for the sake of a better understanding
of the system we will brieﬂy explain what kind of rules RIPPER builds.
Given a set of training examples labeled with a class label (in our case false
and true alerts), RIPPER builds a set of rules discriminating between classes.
110
Tadeusz Pietraszek
Each rule consists of conjunctions of attribute value comparisons followed by a
class label and if the rule evaluates to true a prediction is made.
RIPPER can produce ordered and unordered rule sets. Very brieﬂy, for a two
class problem, an unordered rule set contains rules for both classes (for both
false and true alerts), whereas an ordered rule set contains rules for one class
only, assuming that all other alerts fall into another class (so-called default rule).
Both ordered and unordered rule sets have advantages and disadvantages. We
decided to use ordered rule sets because they are more compact and easier to
interpret. We will discuss this issue further in Sect. 3.6.
Unfortunately, the standard RIPPER algorithm is not cost-sensitive and does
not support incremental learning. We used the following methods to circumvent
these limitations.
Cost-Sensitive Classiﬁcation and Skewed Class Distribution. Among the various
methods of making a classiﬁcation technique cost-sensitive, we focused on those
that are not speciﬁc to a particular machine learning technique: Weighting [33]
and MetaCost [9]. By changing costs appropriately, these methods can also be
used to address the problem of skewed class distribution. These methods produce
comparable results, although this can be data dependent [9, 24]. Experiments not
documented here showed that in our context Weighting gives better run-time
performance. Therefore we chose Weighting for our system.
Weighting resamples the training set so that a standard cost-insensitive learn-
ing algorithm builds a classiﬁer that optimizes the misclassiﬁcation cost. The
input parameter for Weighting is a cost matrix, which deﬁnes the costs of mis-
classiﬁcations for individual class pairs. For a binary classiﬁcation problem, the
cost matrix has only one degree of freedom – the so-called cost ratio. These
parameters will be formally deﬁned in Sect. 3.
Incremental Learning. Ours is an incremental learning task which is best solved
with an incremental learning technique, but can also be solved with a batch
learner [12]. As we did not have a working implementation of a purely incre-
mental rule learner (e.g., AQ11 [26], AQ11-PM [22]) we decided to use a “batch-
incremental” approach.
In this approach we add subsequent training examples to the training set and
build the classiﬁer using the entire training set as new examples become available.
It would not be feasible to rebuild the classiﬁer after each new training example,
therefore we handle training examples in batches. The size of such batches can
be either constant or dependent on the current performance of the classiﬁer. In
our case we focused on the second approach. We evaluate the current classiﬁ-
cation accuracy and, if it drops below a user-deﬁned threshold, we rebuild the
classiﬁer using the entire training set. Note that the weighted accuracy is more
suitable than the accuracy measure for cost-sensitive learning. Hence, the pa-
rameter controlling “batch-incremental” learning is called the threshold weighted
accuracy. It will be formally deﬁned in Sect. 3.
The disadvantage of this technique is that the size of the training set grows
inﬁnitely during a system’s lifetime. A future work item of ours will be to limit
Using Adaptive Alert Classiﬁcation
111
the number of training examples to a certain time window and use a technique
called partial memory [22] to reduce the number of training examples.
Summary. To summarize, we have not found a publicly available machine learn-
ing technique that addresses all our requirements, in particular cost-sensitivity
and incremental learning. Considering the remaining requirements the most suit-
able techniques are rule learners. Based on desirable properties and successful ap-
plications in similar domains, we decided to use RIPPER as our rule-learner. To
circumvent its limitations with regard to our requirements, we used a technique
called Weighting to implement cost-sensitivity and adjust for skewed class dis-
tribution. We also implemented incremental learning as a “batch-incremental”,
approach, whose batch size dependent on the current classiﬁcation accuracy.
3 Experimental Validation
We have built a prototype implementation of ALAC in recommender and agent
mode using the Weka framework [36]. The prototype has been validated with
synthetic and real intrusion detection data and we summarize the results ob-
tained in this section.
Similar to the examples used throughout this paper, our prototype focuses on
binary classiﬁcation only, that is on classifying alerts into true and false positives.
This does not aﬀect the generality of the system, which can be used in multi-class
classiﬁcation. However, it simpliﬁes the analysis of a system’s performance. We
have not evaluated the classiﬁcation performance in a multi-class classiﬁcation.
So far we have referred to alerts related to attacks as true positives and alerts
mistakenly triggered by benign events as false positives. To avoid confusion with
the terms used to evaluate our system, we henceforth refer to true positives
as true alerts and false positives as false alerts, respectively. This allows us to
use the terms true and false positives for measuring the quality of the alert
classiﬁcation.
More formally, we introduce a confusion matrix C to evaluate the perfor-
mance of our system. Rows in C represent actual class labels and columns rep-
resent class labels assigned by the system. Element C[i, j] represents the number
of instances of class i classiﬁed as class j by the system. For a binary classiﬁcation
problem, the elements of the matrix are called true positives (tp), false negatives
(f n), false positives (f p) and true negatives (tn) as shown in Table 1(a).
For cost-sensitive classiﬁcation we introduce a cost matrix Co with identical
meaning of rows and columns. The value of Co[i, j] represents the cost of assign-
ing a class j to an example belonging to class i. Most often the cost of correct
classiﬁcation is zero, i.e., Co[i, i] = 0. In such cases, for binary classiﬁcations
(Table 1(b)), there are only two values in the matrix: c21 (cost of misclassifying
a false alert as a real one) and c12 (cost of misclassifying a true alert as a false
one).
In the remainder of the paper we use the following measures deﬁned on cost
and confusion matrices: true positive rate (T P ), false positive rate (F P ), false
112
Tadeusz Pietraszek
Table 1. Confusion and cost matrices for alert classiﬁcation. The positive class (+)
denotes true alerts and the negative class (–) denotes false alerts. The columns represent
classes assigned given by the system; the rows represent actual classes.
(a) Confusion matrix C
(b) Cost matrix Co
PPPPPPP
classiﬁed
actual
+
–
+ –
tp f n
f p tn
PPPPPPP
classiﬁed
actual
+
–
+ –
0 c12
c21 0
negative rate (F N). We also use cost ratio (CR), which represents the ratio of
the misclassiﬁcation cost of false positives to false negatives, and its inverse –
inverse cost ratio (ICR), which we found more intuitive for intrusion detection.
For cost-sensitive classiﬁcation we used a commonly used evaluation measure –
so-called weighted accuracy (W A). Weighted accuracy expresses the accuracy of
the classiﬁcation with misclassiﬁcations weighted by their misclassiﬁcation cost.
T P =
tp
tp + f n
, F P =
f p
f p + tn
, F N =
f n
tp + f n
CR · tn + tp
CR · (tn + f p) + tp + f n
CR =
c21
c12
,
ICR =
1
CR
, W A =
3.1 Data Sources
We used Snort [31] – an open-source network–based IDS – to detect attacks and
generate alerts. We purposely used the basic out-of-the box conﬁguration and
rule set to demonstrate the performance of ALAC in reducing the amount of
false positives and therefore reducing time-consuming IDS tuning.
Snort was run on two data sources: a synthetic one known as DARPA
1999 [19], and a real-world one – namely the traﬃc observed in a medium-
sized corporate network (called Data Set B). Alerts are represented as tuples of
attribute values, with the following seven attributes: signature name, source and
destination IP addresses, a ﬂag indicating whether an alert is a scan, number of
scanned hosts and ports and the scan time.
DARPA 1999 Data Set is a synthetic data set collected from a simulated medium-
sized computer network in a ﬁctitious military base. The network was connected
to the outside world by a router. The router was set to open policy, i.e., not
blocking any connections. The simulation was run for 5 weeks which yielded
three weeks of training data and two weeks of testing data. Attack truth tables
describing the attacks that took place exist for both periods. DARPA 1999 data
consists of: two sets of network traﬃc (ﬁles with tcpdump [14] data) both inside
and outside the router, BSM and NT audit data, and directory listings.
In our experiments we ran Snort in batch mode using traﬃc collected from
outside the router for both training and testing periods. Note that Snort missed
Using Adaptive Alert Classiﬁcation
113
The DARPA 1999 data set has many well-known weaknesses (e.g.,
some of the attacks in this dataset. Some of them could only be detected using
host-based intrusion detection, whereas for others Snort simply did not have the
signature. It is important to note that our goal was not to evaluate the detection
rate of Snort on this data, but to validate our system in a realistic environment.
[21, 25])
and we want to make sure that using it we get representative results for how
ALAC performs in real-world environments. To make this point we analyze how
the weaknesses identiﬁed by McHugh [25], namely the generation of attack and
background traﬃc, the amount of training data for anomaly based systems,
attack taxonomy and the use of ROC analysis; can aﬀect ALAC.
With respect to the training and test data, we use both training and test data
for the incremental learning of ALAC, so that we have suﬃcient data to train
the system. With respect to attack taxonomy, we are not using the scoring used
in the original evaluation, and therefore attack taxonomy is of less signiﬁcance.
Finally, we use ROC analysis correctly.
The problem of the simulation artifacts is more thoroughly analyzed by Ma-
honey and Chan [21] thus we use their work to understand how these artifacts
can aﬀect ALAC. These artifacts manifest themselves in various ﬁelds, such as
the TCP and IP headers and higher protocol data. Snort, as a signature based
system, does not take advantage of these artifacts and ALAC sees only a small
subset of them, namely the source IP address. We veriﬁed that the rules learned
by ALAC seldom contain a source IP address and therefore the system does not
take advantage of simulation artifacts present in source IP addresses. On the
other hand, we cannot easily estimate how these regularities aﬀect aggregates
used in the background knowledge. This is still an open issue.
We think that the proper analysis of these issues is beyond the scope of our
work, and would also require comparing multiple real-world data sets. DARPA
1999 data set is nonetheless valuable for evaluation of our research prototype.
Data Set B is a real-world data set collected over the period of one month in a
medium-sized corporate network. The network connects to the Internet through
ﬁrewalls and to the rest of the corporate intranet and does not contain any
externally accessible machines. Our Snort sensor recorded information exchanged
between the Internet and the intranet. Owing to privacy issues this data set
cannot be shared with third parties. We do not claim that it is representative
for all real-world data sets, but it is an example of a real data set on which our
system could be used. Hence, we are using this data set as a second validation
of our system.
3.2 Alert Labeling
Our system assumes that alerts are labeled by the analyst. In this section we
explain how we labeled alerts used to evaluate the system (the statistics for both
datasets are shown in Table 2).
DARPA 1999 Data Set. In a ﬁrst step we generated alerts using Snort running
in batch mode and writing alerts into a relational database. In the second step
we used automatic labeling of IDS alerts using the provided attack truth tables.
114
Tadeusz Pietraszek
Table 2. Statistics generated by the Snort sensor with DARPA 1999 data set and
Data set B.
DARPA 1999 Data Set B
Duration of experiment:
Number of IDS alerts:
False alerts:
True alerts:
Unidentiﬁed:
5 weeks
59812
48103
11709
–
1 month
47099
33220
13383
496
For labeling, we used an automatic approach which can be easily reproduced
by researchers in other environments, even with diﬀerent IDS sensors. We con-
sider all alerts meeting the following criteria related to an attack: (i) matching
source IP address, (ii) matching destination IP address and (iii) alert time stamp
in the time window in which the attack has occurred. We masked all remain-
ing alerts as false alerts. While manually reviewing the alerts we found that, in
many cases, the classiﬁcation is ambiguous (e.g., a benign PING alert can be
as well classiﬁed as malicious if it is sent to the host being attacked). This may
introduce an error in class labels.
Note that diﬀerent attacks triggered a diﬀerent number of alerts (e.g., wide
network scans triggered thousands of alerts). For the evaluation of our system
we discarded the information regarding which alerts belong to which attack and
labeled all these alerts as true alerts.
Data Set B. We generated these alerts in real-time using Snort. As opposed to
the ﬁrst data set we did not have information concerning attacks. The alerts
have been classiﬁed based on the author’s expertise in intrusion detection into
groups indicating possible type and cause of the alert. There was also a certain
number of alerts that could not be classiﬁed into true or false positives. Similarly
to the ﬁrst data set we used only binary classiﬁcation to evaluate the system,
and labeled the unidentiﬁed alerts as true positives.
Note that this data set was collected in a well maintained and well protected
network with no direct Internet access. We observed a low number of attacks in
this network, but many alerts were generated. We observed that large groups of
alerts can be explained by events such as a single worm infection and unautho-
rized network scans. The problem of removing such redundancy can be solved
by so-called alert correlation systems [5, 7, 34], where a group of alerts can be
replaced by a meta-alert representative of the alerts in the group, prior to clas-
siﬁcation. The topic of alert correlation is beyond the scope of this paper and
will be addressed as a future work item.
Another issue is that the classiﬁcation of alerts was done by only one analyst
and therefore may contain errors. This raises the question of how such classiﬁ-
cation errors aﬀect the performance of ALAC. To address this issue, one can ask
multiple analysts to classify the dataset independently. Then the results can be
compared using interrater reliability analysis.
Using Adaptive Alert Classiﬁcation
115
3.3 Background Knowledge
We decided to focus on the ﬁrst two types of background knowledge presented in
Sect. 2.1, namely network topology and alert context. Owing to a lack of required
information concerning installed software, we decided not to implement matching
alert semantics with installed software. This would also be a repetition of the
experiments by Lippmann et al. [20].
As discussed in Sect. 3.1, we used an attribute-value representation of alarms
with the background knowledge represented as additional attributes. Speciﬁcally,
the background knowledge resulted in 19 attributes, which are calculated as
follows:
Classiﬁcation of IP addresses resulted in an additional attribute for both
source and destination IP classifying machines according to their known
subnets (e.g., Internet, intranet, DMZ).
Classiﬁcation of hosts resulted in additional attributes indicating the oper-
ating system and the host type for known IP addresses.
Aggregates1 resulted in additional attributes with the number of alerts in
the following categories (we calculated these aggregates for alerts in a time
window of 1 minute):
– alerts with the same source IP address,
– alerts with the same destination IP address,
– alerts with the same source or destination IP address,