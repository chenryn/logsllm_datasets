one of the leading protocols that was first developed by Signal [8],
and later implemented in WhatsApp [14], Facebook Messenger
[5], and Google Allo [6]. The protocol is based on OTR combined
with Silent Circle Instant Messaging Protocol (SCIMP) [30] for
improved forward secrecy. The protocol is also enhanced to allow
asynchronous messaging, and to simplify non-deniability [4]. Viber
[12, 13] and Telegram [9, 10] have also adopted similar protocols.
2.2 MITM Attack Resistance
The encryption key in the E2EE applications is typically exchanged
between the endpoints during an initial key exchange protocol over
the insecure channel (or a channel fully controllable by the service
provider) and is then refreshed during the message exchanges. The
basic key exchange protocol is based on the well-known Diffie-
Hellman (DH) key exchange protocol [3]. However, the basic Diffie-
Hellman key exchange protocol is not authenticated and therefore
is susceptible to the MITM attack. Hence, the applications add a
manual authentication scheme, which we refer to as “code verifica-
tion” to the key exchange to protect against MITM attack.
Regardless of the differences in the E2EE protocols developed
by different apps, they all rely on the human users to perform this
code verification task in an attempt to defeat the MITM attack. This
human-centered task is the focus of our work.
2.3 Code Generation and Presentation
For authentication, users can compare the public keys (or a fin-
gerprint/hash of the public keys) of other users over an auxiliary
channel (e.g., an out-of-band channel such as text or email, or a hu-
man voice channel). To simplify the manual comparison, the public
key or the fingerprint is encoded into a readable/exchangeable code.
We refer to this code as “security code” or in short “the code”.
Specifically, the generated code is presented as a human readable
code or an exchangeable object. Often a long code is represented as
blocks (or chunks) of few digit numbers for readability (e.g., 30-digit
presented as 6 chunks of 5-digit numbers). Figure 8 in Appendix
A.2 shows some of the common code presentations described here:
• QR Code: The code is encoded into a QR code. Since the QR
code is automatically captured and compared by the app without
relying on human user, it can contain the full public key of the
parties. Figure 8(a) shows the QR code presentation for What-
sApp, which includes a version number, the users’ identifier, and
the public key for both parties.
• Numeric: The code is presented as a sequence of numeric digits.
WhatsApp, Signal, Telegram, and Viber use this form of pre-
sentation. Figures 8(a), 8(d), and 8(b) show the code in numeric
presentation in WhatsApp, Signal, and Viber application.
• Images: The code is encoded into an image. Examples of such
images are also presented in prior literature (e.g., [22, 31]). Tele-
gram encodes the code in a shaded blue square as shown in
Figure 8(c).
Usually a set of one or more of the mentioned presentation is used
by the apps. Other encodings such as words [26], alphanumeric,
Base32 and Base64, sentences, and phrases, have also been proposed
in literature, however, they are not being used at this moment by
any of the popular E2EE apps we study in this paper.
2.4 Code Exchange and Verification
There are two notable approaches to verify the security codes in
security applications, Copy-Confirm and Compare-Confirm as in-
troduced in [34]. In Compare-Confirm, the code is displayed on each
peer’s screen, they exchange their respective code, and both accept
or reject the connection by comparing the displayed and received
code. In Copy-Confirm, one party reads the code to the other party,
who types it onto his/her device, and gets notified whether the code
is correct or not. The E2EE apps follow the Compare-Confirm.
In a proximity setting, where the two parties are physically co-
located, the code verification can happen by visually matching the
codes (e.g., comparing the 60-digit numerical code in WhatsApp,
or comparing the graphic in Telegram app). Some apps provide
automated code comparison by embedding the code in a QR code
that can be captured and compared by the app.
In a remote setting, the two parties can exchange the codes over
an out of band channel, for example, through a text message, or
an email. This approach is very common among several apps such
as Whatsapp, and Signal. Another method of code exchange in
a remote setting is transferring the code over an authenticated
channel, for example, through a voice call (e.g., used by Viber). This
approach assumes that the human voice channel over which the
code is exchanged is authenticated.
2.5 Threat Model
In this work, we study the common threat model followed by the
E2EE applications. It is a setting where two trusted parties, Alice
and Bob, intent to start a secure communication over an insecure
channel using only their mobile devices. In this threat model, Alice’s
and Bob’s devices are trusted. However, the communication channel
over which the key is exchanged is assumed to be fully controlled
by the attacker. That is, the attacker can intercept and modify the
key exchange messages.
The key exchange protocol is followed by an authentication
phase to defeat MITM attacks. In the proximity setting, the code
exchange channel is physically-authenticated since the users are
in close proximity and can verify each other’s identity. In the re-
mote setting, the channel over which the code is transferred should
somehow be authenticated. An example of a supposedly authenti-
cated channel is out of band messaging (e.g., SMS, email or social
media). Another authenticated channel used by the applications is
voice channel. The assumption is that the users can recognize each
other’s voice, and therefore, can authenticate each other when the
code is spoken. However, as we discuss below, even the out-of-band
or voice channels may be tampered with, at least partially.
Attacker Capability: We consider two levels of capability for the
attacker. First, we assume that the attacker does not have any con-
trol over the out-of-band or voice channel. This assumption is
generally made by the app designers and motivates them to trans-
fer the code over such channels. Even though the attacker has zero
control over the channel, she can interfere with the key exchange
protocol and run a preimage attack1 on the security codes to gen-
erate attacked codes that are the same or at least partially similar
to the legitimate security codes (in a hope that the user accepts it
due to similarity with the legitimate code). The attacker’s goal is
to guess the public key pairs that generate codes with maximum
similarity to the protocol’s legitimate security code. However, the
computational cost limits the success level of the attack. This level
of capability is considered for the attacker in several prior studies
about public key fingerprint security [21, 25].
Second, we assume that the attacker has control over some part
of the messages transferred over the out-of-band or voice channel.
That is, the attacker may be able to tamper with the exchanged
codes partially. The attacker first interferes with the key exchange
protocol, which results in two different codes at the two parties.
Then during the code exchange, the attacker tampers with the
messages transmitted over the out-of-band or voice channel by
inserting or modifying one or more bits of the transmitted code.
For example, if codeA = 1234 and codeB = 4567, the attacker may
change codeB, while it is being transmitted to Alice, to 1534 (a code
that is different from codeA in only 1 digit).
As an example for the voice-based channel, the attacker may have
access to some pre-recorded samples of the user’s voice, speaking
some of the digits that appear in the code (1, 3, and 4 in codeA, but
not 2). The attacker then tampers with the voice messages of Bob,
while Bob reads the code to Alice, and injects those pre-collected
samples (i.e., change 4 to 1, 6 to 3, and 7 to 4) so that codeB received
by Alice is 1534. Such an attack is known as a voice MITM attack
[32], which allows the attacker to tamper with the voice channel
by mimicking users’ voice or playing the pre-recorded samples.
Another instance of such part manipulation pertains to altering
the codes transmitted over the text-based channels, such as SMS,
emails, or even social media posts. Most of the E2EE apps allow
exchanging and sharing of the codes on different messaging and
social media applications. This gives the attacker the opportunity
to compromise any of these applications or the user accounts to
modify the exchanged code. Also, email and SMS spoofing2 is a
common problem that would make such attacks highly feasible
in practice. Since some of these apps have a character limit (e.g.,
Twitter and SMS apps), they may not be able to accommodate the
code in one message, and therefore have to split the code into few
parts. If the attacker is able to modify some of these fragmented
parts, the attacked code appear to be similar to the legitimate code.
In summary, we allow these two levels of capability for the
attacker, that is, the attacker may have zero or partial control over
the code, and can modify it partly via a pre-image attack indirectly
1A preimage attack on hash functions tries to find a message with a specific hash.
2e.g., a website, http://www.smsgang.com/, can be used to send spoofed SMS messages.
4
or via tampering with the auxiliary channel directly. It is worth
noting that the attacker who has full control over the code may
change the code such that it completely matches a legitimate code
and be impossible for the users to detect. In this light, such a full
manipulation attack is not the focus of our study, since this attack
may have 100% success rate (unless a user mistakenly rejects this
“attacked” matching code, which as our study shows happens up to
only about 20% of the times).
3 STUDY PRELIMINARIES AND GOALS
3.1 Study Objectives
The specific goals of the study are outlined below:
Robustness: How accurate are the users in verifying the code? Ro-
bustness directly impacts two important properties of the system:
security and usability.
• For security assessment, we are interested in determining how
often users accept mismatching security codes. False Accept Rate
(FAR) denotes the probability of incorrectly accepting such in-
stances. False acceptance implies the success of the MITM attack
and the compromise of the system.
• For usability assessment, we are interested in finding out how
often users reject matching security codes. False Reject Rate (FRR)
represents the probability of incorrectly rejecting benign in-
stances. False rejection forces the users to restart the protocol
affecting the overall usability.
User Experience and Perception: How usable do the users find
the code verification task. We define the following parameters to
measure the usability of the system:
• System Usability Scale (SUS): How easy or difficult do the users
find the system? Can the user easily learn how to use the system?
Do they need the support of a technical person?
• Comfort: How comfortable are users with the system?
• Satisfaction: How satisfied are the users with the system in veri-
• Adoptability: Are they willing to use the system in real-life?
fying the codes?
3.2 Selected Applications
We selected a collection of highly popular and representative apps,
based on the number of installations and ratings, to comprehensively
cover different code verification methods including QR, textual,
image, and voice verification. In the textual presentation, we only
picked numeric presentation, given that it is the most commonly
adopted method.
To cover all the state-of-the-art code presentation and verifica-
tion methods, and based on the popularity of the apps, we picked
WhatsApp (v.2.16.201), Viber (v.6.2.1251), Telegram (v.3.10.1), and
Signal (v.3.15.2) in our study. The complete list of studied apps is
described in Appendix A.3.
App #1—WhatsApp: WhatsApp displays the code as a QR code
and a 60-digit number represented as 12 blocks of 5-digit number.
The QR code includes a version number, the user’s identifier, and
the identity key for both parties. WhatsApp generates its 60-digit
(480-bit code by concatenating the 30-digit fingerprint of the users’
public Identity Keys3. To calculate the fingerprint, iteratively SHA-
512 of the public key is computed for 5200 times and the first 30
bytes of the final result is output as the security code.
Users have two options to verify each other’s identity. First, they
can scan the QR code of the peer user; the app then compares and
verifies the codes. This feature is helpful if the users are in close
proximity. Second, the app allows the users to exchange the code
through email or messaging applications and then manually verify
the code. This feature can be used in the remote setting.
App #2—Viber: In Viber, both devices perform DH key exchange
using their own private keys and the peer’s public key. The DH
result is hashed using SHA256 and trimmed to 160 bits. The code is
encoded as 48 digits, displayed as 12 blocks of 4-digit numbers.
To verify the code, the two parties should make a Viber call,
during which they can open the verification screen. The users
verbally announce the displayed code to each other and validate
the identity of the peer if the spoken code and the displayed code
match. Viber does not support any other out-of-band or automated
code verification method.
App #3—Telegram: Telegram generates the code by using the first
128 bits of SHA1 of the initial key (generated when Telegram Secret
Chat is first established) followed by the first 160 bits of SHA256
of the key used when the Secret Chat is updated to layer 464. The
code is displayed to the users as a shaded blue image along with a
string of 64 hexadecimal characters. Telegram does not provide a
facility to send the code directly from the app.
App #4—Signal: The version of Signal used in the study displays
the full 256 bits of the public key hash as a hexadecimal string and
a QR code. The users can scan the QR codes to verify each other’s
identity in a proximity setting or transfer it over an out-of-band
channel in a remote setting.
3.3 Study Assumptions and Hypotheses
Our hypothesis is that the apps offer a low security level, due to
human errors, in verifying the code and that the users find the code
verification to have poor usability.
Since our hypothesis is negative (apps provide a low level of se-
curity and poor usability), we design our study tailored for the near
best possible success of the attack. We assume that the applications
inform the users about the E2EE feature and importance of the
code verification task. We also assume that the users are required
to perform the code verification task. Also, we target young, and
educated users who are technology-aware. We also assume that the
users perform the code verification task whether they are planning
to start a conversation with a peer or not. This assumption implies
that users consider the code verification task as a primary task. In
practice, the primary task of the users is to pursue a conversation
and only the secondary task is to verify the code.
All these assumptions make the attack more difficult since: (1)
the users are well-informed about the security risks associated with
incorrect code verification, (2) the users are enforced and willing
to verify the code, (3) the users perform the task carefully, and (4)
they are only focused on a single task of code verification.
3Identity Key is the long-term Curve25519 key pair generated at install time
4In Telegram, the layer number is initialized at 8 when the Secret Chat is created and
is updated after receiving packets (for details, see https://core.telegram.org/api/end-to-
end.)
5
4 STUDY DESIGN
Our study was designed to evaluate the security and usability of
the code verification according to the objectives defined in Section
3.1. The study was approved by our Institutional Review Board and
standard ethical procedures were followed, e.g., participants being
informed, given choice to discontinue, and not deceived.
4.1 Code Verification Challenges
We considered two types of code verification challenges in the
study, representing benign and attack cases:
Mismatching Codes: For each set of code verification tasks, we
defined three instances of mismatching code pairs representing the
attack setting5. To study the accuracy of the participants in recog-
nizing the attacked session, except for Telegram app6, we created a
code with only one mismatching character, a code with one block
of mismatching characters (the position of the mismatching char-
acter/block(s) was randomly selected), and a completely incorrect
code. We recall that the threat model allows partial manipulation
of the codes through the preimage attack or access to part of the
messages transferred over the auxiliary channel.
Matching Codes: For each set of code verification tasks, we had
two instances of matching codes representing the benign case.
4.2 Experimental Setup and Tested Schemes
To support our study, we designed a survey using the LimeService
platform. The survey presented all the information and instructions
to the participants and guided them to complete the tasks.
To perform the tasks, each participant was provided with an
Android phone. The four applications (WhatsApp, Viber, Telegram,
and Signal) were setup on the phone and five contact names and
numbers, associated with the study examiner, were stored in the
contact list. Android is one of the most popular platforms and all
of our participants perfectly knew how to operate the smartphone.
The examiner (we call him Bob) acted as the peer in the com-
munication set-up only to read, transfer, or to show the security
codes to the participant (we call her Alice). In the benign case, Bob
displayed or read the correct codes, while in the attack case, he
showed incorrect codes.
In the proximity setting, Alice and Bob sat next to each other.
The proximity setting consisted of three types of code verification
methods summarized in Table 2 (Appendix A.2):
• P1-QR – Signal QR Code Verification: In this task, Alice
opens the code verification screen for each contact on the Signal
app to capture the QR code for Bob. The app then compares the