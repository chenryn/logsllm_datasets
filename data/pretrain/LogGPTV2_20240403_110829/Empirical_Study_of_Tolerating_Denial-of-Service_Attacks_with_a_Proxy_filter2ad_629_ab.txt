We describe the key software components used in the
empirical  study,  MicroGrid  simulation  environment,
and the resources used in the experiments.
4.1 Software Environment 
The  experiments  use  four key  components:  a  generic 
proxy network implementation, apache web server [16]
as  the  application,  a  web  testing  tool  ìsiegeî[17]  to 
simulate  user  access,  and  a  DDoS  attack 
tool 
ìTrinooî[11]. 
4.1.1 Proxy Network Implementation 
The generic  proxy  network  is composed  of  proxy
nodes.    Proxies  are  software  programs  that  forward 
application messages.  As shown in Figure 4, each pair
54
14th USENIX Security Symposium
USENIX Association
is  established  upon  proxy 
of  neighboring  proxies maintains  a  TCP connection,
which 
instantiation, 
according  to the  given  topology  and  the  bootstrap 
location  information.    The  TCP  connections  among
proxies  are persistent  and  shared among  users.
Messages can be routed inside the proxy network using 
any  given  routing  algorithm.
The  generic  proxy 
network can be configured to capture a range of proxy
networks with  different 
routing 
algorithms. 
topologies  and 
Topology Spec
Routing 
Algorithm 
User 
Proxy
Network 
Application 
collect  statistics  which  characterize  user experienced 
performance. 
4.1.4 DDoS Attack Toolkit 
Trinoo [11] is a DDoS attack toolkit generally available 
on  the  Internet.    It  includes  a  daemon  and  a  master 
program.    A  typical  trinoo network  consists of  a
collection  of  compromised  Internet  hosts  running the 
trinoo daemon program.  The master program is used to
control  this  trinoo network  to  make  DDoS  attacks. 
Given a list of IP addresses, trinoo daemons send UDP
packets  to  the  targets  at  the  given  start  time.    In  its 
original form, the trinoo daemon repeatedly sends UDP
packets  at 
  To  support  controlled 
experiments,  we  changed  trinoo daemon,  allowing  its
sending rate to be adjusted. 
full  speed. 
App Proxy
4.2 MicroGrid Simulation Toolkit 
Edge Proxy
Internal Proxy 
Figure 4 Proxy Network Prototype 
The  proxy  network 
supports TCP  applications
transparently.    We  apply  the  DNS  scheme  used  by
content delivery networks [18] to direct user access to
proxies.  As shown in Figure 4, edge proxies listen to
user connection requests, and encode application traffic 
into messages which are routed via the proxy network
to  the  application. At  the  exit  of  the  proxy  network,
application proxies (proxies that directly connect to the 
application) decode 
the  messages,  establish  new 
connections to the application if necessary, and send the 
data to the application.  Similarly, the response from the 
application  can be delivered  back  to  the  user  through 
the proxy network.
4.1.2 Application Service 
We  use  Apache  web  server  as  a  representative 
application front-end. Since we focus on the network
impact  of DoS  attacks,  specific  details  of 
the
application  logic  at  the  back-end  are not  critical.    We
use Apache web server to serve files of different sizes 
as a representative scenario. 
4.1.3 User Simulator 
We  use  siege ñ  a  web  test  toolkit  ñ  to  generate user
requests. Siege generates web requests based on a list
of  URLs,  and  measures  the  response  time  for  each  of 
the requests.  This allows us to simulate user access and 
MicroGrid  [9,  10]  is  an  integrated  online  packet-level 
simulator  that  provides  modeling  of  virtual  network
environments.  MicroGrid allows users to configure an
arbitrary virtual network, deploy it to a cluster, and then
execute  their  unmodified  applications directly  in  that 
virtual  network.   Three  key  capabilities  of  MicroGrid
are crucial to our study. 
traffic. 
levels  of 
! Ability to simulate large networks at high fidelity 
even  at  high 
  MicroGrid  has 
demonstrated good  scalability  in  realistic  large-scale 
simulations  of  networks with  20,000
routers
(comparable to a large Tier-1 ISP network like AT&T)
[19].   
Support  for  realistic  topology,  routing  and  a  full 
!
network protocol stack.  MicroGrid is integrated with a
topology  generator  maBrite[20],  which  can  create 
realistic  Internet-like  network  topologies,  and  set  up 
BGP  routing  policies  automatically  based  on realistic
Internet  AS  relationships.    It  supports  Internet  routing
protocols  such  as  BGP  [21]  and  OSPF  [22].    It  also
supports networking  protocols,  such  as  IP,  UDP,  TCP 
[23] and ICMP [24]. 
Support 
!
applications. 
These  capabilities  of  MicroGrid  allow  us to  study  the 
properties  of  the  proxy network  and  detailed  behavior
of the system in a large-scale network environment with
realistic  settings,  running real  applications  and  real
attacks.    These  capabilities  are  markedly greater  than 
testbeds  such  as  PlanetLab  [25]  or  small  scale 
simulators such as NS2 [26], where the scale, intensity 
for  direct  execution  of unmodified 
USENIX Association
14th USENIX Security Symposium
55
Performance Implication of ProxyNetwork (1.5KB file)
1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
i
n
o
at
ul
p
o
P
r
e
s
U
r
e
v
O
F 
D
C
and  range  of  attack  scenarios  that  can  be  studied  are 
limited.
4.3 Simulation Setup 
4.3.1 Simulated Network  
Siege: User Simulator 
Trinoo attackers 
Proxy Network
Apache 
Server 
MicroGrid Simulated Network
0
0
0.1
0.2
Direct Application Access
Access via Proxy Network
0.3
0.6
Response Time (seconds)
0.4
0.5
0.7
0.8
0.9
1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
Performance Implication of ProxyNetwork (100KB file)
Direct Application Access
Access via Proxy Network
i
n
o
at
ul
p
o
P
er
Us
er
v
O
F 
D
C
Cluster 
0
0
0.5
1
1.5
2
2.5
Response Time (seconds)
Figure 5 Experiment Setup 
in 
As  shown  in  Figure  5,  the  proxy network,  apache
server,  siege  programs  and 
trinoo  attackers  are 
deployed 
the  MicroGrid 
simulated  network 
environment. The maBrite topology generator is used
to  create  Internet-like  Power-Law  network  topologies 
[20, 27].    We  use  two virtual  networks  in  our
experiments.  One (named R1K) includes 1000 routers 
and  20  ASes,  and  the  other  (named  R10K)  includes 
10,000 routers and 40 ASes, which is comparable to the 
size  of  a  large  ISP  network.    Both  networks  span  a
geographic area of 5000 miles by 5000 miles, which is
roughly the size of the North American continent.  This
physical extent determines link latencies.  OSPF routing 
is used inside ASes; BGP4 is used for inter-AS routing.
4.3.2 Physical Resources 
Our  experiments  use two  clusters. The MicroGrid
simulator runs on a 16-node dual 2.4GHz Xeon Linux 
cluster  with 1GB  main  memory  on  each  machine, 
connected by a 1Gbps Ethernet switch. Other software
components run on a 24-node dual 450MHz PII Linux 
cluster  with 1GB  main  memory  on  each  machine, 
connected  by  a  100Mbps  Ethernet  switch.  These  two 
clusters are connected with a 1Gbps link.
5 Experiments and Results 
We  study  the  performance  implications  and  DoS 
resilience of proxy networks, and address the problems
stated in Section 3.  
1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
Performance Implication of Proxy Network (1MB file)
 Direct Application Access
Access via Proxy Network
i
n
o
at
ul
p
o
P
er
s
U
er
v
O
F
D
C
0
0
2
4
6
8
10
12
14
Response Time (seconds)
Figure 6 Proxy Network Performance
5.1 Proxy Network Performance 
To  understand  the  basic  performance  implications  of
the  proxy  network  approach,  we  compare  the  user-
observed  service  performance  for  direct  application 
access  and  proxy network  mediation.    Users  choose 
edge  proxies  based  on proximity,  and  no user
authentication is used. 
The  proxy network  is deployed  in  a  resource  pool  of
1000 hosts randomly sampled from the network.  The
following  heuristic  is  used  to  deploy  proxies  in this 
resource pool.  Edge proxies are distributed uniformly 
across  the  resource  pool.  Application  proxies  (see 
Section  4.1)  are  placed  on  those  hosts  in  the  resource
pool which are relatively close to the application.  The 
remaining proxies are distributed evenly between edge
proxies and application proxies.  This heuristic maps a 
proxy  network  to  a given  resource  pool  of Internet
hosts, trying to align the proxy network structure with
underlying  network  to  avoid  long detours  in  overlay 
routes. 
Figure  6  shows  the  results  in  the  R1K  simulated
network  (described  in  Section  4.3)  for a  tree-topology
56
14th USENIX Security Symposium
USENIX Association
192-node proxy network, with 64 edge proxies.  The X-
axis is the response time for a user to download files of
a  given size  (1.5KB,  100KB or  1MB).   We  plot the 
measured  performance  for  direct  access  and  proxy
network mediation.  The Y-axis is Cumulative Density
Function (CDF)  of  user-observed  response time over 
the user population.  Hence a curve closer to the Y-axis
implies that more users have good response time. 
one  might  expect  proxies 
While
to  degrade 
performance, the proxy network improves performance.
For  small  requests  (e.g.  1.5KB),  the  50-percentile 
response time is reduced by half; for requests of modest
sizes  (e.g.  100KB),  the  improvement  is  even  more 
significant, and so is the case of large files (e.g. 1MB). 
There are three main reasons for these phenomena: 
User 
Proxy
Network 
Application 
Figure 7 Direct Access vs. Proxy Network
1. Proxy  network  improves  connection  set  up  time. 
As  described  in  Section  4.1  (see  Figure 7),  there
are  established  TCP  connections  among  proxies. 
For each virtual connection between a user and the 
application,  instead of  establishing  a  long  TCP 
connection  from  the  user  to  the  application,  two
shorter TCP connections are established: one from
the user to the edge proxy, and the other from the 
corresponding application proxy to the application.
Both  of  them  have  small  RTT  (round  trip  time), 
since  application  proxies  are  close 
the 
application,  and  users  choose  edge  proxies  based 
on proximity.  Since the TCP handshake [23] takes 
1.5 RTT, the connection setup cost can be reduced
by one RTT between the user and the application2.  
This  effect  is  prominent  for  small  requests  (e.g. 
1.5KB) as shown in Figure 6. 
to 
2. The TCP connections among proxies are persistent,
and in most cases the TCP congestion windows for 
those  connections have  already been  fully opened
by previous data transfers and other usersí traffic.
Thus, they no longer suffer a slow start phase [23]
to  grow  the  congestion window.    For  requests  of
modest sizes (e.g. 100KB shown in Figure 6), this
effect is most prominent.  
3. A  series  of  shorter  TCP  connections  can  also
improve  throughput  and  robustness  as  studied  in 
Logistic Networking [28].    Here  we  give a  brief
explanation, and details can be found in [28].  The 
throughput  can  be  improved  because  the  TCP 
throughput is roughly TCP send buffer size divided 
by RTT, and the connections among proxies have
shorter  RTTs  comparing  to the  RTT  between  the
user and the application.  The throughput effect can 
be  seen  for  large  requests  (e.g.  1MB  shown  in
Figure 6). 
Varying Proxy Network Topology
64 Edges, Height 4
1
0.9
0.8
0.7