access already-obtained congruent addresses to accelerate TARGET
becoming the LLC eviction candidate. Thus, the number of inner-
loop iterations is expected to decrease as the algorithm proceeds.
To increase the robustness, we test whether the resulting set
successfully evicts the TARGET. If not, an extra address is found, and
the test is repeated. The number of failures until the test succeeds re-
veals the number of false positives in the set, which can be removed
through a short reduction phase, akin to prior work [37, 60, 65].
The algorithm is identical for huge and small virtual memory
pages, but the availability of huge pages speeds up the runtime
significantly, as the guesses are more likely to be congruent due to
the increased control over physical address bits [37, 60].
Algorithm: CD. On non-inclusive Intel caches, the set index map-
ping for the LLC and CD is identical. Hence, eviction sets con-
structed for one may be used for the other. Finding congruent
addresses through contention on the CD is challenging, as congru-
ence in the CD implies congruence in L2 [65], and TARGET may be
Algorithm 2 Eviction Set Construction
Input: TARGET: address for which an LLC eviction set is desired
Output: ES: eviction set
1: ES ‚Üê empty list
2: length ‚Üê 0
3: while length < LLC_WAYS do
4:
5:
6:
7:
8:
9:
10: end while
GUESS ‚Üê a line possibly congruent to the TARGET
access(GUESS)
access(TARGET)
do
while access(TARGET) is fast
ES[length++] ‚Üê GUESS
Figure 11: Median encryptions for AES T-tables (bars in-
dicate 10-90th percentiles). Comparison of Prime+Scope
(PS) with traditional Prime+Probe (PP) and Flush+Reload
(FR), as well as differential-time Prime+Probe (PPv2).
leakage. Information is obtained through differential time between
the start of the AES_encrypt function and one or more table entries.
We use the cache attack as an oracle for accesses to table entries
during the first AES round. We spin up a thread for each monitored
line (including the first instruction cache line of AES_encrypt). The
adversary triggers encryptions, and each thread records the times-
tamp at which the access is detected (if any) for the monitored table
entry. Then, the differential times are used to score the key nibble
hypotheses. The larger the differential time, the larger the penalty
for the key nibble, as the probability is lower that it corresponds to
a first-round access. For a table access in the first round, we observe
the differential time to be around 200-300 cycles.
An advantage of this attack is that every trace carries information
for each monitored table entry, as opposed to only 7.5% for the
traditional first-round attack. Note that a single-threaded Prime+
Scope can also record differential times, but the temporal resolution
decreases linearly with the number of lines scoped in one thread.
Variable-Time Access: Prime+Probe? For comparison, we explore
whether Prime+Probe can also learn from the differential time. To
capture the maximal performance of Prime+Probe, we consider
an optimal, windowless configuration; the Prime is the same as for
Prime+Scope, and the Probe is the simple, unordered traversal of
the set (pattern R1_S1_P0). According to Figure 6iii), we expect a
precision of approx. 400 cycles (cf. 70 cycles for Prime+Scope).
Results. Figure 11 presents the results on the LLC of an Intel Core
i7-7700K (Kaby Lake, 16 ways). It shows the number of encryptions
needed to mount the full first-round attack, which recovers 64 of
the 128 key bits. We consider the key nibble found as soon as the
hypothesis converges (i.e., it reaches the correct value and does not
diverge from it). We perform 1 000 iterations and indicate the me-
dian and 10th and 90th percentiles to convey the variance. Note that
these results are obtained without degrading victim performance
(other than indirectly through the cache sets that are monitored).
Prime+Scope retrieves the secret information with fewer traces
(between 5-25x) than the traditional Prime+Probe. The differential-
time Prime+Probe is also able to capture some of the temporal
information, but again more slowly, with more traces than Prime+
Scope (10-70x). When only a single table entry is monitored in
every encryption, we find that it fails to recover the secret even
123451001,00010,000100,000TableentriesmonitoredEncryptionsPPFRPSPPv2Session 11A: Attestation and Firmware Security CCS ‚Äô21, November 15‚Äì19, 2021, Virtual Event, Republic of Korea2916Table 2: Runtime (median) and accuracy (%) for eviction set
construction (1 000 runs for randomly selected targets)
Ours
99%
Huge
0.25 ms
Vila et al. [60]
Huge‚àó
Small‚àó
316.3 ms
165.2 ms
Processor
Cache
Skylake
12 Way LLC
Skylake
100%
98%
16 Way LLC
Skylake-SP
NA
NA
12 Way CD
NA
NA
‚àó Initial set size for 12
16 Way LLC is 65
90 for huge pages, 3500
113.2 ms
643.8 ms
100%
0.55 ms
96%
3.15 ms
100%
99%
Small
2.80 ms
99%
4.03 ms
100%
35.40 ms
93%
4000 for small.
evicted due to contention on L2, leading to false positives. Thus,
like prior work [65], we perform the construction on the LLC.
The routine is similar to in Algorithm 2. However, recall that
the LLC is non-inclusive, so the memory accesses on lines 4 and
7 do not guarantee the installation of the TARGET and the GUESSes
in the LLC. We replace them with joint accesses by the attacker
thread and a helper thread on another CPU core, as we observed
that accesses from two cores place a copy of the line into the LLC1.
Platforms. We tested the eviction set construction on all the ma-
chines in Table 1, as we had to obtain eviction sets for PrimeTime.
To compare with other work, we perform a detailed comparison
on the Skylake microarchitectures in Table 2. Apart from the dif-
ferences for inclusive and non-inclusive LLCs and a parameter for
LLC associativity, it requires no adaptation to the processor.
Comparison. Vila et al. [60] study eviction set construction in
detail, and propose a linear-time algorithm that improves over the
quadratic-time baseline [37]. These routines iteratively remove one
or more lines from a big initial set, measuring whether the residual
set still evicts the target. In contrast, Algorithm 2 starts from an
empty set, and adds congruent lines to it. It overcomes practical
problems identified by previous works, such as the dependence on
replacement policies (and their adaptivity) [60], TLB thrashing [20],
and hardware prefetchers [55]. Similar to prior techniques [37, 60,
65], it does not require knowledge of the slicing function.
Because our implementation does not require any preparation
steps, such as organizing the memory space in a linked list, or
selecting a suitable starting set, we take into account the total exe-
cution time of the construction routine, which includes the time
spent for failed preparation steps in addition to the last successful
reduction step. As shown in Table 2, our implementation executes
up to 660x faster than the one by Vila et al. [60], while achieving
the same success rate (where success is defined as a set of ùëä ad-
dresses that consistently evicts the target). Furthermore, the default
configuration is adequate for successful execution on all tested Intel
processors, while containing only a few configuration parameters.
For non-inclusive caches, only the initial study by Yan et al. [65]
describes how to find LLC/CD eviction sets. They adapt the congru-
ence test of earlier work [37] to overcome the challenges provided
by non-inclusive LLCs. Compared to ours, their routine has the
1For more information, we refer the reader to
https://www.github.com/KULeuven-COSIC/PRIME-SCOPE/evsets.
advantage of being single-threaded. As performance metrics are
not provided in [65], we are unable to directly compare our work
with theirs. However, it has quadratic complexity, and is so far un-
successful when huge pages are not available. Even if their routine
is adapted to linear time (e.g., [60]), we expect our algorithm to
outperform it, in accordance with the findings for inclusive caches.
7 RELATED WORK
7.1 Classification of Attack Techniques
Complementing the quantitative study in Section 6, Table 3 posi-
tions Prime+Scope with respect to existing cross-core cache attack
techniques on the basis of prerequisites and features.
Prerequisites. The most basic requirement is co-tenancy, where
the attacker can run unprivileged code (native or otherwise) on the
same physical machine as a victim. As long as both parties share at
least one cache level, an attacker can measure contention on shared
cache resources (as is done for Prime+Probe and Prime+Scope).
Some techniques are predicated on additional capabilities, such
as shared memory with the victim, the presence of a clflush in-
struction, or special processor features like Intel‚Äôs TSX. These extra
capabilities can increase the power of the technique, e.g., in terms
of spatial resolution or reliability. However, the additional prerequi-
sites limit the applicability of these techniques. For instance, shared
memory is discouraged in multi-tenant clouds, and clflush may
not be available to code that is not running natively on the system
(e.g., in the browser). Intel TSX is not available on all Intel CPUs and,
for those where it is available, Intel has added support to disable
it [30] in response to recent transient execution attacks [50, 58].
Features. The most relevant features to this work are whether a
technique can be instantiated in a windowless paradigm, and the
number of cache accesses for each measurement.
In terms of spatial granularity, techniques based on shared me-
mory can infer accesses to specific cache lines, whereas cache con-
tention attacks are fundamentally limited to set-granularity. Prime+
Scope belongs to the latter category. Table 3 also indicates which
techniques have been shown on CDs of non-inclusive LLCs [65].
Measuring multiple events enriches the information content of
the channel and is an essential requirement to record differential
times (cf. Section 6). Prime+Abort cannot monitor multiple events
while maintaining the ability to distinguish between them [18].
Other techniques can do so, but may have to take the influence of
spatial hardware prefetching into account [26, 61, 66].
Other Properties. Some techniques are tailored to overcome spe-
cific system-level constraints. Cache occupancy attacks [53] forego
the search for congruent addresses and instead measure contention
on a cache-sized buffer. This makes them amenable for deployment
in (very) restricted environments [52], at the cost of all spatial gran-
ularity and significant time precision. Some techniques offer stealth
against runtime detection [11, 25], or bypass software-based coun-
termeasures with indirect cache accesses [57]. Exploring Prime+
Scope in these system models is beyond the scope of this work.
Session 11A: Attestation and Firmware Security CCS ‚Äô21, November 15‚Äì19, 2021, Virtual Event, Republic of Korea2917Table 3: Classification of cross-core cache attack techniques in terms of prerequisites and features
Mechanism
Prerequisites
Features
Attack
Technique
Leakage
Source
Spatial
Granularity
No Shared
Mem.
No
clflush
Flush+Reload [67]
Flush+Flush [25]
Evict+Reload [26]
Reload+Refresh [11]
Prime+Probe [31, 37]
Occupancy [53]
Prime+Abort [18]
Prime+Scope
load latency
load latency
load latency
repl. state
contention
contention
TSX abort
contention
line
line
line
line
set
none
set
set
‚úó
‚úó
‚úó
‚úó
‚úì
‚úì
‚úì
‚úì
‚úó
‚úó
‚úì
‚úó
‚úì
‚úì
‚úì
‚úì
No
TSX
‚úì
‚úì
‚úì
‚úì
‚úì
‚úì
‚úó
‚úì
Window-
less
‚úó
‚úì
‚úó
‚úó
‚úì
‚úó
‚úì
‚úì
Measure
Size
Multi-
Target
Shown
on CD
1‚úì
1‚úì
1‚úì
2‚úì
ùëä‚úó
huge‚úó
‚àÖ‚úì
1‚úì
‚úì
‚úì
‚úì
‚úì
‚úì
‚úó
‚úó
‚úì
‚úì
‚úì
‚úì
‚úó
‚úì