the analysis results when the adversary ASes are Tier-1 and
victims are in all the ASes in the Internet. In the majority of the
cases (e.g., 85%), there exist more than 100 available shadow
ASes; see the solid line. Although only a small number of
existing, real Bitcoin nodes can be used as shadow IPs (see
the dotted line), almost all Tier-1 ASes (e.g., in 99.5% of our
tested cases) can target victim nodes in any AS with more than
100 unique preﬁx groups distributed in more than a million of
shadow IPs (see the dashed and dash-dot lines).
Figure 3b shows the analysis results when the adversary
ASes are top-100 ASes and victims are 100 random ASes. The
top-100 ASes (which include many Tier-2 ASes) tend to have
less resource (e.g., shadow ASes, preﬁx groups, shadow IPs),
compared to the Tier-1 adversary ASes. Yet, in the majority
(e.g., 85%) cases, the adversary ASes still can utilize 100 or
more unique preﬁx groups; see the dashed line. Also, more
than a million shadow IP addresses are available in 80% of
cases; see the dash-dot line.
C. Geographical Distribution of Shadow IPs
In addition to the distribution in the IP address space,
we also investigate how shadow ASes are geographically
distributed. A cautious Bitcoin node may suspect the EREBUS
attack if its peers are located in a restricted geographic area;
e.g., it would look suspicious if all outgoing connections are
made to one geographic region.
In our case study, we consider Amazon (AS 16509) as
the AS hosting the victim node, as cloud providers host the
majority Bitcoin nodes and would be common targets of this
attack [23]. We choose ﬁve largest Tier-2 ASes in each of the
ﬁve continents, i.e., North America, South America, Europe,
Asia-Paciﬁc, and Africa, as our adversary ASes.4 We show
the geographic distribution of the shadow ASes of the ﬁve
scenarios in Figure 4. Shadow ASes seem to be well dis-
tributed globally despite the location of the adversary ASes. In
particular, in four out of ﬁve tested scenarios, the adversary AS
has shadow ASes distributed in all ﬁve continents. This result
suggests that a strategic adversary can carefully select shadow
ASes so that the victim’s connections look geographically
diverse.
V. CREATING VICTIM-SHADOW PEERING CONNECTIONS
In this section, we describe the attack execution phase,
in which the adversary ultimately occupies all the peering
connections of a victim node with shadow IP addresses. We
begin with a brief overview of the Bitcoin peer-to-peer network
according to the most recent (as of June 2019) Bitcoin core
v0.18.0 [11], focusing on how a Bitcoin node establishes its
incoming and outgoing connections (§V-A). We then present
the attack strategies to dominate the two parts of the internal
peer database of a victim node with shadow IPs, i.e., the new
table (§V-B) and the tried table (§V-C), which subsequently
allow the adversary to occupy all outgoing connections of
the victim. We ﬁnally describe how an EREBUS adversary
occupies the incoming connections of a victim Bitcoin node
(§V-D).
A. Bitcoin’s Peer Connection Mechanisms
A Bitcoin node with a routable IP address can have several
peer connections with other nodes, particularly, up to 8 outgo-
ing peers and 117 incoming peers. Bitcoin nodes accept any
incoming connections from other peers with any IP addresses
unless the peers have been banned due to sending invalid
messages. Outgoing peers, however, are carefully selected
from the pool of IP addresses managed by individual Bitcoin
nodes. This pool contains IP addresses of other nodes in the
network, which Bitcoin nodes learn mainly from the addr
messages.5 The learned IP addresses are stored in the hard
disks in two tables: a new table contains the IPs it has received
but yet to connect and a tried table contains the IP addresses
that it has once successfully made an outgoing connection to.
The new and tried tables have 65,536 and 16,384 slots for
IP addresses, respectively. Bitcoin nodes select a random IP
4Tier-1 ASes have shadow IPs with much better geographic distribution.
5Particularly, each node periodically advertises its IP address via addr
messages to its peers, which are further relayed to the rest of the network.
DNS seeds, which contain a limited number of reliable Bitcoin nodes, can
also be another source of IPs when the Bitcoin nodes ﬁrst join the network.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:19:22 UTC from IEEE Xplore.  Restrictions apply. 
899
(a) North America (AS 6939)
(b) South America (AS 16735)
(c) Europe (AS 1273)
(d) Asia-Paciﬁc (AS 4637)
(e) Africa (AS 37468)
Figure 4: Maps of geographic locations of shadow ASes (blue pins) in ﬁve case studies where victim AS (black pin) is Amazon
(AS 16509) and the attacker ASes (red pins) are the largest Tier-2 ASes in ﬁve continents.
address from the two tables to make an outgoing connection
to until all eight outgoing slots are occupied.
Why is occupying victim’s outgoing connections hard?
The adversary’s goal is to ﬁll the two internal tables of the
victim node with shadow IPs as much as possible to maximize
the chance of a new outgoing connection made to a shadow
IP. This, however, is not trivial, particularly after a series of
countermeasures were deployed for Eclipse defense, because
IP addresses cannot be inserted into the tried table directly.
The EREBUS adversary aims to ﬁll the new table ﬁrst (see
Section V-B) and then occupy the tried indirectly with a
trickle-down attack strategy (see Section V-C).
B. Flooding the New Table with Shadow IPs
The EREBUS adversary selects a shadow node IP address,
say ipa, from the IPs harvested in the reconnaissance step and
makes a peering connection (i.e., a TCP session followed by
a version handshake) with the victim node on behalf of ipa
(i.e., the source IP spoofed with ipa). The replies (e.g., TCP
SYN/ACK, Bitcoin version/verack) from the victim node
to ipa are captured by the adversary AS because she is on the
victim-to-shadow path. The adversary sends addr messages,
each of which contains up to 1,000 shadow IP addresses, to
the victim node and the shadow IPs are inserted into the new
table of the victim node.
When a Bitcoin node inserts an IP address ip to its new
table, it hashes the IP preﬁx group (ip group) (i.e., the /16
of IPv4 addresses or /32 IPv6 addresses) and the preﬁx group
of the peer relayed that IP (peer group) to determine the
bucket for the IP among 1,024 buckets in total; i.e.,
h1 = H(SK, ip_group, peer_group)
h2 = H(SK, peer_group, h1 % 64)
new_bucket = h2 % 1024,
where H(·) is the SHA-256 hash function and SK is a secret
key of the node. The exact slot for ip in the bucket (which
contains 64 slots) is determined by hashing the bucket index
and the entire IP address; i.e.,
new_slot = H(SK, (cid:2)N(cid:2), new_bucket, ip) % 64.
If the slot is already occupied, the existing IP address is
tested with several checks to consider if it is terrible (e.g.,
the existing IP is more than 30 days old, has failed several
connecting attempts). If the existing IP is terrible, it is
replaced by the new IP that is being inserted; otherwise, the
IP being inserted is ignored. Note that IP addresses are stored
along with a timestamp. If the IP is already in the new table,
its timestamp is updated.
60000
50000
40000
30000
20000
10000
d
e
l
l
i
f
f
o
r
e
b
m
u
N
l
e
b
a
t
w
e
n
n
i
s
t
o
s
l
2000
1500
1000
500
s
e
g
a
s
s
e
m
r
d
d
a
f
o
r
e
b
m
u
N
l
e
b
a
t
w
e
n
%
9
9
l
l
i
f
o
t
t
n
e
s
Analysis
Simulation
Number of addr messages
0    
100
101
102
103
Number of Unique Prefix Groups
0
102
103
104
Number of Unique Prefix Groups
(a)
(b)
Figure 5: Number of unique preﬁx groups to ﬁll the new
table reliably. (a) Number of ﬁlled slots in new table versus
number of unique preﬁx groups with results from Equation (1)
and Simulation. (b) Number of addr messages (each contains
1,000 shadow IPs) sent to ﬁll at least 99% of the new table.
Dominating the new table with shadow IPs. The adversary
repeatedly establishes incoming connections on behalf differ-
ent shadow IPs and inserts new shadow node IPs into the
new table at a much higher (e.g., ten times) rate than the rate
of incoming non-shadow IPs, which eventually replace most
existing IPs in the new table.6 We show that in Section VI
that the adversary can easily make the shadow IPs be the vast
majority (e.g., 99%) of all the reachable IP addresses in the
new table in about 30 days.
How many unique preﬁx groups are needed? The bucket
of an inserted shadow IP in the new table is determined by
its preﬁx group. Thus, the more unique preﬁx groups are
available in the pool of shadow IPs, the easier to ﬂood all
the buckets. We evaluate how many unique preﬁx groups
are enough for the adversary AS to ﬁll all the buckets (and
their slots) easily. Suppose that the adversary controls shadow
IPs in g unique preﬁx groups. When sending a shadow IP,
says ip, to the victim on behalf of a shadow node, says
peer, the allocated bucket in the new table is determined by
the preﬁx groups of two IPs; i.e., (ip group, peer group).
The adversary then may have at most g2 unique pairs of
(ip group, peer group). Considering each pair is allocated
1024 and
randomly into a new bucket with the probability of
X is the number of distinct new buckets allocated for g2 pairs,
the expected value of X is determined by:
1
(cid:2)
(cid:3)
1
E[X] = 1024 ×
1 − (1 −
)g2
.
1024
(1)
Figure 5a illustrates the relationship between the number of
unique preﬁx groups and the expected number of ﬁlled slots of
6The attack trafﬁc rate, however, will be only about 1×–2× the rate of
normal conditions because the incoming rate of non-shadow IPs is already
reduced signiﬁcantly (e.g., 10%).
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:19:22 UTC from IEEE Xplore.  Restrictions apply. 
900
a new table in Eq. (1) in the dotted line. The solid line denotes
the simulation of the IP allocation with the IPs selected from
the pool of available shadow IPs in 10K of attack-victim ASes
scenarios (enumerated in Section IV). We can see that the
analysis result matches well with the simulation result; all the
slots in a new table can be occupied reliably when g (cid:2) 100.
We further test this with an experiment of sending shadow
IPs to an actual Bitcoin client running in our lab. As a baseline
attack script, we have implemented a rudimentary Bitcoin
client that is able to receive and send customized (e.g., source
IP spooﬁng) Bitcoin messages (see Section VI for implemen-
tation details). We sample 100 pairs of attacker-victim ASes
from the enumerated 10K of pairs (Section IV-B) and use the
actual shadow IPs from those pairs in our experiments. In
all tests, the victim node is freshly-born with its new table
initially empty. Our attack script ﬂoods the Bitcoin client with
addr messages with spoofed shadow IPs, each containing
1,000 unique shadow IP addresses; see Appendix C for our
efﬁcient shadow IP selection algorithms. Figure 5b illustrates
the number of addr messages that should be sent in order to
have 99% slots of the new table occupied by the shadow IPs.
Figure 5b shows that, in general, 100 unique preﬁx groups are
sufﬁcient to insert IPs into most of the slots in the new table.
Moreover, the more diverse the shadow IPs are, the fewer
number of IPs are needed. For instance, with 500 or more
preﬁx groups, one can easily occupy most of the new table
slots with as few as 500 addr messages, or 500K shadow IPs.
We omit 17 out of 100 cases in which we have less than 100
preﬁx groups from the Figure 5b because we cannot occupy
99% of the new table even after an extremely large number of
addr messages are sent.
Note that from Section IV we have observed that Tier-1
adversary ASes have at least 100 preﬁx groups with 99.5%
probability. With the above analysis, we conﬁrm that Tier-1
ASes can target nearly all the 10K Bitcoin nodes that accept
incoming connections.
C. Trickle-down Migration to Fill the Tried Table
In the current Bitcoin implementation, the only way to insert
an IP address into the tried table is to move it from the
new table after a successful outgoing connection made to that
IP address. This is to ensure that (1) any remote adversaries
cannot directly insert IP addresses into the tried table; and
(2) the IPs in the tried table are likely reachable [33].
Nevertheless, our EREBUS attack indirectly and patiently ﬁlls
up the tried table with the shadow IP addresses by exploiting
what we call the trickle-down effect.
In particular, there are two scenarios for an IP address to be
migrated from new table to the tried table: (1) an outgoing
connection is made to an IP address in the new table and the
IP address is inserted to the tried table; and (2) periodically
(every two minutes) an IP address is randomly selected from
the new table and moved to the tried table if it is reachable.
First, when a new outgoing connection is made, a Bitcoin
node selects either the new or tried table with equal proba-
bility; then, it chooses a random IP address from the selected
table. If an IP address is selected from the new table and
successfully connected, it is moved to the tried table while
its copies are removed from the new table. When inserting the
IP to the tried table, a Bitcoin node uses the IP’s group to
determine its bucket and slot indexes; i.e.,
h1 = H(SK, ip)
h2 = H(SK, ip_group, h1 % 8)
tried_bucket = h2 % 256
tried_slot = H(SK, (cid:2)K(cid:2), tried_bucket, ip) % 64.
Second, a Bitcoin node makes an additional, ephemeral
outgoing connection, called a feeler connection, every two
minutes to test the reachability of a randomly selected IP
address from the new table [28].7 If the selected IP from the
new table is found to be reachable via the feeler connection,
it is inserted into the tried table. If the IP being inserted
collides with an existing IP in the same bucket and slot, the
existing one’s reachability is tested [27]. If the existing IP is
not reachable, the new IP address replaces the existing IP in
the tried table while the existing IP is inserted back to the
new table; otherwise, no change is made.
Trickle-down attack strategy. The EREBUS attack ﬁrst occu-
pies the new table slots as much as possible with the shadow
IPs and then patiently waits for them to be migrated to the
tried table and ultimately dominate the tried table as well.
We call this a trickle-down attack strategy. We show that in
our evaluation in Section VI Tier-1 or large Tier-2 ASes can
inject enough numbers of shadow IPs into the tried table of
a victim node to control all the eight outgoing connections in
a few weeks of attack duration.
Adaptive attack strategy. We further propose an optional
adaptive attack strategy to speed up the attack execution phase.
In the baseline trickle-down attack strategy, an adversary AS
would wait until the probability of all the eight outgoing
connections made to shadow IPs becomes large enough (e.g.,
30% or 50%) and trigger a reboot of the victim node. Note
that rebooting a targeted Bitcoin node has been demonstrated
with several methods including, but not limited to, denial-of-
service or exploiting Bitcoin client’s vulnerabilities [29]. In
our adaptive attack strategy, an adversary AS keeps tracking
of the outgoing connections of the victim node that are already
made to shadow IPs. When the adversary AS is a large transit
AS, the victim node often has some outgoing connections
naturally made to shadow IPs even before attacks. Moreover,
as the attack progresses, some of existing outgoing connections
expire naturally and new outgoing connections can be made