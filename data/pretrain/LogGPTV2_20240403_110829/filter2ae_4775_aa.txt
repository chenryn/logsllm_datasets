## 前言
上一篇文章，简单介绍了一下Python框架下如何去玩跳一跳 [AlphaJump -如何用机器学习去玩微信小游戏跳一跳(一)](https://xianzhi.aliyun.com/forum/topic/1881 "AlphaJump -如何用机器学习去玩微信小游戏跳一跳\(一\)")。
主要通过判断下一跳的位置和棋子的距离来计算屏幕按压时间，使得棋子可以精准的抵达下一跳的位置。
不同屏幕对应的系数并不一样，这里给出1080*1920下的参数和公式
  * 单位 200 ms
  * 系数 1.35
  * 按压时间 = （棋子与下一跳的距离）x 1.35 x 200
这一篇主要介绍如何使用Tensorflow的物体识别的API去检测跳一跳中的物体以及搭建自己的识别别框架用于。
## 准备工作
由于之前不小心搞坏了linux环境以及最近特别多的漏洞需要各种研究分析一直没机会处理，最近终于用闲暇时间在window上搭建起来。赶紧把文补上。先来上一下基础环境配置
  * 物理环境
    * CPU E3-1231
    * GTX 970 显存 4G
    * 内存 16G
  * 软件环境
    * win7 64
    * 388.71 Nvida驱动
    * cuda_8.0.61_windows.exe
    * python 3.5 
    * tensorflow GPU 1.4.0 
在你准备好python3.5 以及 tensorflow 后。就可以开始安装 **object_detection**
了。由于涉及的类和库非常的多，分离起来十分困难，直接下载tensorflow下的models。以后学习研究也非常方便。
### 安装配置 object_detection
官方的安装说明
[installation](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/installation.md)
也可以按照我的来
  * 下载 models 
    * 保存为 models/ 
    * 注：我们需要的API在models/research/object_detection 目录下
  * 根据系统类型 下载 Protobuf [下载地址](https://github.com/google/protobuf/releases "Protobuf")
    * 把protobuf的目录添加环境变量 
    * 测试 shell>protoc  
Missing input file.
  * pip 安装其余的库
    * sudo pip install pillow
    * sudo pip install lxml
    * sudo pip install jupyter
    * sudo pip install matplotlib
  * protoc 转换协议  
在 models/research/ 目录下执行  
protoc object_detection/protos/*.proto --python_out=.
  * 添加PYTHONPATH环境变量
    * PYTHONPATH=models/research/slim 
  * 测试
`python models/research/object_detection/builders/model_builder_test.py`
  * 此时如果提示 ImportError: No module named 'object_detection' 在该文件头部添加以下三行
-    
        import sys
    sys.path.append("E:/models/research/object_detection")
    sys.path.append("E:/models/research")
    * E:/models 改成 你放models的目录 
  * 输出 
        Ran 11 tests in 0.047s
      OK
测试通过 此时准备工作基本完整完成，接下来要搭建我们识别程序的框架。
## 搭建识别框架
### 框架结构
我在这篇文章中说过
[使用TensorFlow自动识别验证码（一）](https://xianzhi.aliyun.com/forum/topic/1505)
深度学习的基本思路是
  * 采样
  * 创建识别模型
  * 生成训练样本和测试样本
  * 训练样本和测试样本来训练识别模型
  * 保存和验证
我们框架也是依据此来建立目录
  * objectdecting_wechatjump 框架目录
    * imgandxml
      * 包含原图库 : 初始化的屏幕截图 [根据[AlphaJump - 如何用机器学习去玩微信小游戏跳一跳(一)](https://xianzhi.aliyun.com/forum/topic/1881 "AlphaJump - 如何用机器学习去玩微信小游戏跳一跳\(一) 获得大量的截图]
      * 采样数据 （xml格式）
    * record 
      * 测试数据集 和 训练数据集
    * modle
      * result 最终输出的模型
      * train 训练中的模型
      * train_set 识别模型以及模型训练设置
    * test 
      * 验证图片
### 开始训练
#### 采样数据
为了简单，我这里把图片的物体分为两种
  * movtarget ：移动的棋子
  * jumptarget ：可以跳跃平台面
    * 这里平台面就是目标位置的顶部部分
但 tensorflow 并不能直接识别图片，需要一种叫 **tfrecord** 格式的才可以进入模型训练。
在目录 **models\research\object_detection\dataset_tools** 下提供了多种的格式转换工具。
这里我选择的 [datitran](https://github.com/datitran/raccoon_dataset "datitran")
使用的采样方式 。
  * 使用labelimg给图片打标签生成xml
  * 通过 **xml_to_csv** 的脚本转为 pascal voc的格式
  * 再稍微修改 **dataset_tools** 下的 **create_pascal_tf_record.py** 即可转为 tensorflow可以识别的 **record** 格式 
  * labelimg的使用非常简单
    * 下载回来后 打开->选择图片文件夹->一个个画框打标签
    * 打完标签后会在对应的目录下生成一个xml文件
我这里一共手工标注了250张的图片。 把这些图片和XML分成两份，一份34，一份216 分别放到
  * 216 用于训练模型 放到 objectdecting_wechatjump\imgandxml\train
  * 34 用于训练中的检测 放到 objectdecting_wechatjump\imgandxml\eval
把 在 [datitran](https://github.com/datitran/raccoon_dataset "datitran") 下载回来的
xml_to_csv.py 文件放到 objectdecting_wechatjump 目录下
  * 把 objectdecting_wechatjump\imgandxml\train 和 eval 目录 传入到 xml_to_csv.py 中的函数xml_to_csv 调用 即可转换完成
  * 把保存文件名分别命名为 train.csv 和 eval.csv 
  * 放到 objectdecting_wechatjump\record\ 目录下 
把 models\research\object_detection\dataset_tools 下的 create_pascal_tf_record.py
稍作修改
  * 把所有的地址参数全部使用FLAGS去传递 方便适应我们的识别模型目录 
    * csv_input CSV文件地址
    * output_path 输出record文件地址
    * img_path 原图地址 
  * 把 def class_text_to_int(row_label): 函数里面识别物体种类改为刚才打标签的种类
    * row_label == 'movtarget': return 1
    * row_label == 'jumptarget': return 2
    * 其他返回 None 
    * 可以用于检测是否有异常字段 
  * 重新命名为 generate_tfrecord.py
  * 执行 python generate_tfrecord.py 
    * 依次输入 csv_input,img_path
    * output_path 的路径保存在 objectdecting_wechatjump\record 下
  * 成功后 可以看到 record中已经保存了tensorflow可以识别的数据