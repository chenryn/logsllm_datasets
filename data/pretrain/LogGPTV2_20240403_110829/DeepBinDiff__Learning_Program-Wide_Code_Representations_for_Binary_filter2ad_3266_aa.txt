title:DeepBinDiff: Learning Program-Wide Code Representations for Binary
Diffing
author:Yue Duan and
Xuezixiang Li and
Jinghan Wang and
Heng Yin
DEEPBINDIFF: Learning Program-Wide Code
Representations for Binary Difﬁng
Yue Duan∗, Xuezixiang Li†, Jinghan Wang†, and Heng Yin†
∗Cornell University †UC Riverside
PI:EMAIL, {xli287, jwang131}@ucr.edu, PI:EMAIL
Abstract—Binary difﬁng analysis quantitatively measures the
differences between two given binaries and produces ﬁne-grained
basic block level matching. It has been widely used to enable
different kinds of critical security analysis. However, all existing
program analysis and machine learning based techniques suffer
from low accuracy, poor scalability, coarse granularity, or require
extensive labeled training data to function. In this paper, we pro-
pose an unsupervised program-wide code representation learning
technique to solve the problem. We rely on both the code semantic
information and the program-wide control ﬂow information to
generate basic block embeddings. Furthermore, we propose a k-
hop greedy matching algorithm to ﬁnd the optimal difﬁng results
using the generated block embeddings. We implement a prototype
called DEEPBINDIFF and evaluate its effectiveness and efﬁciency
with a large number of binaries. The results show that our tool
outperforms the state-of-the-art binary difﬁng tools by a large
margin for both cross-version and cross-optimization-level difﬁng.
A case study for OpenSSL using real-world vulnerabilities further
demonstrates the usefulness of our system.
I.
INTRODUCTION
Binary Code Differential Analysis, a.k.a, binary difﬁng,
is a fundamental analysis capability, which aims to quanti-
tatively measure the similarity between two given binaries and
produce the ﬁne-grained basic block level matching. Given
two input binaries,
it precisely characterizes the program-
wide differences by generating the optimal matching among
basic blocks with quantitative similarity scores. It not only
presents precise, ﬁne-grained and quantitative results about the
differences at a whole binary scale but also explicitly reveals
how code evolves across different versions or optimization
levels. Because of the precision and ﬁne-granularity, it has
enabled many critical security usages in various scenarios
when program-wide analysis is required, such as changed
parts locating [1], malware analysis [28], [45], security patch
analysis [55], [38], binary wide plagiarism detection [40] and
patch-based exploit generation [11]. As a result, binary difﬁng
*This work was conducted while Yue Duan was a PhD student at UC
Riverside, advised by Prof. Heng Yin.
Network and Distributed Systems Security (NDSS) Symposium 2020
23-26 February 2020, San Diego, CA, USA
ISBN 1-891562-61-4
https://dx.doi.org/10.14722/ndss.2020.24311
www.ndss-symposium.org
has been an active research focus. In general, existing works
can be put into two categories.
Traditional Approaches. BinDiff [10], which is the de facto
commercial binary difﬁng tool, performs many-to-many graph
isomorphism detection [35] on callgraph and control-ﬂow
graph (CFG), and leverages heuristics (e.g., function name,
graph edge MD index) to match functions and basic blocks.
Other static analysis based techniques perform matching on
the generated control and data ﬂow graphs [25], [30], [49],
[27] or decompose the graphs into fragments [20], [17], [18],
[40] for similarity detection. Most of these approaches consider
only the syntax of instructions rather than the semantics, which
can be critical during analysis, especially when dealing with
different compiler optimization techniques. Moreover, graph
matching algorithms such as Hungarian algorithm [35] are
expensive and cannot guarantee optimal matching.
Another line of research utilizes dynamic analysis. These
techniques carry out the analysis by directly executing the
given code [26], [53], performing dynamic slicing [44] or
tainting [43] on the given binaries, and checking the semantic
level equivalence based on the information collected during
the execution. In general, these techniques excel at extract-
ing semantics of the code and have good resilience against
compiler optimizations and code obfuscation but usually suffer
from poor scalability and incomplete code coverage, due to the
nature of the dynamic analysis.
Learning-based Approaches. Recent works have leveraged
the advance of machine learning to tackle the binary diff-
ing problem. Various techniques [29], [54], [58], [23] have
been proposed to leverage graph representation learning tech-
niques [16], [42], [37] and incorporate code information into
embeddings (i.e., high dimensional numerical vectors). Then
they use these embeddings for similarity detection. Inner-
Eye [58] and Asm2Vec [23] further rely on NLP techniques
to automatically extract semantic information and generate
embeddings for difﬁng. These approaches embrace two major
advantages over the traditional static and dynamic approaches:
1) higher accuracy as they incorporate unique features of
the code into the analysis by using either manual engineered
features [29], [54] or deep learning based automatic meth-
ods [23], [58]; 2) better scalability since they avoid heavy
graph matching algorithm or dynamic execution. What’s more,
the learning process can be signiﬁcantly accelerated by GPUs.
Limitations. Despite the advantages, we identify three major
limitations of the existing learning-based approaches.
First, no existing learning-based technique can perform
efﬁcient program-wide binary difﬁng at a ﬁne-grained basic
block level. Most of the current techniques conduct difﬁng at
a granularity of functions [29], [54], [36], [23], [39]. Inner-
Eye [58] is the only learning-based technique that achieves
basic block level granularity. Nevertheless, it is not scalable
enough for program-wide binary difﬁng due to its design.
Each calculation of basic block similarity has to go through a
complex neural network (with a total of 3,700,440 parameters
in the current implementation), which signiﬁcantly affects the
performance. To evaluate the scalability, we use pre-trained
models from the authors [7] and measure the performance. The
results show that it takes an average of 0.6ms for InnerEye to
process one pair of blocks. Note that a binary difﬁng could
easily involve millions of basic block distance calculations.
Therefore, it takes hours for InnerEye to ﬁnish difﬁng between
two small binaries unless a powerful GPU is used. As afore-
mentioned, ﬁne-grained binary difﬁng is an essential analysis,
upon which many critical security analyses can be built. Hence,
a ﬁne-grained and efﬁcient difﬁng tool is strongly desired.
is particularly useful
Second, none of the learning-based techniques considers
both program-wide dependency information and basic block
semantic information during analysis. The program-wide de-
pendency information, which can be extracted from the inter-
procedural control ﬂow graph (ICFG), provides the contextual
information of a basic block. It
in
binary difﬁng as one binary could contain multiple very sim-
ilar functions, and the program-wide contextual information
can be vital to differentiate these functions as well as the
blocks within them. Basic block semantic information, on
the other hand, characterizes the uniqueness of each basic
block. InnerEye [58] extracts basic block semantic information
with NLP techniques [42] but only considers local control
dependency information within a small code component by
adopting the Longest Common Subsequence. Asm2Vec [23]
generates random walks only within functions to learn token
and function embeddings.
Third, most of the existing learning-based techniques [55],
[36], [58], [39] are built on top of supervised learning. Thus,
the performance is heavily dependent on the quality of training
data. To begin with, we argue that a large, representative
and balanced training dataset can be very hard to collect,
because of the extreme diversity of the binary programs.
Also, supervised learning could suffer from the overﬁtting
problem [22]. Moreover, state-of-the-art supervised learning
technique InnerEye [58] considers a whole instruction (opcode
+ operands) as a word, therefore, may lead to serious out-
of-vocabulary (OOV) problem. To show this, we follow the
same preprocessing step described in the paper and evaluate
the pre-trained model using the same dataset CoreUtils v8.29.
The results show that the pre-trained model could only achieve
an average of 78.37% instruction coverage for the binaries in
CoreUtils v8.29. In other words, 21.63% of the instruction
cannot be modeled, as compared to only 3.7% reported in the
paper. This is due to the fact that we use GCC compiler while
clang was used in the InnerEye paper. Nonetheless, it shows
that the InnerEye model could easily become much less useful
when facing even a small change in the test setting.
Our Approach. To this end, we propose an unsupervised
deep neural network based program-wide code representation
learning technique for binary difﬁng. In particular, our tech-
nique ﬁrst learns basic block embeddings via unsupervised
deep learning. Each learned embedding represents a speciﬁc
basic block by carrying both the semantic information of the
basic block and the contextual information from the ICFG.
These embeddings are then used to efﬁciently and accurately
calculate the similarities among basic blocks.
To achieve this goal, we modify state-of-the-art NLP
technique Word2Vec [42] to extract semantic information for
tokens (opcode and operands), and further assemble basic
block level feature vectors. Hence, these feature vectors con-
tain the semantic information for blocks. Modeling opcode
and operand separately also eliminates the OOV problem.
Then, we model the basic block embedding generation as a
network representation learning problem and feed the feature
vectors into Text-associated DeepWalk algorithm (TADW) [56]
to generate basic block embeddings that contain program-wide
control ﬂow contextual information. Consequently, these basic
block embeddings contain both the program-wide contextual
information and the semantics from the basic blocks. Finally,
we present a k-hop greedy matching algorithm to match basic
blocks to cope with compiler optimizations including function
inlining and basic block reordering.
We implement a prototype DEEPBINDIFF, and conduct
an extensive evaluation with representative datasets containing
113 C binaries and 10 C++ binaries. The evaluation shows
that our tool soundly outperforms state-of-the-art techniques
BinDiff and Asm2Vec, for both cross-version and cross-
optimization-level difﬁng. Furthermore, we conduct a case
study using real-world vulnerabilities in OpenSSL [9] and
show that our tool has unique advantages when analyzing
vulnerabilities.
Contributions. The contributions of this paper are as follows:
• We propose a novel unsupervised program-wide code
representation learning technique for binary difﬁng.
Our technique relies on both the code semantic in-
formation and the program-wide control-ﬂow graph
contextual information to generate high quality basic
block embeddings. Then we propose a k-hop greedy
matching algorithm to obtain the optimal results.
• We implement a prototype DEEPBINDIFF. It ﬁrst
extracts semantic information by leveraging NLP tech-
niques. Then, it performs TADW algorithm to generate
basic block embeddings that contain both the semantic
and the program-wide dependency information.
•
An extensive evaluation shows that DEEPBINDIFF
could outperform state-of-the-art binary difﬁng tools
for both cross-version and cross-optimization-level
difﬁng. A case study further demonstrates the useful-
ness of DEEPBINDIFF with real-world vulnerabilities.
To facilitate further research, we have made the source code
and dataset publicly available.1
1https://github.com/deepbindiff/DeepBinDiff
2
II. PROBLEM STATEMENT
A. Problem Deﬁnition
Given two binary programs, binary difﬁng precisely mea-
sures the similarity and characterizes the differences between
the two binaries at a ﬁne-grained basic block level. We
formally deﬁne binary difﬁng problem as follows:
Deﬁnition 1. Given two binary programs p1 = (B1, E1) and
p2 = (B2, E2), binary difﬁng aims to ﬁnd the optimal basic
block matching that maximizes the similarity between p1 and
p2:
k(cid:88)
i=1
SIM (p1, p2) =
m1,m2,...,mk∈M (p1,p2)
max
sim(mi), where:
(cid:48)
(cid:48)
1, b
2, ..., b
(cid:48)
• B1 = {b1, b2, ..., bn} and B2 = {b
m} are
two sets containing all the basic blocks in p1 and p2;
Each element e in E ⊆ B × B corresponds to control
ﬂow dependency between two basic blocks;
Each element mi in M (p1, p2) represents a matching
pair between bi and b
sim(mi) deﬁnes the quantitative similarity score be-
tween two matching basic blocks.
•
•
•
(cid:48)
j;
Therefore, the problem can be transformed into two sub-
tasks: 1) discover sim(mi) that quantitatively measures the
similarity between two basic blocks; 2) ﬁnd the optimal
matching between two sets of basic blocks M (p1, p2).
B. Assumptions
We list the following assumptions on the given inputs:
•
Only stripped binaries, no source or symbol informa-
tion is given. COTS binaries are often stripped and
malicious binaries do not carry symbols for obvious
reasons.
Binaries are not packed, but can be transformed with
different compiler optimization techniques, which can
lead to distinctive binaries even with the same source
code input. For packed malware binaries, we assume
they are ﬁrst unpacked before they are presented to
our tool.
Two input binaries are for the same architecture. So
far DEEPBINDIFF supports x86 binaries since they
are the most prevalent in real world. DEEPBINDIFF
could be extended to handle cross-architecture difﬁng
via analysis on an Intermediate Representation (IR)
level. We leave it as future work.
•
•
III. APPROACH OVERVIEW
Figure 1 delineates the system architecture of DEEP-
BINDIFF. Red squares represent generated intermediate data
during analysis. As shown, the system takes as input two
binaries and outputs the basic block level difﬁng results. The
system solves the two tasks mentioned in Section II-A by
using two major techniques. First, to calculate sim(mi) that
quantitatively measures basic block similarity, DEEPBINDIFF
3
embraces an unsupervised learning approach to generate em-
beddings and utilizes them to efﬁciently calculate the similarity
scores between basic blocks. Second, our system uses a k-
hop greedy matching algorithm to generate the matching
M (p1, p2).
The whole system consists of three major components: 1)
pre-processing; 2) embedding generation and 3) code difﬁng.
Pre-processing, which can be further divided into two sub-
components: CFG generation and feature vector generation, is
responsible for generating two pieces of information: inter-
procedural control-ﬂow graphs (ICFGs) and feature vectors
for basic blocks. Once generated, the two results are sent to
embedding generation component that utilizes TADW tech-
nique [48] to learn the graph embeddings for each basic block.
DEEPBINDIFF then makes use of the generated basic block
embeddings and performs a k-hop greedy matching algorithm
for code difﬁng at basic block level.
IV. PRE-PROCESSING
Pre-processing analyzes binaries and produces inputs for
embedding generation. More speciﬁcally, it produces inter-
procedural CFGs for binaries and applies a token embedding
generation model
to generate embeddings for each token
(opcode and operands). These generated token embeddings are
further transformed into basic block level feature vectors.
A. CFG Generation
By combining the call graph with the control-ﬂow graphs
of each function, DEEPBINDIFF leverages IDA pro [5] to ex-
tract basic block information, and generates an inter-procedural
CFG (ICFG) that provides program-wide contextual informa-
tion. This information is particularly useful when differentiat-
ing semantically similar basic blocks in dissimilar contexts.
B. Feature Vector Generation
Besides the control dependency information carried by
ICFGs, DEEPBINDIFF also takes into account the semantic
information by generating feature vector for each basic block.
The whole process consists of two subtasks: token embedding
generation and feature vector generation. More speciﬁcally, we
ﬁrst train a token embedding model derived from Word2Vec
algorithm [42], and then use this model to generate token
(opcode or operand) embeddings. And eventually we gener-
ate feature vectors for basic blocks from token embeddings.
Figure 2 shows the four major steps for the feature vector
generation process.
Random Walks. When distilling semantics of each token,
we would like to make use of the instructions around it as
its context. Therefore, we need to serialize ICFGs to extract
control ﬂow dependency information. As depicted in Step 1
in Figure 2, we generate random walks in ICFGs so that each
walk contains one possible execution path of the binary. To
ensure the completeness of basic block coverage, we conﬁgure
the walking engine so that every basic block is guaranteed to
be contained by at least 2 random walks. Further, each random
walk is set to have a length of 5 basic blocks to carry enough
control ﬂow information. Then, we put random walks together
to generate a complete instruction sequence for training.
Fig. 1: Overview of DEEPBINDIFF.
Normalization. Before sending the instruction sequence to
train our Word2Vec model,
the serialized codes may still
contain some differences due to various compilation choices.
To reﬁne the code, DEEPBINDIFF adopts a normalization
process shown as Step 2 in Figure 2. Our system conducts
the normalization using the following rules : 1) all numeric
constant values are replaced with string ‘im’; 2) all general
registers are renamed according to their lengths; 3) pointers
are replaced with string ‘ptr’. Notice that we do not follow
InnerEye [58] where all the string literals are replaced with
, because the string literals can be useful to distinguish
different basic blocks.
Model Training. DEEPBINDIFF considers the generated ran-
dom walks as sentence for our modiﬁed version of Word2Vec
algorithm [42] and learns the token embeddings by training
a token embedding model to the normalized random walks.
Note that model training is only a one-time effort.
A word embedding is simply a vector, which is learned
from the given articles to capture the contextual semantic
meaning of the word. There exist multiple methods to generate
vector representations of words including the most popular
Continuous Bag-of-Words model (CBOW) and Skip-Gram
model proposed by Mikolov et al. [42]. Here we utilize the
CBOW model which predicates target from its context.
Given a sequence of training words w1, w2, ..., wt, the ob-
jective of the model is to maximize the average log probability
J(w) as shown in Equation 1
T(cid:88)
(cid:88)
t=1
−c≤j≤c
J(w) =
1
T
log p(wt+j|wt)
(1)
where c is the sliding window for context and p(wt+j|wt)
is the softmax function deﬁned as Equation 2.
p(wk ∈ Ct|wt) =
exp(vT
wt
vwk )
exp(vT
wt
wi∈Ct
vwi)
(2)
(cid:80)