### 4.3. Extended BOINC GUI-RPC

The proposed mechanism is designed to enable distributed and cooperative scheduling through the extension of BOINC GUI-RPC (Graphical User Interface - Remote Procedure Call). The original BOINC middleware does not support WU (Work Unit) operations via BOINC GUI-RPCs. Therefore, we have extended the BOINC GUI-RPCs to facilitate WU management.

**Table 1: Extended BOINC GUI-RPC Commands**

| **Command** | **Input** | **Output** | **Description** |
|-------------|-----------|------------|-----------------|
| `attach_wu` | WU name, XML data of WU (including input file path) | None | Append a new WU to the core client. The new WU's information is specified by the input parameters. |
| `detach_wu` | WU name | None | Delete the specified WU from the list of WUs managed by the core client. |
| `get_wu_info` | WU name | XML data of the WU (including input file path) | Retrieve information about the specified WU. |

These minimal extensions enable the proposed task scheduling mechanism and the BOINC core client to work collaboratively, thereby improving the computational efficiency of the community.

### 4.4. Mechanism for Moving WUs Between Clients

The proposed implementation uses the extended BOINC GUI-RPCs to move WUs between clients. The process involves the following steps:

1. **Information Retrieval**: The distributed and cooperative scheduler retrieves the information about computing resources and the BOINC core client via the original BOINC GUI-RPC. This includes the list of WUs held by each client.
2. **WU Selection and Data Retrieval**: The scheduler selects specific WUs from the list and retrieves their data using the `get_wu_info` command.
3. **Detachment**: The scheduler deletes the selected WUs from the BOINC core client using the `detach_wu` command, ensuring that the client no longer processes these WUs.
4. **Data Transfer**: The scheduler sends the WU data to other clients via logical links.
5. **Attachment**: The receiving scheduler appends the WU data to the BOINC core client as new WUs using the `attach_wu` command.

### 5. Performance Evaluation and Discussions

This section presents experimental results and demonstrates how dynamic load balancing and proxy download improve the efficiency of the system. We first evaluate the effect of proxy download on performance, which helps distribute WUs among clients even when the project server is busy. Then, we show the evaluation results to demonstrate that the volunteer computing system can adapt to dynamic load changes, reducing the turnaround time for processing each WU.

#### 5.1. Effect of Proxy Download on Throughput

We first describe the experimental results without the proposed task scheduling mechanism and then discuss the impact of the proxy download, which reduces the load on the project server and improves the utilization ratio of clients.

**Table 2: Server Machine Specifications**

| **Component** | **Specification** |
|---------------|-------------------|
| CPU           | Intel Core2Duo 2.93GHz |
| Memory        | 4.0GB             |
| Network       | Giga-bit Ethernet  |
| OS            | Linux 2.6.23 (Fedora 7) |
| Web Server    | Apache 2.2.6      |
| BOINC Server  | Version 6.1.0     |

**Table 3: Client Machines Specifications**

| **Site Name** | **CPU** | **Memory** | **Network** | **# of Clients** |
|---------------|---------|------------|-------------|------------------|
| chiba         | Intel Core2Duo 2.33GHz | 4GB | Giga-bit Ethernet | 58 |
| hongo         | Intel PentiumM 1.8GHz   | 1GB | Giga-bit Ethernet | 64 |
| suzuk         | Intel Core2Duo 2.33GHz | 4GB | Giga-bit Ethernet | 36 |
| kyoto         | Intel Core2Duo 2.33GHz | 4GB | Giga-bit Ethernet | 35 |
| imade         | Intel Core2Duo 2.33GHz | 4GB | Giga-bit Ethernet | 29 |

**Table 4: Project Performance and Server Load (Without Scheduling Mechanism)**

| **# of Clients** | **WUs/access** | **WUs/sec** | **Accesses/sec** | **CPU Load [%]** | **Rate of Idle Clients [%]** |
|------------------|----------------|-------------|------------------|------------------|------------------------------|
| 29               | 1              | 2.8         | 2.80             | 5                | 0                            |
| 29               | 2              | 2.8         | 1.40             | 5                | 0                            |
| 29               | 4              | 6.6         | 1.65             | 10               | 0                            |
| 29               | 8              | 7.8         | 0.98             | 10               | 0                            |
| 64               | 1              | 6.1         | 6.10             | 11               | 0                            |
| 64               | 2              | 6.1         | 3.05             | 10               | 0                            |
| 64               | 4              | 15.1        | 3.78             | 19               | 0                            |
| 64               | 8              | 15.3        | 1.91             | 20               | 2                            |
| 222              | 1              | 16.1        | 16.10            | 30               | 5                            |
| 222              | 2              | 18.2        | 9.10             | 29               | 5                            |
| 222              | 4              | 19.7        | 4.93             | 30               | 41                           |
| 222              | 8              | 19.7        | 2.46             | 31               | 57                           |

**Table 5: Project Performance and Server Load (With Scheduling Mechanism)**

| **# of Clients** | **WUs/access** | **WUs/sec** | **Accesses/sec** | **CPU Load [%]** | **Rate of Idle Clients [%]** | **Improvement [%]** |
|------------------|----------------|-------------|------------------|------------------|------------------------------|---------------------|
| 29               | 1              | 2.8         | 2.80             | 5                | 0                            | 0                   |
| 29               | 2              | 2.8         | 1.40             | 5                | 0                            | 0                   |
| 29               | 4              | 6.7         | 1.68             | 10               | 0                            | 1.52                |
| 29               | 8              | 9.3         | 1.16             | 16               | 0                            | 19.23               |
| 64               | 1              | 6.1         | 6.10             | 11               | 0                            | 0                   |
| 64               | 2              | 6.1         | 3.05             | 10               | 0                            | 0                   |
| 64               | 4              | 15.2        | 3.80             | 19               | 0                            | 0.66                |
| 64               | 8              | 18.2        | 2.28             | 26               | 0                            | 18.95               |
| 222              | 1              | 16.1        | 16.10            | 30               | 5                            | 0                   |
| 222              | 2              | 18.2        | 9.10             | 29               | 5                            | 0                   |
| 222              | 4              | 20.1        | 5.03             | 32               | 13                           | 2.03                |
| 222              | 8              | 25.1        | 3.14             | 39               | 12                           | 27.41               |

**Figures 3 and 4: Network Traffic on the Project Server**

- **Figure 3**: Network traffic on the project server without the proposed task scheduling mechanism.
- **Figure 4**: Network traffic on the project server with the proposed task scheduling mechanism.

In these figures, the x-axis represents the number of WUs per access, and each line indicates the results for different system sizes. The solid lines labeled "Input Data" show the network bandwidth consumed at the server for incoming data from clients, while the broken lines labeled "Output Data" show the network bandwidth consumed at the server for outgoing data to clients. The network traffic on the project server varies with changes in WUs/access and the number of clients. 

Two factors influence the network traffic:
1. **Constant-Sized Traffic**: This increases linearly with the number of accesses. As Accesses/sec is inversely proportional to WUs/access, a higher WUs/access reduces the network traffic.
2. **WU Downloads and Result Uploads**: Higher throughput in the volunteer computing system leads to increased network traffic for WU downloads and result uploads.

By effectively distributing WUs using the proxy download, the proposed mechanism can significantly improve the rate of idle clients and, consequently, the total throughput of the entire system. For example, in the case of 222 clients with WUs/access = 8, the proxy download improved the rate of idle clients, resulting in a 27% increase in total throughput. However, for lower WUs/access values, the mechanism does not improve performance because there are too few WUs to move between clients.