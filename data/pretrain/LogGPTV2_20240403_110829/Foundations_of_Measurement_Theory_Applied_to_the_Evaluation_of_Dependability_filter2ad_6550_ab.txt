range of values of the measurand for which the measure-
ment system is applicable with speciﬁed measurement un-
certainty under deﬁned conditions.
The importance of taking into consideration measure-
ment time for a complete characterization is intuitive: be-
sides being directly linked to measurement costs (in terms
of resources occupation), the reciprocal of the measurement
time gives an upper bound to the number of measurements
that can be performed in the unit of time.
It is well known that any measurement system perturbs
the measurand, determining a modiﬁcation of its value.
Minimizing such perturbation, that is minimizing the sys-
tem’s intrusiveness, is therefore desirable when designing
a measurement system.
Finally, as measurement results are expressed in terms
of ranges of values, intervals measured through different in-
struments ought to be compared rather than single values.
Speciﬁcally, if results are expressed with the same conﬁ-
dence level, they are said to be compatible if the related
intervals overlap.
3 Metrology and dependability
To adapt the concepts mentioned in the previous Sec-
tion 2 to the ﬁeld of computing systems is not trivial. In this
Section, a classiﬁcation of computing systems, and of mea-
surements that can be of interest on such systems are drawn.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 05:37:28 UTC from IEEE Xplore.  Restrictions apply. 
37th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN'07)0-7695-2855-4/07 $20.00  © 2007Then, on the basis of such classiﬁcation, the most signiﬁ-
cant measurement properties that should characterize mea-
surement tools designed to operate on the different kinds of
systems are highlighted.
First of all, let us classify measurements that can be per-
formed on computing systems, with special regard to de-
pendability evaluation. They can be divided into two main
classes:
• Measurements with negligible uncertainty. This class
includes static quantities which depend on the static
characteristics of the system under evaluation, as well
as countable dynamic quantities, which depend on a
particular execution of the system. Such measure-
ments typically result in integer counts, either attribute
counts or event counts. Many software quality mea-
surements, typical of software engineering, such as
number of source code lines of a given software el-
ement, number of system calls, and so on, belong to
this class. Moreover, this class includes packet size in
packet-switched networks, queue size of a particular
network protocol, number of packets sent on top of a
point-to-point channel, number of messages received
by a network interface, maximum memory size of an
application, maximum number of records in a database
table, etc. Measurements belonging to this class are
characterized by very low uncertainty.
• Measurements with non-negligible uncertainty, which
generally refer to the dynamic behavior of the system
under evaluation and usually involve the estimation of
continuous quantities. Relevant examples of measure-
ments belonging to this class are: delays experienced
in an end-to-end connection, quality of clock synchro-
nization, Mean Time To Failure, Mean Time Between
Failures, direct and indirect measurements depending
on distributed events.
It is quite obvious that this latter class includes quan-
tities whose measurement presents more challenges than
those belonging to the former one. A closer look at this
class highlights the crucial role of time intervals measure-
ments. Dependability-related measurements are very often
based on measuring time intervals, either because the mea-
surand is a time interval, or because the measurand is ob-
tained through indirect measurements based on time inter-
vals. Such measurements are often affected by non negligi-
ble uncertainty.
It can be useful to classify the computing systems whose
QoS or dependability attributes are to be measured along
the following dimensions:
• Real-time: along this paths we start from time-free
systems, characterized by the absence of timing con-
straints or temporal requirements, to reach the case
of so called hard real-time systems, characterized by
well-deﬁned (and usually quite strict) constraints on
their temporal behavior. A system is time-free when
there is no deadline for its operations, whereas it is
hard real-time when the correctness of its behavior is
deﬁned not only based upon the logical correctness of
the operations performed but depends also upon the
time frame in which such operations are performed [6].
• Criticality: along the criticality dimension at one ex-
treme we ﬁnd non-critical systems, while the other
extreme is represented by X-critical systems, which
may take many forms, e.g. safety-critical systems, or
mission-critical systems or life-critical systems. While
the failure of the former does not imply any signiﬁ-
cant damage, for the latter a failure could result in very
dangerous events such as loss of life, signiﬁcant prop-
erty damage, or damage to the environment. There
are many well-known traditional examples in differ-
ent areas, such as medical devices, aircraft ﬂight con-
trol, weapons, and nuclear systems, which ﬁt this def-
inition. In addition to these, many modern informa-
tion systems and infrastructures are starting being con-
sidered X-critical, because the same types of damages
(with even a more severe impact to their scale) can re-
sult from their failure [6].
• Centralized/Distributed: starting from so called cen-
tralized systems we may ﬁnd several forms of dis-
tributed systems. While a centralized system is made
of a unique node, which may eventually be decom-
posed in non autonomous and closely coupled parts, a
distributed system is a set of distinct nodes, with minor
and even unstable coupling constraints, interconnected
by any kind of network, cooperating for common ob-
jectives [6].
The aforementioned dimensions constitute a quite sim-
ple categorization of computing systems to which the con-
cepts of metrology introduced in Section 2 should be ap-
plied. Depending on the category a system belongs to, the
metrology properties and indicators may be less or more
important to be taken into account and less or more difﬁcult
and costly to apply and to assess.
Among the fundamental properties that should be taken
into consideration for a signiﬁcant characterization of mea-
surement systems, those of major concern to dependability
evaluation can be identiﬁed in: uncertainty, repeatability,
resolution and intrusiveness.
Table 1 enlists the abbreviations used in the other tables
presented in this and in the next Section.
Table 2 describes the relative importance of metrolog-
ical properties for the different categories of systems.
It
describes the most important metrological properties that
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 05:37:28 UTC from IEEE Xplore.  Restrictions apply. 
37th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN'07)0-7695-2855-4/07 $20.00  © 2007should be considered to design measurement tools that can
provide reliable results (X stands for important, XX for fun-
damental).
Some details on the arguments used to ﬁll Table 2 are
now given.
Uncertainty. A quantitative evaluation of uncertainty
is necessary to appreciate the quality of the measurement.
Such need is not only theoretical but has an important prac-
tical implication. Let us consider, for example, a safety crit-
ical system with hard real-time requirements; in such sys-
tem there can be cases when uncertainty can be essential
to state whether the system is compliant with its require-
ments or not. If an indicator has to be below a given thresh-
old, and the result of measurements conﬁrms it is below that
threshold, one would be convinced that the system meets its
requirements. What if after evaluating uncertainty, the in-
terval expressing the measurement results is, even partially,
over the threshold? In this case the available knowledge of
the measurand does not necessarily allow to state that the
system meets its requirements with enough conﬁdence.
Uncertainty is maybe even more important (and needs
to be evaluated) in the case of distributed systems. Time
interval measurements carried out on such systems can, in
fact, be signiﬁcantly affected by offset and drift among dis-
tributed clocks. Another case in which uncertainty is very
important is when indirect measurements are performed
by combining results of several direct measurements.
In
such cases, the uncertainty of direct temporal measurements
propagates on uncertainty of indirect measurements; ex-
pression (3) permits to calculate the uncertainty of an in-
direct measurement through the uncertainties of direct mea-
surements utilized for its evaluation.
Intrusiveness. In general, performing measurements al-
ters (to different extents) the state and the behavior of the
system under test. More speciﬁcally, the presence of a mea-
surement system can introduce modiﬁcations on the value
of the measurand. A classical example is provided by the
load effect of a voltmeter that can alter the voltage it is
intended to measure due to its ﬁnite impedance. In com-
puter science, we can think of a target process which acts
as the measurand, and of measures collected with a process
scheduled on the same CPU hosting the target process; the
schedulability of the entire system might be compromised,
with consequent harmful effects on measurement results.
Performing an analysis of the intrusiveness of a measure-
ment system is particularly important when measurements
are carried out on computer systems or infrastructures, since
this often implies loading the system and, ultimately, inﬂu-
encing its behavior in a non negligible way. The importance
of intrusiveness in computer systems is clear and well un-
derstood, although it is difﬁcult to quantify it. It should be
evaluated as the impact of the measurement system on the
performance of the computer system, expressed in terms of
memory usage, CPU usage and/or operating system relative
time. Intrusiveness is a parameter of fundamental impor-
tance for all the cases of interest of this paper. This is partic-
ularly true for real-time systems: a tool able to collect suf-
ﬁciently reliable data in a non real-time environment, may
behave very differently in a hard real-time environment. In-
trusiveness is thus particularly critical in hard real-time sys-
tems, where timing predictability may be altered by the ad-
ditional overhead of monitoring tasks, or other mechanisms,
e.g. fault injection probes.
Intrusiveness and uncertainty are related to each other
since intrusiveness has consequences on uncertainty. This
explains why in Table 2 all the rows in which Intrusiveness
is important exhibit the same importance for Uncertainty.
Resolution. Resolution may be critical in real-time sys-
tems since it needs to be much lower than the imposed time
deadline to allow useful quantitative evaluations of time or
dependability metrics. In computing systems it can be gen-
erally assumed that resolution of the measurement system
for time interval evaluation is equal to the granularity of the
clock used in the experiment. In a centralized context it can
happen that resolution is of the same order of magnitude of
the measure, and it is thus of great importance to evaluate
the resolution. On the other hand, when experiments are
performed on distributed systems, uncertainty is usually far
greater than resolution; in such cases, the evaluation and the
control of resolution may be less crucial.
Table 2. Summary on important metrological
properties to consider in order to perform re-
liable measurements on computing systems
Centralized
Distributed
Real-time
Table 1. Abbreviations used in Tables 2-3
CE
Unc Uncertainty
DI
Intrusiveness
Int
RT
Res
Resolution
¬RT Non real-time Rep Repeatability
CR
¬CR Non-critical
Critical
Unc
CE-¬RT-¬CR X
CE-¬RT-CR
X
CE-RT-¬CR
XX
CE-RT-CR
XX
DI-¬RT-¬CR X
DI-¬RT-CR
X
DI-RT-¬CR
XX
DI-RT-CR
XX
X
Int Res Rep
X
X
X
X
XX X
XX XX X
X
X
XX X
XX X
X
X
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 05:37:28 UTC from IEEE Xplore.  Restrictions apply. 
37th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN'07)0-7695-2855-4/07 $20.00  © 2007Repeatability. Repeatability is often not achievable when
measurements are carried out on computer systems. The
same environmental conditions can, in fact, hardly be guar-
anteed. This is especially true with regard to distributed
systems, where differences among local clocks, in addition
to the problems of thread scheduling and timing of events,
enormously increase the difﬁculty of designing repeatable
experiments. Critical systems are a class of systems in
which repeatability is very important. In such cases, great
efforts to grant the highest possible degree of repeatability
are required and motivated. When performing experimen-
tal validation of a critical system, in fact, it is necessary to
observe the same behavior triggered by the same trace of
execution.
4 Measurements properties in tools and ex-
periments for dependability evaluation
In this Section, tools and experiments used for exper-
imental quantitative evaluation of computing systems are
described, with the purpose of understanding if they have
considered and respected the aforementioned criteria and to
which extent this has been accomplished. With no intent to
criticize any individual experiment or experience, the objec-
tive is to investigate the general consciousness about metro-