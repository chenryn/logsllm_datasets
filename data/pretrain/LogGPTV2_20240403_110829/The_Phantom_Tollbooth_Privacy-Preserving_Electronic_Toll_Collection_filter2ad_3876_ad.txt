user would drive around 1,000 miles each month. While
we realize that these averages will vary greatly between
locations (for example, between a city and a rural area),
we believe that these measures still give us a relatively
realistic setting in which to consider our system.
Table 2 gives the time it takes for the TC to challenge
the OBU on a single segment for several segment lengths
and time steps; we can see that the time taken grows
approximately linearly with the number of segments.
To determine the number of segments, we considered
they are essentially the same as they were within PrETP; the numbers
they provide should therefore provide a reasonably accurate estimate
for the cost of the TSP within our system as well.
both ﬁne-grained and coarse-grained approaches. For the
ﬁne-grained approach, we considered a time step of one
minute. Using our assumptions about driving habits, this
means that in a 30-day month with 22 weekdays, our
average user will drive approximately 1,320 segments.
Adding on an extra 680 segments for weekends, we can
see that a user might accumulate up to 2,000 segments in
a month. In the way that road prices are currently decided,
however, a time step of one minute seems overly short, as
typically there are only two times considered throughout
the day: peak and off-peak. We therefore considered next
a time step of one hour, keeping our segment length at
1 mile. Here the number of miles driven determines the
number of segments rather than the minutes spent in the
car, and so we end up with approximately 1,000 segments
for the month. Finally, we considered a segment length
of 2 miles, keeping our time step at one hour; we can see
that this results in approximately half as many segments
as before, around 500 segments. Longer average physical
segment lengths would result in an even lower number of
segments (and therefore better performance).
Communication overhead. Looking at Table 3, we
can see that the size of a payment message is approxi-
mately 6kB per segment; furthermore, this size is domi-
nated by the NIZK (recall that each segment requires a
commitment, a NIZK, and a ciphertext), which accounts
for over 90% of the total size. For our parameter choices
in Table 2, this would result in a total payment size of
approximately 11MB in the worst case (with 2000 seg-
ments) and 3MB in the best case (with 500 segments).
In PrETP, on the other hand, the authors claim to have
sizes of only 1.5kB per segment [4, Section 4.3]. Using
their more compact segments with our ciphertexts added
on would therefore result in a segment size of only 2kB,
which means the worst-case size of the entire payment
message would be under 4MB (and the best-case size
approximately 1MB).
Finally, we can see that the overhead for the rest of the
Audit protocol is quite small: each blind IBE key sent
from the OBU to the TC is only 494 bytes; if the TC
makes ten queries per audit, then the total data transferred
in the course of the protocol is about 5kB.
5.1 Milo cost analysis
If we continue to assume that the TC always queries the
user on ten cameras, then the entire auditing process will
take less than 10 minutes per user in the worst case (when
there are 2,000 segments) and less than 2 minutes in the
best case (when there are 500 segments). If we consider
pricing computational resources as according to Amazon
EC2 [3], then to approximately match the computer used
for our benchmarks would cost about 10 cents per hour.
Between 6 and 30 users can be audited within an hour, so
Length
1 mile
1 mile
2 miles
Time step
1 minute
1 hour
1 hour
Segments Time for TC (s)
2000
1000
500
55.68
33.51
10.45
Table 2: The average time, in seconds and over a run of 10, for the TC to perform a single spot check given segment lengths
and time steps; we consider only the active time spent and not the time waiting for the OBU. Essentially all of the time was
spent iterating over the segments; as such, the time taken grows approximately linearly with the number of segments. To
determine the approximate number of segments given segment lengths and time steps, we assumed that an average user would
drive for 1,000 miles in a 30-day month, or about 33 hours (1 hour each weekday and an extra 11 hours over four weekends).
Object
NIZK
Commitment
Ciphertext
Total Pay segment
Audit message
Size (B)
5455
130
366
5955
494
Table 3: Size of each of the components that needs to
be sent between the OBU and the TC, in bytes. Each
segment of the payment consists of a NIZK, commitment,
and ciphertext; all the segments are forwarded to the TC
from the TSP at the start of an audit. In the course of the
Audit protocol the OBU must also send blind IBE keys to
the TC.
each user ends up costing the system between one-third
of a cent and 2 cents each month; this is an amount that
the TSP could easily charge the users if need be (although
the cost would presumably be cheaper if the TC simply
performed the computations itself). We therefore believe
that the amount of computation required to perform the
audits, in addition to being necessary in guaranteeing
fairness and honesty within the system, is reasonably
practical.
Finally, to examine how much Milo would cost if de-
ployed in a real population we consider the county of San
Diego, which consists of 3 million people possessing ap-
proximately 1.8 million vehicles, and almost 2,800 miles
of roads [16, 17, 44]. As we just saw, Milo has a compu-
tational cost of up to 2 cents per user per month, which
means a worst-case expected annual cost of $432,000; in
the best case, wherein users cost only one-third of a cent
per month, the expected annual cost is only $72,000. In
the next section, we can see how these costs compares
to that of the “naïve” solution to collusion protection;
i.e., one in which we attempt to protect against driver
collusion through placement of cameras as opposed to
prevention and protection at the system level.
6 Collusion Resistance
Previously proposed tolling systems did not take collusion
into account, as they allow the auditing authority to trans-
mit camera locations in the clear to drivers. Given these
locations, colluding drivers can then share their audit tran-
scripts each month in order to learn a greater number of
camera locations than they would have learned alone. Fur-
thermore, websites already exist which record locations
of red light cameras [38] and speed cameras [37]; one
can easily imagine websites similar to these that collect
crowd-based reports of audit camera locations. With cam-
eras whose locations are ﬁxed from month to month, the
cost to cheat is therefore essentially zero (just check the
website!) and so we can and should expect enterprising
drivers to take advantage of the system. In contrast, Milo
is speciﬁcally designed to prevent these sorts of trivial
collusion attacks.
In addition to learning camera locations through the
course of the audit phase, drivers may also learn camera
locations from simply seeing them on the road. This is
also quite damaging to the system, as drivers can learn
the locations of cameras simply by spotting them. After
pooling together the various locations and times at which
they saw cameras, cheating drivers can ﬁx up their driving
record in time to pass any end-of-month audit protocol.
To prevent such cheating, a system could instead re-
quire the OBU to transmit the tuples corresponding to
segments as they are driven, rather than all together at
the end of the month. Without an anonymizing service
such as Tor (used in VPriv [39]), transmitting data while
driving represents too great a privacy loss, as the TSP
can easily determine when and for how long each driver
is using their car. One possible ﬁx might seem to be to
continually transmit dummy segments while the car is
not in use; transmitting segments in real time over a cel-
lular network, however, leaks coarse-grained real-time
location information to nearby cell towers (for example,
staying connected to a single tower for many hours sug-
gests that you are stationary), thus defeating the main goal
of preserving driver privacy.
Finally, we note that there exists a class of expensive
physical attacks targeting any real-world implementation
of a camera-based audit protocol. For example, against
ﬁxed-location cameras, cheating drivers could disable
their OBU for speciﬁc segments each month, revealing in-
formation about those segments. Against mobile cameras,
a driver could follow each audit vehicle and record its
path, sharing with other cheating drivers as they go. One
can imagine defenses against these attacks and even more
fanciful attacks in response; these sort of attacks quickly
become very expensive and impractical, however, and
provide tell-tale signs of collusion (e.g., repeated cheat-
ing, suspicious vehicles). We therefore do not provide a
system-level defense against them.
6.1 Collusion resistance cost analysis
With Milo, we have modiﬁed the PrETP system to avoid
leaking the locations of cameras as part of the audit pro-
tocol. An alternative approach is to leave PrETP (or one
of the other previously proposed solutions) in place and
increase the number of audit cameras and their mobility,
thus reducing the useful information leaked in audits even
when drivers collude. Whereas deploying Milo would
increase computational costs over PrETP, deploying the
second solution would increase the operational costs as-
sociated with running the mobile audit cameras. In this
section, we compare the costs associated with the two
solutions. Even with intentionally conservative estimates
for the operating costs of mobile audit cameras, Milo ap-
pears to be competitive for reasonable parameter settings;
as Moore’s law makes computation less expensive, Milo
will become more attractive still.
Hardening previous tolling systems against trivial
driver collusion is possible if we consider using continu-
ously moving, invisible cameras. Intuitively, if cameras
move randomly, then knowing the position and time at
which one audit camera was seen does not allow other
cheating drivers to predict any future camera locations.
The easiest way to achieve these random spot checks is to
mount cameras on special-purpose vehicles, which then
perform a random walk across all streets in the audit area.
Even this will not generate truly random checks (as cars
must travel linearly through streets and obey trafﬁc laws);
for ease of analysis we assume it does. Furthermore, we
will make the assumptions that the audit vehicles will
never check the same segment simultaneously, operate
24 hours a day (every day), and are indistinguishable from
other cars; tolling segments are 1 mile; and non-audit vehi-
cles drive all road segments with equal probability. These
assumptions are by no means realistic, but they present
a stronger case for moving cameras and so we use them,
keeping in mind that any more realistic deployment will
have higher cost.
Using a probability analysis similar to that of VPriv [39,
Section 8.4], we consider an area with M miles of road
and C audit vehicles. If both audit vehicles and other
drivers are driving all roads uniformly at random, then
a driver will share a segment with an audit vehicle with
probability p = C
M with each mile driven. If the driver
travels m miles in a tolling period, she will be seen at least
once by an audit vehicle with a probability of
(cid:18) M −C
(cid:19)m
M
1− (1− p)m = 1−
.
(1)
Figure 2: A cost comparison of using the Milo system
against using mobile cameras within previously proposed
systems. We know, from Section 5.1, that Milo has a
worst-case computational cost of $432,000 per year and
a best case of $72,000; for the other systems, we ignore
computation completely (i.e., we assume it is free). Even
with the minimal costs we have assigned to operating
a ﬂeet of audit vehicles 24 hours a day and assuming
worst-case computational costs, Milo becomes equally
cheap when the probability of catching cheating drivers is
83%, and becomes signiﬁcantly cheaper as the probability
approaches 100%. For Milo’s best-case cost, it becomes
cheaper as soon as more than one camera is used.
To determine the overall cost of this type of operation,
we return to San Diego County (discussed already in Sec-
tion 5.1); recall that it consists of 1.8 million vehicles driv-
ing on 2,800 miles of road, in which the average distance
driven by one vehicle is 1,000 miles in a month. Using
Equation 1, with one audit vehicle (C = 1), the probability
that a driver gets caught is 1− (2799/2800)1000 ≈ .3, so
that a potentially cheating driver still has a 70% chance
of completely avoiding any audit vehicles for a month. If
we use two audit vehicles, then this number drops to 49%.
Continuing in this vein, we need 13 audit vehicles to guar-
antee a 99% chance of catching drivers who intentionally
omit segments. Achieving these results requires the TC
to employ drivers 24 hours a day, as well as purchase,
maintain, and operate a ﬂeet of audit vehicles. To con-
sider the cost of doing so, we estimate the depreciation,
maintenance, and operation cost of a single vehicle to be
approximately $12,500 a year [45]. Furthermore, Cali-
fornia has a minimum wage of $8.00/hr; paying this to
operate a single vehicle results in minimum annual salary
costs of $70,080, ignoring all overtime pay and beneﬁts.
Each audit vehicle will therefore cost at least $82,500 per
year (ignoring a number of additional overhead costs).
Finally, we compare the cost of operating these mobile
cameras with the cost of the Milo system. Because Milo
leaks no information about camera locations to drivers,
cameras can in fact stay at ﬁxed locations; as long they
are virtually invisible, drivers have no opportunities to
learn their locations and so there is no need to move them
0%20%40%60%80%100%Probability of Cheating Detection2004006008001,000Cost ($ Thousand)Milo (fixed cameras, worst case)Milo (fixed cameras, best case)Mobile camerascontinuously. We therefore consider placing invisible
cameras at random ﬁxed locations, and can calculate the
probability of drivers being caught by Milo using Equa-
tion 1, where we now use C to represent the number of
cameras (and continue to assume that drivers drive 1,000
miles at random each month).
Figure 2 compares the cost of Milo with ﬁxed cameras
and the cost of previous systems with mobile cameras
as the probability of detecting cheating increases. We
used a per-camera annual cost of $10,000.6 As we can
see, in the worst case, Milo achieves cost parity with
mobile cameras at a detection probability of 83% and
becomes vastly cheaper as the systems approach complete
coverage, while in the best case it achieves cost parity
as soon as more than a single camera is used (which
gives a detection probability of around 30%). With either
of these numbers, we remember that our assumptions
about the cost of operating these vehicles signiﬁcantly
underrated the actual cost; substituting in more realistic
numbers would thus cause Milo to compare even more
favorably. In addition, future developments in computing
technology are almost guaranteed to drive down the cost
of computation, while fuel and personnel costs are not
likely to decrease, let alone as quickly. Therefore, we
believe that Milo is and will continue to be an effective
(and ultimately cost effective) solution to protect against
driver collusion.
7 Related work
The study of privacy-preserving trafﬁc enforcement and
toll collection was initiated in papers by Blumberg, Keeler,
and shelat [8] and Blumberg and Chase [7]. The former of
these papers gave a system for trafﬁc enforcement (such
as red-light violations) and uses a private set-intersection
protocol at its core; the latter gave a system for tolling
and road pricing, and uses general secure function evalu-
ation. Neither system keeps the location of enforcement
or spot-check devices secret from drivers. In an impor-
tant additional contribution, these papers formalized the
“implicit privacy” that drivers currently enjoy: The police
could tail particular cars to observe their whereabouts, but
it would be impractical to apply such surveillance to more
than a small fraction of all drivers.7
6This number was loosely choosen based upon purchase costs for
red light violation cameras. Note that the choice does not affect the
differential system cost, as both systems must operate the same number
of cameras to achieve a given probability of success.
7We would like to correct one misconception, lest it inﬂuence future
researchers. Blumberg, Keeler, and shelat write, “the standards of
suspicion necessary to stop and search a vehicle are much more lax
than those required to enter and search a private residence.” In the
U.S., the same standard — probable cause — governs searches of both
vehicles and residences; the difference is only that a warrant is not
required before the search of a car, as “it is not practicable to secure a
warrant because the vehicle can be quickly moved out of the locality
or jurisdiction in which the warrant must be sought” (Carroll v. United
Another approach to privacy-preserving road pricing
was given by Troncoso et al. [43], who proposed trusted
tamper-resistant hardware in each car that calculates the
required payment, and whose behavior can be audited by
the car’s owner. The Troncoso et al. paper also includes
a useful survey of pay-as-you-drive systems deployed at
the time of its publication. See Balasch, Verbauwhede,
and Preneel [5] for a prototype implementation of the
Troncoso et al. approach.
De Jonge and Jacobs [19] proposed a privacy-