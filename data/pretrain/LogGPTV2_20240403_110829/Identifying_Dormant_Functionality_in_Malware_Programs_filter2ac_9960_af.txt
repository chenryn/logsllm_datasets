compared to modern, template-based spam engines. As a
result, it is rarely (or never) used.
Table V shows results on the pushdo and allaple datasets.
For some genotypes, REANIMATOR does not provide a
signiﬁcant additional coverage. These genotypes correspond
to behaviors that are performed by the malware every time it
runs, such as dropping a payload by Pushdo. Nevertheless,
we gain some additional coverage (8 samples) in cases where
73
a functionality was not successfully executed in Anubis. In
this speciﬁc case, this is because the Pushdo command and
control servers could not be reached. For the spam behavior,
REANIMATOR provides a signiﬁcant increase in coverage.
E. Performance
In this section, we brieﬂy discuss the performance of
the REANIMATOR genotype model extraction and genotype
model matching techniques.
• Genotype model extraction: Performing genotype model
extraction on a single, ﬁve-minute execution of a binary
in Anubis required under two minutes on standard desktop
hardware. Thus, it is feasible in practice to integrate model
extraction into the workﬂow of a large-scale malware anal-
ysis system such as Anubis.
• Genotype model matching: The genotype model matching
techniques used by REANIMATOR are efﬁcient. Matching
against the entire 2.5GB irc bots dataset (with more than ten
thousand samples) took 2, 511 seconds in total on standard
desktop hardware. Hence, around .25 seconds were spent on
each binary. This performance is negligible compared to the
cost of dynamic analysis.
F. Limitations
In our experiments, we have seen that our genotype
matching technique is successful
in statically analyzing
real-world malware code and ﬁnding dormant functionality.
However, malware authors could make it more difﬁcult for
REANIMATOR to perform this matching step. For this, they
could develop evasion techniques speciﬁcally targeted at
our tool, such as semantics-preserving obfuscation of the
control ﬂow graph. As an example, they could intersperse
their program’s entire CFG with a large number of spurious
nodes and edges. Such techniques could be countered by
performing genotype model matching using more powerful,
semantic-aware models [27].
On the other hand, malware authors are more likely to pre-
fer generic evasion techniques that are capable of defeating
a wide range of analysis and detection approaches. This goal
can be achieved by advanced packing techniques (such as
emulation-based packing and conditional code obfuscation)
that cannot be easily defeated using generic unpacking meth-
ods. While recent work has addressed emulation-based pack-
ing [20], conditional code obfuscation [21] can, in certain
settings, provide strong guarantees that the code cannot be
analyzed statically. This is a limitation that REANIMATOR,
or any other tool relying on static analysis, faces.
Another limitation of our approach is that, to generate
a genotype model, REANIMATOR needs to observe the
least one
execution of the corresponding behavior in at
dynamic analysis run. Therefore, behavior that
is never
executed inside our sandbox cannot be detected. As a
consequence, similar to other dynamic analysis approaches,
REANIMATOR can be defeated by malware that detects
the analysis sandbox and refuses to run. Furthermore, it
cannot detect time- or logic- bombs until they are triggered
by at least one sample. However, it may be possible to
combine our technique with other approaches for improving
the coverage of dynamic analysis, such as multiple path
exploration [4]. Using REANIMATOR, the insight provided
by applying such computationally-expensive techniques to
a single malware execution could be leveraged to provide
information for other samples.
VI. RELATED WORK
A number of related works have explored static and
dynamic approaches to analyze malware samples. As we
observed in Section I, one of the motivations to develop
REANIMATOR is that dynamic analysis suffers from the
weakness of partial coverage. To counter this, previous
research has proposed either to run samples multiple times
by crafting inputs that invert the outcomes of conditional
branches (possible triggers) [3], [4] or simply to force
execution along a different path [5]. Unfortunately, using
such techniques is potentially expensive, as the number of
paths that require analysis can grow exponentially. The path
explosion problem similarly affects dynamic software testing
systems such as EXE [28], DART [29], and SAGE [30],
which use symbolic execution to execute more code paths
for the purpose of ﬁnding more bugs.
Structural characteristics, and in particular CFGs, have
been extensively used in static analysis. Besides the results
in [9], which we leveraged in this work, a similar approach
is presented in [31]. The difference is that the authors of [31]
apply normalization techniques to reduce the effects of well-
known code mutation techniques. After normalization, they
use inter-procedural CFGs, linking together the CFGs of
each function of a program.
Structural code characteristics have also been used to
recognize similarities between program binaries. For exam-
ple, the authors of [32] and [33] both deﬁne a distance
function over a set of malware samples that is based on
their function call graphs. In [32],
the authors propose
using such a distance function to classify malware and to
create a phylogeny of malware binaries. SMIT [33] also
uses properties of the function call graphs to implement an
efﬁcient nearest-neighbor search on large malware datasets.
Function call graphs can provide an overall view of an entire
binary, and are, therefore, suitable for globally comparing
binaries. However, these techniques are typically not well-
suited for detecting the presence of a small code fragment
in a larger program. Moreover, they do not associate any
semantics (information about phenotypes) with call graphs.
Besides using control ﬂow or instruction graphs, other
formalisms have been used to identify viral code sequences.
In [11], model checking is used to identify parts of a pro-
gram that implement a previously speciﬁed malicious code
template. This combats common obfuscation techniques.
74
The technique was later extended in [27], allowing more
general code templates and using advanced static analysis
techniques. Model checking is used also in [34] to semanti-
cally identify malware using a temporal logic speciﬁcation.
All of these systems share the limitation that models of
each behavior instantiation have to be speciﬁed manually.
REANIMATOR, in contrast, only requires generic behavioral
models (phenotypes) of what constitutes a malicious behav-
ior, and is then capable of automatically identifying code
that implements that behavior (the genotype). Furthermore,
these techniques are largely orthogonal to our work. Once
REANIMATOR has identiﬁed a genotype, it could potentially
make use of some of these more sophisticated (and computa-
tionally costly) detection techniques for genotype matching.
Similar to our system, AGIS [35] uses a combination of
dynamic and static techniques to analyze malware. More
precisely, the system uses static analysis to identify instruc-
tion sequences that lead to system calls that are associated
with malicious activity. These instruction sequences are then
used as infection (detection) signatures. A signiﬁcant differ-
ence to our system is the fact that AGIS simply includes
into signatures all instructions that lead to interesting system
calls. Our system, on the other hand, attempts to extract
only those parts of the code that are actually responsible for
the observed behavior. This is achieved by REANIMATOR’s
ﬁltering and germination steps.
Plagiarism detection through source code analysis is a
well-explored theme. Besides MOSS [25], other signiﬁcant
work in this area includes CCFinder [36], Dup [37], and CP-
Miner [6]. Some tools are based on textual analysis, compar-
ing the lines of code. Others compare the token sequences
of lines [36], [37], or tree-representations of the code [38].
Others, more interestingly, use the program dependency
graphs of code (i.e., control and data ﬂow dependencies of
functions) [39], something conceptually close to the use of
CFGs on assembly code. Plagiarism detection on binaries
is less developed. In [26],
the authors have extended a
previous system [38] to work on assembly instructions,
through some normalization techniques and devising novel
models to compactly represent information related to binary
instructions. Again, no semantic information is associated
with detected clones, and the approach is much less robust
than ours with regards to small code changes, for example,
due to different compiler options (as discussed in Section V).
VII. CONCLUSIONS
Dynamic malware analysis systems provide important
information about the capabilities of malicious code found
in the wild. However, they typically only execute a single
execution path. As a result,
to
observe a signiﬁcant fraction of the entire functionality that
a malware sample implements.
these systems often fail
In this paper, we present REANIMATOR, a novel system to
identify dormant functionality in malware. The main insight
behind our system is that we can leverage a single observa-
tion of malicious behavior in one malware sample to detect
the same functionality in other malware programs (even
when they do not exhibit this behavior). In order to achieve
this goal, our system operates in three steps. First, we use
simple rules to identify security-related behavior (pheno-
types) in the output and the events that a malware sample
produces during dynamic analysis. Second, we automatically
locate and model the code (genotype) that is responsible for
this behavior. Third, we reuse previously-generated genotype
models for a speciﬁc behavior to statically detect similar
code in malware that does not exhibit this behavior during
the dynamic analysis.
Our approach allows us to unveil dormant functionality in
malware programs. Thus, we can signiﬁcantly increase our
knowledge about the capabilities of malicious code when
compared to the results delivered by dynamic analysis alone.
Our experiments demonstrate that
the generated models
accurately capture code parts (genotypes) that are respon-
sible for a diverse set of malicious behaviors. Moreover,
they show that REANIMATOR can signiﬁcantly increase the
coverage of dynamic analysis systems.
ACKNOWLEDGMENTS
The authors would like to thank Michael Bailey and Jon
Oberheide for providing us the bot source code samples used
in our evaluation, as well as Thorsten Holz and Morgan
Marquis-Boire for help with the unpacking of malware.
We also acknowledge the help of Federico Maggi with the
artwork, and proofreading. This work has been partially
supported by the European Commission through project
IST-216026-WOMBAT funded under the 7th framework
program, by the ONR under grant no. N000140911042 and
by the National Science Foundation (NSF) under grant no.
0845559.
REFERENCES
[1] “Anubis,” http://anubis.iseclab.org/.
[2] “CWSandbox,” http://www.cwsandbox.org/, 2008.
[3] D. Brumley, C. Hartwig, Z. Liang,
J. Newsome,
P. Poosankam, D. Song, and H. Yin, “Automatically
identifying trigger-based behavior in malware,” in Botnet
Detection, 2008.
[4] A. Moser, C. Kruegel, and E. Kirda, “Exploring multiple
execution paths for malware analysis,” in IEEE Symp. on
Security and Privacy, 2007.
[5] J. Wilhelm and T. Chiueh, “A Forced Sampled Execution
Approach to Kernel Rootkit Identiﬁcation,” in Symp. on
Recent Advances in Intrusion Detection (RAID), 2007.
[6] Z. Li, S. Lu, S. Myagmar, and Y. Zhou, “CP-Miner: A
Tool for Finding Copy-paste and Related Bugs in Operating
System Code,” in USENIX Symp. on Operating System Design
and Implementation (OSDI), 2004.
75
[7] H.-A. Kim and B. Karp, “Autograph:
toward automated,
distributed worm signature detection,” in USENIX Security
Symposium, 2004.
[8] J. Newsome, B. Karp, and D. Song, “Polygraph: Automati-
cally generating signatures for polymorphic worms,” in IEEE
Symposium on Security and Privacy, 2005.
[9] C. Kruegel, E. Kirda, D. Mutz, W. Robertson, and G. Vigna,
“Polymorphic worm detection using structural information
of executables,” in Symp. on Recent Advances in Intrusion
Detection (RAID), 2005.
[10] M. Christodorescu, S. Jha, S. A. Seshia, D. Song, and R. E.
Bryant, “Semantics-aware malware detection,” in IEEE Symp.
on Security and Privacy, 2005, pp. 32–46.
[11] M. Christodorescu and S. Jha, “Static analysis of executa-
bles to detect malicious patterns,” in 12th USENIX Security
Symposium, 2003.
[12] M. Christodorescu, S. Jha, and C. Kruegel, “Mining speciﬁca-
tions of malicious behavior,” in 6th Joint European software
engineering conf. and ACM SIGSOFT Symp. on Foundations
of Software Engineering (ESEC-FSE), 2007.
[13] G. Jacob, H. Debar, and E. Filiol, “Malware behavioral de-
tection by attribute-automata using abstraction from platform
and language,” in Symp. on Recent Advances in Intrusion
Detection (RAID), 2009.
[14] L. Martignoni, E. Stinson, M. Fredrikson, S. Jha, and J. C.
Mitchell, “A Layered Architecture for Detecting Malicious
Behaviors,” in Symp. on Recent Advances in Intrusion Detec-
tion (RAID), 2008.
[15] M. G. Kang, P. Poosankam, and H. Yin, “Renovo: a hidden
code extractor for packed executables,” in ACM Workshop on
Recurring malcode (WORM), 2007.
[16] L. Martignoni, M. Christodorescu, and S. Jha, “Omniunpack:
Fast, generic, and safe unpacking of malware,” in Annual
Computer Security Applications Conf. (ACSAC), 2007.
[17] H. Agrawal and J. Horgan, “Dynamic Program Slicing,” in
Conf. on Programming Language Design and Implementation
(PLDI), 1990.
[18] U. Bayer, I. Habibi, D. Balzarotti, E. Kirda, and C. Kruegel,
“Insights into current malware behavior,” in 2nd USENIX
Workshop on Large-Scale Exploits and Emergent Threats
(LEET), 2009.
[19] P. Royal, M. Halpin, D. Dagon, R. Edmonds, and W. Lee,
“Polyunpack: Automating the hidden-code extraction of
unpack-executing malware,” in 22nd Annual Computer Se-
curity Applications Conf. (ACSAC), 2006.
[20] M. Sharif, A. Lanzi, J. Gifﬁn, and W. Lee, “Automatic
reverse engineering of malware emulators,” in IEEE Symp.
on Security and Privacy, 2009.
[21] M. I. Sharif, A. Lanzi, J. T. Gifﬁn, and W. Lee, “Impeding
malware analysis using conditional code obfuscation,” in
Network and Distributed System Security (NDSS), 2008.
[22] A. Decker, D. Sancho, L. Kharouni, M. Goncharov,
the Pushdo / Cutwail
and R. McArdle, “A study of
Botnet,” http://us.trendmicro.com/imperia/md/content/us/pdf/
threats/securitylibrary/study of pushdo.pdf, 2009.
[23] “F-Secure Malware Information Pages - Allaple.A,” http://
www.f-secure.com/v-descs/allaple a.shtml, 2008.
[24] J. Oberheide, M. Bailey, and F. Jahanian, “PolyPack: An
Automated Online Packing Service for Optimal Antivirus
Evasion,” in USENIX Workshop on Offensive Technologies
(WOOT), 2009.
[25] S. Schleimer, D. S. Wilkerson, and A. Aiken, “Winnowing:
local algorithms for document ﬁngerprinting,” in ACM SIG-
MOD Int. Conf. on Management of Data, 2003.
[26] A. Sæbjørnsen, J. Willcock, T. Panas, D. Quinlan, and Z. Su,
“Detecting code clones in binary executables,” in 18th Int.
Symp. on Software testing and analysis (ISSTA), 2009.
[27] M. D. Preda, M. Christodorescu, S. Jha, and S. Debray, “A
semantics-based approach to malware detection,” in Princi-
ples of Programming Languages (POPL), 2007.
[28] C. Cadar, V. Ganesh, P. M. Pawlowski, D. L. Dill, and D. R.
Engler, “Exe: Automatically generating inputs of death,” ACM
Trans. Inf. Syst. Secur., vol. 12, no. 2, pp. 1–38, 2008.
[29] P. Godefroid, N. Klarlund, and K. Sen, “DART: directed
automated random testing,” in ACM SIGPLAN Conf. on
Programming language design and implementation, 2005.
[30] P. Godefroid, M. Levin, and D. Molnar, “Automated White-
box Fuzz Testing,” in 15th Symp. on Network and Distributed
System Security (NDSS), 2008.
[31] D. Bruschi, L. Martignoni, and M. Monga, “Detecting self-
mutating malware using control-ﬂow graph matching,” in
Detection of Intrusions and Malware and Vulnerability As-
sessment (DIMVA), 2006.
[32] E. Carrera and G. Erdelyi, “Digital genome mapping–
advanced binary malware analysis,” in Virus Bulletin Conf.,
2004, pp. 187–197.
[33] X. Hu, T. Chiueh, and K. Shin, “Large-scale malware index-
ing using function-call graphs,” in ACM Conf. on Computer
and Communications Security (CCS), 2009.
[34] J. Kinder, S. Katzenbeisser, C. Schallhart, and H. Veith,
“Detecting malicious code by model checking,” in Detection
of Intrusions and Malware and Vulnerability Assessment
(DIMVA), 2005.
[35] Z. Li, X. Wang, Z. Liang, and M. K. Reiter, “Agis: Towards
automatic generation of infection signatures,” in DSN, 2008.
[36] T. Kamiya, S. Kusumoto, and K. Inoue, “CCFinder: A Mul-
tilinguistic Token-Based Code Clone Detection System for
Large Scale Source Code,” IEEE Trans. on Soft. Eng., pp.
654–670, 2002.
[37] B. Baker, “On ﬁnding duplication and near-duplication in
large software systems,” in Working Conf. on Reverse En-
gineering (WCRE), 1995.
[38] L. Jiang, G. Misherghi, Z. Su, and S. Glondu, “Deckard:
Scalable and accurate tree-based detection of code clones,”
in 29th Int. Conf. on Software Engineering (ICSE), 2007.
[39] J. Krinke, “Identifying similar code with program depen-
dence graphs,” in 8th Working Conf. on Reverse Engineering
(WCRE), 2001.
76