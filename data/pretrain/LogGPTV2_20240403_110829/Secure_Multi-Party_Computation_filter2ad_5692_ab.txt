1. Allowed adversarial behaviour: The most important parameter that must be deﬁned re-
lates to the actions that corrupted parties are allowed to take. There are three main types of
adversaries:
(a) Semi-honest adversaries: In the semi-honest adversarial model, even corrupted parties cor-
rectly follow the protocol speciﬁcation. However, the adversary obtains the internal state of
all the corrupted parties (including the transcript of all the messages received), and attempts
to use this to learn information that should remain private. This is a rather weak adversarial
model, but a protocol with this level of security does guarantee that there is no inadvertent
data leakage. In some cases this is suﬃcient, although in today’s adversarial environment it
is often insuﬃcient. Semi-honest adversaries are also called “honest-but-curious” and “pas-
sive”. (Sometimes, fail-stop adversaries are also considered; these are essentially semi-honest
adversaries who may also halt the protocol execution early.)
(b) Malicious adversaries: In this adversarial model, the corrupted parties can arbitrarily devi-
ate from the protocol speciﬁcation, according to the adversary’s instructions. In general,
providing security in the presence of malicious adversaries is preferred, as it ensures that
no adversarial attack can succeed. Malicious adversaries are also called “active”.
(c) Covert adversaries [1]: This type of adversary may behave maliciously in an attempt to break
the protocol. However, the security guarantee provided is that if it does attempt such an
attack, then it will be detected with some speciﬁed probability that can be tuned to the
application. We stress that unlike in the malicious model, if the adversary is not detected
then it may successfully cheat (e.g., learn an honest party’s input). This model is suited to
settings where some real-world penalty can be associated with an adversary being detected,
and the adversary’s expectation is to lose overall if it attempts an attack.
2. Corruption strategy: The corruption strategy deals with the question of when and how
parties are corrupted. There are three main models:
(a) Static corruption model: In this model, the set of parties controlled by the adversary is ﬁxed
before the protocol begins. Honest parties remain honest throughout and corrupted parties
remain corrupted.
(b) Adaptive corruption model: Rather than having a ﬁxed set of corrupted parties, adaptive
adversaries are given the capability of corrupting parties during the computation. The
choice of who to corrupt, and when, can be arbitrarily decided by the adversary and may
depend on its view of the execution (for this reason it is called adaptive). This strategy
models the threat of an external “hacker” breaking into a machine during an execution, or
a party who is honest initially and later changes its behaviour. We note that in this model,
once a party is corrupted, it remains corrupted from that point on.
(c) Proactive security model [30,7]: This model considers the possibility that parties are cor-
rupted for a certain period of time only. Thus, honest parties may become corrupted
throughout the computation (like in the adaptive adversarial model), but corrupted parties
may also become honest. The proactive model makes sense in cases where the threat is
an external adversary who may breach networks and break into services and devices, and
secure computations are ongoing. When breaches are discovered, the systems are cleaned
and the adversary loses control of some of the machines, making the parties honest again.
The security guarantee is that the adversary can only learn what it derived from the local
state of the machines that it corrupted, while they were corrupted. Such an adversary is
sometimes called mobile.
There is no “right” model when considering the above. Rather, the speciﬁc deﬁnition used and
adversary considered depends on the application and the threats being dealt with.
Modular sequential and concurrent composition. In reality, a secure multiparty computation
protocol is not run in isolation; rather it is part of a system. In [5], it was proven that if you run an
MPC protocol as part of a larger system, then it still behaves in the same way as if an incorruptible
trusted party carried out the computation for the parties. This powerful theorem is called modular
composition, and it enables larger protocols to be constructed in a modular way using secure sub-
protocols, as well as analysing a larger system that uses MPC for some of the computations.
One important question in this context is whether or not the MPC protocol itself runs at the
same time as other protocols. In the setting of sequential composition, the MPC protocol can run
as a subprotocol of another protocol with arbitrary other messages being sent before and after the
MPC protocol. However, the MPC protocol itself must be run without any other messages being
sent in parallel. This is called the stand-alone setting, and is the setting considered by the basic
deﬁnition of security of [5]. The sequential modular composition theorem of [5] states that in this
setting, the MPC protocol indeed behaves like a computation carried out by a trusted third party.
In some (many) cases, MPC protocols are run at the same time as other instances of itself,
other MPC protocols, and other insecure protocols. In these cases, a protocol proven secure under
the aforementioned stand-alone deﬁnition of security may not actually remain secure. A number of
deﬁnitions were proposed to deal with this setting, the most popular of these is that of universal
composability [6]. Any protocol proven secure according to this deﬁnition is guaranteed to behave
like an ideal execution, irrespective of what other protocols run concurrently to it. As such, this is
the gold standard of MPC deﬁnitions. However, it does come at a price (both of eﬃciency, and of
assumptions required on the system setup).
2.3 Important Deﬁnitional Implications
The ideal model and using MPC in practice. The ideal/real paradigm for deﬁning security
actually has some very important implications for the use of MPC in practice. Speciﬁcally, in order
to use an MPC protocol, all a practitioner needs to do is to consider the security of their system
when an incorruptible trusted party carries out the computation for which MPC is used. If the
system is secure in this case, then it will remain secure even when the real MPC protocols is used
(under the appropriate composition case). This means that non-cryptographers need not understand
anything about how MPC protocols work, or even how security is deﬁned. The ideal model provides
a clean and easy to understand abstraction that can be utilised by those constructing systems.
Any inputs are allowed. Although the ideal model paradigm provides a simple abstraction, as
described above, there is a subtle point that is sometime misunderstood. An MPC protocol behaves
like an ideal execution; as such, the security obtained is analogous to that of an ideal execution.
However, in an ideal execution, adversarial parties may input any values that they wish, and indeed
there is no generic way of preventing this. Thus, if two people wish to see who earns a higher salary
(without revealing any more than this one bit of information), then nothing stops one of them from
inputting the maximum possible value as their salary (and then behaving honestly in the MPC
protocol itself), with the result being that the output is that they earn more. Thus, if the security
of an application depends on the party’s using correct inputs, then mechanisms must be used to
enforce this. For example, it is possible to require signed inputs, and have the signature be veriﬁed
as part of the MPC computation. Depending on the speciﬁc protocol, this can add signiﬁcant cost.
MPC secures the process, but not the output. Another subtlety that is often misunderstood
is that MPC secures the process, meaning that nothing is revealed by the computation itself.
However, this does not mean that the output of the function being computed does not reveal
sensitive information. For an extreme example, consider two people computing the average of their
salaries. It is indeed true that nothing but the average will be output, but given a person’s own
salary and the average of both salaries, they can derive the exact salary of the other person. Thus,
just using MPC does not mean that all privacy concerns are solved. Rather, MPC secures the
computing process, and the question of what functions should and should not be computed due to
privacy concerns still needs to be addressed. In some cases, like threshold cryptography, this question
is not an issue (since the output of cryptographic functions does not reveal the key, assuming that
it’s secure). However, in other cases, it may be less clear.
3 Feasibility of MPC
The above-described deﬁnition of security seems to be very restrictive in that no adversarial success
is tolerated, and the protocol should behave as if a trusted third party is carrying out the com-
putation. Thus, one may wonder whether it is even possible to obtain secure protocols under this
deﬁnition, and if yes, for which distributed computing tasks. Perhaps surprisingly, powerful fea-
sibility results have been established, demonstrating that in fact, any distributed computing task
(function) can be securely computed, in the presence of malicious adversaries. We now brieﬂy state
the most central of these results. Let n denote the number of participating parties and let t denote a
bound on the number of parties that may be corrupted (where the identity of the corrupted parties
is unknown):
1. For t  n.
polynomials ℓ1(x), . . . , ℓt(x), where reconstruction is carried out by computing q(x) =!t+1
random coeﬃcients a1, . . . , at ∈ Zp, and sets q(x) =!t
Shamir’s secret sharing scheme utilises the fact that for any for t+1 points on the two dimensional
plane (x1, y1), . . . , (xt+1, yt+1) with unique xi, there exists a unique polynomial q(x) of degree
at most t such that q(xi) = yi for every i. Furthermore, it is possible to eﬃciently reconstruct
the polynomial q(x), or any speciﬁc point on it. One way to do this is with the Lagrange basis
i=1 ℓi(x)·yi.
Given the above, in order to share a secret s, the dealer chooses a random polynomial q(x) of
degree at most t under the constraint that q(0) = s. (Concretely, the dealer sets a0 = s and chooses
i=0 ai · xi.) Then, for every i = 1, . . . , n, the
dealer provides the i’th party with the share yi = q(i); this is the reason why we need p > n, so
that diﬀerent shares can be given to each party. Reconstruction by a subset of any t parties works
by simply interpolating the polynomial to compute q(x) and then deriving s = q(0). Although t + 1
parties can completely recover s, it is not hard to show that any subset of t or fewer parties cannot
learn anything about s. This is due to the fact that they have t or fewer points on the polynomial,
and so there exists a polynomial going through these points and the point (0, s) for every possible
s ∈ Zp. Furthermore, since the polynomial is random, all polynomials are equally likely, and so all
values of s ∈ Zp are equally likely.
4.2 Honest-Majority MPC with Secret Sharing
The ﬁrst step in most protocols for general MPC (i.e., protocols that can be used to compute any