ing, which may cause edges to be drawn unnecessarily. For example, if a network
host sinkholes multiple domains belonging to distinct criminal networks, our
graph building process will erroneously show them as related. To address this
problem in general, we leverage graph structure to identify the criminal networks
using community ﬁnding algorithms.
The community ﬁnding process can automatically infer these scenarios based
on the graph structure and correctly partition the underlying criminal networks.
To perform community ﬁnding, we use the Louvain method [4], an algorithm
known to scale well to graphs with hundreds of millions of vertices and bil-
lions of edges. We apply the community ﬁnding algorithm to each non-isolated
component in our graph at step 5 of Figure 1.
3.3 Graph Analysis
δ = |E|/(cid:0)|V |
2
Deﬁnitions: Understanding whether a graph is dense or sparse is a useful mea-
sure for summarizing graph structure. The density of a graph G, δ, is deﬁned by
(cid:1) and is the ratio of edges present in G to the number of possible
edges in G. A graph with a density of 1 is complete and with a density of 0 has no
edges. In our graphs, vertices are not of uniform importance, so quantifying the
centrality of a vertex in a graph is a useful way of estimating the node’s relative
importance in the graph based on its structure. The eigenvector centrality (EC)
is a measure of a vertex’s centrality which often reﬂects its importance based on
the graph’s structure. Using EC, a vertex is considered important if it has many
neighbors, a few important neighbors, or both. More formally, the eigenvector
centrality xi for a vertex i in a graph G is deﬁned in Equation 2,
(cid:88)
j
Aijxj
xi = κ−1
1
(2)
where A is the adjacency matrix of G, κ1 is its largest eigenvalue, 0 ≤ xi ≤ 1,
and xj are i’s neighbors eigenvector centralities [27]. The EC is a useful metric
for identifying “important” vertices in a graph independent of the underlying
data being represented. We will use this to help determine a takedown strategy
that attempts to maximize damage to a criminal network. Removing important
vertices targets portions of the criminal network that are used both frequently
and collectively to host the operations of multiple criminals.
Consider a social network, such as Facebook, where a vertex represents an
individual and an edge drawn between two vertices represents a friendship. Ver-
tices in this graph with high eigenvector centrality will be individuals with a large
number of friends, a few friends that have many friends, or both. Similarly, high
eigenvector centrality vertices in a criminal network graph are hosting providers
that provide redundancy for many smaller hosting providers, a few larger hosting
providers, or both. As an example, consider that a botnet operator could host
her C&C server using a benign hosting provider, but when the C&C server is
discovered, the diligent hosting provider will likely respond to abuse complaints
and disable it. Thus, our operator uses a less scrupulous hosting provider to pro-
vide redundancy in the event of such a remediation attempt. One can imagine
this behavior occurring in several criminals, and aggregated over time one would
expect some kind of structure to emerge where the least scrupulous and most
diligent hosting providers have the highest and lowest eigenvector centralities,
respectively. This intuition suggests that targeting more structurally important
vertices can help make takedown attempts more damaging to criminal networks.
There is an important caveat in the social network analogy that concerns
connectivity. In a social network, removing social ties can sever friendships be-
tween individuals, but the same is not true in criminal networks. This is because
nothing ﬂows between connections in a criminal network in a literal sense, like
friendship ﬂows between mutual friendships. The assumption that does hold true
is that someone with high social standing is likely to befriend additional high sta-
tus individuals or several individuals en masse. Considering criminal networks,
this means high eigenvector centrality networks are more likely to continue and
expand their malicious activity into the future and therefore are where remedi-
ation eﬀorts ought to be focused.
Simulating Takedowns Our ultimate goal is to determine how to perform eﬀec-
tive and damaging takedowns of criminal networks. We ﬁrst provide a bird’s eye
view of the criminal network landscape to search for recurring graph structures
that are susceptible to takedowns. In other words, graph structures that lend
themselves to comprehensive takedowns that require marginal eﬀort. Next, we
focus on speciﬁc cases of large criminal networks where we identify critical in-
frastructure to target during remediation to maximize the damage inﬂicted on
a criminal network when a comprehensive takedown is prohibitively expensive.
Using the graph analysis measures we deﬁned above, we identify potential
weak points in a criminal network graph that may be susceptible to takedowns,
and analyze how successful our takedowns would be by estimating the potential
loss in future successful lookups. Not all criminal networks have the same struc-
ture, and some structures may be more or less amenable to diﬀerent types of
takedowns, such as taking down speciﬁc subnetworks or remediating groups of
domain names aﬃliated with the network.
We consider the two main methods for takedown: network-level takedown,
accomplished by raiding a hosting facility, or a domain-level takedown, accom-
plished by “revoking” domain names associated with the criminal network in co-
operation with the domain names registrars. The goal of these takedown methods
is to prevent potential victims from reaching key parts of the criminal network
infrastructure.
criminal network G, we deﬁne the criticality of the vertices v ∈ G by:
To determine the order in which to take down infrastructure for a given
crit(v) = vip × vd × vec
(3)
where vip is the number of malicious IPs within vertex v, vd is the number
of malicious domains that have pointed into v, and vec is the vertex’s eigen-
vector centrality. The ﬁrst two measures quantify the vertex’s historic career
of maliciousness and the eigenvector centrality quantiﬁes the vertex’s structural
importance to the criminal network.
eliminate for performing a comprehensive takedown
Input: MD: a set of known malicious domains
Output: Returns, for each criminal network, the suggested order of networks to
MIP ← RHIP(MD)
MNet ← bin IPs in MIP into Class C networks
MNet ← ∀v∈MNet remove v if RHDN (MNet)∩ whitelist (cid:54)= ∅
E ← {}
for v1, v2 ∈ MNet do
if RHDN(v1) ∩ RHDN(v2) (cid:54)= ∅ then
E ← E ∪ (v1, v2)
end
end
G ← (MN et, E)
CriminalN etworks ← CommunityF inding(G)
takedowns ← {}
for subgraph ∈ CriminalNetworks do
takedowns ← takedowns ∪ sort descending by arg maxv∈subgraph crit(v)
end
return takedowns
Algorithm 1: High-level overview of how criminal networks are discovered
and nodes are prioritized for takedown.
In an operational environment, takedowns would be performed based on the
output of Algorithm 1. The system takes sets of known malicious domains and
outputs, for each identiﬁed criminal network, the nodes that should be targeted
during a comprehensive takedown to maximize damage to the hosting infrastruc-
ture. The infrastructure used by the malicious domains are identiﬁed using the
passive DNS database call to RHIP. These IPs are pruned using our whitelisting
procedure and are grouped into their parent Class C (/24) networks. For each
pair of networks, we identify domain name overlaps using the RHDN function.
This identiﬁes networks that share the burden of providing malicious infras-
tucture and if a takedown were desired, must be taken down simultaneously
to perform a comprehensive takedown. The graph is partitioned using the de-
scribed community ﬁnding algorithm to identify distinct criminal networks and
by analyzing the graph structure we can determine which networks provide es-
sential redundant hosting for criminal activity. Because malicious activity is so
heavily distributed, targeting the worst individual hosting facility is insuﬃcient.
To perform comprehensive takedowns, one must consider the criminal network
structure holistically, which motivates the use of the graph-based representa-
tion. It allows us to focus on the entire structure such that we can maximize the
damage against the network.
For every criminal network in our case study, we order the vertices by their
criticality using Equation 3 and estimate the beneﬁt in taking down the criminal
network using either network-level or domain-level takedowns. For each type of
takedown, we present a cumulative distribution function (CDF) showing the
proportion of domain names or networks removed from the criminal network
against the total amount of potential victim lookups with respect to the entire
criminal network. The intuition is that revoking domain names and blocking
IP addresses that received a large volume of queries in the recent past has the
potential of preventing a large fraction of the victim population from reaching
the criminal network hosts in the future. If we successfully targeted critical
infrastructure, the CDF will be superlinear denoting that eliminating key pieces
of infrastructure severely impacts the lookups destined for the criminal network.
If a strategy is unsuccessful, we should see linear/sublinear CDFs.
4 Threat Landscape
In this section, we present general observations about the graphs we built for our
study. We discuss source type distributions and describe a case of a frequently
occurring graph structure that could be easily taken down.
4.1 General Graph Statistics
Starting in May 2011, we began building graphs every day for a period of 8
months. Our ﬁnal graph contains 64,030 vertices and 1,957,614 edges and repre-
sents 127,597 malicious IPs and 3,018,077 malicious domain names. The graph
is disconnected, where 54% of the vertices are isolated components. These are
threats that do not distribute their infrastructure using the DNS. As we men-
tioned earlier, many of these isolated components may also be due to false posi-
tives from non-distributed hosting not present in our whitelist. Figure 2a shows
a breakdown of threat types between isolated and non-isolated components.
Most isolated vertices hosted spam sites or malware-related threats, and very
few hosted any others. Our malware and spam sources are fundamentally noisy
which, could explain the large diﬀerence between the isolated and non-isolated
type distributions.
Since we are building our graphs with historical data, it is possible that
originally bad IPs are remediated and used later on for legitimate purposes. If
the new domains that resolve to the remediated IP space are whitelisted they
will be removed from the graph, but if they are not they would still be ﬂagged as
malicious. To address this problem in future work, a shorter window of analysis
can be used to reduce the likelihood of this behavior becoming commonplace.
4.2 Criminal Network Landscape
The remaining vertices form 4,504 distinct communities where each represents
a criminal network. Of the 4,504 criminal networks identiﬁed, approximately
87% of them formed complete subgraphs. In addition to being complete, Fig-
ure 2b shows that most criminal networks contain few domains and second-level
domains (2LD) and even fewer networks. In over half of the complete cases, a
criminal network could be disabled by de-registering as few as ﬁve domain names
or three 2LDs. This strongly suggests that a large number of small criminal net-
works can be easily remediated.
(a) Type breakdown-isolated vs. non-
isolated. The y-axis represents the threat
type seen in each vertex of our graph.
Most host a single threat type (e.g., spam
or malware), but many host multiple
threat types, even reusing the same IP
address (e.g., malware,spam, etc.).
(b) Log-scale distribution of the crimi-
nal network size, domains and 2LDs in
complete criminal networks.
Fig. 2: Threat landscape breakdown
5 Case Studies
We describe four case studies of large and structurally interesting criminal net-
works that represent the diﬀerent classes of infrastructure we saw in the wild.
The case studies were not chosen automatically, but were chosen based on the
visualizations of the output of our community ﬁnding algorithm described in
Section 3.2. We used simple graph metrics to select the case student criminal
networks by focusing on large graphs (e.g. many vertices) that had high and
low graph densities. In all AS graph visualizations, vertex color encodes the au-
tonomous system number while the vertex size encodes the number of known
malicious domains that historically pointed into the network. Furthermore, the
edges are drawn when one or more domains are shared between two vertices, un-
less otherwise speciﬁed. In all eigenvector centrality (EC) graph visualizations,
vertex shade encodes the eigenvector centrality (darker is more important), and
vertex size and edges are deﬁned as they are for AS graphs, unless otherwise
speciﬁed. The authors suggest that visualizations of the case studies be viewed
in a PDF viewer if a high-resolution color printer is not available to get a clear
view of the infrastructure.
For each criminal network presented, we provide a breakdown of the identiﬁed
criminal operators using them as well as a breakdown of the sources polled to
generate the vertices in the criminal network. Prior to investigating each case
study, we were unaware of the underlying criminal aﬃliations. We will see that
EC is a key factor we can use to dynamically obtain a metric for the critical
vertices in the criminal network. As we noted in Section 3.3, EC is analogous
to PageRank [5] for undirected graphs and provides a similar measure of the
importance of a vertex in a graph.
5.1 Rustock Criminal Network
Rustock criminal network was among the largest criminal networks we identi-
ﬁed with 3,177 vertices and 7,128 edges. Rustock [23] was a large spam-oriented
botnet generally used for fraudulent pharmaceutical sales. We describe the ma-
licious hosting infrastructure used by Rustock and that was still in use during
our study by other criminals.
Rustock criminal network’s most distinguishing features can be seen in Fig-
ure 3a. It is sparse (graph density of 0.001) and the graph contains a dense core
of networks that contain a large proportion of the domain names compared to
the remaining vertices, shown by their larger size. In addition to the number of
malicious domains they host, these vertices are also considered important based
on their eigenvector centrality, shown in Figure 3b.
The top ASs by eigenvector centrality in the Rustock criminal network are
shown in Table 1. This criminal network employs a mixture of bulletproof host-
ing, cloud-based hosting and compromised home user machines as part of its
infrastructure. The inclusion of GoDaddy is due to parking sites the malicious
domains pointed to before and/or after their malicious lifetime. CloudFlare is
currently running sinkholes for Kelihos and most likely for other botnets as well,
(a) Rustock criminal network AS graph
(b) Rustock criminal network EC graph
(c) MojoHost benign hosting network
AS graph
(d) MojoHost benign hosting network
EC graph
Fig. 3: Case Study Visualizations [2]
(a) Masterhost criminal network AS graph (b) Masterhost criminal network EC graph
(c) Botnet criminal network
AS graph
(d) Botnet criminal network
Inverted EC graph
Fig. 4: Case Study Visualizations cont.
(a) Rustock criminal
network
(b) MojoHost benign
hosting network
(c) Masterhost crimi-
nal network
(d) Botnet criminal
network
Fig. 5: Network-level takedown CDFs
AS# AS Description
33626 Oversee
22489 Castle Access Inc.
15146 Cable Bahamas
13335 CloudFlare Inc.
16509 Amazon
32421 Black Lotus Communications
32592 Hunt Brothers
21844 The Planet
26496 GoDaddy
4635 Confluence Network Inc.
# of Domains
14,262
124,321
55,465
21,770