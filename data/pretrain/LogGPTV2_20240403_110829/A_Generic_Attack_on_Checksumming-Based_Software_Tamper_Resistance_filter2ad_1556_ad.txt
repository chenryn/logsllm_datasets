surrounding program. Therefore, an IVK-protected ap-
plication is vulnerable to our attack.
There are many other alternatives if one is willing
to change our requirements and have applications de-
pend on some type of trusted third party. For example,
an application could rely on a custom operating system
extension (e.g. a kernel module) to verify the integrity
of its code. However implementation complexity, lack
of portability, stability, and security concerns that arise
when changing the underlying operating system make
such an approach unappealing.
Another alternative is to assume that an application
has access to some type of trusted platform, whether
in the form of an external hardware “dongle” [9], a
trusted remote server [15], or a trusted operating sys-
tem [20, 23]. Whatever the method used, though, to pre-
vent a processor-based attack such as ours the developer
must be able to guarantee that the code that is executed
is identical to the code that is checked.
To summarize, we do not know of any alternatives
to checksumming in the self-checking tamper resistance
space that combine the ease of implementation, platform
independence, and runtime efﬁciency of checksumming
that are also invulnerable to a processor-based instruc-
tion/data separation attack. Nonetheless, advances in
static and run-time analysis might possibly enable the
development of alternative systems that verify the state
of a program binary by intermingling and checking run-
time intermediate values, that can be applied to existing
programs, and that impose little run-time overhead; our
work provides signiﬁcant motivation for the pursuit of
such methods.
6. Related Work
Various alternate tamper resistance proposals attempt
to address the malicious host problem by the introduc-
tion of secure hardware [29, 28, 32]. Storing programs
in memory which is execute-only4 [18] has also been
proposed, preventing the application from being visible
in its binary form to an attacker. Secure hardware, how-
ever, is not widely deployed and therefore not widely
viewed as a suitable mass-market solution. Other re-
search has involved the use of external trusted third par-
ties [5, 6, 11]. However, not all computers are contin-
uously connected to the network, which among other
drawbacks, makes this solution unappealing in general.
Research is ongoing into techniques for remote authen-
tication (e.g. see [15, 27, 16], also [3]). SWATT [26]
has been proposed as a method for external software to
verify the integrity of software on an embedded device.
Other recent research [24] proposes a method, built us-
ing a trusted platform module [31], to verify client in-
tegrity properties in order to support client policy en-
forcement before allowing clients (remote) access to en-
terprise services.
Software tamper resistance often employs software
obfuscation in an attempt to make intelligent software
tampering impossible (see [10, 34] and recent surveys
[7, 33]). We view obfuscation and tamper resistance as
distinct approaches with different end goals. Obfusca-
tion, which is typically most effective against static anal-
ysis, primarily attempts to thwart reverse engineering
and extraction of intelligence regarding program design
details; as a secondary effect, often this thwarts intelli-
gent software modiﬁcation. Tamper resistance attempts
to make the program unmodiﬁable.
In an obfuscated
program, code modiﬁcations are generally not directly
detected.
4Such execute-only memory differs from execute-only segments as
discussed in Section 4.2.
Proceedings of the 2005 IEEE Symposium on Security and Privacy (S&P’05) 
1081-6011/05 $ 20.00 IEEE
Among other proposed methods of integrity veriﬁca-
tion which differ from self-checksumming tamper resis-
tance are programs like Tripwire [17], which attempt to
protect the integrity of a ﬁle system against malicious
intruders. Integrity veriﬁcation at the level of Tripwire
assumes that the operator is trusted to read and act on
the veriﬁcation results appropriately. Other recent pro-
posals include a co-processor based kernel runtime in-
tegrity monitor [22], but these do not protect against the
hostile host problem in the case of a hostile end user.
Other related work is discussed in Section 5.2.
7. Concluding Remarks
We have shown that the use of self-checksumming
for tamper resistance is less secure than previously be-
lieved on several of today’s prominent computer pro-
cessors, as demonstrated herein on the UltraSparc and
x86. Our attack should therefore be carefully consid-
ered before choosing to use checksumming for tamper
resistance. As noted earlier, other forms of tamper re-
sistance exist which are not susceptible to our attack,
but these typically have their own disadvantages (see
Section 5.2). We encourage further research into other
forms of self-checking tamper resistance, such as new
security paradigms possible through execute-only page
table entries [18].
Memory management functionality within a proces-
sor plays an important role in determining how vulnera-
ble current implementations are to our attack. If a pro-
cessor does not distinguish between code and data reads,
then our attack fails. Modern processors, however, are
increasingly providing functionality that allows such a
distinction to be made, due to the performance and gen-
eral security beneﬁts of code/data separation at a proces-
sor level. On such processors, self-integrity checksum-
ming tamper resistance is not secure against attack, and
tamper resistance mechanisms which are not compro-
mised by such distinctions should instead be pursued.
Acknowledgements. The ﬁrst author acknowledges
Canada’s National Sciences and Engineering Research
Council (NSERC) for funding his PGS M scholarship.
The second author acknowledges NSERC for funding
an NSERC Discovery Grant and his Canada Research
Chair in Network and Software Security. The third au-
thor acknowledges NSERC for funding an NSERC Dis-
covery Grant. We thank David Lie, Mike Atallah, Clark
Thomborson (and his group), and anonymous referees
for their comments on a preliminary draft.
References
[1] Advanced Micro Devices, Inc. AMD64 Architecture
Programmer’s Manual, volume 2: System Program-
ming. Advanced Micro Devices, Inc., Sep 2003.
[2] D. Aucsmith. Tamper resistant software: An implemen-
tation. In R. Anderson, editor, Proceedings of the First
International Workshop on Information Hiding, volume
1174 of Lecture Notes in Computer Science, pages 317–
333. Springer-Verlag, may 1996.
[3] E. Brickell, J. Camenisch, and L. Chen. Direct anony-
mous attestation.
In B. Pﬁtzmann and P. Liu, editors,
Proceedings of the 11th ACM Conference on Computer
and Communications Security, pages 132–144. The As-
sociation for Computing Machinery, Oct 2004.
[4] H. Chang and M. Atallah. Protecting software code by
guards.
In Proc. 1st ACM Workship on Digital Rights
Management (DRM 2001), volume 2320 of Lecture
Notes in Computer Science, pages 160–175. Springer-
Verlag, 2002.
[5] Y. Chen, R. Venkatesan, M. Cary, R. Pang, S. Sinba, and
M. Jakubowski. Oblivious hashing: A stealthy software
integrity veriﬁcation primitive. In Proc. 5th Information
Hiding Workship (IHW), volume 2578 of Lecture Notes
in Computer Science, pages 400–414, Netherlands, Oct.
2002. Springer-Verlag.
[6] J. Claessens, B. Preneel, and J. Vandewalle. (How) can
mobile agents do secure electronic transactions on un-
trusted hosts? A survey of the security issues and the
current solutions. ACM Trans. Inter. Tech., 3(1):28–48,
2003.
[7] C. S. Collberg and C. Thomborson. Watermarking,
tamper-prooﬁng, and obfuscation: Tools for software
protection.
IEEE Trans. Softw. Eng., 28(8):735–746,
2002.
[8] Compaq Computer Corporation. Alpha Architecture
Handbook, chapter 6 - Common PALcode Architecture.
Number EC-QD2KC-TE. 4th edition, Oct 1998.
[9] J. Gosler. Software protection: Myth or reality?
In
Advances in Cryptology – CRYPTO’85, volume 218 of
Lecture Notes in Computer Science, pages 140–157.
Springer-Verlag, 1985.
[10] H. Goto, M. Mambo, K. Matsumura, and H. Shizuya.
An approach to the objective and quantitative evalua-
tion of tamper-resistant software.
In J. S. J. Pieprzyk,
E. Okamoto, editor, Information Security: Third Inter-
national Workshop, ISW 2000, volume 1975 of Lecture
Notes in Computer Science, pages 82–96, Wollongong,
Australia, Dec 2000. Springer-Verlag.
[11] F. Hohl. Time limited blackbox security: Protecting mo-
bile agents from malicious hosts. In Mobile Agents and
Security, volume 1419 of Lecture Notes in Computer
Science, pages 92–113. Springer-Verlag, 1998.
[12] B. Horne, L. Matheson, C. Sheehan, and R. Tarjan.
Dynamic self-checking techniques for improved tam-
per resistance.
In Proc. 1st ACM Workshop on Digi-
tal Rights Management (DRM 2001), volume 2320 of
Proceedings of the 2005 IEEE Symposium on Security and Privacy (S&P’05) 
1081-6011/05 $ 20.00 IEEE
Lecture Notes in Computer Science, pages 141–159.
Springer-Verlag, 2002.
[13] Intel.
IA-32 Intel Archetecture Software Developer’s
Manual, volume 3: System Programming Guide, chap-
ter 3 - Protected-Mode Memory Management. Intel Cor-
poration, P.O. Box 5937 Denver CO, 2003.
[14] H. Jin and J. Lotspiech. Proactive software tampering
detection. In C. Boyd and W. Mao, editors, Information
Security: 6th International Conference, ISC 2003, vol-
ume 2851 of Lecture Notes in Computer Science, pages
352–365, Bristol, UK, Oct 2003. Springer-Verlag.
[15] R. Kennell and L. H. Jamieson. Establishing the genuin-
ity of remote computer systems. In Proceedings of the
12th USENIX Security Symposium, pages 295–308, Aug
2003.
[16] R. Kennell and L. H. Jamieson. An analysis of proposed
attacks against genuinity tests. Technical report, Purdue
University, Aug 2004. CERIAS TR 2004-27.
[17] G. H. Kim and E. H. Spafford. The design and imple-
mentation of Tripwire: A ﬁle system integrity checker.
In Proceedings of the 2nd ACM Conference on Com-
puter and Communications Security, pages 18–29. ACM
Press, 1994.
[18] D. Lie, C. Thekkath, M. Mitchell, P. Lincoln, D. Boneh,
J. Mitchell, and M. Horowitz. Architectural support for
copy and tamper resistant software. In Proceedings of
the Ninth International Conference on Architectural sup-
port for Programming Languages and Operating Sys-
tems, pages 168–177. ACM Press, 2000.
[19] The Linux Kernel Archives, Oct 2004. http://www.
kernel.org.
[20] P. A. Loscocco, S. D. Smalley, P. A. Muckelbauer, R. C.
Taylor, S. J. Turner, and J. F. Farrell. The inevitability
of failure: The ﬂawed assumption of security in mod-
ern computing environments.
In 21st National Infor-
mation Systems Security Conference. National Security
Agency, 1998. http://csrc.nist.gov/nissc/
1998/proceedings/paperF1.pdf.
[21] Motorola. Programming Environments Manual: For 32-
Bit Implementations of the PowerPC Architecture. Dec.
2001. http://e-www.motorola.com/brdata/
PDFDB/docs/MPCFPE32B.pdf.
[22] J. Nick L. Petroni, T. Fraser, J. Molina, and W. A. Ar-
baugh. Copilot - a coprocessor-based kernel runtime
integrity monitor. In Proceedings of the 13th USENIX
Security Symposium, pages 179–194, Aug 2004.
[25] T. Sander and C. Tschudin. Protecting mobile agents
against malicious hosts.
In G. Vigna, editor, Mobile
Agents and Security, volume 1419 of Lecture Notes in
Computer Science, pages 44–60. Springer-Verlag, 1998.
[26] A. Seshadri, A. Perrig, L. van Doorn, and P. Khosla.
SWATT: Software-based attestation for embedded de-
vices.
In Proceedings of the IEEE Symposium on Se-
curity and Privacy, Oakland, CA, May 2004.
[27] U. Shankar, M. Chew, and J. Tygar. Side effects are not
sufﬁcient to authenticate software. In Proceedings of the
13th USENIX Security Symposium, pages 89–102, Aug
2004.
[28] S. W. Smith and S. Weingart.
Building a high-
performance, programmable secure coprocessor. Com-
puter Networks, 31(9):831–860, 1999.
[29] G. E. Suh, D. Clarke, B. Gassend, M. van Dijk, and
S. Devadas. AEGIS: architecture for tamper-evident
and tamper-resistant processing. In Proceedings of the
17th Annual International Conference on Supercomput-
ing, pages 160–171. ACM Press, 2003.
[30] Sun Microsystems. UltraSPARC III Cu user’s man-
ual.
4150 Network Circle, Santa Clara, California,
Jan 2004. http://www.sun.com/processors/
manuals/USIIIv2.pdf.
[31] Trusted Computing Group. Trusted platfrom module
(TPM) main speciﬁcation, version 1.2, revision 62, Oct
2001. http://www.trustedcomputinggroup.
org.
[32] Trusted Computing Group, Oct 2004. http://www.
trustedcomputingroup.com/home.
[33] P. C. van Oorschot. Revisiting software protection. In
C. Boyd and W. Mao, editors, Information Security: 6th
International Conference, ISC 2003, volume 2851 of
Lecture Notes in Computer Science, pages 1–13, Bris-
tol, UK, Oct 2003. Springer-Verlag.
[34] C. Wang.
A Security Architecture for Surviv-
ability Mechanisms.
PhD thesis, University
of Virginia, Charlottesville, Virginia, Oct. 2000.
http://www.cs.virginia.edu/˜survive/
pub/wangthesis.pdf.
[35] G. Wurster, P. C. van Oorschot, and A. Somayaji.
Generic attacks on self-checksumming software tamper
resistance. In preparation.
[23] M. Peinado, Y. Chen, P. England, and J. Man-
Jan
http://research.microsoft.com/
ferdelli.
2005.
˜yuqunc/papers/ngscb.pdf.
NGSCB: A trusted open system,
[24] R. Sailer, T. Jaeger, X. Zhang, and L. van Doorn.
Attestation-based policy enforcement for remote access.
In B. Pﬁtzmann and P. Liu, editors, Proceedings of
the 11th ACM Conference on Computer and Commu-
nications Security, pages 308–317. The Association for
Computing Machinery, Oct 2004.
Proceedings of the 2005 IEEE Symposium on Security and Privacy (S&P’05) 
1081-6011/05 $ 20.00 IEEE