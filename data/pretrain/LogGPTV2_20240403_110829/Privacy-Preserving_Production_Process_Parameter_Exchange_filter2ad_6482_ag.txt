index 𝑖𝑑𝑥′. Our rounding approach resembles a binning of related
records, i.e., related records are rounded to same value such that
their indices are identical. The rounding depends on the absolute
value of the input parameter to achieve a granularity adaption
because smaller changes in smaller values are expected to have a
larger influence than the same absolute change on a larger value. For
example, cooling times can easily be as low as 5 s, while common
melt temperatures for regularly-used polypropylene polymer are
above 200 °C. Here, the absolute difference between the values is far
more than a magnitude, demanding a use case-specific rounding.
In theory, any rounding could be implemented and used as well.
We demonstrate our used rounding approach based on such input
parameters (1.21, 22.22, 333.33). Our defined function 𝑟 rounds each
input parameter 𝑥𝑖 to a certain number of digits, here exemplified
with 2 for all inputs, starting from the digit with the highest potency.
This rounding yields the identifying parameters (1.2, 22.0, 330.0).
This example demonstrates that the rounding of 𝑥1 uses a finer
granularity than 𝑟(𝑥3) due to its smaller absolute value.
A.2 A Basic Similarity Metric
To illustrate the computation of the candidate set 𝑆 = 𝑠(𝑞), we con-
sider the target record (1.2, 22.0, 330.0), a rounding to two digits,
and a metric 𝑠 that computes the 10 % offset for each identifying
parameter. This metric yields 1.1, 1.2, and 1.3 as possible values
for the first parameter because the absolute offset is 0.12 such that
1.0 and 1.4 are not covered. For the second parameter, the metric
computes 5 possible values and 7 for the third parameter. Hence,
the candidate set consists of 3 · 5 · 7 = 105 candidates in total.
B SUPPLEMENTAL PERFORMANCE RESULTS
We include additional supplemental evaluations to substantiate the
made feasibility claims and to justify our parameter choices. We
now present the results of theses supporting measurements.
B.1 Bloom Filter
(b) The FP rate only has a neg-
(a) The capacity of the Bloom fil-
ligible influence on the time re-
ter has only a limited impact on
the measured query time.
quired to query the Bloom filter.
Figure 12: The capacity has only a small influence on the
query time, while the FP rate has nearly no influence at all.
Apart from the Bloom filter size, we also measured the influence
of the capacity and configured FP rate on the insertion or query
(b) The insertion time depends
linearly on the number of in-
serted elements.
(a) The query time depends lin-
early on the number of per-
formed queries.
Figure 13: Both the number of inserted and queried ele-
ments have a linear influence on the corresponding time.
times for a certain number of elements. Furthermore, we measured
the influence of the number of queried elements on the query time.
If not stated otherwise, we set a FP rate of 220, a capacity of 100 Mio.
elements, inserted as many elements as configured by the capacity
and queried a total of 100 Mio. elements. While Figure 12 illustrates
the influence of capacity and FP rate on the query time, Figure 13a
details the influence of the number of queried elements. Both ca-
pacity and FP rate only have a limited influence on the time needed
to query 100 Mio. elements. As expected, for a fixed capacity and
FP rate, the number of queried elements influences the process-
ing linearly (cf. Figure 13a). By design, querying is embarrassingly
parallel as the individual queries are independent of each other.
(b) An exponential decrease of
the FP rate yields an approx. lin-
early increased insertion time.
(a) Even huge sets with a billion
elements can be inserted into a
Bloom filter in under 6 h.
Figure 14: By design, a larger capacity and a lower false pos-
itive (FP) rate influence the insertion time of a Bloom filter.
The time required for the insertion scales linearly with the num-
ber of inserted elements, for a fixed capacity and FP rate (cf. Fig-
ure 13a). In Figure 14, we observe that the insertion of millions of
elements takes several hours with our experimental setup. However,
concerning our design, this time is tolerable because insertions are
one-time activities, which are not time-critical. The insertion likely
occurs with delay as data providers do not offload their records
simultaneously. Moreover, our measurements indicate that the in-
sert time increases approximately linearly with an exponentially
decreasing FP rate. Accordingly, very low false positive rates can
be configured while maintaining reasonable insertion times.
B.2 Oblivious Transfer
We also conducted additional measurements for our second building
block. As detailed in Section 7.2.2, we rely on the semi-honest OT
protocol KKRT16 [42] for all measurements, which is the fastest
semi-honest OT protocol supported by libOTe [64]. Two parameters
influence the OT runtime and memory usage by design: Both the set
size (cf. Figure 15) and the number of OT extensions (cf. Figure 16)
have a linear correlation. All measured runtime stay below 2 min in
these measurements, however, as discussed in Section 7.2.2, network
conditions have a major influence on the runtime as well. With
decent network conditions, our measurements indicate that even
00.2 Bil0.4 Bil0.6 Bil0.8 Bil1.0 BilCapacity [#]020406080Query Time [s]101103106109101210151018FP Rate010203040Query Time [s]00.2 Bil0.4 Bil0.6 Bil0.8 Bil1.0 BilQueries [#]0246Query Time [min]00.2 Bil0.4 Bil0.6 Bil0.8 Bil1.0 BilInserted Elements [#]0100200Insert Time [min]00.2 Bil0.4 Bil0.6 Bil0.8 Bil1.0 BilCapacity [#]0100200300400Insert Time [min]101103106109101210151018FP Rate05101520Insert Time [min]Privacy-Preserving Production Process Parameter Exchange
ACSAC 2020, December 7–11, 2020, Austin, USA
Figure 15: The OT set size linearly influences the runtime
and memory usage. We measure 10 OT extensions each.
Figure 17: The key retrieval dominates the runtime of the
data provision, and the record size has a negligible impact.
Figure 16: With a set size of 220, the number of performed OT
extensions linearly influences the runtime and RAM usage.
200 key retrievals via OT are feasible for a set size of 220. These
numbers are relevant when offloading millions of records overall
and when retrieving tens or even hundreds of keys per client.
B.3 Data Provision
In addition to the building block evaluations, we performed mea-
surements of the data provision phase for each setting. Figure 17
illustrates the influence of the record length. For this measurement,
we uploaded 100 random records while varying the number of in-
cluded parameters 𝑚. The key retrieval remains constant as the
same encryption keys are retrieved for each measurement. The
length of the records does not have a significant influence on the
runtime as the key retrieval dominates the data provision.
In Figure 18, we include the data provision phase of our injection
molding evaluation (cf. Section 7.4). We ran two evaluations with a
varying share of uploaded parameters. For the first measurement,
shown by the left-sided bars, we chose to upload all parameters
with the same identifier before considering the data belonging to a
different geometry. Here, the key retrieval overhead increases with
a larger number of uploaded records because 77 records have the
same index and therefore need the same encryption key. Therefore,
the number of retrieved keys only increases when parameters with
distinct identifiers are offloaded. For the second measurement, we
selected the records uniform at random for each share. Here, already
the first upload (10 %), equaling 462 records, has a high probability
of containing one record of each of the 60 groups, such that all keys
are required. Thus, the key retrieval times remain nearly constant.
Moreover, the figure shows that the key retrieval dominates the
data provision as for our setting with random records in Section 7.3.
The entire provision phase takes less than 12 s, even if all records
are uploaded at once. Consequentially, the data provision is feasible
even in settings where providers upload large amounts of records.
C PPE: PSI-BASED PARAMETER EXCHANGE
We proposed PPE (cf. Section 8.2.1) for settings with metrics that
yield small candidate sets and require increased provider privacy.
Figure 18: Our real-world injection molding use case also
shows that the key retrieval dominates the data provision.
C.1 PPE Protocol Differences
PPE provides improved provider privacy (G1) by replacing the
Bloom filter-based matching in the matching phase with a PSI (cf.
Section 4). As shown in Figure 19, the other parts of the BPE proto-
col remain unchanged. Due to the PSI, the client cannot gain any
knowledge about the server’s set except for the matching elements.
The client utilizes the computed candidate set 𝑆, and the server
takes the indices of all stored records as their sets for the PSI. Since
a PSI further requires indices to perform the intersection on (2128
in our case and larger than the chosen OT set size of 𝐾 = 220), we
introduce a third indexing 𝐿 with 𝐾 ⊂ 𝐿 ⊂ 𝐻, and calculate the
respective truncation for 𝐿 using the values inserted in the sets.
Although, in theory, the PSI would support the intersection
of sets with a size of 2128, to achieve computational feasibility,
the number of elements in the set must be reduced. Notably, in
contrast to OT, the input indices in 𝐿 are not limited by the PSI
set size reducing the chance of clients guessing matching indices
and further, due to computational effort, preventing clients from
performing PSI operations with an extensive number of elements
in their candidate set (e.g., to request all records from the server).
Even though the size of 𝑆 depends on the client and its chosen
metric, we expect that the server set is unlikely to exceed 100 Mio.
elements (cf. Section 7.2.1), and thus, we fix the PSI set size to 220.
C.2 Private Set Intersection Performance
As for the oblivious transfers (cf. Section 7.2.2), we rely on the semi-
honest PSI protocol KKRT16 [42], which is the fastest protocol
supported by libPSI [65]. The main influence on the runtime of
a PSI protocol is the used PSI set size, which scales linearly with
the runtime and memory usage (cf. Figure 20). Due to the linear
influence on the runtime, the maximal supportable PSI set size
for PPE depends on the available memory at the storage server.
Furthermore, the storage server must potentially serve multiple
clients at once, i.e., offer a PSI sender instance for each client. Hence,
defining the maximum supported PSI set size in accordance to the
available memory of the storage server is unreasonable. For the
2202212222233 Mio5 Mio7 Mio10 MioSet Size [#]0102030405060Time [s]0123456RAM Usage [GB]RuntimeClientServer020406080100120140160180200Number of OT Extensions [#]0204060Time [s]012345RAM Usage [GB]RuntimeClientServer1002003004005006007008009001000Record Length [#]0.02.55.07.510.012.515.0Time [s]Hash Key R.Key R. (OT)OT TLSEncryptionSending102030405060708090100Uploaded Records [%]0.02.55.07.510.012.5Time [s]Hash Key R.Key R. (OT)OT TLSEncryptionSendingACSAC 2020, December 7–11, 2020, Austin, USA
Pennekamp et al.
Figure 22: For small candidate sets, both BPE’s and PPE’s
matching phases yield similar runtimes.
Figure 19: For PPE, we replace the Bloom filter-based match-
ing with a PSI, while the remaining protocol is unchanged.
chosen set size of 220 (cf. Appendix C.1), approximately 0.6 GB are
utilized at maximum, so that the server can interact with multiple
clients simultaneously. Moreover, the PSI protocol runtime is also
influenced by network conditions, i.e., both latency and bandwidth
have a major impact (cf. Figure 21). We limited the bandwidth
asynchronously with a ratio of 1/10 to mimic common broadband
connections. The labels in Figure 21a again refer to the server-client
direction. The figure highlights that, especially, a low bandwidth has
a major impact on the performance. However, even for a restricted
bandwidth with 6 MBit/s, the execution time for a PSI with a set size
of 1 Mio. elements stays around 45 min, which is still acceptable as
our scenario tolerates the combined matching and record retrieval
to take several days. As stated for OTs, PSI protocols also exhibit a
trade-off between communication and computation overhead [42].
Accordingly, the used protocol can be adapted to specific needs.
Figure 20: Both runtime and required memory increase ap-
proximately linearly with an increasing PSI set size.
(b) Latency also impacts the com-
munication overhead of PSIs.
(a) A reduced bandwidth affects
the large transmissions of PSIs.
Figure 21: Both a decreased bandwidth and an increased la-
tency negatively influence the linear coefficient when con-
sidering the PSI set size and the overall processing time.
C.3 PPE Full Application Performance
In addition to the building blocks, we also measured the perfor-
mance of PPE. Given that the data provision and record retrieval
remain unchanged, the same considerations as described in Sec-
tion 7.3 apply. Figures 11 and 22 compare the matching and record
Figure 23: While the PSI execution time stays constant (cf.
Figure 22), the preparation time increases with the size of 𝑆.
retrieval phases to BPE. The two figures underline that the per-
formance of BPE and PPE is comparable. In the given setting, the
main overhead is caused by the preparation of the PSI. This phase is
responsible for creating a duplicate free candidate set, which is used
as the receiver set for the PSI. However, as shown in Appendix C.2,
the PSI execution time increases if larger set sizes are used.
We could only perform an evaluation of PPE with IM-2% from
Section 7.4 because the utilized similarity metric for IM-2.5% yields
a candidate set (143 Mio. elements) that is not feasible for PPE as
it exceeds our maximally supported set size of 220. This situation
illustrates the main drawback of the PPE design and explains why
we favor BPE. While PPE can offer an increased level of provider
privacy for privacy cautious providers, it is not applicable in general.
The evaluation of IM-2% with the PPE design (cf. Figure 23)
shows that the runtime of the PSI preparation phase increases for
larger candidate sets, while the PSI execution takes approximately
the same time. Moreover, the measurement implies that for larger
candidate sets, the PSI-based matching produces significantly more
overhead than the Bloom filter-based matching of the BPE variant.
In contrast, our second use case, as described in Section 7.5,
results in significantly smaller candidate sets such that PPE is appli-
cable for both our evaluated metrics. Due to the small candidate sets
(cf. Figure 10), i.e., |𝑆| = 11 for MT-Material, and |𝑆| = 701 for MT-
Diameter, the PSI preparation that dominated our first evaluations
(cf. Figure 11 and 23) only produces negligible overhead. Instead,
the PSI execution accounts for the main runtime in the PSI-based
matching. Here, PPE even outperforms our BPE design. The key re-
trieval times differ due to the number of matched and subsequently
retrieved records (10 for MT-Material vs. 6 for MT-Diameter).
In conclusion, the evaluation of the PPE design variant shows
that the variant is not universally applicable due to the restriction
of the candidate set by the PSI set size and the overhead produced
by the PSI preparation phase. However, for use cases that yield
small candidate sets, such as our considered machine tool setting
from Section 7.5.1, PPE can even outperform BPE while providing
increased provider privacy. Accordingly, the choice of which design
variant is best-suited depends on the given use case.
ClientI: Data ProvisionII: MatchingIII: Record R.II.7: Matching  (PSI)II.5: Hash Key RetrievalIII.8: Key Retrieval (OT)III.9: Record  RetrievalPaymentII.6: Prepare PSIIII.10: DecryptionKey ServerStorage ServerData Provider(s)I.1: Hash Key Retrieval (R.)I.2: Key Retrieval (OT)I.3: EncryptionI.4: SendingFor readability, we omit authentication and reg-istrationhere. We includeit in our implementation.2202212222232246 Mio10 Mio15 Mio20 MioPSI Set Size [#]020406080Time [s]0.02.55.07.510.012.515.0RAM Usage [GB]RuntimeClientServer00.2 Mio0.4 Mio0.6 Mio0.8 Mio1.0 MioPSI Setsize  [#]012345Time [min]    6MBit/s  50MBit/s100MBit/sUnlimited02 Mio4 Mio6 Mio8 Mio10 MioPSI Setsize [#]012345Time [s]300ms250ms200ms150ms100ms  50ms    0msHash Key R.Bloom R.MatchingPSI Prep.PSI Exec.Key R. (OT)Record R.DecryptionPhase0102030405060Time [s]|S|0.3 Mio.|S|0.3 Mio.Standard BPEPSI-based PPERandom-0.3%TLSHash Key R.Bloom R.MatchingPSI Prep.PSI Exec.Key R. (OT)Record R.DecryptionPhase020406080100120Time [s]|S|1 Mio.|S|1 Mio.Standard BPEPSI-based PPEIM-2%TLS