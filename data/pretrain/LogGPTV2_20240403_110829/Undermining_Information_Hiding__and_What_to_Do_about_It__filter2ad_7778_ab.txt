(TCB) and Thread Local Storage (TLS).
Whenever the system spawns a new thread for a pro-
gram, it also initializes a corresponding Thread Control
Block (TCB), which holds information about the thread
(e.g., the address of its stack). However, once an attacker
knows the location of the TCB, she also (already) has
the stack location as the TCB is placed on the newly
allocated stack of the thread. An exception is the cre-
ation of the main thread where the TCB is allocated in
a memory region that has been mapped, with mmap(),
during program initialization. Since the initialization of
the program startup is deterministic, the TCB of the main
stack is located at a ﬁxed offset from the base address of
mmap() (which can be easily inferred by leaked point-
ers into libraries).
Moreover, obtaining the address of the TCB is often
easy, as a reference to it is stored in memory and passed
to functions of the pthread library. While not visi-
ble to the programmer, the metadata required to manage
threads in multi-threaded applications can also leak the
address of the thread stacks. If an attacker is able to ob-
tain this management data, she is also able to infer the lo-
cation of stacks. Note that the management data is stored
in the TCB because threads allocate their own stacks, so
they need to free them as well. Furthermore, we found
that the TCB also contains a pointer to a linked list with
all TCBs for a process, so all stacks can be leaked this
way.
108  25th USENIX Security Symposium 
USENIX Association
4
Additionally, TLS consists of a static portion and a
dynamic portion and the system happens to allocate the
static portion of the TLS directly next to the TCB. The
TLS portions are managed through the Dynamic Thread
Vector (DTV) structure which is allocated on the heap at
thread initialization and pointed to by the TCB. Leaking
the location of DTV will also reveal the stack location.
Another way to obtain the location of the stacks is us-
ing global variables in libpthread.so. The loca-
tions of active stacks are saved in a double linked list
called stacks_used which can be accessed if the location
of the data section of libpthread is known to an at-
tacker.
In summary, our analysis of the implementation re-
veals that references to sensitive information (in our case
safe stacks) do occur in unexpected places in practice.
While these issues may not be fundamental, given the
complexity of the environment and the operating system,
delivering a sound implementation of IH-based defenses
is challenging. All references should be accounted for in
a production defense that regards stack locations as sen-
sitive information. We even argue that any IH-hardening
solution (like the one presented in this paper) should take
implementation ﬂaws of defense solutions such as CPI
into account, since they are common and often not under
direct control of the solution (e.g., because of external
code and libraries).
4.2 Attacks with Thread Spraying
While prior research has already demonstrated that in-
formation hiding mechanisms which utilize a large safe
area are vulnerable to brute-force attacks [17], our re-
search question is: are small safe areas without refer-
ences to them really more secure than large safe areas?
More generally speaking, we explore the limitations of
hiding information in an address space and discuss po-
tential attacks and challenges.
In the following, we investigate in detail CPI’s SafeS-
tack as an illustrative example. While the safe area itself
is very large (dependent on the implementation it may
have sizes of 242 or 230.4 [17, 25]), a safe stack is only a
few MB in size and hence it is challenging to locate it in
the huge address space. We analyze the SafeStack imple-
mentation available in the LLVM compiler toolchain. As
discussed above, the safe stack keeps only safe variables
and return addresses, while unsafe variables are moved
to an unsafe stack. Hence, an attacker—who has the pos-
sibility to read and write arbitrary memory—still cannot
leak contents of the safe stack and cannot overwrite re-
turn addresses: she needs to locate the safe stack ﬁrst.
We study if such an attack is feasible against web
browsers, given the fact that they represent one of the
most prominent attack targets. We thus compiled and
linked Mozilla Firefox (version 38.0.5) for Linux us-
ing the -fsanitize=safe-stack ﬂag of the clang
compiler and veriﬁed that SafeStack is enabled during
runtime. We observed that safe stacks are normally rela-
tively small: each thread gets its own safe stack, which is
between 2MB (221 bytes; 29 pages) and 8MB (223 bytes;
211 pages) in size. With 28 bits of entropy in the 64-
bit Linux ASLR implementation, there are 228 possible
page-aligned start addresses for a stack. Hence, an ad-
versary needs at least 219 probes to locate a 2MB stack
when sweeping through memory in a brute-force man-
ner. In practice, such an attack seems to be infeasible.
For server applications, a brute-force attack would be de-
tectable by external means as it leads to many observable
crashes [25].
However, an attacker might succeed with the follow-
ing strategy to reduce the randomization entropy: while
it is hard to ﬁnd a single instance of a safe stack inside
a large address space, the task is much easier if she can
force the program to generate a lot of safe stacks with a
certain structure and then locate just one of them. Thus,
from a high-level perspective our attack forces the pro-
gram to generate a large number of safe stacks, a tech-
nique we call thread spraying. Once the address space
is populated with many stacks, we make sure that each
stack has a certain structure that helps us to locate an
individual stack within the address space. For this, we
make use of a technique that we term stack spraying, to
spray each stack in such a way that we can later easily
recognize it. Finally, via a brute-force search, we can
then scan the address space and locate a safe stack in a
few seconds. In the following, we describe each step in
more detail.
4.2.1 Thread Spraying
Our basic insight is that an adversary can abuse legit-
imate functions to create new stacks, and thereby de-
crease the entropy. Below, we explain how we performed
the thread spraying step in our attack on Firefox. Fur-
thermore, we show that the thread spraying technique is
also possible in other applications, namely Chrome and
MySQL.
Thread Spraying in Firefox: Our thread spraying in
Firefox is based on the observation that an attacker
within JavaScript can start web workers and each web
worker is represented as a stand-alone thread. Thus, the
more web workers we start, the more safe stacks are
created and the more the randomization entropy drops.
Thread spraying may spawn a huge number of threads.
In empirical tests on Firefox we were able to spawn up to
30,000 web workers, which leads to 30,000 stacks with
a size of 2MB each that populate the address space. In
our attack, we implemented this with a malicious web-
site that consists of 1,500 iframes. Each iframe, loading
USENIX Association  
25th USENIX Security Symposium  109
5
a webpage from distinct domain name, allows the cre-
ation of 20 web workers. As we will show later, forcing
the creation of 2,000 or even only 200 stacks is enough in
practical settings to locate one of the safe stacks reliably.
Fortunately, launching this lower number of concurrent
threads is much less resource intensive and the perfor-
mance impact is small.
Thread Spraying in Chrome: We also tested if Google
Chrome (version 45.0.2454.93) is prone to thread spray-
ing and found that Chrome only allows around 60 worker
threads in the standard conﬁguration. An investiga-
tion revealed that this number is constrained by the to-
tal amount of memory that can be allocated for worker
threads. When we request more worker threads, the
Chrome process aborts as it is unable to allocate mem-
ory for the newly requested thread. However, if the
attacker has a write primitive, she can perform a data
corruption attack [12] and modify a variable that has
an effect on the size of the memory space being allo-
cated for worker threads.
In Chrome, we found that
when we decrease the value of the global data vari-
able g_lazy_virtual_memory, Chrome will allo-
cate less memory space for a worker thread. The less
space allocated, the more worker threads it can spawn.
As a result, we were able to spawn up to 250 worker
threads, with a default stack size of 8MB, after locating
and modifying this data variable, during runtime, in the
bss section of the Chrome binary.
Thread Spraying in MySQL: We also evaluated the
thread spraying attack on the popular MySQL database
server (version 5.1.65).
Interestingly, MySQL creates
a new thread for each new client connection. By de-
fault, the maximum number of simultaneous connections
is 151 and each thread is created with a stacksize of
256KB. With 151 threads, this amounts to 37.8MB of
safe stack area in the memory space which corresponds
to spawning just ~19 Firefox or ~5 Chrome worker
threads. This would make it hard to perform a success-
ful thread spraying attack. However, as in the Chrome
use case above, an attacker with a write primitive can
corrupt exactly those variables that constrain the num-
ber of threads—using a data-oriented attack [12]. We
found that the number of threads in MySQL is con-
strained by the global variables max_connections
and alarm_queue.
Increasing them, allows an at-
tacker to create more connections and thus more threads.
Since MySQL has a default timeout of 10 seconds for
connections, it may be hard to keep a high number of
threads alive simultaneously, but it is just as easy to
overwrite the global variables connect_timeout and
connection_attrib, which contains the stack size
used when creating a thread for a new client connection.
In a simple test we were able to create more than 1000
threads with a stacksize of 8MB.
For example,
Protecting the Thread Limits: In some applications,
such as Chrome and MySQL, there are global vari-
ables that are associated explicitly or implicitly with
in Chrome there is
thread creation.
g_lazy_virtual_memory which,
if reduced, al-
lows for the creation of more worker threads. Placing
these variables in read-only memory can potentially mit-
igate the thread-spraying attacks, however, it is unclear if
the application’s behavior is also affected. In Section 5
we present a defense system that protects applications
from all attacks discussed in this section without relying
on protecting limits associated with thread creation.
4.2.2 Stack Spraying
At this point, we forced the creation of many stacks
and thus the address space contains many copies of safe
stacks. Next, we prepare each stack such that it contains
a signature that helps us to recognize a stack later. This
is necessary since we scan in the next step the memory
space and look for these signatures in order to conﬁrm
that we have indeed found a safe stack (with high prob-
ability).
In analogy with our ﬁrst phase, we term this
technique stack spraying.
From a technical point of view, we realize stack spray-
ing in our attack as follows. Recall that a safe stack as-
sumes that certain variables are safe and this is the case
for basic data types such as integers or double-precision
ﬂoating point values. Moreover, Firefox stores double-
precision values in their hexadecimal form in memory.
For instance, the number 2.261634509803921 ∗ 106 is
stored as 0x4141414141414140 in memory. Ad-
ditionally, calling a JavaScript function with a double-
precision ﬂoat value as parameter leads to the placement
of this value on the safe stack since the system consid-
ers it safe. We exploit this feature to (i) ﬁll the stack
with values we can recognize and (ii) occupy as much
stack space as possible. We therefore use a recursive
JavaScript function in every worker which takes a large
number of parameters. We call this function recursively
until the JavaScript interpreter throws a JavaScript Error
(too much recursion). As we can catch the error within
JavaScript, we create as many stack frames as possible
and keep the occupied stack space alive. Of course, other
implementations of stack spraying are also possible.
A thread’s initial stack space contains various safe
variables and return addresses before we call the recur-
sive function the ﬁrst time. Thus, this space is not con-
trollable, but its size does not vary signiﬁcantly across
different program runs. For example, in our tests the ini-
tially occupied stack space had a size of approximately
three memory pages (0x3000 bytes) in each worker. A
sprayed stack frame consists of the values that the recur-
sive function retrieves as parameters and is additionally
110  25th USENIX Security Symposium 
USENIX Association
6
is also successful against an improved version. For our
evaluation we assumed that an attacker can not always
rely on the stacks being located close to each other. As
such we implemented a simple module that can be loaded
via LD_PRELOAD and forces each call to mmap, associ-
ated with a stack creation (i.e. MAP_STACK provided in
the ﬂags argument), to allocate memory at a random ad-
dress. This means every page is a potential stack base
and our ﬁrst two methods are no longer effective.
4.3.1 Naïve attack on adjacent stacks
The simplest attack is based on the observation that all
stacks are allocated close to each other, starting from a
randomly chosen base address. To investigate this obser-
vation, we spawned 200 worker threads and performed
stack spray in each one. We chose a number of param-
eters for the recursive function such that each sprayed
stack frame had a size of one page (4096 bytes). As
each thread gets a stack of 2MB in size and individ-
ual stacks are grouped closely in memory, we can treat
the compound of stacks as a coherent region of approx-
imately 228B in size. To locate a safe stack we scan
towards lower addresses with 228B sized steps starting
at 0x7ffffffff000, the highest possible stack base.
As soon as we hit mapped memory we start searching in
page sized steps for our sprayed signature. We performed
this scan on three Firefox runs and needed only 16755.0
probing attempts on average (consisting of 1241.3 228B
sized probes and 15513.7 page sized probes) to locate
a signature and thus a safe stack. While this method is
simple to implement and locates stacks with a high prob-
ability it has a chance to miss a stack region, if our single
probe of a potential stack region hits the gap between two
stacks by chance. While retrying with a different start-
ing offset is possible, the next method is more ﬁt for this
purpose.
4.3.2 Optimized attack on adjacent stacks
As a variation of our previous method we modiﬁed the
scanning strategy based on our observations. During
three runs with Firefox, we ﬁrst launched 2,000 worker
threads and again performed stack spraying in each of
them. Afterwards we conducted our memory scanning.
The results are shown in Table 1. As our memory range,
we chose 0x7FxxxxYYYYY0, whereby the least three
signiﬁcant bytes are ﬁxed (YYYYY0) while the fourth
and ﬁfth byte remain variable (xxxx). This yields a
memory range of 216 = 65,536 addresses: due to 28-
bit entropy for top down stack allocations, each of the
chosen ranges constitutes a potential range for stack al-
locations. The probability that one of the chosen ranges
is not a potential stack range is negligibly small.
Figure 1: Memory layout of Firefox with CPI’s SafeStack ﬁlled with
sprayed stack frames
interspersed with data intended to reside in a stack frame.
As the size of this data is predictable, we can control the
size of the stack frame with the number of parameters
passed to the recursive function. While the number of
sprayed stack frames is controllable via the number of
recursive calls, we perform as many recursive calls as
the JavaScript interpreter allows.
Figure 1 illustrates the memory layout of a sprayed
safe stack after the ﬁrst two phases of our attack. Since
the system keeps safe variables such as double-precision
ﬂoating point values on the safe stack, the memory can
be ﬁlled with controlled stack frames which contain user-
controlled signatures in a controllable number. Thus, we
generate a repetitive pattern on the safe stacks of web
workers, which leads to the following observations:
• The probability of hitting a stack during memory
probing attempts increases, as the allocated space of
a safe stack is ﬁlled with a recognizable signature.
• Where safe stacks are not consecutive to each other,
they are separated only by small memory regions.
Thus, probing with stack-sized steps is possible
which reduces the number of probes even further.
• On a signature hit, we can safely read in sprayed
frame sized steps towards higher addresses until we
do not hit a signature anymore. This tells us that
we have reached the beginning of the thread’s stack,
which we can disclose further to manipulate a return
address.
4.3 Scanning methodologies
During our experiments we developed multiple scanning
methods ﬁtted to different defense scenarios. In the fol-
lowing we shortly describe the observations leading to
the development of each and evaluate them against the
targeted defense measures. The ﬁrst two techniques are
targeted at the standard ASLR while the last technique
USENIX Association  
25th USENIX Security Symposium  111
7
Table 1: Memory scans in Firefox on eight different ranges after thread and stack spraying was applied- In each range, byte four and ﬁve
are variable (denoted by ****). Thus, each range consists of 216 = 65536 addresses. Mapped denotes the number of readable addresses, S-hits
the number of addresses belonging to the safe stack that contain our signature, and Non S-Hits represent safe stack addresses not containing our
signature. False S-hits means that our signature was found at an address not being part of a safe stack.
Run 1
Run 2
Run 3
Memory Range Mapped S-Hits Non S-Hits False S-Hits Mapped S-Hits Non S-Hits False S-Hits Mapped S-Hits Non S-Hits False S-Hits
0x7f****000000
0x7f****202020
0x7f****404040
0x7f****606060
0x7f****808080
0x7f****a0a0a0
0x7f****c0c0c0
0x7f****e0e0e0
878
886
884
890
889
889
888
892
184
198
182
197
182
193
190
195
95
74
98
66
92
60
86
64
0
0
0
0
0
0
2