ciphertext Ck,j with the following properties:
(1) Ck,j represents a valid re-encryption of
Ci,j−1 and γk is a commitment to the value
π−1
j (k) = i. Observe that Sj cannot success-
fully open the input/output relationship for
an input without a correct successor.
We refer to a ciphertext that lacks a cor-
rect antecedent or lacks a correct successor
as a dud. Based on our deﬁnitions of an-
tecedents and successors, a dud must be an
“intermediate” ciphertext, i.e., the output of
an odd-numbered server or, equivalently, the
input of an even-numbered one. A given dud
will be detected with probability at least 1/2,
as either its antecedent or successor must be
checked. It may also be seen in our scheme
that duds are checked independently, i.e., as
independent events.
Let us consider “paired” servers (Sj, Sj+1).
Suppose that the input and output cipher-
texts to this pair of servers diﬀer in at least
Kj,j+1 values. More precisely, suppose that
any one-to-one mapping f from outputs to
inputs excludes at least Kj,j+1 output ele-
ments.
It may be seen there exists such a
one-to-one mapping f that includes at least
one distinct input/output pair of ciphertexts
for every intermediate ciphertext that is not
a dud. Therefore, there are at least Kj,j+1
duds among the intermediate ciphertexts. It
is clear that K ≤ K1,2 + K3,4 + . . . + Kn−1,n.
(Intuitively, the total number of altered ci-
phertexts at each server pair cannot exceed
the number of ciphertexts altered across the
entire mix network.) Therefore, there are at
least κ duds among the intermediate cipher-
texts published by all server pairs. Since each
dud is detected independently with probabil-
(cid:12)(cid:13)
ity at least 1/2, the claim follows.
Example 1. Given an output tally of 46
Republican votes and 54 Democratic votes in
a small election, authorities would conclude
that in the worst case, an attacker might have
swung the election through manipulation of a
minimum of four initially Republican votes.
(This would be possible, for example, if the
true tally were 50 Democratic vs. 50 Repub-
lican, for example.) By Claim 1, the prob-
ability that an adversary might have swung
the election is at most 1/16.
Example 2. While the correctness assur-
ance in the above example is very low, a
more realistic example gives a substantially
lower adversarial success probability. Let us
consider the recent U.S. Presidential election
in Florida which yielded a tally with some
2,910,074 votes for Bush and some 2,909,114
votes for Gore [1]. For these tallies to be pro-
duced from ballots in which there was an ex-
act tie or in which Gore obtained more votes,
a minimum of 480 votes would have to be ma-
nipulated. By Claim 1, the probability of this
would be at most 2−480, which is truly neg-
ligible and far smaller than the probability
of breaking a typically parameterized crypto
system.
In typical circumstances, Claim 1 repre-
sents an overestimate of the success proba-
bility of such an attacker. In particular, our
computation here assumes that the attacker
alters ballots in the optimal way. This is pos-
sible for an adversary corrupting the ﬁrst few
servers if voters register with their parties
– otherwise, the adversary could only guess
what ballots to alter.
6 Public Veriﬁability
To deﬁne the property of public veriﬁabil-
ity in a mix network, we require a stronger
adversarial model than for our deﬁnitions of
privacy or correctness. In particular, we must
assume an adversary that potentially controls
all servers and all voters. This is an unreal-
istically pessimistic assumption, but aims to
characterize the security of the mix scheme in
the worst case.
In deﬁning public veriﬁability, we consider
a veriﬁcation function, which we denote by
ver, that is eﬃciently computable by any en-
tity, whether or not the entity participates in
the mixing process. Input to ver includes the
contents of the bulletin board at the conclu-
sion of the mixing process; in particular, it in-
cludes the set of ciphertexts input to the mix
network CIn = {C0,i}n
i=1, the set of output ci-
phertexts COut = {Ct,i}n
i=1, and all commit-
ments, input/output relationships, and other
evidence published by all servers. The func-
tion ver outputs “correct” if the output of the
mix network is a correct representation of the
input, or appears to be such; it outputs “in-
correct” otherwise.
The standard deﬁnition of public veriﬁabil-
ity states, loosely speaking, that a mix net-
work is publicly veriﬁable if for some ver-
iﬁcation function ver, the adversary cannot
feasibly produce input that falsely yields the
output “correct”. In other words, an adver-
sary should not be able to spoof a veriﬁcation
function ver into accepting a “mismatched”
pair (CIn, COut), i.e., a pair such that the
set of plaintexts corresponding to COut is not
equal to that corresponding to CIn.
Our scheme achieves a somewhat weaker
version of public veriﬁability. An adversary
with full control of all players in our scheme
can, strictly speaking, cause (with some prob-
ability) a veriﬁcation function ver to accept
a mismatched pair (CIn, COut). What such
an adversary cannot do, however, is create a
sizable discrepancy between inputs and out-
puts to the mix network. More precisely, we
show that in order to alter κ posted votes
in an election scheme with high probability,
the adversary must perform computational
eﬀort roughly 2κ. In consequence, our scheme
provides public assurance that no adversary
could have feasibly altered, say, 160 votes in
the election. (Furthermore, we know that it
is infeasible to modify even a much smaller
number of votes if not all mix servers collude
– this provides further reassurance of the cor-
rectness in case of narrow margins.)
Recall that all the servers have to commit
to their permutations, as well as to their por-
tion of what determines the challenges. This
eﬃciently makes the protocol deterministic
after it has begun, and makes it impossible
for a colluding set of servers to select permu-
tatations so that only “clean” elements will
be veriﬁed.
Furthermore, recall that servers reveal in-
put/output relations according to a random
seed Q. This seed is computed by applying a
hash function h to the contents of the bulletin
board after all mixing has taken place (but
prior to veriﬁcation, of course). Modeling h
as a random oracle, we may assume that for
every attempt on the part of the adversary
to produce a transcript that spoofs the veriﬁ-
cation function, the adversary must make an
oracle call to determine what challenges the
servers respond to. We consider a veriﬁca-
tion function ver that checks all revealed in-
put/output relations in the obvious manner.
Given this model, and assuming p = 1/2, we
make the following claim.
Claim 1 Suppose that an adversary with full
control of all servers and voters wishes to gen-
erate a pair (CIn, COut) and bulletin board
contents, i.e., server transcripts, with the fol-
lowing property. The set of plaintexts corre-
sponding to CIn diﬀers from that correspond-
ing to COut by at least κ, but ver outputs “cor-
rect”. With q queries to the oracle, the adver-
sary will be successful with probability at most
q2−κ, for a number of queries q to the ran-
(cid:12)(cid:13)
dom oracle.
Given this claim, we may state as a rough rule
of thumb that the results of an election are
publicly veriﬁable in a meaningful way if the
winner leads by a margin of at least 160 votes.
In this case, an adversary that performs com-
putation 280 (more precisely, makes 280 oracle
calls) has success probability at most 2−80.
In a practical setting, however, this security
analysis is rather conservative. It may be re-
laxed somewhat under assumptions such as
the following.
1. Many voters are honest: If a voter does
not collaborate with the adversary, then
her ciphertext randomizes Q in a man-
ner previously unpredictable to the ad-
versary.
In consequence, the adversary
can only make useful oracle queries dur-
ing the interval of time between the last
vote posted by an honest voter and the
time that the tally is output. This places
a practical restriction on the amount
of computing power the adversary can
bring to bear on manipulation of the
election since it forces the adversary to
commence the attack after the ”honest
vote(s)” have been colleted, and thereby
prevents a ”pre-computation attack.”
2. The election includes many ballots: A
second practical security against attacks
is obtained by forcing the recomputata-
tion of long hashes in order to succeed
with an attack. Namely, recall that the
full contents of the bulletin board must
be hashed using h in order to compute
the seed Q.
In a large election, there-
fore, an oracle query is an expensive op-
eration. This restricts (by some medium-
sized factor) the number of oracle queries
an adversary with a given amount of
computing power can make.
Acknowledgements
The third author wishes to extend his
thanks for support from the Carnegie foun-
dation
Of course, if the tally yielded by our scheme
involves too small a margin of victory to en-
sure public veriﬁability, it is always possible
to apply a diﬀerent and more expensive, but
publicly veriﬁable mix network to the posted
votes, e.g., [10, 16].
7 Discussion
The most signiﬁcant advantage of the mix
scheme we propose here is that the proofs are
exceptionally simple; they merely involve re-
vealing the randomizing factors for the ran-
domized encryption operations. No zero-
knowledge proofs are required. The scheme
is therefore exceptionally eﬃcient.
With use of a Chaumian mix net, the bal-
lots may have arbitrary size or content. We
may have write-in votes, or large ballots,
without diﬃculty.
An adversary controlling some minority
group of servers may try to replace κ bal-
lots with its own substitutes. Given p = 1/2,
the chance of the adversary succeeding with-
out detection is at most 1/2κ. Thus trying to
cheat by more than a ballot or two is risky. A
cheating server must either confess to cheat-
ing or (equivalently) fail to produce a required
proof. The penalties for cheating would be so
severe as to preclude the attempt.
In summary, we believe that RPC mix nets
are an interesting and practical approach for
obtaining voter anonymity in an electronic
voting system.
References
[1] George W. Bush, et al., petitioners v.
Albert Gore, Jr., et al., No. 00-949,
Supreme Court of the United States, 531
U.S. December 12, 2000.
[2] M. Abe. Universally veriﬁable mix-net
with veriﬁcation work independent of the
number of mix-servers.
In K. Nyberg,
editor, EUROCRYPT ’98, volume 1403
of Lecture Notes in Computer Science,
pages 437–447. Springer-Verlag, 1998.
[3] M. Abe. Mix-networks on permutation
networks.
In K-Y. Lam, E. Okamoto,
and C. Xing, editors, ASIACRYPT ’99,
volume 1716 of Lecture Notes in Com-
puter Science, pages 258–273. Springer-
Verlag, 1999.
[4] M. Bellare, A. Desai, D. Pointcheval,
and P. Rogaway. Relations among no-
tions of security for public-key encryp-
tion schemes. In Advances in Cryptology
- CRYPTO’98, volume 1462 of Lecture
Notes in Computer Science, pages 26–
45. Springer, 1998.
[5] M. Bellare and P. Rogaway. Optimal
asymmetric encryption.
In R. Ruep-
pel, editor, Advances in Cryptology–
Eurocrypt ’94, volume 950 of Lecture
Notes in Computer Science, pages 92–
111. Springer, 1994.
[6] M. Bellare and A. Sahai. Non-malleable
encryption: Equivalence between two
notions, and an indistinguishability-
based characterization.
In M. Wiener,
editor, Advances in Cryptology - Proc.
Crypto 99, volume 1666 of Lecture Notes
in Computer Science, pages 519–536.
Springer-Verlag, 1999.
[7] D. Chaum.
mail,
return addresses,
Untraceable electronic
and digital
pseudonyms. Communications of the
ACM, 24(2):84–88, 1981.
of Lecture Notes in Computer Science,
pages 178–191. Springer-Verlag, 2000.
[19] C.-P. Schnorr and M. Jakobsson. Se-
curity of signed ElGamal encryption.
In ASIACRYPT, pages 73–89. Springer,
2000.
[20] Y. Tsiounis and M. Yung. On the
security of ElGamal-based encryption.
In Workshop on Practice and Theory
in Public Key Cryptography (PKC ’98).
Springer, 1998.
[8] Y. Desmedt and K. Kurosawa. How
to break a practical mix and design a
In B. Preneel, editor, EU-
new one.
ROCRYPT ’00, volume 1807 of Lecture
Notes in Computer Science, pages 557–
572. Springer-Verlag, 2000.
[9] Danny Dolev, Cynthia Dwork, and Moni
Naor. Non-malleable cryptography.
In
Proceedings 23rd ACM STOC, pages
542–552, 1991.
[10] J. Furukawa and K. Sako. An eﬃcient
scheme for proving a shuﬄe. In J. Kil-
ian, editor, CRYPTO ’01, volume 2139
of Lecture Notes in Computer Science,
pages 368–387. Springer-Verlag, 2001.
[11] M. Jakobsson. A practical mix.
In
K. Nyberg, editor, EUROCRYPT ’98,
volume 1403 of Lecture Notes in Com-
puter Science, pages 448–461. Springer-
Verlag, 1998.
[12] M. Jakobsson. Flash mixing. In PODC
’99, pages 83–89. ACM, 1999.
[13] M. Jakobsson and A. Juels. Millimix:
Mixing in small batches, June 1999. DI-
MACS Technical Report 99-33.
[14] M. Jakobsson and A. Juels. An optimally
In PODC
robust hybrid mix network.
’01, 2001.
[15] M. Mitomo and K. Kurosawa. Attack
for ﬂash MIX.
In T. Okamoto, editor,
ASIACRYPT ’00, volume 1976 of Lec-
ture Notes in Computer Science, pages
192–204. Springer-Verlag, 2000.
[16] A. Neﬀ. A veriﬁable secret shuﬄe and its
application to e-voting. In P. Samarati,
editor, ACM CCS ’01, pages 116–125.
ACM Press, 2001.
[17] W. Ogata, K. Kurosawa, K. Sako, and
K. Takatani. Fault tolerant anonymous
In Proc. ICICS ’97, volume
channel.
1334 of Lecture Notes in Computer Sci-
ence, pages 440–444, 1997.
[18] M. Ohkubo and M. Abe. A length-
invariant hybrid mix.
In T. Okamoto,
editor, ASIACRYPT ’00, volume 1976