# Taming Power Peaks in MapReduce Clusters

**Authors:**
- Nan Zhu
- Lei Rao
- Xue Liu
- Jie Liu
- Haibin Guan

**Affiliations:**
- **Nan Zhu** and **Haibin Guan**  
  Department of Computer Science, Shanghai Jiaotong University, Shanghai, China  
  Email: [PI:EMAIL]
- **Lei Rao** and **Xue Liu**  
  School of Computer Science, McGill University, Montreal, Canada  
  Email: [PI:EMAIL]
- **Jie Liu**  
  Microsoft Research, Microsoft Corp., Redmond, USA  
  Email: [PI:EMAIL]

**Abstract:**
With the increasing demand for cloud services, the energy consumption of Internet Data Centers (IDCs) has become a significant concern. A large portion of applications running on data centers are data-intensive, with MapReduce (and Hadoop) being one of the most widely deployed frameworks. While both academia and industry have focused on reducing energy consumption, the critical issue of power peaks in MapReduce clusters has been overlooked. This paper elaborates on the power peak problem, investigates its causes, and proposes an adaptive approach to regulate these peaks.

**Categories and Subject Descriptors:**
- H.m [Information Systems]: Miscellaneous
- D.0 [Software]: General

**General Terms:**
- Algorithms, Design, Performance

## 1. Motivation and Problem Statement

The energy consumption of IDCs is a crucial aspect of data center efficiency. Reports indicate that IDC operators face extremely high energy bills, and this trend is expected to continue or even intensify as computational needs grow. Both academic and industrial research have increasingly focused on energy management, particularly on regulating high power peaks. High power peaks require Power Distribution Units (PDUs) and other power infrastructure to be configured at high levels, significantly increasing capital costs for building and operating IDCs. Power capping techniques can help host additional machines and prevent overload situations. However, the use of MapReduce introduces new challenges for energy management. The scheduling of map and reduce tasks significantly affects the peak power in IDCs.

We observed this problem in Microsoft Production Servers, where the power consumption of servers running MapReduce does not remain stable, leading to temporary power peaks. Using the Hadoop official software, we replicated this phenomenon in a 200-node Hadoop cluster. The power consumption curve, starting at around 10 kilowatts, surges at certain intervals during the 210 virtual minutes it takes to complete the workload. Only about 8% of the time, the cluster operates near its peak power. Addressing these few intervals could allow for more machines within a given power budget or a lower power budget, improving energy efficiency. This paper systematically studies the causes of these temporary power peaks and proposes an adaptive approach to address them.

## 2. Analysis of Power Consumption and Scheduling

In this section, we analyze the power peak problem in a 200-node Hadoop cluster, where each node has 8 processing cores at 2.4 GHz. We use the workload trace file from Mumak provided by Yahoo! to demonstrate how the scheduling of map and reduce tasks affects power peaks. We trace the power consumption and the number of arrived tasks with a sampling frequency of 1 minute, as shown in Figure 2. The power consumption generally surges with the increase in the number of arrived tasks. At the 44th virtual minute, the power consumption decreases despite a surge in workload. This is because the system utilization was very high at the 42nd and 43rd minutes due to large jobs, and by the 44th minute, only small jobs remained, reducing system utilization. It is important to note that power consumption is linearly related to processor utilization (for a fixed processor frequency) and not directly to the workload arrival rate.

From these observations, we conclude that the default scheduling in Hadoop leads to poor system performance, with the cluster operating at high power during a few intervals and low power during most intervals. An even distribution of system utilization with lower peak power is desirable.

## 3. Design of the Adaptive Approach

Our adaptive approach consists of two main modules: model building and controller. The model building module dynamically estimates the input-output model of the Hadoop cluster, with the workload arrival rate as input and the power of each node as output. The controller module adjusts the input to regulate power peaks.

The architecture of the adaptive approach is shown in Figure 3. The power consumption model for each node \( i \) in the Hadoop cluster is given by:

\[ p_i(k) = A_i p_i(k-1) + B_i \Delta x_i(k), \]

where \( A_i \) and \( B_i \) are unknown system parameters that may vary with the workload, and \( \Delta x_i \) represents the change in the arrival rate threshold for node \( i \). At each time point, the model estimator calculates the system parameters using the recursive least square (RLS) estimator with exponential forgetting. The updated parameters are sent to the adaptive controller, which decides the workload arrival rate for each node based on the power budget.

To achieve power capping, we define the following cost function for each server \( i \):

\[ J_i(k) = \left( p_i(k+1) - p_{\text{cap},i}(k+1) \right)^2, \]

which minimizes the difference between the consumed power and the power cap value, ensuring power consumption remains close to the expected level.

## 4. References

1. Hadoop. http://hadoop.apache.org/.
2. J. Dean and S. Ghemawat. "MapReduce: Simplified Data Processing on Large Clusters." OSDI 04', pages 137â€“150, 2004.
3. X. Fan, W.-D. Weber, and L. A. Barroso. "Power Provisioning for a Warehouse-Sized Computer." In ISCA, 2007.
4. J. Koomey. "Worldwide Electricity Used in Data Centers." Environmental Research Letters, Sept. 2008.