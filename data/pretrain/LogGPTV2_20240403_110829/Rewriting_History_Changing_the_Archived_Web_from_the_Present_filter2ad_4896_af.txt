blocked archive-escape requests such as the one which allowed our
attack in Figure 1.
7.2.2 Modify/Analyze Javascript to Prevent Escapes. In this de-
fense, the archive would statically and dynamically analyze Javascript
code it captures in order to identify scripts might cause archive-
escapes. The archive would then rewrite or wrap these scripts,
replacing the original script with a version that performs the same
operations but avoids generating archive-escapes. For example,
such a defense might hook calls to browser APIs which generate
HTTP requests, interposing on them to rewrite URL arguments to
ensure they do not point outside the archive.
This solution is complex, and its implementation might involve
many engineering hours. Additionally, executing the defense on
each archived resource at time-of-archive might be computationally
expensive. However, if successful, this defense might permit the
Wayback Machine’s URL rewriting to be much more pervasive,
applying even to client-side dynamically generated URLs, the main
source of vulnerabilities that we identify in the archive today.
7.2.3
Serve Distinct Archived Domains from Distinct Subdomains.
Archives could defend against Same-Origin Escapes by serving
content from distinct subdomains, each of which corresponds to the
live domain from which that content was originally published. For
example, an archive might choose to serve captures of example.com/
script.js from the subdomain http://example.com.web.archive.org/
instead of from http://web.archive.org. Since the Same-Origin Policy
considers subdomains as distinct domains, this would cause client
browsers to provide the same isolation in the archival context as
they do in the live context, preserving the same trust model across
both live and archival executions of the page. We recommend that
archives consider implementing this defense.
7.3 Defenses Deployed by Clients
Finally, we discuss defenses deployed inside the client’s browser.
Individual clients can unilaterally deploy these defenses, giving
them high value today. For example, experts in legal cases might
use these defenses to provide more trustworthy testimony. These
defenses are limited by the fact that each client must separately
install the defense, but they do apply to all snapshots in the archive.
7.3.1 Browser Extensions to Block/Highlight Escapes and Anachro-
nisms. This defense interposes on and blocks Archive-Escape and
Anachronistic requests made for subresources while browsing the
archive. It prevents Archive-Escape Abuse by blocking all HTTP
requests from a snapshot which leave the archive. Since the distinc-
tion between archive-escapes and archival requests is cut and dry
(distinguishable by the destination domain of the request), such a
defense should be highly effective against Archive-Escape Abuse.
This defense protects against Anachronism Injection not by pre-
venting the payload from being stored in the archive (as does the
Actively Archive Subresources defense, above), but by blocking the
anachronistic request which delivers that payload to the client. It
does so by blocking anachronistic requests — those requests for
archival resources which have timestamps far from the timestamp
of the enclosing page. This involves an inherent tradeoff, in which
the defense or its user must define how anachronistic a resource
must be to be blocked. In the most extreme case, only resources
with timestamp exactly equal to the snapshot’s timestamp can be
loaded, leading to complete blocking of the vulnerability, but also
preventing many legitimate resources from being loaded, leading
to a less complete picture of the past web.
This defense can also (or instead) visibly highlight, log, or sum-
marize archive-escapes and anachronistic requests and the visible
page elements which correspond to them. Such a feature can help a
human expert to better judge the accuracy of a snapshot. Archive-
Watcher, described in more detail below (Section 7.4), is an example
of this type of defense.
7.4 ArchiveWatcher: An End-User Defense
We prototyped ArchiveWatcher, a client-deployed defense consist-
ing of a browser extension which detects and blocks archive-escape
request vulnerabilities. ArchiveWatcher is implemented as a light-
weight Chrome Extension which interposes on requests made for
resources while browsing snapshots https://web.archive.org/web.
It is written in 6000 lines of Javascript, CSS, and HTML, and its
souce code can be found on Github by following the links at https:
//rewritinghistory.cs.washington.edu.
Session H3:  Web SecurityCCS’17, October 30-November 3, 2017, Dallas, TX, USA1753As described above in Section 7.3.1, ArchiveWatcher blocks re-
quests for archive-escapes. It can display to the user a summary of
the requests it has detected and blocked on the current snapshot
and across the current browsing session. ArchiveWatcher suggests
directions for defenses which could aid technical experts assessing
the veracity of archival snapshots.
8 CONCLUSION
In this paper, we have explored the space of attacks which can
rewrite history — i.e., attacks that can manipulate how clients see
archived websites, focusing on the Wayback Machine. Though
it is known that the archive contains accidental inaccuracies, to
our knowledge, we are the first to explore how an attacker might
introduce intentional errors. We identified and explored several
vulnerabilities in how the Wayback Machine archives and serves
snapshots of websites, and we developed four attacks that leverage
these vulnerabilities. We demonstrated proof-of-concept attacks on
the Wayback Machine, showing that we were able to manipulate
client views of snapshots without compromising the archive’s or
any other servers. We then quantified the prevalence of these types
of vulnerabilities, finding that over 70% of the sites we investigated
are vulnerable to this type of manipulation by some attacker.
The web is important to our modern society, making web archives
a critical source of socially important information, from journalism
to legal proceedings. This work suggests the importance for website
publishers, archive designers, and end users to take steps to prevent
or detect intentional manipulation.
ACKNOWLEDGEMENTS
We thank Lucy Simko, Anna Kornfeld Simpson, and Eric Zeng
for their insightful comments and feedback on the paper; Emily
McReynolds for feedback, advice, and consultation on legal con-
cepts referenced in the paper; and Gaites Swanson for his help
discovering, parsing, and interpreting the legal URLs we studied.
We thank Mark Graham and his colleagues at Internet Archive
for their thoughtful and rapid response to our disclosure of this
work.
This work was supported in part by NSF Grant IIS-1302709, the
Short-Dooley Professorship, and the UW Tech Policy Lab.
REFERENCES
[1] 2012. Laboratory Corp. of America v. United States, 108 Fed.Cl. 549 (2012). (2012).
[2] 2012. People v. Franzen, 210 Cal.App.4th 1193 (2012). (2012).
[3] 2013. Ex Parte Serguei N. Mamedrzaev. 2013 WL 1558372. (2013).
[4] 2014. Tharpe v. Lawidjaja, 8 F.Supp.3d 743 (2014). (2014).
[5] 2016. The Euroeapn Patent Convention, Article 54: Novelty. https://www.epo.
org/law-practice/legal-texts/html/epc/2016/e/ar54.html. (2016). Accessed: 2017-
05-17.
[6] 2017.
Robots.txt meant for search engines don’t work well for web
https://blog.archive.org/2017/04/17/robots-txt-meant-for-search-
archives.
engines-dont-work-well-for-web-archives/. (4 2017). Accessed: 2017-05-19.
[7] 2017. Summary of s3.amazonaws.com. https://web.archive.org/web/*/http://s3.
amazonaws.com/alexa-static/top-1m.csv.zip. (2017). Accessed: 2017-05-05.
[8] 2017. Welcome to LexisNexis - Choose Your Path. https://www.lexisnexis.com/en-
us/gateway.page. (2017). Accessed: 2017-05-19.
[9] 2017. WestLaw.com. westlaw.com. (2017). Accessed: 2017-05-19.
[10] Ada Lerner, Anna Kornfeld Simpson, Tadayoshi Kohno, Franziska Roesner. 2016.
Internet Jones and the Raiders of the Lost Trackers: An Arcahaeological Study
of Web Tracking from 1996 to 2016. 25th USENIX Security Symposium (August
2016).
[11] Scott G. Ainsworth, Ahmed AlSum, Hany SalahEldeen, Michele C. Weigle, and
Michael L. Nelson. 2012. How Much of the Web Is Archived? arxiv.org (2012),
1–10. arXiv:1212.6177 http://arxiv.org/abs/1212.6177
[12] Scott G Ainsworth and Michael L Nelson. 2004. Only One Out of Five Archived
Web Pages Existed as Presented. ACM HT’15 (2004). http://public.lanl.gov/
herbertv/papers/Papers/2015/ht15-ainsworth-submission.pdf
[13] Scott G Ainsworth, Michael L Nelson, and Herbert Van de Sompel. 2015. Only
One Out of Five Archived Web Pages Existed as Presented. In Proceedings of the
26th ACM Conference on Hypertext & Social Media. ACM, 257–266.
[14] Internet Archive. 2017. Heritrix is the Internet Archive’s open-source, ex-
tensible, web-scale, archival-quality web crawler project. https://github.com/
internetarchive/heritrix3. (2017). Accessed: 2017-08-16.
[15] Internet Archive. 2017. IA’s public Wayback Machine (moved from SourceForge).
https://github.com/internetarchive/wayback. (2017). Accessed: 2017-08-16.
[16] Justin F. Brunelle. 2012. 2012-10-10: Zombies in the Archives. http://ws-dl.
blogspot.com/2012/10/2012-10-10-zombies-in-archives.html. (2012). Accessed:
2017-05-13.
[17] Justin F Brunelle, Mat Kelly, Hany Salaheldeen, Michele C Weigle, and Michael L
Nelson. 2015. Not All Mementos Are Created Equal : Measuring The Impact Of
Missing Resources Categories and Subject Descriptors. International Journal on
Digital Libraries (2015).
[18] International Internet Preservation Consortium. 2017. The OpenWayback De-
velopment http://www.netpreserve.org/openwayback. https://github.com/iipc/
openwayback. (2017). Accessed: 2017-08-16.
[19] Shawn E. Douglas. [n. d.]. Citing from a Digital Archive like the Internet
Archive: A Cheat Sheet. http://www.writediteach.com/images/Citing%20from%
20a%20Digital%20Archive%20like%20the%20Internet%20Archive.pdf. ([n. d.]). Ac-
cessed: 2017-05-08.
[20] Peter Eckersley. 2010. How unique is your web browser? Lecture Notes in
Computer Science (including subseries Lecture Notes in Artificial Intelligence and
Lecture Notes in Bioinformatics) 6205 LNCS (2010), 1–18. https://doi.org/10.1007/
978-3-642-14527-8_1
[21] Deborah R Eltgrowth. 2009. Best evidence and the Wayback Machine: toward
a workable authentication standard for archived Internet evidence. Fordham L.
Rev. 78 (2009), 181.
[22] Matthew Fagan. 2007. Can You Do a Wayback on That-The Legal Community’s
Use of Cached Web Pages in and out of Trial. BUJ Sci. & Tech. L. 13 (2007), 46.
[23] David Fifield and Serge Egelman. 2015. Fingerprinting web users through font
metrics. Lecture Notes in Computer Science (including subseries Lecture Notes in
Artificial Intelligence and Lecture Notes in Bioinformatics) 8975 (2015), 107–124.
https://doi.org/10.1007/978-3-662-47854-7_7
[24] Karén Gazaryan. 2013. Authenticity of Archived Websites: The Need to Lower
the Evidentiary Hurdle Is Imminent. Rutgers Computer & Tech. LJ 39 (2013), 216.
[25] Stephanie Hackett, Bambang Parmanto, and Xiaoming Zeng. 2003. Accessibility
of Internet websites through time. ACM SIGACCESS Accessibility and Computing
(2003), 32. https://doi.org/10.1145/1029014.1028638
[26] Internet Archive. 2017. Internet Archive: Digital Library of Free Books, Movies,
Music & Wayback Machine. https://archive.org/. (2017). Accessed: 2017-05-12.
[27] Internet Archive. 2017. Internet Archive Frequently Asked Questions. https:
//archive.org/about/faqs.php#23. (2017). Accessed: 2017-05-04.
[28] Internet Archive. 2017. Wayback Machine. https://web.archive.org. (2017). Ac-
cessed: 2017-05-11.
[29] Internet Memory Foundation. 2017.
Internet Memory Foundation.
http:
//internetmemory.org/en/. (2017). Accessed: 2017-08-16.
[30] Mat Kelly, Justin F. Brunelle, Michele C. Weigle, and Michael L. Nelson. 2013.
On the change in archivability of websites over time. Lecture Notes in Computer
Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes
in Bioinformatics) 8092 LNCS (2013), 35–47. https://doi.org/10.1007/978-3-642-
40501-3_5 arXiv:1307.8067
[31] Mat Kelly, Justin F. Brunelle, Michele C. Weigle, and Michael L. Nelson. 2013. On
the Change in Archivability of Websites Over Time. CoRR abs/1307.8067 (2013).
http://arxiv.org/abs/1307.8067
[32] Library of Congress. 2017. Archived Web Site | Library of Congress. https:
//www.loc.gov/websites/. (2017). Accessed: 2017-05-12.
[33] Keaton Mowery and Hovav Shacham. 2012. Pixel Perfect : Fingerprinting Canvas
in HTML5. Web 2.0 Security & Privacy 20 (W2SP) (2012), 1–12. https://cseweb.
ucsd.edu/
[34] Jamie Murphy, Noor Hazarina Hashim, and Peter O’Connor. 2007. Take Me Back:
Validating the Wayback Machine. Journal of Computer-Mediated Communication
13, 1 (2007), 60–75. https://doi.org/10.1111/j.1083-6101.2007.00386.x
[35] Nick Nikiforakis, Luca Invernizzi, Alexandros Kapravelos, Steven Van Acker,
Wouter Joosen, Christopher Kruegel, Frank Piessens, and Giovanni Vigna. 2012.
You are what you include: large-scale evaluation of remote javascript inclusions.
In Proceedings of the 2012 ACM conference on Computer and communications
security. ACM, 736–747.
[36] Nick Nikiforakis, Alexandros Kapravelos, Wouter Joosen, Christopher Kruegel,
Frank Piessens, and Giovanni Vigna. 2013. Cookieless monster: Exploring the
ecosystem of web-based device fingerprinting. Proceedings - IEEE Symposium on
Security and Privacy (2013), 541–555. https://doi.org/10.1109/SP.2013.43
Session H3:  Web SecurityCCS’17, October 30-November 3, 2017, Dallas, TX, USA1754[37] US Department of Homeland Security. 2016. Homeland Security. http://
webarchive.loc.gov/all/20160205185026/https://www.dhs.gov/. (2016). Accessed:
2017-08-16.
[38] Mary Emily Ohara. 2017. Trump Administration Removes LGBTQ Content
From Federal Websites.
https://web.archive.org/web/20170324052626/http:
//www.nbcnews.com/feature/nbc-out/trump-administration-removes-lgbtq-
content-federal-websites-n711416. (2017). Accessed: 2017-03-27.
[39] OpenGovData Russia Archive. 2017. Arhivacija gosudarstva (konservirovan-
noe gosudarstvo) | Otkrytye dannye v Rossii. http://opengovdata.ru/projects/
govarchive/. (2017). Accessed: 2017-08-16.
[40] James L Quarles III and Richard A Crudo. 2014. Using the Wayback Machine in
[41] Achintya Rao. 2017.
Patent Litigation. Landslide Magazine 6, 3 (Jan/Feb 2014).
https://medium.com/@RaoOfPhysics/using-the-internet-archive-to-cite-
websites-89bd3f2ce0fd. (2017). Accessed: 2017-05-08.
Using the Internet Archive to cite websites.
[42] Franziska Roesner, Tadayoshi Kohno, and David Wetherall. 2012. Detecting
and defending against third-party tracking on the web. Proc. of the USENIX
Conference on Networked Systems Design and Implementation (NSDI) (2012), 12.
[43] Ryan North. 2016. Dinosaur Comics - February 3rd, 2016 - awesome fun
times! http://webarchive.loc.gov/all/20160203203159/http://www.qwantz.com/
index.php. (2016). Accessed: 2017-08-16.
[44] Myriam Ben Saad and Stéphane Gançarski. 2011. Improving the quality of web
archives through the importance of changes. Lecture Notes in Computer Science
(including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in
Bioinformatics) 6860 LNCS, PART 1 (2011), 394–409. https://doi.org/10.1007/978-
3-642-23088-2_29
[45] Kyle Soska and Nicolas Christin. 2014. Automatically Detecting Vulnerable Web-
sites Before They Turn Malicious. 23rd USENIX Security Symposium (USENIX Se-
curity 14) (2014), 625–640. https://www.usenix.org/conference/usenixsecurity14/
technical-sessions/presentation/soska
[46] Stanford Libraries. 2017. Web Archiving | Stanford Libraries. http://library.
stanford.edu/projects/web-archiving. (2017). Accessed: 2017-08-16.
[47] Wikipedia. 2017. List of Web archiving initiatives. https://en.wikipedia.org/wiki/
http://www.franziroesner.com/pdf/webtracking-NSDI2012.pdf
List_of_Web_archiving_initiatives. (2017). Accessed: 2017-08-16.
Session H3:  Web SecurityCCS’17, October 30-November 3, 2017, Dallas, TX, USA1755