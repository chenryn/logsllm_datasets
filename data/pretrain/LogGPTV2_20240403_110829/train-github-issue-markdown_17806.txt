### Issue Summary

Recently, I deployed Celery Beat to production, which had been running smoothly with Celery without Beat for several months. The task was scheduled to run multiple times daily. However, after the deployment, the task started duplicating at a high frequency (multiple times per second), leading to an **Out of Memory (OOM) error** and overwhelming my small ElastiCache instance.

### Environment Details
- **Celery Version:** 4.0.0
- **Python Version:** 3.5.2
- **Other Dependencies:**
  - Kombu: 4.0.0
  - Billiard: 3.5.0.2
  - Redis: 2.10.5

### Configuration
- **Platform:**
  - System: Linux
  - Architecture: 64-bit
  - Implementation: CPython
- **Loader:**
  - `celery.loaders.app.AppLoader`
- **Settings:**
  - Transport: Redis
  - Results Backend: `redis://[elasticache]`
  - Result Persistent: False
  - Enable UTC: False
  - Timezone: 'America/New_York'
  - Broker URL: `[elasticache]`
  - Task Serializer: 'json'
  - Result Serializer: 'json'
  - Include: [tasks -- redacted]
  - Task Create Missing Queues: True
  - Task Acks Late: False
  - Crontab: Not specified
  - Broker Transport Options: `{ 'visibility_timeout': 600 }`
  - Task Time Limit: 200
  - Task Always Eager: False
  - Task Queues:
    - `default`
    - `media.render`
    - `media.emails`
    - `media.other`
  - Beat Schedule: 
    - `'lookup-emails-to-send'`:
      - Args: []
      - Schedule: `crontab()`
      - Task: `send_emails`
  - Accept Content: ['json']
  - Task Default Exchange Type: 'direct'
  - Task Routes: `('worker.routes.AppRouter',)`
  - Worker Prefetch Multiplier: 1
  - BROKER_URL: `[elasticache]`

### Problem Description

After deploying Celery Beat, the task `send_emails` was scheduled to run multiple times daily. However, it began to duplicate the task at a very high rate, causing an OOM error and overwhelming the ElastiCache instance.

### Error Message

```plaintext
Traceback (most recent call last):
  File "python3.5/site-packages/celery/beat.py", line 299, in apply_async
    **entry.options)
  File "python3.5/site-packages/celery/app/task.py", line 536, in apply_async
    **options
  File "python3.5/site-packages/celery/app/base.py", line 717, in send_task
    amqp.send_task_message(P, name, message, **options)
  File "python3.5/site-packages/celery/app/amqp.py", line 554, in send_task_message
    **properties
  File "python3.5/site-packages/kombu/messaging.py", line 178, in publish
    exchange_name, declare,
  File "python3.5/site-packages/kombu/connection.py", line 527, in _ensured
    errback and errback(exc, 0)
  File "python3.5/contextlib.py", line 77, in __exit__
    self.gen.throw(type, value, traceback)
  File "python3.5/site-packages/kombu/connection.py", line 419, in _reraise_as_library_errors
    sys.exc_info()[2])
  File "python3.5/site-packages/vine/five.py", line 175, in reraise
    raise value.with_traceback(tb)
  File "python3.5/site-packages/kombu/connection.py", line 414, in _reraise_as_library_errors
    yield
  File "python3.5/site-packages/kombu/connection.py", line 494, in _ensured
    return fun(*args, **kwargs)
  File "python3.5/site-packages/kombu/messaging.py", line 200, in _publish
    mandatory=mandatory, immediate=immediate,
  File "python3.5/site-packages/kombu/transport/virtual/base.py", line 608, in basic_publish
    return self._put(routing_key, message, **kwargs)
  File "python3.5/site-packages/kombu/transport/redis.py", line 766, in _put
    client.lpush(self._q_for_pri(queue, pri), dumps(message))
  File "python3.5/site-packages/redis/client.py", line 1227, in lpush
    return self.execute_command('LPUSH', name, *values)
  File "python3.5/site-packages/redis/client.py", line 573, in execute_command
    return self.parse_response(connection, command_name, **options)
  File "python3.5/site-packages/redis/client.py", line 585, in parse_response
    response = connection.read_response()
  File "python3.5/site-packages/redis/connection.py", line 582, in read_response
    raise response
kombu.exceptions.OperationalError: OOM command not allowed when used memory > 'maxmemory'.
```

### Log Example

The log shows the rapid duplication of the `send_emails` task:

```plaintext
[2017-05-20 09:00:00,096: INFO/PoolWorker-1] Task send_emails[1d24250f-c254-4fd8-8ffc-cfb17b98a392] succeeded in 0.01704882364720106s: True
[2017-05-20 09:00:00,098: INFO/MainProcess] Received task: send_emails[e968cc65-0924-4d31-b2d7-9a3e3f5aefda]
[2017-05-20 09:00:00,115: INFO/PoolWorker-1] Task send_emails[e968cc65-0823-4d31-b2d7-9a3e3f5aefda] succeeded in 0.015948095358908176s: True
[2017-05-20 09:00:00,117: INFO/MainProcess] Received task: send_emails[2fb9f7ac-5f6a-42e1-813e-25ea4023dc81]
[2017-05-20 09:00:00,136: INFO/PoolWorker-1] Task send_emails[2fb9f7ac-5f6a-42e1-813e-25ea4023dc81] succeeded in 0.018534105271100998s: True
[2017-05-20 09:00:00,140: INFO/MainProcess] Received task: send_emails[59493c0b-1858-497f-a0dc-a4c8e4ba3a63]
[2017-05-20 09:00:00,161: INFO/PoolWorker-1] Task send_emails[59493c0b-1858-497f-a0dc-a4c8e4ba3a63] succeeded in 0.020539570599794388s: True
[2017-05-20 09:00:00,164: INFO/MainProcess] Received task: send_emails[3aac612f-75dd-4530-9b55-1e288bec8db4]
[2017-05-20 09:00:00,205: INFO/PoolWorker-1] Task send_emails[3aac612f-75dd-4530-9b55-1e288bec8db4] succeeded in 0.04063933063298464s: True
[2017-05-20 09:00:00,208: INFO/MainProcess] Received task: send_emails[7edf60cb-d1c4-4ae5-af10-03414da672fa]
```

### Resolution

I found a similar issue online and decided to change the timezone settings back to the default. Previously, the configuration was:

```python
enable_utc = False
timezone = 'America/New_York'
```

I changed these settings to:

```python
enable_utc = True
```

This change seemed to resolve the issue temporarily.