pared to correct run, as the control flow diverges com(cid:173)
pletely to some part of the application with much fewer
number of checks. In the other two cases, the correct run
also has very few invariant checks as the faulty runs.
• In two cases (in mcf,gzip) there are no mismatches of the
monitored values inside the 10M window. iSWAT can't
detect them as there are no checks after 10M window.
• In most cases, control flow does not diverge significantly
- it diverges for a short period and then merges back.
• Irrespective of whether fault injection is in higher or
lower order bits, almost all the value mismatches in SDC
cases were in lower order bits. So, simple range-based
or control-flow invariants are unlikely to be effective for
these cases. In fact, most of the value mismatches were in
lowest 3 bits. We will need other types of invariants/de(cid:173)
tectors for detecting mismatches in lower order bits.
5.4 Latency
Table 7 shows latency results for the faults detected by the
SWAT and the iSWAT systems, binned into various cate(cid:173)
gories from under 1k instructions to under 10M instructions.
In order to perform a fair comparison, the numbers are pre(cid:173)
sented as a percentage of the total number of faults detected
by iSWAT (i.e. the number of detection in the <10M case).
The number of faults detected at a latency of under 1k
instructions shows the largest increase of about 2% (the rest
of the numbers are cumulative). This shows that the latency
of detection of invariants is significantly lower than that of
the other symptoms. This increases the number of faults
that are amenable to simple hardware recovery. Although
the latency benefits offered by iSWAT are not substantial
1-4244-2398-9/08/$20.00 ©2008 IEEE
77
DSN 2008: Sahoo et al.
International Conference on Dependable Systems &Networks: Anchorage, Alaska, June 24-27 2008
Latencies
SWAT
iSWAT
<5k
<lOOk
<lk
41.1% 47.0% 50.7% 78.7% 81.0%
43.1% 49.6% 53.4% 81.2% 83.3%
<10k
<50k
<500k
<1M <5M <10M
87.0% 90.3% 95.7%
98.7%
89.2% 92.7% 97.7% 100.0%
Table 7. Detection latencies for SWAT and iSWAT. The percentages are computed usWg number of detections in iSWAT with <10M
as baseline. The invariants increase the faults amenable to hardware recovery by 2%.
~~
;
~25%
~i 20%
~
~
;:15%
~ 10%
)5%
~
0%
• Spare
--------------1llI-x86-------
art
bzlp2
gzip
mct
parser Geometric
~~~~~~~~~~~~~~~~~~_~~~~_
Figure 3. Overhead of invariants on an UltraSPARC-Illi
(spare) machine and an AMD Athlon machine (x86).
so far, using more sophisticated invariants may improve the
effectiveness of iSWAT to reduce the latency.
5.5 Overhead
We evaluate the overhead of using invariants by running
the binary (with invariants checking) on fault-free hardware,
using two machines: Sun UltraSPARC-Illi 1.2GHz machine
with 1MB unified L2, and 2GB RAM, and on an AMD
Athlon(TM) dual-core MP 2100+ machine with 256KB L2
and 1.5GB RAM. The Sun machine is referred to as Spare
machine, and the AMD one as x86 machine in this section.
Figure 3 shows the overhead of using invariants checking
in the programs as a percentage over the baseline program
which has no invariants checking. The geometric mean of
the overheads is also shown for the two machines.
The sparc machine exhibits a higher overhead when run(cid:173)
ning the invariants code than the x86 machine, with the aver(cid:173)
age overheads being 14% and 5% respectively. In particular,
the overhead for the application mcf is significantly higher
in the Sparc machine (26%) than the x86 machine (2%). The
high overhead of the Sparc machine is likely due to its in(cid:173)
ability to hide the cache misses and branch mispredictions
induced by these extra invariants. The x86 machine is able
to hide these latencies better, resulting in lower overheads.
In spite of these differences, the overheads produced by
these invariants checks are within acceptable overheads for
the increased coverage that they provide, motivating the
iSWAT system for increased resilience.
Related Work
6.
There is a growing body of work on using software-visible
symptoms to detect hardware errors. A number of papers
propose the use of control path signatures to detect control(cid:173)
flow errors [1, 5, 21, 29, 30]. Wang and Patel propose us(cid:173)
ing branch mispredictions, cache misses, and exceptions as
symptoms of faults [32]. Most of this work focuses on tran-
.
Slent faults or intermittent faults, and does not handle perma-
nent faults (the exceptions are discussed below). Permanent
faults are important because of the expected increase in phe-
nomena such as wear-out, insufficient bum-in, and design
d -c
. n our previous work [9], we used simple soft-
elects
ware symptoms to detect both permanent as well as transient
faults and we extend that system in this paper.
[2] I
Dynamically detected program invariants (likely invari-
ants [4]), which are inherently unsound, have been studied
furaw~ernn~~~a~~~~~~clud~gprogrnm~~
lution [4], program understanding [7, 4], and detecting and
diagnosing software bugs [4, 6, 12, 33, 13]. The only work
we know of that uses likely invariants for online error de(cid:173)
tection comprises three recent papers on transient hardware
fault detection [22, 24, 3]. Racunas et al. and Dimitrov et
al. extract the invariants using online hardware monitoring
whereas Pattabiraman et al. use ahead-of-time monitoring of
program runs (similar to our work). In all the cases, how(cid:173)
ever, they can only use their invariants for transient errors
because they do not have any mechanism to distinguish false
positives from true hardware failures. (Racunas et al. and
Dimitrov et al. flush the pipeline, Pattabiraman et al. do not
suggest any concrete solution for false positives.) In contrast,
we can handle both transient and permanent faults.
Meixner et al. in the Argus project have proposed the
use of a program dataflow checker, combined with control
flow signature checking, functional unit checkers, a memory
checker and parity on all data transfer and storage units to
handle a wide range of faults [16, 17]. Their dataflow graph
and control flow signatures conceptually are invariants that
are encoded by the compiler in the binary and checked by
the hardware. Unfortunately, the technique does not work
with interrupts, I/O, etc. because these affect the control
flow. Some parts of the Argus solution may also incur in(cid:173)
ordinate performance overhead. Coverage data is reported
only for a synthetic microbenchmark, thus the effectiveness
of the technique for real programs is not clear [16]. Finally,
the estimated area overhead is 17% of the core for Argus
- a fault in this part could lead to false positives. In con(cid:173)
trast, we look at far cheaper detection techniques, combin(cid:173)
ing software-extracted invariants with several other software
symptoms that can be observed at near-zero cost.
7. Conclusion and Future Work
Previously existing methods for detecting hardware faults
using software-level symptoms, such as SWAT [9], are very
promising because of their high coverage and low cost. Nev(cid:173)
ertheless, these systems need additional detectors for achiev-
1-4244-2398-9/08/$20.00 ©2008 IEEE
78
DSN 2008: Sahoo et al.
International Conference on Dependable Systems &Networks: Anchorage, Alaska, June 24-27 2008
ing reliability levels that would be acceptable for most sys(cid:173)
tems. In this work, we proposed and evaluated the first de(cid:173)
sign (we know of) that uses likely program invariants for
detecting permanent faults. We used simple range-based
invariants on single variable values, in conjunction with
low-overhead symptom-based detection techniques already
available in the SWAT System. Our results show that likely
invariants can reduce the fraction of undetected errors from
4% to 2.8%, when used in conjunction with other symptom(cid:173)
based detection techniques. Further, they reduce SDCs by
47% to 74.2%, which is important for any hardware fault
tolerance solution. We further showed that by leveraging the
diagnosis framework in SWAT, we could keep the overhead
caused by false positives to acceptable levels.
These range-based invariants form a first step towards us(cid:173)
ing invariants to detect hardware faults. We are now inves(cid:173)
tigating more sophisticated invariant schemes to further im(cid:173)
prove the effectiveness of the iSWAT system. We also want
to monitor other program values and to design a strategy
to select the most effective values for monitoring to reduce
overhead. We would also like to evaluate the approach on
more benchmarks and real applications.
Acknowledgments
We would like to thank Robert Bocchino for many discus(cid:173)
sions and help in writing.
References
[1] E. Borin, C. Wang, Y. Wu, and G. Araujo. Dynamic binary
control-flow errors detection. SIGARCH Comput. Archit.
News, 33(5), 2005.
[2] S. Borkar. Designing Reliable Systems from Unreliable
Components: The Challenges of Transistor Variability and
Degradation. IEEE Micro, 25(6), 2005.
[3] M. Dimitrov and H. Zhou. Unified architectural support for
soft-error protection or software bug detection. In Proc. Int'l
Conf on Parallel Architectures and Compilation Techniques
(PACT),2007.
[4] M. D. Ernst, J. Cockrell, W. G. Griswold, and D. Notkin.
Dynamically discovering likely program invariants to support
program evolution. IEEE Trans. Software Eng., 2001.
[5] O. Goloubeva et aI. Soft-Error Detection Using Control Flow
Assertions. In Proc. of18th IEEE Inti. Symp. on Defect and
Fault Tolerance in VLSI Systems, 2003.
[6] S. Hangal and M. S. Lam. Tracking down software bugs
In Proceedings of the
using automatic anomaly detection.
International Conference on Software Engineering, 2002.
[7] Y. Kataoka, M. D. Ernst, W. G. Griswold, and D. Notkin.
Automated support for program refactoring using invariants.
In IEEE Int'l Conf on Software Maintenance (ICSM), 2001.
[8] C. Lattner and V. Adve. LLVM: A Compilation Framework
for Lifelong Program Analysis and Transformation. In Proc.
Int'l Symp. on Code Generation and Optimization, 2004.
[9] M. Li, P. Ramachandran, S. Sahoo, S. Adve, V. Adve, and
Y. Zhou. Understanding the Propagation of Hard Errors to
Software and Implications for Resilient System Design.
In
Proc. Inti. Con! on Architectural Support for Programming
Languages and Operating Systems(ASPL OS), 2008.
[10] M. Li, P. Ramachandran, S. K. Sahoo, S. V. Adve, V. S. Adve,
and Y. Zhou. Trace Based Diagnosis of Permanent Hardware
Faults. In International Conference on Dependable Systems
and Networks, 2008.
[11] B. Liblit, A. Aiken, A. X. Zheng, and M. I. Jordan. Bug
isolation via remote program sampling. In Proc. ofConf on
Programming Language Design and Implementation, 2003.
[12] B. Liblit, M. Naik, A. X. Zheng, A. Aiken, and M. I. Jordan.
Scalable statistical bug isolation.
Programming Language Design and Implementation, 2005.
In Proc. of Conf. on
[13] S. Lu, J. Tucek, F. Qin, and Y. Zhou. Avio: detecting atomicity
In Proc. Int'I
violations via access interleaving invariants.
Con! on Architectural Support for Programming Languages
and Operating Systems (ASPLOS), 2006.
[14] M. Martin et al. Multifacet's General Execution-Driven
SIGARCH
Multiprocessor Simulator (GEMS) Toolset.
Computer Architecture News, 33(4), 2005.
[15] C. J. Mauer, M. D. Hill, and D. A. Wood. Full-System Timing(cid:173)
First Simulation. SIGMETRICS Performance Evaluation Rev.,
30(1), 2002.
[16] A. Meixner, M. E. Bauer, and D. J. Sorin. Argus: Low(cid:173)
cost, comprehensive error detection in simple cores. In Proc.
ACM/IEEE Int'l Symposium on Microarchitecture, 2007.
[17] A. Meixner and D. J. Sorin. Error detection using dynamic
dataflow verification.
In Proc. Int'l Conf. on Parallel
Architectures and Compilation Techniques (PA CT), 2007.
[18] 1. Nakano et al. ReViveI/O: Efficient Handling of I/O in
Highly-Available Rollback-Recovery Servers. In Int'l Symp.
on High Performance Computer Architecture (HPCA), 2006.
[19] N. Nakka et al. An Architectural Framework for Detecting
Process Hangs/Crashes. In European Dependable Computing
Conference (EDCC), 2005.
[20] J. W. Nimmer and M. D. Ernst. Automatic generation of
program specifications. In Proc. ACM SIGSOFT Int'l Symp.
on Software Testing and Analysis, 2002.
[21] N. Oh, P. P. Shirvani, and E. J. McCluskey. Control-flow
checking by software signatures. IEEE Trans. on Reliability,
51, March 2002.
[22] K. Pattabiraman, G. P. Saggesse, D. Chen, Z. KaIbarczyk,
and R. Iyer. Dynamic derivation of application-specific error
detectors and their hardware implementation.
In Proc. of
European Dependable Computing Conference (EDCC), 2006.
[23] M. Prvulovic et al. ReVive: Cost-Effective Architectural
Support for Rollback Recovery in Shared-Memory Multipro(cid:173)
cessors.
In Int'l Symp. on Computer Architecture (ISCA) ,
2002.
[24] P. Racunas et al. Perturbation-based Fault Screening.
In
International Symposium on High Performance Computer
Architecture (HPCA), 2007.
[25] V. Reddy et al. Assertion-Based Microarchitecture Design
for Improved Fault Tolerance. In International Conference on
Computer Design, 2006.
[26] G. A. Reis et al. Software-Controlled Fault Tolerance. ACM
Transactions on Architectural Code Optimization, 2(4), 2005.
[27] E. Rotenberg. AR-SMT: A Microarchitectural Approach
In International
to Fault Tolerance in Microprocessors.
Symposium on Fault-Tolerant Computing (FTCS), 1999.
[28] D. Sorin et al. SafetyNet: Improving the Availability of Shared
Memory Multiprocessors with Global Checkpoint/Recovery.
In Int 'I Symp. on Computer Architecture (ISCA), 2002.
[29] R. Vemu and 1. A. Abraham. CEDA: Control-flow Error De(cid:173)
tection through Assertions. In Inti. On-Line Test Symposium,
2006.
[30] R. Venkatasubramanian et al. Low-Cost On-Line Fault
Detection Using Control Flow Assertions.
On-Line Test Symposium, 2003.
In International
[31] Virtutech. Simics Full System Simulator. Website, 2006.
http://www.simics.net.
[32] N. Wang and S. Patel. ReStore: Symptom-Based Soft
Error Detection in Microprocessors. IEEE Transactions on
Dependable and Secure Computing, 3(3), July-Sept 2006.
[33] P. Zhou, W. Liu, F. Long, S. Lu, F. Qin, Y. Zhou, S. Midkiff,
and J. Torrellas. Accmon: Automatically detecting memory(cid:173)
related bugs via program counter-based invariants. In Proc.
ACM/IEEE Int'l Symposium on Microarchitecture, 2004.
1-4244-2398-9/08/$20.00 ©2008 IEEE
79
DSN 2008: Sahoo et al.