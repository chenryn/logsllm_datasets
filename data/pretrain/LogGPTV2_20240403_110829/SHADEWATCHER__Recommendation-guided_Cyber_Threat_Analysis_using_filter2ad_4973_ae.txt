entities from an entity space to relation spaces. Fortunately,
as the projection (i.e., matrix multiplication) can be largely
parallelized by modern GPUs, it is no longer expensive to
compute. Our experiment shows that TransR is only 1.4X/1.1X
slower than TransE/TransH.
Another interesting observation is that without high-order
information from GNN, SHADEWATCHER consistently per-
forms the worst across all possible thresholds. However, by
enabling GNN, SHADEWATCHER achieves high AUC values
ranging from 0.966 to 0.996. One possible reason is that high-
order connectivity in a KG is critical for interpreting system
entity relationships, hence illustrating the signiﬁcance of high-
order information in audit records for cyber threat analysis.
SHADEWATCHER vs. State-of-the-Art. Elsewhere in the
literature, the TRACE dataset has also been used to evaluate
intrusion detection systems (i.e., Poirot [19] and Morse [17]),
but SHADEWATCHER is fundamentally distinct from them in
terms of detection goals and techniques. Especially, SHADE-
WATCHER performs anomaly-based, not speciﬁcation-based,
detection, requiring no a priori knowledge of attacks. How-
ever, it is worth mentioning that SHADEWATCHER achieves
comparable detection effectiveness to speciﬁcation-based de-
tectors by successfully detecting all four APT attacks on the
TRACE dataset. We further discuss cyber threats that different
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 13:13:26 UTC from IEEE Xplore.  Restrictions apply. 
498
051015202530Epoch0102030405060LossLoss-EpochAUC-Epoch0.60.70.80.91.0AUC0.00.20.40.60.81.0False Positive Rate0.00.20.40.60.81.0True Positive RateTransR(AUC: 0.763)Onehot+GNN(AUC: 0.966)TransE+GNN(AUC: 0.971)TransH+GNN(AUC: 0.974)TransR+GNN(AUC: 0.996)detection systems might miss. False negatives produced by
speciﬁcation-based detection are primarily attributed to zero-
day attacks. For example, Poirot inevitably misses APT attacks
not yet described in existing CTI reports. On the other hand,
SHADEWATCHER experiences false negatives if a threat actor
intentionally steers malicious activities towards the learned
recommendation model to evade detection. We provide details
of evasion attacks on SHADEWATCHER in § IX.
Unicorn [21] is another anomaly detector that identiﬁes
cyber threats without domain expertise. Unfortunately,
the
coarse granularity of its detection signals prevents responding
to threats timely. To illustrate, suppose Unicorn conﬁgures the
size of graph sketches as 2,000 in [21]. An analyst then has
to review 2,000 audit records to investigate a single attack
indicator. On the contrary, SHADEWATCHER explores the po-
tential of performing ﬁner-grained detection on system entity
interactions, which directly signify adversarial intentions.
D. Model Adaptability
By adapting to analyst feedback on false alarms, SHADE-
WATCHER supports dynamic updates to its recommendation
model. We evaluate the ability of SHADEWATCHER’s adaption
to reduce false positives on normal workloads in the Simulated
dataset. For the case of model adaption, we assume that an an-
alyst continuously reports false-positive interactions to update
SHADEWATCHER. To compare false-positive rates (FPR) with
and without model adaption, we evaluate SHADEWATCHER on
three different training sets: (A) the ﬁrst 80% interactions; (B)
the ﬁrst 80% interactions with false positives in the subsequent
10% interactions; (C) the ﬁrst 90% interactions. For a fair
comparison, we consistently extract the last 10% interactions
as the testing set. The sequence of interactions is determined
by their occurrence timestamps in audit records.
By training on the ﬁrst 80% interactions to predict cyber
threats in the subsequent 10% interactions, SHADEWATCHER
reports 263 false positives and 285,508 true negatives. As such,
compared to (A), both (B) and (C) can be viewed as integrating
additional manual feedback on 263 false alarms. The only dif-
ference is that (C) includes extra 285,508 true-negative interac-
tions. Observe that in Table V, SHADEWATCHER reduces 118
false positives by incorporating analyst feedback. Increasing
the training data from 80% to 90% can further remove 37 false
alarms. This makes sense as our model adaption only takes
false-positive interactions as additional supervision, and thus it
inevitably loses the semantics of true-negative interactions that
may also be beneﬁcial for interpreting unknown interactions.
TABLE V: False positive reduction with model adaption.
Training Feedback
80%
80%
90%
0
263
263
#FP
392
274
237
#TN
285,340
285,458
285,495
FPR
0.137%
0.096%
0.083%
E. Efﬁciency
We measure the runtime overhead of SHADEWATCHER
at different phases, including data processing, training, and
(a)
(c)
(b)
(d)
Fig. 7: System performance for provenance graph construc-
tion: (a) (c) (d) show the throughput, CPU utilization and
memory overhead under different numbers of threads. (b)
shows the throughput under 56 threads with different sizes
of audit record batches. Note that our experimental machine
supports at most 56 threads running in parallel.
is,
testing phases. All experiments are performed ﬁve times on the
TRACE dataset, and we report the mean results in Table VI.
Data processing. Data processing aims to parse audit records
into a knowledge graph (KG). The overhead mainly comes
from provenance graph (PG) construction, noise reduction,
and interaction extraction. In total, it takes 100.37 minutes to
process the TRACE dataset with 635GB worth of audit data.
To improve system efﬁciency, we leverage multiple threads
to construct a PG in parallel. Compared with the single-
thread (na¨ıve) prototype, the multi-thread design accomplishes
an 8X speedup. That
it saves over ﬁve hours on just
data processing. To further explore its scalability, we mea-
sure the throughput, CPU utilization, and memory overhead
with different conﬁguration values of thread numbers and
record batch sizes. Figure 7a shows that SHADEWATCHER
processes up to 300 audit records per millisecond with 56
threads. Especially if an end host generates 400k records
per day [14], we estimate that SHADEWATCHER is capable
of scaling the PG construction to upwards of 65,000 hosts.
increases along
In general, SHADEWATCHER’s throughput
with the thread number. However,
it will reach an upper
bound due to the limitation of disk I/O performance. Observe
that in Figure 7b, it is ﬂexible in choosing sizes of audit
record batches while not heavily affecting system efﬁciency.
Figure 7c and Figure 7d further illustrate that CPU utilization
increases along with increasing thread number, while memory
overhead the opposite. This is within our expectation as most
memory overhead comes from record batches stored in the
record queue, and more threads can consume batches faster,
leading to fewer batches maintained in the memory.
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 13:13:26 UTC from IEEE Xplore.  Restrictions apply. 
499
Number of threadsThroughput Records/msSize of record batchThroughput Records/msNumberofthreadsCPU Utilization (*100%)NumberofthreadsMemory Overhead (%)Training. We evaluate the training overhead by measuring
how long SHADEWATCHER takes to obtain a recommendation
model that yields the best accuracy on the validation set.
Because most training computations (i.e., matrix operations)
can be accelerated by GPU parallel computation, we apply a
high-performance GPU to train our model. On average, it takes
2,103 seconds and 1,106 seconds per epoch to train the TransR
and GNN modules, respectively. The fully-trained model is
then saved to disk so that SHADEWATCHER does not need to
be retrained from scratch with new incoming training samples.
Note that we train the model on a single GPU. The training
time can be further reduced by parallelizing SHADEWATCHER
on multiple GPUs [72].
Testing. The testing phase refers to the duration from inputting
system entity interactions to predicting cyber threats via the
recommendation model from the training phase. On average,
it takes 8.16 seconds to predict 792,333 interactions (68,097
malicious and 724,236 benign interactions). So far, we have
conducted all experiments on GPUs, but GPUs may not be
available in most real-life threat detection scenarios. Therefore,
we further evaluate SHADEWATCHER’s efﬁciency on CPUs by
performing detection on the same server with GPU disabled.
Although the testing time increases to 220 seconds, we believe
the efﬁciency is still promising as the scale of the dataset is
comparable to two months of user daily data.
TABLE VI: Runtime overhead on the TRACE dataset.
Phase
Component
Mean
Std Dev
Data
Processing
PG Construction (Na¨ıve)
PG Construction (Parallel)
Noise Reduction
Interaction Extraction
Training
Testing
System Entity Embedding
Graph Neural Network
Cyber Threat Detection
F. Case Study
5.97 Hours
40.47 Min.
55.77 Min.
4.13 Min.
12.27 Hours
6.45 Hours
8.16 Sec.
N/A
0.21
0.09
0.01
N/A
0.93
We demonstrate how SHADEWATCHER uses recommenda-
tions to guide cyber threat analysis by two APT attacks: Ex-
tension Backdoor and Firefox Backdoor. Extension Backdoor
is the attack from which the motivating example is derived.
We leave the description of Firefox Backdoor in Appendix F.
Extension Backdoor generates a total of 995 system entity
interactions, 732 of which are manually labeled as threats. We
would like to point out that the interaction between gtcache
and /etc/passwd is treated as a benign activity. This is because
/etc/passwd serves as public information on a system, which
is regularly read by a variety of daily programs, such as bash,
ssh, and even cat. Accordingly, access to /etc/passwd locally
does not necessarily bring risks.
As shown in Figure 8, SHADEWATCHER predicts the prob-
abilities of being adversarial for individual system entity in-
teractions. The solid (green) edges denote ground-truth benign
interactions, while the dashed (red) edges represent malicious
interactions. We notice that of 263 benign interactions, most
(230) come from process status retrievals (i.e., interactions
with /proc/pid/stat), while of 732 malicious interactions, most
(721) come from port scans for internal reconnaissance (i.e.,
Fig. 8: Recommendations on the Extension Backdoor.
three false positives (e.g.,
interactions with 128.55.12.73). Experimental results show
that SHADEWATCHER accurately identiﬁes all benign ac-
tivities except
interactions with
/proc/24(29,1896)/stat) and warns of all malicious activities
except three false negatives (i.e., interactions with /tmp/ztmp,
146.153.68.151:80, and 162.66.239.75:80). More importantly,
benign and malicious interactions are well-separated with
considerable margins. Case in point, all benign interactions
are predicted with low probabilities (below −1.0) of be-
ing cyber threats, while the malicious ones are given high
probabilities (beyond 0.4). Similar phenomena can also be
found in other attack scenarios. Therefore, we hypothesize
that SHADEWATCHER is not sensitive to thresholds. This also
explains the nearly perfect AUC in § VIII-C.
Although it
is reasonable to access /etc/passwd locally,
we claim that /etc/passwd is not supposed to be sent out to
public networks since it includes sensitive user information.
Any interactions between /etc/passwd and public networks
should be recommended as potential data exﬁltration and
reported to analysts for inspection. To validate this claim, we
conduct an additional experiment to predict the probability
of the interactions between /etc/passwd and network sockets
to be adversarial. As expected, both the interactions between
/etc/passwd and {146.153.68.151:80, 162.66.239.75:80} are
given high probabilities (0.68 and 1.71), which are well
beyond our threshold (-0.5) indicating attack activities.
IX. DISCUSSION & LIMITATION
Benign Dataset. SHADEWATCHER, like most anomaly detec-
tors [21], [26], [73]–[75], requires attack-free data to proﬁle
benign behaviors. However, it does not guarantee that real-
world audit records are perfectly clean. Accordingly, it is
necessary to explore SHADEWATCHER’s robustness against
potential data contamination. To this end, we provide empirical
results to demonstrate what happens if we purposefully poison
our training set by treating malicious system entity interactions
for detection in the TRACE dataset as benign training data.
Results show that false negatives increase from 10 to 18 com-
pared with training on benign audit data. As most malicious
interactions (68,079) are still detected, we hypothesize that
SHADEWATCHER is generally robust to data contaminations.
Evasion Attack. Evading SHADEWATCHER requires non-
trivial efforts even for an attacker who is aware of its detection
logic. Speciﬁcally, SHADEWATCHER differentiates between
benign and malicious system entity interactions by modeling
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 13:13:26 UTC from IEEE Xplore.  Restrictions apply. 
500
-1.88-1.66 0.50.420.51-1.16-1.91gtcachepass_mgrgtcache146.153.68.151:80/etc/passwd/proc/pid/statsh/tmp/ztmpztmp162.66.239.75:80128.55.12.73uname-1.93not only ﬁrst-order (causal) but also high-order (semantic) con-
nectivities. Therefore, directly incorporating noisy interactions
irrelevant to attacks does not serve the purpose of evasion.
Instead, the attacker must carefully match the semantics of
malicious interactions to those of benign interactions. One
possible strategy is to manipulate the structures of our knowl-
edge graph (KG) to perform adversarial attacks on GNNs.
While such attacks have shown potential on network graphs
(e.g., citation network) [76], [77], we argue that they are less
effective on the KG as system auditing provides a signiﬁcantly
more constrained setting for KG perturbations [22]. Especially,
attackers cannot add an edge between two ﬁles or arbitrarily
delete system entity interactions (e.g., /etc/passwd interacting
with 146.153.68.151:80 to exﬁltrate data) without affecting
attacks. Interesting future work would be designing specialized
adversarial attacks for system auditing analysis.
False Alarm. A well-known limitation of anomaly-based de-
tection is generating high false-positive rates (FPRs). SHADE-
WATCHER inherits this by detecting anomalous system entity
interactions as cyber threats. However, as we demonstrate
in Table IV, SHADEWATCHER achieves acceptable FPRs
(below 0.5%) considering that it produces much ﬁner-grained
detection signals than existing anomaly detectors. Although,
at ﬁrst glance, Unicorn [21] generates a lower FPR on the
DARPA TC dataset, it analyzes cyber threats at the granularity
of behaviors that are very large and difﬁcult to interpret in
practice. Counterintuitively,
the high FPR is also a major
concern for speciﬁcation-based detectors [78], although such
detection, in theory, would raise fewer false positives by rigid
attack matching. For example, RapSheet [14] reports a 2.2%
FPR for identifying APT kill chains in provenance graphs.
One approach to mitigating false positives is adopting threat
alarm triage techniques [79], the goal of which is to rank
true alarms higher than false alarms before manual investi-
gation. For example, we can integrate SHADEWATCHER with
NoDoze [11] to assign a threat score for individual malicious
system entity interactions so that analysts can focus on the
most anomalous ones to accelerate incident response.
X. RELATED WORK
System Auditing. System auditing has recently attracted
increasing attention due to its deep visibility into advanced
cyber-attacks [80]–[82]. Extensive literature exists on col-
lecting and storing whole-system audit data effectively and
reliably [7], [8], [44], [83]–[85]. Although auditing is widely
supported in modern SIEM [3]–[5], audit record analysis is
still limited to two fundamental challenges: 1) as audit records
capture low-level system calls, the volume of audit data is
typically too overwhelming for analysts to investigate. Recent
work aims to decrease the overall number of audit records
by data reduction [6], [46] and graph compression [47], [86],
[87]; 2) as each audit record is conservatively considered
dependent on all
the preceding records, system causality
analysis may suffer from the dependency explosion problem
(especially in the case of analyzing long-running processes).
To address dependency explosion, researchers have explored
different techniques to provide precise system provenance,
which include execution unit partition [45], [67], [88], [89],
dynamic tainting [90], [91], modeling-based inference [92],