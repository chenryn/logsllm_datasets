semantics.
With respect to performance, any system the performs taint-speciﬁc
optimizations is likely to suffer when applied to problems beyond
taint. To maintain high performance in a general setting, the tech-
niques and optimizations must be generally applicable to all data
ﬂow tracking problems.
4. OUR SOLUTION
Our system takes a C program as input and produces as output
a modiﬁed version of the program that enforces a selected security
policy. Our system does not require hardware or operating sys-
tem changes, is easy to use and extend, and exploits a powerful
interprocedural data ﬂow analysis to eliminate unnecessary instru-
mentation. While our speciﬁc implementation targets C code, our
techniques are not speciﬁc to taint tracking or C and can be applied
to a wide array of current and future problems and languages.
Our system is easy to deploy: the end user of our system needs
only to recompile a program and select a security policy to create a
secure program. A security expert can extend our system—which
currently includes policies for taint tracking and the prevention of
ﬁle disclosure vulnerabilities—with new analyses and policies by
providing a annotation ﬁle that is independent of any speciﬁc ap-
plication.
Our policies use a simple and ﬂexible dynamic model similar to
General Information Flow [31]. Our system associates symbolic
tags with data objects at runtime, it updates the tags as the program
executes, and it enforces policies based on the tag values. Unlike
prior systems, our system is explicitly based on data ﬂow analy-
sis [29], a technique for computing facts about data by observing
how it ﬂows through the program. This design allows our system
to both statically check for and dynamically guard against policy
violations from the same speciﬁcation. A static data ﬂow analysis
computes an approximate solution that holds over all possible exe-
cutions of the program because a fully precise solution is undecid-
able [29]. In contrast, a dynamic data ﬂow analysis [26] computes
precise facts but only about the current execution. These comple-
mentary characteristics allow our system to use a static data ﬂow
analysis, discussed in Section 4.4, to compute a conservative solu-
tion at compile time and to reﬁne the result at runtime to enforce a
policy efﬁciently and precisely.
To perform the dynamic data ﬂow analysis that actually enforces
the policy, our compiler inserts into the source program calls to a
small runtime library that manages tag information along with any
required checks necessary to enforce the policy. Since nothing in
our system is speciﬁc to taint tracking, our system and our opti-
mizations apply to all general data ﬂow tracking problems.
1
2
3
4
5
6
7
8
9
10
11
12
13
14
char input[1024];
char buf[1024];
char otherbuf[1024];
char buf1[1024];
...
read_from_network(input);
read_from_network(otherbuf);
...
memcpy(buf, input, 1024);
memcpy(buf1, otherbuf, 1024);
process(buf);
process(buf1);
...
printf(buf);
Figure 2: A simple example illustrating the beneﬁts of our static
analysis. Current systems must track all objects, while our
static analysis can eliminate tracking on all except buf.
Eliminating Unnecessary Tracking.
The naive insertion of calls throughout the program inevitably
leads to high overhead, so to achieve good performance, it is critical
that unnecessary calls be eliminated. To illustrate some of the lim-
itations and difﬁculties encountered by current systems, consider
the code in Figure 2. This code contains a format string vulnerabil-
ity where a tainted buffer is printed. Assuming a policy that uses
taint analysis to guard against format string attacks, current taint
tracking systems, including those that perform some static analy-
sis, would track taintedness on all buffers in this example, as well
as anything that the process function touches and anything that
those variables affect. However, very little tracking is actually re-
quired. Our system can prove that tracking on buf1 is not required
because it is never passed to printf or any other sensitive func-
tion. Additionally, if tracking on buf1 is not required, neither
is tracking on otherbuf, because buf1 receives its value only
from otherbuf. We also do not need to track anything in the
call to process(buf1) because none of its results is used by
printf. Moreover, we do not need to track the original input
buffer because we know that it is always tainted; it is sufﬁcient to
simply mark buf as tainted at the call to memcpy. Finally, we do
not need to track anything else that process(buf) can affect if
none of the resulting values is misused.
The keys to removing this type of unnecessary tracking are an
interprocedural static analysis that leverages semantic information
about the security policy and a sophisticated interprocedural pointer
analysis to perform policy-speciﬁc optimizations. Without seman-
tic information about the policy, our system could not distinguish
possible violations from safe events. Without a precise pointer
analysis, our system could not account for ﬂows between objects
in an effective manner. Without a dependence analysis that builds
on the pointer analysis and knowledge of the policy, our system
could not determine which objects are involved in possible vulner-
abilities. Moreover, all of these analyses must be interprocedural to
eliminate ﬂows among functions.
More speciﬁcally, our system operates by ﬁrst performing a static
data ﬂow analysis and a highly precise and scalable pointer analy-
sis to determine where possible policy violations lie. Our system
then instruments the program to ensure that all policy enforcement
checks are performed correctly. Because the portion of a program
involved in any given attack is typically exceedingly small [36], our
system typically adds very little code and incurs negligible over-
head. Identifying this portion requires a powerful static analysis.
Our system is built on the Broadway static data ﬂow analysis
and error checking system [21], which is a source-to-source trans-
lator for C. We use the Broadway annotation language and analy-
sis infrastructure, enhancing it with our own dependence analysis
(described in Section 4.4.3) and dynamic data ﬂow analysis com-
ponent (described in Section 4.1).
The remainder of this section discusses the components of our
system in more detail. We will begin with an overview of our
compiler-based dynamic data ﬂow analysis system, followed by a
discussion of our policy speciﬁcation mechanism. Finally, we will
discuss the details of our static analysis.
4.1 Dynamic Data Flow Analysis
The dynamic data ﬂow analysis that we perform is a typestate
analysis [43], which is an analysis that associates an abstract value,
called typestate, with objects in a program. Unlike types, the type-
state of an object can change during execution. For example, a ﬁle
handle or a string maintains the same type throughout its lifetime,
but its typestate—open or closed, tainted or untainted—can change
as the program executes. Typestate is a general model capable of
supporting a wide variety of security analyses and policies, includ-
ing all those supported by general data ﬂow tracking [31].
Our implementation of dynamic data ﬂow analysis treats type-
states as ﬂow values in a data ﬂow analysis and represents them
at runtime with a map that associates 32-bit tags with data. As
execution proceeds and data are used, the tag map is updated in
accordance with the property being analyzed. To enforce a partic-
ular security policy, checks that use these tags are inserted into the
program.
The map is implemented using a very small runtime library that
includes functions for initializing, checking, updating, and delet-
ing entries from the map. Our implementation tracks tags at the
byte granularity, providing ﬁne-grained tracking of data ﬂow prop-
erties, which is necessary because the tracking of ﬂow values at
the level of variables is unsafe in a type-unsafe language like C,
especially in the presence of aliasing. Our map uses a sparse repre-
sentation similar to tree-like structures previously used for memory
leak proﬁling [25]. Each node in the tree represents an address
range, with child nodes representing ﬁner subdivisions of the range
of their parent nodes. The leaf nodes contain arrays which record
ﬂow values associated with memory at a byte granularity. For ex-
ample, to record the taintedness of a byte of memory at address a,
the library traverses the tree to ﬁnd the leaf node representing the
smallest address range that contains a, and it then record tainted-
ness in that node’s array of ﬂow values. In addition, to save mem-
ory and decrease lookup times, our implementation also allows us
to store ﬂow values in the interior nodes when the entire subtree
contains only one ﬂow value, which can occur when large regions
are marked entirely with the same typestate.
4.2 Code Instrumentation
To use the map to track ﬂow values at runtime, the compiler in-
struments the original program with calls to functions that manage
the map. This process is straightforward. Like most compilers,
our system ﬁrst transforms C to a simpler intermediate representa-
tion before performing analysis and transformations. At this level,
the compiler only needs to consider assignments, basic operators,
pointer dereferences, and function calls. Our transformation for
inserting code is as follows:
• Constants are given the default ﬂow value.
• Assignments transfer the ﬂow value of the source to the tar-
get.
• Operators (such as arithmetic operators and array accesses)
have the ﬂow value of the meet of the operands. The meet
operator in data ﬂow analysis combines ﬂow values based on
their position in the lattice [29].
• Any address or pointer dereference that is used or assigned
to acts on the corresponding entry in the map.
• In keeping with C’s call-by-value semantics, function calls
transfer ﬂow values to the arguments in the function body,
and function calls return any ﬂow values through the return
value.
These rules are analogous to the standard rules for applying data
ﬂow analysis [29] and remain the same for the wide variety of
security problems that lattices naturally model [18]. When ap-
plied to taintedness, these rules are the same code insertion rules
used by other compiler-based systems [48, 31] (although our ad-
ditional analysis and optimizations often allow us to remove con-
siderable amounts of instrumentation). These rules track explicit
ﬂows, which are information ﬂows that occur because of assign-
ments or arithmetic operations. Like taint tracking systems, our
system does not track implicit ﬂows [44, 16, 37, 48, 39, 31].
4.3 Policy Speciﬁcation
In most taint tracking systems, the semantics of taint analysis
are hardcoded into the system. Because our system is designed to
handle general data ﬂow problems, our system instead factors out
the semantics of the analysis and policy to an external ﬁle that con-
tains annotations describing the property to analyze, the policy to
enforce, and the effects of library procedures on the property. This
ﬁle contains the same information that would have been hardcoded
into a compiler-based taint tracking system, but it provides the ca-
pability to extend our system to other problems without changing
the core analysis. Unlike in-lined annotations, our annotations de-
ﬁne an analysis that is independent of the input program, enabling
reuse across many programs. A typical user does not have to write
any annotations to use an existing policy. The creation of new pol-
icy ﬁles is a careful activity that is only necessary when deﬁning a
new analysis or security policy.
Our system uses the Broadway declarative annotation language [22,
21], which has been previously used for static error checking [23]
and library-level optimizations [24]. The annotation ﬁle tells the
compiler how to perform a speciﬁc data ﬂow analysis by supplying
the speciﬁcs for the rules in Section 4.2. The rules fall into three
categories:
• Deﬁning the Lattice. The lattice for each typestate prop-
erty must be deﬁned. The tags used at runtime correspond to
the ﬂow values, while the lattice itself deﬁnes the meet func-
tion that speciﬁes how ﬂow values should be combined when
used together in arithmetic and other operations.
• Describing Effects of Library Calls. The compiler also
needs to know how the various library calls affect tag val-
ues. For each external function that affects the ﬂow values,
a brief summary annotation must be provided that describes
how the function can affect the ﬂow values of globals and
arguments.
• Deﬁning Security Policies. Lastly, the compiler needs to
be given the deﬁnition of policy violations. Violations are
deﬁned as predicates over ﬂow values that are checked at
procedure boundaries, most commonly a check on the ﬂow
value of an argument. By default, violations trigger our de-
fault error handler, which logs the violation and blocks the
operation, but the user can supply a custom error recovery
function, which can be application-speciﬁc.
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
property Taint : { Tainted, { Untainted } }
initially Untainted
procedure recv(s, buf, len, flags) {
on_entry { buf --> buffer }
modify { buffer }
analyze Taint { buffer  string }
access { string }
modify { string_copy }
on_exit { return --> new string_copy }
analyze Taint { string_copy  format_string }
access { format_string }
error if (Taint: format_string could-be Tainted)
"Error: tainted format string!"
}
Figure 3: Example syntax for deﬁning a policy that prevents
format string attacks. First, the concept of taintedness is de-
ﬁned. Then, we specify the introduction of taint through I/O
functions such as recv() and the propagation of taint through
functions such as strdup(). Finally, we prevent the use of
tainted format strings in functions such as printf(). The
forward arrows in the syntax allow us to distinguish between
pointers and pointed-to objects.
Our system readily supports domain-speciﬁc annotations that go
beyond the standard library functions. For example, if the appli-
cation calls an input sanitization function, we can add an annota-
tion for that function that untaints the sanitized output. Our sys-
tem can also support policies that depend on concrete values. For
example, a naive policy that rejects tainted SQL query strings is
inappropriate for detecting SQL injection attacks because query
strings always contain tainted characters. To handle SQL injection