ECC to use.  First, the choice of ECC determines how many 
errors  can  be  corrected  (e.g.,  SECDED)  and  how  much 
storage overhead is required for error correction.  Second, the 
ECC  must  be  “compatible”  with  the  code  used  for  coset 
generation.  
It is important to note that a naive implementation of ECC 
fixes  a  division  between  information  bits  and  parity  bits. 
Schechter et al. [19] showed that such an implementation can 
hurt  endurance  (of  PCM,  but  similar  reasoning  applies  to 
Flash) because the ECC bits get flipped far more frequently 
than the data bits they protect. Indeed, if we simply computed 
ECC for each codeword and appended ECC to the codeword, 
we would hurt our potential lifetime gain as the cells that are 
used to store ECC bits will saturate way faster than the rest of 
the  cells;  however,  when  ECC  is  integrated  with  the  coset 
code  into  a  single  code,  we  preserve  all  of  the  balancing 
properties of the coset code. 
Because the focus of our work is on postponing wearout, 
rather than tolerating errors, we do not further consider ECC 
in  this  paper.  We  simply  note  that  it  is  a  complementary 
feature  that  could  be  added  without  affecting  our  MFC 
heuristics for choosing codewords within cosets. The MFCs 
we demonstrate and analyze assume no error protection. 
VI.  IMPLEMENTATIONS 
In  this  section,  we  present  the  implementations  for 
different codes on top of the v-cell interface. We demonstrate 
MFCs  as  well  as  a  WOM  code.  Although  WOM  codes  are 
already extensively used in prior works, here we analyze their 
gains under a realistic implementation and use those results as 
a  comparison  point.  We  also  remind  the  reader  that  all  our 
implementations are based on the 4-level v-cells. 
  WOM 
For the WOM code, we use the 4-level v-cell to store two 
bits  of  data.  Thus  the  implementation has  an  overall  rate  of 
2/3, because each v-cell—which consists of three bits—holds 
only 2 bits.  In other words, for a raw capacity of C we have a 
host-visible capacity of 2/3C.  
In  Figure  9  we  demonstrate  how 
the  different 
representations of two bits are mapped to different states and 
levels  of  the  v-cell.  Note  that  some  levels  provide  multiple 
options  by  taking  advantage  of  the  multiple  paths  between 
levels. Under each state we mark the bits stored at that state. 
We also demonstrate an example as we re-program the cell in 
Figure 9 in order to update its data.  In the first re-program we 
transition from L0 to L1 by flipping the first bit of the 3-bit 
triplet representing the v-cell. Notice that by doing so the other 
two options of L1 become unreachable. That means we can 
only visit them if we first erase the v-cell. In this example the 
cell is updated 4 times before saturating. 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:41:41 UTC from IEEE Xplore.  Restrictions apply. 
Figure 9. WOM and v-cell representation. Under each state we mark the bits that each state represents. 
The dashed arrows indicate how we transition from ine state to an other for the illustrated example. 
  Methusalah Flash Codes (MFCs) 
All  MFCs  in  this  work  use  the  metric  function  that  was 
presented in Section V.A. We present MFCs based on coset 
codes with multiple rates; 1/2 (MFC-1/2), 2/3 (MFC-2/3), 3/4 
(MFC-3/4) and 4/5 (MFC-4/5).  
For MFC-1/2, we use the v-cells in two different ways, by 
storing  1  bit  per  cell  (MFC-1/2-1BPC)  and  2  bits  per  cell 
(MFC-1/2-2BPC) as shown in Figure 10. These two options 
present a potential tradeoff between host visible capacity loss 
and lifetime gains. Notice that, although MFC-1/2 is based on 
a coset code with rate 1/2, the overall implementation has a 
rate  1/6  when  using  the  v-cell  with  1BPC  and  a  rate  of  1/3 
when using the v-cell with 2BPC. 
For the rest of the MFCs we only explore the case where 
each v-cell stores 1BPC. Thus the implementations of MFC-
2/3, MFC-3/4 and MFC-4/5 have a rate of 2/9, 1/4 and 4/15 
respectively. 
  Performance and Implementation Analysis 
Any implementation of a coding scheme incurs overheads 
in performance (latency and/or bandwidth) and energy. These 
overheads arise due to both the logic for encoding/decoding 
and the extra Flash accesses that may need to be performed. 
These overheads are not unique to MFCs or re-writing codes, 
but  rather  apply  to  any  coding  scheme  that  is  used  for  any 
purpose. 
In the context of Flash, which has relatively slow access 
times  (compared  to,  say,  SRAM  or  DRAM),  the  logic  for 
encoding/decoding 
little  overhead. 
Moreover, the performance impact of encoding/decoding can 
be mitigated with special-purpose hardware, if desired.  
relatively 
incurs 
Figure 10. Two ways to map bits to cells for cosets. 
186
The more challenging overhead arises due to the need for 
extra  accesses  to  the  Flash.  A  code  with  rate  r  (say,  1/2) 
requires each Flash access to read or write 1/r times more bits 
than an uncoded Flash.  If a user accesses one page of data, 
the implementation must access 1/r pages.  The overhead of 
these  extra  accesses  could  be  mitigated  by  exploiting 
parallelism within and across Flash chips, when possible.  It is 
also possible that a custom Flash chip design, targeted for re-
writing codes, could have larger page sizes in order to fit more 
data per page and thus require fewer reads/writes per access. 
Coding  overheads  depend  highly  on  both  the  code  used 
and the details of the overall implementation. For example, a 
re-writing  code  could  be  implemented  at  different  system 
levels  (OS,  drivers,  or  FTL)  and  could  be  accelerated  with 
specialized hardware to reduce performance overhead. 
These overheads are inherent to any coding scheme, and 
they are a necessary price to pay to extend lifetime.  It is not 
the  case  that  we  can  choose  a  lifetime  extension  scheme 
without  overheads;  rather,  we  decide  how  much  lifetime 
extension  we  need  and  we  then  engineer  the  system  to 
minimize the overheads as best we can. 
VII. METHODOLOGY 
We  now  describe  how  we  evaluate  MFCs  and 
quantitatively compare them to prior work.   
  Evaluation Metrics 
Our goal is to increase Flash lifetime while minimizing the 
cost  of  doing  so.  Any  lifetime  extension  scheme  has  some 
cost, which is an increase in raw capacity and/or a decrease in 
host-visible capacity. Raw capacity is the capacity that would 
be  visible  if  the  Flash  were  used  without  any  lifetime 
extension  scheme.  The  host-visible  capacity—the  capacity 
visible to the user and the operating system for the whole life 
of the Flash product—is less than the raw capacity if a coding 
scheme  is  used.    The rate  of  a  code—which  we  previously 
defined  as  the  size  of  a  dataword  divided  by  the  size  of  a 
codeword—is  thus  also  equal  to  the  host-visible  capacity 
divided by the raw capacity; an uncoded Flash has a rate of 1, 
and all coding schemes have rates less than 1.  
The benefit of a lifetime extension scheme is its lifetime 
gain, which we measure as its number of program/erase (PE) 
cycles  divided  by  the  PE  cycles  of  an  uncoded  Flash  that 
allows a page to be programmed once before being erased.  
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:41:41 UTC from IEEE Xplore.  Restrictions apply. 
Our key evaluation metric is the lifetime gain multiplied 
by the rate, and we refer to this metric as aggregate gain.  An 
uncoded Flash has an aggregate gain defined equal to one, and 
our goal is to develop schemes with aggregate gains greater 
than  one.    Referring  back  to  Figure  1,  the  areas  of  the 
rectangles for each scheme equal their aggregate gains.  
We note that schemes with equal aggregate gains may not 
be  equally  desirable.    For  example,  a  scheme  with  lifetime 
gain  3  and  rate  1/2  may  be  more  practically  useful  than  a 
scheme with lifetime gain 30 and rate 1/20, even though both 
have the same aggregate gain of 3/2.  
  Schemes Compared 
The baseline to which we compare is uncoded Flash with 
capacity C (raw capacity equals host-visible capacity for the 
baseline)  and  lifetime L.  As  mentioned  above,  its  aggregate 
gain is defined to equal 1. 
We also compare to a simple redundancy scheme in which 
we use a factor of K times as much raw capacity to achieve 
the same host-visible capacity C, for a rate of 1/K. With simple 
redundancy,  we  use  the  first C  of  the  raw  capacity,  without 
coding,  until  it  wears  out.    Then  we  use  the  next C  of  raw 
capacity  until  it  wears  out,  etc.    Simple  redundancy  thus 
provides  a  lifetime  gain  of  K.  The  aggregate  gain  is  thus 
K/K=1, which is no better than the baseline. 
We  also  evaluate  the  WOM  code  and  the  MFC  codes 
described in Section VI.   
  Simulation 
We simulate a single 4KB page of Flash as it is repeatedly 
programmed  by  a  stream  of  writes.  We  record  the  average 
number of writes that can be performed to this page before it 
needs to be erased, and this value is the lifetime gain.  Because 
the  WOM  codes  and  MFCs  effectively  scramble  the 
datawords  in  converting  them  to  codewords,  the  results  are 
independent of the input data that is written.  For simplicity, 
we model the writes with pseudo-randomly generated data.   
To  fix  the  Flash  page  size,  despite  the  codes  having 
different rates, we vary the size of the datawords to be written, 
so that the codewords are all page-sized.  That is, for a given 
implementation with rate r we choose a dataword size, d, such 
that d×r  =  4KB.  Varying  the  dataword  size  is  a  reasonable 
approach  because,  even 
in  modern  uncoded  Flash 
implementations, the data are grouped in the appropriate size 
before stored, so as to accommodate the possible difference in 
sizes  between  a  Flash  hardware  page  and  a  page  of  virtual 
memory. 
VIII. EVALUATION 
Using the methodology described in the previous section, 
we determined the lifetime gain and aggregate gain for each 
lifetime extension scheme.  These results are summarized in 
Table I, and they show that different implementations provide 
a  wide  range  of  trade-offs  between  cost  (rate)  and  benefit 
(lifetime  gain).    In  the  rest  of  this  section,  we  delve  more 
deeply into these high-level results. 
TABLE I. RATE, LIFETIME AND AGGREGATE GAIN FOR ALL THE 
IMPLEMENSTATION. 
  Fixed-Cost Comparisons 
To highlight the differences between the implementations, 
we  fix  the  raw  capacity  at  C,  the  capacity  of  the  baseline 
uncoded Flash, and show how each implementation provides 
a different trade-off between host-visible capacity and lifetime 
gain.    We  illustrate  these  trade-offs  using  figures  similar  to 
Figure 1, in which the x-axis is lifetime gain and the y-axis is 
host-visible capacity.  The area  of each rectangle represents 
aggregate gain. 
In  Figure  11,  we  show  the  advantages  of  MFCs,  with 
respect  to  prior  work,  by  comparing  three  MFCs  with  the 
baseline,  redundancy,  and  a  WOM  code.  We  make  three 
observations  from  this  figure.    First, MFCs  (e.g.,  MFC-1/2) 
can  achieve  greater  aggregate  gains  than  redundancy  or 
WOM.  Second, an MFC can have the same aggregate gain as 
a  WOM  code  while  providing  a  different  trade-off  of  host-
visible capacity versus lifetime gain, as exemplified by MFC-
1/2-2BPC  and  the  WOM  code  in  the  figure.  Third,  two 
implementations  that  provide  the  same  lifetime  can  provide 
different host-visible capacities, depending on their aggregate 
gain (WOM vs Redundancy-1/2) 
In Figure 12, we compare all of the MFCs to each other. 
We observe that they offer a wide range of trade-offs. MFC-
1/2-2BPC, MFC-2/3, MFC-3/4 and MFC-4/5 achieve a range 
of lifetime gains from 4 to almost 7. MFC-1/2-1BPC stands 
out from the rest of the MFCs with a remarkable lifetime gain 
of 12. 
   Cost to Achieve Extreme Lifetime 
To  highlight  the  importance  of  aggregate  gain,  we 
consider  a  situation  that  demands  extreme  lifetime.  We 
assume an application that requires a lifetime gain of 12 and 
we  compare  the  cost  (raw  capacity)  of  different  coding 
schemes, in order achieve that requirement, for different host-
visible capacity goals.  
Figure  13  summarizes  these  results  for  the  WOM  code, 
MFC-4/5  and  MFC-1/2  codes,  and  redundancy.  The  results 
are normalized to a baseline of capacity C and lifetime L. We 
observe that MFC-1/2, which has the largest aggregate gain, 
provides  the  cheapest  solution  in  comparison  to  the  other 
codes.  From  this  graph,  we  conclude  that  higher  aggregate 
gains provide cheaper solutions (in terms of raw capacity). 
187
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:41:41 UTC from IEEE Xplore.  Restrictions apply. 
Figure 11. Fixed-cost comparisons of MFCs to prior work. 
Figure 12. Fixed-cost comparisons of different MFCs. 
Figure 13. Different costs for a given lifetime and host visible capacity 
goal. 
   Sensitivity Analysis: Lifetime vs Flash Page Size 
 A code’s ability to postpone erasing depends somewhat 
on the Flash page size. A page is no longer re-programmable 
after a sequence of input data that cause some of the cells to 
saturate.  The  number  of  re-programs  before  a  cell  becomes 
saturated  varies  depending  on  the  sequence  of  bits  that  we 
want to store to that cell. Some input data sequences will cause 
cells to saturate faster than others. As the page size increases, 
the probability that such a “bad” sequence of inputs will occur 
for any of our cells increases. Thus it increases the probability 
of  having  saturated  cells  that  will  act  as  a  bottleneck  in  our 
lifetime gain. 
In Figure 14, we plot lifetime gain as a function of page 
size, for WOM and two MFCs.  The results show that smaller 
page sizes indeed provide better lifetime gains.  However, we 
cannot decide to have arbitrarily small Flash pages; there are 