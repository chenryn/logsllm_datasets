collected between 2007 and 2017.
Session 3A: Web Attack MeasurementsAsiaCCS ’19, July 9–12, 2019, Auckland, New Zealand195Country Mapping. We further use MaxMind GeoCity [10] and Pota-
roo [21] datasets to map an IP address to its respective country (i.e.,
territories under sovereign rule or autonomous entities, e.g. BV.)
and country code, and used the Wayback Machine to obtain their
archived versions for historical mappings. Since these archived ver-
sions have “gaps,” we consider the closest available IP-geolocation
mapping to the reported mal-activity timestamp. This approxima-
tion is further discussed in Section 2.6.
2.4 Classification of Mal-Activities
Our augmented FinalBlacklist is composed of a myriad of mal-
activities with 15% (7.6M) originally labeled by their respective
data sources, and the remaining 85% (44M) unlabeled. To classify
all mal-activities, we employ manual classification of the labeled
mal-activities, and leverage machine learning to extend the known
labels onto the unlabeled dataset. We detail these approaches in the
following sections.
2.4.1 Manual Classification of Labeled Dataset. Each labeled mal-
activity in our dataset is classified into one of 4,918 unique mal-
activity labels by their respective data sources. Careful analysis of
these labels shows that the disparity between labels can be reduced
by only considering the end-goal or motivation of the adversary.
Based on this observation, each author re-classified each activity
into one of only six classes of labels. The co-authors disagreed on
1.07% of the cases, which was resolved using majority voting. If
consensus was not reached, the activity was marked as unlabeled
and discarded from the labeled dataset. The classes of reported mal-
activities are Exploits, Malware, Fraudulent Services (FS), Spammers,
Phishing, and Potentially Unwanted Programs (PUP). We define these
mal-activities in Appendix B.
2.4.2 Classifying Unlabeled Dataset. Classification of a large num-
ber (44M, 85%) of unlabeled mal-activities is a non-trivial task. One
way is to leverage the VirusTotal request API to retrieve labels.
However, due to rate limits imposed by VirusTotal, classifying this
volume of mal-activities would require an unreasonable amount of
time. Therefore, we decided to use our labeled dataset (7.6M, 15%)
to determine if there is sufficient information available that can be
used to predict class labels to the unlabeled mal-activities.
Motivation. To motivate the plausibility of this approach, we
highlight one aspect of the labelled dataset called “specialization.”
More precisely, we found that a large proportion of hosts partic-
ipate in single class of mal-activity, i.e., specialize in one class
of activity, indicating that past involvement in a particular mal-
activity class is a good indicator of a future class label. To demon-
strate this, for a given host h (IP address) in the labeled dataset,
we first compute: p(h, a) =
, where
a is one of the six mal-activity classes. We then define a probabilis-
tic metric, host specialization, which is based on the distribution
of mal-activities by hosts in the labeled dataset. Formally, it is
defined as the normalized Shannon entropy per host h given by
a p(h, a) log2 p(h, a))/log2 k, where k ≤ 6 is the num-
ber of activities done by host h and a ranges over the 6 classes of
activities. A host highly specializes in a single class of mal-activity
if it has a lower value of S(h).
S(h) = (−
# of reports for host h with activity a
Total # of reports for host h
Figure 2: IPs, ASes, and Countries Specialization in Blacklist-07-17
dataset. Most IP addresses specialize in a single class of mal-activity.
From Figure 2, we observe that 80% of the reported IP addresses
exclusively participate in one class of mal-activity. When we expand
the definition of a host to include an AS or a country, we observe
a more uniform distribution across the hosts, with 55% of ASes
and only 20% of countries (CC) participating in one class of mal-
activity. Furthermore, only 0.04% (311) of IP addresses, 2.12% (275)
of ASes, and 27.4% (54) of countries, participate in all six classes.
On closer look, we found that 96.8% of IP addresses, 87.7% of ASes
and 74.4% of countries have a relative entropy value of less than
0.50. This suggests that a substantial number of hosts (IPs, ASes,
and Countries) will be biased towards one class of mal-activities.
Following this intuition, we suspect there is sufficient informa-
tion within the mal-activity reports for the training of a classifier
to predict the report’s mal-activity label. Specifically, if this trained
classifier has good testing accuracy on our labelled dataset, we
can leverage the classifier to predict the mal-activity label of our
unlabelled reports.
Machine Learning Approach to Label Mal-Activities. As each re-
port can be labelled one of the 6 mal-activity labels (§2.4), we es-
tablish the task of predicting the mal-activity label as a multi-class
classification problem. We leverage a Random Forest classifier, with
our original labelled dataset divided into training (40%) and testing
(60%) sets. The labelled Blacklist-07-17 dataset contains 1,006,171
samples of malware, 164,149 of phishing, 60,146 of exploit, 297,652
of fraudulent services, 43,582 of unwanted programs, and 2,691
samples of spammers. The split of the dataset (into training and
testing sets) is stratified, with a consistent proportion of training
and testing samples for each mal-activity label. The large number
of reports in the labelled dataset prevented us from using more
reports in the training dataset, as the random forest implementa-
tion from scikit-learn [53] would encounter memory issues, despite
more than 96 GB of RAM provisioned for the task. As the training
set is dwarfed by the testing set, we repeated the model training
and testing process 5 times, each on different training/testing splits
of the data. This repetition ensures our results are not a result of a
biased split in the data.
Table 1 lists the features used for labelling mal-activities. We
note that One-Hot encoding is a common approach of encoding
categorical features, whereby the encoding maps a categorical fea-
ture with k categories into k binary vectors. An alternate method
is to encode the categorical data as numerals, however, this would
also produce a misleading numerical relationship between the cat-
egories depending on their order. We have chosen the features of
Session 3A: Web Attack MeasurementsAsiaCCS ’19, July 9–12, 2019, Auckland, New Zealand196day, month, year, and IP address (decomposed into octets) as this is
the most basic information available in a mal-activity report. On
the other hand, AS, country and organization information can be
easily found from the given IP address via a whois lookup.
We decompose the IP address into its octets to allow the model
to learn possible \8, \16, \24, \32 relationships, that would otherwise
not be possible with a full 32-bit IP encoding. It is also acknowl-
edged that IPs are dynamic in nature, and it has been observed that
malicious domains hosting malware are transferred to other IPs
within an IP block under a single controlling entity (e.g., hosting
provider such as Amazon) [49]. Therefore in the interest of produc-
ing a sufficiently generalized model to handle possible IP changes,
we use octets.
Given that 136,941 (20.7%) of IP addresses in the reports are being
reported to be involved in more than one class of mal-activities,
the percentage breakdown under each metadata attribute such
as IP address, ASes or geolocation (country) does not add up to
100%. We found that the labelled IPs (662,409) host 8.42M, 8.79M,
and 948K number of unique domains, URLs, and malicious files
(i.e., executables), respectively. We also find that IP addresses that
correspond to mal-activities are referenced in 18K malicious files
(i.e., referrers).
Note that, as an IP-endpoint (such as a Web server) could host
more than one domain and could have multiple resources (i.e.,
URLs), once again, the percentage of number of domains and URLs
does not add to 100%.
Table 1: Features used in Classification Task
Feature
Day
Month
Year
IP bits (0-7)
IP bits (8-15)
IP bits (16-23)
IP bits (24-31)
AS
Data Type
integer
integer
integer
integer
integer
integer
integer
integer
Country
One-Hot encoding
Organization One-Hot encoding
Table 2: Summary of the FinalBlacklist dataset. “U” denotes unique
and “FS” represents Fraudulent Services.
Class
# U. IP
# U. ASes
# Reports
FS 1,141,377 (2.21%)
# U. CC
Malware 46,932,466 (90.9%) 427,745 (65%) 11,435 (88%) 196 (99%)
4,402 (34%) 139 (70%)
Phishing 2,450,247 (4.74%) 133,072 (20%)
3,264 (25%) 118 (60%)
87,508 (13%)
895,494 (1.73%) 165,465 (25%)
2,200 (17%)
81 (41%)
2,966 (23%) 112 (57%)
39,854 (6%)
218,791 (0.42%)
7,620 (0.01%)
2,209 (0.3%)
60 (30%)
Total 51,645,995 (100%) 662,409 (100%) 12,950 (100%) 198 (100%)
PUP
Exploits
Spammers
561 (4%)
Performance and Prediction of Unlabelled Data. On 6 Cores of an
Intel Xeon E5-2660 V3 clocked at 2.6 GHz and 96GB of memory, the
whole classification process took approximately 15 minutes. This
includes loading/splitting the data, training, testing and writing
results to disk. As we have trained 5 models on different splits
of the original training data, rather than discarding 4 models to
only use one, we construct an ensemble of all 5 models (a classifier
ensemble).
Each of the 5 models provides a prediction, consisting of a label
and associated probability (confidence). From this, the label with
the highest average probability is assigned to the mal-activity re-
port. This method of majority voting is known as soft-voting. The
class-specific accuracies of Malware, Phishing, Exploits, Fraudulent
Services, PUP, Spammers, averaged over all 5 models is 93.04%,
93.85%, 79.04%, 91.70%, 96.29%, 82.57%, respectively. Since the num-
ber of samples for each label is uneven, we therefore performed a
weighted average over the label-specific accuracies to produce an
overall accuracy, which turned out to be 92.49%.
2.5 Summary of the Augmented Dataset
In Table 2, we report the total number of mal-activities correspond-
ing to the six classes, along with the collected metadata. Overall,
we collected a total of 51,645,995 mal-activity reports from all data
sources (cf. Table 5 in Appendix A.1). With manual labeling and the
use of our random forest machine learning classifier, we categorized
44,003,768 (85%) unlabelled reports into six different classes. The
result produces malware as the largest mal-activity class (90.9%),
and spammers as the smallest (0.01%).
2.6 Limitations
Despite our best efforts to collect the most comprehensive set of
data sources to perform our study, there are still some limitations
worth mentioning.
First, a limitation Blacklist-07-17 is that we did not use some
popular blacklists that we are aware of (e.g., the Spamhaus Project
[26] and PhishTank [20]), as the lists in those reporting services
were dynamically generated and hence it is very difficult to extract
their historical versions (the Way Back machine does not archive
dynamically generated content). Second, Blacklist-07-17 might be
biased towards specific or niche threats, e.g., specific focus of the
Zeus, Spyeye or OpenPhish blacklists (cf. Table 5). Also, Wayback
Machine snapshots are sporadic and as a result Blacklist-07-17 is
subject to sparsity in time coverage. This was one of the motivations
to feed the initial lists to the VirusTotal service to extract more
comprehensive reports across the whole 2007-2017 period.
Finally, the IP-Country mappings described in Section 2.3, are
obtained from Wayback Machine archives of Maxmind and Potaroo.
Here, we could not recover the exact mapping due to the sporadic
nature of Wayback Machine records (as we did for the historical ver-
sions of blacklists using VT Score reporting). Instead, we consider
the closest available IP-geolocation mapping to the reported mal-
activity timestamp. We acknowledge that accuracy of IP address
to location databases may impact our analysis. However, note that
database accuracies are questioned at the city and region-levels,
but previous research has shown that geolocation databases can
effectively locate IP addresses at the country-level [55].
Session 3A: Web Attack MeasurementsAsiaCCS ’19, July 9–12, 2019, Auckland, New Zealand1973 CHARACTERIZATION OF MAL-ACTIVITIES
In this section, we analyze whether a few hosts (IP addresses, coun-
tries and ASes) are more biased towards specific classes of mal-
activities or if the spread is more uniformly distributed. We also
provide further insights where a particular mal-activity is skewed
towards a few hosts.
3.1 Distribution of Mal-Activities
We first study the distribution of IPs over the categories of mal-
activities, then analyze the geolocation distribution at both country
and AS levels.
3.1.1 Across IP Addresses. The majority of IP addresses (63.0%) are
repeat offenders with participation in mal-activities reported more
than once as shown in Figure 3a. Among the different classes of
mal-activities, IP addresses corresponding to Fraudulent Services
(81.6%) and Malware (65.0%) were the most involved in more than
one corresponding mal-activity. Spammers on the other hand are
the least repeated by an IP address (only 36.4%). Overall, about
18.0% of all IP addresses were involved in at least 10 reports of
mal-activity, with an average of 78.0 reports per IP.
Insights. We observe that 54.72.9.51 is the most reported IP
address, managed by AS16509 (AMAZON-02 - Amazon.com, Inc.)
in the US, which is dominated by the malware class with 43,753
reports. This is consistent with reports [41, 46] on cybercriminals
using, often, free Amazon Web Services (AWS) to host a large
volume of SpyEye Trojans and exploit kits for mal-activities. Simi-
larly, we found that 69.172.216.56 is the third most reported IP
address, managed by AS7415 (Integral Ad Science–a Web ad and an-
alytic service) in Canada, primarily due to suspicious ad campaigns
comprising of 35,885 unique PUPs. We were unable to determine
whether this IP address is infected with malware. However, our
study confirms previous findings [49, 50] on cybercriminals us-
ing leading ad networks to propagate mal-activities (in this case,
Integral Ad Science). Previous research [57] showed that spam-
mers often quarantine bots for a period, waiting for them to be
whitelisted again.
3.1.2 Across Countries. Our dataset shows that there is at least
one malicious IP address hosted in almost every country (avg. 4170
IP addresses per country). However, Figure 3b indicates that the
mal-activities are not evenly distributed among countries. The fig-
ure shows that mal-activities are a prevalent cybersecurity threat
worldwide with 20.2% of countries having more than 10K mali-
cious reports, although the distribution varies from one class of
mal-activity to another. Malware is distributed relatively evenly
whilst spammers are concentrated in a few selected countries like
United States, Russia, British Virgin Islands, Ukraine, and Germany
with proportions of the spamming activity at 35%, 22%, 9%, 5%, and
5%, respectively.
Insights. Our results agree with the expectation that countries
with rich IT infrastructure such as US, Germany, China, France,
and the Netherlands are dominant in terms of mal-activities (42M,
1.47M, 1.32M, 1.24M and 0.41M, respectively). Interestingly, British
Virgin Islands (VG) is ranked 8th with 243K mal-activities. Out of