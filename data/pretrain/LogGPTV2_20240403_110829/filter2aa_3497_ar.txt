A5/1 and A5/2 (used in GSM voice
encryption)
54 or 64
1989
RC4
Up to 2048
1993
Counter mode (CTR)
Dependent on block
cipher
N/A
Output Feedback mode (OFB)
Dependent on block
cipher
N/A
Cipher Feedback mode (CFB)
Dependent on block
cipher
N/A
Asymmetric Key Cryptography
Symmetric key cryptography strikes a good balance between security and convenience, but
it has a significant problem: participants in the network need to physically exchange secret
keys. This is tough to do when the network spans multiple geographical regions.
Fortunately, asymmetric key cryptography (commonly called public key encryption) can mitigate
this issue.
An asymmetric algorithm requires two types of keys: public and private. The public key
encrypts a message, and the private key decrypts it. Because the public key cannot decrypt a
message, it can be given to anyone, even over a public network, without fear of its being
captured by an attacker and used to decrypt traffic, as shown in Figure 7-10.
||||||||||||||||||||
||||||||||||||||||||
Figure 7-10: Asymmetric key encryption and decryption
Although the public and private keys are related mathematically, asymmetric key
algorithms are designed to make retrieving a private key from a public key very time
consuming; they’re built upon mathematical primitives known as trapdoor functions. (The
name is derived from the concept that it’s easy to go through a trapdoor, but if it shuts
behind you, it’s difficult to go back.) These algorithms rely on the assumption that there is
no workaround for the time-intensive nature of the underlying mathematics. However,
future advances in mathematics or computing power might disprove such assumptions.
RSA Algorithm
Surprisingly, not many unique asymmetric key algorithms are in common use, especially
compared to symmetric ones. The RSA algorithm is currently the most widely used to
secure network traffic and will be for the foreseeable future. Although newer algorithms
are based on mathematical constructs called elliptic curves, they share many general
principles with RSA.
The RSA algorithm, first published in 1977, is named after its original developers—
Ron Rivest, Adi Shamir, and Leonard Adleman. Its security relies on the assumption that
it’s difficult to factor large integers that are the product of two prime numbers.
Figure 7-11 shows the RSA encryption and decryption process. To generate a new key
pair using RSA, you generate two large, random prime numbers, p and q, and then choose
Technet24
||||||||||||||||||||
||||||||||||||||||||
a public exponent (e). (It’s common to use the value 65537, because it has mathematical
properties that help ensure the security of the algorithm.) You must also calculate two
other numbers: the modulus (n), which is the product of p and q, and a private exponent (d),
which is used for decryption. (The process to generate d is rather complicated and beyond
the scope of this book.) The public exponent combined with the modulus constitutes the
public key, and the private exponent and modulus form the private key.
For the private key to remain private, the private exponent must be kept secret. And
because the private exponent is generated from the original primes, p and q, these two
numbers must also be kept secret.
Figure 7-11: A simple example of RSA encryption and decryption
The first step in the encryption process is to convert the message to an integer, typically
by assuming the bytes of the message actually represent a variable-length integer. This
integer, m, is raised to the power of the public exponent. The modulo operation, using the
value of the public modulus n, is then applied to the raised integer me. The resulting cipher
text is now a value between zero and n. (So if you have a 1024-bit key, you can only ever
encrypt a maximum of 1024 bits in a message.) To decrypt the message, you apply the
same process, substituting the public exponent for the private one.
RSA is very computationally expensive to perform, especially relative to symmetric
ciphers like AES. To mitigate this expense, very few applications use RSA directly to
encrypt a message. Instead, they generate a random session key and use this key to encrypt
the message with a symmetric cipher, such as AES. Then, when the application wants to
||||||||||||||||||||
||||||||||||||||||||
send a message to another participant on the network, it encrypts only the session key
using RSA and sends the RSA-encrypted key along with the AES-encrypted message. The
recipient decrypts the message first by decrypting the session key, and then uses the
session key to decrypt the actual message. Combining RSA with a symmetric cipher like
AES provides the best of both worlds: fast encryption with public key security.
RSA Padding
One weakness of this basic RSA algorithm is that it is deterministic: if you encrypt the
same message multiple times using the same public key, RSA will always produce the same
encrypted result. This allows an attacker to mount what is known as a chosen plaintext attack
in which the attacker has access to the public key and can therefore encrypt any message.
In the most basic version of this attack, the attacker simply guesses the plaintext of an
encrypted message. They continue encrypting their guesses using the public key, and if
any of the encrypted guesses match the value of the original encrypted message, they know
they’ve successfully guessed the target plaintext, meaning they’ve effectively decrypted the
message without private key access.
To counter chosen plaintext attacks, RSA uses a form of padding during the encryption
process that ensures the encrypted output is nondeterministic. (This “padding” is different
from the block cipher padding discussed earlier. There, padding fills the plaintext to the
next block boundary so the encryption algorithm has a full block to work with.) Two
padding schemes are commonly used with RSA: one is specified in the Public Key
Cryptography Standard #1.5; the other is called Optimal Asymmetric Encryption Padding
(OAEP). OAEP is recommended for all new applications, but both schemes provide
enough security for typical use cases. Be aware that not using padding with RSA is a
serious security vulnerability.
Diffie–Hellman Key Exchange
RSA isn’t the only technique used to exchange keys between network participants. Several
algorithms are dedicated to that purpose; foremost among them is the Diffie–Hellman Key
Exchange (DH) algorithm.
The DH algorithm was developed by Whitfield Diffie and Martin Hellman in 1976
and, like RSA, is built upon the mathematical primitives of exponentiation and modular
arithmetic. DH allows two participants in a network to exchange keys and prevents anyone
monitoring the network from being able to determine what that key is. Figure 7-12 shows
the operation of the algorithm.
Technet24
||||||||||||||||||||
||||||||||||||||||||
Figure 7-12: The Diffie–Hellman Key Exchange algorithm
The participant initiating the exchange determines a parameter, which is a large prime
number, and sends it to the other participant: the chosen value is not a secret and can be
sent in the clear. Then each participant generates their own private key value—usually
using a cryptographically secure random number generator—and computes a public key
using this private key and a selected group parameter that is requested by the client. The
public keys can safely be sent between the participants without the risk of revealing the
private keys. Finally, each participant calculates a shared key by combining the other’s
public key with their own private key. Both participants now have the shared key without
ever having directly exchanged it.
DH isn’t perfect. For example, this basic version of the algorithm can’t handle an
attacker performing a man-in-the-middle attack against the key-exchange. The attacker
||||||||||||||||||||
||||||||||||||||||||
can impersonate the server on the network and exchange one key with the client. Next, the
attacker exchanges a different key with the server, resulting in the attacker now having two
separate keys for the connection. Then the attacker can decrypt data from the client and
forward it on to the server, and vice versa.
Signature Algorithms
Encrypting a message prevents attackers from viewing the information being sent over the
network, but it doesn’t identify who sent it. Just because someone has the encryption key
doesn’t mean they are who they say they are. With asymmetric encryption, you don’t even
need to manually exchange the key ahead of time, so anyone can encrypt data with your
public key and send it to you.
Signature algorithms solve this problem by generating a unique signature for a message.
The message recipient can use the same algorithm used to generate the signature to prove
the message came from the signer. As an added advantage, adding a signature to a message
protects it against tampering if it’s being transmitted over an untrusted network. This is
important, because encrypting data does not provide any guarantee of data integrity; that is,
an encrypted message can still be modified by an attacker with knowledge of the
underlying network protocol.
All signature algorithms are built upon cryptographic hashing algorithms. First, I’ll
describe hashing in more detail, and then I’ll explain some of the most common signature
algorithms.
Cryptographic Hashing Algorithms
Cryptographic hashing algorithms are functions that are applied to a message to generate a
fixed-length summary of that message, which is usually much shorter than the original
message. These algorithms are also called message digest algorithms. The purpose of hashing
in signature algorithms is to generate a relatively unique value to verify the integrity of a
message and to reduce the amount of data that needs to be signed and verified.
For a hashing algorithm to be suitable for cryptographic purposes, it has to fulfill three
requirements:
Pre-image resistance Given a hash value, it should be difficult (such as by requiring a
massive amount of computing power) to recover a message.
Collision resistance It should be difficult to find two different messages that hash to
the same value.
Nonlinearity It should be difficult to create a message that hashes to any given value.
A number of hashing algorithms are available, but the most common are members of
Technet24
||||||||||||||||||||
||||||||||||||||||||
either the Message Digest (MD) or Secure Hashing Algorithm (SHA) families. The Message
Digest family includes the MD4 and MD5 algorithms, which were developed by Ron
Rivest. The SHA family, which contains the SHA-1 and SHA-2 algorithms, among others,
is published by NIST.
Other simple hashing algorithms, such as checksums and cyclic redundancy checks
(CRC), are useful for detecting changes in a set of data; however, they are not very useful
for secure protocols. An attacker can easily change the checksum, as the linear behavior of
these algorithms makes it trivial to determine how the checksum changes, and this
modification of the data is protected so the target has no knowledge of the change.
Asymmetric Signature Algorithms
Asymmetric signature algorithms use the properties of asymmetric cryptography to
generate a message signature. Some algorithms, such as RSA, can be used to provide the
signature and the encryption, whereas others, such as the Digital Signature Algorithm
(DSA), are designed for signatures only. In both cases, the message to be signed is hashed,
and a signature is generated from that hash.
Earlier you saw how RSA can be used for encryption, but how can it be used to sign a
message? The RSA signature algorithm relies on the fact that it’s possible to encrypt a
message using the private key and decrypt it with the public one. Although this
“encryption” is no longer secure (the key to decrypt the message is now public), it can be
used to sign a message.
For example, the signer hashes the message and applies the RSA decryption process to
the hash using their private key; this encrypted hash is the signature. The recipient of the
message can convert the signature using the signer’s public key to get the original hash
value and compare it against their own hash of the message. If the two hashes match, the
sender must have used the correct private key to encrypt the hash; if the recipient trusts
that the only person with the private key is the signer, the signature is verified. Figure 7-13
shows this process.
||||||||||||||||||||
||||||||||||||||||||
Figure 7-13: RSA signature processing
Message Authentication Codes
Unlike RSA, which is an asymmetric algorithm, Message Authentication Codes (MACs) are
symmetric signature algorithms. As with symmetric encryption, symmetric signature
algorithms rely on sharing a key between the sender and recipient.
For example, say you want to send me a signed message and we both have access to a
shared key. First, you’d combine the message with the key in some way. (I’ll discuss how to
do this in more detail in a moment.) Then you’d hash the combination to produce a value
that couldn’t easily be reproduced without the original message and the shared key. When
you sent me the message, you’d also send this hash as the signature. I could verify that the
signature is valid by performing the same algorithm as you did: I’d combine the key and
message, hash the combination, and compare the resulting value against the signature you
sent. If the two values were the same, I could be sure you’re the one who sent the message.
How would you combine the key and the message? You might be tempted to try
something simple, such as just prefixing the message with the key and hashing to the
combined result, as in Figure 7-14.
Technet24
||||||||||||||||||||
||||||||||||||||||||
Figure 7-14: A simple MAC implementation
But with many common hashing algorithms (including MD5 and SHA-1), this would
be a serious security mistake, because it opens a vulnerability known as the length-extension
attack. To understand why, you need to know a bit about the construction of hashing
algorithms.
Length-Extension and Collision Attacks
Many common hashing algorithms, including MD5 and SHA-1, consist of a block
structure. When hashing a message, the algorithm must first split the message into equal-
sized blocks to process. (MD5, for example, uses a block size of 64 bytes.)
As the hashing algorithm proceeds, the only state it maintains between each block is the
hash value of the previous block. For the first block, the previous hash value is a set of
well-chosen constants. The well-chosen constants are specified as part of the algorithm
and are generally important for the secure operation. Figure 7-15 shows an example of
how this works in MD5.
||||||||||||||||||||
||||||||||||||||||||
Technet24
||||||||||||||||||||
||||||||||||||||||||
Figure 7-15: The block structure of MD5
It’s important to note that the final output from the block-hashing process depends
only on the previous block hash and the current block of the message. No permutation is
applied to the final hash value. Therefore, it’s possible to extend the hash value by starting
the algorithm at the last hash instead of the predefined constants and then running
through blocks of data you want to add to the final hash.
In the case of a MAC in which the key has been prefixed at the start of the message, this
structure might allow an attacker to alter the message in some way, such as by appending
extra data to the end of an uploaded file. If the attacker can append more blocks to the end
of the message, they can calculate the corresponding value of the MAC without knowing
the key because the key has already been hashed into the state of the algorithm by the time
the attacker has control.
What if you move the key to the end of the message rather than attaching it to the
front? Such an approach certainly prevents the length-extension attack, but there’s still a
problem. Instead of an extension, the attacker needs to find a hash collision—that is, a
message with the same hash value as the real message being sent. Because many hashing
algorithms (including MD5) are not collision resistant, the MAC may be open to this kind
of collision attack. (One hashing algorithm that’s not vulnerable to this attack is SHA-3.)
Hashed Message Authentication Codes
You can use a Hashed Message Authentication Code (HMAC) to counter the attacks described
in the previous section. Instead of directly appending the key to the message and using the
hashed output to produce a signature, an HMAC splits the process into two parts.
First, the key is XORed with a padding block equal to the block size of the hashing
algorithm. This first padding block is filled with a repeating value, typically the byte 0x36.
The combined result is the first key, sometimes called the inner padding block. This is
prefixed to the message, and the hashing algorithm is applied. The second step takes the
hash value from the first step, prefixes the hash with a new key (called the outer padding
block, which typically uses the constant 0x5C), and applies the hash algorithm again. The
result is the final HMAC value. Figure 7-16 diagrams this process.
||||||||||||||||||||
||||||||||||||||||||
Figure 7-16: HMAC construction
This construction is resistant to length-extension and collision attacks because the
attacker can’t easily predict the final hash value without the key.
Public Key Infrastructure
How do you verify the identity of the owner of a public key in public key encryption?
Simply because a key is published with an associated identity—say, Bob Smith from
London—doesn’t mean it really comes from Bob Smith from London. For example, if I’ve
managed to make you trust my public key as coming from Bob, anything you encrypt to
him will be readable only by me, because I own the private key.
To mitigate this threat, you implement a Public Key Infrastructure (PKI), which refers to
the combined set of protocols, encryption key formats, user roles, and policies used to
manage asymmetric public key information across a network. One model of PKI, the web
of trust (WOT), is used by such applications as Pretty Good Privacy (PGP). In the WOT
model, the identity of a public key is attested to by someone you trust, perhaps someone
you’ve met in person. Unfortunately, although the WOT works well for email, where
you’re likely to know who you’re communicating with, it doesn’t work as well for
automated network applications and business processes.
X.509 Certificates
When a WOT won’t do, it’s common to use a more centralized trust model, such as X.509
certificates, which generate a strict hierarchy of trust rather than rely on directly trusting
peers. X.509 certificates are used to verify web servers, sign executable programs, or
authenticate to a network service. Trust is provided through a hierarchy of certificates
using asymmetric signature algorithms, such as RSA and DSA.
To complete this hierarchy, valid certificates must contain at least four pieces of
information:
Technet24
||||||||||||||||||||
||||||||||||||||||||
• The subject, which specifies the identity for the certificate
• The subject’s public key
• The issuer, which identifies the signing certificate
• A valid signature applied over the certificate and authenticated by the issuer’s private key
These requirements create a hierarchy called a chain of trust between certificates, as
shown in Figure 7-17. One advantage to this model is that because only public key
information is ever distributed, it’s possible to provide component certificates to users via
public networks.
Figure 7-17: The X.509 certificate chain of trust
Note that there is usually more than one level in the hierarchy, because it would be
unusual for the root certificate issuer to directly sign certificates used by an application.
The root certificate is issued by an entity called a certificate authority (CA), which might be
a public organization or company (such as Verisign) or a private entity that issues
certificates for use on internal networks. The CA’s job is to verify the identity of anyone it
issues certificates to.
Unfortunately, the amount of actual checking that occurs is not always clear; often, CAs
||||||||||||||||||||
||||||||||||||||||||
are more interested in selling signed certificates than in doing their jobs, and some CAs do
little more than check whether they’re issuing a certificate to a registered business address.
Most diligent CAs should at least refuse to generate certificates for known companies, such
as Microsoft or Google, when the certificate request doesn’t come from the company in
question. By definition, the root certificate can’t be signed by another certificate. Instead,
the root certificate is a self-signed certificate where the private key associated with the
certificate’s public key is used to sign itself.
Verifying a Certificate Chain
To verify a certificate, you follow the issuance chain back to the root certificate, ensuring
at each step that every certificate has a valid signature that hasn’t expired. At this point,
you decide whether you trust the root certificate—and, by extension, the identity of the
certificate at the end of the chain. Most applications that handle certificates, like web
browsers and operating systems, have a trusted root certificate database.
What’s to stop someone who gets a web server certificate from signing their own
fraudulent certificate using the web server’s private key? In practice, they can do just that.
From a cryptography perspective, one private key is the same as any other. If you based the
trust of a certificate on the chain of keys, the fraudulent certificate would chain back to a
trusted root and appear to be valid.
To protect against this attack, the X.509 specification defines the basic constraints
parameter, which can be optionally added to a certificate. This parameter is a flag that