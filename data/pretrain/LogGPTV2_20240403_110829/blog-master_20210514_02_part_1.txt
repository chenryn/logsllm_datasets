## PGSync - PostgreSQL 逻辑订阅同步到 ElasticSearch      
### 作者      
digoal      
### 日期      
2021-05-14       
### 标签      
PostgreSQL , 逻辑订阅    
----      
## 背景      
pgsync开源tool, 通过逻辑订阅将PG增量数据同步到ElasticSearch.      
https://github.com/toluaina/pgsync  
需要注意PG目前的版本不支持slot failover, 如果你的PG是通过流复制实现的HA, 有主从结构的话, 那么一旦发生HA, 逻辑订阅的slot将丢失. 这个非常不友好.      
为了解决这个问题目前阿里云RDS PG内核层面改进支持了slot failover, 也就是发生HA, slot 也会failover. 不会导致逻辑订阅问题.    
如果你用的是社区版本, 在云端使用, 建议使用云盘存储数据, 通过云盘来实现多副本高可靠. 同时建立standby(灾备, 不做自动切换.)    
# PGSync    
[![PyPI version](https://badge.fury.io/py/pgsync.svg)](https://badge.fury.io/py/pgsync)    
[![Build status](https://github.com/toluaina/pgsync/workflows/Build%20and%20Test/badge.svg)](https://github.com/toluaina/pgsync/actions)    
[![Documentation status](https://readthedocs.org/projects/pgsync/badge/?version=latest)](https://pgsync.readthedocs.io/en/latest/?badge=latest)    
[![Python versions](https://img.shields.io/pypi/pyversions/pgsync)](https://pypi.org/project/pgsync)    
[![Downloads](https://img.shields.io/pypi/dm/pgsync)](https://pypi.org/project/pgsync)    
[![codecov](https://codecov.io/gh/toluaina/pgsync/branch/master/graph/badge.svg?token=cvQzYkz6CV)](https://codecov.io/gh/toluaina/pgsync)    
## PostgreSQL to Elasticsearch sync    
[PGSync](https://pgsync.com) is a middleware for syncing data from [Postgres](https://www.postgresql.org) to [Elasticsearch](https://www.elastic.co/products/elastic-stack) effortlessly.    
It allows you to keep [Postgres](https://www.postgresql.org) as your source of truth and    
expose structured denormalized documents in [Elasticsearch](https://www.elastic.co/products/elastic-stack).    
Changes to nested entities are propagated to [Elasticsearch](https://www.elastic.co/products/elastic-stack).    
PGSync's advanced query builder then generates optimized SQL queries     
on the fly based on your schema.    
PGSync's advisory model allows you to quickly move and transform large volumes of data quickly whilst maintaining relational integrity.    
Simply describe your document structure or schema in JSON and [PGSync](https://pgsync.com) will     
continuously capture changes in your data and load it into [Elasticsearch](https://www.elastic.co/products/elastic-stack)     
without writing any code.    
[PGSync](https://pgsync.com) transforms your relational data into a structured document format.    
It allows you to take advantage of the expressive power and scalability of     
[Elasticsearch](https://www.elastic.co/products/elastic-stack) directly from [Postgres](https://www.postgresql.org).     
You don't have to write complex queries and transformation pipelines.    
PGSync is lightweight, flexible and fast.    
[Elasticsearch](https://www.elastic.co/products/elastic-stack) is more suited as as secondary denormalised search engine to accompany a more traditional normalized datastore.    
Moreover, you shouldn't store your primary data in [Elasticsearch](https://www.elastic.co/products/elastic-stack).    
So how do you then get your data into [Elasticsearch](https://www.elastic.co/products/elastic-stack) in the first place?     
Tools like [Logstash](https://www.elastic.co/products/logstash) and [Kafka](https://kafka.apache.org) can aid this task but they still require a bit     
of engineering and development.    
[Extract Transform Load](https://en.wikipedia.org/wiki/Extract,_transform,_load) and [Change data capture](https://en.wikipedia.org/wiki/Change_data_capture) tools can be complex and require expensive engineering effort.    
Other benefits of PGSync include:    
- Real-time analytics    
- Reliable primary datastore/source of truth    
- Scale on-demand    
- Easily join multiple nested tables    
#### Why?    
At a high level, you have data in a Postgres database and you want to mirror it in Elasticsearch.      
This means every change to your data (***Insert***, ***Update***, ***Delete*** and ***Truncate*** statements) needs to be replicated to Elasticsearch.     
At first, this seems easy and then it's not. Simply add some code to copy the data to Elasticsearch after updating the database (or so called dual writes).    
Writing SQL queries spanning multiple tables and involving multiple relationships are hard to write.    
Detecting changes within a nested document can also be quite hard.    
Of course, if your data never changed, then you could just take a snapshot in time and load it into Elasticsearch as a one-off operation.    
PGSync is appropriate for you if:    
- [Postgres](https://www.postgresql.org) is your read/write source of truth whilst [Elasticsearch](https://www.elastic.co/products/elastic-stack) is your     
read-only search layer.    
- You need to denormalize relational data into a NoSQL data source.    
- Your data is constantly changing.    
- You have existing data in a relational database such as [Postgres](https://www.postgresql.org) and you need    
a secondary NoSQL database like [Elasticsearch](https://www.elastic.co/products/elastic-stack) for text-based queries or autocomplete queries to mirror the existing data without having your application perform dual writes.    
- You want to keep your existing data untouched whilst taking advantage of    
the search capabilities of [Elasticsearch](https://www.elastic.co/products/elastic-stack) by exposing a view of your data without compromising the security of your relational data.    
- Or you simply want to expose a view of your relational data for search purposes.    
#### How it works    
PGSync is written in Python (supporting version 3.6 onwards) and the stack is composed of: [Redis](https://redis.io), [Elasticsearch](https://www.elastic.co/products/elastic-stack), [Postgres](https://www.postgresql.org), and [SQlAlchemy](https://www.sqlalchemy.org).    
PGSync leverages the [logical decoding](https://www.postgresql.org/docs/current/logicaldecoding.html) feature of [Postgres](https://www.postgresql.org) (introduced in PostgreSQL 9.4) to capture a continuous stream of change events.    
This feature needs to be enabled in your [Postgres](https://www.postgresql.org) configuration file by setting in the postgresql.conf file:    
```    
> wal_level = logical    
```    
You can select any pivot table to be the root of your document.    
PGSync's query builder builds advanced queries dynamically against your schema.    
PGSync operates in an event-driven model by creating triggers for tables in your database to handle notification events.    
*This is the only time PGSync will ever make any changes to your database.*    
**NOTE**: **If you change the structure of your PGSync's schema config, you would need to rebuild your Elasticsearch indices.**    
There are plans to support zero-downtime migrations to streamline this process.    
#### Quickstart    
There are several ways of installing and trying PGSync    
 - [Running in Docker](#running-in-docker) is the easiest way to get up and running.    
 - [Manual configuration](#manual-configuration)     
##### Running in Docker    
To startup all services with docker.    
Run:    
```    
$ docker-compose up    
```    
Show the content in Elasticsearch    
```    
$ curl -X GET http://[elasticsearch host]:9201/reservations/_search?pretty=true    
```    
##### Manual configuration    
- Setup    
  - Ensure the database user is a superuser     
  - Enable logical decoding. You would also need to set up at least two parameters at postgresql.conf    
    ```wal_level = logical```    
    ```max_replication_slots = 1```    
- Installation    
  - ```$ pip install pgsync```     
  - Create a [schema.json](https://github.com/toluaina/pgsync/blob/master/examples/airbnb/schema.json) for you document representation    
  - Bootstrap the database (one time only) **_```bootstrap --config schema.json```_**    
  - Run the program with **_```pgsync --config schema.json```_** or as a daemon **_```pgsync --config schema.json -d```_**    
#### Features    
Key features of PGSync are:    
- Easily denormalize relational data.     
- Works with any PostgreSQL database (version 9.6 or later).     
- Negligible impact on database performance.    
- Transactionally consistent output in Elasticsearch. This means: writes appear only when they are committed to the database, insert, update and delete operations appear in the same order as they were committed (as opposed to eventual consistency).    
- Fault-tolerant: does not lose data, even if processes crash or a network interruption occurs, etc. The process can be recovered from the last checkpoint.    
- Returns the data directly as Postgres JSON from the database for speed.    
- Supports composite primary and foreign keys.    
- Supports an arbitrary depth of nested entities i.e Tables having long chain of relationship dependencies.    
- Supports Postgres JSON data fields. This means: we can extract JSON fields in a database table as a separate field in the resulting document.    
- Customizable document structure.    
#### Requirements    
- [Python](https://www.python.org) 3.6+    
- [Postgres](https://www.postgresql.org) 9.6+    
- [Redis](https://redis.io) 3.1.0    
- [Elasticsearch](https://www.elastic.co/products/elastic-stack) 6.3.1+    
- [SQlAlchemy](https://www.sqlalchemy.org) 1.3.4+    
#### Example    