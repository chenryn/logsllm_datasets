process-ack. If the current user is the new group member, the
"add-ack" message is accompanied by the direct message that
we constructed in process-add; this direct message dmsg contains
the encrypted ratchet state of the sender of the "add-ack", so we
decrypt it on lines 3â€“5.
On line 6 of process-add-ack, we check if the local user was
already a group member at the time the "add-ack" was sent (which
may not be the case when there are concurrent additions). If so,
on line 7 we compute a new update secret I for the sender of
the "add-ack" by calling update-ratchet with the constant string
"add". In the case of the new member, the ratchet state was just
previously initialized on line 5. This ratchet update allows all group
members, including the new one, to derive each memberâ€™s update
secret for the add operation, but it prevents the new group member
from obtaining any update secret from before they were added.
6.2.5 Handling Concurrency. We have explained all of the func-
tions in Figure 4, except for skipping a few lines that are related to
handling concurrency. In particular, care is required when an add
operation occurs concurrently with an update, remove, or another
add operation. We now discuss those details.
We want all intended recipients to learn every update secret,
since otherwise some users would not be able to decrypt some
messages, despite being a group member. For example, consider a
group with members {A, B, C} as illustrated in Figure 5, and say
A performs an update while concurrently C adds D to the group.
When A distributes a new seed secret through 2SM-encrypted direct
messages, D will not be a recipient of one of those direct messages,
since A did not know about Dâ€™s addition at the time of sending.
D will therefore execute lines 6â€“7 of process-seed, and it cannot
derive any of the member secrets for this update. When B updates
its KDF ratchet using Aâ€™s seed secret, it will compute an update
secret that D does not know, and D will not be able to decrypt Bâ€™s
subsequent application messages.
In this example, B may receive the add and the update in either
order. If B processes Aâ€™s update first, the seed secret from A is al-
ready incorporated into Bâ€™s ratchet state at time time of adding D;
since B sends this ratchet state to D along with its "add-ack" mes-
sage, no further action is needed. On the other hand, if B processes
the addition of D first (as in Figure 5), then when B subsequently
processes Aâ€™s update, B must take the member secret it derives
from Aâ€™s seed secret and forward it to D, so that D can compute
Bâ€™s update secret for Aâ€™s update.
This forwarding takes place on lines 14â€“19 of process-seed,
which is called as part of processing an "update" or "remove"
message. Recall that on line 1 we set recipients to be the set of
group members at the time the update/remove was sent, except for
the sender. On line 14 we then compute the current set of members
according to the local node. The set difference on line 16 thus com-
putes the set of users whose additions have been processed by the
local user, but who were not yet known to sender of the update.
If there are any such users, we construct a direct message to
each of them. One of the member secrets we computed on line 9
is the member secret for the local user. On lines 17â€“19 we 2SM-
encrypt that member secret for each of the users who need it. This
set forward is sent as direct messages along with the "ack" (the
dashed arrow in Figure 5). The recipient of such a message handles
this case on line 7â€“8 of process-ack, where the forwarded member
secret is decrypted and then used to update the ratchet for the
"ack" sender. Note that this forwarding behavior does not violate
forward secrecy: an application message can still only be decrypted
by those users who were group members at the time of sending.
Another scenario that needs to be handled is when two users are
concurrently added to the group. For example, in a group consisting
initially of {A, B}, say A adds C to the group, while concurrently
B adds D. User C first processes its own addition and welcome
message, and then processes Bâ€™s addition of D. However, since C
was not a group member at the time B sent its "add" message, C
does not yet have Bâ€™s ratchet state, so C cannot derive an update
secret for Bâ€™s "add" message. The condition on line 5 of process-add
is false and so C does not derive an update secret on lines 6â€“8.
When B finds out about the fact that A has added C, B sends C its
ratchet state as usual (line 12 of process-add), so C can initialize its
copy of Bâ€™s ratchet as before (lines 4â€“5 of process-add-ack). Simi-
larly, when D finds out about the fact that A has added C, D sends its
ratchet state to C along with the "add-ack" message. The existing
logic therefore handles the concurrent additions: after all acks have
been delivered, C and D have both initialized their copies of all four
ratchets, and so they are able to decrypt application messages that
any group member sent after processing their addition.
7 DCGKA SECURITY ANALYSIS
We capture the security properties of DCGKA and the adversaryâ€™s
capabilities formally in the security game in Appendix A. In sum-
mary, the adversary is given access to oracles to cause group mem-
bers to call the protocol algorithms, deliver messages in causal
order, and compromise group members, revealing their current
state. The adversary is also given a transcript of all messages sent.
However, due to the underlying Authenticated Causal Broadcast,
the adversary is not allowed to modify messages, deliver them out
Session 6D: Authentication and Privacy CCS â€™21, November 15â€“19, 2021, Virtual Event, Republic of Korea2033of causal order, or forge the sender at the DCGKA level. The game
is a key indistinguishability game, in which the adversary may
challenge update secrets, revealing either the actual update secret
or a random value, depending on a random bit b. We show that any
adversary has only a negligible advantage in guessing b.
We do not allow the adversary to send arbitrary messages signed
by a compromised user: as discussed in Section 2.1, we assume
that group members correctly follow the protocol, and we do not
provide post-impersonation security. However, the adversary may
perform arbitrary membership changes. To prevent trivial attacks
in which the adversary compromises a group member and then
decrypts a message intended for that member, the adversary wins
the game only if a safety predicate dom-safe evaluates to true on the
queries made by the adversary. This predicate is defined formally
in Figure 13 in Appendix C.
If the adversary compromises multiple users, and these users
then perform concurrent PCS updates or removals, then the com-
promise is not healed until after a subsequent dominating update
or removal, which is a message that causally succeeds all of them.
dom-safe captures this fact. For example, if multiple users are re-
moved concurrently, and a group member sends an application
message after receiving both remove messages but no subsequent
updates or removals, then the removed users can collude to decrypt
the application message. This slightly weaker-than-optimal post-
compromise security is not a problem in practice because group
members can always detect such a situation and choose to send a
PCS update before their next application message, if no other group
member has done so already. Also, note that if the adversary only
compromises a single group member, that member is healed by
their next PCS update, even if there are other concurrent updates
(in contrast to some proposed techniques for MLS [8, Â§5], [41]).
We define a non-adaptive (t, q, n)-adversary for the DCGKA game
to be an adversary A that runs in time at most t, makes at most q
queries, references at most n IDs, and must specify the sequence
of queries it plans to make in advance, before seeing the result of
any queries. Given a DGM scheme DGM, we say that our protocol
is non-adaptively (t, q, n, dom-safe, DGM, Ïµ)-secure if for all non-
adaptive (t, q, n)-adversaries A, the advantage
(cid:12)(cid:12)(cid:12)(cid:12)Pr[A wins] âˆ’ 1
2
(cid:12)(cid:12)(cid:12)(cid:12) â‰¤ Ïµ
AdvDCKGA,dom-safe,DGM
(Definition 5 in Appendix A).
dcgka-na
(A) := 2
Theorem 4. Let DGM be a DGM function satisfying the assumptions
stated in Section 6.2, and assume user additions are unique. Model
HKDF as a random oracle, let Î» be the bit length of random values
output by KGen and HKDF, and let the 2SM protocol be (tâ€², q, Ïµ2sm)-
secure in the sense of Appendix B. Then the protocol in Figure 4 is
non-adaptively (t, q, n, dom-safe, DGM, Ïµ)-secure, for t â‰ˆ tâ€² and
(cid:18)qn
(cid:19)
2
(cid:19)
2âˆ’Î»
.
(cid:18)
Ïµ = 2q
2
Ïµ2sm + qnt2âˆ’Î» +
n
The proof appears in Appendix C. The basic idea is that each
dominating messageâ€™s seed secret is only sent to current group
members over uncompromised 2SM channels, and hence those seed
secrets are unknown to the adversary. The same then holds for the
challenged update secrets, each of which directly incorporates some
dominating messageâ€™s seed secret. Forward secrecy is guaranteed
by the group membersâ€™ KDF ratchets and by deleting secrets after
use.
Malicious group members and impersonating adversaries. Our
analysis assumes that all group members correctly follow the pro-
tocol, and that the adversary does not use compromised state to
impersonate a group member. Malicious members can trivially
cause a denial of service by sending different seed secrets to differ-
ent users in an update message, causing their ratchets to become
inconsistent. Likewise, an impersonating adversary may cause the
group to ignore future PCS updates from the impersonated user, or
add other devices they own to the group.
However, malicious members and impersonating adversaries
cannot violate the protocol in a way that allows them to decrypt
messages after they, and any devices they add, are removed from
the group (unlike the â€œdouble-joinâ€ attacks on early versions of
MLS [8, Â§5]). Informally, when a user A is removed, the other group
members distribute a fresh seed secret over 2SM channels. Prior
messages by A have no effect on these 2SM channels, even if A
violates the protocol, so A is not able to obtain the seed secret.
8 PERFORMANCE
In this section we examine the performance of our protocol as a
function of n, the number of group members.
8.1 Asymptotic Performance Analysis
In general, causal broadcast requires additional metadata in every
message to establish the causal ordering. The size of this metadata
is proportional to the number of concurrently sent messages by
different group membersâ€”ğ’ª(n) in the worst case [11]. However,
we are able to reduce this overhead to zero because our DCGKA
protocol does not require acks to be delivered in causal order with
respect to each other. Instead, DCGKA only requires that each group
memberâ€™s messages are delivered in order, and that acknowledg-
ment messages are delivered after the message they acknowledge.
The acknowledgment messages and the sequence numbers that are
already contained in DCGKA messages in plaintext are sufficient
to ensure this order.
Additionally, Authenticated Causal Broadcast requires a signa-
ture to authenticate the sender of each message, adding a constant-
size overhead to each message. The AEAD for application messages
and 2SM encryption for direct messages also add a constant over-
head. Each direct message requires a constant number of public-key
operations on both the sender and the recipient side.
Each create, update, or remove DCGKA operation broadcasts
one constant-size control message and sends ğ’ª(n) constant-size
direct messages. Each other group member replies by broadcasting
a constant-size acknowledgment, resulting in ğ’ª(n) network traf-
fic overall. The operation requires ğ’ª(n) public key operations at
the sender, and ğ’ª(1) public key operations for each other group
member.
Add operations send one constant-size control message and one
direct message (the welcome message to the new user), and require
ğ’ª(1) public key operations at the sender. Each other group member
broadcasts a constant-size acknowledgment and sends one constant-
size direct message to the new member, resulting in ğ’ª(n) network
traffic overall. The acknowledgments require in total ğ’ª(n) public
Session 6D: Authentication and Privacy CCS â€™21, November 15â€“19, 2021, Virtual Event, Republic of Korea2034key operations by the added user and ğ’ª(1) public key operations
by each other group member. In the above protocol description, the
welcome message contains the history of group membership opera-
tions and acks, but in practice the acks can be replaced with a DAG
representation of the causal order, as in Matrixâ€™s DGM scheme [21],
plus a description of the maximal messages acknowledged by each
user. The welcome message thus has size ranging between ğ’ª(nâ€²)
(no concurrency) and ğ’ª((nâ€²)2) (maximum concurrency), where nâ€²
is the total number of users that have participated in the group
since it was created. This approach is practical for the group sizes
we target, as demonstrated by the protocolâ€™s use in Matrix.
As an optimization, a group member can choose to delay sending
acknowledgments until the next time it performs a PCS update or
membership operation, or wants to send an application message. By
coalescing the delayed acknowledgments and the new operation or
message into a single message with a single signature, the number
of public key operations per ack is effectively reduced to zero. This
optimization does not affect the security properties of the protocol.
Our analysis assumes that the underlying network supports
broadcast messaging, or at least that the network cost scales with
broadcast message size instead of only with unicast message size.
Indeed, broadcast messages are more efficient than sending distinct
unicast messages in many networks, by reducing, e.g., the senderâ€™s
network usage, storage cost on intermediate nodes, or inter-server
traffic in a federated system. If the network does not support broad-
cast, each broadcast message must become ğ’ª(n) unicast messages.
However, these ğ’ª(n) messages need not all be sent independently:
many group members (and, optionally, some number of untrusted
servers) can be involved in disseminating a broadcast message by
using a suitable network topology, e.g. a mesh network, gossip
protocol [27] or multicast tree [20]. These strategies are commonly
used in practical distributed systems to achieve broadcast at con-
stant cost per node, regardless of group size.
The minimum storage requirement of our algorithm is ğ’ª(n)
for the current list of group members and the ratchet state for
each member. Three elements of the state can exceed ğ’ª(n): the
DGM state (Î³ .history), member secrets that have not yet been used
because not all group members have acknowledged their source
messages, and the 2SM states. The state size for Matrixâ€™s DGM
scheme was discussed above. The member secretsâ€™ state size is
proportional to the number of acknowledgments that have not yet
been received, which can in principle grow without bound, e.g., if
some group members never come online. The 2SM protocols add
state size bounded by the state size considered so far.
8.2 Implementation and Empirical
Measurements
We have implemented a prototype of our DCGKA algorithm in
around 3500 lines of Java. The implementation is available as an
open-source project on GitHub.1 We use a Java implementation of
Curve25519 [7];2 all other cryptographic primitives use the built-
in cryptography providers of the JVM. For the two-party secure
messaging protocol, we use a protocol described informally by Jost
et al. [23, Â§2.2] as a simplification of their full protocol, which we
1https://github.com/trvedata/key-agreement
2https://github.com/trevorbernard/curve25519-java
Figure 6: The total data volume sent by all clients while ex-
ecuting each type of operation, for groups ranging from 8
to 128 members. Broadcast messages are counted as a single
outgoing message.
Figure 7: The CPU time (on a single core) to execute an op-
eration, per sender or recipient, for groups ranging from 8
to 128 members. The error bars show the standard deviation
over 25 independent executions.
describe formally and prove secure in the extended version of this
paper [42]. We ran the evaluation using OpenJDK 8 on a single
machine with 16 GiB memory and an 8-core Intel i7 processor.
Our implementation demonstrates that the performance of our
protocol is good enough for practical use in medium-sized groups of
up to 128 members, even with an implementation that is not highly
optimized. In our experiments we execute multiple test scenarios
consisting of an initial group setup followed by a single group
membership, PCS update, or message send operation. We measure
the network traffic and CPU time resulting from that operation
(including the processing of messages at all group members, and
including any acknowledgments). We run all clients as separate
threads in a single process and simulate a network by passing
messages between threads as serialized byte arrays. Hash functions
and symmetric encryption use a 128-bit security level.
Figure 6 shows that the total network traffic for creating a group,
adding a group member, or removing a group member grows lin-
early with the group size, as expected. Creating a new group of 128
members results in 43.4 kB being sent, and PCS updates (39.6 kB)
and the group membership operations add (75.5 kB) and remove
(39.3 kB) are in the same order of magnitude. Sending an applica-
tion message incurs a constant overhead of 139 bytes regardless of
group size. For our evaluation we send a 32 byte payload.
8163264128Group size103104105Total data sent [bytes]createaddremovemessageupdate8163264128Group size10âˆ’1100101102Sender: CPU time [ms]8163264128Group sizeRecipients: CPU time [ms]createaddremovemessageupdateSession 6D: Authentication and Privacy CCS â€™21, November 15â€“19, 2021, Virtual Event, Republic of Korea2035Figure 7 shows that the average computational effort per sender
or recipient does not exceed 100 ms for group creation, PCS up-
date, and membership operations on groups up to 128 members.3
For groups up to 64 members, the CPU times are less than 50 ms.
Sending and receiving application messages is very fast, taking less
than 1 ms regardless of group size. Comparing these results with
an average mobile network latency of around 50 ms, these results
support our conclusion that DCGKA is practicable for real-world
applications with medium-sized groups.
9 CONCLUSION