locations [32].
III. BACKGROUND
Before presenting our BATE attack against CFG, we need
to recall some basic concepts. Here, we ﬁrst introduce the
main concepts of Control Flow Integrity (Section III-A). We
then explain how Control Flow Guard works (Section III-B).
A. Control Flow Integrity
Control Flow Integrity (CFI) [4] is a security policy that
aims at preventing adversaries from redirecting control ﬂow
to arbitrary locations. Many CFI implementations have been
proposed in the literature, with varying degrees of precision
and performance [7]. CFI computes the application’s control
ﬂow graph statically, either from source during compila-
tion or directly from binaries. At runtime, control ﬂow is
monitored to ensure it sticks to the computed graph. This
can be done by performing checks on instructions that
trasfer control, to ensure they have not been corrupted by
an attacker. Control transfers can be divided in forward
(calls and jumps) and backwards (returns), based on the
direction of their edge in the control ﬂow graph. Depending
on what kind of transfers are protected, CFI can be forward-
edge, backward-edge or both. Forward-edge CFI protects
jumps and calls, which can be direct or indirect. Direct
branches embed their destination in the instruction itself.
Assuming that executable memory is not writable, which
can be ensured by W⊕X, those cannot be corrupted by
an attacker. Indirect branches load their destination from
a memory location, for example when calling through a
function pointer. An attacker that can overwrite the code
pointer in memory can redirect the branch. In Figure 1
we show an example of such attack, and how CFI can
prevent it. In this example, Figure 1a shows code without
CFI enforcement, leading to a successful control ﬂow hijack.
Figure 1b, on the other hand, shows CFI enforcement and
detection of the attack.
In more detail, in Figure 1a a memory corruption vul-
nerability is used to overwrite fptr2 and hijack the second
call to evil instead of the intended target func3. Indirect
calls are extremely common in object-oriented code, where
they are used to implement virtual method calls through
virtual tables. Many modern attacks rely on virtual table
corruption, in order to easily divert control ﬂow [31]. To
avoid this, CFI checks indirect branches at runtime to
ensure that the computed graph has an edge for the transfer.
This can be done by statically determining the set of valid
targets for a call,
i.e., the points-to set of the function
pointer, and then checking the destination against it at
runtime. Figure 1b shows the same attack as before, this
time with CFI. The only allowed target for fptr1 is func1,
while fptr2 can point to func2 or func3. Indeed, before
the calls, there are CFI checks. A call to evil through
fptr2 violates the CFI policy, so the corruption is detected
and can be handled, typically by killing the process.
Unfortunately, precise and sound points-to analysis is
hard and, in the general case, undecidable [30]. As such,
Writable data
fptr1:
&func1
fptr2:
&func3
&evil
Memory
corruption
···
call [fptr1]
···
call [fptr2]
···
(a) Without CFI.
Writable data
fptr1:
&func1
fptr2:
&func3
&evil
···
cfi_call [fptr1]
···
cfi_call [fptr2]
···
Memory
corruption
(cid:66)CFI
violation
Intended callees
func1:
···
ret
func3:
···
ret
evil:
···
Attacker code
fptr1 points-to set
func1:
···
ret
fptr2 points-to set
func2:
···
ret
func3:
···
ret
evil:
···
Attacker code
(b) With CFI.
Fig. 1.
Example of function pointer hijacking, with and without CFI
techniques in place. If there is no CFI, control ﬂow goes to the pointer
speciﬁed by the attacker; if CFI is in place, attacker would be likely pointing
to an invalid target, and CFI successfully prevents malicious redirection.
the set of allowed targets is an approximation of the actual
one. To indicate the level of approximation, CFI policies are
either ﬁne-grained or coarse-grained. While the meaning of
these terms is not standardized in the literature, we use
ﬁne-grained CFI to mean a policy where each call site has
a distinct valid target set, which is as precise as possible. In
other words, only paths that the programmer intended can
be taken. In coarse-grained CFI, there is a single valid target
set, consisting of all the targets of indirect branches in the
entire program. This clearly extends the attack surface, as
an adversary can call unintended functions. For example, if
a coarse-grained CFI was used in Figure 1b, func{1,2,3}
would all be valid targets for both fptr1 and fptr2. There
are also CFI schemes that employ an intermediate number
of equivalence classes: for example, IFCC [43] can group
valid targets by number of arguments.
Backward-edge CFI protects return instructions. When
a call
is performed, the address of the next instruction
in the caller is stored on the stack, to be later used as a
4
return address. Attacks such as stack overﬂows allow an
adversary to overwrite the return address, gaining control
of the execution ﬂow when the callee returns. Statically
determining the set of valid return locations is not very
precise, as a function can be called from many different
places. For this reason, backward-edge CFI implementations
often make use of a shadow stack [12], which resides in a
protected memory area and stores a copy of the real return
address. On returns, the return address fetched from the
real stack can be compared to the one from the shadow
stack and the program can detect whether it was tampered
with.
B. Control Flow Guard
Researchers and companies provided several practical
CFI implementations. One of the prominent ones, because
of widespread diffusion in all Windows operating systems
from 8.1 onwards, is Control Flow Guard (CFG). CFG is a
coarse-grained forward-edge CFI implementation that lever-
ages an instrumentation involving the compiler, the kernel
and the ntdll.dll library [46]. It protects from hijacked
forward branches such as function calls and longjmp
buffers, but does not offer backward-edge CFI, which guards
return addresses. CFG relies on a process-wide bitmap
to perform fast integrity checks, which is similar to the
approach used by MIP [28].
We describe in more detail in the following how CFG
works: we start from code analysis and compiler instrumen-
tation at compile time (Section III-B1), then explain the core
bitmap employed technique (Section III-B2), and ﬁnally
detail how runtime integrity checks work (Section III-B3).
1) Compiler instrumentation: When building a module
(executable or library), the compiler analyzes the source
code and generates a valid target table for indirect branches,
that is, the set of all entry points that can be valid indirect
targets. By default, this analysis includes exports to support
dynamic symbol resolution. However, a feature named ex-
port suppression allows the programmer to make speciﬁc
exports invalid targets. The valid target table is embedded
into the binary’s read-only data section. The compiler also
sets up two global function pointers in the same section,
for check and dispatch functions. Those pointers will be
later ﬁlled in by the kernel when loading the module and
pointed to implementations for CFG checks. Both functions
take an indirect branch target and check whether it is
valid. If this is the case, the check function simply returns,
while the dispatch function jumps to the target. Otherwise,
both terminate the process with a security violation. To
support pre-8.1 Windows, the compiler provides dummy
implementations with which the pointers are initialized, to
be later overridden by the loader. The compiler uses those
functions to implement two modes:
1)
2)
check mode, where a call to the check function is
injected before indirect branches;
dispatch mode, where indirect calls are replaced by
a call to the dispatch function.
Both modes use the same checking algorithm and are equiv-
alent for our purposes. For 32-bit modules, the compiler can
insert further checks to ensure that the stack pointer does
not change after the indirect call [45], [46]. This mitigates
stack desynchronization attacks based on mismatching call-
ing conventions [17]. Dispatch mode, which is common
on 64-bit [20], is only distinguished by the implementation
performing the target branch instead of the caller.
2) Module loading: When the kernel loads a CFG-aware
module, it fetches the valid target table and encodes this
information into the CFG bitmap, a continuous block of
read-only reserved virtual memory (32MB on 32-bit, 2TB on
64-bit) in the process’ addressing space. Each pair of bits
in the bitmap bijectively maps to a 16-byte aligned address
range of 16 bytes in size, so that every address in user space
maps to one and only one bit pair. Thus, each range can
have one of four states associated with it:
•
•
•
•
00 - no address in this range is a valid target;
01 - this range contains an export-suppressed tar-
get;
10 - the only valid target is 16-byte aligned (that is,
the ﬁrst address in the range);
11 - all addresses in this range are valid.
The only virtual bitmap pages actually backed by physical
memory are those that are not completely zeroed. Moreover,
since even when countermeasures such as Address Space
Layout Randomization are in place dynamic libraries are
only relocated at their ﬁrst load, bitmap regions for libraries
used by multiple processes can share their physical backing.
As such, the committed memory footprint is acceptable. If
a module is not CFG-aware, all the bit pairs belonging to
its address space will be set to 11. This allows intermodule
calls from a module that employs CFG to one that does not,
which is essential to preserve backwards compatibility. The
loader also points the check and dispatch function pointers
to implementations within ntdll.
3) Runtime: After loading a module, its bitmap region is
not necessarily static. It can be altered in two ways:
1)
2)
by allocating executable memory, whose bitmap
bits will all be set;
by changing speciﬁc bits through system calls.
A typical case that requires bitmap modiﬁcation is when
code is generated via a just-in-time compiler. Any change
is local to the process, so modifying a shared bitmap page
will result in a private copy being mapped.
To clarify the CFG mechanism, we show in Figure 2
how call checks happen at runtime (in check mode). In this
example, the fptr function pointer resides in a writable
data section, so it could be vulnerable to corruption. The
compiler has protected an indirect call to it via check mode
by prepending a call to the CFG check function. First, the
system fetches the indirect target from fptr and stores
it into the rcx register, which is where the check function
expects it to be. Then, the check function is called indirectly.
This is safe as long as the check and dispatch pointer are
read-only. The check call will jump into ntdll. Here, the
position of the bit pair (highlighted in the ﬁgure) for the
target address into the bitmap is calculated via fast bitwise
operations and the bits are fetched. If the pair resides in an
5
unmapped bitmap page, a memory violation exception will
occur, which is handled by a top-level handler in ntdll.
The handler contains a special case that checks whether the
violation happened within the CFG checking code. If it did,
then the check is resumed as if the page was completely
set to zero, which will lead to a failure since 00 means that
there are no valid targets. The target address is checked
against the bit pair to determine whether it is valid. In the
example the pair is 10, which means the check will pass
only if the target is 16-byte aligned. If the check fails the
process is terminated, otherwise the check function returns
to the caller, which ﬁnally issues the original indirect call.
In dispatch mode, the target address would be passed in
the rax register and the call would be issued directly by
ntdll.
Process
CFG bitmap
. . . 10 00 10 00 00
11 . . .
•
corrupted indirect call, both on 32-bit and 64-bit
systems.
Adversarial computation. The attacker can perform
runtime calculations, for example by targeting a
scripting language interpreter such as JavaScript.
While the seminal work assumed that the attacker had total
control over memory contents, our attack only requires the
ability to corrupt indirect calls. The stack control require-
ment does not imply further memory corruption needs, as
we gain it via controlled arguments.
Defensive Capabilities. The following defenses are in place:
• W⊕X. By default, every memory mapping is either
writable or executable, but not both. This stops
an attacker from modifying code (because it is
not writable) or injecting code (because it is not
executable).
Instrumented code
···
mov rcx, [fptr]
call [check_fptr]
call rcx
···
Module
check_fptr:
0x55667788
Read-only data
Writable data
fptr:
0x11223344
CFG checks
(ntdll)
•
Randomization. The memory layout of the program
is randomized, for example via Address Space Lay-
out Randomization (ASLR).
Call target
V. BATE: OUR ATTACK TO CFG
Fig. 2.
Example of CFG check mode of a function call: ﬁrst, the check
function in ntdll is called and the bit pair from the bitmap is checked; if
the value from the bitmap allows the call target, the check function returns
and the function is called. Otherwise, a security violation is issued.
IV. THREAT MODEL AND ASSUMPTIONS
Overall, our threat model is even stricter than what is
considered in the CFI seminal work [4]. We assume the
application’s control ﬂow integrity protection is provided
solely by CFG: therefore, other CFI implementations and
other integrity protections, such as VTint [48], are not
in place.
Regarding offensive capabilities, our attacker
is less powerful than usual: we assume the attacker has
knowledge of the memory layout and a limited form of
memory corruption, but we do not require arbitrary write
capability. Regarding defensive capabilities by the defender,
differently from the threat model considered in [4], we
consider memory layout randomization to be in place, as it
is nowadays a common countermeasure.
Offensive Capabilities. The attacker has the following ca-
pabilities:
• Memory layout knowledge. The attacker can know
the layout of the program’s addressing space, for
example by reading pointers from memory.
•
•
Indirect call corruption. The attacker can leverage
some memory corruption vulnerability in the pro-
gram to hijack the destination of indirect calls.
Control near the stack top. The attacker can control
a word near the top of the stack. We show that this
can be achieved by controlling an argument to a
6
In this section we describe our Back To The Epi-
logue (BATE) attack to CFG. We start with an overview of