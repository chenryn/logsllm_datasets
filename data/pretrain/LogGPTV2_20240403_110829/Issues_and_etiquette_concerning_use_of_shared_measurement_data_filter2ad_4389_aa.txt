title:Issues and etiquette concerning use of shared measurement data
author:Mark Allman and
Vern Paxson
Issues and Etiquette
Concerning Use of Shared Measurement Data
Mark Allman
ICSI
Berkeley, CA, USA
PI:EMAIL
ABSTRACT
In this note we discuss issues surrounding how to provide and use
network measurement data made available for sharing among re-
searchers. While previous work has focused on the technical de-
tails of enabling sharing via trafﬁc anonymization, we focus on
higher-level aspects of the process such as potential harm to the
provider (e.g., by de-anonymizing a shared dataset) or interactions
to strengthen subsequent research (e.g., helping to establish ground
truth). We believe the community would beneﬁt from a dialog
regarding expectations and responsibilities of data providers, and
the etiquette involved with using others’ measurement data. To
this end, we provide a set of guidelines that aim to aid the pro-
cess of sharing measurement data. We present these not as speciﬁc
rules, but rather a framework under which providers and users can
better attain a mutual understanding about how to treat particular
datasets.
Categories and Subject Descriptors
C.2.0 [Computer-Communication Networks]: General; C.2.3
[Computer-Communication Networks]: Network Operations;
C.2.m [Computer-Communication Networks]: Miscellaneous
General Terms
Measurement,Experimentation
Keywords
Data Sharing,Anonymization
1.
INTRODUCTION
Collecting a substantive set of network measurements gener-
ally requires both favorable circumstances and hard work. The
circumstances regard having the right opportunity: administrative
and legal permission (particularly for passive measurements), op-
erational support (e.g., installation of the measurement apparatus,
subsequent access to it for maintenance), and access to sufﬁcient
resources (e.g., disk space, network taps, kernel mods, smart stu-
dents). The hard work spans developing and debugging associated
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
IMC’07, October 24-26, 2007, San Diego, California, USA.
Copyright 2007 ACM 978-1-59593-908-1/07/0010 ...$5.00.
Vern Paxson
ICSI & LBNL
Berkeley, CA, USA
PI:EMAIL
software, calibration, monitoring the collection process for faults,
organizing the resulting data, ascertaining and capturing appropri-
ate meta-data, iterating the entire process to ﬁx problems that arise,
and interacting with the different parties that make up the favorable
circumstances.
Given these considerable difﬁculties, there is great utility in re-
searchers being able to share measurement datasets rather than
having to independently acquire them.
In addition, for Internet
measurement studies in particular there is major beneﬁt in sharing
datasets in order to gain broader, more representative insight into
the highly diverse nature of Internet trafﬁc and dynamics.
Researchers have advocated sharing data for years (e.g., [4, 16,
9]). An early effort of ours, the Internet Trafﬁc Archive [15], was
established as a place where researchers could make their data
available, but proved more time-consuming to maintain than we
had anticipated, and we failed to keep it growing over time. More
recently, several databases of released1 (mostly passive) datasets
have been established (e.g., DatCat [17] and PREDICT [3]).
In
addition, individual groups have begun making measurement data
available in somewhat ad-hoc ways (e.g., [2, 1]). Network mea-
surement conferences (PAM and IMC, in particular) have also been
trying to encourage sharing of data through awards for high-quality
new datasets released for general use. Finally, a signiﬁcant degree
of non-public sharing of data occurs, both within institutions and
between collaborators at different institutions.
We strongly encourage the widespread sharing of measurement
data. However, we are sometimes dismayed at how such data is
handled. We have used and provided measurement data over the
years (both publicly and privately) and we have been struck by
the range of attitudes and assumptions present in the community
about providing and using shared measurement data. In this note
we attempt to pose a set of reasonable, high-level considerations
for sharing and using measurement data. We do not attempt to of-
fer a complete set of “ground rules”. Such a list is impossible to
create, as each data-sharing situation has its own unique consid-
erations and associated threat model, requiring careful, individual
evaluation. Instead, we attempt to sketch some of the high-level
issues researchers should take into consideration—and sometimes
explicitly specify—when providing and using shared measurement
data.
We emphasize that in this note we have no aim to “lay blame,”
and in fact our own data sharing activities have not always adhered
to the considerations for which we advocate here. Rather, our un-
derstanding of the issues has evolved with experience.
1We use the term “released” rather loosely. Measurements de-
scribed in one of these databases have not necessarily been publicly
released, but the researchers who collected the datasets are willing
to share them with other researchers under some conditions.
In the next section we present issues regarding the decision and
process of releasing data for shared use. We follow this in § 3 with
discussion of the use of such data by others. In § 4 we consider
where releasing data meets use of data, i.e., interactions between
the providers and the users. We offer ﬁnal thoughts in § 5.
2. DATA RELEASE CONSIDERATIONS
Releasing data is fraught with potential problems—so much so
that most institutions will not even consider it. These problems
include potentially compromising the privacy of users, exposing
activity that might embarrass the institution, revealing information
about the site’s network that could enable an attacker to more ef-
fectively mount an attack, and exposing aspects of the network’s
operation to possible competitors. That said, there are also signif-
icant beneﬁts a site can gain by releasing data, in terms of further-
ing understanding about network activity in ways that can directly
or indirectly help the institution, and garnering positive recognition
within the community.
In general, the goal of a data release is to minimize the poten-
tial problems while at the same time trying to maximize the re-
search value of the data, at least for some context (see below, and
also [13] for our exploration with colleagues of such issues in the
context of a particular data release). To aid with this process, re-
searchers have developed a number of anonymization techniques to
scrub data for release [10, 18, 5, 14, 13]. While useful, these tech-
niques do not—and cannot—provide guaranteed protection against
information leakage. Therefore, as discussed in more detail in [13],
ultimately the choice about what to release, how to obscure the
data, and to whom to release the data, are policy decisions. Fur-
thermore, different policies apply to different situations. For ex-
ample, a university’s network operators might consider professors,
their students, and the public, to constitute three different threat
models, deserving three different datasets anonymized in three dif-
ferent ways. Another example concerns providing data with only
a narrowly deﬁned task in mind. In this case, the provider might
well discard the more detailed elements of each data record (e.g.,
a NetFlow record or a packet trace), rendering the data generally
useless outside the context of the given study.
The ﬁrst (obvious) guideline for data release is for providers to
carefully understand the threat model for each situation and to use
this understanding to frame the anonymization policy applied to
the data. A caveat is that no matter how careful a provider is, they
need to understand that they are releasing more information than
they think. Network measurement is often about inferring subtle
information from observed trafﬁc, and the techniques for doing so
evolve continually. Therefore, as researchers contrive better infer-
ence mechanisms, previously “safe” data can become vulnerable to
some forms of information leakage. A key counterpoint here, how-
ever, is that as data ages it often becomes less sensitive, because the
network has changed, IP addresses no longer reﬂect current users
or remote servers, meta-data that links one type of activity to an-
other has disappeared, apparent vulnerabilities have since been ad-
dressed, and so on.
The second guideline is to enumerate an explicit Acceptable Use
policy for the data. While it may seem obvious what constitutes
“scholarly use” of measurement data, the sensitivity can in fact sig-
niﬁcantly depend on where data was collected. Therefore, the best
course of action is for the provider to explicitly state the bounds of
what sort of analysis they wish to allow or disallow researchers to
pursue with their data. For example (illustrative, not exhaustive):
• The user must not attempt to de-anonymize the shared mea-
surement data.
• The user may use the data only for assessing the following
characteristics of trafﬁc: transfer length in bytes and dura-
tion.
• The user may use the data to develop new techniques for ﬁnd-
ing subverted hosts that are part of botnets.
• The shared data is not a general resource; each use of the data
should be undertaken only after gaining explicit permission
from the provider.
• Users noticing failures in the anonymization process are
asked to please inform the data provider.
Clearly a simple statement disallowing some activity will not
stop it. However, if the users of the data violate the explicit terms
then they run the risk of receiving no more data from the given
provider (and, possibly others with whom the provider shares their
experiences). Further, our hope is that Acceptable Use policies can
be cited in papers—and therefore guide reviewers, program com-
mittees and editors as they evaluate work that may violate the given
use constraints. If this were to be the case, then researchers who do
not adhere to the guidelines would run the risk of enduring censure
when attempting to publish their work.
A third guideline for providers is to be explicit about the interac-
tions they are willing to have with the users. Analyzing measure-
ment data often leads to questions about the environment, collec-
tion strategy, ﬁltering artifacts, additional activity, etc. Often, more
details about the trafﬁc garnered from a raw, non-anonymized ver-
sion of the dataset can shed light on these questions. Data providers
should be explicit about what sorts of assistance they can and will
provide to data users when these sorts of questions crop up.
A ﬁnal guideline, related to the above, is that providers should
explicate what sort of raw data and meta-data pertaining to the
shared data that the provider intends to retain, and for how long.
For instance, consider a provider who uses a packet trace to pro-
duce a log of TCP connection summaries that they then anonymize
and share. It may be quite useful for users of the summaries to un-
derstand how long (or even if) the provider retains the raw packet
traces such that the user can ask appropriate questions when chas-
ing down puzzles in the data. Further, it can be quite helpful for
users to understand the degree to which the provider keeps ancil-
lary data about hosts, servers, networks, etc., that can shed light on
aspects of the shared data (e.g., a snapshot of the network topology
at the time a dataset was collected).
Lastly, providers should consider explicitly stating what notiﬁ-
cation they desire regarding use of the data or its appearance in
a publication, and the desired form of acknowledgment that such
publications should include.
3. DATA USE CONSIDERATIONS
While care is clearly necessary (and exercised) when releasing
data, care is also required when using others’ data for scholarly
purposes. First and foremost, users should understand that releas-
ing data is difﬁcult (at best) for the provider. For example, we
recently publicly released packet traces recorded on internal net-
works at Lawrence Berkeley National Laboratory [2]. The effort to
design and implement suitable anonymization policies (described
in [13]), as well as to obtain approval to release traces given the
policies, took months2 of effort on the part of several individuals.
From discussions with colleagues, we believe this experience is in-
dicative of that of others who have released network measurement
data.
2Not including the effort to collect and study the data, as described
in [12].
Given such costs, clearly data providers will strongly desire that
users of shared measurement data should do nothing to hinder the
ability of the providers from releasing more data (to that user or
others) in the future, or anything that would have a broader chill-
ing effect on the community’s ability to release data. Organizations
have an immense list of reasons to say “No” to providing data to
the research community. Organizations that say “Yes” do so with
the hopes of helping the community and the understanding of net-
works, as well as gaining positive recognition within the commu-
nity. The community should therefore endeavor to treat the data as
responsibly as possible. At a minimum, data users should scrupu-
lously follow Acceptable Use policies that accompany the data. In
addition, if use drifts into any sort of “grey area,” the user should
consult the data provider, as discussed below.
We now explore four topics in more detail.
3.1 Reporting
Reporting ﬁndings obtained from using others’ data can some-
times be tricky. Ultimately, researchers strive to learn something
new about the network, protocols, services or hosts present in a
dataset. Very often, these results reﬂect characteristics somewhat
particular to the network from which the shared data comes. The
presentation of this new information can possibly lead to an unde-
sirable impact on the data provider.
For instance, consider a study on a new mechanism for detecting
hosts scanning a network. It may well be useful for a researcher
to use data such as that provided in [13] to attempt to reverse en-
gineer the mechanism the site used to detect scanners, such that
the researcher can then deduce a plausible set of scans that passed
through the site’s ﬁlter—and then whether these scans would be
caught by the proposed new mechanism. Success here (ﬁnding
scans previously uncaught) casts the researcher’s innovation in a
favorable light; but, by publicizing the approach the site currently
uses to detect, can undermine the site’s security posture.
We offer two coping strategies for researchers to use in this re-
gard:
• Aggregate. When reporting results, often one can aggre-
gate information to reduce its sensitivity. For example, in
the above example one could characterize the general nature
of the scans that made it through the site’s ﬁrewall over the
course of a day (say), instead of providing estimates for the
ﬁne-grained thresholds on the detection algorithm.
• Further Anonymization. When discussing particular arti-
facts in a dataset, researchers can go beyond simply reusing
the anonymization applied by the data provider and instead
re-anonymize the data they report, such as referring to hosts
in abstract terms (“host A”) rather than identifying speciﬁc
hosts present in the dataset.
3.2 Purpose-Provided Data
Publicly released datasets clearly provide a major beneﬁt to the
community in terms of allowing broad access to measurement data.
However, it behooves us to also consider data shared more infor-
mally during collaborations; among friendly researchers to help
each other out; or with students for a particular project. Often in
these cases the provider is more lax on anonymizing the data be-
cause they have signiﬁcant trust in the researcher. For instance,
Blanton developed tcpurify [5] as a quick way to obscure IP ad-
dresses from students who needed to work with packet header
traces for a speciﬁc project [6]. In this context, the students could
be generally trusted, and access to the packet traces carefully con-
trolled, but the operators still felt much more comfortable with not
providing the students with the direct data, due to important con-
cerns regarding both privacy and accidental revelations that might
turn up during analysis of the datasets.
In such contexts,
in addition to allocating less effort
to
anonymization, the data provider likely allocates less effort to de-
veloping Acceptable Use statements (as suggested above). We offer
a few general guidelines for this situation:
• A researcher must not further re-distribute non-public data a
provider has shared with the researcher.
• Closely related to the last point, researchers should exercise
great care when storing non-public measurement data, to en-
sure that the data remains inaccessible to anyone outside the
given project.
• When sharing non-public data, researchers should explicitly
inform providers as to who will have access to the data. E.g.,
a professor should identify the students who will work on
the given project, rather than simply assuming the provider
understands that students will naturally be given access to the
data.
• Researchers should employ the data only for the project /