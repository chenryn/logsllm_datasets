this issue, we leverage co-location information preserved in the
binary and indexing table (bi-directional mapping between n and
f ), and considers a unique feature as valid if all the other features
in the same file/class also matches.
4 ARCHITECTURE
OSSPolice is written mostly in Python. This allows us to reuse
existing production-quality tools within the language ecosystem.
In particular, we use Celery [18] job scheduler for distributing
work to multiple servers, Scrapy [75] for efficient crawling of OSS
repos, and Redis distributed key-value cluster [70] for storing and
querying indexing result.
Figure 3 depicts OSSPolice workflow. It consists of four modules,
namely OSSCollector, Indexer, Detector, and Validator. Each module
has an extensible plugin-based design to incorporate additional
functionality as need. Here we briefly describe the function of each
module.
OSSCollector. Our OSSCollector module is responsible for crawl-
ing multiple OSS hosting web services and downloading source
repos or Java artifacts. We use Scrapy [75] web crawling framework.
OSSCollector currently can only collect OSS from popular C/C++
source code hosting webservices, such as GitHub [34] and com-
monly used centralized webservices for distributing Java bytecode
(artifacts), such as Maven [83] and JCenter [14]. However, due to
an extensible design of OSSCollector, support for other hosting
services, such as Bitbucket [6], SourceForge [78], and Sonatype [77]
can be easily added.
When a new repo is discovered, OSSCollector first collects its
metadata, such as software name, unique repo identifier, repo size,
its popularity, programming languages used, number of lines of
code, and details of available release versions (e.g., version iden-
tifier, software license, date created, etc.). Collected metadata is
passed through additional filters to evaluate if an OSS repo should
be downloaded for indexing. Based on the metadata filters, OSSCol-
lector either skips the repo or downloads it and notifies Indexer to
start processing it. Our current prototype deploys filters based on
ValidatorDetectorIndexerCollectorGoogle Play ApplicationsDalvik bytecodeNative  LibraryJava OSS CollectionC/C++ OSS CollectionOSS DetectorGitHub OSS Other OSSMaven OSS JCenter OSSValidation & NotificationSession J3:  Problematic PatchesCCS’17, October 30-November 3, 2017, Dallas, TX, USA2176three constraints: OSS popularity, license type, and vulnerability
score.
We use Fossology[31], an open-source tool from HP, to extract
and identify software licenses of OSS repos by examining license-
like files in root directory of GitHub repos and project descrip-
tion file, namely pom.xml for Java artifacts. OSSCollector currently
works only with GPL/AGPL OSS sources.
OSSCollector also collects vulnerability information for each
OSS by transforming the software names into Common Platform
Enumeration (CPE) format [20] and querying cve-search [58] to get
a detailed list of all related Common Vulnerabilities and Exposures
(CVE) vulnerabilities, including CVE id, its description, Common
Vulnerability Scoring System (CVSS) score, affected versions, etc.
OSSCollector further filters out CVEs based on their CVSS score
and only retains CVEs with CVSS score higher than 4.0, which
we refer to as Severe CVEs. This is done to limit the focus of this
study to only detecting the use of OSS versions that are affected
with critical vulnerabilities.
OSSCollector only downloads software that is either popular or
is being used by at least one FDroid [29] app, which makes our
evaluation dataset (described in §5). Each GitHub repo is attrib-
uted with stargazers count and fork count, indicating approximated
number of users interested in it and number of times its copy has
been created, respectively. We use these attributes to determine
popularity of a GitHub repo. In particular, we downloaded Github
repos with more than 100 stargazers to form our C/C++ OSS Col-
lection (OSSC /C ++), which consisted of 3,119 repos and 60,450 OSS
versions. Popularity information, however, is not available from
Maven and is available only for a few Java artifacts from JCenter
in the form of total number of downloads. This is because JCen-
ter OSS developers may optionally choose to hide the download
statistics1. Therefore, while compiling a list of popular Java soft-
ware, we included additional sources, such as MvnRepository [64]
AppBrain [4], and Android Studio [35]. We narrowed down to Java
software artifacts that received more than 5K downloads, result-
ing in our Java OSS Collection (OSS J ava) with 4,777 artifacts and
77,308 artifact versions.
Of OSSC /C ++, 896 repos were GPL/AGPL-licensed and 347 were
vulnerable with 5,611 severe CVEs, whereas of OSS J ava, 110 repos
were GPL/AGPL-licensed and 83 were vulnerable with 452 severe
CVE ids. The two datasets were used for evaluating the OSSPolice
as well as reporting findings on Google Play Store apps.
AppCollector. It is responsible for crawling appstores and down-
loading app packages (apks) and their metadata, such as developer
information, download count, and app description. Our current
prototype only supports Google Play Store and borrows techniques
from PlayDrone [87]. We used AppCollector to download 1.6M free
Android mobile apps from Google Play Store in Dec, 2016.
Indexer. It extracts birthmark features from C/C++ source and
Java jar/aar files in OSS repos to create an indexing database for
1Developers may distribute multiple Java software and expose their download statistics
selectively on JCenter. For example, apache owns both commons-vfs2 and commons-
compress, but only chooses to disclose the download count for the former (13,478) and
hides it for the latter although both of them are popular.
9
efficient lookup. For feature extraction from C/C++ OSS, we use a
Clang-based fuzzy parser to parses all source files (including head-
ers). At first, we used a regular expression-based feature extractor.
However, it failed to correctly report features in many cases. For
instance, it failed to correctly extract strings or functions wrapped
in a preprocessing macro.
Our parser retrieves string literals and function names from
C/C++ source files. Additionally, it also extracts parameter types,
class names, and namespaces for functions while parsing C++
source files since they are preserved in native libraries. Since pars-
ing OSS files may fail due to missing configuration files and external
dependencies, we designed the parser to infer the semantic context
and insert dummy identifiers for missing data types. Further, we
skip function bodies to speed up the parsing process as we use only
function names and their arguments. To preserve the hierarchi-
cal layout of repos for content deduplication, we separately index
source and header files. As a result, we are also able to easily skip
common strings and functions defined in standard framework and
system include files that tend to dilute matching results because of
their popularity across several source repos. However, we do en-
able all #include directives, to resolve data types defined in header
files and correctly identify function names and string literals that
are wrapped in preprocessing macros, but are referenced in source
files. Conditional preprocessing directives, such as #if and #else
branch directives could also be skipped because of default config
options. We, therefore, process the code within such directives
separately, each forming a conditional group of extracted features
Sometimes developers may comment out a certain piece of code
within #if 0 or #elif 0, which may be erroneous; we detect and
skip such cases. We also skip non-Android and non-arm OS- and
arch-specific macros.
For feature extraction from Java OSS, Indexer uses a Soot-based
parser[55] for both source code and bytecode, which gives us the
flexibility to support various kinds of inputs: jar, dex, apk, and
source code. Indexer extracts features described in §3.3, including
string constants, normalized classes, and centroids.
Detector. It first extracts the same types of features (§3.3) as the
Indexer from mobile app binaries. We write a custom Python mod-
ule around pyelftools [12], to extract strings and exported function
names from native libraries, and use the same Soot-based parser
to extract string constants, normalized classes and centroids. De-
tector then queries extracted features against the indexing table
built by Indexer to find out a list of matched OSS versions. Detector
selectively report these OSS version usage to Validator based on
their license and vulnerability annotations. In particular, Detector
reports usage of GPL/AGPL-licensed OSS as potential license viola-
tions, and usage of OSS version annotated with at least one Severe
CVE as vulnerable usage.
Validator. It performs different checks based on the detected OSS
versions. In the GPL/AGPL-violation scenario, it uses developer’s
information from Google Play Store, searches through app descrip-
tion and the developer’s website for source code hosting links (e.g.
GitHub). If found, it compares the similarity of app binary with
the hosted source code to determine if the hosted code matches
indeed is a match. If the Validator fails to find hosting links or if
Session J3:  Problematic PatchesCCS’17, October 30-November 3, 2017, Dallas, TX, USA2177the similarity match fails, it reports the app as a potential violator
of GPL/AGPL licensing terms. In case of vulnerable OSS detection,
Validator simply retains the OSS versions that matched with unique
features, and presents vulnerability details, such as OSS version and
CVE ids to the user. If no unique features matched, it simply ranks
the detected OSS versions based on their TF-IDF score. However,
fine-grained function-level features (e.g., intra-procedural graph)
can be extracted from both OSS sources and app binaries to increase
the accuracy of version pinpointing at the cost of higher consump-
tion of system resources (CPU, memory, etc.) and increased search
time. We leave this for future work.
5 EVALUATION
In this section, we first present the performance and scalability
evaluation results of OSSPolice to show that it can efficiently match
millions of app binaries against hundreds of thousands of OSS
source repos. We then follow up with the accuracy analysis of
OSSPolice using FDroid [29] open-sourced apps (for ground truth)
to demonstrate that it can accurately detect OSS versions being
used even in the presence of internal code clones, partially built
binaries, and fused binaries (§3.4.1). For comparative analysis, we
also report accuracy of BAT [39] and LibScout [7] since they are
the state-of-the-art tools for OSS reuse detection, closest to ours.
5.1 Performance and Scalability
We deployed OSSPolice on ten servers, each with 16-core Intel
Xeon CPU E5-2673 v3 @ 2.40GHz, 56GB memory, and 4TB drives.
Indexing. To evaluate the scalability of OSSPolice, we indexed
a total of 137,758 OSS repos (60,450 C/C++ and 77,308 Java). We
short-listed them because of their high popularity (§4). While index-
ing, we empirically set Simhash distance threshold (D) to 5 (§3.4.3)
and number of maximum parent nodes (TNp ) for each child node to
2,000 (§3.4). We present the change in memory consumption with
the number of indexed repos in Figure 4a. As the figure demon-
strates, the memory consumption grows sub-linearly due to content
deduplication, suggesting that OSSPolice can easily be scaled to
index more OSS repos.
At the end of indexing, OSSPolice processed 13 million C/C++
source files and 31 million Java classes, which amounts to more
than 2 billion lines of C/C++ source code and 500 million lines of
Java bytecode instructions, respectively. The total number of entries
(keys) in the Redis database reached around 44 million and 9 million
and the database grew to 30GB and 9GB for C/C++ and Java OSS,
respectively. The number of entries created for C/C++ indexing
table was higher than Java because C/C++ repos are generally
larger in size and include auxiliary sources, such as tests, examples,
and third party code, whereas Java bytecode files do not contain
such auxiliary sources. On average, extracting all types of features
described in Table 1 and indexing a source repo take 1,000 and 40
seconds for C/C++ and Java OSS, respectively. For C/C++ OSS, the
majority of indexing time is spent in parsing source files for feature
extraction. This is because the current implementation of our Clang
parser is single-threaded and not optimized to include precompiled
headers. Thus, it recompiles common headers for every source
(a) Memory consumption.
(b) OSS detection time.
Figure 4: OSSPolice indexing and detection scalability. (a) shows
memory consumption of indexing database over time and (b) shows
how number of features in an app affects the detection time.
file. We expect that parallelizing the parser and adding support for
precompiled headers will substantially improve its performance.
However, we leave that for future work. In comparison, indexing
time of Java OSS first increases and then remains stable because
the majority of indexing time is spent on content deduplication,
where number of similarity comparisons first grows with number
of indexing nodes, but later reaches the limit of maximum parent
nodes TNp . Our Soot-based [55] feature extractor is fast because it is
multi-threaded and works directly on the precompiled jar packages.
Detection Time. A typical phenomenon in similarity detection
schemes is that as the app grows bigger and more complex, the time
taken to detect its similarity can increase exponentially, making
these schemes unsuitable for handling large and complex apps. To
test whether this limitation applies to OSSPolice, we randomly
sampled 10,000 Android apps from Google Play Store dataset and
queried them against our OSS database. Figure 4b shows the re-
lationship between time taken by OSSPolice to analyze them for
OSS reuse and number of features found in the selected app bi-
naries (representative of app complexity). As seen from the plot,
there is a linear relationship between the number features and the
detection time; 80% of Dalvik binary and native library detection
queries finish within 100 and 200 seconds, respectively, thus making
OSSPolice suitable for analyzing apps at Google Play Store scale.
5.2 Accuracy
In order to evaluate the accuracy of OSSPolice in detecting OSS
binary clones in Android apps, one needs a labeled mapping of apps
to OSS usage for ground truth. However, no such dataset is pub-
licly available from previous works. Randomly selecting binaries
from actual dataset and labeling them for ground truth may include
obfuscated and stripped binaries, rendering the labeling process
error-prone. We, therefore, decided to use FDroid apps since their
source code and binaries are both publicly available. FDroid hosted
a total of 4469 apps at the time of collection (Feb, 2017). Of those, 579
apps contained at least one native library. We labeled C/C++ OSS
by manually analyzing the source code and subsequently validating
their presence in app binaries by collecting informative strings and
function names. For instance, LibPNG sources were confirmed by
cross-checking whether the function names in the app binaries be-
gan with prefix png_. Java OSS labels were generated by parsing the
10
01020304050607080Numberofindexedrepos(Thousands)0.004.669.3113.9718.6323.2827.9432.6037.25Memoryusage(GB)C/C++MemoryUsageJavaMemoryUsageSession J3:  Problematic PatchesCCS’17, October 30-November 3, 2017, Dallas, TX, USA2178OSS Labels
F DroidC /C ++
OSS Labels
# Uses
295
# Uses
OSSPolice
BAT [39]
VM VP’(%) P(%) R(%)
P(%) R(%)
61
87
55/67
82
OSSPolice
LibScout[7]
82
75
VM VP’(%)
P(%) R(%)
89
92
VM VP’(%) P(%) R(%)
71
92
F Droid J ava
295/320
P, R, VM, VP’ refers to Precision, Recall, Version Match Results and
478/520
7,055
92
Version Precision for OSS with unique feature/profile matches.
Table 2: Accuracy of OSSPolice and comparison with LibScout and
BAT.
VM VP’(%)
92
app build scripts, such as Maven pom.xml and Gradle gradle.build
files that list app build dependencies. However, the specified build
dependencies may further depend on more libraries, making the la-
bels incomplete. For example, MoPub package is known to contain
string mopub-intent-ad-report. Therefore, we validated the labels
by checking package names and strings in the jars.
We labeled a total of 295 C/C++ OSS uses (56 distinct), denoted
as F DroidC /C ++ and 7,055 Java OSS uses (279 distinct), denoted
as F DroidJ ava. We then queried FDroid app binaries against our
indexing database from §5.1, and adjusted thresholds representing
matched ratio (TN ormScor e) for NormScore in Equation 1 and fea-
ture count (TCumScor e) for number of features matched to find a
sweet spot between precision and recall. Our results indicate that
OSSPolice achieves a precison of 82% and a recall of 87% when
TN ormScor e = 0.5 and TCumScor e = 50 for C/C++ OSS detection.
Similarly, OSSPolice reported a precision of 89% and a recall of
92% when TN ormScor e = 0.7 and TCumScor e = 100 for Java OSS
detection. In cases where the target OSS is detected correctly and
there were unique features matched, which amounted to 67 C/C++
and 520 Java OSS usage 2, OSSPolice achieved 82% and 92% version
detection accuracy, respectively.
We inspected the results reported by OSSPolice and found that
the main cause of false positives is the failure to correctly detect
and filter out internal code clones, which may happen if the target