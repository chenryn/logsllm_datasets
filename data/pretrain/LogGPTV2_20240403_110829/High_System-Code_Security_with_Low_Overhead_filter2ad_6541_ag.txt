P
M
E
M
A
L
h
s
i
f
w
o
B
l
i
:
r
e
p
p
R
e
h
t
n
h
o
J
S
E
D
i
:
r
e
p
p
R
e
h
t
n
h
o
J
(b) ASAP performance results for Phoronix benchmarks where omin < 5%.
Fig. 5. Summary of ASAP performance results. For each benchmark, we show three values: The darkest bar represents overhead for full instrumentation.
The next bar shows overhead with ASAP at cost level 0.01. The lightest bar show the residual overhead, i.e., overhead that is due to other factors than
sanity checks. Only elastic benchmarks (with residual overhead of less than ﬁve percent) are shown. ASAP brings the overhead of instrumentation close to
the minimum overhead, while preserving a high level of security. For the benchmarks shown here, ASAP removes 95% of the overhead due to checks, and
obtains an average sanity level of 87%.
875875
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:04:49 UTC from IEEE Xplore.  Restrictions apply. 
%
n
i
d
a
e
h
r
e
v
O
120
100
80
60
40
20
0
ASan
UBSan
Sanity level
100%
99%
98%
95%
90%
80%
Overhead
Omax
Omin
5%
r
u
B
l
S
E
D
:
r
e
p
p
R
e
h
i
t
n
h
o
J
m
u
t
n
a
u
q
b
i
l
.
2
6
4
m
b
l
.
0
7
4
5
D
M
:
r
e
p
p
R
e
h
i
t
n
h
o
J
i
k
c
g
a
M
s
c
h
p
a
r
G
i
.
i
k
c
g
a
M
s
c
h
p
a
r
G
i
h
s
e
r
h
T
e
v
i
t
p
a
d
A
P
C
S
T
.
f
c
m
9
2
4
G
E
P
J
b
L
i
d
m
a
n
.
4
4
4
r
a
t
s
a
.
3
7
4
2
p
z
b
i
.
1
0
4
i
3
x
n
h
p
s
.
2
8
4
r
e
m
m
h
.
6
5
4
i
e
v
e
s
e
m
i
r
P
.
c
n
E
3
P
M
E
M
A
L
h
s
i
f
w
o
B
l
:
r
e
p
p
R
e
h
i
t
n
h
o
J
y
t
f
a
r
C
:
r
e
p
p
R
e
h
i
S
E
D
h
s
i
f
w
o
B
l
:
r
e
p
p
R
e
h
i
t
n
h
o
J
t
n
h
o
J
.
f
c
m
9
2
4
m
b
l
.
0
7
4
2
p
z
b
i
.
1
0
4
c
l
i
.
m
3
3
4
k
m
b
o
g
.
5
4
4
g
n
e
s
.
j
8
5
4
y
t
f
a
r
C
i
3
x
n
h
p
s
.
2
8
4
l
x
e
p
o
s
.
0
5
4
Fig. 6. This graph shows the space of possible performance-security trade-offs. The orange line shows overhead of existing instrumentation tools; it averages
at 54% for ASan and 45% for UBSan. ASAP can reduce this overhead down to the blue minimal overhead line. The shade of the area corresponds to the
sanity level (darker = fewer checks). Reducing the sanity level by a small value has a large impact on overhead; for example, reducing the sanity level to 99%
reduces overhead by 47% on average. There are a few cases where programs with more sanity checks are slightly faster than programs with fewer checks
(e.g., libquantum with ASan or lbm with UBSan). This is due to the sometimes unpredictable effects of checks on caches, compiler heuristics, optimizations
etc.
benchmark; they demonstrate that a cost level of 0.01 would
have been sufﬁcient to prevent all vulnerabilities studied.
1) OpenSSL Heartbleed: The OpenSSL Heartbleed vul-
nerability is due to a bug in OpenSSL that manifests when
processing heartbeat messages. Such messages have a length
ﬁeld and a payload, the size of which is expected to match the
length ﬁeld. Yet, attackers can send a heartbeat message with
a length ﬁeld larger than the payload size. When constructing
the reply, the server would copy the request payload to the
response, plus whatever data followed it in memory, up to the
requested length. This allows the attacker to read the server’s
memory, including sensitive data like passwords.
The vulnerability can happen because the C programming
language does not enforce memory safety. A pointer to the
request packet can be used to read memory beyond the
packet boundary, even though this memory belongs to different
objects. The vulnerability is made worse because, for perfor-
mance reasons, memory that is no longer used is not cleared.
This means that the response returned to the attacker may
contain not only data that is currently used, but also sensitive
data from previous requests.
An attack that exploits the Heartbleed bug causes the
OpenSSL program to read data past the bounds of the original
request. Because of this, any instrumentation that detects over-
ﬂowing memory reads will prevent the vulnerability. Indeed,
compiling OpenSSL with AddressSanitizer produces a check
that catches the overﬂow.
When we proﬁled OpenSSL using its test suite as proﬁling
input, that critical check was never executed. This is because
heartbeat messages are an optional and rarely used feature of
OpenSSL, and the test suite does not cover them. This means
that ASAP estimates the cost of the critical check to be zero
and will never remove it, regardless of the target overhead
speciﬁed.
We extended the test suite with a test case for heartbeat
messages. Now the cost of the critical check is non-zero, but
there are 15,000 other more expensive checks accounting for
99.99% of the total cost. We can further increase the check’s
cost by using larger payloads for the heartbeat messages we
test. With a payload of 4KB, still 99.2% of the cost is spent in
more expensive checks. Thus ASAP will preserve this sanity
check for all cost levels larger than 0.008. This cost level
corresponds to a target overhead that lies just slightly above
the minimum overhead omin of AddressSanitizer. It leads to
only 5% reduction in throughput on a web server serving a
3kB web page via OpenSSL.
2) Python: The interpreter of the widely used Python
scripting language consists of about 350 KLOC of C code,
1,900 of them assertions. When compiled with ASan instru-
mentation, the interpreter binary contains 76,000 checks.
We used the following methodology to evaluate the security
of an ASAP-optimized Python interpreter: We started from the
source code of the most recent 3.4 version of the language.
Into this code, we inserted a set of bugs that have been
876876
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:04:49 UTC from IEEE Xplore.  Restrictions apply. 
present in earlier revisions; these form our reference set. Our
criteria for choosing these bugs were (1) the bugs must be
real-world problems recently reported on the Python issue
tracker, (2) they must be detectable using instrumentation or
assertions, and (3) they must be deterministically reproducible.
We inserted the bugs by reverse-applying the relevant parts of
the patch that ﬁxed them.
The three bugs that we analyze are #10829, a buffer
overﬂow in printf-style string formatting that ASan detects;
#15229, an assertion failure due to an uninitialized object;
and #20500, an assertion failure when an error occurs during
shutdown.2
We ran the Python test suite as proﬁling workload and
used the proﬁling data to generate an ASAP-optimized Python
interpreter. Whenever the cost level is larger than 0.005, this
interpreter is protected against all bugs that we analyzed. At
cost level 0.01, the overhead of Python is at 55%, due to the
large minimum overhead incurred from metadata handling in
AddressSanitizer. §VI-E contains a more detailed evaluation
of sanity checks and bugs in Python.
3) RIPE benchmarks: The RIPE benchmark suite [37] is a
set of exploits for synthetic buffer overﬂows. It consists of a
vulnerable program that attacks itself. In total, it features 850
unique attacks that differ in ﬁve characteristics: (1) the location
of the buffer, e.g., on the stack or inside a structure; (2)
the code pointer being overwritten, e.g., a return address; (3)
whether the target pointer is overwritten directly or indirectly;
(4) the type of shellcode; and (5) the function where the
overﬂow happens, e.g., memcpy or sprintf.
The RIPE benchmark is well-known in the security com-
munity and contains a large number of exploits. However, its
synthetic nature makes it problematic for evaluating ASAP:
First, the exploits are all very similar; they differ only in few
aspects of their construction, so that the number of effectively
different scenarios is much smaller than 850. In particular,
there are only ten distinct program locations where a memory
corruption happens, so that the security gained by instrumen-
tation is based on only ten sanity checks. Second, RIPE is
designed for the sole purpose of overﬂowing buffers. There is
no relevant workload that could be used for proﬁling. For the
lack of an alternative, we exercised all the different overﬂow
mechanisms to obtain proﬁling data. Third, RIPE makes strong
assumptions about the compiler and the operating systems.
Many exploits depend on the order of objects in memory,
or on particular pointer values. Small changes in compilation
settings or even between different runs of a program can cause
such assumptions to fail; this makes it difﬁcult to compare
benchmarks.
For these reasons, we do not evaluate individual exploits
in detail, and solely measure the minimal cost level needed
to preserve the protection against buffer overﬂows gained
by ASan instrumentation. ASAP preserves all critical sanity
checks inserted by ASan for cost levels larger than 0.0004.
Furthermore, nine out of ten buffer overﬂows happen inside
2Reports available on the Python bug tracker at http://bugs.python.org/
library functions such as memcpy, which ASan redirects to
its safe runtime library. Checks in ASan’s runtime library are
part of the residual overhead that ASAP does not yet address.
ASAP currently preserves these checks at all cost levels.
4) Security Evaluation Summary: In our case studies on
OpenSSL, CPython, and RIPE, we determined the minimum
cost level to protect against all known vulnerabilities to be
0.008, 0.005, and 0.0004, respectively. We rounded this up to
0.01 and use this as default cost level for our performance
experiments. A cost level of 0.01 corresponds to a sanity level
of 94% in OpenSSL and 92% in CPython.
Note that a cost level of 0.01, even though it worked well
in our experiments, does not imply that the resulting binaries
are protected against all unknown vulnerabilities. Neither does
such a cost level generalize to other software. Users of ASAP
should analyze the result, e.g., by examining the elided checks
as described in §V.
E. Discussion of Sanity Checks
To understand the security effect of ASAP, it is helpful to
analyze the properties of sanity checks that are removed and
preserved, respectively.
We ﬁrst consider the 100 most expensive sanity checks
in the Python interpreter. These checks together account for
29% of the total cost. They are in hot core locations of the
interpreter: 49 of them belong to core Python data structures
such as maps or tuples; 23 are in the main interpreter loop;
22 are in reference counting and garbage collection code; and
six in other parts of the interpreter. Any meaningful Python
program exercises the code where these checks reside. A bug
in these parts of the interpreter would likely affect many
Python scripts and thus be immediately detected. Hence we
are conﬁdent that removing these checks in production is safe.
The Python developers seem to partially agree with this: 6 out
of these 100 checks are assertions in code regions that are
only compiled when Py_DEBUG is deﬁned, i.e., only during
development.
In contrast,
the checks that guard real-world bugs are
executed rarely. The bugs in our case study are executed only
(i) when a format string contains the "%%" character sequence,
(ii) when a Python script circumvents the usual constructors
and directly executes __new__, or (iii) when an error is raised
during interpreter shutdown. We did not select the bugs to be
particularly rare—it just happens to be that most real-world
bugs are tricky corner cases.
Figure 7 sheds further light on this issue. For this graph, we
looked at the checks in Python 2.7, and differentiate between
checks that are located in buggy code, and “normal” checks.
We take as buggy code those parts of the source code that have
received bug ﬁxes between the time Python 2.7 was released,
until the current version 2.7.8.
We ﬁnd that checks in buggy code are executed less
frequently than regular checks. This makes them less likely
to be affected by ASAP. For example, at cost level 0.01,
ASAP removes 8% of all checks, but only 5% of the checks
in buggy code. If we assume that our notion of buggy code
877877
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:04:49 UTC from IEEE Xplore.  Restrictions apply. 
Type
Checks in buggy code
Regular checks
l
e
v
e
l
y
t
i
n
a
S
1.0
0.9
0.8
0.7
Overall, we found 24 vulnerabilities that potentially lie
in hot code regions. The other 121 (83%) lie in cold code
where ASAP would not affect checks protecting against them.
Because our criteria for cold code are strict, we think this
is a conservative estimate. It provides further evidence that a
large fraction of vulnerabilities could be prevented by applying
instrumentation and sanity checks only to cold code areas,
The results of our CVE study are publicly available and can
be accessed at http://dslab.epﬂ.ch/proj/asap.
1.0
0.1
0.01
Cost level
0.001
0.0001
VII. EXTENSIONS AND FUTURE WORK
Fig. 7. Fraction of checks preserved by ASAP, for various cost levels. The
dark line corresponds to the sanity level as computed by ASAP. The bright
line corresponds to the fraction of protected buggy code. Because checks in
buggy code have a lower cost on average than regular checks, they are more
likely to be preserved.
is representative, we can conclude that the sanity level as
computed by ASAP (92% in this case, for a cost level of 0.01)
is a lower bound on the fraction of bugs that are protected by
checks (95% in this case). This follows from the fact that the
dark line is always below the bright line in Figure 7.
This experiment also shows that there are a few bugs in hot
code, so using ASAP does reduce security. The computed
sanity level gives developers an estimate of this reduction
and allows them to make informed choices regarding the best
trade-off between security and performance.
F. CVE Vulnerability Survey
We complete our security evaluation by studying known
security vulnerabilities from the CVE database [23]. We focus
on memory-related vulnerabilities because sanity checks are
particularly promising for protecting against this category.
The CVE data set contains 879 memory-related vulnerabil-
ities for the year 2014. For 180 of these, it was possible to
obtain the source code and patch that ﬁxed the vulnerability.
From the source code and patch, we determined the location
of the memory error itself. The error is not always located in
the patched program part. For example, a common pattern is
that developers add a missing check to reject invalid input.
In this case, we searched for the location where the program
accesses the illegal input and corrupts its memory. For 145
vulnerabilities, we could tell with sufﬁcient certainty where
the memory error happens.
We then manually analyzed the bugs to determine whether
they lie in hot or cold parts of the program. We used four
criteria to classify a code region as cold: (1) the code does not
lie inside loops or recursively called functions, (2) the code
is only run during initialization or shutdown, (3) comments
indicate that the code is rarely used, and (4) the code is
adjacent to much hotter regions which would dominate the
overall runtime. In absence of these criteria, we classiﬁed a
code region as hot.
1) Elastic Instrumentation Tools: We believe there is a
promising, yet unexplored area of building elastic instrumenta-
tion tools. This requires a change of mind: with techniques like
ASAP, it is no longer the overall instrumentation overhead
that matters, but the minimum, residual overhead when all
checks are removed.
Builders of an elastic instrumentation tool take different
design decisions. Consider, for example, the cost of a check in
AddressSanitizer vs. SoftBound. SoftBound checks are more
expensive because the metadata lookup is more complex. In
contrast, a dynamic memory allocation is cheap for SoftBound
because only a single lookup table entry needs to be updated,
whereas AddressSanitizer needs to set up large shadow mem-
ory areas around the allocated memory object. Similar trade-
offs exist for other operations such as function calls, memory
de-allocation, or pointer arithmetic.
2) Other Sources of Overhead: With ASAP, we tackle
the runtime overhead due to sanity checks. However, runtime
overhead is not the only reason that prevents instrumentation
from being used in practice. For example, systems where
memory is the main bottleneck cannot afford to spend 15%
of it for shadow memory. In other cases, performance might
degrade due to registers being used for sanity checks, or cache
lines being ﬁlled with metadata. The challenge in reducing
this overhead is that
the relationship between checks and
metadata is complex. In most cases, it is not possible to predict
statically where metadata will be used. Still we believe that
it should be possible to gradually eliminate some of these
other hurdles similarly to how ASAP deals with overhead
from sanity checks.
3) Probabilistic and Dynamic Instrumentation: We are also
considering a probabilistic version of ASAP. By default,
ASAP uses a static cost threshold, above which a check is re-
moved. It could alternatively remove checks probabilistically,
with the probability proportional to a check’s cost. An attacker
who wanted to exploit a particular vulnerability then could
not guarantee that it is exposed in the present instance of the
program. Thus, the attacker risks that the attack is detected
and that a zero-day vulnerability becomes known.
A probabilistic mechanism also enables collaboration be-
tween multiple users, or multiple machines in a cloud service.
They could run software with different sets of sanity checks, in
a way that further reduces overhead but causes vulnerabilities
to be detected with high probability by at least one participant.
878878
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:04:49 UTC from IEEE Xplore.  Restrictions apply. 
In a different scenario, users could use ASAP to build
binaries at a range of cost levels. We could envision a system
that dynamically switches between these binaries according to,
for example, system load or the nature of requests. This leads
to a system that automatically becomes more secure when
resources are available.
VIII. CONCLUSION
We presented ASAP, a new approach to give developers
control of how much runtime overhead they are willing to
invest into adding security to their software systems. Our
ASAP prototype automatically and selectively adds sanity
checks to the software, making it as safe as possible for the
chosen overhead.
The most expensive sanity checks lie in code that is fre-
quently executed. However, exploits frequently target poorly
tested and rarely executed code, where sanity checks are
comparatively cheap. ASAP leverages this inverse relationship
to prevent vulnerabilities from being exploited, while incurring
only a low overhead that is suitable for production environ-
ments.
ACKNOWLEDGMENTS
We thank Azqa Nadeem for her work on the experimen-
tal evaluation and CVE case study. We are thankful to Ed
Bugnion, John Regehr, and our colleagues at the Dependable
Systems Lab for ideas and helpful discussions. We would also
like to thank the anonymous reviewers for their feedback. This
work has been partially supported by ERC Starting Grant No.
278656 and by EPSRC grant EP/L022710/1.
REFERENCES
[1] Martín Abadi, Mihai Budiu, Úlfar Erlingsson, and Jay Ligatti. Control-
ﬂow integrity. In CCS, 2005.
[2] Qualys Security Advisory. Ghost: glibc gethostbyname vulnerability.
http://www.openwall.com/lists/oss-security/2015/01/27/9.
[3] Periklis Akritidis, Cristian Cadar, Costin Raiciu, Manuel Costa, and
Miguel Castro. Preventing memory error exploits with WIT. In IEEE
S&P, 2008.
[4] Periklis Akritidis, Manuel Costa, Miguel Castro, and Steven Hand.
Baggy bounds checking: An efﬁcient and backwards-compatible defense
against out-of-bounds errors. In USENIX ATC, 2009.
[5] Kapil Anand, Matthew Smithson, Khaled Elwazeer, Aparna Kotha, Jim
Gruen, Nathan Giles, and Rajeev Barua. A compiler-level intermediate
representation based binary analysis and rewriting system. In EuroSys,
2013.
[6] Todd M. Austin, Scott E. Breach, and Gurindar S. Sohi. Efﬁcient
detection of all pointer and array access errors. In PLDI, 1994.
[7] Trishul M. Chilimbi and Matthias Hauswirth. Low-overhead memory
leak detection using adaptive statistical proﬁling. In ASPLOS, 2004.
[8] Clang User’s Manual. Undeﬁned behavior sanitizer. http://clang.llvm.
org/docs/UsersManual.html.
[9] Crispan Cowan, Calton Pu, Dave Maier, Jonathan Walpole, Peat Bakke,
Steve Beattie, Aaron Grier, Perry Wagle, and Qian Zhang. StackGuard:
Automatic adaptive detection and prevention of buffer-overﬂow attacks.
In USENIX ATC, 1998.
[10] Dinakar Dhurjati, Sumant Kowshik, and Vikram Adve.
Safecode:
enforcing alias analysis for weakly typed languages. In PLDI, 2006.
[11] GCC coverage testing tool, 2010.
http://gcc.gnu.org/onlinedocs/gcc/
[12] Grand uniﬁed Python benchmark suite.
https://hg.python.org/
Gcov.html.
benchmarks/.
[13] Charles Antony Richard Hoare. Assertions: A personal perspective. In
Software pioneers, pages 356–366. Springer, 2002.
[14] Andrei Homescu, Steven Neisius, Per Larsen, Stefan Brunthaler, and
Michael Franz. Proﬁle-guided automated software diversity. In CGO,
2013.
[15] Intel Corporation. Intel architecture instruction set extensions program-
http://download-software.intel.com/sites/default/ﬁles/
ming reference.
319433-015.pdf, 2013.
[16] Trevor Jim, J Gregory Morrisett, Dan Grossman, Michael W Hicks,
In
James Cheney, and Yanling Wang. Cyclone: A safe dialect of C.
USENIX ATC, 2002.
[17] Richard WM Jones and Paul HJ Kelly. Backwards-compatible bounds
checking for arrays and pointers in C programs. In AADEBUG, 1997.
[18] Baris Kasikci, Thomas Ball, George Candea, John Erickson, and Madan-
lal Musuvathi. Efﬁcient tracing of cold code via bias-free sampling. In
USENIX ATC, 2014.
[19] Samuel C Kendall. BCC: Runtime checking for C programs. In USENIX
ATC, 1983.
[20] Volodymyr Kuznetsov, László Szekeres, Mathias Payer, George Candea,
R Sekar, and Dawn Song. Code-Pointer Integrity. In OSDI, 2014.
[21] Chris Lattner and Vikram Adve. LLVM: A compilation framework for
lifelong program analysis and transformation. In CGO, 2004.
[22] Linux 2.6.7. NX (No eXecute) support for x86. https://lkml.org/lkml/
2004/6/2/228, 2004.
[23] MITRE. Vulnerabilities and exposures. http://cve.mitre.org.
[24] Santosh Nagarakatte, Jianzhou Zhao, Milo M K Martin, and Steve
Zdancewic. SoftBound: Highly compatible and complete spatial memory
safety for C. In PLDI, 2009.
[25] Santosh Nagarakatte, Jianzhou Zhao, Milo M K Martin, and Steve
Zdancewic. CETS: Compiler enforced temporal safety for C. In ISMM,
2010.
[26] National Vulnerability Database.
https://web.nvd.nist.gov/view/vuln/
statistics, 2014.
[27] George C. Necula, Scott McPeak, and Westley Weimer. CCured: type-
safe retroﬁtting of legacy code. In POPL, 2002.
[28] Pwn2Own contest. http://www.pwn2own.com/.
[29] John Regehr. Use of assertions. http://blog.regehr.org/archives/1091,
2014.
[30] The Rust programming language. http://www.rust-lang.org/.
[31] Olatunji Ruwase and Monica S Lam. A practical dynamic buffer
overﬂow detector. In NDSS, 2004.
[32] Konstantin Serebryany, Derek Bruening, Alexander Potapenko, and
In
Dmitry Vyukov. AddressSanitizer: A fast address sanity checker.
USENIX ATC, 2012.
[33] Skape. Preventing the exploitation of SEH overrides.
http://www.
uninformed.org/?v=5&a=2.
[34] Joseph L Steffen. Adding run-time checking to the portable C compiler.
Software: Practice and Experience, 1992.
[35] László Szekeres, Mathias Payer, Tao Wei, and Dawn Song. SoK: Eternal
war in memory. In IEEE S&P, 2013.
[36] Xi Wang, Nickolai Zeldovich, M Frans Kaashoek, and Armando Solar-
Lezama. Towards optimization-safe systems: Analyzing the impact of
undeﬁned behavior. In SOSP, 2013.
[37] John Wilander, Nick Nikiforakis, Yves Younan, Mariam Kamkar, and
In
Wouter Joosen. RIPE: Runtime intrusion prevention evaluator.
ACSAC. ACM, 2011.
[38] Ding Yuan, Yu Luo, Xin Zhuang, Guilherme Renna Rodrigues, Xu Zhao,
Yongle Zhang, Pranay U. Jain, and Michael Stumm. Simple testing
can prevent most critical failures: An analysis of production failures in
distributed data-intensive systems. In OSDI, 2014.
879879
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:04:49 UTC from IEEE Xplore.  Restrictions apply.