title:Securing Self-Virtualizing Ethernet Devices
author:Igor Smolyar and
Muli Ben-Yehuda and
Dan Tsafrir
Securing Self-Virtualizing Ethernet Devices
Igor Smolyar, Muli Ben-Yehuda, and Dan Tsafrir, Technion—Israel Institute of Technology
https://www.usenix.org/conference/usenixsecurity15/technical-sessions/presentation/smolyar
This paper is included in the Proceedings of the 24th USENIX Security SymposiumAugust 12–14, 2015 • Washington, D.C.ISBN 978-1-939133-11-3Open access to the Proceedings of  the 24th USENIX Security Symposium is sponsored by USENIXSecuring Self-Virtualizing Ethernet Devices
Igor Smolyar
Muli Ben-Yehuda
Technion – Israel Institute of Technology
{igors,muli,dan}@cs.technion.ac.il
Dan Tsafrir
Abstract
I/O virtualization (SRIOV)
Single root
is a hard-
ware/software interface that allows devices to “self virtu-
alize” and thereby remove the host from the critical I/O
path. SRIOV thus brings near bare-metal performance to
untrusted guest virtual machines (VMs) in public clouds,
enterprise data centers, and high-performance comput-
ing setups. We identify a design ﬂaw in current Ethernet
SRIOV NIC deployments that enables untrusted VMs to
completely control the throughput and latency of other,
unrelated VMs. The attack exploits Ethernet ”pause”
frames, which enable network ﬂow control functional-
ity. We experimentally launch the attack across sev-
eral NIC models and ﬁnd that it is effective and highly
accurate, with substantial consequences if left unmiti-
gated:
(1) to be safe, NIC vendors will have to mod-
ify their NICs so as to ﬁlter pause frames originating
from SRIOV instances; (2) in the meantime, administra-
tors will have to either trust their VMs, or conﬁgure their
switches to ignore pause frames, thus relinquishing ﬂow
control, which might severely degrade networking per-
formance. We present the Virtualization-Aware Network
Flow Controller (VANFC), a software-based SRIOV NIC
prototype that overcomes the attack. VANFC ﬁlters pause
frames from malicious virtual machines without any loss
of performance, while keeping SRIOV and Ethernet ﬂow
control hardware/software interfaces intact.
1
Introduction
A key challenge when running untrusted virtual ma-
chines is providing them with efﬁcient and secure I/O.
Environments running potentially untrusted virtual ma-
chines include enterprise data centers, public cloud com-
puting providers, and high-performance computing sites.
There are three common approaches to providing I/O
services to guest virtual machines: (1) the hypervisor
emulates a known device and the guest uses an unmod-
iﬁed driver to interact with it [71]; (2) a paravirtual
hypervisor
(a) Traditional Virtualization
(b) Direct I/O Device Assignment
Figure 1: Types of I/O Virtualization
driver is installed in the guest [20, 69]; (3) the host as-
signs a real device to the guest, which then controls the
device directly [22, 52, 64, 74, 76]. When emulating a
device or using a paravirtual driver, the hypervisor in-
tercepts all interactions between the guest and the I/O
device, as shown in Figure 1a, leading to increased over-
head and signiﬁcant performance penalty.
The hypervisor can reduce the overhead of device em-
ulation or paravirtualization by assigning I/O devices di-
rectly to virtual machines, as shown in Figure 1b. Device
assignment provides the best performance [38,53,65,76],
since it minimizes the number of I/O-related world
switches between the virtual machine and its hypervisor.
However, assignment of standard devices is not scalable:
a single host can generally run an order of magnitude
more virtual machines than it has physical I/O device
slots available.
One way to reduce I/O virtualization overhead fur-
ther and improve virtual machine performance is to of-
ﬂoad I/O processing to scalable self-virtualizing I/O de-
vices. The PCI Special Interest Group (PCI-SIG) on
I/O Virtualization proposed the Single Root I/O Virtu-
alization (SRIOV) standard for scalable device assign-
ment [60]. PCI devices supporting the SRIOV standard
present themselves to host software as multiple virtual
interfaces. The host can assign each such partition di-
rectly to a different virtual machine. With SRIOV de-
vices, virtual machines can achieve bare-metal perfor-
USENIX Association  
24th USENIX Security Symposium  335
mance even for the most demanding I/O-intensive work-
loads [38, 39]. We describe how SRIOV works and why
it improves performance in Section 2.
New technology such as SRIOV often provides new
capabilities but also poses new security challenges. Be-
cause SRIOV provides untrusted virtual machines with
unfettered access to the physical network, such machines
can inject malicious or harmful trafﬁc into the network.
We analyze the security risks posed by using SRIOV
in environments with untrusted virtual machines in Sec-
tion 3. We ﬁnd that SRIOV NIC, as currently deployed,
suffers from a major design ﬂaw and cannot be used se-
curely together with network ﬂow control.
We make two contributions in this paper. The ﬁrst
contribution is to show how a malicious virtual machine
with access to an SRIOV device can use the Ethernet
ﬂow control functionality to attack and completely con-
trol the bandwidth and latency of other unrelated VMs
using the same SRIOV device, without their knowledge
or cooperation. The malicious virtual machine does this
by transmitting a small number of Ethernet pause or Pri-
ority Flow Control (PFC) frames on its host’s link to
the edge switch. If Ethernet ﬂow control is enabled, the
switch will then shut down trafﬁc on the link for a spec-
iﬁed amount of time. Since the link is shared between
multiple untrusted guests and the host, none of them will
receive trafﬁc. The details of this attack are discussed
in Section 4. We highlight and experimentally evaluate
the most notable ramiﬁcations of this attack in Section 5.
Our second contribution is to provide an understand-
ing of the fundamental cause of the design ﬂaw lead-
ing to this attack and to show how to overcome it. We
present and evaluate (in Section 6 and Section 7) the
Virtualization-Aware Network Flow Controller (VANFC),
a software-based prototype of an SRIOV NIC that suc-
cessfully overcomes the described attack without any
loss in performance.
With SRIOV, a single physical endpoint includes both
the host (usually trusted) and multiple untrusted guests,
all of which share the same link to the edge switch. The
edge switch must either trust all the guests and the host
or trust none of them. The former leads to the ﬂow con-
trol attack we show; the latter means doing without ﬂow
control and, consequently, giving up on the performance
and efﬁcient resource utilization ﬂow control provides.
With SRIOV NICs modeled after VANFC, cloud users
could take full advantage of lossless Ethernet in SRIOV
device assignment setups without compromising their se-
curity. By ﬁltering pause frames generated by the mali-
cious virtual machine, VANFC keeps these frames from
reaching the edge switch. The trafﬁc of virtual machines
and host that share the same link remains unaffected;
thus VANFC is 100% effective in eliminating the attack.
VANFC has no impact on throughput or latency compared
to the baseline system not under attack.
VANFC is fully backward compatible with the current
hardware/software SRIOV interface and with the Ether-
net ﬂow control protocol, with all of its pros and cons.
Controlling Ethernet ﬂow by pausing physical links has
its fundamental problems, such as link congestion prop-
agation, also known as the ”congestion spreading” phe-
nomenon [13]. The attack might also be prevented by
completely redesigning the Ethernet ﬂow control mech-
anism, making it end-to-end credit-based, as in Inﬁni-
Band [18], for example. But such a pervasive approach
is not practical to deploy and remains outside the scope
of this work. Instead, VANFC speciﬁcally targets the de-
sign ﬂaw in SRIOV NICs that enables the attack. VANFC
prevents the attack without any loss of performance and
without requiring any changes to either Ethernet ﬂow
control or to the SRIOV hardware/software interfaces.
One could argue that ﬂow control at the Ethernet level
is not necessary, since protocols at a higher level (e.g.,
TCP) have their own ﬂow control. We show why ﬂow
control is required for high performance setups, such as
those using Converged Enhanced Ethernet, in Section 8.
In Section 9 we provide some notes on the VANFC im-
plementation and on several aspects of VM-to-VM traf-
ﬁc security. We present related work in Section 10. We
offer concluding remarks on SRIOV security as well as
remaining future work in Section 11.
2 SRIOV Primer
Hardware emulation and paravirtualized devices impose
a signiﬁcant performance penalty on guest virtual ma-
chines [15, 16, 21, 22, 23]. Seeking to improve vir-
tual I/O performance and scalability, PCI-SIG proposed
the SRIOV speciﬁcation for PCIe devices with self-
virtualization capabilities. The SRIOV spec deﬁnes how
host software can partition a single SRIOV PCIe device
into multiple PCIe “virtual” devices.
Each SRIOV-capable physical device has at least one
Physical Function (PF) and multiple virtual partitions
called Virtual Functions (VFs). Each PF is a standard
PCIe function: host software can access it as it would
any other PCIe device. A PF also has a full conﬁguration
space. Through the PF, host software can control the en-
tire PCIe device as well as perform I/O operations. Each
PCIe device can have up to eight independent PFs.
VFs, on the other hand, are “lightweight” (virtual)
336  24th USENIX Security Symposium 
USENIX Association
guest VM0
hypervisor
Figure 2: SRIOV NIC in a virtualized environment
PCIe functions that implement a subset of standard PCIe
device functionalities. Virtual machines driving VFs per-
form only I/O operations through them. For a virtual ma-
chine to use a VF, the host software must conﬁgure that
VF and assign it to the virtual machine. Host software
often conﬁgures a VF through its PF. VFs have a partial
conﬁguration space and are usually presented to virtual
machines as PCIe devices with limited capabilities. In
theory, each PF can have up to 64K VFs. Current In-
tel implementations of SRIOV enable up to 63 VFs per
PF [42] and Mellanox ConnectX adapters usually have
126 VFs per PF [57].
While PFs provide both control plane functionality
and data plane functionality, VFs provide only data
plane functionality. PFs are usually controlled by device
drivers that reside in the trusted, privileged, host operat-
ing system or hypervisor. As shown in Figure 2, in virtu-
alized environments each VF can be directly assigned to
a VM using device assignment, which allows each VM to
directly access its corresponding VF, without hypervisor
involvement on the I/O path.
Studies show that direct assignment of VFs provides
virtual machines with nearly the same performance as
direct assignment of physical devices (without SRIOV)
while allowing the same level of scalability as software-
based virtualization solutions such as device emulation
or paravirtualization [33, 38, 41, 77]. Furthermore, two
VMs that share the same network device PF can com-
municate efﬁciently since their VM-to-VM trafﬁc can be
switched in the network adapter. Generally, SRIOV de-
vices include embedded Ethernet switch functionality ca-
pable of efﬁciently routing trafﬁc between VFs, reducing
the burden on the external switch. The embedded switch
in SRIOV capable devices is known as a Virtual Ethernet
Bridge (VEB) [51].
SRIOV provides virtual machines with I/O perfor-
mance and scalability that is nearly the same as bare
metal. Without SRIOV, many use cases in cloud comput-
ing, high-performance computing (HPC) and enterprise
data centers would be infeasible. With SRIOV it is pos-
sible to virtualize HPC setups [24, 37]. In fact, SRIOV
is considered the key enabling technology for fully virtu-
alized HPC clusters [54]. Cloud service providers such
as Amazon Elastic Compute Cloud (EC2) use SRIOV as
the underlying technology in EC2 HPC services. Their
Cluster Compute-optimized virtual machines with high
performance enhanced networking rely on SRIOV [2].
SRIOV is important in traditional data centers as well.
Oracle, for example, created the Oracle Exalogic Elastic
Cloud, an integrated hardware and software system for
data centers. Oracle Exalogic uses SRIOV technology to
share the internal network [40].
3 Analyzing SRIOV Security
Until recently, organizations designed and deployed Lo-
cal Area Networks (LANs) with the assumption that each
end-station in the LAN is connected to a dedicated port
of an access switch, also known as an edge switch.
The edge switch applies the organization’s security
policy to this dedicated port according to the level of trust
of the end-station connected to the port: some machines
and the ports they connect to are trusted and some are
not. But given a port and the machine connected to it, the
switch enforcing security policy must know how trusted
that port is.
With the introduction of virtualization technology, this
assumption of a single level of trust per port no longer
holds. In virtualized environments, the host, which is of-
ten a trusted entity, shares the same physical link with
untrusted guest VMs. When using hardware emulation
or paravirtualized devices, the trusted host can intercept
and control all guest I/O requests to enforce the relevant
security policy. Thus, from the point of view of the net-
work, the host makes the port trusted again.
Hardware vendors such as Intel or Mellanox imple-
ment strict VF management or conﬁguration access to
SRIOV devices. Often they allow VFs driven by un-
trusted entities to perform only a limited set of manage-
ment or conﬁguration operations.
In some implemen-
tations, the VF performs no such operations; instead, it
sends requests to perform them to the PF, which does so
after ﬁrst validating them.
On the data path, the situation is markedly different.
SRIOV’s raison d’ˆetre is to avoid host involvement on
USENIX Association  
24th USENIX Security Symposium  337
the data path. Untrusted guests with directly assigned
VFs perform data path operations—sending and receiv-
ing network frames—directly against the device. Since
the device usually has a single link to the edge switch,
the device aggregates all trafﬁc, both from the trusted
host and from the untrusted guests, and sends it on the
single shared link. As a result, untrusted guests can send
any network frames to the edge switch.
Giving untrusted guests uncontrolled access to the
edge switch has two implications. First, since the edge
switch uses its physical resources (CAM tables, queues,
processing power) to process untrusted guests’ trafﬁc,
the switch becomes vulnerable to various denial of ser-
vice attacks. Second, sharing the same physical link be-
tween trusted and untrusted entities exposes the network
to many Ethernet data-link layer network attacks such
as Address Resolution Protocol (ARP) poisoning, Media
Access Control (MAC) ﬂooding, ARP spooﬁng, MAC
address spooﬁng, and Spanning Tree Protocol (STP) at-
tacks [14, 17, 47, 56, 73, 75]. Therefore, the edge switch
must never trust ports connected to virtualized hosts with
an SRIOV device.
Although the problem of uncontrolled access of un-
trusted end-points is general to Ethernet networks, using
SRIOV devices imposes additional limitations. As we
will see in the next few subsections, not trusting the port
sometimes means giving up the required functionality.
3.1 Traditional Lossy Ethernet
Traditional Ethernet is a lossy protocol; it does not guar-
antee that data injected into the network will reach its
destination. Data frames can be dropped for different
reasons: because a frame arrived with errors or because a
received frame was addressed to a different end-station.
But most data frame drops happen when the receiver’s
buffers are full and the receiving end-station has no mem-
ory available to store incoming data frames. In the origi-
nal design of the IEEE 802.3 Ethernet standard, reliabil-
ity was to be provided by upper-layer protocols, usually
TCP [63], with traditional Ethernet networks providing
best effort service and dropping frames whenever con-
gestion occurs.
3.2 Flow Control in Traditional Ethernet
Ethernet Flow Control (FC) was proposed to control con-
gestion and create a lossless data link medium. FC en-
ables a receiving node to signal a sending node to tem-
porarily stop data transmission. According to the IEEE
802.3x standard [6], this can be accomplished by sending
a special Ethernet pause frame. The IEEE 802.3x pause
link
speed,
Gbps
1
10
40
single frame
pause time, ms
33.6
3.36
0.85
frame rate required to
stop transmission,
frames/second
30
299
1193
Table 1: Pause frame rate for stopping trafﬁc completely
frame is deﬁned in Annex 31B of the spec [9] and uses
the MAC frame format to carry pause commands.
When a sender transmits data faster than the receiver
can process it and the receiver runs out of space, the
receiver sends the sender a MAC control frame with
a pause request. Upon receiving the pause frame, the
sender stops transmitting data.
The pause frame includes information on how long to
halt the transmission. The pause time is a two byte
MAC Control parameter in the pause frame that is mea-
sured in units of pause quanta. It can be between 0
to 65535 pause quanta. The receiver can also tell the
sender to resume transmission by sending a special pause
frame with the pause time value set to 0.
Each pause quanta equals 512 “bit times,” deﬁned
as the time required to eject one bit from the NIC (i.e., 1
divided by the NIC speed). The maximal pause frame
pause time value can be 65535 pause quanta,
which is 65535× 512 = 33.6 million bit times.
one pause
frame with
pause time value
65535 pause quanta
will tell the sender to stop transmitting for 33.6 million
bit times, i.e., 33.6 ms. A sender operating at 10 Gbps
speed will pause for 3.36 ms. A sender operating at 40
Gbps speed will pause for 0.85 ms.
For 1Gbps networks,
of
Table 1 shows the rate at which a network device
should receive pause frames to stop transmission com-
pletely.
The pause time value of each frame is
0xFFFF. Sending 30 pause frames per second will tell
the sender to completely stop transmission on a 1Gbps
link. For a sender operating at 10 Gbps speed to stop
transmission requires sending 299 frames/second. For a
sender operating at 40 Gbps speed to stop transmission
requires sending 1193 frames/second.
3.3 Priority Flow Control in Ethernet
To improve the performance and reliability of Ethernet
and make it more suitable for data centers, the IEEE
802.1 working group proposed a new set of standards,
known as Data Center Bridging (DCB) or Converged En-
338  24th USENIX Security Symposium 
USENIX Association
hanced Ethernet (CEE).
In addition to the IEEE 802.3x Ethernet pause, the
new IEEE 802.1Qbb standard proposed to make Ethernet
truly “lossless” in data center environments by adding
Priority-based Flow Control (PFC) [8].
Similar to the 802.3x FC, PFC is a link-level ﬂow con-
trol mechanism, but it is implemented on a per trafﬁc-
class basis. While 802.3x FC pauses all trafﬁc on the
link, PFC makes it possible to pause a speciﬁc class of