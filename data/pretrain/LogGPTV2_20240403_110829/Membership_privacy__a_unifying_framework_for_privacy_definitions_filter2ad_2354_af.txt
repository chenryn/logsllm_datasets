[15] J. Gehrke, M. Hay, E. Lui, and R. Pass. Crowd-blending
privacy. In CRYPTO, pages 479–496, 2012.
[16] J. Gehrke, E. Lui, and R. Pass. Towards privacy for social
networks: a zero-knowledge based deﬁnition of privacy. In
TCC, pages 432–449, Berlin, Heidelberg, 2011.
Springer-Verlag.
[17] N. Homer, S. Szelinger, M. Redman, D. Duggan, W. Tembe,
J. Muehling, J. V. Pearson, D. A. Stephan, S. F. Nelson, and
D. W. Craig. Resolving individuals contributing trace
amounts of DNA to highly complex mixtures using
high-density SNP genotyping microarrays. PLoS Genet,
4(8):e1000167+, 08 2008.
[18] D. Kifer and B.-R. Lin. Towards an axiomatization of
statistical privacy and utility. In PODS, PODS ’10, pages
147–158, New York, NY, USA, 2010. ACM.
[19] D. Kifer and A. Machanavajjhala. No free lunch in data
privacy. In SIGMOD, pages 193–204, 2011.
[20] J. Lee and C. Clifton. Differential identiﬁability. In KDD,
pages 1041–1049, 2012.
[21] N. Li, T. Li, and S. Venkatasubramanian. t-closeness:
Privacy beyond k-anonymity and l-diversity. In ICDE, pages
106–115, 2007.
[22] N. Li, W. Qardaji, and D. Su. On sampling, anonymization,
and differential privacy or, k-anonymization meets
differential privacy. In ASIACCS, pages 32–33, 2012.
[23] A. Machanavajjhala, J. Gehrke, and M. Götz. Data
publishing against realistic adversaries. Proc. VLDB Endow.,
2(1):790–801, Aug. 2009.
[24] A. Machanavajjhala, J. Gehrke, D. Kifer, and
M. Venkitasubramaniam. ℓ-diversity: Privacy beyond
k-anonymity. In ICDE, page 24, 2006.
[25] A. Machanavajjhala, D. Kifer, J. M. Abowd, J. Gehrke, and
L. Vilhuber. Privacy: Theory meets practice on the map. In
ICDE, pages 277–286, 2008.
[26] F. McSherry and K. Talwar. Mechanism design via
differential privacy. In FOCS, pages 94–103, 2007.
[27] A. Narayanan and V. Shmatikov. Robust de-anonymization
of large sparse datasets. In S&P, pages 111–125, 2008.
[28] K. Nissim, S. Raskhodnikova, and A. Smith. Smooth
sensitivity and sampling in private data analysis. In STOC,
pages 75–84, 2007.
[29] P. Samarati. Protecting respondents’ identities in microdata
release. IEEE Trans. on Knowl. and Data Eng.,
13:1010–1027, November 2001.
[30] L. Sweeney. k-anonymity: A model for protecting privacy.
Int. J. Uncertain. Fuzziness Knowl.-Based Syst.,
10(5):557–570, 2002.
APPENDIX
A. PROOFS
A.1 Proof of Theorem 3.11
PROOF. For any S ⊆ Range(A),
Pr[t|A ∈ S] = p Pr[t | A1(T ) ∈ S]+(1−p) Pr[t|A2(T ) ∈ S]
≤ p · γ Pr[t] + (1 − p)γ Pr[t] = γ Pr[t]
By a similar argument, we know that
Pr[¬t|A ∈ S] ≥
Pr[¬t]
γ
and therefore A also satisﬁes (D, γ)-PMP.
It is easy to see that above proof can be generalized to the case
that the mechanism A is the combination of more than two mech-
anisms; i.e., we have a set of k mechanisms and A is set to be
Ai with some probability pi for any p1, p2, . . . , pk ≥ 0 such that
i=1 pi = 1. In fact, this can be generalized to the case where the
number of methods is inﬁnite.
Pk
A.2 Proof of Theorem 3.12
PROOF. Let us ﬁrst prove for the case that A2 is a determin-
istic mechanism. For any S ⊆ Range(A2), we deﬁne S′ =
{s|A2(s) ∈ S, s ∈ Range(A1)}.
We know then
Pr[t|A2(A1(T )) ∈ S|] = Pr[t|A1(T )) ∈ S′] ≤ γ Pr[t]
and
Pr[¬t|A2(A1(T )) ∈ S|] = Pr[¬t|A1(T )) ∈ S′] ≥
Pr[¬t]
γ
As for a randomized mechanism A2, it can be viewed as com-
binations of a set of deterministic mechanisms. Suppose it is a
2 with probability pi to choose Ai
combination of A1
2.
We know then A2(A1(·)) is set to be Ai
2(A1(·)) with probability
pi. Clearly, each Ai
2 is a deter-
ministic mechanism. Also by the proof of Theorem 3.11, we know
that Ai
2(A1(·)) satisﬁes (D, γ)-PMP as Ai
2(A1(·)) also satisﬁes (D, γ)-PMP.
2 . . . , Ak
2, A2
A.3 Proof of Lemma 4.9
PROOF OF LEMMA 4.9. Suppose we have a mutually indepen-
dent distribution with probability p1, p2, . . . , pn on each entity
t ∈ [n]. Let Pk be its k-bounded distribution. For any particu-
lar T of size k, it is easy to see that
Pr
Pk
[T ] ∝ Yt∈T
ptYt6∈T
(1 − pt).
If we divideQt∈T ptQt6∈T (1 − pt) byQt∈[n](1 − pt) (which is
a constant independent of T ), we get that PrPk [T ] ∝Qt∈T
Let us denoteQt∈T
as p(T ). We know then
1−pt
1−pt
p(T )
pt
pt
.
[T ] =
Pr
Pk
.
PT ⊆[n],|T |=k p(T )
In addition, under distribution Pk, for any t ∈ [n] and T1 that
contains t,
Pr[T1|t] =
p(T1)
Pt∈T,|T |=k p(T )
=
p(T1\{t})
Pt /∈T,|T |=k−1 p(T )
(12)
and for any t /∈ T2,
Pr[T2|¬t] =
.
(13)
p(T2)
Pt /∈T,|T |=k p(T )
The existence of Pk,k−1 is equivalent to whether there exists a
good solution for the following network ﬂow problem on a bipar-
tite graph G(U, V, E). Here each vertex in U is corresponding to
some set T2 such that |T2| = k and t /∈ T2 and each vertex in V
is corresponding to some set |T1| = k − 1 and t /∈ T1. There is
an edge between (T1, T2) if T2 ⊂ T1. There is Pr[T2|¬t] amount
of goods on each node T2 and the capacity for each node T1 in V
is Pr[T1 ∪ {t}|t]. We can only ship goods along the edges and the
question is whether there exists a “perfect ﬂow” so that we can ship
all the goods from the U side to the V side without violating the
capacity constraints on the V side. This problem is equivalent to
the existence of Pk,k−1 as essentially Pr(T1, T2) is corresponding
to the amount of goods we want to ship from T2 to T1.
A necessary condition for the existence of the perfect ﬂow is that:
for any W ⊆ U and let the neighbor of W in G to be N (W ), we
have that
XT2∈W
Pr[T2|¬t] ≥ XT1∈N(W )
Pr[T1 ∪ {t}|t];
(14)
By [14] (which is a generalization of Hall’s marriage theorem),
(14) is also a sufﬁcient condition for the existence of the perfect
ﬂow. To prove (14), if we denote qi = pi
and use (12),(13), it
1−pi
is equivalent to show that
qi
PT2∈W Qi∈T2
P|T |=k,t /∈T Qi∈T qi
qi
≤ PT1∈N(W )Qi∈T1
P|T |=k−1,t /∈T Qi∈T qi
or equivalently
  XT2∈W Yi∈T2
qi! ·
qi
 X|T |=k−1,t /∈T Yi∈T
qi
 ·
≤
 X|T |=k,t /∈T Yi∈T
 XT1∈N(W ) Yi∈T1
qi
If we expand the left hand side and also the right hand side of
the above expression, we would get the sum of many terms of the
form q(S) = QS qi for S being a multiset such that t /∈ S and
|S| = 2k − 1. We know that the number of times q(S) appear
on the left hand side is equal to the number of different T2 ∈ W
so that T2 ⊆ S and S\T2 has distinct elements. Let us call such
T2 “good” for S. The number of times q(S) appear in the right
is equal to the number of different T1 in N (W ) so that S\T1 has
distinct elements. Let us also call such T1 “good” for S. Suppose
U2 contains all the T2 good for S in W and U1 contains all the T1
good for S in N (W ). It remains to prove the following claim.
LEMMA A.1. For any W and S (which deﬁnes U1, U2), we
have that |U1| ≥ |U2|.
We would prove this by induction on k (or equivalently the size
of |S| = 2k − 1). It is easy to check when k=1, above claim holds.
Suppose that |U2| ≤ |U1| holds for any k < k0. When k = k0, ﬁrst
let us consider the case that the elements in S are all distinct. We
construct a graph G(U1, U2, E) where the edge is added between
any T1 ∈ U1 and T2 ∈ U2 such that T1 ⊂ T2.
For any T2, we know that T2\{e} for any e ∈ T2 must be in U1.
Therefore, any T2 in U2 has exactly k neighbours. On the other
hand, for any T1 ∈ U1, any its neighbor in U2 must be of the form
T1 ∪ {e} for some e in S\T1 and there are at most |S| − |T1| = k
of such e. If we count the number of edges from U2 side, there are
k · U2 such edges. And if we count the number of edges from U1
side, there are at most k · |U1| edges. Therefore, |U1| ≥ |U2|.
When some element e in S are not distinct, it must be the case
that it can appear in both T1 and S\T1 (and also T2 and S\T2).
This also means that e appear exactly twice in S. Then essentially
we reduce it to the case when W ′ = {T \{e}|e ∈ T ∈ W }and
S′ = S\{e} and k′ = k0 −1 and therefore holds by induction.
A.4 Proof of Theorem 5.10
PROOF. Let Λβ(T ) denote the process of sampling tuples
from T with probability β.
Then, by deﬁnition, A satis-
ﬁes (β, ǫ)-Positive DPS means for each T , t, and S, we have
Pr[A(Λβ (T ∪{t}))∈S]
Pr[A(Λβ (T ))∈S] ≤ eǫ, which is equivalent to
Pr[A(Λβ (T ∪{t}))∈S]
Pr[A(Λβ (T ))∈S]
= (1−β) Pr[A(Λβ (T ))∈S]+β Pr[A(Λβ (T )∪{t})∈S]
Pr[A(Λβ (T ))∈S]
= 1 − β + β Pr[A(Λβ (T )∪{t})∈S]
Pr[A(Λβ (T ))∈S] ≤ eǫ
Hence, (β, ǫ)-Positive DPS is equivalent to ∀T ∀t∀S
PrD [S|t]
PrD [S|¬t] = Pr[A(Λβ (T )∪{t})∈S]
Pr[A(Λβ (T ))∈S] ≤ eǫ−1+β
β
where D such that all entities in T ∪ {t} have probability β, and
all other entities have probability 0; clearly D ∈ Dβ
F . In fact, there
is a one-to-one correspondence between a pair of T and t in DPS
deﬁnition, and such a distribution in Dβ
F and a tuple t such that
Pr[t] = β.
By deﬁnition, that A satisﬁes (Dβ
F , and S, we have Pr[t|S] ≤ min(γβ, 1 − 1−β
F , γ)-PMP means that for each
γ ). As
Pr[S|t]β
Pr[S|t]β+Pr[S|¬t](1−β) =
1+ 1−β
β
1
Pr[S|¬t]
Pr[S|t]
.
D ∈ Dβ
Pr[t|S] =
We only need to show that by selecting γ = max(cid:16)eǫ, eǫ−1+β
βeǫ (cid:17),
the two conditions PrD [S|t]
PrD [S|¬t] ≤ eǫ−1+β
and
≤
β
1+ 1−β
β
1
Pr[S|¬t]
Pr[S|t]
γ ) become equivalent. Note that PrD [S|t]
PrD [S|¬t] ≤
min(γβ, 1 − 1−β
eǫ−1+β
if and only if
β
1+ 1−β
β
1
Pr[S|¬t]
Pr[S|t]
≤ eǫ−1+β
.
eǫ
Case one, when eǫ ≥ eǫ−1+β
βeǫ
γ = eǫ and min(γβ, 1 − 1−β
Case two, when eǫ < eǫ−1+β
βeǫ
, is similar.
, we have βeǫeǫ ≥ eǫ − 1 + β,
) = eǫ−1+β
.
γ ) = min(βeǫ, eǫ−1+β
eǫ
eǫ