S
f
o
n
o
i
t
c
a
r
F
SybilWalk
SybilWalk-Var
CIA
SybilRank
0.0
0.1
0.3
0.5
0.7
0.9
1.1
1.3
K
1.5
×105
Fig. 4: Fraction of Sybils in top-K ranked nodes.
TABLE II: AUCs, FPRs, and FNRs on the Twitter dataset.
SybilWalk
SybilWalk-Var
AUC
FPR
FNR
0.96
1.3%
17.3%
0.92
4.8%
31.1%
CIA SybilRank
0.82
N/A
N/A
0.52
N/A
N/A
AUCs, FPRs, and FNRs on the Twitter network with real
Sybils: Table II shows the results on the Twitter dataset. We
run SybilWalk for two iterations. Except measuring the ranking
quality, we also show the classiﬁcation results. In particular,
for SybilWalk and SybilWalk-Var, we classify a node to be a
Sybil if and only if its badness score is larger than 0.5. False
Positive Rate (FPR) is the fraction of testing benign nodes
that are classiﬁed as Sybils, and False Negative Rate (FNR)
is the fraction of testing Sybils that are classiﬁed as benign.
Note that CIA and SybilRank are not classiﬁcation methods,
so they do not have FPR and FNR results.
Our results are consistent with those on the social networks
with synthesized Sybils. Speciﬁcally, our methods substantially
outperform CIA and SybilRank, and SybilWalk outperforms
SybilWalk-Var. The reason is that the Twitter network has
a weak homophily (i.e., a large number of attack edges,
compared to the edges in the benign region and Sybil region),
and our methods take advantage of both labeled benign nodes
and labeled Sybils to tolerate a weak homophily.
To better illustrate the ranking quality, Fig. 4 shows the
fraction of Sybils in top-K ranked nodes in the ranking list
produced by each method, where we vary K from 10,000
to 150,000 with a step size of 10,000. We observe that our
methods can accurately detect top-ranked Sybils. Speciﬁcally,
99% of the top-80,000 nodes produced by SybilWalk are
Sybils. However, only 29.9% and 0.27% of the top-80,000
nodes produced by CIA and SybilRank are Sybils, respectively.
C. Robustness to Label Noise
A labeled node has a noisy label if the given label does not
match its true label. Label noises often arise in practice due to
human mistakes. We say the training dataset has α% of label
C
U
A
1.0
0.9
0.8
0.7
0.6
0.5
0.4
0%
SybilWalk
SybilWalk-Var
CIA
SybilRank
10%
20%
Fraction of Label Noise
30%
40%
50%
Fig. 5: AUCs of compared methods on the Facebook dataset
as we increase the level of label noises.
noise if α% of labeled nodes have noisy labels. Speciﬁcally, in
our experiments, we sample α% of labeled benign nodes and
change their labels to be Sybil, and we sample α% of labeled
Sybil nodes and change their labels to be benign. Fig. 5 shows
AUCs of the compared methods on the Facebook dataset as
we increase the label noises α%. Note that, in order to avoid
the inﬂuence of weak homophily, we set the number of attack
edges to be small (i.e., 500) such that all methods achieve
AUCs close to 1 if there are no label noises.
First, our methods are more robust to label noises than CIA
and SybilRank. The reason is that our methods incorporate
both labels in the training dataset. Second, SybilWalk is
more robust to label noise than SybilWalk-Var. Speciﬁcally,
SybilWalk achieves AUCs close to 1 when fraction of label
noises is upto 20%, while SybilWalk-Var can tolerate label
noises upto 10%. The reason is that SybilWalk-Var ﬁxes the
badness scores of the labeled nodes, so the incorrect badness
scores of the labeled nodes with noisy labels keep spreading
among the social network. In contrast, SybilWalk does not
ﬁx the badness scores of labeled nodes, and the noisy labels
could be corrected when iteratively computing the badness
scores. Third, when 50% of labeled nodes have noisy labels, all
methods achieve AUCs that are close to 0.5, i.e., all methods
rank the test nodes uniformly at random. This is because 50%
of label noise essentially means the training dataset is not
informative.
D. Scalability
We evaluate scalability in terms of the time used by each
method. Since evaluating scalability requires social networks
with varying number of edges, we evaluate scalability on syn-
thesized graphs with different number of edges. In particular,
we add edges to the Facebook dataset randomly.
Fig. 6 shows the running times of the compared methods
for different number of edges. Note that all these methods
are iterative algorithms, so their running times highly depend
on the number of iterations. To avoid bias introduced by the
number of iterations, we run these methods for the same
number of iterations, i.e., 20 in our experiments. All methods
have linear time complexity, which is consistent with our
281
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 10:03:48 UTC from IEEE Xplore.  Restrictions apply. 
SybilWalk
SybilWalk-Var
CIA
SybilRank
300
250
200
150
100
50
)
c
e
s
(
e
m
T
i
0.1
0.2
0.3
0.5
0.4
0.7
Number of Edges
0.6
0.8
0.9
1.0
×107
Fig. 6: Running times of compared methods on synthesized
graphs as we increase the number of edges.
theoretical analysis in Section V-B. Moreover, SybilWalk is
as scalable as previous random walk based methods.
E. Summary
•
•
SybilWalk can tolerate a weaker homophily and is
more robust to label noises than existing random walk
based methods, while having the same scalability as
existing random walk based methods.
SybilWalk can tolerate a weaker homophily and is
more robust to label noises than SybilWalk-Var. More-
over, they have the same scalability.
VII. CONCLUSION AND FUTURE WORK
In this work, we design and evaluate SybilWalk, a new ran-
dom walk based Sybil detection method. SybilWalk overcomes
the limitations of existing random walk based methods while
maintaining their advantages. The key technique of SybilWalk
is to capture the structural gap between benign nodes and Sybil
nodes through a random walk on a label-augmented social net-
work. Theoretically, we demonstrate that SybilWalk achieves
a tighter bound on the number of Sybils that are ranked lower
than certain benign nodes than all existing random walk based
methods. Empirically, we show that 1) SybilWalk can tolerate a
weaker homophily than existing random walk based methods,
2) SybilWalk is more robust to label noises than existing
random walk based methods, and 3) SybilWalk is as scalable
as the most efﬁcient existing random walk based methods.
Interesting future work includes 1) learning the edge
weights in the label-augmented social network, 2) analyzing
the bound of the number of falsely rejected benign nodes, and
3) generalizing our theoretical analysis to Markov Random
Fields based methods.
REFERENCES
[1] Facebook User Stat., May 2016.
[2] Facebook Popularity., May 2016.
[3] Hacking Election., May 2016.
[4] Hacking Financial Market., May 2016.
[5] Kurt Thomas, Chris Grier, Justin Ma, Vern Paxson, and
Dawn Song. Design and evaluation of a real-time url
spam ﬁltering service. In IEEE Symposium on Security
and Privacy (IEEE S & P), 2011.
[6] H. Yu, M. Kaminsky, P. B. Gibbons, and A. Flaxman.
SybilGuard: Defending against Sybil attacks via social
networks.
In Proceedings of the 2006 conference on
Applications, technologies, architectures, and protocols
for computer communications (SIGCOMM), 2006.
[7] H. Yu, P. B. Gibbons, M. Kaminsky, and F. Xiao. Sybil-
Limit: A near-optimal social network defense against
Sybil attacks.
In IEEE Symposium on Security and
Privacy (IEEE S & P), 2008.
[8] G. Danezis and P. Mittal. SybilInfer: Detecting Sybil
nodes using social networks. In Network and Distributed
System Security Symposium (NDSS), 2009.
[9] Abedelaziz Mohaisen, Nicholas Hopper, and Yongdae
Kim. Keep your friends close: Incorporating trust into so-
cial network-based sybil defenses. In IEEE International
Conference on Computer Communications (INFOCOM),
2011.
[10] Qiang Cao, Michael Sirivianos, Xiaowei Yang, and Tiago
Pregueiro. Aiding the detection of fake accounts in large
scale social online services. In Symposium on Network
System Design and Implementation (NSDI), 2012.
[11] Chao Yang, Robert Harkreader, Jialong Zhang, Seung-
won Shin, and Guofei Gu. Analyzing spammer’s social
networks for fun and proﬁt. In World Wide Web (WWW),
2012.
[12] Yazan Boshmaf, Dionysios Logothetis, Georgos Siganos,
Jorge Leria, Jose Lorenzo, Matei Ripeanu, and Konstantin
Beznosov.
Integro: Leveraging victim prediction for
robust fake account detection in osns.
In Network and
Distributed System Security Symposium (NDSS), 2014.
[13] Yushan Liu, Shouling Ji, and Prateek Mittal. Smartwalk:
Enhancing social network security via adaptive random
walks. In ACM Conference on Computer and Communi-
cations Security (CCS), 2016.
[14] Neil Zhenqiang Gong, Mario Frank, and Prateek Mittal.
Sybilbelief: A semi-supervised learning approach for
structure-based sybil detection. IEEE TIFS, 9(6), 2014.
[15] Peng Gao, Neil Zhenqiang Gong, Sanjeev Kulkarni, Kurt
Thomas, and Prateek Mittal. Sybilframe: A defense-
in-depth framework for structure-based sybil detection.
CoRR, 2015.
[16] Hao Fu, Xing Xie, Yong Rui, Neil Zhenqiang Gong,
Guangzhong Sun, and Enhong Chen. Robust spammer
detection in microblogs: Leveraging user carefulness.
ACM Transactions on Intelligent Systems and Technology
(TIST), 2017.
[17] Binghui Wang, Le Zhang, and Neil Zhenqiang Gong.
Sybilscar: Sybil detection in online social networks via
local rule based propagation. In INFOCOM, 2017.
[18] J. Pearl. Probabilistic reasoning in intelligent systems:
networks of plausible inference. 1988.
[19] Alex Hai Wang. Don’t follow me - spam detection in
In International Conference on Security and
twitter.
Cryptography (SECRYPT), 2010.
[20] G. Schoenebeck S. Yardi, D. Romero and D. Boyd.
Detecting spam in a Twitter network. First Monday,
15(1), 2010.
282
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 10:03:48 UTC from IEEE Xplore.  Restrictions apply. 
[21] Gianluca Stringhini, Christopher Kruegel, and Giovanni
Vigna. Detecting spammers on social networks.
In
Annual Computer Security Applications Conference (AC-
SAC), 2010.
[22] Fabrıcio Benevenuto, Gabriel Magno, Tiago Rodrigues,
and Virgılio Almeida. Detecting spammers on twitter.
In Collaboration, Electronic messaging, Anti-Abuse and
Spam Conference (CEAS), 2010.
[23] Kurt Thomas, Chris Grier, and Vern Paxson. Adapting
social spam infrastructure for political censorship.
In
USENIX Workshop on Large-Scale Exploits and Emer-
gent Threats (LEET), 2012.
[24] Hongyu Gao, Yan Chen, Kathy Lee, Diana Palsetia, and
Alok Choudhary. Towards online spam ﬁltering in social
networks.
In Network and Distributed System Security
Symposium (NDSS), 2012.
[25] Kurt Thomas, Chris Grier, Vern Paxson, and Dawn Song.
Suspended accounts in retrospect: An analysis of twitter
spam. In Internet Measurement Conference (IMC), 2011.
[26] Gang Wang, Tristan Konolige, Christo Wilson, and Xiao
Wang. You are how you click: Clickstream analysis for
sybil detection. In Usenix Security, 2013.
[27] Jonghyuk Song, Sangho Lee, and Jong Kim.
Spam
ﬁltering in Twitter using sender-receiver relationship. In
International Symposium on Recent Advances in Intru-
sion Detection (RAID), 2011.
[28] Zhi Yang, Christo Wilson, Xiao Wang, Tingting Gao,
Ben Y. Zhao, and Yafei Dai. Uncovering social network
Sybils in the wild. In Internet Measurement Conference
(IMC), 2011.
[29] Gang Wang, Manish Mohanlal, Christo Wilson, Xiao
Wang, Miriam Metzger, Haitao Zheng, and Ben Y. Zhao.
Social turing tests: Crowdsourcing Sybil detection.
In
Network and Distributed System Security Symposium
(NDSS), 2013.
[30] G. Danezis, C. Diaz, C. Troncoso, and B. Laurie. Drac:
An architecture for anonymous low-volume communica-
tions.
In Privacy Enhancing Technologies Symposium
(PETS), 2010.
[31] Christo Wilson, Bryce Boe, Alessandra Sala, Kr-
ishna P.N. Puttaswamy, and Ben Y. Zhao. User inter-
actions in social networks and their implications.
In
Eurosys, 2009.
[32] Eric Gilbert and Karrie Karahalios. Predicting tie strength
In ACM Conference on Human
with social media.
Factors in Computing Systems (CHI), 2009.
[33] Wei Wei, Fengyuan Xu, C.C. Tan, and Qun Li. SybilDe-
fender: Defend against Sybil attacks in large social net-