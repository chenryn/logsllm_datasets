these results are given below.
MasterKey vs K-means++: Recall that the ﬁrst try for
all the adversaries was the mean of the available samples - so
MasterKey and targeted k-means++ start at the same level of
success as they utilize the same adversarial samples. But as it
can be seen from the highlighted segments of the Tables III, IV
and the Figure 2, the performance of our adversaries is lower
bounded by the performance of the MasterKey algorithm. The
tables and ﬁgures also show that Indiscriminate K-means++
also performs consistently better than MasterKey.
A signiﬁcant difference between the adversaries is that
MasterKey’s performance improves much more slowly as com-
pared to our adversaries. This is because it does not explore
the sample space of possible typing patterns well. Its tries are
derived from exploring outwards from the mean of adversarial
samples by perturbing values of this initial estimate - so it does
not improve much even after hundreds of tries. Meanwhile,
both the k-means++ algorithms continue to compromise more
users at regular intervals as can be seen in Figure 2. In
8
Classiﬁer
Manhattan
SVM
Gaussian
Gaussian Mixture
Autoencoder
Contractive Autoencoder
RandomForests
FC Neural Net
k-NN
MasterKey
1: 0.55
10: 0.61
50: 0.61
1: 0.65
10: 0.75
50: 0.78
1: 0.53
10: 0.57
50: 0.57
1: 0.67
10: 0.71
50: 0.82
1: 0.67
10: 0.73
50: 0.8
1: 0.65
10: 0.69
50: 0.78
1: 0.06
10: 0.18
50: 0.33
1: 0.0
10: 0.1
50: 0.14
1: 0.06
10: 0.31
50: 0.57
Targeted K-means++
1: 0.57
10: 0.67
50: 0.86
1: 0.65
10: 0.8
50: 0.92
1: 0.53
10: 0.69
50: 0.96
1: 0.65
10: 0.76
50: 0.96
1: 0.63
10: 0.8
50: 0.94
1: 0.65
10: 0.84
50: 0.94
1: 0.06
10: 0.31
50: 0.69
1: 0.0
10: 0.33
50: 0.73
1: 0.04
10: 0.37
50: 0.82
TABLE III: Fraction of users in the DSN dataset whose classiﬁers were compromised after 1, 10 and 50 tries of MasterKey
and Targeted K-means++ algorithms for each of the classiﬁers we used. The bold values highlight that K-means++ outperforms
MasterKey.
(a) Performance of adversaries against SVM classiﬁer on the MTurk dataset (b) Performance of adversaries against Random Forests classiﬁer on the MTurk
dataset
Fig. 2: Comparison of Targeted K-means++, MasterKey, and Indiscriminate K-means++ adversaries over ﬁrst 100 attempts. (a)
shows one of the best one class classiﬁers, and (b) shows one of the best two class classiﬁers.
particular, Targeted K-means++ seems to essentially be able
to compromise the security of all the users in the limit.
MasterKey also performs worse with a larger number of
users as in the MTurk dataset (Table IV, Figure 2). This also
seems to be a direct consequence of not exploring the sample
space of key-press timings beyond the mean very efﬁciently.
Especially since the MTurk data was collected over the Internet
rather than on a single machine, it was less uniform. Therefore,
9
Classiﬁer
Manhattan
SVM
Gaussian
Gaussian Mixture
Autoencoder
Contractive Autoencoder
Random Forests
FC Neural Net
k-NN
MasterKey
1: 0.272
10: 0.352
50: 0.444
1: 0.32
10: 0.394
50: 0.502
1: 0.306
10: 0.318
50: 0.344
1: 0.322
10: 0.45
50: 0.61
1: 0.322
10: 0.444
50: 0.596
1: 0.304
10: 0.37
50: 0.472
1: 0.022
10: 0.118
50: 0.274
1: 0.01
10: 0.202
50: 0.454
1: 0.09
10: 0.34
50: 0.58
Targeted K-means++
1: 0.272
10: 0.516
50: 0.836
1: 0.32
10: 0.552
50: 0.854
1: 0.306
10: 0.554
50: 0.88
1: 0.322
10: 0.634
50: 0.904
1: 0.322
10: 0.604
50: 0.878
1: 0.302
10: 0.52
50: 0.82
1: 0.022
10: 0.414
50: 0.782
1: 0.01
10: 0.492
50: 0.868
1: 0.092
10: 0.55
50: 0.936
Indiscriminate K-means++
1: 0.258
10: 0.374
50: 0.568
1: 0.288
10: 0.402
50: 0.588
1: 0.302
10: 0.424
50: 0.632
1: 0.314
10: 0.528
50: 0.742
1: 0.286
10: 0.424
50: 0.642
1: 0.292
10: 0.39
50: 0.566
1: 0.024
10: 0.306
50: 0.556
1: 0.01
10: 0.544
50: 0.818
1: 0.102
10: 0.536
50: 0.806
TABLE IV: Fraction of users in the MTurk dataset whose classiﬁers were compromised after 1, 10 and 50 tries of MasterKey,
Targeted K-means++, and Indiscriminate K-means++ for each of the classiﬁers. The bold values highlight that K-means++
adversaries outperformn Masterkey.
exploring around the mean of the sample space is not rewarded
as much as it is in the smaller DSN dataset.
One class vs two class classiﬁers:
For the one class
classiﬁers, it is particularly surprising to see a majority of the
user’s classiﬁers compromised after just a single try (Tables
III, IV). In comparison, the ﬁrst tries are not effective at all
against the two class classiﬁers. This was clearly because the
two class classiﬁers had access to some samples from the
impostors. It is worth noting that the classiﬁers only saw a
small proportion of the total samples from the impostors -
for instance, in the MTurk dataset, each classiﬁer only had
access to 50 impostor training samples, out of a total of over
50000 samples. This highlights the point that global EER
scores are not the ideal measure for the security guarantees
provided by such classiﬁers. Even then, the performance of
the adversaries against the two class classiﬁers in the limit
appears to be converging to the performance of the one class
classiﬁers (Figure 2). This suggests that even these idealized
two class classiﬁers are far from a great solution for keystrokes
authentication.
Targeted K-means++ vs Indiscriminate K-means++: De-
spite having access to almost 20 times less data,
the In-
discriminate K-means++ adversary still performed reasonably
well. Even though both the adversaries start close to each
other, unsurprisingly, the indiscriminate adversary was worse
than the more powerful, Targeted K-means++ in the long run
(Figure 2). But notice that the indiscriminate adversary never
plateaus, and continues to improve steadily up to a 100 tries,
reaching 55 − 75% range of compromised users. This steady
improvement highlights the fact that it has potential to improve
further if the indiscriminate adversary had more power - for
instance access to more data, or data with a longer subsequence
of the password.
DSN vs MTurk datasets:
In general, the results of the
EER scores, and adversarial attempts, appears to be consistent
across both the datasets. Therefore, we present the ﬁgures from
the MTurk dataset as it is bigger and more representative.
Conservative Thresholds: In the Figure 3, we vary the
acceptance threshold score for authentication to model stricter
security settings. We follow the same protocol for selecting
samples,
instead of setting the
threshold at the EER point, we set it based on the scores
the classiﬁer assigned the user’s test samples. We vary the
threshold from the 0th to 100th percentile of these test scores
training, and testing - but
10
(a) Targeted K-means++ against the Manhattan classiﬁer on the MTurk dataset(b) Indiscriminate K-means++ against the Random Forests classiﬁer on the
MTurk dataset
Fig. 3: Performance of the K-means++ adversaries against increasingly more conservative thresholds. The x-axis represents the
acceptance threshold of the given classiﬁer as a percentile of the user’s test scores. For instance, x = 50, represents a threshold
at which half the genuine user’s samples were rejected
- so for instance, at the 0th percentile, all the genuine user’s
test samples will be accepted, and at the 100th percentile, none
of these samples would be accepted. A threshold around the
median level is certainly not a very usable scenario in general.
But in certain high risk situations, for instance if the connection
to the account was from an unknown IP address, such measures
may make sense. As in the previous ﬁgure, we present the
plots on the MTurk dataset, but these trends are even more
pronounced on the smaller DSN dataset. In plot(a), we present
the plot of the Targeted K-means++ adversary against Man-
hattan, one of the best one class classiﬁers. This shows that
even with much more conservative thresholds the classiﬁers
are still not too effective - with the acceptance threshold set at
the median level, the adversary is still able to bypass nearly
half the users in 10 tries. In plot(b), we consider Indiscriminate
K-means++ against Random Forests, the best of the two class
classiﬁers. This shows a similar trend to the previous ﬁgure -
the indiscriminate adversary performs a little worse than the
targeted adversary, but still breaks a non trivial number of
users even against extremely conservative thresholds. Finally,
we would like to point out that the trend shown in these two
plots is also seen with different combinations of classiﬁers
and adversaries. This shows that these classiﬁers should not
be able to make the authentication systems arbitrarily secure
on demand by changing the acceptance thresholds.
3) Touchscreen swipes dataset results: We also ran our
whole suite of classiﬁers on the touchscreen swipes dataset,
however, most classiﬁers performed poorly on it. This is to
be expected as most of these classiﬁers were not used in