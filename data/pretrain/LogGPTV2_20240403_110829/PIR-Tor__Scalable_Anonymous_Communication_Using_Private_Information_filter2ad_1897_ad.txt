of the relay descriptors is about 3.3 MB. Thus the com-
munication overhead per client in the current Tor net-
work is about 1.1 MB every 3 hours (560 KB consensus
6 KB relay descriptors ), while the corresponding
and 3300
overhead in our architecture is 2 MB. Thus, CPIR-Tor is
not suited for the current Tor network size.
Scenario 2: Increasing clients. Total number of re-
lays is ﬁxed at 2 000. Total number of clients increases
 0.1 1 10 100 1000 1000 10000 100000 1e+06 1e+07Compute time(s)Number of relaysR=1R=2R=3R=4R=5 1e+06 1e+07 1e+08 1e+09 1e+10 1000 10000 100000 1e+06 1e+07Number of bytesNumber of relaysdownloadR=1R=2R=3R=4R=5 1 10 100 1000 1000 10000 100000 1e+06 1e+07Compute time(s)Number of relaysR=1R=2R=3R=4R=5Table 1: Summary of results: Comparison of overhead in Tor, CPIR and ITPIR. The communication overhead is
measured per client over a 3 hour interval.
CPIR
ITPIR
(MB / Cores)
(MB / % Core Utilization per guard)
Scenario Relays
Clients
1
2
3
4
5
2000
2000
20 000
20 000
250 000
250 000
2 500 000
250 000
2 500 000
250 000
Tor
(MB)
1.1
1.1
11
11
111
2 / 7
2 / 70
4 / 59
4 / 553
8 / 466
0.2 / 0.425%
0.2 / 4.25%
0.5 / 0.425%
0.5 / 4.25%
0.2 / 0.425%
by a factor of sc. The number of cores required to sup-
port sc · 250 000 clients is sc · 7 (linear increase). Thus if
the number of clients increases to 2.5 million, about 70
cores will be required to support the architecture. Both
the number of cores and the communication overhead of
the system increases linearly with the number of clients.
Scenario 3: Increasing relays. Total number of
relays increases by a factor of sr. Total number of
clients is ﬁxed. The number of cores required to support
sr · 2 000 relays increases sublinearly with sr. For exam-
ple, when the number of relays increases from 2 000 to
20 000, the required number of cores increases from 7 to
59. Note that in this scenario, the communication over-
head for CPIR-Tor also scales sublinearly, while that of
current Tor scales linearly. Thus, as the number of relays
increases, it becomes more and more advantageous to
use CPIR-Tor. For instance, when the number of relays
is 20 000, the communication overhead of Tor is 11 MB
every 3 hours, while that of CPIR is only 4 MB.
Scenario 4: Increasing both clients and relays. To-
tal number of relays and clients increases by a factor
of s. The number of cores required to support s · 2 000
relays and s · 250 000 clients is strictly less than 7 · s2.
In order to support 20 000 relays and 2.5 million clients,
553 cores would be required. We note approximately
50% of the Tor relays are already directory servers, so
553 cores in this scenario is feasible. Again, as the num-
ber of relays increases, the advantage of CPIR-Tor over
Tor becomes larger.
Scenario 5: Converting clients to middle-only re-
lays. Observe that if all 250 000 clients converted to
middle-only relays, then the server compute time for the
middle database is 20 seconds, while that for the exit
database is still 0.1 seconds. Thus, the total number of
cores required to support this scenario is approximately
466. (This scenario is not shown in Figure 4.) As com-
pared to the current Tor network, CPIR reduces the com-
munication overhead in the network from 111 MB per
client every 3 hours to only 8 MB.
Figure 4: Number of cores as a function of the number of
relays and clients (assuming half of the relays are exits).
8 Performance Evaluation of Information-
Theoretic PIR
We use an implementation [13] of the multi-server PIR
scheme by Goldberg [12] and compute the server compu-
tation, total communication, and client computation, for
varying values of the number of relays, using a descriptor
size of 2 100 bytes, and 3 servers.
Figure 5 plots server computation, total communica-
tion, and client computation as a function of the number
of Tor relays, using 3 PIR servers (the entry guards). We
note that the communication cost for a single ITPIR re-
quest is at least 2 orders of magnitude smaller than the
cost for a trivial download for all possible scaling sce-
narios.
Even if we compare the ITPIR-Tor protocol with the
Tor protocol over a period of 3 hours, where clients set up
18 circuits, still the communication overhead of ITPIR is
an order of magnitude smaller than a full download for
all scaling scenarios. Thus in this architecture, we do
not need to reuse blocks, providing security equivalent
to that of Tor, if at least a single guard relay is honest.
Recall that if all guard relays are compromised, then the
adversary can break user anonymity in both the current
 0 100 200 300 400 500 600 2 4 6 8 10 12 14 16 18 20 0 0.5 1 1.5 2 2.5 0 100 200 300 400 500 600CoresRelays  (thousands)Clients  (milions)Cores(a) Server computation
(b) Total communication
(c) Client computation
Figure 5: 3-server ITPIR cost.
Tor network as well as in PIR-Tor, by selectively deny-
ing service [4] to circuits that have an honest exit relay
(or destination server) and performing end-to-end timing
analysis [2] when the exit relay (or destination server) is
compromised.
We now explore various scaling scenarios for Tor, and
compute the number of clients that each guard relay can
support, along with a comparison of the communication
cost to that of Tor. Our results are summarized in Table 1.
Scenario 1: Current Tor Size. Total number of re-
lays is 2 000. Total number of clients is 250 000. For
2 000 relays, the number of exit nodes is around 1 000,
and the corresponding server compute time is 0.005 sec-
onds. Thus to support a single circuit, the total server
compute time is 0.005 seconds (for all three guards com-
bined). Note that each client builds a circuit every 10
minutes. A single guard relay would thus be able to sup-
port 360 000 clients. In the current Tor network, there
are 250 000 clients, and approximately 500 guard relays,
so each guard relay needs to service only 1500 clients on
average, and would utilize only 0.425% of one core. The
communication overhead of Tor is 1.1 MB per client ev-
ery 3 hours. In ITPIR, the cost to build a single circuit is
only 12 KB. Even if clients build 18 circuits over a three
hour interval, the total communication cost of all 18 cir-
cuits is 216 KB. Thus ITPIR is useful even with the size
of the current Tor network.
Scenario 2: Increasing clients. Total number of re-
lays is ﬁxed at 2 000. Total number of clients increases
by a factor of sc. In order to support sc · 250 000 clients,
guard relays would need to utilize sc · 0.425% of a core.
Thus even when the number of clients increases to 2.5
million, but the number of guard relays stays ﬁxed at 500,
then each guard relay only utilizes a 4.25% fraction of a
core. The total communication overhead in the system
increases linearly with the number of clients, similar to
the current Tor network.
Scenario 3: Increasing relays. Total number of
relays increases by a factor of sr. Total number of
In order to support sr · 2 000 relays,
clients is ﬁxed.
guard relays would need to utilize only 0.425% of a core.
This is because the size increase in the PIR database
is offset by the increase in the number of guard relays.
Thus, regardless of the number of relays in the system,
each guard relay utilizes only 0.425% of a core. Also, as
the number of relays increases, the advantage of ITPIR
over a full download in terms of communication cost also
increases. For instance, at 2 000 relays ITPIR is a factor
of 5 more efﬁcient than Tor, while at 20 000 relays, IT-
PIR is a factor of 22 more efﬁcient than Tor (516 KB per
client every 3 hours as compared to 11.1 MB in Tor).
Scenario 4: Increasing both clients and relays. To-
tal number of relays and clients increases by a fac-
In order to support s · 250 000 clients, and
tor of s.
s · 2 000 relays, each guard relay would need to utilize
s · 0.425% of a core. Thus when the number of clients
is 2.5 million, and the number of relays is 20 000, each
guard relay utilizes 4.25% of a core. Even at 100 times
the current client base (25 million), 42% of one core is re-
quired, which may be reasonable in multi-core settings.
As the number of clients increases, the communication
overhead in both ITPIR and Tor increases linearly, while
as the number of relays increases, it becomes a lot more
advantageous to use ITPIR as compared to Tor.
Scenario 5: Converting clients to middle-only re-
lays. Observe that if all 250 000 clients converted to
middle-only relays, then the server compute time for the
guard relays remains unchanged, since PIR is not per-
formed over the middle database. Thus each guard relay
would still utilize only 0.425% of a core.
To further highlight the scalability of ITPIR, we also
consider a scenario where all 250 000 clients convert to
relays, with a similar distribution of guard/middle/exit
relays as in the current Tor network. The communication
overhead of ITPIR in this scenario is 1.7 MB per client
every 3 hours, while that of Tor is 137 MB — two orders
of magnitude higher.
 0.01 0.1 1 10 100 1000 1000 10000 100000 1e+06 1e+07Compute time(s)Number of relays18 ITPIR1 ITPIR 10000 100000 1e+06 1e+07 1e+08 1e+09 1e+10 1000 10000 100000 1e+06 1e+07BytesNumber of relaysdownload18 ITPIR1 ITPIR 1e-05 0.0001 0.001 0.01 0.1 1000 10000 100000 1e+06 1e+07Compute time(s)Number of relays18 ITPIR1 ITPIR9 Discussion
We now discuss some issues in, and ramiﬁcations of, our
design.
Comparison of CPIR vs. ITPIR. The CPIR-Tor ar-
chitecture does not require all guard relays to be direc-
tory servers, and is more easily integrated into the current
Tor network, where a random subset of the relays are di-
rectory servers. Moreover, it is ideal for the scenarios
where either a client’s browsing time is small (possibly
estimated using the client’s past Tor browsing history),
or the client is not interested in the unlinkability of its
connections. On the other hand, the ITPIR-Tor architec-
ture requires all guard relays to be directory servers, thus
requiring them to maintain a global view of the system,
but results in signiﬁcant communication savings for the
clients. The ITPIR-Tor architecture can support a vari-
ety of client workloads, while providing a high level of
security. In particular, ITPIR-Tor can enable a very at-
tractive scenario where all clients become middle-only
relays, without any additional cost to the network, since
the middle relays are fetched for free (without doing PIR)
by the clients.
Robustness. Recall that each block of the descriptor
database is digitally signed by the trusted directory au-
thorities. These signatures prevent malicious PIR servers
from tricking clients into accepting false information.
However, such malicious servers could still deny service
to clients by returning garbage, or by not returning a re-
sponse at all. As we discuss next, in both CPIR-Tor and
ITPIR-Tor clients can easily detect this attack and can
stop using those malicious servers.
In CPIR-Tor, a malicious directory server could mod-
ify its own copy of the descriptor database in order to cor-
rupt blocks containing, for example, many honest nodes,
and leave with correct signatures those blocks containing
collaborating malicious nodes. Clients retrieving these
“malicious blocks” will be successful, but clients retriev-
ing “honest blocks” will not. In order to defend against
this, a CPIR-Tor client that receives even one corrupted
block (out of b requests) from a given (Byzantine) direc-
tory server should discard the entire response, and make
a new, freshly randomly chosen query for all b blocks
from a different server. It should also avoid using that
Byzantine server in the future.
In ITPIR-Tor, on the other hand, such a selective-
corruption attack is not possible unless all three guard
nodes are colluding. In the ITPIR-Tor setting, Byzantine
guard nodes can corrupt the result of the query, but not in
a way that depends on which block was requested. Un-
fortunately, with ITPIR-Tor as presented, although the
client will detect the corruption, it will not learn which
of the guard nodes was Byzantine. This can be rectiﬁed,
however, using the Byzantine robustness techniques of
the underlying ITPIR protocol [12]. In particular, a client
receiving blocks with correct signatures may safely use
those blocks. If there are corrupted blocks, the client can
identify which guard node(s) were Byzantine, and caus-
ing the corruption, by extending the queries for just the
corrupted blocks to additional guard nodes. When three
honest guard nodes are reached, even though the client
does not know a priori which are the honest ones, the
Byzantine nodes will be identiﬁed. However, this may
come at the cost of the Byzantine nodes (if there are at
least three) learning which exit block the client was inter-
ested in. Therefore, the client should not use the resulting
information to build circuits; it should only use it to learn
which nodes were Byzantine and thus should be avoided
in the future.
Additional scaling strategies. The Tor Project has
been actively working on improving its scaling proper-
ties. We now discuss some strategies under consideration
that may be implemented in the future. The ﬁrst strategy
is to download relay descriptors on demand [34] during
the circuit construction process, as opposed to periodi-
cally fetching them in advance. Fetching descriptors on
demand would signiﬁcantly reduce the communication
overhead in Tor. However, note that fetching descriptors
on demand does not satisfy our goal of efﬁcient circuit
creation, since descriptor downloads increase circuit cre-
ation times.
The second strategy introduces the idea of microde-
scriptors [8], which contain all relay descriptor ﬁelds that
rarely change. All frequently changing ﬁelds are placed
in the network consensus. Clients download the network
consensus document frequently, but the microdescriptors
are cached on a long-term basis. We note that this pro-
posal is orthogonal to our architecture, and can be incor-
porated in the PIR-Tor protocol.
In this case, the PIR
database would consist of only the network consensus
information. The size reduction in the PIR database be-
cause of the removal of microdescriptors would translate
into both computational and communication savings in
our architecture.
Computational puzzles to prevent DoS.
In our archi-
tecture, directory servers act as PIR databases and per-
form computation to respond to user queries. This pro-
vides an opportunity to the attacker to launch a denial
of service (DoS) attack against the directory servers by
issuing multiple PIR queries. We propose to use com-
putational puzzles to mitigate the impact of this attack.
When a directory server begins to get computationally
congested, it starts to issue computational puzzles to
clients. Clients solve the computational puzzle and re-
turn the solution to the directory server. The directory
server veriﬁes the puzzle solution, and only then starts
to spend computational resources to process the client’s
PIR query.
Impact of churn.
In the current Tor network, as the
churn in the network increases, clients will have to down-
load the full list of network consensus and relay descrip-
tors more frequently. On the other hand, the impact of
churn on PIR-Tor is minimal, since only a small number
of directory servers or guards will need to download the
global view more frequently. In fact, as long as the rate
of database updates is longer than 10 minutes (it is cur-
rently set to 3 hours), we can expect the number of client
PIR queries to be the same.
Impact of number of circuits. The communication
overhead of PIR-Tor is directly proportional to the num-
ber of circuit constructions, since for optimal security,
clients need to perform 1 or 2 PIR queries per circuit.
Tor developers are already working on a proposal to have
a separate circuit for each application, to prevent certain