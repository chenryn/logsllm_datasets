0.0001
13.4%
27.5%
42.5%
98.72%
99.92%
99.98%
14.2%
32.3%
54.3%
89.34%
99.95%
99.99%
size) divided by the total number of raw messages (uncompressed
information size). Second, we validate the event digests output by
SyslogDigest to see whether they are good representation of real
network events. This validation process done manually by peo-
ple who have rich network experiences and domain knowledge on
these two operational networks.
5.2 Components Effectiveness
We ﬁrst evaluate our design choices in message template identi-
ﬁcation, association rule mining and temporal mining components
shown in Figure 1.
5.2.1 Message Template Identiﬁcation
SyslogDigest automatically abstracts the template of each type
of syslog messages. We validate our template abstraction method
presented in Section 4.1 by comparing the syslog message tem-
plates identiﬁed by SyslogDigest with the “ground truth” templates
obtained from hard-coding comprehensive domain knowledge on
syslog. The domain knowledge we used here are very speciﬁc to
certain router vendors. Hard-coding domain knowledge is clearly
not scalable, and hence we use it only for validation purpose. Note
that such kind of methods require the knowledge of all message
format in advance, which is not practical specially when there are
many messages types and facing different syslog data sources. We
observe that 94% of message templates matches. It indicates our
learning approach can extract the template fairly well.
5.2.2 Association Rule Mining
In order to generated rules, we use three months (Sep 2009 to
Nov 2009) for mining for both datasets.
There are three parameters used by SyslogDigest in mining as-
sociation rules between syslog messages: Window size W , the
threshold of minimal support SPmin, and the minimal conﬁdence
Confmin. We evaluate the sensitivity of these parameter setting
on learning associations between syslog message. In particular, we
vary W from 5 to 300 seconds and Confmin from 0.5 to 0.9. We
also set SPmin at values 0.001, 0.0005, 0.0001. The implication
of these settings of SPmin in our context is shown in Table 5. For
example, when SPmin = 0.005, the top 27.5% types of messages
will be used in rule mining and these types of messages cover over
99.9% of all messages in dataset A.
Figure 6 shows the number of association rules learned from
dataset with ﬁxing the value of W to be 1 minute and varying the
values of SPmin and Confmin. As we expected, the number of
rules decreases as the value of Confmin increases. In addition,
the higher the value of SPmin is, the fewer rules learned from the
dataset. Similar observations hold different values of W . In our
experiments, we set Confmin = 0.8 and SPmin = 0.0005. With
this setting, Figure 7 shows the number of generated rules by vary-
ing the value of W . We observe that the number of rules increases
as W increases. However, the increase in the number rules dimin-
ishes at W = 120 seconds for dataset A and W = 40 second for
dataset B. That is, the number of rules learned by SyslogDigest is
less sensitive to the value of W when W is large. A detailed anal-
ysis on the rules reveals that the newly added rules by increasing
W often captures implicit timing relationship between two types
Suppmin = 0.001
Suppmin = 0.0005
Suppmin = 0.0001
l
s
e
u
r
f
o
r
e
b
m
u
n
e
h
T
 700
 600
 500
 400
 300
 200
 100
 0.5  0.55  0.6  0.65  0.7  0.75  0.8  0.85  0.9
Confmin
Figure 6: The impact of parameter SPmin and Confmin, in
dataset A.
l
s
e
u
r
f
o
r
e
b
m
u
n
e
h
T
 450
 400
 350
 300
 250
 200
 150
 100
 50
 0
Dataset A
Dataset B
 60
 120
 180
 240
 300
Window size (seconds)
Figure 7: The impact of parameter W , when Confmin = 0.8
and SPmin = 0.0005.
of messages. For example, in dataset A, we observe that when W
changes from 10 to 30 seconds, there are several new rules added
to the knowledge base. These rules associate the controller ﬂap,
link ﬂap andline protocol ﬂap messages, indicating that these types
of messages usually occur together between 10-30 apart. Similarly,
in dataset B we ﬁnd that ftp login failure and ssh login failure mes-
sages are associated together when W is set to 30 - 40 seconds.
Next, we present results on association rule mining with using W
= 120 seconds for dataset A and W = 40 seconds for dataset B.
The association rule mining is performed weekly by SyslogDi-
gest to (i) add new rules to the knowledge base, and (ii) iden-
tify invalid rules in the knowledge base and remove them using
the method presented in Section 4.1.4. Figure 8 and Figure 9
show the total number of rules in the knowledge base as well as
added/deleted rules for each week from week 2 to week 12. The
number of rules in the knowledge base becomes stable after week
6 for dataset A and after week 8 for dataset B. This is because the
number of added and deleted rules are close to zero after few weeks
for both datasets.
We further validated the rule sets obtained at the end of week
12 with expert domain knowledge and vendor documentations. We
found that almost all the rules are consistent with either the domain
knowledge or the expected behaviors speciﬁed in vendor documen-
tations. Thus, we believe that SyslogDigest successfully captures
network behaviors using automatically learned rules. However, we
did report a few “unexpected” rules (3 rules for dataset A and 16
rules for dataset B), which means the potential false positive rate
480l
s
e
u
r
f
o
r
e
b
m
u
n
e
h
T
 500
 450
 400
 350
 300
 250
 200
 150
 100
 50
 0
Total rules
Deleted rules
Added rules
 2
 4
 6
 8
 10
 12
The number of weeks
Figure 8: The number of rules over 12 weeks, dataset A.
l
s
e
u
r
f
o
r
e
b
m
u
n
e
h
T
 400
 350
 300
 250
 200
 150
 100
 50
 0
 2
Total rules
Deleted rules
Added rules
 4
 6
 8
 10
 12
The number of weeks
Figure 9: The number of rules over 12 weeks, dataset B.
is less than 0.05 during rule mining. These unexpected rules are
currently under investigation.
5.2.3 Temporal Pattern Mining
The goal of temporal pattern mining is essentially to ﬁnd the
proper parameter α and β, such that the underlying interarrival
model can present the temporal patterns very well. In other words,
we want to ﬁnd α and β such that we can group messages appropri-
ately (i.e. compression ratio would be optimal). Figure 10 shows
the compression ratio of temporal grouping with α varying from 0
to 0.6 and β = 2 (i.e., if a new message arrives at an interval that is
at least twice of the predicted interval, the message is put in a sepa-
rate group). We observe that in both datasets, the larger the value of
α is the higher the compression ratio is, except for very small value
of α (e.g., α < 0.05). The lowest (i.e., best) compression ratio is
achieved when α = 0.05 for dataset A and α = 0.075 for dataset
B. They will be used as the default value for α in the remaining
experiments.
Figure 11 shows the impact of varying value of β (from 2 to 7)
on the compression ratio with α being set at the default values. We
observe that the compression ratio ﬁrst decreases as we increase
the value of β. This is consist to our intuition because a larger
β value means larger intervals are used in temporal grouping of
messages and hence fewer number of groups are output. We also
observe that the improvement of compression diminishes when β
increases. Thus, we set β = 5 for both datasets.
In summary, Table 6 shows the parameter settings in SyslogDi-
gest. The rules of thumb are of choosing parameters are (1) to
ensure the stability of rule sets and (2) to ensure the stability of the
e
t
a
r
s
s
e
r
p
m
o
c
e
h
T
 0.09
 0.08
 0.07
 0.06
 0.05
 0.04
 0.03
 0.02
 0.01
 0
 0
Dataset A
Dataset B
 0.1
 0.2
 0.3
 0.4
 0.5
 0.6
Parameter α
Figure 10: The impact of varying value of α on the compression
ratio (β = 2).
Dataset A
Dataset B
e
t
a
r
s
s
e
r
p
m
o
c
e
h
T
 0.019
 0.018
 0.017
 0.016
 0.015
 0.014
 0.013
 0.012
 0.011
 0.01
 0.009
 0.008
 2
 3
 4
 5
Parameter β
 6
 7
Figure 11: The impact of varying value of β on the compression
ratio (α = 0.05 for dataset A and α = 0.075 for dataset B).
Table 6: Parameter setting in SyslogDigest
Dataset
A
B
α
0.05
0.075
β W (Dataset A/B)
5
5
120
40
SPmin Confmin
0.0005
0.0005
0.8
0.8
compress ratio, as we discussed through Section 5.2. These values
in Table 6 will be used in the rest of our experiments presented in
this paper.
5.3 Performance of SyslogDigest
Using the domain knowledge base built by applying ofﬂine
learning on three months of syslog data, we run SyslogDigest in
online mode and generate event digests for 2 weeks of syslog data
to evaluate the effectiveness of the entire system. Note that it gen-
erally takes less than one hour to digest one day’s syslog. Table 7
shows compression ratios of different message grouping method-
ologies for both datasets. We found that the compression ratio
varies by grouping method by dataset. Overall, the number of event
digests is over three orders of magnitude smaller than the number
of raw syslog messages. This is fairly substantial information com-
pression/reduction.