vides a conservative estimate for the number of non-exit
IP addresses that get blacklisted. In contrast, the Snort
IP blacklist (another proactive list) enlists nearly 37% of
exit IP addresses but less than 1% of non-exit relays.
5.4 Blacklisting of Tor vs. VPN nodes
VPN services are similar to Tor since they provide users
with the option to obscure their IP addresses. In addition,
like Tor exit relays, VPN nodes also egress trafﬁc belong-
ing to many users who could be using the VPN service
for different purposes. In this section we compare black-
listing of Tor with that of popular VPN providers.
VPN providers
like VPNGate [30] and Hide-
MyAss [31] publish lists of their free-tier endpoints,
making them good candidates for our study. Figure 2c
shows, that in February 2017, over 88% of Tor exits are
blacklisted (excluding the proactive blacklists) on one or
more of the commercially available blacklists. In com-
parison, 10% of VPNGate endpoints and 69% of HMA
endpoints appear on blacklists. All of these proxy ser-
vices are considerably more blacklisted as compared to
the IP space of a major university (three /16 preﬁxes used
by the university campus network), of which only 0.3%
IPs are blacklisted.
To have a fair comparison of the rate of blacklisting
with Tor, we need a set of VPN endpoint IP addresses
and a notion of when they ﬁrst began to operate as VPN
endpoints (similar to the notion of exit relays and their
birth in the consensus). However, it is challenging to
gather the IP addresses of VPN nodes over time since
most VPN services do not archive such information. This
is in contrast with Tor, which archives information about
Figure 4: Comparing the time taken for Tor exit IP ad-
dresses and HMA endpoints to get blacklisted.
its relays on an hourly basis. However, the VPN provider
HideMyAss (HMA) publishes a daily list of its free VPN
endpoints [31]. We crawled archived versions of this list
using the Wayback Machine [32] for IP addresses pub-
lished between June 14, 2014 and October 27, 2016.
We can then approximate the time when an IP address
ﬁrst served as an HMA VPN endpoint, assuming this oc-
curs at least 60 days after the start of the time frame. In
this manner we collected a set of 4,234 HMA endpoints
and their ﬁrst seen creation times. Of these, 1,581 IP
addresses became HMA endpoints after our IP address
reputation system started gathering blacklist data. We
analyze the blacklisting of these endpoints using the IP
reputation system.
Figure 3 shows the fraction of HMA endpoints black-
listed by various blacklists. Unlike for Tor relays, no
particular blacklist dominates in the listing of HMA IPs.
Figure 4 shows how quickly HMA endpoints get black-
listed compared to Tor exits; reactive blacklisting of both
occurs at a similar rate.
USENIX Association
26th USENIX Security Symposium    331
0.000.250.500.751.00−50000500010000Time until enlistment of Tor IPsin paid−aggregator (in hours)CDFExit IPsNon−exit IPs0.000.250.500.751.000500010000Time until enlistment of Tor IPsin Contributed Blacklist 12 (in hours)CDFExit IPsNon−exit IPs0.000.250.500.751.00University IPsVPNGateHMA VPNTor ExitsTypes of IP AddressesFraction Blacklisted0.000.250.500.751.00−50000500010000Seen in IP blacklists after (Hours)CDFHMA IP addressesTor Exit IP addressesFigure 3: Fraction of Tor relay and HMA VPN IP addresses listed in IP blacklists (including proactive and reactive).
Some feed names are derived based on the broad categories of undesired trafﬁc they blacklist: e.g., ssh (badips-ssh,
dragon-ssh), content management systems/Wordpress (badips-http, badips-cms).
5.5 Exit policies and bandwidth
We looked for but did not ﬁnd any associations between
various factors and blacklisting. In an attempt to counter
IP blacklisting and abusive trafﬁc, the Tor community
has suggested that exit operators adopt more conserva-
tive exit policies [18]. Intuitively, a more open exit pol-
icy allows a larger variety of trafﬁc (e.g., BitTorrent, ssh,
telnet) that can lead to a larger variety of undesired trafﬁc
seen to originate from an exit. We analyze the exit relays
that ﬁrst appeared in the consensus after the IP reputation
system started to gather data using the hourly consen-
suses of year 2015 and 2016. Since exit relays have a va-
riety of exit policies, we ﬁnd which well-known exit pol-
icy (Default, Reduced, Reduced-Reduced, Lightweight,
Web) most closely matches the relay’s exit policy. To
compute this closeness between exit policies, we calcu-
late the Jaccard similarity between the set of open ports
on a relay and each well-known exit policy.
(See Ap-
pendix B). In this way, we associated approximate exit
policies to 21,768 exit relays. We found that in the last 18
months, only 1.2% of exit relays have exhibited different
well-known exit policies, and excluded these from our
analysis. In the resulting set of exits, we assigned 81%
to Default, 17% to Reduced, 0.6% to Reduced-Reduced,
0.5% to lightweight and 0.4% to Web policy.
We also compute the uptime (in hours) for each of the
exit relays as the number of consensuses in which the
relay was listed. In addition, we maintain the series of
consensus weights that each relay exhibits in its lifetime.
Higher consensus weights imply more trafﬁc travelling
through the relay, proportionally increasing the chance
of undesired trafﬁc from a relay. A high uptime increases
the chance of use of a relay for undesired activities.
We trained a linear regression model on the policies,
scaled uptimes, and consensus weights of exit relays,
where the observed variable was the ratio of hours the IP
address was blacklisted (reactive blacklisting only) and
its overall uptime. Based on the coefﬁcients learned by
the regression model, we conclude that policy, consensus
weight, and relay uptime have very little observed asso-
ciation on IP blacklisting of Tor relays. We provide more
details about the regression model in Appendix C.
5.6 Our Newly Deployed Exit Relays
As described in Section §3, we operated exit relays of
various bandwidth capacities and exit policies to actively
monitor the response of the IP reputation system.
In
this subsection, we analyze the sequence of blacklisting
events for each exit relay that we ran. Figure 5 shows the
timeline of blacklisting events for each of the exit relays
we operated. Each coloured dot represents an event. An
event is either the appearance of a relay on a blacklist or
its appearance in the consensus (an up event).
Prior to launching the exits, none of our prospective
relays’ IP addresses were on any blacklist. We see that
within less than 3 hours of launching, feeds like Snort
IP listed all our relays, supporting our classiﬁcation of
Snort IP as a proactive blacklist. Additionally, both Snort
IP and Paid Blacklist (also classiﬁed as proactive) block
our relay IP addresses for long periods of time. Snort
IP enlists all of relays, and did not remove them for the
entire duration of their lifetime. Paid Blacklist enlists IP
addresses for durations of over a week. Blacklists such
as badips-ssh (for protecting SSH) and badips-cms (for
protecting content management systems such as Word-
press and Joomla) have short bans spanning a few days.
Contributed Blacklist 12 has the shortest bans, lasting
only a few hours. We consider Contributed Blacklist 12’s
blacklisting strategy in response to undesired trafﬁc to be
in the interest of both legitimate Tor users and content
providers that do not intend to lose benign Tor trafﬁc.
On November 29, 2016, we turned off all of our relays
332    26th USENIX Security Symposium
USENIX Association
0.000.250.500.751.00dragon−sshbadips−qmail−smtpContributed BL 12badips−sshContributed BL 14Contributed BL 11badips−postfixbadips−cmsbadips−httpContributed BL 9Contributed BL 15snort−ipContributed BL 10blocklistde−ip−blacklistpaid−ip−blacklistContributed BL 8paid−aggregatorIP blacklistFraction of IPs on blacklistExit relay IP addressesNon−exit relay IP addressesHMA VPN IP addressesFigure 5: Blacklisting of our exit relays over time. Each coloured dot shows the instant when a relay was on a blacklist.
Snort IP and Paid Blacklist have long term bans while other blacklists enlist IPs for short periods of time ranging from
hours to a few days.
to observe how long a proactive blacklist like Snort IP
would take to de-enlist our relays. We observe that such
blacklists drop our relays just as fast as they enlist them,
suggesting a policy of crawling the Tor consensus.
Note that a synchronised absence of data from any
blacklist, while the relays are up, represents an outage
of the IP reputation system.
6 Crawling via Tor
To quantify the number of websites discriminating
against Tor, we performed crawls looking both at front-
page loads, as in prior work [2], and at search and login
functionality. We crawled the Alexa Top 500 web pages
from a control host and a subset of Tor exit relays. These
crawls identify two types of discrimination against Tor
users: (1) the Tor user is blocked from accessing con-
tent or a service accessible to non-Tor users, or (2) the
Tor user can access the content or service, but only after
additional actions not required of non-Tor users—e.g.,
solving a CAPTCHA or performing two-factor authenti-
cation.
6.1 Crawler Design
We developed and used a Selenium-based interactive
crawler to test the functionality of websites. We per-
formed three types of crawls: (1) Front-page crawls at-
tempt to load the front page of each website. We repeated
the crawl four times over the course of six weeks. (2)
Search functionality crawls perform front-page loads and
then use one of ﬁve heuristics (Table 5) to scan for the
presence of a “search box”. Upon ﬁnding the search box,
the crawler enters and submits a pre-conﬁgured search
query. Our crawler found and tested the search func-
tionality of 243 websites from the Alexa Top 500. We
performed the search functionality crawl once. (3) Login
functionality crawls load front pages and scan them for
the presence of a “login” feature. Upon ﬁnding the fea-
ture, and if it has credentials for the webpage available,
the crawler authenticates itself to the site (using Face-
book/Google OAuth when site-speciﬁc credentials were
unavailable). We created accounts on OAuth-compatible
websites prior to the crawl. Since the created accounts
had no prior history associated with them, we speculate
that they were unlikely to be blocked as a result of un-
usual behavior. For example, we found that LinkedIn
blocks log ins from Tor for accounts with prior log in
history, but not for new accounts. Our crawler found
and tested the login functionality of 62 websites from
the Alexa Top 500. We performed the login functionality
crawl once.
The crawler records screenshots, HTML sources, and
HARs (HTTP ARchives) after each interaction. Our in-
teractive crawler improves upon previous work in sev-
eral ways. First, it uses a full browser (Firefox) and in-
corporates bot-detection avoidance strategies (i.e., rate-
limited clicking, interacting only with visible elements,
and action chains which automate cursor movements
and clicks). These features allow it to avoid the (bot-
)based blocking observed while performing page-loads
via utilities such as curl and other non-webdriver li-
braries (urllib). Second, its ability to interact with
websites and exercise their functionality allows us to
USENIX Association
26th USENIX Security Symposium    333
||||||||||GGGGGGGGGGGGGGLarge−Default−2Large−Default−1Medium−Default−2Medium−Default−1Medium−RR−2Medium−RR−1Small−Default−2Small−Default−1Small−RR−2Small−RR−110/10/1610/17/1610/24/1610/31/1611/07/1611/14/1611/21/1611/28/1612/05/1612/12/1612/19/1612/26/1601/02/1701/09/1701/16/1701/23/1701/30/17TimeRelay NicknamesGGGGGGGGGGbadips−cmsbadips−httpbadips−sshblocklistde_ip_blacklistContributed BL 12Contributed BL 9packetmail−ippaid−ip−blacklistsnort−ipupHeuristic
1. Visible and clickable textbox elements contain-
ing search related keywords (q, query, querytext,
search) in their element name, id, value, or label
are assumed to be search boxes.
2. The above heuristic is repeated while considering
all input DOM elements.
3. If the DOM contains exactly one visible and click-
able textbox element, it is assumed to be a search box.
4. If the DOM contains exactly one visible and click-
able input element with a deﬁned max-length, it is
assumed to be a search box.
5. If the DOM contains exactly one visible and click-
able input element, it is assumed to be a search box.
Coverage
98
81
22
12
30
Table 5: Heuristics used to identify search input boxes.
Heuristics are described from most speciﬁc to least spe-
ciﬁc. Coverage indicates the number of sites that were
identiﬁed using the corresponding heuristic.
identify cases where discrimination occurs beyond the
front page — e.g., www.tumblr.com serves Tor users
CAPTCHAs only after they submit a search query, and
www.imdb.com blocks Tor users when they attempt to
log in.
6.2 Relay selection
We randomly selected 100 exit relays from the set of all
exit relays that supported HTTP(S) connections (i.e., the
exit policy allows outbound connections to ports 80 and
443). In addition to these randomly sampled relays, we
also conducted crawls through our own relays (described
in Table 1) and a university-hosted control host.
Since we performed our crawls over a six-week pe-
riod, several of the selected exit relays intermittently
went ofﬂine, with a total of 0, 12, 19, and 28 ofﬂine dur-
ing crawls 1–4, respectively. We account for the result-
ing page-load failures by excluding the failures from our
analysis.
Identifying discrimination
6.3
In each of our experiments we simultaneously performed
crawls exiting through all online sampled exits and our
university-hosted control host. To identify discrimina-
tion of a selected exit relay, we ﬁrst rule out cases of
client and network errors through HAR ﬁle analysis. We
use the HAR ﬁles to verify, for each page load, that (1)
the requests generated by our browser/client were sent to
the destination server (to eliminate cases of client error),
and (2) our client received at least one response from the
corresponding webpage (to eliminate cases of network
errors). If, for a given site, either the control host or the
selected exit relay did not satisfy both these conditions,
we did not report discrimination due to the possibility of
a client or network error.
Next, we compare the crawler-recorded screenshots of
the control server and each selected exit relay using per-
ceptual hashing (pHash) [33], a technique that allows us
to identify the (dis)similarity of a pair of images. We re-
port images with high similarity scores (pHash distance
 0.75)
as cases of discrimination, while ﬂagging others for fur-
ther inspection. The thresholds were set so that only
pages with extreme differences in content and structure
would be automatically ﬂagged as cases of discrimina-
tion, while similar pages were automatically ﬂagged as
cases of non-discrimination. In general, minor changes
in ads/content (e.g., due to geo-location changes) do not
result in ﬂagging. We set the thresholds using data ob-
tained from a pilot study (Figure 6).
Figure 6: Results of pilot study to identify pHash dis-
tance thresholds for automatically identifying cases of
(non) discrimination. We manually tagged 500 ran-
domly chosen samples (i.e., pairs of control and exit re-
lay screenshots of the same website) and computed the
pHash distances. Based on the above distribution, we
classiﬁed distances  0.75 as “discrimination”. Instances having
pHash distances in the 0.40 to 0.75 range were manually
inspected and tagged.
Then, we classiﬁed as discrimination cases where exit
relays received HTTP error codes for requests that our
control host successfully loaded with a 200 status. Fi-
nally, we manually tag the screenshots of remaining
cases to identify more subtle discrimination—e.g., a
block-page served with a 200 status.
6.4 Results
Table 6 summarizes the main results of our three types of
crawls over compatible websites in the Alexa Top 500.
Here, we show the fraction of interactions on which dis-
crimination was detected. We ﬁnd that 20.03% of all
Alexa Top-500 (A-500) website front-page loads showed
evidence of discrimination against Tor users, compared
334    26th USENIX Security Symposium
USENIX Association
0.00.20.40.60.81.0pHash distance between screenshots020406080100120140Samples observedDiscriminationNo DiscriminationOverlapto 17.44% of the search-compatible (S-243) and 17.08%
of the login-compatible (L-62) website front-page loads.
When exercising the search functionality of the 243
search-compatible websites, we see a 3.89% increase in
discrimination compared to the front-page load discrim-
ination observed for the same set of sites. Similarly,
when exercising the login functionality of the 62 login-
compatible websites, we observe a 7.48% increase in dis-
crimination compared to the front-page discrimination
observed for the same set of sites.
Websites
A-500
Interaction
Front page
Discrimination observed
20.03%
S-243
L-62
Front page
Front page + Search
17.44%
21.33% (+3.89%)
Front page
Front page + Login
17.08%
24.56% (+7.48%)
Table 6: Fraction of interactions blocked from 110 ex-
its. A-500 denotes the Alexa Top 500 websites, S-243
denotes the 243 search-compatible websites, and L-62
denotes the 62 login-compatible websites.