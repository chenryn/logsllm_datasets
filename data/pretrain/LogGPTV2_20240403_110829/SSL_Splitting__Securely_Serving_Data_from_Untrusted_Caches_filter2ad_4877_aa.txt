title:SSL Splitting: Securely Serving Data from Untrusted Caches
author:Chris Lesniewski-Laas and
M. Frans Kaashoek
USENIX Association
Proceedings of the
12th USENIX Security Symposium
Washington, D.C., USA
August 4–8, 2003
© 2003 by The USENIX Association
Phone: 1 510 528 8649
FAX: 1 510 548 5738
THE ADVANCED COMPUTING SYSTEMS ASSOCIATION
All Rights Reserved
Email: PI:EMAIL
For more information about the USENIX Association:
WWW: http://www.usenix.org
Rights to individual papers remain with the author or the author's employer.
 Permission is granted for noncommercial reproduction of the work for educational or research purposes.
This copyright notice must be included in the reproduced paper. USENIX acknowledges all trademarks herein.
SSL splitting: securely serving data from untrusted caches
Chris Lesniewski-Laas and M. Frans Kaashoek
{ctl,kaashoek}@mit.edu
Laboratory for Computer Science
Massachusetts Institute of Technology
Abstract
A popular technique for reducing the bandwidth load on
Web servers is to serve the content from proxies. Typ-
ically these hosts are trusted by the clients and server
not to modify the data that they proxy. SSL splitting is
a new technique for guaranteeing the integrity of data
served from proxies without requiring changes to Web
clients. Instead of relaying an insecure HTTP connec-
tion, an SSL splitting proxy simulates a normal Secure
Sockets Layer (SSL) [7] connection with the client by
merging authentication records from the server with data
records from a cache. This technique reduces the band-
width load on the server, while allowing an unmodiﬁed
Web browser to verify that the data served from proxies
is endorsed by the originating server.
SSL splitting is implemented as a patch to the
industry-standard OpenSSL library, with which the
server is linked.
In experiments replaying two-hour
access.log traces taken from LCS Web sites over an
ADSL link, SSL splitting reduces bandwidth consump-
tion of the server by between 25% and 90% depending
on the warmth of the cache and the redundancy of the
trace. Uncached requests forwarded through the proxy
exhibit latencies within approximately 5% of those of
an unmodiﬁed SSL server.
1 Introduction
Caching Web proxies are a proven technique for reduc-
ing the load on centralized servers. For example, an In-
ternet user with a Web site behind an inexpensive DSL
line might ask a number of well-connected volunteers
to proxy the content of the Web site to provide higher
throughput. In today’s practice, these proxies must be
trusted by both the client and the server to return the
data to the client’s queries, unmodiﬁed.
Previous content delivery systems that guarantee the in-
tegrity of the data served by proxies require changes to
the client software (e.g., to support SFSRO [8]), or use
application-speciﬁc solutions (e.g., RPM with PGP sig-
natures [25]). The former have not seen wide applica-
tion due to lack of any existing client base. The latter
are problematic due to PKI bootstrapping issues and due
to the large amount of manual intervention required for
their proper use.
Our goal is to guarantee the integrity of data served by
the proxy without requiring changes to clients. Our
approach is to exploit the existing, widely-deployed
browser support for the Secure Sockets Layer (SSL) pro-
tocol [7]. We modify the server end of the SSL connec-
tion by splitting it (see Figure 1): the central server sends
the SSL record authenticators, and the proxy merges
them with a stream of message payloads retrieved from
the proxy’s cache. The merged data stream that the
proxy sends to the client is indistinguishable from a nor-
mal SSL connection between the client and the server.
We call this technique of splitting the authenticator and
data records SSL splitting.
Server
MACs
Proxy
Payloads Cache
SSL Records
Client
Figure 1: Data ﬂow in SSL splitting.
This research was partially supported by MIT Project Oxygen and the
IRIS project (http://project-iris.net/), funded by the Na-
tional Science Foundation under Cooperative Agreement No. ANI-
0225660.
SSL splitting cleanly separates the roles of the server and
the proxy: the server, as “author”, originates and signs
the correct data, and the proxy, as “distribution channel”,
USENIX Association
12th USENIX Security Symposium 
187
serves the data to clients. SSL splitting cannot provide
conﬁdentiality, since the proxy must have access to the
encryption keys shared between client and server to re-
encrypt the merged stream; thus, our technique is only
useful for distributing public data. SSL splitting also
doesn’t reduce the CPU load on the server, since the
server is still involved in establishing the SSL connec-
tion, which requires a public-key operation on the server.
The primary advantage of SSL splitting is that it reduces
the bandwidth load on the server.
Our primary application for SSL splitting is Barnrais-
ing, a cooperative Web cache. We anticipate that co-
operative content delivery will be useful to bandwidth-
hungry Web sites with limited central resources, such as
software distribution archives and media artists’ home
pages. Currently, such sites must be mirrored by people
known and trusted by the authors, since a malicious mir-
ror can sabotage the content; Barnraising would allow
such sites to harness the resources of arbitrary hosts on
the Internet, while still guaranteeing the integrity of the
data. Barnraising could also be used by ad hoc cooper-
atives of small, independent Web sites, to distribute the
impact of localized load spikes.
the design of the
The contributions of this paper are:
SSL splitting technique, including the simple protocol
between server and proxy to support SSL splitting; an
implementation of SSL splitting based on the freely
available OpenSSL library; a new, grassroots content-
distribution system, Barnraising, which applies SSL
splitting to distribute bandwidth load; and experiments
that show that SSL splitting has CPU costs similar to
SSL, but saves server bandwidth, and improves down-
load times for large ﬁles.
2 Goals
Our main goal is to guarantee that public data served
by caching Web proxies is endorsed by the originating
server. Anybody with an inexpensive DSL line should
be able to author content and distribute it from his own
Web server. To allow this limited connection to support a
higher throughput, authors can leverage the resources of
well-connected volunteers acting as mirrors of the site’s
content. However, since the authors may not fully trust
the volunteers, we must provide an end-to-end authen-
ticity and freshness guarantee: the content accepted by a
client must be the latest version of the content published
by the author.
Our second goal is to provide the data integrity with min-
imal changes to the existing infrastructure. More specif-
ically, our goal is a solution that does not require any
client-side changes and minimal changes to a server. To
satisfy this goal, we exploit the existing support for SSL,
by splitting the server end of the connection.
Conﬁdentiality is not a goal. The intended use is to
distribute public, popular data from bandwidth-limited
servers. Most of the content on the Web is not secret,
and moreover, most pages that require secrecy are dy-
namically generated and hence not cacheable. Lack of
perfect conﬁdentiality is also an inevitable consequence
of caching, because any caching proxy must be able to
tell when two clients have downloaded the same ﬁle; this
requirement violates ciphertext indistinguishability.
SSL splitting does not provide all the beneﬁts of tradi-
tional, insecure mirroring. While it improves the band-
width utilization of the central site, it incurs a CPU load
similar to a normal SSL server. In addition, it does not
improve the redundancy of the site, since the central
server must be available in order to authenticate data.
Redundant central servers must be employed to ensure
continued service in the face of server failure or network
partition.
3 Design of SSL splitting
The key idea behind SSL splitting is that a stream of
SSL records is separable into a data component and an
authenticator component. As long as the record stream
presented to the client has the correct format, the two
components can arrive at the proxy by different means.
In particular, a proxy can cache data components, avoid-
ing the need for the server to send the data in full for
every client.
While SSL splitting does not require changes to the
client software, it does require a specialized proxy and
modiﬁcations to the server software. The modiﬁed
server and proxy communicate using a new protocol that
encapsulates the regular SSL protocol message types
and adds two message types of its own.
3.1 SSL overview
The Secure Sockets Layer protocol provides end-to-end
mutual authentication and conﬁdentiality at the transport
layer of stream-based protocols [7]. A typical SSL con-
nection begins with a handshake phase, in which the
server authenticates itself to the client and shared keys
are generated for the connection’s symmetric ciphers.
The symmetric keys generated for authentication are dis-
tinct from those generated for conﬁdentiality, and the
keys generated for the server-to-client data stream are
188
12th USENIX Security Symposium 
USENIX Association
distinct from those generated from the client-to-server
stream.
SSL Records
After completing the handshake, the server and client ex-
change data asynchronously in both directions along the
connection. The data is split into records of 214 bytes
or less. For each record, the sender computes a Mes-
sage Authentication Code (MAC) using the symmetric
authentication keys; this enables the receiver to detect
any modiﬁcation of the data in transit. SSL can provide
conﬁdentiality as well as integrity: records may be en-
crypted using the shared symmetric encryption keys. Al-
though SSL generates the keys for both directions from
the same “master secret” during the handshake phase,
the two directions are subsequently independent:
the
client or server’s outgoing cipher state depends only on
the previous records transmitted by that party.
3.2
Interposing a proxy
To access a site using SSL splitting, a Web browser
must connect to a proxy using HTTP over SSL/TLS
(HTTPS [18]). The server may have redirected the client
to the proxy via any mechanism of its choice, or the
proxy may have already been on the path between the
browser and the server.
The proxy relays the client’s connection setup messages
to the server, which in turn authenticates itself to the
client via the proxy. Once the SSL connection is set
up, the server starts sending application data: for each
record, it sends the message authentication code (MAC)
along with a short unique identiﬁer for the payload. (See
Figure 2.) Using the identiﬁer, the proxy looks up the
payload in its local cache, splices this payload into the
record in place of the identiﬁer, and relays this recon-
structed record to the client. The client veriﬁes the in-
tegrity of the received record stream, which is indistin-
guishable from the stream that would have been sent by
a normal SSL server.
Since SSL is resistant to man-in-the-middle attacks, and
the proxy is merely a man-in-the-middle with respect to
the SSL handshake, the SSL authentication keys are se-
cret from the proxy. Only the server and the client know
these keys, which enable them to generate and verify the
authentication codes protecting the connection’s end-to-
end integrity and freshness.
3.3 Proxy-server protocol extensions
When a client initiates an HTTPS connection to an SSL-
splitting proxy, the proxy immediately connects to the
MACs
Payloads
Figure 2: Decomposition of an SSL stream into authen-
ticators and payloads. The striped box represents the
SSL handshake, which is handled by the server. The
shaded boxes represent authenticators, while the white
boxes represent payloads.
server using the specialized proxy-server protocol. This
protocol deﬁnes three message types. The ﬁrst type
of message, verbatim, is a regular SSL record, passed
transparently through the proxy from the client to the
server, or vice versa. The second type of message, stub,
is a compact representation of an SSL record:
it con-
tains a MAC authenticator and a short unique identiﬁer
for the payload. The third type of message, key-expose,
communicates an encryption key from the server to the
proxy.
When the proxy receives SSL records from the client,
it forwards them directly to the server using the verba-
tim message. The server, however, may choose to com-
press the data it sends by using the stub message format.
When the proxy receives such a message from the server,
it looks up the data block identiﬁed by the message in its
local cache. It then reconstructs a normal SSL record
by splicing the MAC authenticator from the stub record
together with the payload from the cache, and forwards
the resulting valid SSL record to the client.
3.4 Dropping the encryption layer
A proxy can properly forward stub messages only if it is
able to encode the resulting normal SSL records. If the
client and server use SSL with its end-to-end encryption
layer enabled, however, the proxy cannot send validly
encrypted messages. End-to-end encryption inherently
foils caching, because a proxy will not be able to de-
termine when the same data is downloaded by differ-
ent clients. Therefore, to achieve bandwidth compres-
sion, conﬁdentiality—with respect to the proxy—must
be abandoned.
correct way
to
eliminate SSL’s
encryp-
The
is to negotiate, during the handshake
tion layer
phase, an authentication-only cipher suite such as
SSL RSA WITH NULL SHA; this is usually done with
a Web server conﬁguration setting. When such a cipher
USENIX Association
12th USENIX Security Symposium 
189
suite is in use, no conﬁdentiality is provided for SSL
records sent in either direction; only data authentication
is provided.
Unfortunately, this straightforward approach does not
achieve full compatibility with the existing installed
client base, because current versions of many popular
Web browsers, such as Netscape and Internet Explorer,
ship with authentication-only cipher suites disabled. The
SSL splitting protocol provides a work-around for this
problem, which can be enabled by the server adminis-
trator. If the option is enabled and a client does not of-
fer an authentication-only cipher suite, the server simply
negotiates a normal cipher suite with the client, and then
intentionally exposes the server-to-client encryption key
and initialization vector (IV) to the proxy using the key-
expose message.
SSL computes the encryption key, IV, and MAC key
as independent pseudo-random functions (PRF) of the
master secret. Because SSL uses different PRFs for each
key, revealing the cipher key and IV to the proxy does
not endanger the MAC key or any of the client-to-server
keys [19, p. 165]. Hence, key-expose preserves the data-
authentication property.
When the key-expose feature is turned on and an en-
crypted cipher suite is negotiated, the client-to-server en-
cryption keys are withheld from the proxy; thus, it would
be possible to develop an application in which the infor-
mation sent by a client was encrypted, while the content
returned by the server was unencrypted and cacheable by
the proxy. However, unless the application is carefully
designed, there is a danger of leaking sensitive data in
the server’s output, and so we do not recommend the use
of SSL splitting in this mode without very careful con-
sideration of the risks.
If necessary, an application can restrict the set of hosts
with access to the cleartext to the client, the server, and
the proxy, by encrypting the proxy-server connection.
For example, one could tunnel the proxy-server connec-
tion through a (normal) SSL connection. Of course, this
feature would be useful only in applications where the
proxy can be trusted not to leak the cleartext, intention-