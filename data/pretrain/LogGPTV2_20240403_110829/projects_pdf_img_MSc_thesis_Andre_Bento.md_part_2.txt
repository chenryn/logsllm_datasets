This document presents the Master Thesis in Informatics Engineering of the student
AndréPascoalBento’sduringtheschoolyearof2018/2019,takingplaceintheDepartment
of Informatics Engineering (DEI), Faculty of Sciences and Technology of the University
of Coimbra.
1.1 Context
Software systems are becoming larger and more distributed than ever, thus requiring
new solutions and new development patterns. One approach that emerged in recent years
is to decouple large monolithic components into interconnected “small pieces” that encap-
sulateandprovidespecificfunctions. Thesecomponentsareknownas“Microservices”and
have become mainstream in the enterprise software development industry [1], [2]. Besides
theirimpactonlatency, fine-graineddistributedsystems, includingmicroservices, increase
system complexity, thus turning anomaly detecting into a more challenging task [3].
Totacklethisproblem,DevelopmentandOperations(DevOps)resorttotechniqueslike
monitoring [4], logging [5], and end-to-end tracing [6], to observe and maintain records of
the work performed in a microservices system. Monitoring consists of measuring aspects
like Central Processing Unit (CPU) and hard drive usage, network latency and other
infrastructure metrics around the system and components. Logging provides an overview
to a discrete, event-triggered log. Tracing is similar to logging, but focuses on registering
the flow of execution of the program, as requests travel through several system modules
and boundaries. Distributed tracing can also preserve causality relationships when state
is partitioned over multiple threads, processes, machines and even geographical locations.
Subsection 2.1.3 - Distributed Tracing.
The main problem with this is that there are not many implemented tools for process-
ing tracing data and none for performing analysis of this type of data. For monitoring it
tend to be easier, because data is represented in charts and diagrams, however for logging
and tracing it gets harder to manually analyse the data due to multiple factors like its
complexity, plethora and increasing quantity of information. There are some visualisation
toolsfor theDevOps touse, likethe onespresentedin Subsection2.2.1 -Distributed Trac-
ing Tools, however none of them gets to the point of analysing the system using tracing,
has they tend to be developed only for visualisation and display of tracing data in a more
humanreadableway. DistributedtracingdatacanbeusedbyDevOpsbecauseitispartic-
ularly well-suited to debugging and monitoring modern distributed software architectures,
1
Chapter 1
such as microservices. This kind of data contains critical information about request paths,
response time and status, services presented in the system and their relationship and, for
this reason, can be further analysed to detect anomalous behaviours in requests, response
times and services in these systems. Nevertheless, this is critical information about the
system behaviour, and thus there is the need for performing automatic tracing analysis.
1.2 Motivation
Exploring and develop ways to perform tracing analysis in microservice based systems
lay down the motivation behind this work. The analysis of this kind of systems tend to
be very complex and hard to perform due to their properties and characteristics, as it
is explained in Subsection 2.1.1 - Microservices, and to the type of data to be analysed,
presented in Subsection 2.1.3 - Distributed Tracing.
DevOps teams have lots of problems when they need to identify and understand prob-
lems with distributed systems. They usually detect the problems when a client complains
about the quality of service, and after that, DevOps dive in monitoring metrics like, e.g,
CPU usage, usage, hard drive usage and network latency. Later on, they use distributed
tracing data visualisations and logs to find some explanation to what is causing the re-
ported problem. This involves a very hard and tedious work of look-up through lots of
data that represents the history of work performed by the system and, in most cases, this
tedious work reveals like a big “find a needle in the haystack” problem. For this reason,
DevOps have hard time finding problems in services and end up “killing” and reboot-
ing services, which can be bad for the whole system. However, due to lack of time and
difficulty in identifying anomalous services precisely this is the best approach to perform.
Problems regarding the system operation are more common in distributed systems
and their identification must be simplified. This need of simplification comes from the
exponential increase in the amount of data needed to retain information and the increas-
ing difficulty in manually managing distributed infrastructures. The work presented in
this thesis, aims to perform a research around these needs and focus on presenting some
solutions and methods to perform tracing analysis.
1.3 Goals
The main goals for this thesis consist on the main points exposed bellow:
1. SearchforexistingtechnologyandmethodologiesusedtohelpDevOpsteamsintheir
currentdailywork, withtheobjectiveofgatheringthebestpracticesabouthandling
tracingdata. Also, weaimtounderstandhowthesesystemsareused, whataretheir
advantages and disadvantages to better know how we can use them to design and
produce a possible solution capable of performing tracing analysis. From this we
expect to learn the state of the field for this research, covering the core concepts
related work and technologies, presented in Chapter 2 - State of the Art.
2. Perform a research about the main needs of DevOps teams, to better understand
what are their biggest concerns that lead to their approaches when performing pin-
pointing of microservices based systems problems. Relate these approaches with
related work in the area, with the objective of understanding what other compa-
nies and groups have done in the field of automatic tracing analysis. The processes
2
Introduction
used to tackle this type of data, their main difficulties and conclusions provide a
better insight about the problem. From this we expected to have our research objec-
tives clearly defined and a compilation of questions to be evaluated and answered,
presented in Chapter 3 - Research Objectives and Approach.
3. Reason about all the information gathered to design and produce a possible solution
that provides a different approach to perform tracing analysis. From this we expect
first to propose a possible solution, presented in Chapter 4. Then we implemented it
using state of the art technologies, feed it with tracing data provided by Huawei and
collect results, presented in Chapters 5 - Implementation Process and 6 - Results,
Analysis and Limitations. Finally, we provide conclusions to this research work in
Chapter 7 - Conclusion and Future Work.
1.4 Work Plan
This work represents an investigation and was mainly an exploratory work, therefore,
no development methodology was adopted. Meetings were scheduled to happen every
two weeks. We gathered with the objective of discussing the work carried out and define
new courses of research. The main focus in the first semester were topics like published
papers, state of the art, analysis of related work and a proposition of solution. In the
second semester, two more colleagues joined the project (DataScience4NP) and started
participating in meetings, which contributed with wider discussions of ideas. In these
meeting, the main topics covered were: implementation of the proposed solution, research
foralgorithmsandmethods fortraceprocessingand analysisofgathered data. In theend,
these meetings were more than enough to keep the productivity and good work.
Totaltimespentineachsemester,byweek,weresixteen(16)hoursforthefirstsemester
and forty (40) hours for the second. In the end, it was spent a total of three-hundred and
four (304) hours for the first semester, starting in 11.09.2018 and ending in 21.01.2019
(19 weeks ∗ 16 hours per week). For the second semester, eight-hundred and forty (840)
hours were spent, starting in 04.02.2019 and ending in 28.06.2019 (21 weeks ∗ 40 hours
per week).
As we can see in Figures 1.1 and 1.2, the proposed work for the first semester has
suffered changes, when comparing it to the real work plan. Task 1 - Study the state of
the art (Fig. 1.1), was branched in two, 1 - Project Contextualisation and Background
and 2 - State of the Art, however, these last ones tocked more time to accomplish due to
lack of work in the field of trace processing and trace analysis, core topics for this thesis.
Task 2 - Integrate the existing work (Fig. 1.1) was replaced by task 3 - Prototyping and
Technologies Hand-On (Fig. 1.2) due to redirections in the work course. This redirection
was done due to interest increase in testing state of the art technologies, allowing us to
get a better visualisation of the data provided by Huawei and enhancing our investigation
work. The remaining tasks took almost the predicted time to accomplish.
For the second semester, an “expected” work plan was defined with respect to the
proposed work, presented in Figure 1.1, and the state of the research at the time. The
expected work plan can be visualized in Figure 1.3. This Figure contains the expected
(Grey) and real (Blue) work for the second semester.
Three main changes were made over time in the work plan. The first one involved a
reductionintask1-Metricscollectortool. Whenthesolutionwasbeingimplementedand
the prototype was capable to extract a set of metrics, we decided to stop the implementa-
3
Chapter 1
tion process to analyse the research questions. Second, this analysis lead to an emergence
of ideas, “2 - Restructuring research questions’,’ and thus a project redirection. Tests
were removed from planning and the project followed with the objective of producing the
data analyser, “3 - Data Analyser tool”, and with it, answer two main questions regarding
anomalous services and quality of tracing. Third, the introduction of a new task, “4 -
Write paper to NCA 2019”, covering the work presented in this thesis.
4
2018 2019
September October November December January February March April May June July
Name Begin date End date
1 - Study the state of the art 9/11/18 11/5/18
2 - Integrate the existing work 11/6/18 12/3/18
3 - Define requirements of the monitoring tool 12/4/18 12/31/18
4 - Write intermediate report 1/1/19 1/21/19
5 - Implement the monitoring tool 3/29/19
4/1/19
6/28/19
Figure 1.1: Proposed work plan for first and second semesters.
2018 2019
5
September October November December January February
Name Begin date End date
1 - Project Contextualization and Background 9/11/18 9/24/18
2 - State of the Art 9/25/18 11/19/18
2.1 - Concepts 9/25/18 10/15/18
2.2 - Technologies 10/16/18 11/19/18
3-PrototypingandTechnologiesHands-On 11/20/18 12/3/18
4 - Solution Specification 12/4/18 12/24/18
4.1 - Gathering Requirements 12/4/18 12/17/18
4.2 - Building Architecture 12/18/18 12/24/18
5 - Writing of Intermediary Report 12/25/18 1/21/19
Figure 1.2: Real work plan for first semester.
Introduction
Chapter
2019
February March April May June Jul
Begin date End date
1.a - Metrics collectortool (Expected) 2/4/19 5/3/19
1.1 - Setup project (Expected) 2/4/19 2/6/19 1
1.2 - Implement Controller (Expected) 2/7/19 2/18/19
2/19/19 2/22/19
1.4 - Implement File IO (Expected) 2/25/19 2/27/19
1.5 - Setup databases (Expected) 2/28/19
1.6 - Implement database repositories (Expected) 3/11/19
3/12/19
1.8 - Implement Logging Component (Expected) 3/22/19 3/26/19
1.9 - Research apropriate analysis algorithms (Expected) 3/27/19 4/11/19
1.10 - Implement Data Analyser (Expected) 4/12/19 4/23/19
1.11 - Define tests to be performed (Expected) 4/24/19 4/26/19
4/29/19 5/3/19
1.b - Metrics collector tool 2/4/19 3/15/19
1.1 - Setup project (Real) 2/6/19
2/7/19
1.3 - Setup Docker Containers (Real) 2/8/19 2/8/19
1.4- Implement Controller (Real) 2/11/19 2/20/19
1.5 - Implement File IO (Real) 2/21/19 2/25/19 6
1.6 - Implement Processors (Real) 2/26/19 3/4/19
1.7 - Setup databases (Real) 3/5/19 3/7/19
3/8/19 3/12/19
1.9 - Implement metrics storage (Real) 3/15/19
5/6/19
2.1 - Run tests (Expected) 5/15/19
2.2 - Write analysis results (Expected) 5/16/19 5/27/19
2.b - Restructure research questions (Real) 3/18/19 3/27/19
2.1 - Write question analysis report (Real) 3/18/19 3/22/19
2.2 - Report review (Real) 3/25/19 3/27/19
3.a - Write final report (Expected) 5/28/19 6/28/19
3/28/19 5/17/19
3/28/19
3.1.1 - Time coverability testing (Real) 4/1/19
3.1.2 - Structure testing (Real) 4/2/19 4/3/19
3.2 - Research apropriate analysis algorithms (Real) 4/4/19 4/19/19
3.3 - Setup Jupyter notebooks (Real) 4/22/19 4/24/19
3.4 - Implement proposed solution and gather results (Real) 4/25/19 5/17/19
3.4.1 - Is there any anomalous service? (Real) 4/25/19 5/10/19
3.4.2 - Results gathering (Real) 5/13/19 5/17/19
5/20/19
5 - Write final report (Real) 6/28/19
Figure 1.3: Real and expected work plans for second semester.
Introduction
1.5 Research Contributions
Fromtheworkpresentedonthisthesis, thefollowingresearchcontributionweremade:
• Andre Bento, Jaime Correia, Ricardo Filipe, Filipe Araujo and Jorge Cardoso. On
the Limits of Automated Analysis of OpenTracing. International Symposium on
Network Computing and Applications (IEEE NCA 2019).
1.6 Document Structure
Thissectionpresentsthedocumentstructureinthisreport, withabriefexplanationof
the contents in every section. This document contains a total of eight chapters, including
this one, Chapter 1 - Introduction. The remaining six are presented as follows:
• InChapter2-StateoftheArtthecurrentstateofthefieldforthiskindofproblemis
presented. Thischapterisdividedinthreesections. Thefirstone, Section2.1-Con-
cepts introduces the reader to the core concepts to know as a requirement for a full
understanding of the topics discussed in this thesis. The second, Section 2.2 - Tech-
nologies presents the result of a research for current technologies, that are able to
help solving this problem and produce a proposed solution to be implemented. Fi-
nally, Section 2.3 - Related Work presents the reader to related researches produced
in the field of distributed tracing data handling.
• In Chapter 3 - Research Objectives and Approach the problem is approached in
detail and the objectives of this research are presented. This chapter is divided in
two sections. First, Section 3.1 - Research Objectives, provides a concrete defini-
tion of the problem, how we tackled it, the main difficulties that were found and
the objectives involved in order to propose a solution. Second, Section 3.2 - Re-
search Questions, a compilation of questions are presented and evaluated with some
reasoning about possible ways to answer them.
• In Chapter 4 - Proposed Solution a possible solution for the presented problem is
exposed and explained in detail. This chapter is divided in four sections. The
first one, Section 4.1 - Functional Requirements, expose the functional requirements
with their corresponding priority levels and a brief explanation to every single one
of them. The second one, Section 4.2 - Quality Attributes, contains the gathered
non-functional requirements that were used to build the solution architecture. The
third one, Section 4.3 - Technical Restrictions, presents the defined technical restric-
tions for this project. The last one, Section 4.4 - Architecture, presents the possible
solution architecture using some representational diagrams, and ends with an anal-
ysis and validation to check if the presented architecture meets up the restrictions
involved in the architectural drivers.
• In Chapter 5 - Implementation Process, the implementation process of the possible
solution is presented with detail. This chapter is divided in three main sections cov-
ering the whole implementation process, from the input data set through the pair of
components presented in the previous chapter. The first one, Section 5.1 - Huawei
TracingDataSet,thetracingdatasetprovidedbyHuaweitobeusedasthecoredata
for research is exposed with some detail. Second, in Section 5.2 - OpenTracing Pro-
cessor Component we present the possible solution for the first component, namely
7
Chapter 1