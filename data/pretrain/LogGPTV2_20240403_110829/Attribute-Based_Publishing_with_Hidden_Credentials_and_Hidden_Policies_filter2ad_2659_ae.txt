### References

1. C. Dwork, M. Naor, and A. Sahai. "Concurrent Zero-Knowledge." *Journal of the ACM*, 51(6):851–898, 2004.
2. K. Frikken, J. Li, and M. Atallah. "Trust Negotiation with Hidden Credentials, Hidden Policies, and Policy Cycles." In *13th Annual Network and Distributed System Security Symposium*, pages 157–172, February 2006.
3. P. Golle, M. Jakobsson, A. Juels, and P. F. Syverson. "Universal Re-encryption for Mixnets." In T. Okamoto (ed.), *CT-RSA*, volume 2964 of *Lecture Notes in Computer Science*, pages 163–178. Springer, 2004.
4. V. Goyal, O. Pandey, A. Sahai, and B. Waters. "Attribute-Based Encryption for Fine-Grained Access Control of Encrypted Data." In *CCS '06: Proceedings of the 13th ACM Conference on Computer and Communications Security*, pages 89–98, New York, NY, USA, 2006. ACM Press.
5. J. Groth. "A Verifiable Secret Shuffle of Homomorphic Encryptions." In Y. Desmedt (ed.), *Public Key Cryptography*, volume 2567 of *Lecture Notes in Computer Science*, pages 145–160. Springer, 2003.
6. M. Hirt and K. Sako. "Efficient Receipt-Free Voting Based on Homomorphic Encryption." In *EUROCRYPT*, pages 539–556, 2000.
7. J. E. Holt, R. W. Bradshaw, K. E. Seamons, and H. Orman. "Hidden Credentials." In *2nd ACM Workshop on Privacy in the Electronic Society*, Washington, DC, pages 1–8, October 2003.
8. A. Ivan and Y. Dodis. "Proxy Cryptography Revisited." In *NDSS*. The Internet Society, 2003.
9. J. Katz. "Efficient and Non-Malleable Proofs of Plaintext Knowledge and Applications." In E. Biham (ed.), *EUROCRYPT*, volume 2656 of *Lecture Notes in Computer Science*, pages 211–228. Springer, 2003.
10. H. Khurana, A. J. Slagell, and R. Bonilla. "SELS: A Secure Email List Service." In H. Haddad, L. M. Liebrock, A. Omicini, and R. L. Wainwright (eds.), *SAC*, pages 306–313. ACM, 2005.
11. J. Li and N. Li. "Policy-Hiding Access Control in Open Environment." In *Proceedings of ACM Symposium on Principles of Distributed Computing (PODC)*, pages 29–38, July 2005.
12. H. Lipmaa. "Verifiable Homomorphic Oblivious Transfer and Private Equality Test." In C.-S. Laih (ed.), *ASIACRYPT*, volume 2894 of *Lecture Notes in Computer Science*, pages 416–433. Springer, 2003.
13. M. Naor. "Deniable Ring Authentication." In *CRYPTO 2002*, volume 2442 of *LNCS*, pages 481–498. Springer-Verlag, 2002.
14. P. Paillier. "Public-Key Cryptosystems Based on Composite Degree Residuosity Classes." In *EUROCRYPT*, pages 223–238, 1999.
15. G. Poupard and J. Stern. "Fair Encryption of RSA Keys." In *EUROCRYPT*, pages 172–189, 2000.
16. M. D. Raimondo and R. Gennaro. "New Approaches for Deniable Authentication." In V. Atluri, C. Meadows, and A. Juels (eds.), *ACM Conference on Computer and Communications Security*, pages 112–121. ACM, 2005.
17. R. L. Rivest, L. Adleman, and M. L. Dertouzos. "On Data Banks and Privacy Homomorphisms." In R. DeMillo, D. Dobkin, A. Jones, and R. Lipton (eds.), *Foundations of Secure Computation*, pages 169–180. Academic Press, 1978.
18. A. Sahai and B. Waters. "Fuzzy Identity Based Encryption." In *Advances in Cryptology – Eurocrypt*, volume 3494 of *LNCS*, pages 457–473, 2005.
19. Sun Microsystems. "Sun Fire T1000 and T2000 Servers Benchmarks." http://www.sun.com/servers/coolthreads/t1000/benchmarks.jsp#j, 2006.
20. Sun Microsystems. "Sun Fire T2000 Server." http://www.sun.com/servers/coolthreads/t2000/, 2006.
21. K. Suzuki and M. Yokoo. "Secure Generalized Vickrey Auction Using Homomorphic Encryption." In R. N. Wright (ed.), *Financial Cryptography*, volume 2742 of *Lecture Notes in Computer Science*, pages 239–249. Springer, 2003.
22. W. H. Winsborough and N. Li. "Towards Practical Automated Trust Negotiation." In *Proceedings of the IEEE 3rd International Workshop on Policies for Distributed Systems and Networks*, pages 92–103, June 2002.
23. W. H. Winsborough and N. Li. "Safety in Automated Trust Negotiation." In *Proceedings of the 2004 IEEE Symposium on Security and Privacy*, pages 147–160, Oakland, CA, May 2004. IEEE Press.
24. W. H. Winsborough, K. E. Seamons, and V. E. Jones. "Automated Trust Negotiation." In *DARPA Information Survivability Conference and Exposition (DISCEX)*, pages 88–102, January 2000.
25. T. Yu and M. Winslett. "A Unified Scheme for Resource Protection in Automated Trust Negotiation." In *Proceedings of the IEEE Symposium on Security and Privacy*, pages 110–122, May 2003.
26. T. Yu, M. Winslett, and K. E. Seamons. "Supporting Structured Credentials and Sensitive Policies through Interoperable Strategies for Automated Trust Negotiation." *ACM Transactions on Information and System Security*, 6(1):1–42, 2003.

### Appendix A: Security Proofs

#### A.1 Lemmas

We need the following lemmas to prove the confidentiality and policy privacy of Full-PEAPOD.

**Lemma 1:** For any \( m \in \mathbb{N} \) and \( x_1, x_2, \ldots, x_m \in \mathbb{Z}_p^* \), let the random variables \( X = (b_1x_1, b_2x_2, \ldots, b_mx_m, (\prod_{i=1}^m b_i)^{-1}r) \) and \( R = (r_1, r_2, \ldots, r_m, r_{m+1}) \), where \( b_1, b_2, \ldots, b_m, r \leftarrow \mathbb{Z}_p^* \) and \( r_1, r_2, \ldots, r_{m+1} \leftarrow \mathbb{Z}_p^* \). Then, \( X \) and \( R \) have the same distribution.

**Lemma 2:** For any \( m \in \mathbb{N} \) and \( x_1, x_2, \ldots, x_{m+1} \in \mathbb{Z}_p^* \), let the random variables \( X = (b_1x_1, b_2x_2, \ldots, b_mx_m, (\prod_{i=1}^m b_i)^{-1}x_{m+1}) \) and \( R = (r_1, r_2, \ldots, r_m, (\prod_{i=1}^m r_i)^{-1}r_{m+1}) \), where \( b_1, b_2, \ldots, b_m \leftarrow \mathbb{Z}_p^* \) and \( r_1, r_2, \ldots, r_{m+1} \leftarrow \mathbb{Z}_p^* \). Then, \( X \) and \( R \) have the same distribution.

The proofs for both lemmas are straightforward and are thus omitted.

#### A.2 Proofs

**Proof 1 (Theorem 1) (Sketch):** Recall that a ciphertext returned by the encryption algorithm in Full-PEAPOD consists of the symmetric encryption \( \psi \) of the plaintext message \( M \) under a randomly chosen key \( k \) and an array of Elgamal encryptions of either a sub-key, a random value, or the identity element. The Elgamal ciphertext at the \( i \)-th row and \( j \)-th column in the array is an encryption under the public key of attribute \( j \). The underlying plaintext is a sub-key, a random value, or the identity element if the \( j \)-th attribute is respectively a required, forbidden, or irrelevant attribute for the \( i \)-th clause in the policy.

Assume there exists a probabilistic polynomial-time (PPT) adversary \( A \) who can distinguish between two messages \( M_0 \) and \( M_1 \) used in the encryption that resulted in the challenge ciphertext \( C^* \) with probability non-negligibly greater than \( \frac{1}{2} \). The semantic security of the symmetric encryption implies that \( A \) knows the symmetric key \( k \). This implies that there is at least one clause in the challenge policy \( P^* \) such that \( A \) knows the product of all the sub-keys for that clause. We claim that this implies that \( A \) knows all the individual sub-keys in the product for that clause. Such knowledge means that \( A \) knows the set \( K^* \) of Elgamal decryption keys to the encryption of all those sub-keys, as otherwise Elgamal encryption would not be IND-CPA secure, contradicting the assumption that the Decisional Diffie-Hellman (DDH) problem is hard in \( \mathbb{Z}_p^* \).

We need to consider both cases when \( A \) corrupted the Server and when \( A \) did not. In the former case, the model requires that \( A \) did not corrupt any of the users. The Server itself does not know any of the Elgamal decryption keys. The Server knows all the transformation secret keys, but without the help of the Certificate Authority (CA) or any user in the system, the transformation secret keys have statistical zero-knowledge on any of the Elgamal decryption keys. This contradicts the fact that \( A \) knows \( K^* \).

In the latter case, \( A \) might have corrupted some subset of users. However, Restriction 10 guarantees that any coalition of corrupted users does not collectively satisfy the challenge policy \( P^* \), which means that for any union of corrupted users' attribute sets and any clause in \( P^* \), the union does not satisfy the clause, either because at least one required attribute is missing from the union or one forbidden attribute is present in the union. Both possibilities contradict the fact that \( A \) knows \( K^* \).

Therefore, there does not exist a PPT adversary \( A \) who can win the game with probability non-negligibly greater than \( \frac{1}{2} \). Finally, we note that the above is only a proof sketch. In a full proof, one would have to simulate the deposit and retrieval queries, which could be achieved by following the protocol specification. The contradiction could be derived by embedding a DDH problem instance into one of the array entries of Elgamal ciphertexts in the challenge ciphertext. Such a challenge ciphertext can be simulated correctly without the knowledge of the sub-key behind that particular Elgamal ciphertext.

**Proof 2 (Theorem 2) (Sketch):** Observe that during encryption, the policy affects only the array of plaintexts that are to be Elgamal-encrypted. The symmetric encryption of the message is totally independent of the policy. To prove that Full-PEAPOD has Clausal Policy Indistinguishability, it suffices to show that the two ciphertexts resulting from any message encrypted with two different policies with the same number of satisfying clauses with respect to an adversary are statistically indistinguishable, thereby leaving the adversary no chance in making a correct guess on which policy was used any better than pure guessing, i.e., it cannot win with probability non-negligibly greater than \( \frac{1}{2} \).

Assume there exists a PPT adversary \( A \) who can win the game with probability non-negligibly greater than \( \frac{1}{2} \). Let's first consider the possibility that \( A \) corrupted the Server during the game. In such a case, \( A \) did not corrupt any of the users or otherwise could not have won the game. Since the server does not possess the decryption keys of any of the attributes, all the Elgamal ciphertexts within a deposited ciphertext have computational zero-knowledge in their underlying plaintexts, the knowledge of which is required to tell whether an attribute is required, forbidden, or irrelevant for each clause. Thus, a ciphertext deposited at the server has zero-knowledge in the policy under which it was created, meaning that an adversary who corrupted the server in order to attack policy privacy of Full-PEAPOD cannot do any better than pure guessing which one of the two challenge policies was used.

Therefore, \( A \) must have won without corrupting the Server, in which case \( A \) might have corrupted up to one honest user. If \( A \) did not corrupt any user, then by arguments similar to the above, a ciphertext deposited at the server has zero-knowledge in the policy under which it was created and thus \( A \) could only win with probability negligibly greater than \( \frac{1}{2} \). The only possibility left is that \( A \) corrupted exactly one honest user. Note that the game specification implies that this single corrupted user satisfies the same number of clauses in both challenge policies. The following derives a contradiction.

The ciphertexts the adversary retrieves from the server have all gone through the blinding step through the homomorphic operation on the individual Elgamal ciphertexts. Lemma 2 implies that the decryption of any of these Elgamal ciphertexts could have been a sub-key, a random value, or the identity element before blinding, and the adversary has statistically zero-knowledge to tell which is the case. This means any attribute in any clause in the policy could be a required, forbidden, or irrelevant attribute. The only information a retrieved ciphertext carries is the product of the plaintexts for each clause, which is either equal to the symmetric key if the clause is satisfied by the adversary, or a group element distributed over \( \mathbb{Z}_p^* \) uniformly at random if the clause is not satisfied by the adversary or if it is a bogus one, due to Lemma 1. Finally, due to the uniform randomness, the adversary cannot distinguish between the two policies with non-negligible advantage.

**Proof 3 (Theorem 3) (Sketch):** As discussed, Full-PEAPOD is an offline system in which a sender interacts once with the Server during a deposit, and the receiver interacts once with the Server during a retrieval. Receivers never contact senders during retrieval or decryption. The transcripts for retrieval protocol runs consist of retrieved ciphertexts. The size of the ciphertext retrieved by any user is independent of the attribute set possessed by the user. Furthermore, by arguments similar to the proof sketch for policy privacy, the IND-CPA security of Elgamal encryption implies that the sender who does not have any credentials to decrypt a retrieved ciphertext is unable to learn non-negligible information from the Elgamal ciphertexts about their underlying plaintexts. The result follows.