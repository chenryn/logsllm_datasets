a camera with column scanning pattern from left to right is
shown in Fig 5b, which shows an obvious color gradient from
Red to Green 2.
To transform this unique feature into a strong security
guarantee, the appropriate challenges must be constructed and
veriﬁed to ensure the consistency of responses. In practice, we
construct two types of challenge to be presented on front-end
screen: one is the background challenge displaying a single
color, and the other is the lighting challenge displaying a belt
of different color on the background color. The belt of the
different color from background is called the lighting area,
and one example is shown in Fig 6a, where the background
color is Red while the lighting area is Green.
To verify the consistency in responses, we deﬁned another
concept called Region of Interest (ROI), which is the region
that
the camera is scanning when the front-end screen is
Further, we use alignment results to regularize every rect-
angle. Particularly, we formalize the landmarks on j-th face as
Lj = (l1, l2,··· , l106), where li denotes (xi, yi)(cid:62), the coordi-
nates of i-th landmark. And, we calculate the transformation
matrix Tj by:
1Since we just implemented those existing algorithms on face tracking,
detection and alignment, we will not provide further details about them and
interested readers can refer to original papers.
2Similar but a little bit different color patterns can also be observed on
cameras with row scanning mode. Column scanning mode is used here it is
easier to understand.
6
from the distilled ROI. If it cannot, the delay exists and this
response is counterfeit.
To infer the lighting area, we build 4 linear regression
models handling different part of captured frame (Fig 6b).
Each model is fed a vector, the average vector reduced from
corresponding part of ROI, and estimates the location of u+d
2
independently. Next we gather estimated results according to
the size of each part. An example is shown on Fig 6b where the
ROI is separated into 2 parts: the left part contains a columns
and the right part contains b columns. The gathered result, ˆy,
is calculated as following.
a × m2 + b × m3
a + b
ˆy =
(5)
where m2 and m3 denote the estimated result made by model
2 and model 3 respectively.
(a) screen refreshing
(b) camera refreshing
Fig. 5: Working schemes of screen and camera.
The ﬁnal criteria of consistence is accumulated from ˆyi,
the gathered result of i-th captured frame, as following:
(cid:80)n
di = ˆyi − ui+di
meand =
d =
(cid:80)n
i=1(di−meand)2
2
i=1 di
n
n−1
std2
(6)
(a) lighting challenge
(b) captured frame
Fig. 6: Example of lighting area and calculation of ROI.
displaying the lighting area. The location of ROI is calculated
as followings:
We ﬁnally check whether meand × stdd is smaller than
exp(T h), where T h is a predeﬁned threshold.
Note that
legitimate responses are consistent with our
challenges and will produce both small meand and stdd.
Adversarial responses will be detected by checking our ﬁnal
criteria. An additional demo was illustrated on Fig 7 to explain
visually how the lighting area affects the captured frame.
•
•
•
Calculate tu, the start time to show the lighting area.
tu = tbegin +
u
rows
∗ tf rame
(3)
where u is the upper bound of lighting area, rows is
the number of rows contained in one frame, tbegin is
the start time to show the current frame, and tf rame
is the during time of one frame.
Find the captured frame which recording period covers
tu. Say the k-th captured frame.
Calculate the shift, l, against the ﬁrst column of k-th
captured frame.
l = cols ∗ tu − ctk
ctf rame
(4)
where cols is the number of columns contained in one
captured frame, ctk is the start time to exposure the
ﬁrst column of k-th capture frame, and ctf rame is the
exposure time of one captured frame.
After ﬁnding the location of ROI, we distill it by apply-
ing Eq.(2) on every pixel between the response of lighting
challenge and background challenge. Two applied results are
demonstrated on Fig 7. Now, the consistence can be veriﬁed.
We check whether the lighting area can be correctly inferred
7
(a) light middle area
(b) light bottom area
Fig. 7: Effect of lighting area. In the bottom of both pictures,
these are mirrors showing the location of corresponding light-
ing area.
4) Face Veriﬁcation: After preprocessing, we get a se-
quence frames with vibration removed, size uniﬁed and color
synchronized. Further, we use Eq.(1) to generate the midterm
result from the responses of a background challenge: First, we
randomly choose a pixel on the face as the anchor point; then,
we divide all the pixels by the value of that anchor point. Some
midterm results are shown on Fig 8.
(a)
(b)
(c)
(d)
(e)
(f)
Fig. 8: Examples of midterm results. (a) and (c) are captured from real human faces, (b) is captured from an iPad’s screen, (d)
and (e) are captured from a LCD monitor, and (f) is captured from a paper.
Without any difﬁculty, we can quickly differentiate results
of real human faces from fake ones. This is because real
human faces have uneven geometry and textures, while other
materials, like monitor, paper or iPad’s screen, do not have.
Based on this observation we developed our face veriﬁcation
techniques, as described below.
•
•
•
Step 1: abstract. We vertically divide the face into 20
regions. In every region, we further reduce the image
to a vector by taking the average value. Next, we
smooth every vector by performing polynomial ﬁtting
of 20 degrees with minimal 2-norm deviation. After
that, we will derive images like Fig 9c.
Step 2: resize. We pick out facial region and resize it to
a 20x20 image by bicubic interpolation. An example
is shown on Fig 9d.
Step 3: verify. We feed the resized image to a well-
trained neural network, and the decision will be made
then.
The neural network we used contains 3 convolution layers
with a pyramid structure, which effectiveness was sufﬁciently
proved in Cifar-10, a dataset used to train the neural network
to classify 10 different objects. In Table I, we show the
architecture of our network and the parameters of every layer.
(a) midterm result
(b) midterm result
(c) abstract result
(d) resize result
Fig. 9: Face veriﬁcation.
V. SECURITY ANALYSIS
In this section, we present the security analysis of Face
the mechanisms behind Face
Flashing. First, we abstract
Flashing as a challenge-response protocol. Second, we analyze
the security of two main parts in our protocol: timing veriﬁca-
tions and face veriﬁcation. Finally, we demonstrate how Face
Flashing defeats three typical advanced attacks.
8
000.5511001.5515102152020TABLE I: Architecture of Neural Network.
input size
20x20x3
16x16x16
16x16x16
8x8x16
8x8x32
1x512
layer type
conv 5x5
conv 3x3
pool 2x2
conv 3x3
pool 2x2
inner product
stride
1
1
1
1
1
0
padding size
0
1
0
1
0
0
It is certain that Face Flashing can defeat static attacks,
as the expression detector, one component of our system, is
sufﬁcient to defeat them. Speciﬁcally, static materials cannot
make expressions according to our instructions in time (e.g.,
1 second) and attacks using them will be failed by expression
detector. Besides, we conduct a series of experiments in
Section VI to demonstrate that the expression detector can
be correctly integrated with our other veriﬁcations. Therefore,
the main task of our security analysis is to show that Face
Flashing can defeat dynamic attacks.
A. A Challenge-Response Protocol
Face Flashing is a challenge-response protocol whose se-
curity guarantees are built upon three elements: unpredictable
random challenges, hardly forged responses, and the effective
response veriﬁcations.
The Challenges. Our challenge is a sequence of carefully-
crafted images that are generated at random. Since the front-
end devices are assumed to be well protected, adversaries
could not learn the random values. Besides, a veriﬁcation
session consists of tens of challenges. Even if the adversary
can respond a right challenge by chance, it is unlikely for him
to respond to a sequence of challenges correctly.
The Responses. There are two important requirements for the
responses: First, the response must be easily generated by the
legitimate users, otherwise it may lead to usability problems or
even undermine the security guarantee (e.g., if adversaries can
generate fake responses faster than legitimate users). Secondly,
the responses should include essential characteristics of the
user, which are hard to be forged.
Face Flashing satisﬁes both requirements. The response is
the reﬂected light from the human face, and the user needs
to do nothing besides placing her face against the camera.
More importantly, such responses, in principle, are generated
at the speed of light, which is faster than any computational
process. Besides, the response carries unique characteristics of
the subject, such as the reﬂectance features of her face and
uneven geometry shapes, which are physical characteristics of
human faces that are inherently different from other media,
e.g., screens (major sources of security threats).
Response Veriﬁcation. We use an in-depth defense strategy
to verify the responses and detect possible attacks.
•
•
First, timing veriﬁcation is used to prevent forged
responses (including replay attacks).
Second, face veriﬁcation is used to check if the subject
under authentication has a speciﬁc shape similar to a
real human face.
•
Third, this face-like object must be regarded as the
same person with the victim by the face recognition
module (orthogonal to liveness detection).
Considering the pre-excluded static object, it is very hard
for adversaries to fabricate such a thing satisfying 3 rules above
simultaneously. In general, Face Flashing builds a high bar in
front of adversaries who want to impersonate the victim.
B. Security of Timing Veriﬁcation
The goal of the timing veriﬁcation is to detect the delay
in the response time caused by adversaries. Before further
analysis, we emphasize two points should be considered.
•
•
First, according to the design of modern screens,
the adversary cannot update the picture that is being
displayed on the screen at the arbitrary time. In other
words, the adversary cannot interrupt the screen and
let it show the latest generated response before the
start of next refreshing period.
Second, the camera is an integral device which accu-
mulates the light during his exposure period. And, at
any time, within an initialized camera, there always
exists some optical sensors are collecting the light.
For sake of clarity, we assume the front-end devices contain
a 60-fps camera and 60-Hz screen. On the other side, the
adversary has a more powerful camera with 240-fps and screen
with 240-Hz. Under these settings, we construct a typical
scenario to analyze our security, which time lines are shown
on Fig 10.
In this scenario,
the screen of the front-end device is
displaying the i-th challenge, and the adversary aims to forge
the response to this challenge. The adversary may instantly
learn the location of lighting area of the challenge after tu.
While she cannot present the forged response on her screen
until vk, due to the nature of how the screen works. Hence,
there is a gap between tu and vk. Recalling our method
described in Section IV-B3, during the gap, some columns
in the ROI have already completed the refreshing process. In
other words, these columns’ image will not be affected by the
forged response displaying on the adversary’s screen during
vk to vk+1. We name this phenomenon as delay.
When delay happens, our camera will get an undesired
response inducing four linear regression models to do deviated
estimation about the location of lighting area. Besides, the
standard deviation of these estimations will increase, for two
reasons:
•
•
The adversary’s screen can hardly be synchronized
with our screen. Particularly, it is different even the
length of adjacent refreshing periods. Hence, the delay
is unstable, so as the estimations.
The precision of forging will be affected by the inter-
nal error of adversaries’ measurement about time. This
imprecision will be ampliﬁed again by our camera,
which ﬂuctuates the estimations.
In other words, if the adversary reduces meand by dis-
playing the carefully-forged response, she will simultaneously
9
Our
Screen
Adv
Screen
lighting
area
lighting
area
ti
tu
td
ti+1
vk−1
vk
vk+1
Fig. 10: Security analysis on time.
increase stdd. On the other hand, if the adversary does nothing
to reduce stdd, she will signiﬁcantly enlarge meand. While
for a benign user, the delay will not happen, the discordance
between our camera and screen can be solved by checking the
timestamps afterward, and both the accumulated meand and
stdd will be small, according to our veriﬁcation algorithm.
In summary, we detect the delay by estimating the devia-
tion. And the effectiveness of our algorithm provides a strong
security guarantee on the timing veriﬁcation.
C. Security of Face Veriﬁcation
Our face veriﬁcation abstracts the intrinsic information
of shape through a series of puriﬁcation. And we feed this
information to a well-designed neural network.
If the adversary aims to bypass the face veriﬁcation, there
the
are two conundrums that need to be resolved. First,
adversary needs to conceal the specular reﬂection of the plain
screen. Particularly, during the authentication procedure, we
require the user to hold the phone so their face can occupy the
entire screen. The distance, as we measured, is about 20-cm. In
this short distance, the specular reﬂection is severe. In Fig 8b,
we demonstrate the result captured from a screen without any
covering sheet. Even covered by a scrub ﬁlm (Fig 8d), the
screen’s specular reﬂection is still intense.
Second,
the forged object must have similar geometry