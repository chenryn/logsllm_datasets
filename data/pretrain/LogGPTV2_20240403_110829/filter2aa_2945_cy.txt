There are several points to notice in this fragment of XAML markup:
Download from finelybook PI:EMAIL
986
By default, the command bar appears at the top of the screen and
displays icons for the buttons that it contains. The label for each
button is displayed only when the user clicks the More (…) button
that appears on the right side of the command bar. However, if
you are designing an application that could be used across
multiple countries or cultures, you should not provide hard-coded
values for labels but instead, store the text for these labels in a
culture-specific resources file and bind the Label property
dynamically when the application runs. For more information,
visit the page “Quickstart: Translating UI resources (XAML)” on
the Microsoft website at
https://msdn.microsoft.com/library/windows/apps/xaml/hh965329.aspx
The CommandBar control can contain only a limited set of
controls (controls that implement the ICommandBarElement
interface). This set includes the AppBarButton,
AppBarToggleButton, and AppBarSeparator controls. These
controls are specifically designed to operate within a
CommandBar. If you attempt to add a control such as a button to a
command bar, you will receive the error message “The specified
value cannot be assigned to the collection.”
The UWP app templates include a variety of stock icons (such as
for Previous and Next, shown in the sample code above) that you
can display on an AppBarButton control. You can also define your
own icons and bitmaps.
Each button has a Command property, which is the property that
you can bind to an object that implements the ICommand
interface. In this application, you have bound the buttons to the
PreviousCustomer and NextCustomer commands in the
ViewModel class. When the user clicks either of these buttons at
runtime, the corresponding command will run.
3. On the Debug menu, click Start Debugging.
The Customers form should appear and display the details for John
Sharp. The command bar should be displayed at the top of the form and
contain the Next and Previous buttons, as shown in the following image:
Download from finelybook PI:EMAIL
987
Notice that the Previous button is not available. This is because the
IsAtStart property of the ViewModel is true, and the CanExecute
method of the Command object referenced by the Previous button
indicates that the command cannot run.
4. Click the ellipsis button on the command bar. The labels for the buttons
should appear. These labels will be displayed until you click one of the
buttons on the command bar.
5. On the command bar, click Next.
The details for customer 2, Diana Sharp, should appear, and after a short
delay (of up to one second), the Previous button should become
available. The IsAtStart property is no longer true, so the CanExecute
method of the command returns true. However, the button is not notified
of this change in state until the timer object in the command expires and
triggers the CanExecuteChanged event, which might take up to a second
Download from finelybook PI:EMAIL
988
to occur.
Note If you require a more instantaneous reaction to the change in
state of commands, you can arrange for the timer in the Command
class to expire more frequently. However, avoid reducing the time
by too much because raising the CanExecuteChanged event too
frequently can impact the performance of the UI.
6. On the command bar, click Next again.
7. The details for customer 3, Francesca Sharp, should appear, and after a
short delay of up to one second, the Next button should no longer be
available. This time, the IsAtEnd property of the ViewModel is true, so
the CanExecute method of the Command object for the Next button
returns false, and the command is disabled.
8. Resize the window to display the app in the narrow view and verify that
the app continues to function correctly. The Next and Previous buttons
should step forward and backward through the list of customers.
9. Return to Visual Studio and stop debugging.
Searching for data using Cortana
A key feature of Windows 10 apps is the ability to integrate with the voice-
activated digital assistant, also known as Cortana. Using Cortana, you can
activate applications and pass them commands. A common requirement is to
use Cortana to initiate a search request and have an application respond with
the results of that request. The app can send the results back to Cortana for
display (known as background activation), or the app itself can display the
results (known as foreground activation). In this section, you will extend the
Customers app to enable a user to search for specific customers by name.
You can expand this example to cover other attributes or possibly combine
search elements into more complex queries.
Download from finelybook PI:EMAIL
989
Note The exercises in this section assume that you have enabled
Cortana. To do this, click the Search button on the Windows taskbar. In
the toolbar on the left side of the window, click Settings (the cog icon).
In the Settings window, click the Talk to Cortana tab, and make sure
that Cortana is configured to respond.
Cortana also requires that you have signed in to your computer by
using a Microsoft account, and will prompt you to connect if necessary.
This step is required because speech recognition is handled by an
external service running in the cloud rather than on your local device.
Download from finelybook PI:EMAIL
990
Adding voice activation to an app is a three-stage process:
1. Create a voice-command definition (VCD) file that describes the
commands to which your app can respond. This is an XML file that you
deploy as part of your application.
2. Register the voice commands with Cortana. You typically do this when
the app starts running. You must run the app at least once before
Cortana will recognize it. Thereafter, if Cortana associates a particular
command with your app, it will launch your app automatically. To avoid
cluttering up its vocabulary, Cortana will “forget” commands associated
with an app if the app is not activated for a couple of weeks, and the
commands have to be registered again to be recognized. Therefore, it is
common practice to register voice commands every time the app starts
running—to reset the “forget” counter and give the app another couple
of weeks of grace.
3. Handle voice activation in your app. Your app is passed information
from Cortana about the command that causes the app to be activated. It
is the responsibility of your code to parse this command, extract any
arguments, and perform the appropriate operations. This is the most
complicated part of implementing voice integration.
The following exercises walk through this process using the Customers
app.
Create the voice-command definition (VCD) file for the Customers app
1. In Visual Studio, open the Customers solution in the \Microsoft
Press\VCSBS\Chapter 26\ Cortana folder in your Documents folder.
This version of the Customers app has the same ViewModel that you
created in the previous exercise, but the data source contains details for
many more customers. The customer information is still held in a
List object, but this object is now created by the
DataSource class in the DataSource.cs file. The ViewModel class
references this list instead of creating the small collection of three
customers used in the previous exercise.
2. In Solution Explorer, right-click the Customers project, point to Add,
Download from finelybook PI:EMAIL
991
and then click New Item.
3. In the Add New Item - Customers dialog box, in the left pane, click
Visual C#. In the middle pane, scroll down and select the XML File
template. In the Name box, type CustomerVoiceCommands.xml, and
then click Add, as shown in the following image:
Visual Studio generates a default XML file and opens it in the Code and
Text Editor window.
4. Add the following markup shown in bold to the XML file.
Click here to view code image
    Customers
    Show details of John Sharp
Voice commands are defined in a command set. Each command set has
Download from finelybook PI:EMAIL
992
a command prefix (specified by the CommandPrefix element), which
can be used by Cortana to identify the application at runtime. The
command prefix does not have to be the same as the name of the
application. For example, if your application name is lengthy or contains
numeric characters, Cortana might have difficulty recognizing it, so you
can use the command prefix to provide a shorter and more
pronounceable alias. The Example element contains a phrase that shows
how a user can invoke the command. Cortana displays this example in
response to inquiries such as “What can I say?” or “Help.”
Note The command prefix should reflect the purpose of the
application and should not conflict with other well-known
applications or services. For example, if you specify a command
prefix of “Facebook,” your application is unlikely to pass
verification testing if it is submitted to the Windows Store.
5. If you are not located in the United States, change the xml:lang attribute
of the CommandSet element to reflect your locale. For example, if you
are in the United Kingdom, specify xml:lang=”en-gb”.
This is important. If the language specified does not match your locale,
Cortana will not recognize your voice commands at runtime. The
rationale behind this is that you should specify a separate CommandSet
element for each locale in which your application will run. This enables
you to provide alternative commands for different languages. Cortana
uses the locale of the machine on which the app is running to determine
which command set to use.
6. Add the Command and PhraseTopic elements shown in bold to the
CommandSet element in the XML file:
Click here to view code image
Download from finelybook PI:EMAIL
993
        Customers
        Show details of John Sharp
                show details of John Sharp
                    show details of
                    show details for
                    search for
                Looking for 
                Person Names
You can add one or more commands to a command set, each of which
can invoke a different operation in your application. Each command has
a unique identifier (the Name attribute). This identifier is passed to the
application that Cortana invokes so that the application can determine
which command the user spoke and thereby determine which operation
to perform.
The text in the Example element is displayed by Cortana if the user
selects your app in response to the query “What can I say?”; Cortana
will display the sample phrase for each of the commands that your app
understands.
The ListenFor element is used by Cortana to recognize the requests that
should invoke this app. You can specify multiple ListenFor phrases to
provide flexibility to the user. In this case, the user can speak three
variations of the same phrase to invoke the command. A phrase spoken
by the user should include either the name of the app or the prefix
specified in the CommandSet element. In this example, the name (or
prefix) can be specified at the beginning or end of the spoken phrase (the
RequireAppName attribute is set to BeforeOrAfterPhrase)—for
example, “Customers, show details of John Sharp” or “Search for John
Download from finelybook PI:EMAIL
994
Sharp in Customers.” The text in the ListenFor phrase is a placeholder
that is governed by the PhraseTopic element (described shortly).
The Feedback element is spoken by Cortana when it recognizes a
request. The customer specified by the user is substituted into the
placeholder.
The Navigate element indicates that Cortana will start the app in the
foreground. You can optionally specify which page should be displayed
(if the app contains multiple pages) as the Target attribute of this
element. The Customers app contains only a single page, so the Target
attribute is not specified. If the app is intended to run in the background
and pass data back for Cortana to display, you specify a
VoiceCommandService element instead of Navigate. For more
information, visit the page “Launch a background app with voice
commands in Cortana” online at
https://msdn.microsoft.com/library/dn974228.aspx.
The PhraseTopic element is used to define a placeholder in spoken
phrases. The Label attribute specifies with which placeholder the
element is associated. At runtime, Cortana substitutes the word or words
spoken at this point in the phrase into the phrase topic. The Scenario
attribute and the Subject elements are optional and provide hints to
Cortana about how to interpret these words. In this example, the words
are being used as search arguments and constitute human names. You
can specify other scenarios such as Short Message or Natural Language,
in which case Cortana may attempt to parse these words differently. You
can also specify alternative subjects such as addresses, phone number, or
city and state.
7. On the File menu, click Save CustomerVoiceCommands.xml, and then
close the file.
8. In Solution Explorer, select the CustomerVoiceCommands.xml file. In
the Properties window, change the Copy To Output Directory property
to Copy If Newer.
This action causes the XML file to be copied to the application folder if
it changes and be deployed with the app.
Download from finelybook PI:EMAIL
995
The next step is to register the voice commands with Cortana when the
app runs. You can do this in the code for the OnLaunched method in the
App.xaml.cs file. The OnLaunched method occurs every time a Launched
event occurs when the application starts running. When the application shuts
down, you can save information about the application state (which customer
the user was viewing, for example), and you can use this event to restore the
state of the application (by displaying the same customer) when the
application starts up again. You can also use this event to perform operations
that should occur every time the application runs.
Register voice commands with Cortana
1. In Solution Explorer, expand App.xaml and then double-click
App.xaml.cs to display the file in the Code and Text Editor window.
2. Add the following using directives to the list at the top of the file.
Click here to view code image
using Windows.Storage;
using Windows.ApplicationModel.VoiceCommands;
using System.Diagnostics;
3. Find the OnLaunched method and enable asynchronous operations by
adding the async modifier:
Click here to view code image
protected async override void
OnLaunched(LaunchActivatedEventArgs e)
{
    ...
}
4. Add the code shown below in bold to the end of the OnLaunched
method:
Click here to view code image
protected async override void
OnLaunched(LaunchActivatedEventArgs e)
{
    ...
    // Ensure the current window is active
    Window.Current.Activate();
    try
    {
Download from finelybook PI:EMAIL
996
        var storageFile = await Package.Current.
            InstalledLocation.GetFileAsync(@"CustomerVoiceCommands.xml");
        await VoiceCommandDefinitionManager.
            InstallCommandDefinitionsFromStorageFileAsync(storageFile);
    }
    catch (Exception ex)
    {
        Debug.WriteLine($"Installing Voice Commands Failed:
{ex.ToString()}");
    }
}
The first statement retrieves the XML file that contains the voice-
command definitions from the application folder. This file is then passed
to the VoiceCommandDefinitionManager manager. This class provides
the interface to the operating system for registering and querying voice-
command definitions. The static
InstallCommandDefinitionsFromStorageFileAsync method registers
voice commands found in the specified storage file. If an exception
occurs during this process, the exception is logged, but the application is
allowed to continue running (it just won’t respond to voice commands).
The final step of the process is to have your app respond when Cortana
recognizes a voice command intended for the app. In this case, you can
capture the Activated event by using the OnActivated method of the App
class. This method is passed a parameter of type IActivatedEventArgs, which
contains information describing data passed to the app, including the details
of any voice-activation commands.
Handle voice activation in the Customers app
1. In the Code and Text Editor window, add the OnActivated event method
shown here to the end of the App class, after the OnSuspending method:
Click here to view code image
protected override void OnActivated(IActivatedEventArgs args)
{
    base.OnActivated(args);
}
This method invokes the overridden OnActivated method to perform any
default activation processing required before handling voice activation.
2. Add the following if statement block shown in bold to the OnActivated
Download from finelybook PI:EMAIL
997
method:
Click here to view code image
protected override void OnActivated(IActivatedEventArgs args)
{
    base.OnActivated(args);
    if (args.Kind == ActivationKind.VoiceCommand)
    {
        var commandArgs = args as
VoiceCommandActivatedEventArgs;
        var speechRecognitionResult = commandArgs.Result;
        var commandName =
speechRecognitionResult.RulePath.First();
    }
}
This block determines whether the app has been activated by Cortana as
the result of a voice command. If so, the args parameter contains a
VoiceCommandActivatedEventArgs object. The Result property contains
a speechRecognitionResult object that contains information about the
command. The RulePath list in this object contains the elements of the
phrase that triggered activation, and the first item in this list contains the
name of the command recognized by Cortana. In the Customers
application, the only command defined in the
CustomerSearchCommands.xml file is the showDetailsOf command.
3. Add the following code shown in bold to the if statement block in the
OnActivated method:
Click here to view code image
if (args.Kind == ActivationKind.VoiceCommand)
{
    ...
    var commandName = speechRecognitionResult.RulePath.First();
    string customerName = "";
    switch (commandName)
    {
        case "showDetailsOf":
            customerName =
                speechRecognitionResult.SemanticInterpretation.
                    Properties["customer"].FirstOrDefault();
            break;
        default:
Download from finelybook PI:EMAIL
998
            break;
    }
}
The switch statement verifies that the voice command is the
showDetailsOf command. If you add more voice commands, you should
extend this switch statement. If the voice data contains some other
unknown command, it is ignored.
The SemanticInterpretation property of the speechRecognitionResult
object contains information about the properties of the phrase
recognized by Cortana. Commands for the Customers app include the
placeholder, and this code retrieves the text value for this placeholder as
spoken by the user and interpreted by Cortana.
4. Add the following code to the end of the OnActivated method, after the
switch statement:
Click here to view code image
protected override void OnActivated(IActivatedEventArgs args)
{
    ...
    if (args.Kind == ActivationKind.VoiceCommand)
    {
        ...
        switch (commandName)
        {
            ...
        }
        Frame rootFrame = Window.Current.Content as Frame;
        if (rootFrame == null)
        {
            rootFrame = new Frame();
            rootFrame.NavigationFailed += OnNavigationFailed;
            Window.Current.Content = rootFrame;
        }
        rootFrame.Navigate(typeof(MainPage), customerName);
        Window.Current.Activate();
    }
}
The first block here is boilerplate code that ensures that an application
window is open to display a page. The second block displays the
MainPage page in this window. The Navigate method of the Frame
Download from finelybook PI:EMAIL