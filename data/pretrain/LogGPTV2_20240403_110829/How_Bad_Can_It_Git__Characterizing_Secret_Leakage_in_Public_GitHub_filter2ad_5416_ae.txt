set of regular expressions. While this is similar to our work,
TrufﬂeHog has a more limited set of regular expressions and
does no validation on their results to avoid false positives.
Since users may rely on tools like TrufﬂeHog, we analyze its
performance by running every secret we detected through its
algorithm.
Our results show that TrufﬂeHog is largely ineffective at
detecting secrets, as its algorithm only detected 25.236% of
the secrets in our Search dataset and 29.39% in the BigQuery
dataset. Every one of these secrets were detected by entropy,
while only a fraction of them were double detected by regular
expressions. This discrepancy is worrying as the TrufﬂeHog
developers are deprecating entropy detection in favor of regular
expressions detection [59]. If this change had been in place,
only 19.263% of secrets from Search and 22.29% of secrets
from BigQuery would have been detected. Because this problem
is caused by a set of weak regular expressions, this tool could
be improved by the use of our techniques. While TrufﬂeHog
does detect some secrets, we do not believe it provides strong
enough protection. Developers using tools such as this may
believe they are safe, but may unwittingly be pushing secrets.
Unfortunately, because TrufﬂeHog runs locally, we were unable
to measure the rate of usage.
E. Google Client Secret Files
As a convenience and in an attempt to aid security, Google
provides developers with a client_secret_*.json ﬁle,
where the asterisk would be replaced with a unique identiﬁer.
Google recommends that you download this ﬁle for using your
OAuth credentials instead of embedding the values in code
directly, stressing clearly that the ﬁle should be stored out of the
source tree [30]. To evaluate whether developers took heed of
this warning, we analyzed every ﬁle containing Google OAuth
IDs that matched the client_secret_*.json pattern.
Ideally, these ﬁles should not exist on GitHub; however, we
identiﬁed 2,155 of these ﬁles in the Search dataset and 388 in
the BigQuery dataset. Further, this accounted for 5.027% of
all ﬁles containing Google OAuth IDs in the search dataset,
and 2.246% in the BigQuery dataset. The leakage of this ﬁle
is particularly worrying as it contains other secret information,
such as the OAuth Secret, in an easily parseable format. While
this ﬁle mismanagement is not the primary source of leakage,
it is certainly a substantial factor.
VIII. CASE STUDIES
In this section, we discuss several interesting case studies
discovered in the course of our research.
Secrets in .gitignore Files The .gitignore ﬁle is
intended to allow developers to specify certain ﬁles that should
not be committed, and it can be used (among other things) to
prevent ﬁles containing secrets from being leaked. While this
is a good strategy, many developers do not use this option and
some do not fully understand it. To better investigate its usage,
we used the Search API to collect .gitignore ﬁles over a
3 week period in the same manner as our normal collection
process. Our assumption had been that these ﬁles would not
contain secrets as they should only contain path references to
ﬁles. Yet, we identiﬁed 58 additional secrets from this process.
While this is a small number compared to the full dataset, this
ﬁnding indicates that some developers commit secrets out of
fundamental misunderstandings of features like .gitignore.
YouTube Copyright Infringement Our data collection
methodology uncovered an interesting case study in which a
GitHub user appeared to be conducting copyright infringement.
A single user was hosting repositories containing source code
for different websites that pull videos from YouTube and rehost
them. We found a total of 564 Google API keys in these
repositories, along with indications that they were being used
to bypass rate limits. Because the number of keys is so high,
we suspect (but cannot conﬁrm) that these keys may have been
obtained fraudulently. We could not locate the keys elsewhere
in our limited view of GitHub, but it is possible that the keys
came from elsewhere on GitHub, other public leaks, or accounts
sold on the black market. Further, this example demonstrates
the potential misuse of leaked secrets by a malicious actor.
High-Value Targets Our data shows that even high-value
targets run by experienced developers can leak secrets. In one
case, we found what we believe to be AWS credentials for a
major website relied upon by millions of college applicants
in the United States, possibly leaked by a contractor. We also
found AWS credentials for the website of a major government
agency in a Western European country. In that case, we were
able to verify the validity of the account, and even the speciﬁc
developer who committed the secrets. This developer claims in
their online presence to have nearly 10 years of development
experience. These examples anecdotally support our ﬁndings
in Section VII-A that developer inexperience is not a strong
predictor of leaks.
Rewriting History Does Not Protect Secrets It is obvious
that adversaries who monitor commits in real time can discover
leaked secrets, even if they are naively removed. However, we
discovered that even if commit histories are rewritten, secrets
can still be recovered. In investigating the previous European
case study, we discovered that we could recover the full contents
of deleted commits from GitHub with only the commit’s SHA-1
ID. Using our own repos, we experimentally conﬁrmed that
this held true for both of GitHub’s recommended methods
for removing sensitive information: git filter-branch
or the bfg tool [50]. The difﬁculty in this approach is in
acquiring the commit hash, as it is hidden from GitHub’s
UI and Commits API. However, we found that these hidden
commit hashes could be recovered with trivial effort via the
Events API [20]. Moreover, historical data from this API is
12
available through the GHTorrent Project [31]. Taken together,
this indicates that the consequences of even rapidly detected
secret disclosure is severe and difﬁcult to mitigate short of
deleting a repository or reissuing credentials.
IX. MITIGATIONS
We have shown that an attacker with minimal resources
could compromise many GitHub users by stealing leaked
keys. In this section, we discuss how current mitigations fall
short and what new mitigations might be successful. Through
our results, we addressed three potential mitigations to our
collection methodology and demonstrated their ineffectiveness.
First, secret leakage could be stopped prior to commit using
tools like TrufﬂeHog [59]. However, in Section VII-D, we
found that TrufﬂeHog is only approximately 25% effective.
Second, many API platforms require multiple secret values to
be used, possibly inhibiting a potential attacker. We showed in
Section V-D that complementary secrets are committed in the
same ﬁle with high probability, nullifying the advantages of
this technique in practice. Finally, GitHub imposes strict rate
limits for Search API requests to inhibit large-scale mining.
Unfortunately, Section VI-A demonstrated this rate limiting
can be easily bypassed with a single key.
Fortunately, there is room to improve these mitigations.
For example, TrufﬂeHog could detect all of the secrets that
we detect if it implements our detection techniques. Second,
the fact that many secrets have distinct patterns that simplify
accurate detection means that our techniques could be used
by services to monitor and instantly alert developers and
services of compromise. In fact, there is evidence that AWS
may already do this [3], [9]. Finally, while GitHub might
consider trying to increase their rate limiting, we argue that
this would still be trivial to bypass with multiple keys and would
disproportionately affect legitimate users. Instead, GitHub could
extend their security alerts program [34] to scan for secrets and
notify developers at commit time. GitHub recently introduced
a beta version of Token Scanning [16], [58], which scans
repos for tokens and contacts the provider with the token and
metadata. The provider can then revoke the token mitigating
the impact of it’s disclosure. This feature can be improved with
the ﬁndings from this paper, increasing the providers included.
All of these, however, are mitigations, taking action late
in the secret’s lifetime after it has already been exposed.
Ultimately, we believe that more research is needed on the
question of secret and key management for software. Extensive
work has been done in this area for users (e.g. passwords
and alternative authentication). Two possible approaches to
address this earlier in the process are extending Git to handle
secrets natively, or changing the architecture of libraries to
automatically and securely manage secrets for developers.
X. LIMITATIONS
In this section we brieﬂy detail limitations of our experi-
ments. First, we do not have ground truth knowledge that the
secrets we discover are exploitable. Though we make every
effort to exclude them, some secrets may be non-sensitive,
revoked, stale, or simply invalid. Without actually testing such
secrets (which we do not do for reasons discussed in Section IV),
it is not possible to have certainty that a secret is exploitable.
Second, we focus only on secrets that we felt could be
discovered with high probability of validity and sensitivity.
There are certainly many important services that we do not
detect secrets for. Similarly, while GitHub is the largest public
code hosting service, there are many other services where
secrets may be leaked, including services like BitBucket or
Pastebin. This means that our ﬁndings are a lower bound on
the risks of secret leakage through public repositories.
Finally, for some of the APIs we study we ﬁnd few leaked
keys, as shown in Table II. While we surveyed many public
APIs, the relative usage of each API in a project that would
be hosted on GitHub will naturally differ. We nevertheless
discover a large number of keys overall, including keys for
every service we chose to investigate.
XI. CONCLUSION
GitHub has become the most popular platform for collabora-
tively editing software, yet this collaboration often conﬂicts with
the need for software to use secret information. This conﬂict
creates the potential for public secret leakage. In this paper, we
characterize the prevalence of such leakage. By leveraging two
complementary detection approaches, we discover hundreds
of thousands of API and cryptographic keys leaked at a rate
of thousands per day. This work not only demonstrates the
scale of this problem, but also highlights the potential causes of
leakage and discusses the effectiveness of existing mitigations.
In so doing, we show that secret leakage via public repositories
places developers at risk.
REFERENCES
[1]
[2]
[3]
[4]
(2018, Mar.) About GitHub. [Online]. Available: https://github.com/about
(2018) Alexa Top Software Sites.
[Online]. Available: https:
//www.alexa.com/topsites/category/Top/Computers/Software
(2018) AWS Labs git-secrets. [Online]. Available: https://github.com/
awslabs/git-secrets
(2014, Mar.) AWS Urges Devs To Scrub Secret Keys From
GitHub. [Online]. Available: https://developers.slashdot.org/story/14/03/
24/0111203/aws-urges-devs-to-scrub-secret-keys-from-github
[5] M. Balduzzi, J. Zaddach, D. Balzarotti, E. Kirda, and S. Loureiro, “A
Security Analysis of Amazon’s Elastic Compute Cloud Service,” SAC,
2012.
[6] C. M. Bishop, Pattern Recognition and Machine Learning. Secaucus,
NJ, USA: Springer-Verlag New York, Inc., 2006.
[7] T. F. Bissyande, D. Lo, L. Jiang, L. Reveillere, J. Klein, and Y. L. Traon,
“Got issues? Who cares about it? A large scale investigation of issue
trackers from GitHub,” International Symposium on Software Reliability
Engineering, 2013.
(2015,
Jan.) Bots Scanning GitHub To Steal Amazon EC2
Keys. [Online]. Available: https://it.slashdot.org/story/15/01/02/2342228/
bots-scanning-github-to-steal-amazon-ec2-keys
[8]
[9] D.
Bourke.
[10]
Breach Detection
at
(2017, Oct.)
Scale.
https://developer.atlassian.com/blog/2017/10/
[Online]. Available:
project-spacecrab-breach-detection/
J. Cabot, J. L. C. Izquierdo, V. Cosentino, and B. Rolandi, “Exploring
the use of labels to categorize issues in Open-Source Software projects,”
in 2015 IEEE 22nd International Conference on Software Analysis,
Evolution, and Reengineering (SANER), March 2015, pp. 550–554.
[11] S. Chacon and B. Straub, Pro Git. Apress, 2014.
[12] A. D. Diego, “Automatic extraction of API Keys from Android
applications,” Ph.D. dissertation, UNIVERSIT `A DEGLI STUDI DI
ROMA ”TOR VERGATA”, 2017.
[13] R. Dyer, H. A. Nguyen, H. Rajan, and T. N. Nguyen, “Boa: A
Language and Infrastructure for Analyzing Ultra-Large-Scale Software
Repositories,” International Conference on Software Engineering, 2013.
13
[14] S. Farooqi, F. Zaffar, N. Leontiadis, and Z. Shaﬁq, “Measuring and
Mitigating OAuth Access Token Abuse by Collusion Networks,” in
Proceedings of the 2017 Internet Measurement Conference, ser. IMC
’17. New York, NY, USA: ACM, 2017, pp. 355–368.
[15] D. Fett, R. K¨usters, and G. Schmitz, “A Comprehensive Formal
Security Analysis of OAuth 2.0,” in Proceedings of the 2016 ACM
SIGSAC Conference on Computer and Communications Security, ser.
CCS ’16. New York, NY, USA: ACM, 2016, pp. 1204–1215. [Online].
Available: http://doi.acm.org/10.1145/2976749.2978385
[16] GitHub. (2018, Oct.) About Token Scanning. [Online]. Available:
[Online]. Available:
https://help.github.com/articles/about-token-scanning/
(2018) GitHub API Rate Limiting Documentation. [Online]. Available:
https://developer.github.com/v3/#rate-limiting
(2018) GitHub Content API Documentation. [Online]. Available:
https://developer.github.com/v3/repos/contents/#get-contents
(2018) GitHub dotﬁles. [Online]. Available: https://dotﬁles.github.io/
(2018) GitHub Events API Documentation.
https://developer.github.com/v3/activity/events/
(2013, Jan.) Github Kills Search After Hundreds of Private Keys
Exposed.
[Online]. Available: https://it.slashdot.org/story/13/01/25/
132203/github-kills-search-after-hundreds-of-private-keys-exposed
(2018) GitHub Search API Documentation.
https://developer.github.com/v3/search/#search-code
(2018) GitHub Search API Rate Limiting Documentation. [Online].
Available: https://developer.github.com/v3/search/#rate-limit
(2018) GitHub Searching Code. [Online]. Available: https://help.github.
com/articles/searching-code/
(2013,
up-
[Online].
https://arstechnica.com/information-technology/2013/01/
load
Available:
psa-dont-upload-your-important-passwords-to-github/
[Online]. Available:
Jan.)
passwords
Goodin.
your
PSA:
to
important
GitHub.
Don’t
of
of
and
passwords
Thousands
servers
keys.
(2018,
Mar.)
750MB worth
found
[Online].
https://arstechnica.com/information-technology/2018/03/
leaking
Available:
thousands-of-servers-found-leaking-750-mb-worth-of-passwords-and-keys/
(2018, Apr.) Google BigQuery GitHub Data. [Online]. Available: https:
//console.cloud.google.com/marketplace/details/github/github-repos
(2018) Google BigQuery Public Datasets.
https://cloud.google.com/bigquery/public-data/
(2018) Google Hacking Database. [Online]. Available: https://www.
exploit-db.com/google-hacking-database/
(2018, Jan.) Google Using OAuth 2.0 for Installed Applications.
[Online]. Available: https://developers.google.com/api-client-library/
python/auth/installed-app
[Online]. Available:
[17]
[18]
[19]
[20]
[21]
[22]
[23]
[24]
[27]
[28]
[29]
[30]
[32]
[33]
[25] D.
[26] ——.
[40] A. Kashcha.
(2018) Common Words.
//github.com/anvaka/common-words
[Online]. Available: https:
[41] M. Kumar. (2013, Jan.) Hundreds of SSH Private Keys exposed via
GitHub Search. [Online]. Available: https://thehackernews.com/2013/01/
hundreds-of-ssh-private-keys-exposed.html
J. Linn, “Privacy Enhancement for Internet Electronic Mail: Part I:
Message Encryption and Authentication Procedures,” pp. 1–42, 1993.
[Online]. Available: https://tools.ietf.org/html/rfc1421