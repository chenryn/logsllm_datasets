D =,
where Σ is the input alphabet (composed of server replies),
S is a set of states, each labeled with a client command, s0
is an initial state, and T is a set of transitions. Fg ⊂ S is
a set of good states, representing an email being processed
correctly, while Fb ⊂ S is a set of bad states, representing
an error in the email sending process. Since SMTP com-
mands include variable ﬁelds (such as email addresses), we
abstract speciﬁc ﬁelds of the commands into regular expres-
sions. In particular, we substitute fully-qualiﬁed domains,
IP addresses, host names, and email addresses with generic
identiﬁers. This operation is described in detail in our pre-
vious paper [22].
To build an SMTP dialect, we capture the SMTP conver-
sations between a client and the mailserver and iteratively
build the state machine, as described in [22]. Figure 1 shows
an example of an SMTP dialect. The transitions represent
server replies, while the states represent client commands.
In this particular case, the client ﬁrst announces itself and its
domain (HELO command), then sends a RSET command, spec-
iﬁes the sender and the recipient email addresses (with the
MAIL and RCPT commands, respectively), and starts sending
the content of the email.
{Start}HELO domain 220 debian ESMTP PostﬁxRSET 250 debianMAIL FROM: 250 2.0.0 OkRCPT TO: 250 2.1.0 OkDATA 250 2.1.5 Ok3552.2.1 Learning the Dialects Spoken by Botnets
As we said, we are interested in understanding what bot-
net or MTA generated the emails that have been sent to the
mailserver. To this end, we need previous knowledge about
which SMTP dialects are spoken by diﬀerent botnets and
MTAs. To accomplish this task, we analyzed the SMTP
conversations generated by the malware samples submitted
to Anubis, a popular sandbox malware analysis system [2].
For each malware sample, we ﬁrst learned the SMTP dialect
spoken by it. Then, we grouped together all the samples that
speak the same dialect.
We analyzed the malware samples submitted to Anubis
for the period between January 1, 2013 and May 15, 2013.
In total, 18,849 submitted samples connected to a mailserver
and started an SMTP conversation. These samples include
spamming botnets, self-propagating worms that send a copy
of themselves over email, and generic malware that sends an
email to their botmaster as a heartbeat signal. The sand-
box environment did not allow any SMTP connection to the
outside, but redirected them to a local mailserver. This way,
we were able to log the SMTP conversations generated by
the malware samples.
In total, the malware samples that
we analyzed speak 72 diﬀerent SMTP dialects. As we will
show in Section 3.2, these dialects cover the vast majority
of the hosts that contacted the email addresses that we dis-
seminated on the web.
To assign a name to each dialect, we proceeded as follows.
First, we grouped all the malware samples that speak the
same dialect together. Then, we collected the name given to
those malware samples by popular antivirus programs, by
using Virustotal [25]. Finally, we assigned as a name for
the malware family the most common label assigned to the
samples that speak that dialect by the antivirus programs
in Virustotal. This approach has been already used in
previous work, and it proved to be reliable [22].
Not all spam is sent by botnets though [24]. Some spam-
mers set up their own mailservers and use them to send
spam, instead of setting up botnets. To identify this type of
spam, we need to learn the dialects spoken by popular Mail
Transfer Agents (MTAs). To this end, we set up a number
of virtual machines, and installed a diﬀerent MTA on each of
them. More precisely, we used Virtualbox as our virtualiza-
tion environment — we set up Ubuntu Linux 11.10 virtual
machines, and set up one of the Exim, Postﬁx, Qmail, and
Sendmail MTAs on each of them; we also set up a Windows
Server 2008 virtual machine, and ran Microsoft Exchange
2010 on it. On each virtual machine, we set up a script that
sent emails automatically to a mailserver under our control.
We then leveraged the SMTP conversations generated by
the virtual machines to learn the dialects spoken by each
MTA. As we already noted, each MTA speaks a diﬀerent
dialect from the others [22].
2.3 Spam Campaign Analysis
We call a spam operation a spam campaign. Broadly
speaking, a spam campaign is composed by a set of emails
that advertise the same product. Typical goods advertised
in spam emails are pharmaceutical products, counterfeit goods,
dating sites, and others [21].
In this paper, we consider
a spam campaign as being indicative of a single spammer.
This assumption is motivated by the fact that previous work
showed that each spammer sets up his/her email templates
when sending spam [21].
In principle however, the same
spammer might run multiple spam campaigns at the same
time. We perform a more comprehensive analysis of these
assumptions in Section 3.4.
Even if they advertise the same type of goods, the spam
emails belonging to the same campaign are not identical.
Spammers add some variations in the content, in the subject
lines, and in the advertised URLs to avoid easy detection by
template-based anti-spam techniques [19, 27]. For this rea-
son, we have to adopt more advanced similarity techniques
to group spam emails into spam campaigns. We extract
four features that characterize an email; in the following, we
describe them in detail. We consider two emails as belong-
ing to the same campaign if they match any of these four
criteria.
Subject Line. Subject lines are important in spam emails,
because they are the ﬁrst piece of information seen by a
victim, and might lure them into opening the full email.
Spammers need to make their subject lines captivating, but
also vary them enough to avoid easy detection. We consider
two emails as belonging to the same spam campaign if their
subject lines are either identical or share four or more words.
URL domain. Miscreants change the domains that they
use to host their malicious web pages quite often. Since pur-
chasing domains has a non-negligible cost, however, they use
each of them for multiple emails. For this reason, we con-
sider two emails as belonging to the same spam campaign if
they advertise a URL that shares the same domain. A sim-
ilar technique has been leveraged by previous research [27].
Mailer. Spammers often use fake mail user agent strings in
the email headers (mailer). This mailer is often the same for
the emails belonging to the same campaign [21]. Therefore,
we group together emails that share the same mailer.
Sender email address. From our observations, we noticed
that most spammers set the From address in their emails.
We also observed that this from address is often shared by
multiple emails in the same campaign. For this reason, we
group together emails that share the same sender address.
2.4 Assumptions & Limitations
The methodology that we follow in this paper is based
on a set of assumptions. In the following, we discuss these
assumptions in detail.
Diﬀerent actors in the spam chain engage in a mar-
ket economy. We assume the presence of three diﬀerent
roles, i.e., the harvester, the botmaster, and the spammer.
As suggested by previous work [21], these roles are likely to
be represented by diﬀerent entities that engage in a market
economy. For example, email addresses are collected by the
harvester and then sold to spammers who rent botnets for
the spam dissemination. In other cases, the spammer and
the harvester might represent the same entity.
Diﬀerent usage pattern in the harvesting and spam-
ming process are indicative for the diﬀerent actors.
While we cannot observe the diﬀerent actors directly, we
assume that they can be ﬁngerprinted by diﬀerent observ-
able usage pattern. For instance, short turnaround times
in which spam arrives almost immediately after harvest-
ing [9,20] can be indicative for cases in which the harvesting
is performed by the spammer.
In turn, long turnaround
times of up to multiple years, however, can be indicative
of cases in which email addresses were sold on the market.
Conversely, spammer and harvester are likely to be two in-
356dependent entities. We note that this ﬁrst step provides
indications rather than strict evidence.
Email addresses are being harvested from the web.
In this paper, we only focus on e-mail addresses that were
harvested from public web pages by using crawlers. We re-
mark that there are other ways to harvest email addresses,
such as malicious software locally running on compromised
machines [14]. These further harvesting techniques are, how-
ever, out-of-scope of this paper.
SMTP dialects are indicative for diﬀerent botnets.
To identify diﬀerent botnets, we rely on SMTP dialect ﬁn-
gerprinting. We assume that this technique can reliably dis-
tinguish between malware families that send spam or be-
tween misused MTAs. This assumption is supported by our
previous work, in which we show that all the SMTP imple-
mentations that we encountered in the wild are diﬀerent [22].
A single campaign is indicative for a single spam-
mer. Spam campaigns advertise goods, point to scam web
pages, or disseminate malware. We assume that such cam-
paigns are run by an entity that we refer to as a spammer.
The spammer himself remains invisible to us and only the
launched campaigns can be observed. Previous work showed
that spammers use individual templates for composing spam
mails [21] and thus supports our hypothesis.
In case of a
joint campaign run by multiple spammers, individual enti-
ties cannot be diﬀerentiated by our approach and are merged
into distinct observable campaigns. Thus, we cannot derive
exact ﬁgures on the number of spammers observed.
The assumed behavior of the harvester, the botmaster,
and the spammer are based on indirect measurements of
both the harvesting and the spamming process. The na-
ture of the applied indirect measurements yields correlations
among the behavior of diﬀerent actors in the spam chain.
However, our approach does not allow us to derive exact
ﬁgures and causal relationships for the involved actors. De-
spite these limitations, this work provides a novel ﬁrst step
in understanding these relationships.
3. ANALYSIS OF THE COLLECTED DATA
In the following, we ﬁrst analyze the harvesters that fetched
our email addresses. Then, we analyze the botnets (or MTAs)
that sent the emails and we study the spam campaigns that
targeted our email addresses. Finally, we discuss the rela-
tions among the three actors involved in the spam delivery
process (harvesters, botnets, and spammers).
3.1 Analysis of the Harvesters
In total, the spamtrap email addresses in our dataset were
harvested by 75 unique IP addresses. Note that the num-
ber of IP addresses does not map to the number of har-
vesters. In distributed infrastructures, for instance, multi-
ple IP addresses can belong to the same harvesting entity.
A distributed infrastructure helps in two ways:
it is more
eﬃcient, and it is stealthier. From what we observed in our
experiments, however, the main activity concentrates on a
small set of IPs. In particular, four IP addresses harvested
70% of the email addresses, which ended up receiving 74%
of the total spam.
To classify the harvesters that crawled the web sites, we
manually analyzed the dataset. We consider two IP ad-
dresses as belonging to the same harvester if i) they are lo-
cated in the same autonomous system or if ii) they announce
the same user agent string or share patterns in the HTTP
Figure 2: Harvesting year. As it can be seen, most
addresses have been harvested during 2013.
headers. While several distinct harvester bots can run in
the same AS, we consider the submitted user agent string
pattern to be one characteristic of the harvesting software
being used.
In total, we observed nine distinct harvesters, which are
summarized in Table 4. Five harvesters used a single IP
address, while the others were distributed. The largest dis-
tributed harvester (C) was observed on 56 distinct IP ad-
dresses located in a residential DSL access network in Ger-
many. One unique characteristic of this harvester are random-
looking user agent strings. The total number of machines
used by the harvester is likely to be diﬀerent from the num-
ber of IP addresses, as residential users in this network get
new dynamic IP addresses assigned every 24 hours. While
the 56 IP addresses could in theory belong to the same phys-
ical machine, we observed several parallel crawling activ-
ities from multiple IP addresses. This indeed suggests a
distributed harvesting infrastructure.
Interestingly, the size of the harvester, estimated by the
number of IP addresses, does not correlate with harvesting
activity and spam volume received by the harvested email
address: The largest number of email addresses was collected
by a harvester (D) that was using only three IP addresses.
We assume user agent strings to be a main characteristic
of a harvesting software. Table 4 also shows example user
agents for the email harvesters that we observed. Some of
the user agent strings mimic legitimate browsers, while oth-
ers identify software libraries or consist of random strings.
In some cases, such as harvester I, the user agent does not
change at subsequent requests. For some harvesters, the
user agent is constantly changed, arguably to avoid easy de-
tection. At the extreme is harvester C, which sets a diﬀerent
random string as user agent after each request.
We observe two interesting patterns in the harvesters that
contacted us. Firstly, the Java user agent used by harvester
D correlated with high harvesting activity and caused large
spam volumes. Earlier observations of this user agent in
the context of harvesting [9, 20] suggest that this harvesting
software has existed for at least eight years and thus to be
a stable pattern in the harvesting landscape.
As we observed earlier [9], in some cases addresses that
we returned only to harvesters presenting the user agent of
the Google bot received spam. This denotes the case of har-
vester F that not only presents a legitimate user agent, but
2010201120122013% Harvested Email Addresses0102030405060357Harvester Activity Periods
2
A
1
B
C
41
3
D
1
E
1
F
1
G
4
H
I
4
Start
2010-07-02
2010-10-30
2010-02-10
2011-01-08
2011-01-15
2013-03-29
2012-08-30
2012-10-19
2011-08-27
Stop
2010-07-02
2010-10-30
2010-10-20
2013-04-06
2011-01-15
2013-03-29
2012-08-30
2012-12-05
2012-02-16
Table 2: Activity periods per harvester. As it can
be seen, some harvesters were active in bursts for
short periods of time, while others were constantly
observed for very long periods.
Harvester Median Turnaround Time
26 days
A
15 days
B
343 days
C