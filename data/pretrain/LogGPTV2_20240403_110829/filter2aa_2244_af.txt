believe that anti-A evidence actually supports that position.  There are a lot of experiments that 
confirm this basic bias and explore its complexities. 
If there’s one moral here, it’s that individual preferences are not based on predefined 
models that can be cleanly represented in the sort of indifference curves you read about in 
microeconomics textbooks; but instead, are poorly defined, highly malleable, and strongly 
dependent on the context in which they are elicited.  Heuristics and biases matter.  A lot. 
This all relates to security because it demonstrates that we are not adept at making rational 
security trade-offs, especially in the context of a lot of ancillary information designed to 
persuade us one way or another. 
Making Sense of the Perception of Security 
We started out by teasing apart the security trade-off, and listing five areas where 
perception can diverge from reality: 
1. The severity of the risk. 
2. The probability of the risk. 
The Psychology of Security—DRAFT 
23 
3. The magnitude of the costs. 
4. How effective the countermeasure is at mitigating the risk. 
5. The trade-off itself. 
Sometimes in all the areas, and all the time in area 4, we can explain this divergence as a 
consequence of not having enough information.  But sometimes we have all the information and 
still make bad security trade-offs.  My aim was to give you a glimpse of the complicated brain 
systems that make these trade-offs, and how they can go wrong. 
Of course, we can make bad trade-offs in anything: predicting what snack we’d prefer next 
week or not being willing to pay enough for a beer on a hot day.  But security trade-offs are 
particularly vulnerable to these biases because they are so critical to our survival.  Long before 
our evolutionary ancestors had the brain capacity to consider future snack preferences or a fair 
price for a cold beer, they were dodging predators and forging social ties with others of their 
species.  Our brain heuristics for dealing with security are old and well-worn, and our amygdalas 
are even older. 
What’s new from an evolutionary perspective is large-scale human society, and the new 
security trade-offs that come with it.  In the past I have singled out technology and the media as 
two aspects of modern society that make it particularly difficult to make good security trade-
offs—technology by hiding detailed complexity so that we don’t have the right information about 
risks, and the media by producing such available, vivid, and salient sensory input—but the issue 
is really broader than that.  The neocortex, the part of our brain that has to make security trade-
offs, is, in the words of Daniel Gilbert, “still in beta testing.” 
I have just started exploring the relevant literature in behavioral economics, the psychology 
of decision making, the psychology of risk, and neuroscience.  Undoubtedly there is a lot of 
research out there for me still to discover, and more fascinatingly counterintuitive experiments 
that illuminate our brain heuristics and biases.  But already I understand much more clearly why 
we get security trade-offs so wrong so often. 
When I started reading about the psychology of security, I quickly realized that this 
research can be used both for good and for evil.  The good way to use this research is to figure 
out how humans’ feelings of security can better match the reality of security.  In other words, 
how do we get people to recognize that they need to question their default behavior?  Giving 
them more information seems not to be the answer; we're already drowning in information, and 
these heuristics are not based on a lack of information.  Perhaps by understanding how our 
brains processes risk, and the heuristics and biases we use to think about security, we can learn 
how to override our natural tendencies and make better security trade-offs.  Perhaps we can 
learn how not to be taken in by security theater, and how to convince others not to be taken in by 
the same. 
The evil way is to focus on the feeling of security at the expense of the reality.  In his book 
Influence,58 Robert Cialdini makes the point that people can’t analyze every decision fully; it’s 
just not possible: people need heuristics to get through life.  Cialdini discusses how to take 
advantage of that; an unscrupulous person, corporation, or government can similarly take 
advantage of the heuristics and biases we have about risk and security.  Concepts of prospect 
theory, framing, availability, representativeness, affect, and others are key issues in marketing 
and politics.  They’re applied generally, but in today’s world they’re more and more applied to 
security.  Someone could use this research to simply make people feel more secure, rather than 
to actually make them more secure. 
After all my reading and writing, I believe my good way of using the research is unrealistic, 
The Psychology of Security—DRAFT 
24 
and the evil way is unacceptable.  But I also see a third way: integrating the feeling and reality of 
security. 
The feeling and reality of security are different, but they’re closely related.  We make the 
best security trade-offs—and by that I mean trade-offs that give us genuine security for a 
reasonable cost—when our feeling of security matches the reality of security.  It’s when the two 
are out of alignment that we get security wrong. 
In the past, I’ve criticized palliative security measures that only make people feel more 
secure as “security theater.”  But used correctly, they can be a way of raising our feeling of 
security to more closely match the reality of security.  One example is the tamper-proof 
packaging that started to appear on over-the-counter drugs in the 1980s, after a few highly 
publicized random poisonings.  As a countermeasure, it didn’t make much sense.  It’s easy to 
poison many foods and over-the-counter medicines right through the seal—with a syringe, for 
example—or to open and reseal the package well enough that an unwary consumer won’t detect 
it. But the tamper-resistant packaging brought people’s perceptions of the risk more in line with 
the actual risk: minimal.  And for that reason the change was worth it. 
Of course, security theater has a cost, just like real security.  It can cost money, time, 
capabilities, freedoms, and so on, and most of the time the costs far outweigh the benefits.  And 
security theater is no substitute for real security.  Furthermore, too much security theater will 
raise people’s feeling of security to a level greater than the reality, which is also bad.  But used in 
conjunction with real security, a bit of well-placed security theater might be exactly what we 
need to both be and feel more secure. 
1 Bruce Schneier, Beyond Fear: Thinking Sensibly About Security in an Uncertain World, Springer-
Verlag, 2003. 
2 David Ropeik and George Gray, Risk: A Practical Guide for Deciding What’s Really Safe and What’s 
Really Dangerous in the World Around You, Houghton Mifflin, 2002. 
3 Barry Glassner, The Culture of Fear: Why Americans are Afraid of the Wrong Things, Basic Books, 
1999. 
4 Paul Slovic, The Perception of Risk, Earthscan Publications Ltd, 2000. 
5 Daniel Gilbert, “If only gay sex caused global warming,” Los Angeles Times, 2 Jul 2006. 
6 Jeffrey Kluger, “How Americans Are Living Dangerously,” Time, 26 Nov 2006. 
7 Steven Johnson, Mind Wide Open: Your Brain and the Neuroscience of Everyday Life, Scribner, 2004. 
8 Daniel Gilbert, “If only gay sex caused global warming,” Los Angeles Times, July 2, 2006. 
9 Donald A. Norman, “Being Analog,” http://www.jnd.org/dn.mss/being_analog.html.  Originally 
published as Chapter 7 of The Invisible Computer, MIT Press, 1998. 
10 Daniel Kahneman, “A Perspective on Judgment and Choice,” American Psychologist, 2003, 58:9, 697–
720. 
11 Gerg Gigerenzer, Peter M. Todd, et al., Simple Heuristics that Make us Smart, Oxford University Press, 
1999. 
12 Daniel Kahneman and Amos Tversky, “Prospect Theory: An Analysis of Decision Under Risk,” 
Econometrica, 1979, 47:263–291. 
13 Amos Tversky and Daniel Kahneman, “The Framing of Decisions and the Psychology of Choice,” 
Science, 1981, 211: 453–458. 
14 Amos Tversky and Daniel Kahneman, “Evidential Impact of Base Rates,” in Daniel Kahneman, Paul 
Slovic, and Amos Tversky (eds.), Judgment Under Uncertainty: Heuristics and Biases, Cambridge 
The Psychology of Security—DRAFT 
25 
University Press, 1982, pp. 153–160. 
15 Daniel J. Kahneman, Jack L. Knetsch, and R.H. Thaler, “Experimental Tests of the Endowment Effect 
and the Coase Theorem,” Journal of Political Economy, 1990, 98: 1325–1348. 
16 Jack L. Knetsch, “Preferences and Nonreversibility of Indifference Curves,” Journal of Economic 
Behavior and Organization, 1992, 17: 131–139. 
17 Amos Tversky and Daniel Kahneman,  “Advances in Prospect Theory: Cumulative Representation of 
Subjective Uncertainty,” Journal of Risk and Uncertainty, 1992, 5:xx, 297–323. 
18 John Adams, “Cars, Cholera and Cows,” ((citation)). 
19 David L. Rosenhan and Samuel Messick, “Affect and Expectation,” Journal of Personality and Social 
Psychology, 1966, 3: 38–44. 
20 Neil D. Weinstein, “Unrealistic Optimism about Future Life Events,” Journal of Personality and Social 
Psychology, 1980, 39: 806–820. 
21 D. Kahneman, I. Ritov, and D. Schkade, “Economic preferences or attitude expressions?  An analysis of 
dollar responses to public issues,” Journal of Risk and Uncertainty, 1999, 19:220–242. 
22 P. Winkielman, R.B. Zajonc, and N. Schwarz, “Subliminal affective priming attributional interventions,” 
Cognition and Emotion, 1977, 11:4, 433–465. 
23 Daniel Gilbert, “If only gay sex caused global warming,” Los Angeles Times, July 2, 2006. 
24 Robyn S. Wilson and Joseph L. Arvai, “When Less is More: How Affect Influences Preferences When 
Comparing Low-risk and High-risk Options,” Journal of Risk Research, 2006, 9:2, 165–178. 
25 J. Cohen, The Privileged Ape: Cultural Capital in the Making of Man, Parthenon Publishing Group, 
1989. 
26 Paul Slovic, The Perception of Risk, Earthscan Publications Ltd, 2000. 
27 John Allen Paulos, Innumeracy: Mathematical Illiteracy and Its Consequences, Farrar, Straus, and 
Giroux, 1988. 
28 Amos Tversky and Daniel Kahneman, “Judgment under Uncertainty: Heuristics and Biases,” Science, 
1974, 185:1124–1130. 
29 Bruce Schneier, Beyond Fear: Thinking Sensibly About Security in an Uncertain World, Springer-
Verlag, 2003. 
30 Barry Glassner, The Culture of Fear: Why Americans are Afraid of the Wrong Things, Basic Books, 
1999. 
31 Amos Tversky and Daniel Kahneman, “Availability: A Heuristic for Judging Frequency,” Cognitive 
Psychology, 1973, 5:207–232. 
32 John S. Carroll, “The Effect of Imagining an Event on Expectations for the Event: An Interpretation in 
Terms of the Availability Heuristic,” Journal of Experimental Social Psychology, 1978, 14:88–96. 
33 Robert M. Reyes, William C. Thompson, and Gordon H. Bower, “Judgmental Biases Resulting from 
Differing Availabilities of Arguments,” Journal of Personality and Social Psychology, 1980, 39:2–12. 
34 S. Jim Sherman, Robert B. Cialdini, Donna F. Schwartzman, and Kim D. Reynolds, “Imagining Can 
Heighten or Lower the Perceived Likelihood of Contracting a Disease: The Mediating Effect of Ease of 
Imagery,” Personality and Social Psychology Bulletin, 1985, 11:118–127. 
35 C. K. Morewedge, D.T. Gilbert, and T.D. Wilson, “The Least Likely of Times: How Memory for Past 
Events Biases the Prediction of Future Events,” Psychological Science, 2005, 16:626–630. 
36 Cass R. Sunstein, “Terrorism and Probability Neglect,” Journal of Risk and Uncertainty, 2003, 
((volume and page numbers)). 
37 Scott Plous, The Psychology of Judgment and Decision Making, McGraw-Hill, 1993. 
The Psychology of Security—DRAFT 
26 
38 S.E. Taylor and S.T. Fiske, “Point of View and Perceptions of Causality,” Journal of Personality and 
Social Psychology, 1975, 32: 439–445. 
39 Paul Slovic, Baruch Fischhoff, and Sarah Lichtenstein, “Rating the Risks,” Environment, 1979, 2: 14–
20, 36–39. 
40 Amos Tversky and Daniel Kahneman, “Extensional vs Intuitive Reasoning: The Conjunction Fallacy in 
Probability Judgment,” Psychological Review, 1983, 90:??, 293–315. 
41 Amos Tversky and Daniel Kahneman, “Judgments of and by Representativeness,” in Daniel Kahneman, 
Paul Slovic, and Amos Tversky (eds.), Judgment Under Uncertainty: Heuristics and Biases, Cambridge 
University Press, 1982. 
42 Daniel Kahneman and Amos Tversky, “On the Psychology of Prediction,” Psychological Review, 1973, 
80: 237–251. 
43 Daniel Kahneman and S. Frederick, “Representativeness Revisited: Attribute Substitution in Intuitive 
Judgement,” in T. Gilovich, D. Griffin, and D. Kahneman (eds.), Heuristics and Biases, Cambridge 
University Press, 2002, pp. 49–81. 
44 Thomas Gilovich, Robert Vallone, and Amos Tversky, “The Hot Hand in Basketball: On the 
Misperception of Random Sequences,” Cognitive Psychology, 1985, 17: 295–314. 
45 Richard H. Thaler, “Toward a Positive Theory of Consumer Choice,” Journal of Economic Behavior and 
Organization, 1980, 1:39–60. 
46 Amos Tversky and Daniel Kahneman, “The Framing of Decisions and the Psychology of Choice,” 
Science, 1981, 211:253:258. 
47 Richard Thayer, “Mental Accounting Matters,” in Colin F. Camerer, George Loewenstein, and Matthew 
Rabin, eds., Advances in Behavioral Economics, Princeton University Press, 2004. 
48 Richard Thayer, “Mental Accounting and Consumer Choice,” Marketing Science, 1985, 4:199–214. 
49 Chip Heath and Jack B. Soll, “Mental Accounting and Consumer Decisions,” Journal of Consumer 
Research, 1996, 23:40–52. 
50 Muhtar Ali, “Probability and Utility Estimates for Racetrack Bettors,” Journal of Political Economy, 
1977, 85:803–815. 
51 Richard Thayer, “Some Empirical Evidence on Dynamic Inconsistency,” Economics Letters, 1981, 8: 
201–207. 
52 George Loewenstein and Drazen Prelec, “Anomalies in Intertemporal Choice: Evidence and 
Interpretation,” Quarterly Journal of Economics, 1992, 573–597. 
53 George Loewenstein, “Anticipation and the Valuation of Delayed Consumption,” Economy Journal, 
1987, 97: 666–684. 
54 Uri Benzion, Amnon Rapoport, and Joseph Yagel, “Discount Rates Inferred from Decisions: An 
Experimental Study,” Management Science, 1989, 35:270–284. 
55 Itamer Simonson, “The Effect of Purchase Quantity and Timing on Variety-Seeking Behavior,” Journal 
of Marketing Research, 1990, 17:150–162. 
56 Amos Tversky and Daniel Kahneman, “Judgment under Uncertainty: Heuristics and Biases,” Science, 
1974, 185: 1124–1131. 
57 Howard Schurman and Stanley Presser, Questions and Answers in Attitude Surveys: Experiments on 
Wording Form, Wording, and Context, Academic Press, 1981. 
58 Robert B. Cialdini, Influence: The Psychology of Persuasion, HarperCollins, 1998.