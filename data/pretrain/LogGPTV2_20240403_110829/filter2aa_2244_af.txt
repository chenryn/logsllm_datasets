### Understanding the Role of Heuristics and Biases in Security

It is often believed that anti-A evidence, in fact, supports a particular position. Numerous experiments have confirmed this fundamental bias and explored its complexities.

One key takeaway is that individual preferences are not based on predefined models that can be neatly represented by indifference curves, as described in microeconomics textbooks. Instead, these preferences are poorly defined, highly malleable, and strongly dependent on the context in which they are elicited. Heuristics and biases play a significant role in shaping these preferences.

This insight is particularly relevant to security because it highlights our inability to make rational security trade-offs, especially when influenced by ancillary information designed to persuade us one way or another.

### Making Sense of Security Perception

To better understand the perception of security, we must dissect the security trade-off and identify five areas where perception can diverge from reality:

1. **Severity of the Risk**: How severe the potential harm is.
2. **Probability of the Risk**: The likelihood of the risk occurring.
3. **Magnitude of the Costs**: The financial, time, or other costs associated with mitigating the risk.
4. **Effectiveness of the Countermeasure**: How well the countermeasure reduces the risk.
5. **The Trade-Off Itself**: The overall balance between the benefits and costs of the countermeasure.

In some cases, the divergence between perception and reality can be attributed to a lack of information. However, even when all the necessary information is available, individuals still make poor security trade-offs. This is due to the complex brain systems involved in making these decisions and how they can go awry.

### The Evolutionary Perspective

While we can make poor trade-offs in various contexts—such as predicting future snack preferences or determining a fair price for a cold beer—security trade-offs are particularly vulnerable to biases because they are critical to our survival. Our ancestors had to dodge predators and form social ties long before they could consider such trivial matters. As a result, our heuristics for dealing with security are deeply ingrained and well-worn, with the amygdala, an ancient part of the brain, playing a crucial role.

What is new from an evolutionary perspective is the large-scale human society, which introduces new security trade-offs. Technology and the media, for example, complicate these trade-offs by hiding detailed complexity and providing vivid, salient sensory input. The neocortex, the part of our brain responsible for making security trade-offs, is, as Daniel Gilbert puts it, "still in beta testing."

### Behavioral Economics and Neuroscience

My exploration of the literature in behavioral economics, the psychology of decision-making, the psychology of risk, and neuroscience has revealed a wealth of research and fascinating experiments that shed light on our brain's heuristics and biases. This understanding has made it clear why we frequently get security trade-offs wrong.

### The Dual Use of Research

Research on the psychology of security can be used for both good and evil. The positive use involves aligning people's feelings of security with the actual security. This means encouraging individuals to question their default behaviors. Simply providing more information is not the solution, as we are already overwhelmed with data. Instead, by understanding how our brains process risk and the heuristics and biases we use, we can learn to override our natural tendencies and make better security trade-offs. We can also learn to avoid being misled by security theater and help others do the same.

The negative use involves focusing on the feeling of security at the expense of reality. In his book *Influence*, Robert Cialdini explains that people cannot fully analyze every decision; they need heuristics to navigate life. Unscrupulous individuals, corporations, or governments can exploit these heuristics and biases to manipulate perceptions of risk and security. Concepts like prospect theory, framing, availability, representativeness, and affect are widely used in marketing and politics, and increasingly in security.

### A Third Way: Integrating Feeling and Reality

After extensive reading and writing, I believe that the positive use of this research is unrealistic, and the negative use is unacceptable. However, there is a third way: integrating the feeling and reality of security. These two aspects are different but closely related. We make the best security trade-offs—those that provide genuine security at a reasonable cost—when our feeling of security matches the reality.

For example, tamper-proof packaging on over-the-counter drugs, introduced in the 1980s after a few highly publicized poisonings, is a form of security theater. While it may not significantly reduce the risk, it brings people's perceptions of the risk more in line with the actual minimal risk. This change was worth it because it helped align perception with reality.

Of course, security theater comes with costs, such as money, time, capabilities, and freedoms. These costs often outweigh the benefits, and security theater is no substitute for real security. Moreover, too much security theater can raise people's feeling of security to a level greater than the reality, which is also problematic. However, when used in conjunction with real security, a bit of well-placed security theater might be exactly what we need to both feel and be more secure.

### References

1. Bruce Schneier, *Beyond Fear: Thinking Sensibly About Security in an Uncertain World*, Springer-Verlag, 2003.
2. David Ropeik and George Gray, *Risk: A Practical Guide for Deciding What’s Really Safe and What’s Really Dangerous in the World Around You*, Houghton Mifflin, 2002.
3. Barry Glassner, *The Culture of Fear: Why Americans are Afraid of the Wrong Things*, Basic Books, 1999.
4. Paul Slovic, *The Perception of Risk*, Earthscan Publications Ltd, 2000.
5. Daniel Gilbert, “If only gay sex caused global warming,” *Los Angeles Times*, July 2, 2006.
6. Jeffrey Kluger, “How Americans Are Living Dangerously,” *Time*, November 26, 2006.
7. Steven Johnson, *Mind Wide Open: Your Brain and the Neuroscience of Everyday Life*, Scribner, 2004.
8. Donald A. Norman, “Being Analog,” <http://www.jnd.org/dn.mss/being_analog.html>. Originally published as Chapter 7 of *The Invisible Computer*, MIT Press, 1998.
9. Daniel Kahneman, “A Perspective on Judgment and Choice,” *American Psychologist*, 2003, 58:9, 697–720.
10. Gerd Gigerenzer, Peter M. Todd, et al., *Simple Heuristics that Make us Smart*, Oxford University Press, 1999.
11. Daniel Kahneman and Amos Tversky, “Prospect Theory: An Analysis of Decision Under Risk,” *Econometrica*, 1979, 47:263–291.
12. Amos Tversky and Daniel Kahneman, “The Framing of Decisions and the Psychology of Choice,” *Science*, 1981, 211: 453–458.
13. Amos Tversky and Daniel Kahneman, “Evidential Impact of Base Rates,” in Daniel Kahneman, Paul Slovic, and Amos Tversky (eds.), *Judgment Under Uncertainty: Heuristics and Biases*, Cambridge University Press, 1982, pp. 153–160.
14. Daniel J. Kahneman, Jack L. Knetsch, and R.H. Thaler, “Experimental Tests of the Endowment Effect and the Coase Theorem,” *Journal of Political Economy*, 1990, 98: 1325–1348.
15. Jack L. Knetsch, “Preferences and Nonreversibility of Indifference Curves,” *Journal of Economic Behavior and Organization*, 1992, 17: 131–139.
16. Amos Tversky and Daniel Kahneman, “Advances in Prospect Theory: Cumulative Representation of Subjective Uncertainty,” *Journal of Risk and Uncertainty*, 1992, 5:xx, 297–323.
17. John Adams, “Cars, Cholera and Cows,” ((citation)).
18. David L. Rosenhan and Samuel Messick, “Affect and Expectation,” *Journal of Personality and Social Psychology*, 1966, 3: 38–44.
19. Neil D. Weinstein, “Unrealistic Optimism about Future Life Events,” *Journal of Personality and Social Psychology*, 1980, 39: 806–820.
20. D. Kahneman, I. Ritov, and D. Schkade, “Economic preferences or attitude expressions? An analysis of dollar responses to public issues,” *Journal of Risk and Uncertainty*, 1999, 19:220–242.
21. P. Winkielman, R.B. Zajonc, and N. Schwarz, “Subliminal affective priming attributional interventions,” *Cognition and Emotion*, 1977, 11:4, 433–465.
22. Robyn S. Wilson and Joseph L. Arvai, “When Less is More: How Affect Influences Preferences When Comparing Low-risk and High-risk Options,” *Journal of Risk Research*, 2006, 9:2, 165–178.
23. J. Cohen, *The Privileged Ape: Cultural Capital in the Making of Man*, Parthenon Publishing Group, 1989.
24. Paul Slovic, *The Perception of Risk*, Earthscan Publications Ltd, 2000.
25. John Allen Paulos, *Innumeracy: Mathematical Illiteracy and Its Consequences*, Farrar, Straus, and Giroux, 1988.
26. Amos Tversky and Daniel Kahneman, “Judgment under Uncertainty: Heuristics and Biases,” *Science*, 1974, 185:1124–1130.
27. Bruce Schneier, *Beyond Fear: Thinking Sensibly About Security in an Uncertain World*, Springer-Verlag, 2003.
28. Barry Glassner, *The Culture of Fear: Why Americans are Afraid of the Wrong Things*, Basic Books, 1999.
29. Amos Tversky and Daniel Kahneman, “Availability: A Heuristic for Judging Frequency,” *Cognitive Psychology*, 1973, 5:207–232.
30. John S. Carroll, “The Effect of Imagining an Event on Expectations for the Event: An Interpretation in Terms of the Availability Heuristic,” *Journal of Experimental Social Psychology*, 1978, 14:88–96.
31. Robert M. Reyes, William C. Thompson, and Gordon H. Bower, “Judgmental Biases Resulting from Differing Availabilities of Arguments,” *Journal of Personality and Social Psychology*, 1980, 39:2–12.
32. S. Jim Sherman, Robert B. Cialdini, Donna F. Schwartzman, and Kim D. Reynolds, “Imagining Can Heighten or Lower the Perceived Likelihood of Contracting a Disease: The Mediating Effect of Ease of Imagery,” *Personality and Social Psychology Bulletin*, 1985, 11:118–127.
33. C. K. Morewedge, D.T. Gilbert, and T.D. Wilson, “The Least Likely of Times: How Memory for Past Events Biases the Prediction of Future Events,” *Psychological Science*, 2005, 16:626–630.
34. Cass R. Sunstein, “Terrorism and Probability Neglect,” *Journal of Risk and Uncertainty*, 2003, ((volume and page numbers)).
35. Scott Plous, *The Psychology of Judgment and Decision Making*, McGraw-Hill, 1993.
36. S.E. Taylor and S.T. Fiske, “Point of View and Perceptions of Causality,” *Journal of Personality and Social Psychology*, 1975, 32: 439–445.
37. Paul Slovic, Baruch Fischhoff, and Sarah Lichtenstein, “Rating the Risks,” *Environment*, 1979, 2: 14–20, 36–39.
38. Amos Tversky and Daniel Kahneman, “Extensional vs Intuitive Reasoning: The Conjunction Fallacy in Probability Judgment,” *Psychological Review*, 1983, 90:??, 293–315.
39. Amos Tversky and Daniel Kahneman, “Judgments of and by Representativeness,” in Daniel Kahneman, Paul Slovic, and Amos Tversky (eds.), *Judgment Under Uncertainty: Heuristics and Biases*, Cambridge University Press, 1982.
40. Daniel Kahneman and Amos Tversky, “On the Psychology of Prediction,” *Psychological Review*, 1973, 80: 237–251.
41. Daniel Kahneman and S. Frederick, “Representativeness Revisited: Attribute Substitution in Intuitive Judgement,” in T. Gilovich, D. Griffin, and D. Kahneman (eds.), *Heuristics and Biases*, Cambridge University Press, 2002, pp. 49–81.
42. Thomas Gilovich, Robert Vallone, and Amos Tversky, “The Hot Hand in Basketball: On the Misperception of Random Sequences,” *Cognitive Psychology*, 1985, 17: 295–314.
43. Richard H. Thaler, “Toward a Positive Theory of Consumer Choice,” *Journal of Economic Behavior and Organization*, 1980, 1:39–60.
44. Amos Tversky and Daniel Kahneman, “The Framing of Decisions and the Psychology of Choice,” *Science*, 1981, 211:253:258.
45. Richard Thayer, “Mental Accounting Matters,” in Colin F. Camerer, George Loewenstein, and Matthew Rabin, eds., *Advances in Behavioral Economics*, Princeton University Press, 2004.
46. Richard Thayer, “Mental Accounting and Consumer Choice,” *Marketing Science*, 1985, 4:199–214.
47. Chip Heath and Jack B. Soll, “Mental Accounting and Consumer Decisions,” *Journal of Consumer Research*, 1996, 23:40–52.
48. Muhtar Ali, “Probability and Utility Estimates for Racetrack Bettors,” *Journal of Political Economy*, 1977, 85:803–815.
49. Richard Thayer, “Some Empirical Evidence on Dynamic Inconsistency,” *Economics Letters*, 1981, 8: 201–207.
50. George Loewenstein and Drazen Prelec, “Anomalies in Intertemporal Choice: Evidence and Interpretation,” *Quarterly Journal of Economics*, 1992, 573–597.
51. George Loewenstein, “Anticipation and the Valuation of Delayed Consumption,” *Economy Journal*, 1987, 97: 666–684.
52. Uri Benzion, Amnon Rapoport, and Joseph Yagel, “Discount Rates Inferred from Decisions: An Experimental Study,” *Management Science*, 1989, 35:270–284.
53. Itamar Simonson, “The Effect of Purchase Quantity and Timing on Variety-Seeking Behavior,” *Journal of Marketing Research*, 1990, 17:150–162.
54. Amos Tversky and Daniel Kahneman, “Judgment under Uncertainty: Heuristics and Biases,” *Science*, 1974, 185: 1124–1131.
55. Howard Schurman and Stanley Presser, *Questions and Answers in Attitude Surveys: Experiments on Wording Form, Wording, and Context*, Academic Press, 1981.
56. Robert B. Cialdini, *Influence: The Psychology of Persuasion*, HarperCollins, 1998.