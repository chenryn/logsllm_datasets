User: I am working on a project which uses text files (.txt) for input, reading them line by line but this files can go as large as 1 terabytes. I know some languages/technologies which I used for similar problems, those are Java, Bash, Awk, and Python. But I don't know which one can work with such large file, and what kind on tricks and tweaks will be needed.
Assistant: As long as you process your file line by line and you assemble some statistics, it doesn't really matter what tool you choose. 
Java has some advantage in terms of speed, compared to scripting languages, but in the end it will be a difference only by a constant factor. What matters the most is the algorithm that you use to process the file.