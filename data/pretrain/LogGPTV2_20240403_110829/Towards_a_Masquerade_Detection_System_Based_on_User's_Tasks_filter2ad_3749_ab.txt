WUIL contains a heterogeneous mixture of users with diﬀerent backgrounds,
including students, senior managers, and departmental secretaries. We asked
Towards a Masquerade Detection System Based on User’s Tasks
453
every user to ﬁll in a survey with the aim of obtaining standard personal infor-
mation like age, gender, and level of education. However, through this survey, we
also collected subjective information, such as how skillful a user reckons herself
about OS conﬁguration, or how tidy she considers her personal ﬁle system to
be and why. Overall, our aim is to research whether there exist certain kinds
of users who are easier to protect from being harmed than others (we will have
more to say on this later on in the text, cf. §6.)
WUIL Masquerade Logs. What makes WUIL most distinctive is that it
contains close to real masquerade attempts. This is in contrast with existing
masquerade datasets that use an OVTO approach, raising the concern as to what
a given MDS actually achieves. This is because the ‘intruder’ has no intention
to commit any intrusion, so any result is about the strength of the MDS as a
classiﬁer, but not as to how good it is at the masquerade detection problem.
By contrast, WUIL enables the study of a very speciﬁc intrusion scenario,
namely: the access to a computer session that has been carelessly left unattended
(which, in principle, is similar to a remote connection via privilege escalation).
Accordingly, WUIL includes simulated masqueraders that are limited to be ﬁve
minute long.
For each user, WUIL includes logs taken from the simulation of three diﬀerent
kinds of masqueraders: basic, intermediate, and advanced. In the basic attack,
the masquerader has an occasional opportunity of using the victim computer;
thus, he is not prepared for conducting the attack, lacking from any special
tool or auxiliary equipment. In the intermediate attack, the masquerader aims
at doing the attack, so he brings in an USB ﬂash drive, but he has to manu-
ally gather whatever he reckons interesting, collecting everything into the USB
ﬂash memory. Finally, in the advanced attack, not only does the (more skillful)
masquerader bring in a USB ﬂash memory, but he also executes a script, which
automatically extracts every ﬁle baptized with an interesting name (password,
bank, personal, etc.), and attempts to take oﬀ any intrusion track. We remark
that each of these simulated attacks have all been conducted in the user PC.
The WUIL masquerade attacks are both short and speciﬁc, yielding class un-
balance (there are fewer attack sessions per user). Further, in the FS navigation
approach, it is more diﬃcult to synthesize an attack. As a machine ﬁle sys-
tem changes, so should the masquerade detection model, yielding maintenance
workload.
Currently, WUIL is under improvement, in order to include more users, with
a focus on users running MS Windows 8 (in order to have a more up to date
MS windows version repertoire). In the next section, §3.2, we shall explain the
concept of task we are using and the way we processed WUIL to get the log’s
based on tasks accesses instead of objects accesses.
3.2 Task Abstraction
In an ideal setting, each user should deﬁne her own tasks, associating each of
which to a speciﬁc directory in her ﬁle system. In WUIL, however, user logs do
454
J.B. Cami˜na, J.Rodr´ıguez, and R. Monroy
Fig. 1. A typical directory tree structure organized into tasks and supertasks, consid-
ering a depth cut point equal to four
not come with such information. Thus, we had to ﬁnd a way to emulate this user
deﬁnition. The rational behind our approach to such approximation is that we
conjecture that user tasks are all at the same depth regarding the user FS tree
directory. Thus, we only need to ﬁnd out such depth, we call depth cut point.
Depth Cut Point. To approximate a depth cut point (DCP), we conducted
sort of a backwards breadth-ﬁrst search analysis about user task access rate.
Our analysis makes three considerations. First, the resulting number of tasks
should not exceed 100, as it would be odd for one to have 100 diﬀerent roles.
Second, the DCP should not be deeper than 10, because it would be odd for
one to work that deep in the directory tree structure. And third, when searching
upwards, we should not pass depth four, as that is the standard depth for both
FS directories Desktop and My Documents (assumed to be the user working
directories). Then, our procedure is as follows. Take a user. Set current depth
to be the median of the user depth object access; if greater than 10, set current
depth to 10. For each iteration, if current depth is greater than 4 and if the user
task rate underneath current depth is less than 70%, decrement current depth
and repeat. Otherwise, stop, yielding current depth. Set every directory above a
user’s DCP into a diﬀerent task, we call a super-task, cf. Fig. 1.
Having identiﬁed a DCP, we mapped every WUIL log, both user and attack,
from object access to its corresponding task access. This resulted in two sepa-
rate sets, which were then used for both development and validation purposes.
Tables 1 and 2 respectively show the DCP for each user, and contrast the num-
ber of diﬀerent objects against that of diﬀerent tasks, on a per user basis. From
these tables, we observe both that the DCP often is ﬁve or six, and that the
number of tasks per user is much fewer of that of objects. Looking more closely
Towards a Masquerade Detection System Based on User’s Tasks
455
Table 1. Users’ depth cut point, as found experimentally
User 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20
DCP 5 5 5 5 5 6 6 6 6 5 3 5 3 5 5 6 6 5 5 5
Table 2. A comparison of the number of diﬀerent objects against that of diﬀerent
tasks, per user
User Number of Objects Number of Tasks
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
Average
7886
1672
200
2555
40776
6642
9149
877
10321
655
3524
5616
151477
1809
4925
25718
7370
1385
620
1407
14229
12
14
13
61
60
69
28
9
49
8
377
31
64
15
50
39
86
9
9
26
51
into these tables, we may notice that user 11 has a distinctively large number
of tasks, 377, and that she has a DCP of three. This is because this user has
a number of physical drive units, and, spreads her ﬁle system structure among
them all. This actually makes it more diﬃcult to protect her. We shall more to
say on this and other limitations on our task-based abstraction below (see §5).
Below, §4, we shall describe the experiments that we have conducted to assess
our working hypothesis, namely: that the performance of a task-based MDS is
comparable to an object-based one.
4 Tasks vs Objects: An Experimental Comparison
With the aim of comparing the masquerade detection performance of a task-
based model against an object-based one, we ran an experiment using two dif-
ferent classiﬁers: Markov chains and Na¨ıve Bayes. The rationale behind the se-
lection of these techniques is twofold. First, both techniques are suitable as a
one-class classiﬁer, as required in our problem setting. Second, they are comple-
mentary in that while Na¨ıve Bayes commonly used for a bag of words model,
where only the frequency of an event matters, Markov chain is used for an event
sequence model, where each event depends on past events, accounting for tem-
poral dependencies.
456
J.B. Cami˜na, J.Rodr´ıguez, and R. Monroy
Table 3. Outputs used for assessing classiﬁer performance
Window type Classiﬁer output
Assessment
User
User
User
Masquerader
Masquerader
Masquerader Masquerader
User
True Negative (TN)
False Positive (FP)
False Negative (FN)
True Positive (TP)
Rounding oﬀ, our experiment forms a 2 × 2-matrix, involving an event class
(task/object) and a classiﬁer (Markov chain/Na¨ıve Bayes). Each test was carried
out on a per user basis.
4.1 Experiment Design
There are some parameters that need to be set before starting an experimenta-
tion. These parameters must be similar in all the experiments in order to make
the results comparable. We explain each in turn below.
Construction and Validation Sets. For each user experiment we split the
associated WUIL logs in two diﬀerent sets: construction and validation. The
construction set is composed with a certain percentage of the user log (ordinary
behavior) and is used to create and train the classiﬁer. The validation set consists
of the remaining percentage of the user log, together with the full set of that
user masquerade attacks, and is used to yield a classiﬁcation performance.
For each experiment, we split the user log using diﬀerent percentages for both
sets, construction and validation, namely: 80-20, 70-30, 50-50, 30-70, and 20-80.
The rationale behind this setting decision was studying how much information
is needed to start having similar results, and how these proportions aﬀect the
performance of each classiﬁer. We also conducted a ﬁve-fold cross-validation for
the particular experiment that yielded the best classiﬁcation result.
A Window-Based Analysis. We have divided every user validation set, whether
task-based or object-based, using a windowing approach. We set both the window
size and the window step to be 20. Windows are not mixed; they are ﬁlled in ei-
ther with user events, or masquerader ones. Each time a window is analyzed, the
classiﬁer emits an evaluation, which might be correct, or not, yielding diﬀerent as-
sessments as shown in Table 3.
Threshold. To emit an evaluation, the classiﬁer compares a window score
against a threshold. A window is classiﬁed as masquerade, if the window score
is greater than or equal to the threshold, and normal, otherwise. We vary the
threshold to study the performance of a classiﬁer, thereby drawing a so-called
Receiver Operating Characteristic (ROC) curve. So, we start with a very low
threshold, getting a lax classiﬁer; then, we increase the threshold slowly until
we get a very strict one. Doing so, we have got results from 100% False Positive
(FP) with 0% False Negative (FN), to 0% FP with 100% FN, and with this
information we identify the minimum misclassiﬁcation point for each user (see
section §5).
Towards a Masquerade Detection System Based on User’s Tasks
457
4.2 Markov Chains
For implementing a Markov chain-based MDS, we have followed the work of
Maxion et al. [21]. In a Markov chain, each state comprehends a sequence of
events (objects or tasks, in our case). Each event sequence is called an n-gram. N-
grams are all the same size. A Markov chain is used to assess whether a sequence
of state transitions conforms to a model (the user behavior, in our case). Notice
how a Markov chain captures both event frequency (via a state transition) and
event dependency (via the elements of an n-gram). For a correct operation, the
Markov chain parameters must be tuned. We explain each of them, and how to
ﬁx them, below.
A User Log Is a Trace Sequence. For the construction and validation of
a Markov chain model, we require a number of event sequences, each of which
is called a trace. So, we split a user log into traces. We set a trace to include
entries recording the activity of a calendar day. Whenever a user worked after
midnight, we keep the next day events still as part of the current trace. To mark
the end and the beginning of two adjacent traces, we have speciﬁed an idle time
of at least two hours. Each masquerade attempt is an independent trace. Each
trace is either construction, or validation, but not both. Every validation trace
is divided into windows.
N-gram Size. To ﬁx the size of the n-gram, we have used divergence [21], which
measures how diﬀerent an attack and a Markov chain model are. The more they
diverge, the better the model is to detect an attack. We proceeded as follows.
First, we randomly picked ﬁve pairs: user and attack. Then, working on one pair
at a time, we initialized the n-gram size to one, and loop till 20, with increments
of size one, in order to determine the n-gram size yielding maximum divergence.
Finally, we set the n-gram size to be the average of all these values. It should
be noticed, however, that for object-based masquerade detection, our computer
(see below) was unable to handle models with n-grams greater than ﬁve, and,
so for those we put a cap on size to that value.
Penalization. Penalization, Z, is the amount of bad points added to the score
of a model, whenever that model does not involve a given state transition. In
our case, following some experimentation, we ﬁxed the penalization to be ﬁve.
Having set these parameters, we have built every Markov chain model as
follows. Take a user trace. Create a new state; set it to be the current state and
label it with an n-gram ﬁlled in with null events. Then, inspect the trace, from
left to right, and, event by event, proceed as follows. Take the n-gram of the
current state label, then remove the ﬁrst event of that n-gram and append the
current trace event. If there is not a state labeled with the resulting n-gram,
create one, and then join the current state and the new state with a transition.
Then, update the distribution probability of the state transition model, set the
current state to be the new state with the resulting n-gram, and iterate this
process as many times as the length of the current trace, creating and updating
458
J.B. Cami˜na, J.Rodr´ıguez, and R. Monroy
states and state transitions as required. This procedure is then repeated for every
user trace, using the same Markov chain model.
Also following [21], we use each Markov chain model to classify every user