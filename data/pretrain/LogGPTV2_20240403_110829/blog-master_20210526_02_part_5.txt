- 藏起来  
- 细粒度权限控制 
参考:  
[《重新发现PostgreSQL之美 - 39 谁动了我的奶酪》](../202107/20210706_01.md)    
视频回放: https://www.bilibili.com/video/BV17M4y1M7Zk/    
#### 40、重新发现PostgreSQL之美 - 40 雪崩, 压死骆驼的最后一根稻草
场景:
- 高峰期出现慢SQL, 资源打满(cpu、内存、IO、连接数等), 引起雪崩
- 热表的DDL大锁进入队列中, 可能因为其他长事务的锁和这个大锁冲突, 引起等待, 导致连接数打满, 引起雪崩
挑战:
- 雪崩时业务完全受损, 无一幸免
PG解决方案:
1、各种超时参数.
- deadlock_timeout, 解决死锁造成的死等
- idle_in_transaction_session_timeout, 解决堵塞DDL的小锁长事务引起的雪崩问题
- lock_timeout, 解决DDL死等引起雪崩
- statement_timeout, 解决慢SQL堆积导致的雪崩
2、可编程: 钩子, SQL 限流
Executor Hooks
- ExecutorStart_hook — called at the beginning of any execution of any query plan.
- ExecutorRun_hook — called at any plan execution, after ExecutorStart.
- ExecutorFinish_hook — called after the last ExecutorRun call
- ExecutorEnd_hook — called at the end of execution of any query plan.
- ProcessUtility_hook — hook for the ProcessUtility.
参考:
[《PostgreSQL hook & callback》](../202107/20210708_04.md)
视频回放: https://www.bilibili.com/video/BV1z44y1q7sb/  
#### 41、重新发现PostgreSQL之美 - 41 小结巴,语言处理  
场景:    
- 短文本(评论、客服交互、弹幕等)字符串清洗    
挑战:    
- 语言字符处理逻辑复杂, 例如常见的词组重复、字符重复要求去除, 数字可能重复但是又不能去除    
PG解决方案    
- 正则表达式, 快速清洗数据    
[《PostgreSQL 正则表达式 短文本清洗, 去除重复字符》](../202107/20210709_02.md)    
视频回放: https://www.bilibili.com/video/BV11q4y1p7m1/    
#### 42、重新发现PostgreSQL之美 - 42 精准营销之减负  
场景:    
- 精准营销场景, 判断某个标签里面是否包含当前的用户ID  
挑战:    
- 一个标签里面有很多UID, 例如年龄段标签, 可能包含上亿的UID, 造成大量的memory copy, 同时匹配计算时的运算量增加  
- 展开来存储KV的话, 查询某个用户有哪些标签是快了, 但是会带来指数级的记录数增加, 存储空间撑爆   
PG解决方案:    
- 使用roaringbitmap存储UIDs, 同时把每个标签组按UID进行哈希取模分片, 降低每次用户ID包含计算的运算量和memory copy量.  
    - 性能得到量级提升  
[《实时营销, 人群圈选推荐业务 性能优化 - memory copy+rb contains计算瓶颈 - rb hash分片》](../202107/20210709_01.md)    
视频回放: https://www.bilibili.com/video/BV1xh41167uN/  
#### 43、重新发现PostgreSQL之美 - 43 快速破镜重圆
场景:
- standby 临时开启读写后继续成为standby.
- standby 激活时老主库没有完全同步, 希望老的primary可以变成新主库的standby.
挑战:
- 传统方式, 需要重新拷贝整个数据库, 重建standby. 速度慢, 对当前主库的IO、网络冲击很大.
- 采用rsync的方式, 需要比对所有的数据文件, 找到变化的文件, 即使只是少量的字节变化也需要同步整个文件. 速度慢, 对当前主库的IO冲击很大.
PG解决方案:
- pg_rewind, 支持在线修复分裂, 只需解析并同步自分裂点以来老库的变化blocks. 速度快、对当前主库的IO、网络影响小.
参考: [《重新发现PostgreSQL之美 - 43 快速破镜重圆》](../202107/20210712_01.md)   
视频回放: https://www.bilibili.com/video/BV1zL411H7Z9/  
#### 44、重新发现PostgreSQL之美 - 44 摩斯电码
场景:  
某些字段的值经过计算后再过滤的场景, 例如:  
json里面的内容包含经纬度, 我们需要对经纬度进行地理信息空间查询过滤.  
a,b,c,d分别代表语、数、英、科的分数, 查询总分等于或范围时, 需要计算后再搜索.  
挑战:  
大多数数据库无法使用表达式索引, 只能全表扫描, 逐条计算. 效率低下.  
PG解决方案:  
支持表达式索引(也可以叫函数索引), 性能指数级提升.  
支持表达式统计信息柱状图, 用于优化器计算  
参考: [《重新发现PostgreSQL之美 - 44 摩斯电码》](../202107/20210715_05.md)   
视频回放: https://www.bilibili.com/video/BV1kB4y1N7LT/  
#### 45、重新发现PostgreSQL之美 - 45 个性化  
场景:  
- 业务场景越来越丰富, 但是传统数据库只提供单方面能力, 无法定制化, 仅有一些场景市场空间足够大的时候, 有一些垂直领域的数据库冒出来(例如搜索、图、时序、向量等), 用户需要采用多个种类的DB(关系、图、搜索、推荐、分析等)。   
挑战:  
- 数据需要多份冗余、同步延迟高、数据一致性难以保证、开发、维护成本高 诸多问题.   
- 跨产品的功能很难对齐, 如租户隔离功能, 很难要求所有种类的数据库都有租户隔离能力.   
- 跨数据库产品的类型、功能无法对齐.   
PG解决方案:  
- RDS PG采用模块化设计, 可以针对不同业务场景进行深度优化, 通过对业务需求的深度挖掘, 开发出精准匹配业务的“数据类型、存储和索引结构、操作符与函数”。  
- 相比传统方案性能提升数十倍甚至上万倍. (实时精准营销、分词、全模糊查询、向量相似检索)  
- 同时由于使用同一份数据, 大幅度降低开发、运维、产品成本, 避免同步、一致性等问题.  
[《为什么PG可以模块化堆叠新功能》](../202005/20200527_06.md)      
[《PG模块化功能案例》](../202005/20200527_06.md)      
视频回放: https://www.bilibili.com/video/BV1QU4y1n7ve/  
#### 46、重新发现PostgreSQL之美 - 46 既要又要还要
场景:  
- 实时分析行业SaaS, 低代码场景满足客户个性化分析的诉求.   
- 单个用户的数据总量T级别.   
- 业务数据需要实时写入.   
- 用户分析师拖拽式试错, 产生合理的分析模板. 结果则需要实时高并发查询(例如为不通属性用户定制的动态页面, 需要实时识别用户的属性(即分析结果)), 结果还有二次分析诉求.   
挑战:   
- 既要又要还要:   
    - 用户拖拽式试错, 需要实时分析计算能力.   
    - 分析框架固定后, 需要实时查询, 结果有高并发诉求.   
    - 业务数据实时写入, 用业务+大数据库成本高, 同步延迟高、一致性等问题突出.  
    - 单个用户的数据总量T级别, 不大不小. 用大数据成本高.   
    - 如果拖拽后的固定结果使用普通视图, 那么它只是SQL语句, 不存储结果数据, 也无法支持索引, 查询视图时耗费计算, 效率低, 无法支持高并发.   
    - 如果存储结果, 那么对于采用逻辑复制的数据库, 需要等事务结束客户端才能apply事务, 只读实例延迟高. 物化视图刷新是大事务, 因此这种场景无法通过只读实例扩展性能.   
PG解决方案:   
- 并行计算+JIT满足TB级别拖拽式实时分析需求.  
- 物化视图, 已经算好, 查询效率高.   
- 支持在物化视图上创建索引, 效率高.   
- 定时任务增量刷新物化视图, 可以反映基表变更实时信息.   
- 流复制只读实例, 流式复制, 不需要等事务结束, 解决只读实例延迟高问题.   
- 支持物化视图与基表采用不一致的存储引擎, 例如基表要高并发dml使用行存储, 物化视图如果要大量二次分析可以使用列存储. 使得可以适合最好的效率.   
视频回放: https://www.bilibili.com/video/BV1oM4y1P7QT/    
#### 47、重新发现PostgreSQL之美 - 47 为什么脑容量更大的尼安德特人会被现代智人消灭?     
场景:  
在不同的场合需要的功能也是不一样的, 例如全文检索要的是分词和倒排索引, 空间搜索要的是空间索引, 图式关系查询需要递归. 高并发的点查要的是行存储, 而大范围的分析要的是列存储和并行计算.   
挑战:  
大多数的数据库都只做单项冠军, 综合能力差.   
PG解决方案:  
table access method, 可扩展的数据存储结构.   
- 列存储, 解决大范围的分析导致的IO和计算瓶颈.  
- lsmtree, 解决高速写入时索引更新增加RT导致的写入吞吐瓶颈.  
- heap, 解决高速写入, 高并发查询OLTP业务的性能问题.  
- zedstore 行列混合存储, 解决OLTP OLAP混合场景性能问题.  
- zheap undo多版本控制, 解决高频率更新导致的膨胀问题.  
- 索引组织表, 解决PKV搜索IO多跳瓶颈.   
index access method, 可扩展的索引存储结构.  
- btree  
- hash, 解决大字段点查,btree的空间占用瓶颈或大字段超出btree page1/3的错误问题  
- bitmap, 基于标签的少量条件大量记录聚合查询的精准营销场景性能问题  
- GIN, 提高数组元素搜索、JSON元素搜索、全文检索、模糊查询性能.  
- SP_GIST、GIST, 提高空间搜索、range搜索、JSON查询性能.  
- BRIN, 时序数据索引, 解决引入的索引空间占用大, RT增加的性能问题  
- BLOOM, 解决分析场景, 任意字段搜索时的索引空间占用大, RT增加的性能问题  
如果以上表或索引的存储结构还不能满足你的需求, PG还能自定义的表和索引接口  
使用PG可以因时因地置宜的选择最好的存储结构、索引结构.  
视频回放: https://www.bilibili.com/video/BV1Hq4y1p7Ai/    
#### 48、重新发现PostgreSQL之美 - 48 聚合、窗口过滤 
场景:
- 聚合查询、窗口查询时, 对聚合的内容或窗口的内容本身有过滤条件诉求.
    - 如: 每个分组排除噪点后的方差
    - 某些分组排除噪点后的方差
挑战:
- 传统的方法需要使用 case when 来进行过滤, 然而对于有上下文相关的记录使用case when无法支持, 例如求标准方差、平均值等需要收敛到子
集空间进行计算时, case when结果不一致.
- 传统方法需要扫描多遍table