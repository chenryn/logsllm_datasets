### 5.2 Conversion Pipeline Metrics

The number of visits (D) is defined as the number of accesses to our emulated pharmacy and postcard sites, excluding any crawlers as determined using the methods outlined in Section 4.2. It is important to note that crawler requests, though originating from a small fraction of hosts, accounted for the majority of all requests to our Web sites. For example, out of the 11,720 unique IP addresses accessing the pharmacy site with a valid unique identifier, only 10.2% were blacklisted as crawlers. However, 55.3% of all unique identifiers used in requests originated from these crawlers. Furthermore, 87.43% of all non-image requests made to the site were made by blacklisted IP addresses.

The number of conversions (E) is the number of visits to the purchase page of the pharmacy site or the number of executions of the fake self-propagation program.

Our results from Storm spam campaigns indicate a very low conversion rate. For instance, out of 350 million pharmacy campaign emails, only 28 conversions resulted. Notably, no crawler ever completed a purchase, so errors in crawler filtering did not affect this result. Despite the low conversion rate, it does not necessarily imply low revenue or profitability. The implications of the conversion rate on the spam conversion proposition are discussed further in Section 8.

### 5.3 Time to Click

The conversion pipeline shows the fraction of spam that ultimately resulted in visits to the advertised sites. However, it does not reflect the latency between when the spam was sent and when a user clicked on it. The longer it takes users to act, the longer the scam hosting infrastructure will need to remain available to extract revenue from the spam. In other words, how long does a spam-advertised site need to be available to collect its potential revenue?

**Figure 7: Time-to-click distributions for accesses to the pharmacy site.**

Figure 7 illustrates the cumulative distribution of the "time-to-click" for accesses to the pharmacy site. The time-to-click is the duration from when spam is sent (when a proxy forwards a spam workload to a worker bot) to when a user clicks on the URL in the spam (when a host first accesses the Web site). The graph displays three distributions: for all users, the users who visited the purchase page ("converters"), and the automated crawlers (14,716 such accesses).

The user and crawler distributions exhibit distinctly different behaviors. Almost 30% of the crawler accesses occur within 20 seconds of worker bots sending spam, suggesting that these crawlers are configured to scan sites advertised in spam immediately upon delivery. Another 10% of crawler accesses have a time-to-click of 1 day, indicating periodic batch access. In contrast, only 10% of the user population accesses spam URLs immediately, with the remaining distribution being smooth without distinct modes. The distributions for all users and users who "convert" are roughly similar, suggesting little correlation between time-to-click and whether a user visiting a site will convert. While most user visits occur within the first 24 hours, 10% of times-to-click range from a week to a month, indicating that advertised sites need to be available for long durations to capture full revenue potential.

### 6. Effects of Blacklisting

A significant factor affecting the efficacy of spam delivery is the use of address-based blacklisting by numerous ISPs to reject email from hosts previously reported as spam sources. To assess the impact of blacklisting, we monitored the Composite Blocking List (CBL) [1], a widely used blacklist, from March 21 to April 2, 2008, covering the Pharmacy and April Fool campaigns.

**Figure 8: Change in per-domain delivery rates before (x-axis) and after (y-axis) a worker bot appears in the blacklist. Each circle represents a domain targeted by at least 1,000 analyzable deliveries, with the radius scaled in proportion to the number of delivery attempts.**

Of the 40,864 workers that sent delivery reports, 81% appeared on the CBL. Of those appearing on the list, 77% were listed before we observed their receipt of spamming directives, with a median listing 4.4 days earlier. For those not initially listed but subsequently listed, the median interval until listing was 1.5 hours, strongly suggesting that the spamming activity quickly led to detection and blacklisting.

From the plot, we observe a range of blacklisting behaviors by different domains. Some employ effective anti-spam filtering, indicated by their appearance near the originâ€”spam did not get through even prior to appearing on the CBL. Others make heavy use of the CBL or similar lists, shown by their y-axis values near zero. Points predominantly below the diagonal suggest that blacklisting or other effects related to sustained spamming activity (e.g., learning content signatures) diminish the delivery rate at most domains. Delisting followed by relisting may account for some of the spread of points; those few points above the diagonal may be due to statistical fluctuations. The cloud of points to the upper right indicates a large number of domains that, individually, are not much targeted but collectively form a significant population that appears to employ no effective anti-spam measures.

### 7. Conversion Analysis

We now examine possible factors influencing responses to spam, focusing on coarse-grained effects.

**Figure 9: Geographic locations of the hosts that "convert" on spam: the 541 hosts that execute the emulated self-propagation program (light grey), and the 28 hosts that visit the purchase page of the emulated pharmacy site (black).**

Figure 9 maps the geographic distribution of the hosts that "convert" on the spam campaigns we monitored. The map shows that users around the world respond to spam.

**Figure 10: Response rates (stage D in the pipeline) by TLD for executable download (x-axis) vs. pharmacy visits (y-axis).**

Figure 10 examines differences in response rates among nations, determined by prevalent country-code email domain TLDs. For each email address, we consider it a member of the country hosting its mail server, removing domains that resolve to multiple countries and categorizing them as "international" domains. The x-axis shows the volume of email (log-scaled) targeting a given country, while the y-axis gives the number of responses recorded at our Web servers (also log-scaled), corresponding to Stages A and D in the pipeline (Figure 6). The solid line reflects a response rate of 10^-4, and the dashed line a rate of 10^-3. Unsurprisingly, spam campaigns target email addresses in the United States substantially more than any other country. India, Japan, and the United States dominate responses. In terms of response rates, however, India, Pakistan, and Bulgaria have the highest response rates, while the United States, despite being a dominant target and responder, has the lowest resulting response rate, followed by Japan and Taiwan.

**Figure 11: Response rates (stage D in the pipeline) by TLD for executable download (x-axis) vs. pharmacy visits (y-axis).**

Figure 11 plots the rates for the most prominent countries responding to self-propagation vs. pharmacy spams. The median ratio between these two rates is 0.38 (diagonal line). We see that India and Pakistan exhibit almost exactly this ratio (upper-right corner), and Bulgaria is not far from it. Only a few TLDs exhibit significantly different ratios, including the US and France. Users in the US respond to self-propagation spam substantially more than pharmaceutical spam, and vice versa with users in France. These results suggest that, for the most part, per-country differences in response rate are due to structural causes (quality of spam filtering, general user anti-spam education) rather than differing degrees of cultural or national interest in the specific promises or products conveyed by the spam.