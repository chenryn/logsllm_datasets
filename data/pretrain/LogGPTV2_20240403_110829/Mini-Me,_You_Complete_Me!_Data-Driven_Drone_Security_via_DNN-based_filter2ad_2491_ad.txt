contains 900 to 1000 time instances on a 60ms logging frequency
(averagely 52 seconds in total for each mission) excluding lifting
and landing periods.
Due to the confined computing capacity and memory size in
RAV, we train the neural network on a Linux PC and store its struc-
tural and weights information when the training process finishes.
In order to achieve the best NN model in terms of convergence
and accuracy, we apply the hyperparameter tuning framework op-
tuna [3] to optimize the model training. We search for 5 different
hyperparameters and configurable structural parameters including
learning rate, the numbers of LSTM layers, the number of fully con-
nected layers, batch size and the sliding window size. We suggest
the floating-point value in log domain between 1e-1 to 1e-7 for the
learning rate. We suggest integers between 1 to 4 for each number
of LSTM and fully connected layers. The range of sliding window
is set between 5 to 30 and we suggest numerical options of 32 to
512 for the batch size. We train the LSTM model with the mean
square error as loss function and adam [50] as optimizer. Figure 9
shows the convergence of the LSTM-based approximation model
in repeated experiments, the LSTM model will reach convergence
at around 100 to 150 epochs as shown in the x-axis. Also, the vali-
dation losses in most epochs are greater than the training losses,
which indicates there is no over-fitting on training samples. For the
total dataset we collected, we split 80 percent of the data samples
to train the NN model and keep the remaining 20 percent for vali-
dation purposes. The testing error distributions of LSTM models
are shown in Figure 10, which indicates the reliant convergence of
its training on vehicle data collected on 30 missions, that means,
Mini-Me does not require a massive training dataset compared to
8
Figure 9: Convergence of LSTM-based approximate model
Figure 10: LSTM-based approximate model kernel density
estimation and error distribution function generated from
the 30 benign training missions
control invariant estimation work [27] due to its lightweight and
concise model structural construction. In addition, we create the er-
ror distribution function based on the errors (i.e., distance between
the perceived and estimated control state vector) for all testing sam-
ples. Note that the errors are measured after the normalization of
testing samples, hence they are numerically smaller than the actual
difference of vehicle dynamics. The distribution and probability
density function provide us the average value µ and variance σ,
which helps us determine the threshold (see Figure 13) as the error
boundaries from the point of view of statistical probability.
Model Accuracy on Different Vehicles. We evaluate the gen-
erality of our proposed monitoring framework by showing the
model accuracy for different vehicles and different control mod-
els. We establish the Mini-Me’s approximate models for roll angle
rate control functions extracted from ArduCopter control model
in 3DR IRIS+ and PX4 control model in 3DR Solo. The results in
Figure 11a and 11b show that a LSTM-model is capable to learn
different control model behaviors in autonomous flight missions
once the model is respectively trained for the certain vehicle dy-
namics and its control model. We also observe that the roll angles
estimated by Mini-Me closely approximate the perceived changes
of the roll angle, and the distances between them are measured as
errors on the right side of Figure 11.
In addition, we extract another quaternion-based attitude con-
troller in Crazyflie 2.0 for approximation (as opposed to angle-based
RAV attitude stabilizer). As shown in Figure 12, the x-axis corre-
sponds to operation time (in original timestamp) once the RAV
starts flying along the testing trajectory, and the y-axis represents
the measurement for the four different elements in the attitude
quaternion that are used in rotation calculations and also reflects
020406080100120140Epoch105104103102101Losstrain_lossval_loss0.0000.0020.0040.0060.0080.0100.012LSTM error distance between target and test outputs (bandwidth = 3)050100150200250300350DensityKernel density estimationFitting Gaussian distribution435attacks are ignored. Since the threshold is relevant to the probability
calculated by the error distribution, we test six different thresholds
based on the average error µ and variance σ. From figure 13, we find
that a larger threshold generally brings about lower FP rates and
relatively higher FN rates. Specifically, a larger threshold has lower
FP rates when we test in unfavorable environments (e.g., various
wind speeds) because the error distribution has a small deviation
compared to prior training and testing missions. However, a larger
threshold also leads to a higher FN rate especially when attackers
compromise the RAV controller states in a gradual manner and
long period of time because the malicious states do not have radical
changes. More discussion about stealthy attacks is in Section 6.
Therefore, we choose the threshold close to µ + 3σ to achieve the
best combination of FP and FN rates. Overall, we observe 0% FP
and 4% FN on the ArduCopter-based IRIS+ model with only one
attack evading the detection. For Crazyflie 2.0 model, we observe
0% FP and 0% FN with no attack evading the detection by Mini-Me.
(a) ArduCopter-based 3DR IRIS+
(b) Crazyflie 2.0
Figure 13: False positive (FP) rates and false negative (FN)
rates for different thresholds
5.3 Case Studies
Based on the current known attack cases relevant to our application,
we create five different attack examples to show how Mini-Me
monitors the estimation errors in real-time and detects possible
exploitation.
Sensor Spoofing Attack. For the RAV and its RTOS, sensor
spoofing attacks may occur in physical components (e.g., GPS sig-
nal tampering, vulnerability in sensor readings). When we discuss
the condition in which the attacker compromises the sensor read-
ings or takes over the sensor signals to mislead the RAV to unsafe
operations, we assume that the attacker’s goal is to corrupt the
vehicle dynamic measurements (e.g., roll angle) from the exter-
nal physical channels, which are essential for vehicle filtering and
stabilizer. Our solution is able to prevent this kind of attack by com-
paring vehicle dynamic outputs from the original control logic and
approximate model. Since the manipulation of partial or entire sen-
sor readings will cause the malicious misbehavior, our pre-trained
neural network reads the last updating sensor values augmented
with other control state variables to predict the expected behaviors
of the RAV, reflected as the parameter updates in the RAV’s attitude
and velocity vectors. This significant mismatch of output vectors
will result in abnormal real-time error changes and be detected by
Mini-Me.
(a) ArduCopter-based 3DR IRIS+ control model
(b) PX4-based 3DR Solo control model
Figure 11: Different approximate models get trained to esti-
mate the control state variable of different vehicles
Figure 12: LSTM network approximation results for four at-
titude parameters in practical flight experiments
the flight attitude amidst missions. We observe that the NN-based
approximation model learns the original control logic and accu-
rately predicts the same flight movement patterns in our test cases.
Therefore, we observe that our monitoring framework is agnostic
to the RAV’s controller software and accessible to build and deploy
for different vehicles.
Attack Detection and FP/FN Rates. Figure 13 presents the re-
sults of false positive (FP) rates and false negative (FN) rates for
attack detection under different thresholds. After deploying our
monitoring framework on the RAV, we execute 25 benign missions
in various environmental conditions to measure FP by counting
how many false alarms are created. We launch the same 25 missions
again and start attacks during the flight to measure FN how many
9
01020304050Time (seconds)8642024Roll angle (deg)perceivedestimated01020304050Time (seconds)0.0000.0010.0020.0030.0040.0050.006Error0102030405060Time (seconds)64202468Roll angle (deg)perceivedestimated0102030405060Time (seconds)0.0000.0010.0020.0030.0040.005Error1.821.831.841.851.86Timeline(ms)#106-1-0.500.51Attitude_q0Original control logic1.821.831.841.851.86Timeline(ms)#106-0.04-0.0200.020.040.06Attitude_q1Estimation with NN1.821.831.841.851.86Timeline(ms)#106-0.06-0.04-0.0200.020.040.06Attitude_q21.821.831.841.851.86Timeline(ms)#106-1-0.8-0.6-0.4-0.200.2Attitude_q3++2+3+4+5Threshold0102030Percentage (%)FPFN++2+3+4+5Threshold0102030Percentage (%)FPFN436(a) Sensor spoofing attack
(b) Control parameter attack
(c) Control signal spoofing
(d) Actuator spoofing attack
(e) Hard timer attack
(f) Attack detection
(g) Attack detection
(h) Attack detection
(i) Attack detection
(j) Attack detection
Figure 14: Mini-Me estimation error and real-time detection in practical attack cases
In our test case, Crazyflie 2.0 is set to fly along a testing trajectory.
We launch the sensor spoofing attack [47] at time instance 15.0s
after its taking off to disrupt the inertial sensor readings and com-
promise roll angle measurements, which causes failure to update
state parameters in velocity and position controllers as shown in
Figure 14a. In more detail, the controller task is still running, but
the sensor readings and state estimation used to measure RAV’s
attitudes are compromised. Our results show a sharp increment in
real-time monitoring error, which breaks the upper boundary gen-
erated from the testing estimation error distribution as marked out
in Figure 14f. Thus, with the protection of Mini-Me, the NN-based
approximation model recognizes sudden changes of the attitude
measurements and detects the sensor spoofing attack.
Control Parameter Attack. For real-time RAVs, any distur-
bance or intrusion to control parameters can cause unsafe opera-
tions and even harm to the hardware components. For instance, the
RAV stabilizer logic calculates the RAV velocity based on attitude er-
rors from updated sensor measurements incorporating the current
attitude information. The attacker might leverage control semantic
bugs [49] and modify the security-critical parameters like rollRate,
an important parameter for attitude resolution, to compromise the
control logic and act disruptively amidst a flight mission.
In our experiments, a RAV is tasked with an automatic path-
following mission, moving through a series of sequential way-
points. During its mission, we modify the control parameters in
attitude_pid_controller to push one dimensional of attitude
measurements to a very large scale from time instance 5.0s as shown
in Figure 14b. LSTM approximation model successfully detects this
sudden tampering on control logic because the real-time monitor-
ing errors become greater than the pre-determined upper boundary
as presented in Figure 14g. The reason why estimated errors do not
fluctuate very sharply is that the scalar in the preprocessing layer
leverages this impact of shape increment in the output vector. Our
solution Mini-Me, equipped with LSTM neural network topology,
proves its effectiveness in detecting control parameter attacks by
monitoring the estimation error.
10
Control Signal Spoofing. In control signal spoofing attacks, an
adversary can penetrate the control signals using various wireless
communication techniques. The RC disturbance attack [47] could
corrupt the RAV’s RC signal handling and lead to unsafe flight
operations. The GPS signal spoofing [43, 72] can send malicious
signals to cause operation disturbance.
In our experiments, we launch a control signal spoofing attack
in [27]. The motor pulse width modulation (PWM) signals are used
in 3DS IRIS+ to adjust the motor’s rotation speed and attitude
updates from the state estimation process. We launch the attack
at time instance 5.0s in Figure 14c, which results in a significant
disturbance to the attitude-related parameters in state estimation
including the RollRate (i.e., rate of roll angle). For an autonomous
flight mission, the RollRate performs an important role in RAV
velocity control algorithms such as PID and Kalman filter. As shown
in Figure 14h, our solution recognizes these malicious changes of
the real-time error between the predicted outputs from Mini-Me
and perceived outputs from current running control logic.
Actuator Spoofing Attacks. The autonomous RAVs run control
algorithms with the sensor readings to send commands to actuators.
As a subset of control signal spoofing attacks, the actuator spoofing
attacks specifically compromise actuator signal variable calcula-
tions using control-semantic bugs. Through feeding manipulated
actuator signals, false data will be injected and disrupt the actuator
(e.g. motors) measurements in state estimators.
In this case, we launch a typical actuator spoofing attack via
input validation bugs [49] and misconfiguring the actuator param-
eters within 3DS IRIS+. Specifically, we manipulate the coefficient
parameters of actuator signal PWM at time instance 5.0s amidst an
autonomous flight mission. We define a parameter reset function in
python scripts to raise the motor ratio values to five times more than
their normal readings like Figure 14d, resulting in the compromised
movement diagnosis. When the actuator signal gets compromised,
the original control logic and Mini-Me will receive the same input
data but generate different actuator outputs. As shown in Figure
14i, this kind of change will result in an unmatched input-output
mapping based on the NN model forecasting; in other words, the
051015202530Time(s)10.07.55.02.50.02.55.07.510.0Roll angle (deg)0246810Time(s)0.1000.0750.0500.0250.0000.0250.0500.0750.100Attitude_q10246810Time(s)0246810Rate of roll (deg/s)05101520Time(s)151050510Roll angle (deg)051015202530Time(s)103102101100Real-time ErrorUpper bound of error0246810Time(s)103102101100Real-time ErrorUpper bound of error0246810Time(s)103102101100Real-time ErrorUpper bound of error0246810Time(s)103102101100Real-time ErrorUpper bound of error05101520Time(s)103102101100Real-time ErrorUpper bound of error437Table 1: Mini-Me detection evaluation on multi-category attack cases in comparison with existing cyber-physical attack de-
tection methods. ✔: DETECTED ✗: NOT DETECTED
Attack Cases
Attack Point
Sensor reading
Sensor Spoofing Attack
Control Parameter Attack Control parameter
Control Signal Spoofing
Actuator Spoofing Attack Actuator parameter
Hard Timer Attack
State estimator
SysTick hardware timer
Attack Surface
Description
Malicious sensor intrusion
Tamper the control logic
Mislead the actuator
Mislead the actuator
Slow down real-time response
Mini-Me CI [27]
Detection
SAVIOR [59] MAYDAY [48]
✔
✔
✔
✔
✔
✔
✗∗
✔
✔
✔
✔
✗
✔
✔
✔