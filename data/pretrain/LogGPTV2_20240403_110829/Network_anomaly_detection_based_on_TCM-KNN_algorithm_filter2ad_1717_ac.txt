Y
|
|
1
Y
(
∑
1
j
1
=
j Y
−
2
j
2
)
(7) 
The detail is, for cluster-based algorithm, we set the width  w  of 
the  fixed-width  clustering  to  be  40.  For  the  KNN  algorithm,  k  
was set to 10,000 and also the one-class SVM algorithm, we set 
v =0.01, 
2σ =12.  For  our  method,  we  set  k  1,000  and  the 
confidence measure δ =0.95 (means τ=0.05). Figure 3 shows an 
ROC  (Receiver  Operating  Characteristic)  curve  depicting  the 
results and Table 1 gives the selected points from Figure 3. It is 
clear that our method demonstrates higher TP and lower FP than 
the other three methods. 
Figure  3.  ROC  curves  showing  the  performance  of  our 
method and other three algorithms over the KDD 99 dataset. 
The curves are obtained by varying the threshold 
Table 1. Selected points from the ROC curves in Figure 3 
Algorithm 
TP 
FP 
the 
Secondly, we extracted the “normal” instances (about 97,278) as 
well  as  the  “abnormal”  instances  (about  4,768  and  all  sampled 
from the dataset and included all the four attack types) from KDD 
99 to prepare for the verification of our anomaly detection method 
based  on  TCM-KNN  algorithm.  Moreover,  we  also  prepared  a 
“noisy”  dataset  for  meeting  the  requirement  of  the  contrast 
experiment  between  our  method  and 
three  classical 
unsupervised  anomaly  detection  algorithms  proposed  by  authors 
in [8]. The “noisy” dataset is consisted of 97,278 normal instances 
and  980  attack  instances  (sampled  four  attack  instances  from 
KDD 99), which ensures the dataset included 1% to 1.5% attack 
and  98.5  %  to  99%  normal  instances.  Limiting  the  ratio  of 
abnormal instances below 2% in “noisy” dataset is to ensure the 
detection performance of our method. Based on our experiences, 
if the ratio exceeds 2%, the performance will drop obviously. 
indices  of 
To  evaluate  our  method  we  used 
performance: the detection rate (also named true positive rate, TP) 
and  the false  positive  rate  (FP).  TP  is  defined  as  the  number  of 
intrusion  instances  detected  by  the  system  divided  by  the  total 
number of intrusion instances present in the test set. FP is defined 
as  the  total  number  of  normal  instances  that  were  incorrectly 
classified  as  intrusions  divided  by  the  total  number  of  normal 
instances. 
two  major 
Cluster 
Cluster 
Cluster 
Cluster 
KNN 
KNN 
KNN 
KNN 
One-class SVM 
One-class SVM 
One-class SVM 
One-class SVM 
Our method 
Our method 
Our method 
Our method 
92.78% 
65.29% 
46.83% 
27.98% 
91.23% 
23.15% 
11.08% 
5.33% 
98.32% 
91.26% 
66.83% 
5.12% 
99.44% 
98.99% 
97.28% 
88.22% 
10.08% 
1.87% 
1.09% 
0.45% 
7.87% 
6.45% 
4.32% 
1.98% 
10.08% 
5.69% 
3.94% 
3.66% 
1.74% 
1.59% 
1.27% 
0.98% 
5.2  Contrast Experimental Results 
In the contrast experiments, we used the extracted “noisy” dataset 
for training and test. We adopted ten-fold cross validation method 
to make the experiment. The experimental parameters were set as 
follows. For the  unsupervised  anomaly  detection  algorithms,  we 
set their parameters as in [8] for the convenience of comparison. 
Figure  4.  ROC  curves  showing  the  performance  comparison 
of our method on the “clean” data and the “unclean” data 
17
Moreover,  we  also  test  the  performances  of  our  TCM-KNN 
algorithm  when  provided  with  “clean”  training  dataset  (the 
dataset is only consisted of the normal instances) and “unclean” 
training  dataset  (the  dataset  contains  both  normal  and  abnormal 
instances  as  discussed  in  Section  5.1).  The  result  is  depicted  in 
Figure  4  and  it  clearly  tells  us  that  the  detection  performance 
when using two different datasets for training vibrates a little. It is 
worth noting here that we didn’t show the ROC curves of cluster, 
KNN  and  one-class  SVM  when  using  separate  dataset,  because 
they demonstrated very poor performance. Their functions greatly 
depend on the dataset (generally the dataset should include a great 
deal of “normal” data and a few “abnormal” data), while for our 
TCM-KNN based method, “clean” and “unclean” dataset are all 
suitable for training so long as we could control the ratio between 
normal and abnormal instances for the training dataset. 
adopting 
feature 
to 
selection 
5.3  Experimental Results Using Selected 
Features 
It is natural and necessary because as discussed in Section 3, the 
performance  of  TCM-KNN  algorithm  might  deteriorate  when 
meeting the “curse of dimensionality”, thus, by doing this, we can 
validate  if  our  algorithm  is  robust  and  effective  under  the 
circumstance  of 
reduce 
computational cost. Therefore, for the next experiment, we have 
performed  feature  selection  on  KDD  99  to  acquire  the  most 
relevant and necessary features from the 41 features. 
Feature  selection  is  one  of  the  important  and  frequently  used 
techniques  in  data  preprocessing.  It  can  reduce  the  number  of 
features,  removes  irrelevant,  redundant  features  and  bring  the 
immediate effects for intrusion detection. A detail description of 
related work and theories in feature selection can be found in [16]. 
In our experiments, we used Chi-Square feature selection method. 
The selected features and the experimental results are respectively 
listed  as  Table  2  and  3.  Table  2  shows  the  performance  of  our 
method is good both on original KDD 99 (TP=99.48%, FP=1.74%) 
and on the dataset after employing feature selection (TP=99.32%, 
FP=2.81%). Although the FP increased a little, but it’s still very 
manageable,  thus  we  can  argue  it  is  possible  to  use  a  reduced-
dimension dataset to detect anomalies without significant loss of 
performance. 
Table 2. Feature selection results 
Chi-Square Value
Feature 
Rank 
1 
2 
3 
4 
5 
6 
17586.107 
17368.831 
17073.438 
17032.989 
16503.031 
14357.396 
dst_host_rerror_rate 
src_bytes 
dst_bytes 
hot 
dst_host_srv_rerror_rate
num_compromised 
Table 3. Experimental results on total and selected features 
TP 
FP 
Original KDD 99 
99.48% 
1.74% 
Dataset after feature 
selection 
99.32% 
2.81% 
the  number  of  attack  data).  Therefore, 
5.4  Discussions 
From the above experimental results, we can clearly catch that our 
method based on TCM-KNN algorithm prevails over the state-of-
the-art anomaly detection techniques. It prevails over supervised 
anomaly  detection  in  that  not  any  attack  data  is  needed  for 
constructing  the  attack  detection  classifier.  Experimental  results 
show  it  can  more  effectively  detect  intrusions  with  low  false 
positive  rate,  most importantly, under  the  circumstances  of  both 
without  any  attack  data  for  training  and  even  interfered  by  the 
“noisy  data”,  it  all  demonstrates  good  performances.  The  only 
requirement  for our method is relatively  clean  normal data  (i.e., 
attack  free  data  or  “noisy  data”  whose  normal  data  vastly 
outnumbers 
its 
performance  prevails  over  both  the  current  unsupervised  and 
supervised anomaly detection methods. 
Intuitively, our method detects abnormal points (anomalies) using 
all  the  available  normal  points  to  measure.  Therefore,  it  is 
immune to the effect of limited “noisy data” (about 1%-1.5% of 
the  dataset)  and  could  make  correct  detection  decision.  The 
experimental  results  on  the  dataset  being  employed  feature 
reduction  evident  the  computation  cost  of  our  method  could  be 
effectively reduced without any obvious deterioration of detection 
performance. 
Moreover, we deliberately analyzed  the false  negatives (i.e., the 
percentage  of  attacks  our  detection  method  missed).  We  found 
they all almost came from the R2L and U2R attacks (see Table 4). 
In another word, our method can detect almost all DoS and Probe 
attacks in KDD 99. To our best knowledge and learning from the 
literatures  published  before,  the  results  are  consistent  and  they 
demonstrate  the  features  of  R2L  and  U2R  in  KDD  99  are  little 
different  from  those  of  normal  data,  it  is  very  difficult  for  any 
method to distinguish them. Therefore, we are confident the false 
negative of our method is acceptable and can be further reduced 
or avoided on good quality real dataset. 
Table 4. The average true positive rate for each type of attack 
Attack Type 
True Positives 
DoS 
Probe 
U2R 
R2L 
100% 
99.6% 
89.6% 
96.1% 
Based on the above analyses, we may claim  our method  can be 
optimized  to  a  good  candidate  for  anomaly  detection  in  the 
realistic network environment. We will detail the future work of 
optimization in the next section. 
6.  CONCLUSIONS AND FUTURE WORK 
In  this  paper,  we  proposed  a  novel  anomaly  detection  method 
based on TCM-KNN algorithm. Experimental results demonstrate 
its  effectiveness  and  advantages  over  state-of-the-art  anomaly 
detection methods. 
However, this paper only presents our preliminary work and there 
is a lot of future work for us. On one hand, in the realistic network 
environment, how to select the features forming the feature vector 
for 
training  and  detect  anomalies  should  be  deliberately 
considered by us. Those features may come from the 41 features 
in KDD 99 dataset and need to be proposed by us according to the 
18
real  applications,  because  they  directly  affect  the  effectiveness 
and  efficiency  of  our  method  in  the  real  applications,  in  which 
case  feature  selection  is  not  such  simple  as  in  our  KDD  99  test 
dataset  environment.  On  the  other  hand,  in  order  to  apply  our 
method to the intrusion detection applications, we need solve the 
high  computational  cost  of  distance  calculations  as  discussed  in 
Section  4.  We  should  limit  the  scale  of  “normal”  points  for 
training  and  the  dimension  of  points  to  avoid  the  “curse  of 
dimensionality”.  So,  feature  selection  and  mapping  “normal” 
patterns  of  specific  application  to  limited  points  for  our  method 
are  our  future  work.  Meanwhile,  we  will  study  how  to  more 
effectively detect such normal-like attack types as U2R and R2L 
by improving our method, since their detection rates in our paper 
is relatively lower than those of other attack types. 
7.  ACKNOWLEDGMENTS 
Our authors wish to sincerely thank the anonymous reviewers of 
ASIACCS’07 for their valuable comments on this paper. 
8.  REFERENCES 
[1]  M. Bykova, S. Ostermann, and B. Tjaden. Detecting network 
intrusions via a statistical analysis of network packet 
characteristics. In Proceedings of the 33rd Southeastern 
Symp. on System Theory (SSST 2001), Athens, IEEE, 2001. 
[2]  D.E. Denning. An intrusion detection model, IEEE 
Transactions on Software Engineering, SE-13, 1987, 222-
232. 
[3]  W. Lee, and S. J. Stolfo. Data mining approaches for 
intrusion detection. In Proceedings of the 1998 USENIX 
Security Symposium, 1998. 
[4]  A. Ghosh, and A. Schwartzbard. A study in using neural 
networks for anomaly and misuse detection. In Proceedings 
of the 8th USENIX Security Symposium, 1999. 
[5]  M. Mahoney, and P. Chan. Learning nonstationary models of 
normal network traffic for detecting novel attacks. In 
Proceeding of the Eighth ACM SIGKDD International 
Conference on Knowledge Discovery and Data Mining, 
Edmonton, Canada, 2002, 376-385. 
[6]  D. Barbara, N. Wu, S. Jajodia. Detecting novel network 
intrusions using Bayes estimators. First SIAM Conference on 
Data Mining, Chicago, IL, 2001. 
[7]  N. Ye. A markov chain model of temporal behavior for 
anomaly detection. In Proceedings of the 2000 IEEE Systems, 
Man, and Cybernetics Information Assurance and Security 
Workshop, 2000. 
[8]  E. Eskin, A. Arnold, M. Prerau, L. Portnoy, and S. Stolfo. A 
geometric framework for unsupervised anomaly detection: 
detecting intrusions in unlabeled data. Applications of Data 
Mining in Computer Security, Kluwer, 2002. 
[9]  A. Gammerman, and V. Vovk. Prediction algorithms and 
confidence measure based on algorithmic randomness theory. 
Theoretical Computer Science. 2002, 209-217. 
[10] M. Li, and P. Vitanyi. Introduction to Kolmogorov 
complexity and its applications. 2nd Edition, Springer Verlag, 
1997. 
[11] K. Proedru, I. Nouretdinov, V. Vovk, and A. Gammerman. 
Transductive confidence machine for pattern recognition. 
Proc. 13th European conference on Machine Learning. 2002, 
381-390. 
[12] B. Daniel, D. Carlotta, and P. R. James. Detecting outliers 
using transduction and statistical testing. In Proceedings of 
the 12th ACM SIGKDD international conference on 
Knowledge discovery and data mining, USA, 2006, 55-64. 
[13] Knowledge discovery in databases DARPA archive. Task 
Description. 
http://www.kdd.ics.uci.edu/databases/kddcup99/task.htm 
[14] J. McHugh. The 1998 Lincoln Laboratory IDS evaluation: A 
critique. In Recent Advances in Intrusion Detection (RAID 
2000), Lecture Notes in Computer Science, Springer-Verlag, 
Berlin, volume 1907, 2000, 145-161. 
[15] R. P. Lippmann, D. J. Fried, I. Graf, J. W. Haines, K. R. 
Kendall, D. McClung, D. Weber, S. E. Webster, D. 
Wyschogrod, R. K. Cunningham, and M. A. Zissman. 
Evaluating intrusion detection systems: The 1998 DARPA 
off-line intrusion detection evaluation. In DARPA 
Information Survivability Conference and Exposition 
(DISCEX), volume 2, 2000, 12-26. 
[16] H. Liu, and L. Yu. Towards integrating feature selection 
algorithms for classification and clustering. IEEE 
Transactions on Knowledge and Data Engineering, 17(3), 
2005, 1-12.
19