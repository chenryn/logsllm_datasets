### 5. Experimental Results and Analysis

#### 5.1 Parameter Settings and ROC Curves

For the cluster-based algorithm, we set the width \( w \) of the fixed-width clustering to 40. For the KNN algorithm, \( k \) was set to 10,000. For the one-class SVM algorithm, we set \( v = 0.01 \) and \( 2\sigma = 12 \). For our method, we set \( k = 1,000 \) and the confidence measure \( \delta = 0.95 \) (which means \( \tau = 0.05 \)).

Figure 3 shows an ROC (Receiver Operating Characteristic) curve depicting the results, and Table 1 provides selected points from Figure 3. It is clear that our method demonstrates higher true positive (TP) rates and lower false positive (FP) rates compared to the other three methods.

**Figure 3.** ROC curves showing the performance of our method and three other algorithms over the KDD 99 dataset. The curves are obtained by varying the threshold.

**Table 1.** Selected points from the ROC curves in Figure 3.

| Algorithm         | TP (%)   | FP (%)   |
|-------------------|----------|----------|
| Cluster           | 92.78    | 98.32    |
| KNN               | 65.29    | 91.26    |
| One-class SVM     | 46.83    | 66.83    |
| Our Method        | 27.98    | 5.12     |

#### 5.2 Dataset Preparation

We extracted "normal" instances (approximately 97,278) and "abnormal" instances (approximately 4,768, sampled from the KDD 99 dataset and including all four attack types) to prepare for the verification of our anomaly detection method based on the TCM-KNN algorithm. Additionally, we prepared a "noisy" dataset for the contrast experiment between our method and three classical unsupervised anomaly detection algorithms proposed by authors in [8]. The "noisy" dataset consists of 97,278 normal instances and 980 attack instances (sampled from KDD 99), ensuring that the dataset includes 1% to 1.5% attack instances and 98.5% to 99% normal instances. Limiting the ratio of abnormal instances below 2% in the "noisy" dataset ensures the detection performance of our method. Based on our experiences, if the ratio exceeds 2%, the performance will drop significantly.

#### 5.3 Performance Evaluation Metrics

To evaluate our method, we used two major performance indices: the detection rate (also known as the true positive rate, TP) and the false positive rate (FP). TP is defined as the number of intrusion instances detected by the system divided by the total number of intrusion instances present in the test set. FP is defined as the total number of normal instances that were incorrectly classified as intrusions divided by the total number of normal instances.

**Table 2.** Performance comparison of different methods on the KDD 99 dataset.

| Algorithm         | TP (%)   | FP (%)   |
|-------------------|----------|----------|
| Cluster           | 92.78    | 98.32    |
| KNN               | 65.29    | 91.26    |
| One-class SVM     | 46.83    | 66.83    |
| Our Method        | 27.98    | 5.12     |

#### 5.4 Contrast Experimental Results

In the contrast experiments, we used the extracted "noisy" dataset for training and testing. We adopted a ten-fold cross-validation method. The experimental parameters were set as follows: for the unsupervised anomaly detection algorithms, we set their parameters as in [8] for the convenience of comparison.

**Figure 4.** ROC curves showing the performance comparison of our method on the "clean" data and the "unclean" data.

Moreover, we tested the performance of our TCM-KNN algorithm when provided with a "clean" training dataset (consisting only of normal instances) and an "unclean" training dataset (containing both normal and abnormal instances as discussed in Section 5.1). The results, depicted in Figure 4, clearly show that the detection performance when using the two different datasets for training varies slightly. It is worth noting that we did not show the ROC curves of the cluster, KNN, and one-class SVM methods when using separate datasets because they demonstrated very poor performance. These methods' performance greatly depends on the dataset (generally, the dataset should include a large amount of "normal" data and a few "abnormal" data). In contrast, our TCM-KNN-based method is suitable for training with both "clean" and "unclean" datasets, as long as we can control the ratio between normal and abnormal instances in the training dataset.

#### 5.5 Experimental Results Using Selected Features

It is natural and necessary to reduce the computational cost and improve the performance of the TCM-KNN algorithm by addressing the "curse of dimensionality." Therefore, we performed feature selection on the KDD 99 dataset to acquire the most relevant and necessary features from the 41 available features.

Feature selection is an important and frequently used technique in data preprocessing. It can reduce the number of features, remove irrelevant and redundant features, and improve the efficiency of intrusion detection. A detailed description of related work and theories in feature selection can be found in [16]. In our experiments, we used the Chi-Square feature selection method. The selected features and the experimental results are listed in Tables 3 and 4, respectively.

**Table 3.** Feature selection results.

| Chi-Square Value | Feature                          | Rank |
|------------------|----------------------------------|------|
| 17586.107        | dst_host_rerror_rate             | 1    |
| 17368.831        | src_bytes                        | 2    |
| 17073.438        | dst_bytes                        | 3    |
| 17032.989        | hot                              | 4    |
| 16503.031        | dst_host_srv_rerror_rate         | 5    |
| 14357.396        | num_compromised                  | 6    |

**Table 4.** Experimental results on total and selected features.

| Dataset                           | TP (%)   | FP (%)   |
|-----------------------------------|----------|----------|
| Original KDD 99                   | 99.48    | 1.74     |
| Dataset after feature selection   | 99.32    | 2.81     |

Although the FP rate increased slightly, it remains manageable, indicating that it is possible to use a reduced-dimension dataset to detect anomalies without significant loss of performance.

#### 5.6 Discussions

From the above experimental results, it is clear that our method based on the TCM-KNN algorithm outperforms state-of-the-art anomaly detection techniques. It surpasses supervised anomaly detection methods by not requiring any attack data for constructing the attack detection classifier. Experimental results show that it can more effectively detect intrusions with a low false positive rate, even under circumstances where no attack data is available for training or when the data is interfered with by "noisy" data. The only requirement for our method is relatively clean normal data (i.e., attack-free data or "noisy" data where normal data vastly outnumbers attack data).

Intuitively, our method detects abnormal points (anomalies) using all available normal points for measurement. Therefore, it is immune to the effect of limited "noisy" data (about 1%-1.5% of the dataset) and can make correct detection decisions. The experimental results on the dataset employed with feature reduction demonstrate that the computational cost of our method can be effectively reduced without any obvious deterioration in detection performance.

Moreover, we analyzed the false negatives (i.e., the percentage of attacks our detection method missed). We found that they almost all came from R2L and U2R attacks (see Table 5). In other words, our method can detect almost all DoS and Probe attacks in the KDD 99 dataset. To the best of our knowledge, these results are consistent with previous literature, which indicates that the features of R2L and U2R in KDD 99 are very similar to those of normal data, making them difficult to distinguish. Therefore, we are confident that the false negative rate of our method is acceptable and can be further reduced or avoided with high-quality real datasets.

**Table 5.** The average true positive rate for each type of attack.

| Attack Type | True Positives (%) |
|-------------|--------------------|
| DoS         | 100                |
| Probe       | 99.6               |
| U2R         | 89.6               |
| R2L         | 96.1               |

Based on the above analyses, we can claim that our method can be optimized to be a good candidate for anomaly detection in realistic network environments. We will detail the future work of optimization in the next section.

### 6. Conclusions and Future Work

In this paper, we proposed a novel anomaly detection method based on the TCM-KNN algorithm. Experimental results demonstrate its effectiveness and advantages over state-of-the-art anomaly detection methods.

However, this paper only presents our preliminary work, and there is much future work to be done. On one hand, in realistic network environments, the selection of features forming the feature vector for training and detecting anomalies needs to be carefully considered. These features may come from the 41 features in the KDD 99 dataset and need to be proposed based on real applications, as they directly affect the effectiveness and efficiency of our method. In such cases, feature selection is not as simple as in our KDD 99 test dataset environment. On the other hand, to apply our method to intrusion detection applications, we need to address the high computational cost of distance calculations, as discussed in Section 4. We should limit the scale of "normal" points for training and the dimension of points to avoid the "curse of dimensionality." Therefore, feature selection and mapping "normal" patterns of specific applications to limited points for our method are part of our future work. Additionally, we will study how to more effectively detect normal-like attack types such as U2R and R2L, as their detection rates in our paper are relatively lower than those of other attack types.

### 7. Acknowledgments

The authors wish to sincerely thank the anonymous reviewers of ASIACCS’07 for their valuable comments on this paper.

### 8. References

[1] M. Bykova, S. Ostermann, and B. Tjaden. Detecting network intrusions via a statistical analysis of network packet characteristics. In Proceedings of the 33rd Southeastern Symposium on System Theory (SSST 2001), Athens, IEEE, 2001.

[2] D.E. Denning. An intrusion detection model, IEEE Transactions on Software Engineering, SE-13, 1987, 222-232.

[3] W. Lee, and S. J. Stolfo. Data mining approaches for intrusion detection. In Proceedings of the 1998 USENIX Security Symposium, 1998.

[4] A. Ghosh, and A. Schwartzbard. A study in using neural networks for anomaly and misuse detection. In Proceedings of the 8th USENIX Security Symposium, 1999.

[5] M. Mahoney, and P. Chan. Learning nonstationary models of normal network traffic for detecting novel attacks. In Proceedings of the Eighth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, Edmonton, Canada, 2002, 376-385.

[6] D. Barbara, N. Wu, S. Jajodia. Detecting novel network intrusions using Bayes estimators. First SIAM Conference on Data Mining, Chicago, IL, 2001.

[7] N. Ye. A Markov chain model of temporal behavior for anomaly detection. In Proceedings of the 2000 IEEE Systems, Man, and Cybernetics Information Assurance and Security Workshop, 2000.

[8] E. Eskin, A. Arnold, M. Prerau, L. Portnoy, and S. Stolfo. A geometric framework for unsupervised anomaly detection: detecting intrusions in unlabeled data. Applications of Data Mining in Computer Security, Kluwer, 2002.

[9] A. Gammerman, and V. Vovk. Prediction algorithms and confidence measures based on algorithmic randomness theory. Theoretical Computer Science, 2002, 209-217.

[10] M. Li, and P. Vitanyi. Introduction to Kolmogorov complexity and its applications. 2nd Edition, Springer Verlag, 1997.

[11] K. Proedru, I. Nouretdinov, V. Vovk, and A. Gammerman. Transductive confidence machine for pattern recognition. Proc. 13th European Conference on Machine Learning, 2002, 381-390.

[12] B. Daniel, D. Carlotta, and P. R. James. Detecting outliers using transduction and statistical testing. In Proceedings of the 12th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, USA, 2006, 55-64.

[13] Knowledge discovery in databases DARPA archive. Task Description. http://www.kdd.ics.uci.edu/databases/kddcup99/task.htm

[14] J. McHugh. The 1998 Lincoln Laboratory IDS evaluation: A critique. In Recent Advances in Intrusion Detection (RAID 2000), Lecture Notes in Computer Science, Springer-Verlag, Berlin, volume 1907, 2000, 145-161.

[15] R. P. Lippmann, D. J. Fried, I. Graf, J. W. Haines, K. R. Kendall, D. McClung, D. Weber, S. E. Webster, D. Wyschogrod, R. K. Cunningham, and M. A. Zissman. Evaluating intrusion detection systems: The 1998 DARPA off-line intrusion detection evaluation. In DARPA Information Survivability Conference and Exposition (DISCEX), volume 2, 2000, 12-26.

[16] H. Liu, and L. Yu. Towards integrating feature selection algorithms for classification and clustering. IEEE Transactions on Knowledge and Data Engineering, 17(3), 2005, 1-12.