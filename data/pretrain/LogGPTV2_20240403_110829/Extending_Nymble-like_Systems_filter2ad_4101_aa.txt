title:Extending Nymble-like Systems
author:Ryan Henry and
Ian Goldberg
2011 IEEE Symposium on Security and Privacy
Extending Nymble-like Systems
Ryan Henry and Ian Goldberg
Cheriton School of Computer Science
University of Waterloo
Waterloo, ON, Canada N2L 3G1
{rhenry,iang}@cs.uwaterloo.ca
Abstract—We present several extensions to the Nymble
framework for anonymous blacklisting systems. First, we show
how to distribute the Verinym Issuer as a threshold entity. This
provides liveness against a threshold Byzantine adversary and
protects against denial-of-service attacks. Second, we describe
how to revoke a user for a period spanning multiple linkability
windows. This gives service providers more ﬂexibility in decid-
ing how long to block individual users. We also point out how
our solution enables efﬁcient blacklist transferability among
service providers. Third, we augment the Verinym Acquisition
Protocol for Tor-aware systems (that utilize IP addresses as
a unique identiﬁer) to handle two additional cases: 1) the
operator of a Tor exit node wishes to access services protected
by the system, and 2) a user’s access to the Verinym Issuer
(and the Tor network) is blocked by a ﬁrewall. Finally, we
revisit the objective blacklisting mechanism used in Jack, and
generalize this idea to enable objective blacklisting in other
Nymble-like systems. We illustrate the approach by showing
how to implement it in Nymble and Nymbler.
Keywords-privacy enhancing technologies; anonymity; authen-
tication; anonymous blacklisting; privacy-enhanced revocation.
I. INTRODUCTION
In [21], [35], Tsang et al. proposed Nymble as a so-
lution to the problem of allowing service providers on
the Internet—such as websites,
IRC networks or mail
servers—to revoke access from individual misbehaving users
of anonymous communications networks. Nymble uses a
novel construction to build mutually unlinkable (and efﬁ-
ciently veriﬁable) authentication tokens for users of anony-
mous communications networks, while empowering service
providers with access revocation capabilities comparable to
what they have with nonanonymous users. In particular,
the scheme implements a privacy-preserving analog of IP
address banning for users of anonymous communications
networks. Under some assumptions regarding noncollusion
of certain third parties, their approach is provably secure
(in the random oracle model); i.e., privacy and availability
for honest users are not adversely affected, and blacklisted
users remain anonymous. The construction used in Nymble
results in an extremely lightweight solution for all parties
involved (most notably, for the service provider). It does
this, however, by placing a lot of trust in third parties. Since
Nymble was ﬁrst proposed in 2006, several schemes have
appeared in the literature to solve the same problem, or one
of several closely related problems. (For some examples,
see [6], [19], [20], [22], [23], [32]–[34].) Three of these
schemes operate within the same general framework as
1081-6011/11 $26.00 © 2011 IEEE
DOI 10.1109/SP.2011.17
523
Nymble; they change only low-level details to weaken trust
assumptions and to provide stronger privacy guarantees and
some new functionality. Moreover, further incarnations of
the idea seem likely to emerge in the future [18]. In this
paper, we present several extensions to the abstract Nymble
framework that can be used to improve the security, liveness
and functionality of Nymble-like systems; our extensions
solve several open problems identiﬁed in the future work
sections of [19]–[22].
We ﬁrst
review how the Nymble framework works.
Nymble makes use of two trusted third parties (TTPs) called
the Pseudonym Manager (PM) and the Nymble Manager
(NM). Together, the PM and the NM issue a user (U) with
a set of mutually unlinkable, use-once authentication tokens
(called nymbles). This enables U to access the services
offered by a Service Provider (SP), while preserving the
ability of the SP to block U in the event that U misbehaves.
Nymble divides time into ﬁxed intervals called linkability
windows, which it further subdivides into smaller intervals
called time periods. When U wishes to use the system,
she ﬁrst connects directly (i.e., not through an anonymous
communications network) to the PM; this proves to the PM
that U is in possession of a particular IP address. The PM
then issues U with a pseudonym (called a Nym), which is
computed by applying a one-way function (an HMAC with a
secret key) to U’s IP address. When U wishes to authenticate
with some SP, she connects anonymously (over Tor, for
example) to the NM and presents a copy of her pseudonym
and the canonical name of the SP. Based on these two
values (Nym and canonical name), the NM computes and
issues to U a set of nymbles. Each nymble is valid for
a particular place (an SP) and time (a time period within
the current linkability window). To be sure, nymbles are
not entirely unlinkable; instead, the nymble construction
places a trapdoor within each nymble that allows the NM
to, given a nymble, compute all subsequent nymbles in the
same linkability window. If U somehow abuses the services
offered by the SP, then the SP can transmit the nymble used
by U during that session to the NM. The NM will then use
knowledge of the trapdoor to compute all of U’s subsequent
nymbles for the remainder of the current linkability window.
For each remaining time period, the NM will then place
the corresponding nymble on a list called the linking list
(there is a different linking list for each time period) and
U’s SP-speciﬁc pseudonym (i.e., her last nymble of the
linkability window) on the SP’s blacklist. By consulting the
no one
can go left
x
f (x)
f 2(x)
f 3(x)
. . .
nymbles:
g(x)
g (f (x))
(cid:2)
g
f 2(x)
(cid:3)
(cid:2)
g
f 3(x)
(cid:3)
only NM can go up
Figure 1. The nymble construction procedure: In the original Nymble [21], black arrows (i.e., f (·)) are implemented with an HMAC
and grey arrows (i.e., g(·)) are implemented with symmetric key encryption.
blacklist, U can easily check her revocation status before she
attempts to authenticate. Similarly, by consulting the current
linking list and denying access to any user that attempts
to authenticate with a nymble on it, the SP can prevent
U from further abusing its services for the remainder of
the current linkability window. Figure 1 illustrates the basic
nymble construction.
In [18], we observed that the pseudonym issued by the
PM (or the Credential Manager (CM), as it was called in
the later Nymble-like systems Nymbler [19] and Jack [22])
in existing schemes is really a verinym.1 This observation
highlights the largest security risk in the original Nymble:
a malicious PM and NM can easily collude to learn which
users are connecting to which SPs. If an SP also colludes,
they can also determine what each user is doing when
she interacts with that SP. To ensure that the verinym and
nymble constructions in future Nymble-like systems are not
susceptible to this sort of attack, we proposed a set of two
new security properties called the ZK-verinym property
and the ZK-pseudonym property.2 In our formalization, an
entity called the Verinym Issuer (VI) replaces the PM; the
VI can satisfy the new properties by using a technique ﬁrst
used by Henry et al. in [19]. First, a distributed VI issues
to U an anonymous credential that encodes U’s verinym.
To access an SP’s services, U computes her own nymbles
and uses zero-knowledge proofs (ZKPs) to convince the NM
of their correctness. (U reveals only a commitment to her
verinym.)
We further point out that the NM in existing schemes ﬁlls
two distinct roles. For this reason, we propose to replace
the NM with two separate entities: the Nymble Issuer (NI),
who issues nymbles to users, and the Pseudonym Extractor
(PE) who uses the trapdoor function to revoke misbehaving
users. Figure 2 illustrates the various parties involved in the
Nymble framework and the interactions among them.
We refer the reader to [18] for a more thorough description
1A verinym is any piece of identifying information that can single you
out of a crowd of potential candidates [16].
2The ZK-verinym property says that no party other than U (including the
PM and NM) learns the verinym associated with U. The ZK-pseudonym
property says that no party other than the NM is capable of recovering U’s
pseudonym for a given SP from one of U’s nymbles. We refer the reader
to [18] for formal deﬁnitions of these properties.
of the Nymble framework and Nymble-like systems.
A. Security requirements
A secure Nymble-like system must satisfy the following
security requirements [18]:
Correctness:
An honest SP will accept any well-formed nymble from
an unrevoked user.
Misauthentication resistance:
An honest SP will only accept nymbles that are output
by a correct execution of the system’s protocols; i.e., it
should be infeasible to
– forge a verinym without the VI’s secret key, or
– forge a nymble without the NI’s secret key.
Backward anonymity:
It is infeasible to associate a user’s nymbles with her
real identity, even if this user is, or later becomes,
revoked.
Unlinkability:
It is infeasible for anyone but the PE to determine if
two or more distinct nymbles come from the same user
or from different users. If these nymbles come from
different SPs or linkability windows, then even the PE
should not be able to determine if they come from the
same user or from different users.
Revocability:
With the assistance of the PE, an SP can blacklist any
user in such a way that no coalition of blacklisted users
can later authenticate.
Revocation auditability:
A user can check her revocation status prior to revealing
any nymbles to an SP.
Non-frameability:
No coalition of third parties can convince an honest
SP to blacklist a user for any action that user is not
responsible for.
We refer the reader to [18] for more rigorous formal deﬁni-
tions of these security notions.
B. Performance requirements
In addition to the security requirements we have already
mentioned, a useful Nymble-like system must also satisfy
the following performance requirements [18]:
524
U
Verinym Acquisition
Nymble Showing
Nymble
Acquisition
VI1
VIk
VIj
VIi
NI
PE
Revocation
SP
Figure 2. Nymble framework architecture: This ﬁgure illustrates the various parties involved in the Nymble framework, and the
interactions among them.
Veriﬁer efﬁciency:
Next, we augment the Verinym Acquisition Protocol for
Tor-aware Nymble-like systems (that utilize IP addresses as
a unique identiﬁer) to handle two additional cases: 1) when
the operator of a Tor exit node wishes to access services
protected by the system, and 2) when a user’s access to
the Verinym Issuer (and the Tor network) is blocked by a
ﬁrewall. This latter solution leverages Tor’s existing bridge
infrastructure [10], and a similar idea of using a distributed
collection of simple entities, called Identity Veriﬁers, that
assist users by verifying their IP addresses.
Finally, we revisit the objective blacklisting mechanism
used by Lin and Hopper in Jack [22]. We generalize their
approach to enable similar objective blacklisting capabilities
in other Nymble-like system. We illustrate the approach
by showing how to implement
in Nymble [21] and
Nymbler [19].
it
II. DISTRIBUTED (t, s)-THRESHOLD VERINYM ISSUER
The key idea in our distributed VI is to have the VIs use
a distributed “unique” (t, s)-threshold signature scheme to
compute U’s verinym. The security of this approach relies
on two properties of the underlying threshold signatures: un-
forgeability and uniqueness.3 All secure signature schemes
provide unforgeability [17]; uniqueness, on the other hand,
is a property that is only possessed by certain signature
schemes.
Deﬁnition 1 (Unique Signature Scheme [24]). A signature
scheme is called unique if, for every (possibly maliciously
chosen) public key pk and every message msg, there exists
at most one signature σ such that Verpk(msg, σ) = true.
For completeness, we formally deﬁne a (t, s)-threshold
signature scheme before discussing our approach in detail.
3The uniqueness property is only required if verinyms are computed
deterministically from a user’s unique resource, as in Nymble [21] and
Nymbler [19]. Systems such as Jack [22] and BNymble [23] in which
verinyms are based on user-chosen randomness do not require such a
property.
The value of the system to an SP must be higher than
its cost. Many SPs place little value in the input of
anonymous users, so the cost of supporting them must
be extremely low. This includes storage, bandwidth and
computation, as well as hardware costs.
User efﬁciency:
The system should be available to all users, and it
should avoid adding noticeable latency to the user’s
interactions with an SP.
Again, we refer the reader to [18] for more rigorous formal
deﬁnitions of these performance notions.
C. Our contributions
The remainder of this paper proposes some useful ex-
tensions to the Nymble framework. These extensions im-
prove the liveness, security and functionality of Nymble-like
schemes built from the extended framework; they solve sev-
eral open problems identiﬁed in the future work sections of
existing literature on anonymous blacklisting systems [19]–
[22].
Our ﬁrst contribution is to describe how to build a fully
distributed threshold VI; our construction satisﬁes the ZK-
verinym property and is ideally suited to a nymble format
that satisﬁes the ZK-pseudonym property. This modiﬁcation
provides security and liveness against a threshold Byzantine
adversary.
The second contribution amends the Nymble Acquisition
Protocol of systems satisfying the ZK-verinym and ZK-
pseudonym properties and base verinyms deterministically
on a unique resource (e.g., Nymbler [19]) to support revo-
cation of a user for a duration that spans multiple linkability
windows. This gives service providers ﬂexibility in deciding
how long to block an individual misbehaving user. We
point out how our solution enables blacklist transferability
among service providers and outline how this construction
is efﬁciently implemented using a generic nymble format.
525
Deﬁnition 2 ((t, s)-threshold Signature Scheme). A (t, s)-
threshold signature scheme is a digital signature scheme
with s signers and the property that any subset of at least t
signers can cooperate to sign a message msg. Conversely,
any subset of fewer than t signers should not be able to
compute any nontrivial information about a valid signature
on msg.
A unique (t, s)-threshold signature scheme is just a
(t, s)-threshold signature scheme with the uniqueness prop-
erty.
We use the non-interactive threshold RSA signature
scheme of Damg˚ard and Koprowski [9] for a concrete
realization of this idea. Other choices of unique threshold
signature scheme may also work well. We choose Damg˚ard
and Koprowski’s threshold RSA signatures because: 1) prov-
ing knowledge of an RSA signature in zero-knowledge is
easy, and 2) the scheme does not require a trusted dealer
who knows the factorization of the RSA modulus. This
latter point is particularly useful because some schemes (e.g.,
Nymbler [19]) already make use of an RSA modulus with
unknown factorization (and leave details of its generation
up to the implementer). Damg˚ard and Koprowski’s scheme
makes use of a slightly modiﬁed form of the Robust Efﬁcient
Distributed RSA-Key Generation protocol of Frankel et
al. [15]. In our case we will require that the public key n is
chosen such that N = 4n+1 is a prime;4 this can be accom-
plished by repeatedly executing the protocol of [15] until a
suitable n has been found. The prime number theorem [25,
Fact 2.95] tells us that, for example, the protocol will have
to be executed an average of 1536· ln 2 ≈ 1064 times, for a
1536-bit modulus. Note, however, that key generation occurs
infrequently, since we have the distributed VI generate a
single n to use for a substantial number of future linkability
windows.
The use of signatures in our application presents an
interesting challenge; for security purposes, U must be able
to prove in zero-knowledge that one committed value is a
signature on a second committed value. This means that the
VI cannot just sign a hash of the message as is usually
done to ensure security and integrity of RSA signatures.
Instead, we use a modiﬁed version of Rabin’s function:
mod n in place of a hash.
H(z, ξ) =
We choose this function to prevent U from exploiting the
homomorphic properties of RSA encryption. Full details of
our approach follow.
z2 + (z mod ξ)
(cid:2)
(cid:3)
As in [18], we subdivide each linkability window into
smaller intervals called verinym validity periods (VVPs).