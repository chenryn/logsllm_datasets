B. Government and the DNS
ICTs have been playing an increasingly important role in
supporting and shaping government operations. The govern-
ment use of ICTs is commonly referred to as e-government
[12]. This concept goes beyond simply augmenting existing
systems with technological tools, as e-government is expected
to shape the way in which citizens and governments interact,
and to add value to the services governments provide [13].
While technology is not the focus of e-government, it is the
foundation [14]. Thus, robust e-government will necessarily
require a reliable technological foundation.
High availability, reliability, and security are essential to e-
government. One of the primary ways in which e-government
creates value is to enhance trust in governments [12], [13].
Trust — in technology as well as in governments themselves
— also plays a key role in determining whether or not citizens
will use e-government resources at all [15]. It follows that
governments have a vested interest in promoting trust in the
systems they have created. In this endeavor, the DNS plays
an important role. Many government digital resources and ser-
vices are represented by a domain name, and located using the
DNS. The DNS is thus a key piece of e-government operation.
In this study, we focus on ensuring DNS deployments for
government domains are robust. This is an extension of the
work in [16], using additional data and measurements.
III. DATASETS
We constructed the datasets in three stages. First we iden-
tiﬁed the government domains to be examined. We then
collected the DNS data using both a passive DNS database
and active probes. Finally, we ﬁltered the DNS data.
A. Selecting Domains
Obtaining a representative list of domain names dedicated
to government use is not a straightforward task due to the
diversity of how governments manage their resources. A wide
variety of entities in addition to those dedicated to governance
may be considered government resources (e.g., universities,
utilities, hospitals), but the extent to which these entities are as-
sociated with governments may vary by country, municipality,
or city. Identifying and categorizing such resources to support
a systematic and coherent analysis was beyond the scope
of this stage of our research. Thus we focused on domains
associated with national governments, as we could conﬁdently
identify these and efﬁciently present measurements.
To identify these domains, we used the United Nations E-
Government Knowledge Base [8]. For each of the 193 UN
member nations, the Knowledge Base website contains a link
to the nation’s designated national portal: a central site for
e-government resources. The information about countries’ e-
government is partly self-reported, and UN researchers also
examined the national government websites [7]. This approach
to identifying government domains lends credibility to the list
we obtained. That said, we did ﬁnd it necessary to modify
the list slightly based on additional data found via the UN
site. Eleven of the links we obtained from the UN referred to
domains that we could not resolve. For two of the countries
involved, the registered domains in the link on the UN site
differed from that in the member states questionnaire (MSQ)
[7]. We also found one case where the domain in the link
belongs to a third-party that is using it to serve search results
and advertisements. For this case and the two involving a
mismatch between the link in the page and the MSQ, we used
the domain in the MSQ.
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 13:16:58 UTC from IEEE Xplore.  Restrictions apply. 
194
The FQDNs in the national portal links provided a starting
source to build lists of domain names that allowed us to study
countries’ government DNS deployments in greater depth. The
FQDN itself may be associated only with the national portal
website, while other government-related resources exist in the
same zone. Thus, for each FQDN, we extracted the sufﬁx
or the registered domain of the FQDN in the link, and used
that to seed further searches. For example, given the FQDN
www.australia.gov.au, we used the sufﬁx gov.au. With
this approach, we needed to ensure that a government entity
controls the registered domain or the sufﬁx. To do so, we did
a manual search of the documentation for the country code
top level domain’s (ccTLD’s) registration provider listed in
IANA’s Root Database [17]. We used this documentation to
determine if the sufﬁx was reserved for government use. In
cases where we could ﬁnd such information, we checked a
registrar to see if the sufﬁx was listed as restricted. We found
only three cases (laogov.gov.la, timor-leste.gov.tl
and jis.gov.jm) where we could not verify that the sufﬁx
was reserved for government use. In these cases, we used
the registered domain rather than the sufﬁx. Additionally, we
identiﬁed only one FQDN, www.regjeringen.no (Norway),
which has NS records but
is not covered by our sufﬁx
check. In this case, we veriﬁed that the registered domain
(regjeringen.no) is associated with the government via the
MSQ and Whois information. We refer to the set of the seed
domains as dgov.
To grow a larger list of government-controlled domains,
we used Farsight’s DNSDB [18] to retrieve NS records for
the dgov and their subdomains. A global network of sensors
and several zone ﬁles provide the input to the DNSDB [18].
The DNSDB, which has been maintained since 2010, contains
over 130 billion unique record sets with data for more than
51 billion FQDNs [19]. This dataset allowed us to discover
zones within the namespace deﬁned by our seed domains. We
use left hand wildcard searches in the standard DNSDB to
retrieve NS records for each selected seed domain. As we
intended to use these domains for active queries, we wanted
to identify domains that were likely to still be in use. We noted
that those reported by sensors or seen in zone ﬁles relatively
recently were the most likely to ﬁt this need. Thus, from the
PDNS data, we extracted all FQDNs from records seen in the
database inputs between January 1, 2020 and the time at which
we collected the data in February 2021.
B. Data Collection
We used the PDNS data to generate a list of domains to
examine via active lookup. After some ﬁltering to remove
what appeared to be disposable domains, we obtained a list
of over 147 thousand domains to query. Given this list of
domains to study, we ran a series of DNS queries, retrieving
the domains’ NS records. This collection was performed
through a server in our university’s network in April 2021.
Figure 1 illustrates the measurement setup. Given a subdomain
d, the client ﬁrst identiﬁes the authoritative nameservers of
d’s parent, which will be queried for d’s NS records (x).
Fig. 1: Measurement setup for active data collection
If one of these nameservers returns a referral (y), we will
proceed to the next step. In this step (z), the query client
sends the same query to d’s authoritative nameservers. If
one of d’s authoritative nameservers returns an answer ({),
we will combine the authoritative nameservers returned this
answer with those obtained in step (x). Finally (not shown
in the ﬁgure), the client retrieves the IPv4 addresses of all
authoritative nameservers identiﬁed in the previous steps and
sends a query to each address for d’s NS records.
For cases where the authoritative nameservers of the parent
returned NS records, but
the nameservers listed in those
records did not reply, we ran a second round of queries in case
the inability to reach the latter was due to transient conditions.
The second round of queries was started shortly after the ﬁrst,
and the interval between subsequent queries varied per domain
from a few minutes to a few days. We did not re-run queries
in cases where the parent zone’s authoritative nameservers
did not reply, as we expected many of the domains in these
cases are simply not active anymore, and querying again would
create unnecessary additional trafﬁc.
Given our efforts to make our experiments efﬁcient, one
might question why we did not simply use the DNSDB to
collect data for more of our measurements. That is, why not
retrieve A and AAAA records for the nameservers we studied
and use these to infer information about replication and dele-
gation? Such an approach has been used in other works [20],
[21]. However, doing so requires certain assumptions about
the coverage of the PDNS dataset that are not suitable for
our study. For example, these other studies generally examine
domains at the second level of the DNS hierarchy, whereas
we largely study domains at lower levels. Less than 1% of
the domains we examined were second-level domains. Most
(85.4%) were third-level domains and 10.9% were fourth-
level domains. Information for domains below the second level
may not appear in zone ﬁles. Further, PDNS data could not
support some of the measurements we wished to conduct, such
as identifying unresponsive nameservers. Thus, we relied on
the PDNS data to build our list of domains to query, and
used active measures to assess the state of these domains’
authoritative nameserver deployments.
Figures 2 and 3 summarize the statistics of the PDNS data.
As Figure 2 shows, the number of domains with NS records
seen in the data grew from 113.5 thousand in 2011 to 192.6
thousand in 2020. The slight decrease from 2019 to 2020
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 13:16:58 UTC from IEEE Xplore.  Restrictions apply. 
195
Fig. 2: Number of domains and countries with data in PDNS
from 2011 to 2020
Fig. 3: Number of nameservers in PDNS from 2011 to 2020
appears to be due to a consolidation of the domains for gov-
ernments at different levels in China. Figure 3 shows similar
growth patterns in the number of nameservers (hostnames).
Our active data collection yielded 115 thousand domains with
at least one response from a nameserver in the parent zone.
For 96 thousand of domains, at least one such response was
not empty. Figure 4 shows the distribution of the domains in
the PDNS in 2020 by country. As this ﬁgure shows, some
countries with relatively large populations and developed e-
governments have relatively little data in our dataset. We
consider that there are two main reasons for this. First, a
country’s e-government may be highly centralized and use few
zones. Second, the country may use a domain other than that
which is associated with the national portal for many of its
e-government resources. We discuss this limitation further in
V, and in the following sections we present results by country
in addition to aggregated numbers.
C. Data Filtering
We ﬁltered the PDNS data by removing records that ap-
peared for only a short time. Such records may represent
a variety of scenarios, including misconﬁgurations, the use
of DDoS protection services, or domain expiration. We are
primarily interested in characterizing stable, consistent deploy-
ment strategies, and thus we removed records in which the
difference between the last-seen and ﬁrst-seen timestamps was
less than a minimum number of days. We set this minimum
based on the maximum TTLs of a few popular resolvers [22]–
[26], selecting the largest TTL, 7 days. In a scenario where
an issue can be quickly detected and corrected, we expect the
incorrect records could continue to show up for 7 days due to
caching. Thus, we use a duration of 7 days as a threshold to
differentiate between stable and transient records.
A second step in ﬁltering the PDNS involves identifying the
earliest date on which we can consider that a domain was used
Fig. 4: Number of domains per country in PDNS data, 2020
by a government entity. For those dgov where we use a sufﬁx,
the sufﬁx is reserved for government use. We assume that this
restriction has been in effect from the time delegations within
the associated zone began. Thus, while we may not have any
data for the domain at the start of the period, we are unlikely to
have data for a non-government entity using that domain. For
other domains, we use the Web Archive [27] to ﬁnd the earliest
date on which a website appeared at the domain belonging
to a government entity. While fraudulent websites posing as
ofﬁcial resources are common, we consider it unlikely that a
government would take over a website previously controlled
by imposters and use that domain to serve legitimate content.
D. Ethical Considerations
In our study, a primary concern was to ensure our mea-
surements would not create an unreasonable load, and that
operators of the domains we queried could identify and contact
us. To that end, the server used to run measurements was
assigned a static IP address, for which a PTR was created to
indicate that the server was used for research purposes. We
also limited the rate of our queries. Also, in the case of PDNS
data, user privacy is the primary concern. The data we deal
with has all information that might identify original clients
removed [28]. Additionally, for the studied domains, we do not
attempt to reconstruct zone ﬁles or map a domain’s network.
We have taken steps toward responsible disclosure, contacting
operators of domains in which we found vulnerabilities.
IV. CHARACTERIZATION OF GOVERNMENT DNS
This section presents the results of various measurements of
ADNS conﬁgurations, including measurements of replication,
dependency, delegation, and consistency.
A. Nameserver Replication
The number of designated authoritative nameservers is one
important metric for assessing a domain’s availability and
reliability. Relevant RFCs require that a domain have at least 2
authoritative nameservers, and note that in many cases having
more than 2 is better [9], [11]. Further, these nameservers
should be in different physical locations and networks [11].
Although there is some debate as to whether replication is
practical in all scenarios [29], the number of a domain’s name-
servers does provide a helpful perspective on the domain’s
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 13:16:58 UTC from IEEE Xplore.  Restrictions apply. 
196
Fig. 5: Illustration of identifying the number of authoritative
nameservers for a domain in a given year
ADNS deployment strategy, and is often used by researchers
for examining ADNS deployments [21], [30]–[32].
In the following discussion, we refer to a domain relying
on a single authoritative nameserver as d1N S . We examined
trends in the prevalence of such domains over the past decade
using the PDNS data by identifying the deployment strategy
per domain per year. That is, for a domain, d, in any given
year, we ﬁrst determined how many nameservers d used on
each day of the year. We represented this information as a
list N Sdaily, where each element is a number that represents
the number of nameservers that were in the NS records for d
on each date (see Figure 5). N Sdaily can contain up to 366
elements, or as few as 1 element (since we do not consider
days on which no NS records appear to be active). We used
the mode of N Sdaily to represent the state for d for that year.
Single-nameserver Domains. The results of our measure-
ments on the change in the prevalence of d1N Ss over the
past decade inform us of a mixed story. Between 2011 and
2020, the total number of d1N Ss increased, but at a lower
rate than the overall number of domains in the dataset. The
former increases by a factor of 1.2 (from 4.8 thousand to
5.9 thousand), and the latter by a factor of 1.7 (from 113.5
thousand to 192.6 thousand). For most countries, the number
of d1N Ss decreases (34) or remains the same (98). In most
cases (92), those countries experiencing no change had no
d1N S. The increase in the percent of domains using at least
2 nameservers seems to indicate a trend towards increased
replication. However, as the total number of d1N Ss also
appears to have increased, this is clearly a persistent pattern.
To understand this pattern, we examined the d1N Ss further.
For each year, in the range [2012, 2020], we computed the
percentage of the d1N Ss that were new, and the percentage of
that were observed to be using a single nameserver in 2011.
We also found what percent of d1N Ss from 2011 were no
longer active. As shown in Figure 6, the overlap decreases
steadily, and by 2020, only 21% of the d1N S from 2011 were
still active. Measuring the overlap between sequential years
yielded similar results. The percentage of all d1N Ss that were
new in a given year ranged 14%-23%, and the percentage that
were no longer seen was 16%-26%. This consistent change
suggests that the pattern of d1N Ss cannot be attributed to
a single group of domains that exist across the years, but
to persistent patterns in authoritative NS deployments. We
Fig. 6: Changes in set of of all d1N S per year
Fig. 7: The percentage of D1N S and of all domains using a
private ADNS deployment per year
also examined what percent of the d1N Ss each year were
using a private ADNS deployment strategy. We considered a
domain to be using a private deployment if the nameserver
hostname was in the same dgov as that domain. As the
governments we examined may operate nameservers in other
domains, our measurement represents a lower bound on the
private deployment. As shown in Figure 7, the percentage
of d1N Ss using a private ADNS deployment each year was
over 71%r, while the percentage of domains overall using
a such a deployment was less than 34%. Investigating some
of these cases suggested some d1N Ss belonged to relatively
small entities. For such domains, the resilience gained by
having multiple nameservers may not merit the effort required
to operate them, or the security risks involved in using a
third-party provider. We investigate the question of third-party
providers further in the next section.
We considered what insights we could obtain into current