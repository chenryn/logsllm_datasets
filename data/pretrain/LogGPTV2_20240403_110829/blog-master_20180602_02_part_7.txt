3、查看GPU内存使用量  
nvidia-smi   
```  
Sat Jun  2 19:03:52 2018         
+-----------------------------------------------------------------------------+  
| NVIDIA-SMI 396.26                 Driver Version: 396.26                    |  
|-------------------------------+----------------------+----------------------+  
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |  
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |  
|===============================+======================+======================|  
|   0  GeForce MX150       On   | 00000000:01:00.0 Off |                  N/A |  
| N/A   40C    P8    N/A /  N/A |    727MiB /  2002MiB |      0%      Default |  
+-------------------------------+----------------------+----------------------+  
+-----------------------------------------------------------------------------+  
| Processes:                                                       GPU Memory |  
|  GPU       PID   Type   Process name                             Usage      |  
|=============================================================================|  
|    0     18556      C   ...bgworker: PG-Strom GPU memory keeper      717MiB |  
+-----------------------------------------------------------------------------+  
```  
4、测试全量聚合  
```  
postgres=# explain (analyze,verbose,timing,costs,buffers) select c1,count(*) from ft1 group by 1;  
                                                                 QUERY PLAN                                                                    
---------------------------------------------------------------------------------------------------------------------------------------------  
 GroupAggregate  (cost=50885.38..50887.43 rows=1 width=10) (actual time=20307.148..20313.774 rows=32768 loops=1)  
   Output: c1, pgstrom.sum((pgstrom.nrows()))  
   Group Key: ft1.c1  
   ->  Sort  (cost=50885.38..50885.89 rows=204 width=10) (actual time=20307.143..20308.607 rows=32768 loops=1)  
         Output: c1, (pgstrom.nrows())  
         Sort Key: ft1.c1  
         Sort Method: quicksort  Memory: 3073kB  
         ->  Custom Scan (GpuPreAgg)  (cost=50875.00..50877.55 rows=204 width=10) (actual time=20299.260..20301.464 rows=32768 loops=1)  
               Output: c1, (pgstrom.nrows())  
               Reduction: Local  
               GPU Projection: ft1.c1, pgstrom.nrows()  
               ->  Foreign Scan on public.ft1  (cost=0.00..0.00 rows=100000000 width=2) (actual time=0.002..6229.338 rows=100000000 loops=1)  
                     Output: c1  
 Planning time: 0.088 ms  
 Execution time: 20447.266 ms  
(15 rows)  
```  
5、测试GPU 内部 FILTER  
```  
postgres=# explain (analyze,verbose,timing,costs,buffers) select c1,count(*) from ft1 where c2=1 group by 1;  
                                                                 QUERY PLAN                                                                    
---------------------------------------------------------------------------------------------------------------------------------------------  
 GroupAggregate  (cost=300885.38..300887.43 rows=1 width=10) (actual time=3881.090..3881.615 rows=2817 loops=1)  
   Output: c1, pgstrom.sum((pgstrom.nrows()))  
   Group Key: ft1.c1  
   ->  Sort  (cost=300885.38..300885.89 rows=204 width=10) (actual time=3881.085..3881.169 rows=2817 loops=1)  
         Output: c1, (pgstrom.nrows())  
         Sort Key: ft1.c1  
         Sort Method: quicksort  Memory: 229kB  
         ->  Custom Scan (GpuPreAgg)  (cost=300875.00..300877.55 rows=204 width=10) (actual time=3880.511..3880.677 rows=2817 loops=1)  
               Output: c1, (pgstrom.nrows())  
               Reduction: Local  
               GPU Projection: ft1.c1, pgstrom.nrows()  
               ->  Foreign Scan on public.ft1  (cost=0.00..250000.00 rows=100000000 width=2) (actual time=0.917..3860.842 rows=2955 loops=1)  
                     Output: c1  
                     Filter: (ft1.c2 = 1)  
                     Rows Removed by Filter: 99997045  
 Planning time: 0.107 ms  
 Execution time: 4007.820 ms  
(17 rows)  
```  
6、测试GPU 内部 JOIN  
```  
postgres=# explain (analyze,verbose,timing,costs,buffers) select ft1.c1, count(*) from ft1 join ft2 on (ft1.id=ft2.id and ft1.c1=1 and ft2.c1=1) group by 1;  
                                                                     QUERY PLAN                                                                        
-----------------------------------------------------------------------------------------------------------------------------------------------------  
 GroupAggregate  (cost=177345263386.38..177345263388.43 rows=1 width=10) (actual time=4283.412..4283.412 rows=0 loops=1)  
   Output: ft1.c1, pgstrom.sum((pgstrom.nrows()))  
   Group Key: ft1.c1  
   Buffers: temp read=124 written=62  
   ->  Sort  (cost=177345263386.38..177345263386.89 rows=204 width=10) (actual time=4283.410..4283.410 rows=0 loops=1)  
         Output: ft1.c1, (pgstrom.nrows())  
         Sort Method: quicksort  Memory: 25kB  
         Buffers: temp read=124 written=62  
         ->  Custom Scan (GpuPreAgg)  (cost=177345263376.00..177345263378.55 rows=204 width=10) (actual time=4283.408..4283.408 rows=0 loops=1)  
               Output: ft1.c1, (pgstrom.nrows())  
               Reduction: Local  
               GPU Projection: ft1.c1, pgstrom.nrows()  
               Buffers: temp read=124 written=62  
               ->  Hash Join  (cost=189063.00..175001509376.00 rows=5000000000000 width=2) (actual time=4283.216..4283.216 rows=0 loops=1)  
                     Output: ft1.c1  
                     Hash Cond: (ft1.id = ft2.id)  
                     Buffers: temp read=124 written=62  
                     ->  Foreign Scan on public.ft1  (cost=0.00..250000.00 rows=100000000 width=6) (actual time=0.518..3868.533 rows=3107 loops=1)  
                           Output: ft1.c1, ft1.id  
                           Filter: (ft1.c1 = 1)  
                           Rows Removed by Filter: 99996893  
                     ->  Hash  (cost=25000.00..25000.00 rows=10000000 width=4) (actual time=398.192..398.192 rows=311 loops=1)  
                           Output: ft2.id  
                           Buckets: 1048576  Batches: 32  Memory Usage: 8193kB  
                           ->  Foreign Scan on public.ft2  (cost=0.00..25000.00 rows=10000000 width=4) (actual time=0.404..393.045 rows=311 loops=1)  
                                 Output: ft2.id  
                                 Filter: (ft2.c1 = 1)  
                                 Rows Removed by Filter: 9999689  
 Planning time: 0.118 ms  
 Execution time: 4394.235 ms  
(30 rows)  
```  
7、注意数据库重启时，会清除gstore_fdw外部表的内容。  
### 问题  
开启gstore_fdw字段的压缩属性，写入该字段时，会导致数据库CRASH.   
https://github.com/heterodb/pg-strom/issues/368  
这个版本已修复   
https://github.com/heterodb/pg-strom/commit/06abf8a73d484a09cc58ec794e4d61bfe1cd5d01   
## 小结  
- test1表字段数：9，记录数：1000万。  
- test2表字段数：9，记录数：1亿。  
- CPU：INTEL i7 8550u 。  
- GPU：NVIDIA MX150 。  
- SSD：三星 SM961 256G 。  
case | 计算单元 | 耗时   
---|---|---  
1亿记录COUNT 无过滤条件 | CPU 单核 | 10.3秒  
1亿记录COUNT 无过滤条件 | CPU 并行度8 | 3.9秒  
1亿记录COUNT 无过滤条件 | GPU | 19.2秒  
1亿记录COUNT 无过滤条件 | GPU-DIO-SSD | 10.5秒  
1亿记录COUNT 无过滤条件 | GPU-DIO-SSD + CCACHE | 1秒  
1亿记录COUNT 有过滤条件 | CPU + GPU Hybrid 并行度8 | 13.6秒  
1亿记录COUNT 有过滤条件 | CPU + GPU-DIO-SSD Hybrid 并行度2 | 7.8秒  
1亿记录COUNT 有过滤条件 | GPU-DIO-SSD + CCACHE | 1.8秒  
1亿记录分组聚合 无过滤条件 | GPU-memory Foreign Table | 20.4秒  
1亿记录分组聚合 有过滤条件 | GPU-memory Foreign Table | 4秒  
1000万 JOIN 1亿 无过滤条件 | CPU + GPU Hybrid 并行度4 | 19.5秒  
1000万 JOIN 1亿 无过滤条件 | CPU + GPU-DIO-SSD Hybrid 并行度4 | 16.6秒  
1000万 JOIN 1亿 有过滤条件 | CPU 并行度8 | 3.1秒  
1000万 JOIN 1亿 有过滤条件 | GPU-memory Foreign Table | 4.4秒  
HeteroDB pg_strom是PG的一个GPU加速插件，目前已支持到PG 11的版本。  
在这些场景中可以加速查询，非常适合计算型场景（OLAP场景）  
1、FILTER  
2、聚合  
3、JOIN  
4、GROUP BY  
同时PG_strom还引入了一些高级特性：  
1、结合PG CPU并行计算，实现CPU + GPU混合并行，使得计算能力大幅提升  
2、GPU直接访问SSD，节约内存，同时缩短访问路径，提高了访问吞吐  
3、创建堆表的外部列存格式副本(支持存储在内存目录或普通目录中，建议可以存在高速SSD目录)，custom scan自动识别，如果有列存副本，优先使用列存副本，提高OLAP SQL性能  
使用ccache后，MX150 这样的民用GPU加速比I7 8550U CPU 8个并行快3倍。   
4、可以将经常需要计算的表，加载到GPU的内存中，GPU对这部分数据重复计算时，不需要重复从内存或磁盘加载。  
5、结合PG 11的partition table的智能JOIN，GROUP，可以提高并行计算能力。   
[《PostgreSQL 11 preview - 分区表智能并行JOIN (已类似MPP架构，性能暴增)》](../201802/20180202_02.md)  
[《PostgreSQL 11 preview - 分区表智能并行聚合、分组计算(已类似MPP架构，性能暴增)》](../201803/20180322_07.md)  
GPU的引入，无疑又拔高了数据库的分析能力。以上使用民用硬件对pg_strom进行了一系列测试，生产中的硬件要被测试好很多很多，GPU的加速会更加的明显。    
![pic](20180602_02_pic_005.jpg)    
![pic](20180602_02_pic_006.jpg)    
GPU-DIO-SSD相比非GPU-DIO-SSD，避免了读数据需要绕一下内存的路径，整体性能肯定是提升的。但是这个GPU本身是入门级，所以还达不到CPU I7 8550U的性能。  
目前heteroDB稳定性还有打磨的空间，kaigai响应及时，发ISSUE后，kaigai马上就FIX了。    
## 参考  
https://github.com/heterodb/pg-strom  
http://heterodb.github.io/pg-strom/ref_params/  
https://www.brytlyt.com/  
https://images.nvidia.com/content/tesla/pdf/Apps-Catalog-March-2016.pdf  
#### [PostgreSQL 许愿链接](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216")
您的愿望将传达给PG kernel hacker、数据库厂商等, 帮助提高数据库产品质量和功能, 说不定下一个PG版本就有您提出的功能点. 针对非常好的提议，奖励限量版PG文化衫、纪念品、贴纸、PG热门书籍等，奖品丰富，快来许愿。[开不开森](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216").  
#### [9.9元购买3个月阿里云RDS PostgreSQL实例](https://www.aliyun.com/database/postgresqlactivity "57258f76c37864c6e6d23383d05714ea")
#### [PostgreSQL 解决方案集合](https://yq.aliyun.com/topic/118 "40cff096e9ed7122c512b35d8561d9c8")
#### [德哥 / digoal's github - 公益是一辈子的事.](https://github.com/digoal/blog/blob/master/README.md "22709685feb7cab07d30f30387f0a9ae")
![digoal's wechat](../pic/digoal_weixin.jpg "f7ad92eeba24523fd47a6e1a0e691b59")
#### [PolarDB 学习图谱: 训练营、培训认证、在线互动实验、解决方案、生态合作、写心得拿奖品](https://www.aliyun.com/database/openpolardb/activity "8642f60e04ed0c814bf9cb9677976bd4")
#### [购买PolarDB云服务折扣活动进行中, 55元起](https://www.aliyun.com/activity/new/polardb-yunparter?userCode=bsb3t4al "e0495c413bedacabb75ff1e880be465a")
#### [About 德哥](https://github.com/digoal/blog/blob/master/me/readme.md "a37735981e7704886ffd590565582dd0")