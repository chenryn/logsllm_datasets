关键方法：`maybeReloadConfiguration`方法  
关键语句：this.importer.maybeReloadConfiguration(requestParams, defaultParams);
> 图1  
>
> 
跟进(Step into)关键方法 `maybeReloadConfiguration` 方法
> 图2  
>
> 
关键语句：String dataConfigText = params.getDataConfig();//获取HTTP请求中POST
body中的参数`dataConfig`的值  
执行逻辑：maybeReloadConfiguration方法体中，会获取HTTP请求中POST
body中的参数`dataConfig`的值，即“DataConfig配置信息“，如果该值不为空则该值传递给`loadDataConfig`方法(功能是加载DataConfig配置信息)
本次调试过程中的"DataConfig配置信息"：
解释：  
``表示数据源的类型为URLDataSource
并且该数据源的实体，属性如下
跟进(Step into)关键方法 `loadDataConfig`方法
> 图3  
>
> 
执行逻辑：loadDataConfig方法的具体实现中，调用了`readFromXml`方法，从xml数据中读取信息。  
关键语句：dihcfg = this.readFromXml(document);
跟进(Step into)关键方法 `readFromXml`方法
> readFromXml方法体  
>
> 
关键语句：`return new DIHConfiguration((Element)documentTags.get(0), this,
functions, script, dataSources, pw);`
执行逻辑：`readFromXml`方法的具体实现中，根据各种不同名称的标签(如document，script，function，dataSource等)，得到了配置数据中的元素。如，配置信息中的自定义脚本在此处被赋值给名为`script`的`Script`类型的变量中。使用“迭代器“递归解析完所有标签后，new一个DIHConfiguration对象(传入的6个实参中有个是script变量），这个DIHConfiguration对象作为`readFromXml`方法的返回值，被return。
该DIHConfiguration对象，实际赋值给了（调用`readFromXml`方法的）
loadDataConfig方法体中的名为`dihcfg`的变量。（见图3）
回溯：现在的情况是，之前在loadDataConfig方法体中调用了的`readFromXml`方法已经执行结束并返回了一个DIHConfiguration对象，赋值给了loadDataConfig方法体中的那个名为`dihcfg`的变量，loadDataConfig方法成功获取到配置信息。
回溯：现在的情况是，之前的maybeReloadConfiguration方法体中调用了的loadDataConfig方法执行结束，DataImporter类的maybeReloadConfiguration方法也得到它需要的boolean返回值，true(见图2)
DataImporter类 org.apache.solr.handler.dataimport.DataImporter
DataImporter类 包含的方法和变量，如图，重点关注的方法是：
    maybeReloadConfiguration方法 - boolean maybeReloadConfiguration(RequestInfo params, NamedList defaultParams)
    doFullImport方法 - public void doFullImport(DIHWriter writer, RequestInfo requestParams) 
    runCmd方法
> DataImporter类 包含的方法和变量  
>
>   
>
> 
回溯：现在的情况可参考图0，回到了DataImportHandler类的`handleRequestBody`方法体中，在该方法体中调用了的(DataImporter类中的)maybeReloadConfiguration方法已经执行结束，继续向下执行到关键语句`this.importer.runCmd(requestParams,
sw);`调用了(DataImporter类中的)runCmd方法
跟进(Step into)关键方法 ：(DataImporter类中的)runCmd方法
> 图4 - runCmd方法的方法体  
>
> 
跟进DataImporter类中的doFullImport方法体
> doFullImport方法体  
>
> 
功能如下  
首先创建一个DocBuilder对象。  
DocBuilder对象的主要功能是从给定配置中创建Solr文档 该对象具有名为`config`的`DIHConfiguration`类型的成员变量 见代码
`private DIHConfiguration config;`
然后调用该DocBuilder对象的execute()方法，作用是使用“迭代器“
`this.config.getEntities().iterator();`  
，解析"DIH配置"
即名为`config`的`DIHConfiguration`类型的成员变量，根据“属性名称“（如preImportDeleteQuery、postImportDeleteQuery、）获得Entity的所有属性。
最终得到是一个EntityProcessorWrapper对象。
简单介绍下DocBuilder类。  
DocBuilder类 org.apache.solr.handler.dataimport.DocBuilder
DocBuilder类 包含的方法，如下图，重点关注：
    execute()方法  -   public void execute()
    doFullDump()方法  -   private void doFullDump()
> DocBuilder类 包含的方法  
>
> 
简单介绍下EntityProcessorWrapper类。  
EntityProcessorWrapper类
org.apache.solr.handler.dataimport.EntityProcessorWrapper
EntityProcessorWrapper是一个比较关键的类，继承自EntityProcessor，在整个解析过程中起到重要的作用。
EntityProcessorWrapper类的更多信息参考  
EntityProcessorWrapper类 包含的方法，如下图，重点的是：  
loadTransformers()方法 - 作用：加载转换器
> EntityProcessorWrapper类 包含的方法  
>
> 
在解析完config数据后，solr会把最后“更新时间“记录到配置文件中，这个时间是为了下次进行增量更新的时候用的。  
接着通过this.dataImporter.getStatus()判断当前数据导入是“增量导入”即doDelta()方法，还是“全部导入”即doFullDump()方法。  
本次调试中的操作是全部导入”，因此调用doFullDump()方法
> execute方法中的doFullDump()方法  
>
> 
跟进DocBuilder类中的doFullDump方法体：
    private void doFullDump() {
            this.addStatusMessage("Full Dump Started");
            this.buildDocument(this.getVariableResolver(), (DocBuilder.DocWrapper)null, (Map)null, this.currentEntityProcessorWrapper, true, (ContextImpl)null);
        }
可见，在doFullDump()方法体中，调用的是DocBuilder类中的buildDocument()方法。  
作用是为发送的配置数据的每一个Processor做解析(调用`getVariableResolver()`方法)，当发送的entity中含有Transformers时，会进行相应的转换操作。
例如 DateFormatTransformer 转换成日期格式  
例如 RegexTransformer 根据正则表达式转换  
例如 ScriptTransformer 根据用户自定义的脚本进行数据转换(漏洞关键：脚本内容完全用户可控！！)  
等等
具体如何执行JavaScript脚本？继续跟进，DocBuilder类中的buildDocument()方法。
    private void buildDocument(VariableResolver vr, DocBuilder.DocWrapper doc, Map pk, EntityProcessorWrapper epw, boolean isRoot, ContextImpl parentCtx, List entitiesToDestroy) {
            ContextImpl ctx = new ContextImpl(epw, vr, (DataSource)null, pk == null ? "FULL_DUMP" : "DELTA_DUMP", this.session, parentCtx, this);
            epw.init(ctx);
            if (!epw.isInitialized()) {
                entitiesToDestroy.add(epw);
                epw.setInitialized(true);
            }
            if (this.reqParams.getStart() > 0) {
                this.getDebugLogger().log(DIHLogLevels.DISABLE_LOGGING, (String)null, (Object)null);
            }
            if (this.verboseDebug) {
                this.getDebugLogger().log(DIHLogLevels.START_ENTITY, epw.getEntity().getName(), (Object)null);
            }
            int seenDocCount = 0;
            try {
                while(!this.stop.get()) {
                    if (this.importStatistics.docCount.get() > (long)this.reqParams.getStart() + this.reqParams.getRows()) {
                        return;
                    }
                    try {
                        ++seenDocCount;
                        if (seenDocCount > this.reqParams.getStart()) {
                            this.getDebugLogger().log(DIHLogLevels.ENABLE_LOGGING, (String)null, (Object)null);
                        }
                        if (this.verboseDebug && epw.getEntity().isDocRoot()) {
                            this.getDebugLogger().log(DIHLogLevels.START_DOC, epw.getEntity().getName(), (Object)null);
                        }
                        if (doc == null && epw.getEntity().isDocRoot()) {
                            doc = new DocBuilder.DocWrapper();
                            ctx.setDoc(doc);
                            for(Entity e = epw.getEntity(); e.getParentEntity() != null; e = e.getParentEntity()) {
                                this.addFields(e.getParentEntity(), doc, (Map)vr.resolve(e.getParentEntity().getName()), vr);
                            }
                        }
                        Map arow = epw.nextRow();
                        if (arow == null) {
                            return;
                        }
                        if (epw.getEntity().isDocRoot()) {
                            if (seenDocCount  (long)this.reqParams.getStart() + this.reqParams.getRows()) {
                                log.info("Indexing stopped at docCount = " + this.importStatistics.docCount);
                                return;
                            }
                        }
                        if (this.verboseDebug) {
                            this.getDebugLogger().log(DIHLogLevels.ENTITY_OUT, epw.getEntity().getName(), arow);
                        }
                        this.importStatistics.rowsCount.incrementAndGet();
                        DocBuilder.DocWrapper childDoc = null;
                        if (doc != null) {
                            if (epw.getEntity().isChild()) {
                                childDoc = new DocBuilder.DocWrapper();
                                this.handleSpecialCommands(arow, childDoc);
                                this.addFields(epw.getEntity(), childDoc, arow, vr);
                                doc.addChildDocument(childDoc);
                            } else {
                                this.handleSpecialCommands(arow, doc);
                                vr.addNamespace(epw.getEntity().getName(), arow);
                                this.addFields(epw.getEntity(), doc, arow, vr);
                                vr.removeNamespace(epw.getEntity().getName());
                            }
                        }
                        if (epw.getEntity().getChildren() != null) {
                            vr.addNamespace(epw.getEntity().getName(), arow);
                            Iterator var12 = epw.getChildren().iterator();
                            while(var12.hasNext()) {
                                EntityProcessorWrapper child = (EntityProcessorWrapper)var12.next();
                                if (childDoc != null) {
                                    this.buildDocument(vr, childDoc, child.getEntity().isDocRoot() ? pk : null, child, false, ctx, entitiesToDestroy);
                                } else {
                                    this.buildDocument(vr, doc, child.getEntity().isDocRoot() ? pk : null, child, false, ctx, entitiesToDestroy);
                                }
                            }
                            vr.removeNamespace(epw.getEntity().getName());
                        }
                        if (epw.getEntity().isDocRoot()) {
                            if (this.stop.get()) {
                                return;
                            }
                            if (!doc.isEmpty()) {
                                boolean result = this.writer.upload(doc);
                                if (this.reqParams.isDebug()) {
                                    this.reqParams.getDebugInfo().debugDocuments.add(doc);
                                }
                                doc = null;
                                if (result) {
                                    this.importStatistics.docCount.incrementAndGet();
                                } else {
                                    this.importStatistics.failedDocCount.incrementAndGet();
                                }
                            }
                        }
                    } catch (DataImportHandlerException var24) {
                        if (this.verboseDebug) {
                            this.getDebugLogger().log(DIHLogLevels.ENTITY_EXCEPTION, epw.getEntity().getName(), var24);
                        }
                        if (var24.getErrCode() != 301) {
                            if (!isRoot) {
                                throw var24;
                            }
                            if (var24.getErrCode() == 300) {
                                this.importStatistics.skipDocCount.getAndIncrement();
                                doc = null;
                            } else {
                                SolrException.log(log, "Exception while processing: " + epw.getEntity().getName() + " document : " + doc, var24);
                            }
                            if (var24.getErrCode() == 500) {
                                throw var24;
                            }
                        }
                    } catch (Exception var25) {