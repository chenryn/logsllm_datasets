if (!-f \$request_filename){
break;
proxy_pass http://127.0.0.1;
} //如果请求的文件名不存在，则反向代理到localhost
。这里的break也是停止rewrite检查
if (\$args \~ post=140){
rewrite \^ http://example.com/ permanent;
} //如果query string中包含\"post=140\"，永久重定向到example.com
location \~\* \\.(gif\|jpg\|png\|swf\|flv)\$ {
valid_referers none blocked www.jefflei.com www.leizhenfang.com;
if (\$invalid_referer) {
return 404;
} //防盗链
}
# Nginx 配置 location 以及 return、rewrite 和 try_files 指令
# 七财公司实战nginx配置文件解释：
## 案例一：全局配置nginx.confg
user nobody;
worker_processes 4; #worker角色的工作进程的个数
error_log logs/error.log; #指定日志文件
pid logs/nginx.pid; #记录pid的文件
events {
use epoll;
#nginx默认使用epoll事件模型，因此nginx在Linux操作系统下效率相当高
worker_connections 51200;
#每一个worker进程能并发处理（发起）的最大连接数
}
http {
include mime.types;
default_type application/octet-stream;
log_format main \'\$remote_addr - \[\$time_local\] \"\$request\" \'
\'\$status \$body_bytes_sent \"\$http_referer\" \'
\'\"\$http_user_agent\" \"\$http_x\_forwarded_for\"\';
#access_log logs/access.log main;
server_tokens off; #隐藏nginx版本号
sendfile on;
tcp_nopush on;
server_names_hash_bucket_size 256;
client_header_buffer_size 256k;
keepalive_timeout 300s 60s;
large_client_header_buffers 4 256k;
client_body_buffer_size 256k;
client_header_timeout 3m;
client_body_timeout 3m;
send_timeout 3m;
client_max_body_size 100m;
gzip on; #开启gzip压缩输出，减少网络传输
gzip_min_length 1k;
#允许压缩的页面最小字节数，建议大于1k的字节数，小于1k可能会越压越大
gzip_buffers 4 16k; #安装原始数据大小以16k为单位的4倍申请内存
gzip_http_version 1.0; #用于识别 http 协议的版本
gzip_comp_level 2; \#
gzip压缩比，1压缩比最小处理速度最快，9压缩比最大但处理速度最慢
gzip_types text/plain application/x-javascript text/css application/xml;
#这些类型都会被压缩
gzip_vary on; #在响应头加Vary:
Accept-Encoding，让前端的缓存服务器缓存经过gzip压缩的页面
proxy_connect_timeout 300s;
proxy_read_timeout 300s;
proxy_send_timeout 300s;
proxy_buffer_size 16k;
proxy_buffers 4 64k;
proxy_busy_buffers_size 128k;
proxy_temp_file_write_size 128k;
proxy_temp_path /opt/tmp_dir;
proxy_cache_path /opt/cache levels=1:2 keys_zone=cache_one:200m
inactive=1d max_size=30g;
include vhost/\*.conf;
}
main全局配置：
main全局配置说明：nginx在运行时与具体业务功能（比如http服务或者email服务代理）无关的一些参数，比如工作进程数，运行的身份等。
-   woker_processes
    2：在配置文件的顶级main部分，worker角色的工作进程的个数，master进程是接收并分配请求给worker处理。这个数值简单一点可以设置为cpu的核数grep
    \^processor /proc/cpuinfo \| wc -l，也是 auto
    值，如果开启了ssl和gzip更应该设置成与逻辑CPU数量一样甚至为2倍，可以减少I/O操作。如果nginx服务器还有其它服务，可以考虑适当减少。
-   worker_cpu_affinity：也是写在main部分。在高并发情况下，通过设置cpu粘性来降低由于多CPU核切换造成的寄存器等现场重建带来的性能损耗。如worker_cpu_affinity
    0001 0010 0100 1000; （四核）。
-   worker_rlimit_nofile
    10240：写在main部分。默认是没有设置，可以限制为操作系统最大的限制65535。
events部分：
events部分说明：
-   worker_connections
    2048：写在events部分。每一个worker进程能并发处理（发起）的最大连接数（包含与客户端或后端被代理服务器间等所有连接数）。nginx作为反向代理服务器，计算公式
    最大连接数 = worker_processes \*
    worker_connections/4，所以这里客户端最大连接数是1024，这个可以增到到8192都没关系，看情况而定，但不能超过前面的worker_rlimit_nofile的参数。当nginx作为http服务器时，计算公式里面是除以2。
-   use
    epoll：写在events部分。在Linux操作系统下，nginx默认使用epoll事件模型，得益于此，nginx在Linux操作系统下效率相当高。同时Nginx在OpenBSD或FreeBSD操作系统上采用类似于epoll的高效事件模型kqueue。在操作系统不支持这些高效模型时才使用select。
http部分：
http部分说明：与提供http服务相关的一些配置参数。例如：是否使用keepalive，是否使用gzip进行压缩等。
-   sendfile
    on：开启高效文件传输模式，sendfile指令指定nginx是否调用sendfile函数来输出文件，减少用户空间到内核空间的上下文切换。对于普通应用设为
    on，如果用来进行下载等应用磁盘IO重负载应用，可设置为off，以平衡磁盘与网络I/O处理速度，降低系统的负载。
-   keepalive_timeout 65 :
    长连接超时时间，单位是秒，这个参数很敏感，涉及浏览器的种类、后端服务器的超时设置、操作系统的设置，可以另外起一片文章了。长连接请求大量小文件的时候，可以减少重建连接的开销，但假如有大文件上传，65s内没上传完成会导致失败。如果设置时间过长，用户又多，长时间保持连接会占用大量资源。
-   send_timeout :
    用于指定响应客户端的超时时间。这个超时仅限于两个连接活动之间的时间，如果超过这个时间，客户端没有任何活动，Nginx将会关闭连接。
-   client_max_body_size
    10m：允许客户端请求的最大单文件字节数。如果有上传较大文件，请设置它的限制值
-   client_body_buffer_size 128k：缓冲区代理缓冲用户端请求的最大字节数
http_proxy模块部分：
http_proxy模块说明：这个模块实现的是nginx作为反向代理服务器的功能，包括缓存功能
-   proxy_connect_timeout
    60：nginx跟后端服务器连接超时时间(代理连接超时)
-   proxy_read_timeout
    60：连接成功后，与后端服务器两个成功的响应操作之间超时时间(代理接收超时)
-   proxy_buffer_size
    4k：设置代理服务器（nginx）从后端realserver读取并保存用户头信息的缓冲区大小，默认与proxy_buffers大小相同，其实可以将这个指令值设的小一点
-   proxy_buffers 4
    32k：proxy_buffers缓冲区，nginx针对单个连接缓存来自后端realserver的响应，网页平均在32k以下的话，这样设置
-   proxy_busy_buffers_size 64k：高负荷下缓冲大小（proxy_buffers\*2）
-   proxy_max_temp_file_size：当 proxy_buffers
    放不下后端服务器的响应内容时，会将一部分保存到硬盘的临时文件中，这个值用来设置最大临时文件大小，默认1024M，它与
    proxy_cache
    没有关系。大于这个值，将从upstream服务器传回。设置为0禁用。
-   proxy_temp_file_write_size
    64k：当缓存被代理的服务器响应到临时文件时，这个选项限制每次写临时文件的大小。proxy_temp_path（可以在编译的时候）：指定写到哪那个目录。
-   proxy_pass， proxy_redirect见 location 部分。
http_gzip模块部分：
-   gzip on : 开启gzip压缩输出，减少网络传输。
-   gzip_min_length
    1k：设置允许压缩的页面最小字节数，页面字节数从header头得content-length中进行获取。默认值是20。建议设置成大于1k的字节数，小于1k可能会越压越大。
-   gzip_buffers 4
    16k：设置系统获取几个单位的缓存用于存储gzip的压缩结果数据流。4
    16k代表以16k为单位，安装原始数据大小以16k为单位的4倍申请内存。
-   gzip_http_version 1.0：用于识别 http 协议的版本，早期的浏览器不支持
    Gzip
    压缩，用户就会看到乱码，所以为了支持前期版本加上了这个选项，如果你用了
    Nginx 的反向代理并期望也启用 Gzip 压缩的话，由于末端通信是
    http/1.0，故请设置为 1.0。
-   gzip_comp_level
    6：gzip压缩比，1压缩比最小处理速度最快，9压缩比最大但处理速度最慢(传输快但比较消耗cpu)
-   gzip_types：匹配mime类型进行压缩，无论是否指定,"text/html"类型总是会被压缩的。
-   gzip_proxied
    any：Nginx作为反向代理的时候启用，决定开启或者关闭后端服务器返回的结果是否压缩，匹配的前提是后端服务器必须要返回包含"Via"的
    header头。
-   gzip_vary on：和http头有关系，会在响应头加个 Vary: Accept-Encoding
    ，可以让前端的缓存服务器缓存经过gzip压缩的页面，例如，用Squid缓存经过Nginx压缩的数据。
## 案例二：proxy_set_header 请求转发
admin.kkqb.cn.conf
server {
listen 80;
server_name admin.kkqb.cn;
location / {
\# deny 192.168.1.1; #拒绝此IP访问，可设置为网络段
\# allow 222.240.39.48; #允许此IP访问，可设置为网络段
\# allow 220.168.85.54; #允许此IP访问，可设置为网络段
\# deny all; #拒绝所有，从上到下匹配
proxy_set_header Host \$http_host; #请求头重写
proxy_set_header X-Real-IP \$remote_addr;
#可使web服务器端获得用户的真实ip,\$remote_add客户端地址
proxy_set_header X-Forwarded-For \$proxy_add_x\_forwarded_for;
#可使web服务器端获得用户的真实ip
proxy_set_header X-Forwarded-Proto \$scheme; #\$scheme变量为请求方案
proxy_set_header X-Scheme \$scheme;
\# if (\$remote_addr \~\* \"220.168.85.54\|222.240.39.48\"){
\# proxy_pass http://172.16.148.28:8787;
\# }
auth_basic \"Please input password\";
auth_basic_user_file /usr/local/nginx/conf/passwd;
proxy_pass http://172.16.148.22:8787;
\# root /usr/local/nginx/html;
\# index index.html;
}
}
**proxy_set_header 解释：**
**proxy_set_header Host \$http_host;**
> nginx为了实现反向代理的需求而增加了一个ngx_http_proxy_module模块。其中proxy_set_header指令就是该模块需要读取的配置文件。在这里，所有设置的值的含义和http请求同中的含义完全相同，除了Host外还有X-Forward-For。\
> Host的含义是表明请求的主机名，因为nginx作为反向代理使用，而如果后端真是的服务器设置有类似防盗链或者根据http请求头中的host字段来进行路由或判断功能的话，如果反向代理层的nginx不重写请求头中的host字段，将会导致请求失败【默认反向代理服务器会向后端真实服务器发送请求，并且请求头中的host字段应为proxy_pass指令设置的服务器】。
**proxy_set_header X-Real-IP \$remote_addr;**
#可以使web服务器端获得用户的真实ip
> "经过反向代理后，由于在客户端和web服务器之间增加了中间层，因此web服务器无法直接拿到客户端的ip，通过\$remote_addr变量拿到的将是反向代理服务器的ip地址"。当你使用了nginx反向服务器后，在web端使用request.getRemoteAddr()（本质上就是获取\$remote_addr），取得的是nginx的地址，即\$remote_addr变量中封装的是nginx的地址，当然是没法获得用户的真实ip的，但是，nginx是可以获得用户的真实ip的，也就是说nginx使用\$remote_addr变量时获得的是用户的真实ip，如果我们想要在web端获得用户的真实ip，就必须在nginx这里作一个赋值操作，如：proxy_set_header
> X-real-ip \$remote_addr;
>
> 其中这个X-real-ip是一个自定义的变量名，名字可以随意取，这样做完之后，用户的真实ip就被放在X-real-ip这个变量里了，然后，在web端可以这样获取：request.getHeader(\"X-real-ip\")
> 这样就明白了吧。
**proxy_set_header X-Forwarded-For \$proxy_add_x\_forwarded_for;**
#可以使web服务器端获得用户的真实ip
> 有个X-Forwarded-For变量，这是一个squid开发的，用于识别通过HTTP代理或负载平衡器原始IP一个连接到Web服务器的客户机地址的非rfc标准，如果有做X-Forwarded-For设置的话,每次经过proxy转发都会有记录,格式就是client1,
> proxy1,
> proxy2,以逗号隔开各个地址，由于他是非rfc标准，所以默认是没有的，需要强制添加，在默认情况下经过proxy转发的请求，在后端看来远程地址都是proxy端的ip
> 。也就是说在默认情况下我们使用request.getHeader(\"X-Forwarded-For\")获取不到用户的ip，如果我们想要通过这个变量获得用户的ip，我们需要自己在nginx添加如：
> proxy_set_header X-Forwarded-For \$proxy_add_x\_forwarded_for;
>
> 意思是增加一个\$proxy_add_x\_forwarded_for到X-Forwarded-For里去，注意是增加，而不是覆盖，当然由于默认的X-Forwarded-For值是空的，所以我们总感觉X-Forwarded-For的值就等于\$proxy_add_x\_forwarded_for的值，实际上当你搭建两台nginx在不同的ip上，并且都使用了这段配置，那你会发现在web服务器端通过request.getHeader(\"X-Forwarded-For\")获得的将会是客户端ip和第一台nginx的ip。
**proxy_set_header X-Forwarded-Proto \$scheme;**
**proxy_set_header X-Scheme \$scheme;**
X-Forwarded-For:简称XFF头，它代表客户端，也就是HTTP的请求端真实的IP，只有在通过了HTTP
代理或者负载均衡服务器时才会添加该项。
它不是RFC中定义的标准请求头信息，在squid缓存代理服务器开发文档中可以找到该项的详细介绍。标准格式如下：X-Forwarded-For:
client1, proxy1, proxy2。
这一HTTP头一般格式如下:X-Forwarded-For: client1, proxy1, proxy2
其中的值通过一个 逗号+空格 把多个IP地址区分开,
最左边(client1)是最原始客户端的IP地址,
代理服务器每成功收到一个请求，就把请求来源IP地址添加到右边。
在上面这个例子中，这个请求成功通过了三台代理服务器：proxy1, proxy2 及
proxy3。请求由client1发出，到达了proxy3(proxy3可能是请求的终点)。请求刚从client1中发出时，XFF是空的，请求被发往proxy1；通过proxy1的时候，client1被添加到XFF中，之后请求被发往proxy2;通过proxy2的时候，proxy1被添加到XFF中，之后请求被发往proxy3；通过proxy3时，proxy2被添加到XFF中，之后请求的的去向不明，如果proxy3不是请求终点，请求会被继续转发。
鉴于伪造这一字段非常容易，应该谨慎使用X-Forwarded-For字段。正常情况下XFF中最后一个IP地址是最后一个代理服务器的IP地址,
这通常是一个比较可靠的信息来源。
## 案例三：永久重定向
www.168cd.cn.conf
server {
listen 80;
server_name www.168cd.cn 168cd.cn;
return 301 https://www.siyuanv.com\$request_uri;
location / {
root /opt/syqkl/html;
index index.html index.htm;
}
}
访问www.168cd.cn 168cd.cn 重定向到www.siyuanv.com
\$request_uri:完整的原始请求URI（带参数）
其他案例：http 重定向到 https
server {
listen 80;
server_name www.168cd.cn 168cd.cn;
return 301 https://\$server_name\$request_uri;
}
## 案例四：跨域add_header
跨域概念参考
**一、为什么会出现跨域问题**
出于浏览器的同源策略限制。同源策略（Sameoriginpolicy）是一种约定，它是浏览器最核心也最基本的安全功能，如果缺少了同源策略，则浏览器的正常功能可能都会受到影响。可以说Web是构建在同源策略基础之上的，浏览器只是针对同源策略的一种实现。同源策略会阻止一个域的javascript脚本和另外一个域的内容进行交互。所谓同源（即指在同一个域）就是两个页面具有相同的协议（protocol），主机（host）和端口号（port），所谓同源是指\"协议+域名+端口\"三者相同，即便两个不同的域名指向同一个ip地址，也非同源。
2.  **什么是跨域**
当一个请求url的协议、域名、端口三者之间任意一个与当前页面url不同即为跨域
当前页面url 被请求页面url 是否跨域 原因
http://www.test.com/ http://www.test.com/index.html 否
同源（协议、域名、端口号相同）
http://www.test.com/ https://www.test.com/index.html 跨域
协议不同（http/https）
http://www.test.com/ http://www.baidu.com/ 跨域 主域名不同（test/baidu）
http://www.test.com/ http://blog.test.com/ 跨域 子域名不同（www/blog）
http://www.test.com:8080/ http://www.test.com:7001/ 跨域
端口号不同（8080/7001）
**三、非同源限制**
【1】无法读取非同源网页的 Cookie、LocalStorage 和 IndexedDB
【2】无法接触非同源网页的 DOM 和 JS对象
【3】无法向非同源地址发送 AJAX 请求
**跨域解决方案**
1、 通过jsonp跨域
2、 document.domain + iframe跨域
3、 location.hash + iframe
4、 window.name + iframe跨域
5、 postMessage跨域
6、
跨域资源共享（CORS）：CORS是一个W3C标准，全称是跨域资源共享(Cross-origin
resource sharing)。它允许
浏览器向跨源服务器，发出XMLHttpRequest请求，从而克服了AJAX只能同源使用的限制。
7、 nginx代理跨域
8、 nodejs中间件代理跨域
9、 WebSocket协议跨域
**nginx代理跨域**
1、 nginx配置解决iconfont跨域
浏览器跨域访问js、css、img等常规静态资源被同源策略许可，但iconfont字体文件(eot\|otf\|ttf\|woff\|svg)例外，此时可在nginx的静态资源服务器中加入以下配置。
location / {
add_header Access-Control-Allow-Origin \*;
}