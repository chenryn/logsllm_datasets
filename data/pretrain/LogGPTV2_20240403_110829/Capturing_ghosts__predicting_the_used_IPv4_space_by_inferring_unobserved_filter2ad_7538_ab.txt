machines may be more likely to appear in certain traﬃc logs.
Nevertheless, heterogeneity gives rise to what is called apparent
source dependence. For example, two sources that are biased to-
wards client machines will appear to be positively dependent given
another source that is less biased towards clients. In fact it is well
known that heterogeneity and source dependence are often con-
founded and cannot be clearly separated [19]. Apparent source de-
pendence must be treated similarly to source dependence.
If there is (apparent) dependence such that two sources are pos-
itively correlated, the L-P estimator underestimates the population
size: R/C > M/N and so N > MC/R. Similarly, if two sources are
negatively correlated, the L-P estimator overestimates the popula-
tion size. If the sign of the correlation is known, then L-P estimates
can be used to identify plausible lower or upper bounds [17].
3.3 Log-linear Models
Just as L-P uses a second sample to estimate the fraction of the
population of the ﬁrst sample, a third sample can be used to com-
pensate the correlation between the ﬁrst two samples. This is the
basic idea of log-linear models (LLMs) used for CR [17, 19, 20],
which can model (apparent) source dependence among arbitrarily
many sources.
3.3.1 Description
Let N be the unknown number of distinct individuals of the pop-
ulation. Let t denote the number of sources indexed by 1, 2, . . . , t.
For each individual, let s1 to st be deﬁned such that si = 1 if the
individual occurs in sample i and si = 0 otherwise. Then the string
s1s2 . . . st is called the “capture history” of the individual. The ob-
served outcome of all measurements can then be represented by
variables of the form zs, which are the numbers of individuals with
each capture history s = s1s2 . . . st. These are assumed to be in-
stances of random variables Zs. Note that individuals with the cap-
ture history 00 . . . 0 are unobserved, and our goal is to estimate
Z00...0. Table 1 illustrates the variables Zs for each possible cap-
ture history for three sources (t = 3); “yes” means an individual
was observed and “no” means an individual was not observed by a
source.
For each history s, let h(s) be the set of sources in which the
individual occurs; for example, h(101) = {1, 3}. Deﬁne the indi-
cator function 1A = 1 if statement A is true and 0 otherwise. We
can now write the following system of equations in 2t variables
u, u1, u2, . . . , u12, . . . , u23, . . . up to u12...t:
log(E (Zs)) =
uh =
uh1h⊆h(s) .
(1)
(cid:88)
h⊆h(s)
(cid:88)
h
For example, for t = 3, the system is
(cid:16)E(cid:16)
(cid:17)(cid:17)
log
Zi jk
=u + u11i=1 + u21 j=1 + u31k=1
+ u121i=1∧ j=1 + u131i=1∧k=1
+ u231 j=1∧k=1 + u1231i=1∧ j=1∧k=1 .
The estimate of Z00...0 is then ˆZ00...0 = exp(u).
If we take
E[Zs] = zs then this system has 2t unknowns but only 2t − 1
equations, as Z00...0 is unknown. Hence it is customary to assume
u12...t = 0 [17]. As the number of sources t increases, this t-way
dependency becomes decreasingly important.
The model with all uh (the saturated model) is very sensitive to
small values of Zs. For example, a zero count for some capture
history may give ˆZ00...0 = 0, regardless of the other Zs [17]. Fur-
thermore, the larger t is, the higher is the random error for some
Zs. Including “noisy” parameters uh in a model results in a poor
predictive performance of the model (referred to as over-ﬁtting).
Over-ﬁtting is mitigated by “model selection” (see Section
3.3.2), in which some uh are forced to 0, to reﬂect assumed indepen-
dence between certain combinations of sources. For example, set-
ting u12 = 0 indicates sources 1 and 2 are independent. With such
incomplete models, the system of equations is overdetermined, and
the maximum likelihood parameters u are typically used, based on
the assumption that Zs result from uniform random sampling and
are hence Poisson distributed.
Assuming the Zs are Poisson distributed is appropriate if the up-
per limit for the Zs is unknown. However, we can bound Zs by
the size of the publicly routed IPv4 space. Hence, we use right-
truncated Poisson distributions deﬁned over [0, l] ∩ Z, where l is
the upper limit. These improve estimates substantially for small
strata, where the counters are relatively close to the limit (see Sec-
tion 5.2), but otherwise make little diﬀerence.
3.3.2 Model selection
Model selection for an LLM consists of selecting which uh will
be assumed a priori to be 0. The goal is to select the least complex
model with “adequate” ﬁt of the observed (and by assumption) un-
observed individuals [20].
A common approach is to minimize an “Information Criterion”
(IC). Two common ICs are [21]:
AIC = 2k − 2 log(L),
BIC = log(M)k − 2 log (L)
where L is the likelihood of the data given the assumed model, k
is the number of free parameters of the model and M is the num-
ber of observed individuals. AIC is used more often, but each has
merits [22]. Section 5 compares the BIC and the AIC for our data.
We choose the simplest model m such that no other model n has
ICn < ICm − 7 [21].
321In our case, k is the number of non-zero uh, but L is diﬃcult to
obtain. AIC and BIC assume that each source samples uniformly
and so L is the likelihood of a Poisson model. If the number of
samples is large, the central limit theorem indicates that substantial
deviations from the mean have very low likelihood. In our case,
as in [17, 19], the randomness comes largely from the choice of
sources to monitor, which is hard to characterise but has substan-
tially higher variance. Hence the Poisson assumption selects too
complex a model.
We mitigate this overﬁtting using the simple heuristic of dividing
all zs by some integer d when calculating L. It remains to select d.
If d is so large that any zs gets rounded to zero, the LLM breaks
down. The further heuristic of selecting d to be the largest number
less than mins zs appears to work well (see Section 5.1).
3.3.3 Estimate range
Besides computing point estimates, we also compute estimate
ranges (used in Section 5). We use the procedure in [23] to com-
pute a 100 (1 − α) % proﬁle likelihood “conﬁdence interval” (CI)
for ˆN. Note that this is not a true conﬁdence interval in our case,
since it is based on the assumption that each sample is drawn ran-
domly, resulting in a Poisson number of samples with each history.
In contrast, our samples arise from diﬀerent, not completely ran-
dom sampling procedures. Hence we treat these “conﬁdence in-
tervals” as merely a useful heuristic indication of the sensitivity to
modelling variations and we set α = 10−7 to obtain wide CIs.
3.3.4 Sampling zeros
Even with appropriate model selection, if the number of samples
across all sources is low, we may have a large number of zs that
are near zero leading to unreliable estimates. In our case this only
occurs for a few small countries or territories when stratifying by
country code (see Section 3.4). Hence, we exclude country codes
with fewer than 1000 IP addresses observed by all sources from the
results in Section 6.2 (where they are negligible) and in Section 6.7.
3.4 Stratiﬁcation
We obtain more insight and also initially hoped to mitigate het-
erogeneity by stratifying the population in diﬀerent ways. We clas-
siﬁed IPv4 addresses as statically or dynamically assigned using the
approach described in [10], and based on allocation and whois data
we stratiﬁed by RIR (e.g. APNIC), country, preﬁx size, industry1
and allocation age.
4. DATASETS AND PREPROCESSING
An IPv4 address is considered used if it responds to active probes
or participates in connections. A used /24 subset contains one or
more used addresses. This section describes our sources of used
IPv4 address data, our data collection and processing, and our han-
dling of both spoofed and dynamically assigned addresses.
4.1 Datasets
Our ﬁrst two datasets are from actively probing the whole al-
located IPv4 Internet using ICMP echo requests (IPING) and TCP
SYN packets to port 802 (TPING). Since mid-2011 we probed each
allocated IPv4 address (a census) once every 6 months. The ﬁrst
two censuses used ICMP probing and the rest used both ICMP and
TCP probing (with TCP probing seeing over 7% more observed
1“Industry” indicates whether address space is education, military,
government, corporate, or ISP. We classiﬁed 88% of the allocated
address space based on whois information (down to /17 networks).
2Initially we probed a sample of the Internet using diﬀerent com-
monly used TCP ports and found port 80 to be the most responsive.
includes
addresses
Passively observed IPv4 data
from
Wikipedia’s page edit histories3 (WIKI), potential spam email
senders from [12] (SPAM), addresses of clients tested by Measure-
ment Lab [13] tools (MLAB), web clients participating in our IPv6
readiness test [11] (WEB), anonymized server logs of game clients
connecting to Valve’s Steam online gaming platform (GAME), and
NetFlow records from incoming traﬃc of Swinburne University of
Technology’s access router (SWIN)4 and Caltech’s access router
(CALT).
IP addresses). We limited the overall ping rate and used reversed
bit counting for “traversing” the IP space. On average our prober
sent only one packet every two hours to individual /24 networks,
to minimise congestion, stay below typical ICMP or TCP rate limit
thresholds and avoid triggering monitoring systems (on average we
received only 10–20 complaints per census). For the ﬁrst half of
2011 we use ICMP ping data collected by USC/LANDER [24].
We utilise data gathered from 2011 onwards. We generate
datasets of unique /24 subnets by processing the IPv4 datasets and
setting the last octet of each address to zero and then ﬁltering out
the duplicates. Table 2 shows the number of unique IPv4 addresses
and /24 subnets per dataset for the years 2011–2013 (IPs for GAME
omitted for conﬁdentiality). Note that the numbers in the table can-
not be used as growth trends due to sample method variations.
4.2 Host types sampled
We collected data from diverse locations, but CR estimates will
only be useful if (1) our datasets sample all types of devices using
public IPv4 addresses and (2) a type of device can be sampled by
multiple datasets. We now discuss whether this is the case based
on grouping devices into routers, servers/proxies, clients (e.g. PCs,
smart phones), and specialised devices (e.g. printers, cameras).
ISP routers are sampled by IPING and TPING and may also ap-
pear in SWIN and CALT. Home routers are sampled by IPING and
TPING (we conﬁrmed that some responses came from Cable/DSL
routers by inspecting web pages from IPs responding to TPING)
and by all other sources (with NAT packets sent from home net-
works appear to come from home routers). Servers/proxies are
sampled by IPING, TPING, SWIN and CALT. They can also ap-
pear in WIKI, SPAM and WEB. Clients are sampled mainly by
WIKI, SPAM, MLAB, WEB, GAME, SWIN and CALT, but also
appear in IPING. NAT’ed clients also appear in IPING and TPING.
Specialised devices may be sampled by IPING and TPING.
Overall, our datasets sample most groups well, especially servers
and clients, which we assume are the largest groups. Specialised
devices are likely severely under-represented, but these are very
hard to sample. The authors of [5] probed the entire IPv4 Inter-
net on several hundred ports and detected 36 million addresses that
only responded to TCP SYNs but not to ICMP. In our censuses
15–20 million IPs reacted to port 80 TCP SYNs but not to ICMP.
The diﬀerence of 15–20 million addresses could be specialised de-
vices listening only on speciﬁc ports5 we missed, but this number is
small compared to our total estimate of 1.2 billion used addresses.
4.3 Time windows
We collected data from 1 Jan 2011 until 30 June 2014. To anal-
yse the growth trend of used IPv4 addresses, we split our data
into overlapping 12-month windows. Windows start every three
months, so the ﬁrst window starts at 1 Jan 2011 and the last window
starts at 1 Jul 2013. The last window ends at 30 June 2014. This is a
suitable trade-oﬀ between temporal resolution and noisy estimates.
3Modiﬁcation time and IPv4 address of edits by unregistered users.
4Excluding all traﬃc ﬂows of our active prober.
5E.g., printers responding only on the Internet Printing (IPP) port.
322Table 2: Data sources and observed unique IPv4 addresses and /24 subnets per year (SWIN and CALT after spoofed IP ﬁltering)
Description
Time collected
IPs [M]
/24 [M]
IPs [M]
/24 [M]
IPs [M]
/24 [M]
2011
2012
2013
Wikipedia’s page edit histories
Jan 2011 – Jun 2014
Potential spam email senders
May 2012 – Jun 2014
Clients tested by Measurement Lab
Jan 2011 – Jun 2014
Web clients tested for IPv6
Mar 2011 – Jun 2014
Game clients logged into Valve’s Steam
Jan 2011 – Jun 2014
5.5
-
30.0
22.0
conf
Swinburne access router NetFlow records
Jan 2011 – Jun 2014
150.6
Caltech access router NetFlow records
Jun 2013 – Jun 2014
-
ICMP ping census of IPv4 Internet
Mar 2011 – Jun 2014
320.3
TCP port 80 census of IPv4 Internet
Mar 2012 – Jun 2014
-
1.69
-
2.66
2.92
3.11
3.13
-
4.24