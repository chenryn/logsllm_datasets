### Introduction

Campaign workers and journalists, despite being targeted by sophisticated attackers, have not widely adopted security technologies [63]. Journalists, in particular, noted having limited time and technical expertise to implement security protections. Unlike campaign workers, many journalists work in stable news organizations with at least some IT staff and security infrastructure, emphasizing account security and anti-phishing measures [64]. Individual journalists are more concerned about surveillance from their own government than from foreign governments, making encryption a critical protective measure. Journalists and their organizations often focus on protecting sources, who are typically the ultimate targets of security attacks, but they lack the ability to control the security measures used by these sources.

Small businesses, similar to campaigns, often lack the financial resources and expertise to implement security protections and may underestimate security threats, even though they are targeted by digital attackers who perceive them as soft targets [4, 24]. Recent research by Huaman et al. [46] suggests that many small businesses are now implementing a range of technical security measures and have a basic awareness of security issues, although the adoption of organizational security measures lags behind. Older small businesses are more likely to have certain technical security measures in place, such as antivirus software, firewalls, and backup strategies. Unlike short-lived, amorphous campaigns, investments in security for small businesses can have a different return on investment and may be easier to prioritize, especially as a company matures.

Campaigns are unique compared to other workplaces due to their extreme transience, amorphous boundaries, and leadership structure. Campaigns face sophisticated, nation-state attackers who aim to damage democracy, not just the campaign itself. The fast pace of campaigns and the fixed duration of an election cycle have historically instilled an attitude among campaign workers that effective security protections are beyond practical reach. These factors create a novel threat landscape for the security community to understand.

### Methodology

We conducted semi-structured interviews with 28 participants who had experience working on, with, or in support of political campaigns in the U.S. This section describes our participants, recruiting methods, procedures, data collected, analysis, ethical considerations, anonymization, and study limitations.

#### Participants & Recruiting

We recruited individuals who were or had been involved with U.S. political campaigns, aiming for a broad representation across political parties, roles, organizations, and levels of experience. We identified potential participants through known contacts and social media profiles. Our participants included campaign staff (17), support organization executives/staff (12), consultants (10), party committee executives/staff (10), IT/security support (6), and candidates (4). They had collectively worked directly on or with a campaign (22), with a support organization (12), or on a national/state party committee (10). In terms of political affiliation, 17 participants were from the Democratic Party, 10 from the Republican Party, and 4 were non-partisan or bipartisan. Twenty-five had been involved with Federal campaigns, 8 with State, and 9 with Local. All participants named multiple roles, so the numbers do not total to 28.

We focused on recruiting individuals with extensive, long-term experience to gain insights into changes in campaign culture and practices over time. We also prioritized those with experience following the high-profile attacks of the 2016 election cycle [19, 68, 70, 76]. Seven participants reported 20+ years of experience in politics, 13 reported 10-20 years, 1 reported less than 10 years, and 7 did not clearly specify.

Interviews were conducted from May 2019 to March 2020, prior to the COVID-19 shutdowns in the U.S. All participants reviewed consent materials before the interview, and no financial incentive was provided.

#### Procedures & Data Collected

The lead interviewer began each session by reviewing a two-page consent document, emphasizing the participant's right to end the interview or pause the audio recording at any time. All participants gave informed consent. The first interview question asked about the participant’s background working with political campaigns. Subsequent topics, covered in a semi-structured manner, included:

- **Threats:** Security threats faced by campaigns or related organizations.
- **Vulnerabilities:** Areas of security that could be stronger in campaigns.
- **Work & Technology Practices:** Communication and account practices, and any security training taken.
- **Long-term Outcomes:** The impact of the current campaign security landscape on the future.

Two members of the core research team attended each interview to lead the session and take notes, except for two sessions where only one researcher was present. One researcher led 19 sessions, and the other led 5. Most sessions (N=24) included one participant; two sessions included two participants, and one session included three participants. These multi-participant sessions were arranged at the request of the participants, who served different roles and provided varied perspectives.

To ensure security and confidentiality, 25 interviews were conducted in person, and three included a remote component using video or phone conferencing. Audio recordings were made with participant consent, and detailed notes were taken for the one participant who declined recording. Two members of the core research team transcribed the audio verbatim, producing 948 pages of data. Only the core research team had access to the transcripts.

#### Analysis

We used an inductive, thematic analysis to analyze the transcript data. This approach was chosen because campaign security issues, from a technology user’s perspective, is a novel empirical topic with limited prior work. Thematic analysis was selected for its flexibility and the richness of detail it provides, which is useful for an audience of technology creators.

Three members of the core research team deeply engaged with the data by listening to audio recordings and reading transcripts multiple times. We brainstormed an initial list of inductive codes, and one expert coder then coded all the data, revising the list as needed. Regular meetings were held to develop, discuss, and refine codes. We did not use inter-rater reliability measures (IRR) to assess agreement, as our goal was to identify themes rather than a set of codes, and IRR can sometimes oversimplify complex concepts.

Next, we searched for themes in the coded data, using and iteratively revising memos, summaries, and coding. We created rough thematic maps to aid discussions. In this paper, we focus on the most important and pervasive themes in our dataset.

We performed several credibility checks on our findings. We summarized initial findings and discussed them with domain experts who had experience with campaigns. We also shared our findings in a report and presentation, collecting feedback from a multidisciplinary group of experts at a roundtable event in Summer 2020. Finally, we consulted with security experts to ensure the accuracy of our portrayal of security attacks and technologies.

#### Ethical Considerations

Ethical considerations were essential to our study design, analysis, and reporting, given the targeted threats faced by campaigns. We conducted most interviews in person to minimize the risk of surveillance. We protected all data, including audio, memos, and transcripts, by encrypting records at rest, restricting access to the core research team, and requiring 2FA with a physical security key.

Anonymity was a significant concern, as some participants had experienced harassment and other attacks. To protect anonymity, we omitted unique details and phrases in quotes and reported only coarse, aggregate demographic features. We did not attribute quotes, even using pseudonyms, to prevent the collection of information about any one participant. Instead, we reported that the 32 quotes in this paper are from 18 out of 28 participants, with no single participant quoted more than four times.

Our study plan, data handling practices, and final report were reviewed by a set of experts in ethics, human subjects research, policy, legal, security, privacy, and anti-abuse. While our organization does not require IRB approval, we adhere to similarly strict standards.

#### Limitations

Our study was limited to participants in the U.S., where campaign operations, security advice, and threat perceptions may differ from other regions. Our small sample size favored in-depth reporting over broad generalizability. Participants' experiences skewed toward state-wide or federal races and professionals with more years of experience. Comparing across parties was not a goal, and while we did not observe differences, we cannot rule out that differences could exist. We reached data saturation, indicating that the themes presented are robust for the population represented by our participants. Finally, the study was affected by the standard limitations of self-reported data, including recall bias and observer bias.

### Results

Our results highlight three main security challenges facing campaigns:

1. **Work Culture:** A culture where security is not emphasized or prioritized.
2. **Ad Hoc Security Practices:** Use of ad hoc security practices across many technology platforms to manage data that attackers seek.
3. **Nascent Understanding:** A growing, but still nascent, understanding of the threats facing campaigns that guides decision-making.

While every campaign may face a different subset of these challenges, the themes highlighted were raised by multiple participants. See Table 1 for a preview of these themes.

#### Campaign Work Culture

Campaigns exist to win elections, and participants emphasized this as the top priority. Voter and donor outreach tasks have long been considered crucial, involving communication through various channels. Digital security has only recently become an important need, requiring trade-offs, such as spending less on voter and donor outreach to free up resources for new digital security needs. This was described as a hard sell to decision-makers.

**Transience:** Campaigns are transient, needing to ramp up quickly and shut down after a clear, immovable end date (election day). Staff are hired only for the duration of the campaign, and frequent job changes are common. For technology, this means there is little time to develop IT/security infrastructure or institutional knowledge. Dormant accounts and infrastructure from previous campaigns might be reused, or entirely new infrastructure rapidly brought online.

### Example Quotes

- **Work Culture: Busy**
  - "It’s pretty hard to overstate the chaos of most campaigns. And so, there’s risk everywhere."
- **Work Culture: Security is Not a Priority**
  - "You have to change the culture of the industry, so that it’s expected rather than an afterthought. And right now, I think it’s mostly an afterthought."