being targeted by sophisticated attackers, but were not widely
adopting security technologies [63]. Also similarly, journalists
noted having limited time and technical expertise available
to implement security protections. Unlike campaign work-
ers, many (though not all) journalists worked in stable news
organizations, with at least some IT staff as well as security
infrastructure and policies that emphasized account security
and anti-phishing [64]. Individual journalists were more con-
cerned about surveillance from their own government (than
from foreign governments, as we found for campaign work-
ers), making encryption an important perceived protection.
Unique to their work practices, journalists and their organiza-
tions often focused on protecting sources, who were typically
the ultimate target of security attacks, but neither had the
ability to control security protections that sources used.
Small businesses are similar to campaigns in that they of-
ten lack the ﬁnancial resources and expertise to implement
security protections and underestimate security threats, de-
spite being targeted by digital attackers who perceive them
to be soft targets [4, 24]. However, recent work by Huaman
et al. [46] suggests that many small businesses are now im-
plementing a range of technical security measures and have a
basic awareness of security issues, though adoption of organi-
zational security measures lags behind. Further, older small
businesses studied in [46] were more likely to have certain
technical security measures in place (like antivirus software,
ﬁrewalls, and a backup strategy). Unlike short-lived, amor-
phous campaigns, investments in security have a different
return on investment for small businesses and may be easier
to prioritize, especially as a company matures.
As we will show, campaigns are unique compared to these
previously studied workplaces due to their extreme transience,
amorphous boundaries and leadership structure. Campaigns
also face sophisticated, nation-state attackers who often aim to
damage democracy, not just the campaign. At the same time,
the fast pace of campaigns and ﬁxed duration of an election
cycle have historically instilled an attitude amongst people
involved in campaigns that effective security protections are
beyond practical reach. These qualities create a novel threat
landscape for the security community to understand.
3 Methodology
We conducted semi-structured interviews with 28 participants
who had experience working on, with, or in support of politi-
cal campaigns in the U.S. Here we describe our participants,
recruiting, procedures, data collected, analysis, ethical con-
siderations, anonymization, and study limitations.
3.1 Participants & recruiting
We recruited people who were or had been involved with U.S.
political campaigns, aiming for breadth in political party, role,
organization, and level of experience. We identiﬁed poten-
tial participants who represented this population and directly
contacted them with help from known contacts or via their so-
cial media proﬁles. We ensured representation of a variety of
roles and organizations. Our participants included campaign
staff (17 participants), support organization executives/staff
(12), consultants (10), party committee executives/staff (10),
IT/security support (6), and candidates (4). They had collec-
tively worked directly on or with a campaign (22); with a sup-
port organization such as a super PAC, think tank, university,
or software provider (12); or on a national/state party com-
mittee (10). Relative to their role(s) with campaigns, 17 par-
ticipants were from the Democratic party, 10 the Republican
party, and 4 were Non/Bipartisan (3 had served non/bipartisan
as well as partisan roles). Twenty-ﬁve had been involved with
Federal campaigns, 8 with State, and 9 Local. All partici-
pants named multiple roles they had held working on or with
campaigns, hence numbers will not total to 28.
Though we recruited people with a range of experience, we
focused recruiting on those with extensive, long term experi-
ence, as they could speak to changes in campaign culture and
practices over time. We also placed an emphasis on recruiting
people who had experience with campaigns following the
high proﬁle attacks of the 2016 election cycle [19, 68, 70, 76].
Seven participants reported 20+ years of experience in pol-
itics, 13 reported 10-20 years of experience, 1 reported less
than 10 years, and 7 did not clearly specify.
We conducted interviews from May 2019 to March 2020,
prior to COVID-19 shutdowns in the U.S. All participants had
a chance to review consent materials prior to the interview
starting. No ﬁnancial incentive to participate was provided.
3.2 Procedures & data collected
The lead interviewer began the interview session by going
over with participants a two-paged consent document. We
emphasized their agency to end the interview or pause the
audio recording at any time. All participants gave informed
consent. Next, our ﬁrst interview question asked about the
1184    30th USENIX Security Symposium
USENIX Association
participant’s background working with political campaigns.
Then we drew from the following interview topics, in a semi-
structured way:
• Threats: Security threats participants believed cam-
paign(s) or related organizations faced (probing about
speciﬁc attacks, attackers, what data was at risk, and
what harms could result).
• Vulnerabilities: Areas of security they felt could be
stronger in campaigns or political organizations (probing
about the various security practices that the participant
brought up, best practices in the participant’s opinion,
and perceived barriers to adoption).
• Work & technology practices: Communication and ac-
count practices of the participant and their colleagues,
and any security training they had taken. This included
their understanding and use of 2FA.
• Long-term outcomes: The impact they felt the current
campaign security landscape could have on the future.
The same two members of the core research team attended
the interview sessions to either lead the interview or take
notes, plus ask occasional follow up questions (except two
sessions, which were attended by only one of the researchers).
One researcher led 19 sessions; the other led 5. Most inter-
view sessions (N=24) included one participant; two sessions
included two participants; and one session included three
participants. The three sessions with more than one partici-
pant were arranged at the request of our participants. In those
three sessions, all participants were encouraged to respond to
all questions asked. These participants served different roles
(e.g., candidate and campaign manager), that allowed them
to offer different perspectives and add context to responses.
To ensure security and conﬁdentiality, we conducted all but
three of the interviews entirely in person; the three interviews
that included a remote component employed video or phone
conferencing. We audio recorded sessions with participant
consent. See the Appendix for our interview script, recruiting
material, and consent form.
Sessions lasted 42-118 minutes (µ=75). We collected 27
hours of audio recordings in total (one participant declined
recording, but detailed notes were taken and analyzed with
permission). Two members of the core research team tran-
scribed the audio in a verbatim style (i.e., a word-for-word
transcription, including ﬁllers and non-verbal utterances), pro-
ducing 948 pages of data. For the safety, security, and privacy
of participants, only members of the core research team tran-
scribed the recorded audio and had access to the transcripts.
3.3 Analysis
We used an inductive [86], thematic analysis [17] to analyze
the transcript data. The inductive (or data-driven) method
was appropriate because campaign security issues, from a
technology user’s perspective, is a novel empirical topic with
limited prior work upon which to base a deductive approach.
We chose a thematic analysis for its ﬂexibility and because
we believed the output (a set of patterns coupled with rich
detail) would be most useful for an audience of technology
creators, building an early understanding of this population.
To begin, three members of the core research team (referred
to as “we” from now on; these three were made up of the
two researchers who conducted all of the interviews, and
the two who transcribed all of the audio) deeply engaged
with the interview data by listening to audio recordings and
reading the transcripts multiple times. We used these activities
to memo and summarize all the data, and to brainstorm an
early list of inductive codes. One of us, an expert coder, then
coded all the data, inductively building and revising the list
of codes as the coding progressed, to ensure it described the
full data set. To reach agreement on codes, we met regularly
throughout the coding process to develop, discuss, and reﬁne
codes. We did not set up the coding process to use inter-rater
reliability measures (IRR) to assess agreement for several
reasons covered in McDonald et al. [61]: a set of themes
was the goal of our analysis, not a set of codes (we discuss
stakeholder checks below to establish the credibility of these
themes); and our data was complex and nuanced, and the need
to meet IRR metrics can cause complex concepts and nuance
to be lost. See the Appendix for the list of codes pertaining to
the themes in this paper.
Next, in regular meetings and independently, we searched
for themes in the coded data, using and iteratively adding
to/revising the memos, summaries, and coding. We then re-
viewed our ideas for themes by revisiting the relevantly coded
data, further memoing and revising themes, codes, and coding
of data as needed. We also created rough thematic maps of
our data, to aid discussions. In this paper, we focus on themes
in our dataset that we determined were most important (in
terms of mitigating risk to the population) and pervasive (as
reported by the set of participants).
We performed several credibility checks on our ﬁnd-
ings [86] to ensure they were accurate and covered the most
salient themes about campaign security. First, we summarized
initial ﬁndings and discussed them with domain experts who
had experience on or with campaigns. Second, we shared
our summarized ﬁndings in a report and presentation, and
collected feedback from a multidisciplinary group of experts
who participated in a roundtable that we ran in Summer 2020.
Forty-four experts attended the roundtable, not including the
event organizers; 13 attendees were from the Republican
party, 12 from the Democratic party, 10 from tech compa-
nies, and 9 from academia or non-partisan political nonproﬁts
(see [25] for more about the roundtable and the 28 organiza-
tions that were represented). Finally, we talked with security
experts to ensure we accurately portrayed the security attacks
and technologies in our ﬁndings.
USENIX Association
30th USENIX Security Symposium    1185
3.4 Ethical considerations
When working with any at-risk population, ethical considera-
tions are essential to the study design, analysis, and reporting.
Since campaigns face targeted threats from sophisticated at-
tackers, our focus was on ensuring that participation in this
study would not harm participants and the population more
generally. We conducted the vast majority of interviews in
person, to minimize the risk of surveillance. We protected
the data produced during our study—including audio, memos,
and transcripts—by encrypting all records at-rest, restricting
access to only the core research team (and organizational ad-
ministrators), and requiring 2FA with a physical security key
to access the information.
Anonymity required extra attention. Some of our partici-
pants were concerned about their anonymity, having experi-
enced harassment and other attacks as part of their roles in
politics. We also considered the risk of re-identiﬁcation in
light of their highly public careers. Our goal was to protect
all participants’ anonymity by using a conservative reporting
standard. Thus, when reporting our results, we speciﬁcally
omit unique details, phrases, or words in quotes from partici-
pants to mitigate de-anonymization, and likewise report only
coarse, aggregate demographic features. We do not attribute
quotes, even using pseudonyms, to mitigate the collection of
information about any one participant. Instead, we report that
the 32 quotes in this paper are from 18 out of 28 participants,
and we did not quote any one participant more than 4 times.
To ensure our work did not put participants or others who
work with campaigns at risk, our study plan, data handling
practices, and ﬁnal study report were reviewed by a set of
experts from our organization in domains including ethics,
human subjects research, policy, legal, security, privacy, and
anti-abuse. We note that our organization does not require
IRB approval, though we adhere to similarly strict standards.
3.5 Limitations
Our study was limited to participants in the U.S. where cam-
paign operations, security advice, and threat perceptions may
differ compared to other regions. Our small sample favored
in-depth reporting over broad generalizability across all cam-
paigns and roles. Even though our participants had experi-
ence working on city or regional races, their experiences and
feedback skewed toward state-wide or federal races. They
also skewed toward professionals with more years of experi-
ence. We note that comparing across parties was not a goal
of this work, and while we did not observe differences, we
cannot rule out that differences could exist. All of that said,
we reached data saturation with our interviews, that is, a point
at which we found no new themes as interviews progressed,
indicating that the themes presented in this paper are robust
for the population represented by our participants. Finally, this
study was affected by the standard limitations of self-reported
data, including recall bias and observer bias.
4 Results
Our results point to three main security challenges facing cam-
paigns: (1) a work culture where security is not emphasized
or prioritized; (2) ad hoc security practices used by people
involved with campaigns, across many technology platforms,
to manage data that attackers often seek; and (3) a nascent,
though growing, understanding of the threats facing cam-
paigns that guides decision making. While every campaign
may face a different subset of these challenges, the themes
we highlight were raised by multiple participants. See Table 1
for a preview of these themes.
4.1 Campaign work culture
We detail how campaign work culture, inﬂuenced by many
constraints, created a challenging environment for security.
Winning. Campaigns exist to win elections—participants
emphasized it as the top priority. For decades, voter and donor
outreach tasks have been considered among the most im-
portant to achieving this goal.2 This meant communicating
with voters and donors wherever they were, including at their
doorstep, on TV, in email, and on various social media plat-
forms. Only recently has digital security become an impor-
tant need for campaigns, and prioritizing it required trade-
offs—for example, spending less time and money on voter
and donor outreach to free up time and money for new digital
security needs. This was described as a hard sell to decision
makers on campaigns (these varied, but could include the
campaign manager, senior staff/consultants, or the candidate).
“A $25-million Senate race is pretty standard these days.
And the committees want you to spend all that money on
voter contact and direct communication with voters, which
is smart, but there isn’t the sort of  infrastructure
setup that helps someone who has never run before, who has
no idea that  operatives can be trying to break
into a Senate race and inﬂuence it.” –A participant
Transience.
Participants emphasized that campaigns were
transient—that is, they needed to fully ramp up on a short
timeline (ranging from about 3 months to a little over a year,
depending on the type of race), with a clear, immovable end
date (election day). Staff were only hired for the duration
of the campaign, and frequent job changes were common in
the political sector. For technology, transience meant there
was not time to develop much IT/security infrastructure or
institutional knowledge before a campaign shut down. To
cope, dormant accounts and infrastructure from a previous
campaign might be reused, entirely new infrastructure rapidly
brought online, or a combination of the two.
2Note that campaigns prioritize a host of tasks beyond outreach, and it is
not the purpose of this work to analyze priorities across all tasks. Instead, we
focus on understanding where security ﬁts in the prioritization, and highlight
certain higher priority tasks that contribute to security vulnerabilities.
1186    30th USENIX Security Symposium
USENIX Association
Theme
Work culture: Busy
Work culture: Security is
not a priority
Tech practices: Commu-
nications are sensitive
Tech practices: Account
security is weak
Perceived threats: Pri-
marily nation-states
Perceived threats: Harm
to democracy
Example Quote
“It’s pretty hard to overstate the chaos of most campaigns. And so, there’s risk everywhere.”
“You have to change the culture of the  industry, so that it’s expected
rather than an afterthought. And right now, I think it’s mostly an afterthought.”