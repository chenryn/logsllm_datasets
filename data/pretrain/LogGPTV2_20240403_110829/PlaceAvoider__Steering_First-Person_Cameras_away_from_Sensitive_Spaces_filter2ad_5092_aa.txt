title:PlaceAvoider: Steering First-Person Cameras away from Sensitive Spaces
author:Robert Templeman and
Mohammed Korayem and
David J. Crandall and
Apu Kapadia
PlaceAvoider: Steering First-Person Cameras away from Sensitive Spaces
Robert Templeman,†‡ Mohammed Korayem,† David Crandall,† Apu Kapadia†
†School of Informatics and Computing
Indiana University Bloomington
{retemple, mkorayem, djcran, kapadia}@indiana.edu
‡Naval Surface Warfare Center, Crane Division
PI:EMAIL
Abstract—Cameras are now commonplace in our social and
computing landscapes and embedded into consumer devices like
smartphones and tablets. A new generation of wearable devices
(such as Google Glass) will soon make ‘ﬁrst-person’ cameras
nearly ubiquitous, capturing vast amounts of imagery without
deliberate human action. ‘Lifelogging’ devices and applications
will record and share images from people’s daily lives with their
social networks. These devices that automatically capture images
in the background raise serious privacy concerns, since they are
likely to capture deeply private information. Users of these devices
need ways to identify and prevent the sharing of sensitive images.
As a ﬁrst step, we introduce PlaceAvoider, a technique for
owners of ﬁrst-person cameras to ‘blacklist’ sensitive spaces
(like bathrooms and bedrooms). PlaceAvoider recognizes images
captured in these spaces and ﬂags them for review before
the images are made available to applications. PlaceAvoider
performs novel
image analysis using both ﬁne-grained image
features (like speciﬁc objects) and coarse-grained, scene-level
features (like colors and textures) to classify where a photo was
taken. PlaceAvoider combines these features in a probabilistic
framework that jointly labels streams of images in order to
improve accuracy. We test the technique on ﬁve realistic ﬁrst-
person image datasets and show it is robust to blurriness, motion,
and occlusion.
I.
INTRODUCTION
Cameras have become commonplace in consumer devices
like laptops and mobile phones, and nascent wearable devices
such as Google Glass,1 Narrative Clip,2 and Autographer3 are
poised to make them ubiquitous (Figure 1). These wearable
devices allow applications to capture photos and other sensor
data continuously (e.g., every 30 seconds on the Narrative
Clip), recording a user’s environment from a ﬁrst-person
perspective. Inspired by the Microsoft SenseCam project [24],
1Google Glass: http://www.google.com/glass/start/
2Narrative (formerly known as Memoto): http://getnarrative.com
3Autographer: http://autographer.com
Permission(cid:1) to(cid:1) freely(cid:1) reproduce(cid:1) all(cid:1) or(cid:1) part(cid:1) of(cid:1) this(cid:1) paper(cid:1) for(cid:1) noncommercial(cid:1)
purposes(cid:1)is(cid:1)granted(cid:1)provided(cid:1)that(cid:1)copies(cid:1)bear(cid:1)this(cid:1)notice(cid:1)and(cid:1)the(cid:1)full(cid:1)citation(cid:1)
on(cid:1)the(cid:1)ﬁrst(cid:1)page.(cid:1)Reproduction(cid:1)for(cid:1)commercial(cid:1)purposes(cid:1)is(cid:1)strictly(cid:1)prohibited(cid:1)
without(cid:1)the(cid:1)prior(cid:1)written(cid:1)consent(cid:1)of(cid:1)the(cid:1)Internet(cid:1)Society,(cid:1)the(cid:1)ﬁrst-named(cid:1)author(cid:1)
(for(cid:1) reproduction(cid:1) of(cid:1) an(cid:1) entire(cid:1) paper(cid:1) only),(cid:1) and(cid:1) the(cid:1) author’s(cid:1) employer(cid:1) if(cid:1) the(cid:1)
paper(cid:1)was(cid:1)prepared(cid:1)within(cid:1)the(cid:1)scope(cid:1)of(cid:1)employment.
NDSS(cid:1)’14,(cid:1)23-26(cid:1)February(cid:1)2014,(cid:1)San(cid:1)Diego,(cid:1)CA,(cid:1)USA
Copyright(cid:1)2014(cid:1)Internet(cid:1)Society,(cid:1)ISBN(cid:1)1-891562-35-5
http://dx.doi.org/(cid:18)(cid:17)(cid:15)(cid:18)(cid:21)(cid:24)(cid:19)(cid:19)(cid:16)(cid:79)(cid:69)(cid:84)(cid:84)(cid:15)(cid:19)(cid:17)(cid:18)(cid:21)(cid:15)(cid:19)(cid:20)(cid:17)(cid:18)(cid:21)
Fig. 1. Wearable camera devices. Clockwise from top left: Narrative Clip takes
photos every 30 seconds; Autographer has a wide-angle camera and various
sensors; Google Glass features a camera, heads-up display, and wireless
connectivity. (Photos by Narrative, Gizmodo, and Google.)
these devices are also ushering in a new paradigm of ‘lifel-
ogging’ applications that allow people to document their daily
lives and share ﬁrst-person camera footage with their social
networks. Lifelogging cameras allow consumers to photograph
unexpected moments that would otherwise have been missed,
and enable safety and health applications like documenting
law enforcement’s interactions with the public and helping
dementia patients to recall memories.
However, with these innovative and promising applica-
tions come troubling privacy and legal risks [1]. First-person
cameras are likely to capture deeply personal and sensitive
information about both their owners and others in their envi-
ronment. Even if a user were to disable the camera or to screen
photos carefully before sharing them, malware could take and
transmit photos surreptitiously; work on visual malware for
smartphones has already demonstrated this threat [52]. As ﬁrst-
person devices become more popular and capture ever greater
numbers of photos, people’s privacy will be at even greater
risk. At a collection interval of 30 seconds, the Narrative Clip
can collect thousands of images per day — manually reviewing
this bulk of imagery is clearly not feasible. Usable, ﬁne-grained
controls are needed to help people regulate how images are
used by applications.
A potential solution to this problem is to create algorithms
that automatically detect sensitive imagery and take appro-
priate action. For instance, trusted ﬁrmware on the devices
visual recognition are even more challenging. Third, rooms
change appearance over time due to dynamic scenes (e.g.,
moving objects) as well as variations in illumination and
occlusions from other people and objects. Finally, photos from
‘other’ spaces (i.e., spaces that are not blacklisted) may form a
large fraction of images, and false positives must be kept low
to reduce the burden on the owner.
Our Contributions. Our speciﬁc contributions are:
1)
2)
3)
4)
Presenting PlaceAvoider, a framework that identiﬁes
images taken in sensitive areas to enable ﬁne-grained
permissions on camera resources and photo ﬁles;
Recognizing images of a space by using a novel
combination of computer vision techniques to look
for distinctive ‘visual
landmarks’ of the enrolled
spaces and global features of the room such as color
patterns;
Analyzing photo streams to improve the accuracy
of indoor place recognition by labeling sequences of
images jointly, using (weak) temporal constraints on
human motion in a probabilistic framework;
Implementing and evaluating PlaceAvoider using
ﬁrst-person images from ﬁve different environments,
showing that photos from sensitive spaces can be
found with high probability even in the presence of
occlusion or images taken from non-enrolled spaces.
The remainder of the paper describes these contributions
in detail. Section II describes our architecture, constraints, and
concept of operation, while Section III describes our image
classiﬁcation techniques. Section IV reports our evaluation
on several ﬁrst-person datasets. We discuss the implications
of our results in Section V before surveying related work in
Section VI and concluding in Section VII.
II. OUR APPROACH
Our goal is a system that allows users to deﬁne context-
based ﬁne-grained policies to control
the sharing of their
images from smartphones and ﬁrst-person cameras. We start
by describing our privacy goals.
A. Privacy goals and adversary model
The increasing presence of cameras in electronic devices
means that cameras are now more likely to enter sensitive
spaces, where the cost of image leaks may be high. Our work
aims to protect the privacy of users in two ways.
First, we assume that users will want to share some of their
ﬁrst-person photos with social and professional contacts but
will need help managing and ﬁltering the huge collections of
images that their devices collect. Their social contacts are not
‘adversaries’ in the traditional sense (where attackers actively
try to obtain sensitive photos), but inadvertent sharing of cer-
tain images can nevertheless cause embarrassment (e.g., photos
with nudity) and have social or professional consequences.
Thus it is important to help users identify potentially sensitive
images before they are shared.
Second, malicious applications (such as Trojan applica-
tions) that have access to a device’s camera may seek to
bathroom
personal ofﬁce
lab
common area
Fig. 2. Sample ﬁrst-person images from our datasets. Note the blur and poor
composition, and the visual similarity of these four images despite being taken
in spaces with very different levels of potential privacy risk.
could scan for private content and alert the user when an
application is about to capture a potentially sensitive photo.
Unfortunately, automatically determining whether a photo con-
tains private information is difﬁcult, due both to the computer
vision challenges of scene recognition (especially in blurry
and poorly composed ﬁrst-person images), and the fact that
deciding whether a photo is sensitive often requires subtle and
context-speciﬁc reasoning (Figure 2).
Nevertheless, in this work we take an initial step towards
this goal, studying whether computer vision algorithms can
be combined with (minimal) human interaction to identify
some classes of potentially sensitive images. In particular, we
assume here that certain locations in a person’s everyday space
may be sensitive enough that they should generally not be
photographed: for instance, a professor may want to record
photos in classrooms and labs but avoid recording photos in
the bathroom and in his or her ofﬁce (due to sensitive student
records), while at home the kitchen and living room might be
harmless but bedroom photos should be suppressed.
In this paper we propose an approach called “PlaceAv-
oider”, which allows owners of ﬁrst-person cameras to blacklist
sensitive spaces. We ﬁrst ask users to photograph sensitive
spaces (e.g., bathrooms, bedrooms, home ofﬁces), allowing
our system to build visual models of rooms that should not
be captured. PlaceAvoider then recognizes later images taken
in these areas and ﬂags them for further review by the user.
PlaceAvoider can be invoked at the operating system level to
provide warnings before photos are delivered to applications,
thus thwarting visual malware and withholding sensitive pho-
tos from applications in general.
PlaceAvoider complements existing location services, using
them to reduce the computational effort made when classifying
images. For example, GPS can be used to identify the building
in which the device is located, but it is typically not accurate
enough to identify a speciﬁc room, because GPS signals are
not reliably available indoors. Even if a reliable indoor location
service existed, it would pinpoint where a camera is, not what
it is looking at (e.g., when the camera is in a hallway, but
capturing a nearby bathroom).
Research challenges. This work addresses several research
challenges in order to make PlaceAvoider possible. First, we
need an approach to recognize rooms using visual analysis
with reasonable computational performance (either locally on
the device or on a secure remote cloud). Second, many (or
most) images taken from ﬁrst-person cameras are blurry and
poorly composed, where the already difﬁcult problems of
2
actively capture sensitive images in the background. For ex-
ample, visual malware such as PlaceRaider [52] may be used
to surveil sensitive spaces like ofﬁces or to blackmail victims
by capturing nude photographs in their bedroom. We assume
such applications have been installed (either unwittingly or as
a Trojan application) with the requisite permissions for the
camera and Internet access, but that the operating system has
not been compromised.
B. System model
We consider a model in which sensitive photos are iden-
tiﬁed by analyzing the image content
in conjunction with
contextual information such as GPS location and time, i.e.,
where and when the photo was taken. To make image analysis
for privacy leaks tractable, we focus on ﬁne-grained control
of images based on the physical spaces captured within the
images. Our approach could withhold sensitive images from
applications until
they are reviewed by the owner of the
camera, or it could tag images with metadata to be used by
trusted (e.g., lifelogging) applications to assist the owner in
analyzing their image collections.
Our proposed system has three elements: a privacy policy
to indicate private spaces, an image classiﬁer to ﬂag sensitive
images, and a policy enforcement mechanism to determine how
sensitive images are handled by the receiving applications. For
instance, Figure 3 illustrates how PlaceAvoider allows ﬁne-
grained control of a camera based on context-based policy.
We now brieﬂy describe these three components:
•
•
•
location (e.g.,
Privacy policy. In this work, a policy is a set of
blacklisted spaces — we use the term blacklisted
generally to refer to any space that we want to label
(i.e., a blacklisted space can vary with respect
to
its sensitivity). Each space in the policy includes
a geospatial
latitude and longitude),
enrollment images or a visual model of the space, a
string identiﬁer (e.g., ‘bathroom’), and the action to
be taken by PlaceAvoider (e.g., which application(s)
can access the image). In addition, a sensitivity value
can be given to trade-off between conservative and
liberal blacklisting when the image analysis is not very
certain.
Image classiﬁer. The image classiﬁer builds models
of enrolled spaces, and then classiﬁes new images
according to where they were taken. The classiﬁer
must deal with signiﬁcant
including
motion blur, poor composition, and occlusions (caused
by people and objects added to a space). The classi-
ﬁer can process individual images, or jointly process
image sequences in order to improve accuracy. As
illustrated in Figure 3, this classiﬁcation step could
be outsourced to an off-board image classiﬁer such
as a cloud service (akin to cloud-based speech-to-text
translation offered by Android4 and Apple iOS5). We
discuss trade-offs between on- and off-board process-
ing in Section IV-E.
Policy enforcement. We assume two possible policy
enforcement mechanisms. User policies can specify
image noise,
4Voice Search: http://www.google.com/insidesearch/features/voicesearch/
5Siri: http://www.apple.com/ios/siri/
3
that sensitive photos must be blocked from applica-
tions, in which case users can review these photos
before they are delivered to the application, or users
can allow access to trusted applications that make
use of metadata supplied by the image classiﬁer.
The policy enforcement mechanism delivers photos
accordingly, either to the reviewing interface or to the
trusted applications.
We anticipate two types of scenarios that PlaceAvoider
must handle. The ﬁrst scenario is when the user can practically
enroll all possible spaces in the structure, like in a home with
a dozen rooms. We call these closed locales; for these places,
our classiﬁer can assign each photo into one of these n rooms
using an n-way classiﬁer. The second scenario is for open
locales — buildings with a large number of spaces for which it
is not feasible to enroll every space. This is a more challenging
case in which we also need to identify photos taken in none of
the n classes. We evaluate PlaceAvoider under both scenarios
in Section IV.
C. Usage scenario
PlaceAvoider addresses the following usage scenario. Mary
wears a sensor-enabled lifelogging device so that she can
record her activities throughout the day and capture moments
that would otherwise be hard to photograph (like interactions
with her infant). However, she is concerned about the cam-
era taking photos in sensitive areas. She decides to set a
PlaceAvoider policy. She has ﬁve rooms in her apartment and
enrolls them by taking pictures of each space as prompted
by PlaceAvoider. She asserts that she does not want photos
taken in her bathroom or bedroom. She sets a similar policy
at work. She spends most of her time in her ofﬁce, a lab, and
a conference room. She enrolls these spaces, deeming the lab
a sensitive room.
Soon afterwards she is working in the lab and receives
an alert on her smartphone indicating that an application is
attempting to take a photo in a sensitive space. She conﬁrms
the alert, wondering why her exercise-monitoring app is at-
tempting to take surreptitious photos and decides to uninstall
the app. Later that evening, she downloads the photos from her
lifelogging camera. The PlaceAvoider system neatly organizes
her photos temporally and spatially, ﬂagging the images that
were taken in sensitive spaces.
III.
IMAGE CLASSIFICATION
Having described our system architecture, adversarial
model, and usage scenario, we now turn to the challenge of
automatically recognizing where a photo was taken within an
indoor space based on its visual content. As described above,
we assume that GPS has provided a coarse position, so our goal
here is to classify image content amongst a relatively small
number of possible rooms within a known structure. While
there is much work on scene and place recognition [56], [37],
we are not aware of work that has considered ﬁne-grained
indoor localization in images from ﬁrst-person devices.
We ﬁrst consider how to classify single images, using two
complementary recognition techniques. We then show how to
improve results by jointly classifying image sequences, taking