# PlaceAvoider: Steering First-Person Cameras Away from Sensitive Spaces

**Authors:**
- Robert Templeman†‡
- Mohammed Korayem†
- David J. Crandall†
- Apu Kapadia†

**Affiliations:**
- †School of Informatics and Computing, Indiana University Bloomington
- ‡Naval Surface Warfare Center, Crane Division

**Contact:**
- {retemple, mkorayem, djcran, kapadia}@indiana.edu

## Abstract
Cameras are now ubiquitous in our social and computing environments, embedded in devices such as smartphones and tablets. The advent of wearable devices like Google Glass will soon make first-person cameras nearly omnipresent, capturing vast amounts of imagery without deliberate human action. Lifelogging applications will record and share images from people's daily lives with their social networks. These devices, which automatically capture images in the background, raise significant privacy concerns, as they are likely to capture deeply private information. Users need methods to identify and prevent the sharing of sensitive images.

We introduce PlaceAvoider, a technique for owners of first-person cameras to 'blacklist' sensitive spaces (e.g., bathrooms and bedrooms). PlaceAvoider recognizes images captured in these spaces and flags them for review before they are made available to applications. It performs novel image analysis using both fine-grained features (such as specific objects) and coarse-grained, scene-level features (such as colors and textures) to classify where a photo was taken. PlaceAvoider combines these features in a probabilistic framework that jointly labels streams of images to improve accuracy. We test the technique on five realistic first-person image datasets and show it is robust to blurriness, motion, and occlusion.

## 1. Introduction
Cameras have become commonplace in consumer devices like laptops and mobile phones, and nascent wearable devices such as Google Glass, Narrative Clip, and Autographer are poised to make them ubiquitous. These wearable devices allow applications to continuously capture photos and other sensor data, recording a user's environment from a first-person perspective. Inspired by the Microsoft SenseCam project, these devices are ushering in a new paradigm of 'lifelogging' applications that document daily lives and share first-person camera footage with social networks. Lifelogging cameras enable consumers to photograph unexpected moments and support safety and health applications, such as documenting law enforcement interactions and aiding dementia patients in recalling memories.

However, these innovative applications come with troubling privacy and legal risks. First-person cameras are likely to capture deeply personal and sensitive information about both their owners and others in their environment. Even if a user disables the camera or screens photos carefully before sharing, malware could take and transmit photos surreptitiously. As first-person devices become more popular and capture greater numbers of photos, people's privacy will be at even greater risk. At a collection interval of 30 seconds, the Narrative Clip can collect thousands of images per day, making manual review impractical. Usable, fine-grained controls are needed to help people regulate how images are used by applications.

A potential solution is to create algorithms that automatically detect sensitive imagery and take appropriate action. For instance, trusted firmware on the devices could scan for private content and alert the user when an application is about to capture a potentially sensitive photo. However, automatically determining whether a photo contains private information is challenging due to computer vision difficulties and the need for subtle, context-specific reasoning.

In this work, we take an initial step towards this goal by studying whether computer vision algorithms can be combined with minimal human interaction to identify some classes of potentially sensitive images. We assume that certain locations in a person's everyday space may be sensitive enough that they should generally not be photographed. For example, a professor may want to record photos in classrooms and labs but avoid recording photos in the bathroom and office (due to sensitive student records), while at home, the kitchen and living room might be harmless, but bedroom photos should be suppressed.

We propose PlaceAvoider, which allows owners of first-person cameras to blacklist sensitive spaces. Users first photograph sensitive spaces, allowing the system to build visual models of rooms that should not be captured. PlaceAvoider then recognizes later images taken in these areas and flags them for further review by the user. PlaceAvoider can be invoked at the operating system level to provide warnings before photos are delivered to applications, thus thwarting visual malware and withholding sensitive photos from applications in general.

PlaceAvoider complements existing location services, using them to reduce computational effort. For example, GPS can identify the building, but it is not accurate enough to identify a specific room. Even if a reliable indoor location service existed, it would pinpoint where a camera is, not what it is looking at (e.g., when the camera is in a hallway, but capturing a nearby bathroom).

## 2. Our Approach
Our goal is to develop a system that allows users to define context-based, fine-grained policies to control the sharing of images from smartphones and first-person cameras. We start by describing our privacy goals and adversary model.

### A. Privacy Goals and Adversary Model
The increasing presence of cameras in electronic devices means that cameras are more likely to enter sensitive spaces, where the cost of image leaks may be high. Our work aims to protect the privacy of users in two ways:

1. **User-Controlled Sharing:** Users may want to share some of their first-person photos with social and professional contacts but need help managing and filtering the large collections of images their devices collect. Inadvertent sharing of certain images can cause embarrassment and have social or professional consequences. Thus, it is important to help users identify potentially sensitive images before they are shared.
   
2. **Protection from Malicious Applications:** Malicious applications, such as Trojan apps, that have access to a device’s camera may seek to capture sensitive images in the background. For example, visual malware like PlaceRaider can surveil sensitive spaces like offices or blackmail victims by capturing nude photographs in their bedrooms. We assume such applications have been installed (either unwittingly or as a Trojan app) with the requisite permissions for the camera and Internet access, but that the operating system has not been compromised.

### B. System Model
Our proposed system has three elements: a privacy policy, an image classifier, and a policy enforcement mechanism.

- **Privacy Policy:** A policy is a set of blacklisted spaces, each including geospatial coordinates, enrollment images, a string identifier (e.g., 'bathroom'), and the action to be taken by PlaceAvoider (e.g., which application(s) can access the image). A sensitivity value can be given to balance between conservative and liberal blacklisting when the image analysis is uncertain.
  
- **Image Classifier:** The image classifier builds models of enrolled spaces and classifies new images based on where they were taken. It must handle significant noise, including motion blur, poor composition, and occlusions. The classifier can process individual images or jointly process image sequences to improve accuracy. This classification step can be outsourced to an off-board image classifier, such as a cloud service, similar to cloud-based speech-to-text translation.

- **Policy Enforcement:** Policies can specify that sensitive photos must be blocked from applications, allowing users to review these photos before they are delivered to the application, or users can allow access to trusted applications that use metadata supplied by the image classifier. The policy enforcement mechanism delivers photos accordingly, either to the reviewing interface or to the trusted applications.

We anticipate two types of scenarios: closed locales (e.g., a home with a dozen rooms) and open locales (e.g., buildings with many spaces). For closed locales, the classifier can assign each photo into one of the n rooms using an n-way classifier. For open locales, the classifier must also identify photos taken in none of the n classes. We evaluate PlaceAvoider under both scenarios.

### C. Usage Scenario
Consider Mary, who wears a sensor-enabled lifelogging device to record her activities throughout the day and capture moments that would otherwise be hard to photograph. She is concerned about the camera taking photos in sensitive areas. She sets a PlaceAvoider policy, enrolling her five apartment rooms and asserting that she does not want photos taken in her bathroom or bedroom. She sets a similar policy at work, enrolling her office, lab, and conference room, deeming the lab a sensitive room.

Soon after, she receives an alert on her smartphone indicating that an application is attempting to take a photo in a sensitive space. She confirms the alert, uninstalls the app, and later downloads the photos from her lifelogging camera. PlaceAvoider organizes her photos temporally and spatially, flagging the images taken in sensitive spaces.

## 3. Image Classification
We now turn to the challenge of automatically recognizing where a photo was taken within an indoor space based on its visual content. We assume that GPS has provided a coarse position, so our goal is to classify image content among a relatively small number of possible rooms within a known structure.

We first consider how to classify single images using two complementary recognition techniques. We then show how to improve results by jointly classifying image sequences, taking advantage of temporal constraints on human motion in a probabilistic framework.