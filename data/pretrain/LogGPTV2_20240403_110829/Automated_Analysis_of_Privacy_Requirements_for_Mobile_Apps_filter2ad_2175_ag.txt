### Evaluation of Privacy Policy Consistency

We conducted an evaluation using a random sample of 20 popular apps from the Google Play Store and their associated privacy policies (referred to as the Cal AG app/policy set). We asked users from the California Attorney General's (Cal AG) office to provide their interpretations of these policies. These interpretations were then used to evaluate the performance of our system.

As shown in Table VII, the Facebook Login functionality appears to reliably identify the collection of contact information. However, the results are limited to this small sample of 20 app/policy pairs. Our system achieved high recall overall, indicating that it is effective at identifying the absence of potential inconsistencies. Similar to our findings in § V-A, we observed a non-negligible number of false positives. Specifically, the precision for the collection of device IDs was 0.5, and for location data, it was 0.38. Despite these low precision values, the high recall suggests that our system is unlikely to miss many potential inconsistencies. Upon closer manual inspection, some of these false positives will likely be confirmed as false alarms.

### Future Directions

The law of notice and choice is intended to enforce data practices in mobile apps and other online services. However, verifying whether an app actually adheres to its stated privacy policy is a significant challenge. To address this, we propose an automated analysis system based on machine learning and static analysis to identify potential privacy requirement inconsistencies. Our system advances app privacy in three key areas: it enhances transparency for otherwise opaque data practices, provides the scalability needed to impact the entire app ecosystem, and represents a first step towards automating mobile app privacy compliance analysis.

Our results suggest that potential privacy requirement inconsistencies occur on a large scale. However, the full potential of the techniques introduced here has yet to be fully explored. For example, the privacy policy analysis can be further developed to capture nuances in policy wording, possibly by leveraging the structure of policies (e.g., by identifying definitions of PII and where they are referenced). Similarly, the accuracy of the app analysis could be improved by integrating data flow analysis techniques. However, for performance reasons, resources should be used sparingly. A practical system for large-scale app analysis must remain relatively lightweight.

### Extending the Approach

The findings in this study raise the question of extending our approach to other areas. We believe the principles could be applied to analyzing website practices, for example, by building on the work of Sen et al. [61]. First and third-party cookies and other tracking mechanisms could be observed to evaluate the collection and sharing of data. Implementing our approach on other mobile platforms, particularly iOS, may be more challenging. The difficulty of decompiling iOS apps might necessitate a dynamic app analysis approach [19], [43]. Additionally, the web interface of Apple’s App Store does not provide a standardized privacy policy link field. However, these challenges do not preclude the integration of privacy requirement analysis into iOS software development tools.

### Regulatory and Development Implications

We believe it is necessary to develop the proposed privacy requirement analysis in conjunction with public policy and law. Regulators are currently pushing for app store standardization [10] and early enforcement of potentially non-compliant privacy practices [31]. Approaches like the one proposed here can alleviate regulators' workloads through automation, allowing them to focus their limited resources on moving from a purely reactionary approach to systematic oversight. Since many software publishers do not intend to be non-compliant but may lose track of their obligations or be unaware of them, there is potential for integrating privacy requirement analyses into software development tools and the app vetting process in app stores.

### Acknowledgment

We would like to thank the anonymous reviewers for their comments on the draft of this study. We are also grateful for the insights provided by our Cal AG collaborators Justin Erlich, Cassidy Kim, Stacey Schesser, TiTi Nguyen, Joanne McNabb, Sarah Dalton, Jeremy AronDine, and Sundeep Pattem. We further thank our academic collaborators Aswarth Dara, Peter Story, Mads Schaarup Andersen, Amit Levy, Vaggelis Atlidakis, and Jie SB Li. This study was supported in part by the NSF under grants CNS-1330596, CNS-1330214, and SBE-1513957, as well as by DARPA and the Air Force Research Laboratory, under agreement number FA8750-15-2-0277. The US Government is authorized to reproduce and distribute reprints for governmental purposes notwithstanding any copyright notation thereon. The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies or endorsements, either expressed or implied, of DARPA, the Air Force Research Laboratory, the NSF, or the US Government.

### References

[1] V. Afonso, A. Bianchi, Y. Fratantonio, A. Doupe, M. Polino, P. de Geus, C. Kruegel, and G. Vigna, “Going native: Using a large-scale analysis of Android apps to create a practical native-code sandboxing policy,” in NDSS ’16. ISOC.
...
[72] S. Zimmeck and S. M. Bellovin, “Privee: An architecture for automatically analyzing web privacy policies,” in USENIX Security ’14. USENIX Assoc.

### Appendix A: Policy and App Datasets

1. **Full App Set** - Total Apps Collected from the Google Play Store (n=17,991)
2. **Full Policy Set** - Total Policies Collected for Apps in the Full App Set via Google Play Store Links (n=9,295)
3. **Full App/Policy Set** - Total App/Policy Pairs from the Full App and Full Policy Sets adjusted for Links not actually leading to a Policy (n=9,050)
4. **Policy Test Set** - Random Policies from the OPP-115 Corpus [67] (n=40)
5. **App Test Set** - Random Apps Associated with the Policies in the Policy Test Set (n=40)
6. **App/Policy Test Set** - App/Policy Pairs from the App and Policy Test Sets (n=40)
7. **Cal AG App/Policy Set** - Random Popular Apps and Associated Policies from the Google Play Store (n=20)

### Appendix B: Evaluating Potential Inconsistencies

| Statistic | TP | FP | FN | TN |
| --- | --- | --- | --- | --- |
| **Policy and App Classification** |  |  |  |  |
| Policy=0 correct and App=1 correct |  |  |  |  |
| Policy=0 incorrect and App=1 correct, or Policy=0 correct and App=1 incorrect, or Policy=0 incorrect and App=1 incorrect |  |  |  |  |
| Policy=1 incorrect and App=0 incorrect, or Policy=1 incorrect and App=1 correct, or Policy=0 correct and App=0 incorrect |  |  |  |  |
| All remaining combinations |  |  |  |  |

**Table VIII: Evaluating potential inconsistencies.** For example, a false positive can result from a policy being incorrectly classified as not covering a practice (Policy=0) while the practice actually occurs in the corresponding app (App=1), which was correctly identified.