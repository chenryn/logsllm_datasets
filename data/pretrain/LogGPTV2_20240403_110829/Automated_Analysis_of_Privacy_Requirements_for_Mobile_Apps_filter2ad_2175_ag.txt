on a random sample of 20 popular Play store apps and their
associated policies (Cal AG app/policy set). We asked the Cal
AG users to give us their interpretations of the policies and
used these to evaluate the results of our system. As shown
in Table VII, it appears that the Facebook Login functionality
is able to identify the contact information collection practice
fairly reliably. Obviously, the results are limited to a small
number of 20 app/policy pairs. Further, our system achieves
high recall overall. It performs well on identifying the absence
of potential
the same time, similar to
our results in § V-A, we ﬁnd a non-negligible number of
false positives. Particularly, we observe a precision of 0.5
for collection of device IDs and 0.38 for locations. However,
despite these low precision values,
the high recall values
suggest that our system is unlikely to miss many potential
inconsistencies. Rather, upon closer manual inspections some
of those will prove to be false alarms.
inconsistencies. At
VII. FUTURE DIRECTIONS
The law of notice and choice is intended to enable en-
forcement of data practices in mobile apps and other online
services. However, verifying whether an app actually behaves
according to the law and its privacy policy is decisively hard.
To alleviate this problem we propose the use of an automated
analysis system based on machine learning and static analysis
to identify potential privacy requirement inconsistencies. Our
system advances app privacy in three main areas: it increases
transparency for otherwise largely opaque data practices, offers
the scalability necessary for potentially making an impact on
the app eco-system as a whole, and provides a ﬁrst step towards
automating mobile app privacy compliance analysis.
Our results suggest the occurrence of potential privacy
requirement inconsistencies on a large scale. However, the
possibilities of the techniques introduced here have yet to be
fully explored. For example, the privacy policy analysis can
be further developed to capture nuances in policy wording—
possibly by leveraging the structure of policies (e.g., by
identifying deﬁnitions of PII and where those are referenced
in a policy). Similarly, the accuracy of the app analysis could
be enhanced by integrating data ﬂow analysis techniques.
However, for performance reasons resources should be used
13
sparingly. A practical system for the purpose of large-scale
app analysis necessarily remains relatively lightweight.
The ﬁndings in this study raise the question of extending
our approach to other areas. We believe, the principles could
be used in analyzing website practices, e.g., by leveraging
the work of Sen et al. [61]. First and third party cookies
and other tracking mechanisms could be observed to evaluate
collection and sharing of data. Implementing our approach
in other mobile platforms, particularly, iOS, is likely more
challenging. Notably, the difﬁculty of decompiling iOS apps
might necessitate a dynamic app analysis approach [19], [43].
The web interface of Apple’s App Store also does not seem
to provide app pages with a standardized privacy policy link
ﬁeld. However, these challenges would not need to be resolved
for the integration of a privacy requirement analysis into iOS
software development tools.
it
We think that
is necessary to develop the proposed
privacy requirement analysis in tandem with public policy and
law. Regulators are currently pushing for app store standardiza-
tion [10] and early enforcement of potentially non-compliant
privacy practices [31]. Approaches like the one proposed here
can relieve regulators’ workloads through automation allowing
them to focus their limited resources to move from a purely
reactionary approach towards systematic oversight. As we
also think that many software publishers do not intend non-
compliance with privacy requirements, but rather lose track of
their obligations or are unaware of them, we also see potential
for implementing privacy requirement analyses in software
development tools and integrating them into the app vetting
process in app stores.
ACKNOWLEDGMENT
We would like to thank the anonymous reviewers for their
comments on the draft of this study. We are also grateful for the
insights provided by our Cal AG collaborators Justin Erlich,
Cassidy Kim, Stacey Schesser, TiTi Nguyen, Joanne McN-
abb, Sarah Dalton, Jeremy AronDine, and Sundeep Pattem.
We further thank our academic collaborators Aswarth Dara,
Peter Story, Mads Schaarup Andersen, Amit Levy, Vaggelis
Atlidakis, and Jie SB Li. This study was supported in part
by the NSF under grants CNS-1330596, CNS-1330214, and
SBE-1513957, as well as by DARPA and the Air Force
Research Laboratory, under agreement number FA8750-15-
2-0277. The US Government is authorized to reproduce and
distribute reprints for Governmental purposes not withstanding
any copyright notation thereon. The views and conclusions
contained herein are those of the authors and should not be
interpreted as necessarily representing the ofﬁcial policies or
endorsements, either expressed or implied, of DARPA, the Air
Force Research Laboratory, the NSF, or the US Government.
REFERENCES
[1] V. Afonso, A. Bianchi, Y. Fratantonio, A. Doupe, M. Polino, P. de Geus,
C. Kruegel, and G. Vigna, “Going native: Using a large-scale analysis of android
apps to create a practical native-code sandboxing policy,” in NDSS ’16.
ISOC.
[2] Amazon, “Amazon EC2 instance types,” https://aws.amazon.com/ec2/instance-typ
es/, accessed: Dec 19, 2016.
[3] AppBrain, “Android library statistics,” http://www.appbrain.com/stats/libraries/,
accessed: Dec 19, 2016.
[4] S. Arzt, S. Rasthofer, C. Fritz, E. Bodden, A. Bartel, J. Klein, Y. Le Traon,
D. Octeau, and P. McDaniel, “FlowDroid: Precise context, ﬂow, ﬁeld, object-
sensitive and lifecycle-aware taint analysis for android apps,” in PLDI ’14. ACM.
14
[5] Ask Solem & Contributors, “Celery - distributed task queue,” http://docs.celerypr
oject.org/en/latest/, accessed: Dec 19, 2016.
[6] K. W. Y. Au, Y. F. Zhou, Z. Huang, and D. Lie, “PScout: Analyzing the android
permission speciﬁcation,” in CCS ’12. ACM.
[7] R. Balebako, A. Marsh, J. Lin, J. Hong, and L. F. Cranor, “The privacy and security
behaviors of smartphone app developers,” in USEC ’14.
[8] R. Bhoraskar, S. Han, J. Jeon, T. Azim, S. Chen, J. Jung, S. Nath, R. Wang,
and D. Wetherall, “Brahmastra: Driving apps to test the security of third-party
components,” in USENIX Security ’14. USENIX Assoc.
[9] T. Book and D. S. Wallach, “A case of collusion: A study of the interface between
ad libraries and their apps,” in SPSM ’13. ACM.
[10] California Department of Justice, “Attorney General Kamala D. Harris se-
cures global agreement
to strengthen privacy protections for users of mo-
bile applications,” http://www.oag.ca.gov/news/press-releases/attorney-general-ka
mala-d-harris-secures-global-agreement-strengthen-privacy, Feb. 2012, accessed:
Dec 19, 2016.
[11] ——, “Making your privacy practices public,” https://oag.ca.gov/sites/all/files/
agweb/pdfs/cybersecurity/making your privacy practices public.pdf, May 2014,
accessed: Dec 19, 2016.
[12] ——, “Attorney General Kamala D. Harris
to help
consumers
report violations of California Online Privacy Protection Act
(CalOPPA),” https://oag.ca.gov/news/press-releases/attorney-general-kamala-d-ha
rris-launches-new-tool-help-consumers-report, Oct. 2016, accessed: Dec 19, 2016.
[13] P. Chundi and P. M. Subramaniam, “An Approach to Analyze Web Privacy Policy
launches new tool
Documents,” in KDD Workshop on Data Mining for Social Good, 2014.
[14] E. Costante, J. den Hartog, and M. Petkovic, “What websites know about you:
Privacy policy analysis using information extraction,” in Data Privacy Management
’13. Springer.
[15] E. Costante, Y. Sun, M. Petkovi´c, and J. den Hartog, “A machine learning solution
to assess privacy policy completeness,” in WPES ’12. ACM.
[16] L. F. Cranor, K. Idouchi, P. G. Leon, M. Sleeper, and B. Ur, “Are they actually
any different? comparing thousands of ﬁnancial institutions’ privacy practices,” in
WEIS ’13.
[17] L. F. Cranor, M. Langheinrich, M. Marchiori, M. Presler-Marshall, and J. M.
Reagle, “The Platform for Privacy Preferences 1.0 (P3P1.0) speciﬁcation,” World
Wide Web Consortium, Recommendation REC-P3P-20020416, April 2002.
[18] S. Demetriou, W. Merrill, W. Yang, A. Zhang, and C. Gunter, “Free for all!
assessing user data exposure to advertising libraries on android,” in NDSS ’16.
ISOC.
[19] Z. Deng, B. Saltaformaggio, X. Zhang, and D. Xu, “iRiS: Vetting private api abuse
in iOS applications,” in CCS ’15. ACM.
[20] A. Desnos, “Androguard,” http://doc.androguard.re/html/index.html, accessed:
Dec 19, 2016.
[21] G. Dumpleton, “Modwsgi,” https://modwsgi.readthedocs.io/en/develop/, accessed:
Dec 19, 2016.
[22] W. Enck, P. Gilbert, B.-G. Chun, L. P. Cox, J. Jung, P. McDaniel, and A. N. Sheth,
“TaintDroid: An information-ﬂow tracking system for realtime privacy monitoring
on smartphones,” in OSDI ’10. USENIX Assoc.
[23] W. Enck, D. Octeau, P. McDaniel, and S. Chaudhuri, “A study of android
application security,” in USENIX Security ’11. USENIX Assoc.
[24] ESRB, “ESRB ratings guide,” http://www.esrb.org/ratings/ratings guide.aspx, ac-
cessed: Dec 19, 2016.
[25] Facebook, “Permissions reference - Facebook login,” https://developers.facebook.
com/docs/facebook-login/permissions, accessed: Dec 19, 2016.
[26] A. P. Felt, E. Chin, S. Hanna, D. Song, and D. Wagner, “Android permissions
demystiﬁed,” in CCS ’11. ACM.
[27] FTC, “Privacy online: A report to congress,” https://www.ftc.gov/reports/privacy-
online-report-congress, Jun. 1998, accessed: Dec 19, 2016.
[28] ——, “Mobile apps for kids: Current privacy disclosures are disappointing,” h
ttp://www.ftc.gov/os/2012/02/120216mobile apps kids.pdf, Feb. 2012, accessed:
Dec 19, 2016.
[29] ——, “Mobile apps for kids: Disclosures still not making the grade,” https://ww
w.ftc.gov/reports/mobile-apps-kids-disclosures-still-not-making-grade, Dec. 2012,
accessed: Dec 19, 2016.
[30] ——, “Mobile privacy disclosures,” www.ftc.gov/os/2013/02/130201mobileprivac
yreport.pdf, Feb. 2013, accessed: Dec 19, 2016.
[31] ——, “FTC warns children’s app maker BabyBus about potential COPPA viola-
tions,” https://www.ftc.gov/news-events/press-releases/2014/12/ftc-warns-children
s-app-maker-babybus-about-potential-coppa, Dec. 2014, accessed: Dec 19, 2016.
trade commission study on mobile shop-
ping apps,” https://www.ftc.gov/reports/whats-deal-federal-trade-commission-stud
y-mobile-shopping-apps-august-2014, Aug. 2014, accessed: Dec 19, 2016.
[32] ——, “What’s the deal? a federal
[33] ——, “Kids’ apps disclosures revisited,” https://www.ftc.gov/news-events/blogs/b
usiness-blog/2015/09/kids-apps-disclosures-revisited, Sep. 2015.
[34] K. Ghazinour, M. Majedi, and K. Barker, “A model for privacy policy visualiza-
[65] C. Tumbleson and R. Wi´sniewski, “Apktool,” https://ibotpeaches.github.io/Apktoo
tion,” in COMPSAC ’09.
IEEE.
l/, accessed: Dec 19, 2016.
[35] C. Gibler, J. Crussell, J. Erickson, and H. Chen, “AndroidLeaks: Automatically
detecting potential privacy leaks in android applications on a large scale,” in TRUST
’12. Springer.
[66] T. Watanabe, M. Akiyama, T. Sakai, and T. Mori, “Understanding the inconsisten-
cies between text descriptions and the use of privacy-sensitive resources of mobile
apps,” in SOUPS ’15. USENIX Assoc.
[67] S. Wilson, F. Schaub, A. A. Dara, F. Liu, S. Cherivirala, P. G. Leon, M. S.
Andersen, S. Zimmeck, K. M. Sathyendra, N. C. Russell, T. B. Norton, E. Hovy,
J. Reidenberg, and N. Sadeh, “The creation and analysis of a website privacy policy
corpus,” in ACL ’16. ACL.
[68] S. Wilson, F. Schaub, R. Ramanath, N. Sadeh, F. Liu, N. A. Smith, and F. Liu,
“Crowdsourcing annotations for websites’ privacy policies: Can it really work?”
in WWW ’16.
[69] L. Yu, X. Luo, X. Liu, and T. Zhang, “Can we trust the privacy policies of android
apps?” in DSN ’16.
[70] L. Yu, T. Zhang, X. Luo, and L. Xue, “AutoPPG: Towards automatic generation
of privacy policy for android applications,” in SPSM ’15. ACM.
[71] M. Zhang, Y. Duan, Q. Feng, and H. Yin, “Towards automatic generation of
security-centric descriptions for android apps,” in CCS ’15. ACM.
[72] S. Zimmeck and S. M. Bellovin, “Privee: An architecture for automatically
analyzing web privacy policies,” in USENIX Security ’14. USENIX Assoc.
APPENDIX A
POLICY AND APP DATASETS
1) Full App Set — Total Apps Collected from the Google
Play Store (n=17,991)
2) Full Policy Set — Total Policies Collected for Apps in
the Full App Set via Google Play Store Links (n=9,295)
3) Full App/Policy Set — Total App/Policy Pairs from the
Full App and Full Policy Sets adjusted for Links not
actually leading to a Policy (n=9,050)
4) Policy Test Set — Random Policies from the OPP-115
Corpus [67] (n=40)
5) App Test Set — Random Apps Associated with the
Policies in the Policy Test Set (n=40)
6) App/Policy Test Set — App/Policy Pairs from the App
and Policy Test Sets (n=40)
7) Cal AG App/Policy Set — Random Popular Apps and
Associated Policies from the Google Play Store (n=20)
EVALUATING POTENTIAL INCONSISTENCIES
APPENDIX B
Statistic
TP
FP
FN
TN
Policy and App Classiﬁcation
Policy=0 correct and App=1 correct
Policy=0 incorrect and App=1 correct, or
Policy=0 correct and App=1 incorrect, or
Policy=0 incorrect and App=1 incorrect
Policy=1 incorrect and App=0 incorrect, or
Policy=1 incorrect and App=1 correct, or
Policy=0 correct and App=0 incorrect
All remaining combinations
TABLE VIII: Evaluating potential inconsistencies. For ex-
ample, a false positive can be the result of a policy being
incorrectly classiﬁed as not covering a practice (Policy=0)
while the practice actually occurs in the corresponding app
(App=1), which was correctly identiﬁed.
[36] M. I. Gordon, D. Kim, J. Perkins, L. Gilham, N. Nguyen, and M. Rinard,
“Information-ﬂow analysis of Android applications in DroidSafe,” in NDSS ’15.
ISOC.
[37] A. Gorla, I. Tavecchia, F. Gross, and A. Zeller, “Checking app behavior against
app descriptions,” in ICSE ’14. ACM.
[38] GPEN, “2014 annual report,” https://www.privacyenforcement.net/node/513, Mar.
2015, accessed: Dec 19, 2016.
[39] M. C. Grace, W. Zhou, X. Jiang, and A.-R. Sadeghi, “Unsafe exposure analysis
of mobile in-app advertisements,” in WISEC ’12. ACM.
[40] C. Hoke, L. Cranor, P. Leon, and A. Au, “Are They Worth Reading? An In-Depth
Analysis of Online Trackers Privacy Policies,” I/S : A Journal of Law and Policy
for the Information Society, Apr. 2015.
J. Huang, X. Zhang, L. Tan, P. Wang, and B. Liang, “AsDroid: Detecting
stealthy behaviors in android applications by user interface and program behavior
contradiction,” in ICSE ’14. ACM.
[41]
[42] D. Kong, L. Cen, and H. Jin, “AUTOREB: Automatically understanding the review-
to-behavior ﬁdelity in android applications,” in CCS ’15. ACM.
[43] A. Kurtz, A. Weinlein, C. Settgast, and F. Freiling, “DiOS: Dynamic privacy
analysis of ios applications,” Friedrich-Alexander-Universit¨at Erlangen-N¨urnberg,
Dept. of Computer Science, Tech. Rep. CS-2014-03, Jun. 2014.
J. Lin, B. Liu, N. Sadeh, and J. I. Hong, “Modeling users’ mobile app privacy
preferences: Restoring usability in a sea of permission settings,” in SOUPS ’14.
USENIX Assoc.
[44]
[45] B. Liu, B. Liu, H. Jin, and R. Govindan, “Efﬁcient privilege de-escalation for ad
libraries in mobile apps,” in MobiSys ’15. ACM.
[46] F. Liu, R. Ramanath, N. Sadeh, and N. A. Smith, “A step towards usable privacy
policy: Automatic alignment of privacy statements,” in COLING ’14.
[47] C. D. Manning, P. Raghavan, and H. Sch¨utze, Introduction to Information Retrieval.
Cambridge University Press, 2008.
[48] A. K. Massey, J. Eisenstein, A. I. Ant´on, and P. P. Swire, “Automated text mining
for requirements analysis of policy documents,” in RE ’13.
[49] K. Olmstead and M. Atkinson, “Apps permissions
in the Google Play
store,” http://www.pewinternet.org/2015/11/10/apps-permissions-in-the-google-pl
ay-store/, Nov. 2015, accessed: Dec 19, 2016.
[50] Onyxbits, “Raccoon - apk downloader,” http://www.onyxbits.de/raccoon, accessed:
Dec 19, 2016.
[51] F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel,
M. Blondel, P. Prettenhofer, R. Weiss, V. Dubourg, J. Vanderplas, A. Passos,
D. Cournapeau, M. Brucher, M. Perrot, and E. Duchesnay, “Scikit-learn: Machine
learning in Python,” Journal of Machine Learning Research, 2011.
[52] Pivotal Software,
Inc,
“Rabbitmq,”
https://www.rabbitmq.com/,
accessed:
[53]
Dec 19, 2016.
ponty, “Pyvirtualdisplay,” https://pypi.python.org/pypi/PyVirtualDisplay, accessed:
Dec 19, 2016.
[54] Progress Software Corporation, “Fiddler,” http://www.telerik.com/fiddler, ac-
cessed: Dec 19, 2016.
[55] R. Ramanath, F. Liu, N. Sadeh, and N. A. Smith, “Unsupervised alignment of
[56]
privacy policies using hidden markov models,” in ACL ’14.
J. R. Reidenberg, T. Breaux, L. F. Cranor, B. French, A. Grannis, J. T. Graves,
F. Liu, A. McDonald, T. B. Norton, R. Ramanath, N. C. Russell, N. Sadeh, and
F. Schaub, “Disagreeable privacy policies: Mismatches between meaning and users’
understanding,” Berkeley Technology Law Journal, vol. 30, no. 1, pp. 39–88, 2015.
[57] D. Reidsma and J. Carletta, “Reliability measurement without limits,” Comput.
Linguist., vol. 34, no. 3, pp. 319–326, Sep. 2008.
[58] A. Ronacher, “Flask,” http://flask.pocoo.org/, accessed: Dec 19, 2016.
[59] N. Sadeh, A. Acquisti, T. D. Breaux, L. F. Cranor, A. M. McDonald, J. R.
Reidenberg, N. A. Smith, F. Liu, N. C. Russell, F. Schaub, and S. Wilson, “The
usable privacy policy project,” Carnegie Mellon University, Tech. report CMU-
ISR-13-119, 2013.
[60] Selenium
project,
“Selenium,”
http://www.seleniumhq.org/,
accessed:
Dec 19, 2016.
[61] S. Sen, S. Guha, A. Datta, S. K. Rajamani, J. Tsai, and J. M. Wing, “Bootstrapping
privacy compliance in big data systems,” in SP ’14.
[62] R. Slavin, X. Wang, M. Hosseini, W. Hester, R. Krishnan, J. Bhatia, T. Breaux,
and J. Niu, “Toward a framework for detecting privacy policy violation in android
application code,” in ICSE ’16. ACM.
J. W. Stamey and R. A. Rossi, “Automatically identifying relations in privacy
policies.” in SIGDOC ’09. ACM.
[63]
[64] The Apache Software Foundation, “Apache,” http://httpd.apache.org/, accessed:
Dec 19, 2016.
15