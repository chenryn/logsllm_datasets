PUF behavior can be explained rather intuitively from
physical processes, however, when PUFs should be used
for security purposes, a formal model is often required in
order to bootstrap mathematical reductions for higher level
security claims. Throughout literature, a number of attempts
towards formalizing a PUF deﬁnition exist. We brieﬂy
introduce them and point out why none of them captures
the full spectrum of proposed PUFs and their properties,
either by being too restrictive, i.e., excluding certain PUFs,
or by being too ad-hoc, i.e., listing perceived and even
assumed properties of certain PUFs instead of providing a
more general model. A similar overview and discussion has
been given by Rührmair et al. [33]. However, we do not
completely follow all their arguments and moreover point
out why the new models they propose are still insufﬁcient.
Pappu [1] describes the optical PUF as a physical one-way
function (POWF), taking a laser orientation as challenge and
producing a speckle pattern as response. The ﬁrst part of the
deﬁnition of a POWF states that it is a deterministic physical
interaction that is evaluable in constant time but cannot be
inverted by a probabilistic polynomial time adversary with a
non-negligible probability. The second part of the deﬁnition
focusses on the unclonability of the POWF: both simulating
399
a response and physically cloning the POWF should be
hard. The POWF deﬁnition was the ﬁrst formal attempt of
deﬁning a PUF and solely reﬂects the optical PUF, which
at that time was the only known PUF. As other PUFs were
introduced shortly after, it became clear that this deﬁnition
was too stringent, in particular regarding the one-wayness
assumption. Whilst the optical PUF has a very large range
of possible outputs (speckle patterns), many of the discussed
intrinsic PUFs on ICs have a small output length of only
one or a few bits. In the latter case, one-wayness does
not hold any longer, since inverting such a PUF with non-
negligible advantage becomes trivial. It is also noteworthy to
mention that, as also pointed out by Rührmair et al. [33], for
many security applications one-wayness of the PUF is not a
necessary condition. A ﬁnal issue with the POWF deﬁnition
is that it lacks any notion of noise, in fact it even describes
a POWF as a deterministic interaction. This is contradicted
by the fact that virtually all PUF proposals, including the
optical PUF, produce noisy responses due to uncontrollable
physical effects during the response measurement.
With the introduction of delay-based intrinsic PUFs,
Gassend et al. [16], propose the deﬁnition of physical
random functions to describe PUFs. In brief, a physical
random function is deﬁned as a function embodied by a
physical device, which is easy to evaluate but hard to
predict from a polynomial number of challenge-response
pairs (CRPs). Note that this deﬁnition replaces the very
stringent one-wayness assumption from POWFs by a more
relaxed unpredictability assumption. However, it was quickly
realized that due to the linearity of the internal PUF delays,
simple delay-based PUFs and in particular arbiter PUFs
are relatively easy to model from a limited number of
CRPs [20]. Rührmair et al. [24] show that even more elab-
orate delay-based PUF constructions can be modelled using
advanced machine learning techniques. Once such a model
is made, prediction of unknown responses becomes trivial.
It is clear that for these PUFs the level of unpredictability is
reduced signiﬁcantly when an adversary learns many CRPs.
Also note that the later introduced memory-based intrinsic
PUFs only possess a polynomial number of CRPs and hence
do not classify as physical random functions since they can
be easily modelled through exhaustive readout. Moreover,
the deﬁnition of physical random functions also does not
capture the possibility of noisy responses.
With the introduction of memory-based intrinsic PUFs,
Guajardo et al. [25] further reﬁne the formal speciﬁcation of
PUFs. They describe PUFs as inherently unclonable physical
systems with a challenge-response behavior. It is assumed
that (i) different responses are independent of each other,
(ii) it
to come up with unknown responses,
and (iii) tampering with the PUF substantially changes its
challenge-response behavior. For the ﬁrst time, it is made
explicit that PUF responses are observed as noisy measure-
ments. This deﬁnition also comes with a division in strong
is difﬁcult
and weak PUFs, depending on how many CRPs an adversary
is allowed to obtain in order to model the PUF. If the number
is exponentially large in some security parameter, the PUF
is called a strong PUF, otherwise the PUF is called weak.
It can be argued that some of the assumptions made in
this description do not have a solid experimental basis, in
particular regarding the tamper-evidence assumption, which
has not been tested in practice for any of the intrinsic
PUF proposals. Also, strong PUFs seem to be difﬁcult to
characterize in general, as the idea of a security parameter
is speciﬁc to each PUF instance, and no practical procedure
is proposed to exhibit the required exponential behavior in
practice. Moreover, the terms weak and strong PUFs are
confusing w.r.t. the classical cryptographic notions of weak
and strong pseudorandom functions, where weak and strong
do not refer to an amount of CRPs but to the ability of the
adversary to select his queries adaptively.
Following a similar analysis as above, Rührmaier et
al. [33] proposed yet a further reﬁnement of a formal PUF
deﬁnition. They keep the distinction between strong and
weak PUFs by Guajardo et al. [25] and build upon these
deﬁnitions. Both strong and weak PUFs are now deﬁned by
means of a security game with an adversary. Weak PUFs
are called obfuscating PUFs and are basically considered
as physically obfuscated keys. The main statement in the
deﬁnition of obfuscated PUFs is that an adversary cannot
learn the key after having had access to the PUF for a
limited amount of time. Strong PUFs are deﬁned similarly,
but here the adversary needs to come up with the response
to a randomly chosen challenge after having had access to
the PUF and a PUF oracle for some limited amount of time.
Some issues are again left unresolved in this formalization:
ﬁrst, despite building upon the work by Guajardo et al. [25],
responses are not considered to be noisy. Next, the use
of a PUF oracle in the deﬁnition of a strong PUF seems
questionable. It is argued that this oracle is introduced to
circumvent any kind of practical access restriction to the
PUF. However, if a PUF-based system is secured against
any attacks possible “by the current state of technology”, the
access to such an oracle provides an unrealistic advantage
to the adversary, which weakens the proposed deﬁnition.
Finally, Armknecht et al. [9] introduce another PUF model
that, as opposed to most of the previous proposals, was
not described following the introduction of a new PUF
construction but rather in an attempt to use existing PUFs
as cryptographic building blocks in a block cipher,
i.e.,
in an application of hardware entangled cryptography. For
this goal, the previously discussed deﬁnitions proved to be
insufﬁcient. Armknecht et al. [9] make a distinction between
algorithmic and physical properties of a PUF. From the
algorithmic side, a PUF is said to be a noisy function
for which the distribution of responses is indistinguishable
from a random distribution with a certain amount of min-
entropy. From the physical side, a PUF is assumed to be
400
physically unclonable and tamper-evident, i.e., any physical
attack against the PUF will irreversibly and randomly change
its challenge-response behavior. We already pointed out
the lack of experimental evidence for tamper-evidence of
intrinsic PUFs in practice, and the same argument applies to
this deﬁnition. Contrarily to most of the previous deﬁnitions,
here PUFs are explicitly deﬁned as noisy functions, where
the noise error of the output stays within a certain bound.
As pointed out in this section, existing approaches to
model the security properties of PUFs have several weak-
nesses and drawbacks. In the following, we formalize the
security features of physical functions in accordance to
existing literature on PUFs and propose a general security
framework for physical functions, which modularly captures
the most important properties of PUFs and allows for a
meaningful security analysis of PUF-based constructions.
III. FRAMEWORK
A. Background and Rationale
In this section, we explain the components and procedures
relevant for deploying physical functions (PF). Observe that
we focus not only on PUFs but on physical functions in
general, where unclonability is only one possible security
property. Before we provide formal deﬁnitions, we give an
overview of our framework, which is depicted in Figure 1
that shows all components necessary for creating, evaluating
and post-processing the output of a physical function. In the
following, we explain each of these components separately.
1) Physical Function: A Physical Function (PF) consists
of a physical component p that can be stimulated with
some challenge signal ˜x, which makes p respond with a
corresponding response signal ˜y. In addition to the physical
component p, a PF contains an evaluation procedure Eval
that, on input a digital representation x of ˜x, stimulates
the physical component with ˜x and obtains the resulting
response signal ˜y. Finally, Eval returns a digital represen-
tation y of ˜y. The challenge-response behavior of a PF
heavily relies on the properties of the physical component
p, uncontrollable random noise (e.g.,
thermal noise and
measurement uncertainties), and an evaluation parameter
αPF (e.g., a quantization factor) chosen by the PF manu-
facturer. Observe that the same physical component p can
yield completely different PFs if combined with different
evaluation procedures. This fact should be representable by
a comprehensive model.
2) Extraction Algorithm: Although the notion of a physi-
cal function suggests differently, a PF is not a function in the
classical sense. The main difference is that, when challenged
with the same challenge x twice, a PF may produce different
responses y. This is because the challenge-response behavior
of a PF heavily relies on the physical properties of its
physical component p, which is subject to uncontrollable
random noise. The effects of noise can be removed up to a
certain threshold by an extraction algorithm Extract, which
maps slightly different responses y to the same challenge x
to a unique output z according to some extraction parameter
αEX, which is typically chosen by the PF manufacturer or
the PF user (i.e., the entity that integrates the PUF into
a higher-level protocol or algorithm). We assume that the
extraction parameter speciﬁes both the deployed extraction
algorithm and all possible parameters (e.g., number of
output bits) of the chosen Extract algorithm. The Extract
algorithm can be executed in two different modes: setup
and reconstruction. If a challenge x is requested for the
ﬁrst time, setup mode is used to generate an output z and
some appropriate helper data h(cid:48). Later, when challenge x
is requested again together with helper data h = h(cid:48), the
reconstruction mode is used to recreate z. The purpose of
the helper data h(cid:48) is to twofold [34]: (i) h(cid:48) supports the
extraction algorithm Extract in recreating the same output
z for a challenge x, and (ii) h(cid:48) allows to bind given values
(e.g., cryptographic keys) to a PUF.
3) Physical Function System: As explained above, a PF
is usually coupled with an appropriate extraction algorithm.
Indeed, in a typical application scenario, a user will be
only aware of the challenges given to the PF and the
output returned by the extraction algorithm. Furthermore,
for almost all relevant security notions, both the deployed
PF and the extraction algorithm determine whether a security
property is given or not. Therefore, it is a natural choice to
abstract away the physical function PF and the extraction
algorithm Extract and consider their combination as one
single building block. We term this a Physical Function
System (PF system). Consequently, we will mostly refer to
PF systems only and refer to the underlying PF or extraction
algorithm only if necessary.
4) Creation Process: The creation of the physical com-
ponent p of a physical function PF is the result of a creation
process Create, usually performed by the manufacturer
of PF. The result of this process depends on a creation
parameter αCR that is chosen by the PF manufacturer and
some uncontrollable production variability.
5) Physical Function Infrastructure: We call the combi-
nation of all components described in (1) to (4) a Physical
Function Infrastructure (PFI). We stress that within a PFI
the creation, evaluation and extraction parameters are ﬁxed.
Furthermore, we assume that
these parameters uniquely
specify the deployed procedures, e.g., αPF deﬁnes the full
details of the Eval procedure.
B. Formalization
In the following, we formalize the concepts described
above. We start by introducing our notation.
1) Notation: Let A be a probabilistic procedure. Note that
with procedure we denote a probabilistic polynomial time
algorithm that may involve some physical process (e.g., the
evaluation of a PF). Then y ← A(x) refers to the event that
on input x, procedure A assigns its output to variable y.
401
Figure 1. Generic framework for physical functions.
The term [A(x)] denotes the set of all possible outputs of A
on input x that appear with a probability larger than 0. Let
E be some event (e.g., the result of a security experiment),
then Pr[E] denotes the probability that E occurs. Moreover,
for a set S, the expression s $← S refers to the event that s
has been randomly sampled from S. We denote with  the
empty string, and with HW(x) the Hamming weight of a
bitstring x, i.e., the number of non-zero bits of x.
2) Deﬁnitions: We now formally deﬁne the components
and procedures within a physical function infrastructure as
explained in Section III-A.
Deﬁnition 1 (Physical Function): A physical function PF
is a probabilistic procedure
PFp,αPF : X → Y
(1)
where X denotes the set of challenges and Y the set of
responses. Internally, a PF is the combination of a physical
component p and an evaluation procedure Eval, i.e.,
y ← PFp,αPF (x) = Evalp(αPF, x)
(2)
Usually, the speciﬁcation of p and αPF will be discarded in
our notation, that is we simply write PF instead of PFp,αPF.
physical
Deﬁnition 2 (Physical Function System): A
function system PFS is a probabilistic procedure
PFSp,αPF,αEX : X × (H ∪ {}) → Z × H,
(3)
where X is the set of challenges, H the set of helper data
values,  the empty string, and Z the set of outputs.
Internally, a PF system is the combination of a physical
function PF = PFp,αPF (Deﬁnition 1) and an extraction
algorithm Extract (see Section III-A), i.e.,
(z, h(cid:48)) ←PFSp,αPF,αEX(x, h)
= ExtractαEX(PFp,αPF (x), h)
(4)
402
Hereby, we require that if h (cid:54)= , then h(cid:48) = h. Only in
case h = , a new helper data h(cid:48) is generated for x. in the
following, we omit the internal components and abbreviate
PFS = PFSp,αPF,αEX.
Note that h =  means that Extract should be executed
in setup mode to generate a new helper data h w.r.t.