DCTraces from the dynamic crawler (DCTrace) and web
content of landing pages from the static crawler (LPages). Here
we focus on the malicious DCTraces that are identiﬁed as a
drive-by download by the dynamic crawler.
III. RULE-BASED LANDING PAGE DETECTION
In this section, we present our study on drive-by download
attacks and our system for landing page detection. In the spirit
of SNORT [7], we propose a rule-based detection method
which involves learning a set of rules, in this case the presence
or absence of a set of strings and clusters of strings, that are
used to detect individual MDNs.
The MDN represents the coordinated work of a person or
group attempting to funnel trafﬁc from potentially innocent
landing pages to exploit servers. Thus it is likely that similar
(or the same) content occurs on many of the landing pages.
Given the scale of many MDNs (which contain hundreds or
even thousands of landing pages as shown in Figure 3) it
is likely that the process of injecting malicious content into
compromised pages is done by script, rather than by hand.
Thus, it should be possible to identify previously-unknown
landing pages by searching the static crawl cache for the
malicious content already found on known-bad MDN landing
pages. This can be seen to be the case in Table II and Table
III, where we show strings suspected of being injected content
found on the landing pages associated with several MDNs and
the corresponding domains or URLs.
The basic architecture of our system is shown in Figure
2. We start with an initial set of MDNs. We use Arrow as
described by Zhang et al [8], but our system is agnostic in this
regard: we merely need a collection of MDNs to get started.
From the landing pages of these MDNs we extract strings
which are candidates to be the common content which in many
cases, causes the ﬁrst redirection. We then cluster those strings
and use multiclass feature selection to identify features that
best represent a particular MDN. We then search in the static
crawl cache for pages that possess those strings. In this way
we are able to discover pages within the static crawl cache
that are, with high likelihood, previously-undetected members
of already-known MDNs. Finally, we submit those pages to
the dynamic crawler to verify if they indeed lead to exploit
servers. We now review these steps in more detail.
A. Initial MDN Discovery
We use Arrow to discover an initial set of MDNs. Here we
only brieﬂy review the Arrow system and refer readers to the
paper [8] for details. Arrow works from a set of exploit servers
to ﬁnd MDNs. It takes the DCTrace (illustrated by Table I)
from the dynamic crawler, and then groups malicious traces
that lead to the same exploit server into one MDN. This initial
set of malicious DCTraces were detected by the production
dynamic crawler during normal webpage scanning.
Arrow
DCTrace
Dynamic Crawler (DC)
MDNs
Bing
Landing Pages Labeller
LPages
Static Crawler (SC)
Feature Extractor
Feature
Selector
Regex Alg.
Clustering Alg.
String Alg.
Trainer
Webpages
Rule-Based
Classi!er-Based
Detector
Validation
Suspicious
Pages
Intra Flow
Inter Flow
System Area
Fig. 2: System Diagram
often use fast-ﬂux techniques whereby they change IP ad-
dresses and hostnames frequently. Rather than use single a
domain name or IP address to denote a server, Arrow develops
a Host-IP-Cluster (HIC) to identify servers in the traces.
Simply put, Host-IP-Cluster is a data structure to represent
a group of hostnames that share a large percentage of IPs.
Details regarding HIC computation can be found in [8]. This
technique adds a level of robustness to Arrow’s ability to
identify MDNs. We use Host-IP-Clusters just as Arrow does.
As shown in Figure 2, we feed the output from the dynamic
crawler (DCTraces) to Arrow and receive the MDNs as output.
The original landing pages produced by Arrow then become
the initial seeds for our system.
B. Extracting Malicious Features from Landing Pages
Having found a collection of MDNs, we now examine the
web content of landing pages within an MDN. The ﬁrst task
is to detect common, malicious code segments in the landing
pages of the identiﬁed MDNs. We do this by examining the
content of these pages in the static crawler cache. From the
content, we extract all of the strings that potentially cause
malicious redirection. HTML elements such as ,
, , ,  or  are
potential sources of redirection. This stage produces many
strings per page, the majority of which will obviously be
innocent. For example, the www.nytimes.com page considered
earlier contained 28  strings (obviously we use this
page as example only, and it is not an MDN landing page).
We consider each string as a potential feature.
After processing a large volume of landing pages, we have
a feature space that contains many times more features (i.e.,
strings) than the number of landing pages. Each landing page,
indexed by its associated MDN, will also have a binary vector
indicating whether it contains a particular string or not. This
vector is very sparse; i.e., most strings appear on only a small
number of the landing pages.
C. String Clustering
MDNs can have complex structures. In general they consist
of a set of landing pages, redirection servers and exploit
servers. However, in order to prevent easy blacklisting, MDNs
In the next section, the feature selection process selects
the most discriminative features (i.e., strings) for particular
MDNs. However, these features can be brittle: some MDNs use
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 07:59:16 UTC from IEEE Xplore.  Restrictions apply. 
TABLE II: String features suspected of being injected content on known MDN landing pages. Observe that each is a link, and
that some show slight polymorphism. The feature number refers to a string-cluster rather than a string. Note: these features are
merely suspicious, and have not been validated.
Feature ID Feature String
642
642
642
442
442
442
2203
2203
2203
2203
/*  */
/*  */
/*  */
/*  */
TABLE III: Domains or URLs of landing pages which include members of the string cluster features in Table III. Some of these
string clusters, 642, occur on a wide range of domains, others are found within the same top tier domain, 2203, while others are
found on landing pages within the same hostname, 442. All of these were determined to be malicious at some time in the past.
Feature ID URL
642
642
642
642
642
642
442
442
2203
2203
2203
2203
bzmc.ﬂash-soul.com/html/skill/201103/1292.html
www.xn–4pvoj466jvub.net/faq.php
kdpiao.cn
www.fushi123.cn
www.zbzwow.cn/bbs/viewthread.php
www.hhhhu.com/info.html
fcguy.atspace.name/89.html
fcguy.atspace.name/site-12.html
www.akw81.yoyo.pl/art 30.php
www.amalysz.yoyo.pl/l.html
www.iwadala.yoyo.pl/darmowa-wersja-gry-ﬁm-speedway-grand-prix-2-do-pobrania.html
stowarzyszenie-amicus.yoyo.pl
polymorphism that impairs the effectiveness of the feature se-
lection. In certain MDNs, the malicious content varies slightly
from landing page to landing page. For example, in Table
II, the ﬁrst three strings are almost, but not quite, identical.
Though the injected content is essentially the same code “exact
matching” may be ineffective in the feature selection process.
This polymorphism of the injected content is quite common
and has the effect of expanding the feature space considerably.
As a result, feature selection based on “exact matching” fails
to learn the similar malicious strings employed in one MDN
resulting in a failed detection.
To address this problem, we develop a clustering module
for the extracted strings based on the string similarity. Even
though the polymorphic content is in a different form, the main
body of the code and the code logic remain the same. So for
each entity, we transform each string into a set of trigrams,
and use the Jaccard distance between two strings deﬁned as:
D12 = 1 −
Intersection(Set1, Set2)
U nion(Set1, Set2)
,
where Setk is the set of trigrams generated from the k-th
string. For example, if one string contains trigrams a, b, c
and d, and a second contains b, d, e, f and g the distance
between them would be 1 − 2/7 ≈ 0.71. This proves a
powerful technique in grouping the variants of polymorphic
injection: minor polymorphic variations end up being close
under this distance measure. This allows us to cluster the sets
of strings into groups. We cluster these trigram sets using
the ISODAT A [9] algorithm which does not require a pre-
selected number of clusters.
This technique may reduce the total number of candidate
features from a very large number of strings to a much smaller
number of string clusters. After feature selection, we end up
with a set of rules consisting of string clusters which we refer
as STRING CLUSTER. A string cluster may consist of one
string which can be viewed as a cluster containing a single
item. This feature set will also be used as one type of features
in the classiﬁer-based approach in the following section.
D. Feature Selection
Our task is now a feature selection problem: we seek to se-
lect the strings or string clusters that best represent a particular
MDN but are not indicative of webpages from either legitimate
sites or other MDNs. Recall that landing pages of infected
sites have little in common other than their membership of the
same MDN. Thus, strings that are common, or even similar,
between them are good candidates to have been written by the
MDN owner rather than the owners of the landing pages. That
is, strings that appear on the landing pages of one MDN but
seldom (or never) on those of other MDNs or on benign pages
are good features to characterize this particular MDN. The
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 07:59:16 UTC from IEEE Xplore.  Restrictions apply. 
strings that do best in distinguishing between MDNs, and more
importantly legitimate pages, emerge in this feature selection
phase.
We use a feature selection algorithm based on the mutual
information [10] between the i-th MDN and the k-th feature.
Deﬁne A (resp. C) as the number of landing pages not in
the i-th MDN that do not contain (resp. do contain) the k-
th feature. Deﬁne B (resp. D) as the number of landing
pages in the i-th MDN that do not contain (resp. do contain)
the k-th feature. Then a maximum likelihood estimate of the
information provided about membership in the i-th MDN by
the k-th feature is:
D
N
C
N
( ˆBD)( ˆCD)
( ˆAB)( ˆBD)
B
N
A
N
+
log2
+
log2
R(f ) =
log2
N · A
( ˆAB)( ˆAC)
N · D
N · B
N · C
( ˆCD)( ˆAC)
+
log2
where ˆAB = (A + B), ˆAC = (A + C),
ˆCD = (C + D), and N = A + B + C + D.
ˆBD = (B + D),
Finally, the set of potential features is ranked for each MDN
based on the scores. We select the top 5 ranked features for
each MDN, which best discriminate that particular MDN with
other MDNs and benign webpages under consideration. This
method not only effectively selects malicious code, but also
excludes benign injected code, like normal third-party web
tracking code (e.g.Google Analytics). As normal web tracking
code frequently appears in the benign webpage set,
their
ranking in MDNs would be lowered in the feature selection
process.
E. False Positive Pruning
The rule-based approach is very straightforward: we take
the strings and string-clusters found in Sections III-B and III-C,
and then search for pages that contain them in the static
crawler cache. Recall that these strings are common among
the already-found landing pages of a single MDN, and are thus
with high probability injected malicious content. However, it
is possible that landing pages that belong to very different sites
contain common content that is not malicious. This can happen
if both sites are using a template or web-site authoring tool
that produces content in a certain form.
With a view to reducing the possibility of such false
positives we do as follows. We search for each of our candidate
strings in a randomly selected sparse 10% subset of the static
crawler cache. Any string that co-occurs on landing pages as
result of a template or authoring tool should be found many
times in this sparse set. Many of these pages will also have
been scanned by the dynamic crawler. A feature is retained if
60% or more of the pages that contain the feature and have
been previously scanned by the dynamic crawler were also
detected as being malicious. Otherwise, we regard the string
as a benign feature and remove it from the candidate feature
list. This step is used as a sanity check to avoid producing
large numbers of false positives.
F. Rule-Based Experimental Results
We describe the experimental results used to validate our
proposed rule-based method in the following section. We
begin by describing the preprocessing step which identiﬁes
the MDNs determined from a large collection of DCTraces.
Next, the setup and the rule-based system results are analyzed.
Finally the validation results on the dynamic crawler for this
system is provided.
1) PreProcessing: Referring to the system diagram in Fig-
ure 2, we randomly selected 6.0 million malicious DCTraces
that were diagnosed as drive-by download attacks by the
production dynamic crawler. The traces are selected within
a 60-day period ending on two dates, August 25, 2011 and
January 2, 2012. The ﬁrst 60-day trace ending in August
2011 is used to conduct preliminary experiments with the rule-
based system and also evaluate the classiﬁer-based approach
described in the following section. Here, for brevity, we mainly
describe the details of the January 2, 2012 collection which
serves as our primary DCTrace data set.
We use Arrow to group the DCTraces into MDNs and
use these landing pages in each MDN as the input to the
remainder of our system for evaluation. After ﬁltering out
small MDNs containing no more than 20 distinct DCTraces,
Arrow discovered 53 MDNs with central servers and a total
of 719,089 landing pages. (We choose to study MDNs with a
central server topology because these architectures can be more
complex: the central server sometimes uses fast-ﬂux techniques
to control a collection of exploit servers [8].) Of these we
randomly selected 32,000 landing pages as malicious webpage
samples.
From a separate source we obtain 32,000 pages for our
benign data set. These webpages are known to be legitimate
since they are from reputable websites and have been manually
graded by human analysts. These webpages are a subset of the
those used to train the search engine’s ranker.
Thus, we have 32,000 each of known-good and known-
bad pages for training. We next obtain the webpage content
for these from the static crawler and retain only the strings as
described in Section III-B. We then generate a sparse binary
data set where each row represents a webpage and each column
represents a string found on at least one of the webpages.
The ﬁnal step for creating this experiment’s data set is
to label each webpage. Each MDN has its own label and
malicious landing pages are labeled based on the MDN it
belongs to. On the other hand, all 32,000 benign pages are
grouped under the same label. Thus our feature dataset has
webpages as rows and features as columns. A column is set to
true if the page in question contains that feature. There is one
additional column, which contains the label to indicate which
group the page belongs to (here group means a particular MDN
or the collection of benign pages).
2) Rule-Based Detection System: The features for the rule-
based system consist of individual strings and clusters of
strings. Selecting a maximum of 5 string or string-cluster fea-