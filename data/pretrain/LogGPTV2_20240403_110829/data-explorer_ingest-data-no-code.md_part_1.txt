---
title: 'Tutorial: Ingest monitoring data in Azure Data Explorer without code'
description: In this tutorial, you learn how to ingest monitoring data to Azure Data Explorer without one line of code and query that data.
ms.reviewer: kerend
ms.topic: tutorial
ms.date: 11/09/2022
# Customer intent: I want to ingest monitoring data to Azure Data Explorer without one line of code, so that I can explore and analyze my data by using queries.
---
# Tutorial: Ingest and query monitoring data in Azure Data Explorer
This tutorial will teach you how to ingest data from diagnostic and activity logs to an Azure Data Explorer cluster without writing code. With this simple ingestion method, you can quickly begin querying Azure Data Explorer for data analysis.
In this tutorial, you'll learn how to:
> [!div class="checklist"]
>
> * Create tables and ingestion mapping in an Azure Data Explorer database.
> * Format the ingested data by using an update policy.
> * Create an [event hub](/azure/event-hubs/event-hubs-about)  and connect it to Azure Data Explorer.
> * Stream data to an event hub from Azure Monitor [diagnostic metrics and logs](/azure/azure-monitor/platform/diagnostic-settings) and [activity logs](/azure/azure-monitor/platform/activity-logs-overview).
> * Query the ingested data by using Azure Data Explorer.
> [!NOTE]
> Create all resources in the same Azure location or region.
## Prerequisites
* An Azure subscription. Create a [free Azure account](https://azure.microsoft.com/free/).
* An Azure Data Explorer cluster and database. [Create a cluster and database](create-cluster-and-database.md). In this tutorial, the database name is *TestDatabase*.
## Azure Monitor data provider: diagnostic metrics and logs and activity logs
View and understand the data provided by the Azure Monitor diagnostic metrics and logs and activity logs below. You'll create an ingestion pipeline based on these data schemas. Note that each event in a log has an array of records. This array of records will be split later in the tutorial.
### Examples of diagnostic metrics and logs and activity logs
Azure diagnostic metrics and logs and activity logs are emitted by an Azure service and provide data about the operation of that service.
### [Diagnostic metrics](#tab/diagnostic-metrics)
#### Diagnostic metrics example
Diagnostic metrics are aggregated with a time grain of 1 minute. Following is an example of an Azure Data Explorer metric-event schema on query duration:
```json
{
    "records": [
    {
        "count": 14,
        "total": 0,
        "minimum": 0,
        "maximum": 0,
        "average": 0,
        "resourceId": "/SUBSCRIPTIONS//RESOURCEGROUPS//PROVIDERS/MICROSOFT.KUSTO/CLUSTERS/",
        "time": "2018-12-20T17:00:00.0000000Z",
        "metricName": "QueryDuration",
        "timeGrain": "PT1M"
    },
    {
        "count": 12,
        "total": 0,
        "minimum": 0,
        "maximum": 0,
        "average": 0,
        "resourceId": "/SUBSCRIPTIONS//RESOURCEGROUPS//PROVIDERS/MICROSOFT.KUSTO/CLUSTERS/",
        "time": "2018-12-21T17:00:00.0000000Z",
        "metricName": "QueryDuration",
        "timeGrain": "PT1M"
    }
    ]
}
```
### [Diagnostic logs](#tab/diagnostic-logs)
#### Diagnostic logs example
Following is an example of an Azure Data Explorer [diagnostic ingestion log](using-diagnostic-logs.md#diagnostic-logs-schema):
```json
{
    "time": "2019-08-26T13:22:36.8804326Z",
    "resourceId": "/SUBSCRIPTIONS//RESOURCEGROUPS//PROVIDERS/MICROSOFT.KUSTO/CLUSTERS/",
    "operationName": "MICROSOFT.KUSTO/CLUSTERS/INGEST/ACTION",
    "operationVersion": "1.0",
    "category": "FailedIngestion",
    "resultType": "Failed",
    "correlationId": "d59882f1-ad64-4fc4-b2ef-d663b6cc1cc5",
    "properties": {
        "OperationId": "00000000-0000-0000-0000-000000000000",
        "Database": "Kusto",
        "Table": "Table_13_20_prod",
        "FailedOn": "2019-08-26T13:22:36.8804326Z",
        "IngestionSourceId": "d59882f1-ad64-4fc4-b2ef-d663b6cc1cc5",
        "Details":
        {
            "error":
            {
                "code": "BadRequest_DatabaseNotExist",
                "message": "Request is invalid and cannot be executed.",
                "@type": "Kusto.Data.Exceptions.DatabaseNotFoundException",
                "@message": "Database 'Kusto' was not found.",
                "@context":
                {
                    "timestamp": "2019-08-26T13:22:36.7179157Z",
                    "serviceAlias": "",
                    "machineName": "KEngine000001",
                    "processName": "Kusto.WinSvc.Svc",
                    "processId": 5336,
                    "threadId": 6528,
                    "appDomainName": "Kusto.WinSvc.Svc.exe",
                    "clientRequestd": "DM.IngestionExecutor;a70ddfdc-b471-4fc7-beac-bb0f6e569fe8",
                    "activityId": "f13e7718-1153-4e65-bf82-8583d712976f",
                    "subActivityId": "2cdad9d0-737b-4c69-ac9a-22cf9af0c41b",
                    "activityType": "DN.AdminCommand.DataIngestPullCommand",
                    "parentActivityId": "2f65e533-a364-44dd-8d45-d97460fb5795",
                    "activityStack": "(Activity stack: CRID=DM.IngestionExecutor;a70ddfdc-b471-4fc7-beac-bb0f6e569fe8 ARID=f13e7718-1153-4e65-bf82-8583d712976f > DN.Admin.Client.ExecuteControlCommand/5b764b32-6017-44a2-89e7-860eda515d40 > P.WCF.Service.ExecuteControlCommandInternal..IAdminClientServiceCommunicationContract/c2ef9344-069d-44c4-88b1-a3570697ec77 > DN.FE.ExecuteControlCommand/2f65e533-a364-44dd-8d45-d97460fb5795 > DN.AdminCommand.DataIngestPullCommand/2cdad9d0-737b-4c69-ac9a-22cf9af0c41b)"
                },
                "@permanent": true
            }
        },
        "ErrorCode": "BadRequest_DatabaseNotExist",
        "FailureStatus": "Permanent",
        "RootActivityId": "00000000-0000-0000-0000-000000000000",
        "OriginatesFromUpdatePolicy": false,
        "ShouldRetry": false,
        "IngestionSourcePath": "https://c0skstrldkereneus01.blob.core.windows.net/aam-20190826-temp-e5c334ee145d4b43a3a2d3a96fbac1df/3216_test_3_columns_invalid_8f57f0d161ed4a8c903c6d1073005732_59951f9ca5d143b6bdefe52fa381a8ca.zip"
    }
}
```
### [Activity logs](#tab/activity-logs)
#### Activity logs example
Azure activity logs are subscription-level logs that provide insight into the operations performed on resources in your subscription. Following is an example of an activity-log event for checking access:
```json
{
    "records": [
    {
        "time": "2018-12-26T16:23:06.1090193Z",
        "resourceId": "/SUBSCRIPTIONS//RESOURCEGROUPS//PROVIDERS/MICROSOFT.WEB/SITES/CLNB5F73B70-DCA2-47C2-BB24-77B1A2CAAB4D/PROVIDERS/MICROSOFT.AUTHORIZATION",
        "operationName": "MICROSOFT.AUTHORIZATION/CHECKACCESS/ACTION",
        "category": "Action",
        "resultType": "Start",
        "resultSignature": "Started.",
        "durationMs": 0,
        "callerIpAddress": "13.66.225.188",
        "correlationId": "0de9f4bc-4adc-4209-a774-1b4f4ae573ed",
        "identity": {
            "authorization": {
                ...
            },
            "claims": {
                ...
            }
        },
        "level": "Information",
        "location": "global",
        "properties": {
            ...
        }
    },
    {
        "time": "2018-12-26T16:23:06.3040244Z",
        "resourceId": "/SUBSCRIPTIONS//RESOURCEGROUPS//PROVIDERS/MICROSOFT.WEB/SITES/CLNB5F73B70-DCA2-47C2-BB24-77B1A2CAAB4D/PROVIDERS/MICROSOFT.AUTHORIZATION",
        "operationName": "MICROSOFT.AUTHORIZATION/CHECKACCESS/ACTION",
        "category": "Action",
        "resultType": "Success",
        "resultSignature": "Succeeded.OK",
        "durationMs": 194,
        "callerIpAddress": "13.66.225.188",
        "correlationId": "0de9f4bc-4adc-4209-a774-1b4f4ae573ed",
        "identity": {
            "authorization": {
                ...
            },
            "claims": {
                ...
            }
        },
        "level": "Information",
        "location": "global",
        "properties": {
            "statusCode": "OK",
            "serviceRequestId": "87acdebc-945f-4c0c-b931-03050e085626"
        }
    }]
}
```
---
## Set up an ingestion pipeline in Azure Data Explorer
Setting up an Azure Data Explorer pipeline involves several steps, such as [table creation and data ingestion](ingest-sample-data.md#ingest-data). You can also manipulate, map, and update the data.
### Connect to the Azure Data Explorer web UI
In your Azure Data Explorer *TestDatabase* database, select **Query** to open the Azure Data Explorer web UI.
![Query page.](media/ingest-data-no-code/query-database.png)
### Create the target tables
The structure of the Azure Monitor logs isn't tabular. You'll manipulate the data and expand each event to one or more records. The raw data will be ingested to an intermediate table named *ActivityLogsRawRecords* for activity logs and *DiagnosticRawRecords* for diagnostic metrics and logs. At that time, the data will be manipulated and expanded. Using an update policy, the expanded data will then be ingested into the *ActivityLogs* table for activity logs, *DiagnosticMetrics* for diagnostic metrics and *DiagnosticLogs* for diagnostic logs. This means that you'll need to create two separate tables for ingesting activity logs and three separate tables for ingesting diagnostic metrics and logs.
Use the Azure Data Explorer web UI to create the target tables in the Azure Data Explorer database.
### [Diagnostic metrics](#tab/diagnostic-metrics)
#### Create tables for the diagnostic metrics
1. In the *TestDatabase* database, create a table named *DiagnosticMetrics* to store the diagnostic metrics records. Use the following `.create table` management command:
    ```kusto
    .create table DiagnosticMetrics (Timestamp:datetime, ResourceId:string, MetricName:string, Count:int, Total:double, Minimum:double, Maximum:double, Average:double, TimeGrain:string)
    ```
1. Select **Run** to create the table.
    ![Run query.](media/ingest-data-no-code/run-query.png)
1. Create the intermediate data table named *DiagnosticRawRecords* in the *TestDatabase* database for data manipulation using the following query. Select **Run** to create the table.
    ```kusto
    .create table DiagnosticRawRecords (Records:dynamic)
    ```
1. Set zero [retention policy](./kusto/management/show-table-retention-policy-command.md) for the intermediate table:
    ```kusto
    .alter-merge table DiagnosticRawRecords policy retention softdelete = 0d
    ```
### [Diagnostic logs](#tab/diagnostic-logs)
#### Create tables for the diagnostic logs
1. In the *TestDatabase* database, create a table named *DiagnosticLogs* to store the diagnostic log records. Use the following `.create table` management command:
    ```kusto
    .create table DiagnosticLogs (Timestamp:datetime, ResourceId:string, OperationName:string, Result:string, OperationId:string, Database:string, Table:string, IngestionSourceId:string, IngestionSourcePath:string, RootActivityId:string, ErrorCode:string, FailureStatus:string, Details:string)
    ```
1. Select **Run** to create the table.
1. Create the intermediate data table named *DiagnosticRawRecords* in the *TestDatabase* database for data manipulation using the following query. Select **Run** to create the table.
    ```kusto
    .create table DiagnosticRawRecords (Records:dynamic)
    ```
1. Set zero [retention policy](./kusto/management/show-table-retention-policy-command.md) for the intermediate table:
    ```kusto
    .alter-merge table DiagnosticRawRecords policy retention softdelete = 0d
    ```
### [Activity logs](#tab/activity-logs)
#### Create tables for the activity logs
1. Create a table named *ActivityLogs* in the *TestDatabase* database to receive activity log records. To create the table, run the following Azure Data Explorer query:
    ```kusto
    .create table ActivityLogs (Timestamp:datetime, ResourceId:string, OperationName:string, Category:string, ResultType:string, ResultSignature:string, DurationMs:int, IdentityAuthorization:dynamic, IdentityClaims:dynamic, Location:string, Level:string)
    ```
1. Create the intermediate data table named *ActivityLogsRawRecords* in the *TestDatabase* database for data manipulation:
    ```kusto
    .create table ActivityLogsRawRecords (Records:dynamic)
    ```
1. Set zero [retention policy](./kusto/management/show-table-retention-policy-command.md) for the intermediate table:
    ```kusto
    .alter-merge table ActivityLogsRawRecords policy retention softdelete = 0d
    ```
---
### Create table mappings
 Because the data format is `json`, data mapping is required. The `json` mapping maps each json path to a table column name. JSON paths that include special characters should be escaped as [\'Property Name\']. For more information, see [JSONPath syntax](kusto/query/jsonpath.md).
### [Diagnostic metrics / Diagnostic logs](#tab/diagnostic-metrics+diagnostic-logs)
#### Map diagnostic metrics and logs to the table
To map the diagnostic metric and log data to the table, use the following query:
```kusto
.create table DiagnosticRawRecords ingestion json mapping 'DiagnosticRawRecordsMapping' '[{"column":"Records","Properties":{"path":"$.records"}}]'
```
### [Activity logs](#tab/activity-logs)
#### Map activity logs to the table
To map the activity log data to the table, use the following query:
```kusto
.create table ActivityLogsRawRecords ingestion json mapping 'ActivityLogsRawRecordsMapping' '[{"column":"Records","Properties":{"path":"$.records"}}]'
```
---
### Create the update policy for metric and log data
### [Diagnostic metrics](#tab/diagnostic-metrics)
#### Create data update policy for diagnostics metrics
1. Create a [function](kusto/management/functions.md) that expands the collection of diagnostic metric records so that each value in the collection receives a separate row. Use the [`mv-expand`](kusto/query/mv-expand-operator.md) operator:
     ```kusto