of those who are using camera-based assistive technolo-
gies. For example, Li et al. [56] and Hasan et al. [37, 56]
have been studying privacy transforms that are also visually
appealing to the viewer. For assistive applications, further
research is needed to understand how the quality of assis-
tance might degrade with obfuscating transforms. Tech-
nologies should help to decide the appropriate audience for
the type of question and take appropriate measures for detect-
ing privacy violations for that audience, or, conversely, pick
the right audience based on all subject matter in the photo (and
not just the foreground object). People should be informed if
PII, in particular, is present while using crowd-sourced tech-
nology whereas they should know if prescription medications
are visible when seeking assistance from friends.
Finally, given that our study focused on camera-based as-
sistive technologies, we believe that technical systems, more
broadly, might be creating differential forms of insecurity in
the daily lives of people with VIPs. This leads to a ‘security
paradox’ whereby, on the one hand, these systems are being
used by people with VIPs since they serve an important need
in enabling them to maintain their routines, yet they are also
generating insecurity as they expose them to additional vulner-
abilities. Thus, we need to continue to understand where
systems are creating insecurity through additional explo-
rations of a broad range of assistive technologies amongst
the visually impaired, while also uncovering new values
that can drive future design.
6.3 Limitations
We note several limitations of our study, which could be ad-
dressed in future work. Our participant sample was small,
limited to a few national blind foundations, and restricted to
those who chose to respond to an ad about camera-based assis-
tive technology, so it is difﬁcult to know how well our ﬁndings
generalize to the greater population. However, we also note
the challenges in reaching this population, and compared to
other recent studies of privacy concerns for the visually im-
paired, our sample size is relatively large [7, 14, 75]. We con-
sidered only three types of human assistants; however, other
social groups may have an impact on the information sharing
behaviors of people with VIPs, such as co-workers and spe-
ciﬁc categories of friends (close, distant). Our qualitative data
also showed a distinction between professional crowd agents
versus volunteers and should be explored in future work. In
this study, we considered only the effect of background con-
tent and audiences on a user’s sharing preferences. There may
be other factors that affect people’s preferences as well, such
as the sharing context and purpose. Future research should
study the privacy needs of people with VIPs for other social
groups in varying situations.
7 Conclusion
To better understand the privacy concerns of people with
visual impairments in the context of photo-based, human-
assisted question-answering systems we conducted an online
1942    29th USENIX Security Symposium
USENIX Association
survey with 155 visually impaired people. We found that
while people with visual impairments have privacy and secu-
rity concerns about revealing background objects, their infor-
mation disclosure preferences vary according to the types of
objects and human assistants. Our ﬁndings, in some cases,
were often counter-intuitive. For example, participants were
more concerned with the privacy of bystanders than their
own privacy and they were more comfortable sharing con-
cerns about self-presentation with family (and possibly crowd
workers) as opposed to friends. Moreover, we believe that the
ways in which these systems are designed can create a lack
of personal security in the lives of the people we are trying to
assist. Although assistive technologies have great potential
for social good, they can also potentially harm people. As
designers and builders of sociotechnical systems, we must
continue to understand the more positive aspects as well as the
moral and ethical dilemmas that may arise when our systems
are used. In doing so, we hope these systems will continue to
take on more humanistic, empathetic qualities, and achieve
our goals of assisting as opposed to harming others.
Acknowledgments
This material is based upon work supported in part by the US
National Science Foundation under awards CNS-1408730,
CNS-1252697, and IIS-1657429. We thank Jeffrey P. Bigham
and the VizWiz team for sharing their data with us. We thank
our participants, as well as Sharon Lovering from the Amer-
ican Council of the Blind and Lou Ann Blake from the Na-
tional Federation of the Blind, for helping recruit participants.
References
[1] Aira (2018). https://aira.io/.
[2] Be My Eyes (2018). www.bemyeyes.com.
[3] Ali Abdolrahmani, Ravi Kuber, and Amy Hurst. An
empirical investigation of the situationally-induced im-
pairments experienced by blind mobile device users. In
Proceedings of the 13th Web for All Conference, page 21.
ACM, 2016.
[4] Alessandro Acquisti, Ralph Gross, and Frederic D.
Stutzman. Face recognition and privacy in the age
of augmented reality. Journal of Privacy and Conﬁden-
tiality, 6(2):1, 2014.
[5] Dustin Adams, Lourdes Morales, and Sri Kurniawan. A
qualitative study to support a blind photography mobile
In Proceedings of the 6th International
application.
Conference on PErvasive Technologies Related to Assis-
tive Environments, page 25. ACM, 2013.
[6] Tousif Ahmed, Roberto Hoyle, Kay Connelly, David
Crandall, and Apu Kapadia. Privacy concerns and be-
haviors of people with visual impairments. In Proceed-
ings of the 33rd Annual ACM Conference on Human
Factors in Computing Systems, pages 3523–3532, 2015.
[7] Tousif Ahmed, Apu Kapadia, Venkatesh Potluri, and
Manohar Swaminathan. Up to a limit?: Privacy con-
cerns of bystanders and their willingness to share addi-
tional information with visually impaired users of assis-
tive technologies. Proceedings of the ACM on Inter-
active, Mobile, Wearable and Ubiquitous Technologies,
2(3):89, 2018.
[8] Tousif Ahmed, Patrick Shaffer, Kay Connelly, David
Crandall, and Apu Kapadia. Addressing physical safety,
security, and privacy for people with visual impairments.
In Twelfth Symposium on Usable Privacy and Security
(SOUPS 2016), pages 341–354, 2016.
[9] Taslima Akter, Bryan Dosono, Tousif Ahmed, Apu Ka-
padia, and Bryan Semaan.
Privacy implications of
artiﬁcial and human intelligence assistive tools for visu-
ally impaired people. In CHI Workshop on Bridging the
Gap Between AI and HCI, 2019.
[10] Jeffrey S. Anastasi and Matthew G. Rhodes. An
own-age bias in face recognition for children and older
adults. Psychonomic Bulletin & Review, 12(6):1043–
1047, 2005.
[11] Stanislaw Antol, Aishwarya Agrawal, Jiasen Lu, Mar-
garet Mitchell, Dhruv Batra, C. Lawrence Zitnick, and
Devi Parikh. Vqa: Visual question answering.
In
Proceedings of the IEEE International Conference on
Computer Vision, pages 2425–2433, 2015.
[12] Mauro Avila, Katrin Wolf, Anke Brock, and Niels
Henze. Remote assistance for blind users in daily life:
A survey about be my eyes. In Proceedings of the 9th
ACM International Conference on PErvasive Technolo-
gies Related to Assistive Environments, page 85. ACM,
2016.
[13] Shiri Azenkot, Kyle Rector, Richard Ladner, and Jacob
Wobbrock. Passchords: Secure multi-touch authenti-
In Proceedings of the 14th
cation for blind people.
International ACM SIGACCESS Conference on Com-
puters and Accessibility, pages 159–166. ACM, 2012.
[14] Natã M. Barbosa, Jordan Hayes, and Yang Wang. Uni-
pass: Design and evaluation of a smart device-based
password manager for visually impaired users. In Pro-
ceedings of the 2016 ACM International Joint Confer-
ence on Pervasive and Ubiquitous Computing, pages
49–60. ACM, 2016.
USENIX Association
29th USENIX Security Symposium    1943
[15] Michael S. Bernstein, Joel Brandt, Robert C. Miller,
and David R Karger. Crowds in two seconds: Enabling
In Proceedings
realtime crowd-powered interfaces.
of the 24th annual ACM symposium on User Interface
Software and Technology, pages 33–42. ACM, 2011.
[24] Brendan Cassidy, Gilbert Cockton, and Lynne Coven-
try. A haptic ATM interface to assist visually impaired
users. In Proceedings of the 15th International ACM
SIGACCESS Conference on Computers and Accessibil-
ity, page 1. ACM, 2013.
[16] Jeffrey P. Bigham, Chandrika Jayant, Hanjie Ji, Greg
Little, Andrew Miller, Robert C. Miller, Robin Miller,
Aubrey Tatarowicz, Brandyn White, Samual White, et al.
Vizwiz: Nearly real-time answers to visual questions.
In Proceedings of the 23nd Annual ACM Symposium on
User Interface Software and Technology, pages 333–342.
ACM, 2010.
[17] Michael Bosnjak and Tracy L. Tuten. Prepaid and
promised incentives in web surveys: An experiment.
Social Science Computer Review, 21(2):208–217, 2003.
[18] Erin Brady, Meredith Ringel Morris, and Jeffrey P.
Bigham. Gauging receptiveness to social microvol-
In Proceedings of the 33rd Annual ACM
unteering.
Conference on Human Factors in Computing Systems,
pages 1055–1064. ACM, 2015.
[19] Erin Brady, Meredith Ringel Morris, Yu Zhong, Samuel
White, and Jeffrey P. Bigham. Visual challenges in the
everyday lives of blind people. In Proceedings of the
SIGCHI Conference on Human Factors in Computing
Systems, pages 2117–2126. ACM, 2013.
[20] Erin L. Brady, Yu Zhong, Meredith Ringel Morris, and
Jeffrey P. Bigham. Investigating the appropriateness of
social network question asking as a resource for blind
users. In Proceedings of the 2013 Conference on Com-
puter Supported Cooperative Work, pages 1225–1236.
ACM, 2013.
[21] Stacy M. Branham, Ali Abdolrahmani, William Easley,
Morgan Scheuerman, Erick Ronquillo, and Amy Hurst.
Is someone there? Do they have a gun: How visual
information about others can improve personal safety
management for blind individuals. In Proceedings of
the 19th International ACM SIGACCESS Conference
on Computers and Accessibility, pages 260–269. ACM,
2017.
[22] Judith Butler. Performative acts and gender constitution:
An essay in phenomenology and feminist theory. In The
Routledgefalmer Reader in Gender & Education, pages
73–83. Routledge, 2006.
[23] Sylvain Cardin, Daniel Thalmann, and Frédéric Vexo.
A wearable system for mobility improvement of visually
impaired people. The Visual Computer, 23(2):109–118,
2007.
[25] Shonal Chaudhry and Rohitash Chandra. Design of a
mobile face recognition system for visually impaired
persons. arXiv preprint arXiv:1502.00756, 2015.
[26] Patrick Chiroro and Tim Valentine. An investigation
of the contact hypothesis of the own-race bias in face
recognition. The Quarterly Journal of Experimental
Psychology Section A, 48(4):879–894, 1995.
[27] Karen Church and Nuria Oliver. Understanding mobile
web and mobile search use in today’s dynamic mobile
In Proceedings of the 13th International
landscape.
Conference on Human Computer Interaction with Mo-
bile Devices and Services, pages 67–76. ACM, 2011.
[28] Bryan Dosono, Yasmeen Rashidi, Taslima Akter, Bryan
Semaan, and Apu Kapadia. Challenges in transitioning
from civil to military culture: Hyper-selective disclosure
through ICTs. Proceedings of the ACM on Human-
Computer Interaction, 1(CSCW):41, 2017.
[29] Paul Dourish. What we talk about when we talk about
context. Personal Ubiquitous Computing, 8(1):19–30,
2004.
[30] Anthony Giddens. Modernity and self-identity: Self
and society in the late modern age. Stanford University
Press, 1991.
[31] Erving Goffman. The presentation of self in everyday
life. New York: Anchor Books, 1959.
[32] Yash Goyal, Tejas Khot, Douglas Summers-Stay, Dhruv
Batra, and Devi Parikh. Making the V. in VQA matter:
Elevating the role of image understanding in visual ques-
tion answering. In The IEEE Conference on Computer
Vision and Pattern Recognition (CVPR), July 2017.
[33] Danna Gurari, Qing Li, Chi Lin, Yinan Zhao, Anhong
Guo, Abigale Stangl, and Jeffrey P. Bigham. Vizwiz-
priv: A dataset for recognizing the presence and purpose
of private visual information in images taken by blind
people. In CVPR, 2019.
[34] Danna Gurari, Qing Li, Abigale J. Stangl, Anhong
Guo, Chi Lin, Kristen Grauman, Jiebo Luo, and Jef-
frey P. Bigham. Vizwiz grand challenge: Answering
arXiv preprint
visual questions from blind people.
arXiv:1802.08218, 2018.
[35] Foad Hamidi, Morgan K. Scheuerman, and Stacy M.
Branham. Gender recognition or gender reductionism?:
1944    29th USENIX Security Symposium
USENIX Association
The social implications of embedded gender recognition
In Proceedings of the CHI Conference on
systems.
Human Factors in Computing Systems, pages 8:1–8:13,
2018.
[36] Charles Handy. Trust and the virtual organization. Long
Range Planning, 28(4):126–126, 1995.
[37] Rakibul Hasan, Yifang Li, Eman Hassan, Kelly Caine,
David J Crandall, Roberto Hoyle, and Apu Kapadia.
Can privacy be satisfying?: On improving viewer sat-
isfaction for privacy-enhanced photos using aesthetic
In Proceedings of the 2019 CHI Confer-
transforms.
ence on Human Factors in Computing Systems, pages
367:1–367:13. ACM, 2019.
[38] Jordan Hayes, Smirity Kaushik, Charlotte Emily Price,
and Yang Wang. Cooperative privacy and security:
Learning from people with visual impairments and their
allies. In 15th Symposium on Usable Privacy and Secu-
rity (SOUPS). USENIX, 2019.
[39] Niek Hoogervorst, Judith Metz, Lonneke Roza, and Eva
van Baren. How perceptions of altruism and sincer-
ity affect client trust in volunteers versus paid workers.
Nonproﬁt and Voluntary Sector Quarterly, 45(3):593–
611, 2016.
[40] Mariea Grubbs Hoy and George Milne. Gender dif-
ferences in privacy-related measures for young adult
Journal of Interactive Advertising,
facebook users.
10(2):28–45, 2010.
[41] Roberto Hoyle, Robert Templeman, Denise Anthony,
David Crandall, and Apu Kapadia. Sensitive lifelogs:
A privacy analysis of photos from wearable cameras.
In Proceedings of the 33rd Annual ACM Conference
on Human Factors in Computing Systems, pages 1645–
1648. ACM, 2015.
[42] Roberto Hoyle, Robert Templeman, Steven Armes,
Denise Anthony, David Crandall, and Apu Kapadia. Pri-
vacy behaviors of lifeloggers using wearable cameras.
In Proceedings of the 2014 ACM International Joint
Conference on Pervasive and Ubiquitous Computing,
pages 571–582. ACM, 2014.
[43] Rabia Jafri, Syed Abid Ali, and Hamid R. Arabnia. Face
recognition for the visually impaired. In Proceedings of
the International Conference on Information and Knowl-
edge Engineering (IKE). The Steering Committee of
The World Congress in Computer Science, Computer
Engineering and Applied Computing, 2013.
[44] Chandrika Jayant, Hanjie Ji, Samuel White, and Jef-
frey P. Bigham. Supporting blind photography. In Pro-
ceedings of the 13th International ACM SIGACCESS
Conference on Computers and Accessibility, pages 203–
210, 2011.
[45] Hernisa Kacorri, Kris M. Kitani, Jeffrey P. Bigham,
and Chieko Asakawa. People with visual impairment
training personal object recognizers: Feasibility and
challenges. In Proceedings of the 2017 CHI Conference
on Human Factors in Computing Systems, pages 5839–
5849. ACM, 2017.
[46] Shaun K. Kane, Chandrika Jayant, Jacob O. Wobbrock,
and Richard E Ladner. Freedom to roam: A study
of mobile device adoption and accessibility for people
In Proceedings of
with visual and motor disabilities.
the 11th International ACM SIGACCESS Conference
on Computers and Accessibility, pages 115–122. ACM,
2009.
[47] Ruogu Kang, Laura Dabbish, and Katherine Sutton.
Strangers on your phone: Why people use anonymous
communication applications. In Proceedings of the 19th
ACM Conference on Computer-Supported Cooperative
Work & Social Computing, CSCW ’16, pages 359–370,
New York, NY, USA, 2016. ACM.
[48] R.M. Khan and M.A. Khan. Academic sojourners, cul-
ture shock and intercultural adaptation: A trend analysis.
Studies About Languages, 10:38–46, 2007.
[49] Mohammed Korayem, Robert Templeman, Dennis