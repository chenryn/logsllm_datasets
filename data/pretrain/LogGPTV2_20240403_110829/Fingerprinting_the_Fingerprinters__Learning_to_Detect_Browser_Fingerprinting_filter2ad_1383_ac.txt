2
3
4
5
6
7
8
9
10
11
12
13
14
var _0x2c4a=['\x63\x58\x49\x69','\x42\x6a\x58\
x44\x6f\x41\x3d\x3d','\x55\x54\x72\x43\x69\x73
\x4f\x77\x4f\x38\x4f\x6c\x50\x45\x6e\x43\x6d\x
77\x30\x3d','\x49\x38\x4f\x38\x49\x4d\x4f\x42\
x77\x70\x72\x44\x6e\x41\x3d\x3d','\x77\x35\x54
\x43\x73\x42\x56\x51','\x77\x37\x62\x43\x69\x4
d\x4f\x38\x77\x...............................
....................................x3284af={};
for(i=0x0;i<_0x1b2b65[_0x5d52('0x7','\x28\x6d\
x68\x26')];i++){_0x1d1d56[_0x5d52('0x8','\x67\
x33\x48\x21')]=_0x1b2b65[i];_0x3284af[_0x1b2b6
5[i]]=_0x4d24cc[_0x5d52('0x9','\x35\x70\x64\x4
c')](_0x5d52('0xa','\x28\x6d\x68\x26'))['\x77\
x69\x64\x74\x68'];}
(cid:57)(cid:68)(cid:85)(cid:76)(cid:68)(cid:69)(cid:79)(cid:72)(cid:39)(cid:72)(cid:70)(cid:79)(cid:68)(cid:85)(cid:68)(cid:87)(cid:76)(cid:82)(cid:81)
(cid:57)(cid:68)(cid:85)(cid:76)(cid:68)(cid:69)(cid:79)(cid:72)(cid:39)(cid:72)(cid:70)(cid:79)(cid:68)(cid:85)(cid:68)(cid:87)(cid:76)(cid:82)(cid:81)
(cid:41)(cid:82)(cid:85)(cid:54)(cid:87)(cid:68)(cid:87)(cid:72)(cid:80)(cid:72)(cid:81)(cid:87)
(a) Obfuscated canvas font ﬁngerprinting script from Script 2.
(cid:44)(cid:71)(cid:72)(cid:81)(cid:87)(cid:76)(cid:73)(cid:76)(cid:72)(cid:85)
(cid:37)(cid:79)(cid:82)(cid:70)(cid:78)(cid:54)(cid:87)(cid:68)(cid:87)(cid:72)(cid:80)(cid:72)(cid:81)(cid:87)
(cid:51)(cid:85)(cid:82)(cid:74)(cid:85)(cid:68)(cid:80)
(cid:40)(cid:91)(cid:83)(cid:85)(cid:72)(cid:85)(cid:86)(cid:86)(cid:76)(cid:82)(cid:81)(cid:54)(cid:87)(cid:68)(cid:87)(cid:72)(cid:80)(cid:72)(cid:81)(cid:87)
(cid:40)(cid:91)(cid:83)(cid:85)(cid:72)(cid:86)(cid:86)(cid:76)(cid:82)(cid:81)(cid:54)(cid:87)(cid:68)(cid:87)(cid:72)(cid:80)(cid:72)(cid:81)(cid:87)
(cid:57)(cid:68)(cid:85)(cid:76)(cid:68)(cid:69)(cid:79)(cid:72)(cid:39)(cid:72)(cid:70)(cid:79)(cid:68)(cid:85)(cid:68)(cid:87)(cid:76)(cid:82)(cid:81)
(cid:40)(cid:91)(cid:83)(cid:85)(cid:72)(cid:86)(cid:86)(cid:76)(cid:82)(cid:81)(cid:54)(cid:87)(cid:68)(cid:87)(cid:72)(cid:80)(cid:72)(cid:81)(cid:87)
(cid:41)(cid:82)(cid:85)(cid:54)(cid:87)(cid:68)(cid:87)(cid:72)(cid:80)(cid:72)(cid:81)(cid:87)
(cid:36)(cid:85)(cid:85)(cid:68)(cid:92)(cid:40)(cid:91)(cid:83)(cid:85)(cid:72)(cid:86)(cid:86)(cid:76)(cid:82)(cid:81)
(cid:48)(cid:72)(cid:80)(cid:69)(cid:72)(cid:85)(cid:40)(cid:91)(cid:83)(cid:85)(cid:72)(cid:86)(cid:86)(cid:76)(cid:82)(cid:81)
(cid:44)(cid:71)(cid:72)(cid:81)(cid:87)(cid:76)(cid:73)(cid:76)(cid:72)(cid:85)
(cid:37)(cid:79)(cid:82)(cid:70)(cid:78)(cid:54)(cid:87)(cid:68)(cid:87)(cid:72)(cid:80)(cid:72)(cid:81)(cid:87)
(cid:80)(cid:82)(cid:81)(cid:82)(cid:86)(cid:83)(cid:68)(cid:70)(cid:72)
(cid:54)(cid:68)(cid:81)(cid:86)(cid:16)(cid:86)(cid:72)(cid:85)(cid:76)(cid:73)
(cid:70)(cid:68)(cid:81)(cid:89)(cid:68)(cid:86)
(cid:80)(cid:72)(cid:68)(cid:86)(cid:88)(cid:85)(cid:72)(cid:55)(cid:72)(cid:91)(cid:87)
(b) AST for unpacked script 2
Fig. 2: A truncated AST representation of Scripts 1 and 2. The
edges represent the syntactic relationship between nodes. Dotted lines
indicate an indirect connection through truncated nodes.
and toDataURL APIs. getSupportedExtensions is
used to get the list of supported WebGL extensions, which
vary depending on browser’s implementation. toDataURL
is used to get the base64 representation of the drawn canvas
image, which depending on underlying hardware and OS
conﬁgurations differs for the same canvas image. We then use
these top-1K features as input to train a supervised machine
learning model.
Dynamic analysis. Dynamic analysis complements some
weaknesses of static analysis. While static analysis allows
us to capture the syntactic structure of scripts, it fails when
the scripts are obfuscated or miniﬁed. This is crucial because
prior research has shown that ﬁngerprinting scripts often use
obfuscation to hide their functionality [87]. For example,
Figure 3 shows an AST constructed from an obfuscated
version of Script 2. The static features extracted from this
AST would miss important parent:child pairs that are
essential to capturing the script’s functionality. Furthermore,
some of the important parent:child pairs may be ﬁltered
during feature selection. Thus, in addition to extracting static
features from script contents, we extract dynamic features by
monitoring the execution of scripts. Execution traces capture
the semantic relationship within scripts and thus provide
additional context regarding a script’s functionality, even when
that script is obfuscated.
Dynamic feature extraction: We use two approaches to
extract features from execution traces. First, we keep presence
and count of the number of times a script accesses each
(cid:40)(cid:91)(cid:83)(cid:85)(cid:72)(cid:85)(cid:86)(cid:86)(cid:76)(cid:82)(cid:81)(cid:54)(cid:87)(cid:68)(cid:87)(cid:72)(cid:80)(cid:72)(cid:81)(cid:87)
(cid:40)(cid:91)(cid:83)(cid:85)(cid:72)(cid:86)(cid:86)(cid:76)(cid:82)(cid:81)(cid:54)(cid:87)(cid:68)(cid:87)(cid:72)(cid:80)(cid:72)(cid:81)(cid:87)
(cid:36)(cid:85)(cid:85)(cid:68)(cid:92)(cid:40)(cid:91)(cid:83)(cid:85)(cid:72)(cid:86)(cid:86)(cid:76)(cid:82)(cid:81)
(cid:48)(cid:72)(cid:80)(cid:69)(cid:72)(cid:85)(cid:40)(cid:91)(cid:83)(cid:85)(cid:72)(cid:86)(cid:86)(cid:76)(cid:82)(cid:81)
(cid:70)(cid:59)(cid:79)(cid:76)
(cid:37)(cid:77)(cid:59)(cid:39)(cid:82)(cid:36)(cid:32)(cid:32) (cid:58)(cid:24)(cid:55)(cid:38)(cid:86)(cid:37)(cid:57)(cid:52)
(cid:66)(cid:19)(cid:91)(cid:22)(cid:21)(cid:27)(cid:23)(cid:68)(cid:73) (cid:48)(cid:72)(cid:80)(cid:69)(cid:72)(cid:85)(cid:40)(cid:91)(cid:83)(cid:85)(cid:72)(cid:86)(cid:86)(cid:76)(cid:82)(cid:81)
(b) AST of the obfuscated script shown in (a).
Fig. 3: A truncated example showing the AST representation of an
obfuscated version of the canvas font ﬁngerprinting script in Script 2.
The edges represent the syntactic relationship between nodes. Dotted
lines indicate an indirect connection through truncated nodes.
individual API method or property and use that as a feature.
Next, we build features from APIs that are passed arguments
or return values. Rather than using the arguments or return
values directly, we use derived values to capture a higher-level
semantic that is likely to better generalize during classiﬁcation.
For example, we will compute the length of a string rather
than including the exact text, or will compute the area of
a element rather than including the height and width. This
allows us to avoid training our classiﬁer with overly speciﬁc
features—i.e., we do not care whether the text “CanvasFinger-
print” or “C4NV45F1NG3RPR1NT” is used during a canvas
ﬁngerprinting attempt, and instead only care about the text
length and complexity. For concrete example, we calculate
the area of canvas element, its text size, and whether its is
present on screen when processing execution logs related to
CanvasRenderingContext2D.fillText().
extracted
example,
the
As
trace
the
(HTMLCanvasElement.getContext, True)
(CanvasRenderingContext2D.measureText,
7)
the
age
us-
HTMLCanvasElement.getContext
features, where
of
indicates
True
from
includes
and
an
execution
features
Script
of
3a
as
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:15:55 UTC from IEEE Xplore.  Restrictions apply. 
1148
7
the
size
indicates
in
and
text
A
CanvasRenderingContext2D.measureText.
features extracted from the
more comprehensive list of
execution trace of Script 3a can be found in Appendix IX-B
(Table VIII).
of
To avoid over-ﬁtting, we again apply unsupervised and
the number
supervised feature selection methods to limit
of features. Similar to feature reduction for static analysis,
this allows us to keep the features that represent the most
commonly used APIs for ﬁngerprinting. For example, two of
the features with the highest information gain represent the
usage of CanvasRenderingContext2D.fillStyle
APIs.
and
CanvasRenderingContext2D.fillStyle is
used
to specify the color, gradient, or pattern inside a canvas
shape, which can make a shape render differently across
browsers and devices. navigator.platform reveals the
platform (e.g. MacIntel and Win32) on which the browser is
running. We then use these top-1K features as input to train
a supervised machine learning model.
navigator.platform
Classifying ﬁngerprinting scripts. FP-INSPECTOR uses a
decision tree [81] classiﬁer for training a machine learning
model. The decision tree is passed feature vectors of scripts
for classiﬁcation. While constructing the tree, at each node, the
decision tree chooses the feature that most effectively splits the
data. Speciﬁcally, the attribute with highest information gain
is chosen to split the data by enriching one class. The decision
tree then follows the same methodology to recursively partition
the subsets unless the subset belongs to one class or it can no
longer be partitioned.
Note that we train two separate models and take the union
of their classiﬁcation results instead of combining features
from both the static and dynamic representations of scripts
to train a single model. That is, a script is considered to
be a ﬁngerprinting script if it is classiﬁed as ﬁngerprinting
by either the model that uses static features as input or the
model that uses dynamic features as input. We use union of
the two models because we only have the decision from one
of the two models for some scripts (e.g., scripts that do not
execute). Furthermore, the two models are already trained on
high-precision ground truth [54] and taking the union would
allow us to push for better recall. Using this approach, we
classify all scripts loaded during a page visit—i.e., we include
both external scripts loaded from separate URLs and inline
scripts contained in any HTML document.
B. Mitigating ﬁngerprinting scripts
Existing browser ﬁngerprinting countermeasures can be
classiﬁed into two categories: content blocking and API re-
striction. Content blocking, as the name implies, blocks the
requests to download ﬁngerprinting scripts based on their
network location (e.g., domain or URL). API restriction, on the
other hand, does not block ﬁngerprinting scripts from loading
but rather limits access to certain JavaScript APIs that are
known to be used for browser ﬁngerprinting.
Privacy-focused browsers such as the Tor Browser [15]
prefer blanket API restriction over content blocking mainly
because it side steps the challenging problem of detecting
ﬁngerprinting scripts. While API restriction provides reli-
able protection against active ﬁngerprinting, it can break the
functionality of websites that use the restricted APIs for
benign purposes. Browsers that deploy API restriction also
require additional protections against passive ﬁngerprinting
(e.g., routing trafﬁc over the Tor network). Content blocking
protects against both active and passive ﬁngerprinting, but it
is also prone to breakage when the detected script is dual-
purpose (i.e., implements both ﬁngerprinting and legitimate
functionality) or a false positive.
Website breakage is an important consideration for ﬁnger-
printing countermeasures. For instance, a recent user trial by
Mozilla showed that privacy countermeasures in Firefox can
negatively impact user engagement due to website breakage
[21]. In fact, website breakage can be the deciding factor
in real-world deployment of any privacy-enhancing counter-
measure [8], [26]. We are interested in studying the impact
of different ﬁngerprinting countermeasures based on FP-
INSPECTOR on website breakage. We implement the following
countermeasures:
1) Blanket API Restriction. We restrict access for all scripts
to the JavaScript APIs known to be used by ﬁngerprinting
scripts, hereafter referred to as “ﬁngerprinting APIs”. Finger-
printing APIs include functions and properties that are used
in ﬁngerprintjs2 and those discovered by FP-INSPECTOR in
Section VI. Note that this countermeasure does not at all rely
on FP-INSPECTOR’s detection of ﬁngerprinting scripts.
2) Targeted API Restriction. We restrict access to ﬁnger-
printing APIs only for the scripts served from domains that are
detected by FP-INSPECTOR to deploy ﬁngerprinting scripts.
3) Request Blocking. We block the requests to download
the scripts served from domains that are detected by FP-
INSPECTOR to deploy ﬁngerprinting scripts.
4) Hybrid. We block the requests to download the scripts
served from domains that are detected by FP-INSPECTOR to
deploy ﬁngerprinting scripts, except for ﬁrst-party and inline
scripts. Additionally, we restrict access to ﬁngerprinting APIs
for ﬁrst-party and inline scripts on detected domains. This
protects against active ﬁngerprinting by ﬁrst parties and both
active and passive ﬁngerprinting by third parties.
IV. EVALUATION
We evaluate FP-INSPECTOR’s performance in terms of its
accuracy in detecting ﬁngerprinting scripts and its impact on
website breakage when mitigating ﬁngerprinting.
A. Accuracy
We require samples of ﬁngerprinting and non-ﬁngerprinting
scripts to train our supervised machine learning models. Up-
to-date ground truth for ﬁngerprinting is not readily avail-
able. Academic researchers have released lists of scripts [47],
[54], however these only show a snapshot at the time of
the paper’s publication and are not kept up-to-date. While
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:15:55 UTC from IEEE Xplore.  Restrictions apply. 
1149
many anti-tracking lists (e.g., EasyPrivacy) do include some
ﬁngerprinting domains, Disconnect’s tracking protection list
[12] is the only publicly available list that does not lump
together different types of tracking and separately identiﬁes
ﬁngerprinting domains. However, Disconnect’s list is insufﬁ-
cient for our purposes. First, Disconnect’s list only includes
the domain names of companies that deploy ﬁngerprinting
scripts, rather than the actual URLs of the ﬁngerprinting
scripts. This prevents us from using the list to differentiate
between ﬁngerprinting and non-ﬁngerprinting resources served
from those domains. Second, the list appears to be focused
on ﬁngerprinting deployed by popular third-party vendors.
Since ﬁrst-party ﬁngerprinting is also prevalent [47], we would
like to train our classiﬁer to detect both ﬁrst- and third-party
ﬁngerprinting scripts. Given the limitations of these options,
we choose to detect ﬁngerprinting scripts using a slightly
modiﬁed version of the heuristics implemented in [54].
1) Fingerprinting Deﬁnition: The research community is
not aligned on a single deﬁnition to label ﬁngerprinting
scripts. It is often difﬁcult to determine the intent behind any
individual API access, and classifying all instances of device
information collection as ﬁngerprinting will result in a large
number of false positives. For example, an advertisement script
may collect a device’s screen size to determine whether an
ad was viewable and may never use that information as part
of a ﬁngerprint to identify the device. With that in mind,
we take a conservative approach: we consider a script as
ﬁngerprinting if it uses Canvas, WebRTC, Canvas Font,
or AudioContext as deﬁned in [54]. Speciﬁcally, if the
heuristics trigger for any of the above mentioned behaviors, we
label the script as ﬁngerprinting and otherwise label it as non-
ﬁngerprinting. We do not consider the collection of attributes
from navigator or screen APIs from a script as ﬁngerprinting,
as these APIs are frequently used in non-distinct ways by
scripts that do not ﬁngerprint users. We decide to initially use
this deﬁnition of ﬁngerprinting because it is precise, i.e., it has
a low false positive rate. A low false positive rate is crucial
for a reliable ground truth as the classiﬁers effectiveness will
depend on the soundness of ground truth. The exact details of
heuristics are listed in Appendix IX-C.
2) Data Collection: We use our extended version of Open-
WPM to crawl the homepages of twenty thousand websites
sampled from the Alexa top-100K websites. To build this
sample, we take the top-10K sites from the list and augment
it with a random sample of 10K sites with Alexa ranks from
10K to 100K. This allows us to cover both the most popular
websites as well as websites further down the long tail. During
the crawl we allow each site 120 seconds to fully load before
timing out the page visit. We store the HTTP response body
content from all documents and scripts loaded on the page as
well as the execution traces of all scripts.
Our crawled dataset consists of 17,629 websites with
153,354 distinct executing scripts. Since we generate our
ground truth by analyzing script execution traces, we are
only able to collect ground truth from scripts that actually
execute during our crawl. Although we are not able train our
classiﬁer on scripts that do not execute during our crawl, we
are still able to classify them. Their classiﬁcation result will
depend entirely on the static features extracted from the script
contents. For static features, we successfully create ASTs for
143,526 scripts—9,828 scripts (6.4%) fail because of invalid
syntax. Out of valid scripts, we extract a total of 47,717
parent:child combinations and do feature selection as de-
scribed in Section III. Speciﬁcally, we ﬁrst ﬁlter by a variance
threshold of 0.01 to reduce the set to 8,597 parent:child
combinations. We then select top 1K features when sorted by
information gain. For dynamic features, we extract a total of
2,628 features from 153,354 scripts. Similar to static analysis,
we do feature selection as described in Section III and reduce
the feature set to top 1K when sorted by information gain.
3) Enhancing Ground Truth: As discussed in Section II,
heuristics suffer from two inherent problems. First, heuristics
are narrowly deﬁned which can cause them to miss some
ﬁngerprinting scripts. Second, heuristics are predeﬁned and are
thus unable to keep up with evolving ﬁngerprinting scripts.
Due to these problems, we know that our heuristics-based
ground truth is imperfect and a machine learning model trained
on such a ground truth may perform poorly. We address these
problems by enhancing the ground truth through iterative re-
training. We ﬁrst train a base model with incomplete ground
truth, and then manually analyze the disagreements between
the classiﬁer’s output and the ground truth. We update the
ground truth whenever we ﬁnd that our classiﬁer makes a
correct decision that was not reﬂected in the ground truth (i.e.,
discovers a ﬁngerprinting script that was missed by the ground
truth heuristics). We perform three iterations of this process.
Manual labeling. The manual process of analyzing scripts
during iterative re-training works as follows. We automatically
create a report for every script that requires manual analysis.
Each report contains: (1) all of the API method calls and
property accesses monitored by our instrumentation, including
the arguments and return values, (2) snippets from the script
that capture the surrounding context of calls to the APIs
used for canvas, WebRTC, canvas font, and AudioContext
ﬁngerprinting, (3) a ﬁngerprintjs2 similarity score,3 and (4) the
formatted contents of the complete script. We then manually
review the reports based on our domain expertise to determine
whether the analyzed script is ﬁngerprinting. Speciﬁcally, we
look for heuristic-like behaviors in the scripts. The heuristic-
like behavior means that the ﬁngerprinting code in the script:
1) Is similar to known ﬁngerprinting code in terms of its