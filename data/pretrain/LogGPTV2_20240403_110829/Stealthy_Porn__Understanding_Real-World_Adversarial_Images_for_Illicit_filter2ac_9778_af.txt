it, as we expected, would be much harder than
evading normal networks.
Ethical issue. Before we started this research, we consulted
with IRB and conﬁrmed that this research would not require
the approval of IRB because all of the images that we reviewed
were pre-existing (collected from the Internet). Therefore
only a secondary analysis of already published materials was
involved, and thus did not constitute human subjects research.
In addition, in this paper, we attach a few APPIs to help the
readers better understand our paper and the problem we study.
We have applied masks to cover most exposed skin areas and
actors’ eyes in all the attached explicit images. We are not
intended to distribute any explicit content and leak actors’
privacy.
VIII. Related Work
Explicit content detection. Numerous studies have looked
into the detection of nudity or pornography in color images
or videos. The two traditional elements for explicit content
detection are skin detection and text detection. Platzer et al.
[52] proposed an explicit image detection algorithm which
accurately detects skin and skin position using a collection
of shapes. geometric rules. Chan et al. [30] proposed a
pornographic website based on skin-derived features and text
analysis. Lopes et al. [45] investigated a nudity detection in
videos based on a bag-of-visual-features representation for
frames. Recent years, deep learning techniques have been
used in explicit content detection. Wehrmann et al. [58]
comprised both convolutional neural networks and LSTM
recurrent network for adult content detection in videos. Perez
et al. [51] classiﬁed pornographic videos using convolutional
neural networks along with static and motion information.
In contrast to previous works, which all detect plain explicit
contents, we proposed a unique technique to detect adversarial
explicit contents with multiple evasive techniques (such as
blur, occlusion) applied.
(cid:26)(cid:23)(cid:21)
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:51:56 UTC from IEEE Xplore.  Restrictions apply. 
Adversarial image detection. Recent years have seen rapid
growth in the area of adversarial example detection. Previ-
ous works on adversarial example detection mainly fall into
three categories [28]: the ﬁrst category of detection scheme
is secondary classiﬁcation based detection, which builds a
second classiﬁer to detect adversarial example. Grosse et
al. [38] propose a variant on adversarial re-training, which
introduces a new class solely for adversarial examples. Gong
et al. [36] construct a binary classiﬁer to learn to partition
the natural images from adversarial examples. The second
category of detection scheme is principal component analysis
(PCA) detection, which transforms points from high dimen-
sional space to low dimensional space. Hendrycks et al. [41]
observe adversarial examples placing a higher weight on the
larger principal components than natural images. Li et al. [43]
apply PCA to the values after inner convolutional layers of
the neural network, and use a cascade classiﬁer to detect
adversarial examples. Another category of detection schemes
detect adversarial examples by comparing the distribution of
natural image to the distribution of adversarial example. As an
example of this category, Feinman et al. [33] investigate model
conﬁdence on adversarial samples by looking at Bayesian un-
certainty estimates and other features. Diﬀerent from previous
works, our paper proposed a technique to detect the real-world
adversarial explicit content generated by the attackers and used
for cybercrime.
Image processing for security. Recent years, image pro-
cessing technique has been actively used for security and
privacy research. Borgolte et al. introduced Meerkat [27], a
computer vision approach to website defacement detection.
The technique is capable of identifying malicious content
changes from screenshots of the website. Medvet et al. [47]
propose a system to detect a potential phishing page leveraging
features such as parts of the visible text, the images embedded
in the website, and the overall appearance of the website as
rendered by the browser for detection. Anderson et al. [26]
introduce image shingling, a technique similar to w-shingling,
to cluster screenshots of scams into campaigns. Nappa et al.
[48] leverage perceptual hashing to group visually similar
icons of malicious executables under the assumption that a
similar icon suggests that the two executables are part of the
same malware distribution campaign. Templeman et al. [56]
introduced a technique for owners of ﬁrst-person cameras to
‘blacklist’ sensitive spaces (like bathrooms and bedrooms),
which performs novel image analysis to classify where a photo
was taken. Zannettou et al. [61] develop a processing pipeline
based on image processing technique to detect and to track
memes across multiple Web communities To the best of our
knowledge, no prior work applies image-based methods to
detect promotional adversarial explicit contents.
IX. Conclusion
In this paper, we report our study on adversarial promotional
porn images, which promote the illicit business (e.g., porn
app or gambling site) using adversarial porn image aiming
at evading explicit content detectors. To capture such stealthy
image, our advanced explicit content detector, Mal´ena, utilizes
a set of DNN based techniques to automatically identify
the promotional information and capture the relatively less
obfuscated region in the image. Our study shows that Mal´ena
achieves a low false detection rate (about 9%) with 85%
coverage. Running on 4,042,698 images from 725,384 hottest
posts/microblog across two social media platforms Baidu
Tieba and Sina Weibo, Mal´ena automatically detects 4,353
APPIs, which brings to light the real-world image obfuscation
techniques used by the cybercriminals to evade state-of-art
explicit content detector (e.g., Google Cloud Vision API and
Yahoo Open NSFW model). Such obfuscation techniques
include adding high-frequency signals (e.g.,
texturing and
noising) or ﬁlter eﬀects (e.g., blurring) to an image. Our
research further demonstrates the eﬀectiveness of such ob-
fuscation techniques and the bar our technique raises for the
attacks. Moving forward, our study reveals the ecosystem of
such illicit promotion from the distribution channel, APPI
campaigns to the promoted illicit businesses. It helps to get a
more comprehensive view of the illicit promotion and develop
eﬀective solutions to mitigate such security risks.
X. Acknowledgements
We are grateful to our shepherd Gianluca Stringhini and
the anonymous reviewers for their insightful comments. We
thank Xiaoran Peng, David Crandall and Dmitry Evtyushkin
for their valuable feedback. This work is supported in part
by NSF CNS-1527141, 1618493, 1801432, 1838083, 1801365
and ARO W911NF1610127.
References
[1] “Baidu tieba,” https://tieba.baidu.com/.
[2] “Baidu tieba policy,” http://static.tieba.baidu.com/tb/eula.html.
[3] “Boofcv,” https://boofcv.org/index.php?title=Main Page.
[4] “China
cybersecurity
http://www.cac.gov.cn/2016-11/07/c
law,”
1119867116.htm/.
downloads.
[5] “Clarifai,” https://clarifai.com/.
[6] “Downloads - incidental scene text,” http://rrc.cvc.uab.es/?ch=4&com=
[7] “Google cloud vision api,” https://cloud.google.com/vision/.
[8] “Safesearch - wikipedia,” https://en.wikipedia.org/wiki/SafeSearch.
[9] “Sina weibo,” https://www.weibo.com/.
[10] “Sina weibo service usage agreement,” https://www.weibo.com/signup/
[11] “Twitter media policy,” https://help.twitter.com/en/rules-and-policies/
v5/protocol.
media-policy/.
2008.
[12] “phash: The open source perceptual hash library,” http://www.phash.org,
[13] “Zbar bar code reader,” http://zbar.sourceforge.net, 2011.
[14] “Zxing (”zebra crossing”) barcode scanning library for java, android,”
https://github.com/zxing/zxing/, 2011.
[15] “Libmagic,” https://github.com/threatstack/libmagic, 2014.
[16] “Ms-celeb-1m: Challenge of
recognizing one million celebrities
in the real world,” https://www.microsoft.com/en-us/research/project/
ms-celeb-1m-challenge-recognizing-one-million-celebrities-real-world/,
2016.
[17] “Tensorﬂow implementation of yahoo’s open nsfw model,” https://
github.com/mdietrichstein/tensorﬂow-open nsfw, 2017.
[18] “Baidu aipimagecensor github,” https://github.com/Baidu-AIP/php-sdk/
blob/master/AipImageCensor.php, 2018.
[19] “维基百科,” https://zh.wikipedia.org, 2018.
[20] “Coco - common objects in context,” http://cocodataset.org/, 2018.
(cid:26)(cid:23)(cid:22)
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:51:56 UTC from IEEE Xplore.  Restrictions apply. 
[49] N. Papernot, P. McDaniel, S. Jha, M. Fredrikson, Z. B. Celik, and
A. Swami, “The limitations of deep learning in adversarial settings,”
in Security and Privacy (EuroS&P), 2016 IEEE European Symposium
on.
IEEE, 2016, pp. 372–387.
[50] N. Papernot, P. McDaniel, X. Wu, S. Jha, and A. Swami, “Distillation
as a defense to adversarial perturbations against deep neural networks,”
in Security and Privacy (SP), 2016 IEEE Symposium on.
IEEE, 2016,
pp. 582–597.
[51] M. Perez, S. Avila, D. Moreira, D. Moraes, V. Testoni, E. Valle,
S. Goldenstein, and A. Rocha, “Video pornography detection through
deep learning techniques and motion information,” Neurocomputing, vol.
230, pp. 279–293, 2017.
[52] C. Platzer, M. Stuetz, and M. Lindorfer, “Skin sheriﬀ: a machine
learning solution for detecting explicit images,” in Proceedings of the
2nd international workshop on Security and forensics in communication
systems. ACM, 2014, pp. 45–56.
[53] S. Ren, K. He, R. Girshick, and J. Sun, “Faster r-cnn: Towards real-time
object detection with region proposal networks,” in Advances in neural
information processing systems, 2015, pp. 91–99.
[54] P. Samangouei, M. Kabkab, and R. Chellappa, “Defense-gan: Protecting
classiﬁers against adversarial attacks using generative models,” arXiv
preprint arXiv:1805.06605, 2018.
[55] C. Szegedy, W. Zaremba, I. Sutskever, J. Bruna, D. Erhan, I. Goodfellow,
and R. Fergus, “Intriguing properties of neural networks,” arXiv preprint
arXiv:1312.6199, 2013.
[56] R. Templeman, M. Korayem, D. J. Crandall, and A. Kapadia, “Placeav-
oider: Steering ﬁrst-person cameras away from sensitive spaces.” 2014.
[57] J. R. Uijlings, K. E. Van De Sande, T. Gevers, and A. W. Smeulders,
“Selective search for object recognition,” International journal of com-
puter vision, vol. 104, no. 2, pp. 154–171, 2013.
[58] J. Wehrmann, G. S. Sim˜oes, R. C. Barros, and V. F. Cavalcante, “Adult
content detection in videos with convolutional and recurrent neural
networks,” Neurocomputing, vol. 272, pp. 432–438, 2018.
[59] G. L. Wittel and S. F. Wu, “On attacking statistical spam ﬁlters.” in
CEAS, 2004.
[60] H. Xiao, B. Biggio, G. Brown, G. Fumera, C. Eckert, and F. Roli, “Is fea-
ture selection secure against training data poisoning?” in International
Conference on Machine Learning, 2015, pp. 1689–1698.
[61] S. Zannettou, T. Caulﬁeld, J. Blackburn, E. D. Cristofaro, M. Sirivianos,
G. Stringhini, and G. Suarez-Tangil, “On the origins of memes by
means of fringe web communities,” CoRR, vol. abs/1805.12512, 2018.
[Online]. Available: http://arxiv.org/abs/1805.12512
[21] “Implementation of our paper ’pixellink: Detecting scene text via
instance segmentation’ in aaai2018,” https://github.com/ZJULearning/
pixel
link, 2018.
[22] “Opencv: Opencv modules,” https://docs.opencv.org/3.4/index.html,
2018.
[23] “Pillow,” https://pillow.readthedocs.io/en/latest/, 2018.
[24] “Scikit-image,” https://scikit-image.org, 2018.
[25] W. Abdulla, “Mask r-cnn for object detection and instance segmentation
on keras and tensorﬂow,” https://github.com/matterport/Mask RCNN,
2017.
[26] D. S. Anderson, C. Fleizach, S. Savage, and G. M. Voelker, “Spamscat-
ter: Characterizing internet scam hosting infrastructure,” Ph.D. disserta-
tion, University of California, San Diego, 2007.
[27] K. Borgolte, C. Kruegel, and G. Vigna, “Meerkat: Detecting website
defacements through image-based object recognition.”
[28] N. Carlini and D. Wagner, “Adversarial examples are not easily detected:
Bypassing ten detection methods,” in Proceedings of the 10th ACM
Workshop on Artiﬁcial Intelligence and Security.
ACM, 2017, pp.
3–14.
[29] ——, “Towards evaluating the robustness of neural networks,” in Se-
IEEE, 2017, pp.
curity and Privacy (SP), 2017 IEEE Symposium on.
39–57.
[30] Y. Chan, R. Harvey, and D. Smith, “Building systems to block pornog-
raphy.”
[31] D. Deng, H. Liu, X. Li, and D. Cai, “Pixellink: Detecting scene text via
instance segmentation,” arXiv preprint arXiv:1801.01315, 2018.
[32] R. Di Pietro and L. V. Mancini, Intrusion detection systems. Springer
Science & Business Media, 2008, vol. 38.
[33] R. Feinman, R. R. Curtin, S. Shintre, and A. B. Gardner, “Detecting
adversarial samples from artifacts,” arXiv preprint arXiv:1703.00410,
2017.
[34] R. Girshick, “Fast r-cnn,” in Proceedings of the IEEE international
conference on computer vision, 2015, pp. 1440–1448.
[35] R. Girshick, J. Donahue, T. Darrell, and J. Malik, “Rich feature
hierarchies for accurate object detection and semantic segmentation,”
in Proceedings of the IEEE conference on computer vision and pattern
recognition, 2014, pp. 580–587.
[36] Z. Gong, W. Wang, and W.-S. Ku, “Adversarial and clean data are not
twins,” arXiv preprint arXiv:1704.04960, 2017.
[37] I. J. Goodfellow, J. Shlens, and C. Szegedy, “Explaining and harnessing
adversarial examples,” stat, vol. 1050, p. 20, 2015.
[38] K. Grosse, P. Manoharan, N. Papernot, M. Backes, and P. McDaniel,
“On the (statistical) detection of adversarial examples,” arXiv preprint
arXiv:1702.06280, 2017.
[39] K. He, G. Gkioxari, P. Doll´ar, and R. Girshick, “Mask r-cnn,” in
Computer Vision (ICCV), 2017 IEEE International Conference on.
IEEE, 2017, pp. 2980–2988.
[40] K. He, X. Zhang, S. Ren, and J. Sun, “Deep residual learning for image
recognition,” in Proceedings of the IEEE conference on computer vision
and pattern recognition, 2016, pp. 770–778.
[41] D. Hendrycks and K. Gimpel, “Early methods for detecting adversarial
images,” arXiv preprint arXiv:1608.00530, 2016.
[42] A. Krizhevsky, I. Sutskever, and G. E. Hinton, “Imagenet classiﬁcation
with deep convolutional neural networks,” in Advances in neural infor-
mation processing systems, 2012, pp. 1097–1105.
[43] X. Li and F. Li, “Adversarial examples detection in deep networks with
convolutional ﬁlter statistics.” in ICCV, 2017, pp. 5775–5783.
[44] J. Long, E. Shelhamer, and T. Darrell, “Fully convolutional networks
for semantic segmentation,” in Proceedings of the IEEE conference on
computer vision and pattern recognition, 2015, pp. 3431–3440.
[45] A. P. B. Lopes, S. E. de Avila, A. N. Peixoto, R. S. Oliveira, M. d. M.
Coelho, and A. d. A. Ara´ujo, “Nude detection in video using bag-
of-visual-features,” in Computer Graphics and Image Processing (SIB-
GRAPI), 2009 XXII Brazilian Symposium on.
IEEE, 2009, pp. 224–231.
[46] D. G. Lowe, “Distinctive image features from scale-invariant keypoints,”
International journal of computer vision, vol. 60, no. 2, pp. 91–110,
2004.
[47] E. Medvet, E. Kirda, and C. Kruegel, “Visual-similarity-based phish-
ing detection,” in Proceedings of the 4th international conference on
Security and privacy in communication netowrks. ACM, 2008, p. 22.
[48] A. Nappa, M. Z. Raﬁque, and J. Caballero, “Driving in the cloud:
An analysis of drive-by download operations and abuse reporting,” in
International Conference on Detection of Intrusions and Malware, and
Vulnerability Assessment. Springer, 2013, pp. 1–20.
(cid:26)(cid:23)(cid:23)
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:51:56 UTC from IEEE Xplore.  Restrictions apply.