of virtual machine layering and closures provides strong se-
curity boundaries for Chrome Zero. Finally, we discuss in
Section V-C how to maintain practical usability of Chrome
Zero (Challenge C3), despite the restrictions it introduces.
A. Virtual machine layering
To ensure that our own function is called instead of the
original function, without modifying the browser, we facilitate
a technique known as virtual machine layering [19]. Although
this technique was originally developed for low-overhead run-
time monitoring, we show that in combination with JavaScript
closures,
it can also be applied as a security mechanism.
For security, virtual machine layering has a huge advantage
1Chrome Zero: https://github.com/IAIK/ChromeZero
6
ScriptWrapperExtensionContextPageContextCallReturnCallAllowed?OriginalFunctionYesNoDefaultvalueFilteredvalueFig. 3: Dangerous objects are wrapped in proxy objects. The
proxy object decides whether methods of the original object
are called or substituted by a different functions.
1 (function() {
2 // original is only accessible in this scope
3 var original = window.performance.now;
4 window.performance.now = function() {
5
6
7 }; })();
/ 1000.0) * 1000.0;
return Math.floor((original.call(window.performance))
Listing 3: Virtual machine layering applied to the function
performance.now within a closure. The function name
points to the new function, the original function can only be
called using the reference. However, the reference is not visible
outside the scope, i.e., only the wrapper function can access
the reference to the original function.
type of property, we can convert every property to an accessor
property using Object.defineProperty.
2) Objects: To be able to apply policies to objects, we wrap
the original object within a proxy object as shown in Figure 3.
The proxy object contains the original object and forwards all
functions (which are not overwritten) to the original object.
Thus, all states are still handled by the original object, and
only functions for which a policy is deﬁned have to be re-
implemented in the proxy object.
Although JavaScript prototypes have a constructor, simply
applying virtual machine layering to the constructor function
is not sufﬁcient. The constructor function is only a pointer
to the real constructor and not used to actually instantiate
the object. The alternative to the proxy object for replacing
the constructor is to re-implement the entire object with all
methods and properties. However, as this requires considerable
engineering effort and cannot easily be automated, it is not
feasible, and we thus rely on the proxy object.
B. Self-protection
An important part of the implementation is that it is not
possible for an attacker to circumvent the applied policies
(Challenge C2). Thus, an implementation has to ensure that
an attacker cannot get hold of any reference to the original
functions. We utilize JavaScript closures for security, by cre-
ating anonymous scopes not connected to any object and thus
inaccessible to code outside of the closure. Listing 3 shows
virtual machine layering wrapped in a closure.
With the original version of virtual machine layering as
shown in Listing 2, an attacker could simply guess the name
of the variable holding the original reference. Furthermore,
all global variables are members of the JavaScript root object
window, and an attacker could use reﬂection to iterate over all
variables until the function reference is discovered. Closures
provide a way to store data in a scope not connected to
the window object. Thus, by applying the virtual machine
layering process within a closure, the reference to the original
function is still available to the wrapper function but inacces-
sible to any code outside of the closure. This guarantees that
the virtual machine layering is irreversible.
At the time of writing, there is no mechanism to modify a
function without redeﬁning it. Thus, an attacker cannot inject
new code into the wrapper function (or modify the existing
code) without destroying the closure and therefore losing the
reference to the original function.
have
the
using
objects
Object.freeze after
layering
process. This ensures that deleting the function does not
revert to the original function pointer, as it is otherwise the
case in Google Chrome.
to
virtual machine
Additionally,
be
protected
i.e.,
If a policy requires user interaction,
the user has
to decide whether a function shall be executed or not, this
logic must also be protected against an attacker. By relying
on a browser extension, we already have the advantage of
a different execution context and thus a different security
context. A website cannot access data inside an extension or
inﬂuence code running inside an extension. This also protects
the policies, which are stored within the extension. Therefore,
there is no possibility for a malicious website to modify or
inject new policies.
C. User Interface
Challenge C3 is to have no signiﬁcant impact on compati-
bility and user experience. This implies that Chrome Zero must
not have a perceivable performance impact (cf. Section VI).
As diverting the control ﬂow into the extension (cf. Fig-
ure 2) is relatively costly, we only do that
if absolutely
necessary. Figure 4 shows how Chrome Zero only diverts the
control ﬂow to the extension if a policy requires that the user is
asked for permission. In all other cases, we can directly replace
the function with a stub or wrapper function (Figure 4b and
Figure 4c) before loading a page.
As JavaScript does not provide a mechanism to block
scripts, except for the built-in pop-up boxes (e.g., alert),
pausing a function to ask the user for permission requires
interaction with the browser extension. Chrome Zero relies
on the Google Chrome Debugger API [12] which extends the
functionality of JavaScript to inﬂuence and inspect the internal
state of the JavaScript engine. Using Chrome’s remote debug-
ging protocol [11], Chrome Zero registers a function which
is called whenever a script uses the debugger keyword.
The effect of the debugger keyword is that the JavaScript
engine pauses all currently executing scripts before calling the
registered function [27].
While the script—and thus the entire page—is paused,
Chrome Zero asks the user for permission to execute the
current function. The result is then returned to the calling
function by writing it to a local variable within the closure, and
function execution is resumed using the Debugger API. Note
that only Chrome Zero can access the local variable that stores
the result, as all variables within the closure are inaccessible to
the remaining page (cf. Section V-B). The function then either
resumes execution of the function, or returns a default value in
7
ScriptMethodsObjectMethodsFilternewObjectProxy(Object)(a) Normal function
(b) Blocked function
(c) Modiﬁed function
(d) Function with user permission
Fig. 4: (a) A normal, unmodiﬁed function call as reference. (b) If a function is blocked, it can be immediately replaced with a
function returning the default value. (c) If the return value has to be modiﬁed, the function can be replaced by an anonymous
JavaScript closure which applies the modiﬁcation directly on the page. (d) Only if the user has to be asked for permission, a
switch into the extension context is necessary.
case the user does not give permission to execute the function.
Spurious usage of the debugger keyword on a (malicious)
website has no effect, as Chrome Zero just continues if no
policy is found for the current function.
Chrome Zero does not instrument the existing browser per-
mission system, as it cannot be retroﬁtted to protect arbitrary
functions and objects. The existing browser permission system
only works for APIs designed to be used with the permission
system, i.e., the API has to be asynchronous by relying on
callback functions or promises. The browser asks the user
for permission, and if the user accepts, the browser calls a
callback function with the result, e.g., the current geolocation.
Hence, synchronous APIs, e.g., the result of the function call
is provided as a return value, cannot be protected with the
browser’s asynchronous permission system. For the protection
to be complete, we have to handle both synchronous as well
as asynchronous function calls, and can therefore not rely on
the browser’s internal permission system.
VI. SECURITY EVALUATION
In this section, we evaluate JavaScript Zero by means
of our proof-of-concept Chrome extension, Chrome Zero. In
the ﬁrst part of the evaluation, we show how Chrome Zero
prevents all microarchitectural and side-channel attacks that
can be mounted from JavaScript (cf. Table I). Furthermore,
we show how policies can prevent exploits. We evaluate how
many exploits are automatically prevented by protecting users
against microarchitectural and side-channel attacks.
A. Microarchitectural and Side-Channel Attacks
To successfully prevent microarchitectural and side-channel
attacks, we have to eliminate the requirements identiﬁed in
Section II-B. Depending on the requirements we eliminate,
microarchitectural and side-channel attacks are not possible
anymore (cf. Table I). Consequently, we discuss policies to
eliminate each requirement. Table II shows a summary of all
policies and how they affect state-of-the-art attacks. Table III
shows which policy is active on which protection level.
1) Memory Addresses: In all known attacks, array buffers
are used to retrieve information on the underlying memory
address. An attacker can exploit that array buffers are page-
aligned to learn the least signiﬁcant 12 bits of both the virtual
and physical address [33]. Thus, we have to ensure that array
buffers are not page-aligned and that an attacker does not know
the offset of the array buffer within the page.
Array buffers are raw binary data buffers, storing values
of arrays. However, their content cannot be accessed directly,
but only using typed arrays or DataViews. Thus, we have to
proxy both the DataView object as well as all typed arrays
(e.g., Uint8Array, Uint16Array, etc.).
a) Buffer ASLR: To prevent the arrays from being page-
aligned, we introduce buffer ASLR, which randomizes the start
of the array buffer. We overwrite the length argument of the
constructor to allocate additional 4 KB. This allows us to move
the start of the array anywhere on the page by generating a
random offset in the range [0; 4096). This offset is then added
to the array index for every access. Hence, all data is shifted,
i.e., the value at index 0 is not page-aligned but starts at a
random position within the page. Thus, an attacker cannot rely
on the property anymore that the 12 least signiﬁcant address
bits of the ﬁrst array buffer index are ‘0’.
b) Preloading: However, the protection given by buffer
ASLR is not complete, as an attacker can still iterate over a
large array to detect page borders using page faults [15], [40].
With 21 bits of the virtual and physical address, a THP page
border contains even more information for an attacker. One
simple prevention for this attack is to iterate through the array
after constructing it. Accessing all underlying pages triggers a
page fault for every page, and an attacker subsequently cannot
learn anything from iterating over the array, as the memory
is already mapped. Thus, Rowhammer.js [15] and the DRAM
covert channel [40] are prevented by Chrome Zero.
c) Non-determinism: Instead of preloading, (i.e., iterat-
ing over the array after construction), we can modify the setter
of the array to add a memory access to a random array index
for every access to the array. This has two advantages in terms
of security. First, with only preloading, an attacker could wait
for the pages to be swapped out, or deduplicated, enabling
8
ScriptOriginalFunctionCallReturnScriptFunctionOverrideOriginalFunctionCallReturnScriptFunctionWrapperCallReturnmodiﬁedOriginalFunctionCallReturnCallFunctionWrapperCalloriginalorreturnAskScriptCallReturnOriginalFunctionCallReturnTABLE II: ALL DISCUSSED POLICIES (EXCEPT FOR SENSORS) AND THEIR EFFECT ON ATTACKS.
Prevents
Policy
Buffer ASLR
Array preloading
Non-deterministic array
Array index randomization
Low-resolution timestamp
Fuzzy time
WebWorker polyﬁll
Message delay
Slow SharedArrayBuffer
No SharedArrayBuffer
Summary
Rowham-
mer.js [15]
Page Dedu-
plication [14]
DRAM Covert Anti-
Channel [40]
ASLR [13]
Cache Eviction
[33], [15], [40], [13]
Keystroke
Timing [47], [20]
Browser
[44], [45], [47]
Exploits (cf.
Section VI-B)
*
*
*
*
*
*
*
*
Symbols indicate whether a policy fully prevents an attack, (
), partly prevents and attack by making it more difﬁcult (
), or does not prevent an attack (
A star (*) indicates that all policies marked with a star must be combined to prevent an attack.
).
TABLE III: A TABLE OF HOW POLICIES CORRESPOND TO THE PROTECTION LEVELS OF Chrome Zero.
Requirement
Memory addresses
Accurate Timing
Multithreading
Shared data
Sensor API
Protection Level Off
-
-
-
-
-
Low
Medium
High
Paranoid
Buffer ASLR
Ask
-
-
-
Array preloading
Low-resolution timestamp
Message delay
Slow SharedArrayBuffer
Ask
Non-deterministic array Array index randomization
Fuzzy time
WebWorker polyﬁll
Disable
Fixed value
Disable
Disable
Disable
Disable
(a) Page border detection without random accesses.
(a) Prime+Probe results without random accesses.
(b) Page border detection with random accesses.
(b) Prime+Probe results with random accesses.
Fig. 5: Page border detection without and with Chrome Zero.
When iterating over an array, page faults cause a higher timing
than normal accesses, visible as timing peaks.
page border detection again. The random accesses prevent the
page border detection, as an attacker cannot know whether the
page fault was due to the regular access or due to a random
access. As shown in Figure 5, with the random accesses, the
probability to trigger a page fault for the ﬁrst accesses is
relatively high, as pages are not mapped in the beginning.
This probability decreases until all pages are mapped. Thus, an
attacker cannot reliably detect the actual border of a page but
only the number of pages. Second, this prevents the generation
of eviction sets [33], [15], [40], [13]. A successful eviction of
Fig. 6: When adding random accesses, the timings for cache
hits and misses blend together, making it impractical to decide
whether an access was a cache hit or a miss. In contrast to a
benign use case, the access time is signiﬁcantly increased as
the adversary is priming (i.e., thrashing) the cache and any
memory access is likely a cache miss.
a cache set requires an attacker to measure the access time
of a special memory access pattern [15]. Adding random ac-
cesses in between prevents an attacker from obtaining accurate
measurements, as the random accesses inﬂuence the overall
timing (cf. Figure 6). Note that the access time is signiﬁcantly
increased as the adversary is priming (i.e., thrashing) the cache
and thus, any additional memory access is likely a cache miss.
9
00.20.40.60.811.2·10400.51·105Arrayoffset[KB]Accesstime[cycles]01,0002,0003,0004,0005,00000.51·105Arrayoffset[KB]Accesstime[cycles]501001502002503003504004500246·105Accesstime[cycles]Numberofcasescachehitcachemiss1,5001,6001,7001,8001,9002,0002,1002,2002,3002,40000.511.5·104Accesstime[cycles]NumberofcasescachehitcachemissHence, this does not relate to any benign use case performance
or access time.
d) Array Index Randomization: One attack that can-