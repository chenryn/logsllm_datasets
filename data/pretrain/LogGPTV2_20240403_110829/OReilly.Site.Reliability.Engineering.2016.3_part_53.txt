first step is to invite a representative from that team, or to find a trusted intermediary
to proxy communication or model healthy interactions. There are many reasons why
teams don’t get along, and a wealth of writing on how to solve that problem: this
information is also applicable to SRE teams, but it is important that the end goal of
having a feedback loop from operations is fulfilled, or a large part of the value of hav‐
ing an SRE team is lost.
Occasionally you’ll have too many teams or busy-yet-crucial attendees to invite.
There are a number of techniques you can use to handle those situations:
• Less active services might be attended by a single representative from the product
development team, or only have commitment from the product development
team to read and comment on the agenda minutes.
• If the production development team is quite large, nominate a subset of repre‐
sentatives.
• Busy-yet-crucial attendees can provide feedback and/or steering in advance to
individuals, or using the prefilled agenda technique (described next).
Communications: Production Meetings | 429
Most of the meeting strategies we’ve discussed are common sense, with a service-
oriented twist. One unique spin on making meetings more efficient and more inclu‐
sive is to use the real-time collaborative features of Google Docs. Many SRE teams
have such a doc, with a well-known address that anyone in engineering can access.
Having such a doc enables two great practices:
• Pre-populating the agenda with “bottom up” ideas, comments, and information.
• Preparing the agenda in parallel and in advance is really efficient.
Fully use the multiple-person collaboration features enabled by the product. There’s
nothing quite like seeing a meeting chair type in a sentence, then seeing someone else
supply a link to the source material in brackets after they have finished typing, and
then seeing yet another person tidy up the spelling and grammar in the original sen‐
tence. Such collaboration gets stuff done faster, and makes more people feel like they
own a slice of what the team does.
Collaboration within SRE
Obviously, Google is a multinational organization. Because of the emergency
response and pager rotation component of our role, we have very good business rea‐
sons to be a distributed organization, separated by at least a few time zones. The prac‐
tical impact of this distribution is that we have very fluid definitions for “team”
compared to, for example, the average product development team. We have local
teams, the team on the site, the cross-continental team, virtual teams of various sizes
and coherence, and everything in between. This creates a cheerfully chaotic mix of
responsibilities, skills, and opportunities. Much of the same dynamics could be
expected to pertain to any sufficiently large company (although they might be partic‐
ularly intense for tech companies). Given that most local collaboration faces no par‐
ticular obstacle, the interesting case collaboration-wise is cross-team, cross-site,
across a virtual team, and similar.
This pattern of distribution also informs how SRE teams tend to be organized.
Because our raison d’être is bringing value through technical mastery, and technical
mastery tends to be hard, we therefore try to find a way to have mastery over some
related subset of systems or infrastructures, in order to decrease cognitive load. Spe‐
cialization is one way of accomplishing this objective; i.e., team X works only on
product Y. Specialization is good, because it leads to higher chances of improved
technical mastery, but it’s also bad, because it leads to siloization and ignorance of the
broader picture. We try to have a crisp team charter to define what a team will—and
more importantly, won’t—support, but we don’t always succeed.
430 | Chapter 31: Communication and Collaboration in SRE
Team Composition
We have a wide array of skill sets in SRE, ranging from systems engineering through
software engineering, and into organization and management. The one thing we can
say about collaboration is that your chances of successful collaboration—and indeed
just about anything else—are improved by having more diversity in your team.
There’s a lot of evidence suggesting that diverse teams are simply better teams
[Nel14]. Running a diverse team implies particular attention to communication, cog‐
nitive biases, and so on, which we can’t cover in detail here.
Formally, SRE teams have the roles of “tech lead” (TL), “manager” (SRM), and
“project manager” (also known as PM, TPM, PgM). Some people operate best when
those roles have well-defined responsibilities: the major benefit of this being they can
make in-scope decisions quickly and safely. Others operate best in a more fluid envi‐
ronment, with shifting responsibilities depending on dynamic negotiation. In gen‐
eral, the more fluid the team is, the more developed it is in terms of the capabilities of
the individuals, and the more able the team is to adapt to new situations—but at the
cost of having to communicate more and more often, because less background can be
assumed.
Regardless of how well these roles are defined, at a base level the tech lead is responsi‐
ble for technical direction in the team, and can lead in a variety of ways—everything
from carefully commenting on everyone’s code, to holding quarterly direction pre‐
sentations, to building consensus in the team. In Google, TLs can do almost all of a
manager’s job, because our managers are highly technical, but the manager has two
special responsibilities that a TL doesn’t have: the performance management func‐
tion, and being a general catchall for everything that isn’t handled by someone else.
Great TLs, SRMs, and TPMs have a complete set of skills and can cheerfully turn
their hand to organizing a project, commenting on a design doc, or writing code as
necessary.
Techniques for Working Effectively
There are a number of ways to engineer effectively in SRE.
In general, singleton projects fail unless the person is particularly gifted or the prob‐
lem is straightforward. To accomplish anything significant, you pretty much need
multiple people. Therefore, you also need good collaboration skills. Again, lots of
material has been written on this topic, and much of this literature is applicable to
SRE.
In general, good SRE work calls for excellent communication skills when you’re
working outside the boundary of your purely local team. For collaborations outside
the building, effectively working across time zones implies either great written com‐
munication, or lots of travel to supply the in-person experience that is deferrable but
Collaboration within SRE | 431
ultimately necessary for a high-quality relationship. Even if you’re a great writer, over
time you decay into just being an email address until you turn up in the flesh again.
Case Study of Collaboration in SRE: Viceroy
One example of a successful cross-SRE collaboration is a project called Viceroy,
which is a monitoring dashboard framework and service. The current organizational
architecture of SRE can end up with teams producing multiple, slightly different
copies of the same piece of work; for various reasons, monitoring dashboard frame‐
works were a particularly fertile ground for duplication of work.3
The incentives that led to the serious litter problem of many smoldering, abandoned
hulks of monitoring frameworks lying around were pretty simple: each team was
rewarded for developing its own solution, working outside of the team boundary was
hard, and the infrastructure that tended to be provided SRE-wide was typically closer
to a toolkit than a product. This environment encouraged individual engineers to use
the toolkit to make another burning wreck rather than fix the problem for the largest
number of people possible (an effort that would therefore take much longer).
The Coming of the Viceroy
Viceroy was different. It began in 2012 when a number of teams were considering
how to move to Monarch, the new monitoring system at Google. SRE is deeply con‐
servative with respect to monitoring systems, so Monarch somewhat ironically took a
longer while to get traction within SRE than within non-SRE teams. But no one could
argue that our legacy monitoring system, Borgmon (see Chapter 10), had no room
for improvement. For example, our consoles were cumbersome because they used a
custom HTML templating system that was special-cased, full of funky edge cases, and
difficult to test. At that time, Monarch had matured enough to be accepted in princi‐
ple as the replacement for the legacy system and was therefore being adopted by more
and more teams across Google, but it turned out we still had a problem with consoles.
Those of us who tried using Monarch for our services soon found that it fell short in
its console support for two main reasons:
• Consoles were easy to set up for a small service, but didn’t scale well to services
with complex consoles.
• They also didn’t support the legacy monitoring system, making the transition to
Monarch very difficult.
3 In this particular case, the road to hell was indeed paved with JavaScript.
432 | Chapter 31: Communication and Collaboration in SRE
Because no viable alternative to deploying Monarch in this way existed at the time, a
number of team-specific projects launched. Since there was little enough in the way
of coordinated development solutions or even cross-group tracking at the time (a
problem that has since been fixed), we ended up duplicating efforts yet again. Multi‐
ple teams from Spanner, Ads Frontend, and a variety of other services spun up their
own efforts (one notable example was called Consoles++) over the course of 12–18
months, and eventually sanity prevailed when engineers from all those teams woke
up and discovered each other’s respective efforts. They decided to do the sensible
thing and join forces in order to create a general solution for all of SRE. Thus, the
Viceroy project was born in mid 2012.
By the beginning of 2013, Viceroy had started to gather interest from teams who had
yet to move off the legacy system, but who were looking to put a toe in the water.
Obviously, teams with larger existing monitoring projects had fewer incentives to
move to the new system: it was hard for these teams to rationalize jettisoning the low
maintenance cost for their existing solution that basically worked fine, for something
relatively new and unproven that would require lots of effort to make work. The
sheer diversity of requirements added to the reluctance of these teams, even though
all monitoring console projects shared two main requirements, notably:
• Support complex curated dashboards
• Support both Monarch and the legacy monitoring system
Each project also had its own set of technical requirements, which depended on the
author’s preference or experience. For example:
• Multiple data sources outside the core monitoring systems
• Definition of consoles using configuration versus explicit HTML layout
• No JavaScript versus full embrace of JavaScript with AJAX
• Sole use of static content, so the consoles can be cached in the browser
Although some of these requirements were stickier than others, overall they made
merging efforts difficult. Indeed, although the Consoles++ team was interested in
seeing how their project compared to Viceroy, their initial examination in the first
half of 2013 determined that the fundamental differences between the two projects
were significant enough to prevent integration. The largest difficulty was that Viceroy
by design did not use much JavaScript, while Consoles++ was mostly written in Java‐
Script. There was a glimmer of hope, however, in that the two systems did have a
number of underlying similarities:
Case Study of Collaboration in SRE: Viceroy | 433
• They used similar syntaxes for HTML template rendering.
• They shared a number of long-term goals, which neither team had yet begun to
address. For example, both systems wanted to cache monitoring data and sup‐
port an offline pipeline to periodically produce data that the console can use, but
was too computationally expensive to produce on demand.
We ended up parking the unified console discussion for a while. However, by the end
of 2013, both Consoles++ and Viceroy had developed significantly. Their technical
differences had narrowed, because Viceroy had started using JavaScript to render its
monitoring graphs. The two teams met and figured out that integration was a lot eas‐
ier, now that integration boiled down to serving the Consoles++ data out of the Vice‐
roy server. The first integrated prototypes were completed in early 2014, and proved
that the systems could work well together. Both teams felt comfortable committing to
a joint effort at that point, and because Viceroy had already established its brand as a
common monitoring solution, the combined project retained the Viceroy name.
Developing full functionality took a few quarters, but by the end of 2014, the com‐
bined system was complete.
Joining forces reaped huge benefits:
• Viceroy received a host of data sources and the JavaScript clients to access them.
• JavaScript compilation was rewritten to support separate modules that can be
selectively included. This is essential to scale the system to any number of teams
with their own JavaScript code.
• Consoles++ benefited from the many improvements actively being made to Vice‐
roy, such as the addition of its cache and background data pipeline.
• Overall, the development velocity on one solution was much larger than the sum
of all the development velocity of the duplicative projects.
Ultimately, the common future vision was the key factor in combining the projects.
Both teams found value in expanding their development team and benefited from
each other’s contributions. The momentum was such that, by the end of 2014, Vice‐
roy was officially declared the general monitoring solution for all of SRE. Perhaps
characteristically for Google, this declaration didn’t require that teams adopt Viceroy:
rather, it recommended that teams should use Viceroy instead of writing another
monitoring console.
Challenges
While ultimately a success, Viceroy was not without difficulties, and many of those
arose due to the cross-site nature of the project.
434 | Chapter 31: Communication and Collaboration in SRE
Once the extended Viceroy team was established, initial coordination among remote
team members proved difficult. When meeting people for the first time, subtle cues
in writing and speaking can be misinterpreted, because communication styles vary
substantially from person to person. At the start of the project, team members who
weren’t located in Mountain View also missed out on the impromptu water cooler
discussions that often happened shortly before and after meetings (although commu‐
nication has since improved considerably).
While the core Viceroy team remained fairly consistent, the extended team of con‐
tributors was fairly dynamic. Contributors had other responsibilities that changed
over time, and therefore many were able to dedicate between one and three months
to the project. Thus, the developer contributor pool, which was inherently larger than
the core Viceroy team, was characterized by a significant amount of churn.
Adding new people to the project required training each contributor on the overall
design and structure of the system, which took some time. On the other hand, when
an SRE contributed to the core functionality of Viceroy and later returned to their
own team, they were a local expert on the system. That unanticipated dissemination
of local Viceroy experts drove more usage and adoption.
As people joined and left the team, we found that casual contributions were both use‐
ful and costly. The primary cost was the dilution of ownership: once features were
delivered and the person left, the features became unsupported over time, and were
generally dropped.
Furthermore, the scope of the Viceroy project grew over time. It had ambitious goals
at launch but the initial scope was limited. As the scope grew, however, we struggled
to deliver core features on time, and had to improve project management and set
clearer direction to ensure the project stayed on track.
Finally, the Viceroy team found it difficult to completely own a component that had
significant (determining) contributions from distributed sites. Even with the best will
in the world, people generally default to the path of least resistance and discuss issues
or make decisions locally without involving the remote owners, which can lead to
conflict.
Recommendations
You should only develop projects cross-site when you have to, but often there are
good reasons to have to. The cost of working across sites is higher latency for actions
and more communication being required; the benefit is—if you get the mechanics
right—much higher throughput. The single site project can also fall foul of no one
outside of that site knowing what you’re doing, so there are costs to both approaches.
Motivated contributors are valuable, but not all contributions are equally valuable.
Make sure project contributors are actually committed, and aren’t just joining with
Case Study of Collaboration in SRE: Viceroy | 435
some nebulous self-actualization goal (wanting to earn a notch on their belt attaching
their name to a shiny project; wanting to code on a new exciting project without
committing to maintaining that project). Contributors with a specific goal to achieve
will generally be better motivated and will better maintain their contributions.
As projects develop, they usually grow, and you’re not always in the lucky position of
having people in your local team to contribute to the project. Therefore, think care‐
fully about the project structure. The project leaders are important: they provide
long-term vision for the project and make sure all work aligns with that vision and is
prioritized correctly. You also need to have an agreed way of making decisions, and
should specifically optimize for making more decisions locally if there is a high level
of agreement and trust.
The standard “divide and conquer” strategy applies to cross-site projects; you reduce
communication costs primarily by splitting the project into as many reasonably sized
components as possible, and trying to make sure that each component can be
assigned to a small group, preferably within one site. Divide these components
among the project subteams, and establish clear deliverables and deadlines. (Try not
to let Conway’s law distort the natural shape of the software too deeply.)4
A goal for a project team works best when it’s oriented toward providing some func‐
tionality or solving some problem. This approach ensures that the individuals work‐
ing on a component know what is expected of them, and that their work is only
complete once that component is fully integrated and used within the main project.
Obviously, the usual engineering best practices apply to collaborative projects: each
component should have design documents and reviews with the team. In this way,
everyone in the team is given the opportunity to stay abreast of changes, in addition
to the chance to influence and improve designs. Writing things down is one of the
major techniques you have to offset physical and/or logical distance—use it.
Standards are important. Coding style guidelines are a good start, but they’re usually
quite tactical and therefore only a starting point for establishing team norms. Every
time there is a debate around which choice to make on an issue, argue it out fully
with the team but with a strict time limit. Then pick a solution, document it, and
move on. If you can’t agree, you need to pick some arbitrator that everyone respects,
and again just move forward. Over time you’ll build up a collection of these best
practices, which will help new people come up to speed.
Ultimately, there’s no substitute for in-person interaction, although some portion of
face-to-face interaction can be deferred by good use of VC and good written commu‐
nication. If you can, have the leaders of the project meet the rest of the team in per‐
4 That is, software has the same structure as the communications structure of the organization that produces
the software—see https://en.wikipedia.org/wiki/Conway%27s_law.
436 | Chapter 31: Communication and Collaboration in SRE