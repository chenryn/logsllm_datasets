title:When a Tree Falls: Using Diversity in Ensemble Classifiers to Identify
Evasion in Malware Detectors
author:Charles Smutz and
Angelos Stavrou
When a Tree Falls: Using Diversity in Ensemble
Classiﬁers to Identify Evasion in Malware Detectors
Charles Smutz
George Mason University
PI:EMAIL
Angelos Stavrou
George Mason University
PI:EMAIL
Abstract—Machine learning classiﬁers are a vital component
of modern malware and intrusion detection systems. However,
past studies have shown that classiﬁer based detection systems are
susceptible to evasion attacks in practice. Improving the evasion
resistance of learning based systems is an open problem. To
address this, we introduce a novel method for identifying the
observations on which an ensemble classiﬁer performs poorly.
During detection, when a sufﬁcient number of votes from in-
dividual classiﬁers disagree, the ensemble classiﬁer prediction is
shown to be unreliable. The proposed method, ensemble classiﬁer
mutual agreement analysis, allows the detection of many forms
of classiﬁer evasion without additional external ground truth.
We evaluate our approach using PDFrate, a PDF malware
detector. Applying our method to data taken from a real network,
we show that the vast majority of predictions can be made with
high ensemble classiﬁer agreement. However, most classiﬁer eva-
sion attempts, including nine targeted mimicry scenarios from two
recent studies, are given an outcome of uncertain indicating that
these observations cannot be given a reliable prediction by the
classiﬁer. To show the general applicability of our approach, we
tested it against the Drebin Android malware detector where an
uncertain prediction was correctly given to the majority of novel
attacks. Our evaluation includes over 100,000 PDF documents
and 100,000 Android applications. Furthermore, we show that our
approach can be generalized to weaken the effectiveness of the
Gradient Descent and Kernel Density Estimation attacks against
Support Vector Machines. We discovered that feature bagging
is the most important property for enabling ensemble classiﬁer
diversity based evasion detection.
I.
INTRODUCTION
The use of machine learning has emerged as one of the
primary techniques employed to address a wide range of
malfeasance and malicious activities. Applications of machine
learning include clustering of malware families [7], [20],
detection of malicious downloads [12], [34], detection of
account misuse in social networks [14], [44], and detection of
commonly exploited ﬁle formats such as Java archives [36] and
documents [24], [25], [39]. Moreover, statistical or machine
learning techniques have been used successfully for years to
identify SPAM [11], [21], [35].
Permission to freely reproduce all or part of this paper for noncommercial
purposes is granted provided that copies bear this notice and the full citation
on the ﬁrst page. Reproduction for commercial purposes is strictly prohibited
without the prior written consent of the Internet Society, the ﬁrst-named author
(for reproduction of an entire paper only), and the author’s employer if the
paper was prepared within the scope of employment.
NDSS ’16, 21-24 February 2016, San Diego, CA, USA
Copyright 2016 Internet Society, ISBN 1-891562-41-X
http://dx.doi.org/10.14722/ndss.2016.23078
One of the main weaknesses of systems that employ
machine learning classiﬁcation in adversarial environments is
their susceptibility to evasion attacks. With evasion attacks, we
refer to the classes of attacks that take advantage of knowledge
of how the machine learning system operates, and in many
cases utilize access to the training set and features, to evade
detection passively or actively [8], [9], [15], [33], [45].
A common technique used in evasion attacks against ma-
chine learners is mimicry. Mimicry attacks thwart detection by
making the attack data appear benign according to the model
used by the intrusion detection system. Often this is achieved
by hiding overtly malicious content through encoding or en-
cryption [28], [42] or minimizing the footprint of malicious
content through data misuse or code re-use attacks [17], [37].
For instance, content aligning with a benign observation is
added to cover up or drown out the malicious content. Many
detection systems are evaded by exploiting differences in the
detection system and the systems being protected [16], [19].
Even if operational details of defense systems are kept secret,
enough knowledge to conduct evasion can often be obtained
solely from external testing [18]. With all of these potential
evasion vectors, preventing detection evasion remains an open
problem.
Our approach is not to prevent all possible evasion attacks,
but to introduce a mechanism that provides detection of poor
classiﬁer performance. We analyze the use of introspection in
an ensemble classiﬁer to detect when the classiﬁer provides
unreliable results at classiﬁcation time. The use of ensemble
classiﬁer mutual agreement analysis relies on the intuition
that when individual classiﬁers in an ensemble vote for the
same prediction, the prediction is likely to be accurate. When
a sufﬁcient number of the votes are in opposition, then the
classiﬁer prediction is not trustworthy. In this state of internal
classiﬁer disagreement, the detector returns the outcome of
uncertain instead of a prediction of benign or malicious. In
operation, conﬁdence in the predictions of the classiﬁer is
improved at the cost of a small portion of the samples being
labeled as uncertain, indicating that the classiﬁer is not ﬁt
to provide an accurate response. This separation of accurate
predictions from uncertain predictions is possible because the
majority of the misclassiﬁcations, including evasion attempts,
have a classiﬁer voting score distribution distinct from the
accurate predictions.
To evaluate our
technique, we applied mutual agree-
ment analysis to two well-studied malware detection systems:
PDFrate [40] and Drebin [4]. PDFrate uses features derived
from document structure and metadata fed into a Random
Forest classiﬁer to detect Trojan PDFs. PDFrate is used in
real world intrusion detection systems and can be evaluated by
the public through submissions to pdfrate.com. PDFrate was
selected because it is publicly accessible, well documented,
uses an ensemble classiﬁer which returns the raw voting
score, and has been subjected to multiple recently published
mimicry attacks [26], [27], [43]. Our evaluation includes over
100,000 documents sourced from an operational environment
and hundreds of malicious documents in nine unique evasion
scenarios from two independent evasion studies. To demon-
strate the general applicability of our approach, we apply
mutual agreement analysis to the Drebin Android malware
detector using over 100,000 applications, including over 5,000
malicious applications in over 20 labeled malware families. We
ﬁnd that mutual agreement analysis enables the identiﬁcation
of novel malware that would otherwise not be detected reliably.
In building an evasion resistant ensemble using Support
Vector Machines (SVM) as base classiﬁers, we ﬁnd that
feature bagging, or constructing many individual classiﬁers
with randomized subsets of the whole feature set, is crucial
to providing this discriminatory power. Using this method, we
counter the Gradient Descent and Kernel Density Estimation
(GD-KDE) attack, which is highly successful against a tradi-
tional SVM classiﬁer.
II. RELATED WORK
Adversarial learning is an active research topic [18]. Some
studies have proposed methods for creating effective classi-
ﬁer based intrusion detection systems [6], [15], [41]. Many
studies have addressed the importance of data sanitization or
adversarial inﬂuence at training time [5], [13], [23], [30]. Yet
others focus on evasion of the deployed classiﬁer [8], [27],
[43]. We also focus on evasion of a classiﬁer during operation,
but instead of focusing on strategies for evasion, we propose
a means of detecting these evasion attempts.
Estimation of conﬁdence based on knowledge of a pop-
ulation has long been foundational to statical methods [31].
Contemporary research has demonstrated how these conﬁdence
estimates can be applied to a machine learning based classiﬁer
deployed in an online setting [38]. However, since these
approaches rely on new observations matching the distributions
of training samples for which ground truth is known, they
are not applicable to intrusion detection systems which face
novel observations and mimicry attacks. Rather than seeking
to quantify the overall accuracy of a classiﬁer, we identify the
individual observations for which a classiﬁer cannot provide
a reliable response. Our approach makes use of data already
provided by the classiﬁer, without additional appeal to ground
truth or independent outlier analysis.
Recent work has demonstrated that the diversity in ensem-
ble classiﬁers can improve malware detection rates [22], [29],
[46], [47]. Few studies, however, advance practical strategies
for detection of evasion attempts against these ensemble clas-
siﬁers. Chinvale et al. proposed the use of mutual agreement
between a small number of independent SPAM ﬁlters to
optimize individual classiﬁer re-training necessary due to drift
in input data [11]. We extend this approach to introspection
of ensemble classiﬁers in order to provide a per observation
conﬁdence estimate at test time. We differ fundamentally from
Chinvale et al. in that they use the majority result of their en-
sembles as ground truth for re-training of individual classiﬁers
while we focus on identifying the speciﬁc examples where the
ensemble prediction is not trustworthy. In short, Chinvale et al.
use diversity in ensembles to improve classiﬁer performance.
We use diversity to identify when resorting to external ground
truth is necessary. We study the factors that enable diversity
based conﬁdence estimates in ensembles using variations of
bagging. Going beyond natural drift or novel attacks, we
apply mutual agreement analysis to targeted evasion attempts
consisting of attacks against feature extractors, training data,
and speciﬁc classiﬁers.
Our empirical evaluation relies on current research in ma-
chine learning based malware detectors [4], [40] and mimicry
attacks [26], [27], [43]. We seek to mitigate evasion in these
malware detectors.
III. BACKGROUND
We apply mutual agreement analysis to two malware
detectors: PDFrate and Drebin. Our study of PDFrate includes
two mimicry attacks against PDFrate: Mimicus and Reverse
Mimicry.
A. PDFrate
PDFrate is a machine learning based malware detector
operating on PDF documents. The pdfrate.com website allows
user submissions and returns ratings for these submitted ﬁles.
PDFrate is useful for this study because the underlying mech-
anisms are well documented [40], it is openly available for
online attack, and it provides considerable information about
each submitted PDF. Because of this transparency, PDFrate
has been the target of practical mimicry attack studies [26],
[27], [43].
PDFrate classiﬁes PDF documents based on analysis of
their structural and metadata attributes. Risk factors for a ma-
licious document include items such as existence of Javascript
objects or improperly formatted timestamps. On the other
hand, benign documents contain inert content such as text
content or font objects. Basic structural and metadata informa-
tion is extracted using regular expressions applied to the raw
document. This small subset of structural information taken
from the document is presented to the user in the document
scan report. From this base information, features are extracted.
Examples of features include the number of Javascript objects
and the relative position of the end of ﬁle marker in the
document. All told, 202 features are used.
Random Forests is used as the classiﬁer in PDFrate. A
Random Forest is constructed of hundreds or thousands of
individual classiﬁcation trees. For each tree, a subset of the
training set is used for construction. At each node in the tree,
a subset of features is tried to determine which feature and
threshold best divides the classes. This process is repeated until
each leaf node contains a single class. Hence, in a Random
Forest, each tree is based on both a randomly selected subset
of the training data and the features. New observations are
run through each tree, the leaf node dictating the vote for
that tree. A discriminating characteristic of PDFrate is that it
provides a score or rating instead of a simple benign/malicious
2
determination. The score provided by PDFrate is the portion
of trees that voted for the positive (malicious) class.
The PDFrate website provides scores from classiﬁers based
on multiple training sets. The Contagio data set is taken from
a widely available data set designated for researchers [32]. It
contains 10,000 documents, evenly split between benign and
malicious. The list of documents in this data set is published
openly. The second data set was composed by researchers at
George Mason University and is called the University data set.
It contains a much larger number of documents, over 100,000,
but the exact composition of the training set is not published.
We use both of these training sets, and the classiﬁers derived
from them, in this study.
B. Mimicus
Mimicus [1] is a framework for performing mimicry at-
tacks against PDFrate. It is the implementation of what is
described by ˇSrndi´c and Laskov as “the ﬁrst empirical security
evaluation of a deployed learning-based system” [43]. It is an
independent, comprehensive, and openly available framework
for attacks against the online implementation of PDFrate.
that
Mimicus implements mimicry attacks by modifying ex-
isting malicious documents to appear more like benign doc-
uments. Mimicus adds markers for additional structural and
metadata items to documents. These additions do not involve
adding actual content
is interpreted by a standards-
conforming PDF reader, but rather these additions exploit a
weakness in the feature extractor of PDFrate. The extraneous
PDF attributes are added in slack, or unused space, immedi-
ately preceding the document trailer (structure at the end of the
document), which is not prohibited by the PDF speciﬁcation.
This approach provides considerable ﬂexibility in the evasion
attack as the additional elements do not have to be valid.
Mimicus enables a simple process for the attacker. The attacker
constructs a malicious document without concern for PDFrate
evasion. Mimicus then adds the necessary decoy structural
elements. This mimicry attack only adds fake elements to the
document ﬁle–no existing elements are removed or modiﬁed.
Mimicus constructs these decoy elements by comparing
a malicious document to multiple different benign documents.
The feature vectors for the malicious documents are adjusted to
mirror the feature vectors for the benign documents. These ad-
justments are bounded by the modiﬁcation approach Mimicus
uses. The candidate mimicry feature vectors are run through a
local PDFrate replica to determine the scores. The best feature
vector is selected. That feature vector is used as the goal in
modifying the original malicious document by adding decoy
structural and metadata elements. Due to interrelated features
and other complications, it is not feasible to construct a ﬁnal
mimicry malicious document that exactly matches the target
mimicry feature vector. The resulting malicious document has
a feature vector that is somewhere between that of the original
Trojan document and that of a benign document. After the
mimicry document is created, it is submitted to pdfrate.com
for evaluation.
An important observation of the Mimicus study is that the
interdependency of PDFrate’s features make mimicry attacks
more difﬁcult because modifying one feature necessarily af-
fects other features. It is generally accepted that irrelevant
or redundant features are not desirable for machine learning
methods. However, in the case of PDFrate, redundant features
appear to make evasion attacks, like those implemented by
Mimicus, more difﬁcult by making construction of a PDF
matching a target feature vector more difﬁcult.
The Mimicus attack model requires knowledge of the
feature set used by PDFrate. The premise is that for a mimicry
attack to be successful, at least knowledge of the type of fea-
tures is necessary. Also, since this attack leverages a difference
between normal PDF readers and the PDFrate feature extractor,
knowledge of how to exploit this difference is also necessary.
Hence, all Mimicus attack scenarios are labeled with an “F”,
indicating that the attacker used knowledge of the feature set.
Relying on the common basis of the feature extraction,
the Mimicus attacks demonstrate various levels of knowledge
used by the attacker. In situations where the training data and
classiﬁer are known by the attacker, replicas that are very close
to the original are used. When an attacker with limited system
knowledge is modeled, reasonable substitutes are employed.
The labels “T” and “C” are used to denote attacker knowledge
of training data and classiﬁer, respectively. Hence, an attack
scenario with the label “FTC” denotes attacker knowledge of
all three major facets of PDFrate.
The training set used by the Contagio classiﬁer of PDFrate
is publicly documented and is readily available to researchers.
Hence, in attack scenarios where the training data is known
by the attacker, the same data set is used by PDFrate and
Mimicus. For scenarios where the attacker has no knowledge
of the training set, ˇSrndi´c and Laskov compiled a surrogate
training set with malicious documents sourced from VirusTotal
and benign documents sourced from the Internet. In addition,
they selected 100 malicious documents from within the Con-
tagio training set for the baseline attack documents. To allow
reproduction of results, all of the data sets used by ˇSrndi´c and
Laskov are documented.
Lastly, to complete the ofﬂine PDFrate replica, ˇSrndi´c and
Laskov used a Random Forests classiﬁer when knowledge
of the classiﬁer was known, and a Support Vector Machine
classiﬁer to simulate the case of the naive attacker. The Mim-
icus study shows that when all three particulars of PDFrate
are spoofed, the result is nearly identical scores from the
PDFrate online and the Mimicus ofﬂine classiﬁer, despite
various implementation differences. Mimicus also implements
a GD-KDE attack which seeks to attack the SVM surrogate
classiﬁer directly. This attack does not apply to Random
Forests classiﬁers, and therefore does not directly apply to
PDFrate.
C. Reverse Mimicry
Maiorca et al. also study evasion against PDFrate and
other PDF document classiﬁers [26], [27]. They advance the
Reverse Mimicry technique. Instead of adding content to a
malicious document to make it appear benign (as Mimicus
does), they embed malicious content into a benign PDF, taking
care to modify as little as possible. The Reverse Mimicry attack
implements an independent evasion approach against PDFrate.
Three different evasion scenarios are advanced by Maiorca
et al. In the EXEembed scenario, a malicious executable is
3
implanted in an existing benign PDF document. The malware
is executed when the document is opened. These documents
utilize CVE-2010-1240. In the PDFembed scenario, a mali-
cious PDF is embedded into a benign PDF. These embedded
documents are rendered automatically when the document is
opened. For evaluation, Maiorca et al. embedded a document
leveraging CVE-2009-0927 into existing benign PDF docu-
ments. Lastly, in the JSinject scenario, malicious Javascript, the
same used in the PDFembed embedded document, is injected
directly into the root benign document.
In order to evade detection, the Reverse Mimicry attacks
focus on changing the document structure as little as possible.
For example, in the EXEembed attack, a new logical version
of the PDF is constructed with few new structural elements,
but all the content from the original PDF is left in the ﬁle. A
compliant reader will not display the content associated with
the previous version of the document, but the artifacts will
be analyzed by the feature extractor of PDFrate and similar