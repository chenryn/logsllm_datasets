|---|---|---|
| where SonsOfðniÞ denotes the set of son nodes for node ni (and it is the same for node n). According to this, we can obtain the |where SonsOfðniÞ denotes the set of son nodes for node ni (and it is the same for node n). According to this, we can obtain the |where SonsOfðniÞ denotes the set of son nodes for node ni (and it is the same for node n). According to this, we can obtain the |Table 2 
Combination similarity degrees.
(a) CSim between nodes of T0 and CBN
| Node in T0 | Node in CBN | Combination similarity (CSim0) |
|---|---|---|
| Fault |Fault |0.65 |
| DetailEntries |DetailEntries |0.88 |
| FaultCode |FaultCode |1 |
| Description |Description |1 |
| ... |... |... |
(b) CSim between nodes of T1 and CBN
| Node in T1 | Node in CBN | Combination similarity (CSim1) ||---|---|---|
| Fault |Fault |0.77 |
| DetailEntries |DetailEntries |0.63 |
| FaultEntries |FaultEntries |1 |
| FaultCode |FaultCode |1 |
| ... |... |... |
SDðri;mi;nÞ ¼
where CSetðnÞ represents the set of tree nodes corresponding 8  : 
e;paðeÞ2NodeSetðrÞ
paðeÞ2NodeSetðrÞ P 	P SDðr;paðeÞ;pÞ 	SDðr;paðeÞ;pÞ SDðr;e;qÞ; 	StrEquaðe;qÞ; q2Nt 	q2Ns 	ð5Þ
NodeSet(r) is the node (or element) set of record r, and StrEqual(e, q) means whether e equals to q by string matching.For the CBN of category c, we suppose each node has node c as its father. Thus, the root element of each record in this category has the same parent node c. The conditional proba-bility can be computed as follows
X. Han et al. / CAAI Transactions on Intelligence Technology 1 (2016) 61e71 	67
pðn ¼ qjpaðnÞ ¼ p;cÞ ¼ 	Based on above computation formulas, the similarity-based 	u2Ns∪NT P 	r2RC SimNumðr;p;qÞ P 	r2RC SimNumðr;p;UÞ P 	ð6Þlearning algorithm is shown below.
Given the training records in a category c and the node set of constructed CBN, we can compute the conditional proba-bility P(q j p, c) for each node q and its parent p in the CBN, using this learning algorithm.
4.3. Similarity-based Bayesian learning algorithm in dynamical environmentConsidering the dynamic nature of log data from realworld systems, we need to update the existing classification model to get accurate diagnosis in dynamic environment. Actually, the dependent information of existing CBN model may be inac-curate or incomplete when training data are changing. It re-quires dynamically updating the structure and dependency probabilities of the CBN model. To obtain a more accurate generation model, we dynamically update existing CBN model based on incremental training data, by (1) adding new nodes to current node set, (2) changing dependency between nodes, and (3) calculating the dependency probability for the updated dependency set.Depending on new training data, we incrementally generate the classification model CBND for different categories. Then, for a specific category c, we dynamically update the probability set P 	Dand probability set of existing CBN0, based on the structure Gc 
Pc Dof newly constructed CBND. In this subsection, we propose the dynamic similarity-based learning algorithm, which can update the existing model and calculate its corresponding prob-abilities when new training data are arriving.In this algorithm, according to the obtained similarity, we calculate the similarity degree SDD for different categories between nodes of new model CBND and the existing model CBN0. Herein, SDDðmD; n; cÞ denotes the similarity degree for category c between the node mD of new model CBND and the node n of current model CBN0. The corresponding formula is shown as follows.
SDDðmD;n;cÞ¼SDDðmD;n;cÞ¼
where EquSet(mi) and SimSet(mi) represent the equivalent set 8 < : 	CSimiðmi;nÞ; 	argmaxSimDiðmD;miÞ$CSimiðmi;nÞ; mD2SimSetðmiÞ 0; 	mD2EquSetðmiÞ
other 
	ð7Þand the similar set of a node mi from schema tree Ti, respec-tively. Herein, SimDiðmD; miÞ denotes the similarity degree between node mD and node mi. In other words, if node mD is equivalent to a schema tree node mi, we can obtain SD by directly calculating combination similarity degree of node mi and node n. Otherwise, when node mD is similar to a schema tree node mi, we can get SD by multiplying the similarity Based on the above computation formula, the dynamic degrees SimDiðmD; miÞ and CSimiðmi; nÞ.similarity-based learning algorithm is shown below. The focus of the improved algorithm is the dynamical update of the dependency probabilities of the CBN model. In this algorithm, if an edge does not belong to the intersection of GcandGc D, its probability will be calculated based on the value of the simi-larity degree SDD.
68 	X. Han et al. / CAAI Transactions on Intelligence Technology 1 (2016) 61e71Using the proposed dynamic similarity-based learning al-gorithm, we can update the existing CBN model and calculate its corresponding probabilities based on incremental training data in the dynamic environment.
4.4. Fault diagnosis by classifying log data with CBNsBy labeling the training log records from heterogeneous sources with related categories, fault diagnosis can be viewed as a classification problem for log records obtained in runtime. As mentioned above, we can achieve the goal of fault diag-nosis by classifying log data using the proposed generative model. According to this, the main approach of fault diagnosis is to first construct the combination part of CBNs by matching schema trees, then compute the probabilities of CBNs from training data based on estimated similarity degrees, and finally classify the newly obtained log data into possible fault cate-gories using generated CBNs.In classification task, the CBN model plays a key role which is proposed as a generative model based on Bayesian networks. The log records in training dataset with the same category will share the parameters of a CBN. That is to say, there is a set of such parameters for each fault category. The similarity-based probabilities of the CBNs can improve the accuracy of the classification task. Then, the log records in testing dataset can be classified into possible fault categories,5.1. Experiment setupThe log data used in our experiments are collected from our Web services platform which is supported by ActiveVOS en-gine [27]. The log data are generated by the monitoring module of execution engine. The raw log data have different levels including debug, information, warning, error, and fatal levels. In preprocessing step, we have implemented a moni-toring module to extract fault related log data, which ignores the low level information (e.g. the information in debug level) of raw log data. To simulate the data obtained from hetero-geneous sources, we represent a portion of these log data using different XML structure. Then, we get the training dataset by labeling each record of these XML log data. There are 30 Web services running on this platform which is taken as the testbed of our experiment. Since faults in application and middleware levels are the common causes of failures in Web services execution, we inject 95 such faults into running services in-stances. In addition, we implement a synthetic data generation program to simulate the creation of log data, based on the symptom database [28] for IBM WebSphere Application Server. We have generated 1000 pieces of log records from 11,601 pieces of XML log records in this database. And the training dataset is obtained by labeling each data record ac-cording to the value of “symptomtype” attribute.by calculating the probability that each category will generate 	5.2. Datasets
the log data record. Given a category c and a test log record| rtest, we can estimate the conditional probability by the formula | rtest, we can estimate the conditional probability by the formula | rtest, we can estimate the conditional probability by the formula | rtest, we can estimate the conditional probability by the formula | rtest, we can estimate the conditional probability by the formula | rtest, we can estimate the conditional probability by the formula | Herein, training data and test data are selected randomly in accordance with the 90/10 ratio. Then, 50 percent of training data is used as new data. To simulate the update of the training dataset in dynamic environment, new log data are added to the training dataset at a fixed speed. For each dataset, we design 40 simulation cases, which has a corresponding training and ||---|---|---|---|---|---|---|
| PðrtestjcÞ ¼ |ns2Ns Y |PðnsjpaðnsÞ;cÞ |nt2Nt Y |PðntjpaðntÞ;cÞ |ð8Þ |Herein, training data and test data are selected randomly in accordance with the 90/10 ratio. Then, 50 percent of training data is used as new data. To simulate the update of the training dataset in dynamic environment, new log data are added to the training dataset at a fixed speed. For each dataset, we design 40 simulation cases, which has a corresponding training and |Given the set of predefined categories, our objective is to assign most probable category labels to unlabeled log re-cords, based on the likelihood inference in corresponding CBNs. According to computed conditional probabilities, we will choose the category cMAP which has the maximum posteriori probability value to label the test log record, as shown below.
test datasets.Table 3 shows the detailed information of example datasets used in evaluation. The real and synthetic datasets are further divided into two subsets in different structure, respectively. We select 65 percent of data records in training dataset, which have the structure different from those of the other portion. Then, to show the advantage of our approach, we choose only 30 percent of records in testing dataset, whose structure is the| cMAP¼argmax | PðcÞPðrtestjcÞ 
PðcÞ ns2Ns Y PðnsjpaðnsÞ;cÞ | nt2Nt Y | PðntjpaðntÞ;cÞ | ð9Þ | same to that of the major portion of training dataset. |
|---|---|---|---|---|---|
| cMAP¼argmax |PðcÞPðrtestjcÞ  PðcÞ ns2Ns Y PðnsjpaðnsÞ;cÞ |nt2Nt Y |PðntjpaðntÞ;cÞ |ð9Þ |There are some advantages to evaluate our approach on |
| ¼argmax |PðcÞPðrtestjcÞ  PðcÞ ns2Ns Y PðnsjpaðnsÞ;cÞ |nt2Nt Y |PðntjpaðntÞ;cÞ |ð9Þ |both real and synthetic log datasets. On one hand, we use the || ¼argmax |PðcÞPðrtestjcÞ  PðcÞ ns2Ns Y PðnsjpaðnsÞ;cÞ |nt2Nt Y |PðntjpaðntÞ;cÞ |ð9Þ |real dataset to validate the approach in practical situations. On |
| ¼argmax |PðcÞPðrtestjcÞ  PðcÞ ns2Ns Y PðnsjpaðnsÞ;cÞ |nt2Nt Y |PðntjpaðntÞ;cÞ |ð9Þ |the other hand, the synthetic dataset help us to study the effects |
	of different kinds of structural patterns. 5. Evaluation5.3. Evaluation results To evaluate our approach for fault classification of Web
service flows, we have conducted experiment on both real and synthetic log datasets in this section. We compare the classi-fication results of our approach with those of other classifiers for semi-structured documents. Experimental results show our approach outperforms other two approaches in dynamic andFor evaluating the performance of corresponding ap-proaches, we define accuracy as the proportion of log records that are correctly assigned to a category. The average accu-racy is used as the key metric in this experiment, which is the mean accuracy over all categories of the real and synthetic
heterogeneous environment. 	datasets.| X. Han et al. / CAAI Transactions on Intelligence Technology 1 (2016) 61e71 | X. Han et al. / CAAI Transactions on Intelligence Technology 1 (2016) 61e71 | X. Han et al. / CAAI Transactions on Intelligence Technology 1 (2016) 61e71 | X. Han et al. / CAAI Transactions on Intelligence Technology 1 (2016) 61e71 | X. Han et al. / CAAI Transactions on Intelligence Technology 1 (2016) 61e71 | X. Han et al. / CAAI Transactions on Intelligence Technology 1 (2016) 61e71 | X. Han et al. / CAAI Transactions on Intelligence Technology 1 (2016) 61e71 | 69 ||---|---|---|---|---|---|---|---|
| Table 3 |Table 3 |Table 3 |fixed rate. Herein, we use update rate (UR) to represent the |fixed rate. Herein, we use update rate (UR) to represent the |fixed rate. Herein, we use update rate (UR) to represent the |fixed rate. Herein, we use update rate (UR) to represent the |fixed rate. Herein, we use update rate (UR) to represent the || Example datasets used in evaluation. |Example datasets used in evaluation. |Example datasets used in evaluation. |fixed rate and set the value of UR to r records per minute. And |fixed rate and set the value of UR to r records per minute. And |fixed rate and set the value of UR to r records per minute. And |fixed rate and set the value of UR to r records per minute. And |fixed rate and set the value of UR to r records per minute. And || Record number |Real dataset |Real dataset |Synthetic dataset |Synthetic dataset |the occurrence time of each new record is set randomly. In the |the occurrence time of each new record is set randomly. In the |the occurrence time of each new record is set randomly. In the |