0.02
0.025
0.03
0.035
0.04
0.045
0.05
1 - (False Negative Rate)
False Positive Rate
path length = 5
uniform between 5 and 8
path length = 8
(c) high link delay
(d) edr = 5%, imdr = 1%, high link delay
0.5
0.55
0.6
0.65
0.7
0.75
0.8
0.85
0.9
0.95
1
0
0.05
0.1
0.15
0.2
0.25
0.3
0.35
0.4
0.45
0.5
1 - (False Negative Rate)
False Positive Rate
imdr = 0%, no def. dropping
imdr = 1%, no def. dropping
imdr = 0%, w/ def. dropping
imdr = 1%, w/ def. dropping
0.5
0.55
0.6
0.65
0.7
0.75
0.8
0.85
0.9
0.95
1
0
0.05
0.1
0.15
0.2
0.25
0.3
0.35
0.4
0.45
0.5
1 - (False Negative Rate)
False Positive Rate
imdr = 0% , no def. dropping
imdr = 1%, no def. dropping
imdr = 0%, w/ def. dropping
imdr = 1%, w/ def. dropping
(e) edr = 1%, high link delay
(f) edr = 5%, high link delay
Fig. 2. ROC curves of simulation results.
Timing Attacks in Low-Latency Mix Systems
11
curves are much further from the upper-left-hand corner than the curves based
on tests without defensive dropping. It makes a much larger diﬀerence than the
imdr. From Figures 2(a–b), we know that imdr is an important factor in how well
these tests do. Since defensive dropping has a much larger impact than imdr, we
know that it does much better than typical variations in network conditions for
confusing the attacker.
7
Discussion
Given that we have isolated the timing analysis apart from the systems and at-
tacks, we now discuss the implications of our results. We ﬁrst note that, rather
than in isolation along a single path, timing analysis would occur in a system
with many paths from many initiators. This creates both opportunities and dif-
ﬁculties for an attacker. We begin by showing how the attacker’s eﬀectiveness
is reduced by prior probabilities. We then show how, when paths or network
conditions change, and when initiators make repeated or long-lasting connec-
tions, an attacker can beneﬁt. We then describe other ways an attacker can
improve his chances of linking the initiator to the responder. We also examine
some important systems considerations.
7.1
Prior Probabilities
One of the key diﬃculties an attacker must face is that the odds of a correct
identiﬁcation vary inversely with the number of initiators. Suppose that, for
a given set of network parameters and system conditions, the attacker would
have a 1% false positive rate and a 1% false negative rate. Although these may
seem like favorable error rates for the attacker, there can be a high incidence
of false positives when the number of initiators grows above 100. The attacker
must account for the prior probability that the initiator being observed is the
initiator of interest, I.
More formally, let us say that event I ∼ J, for two initiators I and J, occurs
when the attacker’s test says that packets received at M I
1 and M J
h are correlated.
Assume that the false positive rate, fp = Pr(I ∼ J|I ̸= J), and the false negative
rate, fn = Pr(I ̸∼ J|I = J), are both known. We can therefore obtain:
Pr(I ∼ J) = Pr(I ∼ J|I = J) Pr(I = J) + Pr(I ∼ J|I ̸= J) Pr(I ̸= J)
= (1 − fn) Pr(I = J) + fp(1 − Pr(I = J))
= (1 − fn − fp) Pr(I = J) + fp
Which leads us to obtain:
Pr(I = J|I ∼ J) = (Pr(I = J ∧ I ∼ J))/ Pr(I ∼ J)
= (Pr(I ∼ J|I = J) Pr(I = J))/ Pr(I ∼ J)
= ((1 − fn) Pr(I = J))/((1 − fn − fp) Pr(I = J) + fp)
12
Levine, Reiter, Wang, and Wright
Suppose Pr(I = J) = 1/n, e.g., the network has n initiators and the adversary
has no additional information about who are likely correspondents. Then, with
fn = fp = 0.01, we get Pr(I = J|I ∼ J) = (.99)/(.99 + .01(n − 1)). With only
n = 10 initiators, the probability of I = J given I ∼ J is about 91.7%. As n
rises to 100 initiators, this probability falls to only 50%. With n = 1000, it is
just over 9%.
Contrast this to the case of Pr(I = J) = 0.09, as the adversary might obtain
additional information about the application, or by the derivation above in a
previous examination of a diﬀerent path for the same initiator I (if it is known
that the initiator will contact the same responder repeatedly). Then, with n =
1000, the probability of I = J given I ∼ J is about 90.7%.
The lessons from this analysis are as follows. First, when the number of
initiators is large, the attacker’s test must be very accurate to correctly identify
the initiator, if the attacker has no additional information about the a priori
probability of an initiator and responder interacting (i.e., if Pr(I = J) = 1/n).
In this case, defensive dropping appears to be an eﬀective strategy in stopping a
timing analysis test in a large system. By signiﬁcantly increasing the error rates
for the attacker (see Table 1), defensive dropping makes a timing analysis that
was otherwise useful much less informative for the attacker. Second, a priori
information, i.e., when Pr(I = J) > 1/n, can be very helpful to the attacker in
large systems.
7.2
Lowering the Error Rates
The attackers cannot eﬀectively determine the best level of correlation with
which to identify the initiator unless they can observe the parameters of the net-
work. One approach would be to create fake users, generally an easy task [9], and
each such user F can generate traﬃc through paths that include attacker mixes
as M F
1 and M F
h . This can be done concurrently with the attack, as the attack
data may be stored until the attackers are ready to analyze it. The attacker can
compare the correlations from traﬃc on the same path and traﬃc on diﬀerent
paths, as with our simulations, and determine the best correlation level to use.
In mix server systems, especially cascade mixes [6], the attacker has an ad-
ditional advantage of being able to compare possible initiators’ traﬃc data to
ﬁnd the best match for a data set taken at M I
h for some unknown I. With a
mix cascade in which n users participate, the attacker can guess that the mix
with the traﬃc timings that best correlate to the timings taken from a stream
of interest at M I
h is M I
1 . This can lower the error rate for the attacker: while a
number of streams may have relatively high correlations with the timing data
at M I
h, it may be that M I
1 will typically have the highest such correlation.
7.3
Attacker Dropping
Defensive dropping may also be thwarted by an attacker that actively drops
packets. When an attacker controls the ﬁrst mix on the path, he may drop
suﬃcient packets to raise the correlation level between the ﬁrst and last mixes.
Timing Attacks in Low-Latency Mix Systems
13
With enough such drops, the attacker will be able to raise his success rates.
When defensive dropping is in place, however, the incidence of attacker drops
must be higher than with constant rate cover traﬃc. Any given drop might be
due to the defensive dropping rather than the active dropping. This means that
the rate of drops seen by the packet dropping mix (or mixes) will be higher than
it would otherwise be. What is unclear is whether such an increase would be
enough to be detected by an honest intermediate mix.
In general, detection of mixes that drop too many packets is a problem of
reputation and incentives for good performance [8, 1] and is beyond the scope of
this paper. We note, however, that stopping active timing attacks requires very
robust reputation mechanisms that allow users to avoid placing unreliable mixes
at the beginning of their paths. In addition, it is important that a user have a
reliable link to the Internet so that the ﬁrst mix does not receive a stream of
traﬃc with many holes to exploit for correlation with the last mix on the path.
7.4
TCP Between Mixes
In our model, we have assumed that each message travels on unreliable links
between mixes. This allows for dropped packets that have been important in
most of the attacks we have described. When TCP is used between each mix,
each packet is reliably delivered despite the presence of drops. The eﬀect this
has on the attacks depends on the packet rates from the initiator and on the
latency between the initiator and the ﬁrst mix.
For example, suppose that the initiator sends 10 packets per second and that
the latency to the ﬁrst mix averages 50 ms (100 ms RTT). A dropped packet will
cause a timeout for the initiator, who must resend the packet. The new packet
will be resent in approximately 100 ms in the average case, long enough for an
estimated RTT to trigger a timeout. One additional packet will be sent by the
initiator, but there will still be a gap of 100 ms, which is equivalent to a packet
loss for timing analysis.
This eﬀect, however, is sensitive to timing. When fewer packets are sent per
second and the latency is suﬃciently low, such eﬀects can be masked by rapid
retransmissions. However, an attacker can still actively delay packets, and a
watchful honest mix later in the path will not know whether such delays were
due to drops and high retransmission delays before the ﬁrst mix or due to the
ﬁrst mix itself.
7.5
The Return Path
Timing attacks can be just as eﬀective and dangerous on the path from M I
h back
to I as on the forward path. Much of what we have said applies to the reverse
path, but there are some key diﬀerences. One diﬀerence is that I must rely on
M I
h to provide cover traﬃc (unless the responder is a peer using an anonymous
reverse path). This, of course, can be a problem if the M I
h is dishonest. However,
due to the reverse layered encryption, any mix before M I
1 can generate the cover
traﬃc and it can still be eﬀective.
14
Levine, Reiter, Wang, and Wright
Because many applications, such as multimedia viewing and ﬁle downloads,
require more data from the responder than from the initiator, there is a sig-
niﬁcant performance problem. Constant rate cover traﬃc can quickly become
prohibitive, requiring a signiﬁcant fraction of the bandwidth of each mix. For
such applications, stopping timing attacks may be unattainable with acceptable
costs.
When cover traﬃc remains possible, defensive dropping is no longer an op-
tion, as a dishonest M I
h will know the timings of the drops. The last mix should
not provide the full amount of cover traﬃc, instead letting each intermediate mix
add some constant rate cover traﬃc in the reverse pattern of defensive dropping.
This helps keep the correlation between M I
h and M I
1 low.
8
Conclusions
Timing analysis against users of anonymous communications systems can be
eﬀective in a wide variety of network and system conditions, and therefore poses
a signiﬁcant challenge to the designer of such systems.
We presented a study of both timing analysis attacks and defenses against
such attacks. We have shown that, under certain assumptions, the conventional
use of cover traﬃc is not eﬀective against timing attacks. Furthermore, inten-
tional packet dropping induced by attacker-controlled mixes can nullify the eﬀect
of cover traﬃc altogether. We proposed a new cover traﬃc technique, defensive
dropping, to obstruct timing analysis. Our results show that end-to-end cover
traﬃc augmented with defensive dropping is a viable and eﬀective method to
defend against timing analysis in low-latency systems.
References
1. A. Acquisti, R. Dingledine, and P. Syverson. On the Economics of Anonymity. In
Proc. Financial Cryptography, Jan 2003.
2. A. Back, I. Goldberg, and A. Shostack. Freedom 2.0 Security Issues and Analysis.
Zero-Knowledge Systems, Inc. white paper, Nov 2000.
3. O. Berthold, H. Federrath, and M. Kohntopp. Project anonymity and unobserv-
ability in the internet. In Proc. Computers Freedom and Privacy, April 2000.
4. O. Berthold, A. Pﬁtzmann, and R. Standtke. The Disadvantages of Free Mix-
Routes and How to Overcome Them. In Proc. Intl. Workshop on Design Issues in
Anonymity and Unobservability, July 2000.
5. J. Bolot. Characterizing End-to-End Packet Delay and Loss in the Internet. Jour-
nal of High Speed Networks, 2(3), Sept 1993.
6. D. Chaum.
Untraceable Electronic
Mail,
Return Addresses, and Digital
Pseudonyms. Communications of the ACM, 24(2):84–88, Feb 1981.
7. W. Dei. Pipenet 1.1, August 1996. http://www.eskimo.com/ weidai/pipenet.txt.
8. R. Dingledine, N. Mathewson, and P. Syverson. Reliable MIX Cascade Networks
through Reputation. In Proc. Financial Cryptography, 2003.
9. J. Douceur. The sybil attack. In Proc. IPTPS, Mar 2002.
10. M. Freedman and R. Morris. Tarzan: A Peer-to-Peer Anonymizing Network Layer.
In Proc. ACM Conference on Computer and Communications Security, Nov 2002.
Timing Attacks in Low-Latency Mix Systems
15
11. S. Gribble.
UC Berkeley Home IP HTTP Traces.
http://www.acm.org/ sig-
comm/ITA/, July 1997.
12. M. Jakobsson. Flash mixing. In Proc. Sym. on Principles of Distributed Computing,
May 1999.
13. D. Kesdogan, J. Egner, and R. Buschkes. Stop-and-go-mixes providing probablilis-
tic anonymity in an open system. In Proc. Information Hiding, Apr 1998.
14. A. Pﬁtzmann, B. Pﬁtzmann, and M. Waidner. ISDNMixes: Untraceable Commu-
nication with Very Small Bandwidth Overhead. In Proc. GI/ITG Communication
in Distributed Systems, Feb 1991.
15. C. Rackoﬀ and D. R. Simon. Cryptographic defense against traﬃc analysis. In
Proc. ACM Sym. on the Theory of Computing, May 1993.
16. M. Reed, P. Syverson, and D. Goldschlag. Anonymous Connections and Onion
Routing. IEEE JSAC Copyright and Privacy Protection, 1998.
17. S. Saroiu, P. Krishna Gummadi, and S. Gribble. A Measurement Study of Peer-to-
Peer File Sharing Systems. In Proc. Multimedia Computing and Networking, Jan
2002.
18. A. Serjantov, R. Dingledine, and P. Syverson. From a trickle to a ﬂood: active
attacks on several mix types. In Information Hiding, 2002.
19. P. Syverson, G. Tsudik, M. Reed, and C. Landwehr. Towards an Analysis of Onion
Routing Security. In Workshop on Design Issues in Anonymity and Unobservabil-
ity, July 2000.
20. M. Wright, M. Adler, B.N. Levine, and C. Shields. An Analysis of the Degradation
of Anonymous Protocols. In Proc. ISOC Sym. on Network and Distributed System
Security, Feb 2002.
21. M. Wright, M. Adler, B.N. Levine, and C. Shields. Defending Anonymous Com-
munication Against Passive Logging Attacks. In Proc. IEEE Sym. on Security and
Privacy, May 2003.