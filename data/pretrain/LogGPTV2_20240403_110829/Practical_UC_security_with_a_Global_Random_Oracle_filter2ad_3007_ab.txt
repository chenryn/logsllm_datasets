discussed above. Indeed, this was already used to build extractable commitments in prior works
(see e.g., [Pas03]). How to achieve the equivocation property, however, is not immediately clear.
Indeed, as discussed earlier, in the gRO model the simulator cannot program the outputs of the
random oracle. Further, since we do not allow for trusted setups (such as a CRS), the simulator
does not have immediate access to a “trapdoor” that allows for equivocation.
Towards that end, our starting point is the observation (already implicit in prior works) that
the task of equivocation can, in fact, be reduced to the task of trapdoor extraction. More concretely,
consider a trapdoor commitment scheme in the CRS model where the knowledge of the CRS trap-
door allows for equivocation (but does not compromise the hiding property of the scheme). For
example, Pedersen’s commitment scheme [Ped91] satisﬁes these properties. Then, consider the fol-
lowing protocol template: ﬁrst, the receiver chooses the CRS of the trapdoor commitment scheme
on its own and sends it to the sender along with an extractable commitment to the associated
trapdoor. For concreteness, let us think of the extractable commitment as simply the answer of the
gRO when queried with the trapdoor string. Next, the committer commits to its input string by
simply using the trapdoor commitment scheme. Since we want to preserve the extractability prop-
erty from the committer side, we further require the committer to query the gRO on the opening of
the above commitment and then commit to the answer of the gRO via another instance of trapdoor
commitment. (Similar ideas were used in [OSVW13].)
Now, consider the following simple strategy for equivocation: the simulator ﬁrst extracts the
value committed by the receiver in the ﬁrst message (by simply observing its query to the gRO) and
then uses it as a trapdoor to later equivocate in both of the trapdoor commitments. While such an
approach would indeed work against a semi-honest receiver, unfortunately, it does not work against
a malicious receiver. The problem is that the above protocol does not preclude a cheating receiver
from committing to some bogus value (instead of the correct trapdoor). Note that here we cannot
simply require the receiver to provide a proof of consistency since proving that a given string is the
output of the random oracle is not an NP statement.
Going further, one can observe that an extractable commitment in the gRO model is, in fact,
only eﬀective if it is later decommitted. This is because otherwise the adversary can choose to simply
not query the gRO at all! Thus, in order to verify that the receiver actually commits to the valid
5
trapdoor, we ask it to open its commitment in the decommitment phase. Now, the simulator can
indeed extract the trapdoor from the ﬁrst message of the receiver and be convinced of its validity
since otherwise the receiver would fail to decommit properly later on.
While the above modiﬁcation yields us the desired equivocation property, unfortunately, the
resultant protocol is no longer sound against adversarial committers. This is because after viewing
the trapdoor revealed by the receiver, a cheating committer can now also equivocate in the same
manner as the simulator. Indeed, it may seem that now the simulator and an adversarial committer
have the exact same power (i.e., both have access to the trapdoor). In order to solve this problem,
we leverage the asymmetry between the simulator and the cheating committer.
In particular,
note that the simulator knows how to equivocate even at the start of the decommitment phase
(conditioned on the event that it previously extracted a valid trapdoor from the receiver), while the
cheating sender can only equivocate after the receiver reveals the trapdoor. Thus, we now require
the committer to commit to its openings of the commitments (from the commitment phase) before
the receiver reveals the trapdoor. This immediately prevents the committer from being able to
equivocate, but still preserves the equivocation property of the simulator. Due to technical reasons,
we require the above commitment to also be extractable. Very brieﬂy, this is necessary to formally
reduce the binding property of the UC commitment scheme to the binding property of the trapdoor
commitment scheme.
Discussion on Efficiency. We compare the eﬃciency of our scheme with Lindell’s commitment
scheme [Lin11] (which, to the best of our knowledge, is the most eﬃcient UC secure commitment
scheme in the CRS model, in the literature). Round Complexity. The commitment phase in our
scheme requires 2 rounds while the commitment phase in [Lin11] is non-interactive. On the positive
side, our decommitment phase requires 3 rounds, while [Lin11] requires 5 rounds. Computational
Complexity. Prior works have demonstrated that the main bottleneck in the computational eﬃciency
is the number of exponentiations. When instantiated with Pedersen’s commitment scheme, our
protocol requires only 5 exponentiations per party: the commitment phase requires 1 exponentiation
from the receiver to compute the parameters for Pedersen commitment, and 4 exponentiations
from the committer to compute two Pedersen’s commitments; in the decommitment phase the
same exponentiations are required in the reverse order for the veriﬁcation of the parameters and
the decommitments. In contrast, in [Lin11], requires 13 exponentiations per party. Our protocol
additionally requires 6 random oracle evaluations.
1.2.2 Eﬃcient NISC in gRO Model.
Our starting point is the NISC protocol of [AMPR14], which is UC-secure in the CRS model. Our
goal is to emulate their approach in the gRO model. Towards that end, we observe that this task
can be reduced to implementing a UC secure oblivious transfer (OT) protocol in the gRO model.
In particular, since our focus is on eﬃciency, recall that the NISC protocol of [AMPR14] relies on
the highly eﬃcient UC OT protocol of Peikert et. al [PVW08]. (For convenience, let us refer to
this protocol as PVW OT.) Therefore, our goal then is to realize a version of PVW OT in the gRO
model.
Realizing this simple idea, however, turns out to be highly problematic. Note that since a CRS
is not available in our setting, the natural approach is to have the OT receiver choose the OT
parameters (that comprise the CRS in [PVW08]) and provide a zero-knowledge proof of knowledge
(ZKPoK) of consistency. We stress that both the ZK and PoK properties of the proof are crucial
6
here to ensure that the resulting OT protocol is fully simulatable. Speciﬁcally, the ZK property is
necessary to allow the simulator to cheat in the computation of the parameters and extract both
the inputs of a malicious OT sender. The PoK property, on the other hand, allows the simulator
to extract the input of the receiver. Note, however, that a ZK proof in the gRO model requires at
least two rounds [Pas03]. As such, the resulting OT protocol in the gRO model becomes 3 rounds
which violates the non-interactivity requirement for NISC.
Towards that end, upon closer inspection of the NISC protocol of [AMPR14], we make the
following observation: Let P1 and P2 denote the two parties in the NISC protocol where P1 is the
evaluator of the garbled circuit, and therefore the receiver of the OT, and P2 is the generator of
the garbled circuit and therefore the sender of the OT. Then, [AMPR14] uses the simulatability
property of OT against malicious OT senders to extract the input of the sender P2.
Our ﬁrst idea is to extract the critical information from P2 by exploiting the observability
property of gRO. Speciﬁcally, we modify the NISC protocol of [AMPR14] by requiring that the
randomness used to compute the commitments and the garbled circuits is generated by querying
gRO. This enables the simulator –that observes the queries– to extract all the keys of the garbled
circuits in “straight-line” without simulating the OT protocol for adversarial OT sender. Therefore,
the problem of implementing the NISC protocol of [AMPR14] in the gRO model now reduces to
constructing a 2 round one-sided simulatable OT, namely, an OT which is UC simulatable against
malicious receivers but only guarantees indistinguishability security against malicious senders.
Our next contribution is to provide such a construction. The high-level strategy is to replace
the (2-round) ZKPoK in the above construction of PVW OT with a non-interactive witness hiding
(or witness indistinguishable) PoK in the gRO model. Implementing this idea, however, turns out
to be quite non-trivial. Recall that the security of PVW OT against a malicious sender relies on
the hardness of the DDH problem: an adversary distinguishing the input bit of the honest receiver
can be used to construct an adversary that distinguishes a DDH tuple from a non-DDH tuple. This
reduction goes smoothly when the receiver in PVW OT gives a ZKPoK proof of the correctness of
the OT parameters since the DDH distinguisher can use its challenge tuple as the OT parameters
and give a simulated ZK proof of correctness without knowledge of the corresponding witness.
However, when we replace the ZK proof with (say) a witness hiding (WH) proof, then the above
reduction does not work because the DDH distinguisher does not know the witness for the proof.
Towards that end, we pursue the idea of using a witness-indistinguishable (WI) proof instead of a
WH proof. We have the following two-fold requirement: ﬁrst, the statement for the WI proof should
enable a secondary witness that can be used by the DDH distinguisher in the above reduction to
construct a valid proof (without knowledge of the witness corresponding to the challenge tuple).
Second, the PoK property of the proof should enable extraction of a cheating OT receiver’s input
even if she uses the secondary witness.
As we discuss later in Sec.5, realizing the above two properties simultaneously turns out to be a
diﬃcult task. Our ﬁnal idea towards this end is to essentially run the OT protocol twice in parallel.
Speciﬁcally, we require the OT receiver to choose two independent OT parameters and give a single
WIPoK proof that proves the correctness of one of them. The sender then secret shares each of
its OT input into two parts and then computes two diﬀerent OT messages (using diﬀerent OT
parameters), one for each set of input shares.
Now, in order to argue security against cheating senders, we can construct a DDH distinguisher
who uses the challenge tuple as one of the two OT parameters and generates the second one on
its own. This allows the distinguisher to successfully give a WI proof of correctness. On the other
7
hand, when the OT receiver is corrupted, the soundness of WIPoK ensures that at least one of the
OT parameters is honestly generated. Therefore, we can ensure that a cheating receiver cannot
learn both the inputs of the honest sender. In particular, the simulator uses the PoK property to
extract the input of the receiver (which may be ⊥ if the one set of OT parameters chosen by the
receiver is malformed, since in this case, the receiver will not learn either of the inputs of the honest
sender). We refer the reader to Sec. 5 for more details.
Discussion on Efficiency. Our one-sided simulatable OT in the gRO model is more expensive in
terms of exponentiations compared with the PVW OT in the CRS model. This is due to the WIPoK
that the OT receiver has to perform at the beginning of the protocol to prove the consistency of
the OT parameters. The WIPoK protocol that we use requires t parallel repetitions of a Σ-protocol
(which are necessary to achieve straight-line extractability [Fis05] in the gRO model), where t is
the statistical security parameter. The underlying Σ-protocol is based on the Σ-protocol provided
in [CDS94] to prove OR-statements, and requires 8 exponentiations. Therefore, in total the proof
requires 8t exponentiations. We stress that this proof is executed only once at the beginning, and
the same parameters can be reused for all the subsequent transfers.
Furthermore, as our OT-protocol consists of a double repetition of PVW OT, each transfer
is twice more expensive than a transfer with PVW OT. Additionally, our protocol requires 4.5t
random oracle evaluations (the explanation of such values are deferred to Sec. 5). However, we
observe that the NISC protocol of [AMPR14] requires O(tn + t2) exponentiations, where t is the
statistical parameter for the cut-and-choose protocol and n is the size of the input of one of the
parties. Therefore, when plugged into NISC, our one-sided simulatable OT construction does not
add a signiﬁcant overhead.
2 The Global Random Oracle Model
In this section we describe our model and explain our deﬁnitional choices. Toward this end we
brieﬂy discuss the UC deﬁnition and its extensions JUC (Joint State UC) and GUC (Generalized
UC).
2.1 Basic UC
Informal. The Universal Composability (UC) framework was introduced in [Can01] by Canetti to
simplify the security analysis of protocols running in the complex network environment, like the
Internet, where arbitrary protocols are potentially run concurrently. Namely, assume that one has
to design a protocol and to prove that the protocol is secure even if run concurrently with many
instances of arbitrary protocols. In the proof of security one should somehow take into account all
such possible executions and prove that no matter what all these protocols are doing, the protocol
remains secure. Let us call this protocol –the one for which we want to prove security– challenge
protocol.
The UC framework allows one to analyze the security of the challenge protocol in isolation
(without having to consider the concurrent executions) and then use the composition theorem to
conclude that the protocol will be secure also when composed with arbitrary protocols.
The crucial aspect of the UC framework is indeed its modularity: when programs call subroutines,
these subroutines are treated as separate entities that can be analyzed separately for their security
properties by way of realizing a functionality G. It is then argued, via the universal composition
8
theorem, that any protocol that uses subroutine calls to G keeps all its security properties when G
is replaced by a protocol that realizes it.
This powerful composition theorem holds only when subroutines do not share any part of their
internal states with each other or with the calling protocol. In particular, a setup functionality that
is modeled as a subroutine of the analyzed protocol cannot be invoked by more than one protocol
session. In practice this means that even setup functionalities like PKI or CRS cannot be shared
by more than one protocol.
Technical. The UC framework is based on the ideal/real world paradigm. In the ideal world, one
speciﬁes an ideal functionality F as an interactive Turing machine that privately communicates with
the parties and the adversary S and computes a task in a trusted manner. The speciﬁcation of the
functionality also models the adversary’s ability to inﬂuence the computation and the information
that the protocol leaks.
In the real world, one speciﬁes a protocol Π that is executed by the parties. Parties communicate
over the channel in presence of an adversary A which controls the schedule of the communication
over the channel, and can corrupt parties. Both in the ideal world and in the real world, parties are
identiﬁed by a unique id, called P ID together with a session id, SID. When a party is corrupted
the adversary receives its secret input and its internal state. In this work, we consider only static
adversaries, which means that A can corrupt a party only before the protocol execution starts.
The presence of arbitrary protocol running in the network is modeled via the concept of the
environment Z. The environment Z determines the inputs to the parties running the challenge
protocol and see the outputs generated by these parties. The environment communicates with the
adversary A/S and corrupts parties through the adversary. Typically, wlog one assume that the
adversary A is dummy in the sense that he just acts as a proxy between the environment and the
honest parties participating in the challenge protocol.
A protocol Π securely realizes a functionality F in the UC framework if for any real world
adversary A, there exists an ideal adversary S, such that for any PPT environment Z the view of
an interaction with the protocol and A is indistinguishable from the view of an interaction with the
ideal functionality F and S. One also considers a G-hybrid model, where the real-world parties are
additionally given access to an ideal setup functionality G. During the execution of the protocol,
the parties can send inputs to, and receive outputs from, the functionality G.