The resulting data is the error in the arrival time th(i)
of the i-th hat pulse:
E(i) = th(i) − tr(i), i = 1, 2, . . .
compared to the reference tr(i).
Since (by necessity) our reference is assumed perfect,
we know that tr(i) = tr(1) − 1 + i. We can therefore
recover the hat pulse times as
th(i) = tr(i) + E(i) = tr(1) − 1 + i + E(i)
and obtain the Inter-Pulse Time sequence, used in sta-
bility analysis, as
IPT(i) = th(i + 1) − th(i) = 1 + E(i + 1) − E(i).
To examine pulse shapes we employ the oscilloscope,
collecting summary statistics on rise and fall times, and
pulse widths for the two pulse trains separately. The
scope was set to trigger at 1.2 V for the SRS and 0.86 V
for the hats (50% of the recorded output voltage at
50 ohms). The trigger level, together with the choice
of edge, in fact deﬁnes where pulses ‘are’. The rise/fall
times can therefore be read as bounds on variations in
pulse position arising from alternative trigger choices
that may be found in equipment accepting PPS input.
We collect data from our ‘main’ hat in an experiment
99 hours long, and also from four other hats of the same
type, each 12 hours long.
pulse #i×1050.511.522.533.5E(i) [ns]-2000200400600[ns]-2000200400600med= 73, iqr= 1.2e+02 [ns]3.2 Results
Errors: The error histogram shown in Figure 2 for the
main hat is well behaved. With a median error of 116ns
and an inter-quartile range of only 73ns, by itself this
would suggest that the hat is a more than adequate
hardware basis upon which to build a software clock
with sub-µs precision. The other hats are similar, with
median errors of [−83,−35,−81,−74] ns, correspond-
ing inter-quartile ranges of [105, 134, 119, 121] ns, and
ranges all under 1µs (recall range= max−min). How-
ever, the time series in Figure 2 shows that the errors
E(i) are temporally correlated, with oscillatory behav-
ior on multiple timescales, motivating a deeper stability
analysis.
Stability: The IPT(i) sequence contains the variations
in pulse rate about the ideal of a perfect 1PPS. Under-
standing how this rate ﬂuctuates over time reveals and
quantiﬁes the impact of diverse inﬂuences that operate
at diﬀerent timescales.
It is traditional to characterize the variability or sta-
bility of clock oscillators via the Allan Variance [11].
This can be interpreted as a robust measure of the vari-
Figure 3: Allan Deviation of IPT(i) as a function
of timescale τ .
ance of rate, averaged over timescale τ , as a function
of τ (see [18] for a more detailed discussion). Simple
time domain approaches such as the empirical auto-
correlation function are unsuitable as they are highly
biased on non-stationary data. The Allan Variance is in
fact equivalent to a Haar wavelet energy spectrum plot,
and therefore enjoys a number of statistical robustness
features of wavelet analysis (see [4]).
The Allan Deviation (square root of the Allan Vari-
ance) as a function of τ for IPT(i) is shown in the log-
log plot of Figure 3 for all ﬁve hats (the main hat from
Figure 2 stands out as the longer curve).
The results in each case were very similar. As ex-
pected, the value drops as the averaging interval τ grows.
Even at the smallest scale, here τ = 2s, the relative rate
Metric
rise time [ns]
fall time [ns]
pulse width [ms]
min
2.8
3.7
100
1st median
2.8
4.1
100
3.3
5.1
100
99th max
4.1
4.0
6.2
6.5
100
100
Table 1: Pulse shape statistics for the hat.
Metric
rise time [ns]
fall time [ns]
width [ns]
min
5.1
2.6
9900
1st median
5.2
2.6
9950
5.6
2.8
10000
99th
6.4
3.5
10050
max
6.6
3.9
10050
Table 2: Pulse shape statistics for the SRS.
error/deviation is under 6 × 10−9. (At small scales the
sawtooth on the PPS input is being averaged out. The
slope past τ = 100 s is −1, indicating white phase noise.)
This plot is used below to put into context the Allan
Deviation of the Pi’s hardware counter, the STC.
The above analyses were performed on IPT(i) se-
quences from which any outliers were replaced by neu-
tral surrogate values. This is essential to avoid signif-
icant distortion of the Allan Deviation, which is sensi-
tive to impulses. An eﬀective surrogate is to replicate
a neighbor: we set IPT(i) = IPT(i−1) for each outlier
i. In our data we encountered only a single such out-
lier, with E(i) ≈ 0.9s, due to a counter triggering error.
If any such outliers were to reach the Pi, it is critical
that they can be eﬀectively dealt with by the upstream
software clock algorithm or signiﬁcant errors can result.
We return to this general point in the conclusion.
Pulse Shape: Tables 1 and 2 give results obtained
from 1,000 pulses from the hat and our reference respec-
tively. In both cases the pulses are extremely consistent
in shape, with tight rise and fall times of comparable
size. The pulse width of the hat is much wider than
that of the reference (so wide it results in limited mea-
surement resolution), but this is not important when
rising edges are used in triggering, as here.
4. STABLITY OF THE STC
We now address Goal 1, the stability of the STC on
the Pi. As the core system hardware varies over the
Pi-1, Pi-2 and Pi-3, we provide results for each.
4.1 Experiment Design
We would, ideally, like to read the STC (we call this
raw timestamping) at precisely periodic timepoints with
small period, however performing this within an oper-
ating system is challenging. There are three issues, all
of which concern latency: timestamp triggering, times-
tamping location, and counter reading.
We deal with counter reading by accessing the counter
directly via memory mapping. This provides a minimal
access latency uniformly across kernel and user-space.
Our approach to triggering is to exploit the almost per-
fectly periodic pulses from our reference PPS. Finally, to
τ  [s]100101102103104105Allan deviation10-1210-1110-1010-910-8minimize the latency between the delivery of pulses to
the GPIO pin and their timestamping, the timestamp
location is chosen to be at the beginning of the IRQ
routine responding to pulse interrupts. Kernel modiﬁ-
cations were added to pass the raw timestamps up to a
data logging application.
The resulting data are the raw timestamps STC(ti),
where ti is the true time at which the i-th pulse was
timestamped. We denote the corresponding raw inter-
pulse values by
C(i) = STC(ti+1) − STC(ti).
The timeseries C(i) combines variability from three
sources: (i) the underlying pulses; (ii) the latency be-
tween pulse arrival and timestamping; (iii) the variabil-
ity of the STC itself. It is not possible to separate these
within the Pi, which is why it is so important to send
in the reference quality pulse train to minimize the ﬁrst
component, and to make every eﬀort to minimize the
second as described above, so that C(i) is a low noise
measurement of the underlying STC behavior. It is diﬃ-
cult to provide an accurate ﬁgure for the error bound for
the error in our methodology, that is of latency source
(ii) above, as it depends on hardware characteristics
which can be diﬃcult to obtain. We believe it however
to be typically under 1µs.
We conduct a 20-day long experiment where each Pi
is fed a copy of the same reference pulse from the signal
generator. Hence the pulse and temperature conditions
are identical for each.
4.2 Results
Because the STC is a free running counter, the time-
series STC(ti) displays drift, and so, unlike the case of
the hat’s PPS, C(i) is not centered precisely around its
expected value (namely 106, since the STC is nominally
a 1MHz counter). The actual average period of C(i)
will vary from board to board and can (and must) be
measured, together with the stability about that value.
For each of the Pi’s the variation in C(i) is small: the
inter-quartile range is exactly 1µs in each case, a reﬂec-
tion of the limited resolution of the counter. Accord-
ingly, we use a robust mean rather than the median to
determine the ‘central’ value of the counter period. We
ﬁnd the STC period for the Pi-1, Pi-2 and Pi-3 to diﬀer
from the nominal 1µs by 19.3, −6.76, and −8.13 parts
per million (PPM) respectively. Here and below missing
pulses, and other rare anomalies/outliers in C(i), have
been replaced by neutral surrogates, again to avoid dis-
torting the Allan Deviation.
The Allan Deviation plots for each Pi are shown in
Figure 4. At small scales up to 100s the results are
ordered as one might expect according to generation,
with the older Pi-1 having the most variability and the
Pi-3 the least. At intermediate scales between 100s and
1000s temperature eﬀects enter in, which can aﬀect dif-
ferent platforms diﬀerently (this is more apparent when
looking at subsets of the full trace, which have some
Figure 4: Allan Deviation of ST C(i) as a function
of timescale τ for each generation of Pi.
overlap over this scale range. The full traces are for-
tuitiously well nested here). Finally, at scales beyond
1000s the variability actually starts to increase as diur-
nal temperature proﬁles rather than hardware or soft-
ware eﬀects dominate, and so the platforms become in-
creasingly similar.
The Allan Deviation plot for Pi-3 is very similar in
general terms to that seen in our prior characterization
of commodity PCs and servers [19, 17, 7]. The method-
ology here however, being based on PPS triggering, is
superior, resulting in lower spurious variability. It fol-
lows that the STC is in fact more variable than the
counters previously studied, as one might expect from
a smaller platform, even more so for the Pi-2 and Pi-
1. What is important however is that in each case two
key characterizations: (1) beyond short timescales the
variability drops below 10−7 and stays there, and (2),
the location of the minimum point being of the order
of τ = 1000s, agrees with that of our prior work. This
indicates that the Pi’s are suitable for timekeeping from
the stability point of view, implying underlying limits to
ﬁnal clock quality which are not much worse than those
for PC platforms (see [19, 17]).
The accuracy and reliability of a ﬁnal clock solution
however, depends not only on the underlying counter
hardware, but also on system latencies elsewhere in the
system, and how successfully a synchronization algo-
rithm can ﬁlter these to create a software clock which
is not just accurate, but robust to anomalous events.
5. PITFALLS IN PPS TRIGGERS
Precise coordinated triggering can increase the accu-
racy of distributed measurement applications such as
latency-based Internet coordinate systems, by allowing
precise relative ranging of multiple sources to landmark
nodes [10]. Triggering based on synchronized PPS has
the important advantage that it can be virtually in-
dependent of host system clocks, in particular of their
τ  [s]100101102103104105Allan deviation10-810-710-6Pi-1Pi-2Pi-3This would represent a critical failure to a measurement
infrastructure intending to exploit PPS availability as a
means to coordinate distributed measurement.
In conclusion, although dedicated support exists to
access PPS from user space, for both reliability (failed
callbacks) and accuracy (user-space latency) reasons a
more direct kernel based raw timestamping is needed to
ensure the hat’s potential for well under 1µs triggering
accuracy, exhibited in Figure 2, is realized. This is par-
ticularly true for the special application of disciplining
the system clock itself.
6. PERFORMANCE OF THE PI + HAT
In this section we ask an obvious but important ques-
tion, how good in practical terms is the performance of
the Pi+hat compared to a Pi connected to an expensive,
reference PPS?
6.1 Experiment Design
We compare twin Pi-3’s in a single experiment 28hrs