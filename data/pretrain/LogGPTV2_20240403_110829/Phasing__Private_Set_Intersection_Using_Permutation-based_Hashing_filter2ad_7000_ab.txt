process is repeated until an empty bin is found for the
evicted element. If the resulting sequence of insertion at-
tempts fails a certain number of times, the current evicted
element is placed in a special bin called stash. In [16] it
was shown that for h = 2 hash functions, β = 2(1 + ε)n
bins, and a stash of size s ≤ lnn, the insertion of elements
fails with small probability of O(n−s), which is smaller
than n−(s−1) for sufﬁciently large values of n (cf. §7.2).
2.4 Oblivious Transfer
1-ouf-of-2 oblivious transfer (OT) [8] is a protocol where
the receiver with choice bit c, chooses one of two strings
(x0,x1) held by the sender. The receiver receives xc but
gains no information about x1−c, while the sender gains
no information about c.
OT extension protocols [2, 17] precompute a small
number (say, κ = 128) of “real” public-key-based OTs,
and then compute any polynomial number of OTs using
symmetric-key cryptography alone. The most efﬁcient
OT variant that we use computes random OT. In that pro-
tocol the sender has no input but obtains random (x0,x1)
as output, while the receiver with input c obtains xc [2].
The advantage of this protocol is that the sender does not
need to send messages based on its inputs, as it does not
have any inputs, and instead computes them on-the-ﬂy
during the OT extension protocol. As a result, the com-
munication overhead of the protocol is greatly reduced.
An additional improvement that we use, described
in [17], efﬁciently computes 1-out-of-N OT for short
strings. The communication for a random 1-out-of-N OT
(for 3 ≤ N ≤ 256) is only 2κ-bits, whereas the commu-
nication for a random 1-out-of-2 OT is κ-bits. The com-
putation for a random 1-out-of-N OT amounts to four
pseudo-random generator (PRG) and one correlation-
robust function (CRF) evaluations for the receiver and
two PRG and N CRF evaluations for the sender. In addi-
tion, if the sender only requires i ≤ N outputs of the OT,
it only needs to perform i CRF evaluations.
We use 1-out-of-N OT since we have to perform OTs
for every bit of an element. By using 1-out-of-N OT for
N = 2µ, we process µ bits in parallel with communica-
tion equal to that of processing two bits. We denote m
(cid:29) .
1-out-of-N OTs on (cid:29)-bit strings by(cid:31)N
1(cid:30)-OTm
2.5 Generic Secure Computation
Generic secure two-party computation protocols allow
two parties to securely evaluate any function that can
be expressed as a Boolean circuit. The communica-
tion overhead and the number of cryptographic opera-
tions that are computed are linear in the number of non-
linear (AND) gates in the circuit, since linear (XOR)
gates can be evaluated “for free” in current protocols.
Furthermore, some protocols require a number of inter-
action rounds that are linear in the AND depth of the
circuit. The two main approaches for generic secure
two-party computation on Boolean circuits are Yao’s gar-
bled circuits [25] and the protocol by Goldreich-Micali-
Wigderson [11]. We give a summary of these protocols
in the full version [21].
3 Related Work
We reﬂect on existing PSI protocols by following the
classiﬁcation of PSI protocols in [22]: the naive hash-
ing protocol (§3.1), server-aided PSI protocols (§3.2),
public-key cryptography-based PSI protocols (§3.3),
generic secure computation-based PSI protocols (§3.4),
and OT-based PSI protocols (§3.5). For each category,
4
518  24th USENIX Security Symposium 
USENIX Association
we review existing work and outline the best performing
protocol, according to [22].
(Insecure) Naive Hashing
3.1
In the naive hashing protocol, detailed in the full ver-
sion [21], P1 permutes and hashes its elements, and sends
the results to P2 which compares these values to the
hashes of its elements. This approach is very efﬁcient
and is currently employed in practice, but it allows P2 to
brute-force the elements of P1 if they do not have high en-
tropy. Furthermore, even if inputs elements have high en-
tropy, forward-secrecy is not provided since P2 can check
at any later time whether an element was in X.
3.2 Server-Aided PSI
To increase the efﬁciency of PSI, protocols that use a
semi-trusted third party were proposed [15]. These pro-
tocols are secure as long as the third party does not col-
lude with any of the participants. We mention this set of
protocols here for completeness, as they require different
trust assumptions as protocols involving no third party.
The protocol of [15] has only a slightly higher over-
head than the naive hashing PSI solution described
In that protocol, P1 samples a random κ-bit
in §3.1.
key k and sends it to P2. Both parties compute hi = Fk(xi)
(resp. h(cid:30)j = Fk(y j)), where Fk is a pseudo-random permu-
tation that is parametrized by k. Both parties then send
the hashes to the third party (in randomly permuted or-
der) who then computes I = hi∩h(cid:30)j, for all 1 ≤ i ≤ n1 and
1 ≤ j ≤ n2 and sends I to P2. P2 obtains the intersection
by computing F−1
k
(e) for each e ∈ I.
3.3 Public-Key Cryptography based PSI
The ﬁrst protocols for PSI were outlined in [13, 18] and
were based on the Difﬁe-Hellmann (DH) key exchange.
The overhead of these protocols is O(n) exponentiations.
In [9, 10], a PSI protocol based on El-Gamal encryption
was introduced that uses oblivious polynomial evaluation
and requires O(nloglog(n)) public-key encryptions (the
advantage of that protocol was that its security was not
based on the random oracle model). A PSI protocol that
uses blind-RSA was introduced in [3].
We implement the DH-based protocol of [13, 18]
based on elliptic-curve-cryptography, which was shown
to achieve lowest communication in [22]. We describe
the protocol in the full version [21].
3.4 PSI based on Generic Protocols
Generic secure computation can be used to perform PSI
by encoding the intersection functionality as a Boolean
circuit. The most straightforward method for this encod-
ing is to perform a pairwise-comparison which compares
each element of one party to all elements of the other
party. However, this circuit uses O(n2) comparisons and
hence scales very poorly for larger set sizes [12]. The
Sort-Compare-Shufﬂe (SCS) circuit of [12] is much more
efﬁcient. As indicated by its name, the circuit ﬁrst sorts
the union of the elements of both parties, then compares
adjacent elements for equality, and ﬁnally shufﬂes the re-
sult to avoid information leakage. The sort and shufﬂe
operations are implemented using a sorting network of
only O(nlogn) comparisons, and the comparison step re-
quires only O(n) comparisons.
The work of [12] describes a size-optimized ver-
sion of this circuit for use in Yao’s garbled circuits;
[22] describes a depth-optimized version for use in the
GMW protocol. The size-optimized SCS circuit has
σ (3nlog2 n + 4n) AND gates4 and AND depth (σ +
2)log2(2n)+log2(σ )+1 while the depth-optimized SCS
circuit has about the same number of gates and AND
depth of (log2(σ ) +4) log2(2n), for n = (n1 + n2)/2.
PSI protocols based on generic secure computation
have higher run-time and communication complexity
than most special-purpose PSI protocols [4, 22]. Yet,
these protocols are of great importance since they en-
able to easily compute any functionality that is based
on basic PSI. Consider, for example, an application that
needs to ﬁnd if the size of the intersection is greater than
some threshold, or compute the sum of revenues from
items in the intersection. Computing these functionali-
ties using specialized PSI protocols requires to change
the protocols, whereas a PSI protocol based on generic
computation can be adapted to compute these functional-
ities by using a slightly modiﬁed circuit. In other words,
changing specialized protocols to have a new functional-
ity requires to employ a cryptographer to design a new
protocol variant, whereas changing the functionality of
a generic protocol only requires to design a new circuit
computing the new functionality. The latter task is of
course much simpler. An approximate PSI protocol that
uses generic secure computation protocols in combina-
tion with Bloom ﬁlters was given in [24].
3.5 OT-based PSI
OT-based PSI protocols are the most recent category of
PSI protocols. Their research has been motivated by re-
cent efﬁciency improvements in OT extension. The gar-
bled Bloom ﬁlter protocol of [7] was the ﬁrst OT-based
PSI protocol and was improved in [22]. A novel OT-
based PSI protocol, which we denote OT-PSI protocol,
4The original description of the SCS circuit in [12] embedded input
keys into AND gates in the sort circuit to reduce communication. We
did not use this optimization in our implementation.
USENIX Association  
24th USENIX Security Symposium  519
5
was introduced in [22], combining OT and hashing to
achieve the best run-time among all analyzed PSI pro-
tocols. We next summarize the OT-PSI protocol of [22]
and give a detailed description in the full version [21].
The abstract idea of the OT-PSI protocol is to have
both parties hash their elements into bins using the same
hash function (Step 1, cf. §3.5.1) and compare the ele-
ments mapped to the same bin. The comparison is done
using OTs that generate random masks from the elements
(Step 2, cf. §3.5.2), such that the intersection of the ran-
dom masks corresponds to the intersection of the original
inputs (Step 3, cf. §3.5.3). Finally, the intersection of the
elements in the stash is computed (§3.5.4). We give the
overhead of the protocol in §3.5.5.
3.5.1 PSI via Hashing to Bins
In the ﬁrst step of the protocol, the parties map their el-
ements into their respective hash tables T1 and T2, con-
sisting of β = h(1 + ε)n2 bins (cf. §7). P2 uses Cuckoo
hashing with h hash functions (with h = 2), and obtains
a one-dimensional hash table T2. P1 hashes each item h
times (once for each hash function) using simple hash-
ing and obtains a two-dimensional hash table T1 (where
the ﬁrst dimension addresses the bin and the second di-
mension the elements in the bin). Each party then pads
all bins in its table to the maximum size using respective
dummy elements: P1 pads each bin to maxβ elements
using a dummy element d1 (where maxβ is computed us-
ing β and n1 as detailed in §7 to set the probability of
mapping more items to a bin to be negligible), while P2
ﬁlls each empty bin with dummy element d2 (different
than d1). The padding is performed to hide the number
of elements that were mapped to a speciﬁc bin, which
would leak information about the input.
3.5.2 Masking via OT
After the hashing, the parties use OT to generate an (cid:31)-bit
random mask for each element in their hash table.
Naively, for each bin, and for each item that P2 mapped
to the bin, the parties run a 1-out-of-2 OT for each bit
of this item. P2 is the receiver and its input to the OT
is the value of the corresponding bit in the single item
that it mapped to the bin. P1’s input is two random (cid:31)-bit
strings. After running these OTs for all σ bits of the item,
P1 sends to P2 the XOR of the strings corresponding to
the bits of P1’s item. Note that if P1’s item is equal to
that of P2 then the sent value is equal to the XOR of the
output strings that P2 received in the OTs. Otherwise the
values are different with high probability, which depends
on the length (cid:31) of the output strings.
This basic protocol was improved upon in [22] in sev-
eral ways:
• Recall that OT extension is more efﬁcient when ap-
plied to 1-out-of-N OT [17]. Therefore, the proto-
col uses µ-bit characters instead of a binary repre-
sentation. It splits the elements into t µ-bit charac-
ters, and uses t invocations of 1-out-of-N OT where
N = 2µ, instead of tµ invocations of 1-out-of-2 OT.
• In each bin the parties run OTs for all maxβ items
that P1 mapped to the bin, and to all characters in
these items. P2’s inputs are the same for all maxβ
OTs corresponding to the same character. Thus, the
parties could replace them with a single OT, where
the output string of the OT has maxβ longer size.
• Recall that random OT, where the protocol ran-
domly deﬁnes the inputs of P1, is more efﬁcient
than an OT where P1 chooses these inputs by itself.
For the purpose of PSI the protocol can use random
OT. It is also important to note that if P1 mapped
m < maxβ elements to a bin, it only needs to eval-
uate inputs for m random OTs in this bin and not
for all maxβ random OTs that are taking place. This
improves the overhead of the protocol.
3.5.3
Intersection
The parties compute the intersection of their elements us-
ing the random masks (XOR values) generated during
Step 2: P1 generates a set V as the masks for all of its
non-dummy elements. P1 then randomly permutes the
set V to hide information about the number of elements
in each bin, and sends V to P2. P2 computes the inter-
section X ∩Y by computing the plaintext intersection be-
tween V and the set of XOR values that it computed.
3.5.4
Including a Stash
The OT-based PSI protocol of [22] uses Cuckoo hashing
with a stash of size s. The intersection of P2’s elements
with P1’s elements is done by running the masking pro-
cedure of Step 2 for all s items in the stash, comparing
them with all n1 items in P1’s input. Finally, P1 sends the
masks it computed to P2 (in randomly permuted order)
which can then check the intersection as in Step 3.
3.5.5 Overhead
The overhead of this protocol is linear in the bit-length
of the input elements. Therefore, any reduction in the
bit-length of the inputs directly results in a similar im-
provement in the overhead.
For readers interested in the exact overhead of the pro-
tocol, we describe here the details of the overhead. In
1(cid:30)-OTβt
total, the parties have to evaluate random(cid:31)N
maxβ (cid:31)
+(cid:31)N
1(cid:30)-OTst
n1(cid:31) and send (h + s)n1 masks of (cid:31)-bit length,
where β = h(n2 + ε), N = 2µ, t = (cid:28)σ /µ(cid:27), (cid:31) = λ +
520  24th USENIX Security Symposium 
USENIX Association
6
log2(n1) + log2(n2), and s is the size of the stash. To
be exact, the server has to perform 2t(β + s) pseudo-
random generator evaluations during OT extension, (h +
s)n1t correlation-robust function evaluations to gener-
ate the random masks, and send (2 + s)n1(cid:31) bits. The
client has to perform 4t(β +s) pseudo-random generator
evaluations during OT extension, n2tmaxβ (cid:31)/o + sn1t(cid:31)/o
correlation-robust function evaluations to generate the
random masks, and send 2(β + s)tκ bits during OT ex-
tension, where o is the output length of the correlation-
robust function. Note especially that the client has to
evaluate the correlation-robust function O(nlog2 n) times
to generate the random bits which represent the masks of
the server’s elements. This cost can become prohibitive
for larger sets, as we will show in our evaluation in §8.
4 Permutation-based Hashing
The overhead of the OT-based PSI protocol of [22] and
of the circuit-based PSI protocols we describe in §5 de-
pends on the bit-lengths of the items that the parties map
to bins. The bit-length of the stored items can be re-
duced based on a permutation-based hashing technique
that was suggested in [1] for reducing the memory usage
of Cuckoo hashing. That construction was presented in
an algorithmic setting to improve memory usage. As far
as we know this is the ﬁrst time that it is used in secure
computation or in a cryptographic context.
The construction uses a Feistel-like structure. Let
x = xL|xR be the bit representation of an input item,
where |xL| = logβ , i.e.
is equal to the bit-length of an
index of an entry in the hash table. (We assume here that
the number of bins β in the hash table is a power of 2.
It was shown in [1] how to handle the general case.) Let
f () be a random function whose range is [0,β −1]. Then
item x is mapped to bin xL ⊕ f (xR). The value that is
stored in the bin is xR, which has a length that is shorter
by logβ bits than the length of the original item. This is a
great improvement, since the length of the stored data is
signiﬁcantly reduced, especially if |x| is not much greater
than logβ . As for the security, it can be shown based on
the results in [1] that if the function f is k-wise indepen-
dent, where k = polylogn, then the maximum load of a
bin is logn with high probability.
The structure of the mapping function ensures that if
two items x,x(cid:27) store the same value in the same bin then it
must hold that x = x(cid:27): if the two items are mapped to the
same bin, then xL ⊕ f (xR) = x(cid:27)L ⊕ f (x(cid:27)R). Since the stored
values satisfy xR = x(cid:27)R it must also hold that xL = x(cid:27)L, and
therefore x = x(cid:27).
As a concrete example, assume that |x| = 32 and that
the table has β = 220 bins. Then the values that are stored
in each bin are only 12 bits long, instead of 32 bits in the
original scheme. Note also that the computation of the
bin location requires a single instantiation of f , which
can be implemented with a medium-size lookup table.
A comment about an alternative approach An al-
ternative, and more straightforward approach for reduc-
ing the bit-length could map x using a random permuta-
tion p() to a random |x|-bit string p(x). The ﬁrst logβ
bits of p(x) are used to deﬁne the bin to which x is
mapped, and the value stored in that bin holds the re-
maining |x|− logβ bits of p(x). This construction, too,
has a shorter length for the values that are stored in the
bins, but it suffers from two drawbacks: From a perfor-
mance perspective, this construction requires the usage
of a random permutation on |x| bits, which is harder to
compute than a random function. From a theoretical per-
spective, it is impossible to have efﬁcient constructions
of k-wise independent permutations, and therefore we
only know how to prove the logn maximum load of the
bins under the stronger assumption that the permutation
is random.
5 Circuit-Phasing