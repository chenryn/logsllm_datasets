(cid:3)
[x,y]
ζ([x, y], u, v, i)
We can calculate ζ([x, y], u, v, i) easily as follows:
ζ([x, y], u, v, i) =
⎧
⎪⎪⎪⎪⎪⎨
⎪⎪⎪⎪⎪⎩
((cid:2)
((cid:2)
((cid:2)
0
N
N
Prλ([S1,S2])
j=0 α(u−1,v,j)aj,i bi([x,σ]))β(u,v,i)
j=0 α(u,v−1,j)aj,i bi([σ,y]))β(u,v,i)
j=0 α(u−1,v−1,j)aj,i bi([x,y]))β(u,v,i)
Prλ([S1,S2])
N
Prλ([S1,S2])
if x = s1,u ∧ y = σ
if x = σ ∧ y = s2,v
if x = s1,u ∧ y = s2,v
otherwise
Let the random variable Xi,[x,y] be the number of times that state qi is visited
when qi emits observable symbol [x, y], when λ generates [S1, S2]. For the same
reason as explained in Section 4.3,
E(Xi,[x,y]) =
⎧
⎪⎨
⎪⎩
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
l1
u=1
l1
u=0
l1
u=1
l2
v=0 ζ([x, y], u, v, i)
l2
v=1 ζ([x, y], u, v, i)
l2
v=1 ζ([x, y], u, v, i)
if x (cid:6)= σ ∧ y = σ
if x = σ ∧ y (cid:6)= σ
if x (cid:6)= σ ∧ y (cid:6)= σ
and the bi parameters of λ can be updated as
(cid:18)
(cid:17)
bi([x, y]) ←
wk E(X
(k)
i,[x,y])
/
M(cid:3)
k=1
(cid:18)
wk E(X
(k)
i
)
(cid:17)
M(cid:3)
k=1
38
D. Gao, M.K. Reiter, and D. Song
B Estimating the Best Mimicry Attack
In this section we show how to estimate the best mimicry attack given an HMM
λ. Suppose that the attacker has found a vulnerability in process 2, and wants
to use that vulnerability to exploit the process. Let S2 denote the system call
sequence that constitutes the attacker’s system calls (e.g., S2 = (cid:2)open, write(cid:3)).
Let ˆS2 be an extended sequence of S2, i.e., ˆS2 is obtained by inserting arbi-
trarily many system calls into S2 at any locations. When the anomaly detector
utilizes HMM-based behavioral distance, a mimicry attack is some ˆS2 that in-
duces a large Prλ([S1, ˆS2]), where S1 is the sequence of system calls induced
by the attack request at process 1 (not compromised). We assume that S1 is
ﬁxed (vs. being chosen by the attacker), which is typical since for many appli-
cations an attack request against process 2 induces an error on process 1 (e.g.,
a page-not-found error). If the attacker can induce several possible sequences
at process 1, then this analysis would need to be repeated with the various
alternatives.
For a ﬁxed pair of system call sequences S1 and ˆS2, let ˆPrλ([S1, ˆS2]) denote
the probability of the most probable execution of λ that generates [S1, ˆS2]. Note
that ˆPrλ([S1, ˆS2]) t1≥0
Statet1 = qi ∧
Statet2 = qj ∧
Out>t1∧t1∧t1∧t1∧ v. Intuitively, the danger is HMM executions that, in the course of emitting
v
arbitrary system calls before reaching the next attack system call in S2, in fact
insert attack system calls from S2 as these “arbitrary” system calls. It is for
this reason that in calculating δ(u, v, i) inductively, we need to exclude HMM
executions that output elements of S2 prematurely, hence the arguments to ˆai,j
and ˆbi. Given this, δ(u, v, i) can be solved inductively as follows.
Base cases:
δ(0, 0, i) =
(cid:11)
1
0
if i = 0
otherwise
δ(u, v, 0) =
(cid:11)
1
0
if u = v = 0
otherwise
Induction:
δ(u, 0, i) = max
j∈[0,N]
δ(0, v, i) = max
j∈[0,N]
δ(u, v, i) = max
j∈[0,N]
δ(u, v, i) = max
j∈[0,N]
(cid:7)(cid:28)
δ(u − 1, 0, j)ˆaj,i(s2,1)ˆbi(s1,u, s2,1)
({δ(0, v − 1, j)ˆaj,i(s2,v)bi([σ, s2,v])})
(cid:29)(cid:8)
for u > 0,
i > 0
for v > 0,
i > 0
⎞
⎛
⎜
⎝
⎛
⎜
⎝
(cid:28)
(cid:29)∪
δ(u − 1, v, j)ˆaj,i(s2,v+1)ˆbi(s1,u, s2,v+1)
{δ(u, v − 1, j)ˆaj,i(s2,v)bi([σ, s2,v])} ∪
{δ(u − 1, v − 1, j)ˆaj,i(s2,v)bi([s1,u, s2,v])}
(cid:29)∪
δ(u − 1, v, j)ˆaj,i(⊥)ˆbi(s1,u,⊥)
{δ(u, v − 1, j)ˆaj,i(s2,v)bi([σ, s2,v])} ∪
{δ(u − 1, v − 1, j)ˆaj,i(s2,v)bi([s1,u, s2,v])}
(cid:28)
⎟
⎠ for
⎞
⎟
⎠ for
u, v > 0,
v  0
u > 0,
v = l2,
i > 0
Then, ˆPrλ([S1, ˆS2]) of the estimated-best mimicry attack given S1, S2 and λ is
({δ(l1, l2, i)ˆai,N+1(⊥)})
max
i∈[1,N]
The above inductive algorithm is eﬃcient in calculating ˆPrλ([S1, ˆS2]). More-
over, by recording the most probable ˆS2 (i.e., preﬁx of the eventual, estimated-
best mimicry) for each step of the induction, we can eﬃciently obtain the
estimated-best mimicry attack in the sense we have described.
An interesting question is whether this algorithm can be extended to ﬁnd the
(cid:4)(u, v, i) needs to be
“real” best mimicry attack. To do so, the corresponding δ
deﬁned as the “highest sum of probabilities of all executions” for (u, v, i). How-
ever, in assembling the most probable mimicry as discussed above, do we record
(cid:4)(u, v, i) for all possible ˆS2’s? Unfortunately,
(cid:4)(u, v, i) for one particular ˆS2, or δ
δ
(cid:4)() of larger indices, we need
the latter is required, because when calculating δ
(cid:4)() of lower indices for diﬀerent ˆS2’s. Since for each (u, v, i) we
the results of δ
(cid:4)(u, v, i) for all possible ˆS2’s, this algorithm requires exponen-
need to record δ
tial computation time and memory in the worst case in the length of the best
mimicry. As such, we presently settle for the “estimated-best” mimicry attack,
which showed how to compute eﬃciently above, and leave ﬁnding the absolute
best mimicry attack to future work.