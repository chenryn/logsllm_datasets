# Title: Virtual U: Defeating Face Liveness Detection by Building Virtual Models from Your Public Photos

## Authors
Yi Xu, True Price, Jan-Michael Frahm, and Fabian Monrose  
Department of Computer Science, University of North Carolina at Chapel Hill  
{yix, jtprice, jmf, fabian}@cs.unc.edu

## Abstract
In this paper, we present a novel method to bypass modern face authentication systems. By leveraging a few publicly available photos of the target user, we demonstrate how to create realistic, textured 3D facial models that can undermine the security of widely used face authentication solutions. Our approach utilizes virtual reality (VR) systems, incorporating the ability to perform facial animations (e.g., raising an eyebrow or smiling) to deceive liveness detectors. The synthetic face is displayed on a VR device screen, and as the device moves, the 3D face adjusts accordingly, mimicking the depth and motion cues expected of a real human face.

We argue that such VR-based spoofing attacks represent a fundamentally new class of threats, highlighting a significant vulnerability in camera-based authentication systems. Unless these systems incorporate additional verifiable data, they remain susceptible to attacks via virtual realism. To demonstrate the practicality of this threat, we conduct extensive experiments using an end-to-end implementation of our approach, showing how it undermines the security of several face authentication solutions, including those with both motion-based and liveness detectors.

## 1. Introduction
Over the past few years, face authentication systems have become increasingly popular as enhanced security features in mobile devices and desktop computers. As computer vision algorithms have matured, many application designers and specialist vendors have started offering solutions with varying degrees of security and usability. Major players like Apple and Google are also entering the market, having acquired several facial recognition software companies. Gartner research estimates that the overall market for face recognition technologies will grow to over $6.5 billion by 2018, up from roughly $2 billion today [13].

Improving the accuracy of face recognition remains an active area of research. For example, Google’s FaceNet system achieved near-perfect accuracy on the Labeled Faces in the Wild dataset [47]. Recent advances in deep learning algorithms [38, 53] also show promise in strengthening the robustness of face identification and authentication techniques. State-of-the-art face identification systems now outperform their human counterparts [36], driving the increased use of face recognition systems.

However, despite the high accuracy of modern face recognition technologies, their application in face authentication systems has left much to be desired. At the Black Hat security conference in 2009, Duc and Minh [10] demonstrated the weaknesses of popular face authentication systems from vendors like Lenovo, Asus, and Toshiba. They were able to bypass face-locked computers simply by presenting the software with photographs and fake pictures of faces. This event led to the integration of more robust face authentication protocols, such as Android OS requiring users to blink during authentication to counter still-image spoofing attacks. Unfortunately, even this approach was easily bypassed by alternating images of the user with eyes open and closed [2].

Three types of spoofing attacks have been used in the past: still-image-based, video-based, and 3D-mask-based. Still-image-based attacks present one or more still images of the user to the authentication camera. Video-based attacks use pre-recorded videos of the victim's moving face. 3D-mask-based attacks, explored by Erdogmus and Marcel [11], use 3D-printed facial masks.

To counter these attacks, system designers have incorporated defensive techniques, such as well-designed liveness detection schemes. Most modern systems now require more active participation, often asking the user to rotate their head or raise an eyebrow during login. Motion-based techniques, which check for 3D behavior, are also being researched. For example, Li et al. [34] proposed using liveness detection to thwart video-based attacks by checking the consistency of recorded data with inertial sensors.

In this paper, we show that it is possible to undermine modern face authentication systems using a VR-based attack. We also demonstrate that an accurate facial model can be built using only a few publicly accessible photos. We address two main challenges: the limited number of photos and the unknown illumination settings, poses, and expressions. We leverage robust 3D face reconstruction methods from computer vision and adapt them to our needs. Once a credible synthetic model is obtained, we use entry-level VR displays to defeat state-of-the-art liveness detection.

The rest of the paper is organized as follows: Section 2 provides background and related work. Section 3 outlines the steps of our VR-based attack. Section 4 evaluates the performance of our method on five commercial face authentication systems and a proposed state-of-the-art liveness detection system. Section 5 suggests mitigation strategies, and Section 6 discusses the implications of our successful attack strategy.

## 2. Background and Related Work
### 2.1 Modern Defenses Against Spoofing
New types of spoofing attacks have led to the development of advanced methods for countering them. The most popular liveness detection techniques can be categorized as texture-based, motion-based, or liveness assessment approaches.

**Texture-based approaches** [11, 25, 37, 40, 54, 60] identify spoofing attacks based on the assumption that a spoofed face will have a different texture from a real face. These techniques rely on perceived limitations of image displays and printing techniques. However, with high-resolution displays, the difference between a spoofed image and a living face is hard to notice. Additionally, these techniques often require training on every possible spoofing material, which is impractical for real systems.

**Motion-based approaches** [3, 27, 29, 32, 57] detect spoofing attacks by inferring 3D shape from the user's head motion. Techniques such as optical flow and focal-length analysis are typically used. The basic assumption is that genuine faces usually contain sufficient 3D information, whereas fake faces (photos) are planar in depth. For example, Li et al. [34] check the consistency of movement between the mobile device's internal motion sensors and the observed change in head pose.

**Liveness assessment techniques** [19, 30, 31, 49] require the user to perform certain tasks during authentication, such as eye movement, lip movement, and blinking. These gestures help to defeat contemporary spoofing attacks.

**Take-away:** Real-world systems often combine liveness detection schemes with motion-based approaches to provide better security than either can provide alone. This combination is widely adopted in many commercial systems, including those offered by KeyLemon, Rohos, and Biomids. For the remainder of this paper, we consider this combination as the state of the art in defenses against spoofing attacks for face authentication systems.

### 2.2 Online Photos and Face Authentication
Personal photos from online social networks can compromise privacy. Major social network sites advise users to set privacy settings for uploaded images, but many photos are often accessible to the public or set to 'friend-only' viewing [14, 26, 35]. Users do not have direct control over the accessibility of photos posted by others, although they can remove the association of such photos with their account.

Facebook’s social authentication (SA) system [15] is an extension of CAPTCHAs that seeks to bolster identity verification by requiring the user to identify photos of their friends. While this method requires more specific knowledge, Polakis et al. [42] demonstrated that facial recognition could be applied to a user’s public photos to solve 22% of SA tests automatically.

Given that one’s online photo presence is not entirely controlled by the user, many avenues exist for an attacker to uncover the facial appearance of a user, even when the user makes their own personal photos private. Work by Ilia et al. [17] has explored the automatic privatization of user data across a social network, using face detection and photo tags to selectively blur the face of a user. However, it is unlikely that an individual’s appearance can ever be completely obfuscated from attackers across all social media sites and image stores on the Internet.

The availability of online user photos is a boon for adversaries. Li et al. [33] proposed an attack that defeated commonly used face authentication systems by using photos of the target user gathered from online social networks. They reported that 77% of the users in their test set were vulnerable to their proposed attack. However, their work targeted face recognition systems without liveness detection, which modern systems now incorporate to thwart still-image spoofing attacks.

### 2.3 3D Facial Reconstruction
Constructing a 3D facial model from a small number of personal photos involves powerful techniques from the field of computer vision. Various reconstruction approaches make this task less daunting, and many techniques have been introduced for facial reconstruction from single images [4, 23, 24, 43], videos [20, 48, 51], and combinations of both [52]. For pedagogical reasons, we briefly review concepts that help the reader better understand our approach.