title:Virtual U: Defeating Face Liveness Detection by Building Virtual
Models from Your Public Photos
author:Yi Xu and
True Price and
Jan-Michael Frahm and
Fabian Monrose
Virtual U: Defeating Face Liveness Detection by 
Building Virtual Models from Your Public Photos
Yi Xu, True Price, Jan-Michael Frahm, and Fabian Monrose,  
The University of North Carolina at Chapel Hill
 https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/xu
This paper is included in the Proceedings of the 25th USENIX Security SymposiumAugust 10–12, 2016 • Austin, TXISBN 978-1-931971-32-4Open access to the Proceedings of the 25th USENIX Security Symposium is sponsored by USENIX Virtual U: Defeating Face Liveness Detection by Building Virtual Models
From Your Public Photos
Yi Xu, True Price, Jan-Michael Frahm, Fabian Monrose
Department of Computer Science, University of North Carolina at Chapel Hill
{yix, jtprice, jmf, fabian}@cs.unc.edu
Abstract
In this paper, we introduce a novel approach to bypass
modern face authentication systems. More specifically,
by leveraging a handful of pictures of the target user
taken from social media, we show how to create realistic,
textured, 3D facial models that undermine the security
of widely used face authentication solutions. Our frame-
work makes use of virtual reality (VR) systems, incor-
porating along the way the ability to perform animations
(e.g., raising an eyebrow or smiling) of the facial model,
in order to trick liveness detectors into believing that the
3D model is a real human face. The synthetic face of the
user is displayed on the screen of the VR device, and as
the device rotates and translates in the real world, the 3D
face moves accordingly. To an observing face authenti-
cation system, the depth and motion cues of the display
match what would be expected for a human face.
We argue that such VR-based spoofing attacks con-
stitute a fundamentally new class of attacks that point
to a serious weaknesses in camera-based authentication
systems: Unless they incorporate other sources of verifi-
able data, systems relying on color image data and cam-
era motion are prone to attacks via virtual realism. To
demonstrate the practical nature of this threat, we con-
duct thorough experiments using an end-to-end imple-
mentation of our approach and show how it undermines
the security of several face authentication solutions that
include both motion-based and liveness detectors.
1
Introduction
Over the past few years, face authentication systems have
become increasingly popular as an enhanced security
feature in both mobile devices and desktop computers.
As the underlying computer vision algorithms have ma-
tured, many application designers and nascent specialist
vendors have jumped in and started to offer solutions for
mobile devices with varying degrees of security and us-
ability. Other more well-known players, like Apple and
Google, are posed to enter the market with their own
solutions, having already acquired several facial recog-
nition software companies1. While the market is seg-
mented based on the type of technology offered (e.g.,
2D facial recognition, 3D recognition, and facial analyt-
ics/face biometric authentication), Gartner research esti-
mates that the overall market will grow to over $6.5 bil-
lion in 2018 (compared to roughly $2 billion today) [13].
With this push to market, improving the accuracy of
face recognition technologies remains an active area of
research in academia and industry. Google’s FaceNet
system, which achieved near-perfect accuracy on the La-
beled Faces in the Wild dataset [47], exemplifies one
such effort. Additionally, recent advances with deep
learning algorithms [38, 53] show much promise in
strengthening the robustness of the face identification
and authentication techniques used today. Indeed, state-
of-the-art face identification systems can now outper-
form their human counterparts [36], and this high accu-
racy is one of the driving factors behind the increased use
of face recognition systems.
However, even given the high accuracy of modern face
recognition technologies, their application in face au-
thentication systems has left much to be desired. For
instance, at the Black Hat security conference in 2009,
Duc and Minh [10] demonstrated the weaknesses of pop-
ular face authentication systems from commodity ven-
dors like Lenovo, Asus, and Toshiba. Amusingly, Duc
and Minh [10] were able to reliably bypass face-locked
computers simply by presenting the software with pho-
tographs and fake pictures of faces. Essentially, the secu-
rity of these systems rested solely on the problem of face
detection, rather than face authentication. This widely
publicized event led to subsequent integration of more
robust face authentication protocols. One prominent ex-
ample is Android OS, which augmented its face authen-
1See, for example, “Apple Acquires Face Recognition, Expression
Analysis firm, Emotient”, TechTimes, Jan, 2016; “Google Acquires
Facial Recognition Software Company PittPar,” WSJ, 2011.
USENIX Association  
25th USENIX Security Symposium  497
tication approach in 2012 to require users to blink while
authenticating (i.e., as a countermeasure to still-image
spoofing attacks). Unfortunately, this approach was also
shown to provide little protection, and can be easily by-
passed by presenting the system with two alternating im-
ages — one with the user’s eyes open, and one with her
eyes closed.2 These attacks underscore the fact that face
authentication systems require robust security features
beyond mere recognition in order to foil spoofing attacks.
Loosely speaking, three types of such spoofing attacks
have been used in the past, to varying degrees of success:
(i) still-image-based spoofing, (ii) video-based spoofing,
and (iii) 3D-mask-based spoofing. As the name suggests,
still-image-based spoofing attacks present one or more
still images of the user to the authentication camera; each
image is either printed on paper or shown with a digi-
tized display. Video-based spoofing, on the other hand,
presents a pre-recorded video of the victim’s moving face
in an attempt to trick the system into falsely recognizing
motion as an indication of liveness. The 3D-mask-based
approach, wherein 3D-printed facial masks are used, was
recently explored by Erdogmus and Marcel [11].
As is the typical case in the field of computer se-
curity, the cleverness of skilled, motivated adversaries
drove system designers to incorporate defensive tech-
niques in the biometric solutions they develop. This
cat-and-mouse game continues to play out in the realm
of face authentication systems, and the current recom-
mendation calls for the use of well-designed face live-
ness detection schemes (that attempt to distinguish a real
user from a spoofed one). Indeed, most modern systems
now require more active participation compared to sim-
ple blink detection, often asking the user to rotate her
head or raise an eyebrow during login. Motion-based
techniques that check, for example, that the input cap-
tured during login exhibits sufficient 3D behavior, are
also an active area of research in face authentication.
One such example is the recent work of Li et al. [34]
that appeared in CCS’2015.
In that work, the use of
liveness detection was proposed as a solution to thwart-
ing video-based attacks by checking the consistency of
the recorded data with inertial sensors. Such a detection
scheme relies on the fact that as a camera moves relative
to a user’s stationary head, the facial features it detects
will also move in a predictable way. Thus, a 2D video
of the victim would have to be captured under the exact
same camera motion in order to fool the system.
As mentioned in [34], 3D-printed facial reconstruc-
tions offer one option for defeating motion-based live-
ness detection schemes. In our view, a more realizable
approach is to present the system with a 3D facial mesh
in a virtual reality (VR) environment. Here, the motion
2https://www.youtube.com/watch?v=zYxphDK6s3I
of the authenticating camera is tracked, and the VR sys-
tem internally rotates and translates the mesh to match.
In this fashion, the camera observes exactly the same
movement of facial features as it would for a real face,
fulfilling the requirements for liveness detection. Such
an attack defeats color-image- and motion-based face au-
thentication on a fundamental level because, with suffi-
cient effort, a VR system can display an environment that
is essentially indistinguishable from real-world input.
In this paper, we show that it is possible to undermine
modern face authentication systems using one such at-
tack. Moreover, we show that an accurate facial model
can be built using only a handful of publicly accessible
photos — collected, for example, from social network
websites — of the victim. From a pragmatic point of
view, we are confronted with two main challenges: i) the
number of photos of the target may be limited, and ii) for
each available photo, the illumination setting is unknown
and the user’s pose and expression are not constrained.
To overcome these challenges, we leverage robust, pub-
licly available 3D face reconstruction methods from the
field of computer vision, and adapt these techniques to fit
our needs. Once a credible synthetic model of a user is
obtained, we then employ entry-level virtual reality dis-
plays to defeat the state of the art in liveness detection.
The rest of the paper is laid out as follows: §2 provides
background and related work related to face authentica-
tion, exploitation of users’ online photos, and 3D facial
reconstruction. §3 outlines the steps we take to perform
our VR-based attack. In §4, we evaluate the performance
of our method on 5 commercial face authentication sys-
tems and, additionally, on a proposed state-of-the-art sys-
tem for liveness detection. We suggest steps that could
be taken to mitigate our attack in §5, and we address the
implications of our successful attack strategy in §6.
2 Background and Related Work
Before delving into the details of our approach, we first
present pertinent background information needed to un-
derstanding the remainder of this paper.
First, we note that given the three prominent classes of
spoofing attacks mentioned earlier, it should be clear that
while still-image-based attacks are the easiest to perform,
they can be easily countered by detecting the 3D struc-
ture of the face. Video-based spoofing is more difficult to
accomplish because facial videos of the target user may
be harder to come by; moreover, such attacks can also
be successfully defeated, for example, using the recently
suggested techniques of Li et al. [34] (which we discuss
in more detail later). 3D-mask-based approaches, on the
other hand, are harder to counter. That said, building
a 3D mask is arguably more time-consuming and also
requires specialized equipment. Nevertheless, because
498  25th USENIX Security Symposium 
USENIX Association
of the threat this attack vector poses, much research has
gone into detecting the textures of 3D masks [11].
2.1 Modern Defenses Against Spoofing
Just as new types of spoofing attacks have been intro-
duced to fool face authentication systems, so too have
more advanced methods for countering these attacks
been developed. Nowadays, the most popular liveness
detection techniques can be categorized as either texture-
based approaches, motion-based approaches, or liveness
assessment approaches. We discuss each in turn.
Texture-based approaches [11, 25, 37, 40, 54, 60] at-
tempt to identify spoofing attacks based on the assump-
tion that a spoofed face will have a distinctly different
texture from a real face. Specifically, they assume that
due to properties of its generation, a spoofed face (irre-
spective of whether it is printed on paper, shown on a
display, or made as a 3D mask) will be different from
a real face in terms of shape, detail, micro-textures, res-
olution, blurring, gamma correction, and shading. That
is, these techniques rely on perceived limitations of im-
age displays and printing techniques. However, with the
advent of high-resolution displays (e.g., 5K), the differ-
ence in visual quality between a spoofed image and a
living face is hard to notice. Another limitation is that
these techniques often require training on every possible
spoofing material, which is not practical for real systems.
Motion-based approaches [3, 27, 29, 32, 57] detect
spoofing attacks by using motion of the user’s head to
infer 3D shape. Techniques such as optical flow and
focal-length analysis are typically used. The basic as-
sumption is that structures recovered from genuine faces
usually contain sufficient 3D information, whereas struc-
tures from fake faces (photos) are usually planar in depth.
For instance, the approach of Li et al. [34] checks the
consistency of movement between the mobile device’s
internal motion sensors and the observed change in head
pose computed from the recorded video taken while the
claimant attempts to authenticate herself to the device.
Such 3D reasoning provides a formidable defense against
both still-image and video-based attacks.
Lastly, liveness assessment techniques [19, 30, 31, 49]
require the user to perform certain tasks during the au-
thentication stage. For the systems we evaluated, the
user is typically asked to follow certain guidelines dur-
ing registration, and to perform a random series of ac-
tions (e.g., eye movement, lip movement, and blinking)
at login. The requested gestures help to defeat contem-
porary spoofing attacks.
Take-away: For real-world systems,
liveness detec-
tion schemes are often combined with motion-based ap-
proaches to provide better security protection than either
can provide on their own. With these ensemble tech-
niques, traditional spoofing attacks can be reliably de-
tected. For that reason, the combination of motion-based
systems and liveness detectors has gained traction and
is now widely adopted in many commercial systems, in-
cluding popular face authentication systems offered by
companies like KeyLemon, Rohos, and Biomids. For the
remainder of this paper, we consider this combination as
the state of the art in defenses against spoofing attacks
for face authentication systems.
2.2 Online Photos and Face Authentication
It should come as no surprise that personal photos from
online social networks can compromise privacy. Major
social network sites advise users to set privacy settings
for the images they upload, but the vast majority of these
photos are often accessible to the public or set to ‘friend-
only’ viewing’ [14, 26, 35]. Users also do not have di-
rect control over the accessibility of photos of themselves
posted by other users, although they can remove (‘un-
tag’) the association of such photos with their account.
A notable use of social network photos for online se-
curity is Facebook’s social authentication (SA) system
[15], an extension of CAPTCHAs that seeks to bolster
identity verification by requiring the user to identify pho-
tos of their friends. While this method does require more
specific knowledge than general CAPTCHAs, Polakis
et al. [42] demonstrated that facial recognition could be
applied to a user’s public photos to discover their social
relationships and solve 22% of SA tests automatically.
Given that one’s online photo presence is not entirely
controlled by the user alone — but by their collective
social circles — many avenues exist for an attacker to
uncover the facial appearance of a user, even when the
user makes private their own personal photos. In an ef-
fort to curb such easy access, work by Ilia et al. [17] has
explored the automatic privatization of user data across
a social network. This method uses face detection and
photo tags to selectively blur the face of a user when the
viewing party does not have permission to see the photo.
In the future, such an approach may help decrease the
public accessibility of users’ personal photos, but it is
unlikely that an individual’s appearance can ever be com-
pletely obfuscated from attackers across all social media
sites and image stores on the Internet.
Clearly, the availability of online user photos is a boon
for an adversary tasked with the challenge of undermin-
ing face authentication systems. The most germane on
this front is the work of Li et al. [33]. There, the au-
thors proposed an attack that defeated commonly used
face authentication systems by using photos of the target
user gathered from online social networks. Li et al. [33]
reported that 77% of the users in their test set were vul-
USENIX Association  
25th USENIX Security Symposium  499
nerable to their proposed attack. However, their work
is targeted at face recognition systems that do not in-
corporate face liveness detection. As noted in §2, in
modern face authentication software, sophisticated live-
ness detection approaches are already in use, and these
techniques thwart still-image spoofing attacks of the kind
performed by Li et al. [33].
3D Facial Reconstruction
2.3
Constructing a 3D facial model from a small number
of personal photos involves the application of powerful
techniques from the field of computer vision. Fortu-
nately, there exists a variety of reconstruction approaches
that make this task less daunting than it may seem on first
blush, and many techniques have been introduced for fa-
cial reconstruction from single images [4, 23, 24, 43],
videos [20, 48, 51], and combinations of both [52]. For
pedagogical reasons, we briefly review concepts that
help the reader better understand our approach.