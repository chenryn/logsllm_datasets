# Runtime Overhead vs. Function Entropy

**Figure 4: Function Entropy vs. Runtime Overhead (SPECspeed 2017)**
- **Runtime Overhead (%)**: The figure illustrates the relationship between function entropy and runtime overhead for various randomization techniques, using the SPECspeed 2017 benchmark suite.

## 8.1 Functionality Evaluation

### Low-Level Libraries
- We evaluated the functionality of glibc (libc-2.27.so), the loader (ld-2.27.so), and libpthread (libpthread-2.27.so) after randomizing these libraries.
- These libraries contain approximately 2.3 MB of low-level code, including a significant amount of hand-written assembly.
- The system was rebooted with the randomized versions of these libraries, and we verified that the system started up correctly.
- A variety of command-line and graphical applications were tested to ensure they functioned as expected.
- These tests were repeated for all randomization techniques, ensuring that every application used the SBR-randomized versions of these libraries, but the application code itself was not randomized in this test.

### Commonly Used Applications
- SBR was tested with a range of common applications, as detailed in Table 3.
- The table includes the application name, executable size, number and aggregate sizes of libraries used, and the specific tests performed to check functionality.
- In total, 197 MB of binaries across 202 shared libraries were transformed, as shown in Table 9 on Page 14.

### SPECspeed 2017
- This benchmark consists of 19 programs written in C, C++, and Fortran, compiled using gcc, llvm, and gfortran.
- The total size of these binaries is 420 MB.
- We verified that the randomization techniques discussed in Sections 2.3 and 3 preserve the functionality of all binaries, ensuring they produce the correct results.
- Two programs, omnetpp and leela, use exceptions and continued to work correctly with our reduced metadata.

## 8.2 Performance vs. Security Trade-off

- **Figure 4** plots the function entropy against the runtime overhead for various randomization techniques.
- Deterministic techniques like ZJR, BBR, and PHR are represented as single points on the graph.
- LLR(k) and PHR + LLR(k) provide tunable parameters, allowing different entropies at varying performance costs.
- ZJR has a low 1% overhead but offers only one-sixth the entropy of LLR(16), making it vulnerable in our threat model.
- BBR provides high entropy but at a steep 14% overhead.
- LLR can match BBR's entropy at half the overhead or be tuned to match BBR's performance while providing 60% more entropy.
- LLR(16) offers a good balance of per-function entropy (140 bits average) and low overhead (2.26%) across the SPEC suite.
- PHR has similar entropy to LLR(16) but with a 70% higher overhead.
- For security-critical applications, PHR + LLR(16) is an excellent choice, offering deterministic protection of code pointers and additional assurance, with a 5% overhead.

## 8.3 Function Entropy

- **ZJR**: Despite its low 1% overhead, ZJR's function entropy (FE) is very low at just 25 bits, making it vulnerable to indirect disclosure attacks.
- **BBR**: Provides the highest FE at 228 bits, but LLR and PHR + LLR can achieve a better combination of entropy and performance.
- **PHR**: Ensures leaked pointers do not reveal adjacent instruction locations, but in schemes that keep function bodies together, this is insufficient. PHR’s entropy of 147 bits is comparable to LLR(k).
- **PHR + LLR(16)**: Offers a 40% improvement in entropy over PHR at a 33% higher overhead, providing the best security and performance balance when overheads ≥ 5% are acceptable.

## 8.4 Full & Reduced Unwind Block Entropy (FUBE & RUBE)

- **FUBE**: Captures the difficulty of attacks when all EH-metadata generated by the compiler is included. FUBE values are very low, indicating that full unwinding information in the binary is not secure.
- **RUBE**: Measures the difficulty of attacks after applying metadata reduction and optimization techniques. RUBE values show a dramatic improvement over FUBE, reducing the number of unwinding blocks by 85%, resulting in about 2 unwinding blocks per function on average.
- **Figure 8** (Page 14) shows that LLR(k) can be tuned to provide the same entropy as BBR at half the cost or twice the entropy at the same cost. PHR + LLR(k) offers the best security and performance balance for overheads ≥ 5%.

## 8.5 Runtime Overhead

- **Table 7** compares the runtime overhead of LLR(k) with previous code randomization techniques.
- Each SPECspeed binary was randomized with 5 distinct random seeds, and each variant was run 5 times.
- The average of the medians for each variant was taken as the runtime of a randomized binary.
- Runtime overhead is attributed to additional jump instructions and the negative effects of randomization.

This structured and detailed approach ensures clarity and coherence in the presentation of the experimental evaluation and results.