r
t
n
E
0
5
10
15
Runtime Overhead (%)
Figure 4: Function Entropy vs Runtime Overhead (SPEC-
speed 2017)
collection of frequently used applications and the SPECspeed 2017
benchmark suite. In-depth evaluation of performance and security
of ZJR, BBR, PHR, LLR(k) and PHR +LLR(k) were based on the SPEC
suite.7 For measuring security, we used FE, FUBE and RUBE.
8.1 Functionality Evaluation
Low-level Libraries. We randomized glibc (libc-2.27.so), the
loader (ld-2.27.so) and libpthread (libpthread-2.27.so). They
contain about 2.3MB of low-level code, with significant amount of
hand-written assembly. We replaced these standard libraries with
their randomized versions and rebooted the system, and verified that
the system started up properly. We used a variety of command-
line and graphical applications and verified that they worked as
expected. These tests were repeated for all randomization tech-
niques. Note that every application on the system was using SBR-
randomized versions of these libraries, but the application code was
not randomized in this test. Tests involving application code are
described below.
Commonly Used Applications. We have tested SBR with many
common applications shown in Table 3. The table shows the appli-
cation name, the size of the executable, the number and aggregate
sizes of libraries used by the executable, etc. It also describes the test
performed to check its functionality. Altogether, these tests required
the transformation of 197MB of binaries contained in 202 shared
libraries, as shown in Table 9 on Page 14.
SPECspeed 2017. This benchmark consists of 19 programs8 in 3
languages: C, C++ and Fortran. We compiled these programs using
gcc, llvm and gfortran. The total size of these binaries was 420MB.
We verified that the randomization techniques discussed in Sec. 2.3
and Sec. 3 preserve the functionality of all the resulting binaries, i.e.,
they continue to produce the correct results. Two of these programs,
omnetpp and leela, use exceptions, and they continued to work
correctly with our reduced metadata.
8 EXPERIMENTAL EVALUATION
Evaluation of SBR was carried out on a Ubuntu 18.04.3 system
equipped with an Intel Xeon Silver 4114 2.20GHz CPU and 384GB
RAM. Functionality and compatibility tests were performed on a
7We omitted FR and PB randomization techniques because they do not, by themselves,
address indirect disclosures; and OPHR because of its similarity to PHR.
8The benchmark contains 20 programs, but we found that one of them (cam4) always
exits with a segmentation fault. We have not been able to determine the cause, but
since the problem occurs with the base version, before any processing by SBR, we
excluded it in our experiments.
409ACSAC 2020, December 7–11, 2020, Austin, USA
Soumyakant Priyadarshan, Huan Nguyen, and R. Sekar
8.2 Performance vs Security Trade-off
Fig. 4 plots the entropy against the runtime overhead of various
randomization techniques. While this chart is based on function
entropy, a chart based on RUBE, which measures resistance against
EH-metadata-aware attacks, is very similar. (See Fig. 8 on Page 14.)
Deterministic techniques such as ZJR, BBR and PHR represent single
points in this graph. But since LLR(k) and PHR +LLR(k) provide a
tunable parameter k, we can obtain different entropies at different
performance costs.
From the chart, it is clear that neither ZJR nor BBR is an attractive
choice for deployment. ZJR sports a low 1% overhead, but its low
entropy, at about one-sixth of LLR(16)’s, makes it vulnerable in our
threat model. While BBR offers a high entropy, this comes at a steep
14% overhead. From the chart, we can see that LLR can match BBR’s
entropy at just half its overhead. Alternatively, LLR can be tuned to
match the performance of BBR while providing 60% more entropy.
LLR(16) provides a good combination of per-function entropy
(140 bits average) and low overhead (2.26%) across the SPEC suite.
PHR’s entropy is very close to LLR(16)’s, but it has a 70% higher
overhead than LLR(16).
Where security is a priority, PHR +LLR(16) is an excellent choice.
It deterministically protects all code pointers in data, and in addition,
offers the assurance of LLR(16) that each EH-metadata leak will
reveal the location of at most 16 other instructions. Its overhead is
not negligible, but 5% is acceptable in many settings.
8.3 Function Entropy
Although ZJR has very low overhead, its FE, shown in Table 5, is
way too low — just 25 bits. This makes it vulnerable to indirect
disclosure attacks.
BBR provides the highest FE of any randomization technique
discussed so far, at 228 bits. However, as discussed before, LLR as
well as PHR +LLR can achieve a better combination of entropy and
performance.
PHR ensures that leaked pointers, including function pointers
and return addresses, don’t reveal the locations of instructions
adjacent to the pointer. However, in a randomization scheme that
keeps function bodies together, this is not sufficient to prevent the
attacker from accessing other instructions in the same function.
Thus, the only protection comes in the form of entropy — making it
difficult to predict the instruction that the attacker is able to access.
PHR’s entropy of 147 bits is quite good (and comparable to LLR(k)).
PHR +LLR(16) offers a 40% improvement in entropy over PHR at a
33% higher overhead. From Fig. 4, it is easy to see that this technique
offers the best combination of security strength and performance
in contexts where overheads ≥ 5% are acceptable.
8.4 Full & Reduced Unwind Block Entropy
(FUBE & RUBE)
While FE has the benefit of familiarity, it is not very useful in our
threat model where the attacker can target EH-metadata and stack-
unwinding-compatibility. In Sec. 5, we developed two new metrics,
FUBE and RUBE, for this specific purpose. We use them to evaluate
BBR, PHR, LLR(k) and PHR +LLR(k) below.
FUBE.. This metric captures the difficulty of attacks when all
of the EH-metadata generated by the compiler is included in the
Program
perlbench
gcc
bwaves
mcf
cactuBSSN
lbm
omnetpp
wrf
xalancbmk
x264
pop2
deepsjeng
imagick
leela
nab
exchange2
fotonik3d
roms
xz
ZJR
BBR
PHR
LLR(16)
35
31
4
11
71
5
13
34
20
18
14
20
27
28
17
80
18
28
10
246
262
60
81
407
24
61
442
102
154
234
159
255
144
145
804
394
298
61
148
178
64
42
279
21
71
333
92
87
206
81
215
146
103
149
301
244
38
58
55
165
29
149
42
16
446
26
88
168
54
81
51
61
375
438
332
21
PHR +
LLR(16)
150
179
159
44
312
47
72
492
92
108
238
87
221
149
112
352
489
384
43
Mean
25
228
147
140
196
Table 5: Function Entropy on SPECspeed 2017
binary. As shown in Table 6, FUBE is very low across the board
for all randomization schemes. In other words, it is not feasible
to develop a secure randomization scheme if the full unwinding
information generated by the compiler is left in the binary.
RUBE.. This metric captures the difficulty of carrying out at-
tacks after the metadata reduction and optimization techniques
described in Sec. 4 have been applied. RUBE values in Table 6 show
a dramatic improvement over that of FUBE. In fact, they are about
half of the FE values shown in Table 5. This is because the tech-
niques of Sec. 4 were able to remove 85% of all the unwinding blocks
that were originally present. This translates to a 6.7x reduction in
the number of unwinding blocks. As a result, there are just under 2
unwinding blocks per function on average, as compared with 13
generated by the compiler. It can be seen from the entropy formulas
in Sec. 5 that the entropy increases roughly linearly with the size
s of the entity being randomized. Given that unwinding blocks,
which are the entities being randomized, are about half the size of
functions, it is understandable that RUBE is roughly half of FE.
Fig. 8 on Page 14 provides a way to compare different random-
ization techniques. It is qualitatively similar to Fig. 4 that is based
on FE. Thus, we can make the following observations: (a) LLR(k)
can be tuned to provide the same entropy as BBR at about half the
performance cost, or about 2x the entropy at the same cost, (b) PHR
+LLR(k) provides the best combination of security and performance
in contexts where a runtime overhead ≥ 5% is acceptable.
8.5 Runtime Overhead
Table 7 compares the runtime overhead of LLR(k) with previous
code randomization techniques. Each SPECspeed binary was ran-
domized with 5 distinct random seeds. Each randomized variant
was run 5 times, and the average of the medians for each variant
was taken as the runtime of a randomized binary.
Runtime overhead for a randomized executable can be attributed
to (i) additional jump instructions introduced and (ii) negative effect
410Practical Fine-Grained Binary Code Randomization
ACSAC 2020, December 7–11, 2020, Austin, USA
Program
Full Metadata
ZJR BBR PHR LLR(16)
perlbench
gcc
bwaves
mcf
cactuBSSN
lbm
omnetpp
wrf
xalancbmk
x264
pop2
deepsjeng
imagick
leela
nab
exchange2
fotonik3d
roms
xz
2
3
0
1
5
1
1
1
2
1
1
2
1
3
1
8
1
1
1
17
23
4
7
28
4
6
11
12
13
10
14
13
15
11
83
27
12
6
10
15
4
4
18
3
7
7
11
7
9
7
9
16
8
15
21
10
3
4
5
11
3
11
7
2
11
3
7
7
5
4
6
5
40
32
13
2
PHR +
LLR(16)