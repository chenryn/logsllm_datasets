+---------------------------------------------+    
|c____u_____X___u___X_________u___cXcc______u_|    
+---------------------------------------------+    
Rows marked c match customers pkey condition.    
Rows marked u match username condition.    
Rows marked X match both conditions.    
Bitmap scan from customers_pkey:    
+---------------------------------------------+    
|100000000001000000010000000000000111100000000| bitmap 1    
+---------------------------------------------+    
One bit per heap page, in the same order as the heap    
Bits 1 when condition matches, 0 if not    
Bitmap scan from ix_cust_username:    
+---------------------------------------------+    
|000001000001000100010000000001000010000000010| bitmap 2    
+---------------------------------------------+    
Once the bitmaps are created a bitwise AND is performed on them:    
+---------------------------------------------+    
|100000000001000000010000000000000111100000000| bitmap 1    
|000001000001000100010000000001000010000000010| bitmap 2    
 &&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&    
|000000000001000000010000000000000010000000000| Combined bitmap    
+-----------+-------+--------------+----------+    
            |       |              |    
            v       v              v    
Used to scan the heap only for matching pages:    
+---------------------------------------------+    
|___________X_______X______________X__________|    
+---------------------------------------------+    
The bitmap heap scan then seeks to the start of each page and reads the page:    
+---------------------------------------------+    
|___________X_______X______________X__________|    
+---------------------------------------------+    
seek------->^seek-->^seek--------->^    
            |       |              |    
            ------------------------    
            only these pages read    
and each read page is then re-checked against the condition since there can be >1 row per page and not all necessarily match the condition.    
```  
编排的工作量和索引类似，也会涉及到块的调整，因此也会导致写延时，为了降低写延迟，同样需要类似的优化，延迟编排、分片等。  
### 延迟编排  
为了达到最大的写入吞吐，写入时数据为无序状态。  
### 分片优化  
对写入的数据，按每列的存储分片进行整理，例如每个存储分片32MB。  
整理的目标是使得这32MB的分片的字段按顺序存储（对于不同的类型，整理规则可调整，例如按顺序，按GEOHASH值顺序，按聚集等）。  
整理好之后，生成每个分片内的元信息，例如每8K一个单位，保存这个单位的数据边界（最大最小值），数据的平均值，COUNT，方差等。  
在搜索数据时，由于每个分片存储了每8K的边界信息，所以根据列条件，可以快速的过滤不满足条件的8K单位（不需要扫描它们）。从而达到和索引一样的效果。  
（分片元信息类似BRIN索引：[《PostgreSQL 聚集存储 与 BRIN索引 - 高并发行为、轨迹类大吞吐数据查询场景解说》](../201702/20170219_01.md)  ）。  
### 分片合并归整  
直到前面的优化手段，只是做到了分片内的数据归整，分片和分片直接，是有可能存在数据的交集的。  
例如：  
第一个分片包含cola : 1-1000的数据，第二个分片可能包含cola : 2-2000的数据，这两个分片是有交集的，如果搜索的数据是落在交集中的 ，那么这两个分片都需要扫描。  
分片合并归整的目的就是要尽量的减少分片之间的数据边界模糊问题，让分片的边界更加的清晰。  
例如对于分区表，有32GB数据，每个分片32MB，那么当数据写完后，可以对整个分区做归整，使得每个分片的边界清晰。  
![pic](20170615_01_pic_001.jpg)  
这个操作类似于PostgreSQL的cluster功能。   
## 三、行列混合编排  
列存储非常适合对列进行统计分析，返回少量聚合结果的业务场景。  
但是列存储也可能带来另一个负面影响，例如用户可能要返回多列，或者整行数据。由于列存储每列的存储都是独立的，当需要返回一整行记录时，需要扫描更多的数据块。当返回的记录数多时，可能会放大这个负面影响。  
行列混合存储就出现了，行列混合存储的思想类似与shard的思想。（在分布式数据库中，建表时，将表按规则切分成若干的shard，然后再将shard存储到不同的数据节点(shard数往往大于节点数)，当扩容时，move shard即可，而不需要改变数据在shard层面的分布规则。  例如某个分布式数据库由4个数据节点组成，建表时，可以分成4096个shard，那么在扩容时，移动shard就可以完成扩容。而不需要改变数据的路由规则，它们只需要按原来的方法路由到对应的shard即可。）  
在行列混合存储的应用中，也有类似shard的思想，例如将记录数切片，每一批数据的列存储放到一个单独的数据文件中。  
这么做的好处是，当用户需要访问这批数据时，访问的是连续的数据块，而不是离散的数据库，从而提升返回大量数据的性能。（当然，这里指的是返回相邻的大量数据）。  
![pic](20170615_01_pic_002.jpg)  
![pic](20170615_01_pic_003.jpg)  
## 小结  
大量数据实时读写，实时任意列搜索的场景，优化的手段非常多。  
本文详解介绍了列存储的优化方法。  
包括分片延迟编排，分片归整，行列混合等。  
分片延迟编排，在保证数据高速写入的前提下，可以实现数据在分片内的顺序，8K单位的元数据。减少数据搜索时的扫描成本。   
分片归整，指更大范围的分片编排，进一步提升整体的边界清晰度，从而再一次减少数据搜索时的扫描成本。  
行列混合存储，当需要返回大量的连续整行记录时，可以大幅降低扫描的数据块的离散度。   
#### [PostgreSQL 许愿链接](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216")
您的愿望将传达给PG kernel hacker、数据库厂商等, 帮助提高数据库产品质量和功能, 说不定下一个PG版本就有您提出的功能点. 针对非常好的提议，奖励限量版PG文化衫、纪念品、贴纸、PG热门书籍等，奖品丰富，快来许愿。[开不开森](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216").  
#### [9.9元购买3个月阿里云RDS PostgreSQL实例](https://www.aliyun.com/database/postgresqlactivity "57258f76c37864c6e6d23383d05714ea")
#### [PostgreSQL 解决方案集合](https://yq.aliyun.com/topic/118 "40cff096e9ed7122c512b35d8561d9c8")
#### [德哥 / digoal's github - 公益是一辈子的事.](https://github.com/digoal/blog/blob/master/README.md "22709685feb7cab07d30f30387f0a9ae")
![digoal's wechat](../pic/digoal_weixin.jpg "f7ad92eeba24523fd47a6e1a0e691b59")
#### [PolarDB 学习图谱: 训练营、培训认证、在线互动实验、解决方案、生态合作、写心得拿奖品](https://www.aliyun.com/database/openpolardb/activity "8642f60e04ed0c814bf9cb9677976bd4")
#### [购买PolarDB云服务折扣活动进行中, 55元起](https://www.aliyun.com/activity/new/polardb-yunparter?userCode=bsb3t4al "e0495c413bedacabb75ff1e880be465a")
#### [About 德哥](https://github.com/digoal/blog/blob/master/me/readme.md "a37735981e7704886ffd590565582dd0")