## HAWQ 集群部署 on ECS
### 作者         
digoal          
### 日期        
2016-09-16      
### 标签        
PostgreSQL , HAWQ , Greenplum , ECS , 集群
----        
## 背景  
之前写过两篇HAWQ on CentOS 6.x, 7.x的单机部署，本文主要描述的是HAWQ on ECS的多机部署。  
本文参考以下文章部署，详见如下    
http://hdb.docs.pivotal.io/20/  
http://www.aboutyun.com/thread-7684-1-1.html  
http://www.aboutyun.com/thread-8146-1-1.html  
http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-common/core-default.xml  
http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml  
http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-common/ClusterSetup.html  
## 环境描述
```
ECS * 3
ECS 配置: 2 Core , 8G 
系统: CentOS 7.2 x64
40G /  本地盘    
100G /data01  云盘1  
100G /data02  云盘2  
ioscheduler deadline
mount 选项 ext4   defaults,noatime,nodiratime,nodelalloc,barrier=0,data=writeback   
内网IP
xxx.xxx.xxx.97     namenode, datanode, resourcemanager, nodemanager
xxx.xxx.xxx.108    secondary namenode, datanode, nodemanager
xxx.xxx.xxx.104    datanode, nodemanager
```
## 初始化文件系统
```
mkdir /data01
mkdir /data02
umount /data01
umount /data02
parted -s /dev/vdb mklabel gpt
parted -s /dev/vdc mklabel gpt
parted -s -a optimal /dev/vdb mkpart primary 2 102400 unit MiB
parted -s -a optimal /dev/vdc mkpart primary 2 102400 unit MiB
mkfs.ext4 /dev/vdb1 -m 0 -O extent,uninit_bg -E lazy_itable_init=1
mkfs.ext4 /dev/vdc1 -m 0 -O extent,uninit_bg -E lazy_itable_init=1
sed  -i  "/vdb1/d" /etc/fstab
sed  -i  "/vdc1/d" /etc/fstab
echo "/dev/vdb1 /data01     ext4        defaults,noatime,nodiratime,nodelalloc,barrier=0,data=writeback    0 0" >> /etc/fstab
echo "/dev/vdc1 /data02     ext4        defaults,noatime,nodiratime,nodelalloc,barrier=0,data=writeback    0 0" >> /etc/fstab
mount -a
df -h
```
## 安装7.x epel yum源
http://fedoraproject.org/wiki/EPEL  
```
# wget https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm
# rpm -ivh epel-release-latest-7.noarch.rpm
# yum makecache fast
```
## 从yum仓库安装依赖包
```
# yum install -y man passwd sudo tar which git mlocate links make bzip2 net-tools \
  autoconf automake libtool m4 gcc gcc-c++ gdb bison flex gperf maven indent \
  libuuid-devel krb5-devel libgsasl-devel expat-devel libxml2-devel \
  perl-ExtUtils-Embed pam-devel python-devel libcurl-devel snappy-devel \
  thrift-devel libyaml-devel libevent-devel bzip2-devel openssl-devel \
  openldap-devel protobuf-devel readline-devel net-snmp-devel apr-devel \
  libesmtp-devel xerces-c-devel python-pip json-c-devel libhdfs3-devel \
  apache-ivy java-1.7.0-openjdk-devel \
  openssh-clients openssh-server  
# pip install --upgrade pip
# pip --retries=50 --timeout=300 install --upgrade paramiko pycrypto
# yum install -y lcov
```
## 安装 cmake
```
# useradd gpadmin
# su - gpadmin
$ mkdir -p /home/gpadmin/app
cd ~
wget https://cmake.org/files/v3.6/cmake-3.6.1.tar.gz
tar -zxvf cmake-3.6.1.tar.gz
cd cmake-3.6.1
./configure --parallel=32 --prefix=/home/gpadmin/app/cmake
make -j 32
make install
配置环境变量
echo "export PATH=/home/gpadmin/app/cmake/bin:\$PATH" >> /home/gpadmin/.bash_profile
```
## 配置os
### corefiles目录
```
# mkdir /data01/corefiles
# chmod 777 /data01/corefiles
```
### 内核参数
```
# vi /etc/sysctl.conf
fs.aio-max-nr = 1048576
fs.file-max = 76724600
kernel.core_pattern= /data01/corefiles/core_%e_%u_%t_%s.%p         
kernel.sem = 4096 2147483647 2147483646 512000    
kernel.shmall = 107374182      
kernel.shmmax = 274877906944   
kernel.shmmni = 819200         
net.core.netdev_max_backlog = 10000
net.core.rmem_default = 262144       
net.core.rmem_max = 4194304          
net.core.wmem_default = 262144       
net.core.wmem_max = 4194304          
net.core.somaxconn = 4096
net.ipv4.tcp_max_syn_backlog = 4096
net.ipv4.tcp_keepalive_intvl = 20
net.ipv4.tcp_keepalive_probes = 3
net.ipv4.tcp_keepalive_time = 60
net.ipv4.tcp_mem = 8388608 12582912 16777216
net.ipv4.tcp_fin_timeout = 5
net.ipv4.tcp_synack_retries = 2
net.ipv4.tcp_syncookies = 1    
net.ipv4.tcp_timestamps = 1    
net.ipv4.tcp_tw_recycle = 0    
net.ipv4.tcp_tw_reuse = 1      
net.ipv4.tcp_max_tw_buckets = 262144
net.ipv4.tcp_rmem = 8192 87380 16777216
net.ipv4.tcp_wmem = 8192 65536 16777216
vm.dirty_background_bytes = 4096000000       
vm.dirty_expire_centisecs = 6000             
vm.dirty_ratio = 80                          
vm.dirty_writeback_centisecs = 50            
vm.min_free_kbytes = 2097152  # vm.min_free_kbytes 建议每32G内存分配1G vm.min_free_kbytes
vm.mmap_min_addr = 65536
vm.overcommit_memory = 0     
vm.overcommit_ratio = 90     
vm.swappiness = 0            
vm.zone_reclaim_mode = 0     
net.ipv4.ip_local_port_range = 40000 65535    
# sysctl -p
```
### 资源限制
```
# rm -f /etc/security/limits.d/*.conf
# vi /etc/security/limits.conf
* soft    nofile  1024000
* hard    nofile  1024000
* soft    nproc   unlimited
* hard    nproc   unlimited
* soft    core    unlimited
* hard    core    unlimited
* soft    memlock unlimited
* hard    memlock unlimited
```
## 安装R
```
centos 7带的R版本比较高，如果图省事就直接用YUM安装，建议还是从R官网下载源码安装。
# yum install -y R R-devel
```
## 配置本地域名解析，主机列表
```
获取主机名
# hostname -s
```
配置/etc/hosts  
```
echo "127.0.0.1 localhost" > /etc/hosts
echo "xxx.xxx.xxx.97  host_digoal_01 >> /etc/hosts
echo "xxx.xxx.xxx.108 host_digoal_02 >> /etc/hosts
echo "xxx.xxx.xxx.104 host_digoal_03 >> /etc/hosts
```
## 配置主机与trust认证
```
# su - gpadmin
$ ssh-keygen 
$ cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys
$ chmod 600 ~/.ssh/authorized_keys
所有主机id_rsa.pub全部写入 ~/.ssh/authorized_keys
```
产生known_hosts  
```
cat /etc/hosts|awk '{print "ssh -o \"StrictHostKeyChecking no\" " $1  " date\n ssh -o \"StrictHostKeyChecking no\" " $2 " date \n"}' > /tmp/tmp.sh; . /tmp/tmp.sh ; rm -f /tmp/tmp.sh
```
## 安装java
选择最佳版本  
http://wiki.apache.org/hadoop/HadoopJavaVersions  
```
$ cd ~
get   
Java SE Development Kit 8u102
Linux x64   173.03 MB   jdk-8u102-linux-x64.tar.gz
$ tar -zxvf jdk-8u102-linux-x64.tar.gz
$ mv jdk1.8.0_102 /home/gpadmin/app/
$ echo "export JAVA_HOME=/home/gpadmin/app/jdk1.8.0_102" >> /home/gpadmin/.bash_profile
```
## 下载hadoop稳定版本
http://apache.fayea.com/hadoop/common/stable/  
```
$ cd ~
$ wget http://apache.fayea.com/hadoop/common/stable/hadoop-2.7.3.tar.gz
$ tar -zxvf hadoop-2.7.3.tar.gz
$ mv hadoop-2.7.3 /home/gpadmin/app/
$ cd /home/gpadmin/app/hadoop-2.7.3
$ bin/hadoop
Usage: hadoop [--config confdir] [COMMAND | CLASSNAME]
  CLASSNAME            run the class named CLASSNAME
 or
  where COMMAND is one of:
  fs                   run a generic filesystem user client
  version              print the version
  jar             run a jar file
                       note: please use "yarn jar" to launch
                             YARN applications, not this command.
  checknative [-a|-h]  check native hadoop and compression libraries availability
  distcp   copy file or directories recursively
  archive -archiveName NAME -p  *  create a hadoop archive
  classpath            prints the class path needed to get the
  credential           interact with credential providers
                       Hadoop jar and the required libraries
  daemonlog            get/set the log level for each daemon
  trace                view and modify Hadoop tracing settings
Most commands print help when invoked w/o parameters.
```
配置用户shell环境变量  
```
echo "export PATH=/home/gpadmin/app/hadoop-2.7.3/bin:/home/gpadmin/app/hadoop-2.7.3/sbin:\$PATH" >> /home/gpadmin/.bash_profile
echo "export LD_LIBRARY_PATH=/home/gpadmin/app/hadoop-2.7.3/lib/native:\$LD_LIBRARY_PATH" >> /home/gpadmin/.bash_profile
echo "export CLASSPATH=.:/home/gpadmin/app/jdk1.8.0_102/jre/lib" >> /home/gpadmin/.bash_profile
```
## 配置hadoop环境变量
hadoop-env.sh  
```
$ vi /home/gpadmin/app/hadoop-2.7.3/etc/hadoop/hadoop-env.sh
export JAVA_HOME=/home/gpadmin/app/jdk1.8.0_102
export HADOOP_NAMENODE_OPTS="-XX:+UseParallelGC -Dhadoop.security.logger=${HADOOP_SECURITY_LOGGER:-INFO,RFAS} -Dhdfs.audit.logger=${HDFS_AUDIT_LOGGER:-INFO,NullAppender} $HADOOP_NAMENODE_OPTS"
```
角色相关选项属性描述  
```
NameNode	HADOOP_NAMENODE_OPTS
DataNode	HADOOP_DATANODE_OPTS
Secondary NameNode	HADOOP_SECONDARYNAMENODE_OPTS
HADOOP_PID_DIR - The directory where the daemons’ process id files are stored.
HADOOP_LOG_DIR - The directory where the daemons’ log files are stored. 
                 Log files are automatically created if they don’t exist.
HADOOP_HEAPSIZE_MAX - The maximum amount of memory to use for the Java heapsize.  
                      Units supported by the JVM are also supported here. 
                      If no unit is present, it will be assumed the number is in megabytes. 
                      By default, Hadoop will let the JVM determine how much to use. 
                      This value can be overriden on a per-daemon basis using the appropriate _OPTS variable listed above. 
                      For example, setting HADOOP_HEAPSIZE_MAX=1g and HADOOP_NAMENODE_OPTS="-Xmx5g" will configure the NameNode with 5GB heap.
HADOOP_HOME=/path/to/hadoop
export HADOOP_HOME
```
## 配置Hadoop Daemons配置文件
1\. /home/gpadmin/app/hadoop-2.7.3/etc/hadoop/core-site.xml  
datanode & namenode  
```
fs.defaultFS	        NameNode URI	hdfs://host:port/     # namenode节点的IP, 配置内网IP
io.file.buffer.size	131072	        Size of read/write buffer used in SequenceFiles.
```
配置  
```
$ vi /home/gpadmin/app/hadoop-2.7.3/etc/hadoop/core-site.xml
        fs.defaultFS
        hdfs://xxx.xxx.xxx.97:8020
        io.file.buffer.size
        131072
        ipc.client.connection.maxidletime
        3600000
        ipc.client.connect.timeout