intransitive ﬂow policy could say that information ﬂow
2Here and in some further places we change some notation of [21,
2] from so-called systems to structures. These systems contain sev-
eral possible structures, derived from an intended structure with a trust
model. Here we can always work with individual structures.
B
G
/
S
C
Figure 2. Flow policy for the secretary ex-
ample. All missing edges are of the form
❀, i.e., ﬂow is allowed.
from the user to the printer should not be possible unless
these special services have been used, so some condition
on information ﬂow is imposed here. In the next section,
we examine several further examples with the goal of
investigating arbitrary probabilistic behaviors. The ex-
amples motivate different points of view of intransitive
probabilistic non-interference, resulting in different pos-
sible deﬁnitions.
Naming convention. Throughout the following, we
consider users H and L such that H (cid:10)❀ L should hold
unless explicitly state otherwise. The remaining users
are usually called third parties and named T1, . . . , Tn or
simply T if there is only one.
3 Examples and Deﬁnitions
In this section, we investigate what probabilistic non-
interference means for intransitive ﬂow policies, result-
ing in several possible deﬁnitions, each one motivated
by a concrete example.
3.1 Example: Secretary
Consider a small company selling goods or services
over the Internet. Ordinarily, its CEO (chief executive
ofﬁcer) C does not want to be disturbed by customers,
and thus all normal correspondence is handled by a sec-
retary S. However, some speciﬁc good customers are al-
lowed to contact the CEO directly; we denote the others
by B for “bad” customers. This corresponds to the in-
formation ﬂow graph of Figure 2 for one good customer
G and one bad customer B. This is a typical example
where indirect information ﬂow from B to C via the sec-
retary S is certainly allowed. Further, “bad” customers
that know a good customer can also bypass the secretary
by having the good customer vouch for them. For dig-
ital communication, we may want to enforce this ﬂow
policy by cryptographic authentication and ﬁltering, see
Section 6.
Proceedings of the 2003 IEEE Symposium on Security and Privacy (SP(cid:146)03) 
1081-6011/03 $17.00 ' 2003 IEEE 
3.2 Blocking Non-Interference
How do we express this notion of intransitive infor-
mation ﬂow? According to our intuition, we would like
to model that B can only inﬂuence C if B has help from
either S or G. Equivalently, we can deﬁne that for all C
and all B, there exists an S and a G such that the consid-
ered information ﬂow is prohibited in the resulting con-
ﬁguration. This means that the secretary might refuse
to put the customer through to C and G might refuse to
help. This yields our ﬁrst deﬁnition of intransitive non-
interference, which we call blocking non-interference.
We ﬁrst make it for precisely this ﬂow policy, and gen-
eralize it below.
Deﬁnition 3.1 (Blocking Non-Interference for One Pol-
icy) Let the ﬂow policy G = (∆,E) of Figure 2 for a
structure ( ˆM , S ) be given. We say that ( ˆM , S ) fulﬁlls
the blocking non-interference requirement
a) perfectly (written ( ˆM , S ) |=block intrans
G) iff for
all B, C there exists S, G such that for all non-
B,C = ( ˆM , S ,
interference conﬁgurations conf n in
{B, C, S, G}, A) ∈ Confn in
B,C,I( ˆM , S ) of this struc-
ture the inequality
∗
perf
P (b = b
|
;
B,C ,k
r ← run conf n in
b := r(cid:5)pB bit!;
∗ := r(cid:5)p∗
b
C bit?) ≤ 1
2
holds. (Typically it is then = 1
2 , but C might de-
stroy its guessing chances by not outputting any
Boolean value.)
SMALL
b) statistically for a class SMALL of functions
G) iff for all B, C there ex-
(( ˆM , S ) |=block intrans
ists S, G such that for all non-interference con-
B,C = ( ˆM , S ,{B, C, S, G}, A) ∈
ﬁgurations conf n in
Confn in
B,C,I( ˆM , S ) of this structure the inequality
P (b = b
∗
|
;
B,C ,k
r ← runconf n in
b := r(cid:5)pB bit!;
∗ := r(cid:5)p∗
b
C bit
?) ≤ 1
2
+ s(k)
holds for some s ∈ SMALL. SMALL must be
closed under addition and with a function g also
contain every function g
(cid:4) ≤ g.
c) computationally (( ˆM , S ) |=block intrans
G) iff for
all polynomial-time B, C there exists polynomial-
time S, G such that for all polynomial-time non-
B,C = ( ˆM , S ,
interference conﬁgurations conf n in
poly
H
T
1
T
2
/
T
3
T
4
T
5
L
Figure 3. Flow policy with ﬁve third parties.
All missing edges are the form (cid:10)❀, i.e., ﬂow
is not allowed. Users T1 and T2 form a cut
for H and L.
{B, C, S, G}, A) ∈ Confn in
ture the inequality
|
P (b = b
∗
B,C,I( ˆM , S ) of this struc-
;
B,C ,k
r ← runconf n in
b := r(cid:5)pB bit!;
∗ := r(cid:5)p∗
b
C bit
?) ≤ 1
2
+ s(k)
holds for some s ∈ NEGL, the set of all negligible
functions.3
We write “|=block intrans” if we want to treat all cases to-
gether.
✸
In the upcoming deﬁnitions, we will only deﬁne statis-
tical fulﬁllment, as perfect fulﬁllment is comprised by
the class SMALL = {0}. Similarly, computational ful-
ﬁllment is statistical fulﬁllment for the class SMALL =
NEGL with the further restriction to polynomial-time
conﬁgurations.
More generally, we can consider n third parties
T1, . . . , Tn instead of S and G. The obvious exten-
sion of our above deﬁnition to this case would be to
replace the statement “there exists S, G” with “there ex-
ists T1, . . . , Tn” without any further work. Although
this yields a meaningful deﬁnition, we can signiﬁcantly
strengthen it as follows: We no longer demand that all
users should try to prohibit information ﬂow between
H and L, because this is fairly unrealistic. Instead we
demand that certain subsets of the third parties are suc-
cessful in interrupting the connection. Obviously, this
cannot work for arbitrary subsets; we need that for each
path from H to L in the ﬂow graph, at least one node of
the path is contained in this subset. According to graph
theory, we then call the subset a cut for H and L of the
given ﬂow graph. An example is shown in Figure 3.
Deﬁnition 3.2 (Cut) Let a ﬂow graph G = (∆,E) be
given. Then a cut for two nodes M1, Mn ∈ ∆ is a set
3We have s ∈ NEGL iff for all positive polynomials Q ∃n0 ∀n >
n0 : s(n) < 1
Q(n) .
Proceedings of the 2003 IEEE Symposium on Security and Privacy (SP(cid:146)03) 
1081-6011/03 $17.00 ' 2003 IEEE 
ˆC ⊆ ∆ of nodes that cut all paths from M1 to Mn. I.e.,
let G ˆC := (∆ ˆC ,E ˆC ) with ∆ ˆC := ∆ \ ˆC and E ˆC :=
{(M, M(cid:4)) | (M, M(cid:4)) ∈ E ∧ M, M(cid:4) (cid:10)∈ ˆC}. Then M1 and
Mn should lie in unconnected components of G ˆC , i.e.,
there should be no sequence M2, . . . , Mn−1 such that
(Mi, Mi+1) ∈ E ˆC for j = 1, . . . , n − 1.
✸
Using cuts, we can now give a general deﬁnition of
blocking non-interference (using the general conven-
tion of H (cid:10)❀ L again).
It states that whatever users
Ti1, . . . , Til might do to “help” H to transmit the bit,
the remaining users Tj1 , . . . , Tjt can still prohibit infor-
mation ﬂow, provided that they are a cut for H and L.
Deﬁnition 3.3 (Blocking Non-Interference) Let a ﬂow
policy G = (∆,E) for a structure ( ˆM , S ) be given, con-
sisting of H, L, and third parties T1, . . . , Tn. We say that
( ˆM , S ) fulﬁlls the blocking non-interference require-
ment (( ˆM , S ) |=block intrans
G) iff for all H, L and for all
cuts ˆC for H and L, there exist users {Tj1, . . . , Tjt} :=
ˆC such that
for all non-interference conﬁgura-
H,L = ( ˆM , S ,{H, L, T1, . . . , Tn}, A) ∈
tions conf n in
Confn in
H,L,I( ˆM , S ) of this structure the inequality
P (b = b
SMALL
∗
;
|
r ← runconf n in
b := r(cid:5)pH bit!;
∗ := r(cid:5)p∗
b
holds for a function s ∈ SMALL.
L bit?) ≤ 1
2
H,L ,k
+ s(k)
✸
Unfortunately, our above deﬁnition is too coarse-
grained to capture the full range of probabilistic behav-
iors. It mainly states that the secretary can interrupt the
entire connection, while in reality the secretary should
be able to see the content of an attempted information
ﬂow and judge whether the CEO will want to see it or
not. We will deal with that next.
3.3 Example: Firewall
As another well-known example, consider a ﬁrewall
guarding some honest users from malicious adversaries.
Here the ﬁrewall should prohibit any negative inﬂuence
from outside, so the ﬁrewall itself has to detect when
a speciﬁc information ﬂows to the user. Moreover,
probabilism shows up if we consider cryptographic ﬁre-
walls, i.e., ﬁrewalls whose ﬁltering functions are based
on cryptographic authentication. Here the ﬁrewall main-
tains a set of “allowed” users and checks each incoming
message for a signature belonging to that speciﬁc set.
All other messages are discarded. This motivates a new
deﬁnition of non-interference, which is based on the no-
tion of recognizing when information ﬂow occurs.
L
b*
guisher D and a function ns(cid:4) (cid:10)∈ SMALL such that
b
H
view
/
T
D
b'
P (b = b
(cid:4)
|
;
H,L ,k
r ← run conf n in
b := r(cid:5)pH bit!;
(cid:4) ← D(r(cid:5)T, 1k)) ≥ 1
b
2
+ ns(cid:4)(k).
For the computational case, the distinguisher has to be
polynomial-time.
✸
We can extend our deﬁnition with arbitrary predicates
pred(·,·) on the functions ns and ns(cid:4)
to model concrete
complexity. For instance, fulﬁllment for the predicate
pred(ns, ns(cid:4)) := (ns ≤ ns(cid:4)) ensures that the advantage
of the distinguisher is at least as good as the advantage
of the user L.
The above deﬁnition works ﬁne as long as we only
consider one possible path from H to L where informa-
tion ﬂow is allowed to occur. Consider our secretary
example of the previous section where B has two pos-
sible ways of sending information to C. Assume that it
wants to transmit a codeword m ∈ Σ∗
(e.g., the bit b).
Instead of sending the codeword in cleartext over one of
these paths, B divides it into two parts such that none of
them gives any information on the codeword on its own.
The standard construction is to choose a random string