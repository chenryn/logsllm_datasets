title:Portcullis: protecting connection setup from denial-of-capability
attacks
author:Bryan Parno and
Dan Wendlandt and
Elaine Shi and
Adrian Perrig and
Bruce M. Maggs and
Yih-Chun Hu
Portcullis: Protecting Connection Setup from
Denial-of-Capability Attacks
Bryan Parno
Carnegie Mellon University
PI:EMAIL
Dan Wendlandt
Carnegie Mellon University
PI:EMAIL
Adrian Perrig
Carnegie Mellon University
PI:EMAIL
Bruce Maggs
Carnegie Mellon University
Akamai Technologies
PI:EMAIL
Elaine Shi
Carnegie Mellon University
PI:EMAIL
Yih-Chun Hu
University of Illinois at
Urbana-Champaign
PI:EMAIL
ABSTRACT
Systems using capabilities to provide preferential service to se-
lected ﬂows have been proposed as a defense against large-scale
network denial-of-service attacks. While these systems offer strong
protection for established network ﬂows, the Denial-of-Capability
(DoC) attack, which prevents new capability-setup packets from
reaching the destination, limits the value of these systems.
Portcullis mitigates DoC attacks by allocating scarce link band-
width for connection establishment packets based on per-computation
fairness. We prove that a legitimate sender can establish a capabil-
ity with high probability regardless of an attacker’s resources or
strategy and that no system can improve on our guarantee. We
simulate full and partial deployments of Portcullis on an Internet-
scale topology to conﬁrm our theoretical results and demonstrate
the substantial beneﬁts of using per-computation fairness.
Categories and Subject Descriptors: C.2.0 [Computer-Communication
Networks]: Security and protection
General Terms: Security, Design
Keywords: Network Capability, Per-Computation Fairness
1.
INTRODUCTION
In a Distributed Denial-of-Service (DDoS) attack, an adversary,
sometimes controlling tens of thousands of hosts, sends trafﬁc to a
victim to exhaust a limited resource, e.g., network capacity or com-
putation. The victim of a network DDoS attack can often identify
legitimate trafﬁc ﬂows but lacks the ability to give these ﬂows pri-
oritized access to the bottleneck link; in contrast, routers have the
power to prioritize trafﬁc, but cannot effectively identify legitimate
packets without input from the receiver.
Network capabilities enable a receiver to inform routers of its
desire to prioritize particular ﬂows, offering a promising DDoS de-
fense [3, 22, 25, 31, 32]. To set up a network capability, the source
sends a capability request packet to the destination, and routers on
the path add cryptographic markings to the packet header. When
the request packet arrives at the receiver, the accumulated markings
represent the capability. The receiver permits a ﬂow by returning
the capability to the sender, who includes the capability in subse-
quent packets to receive prioritized service from the routers.
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
SIGCOMM’07, August 27–31, 2007, Kyoto, Japan.
Copyright 2007 ACM 978-1-59593-713-1/07/0008 ...$5.00.
Current pro-
The Denial-of-Capability Attack and Defenses.
posals for capability-based systems treat prioritized trafﬁc (i.e., pack-
ets with a valid capability) preferentially over non-prioritized traf-
ﬁc. However, capability-based systems still suffer from a criti-
cal weakness:
they cannot protect the initial capability request,
because that request is sent unprotected as non-prioritized trafﬁc.
An attacker can ﬂood the capability-setup channel, thus prevent-
ing a legitimate sender from establishing a new capability-protected
channel. This attack, referred to as Denial-of-Capability (DoC) by
Argyraki and Cheriton [4], is the Achilles heel of current capability
proposals. Agryraki and Cheriton show that several thousand at-
tackers can easily saturate the request channel of a typical network
service, preventing legitimate senders from acquiring capabilities.
When describing the DoC vulnerability, Argyraki and Cheri-
ton argue that the same mechanism that protects the request chan-
nel could be used to protect all trafﬁc [4]. We strongly disagree:
since only a single capability request packet is needed to set up
capability-protected communication, a simple and highly efﬁcient
network-based defense sufﬁces. As long as the mechanism pro-
vides a predictable and non-negligible probability that the sender’s
request packet reaches the receiver, it can prevent DoC attacks. For
example, if the capability request channel suffers a 50% loss rate, a
legitimate sender only needs to send about two packets to set up a
capability-protected communication channel. Alas, a 50% loss rate
would be far too high for efﬁcient communication using TCP, and
thus such a mechanism could not protect later packets.
Previously proposed capability-based systems offer few, if any,
defenses against a DoC attack. Early systems simply treat capa-
bility request packets as best-effort packets [3, 22, 31]. The most
recent capability architecture, TVA [32], attempts to achieve DoC
robustness by tagging each packet with an identiﬁer indicating the
packet’s ingress point to the autonomous system (AS) and then fair-
queuing packets at each router based on this identiﬁer.1 However,
our evaluation in Section 6 indicates that this heuristic is insufﬁ-
cient to thwart DDoS attacks on Internet-scale topologies.
In this work, we present Portcullis,2 a system that uses computa-
tional proofs of work (puzzles) to enforce fair sharing of the request
channel. As a result, Portcullis strictly bounds the delay any adver-
sary can impose on a legitimate sender’s capability establishment.
Why Puzzles? While we explore the design space of DoC so-
lutions in Section 2.3, we now provide a high-level explanation of
why puzzles are particularly well-suited for solving the DoC prob-
lem. We argue that approaches like TVA that attempt to use a
packet identiﬁer to group and prioritize aggregates of trafﬁc are in-
1TVA allows further sub-dividing of these queues based on past
AS identiﬁers, but at the cost of greatly increased router state and
increased susceptibility to path spooﬁng.
2A portcullis is a grille or gate that restricts entry into a castle.
adequate for networks as large and diverse as the Internet. A major
reason is that, short of trusting all routers on the Internet, network
identiﬁers are likely to be either spoofable or very course-grained.
Additionally, a single network identiﬁer (e.g., IP address) can rep-
resent vastly different numbers of actual users (e.g., hosts behind a
NAT), limiting achievable fairness.
Proof-of-work schemes offer a compelling alternative. Instead of
trying to use identiﬁers in the packet header to provide fairness, a
router simply provides fairness proportional to the amount of work
performed by a sender. Such work can be veriﬁed and is thus dif-
ﬁcult for an attacker to productively spoof. Since only one packet
must reach the destination in order to set up a capability, proof-of-
work schemes are sufﬁcient to prevent DoC.
Walﬁsh et al. propose a system called speak-up that encourages
legitimate hosts to signiﬁcantly increase their sending rates during
application-layer denial-of-service attacks [26], effectively using
bandwidth as “work”. However, the use of bandwidth as a “cur-
rency” is questionable, because the bandwidth available to typical
users may vary by factors of more than 1,500 (dial-up modem vs.
LAN connection), potentially placing legitimate users at a signiﬁ-
cant disadvantage. Moreover, their results focused on application
layer DDoS attacks and assumed that the network itself was un-
congested. In the context of DoC and network-level congestion,
a speak-up style approach would inevitably create signiﬁcant nega-
tive externalities for the network, because the increased trafﬁc from
legitimate users can create new bottlenecks for clients accessing
destinations not under attack.
In contrast, puzzles provide a compelling solution because the
“work” performed by the end host, hence avoiding additional net-
work congestion. Also, computational disparities between users are
orders of magnitude smaller than disparities in network bandwidth
(Section 7.1 demonstrates a 38x difference in puzzle computation
power between a well-provisioned workstation and a cell phone).
Note that previous work [21] claiming that puzzles do not work
contains a crucial arithmetic miscalculation, and only considers a
simple, ﬁxed-cost puzzle scheme that differs signiﬁcantly from the
novel, variable proof-of-work scheme used by Portcullis (see Sec-
tion 8 for more details).
Contributions.
In this paper we propose Portcullis, a system
that enforces per-computation fairness for a capability system’s re-
quest channel. Portcullis makes the following contributions:
• We theoretically prove strict bounds on the delay that an arbi-
trary number of cooperating attackers computing and sharing
puzzles can inﬂict on a legitimate client’s capability setup us-
ing Portcullis (Section 4). This guarantee holds even if the
legitimate sender possesses no information about current net-
work conditions or the adversary’s resources.
• We theoretically prove that no system can improve on the
• With Internet-scale simulations, we conﬁrm experimentally
that even when tens of thousands of attackers cooperate to
compute and share puzzles, a legitimate client can quickly
overcome the numerical disparity and establish a capability
(Section 6).
• Portcullis’s novel proof-of-work mechanism avoids the pit-
falls of previous puzzle schemes: it does not require routers
or servers to individually provide puzzles to the sender [5,27,
28], does not rely on the sender’s IP address [5,27,28] (avoid-
ing problems with NATs and IP spooﬁng), does not require
senders to solve a different puzzle for each router along the
path to the destination [28], and does not allow puzzle reuse
at multiple servers nor require extensive CPU and memory at
clients, routers or servers [29].
bounds provided by Portcullis.
2. PROBLEM DEFINITION AND GENERAL
COUNTERMEASURES
2.1 Background and Terminology
Capability-based systems divide packets into priority packets,
request packets, and best-effort packets.3 Priority packets are pack-
ets that carry a valid capability. Senders use request packets to es-
tablish a capability. As the request packet traverses the routers be-
tween the sender and the receiver, it accumulates the router mark-
ings that will form the capability. Best-effort packets are sent by
legacy hosts that are not capability-aware. Some capability-based
systems also treat packets with invalid capabilities as best-effort
trafﬁc, while others drop them. Proposed capability systems [3, 22,
31, 32] typically dedicate a large fraction of router bandwidth to
priority packets, a small fraction (5–10%) of total bandwidth to re-
quest packets (often referred to as the request channel), and the rest
(˜5–10%) to best-effort packets.
2.2 Problem Deﬁnition
Capability systems attempt to thwart DDoS attacks by prioritiz-
ing legitimate trafﬁc. However, an attacker can also launch a DDoS
attack on the request channel of the capability system. If the request
packets of legitimate users do not reach the capability granter, then
the capability system provides little protection against the effects
of the traditional DDoS attack. Thus, providing a secure request
channel is essential to the effectiveness of a capability system.
An effective request channel should guarantee that a sender suc-
cessfully transmits a request packet with only a small number of
retries, even in the presence of a large DDoS attack on the request
channel itself. We consider the case in which the adversary con-
trols nm hosts each sending trafﬁc at a rate rm. We also assume the
presence of ng legitimate senders that each send request packets at
a rate rg (typically very low), but we make no assumptions about
the relative size of ng versus nm.
We only examine the case in which the request channel is con-
gested, i.e., nm · rm + ng · rg > γ, where γ= B· α, B is the capacity
of the bottleneck link, and α is the percentage of bandwidth re-
served for the request channel. Since request packets contain no
input from the capability-granting destination to allow distinctions
between desired and undesired requests, the best the network can
do is provide an equal level of service to all requesters. In other
share of the available
words, each requester should receive a
request channel γ, regardless of whether that node is an attacker
with a high request rate or a legitimate node with a low request rate.
However, even with any reasonable fairness guarantee, the time re-
quired to establish a setup packet is still necessarily dependent on
the total number of users (nm + ng) and the amount of network ca-
pacity available.
2.3 Space of Countermeasures Against DoC
nm+ng
1
In this section, we divide the design space of potential counter-
measures into two classes based on identity and proof-of-work.
2.3.1
Identity-Based Fairness
Identity-based fairness schemes attempt to provide fairness based
on some packet identiﬁer (e.g., an IP address). These schemes
are often susceptible to malicious spooﬁng of the identiﬁer space
that can greatly magnify attacker power.
Identity-based fairness
schemes can also experience problems when signiﬁcant disparities
exist with respect to the number of users sharing a single identiﬁer.
3Both Machiraju et al. [22] and Yaar et al. [31] treat request packets
as best-effort packets.
γ
ng+m
(cid:3)
(cid:2)
rg, γ
|P| 1
Npi
). Note that r
(cid:2)
g = min(rg,
Per-Source Fairness. A DDoS-defense system could attempt to
share bandwidth equally over all sources of trafﬁc. In other words,
in a system with ng + nm senders, a legitimate host would achieve
(cid:2)
an outbound sending rate of r
g is
independent of the aggregate attacking rate nm · rm.
Unfortunately, at the network level, an adversary can easily spoof
its IP address, and sources behind large NATs may be subject to
grossly unfair treatment. Egress ﬁltering can lessen the severity of
such an attack [13], but without ubiquitous deployment, we must
assume that many adversaries can spoof their IP addresses with
relative impunity.
For per-path fairness, if P = {p1, p2, . . . , pk}
Per-Path Fairness.
represents the set of paths leading to the bottleneck router and Npi
represents the number of senders using path pi, then a legitimate
sender using path pi should achieve an outbound sending rate of
(cid:2)
g = min
. To encode a path, Yaar, Perrig and Song pro-
r
pose Pi [30], a system in which routers insert path-dependent cryp-
tographic markings into the packet header. However, router queu-
ing based on such path markings breaks when malicious senders
insert bogus initial markings in the path ID ﬁeld, making it appear
that such packets have traversed many distinct paths before arriving
at a particular router. This increases |P|, hurting legitimate senders,
and creates small values of Npi for the spoofed paths, helping the
attacker. TVA bases its notion of fairness on path-dependent mark-
ings [32]. However, to avoid spooﬁng problems, their markings
depend only on the interface from which a packet entered the cur-
rent AS, and hence operates at a very coarse granularity.
Per-Destination Fairness. Alternately, a router could apportion
request channel bandwidth based on a packet’s destination address.
While destination addresses cannot be spoofed, an attacker can
“game” this approach by ﬂooding packets to all destinations that
share the victim’s bottleneck link. Because legitimate users send
packets only to a single host, per-destination queuing can actually
amplify the power of an attacker.
2.3.2 Proof-of-Work Schemes
K
(cid:5)
(cid:2)
g = min
(cid:4)
rg,γ κ
Proof-of-work schemes require senders to demonstrate the use
of a limited resource to the network infrastructure, with fairness
allotted proportionally to the “cost” of that resource. This solves
the spooﬁng/gaming issue (as long as work indicates a real cost),
but the resources needed to provide this work may have negative
externalities.
Per-Bandwidth Fairness. With per-bandwidth fairness, a sender
with bandwidth capacity κ should achieve an outbound sending
, where K represents the aggregate band-
rate of r
width of all senders. To attain per-bandwidth fairness, Walﬁsh et al.
propose a system called speak-up [26]. When a host experiences an