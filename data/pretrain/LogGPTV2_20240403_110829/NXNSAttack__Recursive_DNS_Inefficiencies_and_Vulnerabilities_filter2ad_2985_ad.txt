### 5.1 MaxBreadth

In DNS referral responses, more than 13 name servers are rarely observed, with less than one percent of cases having more than seven. The limitation on the number of name servers should be a function of the zone level and the authoritative name server providing the referral. For a second-level domain (SLD) zone, a default restriction of four name servers might be appropriate. Investigating the exact limits and effects of this MaxBreadth proposal is beyond the scope of this paper.

### 5.2 MaxFetch(k)

We propose to distribute the resolution of multiple delegations for a zone over several requests, resolving one or a few (k) delegations per request, rather than all at once when the referral for the zone first arrives. In general, during the resolution of each client request, while using an already resolved delegated name server, the resolver will also resolve the IP address of an additional k delegated name servers to prepare for future requests. This process continues until all the delegations provided in a referral response are resolved.

Several variations of this scheme are possible. For example, upon receiving the first referral response within the resolution of a client request, the resolver could start with k concurrent resolutions of referred name server names. On each subsequent client request that results in the same referral, the resolver could make one or more additional name server name resolutions.

We modified the BIND 9.12.3 resolver algorithm to implement MaxFetch(1). The maximum number of external fetches (additional resolutions) enforced at each level is configurable. MaxFetch(k) allows the resolution of k additional delegations without associated IP addresses per request. In MaxFetch(1), a resolver using a zone z during a request checks if there are unresolved delegations for z in its NS record. If such a delegation is found, the resolver initiates its resolution, while continuing the original request in parallel using an already resolved delegate for zone z. Note that the first request using zone z (which has also received the corresponding referral response) may have to wait for the resolution of the first delegate if all came without a glue record in the referral response (or all are out-of-bailiwick). In this case, the second request using zone z will use the same delegate as the first one (resolving two delegations in the first request is a possibility we have not tested).

It is important to note that MaxFetch(1) does not negatively affect the latency of a request resolution (see latency analysis in §5.3 and §5.4), nor does it disrupt RTT estimation algorithms (such as sRTT). Most recursive resolvers perform latency-wise algorithms to decide which server to query next. However, MaxFetch(1) does not disrupt these algorithms because it allows the resolution of an additional name server that may be selected in the next client request. After enough requests, all delegations are resolved. The resolution of an additional name server does not add to the latency of a response since each request, except the first, uses a previously resolved name server while issuing the additional resolution in parallel.

### 5.3 MaxFetch(1) Evaluation Under Attack

In Figure 7 (§4.1), we compare the PAF (Packets Amplification Factor) of the original BIND to that of the MaxFetch(1) variant during a long-lived simulated NXNSAttack against an SLD victim. The blue line (−4−) shows that the MaxFetch(1) enhancement avoids most of the additional resolutions, initiating only two additional requests (one IPv4 and one IPv6) per request. Instead of 1,500,319 packets exchanged by the original BIND recursive resolver (as a result of 10,000 malicious client requests), MaxFetch(1) exchanges only 60,061 packets (the measured MaxFetch PAF is reduced from 75x to 3x).

We also repeated the stress tests as in §4.5 to measure the maximal number of client queries per second that the BIND resolver can sustain under the NXNSAttack with and without MaxFetch(1). As seen in Table 4, BIND with MaxFetch(1) can process many more attack requests: 3,390 vs. 932 under the NXNSAttack (and 3,708 for the original BIND under the NXDomain attack in §4.5). We also compared the latency of attack requests with and without MaxFetch(1). The latency values were observed at the attacker client, which generates requests during a simulation of the NXNSAttack against an SLD victim in our testbed. As seen in Table 4, the average, median, and standard deviation latency under attack are much better with MaxFetch(1) than without.

### 5.4 MaxFetch(1) in Normal Operation

Here, we evaluate the recursive resolver operation in practice, with and without MaxFetch(1), under normal operation (without an attack). We measure (i) the latency of client queries and (ii) the number of IPv4 packets processed by the resolver in the resolution process. The purpose is twofold: first, to verify that the MaxFetch(1) modification does not incur query delays or resolution failures (i.e., the number of SERVFAIL and NOERROR responses is not higher than that observed in the original BIND). Second, to measure the impact of the Out-of-Bailiwick overhead on the recursive resolver under normal operation, to determine whether the cache mitigates this overhead over time.

#### 5.4.1 Datasets

Two datasets are used to study the normal operation of a BIND resolver:

- **Dataset A**: A list of the top million domains [21]. We executed DNS 'A' requests (IPv4 resolution) for the first 100,000 domains in this list.
- **Dataset B**: Campus DNS trace. A 24-hour trace of live DNS traffic observed on a campus DNS server. Out of the 1,027,359 queries to domains that do not reside within the campus zone, we took the 386,736 'A' queries, with 10,092 unique ones.

**Ethical Consideration**: Dataset B is a sequence of DNS queries with their timestamps but without the IP addresses that originated them.

With each dataset, we send its query stream (100,000 queries in Dataset A, and 386,736 queries in Dataset B) to both the original BIND and BIND with MaxFetch(1). The 1GB resolvers’ cache is empty at the beginning of each experiment and can store all the responses received in each experiment. We record the traffic between the recursive resolver and the authoritative hierarchy, as well as collecting the BIND statistics.

#### 5.4.2 Results

**Resolution Overhead**: We start by measuring the reduction in resolution cost introduced by MaxFetch(1) in normal operation (see §2.2). Figure 8 and the fourth row (Total recursion packets) in Table 5 show the number of packets processed by the recursive resolver (with and without MaxFetch(1)) in each of the datasets. Using the original BIND, the resolver exchanges 14.84% more packets in the resolution of the queries in Dataset A than it does using the MaxFetch(1) variant (747,494 vs. 650,864). Similarly, for Dataset B (campus DNS trace), the original BIND exchanges 7.34% more packets (454,032 vs. 422,946).

As seen by the green overhead lines (−(cid:5)−) in Figures 8a and 8b, MaxFetch(1) saves more than 50% of the resolution cost in the first 1,000 requests, when the cache has not yet filled up. The lines show the resolution drop \((\frac{Packets_{MaxFetch(1)} - Packets_{orig}}{Packets_{orig}}) \times 100\). The gap decreases as more requests are processed and the cache fills up with name server resolutions that are shared by multiple requests. After 20,000 requests, the gap remains stable at around 15% for Dataset A and 7% for Dataset B. Furthermore, MaxFetch(1) does not result in more SERVFAIL, NOERROR, or NXDOMAIN responses than the original BIND in the resolution of the 386,691 queries in Dataset B (Fifth row in Table 5).

**Latency**: The last row in Table 5 shows the average, median, and standard deviation latency, in both datasets, with and without MaxFetch(1). The response time is slightly faster using MaxFetch(1): 157.37ms using the original BIND vs. 155.95ms using MaxFetch(1) in Dataset A (top domains), and 41.5ms vs. 40.97ms in Dataset B (campus trace).

Note that in Dataset B, most queries are served by the resolver cache because not all the requests are unique. Thus, when calculating the average, median, and standard deviation, we exclude queries with zero latency (we consider only 114,570 out of 386,691 queries).

Figures 9a and 9b show the cumulative distribution of the queries’ latency values for Datasets A and B, with and without MaxFetch(1). The latency values for both datasets with and without MaxFetch(1) are between 0 and 5 seconds. In both datasets, the CDF lines for the original BIND and MaxFetch(1) overlap, exhibiting a nearly identical distribution. The 99th percentile latency distribution in Dataset B shows a similar trend.