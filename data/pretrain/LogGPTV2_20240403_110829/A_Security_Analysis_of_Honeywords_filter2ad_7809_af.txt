ϵ-ﬂat info
10.46%
0.4063
8.75%
0.3345
9.06%
0.4666
4.06%
0.1761
7.52%
0.2624
similarly deﬁne the “Norm PW-model” attack strategy.
For the Markov-model-based honeyword method, we can
As shown in Fig. 5(a), if A exploits our “Norm PW-model”
strategy (trained on Dodonew-tr, tested on Dodonew-ts, and
T2 = 104), honeyword-generation methods directly adapted
from state-of-the-art password models are still vulnerable.
More speciﬁcally, before A makes the ﬁrst failed login attempt,
she can successfully login 58,122 (0.71%) accounts against the
PCFG-based method, and 150,459 (1.84%) accounts against
the Markov-based method; before A makes the 104th wrong
login attempts, she can successfully login 329,957 (4.06%)
accounts and 611,388 (7.52%) accounts, respectively. Fig. 5(b)
reveals that both methods are 0.1761+-ﬂat.
(a) Success-number graph of representative password-model-based methods.
(b) Flatness graph of representative password-model-based methods.
Fig. 5. An investigation of the effectiveness of two representative password-
model-based honeyword-generation methods that are mentioned in [21]:
trained on Dodonew-tr, tested on Dodonew-ts, attacking with the ‘Norm PW-
model” attack strategy (see Sec. III-E). Both methods are vulnerable.
As summarized in Table VII,
the PCFG-based method
performs the best among the six methods in terms of both the
success number and ϵ-ﬂatness metrics. Still, in terms of the
success-number metric, it is 628=(329957/(T2/(k-1))) times
weaker than the optimal method; it is 0.1761-ﬂat, three times
weaker than the expected 0.05. It is likely that under more
effective attacking strategies, the PCFG-based method will be
even weaker. Naturally, an interesting question arises: is our
“Norm PW-model” attacking strategy optimal for password-
model based honeyword methods? Or, what’s the optimal
attacking strategy for password-model based methods? We left
both questions as future research.
Summary. Our real-data grounded attacks show that the four
methods examined all fall short of their expected security:
under Juels-Rivest’s assumed adversary model (i.e., a type-
11
A1 attacker), the real passwords can be distinguished with a
success rate of 29.29%∼32.62% by using our basic trawling-
guessing attack, but not the claimed 5%, with just one guess
when each user account is associated with 19 honeywords. We
also provided a negative answer to the question of “can the
password models underlying cracking algorithms (e.g., [32])
be easily adapted for use?” as left in [21].
IV. ADVANCED TRAWLING GUESSING ATTACKS
In the above, we have evaluated Juels-Rivest’s four primary
methods under two attack strategies by using the List password
model (which is the most basic/simple password model). One
defect of the List model is that, it is not good at eliminating
“sweetword ties” (which are of similarly low probabilities) in
uncommon sweetwords. In this Section, we address this issue
by exploiting two sophisticated password models (PCFG and
Markov) and smoothing techniques. Particularly, both models
follow the Zipf’s law (see Fig. 13(k) of [30]), and thus are
good at assigning monotonically decreasing probabilities to
strings/tokens to eliminate “sweetword ties”.
A. Our no-training-set password model
Before presenting our advanced-model-based experiments,
we propose a special password model for honeywords. It
exploits the fact:
if honeywords are uniformly distributed
(i.e., PrHW(·|x)= 1|T (x)|), then we can get the distribution of
passwords from the distribution of sweetwords, where T (x)
denotes the sweetword space obtainable from the sweetword
cPrPW(x) denote an instantiation of PrPW(x).
x and PrHW(x) denotes the probability that x is chosen as the
honeyword. We similarly deﬁne PrPW(x) and PrSW(x). Let
The sweetword list consists of k − 1 honeywords and one
password. Thus, the sweetword distribution PrSW(·) can be
determined by the password distribution PrPW(·) and the
honeyword distribution PrHW(·|·) by using the equation:
PrPW(y) PrHW(x|y).
PrSW(x) =
Then, we have
PrPW(x) =k PrSW(x) − (k − 1)
PrPW(y) PrHW(x|y)
∑
∑
k − 1
k
PrPW(x) +
1
k
y
y
=k PrSW(x) − (k − 1) PrPW(T (x))
=k PrSW(x) − (k − 1) PrSW(T (x))
1|T (x)|
1|T (x)| .
countSW
, we get an estimation of PrPW(x):
Since the probability of a sweetword, denoted by PrSW(x),
can generally be approximated by its empirical probability
countSW(x)
cPrPW(x) = k· countSW(x)
1|T (x)| .
As there are some sweetwords withcPrPW(·)<0, smoothing
is needed. We tested ﬁve smoothing techniques for cPrPW(x)
countSW(T (x))
−(k−1)
countSW
countSW
in Figs. 6(c) and 6(f), and results show ver5 performs the best.
·
(a) Success-number graph of PCFG-based attacks.
(b) Success-number graph of Markov-based attacks.
(c) Success-number graph of no-training-set attacks.
(d) Flatness graph of PCFG-based attacks.
(e) Flatness graph of Markov-based attacks.
(f) Flatness graph of no-training-set attacks.
Fig. 6.
training sets, with Dodonew-ts as the test set. The List password model trained on Dodonew-tr is used as the baseline.
Experiment results for attacking the tweaking-tail method in [21] by using three sophisticated password models and ﬁve different
TABLE VIII.
SUCCESS-NUMBER INFO (%) ABOUT THE
CRACKING MODELS AND FIVE DIFFERENT TRAINING SETS, UNDER THE
TWEAKING-TAIL METHOD BY USING FOUR ADVANCED PASSWORD
(TYPE-A1) “NORMALIZED TOP-PW ATTACK: 1T” ATTACK, TEST
SET=DODONEW-TS, AND T2 = 104.y
List
PCFG Markov
No-training-set
10.10% 12.45% 14.48% 13.80% (using ver5)
8.94% 12.22% 14.01% 11.06% (using ver3)
7.91% 11.15% 12.23% 10.43% (using ver4)
8.86% 10.73% 10.51% 8.87% (using ver2)
8.05% 9.59% 9.94% 1.79% (using ver1)
Dodonew-tr
Tianya
Tianya sample
Rockyou
Rockyou sample
yA value in bold means the corresponding password model performs best.
All the % are obtained by dividing the 8,129,445 Dodonew-tr accounts.
ϵ-FLAT INFO ABOUT THE TWEAKING-TAIL METHOD. ALL
TABLE IX.
THE EXPERIMENTAL SETTING ARE THE SAME WITH TABLE VIII.
No-training-set
0.3345 (using ver5)
0.2201 (using ver3)
0.2345 (using ver4)
0.2030 (using ver2)
0.1743 (using ver1)
List
0.3755 0.4666
Dodonew-tr
0.2565 0.3917
Tianya
0.2204 0.3704
Tianya sample
0.2044 0.3194
Rockyou
Rockyou sample 0.1813 0.3029
PCFG Markov
0.4063
0.3817
0.3480
0.3094
0.2753
As shown in Fig. 6, and summarized in Table VIII and Table
IX: (1) in general, the PCFG-based model PPCFG(D)(·) and the
Markov-based model PMarkov(D)(·) perform better than the List
model PD(·), when given the same training set and test set;
(2) the tweaking-tail method is 0.47+-ﬂat (see Fig. 6(d)), 9
times weaker than expected in [21]; and (3) surprisingly, our
no-training-set model PF (·) (with smoothing version 5) well
approaches the List model PD(·), indicating that A can even
perform effective attacks by just using the sweetword ﬁle F
(and needs no external training sets).
Summary. Results show that Juels-Rivest’s four methods are
much weaker under our more advanced trawling-guessing
attackers who can exploit various state-of-the-art password
models like PCFG [32] and Markov [24]. More speciﬁcally,
under the adversary model (i.e., a type-A1 attacker) assumed
by Juels and Rivest, the real passwords can be distinguished
with a success rate of 34.21%∼49.02% (see the left category
of Table X), but not the claimed 5%, with just one guess when
each user account is associated with 19 honeywords.
12
Ver1: cPrPWwithSmooth1 = max{0,cPrPW(x)};
Ver2: cPrPWwithSmooth2 = max{
Ver3: cPrPWwithSmooth3 = max{ countSW(x)
Ver4: cPrPWwithSmooth4 = max{
Ver5: cPrPWwithSmooth5 = countSW(x)
,cPrPW(x)};
,cPrPW(x)};
,cPrPW(x)};
countPW
countSW
1
countSW
1
.
countSW
B. Sophisticated password models
In the basic attacks in Sec. III, the probability of sweetwords
comes from the List model—a known (leaked) password dis-
tribution PD(·). However, every leaked password distribution
is of very limited space compared to the total password space.
For instance, the currently known largest one is the 3 billion
Yahoo leak [18], which is still far smaller than the space (about
1032) of passwords that comply with a typical policy: consists
of three kinds of characters and with 8≤len≤16. Thus, one
may conjecture that, under more sophisticated probabilistic
password models (e.g., PCFG [32] and Markov [24]), the four
methods in [21] will be even weaker. Here we follow the
recommendations in [24], and use Laplace smoothing for the
PCFG model and Backoff smoothing for the Markov model.
We now establish this conjecture. We design a series of
attacks (see Fig. 6) against the tweaking-tail method to ex-
plore the effectiveness of various password-cracking models,
including PCFG [32], Markov [24] and our above no-training-
set ones. In our Markov-based attacks, all the settings are the
same with the “Norm top-PW: smooth, 1t” in Fig. 3(a), except
for that: the known password distribution D (e.g., a leaked
password list) is ﬁrst applied to the Markov cracking model
(we use the backoff approach, see [24]), and this results in a
password distribution Markov(D), then PMarkov(D)(·) is used
instead of PD(·) to assign probabilities. We similarly denote
the PCFG-based password model to be PPCFG(D)(·) and the
no-training-set model to be PF (·). See the title of Fig. 6 for
how these models were trained and tested.
(a) Success-number graph: List vs. TarList.
(b) Success-number graph: PCFG vs. TarPCFG.
(c) Success-number graph: Markov vs. TarMarkov.
(f) Success-number graph: Markov vs. TarMarkov.
Fig. 7.
better than type-A1 ones: a clear security hierarchy appears. Sub-ﬁgure 7(f) reveals that, under a Type-A2 attacker, every method in [21] is 0.568+-ﬂat.
(d) Flatness graph: List vs. TarList.
Evaluating Juels-Rivest’s methods under type-A2 attackers, trained on PII-Dodonew-tr, tested on PII-Dodonew-ts. Type-A2 attackers perform much
(e) Success-number graph: PCFG vs. TarPCFG.
V. TARGETED GUESSING ATTACKS
In the above, we have evaluated Juels-Rivest’s four main
honeyword methods [21] under their assumed adversary model
(i.e., a type-A1 attacker). As users love to build their (real)
passwords with PII and such PII is becoming increasingly easy
to be learned by A through various means (see Sec. II-A), a
natural question arises: What’s the security of these methods
when A is further equipped with the knowledge of user PII
(i.e., under a type-A2 attacker)? We now answer this question.
We employ three targeted password-cracking models:
TarPCFG [30], TarList and TarMarkov. Here TarPCFG is just
the TarGuess-I in [30], while TarList and TarMarkov are
PII-enriched Markov model and List model, respectively. The
TarMarkov model can be converted from the Markov model
by applying the type-based PII segment matching method as
proposed in [30]. To accomplish the conversion, we only
need to incorporate the various type-based PII tags {N1, ··· ,
N7; B1, ··· , B10; A1, A2, A3; ···} deﬁned in [30] into the
alphabet (cid:6) (e.g., (cid:6) = {95 printable ASCII characters} in
[24]) of the Markov n-gram model. Then, all operations for
these type-based PII tags are the same with the original
characters in (cid:6). Note that, the PII tag N stands for name
usages, B for birthday, A for account name, and so on; The
subscript of a PII usage means a speciﬁc type but not length,
e.g., N1 stands for full name “john smith” and N2 for the
abbrev. of full name: js←“john smith”. Similarly, we
can convert the List model into the TarList model.
In our TarPCFG-based attacks, all
the settings are the
same with the “Norm top-PW: smooth, 1t” in Fig. 3(a),
except for that: the known password distribution D (e.g., a
leaked password list) is ﬁrst used as the training set to the
TarPCFG password model [30], and this results in a password
distribution PTarPCFG(D). Then, PTarPCFG(D)(·) is used instead
of PD(·) to assign sweetword probabilities. We similarly
denote the TarMarkov model to be PTarMarkov(D)(·) and the
TarList model to be PTarList(·). Note that, each password model
is trained on PII-Dodonew-tr and tested on PII-Dodonew-ts.
Fig. 7 compares the effectiveness of type-A1 and type-A2
TABLE X.