### Evaluation and Observations of Censorship Circumvention Approaches

**Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18, 2021 at 12:11:18 UTC from IEEE Xplore. Restrictions apply.**

#### A. General Observations

The provided tables highlight several key observations:

1. **Evaluation Goals and Metrics:**
   - Publications generally include more evaluation goals and metrics compared to deployed tools.
   - Evaluations share common goals but vary significantly in the metrics used or even the goals mentioned. These differences may be due to varying expectations about user needs and the perceived importance of criteria.
   - Ideally, evaluations should explicitly mention unmet goals to facilitate easier comparison between approaches. It is suspected that developers often focus on criteria where their approach performs well, as evidenced by the small number of unchecked boxes for metrics in Table IV.

   **Recommendation 1:**
   - The evaluation of an approach should be guided by the needs and censorship context of the intended users, rather than the capabilities of the approach itself.

2. **Metrics and Comparison:**
   - There is a lack of consensus on which metrics to use and how they map to specific goals, making comparisons difficult.
   - No existing metric comprehensively evaluates undeployed approaches. For example, the number of users, a reasonable holistic metric of success, cannot be used for undeployed approaches since it requires the approach to be already in use.

   **Research Gap 2:**
   - Prior evaluations lack holistic metrics for undeployed approaches.

#### B. Criteria Related to Attacks

Evaluations of circumvention approaches often (nearly 2/3) focus on criteria related to attacks. Academic papers typically address real attacks on circumvention methods, but they tend to emphasize more complex, hypothetical attacks.

- **Evaluation by Techniques Used:**
  - Table IV shows a large number of metrics starting with "Use," which are binary indicators of whether an approach employs a specific technique (e.g., authentication or encryption) to avoid certain types of exploits.
  - For example, the metric "Use popular hosts" suggests a different metric: "Blocking requires disrupting a popular host." This new metric does not presuppose any specific mechanism and makes cross-approach comparison easier. It also considers all vulnerabilities rather than focusing on a single technique.

   **Research Gap 3:**
   - Approaches should be evaluated based on the properties they provide rather than the techniques they use.

#### C. Other Criteria

While the paper focuses on evaluation related to censorship attacks, other criteria (detailed in Table VII in the appendix) also merit discussion.

- **Ability to Deploy:**
  - Some approaches require advocates to consume resources to maintain a forwarder (e.g., Psiphon [41]). In others, advocates pay for others to maintain it (e.g., Meek [26] and CloudTransport [36]).
  - Rarely, the forwarder might be found and free, but the advocate still needs to maintain the system (e.g., CacheBrowser [50]).

   **Research Gap 4:**
   - Only 6 out of 33 papers mention the costs for advocates maintaining the system.

- **Usability:**
  - Previous research and deployed approaches have examined various usability metrics, such as cost to user, ease of setup, and usage flexibility.
  - Some tools, like Psiphon [41], Ultrasurf [39], and Facet [34], do not require installation, while others, like Lantern, require a small download.
  - Usability is more likely to be evaluated in deployed tools than in undeployed research proposals.

   **Research Gap 5:**
   - Only 9 out of 33 research papers mentioned the goal of usability, and none assessed it with metrics involving actual users.

#### VII. Comparing Resistance Criteria to Real Censors

We now examine criteria assessing an approach's resistance to censors. We aim to classify vulnerabilities and exploits found in both real attacks and academic papers to better understand their relationship and practical implications.

- **Phase Exploited:**
  - Real-world censors exploit features of the channel setup or identifier management (IDM). They look for inherent features during setup or analyze all packets, focusing on the initial phase to minimize monitoring time.
  - We conjecture that censors focus on setup and IDM because this traffic shows little variation across users, unlike channel usage, which varies based on individual use.

   **Recommendation 3:**
   - Circumventors should focus more on vulnerabilities in the channel setup rather than channel usage.

- **Nature of Exploits:**
  - Many academic papers include attacks on the channel setup, but they often deal with features requiring analysis of channel usage. Additionally, many exploits target subsidiary behaviors, which real censors ignore.
  - This discrepancy suggests that research is running ahead of practice. For example, Houmansadr et al. showed that mimicry-based approaches can be fingerprinted by subsidiary behavior, but these approaches have had little impact in practice, making the attacks unnecessary for current censors.

**Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18, 2021 at 12:11:18 UTC from IEEE Xplore. Restrictions apply.**