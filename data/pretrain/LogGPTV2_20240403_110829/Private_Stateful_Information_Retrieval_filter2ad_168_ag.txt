Conference on the Theory and Applications of Cryptographic Techniques, pages 223–238. Springer, 1999.
[43] S. Patel, G. Persiano, M. Raykova, and K. Yeo. PanORAMa: Oblivious RAM with logarithmic overhead.
Cryptology ePrint Archive, Report 2018/373, 2018. https://eprint.iacr.org/2018/373.
[44] M. P˘atra¸scu and E. D. Demaine. Tight bounds for the partial-sums problem. In Proceedings of the
ﬁfteenth annual ACM-SIAM symposium on Discrete algorithms, pages 20–29. Society for Industrial and
Applied Mathematics, 2004.
[45] I. Reed. A class of multiple-error-correcting codes and the decoding scheme. Transactions of the IRE
Professional Group on Information Theory, 4(4):38–49, 1954.
[46] T. Ristenpart and S. Yilek. The mix-and-cut shuﬄe: Small-domain encryption secure against n queries.
In R. Canetti and J. A. Garay, editors, Advances in Cryptology – CRYPTO 2013: 33rd Annual Cryp-
tology Conference, Santa Barbara, CA, USA, August 18-22, 2013. Proceedings, Part I, pages 392–409,
2013.
[47] D. Stinson, R. Wei, and M. B. Paterson. Combinatorial batch codes. Advances in Mathematics of
Communications, 3(1):13–27, 2009.
[48] E. G. Straus. Addition chains of vectors (problem 5125). In American Mathematical Monthly, volume 70,
pages 806–808, 1964.
[49] J. Zhang, W. Zhang, and D. Qiao. MU-ORAM: Dealing with stealthy privacy attacks in multi-user
data outsourcing services. IACR Cryptology ePrint Archive, 2016:73, 2016.
A Cost of OCP
√
For our experiment, we consider randomly chosen constraint subsets of size k = 2
To evaluate the cost of our OCP scheme described in Section 4, we perform benchmarks to measure the CPU
costs of executing GenerateSeed and ExtractPartition as well as the size of the seed transmitted between the
client and server by our PSIR scheme.
n for various values
of database sizes n ∈ {216, 218, 220}. We report results on the CPU costs for executing OCP.GenerateSeed
to construct the succinct representation and for executing OCP.ExtractPartition to construct the explicit
partition. The experiments are run 100 times with the means reported below.
Database Size (n)
Client CPU (ms)
GenerateSeed
Server CPU (ms)
ExtractPartition
Network (KB)
Seed Size
65,536
262,144
1,048,576
37.39
124.18
511.80
23.31
109.23
512.27
10
20
40
We note that the network costs of OCP is signiﬁcantly better than the trivial algorithm of explicitly describing
the entire partition. For example, the communication required to explicitly send the partition for n = 220
database records is approximately 2.5 MB, which is signiﬁcantly larger than the 40 KB used by our OCP
scheme.
26
B Chernoﬀ Bounds
Chernoﬀ Bounds are a concentration equality for a sequence of many independent events with binary random
variable outcomes.
Theorem 18 (Chernoﬀ Bounds). Let X = X1 + . . . + Xn where Xi = 1 with probability pi and Xi = 0
with probability 1 − pi and all Xi are independent. Let µ = E[X] = p1 + . . . + pn. Then,
1. Pr[X ≥ (1 + )µ] ≤ exp(− 2µ
2+ ).
2. Pr[X ≤ (1 − )µ] ≤ exp(− 2µ
2 ).
We get the following corollary for restricted parameters.
Theorem 19. Let X = X1 + . . . + Xn where Xi = 1 with probability pi and Xi = 0 with probability
1 − pi and all Xi are independent. Let µ = E[X] = p1 + . . . + pn. For constant 0 <  < 1 and if
µ = E[X] = p1 + . . . + pn = Ω(log2 n), then
1. Pr[X ≥ (1 + )µ] = negl(n).
2. Pr[X ≤ (1 − )µ] = negl(n).
C PSIR Amortization
In this section, we present several useful techniques for distributing the cost of PSIR.UpdateState for some
important settings.
C.1 Online Work to Oﬄine Processing
One interpretation of our PSIR scheme can be the ability to oﬄoad the online cost of queries to oﬄine
preprocessing. For example, let’s suppose that a client will only query 5 times per day. During the night
before (or any other oﬀ-peak periods), the client will gather a suﬃcient amount of side information using
a PBSR scheme, which will be used when performing queries online the next day. By viewing the PBSR
scheme as oﬄine preprocessing, we are able to reduce the cost of online queries. As a result, an PSIR scheme
can be viewed as a technique to move online work to oﬄine processing.
C.2 Worse Case to Average Case Cost
A natural theoretical question regularly asked is whether the worst case of a query may be reduced to be
equivalent to the average (amortized) cost over a large number of queries. By evenly distributing costs
over queries, there will be no unexpected jumps in resource requirements or unexpected latency increases.
Furthermore, clients and the server do not need to plan for resource allocations that are ever too large.
Reducing worst case cost to average case costs in our PSIR scheme reduces to being able to distribute the
costs of the underlying PBSR scheme over many queries. The costs of StreamPBSR, the scheme used in our
instantiations in Section 7, can be trivially distributed over any set of (1− )c queries. The client will simply
keep a pointer to the last database record downloaded. For each query, the client will perform exactly
(1−)c
work of StreamPBSR. This involves downloading
(1−)c records and adding them to the appropriate side
information. Note, this requires the client to store two sets of side information. One is being used to service
queries and the other set is being built by StreamPBSR to be used once the current set of side information
is exhausted.
n
1
27
D Oblivious Constrained Partition
We present an OCP scheme that only requires the client to store O(k) integers instead of O(n/k + k) integers
required by the OCP scheme of Section 4.
D.1 Online Partial Sums Data Structure
In this section, we present previous results on online partial sums data structure.
Deﬁnition 20 (Online Partial Sums Data Structure). An online partial sums data structure PartialSums
consisting of the following algorithms:
• D ← PartialSums.Init(v1, . . . , vn): an algorithm that takes as input an array of n values, v1, . . . , vn, and
outputs a database D for the values v1, . . . , vn.
• D(cid:48) ← PartialSums.Update(D, i, δ): an algorithm that takes as input an index i ∈ [n] and updates
vi ← vi + δ in D and outputs a new version of the database, D(cid:48).
• s ← PartialSums.Sum(D, i): an algorithm that takes as input an index i ∈ [n] and outputs the sum
s ← v1 + . . . + vi.
• i ← PartialSums.Select(D, v): an algorithm that takes as input a value v and outputs i such that
PartialSums.Sum(i − 1) < v ≤ PartialSums.Sum(i).
Fenwick [20] presented an online partial sums data structure without the Select operation, which required
O(log n) operations using O(n) storage. Using binary search, Select could be done using O(log2 n) operations.
P˘atra¸scu and Demaine [44] present tight bounds for an online partial sums data structure that supports all
operations in O(log n) operations using O(n) storage.
D.2 Space-Eﬃcient OCP Scheme
In our new construction, we select a random subset by using succinctly describable pseudo-random permu-
tation [36] instead of a hash function. Speciﬁcally, for pseudo-random family of permutations γ(·,·) over
[n], we pick a random seed K and output the set T = { γ(K, 1), . . . , γ(K, k)}. Note that now we have
direct access to the set T ; that is, to determine the r-th element of T , only the value γ(K, r) needs to be
computed. The previous subset generation algorithm from Section 4 required computing all of T1, . . . , Tr−1
before computing Tr. As a result, we do not need to keep all elements of T stored to determine the r-th
element. This will completely removes the O(n/k) storage requirement.
However, we now require a more complex data structure to maintain the ranks of the unused items in
the constraint subset since the generated subsets will not be explicitly stored. In particular, we will use
online partial sums data structures, described in Appendix D.1, to store ranks. The items of the constraint
subset are stored in sorted order such that the partial sum up to an index i will be equal to the rank of i-th
largest member of the constraint subset. When initializing the data structure, we will store the diﬀerences
between adjacent elements of the sorted constraint subset to ensure that rank can be retrieved by performing
a partial sum query. Removing an element from the set of unused elements requires decreasing the rank of
all constraint subset elements that are larger than the removed element by one. This can be achieved by
simply subtracting one from the index of the smallest item in the constraint subset that is larger than the
element to be removed. As a result, the rank of all constraint subset elements larger will also decrease by one.
Finding the smallest element from the constraint subset larger than the removed element requires a single
PartialSums.Select operation while retrieving the rank and updating an entry requires a single PartialSums.Sum
and PartialSums.Update operation respectively. The entire data structure only requires storing a single entry
for each constraint subset item meaning storage requirements are O(k).
Construction 21. We describe a pseudorandom partition with a ﬁxed partition OCP = (OCP.GenerateSeed, OCP.
ExtractPartition).
28
OCP.GenerateSeed. This algorithm constructs a key K which describes a partitioning of [n] into n
such S is one of the parts where n, k and S are all inputs.
K ← OCP.GenerateSeed(1λ, 1n, S)
k parts
1. Client locally sorts S and sets k = |S|.
2. Set v1 = S[1];
3. For i = 2, . . . , k, set vi = S[i] − S[i − 1].
4. Client locally constructs online partial sums data structure DSum ← PartialSums.Init(v1, . . . , vk). Note
that, as a result, it holds that PartialSums.Sum(DSum, i) = S[i] for all i ∈ [k].
5. Randomly select r ∈ [n/k] and a permutation τ over [k]. The algorithm will embed S into the r-th
row of the matrix in the order described by τ .
6. Initialize (cid:96) ← 1.
7. While (cid:96) ≤ k:
(a) Initialize rank(cid:96) ← PartialSums.Sum(τ ((cid:96))).
(b) Set unused := n − (n/k)((cid:96) − 1).
(c) Randomly select a λ-bit seed for a pseudorandom permutation γ over the set [unused].
(d) Initialize pivot ← γ−1(rank(cid:96)) − r.
(e) For i = pivot, . . . , pivot + (n/k) − 1 mod unused:
i. Execute j ← PartialSums.Select(DSum, γ(i)).
ii. If PartialSums.Sum(DSum, j) = γ(i) and γ(i) (cid:54)= rank(cid:96) then:
A. Go back to Step 7c.
(f) For i = pivot, . . . , pivot + (n/k) − 1 mod unused:
i. Execute j ← PartialSums.Select(DSum, γ(i)).
ii. Execute DSum ← PartialSums.Update(DSum, j,−1).
(g) Initialize γ(cid:96) ← γ.
(h) Initialize pivot(cid:96) ← pivot.
(i) Increment (cid:96) by 1.
8. Return description of partition (γ1, . . . , γk, pivot1, . . . , pivotk).
OCP.ExtractPartition. This algorithm takes as input the description of a partition and expands it into an
explicit description of the partition.
(P1, . . . , Pn/k) ← OCP.ExtractPartition(γ1, . . . , γk, pivot1, . . . , pivotk).
1. Construct a vector of n integers, v = (1, . . . , 1).
2. Execute DSum ← PartialSums.Init(v).
3. For i = 1, . . . , n/k:
i. Initialize (cid:96)j ← PartialSums.Select(γi(pivoti + j)).
(a) For j = 1, . . . , k:
(b) Set Pi ← {(cid:96)j}j∈[k].
(c) For j = 1, . . . , k:
i. Execute DSum ← PartialSums.Update(DSum, (cid:96)j,−1).
4. Return (P1, . . . , Pn/k).
29
E Private Batched Sum Retrieval
In this section, we present several PBSR schemes that have better network costs than StreamPBSR. However,
each of these schemes introduce signiﬁcant CPU costs prohibiting them from practical use.
E.1 Constant Bandwidth From Homomorphic Encryption
We present a constant bandwidth PBSR scheme built from homomorphic encryption that has both an
homomorphic plaintext absorption and homomorphic addition (see Section 7 for a more detailed explanation).
This scheme will upload c vectors of n homomorphic encryptions of either k−1 encryptions of 1 corresponding
to the addends and all remaining encryptions are 0. For each vector, the server will simply absorb each
database record into the corresponding homomorphic encryption and homomorphically add all ciphertexts
together. Once receiving the ﬁnal ciphertext, the client decrypts to retrieve the sum of its k − 1 chosen
records. This technique requires only O(c) records to download, O(n) ciphertext to upload and O(nc) server
computation. This technique is useful when records are very large. The number of records downloaded is
minimized at the cost of larger uploads of ciphertexts of size λ.
E.2 Private Batched Retrieval
Private batched retrieval is a generalization of private information retrieval where any number of blocks
can be downloaded privately instead of just a single block as described in private information retrieval.
Formally, private batched retrieval considers downloading m blocks from a database of n blocks, where each
block consists of B bits with security parameter λ. Private batched retrieval has been studied by many
previous works [7, 22, 26, 30]. We now present BatchPBSR using any private batched retrieval scheme.
Construction 22. (O1, . . . , Oc) ← BatchPBSR(S1, . . . , Sc)
1. Initialize O1 ← 0, . . . , Oc ← 0.
2. Compute S = S1 ∪ . . . ∪ Sc. If |S| < ck, pad with any arbitrary set of extra blocks until S is of size ck.
3. Execute a private batched retrieval scheme to download S.
4. For all Bi ∈ S:
(a) For all j ∈ [c] such that i ∈ Sj:
i. Oj ← Oj + Bi
5. Return (O1, . . . , Oc).
Theorem 23. BatchPBSR is a private batched sum retrieval scheme according to Deﬁnition 5.
In particular, we can use the work of Groth et al. [26] which presents a private batched retrieval with
information theoretically optimal communication complexity of O(m log n + λ + mB) to retrieve m records.
A more practical approach might use the private batched retrieval from cuckoo hashing by Angel et al. [7].
In either case, BatchPBSR is more communication eﬃcient than StreamPBSR but at the cost of more com-
putational costs.
E.3 Batch Codes and Homomorphic Encryption
Batch codes [7, 8, 29, 30, 47] are a technique used by many private batched retrieval to reduce the problem
into running a private information retrieval scheme. Formally, a batch code is parameterized by the values
(n, N, k, m, t). A database of n blocks, denoted by x, is encoded using the encoding function C(x) into k
buckets such that a total number of N blocks appear in all k buckets. Batch codes ensure the following
for any subset S ⊆ [n] with at most m items, the set {Bi}i∈S may be retrieved by
important property:
30
reading at most t items in each of the k buckets. The majority of works on batch codes [30, 7] consider the
case t = 1. In particular, we will use cuckoo batch codes described by Angel et al. [7].
We now present BatchCodePBSR, which will use a (n, n(cid:48) = O(n), m(cid:48) = O(m), m, 1)-batch code as well
as a private information retrieval scheme using additively homomorphic encryption [31, 42, 19, 14, 13]. We
assume that the database has already been encoded using the chosen batch code.
Construction 24. (O1, . . . , Oc) ← BatchCodePBSR(S1, . . . , Sc).
1. Let S = S1, . . . , Sc and we set m = ck as the number of blocks we wish to retrieve.
2. Perform a PIR request to each of the m(cid:48) buckets to retrieve the block from the bucket necessary
to decode S. Do not download the results of the PIR query, instead store them on the server as
r1, . . . , rO(m). As a result, each of (O1, . . . , Oc) is now a sum of a subset of the results of the O(m)
PIR queries.
3. For i = 1, . . . , c:
(a) Construct a vector (e1, . . . , eO(m)) where ej is an encryption of 1 if and only if Oi requires the
block from the i-th bucket as part of the sum and ej is an encryption of 0 otherwise.
(b) Upload (e1, . . . , eO(m)).
(c) Server homomorphically computes Oi = e1 · r1 + . . . + em(cid:48)rm(cid:48) and returns Oi to the client.
(d) Client decrypts Oi.
4. Return (O1, . . . , Oc).
31