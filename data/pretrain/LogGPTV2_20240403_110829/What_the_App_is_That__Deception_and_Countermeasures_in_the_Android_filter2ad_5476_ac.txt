TABLE II: Component types, flags, and launchMode values tested
by our tool
Component type
Activity, Service, Content Provider, Broadcast Receiver
launchMode
attribute
startActivity flags
standard, singleTop, singleTask, singleInstance
MULTIPLE TASK, NEW TASK, CLEAR TASK,
CLEAR TOP, PREVIOUS IS TOP,
REORDER TO FRONT, SINGLE TOP,
TASK ON HOME
a remote location. To be stealthier, it informs Android that it should
not be listed in the Recent Apps view.
We also developed a proof-of-concept malicious app that covers
and mimics the home screen of a device, and demonstration videos.
The displayed attack uses the “immersive” fullscreen functionality,
but it can be easily adapted to use the “inescapable” fullscreen mode
described in Section III-A3.
IV. STATE EXPLORATION OF THE ANDROID GUI API
We have developed a tool to study how the main Android
GUI APIs can be used to mount a GUI confusion attack. The tool
automatically performs a full state exploration of the parameters
of the startActivity API, which can be used to open Activities on
top of others (including Activities of different apps). Also, our tool
systematically explores all Window-drawing possibilities, to check
if it is possible to create Windows that:
1) entirely cover the device’s screen;
2) leave the user no way to close them or access the navigation bar.
In the following two sections, we will explain our tool in detail,
and we will show what it has automatically found.
A. Study of the startActivity API
First, using the documentation and the source code as references,
three different aspects influence how a
we determined that
newly-started Activity is placed on the Activities’ stack:
• The type of Android component calling startActivity.
• The launchMode attribute of the opened Activity.
• Flags passed to startActivity.
Table II lists the possible Android component types, all the
relevant flags and launchMode values an app can use.
Our tool works by first opening a “victim” app that controls the
top Activity. A different “attacker” app then opens a new Activity
calling the startActivity API with every possible combination of the
listed launch modes and flags. This API is called in four different
code locations, corresponding to the four different types of Android
components. Our tool then checks if the newly-opened Activity has
been placed on top of the “victim” app, by taking a screenshot and
analyzing the captured image.
Our tool found, in Android version 4.4, the following three
conditions under which an Activity is drawn on top of every other:
1) The Activity is opened by calling the startActivity API from a
Service, a Broadcast Receiver, or a Content Provider and the
NEW TASK flag is used.
935935936
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:09:15 UTC from IEEE Xplore.  Restrictions apply. 
TABLE III: Window types and flags. Flags in italics are only
available starting from Android version 4.4, whereas TYPEs in
bold require the SYSTEM ALERT WINDOW permission.
TYPEs
Layout flags
System-UI
Visibility flags
TOAST, SYSTEM ERROR, PHONE,
PRIORITY PHONE, SYSTEM ALERT,
SYSTEM OVERLAY
IN SCREEN, NO LIMITS,
HIDE NAVIGATION, FULLSCREEN,
LAYOUT HIDE NAVIGATION,
LAYOUT FULLSCREEN, IMMERSIVE,
IMMERSIVE STICKY
2) The Activity is opened by calling the startActivity API from
another Activity and it has the singleInstance launch mode.
different from singleTask.
3) The Activity is opened by calling the startActivity API from
another Activity and one of the following combinations of
launch modes and flags is used:
• NEW TASK and CLEAR TASK flags.
• NEW TASK and MULTIPLE TASK flags, and launch mode
• CLEAR TASK flag and singleTask launch mode.
We are only aware of one previous paper [6] that (manually)
studies the behavior of this API for different parameters and under
different conditions. Interestingly, the authors do not find all the
conditions that we discovered. This underlines how the complexity
of the Android API and omissions in the official documentation
are prone to creating unexpected behaviors that are triggered using
undocumented combinations of flags and APIs. Such behaviors
are hard to completely cover through manual investigation. Hence,
our API exploration tool can effectively help Android developers to
detect these situations. As one example, we will now discuss how our
tool revealed the existence of an “inescapable” fullscreen possibility.
B. Study of “inescapable” fullscreen Windows
We first checked the documentation and source code to
determine the three different ways in which an app can influence
the appearance of a Window that are relevant to our analysis:
• Modifying the Window’s TYPE.
• Specifying certain flags that determine the Window’s layout.
• Calling the setSystemUiVisibility API with specific flags to
influence the appearance and the behavior of the navigation bar
and the status bar.
Table III lists all the relevant flags and Window types an app can use.
Our tool automatically spawns Windows with every possible
combination of the listed types and flags. After spawning each
Window, it injects user input that should close a fullscreen Window,
according to the Android documentation (e.g., a “slide” touch from
the top of the screen). It then checks if, after the injection of these
events, the Window is still covering the entire screen, by taking a
screenshot and analyzing the captured image.
Using our tool we were able to find ways to create an
“inescapable” fullscreen Window in Android 4.3, 4.4 and 5.0, which
we will now briefly describe.
In particular, a Window of type SYSTEM ERROR created with
the flag NO LIMITS, can cover the device’s entire screen in Android
4.3. To specifically address this problem, a patch has been committed
in the Android code before the release of the version 4.4. This patch
limits the position and the size of a Window (so that it cannot cover
the navigation bar) if it has this specific combination of type and flag.
However, this patch does not cover all the cases. In fact, the
“immersive” fullscreen mode introduced in Android 4.4 opens
additional ways to create “inescapable” fullscreen Windows,
such as using the SYSTEM ERROR type and then calling the
setSystemUiVisibility API to set the LAYOUT HIDE NAVIGA-
TION, HIDE NAVIGATION, LAYOUT FULLSCREEN, and
IMMERSIVE STICKY flags. We verified that the same parameters
create an “inescapable” fullscreen Window in Android 5.0 as well.
It is important to notice that all the ways we discovered to
create “inescapable” fullscreen Windows require using the SYS-
TEM ERROR type. To fully address this problem, we propose re-
moving this type or restricting its usage only to system components.
V. DETECTION VIA STATIC ANALYSIS
We developed a static analysis tool to explore how (and whether)
real-world apps make use of the attack vectors and enhancing
techniques that we previously explained in Section III. Our goals
with this tool are two-fold:
1) Study if and how the techniques described in Section III are used
by benign apps and/or by malicious apps, to guide our defense
design.
2) Automatically detect potentially-malicious usage of such
techniques.
A. Tool description
Our tool takes as input an app’s apk file and outputs a summary
of the potentially-malicious techniques that it uses. In addition, it
flags an app as potentially-malicious if it detects that the analyzed
app has the ability to perform GUI confusion attacks.
Specifically, it first checks which permissions the app requires
in its manifest. It then extracts and parses the app’s bytecode,
and it identifies all the invocations to the APIs related to the
previously-described attack techniques. Then, the tool applies
backward program slicing techniques to check the possible values
of the arguments for the identified API calls. The results of the static
analyzer are then used to determine whether a particular technique
(or a combination of them) is used by a given application. Finally,
by analyzing the app’s control flow, it decides whether to flag it as
(potentially) malicious.
In this section, we will discuss the static analyzer, the attack tech-
niques that we can automatically detect, and the results we obtained
by running the tool on a test corpus of over two thousand apps. We
would like to note that the implementation of the basic static analysis
tool (namely, the backward program slicer) is not a contribution
of this paper: We reused the one that Egele et al. developed for
Cryptolint [18], whose source code was kindly shared with us.
1) Program slicer: The slicer first decompiles the Dalvik
bytecode of a given app by using Androguard [19]. It then constructs
an over-approximation of the application’s call graph representing
all possible method invocations among different methods in the
analyzed app. Then, a backward slicing algorithm (based on [20])
is used to compute slices of the analyzed app. Given an instruction
I and a register R, the slicer returns a set of instructions that
936936937
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:09:15 UTC from IEEE Xplore.  Restrictions apply. 
can possibly influence the value of R. The slice is computed by
recursively following the def-use chain of instructions defining R,
starting from instruction I. If the beginning of a method is reached,
the previously-computed call graph is used to identify all possible
calling locations of that method. Similarly, when a relevant register
is the return value of another method call, the backward slicer
recursively continues its analysis from the return instruction of the
invoked method, according to the call graph.
As most of the static analysis tools focusing on Android, the
slicer may return incomplete results if reflection, class loading, or
native code are used. Dealing with such techniques is outside the
scope of this project.
2) Detecting potential attack techniques: In the following, we
describe how our tool identifies the different attack vectors and
enhancing techniques.
Draw on top. We detect if the addView API, used to create
custom Windows, is invoked with values of the TYPE parameter
that give to the newly-created Window a Z-order higher than that
of the top-activity Window.
In addition, to detect potentially-malicious usage of a toast
message, we first look for all the code locations where a toast
message is shown, and then we use the slicer to check if the setView
API is used to customize the appearance of the message. Finally,
we analyze the control flow graph of the method where the message
is shown to detect if it is called in a loop. In fact, to create a toast
message that appears as a persistent Window, it is necessary to call
the show API repeatedly.
App Switch. Our tool checks if:
• The startActivity API is used to open an Activity that will be
shown on top of others. As we already mentioned, three aspects
influence this behavior: the type of the Android component from
which the startActivity API is called, the launchMode attribute of
the opened Activity, and flags set when startActivity is called. We
determine the first aspect by analyzing the call graph of the app,
the launchMode is read from the app’s manifest file, whereas
the used flags are detected by analyzing the slice of instructions
influencing the call to the startActivity API.
• The moveTaskToFront API is used.
• The killBackgroundProcesses API is used.
We do not use as a feature the fact that an app is intercepting the
back or power buttons, as these behaviors are too frequent in benign
apps and, being passive methods, they have limited effectiveness
compared to other techniques.
Fullscreen. Our tool checks if the setUiVisibility API is called
with flags that cause it to hide the navigation bar.
Getting information about the device state. Our tool checks
if:
• The getRunningTasks API is used.
• The app reads from the system log. Specifically, since the native
utility logcat is normally used for this purpose, we check if
the Runtime.exec API is called specifying the string “logcat” as
parameter.
• The app accesses files in the /proc file system. We detect this by
looking for string constants starting with “/proc” within the app.
We did not use as a feature the fact that an app is a repackaged
version of another, as its usage, even if popular among malware, is
not necessary for GUI confusion attacks. If desired, our system can
be completed with detection methods as those presented in [13], [14].
During our study, we found that some apps do not ask (on
installation) for the permissions that would be necessary to call
certain APIs for which we found calls in their code. For instance,
we found some applications that contain calls to the getRunningTask
API, without having the GET TASKS permission. The reason
behind this interesting behavior is that this API is called by library
code that was included (but never used) in the app.
In the threat model we consider for this paper, we assume that
the Android security mechanisms are not violated. So, calling an
API that requires a specific permission will fail if the app does not
have it. For this reason, we do not consider an app as using one of
the analyzed techniques if it lacks the necessary permissions.
Since the version 5.0 of Android has been released too close to
the time of the writing of this paper, we expect only a very limited
(and not statistically significant) number of applications using
techniques introduced in this version. For this reason, we decided
not to implement the detection of the techniques only available in
Android 5.0.
App classification. We classify an app as suspicious if the
following three conditions hold:
1) The app uses a technique to get information about the device
state.
2) The app uses an attack vector (any of the techniques in the Draw
on top, App Switch, Fullscreen categories)
3) There is a path in the call graph of the app where Condition 1
(check on the running apps) happens, and then Condition 2 (the
attack vector) happens.
Intuitively, the idea behind our classification approach is that, to
perform an effective attack, a malicious app needs to decide when to
attack (Condition 1) and then how to attack (Condition 2). Also, the
check for when an attack should happen is expected to influence the
actual launch of this attack (hence, there is a control-flow dependency
of the attack on the preceding check, captured by Condition 3).
It is important to note that our tool (and the classification rules)
are designed to identify the necessary conditions to perform a GUI
confusion attack. That is, we expect our tool to detect any app
that launches a GUI confusion attack. However, our classification
rules are not sufficient for GUI confusion attacks. In particular, it
is possible that our tool finds a legitimate app that fulfills our static
analysis criteria for GUI confusion attacks. Consider, for example,
applications of the “app-locker” category. These apps exhibit a
behavior that is very similar to the attacks described in Section III.
They can be configured to “securely lock” (that is, disable) certain
other apps unless a user-defined password is inserted. To this end,
they continuously monitor running applications to check if one of
the “locked” apps is opened and, when this happens, they cover
it with a screen asking for an unlock password. At the code level,
there is no difference between such apps and malicious programs.
The difference is in the intent of the program, and the content shown
to users when the app takes control of the screen.
We envision that our tool can be used during the market-level vet-
ting process to spot apps that need manual analysis since they could
be performing GUI confusion attacks. App-lockers would definitely
need this analysis to check whether they are behaving according to
their specification. In the following evaluation, we do not count app-
lockers and similar programs as false positives. Instead, our system
937937938
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:09:15 UTC from IEEE Xplore.  Restrictions apply. 
has properly detected an app that implements functionality that is
similar to (and necessary for) GUI confusion attacks. The final deci-
sion about the presence of a GUI confusion attack has to be made by
a human analyst. The reason is that static code analysis is fundamen-
tally unable to match the general behavior of an app (and the content
that it displays) to user expectations. Nonetheless, we consider our
static analysis approach to be a powerful addition to the arsenal of
tools that an app store can leverage. This is particularly true under the
assumption that the number of legitimate apps that trigger our static
detection is small. Fortunately, as shown in the next section, this
assumption seems to hold, considering that only 0.4% of randomly
chosen apps trigger our detection. Thus, our tool can help analysts to
focus their efforts as part of the app store’s manual vetting process.
One possibility to address the fundamental problem of static code
analysis is to look at the app description in the market6. However,
this approach is prone to miss malicious apps, as cybercriminals
can deceive the detection system with a carefully-crafted description
(i.e., disguising their password-stealer app as an app-locker).
A second possibility to address this fundamental problem
is to devise a defense mechanism that empowers users to make
proper decisions. One proposal for such a defense solution is based