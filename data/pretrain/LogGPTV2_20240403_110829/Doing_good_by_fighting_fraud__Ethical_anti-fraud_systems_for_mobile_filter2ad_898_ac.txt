concert with card tampering detection to scan both sides
of the card.
A. Threat model
In our threat model, our goal is to reduce ﬁnancial fraud
while ensuring that all users can pass our challenge. Our focus
is on challenges that apps can use to verify that people possess
a genuine credit card.
We assume that the attacker has stolen credit card creden-
tials (e.g., the card number and billing ZIP code), but does not
possess the real credit card.
B. Architecture
To scan cards and verify that they are genuine, Daredevil
asks users to scan the front of their card and the back. This
makes Daredevil ﬂexible to verify a wide range of card designs
where meaningful information can be on either side of the
card. Scanning both sides also provides more data for us to
detect signs of tampering than if we scan only a single side.
Our checks inspect individual card sides to ensure that they
are genuine, as well as combining information from both sides
to make sure that it is consistent.
However, scanning both sides of the card complicates the
machine learning aspects of verifying a card. First, credit cards
are free to print design elements on either side. Second, users
(and some of the authors) are unaware of which side of the
card is the front versus the back. Therefore, Daredevil must
be ﬂexible enough to pull out the appropriate information to
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:14:08 UTC from IEEE Xplore.  Restrictions apply. 
1627
(cid:11)(cid:20)(cid:12)(cid:3)(cid:50)(cid:83)(cid:72)(cid:81)(cid:3)(cid:70)(cid:68)(cid:80)(cid:72)(cid:85)(cid:68)(cid:70)(cid:68)(cid:85)(cid:71)(cid:3)(cid:71)(cid:72)(cid:87)(cid:72)(cid:70)(cid:87)(cid:76)(cid:82)(cid:81)(cid:3)(cid:14)(cid:3)(cid:50)(cid:38)(cid:53)(cid:3)(cid:85)(cid:88)(cid:81)(cid:81)(cid:76)(cid:81)(cid:74)(cid:11)(cid:21)(cid:12)(cid:3)(cid:38)(cid:72)(cid:81)(cid:87)(cid:72)(cid:85)(cid:72)(cid:71)(cid:3)(cid:70)(cid:68)(cid:85)(cid:71)(cid:3)(cid:76)(cid:80)(cid:68)(cid:74)(cid:72)(cid:86)(cid:3)(cid:70)(cid:82)(cid:79)(cid:79)(cid:72)(cid:70)(cid:87)(cid:72)(cid:71)(cid:3)(cid:73)(cid:82)(cid:85)(cid:3)(cid:76)(cid:81)(cid:73)(cid:72)(cid:85)(cid:72)(cid:81)(cid:70)(cid:72)(cid:11)(cid:22)(cid:12)(cid:3)(cid:38)(cid:82)(cid:79)(cid:79)(cid:72)(cid:70)(cid:87)(cid:3)(cid:50)(cid:38)(cid:53)(cid:3)(cid:85)(cid:72)(cid:86)(cid:88)(cid:79)(cid:87)(cid:86)(cid:3)(cid:14)(cid:3)(cid:89)(cid:82)(cid:87)(cid:76)(cid:81)(cid:74)(cid:3)(cid:73)(cid:82)(cid:85)(cid:3)(cid:72)(cid:85)(cid:85)(cid:82)(cid:85)(cid:3)(cid:70)(cid:82)(cid:85)(cid:85)(cid:72)(cid:70)(cid:87)(cid:76)(cid:82)(cid:81)(cid:11)(cid:23)(cid:12)(cid:3)(cid:48)(cid:82)(cid:85)(cid:72)(cid:3)(cid:73)(cid:85)(cid:68)(cid:88)(cid:71)(cid:3)(cid:80)(cid:82)(cid:71)(cid:72)(cid:79)(cid:86)(cid:27)(cid:17)(cid:24)(cid:86)(cid:3)(cid:82)(cid:81)(cid:3)(cid:68)(cid:89)(cid:72)(cid:85)(cid:68)(cid:74)(cid:72)(cid:20)(cid:17)(cid:24)(cid:86)(cid:56)(cid:83)(cid:3)(cid:87)(cid:82)(cid:3)(cid:20)(cid:86)(cid:48)(cid:68)(cid:76)(cid:81)(cid:3)(cid:79)(cid:82)(cid:82)(cid:83)(cid:38)(cid:82)(cid:80)(cid:83)(cid:79)(cid:72)(cid:87)(cid:76)(cid:82)(cid:81)(cid:3)(cid:79)(cid:82)(cid:82)(cid:83)(cid:11)(cid:24)(cid:12)(cid:3)(cid:36)(cid:51)(cid:44)(cid:3)(cid:70)(cid:68)(cid:79)(cid:79)(cid:21)(cid:86)(cid:3)(cid:16)(cid:3)(cid:22)(cid:86)chine learning inference away from the edge. This server-
centric architecture ensures veriﬁcation can run on all phones,
regardless of their compute capabilities while also simplifying
the role of the client
to merely relay data to the server.
However, server-side veriﬁcation puts higher strain on network
bandwidth and latency, with the need to transmit frames from
the camera to the server, resulting in delays in veriﬁcation.
Server-side veriﬁcation also disregards end-user privacy.
the app sends sensitive user
thereby
With server-side veriﬁcation,
information, such as card images,
introducing potential avenues for data breach.
to the server,
Running veriﬁcation on the mobile client involves running
compute intensive machine-learning inference on the client
and only sending high-level features to the server. This client-
ﬁrst architecture puts less strain on the network and can
process more frames faster by virtue of running closer to the
camera. Importantly, client-side veriﬁcation is more respectful
of end-user privacy since it avoids sending sensitive card
images to the server.
B. Solution: Run veriﬁcation on the client
We believe that there are more good users than fraudsters
and respecting the good user’s privacy should be the foremost
concern for anyone attempting to combat fraud. Additionally,
one way fraudsters source stolen card information is through
data breaches, and we strive to minimize these avenues. Thus,
Daredevil chooses to run its veriﬁcation on the client. Dare-
devil’s system design and algorithmic improvements ensure
the running of uniform veriﬁcation on resource-constrained
and well-provisioned devices across different platforms.
C. Challenge: How to ensure high veriﬁcation accuracy on a
mobile phone?
The input to our models is an image or a video stream of a
user holding a card. Changes in illumination, varying camera
quality, orientation of the payment card, wear patterns on the
card, and so on add to the stochasticity of the inputs, which
makes it difﬁcult to ensure high accuracy. However, since we
use this input to verify or block a user, ensuring high accuracy
is critical to provide uniform veriﬁcation.
A common solution to ensure high accuracy in machine
learning is to increase the model size. However, apps are hes-
itant to increase the size of their binary [44], mobile networks
can be slow and content distribution networks are expensive
(a 5MB machine learning model downloaded 50 million times
in a month costs north of $30k / month) complicating model
downloads in the background. All of which puts pressure on
client-side machine learning to keep model sizes down while
still providing fast and accurate predictions.
D. Solution: Decompose veriﬁcation to sub-tasks for improved
efﬁciency and redundancy
We decompose card veriﬁcation into multiple tasks, with
each task having its own independent machine learning model.
Decomposition of the veriﬁcation process into sub-tasks keeps
each sub-task efﬁcient while also providing redundancy across
Fig. 6: Machine learning pipeline for client-side models.
detect fraud dynamically and adapt automatically to scan the
appropriate side of the card for each scan. The net result is
that to verify cards Daredevil must run more machine learning
models than it would if it were just scanning a single side of
the card.
Figure 5 shows this overall process from a user’s perspec-
tive. First, the user (1) opens the ﬂow, which starts the camera.
Then (2) when they put the card in the center of the viewport,
we update the user interface to give them feedback. In parallel,
(3) the card detection and the OCR models run and we display
the details that the OCR extracts from the card. After the
ﬁrst successful OCR prediction we continue running the card
detection and OCR models for 1.5s and collect additional
predictions about the OCR details to vote and correct any
mispredictions. After the error correction process completes,
(4) we run the fake media detection and card tampering
detection models on a subset of the images that we process
for up to 1s, before (5) making an API call to our server to
judge if the scan included a genuine physical card. This API
call includes the output of our client-side machine learning
models and our server-side logic implements rules to make a
ﬁnal overall decision about the validity of a scan.
Figure 6 shows our client-side machine learning pipeline
for processing images (frames) from the camera. This pipeline
uses two different producer/consumer modules and divides the
computation up into a main loop and a completion loop. The
main loop runs on images in real time as the camera extracts
images, and the completion loop runs after the main loop
ﬁnishes but before making the ﬁnal API call.
In this ﬂow we show the scanning process for a single side
of the card, but in Daredevil we scan both sides of the card
using the same basic process before making the ﬁnal API call.
We introduce a card detection model that detects the side of
the card, which we use as the basis for our two-side scan. See
Section V-D for more details.
V. DESIGN
A. Challenge: Where to run veriﬁcation?
Card veriﬁcation can either run on the client or on the
server. Server-side veriﬁcation moves compute intensive ma-
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:14:08 UTC from IEEE Xplore.  Restrictions apply. 
1628
LIFO bufferMain loop modelsPriority bufferOCRExtract numberCard detectCentered cardsCompletion loop modelsCard tamper detectForged cardsFake media detectCards rendered on fake mediatasks for improved accuracy. Decomposition also enables us
to iteratively reﬁne models for each individual task until the
models reach an acceptable level of accuracy.
Daredevil decomposes veriﬁcation into four distinct sub-
tasks: OCR, card detection, fake media detection, and card
tampering detection. OCR scans the number side of the card
and extracts the card number, card detection detects frames
where the user centers the card in the viewport and detects the
side of the card that the user scans (number or non-number
side), and fake media detection checks both sides of the card
to detect cards scanned off fake media such as device screens,
paper, cardboard etc.
Card tampering detection also scans both sides of the
card to detect signs of tampering and inconsistencies. We
scan both sides since newer card designs have meaningful
information printed on both sides. For instance, newer Wells
Fargo payment cards contain the bank and payment network
logos on one side and the card number and expiry on the other
side. In this case, if the card tampering detection detects a
Wells Fargo card number on one side and detects a conﬂicting
bank logo on the same or opposite side, Daredevil ﬂags the
scan as fake.
Decomposition leads to higher accuracy in two ways. First,
our decomposition makes our overall system more efﬁcient,
allocating limited ML resources towards the images that are
most likely to generate meaningful signals (Section V-D1).
Second, our decomposition provides redundant signals to
increase the conﬁdence of the predictions that Daredevil makes
(Section V-D2).
1) Efﬁciency with decomposition: If we pass every frame
coming from the camera through all our machine learning
models, then we waste computation. For example, if there is
an image without a card in it, then running the fake media
detection model or the card tampering detection model on that
image is wasteful because there isn’t even a card in the image,
and it won’t provide meaningful results.
Instead, to make our overall ML pipeline more efﬁcient,
we divide computation up into a main loop that runs on all
frames in real-time, and a completion loop that defers running
of models and operates on only a subset of the frames that
we believe are most likely to have relevant fraud signals.
Logic in the main loop dictates which frames it passes on
to the completion loop, which in Daredevil are any images
that have centered cards in them. Figure 6 shows Daredevil’s
decomposition.
At the heart of our design is the card detector model. The
card detector model is a 3-class image classiﬁer that we train
to detect a centered image of the number side or a centered
image of the non-number side of a card. The card detector
also has a third class, called the background class, to ﬁlter out
frames that contain off-center cards or no cards at all.
We execute the card detector and OCR models on the main
loop. The reason that we run these models on the main loop
is because they both produce user-visible outputs (Figure 5).
The card detection model highlights the corner of our viewport
when it detects a centered card and our OCR model displays
the recognized card number and expiration date using an
animation as it captures them. Thus, these models must run
in the main loop to process frames in real-time and display
their results to the user. We ﬁnish the main loop by using the
results from the card detection model to determine when the
user scans either the number side or non-number side of a
card for 1.5 seconds.
We execute the fake media detection and card tampering
detection models on the completion loop. These models only
produce a result that our system uses to detect fake cards
via an API call, so we defer execution until after the main
loop ﬁnishes and only run them on a subset of frames (up
to six in our current system) identiﬁed by the card detector
model
that are likely to produce evidence of fake cards.
Our decomposition keeps the system efﬁcient by having the
completion loop save computation by only processing frames
with centered cards.
2) Redundancy with decomposition: Daredevil uses differ-
ent forms of redundancy for each of its models to provide
high conﬁdence in the accuracy of its decisions. Some models
have a built-in validation signal for redundancy, while others
require external validation signals for redundancy.
More concretely, OCR has redundancy built into its design
from the Luhn algorithm [18]. The Luhn algorithm is a
checksum used to validate credit card numbers. Thus, we
validate OCR predictions by making sure that they satisfy the
Luhn checksum.
In contrast, our card tampering detection model detects
prominent objects on cards (e.g., the Visa symbol) and our
fake media detection model detects cards scanned off fake
media and do not contain a built-in validation signal. Thus, we
use the predictions of the card detection model and OCR to
provide redundancy. Correlating predictions between models
reinforces their decisions. For example, predictions of seeing
a card by the card detection model, and detecting the presence
of a Visa symbol by the card tampering detection model
reinforce each other. For the number side, these predictions
also reinforce OCR and in turn OCR reinforces them.
Additionally, OCR, card tampering detection, and fake
media detection beneﬁt from voting on predictions across the
frames they process for redundancy. For example, if our fake
media detection model processes ﬁve frames and predicts the
presence of a computer screen on three of them, and no screen
on the remaining two, its ﬁnal decision is that a screen is
present.
Figure 7 summarizes the different forms of redundancy we
use with each model.
important
Redundancy is the most
lesson learned from
our implementation. Even if a model achieves an accuracy
of 100% on a benchmark validation dataset, it can still fall
short for a practical system. Instead, one needs to supplement
these predictions with additional data via voting and validation
signals. To cope with the uncertainty inherent in real deploy-
ments and to handle active attackers, we need these forms of
redundancy.
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:14:08 UTC from IEEE Xplore.  Restrictions apply. 
1629
Task
Redundancy used
Redundancy
provided
Card
detection
OCR
Card
tampering
Fake
media
detection
None
Luhn + voting
Voting + validation
from card detection
and OCR
Voting + validation
from card detection
Centered and focused
card present
Card number and
location
None
None
Fig. 7: Task-level redundancy in Daredevil.
E. Challenge: How to account for resource-constrained mo-
bile phones?
Owing to differences in sensor quality and compute ca-
pabilities, there is a stark difference in the performance of
running image processing machine learning tasks on resource-
constrained and well-provisioned phones. At best, the result
of the difference in this performance inconveniences users by
making them wait longer to verify their cards, and at worst,
prevents users from verifying themselves. In either case, fraud
systems penalize users attempting to verify themselves simply
for not possessing a well-provisioned phone.
From our measurement study (Section III), we can see
ﬁrst-hand the stark differences in running the same machine
learning models on well-provisioned and resource-constrained
devices in a production setting. Even though machine learning
inference is expected to improve with streamlined acceler-
ated hardware support (GPUs, Neural Engine) on iOS which
will bridge the gap between resource-constrained and well-
provisioned iPhones, it continues to be a problem on Android
phones due to inherent hardware heterogeneity, with over 2000
SoCs in distribution, making optimizing for each of them
difﬁcult.
Thus, to have uniform veriﬁcation on all devices irrespective
of hardware capabilities, there is a need for software enhance-
ments for efﬁcient machine learning inference.
F. Solution: Reﬁne machine learning models and improve
system design to provide faster effective frame rates
Our solution to account for resource-constrained phones
consists of algorithmic machine learning improvements for