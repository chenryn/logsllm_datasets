rating (ui, oj , r) corresponds to the edge e = (vui , voj ) ∈ E
being labeled with L(e) = r.
Furthermore, the review graph of user u is the subgraph
Gu = ({vu} ∪ N (vu), Eu, Lu), where N (vu) ⊆ VO is the
neighborhood of vu, i.e. N (vu) = {vo | (vu, vo) ∈ E}, and
Eu ⊆ E and Lu ⊆ L are the corresponding edges and labels
in the subgraph induced by {vu} ∪ N (vu).
An example of a bipartite review graph is shown in Figure
1 (a). In this graph, the review graph of user 0001 consists
of his/her user node, two movie nodes, Star Wars and God-
father, and two labeled edges connecting the user node with
the two movie nodes.
The task of recommender systems is to predict the rating
r ∈ S that a user u ∈ U would assign to an item o ∈ O.
Much research has been done to improve the quality of pre-
diction by combining information from many users, a task
known as collaborative ﬁltering. Most existing approaches to
this task are variations of k-nearest neighbors (e.g., [2], [14])
or singular value decomposition (SVD) (e.g., [15]). We refer
the readers to [5] for a good survey of collaborative ﬁltering
algorithms.
3. PRIVACY AND UTILITY MODELS
In released recommendation data, e.g. Netﬂix, usernames
are replaced with unique integer IDs, while item names and
ratings are made public for data analysis purposes. In this
paper, we identify two privacy goals in anonymizing recom-
mendation data.
(1) Node identiﬁcation privacy: re-identiﬁcation of individ-
uals in a released database is considered a privacy breach.
(2) Link existence privacy: the knowledge of which items are
reviewed by a speciﬁc user is considered private information
of that user.
3.1 Attacks Models
By gathering information from external data sources, an
adversary may know a subset of items that a speciﬁc user
has reviewed. The adversary can try to uniquely identify
the user by matching this background knowledge with the
released dataset. Based on this, we deﬁne the structure-
based attack.
Deﬁnition 2. Structure-based Attack Given a re-
leased bipartite review graph G∗ = (VU ∪ VO, E∗, L∗), let
u = ({vu} ∪ N A(vu), EA
GA
u ,∅) be the subgraph representing
the adversary knowledge of user u. If there are k user nodes,
each of which vu′ ∈ VU has GA
u′ , we say that user u
is identiﬁed by the structure-based attack with probability
1/k.
u ⊆ G∗
Figure 2 (a) shows an example of the adversary knowledge
for a structure-based attack. The adversary knows that Ben
has watched the movies Godfather and English Patient. By
matching this knowledge to the released data in Figure 1
(a), the attacker uniquely identiﬁes Ben as user 0002.
In addition to the structure-based attack that is based on
knowledge of which items have been reviewed by a user, the
attacker may also know the ratings of these items. Such ad-
ditional adversary knowledge enables the label-based attack.
Deﬁnition 3. Label-based Attack Given a released bi-
partite review graph G∗ = (VU ∪ VO, E∗, L∗), let GA
u =
({vu} ∪ N A(vu), EA
u ) be the subgraph representing the
adversary knowledge of user u. If there are k nodes, each
of which vu′ ∈ VU has GA
u′ , we say that user u is
identiﬁed by the label-based attack with probability 1/k.
u ⊆ G∗
u , LA
Figure 2 (b) shows an example of adversary knowledge
for the rating-based attack. The adversary knows that Tim
has given a low rating to the movie English Patient. By
matching this knowledge to the released data (Figure 1 (a)),
the adversary uniquely identiﬁes Tim as user 0003, since the
other user who reviewed English Patient gave a high rating.
The label-based attack is a stronger model than the
structure-based attack. Thus by giving privacy guarantees
against the label-based attack, we are protecting against the
structure-based attack as well. In the following, we mainly
focus on the label-based attack.
3.2 Privacy Model
In practice, it is hard to predict the amount of background
knowledge that an adversary has gained. Therefore, we aim
to provide protection against the strongest adversary that
we have considered, the label-based attack. To achieve this
goal, we adapt the deﬁnition of k-anonymity [30, 33] to our
model. The conventional k-anonymity model deﬁnes quasi-
identiﬁer attributes (publicly available information that may
be used to identify individuals) and sensitive attributes (pri-
vate information known only by the individual). These two
sets of values are assumed to not overlap. In our problem,
the nodes, edges, and labels in the released review graph are
both quasi-identiﬁers and sensitive values. To address this
problem, we deﬁne k-anonymity in recommender systems as
follows:
Deﬁnition 4. k-anonymity Given a bipartite review
graph G = (VU ∪ VO, E, L), let G∗ = (VU ∪ VO, E∗, L∗)
be the review graph of the released dataset. We say G∗ sat-
isﬁes k-anonymity if for every user u ∈ U , there are at least
u is isomorphic to G∗
k − 1 other users {ui}i∈I such that G∗
ui .
We say that {u} ∪ {ui}i∈I is the anonymization group of u.
Intuitively, Deﬁnition 4 requires that for each user node
u, there are at least k − 1 other user nodes that have iden-
tical review graphs to u in terms of both structure and la-
bels. Thus the k-anonymity model is eﬀective for defending
against both the structure-based and label-based attacks.
3.3 Utility Measure
Since data owners publish their recommendation data to
seek improved recommendation algorithms, it is desirable
that the released data preserves prediction accuracy as much
as possible. Unfortunately, existing utility measures for rela-
tional databases (e.g., the ratio of nodes in the generalization
taxonomy trees [19, 35], the distance between the distribu-
tions of the original and anonymized datasets [20], and the
estimation error of aggregate query answers [28]) cannot be
applied to recommender systems to achieve this utility goal.
We propose using the root mean squared error (RMSE)
to measure the accuracy of prediction results. More speciﬁ-
cally, given the original recommendation dataset D and its
anonymized version D∗, let RM SED and RM SED∗ be the
average RMSEs of the prediction results on D and D∗, re-
spectively. Intuitively, the closer these two RMSEs are, the
better utility that the anonymization preserves. Our RMSE-
based method allows us to easily measure the prediction ac-
curacy of both original data values and their anonymized
ones, which is a general approach for computing the amount
of information change during anonymization.
4. PREDICTIVE ANONYMIZATION
To protect sensitive information about users in a recom-
mender system, the data owner should anonymize recom-
mendation data before publishing it. We delineate several
goals for an eﬀective anonymization algorithm:
1. Privacy Goal: the anonymized dataset must satisfy
k-anonymity
2. Utility Goal: the published data should preserve pre-
diction accuracy
3. Performance Goal: the algorithm must be eﬃcient
for large datasets
We design a general method, Predictive Anonymization,
that achieves these goals. The key idea in our method is a
predictive padding step that aims to amplify the original data
features by strategically replacing null entries with mean-
ingful values. However, if not done carefully, padding may
destroy original data patterns and cause information loss.
In this
section, we outline the general Predictive
Anonymization procedure and provide details of our imple-
mentation. The procedure consists of three major steps:
(1) strategically pad the data to reduce sparsity, (2) con-
struct anonymization groups from the pre-processed data,
and (3) homogenize the ratings within each group.
4.1 Step 1: Predictive Padding
Recommender systems are typically sparse [16, 32, 31];
that is, the percentage of items reviewed by an average user
is small. Sparsity can be detrimental to privacy because
it decreases the amount of auxiliary information needed for
re-identiﬁcation [26]. Furthermore, it hampers the eﬀective-
ness of anonymization that is based on grouping users with
similar ratings. Due to data sparsity, even users with very
similar preferences may have very small overlap in the items
they have rated. Thus, anonymization on the original data
may not eﬀectively group similar users, which impairs the
accuracy of prediction.
We
take a novel approach to anonymization by
padding the data with predicted values before constructing
anonymization groups. An important insight of our tech-
nique is that similar users are not necessarily those who have
rated the same items; rather, it is users who have similar
item preferences. Since the end goal is to preserve predic-
tion accuracy in the anonymized dataset, it is essential to
form anonymization groups of users with similar item prefer-
ences to minimize information loss. We use a method called
Regularized SVD (Singular Value Decomposition) to achieve
that goal.
4. Determine anonymization groups by clustering points
within each bin.
Clustering Algorithm The task of clustering data has
been studied in great depth. One classic clustering tech-
nique is known as the k-Means algorithm [21, 23]. To avoid
confusion with the k in k-anonymity, we use the term t-
Means throughout the paper. The t-Means algorithm takes
an input parameter, t, and partitions a set of objects into t
clusters so that the resulting intra-cluster similarity is high.
In practice, however, it has been observed that classic
clustering algorithms frequently produce clusters whose sizes
are of skewed distribution (i.e., some clusters are very large
while some are small or even empty), especially when clus-
tering high-dimensional datasets [4]. In contrast, a balanced
distribution of cluster sizes is desired in Step 2 to ease com-
putation for subsequent steps, as well as in Step 4 to min-
imize information loss during anonymization while guaran-
teeing the k-anonymity privacy requirement.
To achieve this, we use the Bounded t-Means algorithm
from [34], which guarantees that the sizes of all t clusters
are no smaller than a pre-deﬁned lower bound. We ﬁrst
apply the Bounded t-Means algorithm to the sample points
to ﬁnd balanced bins for partitioning the dataset. To reduce
the complexity of the entire clustering procedure, we choose
the value t = √n. More details of why we pick this value
are explained in Section 5.1.
Finally, we apply the Bounded t-Means algorithm to clus-
ter the users in each bin. For bin Bi we set the parameter
t = |Bi|/k, so that every cluster is guaranteed to contain
at least k users. By grouping similar users into the same
bin, we incur little information loss by ﬁrst using our sam-
pling procedure, compared to if we had clustered all the
users at once. However, our procedure yields a signiﬁcant
speed-up in run-time for the clustering step, especially when
performed on large datasets. See Section 5.1 for details.
Similarity Metric To perform Bounded t-Means cluster-
ing, we must ﬁrst deﬁne our user similarity metric. Let ∆ be
the diﬀerence between the highest and the lowest possible
ratings in the dataset, i.e. ∆ = max(S) − min(S). Then
given two users u and u′ and their corresponding rating vec-
tors (r1, . . . , rn) and (r′
n), we deﬁne the similarity
between u and u′ to be
1, . . . , r′
sim(u, u′) = 1 − P1≤i≤n(1 − di)2
n
i|/∆ for 1 ≤ i ≤ n.
where di = |ri − r′
It is straightforward to verify that sim(u, u′) = 0 only
when u and u′ match exactly on every common entry, and
sim(u, u′) = 1 only when u and u′ have opposite minimum
and maximum ratings for each item. This method essen-
tially gives a squared penalty for large diﬀerences in item
preferences between two users. We studied the eﬀectiveness
of this metric against other similarity metrics. More details
can be found in Section 7.4.
Cluster Centers An operation used frequently in the
Bounded t-Means algorithm is computing the center of a
cluster. We adapt the idea of virtual centers from [34] to
our problem.
Consider a cluster C of users {u1, . . . , uk}, each ui as-
signed with a rating vector hri,1, . . . , ri,ni to the items
o1, . . . , on. Then the virtual center c of cluster C is a vector
of ratings hˆr1, . . . , ˆrni such that ˆrj =Pk
i=1 ri,j/n, where ri,j
Figure 3: Our Sample and Cluster Procedure. The
randomly chosen sample points are designated by
stars. The dashed lines identify the bins, and solid
ovals represent the ﬁnal anonymization groups.
Regularized SVD is a matrix approximation method that
has been eﬀectively used in the domain of natural language
processing, and has more recently been proposed for col-
laborative ﬁltering [12]. Given an input matrix A and an
accuracy parameter r, SVD outputs the matrix A′ of rank
r with the minimum approximation error in terms of least
squared distance from A. Regularization imposes additional
restrictions that prevent overﬁtting, which enables us to ex-
tract pertinent information from the existing ratings and use
it to inpute the missing values. Note that although we chose
to use Regularized SVD for our implementation, predictive
padding is a general approach that supports any method of
imputation.
At the end of the padding phase, all null ratings have been
replaced with predicted values, eﬀectively eliminating the
sparsity problem. This predictive padding does not aﬀect
the original data, which may still be used to construct the
ﬁnal released anonymized dataset. Yet, the padded data sig-
niﬁcantly improves the accuracy of clustering that is based
on user similarities, which is explained next.
4.2 Step 2: Forming Anonymization Groups
Our high-level anonymization strategy is to partition users
into anonymization groups of size at least k so that an adver-
sary can not distinguish between the ratings of individuals
within a group. This is accomplished using a clustering algo-
rithm that guarantees a minimum cluster size. At the end of
the procedure, each cluster has at least k users with similar
item preferences.
Since the most accurate clustering algorithms for sparse
recommendation data run in super-linear time, we employ
a sampling technique to improve the eﬃciency of our al-
gorithm. Our clustering procedure diﬀers from existing
clustering-based anonymization work (e.g., [1]) by comput-
ing and utilizing pair-wise similarity values for clustering
weighted bipartite graphs. Also, our method based on sam-
pling and bin-assigning is scalable to large datasets. Our
clustering procedure (shown in Figure 3) works as follows:
1. Randomly select a set of sample points from the
dataset.
2. Cluster the sample points into equal-sized “bins”.
3. Partition the entire dataset, placing each point into
the nearest bin.
100 Bins
500 Bins
y
c
n
e
u
q
e
r
F
6
5
4
3
2
1
0
d100