例的时候，会触发刷盘的操作。这个参数是
hbase.regionserver.global.memstore.upperLimit，默认为整个heap内存的40%。
但这并不意味着全局内存触发的刷盘操作会将所有的MemStore都进行输盘，而是通过
另外一个参数hbase.regionserver.global.memstore.lowerLimit来控制，默认是整个
heap内存的35%。当flush到所有memstore占整个heap内存的比率为35%的时
候，就停止刷盘。这么做主要是为了减少刷盘对业务带来的影响，实现平滑系统负载的
目的。
MemStore达到上限
2. 当MemStore的大小达到hbase.hregion.memstore.flush.size大小的时候会触发刷
盘，默认128M大小
RegionServer的Hlog数量达到上限
3. 前面说到Hlog为了保证Hbase数据的一致性，那么如果Hlog太多的话，会导致故障
恢复的时间太长，因此Hbase会对Hlog的最大个数做限制。当达到Hlog的最大个数
的时候，会强制刷盘。这个参数是hase.regionserver.max.logs，默认是32个。
手工触发
4. 可以通过hbase shell或者java api手工触发flush的操作。
关闭RegionServer触发
5. 在正常关闭RegionServer会触发刷盘的操作，全部数据刷盘后就不需要再使用Hlog恢
复数据。
Region使用HLOG恢复完数据后触发
6. ：当RegionServer出现故障的时候，其上面的Region会迁移到其他正常的
RegionServer上，在恢复完Region的数据后，会触发刷盘，当刷盘完成后才会提供给
业务访问。
14.1.6. HBase vs Cassandra
HBase Cassandra
语言 Java Java
出发点 BigTable BigTable and Dynamo
License Apache Apache
Protocol HTTP/REST (also Thrift) Custom, binary (Thrift)
数据分布 表划分为多个region存在不同region 改进的一致性哈希（虚拟节点）
server上
存储目标 大文件 小文件
一致性 强一致性 最终一致性，Quorum NRW策略
架构 master/slave p2p
高可用性 NameNode是HDFS的单点故障点 P2P和去中心化设计，不会出现单点故障
伸缩性 Region Server扩容，通过将自身发布到 扩容需在Hash Ring上多个节点间调整数据分布
Master，Master均匀分布Region
13/04/2018 Page 188 of 283
读写性能 数据读写定位可能要通过最多6次的网 数据读写定位非常快
络RPC，性能较低。
数据冲突处理 乐观并发控制（optimistic concurrency 向量时钟
control）
临时故障处理 Region Server宕机，重做HLog 数据回传机制：某节点宕机，hash到该节点的新数据自
动路由到下一节点做 hinted handoff，源节点恢复后，推
送回源节点。
永久故障恢复 Region Server恢复，master重新给其 Merkle 哈希树，通过Gossip协议同步Merkle Tree，维
分配region 护集群节点间的数据一致性
成员通信及错误检测 Zookeeper 基于Gossip
CAP 1，强一致性，0数据丢失。2，可用性 1，弱一致性，数据可能丢失。2，可用性高。3，扩容方
低。3，扩容方便。 便。
13/04/2018 Page 189 of 283
15. MongoDB
15.1.1. 概念
MongoDB 是由C++语言编写的，是一个基于分布式文件存储的开源数据库系统。在高负载的情
况下，添加更多的节点，可以保证服务器性能。MongoDB 旨在为WEB应用提供可扩展的高性能
数据存储解决方案。
MongoDB 将数据存储为一个文档，数据结构由键值(key=>value)对组成。MongoDB 文档类似
于 JSON 对象。字段值可以包含其他文档，数组及文档数组。
15.1.2. 特点
 MongoDB 是一个面向文档存储的数据库，操作起来比较简单和容易。
 你可以在MongoDB记录中设置任何属性的索引 (如：FirstName="Sameer",Address="8 Ga
ndhi Road")来实现更快的排序。
 你可以通过本地或者网络创建数据镜像，这使得MongoDB有更强的扩展性。
 如果负载的增加（需要更多的存储空间和更强的处理能力） ，它可以分布在计算机网络中的其
他节点上这就是所谓的分片。
 Mongo支持丰富的查询表达式。查询指令使用JSON形式的标记，可轻易查询文档中内嵌的
对象及数组。
 MongoDb 使用update()命令可以实现替换完成的文档（数据）或者一些指定的数据字段 。
 Mongodb中的Map/reduce主要是用来对数据进行批量处理和聚合操作。
 Map和Reduce。Map函数调用emit(key,value)遍历集合中所有的记录，将key与value传
给Reduce函数进行处理。
 Map函数和Reduce函数是使用Javascript编写的，并可以通过db.runCommand或mapre
duce命令来执行MapReduce操作。
13/04/2018 Page 190 of 283
 GridFS是MongoDB中的一个内置功能，可以用于存放大量小文件。
 MongoDB允许在服务端执行脚本，可以用Javascript编写某个函数，直接在服务端执行，也
可以把函数的定义存储在服务端，下次直接调用即可。
13/04/2018 Page 191 of 283
16. Cassandra
16.1.1. 概念
Apache Cassandra 是高度可扩展的，高性能的分布式 NoSQL 数据库。 Cassandra 旨在处理许
多商品服务器上的大量数据，提供高可用性而无需担心单点故障。
Cassandra 具有能够处理大量数据的分布式架构。 数据放置在具有多个复制因子的不同机器上，
以获得高可用性，而无需担心单点故障。
16.1.2. 数据模型
Key Space（对应SQL数据库中的database）
1. 一个Key Space中可包含若干个CF，如同SQL数据库中一个database可包含多个table
Key（对应SQL数据库中的主键）
2. 在Cassandra中，每一行数据记录是以key/value的形式存储的，其中key是唯一标识。
column（对应SQL数据库中的列）
3. Cassandra中每个key/value对中的value又称为column，它是一个三元组，即：name，
value和timestamp，其中name需要是唯一的。
super column（SQL数据库不支持）
4. cassandra允许key/value中的value是一个map(key/value_list)，即某个column有多个
子列。
Standard Column Family（相对应SQL数据库中的table）
5. 每个CF由一系列row组成，每个row包含一个key以及其对应的若干column。
Super Column Family（SQL数据库不支持）
6. 每个SCF由一系列row组成，每个row包含一个key以及其对应的若干super column。
16.1.3. Cassandra一致 Hash和虚拟节点
一致性Hash（多米诺down机）
为每个节点分配一个 token，根据这个 token 值来决定节点在集群中的位置以及这个节点所存储
的数据范围。
13/04/2018 Page 192 of 283
虚拟节点（down机多节点托管）
由于这种方式会造成数据分布不均的问题，在 Cassandra1.2 以后采用了虚拟节点的思想：不需要
为每个节点分配token，把圆环分成更多部分，让每个节点负责多个部分的数据，这样一个节点移
除后，它所负责的多个token会托管给多个节点处理，这种思想解决了数据分布不均的问题。
如图所示，上面部分是标准一致性哈希，每个节点负责圆环中连续的一段，如果 Node2 突然
down 掉，Node2 负责的数据托管给 Node1，即 Node1 负责 EFAB 四段，如果 Node1 里面有
很多热点用户产生的数据导致Node1已经有点撑不住了，恰巧B也是热点用户产生的数据，这样
一来Node1可能会接着down机，Node1down机，Node6还hold住吗？
下面部分是虚拟节点实现，每个节点不再负责连续部分，且圆环被分为更多的部分。如果 Node2
突然down掉，Node2负责的数据不全是托管给Node1，而是托管给多个节点。而且也保持了一
致性哈希的特点。
16.1.4. Gossip协议
Gossip 算法如其名，灵感来自办公室八卦，只要一个人八卦一下，在有限的时间内所有的人都
会知道该八卦的信息，这种方式也与病毒传播类似，因此 Gossip 有众多的别名“闲话算法”、
“疫情传播算法”、“病毒感染算法”、“谣言传播算法”。 Gossip 的特点：在一个有界网络中，
每个节点都随机地与其他节点通信，经过一番杂乱无章的通信，最终所有节点的状态都会达成一
致。因为 Gossip 不要求节点知道所有其他节点，因此又具有去中心化的特点，节点之间完全对等，
不需要任何的中心节点。实际上 Gossip 可以用于众多能接受“最终一致性”的领域：失败检测、
路由同步、Pub/Sub、动态负载均衡。
13/04/2018 Page 193 of 283
Gossip节点的通信方式及收敛性
Gossip两个节点（A、B）之间存在三种通信方式（push、pull、push&pull）
1. push: A节点将数据(key,value,version)及对应的版本号推送给B节点，B节点更新A中比自
己新的数据。
2. pull：A 仅将数据key,version 推送给B，B将本地比 A 新的数据（Key,value,version）推送
给A，A更新本地。
3. push/pull：与pull类似，只是多了一步，A再将本地比B新的数据推送给B，B更新本地。
如果把两个节点数据同步一次定义为一个周期，则在一个周期内，push需通信1 次，pull需2 次，
push/pull 则需 3 次，从效果上来讲，push/pull 最好，理论上一个周期内可以使两个节点完全一
致。直观上也感觉，push/pull的收敛速度是最快的。
gossip的协议和seed list（防止集群分列）
cassandra使用称为gossip的协议来发现加入C集群中的其他节点的位置和状态信息。gossip进
程每秒都在进行，并与至多三个节点交换状态信息。节点交换他们自己和所知道的信息，于是所
有的节点很快就能学习到整个集群中的其他节点的信息。gossip 信息有一个相关的版本号，于是
在一次gossip信息交换中，旧的信息会被新的信息覆盖重写。要阻止分区进行gossip交流，那么
在集群中的所有节点中使用相同的seed list，种子节点的指定除了启动起gossip进程外，没有其
他的目的。种子节点不是一个单点故障，他们在集群操作中也没有其他的特殊目的，除了引导节
点以外
16.1.5. 数据复制
Partitioners（计算primary key token的hash函数）
在Cassandra中，table的每行由唯一的primarykey标识，partitioner实际上为一hash函数用
以计算primary key的token。Cassandra依据这个token值在集群中放置对应的行
两种可用的复制策略：
SimpleStrategy：仅用于单数据中心，
将第一个 replica 放在由 partitioner 确定的节点中，其余的 replicas 放在上述节点顺时针方向的
后续节点中。
NetworkTopologyStrategy：可用于较复杂的多数据中心。
可以指定在每个数据中心分别存储多少份replicas。
复制策略在创建keyspace时指定，如
CREATE KEYSPACE Excelsior WITH REPLICATION = { 'class' :
'SimpleStrategy','replication_factor' : 3 };
CREATE KEYSPACE Excalibur WITH REPLICATION = {'class' :'NetworkTopologyStrategy',
'dc1' : 3, 'dc2' : 2};
13/04/2018 Page 194 of 283
16.1.6. 数据写请求和协调者
协调者(coordinator)
协调者(coordinator)将write请求发送到拥有对应row的所有replica节点，只要节点可用便获取
并执行写请求。写一致性级别(write consistency level)确定要有多少个replica节点必须返回成功
的确认信息。成功意味着数据被正确写入了commit log和memtable。
其中dc1、dc2 这些数据中心名称要与 snitch中配置的名称一致.上面的拓扑策略表示在 dc1配置
3个副本,在dc2配置2个副本
16.1.7. 数据读请求和后台修复
1. 协调者首先与一致性级别确定的所有replica联系，被联系的节点返回请求的数据。
2. 若多个节点被联系，则来自各replica的row会在内存中作比较，若不一致，则协调者使用含
最新数据的replica向client返回结果。那么比较操作过程中只需要传递时间戳就可以,因为要
比较的只是哪个副本数据是最新的。
3. 协调者在后台联系和比较来自其余拥有对应 row 的 replica 的数据，若不一致，会向过时的
replica发写请求用最新的数据进行更新read repair。
13/04/2018 Page 195 of 283
16.1.8. 数据存储（CommitLog、MemTable、SSTable）
写请求分别到 CommitLog 和 MemTable, 并且 MemTable 的数据会刷写到磁盘 SSTable 上. 除
了写数据,还有索引也会保存到磁盘上.
先将数据写到磁盘中的commitlog，同时追加到中内存中的数据结构memtable 。这个时候就会
返回客户端状态，memtable 内容超出指定容量后会被放进将被刷入磁盘的队列
(memtable_flush_queue_size 配置队列长度)。若将被刷入磁盘的数据超出了队列长度，将内存
数据刷进磁盘中的SSTable,之后commit log被清空。