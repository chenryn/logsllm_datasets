Regulators: Numerous studies from regulators and
law and public policy researchers have manually ana-
lyzed the permissiveness of compliance checks [21, 37].
The number of assessed privacy policies in these stud-
ies is typically in the range of tens of policies. For in-
stance, the Norwegian Consumer Council has investi-
gated the level of ambiguity in deﬁning personal infor-
mation within only 20 privacy policies [37]. Polisis can
scale such studies by processing a regulator’s queries on
large datasets. For example, with Polisis, policies can
be ranked according to an automated ambiguity met-
ric by using the information type attribute and differ-
entiating between the label generic personal information
and other labels specifying the type of data collected.
Similarly, this applies to frameworks such as Privacy
Shield [12] and the GDPR [15], where issues such as
limiting the data usage purposes should be investigated.
536    27th USENIX Security Symposium
USENIX Association
Table 2: The list of Disconnect icons with their description, our interpretation, and Polisis’ queries.
Icon
Disconnect Description
Disconnect Color Assignment
Interpretation as Labels
Automated Color Assignment
Expected
Use
Expected
Collec-
tion
Precise
Location
Data
Retention
Children
Privacy
Discloses whether data it
collects about you is
used in ways other than
you would reasonably
expect given the site’s
service?
Red: Yes, w/o choice to
opt-out. Or, undisclosed.
Yellow: Yes, with choice to
opt-out.
Green: No.
Discloses whether it
allows other companies
like ad providers and
analytics ﬁrms to track
users on the site?
Red: Yes, w/o choice to
opt-out. Or, undisclosed.
Yellow: Yes, with choice to
opt-out.
Green: No.
Let S be the segments with category:
ﬁrst-party-collection-use and purpose:
advertising.
Let S be the segments with category:
third-party-sharing-collection, purpose:
∈ [advertising,analytics-research ], and
action-third-party
∈ [track-on-ﬁrst-party-website-app,collect-
on-ﬁrst-party-website-app].
Discloses whether the
site or service tracks a
user’s actual
geolocation?
Red: Yes, possibly w/o choice.
Yellow: Yes, with choice.
Green: No.
Let S be the segments with
personal-information-type: location.
Discloses how long they
retain your personal
data?
Red: No data retention policy.
Yellow: 12+ months.
Green: 0-12 months.
Let S be the segments with category:
data-retention.
⎫⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎬
⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎭
Yellow: All segments in S have
category: user-choice-control and
choice-type ∈
[opt-in, opt-out-link,
opt-out-via-contacting-company]
Green: S = φ
Red: Otherwise
Green: All segments in S have
retention-period: ∈
[stated-period, limited ].
Red: S = φ
Has this website received
TrustArc’s Children’s
Privacy Certiﬁcation?
Green: Yes. Gray: No.
Let S be the segments with category:
international-and-speciﬁc-audiences and
audience-type: children
Green:
length(S) > 0
Red: Otherwise
Yellow: Otherwise
Table 3: Prediction accuracy and κ for icon prediction, with
the distribution of icons per color based on OPP-115 labels.
Icon
Accuracy Cohen κ
Hellinger
distance
N(R)
N(G)
N(Y)
Exp. Use
Exp. Collection
Precise Location
Data Retention
Children Privacy
92%
88%
84%
80%
98%
0.76
0.69
0.68
0.63
0.95
0.12
0.19
0.21
0.13
0.02
41
35
32
29
12
8
12
14
16
38
1
3
4
5
NA
6 Privacy Icons
Our ﬁrst application shows the efﬁcacy of Polisis in
resolving structured queries to privacy policies. As
a case study, we investigate the Disconnect privacy
icons [18], described in the ﬁrst three columns of Table 2.
These icons evolved from a Mozilla-led working group
that included the Electronic Frontier Foundation, Cen-
ter for Democracy and Technology, and the W3C. The
database powering these icons originated from TRUSTe
(re-branded later as TrustArc), a privacy compliance
company, which carried out the task of manually ana-
lyzing and labeling privacy policies.
In what follows, we ﬁrst establish the accuracy of Poli-
sis’ automatic assignment of privacy icons, using the
Disconnect icons as a proof-of-concept. We perform
a direct comparison between assigning these icons via
Polisis and assigning them based on annotations by law
students [11]. Second, we leverage Polisis to investi-
gate the level of permissiveness of the icons that Discon-
nect assigns based on the TRUSTe dataset. Our ﬁndings
are consistent with the series of concerns raised around
compliance-checking companies over the years [21, 38,
39]. This demonstrates the power of Polisis in scalable,
automated auditing of privacy compliance checks.
6.1 Predicting Privacy Icons
Given that the rules behind the Disconnect icons are
not precisely deﬁned, we translated their description into
explicit ﬁrst-order logic queries to enable automatic pro-
cessing. Table 2 shows the original description and color
assignment provided by Disconnect. We also show our
interpretation of each icon in terms of labels present in
the OPP-115 dataset and the automated assignment of
colors based on these labels. Our goal is not to reverse-
engineer the logic behind the creation of these icons but
to show that we can automatically assign such icons with
high accuracy, given a plausible interpretation. Hence,
this represents our best effort to reproduce the icons, but
these rules could easily be adapted as needed.
To evaluate the efﬁcacy of automatically selecting
appropriate privacy icons, we compare the icons pro-
duced with Polisis’ automatic labels to the icons pro-
duced based on the law students’ annotations from the
OPP-115 dataset [11]. We perform the evaluation over
the same set of 50 privacy policies which we did not use
to train Polisis (i.e., kept aside as a testing set). Each seg-
ment in the OPP-115 dataset has been labeled by three
USENIX Association
27th USENIX Security Symposium    537
experts. Hence, we take the union of the experts’ labels
on one hand and the predicted labels from Polisis on the
other hand. Then, we run the logic presented in Table 2
(Columns 4 and 5) to assign icons to each policy based
on each set of labels.
Table 3 shows the accuracy obtained per icon, mea-
sured as the fraction of policies where the icon based on
automatic labels matched the icon based on the experts’
labels. The average accuracy across icons is 88.4%,
showing the efﬁcacy of our approach in matching the
experts’ aggregated annotations. This result is signif-
icant in view of Miyazaki and Krishnamurthy’s ﬁnd-
ing [21]: the level of agreement among 3 trained human
judges assessing privacy policies ranged from 88.3% to
98.3%, with an average of 92.7% agreement overall. We
also show Cohen’s κ, an agreement measure that ac-
counts for agreement due to random chance4.
In our
case, the values indicate substantial to almost perfect
agreement [40]. Finally, we show the distribution of
icons based on the experts’ labels alongside Hellinger
distance5, which measures the difference between that
distribution and the one produced using the automatic
labels. This distance assumes small values, illustrating
that the distributions are very close. Overall, these results
support the potential of automatically assigning privacy
icons with Polisis.
6.2 Auditing Compliance Metrics
Given that we achieve a high accuracy in assigning
privacy icons, it is intuitive to investigate how they com-
pare to the icons assigned by Disconnect and TRUSTe.
An important consideration in this regard is that sev-
eral concerns have been raised earlier around the level
of leniency of TRUSTe and other compliance compa-
nies [19, 20, 38, 39]. In 2000, the FTC conducted a study
on privacy seals, including those of TRUSTe, and found
that, of the 27 sites with a privacy seal, approximately
only half implemented, at least in part, all four of the fair
information practice principles and that only 63% imple-
mented Notice and Choice. Hence, we pose the follow-
ing question: Can we automatically provide evidence of
the level of leniency of the Disconnect icons using Poli-
sis? To answer this question, we designed an experiment
to compare the icons extracted by Polisis’ automatic la-
bels to the icons assigned by Disconnect on real policies.
One obstacle we faced is that the Disconnect icons
have been announced in June 2014 [41]; many privacy
policies have likely been updated since then. To ensure
that the privacy policies we consider are within a close
time frame to those used by Disconnect, we make use of
Ramanath et al.’s ACL/COLING 2014 dataset [42]. This
4https://en.wikipedia.org/wiki/Cohen%27s kappa
5https://en.wikipedia.org/wiki/Hellinger distance
dataset contains the body of 1,010 privacy policies ex-
tracted between December 2013 and January 2014. We
obtained the icons for the same set of sites using the Dis-
connect privacy icons extension [18]. Of these, 354 poli-
cies had been (at least partially) annotated in the Discon-
nect dataset. We automatically assign the icons for these
sites by passing their policy contents into Polisis and ap-
plying the rules in Table 2 on the generated automatic la-
bels. We report the results for the Expected Use and Ex-
pected Collection icons as they are directly interpretable
by Polisis. We do not report the rest of the icons because
the location information label in the OPP-115 taxonomy
included non-precise location (e.g., zip codes), and there
was no label that distinguishes the exact retention period.
Moreover, the Children privacy icon is assigned through
a certiﬁcation process that does not solely rely on the pri-
vacy policy.
Fig. 5 shows the distribution of automatically ex-
tracted icons vs. the distribution of icons from Discon-
nect, when they were available. The discrepancy be-
tween the two distributions is obvious: the vast majority
of the Disconnect icons have a yellow label, indicating
that the policies offer the user an opt-out choice (from
unexpected use or collection). The Hellinger distances
between those distributions are 0.71 and 0.61 for Ex-
pected Use and Expected Collection, respectively (i.e.,
3–5x the distance in the Table 3).
stem from our
This discrepancy might
icon-
assignment strategy in Table 2, where we assign a
yellow label only when “All segments in S (the con-
cerned subset)” include the opt-in/opt-out choice, which
could be considered as conservative. In Fig. 6, we show
the icon distributions when relaxing the yellow-icon
condition to become: “At least one segment in S” in-
cludes the opt-in/opt-out choice. Intuitively, this means
that the choice segment, when present, should explicitly
mention advertising/analytics (depending on the icon
type). Although the number of yellow icons increases
slightly, the icons with the new permissive strategy are
signiﬁcantly red-dominated. The Hellinger distances
between those distributions drop to 0.47 and 0.50 for
Expected Use and Expected Collection, respectively.
This result indicates that the majority of policies do
not provide users a choice within the same segments
describing data usage for advertising or data collection
by third parties.
We go one step further to follow an even more permis-
sive strategy where we assign the yellow label to any pol-
icy with S! = φ , given that there is at least one segment in
the whole policy (i.e., even outside S) with opt-in/opt-out
choice. For example, a policy where third-party adver-
tising is mentioned in the middle of the policy while the
opt-out choice about another action is mentioned at the
end of the policy would still receive a yellow label. The
538    27th USENIX Security Symposium
USENIX Association
(a) Exp. Use
(b) Exp. Collection
(a) Exp. Use
(b) Exp. Collection
(a) Exp. Use
(b) Exp. Collection
Fig. 5: Conservative icons’ interpretation
Fig. 6: Permissive icons’ interpretation
Fig. 7: Very permissive icons’ interpretation
icon distributions, in this case, are illustrated in Fig. 7,
with Hellinger distance of 0.22 for Expected Use and
0.19 for Expected Collection. Only in this interpreta-
tion of the icons would the distributions of Disconnect
and Polisis come within reasonable proximity. In order
to delve more into the factors behind this ﬁnding, we
conducted a manual analysis of the policies. We found
that, due to the way privacy policies are typically written,
data collection and sharing are discussed in dedicated
parts of the policy, without mentioning user choices. The
choices (mostly opt-out) are discussed in a separate sec-
tion when present, and they cover a small subset of the
collected/shared data.
In several cases, these choices
are neither about the unexpected use (i.e., advertising)
nor unexpected collection by third parties (i.e., advertis-
ing/analytics). Although our primary hypothesis is that
this is due to TRUSTe’s database being generally permis-
sive, it can be partially attributed to a potential discrep-
ancy between our versions of analyzed policies and the
versions used by TRUSTe (despite our efforts to reduce
this discrepancy).
6.3 Discussion
There was no loss of generality when considering only
they provided the needed evidence
two of the icons;
of TRUSTe/TrustArc potentially following a permissive
strategy when assigning icons to policies. A developer
could still utilize Polisis to extract the rest of the icons
by either augmenting the existing taxonomy or by per-
forming additional natural language processing on the
segments returned by Polisis. In the vast majority of the
cases, whenever the icon deﬁnition is to be changed (e.g.,
to reﬂect a modiﬁcation in the regulations), this change
can be supported at the rules level, without modifying
Polisis itself. This is because Polisis already predicts a
comprehensive set of labels, covering a wide variety of
rules.
Furthermore, by automatically generating icons, we
do not intend to push humans completely out of the loop,
especially in situations where legal liability issues might
arise. Polisis can assist human annotators by providing
initial answers to their queries and the supporting evi-
dence. In other words, it accurately ﬂags the segments of
interest to an annotator’s query so that the annotator can
make a ﬁnal decision.
7 Free-form Question-Answering
Our second application of Polisis is PriBot, a sys-
tem that enables free-form queries (in the form of user
questions) on privacy policies. PriBot is primarily moti-
vated by the rise of conversation-ﬁrst devices, such as
voice-activated digital assistants (e.g., Amazon Alexa
and Google Assistant) and smartwatches. For these de-
vices, the existing techniques of linking to a privacy pol-
icy or reading it aloud are not usable. They might require
the user to access privacy-related information and con-
trols on a different device, which is not desirable in the
long run [8].
To support these new forms of services and the emerg-
ing need for automated customer support in this do-
main [43], we present PriBot as an intuitive and user-
friendly method to communicate privacy information.
PriBot answers free-form user questions from a previ-
ously unseen privacy policy, in real time and with high
accuracy. Next, we formalize the problem of free-form
privacy QA and then describe how we leverage Polisis to
build PriBot.
7.1 Problem Formulation
The input to PriBot consists of a user question q about