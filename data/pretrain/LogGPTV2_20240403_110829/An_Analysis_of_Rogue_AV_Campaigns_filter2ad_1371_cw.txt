6
0
.
4
0
.
2
0
.
n =
20
50
100
200
500
1000
2000
0.2
0.4
0.6
0.8
1.0
0.0
0.1
0.2
0.3
0.4
0.5
Delta
Rate of Exploit Behavior (r)
Fig. 17. Varying δ using Adium, with
d/n = 0.1. Mimicry makes detection more
diﬃcult, but, at higher δs, performance
improves logarithmically with n.
Fig. 18. Varying rate of bad behavior (r)
using Camino and showpages, with d/n =
0.1. A suﬃciently large community guar-
antees that bad behavior will overlap.
similar. Tainted training data is symmetric to mimicry: raising μX instead of
lowering μY . Either way, δ is decreased and the following results hold. Intu-
itively, these experiments simulate an exploit that makes system call sequences
in similar (but not identical) proportions to the application. This is done com-
putationally by generating anomaly scores from the application’s distribution,
then shifting them positively by δ. (Y ∼ X + δ.)
Figure 17 gives results from these experiments. Syzygy is able to detect fairly
well even for low δ. The poor performance at the lowest δs, despite large com-
munities, is almost exclusively a result of false negatives: V is set too high. With
a lower V , we can get F1 > 0.6 even when δ = 0.1, n = 10, and d = 1.
We now consider scenario (ii), limiting bad behavior to a ﬁxed rate. Speciﬁ-
cally, if the exploit spreads bad behavior out over time, in bursts that cumula-
tively account for a fraction r of the runtime per client, such that the community
signal does not deviate above μX + V , no epidemic will be reported. Mathemat-
ically, this attack corresponds to decreasing the eﬀective infection size from d to
dr. This, in itself, may be considered a victory under certain circumstances, such
as when a worm may be contained so long as it does not spread too quickly [42].
In our experiment, we splice windows of infected anomaly scores into sequences
of healthy anomaly scores, in proportions determined by the rate r. Figure 18
shows how Syzygy performs against this rate-limiting attack. Again, false neg-
atives dominate the metric—with a better-chosen V , we can get F1 above 0.68
at r = 0.05 with as few as 10 clients.
7 Scalability
Mathematically, Syzygy’s accuracy improves as the community grows, so it is
crucial that the implementation scales well. This issue is independent of the anal-
ysis in Section 3. We described the infrastructure as using a central server, and
demonstrated that it works for as many as 35 clients (Section 5). Communication
is one-way (client to server) and there is no consensus or agreement protocol, so
the total community traﬃc scales linearly with the number of clients.
This central server may be replaced, however, with alternatives that would
increase scalability and avoid a single point of failure. One option is a server hi-
erarchy; each server computes the community score for its children and reports
Community Epidemic Detection Using Time-Correlated Anomalies
379
this value and the size of that sub-community to a parent server. This arrange-
ment works precisely because the function used to compute the community score,
mean(), is associative (when weighted by sub-community size).
In addition to communication overhead, there is monitoring overhead on the
clients. This is typically a consequence of model choice and unaﬀected by com-
munity size. In our controlled experiments, the primary monitoring tool, dtrace,
required less than 10% of one CPU even during heavy activity by the monitored
application; the average usage was below 1%. In our deployment experiments
with Firefox, Syzygy required less than 5% of the CPU on average, and 7% peak,
including strace overhead (see Section 5.3). Using our strace-based implemen-
tation for Windows, however, the slowdown was noticeable. The overhead in our
Apache deployment (see Section 4), which took advantage of the web server’s
built-in logging mechanism, was negligible. If overhead becomes problematic,
then it may be worth changing the model to measure less costly signals. For
example, Sharif et al [30] implemented control-ﬂow monitoring with overhead
comparable to our system call-based approach—this optimization would likely
yield greater precision at lower overhead.
8 Contributions
Syzygy is an epidemic detection framework that looks for time-correlated anoma-
lies in a homogeneous software community—precisely the behavior that would
accompany an exploit as it executes among a set of clients. Our results show
that Syzygy is eﬀective at automated detection of epidemics, is practical to de-
ploy, and scales well. Syzygy takes advantage of the statistical properties of large
communities in a novel way, asymptotically approaching perfect detection.
Acknowledgments
The authors thank the members of the VERNIER team, especially Elizabeth
Stinson, Patrick Lincoln, Steve Dawson, Linda Briesemeister, Jim Thornton,
John Mitchell, and Peter Kwan. Thanks to Sebastian Gutierrez and Miles Davis
for help deploying Syzygy, to Naeim Semsarilar for his invaluable contributions
to the early stages of this work, and to Xuˆan V˜u for her input and support.
References
[1] Bouloutas, A., Calo, S., Finkel, A.: Alarm correlation and fault identiﬁcation in
communication networks. IEEE Transactions on Communications (1994)
[2] Brumley, D., Newsome, J., Song, D.: Sting: An end-to-end self-healing system for
defending against internet worms. In: Malware Detection and Defense (2007)
[3] Costa, M., Crowcroft, J., Castro, M., Rowstron, A., Zhou, L., Zhang, L., Barham,
P.: Vigilante: End-to-end containment of internet worms. In: SOSP (2005)
[4] Cuppens, F., Miege, A.: Alert correlation in a cooperative intrusion detection
framework. In: IEEE Symposium on Security and Privacy, pp. 202–215 (2002)
380
A.J. Oliner, A.V. Kulkarni, and A. Aiken
[5] Debar, H., Becker, M., Siboni, D.: A neural network component for an intrusion
detection system. In: IEEE Symposium on Security and Privacy (1992)
[6] Ellis, D.: Worm anatomy and model. In: WORM (2003)
[7] Eskin, E.: Anomaly detection over noisy data using learned probability distribu-
tions. In: ICML (2000)
[8] Feng, H.H., Kolesnikov, O.M., Fogla, P., Lee, W., Gong, W.: Anomaly detection
using call stack information. In: IEEE Symposium on Security and Privacy (2003)
[9] Forrest, S., Hofmeyr, S.A., Somayaji, A., Longstaﬀ, T.A.: A sense of self for unix
processes. In: IEEE Symposium on Security and Privacy (1996)
[10] Gao, D., Reiter, M.K., Song, D.: Gray-box extraction of execution graphs for
anomaly detection. In: CCS (2004)
[11] Gao, D., Reiter, M.K., Song, D.: Behavioral distance for intrusion detection. In:
Zamboni, D., Kr¨ugel, C. (eds.) RAID 2006. LNCS, vol. 4219, pp. 19–40. Springer,
Heidelberg (2006)
[12] Giﬃn, J.T., Jha, S., Miller, B.P.: Detecting manipulated remote call streams. In:
USENIX Security, pp. 61–79 (2002)
[13] Gu, G., C´ardenas, A.A., Lee, W.: Principled reasoning and practical applications
of alert fusion in intrusion detection systems. In: ASIACCS (2008)
[14] Hofmeyr, S.A., Forrest, S., Somayaji, A.: Intrusion detection using sequences of
system calls. Journal of Computer Security 6(3), 151–180 (1998)
[15] Huang, L., Garofalakis, M., Joseph, A.D., Taft, N.: Communication-eﬃcient track-
ing of distributed cumulative triggers. In: Intl. Conf. on Distributed Computing
Systems (ICDCS) (June 2007)
[16] Huang, L., Nguyen, X.L., Garofalakis, M., Hellerstein, J., Jordan, M., Joseph, A.,
Taft, N.: Communication-eﬃcient online detection of network-wide anomalies. In:
IEEE INFOCOM (2007)
[17] Jakobson, G., Weissman, M.: Alarm correlation. IEEE Network (1993)
[18] Javitz, H.S., Valdes, A.: The SRI IDES statistical anomaly detector. In: IEEE
Symposium on Security and Privacy (1991)
[19] King, S.T., Mao, Z.M., Lucchetti, D.G., Chen, P.M.: Constructing attack scenarios
through correlation of intrusion alerts. In: CCS (2002)
[20] Lincoln, P., et al.: Virtualized Execution Realizing Network Infrastructures En-
hancing Reliability (VERNIER), http://www.sdl.sri.com/projects/vernier/
[21] Locasto, M.E., Sidiroglou, S., Keromytis, A.D.: Software self-healing using collab-
orative application communities. In: NDSS (2005)
[22] Malan, D.J., Smith, M.D.: Host-based detection of worms through peer-to-peer
cooperation. In: ACM Workshop on Rapid Malcode (2005)
[23] Malan, D.J., Smith, M.D.: Exploiting temporal consistency to reduce false posi-
tives in host-based, collaborative detection of worms. In: WORM (2006)
[24] Mutz, D., Valeur, F., Vigna, G., Kruegel, C.: Anomalous system call detection.
In: TISSEC (2006)
[25] Newsome, J., Brumley, D., Song, D.: Vulnerability-speciﬁc execution ﬁltering for
exploit prevention on commodity software. In: NDSS (2006)
[26] Ning, P., Cui, Y., Reeves, D.S.: Constructing attack scenarios through correlation
of intrusion alerts. In: CCS (2002)
[27] Paxson, V.: Bro: a system for detecting network intruders in real-time. Computer
Networks 31 (1999)
[28] Porras, P.A., Neumann, P.G.: Emerald: event monitoring enabling responses
to anomalous live disturbances. In: National Computer Security Conference,
NIST/NCSC (1997)
[29] Sebring, M.M., Whitehurst, R.A.: Expert systems in intrusion detection: a case
study. In: National Computer Security Conference (1988)
Community Epidemic Detection Using Time-Correlated Anomalies
381
[30] Sharif, M., Singh, K., Giﬃn, J., Lee, W.: Understanding precision in host based
intrusion detection. In: Kruegel, C., Lippmann, R., Clark, A. (eds.) RAID 2007.
LNCS, vol. 4637, pp. 21–41. Springer, Heidelberg (2007)
[31] Smaha, S.: Haystack: an intrusion detection system. In: Aerospace Computer Se-
curity Applications Conference (1988)
[32] Staniford-chen, S., Cheung, S., Crawford, R., Dilger, M., Frank, J., Hoagl, J.,
Levitt, K., Wee, C., Yip, R., Zerkle, D.: Grids—a graph based intrusion detection
system for large networks. In: NIST/NCSC (1996)
[33] Tan, K.M.C., Maxion, R.A.: “Why 6?” Deﬁning the operational limits of stide, an
anomaly-based intrusion detector. In: IEEE Symposium on Security and Privacy
(2002)
[34] Ullrich, J.: DShield—distributed intrusion detection system,
http://www.dshield.org
[35] Vaccaro, H., Liepins, G.: Detection of anomalous computer session activity. In:
IEEE Symposium on Security and Privacy (1989)
[36] Valdes, A., Skinner, K.: Probabilistic alert correlation. In: Lee, W., M´e, L., Wespi,
A. (eds.) RAID 2001. LNCS, vol. 2212, p. 54. Springer, Heidelberg (2001)
[37] Wadge, W.W., Ashcroft, E.A.: Lucid, the dataﬂow programming language.
A.P.I.C. Studies in Data Processing (1985)
[38] Wagner, D., Soto, P.: Mimicry attacks on host-based intrusion detection systems.
In: CCS (2002)
[39] Wang, H.J., Platt, J.C., Chen, Y., Zhang, R., Wang, Y.-M.: Automatic miscon-
ﬁguration troubleshooting with PeerPressure. In: OSDI (2004)
[40] Weaver, N., Paxson, V., Staniford, S., Cunningham, R.: A taxonomy of computer
worms. In: WORM (2003)
[41] Weaver, N., Staniford, S., Paxson, V.: Very fast containment of scanning worms.
In: USENIX Security (2004)
[42] Williamson, M.M.: Throttling viruses: Restricting propagation to defeat malicious
mobile code. In: ACSAC (2002)
[43] Xie, Y., Kim, H., O’Hallaron, D., Reiter, M., Zhang, H.: Seurat: a pointillist
approach to anomaly detection. In: Jonsson, E., Valdes, A., Almgren, M. (eds.)
RAID 2004. LNCS, vol. 3224, pp. 238–257. Springer, Heidelberg (2004)
[44] Yegneswaran, V., Barford, P., Jha, S.: Global intrusion detection in the DOMINO
overlay system. In: NDSS (2004)
A Data-Centric Approach to Insider Attack
Detection in Database Systems
Sunu Mathew1,(cid:3), Michalis Petropoulos2,
Hung Q. Ngo2, and Shambhu Upadhyaya2
1 Information Security,
Amazon.com Inc., Seattle WA 98104, USA
PI:EMAIL
2 Computer Science and Engineering,
University at Buﬀalo, Buﬀalo NY 14260, USA
{mpetropo,hungngo,shambhu}@buffalo.edu
Abstract. The insider threat against database management systems is
a dangerous security problem. Authorized users may abuse legitimate
privileges to masquerade as other users or to maliciously harvest data.
We propose a new direction to address this problem. We model users’
access patterns by proﬁling the data points that users access, in contrast
to analyzing the query expressions in prior approaches. Our data-centric
approach is based on the key observation that query syntax alone is a
poor discriminator of user intent, which is much better rendered by what
is accessed. We present a feature-extraction method to model users’ ac-
cess patterns. Statistical learning algorithms are trained and tested using
data from a real Graduate Admission database. Experimental results in-
dicate that the technique is very eﬀective, accurate, and is promising
in complementing existing database security solutions. Practical perfor-
mance issues are also addressed.
1 Introduction
Ensuring the security and privacy of data assets is a crucial and very diﬃcult
problem in our modern networked world. Relational database management sys-
tems (RDBMS) are the fundamental means of data organization, storage and
access in most organizations, services, and applications. Naturally, the ubiquity
of RDBMSs led to the prevalence of security threats against these systems. An
intruder from the outside, for example, may be able to gain unauthorized ac-
cess to data by sending carefully crafted queries to a back-end database of a
Web application. This class of so-called SQL injection attacks are well-known
and well-documented, yet still very dangerous [1]. They can be mitigated by
adopting suitable safeguards, for example, by adopting defensive programming
techniques and by using prepared statements [2].
An insider attack against an RDBMS, however, is much more diﬃcult to
detect, and potentially much more dangerous [29,7,14]. According to the most
(cid:2) Work done as a graduate student at the University at Buﬀalo.
S. Jha, R. Sommer, and C. Kreibich (Eds.): RAID 2010, LNCS 6307, pp. 382–401, 2010.
c(cid:2) Springer-Verlag Berlin Heidelberg 2010
A Data-Centric Approach to Insider Attack Detection in Database Systems
383
recent U.S. Secret Service/CERT/Microsoft E-Crime report, insider attacks con-
stitute 34% of all surveyed attacks (outsiders constitute 37%, and the remain-
ing 29% have unknown sources). For example, insiders to an organization such
as (former) employees or system administrators might abuse their already ex-
isting privileges to conduct masquerading, data harvesting, or simply sabotage
attacks [11].
More formally, the RAND workshop devoted to insider threats [8] deﬁned an
insider as “someone with access, privilege or knowledge of information systems
and services,” and the insider threat problem as “malevolent (or possibly inadver-
tent) actions by an already trusted person with access to sensitive information
and information systems.” Examples of insider attacks include masquerading
and privilege abuse which are well-known threats in the ﬁnancial, corporate and
military domains; attackers may abuse legitimate privileges to conduct snooping
or data-harvesting [29] with malicious intent (e.g., espionage).
1.1 Main Ideas
By deﬁnition, detecting insider attacks by specifying explicit rules or policies is
a moot point: an insider is always deﬁned relative to a set of policies. Conse-
quently, we believe that the most eﬀective method to deal with the insider threat
problem is to statistically proﬁle normal users’ (computing) behaviors and raise
a ﬂag when a user deviates from his/her routine. Intuitively, a good statistical
proﬁler should be able to detect non-stealthy sabotage attacks, quick data har-
vesting attacks, or masquerading attacks, because the computing footprints of
those actions should be signiﬁcantly diﬀerent from day-to-day activities, from a
statistical point of view.
The user proﬁling idea for insider threat detection in particular, and anomaly
detection in general, is certainly not new (see, e.g., [30]). In the context of an
RDBMS (or any problem requiring statistical proﬁling), the novelty is in the
answers to two critical questions: (1) what is a user proﬁle (and how to construct
it)? and (2) which machine-learning techniques and models should we adopt so
that the proﬁles are practically useful for the detection problem? By “useful” we
mean some relevant classes of insider attacks can be detected to a good degree
of accuracy. By “practical” we mean the method can be deployed and perform
eﬀectively in a real RDBMS. The novelty and contributions of this paper come
from answering the above two questions.
Prior studies (e.g., [13,21,17,34,31,18]) have led to the development of intru-
sion detection systems (IDS) that aimed to protect databases from attacks. Our
contribution is complementary, and is focused speciﬁcally on analyzing users’
interactions with an RDBMS by means of database queries. Analysis of other
behavioral features useful in insider threat detection (location of the attacker, in-
formational correlation between consecutive queries, and temporal features such
as time between queries, duration of session, etc.) is beyond the scope of this
paper, and is considered future work.
Perhaps the most natural user “proﬁle” is the set of SQL queries a user issues
daily to the database, or more generally, some feature vectors representing past
384
S. Mathew et al.
queries. Indeed, [18] relied on the SQL-expression syntax of queries to construct
user proﬁles. This approach has the advantage that the query processing of the
insider detection system is computationally light: a new query is analyzed by
some statistical engine; only queries accepted by the engine are then issued to
the database. However, as we shall later demonstrate in this paper, this syntax-
centric view is ineﬀective and error-prone for database anomaly detection in
general, and for database insider threat detection, in particular. On the one hand,
queries may diﬀer widely in syntax yet produce the same “normal” (i.e., good)
output, causing the syntax-based detection engine to generate false positives.
On the other hand, syntactically similar queries may produce vastly diﬀerent
results, leading the syntax-based engine to generate false negatives.
Our main idea and also our conviction is that the best way to distinguish
normal vs. abnormal (or good vs. malicious) access patterns is to look directly
at what the user is trying to access – the result of the query itself – rather than
how he expresses it, i.e. the SQL expressions. In other words, this data-centric
approach values the semantics of the queries more than their syntax. When
a malicious insider tries to acquire new knowledge about data points and their
relationships, the data points accessed are necessarily diﬀerent from the old (i.e.,
previously) accessed points. This deviation occurs in the data harvesting attacks
as well as in the masquerading attacks (e.g., when an intruder gains access to
an insider’s account by means of a compromised account).
1.2 Contributions
Our ﬁrst contribution is the proposed data-centric viewpoint, which to the best
of our knowledge has not been studied in the database security and the insider
threat literature. Intuitively, the data-centric approach has the following advan-
tage: for an insider to evade our system, he has to generate queries producing
results that are statistically similar to the ones he would have gotten anyhow
with legitimate queries using his existing privileges, rendering the attempt at cir-
cumvention inconsequential. In contrast, in the syntax-based approach, queries
with similar syntax can give diﬀerent results: the attacker may be able to craft
a “good-looking” malicious query bypassing the syntax-based detection engine
to access data he’s not supposed to access. This point is validated in Sections 3,
5 and 6.
The second contribution is a method to extract a feature vector from the
result set of a query, which is the core of our answer to question (1) above. The
dimension of the feature vector is only dependent on the database schema, but
independent of the size of the database. In particular, the dimensionality of a
query’s feature vector is independent of how large the result set of the query is.
This bounded dimensionality also partially addresses scalability and performance
concerns the acute reader might have had. Section 4 details the method.
The third contribution is to address the following potential performance prob-
lem: a query has to be executed before the decision can be made on whether or
not it is malicious. What if a malicious query asks for hundreds of gigabytes of
data? Will the query have to be executed, and will our detection engine have to
A Data-Centric Approach to Insider Attack Detection in Database Systems
385