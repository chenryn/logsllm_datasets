ber, and 3 background noises (radio tuning, restaurant sounds, and
swimming pool environment) are available for obfuscation. Each
CAPTCHA consists of 5 digits, so for each position, there are 70
possibilities (7 voices by 10 digits). The total number of combina-
tions of voices and digits is therefore 1,680,700,000 (705), each of
which could be perturbed by one of the 3 background noises for a
total of 5,024,100,000 unique possible CAPTCHAs. While our neural
network is unable to solve every possibility, we found that there
are some combinations which are quite difficult for humans as well.
Moreover, we believe that we could reduce the size even fur-
ther without a substantial loss of accuracy because the long short-
term memory layers may be unnecessarily large for a CAPTCHA-
breaking task. Unlike unCaptcha, we aim to develop our model to
be fully independent of other speech recognition systems as well
as totally end-to-end. DeepCRACk performs no pre-processing,
analyzes the data locally, and returns a complete prediction result.
It also has no knowledge of the length of the CAPTCHA, even
though SimpleCaptcha always generates CAPTCHAs of length 5
by default. We could not use Mozilla’s pre-trained binaries as a
starting point because their model only includes lowercase letters
and no digits inherently. In order to build upon our model for future
use, we simply expanded the default alphabet to include the digits
0 through 9 and retrained from the beginning. Given a change in
CAPTCHA type that is alpha-numeric based, our model could serve
as the baseline for transfer learning as well.
4 EVALUATION
To show the feasibility of DeepCRACk, we examined its perfor-
mance with CAPTCHA challenges generated by SimpleCaptcha.
For evaluation, we generated 100,000 SimpleCaptcha samples for
our train set, 10,000 for our development set, and 10,000 for our test
set. We trained our model on the Google Cloud Compute engine
using a Tesla K80 GPU. Google provides $300 worth of compute
usage for a free trial, and our entire training time was slightly more
than 24 hours, which is well within the free trial limit.
On the testing set of 10,000 SimpleCaptcha samples, DeepCRACk
performed well, obtaining an accuracy of 98.8%. We consider dig-
its which occurred in the audio and which were detected as true
positives (49,946). We consider digits which were reported by the
system but which were not actually present as false positives (75),
and we consider digits which were present in the audio but which
Poster SessionASIACCS’18, June 4–8, 2018, Incheon, Republic of Korea798were not detected as false negatives (52). Using this, our system
performed with 99.85% precision, and with 99.89% recall. The time
required to solve a CAPTCHA was 1.25 seconds on average with a
standard deviation of 0.065 seconds on a MacBook Pro Early 2011
model (8GB RAM, 2.3GHz CPU) running High Sierra 10.13.3 and
running Deep Speech 0.1.1 in CPU mode. Therefore, given a model
trained to crack SimpleCaptcha, most commodity hardware will be
able to solve SimpleCaptcha’s default CAPTCHAs in real time.
Focusing on one type of audio CAPTCHA runs the risk of over-
fitting to that particular task, and indeed, our model does not gen-
eralize to new obfuscation techniques and voices. It cannot solve
other audio CAPTCHAs, even those that are numeric. For example,
DeepCRACk was unable to solve any numerical audio CAPTCHAs
generated by reCAPTCHA. ReCAPTCHA uses a wider variety of
obfuscation techniques and utilizes voices different from those that
appear in SimpleCaptcha. Nonetheless, creating a model that over-
fits to a particular CAPTCHA scheme will suffice. We propose that
breaking other similar CAPTCHA systems with comparable effi-
ciency will be possible after sufficient data collection and training.
5 ADVERSARIAL SOLUTION EXPLORATION
There already exist many proposals for replacing visual CAPTCHAs,
most of which require the user to identify items ranging from
biometric features like eyes [7] to everyday objects like chairs [6]
in complex scenes. Nonetheless, these types of CAPTCHAs are
completely inaccessible to those users with poor or no eyesight. For
audio CAPTCHAs, increasing the obfuscation of the sound would
deter more bots, but this would also inhibit human users as well.
The authors of unCaptcha [1] propose that auditory instructions
like “type the following word” could serve as the next generation of
audio CAPTCHAs, but there may be solutions available to augment
current mechanisms without dramatic architecture changes.
Carlini and Wagner have shown that Deep Speech is vulnerable
to audio-based adversarial attacks [2]. Although at this point re-
search has not demonstrated universal perturbations, these findings
represent a preliminary step to curb CAPTCHA-defeating neural
networks. In our test, we used Deep Speech’s pre-trained models
and Carlini’s method hosted on GitHub2 to generate adversarial
audio against DeepCRACk. The source audio samples were Sim-
pleCaptchas, and our target adversarial audio was “one two three
four five” (Deep Speech pre-trained releases do not allow for digits).
On the 100 SimpleCaptcha samples we used, Carlini’s adversarial
generation technique was able to correctly fool the same release
that generated the audio (either 0.1.0 or 0.1.1) to return the target
adversarial audio, and it was able to confuse the other model as
well, which returned nonsense like “o i o sax rl”. However, our
DeepCRACk model correctly returned the ground truth. Our model
performed with 100% accuracy while Deep Speech’s pre-trained
models performed with 0% accuracy on these adversarial examples.
Note that at this time we are unable to create adversarial examples
targeting DeepCRACk’s model because its shape differs from Deep
Speech’s default shape; we leave this application for future work.
As for the inability to fool DeepCRACk using other pre-trained
releases, the difference likely lies in the size of the trained mod-
els as well as the data they were trained on. Further research will
2https://github.com/carlini/audio_adversarial_examples
determine whether it is possible to apply adversarial audio gener-
ation from one neural network architecture to another. For now,
fooling an audio-cracking neural network requires knowledge of
the underlying architecture on which it was trained, which is not
reasonable for large scale CAPTCHA deployment.
6 CONCLUSION
In this paper, we proposed an end-to-end neural network capable
of defeating SimpleCaptcha’s default settings at 98.8% accuracy. A
replication of our work could be performed using Google Cloud
Compute’s free trial well within the free trial time period. We
also investigated the robustness of DeepCRACk against adversarial
audio samples attempting to confuse our model. Our DeepCRACk
implementation successfully recognizes adversarial samples while
the popularly used speech recognition system Deep Speech fails
against them. Even though the tested adversarial examples were
not generated to target our DeepCRACk implementation directly,
the experiment results demonstrate the potential effectiveness of
DeepCRACk against adversarial examples. As part of future work,
we plan to implement more sophisticated adversarial audio samples
and evaluate the performance of DeepCRACk against them.
RESPONSIBLE DISCLOSURE
We demonstrate a fully working attack tool that is capable of solving
SimpleCaptcha. We contacted the primary creator to report our
findings via SourceForge and highly encourage future adopters
to provide their own voice samples and obfuscating background
sounds. Doing so would allow for audio CAPTCHA implementation
while still providing some protection, at least in the short term.
ACKNOWLEDGMENTS
This research was supported in part by the ITRC program (IITP-
2017-2015-0-00403) and the NRF program (2017R1D1A1B03030627).
REFERENCES
[1] Kevin Bock, Daven Patel, George Hughey, and Dave Levin. 2017. unCaptcha: a
low-resource defeat of reCaptcha’s audio challenge. In Proceedings of the 11th
USENIX Workshop on Offensive Technologies.
[2] Nicholas Carlini and David Wagner. 2018. Audio adversarial examples: Targeted
attacks on speech-to-text. arXiv preprint arXiv:1801.01944 (January 2018).
[3] Google. 2018 (accessed March 1, 2018). Google reCAPTCHA: Tough on bots, Easy
on humans. https://www.google.com/recaptcha/intro/android.html
[4] Awni Hannun, Carl Case, Jared Casper, Bryan Catanzaro, Greg Diamos, Erich
Elsen, Ryan Prenger, Sanjeev Satheesh, Shubho Sengupta, Adam Coates, and
Andrew Y. Ng. 2014. Deep Speech: Scaling up end-to-end speech recognition.
arXiv preprint arXiv:1412.5567 (December 2014).
[5] Martin Kopp, Matěj Nikl, and Martin Holeň. 2017. Breaking CAPTCHAs with con-
volutional neural networks. In Proceedings of the 17th Conference on Information
Technologies - Applications and Theory.
[6] Brian M. Powell, Ekampreet Kalsy, Gaurav Goswami, Mayank Vatsa, Richa Singh,
and Afzel Noore. 2017. Attack-Resistant aiCAPTCHA using a negative selection
artificial immune system. In IEEE Security and Privacy Workshops.
[7] Brian M. Powell, Abhishek Kumar, Jatin Thapar, Gaurav Goswami, Mayank Vatsa,
Richa Singh, and Afzel Noore. 2016. A multibiometrics-based CAPTCHA for
improved online security. In IEEE 8th International Conference on Biometrics
Theory, Applications and Systems.
[8] Suphannee Sivakorn, Iasonas Polakis, and Angelos D Keromytis. 2016.
I am
robot: (deep) learning to break semantic image CAPTCHAs. In IEEE European
Symposium on Security and Privacy (EuroS&P).
[9] Christine Sket. 2017 (accessed March 8, 2018). 508 Compliance: Who Needs to be
Compliant? https://brailleworks.com/508-compliance-needs-compliant/
Poster SessionASIACCS’18, June 4–8, 2018, Incheon, Republic of Korea799