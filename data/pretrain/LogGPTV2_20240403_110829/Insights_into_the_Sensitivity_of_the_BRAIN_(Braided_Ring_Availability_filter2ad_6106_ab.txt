### Software for Selecting the First Redundant Data Copy

In addition to selecting the first redundant data copy, the partitioning and fault detection guarantees of these approaches are excellent. Moreover, application software remains independent of the platform software.

### Advantages of High-Integrity Compute for Application Software Development

The automotive industry, for example, leverages high-integrity compute through the use of fail-silent ECUs (Electronic Control Units). Our model assumes that any single integrity violation by the platform may have safety implications, as a computed and distributed data value may be used by multiple, possibly replicated, actuators.

### Safety from an Availability Perspective

From a safety perspective, the model is concerned with redundancy exhaustion, which can lead to component isolation and loss of communication. For instance, if communication between distributed components cannot be guaranteed, we assume that safety is compromised. A detailed description of the model and the factors leading to loss of communication or decreased integrity is provided below.

### 4.1 Model Parameters

A by-wire architecture typically consists of several components connected to the network. The number of components depends on the specific architectural approach. We expect 8 to 12 nodes directly connected to the network, supporting connections to units for transmission, engine, distributed actuators and sensors, and control computers [1][11][23][29].

Commercial transport airplanes operate for missions averaging 3-10 hours, with major checks every few hundred hours. In the automotive sector, a car is driven on average for 4,000 hours [28]. Ensuring safety over such long periods without checks may not be economically viable. Additionally, car electronics may not be equipped or capable of performing the necessary scrubbing activities to detect latent faults. Therefore, we assume that at every major service—similar to service procedures in the aerospace domain and increasingly common due to higher levels of diagnosis [28]—the car’s by-wire electronic and wire loom will be checked for correctness and latent faults. Major service intervals where all latent errors can be detected are assumed to be around 150 hours, equivalent to approximately 5,250 miles (8,450 km) at 35 mph (56 kph). Such service intervals are currently not mandated in most countries but are recommended during the vehicle warranty period. The results of this paper could be used to consider the impact of service intervals on safety. Error detection coverage at service is assumed to be largely perfect, as manufacturing-level testing can be deployed for critical circuits. The service is expected to scrub all essential FDIR (Fault Detection, Isolation, and Recovery) circuits using scan chains [32], similar to production-level tests.

Component failures are detected based on the underlying network architecture. Once detected, the operation of the by-wire system will be extended for a certain interval. According to U.S. census data [37], the average transit time by car from home to work is 30 minutes. It is assumed that an extension period of 1 hour should be sufficient to return home or drive to a repair facility in case of a detected error. The models will contrast the approach by running simulations with near-immediate repair (1 minute), no repair (modeled as a very low repair rate of 10^-10), and some repair intervals around one hour. For reference, Boeing 777’s ETOPS rating allows the airplane to fly for up to 180 minutes on a single engine. The maximum operating time for engine electronics is 125 hours if the time of fault occurrence is known [31].

Component failure rate parameter ranges were chosen based on our experience with similar technologies and reliability models determined by CALCE [27] and according to MIL-HDBK-217 [26] (note that MIL-HDBK-217 is no longer maintained but remains a good public source for reliability data). Connector failure rates depend on the chosen connector type. While connectors may not perfectly fit the exponential distribution (i.e., constant failure rate), the model and the requirement to quickly solve the model for many different parameters force us to make this assumption. We assume link failure rates are dominated by connector failure rates.

We use a hybrid component fault model where fail-stop failures are assumed to be more frequent than arbitrary node faults, as a node is likely to be part of an ECU (Electronic Control Unit) or an LRU (Line Replaceable Unit). The reliability of such parts (LRU or ECU) is often driven by the power supply unit and a significant number of supply components, leading to a low MTBF (Mean Time Between Failures) rate but with benign system behavior like fail-stop. Arbitrary behavior is driven by the communication chip performing forwarding, checking, and protocol activities. This behavior is probably unboundable, leading to arbitrary behavior in a failure case. The failure rates of these components are assumed to be similar to the reliability numbers of the communication chip (or the chip where the communication chip is part of).

Table 1 provides an overview of the parameter values used for the BRAIN and dual-star model, along with the most representative values (MRV in the table). These MRVs are used when other parameters are varied to show sensitivity to variation.

| Parameter | Values | MRV |
| --- | --- | --- |
| Number of active nodes | 7, 8, 9, 10, 11, 12, 13, 14 | 10 |
| Mission interval [hours] | ½, 1, 20, 50, 100, 120, 150, 200, 250, 3k, 4k, 5k, 6k, 7k | 150 |
| Link failure rate [failures/hour] | 5x10^-7, 10^-6, 2x10^-6, 5x10^-6 | 10^-6 |
| Component failure rate (fail-stop) [failures/hour] | 5x10^-6, 10^-5, 2x10^-5 | 10^-5 |
| Component failure rate (arbitrary) [failures/hour] | 5x10^-8, 10^-7, 5x10^-7 | 10^-7 |
| Repair rate (extended operation time) [1/hours] | 10^-10 (no repair), 0.1 (10 h), 0.5 (2 h), 1 (1 h), 60 (1 min.; near immediate repair) | 1 |

### 4.2 Description of BRAIN Model

The BRAIN can guarantee platform availability and integrity, and thus safety, as long as there is either:
1. One communication path with full propagation integrity from the sender to all receivers, or
2. Two paths from the sender to the receiver where the receiver can perform bit-for-bit comparison between the two paths.

In the first case, a single arbitrary component can be tolerated because each receiver has one path from the sender. Each node on the path checks the direct and skip links bit-for-bit for agreement, then signals the result via an integrity signaling field [18]. This prevents any arbitrarily faulty node from corrupting data during propagation without being detected. Similarly, for single link or other benign component faults, the data will also reach each node on the ring with full integrity.

In the second case, for multiple benign faults (fail-stop), all receiving nodes detect the multiple fault scenario because the integrity field at the end of the data indicates loss of integrity from both directions on the ring. Once detected, the receiver can perform bit-for-bit comparison of the two copies received from each direction and still ensure full integrity of the data.

Medium availability is enforced by guardian mechanisms, performed by each node for its two direct neighbors. Synchronization is guaranteed as long as the nodes send synchronization messages. The SURE model defines state spaces for fail-silent and arbitrary component failures, link failures, and self-checking pair failures (i.e., the link between the pairs or at least one of the two nodes has failed). Link failures are assumed to be benign (e.g., a link is broken or not, but does not "corrupt" data integrity). A special state to model the loss of connectivity in one ring direction is also modeled. Transitions between states are guided by failure or repair rates. Details of the state space and its transitions are not within the scope of this paper, but we modeled the above-described behaviors.

ASSIST/SURE/STEM requires the definition of “death states,” which define when the integrity and availability of the communication can no longer be guaranteed due to faults. These states are at a higher level:
- More than one arbitrary component fault present,
- An arbitrary fault with any other fault combination (link or benign component fault),
- The connectivity from a sender to each receiver is less than two paths (which is either two fail-stop component faults or multiple link failures occurred where connectivity from sender and receivers via two paths is broken), or
- All self-checking pairs failed and protocol execution is compromised (due to link failure between self-checking pairs or component failure).

As the BRAIN performs bit-for-bit comparisons at each node, any error is immediately detected. From the detection of an error, extended operation is allowed until the faulty sub-component is repaired. The time to repair is a parameter, also referred to as the time for extended operation.

In addition to the model parameters in Table 1, the BRAIN-specific model parameter (Table 2) is the number of self-checking pairs needed for protocol operation, such as clock synchronization, startup, and integration.

| Parameter | Values | MRV |
| --- | --- | --- |
| Number of self-checking pairs | 1, 2, 3, 4 | 3 |

### 4.3 Description of Dual-Star Model

To compare the BRAIN to alternative architectures, we evaluated a commonly used architectural alternative, a dual-star model. Given cost constraints, a dual-star model seems to be the best of the alternatives (ring/star/bus dual) for the following reasons: pure bus-based architectures suffer from spatial proximity faults and are likely excluded for by-wire architectures. Ring architectures (without skip links) have low reliability due to the missing path to circumvent (benign) faulty nodes [33] and masquerading faults for forwarded data. Combinations such as ring/star architectures (e.g., wagon wheel architecture) can be powerful but can introduce reliability loss due to serialization of one communication path.

In the star model, benign and arbitrary component faults and link failures are modeled. Given the protocol dependencies of solutions on the market [24][25], solutions are thought to be single-fault tolerant to arbitrary failures from a protocol perspective.

For a dual-star model, evaluating inline integrity approaches and their effect on safety is particularly challenging, as it is difficult to quantify the effects of an undetected error on the application. For example, what are the effects of an erroneous guardian (star) on data integrity? The model assumes that any undetected error may have a safety impact. As the two communication paths in a dual-star network architecture are used for availability with inline integrity protection, any arbitrary faulty star may have an effect.

If a star is arbitrarily faulty, the faulty star is detected with near 100% probability due to the integrity check (e.g., a CRC). However, despite the high probability of detecting the star error, the probability of undetected errors and, thus, data integrity violations remains. This probability of undetected errors depends on the strength of the inline integrity mechanism deployed to cover failures of the intermediate device. Currently, deployed dual-star networks [24][25] use a 24-bit CRC for error detection. Assuming a uniform failure distribution for failures of the central guardian device affecting a frame, the probability of an undetected integrity failure of a frame is 2^-24 (about 5.96x10^-8).

At 5 Mbit/s, it takes 100 µs to send a frame with an average frame length of 500 bits. If the network is 50% loaded, 1.8x10^7 frames would be sent per hour. This rate would lead to about 1 (=2^-24 x 1.8 x 10^7) undetected frame per hour once a star is faulty.

Internal Honeywell explorations of the CRC32 polynomial used in Ethernet indicate that the probability of undetected errors is increased from 2^-32 to 2^-28 for reasonable failure modes in intermediate relaying devices (such as switches or guardians) [30]. Such failure modes are characterized by the relaying device introducing systematic errors (such as a stuck-at-0 or 1 bit every 32 bits of a frame). Such faults may be common in intermediate devices.