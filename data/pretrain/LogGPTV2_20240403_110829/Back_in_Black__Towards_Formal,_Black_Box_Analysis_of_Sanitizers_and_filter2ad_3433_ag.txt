





Fig. 8. Equivalence Checking of HTML encoder implementations.
conclusive. For example, the fact that we found that the twitter
and facebook encoders are equal does not mean that there is no
string in which the two sanitizers differ. This is fundamental
limitation of all black-box testing algorithms. In fact, even the
results on differences between sanitizers might be incorrect
in principle. However, in this case we can easily verify the
differences and, if necessary, update the corresponding models
for the encoders.
VIII. RELATED WORK
Our work is mainly motivated by recent advances in
the analysis of sanitizers and regular expressions, a line of
work which was initiated with the introduction of symbolic
automata [11], although similar constructions were suggested
much earlier [31]. The BEK language was introduced by
Hooimeijer et al. [8] and the theory behind symbolic ﬁnite
state transducers was extended in a follow up paper [15].
Symbolic automata, transducers and the BEK language is a
very active area of research [14], [32]–[35] and we expect that
BEK programs will get more widespread adoption in the near
future. In the inference of symbolic automata and transducers
there are two relevant recent works. Botincan and Babic [36]
used symbolic execution in combination with the Shabaz-Groz
algorithm in order to infer symbolic models of programs as
symbolic lookback transducers. Although the authors claim
that equivalence of symbolic lookback transducers(SLT) is
decidable a paper published recently by Veanes [37] shows
that equivalence of SLTs is in fact undecidable. Moreover,
although [36] implements a symbolic version of Angluin’s
algorithm, in their system the predicates are obtained through
104104
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:12:23 UTC from IEEE Xplore.  Restrictions apply. 
symbolic execution, and therefore, there is no need to infer
the predicate guards or infer the correct transitions for each
state. Since their system is using the Shabaz-Groz algorithm,
our improved counterexample processing would provide an
exponentially faster way to handle counterexamples in their
case too.
The second closely related work in the inference of sym-
bolic automata was done by Maller and Mens [22].They
describe an algorithm to infer automata over ordered alpha-
bets which is a speciﬁc instantiation of symbolic automata.
However, in order to correctly infer such an automaton the
authors assume that the counterexample given by the equiv-
alence oracle is of minimal length and this assumption is
used in order to distinguish between a wrong transition in the
hypothesis or a hidden state. Unfortunately, verifying that a
counterexample is minimal requires an exponential number of
queries and thus this assumption does not lead to a practical
algorithm for inferring symbolic automata. On the other hand,
our algorithm is more general, as it works for any kind of
predicate guards as long as they are learnable, and moreover
does not assume a minimal length counterexample making the
algorithm practical.
The work on active learning of DFAs was initiated by An-
gluin [19] after a negative result of Gold [38] who showed that
it is NP-Hard to infer the minimal automaton consistent with
a set of samples. After its introduction, Anlguin’s algorithm
was improved and many variatons were introduced; Rivest and
Schapire [20] showed how to improve the query complexity
of the algorithm and introduced the binary search method for
processing counterexamples. Balcazar et al. [39] describe a
general approach to view the different variations of Angluin’s
algorithm.
Shabaz and Groz [12] extended Angluin’s algorithm to
handle Mealy Machines and introduced the counterexamlpe
processing we discussed above. Their approach was then
extended by Khalili and Tacchella [40] to handle non deter-
ministic Mealy Machines. However, as we point out above
mealy machines in general are not expressive enough to model
complex sanitization functions. Moreover, the algorithm by
Khalili and Tacchella uses the Shabaz-Groz counterexample
processing thus it can be improved using our method. Since
Shabaz-Groz is used in many contexts including the reverse en-
gineering of Command and Control servers of botnets [41], we
believe that our improved counterexample processing method
will ﬁnd many applications. Lately, inference techniques were
developed for more complex classes of automata such as
register automata [42]. These automata are allowed to use a
ﬁnite number of registers [43]. Since registers were also used
in some case during the analysis of sanitizer functions [15], and
speciﬁcally decoders, we believe that expanding our work to
handle register versions of symbolic automata and transducers
is a very interesting direction for future work.
The implementation of our equivalence oracle is inspired
by the work of Peled et al. [23]. In their work, a similar
equivalence oracle implementation is described for checking
Buichi automata, however, their implentation also utilizes the
Vasileski-Chow algorithm [44], an algorithm for checking
compliance of two automata, given an upper bound on the
size of the black-box automaton. This algorithm however,
has a worst case exponential complexity a fact which makes
it inpractical for real applications. On the other hand, we
demonstrate that our GOFA algorithm is able to infer 90%
of the states of the target ﬁlter on average.
The algorithm for initializing the observation table was ﬁrst
described by Groce et al. [45]. In their paper they describe
the initialization procedure and prove two lemmas regarding
the efﬁciency of the procedure in the context of their model
checking algorithm. However, the lemma proved just shows
convergence and they are not concerned with the reduction of
equivalence queries as we prove.
There is a large body of work regarding whitebox pro-
gram analysis techniques that aim at validating the security
of sanitizer code. The SANER [4] project uses static and
dynamic analysis to create ﬁnite state transducers which are
overapproximations of the sanitizer functions of programs.
Minamide [5] constructs a string analyzer for PHP which
is used to detect vulnerabilities such as cross site scripting.
He also describes a classiﬁcation of various PHP functions
according to the automaton model needed to describe them.
The Reggae system [6] attempts to generate high coverage test
cases with symbolic execution for systems that use complex
regular expressions. Wasserman and Su [7] utilize Context free
grammars to construct overapproximations of the output of
a web application. Their approach could be used in order
to implement a grammar which can then be used as an
equivalence oracle when applying the cross checking algorithm
for verifying equality between two different implementations.
IX. CONCLUSIONS AND FUTURE WORK
Clearly, we are light of need for robust and complete black-
box analysis algorithms for ﬁlter programs. In this paper we
presented a ﬁrst set of algorithms which could be utilized to
analyze such programs. However, the space for research in this
area is still vast. We believe that our algorithms can be further
tuned in order to achieve an even larger performance increase.
Moreover, more complex automata model which are currently
being used [14], [43] can be also utilized to further reduce the
number of queries required to infer a sanitizer model. Finally,
we point out that totally different models might be necessary
to handle other types of ﬁlters programs which are based on
big data analytics or on the analysis of network protocols.
Thus, to conclude we believe that black-box analysis of ﬁlters
and sanitizers presents a fruitful research area which deserves
more attention due to both scientiﬁc interest and practical
applications.
ACKNOWLEDGEMENTS
This work was supported by the Ofﬁce of Naval Research
(ONR) through contract N00014-12-1-0166. Any opinions,
ﬁndings, conclusions, or recommendations expressed herein
are those of the authors, and do not necessarily reﬂect those
of the US Government or ONR.
REFERENCES
[1] D. L. Eduardo Vela, “Our favorite xss ﬁlters/ids and how to attack
them,” in Black Hat Brieﬁngs, 2009.
[2] D. Evteev, “Methods to bypass a web application methods to
bypass a web application ﬁrewall.” http://ptsecurity.com/download/
PT-devteev-CC-WAF-ENG.pdf.
105105
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:12:23 UTC from IEEE Xplore.  Restrictions apply. 
[3] S. Esser, “Web application ﬁrewall bypasses and php exploits
http://www.suspekt.org/downloads/
-rss‘09
RSS09-WebApplicationFirewallBypassesAndPHPExploits.pdf.
november
2009.”
[4] D. Balzarotti, M. Cova, V. Felmetsger, N. Jovanovic, E. Kirda,
C. Kruegel, and G. Vigna, “Saner: Composing static and dynamic
analysis to validate sanitization in web applications,” in Security and
Privacy, 2008. SP 2008. IEEE Symposium on, pp. 387–401, IEEE, 2008.
[5] Y. Minamide, “Static approximation of dynamically generated web
pages,” in Proceedings of the 14th international conference on World
Wide Web, pp. 432–441, ACM, 2005.
[6] N. Li, T. Xie, N. Tillmann, J. de Halleux, and W. Schulte, “Reg-
gae: Automated test generation for programs using complex regular
expressions,” in Automated Software Engineering, 2009. ASE’09. 24th
IEEE/ACM International Conference on, pp. 515–519, IEEE, 2009.
[7] G. Wassermann and Z. Su, “Sound and precise analysis of web
applications for injection vulnerabilities,” in ACM Sigplan Notices,
vol. 42, pp. 32–41, ACM, 2007.
[8] P. Hooimeijer, P. Saxena, B. Livshits, M. Veanes, and D. Molnar, “Fast
and precise sanitizer analysis with bek,” in In 20th USENIX Security
Symposium, 2011.
[9] D. Bates, A. Barth, and C. Jackson, “Regular expressions considered
harmful in client-side xss ﬁlters,” in Proceedings of the 19th interna-
tional conference on World wide web, pp. 91–100, ACM, 2010.
“Programming
https://en.wikipedia.org/wiki/Programming languages used in most
popular websites. Accessed: 2015-11-10.
popular websites.”
languages
in most
used
[10]
[11] M. Veanes, P. d. Halleux, and N. Tillmann, “Rex: Symbolic regular
expression explorer,” in Proceedings of the 2010 Third International
Conference on Software Testing, Veriﬁcation and Validation, ICST ’10,
(Washington, DC, USA), pp. 498–507, IEEE Computer Society, 2010.
[12] M. Shahbaz and R. Groz, “Inferring mealy machines,” in Proceedings
of the 2Nd World Congress on Formal Methods, FM ’09, (Berlin,
Heidelberg), pp. 207–222, Springer-Verlag, 2009.
[13] A. Doup´e, L. Cavedon, C. Kruegel, and G. Vigna, “Enemy of the
state: A state-aware black-box web vulnerability scanner.,” in USENIX
Security Symposium, pp. 523–538, 2012.
[14] M. Veanes, T. Mytkowicz, D. Molnar, and B. Livshits, “Data-parallel
string-manipulating programs,” in Proceedings of
the 42nd Annual
ACM SIGPLAN-SIGACT Symposium on Principles of Programming
Languages, pp. 139–152, ACM, 2015.
[15] N. Bjorner, P. Hooimeijer, B. Livshits, D. Molnar, and M. Veanes,
“Symbolic ﬁnite state transducers, algorithms, and applications,” in IN:
PROC. 39TH ACM SYMPOSIUM ON POPL., 2012.
[16] M. Veanes, P. De Halleux, and N. Tillmann, “Rex: Symbolic regular
expression explorer,” in Software Testing, Veriﬁcation and Validation
(ICST), 2010 Third International Conference on, pp. 498–507, IEEE,
2010.
J. Hopcroft, “An n log n algorithm for minimizing states in a ﬁnite
automaton,” tech. rep., DTIC Document, 1971.
[17]
[18] M. J. Kearns and U. V. Vazirani, An introduction to computational
learning theory. MIT press, 1994.
[19] D. Angluin, “Learning regular sets from queries and counterexamples,”
Information and computation, vol. 75, no. 2, pp. 87–106, 1987.
[20] R. L. Rivest and R. E. Schapire, “Inference of ﬁnite automata using
homing sequences,” Information and Computation, vol. 103, no. 2,
pp. 299–347, 1993.
J. E. Hopcroft, Introduction to automata theory, languages, and com-
putation. Pearson Education India, 1979.
[21]
[22] O. Maler and I.-E. Mens, “Learning regular languages over large
alphabets,” in Tools and Algorithms for the Construction and Analysis
of Systems, pp. 485–499, Springer, 2014.
[23] D. Peled, M. Y. Vardi, and M. Yannakakis, “Black box checking,” in
Formal Methods for Protocol Engineering and Distributed Systems,
pp. 225–240, Springer, 1999.
“Fado library.” https://pypi.python.org/pypi/FAdo. Accessed: 2015-11-
10.
[24]
[25] A. Carayol and M. Hague, “Saturation algorithms for model-checking
pushdown systems,” EPTCS, vol. 151, pp. 1–24, 2014.
“Mod-security.” https://www.modsecurity.org/. Accessed: 2015-11-10.
[26]
[27]
[28]
[29]
[30]
“Phpids source code.” https://github.com/PHPIDS/PHPIDS. Accessed:
2015-11-10.
“How to conﬁgure urlscan 3.0 to mitigate sql injection attacks.” http:
//goo.gl/cmU0ze. Accessed: 2015-11-10.
“Yaxx project.” https://code.google.com/p/yaxx/. Accessed: 2015-11-
10.
“Microsoft antixss library.” https://msdn.microsoft.com/en-us/security/
aa973814.aspx. Accessed: 2015-11-10.
[31] B. W. Watson, “Implementing and using ﬁnite automata toolkits,”
Natural Language Engineering, vol. 2, no. 04, pp. 295–302, 1996.
[32] L. D’Antoni and M. Veanes, “Minimization of symbolic automata,” in
ACM SIGPLAN Notices, vol. 49, pp. 541–553, ACM, 2014.
[33] L. DAntoni and M. Veanes, “Equivalence of extended symbolic ﬁnite
transducers,” in Computer Aided Veriﬁcation, pp. 624–639, Springer,
2013.
[34] M. Veanes, “Symbolic string transformations with regular lookahead
and rollback,” in Perspectives of System Informatics, pp. 335–350,
Springer, 2014.
[35] R. A. Cochran, L. D’Antoni, B. Livshits, D. Molnar, and M. Veanes,
“Program boosting: Program synthesis via crowd-sourcing,” in ACM
SIGPLAN Notices, vol. 50, pp. 677–688, ACM, 2015.
[36] M. Botinˇcan and D. Babi´c, “Sigma*: symbolic learning of input-output
speciﬁcations,” ACM SIGPLAN Notices, vol. 48, no. 1, pp. 443–456,
2013.
[37] L. DAntoni and M. Veanes, “Extended symbolic ﬁnite automata and
transducers,” Formal Methods in System Design, July 2015.
[39]
[38] E. M. Gold, “Complexity of automaton identiﬁcation from given data,”
Information and control, vol. 37, no. 3, pp. 302–320, 1978.
J. L. Balc´azar, J. D´ıaz, R. Gavalda, and O. Watanabe, Algorithms for
learning ﬁnite automata from queries: A uniﬁed view. Springer, 1997.
[40] A. Khalili and A. Tacchella, “Learning nondeterministic mealy ma-
chines,” in Proceedings of the 12th International Conference on Gram-
matical Inference, ICGI 2014, Kyoto, Japan, September 17-19, 2014.,
pp. 109–123, 2014.
[41] C. Y. Cho, D. Babic, E. C. R. Shin, and D. Song, “Inference and
analysis of formal models of botnet command and control protocols,”
in Proceedings of the 17th ACM Conference on Computer and Com-
munications Security, CCS 2010, Chicago, Illinois, USA, October 4-8,
2010, pp. 426–439, 2010.
[42] F. Howar, B. Steffen, B. Jonsson, and S. Cassel, “Inferring canonical
register automata,” in Veriﬁcation, Model Checking, and Abstract Inter-
pretation, pp. 251–266, Springer, 2012.
[43] S. Cassel, F. Howar, B. Jonsson, M. Merten, and B. Steffen, “A succinct
canonical register automaton model,” Journal of Logical and Algebraic
Methods in Programming, vol. 84, no. 1, pp. 54–66, 2015.
[44] T. S. Chow, “Testing software design modeled by ﬁnite-state machines,”
IEEE transactions on software engineering, no. 3, pp. 178–187, 1978.
[45] A. Groce, D. Peled, and M. Yannakakis, “Adaptive model checking,”
in Tools and Algorithms for the Construction and Analysis of Systems,
pp. 357–370, Springer, 2002.
“Xss
Evasion Cheat Sheet. Accessed: 2016-01-10.
https://www.owasp.org/index.php/XSS Filter
sheet.”
cheat
[46]
[47] L. Pitt and M. K. Warmuth, “The minimum consistent dfa problem
cannot be approximated within any polynomial,” Journal of the ACM
(JACM), vol. 40, no. 1, pp. 95–142, 1993.
“Bek guide.” http://www.rise4fun.com/Bek/tutorial/guide2. Accessed:
2015-11-10.
[48]
[49] Y. Freund and R. E. Schapire, “Large margin classiﬁcation using the
perceptron algorithm,” Mach. Learn., vol. 37, pp. 277–296, Dec. 1999.
APPENDIX
A. Comparison of GOFA algorith with random testing
Regarding the usefulness of GOFA algorithm as a security
auditing method it is important to consider it in comparison
to random testing/fuzzing. Currently, most tools in the black-
box testing domain, such as web vulnerability scanners, work
106106
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:12:23 UTC from IEEE Xplore.  Restrictions apply. 
by fuzzing the target ﬁlter with various attack strings until a
bypass is found or the set of attack strings is exhausted.
We argue that our GOFA algorithm is superior to fuzzing
for two reasons:
program name(input){
return iter(c in input)[registers]
{cases}end{cases};
}
1)
2)
the size of
The number of queries of the GOFA algorithm is
the grammar. On the
independent of
other hand, when producing random strings from a
grammar in order to test a ﬁlter a very large number
of strings has to be produced. Moreover, testing for
modern vulnerabilities such as XSS is very complex,
since there is a large number of variations that one
should consider(cf. [46]).
Random testing produces no information on the struc-
ture of the ﬁlter if no attack is found. Consider the