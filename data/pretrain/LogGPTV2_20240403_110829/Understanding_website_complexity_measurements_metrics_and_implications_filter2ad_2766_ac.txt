websites. Figure 10 shows the breakdown of the different content
types served by non-origins, both in terms of the number of objects
and their size in bytes. This breakdown is shown for the median
318(a) By rank
Figure 9: Contribution of non-origin services with respect to
number of objects, number of bytes, and download time.
Classifying non-origins: Beyond types of content, we analyze
the types of services offered by non-origins. For this study, we
rank non-origin domains based on the number of websites in which
they occur. Then, for the 200 most popular non-origins, we identify
the services they offer by combining three sources of information.
First, we lookup each non-origin domain in Alexa’s categorization
of web domains. Second, we use information from CrunchBase4 to
identify the type of company that runs the non-origin service. Last,
we manually classify the remaining non-origins based on informa-
tion gleaned from their website or keyword-based heuristics on the
objects being fetched from them.
Table 3 presents a breakdown of the types of services these top
200 non-origins offer and the number of origins in which each cat-
egory appears. Here, we only consider the 669 origins, in which all
the non-origin objects belong to one of these top 200 non-origins.
Unsurprisingly, the top two categories of non-origin services are
Analytics (e.g., google-analytics and quantserve) and Advertising
(e.g., doubleclick and googleadservices). However, even beyond
these two service types, we see that each of the non-origin service
types are seen on a signiﬁcant fraction of the 669 origins.
To give an example of the types of non-origin services we en-
counter, Table 4 shows the top 10 non-origins with the type of
service they provide and the fraction of sites on which they ap-
pear. While many of these are very recognizable ad and analyt-
ics providers, we were surprised by some of the less recognized
names appearing in a signiﬁcant fraction of websites. For exam-
ple, among the top 20, we found other lesser known services like
bluekai.com, invitemedia.com, and imrworldwide.com, that each
appeared in more than 5% of the websites (not shown).
Finally, we examine the contribution of these non-origin service
types on a typical web page. For this analysis, we only consider the
669 websites where all non-origins on their base web page belong
to the top 200 non-origins. On each of these 669 websites, we com-
pute the fraction of the number of objects and bytes fetched from
non-origins that are attributable to each service type. Figure 10(b)
plots these fractions for the median website. In keeping with the
relative popularity of non-origin services of different types in the
top 200 non-origins, Analytics and Advertising account for most
non-origin objects. However, content fetched from CDNs domi-
nate with respect to the number of bytes.
4http://www.crunchbase.com
(b) By category
Figure 8: Number of distinct origins needed to load the base
web page for websites across different rank ranges and cate-
gories.
website, i.e., the website that loads the median number of objects
(or median number of bytes) for each content type. Interestingly,
we ﬁnd that while the vast fraction of the number of objects served
by non-origins are images, the relative fraction in terms of number
of bytes served is much lower. This is at odds with the normal
expectation that the contribution of images to bytes fetched will be
larger than their contribution to the number of objects, since images
are typically larger than Javascript and CSS objects. Investigating
this further, we ﬁnd that this discrepancy is an artifact of the use
of small gifs fetched from non-origins for analytics services [14].
We illustrate this point in Figure 11, which shows the distribution
of the number of objects and object size for each MIME-type. We
see that though images are the most common type of content, the
median size of an image is less than 2 KB—more than an order of
magnitude smaller than the median size of a Flash object.
Origin vs. non-origin content: Next, we proceed to analyze if the
content served by non-origins differs signiﬁcantly from that served
by the origin sites themselves. Figure 12 shows the contribution
of different MIME-types to the number of objects fetched from
origins and non-origins on the median website. The most notice-
able difference is that non-origins serve a much higher fraction of
Javascript objects while origins serve a greater fraction of images
than non-origins.
319(a) By MIME-type
(a) No. of objects
(b) By service type
Figure 10: Normalized contribution of objects from non-origin
services in the median case.
Type of service
Number
Analytics
Advertising
Tracking Cookies
Services/Widgets
Social Networking
Programming API
CDN
Total
65
64
23
21
18
5
4
200
Found in
no. of origins
593
233
137
142
218
98
96
669
Table 3: Breakdown of the types of services provided by top
200 non-origins.
4.4 Summary of main observations
In summary, our main observations in this section are as follows:
• A website’s rank is not a signiﬁcant indicator of the content
complexity, at least within the top 20K websites.
• However, a website’s category does matter; News sites load
signiﬁcantly more content than others from a lot more servers
and origins, while Kids and Teens sites have signiﬁcantly
more Flash content than others.
• Most websites load a surprisingly large number of CSS and
Javascript objects.
• Content from non-origins represents a signiﬁcant fraction of
objects and bytes on most web pages, but their impact on
download time is relatively low.
5.
IMPACT ON CLIENT PERFORMANCE
In the previous section, we measured a range of content-complexity
and service-complexity metrics. In this section, we tackle the natu-
ral follow-up question: which of these metrics have the most impact
on performance.
(b) Object size
Figure 11: Distributions across content types of the number of
objects and median object size from non-origins.
We consider two performance measures to characterize page load
times. RenderStart measures the time at which the browser has
completed parsing the HTML and has fetched sufﬁcient content to
begin rendering the page, while RenderEnd measures the total time
to fetch and render all content on the web page. For each measure,
we are interested in both the typical load time for each website and
the variability in load time across different samples.
To put our analysis in perspective, Figure 13 shows the distri-
bution of the median and 90th percentile of the RenderEnd values
for each site across several measurements from one of our vantage
points. Rather surprisingly, more than 50% of sites have a median
RenderEnd higher than 2 seconds. (We also validated these seem-
ingly high page load times from independent measurements from
the HTTP Archive project [3].) User studies and industry surveys
show that users are likely to be frustrated beyond this two second
threshold [28]. Thus, it is critical to systematically understand what
are the key factors affecting page load times.
We use correlation and regression based analysis to identify the
key complexity metrics that are the best indicators of page load
times and the variability in them. In this analysis, we use a range
of complexity metrics from the previous section—the {absolute
value or fraction} of {objects, bytes, servers, origins, non-origins}
characterized by {content MIME-type, service type}, and whether
loaded from {origin, non-origin, either}. We also use other aggre-
320Figure 12: Comparison of types of content served from origin
and non-origin servers on the median website.
Rank Name
1
2
3
4
5
6
7
8
9
10
google-analytics.com
doubleclick.net
quantserve.com
scorecardresearch.com
2mdn.net
googleadservices.com
facebook.com
yieldmanager.com
atdmt.com
googleapis.com
Fraction Type
of sites
0.58
0.45
0.30
0.27
0.24
0.18
0.17
0.16
0.14
0.12
Analytics
Ads
Analytics
Analytics
Ads
Ads
Social net
Ads
Analytics
Prog. API
Table 4: Classiﬁcation of the services provided by the top-10
non-origin service providers.
gate metrics such as the size of the maximum object fetched. For
brevity, we only present results for metrics that turned out to be
the most dominant indicators of either absolute load times or their
variability.
5.1 Load times
Correlation: First, we analyze the correlation between RenderEnd
(RenderStart) and various complexity metrics. For this analysis, we
compute for each website the median values of RenderEnd (Ren-
derStart) across multiple measurements of that website and the me-
dian value of various complexity metrics. Then, across all websites
in our dataset, we compute the Pearson and Spearman rank corre-
lation coefﬁcients between the two load time measures and various
complexity metrics. Since the results are similar for RenderStart
and RenderEnd, we present only the results for RenderEnd. Also,
the results are similar for both Pearson and Spearman correlations;
hence, for brevity, we only show the Spearman values. To ensure
that the correlations we observe are not artifacts of a particular mea-
surement site, we consider each of the 4 vantage points separately.
Figure 14 shows the Spearman correlation coefﬁcients with respect
to various complexity metrics in decreasing order of the median
value across the different measurement sites. Across all 4 mea-
surement sites, we see that the ﬁve most correlated metrics are the
total number of objects loaded, the number of these objects that are
Javascripts, the total webpage size, the number of servers, and the
number of origins contacted in loading the page.
Figure 15 further visually conﬁrms the strong correlation be-
tween RenderEnd and the number of objects requested. Here, we
bin websites based on the number of objects on their base web
page. Then, for each bin, we construct a box-and-whiskers plot
showing the median, 25th percentile, and 75th percentile plot in
the “box” and the min/max values for the whiskers. Further, tying
Figure 13: Distribution of RenderEnd times across all websites.
the fact that number of object requests is the most dominant indi-
cator of load times with our observation from Section 4 that News
sites fetch a signiﬁcantly larger number of objects than other sites,
Figure 16 shows that the page load times for News sites are indeed
much higher than for other sites.
Regression: The correlation analysis tells us which metrics are
good indicators of page load times. Next, we attempt to identify a
minimal set of metrics to estimate load times. For this, we augment
the above correlation analysis by building a linear regression model
using the LASSO technique [17]. Each feature in this model rep-
resents one of the various complexity metrics presented in the pre-
vious section. We use LASSO instead of simple linear regression
because it produces a sparser model; thus, models with LASSO are
more robust. To further avoid overﬁtting, we use a k× 2 cross vali-
dation technique. Here, in each run, we partition the set of websites
into two halves—a training set and a testing set. For each run, we
run the LASSO procedure and record the coefﬁcients for each fea-
ture. Then, we build an aggregate model using the average values
of the individual coefﬁcients across all runs.
Figure 17 shows the normalized root mean-squared error (NRMSE),5
as a function of the top k selected features. In this ﬁgure, we sort the
features based on the magnitude of their weights in the model after
the cross-validation procedure described above.6 Then, we emu-
late the effects of using a model that uses only the top k features.
As a point of comparison, we also considered a naive estimator
that simply predicts the mean value of RenderStart and RenderEnd;
its NRMSE was around 50% worse than the LASSO estimate (not
shown).
We see two key results here. First, the set of top k features
roughly mirrors the correlation result we saw earlier. One notable
exception is that the total size is relegated down the list. We spec-
5If ˆX is a vector representing estimates of page load times, and X
contains the true values, then NRMSE = √E[( ˆX−X)2]
max(X)−min(X)
6One obvious concern is whether the magnitude of the weights are
meaningful if the different features and the load time are in differ-
ent “scales”. A pre-processing step in LASSO re-scales all features
to have zero mean/unit variance and also normalizes the load met-
ric to have zero mean. Thus, the magnitude measures the relative
importance of the metric and avoids these scale-related concerns.
321Figure 14: Correlation between RenderEnd and various com-
plexity metrics.
Figure 15: Box-and-whiskers plot conﬁrming the correlation