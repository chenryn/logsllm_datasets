An idea that does not work is sequential allocation, yielding the
tag (or process ID) sequence (cid:10)1, 2, 3, . . .(cid:11). To attack this scheme, a
low process forks, retrieving a child ID i. To communicate the value
“k”, the high process forks k times. The next time the low process
forks, it gets process ID i + k, and by subtracting i recovers the
high message. There are two problems: (1) low and high processes
share the same process ID space; and (2) they can manipulate it in
a predictable way.
The second weakness is exploitable even without the ﬁrst. In a
different attack, a high process communicates a “1” by allocating
a tag via create tag(Add), and communicates a “0” by refraining
from allocating. If a low process could guess which tag was allocated
Fig. 5.
inﬂuences are allowed except high to low.
Intransitive Noninterference. Arrows depict allowed inﬂuence. All
Deﬁnition 3 (Noninterference for System S). For a CSP process S,
and an alphabet of low symbols LO ⊆ αS, the predicate NILO (S) is
true iff
∀tr,tr(cid:2) ∈ traces(S) :
tr (cid:3) LO = tr(cid:2) (cid:3) LO ⇒
SF(cid:4)S/tr(cid:5) (cid:3) LO = SF(cid:4)S/tr(cid:2)(cid:5) (cid:3) LO .
We say that the process S exhibits noninterference with respect to
the low alphabet LO iff NILO (S) is true.
That is, after being advanced by tr and tr(cid:2), the two processes must
accept all of the same traces (projected to low) and refuse all of the
same refusal sets (projected to low).
Given an arbitrary export-protection tag t (one such that t
+ ∈ ˆO
/∈ ˆO), we deﬁne the high and low alphabets as follows. The
(cid:5)
(cid:6)
and t
high symbols emanate from a process with t ∈ Si:
HIt (cid:2)
i.s.(S, I, O, . . . ) | t ∈ S
i.b.(S, I, O, . . . ) | t ∈ S
(cid:6)
−
(cid:5)
∪
The low symbols are the complement set:
(cid:5)
LOt (cid:2)
i.b.(S, I, O, . . . ) | t /∈ S
(cid:5)
(cid:6)
∪
i.s.(S, I, O, . . . ) | t /∈ S
(cid:6)
the stable failures model
1) Stability and Divergence: There are several complications. The
ﬁrst is the issue of whether or not
is
adequate. For instance, if a high process caused the kernel to diverge
(i.e., hang), a low process could record such an occurrence on reboot,
thereby leaking a bit (very slowly!) to low. By construction, the Flume
kernel never diverges. One can check this property by examining each
system call and verifying that only a ﬁnite number of internal events
can occur before the process is ready to receive the next call. User-
space process (e.g., Ui) can diverge, but they cannot observe each
other’s divergence, and so their divergence is inconsequential in our
security analysis.
If divergence attacks were a practical concern, we could capture di-
vergent behavior with the more general Failures, Divergences, Inﬁnite
Traces (FDI) model [20]. We conjecture that Flume’s noninterference
results under the stable failures model also hold in the FDI model,
but the proof mechanics are yet more complicated.
2) Declassiﬁcation: The second complication is declassiﬁcation,
also known as intransitive noninterference. That is, the system should
allow certain ﬂows of information from “high” processes to “low”
processes, if that ﬂow traverses the appropriate declassiﬁer. Figure 5
provides a pictorial representation: the system allows low processes
and the declassiﬁer to inﬂuence all other processes, and the high
processes to inﬂuence other high processes and declassiﬁers but not
to inﬂuence low processes. However, in the transitive closure, all
processes can inﬂuence all other processes, which negates any desired
security properties.
Previous work by Roscoe et al. assumes a global security policy,
and modiﬁes existing noninterference deﬁnitions to rule out ﬂows
68
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 03:18:50 UTC from IEEE Xplore.  Restrictions apply. 
(call it t), it could then attempt to change its label to S = {t}. If the
change succeeds, then the low process had access to t+ through ˆO,
meaning the high process allocated the tag. If the change fails, the
high process must not have allocated. The weakness here is that the
low process “guessed” the tag t without the high process needing to
communicate it. If such guesses were impossible (or very unlikely),
the attack would fail.
Another idea—common to all DIFC kernels (c.f., Asbestos [1],
HiStar [2] and the Flume implementation)—is random allocation
from a large pool. The random allocation scheme addresses the
second weakness—predictability—but not the ﬁrst. That is, oper-
ations like process forking and tag creation always have globally
observable side affects: a previously unallocated resource becomes
claimed. Consider, as an example, this trace for the Flume system:
tr = (cid:10)i.b.({t}, {}, {}, {}),
i.s.({t}, {}, {}, fork),
j.b.({t}, {}, {}, {}),
i.s.({t}, {}, {}, j), . . .(cid:11)
A new process i is born, with secrecy label Si = {t}, and empty
integrity and ownership. Thus, i’s actions fall into the HIt alphabet.
Once i starts, it forks a new process, which the kernel randomly picks
as j. The child j runs with secrecy Sj = {t}, inheriting its parent’s
secrecy label.
Projecting this trace onto the low alphabet yields the empty
sequence (tr (cid:3) LOt = (cid:10)(cid:11)). Thus, this trace should have no impact
on the system from a low process k’s perspective. Unfortunately, this
is not the case. Before tr occurred, l could have forked off process
j, meaning:
tr(cid:2)
= (cid:10)k.b.({}, {}, {}, {}),
k.s.({}, {}, {}, fork),
j.b.({}, {}, {}, {}),
k.s.({}, {}, {}, j), . . .(cid:11)
was also a valid trace for the system. But after tr occurs, tr(cid:2) is no
longer possible, since the process j can only be born once. In other
words, tr (cid:4) tr(cid:2) is not a valid trace for the system but tr(cid:2) is by itself.
This contradicts the deﬁnition of noninterference in the stable failures
model of process equivalence.
To summarize, we have argued that allocation of elements from
ˆO and ˆP , must obey two properties: (1) unpredictability and (2)
partitioning. Our approach is to design a randomized allocation
scheme that achieves both. Deﬁne parameters:
α (cid:2) log2(the number of tags)
β (cid:2) log2(maximum number of operations)
 (cid:2) − log2(acceptable failure probability)
A reasonable value for β is 80, meaning that no instance of the
Flume system will attempt more that 280 operations. Since tag
allocation, forking and constructing labels count as operations, the
system expresses fewer than 2β tags, process IDs, or labels in its
lifetime. A reasonable value for  is 100, meaning the system fails
catastrophically at any moment with probability at most 2
−100.
Deﬁne a lookup table s(·), that given any label or capability
set outputs a integer in [0, 2β) that uniquely identiﬁes it. This
serialization can be predictable. Next consider the family of all
injective functions:
The Flume system, upon startup, picks an element g ∈ G at random.
When called upon by a process with labels S, I, O to allocate a
new tag or process ID, it returns g(s(S), s(I), s(O), x), for some
heretofore unused x ∈ {0, 1}β. The output is a tag in {0, 1}α.
Appendix C derives α ≥ max( + 1, 4β), meaning α = 320 for
our example parameters.
Thus, we let T = P = {0, 1}α, for a sufﬁciently large α. The
kernel picks g ∈ G at random upon startup. Then CHOOSE is reﬁned
as:
CHOOSEY = ?(S, I, O) → (cid:2)
y∈G(S,I,O,Y )(!y) → STOP
where
G(S, I, O, Y ) =
(cid:5)
t | x ∈ T ∧ t = g(s(S), s(I), s(O), x) ∧ t ∈ Y
(cid:6)
.
Note that G(S, I, O, Y ) ⊆ Y , so the nature of the reﬁnement is just
to restrict the set of IDs that CHOOSEY will ever output, based on
the capabilities, secrecy and integrity labels of the calling process.
C. Theorem and Proof
The main theorem is as follows:
Theorem 1 (Noninterference in Flume). For any security parameter
, there exists an instantiation of CHOOSE such that: for any export-
protection tag t, for any Flume instance SYS, Pr[NIDMIDt
LOt (SYS)] ≥
1 − 2
−.
In other words, the system administrator of a Flume system ﬁrst
decides on a security parameter , expecting calamitous system
−. He instantiates CHOOSE
collapse with probability of at most 1−2
then boots the system. The init process runs, spawning
with ,
an assortment of user processes, which combine with the kernel
processes to constitute a new overall system SYS. For any export
protection tag t that is allocated as the system runs, the extended
noninterference property holds with the desired probability. This
guarantee holds over all instances of SYS, regardless of what user
processes (i.e., UPROCS) malicious users might cook up.
The proof is by induction over the number of low symbols in
the two traces, tr and tr(cid:2). (Recall that tr and tr(cid:2) are equivalent when
projected to the low/mid alphabets). For the base case, tr and tr(cid:2) have
no low symbols, and therefore have no high symbols, since the system
accepts only low symbols in its initial state. Since tr = tr(cid:2) = {}, the
theorem follows trivially.
We prove the inductive step casewise, considering each system
call and whether the kernel is looking to accept a new system call
or reply to an outstanding call. Most cases reason about the causal
relationships among events in the trace. A more involved case is
change label, which must consider the unlikely case that a low
process guessed which tags a high process received from the kernel
when calling create tag. See Appendix D for details.
VI. DISCUSSION
To review, we have described the Flume kernel both informally
and with CSP formalism and proven that the CSP model upholds
a deﬁnition of noninterference. In this section, we discuss the
implications of these results, and how they can be translated to a
practical system.
A. Reﬁnement
Due to the well-known reﬁnement paradox, the Flume model might
satisfy noninterference, but implementations (i.e. reﬁnements5) of
G : ({0, 1}β, {0, 1}β, {0, 1}β , {0, 1}β) → {0, 1}α
5Q is a reﬁnement of P iff SF (cid:2)Q(cid:3) ⊆ SF (cid:2)P (cid:3).
69
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 03:18:50 UTC from IEEE Xplore.  Restrictions apply. 
it might not [23]. To circumvent this paradox, Lowe has recently
strengthened notions of noninterference, requiring that a system like
SYS and all of its reﬁnements exhibit noninterference [24]. Other
work has suggested restricting reﬁnement to a set of operators known
to preserve security guarantees [25]. We follow Lowe’s approach
as best as possible, arguing that noninterference holds for most
reﬁnements.
The parts of the Flume model that need reﬁnement are those that
display non-determinism via the (cid:15) or (cid:5) operators: (1) the CHOOSE
process; (2) the user processes Ui; (3) “scheduling”; and (4) the tock
events in timed CSP. As for (1), the proof in Section D holds for
some reﬁnements of CHOOSE, such as the random function speciﬁed
in Section V-B and a more practical hash-based approach considered
below. A Flume implementation should reﬁne CHOOSE as speciﬁed,
or with a method known to preserve noninterference. As for (2), the
proof in Section D holds for arbitrary reﬁnements of user processes
Uis, as long as they communicate only through the designated system
calls (see Section IV-A). In practice, we cannot hope to isolate the Uis
completely from one another: they can communicate by manipulating
shared hardware resources (e.g., disks, CPU cache, CPU cycles,
network bandwidth, etc.)
As for (3), the Flume model hides scheduling for simplicity: any in-
terleaving of processes is admissible, by Equation 1 in Section IV-G.
However, a practical reﬁnement of Flume would implement “fairness”
restrictions on scheduling, disallowing one process from consuming
more than its “fair” share of resources. Scheduling reﬁnements, in and
of themselves, do not affect the proof of security: noninterference
holds in any reordering of high and low processes, as long as all
processes get to run eventually, and do not have any comprehension
of time. As for (4), Appendix E explores extending the Flume model
to show an explicit passage of time: the event tock denotes one clock
tick, and all parts of the model must stand aside and yield to tock. We
conjecture that if tock ∈ HIt, then the proof holds for all reﬁnements
of the scheduler, and that if tock ∈ LOt, that the proof holds for only
some reﬁnements. Further exploration is deferred to future work.
In sum, we believe the Flume model to maintain noninterference
under important reﬁnements—tag allocation, arbitrary user processes,
and scheduling—if timing channels are excluded (i.e., if tock ∈ HIt).
Of course, this is a far cry from proving noninterference in a working
implementation, but a signiﬁcant improvement over the status quo.
Systems such as Asbestos and IX have gaping covert channels baked
into their very speciﬁcations, so any reﬁnements of those systems
are insecure. By contrast, an OS developer has a ﬁghting chance to
realize a secure Flume implementation.
B. Kernel Organization
The Flume DIFC model is a “monolithic” kernel design, in which
the kernel is a hidden black box, and user-level processes have a
well-speciﬁed system call interface. Some modern approaches to
kernel design (e.g. the Exokernel [26] and the Infokernel [27]) expose
more of the kernel’s inner workings to give application developers
more ﬂexibility. However, such transparency in an information-ﬂow
control setting can leak information: imagine a high process issuing
create tag, and a low process observing TAGMGR’s transitions. The
simplest way to work around this problem is to conceal the inner
workings of the kernel (as we have done). Another, more complicated
solution, is to model more parallelism inside the kernel, so that the
tag manager can serve both high and low concurrently.
The Flume model captures most of the kernel processes—like the
i:K, the tag manager, and the process manager—as single-threaded
processes. For instance, if the tag manager is responding to a request
70
for i.g.(create tag, w), it cannot service j.g.(create tag, w) until
it replies to i.g.(create tag, w). In practical implementations of this
CSP model, such serialization might be a bottleneck for performance.
More parallelism internal to the kernel is possible, but would require
explicit synchronization through locks, and more complexity overall.
C. Tag Allocations
The use of a truly random function for CHOOSE is impractical, as
are tag sizes of 320 bits. In practice, a weaker cryptographic primitive
sufﬁces, such as a Message Authentication Code (MAC) [28] with a
collision-resistant hash function [29]. Let M be such a MAC of suit-
able input length. The kernel picks a random secret key k on startup,
and then computes new tags and process IDs using Mk(S, I, O, x) for
a counter variable x. This construction approximates both important
properties. The unforgability property of the MAC implies that
an adversary cannot ﬁnd (S, I, O, x) (cid:8)= (S
) such that
HMACk(S, I, O, x) = HMACk(S(cid:2), I (cid:2), O(cid:2), x(cid:2)), so a high process
with secrecy {t} and a low process with secrecy {} will not get
the same tag. Similarly, user processes cannot predict the output of
HMACk(S, I, O, x) without knowing k.
, O
, I
(cid:2)
(cid:2)
(cid:2)
(cid:2)
, x
D. Integrity
Though we have focused on secrecy, the same arguments hold for
integrity. Analogously, one would pick an integrity-protection tag t,
/∈ ˆO. The low symbols are those
one for which t
whose integrity tags contain t, and the high symbols are those that
do not. The same proof shows that the high events do not interfere
with the low.