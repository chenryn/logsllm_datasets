|   |  
 : : =  
|   | 
 : : =  
|   | 
 : : =  | 
|  | 
Img2 |
 : : = Img1 |
 : : =  | 
. . .
|
ImgN | Unknown
|  |  | 

Fig. 2. VMSim language
The simulation creation process involves the capturing of mouse and keyboard events
of a real user as distinct actions. The actions that are recorded map to the constructs
of the VMSim language. Once the actions are implemented, the simulator is tuned to
mimic a particular user by using various biometric models for keystroke speed, mouse
speed, mouse distance, and the frequency of errors made during typing. These parame-
ters function as controls over the language shown in Fig. 2 and aid in creating variabil-
ity in the simulations. Depending on the particular simulation, other parameters such as
URLs or other text that must be typed are then entered to adapt each action. VMSim
translates the language’s actions into lower level constructs consisting of keyboard and
mouse functions, which are then outputted as X protocol level data that can be replayed
via the XTest extensions.
To construct biometric models for individuals, we have extended QEMU’s VMM to
support the recording of several features including keycodes (the ASCII code represent-
ing a key), the duration for which they are pressed, keystroke error rates, mouse move-
ment speed, and mouse movement distance. Generative models for keystroke timing are
created by ﬁrst dividing the recorded data for each keycode pair into separate classes
where each class is determined by the distance in standard deviations from the mean.
We then calculate the distribution for each keycode sequence as the number of instances
of each class. We adapt simulation keystroke timing to proﬁles of individual users by
generating random times that are bounded by the class distribution. Similarly, for mouse
movements we calculate user speciﬁc proﬁles for speed and distance. Recorded mouse
BotSwindler: Tamper Resistant Injection of Believable Decoys
125
movements are broken down into variable length vectors that represent periods of mouse
activity. We then calculate distributions for each user using these vectors. The mouse
movement distributions are used as parameters for tuning the simulator actions. We note
that identifying the complete set of features to model an individual is an open problem.
Our selection of these features is to illustrate a feasible approach to generating statisti-
cally similar actions. In addition, these features have been useful for verifying the iden-
tify of individuals in keystroke and mouse dynamics studies [24,25]. In Sect. 4.1 we
provide a statistical and information theoretic analysis of the simulated times.
One of the advantages of using a language for the generation of simulation work-
ﬂows is that it produces a speciﬁcation that can be ported across different platforms.
This allows the cost of producing various simulation workﬂows to be amortized over
time. In the prototype version of BotSwindler, the task of mapping mouse and keyboard
events to language actions is performed manually. The mappings of actions to lower
level mouse and keyboard events are tied to particular host conﬁgurations. Although
we have not implemented this for the prototype version of BotSwindler, the process
of porting these mappings across hosts can be automated using techniques that rely on
graphical artifacts like those used in the VMV implementation and applying geometric
transformations to them.
Once the simulations are created, playing them back requires VMSim to have access
to the display of the guest OS. During playback, VMSim automatically detects the po-
sition of the virtual machine window and adjusts the coordinates to reﬂect the changes.
Although the prototype version of BotSwindler relies on the display to be open, it is
possible to mitigate this requirement by using the X virtual frame buffer (Xvfb) [26].
By doing so, there would be no requirement to have a screen or input device.
3.2 Virtual Machine Veriﬁcation
The primary challenge in creating an of out-of-host user simulator is to generate human-
like events in the face of variable host responses. This task is essential for being able
to tolerate and recover from unpredictable events caused by things like the ﬂuctua-
tions in network latency, OS performance issues, and changes to web content. Conven-
tional in-host simulators have access to OS APIs that allow them to easily to determine
such things. For example, simulations created with the popular tool AutoIt can call its
WinWait function, which can use the Win32 API to obtain information on whether a
window was successfully opened. In contrast, an out-of-host simulator has no such API
readily available. Although the Xorg Record extensions do support synchronization to
solve this sort of problem, they are not sufﬁcient for this particular case. The Record
extensions require synchronization on an X11 window as opposed to a window of the
guest OS inside of an X11 window, which is the case for guest OS windows of a VM4.
We address this requirement by casting it as a veriﬁcation problem to decide whether
the current VM state is in one of a predeﬁned set of states. In this case, the states
are deﬁned from select regions of the VM graphical output, allowing states to consist
of any visual artifact present in a simulation workﬂow. To support non-deterministic
4 This was also a challenge when we tested under VMware Unity, which exports guest OS
windows as what appear to be ordinary windows on the native host.
126
B.M. Bowen et al.
simulations, we note that each transition may end in one of several possible next states.
We formalize the VMV process over the set of transitions T , and set of states S, where
each t0, t1, ..., tn ∈ T can result in the the set of states st1, st2, ..., stn ⊆ S. The VMV
decides a state veriﬁed for a current state c, when c ∈ sti.
The choice for relying on the graphical output allows the simulator to depend on the
same graphical features a user would see and respond to, enabling more accurate sim-
ulations. In addition, information speciﬁc to a VM’s graphical output can be obtained
from outside of the guest without having to solve the semantic gap problem [20], which
requires detailed knowledge of the underlying architecture. A beneﬁt of our approach
is that it can be ported across multiple VM platforms and guest OS’s. In addition, we
do not have to be concerned with side effects of hostile code exploiting a system and
interfering with the Win32 API like traditional in-host simulators do, because we do not
rely on it. In experiments with AutoIt scripts and in-host simulations, we encountered
cases where scripts would fail as a result of the host being infected with malware.
The VMV was implemented by extending the Simple DirectMedia Layer (SDL)
component of QEMU’s [11] VMM. Speciﬁcally, we added a hook to the sdl update
function to call a VMV monitor function. This results in the VMV being invoked
every time the VM’s screen is refreshed. The choice of invoking the VMV only during
sdl update was both to reduce the performance costs and because it is precisely
when there are updates to the screen that we seek to verify states (it is a good indicator
of user activity).
States are deﬁned during a simulation creation process using a pixel selection tool
(activated by hotkeys) that we built into the VMM. The pixel selection tool allows the
simulation creator to select any portion of a guest OS’s screen for use as a state. In
practice, the states should be deﬁned for any event that may cause a simulation to delay
(e.g., network login, opening an application, navigating to a web page). The size of the
screen selection is left up to the discretion of the simulation creator, but typically should
be minimized as it may impact performance. In Sect. 4.3 we provide a performance
analysis to aid in this consideration.
3.3 Trap-Based Decoys
Our trap-based decoys are detectable outside of a host by external monitors, so they do
not require host monitoring nor do they suffer the performance burden characteristic of
decoys that require constant internal monitoring (such as those used for taint analysis).
They are made up of bait information including online banking logins provided by
a collaborating ﬁnancial institution, login accounts for online servers, and web based
email accounts. For the experiments in this paper, we focused on the use of decoy
Gmail, PayPal credentials, and banking credentials. These were chosen because they
are widely used and known to have underground economy value [1,27], making them
alluring targets for crimeware, yet inexpensive for us to create. The banking logins are
provided to us by a collaborating ﬁnancial institution. As part of the collaboration, we
receive daily reports showing the IP addresses and timestamps for all accesses to the
accounts at any time.
The decoy PayPal and bank accounts have an added bonus that allows us to ex-
pose the credentials without having to be concerned about an attacker changing their
BotSwindler: Tamper Resistant Injection of Believable Decoys
127
password. PayPal requires multi-factor authentication to change the passwords on an
account. Yet, we do not reveal all of the attributes of an account making it difﬁcult for
an attacker to change the authentication credentials. For the banking logins, we have
the ability to manage the usernames and passwords.
Custom monitors for PayPal and Gmail accounts were developed to leverage inter-
nal features of the services that provide the time of last login, and in the case of Gmail
accounts, the IP address of the last login. In the case of PayPal, the monitor logs into the
decoy accounts every hour to check the PayPal recorded last login. If the delta between
the times is greater than 75 seconds, the monitor triggers an alert for the account and
notiﬁes us by email. The 75 second threshold was chosen because PayPal reports the
time to a resolution of minutes rather than seconds. The choice as to what time inter-
val to use and how frequently to poll presents signiﬁcant tradeoffs that we analyze in
Sect. 4.4.
In the case of the Gmail accounts, custom scripts access mail.google.com to
parse the bait account pages, gathering account activity information. The information
includes the IP addresses for the previous 5 account accesses and the time. If there is
any activity from IP addresses other than the BotSwindler monitor’s host IP, an alert
is triggered with the time and IP of the offending host. Alerts are also triggered when
the monitor cannot login to the bait account. In this case, we conclude that the account
password was stolen (unless monitoring resumes) and maliciously changed unless other
corroborating information (like a network outage) can be used to convince otherwise.
4 Experimental Results
4.1 Statistical and Information Theoretic Analysis
In this section we present results from the statistical analysis of generated keystroke
timing information. The goal of these experiments was to see if a machine learning algo-
rithm (one that would be available to a malware sample to determine whether keystrokes
are real or not) might be able to classify keystrokes accurately into user generated or
machine generated. For these experiments, we relied on Killourhy and Maxion’s bench-
mark data set [28]. The data set was created by having 51 subjects repeatedly type the
same 10 character password, 50 times in 8 separate sessions, to create 400 samples for
each user. Accurate timestamps were recorded by using an external clock. Using this
publicly available real user data ensures that experiments can be repeated.
To evaluate VMSim’s generated timing information, we used Weka [29] for our clas-
siﬁcation experiments. We divided the benchmark data set in half and used 200 pass-
word timing vectors from each user to train Naive Bayes and Support Vector Machine
(SVM) classiﬁers. The remaining 200 timing vectors from each user were used as input
to VMSim’s generation process to generate 200 new timing vectors for each user. The
same 200 samples were used for testing against the generated samples in the classiﬁca-
tion experiments. Note that we only used ﬁelds corresponding to hold times and inter-
key latencies because the rest were not applicable to this work (they can also contain
negative values). The normalized results of running the SVM and Naive Bayes classi-
ﬁers on the generated data and real data are presented in Figs. 3 and 4, respectively. The
results are nearly identical for these two classiﬁers suggesting that this particular type
128
B.M. Bowen et al.
t
c
e
r
r
o
c
 1
 0.8
 0.6
 0.4
 0.2
 0
actual
   vmsim
t
c
e
r
r
o
c
 1
 0.8
 0.6
 0.4
 0.2
 0
actual
   vmsim
5 1
1
2
2
3
3
4
4
5
0
5
0
5
0
5
0
5
0
5 1
1
2
2
3
3
4
4
5
0
5
0
5
0
5
0
5
0
subject #id
subject #id
Fig. 3. SVM classiﬁcation
Fig. 4. Naive Bayes classiﬁcation
actual
   vmsim
s
t
i
b
f
o
r
e
b
m
u
n
 40
 39
 38
 37
 36
 35
 34
 33
 32
 31
 30
5 1
0
1
5
2
0
2
5
3
0
3
5
4
0
4
5
5
0
subject #id
Fig. 5. Entropy of generated and actual timing data.
of analysis would not be useful for an attacker attempting to distinguish the real from
generated actions. In Fig. 5, we present a comparison of entropy values (the amount of
information or bits required to represent the data) [30] for the actual and generated data
for each of the 200 timing vectors of the 51 test subjects. The results indicate that there
is no loss of information in our generation process that would be useful by an adversary
that is attempting distinguish real from generated actions.
4.2 Decoy Turing Test
We now discuss the results of a Turing Test [10] to demonstrate BotSwindler’s per-
formance regarding the humanness, or believability, of the generated simulations. The
point of this experiments is to show that adversaries resorting to manual inspection
of the user activities would be sufﬁciently challenged. Though the simulations are de-
signed to delude crimware, here we focus on convincing humans, a task we posit to
be a more difﬁcult feat, making the adversaries task of designing malware that dis-
cerns decoys far more difﬁcult. To conduct this study, we formed a pool of 25 human
judges, consisting of security-minded PhDs, graduate-level students, and security pro-
fessionals. Their task was to observe a set of 10 videos that capture typical user actions
performed on a host and make a binary decision about each video: real or simulated
(i.e., whether the video shows the actions of a real user or those of a simulator). Our
goal was to demonstrate the believability of the simulated actions by showing failure of
BotSwindler: Tamper Resistant Injection of Believable Decoys
129
human judges to reliably distinguish between authentic human actions and those gener-
ated with BotSwindler. Our videos contained typical user actions performed on a host
such as composing and sending an email message through Gmail, logging into a website
of a ﬁnancial institution such as Citibank or PayPal, and editing text document using
Wordpad. For each scenario we generated two videos: one that captured the task per-
formed by a human and another one that had the same task performed by BotSwindler.
Each video was designed to be less than a minute long since we assumed that our judges
would have limited patience and would not tolerate long-running simulations.
The human generated video samples were created by an independent user who was
asked to perform sets of actions which were recorded with a desktop recording tool
to obtain the video. Similar actions by another user were used to generate keystroke
timing and error models, which could then be used by VMSim to generate keystroke
sequences. To generate mouse movements, we rely on movements recorded from a
real user. Using these, we experimentally determine upper and lower bounds for mouse
movement speed and replay the movements from the real user, but with a new speed
randomized within the determined limits. The keyboard and mouse sequences were
merged with appropriate simulator parameters such as credentials and URLs to form
the simulated sequence which was used to create the decoy videos.
Figure 6 summarizes the results for each of the 10 videos. The videos are grouped in
per-scenario pairs in which the left bars correspond to simulated tasks, while the right
bars correspond to the tasks of authentic users on which the simulations are based. The
height of the bars reﬂects the number of judges that correctly identiﬁed the given task
as real or simulated. The overall success rate was ∼46%, which indicates that VMSim
achieves a good approximation of human behavior. The ideal success rate is 50%, which
suggests that judges cannot differentiate whether a task is simulated or real.