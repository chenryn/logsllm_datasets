date of malware, e.g., Symantec’s Worldwide Intelligence
Network Environment [10].
With dynamic features, ILINE achieved 59.0%–75.0% ac-
curacies without any prior knowledge, and 68.6%–80.6%
accuracies with real timestamps, which is a bit lower than
the accuracies based upon static features.
USENIX Association  
22nd USENIX Security Symposium  91
7.3 Performance
Given N binaries with their features already extracted,
the complexity of constructing lineage is O(N2) due to
the computation of the (cid:31)|N|2 (cid:30) pairwise distances. To give
concrete values, we measured the time to construct lin-
eage with multi-resolution features, SD, and 32 KB of
bit-vectors on a Linux 3.2.0 machine with a 3.40 GHz i7
CPU utilizing a single core. Depending on the size of the
data sets, it took 0.002–1.431s for straight line lineage and
0.005–0.385s for DAG lineage with the help of feature
hashing. On average, this translates to 146 samples/s and
180 samples/s for straight line lineage and DAG lineage,
respectively. As a comparison, our BitShred malware
clustering system [20], which represents the state of the
art at the time of its publication in 2011, can process
257 samples per second using a single core on the same
machine. Since the running times of malware cluster-
ing and lineage inference are both dominated by distance
comparisons, and since ILINE needs to resolve ties us-
ing multi-resolution features whereas BitShred needs not,
we conclude that our current implementation of ILINE is
competitive in terms of performance.
8 Discussion & Findings
Features. File/section size features yielded 94.6–95.5%
mean accuracy in straight line lineage on goodware. Such
high accuracy supports Lehman’s laws of software evolu-
tion, e.g., continuing growth. However, size is not a reli-
able feature to infer malware lineage where malware au-
thors can obfuscate a feature, e.g., samples with the same
ﬁle size in MC2. As simple syntactic features, 4/8/16-
grams achieved 95.3–96.3% mean accuracy in straight
line lineage on goodware, whereas 2-grams achieved only
82.4% mean accuracy. This is because 2-grams are not
distinctive enough to differentiate between samples and
cause too many ties. Basic blocks as semantic features
achieved 94.0–95.6% mean accuracy in straight line lin-
eage on goodware. This slightly lower accuracy when
compared to n-grams was due to ties. Multi-resolution fea-
tures performed best, e.g., it achieved 95.8–98.4% mean
accuracy in straight line lineage on goodware. This is due
to its use of both syntactic and semantic features.
Distance Metrics. Our evaluation indicates that our lin-
eage inference algorithms perform similarly regardless
of the distance metrics except for the Jaccard contain-
ment (JC) distance. JC turns out to be inappropriate for
lineage inference because it cannot capture evolution-
ary changes effectively. Suppose there are three contigu-
ous revisions p1, p2, and p3; and p2 adds 10 lines of
code to p1 and p3 adds 10 lines of code to p2. Then,
JC(p1, p2) = JC(p1, p3) = JC(p2, p3) = 0 because one re-
vision is a subset of another revision. Such ties result
p22
p23
p30
p29
p41
p40
(a) Ground truth
p35
p42
p36
p43
p22
p23
p29
p30
p35
p36
p41
p40
(b) Constructed lineage with the use of pseudo timestamps
p42
p43
Figure 8: Error caused by pseudo timestamps in uzbl
 25000
 20000
 15000
 10000
 5000
d
e
t
a
l
u
m
u
c
c
A
e
c
n
a
t
s
i
D
c
i
r
t
e
m
m
y
S
2.0.0 2.1.0
2.2.0 2.3.0
1.3.0
1.2.0
1.0.01.1.0
0.7.40.8.00.9.0
 0
01/01/00
Figure 9: Development history of nano
01/01/04
01/01/08
Date
in low accuracy. For example, JC yielded 74.5% mean
accuracy, whereas SD yielded 84.0% mean accuracy in
DAG lineage on goodware.
Pseudo Timestamp.
ILINE computes pseudo times-
tamps by ﬁrst building a straight line lineage and then
use the recovered ordering as timestamps. Since ILINE
achieved fairly high accuracy in straight line lineage, at
ﬁrst we expected this approach to do well in DAG lin-
eage. To our initial surprise, ILINE with pseudo times-
tamps actually performed worse. In retrospect, we ob-
served that since each branch had been developed sep-
arately, it is challenging to determine the precise order-
ing between samples from different branches. For ex-
ample, Figure 8 shows the partial ground truth and the
constructed lineage by ILINE for uzbl with pseudo
timestamps. Although ILINE without pseudo times-
tamps successfully recovered the ground truth lineage,
the use of pseudo timestamps resulted in poor perfor-
mance. The recovered ordering, i.e., pseudo timestamps
were p22, p40, p41, p42, p43, p23, p29, p30, p35, p36. Due to
the imprecise timestamps, the derivative relationships in
the constructed lineage were not accurate.
Revision History vs. Release Date. Correct software
lineage inference on a revision history may not corre-
spond with software release date lineage. For example,
Figure 9 shows the accumulated symmetric distance be-
tween two neighboring releases where a development
branch of nano-1.3 and a stable branch of nano-1.2
are developed in parallel. ILINE infers software lineage
consistent with a revision history.
92  22nd USENIX Security Symposium 
USENIX Association
outlier
 500
Symmetric Distance
 400
 300
e
c
n
a
t
s
i
D
c
i
r
t
e
m
m
y
S
 200
 100
 0
 20
 0
 120
Figure 10: An outlier in memcached
 100
 40
 60
 80
 100000
d
e
t
a
l
u
m
u
c
c
A
e
c
n
a
t
s
i
D
c
i
r
t
e
m
m
y
S
 80000
 60000
 40000
 20000
Order
sendmail
openssh
grep
redis
redislite
nano
memcached
Threats to Validity. Our malware experiments were
performed on a relatively small data set because of difﬁ-
culties in obtaining the ground truth. Although it is hard
to indicate a representative of modern malware due to its
surreptitious nature, we evaluated our methods on com-
mon malware categories such as bots, worms, and Trojan
horses. To the best of our knowledge, we are the ﬁrst to
take a systematic approach towards software lineage infer-
ence to provide scientiﬁc evidence instead of speculative
remarks.
9 Limitations
Reverting/Refactoring. Regression of code is a chal-
lenging problem in software lineage inference. A revision
adding new functionalities is sometimes followed by sta-
bilizing phases including bug ﬁxes. Bug ﬁxes might be
done by reverting to the previous revision, i.e., undoing
the modiﬁcations of the code.
Some revisions can become outliers because of ILINE’s
greedy construction and reverting/refactoring issues.
In §4.1.3, we propose a technique to detect and process
outliers by looking for peaks of the distance between
two contiguous revisions. For example, ILINE had 70
inversions and 1 EDTM for the contiguous revisions of
memcached. The error came from the 53rd revision that
was incorrectly located at the end of the lineage. Figure 10
shows the symmetric distance between two adjacent revi-
sions in the recovered lineage before we process outliers.
The outlier caused an exceptional peak of the symmetric
distance at the rightmost of the Figure 10. ILINE iden-
tiﬁed such possible outliers by looking for peaks, then
generated the perfect lineage of memcached after han-
dling the outlier.
There can also be false positives among detected out-
liers, i.e., a peak is identiﬁed even revisions are in the
correct order. For example, a peak can be identiﬁed be-
tween two contiguous revisions when there is a huge
update like major version changes. However, such false
positives do not affect overall accuracy of ILINE because
the original (correct) position will be chosen again when
minimizing the overall distance.
Although our technique improves lineage inference, it
may not be able to resolve every case. Unless we design a
 0
 0
 100
 200
 300
 400
 500
Order
Figure 11: Recovered ordering of mixed data set
precise model describing the developers’ reverting/refac-
toring activity, no reasonable algorithm may be able to
recover the same lineage as the ground truth. Rather, the
constructed lineage can be considered as a more practi-
cal/pragmatic representation of the truth.
Root Identiﬁcation.
It is a challenging problem to iden-
tify the correct roots of data sets where we do not have
any knowledge about the compilation process. ILINE suc-
cessfully identiﬁed the correct roots based upon code size
and complexity in all data sets except for some data sets
of actual release binaries. This shows that the Lehman’s
laws of software evolution are generally applicable to root
identiﬁcation, but with a caveat. For example, with actual
release binaries data sets, ILINE achieved 77.8% mean
accuracy with the inferred roots. The accuracy increased
to 91.8% with the knowledge of the correct ﬁrst revision.
In order to improve lineage inference, we can lever-
age “ﬁrst seen” date of malware, e.g., Symantec’s World-
wide Intelligence Network Environment [10] or tool-
chain provenance such as compilers and compilation op-
tions [36].
Clustering. Clustering may not be able to group pro-
gram accurately due to noise or algorithmic limitations. In
order to simulate cases where clustering failed, we mixed
binaries from seven programs including memcached,
redis, redislite, grep, nano, sendmail, and
openssh into one set and ran our lineage inference algo-
rithm on it. As shown in Figure 11, revisions from each
program group located next to each other in the recovered
order (each program is marked in a different color). This
shows ILINE can identify close relationships within the
same program group even with high noise in a data set.
There are multiple intra-program gaps and inter-program
gaps. Relatively big intra-program gaps corresponded to
major version changes of a program where the Jaccard
distances were 0.28–0.66. The Jaccard distances at the
inter-program gaps were much higher, e.g., 0.9–0.95. This
means we can separate the mixed data set into different
program groups based on the inter-program gaps.
USENIX Association  
22nd USENIX Security Symposium  93
Feature Extraction. Although ILINE achieved an over-
all 95.8% mean accuracy in straight line lineage of good-
ware, ILINE achieved only 77.8% mean accuracy with
actual released binaries. In order to improve lineage infer-
ence, future work may choose to leverage better features.
For example, we may use recovered high-level abstraction
of program binaries [41], or we may detect similar code
that was compiled with different compilers and optimiza-
tion options [24].
10 Related Work
While previous research focuses on studying known soft-
ware lineage or development history, our focus is on de-
signing algorithms to create lineage and evaluating met-
rics to assess the quality of constructed lineage.
Belady and Lehman studied software evolution of IBM
OS/360 [3], and Lehman and Ramil formulated eight
laws describing software evolution process [28]. Xie et al.
analyzed histories of open source projects in order to ver-
ify Lehman’s laws of software evolution [45], and God-
frey and Tu investigated the Linux kernel to understand a
software evolution process in open source development
systems [14]. Shihab et al. evaluated the effects of branch-
ing in software development on software quality with
Windows Vista and Windows 7 [42]. Kim et al. studied
the history of code clones to evaluate the effectiveness
of refactoring on software improvement with respect to
clones [25].
Massacci et al. studied the effect of software evolution,
e.g., patching and releasing new versions, on vulnerabil-
ities in Firefox [33], and Jang et al. proposed a method
to track known vulnerabilities in modern OS distribu-
tions [19]. Edwards and Chen statistically veriﬁed that
an increase of security issues identiﬁed by a source code
analyzer in a new release may indicate an increase of
exploitable bugs in a release [11]. Davies et al. proposed
a signature-based matching of a binary against a known
library repository to identify library version information,
which can be potentially used for security vulnerabilities
scans [7].
Gupta et al. studied malware metadata collected by an
anti-virus vendor to describe evolutionary relationships
among malware [16]. Dumitras and Neamtiu studied
malware evolution to ﬁnd new variants of well-known
malware [9]. Karim et al. generated phylogeny models
based upon code similarity to understand how new mal-
ware related to previously seen malware [22]. Khoo and
Lio investigated FakeAV-DO and Skyhoo malware fami-