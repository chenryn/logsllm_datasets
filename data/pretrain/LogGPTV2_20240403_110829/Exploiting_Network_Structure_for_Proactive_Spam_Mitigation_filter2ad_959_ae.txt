Today, when mail servers experience overload, they drop
connections greedily: the server accepts all connections
until it is at maximum load, and then refuses all connec-
tion requests until its load drops below the maximum.
We aim to improve the performance under overload by
using information in the structure of IP addresses, as sug-
gested by the results in Sec. 2 and Sec. 3. At a high-level,
our approach is to obtain a history of IP addresses and IP
clusters, and use it to select the IP addresses that we pri-
oritize under overload. To explore the potential beneﬁts
of this approach, we simulate the mail server operation
and allow some additional functionality to handle over-
load.
To motivate our simulation, we describe brieﬂy the
way many mail servers in corporations and ISPs operate.
First, the sender’s mail server or a mail relay tries to con-
nect to the receiving mail server via TCP. The receiving
mail server accepts the connection if capacity is avail-
able, and then the mail servers perform the SMTP hand-
shake and transfer the email. The receiving mail server
stores the email to disk and adds it to the spam processing
queue. For each e-mail on the queue, the receiving mail
server then performs content-based spam ﬁltering [3, 1]
which is typically the most expensive part of email pro-
cessing. After this, the spam emails are dropped or de-
livered to a spam mailbox, and the good emails are de-
livered to the inbox of the recipient.
In our simulation we simplify the mail server model,
while ensuring that it is still sufﬁciently rich to capture
the problem that we explore. We believe that our model
is sufﬁciently representative for a majority of mail server
implementations used today; however, we acknowledge
that there are mail server architectures in use which are
not fully captured in our model. In the next section, we
describe the simulation model in more detail.
4.2.1 Mail Server Simulation
We simulate mail-server operation in the following man-
ner:
• Phase 1: When the mail server receives an SMTP
connection request, it may decide whether or not to
accept the connection.
If it decides to accept the
connection, the incoming mail takes t time units to
be transferred to the mail server. Thus, if a server
can accept k connection requests simultaneously, it
behaves like a k-parallel processor in this phase. We
do so because this phase models the SMTP hand-
shake and transfer of mail, and therefore, it needs to
model state for each connection separately.
• Phase 2: Once the mail has been received, it is
added to a queue for spam ﬁltering and delivery to
the receiving mailbox if any. At each time-step, the
mail server selects mails from this queue and pro-
cesses them; the number of mails chosen depend on
the mail server’s capacity and the cost of each in-
dividual mail. Here, since we model computation
cycles, a sequential processing model sufﬁces. The
mail server has a timeout: it discards any mail that
has been in the queue for more than m time units.
If the load has sufﬁcient ﬂuctuation, a large timeout
would be useful, but we want to minimize timeout
since email has the expectation of being timely.
We assume that the cost of denying/dropping a request
is 0, the cost of processing the SMTP connection is α
fraction of its total cost, and the cost of the remainder
is 1 − α fraction of the total cost. We also allow Phase
1 of the mail server simulator to have α fraction of the
server’s computational resources, and Phase 2 to have
the remainder. Since the content-based analysis is typ-
160
16th USENIX Security Symposium
USENIX Association
ically the most expensive part of processing a message,
we expect that α is likely to be small.
This two-phase simulation model allows for more ﬂex-
ibility in our policy design, since it opens the possibility
of dropping emails which have already been received and
are awaiting spam ﬁltering without wasting too many re-
sources.
4.2.2 Policies
Next, we present the prioritization/drop policies that we
implemented and evaluated on the mail server simulator.
In this simulation model, the default mail-server action
corresponds to the following: at each time-interval, the
server accepts incoming requests in the order of arrival,
as long as it is not overloaded. Once mail has been re-
ceived, the server processes the ﬁrst mail in the queue,
and discards any mail that has exceeded its timeout. We
refer to this as the greedy policy.3
The space of policy options that a mail-server is al-
lowed to operate determine the kinds of beneﬁts it can
get.
In this problem, one natural option for the mail
server is to decide immediately whether to accept or re-
ject a connection request. However, such a policy may
be quite sensitive to ﬂuctuation in the workload received
at the mail server. Another option may be to reject some
e-mails after the SMTP connection has been accepted,
but before any spam-ﬁltering checks or content-based
analysis (such as spam-ﬁltering software) has been ap-
plied. Note that content-based analysis typically is the
most computationally expensive part of receiving mail.
Thus, with this option, the mail server may do a small
amount of work for some additional emails that eventu-
ally get rejected, but is less affected by the ﬂuctuation
of mail arrival workload. We restrict the space of policy
options to the time before any content-based analysis of
the incoming mail is done.
To solve the mail-server overload problem, we imple-
ment the following policies at the two phases:
• Phase-1 policy: The policy in Phase 1 is designed to
preferentially accept IP addresses with a good rep-
utation when the server is near maximum load: as
the server gets closer to overload, the policy only ac-
cepts IP addresses with better and better reputations.
The policy itself is more complex, since it needs to
consider the expected legitimate mail workload, and
yet not stay idle too long. We therefore leave exact
details to the appendix. In addition, when the load
is below some percentage (we choose 75%) of the
3To ensure that the current mail server policy is not unfairly mod-
elled under this simulation model, we evaluated greedy policies in an-
other simulation model, in which each connection took z time units to
process from start to end. The performance of the greedy policy was
similar, therefore we do not describe the model further.
total capacity, the server accepts all mail: this way,
it minimizes impact on normal operation of the mail
server. 4
• Phase-2 policy: The scheduling policy here is eas-
ier to design, since the queue has some knowledge
of what needs to be processed. Even a simple policy
that greedily accepts the item with the highest rep-
utation value will do well, as long as the reputation
function is reasonably accurate. We use this greedy
policy for Phase 2.
Our history-based reputation function R is simple:
First, we ﬁnd a list of persistent senders of legitimate
mail from the same time period (we choose all senders
that have appeared in at least 10 days), and for these IP
addresses, we use their lifetime IP spam-ratio as their
reputation value. For the remaining IP addresses, we use
their cluster spam-ratio as their reputation value: for each
week, we use the history of the preceding four weeks in
computing the lifetime spam-ratio (deﬁned over 4 weeks)
for each cluster that sends mail. 5 In this way, we com-
bine the results of the IP-based analysis and cluster-based
analysis in Sec. 2 in designing the reputation function.
This reputation function is extremely simple, but it
still illustrates the value of using a history-based rep-
utation mechanism to tackle the mail server overload
problem. We also note that the historical IP reputa-
tions based on network-aware clusters in this manner
may not always be perfect predictors of spamming be-
haviour. While network-aware clusters are an aggrega-
tion technique with a basis in network structure, they
could serve as a starting point for more complex clus-
tering techniques, and these techniques may also incor-
porate ﬁner notions of granularity and conﬁdence.
A more sophisticated approach to using the history of
IP addresses and network-aware clusters that addresses
these concerns is likely to yield an improvement in per-
formance, but is beyond the scope of this paper and left
as future work. In the following section, we describe the
performance beneﬁts that we gain from using this repu-
tation function in the evaluation.
4.3 Evaluation
We evaluate our history-based policies by replaying the
traces of our data set on our simulator. Since the traces
record each connection request with a time-stamp, we
can replay the traces to simulate the exact workload re-
ceived by the mail server. We do so, with the simplifying
4Technically, this is slightly more complex: it examines if the load
is below 75% of the server capacity allowed to Phase 1.
5One technical detail left to consider are the IP addresses originat-
ing from clusters without history. In our reputation function, any IP
address that has no history-based reputation value is given a slightly
bad reputation.
USENIX Association
16th USENIX Security Symposium
161
assumption that each incoming e-mail incurs the same
computational cost. Since our traces are ﬁxed, we sim-
ulate overload by decreasing the simulated server’s ca-
pacity, and replaying the same traces. This way, we do
not change the distribution and connection request times
of IP addresses in the input traces between the different
experiments. At the same time, it allows us to simulate,
without changing the traces, how the mail server behaves
as a function of the increasing workload.
Simulation Parameters: We now explain the parame-
ters that we choose for our simulation. We choose the
time t for the Phase 1 operation to be 4s.6 We use 60s
for the timeout m, the waiting time in the queue before
Phase 2 (it implies that mail will be delivered within 1
minute, or discarded after Phase 1). This appears to be
sufﬁciently small so as to not noticeably affect the deliv-
ery of legitimate mail. 7
To induce overload, we vary the capacity of the sim-
ulated mail server to 200, 100, 66, 50, and 40 mes-
sages/minute. The greedy policy processed an average
of 95.2% of the messages received when the server ca-
pacity was set to 200 messages/minute, as seen in Ta-
ble 2. At capacities larger than 200 messages/minute,
the number of messages processed by the greedy policy
grows very slowly, indicating that this is likely to be an
effect of the distribution of connection requests in the
traces. For this reason, we take capacity of 200/minute
as the required server capacity. We then refer to the other
server capacities in relation to required server capacity
for this trace workload: a server with capacity of 100
messages/minute must process the same workload with
half the capacity of the required server, so we deﬁne it
to have an overload-factor of 2. Likewise, the server ca-
pacities we test 200, 100, 66, 50 and 40 messages/minute
have overload-factors of around 1, 2, 3, 4, and 5 respec-
tively.
Recall that the parameter α is the cost of processing
the message at Phase 1. We expect α to impact the per-
formance, so we test two values α = 0.1, 0.5 in the eval-
uation; recall that α is likely to be small, and so α = 0.5
is a conservative choice here. The value of α has no ef-
fect on the performance of the greedy policy. For this
reason, the discussion features only one greedy policy
for all values of α. For the history-based policies, α
sometimes has an effect on the performance, since these
policies allow for a decision to be taken at Phase 2. We
therefore refer to the history-based policies as 10-policy,
6We vary t for Phase 1 between 2-4s: our traces have a recorded
time granularity of 1s, and the maximum seen in the traces before a
disconnect was 4s. This does not appear to impact the results pre-
sented here, since both kinds of policies receive the same value of t.
We present in the results for t = 4s
7This value also has no noticeable impact on our results when m ≥
20s suggesting that most of the legitimate mail is processed quickly, or
not at all.
and 50-policy, for α = 0.1 and 0.5 respectively.
4.3.1 Impact on Legitimate mail
We ﬁrst compare the number of legitimate mails ac-
cepted by the different policies over many time intervals,
where each interval is an hour long. Since our goal is
to maximize the amount of legitimate mail accepted, the
primary metric we use is the goodput ratio: the ratio of
legitimate mail accepted by the mail server to the total le-
gitimate mail in the time interval. This is a natural metric
to use, since it makes the different time intervals compa-
rable, and so we can see if the policies are consistently
better than the greedy policy, rather than being heavily
weighted by the number of legitimate mails in a few time
intervals. For the performance evaluation, we examine
the average goodput ratio, the distribution of the goodput
ratios and the goodput improvement factor.
Average Goodput Ratio: Table 1 shows the average
goodput ratios for the different policies under different
levels of overload. It shows that, on average, for each of
these overloads, the goodput of any of the policies is bet-
ter than the greedy policy. The difference is marginal at
overload-factor 1, and increases quickly as the overload-
factor increases: at overload-factor 4, the average good-
put ratio is 64.3−64.5% for any of the history-based poli-
cies, in comparison to 26.8% for the greedy policy. We
also observe that the history-based policies scale more
gracefully with the overload. Thus, we conclude that,
on average, the history-based policies gain a signiﬁcant
improvement over the greedy policy.
Distribution of Goodput Ratios: While the average
goodput ratio is a useful summarization tool, it does not
give a complete picture of the performance. For this
reason, we next compare the distribution of the server
goodput in the different time intervals.
Fig. 8(a)-(b)
shows the CDF of the goodput ratios for the different
policies, for two overload-factors: 1 and 4. We ob-
serve that the goodput ratio distributions are quite sim-
ilar for the greedy and history-based policies when the
overload-factor is 1 (Fig. 8(a)): about 60% of the time,
all of the policies accept 100% messages. This changes
drastically as the overload-factor increases. Fig. 8(b)
shows the goodput ratio distributions for overload-factor
4. As much as 50% of the time, the greedy policy has
a goodput-ratio of at most 0.25. By contrast, more than
90% of the time, the history-based policies have a good-
put ratio of at least 0.5. The results show that the the
history-based policies have a consistent and signiﬁcant
improvement over the greedy policy when the load is suf-
ﬁciently high.
Improvement factor of Goodput-Ratios: Finally, we
compare the goodput ratios on a per-interval basis. For
this analysis, we focus on the 10-policy; our goal is to
162
16th USENIX Security Symposium
USENIX Association
see how often the 10-policy does better than the greedy
algorithm. That is, for each time interval, we compute
the goodput-factor, deﬁned to be Goodput of 10-Policy
Goodput of Greedy .
Fig. 8(c) plots how often goodput-factor lies between
90% − 300% for the different overload-factors. We note
that when the overload-factor is 1, the performance im-
pact of our history-based policy on the legitimate mail
is marginal: in all the time intervals, the 10-policy has a
goodput-factor of at least 90%, and over 95% of the time,
it has a goodput factor of at least 99%. As the overload-
factor increases, the amount of time intervals in which
the 10-policy has a goodput-factor of 100% or more in-
creases, meaning the number of time intervals in which
the 10-policy does better than the greedy algorithm in-
creases, as we would expect. When the overload-factor
is 4, for example, 66% of the time, the goodput-factor is
at least 200%: 10-policy accepts at least twice as many
legitimate mails as the greedy algorithm. We conclude
that in most time intervals, the history-based policies per-
form better than the greedy policy, and the factor of their
improvement increases as the overload-factor increases.
Lastly, we note that the behaviour of the 10-policy
and the 50-policy does not appear to differ too much
when the overload-factor is sufﬁciently high or sufﬁ-
ciently low. With intermediate overload-factors, they
perform slightly differently, as we see in Table 1:
the
50-policy tends to be a little more conservative about ac-
cepting messages that may not have a good reputation in
comparison to the 10-policy.
4.3.2 Impact on Throughput and Spam
While our primary metric of performance is the goodput,
we are still interested in the impact of using the history-
based policies on the total messages and spam processed
by the mail server. While these are not our primary goals,
they are still important since they give a picture of the
complete effect of using these history-based policies.
Impact on Server Throughput: The history-based poli-
cies obviously gain their improvement by selectively
choosing the IP addresses to process: it selectively ac-
cepts only good IP addresses in the incoming workload,
if it is likely that the whole workload might not be pro-
cessed. This may result in a decrease in server through-
put in comparison to the greedy policy for certain load.
For example, if the server receives a little less workload
than it could process, the history-based policies may pro-
cess fewer messages than the greedy policy, because they
may reserve capacity for good IP addresses that they ex-
pect to see but which never actually appear. We observe
this in our simulations and we discuss it now.
We deﬁne throughput to be fraction of the total mes-
sages processed by the server. Table 2 shows the av-
erage throughput achieved by both policies under vari-
s
r
u
o
h
f
o
n
o
i
t
c
a
r
F
1
0.8
0.6
0.4
0.2
0
0
Greedy
α = 0.1
α = 0.5
0.2
0.4
0.6
Goodput−Ratios
0.8
1
(a) Overload-Factor 1: CDF of goodput-ratios for all
policies
1
s
r
u
o
h
f
o
n
o
i
t