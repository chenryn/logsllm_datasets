title:A4NT: Author Attribute Anonymity by Adversarial Training of Neural
Machine Translation
author:Rakshith Shetty and
Bernt Schiele and
Mario Fritz
A4NT: Author Attribute Anonymity by Adversarial 
Training of Neural Machine Translation
Rakshith Shetty, Bernt Schiele, and Mario Fritz, Max Planck Institute for Informatics
https://www.usenix.org/conference/usenixsecurity18/presentation/shetty
This paper is included in the Proceedings of the 
27th USENIX Security Symposium.
August 15–17, 2018 • Baltimore, MD, USA
978-1-939133-04-5
Open access to the Proceedings of the 27th USENIX Security Symposium is sponsored by USENIX.A4NT: Author Attribute Anonymity
by Adversarial Training of Neural Machine Translation
Rakshith Shetty Bernt Schiele Mario Fritz
Max Planck Institute for Informatics
Saarland Informatics Campus
Saarbr¨ucken, Germany
Email: PI:EMAIL
Abstract
Text-based analysis methods enable an adversary to reveal
privacy relevant author attributes such as gender, age and
can identify the text’s author. Such methods can compro-
mise the privacy of an anonymous author even when the
author tries to remove privacy sensitive content. In this
paper, we propose an automatic method, called the Ad-
versarial Author Attribute Anonymity Neural Translation
(A4NT), to combat such text-based adversaries. Unlike
prior works on obfuscation, we propose a system that
is fully automatic and learns to perform obfuscation en-
tirely from the data. This allows us to easily apply the
A4NT system to obfuscate different author attributes. We
propose a sequence-to-sequence language model, inspired
by machine translation, and an adversarial training frame-
work to design a system which learns to transform the
input text to obfuscate the author attributes without paired
data. We also propose and evaluate techniques to impose
constraints on our A4NT model to preserve the semantics
of the input text. A4NT learns to make minimal changes
to the input to successfully fool author attribute classi-
ﬁers, while preserving the meaning of the input text. Our
experiments on two datasets and three settings show that
the proposed method is effective in fooling the attribute
classiﬁers and thus improves the anonymity of authors.
1
Introduction
Natural language processing (NLP) methods includ-
ing stylometric tools enable identiﬁcation of authors of
anonymous texts by analyzing stylistic properties of the
text [1–3]. NLP-based tools have also been applied to
proﬁling users by determining their private attributes like
age and gender [4]. These methods have been shown
to be effective in various settings like blogs, reddit com-
ments, twitter text [5] and in large scale settings with up
to 100,000 possible authors [6]. In a recent famous case,
authorship attribution tools were used to help conﬁrm J.K
Rowling as the real author of A Cuckoo’s Calling which
was written by Ms. Rowling under pseudonymity [7].
This case highlights the privacy risks posed by these tools.
Apart from the threat of identiﬁcation of an anonymous
author, the NLP-based tools also make authors suscep-
tible to proﬁling. Text analysis has been shown to be
effective in predicting age group [8], gender [9] and to
an extent even political preferences [10]. By determining
such private attributes an adversary can build user proﬁles
which have been used for manipulation through targeted
advertising, both for commercial and political goals [11].
Since the NLP based proﬁling methods utilize the stylis-
tic properties of the text to break the authors anonymity,
they are immune to defense measures like pseudonymity,
masking the IP addresses or obfuscating the posting pat-
terns. The only way to combat them is to modify the
content of the text to hide stylistic attributes. Prior work
has shown that while people are capable of altering their
writing styles to hide their identity [12], success rate de-
pends on the authors skill and doing so consistently is
hard for even skilled authors [13]. Currently available
solutions to obfuscate authorship and defend against NLP-
methods has been largely restricted to semi-automatic
solutions which suggest possible changes to the user [14]
or hand-crafted transformations to text [15] which need
re-engineering on different datasets. This however limits
the applicability of these defensive measures beyond the
speciﬁc dataset it was designed on. To the best of our
knowledge, text rephrasing using generic machine trans-
lation tools [16] is the only prior work offering a fully
automatic solution to author obfuscation which can be
applied across datasets. But as found in prior work [17]
and further demonstrated with our experiments, generic
machine translation based obfuscation fails to sufﬁciently
hide the identity and protect against attribute classiﬁers.
Additionally the focus in prior research has been to-
wards protecting author identity. However, obfuscating
identity does not guarantee protection of private attributes
like age and gender. Determining attributes is generally
easier than predicting the exact identity for NLP-based
adversaries, mainly due to former being small closed-set
USENIX Association
27th USENIX Security Symposium    1633
prediction task compared to later which is larger and po-
tentially open-set prediction task. This makes obfuscating
attributes a difﬁcult but an important problem.
Our work. We propose an uniﬁed automatic system
(A4NT) to obfuscate authors text and defend against NLP
adversaries. A4NT follows the imitation model of defense
discussed in [12] and protects against various attribute
classiﬁers by learning to imitate the writing style of a tar-
get class. For example, A4NT learns to hide the gender of
a female author by re-synthesizing the text in the style of
the male class. This imitation of writing style is learned
by adversarially training [18] our style-transfer network
against the attribute classiﬁer. Our A4NT network learns
the target style by learning to fool the authorship clas-
siﬁers into misclassifying the text it generates as target
class. This style transfer is accomplished while aiming to
retain the semantic content of the input text.
Unlike many prior works on authorship obfusca-
tion [14, 15], we propose an end-to-end learnable author
anonymization solution, allowing us to apply our method
not only to authorship obfuscation but to the anonymiza-
tion of different author attributes including identity, gen-
der and age with a uniﬁed approach. We illustrate this
by successfully applying our model on three different at-
tribute anonymization settings on two different datasets.
Through empirical evaluation, we show that the proposed
approach is able to fool the author attribute classiﬁers
in all three settings effectively and better than the base-
lines. While there are still challenges to overcome before
applying the system to multiple attributes and situations
with very little data, we believe that A4NT offers a new
data driven approach to authorship obfuscation which can
easily adapt to improving NLP-based adversaries.
Technical challenges: We design our A4NT network ar-
chitecture based on the sequence-to-sequence neural ma-
chine translation model [19]. A key challenge in learning
to perform style transfer, compared to other sequence-
to-sequence mapping tasks like machine translation, is
the lack of paired training data. Here, paired data refers
to datasets with both the input text and its correspond-
ing ground-truth output text. In obfuscation setting, this
means having a large dataset with semantically same sen-
tences written in different styles corresponding to the
attributes we want to hide. Such paired data is infeasible
to obtain and this has been a key hurdle in developing
automatic obfuscation methods. Some prior attempts
to perform text style transfer required paired training
data [20] and hence were limited in their applicability
beyond toy-data settings. We overcome this by training
our A4NT network within a generative adversarial net-
works (GAN) [18] framework. GAN framework enables
us to train the A4NT network to generate samples that
match the target distribution without need for paired data.
We characterize the performance of our A4NT network
along two axes: privacy effectiveness and semantic simi-
larity. Using automatic metrics and human evaluation to
measure semantic similarity of the generated text to the in-
put, we show that A4NT offers a better trade-off between
privacy effectiveness and semantic similarity. We also an-
alyze the effectiveness of A4NT for protecting anonymity
for varying degrees of input text “difﬁculty”.
Contributions: In summary, the main contributions of
our paper are. (1): We propose a novel approach to au-
thorship obfuscation that uses a style-transfer network
(A4NT) to automatically transform the input text to a tar-
get style and fool the attribute classiﬁers. The network is
trained without paired data by adversarial training. (2):
The proposed obfuscation solution is end-to-end trainable,
and hence can be applied to protect different author at-
tributes and on different datasets with no changes to the
overall framework. (3): Quantifying the performance of
our system on privacy effectiveness and semantic simi-
larity to input, we show that it offers a better trade-off
between the two metrics compared to baselines.
2 Related Work
In this section, we review prior work relating to four dif-
ferent aspects of our work – author attribute detection (our
adversaries), authorship obfuscation (prior work), ma-
chine translation (basis of our A4NT network) and gener-
ative adversarial networks (training framework we use).
Authorship and attribute detection Machine learning
approaches, where a set of text features are input to a
classiﬁer which learns to predict the author, have been
popular in recent author attribution works [2]. These meth-
ods have been shown to work well on large datasets [6],
duplicate author detection [21] and even on non-textual
data like code [22]. Sytlometric models can also be ap-
plied to determine private author attributes like age or
gender [4].
Classical author attribution methods rely on a prede-
ﬁned set of features extracted from the input text [23].
Recently deep-learning methods have been applied to
learn to extract the features directly from data [3, 24].
[24] uses a multi-headed recurrent neural network (RNN)
to train a generative language model on each author’s text
and use the model’s perplexity on the test document to
predict the author. Alternatively, [3] uses convolutional
neural network (CNN) to train an author classiﬁers. To
show generality of our A4NT network, we test it against
both RNN and CNN based author attribute classiﬁers.
Authorship obfuscation Authorship obfuscation meth-
ods are adversarial in nature to stylometric methods of
author attribution; they try to change the style of the input
text so that the author identity is not discernible. The
majority of prior works on author attribution are semi-
automatic [14, 25], where the system suggests authors to
make changes to the document by analyzing the stylo-
1634    27th USENIX Security Symposium
USENIX Association
metric features. The few available automatic obfuscation
methods have relied on general rephrasing methods like
generic machine translation [16] or on predeﬁned text
transformations [26]. Round-trip machine translation,
where input text is translated to multiple languages one
after the other until it is translated back to the source lan-
guage, is proposed as an automatic method of obfuscation
in [16]. Recent work [26] obfuscates text by moving the
stylometric features towards the average values on the
dataset by applying pre-deﬁned transformations on input
text.
We propose the ﬁrst method to achieve fully automatic
obfuscation using text style transfer. This style transfer is
not pre-deﬁned but learnt directly from data optimized for
fooling attribute classiﬁers. This allows us to apply our
model across datasets without extra engineering effort.
Machine translation The task of style-transfer of text
data shares similarities with the machine translation prob-
lem. Both involve mapping an input text sequence onto
an output text sequence. Style transfer can be thought of
as machine translation on the same language.
Large end-to-end trainable neural networks have be-
come a popular choice in machine translation [27, 28].
These methods are generally based on sequence-to-
sequence recurrent models [19] consisting of two net-
works, an encoder which encodes the input sentence into
a ﬁxed size vector and a decoder which maps this encod-
ing to a sentence in the target language.
We base our A4NT network architecture on the word-
level sequence-to-sequence language model [19]. Neu-
ral machine translation systems are trained with large
amounts of paired training data. However, in our setting,
obtaining paired data of the same text in different writ-
ing styles is not viable. We overcome the lack of paired
data by casting the task as matching style distributions
instead of matching individual sentences. Speciﬁcally,
our A4NT network takes an input text from a source dis-
tribution and generates text whose style matches the target
attribute distribution. This is learnt without paired data
using distribution matching methods. This reformulation
allows us to demonstrate the ﬁrst successful application
of the machine translation models to the obfuscation task.
Generative adversarial networks Generative Adversar-
ial Networks (GAN) [18] are a framework for learning a
generative model to produce samples from a target dis-
tribution. It consists of two models, a generator and a
discriminator. The discriminator network learns to dis-
tinguish between the generated samples and real data
samples. Simultaneously, the generator learns to fool this
discriminator network thereby getting closer to the target
distribution. In this two-player game, a fully optimized
generator perfectly mimics the target distribution [18].
We train our A4NT network within the GAN frame-
work, directly optimizing A4NT to fool the attribute clas-
siﬁers by matching style distribution of the target class. A
recent approach to text style-transfer proposed in [29] also
utilizes GANs to perform style transfer using unpaired
data. However, the solution proposed in [29] changes
the meaning of the input text signiﬁcantly during style
transfer and is applied on the sentiment transfer task. In
contrast, authorship obfuscation task requires the gen-
erated text to preserve the semantics of the input. We
address this problem by proposing two methods to im-
prove the semantic consistency between the input and the
A4NT output.
Attacks against machine-learning models: Recent
works have shown that machine learning models are sus-
ceptible to attacks by adversaries which can manipulate
the input of these models [30–32]. By adding only a small
amount of perturbation to the input image, barely notice-
able to the human eye, the adversary can fool state-of-the
art image classiﬁers to wrongly classify the input [30, 31].
Adding adversarial perturbation to images has also been
proposed as a means of protecting the users’ privacy [33].
While large portion of research on adversarial perturba-
tions has focused on the image domain, few recent works
have shown that one can also fool NLP classiﬁers by delet-
ing, adding or replacing few salient words [34, 35] and
by adding whole sentences unrelated to the topic of the
document [36]. However, while the focus of these works
is to fool the NLP classiﬁers with producing realistic text,
there is no consideration to whether the meaning of the
input text is preserved. Additionally the transformations
performed are restricted to the predeﬁned classes like add,
remove or replace, with independently tuned heuristics
for each of these transformations. In contrast, we propose
a machine translation model which automatically learns
to transform the input text appropriately to fool the at-
tribute classiﬁers, while aiming to preserve the meaning
of the input text.
3 Threat Model
In our target scenario, our user is faced with an adver-
sary who can access the text written by the user and the
adversary wishes to determine the user’s private attributes
for identiﬁcation or for proﬁling. We assume that the au-
thor has taken care to remove obvious identiﬁable features
from the text like name, zip code, IP address etc. The
adversary has to rely on stylistic properties of the text for
the analysis. To aid with this analysis, adversary can train
NLP models on large amount of publicly available data,
for example blog dataset [37], twitter dataset [38]. In this
scenario, the proposed A4NT system enables automatic
obfuscation of user’s writing style to hide any desired
private attribute like age group, gender or identity.
USENIX Association
27th USENIX Security Symposium    1635
Figure 1: GAN framework to train our A4NT network.
Input sentence is transformed by A4NT to match the style
of the target attribute. This output is evaluated using the
attribute classiﬁer and semantic consistency loss. A4NT is
trained by backpropagating through these losses.
4 Author Attribute Anonymization
We propose an author adversarial attribute anonymiz-
ing neural translation (A4NT) network to defend against
NLP-based adversaries. The proposed solution includes
the A4NT Network , the adversarial training scheme, and
semantic and language losses to learn to protect private