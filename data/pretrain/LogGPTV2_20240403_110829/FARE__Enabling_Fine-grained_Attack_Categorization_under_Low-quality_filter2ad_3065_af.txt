to accomplish these tasks. The ﬁrst strategy is to manually
analyze samples in a given cluster to assign meaningful labels.
For example, the analysts can identify a small number of
representative samples (e.g., based on centrality) in a given
cluster for in-depth analysis. We argue that, by producing high-
quality clusters, FARE saves analysts’ time who only need
to investigate a smaller number of representative samples. To
further save manual efforts, analysts might take the second
strategy, which is to align clusters with the given labels. For
each cluster that contains given labels, we can compute a
matching score (i.e.,
# of total samples in the cluster) and ﬁnd the label
with the highest matching score. The analyst can set a cut-off
threshold (e.g., 0.9): if the highest matching score is above this
threshold, the cluster stays with the existing label. Appendix-F
shows a running example. The second strategy, while efﬁcient,
should be applied carefully (e.g., to well-known classes only)
since the given labels are not entirely trustworthy.
Computational Complexity.
In Section §IV, we show that
FARE only introduces a small computational overhead on top
of the clustering algorithms. Here, we compare the asymptotic
complexity of FARE and with those of the (semi-)supervised
baselines. Speciﬁcally, the computational complexity of FARE
is O(max{IdBd|θd|K, pN 2, IiM B2
i |θi|}), where N is the
number of samples. Id, Bd, and |θd| represents the number of
training iteration, batch size, and model parameters of DEC.
Similar, Ii, Bi, and |θi| represents the number of training
iteration, batch size, and parameters of input transformation
model (see Appendix-D for the derivation).
# of matched samples
The computational cost of the (semi)-supervised baselines
are: MixMatch – O(IB2A|θ|), Ladder and DNN – O(IB |θ|),
where A is the number of data augmentation rounds in Mix-
i |θi|}, similar
Match. When pN 2 < max{IdBd|θd|K, IiM B2
to MixMatch, the complexity of FARE is also quadratic to
the batch size B. A practical example is the malware dataset
in Section §IV, where the average run time of MixMatch
(i.e., 400.33s) is similar to FARE (i.e., 434.05s). For a very
12
transformation net q,
large scale dataset with an ultra-high dimensionality, FARE
may be slower than semi-supervised learning methods due
to the high cost of DBSCAN. However, recent research has
proposed accelerate DBSCAN through parallel computing [29]
or GPU [25]. These strategies can also be applied to further
accelerate FARE for very large-scale datasets. With the above
analysis, we can conclude that the computational cost of FARE
is acceptable. Our real-world deployment in Section §V also
conﬁrms that practicality of running FARE in production.
Hyperparameters. FARE has the following hyper-parameters:
the number of neighborhood model M, the hyper-parameter
inherited from contrastive learning (the output dimension of
input
the distance radius α and the
regularization coefﬁcients λ), the hyper-parameters inherited
from base clustering algorithms, and the hyper-parameters
introduced by our design (K and p1). As discussed in Sec-
tion §III-D, we set λ to a small value and select the K and p1
based on the AMIs computed on a validation set. For M, as
shown in Section §IV, FARE can achieve a good performance
with merely 10 unsupervised neighborhood models. Appendix-
G shows that FARE is also robust to the subtly changes in
the distance radius α and the output dimension q. For the
hyper-parameters of clustering algorithms, existing works have
provided suggested default setting [11].
Online Setup. While primarily designed for ofﬂine analysis,
FARE can also be used in an online fashion. As is elaborated
in Section §III-A, FARE processes a dataset with three steps.
After the ﬁrst two steps, FARE could learn a transformation
function. Using this function to map each data sample into
a low-dimensional space, FARE then employs K-means to
assign data to the corresponding category. This clustering
step could be done incrementally. Therefore,
introduces
only lightweight computation and offers the possibility of
performing online clustering. In our current design, the ﬁrst
two steps are more computationally intensive than the third
step. Therefore, it is challenging to update the transformation
function in an online fashion. However, this does not hinder
the online usage of FARE.
it
After learning a transformation function, even without
frequently updating it, FARE could still perform clustering
accurately. Take our current deployment
in the real-world
online service J as an example. In order to capture the
distribution/covariate shift [58], [8], we retrain and update
our transformation function weekly. We observe that
this
setup does not jeopardize FARE’s efﬁcacy, which implies the
feasibility of FARE’s online usage. However, we admit that the
retraining cycle could vary for different applications because
of the variation in the data dynamics. This work will leave the
in-depth online usage exploration as part of future work.
Adversarial Attacks. As an machine learning algorithm,
FARE could be vulnerable to adversarial manipulations such as
poisoning attacks and adversarial evasion attacks. Researchers
have explored data poisoning attacks on unsupervised learning
algorithms. To the best of our knowledge, existing attacks
target a speciﬁc learning algorithm (e.g., hierarchical clus-
tering [9] or graph-based clustering [16]), which are not
directly applicable to our algorithm yet. For adversarial eva-
sion, attackers may leverage transferability and use adversarial
examples generated from a supervised classiﬁer to attack our
method. However, transferability relies on the assumption that
13
supervised classiﬁers on the same problem/data share similar
decision boundaries. In our case, FARE is trained with both
labeled and unlabeled data and uses the ensemble of multiple
algorithms, which may produce different cluster boundaries
(compared with those of the classiﬁer). In addition, generating
realizable adversarial malware example is a challenging task.
It requires the adversarial example to be an executable binary
that preserves the original malicious functions. We leave the
evaluation of FARE’s adversarial robustness to future research.
Corrupted Labels.
In our current threat model, we assume
the provided labels are either missing or coarse-grained. In
Appendix-I, we further tested FARE under corrupted training
labels (i.e., samples mislabeled to the wrong classes). The
results show that FARE’s performance slightly drops as more
labels are corrupted. In practice, there are potential ways to
mitigate the negative effect of corrupted labels. For example,
we could measure the discrepancy between the given labels and
the unsupervised clustering results based on the neighborhood
relationship table. If the difference is unusually large, defend-
ers should further inspect the labels or conservatively apply the
unsupervised version of FARE. We defer the implementation
and evaluation of this idea to future work.
Limitations and Future Works. Our work has a few
limitations. First, we mainly choose clustering algorithms that
are already widely used in the security domain. Some of the
clustering algorithms indeed have drawbacks. For example, we
show that DBSCAN, in certain settings, becomes the computa-
tional bottleneck for FARE. As future work, we want to explore
alternative clustering algorithms that can further accelerate
the system. Second, our system could still under-estimate the
number of true classes when the data is extremely imbalanced.
Future work may investigate other solutions such as down-
sampling large clusters and then run FARE alternatively. Third,
we apply the same weight for all the unsupervised models in
the ensemble to simplify the parameter tuning. It is possible
to further improve FARE’s performance by designing a ﬁne-
tuning strategy for the weights of these unsupervised models.
Fourth, we mainly evaluate the impact of missing classes and
coarse-grained labels in separate experiments. Due to the space
limit, we have added a brief experiment (in Appendix-E) where
both labeling issues are present in the same training dataset.
Finally, we tested and demonstrated FARE’s effectiveness on
three security applications (and one image classiﬁcation task
in Appendix-H). As part of future work, we will validate our
system’s generalizability to other (non-)security applications.
VII. RELATED WORK
Supervised Learning Methods. Traditional supervised learn-
ing methods such as Support Vector Machines (SVMs) and
random forests have long been used to classify malware [43],
[64], [5], [22], [50], detect network intrusions [48], [39], [18],
[63], and identify fraudulent accounts [7], [54], [72]. Recently,
deep learning models have been used for similar purposes [1],
[32], [44]. As is shown in Section §IV, the effectiveness of
these methods decreases signiﬁcantly under low-quality labels.
Semi-supervised Learning Methods. SSL can be trained
with partially labeled data. They are usually composed of an
unsupervised component and a supervised component. The
unsupervised component projects an input sample x to a
hidden representation h and the supervised component predicts
its label y from the hidden representation h [24], [3]. Related
semi-supervised systems include Ladder [59], MixMatch [6],
and ODDS [31]. ODDS uses data augmentation techniques to
train a bot detector with limited labels, but it primarily works in
a binary classiﬁcation setting (and thus does not meet our need
for attack categorization). Ladder [59] is applied for network
intrusion detection, and MixMatch [6] has been tested mainly
on image datasets. As is shown in Section §IV, low-quality
labels in the training data would signiﬁcantly jeopardize the
performance of semi-supervised methods.
Unsupervised Learning Methods. Clustering algorithms
such as K-means [28] and DBSCAN [20] have been applied to
identity and group malware samples [76], [12], [40], network
intrusion events [49], [15], and fraudulent accounts [57],
[62]. However, these methods are not good at handling high-
dimensional inputs due to the “curse of dimensionality” [83].
To overcome this challenge, more advanced techniques such as
DEC [78], [53] and DAGMM [84] use deep neural networks
to learn a desired low-dimensional representation of original
inputs before applying the clustering method. To improve
the stability of clustering, clustering ensemble methods are
proposed, which combine the clustering outputs from mul-
tiple (weak) base models using some consensus functions.
For example, CSPA and HGPA [67], [77] are two popular
clustering ensemble methods. CSPA utilizes the probability of
two data points co-locating in the same cluster as the consensus
measure; HGPA represents the outputs from the base clusters
as a hyper-graph and converts the clustering task into a hyper-
graph partitioning problem. Without the guidance of labels,
unsupervised learning methods are usually outperformed by
semi-supervised learning methods.
Zero-shot Learning Methods. ZSL and GZSL have been
recently used in network intrusion detection tasks [60]. These
methods transfer the knowledge learned from one task to a
second task [24] and can be used to classify previously unseen
classes in the testing set. This is done by learning a feature
mapping function based on the well-labeled data of the ﬁrst
task (training set), and transform the inputs of the second task
(testing set) through the mapping function. As is discussed in
Section §II-C, due to the need of rich training labels and “side
information” to construct
the feature mapping, ZSL/GZSL
methods are not suitable for our problem.
VIII. CONCLUSION
This paper introduces FARE, a new method to derive
accurate and robust clustering results for security applications
under low-quality label data. By computing an ensemble of
“given labels” and multiple supervised learning results, we
use a transformation network to transform input samples
into a low-dimensional space for ﬁne-grained clustering. We
evaluate FARE with both controlled experiments (for malware
classiﬁcation and network intrusion detection) and real-world
deployment and testing (for fraudulent account detection).
We demonstrate the beneﬁts of FARE over existing semi-
supervised methods and its usefulness in practice.
ACKNOWLEDGMENT
We thank anonymous reviewers for their constructive com-
ments and suggestions. This work was supported in part by
NSF grants CNS-2030521 and CNS-1717028.
REFERENCES
[1] D. Arp, M. Spreitzenbarth, M. Hubner, H. Gascon, K. Rieck, and
C. Siemens, “Drebin: Effective and explainable detection of android
malware in your pocket,” in Proc. of NDSS, 2014.
[2] A. Authors,
“Malware
AgWFTItaV0h8jLAcx9dRzqIlMvUWtg?e=O3Gj5q.
dataset,”
2019,
https://1drv.ms/u/s!
[3] S. Becker and G. E. Hinton, “Self-organizing neural network that
discovers surfaces in random-dot stereograms,” Nature, 1992.
[4] A. Bendale and T. E. Boult, “Towards open set deep networks,” in Proc.
of CVPR, 2016.
[5] K. Berlin, D. Slater, and J. Saxe, “Malicious behavior detection using
windows audit logs,” in Proc. of AI & Security Workshop of CCS, 2015.
[6] D. Berthelot, N. Carlini, I. Goodfellow, N. Papernot, A. Oliver, and
C. A. Raffel, “Mixmatch: A holistic approach to semi-supervised
learning,” in Proc. of NeurIPS, 2019.
[7] S. Bhattacharyya, S. Jha, K. Tharakunnel, and J. C. Westland, “Data
mining for credit card fraud: A comparative study,” Decision Support
Systems, 2011.
[8] S. Bickel, M. Br¨uckner, and T. Scheffer, “Discriminative learning under
covariate shift.” Journal of Machine Learning Research (JMLR), 2009.
[9] B. Biggio, S. R. Bul`o, I. Pillai, M. Mura, E. Z. Mequanint, M. Pelillo,
and F. Roli, “Poisoning complete-linkage hierarchical clustering,” in
Proc. of SPR and SSPR, 2014.
[10] Y. Boshmaf, D. Logothetis, G. Siganos, J. Leria, J. Lorenzo, M. Ri-
peanu, and K. Beznosov, “Integro: Leveraging victim prediction for
robust fake account detection in osns,” in Proc. of NDSS, 2015.
[11] L. Buitinck, G. Louppe, M. Blondel, F. Pedregosa, A. Mueller,
O. Grisel, V. Niculae, P. Prettenhofer, A. Gramfort, J. Grobler et al.,
“API design for machine learning software: experiences from the scikit-
learn project,” in ECML-PKDD Workshop: Languages for Data Mining
and Machine Learning, 2013.
I. Burguera, U. Zurutuza, and S. Nadjm-Tehrani, “Crowdroid: behavior-
based malware detection system for android,” in Proc. of ACM workshop
on Security and privacy in smartphones and mobile devices, 2011.
[12]
[13] Q. Cao, M. Sirivianos, X. Yang, and T. Pregueiro, “Aiding the detection
of fake accounts in large scale social online services,” in Proc. of
USENIX NSDI, 2012.
[14] Q. Cao, X. Yang, J. Yu, and C. Palow, “Uncovering large groups of
active malicious accounts in online social networks,” in Proc. of CCS,
2014.
[15] P. Casas, J. Mazel, and P. Owezarski, “Unsupervised network intrusion
detection systems: Detecting the unknown without knowledge,” Com-
puter Communications, 2012.
[16] Y. Chen, Y. Nadji, A. Kountouras, F. Monrose, R. Perdisci, M. An-
tonakakis, and N. Vasiloglou, “Practical attacks against graph-based
clustering,” in Proc. of CCS, 2017.
[17] Y. Chen, S. Wang, D. She, and S. Jana, “On training robust pdf malware
classiﬁers,” in Proc. of USENIX Security, 2020.
[18] R. Chitrakar and C. Huang, “Selection of candidate support vectors in
incremental svm for network intrusion detection,” computers & security,
2014.
[19] Y. Duan, X. Li, J. Wang, and H. Yin, “Deepbindiff: Learning program-
wide code representations for binary difﬁng,” in Proc. of NDSS, 2018.
[20] M. Ester, H.-P. Kriegel, J. Sander, X. Xu et al., “A density-based
algorithm for discovering clusters in large spatial databases with noise,”
in Proc. of KDD, 1996.
[21] FireEye, “M-trends reports: Insights into today’s breaches and cyber
attacks,” 2020, https://content.ﬁreeye.com/m-trends/rpt-m-trends-2020.
[22] E. Gandotra, D. Bansal, and S. Sofat, “Malware analysis and classiﬁ-
cation: A survey,” Journal of Information Security, 2014.
[23] N. Z. Gong, M. Frank, and P. Mittal, “Sybilbelief: A semi-supervised
learning approach for structure-based sybil detection,” IEEE Transac-
tions on Information Forensics and Security, 2014.
I. Goodfellow, Y. Bengio, and A. Courville, Deep learning. MIT press,
2016.
[24]
14
[25] M. Gowanlock, C. M. Rude, D. M. Blair et al., “Clustering throughput
optimization on the gpu,” in Proc. of IPDPS, 2017.
[26] R. Hadsell, S. Chopra, and Y. LeCun, “Dimensionality reduction by
learning an invariant mapping,” in Proc. of CVPR, 2006.
[27] B. Harkness, “Dealing with fraud and identity theft,” 2019, https://www.
creditcardinsider.com/learn/fraud-identity-theft/.
J. A. Hartigan and M. A. Wong, “A k-means clustering algorithm,”
Journal of the Royal Statistical Society. Series C, 1979.
[28]
[29] Y. He, H. Tan, W. Luo, H. Mao, D. Ma, S. Feng, and J. Fan, “Mr-
dbscan: an efﬁcient parallel density-based clustering algorithm using