to pass the test. The second CAPTCHA algorithm (CT_S) presents 
two  sets  of  images,  with  each  set  containing  three  images  of  the 
same subject, and asks a user to determine if the two sets have the 
same  subject  or  not.  The  third  CAPTCHA  algorithm  (CT_A) 
presents six images, five of the same subject and one of a different 
subject,  and  asks  a  user  to  identify  the  image  of  the  different 
subject. Like Pix and Animal Pix, it is difficult to grade responses 
automatically  for  the  first  CAPTCHA  algorithm,  and  a  random 
guess  would  result  in  a  sufficiently  high  success  rate,  50%  and 
16.67%,  respectively,  for  the  second  and  third  algorithms.  In 
addition,  Google’s 
inaccurate  or 
irrelevant  images.  Manual  selection  may  be  required  to  remove 
bad  images.  The  image  database  would  be  too  small  to  meet  the 
scalability requirement. 
image  search  may  return 
Asirra  [15]  relies  on  the  capability  gap  between  humans  and  bots 
in distinguishing cats and dogs. It asks a user to identify cats out of 
a  set  of  12  photos  of  both  cats  and  dogs.  A  large  database  of 
labeled  images  of  cats  and  dogs  is  needed  to  generate  Asirra 
challenges. Photos of cats and dogs from Petfinder.com are used in 
generating  challenges.  Asirra  is  not  scalable.  Petfinder.com  has 
only a limited number of photos of cats and dogs. New photos are 
added slowly. With a high volume application such as Hotmail, the 
database  is  quickly  exhausted  and  photos  would  have  to  be 
repeated,  allowing  adversaries  to  use  previously  used  photos  of 
cats and dogs to solve a new challenge. 
Website  HotCaptcha.com  applies  a  CAPTCHA  based  on  a  large 
database of labeled photos from HotOrNot.com, a popular Website 
that  invites  users  to  post  their  photos  and  rate  others’  photos  as 
“hot”  or  “not  hot”.  The  CAPTCHA  asks  a  user  to  pick  three  hot 
people from nine photos of people presented to the user. Whether a 
person is hot or not is subjective and culture-dependent. Different 
people may give different answers. In addition, the success rate by 
or  1.19%,  may  be 
a  random  guess,  which  is  at  least  1  in 
=C
84
3
9
sufficiently high that renders the CAPTCHA not suitable for many 
applications such as anti-spam for a free Web email service. 
A recent proposal [16] (Orientation) is to exploit the capability gap 
between  bots  and  humans  to  identify  the  orientation  of  an  image. 
A  user  is  asked  to  adjust  a  randomly  rotated  image  to  its  upright 
orientation. A large database of candidate images is needed in this 
CAPTCHA.  To generate such a  database, images returned from a 
Web  search  are  first  obtained;  a  suite  of  automated  orientation 
detectors  is  then  applied  to  remove  those  images  that  can  be  set 
upright by a computer; and finally a social feedback mechanism is 
employed  to  remove  those  images  hard  for  humans  to  set 
orientation.  The  quality  of  this  CAPTCHA  depends  critically  on 
the  quality  of  the  image  labeling  result  from  the  social  feedback 
189 
mechanism.  It  is  unclear  whether  there  exists  an  efficient  social 
feedback  system  that  can  label  a  large  number  of  images  to  meet 
the demand of a large scale application such as Gmail or Hotmail. 
In  addition,  a  random  guess  may  result  in  a  sufficiently  high 
success rate. In a challenge, a user is asked to move a scroll bar to 
adjust the orientation of an image, and the position of the scroll bar 
is  returned  for  evaluation.  The  success  rate  of  a  random  guess 
depends  on  the  tolerance  of  variations  in  setting  the  upright 
orientation by  different  people. The  data  reported  in [16]  indicate 
that the success rate of a random guess when one image is used in 
),  which  is  high  enough  for 
a  challenge  is  4.48%  (= √0.009%
many applications that several images are needed in a challenge.  
య
A  new  CAPTCHA  based  on  3D  object  models  is  recently 
employed  by  Yuniti.com  [22].  This  CAPTCHA  presents  in  a 
challenge three objects generated from a set of 3D object models, 
and asks a user to select the matching object from a list of objects 
for  each  of  the  three  displayed  objects.  A  major  problem  for  this 
CAPTCHA  is  that  it  is  costly  to  generate  a  large  number  of  3D 
objects  for  a  large  scale  application.  It  is  also  possible  for 
adversaries  to  reversely  build  the  3D  models  from  the  objects  in 
used challenges, and then to use these models to find the matching 
objects in the list for the three objects in a new challenge.   
A  video  CAPTCHA  using  labeled  video  clips  from  YouTube  is 
proposed  in  [17].  A  user  is  asked  to  label  the  content  of  a  video 
clip  in  a  challenge.  However,  labeling  content  is  subjective; 
different users may label the same content differently.   
In  the  following  subsections,  we'll  discuss  Asirra,  ARTiFACIAL, 
and IMAGINATION. These are the IRCs that we shall examine in 
more details to learn the lesson why they are successfully attacked.  
Figure 1. (a) 3D wire model. (b) Cylindrical head texture. (c) 
Challenge image. 
ARTiFACIAL  [12]  relies  on  the  capability  gap  between  humans 
and  machines  in  recognizing  a  human  face.  Humans  can  easily 
recognize  a  human  face  even  if  the  face  is  distorted,  partially 
occluded, or under poorly illumination. A face detector, however, 
still  suffers  from  head  orientation,  face  asymmetry,  lighting  and 
shading,  and  cluttered  background  [12].  In  ARTiFACIAL,  a  3D 
head  model  (Figure  1(a))  and  a 512×512  pixel  cylindrical 
texture  map  of  an  arbitrary  person  (Figure  1(b))  are  used  to 
generate  a  unique  human  face  with  random  global  head  rotation, 
scaling,  translation,  and  local  facial  feature  deformations  to  take 
advantage  of  the  head  orientation  and  face  symmetry  limitations. 
The  intensity  of  the  face  region  is  perturbed  to  break  the  face 
symmetry  and  to  simulate  illumination  variances.  Finally,  a 
cluttered  background  is  generated  by  randomly  putting  confusion 
heads  and  facial  features  on  the  image.  A  challenge  image  is 
shown  in  Figure  1(c).  A  user  is  required  to  identify  the  single 
human face in a challenge and click the six facial corners (four eye 
corners  and  two  mouth  corners)  on  the  face  to  pass  a  test.  It  is 
claimed  that  the  success  rate  for  a  bot  to  pass  an  ARTiFACIAL 
test  is  at  most  0.0006%  [12].  A  worth-mentioning  feature  of 
ARTiFACIAL  is  that  in  theory  an  infinite  number  of  challenges 
can be generated [12].   
Figure 2. Challenge images in IMAGINATION: (a) click test, 
(b) annotate test.  
IMAGINATION  [13]  actually  consists  of  two  separate  tests:  a 
click test and an annotation test. The two tests are shown in Figure 
2. In the click test, a distorted composite image tiled with 8 images 
is  presented.  A  user  has  to  click  a  position  close  enough  to  the 
geometric center of any one of the 8 constituent images to pass the 
test. In the annotate test, a distorted image containing a meaningful 
object and cluttering curves is presented. To pass a test, a user has 
to choose the correct label for the image from a list of 15 candidate 
words. Candidate labels used in this test are generated by adopting 
a  WordNet-based  method  to  avoid  ambiguity  and  to  thwart  odd-
one-out  attacks  when  the  correct  choice  is  semantically  different 
from all the others. A random guess of the annotation test results in 
a success rate of 6.67%. 
In generating a challenge image of the click test, the region of the 
challenge  image  is  randomly  partitioned  into  8  non-overlapping 
rectangles.  Each  rectangle  is  filled  with  an  image  randomly 
selected  from  a  database,  scaled  if  necessary.  The  following 
dithering  step  is  then  applied  twice:  the  composite  image  is 
randomly divided into another 8 rectangular regions and the Floyd-
Steinberg  error-diffusion  algorithm  is  applied  to  each  region  with 
independent  dithering  parameters  including  base  colors  (18, 
randomly chosen in RGB space). To further enhance the security, 
a  factor  α  chosen  randomly  in  the  range  of  [0.5,  1.5]  is  used  to 
multiply the spreading quantization error during the dithering. The 
intuition behind this step is to introduce false image boundaries in 
the  composite  image  and  to  blur  the  true  boundaries  in  hopes  of 
making  the  image  region  detection  intractable  by  machines.  The 
resulting  composite  image  is  used  in  the  click  test.  It  is  claimed 
that IMAGINATION is resistant to attacks and friendly to humans 
[13].  
The  IRCs  discussed  above,  together  with  Cortcha  (our novel  IRC 
to be presented in Section 6) are compared in Table 1 against the 
CAPTCHA requirements listed in [12] as well as scalability and if 
manual  work  is  needed  for  the  images  to  be  used  to  generate 
challenges.  The  accuracy  rate  and  solving  time  in  the  column 
“Easy  to  human”  of  the  table,  if  presented,  are  from  the  original 
paper  that  proposes  the  CAPTCHA.  The  success  rate  of  no-effort 
attacks  (random  guess),  if  presented,  is  either  from  the  original 
paper or calculated previously in this section.   
IMAGINATION, 
Based  on  Table  1,  we  determine 
ARTiFACIAL  and  Asirra  are  representative  IRCs  that  worth  a 
close examination. 
that 
IRC 
Bongo 
Pix 
Manual 
work 
No  
Labeling 
Animal Pix 
Labeling 
CT_L 
CT_S 
CT_A 
ARTiFACIAL 
No 
No 
No 
No 
Click: No 
Table 1. Evaluation of existing IRCs and Cortcha 
Easy to 
grade 
Easy to human 
Hard to 
machine 
Univer-
sality 
Resistance to no-
effort attacks 
Scalability 
Secret 
database 
Yes 
No 
Yes 
No 
Yes 
Yes 
Yes 
Yes 
Subjective 
Yes 
Accuracy:76.5% 
Time: 24s 
Yes 
Accuracy: 91% 
Time: 51s 
Accuracy:99.7%Ti
me: 14s 
No 
Yes 
No 
Yes 
No 
No 
Yes 
Yes 
No 
No2 
No 
Yes 
Yes 
No (50%) 
Yes 
No (8.3%) 
Yes 
No (50%) 
No (16.6%) 
No 
No 
No 
No 
No 
No 
Yes 
Yes (3.5E-17) 
Yes 
No 
Yes 
Yes 
Yes 
Yes 
Yes 
No 
Yes 
Yes 
Yes 
Yes 
Yes 
Yes 
IMAGINA-TION 
Annotation: 
Yes 
Accuracy: 85% 
Yes 