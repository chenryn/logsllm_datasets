end
foreach machine m ∈ M do
t S (m, x(t));
vm ← 1
γ ← max(0, vm − 1);
p(m) ← M exp
if p(m) ≤ α then
(cid:16)− T γ2
(cid:17)
T
;
2
end
end
Report machine m as suspicious
TABLE I
SUMMARY OF TERMS.
Term
Suspicious
Failing
Healthy
Precision
Recall (TPR)
False
Rate (FPR)
Positive
Description
machine ﬂagged as having a latent fault
machine failed according to health signal
machine healthy according to health signal
fraction of failing machines out of all suspicious =
Pr(failing | suspicious)
fraction of suspicious out of all failing machines =
Pr(suspicious | failing)
fraction of healthy machines out of all suspicious
= Pr(suspicious | healthy)
IV. EMPIRICAL EVALUATION
We conducted experiments on live, real-world, distributed
services with different characteristics. The LG (“large”) ser-
vice consists of a large cluster (∼ 4500 machines) that is a
part of the index service of a large search engine (Bing). The
PR (“primary”) service runs on a mid-sized cluster (∼ 300
machines) and provides information about previous user inter-
actions for Bing. It holds a large key-value table and supports
reading and writing to this table. The SE (“secondary”) service
is a hot backup for the PR service and is of similar size. It
stores the same table as the PR service but supports only write
requests. Its main goal is to provide hot swap for machines
in the PR service in cases of failures. The VM (“virtual
machine”) service provides a mechanism to collect data about
users’ interactions with advertisements in a large portal. It
stores this information for billing purposes. This service uses
15 virtual machines which share the same physical machine
with other virtual machines. We tracked the LG, PR and SE
services for 60 days and the VM service for 30 days. We chose
periods in which these services did not experience any outage.
These services run on top of a data center management in-
frastructure for deployment of services, monitoring, automatic
repair, and the like [6]. We use the automatic repair log to
deduce information concerning the machines’ health signals.
This infrastructure also collects different performance counters
from both the hardware and the running software, and handles
storage, a common practice in such datacenters. Therefore our
analysis incurs no overheard nor any changes to the monitored
service.
Collected counters fall into a wide range of types: common
OS counters such as the number of threads, memory and CPU
usage, and paging; hardware counters such as disk write rate
and network interface errors; and unique service application
counters such as transaction latency, database merges, and
query rate.
A. Protocol Used in the Experiments
We applied our methods to each service independently
and in a daily cycle. That is, we collected counter values
every 5 minutes during a 24-hour period and used them to
ﬂag suspicious machines using each of the tests. To avoid
overﬁtting, parameters were tuned using the historical data of
the SE service. In order to reduce the false alarm rate to a
minimum, the signiﬁcance level α was ﬁxed at 0.01.
To evaluate test performance, we compared detected latent
faults to machine health signals as reported by the infrastruc-
ture at a later date. Health alerts are raised according to rules
for detecting software and hardware failures. Our hypothesis
is that some latent faults will evolve over time into hard
faults, which will be detected by this rule-based mechanism.
Therefore, we checked the health signal of each machine in
a follow-up period (horizon) of up to 14 days immediately
following the day in which the machine was tested for a latent
fault. We used existing health systems to verify the results of
our latent fault detection framework. In some cases we used
manual inspection of counters and audit logs.
Unfortunately, because of limited sensitivity and missing
logs, health information is incomplete. Failing or malfunc-
tioning machines that the current watchdog based implemen-
tation did not detect are considered by default to be healthy.
Similarly, machines with unreported repair actions or without
health logs are considered by default to be healthy. When
ﬂagged as suspicious by our tests, such machines would be
considered false positives. Finally, not all machine failures
have preceding latent faults, but to avoid any bias we include
all logged health alerts in our evaluation, severely impacting
recall, deﬁned below (Section IV-E estimates the amount
of latent faults). Therefore, the numbers we provide in our
experiments are underestimations, or lower bounds on the true
prevalence of latent faults.
In our evaluation, we refer to machines that were reported
healthy during the follow-up horizon as healthy; other ma-
chines are referred to as failing. Machines that were ﬂagged
by a test are referred to as suspicious. Borrowing from
the information retrieval literature [21], we use precision to
measure the fraction of failing machines out of all suspicious
machines and recall (also called true positive rate, or TPR)
to measure the fraction of suspicious machines out of all
failing machines. We also use the false positive rate (FPR) to
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 07:20:08 UTC from IEEE Xplore.  Restrictions apply. 
PREDICTION ON LG WITH SIGNIFICANCE LEVEL OF 0.01.
TABLE II
Period
1 day
7 days
14 days
Test
Tukey
sign
LOF
Tukey
sign
LOF
Tukey
sign
LOF
Recall
0.240
0.306
0.248
0.151
0.196
0.203
0.093
0.126
0.162
FPR
0.023
0.037
0.095
0.014
0.026
0.087
0.011
0.022
0.082
Precision
0.135
0.109
0.038
0.497
0.411
0.180
0.653
0.563
0.306
Fig. 1. Cumulative failures on LG service. Most of the faults detected by
the sign test and the Tukey test become failures several days after detection.
denote the fraction of healthy machines out of all suspicious
machines. Table I summarizes the terms used.
We applied the same techniques to all services, using the
same choice of parameters. Yet, due to their different nature,
we discuss the results for each service separately.
B. The LG Service
Table II shows a summary of the results (failure predic-
tion) for the LG service. The low false positive rate (FPR)
reﬂects our design choice to minimize false positives. Track-
ing the precision results proves that latent faults abound in
the services. For example, the Tukey method has precision
of 0.135, 0.497 and 0.653 when failures are considered in
horizons of 1, 7 and 14 days ahead, respectively. Therefore,
most of the machines ﬂagged as suspicious by this method
will indeed fail during the next two weeks. Moreover, most of
these failures happen on the second day or later.
The recall numbers in Table II indicate that approximately
20% of the failures in the service were already manifested in
the environment for about a week before they were detected.
The cumulative failure graph (Figure 1) depicts the fraction
across all days of suspicious machines which failed up to n
days after the detection of the latent fault. In other words, it
shows the precision vs. prediction horizon. The “total” line
is the fraction of all machines that failed, demonstrating the
normal state of affairs in the LG service. This column is
equivalent to a guessing “test” that randomly selects suspicious
machines on the basis of the failure probability in the LG
service. Once again, these graphs demonstrate the existence
and prevalence of latent faults.
To explore the tradeoffs between recall, false positive rate,
and precision, and to compare the different methods, we
present receiver operating characteristic (ROC) curves and
precision-recall (P-R) curves. The curves, shown in Figure 2,
were generated by varying the signiﬁcance level: for each
value of α we plot the resulting false positive rate and true
positive rate (recall) as a point on the ROC curve. The closer
to the top-left corner (no false positives with perfect recall),
the better the performance. A random guess would yield a
diagonal line from (0, 0) to (1, 1). The P-R curve is similarly
generated from recall and precision.
Both the Tukey and sign tests successfully predict failures
up to 14 days in advance with a high degree of precision,
with sign having a slight advantage. Both perform signiﬁcantly
better than the LOF test, which is still somewhat successful.
The results reﬂect our design tradeoff: at signiﬁcance level
of 0.01, false positive rates are very low (around 2 − 3% for
Tukey and sign), and precision is relatively high (especially
for longer horizons).
The dips in the beginning of the P-R curves reﬂect machines
that consistently get low p-values, but do not fail. Our manual
investigation of some of these machines shows that they can
be divided into (1) undocumented failures (incomplete or
unavailable logs), and (2) machines that are misconﬁgured or
underperforming, but not failing outright since the services do
not monitor for these conditions. Such machines are consid-
ered false positives, even though they are actually correctly
ﬂagged by our framework as suspicious. This is additional
evidence that the numbers reported in our experiments are
underestimates, and that
latent faults go unnoticed in the
environment. This is also why false positive rates are slightly
higher than the signiﬁcance level of 0.01.
Finally, we investigate the sensitivity of the different meth-
ods to temporal changes in the workload. Since this service is
user facing, the workload changes signiﬁcantly between week-
days and weekends. We plot Tukey prediction performance
with a 14-day horizon for each calendar day (Figure 3). Note
that the weekly cycle does not affect the test. The visible dips
at around days 22, 35, and towards the end of the period,
are due to service upgrades during these times. Since the
machines are not upgraded simultaneously, the test detects any
performance divergence of the different versions and reports
these as failures. However, once the upgrade was completed,
no tuning was necessary for the test to regain its performance.
C. PR and SE Services
The SE service mirrors data written to PR, but serves no
read requests. Its machines are thus less loaded than PR
machines, which serve both read and write requests. Hence,
traditional rule-based monitoring systems are less likely to
detect failures on these machines. The existence of latent
faults on these machines is likely to be detected by the health
mechanisms only when there is a failure in a primary machine,
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 07:20:08 UTC from IEEE Xplore.  Restrictions apply. 
 0 0.1 0.2 0.3 0.4 0.5 0.6 0.71 day2 or less3 or less4 or less5 or less6 or less7 or less8 or less9 or less10 or less11 or less12 or less13 or less14 or less15 or lessFraction failedDays after testTukeysignLOFTotal(a) Tukey test
(b) Sign test
(c) LOF test
Fig. 2. ROC and P-R curves on LG service. Highlighted points are for signiﬁcance level α = 0.01.
PREDICTION ON SE, 14-DAY HORIZON, SIGNIFICANCE LEVEL 0.01.
TABLE III
Test
Tukey
sign
LOF
Recall
0.010
0.023
0.089
FPR
0.007
0.029
0.087
Precision
0.075
0.044
0.054
therefore, latent faults do exist in this service as well, albeit
to a lesser extent. As explained above, since this is a backup
service, some of the failures go unreported to the service
platform. Therefore, the true performance is likely to be better
than shown.
The case of the PR service is similar to the SE service but
even more acute. The number of reported failures is so low
(0.26% machine failures per day) that it would be impossible
to verify positive prediction. Nevertheless, all tests show very
low FPR (about 1% for sign and Tukey, 7% for LOF), and in
over 99% of healthy cases there were no latent faults according
to all tests.
D. VM Service
The VM service presents a greater challenge, due to the
use of virtual machines and the small machine population. In
principle, a test may ﬂag machines as suspicious because of
some artifacts related to other virtual machines sharing the
same host. Due to the small size of this cluster, we resort
to manually examining warning logs, and examining the two
machines with latent faults found by the sign test. One of the
machines had high CPU usage, thread count, disk queue length
and other counters that indicate a large workload, causing our
test to ﬂag it as suspicious. Indeed, two days after detection
there was a watchdog warning indicating that the machine is
Fig. 3. Tukey performance on LG across 60 days, with 14-day horizon. It
shows the test is not affected by changes in the workload, quickly recovering
from service updates on days 22 and 35. Lower performance on days 45–55
is an artifact of gaps in counter logs and updates on later days.
followed by the faulty SE machine being converted to the
primary (PR) role.
Unfortunately,
the health monitors for the PR and SE
services are not as comprehensive as the ones for the LG
service. Since we use the health monitors as the objective
signal against which we measure the performance of our tests,
these measurements are less reliable. To compensate for that,
we manually investigated some of the ﬂagged machines. We
are able to provide objective measurements for the SE service,
as there are enough real failures which can be successfully
predicted, despite at least 30% spurious failures in health logs
(veriﬁed manually).
Performance on SE service for a signiﬁcance level of 0.01 is
summarized in Table III. ROC and P-R curves are in Figure 4.
Our methods were able to detect and predict machine failures;
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 07:20:08 UTC from IEEE Xplore.  Restrictions apply. 
 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1TPR (recall)FPRrand. guess1 day7 days14 daysat cutoff 0.01 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1PrecisionRecall 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1TPR (recall)FPRrand. guess1 day7 days14 daysat cutoff 0.01 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1PrecisionRecall 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1TPR (recall)FPRrand. guess1 day7 days14 daysat cutoff 0.01 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1PrecisionRecall 0 0.2 0.4 0.6 0.8 1 0 10 20 30 40 50 60Calendar dayserviceupdatePrecisionRecallFPRlog gaps(a) Tukey