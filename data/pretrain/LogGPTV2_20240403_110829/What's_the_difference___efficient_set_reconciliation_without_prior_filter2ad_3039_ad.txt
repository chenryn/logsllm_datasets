 50
Set Difference
Set Difference
Figure 5: Rate of successful IBF decoding with 50 cells and 4
hash functions. The ability to decode an IBF scales with the size
of the set difference, not the size of the sets.
Figure 6: Probability of successful decoding for IBF’s with 50
cells for different deltas. We vary the number of hashes used to
assign elements to cells (hash_count) from 2 to 6.
ﬁle pairs. As our objective is set reconciliation, we consider an ex-
periment successful only if we are able to successfully determine
all of the elements in the set difference.
6.1 Tuning the IBF
We start by verifying that IBF size scales with the size of the set
difference and not the total set size. To do so, we generated sets
with 100, 1K, 10K, 100K and 1M keys, and deltas between 0 and
50. We then compute the set difference using an IBF with 50 cells.
Figure 5 shows the success rate for recovering the entire set dif-
ference. We see that for deltas up to 25, the IBF decodes completely
with extremely high probability, regardless of set size. At deltas of
45 and 50 the collision rate is so high that no IBF’s are able to
completely decode. The results in Figure 5 conﬁrm that decoding
success is independent of the original set sizes.
Determining IBF size and number of hash functions. Both
the number of IBF cells and hash_count (the number of times an
element is hashed) are critical in determining the rate of successful
decoding. To evaluate the effect of hash_count, we attempted to
decode sets with 100 keys and deltas between 0 and 50 using an IBF
with 50 cells and hash_count’s between 2 and 6. Since the size
of the sets does not inﬂuence decoding success, these results are
representative for arbitrarily large sets. We ran this conﬁguration
for 1000 pairs of sets and display our results in Figure 6.
For deltas less than 30, hash_count = 4 decodes 100% of the
time, while higher and lower values show degraded success rates.
Intuitively, lower hash counts do not provide equivalent decode
rates since processing each pure cell only removes a key from a
small number of other cells, limiting the number of new pure cells
that may be discovered. Higher values of hash_count avoid this
problem but may also decrease the odds that there will initially be
a pure cell in the IBF. For deltas greater than 30, hash_count
= 3 provides the highest rate of successful decoding. However, at
smaller deltas, 3 hash functions are less reliable than 4, with ap-
proximately 98% success for deltas from 15 to 25 and 92% at 30.
To avoid failed decodings, we must allocate IBF’s with more
than d cells. We determine appropriate memory overheads (ratio of
IBF’s cells to set-difference size) by using sets containing 100K el-
ements and varying the number of cells in each IBF as a proportion
of the delta. We then compute the memory overhead required for
99% of the IBF’s to successfully decode and plot this in Figure 7.
Deltas below 200 all require at least 50% overhead to completely
d
a
e
h
r
e
v
O
e
c
a
p
S
 2.4
 2.2
 2
 1.8
 1.6
 1.4
 1.2
 1
 10
Hash Cnt = 3
Hash Cnt = 4
Hash Cnt = 5
Hash Cnt = 6
 100
 1000
 10000
 100000
Set Difference
Figure 7: We evaluate sets containing 100K elements and plot
the minimum space overhead (IBF cells/delta) required to com-
pletely recover the set difference with 99% certainty.
decode. However, beyond deltas of 1000, the memory overhead
reaches an asymptote. As before, we see a hash_count of 4 de-
codes consistently with less overhead than 5 or 6, but interestingly,
hash_count = 3 has the lowest memory overhead at all deltas
greater than 200.
6.2 Tuning the Strata Estimator
To efﬁciently size our IBF, the Strata Estimator provides an es-
timate for d. If the Strata Estimator over-estimates, the subsequent
IBF will be unnecessarily large and waste bandwidth. However, if
the Strata Estimator under-estimates, then the subsequent IBF may
not decode and cost an expensive transmission of a larger IBF. To
prevent this, the values returned by the estimator should be scaled
up so that under-estimation rarely occurs.
In Figure 8, we report the scaling overhead required for var-
ious strata sizes such that 99% of the estimates will be greater
than or equal to the true difference. Based on our ﬁndings from
Section 6.1, we focus on Strata Estimators whose ﬁxed-size IBF’s
use a hash_count of 4. We see that the scaling overhead drops
sharply as the number of cells per IBF is increased from 10 to 40,
and reaches a point of diminishing returns after 80 cells. With
80 cells per stratum, any estimate returned by a Strata Estimator
d
a
e
h
r
e
v
O
n
o
i
t
c
e
r
r
o
C
 3.5
 3
 2.5
 2
 1.5
 1
Delta = 10
Delta = 100
Delta = 1000
Delta = 10000
Delta = 100000
d
a
e
h
r
e
v
O
n
o
i
t
c
e
r
r
o
C
 2.4
 2.2
 2
 1.8
 1.6
 1.4
 1.2
 1
Strata (16 strata, 80 cells)
Min-wise (3840 hashes)
Hybrid (7 strata, 2160 hashes)
 20
 40
 60
 80
 100
 120
 140
 160
 10
 100
 1000
 10000
 100000
IBF Size (in cells)
Set Difference
Figure 8: Correction overhead needed by the Strata Estimator
to ensure that 99% of the estimates are greater than or equal to
the true value of d when using strata IBF’s of various sizes.
Figure 9: Comparison of estimators when constrained to 15.3
KB. We show the scaling overhead to ensure that 99% of esti-
mates are greater than or equal to the true delta.
should be scaled by a factor of 1.39 to ensure that it will be greater
than or equal to d 99% of the time.
Strata Estimator vs. Min-wise. We next compare our Strata
Estimator to the Min-wise Estimator [3, 4] (see Section 2). For our
comparison we used sets with 100K elements and deltas ranging
from 10 to 100K. Given knowledge of the approximate total set
sizes a priori, the number of strata in the Strata estimator can be
adjusted to conserve communication costs by only including parti-
tions that are likely to contain elements from the difference. Thus,
we choose the number of strata to be ⌊log2(dmax)⌋, where dmax
is the largest possible difference. Since our largest delta is 100K,
we conﬁgure our estimator with 16 strata, each containing 80 cells
per IBF. At 12 bytes per IBF cell, this conﬁguration requires ap-
proximately 15.3 KB of space. Alternatively, one could allocate a
Min-wise estimator with 3840 4-byte hashes in the same space.
In Figure 9, we compare the scaling overhead required such that
99% of the estimates from Strata and Min-wise estimators of the
same size are greater than or equal to the true delta. We see that
the overhead required by Min-wise diminishes from 1.35 to 1.0
for deltas beyond 2000. Strata requires correction between 1.33 to
1.39 for the same range. However, the accuracy of the Min-wise
estimator deteriorates rapidly for smaller delta values. In fact, for
all deltas below 200, the 1st percentile of Min-wise estimates are
0, resulting in inﬁnite overhead. Min-wise’s inaccuracy for small
deltas is expected as few elements from the difference will be in-
cluded in the estimator as the size of the difference shrinks. This
makes Min-wise very sensitive to any variance in the sampling pro-
cess, leading to large estimation errors. In contrast, we see that the
Strata Estimator provides reasonable estimates for all delta values
and is particularly good at small deltas, where scaling overheads
range between 1.0 and 1.33.
Hybrid Estimator. The Strata Estimator outperforms Min-wise
for small differences, while the opposite occurs for large differ-
ences. This suggests the creation of a hybrid estimator that keeps
the lower strata to accurately estimate small deltas, while augment-
ing more selective strata with a single Min-wise estimator. We par-
tition our set as before, but if a strata does not exist for a partition,
we insert its elements into the Min-wise estimator. Estimates are
performed by summing strata as before, but also by including the
number of differences that Min-wise estimates to be in its partition.
For our previous Strata conﬁguration of 80 cells per IBF, each
strata consumes 960 bytes. Therefore, we can trade a strata for 240
additional Min-wise hashes. From Figure 9 we see that the Strata
Estimator performs better for deltas under 2000. Thus, we would
like to keep at most ⌊log2(2000)⌋ = 10 strata. Since we expect
the most selective strata to contain few elements for a difference
of 2000, we are better served by eliminating them and giving more
space to Min-wise. Hence, we retain 7 strata, and use the remaining
8640 bytes to allocate a Min-wise estimator with 2160 hashes.
Results from our Hybrid Estimator are plotted in Figure 9 with
the results from the Strata and Min-wise estimators. We see that
the Hybrid Estimator closely follows the results of the Strata Esti-
mator for all deltas up to 2000, as desired. For deltas greater than
2000, the inﬂuence of errors from both Strata and Min-wise cause
the scaling overhead of the Hybrid estimator to drift up to 1.45
(versus 1.39% for Strata), before it progressively improves in ac-
curacy, with perfect precision at 100K. While the Hybrid Estimator
slightly increase our scaling overhead from 1.39 to 1.45 (4.3%), it
also provides improved accuracy at deltas larger than 10% where
over-estimation errors can cause large increases in total data sent.
Difference Digest Conﬁguration Guideline. By using the Hy-
brid Estimator in the ﬁrst phase, we achieve an estimate greater than
or equal to the true difference size 99% of the time by scaling the
result by 1.45. In the second phase, we further scale by 1.25 to 2.3
and set hash_count to either 3 or 4 depending on the estimate
from phase one. In practice, a simple rule of thumb is to construct
an IBF in Phase 2 with twice the number of cells as the estimated
difference to account for both under-estimation and IBF decoding
overheads. For estimates greater than 200, 3 hashes should be used
and 4 hashes otherwise.
6.3 Difference Digest vs. Prior Work
We now compare Difference Digests to Approximate Recon-
ciliation Trees (ART) [5], Characteristic Polynomial Interpolation
(CPISync) [17], and simply trading a sorted list of keys (List).
We note that ART’s were originally designed to compute most but
not all the keys in SA − SB. To address this, the system built
in [5] used erasure coding techniques to ensure that hosts received
pertinent data. While this approach is reasonable for some P2P
applications it may not be applicable to or desirable for all applica-
tions described in Section 1. In contrast, CPISync and List are
always able to recover the set difference.
Figure 10 shows the data overhead required by the four algo-
rithms. Given that ART’s were not designed for computing the
List
ART
CPISync
D.Digest
 500
 400
 300
 200
 100
s
e
t
y
B
K
 0
 10
 100
 1000
 10000
 100000
Set Difference
Figure 10: Data transmission required to reconcile sets with
100K elements. We show the space needed by ART and Differ-
ence Digests to recover 95% and 100% of the set difference,
respectively, with 99% reliability.
complete set difference, we arbitrarily choose the standard of 95%
of the difference 99% of the time and plot the amount of data re-
quired to achieve this level of performance with ART. For CPISync,
we show the data overhead needed to recover the set difference. In
practice, the basic algorithm must be run with knowledge of the
difference size, or an interactive approach must be used at greater
computation and latency costs. Hence, we show the best case over-
head for CPISync. Finally, we plot the data used by Difference
Digest for both estimation and reconciliation to compute the com-
plete difference 99% of the time.
The results show that the bandwidth required by List and ART
decreases as the size of the difference increases. This is intuitive
since both List and the ART encode the contents of SB, which
is diminishing in size as the size of the difference grows (|SB| =
|SA| − |D|). However, ART outperforms List since its compact
representation requires fewer bits to capture the nodes in B.
While the size of the Hybrid Estimator stays constant, the IBF
grows at an average rate of 24 Bytes (three 4-byte values and a
factor of 2 inﬂation for accurate decoding) per key in the differ-
ence. We see that while Difference Digests and CPISync have the
same asymptotic communication complexity, CPISync requires
less memory in practice at approximately 10 bytes per element in
the difference.
Algorithm Selection Guidelines. The results show that for small
differences, Difference Digests and CPISync require an order of
magnitude less bandwidth that ART and are better up to a differ-
ence of 4,000 (4%) and 10,000 (10%), respectively. However, the
fact that ART uses less space for large deltas is misleading since we
have allowed ART to decode only 95% of the difference. CPISync
provides the lowest bandwidth overhead and decodes deterministi-
cally, making it a good choice when differences are small and band-
width is precious. However, as we discuss next, its computational
overhead is substantial.
6.4 KeyDiff Performance
We now examine the beneﬁts of Difference Digest in system-
level benchmarks using KeyDiff service described in Section 5.
We quantify the performance of KeyDiff using Difference Digests
versus ART, CPISync, and List. For these experiments, we
deployed KeyDiff on two dual-processor quad-core Xeon servers
running Linux 2.6.32.8. Our test machines were connected via 10
Gbps Ethernet and report an average RTT of 93µs.
Computational Overhead. In the KeyDiff model, the applica-
tions at the client and server both add keys to KeyDiff. When diff
is called the client requests the appropriate data from the server to
compute the set difference. We begin by evaluating the computa-
tion time required to add new keys to KeyDiff and the time required
by the server to generate its response when using each algorithm.
For this experiment, we added 1 million keys to the KeyDiff server
then requested a structure to decode a difference of 100. In Table 1,
we show the average time required for these operations.
For adding new keys, we see that List and ART are slower than
both CPISync and IBF since both perform log(|S|) operations
— the List to do an ordered insertion, and ART to update hashes
along a path in its tree.
In contrast, CPISync and IBF simply
store the new keys to an unordered list until they learn the size of
the structure to build from the client’s request.
For server compute time, we note that the latencies correspond
closely with the number of memory locations each algorithm touches.
List is quickest at 6.545 msec, as the server only needs to read
and serialize the keys. In contrast, IBF and CPISync must allo-
cate and populate appropriately-sized structures by scanning their
stored lists of keys. For IBF this requires updating 4 cells per key,
while CPISync must evaluate 100 linear equations, each involv-
ing all 1M keys. The time for ART is roughly twice that of IBF
as it must traverse its tree containing 2|S| nodes, to build a Bloom
Filter representation of its set.
At the bottom of Table 1, we show the add and server-compute
times for the three estimation algorithms. Note that since the length
of the IBF’s in the Strata and Hybrid estimators are static, they can
be updated online. We also note that although the Hybrid estimator
maintains 2160 Min-wise hash values, its addition times are sig-
niﬁcantly lower that the original Min-wise estimator. This occurs
because the Min-wise structure in the Hybrid estimator only sam-
ples the elements not assigned to one of the seven strata. Thus,