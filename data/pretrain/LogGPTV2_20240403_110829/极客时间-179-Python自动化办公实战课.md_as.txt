# 负向评价数量:2通过 snownlp 库配合 jieba分词的结果，你就可以实现批量产品评论的自动语义情感分析了。同时，你还可以根据不断累积产品的评价，来持续优化你的产品。小结最后，我来为你总结一下对文件进行情感倾向分析的关键步骤和注意事项。实现语义情感分析功能，你必须掌握分词、优化分词结果、语义情感分析这三个步骤。其中分词是实现中文语义分析的第一步，也是最基础的部分。分词的好坏决定了对每个词的情感进行标注的准确程度。如果默认的jieba 分词没有正确地把词语划分，你也可以使用 jieba 自带的 suggest_freq()函数进行词频调节。举个小例子，"中""将"两个字可以组成"中将"的词语，也可以拆开来用"我们中/将有人成功考上北大"。在不同的语言环境中，我们要通过词频调节来让它们以词的形式出现，还是以两个字的方式出现。调整的方法是：    jieba.suggest_freq(("中", "将"), tune = True)可以看到，利用调节词频使"中""将"都能被分出来，而不会被错误地识别为一个词"中将"，通过这种方式，就可以提升jieba 的识别正确率。在优化分词结果这一步，你可以通过减少虚词和标点符号，通过停止词、词性的选择，来降低它们对情感分析结果的干扰。最后，你还可以为 snownlp增加新的流行词和网络用语，帮你更准确地分析用户对产品的喜好程度，从而提高产品定位的精确度。在 snownlp 中，通过 train() 和 save()两个函数把模型训练和保存之后，就能实现扩展默认字典的功能了。此外，我在工作中还会利用这种方式增加emoji 表情对应的情感倾向分析功能，以此来进一步提升 snownlp分析情感倾向的准确度。我将训练模型和保存训练后的模型的函数也写在这里供你参考，希望通过训练自己的模型，能够让你的产品分析更加准确。    sentiment.train(neg2.txt,pos2.txt);  
#   训练用户自定义正负情感数据集    sentiment.save('sentiment2.marshal');  
# 保存训练模型今天用到的代码，我都放在了 GitHub上，你可以点击这个链接slate-object="inline"查看。思考题我给你留一道思考题，我在最后一段代码分别统计了正向和负向评价的数量，你能否根据这段代码统计一段文字中包含了多少个动词、多少个名词和多少个形容词呢？欢迎你在课程评论区留言，和我一起讨论。