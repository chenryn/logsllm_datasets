将企业应用介绍移到本书最后并更新了内容（第19章）；
增加了对Hadoop安装和代码执行的集中介绍（附录B）。
本书面向的读者
在编写本书时，笔者力图使不同背景、职业和层次的读者都能从这本书中获益。
如果你是专业技术人员，本书将带领你深入云计算的世界，全面掌握Hadoop及其相关技术细节，帮助你使用Hadoop技术解决当前面临的问题。
如果你是系统架构人员，本书将成为你搭建Hadoop集群、管理集群，并迅速定位和解决问题的工具书。
如果你是高等院校计算机及相关专业的学生，本书将为你在课堂之外了解最新的IT技术打开了一扇窗户，帮助你拓宽视野，完善知识结构，为迎接未来的挑战做好知识储备。
在学习本书之前，大家应该具有如下的基础：
要有一定的分布式系统的基础知识，对文件系统的基本操作有一定的了解。
要有一定的Linux操作系统的基础知识。
有较好的编程基础和阅读代码的能力，尤其是要能够熟练使用Java语言。
对数据库、数据仓库、系统监控，以及网络爬虫等知识最好也能有一些了解。
如何阅读本书
从整体内容上讲，本书包括19章和4个附录。前10章、第18章、第19章和4个附录主要介绍了Hadoop背景知识、Hadoop集群安装和代码执行、MapReduce机制及编程知识、HDFS实现细节及管理知识、Hadoop应用。第11章至第17章结合最新版本详细介绍了与Hadoop相关的其他项目，分别为Hive、HBase、Mahout、Pig、ZooKeeper、Avro、Chukwa，以备读者扩展知识面之用。
在阅读本书时，笔者建议大家先系统地学习Hadoop部分的理论知识（第1章、第3章、第6章至第10章），这样可对Hadoop的核心内容和实现机制有一个很好的理解。在此基础上，读者可进一步学习Hadoop部分的实践知识（第2章、第4章、第5章、第18章、第19章和4个附录），尝试搭建自己的Hadoop集群，编写并运行自己的MapReduce代码。对于本书中关于Hadoop相关项目的介绍，大家可以有选择地学习。在内容的编排上，各章的知识点是相对独立的，是并行的关系，因此大家可以有选择地进行学习。当然，如果时间允许，还是建议大家系统地学习全书的内容，这样能够对Hadoop系统的机制有一个完整而系统的理解，为今后深入地研究和实践Hadoop及云计算技术打下坚实的基础。
另外，笔者希望大家在学习本书时能一边阅读，一边根据书中的指导动手实践，亲自实践本书中所给出的编程范例。例如，先搭建一个自己的云平台，如果条件受限，可以选择伪分布的方式。
在线资源及勘误
在本书的附录中，提供了一个基于Hadoop的云计算在线测试平台（http：//cloud-computing.ruc.edu.cn），大家可以先注册一个免费账户，然后即可体验Hadoop平台，通过该平台大家可在线编写MapReduce应用并进行自动验证。如果大家希望获得该平台的验证码，或者希望获得完全编程测试和理论测试的权限，请发邮件到PI:EMAIL。读者也可访问Hadoop的官方网站（hadoop.apache.org）阅读官方介绍文档，下载学习示例代码。
在本书的撰写和相关技术的研究中，尽管笔者投入了大量的精力、付出了艰辛的努力，但是受知识水平所限，书中存在不足和疏漏之处在所难免，恳请大家批评指正。如果有任何问题和建议，可发送电子邮件至PI:EMAIL或PI:EMAIL。
致谢
在本书的编写过程中，很多Hadoop方面的实践者和研究者做了大量的工作，他们是冯博亮、程明、徐文韬、张林林、朱俊良、许翔、陈东伟、谭果、林春彬等，在此表示感谢。
陆嘉恒
2012年6月于北京
第1章 Hadoop简介
本章内容
什么是Hadoop
Hadoop项目及其结构
Hadoop体系结构
Hadoop与分布式开发
Hadoop计算模型—MapReduce
Hadoop数据管理
Hadoop集群安全策略
本章小结
1.1 什么是Hadoop
 1.1.1 Hadoop概述
Hadoop是Apache软件基金会旗下的一个开源分布式计算平台。以Hadoop分布式文件系统（Hadoop Distributed File System, HDFS）和MapReduce（Google MapReduce的开源实现）为核心的Hadoop为用户提供了系统底层细节透明的分布式基础架构。HDFS的高容错性、高伸缩性等优点允许用户将Hadoop部署在低廉的硬件上，形成分布式系统；MapReduce分布式编程模型允许用户在不了解分布式系统底层细节的情况下开发并行应用程序。所以用户可以利用Hadoop轻松地组织计算机资源，从而搭建自己的分布式计算平台，并且可以充分利用集群的计算和存储能力，完成海量数据的处理。经过业界和学术界长达10年的锤炼，目前的Hadoop 1.0.1已经趋于完善，在实际的数据处理和分析任务中担当着不可替代的角色。
1.1.2 Hadoop的历史
Hadoop的源头是Apache Nutch，该项目始于2002年，是Apache Lucene的子项目之一。2004年，Google在“操作系统设计与实现”（Operating System Design and Implementation, OSDI）会议上公开发表了题为MapReduce：Simplifed Data Processing on Large Clusters（《MapReduce：简化大规模集群上的数据处理》）的论文之后，受到启发的Doug Cutting等人开始尝试实现MapReduce计算框架，并将它与NDFS（Nutch Distributed File System）结合，用以支持Nutch引擎的主要算法。由于NDFS和MapReduce在Nutch引擎中有着良好的应用，所以它们于2006年2月被分离出来，成为一套完整而独立的软件，并命名为Hadoop。到了2008年年初，Hadoop已成为Apache的顶级项目，包含众多子项目。它被应用到包括Yahoo！在内的很多互联网公司。现在的Hadoop1.0.1版本已经发展成为包含HDFS、MapReduce子项目，与Pig、ZooKeeper、Hive、HBase等项目相关的大型应用工程。
1.1.3 Hadoop的功能与作用
我们为什么需要Hadoop呢？众所周知，现代社会的信息增长速度很快，这些信息中又积累着大量数据，其中包括个人数据和工业数据。预计到2020年，每年产生的数字信息中将会有超过1/3的内容驻留在云平台中或借助云平台处理。我们需要对这些数据进行分析处理，以获取更多有价值的信息。那么我们如何高效地存储管理这些数据、如何分析这些数据呢？这时可以选用Hadoop系统。在处理这类问题时，它采用分布式存储方式来提高读写速度和扩大存储容量；采用MapReduce整合分布式文件系统上的数据，保证高速分析处理数据；与此同时还采用存储冗余数据来保证数据的安全性。
Hadoop中的HDFS具有高容错性，并且是基于Java语言开发的，这使得Hadoop可以部署在低廉的计算机集群中，同时不限于某个操作系统。Hadoop中HDFS的数据管理能力、MapReduce处理任务时的高效率以及它的开源特性，使其在同类分布式系统中大放异彩，并在众多行业和科研领域中被广泛应用。
1.1.4 Hadoop的优势
Hadoop是一个能够让用户轻松架构和使用的分布式计算平台。用户可以轻松地在Hadoop上开发运行处理海量数据的应用程序。它主要有以下几个优点：
高可靠性。Hadoop按位存储和处理数据的能力值得人们信赖。
高扩展性。Hadoop是在可用的计算机集簇间分配数据完成计算任务的，这些集簇可以方便地扩展到数以千计的节点中。
高效性。Hadoop能够在节点之间动态地移动数据，以保证各个节点的动态平衡，因此其处理速度非常快。
高容错性。Hadoop能够自动保存数据的多份副本，并且能够自动将失败的任务重新分配。
1.1.5 Hadoop应用现状和发展趋势
由于Hadoop优势突出，基于Hadoop的应用已经遍地开花，尤其是在互联网领域。Yahoo！通过集群运行Hadoop，用以支持广告系统和Web搜索的研究；Facebook借助集群运行Hadoop来支持其数据分析和机器学习；搜索引擎公司百度则使用Hadoop进行搜索日志分析和网页数据挖掘工作；淘宝的Hadoop系统用于存储并处理电子商务交易的相关数据；中国移动研究院基于Hadoop的“大云”（BigCloud）系统对数据进行分析并对外提供服务。
2008年2月，作为Hadoop最大贡献者的Yahoo！构建了当时最大规模的Hadoop应用。他们在2000个节点上面执行了超过1万个Hadoop虚拟机器来处理超过5PB的网页内容，分析大约1兆个网络连接之间的网页索引资料。这些网页索引资料压缩后超过300TB。Yahoo！正是基于这些为用户提供了高质量的搜索服务。
Hadoop目前已经取得了非常突出的成绩。随着互联网的发展，新的业务模式还将不断涌现，Hadoop的应用也会从互联网领域向电信、电子商务、银行、生物制药等领域拓展。相信在未来，Hadoop将会在更多的领域中扮演幕后英雄，为我们提供更加快捷优质的服务。
1.2 Hadoop项目及其结构
现在Hadoop已经发展成为包含很多项目的集合。虽然其核心内容是MapReduce和Hadoop分布式文件系统，但与Hadoop相关的Common、Avro、Chukwa、Hive、HBase等项目也是不可或缺的。它们提供了互补性服务或在核心层上提供了更高层的服务。图1-1是Hadoop的项目结构图。
下面将对Hadoop的各个关联项目进行更详细的介绍。
图 1-1 Hadoop项目结构图
1）Common：Common是为Hadoop其他子项目提供支持的常用工具，它主要包括FileSystem、RPC和串行化库。它们为在廉价硬件上搭建云计算环境提供基本的服务，并且会为运行在该平台上的软件开发提供所需的API。
2）Avro：Avro是用于数据序列化的系统。它提供了丰富的数据结构类型、快速可压缩的二进制数据格式、存储持久性数据的文件集、远程调用RPC的功能和简单的动态语言集成功能。其中代码生成器既不需要读写文件数据，也不需要使用或实现RPC协议，它只是一个可选的对静态类型语言的实现。
Avro系统依赖于模式（Schema），数据的读和写是在模式之下完成的。这样可以减少写入数据的开销，提高序列化的速度并缩减其大小；同时，也可以方便动态脚本语言的使用，因为数据连同其模式都是自描述的。
在RPC中，Avro系统的客户端和服务端通过握手协议进行模式的交换，因此当客户端和服务端拥有彼此全部的模式时，不同模式下相同命名字段、丢失字段和附加字段等信息的一致性问题就得到了很好的解决。
3）MapReduce：MapReduce是一种编程模型，用于大规模数据集（大于1TB）的并行运算。映射（Map）、化简（Reduce）的概念和它们的主要思想都是从函数式编程语言中借鉴而来的。它极大地方便了编程人员—即使在不了解分布式并行编程的情况下，也可以将自己的程序运行在分布式系统上。MapReduce在执行时先指定一个Map（映射）函数，把输入键值对映射成一组新的键值对，经过一定处理后交给Reduce, Reduce对相同key下的所有value进行处理后再输出键值对作为最终的结果。
图1-2是MapReduce的任务处理流程图，它展示了MapReduce程序将输入划分到不同的Map上、再将Map的结果合并到Reduce、然后进行处理的输出过程。详细介绍请参考本章1.3节。
图 1-2 MapReduce的任务处理流程图
4）HDFS：HDFS是一个分布式文件系统。因为HDFS具有高容错性（fault-tolerent）的特点，所以它可以设计部署在低廉（low-cost）的硬件上。它可以通过提供高吞吐率（high throughput）来访问应用程序的数据，适合那些有着超大数据集的应用程序。HDFS放宽了对可移植操作系统接口（POSIX, Portable Operating System Interface）的要求，这样可以实现以流的形式访问文件系统中的数据。HDFS原本是开源的Apache项目Nutch的基础结构，最后它却成为了Hadoop基础架构之一。
以下几个方面是HDFS的设计目标：
检测和快速恢复硬件故障。硬件故障是计算机常见的问题。整个HDFS系统由数百甚至数千个存储着数据文件的服务器组成。而如此多的服务器则意味着高故障率，因此，故障的检测和快速自动恢复是HDFS的一个核心目标。
流式的数据访问。HDFS使应用程序流式地访问它们的数据集。HDFS被设计成适合进行批量处理，而不是用户交互式处理。所以它重视数据吞吐量，而不是数据访问的反应速度。
简化一致性模型。大部分的HDFS程序对文件的操作需要一次写入，多次读取。一个文件一旦经过创建、写入、关闭就不需要修改了。这个假设简化了数据一致性问题和高吞吐量的数据访问问题。
通信协议。所有的通信协议都是在TCP/IP协议之上的。一个客户端和明确配置了端口的名字节点（NameNode）建立连接之后，它和名字节点的协议便是客户端协议（Client Protocal）。数据节点（DataNode）和名字节点之间则用数据节点协议（DataNode Protocal）。
关于HDFS的具体介绍请参考本章1.3节。
5）Chukwa：Chukwa是开源的数据收集系统，用于监控和分析大型分布式系统的数据。Chukwa是在Hadoop的HDFS和MapReduce框架之上搭建的，它继承了Hadoop的可扩展性和健壮性。Chukwa通过HDFS来存储数据，并依赖MapReduce任务处理数据。Chukwa中也附带了灵活且强大的工具，用于显示、监视和分析数据结果，以便更好地利用所收集的数据。
6）Hive：Hive最早是由Facebook设计的，是一个建立在Hadoop基础之上的数据仓库，它提供了一些用于对Hadoop文件中的数据集进行数据整理、特殊查询和分析存储的工具。Hive提供的是一种结构化数据的机制，它支持类似于传统RDBMS中的SQL语言的查询语言，来帮助那些熟悉SQL的用户查询Hadoop中的数据，该查询语言称为Hive QL。与此同时，传统的MapReduce编程人员也可以在Mapper或Reducer中通过Hive QL查询数据。Hive编译器会把Hive QL编译成一组MapReduce任务，从而方便MapReduce编程人员进行Hadoop系统开发。
7）HBase：HBase是一个分布式的、面向列的开源数据库，该技术来源于Google论文《Bigtable：一个结构化数据的分布式存储系统》。如同Bigtable利用了Google文件系统（Google File System）提供的分布式数据存储方式一样，HBase在Hadoop之上提供了类似于Bigtable的能力。HBase不同于一般的关系数据库，原因有两个：其一，HBase是一个适合于非结构化数据存储的数据库；其二，HBase是基于列而不是基于行的模式。HBase和Bigtable使用相同的数据模型。用户将数据存储在一个表里，一个数据行拥有一个可选择的键和任意数量的列。由于HBase表是疏松的，用户可以为行定义各种不同的列。HBase主要用于需要随机访问、实时读写的大数据（Big Data）。具体介绍请参考第12章。
8）Pig：Pig是一个对大型数据集进行分析、评估的平台。Pig最突出的优势是它的结构能够经受住高度并行化的检验，这个特性使得它能够处理大型的数据集。目前，Pig的底层由一个编译器组成，它在运行的时候会产生一些MapReduce程序序列，Pig的语言层由一种叫做Pig Latin的正文型语言组成。有关Pig的具体内容请参考第14章。
9）ZooKeeper：ZooKeeper是一个为分布式应用所设计的开源协调服务。它主要为用户提供同步、配置管理、分组和命名等服务，减轻分布式应用程序所承担的协调任务。ZooKeeper的文件系统使用了我们所熟悉的目录树结构。ZooKeeper是使用Java编写的，但是它支持Java和C两种编程语言。有关ZooKeeper的具体内容请参考第15章。
上面讨论的9个项目在本书中都有相应的章节进行详细的介绍。
1.3 Hadoop体系结构
如上文所说，HDFS和MapReduce是Hadoop的两大核心。而整个Hadoop的体系结构主要是通过HDFS来实现分布式存储的底层支持的，并且它会通过MapReduce来实现分布式并行任务处理的程序支持。
下面首先介绍HDFS的体系结构。HDFS采用了主从（Master/Slave）结构模型，一个HDFS集群是由一个NameNode和若干个DataNode组成的。其中NameNode作为主服务器，管理文件系统的命名空间和客户端对文件的访问操作；集群中的DataNode管理存储的数据。HDFS允许用户以文件的形式存储数据。从内部来看，文件被分成若干个数据块，而且这若干个数据块存放在一组DataNode上。NameNode执行文件系统的命名空间操作，比如打开、关闭、重命名文件或目录等，它也负责数据块到具体DataNode的映射。DataNode负责处理文件系统客户端的文件读写请求，并在NameNode的统一调度下进行数据块的创建、删除和复制工作。图1-3所示为HDFS的体系结构。
图 1-3 HDFS体系结构图
NameNode和DataNode都可以在普通商用计算机上运行。这些计算机通常运行的是GNU/Linux操作系统。HDFS采用Java语言开发，因此任何支持Java的机器都可以部署NameNode和DataNode。一个典型的部署场景是集群中的一台机器运行一个NameNode实例，其他机器分别运行一个DataNode实例。当然，并不排除一台机器运行多个DataNode实例的情况。集群中单一NameNode的设计大大简化了系统的架构。NameNode是所有HDFS元数据的管理者，用户需要保存的数据不会经过NameNode，而是直接流向存储数据的DataNode。
接下来介绍MapReduce的体系结构。MapReduce是一种并行编程模式，利用这种模式软件开发者可以轻松地编写出分布式并行程序。在Hadoop的体系结构中，MapReduce是一个简单易用的软件框架，基于它可以将任务分发到由上千台商用机器组成的集群上，并以一种可靠容错的方式并行处理大量的数据集，实现Hadoop的并行任务处理功能。MapReduce框架是由一个单独运行在主节点的JobTracker和运行在每个集群从节点的TaskTracker共同组成的。主节点负责调度构成一个作业的所有任务，这些任务分布在不同的从节点上。主节点监控它们的执行情况，并且重新执行之前失败的任务；从节点仅负责由主节点指派的任务。当一个Job被提交时，JobTracker接收到提交作业和其配置信息之后，就会将配置信息等分发给从节点，同时调度任务并监控TaskTracker的执行。
从上面的介绍可以看出，HDFS和MapReduce共同组成了Hadoop分布式系统体系结构的核心。HDFS在集群上实现了分布式文件系统，MapReduce在集群上实现了分布式计算和任务处理。HDFS在MapReduce任务处理过程中提供了对文件操作和存储等的支持，MapReduce在HDFS的基础上实现了任务的分发、跟踪、执行等工作，并收集结果，二者相互作用，完成了Hadoop分布式集群的主要任务。
1.4 Hadoop与分布式开发
我们通常所说的分布式系统其实是分布式软件系统，即支持分布式处理的软件系统。它是在通信网络互联的多处理机体系结构上执行任务的系统，包括分布式操作系统、分布式程序设计语言及其编译（解释）系统、分布式文件系统和分布式数据库系统等。Hadoop是分布式软件系统中文件系统层的软件，它实现了分布式文件系统和部分分布式数据库系统的功能。Hadoop中的分布式文件系统HDFS能够实现数据在计算机集群组成的云上高效的存储和管理，Hadoop中的并行编程框架MapReduce能够让用户编写的Hadoop并行应用程序运行得以简化。下面简单介绍一下基于Hadoop进行分布式并发编程的相关知识，详细的介绍请参看后面有关MapReduce编程的章节。
Hadoop上并行应用程序的开发是基于MapReduce编程模型的。MapReduce编程模型的原理是：利用一个输入的key/value对集合来产生一个输出的key/value对集合。MapReduce库的用户用两个函数来表达这个计算：Map和Reduce。
用户自定义的Map函数接收一个输入的key/value对，然后产生一个中间key/value对的集合。MapReduce把所有具有相同key值的value集合在一起，然后传递给Reduce函数。用户自定义的Reduce函数接收key和相关的value集合。Reduce函数合并这些value值，形成一个较小的value集合。一般来说，每次调用Reduce函数只产生0或1个输出的value值。通常我们通过一个迭代器把中间value值提供给Reduce函数，这样就可以处理无法全部放入内存中的大量的value值集合了。
图1-4是MapReduce的数据流图，体现MapReduce处理大数据集的过程。简而言之，这个过程就是将大数据集分解为成百上千个小数据集，每个（或若干个）数据集分别由集群中的一个节点（一般就是一台普通的计算机）进行处理并生成中间结果，然后这些中间结果又由大量的节点合并，形成最终结果。图1-4也说明了MapReduce框架下并行程序中的两个主要函数：Map、Reduce。在这个结构中，用户需要完成的工作是根据任务编写Map和Reduce两个函数。
图 1-4 MapReduce数据流图
MapReduce计算模型非常适合在大量计算机组成的大规模集群上并行运行。图1-4中的每一个Map任务和每一个Reduce任务均可以同时运行于一个单独的计算节点上，可想而知，其运算效率是很高的，那么这样的并行计算是如何做到的呢？下面将简单介绍一下其原理。
1.数据分布存储
Hadoop分布式文件系统（HDFS）由一个名字节点（NameNode）和多个数据节点（DataNode）组成，每个节点都是一台普通的计算机。在使用方式上HDFS与我们熟悉的单机文件系统非常类似，利用它可以创建目录，创建、复制、删除文件，并且可以查看文件内容等。但文件在HDFS底层被切割成了Block，这些Block分散地存储在不同的DataNode上，每个Block还可以复制数份数据存储在不同的DataNode上，达到容错容灾的目的。NameNode则是整个HDFS的核心，它通过维护一些数据结构来记录每一个文件被切割成了多少个Block、这些Block可以从哪些DataNode中获得，以及各个DataNode的状态等重要信息。
2.分布式并行计算
Hadoop中有一个作为主控的JobTracker，用于调度和管理其他的TaskTracker。JobTracker可以运行于集群中的任意一台计算机上；TaskTracker则负责执行任务，它必须运行于DataNode上，也就是说DataNode既是数据存储节点，也是计算节点。JobTracker将Map任务和Reduce任务分发给空闲的TaskTracker，让这些任务并行运行，并负责监控任务的运行情况。如果某一个TaskTracker出了故障，JobTracker会将其负责的任务转交给另一个空闲的TaskTracker重新运行。
3.本地计算
数据存储在哪一台计算机上，就由哪台计算机进行这部分数据的计算，这样可以减少数据在网络上的传输，降低对网络带宽的需求。在Hadoop这类基于集群的分布式并行系统中，计算节点可以很方便地扩充，因此它所能够提供的计算能力近乎无限。但是数据需要在不同的计算机之间流动，故而网络带宽变成了瓶颈。“本地计算”是一种最有效的节约网络带宽的手段，业界将此形容为“移动计算比移动数据更经济”。
4.任务粒度
在把原始大数据集切割成小数据集时，通常让小数据集小于或等于HDFS中一个Block的大小（默认是64MB），这样能够保证一个小数据集是位于一台计算机上的，便于本地计算。假设有M个小数据集待处理，就启动M个Map任务，注意这M个Map任务分布于N台计算机上，它们将并行运行，Reduce任务的数量R则可由用户指定。
5.数据分割（Partition）
把Map任务输出的中间结果按key的范围划分成R份（R是预先定义的Reduce任务的个数），划分时通常使用Hash函数（如hash（key）mod R），这样可以保证某一段范围内的key一定是由一个Reduce任务来处理的，可以简化Reduce的过程。
6.数据合并（Combine）
在数据分割之前，还可以先对中间结果进行数据合并（Combine），即将中间结果中有相同key的＜key, value＞对合并成一对。Combine的过程与Reduce的过程类似，在很多情况下可以直接使用Reduce函数，但Combine是作为Map任务的一部分、在执行完Map函数后紧接着执行的。Combine能够减少中间结果中＜key, value＞对的数目，从而降低网络流量。
7.Reduce
Map任务的中间结果在执行完Combine和Partition之后，以文件形式存储于本地磁盘上。中间结果文件的位置会通知主控JobTracker, JobTracker再通知Reduce任务到哪一个TaskTracker上去取中间结果。注意，所有的Map任务产生的中间结果均按其key值通过同一个Hash函数划分成了R份，R个Reduce任务各自负责一段key区间。每个Reduce需要向许多个Map任务节点取得落在其负责的key区间内的中间结果，然后执行Reduce函数，形成一个最终的结果文件。
8.任务管道
有R个Reduce任务，就会有R个最终结果。很多情况下这R个最终结果并不需要合并成一个最终结果，因为这R个最终结果又可以作为另一个计算任务的输入，开始另一个并行计算任务，这也就形成了任务管道。
这里简要介绍了在并行编程方面Hadoop中MapReduce编程模型的原理、流程、程序结构和并行计算的实现，MapReduce程序的详细流程、编程接口、程序实例等请参见后面章节。
1.5 Hadoop计算模型—MapReduce
MapReduce是Google公司的核心计算模型，它将运行于大规模集群上的复杂的并行计算过程高度地抽象为两个函数：Map和Reduce。Hadoop是Doug Cutting受到Google发表的关于MapReduce的论文启发而开发出来的。Hadoop中的MapReduce是一个使用简易的软件框架，基于它写出来的应用程序能够运行在由上千台商用机器组成的大型集群上，并以一种可靠容错的方式并行处理上T级别的数据集，实现了Hadoop在集群上的数据和任务的并行计算与处理。
一个Map/Reduce作业（Job）通常会把输入的数据集切分为若干独立的数据块，由Map任务（Task）以完全并行的方式处理它们。框架会先对Map的输出进行排序，然后把结果输入给Reduce任务。通常作业的输入和输出都会被存储在文件系统中。整个框架负责任务的调度和监控，以及重新执行已经失败的任务。
通常，Map/Reduce框架和分布式文件系统是运行在一组相同的节点上的，也就是说，计算节点和存储节点在一起。这种配置允许框架在那些已经存好数据的节点上高效地调度任务，这样可以使整个集群的网络带宽得到非常高效的利用。
Map/Reduce框架由一个单独的Master JobTracker和集群节点上的Slave TaskTracker共同组成。Master负责调度构成一个作业的所有任务，这些任务分布在不同的slave上。Master监控它们的执行情况，并重新执行已经失败的任务，而Slave仅负责执行由Master指派的任务。
在Hadoop上运行的作业需要指明程序的输入/输出位置（路径），并通过实现合适的接口或抽象类提供Map和Reduce函数。同时还需要指定作业的其他参数，构成作业配置（Job Configuration）。在Hadoop的JobClient提交作业（JAR包/可执行程序等）和配置信息给JobTracker之后，JobTracker会负责分发这些软件和配置信息给slave及调度任务，并监控它们的执行，同时提供状态和诊断信息给JobClient。
1.6 Hadoop数据管理
前面重点介绍了Hadoop及其体系结构与计算模型MapReduce，现在开始介绍Hadoop的数据管理，主要包括Hadoop的分布式文件系统HDFS、分布式数据库HBase和数据仓库工具Hive。
 1.6.1 HDFS的数据管理
HDFS是分布式计算的存储基石，Hadoop分布式文件系统和其他分布式文件系统有很多类似的特性：
对于整个集群有单一的命名空间；
具有数据一致性，都适合一次写入多次读取的模型，客户端在文件没有被成功创建之前是无法看到文件存在的；
文件会被分割成多个文件块，每个文件块被分配存储到数据节点上，而且会根据配置由复制文件块来保证数据的安全性。
通过前面的介绍和图1-3可以看出，HDFS通过三个重要的角色来进行文件系统的管理：NameNode、DataNode和Client。NameNode可以看做是分布式文件系统中的管理者，主要负责管理文件系统的命名空间、集群配置信息和存储块的复制等。NameNode会将文件系统的Metadata存储在内存中，这些信息主要包括文件信息、每一个文件对应的文件块的信息和每一个文件块在DataNode中的信息等。DataNode是文件存储的基本单元，它将文件块（Block）存储在本地文件系统中，保存了所有Block的Metadata，同时周期性地将所有存在的Block信息发送给NameNode。Client就是需要获取分布式文件系统文件的应用程序。接下来通过三个具体的操作来说明HDFS对数据的管理。
（1）文件写入
1）Client向NameNode发起文件写入的请求。
2）NameNode根据文件大小和文件块配置情况，返回给Client所管理的DataNode的信息。
3）Client将文件划分为多个Block，根据DataNode的地址信息，按顺序将其写入到每一个DataNode块中。
（2）文件读取
1）Client向NameNode发起文件读取的请求。
2）NameNode返回文件存储的DataNode信息。
3）Client读取文件信息。
（3）文件块（Block）复制
1）NameNode发现部分文件的Block不符合最小复制数这一要求或部分DataNode失效。
2）通知DataNode相互复制Block。
3）DataNode开始直接相互复制。
作为分布式文件系统，HDFS在数据管理方面还有值得借鉴的几个功能：
文件块（Block）的放置：一个Block会有三份备份，一份放在NameNode指定的DataNode上，另一份放在与指定DataNode不在同一台机器上的DataNode上，最后一份放在与指定DataNode同一Rack的DataNode上。备份的目的是为了数据安全，采用这种配置方式主要是考虑同一Rack失败的情况，以及不同Rack之间进行数据复制会带来的性能问题。
心跳检测：用心跳检测DataNode的健康状况，如果发现问题就采取数据备份的方式来保证数据的安全性。
数据复制（场景为DataNode失败、需要平衡DataNode的存储利用率和平衡DataNode数据交互压力等情况）：使用Hadoop时可以用HDFS的balancer命令配置Threshold来平衡每一个DataNode的磁盘利用率。假设设置了Threshold为10%，那么执行balancer命令时，首先会统计所有DataNode的磁盘利用率的平均值，然后判断如果某一个DataNode的磁盘利用率超过这个平均值，那么将会把这个DataNode的Block转移到磁盘利用率低的DataNode上，这对于新节点的加入十分有用。
数据校验：采用CRC32做数据校验。在写入文件块的时候，除了会写入数据外还会写入校验信息，在读取的时候则需要先校验后读入。
单个NameNode：如果单个NameNode失败，任务处理信息将会记录在本地文件系统和远端的文件系统中。
数据管道性的写入：当客户端要写入文件到DataNode上时，首先会读取一个Block，然后将其写到第一个DataNode上，接着由第一个DataNode将其传递到备份的DataNode上，直到所有需要写入这个Block的DataNode都成功写入后，客户端才会开始写下一个Block。
安全模式：分布式文件系统启动时会进入安全模式（系统运行期间也可以通过命令进入安全模式），当分布式文件系统处于安全模式时，文件系统中的内容不允许修改也不允许删除，直到安全模式结束。安全模式主要是为了在系统启动的时候检查各个DataNode上数据块的有效性，同时根据策略进行必要的复制或删除部分数据块。在实际操作过程中，如果在系统启动时修改和删除文件会出现安全模式不允许修改的错误提示，只需要等待一会儿即可。
1.6.2 HBase的数据管理
HBase是一个类似Bigtable的分布式数据库，它的大部分特性和Bigtable一样，是一个稀疏的、长期存储的（存在硬盘上）、多维度的排序映射表，这张表的索引是行关键字、列关键字和时间戳。表中的每个值是一个纯字符数组，数据都是字符串，没有类型。用户在表格中存储数据，每一行都有一个可排序的主键和任意多的列。由于是稀疏存储的，所以同一张表中的每一行数据都可以有截然不同的列。列名字的格式是“＜family＞：＜label＞”，它是由字符串组成的，每一张表有一个family集合，这个集合是固定不变的，相当于表的结构，只能通过改变表结构来改变表的family集合。但是label值相对于每一行来说都是可以改变的。
HBase把同一个family中的数据存储在同一个目录下，而HBase的写操作是锁行的，每一行都是一个原子元素，都可以加锁。所有数据库的更新都有一个时间戳标记，每次更新都会生成一个新的版本，而HBase会保留一定数量的版本，这个值是可以设定的。客户端可以选择获取距离某个时间点最近的版本，或者一次获取所有版本。
以上从微观上介绍了HBase的一些数据管理措施。那么HBase作为分布式数据库在整体上从集群出发又是如何管理数据的呢？