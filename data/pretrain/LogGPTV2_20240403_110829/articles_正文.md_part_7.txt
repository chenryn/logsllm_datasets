有时，日志会明确给出字段名称和字段值，以key-value的形式展现，让人能够读懂字段的含义。例如，有的日志中，192.168.1.1作为字段出现，而在key-value形式的日志中，可能会以ip=192.168.1.1的形式展现该字段。下面是一个日志示例：
field=tag&filters=&order=desc&page=1&query=\*&size=50&sourcegroup=all&sourcegroupCn=%E6
%89%80%E6%9C%89%E6%97%A5%E5%BF%97&time_range=-2d,now&type=fields
这是一个以&和＝作为分隔符的key-value日志，利用&进行解析，即可得到key=value形式的结果。
5\. 多种方法相结合
日志的字段抽取没有固定的方法，应根据应用场景、编程语言的便利性来决定。有些日志比较复杂，需要将多种字段抽取方法结合起来使用。例如，可以使用key-value解析和正则匹配相结合的方式抽取字段。假设有如下日志：
\May 18 11:20:10 2016 HLJ_S12508_1\_FW
%%10FILTER/6/ZONE_DP_FLT_EXECUTION_TCP_LOG(l): -DEV_TYPE=SECPATH
-PN=210231A0H6010C000002; srcZoneName(1034)=serveruntrust;
destZoneName(1035)=servertrust; rule_ID(1070)=90;
policyActType(1071)=denied; protType(1001)=TCP(6);
srcIPAddr(1017)=10.167.77.99; destIPAddr(1019)=10.166.5.70;
srcPortNum(1018)=49362; destPortNum(1020)=1521;
beginTime_e(1013)=05182016112009; endTime_e(1014)= 05182016112009;
先对上述日志进行正则匹配，获得如下结果：
\(?\%{NOTSPACE}\\s+%{NOTSPACE}\\s+%{NOTSPACE}\\s+%{
NOTSPACE}\\s+)%{NOTSPACE:host}
\\%\\%(?\\[\^/\]\*)/(?\\[\^/\]\*)/(?\\[\^:\]\*):
-DEV_TYPE=SECPATH-PN=210231A0H6010C000002;(?\.\*)
接下来，可使用key-value解析方法对上述结果做进一步处理。
### 5.3.3 常用日志类型的字段抽取
在介绍了各种字段抽取方法后，本节将介绍一些常用日志类型的字段抽取。
1\. Apache
对于Apache日志，可按实际需求配置服务器的日志格式，具体的配置规则定义可参考Apache官方文档。下面列举一种Apache日志格式：
%h %l %u %t \\\"%r\\\" %\>s %b
其中各项含义如下：
 %b：以CLF格式显示的除HTTP头以外传送的字节数。
 %h：远端主机。
 %l：远端登录名。
 %r：请求的第一行。
 %\>s：最后请求的状态。
 %t：时间，采用普通日志时间格式。
还可以自动识别Apache的error日志，通常情况下其日志格式如下：
\[Fri Jul 05 21:28:24 2013\] \[error\] child process 1245 still did not
exit, sending a SIGKILL
对于上述日志，可以解析出timestamp、loglevel、message字段，其值分别对应"Fri
Jul 05 21:28:24 2013""error""child process 1245 still did not
exit，sending a SIGKILL"。
2\. Nginx
Nginx日志格式与Apache日志格式基本相同，具体配置可参考Nginx官方文档。常用的日志格式如下：
log_format main \'\$remote_addr - \$remote_user \[\$time_local\]
\"\$request\"\'
\'\$status \$body_bytes_sent\';
log_format combind \'\$remote_addr - \$remote_user \[\$time_local\]
\"\$request \'
\'\$status \$body_bytes_sent \"\$http_referer\"\'
\'\"\$http_user_agent\"\';
log_format default \'\$remote_addr - \$remote_user \[\$time_local\]
\"\$request\"\'
\'\$status \$body_bytes_sent \"\$http_referer\"\'
\'\"\$http_user_agent\" \"\$http_x\_forwarded_for\"\';
access_log /var/log/nginx/access.log main;
3\. Log4j
Log4j是Java程序常用的日志库，具体配置可参考Log4j配置文档。
下面列举一种Log4j日志格式：
%d{ISO8601} %p %t %c.%M - %m%n
由上述日志可以解析出timestamp、loglevel、thread、class、method、message等字段。
4\. JSON
JSON（JavaScript Object
Notation）是一种轻量级数据交换格式。它基于ECMAScript的一个子集。JSON采用完全独立于语言的文本格式，易于程序员进行阅读和编写，也易于机器解析和生成（一般用于提高网络传输速率）。举例如下：
{
\"timestamp\":\"2014-09-11t01:13:24.012+0800\",
\"family\":{
\"father\":\"LiLei\",
\"mother\":\"HanMeimei\"
}
}
可直接根据key-value形式解析字段，上述示例中可以解析出的字段有timestamp、family、father、mother。一般编程语言都带有解析JSON的库。
5\. MySQL
MySQL是常用的数据库类型。MySQL日志记录了MySQL本身的运行情况，例如：
2014-05-14 23:24:47 15752 \[Note\] Server hostname (bind-address):
\'\*\'; port: 3306
由此可解析出timestamp、loglevel、pid、message等字段。
6\. Linux
Linux是十分常见的操作系统。如果需要分析Linux系统日志，可将其包装成标准的Syslog日志，并解析出如下字段：timestamp、appname、hostname、priority、facility、severity、message。
## 5.4 schema on write与schema on read
对于新到的日志数据，可以先存储再解析，也可以先解析再存储，两种方法各有优缺点。
schema on write表示数据在存入数据库前进行处理，schema on
read表示将数据的处理推迟到从数据库读出后。如果能确定在将来很长的一段时间内，所要处理的日志数据的格式不会发生变化，那么可以采用schema
on
write，这样将数据从数据库中读出后可以直接分析。但是，如果业务种类很多，以后还有可能扩充，那么建议采用schema
on
read。这样可以根据具体需求，结合一些分析工具如Hive、Spark，对数据做一些处理。
schema on write的优点是性能好、解析速度快，缺点是耗费内存。
schema on read的优点是扩展性强，缺点是性能稍差。
## 5.5 字段解析常见问题
### 5.5.1 字段存在别名
有些字段存在别名，如datetime与timestamp、ip与address。在解析字段时，要根据实际应用场景，统一有相同意义、不同名称的字段。
### 5.5.2 多个时间戳
通常情况下，一条日志有多个可用时间戳，分别表示不同的含义。例如，日志显示时间戳表示日志产生的时间，是最直观的时间戳。此外，还有日志发送时间戳、日志到达时间戳等。
在使用的时候，可以指定一个合理的时间戳选取顺序，即在众多时间戳中按照一定的顺序读取第一个可用的时间戳作为解析结果。
另外，时间戳有多种标准格式，解析的时候要注意格式类型的划分。
### 5.5.3 特殊字符
日志本身包含一些特殊字符。为了使字段解析更为便捷，若字段名称中包含一些特殊字符，如空格或圆点，可以考虑用其他字符（如下画线）替换。
例如：
{
\"a\":1,
\"d.e\":3,
\"d\":{
\"e\":4
}
}
上述内容可重写为以下形式：
{
\"a\":1,
\"d_e\":3,
\"d\":{
\"e\":4
}
}
### 5.5.4 封装成标准日志
可以将一些日志封装成某种类型的标准日志，以便于解析。例如，对于Linux日志，可以将其封装成标准的Syslog日志。
### 5.5.5 类型转换
很多时候，字段解析默认提取的字段都是字符串类型的。如果希望转换成数值类型，以便在后面做统计，那么需要在解析的过程中进行类型转换。例如，经过日志解析得出如下字段：
k1:\"123\", k2:\"123.0\"
可以将其转换为以下形式：
k1:123, k2:123.0
### 5.5.6 敏感信息替换
有些字段的内容是敏感信息，如电话号码、家庭住址等。在解析的过程中，要对敏感信息进行替换。例如，日志原文为123abc456，设立一个正则表达式(\\d+)\[a-z\]+，替换内容为\$1###，则日志原文被替换为123###456。
### 5.5.7 HEX转换
日志中如果有十六进制数据（如tcpdump-X的输出），可以通过HEX转换，将十六进制数据转换成原始报文格式。
以下面这个十六进制字符串为例：
68656c6c6f20776f726c64
其转换后的文本有更高的可读性：
hello world