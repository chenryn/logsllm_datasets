title:Boosting efficiency and security in proof of ownership for deduplication
author:Roberto Di Pietro and
Alessandro Sorniotti
Boosting Efﬁciency and Security in Proof of Ownership for
Deduplication
Roberto Di Pietro
Università di Roma Tre, Italy
PI:EMAIL
IBM Research – Zurich, Switzerland
Alessandro Sorniotti
PI:EMAIL
ABSTRACT
Deduplication is a technique used to reduce the amount of
storage needed by service providers. It is based on the in-
tuition that several users may want (for diﬀerent reasons)
to store the same content. Hence, storing a single copy of
these ﬁles is suﬃcient. Albeit simple in theory, the imple-
mentation of this concept introduces many security risks.
In this paper we address the most severe one: an adver-
sary (who possesses only a fraction of the original ﬁle, or
even just partially colluding with a rightful owner) claim-
ing to possess such a ﬁle. The paper’s contributions are
manifold: ﬁrst, we introduce a novel Proof of Ownership
(POW) scheme that has all features of the state-of-the-art
solution while incurring only a fraction of the overhead expe-
rienced by the competitor; second, the security of the pro-
posed mechanisms relies on information theoretical (com-
binatoric) rather than computational assumptions; we also
propose viable optimization techniques that further improve
the scheme’s performance. Finally, the quality of our pro-
posal is supported by extensive benchmarking.
Categories and Subject Descriptors
H.3.5 [Information Systems]: Information storage and re-
trieval—Online information services
General Terms
Security
Keywords
Cloud Security, Deduplication, Proof of Ownership
1.
INTRODUCTION
The rapid surge in cloud service oﬀerings has resulted in
a sharp drop in prices of storage services, and in an increase
in the number of customers. Through popular providers,
like Amazon s3 and Microsoft Azure, and backup services,
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
ASIACCS ’12, May 2–4, 2012, Seoul, Korea.
Copyright 2012 ACM 978-1-4503-1303-2/12/05 ...$10.00.
like Dropbox and Memopal, storage has indeed become a
commodity. Among the reasons for the low prices, we ﬁnd a
strong use of multitenancy, the reliance on distributed algo-
rithms run on top of simple hardware, and an eﬃcient use
of the storage backend thanks to compression and dedupli-
cation.
Deduplication is the process of avoiding having to store
the same data multiple times.
It leverages the fact that
large data sets often exhibit high redundancy. Examples
include, for instance, common email attachments, ﬁnancial
records, with common headers and semi-identical ﬁelds, and
popular media content—such as music, video—likely to be
owned (and stored) by many users.
There are four diﬀerent deduplication strategies, depend-
ing on whether deduplication happens at the client side (i.e.
before the upload) or at the server side, and whether dedu-
plication happens at a block level or at a ﬁle level. Dedu-
plication is most rewarding when it is triggered at the client
side, as it also saves the bandwidth of the upload. For these
reasons, deduplication is a critical enabler for a number of
popular and successful storage services (e.g. Dropbox, Mem-
opal) that oﬀer cheap remote storage to the broad public by
performing client-side deduplication, thus saving both the
network bandwidth and the storage costs associated to pro-
cessing the same content multiple times.
Security Threats to Deduplication.
Harnik et al. [10] have identiﬁed a number of threats that
can aﬀect a storage system performing client-side dedupli-
cation. These threats, brieﬂy reviewed in the following, can
be turned into practical attacks by any user of the system.
A ﬁrst set of attacks targets the privacy and conﬁdentiality
of users of the storage system. For instance, a user can check
whether another user has already uploaded a ﬁle by trying
to upload it as well and by checking whether the upload
actually takes place. This attack is particularly relevant
for rare ﬁles that may reveal the identity of the user who
performed the upload.
A diﬀerent type of attack attempts to subvert the intended
use of a given storage system. Two users who have no direct
connectivity may, for instance, try to use the storage system
as a covert channel. For instance, to exchange a bit of in-
formation, the two users would pre-agree on two ﬁles; then
the transmitting user would upload one of the two ﬁles, and
the receiving user would detect which one gets deduplicated
and would output either 0 (for the ﬁrst ﬁle) or 1 (for the
second).
Finally, users may abuse a storage system by turning it
into a content distribution network: users who wish to ex-
change large ﬁles leveraging the large bandwidth available
to the servers of the storage systems may upload only a
single copy of such a ﬁle and share the short token that trig-
gers deduplication (in most cases, the hash digest of the ﬁle)
among all users who wish to download the content. Real-
world examples of such an approach include Dropship [6].
Proof of Ownership (POW).
To remedy the security threats mentioned above, the con-
cept of Proof of Ownership (POW) has been introduced [9].
POW schemes essentially address the root-cause of the afore-
mentioned attacks to deduplication, namely, that the proof
that the client owns a given ﬁle (or block of data) is solely
based on a static, short value (in most cases the hash digest
of the ﬁle), whose knowledge automatically grants access to
the ﬁle.
POW schemes are security protocols designed to allow a
server to verify (with a given degree of assurance) whether
a client owns a ﬁle. The probability that a malicious client
engages in a successful POW run must be negligible in the
security parameter, even if the malicious client knows a (rel-
evant) portion of the target ﬁle. A POW scheme should
be eﬃcient in terms of CPU, bandwidth and I/O for the
server and all legitimate clients: in particular, POW schemes
should not require the server to load the ﬁle (or large por-
tions of it) from its back-end storage at each execution of
POW.
Halevi et al. [9] have introduced the ﬁrst practical crypto-
graphic protocol that implements POW. This seminal work,
however, suﬀers from a number of shortcomings that might
hinder its adoption. The ﬁrst is that the scheme has ex-
tremely high I/O requirements at the client-side:
it either
requires clients to load the entire ﬁle in memory or to per-
form random block accesses with an aggregate total I/O
higher than the size of the ﬁle itself. Secondly, the scheme
takes a heavy computational toll on the client. Thirdly, its
security is admittedly based on assumptions that are hard
to verify.
Contributions.
In this paper, we present a novel scheme for secure Proof of
Ownership. Our scheme attains several ambitious goals: i)
its I/O and computational costs do not depend on the input
ﬁle size; ii) it is very eﬃcient for a wide range of systems
parameters; iii) it is information-theoretically secure; and,
iv) it requires the server to keep a per-ﬁle state that is a
negligible fraction of the input ﬁle size.
Roadmap.
The remainder of this paper is organised as follows: Sec-
tion 2 reviews the state of the art; Section 3 deﬁnes system
and security models; Section 4 presents our basic scheme and
its two improvements; Section 5 describes the implementa-
tion and benchmarks; Section 6 contains a discussion on the
performance and an optimization that captures all the pre-
ceding ones, while Section 7 presents our conclusions.
2. RELATED WORK
Douceur et al. [5] study the problem of deduplication in
a multitenant system in which deduplication has to be rec-
onciled with conﬁdentiality. The authors propose the use of
convergent encryption, i.e., deriving keys from the hash of
the plaintext, so that two users will produce the same ci-
phertext from the same plaintext block, and the ciphertext
can then be deduped. Storer et al. [16] point out some secu-
rity problems of convergent encryption, proposing a security
model and two protocols for secure data deduplication.
The seminal work of Harnik et al. [10] ﬁrst discusses the
shortcomings of client-side deduplication, and later presents
some basic solutions to the problem. In particular, attacks
to privacy and conﬁdentiality can be addressed without a
full-ﬂedged POW scheme by triggering deduplication only
after a small, but random, number of uploads.
Whereas POW deals with the assurance that a client in-
deed possesses a given ﬁle, Provable Data Possession (PDP)
and Proof of Retrievability (PoR) deal with the dual prob-
lem of ensuring—at the client-side—that a server still stores
the ﬁles it ought to. PDP is formally introduced by Ate-
niese and colleagues [3, 2]. A number of earlier works al-
ready address remote integrity checking, see the Related
Work Section of [2] for more details. Ateniese et al. [4]
present a dynamic PDP scheme based on symmetric cryp-
tography, and show how relaxing the requirement of public
veriﬁability allows a much more lightweight scheme. The
scheme is dynamic in that it allows data blocks to be ap-
pended, modiﬁed and deleted. Erway et al. [7] present for-
mal deﬁnitions of Dynamic PDP together with two protocols
allowing also block insertion. PoR schemes, introduced by
Juels and Kaliski [11] combine message authentication code-
based data veriﬁcation with error-correcting codes to allow
a client to download pre-determined subsets of blocks and
check whether their MAC matches the pre-computed one:
the use of ECC ensures that small changes in the data are
be detected with high probability.
2.1 The State-of-the-Art Solution
Next we shall describe in detail the POW scheme pre-
sented by Halevi et al. [9], as it represents the state-of-the-
art solution our solution will be compared against.
The authors present three schemes that diﬀer in terms
of security and performance. All three involve the server
challenging the client to present valid sibling paths for a
subset of leaves of a Merkle trees [14]. Both the client and
the server build the Merkle tree; the server only keeps the
root and challenges clients that claim to possess the ﬁle. The
Merkle tree is built on a buﬀer, whose content is derived
from the ﬁle, and pre-processed in three diﬀerent ways for
the three diﬀerent schemes.
The ﬁrst scheme applies erasure coding on the content of
the original ﬁle; the erasure-coded version of the ﬁle is the
input for construction of the Merkle tree.
The second scheme pre-processes the ﬁle with a universal
hash function instead of erasure coding, to the same end: the
ﬁle is hashed to an intermediate reduction buﬀer whose size
is suﬃciently large to discourage its sharing among colluding
users, but not too big to be impractical. The authors settle
for a size of 64 MiB. This buﬀer is then used as an input for
the construction of the Merkle tree.
The third scheme, which is the one we will compare our
solution with, follows the same approach, but substitutes
universal hashing with a mixing and a reduction phase that
“hash” the original ﬁle into the reduction buﬀer mentioned
above. In the reminder of this paper, we shall refer to this
scheme as b-POW.
This scheme has two phases (see Figure 1 of [9]): the ﬁrst
phase populates the reduction buﬀer by xoring each block
of the original ﬁle in four random positions in the buﬀer
(after performing a bit shift). The mixing phase ampliﬁes
the confusion and diﬀusion in the reduction buﬀer by xoring
together random positions of the reduction buﬀer.
3. SYSTEM MODEL
The system is composed of two main principals, the client
C and the server S. Both C and S are computing nodes with
network connectivity. S has a large back-end storage facility
and oﬀers its storage capacity to C; C uploads its ﬁles and
can later download them. During the upload process, S at-
tempts to minimize the bandwidth and to optimize the use of
its storage facility by determining whether the ﬁle the client
is about to upload has already been uploaded by another
user.
If so, the ﬁle does not need to be uploaded and we
say it undergoes deduplication.1 Note that a trivial solution
would be to transfer the ﬁle from the client to the server, and
later have the checks performed on the server-side. However,
this solution is highly bandwidth demanding, and also sac-
riﬁces another beneﬁt of deduplication: the reduction of the
completion time on both the client and server-side.
A further requirement on the server-side is to minimize
accesses to its back-end storage system: for example, a pro-
tocol that requires to access the ﬁle content at each interac-
tion with a client to evaluate the potential for deduplication
would not meet this requirement. We assume, however, that
S has a front-end storage facility, whose capacity is a small
fraction of the capacity of the back-end one, and that can
be used to store per-ﬁle information. We ﬁnally assume that
server-side computational power is abundant and cheap, es-
pecially if the required computation does not need to be
executed immediately but can be deferred to moments of
low system load.
C is assumed to have limited resources in terms of compu-
tational power and I/O capability, and therefore one of the
design guidelines of the scheme is to minimize the scheme’s
client-side computational and I/O footprint. C and S engage
in an interactive protocol. As previously mentioned, mini-
mization of the latency of this protocol is another important
objective.
3.1 Adversarial Model
In the context of POW protocols, S is considered to be
a trusted entity that abides by the rules of the protocol as
its correct execution is in S’s best interest. C, in contrast,
is considered to be a malicious principal and consequently
it cannot be assumed that it is bound by the rules of the
protocol.
Given a target ﬁle f∗, the objective of a malicious client
˜C is to convince the server that ˜C owns f∗, despite this not
being the case. It is assumed that ˜C does not know f∗ in
its entirety; however we assume that ˜C knows an arbitrar-
ily large fraction of it. The estimated upper bound on the
fraction of f∗ known to ˜C will be one of the inputs of the
system, playing a role in the scheme’s security analysis. Sev-