veriﬁed vulnerability population in the wild.
We believe that the increase in SSL vulnerabilities shown
in ﬁgure 2 does not indicate a need for increased black-
box scanning. A large number of SSL vulnerabilities were
reported in 2009, causing the upward trend in SSL in-
cidences. However, these are actually certiﬁcate spooﬁng
vulnerabilities that allow a certiﬁcate issued for one domain
name, usually containing a null-character, to become valid
for another domain name [14], [15]. As this vulnerability is
caused by mistakes made by the certiﬁcate authority and the
client application (usually browser), it cannot be prevented
PREVIOUSLY-REPORTED VS SCANNER-FOUND VULNERABILITIES FOR
DRUPAL, PHPBB2, AND WORDPRESS
Table III
Category
XSS
SQLI
XCS
Session
CSRF
Info Leak
Drupal
4.7.0
Known
6
2
4
5
2
4
Found
2
1
0
4
0
3
phpBB2
2.0.19
Wordpress
1.5strayhorn
Known
5
1
1
4
1
1
Found
2
1
0
4
0
1
Known
13
8
8
6
1
6
Found
7
4
3
5
1
4
by the website operator and thus cannot be detected by web
application scanning. In effect, the number of SSL/Server
conﬁguration vulnerabilities that web application scanners
may reasonably aim to detect does not appear to increase
with the increased SSL vulnerability incidence rate.
Finally, Figures 2 and 3 suggest that 2006 was a particu-
larly high-incident year for web application vulnerabilities,
with incidents actually decreasing in subsequent years. (This
trend is also conﬁrmed by searches in the CVE database.)
While it is impossible to be certain, evidence gathered during
the course of this study, including the effectiveness of the
scanners at detecting basic XSS and SQLI vulnerabilities,
suggests that the decrease may possibly be attributable to
headway made by the security community against these
vulnerabilities. Improved security, however, has been an-
swered in turn by efforts to uncover more novel forms of
the vulnerabilities.
IV. SCANNER RESULTS ON COMMON WEB
APPLICATIONS
Having conﬁrmed that the testing vector distribution of
black-box web vulnerability scanners as a group roughly
correlates with the vulnerability population trends in the
wild, we now examine whether the scanners are actually
successful at ﬁnding existent vulnerabilities. We ran all scan-
ners on three popular web applications, Drupal, phpBB2, and
Wordpress, all with known vulnerabilities. We chose to scan
application versions released around January 2006, as this
was prior to the peak in vulnerability reports in 2006. While
these are ﬁeld applications with some inherent uncertainty as
to their exact vulnerability content, the early release dates
mean these application versions are the most ﬁeld-tested,
with most vulnerabilities likely to have been recorded by
VUPEN via the NVD.
Table III lists the speciﬁc application versions tested as
well as the number of known vulnerabilities, including those
reported by the VUPEN database for each of these versions.
For all applications, we installed only the default modules
and included no add-ons.
Table III also shows the number of vulnerabilities found
by any scanners in the group, out of the set of known
335
XSS 
SQLi 
XCS 
Session 
CSRF 
SSL 
Infomation Leak 
2005
2006
2007
2008
2009
Figure 2. Comparison of Web Application Vulnerability Classes in VUPEN Database
Web 
System 
2793
2000
1951
1528
1000
1186
1095
2005
2006
2007
y
t
i
l
i
b
a
r
e
n
u
v
f
l
o
r
e
b
m
u
N
1000
900
800
700
600
500
400
300
200
100
0
3000
2000
s
e
i
t
i
l
i
b
a
r
e
n
u
v
f
l
o
r
e
b
m
u
N
1531
996
2008
1647
1275
2009
Figure 3. Web Application Vulnerabilities versus System Vulnerabilities in VUPEN Database
vulnerabilities. As the table shows, the scanner in total did
a generally good job of detecting these previously known
vulnerabilities. They did particularly well in the Information
Disclosure and Session Management classiﬁcations, leading
to the hypothesis that effective test vectors are easier to add
for these categories than others. The scanners also did a
reasonable job of detecting XSS and SQLI vulnerabilities,
with about 50% detection rate for both. The low detection
rate in the CSRF classiﬁcation may possibly be explained
by the small number of CSRF test vectors. Anecdotally,
one scanner vendor conﬁrmed that they do not report CSRF
vulnerabilities due to the difﬁculty of determining which
forms in the application require protection from CSRF.
V. SCANNER RESULTS ON CUSTOM TESTBED
In addition to testing scanner detection performance on
established web applications, we also evaluated the scanners
in a controlled environment. We developed our own custom
testbed application containing hand-inserted vulnerabilities,
each of which have a proven attack pattern. We veriﬁed each
of the vulnerabilities present in this environment, allowing us
signiﬁcantly smaller uncertainty in vulnerability content than
in the case of ﬁeld-deployed applications. (The scanners as a
group did not uncover any unintended vulnerabilities in our
web application.) We plan to release this testbed publically.
For each vulnerability classiﬁcation, we incorporated both
“textbook” instances and also forward-looking instances,
such as XSS with non-standard tags, for each vulnerability
classiﬁcation. However, we kept the vulnerability content
of our testbed fairly proportional with the vulnerability
population in the wild.
Our testbed has around 50 unique URLs and around
3000 lines of code, installed on a Linux 2.6.18-128.1.6.el5
server running Apache 2.2.3, MySQL 5.0.45, and PHP 5.1.6.
PhpMyAdmin was also running on our server alongside
the testbed application, solely for administrative purposes;
we thus ignored any scanner results having to do with
phpMyAdmin.
The remainder of this section is devoted to scanner testbed
data. We begin by presenting the performance footprint of
each scanner on our testbed. Following this, we report page
coverage results, designed to test scanner understanding of
336
Rapid7
Qualys
N-Stalker
McAfee
IBM
HP
Cenzic
Acunetix
118
168
138
66
87
109
241
Rapid7
186
649
473
Qualys
48
145
N-Stalker
122
877
McAfee
25
53
IBM
71
125
HP
35
206
Cenzic
76
116
Acunetix
123
146
Data sent
Data received
0m 50m 100m150m200m250m300m350m400m450m500m
(a) Scanner Execution Time in Minutes
   0 MB    100 MB   200 MB   300 MB   400 MB   500 MB   600 MB   700 MB   800 MB   900 MB
(b) Scanner Bytes Sent and Received
Figure 4. Scanner Footprint
various content technologies. We then present vulnerability
detection results, ﬁrst an overview and subsequently by
vulnerability classiﬁcation, giving a brief overview of our
testbed design for each classiﬁcation. Finally, we discuss
false positives, including experimentally designed “traps” for
false positives as well as scanner results.
A. Scanner Time and Network Footprint
Figures 4a and 4b respectively plot the time required to
scan the testbed application and the number of network bytes
sent/received by each scanner, as measured on the web server
by tcpdump. Scanning time ranged from 66 to 473 minutes,
while network trafﬁc ranged from 80 MB to nearly 1 GB.
Perhaps surprisingly, the scanning time and network traf-
ﬁc statistics seem to be relatively independent of each
other, as exempliﬁed by the Rapid7, Qualys, N-Stalker,
and McAfee results. It is interesting that the two remote
services, Qualys and McAfee, generated comparatively low
amounts of network trafﬁc. Finally, we wish to note that
the footprint statistics are not indicative of vulnerability
detection performance.
B. Coverage Results
To experimentally evaluate site coverage, we wrote hy-
perlinks using the technology in each category shown in
ﬁgure 5 and embedded each landing page with tracker code
that measured whether the link was followed. For Java,
SilverLight, and Flash,
the linked applet or movie is a
simple, bare shell containing only the hyperlink. We then
link to the technology page containing the link from the
application home page, which is written in regular php.
The link encoding category encompasses links written
in hexadecimal, decimal, octal, and html encodings, with
the landing page ﬁle named in regular ASCII. The “POST
link” test involves a link that only shows up when certain
selections are made on a POST form. The other technologies
are self explanatory. Figure 5 shows the experimental results,
where the measure is percentage of successful links crawled
over total existent links by technology category.
Figure 5 shows that the scanners as a group have fairly
low comprehension of active technologies such as Java
applets, SilverLight, and, surprisingly given its widespread
use, Flash. We speculate that some scanners only perform
textual analysis of http responses in order to collect URLs,
thus allowing them to perform decently on script-based
links, which are represented in text, but not allowing them
to follow links embedded in compiled objects such as Java
applets and Flash movies. This would also explain the better
coverage of SilverLight over Flash and Java, as SilverLight
is delivered in a text-based markup language. We also
see that the scanners could improve their understanding of
various link encodings.
C. Vulnerability Detection Results
1) Overall Results: Figure 6 presents by vulnerability
classiﬁcation the vulnerability detection rate averaged over
all scanners. The detection rate is simply calculated as the
number of vulnerabilities found over the (known) number of
total vulnerabilities. Results for each vulnerability classiﬁ-
cations, including an added malware detection classiﬁcation,
are explained in detail in individual sub-sections to follow.
Each vulnerability classiﬁcation sub-section describes the
testbed for the category, plots the average detection rate over
all scanners, and also plots anonymous individual scanner
results for the category sorted from best- to worst-performing
for that category.
The results show that the scanners as a group are fairly
effective at detecting basic “reﬂected” cross-site scripting
(XSS type 1), with a detection rate of over 60%. Also,
although not shown, basic forms of ﬁrst-order SQL Injection
were detected by a majority of scanners. Unfortunately,
the overall results for the ﬁrst-order SQL vulnerability
337
110%
100%
%
90%
80%
70%
60%
50%
40%
30%
20%
10%
0%
100
100
100
87.5
75
62.5
53.12
50
79.16
50
37.5
12.5
12.5
AJAX
Javascript events
Flash
Silver Light
H
P
Java Applets