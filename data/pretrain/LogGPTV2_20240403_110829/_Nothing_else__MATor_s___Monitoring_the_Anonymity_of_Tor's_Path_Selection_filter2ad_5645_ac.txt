Proof. We will show this theorem inductively. Assume that P is (i, i · ε, eiε · i · δ)-α-IND-CDP. We show that P
is also (i + 1, (i + 1) · ε, e(i+1)·ε(i + 1) · δ)-α-IND-CDP.
Let A be an adversary that sends at most i + 1 challenges. To do so, we construct several games:
• Game: G0 is the normal game ACREAL(0, i + 1) with up to i + 1 challenges where b = 0.
• Game: G1 is an intermediate game ACSIMSzdontsim
(0, i + 1). Here every message from A to A(A) (and
otherwise) goes through the simulator Szdontsim. However, this simulator does not need to simulate anything,
as there are still up to i + 1 challenges and b = 0.
Claim: G0 and G1 are computationally indistinguishable.
Proof: By item 3b Deﬁnition 3 the simulator Szdontsim exists and the games are indistinguishable.
• Game: G2 is an intermediate (hybrid) game ACSIMSz (0, i + 1) with b = 0 and ﬁxed input messages
instead of the challenge with tag i + 1 (so there are at most i challenges left). This is done by using the
simulator Sz for z = [(dontsim, ), . . . , (dontsim, ), (sim, 0)] ∈ {0, 1}i+1, i.e., the simulator simulates the
i + 1st challenge for b = 0.
Claim: G1 and G2 are computationally indistinguishable.
Proof: By item 3 of Deﬁnition 3, we know that the simulator Sz exists. Since the simulator Sz from G2
uses the correct bit bi+1 = 0 for the simulated challenge, Item 3c of Deﬁnition 3 implies that the games are
indistinguishable.
8
• Game: G3 is the intermediate (hybrid) game ACSIMSz(1, i + 1) where the simulator stays Sz but the
challenger changes to b = 1.
Claim: G2 and G3 are (iε, eiεiδ)-indistinguishable.
Proof: The adversary Sz(A) makes at most i queries with challenge tags in {1, . . . , i}. From the re-
liability property of the adversary class (item 1 of Deﬁnition 3) we know that thus A(Sz(A)) uses at
most i challenge tags in {1, . . . , i}. The claim immediately follows from the induction hypothesis: P is
(i, i · ε, i · δ)-α-IND-CDP.
• Game: G4 is a game ACSIMSz(cid:48) (1, i+1) where the simulator Sz(cid:48) with z(cid:48) = [(sim, 1), . . . , (sim, 1), (sim, 0)]
simulates all challenges from A. For the challenge tags 1 to i, Sz(cid:48) simulates the challenges for b1 = . . . =
bi = 1, whereas for the tag i + 1 it still simulates it for bi+1 = 0. The challenger uses b = 1.
Claim: G3 and G4 are computationally indistinguishable.
Proof: Since the simulator Sz(cid:48) from G4 uses the correct bit b1 = . . . = bi = 1 for the challenges that are
not simulated in Sz, Item 3c of Deﬁnition 3 implies that the games are indistinguishable.
• Game: G5 is the game ACSIMSz(cid:48) (0, i + 1) where we use the same simulator Sz(cid:48) but we have b = 0 again.
Claim: G4 and G5 are computationally indistinguishable.
Proof: Since there are no challenge messages (everything is simulated, as by item 3a Sz(cid:48) does not send
any messages (challenge, , , Ψ)), changing the bit b of the challenger does not have any effect. Hence, the
games are indistinguishable.
• Game: G6 is the game ACSIMSz(cid:48)(cid:48) (0, i+1) where we use the simulator Sz(cid:48)(cid:48) with z(cid:48)(cid:48) = [(sim, 1), . . . , (sim, 1),
(dontsim, )]. In other words, we do not simulate the challenge for i + 1 with bi+1 = 0, but we use the
challenger again (also with b = 0).
Claim: G5 and G6 are computationally indistinguishable.
Proof: Since the simulator Sz(cid:48) from G5 uses the correct bit bi+1 = 0 for the simulated challenge (which
the simulator Sz(cid:48)(cid:48) does not simulate), Item 3c of Deﬁnition 3 implies that the games are indistinguishable.
• Game: G7 is ACSIMtranslator (Sz(cid:48)(cid:48) )(0, i + 1) where we build around the simulator Sz(cid:48)(cid:48) we an interface
translator (·) that translates the challenge tag from i+1 to 1 and vice versa in all messages (challenge, , , Ψ)
from Sz(cid:48)(cid:48) to A(A) and in all messages (answer for, , Ψ) from A(A) to Sz(cid:48)(cid:48)..
Claim: G6 and G7 are information theoretically indistinguishable.
Proof: Item 2 of Deﬁnition 3 requires that the renaming of challenge tags does not inﬂuence the behavior
of A(A). It also does not inﬂuence the behavior of the challenger (by deﬁnition) or the protocol (that never
sees challenge tags). Thus, the games are indistinguishable.
• Game: G8 is the game ACSIMtranslator (Sz(cid:48)(cid:48) )(1, i + 1) where the simulator is deﬁned as in G7 but b = 1.
Claim: G7 and G8 are (ε, δ) indistinguishable.
Proof: By assumption of the theorem, the protocol P is (1, ε, δ)-α-IND-CDP for A(A). Moreover, by
deﬁnition of z(cid:48)(cid:48) and by item 3a, the adversary translator (Sz(cid:48)(cid:48)(A)) only uses at most one challenge tag,
namely the tag 1. From the reliability property of the adversary class (item 1 of Deﬁnition 3) we know that
thus A(translator (Sz(cid:48)(cid:48) (A))) uses only the challenge tag 1. Thus, G7 and G8 are (ε, δ) indistinguishable.
• Game: G9 is ACSIMSz(cid:48)(cid:48) (1, i + 1) where we remove the translation interface again.
Claim: G8 and G9 are information theoretically indistinguishable.
Proof: As before, Item 2 of Deﬁnition 3 requires that the renaming of challenge tags does not inﬂuence the
behavior of A(A). It also does not inﬂuence the behavior of the challenger (by deﬁnition) or the protocol
(that never sees challenge tags). Thus, the games are indistinguishable.
• Game: G10 is the normal game ACREAL(1, i + 1) where b = 1.
Claim: G9 and G10 are computationally indistinguishable.
Proof: Since Sz(cid:48)(cid:48) uses the correct bit b1 = . . . = bi = 1 for all simulations, we can replace it with Szdontsim,
that, in turn, is indistinguishable from ACREAL(1, i + 1).
9
We slightly abuse notation in writing Pr [0 = A(G0)] for Pr [0 = (cid:104)A(A(n))||CH(P, α, n, 0)(cid:105)], Pr [0 = A(G1)]
for Pr [0 = (cid:104)A(Sz(b,A(n)))||CH(P, α, n, 0)(cid:105)], etc..
Pr [0 = A(G0)]
≤ Pr [0 = A(G1)] + µ1
≤ Pr [0 = A(G2)] + µ2 + µ1
≤ eiε Pr [0 = A(G3)] + eiεiδ + µ2 + µ1
≤ eiε Pr [0 = A(G4)] + eiε(µ3 + iδ) + µ2 + µ1
≤ eiε Pr [0 = A(G5)] + eiε(µ4 + µ3 + iδ) + µ2 + µ1
≤ eiε Pr [0 = A(G6)] + eiε(µ5 + µ4 + µ3 + iδ) + µ2 + µ1
= eiε Pr [0 = A(G7)] + eiε(µ5 + µ4 + µ3 + iδ) + µ2 + µ1
≤ eiε(eε Pr [0 = A(G8)] + δ) + eiε(µ5 + µ4 + µ3 + iδ) + µ2 + µ1
= e(i+1)ε Pr [0 = A(G8)] + eiε(µ5 + µ4 + µ3 + (i + 1)δ) + µ2 + µ1
= e(i+1)ε Pr [0 = A(G9)] + eiε(µ5 + µ4 + µ3 + (i + 1)δ) + µ2 + µ1
≤ e(i+1)ε Pr [0 = A(G10)] + e(i+1)εµ6 + eiε(µ5 + µ4 + µ3 + (i + 1)δ) + µ2 + µ1
≤ e(i+1)ε Pr [0 = A(G10)] + e(i+1)ε(i + 1)δ
3.4 Anonymity Notions
Finally, we are ready to present the anonymity notions for sender anonymity, recipient anonymity and relationship
anonymity.
Sender anonymity. Sender anonymity models the scenario in which a malicious recipient, which might addition-
ally control some Tor nodes, tries to determine the sender of a message. Since we are not interested in modeling
the (semantic) privacy of messages, we model that the messages do not depend on the sender.
For ease of exposition, we ﬁrst only allow challenges that consist of one single message each. We can model
this simple variant of sender anonymity, called Single Message Sender Anonymity, as follows:
αSA(s, r0 = (S0,R0, m0), r1 = (S1, , ), b)
output ((Sb,R0, m0), over)
Note that the state of the challenge is set to over. For challenges that span a whole session (consisting of
several messages) we require that within this session the sender does not change (i.e., the adversary cannot choose
a new pair of potential senders per message, but only per challenge). Subsequently, we deﬁne the anonymity
function for Session Sender Anonymity as follows.
αSSA(s, r0 = (S0,R0, m0, ), r1 = (S1, , , ), b)
if s = fresh ∨ s = (S0,S1) then
output ((Sb,R0, m0, 1), s := (S0,S1))
Recipient Anonymity.
In recipient anonymity the adversary is assumed to control the link to the Tor network,
e.g., by compromising the ISP of the user. The goal of the adversary is thus to ﬁnd out which web pages a user
visits. Similar to sender anonymity, the adversary additionally controls some Tor nodes.
Recall that in Example 2, adversary classes are needed for modeling recipient anonymity for representing the
servers and potentially the user proﬁles. Hence, recipient anonymity can only be proven for certain adversary
classes. In addition to requiring that the servers are machines and the users follow certain user proﬁles, as in
Example 2, there is an inherent insecurity for recipient anonymity.
Various so-called website ﬁngerprinting attacks [8, 18, 28] are known against the anonymous communication
service Tor that directly break recipient anonymity. In these attacks, the adversary recognizes recipient by their
trafﬁc patterns, such as direction changes or size. These attacks, however, are not speciﬁc to Tor. Every low-latency
anonymous channel is prone to these kinds of attacks. Hence, for a settings in which such website ﬁngerprinting
attacks are possible, recipient anonymity cannot hold.
As a consequence, we only consider settings in which such attacks are not possible. As a ﬁrst step, we deﬁne
an anonymity function αRA for recipient anonymity that excludes challenge messages that are of different size.
10
Similar to sender anonymity, we model the requirement that the sender is constant by always choosing the sender
S0 from the ﬁrst message.
αSRA(s, r0 = (S0,R0, m0, ), r1 = ( ,R1, m1, ), b)
if (s = fresh ∨ s = S0) ∧ |m0| = |m1| then
output ((S0,Rb, mb, 1), s := S0)
These restrictions in the anonymity function, however, do not sufﬁce. We can only deﬁne recipient anonymity
for servers, i.e., recipients, in which the response of the recipients has the same length for all messages that are of
the same length, i.e., the length of the response of a server solely depends on the length of the message.
Relationship Anonymity.
In relationship anonymity the adversary is an observer that might control some Tor
nodes and that tries to deanonymize a communication between a sender and a recipient. As both sender and recip-
ient of this communication are previously unknown to the adversary (otherwise relationship anonymity collapses
to either sender anonymity or recipient anonymity), we require a slightly more complex anonymity function:
αSRel(s, r0 = (S0,R0, m0, ), r1 = (S1,R1, , ), b)
if s = fresh then
a ← {0, 1}
else if ∃x. s = (S0,S1, x) then
a := x
if b=0 then
else
output ((Sa,Ra, m0, 1), s := (S0,S1, a))
output ((Sa,R1−a, m0, 1), s := (S0,S1, a))
In this function there are four possible scenarios for a challenge session: Each of the senders could send its
messages to each recipient and again the choice is made depending on the bit of the challenger. If b = 0, then
one message is sent, by a randomly chosen sender Sa (that is then used for the whole challenge) to the recipient
Ra that was speciﬁed for this sender by the adversary. If b = 1, the (still randomly chosen) sender Sa sends its
messages to the other recipient R1−a. The goal of the adversary is to ﬁgure out whether one of its challenges was
chosen or whether the combination of sender and recipient was swapped.
4 Modeling Tor in AnoA
We brieﬂy recall how Tor and its path selection work and then we explain how they are modeled.
4.1 The Tor’s path selection (PSTOR) algorithm
As mentioned in Section 2, nodes on circuits (or paths) in Tor are not selected (uniform) randomly. To improve the
performance, Tor’s current path selection algorithm makes a weighted random choice over all nodes that support
the user’s connections and preferences, and bases the weights on information that is retrieved from a periodically
published server descriptor and an hourly published consensus document. These documents are generated and
maintained by a small set of semi-trusted directory authorities, and contain up-to-date information about each
node.
In a server descriptor, a Tor node publishes its bandwidth, the ports it would allow as an exit node, its so-
called family (used for distributing trust), its uptime, its operating system, and its version of Tor. In order to
prevent malicious Tor nodes from equivocating (i.e., sending different information to different users), the nodes
are required to periodically upload (every 12 to 18 hours) their current server descriptor to all directory authorities.
The consensus document is computed hourly by the directory authorities, and it contains for each node in-
formation such as the node’s availability, its entrusted bandwidth, a pointer to the up-to-date server descriptor,
and whether this node should be used as an exit node and/or an entry node. Moreover, the consensus document
contains entry, middle, and exit scaling factors for every node in order to balance the bandwidth. This scaling is
necessary since there are fewer nodes that are marked as exit nodes (∼1000 in May 2014) than as entry (∼4000
in May 2014) or middle nodes (∼5000 in May 2014).
The PSTOR algorithm computes the weight of a node based on the retrieved node’s entrusted bandwidth.
Since a circuit establishment is expensive, the path selection tries to include as many of the requested ports into
one circuit as possible. Given a list of requested ports by the user, PSTOR determines the maximal set of ports that
is supported by any exit node, and then excludes all nodes that do not support this maximal set of ports and that are
not marked as exit nodes. Then, the algorithm assigns a weight to every remaining node by dividing its entrusted
11
bS := new list, only containing node
Let bS be an empty list
for node ∈ N do
if node offers more ports from c than the elements in bS then
else if ex offers exactly the same ports as the elements in bS then
exitProb(ex , [N , pf , c])
1: if (ex had an Exit tag in the latest consensus) ∧ (ex is suited for c and for pf ) then
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14: else return 0
bS := bS.append(node)
if ex offers |bS| many ports then
totalSupport := 0
for node ∈ bS do
totalSupport := totalSupport + scEx(node)
return scEx(ex )/totalSupport
else return 0
Figure 4: The computation of the exit node probabilities for Tor’s path selection algorithm
bandwidth node.bw by the sum of the entrusted bandwidths s of all not excluded nodes and multiplies this with the
corresponding exit scaling factor scEx(node) from the consensus document: node.bw/s ∗ scEx(node). Finally,
the algorithm performs a weighted random choice over these nodes.
As Tor is built upon the principle of distributing trust, the path selection excludes circuits with nodes that are
related, i.e., that are in the same /16 subnet and nodes that are in each other’s family. After having chosen the exit
node, the path selection chooses an entry node in two steps: ﬁrst, the algorithm excludes all nodes that are related
to the exit node and all nodes that are not marked as entry nodes in the current consensus; second, the algorithm
computes the weight of each of the remaining nodes by dividing their entrusted bandwidth by the sum of all not
excluded nodes and performs a weighted random choice over these nodes. For the middle node the path selection
proceeds as for the entry nodes except that middle nodes do not require speciﬁc tags. However, all relatives of
both the exit node and the entry node are excluded.
This path selection algorithm adapts to the preferences of the user, who can, e.g., decide to only use nodes
that have the ‘stable’ tag or to build circuits that only use ‘fast’ nodes. Tor’s path selection algorithm also offers a
conﬁguration for including non-valid entry or exit nodes as well as entry nodes that are not considered to be entry
guards.
4.2 The Tor protocol in extended AnoA
We base our model of Tor on our previous work that models Tor as a UC protocol ΠOR [5]. ΠOR is based on
Tor’s speciﬁcation and accurately models the key exchange, the circuit establishment, and the process of relaying
message cells over Tor.
This extension of ΠOR, which we call ΠOR
However, ΠOR abstracts from Tor’s path selection by considering a uniform path selection. In our work, we
use an extension of ΠOR, where instead of the uniform path selection the above described PSTOR algorithm is
used. This extension of ΠOR gives us a protocol on which we can base our analysis of MATOR.
(cid:48), solely extends the path selection algorithm in ΠOR and leaves
everything else untouched. We accordingly extend the ideal functionality FOR from [5], which abstracts from all
cryptographic operations in ΠOR, with Tor’s actual path selection. FOR uses a shared memory between the honest
parties and sends handles over the network instead of the onion ciphertexts that Tor sends over the network. Each
party looks up then which message corresponds to the respective handle. In this way, the adversary does not learn
more than the handles about the single messages that are sent over the network. We call the extension of the ideal
functionality FOR with Tor’s actual path selection FOR
algorithm, the UC realization proof for ΠOR and FOR applies verbatim to ΠOR
In [5] secure OR modules are deﬁned, which comprise a one-way authenticated key exchange protocol, and
secure encryption and decryption operations. Moreover, that work uses a network functionality FNETq for modeling
partially global network adversaries that compromise at most q links, a key registration functionality FREG and a
functionality for a conﬁdential and mutually authenticated channel (for modeling HTTPS connections) FSCS.
(cid:48). Since ΠOR and FOR both execute the same path selection
(cid:48) (Theorem 1).
(cid:48) and FOR
12
Proposition 1. [c.f. [5]] If ΠOR
protocol ΠOR
(cid:48) in the FREG,SCS-hybrid model securely realizes the ideal functionality FOR
(cid:48) uses secure OR modules M, then with the global functionality FNETq the resulting