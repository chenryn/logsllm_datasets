exploit. Beyond that, you might want to add components that are more pertinent to 
your environment and business processes. For this chapter's threat-modeling 
purposes, the DREAD rating system developed by Microsoft is used. No model is 
perfect, but this one provides a fairly good balance of commonly accepted threat 
characteristics. These characteristics are briefly summarized as follows: 
Damage potential What are the repercussions if the threat is exploited 
successfully? 
Reproducibility How easy is it to reproduce the attack in question? 
Exploitability How difficult is it to perform the attack? 
Affected users If a successful attack is carried out, how many users would be 
affected and how important are they? 
Discoverability How difficult is it to spot the vulnerability? 
Each category can be given a score between 1 and 10 (1 being the lowest, 10 the 
highest). Category scores are then totaled and divided by 5 for an overall threat 
rating. A rating of 3 or below can be considered a low-priority threat, 4 to 7 as a 
medium-priority threat, and 8 or greater as a high-priority threat. 
Note 
The Art of Software Security Assessment - Identifying and Preventing Software Vulnerabilities 
77 
The DREAD model is also useful in rating implementation and operational 
vulnerabilities. In fact, you can use DREAD as your general-purpose rating system 
over the entire course of an application review. 
One of the benefits of the DREAD rating system is that it provides a range of detail you 
can use when presenting results to business decision makers. You can give them a 
concise threat assessment, with just the total threat rating and the category it falls 
into. You could also present more detailed information, such as individual scores for 
the five threat categories. You might even want to give them a full report, including 
the model documentation and an explanation of how you arrived at the scores for 
each category. Regardless of your choice, it's a good idea to have information 
available at each level of detail when making a presentation to clients or senior 
management. 
Table 2-2 is an example of applying a DREAD rating to the brute-force login threat. 
Table 2-2. Threat Summary with DREAD Rating 
Threat 
Brute-force login. 
Affected 
Component 
Web application login component. 
Description 
Clients can brute-force attack usernames and passwords by 
repeatedly connecting and attempting to log in. This threat is 
increased because the application returns a different error message 
for an invalid username than a valid one, making usernames easier to 
identify. 
Result 
Untrusted clients can gain access to a user account and, therefore, 
read or modify sensitive information. 
Mitigation 
Strategies 
Make error messages ambiguous so that an attacker doesn't know 
whether the username or password is invalid. Lock the user account 
after repeated failed login attempts. (Three to five attempts would be 
appropriate.) 
Risk 
Damage potential: 6 
Reproducibility: 8 
Exploitability: 4 
Affected users: 5 
The Art of Software Security Assessment - Identifying and Preventing Software Vulnerabilities 
78 
Table 2-2. Threat Summary with DREAD Rating 
Threat 
Brute-force login. 
Discoverability: 8 
Overall: 6.2 
Automatic Threat-Modeling Documentation 
As you can see, quite a lot of documentation is involved in the threat-modeling 
process (both text and diagrams). Thankfully, Frank Swiderski (co-author of the 
previously mentioned Threat Modeling) has developed a tool to help with creating 
various threat-modeling documents. It's available as a free download at 
http://msdn.microsoft.com/security/securecode/threatmodeling/. The tool makes it 
easy to create DFDs, use cases, threat summaries, resource summaries, 
implementation assumptions, and many other documents you're going to need. 
Furthermore, the documentation is organized into a tree structure that's easy to 
navigate and maintain. The tool can output all your documentation as HTML or 
another output form of your choosing, using Extensible Stylesheet Language 
Transformations (XSLT) processing. Familiarizing yourself with this tool for 
threat-modeling documentation is strongly recommended. 
Prioritizing the Implementation Review 
Now that you've completed and scored your threat summaries, you can finally turn 
your attention to structuring the implementation review. When developing your 
threat model, you should have decomposed the application according to a variety of 
factors, including modules, objects, and functionality. These divisions should be 
reflected in the Affected Components entry in each individual threat summary. The 
next step is to make a list of components at the appropriate level of decomposition; 
exactly what level is determined by the size of the application, number of reviewers, 
time available for review, and similar factors. However, it's usually best to start at a 
high level of abstraction, so you only need to consider a handful of components. In 
addition to the component names, you need another column on your list for risk 
scores associated with each component. 
After you have this component list, you simply identify which component a threat 
summary belongs to and add the risk score for that summary to the associated 
component. After you've totaled your list of summaries, you'll have a score for the 
risk associated with each component. Generally, you want to start your assessment 
with the highest scoring component and continue proceeding from highest to lowest. 
You might also need to eliminate some components due to time, budget, or other 
constraints. So it's best to start eliminating from the lowest scoring components. You 
can apply this scoring process to the next level of decomposition for a large 
The Art of Software Security Assessment - Identifying and Preventing Software Vulnerabilities 
79 
application; although that starts to get into the implementation review process, which 
is covered in detail in Chapter 4(? [????.]), "Application Review Process." 
Using a scoring list can make it a lot easier to prioritize a review, especially for a 
beginner. However, it isn't necessarily the best way to get the job done. An 
experienced auditor will often be able to prioritize the review based on their 
understanding of similar applications. Ideally, this should line up with the threat 
summary scores, but sometimes that isn't the case. So it's important to take the 
threat summaries into account, but don't cling to them when you have a reason to 
follow a better plan. 
6.2.5 Summary 
This chapter has examined the essential elements of application design review. 
You've seen that security needs to be a fundamental consideration in application 
design and learned how decisions made in the design process can dramatically affect 
an application's security. You have also learned about several tools for understanding 
the security and vulnerability potential of an application design. 
It's important that you not treat the design review process as an isolated component. 
The results of the design review should progress naturally into the implementation 
review process, discussed in depth in Chapter 4(? [????.]). 
6.3 Chapter 3.  Operational Review 
"Civilization advances by extending the number of important operations which we can 
perform without thinking." 
6.3.1 Introduction 
Operational vulnerabilities are the result of issues in an application's configuration or 
deployment environment. These vulnerabilities can be a direct result of configuration 
options an application offers, such as default settings that aren't secure, or they 
might be the consequence of choosing less secure modes of operation. Sometimes 
these vulnerabilities are caused by a failure to use platform security measures 
properly, such as file system and shared object permissions. Finally, an operational 
vulnerability could be outside the developer's direct control. This problem occurs 
when an application is deployed in a manner that's not secure or when the base 
platform inherits vulnerabilities from the deployment environment. 
The responsibility for preventing these vulnerabilities can fall somewhere between 
the developer and the administrative personnel who deploy and maintain the system. 
Shrink-wrapped commercial software might place most of the operational security 
The Art of Software Security Assessment - Identifying and Preventing Software Vulnerabilities 
80 
burden on end users. Conversely, you also encounter special-purpose systems, 
especially embedded devices and turnkey systems, so tightly packaged that 
developers control every aspect of their configuration. 
This chapter focuses on identifying several types of operational vulnerabilities and 
preventive measures. Concrete examples should help you understand the subtle 
patterns that can lead to these vulnerabilities. The goal is to help you understand how 
to identify these types of vulnerabilities, not present an encyclopedia of potential 
issues. Technologies are varied and change often, but with a little practice, you 
should be able to spot the commonalities in any operational vulnerability, which helps 
you establish your own techniques for identifying vulnerabilities in the systems you 
review. 
6.3.2 Exposure 
When reviewing application security, you need to consider the impact of the 
deployment environment. This consideration might be simple for an in-house 
application with a known target. Popular commercial software, on the other hand, 
could be deployed on a range of operating systems with unknown network profiles. 
When considering operational vulnerabilities, you need to identify these concerns and 
make sure they are adequately addressed. The following sections introduce the 
elements of an application's environment that define its degree of exposure to various 
classes of users who have access to and, therefore, are able to attack the application. 
Attack Surface 
Chapter 2(? [????.]), "Design Review," covered the threat-modeling concepts of 
assets and entry points. These concepts can be used to define an application's attack 
surface, the collection of all entry points that provide access to an asset. At the 
moment, how this access is mitigated isn't a concern; you just need to know where 
the attack surface is. 
For the purposes of this chapter, the discussions of trust models and threats have 
been simplified because operational vulnerabilities usually occur when the attack 
surface is exposed unnecessarily. So it helps to bundle the complexities into the 
attack surface and simply look for where it can be eliminated. 
The actual process of minimizing the attack surface is often referred to as "host 
hardening" or "application hardening." Hardening specific platforms isn't covered in 
this book, as better resources are dedicated to hardening a particular platform. 
Instead, this chapter focuses on several general operational vulnerabilities that occur 
because software deployment and configuration aren't secure. 
Insecure Defaults 
The Art of Software Security Assessment - Identifying and Preventing Software Vulnerabilities 
81 
Insecure defaults are simply preconfigured options that create an unnecessary risk 
in a deployed application. This problem tends to occur because a software or device 
vendor is trying to make the deployment as simple and painless as possiblewhich 
brings you back to the conflict between usability and security. 
Any reader with a commercial wireless access point has probably run into this same 
issue. Most of these devices are preconfigured without any form of connection 
security. The rationale is that wireless security is buggy and difficult to configure. 
That's probably true to an extent, but the alternative is to expose your wireless 
communications to anyone within a few hundred yards. Most people would rather 
suffer the inconvenience of struggling with configuration than expose their wireless 
communications. 
As a reviewer, two types of vulnerable default settings should concern you the most. 
The first is the application's default settings, which include any options that can 
reduce security or increase the application's attack surface without the user's explicit 
consent. These options are discussed in more detail in the remainder of this chapter, 
but a few obvious installation considerations are prompting for passwords versus 
setting defaults, enabling more secure modes of communication, and enforcing 
proper access control. 
You also need to consider the default settings of the base platform and operating 
system. Examples of this measure include ensuring that the installation sets 
adequate file and object permissions or restricting the verbs allowed in a Web request. 
The process can get a bit complicated if the application is portable across a range of 
installation targets, so be mindful of all potential deployment environments. In fact, 
one of main contributors to insecure defaults in an application is that the software is 
designed and built to run on many different operating systems and environments; a 
safe setting on one operating system might not be so safe on another. 
Access Control 
Chapter 2(? [????.]) introduced access control and how it affects an application's 
design. The effects of access control, however, don't stop at the design. Internally, an 
application can manage its own application-specific access control mechanisms or use 
features the platform provides. Externally, an application depends entirely on the 
access controls the host OS or platform provides (a subject covered in more depth 
later in Chapter 9(? [????.]), "Unix I: Privileges and Files," and Chapter 11(? [????.]), 
"Windows I: Objects and the File System"). 
Many developers do a decent amount of scripting; so you probably have a few 
scripting engines installed on your system. On a Windows system, you might have 
noticed that most scripting installations default to a directory right off the root. As an 
example, in a typical install of the Python interpreter on a Windows system, the 
default installation path is C:\Python24, so it's installed directly off the root directory 
The Art of Software Security Assessment - Identifying and Preventing Software Vulnerabilities 
82 
of the primary hard drive (C:). This installation path alone isn't an issue until you take 
into account default permissions on a Windows system drive. These permissions allow 
any user to write to a directory created off the root (permission inheritance is 
explained in more detail in Chapter 11(? [????.])). Browsing to C:\Python24, you find 
python.exe (among other things), and if you look at the imported dynamic link 
libraries (DLLs) that python.exe uses, you find msvcr71.dll listed. 
Note 
For those unfamiliar with basic Windows binary layout, an import is a required library 
containing routines the application needs to function correctly. In this example, 
python.exe needs routines implemented in the msvcr71 library. The exact functions 
python.exe requires are also specified in the imports section. 
Chapter 11(? [????.]) explains the particulars of how Windows handles imported. 
What's important to this discussion is that you can write your own msvcr71.dll and 
store it in the C:\Python24 directory, and then it's loaded when anyone runs 
python.exe. This is possible because the Windows loader searches the current 
directory for named DLLs before searching system directories. This Windows feature, 
however, could allow an attacker to run code in the context of a higher privileged 
account, which would be particularly useful on a terminal server, or in any shared 
computing environment. 
You could have the same problem with any application that inherits permissions from 
the root drive. The real problem is that historically, Windows developers have often 
been unaware of the built-in access control mechanisms. This is only natural when 
you consider that Windows was originally a single-user OS and has since evolved into 
a multiuser system. So these problems might occur when developers are unfamiliar 
with additional security considerations or are trying to maintain compatibility 
between different versions or platforms. 
Unnecessary Services 
You've probably heard the saying "Idle hands are the devil's playthings." You might 
not agree with it in general, but it definitely applies to unnecessary services. 
Unnecessary services include any functionality your application provides that isn't 
required for its operation. These capabilities often aren't configured, reviewed, or 
secured correctly. 
These problems tend to result from insecure default settings but might be caused by 
the "kitchen sink mentality," a term for developers and administrators who include 
every possible capability in case they need it later. Although this approach might 
seem convenient, it can result in a security nightmare. 
The Art of Software Security Assessment - Identifying and Preventing Software Vulnerabilities 
83 
When reviewing an application, make sure you can justify the need for each 
component that's enabled and exposed. This justification is especially critical when 
you're reviewing a deployed application or turnkey system. In this case, you need to 
look at the system as a whole and identify anything that isn't needed. 
The Internet Information Services (IIS) HTR vulnerabilities are a classic example of 
exposing a vulnerable service unnecessarily. HTR is a scripting technology Microsoft 
pioneered that never gained much following, which can be attributed to the release of 
the more powerful Active Server Pages (ASP) shortly after HTR. Any request made to 
an IIS server for a filename with an .htr extension is handled by the HTR Internet 
Server API (ISAPI) filter. 
Note 
ISAPI filters are IIS extension modules that can service requests based on file 
extensions. 
From 1999 through 2002, a number of researchers identified HTR vulnerabilities 
ranging from arbitrary file reading to code execution. None of these vulnerabilities 
would have been significant, however, if this rarely used handler had simply been 
disabled in the default configuration. 
Secure Channels 
A secure channel is any means of communication that ensures confidentiality 
between the communicating parties. Usually this term is used in reference to 
encrypted links; however, even a named pipe can be considered a secure channel if 
access control is used properly. In either case, what's important is that only the 
correct parties can view or alter meaningful data in the channel, assuming, of course, 
that the parties have already been authenticated by some means. 
Sometimes the need for secure channels can be determined during the design of an 
application. You might know before deployment that all communications must be 
conducted over secure channels, and the application must be designed and 
implemented in this way. More often, however, the application design must account 
for a range of possible deployment requirements. 
The most basic example of a secure channel vulnerability is simply not using a secure 
channel when you should. Consider a typical Web application in which you 
authenticate via a password, and then pass a session key for each following 
transaction. (This topic is explained in more detail in Chapter 17(? [????.]), "Web 
Applications.") You expect password challenges to be performed over Secure Sockets 
Layer (SSL), but what about subsequent exchanges? After all, attackers would like to 
The Art of Software Security Assessment - Identifying and Preventing Software Vulnerabilities 
84 
retrieve your password, but they can still get unrestricted access to your session if 
they get the session cookie. 
This example shows that the need for secure channels can be a bit subtle. Everyone 
can agree on the need to protect passwords, but the session key might not be 
considered as important, which is perfectly acceptable sometimes. For example, most 
Web-based e-mail providers use a secure password exchange, but all remaining 
transactions send session cookies in the clear. These providers are offering a free 
service with a minimal guarantee of security, so it's an acceptable business risk. For 
a banking application, however, you would expect that all transactions occur over a 
secure channel. 
Spoofing and Identification 
Spoofing occurs whenever an attacker can exploit a weakness in a system to 
impersonate another person or system. Chapter 2(? [????.]) explained that 
authentication is used to identify users of an application and potentially connected 
systems. However, deploying an application could introduce some additional 
concerns that the application design can't address directly. 
The TCP/IP standard in most common use doesn't provide a method for preventing 
one host from impersonating another. Extensions and higher layer protocols (such as 
IPsec and SSL) address this problem, but at the most basic level, you need to assume 
that any network connection could potentially be impersonated. 
Returning to the SSL example, assume the site allows only HTTPS connections. 
Normally, the certificate for establishing connections would be signed by a trusted 
authority already listed in your browser's certificate database. When you browse to 
the site, the name on the certificate is compared against the server's DNS name; if 
they match, you have a reasonable degree of certainty that the site hasn't been 
spoofed. 
Now change the example a bit and assume that the certificate isn't signed by a default 
trusted authority. Instead, the site's developer has signed the certificate. This 
practice is fairly common and perfectly acceptable if the site is on a corporate intranet. 
You simply need to ensure that every client browser has the certificate added to its 
database. 
If that same site is on the public Internet with a developer-signed certificate, however, 