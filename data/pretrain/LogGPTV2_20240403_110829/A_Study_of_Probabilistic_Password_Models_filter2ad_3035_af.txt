29.3
27.8
27.5
27.8
28.1
29.9
29.3
27.8
27.5
27.8
28.1
30.0
29.2
27.8
28.7
32.3
30.0
29.3
28.0
27.2
27.1
dir
28.8
29.3
31.9
31.1
29.6
29.3
30.1
31.9
31.1
29.6
29.3
29.6
29.9
31.8
31.1
29.6
29.2
29.5
29.9
31.9
31.1
29.6
30.5
34.1
31.9
31.2
29.8
29.0
28.9
end
27.0
27.6
31.1
30.2
28.5
28.1
29.2
31.1
30.2
28.6
28.0
28.5
29.1
31.1
30.2
28.5
28.0
28.5
29.1
31.1
30.2
28.6
29.3
33.8
31.1
30.3
28.8
27.9
27.6
6: Rock→CSDN
dis
22.9
23.0
23.0
22.5
22.1
22.4
23.4
23.1
22.6
22.2
22.4
23.1
25.5
23.0
22.4
22.1
22.2
23.0
25.4
23.0
22.5
22.1
22.8
25.7
23.0
22.6
22.2
22.0
22.1
dir
23.9
24.1
24.2
23.6
23.2
23.4
24.4
24.2
23.7
23.3
23.4
24.2
26.7
24.1
23.6
23.2
23.3
24.1
26.5
24.2
23.6
23.2
23.8
26.8
24.2
23.7
23.3
23.1
23.3
end
22.5
22.6
24.1
23.3
22.8
22.9
23.9
24.1
23.4
22.9
22.9
23.6
26.2
24.0
23.3
22.8
22.8
23.5
26.1
24.1
23.3
22.8
23.4
26.5
24.0
23.4
22.9
22.6
22.6
(compared to 45% for CSDN and 19.5% for Duduniu; recall
that passwords in CSDN tend to be signiﬁcantly longer).
symbols, uppercase are used and where they appear when
computing the entropy, was developed in [22].
VI. RELATED WORK
One active research area in recent years is to study the
quality of users’ password choices under different scenarios,
e.g., when facing different password policies [18], [17], when
presented with different password strength meters [23], [10],
when forced to change passwords due to organizational change
of password policies [22], when forced to change passwords
due to expiration [26], and when “persuaded” to include extra
randomness in their password choices [12]. In a similar study,
Mazurek et al. [20] collected over 25,000 real passwords from
CMU and studied passwords from different groups of users.
In this area, earlier work uses a combination of standard
password cracking tools such as John the Ripper (JTR) [3] and
ad hoc approaches for estimating the information entropy of a
set of passwords. One such approach is NIST’s recommended
scheme for estimating the entropy of one password, which is
mainly based on their length [7]. Florencio and Herley [11],
Forget et al. [12], and Egelman et al. [10] all use the formula
where the bit strength of a password is considered to be
log2((alpha. size)len ); for example, a 9-character password that
contains both upper and lower case characters and digits is
considered to have bit strength of log2(26+26+10)9 ≈ 53.59.
This clearly overestimates the strength of passwords. A more
sophisticated approach, which considers how many numbers,
Weir et al. developed the PCFGW model [25] and argued
that entropy estimation methods such as that recommended
by NIST are inaccurate [24]. Instead, they propose to use the
guess number of passwords. The combination of the PCFGW
model or its variants and guess numbers becomes the standard
method in password security research in recent years [17],
[18], [15], [23], [20]. Our research suggests that probability-
threshold graphs are a better tool than guess number graphs,
and Markov chain based models are likely to offer better
choices than the PCFGW model.
John the Ripper [3], one of the most popular password
cracking tools, has several modes for generating password
guesses. The wordlist mode uses a dictionary plus various
mangling rules. The incremental mode uses trigraph frequen-
cies, i.e., frequencies for the triple of character, position, and
password length. The Markov mode uses Markov chains of
order 1. Narayanan and Shmatikov [21] proposed a template-
based model, with Markov chain being used for assign-
ing probability to letter-based segments. Experimental results
show that
these approaches all signiﬁcantly underperform
higher-order or variable-order Markov models.
Castelluccia et al. [8] proposed to use whole-string Markov
models for evaluating password strengths. Our work differs in
that we evaluate the performance of this model and compare
700
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:59:45 UTC from IEEE Xplore.  Restrictions apply. 
it with a large number of other models in a design space using
our methodology. Dell’Amico et al. [9] compared the cracking
effectiveness of Markov models on the “Italian”, “Finnish”,
and “MySpace” datasets by computing the estimated proba-
bilities for each password in the datasets and using an approx-
imation algorithm to compute the number of guesses for each
threshold. They did not consider normalization, smoothing,
etc. Furthermore, their results show very small search spaces
for higher Markov models, which seems to suggest that their
approximation algorithm underestimates the search space.
Malone and Maher [19] investigated how well password
distributions ﬁt the zipf distribution. They ﬁtted the Rockyou
1
rb for b = 0.7878. Examining
dataset to a zipf distribution
the ﬁgures in [19] one can see that this ﬁts well only for
passwords of rank between 26
. Bonneau [5] also
explored the relationships between password distributions and
zipf distributions.
and 220
Bonneau [6] criticized the comparability and repeatability
of past password cracking results using tools such as John the
ripper and/or dictionaries. He proposed metrics for studying
the overall level of security in large password datasets, based
only on the distribution, and not on the actual password strings.
This work is thus largely orthogonal to ours. The metrics in [6]
cannot be effectively applied to evaluating the security of a
single, or a small dataset collected under a given scenario. We
believe that our approach of using standard Markov models
also corrects many of limitations identiﬁed in [6].
VII. CONCLUSIONS
We make three contributions in this paper. The ﬁrst is to
introduce probability-threshold graphs for evaluating password
datasets. The second is to introduce knowledge and techniques
from the rich literature of statistical language modeling into
password modeling. We also identify new issues (such as nor-
malization) that arise from modeling passwords, and a broad
design space for password models, including both whole-string
models and template-based models. Third, we have conducted
a systematic study of many password models, and obtained a
number of ﬁndings. In particular, we show that the PCFGW
model, which has been assumed to be the state of the art and
has been widely used in password research, underperforms
whole-string Markov models in our experiments. We expect
that the new methodology and knowledge of effectiveness of
Markov models can beneﬁt future password research.
Acknowledgement. This paper is based upon work supported
by the United States National Science Foundation under
Grants No. 1314688 and 0963715, and by by United States
Army Research Ofﬁce Award 2008-0845-04 through North
Carolina State University.
We would also like to thank Lujo Bauer, shepherd for this
paper, and other reviewers for their helpful comments, which
guided us revise and improve the paper.
REFERENCES
[1] Passwords, 2009. http://wiki.skullsecurity.org/Passwords.
[2] Csdn cleartext passwords, 2011. http://dazzlepod.com/csdn/.
[3] John the ripper password cracker, 2013. http://www.openwall.com/john/.
[4] Openwall
2013.
collection,
wordlists
http://www.openwall.com/wordlists/.
[5] J. Bonneau. Guessing human-chosen secrets. Thesis, University of
Cambridge, 2012.
[6] J. Bonneau. The science of guessing: analyzing an anonymized corpus
of 70 million passwords. In Proceedings of IEEE Symposium on Security
and Privacy, pages 538–552. IEEE, 2012.
[7] W. E. Burr, D. F. Dodson, and W. T. Polk. Electronic authentication
guideline. US Department of Commerce, Technology Administration,
National Institute of Standards and Technology, 2004.
[8] C. Castelluccia, M. D ¨urmuth, and D. Perito. Adaptive password-strength
meters from Markov models. In Proceedings of NDSS, 2012.
[9] M. Dell’Amico, P. Michiardi, and Y. Roudier. Password strength: an
empirical analysis. In Proceedings of INFOCOM, pages 1–9, 2010.
[10] S. Egelman, A. Sotirakopoulos, I. Muslukhov, K. Beznosov, and C. Her-
ley. Does my password go up to eleven?: The impact of password meters
on password selection. In Proceedings of CHI, pages 2379–2388, 2013.
[11] D. Florencio and C. Herley. A large-scale study of web password habits.
In Proceedings of WWW, pages 657–666, 2007.
[12] A. Forget, S. Chiasson, P. C. van Oorschot, and R. Biddle. Improving
In Proceedings of SOUPS, pages
text passwords through persuasion.
1–12, 2008.
[13] W. A. Gale and G. Sampson. Good-turing frequency estimation without
tears. Journal of Quantitative Linguistics, 2(1):217–237, 1995.
[14] C. Herley and P. C. van Oorschot. A research agenda acknowledging
IEEE Security & Privacy, 10(1):28–36,
the persistence of passwords.
2012.
[15] S. Houshmand and S. Aggarwal. Building better passwords using
In Proceedings of ACSAC, pages 109–118,
probabilistic techniques.
2012.
[16] S. M. Katz.
Estimation of probabilities from sparse data for the
language model component of a speech recogniser. IEEE Transactions
on Acoustics, Speech, and Signal Processing, 35(3):400401, 1987.
[17] P. G. Kelley, S. Komanduri, M. L. Mazurek, R. Shay, T. Vidas, L. Bauer,
N. Christin, L. F. Cranor, and J. Lopez. Guess again (and again and
again): Measuring password strength by simulating password-cracking
algorithms. In IEEE Symposium on Security and Privacy, pages 523–
537, 2012.
[18] S. Komanduri, R. Shay, P. G. Kelley, M. L. Mazurek, L. Bauer,
N. Christin, L. F. Cranor, and S. Egelman. Of passwords and people:
measuring the effect of password-composition policies. In CHI, pages
2595–2604, 2011.
[19] D. Malone and K. Maher.
Investigating the distribution of password
choices. In Proceedings of WWW, pages 301–310, 2012.
[20] M. L. Mazurek, S. Komanduri, T. Vidas, L. Bauer, N. Christin, L. F.
Cranor, P. G. Kelley, R. Shay, and B. Ur. Measuring password
guessability for an entire university. In Proceedings of ACM CCS, pages
173–186, Berlin, Germany, 2013. ACM.
[21] A. Narayanan and V. Shmatikov. Fast dictionary attacks on passwords
using time-space tradeoff. In Proceedings of ACM CCS, pages 364–372,
2005.
[22] R. Shay, S. Komanduri, P. G. Kelley, P. G. Leon, M. L. Mazurek,
L. Bauer, N. Christin, and L. F. Cranor. Encountering stronger password
requirements: user attitudes and behaviors. In Proceedings of the Sixth
Symposium on Usable Privacy and Security, SOUPS ’10, pages 2:1–
2:20, New York, NY, USA, 2010. ACM.
[23] B. Ur, P. G. Kelley, S. Komanduri, J. Lee, M. Maass, M. Mazurek,
T. Passaro, R. Shay, T. Vidas, L. Bauer, et al. How does your password
measure up? the effect of strength meters on password creation.
In
Proceedings of USENIX Security Symposium, 2012.
[24] M. Weir, S. Aggarwal, M. Collins, and H. Stern. Testing metrics
for password creation policies by attacking large sets of revealed
passwords. In Proceedings of the 17th ACM conference on Computer
and communications security, pages 162–175, 2010.
[25] M. Weir, S. Aggarwal, B. de Medeiros, and B. Glodek. Password
cracking using probabilistic context-free grammars. In IEEE Symposium
on Security and Privacy, pages 391–405, 2009.
[26] Y. Zhang, F. Monrose, and M. K. Reiter. The security of modern
password expiration: An algorithmic framework and empirical analysis.
In Proceedings of ACM CCS, pages 176–186, 2010.
701
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:59:45 UTC from IEEE Xplore.  Restrictions apply. 
(a) Rank vs. probability: (x, y) denotes the 2x most likely password has
probability 1
2y ; dashed lines are y = x + 3 and y = x + 8
(b) Guess-number graph: (x, y) denotes 2x guesses cover y portion of the
dataset
threshold: for guess-number
(c) Superimposing guess number and prob.
curves, x stands for 2x guesses; for threshold curves, x stands for probability
threshold 1
2x ; dic-0294 is used as dictionary for PCFGW
(d) Prob. threshold graph for comparing template-based models (including
PCFGW )
(e) Prob. threshold graph for comparing the effect of smoothing, all with
end-based normalization
(f) Prob. threshold graph for comparing Markov of different orders; with end-
based normalization and add-δ smoothing
(g) Prob. threshold graph for comparing the effect of normalization
(h) Prob. threshold graph for passwords with length no less than 8; comparing
template-based models (including PCFGW )
Fig. 2: Experiment result of Scenario 1: Rock→Ya+Ph.
702
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:59:45 UTC from IEEE Xplore.  Restrictions apply. 
(a) Rank vs. probability: (x, y) denotes the 2x most likely password has
probability 1
2y ; dashed lines are y = x + 3 and y = x + 8
(b) Guess-number graph: (x, y) denotes 2x guesses cover y portion of the
dataset
(c) Superimposing guess number and prob. threshold: for cracking curve, x
stands for 2x guesses; for threshold curve, x stands for probability threshold
2x ; dic-0294 is used as dictionary for PCFGW
1
(d) Prob. threshold graph for comparing template-based models (including
PCFGW )
(e) Prob. threshold graph for comparing the effect of smoothing, all with
end-based normalization
(f) Prob. threshold graph for comparing Markov of different orders; with end-
based normalization and add-δ smoothing
(g) Prob. threshold graph for comparing the effect of normalization
(h) Prob. threshold graph for passwords with length no less than 8; comparing
template-based models (including PCFGW )
Fig. 3: Experiment results for Scenario 2: Du+178→CSDN.
703
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:59:45 UTC from IEEE Xplore.  Restrictions apply. 
(a) Scenario 3: CS+178→Dudu: Prob.
template-based models (including PCFGW )
threshold graph for comparing
(b) Scenario 3: CS+178→Dudu: Guess-number graph. (x, y) denotes 2x
guesses cover y portion of the dataset
(c) Scenario 4: CS+Du→178: Prob. threshold graph for comparing template-
based models (including PCFGW )
(d) Scenario 4: CS+Du→178: Guess-number graph. (x, y) denotes 2x
guesses cover y portion of the dataset
(e) Scenario 5: Chin→Ya+Ph: Prob. threshold graph for comparing template-
based models (including PCFGW )
(f) Scenario 5: Chin→Ya+Ph: Guess-number graph. (x, y) denotes 2x guesses
cover y portion of the dataset
(g) Scenario 6: Rock→CSDN: Prob. threshold graph for comparing template-
based models (including PCFGW )
(h) Scenario 6: Rock→CSDN: Guess-number graph. (x, y) denotes 2x
guesses cover y portion of the dataset
Fig. 4: Experiment result for Scenarios 3, 4, 5, 6.
704
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:59:45 UTC from IEEE Xplore.  Restrictions apply.