results in 𝑡10 were insecure.
KEY— We see slightly different results for KEY due to the selec-
tion of 𝑏𝑠. It trades off higher probability of secure best-practice
results to ensure that insecure results have lower probability than
secure results across the board. This decision had an effect on the
distributions for KEY.
𝐵(10, 0.047) of boosted secure best-practice results, as shown
in Figure 4, (KEY, 𝑡10, green), shows a probability of 33.14% for at
least one result, 8.99% for two results, and 1.4% for three results
in 𝑡10. 𝐵(10, 0.094) of boosted secure results, shown in Figure 4,
(KEY, 𝑡10, blue), revealed a higher probability of one secure result
to appear in 𝑡10 with 37.47%, 22.52% for two, and 7.95% for three
results. The distribution of boosted secure results slightly increased
in comparison to non-boosted secure results shown in Figure 2.
The distribution 𝐵(10, 0.007) shown in Figure 4, (KEY, 𝑡10, red)
for boosted insecure results {𝑐𝑠𝑒𝑏𝑖 (𝑞)}𝑞∈𝑄𝑘𝑒𝑦 , largely decreased in
comparison to non-boosted insecure results shown in Figure 2. For
at least one result in 𝑡10, probability decreased from 37.35% to 9.32%,
and from 15.22% to 0% for two results. Further, there is a chance
of 95.22% that none of the results are insecure, which was 43% for
non-boosted secure results.
CIPHER— The distribution 𝐵(10, 0.062) of boosted secure re-
sults {𝑐𝑠𝑒𝑏𝑠 (𝑞)}𝑞∈𝑄𝑐𝑖𝑝 over 𝑡10, shown in Figure 4, (CIPHER, 𝑡10,
blue), is slightly higher than the respective distribution for IV and
slightly lower than the one for KEY. The probability of at least one
secure result in 𝑡10 increased from 21.06% to 36.76%, from 2.71%
to 12.64% for two results, and from 0.24% to 2.19% for three, in
comparison with non-boosted secure results from Figure 2. There
is 0% chance that one of the results is insecure, which was 37.77%
before, while the chances for no insecure results increased from
44.41% to 100%.
Summary— We have shown that the new distributions of boosted
results show the required relative probabilities. Secure best-practice
results have the highest distribution, secure results the second high-
est, and insecure results very low probabilities to appear in the top
results. However, we observed one exception. Secure best-practice
results for KEY actually have a lower distribution than secure re-
sults. This is due to the boosting trade-off that ensures that insecure
results have the lowest probabilities across the board.
We have shown how clustering of secure best-practice results
and boosting helps to perform security-based re-ranking. In the
next step, we had to test whether the original ranking by 𝑐𝑠𝑒 and
the re-ranking by 𝑐𝑠𝑒𝑏 actually had an effect on code security. In
other words, would we observe different results with respect to
code security if developers solved a programming task with the
help of Google Search, while one group used 𝑐𝑠𝑒 and the other one
𝑐𝑠𝑒𝑏?
6.1 Setup
We used the online study framework Developer Observatory [43]
to perform the study. It provides ready-to-use study templates, an
online code editor, tracking functions, and security features.
Participants were first presented with a landing page that pro-
vided an overview of the study, followed by a consent form and an
explanation about the online code editor and a Jupyter notebook
that was given to solve the tasks. The notebook gave an introduc-
tion and overview of the tasks, followed by text/code cell pairs
that described each task and provided code skeletons to solve them
(see Figure 5). Each of the tasks could be run and solved indepen-
dently from each other. To provide participants the opportunity
to verify that all three tasks were solved functionally correct, the
notebook provided a code cell to run and test the given solutions.
The notebook applied a Java 8 kernel to execute code cells.
Participants were instructed to solve each task using the provided
Google Search bar to look for help online. They were randomly
assigned to one of our conditions. If assigned to the treatment
group, the search bar was run by 𝑐𝑠𝑒𝑏, which applied security-
based re-ranking, as explained in Section 5. Participants that were
assigned to the control group used 𝑐𝑠𝑒, Google’s default search
engine. We provided the respective link to each search bar in the
introduction section of the notebook. The search bar was opened
in a new browser tab.
Figure 5: Example task from Study 2
6.2 Results
(a) Security
(b) Functional Correctness
Figure 6: Interaction plots (number of searches above and
below median Quantile Q2)
6 STUDY 2: IMPACT OF RANKING ON CODE
SECURITY
We performed an online study where participants were presented
the same tasks from Study 1, i.e., CIPHER, IV, and KEY. This time
they not only had to search for potential solutions online but also
had to write small Java programs in order to solve them.
Search Depth— In order to evaluate whether our treatment
helped in writing functional and secure code, we first investigated
to what extent the search engine was actually used to solve the
tasks. Participants may have not used the search engine at all, or
performed very few searches for only a subset of tasks. In contrast,
they may have used the search engine extensively.
Session 11C: Software Development and Analysis CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea3078Security
MS3
MS4
MF1
Functionality
MF2
MF3
MS2
0.256
(0.210)
-
0.106*
(0.052)
-
0.004
(0.210)
-
0.004*
(0.001)
-
-
0.062
(0.244)
0.125*
(0.058)
-
-
1.241***
(0.221)
-1.312***
(0.223)
-1.283***
(0.0226)
-1.246***
(0.226)
-1.272***
(0.224)
-1.343***
(0.225)
-0.485*
(0.214)
-
-0.902***
(0.238)
-
-
-1.149**
(0.333)
-0.784**
(0.267)
-0.575*
(0.271)
0.296***
(0.076)
-
-0.767**
(0.225)
-0.560*
(0.268)
MF4
-1.251***
(0.283)
0.307***
(0.080)
-
-
-0.753**
(0.261)
-0.550*
(0.265)
-0.564*
(0.256)
-
0.002
(0.002)
-
-
-1.008***
(0.286)
-0.521
(0.303)
Condition: Treatment
Condition × Searches†
Condition × Votes†
Secure ∪ Best-Practice Results†
No Searches Performed
Task: IV
Task: Key
MS1
0.083
(0.181)
-
-
-0.587
(0.373)
-1.254***
(0.223)
-1.325***
(0.223)
Table 2: Logistic regression results for SECURITY and FUNCTIONALITY. Significant values are highlighted in bold, and
marked with: +p<0.1, *p<0.05, **p<0.01, and ***p<0.001. Standard errors are included in parentheses. Variables marked with †
are average counts per task.
More specifically, we expected an interaction effect between the
number of searches and condition (i. e., control vs. treatment) on
the security and functional correctness of submitted solutions. The
number of searches was the average number of performed search
queries per task. An interaction plot shows the relationship of the
two observed variables Searches and Condition. We show the two
relevant interaction plots in Figures 6a and 6b.
Figure 6a indicates the interaction effect between Condition and
Searches on the mean of secure solutions (Max: 3 secure solutions
per participant). It shows a red line which represents the median
Quantile 𝑄2 of Searches and a blue line which represents Searches
above 𝑄2. The left side of each line represents the results from the
control group and the right side the results of the treatment group.
Interaction plots indicate an interaction effect within a condition if
their points (diamond and triangle) are far away from each other
on the y-axis. This allows to easily spot differences between the
conditions in the interaction effect if lines are not parallel.
We can easily observe that a higher number of searches has a
different effect on security for each condition. In particular, the
amount of searches did not have a substantial effect on control (i.e.,
the mean of secure solutions remained around 1.6 (blue and red).
However, in the treatment group the mean of security increased
from 1.6 (red) to 1.9 (blue) for search counts that are above the me-
dian. In other words, the more searches performed by participants
in the treatment condition, the stronger the positive effect of the
treatment on the number of securely solved tasks. We show later
on that this interaction effect is statistically significant.
Figure 6b shows the interaction plot for functionality. We again
observe that the amount of searches did not have an effect on
control, since the mean of functional solutions remained around
2.5 (blue and red). In the treatment group we observed an increase
of the mean of functionality from 2.35 (red) to 2.58 (blue) for search
counts above the median. That means, the more the participants
in the treatment group used the modified search engine the more
functional solutions they submitted. We will show that this positive
interaction effect is also statistically significant.
Figure 6b also indicates that the treatment group performed
worse than control (2.51 vs. 2.34) for search counts below the median
(red). We will show that this is likely caused by a difference in the
subject pool, which we will explain later on. However, participants
with high search activity in the treatment condition, outperform
the participants in control irrespective of their degree of search
activity.
The interaction plots indicate that the more that participants in
the treatment condition used the search engine, the more secure and
functional solutions they submitted. In the following, we provide
several logistic regression models that show statistical significance
of this key result.
Security— We provide four logistic regression models for secu-
rity. We used Akaike information criterion (AIC) model selection to
distinguish among a set of possible models describing the relation-
ship between the condition, interaction effect, amount of searches,
search results, tasks and background variables. We present the mod-
els MS1-MS4 which had the best fit in Table 2. Based on Peduzzi et al.
(Rule of 10) and later results by Vittinghoff and McCulloch (suggest-
ing 5-9 samples per independent variable) for logistic regression,
our analysis should be adequately powered [33, 49].
MS1 shows that No Searches Performed had no significant effect
on security for all participants, independently from the condition.
This means participants that did not use the search engine at all
showed no significant difference in the security of submitted solu-
tions. MS2 shows that Secure ∪ Best-Practice Results, the average
count of results per task that where secure or secure best-practices,
had a significant positive effect on all participants (𝑝 < 0.05). The
more the participants received secure or secure best-practice results,
the more secure solutions they submitted. This already indicates
that searching and receiving good results leads to better security.
Therefore, we would expect participants from the treatment group
Session 11C: Software Development and Analysis CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea3079to perform better than the control group with increasing searches,
since they are the ones expected to receive more secure and secure
best-practice results. To measure this we include the interaction
variable Condition × Searches in model MS4. It confirms our expec-
tation: in the treatment group increasing searches had a significant
positive effect on security (𝑝 < 0.05).
Figure 7 further explains this result by showing the distribu-
tion of received results and visited results across both conditions.
The treatment group received more secure (45.8% vs 30.8%) and
drastically more secure best-practice results (36.9% vs. 0.4%) than