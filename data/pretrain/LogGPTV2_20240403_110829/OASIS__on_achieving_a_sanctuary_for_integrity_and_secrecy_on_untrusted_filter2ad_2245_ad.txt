V.inp.encsym ← Enc
({KV P , H (foo())})
K
+
po bind
V → OS
Launch Codea
2. OS
Execute Code
3. IEE
V.inp.privdata ←
: else if (V.inp.cmd = “compute”)
:
:
:
: hfoo(), V.inpi
V.inp.encsym ← outV.encK
AuthEncKV P (privInputs, outV.hosstate)
: else /* other functionality */. . .
: OS.inp ← out.OS
: launch[foo(), {V.inp, OS.inp}]
ksym ← unbind[V.inp.encsym, N U LL]
if (ksym =⊥) then ABORT
data1 ← V.inp.pubdata
if (V.inp.privdata 6= N U LL) then
: if (V.inp.cmd = “setup”) then
:
:
:
:
:
:
:
:
:
:
data2 ← AuthDecksym(V.inp.privdata)
if (data2 =⊥) then ABORT
state ← doWork1(data1, data2)
out ← bind[ksym, state, H(V.inp), N U LL]
data2 ← N U LL
else
ksym ← unbind[N U LL, V.inp.encsym]
if (ksym =⊥) then ABORT
data1 ← V.inp.pubdata
if (V.inp.privdata 6= N U LL) then
: else if (V.inp.cmd = “compute”)then
:
:
:
:
:
:
:
:
:
:
:
data2 ← AuthDecksym(V.inp.privdata)
if (data2 =⊥) then ABORT
stateold ← unbind[N U LL, OS.inp]
if (data2.V hosstate 6= H (stateold)) then ABORT
{statenew, res} ← doWork2 (stateold,
out ← bind[ksym, statenew, H(V.inp), res]
data1, data2)
: else /* other functionality */. . .
Save State
4. IEE → OS : hout.OS, out.V i
OS
: store hfoo(), out.OSi
Verify Execution
5. OS → V
V
: hout.V i
: outV ← AuthDecKV P (out.V )
: if (outV =⊥) then
:
: if (outV.hinp 6= H(V.inp)) then
:
reject: invalid computation
reject: invalid inputs
a
Please note that OS.inp is assigned N U LL during the ﬁrst
launch.
Figure 2: OASIS Execution Protocol: This proto-
col shows the interaction between the veriﬁer V and
untrusted system OS during the initial invocation
(setup) and repeated invocations (compute) of code
foo() within isolated execution environment IEE.
During the initial invocation the veriﬁer V uses the
public platform key K +
po bind to establish shared se-
cret KV P which is used for repeat invocations.
206.2 Rollback Prevention
6.4 Version Updating
A rollback attack occurs when old state is presented to
the isolated execution environment. Since the stale state is
cryptographically consistent, an isolated execution environ-
ment implemented without rollback prevention will incor-
rectly accept it – potentially bypassing stateful protection
mechanisms to, for example, undo the append-only prop-
erty of an audit log. Thus, rollback resistance is needed to
guarantee state continuity of the executing application.
One technique for ensuring state continuity is to include
a protected monotonic counter as part of the state [33]. An-
other technique for rollback prevention is to keep a trusted
summary (e.g., a hash) of the expected state. Parno et al.
include a summary of the state history to permit revert-
ing to a safe state in the case of an unexpected crash [36].
These methods can be achieved by using protected non-
volatile memory for persistent storage of data describing
the expected state. However, we seek a rollback prevention
mechanism that enables OASIS to remain stateless between
invocations. Additionally, we rule out using a trusted third
party for state management.
What follows is a description of how the veriﬁer can con-
ﬁrm state continuity using the OASIS instruction set. Dur-
ing the execution protocol, the unbind[] instruction is in-
voked to decrypt any state belonging to code C (Figure 2
step 3). After executing code C, the bind[] instruction is
invoked to protect state destined for the OS as well as out-
put destined for the veriﬁer. Included in the output for the
veriﬁer is a summary of the current state, H (stateOS). The
veriﬁer output is encrypted under key KV P before transfer-
ring control to untrusted OS code for delivery to the veri-
ﬁer. The veriﬁer includes this state summary as an input
during the next invocation.
If the state presented by the
untrusted OS matches the expected state, the code executes
and the new state summary is communicated to the veriﬁer
as acknowledgment. Otherwise, the protocol aborts. In this
fashion, we achieve rollback prevention without requiring
persistent application state in the OASIS TCB.
6.3 Distributed Deployment
We have presented cryptographic techniques for data se-
crecy, authenticity, and freshness. Still, the rollback pre-
vention mechanism described thus far is insuﬃcient if we
consider the distributed deployment model where multiple
veriﬁers collaborate through a remote service provider. In
this asynchronous context, even if cryptographic techniques
prevent forged responses and data snooping, a compromised
OS can launch forking attacks by concealing the operations
of one veriﬁer from another. For example, a compromised
server may simply omit the current state and replay an old
state to the other veriﬁers.
Fork consistency ensures that all veriﬁers see the same
operations log before an omission but no veriﬁer can see
any other veriﬁer’s operations after an omission fault (fork).
Furthermore, the fork consistency condition enables the ver-
iﬁers to detect a misbehaving service provider after a single
omission.
Li et al. present a protocol for achieving fork consistency
where each veriﬁer maintains a signed version structure list [25].
Each veriﬁer signs increasing version numbers and appends
these to their respective lists, allowing them to compare lists
and detect a fork attack.
To support version updating (i.e., updating code C to le-
gitimate new code C′), the application must implement an
update command which calls bind[] with parameter update
set (where the update parameter contains the new code ver-
sion C′ encrypted under key KV P ). The bind[] instruction
ﬁrst checks parameter update for authenticity and then up-
dates CR.P CR and CR.KC using the new code version C′
(refer to Table 2 for deﬁnitions of variables and Instruction 5
for details on bind[]). In this way the application state of
the current software version C is bound to the new software
version C′. Accordingly, the next invocation of unbind[]
will release the application state to C′.
The decryption and authentication operations prove to
OASIS that the software originated from the veriﬁer V as
she is the only one in possession of the key KV P . It is pos-
sible to design an alternative update mechanism based on
asymmetric operations which has the advantage that an en-
tity diﬀerent from V can provide an update C′, thus granting
it access to the current OASIS state. However, this comes
at the cost of requiring certiﬁcation which would add com-
plexity and computational overhead.
6.5 Device Transferability
Recall that the device owner selects seed value So during
key generation (refer to Function 1 for details). The seed
value So enables derivation of owner-speciﬁc processor keys.
Customization, via the owner-generated seed So, precludes
previous device owners, including the manufacturer, from
generating the same platform secret as the current owner.
Thus, the device can be safely transferred. This protects the
owners of new devices by limiting the ability of malicious
parties (e.g., along the supply chain) to learn the platform
secrets of the end user. This allows, for example, a device
to be repurposed at a new business unit or sold to a new
owner.
Please note that the owner-generated seed So eﬀectively
disassociates any resulting key material from the device man-
ufacturer. Nevertheless, the owner needs a mechanism to
prove the authenticity of their processor to a third party.
A default seed value that is ﬁxed for the life of the device
may be included to support secure device transfer while still
providing a mechanism for proving the authenticity of the
executing platform. We refer to this default seed value as
∗. Next, a master signing key is
the identity seed value or So
∗. Certiﬁca-
derived from root secret Kp and identity seed So
tion can be handled by a third party for further unlinkability.
In this way, secrets linked to the hardware are derived from
∗ whereas secrets exclusive to the
the ﬁxed identity seed So
owner are derived from the custom owner seed So.
Allowing the owner to choose any So as often as they
like may allow an attacker to leak the root platform key
Kp through cryptanalysis. This can be mitigated by rate-
limiting requests for a fresh So. Upon request, the device
generates a fresh seed value So and computes a MAC over it
using a key derived from the root secret Kp and the identity
∗. This ensures that chosen values of So cannot
seed value So
be correlated with a response, during device initialization,
to learn the root platform key Kp.
217. PERFORMANCE EVALUATION
7.1 System Conﬁguration
We model our proposed processor instruction set using
Simics, a full-system simulator [31]. We build a prototype
system by adding our new instructions to the x86-hammer
model.6 We model a 2 GHz processor with non-uniﬁed L1
cache (64 KB data and instruction caches). We use a mod-
iﬁed Linux 2.6.32 kernel as our target operating system.
7.2 Microbenchmark Results
To evaluate micro- and macro-level benchmarks, we mea-
sure the performance of our implementation against TCG-
style implementations of common security-sensitive code op-
erations. We use a pessimistic benchmark for the OASIS
isolated execution environment and compare it to an opti-
mistic benchmark for TCG 1.2. See Table 4 for a list of the
platform primitives and their associated costs. See Table 5
for a comparison of performance overheads for OASIS and
DRTM-based implementations.7
We base the median performance costs associated with
the cryptographic primitives by leveraging open source li-
braries LibTomCrypt and OpenSSL.8 It is likely that these
functions further increase in performance with a hardware
implementation.
7.3 Performance Advantages
We now present the performance advantages of our archi-
tecture as compared to a TPM implementation.
In terms of processor speed, cryptographic applications
beneﬁt from running on a processor core instead of a TPM.
For example, the Inﬁneon TPM co-processor operates at
33 MHz, which pales in comparison to even mid and low-end
commodity processor speeds.
In terms of communication overhead, we avoid costly com-
munication overheads by implementing cryptographic func-
tions on chip instead of on a co-processor. For example, the
TPM interfaces using the Low Pin Count (LPC) bus. The
LPC is used to connect low-bandwidth devices to the CPU
(4-bit-bus on a 33 MHz clock).
8. RELATED WORK
Architecture Extensions. Hardware-based security mech-
anisms have been proposed and implemented by both com-
mercial and academic groups. In terms of commercial hardware-
based IEE technologies, the main components are the Trusted
Execution Environment (TEE) which provides capabilities
for isolated execution and ensuring software is in a known
good state before launch, and the Trusted Platform Mod-
ule (TPM) which provides remote attestation, binding, and
sealing capabilities. Popular TEE implementations include
ARM Trust Zone [1], and Intel TXT [3]. More recently, Intel
has improved on the TXT architecture with the development
of Intel SGX [19]. These techniques can be combined with
the OASIS API. For example, Enclaves from SGX would
6x86-hammer is a hardware model representing a generic
64-bit AMD Operteron processor sans on-chip devices [47].
7We have based performance overheads in Table 5 on TPM
benchmarks from [37] where the reference DRTM implemen-
tation does not provide performance numbers for 2048-bit
RSA operations.
8LibTom: www.libtom.org. OpenSSL: www.openssl.org.
Table 4: Performance overheads for platform operations
used to instrument the OASIS isolated execution environ-
ment hardware simulation. Times are based on a 2 GHz
processor clock.
avg (of 210 executions)
cycles
time(ms)
Platform Support
R
←−{0, 1}ℓ
rand
f_read_PUF
f_init_PUF
f_fuzzy_extract_PUF
1.6 K 7.91 · 10−4
2.55 · 10−5
˜
2.40 · 10−5
˜
3.30 · 10−5
˜
Crypto
H(pe)
KDFCR.Kpo
f_sym_encrypt
f_sym_decrypt
f_rsa_key_gen
f_rsa_encrypt
f_rsa_decrypt
Sign
(m)
(m, σ)
+
X
K
−1
X
K
Verify
4.9 K 2.49 · 10−3
20.9 K 1.04 · 10−2
1.2 K 6.02 · 10−4
1.2 K 6.12 · 10−4
1.61 · 10+3
3.2 B
3.08 M 1.54 · 10+0
65.7 M 3.29 · 10+1
65.9 M 3.30 · 10+1
3.1 M 1.53 · 10+0
OASIS Functions
f_create_sym_keys
f_create_asym_keys
f_read_asym_keys
104 K 5.21 · 10−2
1.84 · 10+3
3.7 B
18.5 K 9.26 · 10−3