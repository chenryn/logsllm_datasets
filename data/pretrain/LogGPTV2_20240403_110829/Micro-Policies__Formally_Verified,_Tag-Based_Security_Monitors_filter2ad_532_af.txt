all be provided by the micro-policy designer. This code might
be handwritten or generated from a high-level language by a
compiler; the details are unimportant. The proof of correctness
of the generic framework is parameterized on correctness proofs
for these policy-speciﬁc components.2
Tag Representation A micro-policy has four sets of sym-
bolic tags (Tm, Tr, Tpc and Ts) that must be represented as
word-sized bit vectors on the concrete machine. Concrete tags
on the register ﬁle and the pc will be used to represent symbolic
ones drawn from the corresponding sets—namely, Tr and Tpc.
Since monitor services are implemented by code that lives in
memory, a tag in memory will either represent something in
Tm (in which case it marks a memory location that is visible
at the symbolic level), or something in Ts (in which case it
marks the address of a monitor service).
Formally, this representation scheme is speciﬁed by par-
tial decoding functions deck(memC, tC) that take a concrete
machine memory and concrete machine tag word as inputs,
and produce symbolic tags as output.3 Here, k ∈ {M, R, P}
speciﬁes which kind of concrete tag—memory, register or pc—
we are decoding, so that we know what kind of symbolic
tag to produce. Hence, decM(memC, tC) ∈ {User tS | tS ∈
Tm}(cid:21){Entry tS | tS ∈ Ts}, while decR(memC, tC) ∈ Tr and
decP(memC, tC) ∈ Tpc. We say that a concrete tag is a valid
user-level tag (given some memory) when it can be decoded
into a symbolic tag. For simplicity, from here on we will refer
to such tags by their symbolic decodings. We require that
deck(memC, Monitor) be undeﬁned—i.e., that no symbolic tag
be represented by it.
Monitor Self-Protection At the symbolic level, it is impos-
sible for user code to interfere with the internal state of the
2To manage the size of our veriﬁcation effort and focus attention on the
more novel parts, we assume the existence of correct monitor implementations
as hypotheses. We expect the actual implementations to be straightforward,
and veriﬁcation of this kind of low-level code is a well-studied area [4], [6],
[17].
3For simple micro-policies, symbolic tags can be accurately represented
in a single machine word, so dec does not depend on the memory argument.
More complex micro-policies may use the memory argument to represent tags
as data structures in memory—e.g., the compartmentalization micro-policy
of §5 uses this feature.
824824
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:04:44 UTC from IEEE Xplore.  Restrictions apply. 
micro-policy. At the concrete level, however (unlike in some of
our own previous work [4], [11]), monitor code and data live in
ordinary memory and registers, which user code must somehow
be prevented from accessing. Moreover, we need to ensure
that only monitor code can execute the special instructions
AddRule, PutTag, GetTag, and JumpFpc. Fortunately, we can
use the PUMP itself both to implement the symbolic micro-
policy and, at the same time, to enforce the restrictions above
(which we call monitor self-protection). To achieve this, we
use the special Monitor tag to mark all of the monitor’s code
and data, allowing the miss handler to detect when untrusted
code is trying to tamper with it, as explained below.
Monitor Code and Ground Rules On the concrete machine,
every instruction causes a rule cache lookup, which results in a
fault if no corresponding rule is present. Since the machine has
no special “privileged mode,” this applies even to monitor code.
To ensure that monitor code can do its job, we set up cache
ground rules (one for each opcode) saying that the machine can
step whenever the PC and CI tags in the iv are tagged Monitor;
in this case, the next pc and any result of the instruction are also
tagged Monitor. Monitor code must never change or override
these rules.
In addition, the fact that the machine uses a special pair of
don’t-care and copy-through masks when running monitor code
lets us ensure that the monitor does not fault when coming in
contact with user tags. For example, while policies will usually
check the tag on the target pc every time user code performs
a Jump (which may cause faults), such checks are not needed
for monitor code, since we assume that it behaves correctly.
To allow for both behaviors, we program the monitor-speciﬁc
masks to always use the tag of a Jump target as the new pc tag,
while disabling this bypass in the normal masks. Aside from
the PC and CI tags, all other positions in the iv are marked as
don’t-care for all opcodes. Copy-throughs are used for keeping
the same pc tag in most instructions and for copying the pc
tag from a register tag in the case of Jump, Jal, and JumpFpc.
Mov, Load, Store, and Jal also use copy-through for the result
tag.
Miss Handler Since ground rules ensure that monitor code
never faults, the miss handler is only invoked for monitoring
user-level code. The job of the miss handler is thus twofold:
(i) implement the symbolic transfer function of a micro-policy;
and (ii) enforce monitor self-protection. For the latter, the
miss handler just needs to ensure that the faulting opcode
is not a privileged instruction (e.g., AddRule), and that the
Monitor tag does not occur anywhere in the faulting iv (which,
crucially, includes the tags on the “old contents” of any registers
and memory locations that the instruction overwrites). If these
checks fail, the miss handler halts the machine. (In a real system,
the miss handler would instead tell the scheduler to halt just the
offending process.) Otherwise, the miss handler can compute
the transfer function on the iv, halting the machine if it violates
the micro-policy. If the instruction is allowed, the miss handler
should store the resulting ov into the appropriate memory slots,
call AddRule to install it, and restart the instruction that trapped
by jumping through the fpc register.
Besides correctly implementing its symbolic counterpart, the
concrete transfer function is also responsible for setting the
next pc to Monitor whenever a valid monitor-service call is
made (i.e., when the instruction tag is Entry tS). This ensures
that monitor services can execute with the appropriate privilege.
Reﬁnement We formalize the relation between the symbolic
machine (instantiated with the symbolic parts of some micro-
policy) and the concrete machine (instantiated with the concrete
parts of the same micro-policy) as a backward reﬁnement
between their step relations.4 The proof of backward reﬁnement
relies on some lemmas relating the symbolic and concrete parts
of the speciﬁc policy; the proofs of these must also be supplied
by the micro-policy designer.
At the heart of our reﬁnement result lies the following strong
simulation relation, which describes how a symbolic machine
state is represented at the concrete level.
Deﬁnition 9.1. Strong simulation ≈CS is deﬁned as follows (its
pieces are discussed below):
regC ∼memC regS
cache ok(memC, cache)
memC ∼ memS
services ok(memC)
memC[0..7] = [ @Monitor, . . . , @Monitor]
I(memC, regC, cache, extra)
decP(memC, tC) = tS
(memC, regC, pc@tC, fpc, cache)
≈CS (memS, regS, pc@tS, extra)
This relation is implicitly parameterized over policy-speciﬁc
decoding functions (decP , etc.) plus an invariant I, which
should be chosen to ensure that (i) the symbolic machine’s
extra state component is correctly represented in the concrete
machine memory; (ii) the monitor’s code and data are tagged
appropriately; and (iii) the cache contains the ground rules
needed by the monitor. A concrete register ﬁle simulates a
symbolic one (regC ∼memC regS) when they agree on register
values and the tags decode to the corresponding symbolic tags:
∀r, x, tS, (∃tC, regC[r] = x@tC ∧ decR(memC, tC) = tS)
⇐⇒ regS[r] = x@tS
The relation memC ∼ memS is deﬁned similarly; notice that
the concrete machine can contain more registers or memory
locations than the symbolic machine, as long as the concrete
tags on these registers or locations do not encode any valid
user tag. The predicate cache ok states that, whenever a rule
with a valid user-level pc tag is found in the cache, the rule’s
result matches that of the symbolic transfer function, modulo
the tag encoding. The predicate services ok states that each
location in the concrete memory that corresponds to a monitor
service is tagged with Entry tS, where tS is that service’s tag.
4Our formal Coq development also gives sufﬁcient conditions for proving
forward reﬁnement between the implementation of some policy on the concrete
machine and the corresponding symbolic machine instance. Since this is not
the focus of the present work—and since, in any case, forward reﬁnement
between the symbolic and abstract machines doesn’t hold for all policies—we
omit the details here, referring the reader to the formal development for more
information.
825825
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:04:44 UTC from IEEE Xplore.  Restrictions apply. 
U ≈CS sS and sC
Once again, we would like to construct a backward re-
ﬁnement inductively by using a backward simulation (Def-
inition 4.2). However, we can’t use Deﬁnition 9.1 for this
right away, since backward reﬁnement doesn’t hold for it
because steps taken by the concrete machine while inside the
monitor are not mapped to any steps of the symbolic machine.
Moreover, the concrete monitor will often need to temporarily
break both the invariants and the strong correspondence with
respect to some symbolic state. To address these points, we
use Deﬁnition 9.1 to deﬁne a weak simulation relation ∼CS:
Deﬁnition 9.2. sC ∼CS sS if either (i) the pc of sC has a
valid user-level tag and sC ≈CS sS, or else (ii) the pc of sC
is tagged Monitor and there exists a state sC
U with a pc that
U →∗ sC,
is a valid user-level tag such that sC
where all states in this execution have the pc tagged Monitor.
Case (ii) handles concrete states where the monitor is executing,
giving us a way to remember enough information from the
point where the monitor was invoked to be able to reestablish
strong simulation once execution returns to user mode.
Deﬁnition 9.3 ({0, 1}-backward simulation). We say that a
low-level machine (StateL,→L) {0, 1}-backward simulates a
high-level machine (StateH ,→H ) with respect to a relation ∼
if, whenever sL
1 or there
exists sH
Theorem 9.4 (Backward CS-simulation). The concrete machine
{0, 1}-backward-simulates the symbolic machine, with respect
to ∼CS.
The proof assumes the correctness of the monitor machine code
provided by the micro-policy designer: (1) On a cache miss, if
all the invariants are satisﬁed at the faulting instruction, then
the miss handler must successfully return to a user state only if
the faulting tag combination is allowed by the transfer function.
In this case, the resulting user state must be a reﬁnement of
the original symbolic state, and the cache must be updated
to allow execution to proceed. (2) When executing a monitor
service, the concrete machine returns to user code only if the
corresponding symbolic monitor service allows that execution.
In this case, the resulting user state must be a reﬁnement of the
new symbolic state. (3) Monitor data structures and invariants
are not affected by updates to user memory.
1 ∼ sH
2 such that sH
2 ∼ sH
1 and sL
1 → sH
1 → sL
2 and sL
2 , either sL
2 ∼ sH
2 .
Therefore, for any policy implemented in terms of abstract
and symbolic machines, we can get end-to-end reﬁnement
by composing Theorem 9.4 and the policy-speciﬁc symbolic-
abstract simulation, relating the abstract machine to the concrete
machine instantiated with a correct monitor implementation.
Example: Concrete Sealing Machine To implement the
sealing micro-policy from §4 on the concrete machine, we
can represent symbolic sealing tags as follows on a concrete
machine with 32-bit words, assuming that |SK| ≤ 228 and the
Monitor tag is represented by 0.5
5Disclaimer: We have implemented and tested this concrete sealing micro-
policy as a sanity check on our framework, but we have not formally proved
the sealing-speciﬁc assumptions supporting Theorem 9.4.
826826
· 1) = •
f (028 · 0 · 0) = Data
f (k · 0 · 1) = Key k
f (k · 1 · 1) = Sealed k
decP(m,
decR(m, t · 0 · 1) = f (t)
decM(m, t · 0 · 1) = User f (t)
· 1 · 0) = Entry •
decM(m,
Here · is bitstring concatenation and k is a 28-bit binary
representation of a symbolic key. (Notice that our sealing tags
can be represented in a single word, so dec does not depend
on the machine memory.) The key counter on the symbolic
machine is represented concretely as a single word of monitor
memory. Implementing the transfer function is easy: we just
need to prevent certain operations (e.g., Binop) from being
performed on sealed values and keys, following the symbolic
rules presented in §4. Implementing the monitor services is also
simple. The mkkey routine increments the key counter (halting
if it would overﬂow) and remembers the old value k. It then
tags the return register with Key k (with a dummy payload) and
returns to user code. The seal routine checks (using GetTag)
that its ﬁrst argument has the form x@Data and its second
argument is tagged Key k, assembles x@Sealed k in rret using
PutTag, and returns; unseal does the converse. All of these
routines halt if the arguments do not have the required form.
10 Related Work
We have already discussed work related to speciﬁc micro-
policies. Here we focus on work related to micro-policies and
reference monitors in general.
Micro-Policies The micro-policies framework and the PUMP
architecture have their roots in SAFE, a clean-slate, security-
oriented architecture [12]. There, the PUMP was used only
to implement dynamic IFC; other special-purpose hardware
mechanisms enforced properties such as memory safety [19]
and compartmentalization [12]. Still, the PUMP design in the
SAFE system was made quite ﬂexible, since dynamic IFC is
an active area of research, with various mechanisms and “label
models” being proposed regularly, making baked-into-hardware
solutions unattractive. A simple IFC micro-policy was studied
formally for an idealized version of the SAFE processor [4].
The present work aims to demonstrate the applicability of
the PUMP beyond IFC and beyond clean-slate hardware. We
consider a diverse set of micro-policies and a more conventional
architecture—a simpliﬁed RISC machine, with bit-strings as
words (instead of integers), with registers (instead of a hardware
stack), and with no separate instruction memory, no call-
stack or memory protection, no special monitor mode with
access to protected memory, and no special monitor invocation
instruction. Despite giving up these multiple specialized hard-
ware protection features, we obtain similar kinds of protection
through more extensive use of the PUMP’s tagging features.
The general structure of our proofs is similar to [4]; in
particular, that work also proves reﬁnement between a concrete
machine and an abstract one, using a “symbolic IFC rule
machine” as an intermediate step; also, as we do here for CFI, it
proves a generic preservation theorem that non-interference can
be carried to the lowest level. The rule machine in [4], however,
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:04:44 UTC from IEEE Xplore.  Restrictions apply. 