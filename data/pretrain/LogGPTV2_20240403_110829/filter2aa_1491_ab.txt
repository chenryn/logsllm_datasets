40
long live the pentest!
the value of the pentest
evolution of the pentest
a framework for repeatable testing 
41
40
2.1
the value of the pentest
41
42
where does pentesting ﬁt?
“penetration testing is a dead-end service line, as more and 
more tasks can be automated”
but is a pentest really just a series of tasks?
“secure coding eliminates the need for pentesting”
pie in the sky?
if everyone were honest, there’d be no more crime
of course, this also overlooks many other more fundamental 
problems in the information security world
43
42
43
so pentesting isn’t quite 
dead yet
we say: “no, not yet”
current level of automation amounts to little more than automated 
vulnerability scanning
as we said before, a pentest is much more than just a vulnscan!
44
43
44
remember that time… 
Client with AS400 and Windows
45
44
45
assessing the value of a 
modern-day pentest
is secure coding a realistic future?
the state of software ﬂaws
the value of third-party review
oracle / litchﬁeld paradigm
challenge issued, accepted and met
not the only example - “pwn to own”
46
45
46
“we aren’t conducting a 
penetration test, we’re…”
“...creating compelling events,” says marty sells (iss)
it makes for a nice pop-quiz to see if current hacker tools and techniques can 
bypass deployed countermeasures
oﬁr arkin’s paper on bypassing NAC or using VLAN hopping to monitor “isolated” 
segments
recent research by Brad Antoniewicz and Josh Wright in wireless security expose 
problems in common implementations of WPA Enterprise
the point being, smart people can ﬁnd unexpected/unforeseen issues that may not be 
common knowledge, so they would not be accounted for in any security initiatives
pentesting might even improve awareness!
47
46
47
getting funding for 
infosec initiatives
database tables for a slot machine operation
doctors doing the Heisman pose
48
47
2.2
evolution of the pentest
48
49
what kind of things do we 
ﬁnd today?
weak passwords
poor architecture
missing patches
system defaults
poorly conﬁgured vendor devices
yep, we’re talking about that printer/scanner/fax!
50
49
50
the funny thing is
these are the same damn things we were ﬁnding 10+ years 
ago!
so have we really learned? 
is software measurably more secure?
is network architecture that much better?
has anybody listened to anything we’ve been saying?
(not a damn thing, apparently!)
51
50
51
an ongoing process
remember the iss addme model?
assess
design
deploy
manage
educate
(rinse and repeat)
52
51
52
a repeatable process!
pentests of lore were often quite ad-hoc
unfortunately, with no continuity between tests, it’s difﬁcult if not 
impossible to effectively determine if things are improving
believe it or not, process and (thank god there are no shmooballs 
at this con) metrics are actually quite important here 
53
52
53
a systematic approach to 
security management
ok, so let’s compare:
yesterday’s pentest:
“here’s your 1300 page report from internet scanner^H^H^H^H^H, 
errr… that we custom generated, just for you!”
“risk proﬁle? what do you mean?”
54
53
54
a systematic approach to 
security management
current pentest
action plan matrix to deal with highest impact / lowest cost 
ﬁrst
(still no accepted standard for determining risk proﬁle 
improvements)
systems that just count vulns don’t take into account the # 
of vulns announced last week, last month, etc.
we need an ever better system of metrics here
55
54
55
the metrics reloaded
optimally, a good metric would account for
number of vulns discovered, over time
number of vulns by platform, over time
mean time for remediation
and follow-up testing would ensure 
follow-up pentest
assessment of effectiveness of deployed countermeasures
56
55
56
invariably variable
a pentest is still always inﬂuenced by the individual pentester’s 
experience and background
again, this reinforces the understanding that simple vuln 
counting is ineffective
for new ﬁndings across a systematic rescan
were these actual new ﬁndings? were they missed previously?
did the tools improve? was there a new team? did the team improve?
57
56
57
hammer time.
2006 pentest with “partial control”
2007 follow-up
how complex are the metrics required to explain this situation?
58
57
58
upgrades to the toolbox
nmap still reigns king (go see fyodor’s talk!)
superscanner
john the ripper
rainbow tables
cain and abel
metasploit, holy shit
59
58
59
upgrades to the toolbox
vulnerability scan^H^H^H^H management
nessus
foundstone
iss
ncircle
tenable
60
59
60
upgrades to the toolbox
wireless
high-powered pcmcia and usb cards (alfa!)
aircrack-ng
kismet, kismac
asleap
cowpatty (omgwtf, saw bregenzer’s talk?)
61
60
61
upgrades to the toolbox
live distros and other misc
backtrack (one pentest distro to rule them all)
damn vulnerable linux
winpe (haha, no just kidding, omg)
62
61
2.3
a framework for repeatable testing
62
63
improved methodologies
isecom’s osstmm now at v2.2, with 3.0 eminent 
(and available to paying subscribers)
the open information systems security group is now proffering the issaf, the 
information systems security assessment framework
kevin orrey (vulnerabilityassessment.co.uk) offers his penetration testing 
framework v0.5
nist special publication 800-42 provides guidelines on network security 
testing
wirelessdefence.org offers a wireless penetration testing framework, now 
part of kevin orrey’s full pentesting framework, above
64
63
64
…forest for the trees
early pentests were little more than exhaustive enumerations of all 
[known] vulnerabilities, occasionally with documentation on the 
process by which to most effectively exploit them
with time, networks grew geometrically more complex, rendering mere 
vulnerability enumeration all but useless
we now have to focus on architectural ﬂaws and systemic issues in 
addition to vulnerability enumeration
methodologies can be very helpful, but don’t obviate the need for 
original thought. in other words, neither a cert nor a methodology can 
make you a good pentester if you don’t already think like a hacker.
65
64
65
tactical vs strategic
the [old] tactical approach
identify all vulnerabilities [known by your automated scanner], rate 
their risk as high, medium or low, then dump them into a client’s 
lap and haul ass
the [new] strategic approach
identify all known vulnerabilities, including architectural and 
conceptual, correlate them within the context of the company’s 
risk (subject to available risk tolerance data) then assist in creating 
an action plan to calculate risk vs effort required to remediate
66
65
66
embrace the strategic
strategic penetration testing therefore requires
a skilled individual or team with sufﬁcient background (and a hacker-like 
mindset, not just a certiﬁcation), capable of creatively interpreting and 
implementing a framework or methodology
a scoring system that factors in things like
system criticality
complexity and/or likelihood of attack
complexity and/or effort involved in remediation
effective metrics!
67
66
67
how providers are chosen
i’ll choose these guys if it’s compliance and i don’t want 
anything found,
or… these other guys if i actually want to know what the hell is 
going on and don’t want to get pwned later
many companies also now have internal “tiger teams” for 
pentesting
while a good idea, third party validation is both important and 
necessary; remember our comments on different backgrounds 
and experience?
68
67
Part 2.4
pentesting in  the 21st century…  
and beyond
68
69
why we need an organic 
[open] methodology
working with what we have
no point trying to reinvent the wheel
already have a methodology of your own? map, correlate and contribute it!
improvement of standardized methodologies only happens through 
contributions
osstmm and issaf stand out as most complete
osstmm has been around longer, but both have wide body of contributors
moderate overlap, so review of both recommended
70
69
70
contributing to open 
methodologies
osstmm and issaf will continue to improve
fueled by contributions
need continuous review
difﬁcult to measure the effectiveness of any one framework, 
but they can be evaluated against each other in terms of 
thoroughness and accuracy
bottom line: not using a framework or methodology (at least in 
part) will almost certainly place you at a disadvantage
71
70
71
adapting to new 
technologies
so how does one keep up with the ever changing threat / vulnerability 
landscape? what about wpa, nac, web2.0 and beyond? (which way 
did he go, george?)
simple answer -- be dan kaminsky or billy hoffman, or:
new technology does not necessarily imply old threats, vulnerabilities, 
attacks and solutions won’t still work
want to pentest a new technology, but not sure where to begin, which tools 
to use?
do what smart developers do, threat/attack models! 
(see bruce scneier, windows snyder, adam shostack, et. al.)
72
71
72
can you test without a 
baseline?
absolutely! (though you might have a hard time quantifying and/
or measuring risks associated with discovered ﬂaws)
then identify data ﬂows, data stores, processes, interactors and trust 
boundaries
in other words, ﬁnd the data, determine how the data is modiﬁed and by 
what/whom, ﬁgure out how and where the data extends and attack as 
many pieces of this puzzle as your existing beachhead allows!
if it’s a piece of software running on a computer, it’s ultimately vulnerable… 
somewhere
73
72
73
threat/attack modeling
several different approaches, but all focus on the same basic set of tasks 
and objectives
msft says: identify security objectives, survey application, decompose 
application, identify, understand and categorize threats, identify vulnerabilities, 
[identify mitigation strategies, test]
wikipedia: identify [business objectives, user roles, data, use cases]; model 
[components, service roles, dependencies]; identify threats to cia; assign risk 
values; determine countermeasures
although threat models are useful for securing software, at a more 
abstract level, they are also extremely useful for compromising new and/
or untested technologies
74
73
74
quality assurance
so can we deﬁne qa and/or qc in the context of penetration testing?
sure, it’s basically an elaboration on our previously mentioned set of 
necessary / desired metrics
# of vulns discovered over time, # discovered by platform, mean time 
for remediation and potential for mitigation by means of available 
countermeasures. further, apply richard bejtlich’s ﬁve components used 
to judge a threat: existence, capability, history, intentions, and targeting
these metrics are then mapped back to assets against which individual 
vulnerabilities were identiﬁed and you have a quantiﬁable and quantitative 
analysis of a penetration test
75
74
75
hacker insurance?
often dubbed “network risk insurance”
$5k - $30k/ year for $1m coverage
is it worth it? should you be recommending it?
well, that’s quite subjective. how good was your pentest? ;)
depends on the organization, the nature of the information they purvey, their potential 
for loss, etc. in general, i say absolutely!
providers include aig, lloyd’s of london / hiscox, chubb, zurich north america, 
insuretrust, arden ﬁnancial, marsh, st. paul, tennant
unless you can “guarantee” your pentest by offering your client a money-back 
guarantee, suggesting hacker insurance might be a wise idea
76
75
76
Conclusions
1 the pentest is dead
2 long live the pentest
2.3 a framework for repeatable testing
2.4 pentesting in the 21st century and beyond
Until next time...
77
76
End.
everything we said might be a lie
thanks for hearing us out,
-taylor and carric
77