     return m;
    }
  * alloc_meta() 
    * 先看有无初始化设置ctx的随机数
    * 如果ctx的free_meta_head链表中有空闲的meta, 那么直接从这里分配一个meta
    * 如果没有可用的, 那么就说明需要向OS申请内存存放meta 
      * 先通过brk分配1页,
      * 如果brk失败的话则会通过mmap()分配许多页内存, 但是这些内存都是PROT_NONE的, 属于guard page, 堆溢出到这些页面会引发SIGV, 而meta不使用开头与结尾的一页, 防止被溢出
    * 然后设置ctx中的meta_area_tail, avail_meta_cnt等信息, 把新分配的一页作为待划分的meta
    //分配一个meta对象, 有可能是用的空闲的meta, 也可能是新分配一页划分的
    struct meta *alloc_meta(void)
    {
     struct meta *m;
     unsigned char *p;
     //如果还没初始化, 就设置secret
     if (!ctx.init_done)
     {
    #ifndef PAGESIZE
      ctx.pagesize = get_page_size();
    #endif
      ctx.secret = get_random_secret(); //设置secret为随机数
      ctx.init_done = 1;
     }
     //设置pagesize
     size_t pagesize = PGSZ;
     if (pagesize > 12;
        need_unprotect = 0;
       }
      }
      if (!ctx.avail_meta_area_count) //如果前面brk()分配失败了, 直接mmap匿名映射一片PROT_NONE的内存再划分
      {
       size_t n = 2UL > 12);
       ctx.meta_alloc_shift++;
      }
      //如果avail_meta_areas与4K对齐, 那么就说明这片区域是刚刚申请的一页, 所以需要修改内存的权限
      p = ctx.avail_meta_areas;
      if ((uintptr_t)p & (pagesize - 1))
       need_unprotect = 0;
      if (need_unprotect)
       if (mprotect(p, pagesize, PROT_READ | PROT_WRITE) && errno != ENOSYS)
        return 0;
      ctx.avail_meta_area_count--;
      ctx.avail_meta_areas = p + 4096;
      if (ctx.meta_area_tail)
      {
       ctx.meta_area_tail->next = (void *)p;
      }
      else
      {
       ctx.meta_area_head = (void *)p;
      }
      //ctx中记录下相关信息
      ctx.meta_area_tail = (void *)p;
      ctx.meta_area_tail->check = ctx.secret;
      ctx.avail_meta_count = ctx.meta_area_tail->nslots = (4096 - sizeof(struct meta_area)) / sizeof *m;
      ctx.avail_meta = ctx.meta_area_tail->slots;
     }
     //ctx的可用meta数组中有能用的, 就直接分配一个出来
     ctx.avail_meta_count--;
     m = ctx.avail_meta++;  //取出一个meta
     m->prev = m->next = 0; //这俩指针初始化为0
     return m;
    }
  * enframe() 
    * 先找到g中第idx个chunk的开始地址与结束地址
    * 然后设置idx与offset等信息
    static inline void *enframe(struct meta *g, int idx, size_t n, int ctr)
    {
     size_t stride = get_stride(g);        //g负责多大的内存
     size_t slack = (stride - IB - n) / UNIT;     //chunk分配后的剩余内存: (0x30 - 4 - 0x20)/0x10 = 0
     unsigned char *p = g->mem->storage + stride * idx; //使用这个meta管理的内存中第idx个chunk,
     unsigned char *end = p + stride - IB;      //这个chunk结束的地方
     // cycle offset within slot to increase interval to address
     // reuse, facilitate trapping double-free.
     //slot内循环偏移增加地址复用之间的间隔
     //如果idx!=0, 那么就用chunk->offset设置off, 否则就用ctr
     int off = (p[-3] ? *(uint16_t *)(p - 2) + 1 : ctr) & 255;
     assert(!p[-4]);
     if (off > slack)
     {
      size_t m = slack;
      m |= m >> 1;
      m |= m >> 2;
      m |= m >> 4;
      off &= m;
      if (off > slack)
       off -= slack + 1;
      assert(off mem->storage) / UNIT; //设置与group中第一个chunk的偏移
     p[-3] = idx;             //设置idx
     set_size(p, end, n);
     return p;
    }
  * 总结, mallocng有如下特性 
    * chunk按照bitmap从低到高依次分配
    * 被free掉的内存会先进入freed_mask, 当avail_mask耗尽时才会使用freed_mask中的
    * mallocng把meta与group隔离开来, 来减缓堆溢出的危害
## free()
  * 先通过get_meta()找到chunk对应的meta
  * 然后重置idx与offset
  * 然后再meta的freed_mask中标记一下就算释放完毕了
  * 然后调用nontrivial_free()处理meta相关操作
    void free(void *p)
    {
     if (!p)
      return;
     struct meta *g = get_meta(p);  //获取chunk所属的meta
     int idx = get_slot_index(p);   //这是group中第几个chunk
     size_t stride = get_stride(g); //这个group负责的大小
     unsigned char *start = g->mem->storage + stride * idx;
     unsigned char *end = start + stride - IB;
     get_nominal_size(p, end);          // 根据reserved来算真实大小
     uint32_t self = 1u last_idx) - 1; //计算这个chunk的bitmap
     ((unsigned char *)p)[-3] = 255;         //idx与offset都无效
     // invalidate offset to group header, and cycle offset of
     // used region within slot if current offset is zero.
     *(uint16_t *)((char *)p - 2) = 0;
     // release any whole pages contained in the slot to be freed
     // unless it's a single-slot group that will be unmapped.
     //释放slot中的一整页
     if (((uintptr_t)(start - 1) ^ (uintptr_t)end) >= 2 * PGSZ && g->last_idx)
     {
      unsigned char *base = start + (-(uintptr_t)start & (PGSZ - 1));
      size_t len = (end - base) & -PGSZ;
      if (len)
       madvise(base, len, MADV_FREE);
     }
     // atomic free without locking if this is neither first or last slot
     //在meta->freed_mask中标记一下, 表示这个chunk已经被释放了
     //如果既不是中间的slot也不是末尾的slot, 那么释放时不需要锁
     for (;;)
     {
      uint32_t freed = g->freed_mask;
      uint32_t avail = g->avail_mask;
      uint32_t mask = freed | avail; //mask = 所有被释放的chunk + 现在可用的chunk
      assert(!(mask & self));     //要释放的chunk应该既不在freed中, 也不在avail中
      /*
       - 两种不能只设置meta的mask的情况, 这两种情况不设置mask, break后调用nontrivial_free()处理
        - 如果!freed, 就说明meta中没有被释放的chunk, 有可能这个group全部被分配出去了, 这样group是会弹出avtive队列的, 
         而现在释放了一个其中的chunk, 需要条用nontrivial_free()把这个group重新加入队列
        - 如果mask+self==all, 那就说明释放了这个chunk, 那么这个group中所有的chunk都被回收了, 
         因此这个meta需要调用nontrivial_free()回收这个group
      */
      if (!freed || mask + self == all)
       break;
      //设置freed_mask, 表示这个chunk被释放了
      if (!MT) //如果是单线程,直接写就好了
       g->freed_mask = freed + self;
      else if (a_cas(&g->freed_mask, freed, freed + self) != freed) //如遇多线程使用原子操作, 一直循环到g->freed_mask为freed+self为止
       continue;
      return;
     }
     wrlock();
     struct mapinfo mi = nontrivial_free(g, idx); //处理涉及到meta之间的操作
     unlock();
     if (mi.len)
      munmap(mi.base, mi.len);
    }
  * nontrivial_free() 
    * 根据free()进入这个函数的方式可以知道, 此时还没有设置freed_mask
    * 如果发现这个group中所有的chunk要么被free, 要么是可用的, 那么就会回收掉这个group 
      * 先调用dequeue从队列中出队
      * 如果队里中后面还有meta的话, 就会激活后一个meta
      * 然后调用free_group()释放整个group
    * 如果发现mask为空 
      * 那么说明malloc分配出最后一个chunk的时候已经把这个meta给弹出队列了
      * 但是现在里面有一个chunk被释放了, 这个meta就应该再次回归队列, 因此调用queue()再次入队
    static struct mapinfo nontrivial_free(struct meta *g, int i)
    {
     uint32_t self = 1u sizeclass;
     uint32_t mask = g->freed_mask | g->avail_mask;
     //如果group中所有chunk要么被释放要么可使用, 并且g可以被释放, 那么就要回收掉整个meta
     if (mask + self == (2u last_idx) - 1 && okay_to_free(g))
     {
      // any multi-slot group is necessarily on an active list
      // here, but single-slot groups might or might not be.
      if (g->next) //如果g有下一个
      {
       assert(sc alloc_slot()=>try_avail()最终就被弹出队列了, 目的取出队列中不可能再被分配的, 提高效率
         //现在这个全部chunk被分配出去的group中有一个chunk被释放了, 因此这个meta要重新入队
      assert(sc freed_mask, self);
     return (struct mapinfo){0};
    }
## 可利用的点
  * mallocng防御堆溢出的方法是meta与分配chunk的group在地址上分离, 并且在meta所在页的前后设置一个NON_PROT的guard page, 来防止发生在group上的堆溢出影响到meta, 产生arbitrary alloc, 因此无法从溢出meta队列
  * 但是队列操作中并没有对mete的prev与next指针进行检查, 属于unsafe unlink, 原因可以能是作者认为, 既然meta无法被修改, 那么meta中的指针一定是正确的  
  * 其实不然, 我们确实无法直接溢出meta, 但是这不代表这我们无法伪造meta结构体
  * 思路 
    * 我们可以溢出一个chunk, 伪造他的offset与next, 使其指向我们伪造的group,
    * 然后伪造group中的meta指针, 使其指向我们伪造的meta
    * 然后伪造meta中的prev next指针, 并且伪造freed_mask与avail_mask, 做出一副这个meta中的chunk已经全部被释放了的样子, 这样就会调用: free()=>nontrivial_free()=>dequeue()完成攻击