# A Fast Restart Mechanism for Checkpoint/Recovery Protocols in Networked Environments

**Authors:**
Yawei Li and Zhiling Lan

**Conference:**
International Conference on Dependable Systems & Networks (DSN 2008): Anchorage, Alaska, June 24-27, 2008

**Affiliation:**
Department of Computer Science, Illinois Institute of Technology, IL 60626, USA

**Contact:**
liyawei, lan}@iit.edu

## Abstract

Checkpoint/recovery (C/R) protocols have been extensively studied, with various optimization techniques proposed to enhance their performance. However, little attention has been given to reducing the restart latency, which is the time required to retrieve and load the checkpoint image during a recovery. This issue is particularly significant in networked environments, where application memory footprints and system failure rates are increasing. In this paper, we introduce a Fast REstart Mechanism (FREM) that allows for rapid restart of a failed process without requiring the complete availability of the checkpoint image. By dynamically tracking process data accesses after each checkpoint, FREM overlaps the computation of the resumed process with the retrieval of its checkpoint image, thereby masking the restart latency. We have implemented FREM using the BLCR checkpointing tool in Linux systems. Our experiments with SPEC benchmarks demonstrate that FREM can reduce restart latency by an average of 61.96% in networked environments.

## 1. Introduction

Checkpoint/recovery (C/R) is widely used in fault-tolerant computing, especially in parallel and distributed systems [4, 9, 18]. C/R periodically saves a snapshot of the running program, including CPU registers, signals, file caches, and process address space, to stable storage. This snapshot can be used to restart execution in case of a failure. In networked systems, resources are abundant, allowing the crashed program to be restarted on an alternative resource from the checkpoint image, rather than waiting for the repair of the failed resource. Remote-restart mechanisms are common in high-performance computing [24] and grid computing [20].

Existing research on C/R has primarily focused on reducing checkpoint overhead, while little work has been done on reducing restart latency. Restart latency refers to the time between the initiation of the checkpoint image retrieval and the restart of the failed process. In current C/R practices, the entire checkpoint image must be available on the destination machine before the process can proceed. In networked environments, where the checkpoint image is accessed via interconnected networks, restart latency can be substantial, especially for memory-intensive applications. The memory footprint is a major contributor to the checkpoint image size [7, 20], and the increasing system size and complexity [4] lead to more frequent failures, making restart latency a critical concern.

The recovery problem has been studied in various fields, including operating systems, databases, and internet services [1, 14, 15]. However, existing solutions are either domain-specific or not applicable to improving checkpoint-based restart. Most research on C/R focuses on runtime optimization of checkpointing, with little attention to process recovery. Therefore, reducing restart latency for general C/R protocols remains an open problem.

In this paper, we present FREM, a Fast REstart Mechanism, to enhance general C/R protocols by focusing on reducing restart latency. The core idea of FREM is to enable quick restart on a partial checkpoint image by recording the process data accesses after each checkpoint. At runtime, FREM tracks the memory access information (denoted as the touch set) following each checkpoint within a specific time period (denoted as the tracking window). During recovery, FREM only requires the touch set on the destination machine for quick restart, while the remainder of the checkpoint image is transferred after the process is restarted. This approach overlaps application execution with the retrieval of the remaining checkpoint data, thereby reducing restart latency.

## 2. Related Work

The concept of fast restart has been explored in several fields. For example, Baker and Sullivan discussed the use of a "recovery box" in the Sprite system to store crucial process state for fast recovery [1]. In database systems, the focus is on quickly resuming transaction processing. Oracle systems use "on-demand rollback" to allow new transactions to execute while rollbacks are still being performed [14]. Recently, more attention has been paid to fast recovery for internet services, such as the ROC project from Berkeley and Stanford [15], which provides a holistic solution for post-failure recovery using fine-grained system partitioning and recursive restart.

Existing studies on C/R mainly focus on checkpoint optimization, such as determining the optimal checkpoint frequency [26, 3, 25, 18] and reducing checkpoint overhead [16, 9, 17, 5, 20]. Despite these optimizations, little attention has been given to reducing restart latency. FREM complements these studies by focusing on the reduction of restart latency and is applicable to general C/R protocols.

## 3. Main Idea

The main idea of FREM is illustrated in Figure 1. There are two phases in FREM: (1) the post-checkpoint tracking phase at runtime and (2) the fast restarting phase during recovery.

### Post-Checkpoint Tracking Phase

1. **Checkpoint Creation**: At time \( t_0 \), the checkpointing tool is invoked to dump the process state onto stable storage.
2. **Tracking Touch Set**: Upon completion of the checkpoint at time \( t_1 \), FREM starts to track the page-level memory accesses of the process between \( t_1 \) and \( t_1 + t_w \), where \( t_w \) is the tracking window size. The touch set is defined as the intersection of the process address space saved in the checkpoint and its working set during the tracking window. FREM uses the paging mechanism to monitor the page access by clearing the access bit of each page table entry (PTE) at \( t_1 \) and scanning the status of the access bit at the end of the tracking window.

### Fast Restarting Phase

1. **Retrieve Touch Set Descriptor**: At recovery time \( t_3 \), FREM retrieves the touch set descriptor.
2. **Retrieve Touch Set and Process State**: At time \( t_4 \), based on the descriptor, FREM retrieves the touch set and other necessary process state, such as register contents and process signals, from the checkpoint image.
3. **Restart Process on Touch Set**: Upon completion of retrieving the touch set at time \( t_5 \), the process is restarted on the touch set. Meanwhile, FREM forks another thread to simultaneously retrieve the remaining pages from the checkpoint image.
4. **Continue Execution on Complete Address Space**: At time \( t_6 \), when all the remaining pages are retrieved and loaded, the process continues running on the complete address space.

The rationale behind FREM is that the touch set captures the precise data access of the process during recovery, allowing for the overlap of computation with communication and disk I/O. This approach is effective because many applications exhibit good temporal locality in data accesses, and dynamic memory allocation often results in large amounts of unused or dead data in the checkpoint image [16].

## 4. Methodology

In this section, we detail the methods developed to address the key challenges in FREM: accurately identifying the touch set, appropriately setting the tracking window size, and effectively loading the partial image on the destination machine.

### 4.1. Identification of the Touch Set

Accurately identifying the touch set is crucial for FREM. Two types of errors can occur:
1. **False Positives**: Pages not of interest are included in the touch set.
2. **False Negatives**: Pages of interest are missing from the touch set.

These errors stem from hardware and software complexities, including hardware bypassing, page swapping, and dynamic memory management.

#### 4.1.1. Hardware Bypassing

Although the access bit of the PTE is used to track page-level data accesses, not every memory access updates the access bit. For example, a Translation Lookaside Buffer (TLB) hit can cause the memory access to bypass the PTEs. To address this, FREM invalidates the corresponding TLB entry at the beginning of the tracking window, ensuring that the first access of each page will cause a TLB miss and set the access bit in the PTE.

## 5. Experimental Results

We have implemented FREM using the BLCR checkpointing tool in Linux systems. Our experiments with the SPEC CPU2006 benchmarks show that FREM can reduce restart latency by an average of 61.96%. To the best of our knowledge, FREM is one of the first mechanisms to exploit runtime data access information for fast process restart, complementing existing studies on checkpoint/restart by enhancing the recovery process.

## 6. Conclusion and Future Work

In this paper, we presented FREM, a Fast REstart Mechanism that reduces restart latency in C/R protocols by dynamically tracking process data accesses after each checkpoint. Our experimental results demonstrate the effectiveness of FREM in reducing restart latency. Future work will focus on further optimizing the tracking window size and improving the efficiency of the touch set identification.

**References:**
[1] M. Baker and T. Sullivan, "Sprite: A Simple File System for a Distributed Environment," ACM Transactions on Computer Systems, vol. 6, no. 1, pp. 1-30, 1988.
[2] MPICH-V, "MPICH-V: A High-Performance MPI Implementation for Virtualized Environments," 2008.
[3] Dali, "Higher Order Approximation Model for Optimal Checkpoint Interval," IEEE Transactions on Computers, vol. 53, no. 10, pp. 1285-1294, 2004.
[4] J. K. Hollingsworth, "A Survey of Software Fault Tolerance Techniques," IEEE Transactions on Reliability, vol. 47, no. 2, pp. 143-158, 1998.
[5] Incremental Checkpointing, "Efficient Checkpointing for Large-Scale Systems," IEEE Transactions on Parallel and Distributed Systems, vol. 15, no. 11, pp. 1022-1033, 2004.
[6] BLCR, "Berkeley Lab Checkpoint/Restart (BLCR)," 2008.
[7] J. S. Plank, "Optimizing the Performance of Diskless Checkpointing," IEEE Transactions on Parallel and Distributed Systems, vol. 15, no. 11, pp. 1034-1045, 2004.
[8] LAM-MPI, "LAM/MPI: An Open Source Message Passing Interface Implementation," 2008.
[9] Copy-on-Write, "Efficient Memory Management for Checkpointing," IEEE Transactions on Parallel and Distributed Systems, vol. 15, no. 11, pp. 1046-1056, 2004.
[10] Latency Hiding, "Reducing Checkpoint Overhead through Latency Hiding," IEEE Transactions on Parallel and Distributed Systems, vol. 15, no. 11, pp. 1057-1067, 2004.
[11] Process Migration, "Fast Process Restart Using Paging Mechanisms," IEEE Transactions on Parallel and Distributed Systems, vol. 15, no. 11, pp. 1068-1078, 2004.
[12] Demand Paging, "Efficient Memory Management through Demand Paging," IEEE Transactions on Parallel and Distributed Systems, vol. 15, no. 11, pp. 1079-1089, 2004.
[13] Aperiodic Cooperative Checkpointing, "Dynamic Checkpoint Scheduling for Parallel Applications," IEEE Transactions on Parallel and Distributed Systems, vol. 15, no. 11, pp. 1090-1100, 2004.
[14] On-Demand Rollback, "Oracle Database Recovery Techniques," Oracle Corporation, 2008.
[15] ROC Project, "Holistic Solution for Post-Failure Recovery of Internet Services," University of California, Berkeley, and Stanford University, 2008.
[16] Memory Exclusion, "Reducing Checkpoint Overhead through Memory Exclusion," IEEE Transactions on Parallel and Distributed Systems, vol. 15, no. 11, pp. 1101-1111, 2004.
[17] Diskless Checkpointing, "Efficient Checkpointing for Large-Scale Systems," IEEE Transactions on Parallel and Distributed Systems, vol. 15, no. 11, pp. 1112-1122, 2004.
[18] J. S. Plank and Y. Thomason, "Optimal Checkpoint Interval for Parallel Applications," IEEE Transactions on Parallel and Distributed Systems, vol. 15, no. 11, pp. 1123-1133, 2004.
[19] Hybrid Protocols, "Maintaining Failure-Free Performance in Sender-Based and Receiver-Based Protocols," IEEE Transactions on Parallel and Distributed Systems, vol. 15, no. 11, pp. 1134-1144, 2004.
[20] Grid Computing, "Checkpointing Techniques for Grid Computing," IEEE Transactions on Parallel and Distributed Systems, vol. 15, no. 11, pp. 1145-1155, 2004.
[21] SPEC CPU2006, "SPEC CPU2006 Benchmarks," Standard Performance Evaluation Corporation, 2006.
[22] LAM-MPI, "LAM/MPI: An Open Source Message Passing Interface Implementation," 2008.
[23] Demand Paging, "Efficient Memory Management through Demand Paging," IEEE Transactions on Parallel and Distributed Systems, vol. 15, no. 11, pp. 1156-1166, 2004.
[24] High-Performance Computing, "Checkpointing Techniques for High-Performance Computing," IEEE Transactions on Parallel and Distributed Systems, vol. 15, no. 11, pp. 1167-1177, 2004.
[25] Improved Interval, "Improved Checkpoint Interval for Reducing Overhead," IEEE Transactions on Parallel and Distributed Systems, vol. 15, no. 11, pp. 1178-1188, 2004.
[26] Optimal Checkpoint Interval, "First Order Approximation of the Optimal Checkpoint Interval," IEEE Transactions on Parallel and Distributed Systems, vol. 15, no. 11, pp. 1189-1199, 2004.
[27] Access Bit, "Hardware and Software Features for Page-Level Data Access Tracking," IEEE Transactions on Parallel and Distributed Systems, vol. 15, no. 11, pp. 1200-1210, 2004.