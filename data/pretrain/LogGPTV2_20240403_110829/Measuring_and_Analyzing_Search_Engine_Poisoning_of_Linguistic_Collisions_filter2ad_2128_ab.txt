


 






	






















Figure 3: WorkÔ¨Çow of Ô¨Ånding linguistic-collision keywords for search engine poisoning. Based on a set of selected target keywords, we design
algorithms to generate potential misspelling candidates (¬ñ), expanding to a larger word set. Then we reduce the candidate sets to identify
the linguistic-collision keywords (¬ó) and collect the corresponding non-auto-corrected results from search engines. Last we check on
blacklists to Ô¨Ånd linguistic-collision keywords associated with malicious websites with high rankings in search results for subsequent analysis (¬ò).
3) Did-you-mean (low conÔ¨Ådence about misspellings).
When search engines suspect the spelling may contain errors,
a warning banner of ‚ÄúDid you mean‚Äù with a suggested
keyword is displayed to users. However, users receive only
search results for the misspelled keyword. Though the
notiÔ¨Åcation banner can blend in with search results and be
ignored, it raises the chances for users to realize misspellings
in the queries and correct them. As shown in Figure 1(c),
search for adube (misspelling of adobe by replacing letter
o with u) on Google leads to search results based on the
misspelling. If users click on the suggested query adobe
in ‚ÄúDid you mean‚Äù, the search will be re-run for the revised
version adobe and the warning message will disappear.
4) Non-auto-corrected (no detection of misspellings).
If search engines have no suspicion of misspellings in the
search terms, the query is performed for the keyword that
users originally submit. In particular, if a misspelling is
coincidentally an existent word, even possibly in a different
language, search engines will not modify the original query
or display any notiÔ¨Åcation to users. The semantic gap is that
search engines have no prior knowledge about the original
keywords that users intend to search. For example, search
for idobe (replacing the Ô¨Årst letter a with i) yields regular
search results for the word. The page will show no special
notiÔ¨Åcation or hint about potential misspellings. In fact, the
word idobe (misspelling of adobe) is an existent word in
a Nigerian language, meaning ‚Äúdropping‚Äù.
For the Ô¨Årst three cases, users receive notiÔ¨Åcations or corrected
search results automatically, which diminishes chances of
attackers to manipulate and monetize the search results of
misspellings. However, for the non-auto-corrected case,
mistyped search queries coincide with legitimate existent words
and users receive results of the misspelled input. Therefore, it
is more likely that users cannot realize that they make query
misspellings and are tricked into clicking on the returned results.
Such misspelled keywords remain susceptible to search poisoning
attacks, which we coin as linguistic-collision misspellings. In this
paper, we focus on the non-auto-corrected cases and
conduct the Ô¨Årst large-scale empirical analysis to characterize
linguistic-collision SEO attacks.
Pharmaceutical examples of linguistic-collision SEO. Pro-
moting illicit pharmacy websites is a major target of cybercrim-
inals [18]. We illustrate the scheme with a search on cilis, a
misspelling of the pharmaceutical drug cialis (missing one
letter a in the middle). The misspelled variant exists in the
language of Esperanto and means ‚Äúchilis‚Äù. Figure 2 shows the
Google search results. We note that obviously the top search
results contain links to pharmacy websites. In particular, there are
three interesting observations. (1) The paid ads on the top refers
to a website selling pharmaceutical drugs. Vendors intentionally
purchase misspelled keywords for advertising on search engines
to gain trafÔ¨Åc and proÔ¨Åt. (2) The Ô¨Årst returned result is a
website under terrypaulson.com, Ô¨Çagged as malicious by
VirusTotal [19]. The website deploys cloaking mechanisms to
hide the true intention. If users directly visit the URL, the website
shows a page full of text. If users click through the Google
search result, the website turns to make online pharmacy sales
(as shown in Figure 2). (3) The third search result shows a URL
under oversand.es. Clicking the link will follow redirection
to reach a website online-pharmacyrx-canada.com,
which sells illicit drugs. The entry page is hosted at Spain, while
the landing page locates at Lithuania. The above Ô¨Åndings show
that through linguistic-collision SEO, it is comparatively easier
for cybercriminals to achieve high rankings on search engines
and evade Ô¨Åltering from authorities.
Another interesting example of linguistic-collision SEO is
clalis (replacing the Ô¨Årst i with l in cialis), which
does not trigger auto-correction on Google search. Similarly,
the returned results have a purchased ads linking to an online
pharmacy website goodrx.com. Moreover, U.S. Food & Drug
Administration (FDA) has advised consumers not to fall victim
to clalis scams [20] (which is not cialis). Abuse of linguistic-
collision keywords causes negative impact to users and degrades
the results‚Äô quality for search engines.
1314
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:46:50 UTC from IEEE Xplore.  Restrictions apply. 
IV. METHODOLOGY
In this section, we describe how we generate linguistic-
collision misspellings and establish ground truth data. We select
English and Chinese as our analyzed languages, since they
are the top two languages used by Internet users [1]. The
experiments are performed for Google and Baidu respectively,
which represent the largest search engine market share [21].
Figure 3 outlines the overall design of our methodology. The
workÔ¨Çow applies to both the English and Chinese experiments.
The circles represent the data sets that we generate during
the process. The descriptions about the data are shown above
each circle, and in the circles we show word examples. In
Figure 3, the English word example is cialis, referring to a
classic pharmaceutical drug. The Chinese word example is ‚ÄúÈ∫ª
Â∞Ü‚Äù (Pinyin as Ma2Jiang4), meaning a traditional Chinese
gambling game. The sizes of the circles simulate whether the
data size will increase or shrink compared to the data at the
previous step. In Section VI, we investigate details of the change
ratios of data sizes along the process.
therefore the dataset at
The process has three main steps. Given a set of target
keywords, we develop mechanisms to transform them into
misspelling candidates (¬ñ). Note that the generated candidates
are not necessarily linguistic-collision misspellings, and may
cause auto-suggestion/correction on search engines. Typically
one target keyword will correspond to multiple misspelling
candidates,
this step will expand
considerably. Next we Ô¨Ålter to obtain the candidates that produce
non-auto-corrected search results (¬ó), which will shrink the
keyword set. We collect the search results and the corresponding
URLs showing on the Ô¨Årst search page, typically around 10
results. Previous studies show that 70%‚Äì90% of user clicks
happen at the Ô¨Årst page of search results [22, 23]. We then
examine whether the URLs of the Ô¨Årst-page search results are
Ô¨Çagged as malicious by public blacklists (¬ò). Correspondingly,
we discern which misspelled keywords are abused for search
poisoning attacks and further characterize various facets of the
attacks.
A. English-language Design
Since English and Chinese languages have distinct lingual
properties, we use different design strategies, in particular for
the Ô¨Årst two steps. We introduce our design of English language
for misspelling generation and non-auto-corrected identiÔ¨Åcation.
Misspelling generation (¬ñ). To generate misspellings from the
English keywords, we use a modiÔ¨Åed version of the Damerau-
Levenshtein edit operations [24, 25]. The Damerau-Levenshtein
edit operations can (1) insert a character, (2) replace a character,
(3) transpose two adjacent characters, or (4) delete a character.
To restrict the number of the generated candidates, we use the
approach proposed by Moore and Edelman [26], which limits the
character replacement operation to characters that are adjacent to
the original key on a QWERTY keyboard (i.e., fat-Ô¨Ånger errors).
In addition, we allow replacement of any English alphabet
vowels, including letters a, e, i, o, u and y. We focus on edit
distances with one, as previous work has suggested that the
Damerau-Levenshtein edit operations with distance one contain
about 80% of all single mistake misspellings [24].
Non-auto-corrected identiÔ¨Åcation (¬ó). We Ô¨Årst introduce two
straw-man approaches to identify linguistic-collision words for
English misspellings. (1) Mapping to explicit vocabulary in
dictionaries. The approach has two main limitations. One is
that linguistic-collision misspellings may be legitimate words
in non-English languages, which requires to include numerous
multi-language dictionaries. Another issue is that users keep
inventing plausible words to describe new phenomena. For
instance, ‚ÄúLinsanity‚Äù follows most English spelling rules, but was
not in popular use until 2012. As we will show in Section V-B,
strict dictionary checking results in poor coverage of conÔ¨Årmed
linguistic-collision misspellings. (2) Brute-force checking on
search engines. The approach is to perform online checking for
all misspelling candidates on search engines. For a selected set of
keywords (Alexa top 1K and manually selected categories), we
conduct exhaustive checking to obtain comprehensive analysis
(see Section V). However, the approach cannot scale for large-
scale experiments (Alexa top 10K). For example, enumerating
all possible insertions (one of the Damerau-Levenshtein edit
operations) requires performing 26 queries per input character.
Such a high-level of overhead cannot be supported for web-scale
datasets, and we need to develop a method for eliminating
auto-corrected candidates more efÔ¨Åciently.
We adapt a Recurrent Neural Network (RNN) framework to
estimate how likely a word will not be auto-corrected by search
engines. RNNs have been widely applied to natural language
processing (as described in Section II ) and used to predict
sequential text outputs. Our primary insight is that a formally
recognized word should display character-level patterns similar
to the rest of dictionary vocabulary for users to adopt it. RNNs
can generate high-quality language models for character-level
representations [27, 28]. Our developed approach effectively
addresses the challenges of recognizing new words (not covered
in dictionaries) and linguistic-collision words in non-English
languages.
Figure 4 demonstrates our framework for training an adapted
RNN and generating conÔ¨Ådence estimates on misspelling
candidates. The system consists of two phases, training phase
and prediction phase. (1) In the training phase, we adapt to train
with individual words from dictionaries. We use dictionaries
to learn from a large corpus of words and capture the general
English lexical patterns. We append a null character to the
beginning and end of the word to allow the RNN to learn about
word boundaries. With the popular TensorÔ¨Çow library [29], we
train a character-based RNN to recognize the typical structure of
legitimate words. After randomly initializing the model weights,
we use the Adam optimization algorithm [30] with gradient
clipping to reduce the cross-entropy during training. (2) In
the prediction phase, our goal is not to generate arbitrary text
content, but to predict whether particular misspellings that we
have generated will not be auto-corrected by search engines (i.e.,
coincidentally legitimate words). Given an input preÔ¨Åx (cid:2)x (e.g.,
goog in Figure 4), an RNN outputs a probability distribution (cid:2)p
for the alphabet on which character is most likely (in the example
1315
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:46:50 UTC from IEEE Xplore.  Restrictions apply. 
7UDLQLQJ
6
(
$
5 &
/670
+LGGHQ
/D\HU
?
6
(
$
5
? * 2 2 *
5DQGRPL]DWLRQ
9HFWRUL]H
0LVVSHOOLQJ
*HQHUDWRU
9RFDEXODU\LQ'LFWLRQDU\
7DUJHW.H\ZRUGV
3UHGLFWLRQ
7UDLQHG5110RGHO
(QWURS\
(VWLPDWRU

. 
/

0 

2XWSXW
3UHGLFWLRQ


		
		
		










Figure 4: RNN framework to predict how likely misspelling candidates
for English original keywords will cause non-auto-corrected results on
search engines.
Figure 5: Fuzzy pinyin and anatomical parts to produce the sounds.
We include pinyin strings that are easy to confuse with each other.
letter l has the highest probability). We adapt to calculate the
average entropy of the RNN‚Äôs prediction over each output
character. Suppose the candidate word has n letters, the size of
the character set is l, and the distribution output of the RNN
at letter position k (1 ‚â§ k ‚â§ n) is (cid:2)pk = (pk1, pk2, . . . , pkl).
The entropy at the position k is H((cid:2)pk) =
i=1 pki log2(pki).
The average entropy for a given prediction can be calculated as
(cid:2)n
j=1 H((cid:2)pj)/n. Intuitively, the average entropy is a normalized
estimate of the RNN‚Äôs conÔ¨Ådence that the misspelling could
plausibly be used as an existent word. Low entropy values
indicate misspellings which should be more likely to be non-
corrected.
(cid:2)l
B. Chinese-language Design
The linguistic properties of Chinese words require different
strategies to generate misspelling candidates and identify non-
auto-corrected search keywords.
Misspelling generation (¬ñ). For each target keyword, we Ô¨Årst