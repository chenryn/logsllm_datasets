分析方法其实并不是狭义的特指某一个方法，分析方法是多变的，只要能达到我们的需求都可以称之为一种”方法“，如果你的数据质量不错，那么有时候一个简单的结构化查询语句便是一种分析方法，而有时候分析方法可能是”增量+结构化查询“的组合，有时候可能分析方法是”计算+结构化查询“的组合，有时候分析方法可能是”计算+数据挖掘“的组合，又或者是一次关联的查询，又或者是只是一次简单的统计分析，又或者是”计算+机器学习“的模型训练与实际应用。分析方法虽然千变万化，但是逃不出一个本质，在原有的数据上通过合理的方法得到有用的结论。
5、可视化/价值输出/结果验证  
如果你已经完成了一些分析，得到了一些结果，那么到这一步便是对结果进行验证，对其中的具有通用的价值进行提取，最后便是对数据进行可视化。并根据得到的结论重新思考整个流程，思考是否达到了我们的分析目的，思考哪些步骤还有提升的空间，是否能进一步的提高数据质量，是否能使用不同的分析方法得到更好的答案。
其实整个过程并不复杂，但如果需要考虑实际的工程化问题，需要考虑拓展性、通用性、可维护性等问题的话，那么整个工程的建设将会非常复杂，因为在整体平台中，我们需要无缝拓展各类数据，需要考虑数据之间如何关联，需要考虑增量后的数据维护，还要考虑数据不同的时间维度，另外还有就是不同的算法如何兼容整个线上的数据，还要考虑算法如果有特殊的计算需求，如对数据进行归一化处理、one-hot、TF/IDF等等，我们在实践完成数据分析平台后，由于平台的技术架构限制，导致很多分析需求根本无法在原有的平台上直接应用，一些特殊的需求甚至需要改动架构才能实现，作为真正的数据分析平台，需要具备较为良好的设计思想，抽象能力，否则最后只能进退两难，最后造成资源浪费。
## 九、数据价值输出
在安全这个领域，最直接输出的价值便是威胁情报，当然通过数据分析得到的任何有价值或实际意义的信息或结论都可称之为数据价值的输出。  
个人最开始听说“威胁情报”是在16年，那时候对这个词的认识和理解仅仅停留在“IP、域名、文件Hash、邮箱”等关联出的信息，翻了翻自己的所以关于威胁情报的笔记，发现正式开始系统性的学习、整理、收集以及尝试是在17年的6月左右，遗憾的是根据当时的阶段性规划，我们的重心并不在此，而在于通过应用本身或系统本身产生的日志数据来分析攻击者的行为从而实现溯源，所以威胁情报关于这一块作者的经验还是有限。其实溯通常情况下溯源的重要需求点在于寻找攻击者（即准确得知关于所有敌方的情报），而其次才是分析历史行为，所以如果仅把重心放在从内部历史数据分析行为这一个环节上，并不能实现真正意义的溯源。  
不过万物相通，在本质上情报也属于数据的一种，如何分析，如何关联，如何验证情报的可信度，其中的方法非常的类似。  
那么我们从数据中到底能提取出哪些有用的信息呢？大概分类如下：
一、黑客/团伙人物画像  
二、黑客动向  
三、黑客攻击手法模型库  
四、妥协指标(IOC)  
五、黑客工具指纹库
此分类并不严谨，此处是按照不同的侧重点进行区分，而非业内标准，仅仅只是告诉大家，我们可以去做这些方向的数据分析与提取。
其实安全的本质是信息是否对等，在攻击者的视角里，攻击者知道了我们不知道的系统脆弱点所以导致我们被攻陷，在防御者视角里，我们无法得知关于攻击者的信息，导致风险被搁置从而造成持续损失，而情报是对信息对等的一个很好的诠释与缓解方案。  
关于情报获取有非常多的方式，而其中最主要的来源便是通过各类安全产品记录的数据进行提取与管理，如EDR、IDS、IPS、Waf、流量审计、开源情报、日志审计。某些厂商，先天具有情报的来源方式，如拥有三分天下的阿里云，又比如在流量分析行业领头的科来，又比如占领终端安全一席之地的360天擎，然而如果不具备对数据的理解能力以及关联能力，以及对此的工程化能力，那么数据中的价值将无法完全发挥。
## 十、安全场景杂谈
目前行业内的安全产品，其实基本都和数据分析强相关，你能在很多产品中看到各种不同分析的影子，而分析的策略基本来源于安全专家的领域知识，而某些在安全专家脑海里的“经验”却很难灵活的进行工程化，从而给大家一种感觉，所有的安全产品都是基于策略与规则，当有安全厂商说，我们是语法树解析，我们是应用时保护，我们是机器学习，我们是无监督算法智能识别等等等的说法的时候，总会有人对此不屑一顾又或者刨根问题，甚至开怼说，你这不还是规则么，当你终于让客户理解了你区别于传统的点的时候，客户又会将传统的安全产品效果和你讲述的进行对比，如别人的WAF一天能拦截并记录到十万百万的攻击，为啥你家的RASP一个月了啥动静也没有，而用户殊不知是因为还没有人能真正的攻击成功并进入到Hook点（这是一个值得思考的产品改进上的问题），又比如用户会说，明明我家的SIEM帮我统计出这一周有100多个黑客，怎么你就分析出只有4个黑客，你家的分析能力也太弱了，殊不知别人家是
**命中规则的IP**
就算为一个黑客，而专业的分析却站在时间维度上、行为维度上、情报维度上、无差别攻击上进行了攻击者合并，最后剔除出真正具有攻击性意图上的黑客（这是一个值得思考并改进的的分析报告完整性的问题）。  
那么关于 **数据驱动安全** 可用于哪些安全场景呢？如下：  
~~Web应用攻击溯源系统(WATS)~~  
应用安全风险管理(ASRM)  
安全信息与事件管理(SIEM)  
网络态势感知(CSA)  
安全运营中心(SOC)  
态势感知与安全运营平台(NGSOC)  
用户行为分析(UEBA)  
威胁情报(TI)  
..  
目前安全行业的安全产品五花八门，各有所长又各有所短，大部分安全产品仅在某一些点上做的十分优秀，而安全是一个面，未来，谁能将数据运用到极致，且领先建立起安全的生态，谁便能成为整个行业的引领者。
## 十一、数据分析平台工程化建设思路
说起工程化，大家似乎都马上想到ELK，但是随着安全需求的复杂化，使用ELK已经很难完成我们的需求，且其中的维护成本过高，比如你要使用学会Ruby写Logstash的插件来完成各种Filter需求，且不同的终端需要进行不同的配置。又比如你要从网络连接信息中获取数据，从进程中获取数据，甚至从内存中获取数据，而此时Logstash已经无法满足。另外就是使用ELK很难进行有计算需求的部分，而机器学习和数据挖掘所学习的便是大量结果计算后提取的特征值。另外就是在ELK体系中，很难把机器学习的流程完美的加入到其体系当中。我们先来看看关于大数据体系常规的技术架构：  
”纯净版“：  
”专业版“：  
”简易流程图“：  
如果你已经自行搭建或者使用过类似ELK、Splunk、安全易以及我们的鲲鹏数据分析平台等类似的数据分析产品，那么想要构建这样一个大数据体系其实并不复杂，各位同学可以根据自己的需求或者目的将侧重点放在不同的地方，如你想更深的理解整个体系中的每个流程，那我建议你首先实际部署整套环境。首先安装在需要采集日志的地方安装并配置Logstash、Flume、FileBeat，然后搭建Kafka并将采集端采集的数据输入到Kafka集群，然后搭建Storm或者Spark集群，并采用自己熟悉的语言进行研发（Storm和Spark都提供各种语言的开发接口，如果你只是为了学习可以使用Python/Scala，如果考虑后期维护性可以使用Java）,Spark案例：
研发的主要功能为从Kafka消费数据，并根据需求完成数据的标准化、结构化、增量解析、计算等等，假设你只是想要从宏观统计安全状况，那么一个日志格式解析器+一个安全相关的增量解析器基本上就能满足你的需求，最后我们将解析后的结果缓存到Redis或者定时存储到ElasticSearch，然后通过Kibana或者其他可视化工具进行相应的可视化即可。如果你能完成到这一步，那么基本上你已经具备了基本的分析平台构建能力，而想要让平台的安全能力不断提升，想要实现各种不一样的安全需求，那么则需要考虑的就是平台的通用性、拓展性、维护性，协同开发。还有就是前面所提到的经验转化以及其他分析方法，如何将不同的研究成果进行工程化的转化并在此架构中测试与实践
## 十二、结束语
写完这篇总结的文章，作者感觉到了自身的渺小，”数据驱动安全“，其实是一个非常大的定义，在提的人很多，在做的人也很多，但想要真正的把数据运用到极致，我们还有很远的路要走。
## 十三、拓展阅读
### 数据相关
### 开源奉献
PS：bloodzer0通过自身的丰富甲方经验，维护以及分享了关于企业安全体系建设相关的技术与思路，后期作者也会参与到bloodzer0的工作中，和他一起维护日志分析相关的知识与经验
## 题外话
~~以下为作者自述，仅代表作者自身观点，不代表任何权威，可能会引起特定人群的不适，非战斗人员请撤离。~~
作者在数据分析领域的经验其实在本人看来还尚浅，既无法和某些具有APT追踪能力的团队相媲美，又无法和某些专业深耕数据产品的团队所匹敌。作者在此领域的经验不足两年，且深耕于此的初衷仅仅是因为想解放双手，让分析从此不再需要耗费大量的人工精力，让应急从此变得轻松又有效率，让聪明且思想跳跃的安全从业者（黑客）能把精力放在更重要的事情上（改变世界），这也是分享此篇文章的原由。反观业内，作者从两年前开始学习数据分析相关的知识，发现能学习的东西非常有限，所有的知识零零散散，和安全相关更加是寥寥无几。对于初学者来说甚至连学习到ELK搭建进行统计安全概况都觉得是一件非常有技术含量的事情，而我原本认为这样的文章或知识应该属于常识，就像你去搜索如何安装JDK环境或者搜索某个状态码代表什么含义一样。说回现状，目前行业内的分析产品大部分都停留在某位大佬所说的“看热闹”阶段，分析类产品需要进一步提升自身的能力，需要进一步证明自身的能力与价值，真正体现“数据驱动安全”，而不是“热闹展现安全”。  
此篇分享其实在11月初就开始撰写，大约花了三周的业余时间构成，初次投稿在11月底-12月初，由于公司领导认为其中涉及未投入到市场的产品被公开，其中包括产品界面（原型），实现流程及思路，故本人联系版主对文章进行了处理，个人把此次事件理解为“资本主义与技术分享”的一次冲突，考虑到涉及利益相关问题，本人已经将溯源相关产品图以及相关具体技术实现逻辑进行了修订与删除，所以大家无法看到目前溯源相关的成果，如果对此产品有兴趣的需求方，欢迎通过[官方&商务](http://www.anbai.com/about/)渠道联系进行产品演示。