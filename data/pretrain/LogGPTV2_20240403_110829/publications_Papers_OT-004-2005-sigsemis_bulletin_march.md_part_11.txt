procedure and Model
contract
Ongoing IST projects http://www.cordis.lu/ist/projects/projects.htm
INFSO.E2 Web site and Call http://www.cordis.lu/ist/directorate_e/kmcc/index.htm
related documentation
EC staff General enquiries and pre-proposals to:
PI:EMAIL
Information session and Luxembourg, 20 January 2005
bilaterals with EC staff Jean Monnet conference complex
http://www.cordis.lu/ist/directorate_e/kmcc/index.htm
63
AIS SIGSEMIS Bulletin 2(1) January-March 2005
ANNEX
IST Workprogramme 2005-2006, p. 22-23
2.4.7 Semantic-based Knowledge and Content Systems
Objectives
To develop semantic-based and context-aware systems to acquire, organise, personalise, share and use the
knowledge embedded in web and multimedia content. Research will aim to maximise automation of the
knowledge lifecycle and to achieve semantic interoperability between heterogeneous information resources and
services, across content types and natural languages. To pioneer intelligent content, which will be self-
describing, adaptive to context and user information needs, and exhibit a seamless interaction with its
surroundings and the user.
Focus
1. Knowledge acquisition and modelling, capturing knowledge from raw information and multimedia content in
webs and other distributed repositories to turn poorly structured information into machine-processable
knowledge.
Foundational research will address formal models and languages for representing static and dynamic
knowledge, and develop the methodological and technical base of interoperable ontologies for semantic
webs, in sectors as diverse as e.g. manufacturing, e-business, science or geo-spatial information,
emphasizing maintainability, extensibility and data-driven approaches. Component level research will
address methods and tools aimed at higher levels of information harvesting, including automated
knowledge discovery, metadata extraction, annotation and summarisation, concept based and contextual
retrieval of all types of digital content, paying due attention to cross-media and cross-lingual aspects. Priority
will be given to open architectures or alternative approaches ensuring seamless interworking between
components and their integration within complete systems.
Instruments: IPs, NoEs, STREPs
2. Knowledge sharing and use, combining semantically enriched information with context to provide actionable
meaning, applying inferencing and reasoning for decision support and collaborative use of trusted
knowledge between organisations.
Foundational research will address in particular the semantics of evolving processes and computational
models for context of use. Component- and system-level research will yield knowledge and data /
application integration technologies enabling semantic-based collaboration services and processes, leading
to scaleable platforms to manage, search, share, personalise, present and exploit complex knowledge
spaces that cross the boundaries between organisations or communities. The overall aim is to develop powerful
and yet flexible solutions that are portable across key application domains in industry, trade, science and
society at large.
Instruments: IPs, NoEs, STREPs, SSAs
3. Exploring and bringing to maturity the intelligent content vision, whereby multimedia objects integrate basic
content with metadata and knowledge about users and contexts. These objects will learn to react to
different stimuli and pro-actively interact with agents, devices and networks, and with each other. They
will have the ability to seamlessly aggregate to create new content and services tailored to user needs.
Foundational research will focus on how such objects can be: created, including collaborative authoring and
extraction of metadata as content is created; managed e.g. combined by means of automated workflows;
rendered for different users and platforms; exchanged and traded with adequate efficiency and trust. Due
consideration will be given to user control as well as to content protection. Component-level research will
provide proof-of-concept methods and tools for creating, aggregating and communicating such objects,
within a unifying framework supporting different content types, across heterogeneous platforms and
networks, in representative use scenarios. System-level work will focus on metadata based systems and
processes aimed at realising content adaptable to different users and formats, with a view to enhancing
both effectiveness and flexibility.
Instruments: IPs, STREPs, SSAs
64
AIS SIGSEMIS Bulletin 2(1) January-March 2005
RTD work should address issues such as modelling of user information behaviours and how to hide
complexity from the non-expert user. Projects should maximise cross-fertilisation between approaches and
disciplines, promote open architectures and coherent stacks of standards, and help build shared
infrastructures for research, training and technology evaluation. Ambitious test-beds will demonstrate the
successful integration of component technologies into robust, high performance and scalable systems in
representative domains, which are readily transferable to other knowledge-intensive sectors.
Instruments: IPs are expected to encompass all stages of the research, where appropriate cutting across the
above research lines, and to address system-level integration in realistic scenarios. Foundational and
component-level research and discrete solutions for particular domains may also be the subject of STREPs.
NoEs should build communities focusing on longer-term, cross-disciplinary research related to knowledge
representation and reasoning or understanding of non-textual information. SSAs should address case studies
and best practices, and more generally drivers and inhibitors for the deployment of new technologies by early
adopters.
Indicative budget: IPs, NoEs: 70%; STREPs, SSAs: 30%
Call information: IST Call 4
65
AIS SIGSEMIS Bulletin 2(1) January-March 2005
REGULAR COLUMNS
In this Issue:
• Semantic Search Technology Technologies by Dr. Peter Alesso
In this issue: Swoogle: A Semantic Web Search Engine
• Semantic Web Technologies by Dr. Jessica Chen Burger
In this issue: A Set of Collaborative Tools for the Semantic Era
• [NEW COLUMN] RDF Technologies – Foundations, Applications and Developments by
Heiner Stuckenschmidt
In this issue: RDF is not Re-inventing the Wheel
66
AIS SIGSEMIS Bulletin 2(1) January-March 2005
REGULAR COLUMNS
Semantic Search Technology Technologies by Dr. Peter Alesso
H. Peter Alesso,
PI:EMAIL
Computer Science Department,
Ohlone College, CA
BOOKS:
• "Building Semantic Web Services," A.K. Peters Ltd., 2004.
• "The Intelligent Wireless Web," Addison-Wesley, Dec. 2001.
• "e-Video: Producing Internet Video as Broadband Technologies Converge," Addison-Wesley, July 2000.
SOFTWARE PUBLICATIONS:
• "Wealth Insurance," Compton's NewMedia, Inc., 1989.
• "Engineering Design," VSL, 1994.
• "Semantic Web Author," A. K. Peters, Ltd., 2004.
Column Description
SCOPE
Articles and news covering explanations, examples, and advances in emerging semantic search
applications including: semantic search technology, latent semantic indexing, ontology matching,
semantic search agents and semantic data clustering. In addition, we will include current
development, algorithms, inference applications and development software tools.
DESCRIPTION
Search engine’s, such as, Google with its 300 million hits per day and over 4 billion indexed Web pages are a
vital part of today’s World Wide Web. The prevaling attitude of surfers on the Web is: When you have a
question - fire up Google.
Current commercial search technologies has been based upon two approaches: human directed search and
automated search. In general, human directed search engine technology utilizes a database of keyword
concepts and references. A great deal of existing search engine technology uses keyword searches to rank
pages, but this often leads to irrelevant and spurious results. Some specific types of human-directed search
engines, such as Yahoo!, use topic hierarchies to help to narrow the search and make search results more
relevant. These topic hierarchies are human created. Because of this, they are costly to produce and maintain
in terms of time, and are subsequently not updated as often as the fully automated systems.
67
AIS SIGSEMIS Bulletin 2(1) January-March 2005
The automated form of Web search technology is based on the Web crawler, spider, robot (bot), or agent
which follows HTTP links from site to site and accumulates information about Web pages. This agent-based
search technology accumulated data automatically and is continuously updating information.
As Semantic technologies become more powerful, it is reasonable to ask for better search capabilities which
can truly respond to detailed requests reducing the amount of irrelevant results. A semantic search engine
seeks to find documents that have similar ‘concepts’ not just similar ‘words’. However, most semantic-based
search engines suffer performance problems from the scale of a very large semantic network. In order for the
semantic search to be effective in finding responsive results, the network must contain a great deal of relevant
information. At the same time, large network must process many paths to a solution.
In this column, we will explore semantic search applications including: semantic search technology, latent
semantic indexing, ontology matching, semantic search agents and semantic data clustering. In addition, we
will include current development, algorithms, inference applications and development software tools.
AUDIENCE
Web Service developers, Web site developers, Semantic Web specialists, and search technology
researchers will all benefit from this exposition of semantic search technology supporting automatic
Web services.
Swoogle: A Semantic Web Search Engine
by H. Peter Alesso , for Jan-March 2005 AIS SIGSEMIS Bulletin.
Swoogle: A Semantic Web Search Engine Swoogle is a crawler-based indexing and retrieval system for
Semantic Web documents in RDF or OWL. It is being developed by the Computer Science and Electrical
Engineering Department of the University of Maryland Baltimore County. It extracts metadata and computes
relations between documents. Discovered documents are also indexed by an information retrieval system to
compute the similarity among a set of documents and to compute rank as a measure of the importance of a
Semantic Web document.
The Semantic Web, currently in the form of RDF and OWL documents, is essentially a parallel universe to the
Web of online HTML documents. A Semantic Web document (SWD) is known for its semantic content. Since
no conventional search engines can take advantage of semantic features, a search engine customized for
SWDs, especially for ontologies, is necessary to access, explore and query the Web’s RDF and OWL
documents.
A prototype Semantic Web search engine called Swoogle, facilitates the development of the Semantic Web, for
finding appropriate ontologies, and helping users specify terms and qualify type (class or property) (see
Figure 1). In addition, ranking mechanism sorts ontologies by their importance.
In order to help users to integrate Semantic Web data distributed on the Web, Swoogle enables querying
SWDs with constraints on the classes and properties. By collecting meta-data about the Semantic Web,
Swoogle reveals interesting structural properties such as how the Semantic Web is connected, how ontologies
are referenced, and how an ontology is modified externally.
Swoogle is designed as a system that will scale up, in order to handle millions of documents. Moreover,
Swoogle also enables rich query constraints on semantic relations. The Swoogle architecture consists of a
database that stores metadata about the SWDs. Two distinct web crawlers discover SWDs and components to
compute semantic relationships among the SWDs. Also, an indexing and retrieval engine, a simple user
interface for query and agent/web service APIs provide useful services.
68
AIS SIGSEMIS Bulletin 2(1) January-March 2005
The algorithm, Ontology Rank, inspired by Google’s Page Rank algorithm is used to rank search results. This
algorithm takes advantage of the fact that the graph formed by SWDs has a richer set of relations. In other
word, the edges in this graph have explicit semantics. Some are defined or derivable from the RDF and OWL
languages and others by common ontologies (e.g.,FOAF).
Figure 1 A prototype Semantic Web search engine called Swoogle
Semantic Web Documents
Semantic Web languages based on RDF allow one to make statements that define general terms (classes and
properties). A Semantic Web Document (SWD) is a document in a semantic Web language that is accessible to
software agents. A SWD is an atomic information exchange object in the Semantic Web.
Two kinds of documents form Semantic Web ontologies (SWOs) and Semantic Web databases (SWDBs). A
document is a SWO when a significant proportion of the statements it makes, define new terms (e.g., new
classes and properties) or extends the definition of terms defined in other SWDs by adding new properties or
constraints. A document is considered as a SWDB when it does not define or extend a significant number of
terms. A SWDB can introduce individuals and make assertions about them or make assertions about
individuals defined in other SWDs. For example, the SWD http://xmlns.com/foaf/0.1/index.rdf is
considered a SWO in that its 466 statements (i.e. triples) define 12 classes and 51 properties but introduces no
individuals. The SWD http://umbc.edu/~finin/foaf.rdf is considered to be a SWDB since it defines or
extends no terms but defines three individuals and makes statements about them.
Swoogle Architecture
69
AIS SIGSEMIS Bulletin 2(1) January-March 2005
Swoogle's architecture can be broken into four major components: SWD discovery, metadata creation, data
analysis, and interface. This architecture is data centric and extensible. These components work independently
and interact with one another through a database.
Figure 2 Swoogle Architecture
.The SWD discovery component discovers potential SWDs throughout theWeb. The metadata creation
component caches a snapshot of a SWD and generates objective metadata about SWDs at both the syntax level
and the semantic level. The data analysis component uses the cached SWDs and the created metadata to
derive analytical reports, such as classification of SWOs and SWDBs, rank of SWDs, and the Information
Retreival (IR) index for the SWDs. The interface component focuses on providing data service.
Finding SWDs
Finding URLs of SWDs is a straightforward approach to search through a conventional search engine. It is not
possible for Swoogle to parse all documents on the Web to see if they are SWDs, however, the crawlers
employ a number of heuristics for finding SWDs starting with a Google crawler which searches URLs using
the Google Web Service.
Relations among SWDs
Looking at the entire Semantic Web, it is hard to capture and analyze relations at the RDF node level.
Therefore, Swoogle focuses on SWD level relations which generalize RDF node level relations.
Google PageRank
Google introduced PageRank evaluates the relative importance of Web documents. Given a document
A, A's PageRank is computed by equation:
PR(A) = PRdirect(A) + PRlink(A)
PRdirect(A) = (1 ¡ d)
PRlink(A) = d ³PR(T1)
C(T1) +...+PR(Tn)
C(Tn) ´
where T1,..., Tn are Web documents that link to A; C(Ti) is the total outlinks of Ti; and d is a damping factor,
which is typically set to 0:85. The intuition of PageRank is to measure the probability that a random surfer will
70
AIS SIGSEMIS Bulletin 2(1) January-March 2005
visit a page. Equation 2 captures the probability that a user will arrive at a given page either by directly
addressing it via PRdirect(A), or by following one of the links pointing to it via PRlink(A).
Ranking SWDs
Given SWDs A and B, Swoogle classifies inter-SWD links into four categories: (i) imports(A,B), A imports all
content of B; (ii) uses-term(A,B), A uses some of terms defined by B without importing B; (iii) extends(A,B), A
extends the definitions of terms defined by B; and (iv) asserts(A,B), A makes assertions about the individuals
defined by B.
These relations should be treated as a surfer observes imports(A,B) while visiting A, follow this link because B
is semantically part of A. Similarly, the surfer may follow extends(A,B) relation because it can understand the
defined term completely only when it browses both A and B. Therefore, the assigned weight is different which
shows the probability of following that kind of link, to the four categories of inter-SWD relations. The RDF
node level relations to SWD level relations, counts the number of references. The more terms in B referenced
by A, the more likely a surfer will follow the link from A to B.
Based on the above, given SWD a, Swoogle computes its raw rank using:
Figure 3 Swoogle Rank Algorithm
The hypothetical Rational Random Surfer(RRS) retain PageRank's direct visit component; the rational surfer
can jump to SWDs directly with a certain probability d. However, in the link-following component, the link is
chosen with unequal probability {f(x;a)/f(x)}, where x is the current SWDB.
Indexing and Retreiving SWDs
Central to a Semantic Web search engine is the problem of indexing and searching SWDs. It is useful to apply
IR techniques to documents not entirely markup. To apply search to both the structured and unstructured
components of a document it is conceivable that there will be some text documents that contain embedded
markup.
Information retrieval techniques have some value characteristics, such as researched methods for ranking
matches, computing similarity between documents, and employing relevance feedback. These compliment
and extend the retrieval functions inherent in Swoogle.
71
AIS SIGSEMIS Bulletin 2(1) January-March 2005
Currently, the most popular kinds of documents are FOAF files and RSS files. Swoogle is intended to support