third party libraries [86], [87]. The threat model is that once
a user grants permission, an app or library is able to access
and send the related data off of the device. The set of apps
we evaluate consists of the 95 apps whose App Store pages
link to the generated policies we collected (§ III-A). After
we downloaded and installed the apps from the App Store on
an iPhone, we explored their permission use. If necessary, we
created an account with the app, navigated to all views, and
tapped on every interactive element to trigger any permission
uses. To avoid under-disclosures it is not sufﬁcient that the
5Apple CEO Tim Cook explained in an interview with MSNBC [47]:
“[Apple is] looking at every app in detail. What is it doing? Is it doing what
it is saying it is doing? Is it meeting the privacy policy that they are stating,
right? And so we are always looking at that.”
5
et al. only offer Location, Contacts, and Camera permissions
without any other options or free-form ﬁelds. Indeed, any
permission use we observed for apps with policies from
TermsFeed et al. — except for the location permission use
— resulted in an under-disclosure.
Over-disclosures are particularly pronounced for the loca-
tion permission with 21% (Figure 1). The majority of these
over-disclosures are contained in privacy policies generated
by Termly, which has, by far, the largest percentage of over-
disclosures with 70% (Table III). A reason for these frequent
location over-disclosures in Termly policies could lie in the
policy text that is generated when answering afﬁrmatively that
an app will “be collecting any derivative data” from users.
The rather unspeciﬁc term of “derivative data” is not tailored
to apps and covers a host of data types “such as your IP
address, browser and device characteristics, operating system,
language preferences, referring URLs, device name, country,
location, and information about how and when you use our
Apps” (emphasis added) [69]. In addition, Termly is asking
about location use in multiple other questions. Afﬁrmative
answers to those will also include location use in the generated
policy. Overall, apps’ permission use is not well reﬂected in
the examined policies. Our results illustrate that the design of
a generator’s questionnaire can have an adverse impact on the
accuracy of disclosures in generated policies.
3) Library Under- and Over-disclosures: Oftentimes, de-
velopers are not aware of third party library practices or if they
are, they may not feel responsible for those [14], [45]. The
integration of libraries can result in compliance issues if their
use is not properly disclosed in privacy policies. We examined
the integration of 10 popular libraries in our set of 95 apps
and their disclosure in the generated privacy policies. While
we interacted with each app, we decrypted and observed its
resulting web trafﬁc using the Fiddler web proxy [54]. After we
had accessed all views and interactive elements of an app we
analyzed the log ﬁles with the captured trafﬁc. If, for instance,
an app made a request
to graph.facebook.com, we
concluded that it integrates Facebook. We used the following
list of ad and analytics domains to identify third party library
integration.
(1) AdMob: googleads.g.doubleclick.net,
pubads.g.doubleclick.net
(2) Facebook: graph.facebook.com
(3) Vungle: ads.api.vungle.com
(4) AdColony: events3.adcolony.com
(5) MoPub: ads.mopub.com
(6) Chartboost: live.chartboost.com
(7) Tapjoy: ws.tapjoyads.com
(8) UnityAds: unityads.unity3d.com
(9) InMobi: sdktm.w.inmobi.com
(10) Flurry: data.flurry.com
We require disclosure of the speciﬁc libraries, per GDPR
Art. 13(1)(e), 14(1)(e), and not just of “other companies,” for
example. Apart from the GDPR, some laws generally only
require the disclosure of categories of third parties and not
their speciﬁc names (e.g., “ad network” instead of “AdMob”).
However, as all generators provide functionality for selecting
or entering speciﬁc third parties in their questionnaire, we are
holding them to that standard.
6
Fig. 1: Permission under- and over-disclosures (by permission).
∗UIImagePickerController allows use of some photos with-
out Photos permission. Therefore, it is not included here.
Questionnaire-based
Policy Generator
App Privacy Policy Generator
iubenda
Termly
TermsFeed et al.
Apps With At Least
Apps With At Least
One Under-disclosure One Over-disclosure
7/20 (35%)
5/20 (25%)
5/20 (25%)
18/35 (51%)
0/20 (0%)
9/20 (45%)
14/20 (70%)
2/35 (6%)
TABLE III: Permission under- and over-disclosures (by generator).
policy of an app contains general disclosures (e.g., “we use
your device data”). Rather, we require that a policy speciﬁes
a certain type of information (e.g., “we use your location
data”). Under-disclosures can be particularly problematic for
third party permission uses as users may incorrectly assume
that granting a permission only refers to an app itself but
not to integrated libraries. An over-disclosure refers to an
app not using a permission that is actually disclosed in its
policy. Arguably, over-disclosures are less harmful than under-
disclosures as an app will simply use fewer permissions than
disclosed. However, over-disclosures can contribute to eroding
trust in privacy policies in general as those may not appear
trustworthy if apps behave differently from what policies
describe. While our analysis of over-disclosures aims to be
as comprehensive as possible, it should be noted that there
is always a possibility of missing to trigger a permission,
which should be taken into account for the interpretation of
our results.
Apps with policies from iubenda and Termly have fewer
under-disclosures compared to apps with policies from the
App Privacy Policy Generator and TermsFeed et al. The latter
exhibits the maximum with 51% (Table III). One reason for
iubenda and Termly covering apps’ permission uses better
than the other two could be the design of the generators’
questionnaires. iubenda’s and Termly’s questionnaires include
menus to select the permissions an app uses and also offer
the option to manually provide additional permissions not
contained in the menus. On the other hand, the App Privacy
Policy Generator has just a free-form text ﬁeld and TermsFeed
Questionnaire-based
Policy Generator
App Privacy Policy Generator
iubenda
Termly
TermsFeed et al.
Apps With At Least
Apps With At Least
One Under-disclosure One Over-disclosure
5/20 (25%)
6/20 (30%)
5/20 (25%)
22/35 (63%)
1/20 (5%)
5/20 (25%)
2/20 (10%)
5/35 (14%)
TABLE IV: Library under- and over-disclosures (by generator).
offering à la carte pricing where the addition of each library
category, e.g., analytics, advertising, or marketing, will incur
extra charges. Also, TermsFeed is the one we’re focusing solely
on now. Developers may feel disincentivized from extensive
privacy disclosures due to the increase in fees that would come
with those. Thus, the reason for TermsFeed et al.’s relatively
higher levels of library under-disclosures may be rooted in its
pricing structure indicating that such can have an impact on
privacy compliance as well.
4) Improper Disclosures of Childrens’ Apps: Online Ser-
vice operators who direct their apps to children under 13 or
who have actual knowledge of such users must provide COPPA
disclosures in their policies (Appendix A). For example, they
must disclose that a parent can review, have deleted, and refuse
to permit further collection or use of the child’s personal infor-
mation [COPPA §312.4(d)(3)]. Whether an app is directed to
children depends, among others, on its subject matter, its visual
content, and the use of animated characters or child-oriented
activities and incentives, music or other audio content [29]. In
our set 6 of the 95 apps meet these criteria. However, neither
of the apps’ policies contain any COPPA disclosures. Rather,
they assume teenage or adult users with 3 policies requiring
a minimum age of 13 and the other 3 requiring a minimum
age of 18. However, even if the developers wanted to make
accurate COPPA disclosures, the generators would not allow
them to do so comprehensively as they do not implement all
requirements (Table I).
61% of apps’ policies require users to be at least 13 or
18 years old while their apps are rated for age 4+ (Figure 3).
This discrepancy is not problematic because age ratings do not
mean that an app is suitable for children of a certain age but
rather only that it is unsuitable below that age [41]. However,
for 2% of apps the discrepancies between their age ratings
and policies’ age requirements present a problem. Their age
ratings require users to be 17+ while their policies only require
users to be at least 13. The policies effectively allow access
to violence, nudity, and other content unsuitable for younger
users. Age ratings are voluntary and self-regulatory industry
efforts. Still, policies should be consistent with the ratings.
IV. GENERATING POLICIES WITH PRIVACYFLASH PRO
We aim to increase privacy transparency and reduce com-
pliance issues with a privacy policy generator that squarely
ﬁts developers’ mental model and tightly integrates into the
software development process and tools.6
6We presented PrivacyFlash Pro at iOSoho - New York City’s largest iOS
Engineer Meetup [34] and were featured on Brian Advent’s iOS development
YouTube channel [3]. All source code is available at https://github.com/
privacy-tech-lab/privacyﬂash-pro/, accessed: January 7, 2021.
Fig. 2: Library under- and over-disclosures (by library).
Fig. 3: App Store age rating and policy age requirements.
Our results reﬂect the online advertising duopoly [52] with
Google’s AdMob and Facebook each being integrated in about
a third of the apps. However, only 15% of apps disclose in their
policies that they integrate AdMob and 20% do not. The results
for under-disclosures of Facebook are similar. 20% of apps
disclose Facebook integration and 21% omit such disclosure.
This trend holds for all other libraries as well, albeit, at lower
integration levels (Figure 2). Compared to the other generators’
policies, it is striking that the rate for under-disclosures in
policies from TermsFeed et al. is more than twice as high
with 63% (Table IV).
Termly and iubenda provide menus with hundreds of third
party libraries for inclusion in the generated policies. On the
other hand, the App Privacy Policy Generator and TermsFeed
et al. only offer a handful of libraries. As all generators
have an option to manually add libraries not
included in
their menus, though, it is generally possible to discloses any
library. However, another difference between the generators
is their pricing structure. The App Privacy Policy Generator
is completely free. Termly and iubenda are offering a basic
version of their generator for free and a more extensive paid
version for a ﬂat subscription fee. But TermsFeed et al. is
7
Fig. 4: Excerpt from PrivacyFlash Pro’s iOS API evidence speciﬁcation for the location framework. The full speciﬁcation, about 3,000 lines
of code, including comments, is available at our project’s GitHub repository (https://github.com/privacy-tech-lab/privacyﬂash-pro/).
A. PrivacyFlash Pro Architecture
Current questionnaire-based generators have design weak-
nesses (§ III). They also necessarily rely on developers’ ability
to answer questions on the privacy practices of their apps
accurately, comprehensively, and over time upon any privacy-
relevant code change. We suggest automating privacy policy
generation by using, as far as possible, ﬁrst, standardized tem-
plates (§ IV-A1), second, automatic code analysis (§ IV-A2),
and third, a questionnaire-based wizard (§ IV-A3).
1) Standardized Templates: Different apps will often be
subject
to the same disclosure requirements. For example,
any app subject to the GDPR must disclose that users can
request access to the data a controller has stored on them
[GDPR, Art. 13(2)(b), 14(2)(c)].7 These types of disclosures
are included via templates in any policy that needs to com-
ply with the GDPR. PrivacyFlash Pro contains templates for
provisions of the GDPR, CCPA, CalOPPA, and COPPA. Such
standardization eases policy comparison and comprehensibility
by use of familiar terminology and placement of information
resources [23]. Using standardized templates also has the
advantage of enabling machine-readability of policies allowing
browsers and other user agents to consume policy data and
take actions on a user’s behalf [23].8 Making natural language
policies machine-readable seems more promising at this point
than developing dedicated machine-readable policy formats
due to the wide adoption of the former. The more standardized
language a policy contains, the easier it will become to make
it machine-readable.
2) Code Analysis: Using Python for the code analysis logic
and JavaScript for the UI, PrivacyFlash Pro runs as a macOS
desktop app locally in the web browser and generates policies
for iOS apps written in Swift and their libraries in Swift and
Objective-C. The signature-based static analysis approach is
language-agnostic as long as the analyzed code is sufﬁciently
expressive to reveal
its privacy-sensitive
behavior when executed.
information about
7PrivacyFlash Pro generates policies for GDPR “controllers” and CCPA
“businesses” as opposed to “processors” and “service providers.”
8The GDPR reintroduced this idea by providing for policy disclosures in
combination with machine-readable icons [GDPR, Art. 12(7)].
a) From Evidence to Signatures to Policies: The de-
tection of a privacy practice by PrivacyFlash Pro depends
on the evidence found in the analyzed codebase. To that
end, PrivacyFlash Pro contains a speciﬁcation layer, distinct
from the analysis logic, that deﬁnes the evidence that will be
searched for. The speciﬁcation contains hundreds of evidence
items from the iOS Swift and Objective-C APIs [8]. Figure 4
shows an excerpt. As Swift and Objective-C continue to
evolve, the speciﬁcation can be updated without restructuring
the analysis logic. The following are the different types of
evidence items and their uses in the analysis:
(1) Plist Permission
include
in
their
iOS 10.0
Info.plist
Strings. Since
apps
must
a
UsageDescription key explaining why access
to a certain permission is requested. This explanation
is used in the generated policy to describe the purpose
for why personal data is processed [e.g., GDPR, Art.
13(1)(c), 14(1)(c)].
ﬁle
(2) Framework Imports: All functionality we are interested
in is bundled in frameworks. For example, an app must
import the CoreLocation or MapKit frameworks to
obtain the location of a device.
(3) Class Instantiations. At least one class from the frame-
work must be instantiated. Otherwise, the framework’s
functionality could not be used.
(4) Authorization Methods. There must be instance method
declarations for authorization methods (for example,
requestAlwaysAuthorization to request the de-
vice location whenever
the app is running). Some-
times they are also called access methods (for exam-
ple, requestAccess to request access to the device’s
microphone). Parameters disambiguate methods with the
same name (for example, both microphone and camera
have a requestAccess method but microphone has an
audio parameter and camera has a video parameter).
(5) Entitlements. Using particularly sensitive resources that
are expanding beyond the sandbox of an app requires an
entitlement, for example, use of HealthKit. Those are
8
Fig. 5: Detection of a location signature in an app’s source ﬁles causing the privacy policy to be populated with the location practice.
controlled by Apple through the app signing process and
must be declared in the Entitlements.plist ﬁle.
(6) Additional Evidence. Instance methods (for example,
startUpdatingLocation) and instance properties
(for example, AVCaptureDeviceInput) require an
authorization method to be used. Just as for authorization
methods, parameters are used to disambiguate instance
methods with the same name.
Once the evidence is completed to a signature, it is inferred
that a privacy practice is performed that should be disclosed
in a privacy policy. The signatures for ﬁrst parties (i.e., apps)
and third parties (i.e., libraries) are composed of the same
evidence items. For a signature of a ﬁrst party practice, the
ﬁrst party (i.e., app) code must contain (1) a Plist permission
string, (2) a framework import, (3) a class instantiation, (4)
an authorization method, and (5) an entitlement, to the extent
required for the practice, where (6) additional evidence can
be used in place of an authorization method if and only if an
authorization method is present in the third party (i.e., library)
code. For a signature of a third party practice, the ﬁrst party