title:Network Growth and Link Prediction Through an Empirical Lens
author:Qingyun Liu and
Shiliang Tang and
Xinyi Zhang and
Xiaohan Zhao and
Ben Y. Zhao and
Haitao Zheng
Network Growth and Link Prediction
Through an Empirical Lens
Qingyun Liu, Shiliang Tang, Xinyi Zhang, Xiaohan Zhao, Ben Y. Zhao and Haitao Zheng
{qingyun_liu, shiliang_tang, xyzhang, xiaohanzhao, ravenben, htzheng}@cs.ucsb.edu
Computer Science, UC Santa Barbara
ABSTRACT
Link prediction in dynamic networks is a well studied topic.
Yet until recently, validation of algorithms has been ham-
pered by limitations in the size and realism of empirical
datasets. In this work, we seek to revisit and reassess the
value and accuracy of prediction methods, by leveraging our
access to several large, detailed traces of dynamics in online
social networks (Facebook, Renren, YouTube). Our goals
are to understand the absolute and comparative accuracy of
existing prediction algorithms, and to develop techniques to
improve them using insights from analysis of network dy-
namics.
We implement and evaluate 18 link prediction algorithms,
labeled as either “metric-based” (those that predict poten-
tial links using a single similarity or proximity metric) or
“classiﬁcation-based” (those that use machine learning clas-
siﬁers with multiple metrics as input features). Despite poor
performance in absolute terms, SVM classiﬁers consistently
perform the best across all our traces.
Its accuracy is oc-
casionally matched by metric-based algorithms, but never
consistently across datasets. Finally, we use observations of
network dynamics to build “ﬁlters” that dramatically reduce
the search space for link candidates. Augmenting current
algorithms with our ﬁlters dramatically improves prediction
accuracy across all traces and algorithms.
1.
INTRODUCTION
Link prediction is the problem of predicting formation of
new edges on a given network. It is a fundamental problem
that applies to networking in numerous contexts, including
the Internet, the web, and online social networks. The sheer
number of studies, including proposals for algorithms and
models [2, 3, 9, 13, 14, 20, 23, 24, 26, 32, 33, 35, 39, 42],
underscores the importance of the problem to a variety of
Permission to make digital or hard copies of all or part of this work for personal
or classroom use is granted without fee provided that copies are not made or
distributed for proﬁt or commercial advantage and that copies bear this notice
and the full citation on the ﬁrst page. Copyrights for components of this work
owned by others than ACM must be honored. Abstracting with credit is per-
mitted. To copy otherwise, or republish, to post on servers or to redistribute to
lists, requires prior speciﬁc permission and/or a fee. Request permissions from
permissions@acm.org.
IMC 2016, November 14-16, 2016, Santa Monica, CA, USA
c(cid:13) 2016 ACM. ISBN 978-1-4503-4526-2/16/11. . . $15.00
DOI: http://dx.doi.org/10.1145/2987443.2987452
applications, ranging from resource allocation in online ser-
vices to ofﬂine efforts in counter-intelligence and counter-
terrorism [19, 21].
As a technical problem, the efﬁcacy of link prediction is
generally not well understood. Today, link prediction algo-
rithms are the basis for social recommendations in a wide
range of social networks and applications, ranging from Face-
book and Pinterest to personal streaming on Periscope and
Q&A sites like Quora. The success of these sites and the
sheer volume of prior literature lead many to believe the
problem is well addressed. Only evidence to the contrary
comes from anecdotes of failed recommendations that trig-
ger potential privacy concerns [16].
Despite years of research in this space and hundreds of
publications (only a small subset of which is cited here),
there has been little opportunity to study these proposals
from an empirical perspective. Until recently, public datasets
of network dynamics have been limited to co-authorship stud-
ies and patent citation graphs, moderate sized networks which
scale up to 20K nodes and 200K edges [4, 36]. In contrast,
algorithms developed using and validated by these datasets
are targeting dynamic networks that are two or more orders
of magnitude larger, with millions or billions of nodes and
billions of edges [44].
Thankfully, things are changing with the arrival of net-
work traces from online social networks (OSNs). We are
taking advantage of this opportunity (and availability to large
traces of network dynamics) to step back and reassess the
space of link prediction algorithms from an empirical per-
spective. We are motivated by questions such as:
• How far have we come in understanding network growth
and predicting the underlying processes that drive it? How
far do we have to go?
• What lessons can we draw from the successes (and fail-
ures) of existing algorithms?
• Can we improve existing approaches by leveraging more
data, e.g. detailed temporal network history?
In this work, we perform an empirical study using large
traces of network growth from three large OSNs, Facebook,
Renren (Facebook equivalent in China), and YouTube. In
each case, detailed timestamps capture the time when spe-
ciﬁc edges were created between nodes (users) in the net-
work. To the best of our knowledge, these are the only
publicly available datasets suitable for this study, both suf-
ﬁciently large and with sufﬁciently detailed timestamps to
capture graph dynamics. These traces cover substantial sub-
sets of users in each network, and in the case of Renren, the
entire user population at a time when the network included
10 million users. We discretize these traces into numerous
temporal snapshots, and use them to drive the evaluation of
18 representative link prediction algorithms. Finally, we use
our lessons and observations from analyzing these network
dynamics to build “ﬁlters” that help prune the set of candi-
date nodes for edge creation. By applying these ﬁlters before
link prediction, we can reduce the search space and focus on
regions of likely growth.
To better understand and compare results across predic-
tion algorithms, we classify them into two groups. First,
Metric-based prediction algorithms deﬁne speciﬁc metrics
that can be computed for all potential links, where a poten-
tial link with a higher score on the metric indicates a higher
probability of formation. For our analysis, we implemented
14 distinct metrics that had scalable algorithms in existing
literature. In contrast, classiﬁcation-based prediction algo-
rithms utilize machine learning classiﬁers that take multiple
metrics as input features, and produce a prediction of like-
lihood of formation for each potential link. Some methods
produce a detailed probability while others produce a binary
result. Experiments in our study cover support vector ma-
chines (SVM), logistic regression, naive Bayesian networks,
and random forests, each using all 14 metrics as input fea-
tures. Our experiments show that more complex techniques,
e.g. larger ensemble methods do not produce noticeable im-
provements in accuracy.
As our ﬁrst result, we ﬁnd that link prediction perfor-
mance remains poor in absolute terms. Correctly predict-
ing link formation within some timeframe is difﬁcult, and
the problem only grows harder, as each new node brings
∼N more potential links to a network of size N . Second,
we ﬁnd that for each of our traces, metric-based prediction
In each case, a
algorithms vary signiﬁcantly in accuracy.
small subset of metric-based predictors do as well as (and
occasionally outperform) the most accurate machine learn-
ing based classiﬁer (SVM in all cases). We note that while
a few metrics perform consistently well, no single metric
predictor consistently performs as well as SVM across all
networks. Instead, there appears to be a strong correlation
between network structure and the relative success of spe-
ciﬁc metric-based algorithms. Machine learning methods do
well in part because they automatically adjust weights across
different metrics, emphasizing those that match the targeted
network without a priori knowledge of its structure. Without
such knowledge, we can either achieve “good” accuracy by
choosing a consistently strong metric, or achieve “near opti-
mal” accuracy by using a ML classiﬁer (at the cost of higher
computational and training costs).
Finally, we revisit existing prediction algorithms with the
goal of augmenting them by leveraging knowledge of past
network dynamics. Our insight is to provide “temporal ﬁl-
ters” that signiﬁcantly reduce the set of potential new links,
reducing the search space and computational cost, while fo-
cusing predictors on more probable link candidates. Our ﬁl-
ters are focused around trends in node activity and poten-
tial link distances, both patterns observed in this and prior
studies of network dynamics. Applying these ﬁlters produce
very encouraging results, in many cases effectively doubling
the predictive power of both metric-based and classiﬁer-based
algorithms. Not only do these ﬁlters outperform recent meth-
ods leveraging temporal information, but they can be com-
bined with temporal methods to provide even better results.
Our key contributions can be summarized as follows:
• We carry out a comprehensive analysis of a wide range
of link prediction algorithms, studying not only their per-
formance but also possible causes of low prediction accu-
racy. We apply decision tree classiﬁers to identify the best
metric-based algorithms for different networks.
• We compare the two categories of link prediction methods,
i.e. metric-based and classiﬁcation methods, study their
cost versus accuracy tradeoffs, and identify strategies for
choosing between them.
• We leverage insights from analysis of network growth to
design ﬁlters that improve prediction accuracy by dramat-
ically reducing the search space. In our tests, these ﬁlters
signiﬁcantly improve prediction power across all methods.
Further, they outperform recent proposals that integrate
temporal information, and can be combined with them to
produce even better results.
2. BACKGROUND: LINK PREDICTION
Link prediction identiﬁes new edges that will likely form
in the near future, by analyzing the structure of the current
network [23]. Given a graph Gt = observed at
time t, it seeks to predict new edges to be created between
nodes Vt at time t′ (t′ > t).1 Note that we focus on pre-
dicting future links at some time t, which is different from
the detection of missing links, where given a partially ob-
served graph, it identiﬁes link status for unobserved pair of
nodes [17, 29].
Existing link prediction algorithms naturally fall into two
categories, which we refer to as metric- and classiﬁcation-
based. We list and classify all of the known popular predic-
tion algorithms in Table 1, which are algorithms we focus
on in this work, and their details will be introduced later in
Table 3. Metric-based algorithms estimate the likelihood of
future connectivity between unconnected nodes, by gener-
ating a numeric score based on some graph-based heuris-
tic [23] or models [9, 35]. All potential node pairs are sorted
by score to determine the most likely future edges. In con-
trast, classiﬁcation-based algorithms treat link prediction as
a classiﬁcation problem [3]. Using scores by metric-based
algorithms and maybe other information as training features,
these classiﬁers then “separates” the node pairs that will likely
connect in the near future from those that will not. Some
classiﬁers also produce a granular similarity score, which
can be used to rank node pairs.
1This is the most common form of link prediction. It does
not consider edges created by new nodes who join after t,
nor edges that might disappear after their creation.
Heuristics
e.g., CN, JC, AA, RA,
LP, SP, PA, Katz,
Probabilistic
Models
Based
Metric-Based Prediction
Classiﬁcation-Based Prediction
Learning Models
e.g., SVM,
Matrix/Tensor
Logistic Regression,
LRW, PPR
e.g., BCN, BAA, BRA
e.g., Rescal
Naive Bayes,
Random Forest
Table 1: Summary of link prediction algorithms, with details listed in Table 3.
Graph
Facebook (New Orleans) [41]
YouTube (Snowball Crawl) [30]
Renren (Non-sampled) [44]
Date
09/05/06
02/09/07
01/01/07
Trace Start
Nodes
48,969
1,406,188
1,413,731
Edges
339,098
3,466,440
13,616,792
Date
01/21/09
07/23/07
12/31/07
Trace End
Nodes
63,731
3,223,589
10,572,832
Edges
817,090
9,376,594
199,564,006
Time
Snapshot
Granularity Delta (k)
# of
Snapshots
Seconds
Days
Seconds
15K
250K
10M
31
21
17
Table 2: Statistics of the three OSN datasets.
Next, we describe these two categories of algorithms in
detail and highlight their differences.
Metric-based link prediction
Metric-based Prediction.
algorithms quantify and rank node pairs by their likelihood
of forming new edges, based on speciﬁc metrics that cap-
ture similarity or proximity between nodes [23]. For sim-
plicity, we refer to the entire group as “similarity metrics,”
and further divide them into heuristics, or more complicated
learning models, as shown in Table 1.
Many popular metric-based algorithms are heuristics based
on common intuitions of graph formation [23], e.g., two cur-
rently unlinked nodes with the most commonly connected
nodes are most likely to link in the future. Those hypotheses
are driven by graph structural properties and do not require
metadata. They generally focus either on node neighborhood
information, where they capture properties of the common
neighborhood between nodes of 2-hop distance, e.g. Com-
mon Neighbors [32] and Adamic Adar Index [2], or on path
properties such as shortest path length [20].
Link prediction can also be performed by inferring the
likelihood of two nodes forming an edge based on learn-
ing models. One way is to use probabilistic models cali-
brated by measurements on Gt. For example, [9, 13] assume
a speciﬁc underlying structure of hierarchies or communi-
ties exists in the graph Gt, and model parameters are esti-
mated using maximum likelihood. Another approach is to
extend the ﬁeld of relational learning to link prediction [39,
42]. However, these underlying models either do not scale
to large graphs (due to complexity in parameter learning)
or rely on special conditions that do not generalize to com-
mon networks such as social networks [42]). Only the local
naive Bayes model [26] meets the needs of large, general-
ized graphs. Other metrics use matrix (tensor) techniques on
matrix representations of graphs. They capture node simi-
larity in a latent space, deﬁned by different models [33, 35].
Among them, only Rescal [33] has been shown empirically
to scale to large graphs of millions of nodes.
While metric-based
Classiﬁcation-based Prediction.
algorithms are known for their simplicity [23], performance
can vary signiﬁcantly depending on the speciﬁc similarity
metric used. Existing work has shown the best metric varies
across datasets and there is no uniﬁed solution [23, 24].
The alternative is what we call classiﬁcation-based meth-
ods.
Instead of using a certain similarity metric, one can
build automated classiﬁers to explore multiple similarity fea-
tures [24]. Compared to single metrics, classiﬁers face the
challenge of high computational complexity, (e.g.
feature
selection and training), especially for massive OSNs [14].
3. DATASETS AND METHODOLOGY
We now describe the datasets used for our study and our
experimental methodology.
3.1 Datasets
Our study uses large traces of dynamic network growth
from three different networks, Renren, Facebook, and YouTube.
As far as we know, these are the only publicly available
large-scale datasets suitable for this study, which have sufﬁ-
ciently detailed timestamps to capture graph dynamics, i.e.,
the time when each edge (link) was created between nodes
(users).
The Renren [44] data includes creation of every edge in
the entire Renren network during a period of over 2 years
(from its ﬁrst edge, to 10 million users, 199 million edges
when the trace ends). The Facebook trace [41] includes
edges created in the New Orleans regional network over 2+
years. The YouTube trace [30] includes edges recorded from
daily snowball crawls of a user community that grew from
1 million to 3 million users over a period of 5 months. To
avoid disruptions from external events, i.e., the network pol-
icy changes in Youtube, and a one-time network merge event
for Renren (Renren merged with its largest competitor in
December 2006), we use continuous subtraces that do not
include the external events in question. Statistics on all three
traces are summarized in Table 2.
We show each network’s daily growth in nodes and edges
in Figure 1. While the three networks all continue on expo-
nential growth trajectories (Facebook has a number of 49K
users at the beginning while the other two has 1.4M users),
we see Renren is on a much faster growing pace. This is be-
cause both the Facebook and YouTube datasets are sampled
networks, i.e., Facebook dataset is a regional network and
YouTube dataset depicts the growth of a user community.
Figures 2-4 provide a quick look at the change in basic net-
Facebook
edges
nodes
t
n
u
o
C
 10000
 1000
 100
 10
 1
 100000
t
n
u
o
C
 10000
 1000
Renren
edges
nodes
YouTube
edges
nodes
t
n
u
o
C
10000000
1000000
100000
10000
1000
 0  100 200 300 400 500 600 700 800 900
 0
 20  40  60  80  100  120  140
 0
 100
Day
Day
 300
 400
 200
Day
Figure 1: Daily new nodes and edges in the three networks.
e
e
r
g
e
D
e
d
o
N
e
g
a
r