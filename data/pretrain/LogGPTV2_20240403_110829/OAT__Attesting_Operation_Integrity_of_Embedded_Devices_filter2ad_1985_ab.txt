feature available on both Cortex-A processors (for mobile and
high-end IoT devices) and Cortex-M processors (for low-cost
embedded systems). TrustZone renders a so-called “Secure
World”, an isolated environment with tagged caches, banked
registers, and private memory for securely executing a stack of
trusted software, including a tiny OS and trusted applications
(TA). In parallel runs the so-called “Normal World”, which
contains the regular/untrusted software stack. Code in the
Normal World, called client applications (CA), can invoke TAs
in the Secure World. A typical use of TrustZone involves a
CA requesting a sensitive service from a corresponding TA,
such as signing or securely storing a piece of data. In addition
to executing critical code, TrustZone can also be used for
mediating peripheral access from the Normal World.
3
OAT measurement engine runs as a TA in the Secure World.
Its code and data,
including collected measurements, are
naturally protected. TrustZone allows provisions of per-device
private keys and certiﬁcates, which enable straightforward
authentication and signed/encrypted communication between
a measurement engine (i.e., prover) and a remote veriﬁer.
During an active attestation phase, the instrumented code in the
Normal World reports raw measurements to the Secure World,
where the raw measurements are processed and signed. The
ﬁnal report (aka. measurement blob) along with the signature
is handed back to the Normal World agent, which sends
the report
to the remote veriﬁer. On our target platforms
(i.e., ARM-based bare-metal embedded devices), TrustZone
is the only feasible TCB option that can support basic remote
attestation operations. Our evaluation (§VIII) shows that the
end-to-end overhead of our system is acceptable, thanks to our
efﬁcient attestation scheme.
III. DESIGN OVERVIEW
A. Example: A Vulnerable Robotic Arm
Before we discuss OEI and the attestation, we ﬁrst present
a simple example to demonstrate the problem. The vulnerabil-
ities shown in this example were drawn from real embedded
programs. This example is also referenced in a later discussion
on how OEI attestation can be easily applied to existing code.
In this example of a vulnerable robotic arm (Listing 1), the
function main_looper ﬁrst retrieves an operation command
from a remote controller and stores it in cmd (Line 11).
The looper then reads a peripheral sensor (Line 12), which
indicates if the arm is ready to perform a new operation.
If ready, the looper ﬁnds the operation function speciﬁed by
cmd->op (Line 15) and calls the function with the parameters
supplied in cmd->param (Line 16). One such function (Line
25) moves the arm to a given position.
We introduce an attacker whose goal is to manipulate the
operation of the robotic arm without being detected by the
remote controller who uses the existing attestation methods.
For simplicity, we assume the attacker has tampered with
the sensor and uses it to feed exploit input to the robotic
arm. This is realistic given that such external peripherals are
difﬁcult to authenticate and protect. The target of the attacker
is Function get_input (Line 12), which contains a buffer
overrun. The vulnerability allows malformatted input to be
copied beyond the destination buffer (peripheral_input)
into the subsequent stack variables (e.g., cmd).
By crafting input via the compromised sensor, the attacker
can launch either control hijacking or data-only attacks on the
robotic arm. To hijack the control, the attacker overwrites both
cmd->param and cmd->op as a result of the buffer overrun
exploit, which leads to the execution of an arbitrary operation.
To mount a data-only attack, the attacker only needs to change
cmd->param while leaving cmd->op intact, which turns the
authorized operation harmful.
Though seemingly simple, such control and data manip-
ulations on embedded devices are realistic and can cause
severe consequences in the physical world. More importantly,
// Command from remote controller
cmd_t cmd;
// Pointer to operation function
int (*op_func)(int, char*);
// Input from peripheral sensor
char peripheral_input[128];
int st = 0;
while(1) {
1 // Simplified control loop for robotic arms
2 void main_looper() {
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22 }
23 ...
24 // The operation that moves the robotic arm
25 int op_move_arm (int, char*) {...}
26 ...
// perform the operation
op_func = get_op_func(cmd->op);
(*op_func)(cmd->p_size, cmd->param);
}
usleep(LOOPER_SLEEP_TIMER);
if (read_command(&cmd)) {
st = get_input(peripheral_input); //BUGGY!
if (status_OK(st)) {
}
}
return;
Listing 1: An example of a control loop in a robotic arm
existing remote attestation methods cannot detect such attacks
because most of them are focused on static code integrity and
none addresses dynamic data integrity. Therefore, the remote
controller is unable to ﬁnd that the robotic arm is compromised
and did not perform the operation as commanded. Moreover,
after receiving an (unveriﬁable) operation-success message
from the compromised robotic arm, the controller may com-
mand other robotic arms to perform follow-up operations,
which can cause further damage. This example illustrates the
need for a new form of attestation that allows IoT backends to
remotely check the integrity of operations performed by IoT
devices.
B. Operation Execution Integrity (OEI)
We propose “Operation Execution Integrity” (or OEI) as a
security property for embedded devices. By verifying OEI,
a remote veriﬁer can quickly check if an execution of an
operation suffered from control-ﬂow hijack or experienced
critical data corruption. We formulate OEI with two goals
in mind: (i) enabling remote detection of aforementioned
attacks; (ii) demonstrating the feasibility of an operation-
oriented attestation that can detect to both control and critical
data manipulations on embedded devices. Next, we formally
deﬁne OEI and provide its rationale.
To avoid ambiguity, we informally deﬁne an operation to
be a logically independent task performed by an embedded
device. To declare an operation for attestation, programmers
need to identify the entry and exit points of the operation in
their code. For simplicity of discussion, we assume that every
operation is implemented in a way that it has a single pair of
entry and exit, (cid:104)Opentry, Opexit(cid:105) where Opentry dominates
Opexit and Opexit post-dominates Opentry in the control ﬂow
4
graph. We do not pose any restriction on what code can an
operation include or invoke, except that an operation cannot
contain another operation.
Let P = {Op1, Op2, ...Opn} be an embedded program,
composed of n operations, denoted as Opi. CF G(Opi) is the
statically constructed CFG (control ﬂow graph) for Opi (i.e.,
the CFG’s root is Opi’s entry point). Let CV be the set of
critical variables in P (i.e., variables affecting the execution
of the operations). D(v) and U (v) are the def- and use-sites
of a critical variable v: a set of statements where v is deﬁned
or used. Vb(v, s) and Va(v, s) are the values of variable v
immediately before and after statement s executes.
Deﬁnition 1. OEI: for an operation Opi, its execution satisﬁes
OEI ⇐⇒ 1(cid:13) the control ﬂow complies with CF G(Opi)
2(cid:13) during the
and maintains backward-edge integrity, and
execution, ∀cv ∈ CV , the value of cv reaching each use-site
is the same as the value of cv leaving the previous def-site,
written as Vb(cv, u) = Va(cv, d), where d ∈ D(cv) is the last
deﬁne of cv prior to the use of cv at u ∈ U (cv).
(cid:52)
OEI entails that the control-ﬂows and critical data involved
in an operation must not be tampered with.
Operation-scoped CFI (§IV): OEI’s control-ﬂow requirement
( 1(cid:13) in Def. 1) is not a simple adoption of CFI to embedded
devices, which would incur impractical time and space over-
head on those constrained devices. Our operation-scoped CFI
takes advantage of the operation-oriented design of embedded
programs. It applies to executions of individual operations,
which represent a much smaller attestation scope than a whole
program and allow for on-demand attestation. It also implies
backward-edge integrity (i.e., returns not hijacked).
Critical Variable Integrity (§V): We call the second require-
ment of OEI ( 2(cid:13) in Def. 1) Critical Variable Integrity, or
CVI. It dictates that the values of critical variables must obey
deﬁne-use consistency. Compared with other data integrity
checkers [13], [3], [11] CVI is different in two ways. First, CVI
only concerns critical variables, rather than all program data.
Second, CVI uses value-based checking, instead of address-
based checking, to signiﬁcantly reduce code instrumentation
and runtime overhead. CVI applies to the entire program
execution and is not scoped by attested operations. We provide
a method to assist developers to automatically identify critical
variables. We deﬁne critical variables and explain our value-
based check in §V.
Secure & Optimized Combination: OEI combines CVI
and operation-scoped CFI. These two sub-properties mutually
complementary. Without CVI, CFI alone cannot detect data-
only attacks or control-ﬂow hijacks that do not violate CFG
(e.g., [10]). Without CFI, CVI can be bypassed (e.g., by
ROP). On the other hand,
this combination yields better
performance than independently performing control-ﬂow and
data-ﬂow checks. This optimized combination allows for the
detection of both control-ﬂow and data-only attacks without
enforcing full CFI and DFI. It is suited for embedded devices.
based on a statically constructed access table. Even when
the integrity checking is only applied to selected variables,
address-based checkers would still need to instrument and
check all memory-accessing instructions to ensure no unin-
tended instructions can write to the addresses of the critical
variables.
Our hybrid attestation scheme achieves complete veriﬁabil-
ity while maintaining acceptable performance on embedded
devices. For CFI attestation, OAT’s measurements contain
compact control-ﬂow transfer traces for forward-edges and
ﬁxed-length hashes for backward-edges. This combination
allows remote veriﬁers to quickly and deterministically re-
construct control ﬂows. It also yields size-optimized measure-
ments. For CVI, OAT performs local veriﬁcation rather than
remote attestation. By doing so, OAT avoids sending a large
amount of data (e.g., critical values at def- and use-sites) to
remote veriﬁers. Sending such data would be costly for IoT
devices and undesirable when privacy is concerned.
To use OEI attestation, programmers declare the to-
be-attested operations
in their code by using two in-
tuitive compiler directives: #oei_attest_begin and
#oei_attest_end. They may also annotate critical vari-
ables of their choice via a GCC-style attribute. For example, to
enable OEI attestation in Listing 1, a programmer only needs
to change Line 4, 8, and 25:
4 cmd_t __attribute__((annotate("critical"))) cmd;
8 int __attribute__((annotate("critical")))
peripheral_input = 0;
25 int op_move_arm (int, char*) {#oei_attest_begin
... #oei_attest_end}
For simplicity, our current design requires that a pair of
#oei_attest_begin and #oei_attest_end is used in
the same function (i.e., an operation enters and exits in the
same call stack frame) and the #oei_attest_end always
dominates the #oei_attest_begin (i.e., an operation al-
ways exits). Operations cannot be nested. These requirements
are checked by our compiler. Developers are advised to keep
the scope of an operation minimal and the logic self-contained,
which is not difﬁcult because most embedded programs are
already written in an operation-oriented fashion.
As shown in Figure 1, during compilation, the customized
compiler instruments a set of control ﬂow transfers inside each
to-be-attested operation. The compiler automatically annotates
control-dependent variables as critical (e.g., condition vari-
ables). It also performs a global data dependency analysis on
both automatically and manually annotated critical variables
so that their dependencies are also treated as critical and
subject to CVI checks. At runtime, the instrumented control
ﬂow transfers and critical variable deﬁne/use events trigger the
corresponding trampolines, which pass the information needed
for CFI or CVI veriﬁcation to the measurement engine in
the Secure World protected by TrustZone. Finally, the signed
Fig. 1: The Workﬂow of OAT, whose components (colored in yellow)
include the compiler, the trampoline library, the measurement engine
in the Secure World (shown in green), and the remote veriﬁcation
engine.
Operation Veriﬁability: OEI caters to IoT’s unique security
needs. One deﬁning characteristic of IoT devices is their
frequent inter-operations with peers or cloud services. When a
device ﬁnishes an operation, the operation initiator may wish
to verify if the operation was executed as expected without
interference. For example, a remote controller needs to verify
if a robotic arm has performed a movement as instructed
without experiencing any control or data manipulations. OEI
attestation answers to such security needs of IoT, which are
currently not addressed.
C. OAT Overview
We build OAT, a system to realize OEI ATtestation on
ARM-based bare-metal embedded devices (i.e., no standalone
OS in the Normal World). OAT consists of: (i) a customized
compiler built on LLVM; (ii) a trampoline library linked
to attestation-enabled programs; (iii) a runtime measurement
engine; (iv) a remote/ofﬂine veriﬁcation engine (Figure 1).
For a given embedded program, the compiler identiﬁes the
critical variables and instruments the code for measurement
collection. At runtime,
the measurement engine processes
the instrumented control-ﬂow and data events and produces
a proof or measurement, which the remote veriﬁer checks
and determines if the operation execution meets OEI. OAT
relies on ARM TrustZone to provide the trusted execution
environment for the measurement engine.
We design a hybrid attestation scheme that overcomes two
challenges associated with CFI and data integrity veriﬁca-
tions. First, remotely attesting CFI is more challenging than