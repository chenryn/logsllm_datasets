value appears in at least one record (no density assumption).
The ApproxValue algorithm in Section III further as-
sumes that queries are drawn i.i.d. and uniformly at random.
The attack and its analysis can be generalized to other query
distributions. As explained earlier, we then introduce the
ApproxOrder algorithm in Section IV precisely to do
away with assumptions on the query distribution. Likewise
all algorithms in Section V function without that assumption.
When it comes to analyzing the query complexity of those
algorithms, we are forced to make a hypothesis on the query
distribution. In that case, we choose an assumption about the
query distribution that helps provide insight into a typical
behavior of the algorithm. We stress that that hypothesis is
in no way required for the algorithm to function and succeed.
C. Related Work
Dautrich Jr. and Ravishankar [24] introduced the use of
PQ-trees in revealing the order of records in a database
with access pattern leakage. They experimentally measured,
in some special cases, how quickly the number of orders
contained in the tree decreases as more queries are gathered.
We use also use PQ-trees for revealing order from range
queries, but otherwise our aims are distinct from theirs—their
paper focuses primarily on heuristic measures of security after
some ordering information is revealed.
Kellaris et al. (KKNO) [3] described the ﬁrst exact recon-
struction attack on range queries with access pattern leakage;
Lacharit´e et al. (LMP) [2] improved the results of KKNO in
the dense setting, obtaining an O(N log N ) exact reconstruc-
tion attack; see Section I-A for more detail. Kornorapoulous et
al. [25] gave an approximate reconstruction attack for access
We conduct experiments with real datasets of US ZIP codes
and public sector salaries in Section IV-D. The resulting
sacriﬁcial -ADR attack is effective: with only 50 queries, we
can learn the ﬁrst two digits of a ZIP code (often identifying
a city) for a majority of records in the target database. With
100 queries on salaries, we can predict a majority of salaries
to within 10000 USD. The table in Figure 1 compares our
different attacks on range queries.
Beyond range queries. As illustration of the power of
the viewpoint we have taken, in Section V, we generalize
approximate reconstruction to other query classes and ana-
lyze the resulting attacks using tools from learning theory.
Using generalization error as a metric γ on the values in
the database, we show that all query classes with ﬁnite VC
dimension reveal the distance (in γ) between the underlying
1069
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:47:08 UTC from IEEE Xplore.  Restrictions apply. 
pattern leakage from k-nearest-neighbor queries. Other papers
attacking encrypted databases include [5], [4], [26], [7], [27];
these mostly analyze so-called “property-revealing encryption”
schemes, which leak strictly more than what we assume.
II. PAC LEARNING AND DATABASE RECONSTRUCTION
ATTACKS
In this section, we explore the connection between learn-
ing theory and database reconstruction attacks. Concretely,
we demonstrate a connection between approximate database
reconstruction and “Probably Approximately Correct” (PAC)
learning [8] in the setting where the attacker has access pattern
leakage from some known queries. For a brief introduction to
PAC learning, see Appendix A-D.
Reconstruction via PAC learning. The attack setting we
consider here is one in which an attacker has observed the
access pattern leakage from a number of known queries drawn
i.i.d. from a ﬁxed query distribution (which the adversary
does not need to know). The assumption of known queries
is somewhat stronger than has been considered previously in
this literature; however, some recent works have argued that
it is realistic [5], [7] on the grounds that the adversary is able
to make some queries or has compromised an honest user.
A crucial question is the relationship between the number
of known queries and the amount of information the adversary
can learn about the database itself, cf. Section I. We will see
that this question is essentially resolved via a simple reduction
to PAC learning in the known query setting.
We can think of a database DB with R records having
values in [N ] as being a vector of length R with values in [N ];
the value of record j is DB[j]. We construct a concept space
C = (Q, C) where the points in the ground set are the possible
queries and C = ∪i∈[N ]Ci for Ci = {q ∈ Q| q(i) = 1}. Here,
q(i) = 1 means that value i matches query q. With this set-up,
we have the following result.
Theorem II.1. Let Q be a class of queries taking inputs in
a set X and C = (Q, C) be the concept space constructed
as above. Let πq be any distribution over Q. Let d be the
VC dimension of C, and assume d is ﬁnite. Then, there is an
adversary such that for any database DB, given as input m ∈
O( d
δ ) queries sampled from πq and their access pattern
leakage on DB, the adversary outputs a database DB(cid:48) such
that Prπq
for all j ∈ [R], with probability at least 1 − Rδ.
(cid:2) q(DB[j]) (cid:54)= q(DB(cid:48)[j])(cid:3) ≤  holds simultaneously
(cid:2) q(DB[j]) (cid:54)= q(DB(cid:48)[j])(cid:3) as the
This theorem requires some explanation. We chose to use
 log d
the generalization error Prπq
accuracy measure in our result. This is intended to surface the
core points without adding unnecessary detail, but it may also
make the result hard to interpret. Section V studies in more
detail how generalization error relates to traditional notions of
attack accuracy.
The proof proceeds via a natural reduction to PAC learning.
The adversary gets as input m known queries along with
their access pattern leakage (i.e. which records match the
query) for each of the R records in the database. The core
observation is that the access pattern is a binary classiﬁcation
of each database element; further, each database element is
a concept in C. This means that the task of reconstructing
each database element can be seen as R independent PAC
learning experiments for the concept space C deﬁned above.
The adversary simply runs the PAC learner R times, invoking
it once for each record j. For each invocation, the adversary
gives the learner as input the m queries and their access
patterns (i.e. the 0/1 labellings) for record j. Each time the
learner is run, it outputs a hypothesis Hind ∈ C corresponding
to an element of X. The adversary’s complete output is then of
the form [H1, H2, . . . , HR], which we denote by DB(cid:48). Each
independent invocation of the learner outputs a hypothesis Hj
with Prπq [ q(Hj) (cid:54)= q(DB[j]) ] >  with probability at most
δ, and a union bound over the R elements completes the proof.
Note here that, while the linear dependence on R in the
probability bound may look discouraging, the sample com-
plexity of PAC learning is only logarithmic in δ, so the loss in
tightness from the union bound over R events is small. Note
also that the union bound over all R database elements can be
avoided entirely with a more careful analysis—for example,
observe that any learner will output the same hypothesis on
any two database records with the exact same access pattern on
all m queries, so the adversary need only run the learner once
per group of records having the same access pattern leakage.
The dependency on R can also be removed at the cost of
replacing the concept set C by C∆ (as deﬁned in section V).
Since tightness is not the goal of this result, we favor simplicity
in presentation. In the full version, we describe some possible
extensions of this result.
Closing remark.
In the encrypted database literature, it has
become apparent that known- and chosen-query attacks are
damaging. However, the quantitative question (“How severe
a risk is a known- or chosen-plaintext attack?”) has not
been fully explored. We posit that extending the above result
using techniques from learning theory will fully resolve this
question. Rather than developing this theme further here, we
leave it to future work and focus the remainder of this work
on more challenging attack settings.
III. SACRIFICIAL APPROXIMATE DATABASE
RECONSTRUCTION
In this section, we introduce sacriﬁcial -approximate
database reconstruction (sacriﬁcial -ADR), which asks to
successfully recover the value of every record in the database
within N, for some target precision , save for records whose
value lies within N of 1 or N. The term -approximate means
that reconstruction is within an error of N, as in [2]. The term
sacriﬁcial means the attack “sacriﬁces” records whose value
lies within N of the endpoints. We explain the need for this
and provide a full deﬁnition in Section III-A. The rest of the
section presents two results.
In Section III-B, we extend KKNO’s database reconstruc-
tion attack [3] to sacriﬁcial -ADR. A direct application of the
1070
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:47:08 UTC from IEEE Xplore.  Restrictions apply. 
Attack
Goal
Data density Proposed attack
Generic lower bound
Source
Query complexity
FDR
FDR
FDR
-ADR
KKNO
KKNO
LMP
LMP
GeneralizedKKNO sacriﬁcial -ADR any
sacriﬁcial -ADR any∗
ApproxValue
sacriﬁcial -AOR any∗
any
dense
dense
dense
ApproxOrder
O(N 4 log N )
Ω(N 4)
O(N 2 log N )
–
N log N + O(N )
2 N log N − O(N )
1
4 N log −1 + O(N ) N log −1 − O(N )
O(−4 log −1)
O(−2 log −1)
O(−1 log −1)
Ω(−4)
Ω(−2)
Ω(−1 log −1)
5
[3]
[3]
[2]
[2]
Section III-B
Section III-C
Section IV
Fig. 1. Comparison of database reconstruction attacks that use access pattern leakage from range queries chosen uniformly at random. N is the number of
possible plaintext values. All attacks are up to global reﬂection. Generic lower bounds are for any attack targeting the same goal under the same assumptions.
“∗” denotes some additional but mild requirements on the existence of records with particular values.
-sample theorem from learning theory shows the dependency
on N vanishes:
the required number of queries becomes
O(−4 log −1), making the attack scale-free.
introduce
In Section III-C, we
a new algorithm,
ApproxValue, for sacriﬁcial -ADR with a mild additional
hypothesis h1: the database contains at least one record whose
value lies in [0.2N, 0.3N ]∪ [0.7N, 0.8N ]. Under this hypoth-
esis, ApproxValue achieves sacriﬁcial -ADR within only
O(−2 log −1) queries. The analysis also uses the -sample
theorem, but is somewhat more involved. This attack shows the
pathological nature of KKNO’s lower bounds on query com-
plexity for FDR. An experimental validation in Section III-D
supports the analysis, and shows that the constants in the O
notation are empirically very small.
the previous two results
also imply full database reconstruction within O(N 4 log N )
queries in general, and O(N 2 log N ) when h1 is satisﬁed. In
the full version, we also show that both attacks are optimal in
data within a log factor—any adversary achieving sacriﬁcial
-ADR for all databases (resp. databases satisfying h1) must
require Ω(−4) (resp. Ω(−2)) queries.
A. Deﬁnition of Sacriﬁcial -ADR
As noted in the introduction,
We now formally deﬁne sacriﬁcial -approximate database
reconstruction (sacriﬁcial -ADR). Let  > 0 be the desired
precision. Let est-val(r) denote the value predicted by the
algorithm for record r. Sacriﬁcial -ADR is said to succeed
iff one of the following two events occur:
1) For every record r such that N ≤ val(r) ≤ N + 1− N,
2) For every record r such that N ≤ val(r) ≤ N + 1− N,
|est-val(r) − val(r)| < N.
|est-val(r) − (N + 1 − val(r))| < N.
The fact that reconstruction is only possible up to reﬂection
is inherent to this setting, as seen in [3], [2]. It is required
that for all values (except those within N of the extrema),
either the estimated value is within N of the correct value,
or its reﬂection. But whichever case it is holds simultaneously
for all values. In other words, only one bit of information is
missing globally regarding the reﬂection symmetry. Note that
setting  = 1/N yields full database reconstruction (FDR), i.e.
exact value reconstruction for all records.
Finally, we come to explaining why our attack needs to
be sacriﬁcial. Sacriﬁcing values that are close to 1 and N is
inherent to a scale-free attack under a uniform query assump-
tion. Intuitively, these values are harder to recover because
fewer range queries touch them. The probability of hitting
records with values 1 and N with a uniform range query is
2/(N +1) = O(1/N ). This remains true for any record whose
value is within O(1) of 1 or N: hitting one of these records
requires Ω(N ) queries. If they are not hit, then it is impossible
for the algorithm to differentiate them or determine which
records are on the same side of N/2—reﬂection symmetry
cannot be determined globally for those values. Note that if
the set of all records is known our algorithms can infer that
these records have values close to either 1 or N because they
were not hit by a query.
If a query on some range [1, x] for some x ∈ [N, N + 1−
N ] is ever issued, then the attacker is trivially able to break
the reﬂection symmetry between the values within N of 1
and N (since the query will hit records with values near one
of the endpoints, but not the other). The problem is that with
uniform queries, the probability of such a query is O(1/N ), so
requiring such a query to occur is not scale-free. In practice,
though, a query of that form seems likely, since endpoints
are generally “interesting” to query. For that reason, we view
the sacriﬁcial aspect of the attack as more of an artefact of
the analysis than a practical issue. Nevertheless, it must be
addressed in a formal treatment of the attack.
B. Generalizing the KKNO Attack
We now present our generalization of the KKNO attack to
sacriﬁcial -ADR. Our algorithm proceeds in two steps. The
ﬁrst step is to (approximately) recover the value of each record
up to reﬂection individually: for each record, we recover an
approximation of its symmetric value, deﬁned as symval(r) def=
min(cid:0)val(r), N +1−val(r)(cid:1). The second step of the algorithm
is to determine which values are on the same side of N/2
so that, in the end, the value of records is recovered up to
reﬂection globally, as discussed above.
We focus here on the ﬁrst step of the attack because it
sufﬁces to highlight the main ideas. For the second step and