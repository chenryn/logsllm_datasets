title:Smart Malware that Uses Leaked Control Data of Robotic Applications:
The Case of Raven-II Surgical Robots
author:Key-whan Chung and
Xiao Li and
Peicheng Tang and
Zeran Zhu and
Zbigniew T. Kalbarczyk and
Ravishankar K. Iyer and
Thenkurussi Kesavadas
Smart Malware that Uses Leaked Control Data of Robotic Applications:
The Case of Raven-II Surgical Robots
Keywhan Chung1, Xiao Li1, Peicheng Tang2, Zeran Zhu1, Zbigniew T. Kalbarczyk1, Ravishankar K. Iyer1,
and Thenkurussi Kesavadas1
1University of Illinois at Urbana-Champaign
2Rose-Hulman Institute of Technology
Abstract
In this paper, we demonstrate a new type of threat that lever-
ages machine learning techniques to maximize its impact.
We use the Raven-II surgical robot and its haptic feedback
rendering algorithm as an application. We exploit ROS vulner-
abilities and implement smart self-learning malware that can
track the movements of the robot’s arms and trigger the attack
payload when the robot is in a critical stage of a (hypotheti-
cal) surgical procedure. By keeping the learning procedure
internal to the malicious node that runs outside the physical
components of the robotic application, an adversary can hide
most of the malicious activities from security monitors that
might be deployed in the system. Also, if an attack payload
mimics an accidental failure, it is likely that the system admin-
istrator will fail to identify the malicious intention and will
treat the attack as an accidental failure. After demonstrating
the security threats, we devise methods (i.e., a safety engine)
to protect the robotic system against the identiﬁed risk.
1
Introduction
A number of attempts have been made to leverage machine
learning (ML) techniques to realize malicious intentions. For
instance, adversarial learning was used to effectively deceive
data-driven models by strategically injecting malicious in-
put [8, 25, 45, 47] to identify the target of an attack [28], or to
infer information hidden behind encrypted data [26, 33]. In
this context, smart malware that employs ML techniques rep-
resents a new concept for the implementation of sophisticated
attack strategies. Such malware can infer attack strategies
based on live operational data and trigger an attack at the
most opportune time so as to maximize the impact.
For threats that use self-learning malware, robotic appli-
cations turn out to be a fascinating target. Like other cyber-
physical systems (CPSes), robotic applications incorporate
sensors and actuators that are connected through a network
that passes around data. Their (i) relatively weak security
[5, 13, 31], (ii) abundance of data that can be used to infer
actionable intelligence [4, 9, 54], and (iii) close proximity to
and direct interactions with humans (such that a successful
attack could have a life-threatening impact) [14, 22, 23] make
robotic applications a tempting target for advanced threats.
To demonstrate the feasibility of smart malware, we have
built an injection module as a prototype. Our prototype smart
malware eavesdrops on the communication between the robot
components of a near-real-time system (as an input for the
smart malware), uses the leaked data to infer intelligence on
when to trigger the payload (or take control over the robot),
and executes the payload at the most opportune time (i.e.,
the output of our smart malware) so that it can maximize the
impact. While our attack model applies to any robotic system,
in this paper, we use the Raven-II surgical robot [3] and its
haptic feedback rendering algorithm as a target application.
Raven-II is driven by the Robot Operating System (ROS)
[44], an open-source framework that has been widely de-
ployed across various robotic applications (i.e., more than
125 applications [38]), and its resiliency is critical to varying
domains (e.g., robotic surgery, aviation, and manufacturing).
However, the most commonly used ROS contains vulnerabili-
ties [15] that leak data (e.g., robot state) transmitted within the
application, and those data can become the basis from which
smart malware can learn about the system behavior and use
this information to decide when to trigger an attack. We ex-
ploited ROS vulnerabilities and implemented smart malware
that tracks the movement of the robot’s arms and triggers the
attack payload when the robot is in a critical state of a (hypo-
thetical) surgical procedure. After demonstrating the security
threats, we discuss the methods (i.e., a safety module) that
we devised to protect the robotic system against the identiﬁed
risk.
What makes our malware stealthy is the invisibility of its
learning process to security monitoring systems. Unlike com-
mon malware, which is installed in a victim system, our mal-
ware runs outside the physical components of the robotic
application. The ROS allows any new node/process to regis-
ter with a master (core) node; hence, an attacker can register
its malicious node to the robotic application without being
noticed. By keeping the learning procedure internal to the
USENIX Association        22nd International Symposium on Research in Attacks, Intrusions and Defenses 337malicious node, an adversary can hide all malicious activities
(except for its network activities with genuine nodes of the
target application) from security monitors that might be de-
ployed. Hence, only the impact of the attack, which mimics
accidental failures, is observable to the system administrator.
As a result, it is likely that malicious faults will be seen as ac-
cidental failures (especially if the network trafﬁc is not being
monitored). Note that additional network trafﬁc introduced
by our malware prototype is negligible (about 0.24% of the
volume of the genuine trafﬁc).
The contributions of this paper are the following:
• We show the possibility of a real attack on a surgical robot
that exploits known vulnerabilities in the underlying run-
time environment, ROS. The vulnerabilities allow a ma-
licious entity to operate as a man-in-the-middle (MITM),
with the ability to eavesdrop (i.e., leak robot control data)
and overwrite communication among the robot components
(i.e., effectively take control of the robot).
• We demonstrate smart malware logic that can infer the
most opportune time of attack from the information ob-
tained through exploitation of the vulnerabilities in ROS.
Our experiment with three use cases that mimic (hypothet-
ical) surgical operations of different levels of complexity
shows that the ML algorithm (DBSCAN) used by our mal-
ware can determine the position of the robot end-effector
with respect to the target object and use this information
to trigger the execution of the payload. Speciﬁcally, the
DBSCAN algorithm triggers the injection of the attack
payload (i.e., corruption of data used to control the robot)
when the robot arm is in close proximity to the target object
(i.e., there is less than 10 mm distance between the robot
end-effector and the target object).
• We present a set of unique faults that, when used as an
attack payload, can threaten the integrity of the surgical
operation. The faults consist of realistic scenarios that can
be disguised as accidental failures, such as network packet
drop, data corruption, or bugs in the control software.
• We implement a ROS-generic safety module that can detect
abnormalities introduced by attacks and can bring the robot
to a safe state. Speciﬁcally, the safety module detects the
shutdown signal generated by the roscore in the case of
a name conﬂict (i.e., a new node registers itself with an
already existing name). If that happens, the safety module
terminates the new node, takes over the control of the robot,
and returns it to a predeﬁned safe state to prevent further
impact.
While we demonstrate the feasibility of the advanced threat
in the context of Raven-II and its underlying framework (i.e.,
ROS), the design of the smart malware is sufﬁciently generic
that it can be used on other robotic systems that generate a
stream of sensor data from input sensors and robot control
data to the physical robots. As summarized in [1], an attacker
can intrude into a robotic system through various entry points
(e.g., third-party networks, vulnerable workstations, and vul-
nerable or incorrectly conﬁgured ﬁrewalls or gateways). Once
smart malware has established an MITM attack (i.e., it can lis-
ten to and overwrite control data), its smart injection module
can infer the critical time of the operation of any robot. The
attack payloads (i.e., the faults to be injected), on the other
hand, are speciﬁc to the robotic application.
2 Motivation for smart malware
Machine learning techniques have been applied in different
domains (e.g., image processing and natural language pro-
cessing) to derive intelligence from data. Researchers and
engineers in cyber security have also deployed ML-based
techniques as part of an effort to advance methods for de-
tecting malicious activities. However, not much work has
considered the possibility that adversaries could take advan-
tage of machine learning algorithms to devise attack strategies.
More speciﬁcally, a few studies have investigated the poten-
tial impact of attacks that are supported by machine learning
algorithms [40, 41]. In this paper, we deﬁne smart malware
as malicious software that can, by itself, derive intelligence
from data obtained from the victim system.
Smart malware is available only at a cost (i.e., high compu-
tation workload). However, we ﬁnd reasons that might justify
the overhead: access to rich data and an ability to achieve
high impact with minimized remote interaction between the
malware (software) and the attacker (human). (That is, to
a certain extent, machine learning algorithms can replace
human-driven analysis in designing/customizing malware.)
Notably, long and unusual remote connections often lead to
exposure of attackers. Furthermore, the computational load
imposed by the execution of the smart malware can be obfus-
cated with techniques such as the “low and slow” approach,
whereby attackers intentionally reduce the computation work-
load despite having to tolerate a longer time of execution.
For machine-learning-driven threats, cyber-physical sys-
tems (especially robotic applications) turn out to be tempting
targets. In cyber-physical systems, sensors and monitors are
deployed across the system to gather information (e.g., on
images, sounds, temperature, and ﬂows). Data collected from
input sensors are sent to controllers or computation units that
derive control variables or decisions, which are passed to the
actuator to update the state of the system. While traditional
robots were contained within a single physical system, the
new concept of distributed robotics (or collaborative robotics)
is expanding the boundary of robotic systems. (E.g., with
remote surgery, a physician can perform surgery from a re-
mote location.) A key enabler for this new mode of attacking
the system is a protocol for sharing data across a network.
However, if the protocol is not properly designed for security,
it can introduce vulnerabilities that eventually exploited by
smart malware.
For instance, a publish-subscribe model is a common mes-
saging pattern in which the information is shared between
338          22nd International Symposium on Research in Attacks, Intrusions and DefensesUSENIX Associationthe publisher and the subscriber. Its advantages include scal-
ability and loose coupling between the publishers and the
subscribers. However, such advantages introduce side effects
that impact the security of the system. Without authentication
and encryption, unauthorized entities can read messages and
leak data. Such data become a baseline for learning, from
which malicious entities can derive actionable intelligence. In
this paper, we demonstrate the threat by using the Raven-II
surgical robot (running on top of ROS) as the target for such
an attack strategy.
3 Background: Robots, ROS, and Raven-II
Robots have been adopted across different application do-
mains. For example, in manufacturing, robot manipulators
assist human workers; drones are deployed in agriculture,
entertainment, and military operations; and surgical robots
support surgeons in performing medical procedures. For such
applications, robots play a critical role. A robot’s failure to
make a correct and timely movement can lead to catastrophic
consequences, such as injuring people near the robots in fac-
tories or risking a patient’s life during surgery. This study
focuses on the resiliency of a surgical robot against malicious
attacks. We use the Raven-II surgical robot [3] and its hap-
tic rendering algorithm as an application to demonstrate the
security threat, and suggest methods to cope with the risk.
Robot Operating System (ROS). The Robot Operating Sys-
tem (ROS) is an open-source framework for programming
robots [44], and is commonly used by various robotic ap-
plications. According to its ofﬁcial website, ROS is widely
deployed across more than 125 different robots, including mo-
bile robots, drones, manipulators, and humanoids [38]. The
framework is being developed to support collaborative de-
velopment by experts from different domains (e.g., computer
vision or motion planning) and provides hardware abstraction,
device drivers, libraries, and a communication interface [44].
For instance, the OpenCV library [6] provides interfaces that
can be used to add vision to robotics applications, and the
OpenNI library [35] focuses on integrating 3D sensors into
robots. As ROS provides the core underlying runtime environ-
ment, the security of ROS is critical in ensuring the correct
operation of the robot.
As shown in Fig. 1a, a ROS-based application consists of
multiple ROS nodes. They can be running on a single physical
machine or can be distributed across multiple machines (i.e.,
Computers A and B in the ﬁgure), as long as they share the
ROS core, which is deployed on the computer declared as the
ROS master. Each node communicates over the network, and
the ROS core serves as the central server for all nodes. Data
are exchanged in the context of a topic, where a topic is a
data structure deﬁned to deliver a speciﬁc context type; e.g.,
the image sensor data are exchanged in the form of multidi-
mensional arrays, which consist of the RGB color codes for
all pixels captured by the image sensor. A node, either a pub-
lisher or a subscriber, registers itself to the ROS core for the
topic that the node is about to publish (or subscribe to). The
ROS core then passes the information (i.e., the IP address) of
the publisher to the subscriber waiting for the topic, so that
the subscriber can establish a TCP connection with the pub-
lisher. After a handshaking protocol and transmission of the
metadata that include the structure of the topic message, the
two entities start passing the message by using a ROS-speciﬁc
protocol.
The ROS nodes can be classiﬁed into three types: input
nodes, output nodes, and computational nodes. An input node
is a node connected to a piece of hardware (e.g., an image
sensor or a haptic device) that provides input to the robot
application. The input node, using the device driver provided
by (or interfaced with) ROS, collects the data and converts the