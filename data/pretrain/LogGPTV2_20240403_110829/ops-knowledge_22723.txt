User: How to use Logstash + Elasticsearch + Kibana to realize centralized management and analysis of logs? Please list the corresponding configuration file content and usage steps.
Assistant: Logstash + Elasticsearch + Kibana (ELK) is a set of open source tools that enable centralized management and analysis of logs. Steps to use: 1. Install Elasticsearch, Logstash and Kibana. 2. Configure Logstash, create input plugins, filter plugins, and output plugins to collect, parse, and send log files to Elasticsearch. 3. Configure Elasticsearch, create indexes, mappings, shards, etc., and store logs in Elasticsearch. 4. Configure Kibana, create index patterns, visualize and search, etc., and analyze and view logs through the web interface. Example configuration file: Input plugin configuration file: ``` input { file { path => "/var/log/sample.log" start_position => "beginning" } } ``` Filter plugin configuration file: ``` filter { grok { match => { "message" => "%{COMBINEDAPACHELOG}" } } date { match => [ "timestamp", "dd/MMM/yyyy:HH:mm:ss Z" ] } } ``` Output plug-in configuration file: ``` output { elasticsearch { hosts => ["localhost:9200"] index => "sample-%{+YYYY.MM.dd}" } } ``` Use ELK to implement centralized log management and analysis: 1. Start Elasticsearch. 2. Start Logstash, and specify configuration files for input plugins, filter plugins, and output plugins. 3. Start Kibana, create index patterns, visualizations, searches, etc. 4. Analyze and view logs through the web interface.