up the data. Again there is an ad-hoc linear-congruential random-
number generator, this time producing each 32-bit seed as the
previous 32-bit seed times 1103515245 plus 12345 modulo 231, and
returning the top 16 bits of the seed (between 0 and 215 ‚àí 1) as
output. The bottom 8 bits of the output are then used as the next
ùëè = 8 bits of input data for the CRC.
For st the obvious costs in initialization were integer and floating-
point divisions by 8095. For crc32, there are no floating-point op-
erations, and the reduction modulo 231 is already written as a logic
operation. Furthermore, the initialization loop in crc32 is already
merged into the CRC computation loop, rather than having one
pass through an array to write data followed by a separate pass
through the array to process data.
However, each iteration of the crc32 loop calls a function in a
separate file to generate a random number. The compiler does not
inline the function. The only changes from crc32 to crc32-opt are
(1) putting the random-number-generation function into the same
file for inlining and (2) marking the main loop with UNROLL(4).
The unrolling increases code size, while the inlining reduces code
size since unnecessary function prologs and epilogs disappear; both
changes in code size are negligible.
Note that it is already common practice for any short function
in C and C++, such as a function generating a random number,
to be defined in a .h file, so that the compiler can easily inline
the function. There is also increasing use of compiler features for
‚Äúlink-time optimization‚Äù, which has the same basic goal.
B.5 Patterns observed, and consequences for
BasicBlocker
In each of these case studies, many of the inefficiencies in the
original code arise directly from loop overhead (and, analogously,
function-call overhead in the crc32 case). Branch prediction does
not magically make loop overhead (and function-call overhead)
17
ArXiv Version, 2021, May
J. Thoma, J. Feldtkeller, M. Krausz, T. G√ºneysu, D. J. Bernstein
disappear; it can reduce the overhead, but extremely short loops
(and functions) are generally performance problems if they are in
hot spots. The standard response is unrolling (plus inlining) for hot
spots, saving time on current CPUs‚Äîand saving even more time
for BasicBlocker.
Further inefficiencies were handled by copy elimination (e.g.,
removing the repeated reads and writes of *Sum), strength reduc-
tion (e.g., replacing divisions by 8095 with multiplications), and
common-subexpression elimination (e.g., eliminating the repeated
computation of variance)‚Äîwhich can indirectly increase branch
frequency by reducing the time spent on arithmetic operations
between branches. However, having fewer instructions in a loop
usually allows more unrolling for the same code size, and then
branch frequency drops again.
BasicBlocker avoids all hot-spot stalls if each hot-spot branch
condition can be computed enough cycles ahead of the branch to
cover the pipeline length. The obvious way to find computations
that are intrinsically bad for BasicBlocker, rather than being bad as a
result of easily fixable failures of unrolling and inlining, is to look for
computations bottlenecked by one data-dependent branch feeding
into another data-dependent branch, such as the bit-by-bit data-
dependent branches in modul64 and xbinGCD inside aha-mont. We
emphasize that these computations also perform poorly on existing
CPUs; we saved time across platforms by replacing these algorithms
with faster algorithms.
These case studies are not necessarily representative. Are there
important computations where the fastest algorithms involve one
data-dependent branch after another? There is a textbook example
at this point, namely sorting integer arrays. Embench includes a
wikisort benchmark (which did not compile for our target), stably
sorting 400 64-bit records, where each record has a 32-bit integer
key used for sorting and 32 bits of further data. The algorithm
used inside wikisort is a complicated merge-sort variant; overall
wikisort has 1117 lines, several kilobytes of compiled code.
However, the textbook picture of the fastest sorting algorithms
has been challenged by the recent speed records in [7] for sorting
various types of arrays on Intel CPUs. The software in [7] has no
data-dependent branches. For a size-400 array, this software uses a
completely predictable pattern of 7199 comparators (size-2 sorting
operations, i.e., min-max operations); merge sort, heap sort, etc. use
half as many comparisons but in an unpredictable pattern, incurring
so much overhead as to be non-competitive.
This raises a research question: exactly how far is wikisort
from optimal on smaller CPUs? An application where sorting is
critical will select the fastest sorting routine from among many
options‚Äînot just comparison-based sorts such as merge sort but
also radix sort, sorting networks, etc. The time taken by wikisort
is, presumably, an overestimate of the time needed for the same
task on current CPUs, and an even more severe overestimate of the
time needed for the same task on BasicBlocker CPUs.
More broadly, algorithms without data-dependent branches are
an essential part of the modern software-optimization picture for
large CPUs, especially because of the role of these algorithms inside
vectorized code. This does not imply that these algorithms have the
same importance on today‚Äôs smaller CPUs, but in any case they are
among the options available for small and large BasicBlocker CPUs.
Taking advantage of this software flexibility brings BasicBlocker
CPUs even closer to current CPUs in overall performance.
C COMPILE FLAGS
The compile flags for the Coremark benchmark are listed in fig. 14
(omitting includes, debug, macros, toolchain paths and flags en-
abling bb instructions).
Flag
O3
march=rv32im
mabi=ilp32
target=riscv32-unknown-
elf
mno-relax
lc
nostartfiles
ffreestanding
Description
Optimization Level 3
32-Bit RISC-V with IM extensions
Calling convention and memory lay-
out
Select target architecture
No linker relexation
Link C library
Do not use standard system startup
files when linking.
Only use features available in free-
standing environment.
Figure 14: Coremark compile flags.
The compile flags for the Embench benchmarks are listed in
fig. 15 (omitting includes, debug, macros, toolchain paths and flags
enabling bb instructions).
Flag
O3
march=[rv32im/rv64imfd]
mabi=[ilp32/lp64d]
target=riscv[32/64]-
unknown-elf
mno-relax
fno-strict-aliasing
Description
Optimization Level 3
32-Bit RISC-V for VexRiscv and 64-
bit for Gem5
Calling convention and memory lay-
out
Select target architecture
No linker relexation
Disable strict aliasing.
Figure 15: Embench compile flags.
D PIPELINE EVALUATION GRAPHS
This Appendix lists the graphs for pipeline prolongation for other
benchmarks.
D.1 VexRiscv Pipeline Length
Figure 16 to 30 show the graphs for VexRiscv.
18
BasicBlocker: ISA Redesign to Make Spectre-Immune CPUs Faster
ArXiv Version, 2021, May
Fig. 16: VexRiscv - coremark
Fig. 17: VexRiscv - aha-mont
Fig. 18: VexRiscv - aha-mont-opt
Fig. 19: VexRiscv - crc32
Fig. 20: VexRiscv - crc32-opt
Fig. 21: VexRiscv - edn
Fig. 22: VexRiscv - huffbench
Fig. 23: VexRiscv - nbody
Fig. 24: VexRiscv - nettle-aes
Fig. 25: VexRiscv - nettle-sha
Fig. 26: VexRiscv - pointer-chase
Fig. 27: VexRiscv - qrduino
Fig. 28: VexRiscv - st
Fig. 29: VexRiscv - statemate
Fig. 30: VexRiscv - ud
D.2 Gem5 Pipeline Length
Figure 31 to 45 show the graphs for Gem5.
19
012345678910012¬∑107PipelineDelayClockCyclesCFSBBInfoBBReschedEarlyDecode012345678910012¬∑107PipelineDelayClockCyclesCFSBBInfoBBReschedEarlyDecode012345678910012¬∑106PipelineDelayClockCyclesCFSBBInfoBBReschedEarlyDecode01234567891000.51¬∑107PipelineDelayClockCyclesCFSBBInfoBBReschedEarlyDecode0123456789100123¬∑106PipelineDelayClockCyclesCFSBBInfoBBReschedEarlyDecode01234567891000.51¬∑107PipelineDelayClockCyclesCFSBBInfoBBReschedEarlyDecode01234567891000.511.5¬∑107PipelineDelayClockCyclesCFSBBInfoBBReschedEarlyDecode01234567891000.511.5¬∑106PipelineDelayClockCyclesCFSBBInfoBBReschedEarlyDecode0123456789100246¬∑106PipelineDelayClockCyclesCFSBBInfoBBReschedEarlyDecode0123456789100246¬∑106PipelineDelayClockCyclesCFSBBInfoBBReschedEarlyDecode012345678910024¬∑107PipelineDelayClockCyclesCFSBBInfoBBReschedEarlyDecode01234567891000.511.52¬∑107PipelineDelayClockCyclesCFSBBInfoBBReschedEarlyDecode01234567891002468¬∑106PipelineDelayClockCyclesCFSBBInfoBBReschedEarlyDecode01234567891000.511.5¬∑107PipelineDelayClockCyclesCFSBBInfoBBReschedEarlyDecode01234567891002468¬∑106PipelineDelayClockCyclesCFSBBInfoBBReschedEarlyDecodeArXiv Version, 2021, May
J. Thoma, J. Feldtkeller, M. Krausz, T. G√ºneysu, D. J. Bernstein
Fig. 31: Gem5 - aha-mont
Fig. 32: Gem5 - aha-mont-opt
Fig. 33: Gem5 - crc32
Fig. 34: Gem5 - crc32-opt
Fig. 35: Gem5 - cubic
Fig. 36: Gem5 - edn
Fig. 37: Gem5 - nbody
Fig. 38: Gem5 - nettle-aes
Fig. 39: Gem5 - nettle-sha
Fig. 40: Gem5 - picojpeg
Fig. 41: Gem5 - qrduino
Fig. 42: Gem5 - st
Fig. 43: Gem5 - st-opt
Fig. 44: Gem5 - statemate
Fig. 45: Gem5 - ud
D.3 Gem5 Pipeline Width
Figure 46 to 60 show the graphs for Gem5.
20
012340123¬∑109PipelineDelayTicksBBInfoUpshiftCFSEarlyBranch01234012¬∑108PipelineDelayTicksBBInfoUpshiftCFSEarlyBranch01234024¬∑109PipelineDelayTicksBBInfoUpshiftCFSEarlyBranch0123402468¬∑108PipelineDelayTicksBBInfoUpshiftCFSEarlyBranch0123400.51¬∑108PipelineDelayTicksBBInfoUpshiftCFSEarlyBranch012340123¬∑109PipelineDelayTicksBBInfoUpshiftCFSEarlyBranch012340123¬∑107PipelineDelayTicksBBInfoUpshiftCFSEarlyBranch0123400.511.5¬∑109PipelineDelayTicksBBInfoUpshiftCFSEarlyBranch0123400.51¬∑109PipelineDelayTicksBBInfoUpshiftCFSEarlyBranch012340246¬∑109PipelineDelayTicksBBInfoUpshiftCFSEarlyBranch012340246¬∑109PipelineDelayTicksBBInfoUpshiftCFSEarlyBranch0123402468¬∑107PipelineDelayTicksBBInfoUpshiftCFSEarlyBranch012340246¬∑107PipelineDelayTicksBBInfoUpshiftCFSEarlyBranch012340123¬∑109PipelineDelayTicksBBInfoUpshiftCFSEarlyBranch0123400.511.52¬∑109PipelineDelayTicksBBInfoUpshiftCFSEarlyBranchBasicBlocker: ISA Redesign to Make Spectre-Immune CPUs Faster
ArXiv Version, 2021, May
Fig. 46: Gem5 - aha-mont
Fig. 47: Gem5 - aha-mont-opt
Fig. 48: Gem5 - crc32
Fig. 49: Gem5 - crc32-opt
Fig. 50: Gem5 - cubic
Fig. 51: Gem5 - edn
Fig. 52: Gem5 - nbody
Fig. 53: Gem5 - nettle-aes
Fig. 54: Gem5 - nettle-sha
Fig. 55: Gem5 - picojpeg
Fig. 56: Gem5 - qrduino
Fig. 57: Gem5 - st
Fig. 58: Gem5 - st-opt
Fig. 59: Gem5 - statemate
Fig. 60: Gem5 - ud
E RAW BENCHMARK RESULTS
E.1 VexRiscv
The Table shown in fig. 61) lists the mean result of each benchmark
on VexRiscv as well as the upper and lower quartiles over 100
executions.
21
1234567012¬∑109PipelineWidthTicksBBInfoBBReschedCFSNoSpec12345670123¬∑108PipelineWidthTicksBBInfoBBReschedCFSNoSpec12345670246¬∑109PipelineWidthTicksBBInfoBBReschedCFSNoSpec123456700.511.52¬∑109PipelineWidthTicksBBInfoBBReschedCFSNoSpec123456700.51¬∑108PipelineWidthTicksBBInfoBBReschedCFSNoSpec1234567024¬∑109PipelineWidthTicksBBInfoBBReschedCFSNoSpec12345670123¬∑107PipelineWidthTicksBBInfoBBReschedCFSNoSpec12345670123¬∑109PipelineWidthTicksBBInfoBBReschedCFSNoSpec12345670123¬∑109PipelineWidthTicksBBInfoBBReschedCFSNoSpec12345670246¬∑109PipelineWidthTicksBBInfoBBReschedCFSNoSpec1234567024¬∑109PipelineWidthTicksBBInfoBBReschedCFSNoSpec123456700.51¬∑108PipelineWidthTicksBBInfoBBReschedCFSNoSpec123456702468¬∑107PipelineWidthTicksBBInfoBBReschedCFSNoSpec1234567024¬∑109PipelineWidthTicksBBInfoBBReschedCFSNoSpec123456700.511.52¬∑109PipelineWidthTicksBBInfoBBReschedCFSNoSpecArXiv Version, 2021, May
J. Thoma, J. Feldtkeller, M. Krausz, T. G√ºneysu, D. J. Bernstein
Benchmark
Coremark
aha-mont
aha-mont-opt
crc32
crc32-opt
cubic
edn
huffbench
matmult-int
minver
nbody
nettle-aes
nettle-sha
picojpeg
pointer-chase
qrduino
st
st-opt
statemate
ud
Quartile
Speculation
Median
Quartile
Quartile
No Speculation
Median
Quartile
Quartile
BB Info
Median
Quartile
Quartile
Rescheduling
Median
Quartile
5175116
4932786
1066889
3230872
2699898
537960
5133587
3342980
4478246
98144
308486
4862599
5879961
5959857
20396094
6053379
347356
285404
6160619
3302205
5175286
4932801
1066913
3230948
2699900
538204
5133694
3343182
4478557
98220
308528
4863024
5881300
5960273
20396748
6053754
347388
285450
6160794
3302306
5175482
4932815
1066938
3231032
2699902
538317
5133840
3343359
4478918