如下图，对Task进行抽样显示，所有的Substasks状态均显示OK，表示未发生大规模的数据堵塞，系统整体运行正常，不需要做任何调整。
![](media/image15.png){width="5.763888888888889in"
height="2.6555555555555554in"}
如果对Task进行采样检测，所有的Subtasks状态均显示HIGH，表示系统触发了较多的反压，需要适当地增加Subtask并发度或者降低数据生产速度，否则经过长时间的运行后，系统中处理的数据将出现比较严重的超时现象。
#### Backpressure配置
针对反压的优化，用户可以调整以下参数：
-   web.backpressure.cleanup-interval：当启动反压数据采集后，需要等待页面并获取反压数据的时间长度，默认是60s。
-   web.backpressure.delay-between-samples：Stack
    Trace抽样到确认反压状态之间的时延，默认为50ms。
-   web.backpressure.num-samples：设定Stack
    Trace抽样数以确定反压状态，默认为100。
    1.  ### Checkpointing监控与优化
#### Checkpointing页面监控
Flink Web页面中也提供了针对Job
Checkpointing相关的监控信息，Checkpointing监控页面中共有Overview、History、Summary、Configuration四个页签，分别对Checkpointing从不同的角度进行了监控，每个页面中都包含了与Checkpointing相关的指标。
Overview页签中宏观地记录了Flink应用中Checkpoints的数量以及Checkpoint的最新记录，包括失败和完成的Checkpoints记录。
如下图所示，Overview页签中包含了以下指标，这些指标会依赖于JobManager的存活，也就是说当JobManager关闭或者重置都会置空这些统计信息。
![](media/image16.png){width="5.763888888888889in"
height="1.8069444444444445in"}
-   Checkpoint
    Counts：包含了触发、进行中、完成、失败、重置等Checkpoint状态数量统计。
-   Latest Completed
    Checkpoint：记录了最近一次完成的Checkpoint信息，包括结束时间，端到端时长，状态大小等。
-   Latest Failed Checkpoint：记录了最近一次失败的Checkpoint信息。
-   Latest Savepoint：记录了最近一次Savepoint触发的信息。
-   Latest
    Restore：记录了最近一次重置操作的信息，包括从Checkpoint和Savepoint两种数据中重置恢复任务。
History页签中记录了历史触发Checkpoint的详情，包括Checkpoint的ID、状态、触发时间、最后一次Acknowledge信息等，通过点击More
details对应的链接可以查看子Task对应的Checkpoint数据。
Summary页面中记录了所有完成的Checkpoint统计指标的最大值、最小值以及平均值等，指标中包括端到端的持续时间、状态大小以及分配过程中缓冲的数据大小。
![](media/image17.png){width="5.763888888888889in" height="1.8625in"}
Configuration页签中包含Checkpoints中所有的基本配置，具体配置解释如下：
-   Checkpointing Mode：标记Checkpointing是Exactly Once还是At Least
    Once的模式。
-   Interval：Checkpointing触发的时间间隔，时间间隔越小意味着越频繁的Checkpointing。
-   Timeout：Checkpointing触发超时时间，超过指定时间JobManager会取消当次Checkpointing，并重新启动新的Checkpointing。
-   Minimum Pause Between
    Checkpoints：配置两个Checkpoints之间最短时间间隔，当上一次Checkpointing结束后，需要等待该时间间隔才能触发下一次Checkpoints，避免触发过多的Checkpoints导致系统资源被消耗。
-   Persist Checkpoints
    Externally：如果开启Checkpoints，数据将同时写到外部持久化存储中。
![](media/image18.png){width="5.763888888888889in"
height="1.8604166666666666in"}
#### Checkpointing优化
Checkpointing优化可以从最小时间间隔、状态容量预估、异步Snapshot、状态数据压缩、Checkpoint
Delay Time几方面入手。
**1.最小时间间隔**
当Flink应用开启Checkpointing功能，并配置Checkpointing时间间隔，应用中就会根据指定的时间间隔周期性地进行Checkpointing操作。默认情况下Checkpointing操作都是同步进行，也就是说，当前面触发的Checkpointing动作没有完全结束时，之后的Checkpointing操作将不会触发。在这种情况下，如果Checkpointing过程持续的时间超过了配置的时间间隔，就会出现排队的情况。如果有非常多的Checkpointing操作在排队，就会占用额外的系统资源用于Checkpointing，此时用于任务计算的资源将会减少，进而影响到整个应用的性能和正常执行。
在这种情况下，如果大状态数据确实需要很长的时间来进行Checkpointing，那么只能对Checkpointing的时间间隔进行优化，可以通过Checkpointing之间最小间隔参数进行配置，让Checkpointing之间根据Checkpointing执行速度进行调整，前面的Checkpointing没有完全结束，后面的Checkpointing操作也不会触发。
通过最小时间间隔参数配置，可以降低Checkpointing对系统的性能影响，但需要注意的是，对于非常大的状态数据，最小时间间隔只能减轻Checkpointing之间的堆积情况。如果不能有效快速地完成Checkpointing，将会导致系统Checkpointing频次越来越低，当系统出现问题时，没有及时对状态数据有效地持久化，可能会导致系统丢失数据。因此，对于非常大的状态数据而言，应该对Checkpointing过程进行优化和调整，例如采用增量Checkpointing的方法等。
**2.状态容量预估**
除了对已经运行的任务进行Checkpointing优化，对整个任务需要的状态数据量进行预估也非常重要，这样才能选择合适的Checkpointing策略。
对任务状态数据存储的规划依赖于如下基本规则：
-   正常情况下应该尽可能留有足够的资源来应对频繁的反压。
-   需要尽可能提供给额外的资源，以便在任务出现异常中断的情况下处理积压的数据。这些资源的预估都取决于任务停止过程中数据的积压量，以及对任务恢复时间的要求。
-   系统中出现临时性的反压没有太大的问题，但是如果系统中频繁出现临时性的反压，例如下游外部系统临时性变慢导致数据输出速率下降，这种情况就需要考虑给予算子一定的资源。
-   部分算子导致下游的算子负载非常高，下游的算子完全是取决于上游算子的输出，因此对类似于窗口算子的估计也将会影响到整个任务的执行，应该尽可能给这些算子留有足够的资源以应对上游算子产生的影响。
**3.异步Snapshot**
默认情况下，应用中的Checkpointing操作都是同步执行的，在条件允许的情况下应该尽可能地使用异步的Snapshot，这样将大幅度提升Checkpointing的性能，尤其是在非常复杂的流式应用中，如多数据源关联、Co-functionsc操作或Windows操作等，都会有较好的性能改善。
在使用异步快照前需要确认应用遵循以下两点要求：
-   首先必须是Flink托管状态，即使用Flink内部提供的托管状态所对应的数据结构，例如常用的ValueState、ListState、ReducingState等类型状态。
-   StateBackend必须支持异步快照，在Flink1.2的版本之前，只有RocksDB完整地支持异步的Snapshot操作，从Flink1.3版本以后可以在heap-based
    StateBackend中支持异步快照功能。
**4.状态数据压缩**
Flink中提供了针对Checkpoints和Savepoints的数据进行压缩的方法，目前Flink仅支持通过Snappy压缩算法对状态数据进行压缩，在未来的版本中Flink将支持其他压缩算法。在压数过程中，Flink的压数算法支持Key-Group层面压缩，也就是不同的Key-Group分别被压缩成不同的部分，因此解压缩过程可以并行进行，这对大规模数据的压缩和解压缩带来非常高的性能提升和较强的可拓展性。
**5.Checkpoint Delay Time**
Checkpoints延时启动时间并不会直接暴露在客户端中，而是需要通过以下公式计算得出。如果该时间过长，则表明算子在进行Barries对齐，等待上游的算子将数据写入到当前算子中，说明系统正处于一个反压状态下。
Checkpoint Delay
Time可以通过整个端到端的计算时间减去异步持续的时间和同步持续的时间得出，即checkpoint_start_delay
= end_to_end_duration -- synchronous_duration -- asynchronous_duration。
### Flink内存优化
Flink基于JVM实现了自己的内存管理，将JVM根据内存区分为Unmanned
Heap、Flink Managed Heap、Network Buffers三个区域。在Flink内部对Flink
Managed Heap进行管理，在启动集群的过程中直接将堆内存初始化成Memory Pages
Pool，也就是将内存全部以二进制数组的方式占用，形成虚拟内存使用空间。新创建的对象都是以序列化成二进制数据的方式存储在内存页面池中，当完成计算后数据对象Flink就会将Page置空，而不是通过JVM进行垃圾回收，保证数据对象的创建永远不会超过JVM堆内存大小，也有效地避免了因为频繁GC导致的系统稳定性问题。
#### Flink内存配置
以下分别对JobManager和TaskManager组件内存配置进行说明。
**1.JobManager配置**
JobManager在Flink系统中主要承担管理集群资源、接收任务、调度Task、收集任务状态以及管理TaskManager的功能，JobManager本身并不直接参与数据的计算过程中，因为JobManager的内存配置项不是特别多，只要指定JobManager堆内存大小即可。
-   jobmanager.heap.size：设定JobManager堆内存大小，默认为1024MB。
**2.TaskManager配置**
TaskManager作为Flink集群中的工作节点，所有任务的计算逻辑均执行在TaskManager之上，因为对TaskManager内存配置显得尤为重要，可以通过以下参数配置对TaskManager进行优化和调整。
-   taskmanager.heap.size：设定TaskManager堆内存大小，默认值为1024M.
-   taskmanager.jvm-exit-on-oom：设定TaskManager是否会因为JVM发生内存溢出而停止，默认为false，当TaskManager发生内存溢出时，也不会导致TaskManager停止。
-   taskmanager.memory.size：设定TaskManager内存大小，默认为0，如果不设定，该值将会使用taskmanager.memory.fraction作为内存分配依据。
-   taskmanager.memory.fraction：设定TaskManager堆中去除Network
    Buffers内存后的内存分配比例。该内存主要用于TaskManager任务排序、缓存中间结果等操作。例如，如果设定为0.8，则代表TaskManager保留80%内存用于中间结果数据的缓存，剩下20%的内存用于创建用户定义函数中的数据对象存储。注意，该参数只有在taskmanager.memory.size不设定的情况下才生效。
-   taskmanager.memory.off-heap：设置是否开启堆外内存供Managed
    Memory或者Network Buffers使用。
-   taskmanager.memory.preallocate：设置是否在启动TaskManager过程中直接分配TaskManager管理内存。
-   taskmanager.numberOfTaskSlots：每个TaskManager分配的slot数量。
#### Network Buffers配置
Flink将JVM堆内存切分为三部分，其中一部分为Network Buffers内存。Network
Buffers内存是Flink数据交互层的关键内存资源，主要目的是缓存分布式数据处理过程中的输入数据。例如在Repartitioning和Broadcating操作过程中，需要消耗大量的Network
Buffers对数据进行缓存，然后才能触发之后的操作。通常情况下，比较大的Network
Buffers意味着更高的吞吐量。如果系统出现了"Insufficient number of network
buffers"的错误，一般是因为Network
Buffers配置过低导致的，因此，在这种情况下需要适当调整TaskManager上的Network
Buffers的内存大小，以使得系统能够达到相对较高的吞吐量。
目前Flink能够调整Network
Buffers内存大小的方式有两种：一种是通过直接指定Network
Buffers内存数量的方式，另外一种是通过配置内存比例的方式。
**1.设定Network Buffer内存数量**
直接设定Network Buffer数量需要通过如下公式计算得出：
NetworkBuffersNum = total-degree-of-parallelism \* intra-node-
parallelism \* n
其中：
-   total-degree-of-parallelism表示每个TaskManager的总并发数量；
-   intra-node- parallelism表示每个TaskManager输入数据源的并发数量；
-   n表示在预估计算过程中Repartitioning或Broadcasting操作并行的数量。
intra-node-
parallelism通常情况下与TaskManager的所占有的CPU数一致，且Repartitioning或Broadcasting一般下不会超过4个并发。所以可以将计算公式转化如下:
NetworkBuffersNum = \\^2 \* \ \* 4
其中：
-   slots-per-TM是每个TaskManager上分配的slots数量；
-   TMs是TaskManager的总数量。
对于一个含有20个TaskManager，每个TaskManager含有8个slot的集群来说，总共需要的Network
Buffer数量为8\^2\*20\*4=5120个，因此集群中配置Network
Buffer内存的大小约为300M较为合适。
> 计算完Network Buffer数量后，可以通过添加如下两个参数对Network
> Buffer内存进行配置。
-   taskmanager.network.numberOfBuffers：指定Network堆栈Buffer内存块的数量。
```{=html}
```
-   taskmanager.memory.segment-size：内存管理器和Network栈使用的内存Buffer大小，默认为32KB。
其中segment-size为每个Network
Buffer的内存大小，默认为32KB，一般不需要修改，通过设定numberOfBuffers参数已达到计算出的内存大小要求。
**2.设定Network内存比例**
在1.3版本以前，设定Network
Buffers内存大小需要通过上面的方式进行，显然相对比较繁琐。从1.3版本开始，Flink就提供了通过指定内存比例的方式设置Network
Buffer内存大小，其涵盖的配置参数如下：
-   taskmanager.network.memory.fraction：JVM中用于Network
    Buffers的内存比例。
-   taskmanager.network.memory.min：最小的Network
    Buffer内存大小，默认为64MB。
-   taskmanager.network.memory.max：最大的Network
    Buffer内存大小，默认为1GB。
-   taskmanager.network.segment-size：内存管理器和Network栈使用的Buffer大小，默认为32KB。
目前Flink已经将直接设定Network
Buffer内存大小的方式标记为@deprecated，也就是说未来的版本中可能会移除这种配置方式，因为建议用尽可能采用按比例配置的方式。
3.  # 部署方案
    1.  ## Flink+Fornaxee方案
自研数据工厂fornaxee沿用了开源streamsets的部分功能（组件和语法），目前支持14个组件（2个origins，10个processors，2个Destinations），作为flink的客户端与flink集群配合使用（销售时flink可以一起或者对接客户flink集群）。这里主要介绍如何部署fornaxee与flink集群。
### 部署flink集群
默认以standalone模式部署，这里以2台机器为例（143为jobmanager，task为100），首先确保部署的机器上需要具备以下条件：
(1)jdk（1.8版本及以上）
(2)jobmanger节点与task节点间需要配置ssh互信
部署流程包括以下步骤：
1.  下载Flink安装包
2.  调整集群基础配置项
3.  启动进程
4.  访问web页面
5.  测试提交任务
#### 下载flink包
*wget
*
*tar -zxvf flink-1.9.2-bin-scala_2.11.tgz -C /opt*
#### 调整集群基础配置项
配置文件/opt/flink-1.9.2/conf/flink-conf.yaml，主要几个配置项如下：
  -----------------------------------------------------------------------
  配置项                              说明
  ----------------------------------- -----------------------------------
  jobmanager.rpc.address:             jobmanger的地址
  192.168.1.143                       
  jobmanager.rpc.port: 6123           节点内部rpc通信端口
  jobmanager.heap.size: 1024m         jobmanger总的可用的内存
  taskmanager.heap.size: 1024m        taskmanager总的可用内存
  taskmanager.numberOfTaskSlots: 4    每个task节点上可使用的cpu个数
  parallelism.default: 1              默认并行计算个数
  rest.port: 8082                     jobmanager的web端口默认8081
  jobmanager.web.submit.enable: false 是否可从 Web 页面进行作业提交
  -----------------------------------------------------------------------
查验配置的task节点：
*cat /opt/flink-1.9.2/conf/slaves*
*192.168.1.100*
*192.168.1.143*
#### 启动进程
从jobmanager节点将flink目录拷贝到task节点（需确保ssh互相通信）
*scp -r /opt/flink/flink-1.9.2 *
在143上启动flink进程：
*cd /opt/flink-1.9.2/bin;./start-cluster.sh*
![](media/image19.png){width="5.768055555555556in"
height="1.0006944444444446in"}
这时会将task节点上的taskmanager进程自动拉起，在taks节点上查看进程如下：
![](media/image20.png){width="5.768055555555556in"
height="0.3840277777777778in"}
#### 访问web页面
浏览器访问：，可以看到有8个TaskSlot和2个TaskManager。
![](media/image21.png){width="5.345687882764654in"