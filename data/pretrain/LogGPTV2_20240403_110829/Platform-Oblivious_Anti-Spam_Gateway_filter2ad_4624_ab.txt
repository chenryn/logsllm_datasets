involved in the spam and ham tweets, with red and blue points
denoting URL counts of the former and the latter, respectively.
Apparently, spammers tend to use more URLs than normal users
since an URL realizes redirection toward a certain malicious website.
This makes the spam tweets stand out, thus exhibiting the outlier
property. It should be noted that a disguise spammer may try to hide
its tweets’ outlier property by lowering the URL counts contained
therein, if the spammer knows the specific feature being targeted
for outlier detection. However, our solution employs a wide range
of features from both semantic and syntactic perspectives for outlier
detection and those features are not static, able to evolve over time,
as stated next.
The outlier property is evidenced by other features as well. Fig-
ure 3 shows different values of various features for spam and ham
050100150TweetsID123#ofURLsHamSpam0123456Tweetsfeatures101103105ValueHamSpam1066ACSAC ’21, December 6–10, 2021, Virtual Event, USA
Yihe Zhang, Xu Yuan, and Nian-Feng Tzeng
is recorded in Occ(s), i.e.,
Occ(s) = {k|if s ∈ Sub(Sk) for 1 ≤ k ≤ K} .
(1)
Definition 1. For any two grams s1 and s2, their equivalent
relation ≡ is defined as: s1 ≡ s2 ⇔ Occ(s1) = Occ(s2).
Let [s1]Occ and [s2]Occ denote the equivalent classes of s1 and
s2, respectively. If s1 ≡ s2, we have s1 ∈ [s2]Occ, s2 ∈ [s1]Occ, and
[s1]Occ = [s2]Occ.
Definition 2. Assume s1, s2,· · · , sn are grams in SubT and they
have the same equivalent relation to s, i.e., s1 ≡ s2 · · · ≡ sn. The
longest equivalent relation LER(s) is defined as:
LER(s) = max{|s1|w, · · · , |sn |w }, for s1, · · · , sn ∈ [s]Occ,
where | · |w denotes the length of the gram.
The rationale of counting LER comprises three key points. First,
the LER measure of a gram s takes into account all other ones that
have the equivalent relation, and that may share the same syntac-
tic/semantic patterns. Second, the higher value of LER indicates
the more unique characteristic of a gram. Third, if a message in-
cludes a commonly used syntactic/semantic pattern, it signifies
more equivalent classes.
Given the fact that a spam typically uses certain uncommon syn-
tactic and semantic patterns, we define the ALER measure, which
will be used last to filter out spam seeds. ALER of Si is calculated
by averaging over all LER measures of grams in Sub(Si), i.e.,

s∈Sub(Si)
ALER(Si) =
1
|Sub(Si)|
LER(s),
(2)
where |Sub(Si)| denotes the total number of grams in Sub(Si).
Meanwhile, the MCER measure is defined to count the number
of different equivalent classes corresponding to a message, used
last for filtering the ham seed, i.e.,
MCER(Si) = #{[s]Occ|s ∈ Sub(Si)},
(3)
where # counts the number of unique equivalent classes. To better
understand the ALER and MCER measures, we use a toy example
to show their calculation procedure, as follows:
Example 3.1 (A Toy Example). We use three messages shown in
Figure 5(a) as an example. After two-step pre-processing, i.e., word
cleaning and stemming, each message can be represented by a set of
stem words shown in Figure 5(b). Then, the N -grams of each message
can be found (see Figure 5(c)). We calculate the Occ according to
Eqn. (1) and derive the equivalent relations shown in Figure 5(d). For
each equivalent class (corresponding to each row in Figure 5(d)), we
calculate the respective LER value as shown in Figure 5(e). Specifically,
LER for the equivalent class [‘urgent’]Occ is 5, since the longest gram
in the same class (i.e., ‘urgent grandson arrest night mexico’) contains
five words. Next, we can calculate the ALERs based on Eqn. (2). That
is, in message 1, there are total 15 grams, so ALER(S1) = 1/15 ∗
(5 ∗ 15) = 5. In message 2, there are 10 grams, then ALER(S2) =
1/10 ∗ (4 ∗ 7 + 2 ∗ 3) = 3.4. In message 3, there are 6 grams, then
ALER(S3) = 1/6 ∗ (3 ∗ 3 + 2 ∗ 3) = 2.5. We then calculate MCER
based on Eqn. (3), with results shown in Figure 5(f). For example, in
message 1, there is only one unique equivalent class [‘urgent’]Occ ,
so MCER(S1) = 1. For message 2, two unique equivalent classes
[‘see’]Occ and [‘major’]Occ exist, so MCER(S2) = 2. For message 3,
Figure 4: Flowchart of our platform-oblivious spam detec-
tion system.
syntaxes and semantics for the spammy purpose, their messages are
constructed to have significant differences from the ham ones. This
inspires us to identify from the target dataset, two sets of words that
are highly likely to be used by spam and ham messages, respectively,
referring them as the spam seed and ham seed corpora. However,
deriving seed corpora is challenging, as for a given word, it is diffi-
cult to surely claim its polarity since it may have different semantic
meanings in various sentence structures. Inspired by the classical
directed acyclic word graphs language model often adopted to de-
tect unique structures of strings and substrings[30], we propose
two new methods, named as Average Longest Equivalent Relation
(ALER) and Mass Class Equivalent Relation (MCER), for calculating
the average length and the number, of different unique patterns in a
message, respectively. Our spam and ham corpora are constructed
according to ALER and MCER measures of all messages.
The initial step of our method is to pre-process the dataset in
two steps. (1) Word Cleaning: by removing auxiliary characters
and information from the dataset, such as the email address, URL
links, @ or hashtag information, etc. They are the regular format or
words that are commonly used in the social platforms but unhelpful
to mine spammers’ patterns, thus subject to removal safely. Then,
we remove the stop words that have little (or no) semantic meaning
by using the NLTK package in Python. (2) Stemming: by employing
the stemming process to further reduce inflected (or derived) words
to their stems, e.g., “take” and “took”. This step aims to use a unified
stem word to capture the corresponding spam or non-spam pattern.
With such two-step pre-processing, each message mi in a target
dataset Dt can be represented with a list of stem words, denoted
as Si = {w1, w2,· · · }. For each Si, we discover all its N -grams
(with N ranging from 1 to 10, for simplicity, knowing that the
range can vary for different datasets) and put them into the set
of Sub(Si). We express all unique grams as SubT = Sub(S1) ∪
Sub(S2),· · · , Sub(SK), where K is the number of messages. For
each gram s ∈ SubT , if s appears in Sk, the corresponding index k
Ham Seed CorpusTarget DatasetText Processing and SegmentationSpam Seed CorpusSampling Word DistributionScoring WordsReconstruct Spam and Ham CorpusEmbed Words into Vector Space via NLP ModelNeural Network ModelTrained Spam Word ModelEncoded MessagesOutlier DetectionEmbed Words into Vector Space via NLP ModelTrain Spam and Ham Model(Section 3.3)Words Corpus Collection (Section 3.1)Reconstruct Spam and Ham Corpus(Section 3.2)Outlier Detection(Section 3.4)ALERMCER1067Platform-Oblivious Anti-Spam Gateway
ACSAC ’21, December 6–10, 2021, Virtual Event, USA
(a) Original messages
(b) Two-step pre-processing
results
(c) N -grams of each message
(d) Co-occurrence of N -grams
(e) Calculating LER
(f) MCER values
Figure 5: An example of calculating ALER and MCER.
there are two unique equivalent classes of [‘life’]Occ and [‘major’]Occ ,
so MCER(S3) = 2.
We scan the spam and ham seeds that lie in the top 1% mea-
sures of ALER and MCER, respectively. More specifically, the stem
words in the messages which belong to top 1% ALER measure but
fail to appear in the messages with top 1% MCER measure, will
be considered as the spam seed. Similarly, the stem words in the
messages which belong to top 1% MCER measure but fail to appear
in the messages with top 1% ALER measure, will be used as the ham
seed. Notably, the threshold 1% is selected based on our empirical
study. We have conducted experiments on 3000 randomly selected
email messages from the Metsis email dataset [26] for verification.
Figure 6 shows the ALER and MCER measures of all messages. It
Figure 6: ALER and MCER measures of 3000 emails.
is observed that a set of spam and ham messages can be safely
singled out by setting the threshold values of 1% for ALER and
MCER, respectively. We further conduct extensive experiments (see
Section 4.5) on various datasets and vary threshold values from
0.2% to 10%. Experimental results confirms that 1% is a confident
threshold on various sized datasets in our system.
3.2 Reconstructing Words Corpora
We have roughly collected both spam seed and ham seed corpora
from the target dataset. But these two seed sets are raw and too tiny
if directly applied for spam detection. We next focus on mining in-
herent features of the roughly collected seed corpora for enhancing
spam and ham words corpora through reconstruction. We aim to
use the word distribution in the target dataset to reconstruct word
corpora, taking advantage of such inherent features for improving
our seed corpora. In the following, we give the details of sampling
word distribution and reconstructing word corpora.
Sampling Words’ Distribution. Given the spam seed corpus
3.2.1
Ss, ham seed corpus Sh, and target dataset Dt , we aim to derive
a score for each word to represent the probability of a message
classified as a spam if it contains the word. We use si ∈ [0, 1] to
denote such a score for each word i while using L to denote the
label of a message, i.e., L = 1 for a spam message and L = 0 for
a ham message. Thus, if a message mj contains the word wi, its
probability of being a spam is Pr(L(mj) = 1)) = si. Specifically,
if this score is close to 1, the message mj is more likely to be a
spam; otherwise, it is more likely to be a ham. For each word in
the spam seed or ham seed corpus, we set the spam scores to be
the constant values cs or ch, respectively, with 0.5 < cs ≤ 1 and
0 ≤ ch ≤ 0.5. For each of other words not in the seed corpora but in
the target dataset, si represents the posterior probability which will
be derived according to the distribution of a word presenting in the
final spam or ham datasets. Since the target dataset is unlabeled,
it is unrealistic to directly distinguish the spam and ham datasets
so as to calculate the words distribution (i.e., the frequency of a
word over the summation of all words’ appearance frequencies)
in each of these two datasets. The Gibbs sampling method [36]
is employed here to iteratively generate the sampling labels and
calculate the words’ distribution. We define a vector θ L with the
size of V , in which each element corresponds to one word and
its entry represents this word’s distribution in the dataset labeled
with L. The sampling values of θ0 and θ1 can be generated by the
following five steps.
Urgent your grandson was arrested last night in Mexico.I will see the major person that can guide me.You are the major person in my life.(1)(2)(3){urgent, grandson, arrest, night, mexico}{see, major, person, guide}{major, person, life}{‘see’, ‘major’, ‘person’, ‘guide’, ‘see major’, ‘major person’, ‘person guide’, ‘see major person’, ‘major person guide’,’see major person guide’}{‘major’, ‘person’, ‘life’, ‘major person’, ‘person life’, ‘major person life’}N-gramsCount15106Index(1)(2)(3){‘urgent’, ‘grandson’, ‘arrest’, ‘night’, ‘mexico’, ‘urgent grandson’, ‘grandson arrest’, ‘arrest night’, ‘hight mexico’,’urgent grandson arrest’, ‘grandson arrest night’, ‘arrest night mexico’, ‘urgent grandson arrest night’, ’grandson arrest gift mexico’, ‘urgent grandson arrest hight mexico’}{‘urgent’, ‘grandson’, ‘arrest’, ‘night’, ‘mexico’, ‘urgent grandson’, ‘grandson arrest’, ‘arrest night’, ‘hight mexico’,’urgent grandson arrest’, ‘grandson arrest night’, ‘arrest night mexico’, ‘urgent grandson arrest night’, ’grandson arrest gift mexico’, ‘urgent grandson arrest hight mexico’}{‘urgent’, ‘grandson’, ‘arrest’, ‘night’, ‘mexico’, ‘urgent grandson’, ‘grandson arrest’, ‘arrest night’, ‘hight mexico’,’urgent grandson arrest’, ‘grandson arrest night’, ‘arrest night mexico’, ‘urgent grandson arrest night’, ’grandson arrest gift mexico’, ‘urgent grandson arrest hight mexico’}N-gramsCo-occurrence Index{1}{‘see’, ‘guide’, ‘see major’, ‘person guide’, ‘see major person’, ‘major person guide’,’see major person guide’}{2}{‘life’, ‘person life’, ‘major person life’}{3}{‘major’, ‘person’, ‘major person’}{2, 3}Equivalent Class[‘urgent’]OccLongest member in the same class[‘urgent grandson arrest hight mexico’]Occ[‘see’]Occ[‘see major person guide’]Occ[‘life’]Occ[‘major person life’]Occ[‘major’]Occ[‘major person’]OccLER5423MessageUrgent your grandson was arrested last night in Mexico.Equivalent Class[‘urgent’]Occ[‘see’]Occ[‘life’]OccMCER122I will see the major person that can guide me.You are the major person in my life.[‘major’]Occ[‘major’]Occ050100150Messagecount0200400600ALERmeasure1%threshoodhamspam050Messagecount02000400060008000MCERmeasure1%threshoodhamspam1068ACSAC ’21, December 6–10, 2021, Virtual Event, USA
Yihe Zhang, Xu Yuan, and Nian-Feng Tzeng
Step 1: Label Initialization. Denote Sr as the union of spam and
ham seed corpora, i.e., Sr = Ss ∩ Sh. The probability pj of message
mj being labeled as a spam is calculated by
¯si
wi ∈Sr∩Sj
(4)
pj =
wi ∈Sr∩Sj
wi ∈Sr∩Sj(1 − ¯si) ,

¯si +

where pj is a posterior probability of Bayesian inference [17] and Sj
represents the set of stem words in message mj. Notably, for each
word wi in Sr , the spam score ¯si has been set to a constant value.
Assume each message follows Bernoulli trial and we randomly label
mj as a spam with the probability of pj. If all words from mj are not
in the seed corpora, mj is designated as a spam with the probability
of 0.5.
Step 2: Word Distribution Initialization. With the labels from
Step 1, the target dataset splits into two datasets, with one for spam
and the other one for ham. In each one, we count the total number
of included messages, denoted as C0 and C1 for ham and spam,
respectively. Meanwhile, we count the frequency of each word
occurring in each dataset and use the vector F L sized V to record
all words’ frequencies in dataset labeled as L, where each element
corresponds to one word. With F L, we can initialize θ0 and θ1.
Step 3: Updating Labels. This step repeats. In each iteration, we
select one message mj with the label of l. We count the frequency
of each word in mj and update vector F l by subtracting such a
frequency value from the corresponding term. We remove mj from
dataset at hand and update Cl by subtracting the message count by
1, i.e., Cl = Cl − 1. Before relabeling this message, we calculate the
likelihood of such a message as spam or ham, respectively, without
considering the spam/ham seed, denoted as vL(L = 1 or L = 0):
vL =
CL + βπ L
C0 + C1 + βπ 1 + βπ 0 − 1
(θL(i))σji ,
(5)
wi (cid:60)Sr ,wi ∈Sj
where βπ 1 and βπ 0 represent the initialized hyper parameters of
Beta distribution corresponding to spam and ham datasets, respec-
tively. Referred to as the shape parameters of the Beta distribution,
βπ 1 and βπ 0 are set to the uniform distribution. θL(i) represents
the respective value of wi in θL, i.e., the current distribution of
word wi in the dataset labeled as L. σji is the frequency of word
wi occurring in message mj. Since each message is assumed to
follow the Bernoulli trial [26] for designating as a spam or ham, the
probability of one message mj to be a spam is calculated as follows:

v1 ·
p =
wi ∈Sr∩Sj
v1 ·
2t√¯si + v0 ·
wi ∈Sr∩Sj
2t√¯si
wi ∈Sr∩Sj
2t(cid:112)(1 − ¯si) ,
(6)
= C¯l
where t is the number of sampling iterations. Then, we can assign
a new label ¯l to mj with the probability of p being designated as a
spam. Then, we add this message to the respective dataset according
to the new label and increase the total count of messages in this
dataset by 1, i.e., C¯l
+1. F l and θl are also updated accordingly.
This step is iteratively executed till all messages are selected.
Step 4: Updating Word Distribution Vectors. We assume all
words distribution can be modeled as the Dirichlet distribution
in both spam and ham datasets [25]. Assume there is a total of
V words in the target dataset, then the Dirichlet distribution can
be considered as the V dimensional distributions. Let’s define a V
dimensional vector tL with each entry tL(i) = FL(i) + γθL(i), where
FL(i) is the frequency value corresponding to wi in F L and γθx(i)
is a hyperparameter of word wi. Note that γθx(i) is added to the
number of observed cases to avoid 0 observation in the dataset
labeled with L, with its value set to 1 in general [36]. Then, we can
sample θ L as θ L ∼ Dirichlet(t L), where Dirichlet represents the
Dirichlet distribution. We denote ⟨yL(1), ..., yL(V)⟩ as the sample
of V words’ frequencies and draw such V independent random
samples from Gamma distribution, each with the density of
tL(i)−1
L
(i)e−yL(i)
y
Gamma(tL(i), 1) =
(7)
where Γ represents the Gamma function. The values of ⟨yx,1, ..., yx,V ⟩
can be sampled via above Gamma distribution. Each value θL(i) in
the sampling vector θ L can be calculated by
Γ(tL(i))
,
θL(i) =
V
yL(i)
j=1 yL(j) .