We now brieﬂy explain what both
samples do. GI60S is a not a malware
per se, but mostly classiﬁed as such.
Once it is installed, it sends the follow-
ing data to some server: contacts, short
messages, call history, and browser his-
tory. When ﬁnished, it will display a
code that can be entered on the GI60S
homepage which will enable the user to
see all stolen data (messages are behind a paywall). In a last step, the software removes
itself from the smartphone. In our case, 251kB of data got transferred. The name is
based on the fact that all this is done in less than 60 seconds. SC promises to speed
up the smartphone by freeing up memory. Additionally, it aims to infect a connected
PC by downloading and storing ﬁles on the SD card which are possibly run by a Win-
dows system if the smartphone is used as an external storage device. It also offers some
bot functionality and is able to gather and forward a bunch of information about the
infected device to the author. The author can also forward and delete arbitrary ﬁles,
send and receive SMS, phish for passwords, and control some device settings. More
detailed analysis reports are available on the Internet [18]. We wrote a small server for
SC and tricked it into connecting to this one and not the original one (which was already
down). This way we were able to control the bot and send commands to it in order to
measure the consumed power. We used the functionality to download several ﬁles (im-
ages, PDF and music), SMS, and contacts next to retrieving all information about the
phone. 22.46MB of data were transferred over WiFi to our server. Table 15 shows the
results of our measurements.
Application Consumption CV
Table 16. Power Consumption during the “all day long
tests”. The CV is calculated from 8 time slices during that
period lasting for 1 hour each.
Run
It can be seen that the en-
ergy consumption is similar to
our test malware with the corre-
sponding feature set. Therefore,
our malware has a reasonable
power consumption and the re-
sults should be comparable to
other software performing sim-
ilar tasks. This also means that
both samples are in 3 out of 4
cases not detectable by its power consumption as our measurements reveal—they go
down in the noise. The total power consumption is even lower than the initial one for
the SC case and is only slightly above the CV for the initial consumption for both
GI60S cases. Only the SC test in scenario B is detectable which is not astonishing, as
64.57mW 70.40%
1.24mW
87.14mW 82.86%
0.54mW
Rise Charge
40%
Total
GI60S
Total
GI60S
2nd day
1st day
1.92%
0.62%
56%
16
Johannes Hoffmann, Stephan Neumann, Thorsten Holz
we copied a lot of data from the phone which raises the energy consumption a lot in the
light usage scenario. Malware could act much less inconspicuous, but that was not our
goal in this test.
Furthermore, we tested GI60S in an “all day long test” (i.e., the phone was “used
normally” during an 8 hour period). During this time, GI60S was run once such that all
data was stolen. This test was performed twice and the results can be found in Table 16.
These show that the overall power consumption during an 8 hour period can greatly
differ. The CV for the total consumption during a day (total runtime was divided into
8 slices lasting one hour each) is huge, with over 70%. This means, the power consumed
during one hour of usage might be completely different from the last hour, depending
on the actual usage pattern. Having such a high CV, it is almost impossible to detect
anything based on a single power measurement. Even if very accurate and timely mea-
surements with small intervals are available and the smartphone reports accurate battery
levels, this would still be a tough job since the user has such a big inﬂuence and his ac-
tions are almost unpredictable resulting in a very high noise ratio. The solution proposed
by Dixon [5] might lower the CV, but it seems unlikely that it will reach a usable value.
We have not tested SC in this test since the results should be very similar.
7 Discussion
In this section, we evaluate our measurements and ﬁndings. We can boldly say that
measuring power consumption on a smartphone in general is not an easy task. There
are many parameters that inﬂuence the whole system and thus the energy demand and
ultimately the smartphone’s runtime. Let alone the fact that precise battery charge levels
are very hard to measure and depend on a lot of different factors [1,17], it is even
harder doing with software only. This fact is somehow mitigated as PowerTutor is a
very specialized tool for this task and is adjusted for the used smartphone. We therefore
deem its measurements as accurate enough for our purposes although it is not perfect.
We will now compare our results with the proposed solutions of VirusMeter [13].
The creation of power signatures would not be satisfactorily for us on a modern smart-
phone operating system: such a signature would contain the energy demands of the
application in question under certain circumstances. If an app would suddenly act in a
malicious way (e. g., stealing private information) a monitor should detect these actions
based on its power signature. In theory, this should work as all additional (malicious)
actions will use additional energy which is measurable. In practice however, accurate
measurements are hard to perform as discussed throughout this paper. This will yield
to a certain error rate which we called “noise” in the previous sections. This noise de-
scribes the varying amount of energy which is consumed more or less for the same
action(s) in the same amount of time. Even for a ﬁve minute interval, a noise ratio of
1% was measured. Despite the fact that we were able to control many settings on the
smartphone during this time span, our measurements were not 100% accurate. Since
we used a modern smartphone with a variety of features, this problems gets worse for
larger intervals as more features kick in (e. g., email fetching or synchronization). This
leads to a noise ratio of up to 2.79% for long time tests. The fact that such a monitor
should run on everyday smartphones, forces it to cope with such noise ratios.
Mobile Malware Detection Based on Energy Fingerprints — A Dead End?
17
Our measurements for the various test cases in Sections 4 and 5 show that such a
power signature would not be accurate enough, as a lot of possible malicious activities
can easily go by undetected compared to the measured amount of energy these actions
cause. If such a signature would only work with the total consumed power of the smart-
phone, it will alert the user for a lot of these actions. But, if the total consumption is
higher than the initial power consumption plus the CV value, this only means that the
action required more energy than the average noise level. Many tests lead to values
which are just a bit above this threshold which could lead to many false positives. Gen-
erating a good threshold is inherently hard, as the users’ habits may change and even
for the same user and for two consecutive days the CV is above 70% (see Table 16),
which is completely unusable. Lowering the measurement interval could decrease the
CV, but only to some extent as it heavily depends on actual user input in some cases,
see Section 9 for an example. A detailed analysis of the smartphone usage of 250 users
was conducted by Falaki et al. [9] and they also found out that even a single user can
show very varying usage patterns. If the total consumption is not considered, an attacker
could, e. g., steal an amount as high as 35MB over 3 hours without being conspicuously.
This is also true for a lot of other actions.
If one not only analyzes the energy consumption introduced by an application in
total or even on a device basis (e. g., WiFi), consumption patterns might occur. But
these patterns still suffer from the introduced noise, as the power consumption is only
interfered from a model that was previously generated (the phone does not provide
power stats of sole devices). Having some kind of pattern which states that some app
consumed x1 mW during y1 seconds in device z1 and then x2 mW during y2 seconds
in device z2 and so on, one could use that as a signature. However, searching for that
information in, e. g., the syscall trace would also be enough because it was used to
interfere these values in the ﬁrst place.
Although such power signatures cannot detect the described activities, they still can
detect some malicious ones. Amateurish written malware could be detected if too many
features are used too aggressively, e. g., determining the current position by GPS in a
very short interval. What is easily detectable is energy-greedy malware which has the
goal to disrupt the battery lifetime. But this clearly is not the normal behavior malware
exhibits—most of them steal (private) data or send premium rate SMS.
This leads us back to VirusMeter: this approach makes use of predicted user behav-
ior and their resulting energy demands. If the used energy (measured by the different
battery charge levels) does not match the assumption, then something is wrong and an
alert is generated. While the tools to measure events and power consumption clearly im-
proved compared to the possibilities the authors of VirusMeter faced, we cannot verify
their ﬁndings for a modern Android based smartphone. The noise ratio and the impact
of interfering events is too big to get good and usable results (see, e. g., Table 16). Even
if all events and measurements are logged and some sophisticated heuristic performs
the evaluation externally or on the smartphone itself if the battery is charging, malware
can still hide below the noise level.
We believe the noise level is the biggest show stopper for such a detection approach.
All other proposed tools such as eprof [15] and AppScope [19] have error rates, and
therefore noise ratios, which are too high. Using some sophisticated power model will
18
Johannes Hoffmann, Stephan Neumann, Thorsten Holz
not negate the small amount of additional energy (often below 2%, which is under the
mean error rate for most tools and settings) that is needed to perform most malicious
activities. We therefore opted to not generate our own model as it is unable to cope with
such settings.
Even if malicious activities are detected by such means, most activities would al-
ready have ﬁnished and the damage would have been committed. Otherwise, no addi-
tional power would have been consumed in order to perform any detection. This as-
sumption lets us further expect that such a system is not feasible in any satisfying man-
ner as most of the relevant cases can only be detected when it is too late. Additionally,
we believe that the false-positive and false-negative rate would be too high in practice,
even if the system does not aim to prevent but only to detect malicious activities.
8 Limitations
In order to reach the goal of this paper—namely to evaluate whether the detection of
malware running on a mobile phone is possible by measuring the power consumption
of certain activities and devices—we need precise power measurements. We believe
that PowerTutor is a good starting point on an adjusted device such as the Nexus One.
Although the measurements are not perfect, we deem them accurate enough for our
purposes. At least they are more accurate than the parameters used for VirusMeter [13].
Additionally, the mean error rate is comparable to other tools such as Appscope and
eprof. One thing PowerTutor is unable to cope with is the power consumption of ac-
tions which make use of the GSM modem, such as the short message service. We were
therefore unable to measure precise results for such activities. Another thing that is not
reported in a good manner is the power consumption of the GPS device. PowerTutor
can only report the consumption of the whole device, not the consumption of a speciﬁc
“consumer”. We therefore have to calculate an approximate value for its usage if more
than one software is using it. eprof would be better suited for such a test case, as it is
able to calculate the consumption for each app separately.
The authors of VirusMeter build a proﬁle for the user in order to detect anomalies
which we did not do. We refrained from doing so, as our measured numbers are either
too close at our thresholds (CV) or too far away. Without reasonable results for the long
time tests generating such a model is futile in our opinion regarding a low false-positive
count. The user’s activities are just too random for modern smartphones [9].
Additionally, our tests were mainly performed with one smartphone, the Nexus One.
A second phone, the Galaxy Nexus, was only used in two test cases to get a feeling of
how a monitoring software performs which does not have access to accurate results
such as provided from PowerTutor. More tested devices would of course be favorable,
but the Nexus One is the only device which is supported by PowerTutor and is still
modern enough to actually perform meaningful tests with it. In fact, AppScope also
only supports this phone. Furthermore, the results are not encouraging at all.
We tried to be as precise as possible during our tests. But since these tests were
all performed by hand, there are certainly slight variations for each result. Automatic
testing was not possible, so all the performed tests took a lot of time and patience.
Mobile Malware Detection Based on Energy Fingerprints — A Dead End?
19
9 Conclusion
Our results indicate that software-based approaches to measure the power consumption
of an Android smartphone and to interfere from these results whether additional ma-
licious activities occurred, is not satisfactory in most cases. The approach mainly fails
due to the noise introduced into the system by unpredictable user and environment inter-
actions, such as the reception rate or the delivered content of accessed websites. While
a more precise power model could mitigate effects such as varying reception rates, it
cannot calculate out the effects of many user interactions, e. g., browser usage. This is
at least true for our long time test results, which do not have optimal but comparatively
real world settings. The short time tests indicate that some activities can be detected by
such a system, but under settings seldom found on a smartphone that is regularly used.
We even go one step further and think that such a system is not feasible at all on
a modern smartphone—at least with available measurement methods and normal use
cases. Let alone the fact that the hardware parts have to provide very accurate values of
consumed energy, the system still needs a very precise model of what the user usually
does and how much energy these actions typically consume. We assume that such an
anomaly detection would generate a lot of false positives, as normal users change their
behavior quite often, depending on the actually installed apps and so on. Even if a
precise proﬁle would exist and the user would not change his habits too often, apps can
be very dynamic in a way that a power proﬁle for these apps cannot be precise at all.
Just imagine what the browser is capable of (e. g., complete Ofﬁce suites are offered as
a web application) and try to generate a power signature for its behavior.
We conclude that well written malicious software running on a modern smartphone
can hardly be detected by means of additionally consumed energy as the noise ratio is
too high. Only DoS attacks against the battery runtime and so called “energy bugs” [11]
as well as certain activities performed under strictly given scenarios can be detected,
which is not enough to be of great use for normal smartphone usage patterns.
As a last point we note that modern smartphones with modern operating systems
such as Android are more or less a general purpose computer with a very small form
factor. If such proposed systems would be usable as a malware detector, they should
also work on regular notebooks or PCs. To the best of our knowledge, no such system
was ever used for this purpose. We therefore deem energy based approaches for malware
detection as a dead end—at least for modern smartphones without extended capabilities
to account for used energy.
Acknowledgments This work has been supported by the German Federal Ministry of
Education and Research (BMBF grant 01BY1020 – MobWorm).
References
1. Battery Performance Characteristics. http://www.mpoweruk.com/performance.htm.
2. N. Balasubramanian, A. Balasubramanian, and A. Venkataramani. Energy Consumption
In
in Mobile Phones: A Measurement Study and Implications for Network Applications.
Internet Measurement Conference (IMC), 2009.
3. Christy Pettey and Rob van der Meulen. Gartner Says Worldwide Sales of Mobile Phones
Declined 3 Percent in Third Quarter of 2012; Smartphone Sales Increased 47 Percent.
http://www.gartner.com/newsroom/id/2237315.
20
Johannes Hoffmann, Stephan Neumann, Thorsten Holz
4. D. Maslennikov and Y. Namestnikov. Kaspersky Security Bulletin. The overall statistics for
2012. www.securelist.com/en/analysis/204792255/Kaspersky Security Bulletin 2012 The
overall statistics for 2012.
5. B. Dixon, Y. Jiang, A. Jaiantilal, and S. Mishra. Location based power analysis to detect
malicious code in smartphones. In ACM Workshop on Security and Privacy in Smartphones
and Mobile Devices, SPSM, 2011.
6. M. Dong and L. Zhong. Self-Constructive High-Rate System Energy Modeling for Battery-
In International Conference on Mobile Systems, Applications,
Powered Mobile Systems.
and Services, MobiSys, 2011.
7. M. Egele, C. Kruegel, E. Kirda, and G. Vigna. PiOS: Detecting Privacy Leaks in iOS Appli-
cations. In Network and Distributed System Security Symposium (NDSS), 2011.
8. W. Enck, P. Gilbert, B.-G. Chun, L. P. Cox, J. Jung, P. McDaniel, and A. N. Sheth. Taintdroid:
An information-ﬂow tracking system for realtime privacy monitoring on smartphones. In
USENIX Symposium on Operating Systems Design and Implementation, OSDI, 2010.
9. H. Falaki, R. Mahajan, S. Kandula, D. Lymberopoulos, R. Govindan, and D. Estrin. Diversity
In International Conference on Mobile Systems, Applications and
in smartphone usage.
Services, MobiSys, 2010.
10. M. Grace, Y. Zhou, Q. Zhang, S. Zou, and X. Jiang. RiskRanker: Scalable and Accurate
Zero-day Android Malware Detection. In International Conference on Mobile Systems, Ap-
plications, and Services, MobiSys, 2012.
11. A. Jindal, A. Pathak, Y. C. Hu, and S. P. Midkiff. Hypnos: Understanding and Treating Sleep
Conﬂicts in Smartphones. In EuroSys, pages 253–266, 2013.
12. H. Kim, J. Smith, and K. G. Shin. Detecting Energy-Greedy Anomalies and Mobile Mal-
ware Variants. In International Conference on Mobile Systems, Applications and Services,
MobiSys, 2008.
13. L. Liu, G. Yan, X. Zhang, and S. Chen. VirusMeter: Preventing Your Cellphone from Spies.
In International Symposium on Recent Advances in Intrusion Detection, RAID, 2009.
14. S. Park, A. Savvides, and M. Srivastava. Battery Capacity Measurement And Analysis Using
In International Symposium on Low Power Electronics and
Lithium Coin Cell Battery.
Design, ISLPED, 2001.
15. A. Pathak, Y. C. Hu, and M. Zhang. Where is the energy spent inside my app? Fine Grained
Energy Accounting on Smartphones with Eprof. In ACM European Conference on Computer
Systems, EuroSys, 2012.
16. A. Pathak, Y. C. Hu, M. Zhang, P. Bahl, and Y.-M. Wang. Fine-Grained Power Modeling
for Smartphones Using System Call Tracing. In ACM European Conference on Computer
Systems, EuroSys, 2011.
17. R. Rao, S. Vrudhula, and D. Rakhmatov. Battery modeling for energy aware system design.
Computer, 36(12):77–87, Dec. 2003.
18. Victor Chebyshev. Mobile attacks! http://www.securelist.com/en/blog/805/Mobile attacks.
19. C. Yoon, D. Kim, W. Jung, C. Kang, and H. Cha. AppScope: Application Energy Metering
Framework for Android Smartphones Using Kernel Activity Monitoring. In USENIX Annual
Technical Conference, ATC, 2012.
20. L. Zhang, B. Tiwana, Z. Qian, Z. Wang, R. P. Dick, Z. M. Mao, and L. Yang. Accurate
online power estimation and automatic battery behavior based power model generation for
smartphones. In Conference on Hardware/Software Codesign and System Synthesis, 2010.
In
21. Y. Zhou and X. Jiang. Dissecting Android Malware: Characterization and Evolution.
IEEE Symposium on Security and Privacy, 2012.
22. Y. Zhou, Z. Wang, W. Zhou, and X. Jiang. Hey, You, Get Off of My Market: Detecting
Malicious Apps in Ofﬁcial and Alternative Android Markets. In Network and Distributed
System Security Symposium (NDSS), 2012.