back to a legitimate system call in the text segment. The
masked mimicry attack we develop will not be detected by
the FSA implementation. VtPath, however, will still be able
to detect both the original and the masked mimicry attack.
We plan to describe our improvements of mimicry attacks
to evade IDS in a separate paper.
In Section 5.2.3 and Section 5.2.4, we will present our
critique of the attacks 1 and 2 we implemented and consider
some general ideas behind the possible attacks against the
detection models discussed in this paper.
5.2.1 Attack 1
As mentioned earlier, due to the lack of precision of many
program execution models, it may be possible for an at-
tacker to jump a security-critical section of a program code
without being detected by IDS. We refer to the class of at-
tacks that exploits this vulnerability as impossible path ex-
ploits (IPEs). The attack 1 we implement belongs to the IPE
class. To the best of our knowledge, this is the ﬁrst working
implementation of the IPE attack.
Attack description. The attack works as follows. Con-
sider login user() function, shown in Figure 4. There are
two possible execution paths in this function because of the
If is regular(user) returns true, path num-
if() statement.
ber one is followed. Otherwise, path number two is fol-
lowed. Suppose the function read next cmd() called at (I)
contains an overﬂow at the strcpy() statement. Then, an at-
tacker can substitute the return address of the function so
that the read next cmd() returns to (II), the address where
the other read next cmd() would otherwise return.
void   read_next_cmd(){
   uchar input_buf[64];
   umask(2);                   // sys_umask()
   ...
   // copy a command
   strcpy( &input_buf[0], getenv( "USERCMD" ));
   printf( "\n" );              // sys_write()
}
void login_user(int user){
   if( is_regular(user)){
      // unprivileged mode
      read_next_cmd();  // (I), this function will
                                      // be overflowed
      ...
      // handle commands allowed to a regular user
      return;
   }
   // privileged mode
   read_next_cmd();     // (II), this function call
                                      // will be skipped
   // −−> this is where the control will be
   // transferred after a ret in read_next_cmd() at (I)
   seteuid(0);
   system( "rsync /etc/master.passwd PI:EMAIL:/ipe" );
   // and other privileged commands accessible only to
   // superuser
}
Figure 4. Pseudo code for attack 1
None of the existing models except VtPath will be
able to differentiate between the sys write() called when
read next cmd() at (I) is called and the sys write() called
when read next cmd() at (II) is called. Consequently, be-
cause of imprecision of the models, including the ones for
N-gram, abstract stack, callgraph, and FSA, after the jump
an IDS would not detect an anomaly. The IDS would think
the program has followed a legitimate execution path num-
ber two.
VtPath can detect the attack since in addition to veri-
fying program counters and state transitions, it also sees
stack context for both invocations of read next cmd().
More speciﬁcally, it can see an invalid virtual path from
sys umask() to sys write() in read next cmd() at (I), as the
return address of read next cmd() is changed by the over-
ﬂow in strcpy().
5.2.2 Attack 2
Attack description. This attack works as follows.
f(),
shown in Figure 5, is called from main() twice for the fol-
lowing two operations - checking a user name and checking
a password. f() selects which operation to perform based on
its parameter. The parameter is saved in a variable, mode.
The variable is modiﬁed by an attacker when the adjacent
local buffer, input, is overﬂowed. The local buffer is over-
ﬂowed with a valid username and trailing zeros so that when
f(1) is called, the value of mode is changed to zero. Under
attack, instead of checking a user name and then checking
a password, f() checks a user name twice. As a result, an
attacker obtains access without knowing a password.
This attack will be detected by VtPath because it will see
an invalid path between the sys close() when f(1) is called
and the following sys write() in main(). N-gram, abstract
stack and callgraph models will not be able to detect the
attack because both branches in f() have the same system
calls and the system call sequence stays unchanged during
the attack. FSA will miss the attack because the transition
from sys close() to sys write() is a valid FSA transition.
5.2.3 Observations
Based on the two attacks we described above, we can make
the following general observations. First, both attacks re-
quire a way to change the control ﬂow of a program. For
our sample attacks we use buffer overﬂows. We realize that
buffer overﬂows are not always possible and will eventu-
ally become a less signiﬁcant threat. However, we believe
our choice is justiﬁed given that over two-third of CERT’s
advisories in recent years were buffer overﬂows [15].
Second, programs that are vulnerable need to have a spe-
ciﬁc structure allowing, for example, a critical section to
be jumped. In attacks described above, we show two ex-
amples of the possible program structures that can be ex-
ploited, namely a security-critical if() or a function whose
argument controls execution and can be overﬂowed. For
the IPE in Attack 1, it is also necessary that there be a func-
tion that is called from more than one point in a program.
Proceedings of the 2003 IEEE Symposium on Security and Privacy (SP(cid:146)03) 
1081-6011/03 $17.00 ' 2003 IEEE 
f(int arg){
   int  mode = arg;              // this variable is overflowed
   char input[10];
   fopen();                          // sys_open(), open passwd file
   // overflow, changes ’mode’ variable => execution flow
   scanf("%s", &input[0] );
   if( mode == CHECK_UNAME ){ // check username?
    fread();                         // sys_read(), read from passwd file
    fclose();                       // sys_close()
    if( is_valid_user(input) ) ret = 1; else ret = 0;
   }
   else if( mode == CHECK_PASSWD ){ // check password?
    fread();                        // sys_read(), read from passwd file
    fclose();                      // sys_close()
    if( is_valid_pass(input) ) ret = 1; else ret = 0;
   }
   return ret;
}
void main(){
   printf( prompt );          // sys_write()
   ret=f(0);                      // (I), read/check username
   if( ret ) ret = f(1);       // (II), read/check password
                                        // if username was correct
   printf( "Authenticated\n" ); // sys_write()
   if( ret )
    execve( "/bin/sh" );            // superuser mode
}
f(){
 ...
 // read in some large string z, syscalls are fine here
 f0();
 // important: f1() has no system calls
 // it copies z to x, z is larger than x, so x is overflowed;
 // after the ret instruction, the overflow code can
 // jump anywhere within f(), as long as it is between
 // f1() and the next system call;
 // for example, the code can jump to IP1
 f1();
 if( cond ){
   // regular user privileges
   ...
   return;
 }
...
 IP1:
 // superuser privileges
 execve( "/bin/sh" );
}
Figure 5. Pseudo code for attack 2
Figure 6. Pseudo code for granularity attack
When the control ﬂow of a vulnerable program is changed
as in Attack 1, the function is exploited and a jump occurs.
5.2.4 Generalizations
The attacks we describe here have a common property in
that they take advantage of the inherent limitations, or the
insufﬁcient level of granularity, of the IDS model. The in-
formation (or audit data) as well as the modeling algorithm
used by an IDS model can be inadequate in a such a way that
some attacks do not manifest as anomalies. For instance,
attackers can exploit the fact that many anomaly-based IDS
only check their program behavior models at a time of a
system call [16, 17, 8]. Consider the example in Figure 6.
This attack will not be detected by any of the approaches
we described so far. VtPath will also be unable to detect the
attack unless the IP1 is somewhere else in the program at a
different level of nestedness so that there is an anomaly in
the stack contents that can be detected.
As [10, 9] proposed and [17] pointed out, it is important
that the intended behavior of a program is taken into account
in a model. If a program comes with a complete speciﬁ-
cation of its intended behavior, any attack that causes the
program to behave differently or violating the speciﬁcation
can be detected, provided that an IDS can check the pro-
gram behavior against the speciﬁcation precisely. For our
purposes, such an IDS will be considered to have a maxi-
mal level of granularity because it can detect all attacks that
cause the program to deviate from its intended behavior. In
most cases, an IDS has an inadequate level of granularity
and thus there are always attacks on the program that can
evade detection.
5.2.5
Importance of IPEs
We recognize that a successful execution of the attacks we
described above is contingent upon quite a few variables
and may not always be possible. It can be tempting to dis-
miss the problem of IPEs altogether as having little rele-
vance since ﬁnding an existing piece of code that is ex-
ploitable may not be easy. Besides, as with many other
attacks, the attacker is constrained by the need to perform
reconnaissance and to have access to the details of the envi-
ronment on the attacked host, particularly the IDS and other
protection tools used.
We must point out, however, that instead of looking
for vulnerable code, attackers can introduce IPE-vulnerable
code into open source products in the form of innocent im-
provements or legitimate bug ﬁxes. In contrast to other se-
curity ﬂaws that attackers may attempt to inject, changes
Proceedings of the 2003 IEEE Symposium on Security and Privacy (SP(cid:146)03) 
1081-6011/03 $17.00 ' 2003 IEEE 
needed for IPEs can be made very subtle, which makes them
less likely to be detected by code inspection. One of the rea-
sons is that it is typically the structure of the code that makes
it vulnerable to IPE, not the actual commands. Furthermore,
it seems natural to assume that attackers will do everything
in their power to disguise the IPE-vulnerable code. This can
be done, for example, by gradually shaping the structure of
a program code over series of patches.
6 A Comparison of System Call Based
Anomaly Detection Approaches
In this section, we compare several anomaly detection
methods based on their underlying principles. These meth-
ods include N-gram, FSA, VtPath, callgraph, abstract stack,
and the method Wespi et al. proposed [20] (We call it Var-
gram because it uses variable length N-gram patterns). The
principles of the methods proposed in [7] are the same as
those of callgraph and abstract stack; thus, our analysis on
callgraph and abstract stack can also be applied to these
methods. Our comparison is based on the algorithmic ap-
proaches of the models as well as the types of information
they use. We analyze their performance characteristics in
terms of false positives, detection capability, space require-
ment, convergence time, and runtime overhead.
We also realize that the performance of the methods can
vary a lot due to their implementation details, such as is-
sues regarding signals, DLLs and system call parameters.
For example, some detection approaches are equipped with
mechanisms to predict static system call parameter values.
These mechanisms can also be applied to other detection
approaches with appropriate modiﬁcation, either through
static analysis or dynamic monitoring. We can also develop
appropriate mechanisms regarding other implementation is-
sues for each approach. In this section, we ignore all the
implementation issues, and focus on the underlying princi-
ples.
State based approach and information captured. We
can model the execution of a program using a state diagram.
At the start of the program, the system is in the start state.
At each event occurrence, the system transits from one state
to another. At any point, it is in a valid state if and only if
the start state was valid and all the intermediate transitions
were also valid. Consider an instantiation of the monitored
program. To capture the normal behavior, the model tries to
capture the valid states and valid state transitions by moni-
toring the behavior of the program at different event points.
The model should also ignore the variables that are speciﬁc
to that particular run of the program. It tries to learn the be-
havior of program by generalizing the observed instances of
the program. However, it is not feasible to monitor the pro-
gram at every event. For the approaches we study here, the
states of the system are recorded only at the point of system
calls. The decision to monitor only at system calls is justi-
ﬁable because many attacks can manifest at the system call
level.
Possible variables which could be considered while
deﬁning the states of the system include “contents of data
heap”, “registers”, “code segment”, “program stack”, “sys-
tem call and its arguments” and other system variables. The
objective of a model is to record only the relevant state vari-
ables. Using the state transition diagram of each run during
the training period, we would like to build a generalized
state transition diagram which represents the normal behav-
ior of the program. Data heap and register values are highly
speciﬁc to that particular run of the program and do not gen-
eralize well, so we can ignore them. Code segment might be
useful in some cases. System calls and their arguments are
certainly useful. Although some arguments of some system
calls are worth recording, many arguments can have many
possible values, resulting in a model with slow convergence
and high overhead. Call stack is important for learning the
ﬂow of program. In general, using more information to de-