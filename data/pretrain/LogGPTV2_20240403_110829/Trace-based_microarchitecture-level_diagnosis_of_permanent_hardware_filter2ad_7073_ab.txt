and compares it to the chosen strategy. Figure 1 shows
an overview of TBFD.
3.1. Identifying Permanent Faults
When a symptom is detected in a core, the diagnosis
firmware rolls the core back to the previous checkpoint and
replays the execution. If the symptom does not recur, it is
diagnosed as a transient. If the symptom occurs again, the
diagnosis firmware loads the checkpoint onto another fault(cid:173)
free core and replays the execution. If the symptom does
1-4244-2398-9/08/$20.00 ©2008 IEEE
24
DSN 2008: Li et al.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 13:17:28 UTC from IEEE Xplore.  Restrictions apply. 
International Conference on Dependable Systems & Networks: Anchorage, Alaska, June 24-27 2008
3.4. Analysis of the Test Trace
The heart of the TBFD algorithm is the analysis of the
generated test trace to to diagnose the fault. This analysis
can be perfonned after completing building of the test
trace. Alternatively,
it may be periodically invoked after
generating every N instructions of the test trace. The latter
strategy may be more efficient if memory space to store
the trace is at a premium. It also allows tenninating test
trace generation as soon as the diagnosis is able to uniquely
identify the faulty structure.
TBFD divides the processor core into three different
parts, on the basis of the infonnation and analysis required
to diagnose a fault in these parts:
1) Front-End: A fault
in this part of the processor
affects which instruction is executed, which operation
is executed, and the logical source and destination
registers accessed.
2) Meta-Datapath: Modem out-of-order processors use
register renaming to translate logical register names
to physical registers. Even if the front-end supplies
the correct logical names, a fault
in the translated
name can result in erroneous computation. This type
of fault is the largest source of complexity in TBFD
- as we will show later, a corruption in the physical
register name may not be caught by analyzing only
the mismatched instructions. We use the tenn meta(cid:173)
datapath to refer to the parts of the core where a fault
can corrupt the physical register name.
3) Datapath: This is the conventional data path, includ(cid:173)
ing the functional units, buses, and data residing in
the physical register files.
In our work, we inject faults in the following structures
as representatives of each of the above categories (see
Table 2): Front-end: Instruction decoders. Meta-datapath:
Register alias table (RAT) entries; source and destination
(physical) register identifier fields in the reorder buffer
(ROB).2 Datapath: ALU, address generation unit, register
data bus, and integer physical registers.
The analysis described below assumes faults in only the
above structures, but can be extended to others as well. 3
The analysis algorithm proceeds by using misbehaved
instructions in the test trace as the starting point of the
diagnosis. On encountering a misbehaved instruction in the
trace, the algorithm systematically analyzes the misbehav(cid:173)
ior and detennines if it can conclusively identify a fault in a
unique structure. If so, it successfully tenninates; otherwise,
it updates counters corresponding to the microarchitectural
resources used by the misbehaved instruction in the test
trace. It then moves on to analyzing the next misbehaved
2. In a real implementation, source register identifier fields would be
in the issue queue; however, our simulator models them in the ROB and
our algorithm uses the same terminology.
3. The algorithm assumes Intel Pentium 4 style register renaming with
a distinct retirement register alias table or RRAT.
instruction. If at any stage, one of the resource counters
reaches a value higher than any other counters, the algo(cid:173)
rithm declares that resource as faulty and tenninates. If the
end of the trace is reached, then the algorithm identifies
the resources with the highest value counters as suspected
faulty units - in this case, it is not able to uniquely identify
a faulty resource.
Next we describe how TBFD systematically analyzes the
misbehaved instructions to track down faults to the three
targeted areas in the processor.
3.4.1. Faults in Front-End. If the misbehaved instruction
is a mismatched instruction (i.e., not hung), TBFD first
suspects a front-end fault. (As will be seen later, a hung
instruction can only arise from a meta-datapath fault.) For
this,
it simply needs to check if the test trace indicates
that the mismatch occurred in the decode infonnation (cid:173)
such a mismatch indicates that the instruction word was
corrupted at the front-end. For example, when the faulty
instruction uses rl as source operand but
the fault-free
instruction uses r3 as source operand, a fault is suspected in
the front-end. Consequently, counters of the front-end units
used in the faulty execution are incremented. In this study,
since only decoders are accounted for in the front-end, the
first mismatch in the instruction word makes the decoder
used by the mismatching instruction identified as the unique
faulty unit and successfully tenninates the algorithm.
3.4.2. Faults in Meta-Datapath. If either the misbehaved
instruction was hung or if it was a mismatched instruction
and no front-end fault was identified, then TBFD analyzes
the misbehavior to check for meta-datapath faults.
the first
instruction that
This class of faults requires the most sophisticated anal(cid:173)
ysis method. This is because, unlike the front-end and
is affected by such a
datapath,
fault may not appear as a misbehaved instruction;
i.e.,
the fields in the faulty trace that are
it may not affect
compared with the fault-free execution. Instead,
it may
silently corrupt processor architectural state, causing later
unrelated instructions to misbehave and obscuring the real
source of the fault.
in Figure 2,
For example,
I a writes to r3 which is
mapped to physical register P23 and Ie reads from T3. I b
writes to rl but is incorrectly mapped to P23 because of
a meta-datapath fault (e.g., the register alias table had the
wrong mapping). Thus, when I b executes, T3 is corrupted
with the value of rl; however, this is not indicated in any
way in the infonnation recorded for I b in the test trace.
Now when Ie retires,
it sees the wrong value. This is
caught when the faulty trace is compared with the fault-free
execution and Ie is marked as a mismatched instruction.
Now if TBFD were to blindly attribute this mismatch to
the datapath structures used by Ie, the actual meta-datapath
fault will never be identified.
In this study, TBFD focuses on meta-datapath faults in
1-4244-2398-9/08/$20.00 ©2008 IEEE
25
DSN 2008: Li et al.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 13:17:28 UTC from IEEE Xplore.  Restrictions apply. 
International Conference on Dependable Systems & Networks: Anchorage, Alaska, June 24-27 2008
2. Find producer of r3
RRAT
log phy
r1
P1S
r3
P23
rS P10
RRAT
log phy
r1
P23
r3
P23
rS P10
la: r3~ r2+r2
Ib : r1~rS+r6
I
I
~
3. Find next writer of P23
4. Detect P23 mapped to r1while live!
RRAT
log phy
r1
P23
r3
P23
rS PSS
Ie: rS~r3-r2
.
;--tnRetIred
InstructIOns
1. Mismatch!
Figure 2. An example scenario depicting how a physical
register that is mapped to more than one logical register is
identified by TBFD.
the ROB and RAT entries. In particular, TBFD checks
the integrity of the logical-physical register mappings of
the misbehaved instruction based on the following two
conditions of fault-free executions.
1) A non-free physical register can be mapped to at most
one logical register at any time.
2) If an instruction reads from physical register Px that
is mapped to logical register 7"y, the last instruction
that writes to logical register 7" y (the producer) must
have written to physical register Px.
If a fault occurs in the meta-datapath, one or both of the
above conditions may not hold. The first condition above
handles the case discussed in Figure 2, where instruction Ie
is detected as a mismatching instruction (step 1). To check
if condition 2 is violated, TBFD searches backward in the
test-trace to check the integrity of the mappings of Ie's
registers. Thus, it finds register 7"3 's producer, instruction
la, that maps 7"3 to physical register P23 (step 2). To verify
that condition 1 holds, TBFD searches forward from I a for
the next writer to P23 and finds that I b maps 7"1 to P23 (step
3) while it is still mapped to 7"3 (step 4) and condition 1 is
violated. Consequently, TBFD increases the counters of the
RAT entries for both 7"1 and 7"3 since it does not know where
the fault
is located. Nonetheless, with more misbehaved
instructions, the faulty RAT entry can be identified.
Condition 2 is usually violated by a ROB fault. To check
if condition 2 holds, TBFD goes backwards in the test-trace
from the misbehaved instruction to the producing instruc(cid:173)
tion and verifies its logical to physical register mappings.
For example, a fault in the destination register number field
causes instruction I A to write to a different physical register
than indicated in the RAT. Then, a dependent instruction
I B reads the mapping from the RAT and waits indefinitely
for a physical register that will never be set ready by I A. As
a result, I B becomes a hung instruction. TBFD then starts
tracing from I B to find that condition 2 is violated. As a
result, TBFD increments the counter of the ROB entries of
both I A and lB. With more misbehaved instructions, the
faulty ROB entry can be uniquely identified.
However, even with techniques described above, RAT
faults that are exercised by speculative instructions can be
hard to diagnose down to the individual RAT entries. The
scenario described below illustrates the difficulty. Consider
that a logical register 7"1 is mapped to a physical register
Pl. Suppose an instruction I that writes to logical register
7"2 enters the rename stage. Because of a fault
in the
RAT entry, 7"2 gets mapped to the already live physical
I executes, writes to PI, and wipes
register Pl. Then,
out 7"1 's data. Later on, I
is squashed as a result of an
exception or a branch mis-prediction, causing PI to be freed
and added to the free list (even though it is supposed to
be live and mapped to 7"1). Subsequently, when another
logical register is mapped to PI and written by another
instruction that retires and becomes architecturally visible,
7"1 now shows a corruption in the architectural state as
its value is now incorrect. However, since TBFD never
looks at the intervening speculative instruction I (remember
that TBFD only tracks retiring instructions),
the faulty
RAT entry is not correctly identified. Nevertheless, with
more misbehaved instructions diagnosed, TBFD is able to
identify the existence of RAT faults.
3.4.3. Faults in Datapath. After TBFD determines that
a mismatched instruction is unlikely to have been caused
by a fault
in the front-end or the meta-datapath, a fault
in the datapath is suspected. At this point, the microarchi(cid:173)
tectural structures (the functional unit, the result bus, and
the destination physical register) on the datapath that are
used by the misbehaved instruction are deemed potentially
the counters of these structures are
faulty. As a result,
incremented. With more misbehaved instructions analyzed,
the faulty module is likely to be the most frequently used
with the highest counter value among all structures and
thus can be identified.
3.5. Implementation
The TBFD algorithm is implemented in firmware. The
detection of a fault on a core must result in an interrupt on
another core (possibly through a protected channel) where
the control transfers to the diagnosis firmware on that core.
A single-core fault model implies that the latter core is
fault-free; otherwise, the system must provide a protected,
possibly simpler, fault-free core to invoke for diagnosis
and recovery. (Analogous support
is likely required for
multicore systems that aim to provide continuous operation
in the presence of a non-repairable fault in a core.)
Additionally, the system must support checkpoint gen(cid:173)
eration for the faulty core and checkpoint migration to a
fault-free core. Several techniques have been proposed for
checkpointing for the purpose of recovery from hardware
failures [13], [17], and can be used for TBFD as well.
For example, the SafetyNet scheme [17] could be used,
with the checkpointed state made accessible to firmware
on other cores.
The most significant hardware support
required for
TBFD pertains to the generation of the test-trace. For
1-4244-2398-9/08/$20.00 ©2008 IEEE
26
DSN 2008: Li et al.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 13:17:28 UTC from IEEE Xplore.  Restrictions apply. 
International Conference on Dependable Systems & Networks: Anchorage, Alaska, June 24-27 2008
RAT
Register File
Instruction Trace
11 : Add r1 f- r2 + r3
12 : Mul r4 f- r1 + r3
13 : St Mem[r2l f- r4
Instruction Trace Buffer (ITB)
P47 600
Decode information I
t J,Jarch resource info
Data values
°P
Add
Mul
St
s
r2
r1
r2
t
r3
r3
r4
d
r1
r4
Ps
P20