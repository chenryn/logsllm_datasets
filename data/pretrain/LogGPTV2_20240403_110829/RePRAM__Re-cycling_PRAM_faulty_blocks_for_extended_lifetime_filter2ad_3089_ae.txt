bits along with addi­
replacement 
processors 
pointers. 
into the 
existing 
In this subsection, 
we present 
further 
analysis 
our RePRAM schemes behave under various 
possible configurati
key insights 
for choosing 
the RePRAM system. 
ons. We show that such analyses 
to the user along with experimental 
user-desirable 
set of parameters 
justification 
toward building 
to show how 
and 
parameters 
present 
1) Lifetime vs. Redundancy Levels: 
In Dim-2, PDR is 
the lifetime 
An advantage 
of PCM device. 
used throughout 
of using just PDR is that every PCM block incurs only 
the write  operations  directly  intended 
for them, i.e., the 
use of PDR configuration 
does not impose  additional 
itself 
writes to  the PCM blocks. However, in Dim-I, we  switch 
to MDR beyond a specific 
accelerate  the 
duplicates 
write ages two separate 
diminishing  capacity 
to investigate 
the PCM block. 
the writes to two different 
PCM blocks, 
of the PCM device. 
every 
PCM blocks, 
contributing 
to the 
Therefore, 
we seek 
of 
when to switch to MDR during the lifetime 
point in time and this may likely 
Since mirroring 
of PCM blocks. 
wear-out 
10 
o 
o 
10 
on  9 
c 
 8 el 
. 7 E 6 
   5 
o   4 
III   3 
:E ::l 2 
III ::E 1 
o 
10 
on  9 
c 
 8 el 
. 7 E 6 
   5 
o   4 
III   3 
:E ::l 2 
III ::E 1 
o 
I 
      U  M  M    M  U 
Normalized block lifetime 
(a) variance=O.l 
I I I 
I 
I 
      U  M  M    M  U 
Normalized block lifetime 
(b) variance=O.2 
I I 
J J J J J I 
J 
      U  M  M    M  U 
Normalized block lifetime 
(c) variance=O.3 
Figure 7. Frequency 
block's 
lifetime. 
of invocation 
of matching 
algorithm 
through 
PRAM 
Figure 5 presents 
comparison 
of lifetime 
for various 
number 
shown in each configuration, 
of Dim-I .  In each case, we begin with PDR 
we cross a "specific 
we switch to MDR 
configurations 
with group size of 3.  After 
of faults" 
where data is mirrored 
to note that, as we  begin  to 
higher number of faults, the cost associated with three-way 
mapping increases 
For example, 
the average number of random trials 
way matching 
a three­
for PCM blocks with up  to 80 faults is 
onto two PCM blocks.  It is important 
sharply (Section ill-A). 
in PDR mode with 
to complete 
operate 
for up  to 60 faults and 
is 2.1 % ;  whereas, 
to do three-way  matching  for  PCM 
compared to the 
matching 
improvement 
one more than three-way 
the corresponding 
lifetime 
the number of trials 
blocks with up to 1 40 faults is ten-fold 
blocks with up  to 60 faults 
improvement 
there are diminishing 
if we try to remain  longer 
group sizes. 
returns 
is 5 .2%. Our experiments  clearly  show 
and the corresponding 
that 
lifetime 
in PCM lifetime 
under PDR with higher order 
improvement 
impact in 
smaller 
2) Sensitivity 
of PDR to DRAM Buffer Size: A factor that 
to minimizing 
the performance 
the overall 
(compared 
to determine 
performance 
to PCM main memory) 
in our benchmarks. Due to smaller 
this effect, we present additional 
the size of DRAM buffers needed 
ratio 
Figure 6 shows the overheads 
with 3 different 
the parity 
PCM data pages, we find that relatively 
could be critical 
PDR is the size of DRAM buffer (that we use for parity 
lookup). To investigate 
experiments 
for storing 
of parity to 
DRAM buffer  sizes 
work very well toward minimizing 
experienced 
by PDR 
impact. 
when we experiment 
DRAM buffer sizes, 
viz., 4MB, 1 6MB and 32MB. Our results  show 
is sufficient 
7%  (average 
high performance 
and xalancbrnk benchmarks. A 32MB DRAM buffer shows 
negligible 
almost every benchmark,  indicating 
(above 1 6MB) is no  longer 
compulsory 
that  the  amount 
overheads 
performance 
of DRAM buffer needed to maintain 
low 
is 
case), while the 4MB DRAM buffer incurs 
that DRAM capacity 
beyond the initial 
benefit over 1 6MB for performance 
of up to 23% in libquantum 
that 1 6MB 
at less than 
across the three benchmark 
to keep the performance 
misses to parity informati
on. This result 
a bottleneck 
overheads 
overheads 
overheads 
suites 
shows 
in 
just 26 th of the capacity 
invested 
in PCM main memory. 
Furthermore, 
16% overheads 
this 1 6MB DRAM buffer has shown less than 
even for the stress  case  (seen 
in Figure 4(b)). 
3) Frequency of Matching Algorithm 
Invocations: 
we perform the 
To 
lifetime
factors 
the results 
algorithm 
for process 
to quantify 
the matching 
Now that the 
as normalized 
the average number of times that 
needs to be invoked during a PRAM 
the OS and software overhead, 
Figure 7 presents 
of 0.1 ,  0.2 and 0.3. In this test, we count 
), that 
a PRAM block, before the block 
understand 
experiments 
matching 
block's lifetime. 
variation 
the number of writes (presented 
has been performed  to 
encounters 
the first bit fault. 
pristine, 
of compatible 
this block and its group pages, they incur more bit faults, 
and eventually 
same byte positions. 
algorithm 
needs to be invoked again to find a new set of compatible 
pages for this faulty PCM block. We repeat this matching 
process 
160 bit faults 
(when  we 
we can see that matching 
clustered 
are often 
towards the end of PRAM block's lifetime 
the block permanent
algorithm 
until the PRAM block has exceeded 
At this point, the matching 
become incompatible 
blocks. As additional 
is invoked to find a group 
due to faults in  the 
block is no longer 
invocations 
ly). From Figure 7, 
algorithm 
discard 
for 
writes are performed  to 
vanatlOn 
variation 
process 
process 
average number of matching 
than 10 throughout 
the matching 
performance 
performed 
algorithm 
overhead 
on the PRAM block. 
of 0.1 ,  while it is more  spaced 
out for 
of 0.3. In all of the cases, we find that 
invocations 
is less 
algorithm 
the PRAM block's lifetime. 
of 
accounts 
for a small  fraction 
Clearly, 
in comparison 
to the actual writes 
Y. CONCLUSIONS AND FUTURE W ORK 
In this paper, we explore 
a number of dynamic redundancy 
faulty PCM pages and improve the 
main memory systems. 
to resuscitate 
of PCM-based 
design choices 
from PDR to MDR, and 2 )  reducing 
techniques 
lifetime 
different 
switching 
in PDR from three to two. We show that, by intelligently 
combining 
of PRAM can be improved 
We explore 
namely, 1 )  
the group size 
by upto 43 x over Fail_Stop. 
the use of PDR and MDR schemes, 
along two  dimensions 
the lifetime 
n-specific 
characteristics 
As future work, we plan to extend RePRAM to incorpo­
and system energy 
the key features 
ions, and tune the hardware 
rate applicatio
awareness. We will focus on capturing 
the memory-intensive 
applicat
adjust to the performance 
Furthermore, 
other resistive memory technologies, 
level effects 
endurance  limitations 
as well as, system­
failures 
resulting 
from write 
in some of these devices. 
demands and energy constraints. 
we will extend this work by investigating 
needed to tolerate 
inherent 
of 
to 
VI. ACKNOWLEDGMENTS 
This material 
Science 
is based upon 
work supported 
under CAREER Award CCF-
in part by the 
National 
1 149557, and grants CCF- I l17243 and OCI-0937875. 
Foundation 
REFERENCES 
[1] C. Bienia, S. Kumar, J.P. Singh, and K. Li.  The 
PARSEC 
Benchmark Suite: Characterization 
cations. 
January 2008. 
Princeton University 
and Architectural 
Impli­
Technical Report TR-811-08, 
[2] Burton H. Bloom. Space/time trade-offs 
in hash coding with 
and Edde Tin-Shek 
and method having 
and  a 
battery, 
Commun. ACM, 13:422-426, July 1970. 
[4] Jie Chen, R. C. Chiang, H. Howie Huang, and Guru 
main 
Energy-aware 
[3] William A. Brant, Michael E. Nielson, 
errors. 
apparatus 
responsive 
In US Patent 5,799,200, 1998. 
allowable 
Tang. Power failure 
a shadow dram,  a flash rom, an auxiliary 
controller. 
Venkataramani. 
memory. SIGOPS Oper. Syst. Rev., 45(3):48
2012. 
H.  Howie Huang. rpram:  Exploring 
to improve lifetlme 
of pcm-based 
ceedings of the 201 1 International 
Architectures 
and Compilation Techniques, 2011 .  
redundancy 
an 
main memory. In Pro­
Conference on Parallel 
[5] Jie Chen, Zachary Wmter, Guru Ve ataramaru, 
writes to non-volatile 
-52, January 
[6] Sangyu ho an Hyunjin Lee. Flip-n-,write: 
a simple 
 d 
. 
nk
'
techniques 
detenrurustlc 
energy  and 
technique 
endurance. 
to Improve pram wnte performance, 
In MICRO, 2009. 
[7] Intel Corporation. Intel core i7-920 processor. 
http://ark.intel.comlProduct.aspx?id=37I47, 
[8] Dave Hayslett. 
System z redundant 
memory. In IBM SWG Competitive 
2010. 
array of inde8endent 
Project Offi ce, 2 1 1 .  
[9] Engin Ipek, Jeremy Condit, Edmund B. Nihtingale, 
Burger, and Thomas Moscibroda. 
memory: building  reliable 
memones. In ASPLOS, 2010. 
LIs: Cooperative integration 
for pcm main memory. In DSN, pages 221 -232, june 201 1 .  
DynamIcally 
systems from nanoscale 
[10] Lei Jiang, Yu Du, Youtao Zhang, B.R. Childers, 
of wear-leveling 
and Jun Yang. 
and salvaging 
replicaed 
resistlve 
Doug 
[ 1 1 ]  Nikolai Joukov, Arun M .  Krishnakumar, 
Chaitanya 
and Erez Zadok. 
Patti, 
filesystems. 
MSST, 
[12]  Randy H. Katz. Raid: A  personal  recollection 
of how storage 
Abhishek Rai, Sunil Samur, Avishay Traeger, 
Raif: Redundant array of independent 
0:199-214, 2007. 
became  a 
32(4), 2010. 
system. 
Annals of the History of Computing, IEEE, 
[13] HP Labs. Cacti 5.3. http://quid.hpl.hp. com:908IlcactV, 2010. 
[14] Benjamin C. Lee, Engin Ipek, Onur Mutiu, and Doug Burger. 
dram alter­
[15] Rami Melhem, Rakan Maddah,  and  Sangyeun 
phase change memory as a scalable 
Architecting 
native. 
In ISCA, 2009. 
recursivel
stuck-at 
International 
works, 2012. 
to enable new memory usage models. White Paper 
http://www.numonyx.coml. 2009. 
y defined invertible set scheme to tolerate 
In Proceedings 
faults in resistive  memory. 
Conference on Dependable Systems and Net­
[16] Numonyx. Phase change memory: A new memory 
[17] David A. Patterson, Garth Gibson,  and 
Randy H. Katz. A case 
of the 
multlple 
arrays of inexpensive 
disks (raid). 
In SIGMOD, 
for redundant 
pages 109-116, 1988. 
Cho.  Rdi:  a 
[18] Devices Process Integration and Structures. 
International 
roadmap for semiconductors. 
http://www.itrs.net. 
technology 
2007. 
ploiting 
corruptlon 
[19]  Feng Qin, Shan Lu, and Yuanyuan Zhou. Safemem: Ex­
ecc-memory 
for detecting 
memory leaks and memory 
during production  runs. 
In HPCA, 2005. 
[20] Moinuddin K. Oureshi, 
John Karidis, 
Michele Franceschini, 
Vijayalakshmi 
Enhancing 
with start-gap 
Srinivasan, 
wear leveling. 
Luis Lastras, 
In MTCRO, 2009. 
and security 
lifetime 
of pcm-based 
and Bulent Abali. 
main memory 
[21] Moinuddin K. Qureshi, Vijayalakshmi Srinivasan, 
and 
main memory 
In ISCA, 
Y  C 
high performance 
memory technology. 
phase-change 
Jude A. Rivers. Scalable 
system  using 
2009. 
.  . h C T R
[22]  S.  Raoux, 
Chen, R. M. Shelby, 
Lung, and C. H. Lam. Phase-change 
a scalable 
technology. 
M. Salmga, D. Kreos, S.-H. Chen, H.-L. 
random access memory: 
IBM J. Res. Dev., 52, July 2008. 
[23] Jose Renau et al. SESe. http://sesc.sour
[24] Stuart Schechter, Gabriel H. Loh, Karin Straus,  and 
2006. 
ceforge.net, 
[25] Nak Hee Seong, Dong Hyuk Woo, and Hsien-Hsin 
Burger. Use ecp, not ecc, for  hard 
memories. In ISCA, 2010. 
S. Lee. 
Security refresh: prevent malicious  wear-out 
with dynamically 
durabilIty 
ran­
domized address mapping. In Proceedings 
of the 37th annual 
international 
for phase-change  memory 
2010. 
symposium on  Computer architecture, 
failures 
Doug 
and increase 
in resistive 
[26] Nak Hee Seong, Dong Hyuk Woo, Vijayalakshmi 
Srinivasan, 
Jude A. Rivers, 
error recovery 
and Hsien-Hsin 
for memories. In MICRO, 2010. 
S. Lee. Safer: Stuck-at-fault 
Corporation. 
Evaluation 
SPEC Bench­
Performance 
[27] Standard 
marks. http://www.spec.org, 2006. 
[28] Chris Wilkerson, Alaa R. Alameldeen, 
Wu, Dinesh Somasekhar, and Shill-lien 
power with low-cost, 
lSCA,201O. 
The hp autoraid 
Comput. Syst., 14, February 1996. 
[29] John Wilkes, Richard Golding, 
hierarchical 
multi-bit  error-correcting 
and Tim Sullivan. 
Carl Staelin, 
storage system. ACM Trans. 
Zeshan Chishti, 
Wei 
Lu. Reducing cache 
codes. In 
[30] S.e. Woo, M. Ohara, E. Torrie, J.P. Singh, and A. Gupta. 
programs: 
The splash-2 
consideratio
[31]  B. Yang, J. Lee, J. Kim, J. Cho, S. Lee, and B. Yu.  A 
low power phase change random access memory using  a 
data 
comparison  write  scheme. 
Characterization 
ns. In ISCA, June 1995. 
In ISCAS, 2007. 
[32] Doe Hyun Yoon, Naveen Muralimanohar, 
Parthasarathy 
Erez. Free-p: Protecting 
hard  and 
soft errors. 
Ranganathan, 
In HPCA, February 2011 .  
Jichuan Chang, 
Jouppi, and Mattan 
non-volatile memory against both 
Norman  P. 
and methodolOgical 
G. W. Burr, M. J: BreitwIsc; .  .  etmer,  .- . 
[33] Wangyuan Zhang and Tao Li. Characterizing 
and mitigating 
the Impact of process variations 
memory systems. 
In MICRO, 2009. 
on phase  change 
based 
[34] Ping Zhou, Bo Zhao,  Jun 
Yang, and Youtao Zhang. A 
durable and energy efficient main memory using phase change 
memory technology. 
In ISCA, 2009.