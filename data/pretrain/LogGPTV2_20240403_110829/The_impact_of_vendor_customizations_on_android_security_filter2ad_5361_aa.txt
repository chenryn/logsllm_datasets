title:The impact of vendor customizations on android security
author:Lei Wu and
Michael C. Grace and
Yajin Zhou and
Chiachih Wu and
Xuxian Jiang
The Impact of Vendor Customizations on Android Security
Lei Wu, Michael Grace, Yajin Zhou, Chiachih Wu, Xuxian Jiang
Department of Computer Science
North Carolina State University
{lwu4, mcgrace, yajin_zhou, cwu10}@ncsu.edu, PI:EMAIL
ABSTRACT
The smartphone market has grown explosively in recent years, as
more and more consumers are attracted to the sensor-studded mul-
tipurpose devices. Android is particularly ascendant; as an open
platform, smartphone manufacturers are free to extend and modify
it, allowing them to differentiate themselves from their competitors.
However, vendor customizations will inherently impact overall An-
droid security and such impact is still largely unknown.
In this paper, we analyze ten representative stock Android im-
ages from ﬁve popular smartphone vendors (with two models from
each vendor). Our goal is to assess the extent of security issues
that may be introduced from vendor customizations and further de-
termine how the situation is evolving over time. In particular, we
take a three-stage process: First, given a smartphone’s stock im-
age, we perform provenance analysis to classify each app in the
image into three categories: apps originating from the AOSP, apps
customized or written by the vendor, and third-party apps that are
simply bundled into the stock image. Such provenance analysis
allows for proper attribution of detected security issues in the ex-
amined Android images. Second, we analyze permission usages of
pre-loaded apps to identify overprivileged ones that unnecessarily
request more Android permissions than they actually use. Finally,
in vulnerability analysis, we detect buggy pre-loaded apps that can
be exploited to mount permission re-delegation attacks or leak pri-
vate information.
Our evaluation results are worrisome: vendor customizations are
signiﬁcant on stock Android devices and on the whole responsible
for the bulk of the security problems we detected in each device.
Speciﬁcally, our results show that on average 85.78% of all pre-
loaded apps in examined stock images are overprivileged with a
majority of them directly from vendor customizations. In addition,
64.71% to 85.00% of vulnerabilities we detected in examined im-
ages from every vendor (except for Sony) arose from vendor cus-
tomizations. In general, this pattern held over time – newer smart-
phones, we found, are not necessarily more secure than older ones.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full citation
on the ﬁrst page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from permissions@acm.org.
CCS’13, November 4–8, 2013, Berlin, Germany.
Copyright is held by the owner/author(s). Publication rights licensed to ACM.
ACM 978-1-4503-2477-9/13/11 ...$15.00.
http://dx.doi.org/10.1145/2508859.2516728.
Categories and Subject Descriptors
D.4.6 [Security and Protection]: Information ﬂow controls; D.2.5
[Software Engineering]: Testing and Debugging—Code inspec-
tions and walk-throughs
Keywords
Android; Provenance; Customization; Static Analysis
1.
INTRODUCTION
The smartphone market has grown explosively in recent years,
as more and more consumers are attracted to the sensor-studded
multipurpose devices. According to IDC [30], smartphone ven-
dors shipped a total of 482.5 million mobile phones in the fourth
quarter of 2012 – levels nearly equal to those of feature phones.
Meanwhile, among smartphones, Google’s Android captured al-
most 70% of the global smartphone market share last year [31],
compared to about 50% the year before [20].
Android’s popularity is due in part to it being an open platform.
Google produces a baseline version of Android, then makes it freely
available in the form of the Android Open Source Project (AOSP).
Manufacturers and carriers are free to build upon this baseline,
adding custom features in a bid to differentiate their products from
their competitors. These customizations have grown increasingly
sophisticated over time, as the hardware has grown more capable
and the vendors more adept at working with the Android frame-
work. Flagship devices today often offer a substantially different
look and feel, along with a plethora of pre-loaded third-party apps.
From another perspective, vendor customizations will inherently
impact overall Android security. Past work [24] has anecdotally
shown that Android devices had security ﬂaws shipped in their pre-
loaded apps. Note that stock images include code from potentially
many sources:
the AOSP itself, the vendor, and any third-party
apps that are bundled by the vendor or carrier. It is therefore im-
portant to attribute each particular security issue back to its source
for possible bug-ﬁxes or improvements.
In this paper, we aim to study vendor customizations on stock
Android devices and assess the impact on overall Android secu-
rity. Especially, we intend to determine the source of the security
issues that trouble Android smartphone images, then further deter-
mine how the situation is evolving over time. To that end, we de-
velop a three-stage process to evaluate a given smartphone’s stock
ﬁrmware image. First, we perform provenance analysis, aiming
to classify each pre-loaded app into three categories: apps origi-
nating from the AOSP, apps customized or written by the vendor,
and third-party apps that are simply bundled into the stock image.
We then analyze, in two different ways, the security implications of
each app: (1) Permission usage analysis compares the permissions
623requested by the app with those that it actually uses, looking for
apps that request more permissions than they use. This situation
is known as permission overprivilege, and it indicates a poor un-
derstanding of the Android security model; (2) Vulnerability anal-
ysis, in comparison, looks for two general types of actual security
vulnerabilities: permission re-delegation attacks and content leaks.
Permission re-delegation attacks allow unprivileged apps to act as
though they have certain sensitive permissions, while content leaks
allow such apps to gain (unauthorized) access to private data.
To facilitate our analysis, we implement a Security Evaluation
Framework for Android called SEFA to evaluate stock smartphone
images. Given a particular phone ﬁrmware image, SEFA ﬁrst pre-
processes it and imports into a local database a variety of informa-
tion about the image, including the number of apps and numerous
information about each app, such as the list of requested permis-
sions, declared components, and the set of used Android APIs.
Then SEFA compares each pre-loaded app with various ones in
the original AOSP to determine its source and further performs a
system-wide data-ﬂow analysis to detect possible vulnerabilities.
In our study, we have applied SEFA to ten ﬂagship phone models
from ﬁve popular vendors: Google, Samsung, HTC, LG, and Sony.
For each vendor, we selected two phones: one from the current
crop of Android 4.x phones, and one from the previous generation
of 2.x devices. This slate of devices allows us to do two compara-
tive analyses: horizontal differential analysis compares the various
manufacturers’ offerings for a given generation, while vertical dif-
ferential analysis studies the evolution of any given vendor’s secu-
rity practices chronologically.
Our evaluation results show that more than 81.78% of pre-loaded
apps (or 76.34% of LOC) on stock Android devices are due to
vendor customizations. It is worrisome to notice that vendor cus-
tomizations were, on the whole, responsible for the bulk of the se-
curity problems suffered by each device. On average, 85.78% of all
pre-loaded apps in examined stock images are overprivileged with
a majority of them directly from vendor customizations. And ven-
dor apps consistently exhibited permission overprivilege, regard-
less of generation. Our results also show that vendor customiza-
tions are responsible for a large proportion of the vulnerabilities
in each phone. For the Samsung, HTC, and LG phones, between
64.71% and 85.00% of the vulnerabilities were due to vendor cus-
tomizations. This pattern was largely stable over time, with the no-
table exception of HTC, whose current offering is markedly more
secure than the last-generation model we evaluated.
The rest of this paper is organized as follows. We present our
methodology and system framework in Section 2, and describe im-
plementation and evaluation results with case studies in Section 3.
We then discuss for possible improvements in Section 4. Finally,
we compare with related work and conclude this paper in Section 5
and Section 6 respectively.
2. DESIGN
The goal of this work is to study vendor customizations on stock
Android devices and assess corresponding security impact. Note
that the software stack running in these devices are complex, and
their ﬁrmware is essentially a collaborative effort, rather than the
work of a single vendor. Therefore, we need to categorize the code
contained in a stock image based on its authorship and audit it for
possible security issues. After that, we can attribute the ﬁndings of
the security analyses to the responsible party, allowing us to better
understand the state of smartphone security practices in the industry
and spot any evident trends over time.
In Figure 1, we summarize the overall architecture of the pro-
posed SEFA system. Our system takes a stock phone image as
Preprocessing
Database
Provenance Analysis
Permission Usage Analysis
Vulnerability Analysis
Figure 1: The overall architecture of SEFA
its input, preprocessing each app and importing the results into a
database. This database, initially populated with a rich set of in-
formation about pre-loaded apps (including information from their
manifest ﬁles, signing certiﬁcates, as well as their code, etc.), is
then used by a set of subsequent analyses. Each analysis reads
from the database, performs its analysis, and stores its ﬁndings in
the database.
To study the impact of vendor customizations on the security of
stock Android smartphones, we have developed three such analy-
ses. First, to classify each app based on its presumed authorship,
we perform provenance analysis (Section 2.1). This analysis is
helpful to measure how much of the baseline AOSP is still retained
and how much customizations have been made to include vendor-
speciﬁc features or third-party apps. To further get a sense of the
security and privacy problems posed by each app, we use two dif-
ferent analyses: permission usage analysis (Section 2.2) assesses
whether an app requests more permissions than it uses, while vul-
nerability analysis (Section 2.3) scans the entire image for concrete
security vulnerabilities that could compromise the device and cause
damage to the user. Ultimately, by correlating the results of the se-
curity analyses with the provenance information we collected, we
can effectively measure the impact of vendor customizations.
2.1 Provenance Analysis
The main purpose of provenance analysis is to study the distri-
bution of pre-loaded apps and better understand the customization
level by vendors on stock devices. Speciﬁcally, we classify pre-
loaded apps into three categories:
• AOSP app: the ﬁrst category contains apps that exist in the
AOSP and may (or may not) be customized by the vendor.
• vendor app: the second category contains apps that do not
exist in the AOSP and were developed by the vendor.
• third-party app: the last category contains apps that do not
exist in the AOSP and were not developed by the vendor.
The idea to classify pre-loaded apps into the above three cat-
egories is as follows. First we collect AOSP app candidates by
searching the AOSP, then we exclude these AOSP apps from the
pre-loaded ones. After that, we can classify the remaining apps
by examining their signatures (i.e., information in their certiﬁcate
ﬁles) based on a basic assumption: third-party apps shall be private
and will not be modiﬁed by vendors. Therefore, they will not share
the same signing certiﬁcates with vendor apps.
In practice, this process is however not trivial. Since AOSP apps
may well be customized by vendors, their signatures are likely to
be changed as well. Although in many cases, the app names, pack-
age names or component names are unchanged, there do exist ex-
ceptions. For example, Sony’s Conversations app, with package
name com.sonyericsson.conversations, is actually a customized
version of the AOSP Mms app named com.android.mms. In order
to solve this problem, we perform a call graph similarity analysis,
624which has been demonstrated to be an effective technique even to
assist malware clustering and provenance identiﬁcation [29].
To generate the call graph required by any such analysis, we add
all method calls that can be reached starting from any entrypoint
method accessible to other apps or the framework itself. However,
we are hesitant to use graph isomorphism techniques to compare
these call graphs, as they are complex and have undesirable perfor-
mance characteristics. Instead, we notice that later analysis (Sec-
tion 2.3) will use paths, sequences of methods that start at an en-
trypoint and ﬂow into a sink (i.e., API or ﬁeld which may require
sensitive permissions, lead to dangerous operations or meet other
special needs). Therefore, we choose to preprocess each app, ex-
tract and compare the resulting paths, a much more straightforward
process that still compare the parts of each app that we are most
concerned with.
From our prototype, we observe that such a path-based similarity
analysis is implementation-friendly and effective. Particularly, we
use the return type and parameters (number, position and type) of
each node (method) in the path as its signature. If the similarity be-
tween two paths exceeds a certain threshold, we consider these two
paths are matching. And the similarity between two apps is largely
measured based on the number of matched paths. In our prototype,
to determine which apps belong to the AOSP, we accordingly take
the approach: (1) by matching app names and package names; (2)
by matching component names in the manifest ﬁle; (3) and then
by calculating the similarity between paths and apps. We point out
that a ﬁnal manual veriﬁcation is always performed to guarantee
the correctness of the classiﬁcation, which can also conﬁrm the ef-
fectiveness of our heuristics.
During this stage, we also collect one more piece of informa-
tion: the code size of pre-loaded apps measured by their lines of
code (LOC). Although it is impossible for us to get all the source
code of the pre-loaded apps, we can still roughly estimate their size
based on their decompiled .smali code.1 Therefore, we can draw a
rough estimate of vendor customization from provenance analysis
because the number and code size of apps are important indicators.
In addition, we also collect ﬁrmware release dates and update cy-
cles as supplementary information for our later evaluation (Section
3.1).
2.2 Permission Usage Analysis
Our next analysis stage is designed to detect instances of permis-
sion overprivilege, where an app requests more permissions than it
uses. SEFA applies permission usage analysis to measure the adop-
tion of the principle of least privilege in app development. Note that
here it is only possible to get the usage of permissions deﬁned in the
standard AOSP framework. The usage of vendor-speciﬁc permis-
sions cannot be counted because of the lack of related information.
There are four types of permissions in Android: normal, dan-
gerous, system and systemOrSignature. The latter three are sensi-
tive, because normal permissions are not supposed to be privileged
enough to cause damage to the user. Speciﬁcally, we deﬁne per-
missions declared by element uses-permission in the manifest ﬁle
as requested permissions, and permissions which are actually used
(e.g., by using related APIs) as used permissions respectively. An
overdeclared permission is a permission which is requested but not
used. Overprivileged apps contain at least one overdeclared per-
mission.
Algorithm 1 outlines our process for permission usage analysis.
From the database, we have the initial requested permission set of
apps (as it is in the manifest information), and our goal is to ﬁnd the
1We use the baksmali [42] tool to translate the Android app’s
.dex code into the .smali format.
Algorithm 1: Permission Usage Analysis
Input: initial info. in our database about pre-loaded apps
Output: overdeclared permission set of apps
apps = all apps in one image;
mappings = all permission mappings;
A = API invocation set;
I = intent usage set;
C = content provider usage set;
S = shared user id set;
R = requested-permission set;
U = ∅; // used permission set
O = ∅; // overdeclared permission set
foreach s ∈ S do
tmp = ∅;
foreach app ∈ s do
tmp = tmp ∪ R[app];
foreach app ∈ s do
R[app] = tmp;
foreach app ∈ apps do
foreach a ∈ A[app] do
U [app].add(mappings[a]);
foreach i ∈ I[app] do
U [app].add(mappings[i]);
foreach c ∈ C[app] do
U [app].add(mappings[c]);
foreach app ∈ apps do
O[app] = R[app] − U [app];
return O
overdeclared permission set. Despite the initial requested permis-
sion set, we ﬁnd it still needs to be augmented. Especially, there is
a special manifest ﬁle attribute, sharedUserId, which causes mul-
tiple apps signed by the same developer certiﬁcate to share a user
identiﬁer, thus sharing their requested permission sets.
(As per-
missions are technically assigned to a user identiﬁer, not an app, all
such apps will be granted the union of all the permissions requested
by each app. Accordingly, apps with the same sharedUserId re-
quire extra handling to get the complete requested permission set.)
Next, we leverage the known permission mapping built by earlier
work [2] to determine which permissions are actually used.2 Hav-
ing built both the requested permission set and the used permission
set, we can then calculate the overdeclared permission set.
Our approach to calculate the overdeclared permission set is con-
servative. Notice that some permissions declared in the manifest
ﬁle may be deprecated in the corresponding standard Android frame-
3 that was
work. An example is the permission READ_OWNER_DATA
removed after API level 8 (i.e., Android version 2.2), but still de-
clared by one app in the Nexus 4 (API level 17, or Android 4.2).
We do not consider them as overdeclared permissions, because the
vendor may retain deprecated permissions in the customized frame-
work for its own usage.
2Early studies including PScout [2] concern themselves only
with those permissions that are available to third-party apps. In our
study, we need to cover additional permissions deﬁned at system
and systemOrSignature levels, which may not be well documented.
3Without speciﬁcation, the preﬁx of standard Android permis-
sion name android.permission. is omitted in this paper.
625After obtaining the overdeclared permission set, we then analyze
the overall permission usage of each device, and classify results
by provenance. The distributions of overprivileged apps as well as
overdeclared permissions can then both be studied. Further, we also
perform horizontal and vertical analysis, i.e., cross-vendor, same-
generation, vs. cross-generation, same-vendor comparisons.
2.3 Vulnerability Analysis
While our permission usage analysis aims to measure the soft-
ware development practices used in the creation of each pre-loaded
app, vulnerability analysis is concerned with ﬁnding real, action-
able exploits within those apps. Speciﬁcally, we look for two rep-
resentative types of vulnerabilities in the Android platform which
stem from misunderstanding or misusing Android’s permission sys-
tem. First, we identify permission re-delegation attacks [18], which
are a form of the classic confused deputy attack [27]. Such an
attack exists if an app can gain access to an Android permission
without actually requesting it. A typical example is an app which
is able to send Short Message Service (SMS) messages without ac-
quiring the (supposedly required) SEND_SMS permission. For the
second kind of vulnerability, we consider content leaks, which es-
sentially combines the two types of content provider vulnerabili-
ties reported by Zhou and Jiang [52]: passive content leaks and
content pollution. An unprotected content provider (i.e., one that
takes no sensitive permission to protect its access) is considered
to have a passive content leak if it is world-readable, and to have
content pollution if it is world-writable. We extend this deﬁnition
to cover both open and protected content providers. The protected
ones are also interesting as there may also exist unauthorized ac-
cesses to them through the other three types of components which
could serve as springboards for exploitation. For ease of presenta-
tion, we call these vulnerabilities content leaks.
As our main goal is to accurately locate possible vulnerabilities,
we in this study consider the following adversary model: a mali-
cious app, which is compatible with the phone, may be installed
on the phone by the user. We do not expect the malicious app will
request any sensitive permissions during installation, which means
it will only rely on vulnerable apps to accomplish its goals: either
steal money from the user, gather conﬁdential data, or maliciously
destroy data. In other words, we limit the attacker to only unprivi-
leged third-party apps to launch their attacks.
Keeping this adversary model in mind, we focus our analysis
on security-critical permissions – the ones that protect the func-
tions that our adversary would most like to gain access to. Specif-
ically, for permission re-delegation attacks, we focus on permis-
sions that are able to perform dangerous actions, such as SEND_SMS
and MASTER_CLEAR, because they may lead to serious damage to the
user, either ﬁnancially or in terms of data loss. As for content leaks,
we ignore those whose exposures are likely to be intentional4. Note
that some apps may be vulnerable to low-severity content leaks;
for example, publicly-available information about a network TV
schedule is not as sensitive as the user’s banking credentials. In
other words, we primarily consider serious content leaks whose ex-
posures are likely to cause critical damages to the user.
To actually ﬁnd these vulnerabilities, we rely on a few key tech-
niques. An essential one is reachability analysis, which is used to
determine all feasible paths from the entrypoint set of all Android
components, regardless of whether we consider them to be pro-
tected by a sensitive permission (Section 2.3.1). To better facilitate
vulnerability analysis, we deﬁne two varieties of sinks:
4Some content providers are exported explicitly, such as
TelephonyProvider in the app of the same name.
• sensitive-sinks: sensitive Android APIs which are related to
sensitive permissions (e.g., MASTER_CLEAR) of our concern
• bridge-sinks: invocations that are able to indirectly trigger