title:Towards an evolvable internet architecture
author:Sylvia Ratnasamy and
Scott Shenker and
Steven McCanne
Towards an Evolvable Internet Architecture
Sylvia Ratnasamy
Intel Research, Berkeley
Scott Shenker
U.C.Berkeley and ICSI
Steven McCanne
Riverbed Technology
PI:EMAIL
PI:EMAIL
PI:EMAIL
ABSTRACT
There is widespread agreement on the need for architectural change
in the Internet, but very few believe that current ISPs will ever ef-
fect such changes. In this paper we ask what makes an architecture
evolvable, by which we mean capable of gradual change led by the
incumbent providers. This involves both technical and economic
issues, since ISPs have to be able, and incented, to offer new archi-
tectures. Our study suggests that, with very minor modiﬁcations,
the current Internet architecture could be evolvable.
Categories and Subject Descriptors: C.2.1 [Network Architec-
ture and Design]:Network communications
General Terms: Design.
Keywords: Network Architecture, Anycast.
1.
INTRODUCTION
In the early days of the commercial Internet (mid 1990’s) there
was great faith in Internet evolution. Many believed that when-
ever new versions of IP (such as IPv6), or extensions to IP (such as
IntServ or IP Multicast), were evaluated on testbeds and standard-
ized by the IETF, the ISPs would soon deploy them in the public
Internet. This was not envisioned as a one-time change, but as an
ongoing process of Internet evolution. This widespread optimism
about change fueled ambitious efforts to extend or revise the Inter-
net architecture, and we all looked forward to a brighter future.
The remarkable success of the Internet surpassed our wildest
imagination, but our optimism about Internet evolution proved to
be unfounded. The unfortunate history of IPv6, IntServ, IP Multi-
cast, and other such proposals has turned that early optimism into a
deep pessimism about evolutionary architectural change. The pre-
vailing wisdom now is that ISPs have little incentive to deploy new
architectures; since they all have to act in concert, there is no com-
petitive advantage to such advances, and the costs of universally
deploying a new architecture are immense. Thus, the ISPs, which
were once thought the agents of architectural change, are now seen
as the main cause of the Internet impasse [1].
This comes at an unfortunate time as the need for evolution is
more apparent than ever. The Internet’s success has brought with it
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
SIGCOMM’05 August 22–26, 2005, Philadelphia, Pennsylvania, USA.
Copyright 2005 ACM 1-59593-009-4/05/0008 ...$5.00.
unforeseen stresses and strains that have revealed numerous limita-
tions in the Internet architecture. The literature is replete with calls
for change, from the enduring worries about security [2–5], quality-
of-service [6] and mobility [7], to more recent concerns about high-
speed congestion control [8] and middleboxes [9,10], to fundamen-
tal revisions in the basic architectural framework [9, 11–17].
This collision between the improbability and the necessity of
change has produced two reactions in the community. Some have
tried to augment the Internet architecture through overlay networks.
Overlays have been proposed for a variety of services, including
multicast [18], quality-of-service [19], robust routing [20], and con-
tent distribution [21, 22]. These overlays would not lead to funda-
mental changes in the underlying architecture, but would merely
mask some of its most obvious deﬁciencies.
More recently, overlays have been proposed as a way to under-
mine the current ISPs. As observed in [1], overlays are not re-
stricted to offering isolated services; they can instead be used to
deploy radically new architectures (with, of course, certain limi-
tations in the QoS and security offered). As such, overlays would
enable a new entrant — that is, an aspiring rather than an incumbent
ISP — to enter the market with a new architecture. This, however,
is revolution not evolution; change would require destabilizing the
market, with the current ISPs replaced by a new generation of ser-
vice providers. Moreover, maintaining evolution would require a
succession of such revolutions.
Neither of these two stories is very comforting. One offers lim-
ited change, providing additional services but not substantial revi-
sion to the fundamental architecture. The other requires repeated
market destabilization, which is unlikely to be an easy or frequent
occurrence for such a global, large-scale business.
In this paper we return to the original goal of Internet evolution.
Rather than take ISP non-cooperation as an unchangeable given,
we regard the lack of incentives for evolution as an architectural
ﬂaw and ask how this can be remedied. Hence, we ask: how can
one make an architecture evolvable? The term architecture can be
a somewhat fuzzy one and so, to be speciﬁc, what we’re referring
to here is IP. By evolving the Internet architecture, we mean the
ability to change IP – IP headers, addressing, forwarding and so
forth. By evolvable we mean capable of gradual (but unlimited)
change within the current market structure: that is, change that is
not restricted architecturally and that does not require a change in
the incumbent ISPs.
Many have posed this question before, and yet, we ﬁnd ourselves
with no proposed solution. Here we want to address this question
in a very concrete and pragmatic fashion. Hence rather than adopt
a clean-slate approach and design the “ideal” evolvable IP, we try
and create an evolvable IP starting from the conﬁnes of today’s IP.
Our discussion is primarily a walk-through of design options and
313their implications with little to offer in novel mechanisms or radical
insights; it is the importance of the question at hand that provides
the impetus. We turn to that question in the next section.
2. REQUIREMENTS FOR EVOLVABILITY
2.1 General Discussion
To express the problem of evolvability in very concrete terms,
we reduce it to a single question:
When a new version of IP, call it IPvN, becomes standardized or
otherwise deﬁned, what conditions would lead ISPs to deploy it?
This question, which the remainder of this paper will attempt to
answer, is primarily one of incentives and the mechanisms needed
to support them. While it is technically straightforward (though
perhaps expensive) for ISPs to support a new protocol, they must
have the incentive to do so. However, this need for the proper incen-
tives inﬂuences the technical means by which IPvN will be initially
offered. Thus, it is the incentive issues that drive the evolutionary
requirements. In this section we motivate and identify the technical
conditions necessary to provide ISPs with the incentives to deploy
IPvN. The following section then presents the details of how these
technical requirements might be met. As before, we don’t claim
novelty for the ensuing discussion, merely (we hope) relevance.
The key to ensuring the right incentives is fostering competition.
Early-adopting ISPs will offer new architectures only if they be-
lieve it will give them a competitive edge, and late-adopting ISPs
will do so only if they feel they are at a competitive disadvantage
without it. There are several (related) factors in encouraging com-
petition:
(cid:127) Foster independent innovation: an ISP should not be able
to block innovation by others.
(cid:127) Enable customer choice: ISPs will then have to compete for
customers.
(cid:127) Allow ISPs some degree of control: if ISPs have no control,
then they cannot recoup their expenses and are unlikely to
deploy.
These overly general principles are best appreciated in the con-
text of a speciﬁc technical decision and hence, rather than expand
on them here, we will repeatedly return to these points when dis-
cussing design options. One recurring theme is the conﬂict between
user choice and ISP control; our discussion will highlight the trade-
offs we make between these.
Our technical discussion begins with four very basic assumptions
that must be incorporated in any discussion of Internet evolvability.
The ﬁrst three limit our expectations, while the fourth offers hope:
(A1) Assume partial ISP deployment. Clearly, we can-
not expect that all ISPs will simultaneously adopt IPvN. Requiring
ISPs to move in lockstep allows individual ISPs to block deploy-
ment, and prevents early-adopters from gaining a competitive ad-
vantage. Thus, we should assume that only a subset of the ISPs,
perhaps only one, will initially deploy IPvN. Moreover, we cannot
even expect an adopting ISP to initially deploy IPvN in all of its
routers. Hence, all mechanisms must work with only a subset of an
ISP’s routers implementing IPvN.
(A2) Assume partial ISP participation. While an ISP might
choose not to deploy IPvN in its network, one might hope that
it would participate in a larger, general plan for evolvability (for
example, through general conﬁguration tools that would help its
clients access IPvN services deployed elsewhere). However, for the
same reasons as above, any proposal requiring explicit participation
by all ISPs is unlikely to achieve ubiquity. Hence, while any tech-
nical solution should accommodate ISP participation where avail-
able, we require that any plan for evolution to IPvN not rely on such
global participation.
(A3) Assume the existing market structure and contrac-
tual agreements. For example, we avoid requiring that clients
enter new contractual agreements beyond their current ones with
access providers for basic Internet connectivity. In particular, we
do not require that clients sign up with speciﬁc (possibly in addi-
tion to their current ISP) providers in order to obtain IPvN service.
This constraint is to some extent self-imposed because of our desire
for solutions that are practical in today’s Internet. More importantly
however, this assumption follows from our “evolution, not revolu-
tion” argument; i.e., the general process of transition should avoid
requiring such upheaval. Note though that we do not preclude such
change; we merely avoid requiring it.
(A4) Assume revenue ﬂow. If there is no ﬁnancial gain to be
realized from offering IPvN, then it won’t be deployed. What we
assume here is that if IPvN attracts users, then revenue will ﬂow to-
wards those ISPs offering IPvN. An ISP that attracts new customers
would obviously increase revenue. We also posit that an ISP that
attracts new trafﬁc, by offering IPvN, will also gain revenue possi-
bly due to increased settlement payments (trafﬁc from non-offering
ISPs to offering ISPs would increase).
The need for certain technical mechanisms follow from these as-
sumptions. Tolerating partial deployment, both within an ISP and
across ISPs, immediately implies the obvious conclusion that evo-
lution will initially require some form of overlay or virtual network
to bridge across ISPs that do not support IPvN. While overlays are
common, the IPvN overlay is not administered as a single unit (un-
like, for example, RON [20], PlanetLab [23], Akamai [24], Over-
Cast [21]), but instead is formed by peering arrangements across
the IPvN overlays within individual ISPs (akin to the MBone [25],
XBone [26], etc.). We sketch an example of how this might be done
in Section 3.3.
The assumption of revenue ﬂow means that an ISP would be re-
warded for attracting usage. This is a crucial component in foster-
ing competition, and points to the single most important technical
requirement for evolvability, universal access (UA), which we sum-
marize below:
Require Universal Access All clients can use IPvN if they so
choose, regardless of whether their ISP deploys IPvN or assists
their clients in accessing IPvN.
Even if a single ISP deploys IPvN, every client has access to it.
Thus, no ISP can block use of IPvN. In this way, universal access
fosters innovation.
Universal access also provides for customer choice; customers
can access IPvN no matter what their ISP does. If access was re-
stricted such that clients could only access IPvN with the assis-
tance of their ISP, then customer choice would be severely limited.
This would, in turn, decrease competition between the ISPs since it
would require changing ISPs, which is a signiﬁcant burden, before
a customer could experiment with IPvN.
On a more positive note, universal access creates a positive feed-
back cycle for evolution. As long as a single ISP was willing to
deploy IPvN, application developers could have a large market for
IPvN-aware software, and this in turn would create more demand
for IPvN. A virtuous cycle between application demand (for IPvN-
aware software) and service demand (for IPvN deployment) could
lead to rapid deployment.
The ﬂip side of this scenario was most clearly exempliﬁed in the
attempted deployment of IP Multicast. There are myriad reasons
why multicast, despite being supported by most major router ven-
dors, was never deployed at scale. One was, we believe, the lack
of universal access. Even had a major ISP (say Sprint) deployed
multicast, this new functionality would only have been available to
Sprint’s customers. Application developers on the other hand (e.g.,
content providers such as CNN), were reluctant to develop multi-
cast applications that could only service a fraction of Internet users.
This led to a chicken-and-egg scenario where ISPs were reluctant
to deploy a service for which there was no apparent application
demand, while application developers were reluctant to rely on a
service that was not universally available. If instead, any endhost
had been able to access Sprint’s multicast services, then applica-
tion developers might have been more willing to experiment with
the service. Thus, requiring universal access of a partially deployed
service fosters demand and encourages independent innovation (by
both ISPs and applications).
Given partial deployment, the need for universal access leads to
our second technical requirement – redirection. To tolerate partial
IPvN deployment (A1) and participation (A2), IPvN packets leav-
ing a host must ﬁnd their way to the virtual IPvN network whether
or not their local ISP supports IPvN (A1) or supports the conﬁg-
uration needed to redirect packets to IPvN domains (A2). While
redirection is always a requirement for overlay networks, here we
require that redirection cannot be through application-speciﬁc or
manual conﬁguration on the host. Manual conﬁguration is outside
the capabilities of most Internet users, and it would be doubly dif-
ﬁcult to conﬁgure if one’s own ISP is not willing to assist in doing
so. Thus, for evolution, the redirection challenge is not how to
intercept packets, which is a signiﬁcant issue itself (though there
has been recent progress in general techniques to do this [27]), but
knowing where to redirect them to. This problem has not received
much attention, but it turns out to be crucial to our story. Moreover,
incentive issues, rather than technical ones, are the dominant factor.
Note that enabling universal access leads to a balance between
the competing needs of user choice and ISP control. Users are free
to choose whether or not to use IPvN (which drives ISP competi-
tion), but the operation of the IPvN virtual network and the process
of redirecting IPvN packets is left under the control of ISPs. A
further tilt to this balance would be to offer users the choice of
which IPvN service provider their IPvN packets are redirected to.
We do not explore this option in detail but note that the technical
framework we describe in the following sections could, with few
modiﬁcations, be adapted to such scenarios.
There are two obvious approaches to redirection: application-
level controlled by third-party brokers and network-level controlled
by ISPs. We discuss each in turn.
2.2 Application-Level Redirection
For application-level redirection, one might have a lookup ser-
vice that tracks the state of IPvN deployment in terms of which ISP
domains and/or routers support IPvN. When queried by an end-
host, the lookup service would return an IP address for a nearby
IPvN router. The client can then tunnel IPvN packets to that router,
which injects them into the IPvN overlay.
The crucial question is: who runs this lookup service? In one
scenario, this would be offered by ISPs themselves; i.e., ISPs could
exchange deployment information with each other and then each
provide such a lookup service. However, in that case, non-offering
ISPs would have little incentive to provide such a lookup service
(assumptions A1 and A2) and hence a customer of a non-offering
ISP would have to use the lookup service of another ISP. This vio-
lates our assumption that customers enter no new contractual agree-
ments. This is also technically difﬁcult because, in the absence
of any additional redirection services, it would require endusers
to know which ISPs offered such lookup services (at any point in
time, they would have to know which ISPs were offering IPvN) and
which offering ISP is best suited to serving the enduser in terms of
network proximity. Thus, relying on ISPs to provide a lookup ser-
vice would likely interfere with universal access.
Another possibility is that the lookup service could be run by
third-party brokers who gather deployment information from each
of the ISPs. At a technical level, this would be consistent with
universal access since any client could reach such brokers. This
option however alters the current market structure and, in terms of
incentives, is riddled with open questions. Chief among these is
that under this arrangement, brokers become a crucial component
of the infrastructure, signiﬁcantly inﬂuencing the routing of IPvN
packets, and hence it isn’t clear whether and why ISPs would be
willing to relinquish control to such brokers. At the same time,
third party-brokers are dependent on ISPs for the deployment in-
formation needed to effect redirection. One (positive) possibility
here is that if some ISPs did enter agreements with brokers, the
rest would have to follow to compete. Yet another question is who
would pay these brokers: they could be paid by ISPs to direct trafﬁc
to them, or by customers to provide good referrals, or both. This in
turn leads to the question of how one would ensure competition at
the broker level. Presumably there would be multiple brokers that
would likely peer with each other, or only provide partial visibility
into the IPvN overlay.
In summary, both the above options for application-level redirec-
tion are less than satisfactory: ISP-based redirection is difﬁcult in
the event of partial participation requiring manual conﬁguration by
endusers, while redirection by third-party brokers upsets the cur-
rent market structure. This leads us to explore an alternate option,
namely that of network-level support for IPvN redirection.
2.3 Network-level Redirection
Network-level redirection involves no lookup to ﬁnd a nearby
IPvN router. Instead, every router in the network (whether IPvN
or not) is equipped with the knowledge needed to forward an IPvN
packet towards an IPvN router; i.e., the network naturally routes
IPvN packets to an appropriate destination. Ignoring the technical
difﬁculties for a moment (we discuss them in detail in the follow-
ing section), this has the nice property that it works within the cur-
rent market structure. Such redirection is under the shared control
of ISPs and, as we discuss later, doesn’t involve establishing new
brokers or even making substantial changes in routing. While it
may not have the full ﬂexibility that a lookup service could have,
it would thus be easier to achieve with incremental changes. The
main problem is this: if we allow redirection to be done by ISP
routing, how can a client in a non-offering ISP be guaranteed ac-
cess to IPvN? Can’t the ISP block such access through its routing
algorithms? That is the question we address in the next section.
3. MECHANISMS FOR EVOLVABILITY
The previous section argued for network-level redirection as a
vital primitive in supporting the evolvability of a multi-provider
network infrastructure. In this section, we propose the use of IP
Anycast as a candidate mechanism by which to effect this network-
level redirection. We show that IP Anycast is both well-suited to
the task and a practical choice as support for anycast routing can be
deployed with little-to-no change in today’s routing infrastructure.
We discuss anycast and its deployment scenarios in Section 3.1.
The second required component identiﬁed in Section 2 is the set
of mechanisms used in the construction and maintenance of multi-
provider virtual networks (vN-Bones). We explore candidate so-
lutions for this in Section 3.3. Finally, Section 3.4 describes how
packet forwarding is implemented through the combination of IP
anycast and vN-Bone tunneling.
We stress that there is remarkably little innovation in the details
of the technical discussion that follows. Rather, our contribution
is one of synthesis – in identifying the necessary components and
piecing them together to construct a plausible scenario of IP evolv-
ability. At the same time, the incremental nature of the individual
pieces lends hope that our proposal for evolvability is practical and
within grasp of real deployment.
3.1 IP Anycast as Network-level Redirector
RFC 1546 [28] deﬁnes anycasting as a network service in which
a host transmits a datagram to an anycast address and the network
is responsible for providing best effort delivery of the datagram to
one of possibly multiple servers that accept datagrams for that any-
cast address. Typically, a datagram will be delivered to the server
closest to the client host where “closest” is deﬁned in terms of the
network’s measure of routing distance.
Since its proposal in 1993, IP Anycast has been deployed within
individual domains primarily for service discovery (e.g., to locate
rendezvous points in PIM-SM [29]) and on a global scale for the
robust implementation of root DNS name servers RFC3258 [30].
Here, we propose the use of IP Anycast as the mechanism for
network-level redirection in support of the deployment of succes-
sive generations of IP. As described in Section 2, in a network
where the ubiquitously supported IP service is (say) IPv4, and the
next generation IP being deployed is (say) IPv8, network-level redi-
rection is needed to steer IPv8 packets towards IPv8 routers. Us-
ing anycast, this is easily achieved as follows: a well-known IPv4
anycast address A4 is assigned to the deployment of IPv8 and ev-
ery IPv8 router accepts delivery of packets destined to A4. To use
IPv8, any endhost can simply encapsulate an IPv8 packet in an IPv4
packet with destination A4. Anycast ensures this packet will be de-
livered to the closest IPv8 router, from which point on the packet is
in the hands of IPv8 routers.
Our choice of anycast stems from two key reasons –
1. the abstraction of an anycast address enables the seamless
spread of deployment. By this we mean that the use of an
anycast address allows endhosts and (if desired) ISPs to re-
main ignorant of the state of IPv8 deployment in terms of
which ISP domains/routers currently support IPv8. Were
this not the case, then deployment by one ISP could trigger
widespread reconﬁguration at possibly remote endhosts.1
2. because anycast reuses the existing unicast routing infras-
tructure, it inherits the highly decentralized control structure
of IP routing and hence individual ISPs can independently
conﬁgure and control the redirection process.
1In fact, it isn’t clear how an ISP might, without global knowledge,
even identify the set of endhosts that need reconﬁguration.
ISP X
ISP W
ISP Y
ISP Z
C
`
Figure 1: Anycast enables the seamless spread of deployment:
IPv8 is deployed successively in ISPs X, then Y and ﬁnally Z.
Throughout, client C is seamlessly redirected to the closest IPv8
provider.
To see this, consider the deployment of IPv8 in Figure 1. Ini-
tially, provider X is the only ISP to deploy IPv8 and hence IPv8
packets from client C, with local ISP Z, are routed through X’s do-
main. However, once ISP Y deploys IPv8, C’s packets are routed
through Y instead of X and ﬁnally, when Z deploys IPv8, C’s IPv8
packets are handled by its own local ISP. Note that throughout this
deployment process, client C’s packets are seamlessly redirected
through the appropriate providers without requiring any form of
reconﬁguration or indeed any awareness of the state of IPv8 de-
ployment on the part of endhosts. The same is largely true for ISPs
as well. The natural inter-domain routing protocols (with possible
support for anycast, as described below) ensures that packets are
routed to the appropriate provider without ISPs having to explicitly
monitor, and adapt to, the global state of IPv8 deployment.
Moreover, note that despite its seamless nature, ISPs can, to
some extent, control the process of redirection through policy
choices in their inter-domain routing. For example, in Figure 1, ISP
W might, based on peering policies, choose to route anycast pack-
ets to ISP X before Y. As with regular inter-domain routing, this
control is both partial (i.e., shared across ISPs) and implemented in
a decentralized manner.
Thus, unlike the case of application-level redirection described
in Section 2, here the network, in a completely decentralized man-
ner, “self-manages” redirection without the need for higher-layer,
third party brokers that track and/or control the global state of de-
ployment.
In summary, anycast implements network-level redirection in a
manner that addresses the issues of incentives raised in Section 2.
Speciﬁcally:
(cid:127) universal access is achieved even under partial deployment
(cid:127) the existing ISP control structure is preserved
(cid:127) operation is not dependent on all ISPs participating (we dis-
(cid:127) through peering policies, ISPs can control but not gate de-
(cid:127) as with regular unicast routing, control is decentralized and
cuss anycast routing with partial ISP participation below)
ployment
shared across ISPs
The above discussion assumes the existence of a global IP Any-
cast service. Unfortunately, anycast deployment today is typically
limited to individual domains.
In what follows, we discuss two
options to deploying a global IP anycast service. In keeping with
our goals, we would rather not assume that all ISPs will participate
either in the deployment of a new generation of IP (IPvN), nor in
our plan for evolvability. Hence while we assume that a participant
ISP (by which we mean an ISP that is willing to deploy IPvN) will
also be willing to deploy mechanisms to support anycast, we are
unwilling to assume that all ISPs shall do so. The question then is
what minimal degree of support for anycast can we require of non-
participant ISPs. The two options we describe below differ slightly
in this respect: our ﬁrst option requires that a non-participant ISP be
willing to propagate a small number of non-aggregatable (i.e., with
preﬁx longer than the /22 deemed acceptable for propagation in to-
day’s routing infrastructure) anycast addresses in its inter-domain
routing protocol. Note that this is a change in policy on the part
of an ISP and does not require the deployment of any new mech-
anism. Our second option requires no change (neither policy nor
deployment) by non-participant ISPs but does result in a somewhat
less “pure” form of anycast.
Before proceeding, we note that our discussion here implicitly
promotes a somewhat stripped down anycast service model.
In-
stead of the fully dynamic framework assumed in RFC 1546 where
arbitrary hosts can join and leave anycast groups dynamically we
envision a more statically provisioned framework where only con-
ﬁgured hosts within the network infrastructure are members of an
anycast group and ISPs explicitly control the allocation and adver-
tisement of anycast addresses.
3.2 Anycast Routing
link-state,
Intra-Domain. Standard intra-domain unicast routing algo-
rithms, whether distance-vector or
are naturally
amenable to routing anycast. As described in [31], for link-state
protocols such as OSPF, the only modiﬁcation required is that IPvN
routers also advertise a high-cost “link” to the corresponding any-
cast address. This high cost is necessary to prevent routers from
attempting to route through an anycast address. Note that from
these link state advertisements, an IPvN router can easily identify
every other IPvN router within its domain. With distance-vector
protocols such as RIP [32], anycast routing merely requires that an
IPvN router advertise a distance of zero to its anycast address; stan-
dard distance-vector then ensures that every router will discover the
next hop to its closest IPvN router. Note that here, unlike link-state
routing, an IPvN router cannot easily identify other IPvN routers.
An alternate approach to both the above is simply to have an
IPvN router indicate this in its standard unicast route advertise-
ment by, for example, explicitly listing its anycast address. Be-
cause intra-domain routing algorithms build a complete (i.e., non-
aggregated) routing table,
this makes anycast routing trivial –
a router merely checks its unicast routing table for the closest
anycast-addressed router. This involves a small modiﬁcation to ex-
isting intra-domain routing algorithms but makes it trivial for IPvN
routers to discover one another. As described in Section 3.3, this
knowledge enables very simple intra-domain virtual topology con-
struction.2
2While the remainder of this paper will assume that the intra-
domain protocol does allow IPvN routers to discover one another
we stress that this is merely a simpliﬁcation and in no way a neces-
sary requirement. In its absence (i.e., for domains that use unmod-
iﬁed RIP [32]), the intra-domain virtual topology construction will
merely have to implement some additional discovery mechanisms
P
Q
Default domain 
for An
D
X
`
Y
`
IPvN traffic to acast 
destination An
IPvN traffic to An
after Y and Q peer
ISP-Q 
advertises An
internally
`
Z
`
Figure 2: Inter-domain anycast routing using ISP-rooted unicast
addresses and “default” routes.
Inter-Domain, option 1: non-aggregatable addresses,
global routes. One approach to supporting inter-domain any-
cast is to designate a portion of the regular unicast address space
to serve as anycast addresses and require that ISPs propagate route
advertisements for anycast addresses in their inter-domain routing
protocols. This approach is certainly implementable even today –
as suggested by [28,31], a designated portion of the unicast address
space could be assigned to anycast and propagating these routes
in BGP would require a change in policy but not mechanism on
the part of ISPs – and yet there is, with one exception [30], lit-
tle deployment of global IP anycast. One reason for this narrow
adoption is concern over the scalability of such an approach, par-
ticularly under RFC1546’s fully general and dynamic IP anycast
service model. Anycast addresses, as described above, are not ag-
gregatable and must hence be advertised individually by routing
protocols and lead to routing state that grows in direct proportion
to the number of anycast groups. However, for our proposed use of
anycast, scalability is unlikely to be a concern. Recall that a single
anycast address is needed to serve each new generation of IP. Given
the cost and effort for an ISP to roll out a new generation of routers,
we imagine that the number of simultaneous attempts to deploy dif-
ferent IP versions is likely to be very small (ideally one) and will
not lead to a problematic growth in routing state. Moreover, unlike
the more commonly advocated uses of anycast (server selection,
etc.), here the consumers of anycast addresses are not arbitrary en-
dusers but rather the ISPs themselves who have an incentive to use
these addresses sparingly. To further ensure this, ISPs might even
charge to route anycast.
Instead, our concern with this approach is that it requires that all
ISPs eventually support the propagation of anycast routes. While
this seems like a not unreasonable hope given that the only change
required is a simple modiﬁcation to policy, we would rather not rely
on this assumption and hence explore alternate approaches.
Inter-Domain, option 2: aggregatable addresses, de-
fault routes. To address the poor scaling of traditional anycast
architectures, Katabi et al. propose GIA [31]. In GIA, scalabil-
ity is achieved by introducing the notion of a “home” ISP domain
associated with an anycast group. GIA still allocates anycast its
such as those described in Section 3.3.
own portion of the IP address space – all addresses preﬁxed by a
well-known “Anycast Indicator” sequence of bits. However the re-
maining address bits are drawn from the unicast address space of
the home domain. This allows for simple “default” routes; a router
with no anycast routing entry for a given address can look up the
home domain’s preﬁx in its unicast routing table and forward the
packet towards the home domain. GIA requires that the home do-
main include at least one member of the anycast group and hence
this ensures the packet will reach a group member although not
necessarily the closest. For more optimized anycast routes, Katabi
et al. propose an extension to BGP whereby border routers can
initiate searches for nearby members of an anycast group.
While GIA offers an elegant solution to scalable anycast, its de-
ployment requires modifying the border routers at client domains.
Given the current lack of deployment of GIA by ISPs, and to sat-
isfy our stated required assumption of no global participation (Sec-
tion 2), we present here an approach to anycast that requires no
change by non-participant ISPs. We stress however that our pro-
posal is somewhat motivated by expediency and open to eventual
replacement by GIA (or a similar design) and/or the use of a limited
number of non-aggregatable addresses as described above.
Our proposal, along the lines described in [33], is to avoid (at
least for now) introducing a special type of anycast address and in-
stead just reuse a piece of the existing unicast address space. We
borrow the basic insight behind GIA and advocate that anycast ad-
dresses be allocated from the unicast address space of a “default”
ISP (e.g., the ﬁrst ISP to initiate deployment of IPvN) and IPvN
routers are conﬁgured to advertise the anycast address in their IGP
as described earlier. Additional ISPs that adopt IPvN also conﬁgure
their IPvN routers to advertise the same anycast address internally.
Standard unicast routing will deliver anycast packets to the closest
IPvN router along the path from the source to the default ISP. For
example, in Figure 2, ISPs Q and D deploy IPvN and D is the de-
fault domain; anycast packets from domains X and Y terminate in
domain D while those from Z reach Q. To widen their reach, non-
default domains can peer with neighboring domains to advertise
their anycast route. For example, in Figure 2, Q can peer with Y to
advertise its path for the anycast address in question; Y’s packets
will then be delivered to Q rather than D.
Thus the ﬁnal picture in our proposal is not unlike that using
non-aggregatable addresses. The key difference is that our use of a
default ISP allows us to transition to that ﬁnal picture through the
optional and independent participation of ISPs. Even with no coop-
eration from non-IPvN domains, the above scheme will route any-
cast correctly, although imperfectly in terms of proximity to, IPvN
routers. Here, the use of inter-domain advertising is an optimiza-
tion that leads to more improved anycasting. A potential failing of
our approach is that the default provider owns the anycast address
and receives a larger than normal share of IPvN trafﬁc.
Ideally
though, this could incite other ISPs to pursue inter-domain adver-
tising of anycast addresses.
Given its practicality, our discussion from here on will assume
the the use of anycast addresses rooted in default ISPs.
3.3 vN-Bone Formation
Sections 3.1 and 3.2 described how IPvN packets are steered to
IPvN routers. We now describe how these IPvN routers cooper-
ate to form a “virtual” IPvN network, or vN-Bone, overlaid on an
Internet where IPv(N-1) is ubiquitously deployed.
Before delving into the details of our mechanisms, we make two
observations: the ﬁrst is that, unlike the case of network redirec-
tion which must be ubiquitously supported (whether explicitly as
in option 1 for inter-domain anycast, or implicitly as in option 2 for
inter-domain anycast, as described in Section 3.2) by both partici-
pant and non-participant providers, vN-Bones are implemented en-
tirely by participant ISPs and hence this design space is much less
constrained. Indeed, many of the techniques from the literature on
overlays and testbeds [18, 20, 21, 21, 23] could likely ﬁnd use here
and, as such, our proposals are best viewed as one set of candi-
date solutions. The second observation is that virtual networks that
span multiple ISPs are not new. Networks like the MBone [25] and
6Bone were all pioneering efforts in this respect. These networks
relied greatly on manual conﬁguration and, while the solutions we
present do automate much of the topology construction and main-
tenance process, we readily accept that many ISPs might, as in the
past, simply choose to conﬁgure their networks by hand.
There are two main components to a virtual network:
1. virtual topology construction, and
2. routing over this virtual network
Note that because we do not assume ubiquitous deployment even
within a participant ISP, each of the above must be addressed at
both the intra and inter-domain level.
3.3.1 Topology Construction
The ﬁrst component – vN-Bone construction – is fairly straight-
forward as it largely builds off the connectivity information re-
vealed by the underlying IPv(N-1) routing protocols. For example,
the IPv(N-1) intra-domain routing, whether link-state or distance-
vector (and assuming the anycast extensions described in the pre-
vious section), ensures that every IPvN router has complete knowl-
edge of the set of IPvN routers within its domain.3 The intra-
domain vN-Bone topology can then be constructed through simple
rules such as: every IPvN router picks its k closest IPvN routers
as neighbors on the vN-Bone. In the event that such rules leads to
partitions, these can be easily detected and repaired because every
router has complete knowledge of all other IPvN routers.
At the inter-domain level, the most likely scenario is that ISPs
set up inter-domain tunnels based on their peering policies. In the
absence of such conﬁguration, a newly joined ISP could reuse the
anycast mechanism as the initial bootstrap by which to discover at
least one other ISP that currently supports IPvN; having done this,
the new ISP can discover additional neighbors through the inter-
domain vN-Bone routing (described below).4 For preventing parti-
tions of the inter-domain vN-Bone topology, one simple approach
is for every domain to ensure that it is connected (either directly or
indirectly) to the “default” provider of the anycast address.
Finally, as deployment spreads, the vN-Bone topology should
evolve to be congruent with the underlying physical topology. This
is easily achieved using the connectivity information revealed by
the v(N-1) routing protocols at the intra and inter-domain levels.
3.3.2 Routing in vN-Bones
Addressing. The issue of routing is closely tied to that of host
addressing. There are at least three aspects to addressing that to
3Recall our discussion in Section 3.2 about how such global knowl-
edge can be achieved even in distance-vector protocols like RIP
with one minor modiﬁcation. In the absence of this modiﬁcation,
intra-domain vN-Bone construction over RIP would have to be im-
plemented along the lines of the inter-domain vN-Bone construc-
tion; i.e., through explicit neighbor discovery leveraging anycast
for the initial bootstrap.
4Note that this use of anycast is only possible for a new ISP that
isn’t yet actively advertising the anycast. Otherwise, the anycast
route would simply loop back to the initiator.
C
`
Y
Z
IPv(N-1) 
“links”
IPv(N-1) 
router
Path to C w/ only BGPvN
 Last IPvN hop is X
IPvN 
router
ISP-O
IPvN
 “links”
Path to C with 
BGPv(N-1)+BGPvN
Last IPvN hop is Y
X
ISP-M
Z
IPv(N-1) inter-
domain links
IPvN inter-
domain links
C
N
B
Path from A to Z with 
advertising-by-proxy. 
M
Path from A to Z without  
advertising-by-proxy. 
A
Figure 3: Inter-domain vN-Bone Routing: IPvN border routers
must run BGPvN and, in addition, obtain BGPv(N-1) information
from IPv(N-1) border routers.
Figure 4: Inter-domain vN-Bone Routing: advertising-by-proxy;
ISPs A, B and C support IPvN. ISPs M, N and Z support only
IPv(N-1). Hence, B and C advertise their distance to Z into the
BGPvN routing protocol.
be considered: (1) the format or structure of addresses, (2) address
allocation and, (3) advertising addresses into the routing fabric.
In today’s Internet, the allocation and advertisement of an end-
host’s IPv4 address is handled by its local access provider. If future
IPvN architectures adopt a similar model then supporting univer-
sal access raises the question of how an endhost might obtain an
IPvN address if its access provider does not yet support IPvN. A
possible solution, along the lines proposed in RFC 3056 [34], is to
have the endhost assign itself a unique IPvN address. This can be
done, for example, by using one address bit to indicate such “self
addressing” and deriving the remaining IPvN address bits from the
endhost’s unique IPv(N-1) address. Note that these self-addresses
are very likely temporary and such endhosts will have to relabel
if and when their access providers do adopt IPvN. This leaves us
then with the question of how such temporary IPvN addresses are
advertised and routed on. We explore this question in detail in the
discussion on routing that follows. Finally, we note that this need
for self-addressing arises in the case where address assignment is
handled by an endhost’s local provider. More generally however,
we place no particular constraints on the addressing structure or
allocation policy a next-generation IPvN may adopt.
Routing. In considering routing on this virtual network, we have
to do so at two levels:
(cid:127) routing between IPvN routers on the vN-Bone, and
(cid:127) routing between any two IPvN endhosts
The two issues are closely related – given the ability to route
between IPvN routers, routing between two IPvN endhosts is pri-
marily a question of how we ﬁnd the appropriate ingress and egress
IPvN routers for a given source and destination IPvN endhosts.
Note that most discussions of routing, whether application layer
as in overlays, or at the IPv4 network layer, need not distinguish be-
tween the two cases above. The current network layer assumes that
an endhost’s ingress or egress router is simply its access router and
hence this distinction in unnecessary. Unfortunately, our need for
universal client access under partial IPvN deployment makes this
assumption invalid (at the IPvN layer). Proposed overlay-based
routing systems [9, 20] on the other hand, assume some form of
higher-layer (e.g., DNS) or out-of-band translation between an end-
host identiﬁer and its “attachment” point in the overlay. This trans-
lation can be invoked prior to communication between two end-
hosts and hence the issues of routing between endhosts is easily
mapped to that of routing between two overlay routers. In our case
however, there are a number of reasons why we might not want to
make a similar assumption. First, endhosts are not assigned explicit
attachment points in the vN-Bone. Moreover, an endhost might
have different attachment points depending on the network loca-
tion of the endhost it is communicating with and these attachment
points will change as deployment spreads. Most importantly, this
option raises issues similar to those with application-level redirec-
tion (Section 2.2) – given our self-imposed reluctance to assume the
introduction of new services, it isn’t clear who can effect this trans-
lation or how, because doing so would require intimate knowledge
of the state of IPvN deployment.
Between routers:. The topology construction in Section 3.3.1
described the global vN-Bone as composed of intra-domain vN-
Bone topologies interconnected by inter-domain tunnels. Given
this topology, establishing routes between IPvN routers is achieved
by IPvN routing protocols and will thus depend on the speciﬁcs of
a particular IPvN. The space of possible routing solutions here is
fairly unconstrained as the participant nodes are all IPvN routers.
In the discussion that follows, we assume the existence of sepa-
rate intra and inter-domain IPvN routing protocols but assume no
speciﬁc routing algorithm. For simplicity, we use the notation BG-
PvN to denote the IPvN inter-domain routing protocol even though
BGPvN need not strictly resemble today’s BGP.
Between endhosts:. We consider the problem of routing be-
tween endhosts in the face of partial IPvN deployment at the inter-
domain level; the intra-domain case follows along similar lines.
The question of ﬁnding an appropriate ingress router is easily
resolved by our use of anycast for redirection. An IPvN packet
injected by a source host will, through anycast, ﬁnd its way to an
ingress IPvN router without special support or conﬁguration by the
endhost. Hence the main question is that of ﬁnding an appropriate
egress IPvN router. If the destination is in an IPvN domain, this is
simple. In this case, the destination has a routable IPvN address,
its home domain advertises this address into the IPvN-Bone rout-
ing topology and hence all IPvN routers know how to forward the
packet through to that address. In other words, in this case, routing
is based entirely on the IPvN destination address, using the IPvN
routing protocols.
The case where the destination IPvN client is not in an IPvN
enabled domain is less obvious. Recall that such a client has an un-
advertised, temporary IPvN address. One apparently simple option
would be to have the IPvN client use anycast to locate a closeby
IPvN router and have that router advertise the client’s temporary
IPvN address. An endhost would periodically repeat this process
in order to adapt to spread in deployment as also to router and net-
work dynamics. While simple, this is somewhat of a departure from
existing norms for route advertisement. Endhosts today are not in-
dividually responsible for route advertisement nor do routers typi-
cally accept direct route advertisements from remote endhosts (or
even remote routers); the security and policy implications of such
a change are an open question. Moreover, this introduces a form of
fate-sharing between an endhost and its route advertisement that,
again, isn’t common today. Finally, such routes for temporary IPvN
addresses would be injected into the IPvN routing protocol and it
isn’t clear how this would constrain the design space for routing
and addressing at the IPvN layer. For these reasons, in the remain-
der of this paper we do not adopt the above solution. Instead, we
look for solutions that place the burden of locating an appropriate
egress IPvN router on the IPvN routers themselves rather than on
endhosts. Nonetheless, the simplicity of this anycast-based scheme
is appealing and should be considered in the case of IPvNs where
the above issues turn out to not be problematic.
A different option is to leverage the destination’s IPv(N-1) ad-
dress and IPv(N-1) routing information. The destination’s IPv(N-1)
address could either be inferred from its temporary IPvN address or
might be carried in a separate option ﬁeld in the IPvN header. Here
again, there are multiple possible options.
The simplest option is to simply exit the vN-Bone and forward
the packet directly to the destination’s IPv(N-1) address. This how-
ever fails to fully exploit IPvN deployment. Consider for example,
the scenario in Figure 3. Here, the IPvN border router X in ISP do-
main M does not contain an IPvN-level route to client C and hence
would just deliver the packet directly to C over IPv(N-1) effectively
“exiting” the vN-Bone at X. Ideally however, X could have for-
warded the packet over the vN-Bone to Z in ISP-O and from there
to Y at which point the packet would exit the vN-Bone and be tun-
neled to C. This would be possible were M’s IPvN border routers
aware of the IPv(N-1) domain-level path between ISP M and C’s
domain. This is easily achieved by having an IPvN border router
acquire BGPv(N-1) routing tables from its domain’s IPv(N-1) bor-
der router. In addition, the IPvN router must know the IPv(N-1)
domain associated with the different IPvN border routers (in this
case Z). This too can be easily achieved by having IPvN border
Domain
BGPv(N-1) path
IPvN? w/ adv-by-proxy
C
N
B