them, in the absence of proper permissions. Speciﬁcally, our
reader is designed to work on touch events and capable of
extracting the coordinates (ABS_X, ABS_Y) of any touch on
the screen, together with its status (ABS_PRESSURE with 0
for up and 1 for down). The input reader can be embedded into
a malicious app running in the background and silently logging
all the touch events from the screen. Since a phone’s keyboard
layout is ﬁxed, the app can easily identify all the keys the
user enters from those events. The consequence of this attack
is serious, which allows an unprivileged adversary to steal the
phone user’s password and any sensitive information she types
through the touchscreen. Given the popularity of Galaxy SII
and other phones with the same vulnerabilities, this problem
affects millions of Samsung customers. A video demo of the
attack [1], which shows the input reader recording coordinates
of touch events, is posted online.
Camera attack. Our automatic analysis detected the exposure
of the camera device node on Galaxy SII, a problem that
also exists on other popular phones (Section V). Speciﬁcally,
the ﬁle (/dev/video0) of Galaxy SII was correlated to the
device node on the reference from their argument ﬁngerprints,
and it was also found to be public. With this device node’s
complete disclosure, one can take pictures without any camera-
access permission in theory. However, exploiting this ﬂaw
in practice is highly nontrivial, as the driver is customized
and Samsung never provides any documentation about how
3The two camera LCFs are similar. We just exploited one of them.
4The number may change depending on the systems and conﬁgurations.
416
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:57:07 UTC from IEEE Xplore.  Restrictions apply. 
TABLE V.
LCFS DETECTED BY RISK IDENTIFIER
Device
camera
input
framebuffer
Nexus 4
/dev
video0(rear)
video1(front)
input/event*
graphics/fb*
Galaxy SII
/dev
mod owner
660
660
660
660
system:camera video0(front)
system:camera video1(rear)
input/event*
root:input
root:graphics
graphics/fb*
Galaxy ACE 3
/dev
owner
system:root
video0
system:camera video1
root:input
root:graphics
mod
660
660
input/event* 660
graphics/fb* 666
mod
666
666
666
660
owner
system:camera
system:camera
root:input
system:graphics
Galaxy GRAND
mod
/dev
666
vchiq
vc-cam
666
input/event* 660
graphics/fb* 660
owner
system:system
system:system
root:input
root:graphics
to directly work on it. Following we describe our end-to-end
attack on this vulnerability.
rear channel
To communicate with the camera device, we ﬁrst tried the
operation sequence speciﬁed by the V4L2 standard [17] as
shown on the left column of Table VI. This approach turned
out to be ineffective and keep crashing and rebooting the
phone when we invoked the command VIDIOC_ENUM_FMT
through ioctl, which itself is a denial-of-service attack. To
ﬁnd out the correct way to take a picture, we ﬁrst analyzed
traces collected from normal operations
the system-call
of the camera on SII and found that
the sequence here
is different from that on Nexus 4. Speciﬁcally, we found
that
in Samsung SII, video0 is for both its front and
rear camera and a camera client needs to select the front
or
through VIDEO_S_INPUT before using
the camera. Even after we made the sequence right, our
app still caused the system to crash at VIDIOC_S_FMT, a
command for specifying the format parameters for pictures.
By digging the speciﬁcations for the camera chips used in
the phone (S5K5BAFX and M5M0), we ﬁnally realized
that Samsung customized the V4L2 protocol deﬁned in
videodev2.h with new settings. For example, the V4L2
standard buffer type v4l2_buf_type has been extended by
V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE,
adding
and
V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE
V4L2_BUF_TYPE_PRIVATE. We ended up implementing
the whole Hardware Abstract Layer (HAL) within our app,
based upon an open-source driver for the same chips [15].
Using our own HAL, we successfully commanded our at-
tack app (without any camera permission) to open the camera,
take pictures, retrieve camera raw data from the exposed device
and covert them from the YUV color space [18] to the RGB
color space [14] for constructing images.
TABLE VI.
DIFFERENCE OF CAMERA OPERATIONS ON NEXUS 4 AND
SAMSUNG SII
Nexus 4
open
VIDIOC QUERYCAP
Samsung SII
open
VIDIOC QUERYCAP
VIDIOC ENUMINPUT
VIDIOC S INPUT
VIDIOC S CTRL*
VIDIOC ENUM FMT
VIDIOC ENUM FMT
VIDIOC S FMT
VIDIOC REQBUFS
VIDIOC QUERYBUF
VIDIOC S FMT
VIDIOC REQBUFS
VIDIOC QUERYBUF
VIDIOC QBUF
VIDIOC QBUF
VIDIOC STREAMON
VIDIOC STREAMON
VIDIOC DQBUF
VIDIOC DQBUF
VIDIOC S CTRL
VIDIOC STREAMOFF
Operations
open camera device
query capabilities
enumerate video input
set the input
set white balance, mode,
focus
enumerate supported for-
mat
set format
allocate shared memory
query the status of the
buffer
exchange a buffer with
the driver
start or stop streaming
I/O
exchange a buffer with
the driver
pause in our case
close the stream
Again, our attack does not need any camera-access permis-
sions, and nor does it demonstrate any visual effects during
picture taking (such as showing preview in a normal use of
the camera). Therefore, it is completely stealthy to the phone
user. A video demo of the attack is here [1]. This problem
affects millions of phone users (Section V).
Screenshot capture. Screenshot taking is considered to be a
highly sensitive capability, which Google guards with a system
permission READ_FRAME_BUFFER and never grants to any
third-party app. Actually, apps that provide programmatic ap-
proaches to capturing screenshots need to either run on a rooted
phone or get the capability through Android Development
Bridge [10]. However, we found in our study that some
vendors expose this capability to the public. Speciﬁcally, on
Galaxy ACE 3 GT-7270L (running 4.2.2), the Linux standard
frame buffer device /dev/graphics/fb0 is set
to be
publicly readable and writable. The fb0 ﬁle is a hardware
independent graphic abstraction layer and contains the current
image on screen. We suspect that this oversight (exposure of
the frame buffer) could be caused by the attempt to provide a
customized screenshot capability for vendor pre-installed apps
such as screenshot for Samsung Note app. In our study, we
implemented an attack on this ﬂaw over Samsung Galaxy ACE
3, a phone model distributed in Latin America.
In the attack, again we implemented a malicious app that
runs as a background service and periodically reads from the
frame buffer. Each time, the app converts the content it gets
from the buffer into an image ﬁle (JPG) and saves it on
the phone’s SD card. Whenever the user is running sensitive
apps such as those providing ﬁnancial services (which can be
found out from the package names of the running processes),
the malicious app continuously takes screenshots to collect
sensitive user data. The demo of this attack is also online [1].
All those malicious apps can be made highly context-
aware: that is, they can continuously monitor what the phone
user is running and only start collecting information at the
right moment. This can be done through inspecting the list of
running processes and CPU, memory usages of those apps, as
proposed in prior research [46].
V. A LARGE-SCALE MEASUREMENT STUDY
Our study on 4 Android devices, as described in Section IV,
reveals the great impact of customization errors to Android
device security, which allow an unauthorized app to get access
to critical system capabilities on popular phones. What is less
clear is how pervasive those security-critical ﬂaws are across a
large number of phones, tablets and all kinds of Linux devices,
beyond those on our short list (Table V). Since it is hard to
get the answer to this question by running ADDICTED over
thousands of physical devices, we have to statically check
factory images. The problem is that without hardware, we
cannot perform the dynamic analysis to identify all customized
417
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:57:07 UTC from IEEE Xplore.  Restrictions apply. 
TABLE VII.
ANDROID FACTORY IMAGES COLLECTED BY OUR
CRAWLER
Version
4.0.3
4.0.4
4.1.1
4.1.2
4.2.1
4.2.2
4.3
TOTAL
# of Phone Models of each Version
16
113
48
159
1
59
21
417 (288 distinct models)
# of Images
109
564
238
1054
1
397
60
2423
device ﬁles even for those on our short list. All we can do is
to use the names of the device related ﬁles on the reference
to search for those on customized images to ﬁnd out whether
they are as well protected there as on the reference.
Also we want to go beyond the devices on the list. Device
nodes are typically located under /dev with some of them
placed under /sys. Finding what hardware pieces those
individual ﬁles serve is challenging. In our research, we just
blindly compared them with their counterparts on the reference
according to their names, to get some clues about whether
they are well conﬁgured based on their Linux permission
settings. Another trouble here is that /sys and /dev are
actually dynamically generated by the Linux init process.
To ﬁnd out those virtual ﬁles’ security settings, we resorted
to the conﬁguration ﬁles that init utilizes to determine
their protection levels. Speciﬁcally, when Linux initializes,
init runs the ueventd process to read from ueventd.rc
and ueventd.$HARDWARE.rc settings of different device
nodes. In our research, we just extracted these two ﬁles from
factory images and used them to analyze device-related ﬁles’
Linux protection. Following we ﬁrst explain the methodology
used in our study and then present the ﬁndings we made.
A. Methodology and Data
As discussed above, the methodology of our measurement
study is to analyze the conﬁguration ﬁles of different factory
images, comparing the device settings on these images (as
recorded in the ﬁles) with those on the reference to identify
LCFs. Most important to this study is to ﬁnd out as many
images as possible to collect their conﬁguration ﬁles. Here we
discuss how this was done in our research.
Factory image collection. Although vendors release the
source code of their Android updates, they typically do not
make public the conﬁguration ﬁles we are looking for. Those
ﬁles can only be extracted from factory images. In our study,
we developed a crawler that automatically checks top image
storing websites,
including Samsung update [5] and full-
ﬁrmwarec [4], to download those images. From all the images
there, we selected one image for each phone model each
version (at
least 4.0). In total, our crawler gathered 2423
images covering 417 phone models ranging from android 4.0
to 4.3 and total of 2.5TB disk size. Table VII summarizes
the scale of our study. (Note that one phone model even at
one speciﬁc version may have multiple images for different
countries or regions.)
Conﬁguration ﬁle extraction. The factory image we down-
loaded is usually in zip or tar format. To extract from
it
the conﬁguration ﬁles, our approach ﬁrst unzipped the
Fig. 3. Number of phone models with the 3 conﬁrmed vulnerabilities. No
data is available for gray areas.
image to search for zImage or boot.img. Then it ran
zImageTool and Boot-Image-tools [9] to split the image into
kernel and ramdisk. From the ramdisk part, we retrieved the
.rc conﬁguration ﬁles. Those ﬁles were parsed and their
relevant content was stored into a database. During this pro-
cess, ueventd.$HARDWARE.rc was always processed after
ueventd.rc, as the conﬁgurations in the former overrule
those in the latter during Linux initialization.
All the ﬁle settings from one image were then compared
with those on the reference with the image’s Android version.
For example,
the two conﬁguration ﬁles from a Samsung
customized 4.0.4 were analyzed against those on AOSP 4.0.4.
B. Results
Pervasiveness of LCFs. Our study shows that security hazards
of device customizations are indeed pervasive. Table VIII
summarizes the total number of LCFs we found. From the
table, we can see that 1290 (53.24%) images we studied
contain LCFs. More speciﬁcally, they include at least one
device ﬁle whose protection level is set to be publicly readable
and writable, way below that of the same ﬁle on the reference.
We found that such LCFs affect 75.65% of the distinct phone
models and 86.65% of the carriers we studied.
We also measured the magnitude of the conﬁrmed vulner-
abilities we exploited (Section IV). Table VIII shows the per-
vasiveness of these ﬂaws across different customized devices.
Just for an example, the problem with the camera driver was
found within 952 images for 72 phone models.
Distribution of the ﬂaws. We further studied the distribution
of the LCFs across different geo-locations. For this purpose, we
identiﬁed the countries of different factory images and mapped
to them the number of the phone models in those individual
countries affected by the 3 conﬁrmed ﬂaws (Section IV-B).
Figure 3 illustrates the results, which are presented on the
Google maps. Interestingly, we found that developing countries