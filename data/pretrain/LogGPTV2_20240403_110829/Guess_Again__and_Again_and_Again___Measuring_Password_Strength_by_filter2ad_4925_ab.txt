as the dictionary.
comprehensive8:
Participants were given the email sce-
nario and the composition policy “Password must have at
least 8 characters including an uppercase and lowercase
letter, a symbol, and a digit. It may not contain a dictionary
word.” We performed the same dictionary check as in dic-
tionary8. This condition reproduced NIST’s comprehensive
password-composition requirements [11].
blacklistEasy: Participants were given the email scenario
and the composition policy “Password must have at least
8 characters. It may not contain a dictionary word.” We
checked the password against the simple Unix dictionary,
ignoring case. Unlike the dictionary8 and comprehensive8
conditions, the password was not stripped of non-alphabetic
characters before the check.
blacklistMedium:
except we used the paid Openwall list.
blacklistHard: Same as the blacklistEasy condition, except
we used a ﬁve-billion-word dictionary created using the
algorithm outlined by Weir et al. [25]. For this condition, we
trained Weir et al.’s algorithm on the MySpace, RockYou,
and inﬂection lists. Both training and testing were conducted
case-insensitively, increasing the strength of the blacklist.
Same as the blacklistEasy condition,
These conditions represent a range of NIST entropy
values: 18 bits for basic8 and basic8survey, 30 bits for com-
prehensive8 and basic16, and 24 bits for the four dictionary
and blacklist conditions [11], [46]. We test the increasingly
popular blacklist approach (see Section II) with a wide range
of blacklist sizes.
D. Participant demographics
Of participants who completed part one of our study, 55%
returned within 3 days and completed part two. We detected
no statistically signiﬁcant differences in the guessability of
passwords between participants who completed just part one
and those who completed both. As a result, to maximize data
for our analyses and use the same number of participants
for each condition, our dataset includes passwords from
the ﬁrst 1,000 participants in each condition to successfully
complete the ﬁrst part of the study. To conduct a wider
variety of experiments, we used data from an additional
2,000 participants each in basic8 and comprehensive8.
Among these 12,000 participants, 53% percent reported
being male and 45% female, with a mean reported age of
29 years. This sample is more male and slightly younger
than Mechanical Turk participants in general [14], [16].
About one third of participants reported studying or working
in computer science or a related ﬁeld. This did not vary
signiﬁcantly across conditions, except between blacklistEasy
and blacklistHard (38% to 31%; pairwise Holm-corrected
Fisher’s exact test [PHFET], p  0.05).
IV. METHODOLOGY: DATA ANALYSIS
This section explains how we analyzed our collected
password data. First, and most importantly, Section IV-A
discusses our approach to measuring how resistant pass-
words are to cracking, i.e., guessing by an adversary. We
present a novel, efﬁcient method that allows a broader
exploration of guessability than would otherwise be possible.
For comparison purposes, we also compute two independent
entropy approximations for each condition in our dataset,
using methods described in Section IV-B.
A. Guess-number calculators
Traditionally, password guess resistance is measured by
running one or more password-cracking tools against a
password set and recording when each password is cracked.
This works well when the exploration is limited to a
relatively small number of guesses (e.g., 1010, or roughly
the number of guesses a modern computer could try in
one day). However, as the computational power of potential
adversaries increases, it becomes important to consider how
many passwords can be cracked with many more guesses.
To this end, we introduce the guess-number calcula-
tor, a novel method for measuring guess resistance more
efﬁciently. We take advantage of the fact that, for most
deterministic password-guessing algorithms, it is possible to
create a calculator function that maps a password to the
number of guesses required to guess that password. We
call this output value the guess number of the password.
A new guess-number calculator must be implemented for
each cracking algorithm under consideration. For algorithms
(e.g., [13]) that use a training set of known passwords to
establish guessing priority, a new tuning of the calculator is
generated for each new training set to be tested.
Because we collect plaintext passwords, we can use a
guessing algorithm’s calculator function to look up the
associated guess number for each password, without actually
running the algorithm. This works for the common case
of deterministic guessing algorithms (e.g., [13], [27], [43],
[45]).
We use this approach to measure the guessability of a set
of passwords in several ways. We compute the percentage
of passwords that would be cracked by a given algorithm,
which is important because the most efﬁcient cracking tools
use heuristics and do not explore all possible passwords.
We also compute the percentage that would be cracked
with a given number of guesses. We also use calculators to
compare the performance of different cracking algorithms,
and different training-set tunings within each algorithm. By
combining guess-number results across a variety of algo-
rithms and training sets, we can develop a general picture
of the overall strength of a set of passwords.
We implemented two guess-number calculators: one for a
brute-force algorithm loosely based on the Markov model,
and one for the heuristic algorithm proposed by Weir et al.,
which is currently the state-of-the-art approach to password
cracking [13], [31]. We selected these as the most promising
brute-force and heuristic options, respectively, after compar-
ing the passwords we collected to lists of 1, 5, and 10 billion
guesses produced by running a variety of cracking tools and
tunings. Henceforth, we refer to our implementations as the
brute-force Markov (BFM) and Weir algorithms.
1) Training sets: Both algorithms require a training set: a
corpus of known passwords used to generate a list of guesses
and determine in what order they should be tried.
We explore a varied space of training sets constructed
from different combinations of the publicly available word
lists described in Section III-B and subsets of the passwords
we collected. This allows us to assess whether comple-
menting publicly available data with passwords collected
from the system under attack improves the performance
of the cracking algorithms. We further consider training-set
variations speciﬁcally tuned to our two most complex policy
conditions, comprehensive8 and basic16.
In each experiment we calculate guess numbers only for
those passwords on which we did not train, using a cross-
validation approach. For a given experiment, we split our
passwords into n partitions, or folds. We generate a training
set from public data plus (n−1) folds of our data, and test it
on the remaining fold. We use each of the n folds as test data
exactly once, requiring n iterations of testing and training.
We combine results from the n folds, yielding guess-number
results for all of our passwords. Because training often
involves signiﬁcant computational resources, as described
in Section IV-A3, we limit to two or three the number of
iterations in our validation. Based on the similarity of results
we observed between iterations, this seems sufﬁcient. We
describe our training and test sets in detail in Appendix A.
We do not claim these training sets or algorithms repre-
sent the optimal technique for guessing the passwords we
collected; rather, we focus on comparing guess resistance
across password-composition policies. Investigating the per-
formance of guessing algorithms with different tunings also
provides insight into the kind of data set an attacker might
need in order to efﬁciently guess passwords created under a
speciﬁc password-composition policy.
2) BFM calculator: The BFM calculator determines
guess numbers for a brute-force cracking algorithm loosely
based on Markov chains [27], [43]. Our algorithm differs
from previous work by starting with the minimum length
of the password policy and increasing the length of guesses
until all passwords are guessed. Unlike other implementa-
tions, this covers the entire password space, but does not try
527
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:47:23 UTC from IEEE Xplore.  Restrictions apply. 
guesses in strict probability order.
The BFM algorithm uses the training set to calculate the
frequency of ﬁrst characters and of digrams within the pass-
word body, and uses these frequencies to deterministically
construct guessing order. For example, assume an alphabet
of {A, B, C} and a three-character-minimum conﬁguration.
If training data shows that A is the most likely starting
character, B is the character most likely to follow A, and C
is the character most likely to follow B, then the ﬁrst guess
will be ABC. If the next-most-likely character to follow B
is A, the second guess will be ABA, and so forth.
Our guess-number calculator for this algorithm processes
the training data to generate a lookup table that maps each
string to the number of guesses needed to reach it, as follows.
For an alphabet of N characters and passwords of length L,
if the ﬁrst character tried does not match the ﬁrst character
of the target password, we know that the algorithm will
try N L−1 incorrect guesses before switching to a different
ﬁrst character. So, if the ﬁrst character of the password
to be guessed is the k-th character to be tried, there will
be at least (k − 1)N L−1 incorrect guesses. We can then
iterate the computation: when the ﬁrst character is correct,
but the second character is incorrect, the algorithm will
try N L−2 incorrect guesses, and so forth. After looking
up the order in which characters are tried, we sum up the
number of incorrect guesses to discover how many iterations
will be needed before hitting a successful guess for a given
password, without having to actually try the guesses.
3) Weir algorithm calculator: We also calculate guess
numbers for Weir et al.’s more complex algorithm. The
Weir algorithm determines guessing order based on the
probabilities of different password structures, or patterns
of character types such as letters, digits, and symbols [25].
Finer-grained guessing order is determined by the probabil-
ities of substrings that ﬁt into the structure. The algorithm
deﬁnes a terminal as one instantiation of a structure with
speciﬁc substrings, and a probability group as a set of
terminals with the same probability of occurring.
As with the BFM calculator, we process training data to
create a lookup table, then calculate the guess number for
each password. The mechanism for processing training data
is outlined in Algorithm 1. To calculate the guess number for
a password, we determine that password’s probability group.
Using the lookup table created from the training set, we
determine the number of guesses required to reach that prob-
ability group. We then add the number of guesses required to
reach the exact password within that probability group. This
is straightforward because once the Weir algorithm reaches a
given probability group, all terminals in that group are tried
in a deterministic order.
Because creating this lookup table is time-intensive, we
set a cutoff point of 50 trillion guesses past which we do
not calculate the guess number for additional passwords.
This allows most Weir-calculator experiments to run in 24
hours or less in our setup. Using the structures and termi-
nals learned from the training data, we can still determine
whether passwords that are not guessed by this point will
ever be guessed, but not exactly when they will be guessed.
Algorithm 1 Creation of a lookup table that, given a proba-
bility group, returns the number of guesses required for the
Weir algorithm to begin guessing terminals of that group. An
l.c.s. is a longest common substring, the longest substrings in
a probability group made from characters of the same type.
For example, for UUss9UUU, the l.c.s.’s would be UU, ss, 9,
and UUU. (In this example, U represents uppercase letters,
s represents lowercase letters, and 9 represents digits.)
T = New Lookup Table
for all structures s do
for all l.c.s. ∈ pg do
for all probability group pg ∈ s do
ci=Number of terminals of l.c.s.
pi=Probability of l.c.s. in training data
end for
(cid:2)
pi; size =
probability =
T .add: pg, probability, size
(cid:2)
ci
end for
end for
Sort(T ) by probability
Add to each value in (T ) the sum of prior size values
Distributed computation. Calculating guess numbers for
Weir’s algorithm becomes data intensive as Algorithm 1 gen-
erates a large number of elements to build the lookup table
T . To accelerate the process, we implemented a distributed
version of Algorithm 1 as follows. We split the top-most
loop into coarse-grained units of work that are assigned to
m tasks, each of which processes a subset of the structures
in s. Each task reads a shared dictionary with the training
data and executes the two internal loops of the algorithm.
Each iteration of the loop calculates the probability and size
for one probability group in s. This data is then sorted by
probability. A ﬁnal, sequential pass over the sorted table
aggregates the probability group sizes to produce the starting
guess number for each probability group.
We implemented our distributed approach using Hadoop
[48], an open-source version of the MapReduce frame-
work [49]. In our implementation, all m tasks receive
equally sized subsets of the input, but perform different
amounts of work depending on the complexity of the struc-
tures in each subset. As a result, task execution times vary
widely. Nevertheless, with this approach we computed guess
numbers for our password sets in days, rather than months,
on a 64-node Hadoop cluster. The resulting lookup tables
store hundreds of billions of elements with their associated
probabilities and occupy up to 1.3 TB of storage each.
528
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:47:23 UTC from IEEE Xplore.  Restrictions apply. 
70%
60%
50%
40%
30%
20%
10%
d
e
k
c
a
r
c
s
d
r
o
w
s
s
a
p
f
o
e
g
a
t
n
e
c
r
e
P
1E1
1E0
1E4
Number of guesses (log scale)
1E2
1E3
basic8survey
basic8
blacklistEasy
blacklistMedium
dictionary8
blacklistHard
comprehensive8
basic16
1E5
1E6
1E7
1E8
1E9
1E10 1E11 1E12 1E13
Figure 1. The number of passwords cracked vs. number of guesses, per condition, for experiment E. This experiment uses the Weir calculator and our
most comprehensive training set, which combines our passwords with public data.
B. Entropy
To investigate how well entropy estimates correlate with
guess resistance, we compare our guess-number results for
each condition to two independently calculated entropy
approximations. First, we apply the commonly used NIST
guidelines, which suggest that each password-composition
rule contributes a speciﬁc amount of entropy and that the
entropy of the policy is the sum of the entropy contributed
by each rule. Our second approximation is calculated em-
pirically from the plaintext passwords in our dataset, using
a technique we described previously [9]. In this method,
we calculate for each password condition the entropy con-
tributed by the number, content, and type of each character,
using Shannon’s formula [50]. We then sum the individual
entropy contributions to estimate the total entropy of the
passwords in that condition.
V. FINDINGS
We calculated guess numbers under 31 different com-
binations of algorithm and training data. Although we do
not have space to include all the results, we distill from
them four major ﬁndings with application both to selecting
password policies and to conducting password research:
• Among conditions we tested, basic16 provides the
greatest security against a powerful attacker, outper-
forming the more complicated comprehensive8 con-
dition. We also detail a number of other ﬁndings
about the relative difﬁculty of cracking for the different
password-composition policies we tested.
• Access to abundant, closely matched training data is
important for successfully cracking passwords from
stronger composition policies. While adding more and
better training data provides little to no beneﬁt against
passwords from weaker conditions, it provides a sig-
niﬁcant boost against stronger ones.
• Passwords created under a speciﬁc composition policy
do not have the same guess resistance as passwords
selected from a different group that happen to meet the
rules of that policy; effectively evaluating the strength
of a password policy requires examining data collected
under that policy.
• We observe a limited relationship between Shannon
information entropy (computed and estimated as de-
scribed in Section IV-B) and guessability, especially
when considering attacks of a trillion guesses or more;
however, entropy can provide no more than a very
rough approximation of overall password strength.
We discuss these ﬁndings in the rest of this section.
We introduce individual experiments before discussing their
results. For convenience, after introducing an experiment we
may refer to it using a shorthand name that maps to some
information about that experiment, such as P for trained with
public data, E for trained with everything, C8 for special-
ized training for comprehensive8, etc. A complete list of
experiments and abbreviations can be found in Appendix A.
A. Comparing policies for guessability
In this section, we compare the guessability of passwords
created under the eight conditions we tested. We focus on