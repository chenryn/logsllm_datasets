determine whether the database instance has been tampered with.
However, for forensic investigations, it is often important to pinpoint
the modiﬁed tuples. We propose a solution to this problem.
When an audit fails, the forensic analysis process steps through
each table of the previous snapshot, computing a new relation
Hashes that contains (t.k, H(t)) for each tuple t with key k and
cryptographic hash H(t). Then the forensic analysis process steps
through L, ﬁnding each new tuple t(cid:48) and computing its hash H(t(cid:48)).
The forensic analysis ﬁnds the key of t(cid:48) in Hashes and changes
the value H(t) stored there to be ADD_HASH(H(t), H(t(cid:48))). To
make this fast, we can build a B+-tree over the key attributes of
Hashes and use it to ﬁnd each key as needed. Alternatively, we
can scan the log and compute all the new (t(cid:48).k, H(t(cid:48))) values, sort
them on k, and then do a zigzag join (i.e., merge join with auxiliary
indices) of them with Hashes, updating the content of Hashes
each time we ﬁnd a matching tuple.
Finally, the forensic analysis considers each tuple in the current
instance of the database, checking whether its hash is what is stored
for its key k in Hashes, and marking the key k in Hashes as
having been matched with a key from the current instance. This can
be sped up by using any available B+-trees for the two relations.
Mismatched hash values indicates tampering, as does the absence
of k in Hashes. At the end of the pass over current DB, if any keys
in Hashes have not been matched, that also indicates tampering. If
audit failures are common, then after repair and successful re-audit,
the auditor can sign Hashes and store it on WORM for future use.
7. EMPIRICAL EVALUATION
Setup. To evaluate TLOW performance, we used the Shore imple-
mentation [24] of the industry standard TPC-C benchmark, ported
to run on BerkeleyDB 4.7.25. The DBMS ran on a server with a
Pentium dual core 2.8 GHz CPU, 512KB L2 cache, 4GB RAM, and
a 1TB hard disk. We simulated the WORM server using a Pentium
2.8 GHz single core CPU, 512KB L2 cache, with a portion of its
local disks exported as an NFS volume. The DBMS mounted the
WORM volume over NFS and stored the logs there. We ran AH on
the DBMS server. AH can be run on a separate server and still utilize
of the warm WORM cache, but its overhead is so small that we left
it on the DBMS server. We also measured LDA’s performance in
our setting where the WORM stored the LDA compliance log.
We ran 100,000 transactions with a 512 MB DBMS cache and a
10 warehouse TPC-C conﬁguration, resulting in a 2.5 GB database.
We ensured that the ﬁle system caches on the WORM and DBMS
servers were cold at the start of each run. For runs without support
for term-immutability, we used the DBMS’s default maximum log
ﬁle size of 10MB. When this size is reached, the DBMS starts a
new log ﬁle, resulting in 232 log ﬁles per run, of size 2.32 GB. The
log creation rate averaged 38 MB/min. For runs with support for
term-immutability, every r/2 seconds we called a DBMS function
to ﬂush and close the log ﬁle and started a new log ﬁle. AH polls
the log directory on the WORM, and on ﬁnding a new log ﬁle, it
hashes the ﬁle’s newly inserted tuples and ﬂushes the results to an
H log ﬁle on WORM every r/2 seconds.
TLOW and AH TPC-C performance. We measured TPC-C per-
formance in the TLOW architecture with regret intervals r of 30
seconds, 2 minutes, and 5 minutes. We also measured TPC-C perfor-
mance under the TLOW architecture, with an audit helper AH. The
resulting TPC-C run times are shown in Figure 7. With a 2 minute
or a 5 minute regret interval, we have less than 1% overhead in all
cases up to 100K transactions when using the TLOW architecture.
For a 30 second regret interval, the overhead is always less than 2%.
In general, the faster the DBMS generates log records, the lower the
246
Figure 7: TPC-C run times with unmodiﬁed BerkeleyDB, LDA
with regret interval 300 sec., TLOW with regret interval 300
sec., TLOW with regret interval 120 sec., TLOW with regret
interval 30 sec., and TLOW with AH and 30-sec. regret interval.
As the overheads are less than 1% for both TLOW-300 and
TLOW-120, less than 2% for TLOW-30, and less than 4% with
TLOW-30-AH, the curves almost coincide. In contrast, LDA
without hash-page-on-read had an overhead of 14%.
overhead will be. AH added less than 1.5% overhead, and processed
L ﬁles much faster than the DBMS generated them. To compare
TLOW with LDA, we ran TPC-C with LDA, with a regret interval of
5 minutes. The measured overhead (without the hash-page-on-read
reﬁnement) was 14%. For non-probabilistic detection of untam-
per attacks, previous experiments show that the extra overhead for
hash-page-on-read reﬁnement is 10% on our platform [16].
Audit includes the tuple completeness check, the integrity check
on the current DB instance, and (for non-probabilistic detection of
untamper attacks) the check of the hashes of pages read by transac-
tions. The integrity check must be done at regular intervals, even
without auditing for compliance. The costly steps of the tuple com-
pleteness check are hashing the new tuples in L and in the current
DB. Figure 8 shows that the new tuples of 100K TPC-C transactions
on L can be hashed in less than a second when H ﬁles are available
for all transactions; if no H ﬁles are available, hashing takes about
100 seconds. As AH can easily keep up with the DBMS, we expect
that after a year, H ﬁles will be available for almost all committed
transactions. This implies that the time to scan H ﬁles from a year
of non-stop TPC-C will be just under two hours.
To hash the current DB, page fetches are a major expense. The
overhead of parsing and hashing fetched pages after 100K transac-
tions, given that the pages were already in the ﬁle system cache, was
8 seconds. Thus the time to parse and hash a year of TPC-C tuple
versions is less than 20 hours. If an ordinary DB integrity check is
being performed, then each page must be parsed anyway and the
additional cost to hash the tuples is miniscule. We conclude that in
practice, the tuple completeness check will be so affordable that the
organization should be able to perform an informal audit whenever
it runs a routine integrity check on its DB.
8. RELATED WORK
Researchers have looked into several aspects of compliance for
database data. We have already described LDA [16], which offers
a different approach to the same problem that TLOW addresses.
247
Figure 8: Audit time for the transaction log. Without any opti-
mizations, the log ﬁle audit time is approx. 100 sec. for 100K
TPC-C transactions. With AH, the audit time drops to between
0.8 sec. (100% H ﬁles valid) and 35 sec. (50% H ﬁles valid).
Another recent innovation is a framework for auditing changes to
a database while respecting retention policies [13]. It focuses on
policy based redaction and removal of sensitive information from
the database and its history, and handling the uncertainties in answer-
ing audit queries The TLOW approach for ensuring that database
contents are term-immutable can be combined with this framework,
so that one can support audit queries over sensitive information
while guaranteeing that tampering with contents or history can be
detected. Researchers have addressed the related problem of writing
and enforcing tuple retention and shredding policies, expressed as
restrictions on the operations that can be performed on views [2].
Their approach relies on the DBMS to enforce the policies. TLOW
can augment this by protecting the database contents against tam-
pering by adversaries who gain superuser access, or even insiders
with incentives to tamper with the data. For example, suppose that a
skilled DBA opens the database ﬁle with a ﬁle editor or an uncerti-
ﬁed copy of the DBMS, and removes or alters some of its content.
TLOW can identify this tampering at the next audit.
Tamperproof database audit logs are another direction of research.
In one scheme [22], the transactional data is cryptographically
hashed by the DBMS, signed periodically by a trusted third-party
notary, and then stored in the database. Later, a validator veriﬁes
the current database state using the certiﬁed hashes. If tampering is
detected, a forensic analyzer helps to identify when and where the
database was tampered with. One drawback of this approach is that
newly added content can be tampered with until the next notariza-
tion, without subsequent detection. As the notaries are trusted third
parties, it is hard to shrink the notarization interval below, say, once
a day. The TLOW approach shrinks this window of vulnerability to
a minute or less, with minimal impact on transaction throughput.
Many researchers have tackled the security problems associated
with outsourced database and ﬁle management [6, 7, 15, 20, 25],
and cryptographic ﬁle systems [5, 9, 10, 18]. The high-level goals
of outsourcing research are for the data owner to receive integrity
guarantees for databases/ﬁles stored on untrusted servers, and cor-
rectness guarantees for DBMS/ﬁle system responses to user requests.
The assumption is that the data owner is trustworthy and will not
tamper with the data, but the storage server is untrustworthy. In data
retention scenarios, the WORM storage server is trusted, but we do
25003000350040004500Time (seconds)TPC-C RegularTPC-C TLOW (r=30)TPCC-TLOW-(r=120)TPCC-TLOW-AH (r=30)TPCC-TLOW-(r=300)LDA-No HPoRTPC-C(regular),vsTPC-CTPC-CintheTLOWmodel,r=30sec,withAHrunning.Thetotaloverheadislessthan4%TPC-C,intheLDAmodel,r=300sec.Theoverheadis14%0500100015002000020000400006000080000100000120000Time (seconds)Number of TransactionsTPC-C(regular),vsTPC-CintheTLOWmodel,withr=30sec,r=120sec,r=300sec.Becausetheoverheadsinallcasesarelessthan1.5%,the4curvesappeartocoincideNumber of Transactions5060708090100Audit time (seconds)AH (100%)AH (90%)AH (50%)AH (10%)AH (0%)Audit without AH010203040501000020000400006000080000100000Audit time (seconds)Number of TransactionsNumber of Transactions[9] M. Kallahalla, E. Riedel, R. Swaminathan, Q. Wang, and
K. Fu. Plutus: Scalable secure ﬁle sharing on untrusted
storage. In Proceedings of FAST, 2003.
[10] J. Li, M. N. Krohn, D. Mazières, and D. Shasha. Secure
untrusted data repository (SUNDR). In Proceedings of OSDI,
2004.
[11] D. Lomet, R. Barga, M. Mokbel, and G. Shegalov.
Transaction time support inside a database engine. In
Proceedings of ICDE, 2006.
[12] D. Lomet and B. Salzberg. The performance of a multiversion
access method. In Proceedings of SIGMOD, 1990.
[13] W. Lu and G. Miklau. Auditing a database under retention
restrictions. In Proceedings of ICDE, 2009.
[14] Microsoft Corporation. Windows kernel patch protection.
Online at http://www.microsoft.com/whdc/
driver/kernel/64bitpatch_FAQ.mspx.
[15] G. Miklau and D. Suciu. Implementing a tamper-evident
database system. In Proceedings of the Asian Computing
Science Conference, 2005.
[16] S. Mitra, M. Winslett, R. T. Snodgrass, S. Yaduvanshi, and
S. Ambokar. An architecture for regulatory compliant
databases. In Proceedings of ICDE, 2009.
[17] Network Appliance Inc. SnapLock Compliance and SnapLock
Enterprise Solution. Online at http://www.netapp.
com/products/software/snaplock.html, 2007.
[18] B. Schneier and J. Kelsey. Secure audit logs to support
computer forensics. ACM Trans. Inf. Syst. Secur.,
2(2):159–176, 1999.
[19] Securities and Exchange Commission. Guidance to
broker-dealers on the use of electronic storage media under
the National Commerce Act of 2000 with respect to rule
17a-4(f). Online at http:
//www.sec.gov/rules/interp/34-44238.htm,
2001.
[20] R. Sion. Query execution assurance for outsourced databases.
In Proceedings of VLDB, 2005.
[21] R. Snodgrass. Developing Time-Oriented Database
Applications in SQL. Morgan Kaufmann, 1999.
[22] R. T. Snodgrass, S. S. Yao, and C. S. Collberg. Tamper
detection in audit logs. In Proceedings of VLDB, 2004.
[23] M. Stonebraker. The Design of the POSTGRES Storage
System. In Proceedings of VLDB, 1987.
[24] University of Wisconsin. Shore - a high-performance,
scalable, persistent object repository. Online at
http://www.cs.wisc.edu/shore.
[25] M. Xie, H. Wang, J. Yin, and X. Meng. Integrity auditing of
outsourced data. In Proceedings of VLDB, 2007.
not trust the data owner who may have root access and powerful
incentives to tamper with the data.
Data retention is just one important aspect of SOX compliance.
Agrawal et al. [1] describe how databases can play an important role
in helping companies comply with many other aspects of Sarbanes-
Oxley, and present several open research problems.
9. CONCLUSION
In this paper, we proposed TLOW, an efﬁcient approach to sup-
porting term-immutable databases for regulatory compliance. T-
LOW stores the current DB instance on traditional storage and the
transaction log on a low-cost WORM storage server; the transaction
log is segmented in a manner that allows an auditor to detect a vari-
ety of attacks, including clock tampering. Our proof of correctness
for TLOW sheds light on a variety of potential attacks, including
one that causes trouble for LDA, a previously proposed approach.
Our experiments with TPC-C show that TLOW supports a regret
interval as small as 2 minutes with less than 1% slowdown in trans-
action throughput. That is, 2 minutes after a transaction commits a
new tuple, the tuple becomes term-immutable, in the sense that an
auditor can detect any subsequent attempts to tamper with it. This
is a signiﬁcant performance improvement over LDA – the previous
state of the art, and shows that TLOW is practical and efﬁcient for
OLTP applications where one can keep all past versions of tuples.
To make audits fast, we introduced a trustworthy audit helper
function that has no signiﬁcant impact on transaction performance,
yet speeds up audits enormously, reducing the cost of auditing the
transaction log by a factor of 100. We also show how to reduce the
cost of hashing the current DB instance to just a few seconds, by
piggybacking the task onto periodic database integrity checks.
Acknowledgments
This work was supported by NSF under the grants CNS-0716532,
IIS-0803280, and CCF-0938071. In addition, Hasan was supported
by the National Science Foundation under Grant #0937060 (sub-
award CIF-389) to the Computing Research Association for the
CIFellows Project.
10. REFERENCES
[1] R. Agrawal, C. Johnson, J. Kiernan, and F. Leymann. Taming
compliance with Sarbanes-Oxley internal controls using
database technology. In Proceedings of ICDE, 2006.
[2] A. A. Ataullah, A. Aboulnaga, and F. W. Tompa. Records
retention in relational database systems. In Proceedings of
CIKM, 2008.
[3] M. Bellare and D. Micciancio. A new paradigm for
collision-free hashing: Incrementality at reduced cost. In
Proceedings of EUROCRYPT, 1997.
[4] Congress of the United States. Sarbanes-Oxley Act. Online at
http://thomas.loc.gov, 2002.
[5] E.-J. Goh, H. Shacham, N. Modadugu, and D. Boneh. SiRiUS:
Securing remote untrusted storage. In Proceedings of NDSS,
2003.
[6] H. Hacigumus, B. Iyer, C. Li, and S. Mehrotra. Executing
SQL over encrypted data in database service provider model.
In Proceedings of SIGMOD, 2002.
[7] H. Hacigumus, S. Mehrotra, and B. Iyer. Providing database
as a service. In Proceedings of ICDE, 2002.
[8] C. S. Jensen and et al. The consensus glossary of temporal
database concepts - February 1998 version. In Temporal
Databases, pages 367–405, 1997.
248