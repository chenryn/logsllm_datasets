customers over the object(A, sales_process, object) (RELATION ?process HAS-PART ?part) ∧
internet and avoids object(B, customer, person) (ATTRIBUTE “Name” OF ?part INCLUDES “inform”) ∧
unwanted predicate(C, event, inform, A, B) (ATTRIBUTE “Name” OF ?part INCLUDES “customer”) ∧
solicitations with an object(D, internet, object) (RELATION ?part USES-MECHANISM ?mechanism) ∧
opt-out list? modifier(C, instrument, over, D) (ATTRIBUTE “Name” OF ?mechanism INCLUDES “internet”) ∧
object(E, solicitation, object) (RELATION ?part HAS-EXCEPTION ?exception) ∧
property(F, unwanted, E) (ATTRIBUTE “Name” OF ?exception INCLUDES “unwanted”) ∧
predicate(G, event, avoid, A, E) (ATTRIBUTE “Name” OF ?exception INCLUDES “solicitation”) ∧
object(H, opt_out_list, object)
(RELATION ?exception IS-AVOIDED-BY ?handler) ∧
modifier(G, instrument, with, H)
(ATTRIBUTE “Name” OF ?handler INCLUDES “opt-out”) ∧
(ATTRIBUTE “Name” OF ?handler INCLUDES “list”)
Example 4: Transformation of "Which sales process informs its customers over the internet and avoids unwanted
solicitations with an opt-out list?"
For the non-trivial query presented in Example 4 the database contained four correct answers. Our NLP query
interface found three correct answers, missing one. The TFIDF-ranking found the correct answers at the 2nd,
35th, 47th, and 183rd positions. The simple keyword matcher returned no answers as the conjunction of all
keywords overconstrained the query. This example indicates that our approach – while maintaining natural
language simplicity – provides a performance akin to logic-based retrieval engines that usually outperform
precision and recall of keyword engines.
5. Limitations of Our Approach, Future Research, and Related Work
We can think of three limitations to the work presented in this paper. First, the use of a controlled language
imposes a cost on the user since the language has to be learned. Users might be discouraged from employing a
language they have to learn, but experience with ACE – and with other controlled languages such as Boeing
Simplified English [Wojcik 2004] – has shown that learning a controlled language is much easier than learning
logic, and takes only a couple of days for the basics and 4-6 weeks for full proficiency. Furthermore, some
researchers are currently developing query interfaces that will help people to write correct controlled English
sentences by guiding them as they write [Schwitter et al. 2004].
Second, our current prototype requires some manual adaptation of the rewrite rules when using it with a new
ontology or new knowledge base. Given our experience with hand-adaptation, we found that most of the time
an inspection of the meta-model was sufficient, and we believe that the rules could be automatically generated
based on the ontology structure.
Last but not least, the exemplary evaluation shown in this paper is clearly limited and can only provide an
idea of the potential of this approach. Consequently, the approach needs to be thoroughly evaluated. This
evaluation should include giving people retrieval tasks and comparing their performance using our front-end
with respect to other semantic web query tools based on plain logic, query by example, etc. Furthermore, we
would have to investigate how people’s retrieval performance is related to their background.
We did not find any other application of controlled natural language querying of semantic web content.
Furthermore, we found that work on natural language interfaces to data bases (not ontologized knowledge
bases) has largely tapered off since the 80’s [Androutsopoulos et al. 1995], even though the need for them has
become increasingly acute. The most closely related work we found is the PRECISE project [Popescu et al. 2003]
that proposes a natural language interface to relational databases. PRECISE uses a data-base augmented
tokenization of a query’s parse tree to generate the most likely corresponding SQL statement. It is,
consequently, limited to a sublanguage of English, i.e. the language defined by the subject area of the
database. In contrast, our approach limits the possible language constructs and not the subject domain.
Obviously, our front-end will not return any useful answers when none can be found in the ontology. It will,
however, be able to generate an appropriate PQL statement. We hope to be able to include an empirical
comparison between the two approaches in our future work.
The approach presented in this paper is clearly in its infancy. While ACE has been under development for
many years, the ontology-based transformation rules are very new. Nevertheless, we believe that people’s
familiarity with natural languages might be the key to simplify their interaction with vast ontologies and that
our approach, therefore, has the promise to provide an important step in bridging the gap between the
semantic web and its users.
46
AIS SIGSEMIS Bulletin 2(1) January-March 2005
Acknowledgements
The authors would like to thank the MIT Process Handbook project for making available the data on which
the evaluation is based, Stefan Höfler, and the anonymous reviewers for their helpful comments. This work
was partially supported by the Swiss National Science Foundation (200021-100149/1).
References
Androutsopoulos, I., Ritchie, G.D., and Thanisch, P. "Natural Language Interfaces to Databases - An
Introduction," Natural Language Engineering (1:1) 1995, pp 29-81.
Bonin, J. von, "From Discourse Representation Structures to Process Query Language - A Controlled Natural
Language Front-end to the Process Handbook," unpublished Diploma Thesis, Department of
Informatics, University of Zurich, 2004.
Fuchs, N.E. et al., Attempto Controlled English (ACE), www.ifi.unizh.ch/attempto, 2003.
Fuchs, N.E., Höfler, S., Schneider, G., and Schwertel, U. "Discourse Representation Structures of ACE 4
Sentences," IfI-2004, Technical Report, Department of Informatics, University of Zurich, 2004.
Kamp, H., and Reyle, U. From Discourse to Logic: Introduction to Modeltheoretic Semantics of Natural Language,
Kluwer, Dordrecht, Boston, London, 1993.
Klein, M., and Bernstein, A. "Towards High-Precision Service Retrieval," IEEE Internet Computing (8:1), January
2004, pp 30-36.
Malone, T.W., Crowston, K., Lee, J., Pentland, B., Dellarocas, C., Wyner, G., Quimby, J., Osborn, C., Bernstein,
A., Herman, G., Klein, M., and O'Donnell, E. "Tools for inventing organizations: Toward a handbook of
organizational processes," Management Science (45:3) 1999, pp 425-443.
Miller, L., Seaborne, A., and Reggiori, A. "Three Implementations of SquishQL, a Simple RDF Query
Language," The International Semantic Web Conference, Sardinia, Italy, 2002, pp. 423-435.
Popescu, A.-M., Etzioni, O., Kautz, H. "Towards a Theory of Natural Language Interfaces to Databases," 8th
International Conference on Intelligent User Interfaces, Miami, FL, 2003, pp. 149-157.
Salton, G., McGill, M.J. Introduction to modern information retrieval, McGraw-Hill, New York, 1983.
Schwitter, R., and Tilbrook, M. "Dynamic Semantics at Work," JSAI, Kanazawa, Japan, 2004.
Spoerri, A. "InfoCrystal: A visual tool for information retrieval management," Second International Conference
on Information and Knowledge Management, Washington, D.C., 1993, pp. 11-20.
Wojcik, R.H., Personal Communication, 2004 (Richard H. Wojcik is Manager of the Boeing Simplified English
Project).
47
AIS SIGSEMIS Bulletin 2(1) January-March 2005
SWAP - A Framework for Ontology Support in Semantic Web
Applications
Arijit Sengupta
Indiana University
Kelley School of Business
Bloomington, IN 47408, USA
Henry Kim
York University
Schulich School of Business
Toronto, Ontario M3J 1P3, Canada
Abstract
We present SWAP (Semantic Web Application Pyramid), a framework for incorporating ontologies in data-
oriented semantic web applications. We have implemented this framework with a measurement ontology for
a quality management web service. This quality management web service is built on top of a set of XML web
services implementing agents representing quality management clients, quality management servers and
vendors. SWAP facilitates data exchange between these web services with vendor data stored in databases,
and the processing of the data using a combination of RuleML and SQL. The testbed implementation
demonstrates the feasibility and scalability of the framework for any type of three-tier ontology-based
semantic web applications involving low to moderate data exchange. We discuss methods for improving this
framework for high data exchange volumes as well. The primary contribution of this framework is in the
component-based implementation of real world semantic web applications.
1 Introduction
The semantic web, introduced by Berners-Lee [1] opens the door to intelligent web applications. The concept
of the semantic web is still evolving, and needs the integration of several key technologies such as databases,
XML web services, and rule processing. We present SWAP (Semantic Web Application Pyramid) - a
framework with a three-tier architecture for developing semantic web applications, with or without agent
technology, and possible integration to databases. To demonstrate the applicability of this framework, we use
a measurement ontology to create a quality management web service for the semantic web using this
framework. Thus this paper serves the dual purpose of presenting the SWAP framework as well as its
prototypical application. The rest of this paper is organized as follows: in Section 2 we explore some
background in quality management, measurement ontologies and semantic web architectures. Section 3
presents the measurement ontology that we use. Section 4 presents the SWAP framework and the process of
integrating databases into the framework. Section 5 describes experiments with the framework, in particular
our testbed application using the presented measurement ontology. Finally we conclude in Section 6.
2 Background and Literature Review
Because of the length restriction, a full-length literature review is not included in this article. The primary
background of this paper is in software development protocols, and not simply ontology mediation, so here
we summarize some of the current efforts in software development protocols for the semantic web, and on the
development of quality measurement ontologies.
Application protocols for semantic web is not a highly researched topic. The most important problem in this
domain which is actively researched is metadata management. Shah and Seth [10] propose a model for
managing metadata in a distributed environment. Interoperation across ontologies is also heavily researched
and implemented (see e.g., [9]). We concentrate on a framework for appropriately and meaningfully
distributing both data and meta-data in SWAP, thereby creating a full environment where distributed
semantic web applications can be developed. OWL (Ontology Web Language) [11] is the culmination of W3C
48
AIS SIGSEMIS Bulletin 2(1) January-March 2005
and other researchers' efforts at developing a standardized ontology language for the semantic web. SWRL
(Semantic Web Rule Language) [6] combines the frame-based approach to knowledge representation of OWL
with the rule-based approach of RuleML (Rule Markup Language) [2] for the semantic web. Unfortunately,
automatic inference engines explicitly for these ontology languages are not as well-developed as XML query
engines [8], thus making the use of a hybrid approach such as SWAP pragmatic.
Though not specifically designed for the semantic web, there are ontologies that support day-to-day business
decisions such those made for quality control. These ontology-based enterprise modeling projects are the
Enterprise [12] and TOVE [3] projects. The Enterprise Ontology is comprised of ontologies of activity, time,
organization, strategy, and marketing. A “building block” approach is taken in the TOVE project to construct
ontologies of higher-level core concepts such as product, activity, state, causality, and time, resource
collectively called the activity-state ontology [4]. A fundamental domain necessary to execute ontology-based
web services is measurement, and a measurement ontology is built from the TOVE core ontologies. Though
other measurement ontologies do exist (e.g., [5]), they are not developed to support enterprise activities as
would be required for quality management web services.
3 The TOVE Measurement Ontology
For the purpose of our quality management case, we use the TOVE measurement ontology [7]. The TOVE
measurement ontology is designed explicitly with quality control in mind, rather than only the basic process
of measurement. A complete discussion of the ontology is out of the scope of this paper, here we only present
some of the most important terms and axioms.
TOVE Measurement Ontology terms are defined with propositions (or boolean terms) from the TOVE Core
Ontologies. The TOVE measurement ontology consists of 19 core terms, 16 terms and 3 axioms. Table 1 shows
some of the main terms and their descriptions.
4 The SWAP Framework
One of the most crucial parts of a semantic web application is the automation of the processing of ontologies.
We now present an architecture that supports one way of processing ontologies in a semantic web application.
This framework also has a three tier structure as shown in Figure 1.
1. The top tier is the client tier, consisting of clients or client agents, which are capable of sending requests
to the next tier. Clients can be users interacting with a user interface, or automated intelligent software
agents (ISAs). At this tier, clients pose queries using client ontologies and submit them to the next tier.
49
AIS SIGSEMIS Bulletin 2(1) January-March 2005
2. The next tier is the ontology processing tier. This tier uses the ontology, as well as any available
mapping techniques to process the queries coming from the client tier. All rules and axioms are
available at this layer for processing. Facts are retrieved as needed by sending appropriate queries to
the data layer. The retrieved facts can then be processed for the purpose of answering the client
queries.
3. The data layer consists of all the facts included in the knowledge base. The ontology processing layer
decides on which facts need to be retrieved, and sends appropriate queries to the data layer. The
queries are processed at the data layer using any necessary mapping methods, and resulting facts are
sent back to the ontology processing layer.
Figure 1: The SWAP pyramid showing the client, ontology and data layers, and the quality management
As an illustration of the above framework, let's consider a simple ontology for processing family trees. This
sample ontology consists of a single class Person, having properties hasSex, and hasChild. Represented in a
prolog-like format, a sample set of facts and rules in this ontology are shown in Figure 2:
Figure 2: A simple Family Tree Facts and Rules
In our framework, the client will issue a query such as ancestor(X,'Mike'), and would expect a response from
the ontology processor returning all possible substitution for the variable X. The ontology processor has all the
rules, and the data tier has all the facts. During the processing of the rules at the ontology processor, whenever
facts are needed, they are retrieved from the data tier. For example, in processing the above query, the system
will need to send the following fact queries to the data layer: (i) hasChild(X,'Mike'), (ii) hasChild(X, 'Joe') and
(iii) hasChild(X, 'Jill').
50
AIS SIGSEMIS Bulletin 2(1) January-March 2005
4.1 Integrating Databases
In the above discussion, we have not made any specific assumption about the data tier. Typically
organizational data is stored in relational databases, and agents in this tier would need to translate the fact
retrieval queries into SQL. This process is fairly trivial, since a fact retrieval can be translated into SQL by
simply placing constants in the query in the WHERE clause of the SQL statement. For example, in the above
example, a fact retrieval such as hasChild(X,'Mike') translates to the SQL query SELECT * from hasChild
WHERE col2='Mike' (assuming that the database has the hasChild stored in a table hasChild with columns
col1 and col2).
Integrating databases into the data tier enables the use of database query optimization techniques to speed up
the retrieval of the facts, which helps in the overall performance of the system in general. As shown in the
measurement ontology case above, the use of multiple agents at one or more levels also increases the
scalability of the system. Databases can be distributed over different agents and can be merged during the post
retrieval process. All of these advances are possible because of the separation of the different tiers, enabling a
form of data independence in semantic web applications.
5 Experiments with the SWAP Framework
We have implemented the SWAP Framework on several ontology-based applications, including test
applications like the simple family tree ontology above, as well as a complex quality management web service
using the measurement ontology discussed above. Here we describe our primary prototype case with a
quality management web service.
5.1 A Quality management web service using SWAP
A prototype application for simulated quality mediation between organizations has been developed,
completely using SWAP. The readers should note that the functionality of the mediation system was less
critical than the applicability of SWAP in its development, and as a generalized semantic web application
development protocol. In this section, we present a scenario that explains how the ontology and data queries
flow between the different layers. In the prototype system, we implemented all the SWAP layers using agents
implemented using J2EE web services, with two independent producer agents comprising the data tier, the
customer agents at the client tier, and the QM agent is at the ontology tier.
Information flow between SWAP Layers First the customer agent sends the quality requirements for a
receiving product to the Quality Management (QM) agent. The QM agent then classifies and stores these
requirements along with other customers. The QM agent can then play the role of a third-party responsible for
independent quality auditing, assurance, and control for the customer, automatically working with producer
agents to ensure compliance to quality requirements. The following provides a detailed excerpt of this
scenario.
1. The customer agent, org1, sends its quality requirements to the QM agent, qm0:
agent_sends(org1,qm0,q_requirement_bundle_from_org1).
q_requirement_bundle_from_org1 is a pointer to a hierarchy of quality sub-requirements.
2. The QM agent represents a hierarchy of requirements in the following exemplar way:
quality_requirement(q_requirement_bundle_from_org1),
has_requirement(q_requirement_bundle_from_org1,qreq1),
has_requirement(q_req1,q_req1_1).
3. If a requirement has no sub-requirements, e.g. q req1 1, then the QM agent translates the contents of
the requirement in the following exemplar way
primitive_requirement_measures_attribute(q_req1_1,widget_length),
has_standard_value(widget_length,15),
has_specification_set(widget_length,[14.5,15,5]),
has_unit_of_measurement(widget_length,cm).
Standard value is akin to mean; specification set, tolerance specifications.
51
AIS SIGSEMIS Bulletin 2(1) January-March 2005
4. These requirements are sent to producer agents, and results of their quality control measurements are
sent back to the QM agent:
measurement_point(batch22,widget_length, 14.8,10), where 14.8cm is the value of the
measurement and 10s the time of measurement.
5. Each measurement point is assessed by the QM agent as a conformance or nonconformance point, e.g.
conformance_pt(q_req1_1,batch22,widget length, 10). Reports of conformance are sent
to the customer agent for immediate action or periodic reporting.
6 Conclusion and Future Work
As shown in the quality management web service, the framework can be easily augmented with agents to
automate the process of exchange and retrieval. These experiments show the applicability of this framework
as a generalized method for implementing semantic web applications, with or without major data retrieval
tasks. We believe a generalizable framework for ontology and data-oriented semantic web applications is a