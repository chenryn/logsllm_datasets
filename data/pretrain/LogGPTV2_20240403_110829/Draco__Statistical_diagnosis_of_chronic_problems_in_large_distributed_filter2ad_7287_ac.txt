events as compare to failures. Sampling successful events as
they are read by the diagnosis engine yields both a signiﬁcant
reduction in overall memory utilization, and also signiﬁcantly
reduces the time to perform an analysis. To sample, we bin
each successful event based on its time slice, and keep 1
out of every Nth successful event
in each bin. Unbiased
random sampling preserves the correctness of the Bayesian
estimation of success and failure distributions as described
in Section III-B, and thus preserves the correctness of the
anomaly score of Equation 1. Its only impact is to reduce
the number of success events, and thus the uncertainty of
the success distribution. The results from our production runs
of Draco, discussed in Section VI, shows that sampling does
not appreciably impact Draco’s accuracy, but does increase its
speed by more than two orders of magnitude.
B. Visualization
Operators access the prototype via an interactive web-based
user interface. Figure 7 illustrates how the web-interface
facilitates the operator’s workﬂow.
1) The operator searches for the date and the types of
problems they are interested in analyzing. For example,
V. RESULTS FROM FAULT INJECTION STUDY
We conducted a fault
injection study to investigate the
effectiveness of Draco under a variety of precisely controlled
synthetic faults so that ground truth was known. We also
benchmarked our approach against Pinpoint [11] and Spec-
troscope [20].
A. Fault Injection Dataset
We simulated faults using actual call-detail records (CDRs)
of successful calls from the VoIP production system. We
divided the CDRs into 1-hour intervals to yield 500 hourly
traces. We injected faults by changing the labels of successful
calls, which contained attributes of interest, to failed calls.
The attributes of interest were individual network elements,
customer sites, links (routes), and their combinations. These
attributes were selected because they were the most common
features tracked by the operations team at the large ISP.
We randomly varied the combination of attributes associated
with each fault from 1 to 3, and ensured that these attributes
were not synonyms of each other. We also varied the number
of independent faults in each hourly trace from 1 to 3.
The probability of each fault injected ranged from 1% to
10% of calls containing the chosen attributes. In addition,
we investigated the effect of mislabeled data by incorrectly
labeling 5–20% of failed calls as successful, and randomly
labeling an equivalent number of successful calls as failed.
We sought to answer the following questions through fault
injection: 1) how does varying the fault probability impact
the effectiveness of diagnosis? 2) how well can we diagnose
complex failures involving multiple attributes? 3) can we
identify multiple concurrent faults? and 4) how does noise
due to mislabeled data affect diagnosis?
We evaluated the effectiveness of Draco based on the rank of
the correct root-cause in the diagnostic output, and computed
recall and mean-average-precision. Recall is the fraction of
injected faults that were correctly identiﬁed in the top-20
root-causes. Mean-average-precision is a measure of the false
positive rate, which is typically used to analyze the quality of
ranked search results. A high mean-average-precision indicates
that the algorithm had low false positive rates, and ranked the
relevant root-causes at the top of the list.
1. Problem1    STOP.IP-TO-PS.487.3     Chicago*GSXServers    MemoryOverload2. Problem2    STOP.IP-TO-PSTN.102    ServiceB                                                                CustomerAcme    IP_w.x.y.z2011-9-100:002011-9-124:002011-9-100:002011-9-124:00Zulu (GMT)Call countCall countView sample callsView sample callsFailed calls matching Problem2Failed calls matching Problem1FilterSearchRanked List of Problems213Log(y)Log(y)(a) Draco’s precision and recall remained relatively
constant despite variations in fault probability.
(b) Draco correctly identiﬁed complex prob-
lems involving a combination of attributes.
(c) Draco’s recall is robust to noise, and its preci-
sion is degraded in proportion to noise.
Fig. 8. Effect of variation in fault probability, number of attributes associated with each fault, and noise on Draco’s performance.
B. Draco’s Fault Injection Results
C. Benchmarking Against Existing Algorithms
Draco successfully diagnosed 97% of faults injected, with
lower than 4% false positives. All the false negatives occurred
when we injected two faults that were logically indepen-
dent, but happened to share a large intersection of attributes
correlated with the faults. In these cases, Draco typically
reported a single root-cause that listed the shared attributes. A
more detailed breakdown of the results of our fault injection
experiments is provided below.
1) Draco is robust to variations in fault probability. Fig-
ure 8(a) shows that Draco correctly identiﬁed the root-
cause of injected faults despite variations in the fault
probability; Draco’s precision and recall remained rela-
tively constant at >96% and >94% respectively.
2) Draco correctly diagnoses chronics triggered by com-
plex conditions. Figure 8(b) shows that Draco correctly
diagnosed chronics triggered by the interaction of two
or more attributes. Draco’s precision and recall were
slightly degraded from 99% to 98%, and 99% to 93%
respectively for chronics involving multiple attributes.
As explained above, this drop in recall was due to the
presence of faults that were not truly independent rather
than the number of attributes associated with each fault.
3) Draco is effective at diagnosing multiple concurrent
faults. Draco correctly ranked 97% of the relevant root-
causes within the top-3 likely causes of chronics. This
high ranking of likely root-causes allows operators to
quickly focus their attention on the most pressing issues.
4) Draco tolerates noise due to occasional mislabeling.
Figure 8(c) shows that Draco’s recall is robust to noise,
and that precision is degraded in proportion to noise. The
drop in precision is due spurious attributes introduced
by the incorrect labels. Draco’s ranking of likely causes
remained robust to noise—even when 20% of failed calls
were mislabeled, Draco correctly identiﬁed >94% of
injected faults within the top-3 likely causes.
We benchmarked our approach against Pinpoint [11] and
Spectroscope [20]. These diagnosis algorithms are most sim-
ilar to Draco as they rely on truth tables, and decision trees
that use information-theoretic splitting functions to identify
attributes most indicative of failures. We implemented the
decision tree algorithms using See5 [19], an open-source
implementation of the C5.0 algorithm written in C++.
1) Pinpoint: We implemented Pinpoint [11] by training a
decision tree using the labeled failed and successful calls. We
then diagnosed problems by examining each branch in the
decision tree whose leaf node classiﬁed failed calls, and ranked
the branches based on the number of failed calls. We observed
that precision and recall were primarily inﬂuenced by the ratio
of failed calls to successful calls in the dataset, as shown in
Figure 9. We varied this ratio by randomly sampling successful
calls, while leaving the number of failed calls unmodiﬁed. The
best performance was achieved when the ratio of failed to
successful calls was similar. Weiss and Provost [21] explain
that the performance of decision tree algorithms is degraded
when class distributions are imbalanced—these imbalances
are commonplace when diagnosing chronics as the number
of successes signiﬁcantly exceeds the number of failures. An
example of this degraded performance is shown in Figure 9
where recall dropped to 48% when the number of successful
calls outweighed the number of failed calls by a factor of 100.
In this case, often the best predictor was a decision tree with
no branches that always predicted success.
2) Spectroscope: Spectroscope [20] localizes the source of
performance degradations between two periods or executions
of a system to just a few relevant components. It does so
by leveraging the insight that such changes often manifest as
changes or mutations in the structure of individual requests
(e.g., the components visited, the functions executed, etc.) or
in their per-component latencies. Spectroscope identiﬁes mu-
tated request ﬂows from the problem period and localizes the
problem by showing how they differ from their precursors—
0.700.851.000.020.060.10Fault ProbabilityPrecision/Recall0.980.961PrecisionRecall0.700.851.00123Number of AttributesPrecision/Recall10.980.95PrecisionRecall051015200.700.851.00Noise (%)Precision/Recall0.970.730.95PrecisionRecallFig. 9. The performance of decision trees is inﬂuenced by the ratio of failed
to successful calls in the dataset. Performance degrades signiﬁcantly when
successful calls greatly outnumber failed calls in the dataset.
the way they were serviced in the non-problem period. Ad-
ditional localization is performed by using a decision tree to
identify low-level parameters (e.g., function calls) that best
differentiate a mutation from its precursor.
The fault models for Spectroscope and Draco are different—
Spectroscope targets problems that result in signiﬁcant perfor-
mance degradations, whereas Draco targets chronics. There-
fore, we implemented a modiﬁed version of Spectroscope-
mod where successful calls represent the non-problem period,
and failed calls represent the problem period. We investigated
whether sampling successful calls using the notion of precur-
sors (i.e, successful calls that were similar, but not identical to
failed calls), yielded better results than the random sampling
we employed for Pinpoint. We identiﬁed precursors by sam-
pling successful calls whose string-edit distance from failed
calls was below a predeﬁned threshold. We then localized the
root-cause of the problem using decision trees.
D. Benchmarking results
Figure 10(a) summarizes the overall mean-average-precision
and recall of Pinpoint2, Spectroscope-mod, and Draco when
diagnosing injected faults, in the absence of noise. Draco
performed better than both Pinpoint and Spectroscope-mod by
identifying 97% of injected faults with an average precision
of 99%. The precision of Pinpoint and Spectroscope-mod
were comparable, at 90%. Spectroscope-mod’s recall was 6%
higher than Pinpoint’s demonstrating that strategic sampling
of success data can improve performance.
The differences in performance between Draco and the
decision tree approaches were more pronounced when we lim-
ited our analysis to fault injection traces that either contained
multiple independent faults, or chronics triggered by complex
corner cases involving a combination of two attributes. Draco
correctly diagnosed up to 20% more injected faults for traces
containing multiple independent faults, as illustrated in Fig-
ure 10(b). Draco signiﬁcantly outperformed the decision tree
approaches for chronics triggered by a combination of two
2For Pinpoint and Spectroscope-mod, we sampled successful calls to yield
a 1:5 ratio of failed to successful calls, which provided the best performance.
(a) Overall, Draco performed better than both Pinpoint
and Spectroscope-mod at diagnosing chronics.
(b) Draco’s recall was higher by up to 20% for traces
containing multiple independent faults; Spectroscope-mod
performed 6% better than Pinpoint for these traces.
(c) Draco outperformed both Pinpoint and Spectroscope-
mod, with a recall of up to 56% better for complex chron-
ics triggered by a combination of 2 or more attributes.
Fig. 10. Benchmarking Draco against Pinpoint and Spectroscope-mod.
or more attributes, achieving a recall of up to 56% higher as
shown in Figure 10(c).
The reasons for the degraded precision and recall for
Pinpoint and Spectroscope-mod are outlined below:
1) The decision tree performed poorly at diagnosing faults
injected with low probabilities, particularly in traces
containing multiple concurrent faults. In these instances,
the decision tree algorithm would split
the tree to
classify faults occurring at higher probabilities, thereby
masking faults with lower probabilities.
2) The performance of the decision tree is degraded when
chronic problems arise due to a combination of attributes
because it identiﬁes some, but not all relevant root-
causes. We took great care to ensure that the combi-
nation of attributes associated with each injected fault
0.00.51.01:11:101:100Failed:Successful calls (Log scale)Precision/Recall0.740.940.30.48PrecisionRecallPinpointSpectroscope-modDraco0.900.910.990.850.910.970.00.51.0Precision                  RecallOverall Performance0.870.890.990.770.830.970.00.51.0Precision                  RecallMultiple Faults0.780.800.990.380.380.940.00.51.0Precision                  RecallMultiple Attributeswere not synonyms of each other to eliminate this as
contributing factor to the poor performance. We investi-
gated the effect on performance of considering partial
matches where at least one of the affected attributes is
identiﬁed. In this case, the recall of both Pinpoint are
Spectroscope-mod improved to 83% suggesting that the
decision tree was pruning relevant features.
VI. DRACO IN PRACTICE
We have deployed Draco on a portion of wireline VoIP
services provided by a major ISP. Over the past year, Draco has
assisted operators in performing chronics analysis of dropped
and blocked calls on the production system. We evaluated the
effectiveness of Draco using a diverse set of real incidents from
a production telecommunication system, listed in Table I. We
ran our experiments on a 8-core Xeon HT (@2.4GHz) with
24GB of memory.
A. Real Incidents
We evaluated Draco against chronics with known root-
causes from the production system; see Table I. The root-
causes of the chronics included conﬁguration problems at the
customer premises, resource contention, software problems,
and an intermittent power-outage. Draco correctly localized
the network element or customer associated with the chronic
problem in 8 out of these 10 incidents. Once the problem
is localized by Draco, operators can promptly liase with
customers, or query logs outside Draco’s scope to diagnose
the problem in more detail. The two incidents in which we did
not implicate the correct element were a software problem in
a policy server (incident 9) and a power outage that resulted
in intermittent problems during failover (incident 10). In both
incidents, the network element that was the root-cause of the
problem was not present in our input data so Draco indicted
the network elements adjacent to the root-cause.
In addition to localizing network elements associated with
the chronic problem, Draco analyzed the performance logs of
the identiﬁed network element whenever they were available.
Draco ﬂagged a resource metric as anomalous if the distribu-
tion of the metric in failed calls was signiﬁcantly different from
that in successful calls. Draco used the Mann-Whitney rank
test to reject the null hypothesis that the real-valued metrics
associated with failed and successful calls were drawn from
the same distribution with a signiﬁcance-level of 1%. The test
helped to localize problems due to resource-contention at a
network element.
B. Case Studies
We highlight four case studies from Table I, to illustrate
how Draco has been used by the chronics team quickly to
identify several new problems.
loss) is a chronic problem that
Incident 4: Poor call quality (due to packet delay, jitter,
and packet
to
detect because the call is neither blocked nor dropped and
thus appears as a successful event from the system’s point of
view. To diagnose poor call quality, the gateway servers were
is difﬁcult
conﬁgured to log the message-loss percentage for each call.
In addition, the Draco data collector was modiﬁed to ignore
failed (dropped and blocked) calls and treat the set of calls
with poor quality (loss > threshold) as the new set of failed
calls. The resulting data can then be analyzed normally by
Draco’s diagnosis engine.
Draco indicated that the top quality of service issue (ap-
proximately 48% of all poor quality calls) was related to a
single business customer. Further, Draco did not implicate any
network elements indicating that the root-cause of the problem
was likely with the customer equipment and not a problem
with the ISP’s hardware and/or network. When the customer
was notiﬁed, and the problem corrected, the overall number
of quality of service failures was reduced as expected.
Incident 5: A business customer experienced extremely
high call volumes which resulted in intermittent congestion
on bundles between two gateway servers and a switch. Draco
identiﬁed the network element associated with the customer
(i.e., the customer’s IPBE), and determined that the problem
was correlated with high concurrent sessions and CPU usage.
Incident 6: An intermittent performance problem with
two application servers led to an increase in call defects
persisting for several days. This problem affected 0.1% of
all calls passing through these application servers. Draco
identiﬁed both servers affected by the problem. After the
operations team failed over trafﬁc to a backup server, the
number of defects was reduced by 85%. We analyzed the CPU,
memory and network-related metrics on the application servers
and observed that these failures occurred during periods of
heavy load and high CPU usage.
Incident 9: A chronic problem arose when a policy
server in the VoIP network stopped responding to invites from
application servers, and affected 0.4% of calls passing through
the application server. Since records for the policy server were