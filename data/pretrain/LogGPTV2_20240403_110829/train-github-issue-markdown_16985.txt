 **System information**
  * Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
  * OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
  * Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
  * TensorFlow installed from (source or binary): binary
  * TensorFlow version (use command below): 1.12
  * Python version: 3.6.5
  * Bazel version (if compiling from source): N/A
  * GCC/Compiler version (if compiling from source): N/A
  * CUDA/cuDNN version: N/A
  * GPU model and memory: N/A
**Describe the current behavior**  
Running below code that I found in many pages on the net, I faced some
problems:
    import json
    import os
    import tensorflow as tf
    from tensorflow.contrib.learn.python.learn.datasets.mnist import read_data_sets
    data_dir = '.\\MNIST_data'
    log_dir = '.\log_dist'
    batch_size = 512
    tf.logging.set_verbosity(tf.logging.INFO)
    def keras_model(lr, decay):
        """Return a CNN Keras model"""
        input_tensor = tf.keras.layers.Input(shape=(784,), name='input')
        temp = tf.keras.layers.Reshape([28, 28, 1], name='input_image')(input_tensor)
        for i, n_units in enumerate([32, 64]):
            temp = tf.keras.layers.Conv2D(n_units, kernel_size=3, strides=(2, 2),
                                          activation='relu', name='cnn'+str(i))(temp)
            temp = tf.keras.layers.Dropout(0.5, name='dropout'+str(i))(temp)
        temp = tf.keras.layers.GlobalAvgPool2D(name='average')(temp)
        output = tf.keras.layers.Dense(10, activation='softmax', name='output')(temp)
        model = tf.keras.models.Model(inputs=input_tensor, outputs=output)
        optimizer = tf.keras.optimizers.Adam(lr=lr, decay=decay)
        model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])
        print(model.summary())
        return model
    def main():
        """Main function"""
        data = read_data_sets(data_dir,
                              one_hot=False,
                              fake_data=False)
        model = keras_model(lr=0.001, decay=0.001)
        config = tf.estimator.RunConfig(
                    model_dir=log_dir,
                    save_summary_steps=1,
                    save_checkpoints_steps=100)
        estimator = tf.keras.estimator.model_to_estimator(model, model_dir=log_dir, config=config)
        train_input_fn = tf.estimator.inputs.numpy_input_fn(
                             x={'input': data.train.images},
                             y=data.train.labels,
                             num_epochs=None,   # run forever
                             batch_size=batch_size,
                             shuffle=True)
        eval_input_fn = tf.estimator.inputs.numpy_input_fn(
                             x={'input': data.test.images},
                             y=data.test.labels,
                             num_epochs=1,
                             shuffle=False)
        train_spec = tf.estimator.TrainSpec(input_fn=train_input_fn,
                                            max_steps=2000)
        eval_spec = tf.estimator.EvalSpec(input_fn=eval_input_fn,
                                          #throttle_secs=1,
                                          steps=None    # until the end of evaluation data
                                          )
        evaluate_result = tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)
        print("Evaluation results:")
        for key in evaluate_result[0].keys():
            print("   {}: {}".format(key, evaluate_result[0][key]))
And then the rest of the code just included the TF_CONFIG definition for
chief, worker and ps. I faced below issues:
  * I was able to run this code on Tensorflow 1.12 but not on Tensorflow 1.13, where I got the error `ValueError: Can not squeeze dim[1], expected a dimension of 1, got 10 for 'metrics/acc/remove_squeezable_dimensions/Squeeze' (op: 'Squeeze') with input shapes: [512,10]`. What is the reason?
  * I could get evaluation results printed at the end of training when I was running program in non-distributed mode, but I get below error when it tries to print the final evaluation results in distributed mode:
    Traceback (most recent call last):
      File "mnist_estimator.py", line 81, in 
        main()
      File "mnist_estimator.py", line 62, in main
        for key in evaluate_result[0].keys():
    TypeError: 'NoneType' object is not subscriptable
  * The final loss for distributed learning was higher than non-distributed learning (for the same number of training steps). What can be the reason? Is it the nature of distribution?
  * When running in distributed mode, the chief or worker are not waiting for the other party to start and immediately starts training (when the other party joins they do the task together, though). I thought they should wait for each other to be ready (as it was in my previous experiences with Tensorflow distributed training), isn't it?
  * What I read in Tensorflow-related pages about data-parallelism is that there are the same copies of code for different servers except in assignment in TF_CONFIG. The chief synchronizes the parameters update and parameter servers keeps the parameters, but I don't clearly understand who split the data between different workers. Is there just one copy at the chief server and it will split the data and send batches to the workers, or the workers each have a local copy of data and do the splitting and skip some data themselves?