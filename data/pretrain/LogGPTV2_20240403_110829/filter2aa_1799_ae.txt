what appear to be two segments, and combining the high, middle, and low base address bytes:
0: kd> dg 40 48 
P Si Gr Pr Lo 
Sel        Base              Limit          Type    l ze an es ng Flags 
---- ----------------- ----------------- ---------- - -- -- -- -- -------- 
0040 00000000`7074d000 00000000`00000067 TSS32 Busy 0 Nb By P  Nl 0000008b 
0048 00000000`0000ffff 00000000`0000f802  0 Nb By Np Nl 00000000
“Meltdown” architectural processor vulnerability, this stack pointer will be the kernel stack 
whereas on systems that are vulnerable, this will point to the transition stack inside of the 
dg
to look at it:
kd> dg a0 a0
P Si Gr Pr Lo
Sel    Base     Limit     Type    l ze an es ng Flags
---- -------- -------- ---------- - -- -- -- -- --------
00A0 81170590 00000067 TSS32 Avl  0 Nb By P  Nl 00000089 
.tss command instead of dx, which will format the various 
case, the input parameter is the task selector (A0h).
kd> .tss a0
eax=00000000 ebx=00000000 ecx=00000000 edx=00000000 esi=00000000 edi=00000000
eip=81e1a718 esp=820f5470 ebp=00000000 iopl=0         nv up di pl nz na po nc
cs=0008  ss=0010  ds=0023  es=0023  fs=0030  gs=0000             efl=00000000
hal!HalpMcaExceptionHandlerWrapper:
81e1a718 fa              cli 
Note how the segment registers are set up as described in the “Lazy segment loading” section 
.tss
Directory. In the “Trap dispatching” section, we revisit this TSS when using the !idt command.
EXPERIMENT: Viewing the TSS and the IST on an x64 system
On an x64 system, the dg command unfortunately has a bug that does not correctly show 64-bit 
segment base addresses, so obtaining the TSS segment (40h) base address requires dumping 
what appear to be two segments, and combining the high, middle, and low base address bytes:
0: kd> dg 40 48
P Si Gr Pr Lo
Sel        Base              Limit          Type    l ze an es ng Flags
---- ----------------- ----------------- ---------- - -- -- -- -- --------
0040 00000000`7074d000 00000000`00000067 TSS32 Busy 0 Nb By P  Nl 0000008b
0048 00000000`0000ffff 00000000`0000f802  0 Nb By Np Nl 00000000
CHAPTER 8 System mechanisms
9
0xFFFFF8027074D000. To showcase yet another 
TssBase, which con-
0: kd> dx @$pcr->TssBase 
@$pcr->TssBase
: 0xfffff8027074d000 [Type: _KTSS64 *] 
    [+0x000] Reserved0
: 0x0 [Type: unsigned long] 
    [+0x004] Rsp0
: 0xfffff80270757c90 [Type: unsigned __int64]
RSP0, which, similarly to x86, contains the address of the 
kernel stack for the current thread (on systems without the “Meltdown” hardware vulnerability) 
or the address of the transition stack in the Processor Descriptor Area.
On the system on which this experiment was done, a 10th Generation Intel processor was 
used; therefore, RSP0 is the current kernel stack:
0: kd> dx @$thread->Tcb.InitialStack 
@$thread->Tcb.InitialStack : 0xfffff80270757c90 [Type: void *]
-
the Interrupt Dispatch Table (IDT) references these stacks:
0: kd> dx @$pcr->TssBase->Ist 
@$pcr->TssBase->Ist     [Type: unsigned __int64 [8]] 
    [0]
: 0x0 [Type: unsigned __int64] 
    [1]
: 0xfffff80270768000 [Type: unsigned __int64] 
    [2]
: 0xfffff8027076c000 [Type: unsigned __int64] 
    [3]
: 0xfffff8027076a000 [Type: unsigned __int64] 
    [4]
: 0xfffff8027076e000 [Type: unsigned __int64]
Now that the relationship between ring level, code execution, and some of the key segments in the 
segments (and their ring level) in the upcoming section on trap dispatching. Before discussing trap 
the Meltdown hardware side-channels attack.
Hardware side-channel vulnerabilities
Modern CPUs can compute and move data between their internal registers very quickly (in the order 
instruct the CPU to move data from the CPU registers into the main memory and vice versa. There 
are different kinds of memory that are accessible from the main CPU. Memory located inside the CPU 
package and accessible directly from the CPU execution engine is called cache and has the character-
istic of being fast and expensive. Memory that is accessible from the CPU through an external bus is 
usually the RAM (Random Access Memory) and has the characteristic of being slower, cheaper, and big 
0xFFFFF8027074D000. To showcase yet another 
TssBase, which con-
0: kd> dx @$pcr->TssBase
@$pcr->TssBase
: 0xfffff8027074d000 [Type: _KTSS64 *]
    [+0x000] Reserved0
: 0x0 [Type: unsigned long]
    [+0x004] Rsp0
: 0xfffff80270757c90 [Type: unsigned __int64]
RSP0, which, similarly to x86, contains the address of the 
kernel stack for the current thread (on systems without the “Meltdown” hardware vulnerability) 
or the address of the transition stack in the Processor Descriptor Area.
On the system on which this experiment was done, a 10th Generation Intel processor was 
used; therefore, RSP0 is the current kernel stack:
0: kd> dx @$thread->Tcb.InitialStack
@$thread->Tcb.InitialStack : 0xfffff80270757c90 [Type: void *]
-
the Interrupt Dispatch Table (IDT) references these stacks:
0: kd> dx @$pcr->TssBase->Ist
@$pcr->TssBase->Ist     [Type: unsigned __int64 [8]]
    [0]
: 0x0 [Type: unsigned __int64]
    [1]
: 0xfffff80270768000 [Type: unsigned __int64]
    [2]
: 0xfffff8027076c000 [Type: unsigned __int64]
    [3]
: 0xfffff8027076a000 [Type: unsigned __int64]
    [4]
: 0xfffff8027076e000 [Type: unsigned __int64]
10 
CHAPTER 8 System mechanisms
on memories of different speeds and sizes (the more memory is closer to the CPU, the more memory is 
-
ferent levels of fast cache memory, which is directly accessible by the execution engine of each physical 
-
cessors, the L3 cache usually does not exist).
Core 1
Registers
L1 Cache
L2 Cache
Core 2
Registers
L1 Cache
L2 Cache
L3 Cache
Shared
Size:
Speed:
~ 2KB
250 ps
64 KB
1 ns
256 KB
3 - 10 ns
2 - 32 KB
10 + 20 ns
8 -128 KB
50 - 100 ns
128 GB - 2 TB
50 - 100 µs
SSD
CPU
FIGURE 8-2 Caches and storage memory of modern CPUs and their average size and access time.
though it is still slower). Access time to the main memory is instead a hundred times slower. This means 
that in case the CPU executes all the instructions in order, many times there would be huge slowdowns 
due to instructions accessing data located in the main memory. To overcome this problem, modern 
CPUs implement various strategies. Historically, those strategies have led to the discovery of side-chan-
nel attacks (also known as speculative attacks), which have been proven to be very effective against the 
overall security of the end-user systems. 
To correctly describe side-channel hardware attacks and how Windows mitigates them, we should 
discuss some basic concepts regarding how the CPU works internally.
Out-of-order execution
A modern microprocessor executes machine instructions thanks to its pipeline. The pipeline contains 
many stages, including instruction fetch, decoding, register allocation and renaming, instructions 
reordering, execution, and retirement. A common strategy used by the CPUs to bypass the memory 
slowdown problem is the capability of their execution engine to execute instructions out of order as 
soon as the required resources are available. This means that the CPU does not execute the instructions 
in a strictly sequential order, maximizing the utilization of all the execution units of the CPU core as 
exhaustive as possible. A modern processor can execute hundreds of instructions speculatively before 
it is certain that those instructions will be needed and committed (retired). 
One problem of the described out-of-order execution regards branch instructions. A conditional 
-
pends on the previously executed instructions. When calculating the condition depends on previous 
CHAPTER 8 System mechanisms
11
instructions that access slow RAM memory, there can be slowdowns. In that case, the execution engine 
memory bus to complete the memory access) before being able to continue in the out-of-order execu-
tion of the following instructions belonging to the correct path. A similar problem happens in the case 
of indirect branches. In this case, the execution engine of the CPU does not know the target of a branch 
(usually a jump or a call) because the address must be fetched from the main memory. In this context, 
the term speculative execution-
tions in parallel or in an out-of-order way, but the results are not retired into permanent registers, and 
The CPU branch predictor
How does the CPU know which branch (path) should be executed before the branch condition has 
been completely evaluated? (The issue is similar with indirect branches, where the target address is 
not known). The answer lies in two components located in the CPU package: the branch predictor and 
the branch target predictor.
The branch predictor is a complex digital circuit of a CPU that tries to guess which path a branch 
that tries to predict the target of indirect branches before it is known. While the actual hardware imple-
mentation heavily depends on the CPU manufacturer, the two components both use an internal cache 
called Branch Target Buffer (BTB), which records the target address of branches (or information about 
what the conditional branch has previously done in the past) using an address tag generated through 
an indexing function, similar to how the cache generates the tag, as explained in the next section. The 
time, the execution pipeline is stalled, forcing the CPU to wait for the condition or target address to be 
fetched from the main memory. The second time the same branch is executed, the target address in 
of an example branch target predictor.
Virtual address: 0xFFFF AAAA9F43AA17
Indexing
Function
Idx
12
Address Tag
9F43AA17
Target
0x9F528092
Branch Target Buffer
F(Addr)
FIGURE 8-3 The scheme of a sample CPU branch predictor.
In case the prediction was wrong, and the wrong path was executed speculatively, then the instruc-
fed into the CPU pipeline and the execution restarts from the correct branch. This case is called branch 
12 
CHAPTER 8 System mechanisms
misprediction. The total number of wasted CPU cycles is not worse than an in-order execution wait-
ing for the result of a branch condition or indirect address evaluation. However, different side effects 
of the speculative execution can still happen in the CPU, like the pollution of the CPU cache lines. 
Unfortunately, some of these side effects can be measured and exploited by attackers, compromising 
the overall security of the system.
The CPU cache(s)
As introduced in the previous section, the CPU cache is a fast memory that reduces the time needed for 
sizes (usually 64 or 128 bytes) called lines or cache blocks. When a cache line is copied from memory 
into the cache, a cache entry is created. The cache entry will include the copied data as well as a tag 
identifying the requested memory location. Unlike the branch target predictor, the cache is always in-
dexed through physical addresses (otherwise, it would be complex to deal with multiple mappings and 
Whereas the higher bits usually represent the tag, the lower bits represent the cache line and the offset 
into the line. A tag is used to uniquely identify which memory address the cache block belongs to, as 
cache (in any cache lines that might contain data from that address. Some caches have different ways 
-
cation is in the cache, a cache hit has occurred, and the processor immediately reads or writes the data 
from/in the cache line. Otherwise, a cache miss has occurred. In this case, the CPU allocates a new entry 
in the cache and copies data from main memory before accessing it. 
CPU
RAM Memory
48-bits one-way 256 blocks CACHE
Block size: 256 byte
Physical Address
0x00019F56 60 30
0x019F566030
0
0
10
20
30
40
50
60
70
80
90
A0
B0
C0
D0
E0
F0
10 20 30 40 50 60 70 80 90 A0 B0 C0 D0 E0 F0
TAG
0x019F56
DATA
FIGURE 8-4 A sample 48-bit one-way CPU cache.
of virtual address space. In the sample, the CPU is reading 48 bytes of data located at virtual address 
CHAPTER 8 System mechanisms
13
In a similar way, when the CPU is instructed to write some new content to a memory address, it 
data back to the physical RAM as well, depending on the caching type (write-back, write-through, 
uncached, and so on) applied to the memory page. (Note that this has an important implication in 
multiprocessor systems: A cache coherency protocol must be designed to prevent situations in which 
another CPU will operate on stale data after the main CPU has updated a cache block. (Multiple CPU 
cache coherency algorithms exist and are not covered in this book.)
To make room for new entries on cache misses, the CPU sometime should evict one of the existing 
cache blocks. The algorithm the cache uses to choose which entry to evict (which means which block 
will host the new data) is called the placement policy. If the placement policy can replace only one block 
for a particular virtual address, the cache is called direct mapped 
way and is direct mapped). Otherwise, if the cache is free to choose any entry (with the same block 
number) to hold the new data, the cache is called fully associative. Many caches implement a compro-
mise in which each entry in main memory can go to any one of N places in the cache and are described 
as N-ways set associative. A way is thus a subdivision of a cache, with each way being of equal size and 
can store data belonging to four different physical addresses indexing the same cache block (with dif-
ferent tags) in four different cache sets.
Data RAM
Offset
Tag
Tag RAM
Way
Index
Set
Line
FIGURE 8-5 A four-way set associative cache.
Side-channel attacks 
As discussed in the previous sections, the execution engine of modern CPUs does not write the result of 
the computation until the instructions are actually retired. This means that, although multiple instruc-
tions are executed out of order and do not have any visible architectural effects on CPU registers and 
memory, they have microarchitectural side effects, especially on the CPU cache. At the end of the year 
14 
CHAPTER 8 System mechanisms
2017, novel attacks were demonstrated against the CPU out-of-order engines and their branch predic-
tors. These attacks relied on the fact that microarchitectural side effects can be measured, even though 
they are not directly accessible by any software code.
The two most destructive and effective hardware side-channel attacks were named Meltdown 
and Spectre.
Meltdown
Meltdown (which has been later called Rogue Data Cache load, or RDCL) allowed a malicious user-
mode process to read all memory, even kernel memory, when it was not authorized to do so. The at-
tack exploited the out-of-order execution engine of the processor and an inner race condition between 
the memory access and privilege check during a memory access instruction processing. 
-
tions that do so are callable from user mode). The process then executes an illegal kernel memory 
probe array). The process 