variables introduced by encoding Ski .
Encoding Size. The total CNF formula size is linear in the size of
the model. Given one cardinality constraint S(vk), where |vk| =
n, a cardinality network encoding produces a CNF formula with
O(n loд2 c) clauses and variables. The constant c is the maximum
value that the parameters of the BNN can take, hence the encoding
is linear in n. For a given layer with m neurons, this translates to m
C and aki
cardinality constraints, each over n variables. Hence, our encoding
procedure produces O(m × n) clauses and variables for each layer.
For the output block, s is the number of output classes and n is the
number of neurons in the previous layer. Thus, there are O(s×s×n)
clauses and variables for the output block. Therefore, the total size
for a BNN with l layers of the CNF is O(m × n × l + s × s × n), which
is linear in the size of the original model.
Alternative encodings. Besides cardinality networks, there are
many other encodings from cardinality constraints to CNF [3, 4, 8,
31, 91] that can be used as long as they are equi-witnessable. We
do not formally prove here but we strongly suspect that adder net-
works [31] and BDDs [3] have this property. Adder networks [31]
provide a compact, linear transformation resulting in a CNF with
O(n) variables and clauses. The idea is to use adders for numbers
represented in binary to compute the number of activated inputs
and a comparator to compare it to the constant c. A BDD-based [31]
encoding builds a BDD representation of the constraint. It uses
O(n2) clauses and variables.
5.3 Projected Model Counting
We instantiate the property P encoded in CNF and the neural net-
work encoded in a CNF formulae C. We make the powerful observa-
tion that we can directly count the number of satisfying assignment
for φ over a subset of variables, known as projected model count-
ing [10]. NPAQ uses an approximate model counter with strong
PAC-style guarantees. ApproxMC3 [92] is an approximate model
counter that can directly count on a projected formula making a
logarithmic number of calls in the number of formula variables to
an NP-oracle, namely a SAT solver.
Theorem 5.5. NPAQ is an (ϵ, δ)-NQV.
Proof. First, by Lemma 4.3, since each cardinality constraint Ski
is equi-witnessable to Cki (Lemma 5.4), the conjunction over the car-
dinality constraints is also equi-witnessable. Second, by Lemma 5.1,
BNN is equi-witnessable to C. Since we use an approximate model
counter with (ϵ, δ) guarantees [92], NPAQ returns r for a given
BNN and a specification φ with (ϵ, δ) guarantees.
□
6 IMPLEMENTATION & EVALUATION
We aim to answer the following research questions:
(RQ1) To what extent does NPAQ scale to, e.g., how large are the
neural nets and the formulae that NPAQ can handle?
(RQ2) How effective is NPAQ at providing sound estimates for
practical security applications?
(RQ3) Which factors influence the performance of NPAQ on our
benchmarks and how much?
(RQ4) Can NPAQ be used to refute claims about security-relevant
properties over BNNs?
Implementation. We implemented NPAQ in 4, 600 LOC of Python
and C++. We use the PyTorch (v1.0.1.post2) [79] deep learning
platform to train and test binarized neural networks. For encoding
the BNNs to CNF, we build our own tool using the PBLib library [81]
for encoding the cardinality constraints to CNF. The resulting CNF
formula is annotated with a projection set and NPAQ invokes the
approximate model counter ApproxMC3 [92] to count the number
of solutions. We configure a tolerable error ϵ = 0.8 and confidence
parameter δ = 0.2 as defaults throughout the evaluation.
Models. Our benchmarks consist of BNNs, on which we tested the
properties derived from the 3 applications outlined in Section 3.
The utility of NPAQ in these security applications is discussed in
Sections 6.2- 6.4. For each application, we trained BNNs with the
following 4 different architectures:
• ARCH1 - BLK1(100)
• ARCH2 - BLK1(50), BLK2(20)
• ARCH3 - BLK1(100), BLK2(50)
• ARCH4 - BLK1(200), BLK2(100), BLK3(100)
For each architecture, we take snapshots of the model learnt at differ-
ent epochs. In total, this results in 84 total models, each with 6, 280−
51, 410 parameters. Encoding various properties (Sections 6.2- 6.4)
results in a total of 1, 056 distinct formulae. For each formula, NPAQ
returns r i.e., the number of satisfying solutions. Given r, we calcu-
late PS i.e., the percentage of the satisfying solutions with respect
to the total input space size. The meaning of PS percentage values
is application-specific. In trojan attacks, PS(tr) represents inputs
labeled as the target class. In robustness quantification, PS(adv)
reports the adversarial samples.
Datasets. We train models over 2 standard datasets. Specifically, we
quantify robustness and trojan attack effectiveness on the MNIST [66]
dataset and estimate fairness queries on the UCI Adult dataset [2].
We choose them as prior work use these datasets [7, 25, 41, 43, 83].
MNIST. The dataset contains 60, 000 gray-scale 28 × 28 images of
handwritten digits with 10 classes. In our evaluation, we resize the
images to 10 × 10 and binarize the normalized pixels in the images.
UCI Adult Census Income. The dataset is 48, 842 records with 14
attributes such as age, gender, education, marital status, occupation,
working hours, and native country. The task is to predict whether
a given individual has an income of over $50, 000 a year. 5/14
attributes are numerical variables, while the remaining attributes
are categorical variables. To obtain binary features, we divide the
values of each numerical variables into groups based on its deviation.
Then, we encode each feature with the least amount of bits that are
sufficient to represent each category in the feature. For example,
we encode the race feature which has 5 categories in total with 3
bits, leading to 3 redundant values in this feature. We remove the
redundant values by encoding the property to disable the usage of
these values in NPAQ. We consider 66 binary features in total.
Experimental Setup. All experiments are performed on 2.5 GHz
CPUs, 56 cores, 64GB RAM. Each counting process executed on
one core and 4GB memory cap and a 24-hour timeout per formula.
6.1 NPAQ Benchmarking
We benchmark NPAQ and report breakdown on 1, 056 formulae.
Estimation Efficiency. NPAQ successfully solves 97.1% (1, 025 /
1, 056) formulae. In quantifying the effectiveness of trojan attacks
and fairness applications, the raw size of the input space (over all
possible choices of the free variables) is 296 and 266, respectively.
Naive enumeration for such large spaces is intractable. NPAQ re-
turns estimates for 83.3% of the formulae within 12 hours and 94.8%
1,100
e
a
l
u
m
r
o
f
d
e
v
l
o
s
f
o
#
950
800
650
500
350
1, 056 formulae
4
12
8
16
Time (hour)
20
24
Figure 3. Number of formulae NPAQ solves with respect to
the time. The solid line represents the aggregate number of
formulae NPAQ solves before the given time. The dashed line
represents the total number of formulae.
e
a
l
u
m
r
o
f
f
o
%
100
80
60
40
20
0
0-6
6-12
12-18
Time (hour)
18-24
PS ≤ 10% 10%  50%
Figure 4. PS with respect to the time taken by NPAQ. The
size of each region represents the fraction of formulae NPAQ
solves within the specific time for each range of PS.
of the formulae within 24 hours for these two applications. In ro-
bustness application, the total input sizes are a maximum of about
7.5 × 107.
Result 1: NPAQ solves 97.1% formulae in 24-hour timeout.
Encoding Efficiency. NPAQ takes a maximum of 1 minute to
encode each model, which is less than 0.05% of the total timeout.
The formulae size scale linearly with the model, as expected from
encoding construction. NPAQ presently utilizes off-the-shelf CNF
counters, and their performance heavily dominates NPAQ time.
NPAQ presently scales to formulae of ~3.5 × 106 variables and
~6.2×106 clauses. However, given the encoding efficiency, we expect
NPAQ to scale to larger models with future CNF counters [22, 92].
Result 2: NPAQ takes ~1 minute to encode the model.
Number of Formulae vs. Time. Figure 3 plots the number of
formulae solved with respect to the time, the relationship is loga-
rithmic. NPAQ solves 93.2% formulae in the first 12 hours, whereas,
it only solves 3.9% more in the next 12 hours. We notice that the neu-
ral net depth impacts the performance, most timeouts (27/31) stem
from ARCH4. 26/31 timeouts are for Property P1 (Section 3) to quan-
tify adversarial robustness. Investigating why certain formulae are
harder to count is an active area of independent research [5, 27, 28].
Performance with varying (ϵ, δ). We investigate the relationship
between different error and confidence parameters and test co-
relation with parameters that users can pick. We select a subset of
formulae 2 which have varying degrees of the number of solutions,
a large enough input space which is intractable for enumeration,
and varying time performance for the baseline parameters of ϵ =
0.8, δ = 0.2. Since these arise most naturally in fairness application
encodings using ARCH2, we chose all the 3 formulae in it.
We first vary the error tolerance (or precision), ϵ ∈ {0.1, 0.3, 0.5,
0.8} while keeping the same δ = 0.2 for the fairness application,
as shown in Table 3. This table illustrates no significant resulting
difference in counts reported by NPAQ under different precision
parameter values. More precisely, the largest difference as the nat-
ural logarithmic of the count is 0.1 for ϵ = 0.3 and ϵ = 0.8 for the
feature “Gender”. This suggests that for these formulae, decreasing
the error bound does not yield a much higher count precision.
Higher precision does come at a higher performance cost, as the
ϵ = 0.1 takes 16× more time than ϵ = 0.8. The results are similar
when varying the confidence parameter δ ∈ {0.2, 0.1, 0.05, 0.01}
(smaller is better) for ϵ = 0.1 (Table 3). This is because the number
of calls to the SAT solver depends only on the δ parameter, while
ϵ dictates how constrained the space of all inputs or how small
the “bucket” of solutions is [21, 92]. Both of these significantly
increase the time taken. Users can tune ϵ and δ based on the required
applications precision and the available time budget.
Result 3: NPAQ reports no significant difference in the
counts produced when configured with different ϵ and δ.
PS vs. Time. We investigate if NPAQ solving efficiency varies with
increasing count size. Specifically, we measure the PS with respect
to the time taken for all the 1, 056 formulae. Table 4 shows the PS
plot for 4 time intervals and 3 density intervals. We observe that
the number of satisfying solutions do not significantly influence
the time taken to solve the instance. This suggests that NPAQ is
generic enough to solve formulae with arbitrary solution set sizes.
Result 4: For a given ϵ and δ, NPAQ solving time is not
significantly influenced by the PS.
6.2 Case Study 1: Quantifying Robustness
We quantify the model robustness and the effectiveness of defenses
for model hardening with adversarial training.
2Our timeout is 24 hours per formula, so we resorted to checking a subset of formulae.
Table 3. Influence of (ϵ, δ) on NPAQ’s Performance. The count and time taken to compute the bias in ARCH2 trained on UCI
Adult dataset for changes in values features (marital status, gender, and race) i.e., the percentage of individuals whose predicted
income changes from ≤ 50K to > 50K when all the other features are same. NLC represents the natural logarithm of the count
NPAQ generates. Time represents the number of hours NPAQ takes to solve the formulae. x represents a timeout.
δ = 0.2
ϵ = 0.1
Feature
Marital Status
Race
Gender
ϵ = 0.1
ϵ = 0.3
ϵ = 0.5
ϵ = 0.8
δ = 0.01
δ = 0.05
δ = 0.1
δ = 0.2
NLC Time NLC Time NLC Time NLC Time NLC Time NLC Time NLC Time NLC Time
8.79
39.10
40.68
3.10
3.23
41.82
39.13
40.73
41.91
39.07
40.67
41.81
22.48
8.21
8.22
39.07
40.67
41.81
15.74
5.80
6.02
39.10
40.68
41.82
39.08
40.64
41.81
x
40.68
41.81
x
14.68
15.48
39.09
40.65
41.88
0.80
0.42
0.40
0.34
0.27
0.27
8.79
3.10
3.23
1.35
0.68
0.62
Table 4. Quantifying robustness for ARCH1..4 and pertur-
bation size from 2 to 5. ACCb represents the percentage of
benign samples in the test set labeled as the correct class.
#(Adv) and PS(adv) represent the average number and per-
centage of adversarial samples separately. #(timeout) repre-
sents the number of times NPAQ timeouts.
Table 5. Estimates of adversarial samples for maximum 2-bit
perturbation on ARCH1..4 for a plain BNN (epoch 0) and for
2 defense methods at epochs 1 and 5. ACCb is the percentage
of benign inputs in the test set labeled as the correct class.
#(Adv) is the number of adversarial samples.
Arch
ACCb
ARCH1
76
ARCH2
79
ARCH3
80
ARCH4
88
Perturb
Size
k ≤ 2
k = 3
k = 4
k = 5
k ≤ 2
k = 3
k = 4
k = 5
k ≤ 2
k = 3
k = 4
k = 5
k ≤ 2
k = 3
k = 4
k = 5
#(Adv)
PS(adv)
#(timeout)
561
26,631
685,415