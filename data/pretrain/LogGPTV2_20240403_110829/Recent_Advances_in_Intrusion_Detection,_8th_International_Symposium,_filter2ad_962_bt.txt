of worms tested and reported in the paper is limited in number and in scope. We hope 
that others with substantially larger zoos might make them available for testing, or to 
repeat the experiments reported herein to validate the results. Although we used real 
packet traces from three sources, a larger scale study of the methods described in this 
paper  is  necessary  to  understand  whether  the  methods  scale  as  we  conjecture,  and 
whether  sites’  content  flows  provide  the  necessary  diversity  to  more  readily  detect 
common attack exploits that each may see during a worm outbreak. 
PAYL  can  accurately  detect  new  worms  without  signatures.  Correlating  content 
alerts  generated  by  PAYL  reduces  false  alarms,  and  generates  detailed  content 
signatures that  may be used  for filtering  worm attacks at  multiple sites. We believe 
that worm writers will have substantially new and effective defenses to overcome, and 
we  wish  them  nothing  but  failure  and  frustration  in  attempting  to  thwart  these  new 
generation  of  defensive  systems.  We  further  posit  that  the  worm  problem  will 
ultimately  be  solved  by  defensive  “coalitions”,  making  network  systems  in  general 
safe from at least this class of cyber attacks for the foreseeable future.  
Acknowledgments 
We’d  like  to  thank  Janak  J.  Parekh,  Wei-Jen  Li  for  help  in  collecting  data,  the 
experimental set up, and for useful discussions and helpful comments on this paper.   
References 
[1]  S.  Bhatkar.  D.  C.  DuVarney,  R.  Sekar.  Address  Obfuscation:  an  Efficient  Approach  to 
Combat  a  Broad  Range  of  Memory  Error  Exploits,  12th  USENIX  Security  Symposium, 
2003. 
[2]  M. Damashek. Gauging similarity with n-grams: language independent categorization of 
text. Science, 267(5199):843--848, 1995 
[3]  D. Gusfield. Algorithms on Strings, Trees and Sequences, Cambridge University Press, 
1997. 
[4]  J. O. Kephart and W. C. Arnold. Automatic extraction of computer virus signatures. In 
Processing of  the 4th International Virus Bulletin Conference, Sept. 1994. 
[5]  K.-A Kim and B. Karp. Autograph: Toward Automated Distributed Worm Distribution, 
In Proceedings of the USENIX Security Symposium, August 2004. 
[6]  O.  Kolesnikov,  W.  Lee,  "Advanced  Polymorphic  Worms:  Evading  IDS  by  Blending  in 
with Normal Traffic", Tech Report, GIT-CC-05-09, 2005 
[7]  C. Kreibich and J. Crowcroft. Honeycomb-Creating Intrusion Detection Signatures Using 
Honeypots, In Proceedings of the 2nd Workshop on Hot Topics in Networks (HotNets-II), 
November 2003. 
[8]  W. Li, K. Wang, S. Stolfo and B. Herzog. Fileprints: Identifying File Types by N-gram 
Analysis, In the Proceedings of the 2005 IEEE Workshop on Information Assurance and 
Security, June 2005. 
[9]  R.  Lippmann,  et  al.  The  1999  DARPA  Off-Line  Intrusion  Detection  Evaluation, 
Computer Networks 34(4) 579-595, 2000. 
[10]  M. Locasto, J. Parekh, S. Stolfo, A.  Keromytis,  T. Malkin and V. Misra. Collaborative 
Distributed Intrusion Detection, Columbia University Tech Report CUCS-012-04, 2004. 
246 
K. Wang, G. Cretu, and S.J. Stolfo 
[11]  D. Moore, V. Paxson, S. Savage, C. Shannon, S. Staniford and N. Weaver. The Spread of 
the Sapphire/Slammer Worm, http://www.cs.berkeley.edu/~nweaver/sapphire/ 
[12]  D.  Moore  and  C.  Shannon.  Code-Red:  A  Case  Study  on  the  Spread  and  Victims  of  an 
Internet  Worm,  In  Proceeding  of  the  2002  ACM  SIGCOMM  Internet  Measurement 
Workshop  (IMW 2002), November 2002. 
[13]  D. Moore, C. Shannon, G. Voelker, and S. Savage. Internet Quarantine: Requirements for 
Containing Self-Propagating Code. In IEEE Proceedings of the INFOCOM, Apr. 2003. 
[14]  S.  Sidiroglou  and  A.  D.  Keromytis.  Countering  Network  Worms  through  Automatic 
Patch Generation. To appear in IEEE Security and Privacy 2005.  
[15]  S. Singh, C. Estan, G. Varghese and S. Savage. Automated Worm Fingerprinting, Sixth 
Symposium on Operating Systems Design and Implementation (OSDI), 2004. 
[16]  S. Staniford, V. Paxson, and N. Weaver. How to Own the Internet in Your Spare Time. In 
Proceedings of the USENIX Security Symposium, Aug. 2002. 
[17]  S. Stolfo. Collaborative Security, The Black Book on Corporate Security, Ch 9. Larstan 
publishing, 2005. 
[18]  V.  Yegneswaran,  P.  Barford,  and  S.  Jha.  Global  Intrusion  Detection  in  the  DOMINO 
Overlay System. In Proceedings of Network and Distributed System Security Symposium 
(NDSS), Feb, 2004. 
[19]  H.  J.  Wang,  C.  Guo,  D.  R.  Simon,  and  A.  Zugenmaier.  Shield:  Vulnerability-Driven 
Network Filter for Preventing Known Vulnerability Exploits. In Proceedings of the ACM 
SIGCOMM Conference, Aug. 2004.  
[20]  K.  Wang  and  S.  Stolfo.  Anomalous  payload-based  network  intrusion  detection,  in 
Proceedings of Recent Advance in Intrusion Detection (RAID), Sept. 2004. 
On Interactive Internet Traﬃc Replay
Seung-Sun Hong and S. Felix Wu
University of California, Davis CA 95616, USA
{hongs, wu}@cs.ucdavis.edu
Abstract. In this paper, we introduce an interactive Internet traﬃc
replay tool, TCPopera. TCPopera tries to accomplish two primary goals:
(1) replaying TCP connections in a stateful manner, and (2) supporting
traﬃc models for trace manipulation. To achieve these goals, TCPopera
emulates a TCP protocol stack and replays trace records interactively
in terms of TCP connection-level and IP ﬂow-level parameters. Due to
the stateful emulation of TCP connections, it ensures no ghost packet
generation which is a critical feature for live test environments where the
accuracy of protocol semantics are of fundamental importance. In our
validation tests, we showed that TCPopera successfully reproduces trace
records in terms of a set of traﬃc parameters. Also we demonstrated how
TCPopera can be deployed in test environments for intrusion detection
and prevention systems.
1 Introduction
For the purpose of testing new applications, systems, and protocols, the net-
work research community has a persistent demand for traﬃc generation tools
that can create a range of test conditions similar to those experienced in live
deployment. Having an appropriate tool for generating controllable, scalable,
reproducible, and realistic network traﬃc is of great importance in various
test environments including laboratory environments [1, 2], simulation environ-
ments [3, 4], and emulation environments [5, 6, 7, 8, 9]. When the tools fail to
consistently create realistic network traﬃc conditions, new systems will have the
risk of unpredictable behavior or unacceptable performance when deployed in live
environments.
There are two diﬀerent approaches to generate test traﬃc: trace-based traﬃc
replaying and analytic model-based traﬃc generation. Trace-based traﬃc re-
playing reproduces a stream of IP packets recorded from a real network. This
approach is easy to implement and mimic behaviors of a known system, but
replayed traﬃc might not be representative unless the congestion situation in
a test network is the same as that in a real network. Also, because it treats
various traﬃc characteristics of trace records as a black box, it is diﬃcult to ad-
just them for diﬀerent test conditions. In contrast, analytic model-based traﬃc
generation starts with mathematical models for various traﬃc/workload charac-
teristics, and then produces network traﬃc adhere to models. This approach is
challenging because it is necessary to identify important traﬃc characteristics to
A. Valdes and D. Zamboni (Eds.): RAID 2005, LNCS 3858, pp. 247–264, 2006.
c(cid:2) Springer-Verlag Berlin Heidelberg 2006
248
S.-S. Hong and S. Felix Wu
model as well as those characteristics must be empirically measured beforehand.
Furthermore, it can be diﬃcult to produce a single output that accurately shows
all traﬃc characteristics. However, this approach is very straightforward to tune
traﬃc parameters to adjust traﬃc conditions.
Although choosing an appropriate traﬃc generation method for test environ-
ments depends on its primary goal, there are test environments where both the
realism of trace contents and the accuracy of protocol semantics are of fundamen-
tal importance. For example, the best traﬃc for Intrusion Prevention Systems
(IPS) testing is the one capturing attacks or suspicious behaviors from a real net-
work. Besides, how we can provide trace records for test environments without
breaking protocol semantics is a challenging issue because neither trace-based
traﬃc replaying nor analytic model-based traﬃc generation is suﬃcient to satisfy
those traﬃc conditions.
In this paper, we present an interactive traﬃc replay tool, TCPopera, that
follows a middle road between trace-based traﬃc replaying and analytic model-
based traﬃc generation. This new traﬃc replay paradigm resolves several prob-
lems of existing traﬃc replay tools. First, TCPopera removes any false packet
breaking TCP semantics, called a ghost packet, by performing a stateful TCP
emulation. An example of ghost packets is an TCP acknowledgment segment
that acknowledges a data segment that has never delivered. Second, the TCP-
opera architecture supports the extension of various traﬃc models to overcome
the limitation of existing traﬃc replay tools. Third, TCPopera supports envi-
ronment transformation including address remapping and ARP emulation to
modify input trace records for a target network. Next, TCPopera supports IP
ﬂow-level inter-dependencies between two hosts. Last, the TCPopera architec-
ture is designed to be deployed in a large-scale emulation environment such as
DETER. Some of these features are still under development, but we believe
that the current TCPopera implementation still can make contributions to sev-
eral applications including IDS/IPS evaluation, and the debugging of in-line
devices.
We demonstrated TCPopera’s capabilities throughout our validation tests.
First, we compared the TCPopera traﬃc to input trace records in terms of traﬃc
volume and other distributional properties. During the traﬃc reproductivity test,
we found that TCPopera successfully reproduced IP ﬂows without breaking TCP
semantics. Second, we also demonstrated how TCPopera can be deployed in live
test environments for the IDS/IPS evaluation. From the eﬀectiveness test, we
observed that Snort generated diﬀerent results when we changed test conditions.
At least some of these interesting diﬀerences we discovered, as we will explain
later in this paper, are due to the implementation bugs of Snort.
This paper is organized as follows. After presenting related work in section 2,
we describe the issues related to the TCPopera design and implementation to
support new interactive traﬃc replay paradigm in section 3. In section 4, we
present the results of our validation tests and analyze them. Then, we conclude
our work and present future directions of the TCPopera development in the
section 5.
2 Related Work
On Interactive Internet Traﬃc Replay
249
For test environments for security products, high-volume traﬃc/workload gen-
eration tools are insuﬃcient to satisfy thet goals because they are not capable
of creating attack traﬃc. For this reason, testing groups still prefer conven-
tional traﬃc replay tools in order to evaluate security products. In this section
we present an brief overview of most commonly used open-source traﬃc replay
tools.
TCPreplay [14], originally developed to provide more precise testing method-
ologies for the research area of network intrusion detection, is a tool designed
to replay trace records at arbitrary speeds. TCPreplay provides a variety of fea-
tures for both passive sniﬀer devices as well as in-line devices such as routers,
ﬁrewalls, and IPS. IP addresses can be rewritten or randomized, MAC addresses
can be rewritten, transmission speeds can be adjusted, truncated packets can be
repaired, and packets are selectively sent or dropped. Because the main purpose
of TCPreplay is to send the capture traﬃc back to a target network, the exact
opposite of TCPdump [15], it cannot connect to services running on a real device.
To overcome this problem, the developers of TCPreplay added Flowreplay [14],
that can connect to a server via TCP or UDP sends/receives data based on a
pcap capture ﬁle [16]. It provides more testing methodologies, however, the ma-
jor limitation of Flowreplay is that it is only capable of replaying a client side
of trace records against a real service on a target host.
TCPivo [17] is a high-performance replay engine that reproduces traﬃc from
a variety of existing trace collection tools. The design goal of TCPivo is to
have a cost-eﬀective tool that easily runs on pre-existing systems such as x86-
based systems. To achieve this goal, TCPivo considered following issues. First,
TCPivo uses the on-the-ﬂy prefetching of a packet from a trace ﬁle to minimize
the latency of I/O operations. Using mmap() and madvise() functions, TCPivo
implemented a double buﬀered approach that one buﬀer for prefetching and the
other for being actively accessed. Second, TCPivo uses usleep() with real-time
priority set to improve the accuracy. Third, TCPivo used a null-padded payload
by getting rid of reading a payload from a ﬁle system to speed-up the packet
transmission loop.
Monkey is a tool to replay an emulated workload identical to the site’s normal
operating conditions [18]. Monkey infers delays caused by a client, a protocol, a
server, a the network in each captured ﬂow and replays each ﬂow according to
them. Monkey has two major components: Monkey See, a tool for TCP tracing,
Monkey Do, a tool for TCP replaying. Monkey See captures TCP packet traces
at a packet sniﬀer adjacent to an Web server being traced and performs an
oﬄine trace analysis to extract observable link delay, packet losses, bottleneck
bandwidth, packet MTUs, and HTTP event timing. Monkey Do consists of three
emulators. The client emulator replays client HTTP requests in sequence by
creating user-level sockets for each connection. The server emulator presents the
HTTP behavior of a Google server interacting with a client. Last, The network
emulator recreates network conditions identical to those at the time the trace
was captured.
250
S.-S. Hong and S. Felix Wu
Tomahawk is a tool for testing the performance and in-line blocking capa-
bilities of IPS devices [19]. It runs on a machine with three network inter-
face cards (NIC): one for management and two for testing. Two test NICs are
typically connected through a switch, a crossover cable, or an NIPS. Toma-
hawk divides trace records into two parts: client packets, generated by a client,
and server packets, generated by a server.1 When Tomahawk replays packets,
server packets are transmitted on eth1 and client packets are transmitted on
eth0 as default. If a packet is lost, a sender retries after a timeout period. If
progress is not made after a speciﬁed number of retransmissions, a connec-
tion is aborted. When Tomahawk ﬁnished replaying an input trace, it reports
whether replaying is completed or timed out. For an IPS testing, a timed-out
connection containing attacks implies that IPS blocked it successfully. However,
Tomahawk has some inherent limitations because it can only operate across
a layer 2 network. In addition, it cannot handle traces containing badly frag-
mented traﬃc and multiple connections in the same trace records can sometimes
confuse it.
The most signiﬁcant diﬀerence of TCPopera from aforementioned traﬃc
replay tools is that TCPopera is designed for a stateful emulation of TCP connec-
tions. Both TCPreplay and TCPivo are applicable for testing passive sniﬀer de-
vices, but they have problems in testing in-line devices such as routers, ﬁrewalls,
and IPS. Although TCPreplay has recently added multiple interface support, its
functionality is limited to split input traﬃc into diﬀerent NICs. Comparing to
TCPreplay, Tomahawk uses the clever method to control TCP connections, but
its inherent drawbacks keep it from deploying in real test environments. Flowre-
play and Monkey diﬀer from other replay tools in that they eventually emulate
TCP connections from trace records. However, they also have the limitation in
that Flowreplay is only capable of emulating a client side of TCP connections
and Monkey is dedicated to the HTTP traﬃc.
3 TCPopera
3.1 Design Goals
TCPopera is an interactive traﬃc replay tool for live test environments. With re-
spect to live traﬃc replaying, there are several requirements TCPopera must con-
sider for its design. The rest of this section discusses about these requirements.
– No ghost packet generation. Since most of traﬃc replay tools are not
capable of a stateful TCP emulation, they are often generating ghost packets
that breaks TCP semantics and degrades the accuracy of testing results.
TCPopera ensures no ghost packet generation by emulating TCP connections
in a stateful manner.
1 At the ﬁrst time an IP address is seen from a trace ﬁle, it is assigned to a client if
it is seen in the IP source address ﬁeld. Likewise, it is assigned to s server if it is in
the destination address ﬁeld.
On Interactive Internet Traﬃc Replay
251
– Traﬃc models support. One signiﬁcant drawback of existing traﬃc re-
play tools is that it is diﬃcult to adjust traﬃc for various test conditions. For
traﬃc replay tools, supporting traﬃc models require an appropriate reverse-
engineering on input trace records to extract important traﬃc parameters.
In addition, new traﬃc models should be easily employable. TCPopera pre-
processes input trace records to extract all necessary information to emulate
TCP connections and provides text-based conﬁguration ﬁles in order to al-
low users to adjust these traﬃc parameters. Traﬃc models are implemented
as the TCPopera internal library.
– Environment transformation. Address remapping is one of most com-
mon features in existing traﬃc replay tools, however it is doubtful whether
they can handle low-level protocol changes such as ARP (Address Resolu-
tion Protocol) after IP address remapping. It implies that current remapping
features in traﬃc replay tools do not consider a dependency of high-level pro-
tocols (i.e. IP, TCP/UDP) on low-level protocols (ARP, DNS). In contrast,
the current TCPopera implementation supports address remapping as well
as ARP emulation for environment transformation. This feature helps re-
playing input trace records on live test environments to ensure that packets
are delivered to its destination.
– Inter-connection dependency. Many of current network applications, i.e.
FTP, HTTP, P2P, etc, use multiple TCP connections tightly related to each
other. For traﬃc replay tools, it is a challenging task to identify inter-
dependencies among TCP connections because it requires a large amount
of computation as well as comprehensive understanding on such applica-
tions. In order for TCPopera to reduce a loss of accuracy at a reasonable
cost, it tries to reserve the packet sequence within a single IP ﬂow. We also
have the plan to provide more application-speciﬁc model for interconnection
dependencies in the later version of TCPopera.
3.2 TCPopera Components and Implementation
Each TCPopera node, a TCPopera-installed host, represents a set of hosts/
networks and interacts with its peer TCPopera nodes. Figure 1(a) shows major
components of TCPopera and Figure 1(a) depicts how TCPopera processes IP
ﬂows from input trace records. We explain the details of the TCPopera compo-
nents & implementations in the rest of this section.
Flow Preprocess. The Flow Preprocess component extracts IP ﬂows from
input trace records based on a host list. TCPopera users can set up replaying
environments including a host list, address remapping,2 and traﬃc parameters
using conﬁguration ﬁles. During IP ﬂow extraction, any information related to
the initiation of a TCP control block and IP ﬂow, includin Round-Trip Time
(RTT), transmission rate, packet loss rate, path MTU, is collected.
2 Currently, TCPopera only supports one-to-one address mapping function between
the same size of network segments.
252
S.-S. Hong and S. Felix Wu
TCPopera
library
Configuration files
Flow Preprocess
Traffic
Models
TCPopera
Timer
IP Flow
Process
TCP
Functions
TCPopera
Control
Packet
Injection
Packet
Capturing