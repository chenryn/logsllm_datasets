(cid:4)(cid:11)(cid:15)(cid:16)(cid:15)(cid:19)(cid:13)(cid:1)(cid:3)
(cid:7)(cid:11)(cid:13)(cid:15)(cid:11)(cid:13)(cid:14)
(cid:7)(cid:14)(cid:8)(cid:19)(cid:13)(cid:14)(cid:8)(cid:15)
(cid:7)(cid:14)(cid:11)(cid:19)(cid:29)(cid:14)(cid:11)(cid:19)
(cid:9)(cid:12)(cid:4)(cid:12) (cid:1) (cid:6)(cid:8)(cid:3) (cid:1) (cid:2)(cid:5) (cid:1) (cid:16)(cid:12)(cid:13)(cid:11)(cid:10)
(cid:14)(cid:12)(cid:2)(cid:3)(cid:5)(cid:12)(cid:10)(cid:15)(cid:14)(cid:5)
(cid:7)(cid:11)(cid:5)(cid:12)(cid:6)(cid:1)
(cid:14)
(cid:10)
(cid:11)
(cid:7)
(cid:15)
(cid:4)
(cid:3)
(cid:13)
(cid:6)
(cid:16)
(cid:3)
(cid:12)
(cid:8)
(cid:8)
(cid:16)
(cid:3)
(cid:12)
(cid:14)
(cid:5)
(cid:7)
(cid:6)
(cid:9)
(cid:3)
(cid:2)
(cid:1)
(cid:13)(cid:21)(cid:32)(cid:34)(cid:28)(cid:30)(cid:25) (cid:20)(cid:21)(cid:26)(cid:18)(cid:35) (cid:2)(cid:37)(cid:7)(cid:4)(cid:5)(cid:3) (cid:1)
(cid:32)(cid:23)(cid:30)(cid:28)(cid:33)(cid:22)(cid:23)(cid:29)(cid:33)(cid:32) (cid:2)(cid:37)(cid:7)(cid:4)(cid:6)(cid:3)
(cid:5)(cid:22)(cid:20)(cid:26)(cid:10)(cid:1)(cid:23)(cid:20)(cid:25)(cid:22)(cid:9)(cid:15)(cid:19)(cid:13) (cid:11)(cid:27)(cid:21)(cid:11)(cid:22)(cid:15)(cid:18)(cid:11)(cid:19)(cid:24)(cid:23)
(cid:3)(cid:10)(cid:9)(cid:11)(cid:8)(cid:5)(cid:14)(cid:5) (cid:8)(cid:6) (cid:22)(cid:20)(cid:9)(cid:10)(cid:12)(cid:21)
(cid:16)(cid:7)(cid:4)(cid:5)(cid:10)(cid:13)
(cid:5)(cid:15)(cid:24)(cid:12) (cid:7)(cid:22)(cid:20)(cid:12)(cid:9)(cid:17)(cid:15)(cid:18)(cid:14)
(cid:16)(cid:10)(cid:31)
(cid:2)(cid:16)(cid:19)(cid:23)(cid:11) (cid:4)(cid:9)(cid:17)(cid:15)(cid:18)(cid:14)
(cid:9)(cid:29)(cid:29)(cid:26)(cid:24)(cid:19)(cid:18)(cid:32)(cid:24)(cid:28)(cid:27) (cid:14)(cid:28)(cid:10) (cid:2)(cid:37)(cid:7)(cid:4)(cid:7)(cid:3)
(cid:28)(cid:10) (cid:2)(cid:2)(cid:37)(cid:37)(cid:7) (cid:7)(cid:7)(cid:4)(cid:7)(cid:3)(cid:3)
(cid:5)(cid:20)(cid:19)(cid:24)(cid:22)(cid:20)(cid:17)(cid:17)(cid:11)(cid:10) (cid:11)(cid:27)(cid:21)(cid:11)(cid:22)(cid:15)(cid:18)(cid:11)(cid:19)(cid:24)(cid:23)
(cid:10)(cid:20)(cid:22)(cid:21) (cid:34)(cid:28)(cid:30)(cid:25)(cid:26)(cid:28)(cid:18)(cid:20)(cid:31)
(cid:19)(cid:23)(cid:18)(cid:30)(cid:18)(cid:19)(cid:32)(cid:21)(cid:30)(cid:24)(cid:36)(cid:18)(cid:32)(cid:24)(cid:28)(cid:27) (cid:2)(cid:37)(cid:8)(cid:3)
(cid:6)(cid:12)(cid:12)(cid:17)(cid:15)(cid:19)(cid:11) (cid:8)(cid:19)(cid:8)(cid:17)(cid:28)(cid:23)(cid:15)(cid:23)
Figure 1: The overall organization of NEP platform (top) and
our measurement methodologies (bottom).
the key lessons learned in §6. Given the increasing prevalence of
edge computing (in particular fueled by 5G), our work provides cru-
cial insights towards improving future edge services. Meanwhile,
our results also provide an important “baseline” for studying how
it evolves in the future.
Open source The edge workloads traces we collected are available
at https://github.com/xumengwei/EdgeWorkloadsTraces.
2 THE NEP EDGE PLATFORM
Context and terminology The primary differences between NEP
and cloud providers, e.g., Alibaba Cloud (AliCloud) and AWS EC2,
are how physical servers are located, organized, and maintained.
While cloud providers also build their large data centers across
different geographical locations, edge providers take a step further
and treat such geo-distribution as their first-class target. We call
data centers at different locations sites. A site consists of many
servers, and each server hosts many VMs. The customers of NEP
typically subscribe to one or multiple VMs, on which they operate
applications or services. In this study, we assume the VMs that use
the same system image and belong to the same user serve the same
application (edge app). Figure 1 shows the overall organization of
NEP and our measurement methodology as will be discussed in the
following subsection.
NEP overview While still at its early stage, NEP has now be-
come a leading edge platform in China. Compared to cloud plat-
forms that typically have less than 10 sites in one country, NEP’s site
number is about two orders of magnitudes larger and the number
is still fast-growing. Such a difference leads to a significant chain
reaction in other aspects of the platforms such as app performance,
resource usage, and so on as we will characterize in the following
sections. A site in cloud computing often hosts thousands or even
millions of servers and the number is highly scalable; while a NEP
site typically hosts only tens or hundreds of servers as constrained
by the physical infrastructure, e.g., space and electricity. While NEP
supports many types of services (e.g., PaaS and FaaS), the current
dominant usage is Infrastructure-as-a-Service (IaaS) VMs. Thus,
this paper mainly targets at IaaS VMs hosted in NEP for workload
analysis. The physical servers of NEP come from many sources.
The majority of them are built atop Alibaba CDN PoPs. Some are
39
cooperatively managed by NEP and other third-part IDCs or net-
work operators. NEP also provides business customers with edge
infrastructures that are hosted on the customers’ own hardware.
Nevertheless, the current form of NEP is mainly based on micro
datacenters and has not generally sunk into cellular core networks
as envisioned by MECs [51].
NEP operation Just as cloud, deploying an app on NEP takes
two main stages. (1) VM placement by edge provider. The cus-
tomers first submit their resource requirements at different geo-
graphical locations to NEP administrators. For example: “I need
10 virtual machines in Guangdong province, each with 16 CPU
cores and 32GB memory.” Generally speaking, NEP only exposes a
relatively coarse spatial granularity for customers to subscribe (e.g.,
province instead of site). This is to ensure an elastic resource alloca-
tion strategy, as the resources available on each site are very limited.
Once a subscription request arrives, NEP returns one feasible al-
location. While there are often thousands of options, NEP favors
the servers that are low in usage in terms of the sales ratio and ac-
tual CPU usage (mean and max). (2) End-user traffic scheduling
by edge customers. Once NEP allocates the VMs, customers take
over the whole control of those VMs. They are also in charge of
scheduling the requests from end users to a given VM. Similar to
traffic routing in content delivery network (CDN), edge customers
typically route user requests to their nearby sites based on DNS or
HTTP 302.
2.1 Measurement Methodology
We collect two kinds of datasets from NEP: (i) edge performance
(§2.1.1), for which we actively build benchmark tools and obtain
testing results through crowdsourcing and controlled experiments;
(ii) edge workloads (§2.1.2), for which we passively log the edge
VMs’ activities and traces.
2.1.1 Edge Performance Data Collection. We actively collected
three kinds of data: network latency, network throughput, and
application-level performance, for both edges and clouds. The first
two were obtained by crowdsourcing, while the other one is per-
formed in controlled settings.
Edge and cloud servers (1) For latency, we set up one VM on
each edge site of NEP and each cloud region of AliCloud. Those
VMs are used as the ping destinations. (2) For throughput, we set
up 20 NEP VMs at different cities, each with 1Gbps bandwidth
capacity. We didn’t use AliCloud or all NEP regions because the ex-
periments impose too much traffic overhead. However, the 20 VMs
are enough to draw our key conclusions as will be later presented.
(3) For application QoE, we set up 1 nearest edge VM and 3 cloud
VMs at different locations that are 670Km/1300Km/2000Km away
from where the experiments are performed. Each VM has 8 vCPUs
(2.5GHz), 16GBs memory, and sufficient bandwidth.
User equipments (UE) We use several commodity off-the-shelf
UEs for crowd-sourced network measurements. For application QoE
testing, we used one laptop (MacBook Pro, 2019 version, 16-inch)
and three smartphones: Samsung Note 10+ (Snapdragon 855, 5G-
supported), Xiaomi Redmi Note 8 (Qualcomm Snapdragon 665), and
Nexus 6 (Qualcomm Snapdragon 805). We mainly used Qualcomm
chipsets because the GamingAnywhere [53] framework cannot
utilize the built-in codec hardware for other chips.
IMC ’21, November 2–4, 2021, Virtual Event, USA
Mengwei Xu et al.
We mainly focus this study on smartphones because (1) smart-
phone is often regarded as the major type of UE for accessing edge
resources, and (2) the wifi speed on smartphones and laptops are
similar as we have measured.
Testing tools and applications We mainly used traceroute
(ICMP) and iPerf3 (TCP) to obtain the network latency and through-
put performance. We also built two QoE-testing apps, which are
commonly envisioned to be (future) killer apps in the era of edge
computing. (1) Cloud gaming: we adopted three desktop games
(Battle Tanks [1], Pingus [2], and Flare [9]) to be cloud-powered
based on GamingAnywhere [53], the state-of-the-art cloud gaming
platform. Edge/cloud servers are to receive player actions from UEs,
perform game logic, render the images, and finally encode and send
them back to the UE for display. (2) Live streaming: we built a live
streaming app based on real-time messaging protocol (RTMP) with
Nginx [20] (server side, Ubuntu), EasyRTMP-Android [14] (sender
UE, Android device), and MPlayer [19] (receiver UE, Mac Laptop).
In this application, edge/cloud servers are to pull the videos from
the sender UE, (optionally) transcode the videos, and push them to
the receiver UE.
Testing process (1) For latency, we recruited volunteers in
China using Android devices. We installed our speed-testing app
on their devices, and asked them to run the tests. During testing,
the app will obtain the round-trip time (RTT) to each edge/cloud
VM we set up and the intermediate hops if visible. Each IP testing
is repeated by 30 times. Once finished, the testing results will be
encrypted and uploaded to our server, along with the network con-
dition (WiFi/LTE/5G), testing time, and the city name. In total, we
received 385 testing results (>2M pings) from Jun. 1st to Aug. 1st in
20203. The results come from 158 users, covering 20 provinces, and
41 cities in China. For network type, 59%/34%/7% of the testings
are performed under WiFi/LTE/5G. During each test, we ask the
participants to keep their smartphones in a stationary context, e.g.,
no WiFi/4G switching or 4G handoff. This is ensured by our testing
script that monitors the network condition and physical motions
of the devices. (2) For throughput, we selected 25 volunteers at
different cities, a subset from the above, to run our testing script.
The script used iPerf3 to get both downlink/uplink throughput to
each of the 20 edge VMs we selected, where iPerf3 runs for 15
seconds per connection. (3) The application QoE experiment was
performed by the authors. Each testing was repeated across 4 dif-
ferent locations in the same city: campus indoor/outdoor and office
building indoor/outdoor.
2.1.2 Edge Workloads Data Collection. This dataset contains infor-
mation about every VM running on NEP from June 1st to Sep 1st,
2020. More specifically: (1) a VM table, with each VM’s placement
information (which server and site it’s hosted at), customer infor-
mation (whom it belongs to), and system information (the image
id, os type, kernel number, etc); (2) the resource size (capacity) in
terms of maximum CPU cores, memory, and disk for each VM and
server; (3) the CPU usage reported every 1 minute for each VM;
(4) the bandwidth usage reported every 5 minutes for each VM,
including both private (intra-site) and public traffic.
3The volunteers recruited are not affiliated with NEP. All participants are paid for
their efforts and the traffic data consumed in the experiments.
2.2 Selecting cloud workloads for comparison
The goal of this work is to compare NEP with cloud platforms
to reveal their disparity, and therefore showcase the key benefits
brought by NEP. Regarding the workloads comparison (§4), we
investigate the cloud workloads datasets that are publicly available
and summarize them in Table 2. Next, we describe these datasets
in detail and explain why we choose to use or not use each of them
for comparison.
• Azure dataset [38] is the most representative counterpart of
NEP on public cloud platforms and thus comprehensively compared
in this work (we used the 2019 version).
• AliCloud dataset [3] is not compared because: (1) It only con-
tains the usage of containers instead of VMs, while the major form
of NEP is VM; (2) Its time range is too short for certain analysis (8
days), e.g., resource usage profiling and prediction.
• Google dataset [92] is not compared because: (1) Its resources
are not available to public but only to Google’s internal devel-
opers, making it not representative of public cloud platforms. (2)
The dataset access is through Google’s BigQuery interface, which
doesn’t support complicated usage such as ML-based prediction.
• GWA-T-12 dataset [88] is not compared because it’s too small-
scale and out-of-date.
2.3 Ethics
When conducting this study, we take careful steps to protect user
privacy and preserve the ethics of research. (i) For collecting the
edge performance dataset, the data collection was approved by
the Research Ethical Committee of the institutes that the authors
are currently affiliated with; the collection was also approved by
the participants ahead of experiments through informed consent;
we collected no sensitive data from the participants except their
residential city, which was input by the participants themselves. (ii)
For collecting the edge workloads dataset of NEP, the data collection
was approved by its customers through the service agreement; no
customer identifiable information was collected during the study.
When exported, the customer ID of the dataset is anonymized.
3 DEMYSTIFYING EDGE PERFORMANCE
3.1 End-to-end Network Latency
Based on the collected data (§2.1.1), we first calculate the median
network delay among each user and NEP site, and then aggregate
the results across users. This is to eliminate the impacts from heavy
users who have run our testing multiple times.
For simplicity, we define the “nearest edge/cloud” as the edge/-
cloud site that has the smallest median RTT to an end user. Besides
the nearest edge/cloud that represents the optimal network perfor-
mance available in the current deployment of NEP/AliCloud, we
include two other baselines: (i) the 3rd-nearest edge, for which we
will show that there are multiple edges that are close to each user;
(ii) all clouds, which is averaged across all the sites of AliCloud.
This baseline reflects the performance of deploying on a centralized
server for users of a nation (China in our case), a common tradeoff
among economic and performance perspectives.
40
From Cloud to Edge: A First Look at Public Edge Platforms
IMC ’21, November 2–4, 2021, Virtual Event, USA
Platform
Azure Dataset [38]
Azure Cloud
AliCloud Dataset [3]
AliCloud ECS
Google Dataset [92]
Google Borg
GWA-T-12 [88]
Our Dataset
Bitbrains
NEP
Duration
1 month in 2017
1 month in 2019
12 hours in 2017
8 days in 2018
1 month in 2011
1 month in 2019
3 months in 2013
3 months in 2020
Scale
2.0M VMs
2.7M VMs
1.3k servers
4.0k servers
12.6k servers
96.4k servers
1.75k VMs
Complete set
Customers
Why it’s not compared?
public
public
The 2019 version is used.
Only containers’ usage are included.
Google developers
Only support BigQuery. Not public platform.