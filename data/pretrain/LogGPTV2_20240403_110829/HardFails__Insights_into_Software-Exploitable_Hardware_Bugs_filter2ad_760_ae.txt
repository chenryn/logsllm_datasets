scale well in practice beyond toy examples. Moreover, timing
(and other) side-channel information ﬂows are not modeled.
Finally, computational scalability to verifying real-world com-
plex SoCs remains an issue given that the proof veriﬁcation
for a single AES core requires ≈ 30 minutes to complete [6].
Model checking-based approaches check a given prop-
erty against the modeled state space and possible state tran-
sitions using provided invariants and predeﬁned conditions.
They face scalability issues as computation time scales ex-
ponentially with the model and state space size. This can
be alleviated by using abstraction to simplify the model or
constraining the state space to a bounded number of states
using assumptions and conditions. However, this introduces
false positives, may miss vulnerabilities, and requires expert
knowledge. Most industry-leading tools, such as the one we
use in this work, rely on model checking algorithms such as
boolean satisﬁability problem solvers and property speciﬁca-
tion schemes, e.g., assertion-based veriﬁcation to verify the
required properties of a given hardware design.
Side-channel leakage modeling and detection remain
an open problem. Recent work [76] uses the Murϕ model
checker to verify different hardware cache architectures for
side-channel leakage against different adversary models. A
formal veriﬁcation methodology for SGX and Sanctum en-
claves under a limited adversary was introduced in [67]. How-
ever, such approaches are not directly applicable to hardware
implementation. They also rely exclusively on formal veri-
ﬁcation and remain inherently limited by the underlying al-
gorithms in terms of scalability and state space explosion,
besides demanding particular expertise to use.
Information ﬂow analysis (such as SPV) works by assign-
ing a security label (or a taint) to a data input and monitoring
the taint propagation. In this way, the designer can verify
whether the system adheres to the required security policies.
Recently, information ﬂow tracking (IFT) has been shown ef-
fective in identifying security vulnerabilities, including timing
side channels and information-leaking hardware Trojans.
IFT techniques are proposed at different levels of abstrac-
tion: gate-, RT, and language-levels. Gate-level information
224    28th USENIX Security Symposium
USENIX Association
ﬂow tracking (GLIFT) [2, 58, 70] performs the IFT analysis
directly at gate-level by generating GLIFT analysis logic that
is derived from the original logic and operates in parallel to it.
Although gate-level IFT logic is easy to automatically gener-
ate, it does not scale well. Furthermore, when IFT uses strict
non-interference, it taints any information ﬂow conservatively
as a vulnerability [34] which scales well for more complex
hardware, but generates too many false positives.
At the language level, Caisson [42] and Sapper [41] are
security-aware HDLs that use a typing system where the de-
signer assigns security "labels" to each variable (wire or reg-
ister) based on the security policies required. However, they
both require redesigning the RTL using a new hardware de-
scription language which is not practical. SecVerilog [22, 75]
overcomes this by extending the Verilog language with a dy-
namic security type system. Designers assign a security label
to each variable (wire or register) in the RTL to enable a
compile-time check of hardware information ﬂow. However,
this involves complex analysis during simulation to reason
about the run-time behavior of the hardware state and depen-
dencies across data types for precise ﬂow tracking.
Hardware/ﬁrmware co-veriﬁcation to capture and verify
hardware/ﬁrmware interactions remains an open challenge
and is not available in widely used industry-standard tools. A
co-veriﬁcation methodology [28] addresses the semantic gap
between hardware and ﬁrmware by modeling hardware and
ﬁrmware using instruction-level abstraction to leverage soft-
ware veriﬁcation techniques. However, this requires modeling
the hardware that interacts with ﬁrmware into an abstraction
which is semi-automatic, cumbersome, and lossy.
While research is underway [71] to analyze a limited
amount of low-level ﬁrmware running on top of a simulated
RTL design these approaches are still under development and
not scalable. Current veriﬁcation approaches focus on register-
state information-ﬂow analysis, e.g., to monitor whether sensi-
tive locations are accessible from unprivileged signal sources.
Further research is required to explicitly model non-register
states and timing explicitly alongside the existing capabilities
of these tools.
8.2 Recent Attacks
We present and cautiously classify the underlying hardware
vulnerabilities of recent cross-layer exploits (see Table 2 in
Appendix B), using the categories introduced in 3.1. We do
not have access to proprietary processor implementations,
so our classiﬁcation is only based on our deductions from
the published technical descriptions. Yarom et al. demon-
strate that software-visible side channels can exist even below
cache-line granularity in CacheBleed [74]–undermining a
core assumption of prior defenses, such as scatter-gather [9].
MemJam [45] exploits false read-after-write dependencies in
the CPU to maliciously slow down victim accesses to mem-
ory blocks within a cache line. We categorize the underlying
vulnerabilities of CacheBleed and MemJam as potentially
hard to detect in RTL due to the many cross-module connec-
tions involved and the timing-ﬂow leakage. The timing ﬂow
leakage is caused by the software triggering clock cycle differ-
ences in accesses that map to the same bank below cache line
granularity, thus breaking constant-time implementations.
The TLBleed [23] attack shows how current TLB imple-
mentations can be exploited to break state-of-the-art cache
side-channel protections. As described in Section 4, TLBs
are typically highly interconnected with complex processor
modules, such as the cache controller and memory manage-
ment unit, making vulnerabilities therein very hard to detect
through automated veriﬁcation or manual inspection.
BranchScope [20] extracts information through the direc-
tional branch predictor, thus bypassing software mitigations
that prevent leakage via the BTB. We classify it as a cache-
state gap in branch prediction units, which is signiﬁcantly
challenging to detect using existing RTL security veriﬁcation
tools, which cannot capture and verify cache states. Melt-
down [43] exploits speculative execution on modern proces-
sors to completely bypass all memory access restrictions. Van
Bulck et al. [72] also demonstrated how to apply this to Intel
SGX. Similarly, Spectre [37] exploits out-of-order execution
across different user-space processes as arbitrary instruction
executions would continue during speculation. We recognize
these vulnerabilities are hard to detect due to scalability chal-
lenges in existing tools, since the out-of-order scheduling
module is connected to many subsystems in the CPU. Addi-
tionally, manually inspecting these interconnected complex
RTL modules is very challenging and cumbersome.
CLKScrew [69] abuses low-level power-management func-
tionality that is exposed to software to induce faults and
glitches dynamically at runtime in the processor. We cat-
egorize CLKScrew to have vulnerable hardware-ﬁrmware
interactions and timing-ﬂow leakage, since it directly exposes
clock-tuning functionality to attacker-controlled software.
9 Conclusion
Software security bugs and their impact have been known for
many decades, with a spectrum of established techniques to
detect and mitigate them. However, the threat of hardware
security bugs has only recently become signiﬁcant as cross-
layer exploits have shown that they can completely undermine
software security protections. While some hardware bugs can
be patched with microcode updates, many cannot, often leav-
ing millions of affected chips in the wild. In this paper, we
presented the ﬁrst testbed of RTL bugs and systematically
analyzed the effectiveness of state-of-the-art formal veriﬁca-
tion techniques, manual inspection and simulation methods
in detecting these bugs. We organized an international hard-
ware security competition and an in-house study. Our results
have shown that 54 teams were only able to detect 61% of
the total number of bugs, while with industry-leading formal
veriﬁcation techniques, we were only able to detect 48% of
USENIX Association
28th USENIX Security Symposium    225
the bugs. We showcase that the grave security impact of many
of these undetected bugs is only further exacerbated by being
software-exploitable.
Our investigation revealed the limitations of state-of-the-
art veriﬁcation/detection techniques with respect to detecting
certain classes of hardware security bugs that exhibit partic-
ular properties. These approaches remain limited in the face
of detecting vulnerabilities that require capturing and verify-
ing complex cross-module inter-dependencies, timing ﬂows,
cache states, and hardware-ﬁrmware interactions. While these
effects are common in SoC designs, they are difﬁcult to model,
capture, and verify using current approaches. Our investiga-
tive work highlights the necessity of treating the detection
of hardware bugs as signiﬁcantly as that of software bugs.
Through our work, we highlight the pressing call for further
research to advance the state of the art in hardware security
veriﬁcation. Particularly, our results indicate the need for in-
creased scalability, efﬁcacy and automation of these tools,
making them easily applicable to large-scale commercial SoC
designs—without which software protections are futile.
Acknowledgments
We thank our anonymous reviewers and shepherd, Stephen
Checkoway, for their valuable feedback. The work was sup-
ported by the Intel Collaborative Research Institute for Col-
laborative Autonomous & Resilient Systems (ICRI-CARS),
the German Research Foundation (DFG) by CRC 1119
CROSSING P3, and the Ofﬁce of Naval Research (ONR
Award #N00014-18-1-2058). We would also like to ac-
knowledge the co-organizers of Hack@DAC: Dan Holcomb
(UMass-Amherst), Siddharth Garg (NYU), and Sourav Sudhir
(TAMU), and the sponsors of Hack@DAC: the National Sci-
ence Foundation (NSF CNS-1749175), NYU CCS, Mentor - a
Siemens Business and CROSSING, as well as the participants
of Hack@DAC.
References
[1] M. Abadi, M. Budiu, U. Erlingsson, and J. Ligatti. Control-ﬂow in-
tegrity. ACM conference on Computer and communications security,
pages 340–353, 2005.
[2] A. Ardeshiricham, W. Hu, J. Marxen, and R. Kastner. Register Trans-
fer Level Information Flow Tracking for Provably Secure Hardware
Design. Design, Automation & Test in Europe, pages 1695–1700, 2017.
[3] ARM. Security technology building a secure system using trust-
http://infocenter.arm.com/
zone technology (white paper).
help/topic/com.arm.doc.prd29-genc-009492c/PRD29-GENC-
009492C_trustzone_security_whitepaper.pdf, 2009.
[5] Averant.
Solidify.
documents/Solidify.pdf, 2018.
http://www.averant.com/storage/
[6] M.-M. Bidmeshki, X. Guo, R. G. Dutta, Y. Jin, and Y. Makris. Data Se-
crecy Protection Through Information Flow Tracking in Proof-Carrying
Hardware IP—Part II: Framework Automation. IEEE Transactions on
Information Forensics and Security, 12(10):2430–2443, 2017.
[7] M.-M. Bidmeshki and Y. Makris. VeriCoq: A Verilog-to-Coq Con-
verter for Proof-Carrying Hardware Automation. IEEE International
Symposium on Circuits and Systems, pages 29–32, 2015.
[8] F. Brasser, D. Gens, P. Jauernig, A.-R. Sadeghi, and E. Stapf. SANC-
TUARY: ARMing TrustZone with User-space Enclaves. Network and
Distributed System Security Symposium (NDSS), 2019.
[9] E. Brickell, G. Graunke, M. Neve, and J.-P. Seifert. Software mitiga-
tions to hedge AES against cache-based software side channel vulnera-
bilities. IACR Cryptology ePrint Archive, 2006:52, 2006.
[10] Cadence. Incisive Enterprise Simulator. https://www.cadence.com/
content/cadence-www/global/en_US/home/tools/system-
design-and-verification/simulation-and-testbench-
verification/incisive-enterprise-simulator.html, 2014.
[11] Cadence.
JasperGold Formal Veriﬁcation Platform.
https:
//www.cadence.com/content/cadence-www/global/en_US/
home/tools/system-design-and-verification/formal-
and-static-verification/jasper-gold-verification-
platform.html, 2014.
[12] Cadence.
JasperGold Security Path Veriﬁcation App.
https://www.cadence.com/content/cadence-www/global/en_
US/home/tools/system-design-and-verification/formal-
and-static-verification/jasper-gold-verification-
platform/security-path-verification-app.html, 2018. Last
accessed on 09/09/18.
[13] M. Castro, M. Costa, and T. Harris. Securing software by enforcing
data-ﬂow integrity. USENIX Symposium on Operating Systems Design
and Implementation, pages 147–160, 2006.
[14] D. P. Christopher Celio, Krste Asanovic. The Berkeley Out-of-Order
https://riscv.org/wp-content/uploads/2016/01/
Machine.
Wed1345-RISCV-Workshop-3-BOOM.pdf, 2016.
[15] Cisco.
Cisco: Strengthening Cisco Products.
https://www.
cisco.com/c/en/us/about/security-center/security-
programs/secure-development-lifecycle.html, 2017.
[16] E. M. Clarke, W. Klieber, M. Nováˇcek, and P. Zuliani. Model check-
ing and the state explosion problem. Tools for Practical Software
Veriﬁcation, 2012.
[17] K. Conger. Apple announces long-awaited bug bounty program.
https://techcrunch.com/2016/08/04/apple-announces-
long-awaited-bug-bounty-program/, 2016.
[18] V. Costan, I. A. Lebedev, and S. Devadas. Sanctum: Minimal Hardware
Extensions for Strong Software Isolation. USENIX Security Symposium,
pages 857–874, 2016.
[19] O. Demir, W. Xiong, F. Zaghloul, and J. Szefer.
Survey of ap-
proaches for security veriﬁcation of hardware/software systems. https:
//eprint.iacr.org/2016/846.pdf, 2016.
[4] R. Armstrong, R. Punnoose, M. Wong, and J. Mayo.
Sur-
vey of Existing Tools for Formal Veriﬁcation.
Sandia Na-
tional Laboratories https://prod.sandia.gov/techlib-noauth/
access-control.cgi/2014/1420533.pdf, 2014.
[20] D. Evtyushkin, R. Riley, N. C. Abu-Ghazaleh, D. Ponomarev, et al.
BranchScope: A New Side-Channel Attack on Directional Branch
Predictor. ACM Conference on Architectural Support for Programming
Languages and Operating Systems, pages 693–707, 2018.
226    28th USENIX Security Symposium
USENIX Association
[21] F. Farahmandi, Y. Huang, and P. Mishra. Formal Approaches to Hard-
ware Trust Veriﬁcation. The Hardware Trojan War, 2018.
[22] A. Ferraiuolo, R. Xu, D. Zhang, A. C. Myers, and G. E. Suh. Veriﬁ-
cation of a Practical Hardware Security Architecture Through Static
Information Flow Analysis. ACM Conference on Architectural Support
for Programming Languages and Operating Systems, pages 555–568,
2017.
[23] B. Gras, K. Razavi, H. Bos, and C. Giuffrida. Translation Leak-aside
Buffer: Defeating Cache Side-channel Protections with TLB Attacks.
USENIX Security Symposium, 2018.
[24] D. Gruss, C. Maurice, A. Fogh, M. Lipp, and S. Mangard. Prefetch Side-
Channel Attacks: Bypassing SMAP and Kernel ASLR. Proceedings of
the 2016 ACM SIGSAC Conference on Computer and Communications
Security, pages 368–379, 2016.
[25] M. Hicks, C. Sturton, S. T. King, and J. M. Smith.
SPECS:
A Lightweight Runtime Mechanism for Protecting Software from
Security-Critical Processor Bugs. In Proceedings of the International
Conference on Architectural Support for Programming Languages and
Operating Systems, ASPLOS. ACM, 2015.
[26] M. Howard and S. Lipner. The Security Development Lifecycle. Mi-
crosoft Press Redmond, 2006.
[27] H. Hu, S. Shinde, A. Sendroiu, Z. L. Chua, P. Saxena, and Z. Liang.
Data-oriented programming: On the expressiveness of non-control data
attacks. IEEE Symposium on Security and Privacy, 2016.
[28] B.-Y. Huang, S. Ray, A. Gupta, J. M. Fung, and S. Malik. Formal Se-
curity Veriﬁcation of Concurrent Firmware in SoCs Using Instruction-
level Abstraction for Hardware. ACM Annual Design Automation
Conference, pages 91:1–91:6, 2018.
[29] R. Hund, C. Willems, and T. Holz. Practical timing side channel attacks
against kernel space ASLR. Symposium on Security and Privacy, 2013.
[30] F. Inc. Common Vulnerability Scoring System v3.0. https://www.
first.org/cvss/cvss-v30-specification-v1.8.pdf, 2018.
[31] Intel.
Intel Software Guard Extensions (Intel SGX).
https://
software.intel.com/en-us/sgx, 2016. Last accessed on 09/05/18.
[32] Intel.
Intel Bug Bounty Program.
https://www.intel.
com/content/www/us/en/security-center/bug-bounty-
program.html, 2018.
[33] S. Islam, A. Moghimi, I. Bruhns, M. Krebbel, B. Gulmezoglu, T. Eisen-
barth, and B. Sunar. SPOILER: Speculative Load Hazards Boost
Rowhammer and Cache Attacks. https://arxiv.org/abs/1903.
00446, 2019.
[38] C. Lattner and V. S. Adve. LLVM: A compilation framework for
lifelong program analysis & transformation. International Symposium
on Code Generation and Optimization, 2004.
[39] D. Lee. Keystone enclave: An open-source secure enclave for risc-v.
https://keystone-enclave.org/, 2018.
[40] Lenovo.
Lenovo: Taking Action
on Product Security.
https://www.lenovo.com/us/en/product-security/about-
lenovo-product-security, 2017.
[41] X. Li, V. Kashyap, J. K. Oberg, M. Tiwari, V. R. Rajarathinam, R. Kast-
ner, T. Sherwood, B. Hardekopf, and F. T. Chong. Sapper: A Language
for Hardware-level Security Policy Enforcement. International Con-
ference on Architectural Support for Programming Languages and
Operating Systems, pages 97–112, 2014.
[42] X. Li, M. Tiwari, J. K. Oberg, V. Kashyap, F. T. Chong, T. Sherwood,
and B. Hardekopf. Caisson: A Hardware Description Language for
Secure Information Flow. ACM SIGPLAN Conference on Programming
Language Design and Implementation, 46(6):109–120, 2011.
[43] M. Lipp, M. Schwarz, D. Gruss, T. Prescher, W. Haas, S. Mangard,
P. Kocher, D. Genkin, Y. Yarom, and M. Hamburg. Meltdown. https:
//arxiv.org/abs/1801.01207, 2018.
[44] Mentor. Questa Veriﬁcation Solution. https://www.mentor.com/
products/fv/questa-verification-platform, 2018.
[45] A. Moghimi, T. Eisenbarth, and B. Sunar. MemJam: A false depen-
dency attack against constant-time crypto implementations in SGX.
Cryptographers’ Track at the RSA Conference, pages 21–44, 2018.