λ ≥= 1120 will sufﬁce. Then if K = 1000, λ can be as low
K
as 2 epochs, if K = 100, then λ = 126 epochs (or 5.25 days), but
to get an average number of visits per epoch to within K = 1, we
would need over 140 years.
We now analyze the case where some fraction of DCs may be
malicious. Assume that we expect that the total honest weight is at
√
H = 240/0.8 = 300. Then, for
least 80%. We adjust σ to σH = σ
λ ≥ 1400 will sufﬁce. For the
the same utility error as above, K
same values of K we would now need 2 epochs, 8.2 days, and over
224 years respectively.
In the preceding analysis we only need consider the amount of
noise to add in terms of the standard deviation σ of the distribution
we sample from. We can link this back to (, δ)-differential privacy
by observing the parameters’ relation to σ as follows [14]:
(cid:115)
(cid:18) 1.25
(cid:19)
ln
δ
σ =
·
S

Thus, rather than, as in previous works [10, 14], having the system
designer select not-very-meaningful values of  and δ, and comput-
ing σ as above to determine how much noise to add, we instead
determine σ directly using parameters speciﬁcally pertinent to the
system and to the questions it is trying to answer.4
4.4.2 Distributed Noise Application
The DCs independently apply the noise as we never want the raw
(un-noisy) data to be divulged. We can distribute the application
of noise since we know from Dwork et al. [11] that if individual
databases are differentially private then so is their sum.
A naive way to go about this, and one that avoids the use of third
parties, is for the DCs to publish their noisy data directly to the
public. The consequence of this is that each DC would need to add
enough noise so that its individual statistics provided the desired
bound on the advantage of the privacy adversary. This would make
the total noise considerably larger (by a factor of the square root
of the number of DCs), and so the number of periods λ to average
over must increase by a factor of the number of DCs in order to
keep the desired bound on the utility error.
This is why PrivEx works with global noise instead of local
noise: each DC adds some amount of noise, whose total is dis-
tributed as N (0, σ) for the desired σ, but does so using secure
multiparty computation so that the individual noise components are
never revealed.
We then need to calculate how much noise each DC should add.
What we want is for each DC i to add noise from N (0, σi), where
σi is proportional to the probability wi that the DC will get used.
In Tor, for example, high-bandwidth nodes get used with higher
probability, so they will see more usage, and add more noise, while
more impoverished nodes will have less usage and less noise.
Then, given the desired σ, we want to solve for the σi such
that σi ∝ wi (so σi = wi · φ for some φ independent of i) and
4Since we only ever make one query we do not need to calculate
how much privacy budget we have left after publishing our aggre-
gated statistics.
Figure 5: The probability of error is 0.1% (dark shaded area)
when the reported statistic (averaged over λ = 126 epochs)
appears closer to K than to 0. Compare this to the much larger
error of 41.75% (lighter shaded area) when λ = 1.
λ
λ
N (0, 1) 
√
2σ ], as depicted in Figure 5. Slightly different questions would
K
λ
produce slightly different formulas for the utility error, but they will
be computable in the same vein.
) > K
Therefore, for a given sensitivity S and tolerance P on the ad-
vantage of the privacy adversary, we can work out the desired stan-
dard deviation σ for our noise by solving for P r[0  K
√
2σ ] ≤ U similarly.
λ
In the presence of possibly malicious DCs, the situation is only
slightly more complicated. Malicious DCs (who do not immedi-
ately forget the amounts of noise with which they initialized the se-
cure counters) know the amount of noise they added. By removing
that from the reported tally, the remaining amount of noise (con-
tributed by the honest DCs) is less than expected.
As we will see in §4.4.2, each DC i adds noise selected from a
normal distribution whose standard deviation is proportional to its
weight—the probability wi that that DC will be selected by a user.
If we can assume a lower bound H on the total weight of honest
DCs, we can adjust the above calculations in a simple manner. (In
§5.1.2 we will argue that H = 0.8 is a reasonable lower bound
for Tor.) Honest DCs tune the amount of noise to add by adjusting
H . This has the effect that honest DCs
the value of σ to σH = σ
add more noise so that it maintains the desired privacy level, at
00.0020.0030SK/2KS/2σ/√λσUtility Loss (S=6, K=100, λ=126)N(µ=0,σ=240)Utility Error aggregating over 1 epochN(µ=0,σ/√λ=21.38)Utility Error aggregating over λ epochs(cid:80)
i N (0, σi) ∼ N (0, σ). Since(cid:80)
(cid:0)(wi · φ)2(cid:1), so solving for φ, we ﬁnd that
we have that σ2 =(cid:80)
wi√(cid:80)
i N (0, σi) ∼ N (0,(cid:112)(cid:80)
. In PrivEx, the values of φ and σ are
σi = wi · φ = σ ·
made available to the DCs from the PBB or TKSs.
i(w2
i )
i σ2
i ),
i
That we are adding together a potentially large number of inde-
pendent noise sources is the reason we target Gaussian rather than
Laplacian noise: while adding many Gaussians yields a Gaussian,
a Laplacian distribution cannot be decomposed into sums of other
independent random variables.
We note that, when adding noise, it is important for each DC to
preserve non-integral and negative values for the noisy count, so
that, when added together, extra biases are not introduced. As the
encryption used in our counters takes integer plaintexts, we must
use a ﬁxed-point representation where all of our values are ex-
pressed as multiples of some small number γ. If there are N DCs,
then in order that adding N values of resolution γ together will be
unlikely to produce an error of more than 1, we set γ ≤ 1
√
For N ≈ 1000, as in the current Tor network, γ = 0.01 will suf-
ﬁce.5 Note, however, that this ﬁxed-point representation expands
γ , and so increases the time to
the plaintext space by a factor of 1
compute the discrete logarithm in the ﬁnal step of the PrivEx-D2
protocol by a factor of 1√
N
.
2
γ .
4.4.3 Targeted Temporal Queries
PrivEx publishes the noisy total statistics for each epoch. The
amount of noise is computed to protect privacy, and a number of
epochs’ statistics must be averaged to gain utility. However, these
epochs do not need to be consecutive, so, for example, one could
ask questions like, “Is Wikipedia visited via this ACN more often
on weekends or weekdays?”. The number of epochs to average will
not change, however, so if the epochs of interest are spread out in
time, the total time to answer such a question will increase.
5. SECURITY ANALYSIS
5.1 Resistance to Attacks
We now address the attacks that are of the most concern. Re-
call that our requirement for security is that PrivEx should not re-
veal private information to an adversary, even if it fails to produce
meaningful answers to the system designers’ questions.
5.1.1 Legal or Other Compulsion
A DC can be compelled to reveal its database of collected statis-
tics through a legal order or extra-legal compulsion. If this database
is stored in the clear then privacy would be violated. PrivEx miti-
gates this threat by storing an encrypted database with the property
that the DC cannot decrypt the database on its own. Recall that at
the setup stage in PrivEx, all DC databases were encrypted using
shared keys with, or public keys of, the tally key servers.
The adversary can also compel the servers to comply in the de-
cryption of individual DCs’ measurements (with less noise than
the aggregate). This would indeed be troublesome, but we mitigate
this by ensuring that the PrivEx servers are distributed across di-
verse legal boundaries making compulsion infeasible. Indeed, as
long as at least one server is uncompromised then all DC data is
safe. Furthermore, since we start with fresh keys for each epoch,
this compulsion could not occur retroactively.
PrivEx requires that we bound the sensitivity—the maximum
number of times one client can access a particular website in one
5This also deals with an issue with rounding and differential pri-
vacy identiﬁed by Mironov. [24]
epoch. We do this by maintaining, in plaintext, a list of websites
visited during the lifetime of a circuit, which is 10 minutes in Tor.
This introduces a potential information leak if the adversary is able
to compromise an honest DC while circuits are being served; this
would reveal the censored websites visited by each circuit. While
this in itself does not link a client to a destination an adversary may
use this information to correlate trafﬁc patterns it can record at the
client side of the circuit. However, if the adversary can compromise
an ACN relay while it is actively serving an open circuit, then the
encryption keys it could recover could compromise those circuits
anyway even without access to the plaintext list.
5.1.2 Malicious Actors
Data Collector. The DC can behave maliciously by reporting un-
true statistics. While there is no safeguard to an attack on the in-
tegrity of the statistics we are interested in, the conﬁdentiality of
the statistics collected at other DCs and the aggregate statistics that
are output by PrivEx are safe from the actions of a misbehaving
DC as long as the security of the encryption schemes that we use
remains intact. We may mitigate the impact of this attack by using
range proofs at additional computation and communication costs,
but this still does not remove the threat entirely. In §4.4.1 we sug-
gested that H = .8 is a reasonable lower bound on the amount of
honest DC weight for Tor. The reason we give this value is that if
more than 20% of the exit weight of Tor is compromised, then Tor
is sufﬁciently susceptible to circuit linking attacks [1], and could
more easily compromise clients without using the less-noisy statis-
tics provided by the degraded PrivEx.
Finally, we note that if a DC is compromised, the adversary can
also perform a correlation attack, and can likely read the mem-
ory, including encryption keys protecting any active circuits, thus
retroactively deanonymizing them. This is a shortcoming of the
underlying ACN; PrivEx does not exacerbate this problem.
Tally Key Server. The tally key servers collectively play a critical
role in the PrivEx schemes and hence are vectors of attack. A bad
actor may try to gain access to the statistics in a less secure manner
or an insecure intermediate form (i.e. without noise).
We guard against this in both variants of PrivEx by ensuring that
in the setup stage all DCs initialize their databases by encrypting
each secure counter using the key material provided by, or shared
with, all the participating TKS servers. This ensures that even if
all but one TKS try to decrypt the data in an information-leaking
manner, a single honest server’s key material and noise added by
the DCs prevents any information from being revealed.
In PrivEx-S2, a single DC or TKS can launch a denial of ser-
vice attack by not sending its share, which would mean that for
that epoch no results could be determined. In PrivEx-D2, we can
identify the misbehaving TKS, which introduces consequences to
DoSing. In either case, no private information is leaked.
Tally Server and Public Bulletin Board. The TS and PBB are
unable to learn anything extra by misbehaving since none of the
intermediate data is ever in the clear and their inputs and outputs
are public, making veriﬁcation possible.
5.2 Correlation Attack with Auxiliary Infor-
mation
Data Collector trafﬁc information may not reveal anything on its
own, but there is a danger that an attacker could fruitfully combine
it with auxiliary information, such as observations of a target user’s,
or indeed of many users’, network trafﬁc.
For example, if we did not add noise, but simply released accu-
rate counts only if they were in excess of some threshold, then an
adversary could generate its own network trafﬁc to push the counts
above the threshold, and then subtract its own trafﬁc (for which
it knows the true counts) to yield accurate counts of potentially a
single user’s trafﬁc.
The differential privacy mechanism proposed adequately addresses
this threat. It ensures that, for any adversary, the response of PrivEx
if the target user did visit a target website in a given epoch will be
hard to distinguish from the response if the user did not.
We also note that since there is only one question PrivEx answers
(How many visits were made via the ACN to each of this list of
websites in this epoch?), and it can be asked only once per epoch,
differential privacy’s notion of a “privacy budget” is not required in
our setting.
6.
IMPLEMENTATION
We have built proof-of-concept implementations for both vari-
ants of PrivEx. They are implemented in Python using the Twisted
library for asynchronous networking between the parties of the sys-
tem.
Each PrivEx scheme uses a few hundred lines of python code.
The code is available for download from our PrivEx website.6 Both
schemes use TLS 1.2 with ECDHE for communication between
endpoints to ensure that the key material remains conﬁdential dur-
ing transit and beneﬁts from perfect forward secrecy. We set up
long-lived TLS connections when PrivEx ﬁrst comes online; their
communication and computational costs are amortized over many
epochs.
We have not implemented the Country of Origin feature at this
time since we would like to see PrivEx deployed in the Tor network
with the core feature set before expanding on it. The core imple-
mentation above is ACN agnostic, and we aim to integrate it with
Tor in the near future.
In the tables in this section, the “Per node” column is calculated