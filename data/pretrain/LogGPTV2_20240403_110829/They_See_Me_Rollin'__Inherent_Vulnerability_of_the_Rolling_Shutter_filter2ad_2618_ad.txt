an image for SSD and up to 65% for FRCNN. This is in line with the
fact that SSD is designed with more focus on speed of execution
050100FRCNN%ofHiddenObjectstexp=32µs25Hz250Hz500Hz750Hztexp=75µstexp=200µs050100SSD255075100FRCNN%ofObjectston(µs)texp=32µstexp=75µsHiddenMisplacedAppearedtexp=200µs1.3266.7533.3255075100SSD1.3266.7533.31.3266.7533.3406They See Me Rollin’: Inherent Vulnerability of the Rolling Shutter in CMOS Image Sensors
ACSAC ’21, December 6–10, 2021, Virtual Event, USA
7.2.2 Results. Figure 11 shows the frame-to-frame perturbation
introduced by the blinding and the rolling shutter attack for texp =
32µs and texp = 200µs. The results indicate that for short texp our
attack is causing interference that is similar across all metrics to
the expected level of perturbation seen in consecutive legitimate
video frames. In contrast, the blinding attack generates much larger
perturbations compared to our attack, which are easily detected.
We found that SSIM, MS-SSIM and UQI could detect almost 100%
of blinding attacks with the binary-threshold approach, i.e., ROC-
AUC of 0.99, 1.0 and 1.0, respectively. While higher texp causes
more perturbation, the level of interference is still closer to that for
legitimate video frames than for blinding. In comparison, for most
cases our attack was indistinguishable from legitimate frame-to-
frame changes when using the same threshold approach. The ROC-
AUC scores for the detection of the rolling shutter attack with texp
= 32µs and ton = 0.53ms are 0.61, 0.68 and 0.80, for SSIM, MS-SSIM
and UQI, respectively. Similar results (0.67, 0.79, 0.81) were observed
for texp = 200µs and ton = 0.01ms. However, as expected, the attack
is more easily detected with increasing ton. Nevertheless, choosing
the worst performing scenario for the rolling shutter attack at the 0%
false positive rate threshold (ton = 0.53ms, texp = 32µs and using
MS-SSIM), we obtain that 100% of blinding attacks are detected
while only 6.55% of rolling shutter attacks are.
8 COUNTERMEASURES
The vulnerability that enables the rolling shutter attack is inherent
to CMOS image sensors, meaning that attacks cannot be prevented
entirely without changing the hardware design. However, detection
in software can mitigate the attacks’ impact, while other counter-
measures are applicable in some special cases.
8.1 Hardware Countermeasures
A clear design option is to use a camera with a global shutter mech-
anism. This does not stop the injected light but prevents rolling
shutter attacks as the image rows are exposed at the same time,
leading to a simple blinding attack. However, this requires a design-
time choice and also carries additional component costs for incor-
porating frame memory or using CCD image sensors. These costs
increase dramatically for existing systems, as the replacements
must be retrofitted as well.
Additionally, camera redundancy is a straightforward protection
approach, but also quickly increases manufacturing costs for little
improvement in security. In some scenarios, the existing use of mul-
tiple sensors allows the system to continue operating effectively
despite the performance degradation caused by the rolling shutter
attack (e.g., in autonomous driving, with multiple cameras or LI-
DAR). However, it is not trivial to reliably determine which sensor
input is malicious or untrustworthy in order to stop relying on it.
Furthermore, while a system may be tolerant to the degradation of
its sensor inputs, there is still some finite budget for degradation
that it can withstand before it becomes unsafe or ineffective.
8.2 Deep Learning Based Detection
Here, we explore the re-use of the deep network used for the com-
puter vision task to detect the presence of the attack. We re-use
the backbone network using the insight that appearance of the
Figure 11: Image perturbation metrics between consecutive
frames for f = 750Hz during normal operation, a rolling
shutter attack and a blinding attack. High values correspond
to large perturbations.
rather than prediction accuracy: SSD can execute one inference
every 30ms, while FRCNN needs 89ms.
The impact that the rolling shutter attack can have on an au-
tonomous driving platform as a whole, where object detection is
used together with other components, is illustrated in Appendix C.
7.2 Comparison with Blinding Attack
7.2.1 Method. To measure the perturbation caused by our attack,
we repeated parts of the simulation on the BDD100K dataset as
described in Section 7.1. We randomly selected 100 videos from
the validation set and extracted 10 evenly spaced frame pairs,
whereas each pair consisted of two consecutive frames. For clarity,
we refer to those frames as previous and current. We then calcu-
lated the amount of perturbation between those consecutive frames
to evaluate how the current frame has changed compared to the
previous frame during (i) normal operation, (ii) a rolling shutter
attack, and (iii) a blinding attack. For (ii) and (iii), we generated
corrupted frames by overlaying the malicious patterns, as described
in Section 7.1, onto the current frame of each pair. We measured the
image perturbation with several metrics from adversarial machine
learning literature [39]. For each scenario and pair of frames, we
calculated three different metrics: the Structural Similarity (SSIM),
Multi-Scale SSIM (MS-SSIM) and Universal Image Quality Index
(UQI). The values for SSIM, MS-SSIM and UQI are bounded in [0, 1]
and were inverted in our case to represent dissimilarity rather than
similarity. In addition, we removed perturbations with a value of 0,
as these correspond to stationary frames. To measure the detection
performance for pairs of anomalous frames, we set up a simple
binary-threshold approach, i.e., if the dissimilarity metric value is
higher than a certain threshold, we label the frame pair as anoma-
lous. We report detection results with the area under the receiver
operating characteristic curve (ROC-AUC), where a score of 1.0
corresponds to perfect detection while a score of 0.5 corresponds
to random guess.
407ACSAC ’21, December 6–10, 2021, Virtual Event, USA
Sebastian Köhler, Giulio Lovisotto, Simon Birnbach, Richard Baker, and Ivan Martinovic
Table 3: Rolling shutter attack detection performance for
the backbone networks. False Negatives (FN) and False Posi-
tives (FP) are calculated over 3,560 test frames. The column
Overhead represents the computational overhead for the de-
tection mechanism in percentages with the standard devia-
tion in parentheses.
Model
SSD
SSD
FRCNN
FRCNN
Backbone
Mobilenet v2
Inception v2
Inception v2
Resnet-50
Accur.
0.98820
0.99494
0.99551
0.98989
FN FP Overhead in % (±σ )
32
18
7
25
+0.57 (±4.059)
+0.13 (±4.242)
-0.11 (±5.045)
+1.38 (±5.119)
10
0
9
11
distortions can be captured by early convolutional filters, designed
to capture low-level input features.
Setup and Training. Given the backbone network, we added a
network head as follows: on top of the first convolutional layer
(after pooling, when present) we added one additional convolution
layer with 32 filters, then we used global maximum pooling and
added a binary classification layer which predicts whether the
input is corrupted by a rolling shutter attack. We also used dropout
and selected leaky ReLu as the activation function, which has been
found to lead to faster convergence and improved performance [52].
We created a dataset to train our detection by splitting both collected
patterns and video frames into training, validation and testing
subsets, with ratios 60%, 20% and 20%, respectively. As in Section 7.1,
corrupted frames were obtained by overlaying the pattern onto the
legitimate frame. We used all patterns collected for the Axis camera
(∼6,500, see Section 6.1) and 180 videos randomly selected from
BDD100K, which we sampled every 10th frame (20,880 frames). We
used cross entropy loss and trained the added parameters with
Adam, with learning rate 10−4 and for 10 epochs.
Results. The test set accuracies for the two object detectors with
different backbones are presented in Table 3. The detection is effi-
cient, all networks obtain over 98.8% accuracy on the task, although
MobileNet v2 performs slightly worse due to design compromises
for faster execution speed. Table 3 also reports the number of False
Negatives (FN) and False Positives (FP). This shows that setting the
detection threshold to 0.5 would generally tend to favor low false
positives, but a different trade-off can be sought by changing the
threshold for detection.
To analyze the performance impact of the proposed detection
mechanism, we measured the required inference time for all images
in the test set (batch size = 1) with and without the added layers
on an NVIDIA TITAN RTX. The last column of Table 3 shows
the computational overhead of the detection, indicating that it is
negligible. As such, this detection measure could be applied as a
software patch to protect existing systems. Additionally, the method
represents a general approach that can be applied to protect any
computer vision network from rolling shutter attacks.
9 LIMITATIONS
In this section, we provide an overview of the limitations of our
evaluation and the rolling shutter attack itself.
9.1 Evaluation Limitations
The evaluation presented in this paper is a first step in raising
awareness about the rolling shutter attack and its impact. Never-
theless, our attack evaluation has some limitations that an attacker
might need to consider when performing the attack. Although the
patterns we used have been collected from real cameras under close
to real-world settings, our simulations do not perfectly reflect the
dynamic behavior of the target camera under attack. Depending
on the camera, numerous factors and mechanisms may influence
the appearance of the injected distortion. We mimicked the behav-
ior by exhaustively simulating the attack with different patterns
that correspond to different exposure times. Nevertheless, depend-
ing on the scenario, an attacker might not always freely choose
parameters f and ton while maintaining the desired brightness
of the injected distortions. For instance, in bright settings, short
ton and non-powerful lasers might not generate enough light to be
captured by the camera. Furthermore, we have not explicitly consid-
ered the effect of auto-exposure and auto-focus mechanisms. While
we found that these are generally not triggered for most of our
attack configurations, we cannot exclude that these mechanisms
might come into play as the attack is executed (this will depend
on camera-specific factors). This will have an effect on the appear-
ance of the distortions and may cause warnings in the vision-based
system.
9.2 Attack Limitations
Due to the characteristics of the rolling shutter attack, there are
some limitations that cannot be easily solved.
Limitations in Dim Conditions. Contrary to what humans per-
ceive, the amount of ambient light does not scale linearly between
what is perceived as bright versus what is perceived as dark. For
example, on a clear day, the amount of ambient light at midday
is >30k lx, at sunset, it is ∼400 lx while at night it is close to 0 lx.
Cameras are no exception: in poor lighting conditions, cameras
have to increase the exposure time dramatically to capture enough
light. This leads to a large overlap of consecutive pixel rows re-
sulting in fine-grained distortions not being achievable. Therefore,
in dim conditions, even a very short ton will impact a significant
proportion of image rows, limiting the amount of high-frequency
distortions from which the attack benefits.
Timing & Synchronization. While it is, in principle, possible to
target specific rows during the attack, tight synchronization be-
tween the modulation signal and the row reset signal of the image
sensor is required. Altering the content of the i-th row to hide a spe-
cific object, requires exact knowledge about the exposure timing. In
case the attacker has access to the video feed, such synchronization
could be obtained through an iterative process. However, as in our
threat model, it is generally reasonable to assume that the attacker
does not have this information and therefore needs to design their
attack accordingly.
Frame Rate Accuracy. To control the movement of distortions
between consecutive frames, the laser modulation must vary in
relation to the camera frame rate, or a multiple of it. Accurate
knowledge of the frame rate allows the attacker to keep the pro-
gression of the pattern in line with their intentions. The frame rate
408They See Me Rollin’: Inherent Vulnerability of the Rolling Shutter in CMOS Image Sensors
ACSAC ’21, December 6–10, 2021, Virtual Event, USA
F of a camera is typically specified in the datasheet, although minor
timing inaccuracies might cause the frame rate to deviate slightly
(e.g., 30.0025 fps instead of 30 fps). However, this only causes the
pattern to drift slowly if the attack is carried out over an extended
period of time and is negligible for attacks of short duration.
10 CONCLUSION
In this paper, we have highlighted an inherent vulnerability of
the electronic rolling shutter mechanism implemented in most
modern CMOS image sensors, which can be exploited to inject
fine-grained distortions into the captured frames. We showed how
an adversary can construct an attack in practice by introducing a
model to accurately predict the size of the injected distortions. We
describe how this model can be used to account for uncontrolled
camera-specific and environmental variations, in order to make
the attack more reliable. Using only off-the-shelf equipment, we
reproduced the attack steps in practice on two separate cameras.
We then investigated the attack within the context of an object
detection task, where the camera-captured images are used by
computer vision models to locate and classify objects. Based on two
well-known video datasets, we evaluated the performance of two
state-of-the-art object detection models under the rolling shutter
attack, showing that for SSD, our attack can hide up to 75% of
objects present in the input frames. At the same time, we showed
that our attack is stealthier than a global blinding attack across
several anomaly metrics, making it harder to detect. Our findings
outline a weakness in using cameras with CMOS images sensors in
settings with potentially-adversarial camera inputs, and particularly
for computer vision applications in safety-critical systems.
ACKNOWLEDGMENTS
This work was supported by a grant from Mastercard and by the
Engineering and Physical Sciences Research Council (EPSRC).
REFERENCES
[1] Amazon.com. [n. d.]. 1,8 W A M140 445 Nm blue Diode.
https://www.amazon.com/dp/B00UECEMEE.
[2] Amazon.com. [n. d.]. JING TAI Powerful Pointer.
https://amazon.com/dp/B0932TQMNZ.
(1976).
[3] Axis Communications. 2020. Network video solutions for all industries.
https://www.axis.com/en-us/solutions-by-industry.
[4] BE Bayer. 1976. Colour filter array. United States of America patent 3971065
[5] Yulong Cao, Jiaxiang Ma, Kevin Fu, Rampazzi Sara, and Morley Mao. [n. d.].
Automated Tracking System For LiDAR Spoofing Attacks On Moving Targets.
([n. d.]).
[6] Yulong Cao, Yimeng Zhou, Qi Alfred Chen, Chaowei Xiao, Won Park, Kevin
Fu, Benjamin Cyr, Sara Rampazzi, and Z. Morley Mao. 2019. Adversarial sensor
attack on LiDAR-based perception in autonomous driving. Proceedings of the
ACM Conference on Computer and Communications Security (2019), 2267–2281.
https://doi.org/10.1145/3319535.3339815 arXiv:1907.06826
[7] Yaobin Chen and Lingxi Li. 2013. Advances in Intelligent Vehicles. https://doi.
org/10.1016/C2011-0-07400-8
[8] Anthony Cuthbertson. 2019. Hong Kong protesters use lasers to avoid facial
recognition cameras and blind police. https://www.independent.co.uk/news/
world/asia/hong-kong-protests-lasers-facial-recognition-ai-china-police-
a9033046.html.
[9] Jifeng Dai, Yi Li, Kaiming He, and Jian Sun. 2016. R-fcn: Object detection via
region-based fully convolutional networks. In Advances in neural information
processing systems. 379–387.
[10] Henry Dietz and Paul Eberhart. 2019. Shuttering methods and the artifacts they
produce. Electronic Imaging 2019, 4 (2019), 590–591.
[11] Alexey Dosovitskiy, German Ros, Felipe Codevilla, Antonio Lopez, and Vladlen