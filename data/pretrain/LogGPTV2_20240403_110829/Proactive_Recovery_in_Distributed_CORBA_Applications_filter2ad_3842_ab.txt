### Optimized Text

#### Proactive Fault-Tolerance Manager and Recovery Mechanisms

When a replica consumes 80% of its allocated resources, the Proactive Fault-Tolerance Manager (PFTM) at that replica requests the Recovery Manager to launch a new replica. If the resource usage exceeds a second threshold, such as 90% of the allocated resources, the PFTM can initiate the migration of all current clients to the next non-faulty server replica in the group.

#### Challenges in Developing the Proactive Fault-Tolerance Manager

We encountered two primary challenges during the development of the Proactive Fault-Tolerance Manager:

1. **Timing of Proactive Recovery:**
   - **Challenge:** Determining the optimal time to initiate proactive recovery.
   - **Issue with Early Triggering:** Initiating fault-recovery too early can lead to unnecessary overhead from prematurely failing over clients to non-faulty servers, thereby negating the benefits of a proactive strategy.
   - **Issue with Late Triggering:** Delaying recovery initiation can cause the system to resemble a reactive strategy, as it may not have enough time to fail-over client processes to a non-faulty server.
   - **Solution:** The ideal trigger time depends on factors such as the server's fault rate and the time required for fault-recovery, which includes finding an alternative working server replica, restoring its state, and redirecting clients.

2. **Ensuring a Quiescent State:**
   - **Challenge:** Ensuring the faulty replica reaches a quiescent state before restarting.
   - **Issue:** Simply restarting a server replica when the rejuvenation threshold is reached can cause significant "spikes" in client round-trip times due to CORBA exceptions.
   - **Solution:** Using proactive recovery messages to seamlessly redirect existing clients to the next non-faulty server in the group, thereby reducing these "spikes."

#### MEAD Recovery Manager

Within our proactive dependability framework, the MEAD Recovery Manager is responsible for launching new server replicas to restore the application's resilience after a server replica or node crashes. The Recovery Manager must have up-to-date information about the server's degree of replication (i.e., the number of replicas). To propagate this information, new server replicas join a unique server-specific group upon launch, allowing the Recovery Manager to receive membership-change notifications and launch new replicas as needed.

The Recovery Manager also receives proactive fault-notification messages from the MEAD Proactive Fault-Tolerance Manager, which can trigger the launch of a new replica to replace one that is expected to fail. Currently, the Recovery Manager is a single point of failure, but future implementations will extend proactive mechanisms to it as well.

#### Proactive Recovery Schemes

The Proactive Fault-Tolerance Manager implements proactive recovery through three different schemes: GIOP LOCATION FORWARD Reply messages, GIOP NEEDS ADDRESSING MODE Reply messages, and MEAD’s own proactive fail-over messages. Each scheme assumes the use of CORBA’s persistent object key policies to uniquely identify objects, facilitating request forwarding between server replicas.

1. **GIOP LOCATION FORWARD Messages:**
   - **Mechanism:** The server sends a LOCATION FORWARD Reply message containing an Interoperable Object Reference (IOR) to redirect clients to an alternative server location.
   - **Advantages:** No need for a client-side Interceptor; the client ORB handles retransmission.
   - **Disadvantages:** High overhead due to parsing incoming GIOP Request messages and maintaining IORs.

2. **NEEDS ADDRESSING MODE Messages:**
   - **Mechanism:** The server sends a NEEDS ADDRESSING MODE Reply message, prompting the client ORB to resend the request.
   - **Advantages:** Masks communication failures from the client application.
   - **Disadvantages:** Can increase average fail-over time and is based on the assumption that an EOF response indicates an abrupt server failure, which is not always true.

3. **MEAD Proactive Fail-over Messages:**
   - **Mechanism:** The PFTM intercepts the listen() call to determine the server's listening port, broadcasts this information, and redirects client connections using a combined GIOP Reply and MEAD message.
   - **Advantages:** Reduces average failover time by avoiding request retransmission and incurs low overhead.
   - **Disadvantages:** Does not readily support replicated clients.

#### Empirical Evaluation

**Fault-Injection Strategy:**
- **Method:** A memory-leak fault was injected by declaring a 32KB buffer and slowly exhausting it according to a Weibull probability distribution.
- **Activation:** The memory leak was activated upon the first client request, and memory chunks were exhausted every 150ms, leading to approximately one server failure per 250 client invocations.

**Results:**
- **Experimental Setup:** Experiments were conducted on five Emulab nodes with specific hardware and software configurations, using a simple CORBA client requesting the time-of-day from three warm-passively replicated CORBA servers.
- **Comparison:** Proactive schemes were compared against traditional reactive recovery schemes, measuring parameters such as percentage increase in client-server round-trip times, percentage of failures exposed to the client application, and failover time.
- **Findings:**
  - **Reactive Without Cache:** 1:1 correspondence between client and server failures.
  - **Reactive With Cache:** Higher failure rate due to stale cache references.
  - **NEEDS ADDRESSING MODE:** Eleven client-side failures due to insufficient advance warning.
  - **Proactive Schemes (LOCATION FORWARD, MEAD Message):** No client exceptions when there was sufficient advance warning of impending failure.

#### Summary

- **Proactive Recovery:** Effectively reduces the exposure of failures to the client application and minimizes failover times.
- **Optimal Thresholds:** Proactive recovery is most effective when triggered at thresholds below 100%.
- **Future Work:** Extending proactive mechanisms to the Recovery Manager to eliminate single points of failure.