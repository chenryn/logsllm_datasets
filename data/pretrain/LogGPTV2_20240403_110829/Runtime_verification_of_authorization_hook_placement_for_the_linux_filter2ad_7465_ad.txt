number of different authorization cases that exist in the data. Also,
the sensitivity class lists are easier to use in regression testing since
they are textual [9].
Figure 6 shows the partition of controlled operations for the read
system call. This partition is used as the example in Section 3.2. As
Authorization graph for fcntl calls
Figure 5:
for
F SETLEASE (controlled operations
in lease modify
and fput) and F SETOWN (controlled operations in do fcntl
and put). When command is F SETOWN both FCNTL and
SET OWNER are authorized, but only FCNTL is authorized for
F SETLEASE.
system call context. The speciﬁcation of (D,1) on the second line
means that all controlled operations of this type within a read sys-
tem call will be extracted. If the authorizations associated with this
controlled operation are not the same, then the member access is
sensitive to its location.
The system call input sensitive rule collects all the log entries
in each open system call for read-only access. The authorizations
of the open system call depend on the access for which the ﬁle is
opened, so open is system call input sensitive. Further, we also
show a negative ﬁlter in this rule that eliminates all entries within
the scope of the path_walk function. The authorizations for ﬁle
lookup, including any link traversal, can be separated from those
for authorizing the open of this ﬁle. Such ﬁltering capabilities en-
able us to choose our analysis scope ﬂexibly.
4.2.2 Graphical Log Analysis
The analysis tool can also generate graphs that enable visual
analysis of the ﬁltered data. Using these graphs, it is possible to
verify the authorization sensitivities by inspection, as we will de-
scribe below. An authorization graph consists of two sets of nodes
in a ﬁltered log: (1) the controlled operations and (2) the autho-
rizations made. Edges are drawn from each controlled operation
to the authorizations that have been satisﬁed when it is run. There
are two types of edges: (1) always edges mean that the associated
authorization is satisﬁed every time the controlled operation is run
and (2) sometimes edges mean that the associated authorization is
satisﬁed at least once when the controlled operation is run.
An always edge (as well as the lack of an edge) means that the
authorization is not sensitive to lower-level attributes. A sometimes
edge indicates a sensitivity. The lack of an edge where an edge
would be expected would indicate a missing authorization.
Figure 5 shows an example authorization graph. The example
graph is displayed using the dotty graph visualization tool [10].
In this case, the authorization graph shows the controlled oper-
ations and the authorizations for two types of fcntl calls: (1)
fcntl(fd, F_SETOWN, pid_owner) and (2) fcntl(fd,
F_SETLEASE,F_UNLCK). The controlled operation nodes in-
clude location (function name, ﬁle name, line number) and oper-
232# fcntl for F SETOWN with just the field
f owner
1 = (+,id type,CONTEXT) (+,di cfm eax,fcntl)
(+,co ecx,F SETOWN)
2 (D,1) = (+,id type,SEC CHK)
3 (D,1) = (+,id type,CNTL OP)
(+,di dfm member,f owner)
# fcntl for F SETLEASE with just the field
f owner
4 = (+,id type,CONTEXT) (+,di cfm eax,fcntl)
(+,co ecx,F SETLEASE) (+,co edx,F UNLCK)
5 (D,4) = (+,id type,SEC CHK)
6 (D,4) = (+,id type,CNTL OP)
(+,di dfm member,f owner)
Figure 7: Rules for ﬁnding the f owner anomaly.
described there, the sensitivity class list shows two classes that are
sensitive at the datatype level: one for tasks and superblocks with
no authorizations and one for ﬁles with read authorization. Then,
the sensitivity class list has two classes that are object-sensitive:
one for the inode that is read authorized and one for its directory
that has no authorizations. Ultimately, we expect to annotate cur-
rent task, ﬁle’s directory, and ﬁle’s superblock as read authorized
which will result in all controlled operations having the same au-
thorization (i.e., being system call sensitive).
Most of our experience is with the ﬁle system although we have
also examined task authorizations. Most objects have either one or
no authorizations, so the sensitivity class lists are not too complex.
The system call unlink is one of the few where an object has mul-
tiple authorizations. Using sensitivity class lists it is easy to see that
the directory inode has three authorizations (exec, write, unlink dir)
and the inode being removed has one (unlink ﬁle) because they are
object-sensitive and placed in different classes. Thus, for the ﬁle
system and the task operations we have examined, authorization
graphs and sensitivity class lists have been sufﬁcient to verify au-
thorizations.
4.2.4 Sample Analysis
We brieﬂy demonstrate a sample analysis for an anomaly that
we found. While the approach to ﬁnding anomalies was devel-
oped concurrently to actually ﬁnding anomalies, we used roughly
the same approach as described although some of it was not auto-
mated. This anomaly occurs in the fcntl system call. The sensi-
tivity class list for fcntl shows that its authorizations are system
call input sensitive. The values of the cmd and arg parameters
to fcntl can change the authorizations that are required. We use
authorization graphs to look at the authorizations under the differ-
ent inputs since it is easier to see coarse-grained problems – lots of
sometimes edges occur.
Figure 7 contains two sets of rules: (1) one which collects all
authorizations and controlled operations of the ﬁle structure ﬁeld
f_owner in a fcntl(fd, F_SETOWN, pid_owner) sys-
tem call and (2) one which collects all authorizations and controlled
operations on the ﬁeld f_owner in a fcntl(fd, F_SETLEASE,
F_UNLCK) system call. Note that this is same rule (less the fput
controlled operations) used to generate the graph in Figure 5.
In Figure 5, we see that some of the controlled operations are
authorized for the fcntl and set_fowner authorizations and
some are only authorized for fcntl. This is despite the fact that
the controlled operations access the same ﬁeld, f_owner (offset
480). Given this anomaly, we examined the kernel source to deter-
mine whether an exploit of this anomaly is possible. We discuss
the results of this analysis in the next section.
4.3 Results
We applied the December 10, 2001 LSM patch to the Linux
2.4.16 source and compiled the kernel using our modiﬁed version
of GCC-3.0 3. To create an execution log to analyze, we executed
in parallel three instances of LMBench, the SAINT vulnerability
tool (www.wwdsi.com/saint/), a kernel compile, some regular us-
age, and some test programs that we wrote as we became suspi-
cious of anomalies. Since the effectiveness of runtime analysis de-
pends on running enough code, the development of benchmarks
that cover the enough of the interesting paths must be developed.
For example, LMBench only runs about 20% of the kernel code.
Also, our static analysis tool ﬁnds some other potential errors for
which benchmarks should be written to determine if they can be
exploited.
We have instrumented the kernel to collect controlled operations
on the major kernel data structures: ﬁles, inodes, superblocks, tasks,
sockets, and skbuffs. Thusfar, we have only done a detailed analy-
sis on the ﬁle system authorizations, and an initial analysis on task
authorizations. Since the ﬁle system is fairly well-understood, we
did not expect a large number of anomalies, but we found some
nonetheless.
(cid:15) Member Sensitive (multiple system calls): We found that
there is no authorization hook in the function setgroups16,
but that we can reset the task’s group set. An authoriza-
tion protects this operation in setgroups. This hook was
missed because these backwards ABI-compatible 16-bit task
operations, such as setuid16 and setchown16 usually
convert their 16-bit values to 32-bit values and call the cur-
rent versions that do contain authorizations. However, since
setgroups16 sets an array, it is easier not to convert the
array, so the current version (that contains a hook) is not
called. Note that there is no setgroups16 call in the cur-
rent version of libc, so we had to write an assembler program
to perform this exploit.
(cid:15) Member Sensitive (single system call): The f_owner.pid
member of struct file tells the kernel which process to
send signals to regarding IO on this ﬁle. Setting this ﬁeld is
authorized by file_ops->set_fowner if the user tries
to set it directly via fcntl(fd, F_SETOWN, pid_-
owner). However, if a user removes a lease from a ﬁle
via fcntl(fd, F_SETLEASE, F_UNLCK), the owner
is set to zero without the authorization being performed. Fur-
thermore, a process can set the owner of a Universal TUN de-
vice (drivers/net/tun.c) to itself without the authorization be-
ing performed. To achieve this, the process calls ioctl(fd,
F_SETFL, FASYNC) on an open, attached, TUN device.
(cid:15) Member Sensitive (single system call): During our investi-
gation of the sensitivity of filp.f_owner described above,
we we found that access to filp.f_owner.signum (the
signal that should be sent upon IO completion) can be set
without the authorization via fcntl(fd, F_SETSIG,
sig).
(cid:15) System Call Sensitive (missing authorization): A read
authorization is performed at the beginning of every read
3Keeping up with kernel version is not a great deal of work. We
have the system running on Linux 2.4.18 now, and the only thing
we had to do was update our authorization ﬁlter to the current LSM
interface.
233[6] J. Foster, M. Fahndrich, and A. Aiken. A theory of type
qualiﬁers. In ACM SIGPLAN Conference on Programming
Language Design and Implementation (PLDI ’99), pages
192–203, May 1999.
[7] P. Gutmann. The design and veriﬁcation of a cryptographic
security architecture, August 2000. Submitted thesis.
Available at
www.cs.auckland.ac.nz/ pgut001/pubs/thesis.html.
[8] ITSEC. Common Criteria for Information Security
Technology Evaluation. ITSEC, 1998. Available at
www.commoncriteria.org.
[9] T. Jaeger, X. Zhang, and A. Edwards. Maintaining the
correct of the Linux Security Modules framework. In
Proceedings of the 2002 Ottawa Linux Symposium, pages
223-241, June 2002.
[10] E. Koutsoﬁos and S. North. Drawing graphs with Dot.
Available at http://www.research.att.com/sw/tools/graphviz/.
[11] L. Koved, M. Pistoia, and A. Kerschenbaum. Access rights
analysis for Java. In Proceedings of 17th Annual ACM
Conference on Object-Oriented Programming Systems,
Languages, and Applications (OOPSLA), November 2002.
[12] D. Larochelle and D. Evans. Statically detecting likely buffer
overﬂow vulnerabilities. In Proceedings of the Tenth
USENIX Security Symposium, pages 177–190, August 2001.
[13] NCSC. Trusted Computer Security Evaluation Criteria.
National Computer Security Center, 1985. DoD
5200.28-STD, also known as the Orange Book.
[14] G. C. Necula, S. McPeak, and W. Weimer. CCured:
Type-safe retroﬁtting of legacy code. In Proceedings of the
29th ACM Symposium on Principles of Programming
Languages (POPL02), January 2002.
[15] U. Shankar, K. Talwar, J. S. Foster, and D. Wagner. Detecting
format string vulnerabilities with type qualiﬁers. In
Proceedings of the Tenth USENIX Security Symposium,
pages 201–216, August 2001.
[16] J. Viega, J. Bloch, Y. Kohno, and G. McGraw. ITS4: A static
vulnerability scanner for C and C++ code. In Proceedings of
2000 Annual Security Applications Conference, December
2000.
[17] D. Wagner, J. S. Foster, E. A. Brewer, and A. Aiken. A ﬁrst
step towards automated detection of buffer overrun
vulnerabilities. In Proceedings of Network and Distributed
System Security Symposium (NDSS 2000), February 2000.
[18] X. Zhang, A. Edwards, and T. Jaeger. Using CQUAL for
static analysis of authorization hook placement. In
Proceedings of the 11th USENIX Security Symposium,
August 2002.
system call. This authorization is required since the autho-
rization performed when the ﬁle was originally opened may
no longer be valid, due to the process changing its security
attributes, the ﬁle changing its security attributes, the ﬁle be-
ing used by a new process, or a change in the security policy.
This authorization, however, is not performed during a page-
fault on a memory-mapped ﬁle. Therefore, once a process
has memory-mapped a ﬁle it can continue to read the ﬁle re-
gardless of changes to security attributes or security policy.
We engaged in a discussion with that resulted in a patch to all
the anomalies, except the one for reading memory-mapped ﬁles.
The community decided that a ﬁle that requires read authorization
must not be memory-mapped. We are encouraged that we have
been able to help ﬁnd and ﬁx hook placement problems. We have
found that the analysis approach can document the current state of
an LSM kernel, so future LSM kernels can be regression tested.
Also, we are developing an approach that takes into account both
the static and runtime analyses. Lastly, we are also encouraged that
our initial assumption that LSM is mostly correct appears valid, at
least for the ﬁle system.
5. CONCLUSIONS
In this paper, we presented tools for assisting the Linux com-
munity in verifying the correctness of the Linux Security Modules
(LSM) framework. The LSM framework consists of a set of au-
thorization hooks placed inside the kernel, so it is more difﬁcult to
identify the complete mediation points. We leveraged the fact that
most of the LSM hooks are properly placed to identify misplaced
hooks. We used structure member operations on major kernel data
structures as the mediation interface and collected the authoriza-
tions on these operations. By analyzing the output of a runtime log-
ging tool, we identiﬁed the operations whose authorizations were
inconsistent. We have analyzed the ﬁle system and some task op-
erations and found some anomalies that could have been exploited.
Working with the LSM community, these problems have since been
ﬁxed. For example, we found that some variants of fcntl enabled
operations to be performed that were authorized in other cases. Ul-
timately, we found that runtime analysis is useful for verifying sys-
tems where a inconsistencies from the norm are likely to be errors.
Further development of benchmarks for runtime analysis remains
an challenge.
6. REFERENCES
[1] K. Ashcraft and D. Engler. Using programmer-written
compiler extensions to catch security holes. In Proceedings
of the IEEE Symposium on Security and Privacy 2002, May
2002.
[2] M. Bishop and M. Dilger. Checking for race conditions in
ﬁle accesses. Computing Systems, 9(2):131–152, 1996.
[3] H. Chen and D. Wagner. MOPS: An infrastructure for
examining security properties of software. In Proceedings of
the 9th Conference on Computer and Communications
Security, November 2002.
[4] A. Edwards, T. Jaeger, and X. Zhang. Runtime veriﬁcation of
authorization hook placement for the Linux Security
Modules framework. Technical Report RC22254, IBM
Research, December 2001.
[5] D. Engler, B. Chelf, A. Chou, and S. Hallem. Checking
system rules using system-speciﬁc, programmer-written
compiler extensions. In Proceedings of the Fourth
Symposium on Operation System Design and Implementation
(OSDI), October 2000.
234