title:An Efficient Black-box Technique for Defeating Web Application Attacks
author:R. Sekar
An Efﬁcient Black-box Technique for Defeating Web Application Attacks∗
Stony Brook University, Stony Brook, NY, USA
R. Sekar
Abstract
Over the past few years, injection vulnerabilities have
become the primary target for remote exploits. SQL in-
jection, command injection, and cross-site scripting are
some of the popular attacks that exploit these vulnerabili-
ties. Taint-tracking has emerged as one of the most promis-
ing approaches for defending against these exploits, as it
supports accurate detection (and prevention) of popular in-
jection attacks. However, practical deployment of taint-
tracking defenses has been hampered by a number of fac-
tors, including: (a) high performance overheads (often over
100%), (b) the need for deep instrumentation, which has
the potential to impact application robustness and stabil-
ity, and (c) speciﬁcity to the language in which an appli-
cation is written. In order to overcome these limitations,
we present a new technique in this paper called taint infer-
ence. This technique does not require any source-code or
binary instrumentation of the application to be protected;
instead, it operates by intercepting requests and responses
from this application. For most web applications, this inter-
ception may be achieved using network layer interposition
or library interposition. We then develop a class of policies
called syntax- and taint-aware policies that can accurately
detect and/or block most injection attacks. An experimental
evaluation shows that our techniques are effective in detect-
ing a broad range of attacks on applications written in mul-
tiple languages (including PHP, Java and C), and impose
low performance overheads (below 5%).
1
Introduction
The past few years have witnessed a signiﬁcant shift in
terms of software vulnerabilities: while buffer overﬂows in
C/C++ programs were dominant earlier, CVE reports indi-
cate that the vast majority of today’s vulnerabilities are in
∗This work was partially funded by Defense Advanced Research
Project Agency under contract N00178-07-C-2005, by ONR grant
N000140710928 and an NSF grant CNS-0627687. The views and con-
clusions contained in this document are those of the authors and should
not be interpreted as representing the ofﬁcial policies, either expressed or
implied, of the Defense Advanced Research Project Agency, the Naval
Surface Weapons Center, ONR, NSF, or the U.S. Government.
Figure 1. CVE vulnerabilities over 2006-07.
web applications. So-called injection vulnerabilities dom-
inate, including SQL injection, command injection, path
traversals, cross-site scripting (XSS), and so on. As shown
in Figure 1, more than half the CVE reports in 2006-071
correspond to these injection vulnerabilities. If we omit the
“other” category, which includes very general vulnerability
categories such as conﬁguration and design errors, and fo-
cus on well-deﬁned vulnerabilities, about 85% of these are
injection vulnerabilities2. The techniques developed in this
paper target this large fraction of current software vulnera-
bilities.
Figure 2 illustrates the general context for injection at-
tacks. The attack target (henceforth called a target appli-
cation, or simply as “application”) is a program that ac-
cepts requests (inputs) from an untrusted source.
It car-
ries out these requests using operations (henceforth called
“sensitive operations” or “outgoing requests”) on back-end
“resources” such as databases, back-end servers, ﬁles, and
other applications (including command interpreters) run-
ning on the target machine. Finally, it outputs a response
back to the client. The target application decides which sen-
sitive operations to make, as well as the parameters to these
operations.
1Speciﬁcally, the chart captures CVE candidates and vulnerabilities
2We are including format string vulnerabilities among injection vulner-
from January 2006 to July 2007.
abilities but not buffer overﬂows.
of data has its own taint bit. As a result, we can determine
whether an individual byte within a security-sensitive ar-
gument is derived from attacker-furnished data, and hence
can be “attacker-controlled.” In Figure 2, tainted data bytes
are shown using red color and in italics. A number of re-
searchers have developed techniques for ﬁne-grained taint-
tracking. Some of these techniques rely on processor-
support for taint-tracking [27, 5], while others rely on auto-
mated program transformations on source code [28, 13, 10]
or binary code [16, 22, 23].
To answer the second question, we need policies to cap-
ture the degree of control that is intended. For instance, in
Figure 2, the SquirrelMail developers intended that the un-
trusted user be able to control the values of some command-
line arguments to gpg, but not the introduction of shell
metacharacters (such as semicolons) or additional shell
commands. Attacks such as command injection, which pro-
vide the ability to introduce “commands” rather than “data,”
can be detected using very general policies that are inde-
pendent of the web application [4, 21, 26, 28, 10, 25]. For
attacks that involve injection of data, (e.g., use of unin-
tended data values in SQL queries, path traversals, etc.)
application-speciﬁc policies are usually needed.
Drawbacks of Taint-Tracking Techniques. Since taint-
based techniques were introduced, they have become the
de-facto standard for detecting injection attacks. They
have been shown to be very effective and accurate, pro-
viding essentially zero false positives and false negatives
[10, 28, 21, 17]. However, taint-based techniques suffer
from one of more drawbacks that make them difﬁcult to use
on production systems:
• Intrusive instrumentation. Taint-tracking requires a
ﬁne-grained transformation of the target application.
Every statement in the application needs to be trans-
formed to introduce additional statements that propa-
gate taint. Such instrumentation can affect the stability
and robustness of the target application, making ad-
ministrators reluctant to use these techniques on pro-
duction systems.
• High performance overheads. Taint-tracking tech-
niques, especially those operating on C [28, 13] or
binary code [16, 22, 23], have high overheads, often
slowing down programs by a factor of two or more.
• Language dependence. Source-code based techniques
[21, 17, 10, 28] are language-speciﬁc, and need to
be redesigned and reimplemented for each language.
Even for binary-based techniques, it is not straight-
forward to apply them across all languages — for in-
stance, applying a machine-code based taint-tracking
to Java requires the JVM to be taint-tracked, which can
Figure 2. SquirrelMail Command Injection.
To ensure that untrusted users cannot exert undue control
over these decisions, the target application should incorpo-
rate input validation checks on untrusted inputs. However,
due to software bugs, these checks may be incomplete, or
may be missed on some program paths between the input
and output operations. This leads to vulnerabilities that al-
low an attacker to modify the output operations by “inject-
ing” malicious data at the input. The left-hand side of Fig-
ure 2 shows the key statements responsible for a command
injection vulnerability in version 1.4.0 of SquirrelMail (a
popular web application for email access) with GPG plug-
in version 1.1.
(These statements are written in the PHP
language, and have been abstracted to improve readability.)
The right-hand side of the ﬁgure shows the input provided
by the attacker, and the result of executing the statements on
this input. In particular, SquirrelMail uses the program gpg
to encrypt email body. The gpg program needs to access
the public key of the recipient, so the recipient name should
be provided as a command-line argument. SquirrelMail re-
trieves the name of the recipient from the “to” ﬁeld on the
email composition form, and constructs a shell command to
launch gpg. By providing an unexpected value in the “to”
ﬁeld, the attacker is able to execute arbitrary commands on
the target machine. The ability to carry out an injection at-
tack hinges on these questions:
1. Is the attacker able to exert control over a sensitive
operation performed by an application?
2. Is this degree of control intended by the programmer
(or the administrator) of the target application?
Fine-grained taint-tracking has been proposed as an effec-
tive technique for answering the ﬁrst question. It involves
marking untrusted inputs as “tainted,” and as the program
uses this data, copying the taint labels together with data
values. Taint is tracked at ﬁne granularity, i.e., each byte
pose challenges in terms of false positives and false
negatives. As a result, previous techniques have either
been applicable to Java [10, 25] or to C/C++/compiled
binaries, but not both.
as shell, SQL and HTML. Equally important, variations
in these languages are handled without having to rewrite
code, e.g., our implementation supports variations in SQL
across different servers, as well as variations among com-
mon shell-scripting languages.
Our Approach.
In this paper, we overcome the above
drawbacks by developing a new,
low-overhead, non-
intrusive and language-independent approach for detect-
ing injection attacks. This approach features:
• an efﬁcient, black-box taint-inference technique, and
• a ﬂexible and powerful policy framework called
syntax- and taint-aware policies.
Our approach infers taint by observing data at the input and
output interfaces shown in Figure 2. These observations
could be made on the network in most cases, but our imple-
mentation relies primarily on library interposition. Taint is
inferred if the data at the output interface is obtained from
the data at the input interface using predeﬁned “transforma-
tions.” We point out that web applications frequently trans-
form their inputs, e.g., to decode form data and parameters,
remove white space, convert upper-case characters to lower-
case, etc. Our technique is designed to accommodate such
transformations.
Inferring taint from input/output observations may ap-
pear to be a hard problem, but we have been able to exploit
the characteristics of web applications to make this prob-
lem tractable. Incoming requests to web applications use
the HTTP protocol, with standardized ways of encoding pa-
rameter names and values. Web applications typically re-
trieve these parameter values, apply simple sanitization or
normalization operations on them, and ﬁnally use their val-
ues within an outgoing request sent to a back-end system.
As a result, data ﬂows can be identiﬁed by comparing input
parameter values against (all possible) substrings of outgo-
ing requests. Our technique relies on approximate (rather
than exact) string match so as to be able to identify taint in
the presence of simple sanitization or normalization opera-
tions used by a web application.
As observed by previous works [17, 21, 9, 26, 28], SQL
injection attacks are characterized by the fact that tainted
data modiﬁes the lexical and/or syntactic structure of an out-
going SQL query. Other attacks, such as cross-site scripting
(XSS), may not change the output structure, but are charac-
terized by certain sensitive components (e.g., a script name
or a script body) becoming tainted. Finally, format string
and path traversal attacks are characterized by the fact that
tainted parameters have impermissible values. In order to
detect all these attacks within a uniform framework, we
have developed a class of policies that we call as syntax-
and taint-aware policies. Our policy framework is able
to support different languages at the output interface, such
2 Overview of Approach
Figure 3 illustrates the architecture of our system.
It
“hooks” into existing web server/web application architec-
tures using network-layer or library interposition in order
to observe incoming and outgoing requests. These “events”
are captured by an event collector that feeds into a syntax
analyzer, which in turn feeds into the taint inference and
attack detection components.
The event collector is responsible for intercepting incom-
ing as well as outgoing requests. On the input side, our
system takes advantage of the plug-in architecture provided
by web servers such as Apache and IIS. Speciﬁcally, it is
possible to register plug-ins that get invoked at key points
during the processing of every HTTP request. This plug-in
can then examine the data associated with the request, as
well as the response. The event collector uses this frame-
work to keep track of “sessions,” which are used to limit
the scope over which taint inference algorithms are applied.
Each session begins when the web server receives a request,
and ends when a response is sent back. Whenever the web
server invokes the plug-in, it provides information that iden-
tiﬁes the session. When intercepting library functions, the
event collector uses information such as the thread identiﬁer
to keep track of sessions.
The event interceptor incorporates a pluggable architec-
ture for syntax analysis. In particular, each intercepted op-
eration can be associated with a syntax analyzer plug-in.
We have currently implemented six plug-ins: two on the in-
put side (for HTTP and XML RPC requests), and four on
the output side (HTML, SQL, shell-scripts, and HTTP re-
sponses).
The primary goal of syntax analyzers on the input side is
to decompose the input into multiple components in such a
way as to simplify taint inference. Our syntax analyzer for
HTTP performs all the normalization and decoding opera-
tions that are necessary on the request, and parses its con-
tents into an URI, form ﬁelds, cookies, HTTP header ﬁelds,
etc. The XML RPC parser carries out a similar function,
parsing the request to extract RPC parameters. All this in-
formation is captured uniformly as (cid:104)name, value(cid:105) pairs so
as to simplify the design of the rest of the components. Fur-
ther details about event collection and syntax analysis are
provided in Section 3.
Our taint inference algorithm is best understood as op-
erating on a single pair of data items at a time, and identi-
fying whether there is a ﬂow of information from the ﬁrst
Figure 3. System Architecture.
item to the second. Speciﬁcally, given a name-value pair
(N, I) from the input syntax analyzer and an output O, the
goal of taint inference is to determine if any substring of O
contains data from I. In principle, different taint inference
algorithms could be applied for different types of data, but
in practice, we rely on a single inference algorithm that is
motivated by the way most web applications operate: they
retrieve cookies and form ﬁelds from an input request, and
use them (after possibly some simple sanitizations and/or
edits) to construct an outgoing request. Thus, the value I
would likely appear within the outgoing request O, possi-
bly after some slight modiﬁcations. Hence our technique
infers a taint on a substring o of O if there is an approxi-
mate string match between I and o, or equivalently, if the
edit-distance between I and o is less than a given thresh-
old. The taint-inference algorithm is further described in
Section 4.
The goal of output syntax analyzers is to provide support
for syntax-aware policies. Our syntax analyzers implement
“rough parsers3” that recognize key elements of the syntax
of the language in question, but are not meant to be full
parsers. We rely on rough parsing for several reasons. First,
implementing full parsers can be a signiﬁcant amount of ef-
fort for most languages. Second, a rough parser can accom-
modate variations in the language across different vendor
implementations of the same language, for example, vari-
ations in SQL syntax across MySQL, Postgres, etc. Simi-
larly, a rough parser can be written that recognizes syntactic
components that remain the same across various ﬂavors of
shells4. The syntax analyzers must also be robust in the face
of syntax errors, as they are relatively common in some lan-
guages, e.g., HTML. We have designed our parsers with an
eye toward error-recovery so as to make them more robust
in the face of syntax errors. (This task is also simpliﬁed by
3An exception is the HTTP parser, where we have relied on readily
available parsers to accurately parse HTTP requests.
4Actually, in the case of shell languages, variable substitution, evalu-
ation and parsing are intertwined, so it is not possible to construct a full
parser without also implementing a shell interpreter.
our decision to rely on rough rather than full parsing.)
An output syntax analyzer constructs an abstract syntax
tree (AST), which is a data-structure that is common to all
output languages. As described in Section 5, syntax and
taint-aware policies are applied against this AST. If there is
a policy violation, the output request is blocked by the event
interceptor and an error code returned to the caller.
Implementation, optimization and evaluation of our
techniques are described in Sections 6 and 7, followed by
related work in Section 8 and concluding remarks in Sec-
tion 9.
3 Event Collection & Syntax Analysis
Our event interceptor for HTTP requests and responses
is based on ModSecurity [3], which is a open-source web
application ﬁrewall. ModSecurity operates as an Apache
module, and uses the Apache plug-in infrastructure to in-
tercept every request received by the web server and the
response sent back. It can then apply user-speciﬁed regular-
expression based ﬁlters against HTTP requests, cookies,
parameters, responses, etc. In order to do this, ModSecu-
rity incorporates code for handling various HTTP requests
(GET, PUT, POST, etc.), handling multi-part requests, ex-
tracting form parameters and cookies, and so on. In addi-
tion, in order to ensure accurate matching against ﬁltering
rules, ModSecurity handles various encodings that are com-
monly used with HTTP (e.g., base64 encoding), and ensures
that all elements of HTTP request and response are appro-