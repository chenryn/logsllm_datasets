title:OTO: online trust oracle for user-centric trust establishment
author:Tiffany Hyun-Jin Kim and
Payas Gupta and
Jun Han and
Emmanuel Owusu and
Jason I. Hong and
Adrian Perrig and
Debin Gao
OTO: Online Trust Oracle for
User-Centric Trust Establishment
Tiffany Hyun-Jin Kim† Payas Gupta§
Jun Han† Emmanuel Owusu†
Jason Hong† Adrian Perrig† Debin Gao§
† Carnegie Mellon University
{hyunjin,junhan,eowusu,jasonh,perrig}@cmu.edu
§ Singapore Management University
{payas.gupta.2008,dbgao}@smu.edu.sg
ABSTRACT
Malware continues to thrive on the Internet. Besides auto-
mated mechanisms for detecting malware, we provide users
with trust evidence information to enable them to make in-
formed trust decisions. To scope the problem, we study the
challenge of assisting users with judging the trustworthiness
of software downloaded from the Internet.
Through expert elicitation, we deduce indicators for trust
evidence, then analyze these indicators with respect to scal-
ability and robustness. We design OTO, a system for com-
municating these trust evidence indicators to users, and we
demonstrate through a user study the eﬀectiveness of OTO,
even with respect to IE’s SmartScreen Filter (SSF). The
results from the between-subjects experiment with 58 par-
ticipants conﬁrm that the OTO interface helps people make
correct trust decisions compared to the SSF interface regard-
less of their security knowledge, education level, occupation,
age, or gender.
Categories and Subject Descriptors
K.6.5 [MANAGEMENT OF COMPUTING AND IN-
FORMATION SYSTEMS]: Security and Protection—
Invasive software; H.1.2 [MODELS AND PRINCIPLES]:
User/Machine Systems—Human factors
Keywords
User Interfaces for Security, Human Factors, Trust Evidence,
Software Download, Trust Validation for Uncertiﬁed Soft-
ware
1.
INTRODUCTION
Gauging the authenticity and legitimacy of software on-
line is challenging. For example, novice users do not under-
stand the dangers and generally lack the ability to validate
downloaded software, and even security-conscious users are
often frustrated by their inability to judge the legitimacy of
software.
We observe that useful trust evidence information is avail-
able on the Internet, which can help validate the correctness
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
CCS’12, October 16–18, 2012, Raleigh, North Carolina, USA.
Copyright 2012 ACM 978-1-4503-1651-4/12/10 ...$15.00.
and trustworthiness of software. Some examples include
trusted Certiﬁcate Authority-issued public-key certiﬁcates,
social network-based reviews, authority or expert-based re-
ports, PageRank information, etc. However, several factors
complicate successful veriﬁcation by end-users:
• Cumbersome information gathering: users need to
spend time and eﬀort to collect trust evidence.
• Being aware of what evidence exists: most users
(especially non-experts) are unaware of available trust ev-
idence indicators for validation.
• Finding the evidence: users may not even know where
and how to start searching for evidence.
• Assessing the quality of the evidence: even if users
ﬁnd trust evidence, it may be false information (e.g., users
only ﬁnd evidence supporting the trustworthiness of a cer-
tain application which happens to provide malicious con-
tents). Furthermore, contradicting evidence may exist. In
this case, users may face diﬃculty of correctly interpreting
and prioritizing the relevance of trust evidence indicators.
• Limited trust establishment resources: mechanisms
for querying certain resources for trust establishment are
currently unavailable. For example, users can rely on their
online social network (OSN) friends to check if they have
experience with the resources and get personal feedback;
however, such a mechanism is currently unavailable.
One tempting solution would be to automate trust de-
cisions for users based on the available evidence that sys-
tems can gather. In cases where the downloaded software is
clearly malicious, such automated systems are eﬀective, but
in the frequent cases where the malware authors circumvent
the automated system [15], the user is still left alone to make
a trust decision. Indeed, automated protection has not been
100% accurate, due to delays in identifying malware as well
as new and evolving threats.
In such a case, how can we provide useful evidence that
can guide non-expert users to enhance their user experience
in terms of making correct context-dependent trust deci-
sions? To address this question, we explore how to combine
multiple pieces of trust evidence and present them to users in
a usable manner as follows: we furnish users with (1) an ev-
idence list that supports the trustworthiness of the applica-
tion in question, and (2) another evidence list that questions
the legitimacy of the application. Applying this design to
the previous example, a user downloading software would be
presented with evidence showing that the software has low
popularity, in which case the user would be able to weigh
this evidence against the software’s claim to be a commonly
installed application, as is the case in many attacks.
391We further explore how to customize the order of the ev-
idence for each list based on user preferences. However,
novice users may miss the critical evidence before they make
trust decisions. To educate novice users, we compare the be-
havior between security experts and novice users and sug-
gest what evidence experts check that novice users fail to
pay close attention to.
This paper makes the following research contributions:
• We report the observation results of a user study that we
conducted with security experts, to understand how they
make their trust decisions when installing software. We
aggregated what factors these experts take into account,
which was used to inform the design of our user interface.
• We present the design of OTO, short for Online Trust
Oracle, a user interface that is presented before software
is installed. OTO presents two categories of evidence to
assist users in determining software legitimacy: the posi-
tive evidence of why the software is safe to download, and
the negative evidence for potential malware. OTO uses
evidence that resists spooﬁng attacks.
• We present the results of a user study comparing OTO
against SmartScreen Filter (SSF) on Microsoft Internet
Explorer (IE) for software downloads. The results from
the between-subjects experiment with 58 participants con-
ﬁrm that the OTO interface helps people make correct
trust decisions compared to the SSF interface regardless of
their background security knowledge, education level, occu-
pation, age, or gender. OTO especially helps when the un-
derlying operating system (OS) (which controls SSF and
OTO) fails to correctly label the software legitimacy (i.e.,
the OS detects malware as legitimate, and vice versa), and
when the OS correctly labels legitimate software.
2. PROBLEM DEFINITION
We address the following fundamental problem: how can
we gather and present robust trust evidence indicators to as-
sist a novice user to make a correct trust decision on a piece
of software that is about to be downloaded? Numerous sub-
problems exist: Which trust evidence indicators are robust
against adversarial inﬂuence? What trust evidence can be
meaningfully and automatically gathered? How should the
trust evidence be presented to the user?
Our goal is thus to design a dialog box with robust trust
evidence indicators to help novice users avoid malware, even
if the underlying OS fails to correctly label the legitimacy
of software.
2.1 Assumptions
We assume that malware cannot interfere with OTO op-
eration, such as the display of the OTO dialog box, the
detection of software downloads, or the gathering of trust
evidence. Addressing these challenges would go beyond the
scope of this paper.
2.2 Desired Properties
The following properties are desired for the trust evidence
indicators:
Correct. Our trust evidence information should be cor-
rect such that users can trust both the information and the
information source. In other words, users should be able to
rely on it (without searching the Internet extensively them-
selves) when they need to make trust decisions.
Prevalent
security threats
E!ective
design principles
OTO:
trust evidence
user interface
Common
pitfalls
Experts’
feedback
Figure 1: Factors we took into account in our design of Online
Trust Oracle (OTO). We considered the most common threats and
vectors in malware attacks that involve human interaction. We also
drew on design principles, examined common pitfalls of novice
users, and solicited feedback from experts to understand how ex-
perts make decisions regarding software installation.
When the multiple pieces of evidence result in uncertainty
over whether a given piece of software is benign or malicious,
users should still be able to make a correct trust decision
based on how the evidence is presented.
The evidence indicators should be intuitively
Usable.
useful to novice users when they need to make trust deci-
sions. Also, the information should not annoy users.
2.3 Adversary Model
Malware distributors may attempt to manipulate trust
evidence information. For example, they may provide fal-
sifying information, or hide crucial information, misguiding
users to perceive their software as legitimate.
3. DESIGN OVERVIEW AND RATIONALE
Our main goal of this section is to understand the most
common security threats and attack vectors involving some
form of user interaction. This analysis will help us design
(1) a user interface that can eﬀectively present trust evidence
and (2) user study scenarios to validate the eﬀectiveness of
the new interface. To achieve our goal, we consider four
factors: analysis of popular security threats, eﬀective design
principles, common pitfalls of novice users, and feedback
from experts (see Figure 1).
3.1 Analysis of Prevalent Security Threats
An important factor in designing a user interface to sup-
port trust decisions is understanding prevalent security th-
reats. According to SophosLabs, 85% of all malware comes
from the web; in particular, the top threat in 2011 was drive-
by downloads where attackers lure users to malicious sites
that are injected with malicious code, or to legitimate sites
that host the malware [3]. According to Microsoft’s Security
Intelligent Report, 44.8% of successful malware attacks hap-
pen because of some action taken by the end-user [1]. This
indicates that enabling users to defend themselves against
online threats is critical, especially with ever increasing num-
bers of Internet-accessible devices, including laptops, smart-
phones, tablet PCs, etc.
In terms of identifying the threats, SophosLabs has identi-
ﬁed that one of the more persistent threats of Year 2010 was
fake antivirus (also known as ransomware, rogueware and
scareware, mostly with a Trojan horse component) which
resembles or impersonates genuine security solutions and in-
veigles into a victim’s machine [2]. Although declining in
number, possibly due to international law enforcement co-
392operation, fake antivirus continued to be a big problem in
2011 [3]. Other threats include keyloggers to capture per-
sonal information and passwords, and botnet software to
distribute spam, host illegal content, or serve malware.
The reports cited above list the commonly used techniques
to distribute malware, which are as follows:
• Blackhat search engine optimization (SEO) ranks websites
with malware highly in search results.
• Social engineering click-jacking uses social relationships
to trick users into clicking on webpages.
• Malvertising embeds malware in advertisements displayed
on legitimate, high-traﬃc sites.
• Drive-by downloads cause users to install malware simply
by visiting a website.
• Compromised legitimate websites host embedded malware
that spreads to users who access the websites.
In terms of software threats, SophosLabs and Microsoft
have analyzed that malware targets Microsoft products (e.g.,
Microsoft oﬃce, IE, etc.), Java vulnerabilities, HTML and
JavaScript, document parsers, and Adobe products (e.g.,
Flash, PDF) [1, 3].
All reports emphasize that educating users is one of the
most critical steps to reduce the damage caused by attackers.
3.2 Common Pitfalls of Novice Users
Prior research has shown that novice users tend to en-
counter several common pitfalls when they make security
decisions online [5, 8, 9, 18]. Such common pitfalls can help
us design an eﬀective user interface that prevents users from
repeatedly making the same mistakes. We summarize the
common mistakes from past work as follows:
Lack of security and systems knowledge. Users tend
to misinterpret various indicators (e.g., a security lock icon,
false address in the “from” line of an email, broken image,
syntax of domain names, etc.) that could be used to deter-
mine whether an email or a website is trustworthy.
Visual deception. Users tend to be deceived by how an
email or a website visually presents information. For exam-
ple, users tend to trust a website that has professional or
sophisticated layout, or that mimics the legitimate website.
Moreover, users tend to be fooled by “typejacking” homo-
graph attacks that substitute letters of a URL with similar-
looking ones (e.g., www.bankofthevvest.com) or adding
extra repeating letters (e.g., www.gooogle.com).
Even security experts fail to
Psychological pressure.
defend against messages that invoke fear, threat, excitement,
or urgency [18]. For example, scareware and rogueware pro-
vide terrifying messages and force people to download (and
pay for) malware. This is because such urgent cues pres-
sure people and short circuit the available resources which
in other cases help people detect deceptions.
Prior experience.
Users who are familiar with partic-
ular scams seem to be good at spotting similar ones. How-
ever, this characteristic does not hold when these users are
exposed to unfamiliar scams.
Bounded attention. Users tend to separate headers or
URLs from the actual content of an email or a website. Users
also pay insuﬃcient attention to existing security indicators,
and fail to notice when security indicators are absent.
3.3 Design Principles
In this section, we describe design principles that informed
our design for interfaces that can eﬀectively display trust
Table 1: User study scenarios. To observe the mental model
of security experts when they analyze the legitimacy of given soft-
ware, we conducted a user study with 10 software programs, where
5 are legitimate and 5 are malicious. “Difﬁculty” represents how
challenging we believed it would be to determine the legitimacy of
a given software program.
Type
Software
Visual organizer
MindMaple
Antivirus
AhnLab
Spam ﬁlter
SPAMﬁghter Pro
Antivirus
Kaspersky
Rkill
Anti-malware
Windows activation Ransomware
Privacy violation
ActiveX codec
HDD Diagnostic
Adobe ﬂash update
Difﬁculty
Easy
Medium
Medium
Difﬁcult
Difﬁcult
Easy
Scareware
Medium
Trojan malware Medium
Difﬁcult
Rogueware
Trojan malware
Difﬁcult
Malicious
Legitimacy
Legitimate
evidence to users. We follow the design guideline suggested
by Kuo [13] and Egelman [10] to minimize common errors
in the stages of the C-HIP model [20].
Grayed-out background.
Dialog boxes on grayed-out
background is shown to be eﬀective in getting users’ full at-
tention [13]. Users also believe that such dialog boxes orig-
inate from the OS and not from malicious pop-ups. More-
over, this approach ensures that users do not overlook the
dialog boxes, and forces them to make a decision [10].
Mimicked UI of OS vendor.
Professional look and
feel is important to enable users to develop conﬁdence in
the warning messages [13]. Hence, the warning messages
should mimic the user interfaces of the OS vendor.
Detailed explanation.
Users tend to ignore warnings
that they do not understand [13]. Hence, it is important that
the interface provides detailed explanations that people can
easily understand while avoiding jargon. More speciﬁcally,