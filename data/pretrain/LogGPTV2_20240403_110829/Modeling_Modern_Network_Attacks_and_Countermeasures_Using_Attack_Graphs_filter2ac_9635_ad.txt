Enclave 3
Enclave 4
Figure 5. Synthetic Network Structure Used for Scaling Experiments
includes a border ﬁrewall, a DMZ, an internal network, and
four additional enclaves, each with its own border ﬁrewall.
An attack path from the outside, to the DMZ, to the inside,
and ﬁnally to each enclave was established. Ten ports were
assigned to each host, half of which were assigned one
vulnerability each.
In the ﬁrst case, shown on the top of Figure 4, we kept the
number of rules constant at 250 per ﬁrewall and varied only
the total number of hosts in the network. We show results
123
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 13:13:13 UTC from IEEE Xplore.  Restrictions apply. 
with and without personal ﬁrewalls, where the personal
ﬁrewalls used common per-enclave rulesets of 250 rules.
The graph’s scale is log-linear and shows the tool’s ability
to handle large numbers of hosts in seconds.
In the second case, shown on the bottom of Figure 4, we
leave the number of hosts constant at 1,250 and vary the
number of rules on each ﬁrewall. We again show results
with and without personal ﬁrewalls; here, the number of
rules on the personal ﬁrewalls equals the number on the
infrastructure ﬁrewalls. The graph’s scale is log-linear and
shows that running time remains under two minutes in the
typical 100 to 2,000 rules per ﬁrewall expected in practice.
B. Evaluation on a Real Network
We also evaluated the system using a real network of
85 hosts behind a Juniper Netscreen ﬁrewall. We began by
collecting typical data, consisting of a Nessus scan and the
Juniper ﬁrewall ruleset. We then collected additional host-
based data, discussed in Section VI-B1, and then evaluated
several scenarios on the network in Section VI-B2.
1) OVAL Scanning: We deployed the OVAL scanner on
the target network’s Windows-based hosts and collected
vulnerability scan data every time a user logged into the
Windows domain.
Over the course of a month, we obtained 155 scans of 43
hosts, logging a total of 402 unique vulnerabilities over that
time. The NVD database categorized 233 of them as client-
side vulnerabilities (the NVD entries have the user_init
ﬂag set). The remainder were classiﬁed as locally exploitable
(26) or remotely (server-side) exploitable (143); of those
143, 25 are said to yield root access when exploited.
We randomly chose ten of the 25 remote-to-root vul-
nerabilities identiﬁed as remotely exploitable and evaluated
them by hand, examining the NVD entries and additional
references. The ten CVE IDs and their evaluations appear
in Table I. Based on our evaluation, eight of the ten were
incorrectly classiﬁed as server-side vulnerabilities.
This result makes us hesitant to trust NVD’s otherwise
solid data when evaluating a vulnerability that is suspected
to be client-side. Until this is addressed, we suggest miti-
gating the risk of false negatives in the attack surface by
considering all vulnerabilities discovered by OVAL to be
client-side vulnerabilities and additionally using a network-
based scanner to discover server-side vulnerabilities.
2) Experiments: Data in hand, we began evaluating the
results with NetSPA. In all cases we hypothesized an adver-
sary on the outside of the ﬁrewall.
The results of this and all other experiments on the real
network are shown in Figure 6.
Figure 6a clearly shows that the situation is dire; all 169
of the server-side vulnerabilities and 51 of the 84 hosts
can be exploited directly, through the perimeter ﬁrewall.
We investigated the reachability traces provided by NetSPA
and identiﬁed three rules which were permitting the majority
of the inbound trafﬁc. All three were intentional, allowing
trafﬁc from an asset management server and a handful of
machines that belonged behind the enclave but weren’t phys-
ically located there. As a hypothetical hardening measure,
we removed these rules. The adversary could now only
directly compromise 69 vulnerabilities as shown in Figure
6b. Once past the ﬁrewall, of course, the other 100 can
still be exploited from an initially compromised host, as
shown by the light gray squares. All 51 vulnerable hosts are
exploited, although only 22 are exploited in the ﬁrst step.
We then discovered an omission in the Juniper ruleset: a
server called “MS-WINS” was used in an allow rule, but
the port number was not deﬁned. NetSPA models the worst
case, so it assumed the rule allowed trafﬁc to any destination
port number. When redeﬁned with the appropriate WINS
port number of 1512, as shown in Figure 6c, the network
became impervious to attack – as shown, the vulnerabili-
ties are known but cannot be exploited, and no hosts are
compromised.
At this point we introduced the OVAL scans from Section
VI-B1, adding knowledge of 514 client-side vulnerabilities
to the network. As shown in Figure 6d, the adversary could
immediately take advantage, compromising even more hosts
than before – 65 instead of 51 – as we are now aware
of client-side vulnerabilities on hosts that had no server-
side vulnerabilities. First, the client-side vulnerabilities are
compromised, and then the server-side vulnerabilities can be
attacked from any of those initially compromised hosts.
We next added available data on personal/endpoint ﬁre-
walls on the network, but they did not impede the adversary,
as they did not restrict trafﬁc from the adversary’s starting
location or from hosts within the enclave itself. As a ﬁnal
step, we hypothesized an inline IPS capable of blocking
exploits against Microsoft Ofﬁce. We assumed, for example,
that an adversary relying on a vulnerable client downloading
a corrupt Word document would be thwarted. Note that
we are neglecting simple attacker workarounds, such as
convincing the client to use an encrypted connection, but
for the sake of example we assume the adversary is using
unobfuscated transmission methods. Figure 6e shows the
impact such an IPS could have; 267 of the client-side
vulnerabilities are no longer immediately compromisable
from the outside, though the same number of hosts (65)
are still eventually compromised. What-if experiments such
as these could help defenders decide if potential changes are
worthwhile investments.
VII. RELATED WORK
To the best of our knowledge, no other commercial or
research tools that use attack graphs to assess network risk
include explicit models of personal ﬁrewalls, intrusion pre-
vention systems, or modern client-side attacks. A compre-
hensive review of past attack graph research is presented in
[8]. More recent approaches include [11], [18], and [19]. The
124
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 13:13:13 UTC from IEEE Xplore.  Restrictions apply. 
CVE ID
Description
Buffer overﬂow in Microsoft Word 2002 ... in a .doc ﬁle
vulnerability in Adobe Acrobat Reader 6.0.0 ... .ETD document
overﬂow in the DHCP Client service for Microsoft Windows 2000
CVE-2004-0963
CVE-2004-1153
CVE-2006-2372
CVE-2006-4691 Workstation service (wkssvc.dll) ... via NetrJoinDomain2 RPC
CVE-2007-0065
(OLE) Automation in Microsoft Windows ... remote attackers ... via a crafted script
request (from Microsoft: “could allow remote code execution if a user viewed a
specially crafted Web page.”
CVE-2007-1204 Universal Plug and Play (UPnP) service ... crafted HTTP headers
CVE-2008-0082 An ActiveX control ... is marked as safe for scripting
CVE-2008-0102 Microsoft Ofﬁce Publisher ... via crafted .pub ﬁle
CVE-2008-3009 Windows Media Player 6.4 ... replies to authentication requests
CVE-2008-3010 Windows Media Player 6.4 ... credential-reﬂection attacks, by sending an authen-
tication request
Client-side?
yes
yes
yes
no
yes
no
yes
yes
yes
yes
EVALUATION OF TEN ALLEGEDLY REMOTE-TO-ROOT VULNERABILITIES FOUND BY OVAL
Table I
Figure 6. Order of Vulnerability Instance Compromise in Six Scenarios. The upper bar represents compromised hosts: white is uncompromised; light gray
is compromised via a “stepping-stone” host; dark gray is compromised immediately. The lower graphic represents vulnerability instances: white squares
indicate known but uncompromisable vulnerabilities; light gray squares indicate vulnerabilities that can only be compromised via a “stepping-stone” host;
dark gray squares indicate an immediately exploitable vulnerability.
Topological Vulnerability Analysis (TVA) system [20] used
in [11] does not explicitly model any type of ﬁrewall or ana-
lyze ﬁrewall rules. Instead, a subset of the network’s host-to-
host reachability is estimated using exhaustive host-to-host
vulnerability scans. This introduces quadratic complexity,
scales poorly to large networks, and complicates ﬁrewall
modeling. This system also relies on a network vulnerability
scanner and does not gather information about client-side
attacks. The MulVAL system [21] used in [18] also does
not explicitly model ﬁrewalls but assumes reachability is
provided. Research in [19] uses our prior NetSPA system
and thus scales well, but like our prior research, modern
attacks and countermeasures are not modeled. Commercial
attack graph products such as RedSeal [22] and Skybox [23]
model ﬁrewalls and compute reachability from ﬁrewall rules
but neither product’s website mentions the ability to model
personal ﬁrewalls, IPSs, or client side attacks.
There are many papers on ﬁrewall ruleset analysis and
a few companies that analyze rulesets. Wool et al. [24]
provides typical sizes for rulesets and conﬁrms that ﬁre-
wall conﬁguration errors are very common. Systems like
FIREMAN [16], FANG [25] and a few companies (e.g.,
AlgoSec [26], RedSeal [22], Skybox [23]) detect different
types of ﬁrewall misconﬁgurations such as overlapping or
contradictory rules. Some also compute reachability and
determine if ﬁrewalls enforce an overall policy. We use
BDDs from [16] for efﬁcient rule application which are
similar in purpose to Michigan State’s Firewall Decision
Diagrams (FDDs) [27]–[29].
VIII. LIMITATIONS AND FUTURE WORK
The current NetSPA tool includes many countermeasures
and attacks, but these need to be supplemented and im-
proved. Some additional countermeasures we plan to add
include the Federal Desktop Core Conﬁguration (FDCC) for
Windows, application white listing on hosts, and ﬁltering
provided by IPSs for exploits related to speciﬁc vulnera-
bilities. We also plan to model additional threats such as
conﬁcker [1] that use restricted exploit sets and propagation
vectors. We additionally plan to model adversaries exploiting
trust relationships between hosts, for example by using open
Windows shares or shares protected by weak or common
passwords. We also plan to explore more complex client-side
attacks and model attacks speciﬁc to web sites and database
125
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 13:13:13 UTC from IEEE Xplore.  Restrictions apply. 
servers such as SQL injection and cross-site scripting. Vir-
tual machines offer another exploit vector that should be
considered, as access to the host OS allows compromise of
all guest OS images. Improved modeling of zero-day attacks
will involve capturing the application inventory on clients
using OVAL and adding the ability to insert hypothetical
zero-day vulnerabilities into the applications discovered.
Field tests of the tool are always highly instructive; they
generally involve importing rules from additional types of
ﬁrewalls and performing further tests on actual networks.
The tool’s usability will also be improved via further reﬁne-
ments to the attack graph GUI [5].
REFERENCES
[1] P. Porras, H. Saidi, and V. Vegneswaran, “An analysis of
conﬁcker’s logic and rondezvous points,” SRI International,
Tech. Rep., February 2009.
[2] S. Nagaraja and R. Anderson, “The snooping dragon: social-
malware surveillance of the tibetan movement,” University
of Cambridge, Computer Laboratory, Tech. Rep. UCAM-CL-
TR-746, Mar. 2009.
[3] R. Lippmann et al., “Validating and restoring defense in
depth using attack graphs,” in IEEE Military Communications
Conference (MILCOM), 2006.
[4] K. Ingols, R. Lippmann, and K. Piwowarski, “Practical attack
IEEE
graph generation for network defense,” in ACSAC.
Computer Society, 2006, pp. 121–130.
[5] L. Williams, R. Lippmann, and K. Ingols, “GARNET: A
graphical attack graph and reachability network evaluation
tool,” in Visualization for Computer Security (VizSEC), ser.
Lecture Notes in Computer Science, J. R. Goodall, G. J.
Conti, and K.-L. Ma, Eds., vol. 5210.
Springer, 2008, pp.
44–59.
[6] D. L. Buckshaw et al., “Mission oriented risk and design
analysis of critical information systems,” Military Operations
Research, vol. 10, pp. 19–38, 2005.
[7] P. Mell, K. Scarfone, and S. Raomanosky, “A complete guide
to the common vulnerability scoring system version 2.0,” in
Forum of Incident Response and Security Teams (FIRST),
2007.
[8] R. P. Lippmann and K. Ingols, “An annotated review of past
papers on attack graphs,” MIT Lincoln Laboratory, Project
Report IA-1, 2005.
[9] “IBM Internet Security Systems X-Force 2008 trend and risk
report,” IBM Global Technology Services, Tech. Rep., 2009.
[10] D. Turner et al., “Symantec internet security threat report,
trends for July - December 07,” Symantec, Tech. Rep., 2008.
[11] S. Noel and S. Jajodia, “Optimal IDS sensor placement and
alert prioritization using attack graphs,” Journal of Network
and Systems Management, vol. 16, no. 3, pp. 259–275, 2008.
[12] Tenable. Nessus
security scanner.
http://www.nessus.org
[Online]. Available:
126
[13] R. Martin, “Making security measurable and manageable,”
in IEEE Military Communications Conference (MILCOM),
2008.
[14] Common platform enumeration. MITRE. [Online]. Available:
http://cpe.mitre.org
[15] R. Ross et al., “Recommended security controls for federal
information systems and organizations,” National Institute of
Standards and Technology, NIST Special Publication 800-53,
Revision 3, February 2009.
[16] L. Yuan et al., “FIREMAN: A toolkit for FIREwall modeling
and ANalysis,” in IEEE Symposium on Security and Privacy.
IEEE Computer Society, 2006, pp. 199–213.
[17] J. Lind-Nielsen et al. BuDDy, a binary decision diagram
library. [Online]. Available: http://buddy.sourceforge.net/
[18] R. E. Sawilla and X. Ou, “Identifying critical attack assets
in dependency attack graphs,” in 13th European Symposium
on Research in Computer Security (ESORICS), S. Jajodia and
J. L´opez, Eds., vol. 5283. Springer, 2008, pp. 18–34.
[19] N. Pham, L. Baud, P. Bellot, and M. Riguidel, “A near real-
time system for security assurance assessment,” in 3rd Inter-
national Conference on Internet Monitoring and Protection
(ICIMP), 2008, pp. 152–160.
[20] S. Jajodia, S. Noel, and B. O’Berry, Topological Analysis of
Network Attack Vulnerability. Kluwer Academic Publisher,
2003, ch. 5.
[21] X. Ou, S. Govindavajhala, and A. Appel, “MulVAL: A logic-
based network security analyzer,” in Proceedings of the 14th
USENIX Security Symposium, 2005, pp. 113–128.
[22] RedSeal. (2009, April) Redseal systems. [Online]. Available:
http://www.redseal.net
[23] Skybox.
(2009, April) Skybox security,
Available: http://www.skyboxsecurity.com/
inc.
[Online].
[24] A. Wool, “A quantitative study of ﬁrewall conﬁguration
errors,” Computer, vol. 37, no. 6, pp. 62–67, June 2004.
[25] A. Mayer, A. Wool, and E. Ziskind, “Fang: A ﬁrewall analysis
engine,” in IEEE Symposium on Security and Privacy, 2000,
pp. 177–187.
[26] Algosec. [Online]. Available: http://www.algosec.com
[27] A. Liu, E. Torng, and C. Meiners, “Firewall compressor: An
algorithm for minimizing ﬁrewall policies,” in 27th Confer-
ence on Computer Communications (INFOCOM).
IEEE,
2008, pp. 176–180.
[28] C. Meiners, A. Liu, and E. Torng, “TCAM Razor: A sys-
tematic approach towards minimizing packet classiﬁers in
TCAMs,” in 15th IEEE International Conference on Network
Protocols (ICNP), 2007, pp. 226–275.
[29] A. Khakpour and A. Liu, “Quarnet: A tool for quantify-
ing static network reachability,” Michigan State University,
East Lansing, Michigan, Tech. Rep. MSU-CSE-09-2, January
2009.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 13:13:13 UTC from IEEE Xplore.  Restrictions apply.