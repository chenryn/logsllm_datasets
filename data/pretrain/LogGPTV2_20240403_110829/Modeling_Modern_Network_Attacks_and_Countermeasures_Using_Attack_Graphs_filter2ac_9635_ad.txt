### Enclave 3 and Enclave 4

**Figure 5: Synthetic Network Structure for Scaling Experiments**

The synthetic network structure used in the scaling experiments includes a border firewall, a DMZ (Demilitarized Zone), an internal network, and four additional enclaves, each with its own border firewall. An attack path was established from the outside, through the DMZ, into the internal network, and finally to each enclave. Each host in the network was assigned ten ports, with half of these ports having one vulnerability each.

#### Experiment 1: Varying the Number of Hosts
In the first experiment, illustrated at the top of Figure 4, we kept the number of firewall rules constant at 250 per firewall and varied the total number of hosts in the network. We compared the results with and without personal firewalls, where the personal firewalls used common per-enclave rule sets of 250 rules. The graph's scale is log-linear, demonstrating the tool's ability to handle large numbers of hosts in seconds.

#### Experiment 2: Varying the Number of Rules
In the second experiment, shown at the bottom of Figure 4, we kept the number of hosts constant at 1,250 and varied the number of rules on each firewall. Again, we compared the results with and without personal firewalls, where the number of rules on the personal firewalls equaled the number on the infrastructure firewalls. The graph's scale is log-linear, showing that the running time remains under two minutes for typical rule counts between 100 and 2,000 per firewall, as expected in practical scenarios.

### Evaluation on a Real Network

We also evaluated the system using a real network consisting of 85 hosts behind a Juniper Netscreen firewall. The evaluation process involved several steps:

1. **Data Collection:**
   - We began by collecting typical data, including a Nessus scan and the Juniper firewall ruleset.
   - Additional host-based data, discussed in Section VI-B1, was then collected.
   - Several scenarios were evaluated on the network, as detailed in Section VI-B2.

2. **OVAL Scanning:**
   - We deployed the OVAL scanner on the target network's Windows-based hosts and collected vulnerability scan data every time a user logged into the Windows domain.
   - Over a month, we obtained 155 scans of 43 hosts, logging a total of 402 unique vulnerabilities. The NVD database categorized 233 of these as client-side vulnerabilities, 26 as locally exploitable, and 143 as remotely (server-side) exploitable, with 25 of the latter yielding root access when exploited.
   - We randomly selected ten of the 25 remote-to-root vulnerabilities identified as remotely exploitable and evaluated them manually. Based on our evaluation, eight of the ten were incorrectly classified as server-side vulnerabilities.
   - This result suggests caution when relying on NVD data for evaluating client-side vulnerabilities. Until this issue is addressed, we recommend considering all vulnerabilities discovered by OVAL as client-side and using a network-based scanner to identify server-side vulnerabilities.

3. **Experiments with NetSPA:**
   - With the data in hand, we began evaluating the results using NetSPA, hypothesizing an adversary on the outside of the firewall.
   - The results of this and other experiments on the real network are shown in Figure 6.
   - **Figure 6a:** Shows that all 169 server-side vulnerabilities and 51 of the 84 hosts can be exploited directly through the perimeter firewall.
   - **Figure 6b:** After removing three intentional rules that permitted most inbound traffic, the adversary could only directly compromise 69 vulnerabilities.
   - **Figure 6c:** An omission in the Juniper ruleset was discovered, and when corrected, the network became impervious to attack.
   - **Figure 6d:** Adding knowledge of 514 client-side vulnerabilities, the adversary could compromise even more hosts (65 instead of 51).
   - **Figure 6e:** Hypothesizing an inline IPS capable of blocking exploits against Microsoft Office, 267 of the client-side vulnerabilities were no longer immediately compromisable, though the same number of hosts (65) were still eventually compromised.

### Related Work

To the best of our knowledge, no other commercial or research tools that use attack graphs to assess network risk include explicit models of personal firewalls, intrusion prevention systems, or modern client-side attacks. A comprehensive review of past attack graph research is presented in [8]. More recent approaches include [11], [18], and [19].

- **Topological Vulnerability Analysis (TVA) System [20]:** Used in [11] but does not explicitly model any type of firewall or analyze firewall rules. It relies on exhaustive host-to-host vulnerability scans, which introduces quadratic complexity and scales poorly to large networks.
- **MulVAL System [21]:** Used in [18] but does not explicitly model firewalls and assumes reachability is provided.
- **Research in [19]:** Uses our prior NetSPA system and scales well, but like our prior research, it does not model modern attacks and countermeasures.
- **Commercial Attack Graph Products (RedSeal [22], Skybox [23]):** Model firewalls and compute reachability from firewall rules but do not mention the ability to model personal firewalls, IPSs, or client-side attacks.

### Limitations and Future Work

The current NetSPA tool includes many countermeasures and attacks but needs further supplementation and improvement. Future work will include adding additional countermeasures such as the Federal Desktop Core Configuration (FDCC) for Windows, application whitelisting on hosts, and filtering provided by IPSs for specific vulnerabilities. We also plan to model additional threats, such as Conficker, and explore more complex client-side attacks, including those specific to web sites and database servers. Field tests and usability improvements are also planned.

### References

[References are listed as provided, with no changes made.]

---

This revised text aims to provide a clear, coherent, and professional presentation of the original content.