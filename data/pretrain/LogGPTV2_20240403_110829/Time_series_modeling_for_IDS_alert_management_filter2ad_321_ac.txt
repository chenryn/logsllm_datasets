# Detection Process and Anomaly Identification

## 5.2 Trend Removal
The trend removal process is essential to isolate the stationary structure of the time series. We use the lag-d differencing operator, ∇d, for this purpose. The operator is defined as:
\[ \nabla^d X_t = X_t - X_{t-d} \]
This operation computes the difference between two observations in the series that are d time units apart. For d = 1, it acts similarly to the derivative operator for continuous functions.

### Application of ∇1 to a Linear Trend
When applied to a linear trend \( T_t = bt + c \), the operator ∇1 yields:
\[ \nabla^1 T_t = T_t - T_t-1 = b \]
This result represents the slope of the trend function, effectively leaving us with a series that shows the rate of change in the alert flow. For example, in the SNMP Request UDP, this step removes the constant component (as seen in Fig. 2(a)) and makes level shifts more apparent. The transformed series is shown in Fig. 4.

### Information Loss
Applying ∇1 to all series results in a loss of information, but for anomaly detection, the linear trend and the absolute value of the alert intensity are not necessary.

## 5.3 Removing Periodicity
The ∇d operator can also remove periodic components from the time series. Applying ∇d to a model \( X_t \) without the trend component and with a periodic component \( P_t \) of period d, we get:
\[ \nabla^d X_t = P_t - P_{t-d} + R_t - R_{t-d} = R_t - R_{t-d} \]
This leaves us with a random component \( R_t - R_{t-d} \). The application of ∇d requires knowledge of the period d, which we assume is known for now.

### Determining the Need for ∇d
We decide whether to apply ∇d based on the sample autocorrelation function values of the series. For a series without any structure, about 95% of the sample autocorrelations should fall within the bounds \( \pm 1.96 / \sqrt{n} \), where n is the number of samples. If the sample autocorrelation values for lag d are outside these limits, we apply ∇d to the series.

## 5.4 Removing the Stationary Structure
To remove the remaining stationary structure \( R_t \) from the series, we build an AR(p) time series model:
\[ R_t = \sum_{k=1}^{p} \phi_k R_{t-k} + Z_t \]
where \( \{Z_t\} \sim WN(0, \sigma^2) \) (white noise). This means the current value of \( R_t \) is a weighted sum of p previous observations plus a noise term.

### Model Parameter Estimation
The model is parametric, requiring the choice of the model degree p and estimation of parameters \( \phi_k \) for \( k = 1, \ldots, p \). The choice of p is typically done by comparing different models using a criterion. In our case, we aim for a balance between interesting phenomena and non-interesting signals. Parameter estimation is done using a least squares algorithm, minimizing the squared difference between observations and model predictions.

### Whiteness Test
If the model sufficiently describes the normal component of the alert series after removing trend and periodicity, further modeling with AR models may be unnecessary. This can be tested using the Ljung-Box test. If the remaining series resembles white noise, no further modeling is needed. However, real-world data often contains anomalies, making this approach less feasible. We build an AR model for every series, which can introduce some computational overhead.

## 5.5 Anomaly Detection
After isolating the abnormal component \( E_t \) of the alert series, we detect anomalies by signaling if the current value \( e_t \) differs more than n standard deviations from the average of past values. The default value for n is three, but it can be adjusted. The average and standard deviation are estimated using exponentially weighted moving averages.

## 6. Results

### 6.1 Periodicity in Alert Flows
To remove the periodic component \( P_t \) with period d using ∇d, we need to know d. Visual inspection and the sample ACF values suggested periods close to one day or week. Figure 5 shows the sample ACF values for Whatsup up to a lag of nine days. Strong positive correlations were observed at lags corresponding to one week and one day. Table 2 lists the first four lags used for periodicity removal. The strongest periodic component removed had a period multiple of 24 hours for most flows, except SNMP Request udp, which showed no periodicity.

### 6.2 Defining Model Degrees
We used several model degrees p (4, 10, 16, 26) to find the most suitable for each flow. ARMA (p, q) models did not provide significant improvement over AR models. The chosen model degrees were: SNMP AR(4), Whatsup AR(26), Dest Unr AR(26), LOCAL POLICY AR(26), and speedera AR(26).

### 6.3 Detected Anomalies
After fixing the model degrees and estimating parameters, we applied the complete alert processing method to the validation data. Table 3 summarizes the anomalies signaled for each flow. Columns K+ and K- show the detected and missed known phenomena, respectively. New anomalies (N+) and artifacts (N-) are also recorded. For SNMP, all known phenomena were detected, and additional anomalies were small vibrations. The EWMA approach provided similar meta-alerts for this flow.

---

This optimized version aims to make the text more coherent, clear, and professional, while maintaining the technical details and structure of the original content.