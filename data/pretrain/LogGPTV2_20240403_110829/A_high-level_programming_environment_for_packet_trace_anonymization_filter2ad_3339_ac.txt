in order to keep the cross-reference structure intact. Operationally,
the site keeps the ﬁrst 512 bytes of each entity, and keeps those
with a MIME type of “text” in their entirety; this results in about a
factor of 10 in size savings, yet retains enough information to help
analyze most HTTP attacks to determine whether they succeeded.
SMTP trace rewriter: Replaces mail bodies with MD5 hash val-
ues and size information, but keeps all SMTP commands/replies
and mail headers.
4. TRACE ANONYMIZATION
In this section we discuss general issues in trace anonymization,
analyze four types of possible attacks, and present our anonymi-
zation scheme for LBNL FTP traces. Although the scheme is in-
evitably dependent on the speciﬁc policy approved by the site, the
general techniques are also applicable to other sites and protocols.
4.1 Objectives of Anonymization
The information we try to hide through anonymization falls into
two categories:
identities, including identity of users, hosts, and
data; and conﬁdential attributes, e.g., passwords, or speciﬁcs of
sensitive user activity [4].
The ﬁrst step of developing an anonymization scheme is to de-
cide what information in the trace we need to hide. For example, in
anonymizing FTP traces, we aim to hide identities of clients, pri-
vate data (hidden ﬁles), and private servers; and sensitive attributes:
e.g., passwords, authentication keys, and in some cases ﬁlenames.
Conﬁdential information can be exposed via direct means, or in-
ferred via indirect means. Therefore, to hide the identity of client
hosts, it may not be enough to just anonymize their IP addresses.
We will shortly analyze four kinds of inference attacks that may
reveal conﬁdential information through indirect means, but before
doing so we ﬁrst discuss the anonymization primitives, i.e., how we
anonymize basic data elements.
4.2 Anonymization Primitives
Constant Substitution: One way to anonymize a data element is
to substitute the data with a constant, e.g., replace any password
with the string “”.
Constant substitution is usually used to anonymize conﬁdential
attributes. Applying constant substitution to identiﬁers (e.g., IP ad-
dresses), however, is generally undesirable, as we would then no
longer be able to precisely distinguish objects from one another. In-
stead, identiﬁers are usually anonymized with a 1-1 mapping, such
as sequential numbering or hashing, so that the anonymized identi-
ﬁers are still unique, as follows.
Sequential Numbering: We can sequentially number all distinct
identiﬁers in the order of appearance, e.g., mapping ﬁles names to
“file1”, “file2”, etc.
HTTP trace rewriter: Replaces HTTP entities beyond a speci-
ﬁed size with their MD5 hash values, changes the Content-Length
Hashing: One shortcoming of sequential numbering is that we
have to keep the whole mapping history to maintain a consistent
mapping during the anonymization process and across anonymiza-
tions. Instead, we can use a hash function as the mapping. Doing
so requires no additional state during the anonymization process,
and in addition using the same hash function across anonymiza-
tions will render a consistent mapping (assuming that the range of
the hashing function is large enough so that likelihood of collision
is negligible). To preserve conﬁdentiality, the hash function must
be one-way and preferably resistant to chosen plain-text attack, so
that an adversary can neither discover the input from the output
nor compute the hash by themselves. HMAC-MD5 (with a secret
key) satisﬁes these requirements. Assuming the adversary can nei-
ther reverse MD5 nor extract the secret HMAC key, hashing is as
secure as sequential numbering.
Preﬁx-Preserving Mapping: Sometimes it is valuable to preserve
some of the structural relationships between the identiﬁers, which
sequential numbering and hashing cannot do. For example, IP ad-
dresses can anonymized in a preﬁx-preserving way [12, 21] such
that any two IP addresses sharing a preﬁx will share a preﬁx of the
same length in their anonymized form. Preﬁx-preserving mapping
can be similarly applied on the directory components of ﬁle names.
While being valuable for some forms of analysis, preﬁx-preserving
mapping also reveals more information about the identiﬁers and
thus is more vulnerable to attacks [22].
Adding Random Noise: We can add noise to numeric values, e.g.,
ﬁle sizes, to make the result more resistant to ﬁngerprinting attacks
such as matching ﬁle sizes in the trace with public ﬁles [19]. We
have not applied this primitive in our experiments, however, so we
do not have experience regarding how effective it is and the degree
to which it diminishes the value of the trace.
4.3 Inference Attacks
Besides anonymizing certain identiﬁers and attributes to elimi-
nate direct exposure of identities and secret data, we also consider
rewriting other data ﬁelds to prevent indirect exposure. In order to
understand which data should be anonymized, we need to analyze
how an adversary might use additional data to infer conﬁdential
information. Below we will discuss four kinds of inference tech-
niques and how they relate to our FTP anonymization efforts.
4.3.1 Fingerprinting
“Fingerprinting” is the notion of an adversary recovering the
identity of an object by comparing its attributes to attributes of ob-
jects known by the adversary. In order to do so the adversary has to
know the ﬁngerprints of the candidate objects. Thus, they cannot,
for example, discover a previously unknown FTP server through
ﬁngerprinting.
We present here a brief analysis of possible ﬁngerprinting on our
anonymized FTP traces, to convey the ﬂavor of problem:
1. Fingerprinting ﬁles: possible for public ﬁles, by looking for
matches in ﬁle sizes, similar in spirit to the techniques of Sun
et al [19].
2. Fingerprinting servers: possible for public servers, by the
structure of their reply messages (especially the 220 greet-
ing banner), help replies, SITE commands, or through ﬁn-
gerprinting ﬁles on the server. It is unclear to us whether it is
possible to ﬁngerprint servers by analyzing response timing.
3. Fingerprinting clients: there are at least two possible ways
to ﬁngerprint clients: 1) when the client displays some pe-
culiar behavior known to the adversary; 2) through “active”
ﬁngerprinting: the adversary inserts a ﬁngerprint for a cer-
tain client by sending packets to the trace collection site with
a forged source address of the client’s host address, and then
looks for how these were transformed in the anonymized
trace.
While ﬁngerprinting of ﬁles and servers can expose usage pat-
terns, this does not appear to be a serious issue because who made
the access is not exposed.
Fingerprinting clients, on the other hand, would in some circum-
stances pose a signiﬁcant privacy threat. But this is generally dif-
ﬁcult for the adversary to accomplish. For the ﬁrst type of ﬁnger-
printing, the client’s sessions must possess peculiarities that survive
the anonymization process, and the adversary must discover these.
For the second type of ﬁngerprinting, the ﬁngerprint has to be in-
serted during trace collection. We discuss a defense against active
ﬁngerprinting, “knowledge separation”, in Section 4.3.4.
A particular threat is that a class of clients displaying certain
peculiar behaviors will stand out from other clients.
If we want
to eliminate this threat, we should eliminate or blur the distinc-
tion among client behaviors—which might signiﬁcantly reduce the
value of the trace.
4.3.2 Structure Recognition
Similar to ﬁngerprinting, the adversary may also exploit the
structure among objects to infer their identities. For example, traces
of Internet trafﬁc will often include sequential address scans made
by attackers probing for vulnerable hosts. By assuming that an
anonymized trace probably includes such scans, an adversary can
hunt for their likely presence, such as by noting that a series of
unanswered SYN packets occur close together in one part of the
trace, or that (when using sequential numbering) suddenly a group
of new hosts appears in the trace. They can then infer the original
addresses of other hosts by the sequence they occupy in the scan,
given the assumption that the scan started at a particular base ad-
dress and proceeded sequentially up from it [18]. In addition, if the
adversary has identiﬁed a single host in the trace (say a well-known
server), they can then calibrate their inference by conﬁrming that it
shows up in the scan in the expected sequence.
4.3.3 Shared-Text Matching
When attributes or identiﬁers of different objects share the same
text, the unmasking of one can lead to exposure of the other. For
example, if there is both a user name “alice” and a ﬁle name “alice”,
the user name will be exposed if the adversary can identify the ﬁle.
To avoid this attack, we apply “type-separation”: the user name “al-
ice” should be anonymized as the string “user+alice”, and the ﬁle
name as “ﬁle+alice”. Generally it is good practice to avoid using
the same text for distinct objects (e.g., ﬁles with the same name on
different servers) unless there is some trace analysis value in doing
so. The attack on preﬁx-preserving IP anonymization also exploits
shared-text matching for cascading effects, where the shared text is
the preﬁx.
4.3.4 Known-Text Matching
When both the original
text and the anonymized text are
known to the adversary, they can identify all appearances of the
anonymized text in the trace. The knowledge required for a known-
text attack is often obtained through ﬁngerprinting.
One example is a “known server log” attack: if the adversary
obtains the log of a server present in the trace, they may be able
to identify the mapping between client addresses and anonymized
addresses through ﬁngerprinting, and then unmask the clients’ ac-
tivities on other servers.
(Obtaining such logs is sometimes not
difﬁcult—for example, occasionally a query to a search engine will
ﬁnd them, because the logs are maintained in a publicly accessible
manner.)
Another example is if the adversary can insert trafﬁc with given
strings, such as a particular user ID, into the trace, similar to the
“active ﬁngerprinting” discussed above. They can then observe
how the string was mapped, and look for other occurrences of the
resulting text in order to unmask instances of the same original text.
A general method to counter known-text attacks is through
“knowledge separation”. This is similar to the type-separation de-
fense against shared-text matching discussed above. For example,
to counter a “known server log” attack, we can anonymize a client
IP differently depending on the server it accesses. To counter the
user ID insertion attack, we can anonymize user IDs differently de-
pending on whether the login is successful or not (an alternative
is to anonymize user IDs depending on the client’s IP address).
Similarly, “active ﬁngerprinting” with forged source IPs can de-
feated by anonymizing addresses differently for connections that
are never established, since the adversaries will fail to complete
the TCP three-way handshake unless they can conduct an initial-
sequence-number guessing attack.
When we apply “knowledge separation”, a single object can
have multiple identiﬁers in the anonymized trace, which reduces
the value of the trace for some types of analysis. This is a basic
trade-off, and the choice of the degree to incur it will be policy-
dependent.
4.4 Case Study: FTP Anonymization
In light of these possible attacks and defenses, we now turn to the
anonymization scheme we used for LBNL’s FTP traces. Though
the scheme is inevitably dependent on the speciﬁc policy approved
by the site, and thus may not be directly applicable to other sites, we
believe the considerations and techniques, for instance, the “ﬁlter-
in” principle, will be also applicable to other site policies and other
application protocols. Accordingly, we discuss in detail relevant
points of the resulting anonymization process. The full scheme can
be found at [6].
The FTP traces were collected at the Internet access point (Giga-
bit Ethernet) of LBNL, and contain incoming anonymous FTP con-
nections to port 21. The traces do not include any of the transferred
FTP items (ﬁles uploaded or downloaded, or directory contents cor-
responding to the FTP “LIST” command), but only requests and
replies in the traces.
As stated above, our objectives are: 1) ensure that the anonymi-
zation hides the identity of clients, non-public FTP servers, and
non-public ﬁles, as well as conﬁdential authentication informa-
tion;3, and 2) the anonymization keeps the original request/reply
sequence and other nonsensitive information intact.
In some ways, these goals and the resulting traces are quite mod-
est. But we believe that the path to site’s becoming open to releas-
ing traces with packet contents is one that must be tread patiently,
as sites quite naturally must develop a solid sense that trust in the
anonymization process is warranted.
Self-Explaining: Besides the above objectives, we designed the
anonymization scheme to be self-explaining: it should be easy for
other people to examine and validate the scheme by merely look-
ing at the scheme description or the policy script, without being
familiar with every detail of FTP. We believe this is particularly
important in order for the policy makers at a site to understand and
accept trace anonymization.
3Here, hiding a “non-public” server/ﬁle means that if an adversary does not
know where to ﬁnd the server/ﬁle beforehand, they will not be able to ﬁnd
it after looking at the anonymized traces.
4.4.1 The Filter-In Principle
The key to obtaining a robust and coherent anonymization
scheme is to apply the “ﬁlter-in” principle, which is that the anony-
mization policy script explicitly speciﬁes what data to leave in
the clear, and everything else is anonymized (or removed). Thus,
“ﬁltering-in” implies using “white lists” of what is okay instead of
“black lists” of what is disallowed. The design choice in our frame-
work of “explicit rewriting” also reﬂects the “ﬁlter-in” principle.
It is critical to employ “ﬁlter in” instead “ﬁlter out”. Anonymiz-
ing FTP trafﬁc is complex enough that if we try to “ﬁlter out” pri-
vate information by enumerating all the sensitive data ﬁelds, it is
very likely that we will miss some of them. Also, a “ﬁlter-out”
scheme would be hard to verify, unless the veriﬁer can themselves
enumerate all of the sensitive ﬁelds.
Following the “ﬁlter-in” principle,
the difference between a
crude anonymization script and a reﬁned one is that the reﬁned
script will preserve more nonsensitive information in the output
trace; but the two scripts should be equally privacy-safe (though
we must keep in mind the maxim that complexity is the enemy of
robust security). Also, a “ﬁlter-in”-style anonymization scheme is
to some degree self-explaining—veriﬁcation of the scheme does
not require enumerating every possibility.
4.4.2 Selected Details of FTP Anonymization
IP addresses: (which appear in IP headers, PORT arguments, and
some reply messages such as reply to the PASV command) are se-
quentially numbered, since the site views preserving client privacy
as vital. (Recognizing IP addresses in reply messages is discuss in
Section 4.4.4.)
for “anonymous”,
“guest”,
IDs: