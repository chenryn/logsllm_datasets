0.1
0.2
-0.1
-1.3
0.2
SS
0.0
0.0
2.9
1.5
-2.3
-1.5
-0.6
-0.6
0.0
-0.3
0.0
-7.3
-0.4
0.0
0.0
0.0
0.0
-0.2
0.0
1.6
0.0
1.3
-1.0
-0.2
0.0
-0.2
0.0
0.0
-0.4
0.0
-1.1
0.0
-0.4
1.1
0.0
0.3
0.0
-3.5
0.1
PO
0.0
0.2
-0.2
0.0
0.0
-0.3
0.0
0.0
-0.1
0.0
0.0
0.0
0.0
0.4
0.0
0.0
0.1
-0.1
0.6
2.0
0.1
0.0
-1.0
0.2
-1.3
0.5
0.0
-0.4
0.0
-0.1
0.0
2.1
-0.3
1.1
0.0
0.9
0.1
0.0
0.1
All
2.9
-1.0
1.3
3.0
-1.4
5.3
2.0
0.7
0.8
1.7
-0.5
-7.3
0.7
0.4
1.7
1.2
-0.4
2.4
0.7
1.7
0.4
1.5
1.7
0.1
0.0
2.1
-1.2
-2.4
-1.3
-8.7
0.1
1.4
0.1
0.4
0.4
2.1
0.6
-3.7
1.1
the ﬁnal binary. A trap function is a small function which,
if executed, jumps to a fault handler. These traps are never
executed in a benign execution and thus incur no runtime
overhead but detect unexpected execution.
VI. EVALUATION
We evaluate the performance of EPOXY with respect to the
design goals, both in terms of security and resource overhead.
We ﬁrst evaluate the impact on runtime and energy using a set
of benchmarks. We then use three real-world IoT applications
to understand the effects on runtime, energy consumption, and
memory usage. Next, we present an evaluation of the effec-
tiveness of the security mechanisms applied in EPOXY. This
includes an evaluation of the effectiveness of diversiﬁcation
to defeat ROP-based code execution attacks and discussion
of the available entropy. We complete our evaluation by
comparing our solution to FreeRTOS with respect to the three
IoT applications.
Several different kinds of binaries are evaluated for each
program using different conﬁgurations of EPOXY these are:
(1) unmodiﬁed baseline, (2) privilege overlays (i.e., applies
privilege overlaying to allow the access controls to protect
system registers and apply W ⊕ X.), (3) SafeStack only, and
(4) fully protected variants that apply privileged overlaying,
SafeStack, and software diversity. We create multiple variants
of a program (20 is the default) by providing EPOXY a unique
diversiﬁcation seed. All binaries were compiled using link time
optimization at the O2 level.
We used two different development boards
for our
experiments
the STM32F4Discovery board [6] and the
STM32F479I-Eval [5] board. Power and runtime were mea-
sured using a logic analyzer sampling execution time at
100Mhz. Each application triggers a pin at the beginning and
at the end of its execution event. A current sensor with power
resolution of 0.5 μW was attached in series with the micro-
controller’s power supply enabling only the power used by the
micro-controller to be measured. The analog power samples
were taken at 125 KHz, and integrated over the execution time
to obtain the energy consumption.
A. Benchmark Performance Evaluation
To measure the effects of our techniques on runtime and en-
ergy we use the BEEBs benchmarks [47]. The BEEBs’ bench-
marks are a collection of applications from MiBench [34],
WCET [33] and DSPstone [60] benchmarks. They were de-
signed and selected to measure execution performance and en-
ergy consumption under a variety of computational loads. We
selected the 75 (out of 86) BEEBs’ benchmarks that execute
for longer than 50,000 clock cycles, and thus, providing a fair
comparison to real applications. For reference, our shortest IoT
application executes over 800,000 clock cycles. Each is loaded
onto the Discovery board and the logic analyzer captures
the runtime and energy consumption for 64 iterations of the
benchmark for each binary.
Across the 75 benchmarks the average overhead is 1.6%
for runtime and 1.1% for energy. The largest increase is on
cover 14.2% runtime, 17.9% energy and largest decrease on
compress (-11.7% runtime, -10.2% energy). ctl stack is the
only other benchmark that has a change in runtime (13.1%) or
energy (15.8%) usage that exceeds ±10%. Table II shows the
runtime and energy overheads for the benchmarks executing
over 2 million clock cycles. The remaining benchmarks are
omitted for space. We ﬁnd runtime is the biggest factor in
energy consumption—the Spearman’s rank correlation coefﬁ-
cient is a high 0.8591.
The impact on execution time can be explained by the
application of SafeStack (e.g., sg..queue in Table II) and diver-
siﬁcation. Modest improvements in execution time were found
by the creators of SafeStack ([40] §5.2), the primary cause
being improvements in locality. Likewise, our improvements
come from moving some variables to the unsafestack. These
typically tend to be larger variables like arrays. This increases
the locality of remaining variables on the regular stack and
297
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:26:08 UTC from IEEE Xplore.  Restrictions apply. 
enables them to be addressed from offsets to the stack pointer,
rather than storing base addresses in registers and using offsets
from these. This frees additional registers to store frequently
used variables, thus reducing register spilling, and consequent
writes and reads to the stack, thereby improving execution
time. The impact of the privilege overlay on the running
time is minimal because these benchmarks have few restricted
operations in them and the setups due to EPOXY (such as
MPU conﬁguration) happen in the startup phase which is not
measured for calculating the overhead.
Diversiﬁcation changes execution time in two ways. The
ﬁrst is locality of functions and variables relative to each other.
Consider separately the case of a control-ﬂow transfer and a
memory load/store. When a control-ﬂow transfer is done (say
a branch instruction) and the target is close by, then the target
address is created relative to the PC and control ﬂow is trans-
ferred to that address (1 instruction). On the other hand, if the
target address is farther off, then a register is loaded with the
address (2 instructions) and control transferred to the content
of the register (1 instruction). Sometimes diversiﬁcation puts
the callee and called function farther apart than in the baseline
in which case the more expensive operation is used. In other
cases the opposite occurs, enabling less expensive (compared
to the baseline) control transfer to be used. Similarly, when
a memory load (or store) is done from a far off location, a
new register needs to be loaded with the address and then
the location accessed (3 instructions), while if it were to a
location near an address already in a register, then it can
be accessed using an offset from that register as the base
address (1 instruction). The dispersed accesses also uses more
registers, increasing register pressure.
Another effect of diversiﬁcation is even more subtle and
architecture speciﬁc. In our target ARM architecture, when a
caller invokes a function, general-purpose registers R0-R3 are
assumed to be used and overwritten by the callee function
and therefore the compiler does not need to save the values
of those registers in the callee context. Thus the compiler
gives preference to using R0-R3 when allocating registers. Due
to our register randomization this preference is not always
followed, and other general purpose registers (R4-R13) are
used more often than they are in the baseline case. When R4-
R13 are used they ﬁrst must be saved to, and restored from
the stack, decreaseing performance. To partially alleviate this
performance hit, EPOXY in its register randomization favors
the use of the registers R0-R3 in the callee function through a
non-uniform stochastic process, but does not deterministically
enforce this. Reassuringly, the net effect from all the instances
of the diversiﬁcation is only a small increase in the runtime—
a worst case of 14.7% and an average of 1.1% across all the
benchmark applications.
B. Application Performance Evaluation
Benchmarks are useful for determining the impact of our
techniques under controlled conditions. To understand the
overall effects on realistic applications, we use three represen-
tative IoT applications. Our ﬁrst program, PinLock, simulates
a simple IoT device like a door lock. It requests a four digit
pin be entered over a serial port. Upon reception the pin is
hashed, using SHA1, and compared to a precomputed hash.
If the hashes match, an LED is turned on, indicating the
system is unlocked. If an incorrect pin is received the user is
prompted to try again. In this application the IO is restricted
to privileged mode only, thus each time the lock is unlocked,
privileged execution must ﬁrst be obtained. This demonstrates
EPOXY’s ability to apply application speciﬁc access controls.
We repeatedly send an incorrect pin followed by the correct
pin and measure time between successful unlocks. The baud
rate (115,200 max standard rate) of the UART communications
is the limiting factor in how fast login attempts are made.
We also use two vendor applications provided with the
STM32F479I-Eval board. The FatFS-uSD program imple-
ments a FAT ﬁle system on a micro-SD card. It creates a
ﬁle on the SDCard, writes 1KB of data to the ﬁle and then
reads back the contents and checks that they are the same. We
measure the time it takes to write, read and verify the ﬁle. The
TCP-Echo application implements a TCP/IP stack and listens
for a packet on the Ethernet connection. When it receives a
packet it echoes it back to the receiver. We measure the time
it takes to send and receive 1,000 packets, with requests being
sent to the board fast enough to fully saturate the capabilities
of the STM32F479I-Eval board (i.e., computation on the board
is the limiting factor in how fast packets are sent and received).
For each of the three applications we create the same set
of binaries used for the benchmarks: baseline, SafeStack only,
privilege overlay only, and 20 variants with all protections
of EPOXY. To obtain runtime and energy consumption we
average 10 executions of each binary. Percent increase relative
to the baseline binary is taken for each binary. The average
runtime overhead is 0.7% for PinLock, 2.4% for FatFS-uSD,
and 2.1% for TCP-Echo. Figure 5a shows the execution time
overheads as a whisker plot. In the worst case among all
executions of all applications protected with EPOXY,
the
runtime overhead is 6.5% occurring on TCP-Echo. Again
we see energy consumption is closely related to execution
time. Each application’s average energy overheads are: −2.9%
for PinLock, 2.6% for FatFS-uSD and 1.8% for TCP-Echo.
Figure 5b shows the energy consumption overheads, with
a noticeable difference: PinLock has a very tight runtime
distribution, and a relatively wide energy distribution. This
application is IO bound and the application is often waiting to
receive a byte over the serial port, due to the slow serial con-
nection, causing the time variation to be hidden. However, the
changed instruction mix due to EPOXY still causes variation
in energy overhead.
Changes in memory usage are shown in Table III. It shows
the averages of increase to code (text section), global data (data
and bss sections), and stack usage for the 20 variants of each
application. SafeStack, privilege overlaying, and diversiﬁca-
tion can all affect the code size. SafeStack increases the code
size by requiring additional instructions to manage a second
stack, privilege overlaying directly injects new code, and as
discussed previously diversiﬁcation can cause the compiler to
298
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:26:08 UTC from IEEE Xplore.  Restrictions apply. 
SS
PO
15
10
5
0
−5
e
m
i
t
n
u
R
e
s
a
e
r
c
n
I
%
−10
−15
k
c
o
L
n
P
i
D
S
u
-
S
F
t
a
F
(a)
o
h
c
E
-
P
C
T
y
g
r
e
n
E