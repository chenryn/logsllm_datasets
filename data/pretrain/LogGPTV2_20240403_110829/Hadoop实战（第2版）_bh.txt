"RemoteException"：
{
"exception"："FileNotFoundException"，
"javaClassName"："java.io.FileNotFoundException"，
"message"："File does not exist：/foo/a.patch"
}
}
出现这种异常的原因是找不到指定的目录或者文件，这需要用户确认自己命令中的路径和文件。
9.9 本章小结
在本章中，深入介绍了Hadoop中一个关键的分布式文件系统HDFS。HDFS是Hadoop的一个核心子项目，是Hadoop进行大数据存储管理的基础，它支持MapReduce分布式计算。
首先，对Hadoop的文件系统进行了总体的概括，随后针对HDFS进行了简单介绍，分析了它的研究背景和设计基础。有了这样的背景知识，就可以在随后的章节中更好地理解HDFS的功能和实现。本章还从结构上对HDFS进行了描述，给出了HDFS的相关概念，包括块、NameNode、DataNode等。通过对HDFS概念的学习，还可以了解HDFS的体系结构。
其次，在掌握基本概念的基础上，我们介绍了HDFS的基本操作接口。HDFS为开发者提供了丰富的接口，包括命令行接口和各种方便使用的Java接口，可以通过Java API对HDFS中的文件执行常规的文件操作。不仅如此，在使用API对HDFS文件系统进行管理的基础上，还对HDFS中文件流的读/写进行了详细介绍。这对更深入地了解HDFS有很大帮助。
最后，本章对HDFS的命令进行了详细讲解，并对其中特有的distcp操作和归档文件进行了具体说明，理解了它们可以更好地帮助大家了解Hadoop的文件系统。
第10章 Hadoop的管理
本章内容
HDFS文件结构
Hadoop的状态监视和管理工具
Hadoop集群的维护
本章小结
在第2章我们已经详细介绍了如何安装和部署Hadoop集群，本章我们将具体介绍如何维护集群以保证其正常运行。毋庸置疑，维护一个大型集群稳定运行是必要的，手段也是多样的。为了更清晰地了解Hadoop集群管理的相关内容，本章主要从HDFS本身的文件结构，Hadoop的监控管理工具以及集群常用的维护功能三方面进行讲解。
10.1 HDFS文件结构
作为一名合格的系统运维人员，首先要全面掌握系统的文件组织目录。对于Hadoop系统的运维人员来说，就是要掌握HDFS中的NameNode、DataNode、Secondery NameNode是如何在磁盘上组织和存储持久化数据的。只有这样，当遇到问题时，管理人员才能借助系统本身的文件存储机制来快速诊断和分析问题。下面从HDFS的几个方面来分别介绍。
1.NameNode的文件结构
最新格式化的NameNode会创建以下目录结构：
${dfs.name.dir}/current/VERSION
/edits
/fsimage
/fstime
其中，dfs.name.dir属性是一个目录列表，是每个目录的镜像。VERSION文件是Java属性文件，其中包含运行HDFS的版本信息。下面是一个典型的VERSION文件包含的内容：
#Wed Mar 23 16：03：27 CST 2011
namespaceID=1064465394
cTime=0
storageType=NAME_NODE
layoutVersion=-18
其中，namespaceID是文件系统的唯一标识符。在文件系统第一次被格式化时便会创建namespaceID。这个标识符也要求各DataNode节点和NameNode保持一致。NameNode会使用此标识符识别新的DataNode。DataNode只有在向NameNode注册后才会获得此namespaceID。cTime属性标记了NameNode存储空间创建的时间。对于新格式化的存储空间，虽然这里的cTime属性值为0，但是只要文件系统被更新，它就会更新到一个新的时间戳。storageType用于指出此存储目录包含一个NameNode的数据结构，在DataNode中它的属性值为DATA_NODE。
layoutVersion是一个负的整数，定义了HDFS持久数据结构的版本。注意，该版本号和Hadoop的发行版本号无关。每次HDFS的布局发生改变，该版本号就会递减（比如-18版本号之后是-19），在这种情况下，HDFS就需要更新升级，因为如果一个新的NameNode或DataNode还处在旧版本上，那么系统就无法正常运行，各节点的版本号要保持一致。
NameNode的存储目录包含edits、fsimage、fstime三个文件。它们都是二进制的文件，可以通过HadoopWritable对象进行序列化。下面将深入介绍NameNode的工作原理，以便使大家更清晰地理解这三个文件的作用。
2.编辑日志（edit log）及文件系统映像（filesystem image）
当客户端执行写操作时，NameNode会先在编辑日志中写下记录，并在内存中保存一个文件系统元数据，元数据会在编辑日志有所改动后进行更新。内存中的元数据用来提供读数据请求服务。
编辑日志会在每次成功操作之后、成功代码尚未返回给客户端之前进行刷新和同步。对于要写入多个目录的操作，写入流要刷新和同步到所有的副本，这就保证了操作不会因故障而丢失数据。
fsimage文件是文件系统元数据的持久性检查点。和编辑日志不同，它不会在每个文件系统的写操作后都进行更新，因为写出fsimage文件会非常慢（fsimage可能增长到GB大小）。这种设计并不会影响系统的恢复力，因为如果NameNode失败，那幺元数据的最新状态可以通过将从磁盘中读出的fsimage文件加载到内存中来进行重建恢复，然后重新执行编辑日志中的操作。事实上，这也正是NameNode启动时要做的事情。一个fsimage文件包含以序列化格式存储的文件系统目录和文件inodes。每个inodes表示一个文件或目录的元数据信息，以及文件的副本数、修改和访问时间等信息。
正如上面所描述的，Hadoop文件系统会出现编辑日志不断增长的情况。尽管在NameNode运行期间不会对系统造成影响，但是，如果NameNode重新启动，它将会花费很长时间来运行编辑日志中的每个操作。在此期间（即安全模式时间），文件系统还是不可用的，通常来说这是不符合应用需求的。
为了解决这个问题，Hadoop在NameNode之外的节点上运行一个Secondary NameNode进程，它的任务就是为原NameNode内存中的文件系统元数据产生检查点。其实Secondary NameNode是一个辅助NameNode处理fsimage和编辑日志的节点，它从NameNode中复制fsimage和编辑日志到临时目录并定期合并生成一个新的fsimage，随后它会将新的fsimage上传到NameNode，这样，NameNode便可更新fsimage并删除原来的编辑日志。下面我们参照图10-1对检查点处理过程进行描述。
下面介绍检查点处理过程的具体步骤。
1）Secondary NameNode首先请求原NameNode进行edits的滚动，这样新的编辑操作就能够进入一个新的文件中了。
2）Secondary NameNode通过HTTP方式读取原NameNode中的fsimage及edits。
3）Secondary NameNode读取fsimage到内存中，然后执行edits中的每个操作，并创建一个新的统一的fsimage文件。
4）Secondary NameNode（通过HTTP方式）将新的fsimage发送到原NameNode。
5）原NameNode用新的fsimage替换旧的fsimage，旧的edits文件通过步骤1）中的edits进行替换。同时系统会更新fsimage文件到记录检查点记录的时间。
图 10-1 检查点处理过程
在这个过程结束后，NameNode就有了最新的fsimage文件和更小的edits文件。事实上，对于NameNode在安全模式下的这种情况，管理员可以通过以下命令运行这个过程：
hadoop dfsadmin-saveNamespace
这个过程清晰地表明了Secondary NameNode要有和原NameNode一样的内存需求的原因—要把fsimage加载到内存中，因此Secondary NameNode在集群中也需要有专用机器。
有关检查点的时间表由两个配置参数决定。Secondary NameNode每小时会插入一个检查点（fs.chec-kpoint.period，以秒为单位），如果编辑日志达到64MB（fs.checkpoint.size，以字节为单位），则间隔时间更短，每隔5分钟会检查一次。
3.Secondary NameNode的目录结构
Secondary NameNode在每次处理过程结束后都有一个检查点。这个检查点可以在一个子目录/previous.checkpoint中找到，可以作为NameNode的元数据备份源，目录如下：
${fs.checkpoint.dir}/current/VERSION
/edits
/fsimage
/fstime
/previous.checkpoint/VERSION
/edits
/fsimage
/fstime
以上这个目录和Secondary NameNode的/current目录结构是完全相同的。这样设计的目的是：万一整个NameNode发生故障，并且没有用于恢复的备份，甚至NFS中也没有备份，就可以直接从Secondary NameNode恢复。具体方式有两种，第一种是直接复制相关的目录到新的NameNode中。第二种是在启动NameNode守护进程时，Secondary NameNode可以使用-importCheckpoint选项，并作为新的NameNode继续运行任务。-importCheckpoint选项将加载fs.checkpoint.dir属性定义的目录中的最新检查点的NameNode数据，但这种操作只有在dfs.name.dir所指定的目录下没有元数据的情况下才进行，这样就避免了重写之前元数据的风险。
4.DataNode的目录结构
DataNode不需要进行格式化，它会在启动时自己创建存储目录，其中关键的文件和目录如下：
${dfs.data.dir}/current/VERSION
/blk_＜id_1＞
/blk_＜id_1＞.meta
/blk_＜id_2＞
/blk_＜id_2＞.meta
/……
/subdir0/
/subdir1/
/……
/subdir63/
DataNode的VERSION文件和NameNode的非常类似，内容如下：
#Tue Mar 10 21：32：31 GMT 2010
namespaceID=134368441
storageID=DS-547717739-172.16.85.1-50010-1236720751627
cTime=0
storageType=DATA_NODE
layoutVersion=-18
其中，namespaceID、cTime和layoutVersion值与NameNode中的值都是一样的，namaspaceID在第一次连接NameNode时就会从中获取。stroageID相对于DataNode来说是唯一的，用于在NameNode处标识DataNode。storageType将这个目录标志为DataNode数据存储目录。
DataNode中current目录下的其他文件都有blk_refix前缀，它有两种类型：
1）HDFS中的文件块本身，存储的是原始文件内容；
2）块的元数据信息（使用.meta后缀标识）。一个文件块由存储的原始文件字节组成，元数据文件由一个包含版本和类型信息的头文件和一系列块的区域校验和组成。
当目录中存储的块数量增加到一定规模时，DataNode会创建一个新的目录，用于保存新的块及元数据。当目录中的块数量达到64（可由dfs.DataNode.numblocks属性值确定）时，便会新建一个子目录，这样就会形成一个更宽的文件树结构，避免了由于存储大量数据块而导致目录很深，使检索性能免受影响。通过这样的措施，数据节点可以确保每个目录中的文件块数是可控的，也避免了一个目录中存在过多文件。
10.2 Hadoop的状态监视和管理工具
对一个系统运维的管理员来说，进行系统监控是必须的。监控的目的是了解系统何时出现问题，并找到问题出在哪里，从而做出相应的处理。管理守护进程对监控NameNode、DataNode和JobTracker是非常重要的。在实际运行中，因为DataNode及TaskTracker的故障可能随时出现，所以集群需要提供额外的功能以应对少部分节点出现的故障。管理员也要隔一段时间执行一些监测任务，以获知当前集群的运行状态。本节将详细介绍Hadoop如何实现系统监控。
 10.2.1 审计日志
HDFS通过审计日志可以实现记录文件系统所有文件访问请求的功能，其审计日志功能通过log4j实现，但是在默认配置下这个功能是关闭的：log的记录等级在log4j.properties中被设置为WARN：
log4j.logger.org.apache.hadoop.fs.FSNamesystem.audit=WARN
在此处将WARN修改为INFO，便可打开审计日志功能。这样在每个HDFS事件之后，系统都会在NameNode的log文件中写入一行记录。下面是一个请求/usr/hadoop文件的例子：
2010-03-13 07：11：22，982 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit：
ugi=admin, staff, admin ip=/127.0.0.1 cmd=listStatus src=/user/admin=null
perm=null
关于log4j还有很多其他配置可改，比如可以将审计日志从NameNode的日志文件中分离出来等。具体操作可查看Hadoop的Wiki：http：//wiki.apache.org/hadoop/HowToConfigure。
10.2.2 监控日志
所有Hadoop守护进程都会产生一个日志文件，这对管理员来说非常重要。下面我们就介绍如何使用这些日志文件。
1.设置日志级别
当进行故障调试排除时，很有必要临时调整日志的级别，以获得系统不同类型的信息。log4j日志一般包含这样几个级别：OFF、FATAL、ERROR、WARN、INFO、DEBUG、ALL或用户自定义的级别。
Hadoop守护进程有一个网络页面可以用来调整任何log4j日志的级别，在守护进程的网络UI后附后缀/logLevel即可访问该网络页面。按照规定，日志的名称和它所对应的执行日志记录的类名是一样的，可以通过查找源代码找到日志名称。例如，为了调试JobTracker类的日志，可以访问JobTracker的网络UI：http：//jobtracker-host：50030/logLevel，同时设置日志名称org.apache.hadoop.mapred.JobTracker到层级DEBUG。当然也可以通过命令行进行调整，代码如下：
hadoop daemonlog-setlevel jobtracker-host：50030\
org.apache.hadoop.mapred.JobTracker DEBUG
通过命令行修改的日志级别会在守护进程重启时被重置，如果想要持久化地改变日志级别，那么只要改变log4j.properties文件内容即可。我们可以在文件中加入以下行：
log4j.logger.org.apache.hadoop.mapred.JobTracker=DEBUG
2.获取堆栈信息
有关系统的堆栈信息，Hadoop守护进程提供了一个网络页面（在网络UI后附后缀/stacks才可以访问），该网络页面可以为管理员提供所有守护进程JVM中运行的线程信息。可以通过以下链接访问该网络页面：http：//jobtracker-host：50030/stacks。
10.2.3 Metrics
事实上，除了Hadoop自带的日志功能以外，还有很多其他可以扩展的Hadoop监控程序供管理员使用。在介绍这些监控工具之前，先对系统的可度量信息（Metrics）进行简单讲解。
HDFS及MapReduce的守护进程会按照一定的规则来收集系统的度量信息。我们将这种度量规则称为Metrics。例如，DataNode会收集如下度量信息：写入的字节数、被复制的文件块数及来自客户端的请求数等。
Metrics属于一个上下文，当前Hadoop拥有dfs、mapred、rpc、jvm等上下文。Hadoop守护进程会收集多个上下文的度量信息。所谓上下文即应用程序进入系统执行时，系统为用户提供的一个完整的运行时环境。进程的运行时环境是由它的程序代码和程序运行所需要的数据结构以及硬件环境组成的。
这里我们认为，一个上下文定义了一个单元，比如，可以选择获取dfs上下文或jvm上下文。我们可以通过配置conf/hadoopmetrics.properties文件设定Metrics。在默认情况下，会将所有上下文都配置为NullContext类，这代表它们不会发布任何Metrics。下面是配置文件的默认配置情况：
dfs.class=org.apache.hadoop.metrics.spi.NullContext
mapred.class=org.apache.hadoop.metrics.spi.NullContext
jvm.class=org.apache.hadoop.metrics.spi.NullContext
rpc.class=org.apache.hadoop.metrics.spi.NullContext
其中每一行都针对一个不同的上下文单元，同时每一行定义了处理此上下文Metrics的类。这里的类必须是MetricsContext接口的一个实现；在上面的例子中，这些NullContext类正如其名，什么都不做，既不发布也不更新它们的Metrics。
下面我们来介绍MetricsContext接口的实现。
1.FileContext
利用FileContext可将Metrics写入本地文件。FileContext拥有两个属性：fileName—定义文件的名称，period—指定文件更新的间隔。这两个属性都是可选的，如果不进行设置，那么Metrics每隔5秒就会写入标准输出。
配置属性将应用于指定的上下文中，并通过在上下文名称后附加点“.”及属性名进行标示。比如，为了将jvm导出一个文件，我们会通过以下方法调整它的配置：
jvm.class=org.apache.hadoop.metrics.file.FileContext
jvm.fileName=/tmp/jvm_metrics.log
其中，第一行使用FileContex来改变jvm的上下文，第二行将jvm上下文导出临时文件。
需要注意的是，FileContext非常适合于本地系统的调试，但是它并不适合在大型集群中使用，因为它的输出文件会被分散到集群中，使分析的时间成本变得很高。
2.GangliaContext
Ganglia（http：//ganglia. info/）是一个开源的分布式监控系统，主要应用于大型分布式集群的监控。通过它可以更好地监控和调整集群中每个机器节点的资源分配。Ganglia本身会收集一些监控信息，包括CPU和内存使用率等。通过使用GangliaContext我们可以非常方便地将Hadoop的一些测量内容注入Ganglia中。此外，GangliaContext有一个必须的属性—servers，它的属性值是通过空格或逗号分隔的Ganglia服务器主机地址：端口。我们将在10.2.5节中进行详细讲解。
3.NullContextWithUpdateThread
通过前面的介绍，我们会发现FileContext和GangliaContext都将Metrics推广到外部系统。而Hadoop内部度量信息的获取需要另外的工具，比如著名的Java管理扩展（Java Management Extensions, JMX），JMX中的NullContextWithUpdateThread就是用来解决这个问题的（我们将在后面进行详细讲解）。和NullContext相似，它不会发布任何Mertics，但是它会运行一个定时器周期性地更新内存中的Metrics，以保证另外的系统可以获得最新的Metrics。
除NullContextWithUpdateThread外，所有MetricsContext都会执行这种在内存中定时更新的方法，所以只有当不使用其他输出进行Metrics收集时，才需要使用NullContext-WithUpdateThread。举例来说，如果之前正在使用GangliaContext，那么随后只要确认Metrics是否被更新，而且只需要使用JMX，不用进一步对Metrics系统进行配置。
4.CompositeContext
CompositeContext允许我们输出多个上下文中的相同的Metrics，比如下面的这个例子：
jvm.class=org.apache.hadoop.metrics.spi.CompositeContext
jvm.arity=2
jvm.sub1.class=org.apache.hadoop.metrics.file.FileContext
jvm.fileName=/tmp/jvm_metrics.log
jvm.sub2.class=org.apache.hadoop.metrics.ganglia.GangliaContext
jvm.servers=ip-10-70-20-111.ec2.internal：8699
其中arity属性用来定义子上下文数量，在这里它的值为2。所有子上下文的属性名称都可以使用下面的句子设置：jvm.sub1.class=org.apache.hadoop.metrics.file.FileContext。
10.2.4 Java管理扩展
Java管理扩展（JMX）是一个为应用程序、设备、系统等植入管理功能的框架。JMX可以跨越一系列异构操作系统平台、系统体系结构和网络传输协议，灵活地开发无缝集成的系统、网络和服务管理应用。Hadoop包含多个MBean（Managed Bean，管理服务，它描述一个可管理的资源），它可以将Hadoop的Metrics应用到基于JMX的应用程序中。当前MBeans可以将Metrics展示到dfs和rpc上中文中，但不能在mapred及jvm上下文中实现。表10-1是MBeans的列表。