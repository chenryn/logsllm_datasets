ing to find relations between binaries. BLEX [20] collects dynamic
behaviors such as memory accesses and syscalls during execution
and then computes the similarity of the functions.
Evaluation Metrics. Since PatchScope and baseline techniques
have metrics to represent differences, directly showing their results
is not informative. As a normalization, we represent their results by
counting the number of different units, including different instruc-
tions (BinDiff, Diaphora), basic blocks (DarunGrim, DeepBinDiff,
and CoP), system calls (BinSim), memory cells (BLEX), and memory
object access items (PatchScope).
5.2 Locating Patch Differences
Table 2 summarizes our comparative evaluation results in terms
of located patch differences. The left three columns list vulnera-
ble programs, CVE ID, and vulnerability types. The following two
columns list lines-of-code changes and security patch types. For the
last eight applications, as we do not have their concrete security
patch information, the corresponding items (“LOC” & “Type”) are
denoted as “NA”. The two sub-columns under “Time (s)” shows
PatchScope’s overhead. The runtime overhead imposed by multi-
tag taint analysis and execution monitoring (as shown in “Trace”
sub-column) is about 10X slowdown on average. “Diff” sub-column
shows the running time of PatchScope’s offline comparison. Con-
sidering that PatchScope attempts to free security professionals
from the burden of manually reverse-engineering security patches,
PatchScope’s overhead is acceptable.
By examining the numbers of located differences from Table 2,
we have several observations. The most important take-away in-
formation is PatchScope delivers more accurate results than other
techniques. PatchScope and DeepBinDiff identify much fewer dif-
ferences than other techniques. Intuitively, this result indicates that
PatchScope and DeepBinDiff are more effective. A deeper analysis
shows that DeepBinDiff fails to identify more patch differences
than PatchScope. We will compare their false positives and false
negatives as follows.
Second, three industry binary diffing tools and BLEX [20] report
more numbers than other techniques. By associating the numbers
of differences and the lines-of-code changes, we further observe
that these tools work well when the small LOC changes explicitly
modify CFG/CG structures. However, with the LOC number in-
creasing, they suffer from a large number of low-level assembly
code differences.
Third, BinSim identifies patch differences accurately only in
12 applications. This result confirms our theoretical analysis that
program representations used in semantics-aware binary diffing
techniques are too coarse-grained to fit patch analysis, because
many security patch types do not involve any API/syscall changes.
Static vs. Dynamic. Static and dynamic techniques have their own
advantages. Dynamic techniques based on PoCs can filter out patch-
irrelevant differences. However, dynamic techniques may also miss
patch-relevant differences due to incomplete coverage.
By comparing the numbers of identified differences, we can fur-
ther observe that dynamic techniques identify fewer differences
than static techniques for most of the applications. For example,
trace-based binary diffing reports much less number of differences
than static-based binary diffing, except for 7 applications (includ-
ing newspost-2.1, libsndfle-1.0.25, ringtonetools-2.22, O3read-0.03,
conquest-8.2a, libsmi-0.4.8, and 2fax-3.04).
For these 7 exception applications, we manually examined the
code changes and execution traces, and find that most of the identi-
fied differences are duplicated within a loop. That is, patches for
these seven applications involve a code change with a loop. For
example, the security patch in newspost-2.1 checks the index of an
array within its boundary for each memory access to the internal
bytes of the array. Then, the code change corresponding to the
check will be repeated along with the execution.
To move further, we observe that PatchScope identifies fewer
differences for these seven applications, which is less impacted
by code changes in a loop. For example, trace-based binary diff-
ing tools report thousands of differences in newspost-2.1, whereas
PatchScope reduces the large difference number to only 1. To con-
firm this result, we inspect the result of PatchScope and observe
that PatchScope does not capture the difference caused by the
security check on index, because the index does not directly depend
on program inputs and thus is not tainted. Instead, PatchScope
detected a pair of different memory object access items, where
the continuous bytes (the element α in Definition 2) differ. With
this information, we can infer that the patched program regulates
the handling of the PoC by cutting the received input. This case
demonstrates that the memory object access enables PatchScope to
capture higher-level patch differences beyond assembly code.
False positives and False Negatives. To verify that located dif-
ferences are patch relevant, we manually examine identified differ-
ences, and calculate the false positives and false negatives based
on the ground truth. Unlike binary diffing techniques that directly
identified different instructions or blocks, BLEX [20] identifies dif-
ferent memory accesses regarding values of memory cells, and
PatchScope identifies different memory object access items. To cal-
culate false positives and false negatives, we associate the identified
Table 3: False positive and false negative rates.
BinDiff
static
trace
static
Diaphora
trace
DarunGrim static
trace
static
trace
DeepBinDiff
BLEX
CoP
BinSim
PatchScope
FPR
42.23%
32.67%
39.29%
29.37%
33.75%
22.76%
18.31%
12.12%
81.56%
27.12%
0.00%
14.73%
FNR
15.56% (7/45)
15.56% (7/45)
15.56% (7/45)
15.56% (7/45)
15.56% (7/45)
15.56% (7/45)
26.67% (12/45)
26.67% (12/45)
2.22% (1/45)
51.11% (23/45)
73.33% (33/45)
2.22% (1/45)
item with patched code via its operation instruction. The statistics
are shown in Table 3.
The false-positive rate is calculated as the ratio of the number of
patch-irrelevant differences to the number of all identified differ-
ences. Please note that we only calculate false positives for the 37
applications of which the patch source is available. Among these
37 applications, only one patch is involved for each pair of patched
and unpatched applications. For the other 8 applications where the
vulnerabilities are fixed in update versions, the updated versions
may contain multiple fixes and there are multiple differences indeed.
Thus, we cannot regard an identified difference that is irrelevant to
the fixed vulnerability as a false positive.
A false negative refers to a missed patch difference. The false-
negative rate is calculated as the ratio of the number of missed
patches to the number of all patches. In total, the statistics of false
positives covers 37 applications, and the statistics of false negatives
covers all 45 applications.
As shown in Table 3, the false-positive rate in PatchScope is a lit-
tle larger than that in the trace-based DeepBinDiff, but much smaller
than those in other techniques. In fact, some patch-irrelevant MOA
items identified by PatchScope are affected by the patch. For exam-
ple, if a memory object is overwritten during the execution of a PoC,
accessing this memory object will be identified as a difference by
PatchScope. To alleviate false positives, we can further tie different
MOA items according to their data dependencies. By contrast, false
positives in other techniques lack such associations.
CoP [40] encounters more false negatives, because CoP does
not deal with library functions. Thus, changes related to library
functions will be missed by CoP. We observe that the false-positive
rate of BLEX is pretty high. As BLEX [20] identifies different values
read from or written to memory cells, code changes would result
in a number of differences, including function pointers, instruc-
tion addresses, function parameters, and values of variables. By
contrast, PatchScope outperforms BLEX [20] on two aspects: 1)
PatchScope identifies differences on top of the reverse-engineered
memory objects, which is a higher-level program abstraction than
memory cells in BLEX [20]; 2) PatchScope only captures differ-
ences regarding input manipulations via memory objects, whereas
BLEX [20] identifies all memory access behaviors.
We can observe that PatchScope encounters the least false neg-
atives, which fails to identify patch differences for only one ap-
plication. The only one false negative is caused by an off-by-one
vulnerability in Apache-1.3.35 and its patch. With basic code com-
parison, we identify that patch changes an instruction from cmp
$0x5,%ecx to cmp $0x4,%ecx. All the techniques fail to identify this
small code change. Through dynamic debugging, we observe that
the off-by-one operation overruns a memory object with a pointer
pointing to a memory object for received inputs. As our dynamic
taint component only tracks input propagations on memory objects,
pointers to these memory objects will not be tainted. Thus, our
approach fails to identify this patch points.
PatchScope and other dynamic techniques may miss a part of
patch-relevant differences if the corresponding code is not traversed.
By examining the ground truth, we find that the vulnerability (CVE-
2005-4807) exists in 4 different locations in binutils-2.12. The se-
curity patch fixes 4 different vulnerable statements. PatchScope
only identifies 2 locations that are covered by the execution trace,
because the PoC did not trigger the vulnerability at the other two
locations. An interesting observation is that DeepBinDiff identifies
only 2 differences, even though all the 4 differences are induced by
the same fix.
By comparing the false negatives of PatchScope with other
techniques, we find 4 applications of which the security patch dif-
ferences can only be captured by PatchScope. Further inspection
shows that these patches include resizing a buffer length, chang-
ing a parameter, and changing the value of a const variable. For
example, the security patch of streamripper increases a buffer size
from 0x32 to 0x f b8. The security patch of Fontforge changes a for-
mat string from %[\”] to %99[\”]. Other techniques fail to identify
them because these patches induce no changes in assembly code.
By contrast, PatchScope can identify them via MOAS comparison
because such code changes induce different input manipulations.
5.3 Interpreting Identified Differences
In terms of granularity, differences identified by PatchScope is the
most fine-grained and informative one among these units. Accord-
ing to Definition 1 and Definition 2, different items in MOAS
include details of memory objects, contexts, operations on mem-
ory objects, and correlated input manipulations. Such contexts can
interpret and determine differences caused by security patches.
To demonstrate that PatchScope delivers rich information for
interpreting differences, we summarize the details of different MOA
items identified by PatchScope, and present detailed elements
between a pair of MOA items. Besides, we also present the impacts
on input manipulations by examining the elements of α. Please
note that elements can impact others. For example, changes of cc
and op typically lead to different α. For this problem, we mark α as
different if and only if the elements of α differ.
From Table 4, we observe that security patches include changes
in both memory objects and the accesses to memory objects. For
security patches that induce no changes in assembly code, such
as streamripper and Fontforge, PatchScope can detect different
MOA items via the impact on input manipulations (α). Indicated by
such information, a reverse-engineer can reason this difference by
backtracking the contexts for calling library functions, and identify
the different parameters.
On the contrary, PatchScope can also locate patch-relevant
differences with our program abstraction for complicated patches.
Table 4: Interpreting differences via the elements in MOA.
Impacts on input manipulations
cut the inputs
filter the inputs None
Diff in MO
Diff in MOA
alloc
size
type
cc
op
α
0
3
1
0
7
10
0
0
0
17
0
0
1
0
0
0
5
0
For example, the patch for 2fax-3.04 overwrites a function. Most of
the baseline techniques identify a pair of unmatched functions and a
large number of unmatched items, which is impractical to interpret
these differences as security experts could be plagued by such a
large number of low-level code differences. With the assistance of
PatchScope, we find that the MOAS from the patched program
adds a security check. More details are presented in Appendix C.
Another remarkable case is putty, of which the patch is unavail-
able. Its new version contains quite a lot of updates. Diaphora shows
up to 696 different instructions. BLEX [20] identifies up to 4564
different memory accesses, and these differences would overwhelm
reverse-engineers. Besides, it is difficult to extract semantics and
contexts from these differences.
To further reveal the advantages that PatchScope provides rich
patch context information that other tools cannot offer, we present
several case studies in the appendix to show how PatchScope can
assist patch analysis.
6 DISCUSSION AND CONCLUSION
Our approach relies on dynamic taint analysis to excavate program
data structures. It may lead to under-tainting problems caused by
control-flow dependencies and pointer tainting. A possible solution,
like DTA++ [32] and pointer tainting policy [56], is to add additional
taint rules for implicit data flows.
We focus on security patches for memory corruption. Our insight
that most security patches aim to better regulate the handling of
bad inputs may also apply to other types of vulnerabilities such as
permission bypassing. We will leave it as future work.
The evaluation only consists of x86 applications, because the
runtime analysis is built on top of DECAF [28] and DECAF for
supporting x86-64 is still under development. To support x86-64
applications, we should revise our algorithm for excavating pro-
gram data structures as the calling convention changes. We believe
it is not difficult since the calling convention in x86-64 should also
follow memory access patterns.
Patch analysis is a prominent application of binary diffing tech-
niques. In this paper, we develop a memory object centric dynamic
approach for patch analysis. Our technique can not only capture
small security patch differences but also reveal more patch details.
Security professionals utilizing PatchScope will enjoy a simpler
and a more streamlined patch analysis process than ever before.
ACKNOWLEDGMENT
This work is partly supported by National Natural Science Founda-
tion of China under Grant No.61672394, U1836112, and 61876134.
Jiang Ming and Haotian Zhang were supported by National Science
Foundation (NSF) under grant CNS-1850434.
REFERENCES
[1] Gautam Altekar, Ilya Bagrak, Paul Burstein, and Andrew Schultz. 2005. OPUS:
Online Patches and Updates for Security. In Proceedings of the 14th USENIX
Security Symposium.
[2] Frederico Araujo, Kevin W. Hamlen, Sebastian Biedermann, and Stefan Katzen-
beisser. 2014. From Patches to Honey-Patches: Lightweight Attacker Misdirection,
Deception, and Disinformation. In Proceedings of the 2014 ACM SIGSAC Conference
on Computer and Communications Security (CCS’14).
[3] Ionut Arghire. 2019. Patches for Internet Explorer Zero-Day Causing Problems
for Many Users. https://www.securityweek.com/patches-internet-explorer-zero-
day-causing-problems-many-users.
[4] Jeffrey Avery and Eugene H. Spafford. 2017. Ghost Patches: Fake Patches for
Fake Vulnerabilities. In Proceedings of the 32nd International Conference on ICT
Systems Security and Privacy Protection (IFIP SEC’17).
[5] Ulrich Bayer, Paolo Milani Comparetti, Clemens Hlauschek, Christopher Kruegel,
and Engin Kirda. 2009. Scalable, Behavior-Based Malware Clustering. In Pro-
ceedings of the 16th Annual Network and Distributed System Security Symposium
(NDSS’09).
[6] Tim Blazytko, Moritz Schlögel, Cornelius Aschermann, Ali Abbasi, Joel Frank,
Simon Wörner, and Thorsten Holz. 2020. AURORA: Statistical Crash Analysis
for Automated Root Cause Explanation. In Proceedings of 29th USENIX Security
Symposium (USENIX Security’20).
[7] Martial Bourquin, Andy King, and Edward Robbins. 2013. BinSlayer: Accurate
Comparison of Binary Executables. In Proceedings of the 2nd ACM SIGPLAN
Program Protection and Reverse Engineering Workshop (PPREW’13).
[8] David Brumley, Pongsin Poosankam, Dawn Song, and Jiang Zheng. 2008. Auto-
matic Patch-Based Exploit Generation is Possible: Techniques and Implications.
In Proceedings of the 29th IEEE Symposium on Security and Privacy (S&P’08).
[9] Juan Caballero, Heng Yin, Zhenkai Liang, and Dawn Song. 2007. Polyglot: Auto-
matic Extraction of Protocol Message Format Using Dynamic Binary Analysis.
In Proceedings of the 14th ACM Conference on Computer and Communications
Security (CCS’07).
[10] Hongxu Chen, Yinxing Xue, Yuekang Li, Bihuan Chen, Xiaofei Xie, Xiuheng Wu,
and Yang Liu. 2018. Hawkeye: towards a desired directed grey-box fuzzer. In
Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communications
Security. ACM, 2095–2108.
[11] William D. Clinger. 1998. Proper Tail Recursion and Space Efficiency. In Proceed-
ings of the ACM SIGPLAN 1998 Conference on Programming Language Design and
Implementation (PLDI’98).
[12] Paolo Milani Comparetti, Guido Salvaneschi, Engin Kirda, Clemens Kolbitsch,
Christopher Kruegel, and Stefano Zanero. 2010. Identifying Dormant Functional-
ity in Malware Programs. In Proceedings of the 31st IEEE Symposium on Security
and Privacy (S&P’10).
[13] Bart Coppens, Bjorn De Sutter, and Koen De Bosschere. 2013. Protecting Your
Software Updates. IEEE Security & Privacy 11, 2 (March 2013), 47–54.
[14] Manuel Costa, Miguel Castro, Lidong Zhou, Lintao Zhang, and Marcus Peinado.
2007. Bouncer: Securing Software by Blocking Bad Input. In Proceedings of 21st
ACM SIGOPS Symposium on Operating Systems Principles (SOSP’07).
[15] Yaniv David, Nimrod Partush, and Eran Yahav. 2016. Statistical Similarity of
Binaries. In Proceedings of the 37th ACM SIGPLAN Conference on Programming
Language Design and Implementation (PLDI’16).
[16] Yaniv David, Nimrod Partush, and Eran Yahav. 2018. FirmUp: Precise Static Detec-
tion of Common Vulnerabilities in Firmware. In Proceedings of the Twenty-Third
International Conference on Architectural Support for Programming Languages and
Operating Systems (ASPLOS’18).