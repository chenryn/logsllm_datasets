In this example, either of the receive events 5 and 7 in process
P 1 pairs with send events 2 and 3 in process P 0 and so it
is impossible to pair receive event 7 in process P 1 with the
corresponding send event 2 in process P 0.
In the cases discussed above, the problem is that Lamport
clocks count events in the distributed system globally, which
means the clock value depends on multiple nodes. Such
global counting causes logical clocks to increase their values
without regular intervals, which reduces the opportunities for
compression.
C. Tracing Concurrent Interprocedural Control-ﬂow
CADeT can be combined with node-local approaches such
as [27], [9] to diagnose distributed faults. We summarize
one such state-of-the-art local tracing approach called Tiny-
Tracer [9] as we use it in our evaluation. TinyTracer encodes
the interprocedural control-ﬂow of concurrent events in a WSN
before discussing fault case studies. First,
let us consider
the intraprocedural encoding. If there are n acyclic control-
ﬂow paths in a procedure, it can be encoded optimally with
log n bits as an integer from 0 to n − 1. In their seminal
paper, Ball and Larus [39] proposed an algorithm that uses
minimal
instrumentation of the procedure to generate the
optimal encoding at runtime. TinyTracer extends that approach
to generate interprocedural path encoding of all concurrent
events in WSN applications written in nesC for TinyOS, a
widely used WSN operating system. The technique records
the event identiﬁer at the beginning of the event handler and
the encoding of the interprocedural path taken inside the event
handler and an end symbol at the end of the event handler.
The trace generated by the approach would include all the
concurrent events along with the interprocedural path taken in
the order the events occurred.
D. Problem Deﬁnition
Thus in this paper, we address the problem of how to
enhance local control-ﬂow traces such that distributed faults
in WSNs can be diagnosed efﬁciently?
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 07:58:43 UTC from IEEE Xplore.  Restrictions apply. 
P2P0P1112234P2P0112234P1RP2 2  RP1 3  RP1 4 P0SP0 1  SP0 2P1RP2 2 RP1 3  RP1 4 P0SP0 1  SP0 2P1P2P0P1122321P2P0P11223214P0SP0 1  SP0 2P1RP2 2  RP2 3 RP1 4 P0SP0 1  SP0 2P1RP2 2  RP2 3 RP1 4 4P2P0P123415776123P0RP2 4 RP0 5 SP2 6 RP0 7 P1SP1 2  SP1 3III. CADET
We propose a novel efﬁcient decentralized compression-
aware message tracing technique that records message order
correctly and satisﬁes the WSN speciﬁc requirements.
A. Design Rationale
We exploit the following WSN application characteristics.
1) Nodes most commonly communicate with only few
other nodes, usually the neighbors or special nodes such
as cluster heads or a base station. [40], [41]
2) Nodes local control-ﬂow trace can be used to infer
the contents of the message such as type and local
ordering. [9].
3) The common case is that messages are not lost and arrive
in order, though such incidents must be handled.
The key idea of our design is to optimize for the com-
mon case, i.e., when there are no message losses or out-
of-order message arrivals. For the common case, we record
minimal information required to trace a message and ensure
that information is compressible, which means the recorded
information for a message has less variability from previously
recorded information. This is achieved by maintaining some
in-memory state which is periodically recorded into the trace
and serves as local checkpoint. When a message loss or out-of-
order message arrival occurs, we store additional information
to infer it.
There are many advantages of our design. First, our design
allows message sends and receives to be paired for both unicast
and broadcast even in the presence of unreliability. Second,
our design is compression-aware, i.e., it records information
such that
it can be easily compressed. Third, our design
allows lightweight local checkpointing and the checkpoints
store information about the number of messages sent/received
with every node it communicates with. Fourth, our design is
efﬁcient because it uses only one byte sequence numbers as
the sequence numbers are unique to each pair of nodes and
take long time to wrap around.
B. Data Structures
Compression-aware distributed tracing hinges on two key
techniques, namely, address aliasing and per-partner sequence
numbers. We refer to the nodes that communicate with a
particular node as partners of that node. For each partner, a
local alias, which can be encoded in fewer bits compared to the
original address (unique network address), is assigned when
a communication is initiated or received from that partner.
This mapping (one-to-one) from original addresses to aliases
is maintained in an address alias map, AAMap. For each local
alias, we also maintain a pair (last sequence number sent, last
sequence number received) in a partner communication map,
PCMap.
C. Algorithm Description
Algorithm 1 presents our message tracing algorithm.
When a node Q sends a message to a partner P the sender
address Q and the next sequence number are appended to
Algorithm 1 Tracing message sends. AAMap is a map from
partner addresses to local aliases and PCMap a map from
local aliases to respective communication histories. LOOKU-
PAAMAP returns the unicast alias of the message network
address of the destination. If the destination address is not
present, the destination address is added along with the next
available local alias to the AAMap and that alias is returned.
Similarly, LOOKUPAAMAPBCAST returns the broadcast alias
for the network address, which is different from the unicast
alias. LOOKUPPCMAP returns the communication history of
the partner. If the partner alias is not present, it is added
along with the pair (0,0) to the PCMap and the pair (0,0) is
returned indicating no communication history in the map. The
address of the node, the message’s destination address and the
message’s source address are respectively shown as myAddr,
msg.destAddr, and msg.sourceAddr.
1: UPON SEND (msg)
2: if msg.destAddr is not a broadcast address then
3:
4: else
5:
6: end if
7: (lastSentSeq, lastRcvdSeq) ← LOOKUPPCMAP (alias)
8: nextSendSeq ← lastSendSeq + 1
9: APPENDTOMESSAGE (myAddr, nextSendSeq)
10: RECORDTOTRACE (’S’, alias)
11: UPDATEPCMAP (alias, (nextSendSeq, lastRcvdSeq))
alias ← LOOKUPAAMAP (msg.destAddr)
alias ← LOOKUPAAMAPBCAST (myAddr)
1: UPON RECEIVE (msg)
2: if msg.destAddr is not a broadcast address then
alias ← LOOKUPAAMAP (msg.sourceAddr)
3:
4: else
alias ← LOOKUPAAMAPBCAST (msg.sourceAddr)
5:
6: end if
7: (lastSentSeq, lastRcvdSeq) ← LOOKUPPCMAP (alias)
8: expectSeq ← lastRcvdSeq + 1
9: if msg.seq = expectSeq then
10:
11:
12: else if msg.seq > expectSeq then
13:
14:
15: else
16:
17: end if
UPDATEPCMAP (alias, (lastSendSeq, expectSeq))
RECORDTOTRACE (’R’, alias)
UPDATEPCMAP (alias, (lastSendSeq, msg.seq))
RECORDTOTRACE (’R’, alias, msg.seq)
RECORDTOTRACE (’R’, alias, msg.seq)
the message and the send event and the alias for P are
recorded in the trace. Observe that the next sequence number
is not recorded. We update the PCMap with the new sequence
number. Suppose the partner is not present in AAMap, then
an alias for that partner is added to AAMap and the new alias
with pair (0,0) is added to PCMap.
When a node P receives a message from a partner Q
the sequence number received in the message is checked
against the expected sequence number (= last sequence number
received + 1) from the PCMap at P . If the sequence number in
the message is the same as the expected sequence number, then
the receive event and the alias of Q are recorded in the trace.
The PCMap is updated with the expected sequence number
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 07:58:43 UTC from IEEE Xplore.  Restrictions apply. 
(a) Handling out-of-order message arrivals
(b) Handling message loss
(c) Handling trace chunks
Fig. 2. Traces generated by CADeT for the same set of processes and messages in Fig. 1. The red colored entries in trace shows that message loss and
out-of-order message arrivals can be distinguished correctly and message sends and receives can be paired correctly. In Figure 2(c) the local checkpoints are
shown as black square dots on the space-time diagram. The internal data structures are not shown.
indicating that the sequence number has been successfully
received. This is the common case when there are no message
losses or out-of-order message arrivals.
If the sequence number in the message is greater than
expected (some message loss or out-of-order message arrival
happened), then PCMap is updated with the sequence number
of the message as the last sequence number received. If the
sequence number in the message is less than expected (some
old message is arriving late), the PCMap is not updated. In
both the cases of unexpected arrivals, the receive event, the
alias of Q, and the unexpected sequence number are recorded
in the trace. Note that we record the unexpected sequence
number information in the trace to correctly pair messages in
the case of message loss or out-of-order message arrival.
In WSNs, broadcasts to neighbors are not uncommon –
e.g., advertise detection of an intruder to your neighbors. It’s
necessary to handle broadcast to be able to pair sends and
receives correctly. To handle broadcast, we treat each node to
have two addresses, its own address and its own address with a
broadcast marker. Thus, when a broadcast is sent or received,
it is counted separately from the unicast. For example, when a
node P sends a broadcast followed by a unicast to node Q and
assuming no other communication happened in the network,
node Q’s AAMap map will have two entries, one for node P
(unicast receive), and another for node P∗ (broadcast receive)
and it’s PCMap will contain two (0, 1) entries corresponding
to the two messages received from node P . Similarly, node
P will have two entries in AAMap corresponding to node Q
(unicast send) and node P∗ (broadcast send) and it’s PCMap
will contain two (1, 0) entries corresponding to the two sends.
Both the unicast send and the broadcast send of node P can
be correctly paired with their corresponding receives at node
Q as the send and recieve events are counted separately.
Figures 2 shows how CADeT handles out-of-order message
arrivals, message losses and local purging for the scenarios
shown in Figures 1.
D. Proof Sketch
We informally argue the correctness of the algorithm. The
goal of the algorithm is to track the order of message recep-
tions. Because sender-receiver pairs are handled independently
of each other by including sender identiﬁers, it is sufﬁcient
to consider one sender-receiver pair. Assume a sequence of
messages received with respective sequence numbers [i1, i2,
i3, i4,..]. Rather than logging the numbers, an equivalent way
is to log the ﬁrst, then the differences i1, [i2 − i1, i3 − i2,
i4 − i3, ...]. The original order can be trivially reconstructed.
The numbers in the original sequence need not be ordered
which supports out-of-order message reception and message
losses. In our case, the difference between adjacent numbers
in the sequence is commonly 1, which can be exploited by
logging a simple predeﬁned tag rather than the difference
value. Otherwise we log the number itself which is equivalent
to logging the difference as explained above. Since senders use
monotonically increasing per-receiver counters the differences
between subsequent message sends are invariably 1 and se-
quence numbers are unique, allowing for correct pairing. Since
broadcast uses separate counters, the same proof applies.
IV. DISTRIBUTED FAULT CASE STUDIES
With the help of real-world bug case studies, we show
that the distributed control-ﬂow traces generated by CADeT
together with TinyTracer [9] aid in diagnosing complex faults
in distributed protocols proposed for WSNs. First, we present
LEACH [42], a WSN clustering protocol, followed by diag-
nosis of two faults diagnosed in its implementation. Next,
we present diagnosis of faults in WSNs designed as pursuer-
evader networks [8]. Finally, we present diagnosis of two
practical issues in directed diffusion [7], a scalable and robust
communication paradigm for data collection in WSNs. In all
the case studies, we assume the presence of CADeT’s trace of
messages as well as trace of message send and receive events
local control-ﬂow.
A. LEACH
LEACH [42] is a TDMA-based dynamic clustering pro-
tocol. The protocol runs in rounds. A round consists of a
set of TDMA slots. At the beginning of each round, nodes
arrange themselves in clusters and one node in the cluster
acts as a cluster head for a round. For the rest of the round,
the nodes communicate with the base station through their
cluster head. The cluster formation protocol works as follows.
At the beginning of the round, each node elects itself as a
cluster head with some probability. If a node is a cluster head,
it sends an advertisement message out in the next slot. The
nodes that are not cluster heads on receiving the advertisement
messages from multiple nodes, choose the node closest to them
based on the received signal strength as their cluster head and
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 07:58:43 UTC from IEEE Xplore.  Restrictions apply. 
P2P0P1112P2P011123P11121P0P1(P2: 0)R0(P1: 1)R1R1(P0: 0) S0S0P0P1(P2: 0)R0(P1: 1) R12 R11(P0: 0) S0S0P0SP0 1 SP0 2 P1RP2 1  RP1 1 RP1 2 P0SP0 1 SP0 2 P1RP2 1  RP1 2 RP1 1 P2P0P11212P2P0P11212121211P0P1(P2: 0)R0R0 (P1: 1)R12 (P0: 0) S0S0P0P1(P2: 0)R0R0 (P1: 1)R1(P0: 0) S0S0P0SP0 1 SP0 2 P1RP2 1  RP2 2 RP1 2 P0SP0 1 SP0 2 P1RP2 1  RP2 2 RP1 1 P2P0P112211222123P0RP2 1 RP0 1 SP2 2 RP0 2 P1SP1 2  SP1 3P0[(P2: 0) (0: (1,0))] R0 (P0: 1)R1 S0 R1P1[(P1: 0) (0: (1, 0))]S0 S0 send a join message to that chosen node in the next slot. The
cluster head, on receiving the join message, sends a TDMA
schedule message which contains slot allocation information
for the rest of the round, to the nodes within its cluster. The
cluster formation is complete and the nodes use their TDMA
slots to send messages to the base station via the cluster head.
B. Network Congestion in LEACH
1) Fault Description: When we increased the number of
nodes in our simulation to 100, we found that data rate
received at the base station reduced signiﬁcantly. The nodes
entered NO-TDMA-STATE and didn’t participate in sending
data to the clusterhead. The reason was that many nodes were
trying to join a cluster in the same time slot. Due to the
small size of the time slot, Join messages were colliding.
Consequently, only fewer nodes successfully joined clusters.