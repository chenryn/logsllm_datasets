述 runtime.sh 在运行时修改了 docker 的 eth0 IP。其中计算
MAC 地址的算法是：
高可用架构 10
同时我们按照雪球统一的运维规范在运行时修改了容器
Hostname、Hosts、DNS 配置。
在交互上，我们在容器中提供了 sshd，以方便业务同学直接 ssh
方式进入容器进行交互。Docker 原生不提供 /sbin/init 来启动
sshd 这类后台进程的，一个变通的办法是使用带 upstart 的根
操作系统镜像，并将 /sbin/init 以 entrypoint 参数启动，作为
PID=1 的进程，并且严禁各种其他 CMD 参数。这样其他进程就
可以成为 /sbin/init 的子进程并作为后台服务跑起来。
然后跟大家介绍下我们在 docker 周边做的一些运维生态圈。
首先我们对容器做了资源限制。一个容器默认分配的是 4core 8G
标准。CPU 上，我们对 share 这种相对配额方式和 cpuset 这种
静态绑定方式都不满意，而使用了 period + quota 两个参数做动
态绝对配额。
在内存上我们禁用了 swap，原因是当一个服务 OOM 的时候，我
们希望服务会 Fast Fail 并被监控系统捕捉到，而不是使用 swap
硬撑。死了比慢要好，这也是我们大力推进服务化和去状态的原因。
对了，顺便提一下 docker daemon 挂掉，或者升级，我们也是
靠应用层的分布式高可用方案去解决。只要去掉状态，什么都好说。
高可用架构 11
在日志方面，我们以 rw 方式映射了物理机上的一个与 Docker IP
对应的目录到容器的 /persist 目录，并把 /persist/logs 目录软
连接为业务的相对 logs 目录。这样对业务同学而言，直接输出日
志到相对路径即可，并不需要考虑持久化的事宜。这样做也有助于
去掉 docker 的状态，让数据和服务分离。日志收集我们在 java
中使用 logback appender 方式直接输出。对于少数需要 tail -F
收集的，则在物理机上实现。
在监控方面，分成两部分，对于 CPU、Mem、Network、BlkIO
以及进程存活和TCP连接，我们把宿主机的 cgroup 目录以及一
个统一管理的监控脚本映射到容器内部，这个脚本定期采集所需数
据，主动上报到监控服务器端。
对于业务自身的 QPS、Latency 等数据，我们在业务中内嵌相关
的 metrics 库来推送。不在宿主机上使用 docker exec API 采集
的原因是性能太差。据说 docker 1.8 修过了这个 docker exec
的 bug，我们还没有跟进细看。
以上是我们在上半年的一些工作，主要方向是把业务迁移入 docker
中，并做好生态系统。
弹性扩容
大家知道上半年时，股市异常火爆，我们急需对业务进行扩容。而
通过采购硬件实现弹性扩容的，都是耍流氓。雪球活跃度与证券市
场的热度大体成正相关关系，当行情好的时候，业务部门对硬件资
高可用架构 12
源的需求增长是极其陡峭的。在无法容忍硬件采购的长周期后，我
们开始探索私有云+公有云混合部署的架构。我们对本地机房和远
端云机房的流量请求模型做了一些抽象，如下：
我们把服务栈分为接入层、服务层、数据层三层。
第一个阶段，只针对接入层做代理回源，目的可以是借助公有云全
球部署的能力实现全球就近接入。
第二个阶段，我们开始给远端的接入层铺设当地的服务层。演进到
第三个阶段，远端的服务层开始希望直接请求本地数据。
高可用架构 13
这里比较有趣的一点是，如果远端服务是只读逻辑，那么我们只需
要把数据做单向同步即可。
如果要考虑双向同步，也即演进到第四个阶段，也即我们所说的双
活。其中不同机房之间的流量切换可以使用 DNS 做负载均衡，在
雪球我们开发了一套 HTTP DNS 较完美的解决此问题。
目前雪球的混合云架构演进到第三个阶段，也即在公有云上部署了
一定量的只读服务，获得一定程度的弹性能力。在公有云上部署
Docker 最大的难题是不同虚拟机上的 Docker 之间的网络互通问题。
我们与合作厂商进行了一些探索，采用了如下的 Bridge (NAT) 方案。
高可用架构 14
这本质上是一个路由方案。首先虚拟机要部署在同一个 VPC 子网中，
然后在虚拟机上开启 iptables 和 ip_forward 转发，并给每个虚
拟机创建独立的网桥。网桥的网段是独立的 C 段。最后在 VPC
的虚拟路由器上设置对应的目标路由。这个方案的缺点是数据包经
过内核转发有一定的性能损失，同时在网络配置和网段管理上都有
不小的成本。庆幸的是越来越多的云服务商都在将 Docker 的网
络模型进行产品化，例如据我们了解，阿里云就在向 docker 提交
docker machine 的 driver。
除了路由方案外，另一个方案是隧道方案。也即铺设 ovs 之类的
overlay。但是，在公有云上本来底层网络就是一层 overlay，再
铺设一层软件 overlay，性能必然会大打折扣。我们最希望的，还
是公有云自身的 SDN 能够直接支持去 NAT 的 bridge。
当使用 Docker 对服务进行标准化后，我们认为有必要充分发挥
Docker 装箱模型的优势来实现对业务的快速发布能力，同时希望
有一个平台能够屏蔽掉本地机房与远端公有云机房的部署差异，进
而获得跨混合云调度的能力。
于是我们开发了一套发布系统平台，命名为 Rolling，意喻业务
系统如滚雪球般不断向前。 在此之前，雪球有一套使用开源软件
Capistrano 构建的基于 ssh 分发的部署工具，Rolling 平台与其
对比如下：
高可用架构 15
大家可以点开图细看下，Rolling 帮助我们解决了非常多的痛点。
像编译时机、环境干净程度、代码验证、版本控制，等等。Rolling
的上下游系统如下图所示：
高可用架构 16
下面截取了几张 Rolling 平台在部署过程中的几个关键步骤截图：
上图显示了 Rolling 在部署时的第三个步骤：资源选择。目前雪球
仍然是靠人力进行调度配置，接下来会使用自动化的调度工具进行
资源配置，而 Rolling 已经赋予我们这种可能性。在真正开始部署
之后，还有一键暂停、强制回滚、灰度发布的功能。
高可用架构 17
上图显示了某业务在使用 Rolling 部署后的运行状态。
Rolling 平台带来的质变意义有两方面：
其一从运维同学的角度，Rolling 使得我们对服务的调度能力从静
态跃迁为动态。而配合以大力推进的服务去状态化，Rolling 完全
可以发展成为公司内部私有 PaaS 云平台的一款基石产品。
其二从业务同学的角度，其上线时不再是申请几台机器，而是申请
多少计算和存储资源。
理想情况下业务同学甚至可以评估出自己每个 QPS 耗费多少
CPU 和内存，然后 Rolling 平台能够借助调度层计算出匹配的
Docker 容器的数量，进而进行调度和部署。也即从物理机（或虚
拟机）的概念回归到计算和存储资源本身。
未来规划
一方面，我们非常看好公有云弹性的能力，雪球会和合作厂商把公
有云部署 Docker 的网络模型做到更好的产品化，更大程度的屏
蔽底层异构差别。另一方面，我们考虑在资源层引入相对成熟的开
源基础设施，进而为调度层提供自动化的决策依据。■
高可用架构 18
Q&A
Q1：同时维护五类操作系统环境，是不是太多了？
多套环境，是确实有多种需求，很难砍掉。物理机，不用说了，上
面要部署nginx/redis等等。KVM，因为雪球要装一些windows，
来对接券商等传统行业（必须要求windows）。LXC，确实是历史
遗留，不排除切换到物理机，但是目前没有动力。Docker，无状
态服务。PS. 我们实践中，只把无状态的服务放到 Docker 中，有
状态的不会放。
Q2：跨机房的事情如何处理的？
跨机房这块我们在本地机房与公有云之间铺设了专线。目前使用情
况如我跨机房图的第三图所示，也即云端有只读服务。
Q3：公有云和私有云拉专线么，雪球处于哪个阶段？
跨机房这块我们在本地机房与公有云之间铺设了专线。目前使用情
况如我跨机房图的第三图所示，也即云端有只读服务。
Q4：调度参考监控系统的哪些指标？
我们调度目前还没真正做起来，参考的值必然会包括操作系统层面
的指标（CPU/Mem/Network/BlkIO），同时应该会参考业务的指
标（QPS、Latency）等等。
高可用架构 19
Q5：能详细说一下用shell脚本配置如何做，雪球是不是已
经自研一套shell脚本组件来管理配置，代替dockerfile？
shell 脚本（也即capistrano这套基于ssh的发布系统），逻辑上就
是git拉取代码，然后执行编译，然后打包，然后基于不同项目的配置，
scp到不同的目标机上，启动起来。我们并没有替代 dockerfile，
而是简化dockerfile，而且这一步是在构建base镜像时做的。跟
业务部署并没有关系。
Q6：目前雪球有多少个业务（核心的）跑在docker上？
我们的 docker 总体数量大概是1000个左右，其中大约有1/5是
测试、预发布环境的，剩下的800个左右线上。我们总共有40个
左右的业务，有的大，有的小。
Q7：rolling打算开源吗？
最初考虑过这个问题，可能拆除业务逻辑后有机会吧。我个人理解，
在的许多公司一定有能力自行研发一套自己的 Rolling，重要的是
去想清楚它的思想，从代码生产，到上线提供服务，中间到底需要
什么，如何进行标准化，这是我们最受益的。
高可用架构 20
Docker 实战
Docker 在芒果 TV 的实践之路
作者/ 彭哲夫 在这篇文章中，我将和大家分享一下最近几年我做平台的一些思考，
芒果TV平台部核心技术 并介绍一下目前我做的这个基于 Docker 的项目的一些技术细节，
团 队 负 责 人，主 要 负 责
以及为什么我们会那么做。
Docker 和 Redis Cluster
相关的基础设施开发。 前豆
豆瓣时期
瓣App Engine核心主程，
前金山快盘核心主程。在系
我在豆瓣工作的时候，主要是写 Douban App Engine 。大体上
统工程方面经验丰富。彭首
它和 GAE 类似，有自己的 SDK 和服务端的 Runtime。因为是
席，知识丰富，功底深厚，
对内使用，所以在 SDK 和 Runtime 实现细节上，我们并没有像
语言幽默风趣，知乎上、简
GAE 那样做太多的 Mock 来屏蔽一些系统层面的 AP（I 比如重写
书上有不少彭首席的精彩大
作和回复。 OS 库等）。对于一家大部分都是使用 Python 的公司而言，我们
只做了 Python 的 SDK 和 Runtime，我们基于 Virtualenv 这个
工具做了运行时的隔离，使得 App 之间是独立分割的。但是在使
用过程中，我们发现有些运行时的隔离做得并不是很干净，比如说
我们自己在 Runtime 使用了 werkzeug 这个库来实现一些控制逻
辑，然后叠加应用自身 Runtime 的时候可能因为依赖 Flask ，因
此也安装了另一个 werkzeug 库，那么到底用哪个版本，就成了
我们头疼的一个问题。
高可用架构 21
一开始我们考虑修改 CPython 来做这件事，包括一些 sys.path
的黑魔法，但是发现成本太高，同时要小心翼翼的处理依赖和路径
关系，后面就放弃使用这种方法了，采用分割依赖来最小化影响，
尽量使得 Runtime 层叠交集最小。