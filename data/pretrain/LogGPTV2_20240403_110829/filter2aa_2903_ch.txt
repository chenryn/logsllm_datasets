对于软件开发者来说，在几家著名的GPU厂商中，Nvidia算得上最
封闭的。这主要表现在两个方面。首先，不公开GPU的硬件文档，比如
用于编写软件与驱动程序的寄存器信息和指令集等。其次，不提供
Linux版本驱动程序的源代码。这意味着，在Linux系统中使用CUDA技
术和Nvidia GPU时，需要安装以二进制文件为主的Nvidia私有驱动程
序，这会导致Linux内核进入被污染（tainted）状态。比如，在Ubuntu系
统中安装Nvidia的390.12版本驱动程序后，以下是使用dmesg | grep
nvidia命令观察到的不和谐消息。
[    0.923328] nvidia: loading out-of-tree module taints kernel.
[    0.923330] nvidia: module license 'NVIDIA' taints kernel.
[    0.923331] Disabling lock debugging due to kernel taint
Linux内核社区对Nvidia的做法有很多批评意见，Linux内核创始人
Linus先生曾公开指责Nvidia公司，将其称为“独一无二的最糟糕公
司”（the single worst company）。
当然，这种封闭性也增加了本章的写作难度。好在Nvidia的CUDA
工具包（toolkit）中包含了一些有深度的文档，比如CUDA开发者指南
和PTX指令集手册等。如果不特别说明，本章的信息大多都源自这些文
档以及Nvidia公司的技术白皮书。
9.2 微架构
微架构是芯片领域的一个常用术语，它代表芯片内部的基本结构和
根本设计。通常一家芯片设计公司会集中精力设计一套微架构，根据目
标市场封装成不同产品线里的产品。
本节将选取一些有代表性的GPU来认识Nvidia GPU的微架构，目的
是希望读者能对Nvidia GPU硬件有所了解，为后面学习软件模型和调试
设施打下较好的基础，这里仍从G80说起。
9.2.1 G80（特斯拉1.0微架构）
G80内部一共有128个流式处理器（Streaming Processor，SP），每8
个一组，组成一个流式多处理器（Streaming Multiprocessor，SM），每
两个SM组成一个集群，称为纹理处理器集群（Texture/Processor
Cluster，TPC）。换个角度来说，G80内部包含了8个TPC、16个SM和
128个SP，如图9-1所示[6]。
图9-1最下方的方框代表显存（DRAM），其上的ROP代表光栅操
作处理器（Raster Operation Processor），可以直接对显存中的图形数据
做各种位运算。ROP旁边的L2代表二级缓存。ROP和L2上面的横条代表
互联网络，它把所有TPC和其他部件连接起来。
图9-1中央是8个TPC，其上方是三种任务分发器，分别用来分发顶
点任务（处理点、线和三角形），像素任务（处理光栅输出、填充图元
的内部区域），以及通用计算任务。
图9-1中最上方的三个矩形（位于GPU外面）代表通过总线桥接与
系统内存和主CPU的通信。
图9-1 G80结构框图
对G80的宏观架构有个大体了解之后，下面再深入TPC和SM的内
部。图9-2是TPC的内部结构框图，为了节约篇幅，这里将其画为横向布
局。
首先，在每个TPC中，包含两个SM，以及如下共享的设施。
一个SM控制器（SMC）：除了管理SM外，它还负责管理和调度
TPC的其他资源，包括读写内存，访问I/O，以及处理顶点、像素和
几何图形等类型的工作负载。
几何控制器（geometry controller）：负责把软件层使用DX10着色
器定义的顶点处理和几何处理逻辑翻译为SM上的操作，并负责管
理芯片上专门用于存储顶点属性的存储区，根据需要读写或者转发
其中的数据。
纹理单元（texture unit）：负责执行纹理操作，通常以纹理坐标为
输入，输出R、G、B、A这4个分量。
图9-2 TPC和SM的内部结构框图
在每个SM中，除了由8个流处理器组成的SP阵列外，还包含如下共
享的设施。
一级缓存（cache），分为两个部分。一个部分用于缓存代码，称
为指令缓存（I cache）；另一部分用来缓存常量数据，称为常量缓
存（C cache）。
共享内存，后面将讲到的使用__shared__关键字描述的变量会分配
在这里。
两个特殊函数单元（Special Function Unit，SFU），用于支持比较
复杂的计算，比如对数函数、三角函数和平方根函数等，每个SFU
内部包含4个浮点乘法器。
一个多线程指令发射器（MT issuer），用于读取指令，并以并发的
方式发射到SP或者SFU中。
最后再介绍一下SM中最重要的执行单元——SP。在每个SP内，都
包含一个标量乘加（multiply-add）单元，它可以执行基本的浮点运算，
包括加法、乘法和乘加。SP还支持丰富的整数计算、比较和数据转换操
作。
值得说明的是，SP和SFU是独立的，可以各自执行不同的指令，同
时工作，以提高整个SM的处理能力。
9.2.2 GT200（特斯拉2.0微架构）
2008年6月，Nvidia发布了GeForce GTX 280产品，其GPU基于第二
代特斯拉微架构。与其相对，G80所使用的微架构称为第一代特斯拉
（特斯拉1.0）。下面便以GT200为例简要介绍特斯拉2.0微架构。
首先，GT200增加了更多的SP，将其从G80中的128个增加到240
个，但仍然是每8个SP 组成一个SM。其次，把30个SM分成10个集群
（TPC），每个TPC包含3个SM（G80中是两个）。
GT200的其他改进有支持双精度浮、提升纹理处理能力以及更大的
寄存器文件等。
9.2.3 GF100（费米微架构）
2010年3月，Nvidia发布GeForce 400系列GPU产品，其微架构名叫
费米（Fermi）。初期所发布产品的GPU代号名为GF100，代号中的F代
表费米微架构[7]。
与前一代相比，GF100的第一个明显变化是进一步增加SP的数量，
由GT200中的240个增加到512个。SP的名字也改称CUDA核心
（core）。每个SM包含32个CUDA核心，每4个SM组成一个集群，集群
的名字由TPC改称GPC（Graphics Processing Cluster）。GF100中包含4
个GPC，如图9-3所示。
图9-3 GF100结构框图
GF100的最重要技术之一是所谓的二级分布式线程调度器（two-
level distributed thread scheduler）。第一级是指图9-3上方的吉咖线程引
擎，它是芯片级的，负责分发全局工作，把线程块（block）分发给各
个SM。第二级是指SM内部的WARP调度器，它负责把线程以WARP为
单位分发给SM中的执行单元。
在每个SM内部（见图9-4），除了有32个CUDA核心外，还有一些
共享的资源，包括128KB的寄存器文件、64KB大小的共享内存和L1缓
存、4个特殊函数单元（SFU）、16个用于访问内存的LD/ST单元、1个
用于3D应用的PolyMorph引擎、4个纹理处理单元，以及纹理数据缓存
等。
在每个CUDA核心中（见图9-4左侧），包含了浮点单元和整数单
元，分别用于执行对应类型的数学运算。
把特斯拉1.0、2.0微架构和费米微架构相比较，一个明显的变化趋
势是每个集群的SM数量增加，从2到3再到4。每个SM中包含的核心数
量也在不断增加，从8到10再到32。
图9-4 GF100的流式多处理器和CUDA核心框图
9.2.4 GK110（开普勒微架构）
2012年3月，Nvidia发布GeForce 680 2GB显卡，其GPU代号为
GK104，并且基于新的开普勒微架构。这与上一代费米微架构正式发布
刚好相隔两年。一年之后，Nvidia发布GeForce GTX Titan 6GB显卡，其
GPU为GK110，是基于改进版本的开普勒微架构。下面便以GK110为例
来理解开普勒微架构的特征。
开普勒微架构最大的特点是大刀阔斧地对SM扩容，很多单元都翻
倍甚至翻几倍（见表9-1），不仅核心数特别多，其他共享资源也随着
大幅度增加，其数量达到空前的规模，但这个发展方向似乎是错的，因
为从后面一代麦斯威尔微架构开始又把SM做小了。因此可以说，开普
勒微架构中SM的个头是空前绝后的。为了突出它的大个头，Nvidia把这
一代的SM称为SMX。
表9-1 开普勒微架构中SM与费米微架构中SM的比较
每个SM中的模块
GK104/GK110（开普勒微架构）
GF104（费米微架构） 比率
32位CUDA核心
192
48
4:1
特殊函数单元
32
8
4:1
LD/ST单元
32
16
2:1
纹理单元
16
8
2:1
Warp调度器
4
2
2:1
在每个SMX中（见图9-5），有192个32位的CUDA核心，64个双精
度浮点单元，32个特殊函数单元（SFU），32个LD/ST单元，256KB的
寄存器文件，4个Warp调度器，16个纹理单元。
图9-5 GK110的SMX结构框图
在GK110的设计中，SMX的个数为15个，于是总共有2880个32位
CUDA核心。但是因为芯片生产中某些单元可能存在瑕疵，可能禁止对
应的SMX，所以Nvidia的文档中特别注明用户产品中实际的SMX个数可
能是13或者14，CUDA核心数可能是2496或者2688。产品良率方面的因
素应该也是后来又把SM做小的一个原因。
除了重构SM之外，开普勒微架构引入的新技术还有Hyper-Q（工作
队列数提升到32个，以提高内部处理器的利用率），Dynamic
Parallelism（在GPU的算核函数内可以启动新的算核和线程，此前只能
从CPU端启动算核），Grid Management Unit（管理要执行的线程网
格），GPU Boost（与CPU的调频技术类似），GPUDirect（在同一台机
器上的多个GPU之间直接传递数据）。
9.2.5 GM107（麦斯威尔微架构）
2014年2月18日，Nvidia同时发布GeForce GTX 750和GeForce GTX
750 Ti两款显卡产品，它们的GPU都是GM107，基于的微架构名叫麦斯
威尔。
在GTX 750 Ti的白皮书中[8]，副标题特别强调这个产品的设计目标
是追求每瓦特电能所能提供的性能（Designed for Extreme Performance
per Watt）。正文中解释说GM107是为供电有限的移动平台和小型电脑
而设计的，其设计灵魂就是要提高每瓦特的性能（The Soul of Maxwell:
Improving Performance per Watt）。针对这样的目标，Nvidia重新设计了
SM，并给新的SM取了个新的名字，叫SMM。作者认为最后一个M可能
代表Maxwell，也可能有缩小（Mini）之意。
在每个SMM中（见图9-6），把处理器核心划分为4个片区
（block），每个片区包含32个CUDA核心，8个SFU，8个LD/ST单元。
每个片区有自己的指令缓冲区和Warp调度器，以及64KB的寄存器文
件。4个片区加起来，一共有128个CUDA核心，32个SFU。
作者写作本节书稿时所用笔记本电脑中就包含了一个麦斯威尔微架
构的GPU，型号为GM108-A，它有3个SMM，384个CUDA核心，它的
设计功耗（Thermal Design Power）为30W。
9.2.6 GP104（帕斯卡微架构）
2016年5月，Nvidia发布GeForce GTX 1080，一个月后，又发布
GeForce GTX 1070，两款显卡使用的GPU都是GP104，微架构名叫帕斯
卡。
GP104的SM结构与上一代麦斯威尔SM的结构非常类似，在每个SM
中，分4个片区配置128个32位的CUDA核心，每个片区配备8个SFU和8
个LD/ST单元。
不同的是，在GP104中（见图9-7），SM的个数大大增多，共有20
个，每5个SM组成一个图形处理集群（GPC）。在整个GPU中，一共有
4个GPC，20个SM，2560个32位CUDA核心，以及160个纹理处理单元
（每个SM包含8个纹理处理单元）。
图9-6 GM107（麦斯威尔微架构）的SMM结构框图
图9-7 GP104（帕斯卡微架构）的结构框图
帕斯卡微架构中，另一项值得关注的功能是把GPU的多任务调度支
持提升到一个新的水平。当执行图形任务时，可以在像素级别暂停当前
任务，当执行计算任务时，可以在指令级别暂停当前任务，二者分别称
为“像素级别的图形任务抢先”（Pixel-Level Graphics Preemption）和“指
令级别的计算任务抢先”（Instruction-Level Compute Preemption）[9]。
9.2.7 GV100（伏特微架构）
2017年5月，Nvidia对外宣布了基于新一代伏特微架构的GV100
GPU，同时宣布了基于该GPU的首款显卡产品特斯拉V100。
GV100的主要变化体现在两个方面，一方面是进一步优化SM内部