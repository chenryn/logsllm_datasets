所谓的“当前栈”，指的是ESP的值所在的栈空间。如果ESP的值位于用户栈的范围内，
那么程序的当前栈就是用户栈，反之亦然。此外，寄存器SS的值还应该指向当前栈所在的
页。所以，将当前栈由用户栈切换为内核栈的实际行为就是：
（1）保存当前的 ESP、SS的值。
（2）将ESP、SS的值设置为内核栈的相应值。
反过来，将当前栈由内核栈切换为用户栈的实际行为则是：
（1）恢复原来ESP、SS的值。
（2）用户态的ESP和SS的值保存在哪里呢？答案是内核栈上。这一行为由i386的中
程序员的自我修养—链接、装载与库
---
## Page 417
394
第12章系统调用与API
断指令自动地由硬件完成。
当0x80号中断发生的时候，CPU除了切入内核态之外，还会自动完成下列儿件事：
（1）找到当前进程的内核栈（每一个进程都有自己的内核栈）。
（2）在内核栈中依次压入用户态的寄存器SS、ESP、EFLAGS、CS、EIP。
而当内核从系统调用中返回的时候，须要调用iret指令来回到用户态，iret指令则会从
内核栈里弹出寄存器SS、ESP、EFLAGS、CS、EIP的值，使得栈恢复到用户态的状态，这
个过程可以用图12-4来表示。
内核栈
iret
4
用户栈
SS
ESP
由i自动填充
或邮ret恢复
EFLAGS
CS
EIP
+ esp
55 e
图12-4中断时用户栈和内核栈切换
3.中断处理程序
在int指令合理地切换了栈之后，程序的流程就切换到了中断向量表中记录的0x80号中
新处理程序。Linux内部的i386中断服务流程如图12-5所示。
中路间
硬件驱
图12-5Linux i386中断服务流程
程序员的自我修养一链接、装载与库
---
## Page 418
12.2系统调用原理
395
i386的中断向量表在Linux 源代码的Linux/arch/i386/kermel/traps.e里可见一部分。在该
文件的末尾，我们能看到一个函数trap_init，该函数用于初始化中断向量表：
void init trap_init (void)
.....
set_trap_gate (0, &divide_error) :
set_intr_gate (1,&debug1 :
set_systen_intr_gate (3, &int3) :
set_intr_gate (2,&nmi1 ;
set_system_gate (5, &bounds) ;
set_system_gate(4, &overflow) ;
set_trap_gate (6,&invalid_op) ;
set_trap_gate (7, &device_not_available) :
set_ta8k_gate (8, GDT_ENTRY_DOUBLEFAULT_TSS) :
set_trap_gate (10, 6invalid_rss) :
set_trap_gate (11, &segment_not_present) :
set_trap_gate (13, &genera1_protect ion) :
get_trap_gate(15,&spurious_interrupt_bug) ;
set_intr_gate (14, &page_fault) ;
set_trap_gate(17,&alignment_check);
set_trap_gate (16,&coprocessor_error) :
#ifdef CONFIG_X86_MCE
tendif
set_trap_gate (18, &machine_check) ;
set_trap_gate (19, &sind_coprocessor_error) 1
set_Bystem_gate (SYsCALL_VEcToR, &systen_ca11) :
......
以上代码中的函数 set_intr_gate/set_trap_gate/set_system_gate/ set_system_int_gate 用于
设置某个中断号上的中断处理程序。之所以区分为3种名字，是因为在i386下对中断有更
加细致的划分，限于篇幅这里就不详细介绍了，读者在这里可以暂时将它们都等同对待。
从这段代码可以看到0~19号中断对应的中断处理程序，其中包含算数异常（除零、溢
出）、页缺失（page fault）、无效指令等。在最后一行：
set_sy8tem_gate (SYSCALL_VECTOR, &system_ca11) :
可看出这是系统调用对应的中断号，在Linux/include/asm-i386/mach-default/irq_vectors.h里
可以找到SYSCALL_VECTOR的定义：
#define SYSCALL_VECTOROx80
可见i386下Linux的系统调用对应的中断号确实是0x80。必然的，用户调用int0x80
之后，最终执行的函数是system_call，该函数在Linux/arch/i386/kemelentry.S里可以找到定
义。但很遗憾，这段代码是由汇编写成并且篇幅较长，因此必须一段一段选择性地研究：
程序员的自我修养一—链接、装载与库
---
## Page 419
396
第12章系统调用与API
main -> fork -> int 0x80 -> system_ca11:
ENTRY (systen_ca11)
SAVE_ALL
cnp1 S (nr_8ysca11s) , 8eax
jae sysca11_badsys
这一段是 system_call的开头，中间省略了一些不太重要的代码。在这里一开始使用宏
SAVE_ALL将各种寄存器压入栈中，以免它们的值被后续执行的代码所覆盖。然后接下来
使用cmpl指令比较eax和nr_syscalls 的值，nr_syscalls 是比最大的有效系统调用号人1的值，
因此，如果cax（即用户传入的系统调用号）大于等于nr_syscalls，那么这个系统调用就是
无效的，如果这样，接着就会跳转到后面的 syscall_badsys 执行。如果系统调用号是有效的，
那么程序就会执行下面的代码：
sysca11_ca11:
ca11 *sys_ca11_table(0, $eax, 4)
RESTORE_RBGS
iret.
确定系统调用号有效并且保存了寄存器之后，接下米要执行的就是调用*sys_call_table
（0.%eax,4）来查找中断服务程序并执行。执行结束之后，使用宏RESTORE_REGS来恢复之
前被SAVE_ALL保存的寄存器。最后通过指令iret从中断处理程序中返回。
能找到定义：
,data
ENTRY (ays_ca11_table)
[t0osAs"xe?sex"sAs 5uo*
,1ong sy8_exit
.long sys_fork
,Long sys_read
,1ong sy8_write
+ ++.+. *
这就是Linux的i386系统调用表，这个表里的每一个元素（long，4字节）都是-个系
统调用函数的地址。那么不难推知*sys_call_table(0,%eax,4）指的是sys_call_table 上偏移最为
0+%eax*4上的那个元素的值指向的函数，也就是%eax所记录的系统调用号所对应的系统
调用函数（见图12-6）。接下来系统就会去调用相应的系统调用函数。例如，如果%eax=2，
那么sys_fork就会调用。
内核里的系统调用函数往往以sys_加上系统调用函数名来命名，例如sys_fork、
sys_open 等。
程序员的自我修养—链接、装载与库
---
## Page 420
12.2系统调用原理
397
整个调用过程如图12-6所示。
pid_t fork()
Int main()
call*sys_cal_table(0,%eax,4)
system_callt
08x0 1UI
sys_fork(
tork();
栈切换
ret
iret
图12-6Linux系统调用流程
08A
Q：内核里以sys开头的系统调用函数是如何从用户那里获得参数的？
A：我们如道用户调用系统调用时，根据系统调用参数数量的不同，依次将参数放入EBX、
ECX、EDX、ESI、EDI和EBP这6个等存器中传递。例如一个参数的系统调用就是
用EBX，而两个参数的系统调用就使用EBX和ECX，以此类推。
在进入系统调用的服务程序system_call的时候，system_call 调用了一个宏 SAVE_ALL
来保存各个等存器，由于篇幅原因我们没有在正文中仔细讲解SAVE_ALL。不过
SAVE_ALL实际与系统调用的参数传递息息相关，所以有必要在这里提一下。
SAVE_ALL的作用为保存寄存器，因此其内容就是将各个寄存器压入栈中。SAVE_ALL
的大致内容如下：
define SAVE_ALL \
push teax
dqos qend
push %ed1
push %edx
push %esi
push
%ecx
push %ebx
mov $ (KERNEL_DS) ,Bedx
mov ledx, $ds
mov ledx, tes
抛开SAVE_ALL的最后3个mov指令不看（达3条指令用于设置内核数据段，它们不
影响栈），我们可以发现SAVE_ALL的一系列push指令的最后6条所压入栈中的等存
器恰好就是用来存效系统调用参数的6个等存器，连顺序都一样，这当然不是一个巧
合。
再回到system_call的代码，我们可以发现，在执行SAVE_ALL与执行call
*sys_call_table(0,%eax,4）之间，没有任何代码会影响到栈。因此期刚进入sys开头的内
核系统调用函数的时候，栈上恰好是这祥的情景，如图12-7所示。
程序员的自我修养一链接、装载与库
---
## Page 421
398
第12章系统调用与API
ebp
edi
e8i
edx
ecx
ebx
Retum Address
图12-7系统调用时堆栈分布
可以说，系统调用的参数被SAVE_ALL“阴差阳错”地放置在了栈上。
另一方面，所有以sys开头的内核系统调用函数，都有一个asmlinkage 的标识，例如：
asmlinkage pid_t sys_fork(void);
asmlinkage 是一个宏，定义为：_attribute_（(regparm(0))
这个扩展关键字的意义是让这个函数只从栈上获取参数。固为gCC对普通函数有优化
措施，会使用寄存器来传递参数，而SAVE_ALL将参数全部放置于栈上，因此必须使
用asmlinkage来强迫函数从栈上获取参数。这样一来，内核里的系统调用函数就可以
正确地获取用户提供的参数了。整个过程可以用图12-8表示。
资存器
EBXECX
EDX
ESI
EDI
EBP
放置在这里
SAVE_ALL拒离存器保存在这里
用户的参数数据
EBP
EDI
ESI
EDX
Ss系列内核系统调用函数
ECX
EBX
退网地址
图12-8Linux系统调用中如网向内核传递参数
程序员的自我修养一
链接、装载与库
---
## Page 422
12.2系统调用原理
399
12.2.3Linux的新型系统调用机制
由于基于int指令的系统调用在奔腾4代处理器上性能不佳，Linux在2.5版本起开始支
门针对系统调用的指令—sysenter和sysexit。在本节中，我们将对这种新系统调用机制进
行一个初步的了解。
如果使用Idd来获取一个可执行文件的共享库的依赖情况，你会发现一些奇怪的现象：
$ 1dd /bin/ls
linux-gate.8o.1=>(0xffffe000)
librt,8o.1 => /1ib/t1s/i686/cmov/1ibrt,so.1 (0xb7f7a000)
libacl.so.1 =>/1ib/1ibacl.so.1 (0xb7f74000)
1ibc.80.6 => /1ib/t1s/i686/cmov/1ibc.80.6 (0xb7e2d000)
1ibpthread.8o.0 => /1ib/t1s/i686/cmov/1ibpthread.so.0 (0xb7e1b000)
/1ib/1d-1inux.so.2(0xb7f97000)
1ibattr.so.1 *>/1ib/1ibattr.8o.1 (0xb7e17000)
1ibdl.8o.2 => /1ib/t1s/i686/cnov/1ibdl.so.2 (0xb7e13000)
1ibsepol.8o.1 => /1ib/1ibsepol.so.1 (0xb7dd2000)
我们可以看到inux-gate.so.1没有与任何实际的文件相对应，这个共享库在前面分析
Linux共享库的时候也与它碰过面，但是当时没有深入地分析它。那么这个库究竞是做什么
的呢？答案正是Linux用于支持新型系统调用的“虚拟”共享库。linux-gate.so.1并不存在
实际的文件，它只是操作系统生成的一个虚拟动态共享库（VirtualDynamicSharedLibrary，
VDSO）。这个库总是被加载在地址0xfffe000的位置上。我们可以通过Linux的proc文件
系统来查看一个可执行程序的内存映像，看看能不能找到这个虚拟文件：
$ cat /proc/self/naps
08048000-0804c000 r-xp 00000000 08:01 13271
/bin/cat
0804c000-0804d000 rα-p 00003000 08:01 13271
/bin/cat
ffffe000-fffffoo0r-xp0oo000co 0o:000