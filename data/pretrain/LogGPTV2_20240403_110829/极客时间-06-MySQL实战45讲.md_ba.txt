# QPS 突增问题有时候由于业务突然出现高峰，或者应用程序 bug，导致某个语句的 QPS突然暴涨，也可能导致 MySQL 压力过大，影响服务。我之前碰到过一类情况，是由一个新功能的 bug导致的。当然，最理想的情况是让业务把这个功能下掉，服务自然就会恢复。而下掉一个功能，如果从数据库端处理的话，对应于不同的背景，有不同的方法可用。我这里再和你展开说明一下。1.  一种是由全新业务的 bug 导致的。假设你的 DB    运维是比较规范的，也就是说白名单是一个个加的。这种情况下，如果你能够确定业务方会下掉这个功能，只是时间上没那么快，那么就可以从数据库端直接把白名单去掉。2.  如果这个新功能使用的是单独的数据库用户，可以用管理员账号把这个用户删掉，然后断开现有连接。这样，这个新功能的连接不成功，由它引发的    QPS 就会变成 0。3.  如果这个新增的功能跟主体功能是部署在一起的，那么我们只能通过处理语句来限制。这时，我们可以使用上面提到的查询重写功能，把压力最大的    SQL 语句直接重写成\"select 1\"返回。当然，这个操作的风险很高，需要你特别细致。它可能存在两个副作用：1.  如果别的功能里面也用到了这个 SQL 语句模板，会有误伤；2.  很多业务并不是靠这一个语句就能完成逻辑的，所以如果单独把这一个语句以    select 1 的结果返回的话，可能会导致后面的业务逻辑一起失败。所以，方案 3是用于止血的，跟前面提到的去掉权限验证一样，应该是你所有选项里优先级最低的一个方案。同时你会发现，其实方案 1 和 2都要依赖于规范的运维体系：虚拟化、白名单机制、业务账号分离。由此可见，更多的准备，往往意味着更稳定的系统。
# 小结今天这篇文章，我以业务高峰期的性能问题为背景，和你介绍了一些紧急处理的手段。这些处理手段中，既包括了粗暴地拒绝连接和断开连接，也有通过重写语句来绕过一些坑的方法；既有临时的高危方案，也有未雨绸缪的、相对安全的预案。在实际开发中，我们也要尽量避免一些低效的方法，比如避免大量地使用短连接。同时，如果你做业务开发的话，要知道，连接异常断开是常有的事，你的代码里要有正确地重连并重试的机制。DBA虽然可以通过语句重写来暂时处理问题，但是这本身是一个风险高的操作，做好SQL 审计可以减少需要这类操作的机会。其实，你可以看得出来，在这篇文章中我提到的解决方法主要集中在 server层。在下一篇文章中，我会继续和你讨论一些跟 InnoDB 有关的处理方法。最后，又到了我们的思考题时间了。今天，我留给你的课后问题是，你是否碰到过，在业务高峰期需要临时救火的场景？你又是怎么处理的呢？你可以把你的经历和经验写在留言区，我会在下一篇文章的末尾选取有趣的评论跟大家一起分享和分析。感谢你的收听，也欢迎你把这篇文章分享给更多的朋友一起阅读。
# 上期问题时间前两期我给你留的问题是，下面这个图的执行序列中，为什么 session B 的insert 语句会被堵住。![](Images/f19315a2cda76213f86f4e7d56b9a246.png){savepage-src="https://static001.geekbang.org/resource/image/3a/1e/3a7578e104612a188a2d574eaa3bd81e.png"}\我们用上一篇的加锁规则来分析一下，看看 session A 的 select语句加了哪些锁：1.  由于是 order by c desc，第一个要定位的是索引 c 上"最右边的"c=20    的行，所以会加上间隙锁 (20,25) 和 next-key lock (15,20\]。2.  在索引 c 上向左遍历，要扫描到 c=10 才停下来，所以 next-key lock    会加到 (5,10\]，这正是阻塞 session B 的 insert 语句的原因。3.  在扫描过程中，c=20、c=15、c=10 这三行都存在值，由于是 select    \*，所以会在主键 id 上加三个行锁。因此，session A 的 select 语句锁的范围就是：1.  索引 c 上 (5, 25)；2.  主键索引上 id=15、20 两个行锁。这里，我再啰嗦下，你会发现我在文章中，每次加锁都会说明是加在"哪个索引上"的。因为，锁就是加在索引上的，这是InnoDB 的一个基础设定，需要你在分析问题的时候要一直记得。评论区留言点赞板：> \@HuaMax 给出了正确的解释。> \@Justin 同学提了个好问题，\ 到底是间隙锁还是行锁？其实，这个问题，你要跟"执行过程"配合起来分析。在> InnoDB> 要去找"第一个值"的时候，是按照等值去找的，用的是等值判断的规则；找到第一个值以后，要在索引内找"下一个值"，对应于我们规则中说的范围查找。> \@信信> 提了一个不错的问题，要知道最终的加锁是根据实际执行情况来的。所以，如果一个> select \* from ... for update> 语句，优化器决定使用全表扫描，那么就会把主键索引上 next-key lock> 全加上。> \@nero> 同学的问题，提示我需要提醒大家注意，"有行"才会加行锁。如果查询条件没有命中行，那就加> next-key lock。当然，等值判断的时候，需要加上优化> 2（即：索引上的等值查询，向右遍历时且最后一个值不满足等值条件的时候，next-key> lock 退化为间隙锁。）。> \@小李子、@发条橙子同学，都提了很好的问题，这期高质量评论很多，你也都可以去看看。最后，我要为元旦期间还坚持学习的同学们，点个赞 \^\_\^![](Images/48edcb93fb03e3e52d7e7099be6b5cb3.png){savepage-src="https://static001.geekbang.org/resource/image/09/77/09c1073f99cf71d2fb162a716b5fa577.jpg"}
# 23 \| MySQL是怎么保证数据不丢的？今天这篇文章，我会继续和你介绍在业务高峰期临时提升性能的方法。从文章标题"MySQL是怎么保证数据不丢的？"，你就可以看出来，今天我和你介绍的方法，跟数据的可靠性有关。在专栏前面文章和答疑篇中，我都着重介绍了 WAL 机制（你可以再回顾下[第 2篇](https://time.geekbang.org/column/article/68633)、[第 9篇](https://time.geekbang.org/column/article/70848)、[第 12篇](https://time.geekbang.org/column/article/71806)和[第 15篇](https://time.geekbang.org/column/article/73161)文章中的相关内容），得到的结论是：只要redo log 和 binlog 保证持久化到磁盘，就能确保 MySQL异常重启后，数据可以恢复。评论区有同学又继续追问，redo log 的写入流程是怎么样的，如何保证 redo log真实地写入了磁盘。那么今天，我们就再一起看看 MySQL 写入 binlog 和 redolog 的流程。
# binlog 的写入机制其实，binlog 的写入逻辑比较简单：事务执行过程中，先把日志写到 binlogcache，事务提交的时候，再把 binlog cache 写到 binlog 文件中。一个事务的 binlog是不能被拆开的，因此不论这个事务多大，也要确保一次性写入。这就涉及到了binlog cache 的保存问题。系统给 binlog cache 分配了一片内存，每个线程一个，参数 binlog_cache_size用于控制单个线程内 binlog cache所占内存的大小。如果超过了这个参数规定的大小，就要暂存到磁盘。``{=html}事务提交的时候，执行器把 binlog cache 里的完整事务写入到 binlog中，并清空 binlog cache。状态如图 1 所示。![](Images/eb7ecb6b95a39cb26661f8f6b282407c.png){savepage-src="https://static001.geekbang.org/resource/image/9e/3e/9ed86644d5f39efb0efec595abb92e3e.png"}```{=html}```图 1 binlog 写盘状态]{.reference}```{=html}```可以看到，每个线程有自己 binlog cache，但是共用同一份 binlog 文件。-   图中的 write，指的就是指把日志写入到文件系统的 page    cache，并没有把数据持久化到磁盘，所以速度比较快。-   图中的 fsync，才是将数据持久化到磁盘的操作。一般情况下，我们认为    fsync 才占磁盘的 IOPS。write 和 fsync 的时机，是由参数 sync_binlog 控制的：1.  sync_binlog=0 的时候，表示每次提交事务都只 write，不 fsync；2.  sync_binlog=1 的时候，表示每次提交事务都会执行 fsync；3.  sync_binlog=N(N\>1) 的时候，表示每次提交事务都 write，但累积 N    个事务后才 fsync。因此，在出现 IO 瓶颈的场景里，将 sync_binlog设置成一个比较大的值，可以提升性能。在实际的业务场景中，考虑到丢失日志量的可控性，一般不建议将这个参数设成0，比较常见的是将其设置为 100\~1000 中的某个数值。但是，将 sync_binlog 设置为N，对应的风险是：如果主机发生异常重启，会丢失最近 N 个事务的 binlog日志。