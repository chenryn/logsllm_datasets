phases can be further optimized by leveraging more sophisti-
cated static analysis. For example, if it is certain that the original
code already nullifies a pointer, DANGNULL would not need
to nullify it again. Although we have not heavily explored this
direction, this has to be done carefully because soundly learning
this information involves pointer-aliasing problems, which are
well-known difficult problems in program analyses, and any
incorrect analysis results would lead to both false positives and
false negatives.
Moreover, we identified that manipulation of shadowObjTree
is the main performance bottleneck, and this can be optimized
by 1) leveraging transactional memory [20] to enhance locking
performance on shadowObjTree; 2) designing a software cache
for shadowObjTree; 3) using alternative data-structures to imple-
ment shadowObjTree (e.g., alignment-based metadata storage by
replacing the memory allocator [18]); or 4) creating a dedicated
analyzing thread or process for shadowObjTree [23].
False negatives. DANGNULL’s static instrumentation
assumes that a pointer is propagated only if either the left–
or right–hand side of a variable is a pointer type. This would
not be true if the program is written in a manner such that
the propagation is done between non-pointer-typed variables.
Consider the example we introduced in Example 1. If the child
member variable is typed as long (i.e., long child at line 4)
and all the following operations regarding child are using type
casting (i.e., doc->child=(long)body at line 13 and ((Elem*)doc-
>child)->getAlign() at line 21), then such a pointer propagation
would not be traced. DANGNULL would under-trace object
relationships in this case, and there would be false negatives if
child becomes an unsafe dangling pointer.
False positives. To stop dereferencing on unsafe dangling
pointers, DANGNULL nullifies not only unsafe dangling point-
ers but also benign dangling pointers. This implies DANGNULL
additionally nullifies benign dangling pointers, and it is possible
it may cause some false positives, although these should not
have any semantic meaning as they are “dangled”.
While testing DANGNULL for SPEC CPU benchmarks and
the Chromium browser, we found one rare false positive case.
This false positive case sporadically occurs when a new tab
is manually created inside the Chromium browser, and it is
related to the unique pointer hash table design (Example 4).
We believe this false positive example would not be a critical
concern for deploying DANGNULL due to its rareness. As we
described in the compatibility evaluation in §V-D, DANGNULL
passed more than 30,000 stress tests with the Chromium
browser, a large scale and highly complicated application.
VII. RELATED WORK
Memory-related issues, including invalid memory accesses,
memory leaks, and use-after-free bugs, have been studied for
many years. Numerous methods have been proposed for C/C++
12
1 enum child_status {IN_USE=0, DELETED=1};
2 hash_map  allChilds;
3
4 Document *doc = new Document();
5 Element *elem = new Element();
6
7 // hold child reference
8 doc->child = elem;
9
10 // mark it as in-use in the hash_map
11 allChilds[elem] = IN_USE;
12
13 // delete child, nullified accordingly
14 delete doc->child;
15
16 // doc->child is nullified,
17 //
18 allChilds[doc->child] = DELETED;
19
20 // makes sure all childs are deleted
21 for (it = allChilds.begin(); it != allChilds.end(); ++ it)
22
23
but Chromium relies on the stale pointer
if (it->second == IN_USE)
delete it->first;
Example 4: A simplified false positive example of DANGNULL
in the Chromium browser. This sporadically occurred when
the tab is manually created inside the browser. If applications
rely on the stale pointer (using the freed pointer as a concrete
value, as doc→child in line 18), DANGNULL can cause a false
positive. We fixed this issue for DANGNULL by switching the
order of deletion and marking operations (switching line 14
and line 18).
programs. In this section, we categorize them and compare
them with DANGNULL.
Use-after-free detectors. There is a line of research
specifically focusing on detecting use-after-free vulnerabilities.
In general, use-after-free vulnerabilities can be detected through
both static and dynamic analysis. However, since 1) a dangling
pointer itself is not erroneous behavior and 2) statically
determining whether a dangling pointer will actually be used in
the future requires precise points-to and reachability analyses
across all possible inter-procedure paths, even state-of-the-art
use-after-free detection tools based on the static analysis are
only suitable for analyzing small programs [13, 34].
For this reason, most use-after-free detectors [6, 30, 48] are
based on the runtime dynamic analysis. CETS [30] maintains a
unique identifier with each allocated object, associates this
metadata with pointers, and checks that the object is still
allocated on pointer dereferences. To handle pointer arithmetic,
CETS uses taint propagation (i.e., the resulting pointer will
inherit the metadata from the base pointer of the corresponding
arithmetic operation). Unfortunately, the assumption behind
this design choice —the propagated pointer should point to
the same object—does not always hold, which results in high
false positive rates. From our experiments, CETS raised false
alarms on 5 out of 16 tested programs while DANGNULL was
able to correctly run all 16 programs. In addition to high false
positive rates, CETS relies on explicit checks to guarantee
the memory access validity for all memory operations, thus
imposing higher performance overhead in SPEC CPU2006
compared to DANGNULL. For 4 programs (bzip2, milc, sjeng,
h264ref, and lbm) that CETS was able to run7, on average it
incurred 40% slow down, while DANGNULL incurred 1% slow
7CETS failed to compile 7 programs out of 16 SPEC CPU2006 programs
we tested.
13
down.
Undangle [6] is another runtime dynamic analysis tool to
detect use-after-free. It assigns each return value of memory
allocation functions a unique label, and employs a dynamic
taint analysis to track the propagation of these labels. On
memory deallocation, Undangle checks which memory slots
are still associated with the corresponding label, and then
determines the unsafe dangling pointers based on the lifetime
of dangling pointers (i.e., if the lifetime of a dangling pointer is
higher than the certain threshold number, it is identified as an
unsafe dangling pointer). While this approach can collect more
complete pointer propagation information than DANGNULL
(which would better help a bug triage or debugging process),
a significant performance cost is required.
Control flow integrity. Control flow integrity (CFI) [1, 49–
51] enforces indirect function calls to be legitimate (i.e., enforc-
ing integrity of the control-flows). Similarly, SafeDispatch [22]
prevents illegal control flows from virtual function call sites. Un-
like use-after-free and memory error detectors, CFI makes use-
after-free vulnerabilities difficult to exploit. Specifically, CFI
only shepherds function pointers to guarantee legitimate control
flows. In practice, however, most CFI implementations enforce
coarse-grained CFI to avoid heavy performance overheads
and false positive alarms, but recent research [7, 11, 15, 16]
has demonstrated that all the aforementioned coarse-grained
CFI implementations can be bypassed. Moreover, dangling
pointers can also be abused to corrupt non-control data (e.g.,
vector length variables, user privilege bits, or sandbox enforcing
flags) in objects [8], all of which are not function pointers,
which makes CFI based protection techniques bypassable. For
example, a recent attack [27] overwrote user permission bits in
the metadata to bypass user authorizations, including all other
defense mechanisms. As an another example, vector length
variable corruption is one popular technique to exploit use-after-
free vulnerabilities that lead to information leakage attacks or
additional heap buffer overflows.
DANGNULL eliminates dangling pointers at the moment
they are created. Thus, it can protect not only control flows but
also any other security sensitive metadata in the objects from
being abused by use-after-free or double-free vulnerabilities.
Memory error detectors. Memcheck (Valgrind) [32] and
Purify [19] are popular solutions for detecting memory errors.
Since their main goal is to help debugging, they are designed
to be complete (incurring no false negatives) and general
(detecting all classes of memory problems) in identifying
memory-leak vulnerabilities, imposing very high memory and
CPU overheads.
AddressSanitizer [38] is another popular tool developed
recently that optimizes the method of representing and probing
the status of allocated memory. However, due to an assumption
to support this optimization (a quarantine zone that prevents
reuse of previously freed memory blocks), it cannot detect
use-after-free bugs if the assumption does not hold (i.e.,
heap objects are reallocated). Specifically, attackers can easily
leverage various techniques to force reallocation of previously
freed memory blocks, such as Heap Spraying [10, 36] and
Heap Fengshui [39]. To clearly demonstrate this issue, we
developed a proof-of-concept exploit bypassing the detection of
AddressSanitizer (Example 5). However, with DANGNULL, all
drainBuffer = null;
gc();
}
// allocate/fill up the landing zone
var landBuffer = new Uint32Array(44);
for (var j = 0; j 
dangling pointers will be nullified upon the deallocation of their
objects, rendering use-after-free vulnerabilities unexploitable,
even with sophisticated manipulations.
Safe memory allocators. Many safe memory allocators
have been proposed to prevent dangling pointer issues. Cling [2]
can disrupt a large class of exploits targeting use-after-free
vulnerabilities by restricting memory reuse to objects of the
same type. Diehard and Dieharder [4, 33] mitigate dangling
pointer issues by approximating an infinite-sized heap.
Smart pointers. A smart pointer is an abstract data
type that encapsulates a pointer to support automatic resource
management. Theoretically, an application would not suffer
from use-after-free issues if all the pointers are represented with
smart pointers (i.e., no raw pointers are used in the application
code). However, it is common to expose raw pointers even in
applications heavily using smart pointers. For example, in order
to break the resource graph cycle connected with shared pointers
(e.g., std::shared_ptr in C++11), browser rendering engines
including WebKit [45] and Blink [5] usually expose a raw
pointer instead of using weak pointers (e.g., std::weak_ptr in
C++11) to avoid extra performance overheads and be compatible
with legacy code [26], and these exposed raw pointers have
been major use-after-free vulnerability sources for those engines.
14
Note that automatically wrapping raw pointers with smart
pointers is another challenging static analysis problem, as this
requires understanding precise raw pointer semantics to be
properly implemented.
VIII. CONCLUSIONS
In this paper, we presented DANGNULL, a system that
detects temporal memory safety violations in runtime. We
implemented DANGNULL, applied it to Chromium, and con-
ducted a thorough evaluation showing the effectiveness and
compatibility of DANGNULL. In particular, we demonstrated
that DANGNULL can be applied to complex,
large-scale
software, such as the Chromium browser, to effectively mitigate
use-after-free exploits with even the most sophisticated attack
techniques. We believe DANGNULL can be used for a range of
security applications: back-end use-after-free detection, runtime
use-after-free mitigation, or use-after-free resilient programs.
ACKNOWLEDGMENTS
The authors would like to thank the anonymous reviewers
and our shepherd, Juan Caballero, for their help and feedback,
as well as our operations staff for their proofreading efforts.
This material is based upon work supported in part by the
National Science Foundation under Grants No. CNS-1017265,
CNS-0831300, and CNS-1149051, by the Office of Naval
Research under Grant No. N000140911042, by the Department
of Homeland Security under contract No. N66001-12-C-0133,
and by the United States Air Force under Contract No.
FA8650-10-C-7025. Any opinions, findings, and conclusions
or recommendations expressed in this material are those of
the authors and do not necessarily reflect the views of the
National Science Foundation, the Office of Naval Research, the
Department of Homeland Security, or the United States Air
Force.
REFERENCES
[1] M. Abadi, M. Budiu, U. Erlingsson, and J. Ligatti, “Control-flow
integrity,” in ACM Conference on Computer and Communications
Security (CCS), 2005.
[2] P. Akritidis, “Cling: A Memory Allocator to Mitigate Dangling
Pointers,” in USENIX Security Symposium (Security), 2010.
[3] Alexa, “The Top 500 Sites on the Web,” http://www.alexa.com/
topsites, Aug 2014.
[4] E. D. Berger and B. G. Zorn, “DieHard: Probabilistic Memory
Safety for Unsafe Languages,” in ACM SIGPLAN Conference
on Programming Language Design and Implementation (PLDI),
2006.
[5] Blink : the rendering engine used by Chromium, http://www.
chromium.org/blink, Aug 2014.
[6] J. Caballero, G. Grieco, M. Marron, and A. Nappa, “Undangle:
Early Detection of Dangling Pointers in Use-after-free and
Double-free Vulnerabilities,” in International Symposium on
Software Testing and Analysis (ISSTA), 2012.
[7] N. Carlini and D. Wagner, “ROP is still dangerous: Breaking
modern defenses,” in USENIX Security Symposium (Security),
2014.
[8] S. Chen, J. Xu, E. C. Sezer, P. Gauriar, and R. K. Iyer, “Non-
control-data Attacks Are Realistic Threats,” in USENIX Security
Symposium (Security), 2005.
[9] Chromium Projects, “Running Tests at Home,” http://www.
chromium.org/developers/testing/running-tests, Aug 2014.
[10] M. Daniel, J. Honoroff, and C. Miller, “Engineering Heap
Overflow Exploits with JavaScript,” in USENIX Workshop on
Offensive Technologies (WOOT), 2008.
[11] L. Davi, D. Lehmann, A.-R. Sadeghi, and F. Monrose, “Stitching
the Gadgets: On the Ineffectiveness of Coarse-Grained Control-
Flow Integrity Protection,” in USENIX Security Symposium
(Security), 2014.
[12] D. Dhurjati and V. Adve, “Efficiently Detecting All Dangling
Pointer Uses in Production Servers,” in International Conference
on Dependable Systems and Networks (DSN), 2006.
[13] J. Feist, L. Mounier, and M.-L. Potet, “Statically detecting use
after free on binary code,” Journal of Computer Virology and
Hacking Techniques, 2013.
[14] Flak, “Analysis of OpenSSL Freelist Reuse,” http://www.
tedunangst.com/flak/post/analysis-of-openssl-freelist-reuse, Aug
2014.
[15] E. Göktas, E. Athanasopoulos, H. Bos, and G. Portokalidis,
“Out of control: Overcoming Control-Flow Integrity,” in IEEE
Symposium on Security and Privacy (Oakland), 2014.
[16] E. Gökta¸s, E. Athanasopoulos, M. Polychronakis, H. Bos, and
G. Portokalidis, “Size does matter: Why using gadget-chain
length to prevent code-reuse attacks is hard,” in USENIX Security
Symposium (Security), 2014.
[17] Google, “Octane Benchmark,” https://code.google.com/p/octane-
benchmark, Aug 2014.
[18] Google, “Specialized memory allocator for ThreadSanitizer,
http://llvm.org/klaus/compiler-
MemorySanitizer,
rt/blob/7385f8b8b8723064910cf9737dc929e90aeac548/lib/
sanitizer_common/sanitizer_allocator.h, Nov 2014.
etc.”
[19] R. Hastings and B. Joyce, “Purify: Fast detection of memory
leaks and access errors,” in Winter 1992 USENIX Conference,
1991.
[20] M. Herlihy and J. E. B. Moss, Transactional memory: Architec-
tural support for lock-free data structures. ACM, 1993, vol. 21,
no. 2.
[21] HP, “Pwn2Own 2014: A recap,” http://www.pwn2own.com/2014/
03/pwn2own-2014-recap, Aug 2014.
[22] D. Jang, Z. Tatlock, and S. Lerner, “SafeDispatch: Securing C++
Virtual Calls from Memory Corruption Attacks,” in Network and
Distributed System Security Symposium (NDSS), 2014.
[23] K. Jee, V. P. Kemerlis, A. D. Keromytis, and G. Portokalidis,
“ShadowReplica: efficient parallelization of dynamic data flow
tracking,” in ACM Conference on Computer and Communications
Security (CCS), 2013.
[24] LLVM Project, “LLVM Language Reference Manual,” http://
llvm.org/docs/LangRef.html.
[25] F. Long, S. Sidiroglou-Douskos, and M. Rinard, “Automatic
Runtime Error Repair and Containment via Recovery Shepherd-
ing,” in ACM SIGPLAN Conference on Programming Language
Design and Implementation (PLDI), 2012.
[26] Mads Ager, Erik Corry, Vyachslav Egorov, Kentaro Hara, Gustav
Wibling, Ian Zerny, “Oilpan: Tracing Garbage Collection for
Blink,” http://www.chromium.org/blink/blink-gc, Aug 2014.
[27] Mallocat,
“Subverting without EIP,” http://mallocat.com/
subverting-without-eip, Aug 2014.
[28] Mozilla, “DROMAEO, JavaScript Performance Testing,” http:
//dromaeo.com, Aug 2014.
[29] S. Nagaraju, C. Craioveanu, E. Florio, and M. Miller, “Software
Vulnerability Exploitation Trends,” Microsoft, 2013.
15
[30] S. Nagarakatte, J. Zhao, M. M. K. Martin, and S. Zdancewic,
“CETS: Compiler Enforced Temporal Safety for C,” in Interna-
tional Symposium on Memory Management (ISMM), 2010.
[31] S. Nagarakatte, J. Zhao, M. M. Martin, and S. Zdancewic,
“SoftBound: Highly Compatible and Complete Spatial Memory
Safety for C,” in ACM SIGPLAN Conference on Programming
Language Design and Implementation (PLDI), 2009.
[32] N. Nethercote and J. Seward, “Valgrind: A Framework for
Heavyweight Dynamic Binary Instrumentation,” in ACM SIG-
PLAN Conference on Programming Language Design and
Implementation (PLDI), 2007, pp. 89–100.
[33] G. Novark and E. D. Berger, “DieHarder: Securing the Heap,”
in ACM Conference on Computer and Communications Security
(CCS), 2010.
[34] H. Post and W. Küchlin, “Integrated static analysis for linux de-
vice driver verification,” in Integrated Formal Methods. Springer,
2007, pp. 518–537.
[35] M. Prandini and M. Ramilli, “Return-oriented programming,”
IEEE Security & Privacy, 2012.
[36] P. Ratanaworabhan, B. Livshits, and B. Zorn, “NOZZLE: A
Defense Against Heap-spraying Code Injection Attacks,” in
USENIX Security Symposium (Security), 2009.
[37] R. Seacord, Secure Coding in C and C++, 1st ed. Addison-
Wesley Professional, 2005.
[38] K. Serebryany, D. Bruening, A. Potapenko, and D. Vyukov,
“AddressSanitizer: A Fast Address Sanity Checker,” in USENIX
Conference on Annual Technical Conference (ATC), 2012.
[39] A. Sotirov, “Heap Feng Shui in JavaScript,” Black Hat Europe,
2007.
[40] Standard Performance Evaluation Corporation, “SPEC CPU
2006,” http://www.spec.org/cpu2006, Aug 2014.
[41] The Chromium Project, http://www.chromium.org/Home, Aug
2014.
[42] The Chromium Projects, “Chromium Issues,” https://code.google.
com/p/chromium/issues, Aug 2014.
[43] The LLVM Compiler Infrastructure, http://llvm.org, Aug 2014.
[44] The Web Standards Project, “Acid Tests,” http://www.acidtests.
org/, Aug 2014.
[45] The WebKit Open Source Project, http://www.webkit.org, Aug
2014.
[46] Ubuntu, “0-address protection in Ubuntu,” https://wiki.ubuntu.
com/Security/Features#null-mmap, Aug 2014.
[47] WebKit, “SunSpider 1.0.2 JavaScript Benchmark,” https://www.
webkit.org/perf/sunspider/sunspider.html, Aug 2014.
[48] W. Xu, D. C. DuVarney, and R. Sekar, “An efficient and
backwards-compatible transformation to ensure memory safety
of C programs,” in ACM SIGSOFT International Symposium on
Foundations of Software Engineering (FSE), 2004.
[49] B. Zeng, G. Tan, and G. Morrisett, “Combining Control-flow
Integrity and Static Analysis for Efficient and Validated Data
Sandboxing,” in ACM Conference on Computer and Communi-
cations Security (CCS), 2011.
[50] C. Zhang, T. Wei, Z. Chen, L. Duan, L. Szekeres, S. McCamant,
D. Song, and W. Zou, “Practical Control Flow Integrity and
Randomization for Binary Executables,” in IEEE Symposium on
Security and Privacy (Oakland), 2013.
[51] M. Zhang and R. Sekar, “Control Flow Integrity for COTS
Binaries,” in USENIX Security Symposium (Security), 2013.