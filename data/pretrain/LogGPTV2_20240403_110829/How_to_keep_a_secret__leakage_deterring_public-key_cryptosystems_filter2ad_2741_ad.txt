the same random tape but a diﬀerent random oracle. Using
these two forgeries that are correlated, one can extract the
secret key of the owner.
Our construction of leakage-deterring signature is based
on two independent digital signatures instances Sig0 and
Sig1 that are unforgeable under adaptively chosen message
attacks. Further, Sig1 is required to be unforgeable in the
random oracle(RO) model following [29]; speciﬁcally, the sig-
nature has the form of (m, σ1, h, σ2) as in [29], and satisﬁes
h = H(m, σ1), and σ2 only depends on m, σ1, h, where H is
a RO. We call the following construction Scheme-V.
• KeyGen(1λ): This algorithm executes the KeyGen
algorithm of Sig0, and returns the key pair (pk0, sk0).
• EnKey(O, A): This protocol is executed between O, A
with inputs (pk0, sk0, s), and (pk0, s) respectively. A
runs KeyGen algorithm of Sig1 to generate a key
pair (pk1, sk1). The protocol terminates with O ob-
taining (epk, esk), and A obtaining epk, where epk =
(pk0, pk1, H(sk1) ⊕ s), and esk = (sk0, sk1).
• Sign(esk, m): On input a message m, this algorithm
returns the signature σ = (σ0, σ1), where it holds σ0 =
1, h1, σ2
Sign0(sk0, m), and σ1 = Sign1(sk1, m) = (σ1
1).
• Verify(epk, m, σ): On input a message-signature pair
(m, σ) and enhanced public key epk = (pk, pk(cid:48)), this
algorithm returns 1 if both of the two signatures are
valid, 0 otherwise.
1, h1, σ2
• RecD(epk, B, δ): The recovering algorithm follows the
security proof argument of [29]: Whenever the box B
asks a random oracle query (suppose total number of
such queries is bounded by q), the algorithm selects a
uniform response from the range of the random oracle
and feeds it to the box; it also maintains a table of
all these queries. The recovering algorithm samples a
message m according to D and simulates the box B
on m. When the box outputs a valid signature σ0, σ1,
where σ1 = (σ1
1), algorithm checks the table
and identiﬁes the index i of the ﬁrst query from B on
(m, σ1
1). Then, it rewinds B to the state prior to the
i-th query, and continues the simulation picking new
random query responses.
The above procedure is repeated until the box outputs
another valid signature (σ(cid:48)
0, σ(cid:48)
1) on the same message
m, where σ(cid:48)
1, σ(cid:48)
2), and also the index i that
1) was queried is the same for both σ1 and σ(cid:48)
(m, σ1
1.
Refer to the appendix for a more formal explanation
of knowledge extraction.
Now the algorithm can extract the second secret key
sk1 from (m, σ1
2) using the Σ pro-
tocol properties of the scheme that deﬁne Sig1. The
recovery of s follows immediately.
1), (m, σ1
1, h, σ(cid:48)
1 = (σ1
1, h(cid:48)
1, h1, σ2
Security Analysis: We now analyze the three properties.
It is easy to see that unforgeability against adaptively chosen
message attacks can be derived from the property of Sig0
as any forgery will imply also a forgery of Sig0. Note that
signing queries are easy to simulate because the simulator
has the secret key for Sig1, and can ask signing queries to
the challenger for Sig0. Privacy w.r.t. a secret-key oracle
for any distribution can be achieved because any successful
privacy attacker will have to eventually query sk1 to the ran-
dom oracle hence violating the unforgeability of Sig1. Note
that recoverability cannot violate privacy w.r.t. an arbitrary
secret key oracle, since it is achieved now via a non-black-
box technique. It uses the fact that rewinding the signing
box and controlling the random coins in an execution, one
can always ﬁnd a pair of signatures that reveal the secret
key, something that yields the private data. Details of the
analysis are in the full version.
4.2 Leakage-deterring Identiﬁcation
We will construct a leakage-deterring identiﬁcation scheme
by using a similar approach as in the signature case. How-
ever here we will show our construction secure in the stan-
dard model, and thus we need a novel method to embed the
owner private data into the enhanced public key. In fact we
will need no additional assumption beyond the one employed
for the underlying scheme.
Our construction of a leakage-deterring identiﬁcation scheme
is based on the class of identiﬁcation schemes which are
derived from zero-knowledge proofs of knowledge protocols
that can be parallely composed. We utilize the fact that
given access to the code of any box that implements the
identiﬁcation functionality, one can rewind the box and im-
plement the knowledge extractor assured to exist due to the
soundness property of the zero-knowledge proof. We call the
following construction Scheme-VI and is based on a param-
eter t that we specify below.
950• KeyGen(1λ): This algorithm executes the KeyGen
algorithm of the underlying identiﬁcation scheme, and
returns the key pair (pk, sk).
• EnKey(O, A): This is a protocol executed between
O, A with inputs (pk, sk, s), and (pk, s) respectively. A
runs KeyGen algorithm to generate t new key pairs
(pk1, sk1), . . . , (pkt, skt), and further, A calculates s(cid:48) =
r ⊕ s, where r = Ext(sk1|| . . .||skt, ρ) and Ext is a
strong randomness extractor (see below for implemen-
tation remarks) while ρ is the random seed. The proto-
col terminates with O obtaining (epk, esk), and A ob-
taining epk, where epk = (pk, pk1, . . . , pkt, s(cid:48), ρ), and
esk = (sk, sk1, . . . , skt).
• Identify(P, V ): This protocol is executed between P, V
with inputs (epk, esk), and epk respectively. The pro-
tocol is the parallel composition of the t + 1 underlying
identiﬁcation schemes. The protocol terminates with
V outputting 1 if he accepts the proof of knowledge of
all secret keys, and 0 otherwise.
• Rec(epk, B): The algorithm given B, runs the knowl-
edge extractor algorithm for the parallel composition
of the t schemes until all the secret keys of {sk1, . . . , skt}
are recovered. Then it applies the randomness extrac-
tor on ρ and returns s = s(cid:48) ⊕ Ext(sk1|| . . .||skt, ρ)
Security Analysis: We now analyze the security proper-
ties. Recoverability is essentially the same as the recover-
ability of Scheme-V. Impersonation resistance is also similar
to the unforgeability property of Scheme-IV; this property
mainly relies on the fact that nothing related to the original
secret key of the owner sk is added to the epk, therefore the
security of identiﬁcation using the original (pk, sk) can be
reduced to the impersonation resistance of Scheme-V. Re-
garding privacy, according to impersonation resistance, af-
ter seeing a polynomial number of transcripts of interaction
between P, V , there is still unpredicatability on the secret
key, (otherwise, one can impersonate by eavesdropping) then
applying the strong extractor one can get pure randomness
out of the secret-keys, and thus the owner data is hidden
computationally. Details are given in the full version.
Remark1: The strong randomness extractor Ext should work
on any source with suﬃcient conditional unpredictability
along the lines of [19]. For instance, we can use the extractor
derived from the Goldreich-Levin hard-core predicate [12].
Intuitively, one can think of the view (protocol transcripts
adaptively queried) of the adversary as the output of a one
way function on input {ski}. Using this, [12] implies an ex-
tractor of log λ bits per instance and thus t should be as long
as |s|/ log λ.
Remark2: If one is willing to allow additional intractabil-
ity assumptions, a more compact construction for leakage-
deterring signature (in the RO model) and leakage-deterring
identiﬁcation is also possible4. The construction would uti-
lize two key pairs (pk0, sk0), (pk1, sk1) and the secret infor-
mation will be embedded as E(pk1, s), thus only sk1 will be
used by the recoverability algorithm. Observe now that pri-
vacy will rely on the security of the encryption scheme (and
thus may require assumptions going beyond the underlying
identiﬁcation scheme). Furthermore reusing the same key
for signing and decrypting may not always be secure and
4We thank an anonymous reviewer for pointing this out.
Scheme Ciphertext/Signature Size Enc/Sign Time
I
III
V
1
O(log 1
δ )
2
1
O(log 1
δ )
2
Table 1: Eﬃciency of main leakage-deterring (LD)
schemes, the size and time denote the ratio of the
LD-scheme to the underlying primitive.
some specialized systems would need to be employed, for
instance cf. [18].
5. LEAKAGE-DETERRING CRYPTOSYSTEMS
IN PRACTICE
In this section we ﬁrst summarize the eﬃciency of our
main constructions of leakage-deterring public key primi-
tives in Table 5. Then we explore in more detail practi-
cal scenarios where leakage-deterring cryptosystems can be
used to provide novel solutions to security problems related
to sharing and transferring cryptographic functions.
Let us start with a more detailed motivating scenario:
consider a user that maintains all her e-mail encrypted on
a mailserver. The user is approached by someone wishing
to buy all e-mails sent by the e-mail address x@y in the
past, present and future. Using a regular encryption, the
user may release to the attacker an implementation of her
decryption function that works only if the plaintext is an
e-mail sent by x@y (and rejects all other input). If the user
does not care about the secrecy of the e-mails from x@y, she
has no strong reason to be deterred from releasing the im-
plementation (all her other messages can still be relatively
safe assuming the implementation is suﬃciently obfuscated
or delivered in hardware). Using our encryption however,
she is deterred:
if she releases the above implementation
(even in the form of a hardware token) an adverse action is
guaranteed to take place (via the recoverability algorithm):
her private information will be revealed. Obviously, a de-
termined secret-key owner can always decrypt and release
the plaintexts corresponding to those e-mails individually.
But this has to be done one by one, at a potentially high
cost. In this scenario, leakage-deterring public-key encryp-
tion ensures there is no way to optimize this operation:
if
one wants to provide access to his decryption he has to do it
on a “per-case” basis. Within a PKI this enforces secret-key
owners to practice more responsible secret-key management.
to secret key oracles (that would
be the CCA ﬂavor of our privacy property) and recover-
ability can not be achieved simultaneously in the general
case: the two properties are mutually exclusive. Thus, one
needs to choose a proper trade-oﬀ if he wants to implement
leakage-deterring public key schemes. Regarding PKE, our
objective in this work is to maximize the scope of recov-
erability:
it should work for all (even partially functional)
implementations; this makes our primitive most useful from
a self-enforcement perspective and necessitates the restric-
tions we have made in terms of the privacy property. If the
user wishes the private information to remain hidden, she
should provide no access to her secret-key. In the case of
signature/identiﬁcation schemes the situation is more tricky
since by nature of the functionality, the user is expected to
release signatures/identiﬁcation transcripts publicly (which
Recall privacy w.r.t.
951in some cases they may even be adaptively selected). Thus,
we must compromise and weaken our recoverability property
in some way. We resolved this by adopting a non-black-box
recoverability algorithm. As expected, if the implementation
becomes “obfuscated” then recoverability would be infeasi-
ble. We believe the trade-oﬀs we utilized are natural for
the primitives studied, but of course diﬀerent tradeoﬀs can
be possible between privacy and recoverability, and we leave
them as future work.
Depending on diﬀerent application scenarios, we can em-
bed various types of private owner information to deter the
leakage of a cryptographic functionality:
Self-enforcement. In the context of self-enforcement the
owner of the cryptographic functionality has embedded into
her enhanced public-key some private information that she
normally prefers to keep secret. This can be e.g., her credit-
card number or similar piece of private information as sug-
gested by Dwork, Lotspiech and Naor [9] that introduced
self-enforcement (in a diﬀerent context - see related work
in the introduction). In this way, when using our leakage-
deterring primitives, if the owner releases any implementa-
tion of the cryptographic functionality, any recipient of the
implementation will become privy to the hidden informa-
tion. This property “self-enforces” the owner to keep the
functionality to herself and solves the problem of how to
deter the sharing of software or hardware devices that im-
plement cryptographic functionalities.
All-or-nothing sharing of cryptographic functions.
In this scenario, the owner is obliged to embed the secret
key of the cryptographic primitive itself into the enhanced
public-key (in practice this can be done e.g., by a trusted key
generator algorithm which will be running the embedding al-
gorithm that is executed by the authority in our model). Us-
ing our techniques this means that any working implementa-
tion of the cryptographic functionality would leak the whole
secret-key. In this sense, the cryptographic functionality be-
comes “unobfuscatable”, any program that partially imple-
ments it, say for some types of inputs, can be transformed to
a program that implements it perfectly. Leakage-deterring
primitives used in this way suggest a type of all-or-nothing
property for cryptographic keys: owners of a cryptographic
functionality cannot partially share it, they either have to
keep it to themselves or share it fully. In practice, one can
expect that this is also a type of self-enforcing mechanism:
either all information about the cryptographic key will be
leaked or none.
Anonymity revocation from implementations. In this
setting, the owner of the cryptographic functionality oper-
ates it under a pseudonym (i.e., the enhanced public-key is
certiﬁed but without openly identifying the owner). How-
ever, the embedded information is ensured by the author-
ity to be either the owner’s real identity or an identity cre-
dential that the owner prefers to hide. In this setting, us-
ing our methodology, if any working implementation of the
functionality is conﬁscated, it will be possible to use the
recovering algorithm to reveal the hidden identity creden-
tial. This in turn, ensures some level of accountability: the
owner remains pseudonymous as long as he does not share
the cryptographic functionality but can be identiﬁed in case
any (even partially working) implementation is leaked.
6. CONCLUSIONS AND OPEN PROBLEMS
We introduced the notion of leakage-deterring cryptosys-
tems. Our schemes have the property that whenever an
owner releases an (even partially) “functional” box for oth-
ers to use instead of herself, anyone who has access to the
box can recover some private information that is embedded
into the public-key of the owner. We deﬁned the security
properties of these primitives and we provided several con-
structions for public key encryption, signatures, and identi-
ﬁcation.
Since this is the ﬁrst step in the formal investigation of
such primitives, several interesting open questions remain.
A natural question is how to combine the notion with traitor
tracing and other multi-user oriented cryptosystems. An-
other direction is with respect to CCA2 security: our con-
struction can potentially be optimized for eﬃciency and
avoid the nesting of two encryptions. A third direction is to
see to what extent it is feasible to construct leakage-deterring
signatures and identiﬁcation with black-box recoverability in
the standard model or more generally explore the tradeoﬀ
between recoverability and privacy. Last but not least, it
would be desirable to see how the trust to the authority can
be reduced (and e.g., obviate the need for the authority to
know the secret information).
Acknowledgements.