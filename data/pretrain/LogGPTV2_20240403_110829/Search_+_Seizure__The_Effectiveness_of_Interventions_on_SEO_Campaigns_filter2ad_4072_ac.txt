### 4.1.2 Crawling Search Results

For each search term, we query Google daily to retrieve the top 100 search results. For each result, we crawl the page using an updated version of the Dagger cloaking detection system from previous work [35]. Dagger employs heuristics to detect cloaking by comparing the content fetched as a user and as a search engine crawler (distinguished by the User-Agent field in the HTTP request).

A previous limitation of Dagger was its inability to render pages and follow JavaScript (JS) redirects. To address this, we extended Dagger by rendering each detected cloaked search result using HtmlUnit [13], a headless browser with a JavaScript interpreter. This enhancement allows us to follow JS redirects, but due to the computational cost, we only render pages that are detected as cloaked.

To detect iframe cloaking (Section 3.1.1), we developed a second crawler, VanGogh, which also uses HtmlUnit for rendering. VanGogh identifies iframes that attempt to occupy the entire page visually, thereby hiding the original content. Specifically, we classify pages as using iframe cloaking if they load iframes with height and width attributes set to 100% or larger than 800 pixels.

Due to the high overhead of rendering, we limit the number of pages crawled by VanGogh. For each measurement, we randomly select and crawl at most three pages from the same doorway domain. Additionally, we avoid crawling domains previously seen and not detected as poisoned by either VanGogh or Dagger. This approach is effective given the low daily churn in search results (on average, 1.84% of newly seen domains appear in search results each day).

### 4.1.3 Store Detection

Our ultimate goal is to identify counterfeit luxury storefronts advertised through Poisoned Search Results (PSRs). We detect these stores by applying two heuristics to the set of PSRs discovered during crawling. First, we inspect cookies on each landing site (the final page loaded in the user's browser after redirection) for cookies commonly used by counterfeit luxury storefronts, such as those related to payment processing (e.g., Realypay, Mallpayment), e-commerce (e.g., Zen Cart, Magento), and web analytics (e.g., Ajstat, CNZZ). Second, we search for the substrings "cart" or "checkout" on the landing pages. If either heuristic succeeds, we classify the landing site as a counterfeit luxury store advertised through search poisoning.

We validated our detection methodology by manually inspecting sampled search results from three popular verticals: Beats By Dre, Isabel, and Louis Vuitton. For each vertical, we randomly selected three search terms and compared the search results from two measurements taken at least two months apart (e.g., one from November 23, 2013, and one from February 24, 2014). In total, we examined 1,800 search results and detected 532 storefronts advertised using cloaked search results. Our validation found no false positives and 21 (1.2%) false negatives, indicating that our method is reliable and underrepresents the number of storefronts minimally.

### 4.2 Campaign Identification

Our targeted crawls of Google search results yield a large collection of doorway pages and counterfeit storefronts. We aim to understand the full ecosystem of SEO campaigns operating in the counterfeit luxury market rather than focusing on a single campaign, such as the KEY campaign.

A brute-force approach would require a domain expert to examine each web page and use domain-specific heuristics to infer the SEO campaign behind it. However, manual labeling is time-consuming and does not scale well to the thousands of examples in our collection. Instead, we take a statistical approach, described below, to automatically identify the SEO campaigns behind individual doorway and storefront web pages.

To build a statistical model, we created a labeled dataset by identifying the SEO campaigns behind a small subset of 491 web pages. From this dataset, we learned a classifier that mapped the remaining thousands of doorway and storefront web pages to 52 SEO campaigns. The results of this analysis provide a comprehensive understanding of the SEO campaign ecosystem in the counterfeit luxury market.

### 4.2.1 Feature Extraction

Our statistical approach assumes that doorway and storefront web pages contain predictive signatures of the SEO campaigns behind them. Motivated by previous work [2], we looked for these signatures in the HTML source code. We expect HTML-based features to be predictive because SEO campaigns use specialized strategies to manipulate search rankings and often develop in-house templates for large-scale deployment of online storefronts.

To extract HTML features, we use a conventional "bag-of-words" approach. We construct a dictionary of all terms that appear in the HTML source code and count the occurrences of each term for each web page. Each web page is represented as a sparse, high-dimensional vector of feature counts. We implemented a custom bag-of-words feature extractor based on tag-attribute-value triplets [5] for the web pages in our dataset.

While network-based features (e.g., IPv4 address blocks, ASes) might also be predictive, we found them ill-suited due to the growing popularity of shared hosting and reverse proxying infrastructure (e.g., CloudFlare). Therefore, we did not pursue the use of such features.

### 4.2.2 Model Estimation

We used the LIBLINEAR package [7] to learn L1-regularized models of logistic regression from our labeled dataset. The L1-regularization encourages sparse linear models, making the predictions highly interpretable. For each campaign, the regularization identifies the most strongly characteristic HTML features from the tens of thousands extracted.

We evaluated the predictive accuracy of the classifier using 10-fold cross-validation on the labeled dataset. The average accuracy for multi-way classification into 52 different SEO campaigns was 86.8%. This high accuracy gave us confidence to classify the remaining unlabeled web pages.

### 4.2.3 Model Validation and Refinement

We used the trained models to infer the SEO campaigns behind the remaining unlabeled web pages. We extracted HTML features from the unlabeled pages and used the classifiers to predict the most likely campaign. To validate these predictions, we manually inspected additional subsets of unlabeled examples, focusing on the top-ranked predictions for each SEO campaign.

We validated the classifier's predictions by checking for distinct infrastructure such as SEO doorway pages, C&Cs, payment processing, and customer support. We also considered less robust indicators like unique templates, WHOIS registrant, image hosting, and web traffic analytics (e.g., 51.la, cnzz.com, statcounter.com).

The final stage involves refining the model by using the manually verified predictions to expand the set of labeled web pages, retraining the classifier, and repeating this process iteratively. This human-machine interaction approach is far more efficient than a brute-force expert analysis.

### 4.3 Purchases

From previous work studying email spam advertising illicit pharmaceutical and software storefronts [16, 20], we found that making orders on sites can reveal normally opaque aspects of underground businesses, such as order volume, payment processing, and order fulfillment. This information serves two roles: it reveals the interplay between various actors in the counterfeit luxury ecosystem (SEO campaigns, payment processors, and suppliers) and provides a metric to measure the effectiveness of interventions.

Similar to prior work, we created test orders on counterfeit stores to estimate their order volume over time and made actual purchases to reveal the payment processors and the quality of the merchandise.

### 4.3.1 Order Volume

We used the "purchase pair" technique [16] to estimate the order volume of individual stores over time. This technique exploits the fact that stores use monotonically increasing order numbers, where the difference between order numbers represents the total number of orders created over the time delta between orders.

Using this technique, we created 1,408 orders from 290 stores, touching 24 distinct campaigns and 13 verticals, between November 29, 2013, and July 15, 2014. We created 343 orders manually and 1,065 orders using scripts. Operationally, we visit each store via TOR, create orders at weekly intervals, and limit orders to three per day per campaign to reduce detection risk. We take the orders to the payment processing page before leaving the site. The order and customer information provided are semantically consistent but fictional and automatically generated [6].

### 4.3.2 Transactions

To shed light on payment processing and order fulfillment, we successfully placed product orders from 16 unique stores covering 12 different campaigns. We received 12 knock-offs of low to medium quality, all shipped from China. From the bank identification numbers (BINs) in our transactions, we found that our purchases were processed through three banks (two in China, one in Korea). This concentration suggests that payment processing is a viable area for interventions, though further investigation is needed.

### 4.4 User Traffic

As surveyed in Section 2 and described in our previous study [36], SEO campaigns poison search results to acquire user traffic, which is then monetized through scams, such as counterfeit luxury stores. The order volume data shows that these stores successfully convert user traffic into sales, indirectly measuring an SEO campaign's effectiveness in attracting traffic via PSRs.

For a small number of stores, we collected AWStats data, which directly measures an SEO campaign's effectiveness in attracting customers. AWStats is a web analytics tool [1] that uses server logs to report aggregated visitor information. We discovered that some stores left their AWStats pages publicly accessible, allowing us to fetch visitor data for 647 storefronts in 12 campaigns.

### 4.5 Supply Side Shipments

To better understand the operational relationships among storefronts and suppliers, we collected longitudinal shipment data from a supplier partnering with MSVALIDATE, one of the largest SEO campaigns peddling counterfeit Louis Vuitton. We discovered the supplier site from the packing slip of two of our purchases. The site contains a scrolling list of fulfilled orders and a mechanism to look up shipping records in bulk (20 orders at a time).

Using this mechanism, we collected over 279,000 shipping records for nine months of orders placed through the supplier between July 5, 2013, and March 28, 2014. In summary, 256,000 orders successfully reached their destination, 4,000 were seized at the source (China), 15,000 were seized at the destination, and 1,319 were returned by the customer. The three largest destinations were the United States, Japan, and Australia, with 90,000, 57,000, and 39,000 orders, respectively. Combined with Western Europe (41,000), these regions account for over 81% of orders.

### 5. Results

In this section, we use our crawler data to characterize the activities of SEO campaigns that use search to promote stores selling counterfeit luxury goods. We also use our order data to study the effects of search engine and domain seizure interventions on these activities. We find that both interventions can disrupt counterfeit sites, but they need to be more reactive and comprehensive to undermine the entire ecosystem of SEO campaigns exploiting search engines for customers.