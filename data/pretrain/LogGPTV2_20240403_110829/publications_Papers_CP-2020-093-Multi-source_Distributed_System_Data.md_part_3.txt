800 400 into the logs with wsgi related modules being the most fre-
quent ones (neutron wsgi, nova.osapi wsgi and server wsgi).
700
700 350 The programname refers to the program which operations
600 are being executed. There are a total of 127654 different
600 300
Payloads happened in the system and the most frequent
500
500 250 is related to the GET operation.
For the realized HTTP calls there is information for the
400 400 200
http statuswith6differentcodevalues,http_method
300 300 150 with 4 possible values (GET, POST, DELETE and PUT),
http_urls with a total of 3655 values and the ver-
200 200 100 sion of the http protocol stored ins http_version.
There are columns such as_domain_id, user_domain,
100 100 50
tenant_id, request_id, user_id, _score, _type,
0 25 50 75 0 1.10 1.15 1.20 0 2.5 5.0 7.5 10.0 project_domain, Pid and domain_id that have either
cpu.user mem.used 1e10 load.min1
very large or very small variance in the number of unique
Fig.2. Distributionofthevaluesofthemetricsfeatureforthenodewally113. values per feature. They represent start and end point in form
of IP address or a result from a hash function.
B. Logs
C. Traces
Since the logs are semi-structured data, first we try to
organize them and observe the range of interesting features Table II represents the total number of services for each of
that can appear in them. There are 139799 log messages thetracesforthethreesequentialoperationsbeingexecuted.It
TABLEII
TRACES:COUNTSOFSERVICESPERRALLYACTION
wsgi db comp. api nova image neutron api neutron db rpc
image create delete 11436 81321 0 0 0 0 0
network create delete 4692 14101 0 0 0 125321 855
boot delete 46591 125975 21572 752 313744 46642 36560
TABLEIII
TRACESINFORMATION:MEDIANTIMEOFASERVICEPERITERATION
wsgi db comp. api nova image neutron api neutron db rpc
image create delete 0.046 0.001 0 0 0 0 0
network create delete 0.285 0.001 0 0 0 0.001 0.001
boot delete 0.0410 0.001 0.039 0.035 0.001 0.002 0.009
isgivenasatotalsumoveralltherepetitionoftheexperiment. Multi-source Anomaly Detection. The distributed logs over
Onecanbeobservethattherearedifferentserviceinvokedper projects and physical hosts enable multimodal end-to-end
operation. For example, for the image_create_delete learning and more robust log anomaly detection. Of course,
operation the open stack service involved is completely on this adds complexity for data integration and fusion, as the
the controller node, hence the compute nodes are contacted distributed logs are produced with different timestamps. To-
andthereisnooperationrelatedtothem.Themostfrequently gether,thedistributedlogsandmetricscanagainbecombined
occurring invocation is split between db and wsgi. Second the into more complex model or network of models. Lastly, the
operations are ordered by complexity and it can be seen that graph-like structures of the tracing data can be incorporated
the boot_delete_task involves all of the 7 services. to complete the robust anomaly detection where all available
Table III represents the median time of execution for each observability data is considered.
of the invoked services. The median is chosen since the
Root-cause Analysis. The integration of multi-source ob-
distributions are skewed and the mean is not representative
servability data can be exploited by using some kind of
of the sample distribution. As it can be observed, the wsgi
Fishbone diagrams [38] to find the root-cause of problems. A
services are slower than the db calls since wsgi relays on http
method can start with simple metric-only anomaly detection,
communication.Itisinterestingtoobservethatforthenetwork
which typically provides little information about the root-
create delete operation the rpc is quite small. One explanation
causes of problems, and drill down to more complex data
for this is the small rate of rpc call per individual execution.
structures which are richer in explaining anomalies. For ex-
This means that not all executions of this operation involve
ample,onecanstartbyanalyzingthelatencyofmicroservices
rpc calls. Since multiple workloads involve invoking different
endpoints. If anomalies are detected after processing metrics,
number of individual operation the times should be compared
one can use the timeframe when the anomaly occurred to
with caution.
select and analyze structural changes in traces. Traces can
VI. APPLICATIONSOFMULTI-SOURCEAIOPS provide information about which servers are possibly faulty.
Afterwards, application logs can be accessed to find the root-
While previous work has been generally done on single-
cause of problems.
source data, we believe that to develop robust, holistic ap-
proaches for anomaly detection, root-cause analysis, self-
Precision Increase. Ensemble learning [39] can be used to
healing, resource optimization, and performance analysis a
machinelearningalgorithmresultsbycombiningseveralmod-
multi-source data is highly desirable.
elsappliedtothethreecorrelateddatasourcescategories.Such
One of the first proposals to use more than one category of
an approach would allow the production of algorithms with
observability data in a single model is made in Nedelkoski et
better predictive accuracy when compared to the algorithms
al. [13], [14]. A new research direction for anomaly detection
which process single-data sources.
is explored. Besides the response time, a second category of
data:thetracingdatacollectedduringtheexecutionofsystem Feature Extension. Many machine learning algorithms rely
operations is analyzed. The results of this new approach are on features, which for AIOps are individual measurable char-
encouragingandprovideadirectionofdevelopmentofmodels acteristicsofthebehaviourofITdistributedsystemsatagiven
that combine and explore additional data categories. time. By using multi-source data, the spectrum of available
In this section, we shortly describe possible AIOps ap- features to an algorithm is dramatically increased. Thus, we
proaches that can exploit the benefits of processing multi- expect the quality of algorithms and their results to increase
source observability data. in the future.
VII. CONCLUSION [14] ——, “Anomaly detection and classification using distributed tracing
and deep learning,” in 2019 19th IEEE/ACM International Symposium
AIOps systems rely on suitable observability data. We re-
onCluster,CloudandGridComputing(CCGRID). NewJersey:IEEE,
leasedamulti-sourcedatacontainingdistributedmetrics,logs, 2019,pp.241–250.
and tracing data obtained from a complex distributed system [15] T.D.Jick,“Mixingqualitativeandquantitativemethods:Triangulation
inaction,”AdministrativeScienceQuarterly,vol.24,pp.602–611,1979.
based on microservice architecture. We describe in details the
[16] (2019)Oregon.[Online].Available:http://odds.cs.stonybrook.edu/
infrastructure, experiments performed, and the fault injection. [17] S. Ahmad, A. Lavin, S. Purdy, and Z. Agha, “Unsupervised real-time
Furthermore, we provided descriptive statistical properties of anomaly detection for streaming data,” Neurocomputing, vol. 262, pp.
134–147,2017.
the data.
[18] M. Goldstein. (2015) Unsupervised Anomaly Detection Benchmark.
Furthermore,wemotivatedpossibleapplicationsofthisdata [Online].Available:https://doi.org/10.7910/DVN/OPQMVF
for improvements in anomaly detection, root-cause analysis, [19] (2019) Elki. [Online]. Available: https://elki-project.github.io/datasets/
outlier
remediation, and feature extension. We hope that this dataset
[20] (2019) Lmu. [Online]. Available: https://www.dbs.ifi.lmu.de/research/
willfosteradvancesintheresearchofAIOps,whichhasbeen outlier-evaluation/
limited mainly to explored data capturing only a single data [21] (2019)Cfdr.[Online].Available:https://www.usenix.org/cfdr-data
[22] J. Zhu, S. He, J. Liu, P. He, Q. Xie, Z. Zheng, and M. R. Lyu,
source category.
“Tools and benchmarks for automated log parsing,” in Proceedings of
the 41st International Conference on Software Engineering: Software
REFERENCES
EngineeringinPractice. Piscataway,NJ,USA:IEEEPress,2019,pp.
[1] Y. Dang, Q. Lin, and P. Huang, “Aiops: real-world challenges and re- 121–130.
searchinnovations,”inProceedingsofthe41stInternationalConference [23] W.Meng,Y.Liu,Y.Zhu,S.Zhang,D.Pei,Y.Liu,Y.Chen,R.Zhang,
onSoftwareEngineering:CompanionProceedings. IEEEPress,2019, S.Tao,P.Sun,andR.Zhou,“Loganomaly:Unsuperviseddetectionof
pp.4–5. sequentialandquantitativeanomaliesinunstructuredlogs,”inProceed-
[2] “Zabbix.”[Online].Available:https://github.com/zabbix ings of the Twenty-Eighth International Joint Conference on Artificial
[3] “Nagios enterprises.” [Online]. Available: https://github.com/ Intelligence,IJCAI2019,Macao,China,August10-16,2019,2019,pp.
NagiosEnterprises 4739–4745.
[4] C. Sridharan, Distributed Systems Observability: A Guide to Building [24] OpenZipkin, “openzipkin/zipkin,” 2018. [Online]. Available: https:
RobustSystems. O’ReillyMedia,2018. //github.com/openzipkin/zipkin
[5] F.Schmidt,A.Gulenko,M.Wallschlger,A.Acker,V.Hennig,F.Liu, [25] E. Cortez, A. Bonde, A. Muzio, M. Russinovich, M. Fontoura, and
and O. Kao, “Iftm - unsupervised anomaly detection for virtualized R. Bianchini, “Resource central: Understanding and predicting work-
networkfunctionservices,”in2018IEEEInternationalConferenceon loads for improved resource management in large cloud platforms,”
WebServices(ICWS). NewJersey:IEEE,2018,pp.187–194. in Proceedings of the International Symposium on Operating Systems
[6] A. Gulenko, F. Schmidt, A. Acker, M. Wallschlager, O. Kao, and Principles(SOSP),2017.
F. Liu, “Detecting anomalous behavior of black-box services modeled [26] H.ShenandC.Li,“Zeno:Astragglerdiagnosissystemfordistributed
withdistance-basedonlineclustering,”in2018IEEE11thInternational computing using machine learning,” in High Performance Computing.
ConferenceonCloudComputing(CLOUD). NewJersey:IEEE,2018, Cham:SpringerInternationalPublishing,2018,pp.144–162.
pp.912–915. [27] F.LiandB.Hu,“Deepjs:Jobschedulingbasedondeepreinforcement
[7] F. Schmidt, F. Suri-Payer, A. Gulenko,M. Wallschlger, A. Acker,and learninginclouddatacenter,”inProceedingsofthe20194thInterna-
O. Kao, “Unsupervised anomaly event detection for cloud monitoring tionalConferenceonBigDataandComputing. NewYork,NY,USA:
using online arima,” in 2018 IEEE/ACM International Conference on ACM,2019,pp.48–53.
Utility and Cloud Computing Companion (UCC Companion). New [28] (2019) Alibaba trace data. [Online]. Available: https://github.com/
Jersey:IEEE,2018,pp.71–76. alibaba/clusterdata
[8] F.Pina,J.Correia,R.Filipe,F.Araujo,andJ.Cardoso,“Nonintrusive [29] (2019) Google trace data. [Online]. Available: https://github.com/
monitoring of microservice-based systems,” in 2018 IEEE 17th Inter- google/cluster-data
national Symposium on Network Computing and Applications (NCA), [30] N. El-Sayed,H. Zhu, andB. Schroeder,“Learning from failureacross
2018,pp.1–8. multipleclusters:Atrace-drivenapproachtounderstanding,predicting,
[9] J. Correia, F. Ribeiro, R. Filipe, F. Arauio, and J. Cardoso, “Response and mitigating job terminations,” in International Conference on Dis-
time characterization of microservice-based systems,” in 2018 IEEE tributedComputingSystems(ICDCS),2017,pp.1333–1344.
17thInternationalSymposiumonNetworkComputingandApplications [31] A.Shrivastwa,S.Sarat,K.Jackson,C.Bunch,E.Sigler,andT.Camp-
(NCA). NewJersey:IEEE,2018,pp.1–5. bell, OpenStack: Building a Cloud Environment. Packt Publishing,
[10] M.Du,F.Li,G.Zheng,andV.Srikumar,“Deeplog:Anomalydetection 2016.
anddiagnosisfromsystemlogsthroughdeeplearning,”inProceedings [32] “Kolla-ansible’s documentation.” [Online]. Available: https://docs.
of the 2017 ACM SIGSAC Conference on Computer and Communica- openstack.org/kolla-ansible/latest/
tionsSecurity. NewYork,NY,USA:ACM,2017,pp.1285–1298. [33] “Rally.”[Online].Available:https://rally.readthedocs.io/en/latest/
[11] H. Hamooni, B. Debnath, J. Xu, H. Zhang, G. Jiang, and A. Mueen, [34] Performa,“os-faults.”[Online].Available:https://opendev.org/performa/
“Logmine: Fast pattern recognition for log analytics,” in Proceedings os-faults
of the 25th ACM International on Conference on Information and [35] Nicolargo, “nicolargo/glances,” 2019. [Online]. Available: https:
KnowledgeManagement. NewYork,NY,USA:ACM,2016,pp.1573– //github.com/nicolargo/glances
1582. [36] Taraslayshchuk, “taraslayshchuk/es2csv,” 2018. [Online]. Available:
[12] S. He, J. Zhu, P. He, and M. R. Lyu, “Experience report: System https://github.com/taraslayshchuk/es2csv
log analysis for anomaly detection,” 2016 IEEE 27th International [37] Openstack, “openstack/osprofiler.” [Online]. Available: https://github.
SymposiumonSoftwareReliabilityEngineering(ISSRE),pp.207–218, com/openstack/osprofiler
2016. [38] K.Ishikawa,GuidetoQualityControl. Tokyo:JUSE,2012.
[13] S. Nedelkoski, J. Cardoso, and O. Kao, “Anomaly detection from [39] C. Zhang and Y. Ma, Ensemble Machine Learning: Methods and
system tracing data using multimodal deep learning,” in 2019 IEEE Applications. NewYork:SpringerVerlag,2012.
12th International Conference on Cloud Computing (CLOUD). New
Jersey:IEEE,2019,pp.179–186.