### 分析与优化后的文本

#### 日志分析
在日志中，WSGI 相关模块的出现频率最高，包括 `neutron wsgi`、`nova.osapi wsgi` 和 `server wsgi`。其中，`programname` 指的是执行操作的程序名称。系统中共有 127,654 种不同的负载（payloads），其中最频繁的是 GET 操作。

对于已实现的 HTTP 调用，记录了以下信息：
- **HTTP 状态码**：共有 6 种不同的状态码。
- **HTTP 方法**：共有 4 种可能的方法（GET、POST、DELETE 和 PUT）。
- **HTTP URL**：共有 3,655 种不同的值。
- **HTTP 版本**：存储在 `http_version` 中。

此外，还有 `_domain_id`、`user_domain`、`tenant_id`、`request_id`、`user_id`、`_score`、`_type`、`project_domain`、`Pid` 和 `domain_id` 等列，这些列中的唯一值数量要么非常大，要么非常小。它们通常表示 IP 地址或哈希函数的结果作为起始点和结束点。

#### 追踪数据
由于日志是半结构化数据，我们首先尝试对其进行组织，并观察可能出现的各种特征。总共有 139,799 条日志消息。表 II 显示了三种顺序操作执行时每种服务的数量。

| 操作 | WSGI | 数据库 | 计算 | API | Nova 图像 | Neutron API | Neutron 数据库 | RPC |
|------|------|--------|------|-----|------------|-------------|----------------|-----|
| 图像创建/删除 | 11,436 | 81,321 | 0 | 0 | 0 | 0 | 0 |
| 网络创建/删除 | 4,692 | 14,101 | 0 | 0 | 0 | 125,321 | 855 |
| 启动/删除 | 46,591 | 125,975 | 21,572 | 752 | 313,744 | 46,642 | 36,560 |

表 III 显示了每次迭代中每个服务的中位执行时间。

| 操作 | WSGI | 数据库 | 计算 | API | Nova 图像 | Neutron API | Neutron 数据库 | RPC |
|------|------|--------|------|-----|------------|-------------|----------------|-----|
| 图像创建/删除 | 0.046 | 0.001 | 0 | 0 | 0 | 0 | 0 |
| 网络创建/删除 | 0.285 | 0.001 | 0 | 0 | 0 | 0.001 | 0.001 |
| 启动/删除 | 0.0410 | 0.001 | 0.039 | 0.035 | 0.001 | 0.002 | 0.009 |

可以看到，不同操作涉及的服务各不相同。例如，在 `image_create_delete` 操作中，OpenStack 服务完全在控制节点上运行，因此计算节点没有参与。最常见的调用是数据库和 WSGI 之间的分割。操作按复杂性排序，可以看到 `boot_delete_task` 涉及所有 7 个服务。

表 III 显示了每个调用服务的中位执行时间。选择中位数是因为分布偏斜，均值不能代表样本分布。可以看出，WSGI 服务比数据库调用慢，因为 WSGI 依赖于 HTTP 通信。有趣的是，在 `network_create_delete` 操作中，RPC 的时间非常短。这可能是由于每次执行中 RPC 调用的频率较低。这意味着并非所有执行都涉及 RPC 调用。由于多个工作负载涉及不同的操作，时间应谨慎比较。

#### 多源异常检测
分布式日志和指标可以结合成更复杂的模型或模型网络，以进行多模态端到端学习和更强大的日志异常检测。当然，这增加了数据集成和融合的复杂性，因为分布式日志的时间戳不同。通过结合追踪数据的图结构，可以实现全面的异常检测，考虑所有可用的可观测性数据。

#### 根因分析
多源可观测性数据的集成可以通过使用鱼骨图等方法来查找问题的根本原因。一种方法可以从简单的基于指标的异常检测开始，这种方法通常提供的关于根本原因的信息较少，然后深入到更复杂的数据结构，这些结构在解释异常方面更为丰富。例如，可以先分析微服务端点的延迟。如果在处理指标时检测到异常，可以使用异常发生的时间段来选择并分析追踪中的结构变化。追踪可以提供有关哪些服务器可能存在故障的信息。之后，可以访问应用程序日志以找到问题的根本原因。

#### 应用
虽然以前的工作主要集中在单源数据上，但我们认为，为了开发稳健的整体方法来进行异常检测、根因分析、自愈、资源优化和性能分析，多源数据是非常理想的。集成学习可以用来结合多个模型应用于三个相关数据源类别，从而产生具有更好预测准确性的算法，相比处理单一数据源的算法。

#### 结论
AIOps 系统依赖于合适的可观测性数据。我们发布了包含从基于微服务架构的复杂分布式系统中获取的分布式指标、日志和追踪数据的多源数据集。详细描述了基础设施、实验和故障注入，并提供了数据的描述性统计属性。此外，我们探讨了该数据在改进异常检测、根因分析、补救措施和特征扩展方面的潜在应用。我们希望这个数据集能够促进 AIOps 领域的研究进展，目前该领域的研究主要局限于单一数据源类别的数据捕获。

#### 参考文献
[此处省略具体参考文献，可根据需要补充]

---

通过以上优化，文本更加清晰、连贯且专业，便于读者理解和进一步研究。