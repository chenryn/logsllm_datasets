small changes in the short-term half-life value can dramatically aﬀect the
optimal threshold. This suggests that small random perturbations can cause
one or the other of the two threshold values to be deemed optimal. As we
run experiments varying the block size and the saturation, these random
perturbations can cause the optimal short-term half life or threshold to jump
between the two local minima, resulting in the jagged appearance of the
optimal threshold surface.
– Low sensitivity – Notice also that even on the Hst = 15 curve, the cost value
is nearly ﬂat near the minimum point. Again this suggests that random
perturbations can cause the optimum point to jump, further contributing to
the diﬃculty in ﬁnding a stable optimal threshold.
122
J.P. Hansen, K.M.C. Tan, and R.A. Maxion
l
t
t
s
o
C
e
u
o
s
b
A
0.60
0.50
0.40
0.30
0.20
0.10
0.00
0.0
0.5
1.0
1.5
2.0
2.5
3.0
3.5
4.0
Threshold (T)
Hst=5
Hst=15
Hst=25
Hst=50
Hst=100
Hst=150
Hst=200
Fig. 5. Eﬀect of detector tuning on error cost with B = 900 and λa = 0.3
Turning our attention back to the optimal short-term half-life surface shown
in Figure 4(a), we notice that there are three basic regions on this surface based
on the foreign-symbol saturation (λa) value:
– Low foreign-symbol saturation – In this region the normal and anomalous
blocks are so similar that even when optimally tuned, detector performance
is poor (see Figure 2). In this region, the cost as a function of the short-term
half-life is essentially ﬂat except for noise due to random variations in the
synthetic data. This results in the optimal short-term half-life being decided
by these random variations rather than by the eﬀects of the data or detector,
resulting in the jagged peaks and valleys.
– Medium foreign-symbol saturation – In this region the optimal short-term
half-life increases as the block size increases. This is due to the trade-oﬀ
between the accuracy that results from a larger short-term half-life (and thus
larger eﬀective sample size) and the block-boundary problem (discussed in
Section 6.1) that is exacerbated by larger short-term half-life values. As the
block size increases, the transition problem becomes less signiﬁcant, and thus
a larger short-term half-life becomes more eﬀective.
– High foreign-symbol saturation – In this region the foreign-symbol saturation
is so high that the anomalies can be easily detected even with a small sample.
Since there is no signiﬁcant beneﬁt to using a large sample (i.e., a large short-
term half-life) a smaller short-term half-life is preferred to minimize errors
due to block transitions.
6.3 Comparison with Real-World Data
To validate the signiﬁcance of the synthetic-data experiments, we compared
the results of an experiment using real-world data to results using synthetic
data. The real-world data was the sendmail system-call trace data collected by
researchers at the University of New Mexico [5]. The trace data consists of a
“normal” trace ﬁle and an “intruder” trace ﬁle. We ﬁrst created three 100,000-
symbol data sets, drawn from the ﬁrst 300,000 symbols of the normal trace
Anomaly Detector Performance Evaluation
123
0.5
t
s
o
C
e
t
u
o
s
b
A
l
0
10
200
400
600
Block Size
800
1000
0
0
2
0
5
h
1
S
o rt- T
0.5
t
s
o
C
e
t
u
o
s
b
A
l
0
10
200
400
600
Block Size
800
1000
0
0
2
0
5
h
1
S
o rt- T
0
0
5
alf- Lif e
1
0
0
e r m   H
0
0
5
alf- Lif e
1
0
0
e r m   H
(a) Cost function for real-world data
(sendmail trace).
(b) Cost function for synthetic data with
foreign-symbol injection of λa = 0.5
Fig. 6. Comparison between real-world data (left) and synthetic data (right)
ﬁle (which contained 1,571,583 symbols); these data sets, each the same size
as those used in the synthetic data sets, were used to train the detector. We
next constructed the test data by splicing together alternating blocks of symbols
from the normal trace (starting at symbol 300,001, so as to avoid using the same
data for training and testing) and the intruder trace. We used the block-size
parameter B to vary block sizes in the same way in which we varied the block
sizes for the synthetic data. This gives us a trace based on real-world data that
is directly comparable to our synthetic-data experiments.
Figure 6(a) shows the detector error cost for the real-world data as a function
of the block size and the detector short-term half-life. The threshold is assumed
to be optimally tuned. Figure 6(b) shows the corresponding graph for synthetic
data with foreign symbol injections at a saturation of λa = 0.5. With a few
small diﬀerences, the basic shape of the two graphs is very similar. The two
most obvious diﬀerences are:
– In the experiment with real-world data, the error cost falls oﬀ almost imme-
diately as the block size increases, whereas in the synthetic-data experiment
the error cost remains constant until the block size is moderately large.
– The optimal cost for the synthetic-data experiment is lower than that for
the real-world data experiment.
While injection type (foreign, rare or uncommon) and saturation do aﬀect the
details of the cost surface shape, the same basic features are generally preserved.
Typically, lower saturation values result in a cost surface that slopes down more
gradually from the small-blocksize/high-short-term-half-life corner, and has a
124
J.P. Hansen, K.M.C. Tan, and R.A. Maxion
larger lip on the low-short-term-half-life edge of the curve. Furthermore, other
parameters that were not studied in detail in this paper (e.g., alphabet size and
symbol-type distribution standard deviation σ), would also be expected to have
an eﬀect. Given that changing the data characteristics can result in a variety of
similar cost curves, we believe that our sendmail trace results are well within
the scope of our expectations.
7 Conclusion
In this paper we presented an evaluation approach for an anomaly-based detec-
tor, using a parameterized family of synthetic data sets. We varied the injection
type and saturation level, as well as the block size (via injection length and time
between injections). We also validated our observed performance characteristics
on the synthetic data by comparing it with a real-world data set, noting that we
obtained similar performance curves.
We observed a relationship between the block size and the optimal short-
term half life. We showed that as the block size decreased we needed to decrease
the short-term half-life in order to maintain optimal performance. This suggests
that when placed in an environment where attacks are expected to be short or
frequent, the short-term half life should be small. Since the short-term half life
essentially sets a short-term window, we could also expect similar results for
other detectors that have a window-size parameter. An exception to this rule
is that when an intruder manifests as an obvious and easy-to-detect anomaly
(e.g., has a high saturation value), or conversely, is on the margin of the de-
tector’s discriminatory capability, larger short-term half-life values should be
used.
We have evaluated RIDES over a wide range of data environments. The lessons
learned have been consistent through all of those environments, strongly suggest-
ing that the results are extensible to other data sets. For example, since we have
observed through all of the environments that RIDES is blind to a low saturation
of anomalies, we believe that it is highly unlikely that RIDES would be able to
detect a single foreign symbol in any other environment.
We also showed that there are challenges remaining to be faced in the area of
intrusion-detector performance modeling. Interaction among the detector param-
eters can lead to multiple local optima, making it diﬃcult to ﬁnd a satisfactory
tuning in some cases. More work is needed in this area to identify additional
criteria upon which tuning decisions can be made.
Acknowledgements
The authors are grateful for helpful comments from F. Arshad, K. Killourhy,
P. Loring, and R. Roberts. The authors are also thankful to several anonymous
referees whose thoughtful remarks inspired improvements in the paper. This work
was supported by National Science Foundation grant number CNS-0430474.
Anomaly Detector Performance Evaluation
125
References
1. Anderson, Debra; Lunt, Teresa F.; Javitz, Harold; Tamaru, Ann and Valdes, Al-
fonso. “Detecting Unusual Program Behavior Using the Statistical Component of
the Next-Generation Intrusion Detection Expert System (NIDES),” Technical Re-
port SRI-CSL-95-06, Computer Science Laboratory, SRI International, May 1995.
2. Anderson, Debra; Lunt, Teresa F.; Javitz, Harold; Tamaru, Ann and Valdes, Al-
fonso. “Safeguard Final Report: Detecting Unusual Program Behavior Using the
NIDES Statistical Component,” Technical Report, Computer Science Laboratory,
SRI International, Menlo Park, California, 02 December 1993.
3. Arbel, Gil. Anomaly Detection Falls Short http://www.techworld.com/
networking/features/index.cfm?featureID=2331, TechWorld, 13 March 2006.
4. Denning, Dorothy E. An Intrusion-Detection Model, IEEE Transactions on Soft-
ware Engineering, Vol. SE-13, No. 2, pp. 222-232, February 1987.
5. Forrest, Stephanie. “Computer Immune Systems.” Data sets for sequence-based
intrusion detection: http://www.cs.unm.edu/∼immsec/systemcalls.htm. Com-
puter Science Department, University of New Mexico, Albuquerque, New Mexico.
2006.
6. Forrest, Stephanie; Hofmeyr, Steven A.; Somayaji, Anil and Longstaﬀ, Thomas A.
“A Sense of Self for Unix Processes,” In IEEE Symposium on Security and Privacy,
pp. 120-128, 06-08 May 1996, Oakland, California. IEEE Computer Society Press,
Los Alamitos, California.
7. Ghosh, Anup K.; Schwartzbart, Aaron and Schatz, Michael. “Learning Program
Behavior Proﬁles for Intrusion Detection ,” In 1st USENIX Workshop on Intrusion
Detection and Network Monitoring, pp. 51-62, Santa Clara, CA, 09-12 April 1999.
8. Ghosh, Anup K.; Wanken, James and Charron, Frank. “Detecting Anomalous and
Unknown Intrusions Against Programs,” In 14th Annual Computer Security Appli-
cations Conference, pp. 259-267, Phoenix, AZ, 07-11 December 1998. Los Alamitos,
CA, IEEE Computer Society Press, 1998.
9. Javitz, Harold S. and Valdes, Alfonso. The NIDES Statistical Component: Descrip-
tion and Justiﬁcation. Annual Report A010, 07 March 1994, SRI International,
Menlo Park, California.
10. Javitz, Harold S. and Valdes, Alfonso. “The SRI IDES Statistical Anomaly De-
tector,” In IEEE Symposium on Research in Security and Privacy, pp. 316-326,
Oakland, California, 20-22 May 1991. IEEE Computer Security Press, Los Alami-
tos, California.
11. Jha, Somesh; Tan, Kymie M. C. and Maxion, Roy A. “Markov Chains, Classiﬁers,
and Intrusion Detection,” In 14th IEEE Computer Security Foundations Workshop,
pp. 206-219, Cape Breton, Nova Scotia, Canada, 11-13 June 2001.
12. Swets, John A. and Pickett, Ronald M. Evaluation of Diagnostic Systems: Methods
from Signal Detection Theory. Academic Press, New York, 1982.
13. Tan, Kymie M. C. and Maxion, Roy A. “Determining the Operational Limits
of an Anomaly-Based Intrusion Detector.” IEEE Journal on Selected Areas in
Communications, Special Issue on Design and Analysis Techniques for Security
Assurance, Vol. 21, No. 1, pp. 96-110, January 2003.
14. Tan, Kymie M. C. and Maxion, Roy A. “The Eﬀects of Algorithmic Diversity
on Anomaly Detector Performance,” In International Conference on Dependable
Systems & Networks (DSN-05), pages 216-225, Yokohama, Japan, 28 June - 01
July 2005. IEEE Computer Society Press, Los Alamitos, California, 2005.
126
J.P. Hansen, K.M.C. Tan, and R.A. Maxion
15. Valdes, Alfonso and Anderson, Debra. Statistical Methods for Computer Usage
Anomaly Detection Using NIDES (Next-Generation Intrusion Detection Expert
System), Third International Workshop on Rough Sets and Soft Computing (RSSC-
94), 10-12 November 1994, San Jose, California. Published by the Society for Com-
puter Simulation, San Diego, 1995, pp. 104-111.
16. Warrender, Christina; Forrest, Stephanie and Pearlmutter, Barak. “Detecting In-
trusions Using System Calls: Alternative Data Models,” In IEEE Symposium on
Security and Privacy, pp. 133-145, Oakland, California, 09-12 May 1999. IEEE
Computer Security Press, Los Alamitos, California.
17. Zissman, Marc.
“1998/99 DARPA Intrusion Detection Evaluation data
sets,” MIT Lincoln Laboratory, http://www.ll.mit.edu/IST/ideval/data/
data index.html.