（来自JDK帮助文档：https://docs.oracle.com/javase/7/docs/api/java/net/ServerSocket.html）
**半连接队列的大小取决于：max(64,  /proc/sys/net/ipv4/tcp_max_syn_backlog)。 [不同版本的os会有些差异](https://developer.aliyun.com/article/804896)**
> 我们写代码的时候从来没有想过这个backlog或者说大多时候就没给他值（那么默认就是50），直接忽视了他，首先这是一个知识点的忙点；其次也许哪天你在哪篇文章中看到了这个参数，当时有点印象，但是过一阵子就忘了，这是知识之间没有建立连接，不是体系化的。但是如果你跟我一样首先经历了这个问题的痛苦，然后在压力和痛苦的驱动自己去找为什么，同时能够把为什么从代码层推理理解到OS层，那么这个知识点你才算是比较好地掌握了，也会成为你的知识体系在TCP或者性能方面成长自我生长的一个有力抓手
#### netstat 命令
netstat跟ss命令一样也能看到Send-Q、Recv-Q这些状态信息，不过如果这个连接不是**Listen状态**的话，Recv-Q就是指收到的数据还在缓存中，还没被进程读取，这个值就是还没被进程读取的 bytes；而 Send 则是发送队列中没有被远程主机确认的 bytes 数
```
$netstat -tn  
Active Internet connections (w/o servers)
Proto Recv-Q Send-Q Local Address   Foreign Address State  
tcp    0  0 server:8182  client-1:15260 SYN_RECV   
tcp    0 28 server:22    client-1:51708  ESTABLISHED
tcp    0  0 server:2376  client-1:60269 ESTABLISHED
```
**netstat -tn 看到的 Recv-Q 跟全连接半连接中的Queue没有关系，这里特意拿出来说一下是因为容易跟 ss -lnt 的 Recv-Q 搞混淆**
所以ss看到的 Send-Q、Recv-Q是目前全连接队列使用情况和最大设置
netstat看到的 Send-Q、Recv-Q，如果这个连接是Established状态的话就是发出的bytes并且没有ack的包、和os接收到的bytes还没交给应用
我们看到的 Recv-Q、Send-Q获取源代码如下（ net/ipv4/tcp_diag.c ）：
```
static void tcp_diag_get_info(struct sock *sk, struct inet_diag_msg *r,
  void *_info)
{
    const struct tcp_sock *tp = tcp_sk(sk);
    struct tcp_info *info = _info;
    if (sk->sk_state == TCP_LISTEN) {  //LISTEN状态下的 Recv-Q、Send-Q
	    r->idiag_rqueue = sk->sk_ack_backlog;
	    r->idiag_wqueue = sk->sk_max_ack_backlog; //Send-Q 最大backlog
    } else {						   //其它状态下的 Recv-Q、Send-Q
	    r->idiag_rqueue = max_t(int, tp->rcv_nxt - tp->copied_seq, 0);
	    r->idiag_wqueue = tp->write_seq - tp->snd_una;
    }
    if (info != NULL)
    	tcp_get_info(sk, info);
}
```
比如如下netstat -t 看到的Recv-Q有大量数据堆积，那么一般是CPU处理不过来导致的：
![image.png](https://cdn.jsdelivr.net/gh/shareImage/image@_md2zhihu_programmer_case_81efef37/就是要你懂TCP--半连接队列和全连接队列/77ed9ba81f70f794-77ed9ba81f70f7940546f0a22dabf010.png)
#### netstat看到的listen状态的Recv-Q/Send-Q
netstat 看到的listen状态下的Recv-Q/Send-Q意义跟 ss -lnt看到的完全不一样。上面的 netstat 对非listen的描述没问题，但是listen状态似乎Send-Q这个值总是0，这要去看netstat的代码了，实际上Listen状态它不是一个连接，所以肯定统计不到流量，netstat似乎只是针对连接的统计
从网上找了两个Case，server的8765端口故意不去读取对方发过来的2000字节，所看到的是：
```
$ netstat -ano | grep 8765  
tcp0  0 0.0.0.0:87650.0.0.0:*   LISTEN  off (0.00/0/0)  
tcp 2000  0 10.100.70.140:8765  10.100.70.139:43634 ESTABLISHED off (0.00/0/0)
```
第二个Case，8000端口的半连接满了（129），但是这个时候Send-Q还是看到的0
```
$ netstat -ntap | grep 8000 
tcp      129      0 0.0.0.0:8000            0.0.0.0:*               LISTEN      1526/XXXXX- 
tcp        0      0 9.11.6.36:8000          9.11.6.37:48306         SYN_RECV    - 
tcp        0      0 9.11.6.36:8000          9.11.6.34:44936         SYN_RECV    - 
tcp      365      0 9.11.6.36:8000          9.11.6.37:58446         CLOSE_WAIT  -  
```
## 案列：如果TCP连接队列溢出，抓包是什么现象呢？
![image.png](https://cdn.jsdelivr.net/gh/shareImage/image@_md2zhihu_programmer_case_81efef37/就是要你懂TCP--半连接队列和全连接队列/c0849615ae525318-c0849615ae52531887ce6b0313d7d2d1.png)
如上图server端8989端口的服务全连接队列已经满了（设置最大5，已经6了，通过后面步骤的ss -lnt可以验证）， 所以 server尝试过一会假装继续三次握手的第二步，跟client说我们继续谈恋爱吧。可是这个时候client比较性急，忙着分手了，server觉得都没恋上那什么分手啊。所以接下来两边自说自话也就是都不停滴重传
### 通过ss和netstat所观察到的状态
![image.png](https://cdn.jsdelivr.net/gh/shareImage/image@_md2zhihu_programmer_case_81efef37/就是要你懂TCP--半连接队列和全连接队列/ec25ccb6cce8f554-ec25ccb6cce8f554b7ef6927f05bd530.png)
![image.png](https://cdn.jsdelivr.net/gh/shareImage/image@_md2zhihu_programmer_case_81efef37/就是要你懂TCP--半连接队列和全连接队列/2fbdd05162e9fd51-2fbdd05162e9fd51e803682b8a18cc51.png)
[另外一个案例，虽然最终的锅不是TCP全连接队列太小，但是也能从重传、队列溢出找到根因](/2019/08/31/%E5%B0%B1%E6%98%AF%E8%A6%81%E4%BD%A0%E6%87%82TCP%E9%98%9F%E5%88%97--%E9%80%9A%E8%BF%87%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E6%9D%A5%E5%B1%95%E7%A4%BA%E9%97%AE%E9%A2%98/)
## 实践验证一下上面的理解
上面是通过一些具体的工具、指标来认识全连接队列，接下来结合文章开始的问题来具体验证一下
把java中backlog改成10（越小越容易溢出），继续跑压力，这个时候client又开始报异常了，然后在server上通过 ss 命令观察到：
```
Fri May  5 13:50:23 CST 2017
Recv-Q Send-QLocal Address:Port  Peer Address:Port
11         10         *:3306               *:*
```
按照前面的理解，这个时候我们能看到3306这个端口上的服务全连接队列最大是10，但是现在有11个在队列中和等待进队列的，肯定有一个连接进不去队列要overflow掉，同时也确实能看到overflow的值在不断地增大。
**能够进入全连接队列的 Socket 最大数量始终比配置的全连接队列最大长度 + 1**，结合内核代码，发现**内核在判断全连接队列是否满的情况下，使用的是 > 而非 >=** 。
> Linux下发SIGSTOP信号发给用户态进程，就可以让进程stop不再accept，模拟accept溢出的效果
> 
> kill -19 pid 即可； kill -18 pid 恢复暂停进程
> 
> ```
> #define SIGKILL     9    /* Kill, unblockable (POSIX). */
> #define SIGCONT     18   /* Continue (POSIX).  */
> #define SIGSTOP     19   /* Stop, unblockable (POSIX). */
> ```
tsar监控accept队列的溢出
> tsar --tcpx -s=lisove -li 1
### Tomcat和Nginx中的Accept队列参数
Tomcat默认短连接，backlog（Tomcat里面的术语是Accept count）Ali-tomcat默认是200, Apache Tomcat默认100.
```
#ss -lnt
Recv-Q Send-Q   Local Address:Port Peer Address:Port
0       100                 *:8080            *:*
```
Nginx默认是511
```
$sudo ss -lnt
State  Recv-Q Send-Q Local Address:PortPeer Address:Port
LISTEN    0     511              *:8085           *:*
LISTEN    0     511              *:8085           *:*
```
因为Nginx是多进程模式，所以看到了多个8085，也就是多个进程都监听同一个端口以尽量避免上下文切换来提升性能
![image.png](https://cdn.jsdelivr.net/gh/shareImage/image@_md2zhihu_programmer_case_81efef37/就是要你懂TCP--半连接队列和全连接队列/01dc036aca4b445e-01dc036aca4b445ed86e3e295bf245b8.png)
## 进一步思考 client fooling 问题
如果client走完第三步在client看来连接已经建立好了，但是server上的对应的连接有可能因为accept queue满了而仍然是syn_recv状态，这个时候如果client发数据给server，server会怎么处理呢？（有同学说会reset，还是实践看看）
先来看一个例子：
![image.png](https://cdn.jsdelivr.net/gh/shareImage/image@_md2zhihu_programmer_case_81efef37/就是要你懂TCP--半连接队列和全连接队列/9179e08ac24ce3d5-9179e08ac24ce3d53e74b92dbd044906.png)
如上图，图中3号包是三次握手中的第三步，client发送ack给server，这个时候在client看来握手完成，然后4号包中client发送了一个长度为238的包给server，因为在这个时候client认为连接建立成功，但是server上这个连接实际没有ready，所以server没有回复，一段时间后client认为丢包了然后重传这238个字节的包，等到server reset了该连接（或者client一直重传这238字节到超时，client主动发fin包断开该连接，如下图）
![image.png](https://cdn.jsdelivr.net/gh/shareImage/image@_md2zhihu_programmer_case_81efef37/就是要你懂TCP--半连接队列和全连接队列/3f5f1eeb0646a3af-3f5f1eeb0646a3af8afd6bbff2a9ea0b.png)
这个问题也叫client fooling，可以看这个patch在4.10后修复了：https://github.com/torvalds/linux/commit/5ea8ea2cb7f1d0db15762c9b0bb9e7330425a071 ，修复的逻辑就是，如果全连接队列满了就不再回复syn+ack了，免得client误认为这个连接建立起来了，这样client端收不到syn+ack就只能重发syn。
**从上面的实际抓包来看不是reset，而是server忽略这些包，然后client重传，一定次数后client认为异常，然后断开连接。**
如果这个连接已经放入了全连接队列但是应用没有accept（比如应用卡住了），那么这个时候client发过来的包是不会被扔掉，OS会先收下放到接收buffer中，知道buffer满了再扔掉新进来的。
## 过程中发现的一个奇怪问题
```