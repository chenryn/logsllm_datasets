96 90 50
4 10 50
W
A
R
R
E
S
3
T
S
1
T
S
4
N
T
T
Y
E
S
S
N
1 78 16 19 18 24
5
0 99 100 100 94 100 80
0
CRI: 100
1
0
0
6
0 20 100
U
O
H
D
T
V
1 63
0 100
0
2 unknown 100 100 100 100 100
E
wrong
correct 89 67 57
unknown 11 33 43 100
0 92
8
3
E
74 100 100
0 100 100 100 100 100 100 100 100
NET: 26
CRI: 100
81 76 25
19 24 75
0 88 88 84 78 92 60
0 12 13 16 22
8 40 100
0 97
3
wrong
CRI: 100
Linking Ampliﬁcation DDoS Attacks to Booter Services
439
Table 3 shows the results for both DNS and NTP. For each experiment we
give the percentage of attacks correctly attributed to its booter, the percentage
of attacker the classiﬁer labeled as unknown, as well as the percentage of attacks
that were misclassiﬁed, along with their putative label. Additionally, the ﬁrst
row states the number of attacks contained in our data set6. Note that in the
second experiment (E2) every column regards a classiﬁer trained on the entire
data set except the corresponding booter; hence the classiﬁer is correct when
assigning the unknown label in this case.
In the 10-fold CV (E1) our DNS classiﬁer correctly attributed 78% or more of
the attacks for each booter. Exceptions are the cases of EXI and VDO, for which
our data set only contains a single attack, which naturally cannot be attributed
correctly due to lack of training data. All the remaining attacks were labeled
as unknown. In fact, the DNS classiﬁer never attributed an attack to a wrong
booter in all three experiments. This is especially remarkable in the leave-one-
out scenario (E2), when the classiﬁer was not trained on data for one of the
booters. That is, even in this case our classiﬁer did not lead to false accusations,
showing the resilience of the classiﬁer against attacks stemming from booters
not contained in the training set. Of course, this resilience comes at the cost of
higher false negative rates in the other experiments (E1 & E3), as we prefer the
classiﬁer to label an attack as unknown over attributing it to the wrong booter.
This could possibly be alleviated by obtaining more training data per booter.
The last experiment (E3) simulates the performance of the classiﬁer in a real-
time scenario, i.e., when classifying an attack only based on training data that
was obtained prior to the attack. In contrast to this, the ﬁrst experiment (E1)
measured the performance when classifying attacks after the fact. Since booters
regularly rescan for ampliﬁers and update their set of ampliﬁers accordingly, our
classiﬁer will achieve a performance worse than in the ﬁrst experiment (E1).
However, even in the real-time attribution setting, we could still attribute at
least 67% of all attacks without any incorrect attributions. The loss compared
to E1 can be explained by the fact that the ﬁrst attack of a booter can never be
correctly classiﬁed due to lack of prior training data.
In the case of NTP, we achieved an overall attribution rate of 78% or more in
the 10-fold CV (E1) for most booters, with the exception of those which occur
only once in the data set. Remarkably, the cases of EXI and SYN show that the
classiﬁer also performs reasonably well even for small amounts of training data.
The NTP classiﬁer generates misclassiﬁcations. However, this only stems from
a few attacks by NET and CRI, which exhibit precisely the same characteristics.
While we suspect that NET and CRI share the same infrastructure, we were not
able to verify this assumption by leveraging layer 7 attacks (as done previously
for RAW and WEB). The same two attacks are also the cause for the only mis-
classiﬁcations in the leave-one-out scenario (E2), as about a quarter of attacks
from CRI were attributed to NET, when the classiﬁer was not trained on data
from CRI. In the real-time scenario (E3), the NTP classiﬁer attributed over 76%
of the attacks in most cases, even outperforming the DNS classiﬁer. Since NTP
6 This eﬀectively provides the entire confusion matrix for each experiment.
440
J. Krupp et al.
experiences less ampliﬁer churn, booters can use the same ampliﬁer set for a
longer period of time, i.e., an attack is more likely to use a set of ampliﬁers for
which the classiﬁer already observed a training sample. A notable exception here
is BO1, for which only 57% of the attacks could be attributed, despite the large
number of attacks contained in the data set. This indicates that BO1 performs
rescans more frequently than other booters.
Averaging over booters for which the data set contains more than one attack,
our classiﬁer achieves a macro-averaged precision of 100.00% and recall of 86.25%
in E1 for DNS, and 99.74% and respectively 91.01% for NTP. In the case of
real-time attribution (E3), the precision stays similarly high (100.00% for DNS,
99.69% for NTP), while the recall drops to 69.35% and respectively 76.73%.
5.3 Attribution
After validating the classiﬁcation mechanism, we now turn to applying it to our
entire data set of attacks observed at the honeypots (excluding the self-attacks).
Due to their low entropy, we excluded attacks that were only observed by a
single honeypot. This left 266,324 NTP-based and 161,925 DNS-based attacks.
For both we trained our classiﬁer on all self-attacks collected from December 9
to February 10.
Our NTP classiﬁer attributed 38,520 attacks (14.46%) to one of the booters
it was previously trained on and our DNS classiﬁer attributed almost a third of
all attacks (49,297, 30.44%) to a booter. Note that not all attacks observed at
the honeypots have to be caused by booters; they can also be caused by malev-
olent parties that do not oﬀer their attack capabilities on an online platform.
Furthermore, since we only trained our classiﬁer on a limited set of booters, our
classiﬁer cannot possibly achieve a classiﬁcation rate of 100%. Still, attributing
a considerable amount of attacks to the booters of our training set indicates that
the booters we considered are used very actively.
6 Victim-Driven Attack Attribution
Based on the success of the classiﬁer that allows honeypot operators to attribute
DDoS attacks, we now aim to build a similar classiﬁcation method that will
enable victims to attribute attacks based on features that can be extracted from
victims’ network traces. The core idea is to isolate a set of features that are
directly observable by the victim and that can precisely attribute attacks to a
particular booter service using a similar k-NN-classiﬁer algorithm.
6.1 Description
Motivated by the fact that each booter abuses characteristic sets of ampliﬁers,
we use the set of ampliﬁers as seen in the victim’s attack traces as a feature for
training our victim-driven classiﬁer. However, the TTL value of the attack source
used in the honeypot operator attribution technique is not directly observable by
Linking Ampliﬁcation DDoS Attacks to Booter Services
441
a victim, so we cannot use this feature in our victim based attribution method.
The loss of the TTL value feature is mostly compensated for by the victim being
able to see a larger set of ampliﬁers used by the booter service.
As we will show, this single feature is suﬃcient to build a classiﬁer that
can accurately attribute NTP, SSDP, and CharGen attacks from the victim’s
perspective. The one exception is that the set of open DNS resolvers used by
individual booter services are less stable over time, likely due to churn. As a
result, relying on the set of ampliﬁers as the sole feature for classifying DNS
attacks will not provide the same classiﬁcation performance as for the other
three attack types. Therefore, we must identify additional entropy to improve
the accuracy of our victim-based DNS attack classiﬁcation technique. Based on
our analysis of DNS attack traces captured at our victim server, we noticed that
each booter service tends to send spoofed ANY requests for a very small number
of mostly non-overlapping domain names. We thus complement the feature of
ampliﬁer sets with an additional feature over the set of domain names resolved
in DNS attacks. That is, for DNS, the Jaccard index is computed both for the set
of ampliﬁers and for the set of resolved domains, and the similarity score is the
mean of the two computed Jaccard indices. For all other protocols (NTP, SSDP,
and CharGen), we use the Jaccard index computed over the set of ampliﬁers.
In the victim-driven data set, all attacks are labeled with the booter service
and we do not have any unknown attacks. However, we will evaluate the situation
of unattributed attacks by performing the same E2 leave-one-out CV experiment
as in Sect. 5.2. Given this, we select a cutoﬀ threshold t to introduce a label for
an unknown classiﬁcation result that is used in the same way as in Sect. 5.2. We
choose a conservative threshold of t = 0.55 for CharGen, t = 0.60 for DNS,
t = 0.55 for NTP, and t = 0.45 for SSDP. In order to select the threshold value,
the score of correct classiﬁcations and incorrect classiﬁcations were manually
checked and a reasonably conservative value was selected for each attack type.
Only attack instances in the training set for which the similarity score is no less
than t were considered as potential neighbors. If no neighbor could be found for
a test instance, it was classiﬁed as unknown.
6.2 Validation
To validate the results of our victim-driven classiﬁer, we perform the same exper-
iments as in Sect. 5.2. Table 4 shows the result of our victim-driven classiﬁer
experiments for DNS and NTP7.
In E1, our DNS classiﬁer achieved high attribution rates of 80% or more,
except for BO2, EXI, EXO, and VDO, where a large fraction was also marked as
unknown. However, in ﬁve cases the classiﬁer also mistook attacks from one
booter as coming from another. The higher number of false positives for DNS is
attributable to the less stable set of DNS ampliﬁers abused by booters. These
results are worse than those for the honeypot-driven classiﬁer, possibly due to
the fact that unlike organic sets of ampliﬁers, the honeypots do not churn over
7 Results for CharGen and SSDP can be found in Sect. A.1.
442
J. Krupp et al.
Table 4. Victim-driven experimental results
(a) DNS
R
U
A
N
A
B
samples 25 10
correct 96 80
unknown
wrong
2
O
B
2
0
4 20 100
1
E
2 unknown 100 100 100
E
wrong
correct 76 60 50
unknown 24 40 50
3
E
wrong
T
E
N
19
95
0
NET 4 EXO 5
47
EXO 42
STA 11 SYN 2
I
X
E
7
29
71
O
X
E
25
60
36
3
O
B
27
89
4
VDO 7
74
64
VDO 22 RAW 14 NET 12
THU 4
STA 24
40
56
79
5
81
19
14
86
86
4
1
T
S
R
E
S
W
2
A
T
R
S
81 36 21 51
96 100 95 98
2
0
5
98 100 100 100
75 92 71 82
8 29 18
22
NET 4 EXO 16 SYN 1
EXI 1
A
T
S
21
100
0
3
T
S
18
83
11
SYN 6
89
48
SYN 11 EXO 43
NET 10
86
0