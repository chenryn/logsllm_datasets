title:Yes, We LEDBAT: Playing with the New BitTorrent Congestion Control
Algorithm
author:Dario Rossi and
Claudio Testa and
Silvio Valenti
Yes, We LEDBAT: Playing with the New BitTorrent
Congestion Control Algorithm
Dario Rossi, Claudio Testa, and Silvio Valenti
Telecom ParisTech, Paris, France
PI:EMAIL
Abstract. Since December 2008, the ofﬁcial BitTorrent client is using a new
congestion-control protocol for data transfer, implemented at the application layer
and built over UDP at the transport-layer: this new protocol undergoes the name
of LEDBAT, for Low Extra Delay Background Transport.
In this paper, we study different ﬂavors of the LEDBAT protocol, correspond-
ing to different milestones in the BitTorrent software evolution, by means of an
active testbed. Focusing on single ﬂow scenario, we investigate emulated artiﬁ-
cial network conditions, such as additional delay and capacity limitation. Then,
in order to better grasp the potential impact of LEDBAT on the current Internet
trafﬁc, we consider a multiple ﬂows scenario, and investigate the performance of
a mixture of TCP and LEDBAT ﬂows, so to better assess what “lower-than best
effort” means in practice. Our results show that LEDBAT has already fulﬁlled
some of its original design goals, though some issues still need to be addressed.
1 Introduction
Last December 2008, BitTorrent announced in the developer forum [1] that data transfer
would move to UDP: shortly after this announcement, panic started spreading on pop-
ular websites [2], since the announcement directly led to the misbelief that BitTorrent
plus UDP would equate with Internet meltdown. Yet, as already discussed at IETF [3]
and later recognized on the Web [4], the BitTorrent development process embraces
both ISP-friendliness (through AS-aware peer selection process) and TCP-friendliness
(through a novel congestion control protocol for data transfer).
This work focuses precisely on this latter aspect of BitTorrent evolution: BitTorrent
co-chairs an IETF Working Group on Low Extra Delay Background Transport (LED-
BAT), which has very recently released its ﬁrst draft document. To better understand
the motivations behind LEDBAT, let us recall that the standard TCP congestion control
mechanism needs losses to back off. Under a drop-tail FIFO queuing discipline, this
means that TCP necessarily ﬁlls the buffer: as uplink devices of low-capacity home
access networks have very large buffers, this may translate into poor performance of
interactive applications (e.g., slow Web browsing and bad gaming/VoIP quality). LED-
BAT attempts at avoiding this drawback, by implementing a distributed congestion con-
trol mechanism, tailored for the transport of non-interactive trafﬁc with lower than Best
Effort (i.e., TCP) priority. As stated in [5], among the main design goals of LEDBAT
there are the ability (i) to minimize the extra delay it induces in the bottleneck, while (ii)
saturating the available capacity at the same time. To fulﬁll these goals, LEDBAT has
A. Krishnamurthy and B. Plattner (Eds.): PAM 2010, LNCS 6032, pp. 31–40, 2010.
c(cid:2) Springer-Verlag Berlin Heidelberg 2010
32
D. Rossi, C. Testa, and S. Valenti
been designed as a windowed protocol (i) able to infer earlier than TCP the occurrence
of congestion, by estimating the queuing delay variation on the end-to-end path, (ii) to
which it reacts by continuously modulating the congestion window growth/shrink by a
proportional-integral-derivative (PID) controller.
The aim of this work is twofold. On the one hand, we target at understanding the
performance of LEDBAT in a number of simple single ﬂow scenarios, considering mul-
tiple versions of the ofﬁcial client so to better clutch its evolution. On the other hand, by
means of multiple ﬂows scenarios, we aim at gathering a preliminary understanding of
the implication that a widespread adoption of LEDBAT could have on the current Inter-
net landscape. We tackle the above issues with an active-measurement black-box study
of the ofﬁcial BitTorrent client. Since LEDBAT is openly described in a IETF draft, the
performance of the protocol could be assessed by means of simulations as we did indeed
in [6]. Yet we still ﬁnd active testbed experimentation extremely useful for several rea-
sons. First, the BitTorrent implementation of the LEDBAT protocol may differ from any
draft-compliant implementation by some design choices or parameter setting, that may
have a deep impact on the protocol performance. Second, the most widespread LED-
BAT implementation on the Internet will be the ofﬁcial BitTorrent version, rather than
a legacy implementation, which motivates a direct evaluation of this client. Third, from
our point of view, the analysis of proprietary applications by independent observers has
the beneﬁt of sheding light on the protocol inner workings. Finally real-world dynamics
introduced by network devices are often much more complex than the synthetic ones
that a simulation environment, although accurate, can reproduce.
With such an approach, we conduct a preliminary yet insightful evaluation of the
protocol performance. First, we are able to report on the entire evolution of the protocol
implementation, from the ﬁrst (immature) version to the last (nearly stable) one. We
point out that LEDBAT is able to, at least partly, fulﬁll its original design goals: un-
der both controlled testbed and Internet experiments, LEDBAT avoids an uncontrolled
queuing (unlike TCP), and is, under a range of conditions, able to saturate the available
capacity (or, in case capacity is not saturated, this could be done by a simple tweaking
of LEDBAT parameters). At the same time, we identify some open points regarding the
protocol efﬁciency: for instance, TCP trafﬁc on the “unrelated” backward path is able
to slow down LEDBAT transmission on the forward path, whose capacity may be then
signiﬁcantly underutilized. Finally, we stress that the precise meaning of “lower-than
best effort” should be carefully speciﬁed, as the mutual inﬂuence of TCP and LEDBAT
trafﬁc may signiﬁcantly differ depending on the TCP ﬂavor and settings as well.
2 Methodology and Preliminary Insights
For the investigation of the LEDBAT, we adopt an active-measurements black-box ex-
perimental approach, consisting in the analysis of the trafﬁc generated by the BitTorrent
client on different network scenarios. We run several versions of the new BitTorrent
client on PCs equipped with dual-core processors featuring (i) unless otherwise stated,
native installations of Windows XP or (ii) BitTorrent clients running on Linux using
the wine Windows emulator. PCs are either (i) connected to the Internet through ISPs
offering ADSL access, or (ii) in a local LAN testbed via Ethernet cards. In the ﬁrst case
Yes, We LEDBAT: Playing with the New BitTorrent Congestion Control Algorithm
33
we leave the default modem settings unchanged, while in the second one we disable
the interrupt coalescing feature and avoid the usage of jumbo frames. Moreover in the
LAN testbed, the trafﬁc is routed through a middlebox running a 2.6.28 Linux kernel,
which acts also as network emulator by means of netem, in order to enforce artiﬁcial
network conditions.
As formerly stated, in our experiments we consider both single ﬂow and multiple
ﬂows scenarios. Single ﬂow experiments are useful to understand the protocol perfor-
mance under a range of different network conditions, while multiple ﬂows experiments
are needed to quantify the level of inter-protocol priority (e.g., with respect to TCP
ﬂows) and intra-protocol fairness (e.g., with respect to other LEDBAT ﬂows) achieved
by the distributed control algorithm. Under the classic BitTorrent terminology, every
LEDBAT sender-receiver pair is a seeder-leecher pair, so that data transfer happens in a
single direction. In case of multiple-ﬂows experiments, every pair of actors belongs to
a different torrent, so that no data exchange happens between different leechers.
We start by providing some insights on the BitTorrent evolution with the help of
Fig. 1. Every picture refers to a different experiment, of which we report the ﬁrst minute,
corresponding to a different BitTorrent ﬂavor. The seeder connects to the middlebox
with a 100 Mbps Ethernet link, while between the middlebox and the leecher there is
a 10 Mbps Ethernet bottleneck link. No other trafﬁc is present on the bottleneck, and
the one-way delay on the forward path is forced to 50 ms, to loosely emulate a scenario
where two faraway peers with high speed Internet access (e.g., ADSL2+, FTTH or
Ethernet) are connected together.
Pictures are arranged so that the macroscopic timescale of BitTorrent evolution also
grows from left to right: Fig. 1-(a) shows, as a reference, the old open-source TCP-based
client, while Fig. 1-(b) refers to the ﬁrst closed-source version α1, released December
2008. Then, Fig. 1-(c) depicts the α2 version, released roughly at the same time of the
ﬁrst IETF draft [5] in March 2009. Finally, Fig. 1-(d) refers to the β1 version, released
after the draft was accepted as an ofﬁcial IETF WG item in August 2009.
The comparison of different versions of the protocol yields several interesting obser-
vations. First, notice that all versions analyzed correspond to important milestones in the
development process of the protocol: thus, they provide a valuable perspective which
highlights the ﬂaws as well as the improvements of the subsequent steps of LEDBAT
evolution. In particular, the α1 version (which precedes the draft speciﬁcation and mo-
tivates a black-box approach) was particularly instable and soon superseded. Moreover,
from this study it emerges that the LEDBAT implementation is constantly evolving: as
such, we believe that picking a single version, such as the most recent one, would limit
the scope of our study.
For each ﬂavor represented in Fig. 1, pictures depict the packet size on the y-axis,
measured at the sender side, with time of the experiment running on the x-axis. As it
can be seen, the application-layer segmentation policy is remarkably variable across
different LEDBAT ﬂavors. In contrast with TCP, which always transmits segments of
maximum size, LEDBAT instead uses variable packet sizes. For instance, the α1 im-
plementation of Fig. 1-(b) mostly used small segments of about 350 bytes, transmit-
ted at very high rate. Although this allows a ﬁner tuning of the congestion window
size, (e.g., likely to be more reactive to network condition), it deﬁnitively results in an
34
D. Rossi, C. Testa, and S. Valenti
]
]
]
]
e
e
e
e
t
t
t
t
y
y
y
y
B
B
B
B
[
[
[
[
e
e
e
e
z
z
z
z
i
i
i
i
s
s
s
s
t
t
t
t
e
e
e
e
k
k
k
k
c
c
c
c
a
a
a
a
P
P
P
P
 1500
 1250
 1000
 750
 500
 250
 0
TCP
v5.2.2 (Until Oct’08)
Open Source
α1
α2
v1.9-13485 (Since Dec’08)
v1.9-15380 (Since Mar’08)
Closed Source
First LEDBAT draft
β1
v1.9-16666 (Since Aug’09)
Draft accepted as WG item
 0
 10
 20
 30
Time [s]
(a)
 40
 50
 0
 10
 20
 30
Time [s]
(b)
 40
 50
 0
 10
 20
 30
Time [s]
(c)
 40
 50
 0
 10
 40
 50
 20
 30
Time [s]
(d)
Fig. 1. The last few months of BitTorrent client evolution: Temporal plot of packet-level traces
for different BitTorrent ﬂavors, reporting packet size during the ﬁrst minute of the transfer
unnecessary overhead. This segmentation policy is a bad choice for large transfers, and
was indeed soon dropped in favor of larger segment sizes. As can be gathered from
Fig. 1-(c) and Fig. 1-(d), newer BitTorrent ﬂavors start by segmenting data in small-
size segments, and then gradually increase the segment size over time, rarely changing
it once the full-payload segment size is reached. In case of α2 ﬂavor, we observe subse-
quent phases, about 10-seconds long, where only a single segment size is used: it takes
about 40 seconds to the application-layer segmentation policy to settle to full-payload
segment size. The β1 ﬂavor behaves similarly, although a wider range of segment sizes
is employed during the whole experiment, probably to obtain a ﬁner byte-wise control
of the congestion window.
The corresponding time evolution of the achieved throughput, measured over 1 s
time-windows is depicted in Fig. 2-(a), using a longer timeframe of about 4 minutes.
We merely superpose the curves for the sake of comparison, but experiments have
been independently performed. It can be seen that, shortly after achieving a sustained
throughput of about 9 Mbps during about 50 seconds, the sending rate of the α1version
suddenly drops, and about 2 minutes are necessary to recover from this starvation (this
unstable behavior was observed under a wide range of conditions). In contrast, α2 and
β1 achieve a lower but steady throughput, slightly above 4 and 7 Mbps respectively.
As a reference, we also report the throughput of a BitTorrent client using TCP run-
ning on the native Windows and Linux networking stacks under their default settings.
The networking stack implementation and conﬁguration dramatically impacts the pro-
tocol performance also in the TCP case. As reported in [7], in Windows XP, for trans-
mission rates between 10-100 Mbps the default receive window is set to 17520 Bytes,
whereas the default value of the Linux receive window (set in net.ipv4.tcp mem)
is about 6 times larger. Notice that in the Windows XP case, due to the 50 ms delay, the
default value of the maximum window is not large enough to allow full saturation of
the bottleneck pipe. This is an important, though not novel, observation on which we
will come back later on Sec. 3.2.
3 Experimental Results
In this section, we start with simple single ﬂow scenarios so to reﬁne the performance
pictures of the different ﬂavors by testing the impact of varying network conditions.
Yes, We LEDBAT: Playing with the New BitTorrent Congestion Control Algorithm
35
 10
]
s
p
b
M
[
t
u
p
h
g
u
o
r
h
T
 8
 6
 4
 2
 0
TCP Linux
(108 KB)