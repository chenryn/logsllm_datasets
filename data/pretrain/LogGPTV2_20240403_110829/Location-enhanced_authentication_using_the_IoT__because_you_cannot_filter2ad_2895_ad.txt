except during the initial registration step that takes place over HTTPS.
To register a device the user logs in to Icelus user interface over
HTTPS, and performs a standard two way registration step with
the Icelus client, server-client keys are generated and exchanged.
After this step all communication happens over HTTP.
The messages exchanged can be broken down to three parts: a
header, which is composed by the device ID and a ﬂag indicating
whether the message body is encrypted, the body which includes
timestamped sensor data, and a tail, where the digital signature of
the header and body, produced using the private key of the sender,
is placed. Sensor data can include information such as GPS data
(coordinates, speed, bearing), step count (indicates activity), the
SSID of the currently connected WiFi access point, list of paired
Bluetooth devices, etc.
Optimizations: Clients can choose to omit certain data from re-
ports when they determine that no signiﬁcant change to their state
has occurred. For example, when the device has not moved and is
idle. The client will then send the equivalent of a heartbeat mes-
sage that simply notiﬁes the Hub that the device is active and at its
previous location and state.
8. EVALUATION
In this section, we present the evaluation of Icelus in terms of ef-
fectiveness in making authentication decisions and efﬁciency. While
our system is designed to leverage the power of IoT and beneﬁts
as the number of devices increases, we chose our device testbed
in such a way that allowed us to sufﬁciently evaluate our system,
while also portraying a realistic setup for a user today.
8.1 Effectiveness
To evaluate our approach, we performed two ﬁeld studies having
one of the paper’s authors use Icelus. We hosted a Hub on Ama-
zon’s EC2 cloud and registered the following user devices: an Asus
Zenfone 2 smartphone as a Trinket, a Samsung Gear Live smart-
watch as a Trinket, a Fitbit Charge wrist wearable as Fragment, and
a TrackR Bravo BLE tag attached on the user’s key chain as a To-
ken. Trinkets were set to periodically report to the Hub every ﬁve
minutes. We could not place code to control the Fitbit Fragment,
and the TrackR Token is passive and can be observed by the Smart-
phone and the TrackR’s crowd GPS service. We did not include
any third-party services as Beacons.
In the ﬁrst study, S1, we deployed Icelus using the smartphone,
the Fitbit, and the TrackR and collected data over the course of
one month.
In the second study, S2, we deployed Icelus using
the smartphone, the smartwatch, and the TrackR and collected data
over the course of one workday.
8.1.1 Accuracy
To test the accuracy of the decisions made by Icelus, we em-
ulated query requests coming from our institute, which acts as a
Site, whenever the magnetic id swipe card of the user was used to
enter any of the access-controlled spaces in the institute. For ex-
ample, this included the door to the user’s ofﬁce, the gym, etc. We
obtained this data through the institute’s IT department. In total,
this included 49 accesses in 5 different card-protected doors in the
ﬁrst study, and 5 accesses in 3 doors in the second one. In all cases,
the user was the one actual using the access card, so these data also
correspond to the ground truth. We use the access-card and study
S1 data to calculate the following authentication metrics:
Window size
0
1
2
3
4
5
FRR (# FR)
6.12% (3)
6.12% (3)
4.08% (2)
4.08% (2)
4.08% (2)
4.08% (2)
PFAR
8.16%
6.12%
8.16%
8.16%
10.20%
12.24%
Table 2: Accuracy of Icelus in ﬁeld study S1 conducted over
the period of a month. We report FRR and PFAR when using
different window sizes in the moving average function in the
calculation of Avatar Conﬁdence Score. The total number of
authentication requests was 49.
• False Reject Rate (FRR). FRR is the rate of falsely denying ac-
cess to the real user. It occurs when an Avatar above the rejection
threshold is estimated to be at a different location from the one
the Site is querying about, an access-controlled door in our case
• Potential False Acceptance Rate (PFAR). Since during our ex-
periments there were no attempts to gain illegal access, PFAR
represents the potential False Acceptance Rate (FAR) of Icelus.
For calculating PFAR, we assume that an attacker continuously
attempts to enter the institute. This means that the attacker has
obtained the user’s swipe card and attempts to enter the institute
every ﬁve minutes. Since we are using a ﬁve minute period to
update the Conﬁdence Score a higher attempt frequency would
not change anything. Hence, PFAR is the rate of falsely accept-
ing such an ideal malicious user, because the Conﬁdence Score
of existing Avatars is below the rejection threshold.
Table 2 presents the results, when we employ a different window
size in the moving average calculation of the Conﬁdence Score.
The FRR and PFAR are equal for a window size of one. Note that
because we were not able to receive live queries from the swipe-
card system, we relied strictly on the data periodically received by
the Hub, that is, we could not request for fresh data from Trinkets.
We also investigated the three false rejections of the system. Two
of them occurred because of invalid data received from the user’s
smartphone. In detail, the user was driving to the ofﬁce, a short
drive of about 5 minutes. The smartphone reported once during
the drive to the Hub, but failed to read its updated GPS location.
That triggered a bug in our implementation that transmits the pre-
vious coordinates, if new coordinates cannot be read from the GPS,
which also led to an invalid estimation of the user’s speed. As a re-
sult, the Avatar remained at the previous location and its range did
not increase. In a full deployment of Icelus, we would be able to
contact the user’s Trinkets to update location at the point of authen-
tication and prevent such false rejections.
The third rejection occurred when the user forgot his smartphone
when going to the gym, which is only a few minutes away from the
ofﬁce. As a result, the now forgotten smartphone, only reported that
it is idle and no longer ﬁnds the user’s Fitbit in the next 5-minute
time window. We should note that such cases may not cause a huge
inconvenience to the user, who only needs to walk a few minutes
to retrieve the smartphone. We could argue that it is similar to
forgetting one’s keys.
Lessons Learned.
Besides correcting the buggy behavior in Icelus Trinket software,
other actions that we are considering to address such issues is to
enable devices to asynchronously report to the Hub, when a signif-
icant change in acceleration occurs. Immediately reporting Frag-
ments that disappear is another option.
In future work, we also
Device
Time and stddev.
3G
WiFi
Devices with direct connection to the Hub
Zenfone 2
Galaxy S5
Galaxy S4
Bluetooth devices tethered through Zenfone2
Gear (as a Trinket)
Gear (as a Fragment)
170.8ms ±53.8
173.7ms ±47.7
172.9ms ±52.8
280.8ms ±70.8
310.8ms ±83.8
645.8ms ±280.8
683.1ms ±300.1
710.2ms ±290.9
680.8ms ±283.8
745.8ms ±330.8
Table 3: Device response time.
to the set or number of devices that are not carried by the user. For
example, 2:5 corresponds to the scenario where the user is missing
two of his Trinkets and 5 of his Fragments. As it is evident even
when the user has under his control the minority of the devices our
proposed mechanism produces an Avatar strong enough to differ-
entiate him and answer inquiries about him with conﬁdence while
at the same time we vastly beneﬁt from device number since as it
is shown the attacker would have to compromise an ever increasing
number of devices to achieve the same result.
8.2 Efﬁciency
We evaluate Icelus in terms of efﬁciency by measuring the re-
sponse times and the impact of running the client on mobile devices
in terms of battery consumption. We tested the following Android
devices, which were not modiﬁed in any way other than adding
our client app: (a) 3 smartphones: an Asus Zenfone 2 with an
Intel Atom Z3560 Quad-core CPU at 1.8GHz, a Samsung Galaxy
S5 SM 900H with a Cortex-A15 Quad-core CPU at 1.9GHz, and a
Samsung Galaxy S4 GT-I9500 with a Cortex-A15 Quad-core CPU
at 1.6GHz, and (b) 1 smartwatch: a Samsung Gear Live E42F with
a Snapdragon 400 CPU at 1.2GHz.
8.2.1 Device Response Time
To evaluate the amount of time it takes for devices to report to
the Hub, we conducted an experiment were devices submit 255-
byte long reports to the Hub and timed the operations. We issued
over 20,000 reports, where each report included data from avail-
able device sensors, their list of connected devices, and movement
speed. Messages are padded to 255 bytes and encrypted with a
4096-bit RSA key before being sent.
Table 3 shows the average time and standard deviation in mil-
liseconds to complete the operation when connected on our campus
WiFi and over 3G. Note that the total time required for the Hub to
request and receive a report include the time required to notify the
devices, which in Android’s case happens through the GCM ser-
vice. So while previous works [41] have demonstrated low connec-
tion times, others have reported that they ﬂuctuate when the notiﬁed
device is ofﬂine [3]. The experiment shows that the process takes
less than a second. Hence, even though not required, requesting
new information from devices will not impose signiﬁcant delays
on authentication.
8.2.2 Reporting Period
How frequently devices report to the Hub, affects battery con-
sumption and the accuracy of the location information. In Table 4,
we show the battery consumption imposed by our prototype client
over a 10-hour period, when using different report windows. The
last row shows the radius of the area where a user may have moved
during the report window, assuming he is walking at 4Km/hr. Since
energy consumption may change non-linearly depending on the
Figure 6: Conﬁdence plot when user carries a smartwatch and
a Bravo tracker. Yellow areas denote no WiFi access.
plan to explore using learning to identify user habits for the same
purpose. For instance, knowing that the user goes to the gym every
afternoon could prevent errors.
8.1.2 Comparison with Smartphone-only LBA
A smartphone-only location-based authentication (LBA) system [41]
would accept the user correctly as long as the smartphone is with
him, it is on, and it has Internet connectivity. Moreover, it may re-
quire interaction with the user. Using the smartphone data obtained
from our ﬁeld studies, we estimate the FRR for such a system to
8.1% (4 rejections). These occurred when the user forgot/left his
phone at the ofﬁce when going to the gym.
Assuming the user’s smartphone has not been compromised, the
smartphone-only approach does not have false acceptances. How-
ever, compromising or stealing the smartphone leads to an 100%
FAR. In contrast, the true power of Icelus lies in numbers. For ex-
ample, in study S2 the user has two Trinkets; if the smartphone is
compromised by an adversary, the smartwatch and the remaining
devices enable us to still reject the attacker.
Let us consider the following attack scenario. The adversary
steals the user’s smartphone at a coffee shop, which is also a wallet
containing they access card. Alternatively, the adversary may have
cloned the user’s contactless access card earlier [15]. The user still
carries TrackR’s Bravo attached in his key chain and wearing his
smartwatch, which is connected to the shop’s WiFi. The adversary
then attempts to enter the user’s ofﬁce, while the user is still enjoy-
ing his coffee.
Simulation of Larger Scale
In the case of smartphone-only LBA, the adversary has obtained
all the tokens required to gain access. With Icelus, on the other
hand, the adversary can only attempt to reduce conﬁdence score of
the user’s Avatar to gain access. In Fig. 6, we plot the conﬁdence of
the user’s Avatar in study S2 after removing the smartphone from
him, that is, ignoring all data obtained through it. We notice that
the Conﬁdence Score of the user’s Avatar remains over the rejection
threshold for 80% of the day even without the smartphone, which
would reject prospective attackers.
8.1.3
To evaluate how our solution will fare in the future, when more
devices are included, we conducted a simulation with a larger num-
ber of Trinkets, Fragments, and Tokens. Our goal is to compare the
conﬁdence score of Avatars corresponding to the legitimate user,
and a set of devices that have been left unattended or compromised
(e.g., forgotten at home). As before, the adversary may have com-
promised devices physically or virtually to reduce the Conﬁdence
Score of the user’s Avatar. As the number of devices of a certain
type increases, we also normalize the Max Credit of each device
splitting it equally amongst all devices of the same type that the
user registers.
We present the results of these simulations in Fig. 7 The y-axis in
the plots measures Conﬁdence Score, while the x-axis corresponds
 0 0.2 0.4 0.6 0.8 100:0002:0004:0006:0008:0010:0012:0014:0016:0018:0020:0022:00User SleepingConfidence24 hour period WatchSafe Zone BonusReject ThresholdFigure 7: Comparing the Conﬁdence Score that can be achieved by Avatars corresponding to the legitimate user, and an unattended
cluster of devices. Our system’s robustness increases with higher device cardinality. Forcing the attacker to compromise multiple
devices. The X axis shows the number of devices not carried by the user, formatted as Trinkets #:Fragments #.
Period Zenfone 2
7.1%
0s
15s