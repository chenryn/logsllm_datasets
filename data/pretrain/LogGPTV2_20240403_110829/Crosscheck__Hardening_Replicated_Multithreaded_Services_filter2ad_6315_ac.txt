client requests. Upon arrival of , we validate local
results, and in the fault free case, forward them to the respective
clients.
V. PRELIMINARY RESULTS
As part of our preliminary evaluation, we were interested in
the overhead introduced by hardening a multithreaded key-value
store via CROSSCHECK. Thereby, we measured the overhead of
applying GOP to individual classes, and also when hardening
all relevant classes.
For our evaluation, we used MEMCACHED++ that is orig-
inally based on version 1.4.10 of memcached. For ordering
requests, we utilized the most recent version of the Spread
toolkit (v. 4.3.0). To simulate clients, we selected the memslap
benchmark, which is a part of libmemcached.
651
Description
Hashtable
Key-value container
Class
Assoc
Item
Items Management of items and statistics
Slab
Container for pre-allocated memory
Slabs Management of Slab instances
Fig. 4. GOP-hardened classes
All evaluations were performed on a cluster of four machines
with each a Core i7-3770 CPU (4 Cores at 3,4 GHz, supporting
8 parallel threads), equipped with 16 GB RAM and connected
over a switched gigabit network. Three machines were used for
hosting replicas, whereas the fourth machine was responsible
for generating client requests.
We selected a write-intensive workload where each client
performs 10.000 set requests with a key length of 100 B and a
value length of 400 B. To enable concurrent execution, each
MEMCACHED++ instance used four worker threads for handling
requests. As can be seen in Figure 5, we constantly increased
the workload by simulating more clients. The baseline of
our measurement builds a plain replicated version of MEM-
CACHED++ without generic object protection. Furthermore,
we individually hardened ﬁve classes (see Figure 4) with a
CRC32 error detection code. In Figure 5(b), we also evaluated
GOP with object state copy, thereby enabling a local recovery
from state corruption that are detected ahead of execution.
As can be seen in both ﬁgures the overhead for the individual
classes varies signiﬁcantly between 2% and 23%. The reasons
are twofold: The overhead greatly depends on the state objects
size of protected data as well as on the access pattern for the
individual object. For Items and Item both issues apply. The
size of these objects ranges from 300 B (Items) to 712 B (Item).
Furthermore, for each request one object of both classes is
checksummed around 40 to 80 times per request. However,
objects of type Assoc and Slab are much smaller and accessed
only a few times, hence they introduce only little overhead of
2% to 10% decrease in performance.
For the protection of all ﬁve classes the overhead sums up to
a performance decrease of 30% for 256 clients. The addition
of a local object state copy reduces the performance by another
9%, resulting in a 39% performance reduction.
However, these results can be optimized by further tailoring
GOP to ﬁt the demands of CROSSCHECK. So far, each time
objects are accessed, at least one checksum is generated. In
case of Items and Item this leads to a signiﬁcant overhead.
However, during the crosscheck, we only compare the most
recent generated checksums. Hence, instead of generating a
checksum, we could simply log (e.g. by using a dirty bit) if an
object is accessed. Then at the end of executing a request, but
before initiating the actual crosscheck, we generate checksums
for all logged objects. This way only one checksum is generated
for each object per request.
Unfortunately this approach would reduce our error
detection capabilities ahead of execution. To mitigate this
each class could be individually protected by the GOP. For
example, Assoc and Slab could be protected by CRC32 error
C
E
S
/
S
T
S
E
U
Q
E
R
K
C
E
S
/
S
T
S
E
U
Q
E
R
K
60
50
40
30
20
10
0
60
50
40
30
20
10
0
Baseline
Slabs
Slab
Items
Assoc
Item
All
32
64
128
256
(a) Without local object state copy
# CLIENTS
Baseline
Slabs
Slab
Items
Assoc
Item
All
32
64
128
256
# CLIENTS
(b) With local object state copy
Fig. 5. Overhead of generic object protection
detection code plus local copy while Items and Item could be
protected with the optimization described above. With these
optimizations we expect to decrease the overall performance
overhead far below the current level.
VI. RELATED WORK
Utilizing checksums to compare and synchronize replicas
in distributed system has been proposed in multiple contexts,
however support is usually either limited to persistent state [22],
[23] or does not consider state corruptions [24]. CROSSCHECK
focuses on hardening and recovering the in-memory state of
replicated services.
Correia et. al. [11] proposed an approach for hardening
distributed applications against arbitrary state corruptions by
means of redundant execution at the granularity of requests
inside of a single node. This way, state corruptions can be
contained at the node level and masked as crash faults. While
being effective for hardening distributed applications, this
approach demands a certain application structure to access
application state and effectively doubles memory and CPU
demand.
The approach of Behrens et. al. [12] can be seen as a
reﬁnement of [11]. It explicitly addresses the memory overhead
by saving checksums of an initial execution instead of a full
state copy. Furthermore, data access is intercepted and checked
via checksums at the level of memory pages. Behrens et. al.
[25] also propose the use of encoded processing via AN-coding.
Amongst other things this offers ﬁne-grained control-ﬂow
checks but comes attached with an computational overhead
652
of factor ﬁve. In comparison to the aforementioned systems,
CROSSCHECK achieves a similar fault-tolerance level, but
requires only moderate additional resources due to its tight
integration with SMR.
Furthermore, there is only limited work that considers faults
beyond crashes, and, at the same instance, allows multithreaded
execution. Instead of enforcing determinism, Kapritsos et al.
[26] cleverly batches requests to minimize concurrent access
to state objects. During parallel execution, if the replicas don’t
reach a consistent state, a revert with sequential re-execution
is performed. This introduces a signiﬁcant overhead when
state object access is shared by many requests as is the case
for management objects in our prototype. Same issues apply
to Kotla et al. [27] who enables the concurrent execution of
requests if they do not change shared state. This essentially
leaves the middle ground where services can freely utilize
threads but determinism is pro-actively persevered.
VII. CONCLUSIONS
CROSSCHECK builds an approach to tolerate arbitrary state
corruptions for implementing highly available multithreaded
services for data centers. The use of generic object protection
enables CROSSCHECK to harden state objects in a generic
and ﬂexible kind of fashion. Our initial evaluation based on
key-value store showed an overhead of 2% to 23% for the
different protected classes. Our next steps are performance
optimization, support for efﬁcient recovery, and performing a
fault-injection campaign to assess the achieved error coverage.
REFERENCES
[1] M. Burrows, “The chubby lock service for loosely-coupled dist. sys-
tems,” in Proc. of the 7th Symp. on Operating Systems Design and
Implementation, 2006, pp. 335–350.
[2] W. J. Bolosky, D. Bradshaw, R. B. Haagens, N. P. Kusters, and P. Li,
“Paxos replicated state machines as the basis of a high-performance data
store,” in Proc. of the 8th USENIX Conf. on Networked Systems Design
and Implementation, 2011.
[3] T. Kraska, G. Pang, M. J. Franklin, S. Madden, and A. Fekete, “Mdcc:
Multi-data center consistency,” in Proc. of the 8th ACM European Conf.
on Comp. Systems, 2013, pp. 113–126.
[4] A. A. Hwang, I. A. Stefanovici, and B. Schroeder, “Cosmic rays don’t
strike twice: Understanding the nature of dram errors and the implications
for system design,” SIGARCH Comp. Architecture News, vol. 40, no. 1,
pp. 111–122, 2012.
[5] V. Sridharan and D. Liberty, “A study of dram failures in the ﬁeld,” in
Proc. of High Performance Computing, Networking, Storage and Analysis
(SC), 2012, pp. 1–11.
[6] S. Y. Borkar, “Designing reliable systems from unreliable components:
the challenges of transistor variability and degradation,” IEEE Micro,
vol. 25, no. 6, pp. 10–16, 2005.
[7] M. Castro and B. Liskov, “Practical Byzantine fault tolerance and
proactive recovery,” ACM Transactions on Computer Systems, vol. 20,
no. 4, pp. 398–461, 2002.
[8] J. Yin, J.-P. Martin, A. Venkataramani, L. Alvisi, and M. Dahlin,
“Separating agreement from execution for Byzantine fault
tolerant
services,” in Proc. of the 19th Symp. on Operating Systems Principles,
2003, pp. 253–267.
[9] G. S. Veronese, M. Correia, A. N. Bessani, L. C. Lung, and P. Ver´ıssimo,
“Efﬁcient Byzantine fault tolerance,” IEEE Transactions on Computers,
2011.
[10] T. Wood, R. Singh, A. Venkataramani, P. Shenoy, and E. Cecchet, “ZZ
and the art of practical BFT execution,” in Proc. of the 6th EuroSys
Conf., 2011, pp. 123–138.
[11] M. Correia, D. G. Ferro, F. P. Junqueira, and M. Seraﬁni, “Practical
hardening of crash-tolerant systems,” in Proc. of the 2012 USENIX
Annual Technical Conf., vol. 12, 2012.
[12] D. Behrens, C. Fetzer, F. P. Junqueira, and M. Seraﬁni, “Towards
transparent hardening of distributed systems,” in Proc. of the 9th Work.
on Hot Topics in Dependable Systems, 2013, pp. 4:1–4:6.
[13] G. Kiczales, J. Lamping, A. Mendhekar, C. Maeda, C. V. Lopes, J.-M.
Loingtier, and J. Irwin, “Aspect-oriented programming,” in Proc. of the
Eleventh European Conf. on Object-Oriented Programming, 1997, pp.
220–242.
[14] R. Kapitza, M. Schunter, C. Cachin, K. Stengel, and T. Distler,
“Storyboard: optimistic deterministic multithreading,” in Proc. of the
6th Int. Work. on Hot Topics in System Dependability, 2010.
[15] O. Spinczyk and D. Lohmann, “The design and implementation of
AspectC++,” Knowledge-Based Systems, Special Issue on Techniques to
Produce Intelligent Secure Software, vol. 20, no. 7, pp. 636–651, 2007.
[16] F. B. Schneider, “Implementing fault-tolerant services using the state
machine approach: A tutorial,” ACM Comp. Survey, vol. 22, no. 4, pp.
299–319, 1990.
[17] L. Lamport, “The part-time parliament,” ACM Transaction Computer
Systems, vol. 16, no. 2, pp. 133–169, May 1998.
[18] Y. Amir, C. Danilov, M. Miskin-Amir, J. Schultz, and J. Stanton, “The
spread toolkit: Architecture and performance,” Johns Hopkins University,
Center for Networking and Dist. Systems (CNDS) Technical report CNDS-
2004-1, 2004.
[19] M. Hoffmann, C. Borchert, C. Dietrich, H. Schirmeier, R. Kapitza,
O. Spinczyk, and D. Lohmann, “Effectiveness of Fault Detection
Mechanisms in Static and Dynamic Operating System Designs,” in
Proc. of the 17th IEEE Int. Symp. on Object-Oriented Real-Time Dist.
Comp., 2014.
[20] C. Borchert, H. Schirmeier, and O. Spinczyk, “Generative software-
based memory error detection and correction for operating system
data structures,” in Proc. of the 43rd Annual IEEE/IFIP Int. Conf. on
Dependable Systems and Networks, 2013, pp. 1–12.
[21] P. Hunt, M. Konar, F. P. Junqueira, and B. Reed, “ZooKeeper: Wait-free
coordination for Internet-scale systems,” in Proc. of the 2010 USENIX
Annual Technical Conf., 2010, pp. 145–158.
[22] A. Tridgell and P. Mackerras, “The rsync algorithm,” 1996.
[23] M. Castro, R. Rodrigues, and B. Liskov, “Base: Using abstraction to
improve fault tolerance,” ACM Transaction Computer Systems, vol. 21,
no. 3, pp. 236–269, Aug. 2003.
[24] R. Kapitza, T. Zeman, F. J. Hauck, and H. P. Reiser, “Parallel State
Transfer in Object Replication Systems,” in Distributed Applications and
Interoperable Systems, vol. 4531, 2007, pp. 167–180.
[25] D. Behrens, S. Weigert, and C. Fetzer, “Automatically tolerating arbitrary
faults in non-malicious settings,” in Proc. of 6th Latin-American Symp.
on Dependable Comp., 2013, pp. 114–123.
[26] M. Kapritsos, Y. Wang, V. Quema, A. Clement, L. Alvisi, and M. Dahlin,
“All about eve: Execute-verify replication for multi-core servers,” in
Proc. of the 10th USENIX Conf. on Operating Systems Design and
Implementation, 2012, pp. 237–250.
[27] R. Kotla and M. Dahlin, “High throughput byzantine fault tolerance,”
in Proc. of the 2004 Int. Conf. on Dependable Systems and Networks,
2004, pp. 575–.
653