readable. Also, we found that app developers tend to avoid
obfuscating data-related modules (e.g., those containing GSON
objects) and third-party SDKs, since improper changes to these
program elements could easily introduce errors to program
execution or even cause a crash. As an example, GSON utilizes
reﬂection at runtime to dynamically map JSON objects to
classes, constructing properties based upon matching strings
discovered from the objects with keywords; this approach no
longer works when the string such as “model.name” is replaced
with “a.b” by ProGuard. Further, third-party frameworks (e.g.,
Inmobi [4]) and SDK interfaces are rarely obfuscated, to make
sure that the developers can easily incorporate them into her
app code.
C. Comparing with Prior Approaches
API-based labeling. As mentioned earlier (Section II), prior
work SUSI
[35] can automatically discover hundreds of
sources from various Android System APIs. However, it often
cannot determine whether a source is indeed sensitive. For
example, json.get(“password”) becomes related to sensitive
content only because its parameter reveals that the method
returns password.
ClueFinder is designed to identify such sensitive sources
from their context. In our research, we randomly selected 15
popular APIs and extracted 10,116 statements involving them
from 100 randomly chosen apps. Among all these statements,
ClueFinder detected 2,266 sensitive data sources. As a result,
over 77.6% (7,850) of statements which SUSI found turning
out to be false positives (not sensitive). Given the effectiveness
of ClueFinder that already discussed before (with 92.7% pre-
cision and 97.2% recall), the comparison result indicates that
our approach is much more effective in ﬁnding truly sensitive
data sources compared with SUSI.
elements (e.g. an input ﬁeld). However, these elements are
only a subset of private data sources in an app. In contrast,
ClueFinder is capable of ﬁnding all sensitive sources, including
not only UI elements but also imports of private data from
servers. In our study, from the aforementioned unknown set
with 100 randomly selected apps, we manually identiﬁed 892
unique UI elements related to private inputs (e.g., username
and password in UI). These elements are all the prior ap-
proaches could ﬁnd. Then, we ran ClueFinder over the 100
apps which reported 2,388 unique sensitive data sources. Our
further manual validation over these sources showed that in
most cases, ClueFinder identiﬁes all the UI sources. What’s
more, it identiﬁes 2 times more non-UI sources missed by
approaches like UIPicker and SUPOR in total.
Semantics-based taint tracking. Similar to ClueFinder, Bid-
Text also searches constant strings inside programs for sen-
sitive keywords. However, BidText is more focused on its
unique bi-directional taint analysis than semantics-based sen-
sitive source discovery. It does not work on variable, method
names, preﬁxes and abbreviations of keywords, nor does it
evaluate grammatical dependencies among semantics tokens
except the negative relation. In our research, by setting up
these two approaches with basically the same settings for
data-ﬂow analysis (we implemented an intra-process, ﬂow-
sensitive analysis with sinks to HTTP network), we compared
our implementation of ClueFinder with the released version of
BidText [2], in terms of precision, coverage and performance
in discovering sensitive sources.
As Table III shows, among the 100 popular apps in the
unknown set, ClueFinder reported 50 (44.6%) more sensitive
sources than BidText (162 true positives vs. 112), resulting
in a much higher coverage than BidText. This is mainly
due to ClueFinder’s in-depth NLP analysis for understanding
code semantics, as well as the utilization of code structure
for locating private data. For example, ClueFinder found 32
sensitive sources using semantic information from method
names, which BidText could not handle. Also, ClueFinder has
a more detailed knowledge base (characterized by not only
keywords but also meaningful preﬁxes and abbrievations), and
its semantic locating mechanism (in Section III-B ) enables
it to capture more privacy-related semantics: e.g. “addr” for
“address”. BidText utilizes only a ﬁxed keyword set, and
matches these keywords from app code by human-deﬁned reg-
ex expressions.
Also, ClueFinder reduces the false positive rate compared
with BidText (8.5% vs. 14.5%), because our approach utilizes
more grammatical relations and program structures to control
false positives, while BidText only drops the labled strings
involving negative description. Other strings, such as 1, 2, 3 in
Table II, will be falsely reported. Further, since BidText only
evaluates constant strings and most of them do not contain
complicated expressions, our approach only lowers down the
false positive rate by 6% compared with the prior approach. It
is important to note that the major strength of ClueFinder is it
expands the types of sensitive sources that can be discovered.
In this perspective, the advantage of our approach is signiﬁcant,
detecting 44.6% more true positives.
UI-based labeling. Prior approaches like UIPicker [32] and
SUPOR [25] can identify sensitive data from an app’s UI
Finally, ClueFinder outperforms BidText in performance
(1.86 times faster), due to its lightweight semantics-based
9
leakage analysis, which largely avoids the expensive data-ﬂow
analysis. In the meantime, we acknowledge that BidText’s
unique bi-directional dataﬂow technique could help it more
accurately track some information leaks ClueFinder misses,
given that the focus of our approach is just sensitive source
discovery.
TABLE III.
COMPARISON WITH BIDTEXT
BidText ClueFinder
Detected sensitive data
Num. of false positives
Avg. Analysis Time (Sec)
Precision
131
19
97
83.5%
177
15
55
91.5%
V. LARGE-SCALE LEAKAGE STUDY
In this section, we report our measurement study over
445,668 real-world apps, which analyzed their privacy leak-
age to third-party libraries. Note that although ClueFinder is
capable of detecting all kinds of private data within an given
app code, here we just focus on the ﬁndings related to the
sources missed by the prior research, since more conventional
sources, such as API-based imports of IMEI, IMSI and GPS
locations, have already been studied before [22], [37], [40].
Our research brings to light the pervasiveness of the exposure
risk (disclosing sensitive user data to third-party libraries) and
interesting cases never reported before.
A. Measurement Settings
Exposure risk. As mentioned earlier (Section I),
in our
measurement study, we looked for the exposure risk, that is,
leaks of sensitive user data to third-party libraries. We focus
on this risk instead of the library’s export of sensitive data
to the Internet because the latter is more difﬁcult to detect
through a static analysis (necessary for evaluating a large
number of apps), in terms of performance and accuracy. Also,
once an untrusted library obtains private data, it often can
manage to send the data out through cover channels without
getting caught. Therefore, in our study, we just conservatively
considered that information leaks could happen whenever the
untrusted library gets access to the sensitive data.
App gathering. As Table IV shows, our datasets are crawled
from 2 different Android markets: the ofﬁcial Google-Play
market and a third-party market (Tencent App Store). Each app
in these datasets has a unique MD5-Hash to make sure there’s
no overlapping between different datasets. Among them, apps
in the Play-15 dataset were selected according to the top app
list provided by the Google-Play website, and those in the other
3 datasets were randomly crawled from their markets. In this
way, we can better understand how data leaks to third-party
libraries happen in both popular and ordinary apps.
Implementation for Leakage Tracker.
Speciﬁcally, serving the purpose of detecting privacy leak-
age to third-party libraries, Leakage Tracker in ClueFinder
(Section III-C) went
the invocation statements
reported by its previous module Semantic Checker, and con-
ducted a inter-procedure data-ﬂow analysis over the identiﬁed
data objects. Meanwhile, it picked out those statements either
through all
inside a third-party library or calling the library’s methods.
As an example in Figure 2, if the method contain HashMap
object “basicInfo” ﬂows to an API of a third-party library,
immediately we conclude that the user’s location data are
exposed to the library by this statement.
To this end, we checked whether the package or class
name of the identiﬁed statement
is different from that of
the app, using its ﬁrst two preﬁxes, e.g. com.facebook for
com.facebook.message, which indicates that the statement is
either inside a third-party library’s code or involves the li-
brary’s method. Although this treatment is a bit coarse (e.g.,
which cannot distinguish the ad library com.facebook.ads from
the analytic one com.facebook.analytic), it is still informative
for us to determine whether private data have been accessed
by a third-party library or by the app itself. Further we veriﬁed
that such a statement is not dead code through a standard
reachability analysis: that is, building call-graphs from the
app’s entry points to conﬁrm that indeed the target method
invocation can be reached. Note that this treatment can miss
some information leaks, however, it is sufﬁciently accurate for
detecting most leaks to third-party libraries because most of
such invocations could be the interfaces between a library and
its hosting app, and also lightweight, which is important for a
large-scale study.
We utilized the experimental setting described in Sec-
tion IV for the measurement study. During the experiments,
each dataset was processed by 8 concurrently-running pro-
cesses, with a 20-minute timeout set for each app. Overall,
our 32-core server took 710 hours to go through all 445,668
apps, with 45.88 seconds each on average. Among all these
apps, 32,533 (7.3%) could not be successfully analyzed within
the timeout window.
B. Measurement Results
Landscape. As can be seen from Table IV, among all 445,668
apps, ClueFinder totally discovered 118,296 (26.5%) leaking
private user data to 3,502 third-party libraries2. On average,
each app exposes 8.07 data items (e.g., an identiﬁers, full
name, location, etc.) to 1.97 libraries. This indicates that such
information exposure is indeed pervasive (over 26.5% of all
the apps analyzed). For example, when the user logs into an
app with her Facebook account, her Facebook proﬁle could
be sent to an ad library for marketing, and to an analytical
library to track her online activities. Also, for all discovered
3,502 libraries accessing user’s private data, averagely each
of them collects 2.45 data items, including not only different
identiﬁers such as Facebook id, but also other information like
her various attributes, for the purpose like targeted advertising.
Particularly, the Play-15 dataset, with selected 13,500 most
popular Google-Play apps, was found to have 39.9% of its apps
leaking out user data. As illustrated in Table V, such data are
2To avoid including outliers (e.g., an obfuscated package name) as a
third-party library, we ﬁrst exclude those extremely short package names
(e.g., com.a.ab) which obviously to be obfuscated. Meanwhile, we deﬁne a
threshold=10 to decide whether a package name surely presents a third-party
library. The threshold is the number of total appearances of a package name
in our whole dataset. Also, we exclude common social network libraries (e.g.,
Facebook, Twitter, Weibo, etc.) since most of private data in such libraries are
originated from themselves.
10
TABLE IV.
OVERALL LEAKAGE STATISTICS
DataSet
Collect Time
Nov.15 - Dec.15
Jul.16 - Aug.16
Feb.15 - Apr.15
Jun.16 - Jul.16
Nov.15 - Aug.16
Total Apps
13,500
71,686
169,051
191,431
445,668
Affected Apps
# Apps % Apps Avg.Items/App Avg.Libs/App
5,385
16,310
44,392
52,209
118,296
39.9%
22.8%
26.3%
27.3%
26.5%
2.83
1.32
1.64
2.1
1.97
7.6
5.26
7.55
9.53
8.07
Affected Libs
# Libs Avg.Items/Lib
709
1,011
2,315
3,097
3,502
2.45
2.36
2.43
2.33
2.39
Play-2015
Play-2016
Tencent-2015
Tencent-2016
Total
uniformly distributed across several categories (user attributes,
user identiﬁers, account information and location data), with
each app exposing 7.6 data items to 2.83 third-party libraries
on average. Compared with randomly selected apps in Play-
16, these top apps apparently expose more information. This
indicates that popular apps extensively disclose all kinds of pri-
vate user information to multiple libraries within a single app.
Further, by manually looking into the code of 100 randomly
selected apps identiﬁed by ClueFinder, we found over half of
the ﬂagged method invocations (53.1%) are related to HTTP
connections (e.g., an HTTP post where its parameters contain
privacy-related contents). Also, our runtime veriﬁcation by
intercepting the network trafﬁc of these apps conﬁrmed that 59
out of 100 apps are indeed leaked private data to the servers
of different third-party libraries. Note that the actual leakage
scale should be higher than what we observed. We didn’t see
the trafﬁc for the other 41 apps since most of them require
further manual steps, e.g., logging in or even pre-registering an
account. Additionally, since some libraries encode or encrypt
their trafﬁc, the leakage cannot be directly conﬁrmed even
when the app was well-explored.
TABLE V.
LEAKAGE RESULTS BY PRIVACY CATEGORY IN PLAY-15
DATASET
Category
Apps (%)
Avg.Items
Libs
Avg.Libs/App
User Attributes
Account
User Identiﬁers
Location Data
Total
4,928 (36.5%)
2,444 (18.1%)
5,157 (38.2%)
4,307 (31.9%)
5,385 (39.9%)
4.19