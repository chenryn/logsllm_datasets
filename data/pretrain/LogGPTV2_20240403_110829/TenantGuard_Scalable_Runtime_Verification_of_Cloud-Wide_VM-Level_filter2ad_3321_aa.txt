title:TenantGuard: Scalable Runtime Verification of Cloud-Wide VM-Level
Network Isolation
author:Yushun Wang and
Taous Madi and
Suryadipta Majumdar and
Yosr Jarraya and
Amir Alimohammadifar and
Makan Pourzandi and
Lingyu Wang and
Mourad Debbabi
TenantGuard: Scalable Runtime Veriﬁcation of
Cloud-Wide VM-Level Network Isolation
Yushun Wang∗, Taous Madi∗, Suryadipta Majumdar∗, Yosr Jarraya†,
Amir Alimohammadifar∗, Makan Pourzandi†, Lingyu Wang∗ and Mourad Debbabi∗
Email: {yus wang, t madi, su majum, ami alim, wang, debbabi}@encs.concordia.ca
∗CIISE, Concordia University, Canada
†Ericsson Security Research, Ericsson Canada
Email: {yosr.jarraya, makan.pourzandi} @ericsson.com
Abstract—Multi-tenancy in the cloud usually leads to security
concerns over network isolation around each cloud tenant’s
virtual resources. However, verifying network isolation in cloud
virtual networks poses several unique challenges. The sheer size
of virtual networks implies a prohibitive complexity, whereas
the constant changes in virtual resources demand a short re-
sponse time. To make things worse, such networks typically
allow ﬁne-grained (e.g., VM-level) and distributed (e.g., security
groups) network access control. Those challenges can either
invalidate existing approaches or cause an unacceptable delay
which prevents runtime applications. In this paper, we present
TenantGuard, a scalable system for verifying cloud-wide, VM-
level network isolation at runtime. We take advantage of the
hierarchical nature of virtual networks, efﬁcient data structures,
incremental veriﬁcation, and parallel computation to reduce the
performance overhead of security veriﬁcation. We implement our
approach based on OpenStack and evaluate its performance both
in-house and on Amazon EC2, which conﬁrms its scalability and
efﬁciency (13 seconds for verifying 168 millions of VM pairs).
We further integrate TenantGuard with Congress, an OpenStack
policy service, to verify compliance with respect to isolation
requirements based on tenant-speciﬁc high-level security policies.
I.
INTRODUCTION
The widespread adoption of cloud is still being hindered
by security and privacy concerns, especially the lack of trans-
parency, accountability, and auditability [1]. Particularly, in
a multi-tenant cloud environment, virtualization allows opti-
mal and cost-effective sharing of physical resources, such as
computing and networking services, among multiple tenants.
On the other hand, multi-tenancy is also a double-edged
sword that often leads cloud tenants to raise questions like:
“Are my virtual machines (VMs) properly isolated from other
tenants, especially my competitors?” In fact, network isolation
is among the foremost security concerns for most cloud
tenants [2], [3], and cloud providers often have an obligation to
provide clear evidences for sufﬁcient network isolation [4], [5],
either as part of the service level agreements, or to demonstrate
Permission  to  freely  reproduce  all  or  part  of  this  paper  for  noncommercial 
purposes  is granted  provided  that copies  bear this  notice  and the full  citation 
on the ﬁrst page. Reproduction  for commercial  purposes is strictly prohibited 
without the prior written consent of the Internet Society, the ﬁrst-named author 
(for  reproduction  of  an  entire  paper  only),  and  the  author’s  employer  if  the 
paper  was  prepared  within  the  scope of employment.
NDSS ’17, 26 February  - 1 March 2017,  San Diego,  CA, USA
Copyright  2017 Internet  Society,  ISBN 1-891562-46-0
http://dx.doi.org/10.14722/ndss.2017.23365
compliance with security standards (e.g., ISO 27002/27017 [6],
[7] and CCM 3.0.1 [8]).
Verifying network isolation potentially requires checking
that VMs are either reachable or isolated from each other
exactly as speciﬁed in cloud tenants’ security policies. In
contrast to traditional networks, virtual networks pose unique
challenges to the veriﬁcation of network isolation.
- First, the sheer size of virtual networks inside a cloud
implies a prohibitive complexity. For example, a decent-
size cloud is said to have around 1,000 tenants and
100,000 users, with 17 percent of users having more than
1,000 VMs [9], [10]. Performing a cloud-wide veriﬁcation
of network isolation at the VM-level for such a cloud
with potentially millions of active VM pairs using existing
approaches results in a signiﬁcant delay (e.g., Plotkin et
al. [11] take 2 hours to verify 100k VMs). Most existing
techniques in physical networks are not designed for such
a scale, and will naturally suffer from scalability issues
(a detailed review of related work is given in Section II)
and quantitative comparison with state-of-the-art work is
provided in Section VI.
- Second, the self-service nature of a cloud means virtual
resources in a cloud (e.g., VMs and virtual routers or
ﬁrewalls) can be added, deleted, or migrated at any
time by cloud tenants themselves. Consequently, tenants
may want to verify the network isolation repeatedly or
periodically at runtime, instead of performing it only
once and ofﬂine. Moreover, since any veriﬁcation result
will likely have a much shorter lifespan under such a
constantly changing environment, tenants would naturally
expect the results to be returned in seconds, instead of
minutes or hours demanded by existing approaches [11].
- Third, a unique feature of virtual networks, quite unlike
that in traditional networks, is the ﬁne-grained and dis-
tributed nature of network access control mechanisms. For
example, instead of only determined by a few physical
routers and ﬁrewalls, the fate of a packet traversing virtual
networks will also depend on the forwarding and ﬁltering
rules of all the virtual routers, distributed ﬁrewalls (e.g.,
security groups in OpenStack [12]), and network address
translation (NAT), which are commonly deployed in a
very ﬁne-grained manner, such as on individual VMs.
Unfortunately, most existing works fail to reach such a
granularity since they are mostly designed for (physical)
network-level veriﬁcation (i.e., between IP preﬁxes) in-
stead of VM-level veriﬁcation with distributed ﬁrewalls.
Motivating Example. Figure 1 shows the simpliﬁed view of
a multi-tenant cloud environment.1 The solid line boxes depict
the physical machines (N compute nodes and one network
node) inside which are the VMs, distributed ﬁrewalls (security
groups), and virtual routers or switches. The virtual resources
of different tenants (e.g., VM_A1 of Alice, and VM_B2 of Bob)
are depicted by different ﬁlling patterns.
Alice’s resources
Bob’s resources
External Network
VM
Security group
Virtual router
Compute node 1
VM_A1
Priv: 10.0.0.12
Pub: 1.10.0.75
Compute node N
VM_B2
Priv: 19.0.0.30
Pub: 1.10.1.12
Allow src
1.10.1.12
VLAN 200
. . .
Allow src
1.10.0.75
VLAN 201
VLAN 100
VLAN 103
VLAN 300
VLAN 103
Network node
Virtual Switch
R_A1
R_A2
R_A3
R_B1
Virtual Switch
Virtual Switch
Virtual Switch
VNet 101
VNet 110
VNet 200
VNet 101
VNet 110
VNet 200
Fig. 1. An Example of a Multi-Tenant Cloud
- Network isolation may be compromised through ei-
ther unintentional misconﬁgurations or malicious attacks
exploiting implementation ﬂaws. For example, assume
the current security policies of tenants Alice and Bob
allow their VMs VM_A1 and VM_B2 to be reach-
able from each other, as reﬂected by the two secu-
rity group rules allow src 1.10.1.12 and allow
src 1.10.0.75. Now suppose Alice would like to
stop accesses to her VM VM_A1, and therefore she deletes
the rule allow src 1.10.1.12 and updates her high
level deﬁned security policy accordingly. However, Alice
is not aware of an OpenStack vulnerability OSSA 2015-
021 [13], which causes such a security group change to
silently fail to be applied to the already running VM
VM_A1. At the same time, a malicious user of tenant
Bob exploits another vulnerability OSSA 2014-008 [14]
by which OpenStack (Neutron) fails to perform proper
authorization checks, allowing the user to create a port
on Alice’s virtual router R_A3 and subsequently bridges
that port to his own router R_B1. Consequently, Alice’s
VM, VM_A1, will remain to be accessible by Bob, which
is a breach of network isolation.
- To detect promptly such a breach of network isolation, the
challenge Alice faces is again threefold. First, assume the
cloud has 25, 000 active VMs among which Alice owns
2, 000. Since all those VMs may potentially be the source
of a breach, and each VM may have both a private IP and
a dynamically allocated public IP, Alice potentially has to
verify the isolation between 25, 000 × 2, 000 × 2 = 100
millions of VM pairs. Second, despite such a high com-
plexity, Alice wants to schedule the veriﬁcation to be
1To make our discussions more concrete, the examples will mostly be based
on OpenStack, and Section VII discusses the applicability of our approach to
other cloud platforms.
performed every ﬁve minutes and is expecting to see the
results within a few seconds, since she knows the result
may only be valid until the next change is made to the
virtual networks (e.g., adding a port by Bob). Finally, to
perform the veriﬁcation, Alice must collect information
from heterogeneous data sources scattered at different
locations (e.g., routing and NAT rules in virtual routers,
host routes of subnets, and ﬁrewall rules implementing
tenant security groups).
In this paper, we present TenantGuard, a scalable system
for verifying cloud-wide, VM-level network isolation at run-
time, while considering the unique features of virtual networks,
such as distributed ﬁrewalls. To address the aforementioned
challenges, our main ideas are as follows. First, TenantGuard
takes advantage of the hierarchical structure found in most
virtual networks (e.g., OpenStack includes several abstraction
layers organized in a hierarchical manner,
including VM
ports, subnets, router interfaces, routers, router gateways, and
external networks) to reduce the performance overhead of
veriﬁcation. Second, TenantGuard adopts a top-down approach
by ﬁrst performing the veriﬁcation at the (private and public) IP
preﬁx level, and then propagating the partial veriﬁcation results
down to the VM-level through efﬁcient data structures with
constant search time, such as radix binary tries [15] and X-
fast binary tries [16]. Third, TenantGuard supports incremental
veriﬁcation by examining only parts of the virtual networks
affected by a conﬁguration change. Finally, TenantGuard
leverages existing cloud policy services to check isolation
results against tenant-speciﬁc high-level security policies. The
following summarizes our main contributions:
- We propose an efﬁcient cloud-wide VM-level veriﬁcation
approach of network isolation with a practical delay for
runtime applications (13 seconds for verifying 25, 246
VMs and 168 millions of VM pairs, as detailed in
Section VI).
- We devise a hierarchical model for virtual networks
along with a packet forwarding and ﬁltering function to
capture various components of a virtual network (e.g.,
security groups, subnets, and virtual routers) and their
relationships.
- We design algorithms that leverage efﬁcient data struc-
tures, incremental veriﬁcation, and an open source parallel
computation platform to reduce the veriﬁcation delay.
- We implement and integrate our approach into Open-
Stack [12], a widely deployed open source cloud man-
agement system. We evaluate the scalability and efﬁciency
of our approach by conducting experiments both in-house
and on Amazon EC2.
- We further integrate TenantGuard into Congress [17], an
OpenStack policy checking service, in order to check the
compliance of isolation results against tenants’ predeﬁned
high-level security policies.
The remainder of this paper is organized as follows.
Section II reviews the related work. Section III describes the
threat model and virtual network model. Section IV discusses
our system design and implementation. Section V provides
details on TenantGuard’s integration into OpenStack and Sec-
2
tion VI gives experimental results. Section VII discusses the
adaptability and integrity preservation. Section VIII discusses
limitations, provides future directions, and concludes the paper.
II. RELATED WORK
Table I summarizes the comparison between existing works
on network reachability veriﬁcation and TenantGuard. The ﬁrst
column divides existing works into two categories based on
the targeted environments, i.e., either cloud-based networks or
non-cloud networks. The second and third columns list existing
works and indicate their veriﬁcation methods, respectively. The
next column compares those works to TenantGuard according
to various features, e.g., the support of parallel implementa-
tion, incremental veriﬁcation, NAT, and all pairs reachability
veriﬁcation (which is the main target of TenantGuard). The
next two columns respectively compare the scope of those
works, i.e., whether the work is designed for physical or virtual
networks, and whether it addresses control or data plane in
such networks. Note that a L3 network is composed of a
control plane for building the network typology and the routing
tables based on various routing protocols (e.g., OSPF, BGP),
and a data plane for handling packets according to the built
routing tables. The last two columns show the size of input
and veriﬁcation time, respectively, as reported in those papers.
In summary, TenantGuard mainly differs from the state-
of-the-art works as follows. First, TenantGuard performs ver-
iﬁcation at a different granularity level (i.e., all-pair VM-
level vs single-pair router-level). Second, TenantGuard is more
scalable (e.g., verifying 100k VMs within 17mins). Finally,
TenantGuard employs custom algorithms instead of relying on
existing veriﬁcation tools (e.g., [11], [27], [29], [28]), which
enables TenantGuard to more efﬁciently deal with complexity
factors speciﬁc to the cloud network infrastructure such as a
large number of VMs, longer routing paths (number of hops),
and increased number of security rules.
Non-Cloud Network Veriﬁcation. In non-cloud networks,
several works (e.g., [30], [20], [18], [21], [19], [22], [23])
propose data plane analysis approaches, while others propose
control plane analysis (e.g., [25], [24], [26]). Some existing
works (e.g., [30], [20], [18]) address non-virtualized physical
networks. Speciﬁcally, Xie et al. [30] propose an automated
static reachability analysis of physical IP networks based on a
graph model. Anteater [20] and Hassel [18] detect violations
of network invariants such as absent forwarding loops. While
those works are successful for verifying enterprise and campus
networks, they cannot address challenges of large scale virtual
networks deployed in the cloud with hundreds of thousands
of nodes. For instance, Hassel [18] needs 151 seconds to
compress forwarding tables before spending an additional 560
seconds in verifying loop-absence for a topology with 26
nodes.
Other works (e.g., [21], [19], [22]) propose approaches
for virtualized networks. VeriFlow [21], NetPlumber [19]
(extension of [18]), and AP veriﬁer [22] outperform previ-
ous works by proposing a near real-time veriﬁcation, where
network events are monitored for conﬁguration changes, and
veriﬁcation is performed only on the impacted part of the
network. Those works propose query-based network invariants
veriﬁcation between a speciﬁc pair of source and destination
nodes. In order to cover all-pairs, the total number of queries
would grow signiﬁcantly. This hinders the scalability of these
approaches to tackle large cloud data centers. Furthermore,
most of these works consider routers/switches as the source
and destination nodes for their veriﬁcation. NetPlumber and
VeriFlow offer similar runtime performance. For a network
of 52 nodes, Netplumber [19] checks all-pairs reachability
in 60 seconds, whereas a single-machine implementation of
TenantGuard takes only 4.6 seconds to verify a network of
4,300 nodes (see Figure 10). Libra [23] uses a divide and
conquer technique to verify forwarding tables in large networks
for subnet-level reachability failures. While Libra relies on the
assumption that rules in switches consist of preﬁxes aggre-
gating many subnets, we additionally deal with more speciﬁc
rules (longer preﬁxes) by running the preorder traversal on the
radix binary tries.
Works designed for control plane veriﬁcation in physical
networks like ARC [24], Batﬁsh [25] and ERA [26], if applied
to the cloud, would face the difﬁculty that (unlike physical
networks) routing rules and ACLs for tenants’ private virtual
networks are not generated by the control plane.
Network Veriﬁcation for Cloud Deployments. There are
several works (e.g., [27], [11], [31], [32], [33], [28]) ver-
ifying the virtualized infrastructure in the cloud. Most of
those solutions focus on verifying conﬁguration correctness
of virtualization infrastructures in terms of structural prop-
erties (e.g., Cloud Radar [28]), which is different from the
properties targeted by TenantGuard. NoD [27], SecGuru [34]
and their successor (Plotkin et al. [11]) are the closest works
to TenantGuard, as they can check all-pairs reachability in
physical networks for large cloud data centers. NoD is a
logic-based veriﬁcation engine that has been designed for
checking reachability policies using Datalog deﬁnitions and