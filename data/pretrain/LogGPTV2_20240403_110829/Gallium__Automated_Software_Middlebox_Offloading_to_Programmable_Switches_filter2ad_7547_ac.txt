′ ⇝∗
′ ⇝∗
′ ⇝∗
∧ pre ∈ L(S
′ ⇝∗
,(S
′
(4) ∀S, S
S ∧ post (cid:60) L(S)) =⇒ post (cid:60) L(S
′)) =⇒ pre (cid:60) L(S)
S ∧ pre (cid:60) L(S
′ access same global state
S ∧ S, S
′)
′)) =⇒ pre (cid:60) L(S)
S ∧ S, S
′ access same global state
∧ post ∈ L(S)) =⇒ post (cid:60) L(S
′)
S =⇒ L(S) = {non_off}
(5) ∀S, S ⇝∗
The first two rules ensure that the partitions are consistent with
the dependencies. The third and fourth rules are required due to
the P4 language’s limitation that a global state can only be accessed
once inside the switch pipeline. In particular, if there is some global
state accessed in multiple different program locations, then at most
one of the statements can be executed on the switch.2 The last
rule prevents the offloading of statements that appear in a loop
body as P4 does not support loops. Gallium repeatedly applies
these rules to eliminate labels until no label can be further removed.
This algorithm always converges as the total number of labels
monotonically decreases and terminates when the constraints are
satisfied for every pair of statements in the dependency graph.
4.2.2 Satisfying Resource Constraints The labels assigned
to each statement indicate the partitions a statement can be assigned
to, given the dependencies but without considering the resource
constraints. We consider several types of resource constraints. We
notice that there are two types of state a middlebox needs to store:
per-packet state and global state. The per-packet state is pieces of
information whose lifetimes only last during the processing of a
2The third and fourth rules can be relaxed if the switch supports a disaggregated RMT
architecture [8].
switch does not exceed the size of the switch memory.
single packet, such as thehash32 variable inMiniLB. The global state
has to be maintained across all packets, such as the map variable in
MiniLB.
We need to enforce the following resource constraints:
• Constraint 1: The total size of the global state maintained by the
• Constraint 2: The length of the longest dependency chain in the
• Constraint 3: Each element of the global state maintained on the
• Constraint 4: The total size of the per-packet state does not exceed
• Constraint 5: The additional per-packet information transferred
offloaded code cannot exceed the switch’s pipeline depth.3
switch can only be accessed once during packet processing.
the maximum allowed per-packet metadata.
between the server and the switch is bounded.
The first, second, and fourth constraints are due to the limited
memory and computational resources on a programmable switch.
The third one reflects the limited expressiveness of the pipeline
architecture in traditional P4 devices; match action tables can only
be accessed once during packet processing to ensure efficient packet
processing at line rate. The last one is because the Ethernet frame
size is limited, and we want to use a large fraction of the frame
size to deliver actual packet content. We set this constraint to be
20 bytes.
We can meet all of the five constraints by moving more of the
code to the non-offloaded partition. (Note that executing all of the
code on the server trivially satisfies the constraints.) Gallium first
deals with Constraints 1, 2, and 3. Because once Constraints 1, 2,
and 3 are met, moving more code to the non-offloaded partition
never violates them again. For (1) and (2), Gallium first computes
the following dependency distance metric of various statements
from both the beginning and the end of the program. The depen-
dency distance between two program points is the length of the
longest dependency chain connecting the two points. Given a pro-
grammable pipeline with k stages, it removes “pre” labels from all
statements that are at a dependency distance of greater than k from
the program’s entry point and “post” labels from all statements that
are at a dependency distance of greater than k from the program’s
3We use a conservative constraint on the length, as the actual number of operations
that could be performed on the switch is embedded in the P4 compiler and is not
publicly available. We choose a conservative value based on empirical experiments.
288
Gallium: Automated Software Middlebox Offloading to Prog. Switches
SIGCOMM ’20, August 10–14, 2020, Virtual Event, NY, USA
exit point. This transformation helps us satisfy Constraint 2. Gal-
lium then gradually removes “pre” labels from statements in the
reverse source program order and “post” labels from statements in
the source program order until Constraint 1 is satisfied.
For Constraint 3, Gallium uses an exhaustive search to find the
placement that maximizes the number of statements on the pro-
grammable switch. For each global state, Gallium first locates all
the accesses to the state that are labeled with pre (or post). It then
enumerates all possible placements of those accesses where only
one of them is executed on the switch. Gallium computes the num-
ber of statements that could be put on a programmable switch in
each case and choose the placement with the maximum number of
statements.
Gallium then moves more code to the non-offloaded partition,
performing a variable liveness test after each removal to determine
the amount of program state that needs to be transferred across
partition boundaries, and repeats this until the partitioned code sat-
isfies Constraints 4 and 5. Each time a statement is moved, Gallium
runs the label-removing algorithm to ensure that the dependency
constraints are met.
However, note that moving code from the offloaded partition
does not always reduce the data that has to be transferred to the
non-offloaded partition. For example, moving an integer addition
from the switch to the server requires the offloaded code to send
two integers to the middlebox server instead of one). Finding the
minimal set of code that, when moved to the server, could satisfy
Constraint 5, requires enumerating all possible combinations of
code movements. Gallium chooses to use a greedy approach: It
tries to move code to the non-offloaded partition based on a fixed
topological order of the data dependencies. This heuristic will give
us a sub-optimal result when there are multiple branches in the
offloaded code. For instance, the greedy approach only checks the
second branch after the first branch is all removed, instead of con-
sidering all possible orders of moving code fragments. Nevertheless,
it only requires one linear scan of the offloaded code, and therefore,
it can find a code partition that satisfies Constraints 4 and 5 in a
reasonable amount of time.
Gallium assigns a partition for each statement by looking at the
labels. When a statement has both “pre” and “post” labels, Gallium
assigns the statement to the pre-processing partition. When a state-
ment has the “post” label but not the “pre” label, Gallium assigns it
to the post-processing partition. The rest of the code is assigned to
the non-offloaded partition. Gallium then splits the input program’s
control flow graph (CFG) into separate CFGs that correspond to
the three partitions. Figure 4 shows the resulting CFGs for MiniLB.
4.3 Code Generation and Runtime Execution
We now describe the code generation process and the mechanisms
used for communicating state between the switch and the server.
First, we explain how we transform the CFGs of the pre- and post-
processing partitions to a P4 program. For the non-offloaded par-
tition, Gallium needs to convert the corresponding CFG back to
C++. Transforming from a CFG to C++ is easy because C++ is very
expressive, and we omit the details for this transformation. Second,
we describe how the temporary state can be communicated in-band
by customizing the packet format used between the switch and the
server. Third, we detail the runtime mechanisms for synchronizing
global state and how we can provide run-to-completion semantics
for concurrent packet processing.
4.3.1 Mapping CFG to P4 We now describe how we map a
CFG to a P4 program. Figure 6 shows how we map different states
and instructions in the CFG to corresponding P4 primitives.
The per-packet state, such as temporary variables, are mapped
to metadata fields in the scratchpad memory. Since the amount of
metadata that can be allocated is less than 100 bytes to conserve
on scratchpad memory, Gallium records when temporary variables
are first and last used. Gallium reuses the memory consumed by
variables that are no longer useful. In MiniLB, key and bk_addr are
temporary variables.
For the global state, Gallium chooses different representations
based on the access pattern. States that are accessed exclusively
by the switch will be maintained on the switch if there is a P4
realization of the state. Gallium supports two types of global state
on the programmable switch: global variables and maps. Gallium
maps these two types of switch state into P4 match-action tables
and P4 registers, respectively. Note that Gallium choose to use P4
registers for global variables only if the switch alone accesses the
state. Similarly, states that are exclusively accessed by the server
are represented with the same data structure as the original pro-
gram. For the program state accessed by both the switch and the
server, Gallium maintains a copy of the state on both devices. State
replication enables faster access but complicates updates, as we
will discuss later. In MiniLB, map is a HashMap in the input mid-
dlebox, and it is offloaded as a P4 match-action table. Because a
C++ HashMap can be unbounded in size, but programmable switches
have a limited amount of memory, Gallium requires a middlebox
developer to annotate a maximum size for each HashMap that the
developer wishes to offload.
Once states are mapped to their P4 counterparts, Gallium start
to maps each instruction to P4. Branches, packet header accesses,
and ALU operations are directly mapped to their P4 counterparts.
Map lookups in the input middlebox program are mapped to P4
match-action table lookups. In MiniLB, map.find(&key) is mapped
to a P4 table lookup.
We also combine the pre- and post-processing partitions into a
single P4 program. Gallium includes all the match-action table and
register definitions from the two partitions. The instructions from
the two partitions are also placed in the combined P4 program. To
determine which partition should execute when receiving a packet,
Gallium creates a match-action table that matches on the ingress
interface of the packet at the beginning of the processing pipeline. If
the packet is coming from the interface connected to the middlebox
server, Gallium invokes the post-processing partition. Otherwise,
the pre-processing partition handles the packet.
4.3.2 Communicating temporary state between the switch
and the server Some temporary state has to be communicated be-
tween the switch and the server. Gallium transmits this state along
with the packet data. We determine the packet format for packets
going from the pre-processing partition to the non-offloaded parti-
tion and from the non-offloaded partition to the post-processing
partition. Gallium does a variable liveness test on the partition
boundary to decide what variables need to be transferred across
289
SIGCOMM ’20, August 10–14, 2020, Virtual Event, NY, USA
Kaiyuan Zhang, Danyang Zhuo, and Arvind Krishnamurthy
Ether. Header
E
IP Header
TCP Header
. . .
bk_addr == NULL
hash32
32
0
33
(a) Packet from the pre-processing to the offloaded partition
Ether. Header
IP Header
. . .
bk_addr == NULL
33
32
TCP Header
backends[idx]
0
(b) Packet from the non-offloaded to the post-processing parti-
tion
Figure 5: The packet format used between programmable
switch and middlebox server in MiniLB.
Control Flow
Graph
Temporary Variable
Metadata Field
Map
Global Variable
Branch
Header Access
ALU Operation
Map Lookup
P4 Table
P4 Register
Branch
Header Access
P4 ALU Primitive
P4 Table Lookup
Figure 6: Mapping a control-flow graph’s states and instruc-
tions to their P4 counterparts.
partition boundaries. 4 Gallium allocates space in the packet header
to store these variables and generates the corresponding packet
header parser specification in P4.
We insert these additional packet header fields between the Eth-
ernet header and the IP header. The Ethernet header is expected
by the receiving NIC and ensures that the packet is delivered over
the wire to the middlebox server’s NIC. We don’t need to put the
additional header after the IP header because we expect the pro-
grammable switch to have a direct connection to the middlebox
server; thus, a destination Ethernet address is sufficient for routing.
To accommodate this additional header, we use a slightly larger
maximum transmission unit (MTU) for the link between the pro-
grammable switch and the middlebox server compared with the
rest of the network.
Figure 5 shows the packet format for MiniLB. The condition
for branching, bk_addr==NULL, has to be shared across all three
partitions. Gallium allocates 1 bit in the packet header for this in-
formation. Also, hash32 is communicated from the pre-processing
partition to the non-offloaded partition. backends[idx] is commu-
nicated from the non-offloaded partition to the post-processing
partition. Gallium allocates 32 bits in the packet header for storing
these variables.
4.3.3 Synchronizing global state We now describe the state
synchronization techniques required to provide the desired run-to-
completion semantics. Recall that this execution semantics requires
4In the partitioning step, Gallium has already verified that the additional packet header
space needed for transferring these variables is below 20 bytes.
a packet’s state updates to be atomic, i.e., other packets observe
all or none of the state updates performed by a packet. Further, a
packet is required to observe all of the state updates performed by
causally antecedent packets.
It is worth noting some aspects of the desired run-to-completion
semantics, which we had described earlier in §3. The correctness
criteria does not impose execution restrictions on packets that are
traversing the network at about the same time, since those packets
could be processed by a middlebox server in any order. Instead, a
packet P’s causally antecedent packets are precisely those packets
that have already been received by one of the end-hosts before P
is transmitted. We just need to ensure that the state updates of
these causally antecedent packets have been consistently replicated
across the switch and the server.
Further, the correctness criteria does not provide ordering guar-
antees. That is, packet P that is not causally dependent on packet Q
might observe the state changes performed by packet Q, but might
still be transmitted by the middlebox (i.e., the server-switch pair)
before packet Q. We believe that this is not unreasonable as this
is equivalent to packet reordering introduced on multi-threaded
middlebox implementations or even by the network itself.
Distributed state management: We first note that our parti-
tioning and code generation techniques ensure that, when a global
variable or map is replicated across the switch and the server, any
updates will only be made by the server. Given this placement
and access restriction, the required run-to-completion semantics
is equivalent to supporting transactional (or serializable) opera-
tions on the state, with the switch operations being limited to
read-only accesses. Given this observation, we borrow two tech-