HsrMorpher, we give a condition whereby EvadeHC performs
poorly and cannot outperform BiRand.
Randomly morphed sample. .
Let us call a sample seen, if it has been queried against
T ,D or M, or has been an output of M. In other words, a
sample is seen if it has been processed by one of the black-
boxes. A sample is unseen otherwise. On a query consisting
of a sample x and a random seed s, M ﬁrst checks whether
the query (x, s) has been issued before. If that is not the
case, M randomly and uniformly chooses an unseen sample
to be the morphed sample3. Otherwise, the previously cho-
sen sample will be outputted. In additional, M also decides,
in a random way, the hidden state of the morphed sample,
which is to be described next.
3If the pool of unseen samples is empty, M simply halts and
does not generate a morphed sample.
Randomly reducing hidden values. .
Under HsrMorpher, each sample x is associated with a
hidden state, represented by two real values (a, b). There is a
particular sample xo with state (1, 1) set to be seen initially,
and it is also known to the adversary. Upon receiving a
query (x, s), M outputs a morphed sample (cid:101)x as described
S and sets the hidden state of (cid:101)x as
in the previous paragraph. If x is unseen, then the morpher
sets the state of x to (0, 0) and remembers that. Next, the
morpher selects two real values (α, β) from a random source
(a − α, b − β)
where (a, b) is the hidden state of x.
The tester T , when given a query x, decides the outcome
based on the hidden state. If x is unseen, then T sets the
hidden state to (0, 0). Suppose the hidden state of x is
(a, b), then T outputs malicious iﬀ a > 0. Likewise, for
the detector D, it outputs reject iﬀ b > 0, and sets the state
of x to be (0, 0) if it is unseen.
Note that the only parameter in the HsrMorpher model is
the random source S.
4.3 Analysis of EvadeHC on HsrMorpher
HsrMorpher behaves randomly, and is arguably the worst
situation the adversary can be in, as the adversary is unable
to exploit domain knowledge to manipulating the samples.
For instance, given two samples x0 and x1, it is not clear
how to ﬁnd a sequence of random seeds that morph x0 to
x1.
Ineffectiveness of EvadeHC.
To understand the performance of EvadeHC, let us give
a particular source S for HsrMorpher that renders EvadeHC
ineﬀective. Let us consider a source S where α and β are
discrete and only take on value 0 or 1. Thus, all possible
hidden states are (a, b) where a, b are integers not greater
than 1. We can view the samples seen during an execution
of EvadeHC as a tree.
It is not diﬃcult to show that the
conditional probability Pr(Gx > 0 | state of x is (1, 1)) is
the same for all x in this tree. Thus, in every iteration, all
candidates have the same probabilities and it is irrelevant
which is chosen for the next iteration.
Random Source S.
.
The model HsrMorpher assumes that the reduction of the
hidden values is independent of the sample x. To validate
that real-life classiﬁers exhibit such property, in our em-
pirical studies, we treat their internal classiﬁcation score
assigned to a sample as the sample’s hidden state. The
empirical results demonstrate that the distributions of the
reduction are similar over a few selected samples.
Remarks.
.
One can visualise the search for evading sample as a race in
reducing the hidden state (a, b). Statistically, a is expected
to drop faster than b. The evasion’s goal is to ﬁnd a random
path that goes against all odds with b reduces to 0 before
a does. Essentially, EvadeHC achieves this in the following
way: It generates and instantiates a few random paths. The
path with the smallest gap arguably has b reducing faster
than average. Hence, EvadeHC chooses a point along this
path as the starting point for the next iteration. Figure 8
depicts this process based on an actual trace obtained in our
experimentation.
5. EVALUATION
To study the feasibility and eﬀectiveness of our proposed
approaches, we conduct experimental evaluation on two
well-known PDF malware classiﬁer, namely PDFrate [28]
and Hidost [30]. We defer overview of PDF malwares and
the two classiﬁers to Appendix A. We ﬁrst describe our ex-
perimental setups and then reports the results.
5.1 Experimental Setups
Morpher M. We employ a simple morphing mechanism
M that performs three basic operations with either insert,
delete or replace an object in the original PDF ﬁle. In order
to perform these operations, the morpher M needs to be able
to parse the PDF ﬁle into a tree-like structure, to perform
the insertion, deletion or replacement on such a structure
and ﬁnally to repack the modiﬁed structure into a variant
PDF4. We employ a modiﬁed version of pdfrw [5] available
at [3] for parsing and repacking.
For insertion and replacement, the external objects that
are placed into the original ﬁle is drawn from a benign PDF
ﬁle. We collect ten benign PDF ﬁles of size less than 1MB
via a Google search to feed into M as a source of benign
objects. They are all accepted by the targeted detectors
and conﬁrmed by the tester T as not bearing any malicious
behaviours.
Tester T . The tester T is implemented using a malware
analysis system called Cuckoo sandbox [1]. The sandbox
opens a submitted PDF ﬁle in a virtual machine and
captures its behaviours, especially the network APIs and
their parameters. The PDF ﬁle is considered malicious if
its behaviours involve particular HTTP URL requests and
APIs traces. We follow previous work by Xu et al. [35]
in selecting the HTTP URL requests and APIs traces as
reliable signature in detecting malicious behaviours of the
submitted PDF ﬁles.
Dataset. We conduct the experimental studies using a
dataset which consists of 500 malicious PDF ﬁles that had
been selected by Xu et al. in their experiments [35]. These
samples are drawn from the Contagio [6] dataset, satisfying
the following three conditions. First, they exhibit malicious
behaviours observed by the tester. Secondly, they have
to be compatible with the morphing mechanism (i.e. can
be correctly repacked by pdfrw). And lastly, they are all
rejected by both targeted detectors. We shall refer to these
as malware seeds hereafter.
Targeted detectors.
The targeted detectors in our
experiments are based on the two PDF malware classiﬁers,
namely PDFrate and Hidost. We make small changes to
their original implementations [4, 30] such that the ﬁnal
outputs are binary decisions, rather than real-value scores.
Scoring function. The score function adopted in this
studies is score1(m, r) = m − r, where m is the malice-
4To avoid redundant parsing of the same PDF ﬁle in mul-
tiple steps, M caches the modiﬁed tree structure (or the
original tree structure of the malicious PDF ﬁle), and di-
rectly modiﬁes it without having to parse the PDF ﬁle in
each step.
120
100
80
60
40
20
0
200
150
100
50
0
Average No. of iterations
Average No. of iterations
4
6
8 10 12
5
10
15
20
(a) PDFrate
(b) Hidost
iterations
Figure 3: Histogram of average numbers of
EvadeHC needs in ﬁnding evading samples against the two
detectors.
ﬂipping distance and r is the reject-ﬂipping distance.
Machine and other parameters. All experiments are
conducted on Ubuntu 14.04 commodity machines equipped
with Intel(R) Xeon(R) CPU E5-2620 v3 @ 2.40GHz pro-
cessors and 64GB of physical memory. The evasion process
can be run in parallel, as there are no dependencies between
diﬀerent executions.
In our experiments, we dedicate one
machine to run D and M, and nine others to run the tester
T . Each of these nine machines deploys 24 virtual machines
simultaneously, and is capable of performing approximately
2, 000 tester queries per hour.
We conducted ﬁve sets of experiments. The ﬁrst set of
experiments examines how the parameters q1, q2 and ∆
eﬀect the performance of EvadeHC. The second and third
experiment sets evaluate the eﬀectiveness of the proposed
approaches in evading PDFrate and Hidost detectors, re-
spectively. The eﬃciency of the evasion is determined by
number of blackboxes queries and the overall running time.
In the forth set of experiments, we consider a hypothetical
setting where the detectors are hardened to make evasion
more diﬃcult and benchmark our approaches against the
closely related work by Xu et al.[35], which relies on classi-
ﬁcation scores output by the detectors to guide the evasion.
We emulate the hardening of detectors by reducing their de-
faults thresholds: below 0.5 for PDFrate and below 0 for
Hidost. The last set of experiments validates the HsrMor-
pher model we discussed earlier in Section 4. Unless other-
wise stated, the reported results are average values obtained
over 10 instances.
5.2 Effect of Parameter Settings on EvadeHC
We ﬁrst examine how the choice of parameters q1,
q2 and ∆ eﬀects the performance of EvadeHC. We run
EvadeHC with diﬀerent parameter settings on 100 mal-
ware seeds randomly selected from our experimental dataset
against PDFrate detector, varying q1 from 10 to 60, and
setting q2 proportional to q1 with a percentage ranging from
10% to 50%. In addition, we vary the jump factor ∆ from
0.4 to 0.9. The average numbers of iterations and amounts
of detector queries required to ﬁnd evading samples are re-
ported in Figure 4.
Figure 4a indicates that increasing q1 will lessen the num-
ber of iterations. This is consistent with an intuition we dis-
cussed earlier, for larger q1 would improve a likelihood that
the algorithm is going toward the right direction. q2, on the
other hands, has a more subtle eﬀects on the number of iter-
s
n
o
i
t
a
r
e
t
i
f
o
.
o
n
e
g
a
r
e
v
A
40
30
20
10
0
s
n
o
i
t
a
r
e
t
i
q2 = 10% · q1
q2 = 25% · q1
q2 = 50% · q1
f
o
.
o
n
e
g
a
r
e
v
A
10
20
q1
40
60
(a) Eﬀect of q1, q2
q2 = 10% · q1
10
8
6
4
2
0
0.40.50.60.70.80.9
∆
q2 = 25% · q1
(b) Eﬀect of ∆
q2 = 50% · q1
d
N
1,000
800
600
400
200
0
10
20
q1
40
60
(c) Average Nd w.r.t diﬀerent q1, q2
Figure 4: Eﬀect of q1, q2 and ∆ on performance of EvadeHC
ations. In particular, a too small value may lead the search
to a local minimum, hindering the search progress, while a
too large value may accidentally bring “bad” candidates onto
the next iterations. A similar trend is also observed on ∆
(Figure 4b). When it is increased from 0.4 to 0.7, we wit-
ness a reduction in number of iterations. However, when it
reaches 0.9, the algorithm tends to loop through more iter-
ations in order to ﬁnd evading samples. The reason is that
too small ∆ limits progress the search can make in each it-
eration, while unnecessarily large ∆ would increase the like-
lihood of samples in the next iterations being rejected.
It is worth noting that the number of detector queries re-
quired to ﬁnd evading samples depends not only on the num-
ber of iterations, but also the value of q1. Figure 4c shows
average number of detector queries with respect to diﬀerent
settings of q1 and q2. While larger q1 leads to smaller num-
ber of iterations, it may result in larger number of detector
queries per each iterations, and thus larger queries overall
(e.g., with q2 = 25%· q1, increasing q1 from 20 to 60 leads to
an increase in Nd). From the result of this experiment set,
we choose q1 = 20, q2 = 5 and ∆ = 0.75 as the parameter
setting for EvadeHC through all other sets of experiments.
5.3 Evading PDFrate Detector
on
set
The
second
focuses
experiment
evading
PDFrate detector. All of our methods achieve 100%
evasion rates (i.e., found evading samples for all 500 mal-
ware seeds in our dataset). While the baseline SeqRand and
BiRand traverse 1048 random paths on average to ﬁnd
an evading sample, EvadeHC only needs from three to six
iterations (each iteration involves assessing 20 random
paths). Nevertheless, there are a few exceptions which
require EvadeHC to take up to 19 iterations to ﬁnd evading
samples (Figure 3a).
100
80
60
40
20
0
40
60
(a) Ratios of Nd by
SeqRand and BiRand
60
40
20
0
3
2
4