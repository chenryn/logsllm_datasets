FSDataOutputStream out=fs.create（p）；
out.write（"content".getBytes（"UTF-8"））；
out.flush（）；
out.sync（）；
assertThat（fs.getFileStatus（p）.getLen（），is（（（long）"content".length（））））；
这个操作类似于UNIX系统中的fsync系统调用，为一个文件描述符提交缓存数据，利用Java API写入本地数据，这样就可以保证看到刷新流并且同步之后的数据，代码如下：
FileOutputStream out=new FileOutputStream（localFile）；
out.write（"content".getBytes（"UTF-8"））；
out.flush（）；//flush to operating system
out.getFD（）.sync（）；//sync to disk
assertThat（localFile.length（），is（（（long）"content".length（））））；
在HDFS中关闭一个文件也隐式地执行了sync（）函数，代码如下：
Path p=new Path（"p"）；
OutputStream out=fs.create（p）；
out.write（"content".getBytes（"UTF-8"））；
out.close（）；
assertThat（fs.getFileStatus（p）.getLen（），is（（（long）"content".length（））））；
下面来了解一致性模型对应用设计的重要性。文件系统的一致性和设计应用程序的方法有关。如果不调用sync（），那么需要做好因客户端或者系统发生故障而丢失部分数据的准备。对大多数应用程序来说，这是不可接受的，所以需要在合适的时刻调用sync（），比如在写入一定量的数据之后。尽管sync（）被设计用来最大限度地减少HDFS的负担，但是它仍然有不可忽视的开销，所以需要在数据健壮性和吞吐量之间做好权衡。其中一个好的参考平衡点就是：通过测试应用程序来选择不同sync（）频率间性能的最佳平衡点。
9.7 HDFS命令详解
Hadoop提供了一组shell命令在命令行终端对Hadoop进行操作。这些操作包括诸如格式化文件系统、上传和下载文件、启动DataNode、查看文件系统使用情况、运行JAR包等几乎所有和Hadoop相关的操作。本节将具体介绍HDFS的相关命令操作。
 9.7.1 通过distcp进行并行复制
Java API等多种接口对HDFS访问模型都集中于单线程的存取，如果要对一个文件集进行操作，就需要编写一个程序进行并行操作。HDFS提供了一个非常实用的程序—distcp，用来在Hadoop文件系统中并行地复制大数据量文件。distcp一般适用于在两个HDFS集群间传送数据的情况。如果两个集群都运行在同一个Hadoop版本上，那么可以使用HDFS模式：
hadoop distcp hdfs：//NameNode1/foo hdfs：//NameNode2/bar
这条命令会将第一个集群/foo文件夹以及文件夹下的文件复制到第二个集群/bar目录下，即在第二个集群中会以/bar/foo的目录结构出现。如果/bar目录不存在，则系统会新建一个。也可以指定多个数据源，并且所有的内容都会被复制到目标路径。需要注意的是，源路径必须是绝对路径。
默认情况下，虽然distcp会跳过在目标路径上已经存在的文件，但是通过-overwirte选项可以选择对这些文件进行覆盖重写，也可以使用-update选项仅对更新过的文件进行重写。
distcp操作有很多选项可以设置，比如忽略失败、限制文件或者复制的数据量等。直接输入指令或者不附加选项可以查看此操作的使用说明。具体实现时，distcp操作会被解析为一个MapReduce操作来执行，当没有Reducer操作时，复制被作为Map操作并行地在集群节点中运行。因此，每个文件都可以被当成一个Map操作来执行复制。而distcp会通过执行多个文件聚集捆绑操作，尽可能地保证每个Map操作执行相同数量的数据。那么执行distcp时，Map操作如何确定呢？由于系统需要保证每个Map操作执行的数据量是合理的，来最大化地减少Map执行的开销，而按规定，每个Map最少要执行256MB的数据量（除非复制的全部数据量小于256MB）。比如要复制1GB的数据，那么系统就会分配4个Map任务，当数据量非常大时，就需要限制执行的Map任务数，以限制网络带宽和集群的使用率。默认情况下，每个集群的一个节点最多执行20个Map任务。比如，要复制1000GB数据到100节点的集群中，那么系统就会分配2000个Map任务（每个节点20个），也就是说，每个节点会平均复制512MB。还可以通过调整distcp的-m参数减少Map任务量，比如-m 1000就意味着分配1000个Maps，每个节点分配1GB数据量。
如果尝试使用distcp进行HDFS集群间的复制，使用HDFS模式之后，HDFS运行在不同的Hadoop版本之上，复制将会因为RPC系统的不匹配而失败。为了纠正这个错误，可以使用基于HTTP的HFTP进行访问。因为任务要在目标集群中执行，所以HDFS的RPC版本需要匹配，在HFTP模式下运行的代码如下：
hadoop distcp hftp：//NameNode1：50070/foo hdfs：//NameNode2/bar
需要注意的是，要定义访问源的URI中NameNode的网络接口，这个接口会通过dfs.http.address的属性值设定，默认值为50070。
9.7.2 HDFS的平衡
当复制大规模数据到HDFS时，要考虑的一个重要因素是文件系统的平衡。当系统中的文件块能够很好地均衡分布到集群各节点时，HDFS才能够更好地工作，所以要保证distcp操作不会打破这个平衡。回到前面复制1000GB数据的例子，当设定-m为1，就意味着1个Map操作可以完成1000GB的操作。这样不仅会让复制操作非常慢，而且不能充分利用集群的性能。最重要的是复制文件的第一个块都要存储在执行Map任务的那个节点上，直到这个节点的磁盘被写满，显然这个节点是不平衡的。通常我们通过设置更多的、超过集群节点的Map任务数来避免不平衡情况的发生，所以最好的选择是刚开始还是使用的默认属性值，每个节点分配20个Map任务。
当然，我们不能保证集群总能够保持平衡，有时可能会限制Map的数量以便节点可以被其他任务使用，这样HDFS还提供了一个工具balancer（参见第10章）来改变集群中的文件块存储的平衡。
9.7.3 使用Hadoop归档文件
在9.2节中介绍过，每个文件HDFS采用块方式进行存储，在系统运行时，文件块的元数据信息会被存储在NameNode的内存中，因此，对HDFS来说，大规模存储小文件显然是低效的，很多小文件会耗尽NameNode的大部分内存。
Hadoop归档文件和HAR文件可以将文件高效地放入HDFS块中的文件存档设备，在减少NameNode内存使用的同时，仍然允许对文件进行透明访问。具体来说，Hadoop归档文件可以作为MapReduce的输入。这里需要注意的是，小文件并不会占用太多的磁盘空间，比如设定一个128MB的文件块来存储1MB的文件，实际上存储这个文件只需要1MB磁盘空间，而不是128MB。
Hadoop归档文件是通过archive命令工具根据文件集合创建的。因为这个工具需要运行一个MapReduce来并行处理输入文件，所以需要一个运行MapReduce的集群。而HDFS中有些文件是需要进行归档的，例如：
hadoop fs-lsr/user/ubuntu/In/
-rw-r--r--3 ubuntu\ubuntu supergroup 13 2012-03-18 20：15/user/ubuntu/In/hello.c.txt
-rw-r--r--1 ubuntu\ubuntu supergroup 13 2012-03-17 15：13/user/ubuntu/In/hello.txt
运行archive命令如下：
hadoop archive-archiveName files.har/user/ubuntu/In//user/ubuntu/
12/03/18 20：46：47 INFO mapred.JobClient：Running job：job_201010182044_0001
12/03/18 20：46：48 INFO mapred.JobClient：map 0%reduce 0%
12/03/18 20：47：21 INFO mapred.JobClient：map 100%reduce 0%
12/03/18 20：47：39 INFO mapred.JobClient：map 100%reduce 100%
12/03/18 20：47：41 INFO mapred.JobClient：Job complete：job_201010182044_0001
12/03/18 20：47：41 INFO mapred.JobClient：Counters：17
12/03/18 20：47：41 INFO mapred.JobClient：Job Counters
12/03/18 20：47：41 INFO mapred.JobClient：Launched reduce tasks=1
12/03/18 20：47：41 INFO mapred.JobClient：Launched map tasks=1
12/03/18 20：47：41 INFO mapred.JobClient：FileSystemCounters
12/03/18 20：47：41 INFO mapred.JobClient：FILE_BYTES_READ=540
12/03/18 20：47：41 INFO mapred.JobClient：HDFS_BYTES_READ=531
12/03/18 20：47：41 INFO mapred.JobClient：FILE_BYTES_WRITTEN=870
12/03/18 20：47：41 INFO mapred.JobClient：HDFS_BYTES_WRITTEN=305
12/03/18 20：47：41 INFO mapred.JobClient：Map-Reduce Framework
12/03/18 20：47：41 INFO mapred.JobClient：Reduce input groups=6
12/03/18 20：47：41 INFO mapred.JobClient：Combine output records=0
12/03/18 20：47：41 INFO mapred.JobClient：Map input records=6
12/03/18 20：47：41 INFO mapred.JobClient：Reduce shuffle bytes=0
12/03/18 20：47：41 INFO mapred.JobClient：Reduce output records=0
12/03/18 20：47：41 INFO mapred.JobClient：Spilled Records=12
12/03/18 20：47：41 INFO mapred.JobClient：Map output bytes=280
12/03/18 20：47：41 INFO mapred.JobClient：Map input bytes=399
12/03/18 20：47：41 INFO mapred.JobClient：Combine input records=0
12/03/18 20：47：41 INFO mapred.JobClient：Map output records=6
12/03/18 20：47：41 INFO mapred.JobClient：Reduce input records=6
在命令行中，第一个参数是归档文件的名称，这里是file.har文件；第二个参数是要归档的文件源，这里我们只归档一个源文件夹，即HDFS下/user/ubuntu/In/中的文件，但事实上，archive命令可以接收多个文件源；最后一个参数，即本例中的/user/ubuntu/是HAR文件的输出目录。可以看到这个命令的执行流程为一个MapRedeuce任务。
下面我们来看这个归档文件是怎么创建的：
hadoop fs-ls/user/ubuntu/In//user/ubuntu/
Found 2 items
-rw-r--r--3 ubuntu\ubuntu supergroup 13 2012-03-18 20：15/user/ubuntu/In/hello.c.txt
-rw-r--r--1 ubuntu\ubuntu supergroup 13 2012-03-17 15：13/user/ubuntu/In/hello.txt
Found 3 items
drwxr-xr-x-ubuntu\ubuntu supergroup 0 2012-03-18 20：15/user/ubuntu/In
drwxr-xr-x-ubuntu\ubuntu supergroup 0 2012-03-18 18：53/user/ubuntu/ubuntu
drwxr-xr-x-ubuntu\ubuntu supergroup 0 2012-03-18 20：47/user/ubuntu/files.har
这个目录列表展示了一个HAR文件的组成：两个索引文件和部分文件（part file）的集合。这里的部分文件包含已经连接在一起的大量源文件的内容，同时索引文件可以检索部分文件中的归档文件，包括它的长度、起始位置等。但是，这些细节在使用HAR URI模式访问HAR文件时多数都是隐藏的。HAR文件系统是建立在底层文件系统上的（此处是HDFS），以下命令以递归的方式列出了归档文件中的文件：
hadoop fs-lsr har：///user/ubuntu/files.har
drw-r--r---ubuntu\ubuntu supergroup 0 2012-03-18 20：47/user/ubuntu/files.har/user
drw-r--r---ubuntu\ubuntu supergroup 0 2012-03-18 20：47/user/ubuntu/files.har/
user/ubuntu
drw-r--r---ubuntu\ubuntu supergroup 0 2012-03-18 20：47/user/ubuntu/files.har/
user/ubuntu/In
-rw-r--r--10 ubuntu\ubuntu supergroup 13 2012-03-18 20：47/user/ubuntu/files.
har/user/ubuntu/In/hello.c.txt
-rw-r--r--10 ubuntu\ubuntu supergroup 13 2012-03-18 20：47/user/ubuntu/files.
har/user/ubuntu/In/hello.txt
如果HAR文件所在的文件系统是默认的文件系统，那么这里的内容就非常直观和易懂，但是，如果你想要在其他文件系统中使用HAR文件，就需要使用不同格式的URI路径。下面两个命令即具有相同的作用：
hadoop fs-lsr har：///user/ubuntu/files.har/my/files/dir
hadoop fs-lsr har：//hdfs-localhost：8020/user/ubuntu/files.har/my/files/dir
第二个命令，它仍然使用HAR模式描述一个HAR文件系统，但是使用HDFS作为底层的文件系统模式，HAR模式之后紧跟一个HDFS系统的主机和端口号。HAR文件系统会将HAR URI转换为底层的文件系统访问URI。在本例中即为hdfs：//localhost：8020/user/ubuntu/archive/files.har，文件的剩余部分路径即为文件归档部分的路径/my/files/dir。
想要删除HAR文件，需要使用删除的递归格式，这是因为底层的文件系统HAR文件是一个目录，删除命令为hadoop fs-rmr/user/ubuntu/files.har。
对于HAR文件我们还需要了解它的一些不足。当创建一个归档文件时，还会创建原始文件的一个副本，这样就需要额外的磁盘空间（尽管归档完成后会删除原始文件）。而且当前还没有针对归档文件的压缩方法，只能对写入归档文件的原始文件进行压缩。归档文件一旦创建就不能改变，要增加或者删除文件，就要重新创建。事实上，这对于那些写后不能更改的文件不构成问题，因为可以按日或者按周进行定期成批归档。
如前所述，HAR文件可以作为MapReduce的一个输入文件，然而，没有一个基于归档的InputFormat可以将多个文件打包到一个单一的MapReduce中去。所以，即使是HAR文件，处理小的文件时效率仍然不高。
9.7.4 其他命令
其他相关命令还包括以下这些：
NameNode-format：格式化DFS文件系统
secondaryNameNode：运行DFS的SecondaryNameNode进程
NameNode：运行DFS的NameNode进程
DataNode：运行DFS的DataNode进程
dfsadmin：运行DFS的管理客户端
mradmin：运行MapReduce的管理客户端
fsck：运行HDFS的检测进程
fs：运行一个文件系统工具
balancer：运行一个文件系统平衡进程
jobtracker：运行一个JobTracker进程
pipes：运行一个Pipes任务
tasktracker：运行一个TaskTracker进程
job：管理运行中的MapReduce任务
queue：获得运行中的MapReduce队列的信息
version：打印版本号
jar＜jar＞：运行一个JAR文件
daemonlog：读取/设置守护进程的日志记录级别
相信大家已经对这些命令中的一部分很熟悉了，比如在命令行终端中，jar是用来运行Java程序的，version命令可以查看Hadoop的当前版本，或者在安装时必须运行的NameNode-format命令。在这一小节，我们介绍的是与HDFS有关的命令。其中与HDFS相关的命令有如下几个：secondaryNameNode、NameNode、DataNode、dfsadmin、fsck、fs、balancer、distcp和archieves。
它们的统一格式如下：
bin/hadoop command[genericOptions][commandOptions]
其中只有dfsadmin、fsck、fs具有选项genericOptions及commandOptions，其余的命令只有commandOptions。下面先介绍只有commandOptions选项的命令。
distcp。Distcp命令用于DistCp（即Dist分布式，Cp复制）分布式复制。用于在集群内部及集群之间复制数据。
archives。archives命令是Hadoop定义的档案格式。archive对应一个文件系统，它的扩展名是.har，包含元数据及数据文件。
这两个命令在前文中已有介绍，这里就不再赘述了。
DataNode。DataNode命令要简单一些。你可以使用如下命令将Hadoop回滚到前一个版本，它的用法如下：
hadoop DataNode[-rollback]
NameNode。nameNode命令稍稍复杂一些，它的用法如下：
hadoop nameNode
[-format]//格式化NameNode
[-upgrade]//在Hadoop升级后，应该使用这个命令启动NameNode
[-rollback]//使用NameNode回滚前一个版本
[-finalize]//删除文件系统的前一个状态，这会导致系统不能回滚到前一个状态
[-importCheckpoint]//复制备份checkpoint的状态到当前checkpoint
SecondaryNameNode。secondaryNameNode的命令用法如下：
hadoop secondaryNameNode
[-checkpoint[force]]
//当editlog超过规定大小（默认64MB）时，启动检查secondaryNameNode的checkpoint过程；如果启用force选项，则强制执行checkpoint过程
[-geteditsize]
//在终端上显示editlog文件的大小
balancer。balancer命令如解释中所说，用于分担负载。很多原因都会造成数据在集群内分布不均衡，一般来说，当集群中添加新的DataNode时，可以使用这个命令来进行负载均衡。其用法如下：
hadoop balancer
接下来的dfsadmin、fsck、fs这三个命令有一个共同的选项genericOptions，这个选项一般与系统相关，其用法如下：
-conf＜configuration file＞//指定配置文件
-D＜property=value＞//指定某属性的属性值
-fs＜local|namenode：port＞//指定DataNode及其端口
dfsadmin。在dfsadmi命令中可以执行一些类似Windows中高级用户才能执行的命令，比如升级、回滚等。其用法如下：
hadoop dfsadmin[GENERIC_OPTIONS]