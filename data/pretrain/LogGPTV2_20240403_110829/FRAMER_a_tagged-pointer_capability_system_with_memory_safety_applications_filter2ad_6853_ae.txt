g
f
m c
h m m s j e
g
n
q
l i b
4
6
2
h
Figure 9: Normalised maximum resident set size
perlbench
bzip2
h264
ks
anag
0
Accessheader
20
40
Accessentry
60
Branch
80
Calculation
100
Untagging
Figure 10: Runtime overheads for metadata management
and retrieval (the overhead for bounds checking excluded)
MPKI (cache misses) and branch prediction misses MPKI. The base-
line D-cache miss rate was 2.48% (Table 2) but this improves with
FRAMER enabled owing to repeated access to the same cache data.
In Fig. 11, we normalise cache misses to the uninstrumented
figure. The average normalised cache misses is 0.66 and 0.38 for
store-only and full-checking, respectively. The miss rate is reduced
since the additional operations we add have high cache affinity
which dilutes the underlying miss rate of the application.
While ASan showed increase for four tests. ASan’s normalised
misses on average is 0.73, which is higher than FRAMER’s 0.38.
ASan’s highest overhead is 197% for bc, and two tests reached in-
crease more than by 100%. On FRAMER, power’s overhead by 48%
is mainly caused by the very low increase in instruction executed
in producing MPKI. The rest of benchmarks’ misses decreased, and
normalised misses in full-checking mode were below 0.5 for 21
tests among 28 working set, whereas only 13 tests’ on ASan were
lower than 0.5. The overall cache miss rate showed FRAMER is
cache-efficient and stable.
Cache misses (MPKI) may appear decreased with bloated instruc-
tion counts, so we also present the increase in total numbers of
cache misses. Fig. 13 shows the normalised counts of cache misses
for big-sized programs in SPEC. The averages of shown tests for
FRAMER (Full) and ASan are 1.24 and 2.40, and the averages for the
whole set are 1.40 and 2.31, respectively. This shows the increase in
cache miss count to access metadata in FRAMER is minimal. On
FRAMER, the increase rate of all the tests except one (277% for
voronoi) are below 100%. On ASan, the increases for 7 tests are
above 100%, and bc’s increase rate is 1160%.
7.4 Instructions Executed
Fig. 12 reports normalised overheads per benchmark. FRAMER
increases dynamic instruction count by 124% for store-only, and
425% for full checking. This increase is the main contributor to
slowdown. Dynamic instruction penalty arises from setting up and
using tagged pointers. The major source of the growth is arithmetic
operations. As shown in Fig. 10, 75% of runtime overhead of meta-
data management/retrieval is dominated by calculation of (1) the
header address at memory access and (2) the tag at allocation. This
cost can be resolved with hardware acceleration with ISA.
The penalty of utilising top bits is over-instrumentation – unless
individual memory access is proven tag-free statically, we have to
instrument it (i.e. tag-cleaning) to avoid segmentation fault in all
major architectures, requiring the top bits to be zero (or special
pointer authentication code in ARM8). This results in stripping the
tag field for untagged pointers.
The average overhead for ASan is 226%, which is lower than
FRAMER. The average excluding the highest test (1336% for bh) is
184%, while FRAMER’s average excluding the highest (1098% for
mcf) is 400%. The difference in slowdown on average (FRAMER:
213%, ASan: 139%) was not big as the difference of instruction
executed due to FRAMER’s cache efficiency. ASan consumes fewer
dynamic instructions, since shadow space-only metadata storage
helps simpler derivation of metadata location, taking advantage of
re-alignment of objects, as trade-off of space and high locality.
Future implementations can optimise the case where conserva-
tive analysis reveals the tag never needs to be added. More discus-
sion on optimisation is described in Section 8.3.
Myoung Jin Nam, et al.
1.57
2.97
2.06
Store-only
Full
ASan
h
b
o
b i s
e m 3
a l
e
h
t
m s
r i
e
p
o w
p
e
e
r
t
p
s
t
o
r
o
v
g
a
n
a
c
b
ft
s
k
r
c
a
y
r l 1
e
p
r l 2
e
p
r l 3
e
p
r l 4
e
p
1
z i p
b
2
z i p
b
3
z i p
b
c
c
g
f
m c
h m m s j e
g
n
q
l i b
4
6
2
h
Figure 11: Normalised L1 D-cache load misses per 1000 instructions (MPKI)
14.42
11.97
1.5
1
0.5
10
8
6
4
2
h
b
o
b i s
e m 3
a l
e
h
t
m s
r i
e
p
o w
p
e
e
r
t
p
s
t
o
r
o
v
g
a
n
a
c
b
ft
s
k
r
c
a
y
r l 1
e
p
r l 2
e
p
r l 3
e
p
r l 4
e
p
1
z i p
b
2
z i p
b
3
z i p
b
c
c
g
f
m c
h m m s j e
g
n
q
l i b
4
6
2
h
Figure 12: Normalised dynamic instruction count
5.87 6.32
Full
ASan
4.12
4
3
2
1
r l 1
e
p
r l 2
e
p
r l 3
e
p
r l 4
e
p
1
z i p
b
2
z i p
b
3
z i p
b
c
c
g
f
m c
h m m
g
n
s j e
q
l i b
4
6
2
h
Figure 13: Normalised L1 D-cache load miss count
7.5 Branch Misses
Additional conditional branches arise in FRAMER from checking
whether small or large frame is used and in the pointer validity
checks themselves. Many approaches using shadow space are re-
lieved from these branches at metadata retrieval.
As shown in Table 2 col 7, the dynamic branch density de-
creases slightly under FRAMER instrumentation, but the branch
mis-prediction rate greatly decreases (col 8). The averages of nor-
malised branch misses for store-only and full-checking are 0.62
and 0.42, respectively. This shows the additional branches achieve
highly accurate branch prediction and that branch predictors are
not being overloaded. Of the new branches added, the ones checking
small/large frame size are completely statically predictable owing
to the checking code instances being associated with a given object.
And the ones checking pointer validity also predict perfectly since
no out-of-bounds errors are detected.
8 DISCUSSION
8.1 Comparison with Other Approaches
Shadow space-based approaches. Shadow space-based ap-
8.1.1
proaches reduce slowdown by lowering executed instructions. Trade-
off of data memory is tolerable in most systems during development.
For practical deployment, however, their slowdown is still high and
memory footprint is critical in some systems, e.g. ARM running
in an embedded system or I/O-heavy server-side loads. In using
shadow space, it is inevitable to pad and re-align objects to avoid
conflicts in entries [3, 25, 39]. ASan pads each object for wider de-
tection coverage and more padding for alignment, which burdens
space, whereas FRAMER’s fake padding and wrapper frames do
not consume any space. Furthermore, their higher cache misses
to access metadata in remote memory region (including ASan’s
resetting entries at deallocation), making its runtime overheads
unpredictable.
In comparison with ASan, FRAMER showed better efficiency
both in memory footprint (FRAMER: 23%, ASan: 784%) and cache
miss counts overhead (FRAMER: 40%, ASan: 131%). ASan showed