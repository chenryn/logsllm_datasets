title:ABY\(^\mbox3\): A Mixed Protocol Framework for Machine Learning
author:Payman Mohassel and
Peter Rindal
ABY3: A Mixed Protocol Framework for Machine Learning
Payman Mohassel and Peter Rindal
ABSTRACT
Machine learning is widely used to produce models for a range of
applications and is increasingly offered as a service by major tech-
nology companies. However, the required massive data collection
raises privacy concerns during both training and prediction stages.
In this paper, we design and implement a general framework
for privacy-preserving machine learning and use it to obtain new
solutions for training linear regression, logistic regression and neu-
ral network models. Our protocols are in a three-server model
wherein data owners secret share their data among three servers
who train and evaluate models on the joint data using three-party
computation (3PC).
Our main contribution is a new and complete framework (ABY3)
for efficiently switching back and forth between arithmetic, binary,
and Yao 3PC which is of independent interest. Many of the conver-
sions are based on new techniques that are designed and optimized
for the first time in this paper. We also propose new techniques for
fixed-point multiplication of shared decimal values that extends be-
yond the three-party case, and customized protocols for evaluating
piecewise polynomial functions. We design variants of each build-
ing block that is secure against malicious adversaries who deviate
arbitrarily.
We implement our system in C++. Our protocols are up to four
orders of magnitude faster than the best prior work, hence signifi-
cantly reducing the gap between privacy-preserving and plaintext
training.
ACM Reference Format:
Payman Mohassel and Peter Rindal. 2018. ABY3: A Mixed Protocol Frame-
work for Machine Learning. In 2018 ACM SIGSAC Conference on Com-
puter and Communications Security (CCS ’18), October 15–19, 2018, Toronto,
ON, Canada. ACM, New York, NY, USA, 18 pages. https://doi.org/10.1145/
3243734.3243760
1 INTRODUCTION
Machine learning is widely used to produce models that classify
images, authenticate biometric information, recommend products,
choose which Ads to show, and identify fraudulent transactions.
Major technology companies such as Microsoft, IBM, Amazon,
and Google are providing cloud-based machine learning services
[1, 3, 4, 6] to their customers both in form of pre-trained models that
can be used for prediction as well as training platforms that train
models on customer data. Advances in deep learning, in particular,
have lead to breakthroughs in image, speech, and text recognition
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
CCS ’18, October 15–19, 2018, Toronto, ON, Canada
© 2018 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 978-1-4503-5693-0/18/10...$15.00
https://doi.org/10.1145/3243734.3243760
to the extent that the best records are often held by neural network
models trained on large datasets.
A major enabler of this success is the large-scale data collec-
tion that deep learning algorithms thrive on. Internet companies
regularly collect users’ online activities and browsing behavior to
train more accurate recommender systems, the healthcare sector
envisions a future where patients’ clinical and genomic data can
be used to produce new diagnostic models and there are efforts to
share security incidents and threat data, to improve future attack
prediction.
The data being classified or used for training is often sensitive
and may come from multiple sources with different privacy require-
ments. Regulations such as HIPPA, PCI, and GDPR, user privacy
concerns, data sovereignty issues, and competitive advantage are
all reasons that prevent entities from pooling different data sources
to train more accurate models.
Privacy-preserving machine learning based on secure multiparty
computation (MPC) is an active area of research that can help ad-
dress some of these concerns. It ensures that during training, the
only information leaked about the data is the final model (or an
encrypted version), and during prediction, the only information
leaked is the classification label. These are strong guarantees that,
though do not provide a full-proof privacy solution (the models
themselves or interactions with them can leak information about
the data [51, 53, 55]), provide a strong first line of defense which
can be strengthened when combined with orthogonal mechanisms
such as differential privacy [7, 41]. The most common setting con-
sidered in this line of work is a server-aided model where data
owners (clients) send encrypted version of their data to multiple
servers who perform the training procedure on the combined data
or apply a (shared) pre-trained model to classify new data sam-
ples. Performance of these solutions has improved significantly
over the years, leading to orders of magnitude speedup in privacy-
preserving machine learning. Nevertheless, there is still a large gap
between plaintext training and the privacy-preserving solutions.
While part of this gap is unavoidable given the desired guarantees,
the current state of affairs is far from optimal. In the three-party
computation (3PC) setting with one corruption, following up on a
large body of work [12, 13, 22, 38], new techniques and implementa-
tions [9, 28, 42] have significantly reduced this gap, e.g. processing
7 billion AND gates per second. The MPC techniques for machine
learning, however, are primarily limited to the two-server model
and do not benefit from these speedups. They also only consider
security against the weaker semi-honest attackers.
In this paper, we explore privacy-preserving machine learning
in the three-server model. We emphasize this does not mean only
three data owners can participate in the computation. We envision
application scenarios where the servers are not considered the same
as data owners. Each server can be an independent party or the
representative for a subset of data owners. In other words, as long as
we guarantee that at most one of the three servers is compromised,
Session 1B: PrivacyCCS’18, October 15-19, 2018, Toronto, ON, Canada35an arbitrary number of data owners can incorporate their data into
the framework.
A natural question is whether directly applying the new 3PC
techniques to machine learning algorithms would yield the same
speedup for server-aided privacy-preserving machine learning. Un-
fortunately, when using existing techniques the answer is negative.
− The first challenge is that the above-mentioned 3PC techniques
are only suitable for computation over a Z2k ring. This is in
contrast with machine learning computation wherein both the
training data and the intermediate parameters are decimal val-
ues that cannot be natively handled using modular arithmetic.
The two most common solutions are to (i) represent decimal
values as integers where the least significant bits represent the
fractional part, and choose a large enough modulo to avoid
a wrap around. This approach fails when performing many
floating point multiplications, which is the case in standard
training algorithms (e.g. stochastic gradient descent) where
millions of sequential multiplications are performed. More-
over, a large modulo implies a more expensive multiplication
that further reduces performance, (ii) perform fixed-point mul-
tiplication using a boolean multiplication circuit inside the
MPC. Such a boolean circuit can be evaluated using either
the secret sharing based [9] or the garbled circuit based [42]
techniques, leading to a significant increase in either round or
communication cost of the solution, respectively.
− The second challenge is that most machine learning proce-
dures require switching back and forth between arithmetic op-
erations such as multiplication and addition, and non-arithmetic
operations such as approximate activation functions (e.g. logis-
tic function), and piecewise polynomial functions (e.g. RELU).
The former is most efficiently instantiated using arithmetic
secret sharing while the latter should be implemented using
either binary secret sharing or Yao sharing. Standard ways
of converting between different sharing types are costly and
quickly become a major performance bottleneck.
Addressing the above challenges efficiently is even harder in
presence of an attacker who behaves arbitrarily malicious.
1.1 Our Contribution
We design and implement a general framework for privacy-preserving
machine learning in the three-server model with a single corrupted
server. Our contributions are as follows:
1. New approximate fixed-point multiplication protocols for shared
decimal numbers at a cost close to a standard secret shared
modular multiplication, in both the semi-honest and the mali-
cious case. For a single multiplication, we find that our protocol
results in a 50× improvement in throughput and 24× improve-
ment in latency compared to an optimized boolean circuit.
For some machine learning operations, our fixed-point tech-
nique reduces the amount of communication by 32, 768× and
requires 80× fewer rounds. See Appendix B for details.
We note that the recent fixed-point multiplication techniques
of [43] fails in the 3PC setting and certainly fails in presence
of malicious adversaries. Our new techniques are not only se-
cure against malicious adversaries but also extend to arbitrary
number of parties.
2. A new general framework for efficiently converting between
binary sharing, arithmetic sharing [9] and Yao sharing [42] in
the three-party setting, that yields the first Arithmetic-Binary-
Yao (ABY) framework for the three-party case with security
against malicious adversaries (See Table 1). Many of these con-
versions are based on new techniques and are designed and
optimized for the first time in this paper. Our framework is of
general interest given that several recent privacy-preserving
machine learning solutions [40, 43, 46] extensively utilize ABY
conversions, and its use cases go beyond machine learning [23].
As we will see later, the techniques we develop for our ABY
framework are quite different from the original two-party
framework of [24], since secure three-party computation tech-
niques deviate significantly from their two-party counterparts.
3. Other optimizations include a delayed re-share technique that
reduces the communication complexity for vectorized oper-
ations by several orders of magnitude and a customized 3PC
protocol for evaluating piecewise polynomial functions based
on a generalized three-party oblivious transfer primitive.
4. We instantiate all our building blocks in both the semi-honest
and the malicious setting, often requiring different techniques.
5. We implement our framework in the semi-honest setting and
run experiments for training and inference for linear, logistic
regression and neural network models. Our solutions are up
to 55000× faster than the two-party solution of SecureML [43]
when training neural networks, and our framework can do
5089 linear regression training iterations per second compared
to 3.7 iterations by [43]. Similarly, our neural network experi-
ment can generate a handwriting prediction in 10 milliseconds
compared to the state-of-the-art Chameleon [46] protocol re-
quiring 2700 milliseconds.
1.2 Overview of Techniques
As a brief notational introduction, we define(cid:74)x(cid:75) as the sharing of
a secret value x. This sharing will be one of three types: 1)(cid:74)x(cid:75)A
denotes an additive secret sharing of x ∈ Z2k over the group Z2k .
2)(cid:74)x(cid:75)B denotes a vector of k binary secret sharing which encodes
x ∈ Z2k . 3)(cid:74)x(cid:75)Y to denote that x is secret shared using keys which
are suitable for evaluating a Yao’s garbled circuit[42].
Approximate fixed-point multiplication. Our starting point is the
semi-honest three-party secure computation protocol of Araki et
al. [9] based on replicated secret sharing in the ring Z2k . This
protocol represents a value x ∈ Z2k by linearly secret sharing it
into three random values x1, x2, x3 ∈ Z2k such that sum of them
equals x. Each of the three parties is given two of these shares such
that any two parties can reconstruct x. The first challenge in the
use of replicated secret sharing is that it does not naturally support
fixed-point multiplication and the fixed-point technique introduced
in [43] fails in the three-party setting.
We design a new construction for this problem which can be
reduced to computing(cid:74)x(cid:75) :=(cid:74)x′/2d(cid:75) given(cid:74)x′(cid:75) and d. The solution
generates an offline pair(cid:74)r′(cid:75),(cid:74)r(cid:75) ∈ Z2k where r = r′/2d. Given
such a truncation pair, parties can truncate a shared value(cid:74)x′(cid:75) by
first revealing x′ − r′ to all and jointly computing(cid:74)x(cid:75) = (cid:74)r(cid:75) +
(x′ − r′)/2d. We show that with high probability, x is a correct
truncation of x′ with at most 1 bit of error in the least significant
Session 1B: PrivacyCCS’18, October 15-19, 2018, Toronto, ON, Canada36bit. We also show how to efficiently generate the pair(cid:74)r(cid:75),(cid:74)r′(cid:75) using
high throughput techniques. This approach can be made secure
against malicious adversaries and it is easy to see that it generalizes
to an arbitrary number of parties.
Moreover, we show that fixed-point multiplication can be further
optimized when working with vectors and matrices. In particular,
the inner product of two n-dimensional vectors can be performed
using O(1) communication and a single truncation pair.
Three-party ABY framework. For training linear regression mod-
els, we only need to use arithmetic sharing, i.e. additive replicated
sharing over Z2k where k is a large value such as 64. In logistic
regression and neural network training, however, we also need to
perform computation that requires bit-level operations. The best
way to perform such tasks is to either use binary sharing i.e. additive
sharing over Z2 or Yao sharing based on three-party garbling [42].
The former is more communication efficient, with only O(n) bits
communicated for a circuit with n gates, but with the number of
rounds proportional to the circuit depth, while the latter only re-
quires 1 or 2 rounds but a higher communication cost.
We show efficient conversions between all three sharing types,
with the goal of minimizing both round and communication cost.
Please refer to Table 1 for a complete list of our conversion protocols
and their cost. When compared to the original two-party ABY
framework of [24], we reiterate that our conversion techniques,
while functionally similar, differ significantly due to large deviations
between 3PC and the less efficient 2PC techniques. To provide a
flavor of our techniques, we review our new solution for converting
an arithmetic share at the cost of a single addition circuit. Consider
sharing, party 1 holds both x1 and x2 and can compute x1 + x2
locally. Party 1 then inputs (x1 + x2) while party 3 inputs x3 to a
binary sharing 3PC that computes an addition circuit that computes
(cid:74)x(cid:75)A = (x1, x2, x3) where x = x1 + x2 + x3. Since we use replicated
(cid:74)(x1 + x2)(cid:75)B +(cid:74)x3(cid:75)B. Parties also locally compute binary sharing of
two random values(cid:74)y2(cid:75)B,(cid:74)y3(cid:75)B which are revealed to parties (1,2)
and parties (2,3) respectively. They then locally compute(cid:74)y1(cid:75)B =
((cid:74)(x1 + x2)(cid:75)B +(cid:74)x3(cid:75)B) ⊕(cid:74)y2(cid:75)B ⊕(cid:74)y3(cid:75)B and reveal it to parties (1,3).
(cid:74)x(cid:75)B = (y1, y2, y3). When using a binary sharing 3PC, we use an
This completes the semi-honest conversion to the binary sharing
optimized parallel prefix adder [33] to reduce the number of rounds
from k to loд(k) at the cost of O(k log k) bits of communication.
For a Yao sharing, we present an optimization which allows the
conversion to be performed using k AND gates and a single round
by leveraging redundancies in the replicated secret sharing.
But this approach is only secure against a semi-honest adversary.
A malicious party 1 can use a wrong value in place of (x1 + x2)
which goes undetected since the addition is done locally. We can
prevent this by performing the addition inside another malicious
3PC but this would double both round and communication cost. We
introduce new techniques to avoid this extra cost in case of binary
sharing 3PC.
3PC for piecewise polynomial functions. Piecewise polynomial
functions compute a different polynomial at each input interval. Ac-
tivation functions such as RELU are a special case of such functions
and many of the proposed approximations for other non-linear
Semi-honest
Malicious
Conversion
(cid:74)x(cid:75)A →(cid:74)x(cid:75)B
((cid:74)x(cid:75)A, i) →(cid:74)x[i](cid:75)B
(cid:74)x(cid:75)B →(cid:74)x(cid:75)A
(cid:74)b(cid:75)B →(cid:74)b(cid:75)A
(cid:74)b(cid:75)Y →(cid:74)b(cid:75)B
(cid:74)b(cid:75)B →(cid:74)b(cid:75)Y
(cid:74)x(cid:75)Y →(cid:74)x(cid:75)A
(cid:74)x(cid:75)A →(cid:74)x(cid:75)Y
Comm.
k + k log k
k
k + k log k
Rounds
1 + log k
1 + log k