communication
Dec. 2009.
336336
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:07:16 UTC from IEEE Xplore.  Restrictions apply. 
[50] C. Kaufman, P. Hoffman, Y. Nir, P. Eronen, and K. T, “RFC7296:
Internet key exchange protocol version 2 (IKEv2),” Oct. 2014.
[51] D. Kedogan, D. Agrawal, and S. Penz, “Limits of anonymity in open
environments,” in Information Hiding, 2003.
[52] R. Krikorian, “New Tweets per second record, and how!” https://blog.
twitter.com/2013/new-tweets-per-second-record-and-how, Aug. 2013.
[53] S. Le Blond, D. Choffnes, W. Zhou, P. Druschel, H. Ballani, and P. Fran-
cis, “Towards efﬁcient trafﬁc-analysis resistant anonymity networks,” in
SIGCOMM. ACM, 2013.
[54] B. Liskov and J. Cowling, “Viewstamped replication revisited,” MIT
CSAIL, Tech. Rep. MIT-CSAIL-TR-2012-021, Jul. 2013.
[55] M. G. Luby, M. Luby, and A. Wigderson, Pairwise independence and
derandomization. Now Publishers Inc, 2006.
[56] N. Mathewson and R. Dingledine, “Practical trafﬁc analysis: Extending
and resisting statistical disclosure,” in Privacy Enhancing Technologies,
2005.
[57] V. S. Miller, “Use of elliptic curves in cryptography,” in CRYPTO, 1986.
[58] J. Mirkovic and T. Benzel, “Teaching cybersecurity with DeterLab,”
Security & Privacy, vol. 10, no. 1, 2012.
[59] P. Mittal and N. Borisov, “ShadowWalker: Peer-to-peer anonymous
communication using redundant structured topologies,” in CCS. ACM,
November 2009.
[60] S. J. Murdoch and G. Danezis, “Low-cost trafﬁc analysis of Tor,” in
Security and Privacy.
IEEE, 2005.
[61] S. J. Murdoch and P. Zieli´nski, “Sampled trafﬁc analysis by Internet-
exchange-level adversaries,” in PETS, June 2007.
[62] E. Nakashima and B. Gellman, “Court gave NSA broad leeway in
surveillance, documents show,” Washington Post, 30 Jun. 2014.
[63] M. Naor, B. Pinkas, and O. Reingold, “Distributed pseudo-random
functions and KDCs,” in EUROCRYPT, 1999.
[64] National Institute of Standards and Technology, “Speciﬁcation for the
advanced encryption standard (AES),” Federal Information Processing
Standards Publication 197, Nov. 2001.
[65] C. A. Neff, “A veriﬁable secret shufﬂe and its application to e-voting,”
in CCS. ACM, 2001.
[66] D. Ongaro and J. Ousterhout, “In search of an understandable consensus
algorithm,” in ATC. USENIX, Jun. 2014.
[67] R. Ostrovsky and V. Shoup, “Private information storage,” in STOC,
1997.
[68] T. P. Pedersen, “Non-interactive and information-theoretic secure veriﬁ-
able secret sharing,” in CRYPTO, 1992.
[69] M. O. Rabin and R. L. Rivest, “Efﬁcient end to end veriﬁable electronic
voting employing split value representations,” in EVOTE 2014, Aug.
2014.
[70] C. Rackoff and D. R. Simon, “Non-interactive zero-knowledge proof of
knowledge and chosen ciphertext attack,” in CRYPTO, 1992.
[71] M. K. Reiter and A. D. Rubin, “Crowds: Anonymity for Web transac-
tions,” ACM Transactions on Information and System Security, vol. 1,
no. 1, pp. 66–92, 1998.
[72] L. Sassaman, B. Cohen, and N. Mathewson, “The Pynchon gate: A
secure method of pseudonymous mail retrieval,” in WPES, November
2005.
[73] A. Serjantov, R. Dingledine, and P. Syverson, “From a trickle to a ﬂood:
Active attacks on several mix types,” in Information Hiding, 2003.
[74] P. Syverson, “Why i’m not an entropist,” in Security Protocols XVII,
2013.
[75] M. Waidner and B. Pﬁtzmann, “The Dining Cryptographers in the disco:
Unconditional sender and recipient untraceability with computationally
secure serviceability,” in EUROCRYPT, Apr. 1989.
[76] D. Wolinsky, E. Syta, and B. Ford, “Hang with your buddies to resist
intersection attacks,” in CCS, November 2013.
[77] D. I. Wolinsky, H. Corrigan-Gibbs, A. Johnson, and B. Ford, “Dissent
in numbers: Making strong anonymity scale,” in 10th OSDI. USENIX,
Oct. 2012.
[78] A. C. Yao, “Protocols for secure computations,” in FOCS.
IEEE, 1982.
APPENDIX
A. Deﬁnition of Write Privacy
An (s, t)-write-private database scheme consists of the
following three (possibly randomized) algorithms:
337337
Write((cid:2), m) → (w(0), . . . , w(s−1)). Clients use the Write
functionality to generate the write request queries sent to
the s servers. The Write function takes as input a message
m (from some ﬁnite message space) and an integer (cid:2) and
produces a set of s write requests—one per server.
Update(σ, w) → σ(cid:2). Servers use the Update functionality to
process incoming write requests. The Update function
takes as input a server’s internal state σ, a write request
w, and outputs the updated state of the server σ(cid:2).
Reveal(σ0, . . . , σs−1) → D. At the end of the time epoch,
servers use the Reveal functionality to recover the contents
of the database. The Reveal function takes as input the
set of states from each of the s servers and produces the
plaintext database contents D.
We deﬁne the write-privacy property using the following
security game, played between the adversary (who statically
corrupts up to t servers and all but
two clients) and a
challenger.
1) In the ﬁrst step, the adversary performs the following
actions:
• The adversary selects a subset As ⊆ {0, . . . , s − 1}
|As| ≤ t. The set As
of the servers, such that
represents the set of adversarial servers. Let the set
Hs = {0, . . . , s − 1} \ As represent the set of honest
servers.
• The adversary selects a set of clients Hc ⊆ {0, . . . , n−
1}, such that |Hc| ≥ 2, representing the set of honest
clients. The adversary selects one message-location
pair per honest client:
M = {(i, mi, (cid:2)i) | i ∈ Hc}
The adversary sends As and M to the challenger.
2) In the second step, the challenger responds to the adver-
sary:
• For each (i, mi, (cid:2)i) ∈ M, the challenger generates a
write request:
(w(0)
) ← Write((cid:2)i, mi)
, . . . , w(s−1)
i
i
The set of shares of the ith write request revealed to
i }j∈AS .
the malicious servers is Wi = {w(j)
In the next steps of the game,
the challenger will
randomly reorder the honest clients’ write requests.
The challenger should learn nothing about which client
wrote what, despite all the information at its disposal.
• The challenger then samples a random permutation π
over {0, . . . ,|Hc| − 1}. The challenger sends the fol-
lowing set of write requests to the adversary, permuted
according to π:
(cid:16)Wπ(0), Wπ(1), . . . , Wπ(|Hc|−1)(cid:17)
3) For each client i in {0, . . . , n − 1} \ Hc, the adversary
computes a write request (w(0)
) (possibly
according to some malicious strategy) and sends the set
of these write requests to the challenger.
, . . . , w(s−1)
i
i
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:07:16 UTC from IEEE Xplore.  Restrictions apply. 
4) • For each server j ∈ Hs,
the challenger computes
the server’s ﬁnal state σj by running the Update
functionality on each of the n client write requests in
order. Let S = {(j, σj) | j ∈ Hs} be the set of states
of the honest servers.
• The challenger samples a bit b ←R {0, 1}. If b = 0,
the challenger send (S, π) to the adversary. Otherwise,
the challenger samples a fresh permutation π∗ on Hc
and sets (S, π∗
) to the adversary.
5) The adversary makes a guess b(cid:2) for the value of b.
The adversary wins the game if b = b(cid:2). We deﬁne the
adversary’s advantage as | Pr[b = b(cid:2)
] − 1/2|. The scheme
maintains (s, t)-write privacy if no efﬁcient adversary wins the
game with non-negligible advantage (in the implicit security
parameter).
B. Correctness Proof for (2, 1)-DPF
This appendix proves correctness of the distributed point
construction of Section IV-C. For the scheme to be correct, it
must be that, for (kA, kB) ← Gen((cid:2), m), for all (cid:2)(cid:2) ∈ ZL:
Eval(kA, (cid:2)(cid:2)
) + Eval(kB, (cid:2)(cid:2)
) = P(cid:2),m((cid:2)(cid:2)
).
Let ((cid:2)x, (cid:2)y) be the tuple in Zx × Zy representing location (cid:2)
x, (cid:2)(cid:2)
and let ((cid:2)(cid:2)
y) be the tuple representing (cid:2)(cid:2). Let:
A ← Eval(kA, (cid:2)(cid:2)
m(cid:2)
B ← Eval(kB, (cid:2)(cid:2)
m(cid:2)
).
)
x, the seeds sA[(cid:2)(cid:2)
We use a case analysis to show that the left-hand side of the
equation above equals P(cid:2),m for all (cid:2)(cid:2):
x. When (cid:2)x (cid:8)= (cid:2)(cid:2)
Case I: (cid:2)x (cid:8)= (cid:2)(cid:2)
x] and sB[(cid:2)(cid:2)
x]
are equal, so gA = gB. Similarly bA[(cid:2)(cid:2)
x] = bB[(cid:2)(cid:2)
x]. The
A will be gA[(cid:2)(cid:2)
y], The output m(cid:2)
output m(cid:2)
x]v[(cid:2)(cid:2)
y] + bA[(cid:2)(cid:2)
B
will be identical to m(cid:2)
A. Since the ﬁeld is a binary ﬁeld,
adding a value to itself results in the zero element, so the
sum m(cid:2)
sA[(cid:2)(cid:2)
bA[(cid:2)(cid:2)
gB[(cid:2)(cid:2)
applies when bA[(cid:2)(cid:2)
B will be zero as desired.
x and (cid:2)y (cid:8)= (cid:2)(cid:2)
x, the seeds
x] are not equal, so gA (cid:8)= gB. Similarly
x]. When (cid:2)y (cid:8)= (cid:2)(cid:2)
y] +
x] = 0 (an analogous argument
x] and sB[(cid:2)(cid:2)
x] (cid:8)= bB[(cid:2)(cid:2)
y]. Assume bA[(cid:2)(cid:2)
A + m(cid:2)
Case II: (cid:2)x = (cid:2)(cid:2)
y. When (cid:2)x = (cid:2)(cid:2)
y] = gA[(cid:2)(cid:2)
x] = 1), then:
y, v[(cid:2)(cid:2)
m(cid:2)
A + m(cid:2)
B = gA[(cid:2)(cid:2)
x and (cid:2)y = (cid:2)(cid:2)
B will then be:
y] + gB[(cid:2)(cid:2)
y. This is the same as Case II,
y, so the sum
y] = m when (cid:2)y = (cid:2)(cid:2)
x] + v[(cid:2)(cid:2)
y] = 0.
Case III: (cid:2)x = (cid:2)(cid:2)
except that (m · e(cid:2)y )[(cid:2)(cid:2)
m(cid:2)
A + m(cid:2)
B = m, as desired.
v[(cid:2)(cid:2)
The sum m(cid:2)
y] = (m · e(cid:2)x )[(cid:2)(cid:2)
A + m(cid:2)
y] + gA[(cid:2)(cid:2)
y] + gB[(cid:2)(cid:2)
y].
everywhere. In this case, the test vectors that servers A and
B send to the audit server will be equal everywhere and the
audit server will always output “0.”
Next, consider the case when the v vectors differ at k + 1
positions, where k > 0. The soundness error k is equal to
the probability that, for every index i(cid:2) where the vectors are
unequal (except one), there is a hash collision. Since the prob-
ability of many hash collisions is bounded by the probability
of a single hash collision, k ≤ 1. The probability, 1, of a
single collision we know from the properties of a pairwise-
independent hash function family, where each member of the
family has range R:
1 = Pr[hi ←R H : hi(vA[i]) = hi(vB[i])] ≤ 1|R|2
The overall soundness error is then at most  ≤ 1/|R|. Since
|R| (the output space of the hash function) is exponentially
large in the security parameter, this probability is negligible.
Completeness. If the vectors vA and vB differ in exactly one
position, the audit server must output “1” with overwhelming
probability. Since the audit server only outputs “1” if exactly
one element of the test vectors is equal, whenever there is at
least one collision in the hash function, the protocol will return
an incorrect result. The probability of this event happening is
negligible, however, as long as the length of the vectors is
polynomial in the security parameter.
Zero Knowledge. The zero-knowledge property need only
hold when the vectors differ at exactly one index. In this case,
servers A and B receive a single bit from the audit server (a
“1”), so the simulation is trivial for the database servers. Thus,
we only need to prove that the zero-knowledge property holds
for the audit server.
Whenever the vectors differ at exactly one position the audit
server can also simulate its view of the protocol. The audit
server simulator runs by picking length-n vectors of random
elements elements in the range of the pairwise hash function
family H subject to the constraint that the vectors are equal
at a random index i(cid:2) ∈ Zn. The simulator outputs the two
vectors as the vectors received from servers A and B.
The simulation is valid because H is a pairwise-independent
hash function family. Let H be a family of hash function hi :
D → R Then for all x, y ∈ D, by deﬁnition of pairwise
independence:
Pr[h ←R H : h(x) = h(y)] ≤ 1
R
C. Proofs for the AlmostEqual Protocol
This appendix proves security of the AlmostEqual protocol
of Section V-A.
Soundness. We compute the probability that an honest audit
server will output “1” when the vectors are not equal at exactly
one index. First, consider the case when the v vectors are equal
This property implies that the two vectors sent to the audit
server leak no information about the v vectors, since an honest
client’s v vector will be independent of the choice of hash
function h, and so every every element of the vectors sent
to the audit servers takes on every value in R with equal
probability. As in the real protocol, the simulated vectors are
equal at one random index.
338338
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:07:16 UTC from IEEE Xplore.  Restrictions apply.