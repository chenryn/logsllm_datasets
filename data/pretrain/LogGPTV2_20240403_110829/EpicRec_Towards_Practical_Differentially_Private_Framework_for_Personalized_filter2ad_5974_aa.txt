# EpicRec: Towards Practical Differentially Private Framework for Personalized Recommendation

**Authors:** Yilin Shen and Hongxia Jin  
**Affiliation:** Samsung Research America, 665 Clyde Ave, Mountain View, CA 94043  
**Email:** [PI:EMAIL]

## Abstract
Recommender systems typically require users' historical data to provide personalized recommendations, which are often processed on the cloud or server. However, the release of such private data to the cloud has been shown to put users at risk. It is highly desirable to provide high-quality personalized services while respecting user privacy.

In this paper, we introduce the first Enhanced Privacy-built-In Client for Personalized Recommendation (EpicRec) system, which performs data perturbation on the client side to protect user privacy. Our system does not assume a trusted server, requires no changes to the recommendation algorithms on the server, and minimizes user interaction, making it practical for real-world use.

The EpicRec system consists of three main modules:
1. **Usable Privacy Control Interface:** Enables two types of user-preferred privacy controls—overall and category-based—in a way that users can understand.
2. **User Privacy Level Quantification:** Automatically quantifies user privacy concern levels from user inputs.
3. **Lightweight Data Perturbation Algorithm:** Perturbs user data with provable guarantees on both differential privacy and data utility.

Using large-scale real-world datasets, we demonstrate that EpicRec outperforms existing methods in terms of both perturbation quality and personalized recommendation accuracy, with negligible computational overhead. This enables the dual goals of privacy preservation and recommendation accuracy. We also implement a proof-of-concept EpicRec system for movie recommendations with web-based privacy controls. We believe EpicRec is a significant step towards designing a practical system that allows companies to monetize user data with strong privacy protection, gaining user acceptance and adoption of their services.

## Keywords
Privacy-Preserving Recommendation, Differential Privacy, Privacy Paradox

## 1. Introduction
Over the past few decades, recommender systems have become widely used to provide personalized services, such as intelligent personal assistants and smart TV content recommendations. These personalized services are key business drivers for many companies, but they rely heavily on user data. However, privacy concerns have risen due to the release of users' private data. According to Pew Research, 68% of consumers believe current laws are insufficient to protect their privacy, and 86% of Internet users have taken steps to remove or mask their digital footprints. Governments in the US and EU are increasing and enforcing privacy regulations, and companies like LG TV have faced lawsuits over illegal data collection.

To address the tension between business intelligence and user privacy, it is crucial to develop technologies that preserve and control user data privacy while still allowing for personalized services. Without such technologies, users may stop using services, and companies may be unable to deploy services due to privacy law constraints and user concerns.

Most existing methods [5, 6, 9, 10, 11, 19] assume that the recommender server is trusted, such as in the Netflix movie recommendation system. This assumption is based on the fact that classic recommendation algorithms, like Collaborative Filtering [25], require multiple users' data. A trusted server collects all users' data and performs personalized recommendations. The most relevant privacy-preserving approach, proposed by McSherry et al. [19], adds random noise to each step of the aggregates in the recommendation algorithm. These methods aim to protect user privacy when the server releases data to third-party applications and business partners.

However, in device-cloud-based recommender systems, there are other privacy attacks (as shown in Figure 1) that cannot be addressed in a trusted server setting. For example, attackers can eavesdrop on the transmission channel and launch man-in-the-middle attacks, requiring data encryption during transmission. Malicious attackers can also break into the cloud/server and steal user data, demanding security measures like encrypting data in storage. Additionally, server insiders may leak user data to other parties.

In this paper, we design a novel and practical privacy-built-in client for untrusted server settings, where user data is perturbed and anonymized on the client side before leaving the device. This provides users with more peace of mind. Data perturbation on the client side under untrusted server settings poses additional challenges because it must be done without knowledge of other users' data.

Some existing approaches for untrusted server settings include cryptography techniques [3, 21], differential privacy-based techniques [24], and randomization techniques [23]. However, these approaches are impractical due to high computational costs, the need for an impractical trusted third party, and lack of usability.

We propose the first practical Enhanced Privacy-built-In Client for Personalized Recommendation (EpicRec) system. As shown in Figure 2, EpicRec resides on the user's hub device (e.g., personal laptop, smartphone) and collects and perturbs user data based on their privacy concerns. EpicRec satisfies users' privacy needs, requires no trusted server, and makes no changes to recommendation algorithms, making it very practical. Our contributions are summarized as follows:

- **Design of EpicRec Framework:** We design the first privacy-preserving EpicRec framework on the user client for personalized recommendation. EpicRec collects user data from various devices, provides usable privacy control interfaces, quantifies user privacy control input, and uses it to perturb user data. It supports overall and category-based privacy controls, minimizing user interactions.
- **S-EpicRec and M-EpicRec Systems:** We design S-EpicRec and M-EpicRec systems based on state-of-the-art differential privacy and utility notions. We quantify user privacy levels by optimizing utility based on underlying data properties and develop a lightweight data perturbation algorithm to preserve category aggregates with theoretical guarantees, significantly improving upon existing approaches [24].
- **Experimental Evaluation:** We conduct extensive experiments on large-scale real-world datasets, showing that our proposed S-EpicRec and M-EpicRec systems consistently outperform other methods in terms of both privacy and utility. Our approach takes less than 1.5 seconds on personal computers.
- **Proof-of-Concept Implementation:** We implement a proof-of-concept EpicRec system for personalized movie recommendations with web-based privacy controls.

The rest of the paper is organized as follows. Section 2 discusses related work. Section 3 presents the background and architecture design of the EpicRec system. Sections 4 and 5 detail the design of S-EpicRec and M-EpicRec systems. Section 6 presents experimental results, and Section 7 describes the implementation of the proof-of-concept system. Section 8 concludes the paper and discusses future work.

## 2. Related Work
### Privacy-Preserving Recommendation
Table 1 compares our EpicRec system with existing approaches for personalized recommendation under untrusted server settings. The earliest work by Polat et al. [23] developed randomized mechanisms to perturb user data, but it lacked provable privacy guarantees and was later found to be vulnerable to clustering methods [30].

Cryptography-based approaches [21, 3] offer privacy guarantees but require a trusted third party and expensive computations. Another class of approaches [24] is based on differential privacy, providing both privacy and utility guarantees. However, these approaches largely ignore the need for user-friendly privacy controls.

### Differential Privacy
Differential privacy [7, 8] has become the de facto standard for privacy-preserving data analytics. Dwork et al. [8] established guidelines for guaranteeing differential privacy for individual aggregate queries by calibrating Laplace noise based on global sensitivity. Various works have adopted this definition for publishing histograms [28], search logs [15], mining data streams [4], and record linkage [1].

Machanavajjhala et al. [18] proposed probabilistic differential privacy, which allows for high-probability privacy preservation, improving flexibility. Nissim et al. [22] introduced local sensitivity and smooth sensitivity, allowing for instance-based noise injection. However, these approaches require strict satisfaction of perturbed aggregates, limiting their application to statistical data publishing.

A recent work [24] addresses these constraints by perturbing data to ensure both differential privacy and recommendation quality. Our data perturbation module in EpicRec builds on this work, providing a practical solution for untrusted server settings.

[Figures and Tables are referenced but not included in this text. Please refer to the original document for visual aids.]