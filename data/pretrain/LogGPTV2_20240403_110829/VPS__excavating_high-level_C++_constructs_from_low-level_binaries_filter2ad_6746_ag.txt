220.2 (+ 2%)
153.3 (+13%)
370.2 (+28%)
351.6 (+ 0%)
249.4 (+35%)
+ 11%
271.8
586.3
498.7
507.4
366.8
325.8
345.1
535.5
271.8 (+ 0%)
603.1 (+ 3%)
572.0 (+15%)
661.7 (+30%)
461.5 (+26%)
328.6 (+ 1%)
353.1 (+ 2%)
534.6 (+ 0%)
+ 9%
8.1 Counterfeit Object-oriented Programming
CFI approaches targeting C++ must cope with advanced attackers
using Counterfeit Object-oriented Programming (COOP) attacks
[11, 38]. This attack class thwarts defenses that do not accurately
model C++ semantics. As we argue below, vps reduces the attack
surface sufficiently that practical COOP attacks are infeasible.
For a successful COOP attack, an attacker must control a con-
tainer filled with objects, with a loop invoking a virtual function
on each object. The loop may be an actual loop, called a main loop
gadget, or can be achieved through recursion, called a recursion
gadget. We refer to both types as loop gadget. The attacker places
counterfeit objects in the container, allowing them to hijack control
flow when the loop executes each object’s virtual function. To pass
data between objects, the attacker can overlap the objects’ fields.
The first restriction vps imposes on an attacker is to prevent
filling the container with counterfeit objects; because the objects
were not created at legitimate object creation sites, the safe memory
does not contain stored vtblptrs for them. An attacker has only two
options to craft a container of counterfeit objects under vps: either
the program allows attackers to arbitrarily invoke constructors and
create objects, or the attacker can coax the program into creating
all objects needed on their behalf. The former occurs (in restricted
form) only in programs with scripting capabilities. The latter sce-
nario, besides requiring a cooperative victim program, hinges on
the attacker’s ability to scan data memory to find all needed objects
without crashing the program (hence losing the created objects)
and filling the container with pointers to these.
The second restriction is prohibiting overlapping objects (used
for data transfer in COOP), since objects can only be created by
legitimate constructors. As a result, a COOP attack would have to
pass data via argument registers or scratch memory instead. Data
passing via argument registers works only if the loop gadget does
not modify the argument registers between invocations. Moreover,
the virtual functions called must leave their results in the correct
argument registers when they return. Passing data via scratch mem-
ory limits the attack to the use of virtual functions that work on
memory areas. The pointer to the scratch memory area must then
be passed to the virtual function gadgets either via an argument
register (subject to the earlier limitations), or via a field in the ob-
ject. To use a field in the object as a pointer to scratch memory, the
attacker must overwrite that field prior to the attack, which could
lead to a crash if the application tries to use the modified object.
As a third restriction, vps’s checks of the vtblptr at each vcall
instruction limit the virtual functions attackers can use at a loop
gadget. Only the virtual function at the specific vtable offset used by
the vcall is allowed; attackers cannot “shift” vtables to invoke alter-
native entries. This security policy is comparable to vfGuard [35].
To summarize, vps restricts three crucial COOP components:
object creation, data transfer, and loop gadget selection. Because all
proof-of-concept exploits by Schuster et al. [38] rely on object over-
lapping as a means of transferring data, vps successfully prevents
them. Moreover, Schuster et al. recognize vfGuard as a significant
constraint for an attacker performing a COOP attack. Given that
vps raises the bar even more than vfGuard, we argue that vps makes
currently existing COOP attacks infeasible.
We found that multiple of the virtual callsites missed by VTV (as
shown in Section 7.1) reside in a loop in a destructor function (sim-
ilar to the main loop gadget example used by Schuster et al. [38]).
Because the loop iterates over a container of objects and uses a
virtual call on each object, COOP attacks can leverage these missed
110callsites as a main loop gadget even with VTV enabled. This demon-
strates the need for defense-in-depth, with multiple hurdles for an
attacker to cross in case of inaccuracies in the analysis.
8.2 Limitations
At the moment, our proof-of-concept implementation of the in-
strumentation ignores object deletion because it does not affect
the consistency of the safe memory. As a result, when an object is
deleted, its old vtblptr is still stored in safe memory. If an attacker
manages to control the memory of the deleted object, they can
craft a new object that uses the same vtable as the original object.
Because the vtblptr remains unchanged, this attack is analogous
to corrupting an object’s fields and does not allow the attacker
to hijack control. Thus, while our approach does not completely
prevent use-after-free, it forces an attacker to re-use the type of the
object previously stored in the attacked memory.
Another limitation of our approach lies in the runtime verifica-
tion of candidate vcall sites. If an attacker uses an unverified vcall
instruction, they can force the analysis instrumentation to detect a
“false positive” vcall and remove the security instrumentation for
this instruction, leaving the vcall unprotected. Because we cache
analysis results, this attack only works for vcall sites that are unver-
ified in the static analysis and have never been executed before in
any run of the program (since otherwise only the security check is
performed), leading to a race condition between the analysis instru-
mentation and the attacker. The only way to mitigate this issue is
by improving coverage during the dynamic profiling analysis and
therefore reducing the number of unverified vcalls. This is possible
by running test cases for the protected program or through tech-
niques such as fuzzing [22, 36]. Note also that this attack requires
specific knowledge of an unverified vcall; if the attacker guesses
wrong and attacks a known vcall, we detect and log the attack.
vps inherits some limitations from Dyninst, such as Dyninst’s
inability to instrument functions that catch or throw C++ exceptions
and Dyninst’s inability to instrument functions for which it fails to
reconstruct a CFG. These limitations are not fundamental to vps
and can be resolved with additional engineering effort.
Finally, we note that our safe memory region implementation—
an orthogonal research topic [27] and merely a building block for
vps—can be enhanced to provide stronger protection against prob-
ing attacks [20, 32]. For example, this can be done by using hardware
features such as Memory Protection Keys (MPK) [10]. In the cur-
rent implementation, an adversary might still be able to overwrite
values in the safe memory region under the right circumstances.
9 RELATED WORK
Marx [33] reconstructs class hierarchies from binaries for VTable
Protection and Type-safe Object Reuse. VTable Protection verifies at
each vcall whether the vtblptr resides in the reconstructed class hier-
archy. However, the analysis is incomplete and the instrumentation
falls back to PathArmor [45] for missing results. Marx’s Type-safe
Object Reuse prevents memory reuse between different class hier-
archies, reducing the damage that can be done with use-after-free.
However, this approach leaves considerable wiggle room for at-
tackers for large class hierarchies. In contrast, vps does not rely on
class hierarchy information and provides stronger security by only
allowing exactly correct types. Moreover, Marx only protects the
heap whereas vps protects all objects.
VTint [48] instruments vtables with IDs to check their validity,
but unlike vps allows exchanging the original vtblptr with a new
pointer to an existing vtable. Moreover, VTint breaks the binary in
case of false positives.
VTPin [37] overwrites the vtblptr whenever an object is freed
to protect against use-after-free, but it requires RTTI and does not
prevent vtblptr overwrites in general.
vfGuard [35] identifies vtables and builds a mapping of valid
target functions at each vtable offset. At vcalls, it checks the target
and calling convention. Unlike vps, vfGuard allows fake vtables
as long as each entry appears in a valid vtable at the same offset.
Further, vfGuard may break the binary in case of false positives.
T-VIP [17] protects vcalls against fake vtables, but breaks the
binary when vtables reside in writable memory (e.g., in .bss).
Moreover, unlike vps, T-VIP uses potentially bypassable heuristics.
VCI [14] only allows a specific set of vtables at each vcall, mimick-
ing VTV [43]. When the analysis cannot rebuild the sets precisely,
VCI falls back to vfGuard. Moreover, false positive virtual callsites in
VCI break the application, as may incomplete class hierarchies (e.g.,
due to abstract classes [33]). In contrast, vps allows calls through
any legitimately created object. Moreover, even in the hypothetical
case of a perfect VCI analysis, VCI allows changing the vtblptr to
another one in the set, unlike vps.
VTV [43] is a GCC compiler pass that only allows a statically
determined set of vtables at each vcall, like most binary-only ap-
proaches [14, 17, 33, 35].
CFIXX [7] is the state-of-the-art source-based C++ defense. Like
vps, it stores vtblptrs in safe memory and fetches them at each
callsite. Given the lack of comparison against the vtblptr as stored
in the object, CFIXX prevents but does not detect vtable hijacking.
As an LLVM compiler extension, CFIXX cannot protect applica-
tions for which no source code (and LLVM compilation) is available.
Therefore, proprietary legacy applications cannot be protected af-
terwards. While CFIXX and vps offer similar security, our binary-
level analysis is completely novel. Unlike source-level analysis, our
analysis must consider both direct and indirect vtable accesses.
Moreover, identifying the virtual callsites for subsequent security
instrumentation is challenging given the lack of type information.
10 CONCLUSION
In this paper, we presented vps, a practical binary-level defense
against C++ vtable hijacking. While prior work restricts the tar-
gets of virtual calls, we protect objects at creation time and only
allow virtual calls reachable by the object, sidestepping accuracy
problems. vps improves correctness by handling false positives at
vcall verification. During our evaluation, we also uncovered several
inaccuracies in VTV, a source-based approach that is considered
the state-of-the-art among C++ defenses. We release vps as open
source software to foster research on this topic.
ACKNOWLEDGEMENTS
This work was supported by the German Research Foundation
(DFG) within the framework of the Excellence Strategy of the Fed-
eral Government and the States – EXC 2092 CaSa – 39078197, by
111the United States Office of Naval Research under contracts N00014-
17-1-2782 and N00014-17-S-B010 “BinRec”, and by the European
Research Council (ERC) under the European Union’s Horizon 2020
research and innovation programme under grant agreement No.
786669 (ReAct), No. 825377 (UNICORE), and No. 640110 (BASTION).
Any opinions, findings, and conclusions or recommendations ex-
pressed in this paper are those of the authors and do not necessarily
reflect the views of any of the sponsors or any of their affiliates.
REFERENCES
[1] 2018. Executable and Linkable Format (ELF). https://www.cs.cmu.edu/afs/cs/
academic/class/15213-s00/doc/elf.pdf.
[2] Martín Abadi, Mihai Budiu, Ulfar Erlingsson, and Jay Ligatti. 2005. Control-Flow
Integrity. In ACM Conference on Computer and Communications Security (CCS).
[3] Adobe. 2019. Adobe Flash Player. https://get.adobe.com/de/flashplayer/.
[4] Andrew R. Bernat and Barton P. Miller. 2011. Anywhere, Any-Time Binary
Instrumentation. In ACM SIGPLAN-SIGSOFT Workshop on Program Analysis for
Software Tools and Engineering (PASTE).
[5] Tyler Bletsch, Xuxian Jiang, and Vince Freeh. 2011. Mitigating Code-reuse Attacks
with Control-Flow Locking. In Annual Computer Security Applications Conference
(ACSAC).
[6] Dimitar Bounov, Rami Gökhan Kici, and Sorin Lerner. 2016. Protecting C++
Dynamic Dispatch Through VTable Interleaving. In Symposium on Network and
Distributed System Security (NDSS).
[7] Nathan Burow, Derrick McKee, Scott A Carr, and Mathias Payer. 2018. CFIXX:
Object Type Integrity for C++ Virtual Dispatch. In Symposium on Network and
Distributed System Security (NDSS).
[8] Nicholas Carlini, Antonio Barresi, Mathias Payer, David Wagner, and Thomas R
Gross. 2015. Control-Flow Bending: On the Effectiveness of Control-Flow In-
tegrity. In USENIX Security Symposium.
[9] Mauro Conti, Stephen Crane, Lucas Davi, Michael Franz, Per Larsen, Marco
Negro, Christopher Liebchen, Mohaned Qunaibit, and Ahmad-Reza Sadeghi.
2015. Losing Control: On the Effectiveness of Control-Flow Integrity under Stack
Attacks. In ACM Conference on Computer and Communications Security (CCS).
[10] Jonathan Corbet. 2015. Memory protection keys. https://lwn.net/Articles/
643797/.
1.83.html.
[11] Stephen J Crane, Stijn Volckaert, Felix Schuster, Christopher Liebchen, Per Larsen,
Lucas Davi, Ahmad-Reza Sadeghi, Thorsten Holz, Bjorn De Sutter, and Michael
Franz. 2015. It’s a TRaP: Table Randomization and Protection against Function-
Reuse Attacks. In ACM Conference on Computer and Communications Security
(CCS).
[12] Ron Cytron, Jeanne Ferrante, Barry K Rosen, Mark N Wegman, and F Kenneth
Zadeck. 1991. Efficiently Computing Static Single Assignment Form and the
Control Dependence Graph. In ACM Transactions on Programming Languages
and Systems (TOPLAS).
[13] Valgrind Developers. 2018. Valgrind. http://www.valgrind.org/.
[14] Mohamed Elsabagh, Dan Fleck, and Angelos Stavrou. 2017. Strict Virtual Call In-
tegrity Checking for C++ Binaries. In ACM Symposium on Information, Computer
and Communications Security (ASIACCS).
[15] Agner Fog. 2018. Calling conventions for different C++ compilers and operating
systems. http://agner.org/optimize/calling_conventions.pdf.
[16] Linux Foundation. 2018. Itanium C++ ABI. http://refspecs.linuxbase.org/cxxabi-
[17] Robert Gawlik and Thorsten Holz. 2014. Towards Automated Integrity Protection
of C++ Virtual Function Tables in Binary Programs. In Annual Computer Security
Applications Conference (ACSAC).
[18] Xinyang Ge, Mathias Payer, and Trent Jaeger. 2017. An Evil Copy: how the
Loader Betrays You. In Symposium on Network and Distributed System Security
(NDSS).
[19] Enes Göktas, Elias Athanasopoulos, Herbert Bos, and Georgios Portokalidis. 2014.
Out Of Control: Overcoming Control-Flow Integrity. In IEEE Symposium on
Security and Privacy (S&P).
[20] Enes Goktas, Robert Gawlik, Benjamin Kollenda, Elias Athanasopoulos, Georgios
Portokalidis, Cristiano Giuffrida, and Herbert Bos. 2016. Undermining Informa-
tion Hiding (And What to do About it). In USENIX Security Symposium.
[21] Google. 2018. Protocol Buffers. https://developers.google.com/protocol-buffers/.
[22] Jesse Hertz. 2018. Project Triforce: Run AFL on Everything! https://www.
nccgroup.trust/us/about-us/newsroom-and-events/blog/2016/june/project-
triforce-run-afl-on-everything/.
[23] IDAPython. 2018. IDAPython. https://github.com/idapython.
[24] Wesley Jin, Cory Cohen, Jeffrey Gennari, Charles Hines, Sagar Chaki, Arie
Gurfinkel, Jeffrey Havrilla, and Priya Narasimhan. 2014. Recovering C++ Objects
From Binaries Using Inter-Procedural Data-Flow Analysis. In ACM SIGPLAN
Program Protection and Reverse Engineering Workshop (PPREW).
[25] Omer Katz, Ran El-Yaniv, and Eran Yahav. 2016. Estimating Types in Binaries
using Predictive Modeling. In ACM Symposium on Principles of Programming
Languages (POPL).
[26] Omer Katz, Noam Rinetzky, and Eran Yahav. 2018. Statistical Reconstruction of
Class Hierarchies in Binaries. In International Conference on Architectural Support
for Programming Languages and Operating Systems (ASPLOS).
[27] Koen Koning, Xi Chen, Herbert Bos, Cristiano Giuffrida, and Elias Athanasopou-
los. 2017. No Need to Hide: Protecting Safe Regions on Commodity Hardware.
In European Conference on Computer Systems (EuroSys).
[28] Volodymyr Kuznetsov, László Szekeres, Mathias Payer, George Candea, R Sekar,
and Dawn Song. 2014. Code-Pointer Integrity. In USENIX Symposium on Operating
Systems Design and Implementation (OSDI).
[29] Chi-Keung Luk, Robert Cohn, Robert Muth, Harish Patil, Artur Klauser, Geoff
Lowney, Steven Wallace, Vijay Janapa Reddi, and Kim Hazelwood. 2005. Pin:
Building Customized Program Analysis Tools with Dynamic Instrumentation. In
ACM SIGPLAN Conference on Programming Language Design and Implementation
(PLDI).
[30] Ben Niu and Gang Tan. 2014. Modular Control-Flow Integrity. In ACM SIGPLAN
Conference on Programming Language Design and Implementation (PLDI).
[31] United States Government Accountability Office. 2016. Federal Agencies Need to
Address Aging Legacy Systems. https://www.gao.gov/assets/680/677436.pdf.
[32] Angelos Oikonomopoulos, Elias Athanasopoulos, Herbert Bos, and Cristiano
Giuffrida. 2016. Poking Holes in Information Hiding. In USENIX Security Sympo-
sium.
[33] Andre Pawlowski, Moritz Contag, Victor van der Veen, Chris Ouwehand,
Thorsten Holz, Herbert Bos, Elias Athanasopoulos, and Cristiano Giuffrida. 2017.
MARX: Uncovering Class Hierarchies in C++ Programs. In Symposium on Network
and Distributed System Security (NDSS).
[34] Pieter Philippaerts, Yves Younan, Stijn Muylle, Frank Piessens, Sven Lachmund,
and Thomas Walter. 2011. Code Pointer Masking: Hardening Applications against
Code Injection Attacks. In Conference on Detection of Intrusions and Malware &
Vulnerability Assessment (DIMVA).
[35] Aravind Prakash, Xunchao Hu, and Heng Yin. 2015. vfGuard: Strict Protection
for Virtual Function Calls in COTS C++ Binaries. In Symposium on Network and
Distributed System Security (NDSS).
[36] Sanjay Rawat, Vivek Jain, Ashish Kumar, Lucian Cojocar, Cristiano Giuffrida,
and Herbert Bos. 2017. Vuzzer: Application-aware Evolutionary Fuzzing. In
Symposium on Network and Distributed System Security (NDSS).
[37] Pawel Sarbinowski, Vasileios P Kemerlis, Cristiano Giuffrida, and Elias Athana-
sopoulos. 2016. VTPin: Practical VTable Hijacking Protection for Binaries. In
Annual Computer Security Applications Conference (ACSAC).
[38] Felix Schuster, Thomas Tendyck, Christopher Liebchen, Lucas Davi, Ahmad-Reza
Sadeghi, and Thorsten Holz. 2015. Counterfeit Object-oriented Programming:
On the Difficulty of Preventing Code Reuse Attacks in C++ Applications. In IEEE
Symposium on Security and Privacy (S&P).
[39] SPEC. 2018. SPEC CPU2006. https://www.spec.org/cpu2006.
[40] SPEC. 2018. SPEC CPU2017. https://www.spec.org/cpu2017.
[41] Bjarne Stroustrup. 2013. The C++ Programming Language. Pearson Education.
[42] Caroline Tice. 2012. Improving Function Pointer Security for Virtual Method
Dispatches. In GNU Tools Cauldron Workshop.
[43] Caroline Tice, Tom Roeder, Peter Collingbourne, Stephen Checkoway, Úlfar
Erlingsson, Luis Lozano, and Geoff Pike. 2014. Enforcing Forward-Edge Control-
Flow Integrity in GCC & LLVM. In USENIX Security Symposium.
[44] Victor van der Veen. 2017. Trends in Memory Errors. https://vvdveen.com/
memory-errors/.
[45] Victor van der Veen, Dennis Andriesse, Enes Göktaş, Ben Gras, Lionel Sambuc,
Asia Slowinska, Herbert Bos, and Cristiano Giuffrida. 2015. Practical Context-
Sensitive CFI. In ACM Conference on Computer and Communications Security
(CCS).
[46] Victor van der Veen, Dennis Andriesse, Manolis Stamatogiannakis, Xi Chen,
Herbert Bos, and Cristiano Giuffrida. 2017. The Dynamics of Innocent Flesh
on the Bone: Code Reuse Ten Years Later. In ACM Conference on Computer and
Communications Security (CCS).
[47] Victor Van Der Veen, Enes Göktas, Moritz Contag, Andre Pawoloski, Xi Chen,
Sanjay Rawat, Herbert Bos, Thorsten Holz, Elias Athanasopoulos, and Cristiano
Giuffrida. 2016. A Tough Call: Mitigating Advanced Code-Reuse Attacks at the
Binary Level. In IEEE Symposium on Security and Privacy (S&P).
[48] Chao Zhang, Chengyu Song, Kevin Zhijie Chen, Zhaofeng Chen, and Dawn Song.
2015. VTint: Protecting Virtual Function Tables’ Integrity. In Symposium on
Network and Distributed System Security (NDSS).
[49] Chao Zhang, Dawn Song, Scott A Carr, Mathias Payer, Tongxin Li, Yu Ding, and
Chengyu Song. 2016. VTrust: Regaining Trust on Virtual Calls.. In Symposium
on Network and Distributed System Security (NDSS).
112