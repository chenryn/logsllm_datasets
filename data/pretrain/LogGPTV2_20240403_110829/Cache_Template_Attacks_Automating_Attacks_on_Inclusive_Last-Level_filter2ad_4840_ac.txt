negatives. Cache hits that coincide with an event are
counted as true positive and cache hits that do not coin-
cide with an event as false positive. Cache misses which
coincide with an event are counted as true negative and
cache misses which do not coincide with an event as false
negative. Based on these four values we can determine
the accuracy of our Template, for instance, by computing
the F-Score, which is deﬁned as the harmonic mean of
the cache-hit ratio and the positive predictive value (per-
centage of true positives of the total cache hits). High
F-Score values show that we can distinguish the given
event accurately by attacking a speciﬁc address. In some
cases further lines can be pruned from the Cache Tem-
plate matrix based on these measures. The true positive
rate and the false positive rate for an event e can be de-
termined by the proﬁle (cid:31)pe of e and the average over all
proﬁles except e.
Runtime of
the Proﬁling Phase. Measuring the
cache-hit ratio is the most expensive step in our attack.
To quantify the cost we give two examples.
In both
cases we want to proﬁle a 1 MB library, once for a low-
frequency event, e.g., a keypress, and once for a high-
frequency event, e.g., an encryption. In both cases, we
try to achieve a runtime which is realistic for ofﬂine and
online attacks while maintaining a high accuracy.
We choose a proﬁling duration of d = 0.8 seconds for
the low-frequency event. During 0.8 seconds we can trig-
ger around 200 events, which is enough to create a highly
accurate proﬁle. Proﬁling each address in the library for
0.8 seconds would take 10 days. Proﬁling only cache-
line-aligned addresses still takes 4 hours. Applying both
optimizations, the full library is proﬁled in 17 seconds.
In case of the high-frequency event, we attack an en-
cryption. We assume that one encryption and the cor-
responding Flush+Reload measurement take 520 cycles
on average. As in the previous example, we proﬁle each
address 200 times and, thus, we need 40–50 microsec-
onds per address, i.e., d = 50µs. The basic attack takes
less than 55 seconds to proﬁle the full library for one
event. Proﬁling only cache-line-aligned addresses takes
less than 1 second and applying both optimizations re-
sults in a negligible runtime.
As already mentioned above, the accuracy of the re-
sulting proﬁle depends on how many times an event can
be triggered during proﬁling duration d. In both cases we
chose durations which are more than sufﬁcient to create
accurate proﬁles and still achieve reasonable execution
times for an online attack. Our observations showed that
it is necessary to proﬁle each event at least 10 times to
get meaningful results. However, proﬁling an event more
than a few hundred times does not increase the accuracy
of the proﬁle anymore.
3.2 Exploitation Phase
In the exploitation phase we execute a generic spy pro-
gram which performs either the Flush+Reload or the
Prime+Probe algorithm. For all addresses in the Cache
Template matrix resulting from the proﬁling phase, the
cache activity is constantly monitored.
We monitor all addresses and record whether a cache
hit occurred. This information is stored in a boolean vec-
tor (cid:31)h. To determine which event occurred based on this
observation, we compute the similarity S((cid:31)h,(cid:31)pe) between
(cid:31)h and each proﬁle (cid:31)pe from the Cache Template matrix.
The similarity measure S can be based, for example, on
a mean squared error (MSE) function. Algorithm 2 sum-
marizes the exploitation phase.
Algorithm 2: Exploitation phase.
Input: Target program binary b,
Cache Template matrix T = ((cid:31)pe1,(cid:31)pe2 , ...,(cid:31)pen)
Map binary b into memory
repeat
foreach address a in T do
Flush+Reload attack on address a
Store 0/1 in(cid:31)h[a] for cache miss/cache hit
end
if (cid:31)pe equals(cid:31)h w.r.t. similarity measure then
Event e detected
end
The exploitation phase has the same requirements as
the underlying attack techniques. The attacker needs to
be able to execute a spy program on the attacked sys-
tem.
In case of Flush+Reload, the spy program needs
no privileges, except opening the attacked program bi-
nary in a read-only shared memory. It is even possible
6
902  24th USENIX Security Symposium 
USENIX Association
while ( 1 ) {
1 i n t map [ 1 3 0 ] [ 1 0 2 4 ] = {{−1U} , . . . ,{ − 1 3 0U}};
2 i n t main ( i n t argc , char∗∗ a r g v ) {
3
4
5
6
7 } }
Listing 1: Victim program with large array on Linux
/ / u n b u f f e r e d
( map [ ( c % 128) + 1 ] [ 0 ] == 0 )
e x i t (−1) ;
i n t c = g e t c h a r ( ) ;
i f
0
1
2
3
S
S
E
R
D
D
A
0x32040
0x33040
0x34040
0x35040
0x36040
0x37040
0x38040
0x39040
0x3a040
0x3b040
KEY
4
5
6
7
8
9
to attack binaries running in a different virtual machine
on the same physical machine, if the hypervisor has page
deduplication enabled. In case of Prime+Probe, the spy
program needs no privileges at all and it is even possi-
ble to attack binaries running in a different virtual ma-
chine on the same physical machine, as shown by Irazo-
qui et al. [20]. However, the Prime+Probe technique is
more susceptible to noise and therefore the exploitation
phase will produce less reliable results, making attacks
on low-frequency events more difﬁcult.
The result of the exploitation phase is a log ﬁle con-
taining all detected events and their corresponding times-
tamps. The interpretation of the log ﬁle still has to be
done manually by the attacker.
4 Attacks on Artiﬁcial Applications
Before we actually exploit cache-based vulnerabilities in
real applications in Section 5, we demonstrate the basic
working principle of Cache Template Attacks on two ar-
tiﬁcial victim programs. These illustrative attacks show
how Cache Template Attacks automatically proﬁle and
exploit cache activity in any program. The two attack
scenarios we demonstrate are: 1) an attack on lookup
tables, and 2) an attack on executed instructions. Hence,
our ideal victim program or library either contains a large
lookup table which is accessed depending on secret in-
formation, e.g., depending on secret lookup indices, or
speciﬁc portions of program code which are executed
based on secret information.
Attack on Data Accesses. For demonstration pur-
poses, we spy on simple events like keypresses.
In
our victim program, shown in Listing 1, each keypress
causes a memory access in a large array called map.
These key-based accesses are 4096 bytes apart from each
other to avoid triggering the prefetcher. The array is ini-
tialized with static values in order to place it in the data
segment and to guarantee that each page contains differ-
ent data and, thus, is not deduplicated in any way. It is
necessary to place it in the data segment in order to make
it shareable with the spy program.
In the proﬁling phase of the Cache Template Attack,
we simulate different keystroke events using the X11 au-
Figure 2: Cache Template matrix for the artiﬁcial victim
program shown in Listing 1. Dark cells indicate high
cache-hit ratios.
tomation library libxdo. This library can be linked stat-
ically into the spy program, i.e., it does not need to be
installed. The Cache Template matrix is generated as de-
scribed in Section 3. Within a duration of d = 0.8 sec-
onds we simulated around 700 keypress events. The re-
sulting Cache Template matrix can be seen in Figure 2
for all number keys. We observe cache hits on addresses
that are exactly 4 096 bytes apart, which is due to the data
type and the dimension of the map array. In our measure-
ments, there were less than 0.3% false positive cache hits
on the corresponding addresses and less than 2% false
negative cache hits. The false positive and false negative
cache hits are due to the high key rate in the keypress
simulation.
For veriﬁcation purposes, we executed the generated
keylogger for a period of 60 seconds and randomly
pressed keys on the keyboard. In this setting we mea-
sured no false positives and no false negatives at all.
This results from signiﬁcantly lower key rates than in the
proﬁling phase. The table is not used by any process
other than the spy and the victim process and the proba-
bility that the array access happens exactly between the
reload and the ﬂush instruction is rather small, as we have
longer idle periods than during the proﬁling phase. Thus,
we are able to uniquely identify each key without errors.
Attack on Instruction Executions. The same attack
can easily be performed on executed instructions. The
source code for this example is shown in Listing 2. Each
key is now processed in its own function, as deﬁned by
the CASE(X) macro. The functions are page aligned to
avoid prefetcher activity. The NOP1024 macro generates
1024 nop instructions, which is enough to avoid acciden-
tal code prefetching of function code.
Our measurements show that there is no difference
between Cache Template Attacks on code and data ac-
cesses.
Performance Evaluation. To examine the perfor-
mance limits of the exploitation phase of Cache Template
Attacks, we evaluated the number of addresses which can
USENIX Association  
24th USENIX Security Symposium  903
7
f ##X( ) ; break ; }
1 # d e f i n e NOP1024 /∗ 1024 t i m e s asm ( ” nop ” ) ; ∗ /
2 # d e f i n e CASE(X) case X:\
{ ALIGN( 0 x1000 ) void f ##X( ) { NOP1024 };\
3
4
5 i n t main ( i n t argc , char∗∗ a r g v ) {
6
7
8
9
10
11
12 } } }
Listing 2: Victim program with long functions on Linux
i n t c = g e t c h a r ( ) ;
switch ( c ) {
/ / u n b u f f e r e d
while ( 1 ) {
CASE ( 0 ) ;
/ /
CASE( 1 2 8 ) ;
. . .
be accurately monitored simultaneously at different key
rates. At a key rate of 50 keys per second, we man-
aged to spy on 16000 addresses simultaneously on an
Intel i5 Sandy Bridge CPU without any false positives or
false negatives. The ﬁrst errors occurred when monitor-
ing 18000 addresses simultaneously. At a key rate of 250
keys per second, which is the maximum on our system,
we were able to spy on 4000 addresses simultaneously
without any errors. The ﬁrst errors occurred when moni-
toring 5000 addresses simultaneously. In both cases, we
monitor signiﬁcantly more addresses than in any practi-
cal cache attack today.
However, monitoring that many addresses is only pos-
sible if their position in virtual memory is such that the
prefetcher remains inactive. Accessing several consec-
utive addresses on the same page causes prefetching of
more data, resulting in cache hits although no program
accessed the data. The limiting effect of the prefetcher
on the Flush+Reload attack has already been observed
by Yarom and Benger [54]. Based on these observations,
we discuss the possibility of using the prefetcher as an
effective countermeasure against cache attacks in Sec-
tion 6.3.
5 Attacks on Real-World Applications
In this section, we consider an attack scenario where an
attacker is able to execute an attack tool on a targeted
machine in unprivileged mode. By executing this at-
tack tool, the attacker extracts the cache-activity proﬁles
which are exploited subsequently. Afterwards, the at-
tacker collects the secret information acquired during the
exploitation phase.
For this rather realistic and powerful scenario we
present various case studies of attacks launched against
real applications. We demonstrate the power of automat-
ically launching cache attacks against any binary or li-
brary. First, we launch two attacks on Linux user inter-
faces, including GDK-based user interfaces, and an at-
tack against a Windows user interface. In all attacks we
simulate the user input in the proﬁling phase. Thus, the
attack can be automated on the device under attack. To
demonstrate the range of possible applications, we also
present an automated attack on the T-table-based AES
implementation of OpenSSL 1.0.2 [37].
5.1 Attack on Linux User Interfaces
There exists a variety of software-based side-channel at-
tacks on user input data. These attacks either measure
differences in the execution time of code in other pro-