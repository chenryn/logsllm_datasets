## 构建逻辑回归分类器逻辑回归虽然不在我们讲解的十大经典数据挖掘算法里面，但也是常用的数据挖掘算法。逻辑回归，也叫作 logistic回归。虽然名字中带有"回归"，但它实际上是分类方法，主要解决的是二分类问题，当然它也可以解决多分类问题，只是二分类更常见一些。在逻辑回归中使用了 Logistic 函数，也称为 Sigmoid 函数。Sigmoid函数是在深度学习中经常用到的函数之一，函数公式为：![](Images/2af54c575e8c3bd34b45a0b616d377b0.png){savepage-src="https://static001.geekbang.org/resource/image/3e/18/3e7c7cb4d26d1a71f958610f26d20818.png"}\函数的图形如下所示，类似 S 状：![](Images/2459d08fea25c270b370326dc28ae1ab.png){savepage-src="https://static001.geekbang.org/resource/image/b7/3b/b7a5d39d91fda02b21669137a489743b.png"}\你能看出 g(z) 的结果在 0-1 之间，当 z 越大的时候，g(z) 越大，当 z趋近于无穷大的时候，g(z) 趋近于 1。同样当 z 趋近于无穷小的时候，g(z)趋近于 0。同时，函数值以 0.5 为中心。``{=html}为什么逻辑回归算法是基于 Sigmoid函数实现的呢？你可以这样理解：我们要实现一个二分类任务，0 即为不发生，1即为发生。我们给定一些历史数据 X 和 y。其中 X 代表样本的 n 个特征，y代表正例和负例，也就是 0 或 1的取值。通过历史样本的学习，我们可以得到一个模型，当给定新的 X的时候，可以预测出 y。这里我们得到的 y 是一个预测的概率，通常不是 0% 和100%，而是中间的取值，那么我们就可以认为概率大于 50%的时候，即为发生（正例），概率小于 50%的时候，即为不发生（负例）。这样就完成了二分类的预测。逻辑回归模型的求解这里不做介绍，我们来看下如何使用 sklearn中的逻辑回归工具。在 sklearn 中，我们使用 LogisticRegression()函数构建逻辑回归分类器，函数里有一些常用的构造参数：1.  penalty：惩罚项，取值为 l1 或 l2，默认为    l2。当模型参数满足高斯分布的时候，使用    l2，当模型参数满足拉普拉斯分布的时候，使用 l1；2.  solver：代表的是逻辑回归损失函数的优化方法。有 5 个参数可选，分别为    liblinear、lbfgs、newton-cg、sag 和 saga。默认为    liblinear，适用于数据量小的数据集，当数据量大的时候可以选用 sag 或    saga 方法。3.  max_iter：算法收敛的最大迭代次数，默认为 10。4.  n_jobs：拟合和预测的时候 CPU 的核数，默认是 1，也可以是整数，如果是    -1 则代表 CPU 的核数。当我们创建好之后，就可以使用 fit 函数拟合，使用 predict 函数预测。
## 模型评估指标我们之前对模型做评估时，通常采用的是准确率(accuracy)，它指的是分类器正确分类的样本数与总体样本数之间的比例。这个指标对大部分的分类情况是有效的，不过当分类结果严重不平衡的时候，准确率很难反应模型的好坏。举个例子，对于机场安检中恐怖分子的判断，就不能采用准确率对模型进行评估。我们知道恐怖分子的比例是极低的，因此当我们用准确率做判断时，如果准确率高达99.999%，就说明这个模型一定好么？其实正因为现实生活中恐怖分子的比例极低，就算我们不能识别出一个恐怖分子，也会得到非常高的准确率。因为准确率的评判标准是正确分类的样本个数与总样本数之间的比例。因此非恐怖分子的比例会很高，就算我们识别不出来恐怖分子，正确分类的个数占总样本的比例也会很高，也就是准确率高。实际上我们应该更关注恐怖分子的识别，这里先介绍下数据预测的四种情况：TP、FP、TN、FN。我们用第二个字母P 或 N 代表预测为正例还是负例，P 为正，N 为负。第一个字母 T 或 F代表的是预测结果是否正确，T 为正确，F 为错误。所以四种情况分别为：1.  TP：预测为正，判断正确；2.  FP：预测为正，判断错误；3.  TN：预测为负，判断正确；4.  FN：预测为负，判断错误。我们知道样本总数 =TP+FP+TN+FN，预测正确的样本数为 TP+TN，因此准确率Accuracy = (TP+TN)/(TP+TN+FN+FP)。实际上，对于分类不平衡的情况，有两个指标非常重要，它们分别是精确度和召回率。精确率 P = TP/(TP+FP)，对应上面恐怖分子这个例子，在所有判断为恐怖分子的人数中，真正是恐怖分子的比例。召回率 R = TP/(TP+FN)，也称为查全率。代表的是恐怖分子被正确识别出来的个数与恐怖分子总数的比例。为什么要统计召回率和精确率这两个指标呢？假设我们只统计召回率，当召回率等于100% 的时候，模型是否真的好呢？举个例子，假设我们把机场所有的人都认为是恐怖分子，恐怖分子都会被正确识别，这个数字与恐怖分子的总数比例等于100%，但是这个结果是没有意义的。如果我们认为机场里所有人都是恐怖分子的话，那么非恐怖分子（极高比例）都会认为是恐怖分子，误判率太高了，所以我们还需要统计精确率作为召回率的补充。实际上有一个指标综合了精确率和召回率，可以更好地评估模型的好坏。这个指标叫做F1，用公式表示为：![](Images/4994099f35c0303ef37be637ba925bbd.png){savepage-src="https://static001.geekbang.org/resource/image/b1/ce/b122244eae9a74eded619d14c0bc12ce.png"}\F1 作为精确率 P 和召回率 R 的调和平均，数值越大代表模型的结果越好。
## 对信用卡违约率进行分析我们来看一个信用卡欺诈分析的项目，这个数据集你可以从百度网盘（因为数据集大于100M，所以采用了网盘）中下载：> 链接： 提取码：58gp数据集包括了 2013 年 9 月份两天时间内的信用卡交易数据，284807笔交易中，一共有 492 笔是欺诈行为。输入数据一共包括了 28 个特征V1，V2，......V28 对应的取值，以及交易时间 Time 和交易金额Amount。为了保护数据隐私，我们不知道 V1 到 V28这些特征代表的具体含义，只知道这 28 个特征值是通过 PCA变换得到的结果。另外字段 Class 代表该笔交易的分类，Class=0为正常（非欺诈），Class=1 代表欺诈。我们的目标是针对这个数据集构建一个信用卡欺诈分析的分类器，采用的是逻辑回归。从数据中你能看到欺诈行为只占到了492/284807=0.172%，数据分类结果的分布是非常不平衡的，因此我们不能使用准确率评估模型的好坏，而是需要统计F1 值（综合精确率和召回率）。我们先梳理下整个项目的流程：![](Images/f57353fa3a065badaa31ae32e219ed0b.png){savepage-src="https://static001.geekbang.org/resource/image/92/a5/929c96584cbc25972f63ef39101c96a5.jpg"}1.  加载数据；2.  准备阶段：我们需要探索数据，用数据可视化的方式查看分类结果的情况，以及随着时间的变化，欺诈交易和正常交易的分布情况。上面已经提到过，V1-V28    的特征值都经过 PCA 的变换，但是其余的两个字段，Time 和 Amount    还需要进行规范化。Time    字段和交易本身是否为欺诈交易无关，因此我们不作为特征选择，只需要对    Amount 做数据规范化就行了。同时数据集没有专门的测试集，使用    train_test_split 对数据集进行划分；3.  分类阶段：我们需要创建逻辑回归分类器，然后传入训练集数据进行训练，并传入测试集预测结果，将预测结果与测试集的结果进行比对。这里的模型评估指标用到了精确率、召回率和    F1 值。同时我们将精确率 - 召回率进行了可视化呈现。基于上面的流程，具体代码如下：    
# -*- coding:utf-8 -*-
# 使用逻辑回归对信用卡欺诈进行分类import pandas as pdimport numpy as npimport seaborn as snsimport matplotlib.pyplot as pltimport itertoolsfrom sklearn.linear_model import LogisticRegressionfrom sklearn.model_selection import train_test_splitfrom sklearn.metrics import confusion_matrix, precision_recall_curvefrom sklearn.preprocessing import StandardScalerimport warningswarnings.filterwarnings('ignore') 
# 混淆矩阵可视化def plot_confusion_matrix(cm, classes, normalize = False, title = 'Confusion matrix"', cmap = plt.cm.Blues) :    plt.figure()    plt.imshow(cm, interpolation = 'nearest', cmap = cmap)    plt.title(title)    plt.colorbar()    tick_marks = np.arange(len(classes))    plt.xticks(tick_marks, classes, rotation = 0)    plt.yticks(tick_marks, classes)     thresh = cm.max() / 2.    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])) :        plt.text(j, i, cm[i, j],                 horizontalalignment = 'center',                 color = 'white' if cm[i, j] > thresh else 'black')     plt.tight_layout()    plt.ylabel('True label')    plt.xlabel('Predicted label')    plt.show() 
# 显示模型评估结果def show_metrics():    tp = cm[1,1]    fn = cm[1,0]    fp = cm[0,1]    tn = cm[0,0]    print('精确率: {:.3f}'.format(tp/(tp+fp)))    print('召回率: {:.3f}'.format(tp/(tp+fn)))    print('F1 值: {:.3f}'.format(2*(((tp/(tp+fp))*(tp/(tp+fn)))/((tp/(tp+fp))+(tp/(tp+fn))))))
# 绘制精确率 - 召回率曲线def plot_precision_recall():    plt.step(recall, precision, color = 'b', alpha = 0.2, where = 'post')    plt.fill_between(recall, precision, step ='post', alpha = 0.2, color = 'b')    plt.plot(recall, precision, linewidth=2)    plt.xlim([0.0,1])    plt.ylim([0.0,1.05])    plt.xlabel('召回率')    plt.ylabel('精确率')    plt.title('精确率 - 召回率 曲线')    plt.show(); 
# 数据加载data = pd.read_csv('./creditcard.csv')
# 数据探索print(data.describe())
# 设置 plt 正确显示中文plt.rcParams['font.sans-serif'] = ['SimHei']
# 绘制类别分布plt.figure()ax = sns.countplot(x = 'Class', data = data)plt.title('类别分布')plt.show()