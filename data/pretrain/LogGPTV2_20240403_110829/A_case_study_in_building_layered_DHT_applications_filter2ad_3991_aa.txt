title:A case study in building layered DHT applications
author:Yatin Chawathe and
Sriram Ramabhadran and
Sylvia Ratnasamy and
Anthony LaMarca and
Scott Shenker and
Joseph M. Hellerstein
A Case Study in Building Layered DHT Applications
Yatin Chawathey
PI:EMAIL
Anthony LaMarcay
PI:EMAIL
yIntel Research Seattle
Sriram Ramabhadran(cid:3)
PI:EMAIL
Scott Shenker(cid:7)
PI:EMAIL
(cid:3)UC San Diego
(cid:7)ICSI/UC Berkeley
Sylvia Ratnasamyz
PI:EMAIL
Joseph Hellersteinz
PI:EMAIL
zIntel Research Berkeley
ABSTRACT
Recent research has shown that one can use Distributed Hash
Tables (DHTs) to build scalable, robust and e(cid:14)cient applica-
tions. One question that is often left unanswered is that of
simplicity of implementation and deployment. In this paper,
we explore a case study of building an application for which
ease of deployment dominated the need for high performance.
The application we focus on is Place Lab, an end-user posi-
tioning system. We evaluate whether it is feasible to use
DHTs as an application-independent building block to imple-
ment a key component of Place Lab: its \mapping infrastruc-
ture." We present Pre(cid:12)x Hash Trees, a data structure used by
Place Lab for geographic range queries that is built entire on
top of a standard DHT. By strictly layering Place Lab’s data
structures on top of a generic DHT service, we were able to
decouple the deployment and management of Place Lab from
that of the underlying DHT. We identify the characteristics
of Place Lab that made it amenable for deploying in this lay-
ered manner, and comment on its e(cid:11)ect on performance.
Categories: C.2.4 Distributed Systems
General Terms: Design, Algorithms, Experimentation
Keywords: DHTs, Layering, Range queries
1.
INTRODUCTION
Distributed Internet-scale applications are typically de-
signed with scalability, availability, and robustness in mind.
An issue that is frequently overlooked is simplicity of imple-
mentation and deployment. Yet, in practice, this is often
an equally important and di(cid:14)cult challenge. This is par-
ticularly true of recent peer-to-peer systems that are highly
distributed in both location and administration.
This paper describes the design and evaluation of an appli-
cation in which concerns about ease of operation dominated
the need for high performance. The application, Place Lab,
is an end-user positioning service for location-enhanced ap-
plications [21]. Place Lab clients estimate their physical lo-
cation by listening for nearby radio beacons such as 802.11
access points and GSM cell towers in conjunction with a
database of known beacon locations. The beacon database
was initially designed as a centralized \mapping service."
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for pro(cid:2)t or commercial advantage and that copies
bear this notice and the full citation on the (cid:2)rst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speci(cid:2)c
permission and/or a fee.
SIGCOMM’05, August 22–26, 2005, Philadelphia, Pennsylvania, USA.
Copyright 2005 ACM 1›59593›009›4/05/0008 ...$5.00.
However, as the system gained popularity|since March 2004,
users have downloaded the Place Lab software from over 5600
unique locations|concerns of privacy and ownership of the
beacon database required transitioning to a decentralized ar-
chitecture composed of mapping servers distributed across
organizational domains.
What makes Place Lab’s mapping service an interesting
case study is that Place Lab’s operators, a small group of
ubiquitous computing researchers, wished to limit the imple-
mentation and deployment overhead involved with providing
a fully decentralized infrastructure. So we ask the question
whether it is possible to isolate the Place Lab developers
from the distributed application’s deployment, management
and robustness concerns.
A powerful design principle that is commonly used to sim-
plify the construction of complex systems is that of layering.
For example, the strict layering between IP and TCP allows
the network to handle the complex operations of packet de-
livery and the end-hosts deal with reliability and congestion
control. At a higher layer, Distributed Hash Tables (DHTs)
are often cited as playing a similar role in building decen-
tralized applications. Building an application on top of a
DHT frees designers from having to address issues of scala-
bility and robustness directly. Such an approach, if viable,
would greatly simplify the building of distributed applica-
tions. CFS [11], i3 [30] and PAST [12] are examples of appli-
cations that make straightforward use of a DHT for simple
rendezvous or storage and are easy to implement in a layered
fashion. On the other hand, systems such as Mercury [8] and
CoralCDN [14] have more sophisticated requirements, which
they achieve by altering the underlying DHT mechanisms.
Place Lab’s mapping service is closer to this second cate-
gory of applications in that it has more complex requirements
than simply storage and rendezvous. Its application inter-
face is based on geographic range queries, not exact-match
lookups. Place Lab clients download relevant segments of the
beacon database as needed. For example, when a user arrives
in a new city, her device will query the mapping service for
all beacon data within that region.
In spite of these requirements, if we could easily layer Place
Lab over an existing DHT, that would go a long way toward
simplifying implementation. However, this would not sim-
plify operation of the service; Place Lab’s operators would
still have to deploy and manage a full-(cid:13)edged DHT which is
arguably not an easy task. Hence, we decided to push the
notion of layering a step further and outsourced the oper-
ation of the DHT altogether to a third-party DHT service.
Building on top of a third-party DHT service restricts the in-
teraction between the application and the DHT to a narrow
and well-de(cid:12)ned API. It is precisely these con(cid:13)icting needs|
97building a complex data structure while having to live with
a narrow DHT interface|that we believe makes Place Lab a
good (admittedly harsh) stress test for the claim of DHTs as
a composable building block. This is an important question
because a lot of the value of DHTs will lie in the validation
of their (cid:13)exibility as a re-usable programming platform for
large-scale distributed applications.
In this paper, we describe the design and implementation
of Place Lab’s mapping service over the OpenDHT [2] ser-
vice. We use our experience to answer the following three
questions:
(cid:15) Is it feasible to use a simple DHT service as a building
block for a larger more complex application?
(cid:15) Can this application leverage the purported simplicity
and deployability advantages of DHTs?
(cid:15) What is the performance impact of using application-
independent DHTs for this application?
We recognize that a single case study is not su(cid:14)cient to
answer the more general question of just how broad a class
of applications can be supported on top of a strictly lay-
ered DHT. Rather, our results provide an initial insight into
the requirements that applications beyond simple rendezvous
and storage can impose on DHT infrastructures. Moreover
these requirements arise from a real application that is be-
ing actively used by members of the research community and
other early-adopters.
Our primary challenge was to address Place Lab’s need for
range-based queries without modifying the underlying DHT.
Our solution is called Pre(cid:12)x Hash Trees (PHTs), a distributed
trie-like data structure that can be built on top of a generic
DHT. A simple PHT can perform single-dimensional range
queries and an extension using linearization techniques [18]
allows us to perform multi-dimensional queries (and speci(cid:12)-
cally 2-D geographic range queries).
Our experience with building Place Lab has mixed results.
We found that the simple DHT interface goes a long ways
in supporting Place Lab’s non-traditional and varied use of
the DHT. Building Place Lab over a DHT was relatively easy
(2100 lines of glue code) and our system e(cid:11)ortlessly inherited
the scalability, robustness, and self-con(cid:12)guration properties
of the DHT. This would seem to validate our hope for a DHT-
based \narrow waist" for networked systems. However, the
simple DHT put/get/remove interface was not quite enough.
OpenDHT has no support for atomicity primitives, which
are crucial for correctness in the face of concurrent updates.
Yet, a simple atomicity primitive can be implemented as an
application-independent extension to the basic DHT API, so
it should be possible for a third-party DHT implementation
to support such primitives. Thus, we remain hopeful that
sophisticated applications can be layered on top of a DHT
service, but think that DHT services should slightly broaden
their interface.
In return for ease of implementation and deployment, we
sacri(cid:12)ced performance. With the OpenDHT implementa-
tion, a PHT query operation took a median of 2{4 seconds.
This is because layering entirely on top of a DHT service in-
herently implies that applications must perform a sequence of
get operations to implement higher level semantics with lim-
ited opportunity for optimization within the DHT. Whether
this loss of performance is a worthy tradeo(cid:11) for ease of de-
ployment is something that individual application developers
will have to assess.
The rest of the paper is organized as follows. We discuss
related work in Section 2. Section 3 describes Place Lab and
its requirements from the DHT framework, while Section 4
presents details on the Pre(cid:12)x Hash Tree data structure. In
Section 5 we discuss our experimental results, highlight the
lessons learned in Section 6 and (cid:12)nally conclude in Section 7.
2. RELATED WORK
There has been a variety of related work in DHT-based ap-
plications, in techniques for distributed range queries, and in
the use of trie-based schemes in networking. Place Lab is by
no means the (cid:12)rst application to be built on DHTs. But un-
like most existing applications, it uses DHTs not only for tra-
ditional key-based lookup, but also as a building block for im-
plementing a data structure with richer functionality (PHT)
while still retaining the simple application-independent API
of the DHT.
2.1 Other DHT-based Systems
An early and signi(cid:12)cant class of DHT-based applications
are storage and rendezvous systems, including PAST [12],
OceanStore [20], i3 [30]and those based on Chord’s DHASH
layer [31] (for example, CFS [11], Ivy [25] and UsenetDHT
[29]). Although these applications make straightforward use
of the DHT, their implementations are not always decompos-
able from their underlying DHT. Scribe [28] and SDIMS [34]
use the DHT topology to construct trees for multicast, any-
cast and aggregation. PIER [17] uses DHTs for relational
database and (cid:12)le-sharing queries, extending the DHT beyond
its basic put/get semantics to support query dissemination,
as well as join and aggregation operations. Lastly, systems
like CoralCDN [14] and POST [23] support large-scale appli-
cations by building custom DHTs underneath. What distin-
guishes Place Lab from all of these applications is its strict
use of a layered approach by building entirely on top of the
OpenDHT service.
2.2 Peer-to-Peer Range Queries
In recent years there has been a (cid:13)urry of work on provid-
ing peer-to-peer range query functionality. We believe that
the PHT scheme we describe here stands out because it is
built without modifying the internal routing or topology of
the DHT. This clean layering makes it easy to implement
over third-party DHT infrastructures, and allows DHTs to
support multiple functionalities, without being tuned specif-
ically for range search.
In comparison, the Mercury system [8], Sword [26], Karger
and Ruhl’s item balancing [19], and Ganesan et al’s online
balancing work [15] explicitly load-balance the distribution
of items by including speci(cid:12)c modi(cid:12)cations to the behavior
of the underlying DHT. Typically, with evolving applications
and data sets, this can induce churn in the DHT. PHTs on
the other hand are built entirely on top of an existing DHT
and rely on the spatial distribution of the data to achieve
load balancing.
Aspnes and Shah [4] have proposed skip graphs, a dis-
tributed data structure that implements range search. Awer-
buch and Scheideler [5] build skip graphs over a DHT by
using the DHT mechanism to implement pointers in the the
skiplist structure. However, maintaining load balance while
mapping items to peers in the network requires non-trivial
extensions to skip graphs [3]. In contrast, the PHT is based
on a trie data structure, whose simplicity allows for a simple
realization over a network of peers, as is demonstrated in this
paper. Other related work includes a DHT-based caching
scheme [16]; P-tree [10], a special-purpose P2P range-search
structure; and a technique speci(cid:12)cally for the CAN DHT
based on space-(cid:12)lling curves [32].
2.3 Trie-based peer-to-peer systems
Cone [7] is a DHT-inspired, trie-based distributed data
structure that is used to evaluate aggregation operators, such
as MIN, MAX and SUM, over keys in a DHT. Cone is similar
to PHTs in that it is based on a trie, but it is designed for
aggregation operations, not range queries.
In comparison,
the PHT can not only perform range queries, but is easily
capable of evaluating aggregation operators over elements
satisfying a range predicate.
P-Grid is a DHT-like peer-to-peer lookup system that uses
a trie-based approach at its core [1], along with a network of
randomized links. It is quite di(cid:11)erent in design spirit from
the PHT, which is a data structure layered on top of any
DHT.
Finally, in independent work, Yalagandula [33] has pro-
posed a trie-based scheme that is similar to our PHT pro-
posal.
In this paper, we have explored beyond the basic
concept of a PHT and built and deployed it for a real appli-
cation.
3. PLACE LAB
3.1 Overview
Place Lab [21] is a radio-beacon-based device position-
ing system that runs on commodity laptops, PDAs and cell
phones. Client devices listen for broadcasts of beacon mes-
sages from nearby 802.11 access points and GSM cell towers.
They estimate their own position by looking up these beacons
in a beacon database that maps beacon identi(cid:12)ers to their lo-
cation. Using locally cached segments of the database, clients
can position themselves with a median accuracy of 12{40 me-
ters depending on beacon density [21].
Input for the beacon database can come from organizations
that already know the locations of their 802.11 access points
or from war drivers who drive around a neighborhood with a
mobile computer equipped with a GPS device and an 802.11
card gathering traces of beacon availability. Many central-
ized beacon databases already exist (e.g., www.wigle.net).
However, as the Place Lab infrastructure grows and becomes
more popular, a central authority for the beacon database
will raise numerous concerns about privacy, ownership, and
access. Since the database is critical for clients to compute
their own location, centralizing it would in some ways be
analogous to using a single centralized DNS server for clients
to resolve DNS names.
Hence, the Place Lab researchers proposed a decentralized
architecture for Place Lab’s mapper service where any num-
ber of organizations, each with their own mapping servers,
can host a portion of the beacon database. Rather than di-
vide the database geographically (which raises concerns such
as \who is responsible for high-pro(cid:12)le areas like Manhat-
tan"), we chose to distribute the data \randomly" across
all servers by making each server responsible for a random
portion of the beacon identi(cid:12)er space. This method elimi-
nates the need to assign servers by geography and ensures
robustness by spreading data for a single region across mul-
tiple random servers. Such an organization is well-suited for
implementation on top of a DHT. Given Place Lab’s require-
ments of ease of deployment, we built the service on top of
OpenDHT [2], a third-party DHT service. OpenDHT pro-
vides a simple put/get/remove interface to its applications.
Applications put data into the DHT along with a time-to-
live; the DHT stores the data until the TTL expires.
War drivers use the DHT to route data to the mapping
servers. Mapping servers are responsible for aggregating in-
formation about individual radio beacons and generating a
single estimate of the beacon’s location.1 In addition, they
build and maintain a geographical index of all access points
to simplify retrieval. The DHT takes care of robustness and
availability of the data. The rest of this section details how
this separation of concerns between the DHT and mapping
servers is achieved.
3.2 Content-based Routing
The processing of war-driving records for a single radio
beacon is independent of those for other beacons. Accord-
ingly, we distribute the mapping data such that data for a
single beacon is always hosted by a deterministic mapping
server and all war-driving records for that beacon are for-
warded to that mapping server.
DHTs provide a natural mechanism for achieving this dis-
tribution. We map beacon identi(cid:12)ers to SHA1 [13] keys.
Each mapping server is responsible for a well-de(cid:12)ned por-
tion of the key space. To allow mapping servers to register
with the DHT and for clients to route war-driving records to
appropriate mapping servers, we use the OpenDHT ReDiR
mechanism [2]. ReDiR maintains a hierarchy of rendezvous
points that allows clients to look up the appropriate server(s)
for their records. It is implemented entirely by the mapping
servers and their clients using the simpler put/get interface
of the DHT.
A mapping server coalesces war-driving records for a sin-
gle radio beacon and computes running estimates for the
positions of all radio beacons that it manages. Periodically,
it stores these estimates in the DHT (keyed by the beacon
identi(cid:12)er) to ensure their availability. E(cid:11)ectively, the DHT
provides the routing primitives that clients use to locate map-
ping servers and stores estimates of beacons’ locations as
generated by the mapping servers.
3.3 Indexing for Retrieval
When a Place Lab client enters a new area, she must
(cid:12)rst download the beacon data for the new region. This in-
volves performing a geographical range query over the data.
Rather than allow arbitrarily complex query regions, we re-
strict queries to rectangular bounding boxes.
The underlying DHT’s routing algorithm spreads beacon
data uniformly across mapping servers with no semblance
of spatial locality; yet, such locality is important to perform
the above query e(cid:14)ciently. Pre(cid:12)x Hash Trees (PHTs) are our
solution to e(cid:14)ciently coalesce estimated positions of nearby
radio beacons. When a mapping server updates its estimate
of a beacon’s location based on new war driving readings,
it also updates the PHT. For e(cid:14)ciency, these updates can
be batched and performed lazily. We will discuss this data