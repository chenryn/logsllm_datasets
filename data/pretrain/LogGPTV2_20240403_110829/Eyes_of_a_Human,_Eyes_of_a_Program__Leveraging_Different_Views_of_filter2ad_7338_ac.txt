general fraud schemes (such as fake pharmacies or fake antiviruses), whereas
benign usages are much more likely to appear as outliers.
To this end, we leveraged obfuscated words as features for each page. Several
methods exist to eliminate outliers: we opted for density-based clustering (DB-
SCAN), as it performs well and can be fully automated for this purpose as long
as known-benign obfuscated samples are available.2
This step is not strictly necessary, as far as ﬁnding interesting and suspicious
pages: Without further reﬁnement, the heuristic already pointed to 199 truly
malicious pages (and 56 benign ones), many of which were not originally found by
2 Speciﬁcally, we rely on the presence of a few samples originated from the Alexa
set for our purposes: Intuitively we want the clustering to consider them as “noise,”
so (for the purpose of this step) we classify them as “benign” and everything else
as “malicious”. With this assignment, we have a rough estimate of how good each
possible clustering is (using, for instance, the F1 score) at discriminating between
benign and malicious samples. At this point, a simple grid search can ﬁnd the values
for the two DBSCAN parameters (the point neighborhood size ε and the minimum
cluster size) that maximize this estimated score. On Table 2’s data, 0.82 and 3 were
found by the grid search; the corresponding clustering is shown in Table 3.
140
J. Corbetta et al.
Table 3. Samples found by the content obfuscation heuristic, automatically grouped
by cluster and de-noised leveraging the obfuscated words that were detected
Page type
Samples
“Blackhole” exploit kit
First fake-AV campaign
“Blackhole” exploit kit
First fake-AV campaign (minor variation)
Second fake-AV campaign
Third fake-AV campaign
Updated version of the “Blackhole” exploit kit
False positives
Fake ﬂash player campaign
“Blackhole” exploit kit
False positives
Cluster 1
Cluster 2
Cluster 3
Cluster 4
Cluster 5
Cluster 6
Cluster 7
Cluster 8
Cluster 9
Cluster 10
Cluster 11
Cluster 12 Third fake-AV campaign (minor variation)
Cluster 13 Third fake-AV campaign (minor variation)
Cluster 14 Third fake-AV campaign (minor variation)
Cluster 15 Updated version of the “Blackhole” exploit kit
Cluster 16
Cluster 17
False positives
False positives
Samples
discarded
as noise
7 questionable, 3 fake-AV campaigns (all minor variations of
the campaigns above), 3 pharmacy scams, 1 “Blackhole” ex-
ploit kit (bugged sample), 3 “get rich quick” scams, and 43
benign
41
23
20
16
5
9
12
4
4
12
3
15
20
4
8
3
3
60
Wepawet’s analysis, especially among the scam campaigns that did not leverage
any browser vulnerability.3
However, we found this step very useful both for our manual analysis and for
a more punctual malicious content detection. Its results are presented in Table 3,
which also serves as a recap of the nature of the pages found by the heuristic
of this section. Conﬁrming the validity of our intuition that most benign pages
would appear as outliers, this clustering step was able to achieve a precision of
93.56% and a recall 94.97% in ﬁnding malicious pages among the samples that
presented obfuscation.
The false positives are multiple benign sites that were obfuscating a few sim-
ilar words, usually for search engine optimization purposes. All fake antivirus
campaigns present in the dataset were identiﬁed correctly. As mentioned, pages
from two well-known exploit kits were also identiﬁed.
3 Interestingly, while reviewing the pages that were found, we even encountered several
that appeared to be generated by an exploit kit, although Wepawet had not detected
them as such. Further review revealed that these pages, generated by the “Blackhole”
exploit kit, were ﬁngerprinting Wepawet’s JavaScript engine and disabling their ma-
licious payload to escape detection.
Eyes of a Human, Eyes of a Program
141
As expected, campaigns tend to emerge as distinct clusters. Incidentally, we
have observed a certain number of minor variations, updates, or bugs within the
same campaign or usage of exploit kits: this tends to surface as a splitting of a
campaign in a few distinct clusters.
5 Counterfeit Certiﬁcation Seals
Our second heuristic explores an attempt to confuse human consumers without
attempting to deceive automated analyzers.
In particular, we observed that in many cases scammers try to make their
pages appear more legitimate by including certiﬁcation seals: small images meant
to convey that the site has passed a review by a trusted third party. These seals
are also often displayed by legitimate online sellers to reassure users about the
safety of their data. Reputable companies releasing these certiﬁcations include
Symantec, GeoTrust, McAfee and other well-known certiﬁcation authorities and
vendors of security software.
No standard mandates the exact meaning of the certiﬁcation. Some issuers
just claim to periodically check the website for malware, others are meant to fully
verify that the site is owned by a reputable business entity. In all cases, seals
are included to make visitors more comfortable (and presumably more likely to
spend time or money on the site). As such, their counterfeiting is attractive for
fraudsters, even if no computer program would “understand” them or consider
them in any way.
5.1 Use by Fraudsters
Unfortunately, there are also no standards on how certiﬁcation seals should be
included in a page and how an end user can verify their legitimacy. Unlike
HTTPS certiﬁcates, browsers cannot check them on the user’s behalf, as the
seal is usually just another image on the page.
Issuers can mandate certain technical measures in their usage policies, such
as the requirement to include a script served from an authority’s server [41].
Typically, correctly included seals should react to clicks by opening a veriﬁcation
page hosted by the issuer.
Nothing, however, prevents a malicious seller from simply copying the seal
image from a legitimate site and displaying it on a fraudulent page. Should
someone click on the seal to verify it, the scammer can simply present a locally-
hosted fake certiﬁcation. Unless the end user speciﬁcally checks the certiﬁcation
page origin (and knows the correct domain name of the authority that issues the
seal in question), the page will look legitimate.
Given the ease of including a copied image and the low risk of detection by
untrained users, fraud perpetrators often display copious amounts of certiﬁcation
seals on their pages, especially on online shops such as rogue pharmacies. Figure 1
shows a few examples.
142
J. Corbetta et al.
Fig. 1. Examples of counterfeit certiﬁcation seals found on rogue pharmacy sites
Seal images can be completely made-up and refer to no established third-party,
present alterations of logos of real certiﬁcation authorities [3] or, as we most com-
monly observed, present copies of actual logos and faked certiﬁcation pages.
5.2 Heuristic
For our study, we augmented the system described in Section 4.2 with a com-
ponent that calculates a perceptual hash [49] (for resilience against small al-
terations) of all images with a size comparable to the ones typically used for
certiﬁcation seals, compares them with the known ones, and checks if they are
legitimate or not.
There are few legitimate seal providers: a manual review of their terms of
services and inclusion practices would allow constructing a fully reliable detector,
if desired. As expected for a deception technique exclusively directed toward
humans, we did not observe any attempt to hide its use from even a simple
analyzer. Therefore, we opted again for a fully-automated approach in our survey:
we performed optical character recognition on the 100 most common images
(as aggregated by the perceptual hashing function) and looked for keywords
expressing trust and protection such as “secured,” “approved,” “trust,” and
“license” to ﬁnd seals, and check legitimacy simply by verifying if they link oﬀ-
site or not: an imperfect approach that however highlights how easy it can be
for a program to detect purely human-directed deception attempts.
While not uncovering all frauds in our dataset (not all of them use these
fake seals, nor does our heuristic cover all of these images), this simple heuristic
correctly ﬂagged about 400 samples, with no false positives. All these samples
originated from rogue pharmacy campaigns and, as we will show in the next sec-
tion, proved to be a valuable starting point for a detector of this entire category
of scams.
6 Proof-of-concept General Detector
As we have seen, the diﬀerence between a human view and an algorithmic view
can indeed be useful in pointing out malicious pages, even with two simple
heuristics such as ours. Of particular note is its tendency to ﬁnd “pure” scam
campaigns that do not involve software exploits, yet succeed due to deception.
Eyes of a Human, Eyes of a Program
143
In this section we will show if these heuristics could be useful to a complete
maliciousness detection suite, in particular by seeing if the pages they uncover
could enable ﬁnding more. To this end, we implemented a proof-of-concept de-
tector that uses them as its only starting point, and we will show how it can
already reach signiﬁcant detection rates. It is fairly standard in its construc-
tion (signature generation and matching), but we will also use it to exemplify
a similarity measure that gives a diﬀerent “weight” to certain words (the ones
that were obfuscated, in our case) and is resilient to the inclusion of extraneous
text, as we have observed this happens with a certain frequency in scam pages
when they are part of a larger page (posts in hijacked forums are an example).
Incidentally, this approach would also defend against fraudsters including large
amounts of irrelevant text speciﬁcally to thwart automated analysis, even if it
was presented in such a way that humans would not pay attention to it (i.e., in
a semi-invisible color, at the end of a long page, out of view, . . . ).
6.1 Signature Generation
The clusters in Table 3, with the addition of the pages detected due to seal
counterfeiting, serve as the basis to generate signatures. In particular, our sys-
tem tries to identify contiguous regions of text that are “typical” of a cluster,
to maximize the impact of common textual elements (presumably core to the
nature of those pages), while de-emphasizing regions that are variable among the
diﬀerent samples: A score is assigned to each word present in pages belonging
to the cluster. The score is initially the number of occurrences of the word in
the samples, doubled if the word was obfuscated; scores are then normalized to
have zero-average (to further reduce noise, we also exclude the 100 most com-
mon English words). All the maximal-scoring contiguous regions of text are then
found (this operation has linear-time complexity [34]) and identical regions are
aggregated to form the “signature” regions for that cluster.
As an example, for the cluster of a simple fake-AV campaign that included
a few variations, the following regions were chosen: center initializing virus
protection system, initializing virus protection system, initializing treat
protection system., whereas for a pharmacy scam regions included both the
entire common content of the typical sales page, and smaller text snippets that
were present in many, but not all pages (mainly, the type of drugs sold in speciﬁc
subpages).
6.2 Signature Matching
When presented with a sample, our proof-of-concept detector will perform a
fuzzy matching with the signature regions, to ﬁnd other similar but unknown
campaigns.
Simple textual similarity measures (i.e., the Jaccard coeﬃcient) weight the
amount of common elements versus the amount of uncommon ones. As men-
tioned, we will propose here a slightly diﬀerent approach that is more resilient
to the inclusion of unrelated random words in the page, as we consider this a
144
J. Corbetta et al.
good property when faced with content that exclusively tries to deceive humans:
in those cases, a small amount of information could very well be suﬃcient.
In particular, when evaluating a page:
1. A candidate match mi is found for each of the n signature regions si (longest
matching subsequence in the page text).4
2. The Jaccard distance di is computed for each (mi, si) pair.
3. The distance of the page to the clusters is computed: d = min{d1 . . . dn}.
Notice that with this method only one zone of the page inﬂuences the ﬁnal
result: the one that is most similar to one of the clusters. Therefore, as opposed
to inserting disturbances anywhere, an author that wished to avoid detection
would have to modify several words right in the middle of their most relevant
content, likely changing the message perceived by a potential victim.
At this point we can mark a page as benign or malicious based, using a
threshold on d. To make sure the threshold is neither too low nor too high, we
used a separate training phase to select a good value.5
To exemplify extra robustness precautions that would be included in a com-
plete detector, we added two image-based matching systems based on a page
screenshot. One recovered text through Optical Character Recognition (which
can then be used as normal HTML text), the other directly compared the page
screenshot with those of the pages found by the two heuristics.
6.3 Evaluation
We evaluate the overall performance of our proof-of-concept system on the (oth-
erwise unlabeled) 50,000 samples obtained from real-time submissions. As men-
tioned in Section3, this set includes a variety of scam sites, traditional drive-by
download exploit pages, and benign pages.
Table 4 provides a numerical overview of its performance. Overall, the system