title:Improving Reliability with Dynamic Syndrome Allocation in Intelligent
Software Defined Data Centers
author:Ulya Bayram and
Dwight Divine and
Pin Zhou and
Eric William Davis Rozier
2015 45th Annual IEEE/IFIP International Conference on Dependable Systems and Networks
2015 45th Annual IEEE/IFIP International Conference on Dependable Systems and Networks
Improving Reliability with Dynamic Syndrome
Allocation in Intelligent Software Deﬁned Data
Centers
Ulya Bayram and Eric W.D. Rozier
Department of EECS
University of Cincinnati
PI:EMAIL, PI:EMAIL
Dwight Divine
Illinois Natural History Survey
University of Illinois
PI:EMAIL
Pin Zhou
Datos IO, Inc.
San Jose, CA, USA
PI:EMAIL
Abstract—We propose new algorithms for implementing a
software-deﬁned data center (SDDC) to improve the dependabil-
ity of storage systems without the addition of new hardware.
We deﬁne the construction of a system that can predict its
future resource requirements and act on these predictions to
allocate overprovisioned resources to improve reliability. We
introduce algorithms for implementing a smart SDDC (S2DDC)
that characterizes user I/O transactions (writes and deletes), and
use these models to predict the level of overprovisioning within a
system, overbooking excess resources to improve reliability, while
mitigating the impact on quality of service. We compare several
implementations of our methods experimentally, and discuss
methods for improving the fault-tolerance of our S2DDC, present
experimental results showcasing our ability to improve system
reliability showing the decrease in expected annual block loss due
to disk failures and latent sector errors, and highlight the beneﬁt
of dependence based usage models in estimating overprovisioning.
I.
INTRODUCTION
Many industry leaders, such as NASA Goddard, Yahoo,
and NOAA have cited the growth of Big Data as a primary
challenge for the storage industry, with growth rates exceeding
the ability of designers and researchers to build appropriate
platforms [1], [2]. The NASA Center for Climate Simulation
revealed that while their computing needs had increased 300
fold in the last ten years, storage had increased 2,000 fold,
and called storage infrastructure one of the largest challenges
facing climate scientists [3]. In addition to the increase in
data production, the requirements for long term and reliable
storage of data have also been increasing, due to new laws
such as Sarbanes-Oxley [4], HIPAA [5], requirements from
NIH and NSF, regulations from U.K. Joint Information Sys-
tems Committee, policies by the British Library, and new
organizations such as Digital Preservation Europe [6]. The
ancillary costs, such as power, curation, and salaries of data
science professionals, have also been rapidly increasing as well
[7], [6]. These factors are all continuing to drive reliance on
Commercial Off the Shelf (COTS) solutions to drive down the
cost of data ownership. While important, the goal of afford-
ability is typically at odds with the goal of reliability, creating
system design constraints that are difﬁcult to reconcile. To
meet
the idea of Software Deﬁned Data
Centers (SDDCs) [8], [9] has been proposed as a means of
adding support for virtualization concepts such as abstraction,
these challenges,
automation, and pooling that are already being deployed in
Software Deﬁned Networks (SDNs) [10], [11] to extend the
capabilities of data centers.
In this paper, we build upon the idea of intelligent, user-
aware SDDCs ﬁrst proposed in [9]. We propose the use of
smart SDDCs (S2DDCs) that dynamically improve the relia-
bility of existing systems, without any additional hardware.
We focus on this goal due to the traditionally under-served
area of domains which are cost-constrained, such as primary
scientiﬁc institutions, and state or federally sponsored research
facilities. Despite the growing data needs of these groups,
the current funding climate means they are trying to do
more, with less, making an inexpensive solution which does
not require specialized hardware, and preferably works with
existing hardware very important. We present a novel system
framework which monitors both the system resources and the
I/O patterns in the write/delete space of users to help identify
patterns and exploit the fact that storage systems are often
overprovisioned. We propose the utilization of this information
to allocate overprovisioned space to improve reliability using
a novel middle-ware layer, while still maintaining quality of
service by extending previous work proposed in [9].
The primary contributions of our paper are as follows:
• We expand upon the prediction algorithm ﬁrst outlined
in [9], analyzing the effect of the number of clusters
used to represent user behaviors in terms of quality of
service and reliability, and demonstrate our algorithm
by performing simulated run-time-prediction of usage
patterns, identifying overprovisioned resources using
real data, and monitoring the under-prediction rate and
the additional space available for syndrome allocation.
• We experimentally study the overprovisioning patterns
in real data, and simulate our algorithm under levels of
increasingly risk averse parameterizations to demon-
strate our ability to improve reliability while main-
taining Quality of Service (QoS) with respect to the
availability of space for large writes without delay due
to destaging our allocated syndromes. We demonstrate
the tunability of our method, using different levels of
risk aversion as a tunable parameter, and show how
this can be used effectively in an S2DDC.
• We introduce novel algorithms for utilizing over-
978-1-4799-8629-3/15 $31.00 © 2015 IEEE
978-1-4799-8629-3/15 $31.00 © 2015 IEEE
DOI 10.1109/DSN.2015.46
DOI 10.1109/DSN.2015.46
219
219
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 08:49:20 UTC from IEEE Xplore.  Restrictions apply. 
provisioned space to allocate dynamic independent
syndromes to improve the reliability of the underlying
system, and analyze the efﬁcacy of these methods by
modeling failures in our system, showing the success
of our S2DDC algorithm in terms of a reduction of the
expected annual block loss in a one petabyte storage
system.
The remainder of this paper is organized as follows.
In Section II we discuss previous work relating to storage
modeling, clustering, and improving reliability in a dynamic
fashion. In Section III we discuss our on-line prediction
technique, highlighting our extensions to the methods detailed
in the literature in [9]. Section III-E details our novel dy-
namic reliability mechanisms and discusses their impact on
the normal operation of the underlying ﬁle systems, along with
QoS concerns. We present an experimental evaluation of our
proposed framework in Section IV, showing results using real
system data and discuss the consequences of these results in
Section V. Finally in Section VI we outline our plan for future
work, and highlight ways in which our framework could be
extended and generalized.
II. RELATED WORK
While many studies of system modeling exist which fo-
cus on understanding the reliability of storage systems [12],
[13], [14], system workloads [15], [16], [17], application I/O
patterns [18], and performance modeling [19], the literature
is scarce when it comes to modeling usage patterns within a
system [9]. Previous work in the literature on usage modeling
is primarily limited to a study of the statistics of a large set
of production backup systems [15] and generalized workload
patterns studied in [16], which discusses statistical properties,
such as I/O size, inter-arrival time, seek distance, read-write
ratio, etc. The authors of [18] present a formal speciﬁcation
for use in characterizing applications, workloads and hardware,
and propose a storage conﬁguration compiler to automate the
exploration of the large storage conﬁguration space based on
the input speciﬁcations.
A large deﬁciency in the existing literature is the lack of
studies on usage patterns of individual users, and methods
to characterize those users to capture complex interdependent
behavior. Most studies focus on characterizing whole system
and application workloads, missing the most basic block of
workloads on a data center, the users, making it hard to
generalize user patterns, and to extract and build new synthetic
workloads. The only study that considers the user-level system
workloads [9] gives the literature an idea on the importance
of user-level modeling. It gives a ﬁner grained ability to
analyze the impact of various users of the system, classify
those users, and build realistic behaviors into our workload
models based on the correlation of I/O patterns from a single
source. In this paper, we adopt the SDDC model of [9] that is
capable of capturing the user behaviors and predict the future
resource needs, and propose our novel S2DDC system that
utilizes extra resources by automated syndrome allocation, and
includes failure modeling that proves the importance of our
user-level usage pattern modeling on improving the system
reliability. Our study ﬁlls the need for an applicable, complete,
trustworthy method in the literature to create reliable smart
systems.
III. METHODS
As the lack of user-level system resourse usage behavior
modeling in the literature leads to inefﬁciently used resources
by over-assigning them to users, here we focus on building
a system that is capable of assigning enough resources to
users without affecting the QoS, and efﬁciently utilizing the
remaining resources to improve the reliabillity of the system.
The S2DDC system we propose is easily applicable on all
existing storage systems.
In order to build models of system resource needs, we ﬁrst
construct models which capture the system dynamics relating
to these resource needs, namely the patterns of writes and
deletes characterizing the I/O transaction patterns of users of
the system. Based on the work provided in [9], we adopt the
hypothesis that the future behaviors of users can be reasonably
and accurately predicted based on the observations of the
past behaviors, and that
these behaviors feature important
dependent relationships based on the past actions. As in [9]
we construct these models by observing the behaviors in a
system for some length of time, and by using that data, we
build a model capable of predicting the future behavior with
the following steps:
1)
2)
3)
4)
Scale the data for ease of processing.
Divide the dataset into two halves, take the ﬁrst part
as training set, and treat the second part as the test
data that is given to the system as the real-time input
of our S2DDC system.
Cluster the training data using k-means as in [9], and
mean-shift, evaluate and compare the performances
and show the importance of choosing the correct
clustering method and appropriate parameters.
Build Markov models for each user as in [9] using the
training data to obtain the transitions between states
which correspond to the identiﬁed clusters.
Following the construction of predictive models that cap-
ture the future behavior similar to [9], we utilize the predictions
to build our S2DDC by including the automated syndrome
allocation methods to the system. Then we model the complete
S2DDC system by introducing certain system failure types and
their occurrence rates observed in real systems into this system
to be able to simulate and obtain the measurable reliability of
our proposed system.
A. Data Normalization
In systems where the system admin can only trace the
user level operations, the feature space is one dimensional,
characterized by write or delete operations in units of bytes. We
pre-process the data by transforming it according to a pseudo-
log2 scale [9] before applying any kind of further processing.
⎧⎨
⎩
f (o) =
log2(o)
log2(o) · −1
0
if o is a write operation
if o is a delete operation
if o is a nop operation
This normalization step is important as it makes writes
and deletes comparable, merges them into a single space, and
scales the space by a log factor, ensuring write operations on
220220
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 08:49:20 UTC from IEEE Xplore.  Restrictions apply. 
the same order (GB, MB, etc) are closer than those of a smaller
order.
B. Behavior Characterization
Studying various clustering techniques, we found that
choosing the right clustering algorithm has an impact on the
performance when attempting to characterize user behavior
patterns. We compare two popular algorithms from the liter-
ature: k-means and mean-shift. We select k-means due to its
use in the literature [9], and its popularity in classiﬁcation
problems. We select mean-shift due to its popularity and
success in the ﬁeld of computer vision research for tasks
such as image segmentation, blob tracking, and other similar
applications [20].
1) K-Means: K-means is a well-studied and popular
method in the literature for the problem of clustering various
kinds of data, and is therefore implemented in a variety of
application speciﬁc ways [21], [22], [23]. Despite this diversity
in implementation, the core algorithm remains the same. K-
means is a parametric method with three primary parameters
[23]:
•
•
•
The number of clusters, k.
A choice of initial centroids for these clusters.
A distance metric used to assign each data point to
the cluster with the closest centroid.
The selection of these parameters has a large impact on
the performance of the k-means algorithm, and the goodness-
of-ﬁt of the ﬁnal clusters. This is the main problem faced
when implementing the k-means algorithm in practice; the user
may choose sub-optimal values for k and obtain too many
or too few clusters. Another disadvantage of k-means is the
random selection of initial centroids, which might cause the
algorithm to become stuck in a local optimum. An improper
distance metric can likewise result in a poor ﬁt in the ﬁnal
proposed clustering, as selection of a good distance metric
is highly correlated with the data type, and distribution. The
literature offers some guidance for more intelligent selection of
these parameters, such as the X-means method [23] that uses
ideas such as Bayesian information criterion. Such automatic
selection of k has the potential to result in a more optimal
clustering, but increases the computational complexity of the
method, without any guarantees of optimality. While the study
in [9] acknowledges these problems, it does not present a
deﬁnitive answer, we study these questions in Section IV and
examine the effects on QoS and reliability. We attempt to
experiment k-means clustering in a way to account for all
stated potential problems. For this reason, we select and tune
the parameter k, which represents the number of clusters based
on experimental results, choose the initial cluster centroids
randomly for writes, and deletes uniformly and with one
cluster allocated for the no operation case.
2) Mean-Shift: The mean-shift algorithm is a mode-
seeking, deterministic clustering algorithm, ﬁrst proposed by
[24] and generalized by [25]. In the algorithm, a user-selected
kernel function (Gaussian, Epanechnikov, Uniform, etc.) is
applied over the feature set
in order to associate weights
to nearby points, allowing the user to obtain a probability
density function (pdf). Dense regions in this pdf correspond
to the local maximas (modes), and thus potential cluster
centroids. In order to determine the clusters, an estimation of
the gradient density is obtained by taking the derivative of the
pdf [20]. In this estimation of gradient density, a part of the
formulation corresponds to the mean-shift gradient estimation
where m(x) represents the mean-shift gradient function. A
window with bandwidth parameter h is deﬁned and centered
at each data point, with the result of m(x) obtained over the
window. As the window gets closer to the local maxima, the
result of m(x) tends to decrease, and when it is stable the
cluster centroid is reached. This mean-shift clustering process
therefore corresponds to a determination of cluster centroids,
and a unique assignment of each data point to the closest
cluster.
Though the gradient density estimation steps make mean-
shift robust to noise and outliers, it is disadvantageous to
apply these steps over one dimensional user writes/deletes
data, it increases the computational complexity and results in
a loss of resolution in the raw data. Usage data is the only
attribute and cannot be assumed to contain noise since it rep-
resents empirical observations of write and delete operations
performed by real users. We thus omit the kernel function
and gradient density estimation steps of mean-shift algorithm,
allowing our clustering method to converge into a type of
sequential clustering.
In our simpliﬁed version of the mean-shift algorithm, we
perform clustering by centering a window with pseudo-log-
scale radius of h at each data point, and check for data within
the window range of [2x−h, 2x+h] bytes. When we encounter
data within the window, we cluster them and take their average
as the new centroid, and repeat the procedure. We also apply
pruning by merging nearby clusters whose new bounds are
2x−h or 2x+h.
C. Predicting Future Behaviors
Once the cluster centers have been identiﬁed over the
training set, we create and train our Markov models as in [9],
based on the dependent pattern of behaviors, allocating a state
for each centroid utilized in the clustering step. We estimate
the transitions in the model by noting temporal locality of
user behaviors. Given a user j who is witnessed making an
I/O transaction which belongs to the cluster corresponding
to state si, if the next I/O transaction belongs to a cluster
corresponding to some state sh, we train the transition from
si → sh in the transition matrix Pj corresponding to that user.
Once all training is completed, the result is a Markov model
such as the example in Figure 1.
As the models for all users in a system are trained, we
move forward on modeling the algorithm that performs with
real-time predictions. We predict the behavior of the system
during the next observation period on a per user basis using the
trained Markov models. Given the new observation of a user
in terms of a scaled write or delete operation, we determine
its state by assigning it to the closest cluster center. Then we
generate a state occupancy probability vector for user j at
the current time, t, (cid:2)πt,j such that the state corresponding to
the cluster containing the last observed read or write executed
by user j has probability 1.0, and the rest probability 0.0.
221221
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 08:49:20 UTC from IEEE Xplore.  Restrictions apply. 
(cid:10)
(cid:11)
(cid:12)
(cid:13)
(cid:2)(cid:4)
(cid:1)(cid:2)
(cid:1)(cid:2)(cid:2)(cid:4)
(cid:1)(cid:2)(cid:2)(cid:4)
(cid:1)(cid:2)(cid:2)(cid:4)
(cid:5)(cid:2)