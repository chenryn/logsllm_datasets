focus only on a single program or a few programs developed
by their company and change focus less frequently.
In addition to their full-time jobs, we found that many of
our hackers and some testers performed vulnerability discovery
on real-world programs as a hobby (T=3, H=11). These
participants explained that they searched for vulnerabilities,
though there was no expected economic beneﬁt, for the purpose
of hands-on learning and personal enjoyment.
Gained through hacking exercises. Many of our hackers
and some of our testers participate in hacking exercises like
capture-the-ﬂag competitions or online war games [101], [102]
(T=4, H=13). These exercises expose players to a variety of
vulnerabilities in a controlled, security-speciﬁc setting with
little program functionality aside from vulnerable components.
H3G explained that hacking exercises help players focus
on important details without becoming “overloaded"; these
exercises also offer a “way of measuring the progress of your
skills." Notably, the four testers had participated in only a few
narrowly-focused workplace competitions, while our hackers
mentioned many broad-ranging exercises.
Learned from their community. Both hackers and testers
reported similar experiences learning through colleagues, both
within and external to their workplace. Participants mention
learning from co-workers (T=7, H=7); from hobbyist (T=7,
H=10) and professional (T=2, H=0) organizations in which
they are a member; and from informal personal contacts (T=6,
H=12). Within these communities, practitioners are taught by
those with more experience (T=10, H=13) and learn by working
through and discussing difﬁcult problems with their peers (T=6,
H=9). For example, T5W described “Just watching other people
test, grabbing what one person uses and then another and
adding it to your own handbook.” H2H explained that starting
his career at a security company with “a lot of institutional
knowledge” was critical to his development because he had
“a lot of folks that I was able to pick their brain.” Whenever
personal contacts are not sufﬁcient, practitioners also seek out
information published online, typically in the form of expert
blog articles and web forum posts (T=6, H=10).
Learned from prior vulnerability reports. Additionally,
many participants—but particularly hackers—regularly read
other individuals’ vulnerability reports or discussed vulnera-
bilities found by colleagues to learn about new vulnerability
types and discovery techniques, essentially gaining practical
experience vicariously (T=6, H=15). H1H described using bug
reports to test his vulnerability ﬁnding skills. Before reading a
report, he asks himself, “Can I see the bug?” in the vulnerable
version of the program. If the answer is no, he looks at the
report to see “what the issue was and what the ﬁx was and then
where in the source the bug was.” However, testers commonly
only look at internal reports (T=5, H=0), whereas hackers view
reports from a variety of programs (T=1, H=15), exposing
them to a wider range of experiences.
Rarely learned through formal education. Finally, some
participants mentioned more formal training such as books
(T=1, H=7), academic courses (T=2, H=6), and certiﬁcations
(T=0, H=1). In all cases, however,
these methods were
perceived to only support attaining the skills to participate
in hands-on methods, not to be sufﬁcient on their own.
381
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:29:31 UTC from IEEE Xplore.  Restrictions apply. 
Fig. 3: Underlying System Knowledge Category Graph.
B. Underlying system knowledge
Almost all participants in both populations (T=8, H=15) em-
phasized the importance of underlying system knowledge (e.g.,
operating systems, programming languages, network protocols,
and software libraries) for successful vulnerability discovery.
Unlike with vulnerability discovery experience, our hackers and
testers expressed similar levels of system knowledge. Instead,
the biggest variation is in which underlying systems participants
understand, primarily due to software specialization. Many
participants reported focusing on a particular type of software
(e.g., web, mobile, host) out of necessity, such as limited time
to maintain proﬁciency in all software types (T=5, H=11).
We found that practitioners in both populations limit their
vulnerability searches based on their specialty (e.g., mobile
specialists only consider a mobile app and not its associated
web server).
Both populations indicated that system knowledge plays a
role in the Attack Surface phase; hackers were more likely to
report that it also plays a role in the Vulnerability Recognition
phase (See Figure 3.)
1) How does system knowledge affect the process? Under-
standing the underlying system components allows practitioners
to recognize vulnerabilities caused by discrepancies between
the developer’s assumptions about how the system behaves and
what actually occurs (T=2, H=6). H14W described how his
understanding of Mozilla web add-ons helps him recognize
vulnerabilities in other developers’ code, saying that add-on
developers “have no idea what they are doing there, and I see
they do horrible stuff.”
Strong system knowledge helps practitioners identify more
input vectors into a program, as well as the full range of
potential inputs (T=5, H=12). H1H gave an example of better
system understanding improving his view of the attack surface:
“I took [Operating Systems] where I was writing a kernel,
and that was incredibly important. It wasn’t until I took
this that I really understood what the attack surfaces really
were. . . The idea of being the [Virtual Machine] host where
you’re communicating with the GPU via some channel, I
wouldn’t have thought about that layer if I hadn’t written
a kernel.”
Fig. 4: Access to development process category graph.
2) How is system knowledge developed? The development
of system knowledge closely parallels the development of
vulnerability discovery experience, with participants relying on
hands-on experience and the community. Participants indicated
learning through a mixture of on-the-job learning as a tester
or hacker (T=10, H=13) and experience as a developer (T=6,
H=11) or systems administrator (T=0, H=3). H5M discussed
the impact of his prior employment; “I worked at an antivirus
company and you had to look at a lot of samples really
quick. . . and [now] it’s easy to say ‘Ok, here’s where they’re
doing this’. . . and just quickly looking at it.”
Participants also mentioned using community (T=7, H=7)
and online resources (i.e., expert blogs and web forums) (T=7,
H=8) to supplement their experiential learning. Participants
also learn from standards documents such as network protocol
RFCs and assembly language instruction set documentation
(T=2, H=4). Again, very few mentioned formal education (T=2,
H=2), and of those who did, none considered it necessary. H6G
explained that he has read some good books and has a computer
science degree, but ﬁnds hands-on learning the best because
“For me I need ten hours reading a book. It’s the same as 2
[or] 3 hours trying to solve a challenge.”
C. Access to development process
Another factor that inﬂuences the vulnerability discovery
process is whether a practitioner has access to the development
process. Figure 4 shows the effect of this access on the
phases of vulnerability discovery. Clearly, because testers serve
in an internal role, they have greater access to the source
code, program requirements, and the developers themselves;
they are also commonly involved in program-design decisions
(T=7, H=0). All of our hackers, conversely, are (intentionally)
outsiders (H=15) approaching the program as a black box with
access at most to the source code if it is an open-source project
or unobfuscated client-side script. Our participants report that
both perspectives have key advantages and disadvantages: as
outsiders by design, hackers are not biased by the assumptions
of the developers, but testers have potentially valuable inside
knowledge as well as an advantage in communicating ﬁndings
to developers.
Internal efforts rely on documentation and direct developer
382
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:29:31 UTC from IEEE Xplore.  Restrictions apply. 
communication. When gathering information, most testers rely
on internal code tracking databases and communication with
developers and other testers to determine the results of prior
vulnerability discovery efforts (T=9, H=0). When trying to
understand the program, because testers are involved in the
program’s design, they get into the mindset of developers by
talking to them (T=8, H=0). T6W described participating with
developers and other stakeholders in “a design session. That’s
where we are going to put down the requirements.” This session
includes discussions about how to build the system and “what
kind of testing we are going to [do].”
Having internal access to the development process can reveal
ﬂawed assumptions that would never be found by an outsider.
However, knowing too much about the program going into
the vulnerability search can blind the investigator to certain
issues. T4G explains this, saying, “I try to learn as much about
it without knowing too much about it. . . . It’s hard to ignore
certain details once you know about certain areas already.”
However, T4G still recognized the value of communicating
with his developers, saying, “You can give feedback to your
teammates, your developers, your product owners. . . . You’re
coming back with information, and then they react on it. Then
you have to go back there [to explore] again.”
External efforts use black-box testing and reverse engi-
neering techniques. Because hackers do not have access to
internal resources, they have to use more complicated methods
to directly interrogate the system. When initially gathering
information about a program, hackers use network-scanning
tools and other black-box enumeration techniques to determine
how the program is built and what underlying technologies
it uses (T=0, H=5). During the program understanding phase,
hackers rely only on their ability to reverse engineer the
developer’s intentions by reading and executing the code in
lieu of talking to developers (T=0, H=15). H9G builds a clear
picture of how the developer is thinking and what they are
trying to do by looking directly at their code, because “when
you look at the binary. . . you get a more intimate look into
how the programmer was thinking.” He reads the code to “see
certain implementations and certain patterns in the code. . . that
can potentially allow you to make an assumption about a part
of the speciﬁcation.”
Building rapport with developers. In contrast to the mixed
effect on the vulnerability search, our participants indicated
that having greater access to the development process provides
an advantage when reporting the vulnerability. Our testers
discussed using this connection to develop a shared language
about the program (T=8, H=0) and build a relationship where
they can go to the developers directly to discuss the issue and
mitigate the problem (T=9, H=0). T1W stated that he tries
“to use the same verbiage, so if for example I’m testing an
application and I’m referencing certain parts, . . . [I’ll] see how
they name those speciﬁc ﬁelds. . . and I’ll try to use the terms
they’re using versus regular colloquial terms.” He explained
that the shared language and relationship allows him to avoid
misunderstandings that could slow or even stop the remediation
process.
Our hackers rarely have the same rapport because, as external
participants, they communicate with developers only when they
ﬁnd a vulnerability, which may only occur once per program.
In a few cases, our hackers were able to develop a strong
relationship with a particular company (H=2), but this only
occurred after they submitted multiple reports to that company.
H8M focuses on a very speciﬁc program type, mobile device
ﬁrmware, and therefore has developed a relationship with most
of the major companies in this area. He described adjusting
the information he reports depending on previous interactions.
For less security-proﬁcient companies he needs “to go into
full details, as well as sending a fully compiled, weaponized
exploit,” but for companies he has a better relationship with,
he just says “In this application in this class, you don’t handle
this right,” and they can identify and ﬁx the issue quickly. This
avoids wasting his time creating a lengthy report or developers’
time reading it.
Hackers make up for lack of access with proofs-of-concept.
Because most hackers have minimal communication with
developers, they stressed the necessity of proving the existence
and importance of the vulnerability with a proof-of-concept
exploit to avoid spending signiﬁcant amounts of time explaining
the problem. H3G explained that “including the proof-of-
concept takes more time to develop, but it saves a lot of
time and communication with the [developers], because you
show that you can do an arbitrary [code execution]. . . and that
this theoretical vulnerability cannot be mitigated.” While this
approach is straightforward, developing an exploit can be the
most time-consuming part of the process (H=2), and developers
may not accept a report even in the face of evidence (T=7, H=9)
or appropriately ﬁx the code because they do not understand
the root of the problem (T=7, H=9). H15W gave an example
of a time when he was reviewing a bug report and found that
“they didn’t ﬁx it properly. [It was] still exploitable in other
ways.” Testers overcome these challenges by spending time in
discussion with the developers to clear up misunderstandings,
but hackers typically do not have these necessary relationships
and access to developers.
D. Motivation
The ﬁnal inﬂuencing factor on the discovery process is a
practitioner’s motivation for looking for vulnerabilities. Figure 5
illustrates how motivations affect the discovery process. Most of
our participants select which programs to search and what parts
of the code to look at based on a calculation of likelihood to
ﬁnd vulnerabilities versus the value of the vulnerabilities found
(T=10, H=11). The four hackers who did not describe this
likelihood versus value calculation still consider likelihood as a
factor (T=10, H=15), but either are paid a ﬁxed rate as part of
an internal security team or contracted review or are motivated
by some non-monetary beneﬁt (see Section VI-D). Overall, our
hackers and testers estimate vulnerability likelihood similarly,
but differ signiﬁcantly when determining value. Additionally,
383
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:29:31 UTC from IEEE Xplore.  Restrictions apply. 
The ﬁrst strategy seeks out programs where the hacker has
a competitive advantage based on specialized knowledge or
experience that makes it unlikely that others will ﬁnd other
similar vulnerabilities (H=9). Hackers following this strategy
participate in bug bounties even if they are unlikely to receive
immediate payouts, because they can gain experience that will
help them later ﬁnd higher-payout vulnerabilities. H1H said
that he focuses on more complex problems even though “I had
no success for the ﬁrst year, I knew that the barrier to entry
was so high, that once I got good enough, then it would work
out consistently that I could ﬁnd bugs and get rewards. . . once
you get good at it there’s less competition.”
The other payout maximizing strategy we observed is to
primarily look for simple vulnerabilities in programs that have
only recently started a bug bounty program (H=8). In this
strategy, hackers race to ﬁnd as many low-payout vulnerabilities
as possible as soon as a program is made public. Hackers
dedicate little time to each program to avoid the risk of report
collisions and switch to new projects quickly. H12W said that
he switches projects frequently, just looking for “low-hanging
fruit,” because “somebody else could get there before you,
while you are still hitting your head on the wall on this old
client.” This aligns with the phenomenon observed by Maillart
et al., where hackers switch quickly to new bug bounties
because they are more likely to have more vulnerabilities [12].
We found that hackers typically consider this approach when
searching for web vulnerabilities, which have a “lower barrier
to entry” than ﬁnding vulnerabilities in host software for which
“the process to become proﬁcient is higher [harder]” (H1H).
Additionally, some hackers completely avoid any company
they have previously had poor relations with, either because
they do not think it is likely they will be compensated fairly
for their efforts or because the payment is not worth the
administrative struggle (T=0, H=6). H9G described submitting
a remote-code-execution vulnerability, but never receiving a
response, when it should have garnered a large bounty based
on the company’s published policy. He said that “When we
encounter that hostile behavior, that’s pretty much an instant
turn-off” from working with that company again.
Some participants also consider non-monetary value.
Speciﬁcally, participants cited motivations including altruism
(i.e., bounty paid to charity or improved security for the greater
good) (T=2, H=7), enjoyment (T=1, H=11), peer pressure (T=0,
H=1), and personal protection (i.e., ﬁx security bugs in products
they use to avoid personal exploitation) (T=0, H=2). However,
these factors are commonly secondary to monetary value.
All practitioners are motivated to report well. Practitioners’
motivations also inﬂuence how they communicate with devel-
opers when reporting. Both populations expressed the need
to make developers aware of the importance of ﬁxing these
bugs (T=10, H=12). Testers are only able to prevent harm
to the company if developers accept and adequately ﬁx the
vulnerabilities they report. Hackers, motivated by a bug bounty
payout, receive their payment only when the company accepts
their report and are only paid at the level they expect if the
Fig. 5: Motivation category graph.
we found that all participants were motivated to report clearly,