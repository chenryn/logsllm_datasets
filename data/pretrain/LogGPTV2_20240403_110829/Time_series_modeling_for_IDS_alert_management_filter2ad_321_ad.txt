11
2
3
4
1
21
0
5
9
5
2
21
Whatsup The known phenomena p2, p3, p6, and p8 were
detected, but p4, p5, and p7 were missed by the tool. All
the phenomena are shifts in constant level activity. The
common factors for K- are the smallness of the shift and
the fact that the shift is placed after other anomalies. The
reason for this will be discussed in more detail in section 6.4.
The two new interesting anomalies are actually the de-
layed detection of missed p4 and p7 as the tool reacts to the
changed height of a weekday peak after the constant level
decreases.
Of the ﬁve N- occurrences, two are extra anomalies or
duplicates, signaled right after an interesting known or new
phenomenon. The remaining three were issued due to changed
intensity of the weekday peaks compared to the observations
of the previous week. We did not consider these interesting
enough, and placed them into this category. As such, these
phenomena highlighted by the tool are not harmful, or can
even be useful for the operator.
Compared to the EWMA approach, the signaled anoma-
lies are almost the same. However, the model of normal be-
havior is more accurate, and even the missed known anoma-
lies can be seen in the residual series Et even though the
detection method did not pick them out.
Destination Unreachable This ﬂow did not contain any
known, interesting phenomena, only a rather weak weekly
rhythm. The tool signaled in total twelve anomalies.
We placed three into the interesting category, as they
pointed out overall intensity changes in both high (week-
day) and low (weekend) activity periods with respect to the
situation week before. Of the nine N- anomalies, two were
clearly artifacts created by ∇week. They were relatively easy
to identify as artiﬁcial phenomenon.
For the remaining seven we could not give an explanation.
At ﬁrst this might seem like a disappointing result. However,
it is also interesting to note that the periodicity removal step
explains quite many peaks of the original ﬂow, which could
have seemed suspicious by manual inspection. Even though
if we only signal three interesting phenomena, we are able
to explain many more as part of the weekly rhythm.
The EWMA approach signaled over 50% more anomalies,
mostly peaks part of the weekly rhythm. It was unable to
point out the level shifts we found out using the proposed
methodology.
LOCAL-POLICY The known, interesting phenomena
p2, p4, and p5 were signaled, and p3 was missed. Given that
the missed p3 is a change in high frequency peak intensity
levels from 1 to 2, among the peaks reaching up to 10000
alerts, we do not consider this as a serious shortcoming.
The tool pointed out four new, interesting phenomena.
These were additional or missing peaks breaking the weekly
rhythm, or changes in the intensity of periodic peaks. Look-
ing the situation a posteriori, these seem quite evident, but
0
before more thorough analysis of the ﬂow structure these
were not so easy to pick out.
The ﬁve N- contain two artifacts generated by ∇week, two
anomalies signaled on extremely high (3000 and 8000 alerts)
peaks that however are part of the weekly rhythm, and one
anomaly that could be caused by variations in the low-level
components. These variations are interesting, but as we
cannot be sure that the anomaly is really signaled because of
these variations, it was assigned in N-. As the two artiﬁcial
anomalies were easy to identify, the N- category for this ﬂow
contains rather harmless meta-alerts.
Even though the alert ﬂow is quite challenging to pro-
cess, consisting mainly of huge alert impulses, we are able
to pick out the known interesting phenomena. In addition,
the analysis performed with this methodology helped us to
better understand the structure in the alert ﬂow by signaling
new anomalies, and by not reacting to certain peaks.
The EWMA approach had diﬃculties particularly with
this ﬂow. In practice it signaled every peak, and was unable
to leave out the peaks following the weekly rhythm.
Speedera The ﬂow is depicted with the signaled anoma-
lies in Fig. 6. It contained only two known, interesting phe-
nomena, p1 and p2, both of which were detected.
The N+ contained only one alert n2, pointing out a lower-
than-normal intensity Friday.
In the N- two signaled anomalies were related to arti-
facts created by ∇week. Both known anomalies are echoed
in transformed series ( s
1 of Fig. 3) one week later, p1 caus-
ing n3, and p2 causing n4. Knowing the behavior of the
∇week, these artifacts were easy to identify in this ﬂow.
The phenomenon n1 in the beginning of the series is an
artifact of two adjacent anomalies created by the two facts,
1) an AR(p) model starts to provide good predictions start-
ing only from (p + 1)th observation fed into the equation (5),
and 2) the detection component needs to receive more data
for correct thresholding. This type of artifact is created both
with this methodology and with the EWMA approach for
every ﬂow. We can ignore these anomalies systematically,
and thus have excluded them from the statistics.
We chose to visualize speedera’s results as they contain
good examples of unwanted artifacts that can be created by
∇week. The results also show how well we are able to ﬁlter
out the alerts being part of the normal ﬂow behavior.
The EWMA approach signals an anomaly only in the be-
ginning of every Monday, when the periodic intensity in-
crease takes place. As such it is unable to both cope with
the strong periodic component, and to detect any non dras-
tic changes in the ﬂow behavior.
6.4 Discussion
Overall, we can model regular and periodic behavior in
alert ﬂows, and we detect sharp and impulse-like peaks and
valleys (all ﬁve ﬂows) outside the day and the week rhythms
of the alert ﬂow. On the other hand, normal behavior of
alert ﬂows consisting only of impulse like peaks, e.g. LOCAL
POLICY, is diﬃcult to capture with proposed model. We
can also detect, up to certain degree, shifts in the constant
components (SNMP and Whatsup) and the overall intensity
(Dest. Unr.). However, the series detrending makes the
detection of these shifts more diﬃcult, as only the transition
remains visible afterwards.
Preceding variations in the residual series (abnormal com-
ponent) can mask the current anomaly because the detec-
200
p1
n1
n2
n3
p2
n4
y
t
i
s
n
e
t
n
I
100
1
0.5
0
0
0
5
5
10
10
15
15
Time (d)
20
20
0
25
25
Figure 6: The detected anomalies for speedera. The
series is the original alert ﬂow, corresponding to the
values s1 of Fig. 3 and signaled anomalies are indi-
cated as peaks
tion threshold is based on the standard deviation. Therefore
small level shifts, like the ones in Whatsup, are in danger
to be lost when alert ﬂow is not very regular or constant.
However, the shifts are present in the residuals, and could
be picked out with other means.
In other words, we could possibly catch more anomalies
by developing the detection component of the processing
chain (Fig. 3) or just by customizing the smoothing factor
and the alerting thresholds, However, the current approach
works suﬃciently well yet being rather generic, and generic
tools are easier to deploy. For these reasons we regarded the
extra step not worth the trouble.
Now coming back to our main objective: allowing the op-
erator to focus on more relevant tasks by relieving him from
the manual inspection of numerous benign alerts. As we are
processing alert ﬂows and the meta-alerts point to a time in-
terval, a direct comparison of alert numbers before and after
is not the most suitable metric to use. If investigating the
alerts manually, the operator is probably not monitoring this
type of alerts constantly, but more likely checks from time
to time if the situation seems normal or not. Let us assume
for the sake of the discussion that from time to time is once
in an hour. The operator would need to perform at least a
minimal check every hour during which alerts are generated.
Since in normal situation alerts occur all the time, also zero
activity intervals could incite additional checks.
Table 4 shows the number of meta-alerts issued by the tool
in the second column and the number of non-zero intervals
requiring inspection without automated processing in the
validation data for each ﬂow in the third column. The fourth
column shows the time gain as the proportion of these one
hour time slots freed from manual inspection when alert
processing is automated. The proposed approach can relieve
the operator from 90% or more of the status checks, and
the gained time can be spent on more relevant tasks.
In
addition, the analysis done by applying the methodology
can point out phenomena that would be diﬃcult to see via
manual inspection, even if looking at the alerts at the ﬂow
level.

Table 4: The gain in time slots with the methodol-
ogy
Flow
Automated Manual Gain
SNMP
Whatsup
Dest Unr
LOCAL-POLICY
Speedera
15
11
12
12
5
564
390
556
118
518
0.97
0.97
0.98
0.90
0.99
On the negative side, the methodology signals few artiﬁ-
cial phenomena, but they seem to be usually rather easy to
identify. The approach also misses some interesting phenom-
ena, typically small changes close to larger disturbations.
These costs need to be weighed against the gain. From the
results we can see, that the number of false positives is rel-
atively small. However, we cannot provide comprehensive
statistics on the quality of detection as we lack analyzed
and labeled real world alert sets.
The proposed methodology has been tailored for our needs,
for the alert types and volumes we encounter. Part of the
reported ﬂow behaviors are likely to be speciﬁc to our en-
vironment. This is not a general solution for all alert pro-
cessing, but a component for a speciﬁc task in larger alert
management system. However, we believe that similar prob-
lems exist also in other information systems, and that this
processing methodology can be useful also elsewhere.
It
should also be pointed out that like all anomaly detection
approaches, the methodology does not provide diagnostic of
the meta-alert’s cause, and it is not even intended to help
in root cause analysis.
7. CONCLUSIONS
In this paper we have presented an analysis of real world
alert data. The alerts consisted mainly of types that can
be considered as background noise of an operational infor-
mation system. Among the noise there can be premises
or consequences of attacks or more general problems, and
therefore monitoring this kind of background noise can be
interesting with suitable methods, despite the high alert vol-
umes. The analysis revealed signiﬁcant structure in the alert
ﬂows, both visually and with basic mathematical tools.
Based on the observations, we proposed a methodology
to process these alerts in order to highlight the interesting
phenomena contained in the alert ﬂows. We assume that
the stationary structure in these ﬂows originates from the
normal behavior of the monitored system. We model the
normal behavior, and then signal deviations from the model.
The process consists of two phases, the estimation and the
detection. In both we perform the necessary steps to build
an alert series, and to remove the trend and the periodic-
ity from the series. Then, during the estimation phase, we
estimate a time series model for the remaining structure in
the signal. During the detection phase, the model output is
compared to the observations to isolate the abnormal com-
ponent of the alert ﬂow for further analysis.
dition the proposed processing has the possible side eﬀect
of creating artiﬁcial anomalies into the alert data. However,
these risks seem to be relatively small compared to the gains.
As we use real world data for model estimation, we are
incorporating also existing anomalies in addition to the nor-
mal behavior into model parameters. The results show that
anomalies in estimation data did not have signiﬁcant ad-
verse eﬀect on the detection capabilities. One should how-
ever keep this fact in mind, and avoid ﬁtting the model too
well to the data.
We have used one hour sampling interval in this work. It
can seem long, but given the nature of processed alerts we
consider this reasonable. As discussed previously, this type
of alerts are unlikely to be treated in real-time in any case.
One might need to decrease the sampling interval for more
timely detection, especially if trying to react to automated
threats such as worms. Worm detection is not per se the
goal of this work. In addition changes in sampling interval
may aﬀect the observed ﬂow behaviors, and make certain
characteristics appear or disappear.
Currently we are performing this processing at the man-
ager level of the intrusion detection framework. For certain
alert ﬂows, especially where no pattern matching is needed
and the aggregation can be done using for example packet
header information, it could be possible to push this kind of
processing towards the sensors.
8. REFERENCES
[1] S. Axelsson. The Base-Rate Fallacy and Its
Implications for the Diﬃculty of Intrusion Detection.
In Proc. of the ACM CCS’99, Nov. 1999.
[2] P. Barford, J. Kline, D. Plonka, and A. Ron. A Signal
Analysis of Network Traﬃc Anomalies. In Proc of
ACM SIGCOMM Internet Measurement Workshop,
Nov. 2002.
[3] P. J. Brockwell and R. A. Davis. Time series: theory
and methods. Springer Texts in Statistics, 1991.
[4] P. J. Brockwell and R. A. Davis. Introduction to time
series and forecasting. Springer Texts in Statistics,
2002.
[5] H. Debar and B. Morin. Evaluation of the Diagnostic
Capabilities of Commercial Intrusion Detection
Systems. In Proc. of the RAID’02. Springer–Verlag,
2002.
[6] H. Debar and A. Wespi. Aggregation and Correlation
of Intrusion-Detection Alerts. In Proc. of the
RAID’01. Springer–Verlag, 2001.
[7] K. Julisch. Mining Alarm Clusters to Improve Alarm
Handling Eﬃciency. In Proc. of the ACSAC’01, Dec.
2001.
[8] K. Julisch and M. Dacier. Mining Intrusion Detection
Alarms for Actionable Knowledge. In Proc. of the
SIGKDD’02, 2002.
[9] C. Kruegel and W. Robertson. Alert veriﬁcation:
Determining the success of intrusion attempts. In
Proc. of the DIMVA’04, Dortmund, Germany, July
2004.
We presented results obtained with a tool using this method-
[10] G. M. Ljung and G. E. P. Box. On a Measure of Lack
ology. They indicate that we can free signiﬁcant amount of
the time spent on analyzing these alerts when compared to
the manual processing. As with all automated processing
methods, there is a risk of ﬁltering interesting alerts. In ad-
of Fit in Time Series Models. Biometrica,
65(2):297–303, Aug. 1978.
[11] V. A. Mahadik, X. Wu, and D. S. Reeves. Detection of
Denial of QoS Attacks Based on χ2 Statistic and

EWMA Control Chart. URL:
http://arqos.csc.ncsu.edu/papers.htm, Feb. 2002.
[12] S. Manganaris, M. Christensen, D. Zerkle, and
K. Hermiz. A Data Mining Analysis of RTID Alarms.
RAID’99, 1999.
[13] H. Mannila, H. Toivonen, and A. I. Virkamo.
Discovering Frequent Episodes in Sequences. In Proc.
of the KDD’95, 1995.
[14] P. A. Porras, M. W. Fong, and A. Valdes. A
Mission-Impact-Based Approach to INFOSEC Alarm
Correlation. In Proc. of the RAID’02.
Springer–Verlag, 2002.
[15] X. Qin and W. Lee. Statistical Causality Analysis of
INFOSEC Alert Data. In Proc. of the RAID’03.
Springer–Verlag, 2003.
[16] A. Valdes and K. Skinner. Probabilistic Alert
Correlation. In Proc. of the RAID’01.
Springer–Verlag, 2001.
[17] J. Viinikka and H. Debar. Monitoring IDS
Background Noise Using EWMA Control Charts and
Alert Information. In Proc. of the RAID’04,
Springer–Verlag, 2004.
[18] N. Ye, C. Borror, and Y. Chang. EWMA Techniques
for Computer Intrusion Detection Through Anomalous
Changes In Event Intensity. Quality and Reliability
Engineering International, 18:443–451, 2002.
[19] N. Ye, S. Vilbert, and Q. Chen. Computer Intrusion
Detection Through EWMA for Autocorrelated and
Uncorrelated Data. IEEE Transactions on Reliability,
52(1):75–82, Mar. 2003.
