We extracted sharing and collection statements from 94.4%
(13,021/ 13,796) of privacy policies. From those policies,
218,257 policy statements were extracted from 48,831 sen-
tences that were identiﬁed as a sharing or collection sentence,
such that 7,526 had negative sentiment and 210,731 had posi-
tive sentiment. 31.2% (4,299/ 13,796) of policies had at least
one negative sentiment policy statement and 92.6% (12,779/
13,796) of policies had at least one positive sentiment policy
statement. The policy statements discussed 34 distinct granu-
larities of data types and 52 distinct granularities of entities.
In total, there were 412 unique policy statement tuples.
For the 45,603 data ﬂows across the 13,796 applications,
there were 13 unique data types transmitted to 2,243 unique
domains. The 2,243 domains were resolved to 112 unique en-
tities. In total, there were 364 unique data ﬂow tuples. Overall,
Ad IDs were the most frequently transmitted data type, which
accounted for 26,628 data ﬂows to 100 unique entities across
11,585 applications. Across all of the ﬂows, Unity was the
most common recipient, which accounted for 6,270 data ﬂows
containing 6 unique data types across 4,381 applications.
We ran POLICHECK on the dataset and the raw statistics
from analysis are listed in Table 3. We ﬁnd that 42.4% of
applications contain at least one omitted disclosure or incor-
rect disclosure, which the data ﬂow is not disclosed by the
policy or is in direct conﬂict with statements in the policy.
We presented various case studies found by POLICHECK in
Section 2. Section 6 provides additional case studies. The
remainder of this section discusses the ﬁndings made possible
by POLICHECK.
Note that, in this study, we consider all device IDs to be
personally identiﬁable information (PII). Device IDs are clas-
siﬁed as PII under GDPR [3] and CCPA [1], as they are gen-
erally used for tracking and attribution. Ad IDs were initially
introduced as a pseudonymous identiﬁer to be used to track
users instead of collecting persistent identiﬁers, such as An-
droid IDs, IMEI, and email addresses. However, we ﬁnd that
74.7% of entities that receive Ad IDs also receive a persistent
identiﬁer. Therefore, we also consider Ad IDs to be PII, be-
cause mixing them with persistent identiﬁers nulliﬁes their
originally intended properties since they lose the property of
non-persistence and tracking can be bridged across resets. We
ﬁnd that 11,589 applications send this unique identiﬁer to
third-parties, which is then linkable to users’ email addresses,
other device identiﬁers, and other sensitive information.
Finding 1: Only 0.5% of data ﬂows were explicitly discussed
by sentences within the privacy policy in terms of the exact
entity and exact data type. In total, only 223 data ﬂows were
classiﬁed as clear disclosures. Figure 2 shows the number
of clear disclosures for each of the data ﬂow tuples. The
hatched sections denote that there were no transmissions of
that speciﬁc data type to that entity in the entire dataset. While
third-parties account for 42,592 of the total data ﬂows, only 7
data ﬂows were classiﬁed as clear disclosures. As we discuss
in Finding 2, this is likely due to the fact that policies are
being vague about third-party disclosures.
In contrast, applications were more likely to clearly dis-
USENIX Association
29th USENIX Security Symposium    993
Figure 2: Clear Disclosure HeatMap - Policies are clearer
about the ﬁrst-party receiving a speciﬁc data type than a third-
party doing so.
Figure 3: Vague Disclosure Heatmap - Policies often discuss
the sharing of Android and advertising IDs in vague terms.
close their ﬁrst-party data ﬂows (216 data ﬂows across 206
apps). The most commonly disclosed ﬁrst-party ﬂow involved
location data, which was clearly discussed for 81 data ﬂows.
However, as there were over 282 instances of ﬁrst-parties
collecting location data, this only accounts for 28.7% (81/
282) of ﬁrst-party data ﬂows involving location. Similarly,
IMEIs are the second most frequent clear disclosure with 41
data ﬂows, but still only accounted for 12.1% (41/339) of
total ﬁrst-party data ﬂows. The low rate of clear disclosure
indicates that privacy policies are not explicitly discussing the
types of data that they collect and with whom they share it.
Finding 2: 49.5% of applications are disclosing their third-
party sharing practices using vague terms. In total, 54.9%
(23,367/ 42,592) of third-party ﬂows were disclosed using
vague terms to refer to the entity, the data type, or both. Fig-
ure 3 shows the number of vague disclosures for each of the
data ﬂow tuples with the 8 most common third-party entities.
The hatched sections denote that there were no transmissions
Figure 4: Vagueness Score Scatter Plot - Policies are likely to
use vague terms to describe both data types and entities.
of that speciﬁc data type to that entity in the entire dataset. Ad
IDs and Android IDs accounted for 50.2% (21,363/ 42,592)
of the vague disclosures for third-party ﬂows. Ad IDs and An-
droid IDs were disclosed 40.7% of the time by the policy state-
ment (third-party, collect, personally identiﬁable information)
and 25.2% of the time by (third-party, collect, information).
The vagueness of these policy statements does not provide
transparency to the wide-range of advertisers and analytics
providers that this information is being sent to. As shown
in Figure 3, Crashlytics and Unity3d were the most frequent
entities of data ﬂows that were classiﬁed as vague disclosures.
Crashlytics is an analytics provider owned by Google and
Unity3d provides a game engine to developers, but also pro-
vides advertisements and analytics. In particular, data ﬂows
to Crashlytics and Unity3d accounted for 7.4% of third-party
vague disclosures (3,131/ 42,592). These entities were dis-
cussed as third-parties in 80.7% (2,528/ 3,131) and 72.9%
(2,142/ 2,938) of the time, respectively.
Figure 4 shows a graphical representation of the frequency
of policy consistency vagueness. Note the root node of the
data vagueness is the term “information” while the root node
of the entity vagueness is “anyone.” The data vagueness score
of around 0.5 generally represents terms such as “personally
identiﬁable information,” “device information,” or “user infor-
mation.” The entity vagueness score of around 0.67 generally
represents the term “third-party” while 0.5 represents terms
such as “advertising network” or “analytic provider.” There-
fore, in general, third-party data ﬂows are most frequently
described in vague terms for both entities and data types. As
the corners of the ﬁgure are relatively sparse, it means that if
the policy is discussing the entity vaguely then they are likely
discussing the data type vaguely. Further, the fact that “third-
party” is the most commonly used term to discuss entities,
it raises concerns that applications are not complying to the
GDPR’s mandate on speciﬁcity of disclosures.
Figure 5 shows the CDF of the number of unique entities
and data types involved within third-party vague disclosures
per application. In total, around 80% of the applications with
994    29th USENIX Security Symposium
USENIX Association
UnityGoogleFacebook1st PartyEntityAd IDAndroid IDEmail AddrLocationIMEIPhone #Data Type500000100100035739814113020406080Number of Clear DisclosuresVungleUnityFlurryFacebookCrashlyticsChartboostAppsflyerApplovin1st PartyEntityAd IDAndroid IDApps InstalledEmail AddrLocationGSFIDIMEIMAC AddrPhone #Router SSIDSerial #Sim Serial #Data Type679100120131213402325004959107381784263331152516000661563711205571429722090322552692532315082372176241605802004006008001000120014001600Number of Vague DisclosuresExact0.250.50.75RootData VaguenessExact0.250.50.75RootEntity Vagueness2000400060008000Number of DisclosuresFigure 5: It is feasible for developers to convert vague disclo-
sures to clear disclosures.
third-party vague disclosures contain 4 or fewer unique enti-
ties within its data ﬂows. Further, 97.8% of applications with
third-party vague disclosures contain 3 or fewer unique data
types within its data ﬂows. Therefore, it is largely feasible
that developers explicitly disclose the exact data types being
shared with the exact entities (clear disclosures) As the devel-
opers disclosed the behaviors within the privacy policy, albeit
vaguely, they are likely aware that the third-party libraries
collect some data. However, it is unknown whether develop-
ers are using vague terminology due to not understanding the
scope of data collection or whether they do not understand the
importance of clear disclosures. Determining the root cause
for vague disclosures is left as future work.
Finding 3: 11.6% of applications are disclosing their ﬁrst-
party collection practices using broad terms. In total, 73.4%
(2,211/ 3,011) of ﬁrst-party ﬂows were disclosed using vague
terms to refer to the data type. The right column in Figure 3
shows the distribution of vague disclosures for ﬁrst-parties.
Android IDs accounted for 41.8% (925/ 2,211) of the ﬁrst-
party vague disclosures. Similar to the case for third-parties,
these ﬂows were most commonly disclosed as the policy tuple
(we, collect, personally identiﬁable information). Surprisingly,
they were only disclosed by the terms “device identiﬁers” or
“identiﬁers” in 20.8% of the ﬂows (192 / 925). A similar trend
follows for ﬁrst-party collection of Ad IDs and IMEIs. In total,
97.7% of the applications with ﬁrst-party vague disclosures
contain 3 or fewer unique data types within its data ﬂows.
Therefore, it is also feasible that developers explicitly disclose
the exact data types that they collect (i.e., clear disclosures).
Finding 4: 719 applications make incorrect statements about
their data practices. POLICHECK identiﬁed that 719 appli-
cations contained incorrect disclosures. These applications
consisted of 4.2% (1,930/ 45,603) of the data ﬂows. Figure 6
shows that the most frequent incorrect disclosures involved
sharing Ad IDs and Android IDs with Crashlytics (15.7%:
303/ 1,930), Unity3d (13.7%: 264/ 1,930), and Flurry (9.6%:
185/ 1,930). The policy statement (third-party, not_collect,
personally identiﬁable information) accounted for 63.4% dis-
closures for these cases.
Finding 5: POLICHECK identiﬁed 31.1% (14,409/45,603)
Figure 6: Incorrect Disclosure Heatmap - POLICHECK identi-
ﬁed 1,912 incorrect disclosures across 719 applications
Figure 7: Omitted Disclosure Heatmap - Applications often
do not disclose sharing Android and Ad IDs with third-parties.
This may be due to the perception that such collection is
implied when they disclose that they use an advertiser.
of data ﬂows as omitted disclosures. Of the 14,409 omitted
disclosures, 208 were ﬁrst-party ﬂows and 14,201 involved
third-parties. As shown in Figure 7 only 6.9% (208 / 3,011)
of ﬁrst-party ﬂows were not disclosed. The 3 most frequently
omitted data types for ﬁrst-party ﬂows were Android IDs
(78/208), Ad IDs (50/208), and the device IMEI (30/208).
For third-party ﬂows, Figure 7 shows that sharing both An-
droid IDs and Ad IDs with Crashlytics and Unity3d accounted
for 27.8% (3,168/11,398) and 24.7% (2,810/11,398) omit-
ted disclosures, respectively. Further, sharing AD IDs with
Facebook accounts for 15.8% (1,798/11,398) of third-party
omitted disclosures. It is surprising that Crashlytics collects
Android IDs, as they are a subsidiary of Google, and using
persistent hardware identiﬁers is against Google’s outline for
the best practices on collecting unique identiﬁers.
The signiﬁcant number of omitted disclosures raises the
following two questions. First, do developers understand the
types of data that are actually being collected when they in-
USENIX Association
29th USENIX Security Symposium    995
0246810121416Number of Unique {Entities | Data Types} in Data Flows0.00.20.40.60.81.0Cumulative Ratio of Appswith Third-Party Vague DisclosuresEntitiesData TypesVungleUnityStartappFlurryFacebookCrashlyticsChartboostAppsflyerAdjust1st PartyEntityAd IDAndroid IDApps InstalledLocationIMEIMAC AddrRouter SSIDSerial #Sim Serial #Data Type3190087177231600790101688410131140101014915400374009726060013730000342240021020406080100120140160Number of Incorrect DisclosuresVungleUnityStartappFlurryFacebookCrashlyticsChartboostAppsflyerApplovin1st PartyEntityAd IDAndroid IDEmail AddrLocationGSFIDIMEIMAC AddrPhone #Router SSIDSerial #Data Type40948739831304300642056535818324549862948553103074179504553575349212706412051900350786194305565020040060080010001200Number of Omitted Disclosuresplications are not sharing data with third-parties. While the
other 40% (249/622) of applications did not contain any data
ﬂows to third-parties in the observed client-side behavior, their
privacy policy contained statements that disclosed potential
third-party sharing. This property may indicate that the data
collected within ﬁrst-party ﬂows may ﬂow to third-parties
server-side. For example, we found that 35 applications con-
tained ﬁrst-party ﬂows collecting a wide-range of data (e.g.,
location (22 apps), phone number (6 apps), email address (2
apps), applications installed (1 app), Ad IDs (3 apps), and
various identiﬁers (3)). Their privacy policy states that they
share data that subsumes the data from a ﬁrst-party ﬂow to
“third-parties,” which permits server-side sharing of such data.
5.2 Evaluation
In this section, we present our evaluation of POLICHECK and
additional ﬁndings from our evaluation. First, we manually
validate a random selection of 153 data ﬂows across 151 ap-
plications and show that POLICHECK has a 90.8% precision.
Second, we perform a sensitivity analysis on POLICHECK’s
consistency model and show that POLICHECK’s entity-
sensitive model vastly outperforms entity-insensitive models.
The remainder of this section describes these experiments.
5.2.1 POLICHECK’s Performance
To evaluate the precision of POLICHECK, we manually val-
idate a subset of data ﬂows. Note that we do not evaluate
ambiguous disclosures, as attempting to resolve ambiguity
injects annotator bias into the evaluation. For the remaining
disclosure types, we randomly select up to 5 data ﬂows for
each data type, such that the ﬁrst-party and third-party data
ﬂows are proportionate to the disclosure type’s population.
Our dataset consists of 180 data ﬂows across 166 apps.
Validation Methodology: For validation, one-of-three au-
thors began by reading through the sentences that were ex-
tracted from each privacy policy to ensure correctness of
policy statement extraction. If there was an error with pol-
icy statement extraction, we record the disclosure as a false
positive and stopped analysis. For clear disclosures, vague
disclosures, and incorrect disclosures, we locate the sentences
in the policy and ensure that the sentence retains the same
meaning in the context of the rest of the policy. For omitted
disclosures, we read through the rest of the policy to determine
if any statements disclose the data ﬂow. If it is not apparent
and there is any uncertainty, we mark the ﬂow as “uncertain”
to avoid bias. Note that we marked 27 ﬂows as uncertain,
resulting in 153 data ﬂows across 151 applications
Results: POLICHECK achieves an overall 90.8% precision
(139/153) for performing ﬂow-to-policy consistency analysis.
For identifying consistencies (i.e., clear disclosures and vague
disclosures), POLICHECK had 86 true positives and only 4
false positives. For incorrect disclosures, POLICHECK had 35
Figure 8: Ambiguous Disclosure Heatmap - Privacy policies
are often contradictory when they discuss the sharing of An-
droid and advertising IDs.
clude a third-party SDK into their application? Second, do
developers know that they are responsible for disclosing such
behaviors in their privacy policy? We leave the exploration
of these questions as future work. Note that in comparison
to other disclosure types, POLICHECK has lower precision
for detecting omitted disclosures. We discuss this in detail in
Section 5.2 and provide a case study that they may also be
used as indicators for policies that are difﬁcult to comprehend.
Finding 6: 7.6% of applications have ambiguous privacy
policies. In total, 7.6% (3,463/ 45,603) of data ﬂows were
classiﬁed as ambiguous disclosures, which occurred across
7.6% (1,101/ 13,796) of applications. As shown in Figure 8,
Android IDs and Ad IDs are involved in 88.8% (3,074/ 1,101)
of ambiguous disclosures. In total, C1 contradictions were the
most common type whose policy statements both state that
they do and do not collect information at the same semantic
granularity, which accounted for 1,618 types of ambiguous
disclosures. For example, on such example is a children’s
application called “MiraPhone - Kids Phone 4-in-1 apk” (-
com.gokids.chydofon). This application collects the user’s
Android ID, but the privacy policy explicitly states, “We DO
NOT collect your unique identiﬁcator [sic],” and also states
“Anonymous identiﬁers, we use anonymous identiﬁers when
you interact with services, such as advertising services and
others.” These two statements are contradictory policy state-
ments and it is unclear what the correct interpretation of the
policy should be.
Finding 7: Only 2.7% of applications may not be sharing
data with third-parties. In total, only 4.5% (622/13,796) of
applications in our dataset did not contain any data ﬂows
to third-parties in the observed client-side behavior. 60.0%
(373/622) of those applications did not contain statements that
disclosed that data may be shared with third-parties. There-
fore, assuming that their privacy policy accurately reﬂects
server-side behaviors, only around 2.7% (373/13,796) of ap-
996    29th USENIX Security Symposium
USENIX Association
UnityTapjoyFlurryFacebookCrashlyticsChartboostAppsflyerAdjust1st PartyEntityAd IDAndroid IDEmail AddrLocationIMEIMAC AddrPhone #Router SSIDSerial #Data Type141185341100506503701416021211991100026627514495621614702610093170290911331302775262050100150200250Number of Ambiguous Disclosurestrue positives and 3 false positives.
5.2.2 Sensitivity Analysis
For omitted disclosures, POLICHECK had 18 true positives
and 7 false positives, which was primarily due to incomplete
policy statement extraction. The main reason for incomplete
policy extraction was that the information describing the shar-
ing and collection practices spanned multiple sentences and
sections of the policy. The policy did not make declarative
statements on their collection and sharing practices. Under-
standing an entire document is beyond the current limits of
NLP, but this stratiﬁcation also leads to an important obser-
vation. The policies for the omitted disclosure false positives
were generally more difﬁcult to read than other policies, and
often required a great deal of mental effort to understand.
Therefore, these omissions can potentially be indicative of
poor privacy policy interpretability. We explored this direc-
tion by analyzing a select number of applications with the
greatest number of omitted disclosures in our data set.
Case Study: Omitted disclosures may also indicate confusing
language in privacy policies: A popular game application
with over 100M+ downloads called ‘Ant Smasher by Best
Cool & Fun Games,” (com.bestcoolfungames.antsmasher)
had 17 unique omitted disclosures. The application has an
E rating, which means that it is marketed towards children,
but yet it shares Ad IDs, Android IDs, and location data with
advertisers and analytics providers. When validating these
data ﬂows, we found the following policy statement, which
potentially discloses these practices albeit vaguely.