Table 2: Runtime overheads of Robusta for a set of
JNI programs.
to Zlib, which performs the compression and returns
the result to the Java side. Then the Java side passes
the next buﬀer of data to Zlib. Therefore, the number
of context switches diﬀers signiﬁcantly with diﬀerent
buﬀer sizes. We tested the zip program with buﬀer
sizes 1KB, 2KB, 4KB, 8KB, and 16KB.
• libec. Experiments were set up to generate pairs of
public and private keys of varying sizes from random
seeds. We experimented with key sizes 112, 160, 224,
256, 384, 521 and 571.
• StrictMath. Experiments were set up to invoke li-
brary functions in the fdlibm math library repeatedly.
• libharu. Experiments were set up to generate a 100-
page PDF document from sample text.
• libjpeg. Experiments were set up to convert a 5Mb
bmp image into JPEG format.
Table 2 presents the experimental results for the bench-
mark programs. The numbers in the column of “Robusta
increase” were obtained in the following way. We ﬁrst com-
piled the program through the GNU toolchain and ran it
in the vanilla OpenJDK. Let x1 denote the total runtime.
The program was then fed to the NaCl toolchain to produce
NaCl-compliant binaries and was run in Robusta. Let y1
be the total runtime in Robusta. With these measurements,
(y1 − x1)/x1 is the runtime overhead of Robusta over Open-
JDK and is the number in the “Robusta increase” column of
the result table.
Table 2 also shows the measurements for the context switch
intensity, or the number of context switches per millisecond.
As we can see from the table, the runtime overhead corre-
lates strongly with the context-switch intensity. In the zip
benchmark, as the context switch intensity decreases from
18.50 (with the buﬀer size 1KB) to 0.95 (with the buﬀer
size 16KB), the performance overhead also decreases from
9.64% to 1.40%. A similar story applies to the libec bench-
mark. StrictMath is an extreme case. It makes around 270
context switches per millisecond and its performance over-
head is signiﬁcant. The high context switch intensity is due
to the fact that each native method call in this benchmark
stays in the sandbox very shortly. Another extreme case is
libjpeg, which has a very low number of context switches
per millisecond and thus Robusta incurs little overhead over
SFI.
The result table also shows some performance improve-
ments. We believe it is due to NaCl because in those cases
the context-switch intensity is low. NaCl reported perfor-
mance improvements for some SPEC2000 benchmark pro-
grams because of positive interactions between alignment
and processor microarchitectures.
In general, the results show that Robusta is best used
for applications that do not have intensive levels of context
switching. For those applications where it is possible to
control context-switch intensity (such as zip), we suggest
increasing the amount of time that the applications stay in
the sandbox before switching out.
Robusta’s runtime overhead compares favorably to Safe-
JNI [30], which reports 63% performance overhead for the
zip benchmark with the 16KB buﬀer size. The reason is
that SafeJNI performs array bounds checking for every ac-
cess to the buﬀer passed from Java to native code, while it
is unnecessary in Robusta thanks to SFI.5 Robusta’s run-
time overhead also compares favorably to reimplementation
of native libraries in Java code. SafeJNI reported that the
runtime overhead of a pure Java implementation of the Zlib
library (jzlib-1.0.5) is 74%.
7. RELATED WORK
There has been a rich tradition of computer-security re-
search aiming to isolate untrusted code from a trusted envi-
ronment. Operating systems have long used hardware-based
protection to isolate one process from another. Nooks [29]
isolates device drivers from kernel code, and Xax [3] isolates
web applications from browsers. Robusta follows a software-
based approach [33, 28, 4, 5, 18, 34, 26]. Robusta shows SFI
can serve as a basis for eﬃciently isolating native libraries
in a type-safe language (Java), even in the case that the
two sides communicate through a tight interface (the JNI).
In terms of mediating system calls, Robusta is related to a
number of previous eﬀorts such as systrace [24] and many
others (e.g., [8, 11, 7]). The diﬀerence of Robusta is that
it delegates the job to Java’s security manager. This is a
general strategy of how system calls in native code can be
handled in language virtual machines.
5We assume a “ensure, but don’t check” strategy [18]. When
an out-of-bound access happens, the access is re-routed to
an address within the sandbox. Bounds checking would be
required if it is necessary to abort execution.
209Klinkoﬀ et al. designed a sandboxing mechanism for pro-
tecting managed code and the .NET runtime from unman-
aged code [13]. Although in a diﬀerent context, their sys-
tem addresses similar security problems as Robusta does.
Their system puts unmanaged code into a separate process
and seems to suﬀer from high performance overhead due to
inter-process communication.
In addition, system calls in
unmanaged code are intercepted and regulated by a kernel
add-on. By contrast, Robusta is a more-eﬃcient security
mechanism thanks to SFI and it is a pure user-space mod-
ule.
An alternative approach to achieving safety in Java-native
interoperation requires native code to be compiled from a
type-safe low-level language, such as Cyclone [12]. The com-
piler can produce binaries in the form of Proof-Carrying
Code [22] or Typed Assembly Languages [21], whose safety
can be independently veriﬁed at the code consumer’s site.
This approach can avoid some of the runtime overhead in
Robusta and is proﬁtable for performance-critical native code.
On the ﬂip side, rewriting legacy code in type-safe languages
requires a large amount of eﬀort and does not address the
issue of safe interoperation between Java and native code.
The JNI does not mandate any checking of native meth-
ods. Native methods are notoriously unsafe and is a rich
source of software errors. Recent studies have reported hun-
dreds of interface bugs in JNI programs [6, 31, 14]. A num-
ber of systems are designed to improve and ﬁnd misuses of
the JNI interface. They can be classiﬁed into three cat-
egories: (1) Jeannie [10] is a new interface language that
allows programmers to mix Java with C code and a Jean-
nie program is then compiled into JNI code by the Jeannie
compiler. (2) Several recent systems employ static analysis
to identify speciﬁc classes of errors in JNI code [6, 32, 14,
16]. (3) Jinn [15] generates dynamic checks at the language
boundary to ﬁnd interface errors. These systems have im-
proved the JNI’s overall safety by reducing errors in the JNI
code, but they are not designed to enforce a security policy.
SafeJNI [30] is in spirit closest to Robusta in that they both
protect Java from untrusted native code. However, Safe-
JNI is based on CCured [23], which performs source-code
rewriting for security, while Robusta is based on SFI.
The Joe-E system [20] by Mettler et al. designs a Java
subset that aims at the development of secure software sys-
tems. To reason about the security capabilities possessed
by a Joe-E class, its veriﬁer rejects many potentially un-
safe Java features. This includes the use of native methods,
which could escalate the capabilities of Joe-E classes. We be-
lieve the features provided by Robusta can enable systems
such as Joe-E to extend their security reach to native code.
It would be interesting to combine Joe-E and Robusta.
8. FUTURE WORK
We plan to explore what portions of native libraries in
Java’s system classes can be put under the control of Ro-
busta. There are 800,000 lines of C/C++ code in Sun’s JDK
1.6. We expect Robusta should be able to sandbox most of
JDK’s system libraries, as we have demonstrated for zip and
libec. However, it is possible that not all native libraries
for system classes are suitable for Robusta because of restric-
tions related to functionality or performance. Some system
native libraries may need direct access to the JVM state.
For instance, a security manager accesses JVM’s method-
call stack directly. Some system classes’ native libraries may
cross the boundary between the Java and native worlds so
often that putting them into a sandbox would have a sig-
niﬁcant performance penalty for the JVM; in these cases,
perhaps a combination of Robusta and static veriﬁcation is
beneﬁcial.
We are developing a napplet mechanism for Robusta, which
will allow the distribution of both a Java applet and its re-
quired native libraries in a single package (in the spirit of
a standard JAR ﬁle). Robusta’s sandbox will then prevent
any abusive native code in the napplet from harming the
host system.
We plan to explore techniques for stronger security poli-
cies within Robusta. Robusta already prevents code-injection
attacks in native libraries because all code is statically veri-
ﬁed before execution and no memory region is both writable
and executable (these invariants are also maintained during
dynamic loading). On the other hand, it does not prevent
exploits of vulnerabilities using code snippets already in the
code region (e.g., return-to-libc attacks or return-oriented
programming [27]). Control-Flow Integrity (CFI, [1]) can
foil a large number of attacks that are based on illegal control
transfers. Given an untrusted module, CFI predetermines
its control-ﬂow graph. The control-ﬂow graph serves as a
speciﬁcation of the legal control ﬂow allowed in the module
and CFI inserts runtime checks to enforce the speciﬁcation.
We are in the process of incorporating CFI into Robusta.
9. CONCLUSIONS
Native code has always been the dark corner of Java se-
curity. Although powerful, native code in Java applications
poses serious security threats. We have discussed the design
and implementation of Robusta, which protects the JVM
from native code while incurring modest runtime overhead.
Robusta is especially suitable for applications without in-
tense context switching between Java and native code. It
provides a migration path for moving the 800,000 lines of
native code outside of the JDK, and for enabling mobile
Java programs with native libraries.
Acknowledgments
We thank Mark Seaborn for explaining his scheme of a new
address space layout for supporting dynamic linking/load-
ing in NaCl. We thank anonymous referees of CCS ’10 for
detailed comments on an earlier version of this paper. This
research is supported in part by NSF grant CCF-0915157,
CCF-0915030, and a research grant from Google.
10. REFERENCES
[1] M. Abadi, M. Budiu, ´Ulfar Erlingsson, and J. Ligatti.
Control-ﬂow integrity. In 12th ACM conference on
Computer and communications security (CCS), pages
340–353, 2005.
[2] A. Daniele, B. Patrizio, and D. B. Luca. NX bit: A
hardware-enforced BOF protection. http:
//patrizioboschi.it/work/nx-bit/NX-bit.pdf.
[3] J. R. Douceur, J. Elson, J. Howell, and J. R. Lorch.
Leveraging legacy code to deploy desktop applications
on the web. In USENIX Symposium on Operating
Systems Design and Implementation (OSDI), pages
339–354, 2008.
[4] U. Erlingsson and F. B. Schneider. SASI enforcement
of security policies: a retrospective. In NSPW ’99:
210Proceedings of the 1999 workshop on New security
paradigms, pages 87–95, 2000.
[5] B. Ford and R. Cox. Vx32: Lightweight user-level
sandboxing on the x86. In USENIX Annual Technical
Conference, pages 293–306, 2008.
[6] M. Furr and J. S. Foster. Polymorphic type inference
for the JNI. In 15th European Symposium on
Programming (ESOP), pages 309–324, 2006.
[7] T. Garﬁnkel, B. Pfaﬀ, and M. Rosenblum. Ostia: A
delegating architecture for secure system call
interposition. In NDSS, 2004.
[8] I. Goldberg, D. Wagner, R. Thomas, and E. A.
Brewer. A secure environment for untrusted helper
applications: Conﬁning the wily hacker. In Proceedings
of the 6th conference on USENIX Security
Symposium, 1996.
[9] L. Gong. Java 2 Platform Security Architecture. Sun
Microsystems, 1997-2002.
[10] M. Hirzel and R. Grimm. Jeannie: Granting Java
Native Interface developers their wishes. In ACM
Conference on Object-Oriented Programming,
Systems, Languages, and Applications (OOPSLA),
pages 19–38, 2007.
[11] S. Ioannidis, S. M. Bellovin, and J. M. Smith.
Sub-operating systems: a new approach to application
security. In ACM SIGOPS European Workshop, pages
108–115, 2002.
[12] T. Jim, J. G. Morrisett, D. Grossman, M. W. Hicks,
J. Cheney, and Y. Wang. Cyclone: A safe dialect of C.
In Proceedings of the General Track: 2002 USENIX
Annual Technical Conference, pages 275–288.
USENIX Association, 2002.
[13] P. Klinkoﬀ, E. Kirda, C. Kruegel, and G. Vigna.
Extending .NET security to unmanaged code.
Internation Journal of Information Security,
6(6):417–428, 2007.
[14] G. Kondoh and T. Onodera. Finding bugs in Java
Native Interface programs. In ISSTA ’08: Proceedings
of the 2008 International Symposium on Software
Testing and Analysis, pages 109–118, New York, NY,
USA, 2008. ACM.
[15] B. Lee, M. Hirzel, R. Grimm, B. Wiedermann, and
K. S. McKinley. Jinn: Synthesizing a dynamic bug
detector for foreign language interfaces. In ACM
Conference on Programming Language Design and
Implementation (PLDI), pages 36–49, 2010.
[16] S. Li and G. Tan. Finding bugs in exceptional
situations of JNI programs. In 16th ACM conference
on Computer and communications security (CCS),
pages 442–452, 2009.
[17] S. Liang. Java Native Interface: Programmer’s Guide
and Reference. Addison-Wesley Longman Publishing
Co., Inc., 1999.
[18] S. McCamant and G. Morrisett. Evaluating SFI for a
CISC architecture. In 15th Usenix Security
Symposium, 2006.
[19] G. McGraw and E. W. Felten. Securing Java: Getting
Down to Business with Mobile Code. John Wiley &
Sons, 1999.
[20] A. Mettler, D. Wagner, and T. Close. Joe-E: A
security-oriented subset of Java. In Network and
Distributed Systems Symposium (NDSS), 2010.
[21] G. Morrisett, D. Walker, K. Crary, and N. Glew. From
System F to typed assembly language. In 25th ACM
Symposium on Principles of Programming Languages
(POPL), pages 85–97, New York, 1998. ACM Press.
[22] G. C. Necula. Proof-carrying code. In 24th ACM
Symposium on Principles of Programming Languages
(POPL), pages 106–119, New York, 1997. ACM Press.
[23] G. C. Necula, S. McPeak, and W. Weimer. CCured:
type-safe retroﬁtting of legacy code. In 29th ACM
Symposium on Principles of Programming Languages
(POPL), pages 128–139, 2002.
[24] N. Provos. Improving host security with system call
policies. In Proceedings of the 12th conference on
USENIX Security Symposium, pages 257–272, 2003.
[25] M. Seaborn. Segment layout. Sent to the Native Client
mailing list, Dec 2008.
[26] D. Sehr, R. Muth, C. Biﬄe, V. Khimenko, E. Pasko,
K. Schimpf, B. Yee, and B. Chen. Adapting software
fault isolation to contemporary CPU architectures. In
19th Usenix Security Symposium, 2010. to appear.
[27] H. Shacham. The geometry of innocent ﬂesh on the
bone: return-into-libc without function calls (on the
x86). In 14th ACM conference on Computer and
communications security (CCS), pages 552–561, 2007.
[28] C. Small. A tool for constructing safe extensible C++
systems. In COOTS’97: Proceedings of the 3rd
conference on USENIX Conference on Object-Oriented
Technologies (COOTS), pages 174–184, 1997.
[29] M. M. Swift, M. Annamalai, B. N. Bershad, and
H. M. Levy. Recovering device drivers. In USENIX
Symposium on Operating Systems Design and
Implementation (OSDI), pages 1–16, 2004.
[30] G. Tan, A. W. Appel, S. Chakradhar,
A. Raghunathan, S. Ravi, and D. Wang. Safe Java
Native Interface. In Proceedings of IEEE International
Symposium on Secure Software Engineering, pages
97–106, 2006.
[31] G. Tan and J. Croft. An empirical security study of
the native code in the JDK. In 17th Usenix Security
Symposium, pages 365–377, 2008.
[32] G. Tan and G. Morrisett. ILEA: Inter-language
analysis across Java and C. In ACM Conference on
Object-Oriented Programming, Systems, Languages,
and Applications (OOPSLA), pages 39–56, 2007.
[33] R. Wahbe, S. Lucco, T. Anderson, and S. Graham.
Eﬃcient software-based fault isolation. In Proc. 14th
ACM Symposium on Operating System Principles,
pages 203–216, New York, 1993. ACM Press.
[34] B. Yee, D. Sehr, G. Dardyk, B. Chen, R. Muth,
T. Ormandy, S. Okasaka, N. Narula, and N. Fullagar.
Native client: A sandbox for portable, untrusted x86
native code. In IEEE Symposium on Security and
Privacy (S&P), pages 79–93, May 2009.
211