Bhatkar et al.’03 [6]
Kc et al.’03 [37]
Barrantes et al.’05 [5]
Bhatkar et al.’05 [8]
Kil et al.’06 [38]
Bhatkar et al.’08 [7]
De Sutter et al.’09 [22]
Williams et al.’09 [67]
Novark et al.’10 [46]
Jackson et al.’11 [35]
Wei et al.’11 [66]
Pappas et al.’12 [47]
Hiser et al.’12 [29]
Giuffrida et al.’12 [27]
Wartell et al.’12 [64]
Collberg et al.’12 [15]
Shioji et al.’12 [59]
Jackson et al.’13 [34]
Homescu et al.’13a [31]
Coppens et al.’13 [18]
Gupta et al.’13 [28]
Davi et al.’13 [21]
Homescu et al.’13b [30]
Inj.,
Buf.
Corr.,
Many
Stack
Ovf.
Mem.
Code Inj.
Buffer Ovf
Many
Code Inj.
Code Inj.
Many
Mem. Corr.
Mem. Corr.
Code
Matching
Code
Code Reuse
Mem. Alloc.,
Heap
Buf.
Ovf.
Many
Heap
JIT Spray
Code Reuse
Code Reuse
Many
Code Reuse
Tampering
Code Reuse
Code Reuse
Code Reuse
Code
Matching
Code Reuse
Code Reuse
JIT
Code Reuse
Spray,
Spray,
y
p
o
r
t
n
E
c
ﬁ
i
c
e
p
S
l
a
c
i
g
o
L
k
c
a
t
t
A
(cid:2)
(cid:2) (cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2) (cid:2) (cid:2) (cid:2)
(cid:2)
(cid:2)
(cid:2) (cid:2) (cid:2)
(cid:2)
(cid:2)
(cid:2) (cid:2)
(cid:2)
(cid:2)
(cid:2) (cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2) (cid:2) (cid:2) (cid:2)
(cid:2) (cid:2) (cid:2) (cid:2)
(cid:2)
(cid:2) (cid:2) (cid:2) (cid:2)
(cid:2) (cid:2) (cid:2) (cid:2)
(cid:2) (cid:2)
(cid:2)
(cid:2)
(cid:2) (cid:2) (cid:2)
(cid:2) (cid:2) (cid:2)
(cid:2) (cid:2)
(cid:2)
(cid:2) (cid:2) (cid:2) (cid:2)
(cid:2)
Since each of the ways to evaluate security impacts are
imperfect, authors often use both abstract and concrete security
evaluations. Table II shows how each implementation evaluates
the impact of their approach. One commonality among all
evaluations is the assumption that the effects of diversiﬁcation
remain hidden from attackers. However, in Section VI-C we
highlight vulnerabilities that enable implementation disclosure
and thereby undermine this assumption.
B. Performance Impact
The chance that a security technique sees adoption is
arguably inversely proportional to its performance overhead.
So far, the only ones that have been widely adopted (ASLR,
DEP, and stack canaries) are those with negligible performance
impact. For another technique to be adopted at large, its
performance impact must be below 5-10% according to
Szekeres et al. [61].
Different studies of diversity measure performance cost
differently. The most popular benchmark for this is the SPEC
CPU benchmark suite, usually the most recent version available
(at present, that is SPEC CPU 2006). In cases where SPEC CPU
is not available or appropriate as a benchmark, implementations
measure the CPU impact on other workloads, such as real-world
applications (Apache, Linux command line utilities, the Wine
test suite) or other CPU benchmarks. As the implementations of
most of the techniques we discussed are not publically available,
we rely on self-reported performance numbers from their
286
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:59:27 UTC from IEEE Xplore.  Restrictions apply. 
Study
Randell’75 [52]
Avizienis & Chen’77 [11]
Cohen’93 [13]
Forrest et al.’97 [24]
PaX Team’01 [48]
(ASLR results by Payer [49])
Chew & Song’02 [12]
Bhatkar et al.’03 [6]
Kc et al.’03 [37]
Barrantes et al.’05 [5]
Bhatkar et al.’05 [8]
Kil et al.’06 [38]
Bhatkar et al.’08 [7]
De Sutter et al.’09 [22]
Williams et al.’09 [67]
Novark et al.’10 [46]
Jackson et al.’11 [35]
Wei et al.’11 [66]
Pappas et al.’12 [47]
Hiser et al.’12 [29]
Giuffrida et al.’12 [27]
Wartell et al.’12 [64]
Collberg et al.’12 [15]
Shioji et al.’12 [59]
Jackson et al.’13 [34]
Homescu et al.’13a [31]
Coppens et al.’13 [18]
Gupta et al.’13 [28]
Davi et al.’13 [21]
Homescu et al.’13b [30]
Stage
Impl.
Impl.
Comp.
Comp.
Comp.,
Load
Comp.,
Load
Inst.
Inst.
Load,
Exec.
Comp.
Link
Comp.
Link
Load,
Exec.
Exec.
Comp.
Exec.
Inst.
Inst.,
Exec.
Comp.,
Exec.
Inst.,
Load
Comp.
Load.,
Exec.
Comp.
Comp.
Upd.
Inst.
Load
Exec.
TABLE III: Costs of transformations.
Benchmark
Performance Overhead
SPEC CPU 2006 32-bit
SPEC CPU 2006 64-bit
9%
2%
N/A
Code Increase Memory Increase
N/A
N/A
N/A
N/A
N/A
N/A
Linux utils
ftp
sendmail
ﬁbonacci
Apache—SPEC web 99
0%-21%
33%
1974%
28781%
62%
Linux utils, Apache
SPEC CPU 2000
LMBench
Apache
Linux utils
SPEC CPU 2006
SPEC CPU 2000—ISR
SPEC CPU 2000—CSD
SPEC int 2006
Firefox
V8
Wine tests
SPEC CPU 2006
11%
0%
3.57%
0%
15%
5%-10%
17%
54%
20%
5%
5%
0%
N/A
13%-16%
SPEC CPU 2006
devtools
SPEC CPU 2000
Linux coreutils
SPEC CPU 2000
bzip2
4.8%
1.6%
4.6%
0.3%
5%-10%
265%-2510%
N/A
N/A
N/A
N/A
N/A
N/A
N/A
N/A
N/A
N/A
N/A
N/A
14MB-345MB
14MB-264MB
73%
37%
SPEC CPU 2006
Apache
SPEC CPU 2006
SPEC CPU 2000
5%-10%
11.3%
1%
5%-30%
SPEC CPU 2006
V8
HotSpot
1.2%-5%
250%
15%
20%-50%
15%-20%
1.76%
N/A
N/A
N/A
N/A
N/A
N/A
5%-30%
5%
Language
(Language Agnostic)
C/C++
C/C++
C/C++
C/C++
C/C++
C/C++
C/C++
C/C++
C/C++
C/C++
C/C++
JavaScript
C/C++
C/C++
C/C++
C/C++
C/C++
C/C++
C/C++
C/C++
C/C++
C/C++
C/C++
JavaScript
Java
authors. Along with the average impact of each implementation
on program running time, we also show the effects on memory
usage and on-disk binary ﬁle size (when reported). Table III
shows the time and space cost of each technique.
For pre-distribution approaches, the overheads generally
range from 1 to 11%. For post-distribution methods, the range
of reported overheads is greater and typically range from 1% to
250% indicating that implementations of these approaches must
take greater care to keep overheads in check. (Note that Pappas
et al. [47] use an unorthodox benchmarking approach and that
we consider the approaches by Kc et al. [37] and Shioji [59]
to be outliers.) While the benchmarking methodology varies
considerably, we conclude that both pre and post-distribution
approaches can result in low runtime overheads [31], [21].
We also see greater variability in the binary size overheads
among post-distribution approaches when compared to pre-
distribution approaches; in both cases, the overheads are small
to moderate. Some post-distribution approaches also increase
runtime memory overheads—between 5% and 37%.
Note that Table III excludes ahead-of-time costs associated
with diversiﬁcation. For pre-distribution methods, the software
developer or distributor may pay the diversiﬁcation costs. For
post-distribution methods, end users contribute the computing
resources to diversify programs during installation, loading or
running. It remains to be seen if on-device diversiﬁcation is
practical on resource and power-constrained computers such
as mobile devices and embedded systems.
VI. OPEN AREAS AND UNSOLVED CHALLENGES
While the security and performance implications of diversi-
ﬁed software are well understood, several practical concerns
remain to be addressed. In addition, existing research has not
fully explored the protective qualities of diversiﬁed software
nor has it reached consensus on how to evaluate the efﬁcacy
of software diversity with respect to the attacker workload. For
example, we think that it can provide probabilistic protection
against the long standing problem of covert channels.
A. Hybrid Approaches
A schism exists between proponents of compilation-based
diversiﬁcation and diversiﬁcation via binary rewriting. It is
frequently argued that binary rewriting is preferable to compiler-
based methods because the latter require source code access,
custom compilers, and require changes to current program
distribution mechanisms [67], [64], [29], [47]. However, binary
rewriting approaches are inherently client-side solutions and
therefore cannot defend against
tampering or discourage
piracy via watermarking [40]. Moreover, a decompiler that
287
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:59:27 UTC from IEEE Xplore.  Restrictions apply. 
produces LLVM compiler intermediate representation [3] can
be combined with a compiler-based diversiﬁcation engine. This
results in a hybrid approach where the same randomizing
transformations can be applied to source code as well as legacy
binaries.
Another hybrid-approach of interest is centered around
compiler-rewriter cooperation. Static binary rewriting of
stripped binaries suffers from incomplete information. The
code-data separation problem could be entirely avoided if the
compiler (or linker) contains a map of all indirect branch
targets; this information is readily available at compile and
link-time. Enabling reliable disassembly not only simpliﬁes
the implementation of binary rewriters and improves their
throughput, but the resulting binaries also run faster without
the need to detect and correct disassembly errors at runtime.