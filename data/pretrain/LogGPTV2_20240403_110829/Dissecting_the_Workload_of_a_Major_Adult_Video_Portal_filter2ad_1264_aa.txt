title:Dissecting the Workload of a Major Adult Video Portal
author:Andreas Grammenos and
Aravindh Raman and
Timm B&quot;ottger and
Zafar Gilani and
Gareth Tyson
Dissecting the Workload of a Major
Adult Video Portal
Andreas Grammenos1,3(B), Aravindh Raman2,3, Timm B¨ottger3,
Zafar Gilani3, and Gareth Tyson3
1 University of Cambridge, Cambridge, UK
PI:EMAIL
2 King’s College London, London, UK
3 Queen Mary University of London, London, UK
Abstract. Adult content constitutes a major source of Internet traﬃc.
As with many other platforms, these sites are incentivized to engage
users and maintain them on the site. This engagement (e.g.,
through
recommendations) shapes the journeys taken through such sites. Using
data from a large content delivery network, we explore session journeys
within an adult website. We take two perspectives. We ﬁrst inspect the
corpus available on these platforms. Following this, we investigate the
session access patterns. We make a number of observations that could
be exploited for optimizing delivery, e.g.,
that users often skip within
video streams.
1 Introduction
The Internet has evolved from a largely web-oriented infrastructure to a mas-
sively distributed content delivery system [10]. Video content has become partic-
ularly popular, and we have therefore seen a range of studies investigating the
usage and access patterns of major portals, e.g., user-generated content (UGC)
[5,16], video on demand (VoD) [23], Internet TV (IPTV) [6] and catch-up TV
[1,13]. A particularly prevalent form of online video is that of adult content,
i.e., pornographic material [3]. In the last ﬁve years there has been a surge of
research activity in this space, attempting to characterize the content corpus of
sites [18,20], the workload of sites [3,24] and the use of adult social networks [19].
Despite this, we still lack the breadth and depth of understanding common to
many other aspects of online video delivery.
Due to the paucity of data, there is a particular lack of understanding related
to the unique workload that such websites place on the infrastructure of a Con-
tent Delivery Network (CDN). Particularly, there has been limited work explor-
ing the per-session content request patterns on these portals. Thus, in this paper,
we present a large-scale analysis of access patterns for a major adult website, with
a focus on understanding how individual viewer decisions (or “journeys”) impact
the workload observed.
To achieve this, we bring together two key datasets. We have gathered data
from a large CDN, covering 1 h of access logs for resources hosted served by the
c(cid:2) Springer Nature Switzerland AG 2020
A. Sperotto et al. (Eds.): PAM 2020, LNCS 12048, pp. 267–279, 2020.
https://doi.org/10.1007/978-3-030-44081-7_16
268
A. Grammenos et al.
site. This covers 20.08M access records, 62K users and 3.28 TB of exchanged data.
Although this oﬀers ﬁne-grained insight into content request patterns, alone is it
insuﬃcient. This is because modern adult websites also consist of a large body
of surrounding “meta” interactions, including categories and ranking of content.
Hence, we also gather metadata about each access by scraping the web content
itself, e.g., content category and upload date.
In this paper, we look into three aspects of operation. First, we inspect the
corpus and workload served by the platform (Sect. 4). Despite its prominence as
a video portal, the access logs are dominated by image content, primarily serv-
ing thumbnail content. That said, we ﬁnd that the majority of bytes served is
actually for video content, primarily due to it voluminous nature. Video content
tends to be relatively short, with subtle variations observed across the cate-
gories. Popularity across these resources is highly skewed though: the top 10%
of videos contribute 73.7% of all accesses. This leads us to explore the speciﬁcs
of per-session access patterns on the site (Sect. 5). We see that, for instance, the
majority of sessions limit accesses to one or two categories. This leads us to
inspect where accesses come from. The majority of views arrive from the main
video page, but we also observe a number of views from the homepage and search
function. Finally, we discuss potential implications from our work (Sect. 6). We
ﬁnd that this genre of material is highly cacheable, and brieﬂy test the eﬃcacy of
city-wide edge cache deployment. We conclude by proposing simple innovations
that could streamline delivery (Sect. 7).
2 Background and Related Work
Pornography is amongst the most searched for content on the web [14,22].
Although this topic remains a taboo in some research ﬁelds, there has been
an expanding body of research into the video platforms that drive its delivery.
We have seen recent work inspecting the content corpus of popular adult web-
sites [18,20] and their workloads [3,12,24,25] as well as various studies that have
attempted to estimate the load that they create on the wider Internet. For exam-
ple, [14] estimates that Porn 2.0 sites such as xHamster and YouPorn can gain
up to 16 million views per month.
There have also been a number of related studies that have explored the topic
of online pornography more generally, e.g., privacy [21]; automated recognition
and classiﬁcation [9,11]; interest recommendations [17]; and security issues [22].
This paper presents one of the ﬁrst large-scale studies of an online adult mul-
timedia delivery service. That said, there are a multitude of studies into more
traditional video streaming systems that already provide some insight. These
include catch-up TV [1,13], user generated content [5,16,26], Video-on-Demand
[23] and IPTV [6,7]. These insights have been used to drive a range of model-
ing and systems research activities, e.g., building content popularity models [8],
optimized caching techniques [1] and improved delivery schemes [4]. The paucity
of data related to adult video access, however, makes it diﬃcult to appreciate the
applicability of these technologies to this particular ﬁeld. We write this paper to
shed insight into the session-level speciﬁcs of adult content access patterns.
Dissecting the Workload of a Major Adult Video Portal
269
3 Methodology and Data
The work in this paper relies on two key datasets. First, we utilize a dataset pro-
vided by a CDN, which captures access logs to an anonymous major adult video
content provider. Second, we compliment this with web metadata surrounding
each video in the access logs.
3.1 CDN Data
We ﬁrst describe the basic features of the CDN data, collected in 2019, as well
as the necessary post-processing required to extract sessions.
Data Description. We have been given access logs for web resources hosted by
a major adult video website. The data has been collected from the vantage point
of a single US-based data center operated by a major Content Delivery Network
(CDN). The dataset covers 1 h, and includes 20.08M access entries. Each log
entry maps to a single resource request, consisting of:
– Timestamp: The time when the item was requested.
– Client ID: This is a preﬁx preserving anonymized IP Address (so that we can
approximate client location).
– Resource: The web resource requested.
– User Agent: This is the user-agent identiﬁer included within the HTTP
request header. This allows us to diﬀerentiate mobile from desktop users.
– HTTP Referrer: This is the Referrer from the HTTP request header; it pro-
vides the URL that the client was redirected from.
– City ID: Using Maxmind, the anonymized IP addresses are mapped to their
geolocation. Only requests for which the coordinates have an estimated accu-
racy of less than 20KM are tagged. This covers 75.91% of all requests. Each
city is then associated with an anonymized numerical City ID.
Identifying Sessions. For the CDN traces, we take a simple but eﬀective way
of mapping the requests to sessions. For each log entry, we generate a session
identiﬁer by computing the following hash: SHA256(IP Address, Device, Browser).
We then group requests into individual sessions using their identiﬁers. Overall,
the data covers 62K unique user sessions. To remove incomplete sessions, we
extract all sessions that contain requests within the ﬁrst or last 5 min of the trace,
and then ﬁlter them from the rest of the logs. This removes 15% of requests. Note
that we also performed our analysis on the unﬁltered data and only found slight
diﬀerences.
3.2 Web Scrape Data
The CDN logs oﬀer ﬁne-grained insight into individual access patterns, but no
metadata related to the content being accessed. Hence, we scrape metadata from
the website front end for each video contained within the CDN dataset. The web
scrape data, for each video, includes the category, the global view counter, the
number of likes/dislikes and any associated hashtags. In total we gathered this
metadata for 4.9 million videos, covering 91.1% of all videos in the CDN traces.
270
A. Grammenos et al.
3.3 Ethical Considerations and Limitations
Limitations. We emphasize that the duration of our trace data limits our
ability to make generalizable statements, particularly pertaining to longitudinal
trends. Critically, this creates a clear bias towards shorter sessions that do not
exceed an hour (we ﬁlter out longer sessions that do not entirely fall within the
measurement period). Another limitation is that the data only covers a single
portal from the vantage point of a single data center. Hence, we cannot quantify
to what extent this applies to alternative deployments. We therefore temper our
later analysis with these observations; despite this, we argue that the data oﬀers
a powerful ﬁrst insight into traﬃc patterns within this domain.
Ethical Consideration. We took a number of steps to address ethical con-
cerns. Before receiving the logs, they were ﬁrst fully anonymized by the CDN,
and there was no way to map logs back to speciﬁc users. Hence, all user identi-
ﬁers were removed prior to access, including cookies and source IP addresses. We
further anonymized sensitive data (such as content category tags) from the web
data, instead generating a set of neutral tags. Although this restricted “semantic”
analysis of the content, it reduced exposure to sensitive insight. Pre-processing
was done by one author, who did not perform the subsequent analysis. Further-
more, all data was stored remotely in a secure silo with restricted access to just
two authors. We obtained IRB approval.
4 Characterization of Corpus and Workload
We start by performing a basic characterization of the corpus served, as well as
the overall site workloads observed at the CDN.
Resource Type. Typical sites consist of a wide range of media. To inspect
this, we ﬁrst look at the mix of content types encountered within the CDN logs.
Figure 1a presents the fraction of requests to each resource type; this shows the