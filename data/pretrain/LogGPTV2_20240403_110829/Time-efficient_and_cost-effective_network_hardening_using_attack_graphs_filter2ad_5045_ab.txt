in our approach to network hardening.
V. COST MODEL
Disabling a set of initial conditions in order to prevent
attacks on given targets may result in undesired effects,
such as denial of service to legitimate users. These effects
are greatly ampliﬁed when initial conditions cannot be
individually disabled, but rather require actions that disable
a larger number of conditions. In the following, we deﬁne
a network hardening strategy as a set of atomic actions that
can be taken to harden a network.
1Initial conditions that the administrators cannot control are not consid-
ered for the purpose of network hardening. In the example of Figure 1,
the condition user(0), corresponding to user privileges on the attacker’s
machine, is ignored.
ftp(0,1) 
ftp_rhosts(0,1) 
ftp(1,2) 
trust(1,0) 
sshd(0,1) 
ftp(0,2) 
ftp_rhosts(1,2) 
rsh(0,1) 
sshd_bof(0,1) 
ftp_rhosts(0,2) 
trust(2,1) 
user(1) 
trust(2,0) 
rsh(1,2) 
rsh(0,2) 
user(2) 
local_bof(2) 
root(2) 
Figure 2. A tree-style attack graph equivalent to the graph of Figure 1
w.r.t. target condition root(2)
For instance, an allowable hardening action may consist in
stopping ftp service on a given host. Thus, each action may
have additional effects besides disabling a desired condition.
Such effects must be taken into account when computing
minimum-cost solutions. Previous work simply assumes that
initial conditions can be individually disabled. We take a
more general approach and therefore drop this assumption.
For instance, in the attack graph of Figure 1, disabling
f tp(1, 2) might not be possible without also disabling
f tp(0, 2).
Deﬁnition 3 (Allowable hardening action): Given an at-
tack graph G = (E ∪ C, Rr ∪ Ri), an allowable hardening
action (or simply hardening action) A is any subset of the
set Ci of initial conditions such that all the conditions in A
can be jointly disabled in a single step, and no other initial
condition c ∈ Ci \ A is disabled when conditions in A are
disabled.
A hardening action A is said to be minimal if and only if
∗ ⊂ A s.t. A
∗ is an allowable hardening action. We use
(cid:2)A
A to denote the set of all possible hardening actions.
Figure 3 depicts the same attack graph of Figure 2,
but
it explicitly shows the allowable hardening actions,
represented as rounded rectangles. Dashed edges indicate
which conditions are disabled by each action. Intuitively,
a network hardening action is an atomic step that network
administrators can take to harden the network (e.g., closing
an ftp port). When an action A is taken, all and only
Authorized licensed use limited to: Tsinghua University. Downloaded on March 18,2021 at 14:49:08 UTC from IEEE Xplore.  Restrictions apply. 
stop_ftp(2) 
block_host(0) 
stop_sshd(1) 
ftp(0,1) 
ftp_rhosts(0,1) 
ftp(1,2) 
trust(1,0) 
sshd(0,1) 
ftp(0,2) 
ftp_rhosts(1,2) 
rsh(0,1) 
sshd_bof(0,1) 
ftp_rhosts(0,2) 
trust(2,1) 
user(1) 
trust(2,0) 
rsh(1,2) 
rsh(0,2) 
user(2) 
local_bof(2) 
root(2) 
Figure 3.
graph of Figure 2
Possible hardening actions (orange rectangles) for the attack
the conditions in A are removed2. In the example of Fig-
ure 3, A = {stop f tp(2), block host(0), stop sshd(1)},
stop f tp(2) = {f tp(0, 2), f tp(1, 2)}, block host(0) =
{f tp(0, 1), sshd(0, 1), f tp(0, 2)}, and stop sshd(1) =
{sshd(0, 1)}. In this example, the condition f tp(1, 2) cannot
be individually disabled, and can only be disabled by taking
action stop f tp(2), which also disables f tp(0, 2)3.
Therefore, when choosing a set of initial conditions to
be removed in order to prevent attacks on given targets, we
should take into account all the implications of removing
those conditions. Removing speciﬁc initial conditions may
require to take actions that disable additional conditions,
including conditions not explicitly modeled in the attack
graph, such as conditions that are not part of any attack
path. To address this problem, we formalize the notion
of hardening strategy in terms of allowable actions, and
deﬁne a cost model that takes into account the impact of
hardening actions. This novel approach improves the state
of the art, while preserving the key idea that solutions are
truly enforceable only if they operate on initial conditions.
First, we drop the assumption that initial conditions can
2In practice, an action may also remove conditions not explicitly modeled
in the attack graph, and this should be taken into account when assigning
a cost to each action.
3More precisely, all conditions of the form f tp(x, 2), where x is any
host, are disabled by action stop f tp(2).
be individually disabled. In our framework, this simplifying
assumption corresponds to the special case where, for each
initial condition, there exists an allowable action that dis-
ables that condition only, i.e., (∀c ∈ Ci)(∃A ∈ A)A = {c}.
We then deﬁne the notion of network hardening strategy in
terms of allowable actions.
Deﬁnition 4 (Network hardening strategy): Given an at-
tack graph G = (E ∪ C, Rr ∪ Ri), a set A of allowable
actions, and a set of target conditions Ct = {c1, . . . , cn}, a
network hardening strategy (or simply hardening strategy)
S is a set of network hardening actions {A1, . . . , Am} s.t.
conditions c1, . . . , cn cannot be reached after all the actions
in S have been taken. We use S to denote the set of all
possible strategies, and C(S) to denote the set of all the
A∈S A.
conditions disabled under strategy S, i.e., C(S) =
Intuitively, a hardening strategy is a set of allowable
actions breaking all attack paths leading to the target condi-
tions.
(cid:2)
We now introduce a cost model, enabling a more accurate
Deﬁnition 5 (Hardening cost function): A
analysis of available hardening options.
hardening
cost function is any function cost : S → R+ that satisﬁes
the following axioms:
cost(∅) = 0
(1)
(∀S1, S2 ∈ S) (C(S1) ⊆ C(S2) ⇒ cost(S1) ≤ cost(S2)) (2)
(∀S1, S2 ∈ S) (cost(S1 ∪ S2) ≤ cost(S1) + cost(S2))
(3)
In other words, the above deﬁnition requires that (i) the
cost of the empty strategy – the one not removing any
condition – is 0; (ii) if the set of conditions disabled under S1
is a subset of the conditions disabled under S2, then the cost
of S1 is less than or equal to the cost of S2 (monotonicity);
and (iii) the cost of the combined strategy S1 ∪ S2 is less
than or equal to the sum of the individual costs of S1 and
S2 (triangular inequality).
Combining the three axioms above, we can conclude that
(∀S1, S2 ∈ S) (0 ≤ max(cost(S1), cost(S2)) ≤ (cost(S1 ∪
S2) ≤ cost(S1) + cost(S2)).
A cost function is said to be additive if and only if the
following additional axiom is satisﬁed.
(∀S1, S2 ∈ S)
(S1 ∩ S2 = ∅ ⇐⇒
(4)
cost(S1) + cost(S2) = cost(S1 ∪ S2))
Many different cost functions may be deﬁned. The fol-
lowing is a very simple cost function:
costa(S) = |C(S)|
(5)
The above cost function simply counts the initial condi-
tions that are removed under a network hardening strategy
S, and clearly satisﬁes the three axioms of Deﬁnition 5. If
actions in A are pairwise disjoint, then costa is also additive.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 18,2021 at 14:49:08 UTC from IEEE Xplore.  Restrictions apply. 
VI. NETWORK HARDENING
In this section, we ﬁrst examine in more details the limita-
tions of the approach proposed in [2], and then introduce our
approximation algorithm to ﬁnd reasonably good hardening
strategies in a time efﬁcient manner.
A. Limitations of Previous Approach
The algorithm presented in [2] starts from a set Ct of
target conditions and traverses the attack graph backwards,
making logical inferences. At the end of the graph traversal,
a logic proposition of the initial conditions is derived as
the necessary and sufﬁcient condition for hardening the
network with respect to Ct. This proposition then needs to be
converted to its disjunctive normal form (DNF), with each
disjunction in the DNF representing a particular sufﬁcient
option to harden the network. Although the logic proposition
can be derived efﬁciently, converting it to its DNF may incur
into an exponential explosion.
to the one described in [2] – in that
Algorithm BackwardSearch (Algorithm 1) is function-
ally equivalent
it
generates all possible hardening solutions4 – under the sim-
plifying hypothesis that initial conditions can be individually
disabled, i.e., (∀ci ∈ Ci)(∃A ∈ A)(A = {ci}). However,
our rewriting of the algorithm has several advantages over
its original version. First, it is more general, as it does not as-
sume that initial conditions can be individually disabled, and
incorporates the notions of allowable action and hardening
strategy deﬁned in Section V. Second, it directly computes
a set of possible hardening strategies, rather then a logic
proposition that requires additional processing in order to
provide actionable intelligence. Last, in a time-constrained
or real-time scenario where one may be interested in the ﬁrst
available hardening solution, the rewritten algorithm can be
easily modiﬁed to terminate as soon as a solution is found.
To this aim, it is sufﬁcient to change the condition of the
main while loop (Line 3) to ((cid:2)S ∈ S)(S ⊆ Ci). Such
variant of the algorithm will generate hardening strategies
that disable initial conditions closer to the target conditions.
However, when used to ﬁnd the minimum-cost hardening
solution, Algorithm BackwardSearch still faces the com-
binatorial explosion described below. Instead, the algorithm
introduced in Section VI-B provides a balance between the
optimality of the solution and the time to compute it.
Under the simplifying hypothesis that initial conditions
can be individually disabled – i.e., (∀ci ∈ Ci)(∃A ∈
A)(A = {ci}) – and allowable actions are pairwise disjoint
– i.e., (∀Ai, Aj ∈ A)(Ai ∩ Aj = ∅) – it can be proved
that, in the worst case, the number of possible hardening
strategies is
|S| = |Ct| · n
(cid:2) d
2
k=1 nk
(6)
d
and the size of each solution is n
2 , where d is the maximum
distance (number of edges) between initial and target con-
ditions5, and n is the maximum in-degree of nodes in the
attack graph. Worst case complexity is then O(nnd
). The
proof is omitted for reasons of space.
The authors of [2] rely on the assumption that the attack
graph of a small and well-protected network is usually small
and sparse (the in-degree of each node is small), thus, even
if the complexity is exponential, running time should be
acceptable in practice. However, the result above shows that
computing an optimal solution may be impractical even for
relatively small attack graphs. For instance, consider the at-
tack graph of Figure 4, where n = 2, Ct = {c21}, and d = 4.
According to Equation 6, there are 64 possible hardening
strategies in the worst case, each of size 4. The strategy
that disables the set of initial conditions {c1, c3, c9, c11} is
one of such possible strategies. When d = 6, the number of
initial condition is 64, and the number of possible strategies
becomes 16,384. For d = 8, |Ci| = 256 and the number of
possible strategies is over a billion.
B. Approximation Algorithm
To address the limitations of the previous network harden-
ing algorithm, we now propose an approximation algorithm
that computes reasonably good solutions in a time efﬁcient
manner. We will show that, under certain conditions, the
solutions computed by the proposed algorithm have a cost
that is bound to be within a constant factor of the optimal
cost.
Algorithm F orwardSearch (Algorithm 2) traverses the
attack graph forward, starting from initial conditions. A
key advantage of traversing the attack graph forward is
that intermediate solutions are indeed network hardening
strategies with respect to intermediate conditions. In fact,
in a single pass, Algorithm F orwardSearch can compute
hardening strategies with respect to any condition in C.
To limit
the exponential explosion of the search space,
intermediate solutions can be pruned – based on some
pruning strategy – whereas pruning is not possible for the
algorithm that traverses the graph backwards. In fact, in
this case, intermediate solutions may contain exploits and
intermediate conditions, and we cannot say anything about
their cost until all the exploits and intermediate conditions
have been replaced with sets of initial conditions.
In this section, for ease of presentation, we consider
hardening problems with a single target condition. The
generalization to the case where multiple target conditions
need to be hardened at the same time is straightforward and
is discussed below.
Given a set Ct of target conditions, we add a dummy
exploit ei for each condition ci ∈ Ct, such that ei has ci as
its only precondition, as shown in Figure 5. Then, we add a
4For ease of presentation, the pseudocode of Algorithm 1 does not show
how cycles are broken. This is done as in the original algorithm.
5Note that d is always an even number.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 18,2021 at 14:49:08 UTC from IEEE Xplore.  Restrictions apply. 
Algorithm 1 BackwardSearch(G, Ct)
Input: Attack graph G = (E ∪ C, Rr ∪ Ri), and set of target conditions Ct.
Output: Optimal hardening strategy.
1: // Initialize the set of all solutions and iterate until solutions contain initial conditions only
2: S ← {Ct}
3: while (∃S ∈ S)(S (cid:15)⊆ Ci) do
for all c ∈ S s.t. c /∈ Ci do
S ← S \ {c} ∪ {e ∈ E | (e, c) ∈ Ri}
end for
// Replace each non-initial condition with the set of exploits that imply it
for all S ∈ S do
4:
5:
6:
7:
8:
9:
10:
11:
12:
end for
13:
14: end while
15: // Replace initial conditions with allowable actions and generate all possible combinations
16: for all S = {c1, . . . , cn} ∈ S do
end for
// Replace exploits with required conditions and generate all possible combinations
for all S = {e1, . . . , em} ∈ S do
S ← S \ {S} ∪ {{c1, . . . , cm} | (∀i ∈ [1, m]) (ci, ei) ∈ Rr}
S ← S \ {S} ∪ {{A1, . . . , An} | (∀i ∈ [1, n]) Ai ∈ A ∧ ci ∈ Ai}
17:
18: end for
19: return argmaxS∈S cost(S)
c1
c2
c3
c4
c5
c6
c7
c8
c9
c10
c11
c12
c13
c14
c15
c16
e1
e2
e3
e4
e5
e6
e7
e8
c17
c18
c19
c20
e9
e10
c21
Figure 4. Example of attack graph with n = 2 and d = 4
dummy target condition ct, such that all the dummy exploits
ei have ct are their only postcondition. It is clear that any
strategy that hardens the network with respect to ct implicitly
hardens the network with respect to each ci ∈ Ct. In fact, as