2
10 pages
10 pages
7 pages
8. RELATED WORK
Application-level secret protection. There are many
systems aiming at protecting secret data (e.g., cryptographic
keys) from application-level memory disclosure attacks by
leveraging library or OS kernel support [36, 8, 22, 37, 26].
For example, DieHarder [36] presents a security-oriented
memory allocator to defend heap-based memory attacks. Se-
cureHeap [8] is a patch for OpenSSL from Akamai Technol-
ogy, which allocates speciﬁc area to store private keys to pre-
vent private keys from disclosing. CRYPTON [22] designs
1616a data abstraction and browser primitive to isolate sensitive
data within the same origin. However, they all rely on the
trustworthiness of the entire library of OS kernel, and thus
still suﬀer from larger attack surfaces compared to SeCage.
Other approaches try to keep cryptographic keys solely
inside CPU [37, 26]. For example, Safekeeping [37] uses x86
SSE XMM registers to ensure no cryptographic key appear
in its entirety in the RAM, while allowing eﬃcient cryp-
tographic computations. Similarly, Copker [26] implements
asymmetric cryptosystems entirely within the CPU, without
leaking the plaintext of private keys to memory. However,
code running in cache needs to be specially crafted and it
needs to rely on the trustworthiness of OS kernel for security.
Hypervisor-based application protection. Systems
like CHAOS [17, 16], OverShadow [18] and others [19, 28, 53]
leverage virtualization-based approaches to providing iso-
lated execution environment to protect an application from a
compromised OS. Speciﬁcally, they leverage hypervisor pro-
vided memory isolation, and intercept transition between a
protected application and the OS to enforce isolation. Ink-
Tag [28] makes a step further to use paraveriﬁcation to ease
verifying of OS to defend again Iago attacks [15]. Com-
pared to these systems, SeCage aims to provide ﬁne-grained
intra-domain protection instead of whole application protec-
tion. Further, the separation of control and data planes sig-
niﬁcantly reduces hypervisor intervention and thus reduces
performance overhead.
Some other virtualization-based systems [29, 25, 45, 42]
run protected applications in a trusted component with re-
stricted functionalities (e.g., an application-speciﬁc OS), and
use hypervisor to enforce the interactions between trusted
and untrusted components. Compared with SeCage, such
approaches have larger TCB since they need to trust all
secure components like the OS. Further, they all need to
retroﬁt the whole OS and thus require signiﬁcant porting
eﬀort to run real, large software atop.
There are various systems aiming at providing isolated en-
vironment for the whole virtual machine [54, 50, 44], though
they are eﬃcient in guest VM protection, they cannot defend
against intra-domain attacks.
Protecting pieces of application logic. Flicker [35]
leverages TPM and takes a bottom-up approach to provide a
hardware-support isolation of security-sensitive code. With
the help of TPM, securely running Pieces of Application
Logic (PAL) can rely only on a few hundred lines of code
as its TCB. However, since Flicker heavily uses the hard-
ware support for a dynamic root of trust for measurement
(DRTM), it introduces very high overhead. TrustVisor [34]
proposes a special-purpose hypervisor to isolate the execu-
tion of the PAL. Compared with Flicker, it introduces the
software-based TPM called micro-TPM (uTPM) for each
PAL, to realize a more eﬃcient PAL protection. Flicker
and TrustVisor show a kind of eﬀectively isolated code ex-
ecution with extremely small TCB, they both assume that
the protected code is self-contained with predeﬁned inputs
and outputs, and heavily depend on programmers to spec-
ify sensitive functions, as well as (un)marshal parameters
between trusted and untrusted mode, which kind of de-
sign makes them very diﬃcult to adapt to existing sys-
tems. MiniBox [31] focus on providing a two-way sandbox
for both PAL and OS: besides protecting PAL from mali-
cious OS as TrustVisor does, it also prevents untrusted ap-
plications compromising the underlying OS. Since MiniBox
uses TrustVisor to do the ﬁrst part, they share the same
problems.
Hardware-assisted protection. There is also much
work on designing new hardware features to isolate critical
code and data [33, 43, 24, 14, 20, 10, 47, 49]. For example,
XOMOS [33] is built upon XOM [32] to support tamper-
resistant software. The concept of compartment is borrowed
from XOMOS, but is used to run a closure of code operat-
ing speciﬁc secret data. Further, SeCage leverages existing
hardware virtualization features to enforce strong protec-
tion. Haven [10] introduces the notion of shielded execution,
which utilizes Intel’s recent SGX security proposal to pro-
tect the code and data of the unmodiﬁed application from
divulging and tampering from privileged code and physi-
cal attack, but only targets whole application protection in-
stead of intra-application protection. SeCage illustrates how
to decompose large-scale software and adapt it to diﬀerent
hardware-assisted isolation environment.
Mimosa [27] uses hardware transactional memory (HTM)
to protect private keys from memory disclosure attacks. It
leverages the strong atomicity guarantee provided by HTM
to prevent malicious concurrent access to the memory of sen-
sitive data. Though Mimosa shares almost the same threat
model with SeCage, it has some limitations, e.g., in order
to prevent attackers from accessing debug registers (which
is used to store the AES master key of the private keys), it
needs to patch the ptrace system call, disable loadable kernel
modules (LKMs) and kmem, and remove JTAG ports. Com-
pared with SeCage, Mimosa can only adapt much simpliﬁed
PolarSSL instead of OpenSSL to the HTM protection.
CODOMs [47] enforces instruction-pointer capabilities to
provide a code-centric memory domain protection. CHERI [49]
implements a capability coprocessor and tagged memory to
enable capability-based addressing for intra-program protec-
tion. Both designs promise very small TCB (e.g., micropro-
cessor and up to limited software component like trusted ker-
nel), and can provide strong isolation enforced by hardware.
However, since they all need newly speciﬁc designed hard-
ware which are currently not available, they are all imple-
mented on emulators. Further, they usually require rewrit-
ing of the whole software stack, which lead to non-trivial
engineering work and make them not ready for deployment.
Privilege separation. PrivTrans [13] is a privilege sep-
aration tool that can automatically decouple a program into
monitor and slave parts provided a few programmer anno-
tations. Compared with the mechanism of SeCage, Priv-
Trans approach partitions code in instruction-level, which
introduces a large number of expensive calls between the
two parts. Meanwhile, it trusts the whole operating system,
whose threat model is quite diﬀerent with SeCage. Virtual
Ghost [21] is the ﬁrst one to combines compilation technique
and OS code runtime check to provide critical application
with some secure services, and protect it from compromised
OS without higher privilege level than the kernel. However,
it needs to retroﬁt OS and runs it in a secure virtual archi-
tecture (SVA), which requires non-trivial eﬀorts to deploy it
in current infrastructures.
VMFUNC utilization. SeCage is not the ﬁrst system
to use the Intel’s VMFUNC hardware feature. Following
the philosophy of separating authentication from authoriza-
tion, CrossOver [30] extends Intel’s VMFUNC mechanism to
provide a ﬂexible cross-world call scheme that allows calls
not only across VMs, but across diﬀerent privilege levels
1617and address spaces. We believe such a mechanism can be
applied to SeCage to provide more ﬂexible protection. An
eﬀort from the open-source community [9] takes advantages
of VMFUNC, and proposes an eﬃcient NFV on Xen. As
far as we know, SeCage is the ﬁrst system making uses of
VMFUNC to protect pieces of application logic and prevent
from both user and kernel level memory disclosure attacks.
9. DISCUSSION AND LIMITATION
Deployment eﬀort. The deployment of SeCage is not
fully automated, the minor manual eﬀort is required. For
OpenSSL and CryptoLoop, we respectively add 25 and 15
LoCs. They are mainly attributed to the dynamic analysis,
secret memory allocation and hypercall used for initializa-
tion. Comparing it with other work, TrustVisor [34], Mi-
mosa [27] and many others did not support OpenSSL so they
resort to the much more simpliﬁed PolarSSL. PrivTrans [13]
only adds 2 annotations, however it puts all cryptographic
operations in the monitor, while SeCage only allows very
limited code in the secret compartment.
SeCage TCB. For one secret compartment, the TCB
contains hardware, hypervisor and the sensitive functions.
Currently, our implementation uses KVM as the trusted
hypervisor, which arguably has a large TCB. However, as
SeCage only involves minor functionalities in hypervisor, it
should be easy to port SeCage to a security-enhanced hy-
pervisor such as TrustVisor [34] or XMHF [46] to further
reduce TCB, which will be our future work.
The scope of secrets. SeCage is supposed to protect
critical secrets like private keys, whose related sensitive func-
tions are limited to a small piece of code. Since the small
code base of a secret compartment is one of the most impor-
tant assurance to secrets’ security, SeCage is not designed
for protecting data whose closure involves large fraction of
the code. Fortunately, the three cases we studied, which
should be representative of large-scale software, ﬁt very well
with our scope.
Static library vs. dynamic library. Currently, SeCage
compiles OpenSSL as a static library, and slightly modiﬁes
the linker to link the sensitive and trampoline functions to
speciﬁc memory locations. We can also adopt dynamic li-
braries, by modifying system’s loader. We do not assume the
loader as trusted; even if it behaves maliciously by refusing
to load sensitive functions or loading them to wrong mem-
ory locations, the secrets will still not be disclosed. This is
because the hypervisor can reject to load the secrets during
the integrity checking phase (Section 3.4).
10. CONCLUSION AND FUTURE WORK
We presented SeCage, a novel approach that leverages vir-
tualization to protect user-deﬁned secrets from application
vulnerabilities and malicious OS. SeCage prevents sensitive
information disclosure by completely shadowing the secret
compartment from the main compartment, and utilizes In-
tel hardware extension to enormously reduce hypervisor in-
tervention during application runtime. Meanwhile, SeCage
provides a practical application analysis and decomposition
framework to (mostly) automatically deploy applications.
SeCage was shown to be useful by protecting real and large-
scale software from HeartBleed attack, kernel memory dis-
closure and rootkit memory scanning eﬀectively, and incur-
ring negligible performance overhead to applications.
We plan to extend our work in several directions. First,
we plan to deploy more applications with SeCage to prevent
sensitive memory disclosure based on the CVEs. Second,
we plan to adopt binary rewriting techniques to avoid the
requirement of source code rewriting. Third, we plan to im-
plement SeCage in other virtualization platform, e.g., Xen.
11. ACKNOWLEDGEMENT
We thank the anonymous reviewers for their insightful
comments. This work is supported in part by a research
grant from Huawei Technologies, Inc., National Natural Sci-
ence Foundation (61303011), a foundation for the Author
of National Excellent Doctoral Dissertation of PR China
(No. TS0220103006), Program for New Century Excellent
Talents in University of Ministry of Education of China
(ZXZY037003), the Shanghai Science and Technology De-
velopment Fund for high-tech achievement translation (No.
14511100902), Zhangjiang Hi-Tech program (No. 201501-
YP-B108-012), and the Singapore NRF (CREATE E2S2).
12. REFERENCES
[1] CIL. http://kerneis.github.io/cil/.
[2] Coppersmith’s attack.
http://en.wikipedia.org/wiki/Coppersmith’s Attack.
[3] The heartbleed bug. http://heartbleed.com/.
[4] How heartbleed leaked private keys.
http://blog.cloudﬂare.com/searching-for-the-prime-
suspect-how-heartbleed-leaked-private-keys/.
[5] Http persistent connection wiki.
https://en.wikipedia.org/wiki/HTTP persistent connection.
[6] Poc of private key leakage using heartbleed.
https://github.com/einaros/heartbleed-tools.
[7] Polyvariance.
http://en.wikipedia.org/wiki/Polyvariance.
[8] Secure heap patch for heartbleed.
http://www.mail-archive.com/openssl-
PI:EMAIL/msg73503.html.
[9] Xen as high-performance nfv platform.
http://events.linuxfoundation.org/sites/events/ﬁles/
slides/XenAsHighPerformanceNFVPlatform.pdf.
[10] A. Baumann, M. Peinado, and G. Hunt. Shielding
applications from an untrusted cloud with haven. In
OSDI, 2014.
[11] A. Bittau, A. Belay, A. Mashtizadeh, D. Mazieres, and
D. Boneh. Hacking blind. In S&P, 2014.
[12] E. Bosman and H. Bos. Framing signals: A return to
portable shellcode. In S&P, 2014.
[13] D. Brumley and D. Song. Privtrans: Automatically
partitioning programs for privilege separation. In
Usenix Security, 2004.
[14] D. Champagne and R. B. Lee. Scalable architectural
support for trusted software. In HPCA, 2010.
[15] S. Checkoway and H. Shacham. Iago attacks: why the
system call api is a bad untrusted rpc interface. In
ASPLOS, 2013.
[16] H. Chen, J. Chen, W. Mao, and F. Yan. Daonity–grid
security from two levels of virtualization. Information
Security Technical Report, 12(3):123–138, 2007.
[17] H. Chen, F. Zhang, C. Chen, Z. Yang, R. Chen,
B. Zang, and W. Mao. Tamper-resistant execution in
1618an untrusted operating system using a virtual machine
monitor. Technical Report, FDUPPITR-2007-0801.
[18] X. Chen, T. Garﬁnkel, E. C. Lewis, P. Subrahmanyam,
C. A. Waldspurger, D. Boneh, J. Dwoskin, and D. R.
Ports. Overshadow: a virtualization-based approach to
retroﬁtting protection in commodity operating
systems. In ASPLOS, 2008.
[19] Y. Cheng, X. Ding, and R. Deng. Appshield:
Protecting applications against untrusted operating
system. Technical Report, SMU-SIS-13, 2013.
[20] S. Chhabra, B. Rogers, Y. Solihin, and M. Prvulovic.
Secureme: a hardware-software approach to full
system security. In ICS, 2011.
[21] J. Criswell, N. Dautenhahn, and V. Adve. Virtual
ghost: protecting applications from hostile operating
systems. In ASPLOS, 2014.
[22] X. Dong, Z. Chen, H. Siadati, S. Tople, P. Saxena,
and Z. Liang. Protecting sensitive web content from
client-side vulnerabilities with cryptons. In CCS, 2013.
[23] Z. Durumeric, J. Kasten, D. Adrian, J. A. Halderman,
M. Bailey, F. Li, N. Weaver, J. Amann, J. Beekman,
et al. The matter of heartbleed. In IMC, 2014.
[24] J. S. Dwoskin and R. B. Lee. Hardware-rooted trust
for secure key management and transient trust. In
CCS, 2007.
[25] T. Garﬁnkel, B. Pfaﬀ, J. Chow, M. Rosenblum, and
D. Boneh. Terra: A virtual machine-based platform
for trusted computing. In SOSP, 2003.
[26] L. Guan, J. Lin, B. Luo, and J. Jing. Copker:
Computing with private keys without ram. In NDSS,
2014.
[27] L. Guan, J. Lin, B. Luo, J. Jing, and J. Wang.
Protecting private keys against memory disclosure
attacks using hardware transactional memory. In S&P,
2015.
[28] O. S. Hofmann, S. Kim, A. M. Dunn, M. Z. Lee, and
E. Witchel. Inktag: secure applications on an
untrusted operating system. 2013.
[29] P. C. Kwan and G. Durfee. Practical uses of virtual
machines for protection of sensitive user data. In
ISPEC. 2007.
[30] W. Li, Y. Xia, H. Chen, B. Zang, and H. Guan.
Reducing world switches in virtualized environment
with ﬂexible cross-world calls. In ISCA, 2015.
[31] Y. Li, J. McCune, J. Newsome, A. Perrig, B. Baker,
and W. Drewry. Minibox: A two-way sandbox for x86
native code. In ATC, 2014.
[32] D. Lie, C. Thekkath, M. Mitchell, P. Lincoln,
D. Boneh, J. Mitchell, and M. Horowitz. Architectural
support for copy and tamper resistant software. 2000.
[33] D. Lie, C. A. Thekkath, and M. Horowitz.
Implementing an untrusted operating system on
trusted hardware. In SOSP, 2003.
[34] J. M. McCune, Y. Li, N. Qu, Z. Zhou, A. Datta,
V. Gligor, and A. Perrig. Trustvisor: Eﬃcient tcb
reduction and attestation. In S&P, 2010.
[35] J. M. McCune, B. J. Parno, A. Perrig, M. K. Reiter,
and H. Isozaki. Flicker: An execution infrastructure
for tcb minimization. In EuroSys, 2008.
[36] G. Novark and E. D. Berger. Dieharder: securing the
heap. In CCS, 2010.
[37] T. P. Parker and S. Xu. A method for safekeeping
cryptographic keys from memory disclosure attacks. In
Trusted Systems. 2010.
[38] J. Shi, X. Song, H. Chen, and B. Zang. Limiting
cache-based side-channel in multi-tenant cloud using
dynamic page coloring. In DDSN-W, 2011.
[39] G. Smith, C. E. Irvine, D. Volpano, et al. A sound
type system for secure ﬂow analysis. Journal of
Computer Security, 1996.
[40] K. Z. Snow, F. Monrose, L. Davi, A. Dmitrienko,
C. Liebchen, and A.-R. Sadeghi. Just-in-time code
reuse: On the eﬀectiveness of ﬁne-grained address
space layout randomization. In S&P, 2013.
[41] R. Strackx, B. Jacobs, and F. Piessens. Ice: a passive,
high-speed, state-continuity scheme. In ACSAC, 2014.
[42] R. Strackx and F. Piessens. Fides: Selectively
hardening software application components against
kernel-level or process-level malware. In CCS, 2012.
[43] G. E. Suh, D. Clarke, B. Gassend, M. Van Dijk, and
S. Devadas. Aegis: architecture for tamper-evident
and tamper-resistant processing. In ICS, 2003.
[44] J. Szefer and R. B. Lee. Architectural support for
hypervisor-secure virtualization. In ASPLOS, 2012.
[45] R. Ta-Min, L. Litty, and D. Lie. Splitting interfaces:
Making trust between applications and operating
systems conﬁgurable. In OSDI, 2006.
[46] A. Vasudevan, S. Chaki, L. Jia, J. McCune,
J. Newsome, and A. Datta. Design, implementation
and veriﬁcation of an extensible and modular
hypervisor framework. In S&P, 2013.
[47] L. Vilanova, M. Ben-Yehuda, N. Navarro, Y. Etsion,
and M. Valero. Codoms: protecting software with
code-centric memory domains. In ISCA, 2014.
[48] Z. Wang, C. Wu, M. Grace, and X. Jiang. Isolating
commodity hosted hypervisors with hyperlock. In
CCS, 2012.
[49] J. Woodruﬀ, R. N. Watson, D. Chisnall, S. W. Moore,
J. Anderson, et al. The cheri capability model:
Revisiting risc in an age of risk. In ISCA, 2014.
[50] Y. Xia, Y. Liu, and H. Chen. Architecture support for
guest-transparent vm protection from untrusted
hypervisor and physical attacks. In HPCA, 2013.
[51] Y. Xia, Y. Liu, H. Chen, and B. Zang. Defending
against vm rollback attack. In DCDV, 2012.
[52] Y. Xia, Y. Liu, H. Guan, Y. Chen, T. Chen, B. Zang,
and H. Chen. Secure outsourcing of virtual appliance.
IEEE Transactions on Cloud Computing, 2015.
[53] J. Yang and K. G. Shin. Using hypervisor to provide
data secrecy for user applications on a per-page basis.
In VEE, 2008.
[54] F. Zhang, J. Chen, H. Chen, and B. Zang. Cloudvisor:
retroﬁtting protection of virtual machines in
multi-tenant cloud with nested virtualization. In
SOSP, 2011.
[55] Y. Zhang, A. Juels, M. K. Reiter, and T. Ristenpart.
Cross-vm side channels and their use to extract
private keys. In CCS, 2012.
1619