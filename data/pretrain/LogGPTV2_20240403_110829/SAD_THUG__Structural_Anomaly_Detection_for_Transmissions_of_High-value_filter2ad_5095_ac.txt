E ← {} {Edges}
F ← /0 {Final states}
γ : E → N∗ {Annotations}
for s in A do
call train_with_ﬁle (s)
return (V,v0,Σ,E,F,γ) {Trained automaton with annotations}
method train_with_ﬁle (s)
v ← v0 {Start with the HEAD state}
for si in s = s0, ...,sn−1 do
v(cid:48) ← σ (si)
V ← V ∪{v(cid:48)} {Add vertex, if missing}
E ← E ∪{(v,si) → v(cid:48)} {Add transition}
if (cid:96)(si) is ﬁxed then
γ(v,v(cid:48)) ← γ(v,v(cid:48)) + 1
γ(v,v(cid:48)) ← γ(v,v(cid:48)) (cid:95) (cid:96)(si)
else
v ← v(cid:48)
F = F ∪{v} {Add current state to ﬁnal states}
Figure 4: Training algorithm
(V,v0,ΣT ,E,F,γ). Processing each image individually,
as described by method train_with_file, the automa-
ton is constructed and, once all ﬁles have been processed,
returned. The automaton can then be used in the classiﬁ-
cation phase to classify previously unobserved ﬁles.
In each iteration of train_with_file, we start with
the predecessor variable v pointing to a virtual HEAD state
that represents the beginning of the ﬁle. For each ob-
served segment, we determine the corresponding vertex
v(cid:48) and add it to the set of vertices V in the automaton if
necessary. Also, we ensure that the automaton contains
an edge e ∈ E from v(cid:48)s predecessor v to that vertex. Fi-
nally, we update the annotations γ(e) for that edge. If
the segment’s length is ﬁxed, we increment the annota-
tion for that edge by one, assuming the annotations were
initialized to 0. For variable length segments, the anno-
tations were initialized to an empty tuple and we append
the observed length to the edge’s annotation. Finally, we
set v(cid:48) to be the next predecessor v and process the next
USENIX Association
27th USENIX Security Symposium    1153
SOIAPP1DQT0DQT1ScanEOI25069692470272ScanAPP0SOIEOIDQT0HEADScanAPP0SOIEOIDQT0DQT1APP1HEADRequire: (V,v0,ΣT ,E,F,γ) {Trained automaton with annotations}
Require: α {Length sensitivity parameter}
Require: τ {Conﬁrmation threshold}
Require: s {Decomposed image}
v ← v0
for si in s = s0, ...,sn−1 do
v(cid:48) ← σ (si)
if not is_acceptable_transition(v,si,v(cid:48)) then
v ← v(cid:48)
return anomaly
if not v ∈ F then
return anomaly
else
return normal
method is_acceptable_transition (v,si,v(cid:48))
if not (v → v(cid:48)) ∈ E then
if (cid:96)(si) is ﬁxed then
return false
if not γ(v,v(cid:48)) ≥ τ then
return false
else
return false
return true
C = {x(cid:107)x ∈ γ(v,v(cid:48))∧ (|x− (cid:96)(si)| ≤ (cid:100)(cid:96)(si)· α(cid:101)}
if not |C| ≥ τ then
Figure 5: Classiﬁcation algorithm
segment.
After all segments are processed, v contains the ver-
tex corresponding to the last processed segment. Hence,
we add this vertex to the set of legitimate ﬁnal states F.
When this procedure has been completed for all individ-
ual ﬁles, we return the resulting automaton.
Figure 3 b) shows an automaton after training on a
simpliﬁed JFIF ﬁle while ﬁg. 3 c) shows the same au-
tomaton after learning the simpliﬁed Exif ﬁle depicted in
ﬁg. 3 a). Here, the added vertices and edges are high-
lighted in green and we omit lengths in b) and c). Both
ﬁles start with a ﬁxed length SOI marker, so in the ﬁrst
step, the annotation for the edge from the HEAD state
to the respective vertex is incremented. However, in the
Exif ﬁle, it is followed by an APP1 rather than an APP0
marker and the corresponding vertex and an edge to it
are added. The automaton already contains a vertex cor-
responding to the DQT0 segment following in the ﬁle
and hence we only need to add another edge to process
it. That segment however is followed by a previously
unobserved DQT1 segment. Thus, again a new vertex
and an edge from the DQT0 to the new DQT1 vertex
are added. From there, an edge to the existing Scan ver-
tex is added, reﬂecting the sequence of segments in the
Exif ﬁle. Since – like in the JFIF ﬁle the automaton was
trained with – the last segment is an EOI segment behind
the Scan segment, the respective ﬁnal transition only up-
dates the automaton’s annotations.
5.4 Classiﬁcation Phase
Once the ﬁnite-state automaton has been built using the
procedure described above, we enter the classiﬁcation
phase. Here, we treat each ﬁle as a sequence of symbols
that are either accepted or rejected as words in a language
of legitimate ﬁles of that type. This process can be tuned
by adjusting the two parameters τ and α. τ is the num-
ber of times a transition has to have been observed dur-
ing training before we accept that transition in the clas-
siﬁcation phase. Obviously, with τ set to 1, we accept
any transition ever observed during the training phase.
As we increase τ, our classiﬁer becomes more restrictive
but also more robust against coincidental anomalies in
the training data or deliberate attempts to manipulate it
during the training phase.
For transitions to a variable length segment si, we only
consider those observations that are within a reasonable
range from that segment’s length, determined by our pa-
rameter α. More speciﬁcally, we calculate the range by
taking the ceiling of multiplying α with the given seg-
ment’s length: (cid:100)α · (cid:96)(si)(cid:101). Figure 6 illustrates this con-
cept.
It shows the absolute frequency of sizes for the
JPEG DC0 huffman table that lie between 0 and 100. A
green line indicates an observation of length 33. With
α set to 0.1, this corresponds to a range of 4, i.e.
the
area highlighted in green in ﬁg. 6. Our training data con-
tains many observations within this range, so we accept
the observation as legitimate. As another example, take
the red line at 70 in the ﬁgure. Its larger absolute value
results in a signiﬁcantly larger range as well. However,
as the area highlighted in red shows, there are few ob-
servations in this range, so – depending on the conﬁgu-
ration – our approach will classify this observation as an
anomaly.
Figure 5 shows the full classiﬁcation algorithm. It re-
quires a trained automaton, the two parameters τ and α
and ﬁnally a decomposed image as inputs. The result re-
turned is the classiﬁcation for the given ﬁle which may
be “anomaly”, if the ﬁle is considered to be malicious, or
“normal” otherwise.
Like in the training algorithm, decomposed ﬁles are
processed segment by segment. As sketched above,
the main task is to identify whether individual transi-
tions occurred in the training phase – taking into account
our parameters τ and α. This is handled by method
is_acceptable_transition in ﬁg. 5. Here, we ﬁrst
check whether a transition exists from the previous ver-
tex to a vertex that represents the current segment. If that
segment has not been observed during the training phase
or not been observed to follow the previous segment, the
check fails and we consider the ﬁle to be anomalous.
Otherwise, we verify whether the transition’s annotations
satisfy the constraints imposed by our parameters τ and
1154    27th USENIX Security Symposium
USENIX Association
Figure 6: The length of JPEG huffman table segments in bytes (excerpt).
α. If the segment’s size is ﬁxed, we check whether the
stored observation count reaches or exceeds the desired
threshold τ. For variable length segments, we ﬁrst de-
termine the observed lengths that were within (cid:100)α · (cid:96)(si)(cid:101)
bytes from si’s length (cid:96)(si). We then check whether they
exceed our threshold τ and reject the image, if that is not
the case. Given that all observed transitions were suc-
cessfully validated, we only need to check whether the
vertex corresponding to the last segment is also a ﬁnal
state in our trained automaton. If and only if that is the
case, we accept the image as normal with respect to our
training set.
6 Evaluation
We evaluated our approach using a large body of JPEG
and PNG ﬁles with embeddings from ten different mal-
ware families. The respective data sets are derived from
a total of 270,000 JPEG and 33,000 PNG ﬁles down-
loaded from popular websites. The same data set is also
used for training and to determine our approach’s false
positive ratio. Given the design of our experiment and
the size of our data sets, we believe that the results pre-
sented here closely resemble those achieved in a real en-
vironment.
In this section, we thus ﬁrst describe the general de-
sign of our experiment, before discussing the details of
our data sets. Section 6.3 describes how we obtained a
meaningful conﬁguration for our approach. We then pro-
vide an overview to Stegdetect, which we use as a bench-
mark. Finally, in section 6.5, we describe the results of
our evaluation for both approaches.
6.1 Experiment Design
We conduct a ten-fold cross-validation on a large data
set of 270,000 JPEG and 33,000 PNG ﬁles, downloaded
from the Internet as described in section 6.2.1, to verify
the accuracy and effectiveness of our approach. In each
iteration, we use nine tenths of each data set as training
data. The remaining data is further subdivided to con-
struct realistic data sets using a diverse set of embedding
methods. We use them – along with additional data sets
– as test sets for our evaluation.
As a consistent measure for the quality of the detec-
tion, we use the true classiﬁcation ratio. This metric
can be applied on both ﬁles without and with a stegano-
graphic payload. For the former ﬁles, it corresponds to
the fraction of the ﬁles that were classiﬁed as benign.
Files that contain an embedding, on the other hand, must
be classiﬁed as malicious to contribute to the respective
true classiﬁcation ratio. Thus, a value of 1 indicates a
perfect result for the given data set while a value of 0
shows that the approach is not at all able to correctly clas-
sify items in the respective subgroup.
6.2 Data Sets
6.2.1 Base Data Set
We obtained a large data set closely resembling a set of
images retrieved by average users browsing the Internet.
To do so, we determined the top 25 websites according
to Alexa [7] but after replacing semantic duplicates with
a single domain name. For instance, google.co.in,
google.co.jp and google.com all redirect to the same
website, based on your assumed locality and were thus
were replaced by a single instance of google.com in
our list. We then recursively crawled this pruned list but
stopped the recursion once a non-image resource was re-
trieved from a third-party domain. Many professionally
operated websites serve static resources under a differ-
ent domain name and thus without this exemption many
images that were part of a website would not be loaded
by our simulated Internet user. Through this process,
we obtained a total of 271,968 JPEG and 33,651 PNG
ﬁles. We removed randomly selected ﬁles from these sets
USENIX Association
27th USENIX Security Symposium    1155
02000050000Frequency20406080100to trim them to 270,000 JPEG and 33,000 PNG ﬁles.
This facilitates creating evenly-sized groups from them,
as discussed below. Note that our unbiased crawling re-
turned more than 8 times as many JPEG than PNG ﬁles,
reﬂecting the popularity of the two ﬁle formats.
Since we obtained these ﬁles from third parties, we
cannot completely rule out the possibility that they do
in fact contain hidden messages. However, the sites
we crawled are professionally run by respectable oper-
ators, so we assume that they do not deliberately provide
malicious image ﬁles. On the other hand, the sites we
crawled may allow users to upload content or reference
user-uploaded content on third party websites and some
users may decide to abuse their functionality to upload
ﬁles with steganographic content. Since we are crawling
popular websites with a large user base only, it is safe to
assume that only a diminishing fraction of users – if any
– engage in such activities. In turn, if our base data set
does contain images with steganographic content, their
quantity will be negligible. Weighing this against the in-
evitable lack of diversity in a self-assembled data set and
consequentially the remoteness of such a data set from
a live deployment, we opted for the approach described
above.
Further analysis of the data set nevertheless revealed
some interesting details. For instance, 15,005 ﬁles or
5.56%, of the JPEG ﬁles and 777 or 2.35% of the PNG
ﬁles contain data behind their EOI or IEND segment.
4,484 JPEG ﬁles have 3 or less residual bytes behind
their EOI marker, i.e. they are unlikely to carry any hid-
den message.
In the PNG partition, only 56 ﬁles fall
into that category. For both formats, the lion’s share of
the remaining ﬁles with four or more appended bytes is
made up by twitter.com. It accounts for 9,527 of the
10,521 JPEG and 475 of the 721 respective PNG ﬁles.
In a manually inspected sample, these ﬁles contained the
space character (0x20) appended up to 455,942 times.
The only reasonable explanation for this phenomenon is
a programming error. qq.com accounts for most of the
remaining ﬁles, i.e. 887 JPEG and 126 PNG ﬁles. Here,
the ﬁles contain 46 additional bytes each, primarily a 32
letter hexadecimal ASCII string. Since this corresponds
to the length of an MD5 hash, we assume that the data
serves as a kind of watermark.
We acknowledge that these observations may be con-
sidered anomalies and that the respective ﬁles could be
removed from the data set on that grounds. However,
we left them in the data set for two reasons. First, with
respect to SAD THUG, the presence of these ﬁles may
decrease but not increase its detection performance, i.e.
we avoid a potential unfair advantage for SAD THUG
in our evaluation. Second, the ﬁles are part of an un-
biased snapshot of ﬁles provided on the Internet. Re-
moving them would conceal a challenge that a detection
method would face in practice.
In our evaluation, we use the base data set for two
purposes. First, it serves as a training set for our ap-
proach. Second, we use it to create sets of ﬁles that con-
tain messages embedded with one of a total of 12 meth-
ods (for reasons explained below, this ﬁgure does not in-
clude CryLocker’s and DuQu’s methods).
6.2.2 Payload Data Sets
Malpedia is a curated collection of live malware sam-
ples and analysis [46]. After removing signatures, notes
and script-based samples from the collection, we ob-
tained a data set that contains a total of 4,558 malicious
ﬁles.
ZeusVM Conﬁguration The ZeusVM malware uses
JPEG ﬁles to transfer two pieces of conﬁguration to in-
fected machines. The ﬁrst part consists primarily of a
list of URLs that are used for command and control. We
discuss the other part, web-injects, below. To create this
data set, we extracted and parsed the content from 24 live
conﬁgurations for ZeusVM. From these conﬁgurations,
we determined the smallest and largest number of values
as well as all unique values for each option. To gener-
ate new conﬁgurations that closely resemble the original
ones, we chose a random count between the minimum
and maximum number of values observed for each given
option and then added random values from the pool of