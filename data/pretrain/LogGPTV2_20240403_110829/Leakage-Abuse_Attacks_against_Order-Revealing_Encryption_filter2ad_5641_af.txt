attack we prefer. The adversary then takes the union of the
resulting guesses, adds the q known plaintexts to this solution
appropriately, and outputs the result as its guess.
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:24:38 UTC from IEEE Xplore.  Restrictions apply. 
Birth dates
ZIP codes
Raw RR
Unique RR
90
68
0.25% 2.75% 5.25% 0.25% 2.75% 5.25%
61
41
95
78
96
81
22
14
51
35
Figure 10: Known-plaintext attacks on Birth dates and ZIP codes
with order and frequency leakage. Numbers in the second row refer
to the percentage of known plaintexts.
Results. We perform experiments using the partitioning
attack together with the non-crossing attack using just fre-
quency and order leakage. While the attack increases suc-
cess for the BCLO, CLWW, and decomposition attacks as
well, the relative gain will be more modest as those attacks
(without known plaintexts) already perform well. To enable
comparison across the various names datasets, we set the
number of known plaintexts to be a fraction of the total
number of target plaintexts. We experiment with 0.25%,
2.75%, and 5.25% of randomly-sampled plaintexts being
known by the adversary. These correspond to somewhere
between 5 and 300 plaintexts for 0.25% and 150 and 6,000
plaintexts for 5.25%, depending on the dataset. Recovery
rates are averaged over ﬁve trials. Because the distribution
is uniform over unique names and ﬁrst and last names are
long-tailed in terms of frequency, the raw frequency of the
randomly-sampled known plaintexts was very low in all
experiments. Intuitively, this is because only a small fraction
of unique names have high frequency; most occur only once
or twice. Birthdates and ZIP codes have a ﬂatter distribution,
so the sampled plaintexts had very low frequency there as
well.
Figure 10 shows the results of our known-plaintext parti-
tioning attack for 0.25%, 2.75%, and 5.25% of the unique
birthdates and ZIP codes. The partitioning attack performs
extremely well for birthdates. With only 0.25% of values
known, the raw recovery rate jumps from less than one
percent (in our attack with no known plaintexts) to nearly
90%. This jump can be attributed to the density of birth
months and days for high-frequency years. Since the known
plaintexts will, with high probability, reveal the year of most
birth dates by upper- and lower-bounding unknown values,
the non-crossing attack simply matches the days of the year
in sequence. Another way of looking at this is that once the
partitioning occurs, the non-crossing attack just performs a
kind of sorting attack on the days in each partition. This
“density” property is not speciﬁc to our datasets — any
real birthdate dataset of comparable size to ours will have
this density property. The partitioning attack also increases
accuracy for ZIP codes substantially.
For ﬁrst names, the increase in average recovery rates was
modest. For 0.25% the average was 84%, only about 0.5%
higher than the attack with no known plaintexts. With 5.25%
the average was 87%, again a modest gain. The non-crossing
attack with no known values already does quite well for
ﬁrst names, so having known plaintexts can only aid us in
recovering very low-frequency values. For last names the
known plaintexts had a bigger effect. Compared to a 38%
average with no known plaintexts, having 0.25% of values
known gives a 40% average, and having 5.25% of values
known gives a large increase to 49% on average. The standard
deviation of attacks on ﬁrst names was around 7%, and for
last names it was between 11% and 14%.
VIII. ATTACKING FREQUENCY-HIDING SCHEMES
All our previous attacks are against deterministic OPE and
ORE schemes. OPE and ORE are not inherently determinis-
tic but no security notions or constructions of randomized
OPE/ORE were known until recently. The ﬁrst notion of
security for randomized ORE was provided by Boneh et
al. [7], and they also give a scheme based on multilinear
maps that provably meets their deﬁnition. A more efﬁcient
randomized OPE scheme was proposed by Kerschbaum [25]
along with a suitable security notion it was shown to provably
meet. The scheme preserves order by storing state (in the
form of a binary search tree) on the client. When a value
is added, the tree is traversed as it would be in a standard
binary tree insertion operation. If the value to be inserted is
already present in the tree, randomness is used to choose a
new ciphertext for the value, while preserving order.
The Kerschbaum scheme is requires an interactive pro-
tocol, and the client must store state whose size is propor-
tional to the number of elements in the database. It also
has mutable ciphertexts. All these issues are inherent hurdles
to deployment. Nevertheless, there may in the future be
settings in which deployment is feasible, or other schemes
may be produced that hide frequency while being more
practical. We therefore seek to analyze security of schemes
that only leak order. To that end, we will describe a simple
attack that targets high-frequency elements of a distribution
by estimating where the ciphertexts of those elements are
relative to the others. We call this attack the “binomial” attack
because it uses a simple biased-coin model to estimate the
locations of plaintexts.
Plaintext ranges and coin ﬂips. We’ll start with some
preliminaries. Let C = (c1, . . . , cn) be an ordered list
of (randomized) ciphertexts. For simplicity, assume each
ciphertext is an encryption of some element of the attacker’s
auxiliary data Z. As in all our attacks, the basic task we
need to perform is a kind of labelling or matching — given a
ciphertext, we need to guess what is its underlying plaintext.
None of our prior approaches apply here, though, since
frequency is not leaked. So, more precisely, we need to ﬁnd
the range of ciphertexts which are all encryptions of the same
underlying plaintext. Let the plaintext whose range we’re
trying to ﬁnd be zi. The encryptions of zi are, by correctness,
a contiguous sub-list of C, and we need to ﬁnd the ﬁrst and
668
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:24:38 UTC from IEEE Xplore.  Restrictions apply. 
(cid:5)
u
c1
 zi
cn
Figure 11: Pictorial aid for explaining the binomial attack. To
recover the plaintext zi, the attacker must locate the range [(cid:2), u]
of ciphertexts whose encryptions are zi.
Rank
1
2
3
4
5
First names
RR
94
91
85
89
72
Rank
6
7
8
9
10
RR
100
95
83
94
72
Rank
1
2
3
4
5
Last names
RR
83
63
87
100
37
Rank
6
7
8
9
10
RR
98
82
62
74
63
last indices of this sub-list. In Figure 11 these two indices are
denoted (cid:5) and u. We can estimate (cid:5) and u using two simple
observations.
The ﬁrst observation is that if we know (cid:5), we can esti-
mate u by estimating the number of times the element zi
occurs in an n-element draw with replacement from Z. If zi
is drawn k times, then u = k + (cid:5). With the auxiliary data Z,
estimating k is trivial: if fzi is the probability of drawing zi,
the distribution of k is the number of times heads occurs in n
ﬂips of a biased coin where the probability of a single head
is fzi. Thus, the expected value of k is n · fzi.
We know how to estimate the upper bound given the lower
bound, so to ﬁnish we only need to show how to estimate
the lower bound. Our second observation is that if we can
estimate the number of elements of Z strictly less than zi in
our sample, call this number j, then we know (cid:5) right away.
Namely, (cid:5) = j + 1. In Figure 11 this is the dashed blue
region labelled “ 0,
the number of heads H(n) obeys the inequality
Pr [ (p − )n ≤ H(n) ≤ (p + )n ] ≥ 1 − 2e−22n .
Clearly, a larger  leads to a larger range of possible values
for H(n), which compensates for more uncertainty about the
exact plaintext distribution. However, a larger  also lowers
the precision (i.e., causes false positives) and can cause
ranges to overlap, which requires special handling (as we will
describe below). Using the bound, an  can be computed for
any desired conﬁdence d ∈ [0, 1] as
log 1−d
2−2n
(cid:7)
 =
.
To sum up, for plaintext zi with fzi and f<zi deﬁned
above, we will estimate the range [(cid:5), u] for zi as in Figure 11
as
(cid:6)
− )n , (f<zi + )n + (fzi + )n
(f<zi
(cid:5)
.
669
Figure 12: Average recovery rates (RR) for top ten ﬁrst and last
names in the auxiliary data with our binomial attack. Rank refers to
its position in the histogram sorted descending by frequency.
This takes the lower bound of the estimate for (cid:5) and the upper
bound of the estimate for u.
There is one issue of practical importance we have not
resolved: if ranges for two different plaintexts overlap, the
attacker has some ambiguity about which guess is correct.
In our implementation, we resolve overlaps by splitting the
range proportional to the probabilities of the two elements.
So, for example, if ranges corresponding to plaintexts zi and
/(fzi + fzj ) of the overlap
zj overlap, we allot a fraction fzi
to plaintext zi and fzj
/(fzi + fzj ) to plaintext zj. This is
a heuristic that seems to work well, but a more principled
approach may be possible.
Running the binomial attack. To actually run the bi-
nomial attack to recover plaintexts from an ordered list of
ciphertexts (c1, . . . , cn) of size n, choose the ﬁrst k highest
= {z1, . . . , zk} in the
frequency plaintext elements Z(cid:2)
auxiliary data. For each zi, compute the range [(cid:5)zi
, uzi ]
using the method described above and output the mapping
(zi,{c(cid:3), c(cid:3)+1, . . . , cu}).
The attacker can target any number k of the highest-
frequency elements of the plaintext distribution. There is a
point of diminishing returns, though: when an element is
too low-frequency we will fail to ﬁnd any of its ciphertexts
because small mismatches between the predicted and actual
frequency will cause its ciphertexts to be shifted entirely out
of the predicted range.
Results. For all experiments we computed the interval
width  using conﬁdence d = 0.99. Our recovery rates for
birthdates and ZIP codes were low. However, our preﬁx
recovery rate was 37% for birthdates, one full character
over the baseline on average. This means our hypothetical
attacker can (on average) learn the decade of birth for some
records in the database. Our preﬁx recovery rate for ZIP
codes was 12%. Our attack did not perform particularly well
for ZIP codes, which is unsurprising — its distribution is
closer to uniform than the others.
For ﬁrst and last names we will discuss two different
notions of “recovery rate”. Since we are explicitly attack-
ing certain elements of the distribution, one logical way to
quantify recovery is as the fraction of ciphertexts of elements
we attacked that we correctly matched to their underlying
plaintext. We will refer to this as “average recovery rate
for the top k names”. The other notion of “recovery rate”
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:24:38 UTC from IEEE Xplore.  Restrictions apply. 
is the standard one from above — namely, the number of
correctly recovered ciphertexts divided by the total number
of ciphertexts.
Recovery rates for the top 10 highest-frequency ﬁrst and
last names (i.e., k = 10 in the attack description above)
are presented in Figure 12. For ﬁrst names, we recovered
the name “michael” with 94% accuracy on average. For last
names, we recovered the name “brown” with 100% accuracy
in all datasets. The average recovery rate for the top 10
most frequent ﬁrst names was 86%, and for the top 10 most
frequent last names was 76%. Attacking only the top 10 most
frequent names, the average whole-dataset recovery rate for
ﬁrst names was 21% and for last names was 4%.
Attacking the top 40 most frequent names, the whole-
dataset recovery rates go up (to 30% for ﬁrst names and 7%
for last names) but the per-name recovery rates are lower.
For example, when attacking the top 40 ﬁrst names we only
recover 58% of the “michael”s on average. Note that this
whole-dataset recovery rate for last names is actually higher
than the corresponding recovery rate for the NKW greedy
attack on last names discussed in Section IV, despite the
fact that this attack (unlike NKW greedy) does not use any
frequency information.
One would expect that recovery rates might go down for