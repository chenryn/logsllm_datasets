Subject: Seeking Advice on Handling High Cardinality Dimensions in Druid

Dear [Recipient's Name],

We are currently facing significant performance issues with our Druid deployment due to a high-cardinality dimension in one of our data sources. This dimension is essential, but we only need to retain it if it appears in a substantial number of rows. Specifically, we would like to ignore or discard cases where the dimension has a unique value that only appears once.

To address this, we have considered a two-step process:

1. **Real-time Insertion:** As we are ingesting data in real-time from Storm, we cannot determine whether a unique value is appearing for the first time. Therefore, we insert all data as it arrives.
2. **Post-Processing:** After an hour, when the segment is closed, we run a secondary query on a HIVE view to group and aggregate the unique values that appear only once under a category such as "Unknown." We then re-insert this processed data.

While this approach mitigates the performance degradation for data outside the real-time segment, it still causes performance issues during the current hour.

This is a temporary, in-house solution, and we are seeking a more elegant and efficient method to handle this problem. We are currently using Druid version 0.9.2.

Thank you for your time and assistance.

Best regards,
[Your Name]  
[Your Position]  
[Your Contact Information]  
[Your Company]