title:Formalizing and Enforcing Purpose Restrictions in Privacy Policies
author:Michael Carl Tschantz and
Anupam Datta and
Jeannette M. Wing
2012 IEEE Symposium on Security and Privacy
Formalizing and Enforcing Purpose Restrictions in Privacy Policies
Michael Carl Tschantz
Carnegie Mellon University
Email: PI:EMAIL
Anupam Datta
Carnegie Mellon University
Email: PI:EMAIL
Jeannette M. Wing
Carnegie Mellon University
Email: PI:EMAIL
Abstract—Privacy policies often place restrictions on the
purposes for which a governed entity may use personal
information. For example, regulations, such as the Health
Insurance Portability and Accountability Act (HIPAA), require
that hospital employees use medical
information for only
certain purposes, such as treatment, but not for others, such as
gossip. Thus, using formal or automated methods for enforcing
privacy policies requires a semantics of purpose restrictions to
determine whether an action is for a purpose or not. We provide
such a semantics using a formalism based on planning. We
model planning using a modiﬁed version of Markov Decision
Processes (MDPs), which exclude redundant actions for a
formal deﬁnition of redundant. We argue that an action is for a
purpose if and only if the action is part of a plan for optimizing
the satisfaction of that purpose under the MDP model. We
use this formalization to deﬁne when a sequence of actions is
only for or not for a purpose. This semantics enables us to
create and implement an algorithm for automating auditing,
and to describe formally and compare rigorously previous
enforcement methods. To validate our semantics, we conduct
a survey to compare our semantics to how people commonly
understand the word “purpose”.
I. INTRODUCTION
Purpose is a key concept for privacy policies. For exam-
ple, the European Union requires that [1]:
Member States shall provide that personal data
must be [. . .] collected for speciﬁed, explicit and
legitimate purposes and not further processed in a
way incompatible with those purposes.
The United States also has laws placing purpose restrictions
on information in some domains such as the Health Insur-
ance Portability and Accountability Act (HIPAA) [2] for
medical information and the Gramm-Leach-Bliley Act [3]
for ﬁnancial records. These laws and best practices motivate
organizations to discuss in their privacy policies the purposes
for which they will use information.
Some privacy policies warn users that the policy provider
may use certain information for certain purposes. For ex-
ample, the privacy policy of a medical provider states, “We
may disclose your [protected health information] for public
health activities and purposes [. . .]” [4]. Such warnings do
not constrain the behavior of the policy provider.
Other policies that prohibit using certain information for
a purpose do constrain the behavior of the policy provider.
Examples include the privacy policy of Yahoo! Email, which
states that “Yahoo!’s practice is not to use the content of
messages stored in your Yahoo! Mail account for marketing
purposes” [5, emphasis added].
Some policies even limit the use of certain information
to an explicit list of purposes. The privacy policy of The
Bank of America states, “Employees are authorized to
access Customer Information for business purposes only.” [6,
emphasis added]. The HIPAA Privacy Rule requires that
health care providers only use protected health information
about a patient with that patient’s authorization or for a ﬁxed
list of allowed purposes, such as treatment and billing [2].
These examples show that verifying that an organization
obeys a privacy policy requires a semantics of purpose
restrictions. In particular, enforcement requires the ability
to determine that the organization obeys at least two classes
of purpose restrictions. Yahoo!’s privacy policy shows an
example of the ﬁrst class: a rule requiring that an organiza-
tion does not use certain information for a purpose. HIPAA
provides an example of the second class: a rule requiring that
an organization use certain information only for a given list
of purposes. We call the ﬁrst class of restrictions prohibitive
rules (not-for) and the second class exclusivity rules (only-
for). A prohibitive rule disallows an action for a particular
purpose. An exclusivity rule disallows an action for every
purpose other than the exceptions the rule lists. Each class
of rule requires determining whether the organization’s
behavior is for a purpose, but they differ in whether this
determination indicates a violation or compliance.
Manual enforcement of privacy policies is labor intensive
and error prone [7]. Thus, to reduce costs and build trust,
organizations should automate the enforcement of their pri-
vacy policies; tool support for this activity is emerging in the
market. For example, Fair Warning sells automated services
to hospitals for detecting privacy breaches [7]. Meanwhile,
previous research has proposed formal methods to enforce
purpose restrictions [8]–[15].
However, each of these endeavors starts by assuming that
actions or sequences of actions are labeled with the purposes
they are for. They avoid analyzing the meaning of purpose
and provide no method of performing this labeling other than
through intuition alone. The absence of a formal semantics
to guide this determination has hampered the development
of methods for ensuring policy compliance. Such a deﬁni-
tion would provide insights into how to develop tools that
identify suspicious accesses in need of detailed auditing and
© 2012, Michael Carl Tschantz. Under license to IEEE.
DOI 10.1109/SP.2012.21
176
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:47:51 UTC from IEEE Xplore.  Restrictions apply. 
algorithms for determining whether an action could be for
a purpose. It would also show which enforcement methods
are most accurate. More fundamentally, it could frame the
scientiﬁc basis of a societal and legal understanding of
purpose and of privacy policies. Such a foundation can, for
example, guide implementers as they codify in software an
organization’s privacy policies.
The goal of this work is to study the meaning of pur-
pose in the context of enforcing privacy policies. We aim
to provide formal deﬁnitions suitable for automating the
enforcement of purpose restrictions. We focus on automated
auditing since we ﬁnd that post-hoc auditing by a trusted
auditor provides the perspective often required to determine
the purpose of an action. However, we believe our semantics
is applicable to other enforcement mechanisms and may also
clarify informal reasoning. For example, in Section V-C,
we use it to create an operating procedure that encourages
compliance with a purpose restriction.
We ﬁnd that planning is central to the meaning of purpose.
We see the role of planning in the deﬁnition of the sense of
the word “purpose” most relevant to our work [16]:
The object for which anything is done or made, or
for which it exists; the result or effect intended or
sought; end, aim.
Similarly, work on cognitive psychology calls purpose “the
central determinant of behavior” [17, p. 19]. In Section II, we
present an example making this relationship between plan-
ning and purpose explicit. We (as have philosophers [18])
conclude that if an auditee (the person or organization being
audited) chooses to perform an action a while planning to
achieve the purpose p, then the auditee’s action a is for the
purpose p. Our goal is to make these notions formal in a
manner useful for the automation of auditing.
In Section III, we present a formalism based upon these
intuitions. We formalize planning using Markov Decision
Processes (MDPs) and provide semantics to purpose restric-
tions based upon planning with MDPs. Section IV provides
an auditing method and discusses the ramiﬁcations of the
auditor observing only the behaviors of the auditee and not
the underlying planning process of the auditee that resulted
in these behaviors. We characterize circumstances in which
the auditor can still acquire enough information to determine
that the auditee violated the privacy policy. To do so, the
auditor must ﬁrst use our MDP model
to construct all
the possible behaviors that the privacy policy allows and
then compare it with all the behaviors of the auditee that
could have resulted in the observed auditing log. Section V
presents an implemented algorithm for auditing based on our
formal deﬁnitions and also shows how to use it to create
an operating procedure that encourages compliance with a
purpose restriction.
To validate our semantics, we perform an empirical study.
In Section VI, we present the results of a survey testing how
people understand the word “purpose”. The survey compares
our planning based method to the prior method based on
whether an action improves the satisfaction of a purpose.
We ﬁnd that our method matches the survey participants’
responses much more closely than the prior method.
In Section VII, we use our formalism to discuss the
strengths and weaknesses of each previous method. In par-
ticular, we ﬁnd that each method enforces the policy given
the set of all possible allowed behaviors, which is a set that
our method can construct. We also compare the previous
auditing methods, which differ in their trade-offs between
auditing complexity and accuracy of representing this set of
behaviors. Section VIII discusses other related work.
Our work makes the following contributions:
1) The ﬁrst semantic formalism of when a sequence of
actions is for a purpose;
2) Empirical validation that our formalism closely corre-
sponds to how people understand the word “purpose”;
3) An algorithm employing our formalism and its imple-
mentation for auditing; and
4) The characterization of previous policy enforcement
methods in our formalism and a comparative study of
their expressiveness.
The ﬁrst two contributions illustrate that planning can for-
malize purpose restrictions. The next two illustrate that our
formalism may aid automated auditing and analysis. While
we view these results as a signiﬁcant step towards enforce-
ment of practical privacy policies with purpose restrictions,
we recognize that further work is needed before we will
have audit tools that are ready for use in organizations that
must comply with complex policies. We outline concrete
directions for future work towards this goal in Section IX.
Although motivated by our goal to formalize the notions
of use and purpose prevalently found in privacy policies, our
work is more generally applicable to a broad range of poli-
cies, such as ﬁscal policies governing travel reimbursement
or statements of ethics proscribing conﬂicts of interest.
A related technical report offers proofs and additional
details [19].
II. MOTIVATION OF OUR APPROACH
We start with an informal example that suggests that an
action is for a purpose if the action is part of a plan for
achieving that purpose. Consider a physician working at a
hospital who, as a specialist, also owns a private practice that
tests for bone damage using a novel technique for extracting
information from X-ray images. After seeing a patient and
taking an X-ray, the physician forwards the patient’s medical
record including the X-ray to his private practice to apply
this new technology. As this action entails the transmission
of protected health information, the physician will have
violated HIPAA if this transmission is not for one of the
purposes HIPAA allows. The physician would also run
afoul of the hospital’s own policies governing when outside
consultations are permissible unless this action was for a
177
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:47:51 UTC from IEEE Xplore.  Restrictions apply. 
legitimate purpose. Finally, the patient’s insurance will only
reimburse the costs associated with this consultation if a
medical reason (purpose) exists for them. The physician
claims that this consultation was for reaching a diagnosis.
As such, it is for the purpose of treatment and, therefore,
allowed under each of these policies. The hospital auditor,
however, has selected this action for investigation since the
physician’s making a referral to his own private practice
makes possible the alternate motivation of proﬁt.
Whether or not
the physician violated these policies
depends upon details not presented in the above description.
For example, we would expect the auditor to ask questions
such as: (1) Was the test relevant to the patient’s condition?
(2) Did the patient beneﬁt medically from having the test?
(3) Was this test the best option for the patient? We will
introduce these details as we introduce each of the factors
relevant to the purposes behind the physician’s actions.
States and Actions: Sometimes the purposes for which
an agent takes an action depend upon the previous actions
and the state of the system. In the above example, whether
or not the test is relevant depends upon the condition of the
patient, that is, the state that the patient is in.
While an auditor could model the act of transmitting the
record as two (or more) different actions based upon the state
of the patient, modeling two concepts with one formalism
could introduce errors. A better approach is to model the
state of the system. The state captures the context in which
the physician takes an action and allows for the purposes of
an action to depend upon the actions that precede it.
The physician’s own actions also affect the state of the
system and, thus, the purposes for which his actions are. For
example, had the physician transmitted the patient’s medical
record before taking the X-ray, then the transmission could
not have been for treatment since the physician’s private
practice only operates on X-rays and would have no use for
the record without the X-ray.
The above example illustrates that when an action is for
a purpose, the action is part of a sequence of actions that
can lead to a state in which some goal associated with the
purpose is achieved. In the example, the goal is reaching a
diagnosis. Only when the X-ray is ﬁrst added to the record
is this goal reached.
Non-redundancy: Some actions, however, may be part
of such a sequence without actually being for the purpose.
For example, suppose that the patient’s X-ray clearly shows
the patient’s problem. Then,
the physician can reach a
diagnosis without sending the record to the private practice.
Thus, while both taking the X-ray and sending the medical
record might be part of a sequence of actions that leads
to achieving a diagnosis, the transmission does not actually
contribute to achieving the diagnosis: the physician could
omit it and the diagnosis could still be reached.
From this example, it may be tempting to conclude that
an action is for a purpose only if that action is necessary to
achieve that purpose. However, consider a physician who,
to reach a diagnosis, must either send the medical record to
a specialist or take an MRI. In this scenario, the physician’s
sending the record to the specialist is not necessary since
he could take an MRI. Likewise, taking the MRI is not
necessary. Yet, the physician must do one or the other and
that action will be for the purpose of diagnosis. Thus, an
action may be for a purpose without being necessary for
achieving the purpose.
Rather than necessity, we use the weaker notion of non-
redundancy found in work on the semantics of causation
(e.g., [20]). Given a sequence of actions that achieves a goal,
an action in it is redundant if that sequence with that action
removed (and otherwise unchanged) also achieves the goal.
An action is non-redundant if removing that action from the
sequence would result in the goal no longer being achieved.
Thus, non-redundancy may be viewed as necessity under an
otherwise ﬁxed sequence of actions.
For example, suppose the physician decides to send the
medical record to the specialist. Then,
the sequence of
actions modiﬁed by removing this action would not lead to a
state in which a diagnosis is reached. Thus, the transmission