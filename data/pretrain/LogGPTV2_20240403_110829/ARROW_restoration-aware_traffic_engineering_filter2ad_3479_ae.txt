FFC-2
2.4√ó
2.4√ó
2.3√ó
2.0√ó
ECMP
2.3√ó
2.4√ó
2.3√ó
2.0√ó
Table 5: Arrow‚Äôs gain at different availability levels for B4
topology.
single fiber cut or double fiber cut scenarios. When a fiber fails, all
IP links on this fiber fail simultaneously.
Demand scaling. Given the fact that production WANs are over-
provisioned, we start with a network state where 100% of traffic
demand is satisfied. Similar to prior work [17, 48, 63], we scale the
demand matrix uniformly to evaluate each TE‚Äôs traffic allocation
over tunnels under different traffic loads and failure scenarios.
6.1 Availability and Satisfied Demand Gains
In this section, we show that Arrow improves availability and
throughput by restoring the lost IP capacity and reviving the IP-
layer network.
Availability metric definition. Availability is a key metric to
evaluate the satisfaction of Service Level Agreements (SLAs), and it
is directly related to the revenue of network providers [41, 85]. Our
availability metric is calculated as follows: for each topology and
traffic matrix, we first solve each TE formulation to obtain traffic
splitting rules. We then simulate all probabilistic failure scenarios
and calculate the availability of each scenario based on the per-
centage of total demand satisfaction during that scenario. We then
take the sum of the availabilities of all failure scenarios weighted by
each scenario‚Äôs probability as availability of a given traffic matrix.
For each topology and demand scale, we then take the average
availability across all traffic matrices.
Impact of demand scaling on availability. Fig. 13 shows the
availability of different TE schemes on B4, IBM, and Facebook
topologies. We focus on availability performance region larger than
99% because network operators need to maintain their network at
high availability [41, 43, 85]. Fig. 13 shows that Arrow maintains
higher availability levels as the demand is scaled for all three topolo-
gies. Specifically, we find that on B4 topology, Arrow can guarantee
99.99% availability, even when the traffic demand is scaled by 3.61√ó,
while FFC-1 can sustain at most 1.63√ó demand increase at 99.99%
availability. As a result, Arrow provides 2.2√ó gain in throughput
compared to FFC-1 without sacrificing 99.99% availability. Table 5
summarizes Arrow‚Äôs gains with respect to all considered prior
Topo.
Facebook
IBM
B4
# Routers /
ROADMs
34/84
17/17
12/12
156
23
19
262
85
52
12
30
30
Table 4: Network topologies used in our simulations.
‚Ä¢ Arrow-Naive. To evaluate the impact of Arrow‚Äôs two-phased
approach, we consider a naive version of Arrow, called Arrow-
Naive, that consists of only phase II. Hence, instead of using Lot-
teryTickets, this approach considers restoration solely at the optical
layer without taking instantaneous traffic matrices into account. To
do so, Arrow-Naive solves the RWA formulation (Appendix A.2)
only once and uses its output as a winning LotteryTicket and by-
passes Phase I at every TE run.
Topologies. We evaluate Arrow on three WAN topologies: Face-
book, IBM, and B4 (Table 4). For Facebook topology, we use a subset
of the optical-layer topology in production. For B4 and IBM, we take
the topologies in [58] and use them as the optical-layer topology.
Note that in large-scale WANs, the IP-layer topology tends to be
denser than the optical-layer topology [65, 71]. To generate realistic
IP-layer topologies, we measure the number of IP links per fiber
and the number of wavelengths per IP link in Facebook (shown in
Fig. 22 in Appendix A.8) and use these distributions to guide us to
generate the IP-layer topologies. Unless otherwise stated, we use
120, 90, and 80 as the number of LotteryTickets for running Arrow
on Facebook, IBM and B4, respectively.
Traffic matrix. For B4 and IBM networks, we use 30 traffic ma-
trices from SMORE [58] generated by fitting the real-world traffic
considering time variations and diurnal/weekly patterns. For the
Facebook topology, we use 12 real traffic matrices from production.
Tunnel selection. Arrow is orthogonal to tunnel selection meth-
ods. In our evaluations, we use both fiber-disjoint routing and
ùëò-shortest path routing algorithms to route tunnels over the IP-
layer topology, while ensuring that there is at least one residual
tunnel for every flow under each failure scenario. We set the num-
ber of tunnels per flow at 8, 12, and 16, for B4, IBM, and Facebook,
respectively.
Fiber cut scenarios. Following the methodology in TeaVaR [17],
we use a Weibull distribution (shape=0.8, scale=0.02) to model the
failure probability of each fiber. We then generate fiber cut scenarios
using cutoff values of 0.001, 0.001, 0.0002 for B4, IBM, Facebook,
respectively. Note that depending on the failure probabilities and
the cutoff value, the generated fiber cut scenarios may contain both
9999.299.499.699.810012.33.64.96.2Availability (%)Demand ScaleARROWARROW-NaiveFFC-1FFC-2TeaVaRECMP(a) B49999.299.499.699.810013579Availability (%)Demand Scale(c) Facebook(b) IBM9999.299.499.699.810012.545.57Availability (%)Demand ScaleFigure 14: Impact of number of LotteryTickets on Arrow‚Äôs
throughput in B4 topology.
ùëì ùëè ùëìùëì ùëëùëì ) returned by
approaches for the B4 topology at different availability levels. We
observe a similar trend for IBM and Facebook topologies, as shown
in Fig. 13(b) and (c). At 99.99% availability, Arrow improves the
network throughput by 1.6√ó and 2.4√ó compared to FFC-1. Note that
FFC-1 only provides failure guarantees for single fiber cut scenarios
while Arrow considers a combination of single and double fiber
cuts. FFC-2 considers all double fiber failures but it has a consider-
ably lower availability than Arrow (ECMP and FFC-2 curves are
often overlapping). Although TeaVaR and Arrow both consider
the same set of failure scenarios, Arrow outperforms TeaVaR by
2.4√ó, 2.8√ó, and 2.7√ó at 99.99% availability in B4, IBM, and Facebook,
respectively.
6.2 Impact of LotteryTickets
Throughput metric definition. Network throughput is another
core metric to evaluate TE algorithms because it shows the total
traffic that a network can accommodate. For each topology and
traffic matrix, our throughput metric is calculated as the ratio of
total admissible bandwidth over total demand (
the TE optimization formulation. We then take the average network
throughput across all traffic matrices.
Impact of number of LotteryTickets on throughput. Fig. 14
shows the impact of the number of LotteryTickets on Arrow‚Äôs
network throughput for B4 topology when the demand is scaled by
4.2√ó. The figure shows that when the number of LotteryTickets is
small, the throughput fluctuates. This is because LotteryTickets are
generated using randomized rounding, hence, more LotteryTickets
are probabilistically better. When the number of LotteryTickets
is one, it means we only have one restoration candidate for each
failure scenario and hence it represents the Arrow-Naive approach
where the restoration plan comes from solving the optical restora-
tion RWA formulation (Appendix A.2) offline. As the number of
LotteryTickets increases, Arrow‚Äôs throughput gradually increases
with less fluctuations until it reaches a plateau reflecting that the
LotteryTickets have already covered a good set of restoration candi-
dates, and continuing to add new LotteryTickets does not help much.
To find a balance between TE execution time and throughput, the
operator should select the appropriate number of LotteryTickets.
TE optimization runtime. We now compare Arrow‚Äôs optimiza-
tion runtime for different number of LotteryTickets. Arrow‚Äôs op-
timization is formulated as an LP, and is solvable in polynomial
time using Gurobi [66]. Fig. 15 presents Gurobi‚Äôs solve time for
Arrow TE optimization (Phase I + Phase II runtime) on a Linux
server with AMD EPYC 7502P 32-Core CPU processor and 256 GB
Figure 15: Runtime of Arrow optimization.
RAM. Note that this runtime only captures the optimization solve
time and excludes the time it takes to build the optimization model.
The figure shows that, Arrow‚Äôs runtime increases as the number
of LotteryTickets increase. For the Facebook topology with 120
LotteryTickets, Arrow‚Äôs formulation is solved within 104 seconds.
As mentioned in Section 3.1, the deadline for our TE runtime is
5 minute. Hence, Arrow is within the acceptable runtime range in
Facebook.
6.3 Cost Savings
Availability-guaranteed throughput. To compare the cost asso-
ciated with each TE scheme, following TeaVaR‚Äôs approach, we first
compute the availability-guaranteed throughput for each TE. This is
because different TE algorithms that we consider provide different
availability guarantees. For instance, FFC-1 guarantees 100% avail-
ability for all single fiber cut scenarios, but it does not guarantee
anything for double fiber cuts. On the other hand, FFC-2 guaran-
tees 100% availability for all double fiber cuts and hence achieves
lower throughput. To make apples-with-apples comparison, we
calculate the availability-guaranteed throughput. Specifically, for a
given availability target (e.g., ùõΩ = 99.9%), we iterate over all failure
scenarios of interest to compute the normalized demand loss for
each scenario. We then sort the failure scenarios based on their
loss values and find the scenario at the ùõΩ-percentile. The normal-
ized satisfied demand (1 - loss) of this scenario is reported as the
availability-guaranteed throughput. In other words, the through-
put is guaranteed to be no smaller than this value for ùõΩ percent of
failure scenarios.
Number of required router ports. The number of required
router ports to sustain a highly available network directly relates to
the cost of the network. To calculate the number of required router
ports, we find the worst-case traffic allocated on each IP link ùëí across
all failure scenarios (ùê∂ùê¥ùëÉùëí). We then calculate ùê∂ùê¥ùëÉ =ùëí ùê∂ùê¥ùëÉùëí to
find the required network capacity for the entire topology. To make
a fair comparison across different TE schemes, we then normalize
ùê∂ùê¥ùëÉ by the availability-guaranteed throughput value as a proxy
for the number of required router ports for each TE scheme and
network topology. Fig. 16 shows the number of required router
ports to achieve the same availability-guaranteed throughput with
ùõΩ = 99.9% availability target for different TE algorithms. To put
Arrow‚Äôs savings into perspective, we also calculate the minimum
number of required router ports by considering a hypothetical TE
that can achieve 100% availability at all times by fully restoring
every failure scenario. This reflects a TE that does not require any
over-provisioning of router ports to achieve 100% availability. We call
this approach Fully Restorable TE and use it as the baseline in Fig. 16.
The figure shows that Arrow has a fundamental advantage over
8090100110100Throughput (%)# of LotteryTicketsARROW1ARROW-Naive0.1110100Number of IP edges1 LotteryTicket10 LotteryTickets40 LotteryTickets80 LotteryTickets90 LotteryTickets120 LotteryTickets2625285Optimization time (s)B4IBMFacebookFigure 16: Number of router ports required for different TE
algorithms to support the same throughput with the same
availability level (99.9%).
existing TEs because it can restore lost IP capacity. This feature
allows Arrow to provide the same level of availability with less
over-provisioning. Specifically, for the Facebook topology, Arrow
requires 2.8√ó fewer router ports than the best failure-aware TE
(i.e., TeaVaR). Importantly, TeaVaR, FFC-1, and FFC-2 require 4.1√ó,
5.2√ó, 311.4√ó more router ports compared to the fully restorable
TE. However, Arrow only requires 1.5√ó more router ports to sus-
tain high availability even with partially restorable fibers (see ¬ß2.3).
Although our fully restorable TE case is a hypothetical best case
scenario, this result highlights Arrow‚Äôs ability to maintain high
throughput and high availability under failures without requiring
extensive over-provisioning.
Number of required transponders. Similar to router ports, the
number of required transponders also impact cost. In general, there
is a 1-to-1 mapping between router ports and transponders (Fig. 1).
Hence, the cost savings for router ports directly relate to cost sav-
ings for transponders as well.
7 RELATED WORK
Traffic Engineering. Traffic engineering is an important topic in
WANs [6, 17, 42, 43, 47, 48, 57, 58, 63, 79]. Work related to Arrow
includes failure-aware TE techniques [17, 48, 63], where the TE
formulation considers failure scenarios and pre-allocates enough
headroom on links so that when failures happen, traffic loss is
minimized (or is zero). Although such techniques embed failure-
recovery constraints in the TE formulation, in the case of fiber cuts,
they end up under-utilizing the WAN significantly. TeaVaR [17]
improves the utilization by assigning a probability to each failure
scenario but it still needs to allocate headroom for probable failures.
The first row in Table 10 (see Appendix A.9) illustrates the proper-
ties of this class of solutions. There are also other failure-oblivious
TE algorithms that aim at assigning traffic that respecting link
capacity [42], distributing traffic to equalize link utilization with
traffic-oblivious tunnels [58], or contracting network topologies
for runtime optimization [6]. These algorithms generally do not
consider failure scenarios in their formulation and can only respond
to failures in a reactive way without performance guarantees.
Optical path protection. Optical path protection techniques [14,
19, 59, 68, 80, 81, 84] pre-allocate failover paths solely on the optical
domain using a device called the Optical Transport Network (OTN)
switch. This is done by statically assigning a set of standby failover
paths to each fiber during the capacity planning phase. When a
failure happens, the OTN device quickly shifts the traffic from the
failed fiber to its active back up path without notifying the TE. The
second row in Table 10 illustrates this class of solutions. Although
this approach saves on router ports, it still needs to pre-allocate
transponders and keeps them idle to be prepared for fast failover.
Moreover, since the failover is entirely configured in the optical
layer, the TE is blind to the extra available capacity and cannot
utilize it optimally.
Classical optical restoration. Classical optical restoration tech-
niques are the most relevant work to this paper. Although the
benefits of optical restoration have been demonstrated in prior