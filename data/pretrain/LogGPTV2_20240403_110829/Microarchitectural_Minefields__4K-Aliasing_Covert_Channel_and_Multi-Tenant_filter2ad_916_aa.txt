title:Microarchitectural Minefields: 4K-Aliasing Covert Channel and Multi-Tenant
Detection in Iaas Clouds
author:Dean Sullivan and
Orlando Arias and
Travis Meade and
Yier Jin
Microarchitectural Mineﬁelds: 4K-Aliasing Covert
Channel and Multi-Tenant Detection in IaaS Clouds
Dean Sullivan
University of Florida
deanms@uﬂ.edu
Orlando Arias
Travis Meade
Yier Jin
University of Central Florida
PI:EMAIL
University of Central Florida
PI:EMAIL
University of Florida
yier.jin@ece.uﬂ.edu
Abstract—We introduce a new microarchitectural
timing
covert channel using the processor memory order buffer (MOB).
Speciﬁcally, we show how an adversary can infer the state of a spy
process on the Intel 64 and IA-32 architectures when predicting
dependent loads through the store buffer, called 4K-aliasing. The
4K-aliasing event is a side-effect of memory disambiguation mis-
prediction while handling write-after-read data hazards wherein
the lower 12-bits of a load address will falsely match with store
addresses resident in the MOB.
In this work, we extensively analyze 4K-aliasing and demon-
strate a new timing channel measureable across processes when
executed as hyperthreads. We then use 4K-aliasing to build a
robust covert communication channel on both the Amazon EC2
and Google Compute Engine capable of communicating at speeds
of 1.28 Mbps and 1.49 Mbps, respectively. In addition, we show
that 4K-aliasing can also be used to reliably detect multi-tenancy.
I.
INTRODUCTION
Infrastructure as a Service (IaaS) clouds, such as Amazon
EC2 and Google Compute Engine (GCE), are growing in pop-
ularity as increasingly powerful computing resources become
more affordable. IaaS affordability is largely a result of many
users sharing the same cloud infrastructure in a process known
as multi-tenancy. Multi-tenancy allows disparate users with
varying needs to deploy applications on-demand and at scale,
while at the same time signiﬁcantly improving utilization of
data center resources [32].
Research has demonstrated, however, that malicious users
can abuse multi-tenancy to leak information across virtual
machine (VM) instances via covert- and side-channels. Attacks
demonstrating extraction of sensitive information via side-
channels across colocated VMs are prevalent [34], [43], [27],
[26], [25], [41]. Other equally damaging attacks in the cloud
include covert channels. These attacks occur when two coop-
erating, but isolated, parties communicate with one another.
Often covert channels are used to extract information, but can
also be effective in determining multi-tenancy [14], [39], [28],
[38], [36].
Network  and  Distributed  Systems  Security  (NDSS)  Symposium  2018 
18-21  February  2018,  San  Diego,  CA,  USA
ISBN  1-891562-49-5
http://dx.doi.org/10.14722/ndss.2018.23221
www.ndss-symposium.org
Historically, IaaS timing channel attacks focus on cross-
core leakage. In contrast, there has been less research on IaaS
same-core timing attacks that exploit hardware hyperthreads,
also known as symmetric multithreads (SMT), or shared
resources. Under controlled experimental environments and
desktop platforms, innovative work has demonstrated SMT
covert- and side-channels on branch predictors [24], [16],
[2], [15], CPU functional units [37], [4], [6], the translation-
lookaside buffer [23], [20], and level one instruction [1],
[3] and data caches [42], [33], [30], [35]. Despite the large
number of such attacks, many have yet to be demonstrated
on the public cloud. The lack of research on SMT-based IaaS
timing channels follows from two assumptions: 1) SMT covert-
and side-channels are usually considered trivial to prevent by
simply disabling hyperthreading; and 2) It is relatively easier
to colocate two VMs on the same package, as opposed to the
same core.
it
The ﬁrst assumption is prima facie true, but not without
side-effects in that
impacts both end-user total cost of
ownership (TCO) and performance. For example, benchmark-
ing ﬂoating point intensive applications with SMT enabled
typically degrades performance because of competition for
limited ﬂoating point unit resources [8], [19]. In these cases,
disabling hyperthreading may be a good option to improve
performance. However, even when SMT is disabled in the VM
the hypervisor is free to schedule it as a hyperthread on the
processor.
Dedicated instances are offered as solutions ensuring that
the hardware
a user’s application is physically isolated at
level from VMs belonging to other accounts [5]. In turn, this
yields a higher TCO due to the cloud provider’s increased
operational expenses incurred for allocating the dedicated
hardware. In the past Microsoft Azure completely disabled
hyperthreading by default, but has recently moved towards of-
fering hyperthreaded VMs for general purpose workloads [22].
Similarly, the majority of Amazon EC2 and GCE instances
come with SMT enabled. This implies, along with Azure’s shift
to offering SMT VMs, that decreasing the cost of operational
expenses outweighs the need to manage speciﬁc workloads
causing performance degradation. Hyperthreading is expected
to become more popular on IaaS platforms in the near future
in order to keep them affordable.
We address the second assumption by demonstrating a
new SMT-based covert channel on both the Amazon EC2 and
GCE IaaS platform. We show that it is capable of detecting
multi-tenancy with equivalent success rate to other cross core
multi-tenant detection schemes at comparable cost. Using two
Wang & Lee [37]
SMT/FU
SMT/Cache
spec. load
BTB
BPU
Aciic¸mez et al [4]
Hunger et al [24]
Xu et al [39]
Ristenpart et al [34]
Wu et al [38]
Maurice et al [28]
This work
† Authors present a discussion that isolation through a hypervisor is not sufﬁcient to prevent the described covert channel and side channels, but provide no metrics on their
LL Cache
L2 Cache
LL Cache
LL Cache
Store buffer
100 kbps
3.2 bps
0.2 bps
346 bps‡
751 bps
1.28∗ & 1.49∗∗ Mbps
Bitrate
500 kbps
3.2 Mbps
200 kbps
N/L
†
†
†
N/L
N/L
N/L
21%
45.2%
9.3%
N/L
0.39%‡
5.7%
< 8.7%
TABLE I: Comparison of side and covert channels. Approaches with N/L in a ﬁeld do not list that particular metric.
Method
Shared Resource
Covert Channel
Side Channel
Col. Detect.
Error rate
VM SMT
bandwidth or error rate in a cloud environment.
‡ Best case scenario metrics in a cloud environment.
∗ Amazon EC2.
∗∗ Google Computer Engine (GCE).
cooperating accounts, we demonstrate multi-tenant detection
after launching 14 instance pairs on EC2 and 12 instance
pairs on GCE using the placement strategies outlined in [36].
We further demonstrate that our SMT covert channel results
in a 15x increase in channel capacity compared to other
demonstrated IaaS covert channels once multi-tenancy has
been established.
4K-Aliasing. Our new covert communication channel lever-
ages Intel’s memory ordering buffer (MOB). The MOB is an
intermediate pipeline buffer that resides between the execution
units and L1 data cache. It manages in-ﬂight reads and writes
that have not yet been written back to memory, henceforth
referred to as committed. Intel’s memory ordering model [9]
guarantees program consistency on all processor families that
execute instructions out of program order. However, out-of-
order (OoO) execution causes several common data hazards
such as when a later1 write passes an earlier load [write-after-
read (WAR)] or a later read passes an earlier write [read-after-
write (RAW)]. As memory reads and writes are speculatively
executed the MOB is checked prior to when an instruction is
retired. When a data hazard is detected the instructions can
be re-issued safely as the contents of the MOB have not yet
been committed, otherwise they can be written to memory as
normal.
We use a side-effect of managing the write-after-read data
hazard by the MOB called 4K-aliasing. WAR hazards occur
when the address of a speculatively executed younger write is
found to alias with an older read. The hazard is detected during
memory disambiguation prediction by comparing the lower
12-bits of every load and store in the MOB. Upon a match,
the load is re-issued with an associated performance penalty.
However, a read address separated from a write by 4 KB
will falsely match. We demonstrate that the falsely matching
4K-aliasing event incurs a deterministic performance penalty
measureable across processes.
Contributions. To the best of our knowledge we are the ﬁrst
to investigate 4K-aliasing as a covert channel. We therefore
extensively evaluate the associated timing and noise character-
istics under ideal, single process conditions before moving on
to isolated processes across cores, and then VM instances on
1We use the terms later and earlier to refer to program order.
IaaS public clouds. We demonstrate a robust covert channel on
both Amazon EC2 and GCE clouds with a low bit error rate
and channel capacity of 1.28 Mbps and 1.49 Mbps respectively.
We further present a case-study on multi-tenancy detection on
EC2 after launching 14 cooperative instance pairs, and on GCE
after launching 12 cooperative instance pairs.
The remainder of the paper is organized as follows: In
Section II we overview related works and provide comparisons
with our 4K-aliasing timing channel. In Section III we estab-
lish the background and basis for 4K-aliasing. In Section IV
we characterize the 4K-aliasing channel in a single process
scenario. In Section V we present both a simple and robust 4K-
aliasing covert communication channel. Section VI provides a
case study when the 4K-aliasing covert channel is deployed on
both Amazon EC2 and GCE. Section VII describes our multi-
tenancy detection experiment and results. In Section VIII we
analyze possible mitigations. Finally, Section IX concludes and
provides directions for future work.
II. RELATED WORKS
A. Shared Resources Timing Channels
There have been several side-channels leveraging con-
tention between functional unit resources while hyperthread-
ing. Wang and Lee [37] demonstrated a covert channel due
to exception handling during control speculation on loads
using the IA-64 ISA. Aciic¸mez and Seifert [4] show that
hardware threads contending for a shared multiplier can form
the basis for a side-channel capable of distinguishing mul-
tiplications from squarings in OpenSSL’s implementation of
RSA. Andrysco et al. [6] implement a timing attack capable
of rendering victim web pages through the Firefox browser
caused by ﬂoating-point unit slowdown when operating on
subnormal values.
Timing channels caused by contention for the branch
prediction or branch target buffer (BTB) also leverage hy-
perthreading. Aciic¸mez et al. [2] demonstrated that RSA
encryption keys can be partially recovered by monitoring
execution latency after evicting branch target addresses in the
BTB. Recently Evtyushkin et al. [15] demonstrated that BTB
collisions could be exploited to leak kernel space addresses
to break kernel address space layout randomization. Hunger
et al. [24] demonstrate a covert channel based on the branch
predictor as opposed to the BTB.
2
Hund et al. [23] and Gruss et al. [20] both use contention
in the translation lookaside buffer (TLB) to defeat kernel
address space layout randomization. While not reliant upon
hyperthreading,
their work leverages the core-private TLB
which is a shared resource in that it saves address translation
data across isolated security domains, namely kernel-space and
user-space addresses. Similarly, Aciic¸mez [1] and Aciic¸mez
and Schindler [3] both demonstrate a PRIME + PROBE style
attack using the instruction cache by ﬁlling it with dummy in-
structions, and then timing their re-execution after preemption
from an RSA process. Osvik et al. [30] use memory access
patterns in the L1 data cache to fully extract an AES key from
a victim process. The work is extended in [35] by Tromer et al.
Yarom et al. [42] demonstrate complete private key recovery
against a constant time RSA implementation using L1 data
cache bank collisions.
B. Covert Communication Channels
Xu et al. [39] demonstrate a covert channel using shared
last level caches between cooperating VMs on Amazon EC2
with a bit rate of 3.2 bps and error rate of 9.3% on average.
This improved upon a prior public cloud covert channel by
Ristenpart et al. [34], which reported a bit rate of 0.2 bps using
the shared L2 data cache. Wu et al. improve upon both schemes
using atomic operations on last level caches to induce memory
bus transactions in [38]. In house experiments by the authors
observe a channel transmission rate of around 750 bps with
an error rate of 0.09%. When deploying to an EC2 instance
under best conditions the channel presents a transmission rate
of 343.5 bps with an error rate of 0.39%. Under heavy noise
conditions the channel presents a similar transmission rate but
the error increases to 21.56%. The authors then change the
protocol for better error handling effectively lowering the data
transmission rate to about 110 bps but an improved error rate
of 0.75%. Maurice et al. [28] again target the shared last level
cache, but address the uncertainty of which cache lines the
cooperating parties should transmit upon using inclusiveness.
In doing so, they achieve a bit rate of 751 bps in a virtualized
environment.
C. Multi-Tenancy Detection and Placement
The ﬁrst work to demonstrate multi-tenant detection
mapped externally available VM instance IP addresses to
their internal IP addresses, allowing them to topologically
map the data center and then colocate malicious VMs next