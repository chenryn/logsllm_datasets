Certainly! Below is the optimized version of your text, aiming for clarity, coherence, and a professional tone:

---

Our protocol is built upon the functionalities \( F_{\text{Com}}^{(t,n)} \) and \( F_{\text{RDL,Com-ZK}}^n \). We assume that secure instantiations of these functionalities are available. Our analysis focuses on the remaining attack vectors, which involve corrupted parties supplying inconsistent inputs to these functionalities, potentially leading to the generation of signatures for unexpected messages or the leakage of information about the honest parties' secrets. Specifically, we will argue that if inconsistent inputs are supplied to these functionalities, the consistency checks will fail, and the remaining honest party will abort with overwhelming probability.

We can categorize the attacks into two main subclasses: inconsistent inputs to the instance key exchange and inconsistent inputs to the secret key multiplication.

### Inconsistent Inputs to Instance Key Multiplication

Recall that in their interactions with \( F_{\text{Mul}}^{(t,n)} \), the pool of corrupted parties is represented by an ideal adversary \( S_{\text{P}^*} \), which submits a single unified input for the entire pool. Let \( k_{\text{P}^*} \) be the first value in the batch supplied by \( S_{\text{P}^*} \) in step 2 of \( \pi_{\text{ECDSA-Sign}}^{(t,n)} \), and let \( \varphi_{\text{P}^*} \) be the product of the values submitted by the corrupt parties to \( F_{\text{Com}}^n \) in step 1. Define the error value \( e_a \) such that \( \varphi_{\text{P}^*} / k_{\text{P}^*} + e_a \) is the second input in the batch supplied by \( S_{\text{P}^*} \) to \( F_{\text{Mul}}^{(t,n)} \) in step 2. Let \( u_{\text{P}^*} \) and \( v_{\text{P}^*} \) be the unified (summed) outputs corresponding to the first and second inputs, respectively. This yields:
\[
u_h + u_{\text{P}^*} = k_h \cdot k_{\text{P}^*}
\]
\[
v_h + v_{\text{P}^*} = \frac{\varphi_h \cdot \varphi_{\text{P}^*}}{k_h \cdot k_{\text{P}^*}} + \varphi_h \cdot e_a
\]

For the first consistency check to pass, it must be the case that \( v_h \cdot R + \Gamma_1^{\text{P}^*} = \varphi \cdot G \). If and only if \( e_a = 0 \), the adversary can compute \( \Gamma_1^{\text{P}^*} \) such that this is true. Otherwise, the adversary must compute \( \Gamma_1^{\text{P}^*} = v_{\text{P}^*} \cdot R - \varphi_h \cdot e_a \cdot R \), where \( \varphi_h \) is uniform and revealed to the adversary only after \( \Gamma_1^{\text{P}^*} \) is committed. Therefore, the adversary can do no better than guessing, and with overwhelming probability, the check message will not verify, causing \( P_h \) to abort.

### Inconsistent Inputs to Secret Key Multiplication

Suppose all values are defined as above, and \( \text{ski} \) is the correct value given \( P_i \)'s Shamir share \( p(i) \) (itself defined as the output of the setup protocol). Suppose further that some individual corrupted party \( P_i^* \) supplies a batched input \( \{ \text{ski} + \text{esk}, v_i + e_v \} \) when invoking \( F_{\text{2PMul}}^{(t,n)} \) with \( P_h \) in step 4 of \( \pi_{\text{ECDSA-Sign}}^{(t,n)} \), receiving as output \( \{ w_{h,1}^i, w_{h,2}^i \} \). For simplicity, we assume only one corrupted party induces an offset, though the argument applies equally well to multiple corrupted parties. This yields:
\[
w_{\text{P}^*} = \text{sk}_{\text{P}^*} \cdot v_{\text{P}^*} + \sum_{i \in \text{P}^*} (w_{h,1}^i + w_{h,2}^i)
\]
where \( w_{\text{P}^*} \) is a unified (summed over the corrupt parties) version of the output specified in step 5 of \( \pi_{\text{ECDSA-Sign}}^{(t,n)} \). This yields the relation:
\[
w_h + w_{\text{P}^*} = \frac{\text{sk} \cdot \varphi}{k} + \text{esk} \cdot \varphi_h + e_v \cdot \text{sk}_h
\]

If \( \text{esk} \neq 0 \), the adversary can only pass the second consistency check by computing the corrupted parties' values such that their sum \( \Gamma_2^{\text{P}^*} \) is:
\[
\Gamma_2^{\text{P}^*} = v_{\text{P}^*} \cdot \text{pk} + w_{\text{P}^*} \cdot G - \text{esk} \cdot \varphi_h \cdot G
\]
where the adversary knows \( R_h = k_h \cdot G \), but neither \( k_h \) nor \( \varphi_h \), both of which are uniform. As before, \( \varphi_h \) is revealed to the adversary only after \( \Gamma_2^{\text{P}^*} \) is committed, and therefore \( P_h \) will abort with overwhelming probability when \( \text{esk} \neq 0 \).

If \( e_v \neq 0 \), the adversary can only pass the third consistency check by computing the corrupted parties' values such that their sum \( \Gamma_3^{\text{P}^*} \) is:
\[
\Gamma_3^{\text{P}^*} = w_{\text{P}^*} \cdot R - e_v \cdot \text{sk}_h \cdot R
\]
where the adversary knows:
\[
\text{sk}_h \cdot G = \text{pk} - \sum_{i \in \text{P}^*} \text{ski} \cdot G
\]
but does not know \( \text{sk}_h \) itself. Computing \( \text{sk}_h \cdot R \) given only \( R \) and \( \text{sk}_h \cdot G \) is a direct violation of the Computational Diffie-Hellman Assumption, and therefore under that assumption, \( P_h \) will abort with overwhelming probability when \( e_v \neq 0 \).

This covers all opportunities available to an adversary for supplying inconsistent inputs. We conclude that if the adversary does so, it will fail at least one of the checks, assuming the Computational Diffie-Hellman Problem is hard in the elliptic curve group \( G \). A formal treatment of security can be found in the full version.

### Round Count

For readability, we expressed the protocol \( \pi_{\text{ECDSA-Sign}}^{(t,n)} \) in individual steps, but many of these can be collapsed in practice to reduce the number of rounds. The process of committing to \( \varphi_i \) for \( i \in P \) is independent of and can be performed simultaneously with the first round of preprocessing for \( \pi_{\text{Mul}}^{(t,n)} \), and the preprocessing for all instances of \( \pi_{\text{2PMul}} \) can be moved forward to occur at the same time. The round-count optimization originally described in Section III can be applied, reducing the remaining rounds required by \( \pi_{\text{2PMul}} \) to \( \log(t) \). Following this, a single round is required to complete all instances of \( \pi_{\text{2PMul}} \) simultaneously. The process of committing to \( R_i \) and an associated proof of knowledge for \( i \in P \) is independent of the secret key multiplication and can be performed immediately after \( \pi_{\text{2PMul}} \) completes. Another round is required to decommit, and two more to commit to and then release the check messages. Finally, the last round is used to swap shares of the signature. Thus, the total round count for ECDSA signing comes to \( \log(t) + 6 \).

### Cost Analysis

In Table I, we provide an accounting of the communication costs for our ECDSA setup and signing protocols, and in Table II, we account for the costs of our multiplication protocols. Our equations assume that elements from \( \mathbb{Z}_q \) are represented in \( \kappa \) bits, and that curve points are transmitted with point compression and thus are represented in \( \kappa + 1 \) bits. We assume that commitments require transmission of a single element from \( \mathbb{Z}_q \), that decommitments consist simply of the committed values, and that zero-knowledge proofs of knowledge of discrete logarithm comprise two curve points and a single element from \( \mathbb{Z}_q \), along with the point for which knowledge of discrete logarithm is to be proven.

The signing protocol \( \pi_{\text{ECDSA-Sign}}^{(t,n)} \) contains one execution of the \( \pi_{\text{2PMul}} \) protocol for each pair of parties with \( \lambda = 4 \); see Section VII for a discussion of the optimization that allows this, as opposed to the two executions each with \( \lambda = 2 \) that would be suggested by the protocols as previously described. Each party that participates in the signature must broadcast commitments and decommitments to \( \varphi_i \), \( R_i \), a proof of knowledge of discrete logarithm for \( R_i \), and check messages \( \Gamma_1^i \), \( \Gamma_2^i \), and \( \Gamma_3^i \). Finally, each party must broadcast its signature share \( \text{sig}_i \). The commitments are coalesced such that only three calls to \( F_{\text{Com}}^n \) are required, each adding \( \kappa \) bits of communication to the cost of the value committed.

For the setup protocol \( \pi_{\text{Setup}}^{(t,n)} \) and (by proxy) \( \pi_{\text{Mul}}^{(t,n)} \), the bulk of the communication cost comes from the initialization of OT-extensions, which will later be used by \( \pi_{\text{2PMul}} \). The only other elements transmitted during setup are polynomial points \( p_j(i) \) from every party \( P_j \) to every \( P_i \), and for every \( P_i \) a commitment and decommitment to the curve point \( T_i \) and a corresponding proof of knowledge of \( T_i \)'s discrete logarithm.

Concretely, for \( \kappa = 256 \), \( s = 80 \), and \( \kappa_{\text{OT}} = 128 + s \) (an additional security parameter for OT-extension [29]), the communication cost for signing is roughly \( 64.7 \cdot t \cdot (t - 1) \) kilobytes, and for setup roughly \( 20.5 \cdot n \cdot (n - 1) + 0.1 \cdot n \) kilobytes. As an example, for \( n = 16 \) and \( t = 8 \), setup requires 15291 KB of communication and signing requires 3571 KB.

### Implementation

We created proof-of-concept implementations of our \( t \)-of-\( n \) setup and signing protocols in the Rust language, derived from the open-source 2-of-\( n \) implementations of Doerner et al. [1]. Our implementation uses the secp256k1 curve, as standardized by NIST [5]. For all benchmarks, \( \kappa = 256 \); additionally, we chose \( s = 80 \). We instantiated the \( F_{\text{COTe}}^\eta \) functionality using the protocol of Keller et al. [29] and set the OT-extensions security parameter \( \kappa_{\text{OT}} = 128 + s \), following their analysis. We chose, as Doerner et al. did, to instantiate \( F_{\text{RDL,Com-ZK}}^n \) via the Fiat-Shamir Heuristic (though we note that this transform is not UC-secure), and to instantiate the PRG, the random oracle \( H \), and the commitment functionality \( F_{\text{Com}}^n \) via SHA-256. Consequently, our protocol uses the same concrete hash function as specified in the ECDSA standard.

We note that while the folkloric hash-based instantiation of \( F_{\text{Com}}^n \) (i.e., \( H(m \| r) \) where \( m \) is the message, and \( r \leftarrow \{0, 1\}^\kappa \)) requires a random nonce to be appended to the message to hide the message regardless of its distribution, in our protocol, all committed messages have sufficient entropy that the nonce can be omitted.

Unlike Doerner et al., we do not parallelize vectors of hashing operations. Instead, each party parallelizes its interactions with its counterparties (and the computations they require) using a number of threads equal to the number of parties or a specified maximum, whichever is smaller. Additionally, the pairwise OT-extension initialization required by our setup protocol is parallelized among a number of threads equal to the number of parties. While we have assumed throughout this paper that the setup protocol can parallelize key-generation and OT-extension initialization, our implementation runs these two phases sequentially, and thus the practical round count is increased from five to eight.

In our signing protocol, as described in Section V, the parties instantiate both the \( F_{\text{2PMul}} \) and \( F_{\text{Mul}}^{(t,n)} \) functionalities with batch sizes of \( \lambda = 2 \). Within the \( \pi_{\text{Mul}}^{(t,n)} \) protocol that realizes \( F_{\text{Mul}}^{(t,n)} \), \( F_{\text{2PMul}} \) is instantiated a second time by all pairs of parties, again with a batch size \( \lambda = 2 \). Observe that the preprocessing for both sets of \( F_{\text{2PMul}} \) instances can be performed simultaneously, and when \( \pi_{\text{2PMul}} \) is used to realize \( F_{\text{2PMul}} \), it is feasible for the parties to provide inputs and produce outputs for each element in a batch independently. In our implementation, we combine the batches and use only a single instance of the \( \pi_{\text{2PMul}} \) protocol for each pair of parties, with a batch size \( \lambda = 4 \). This allows us to perform only one OT-extension operation, thereby saving the overhead associated with a second.

We benchmarked our implementation using a set of Google Cloud Platform n1-highcpu-8 nodes, each running Ubuntu 18.04 with kernel 4.15.0. Each node of this type has four physical cores clocked at 2.0 GHz and is capable of executing eight threads simultaneously. These machines are slightly slower than those used by Doerner et al. [1], and thus the timings we report for their protocol are slightly slower than they report themselves. Each party participating in a benchmark was run on a separate node.

### Benchmarking Parameters

- **n/t Range**: [2, 8], (8, 16]
- **n/t Step**: 1
- **Samples (Signing)**: 100
- **Samples (Setup)**: 100

---

This should make the text more clear, coherent, and professional.