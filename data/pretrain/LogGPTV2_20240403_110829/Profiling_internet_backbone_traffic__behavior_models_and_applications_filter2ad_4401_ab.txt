1.6
1.4
1.2
1
0.8
0.6
0.4
0.2
)
%
(
l
d
o
h
s
e
r
h
t
e
v
i
t
p
a
d
A
Total values
Significant values
50
100
150
Time
200
250
300
106
105
104
103
102
101
0
s
r
e
l
t
s
u
c
P
I
t
s
d
Total values
Significant values
Total values
Significant values
106
105
104
103
102
101
s
r
e
l
t
s
u
c
t
r
o
P
c
r
s
50
100
150
Time
200
250
300
0
50
100
150
Time
200
250
300
106
105
104
103
102
101
0
s
r
e
l
t
s
u
c
t
r
o
P
t
s
d
Total values
Significant values
50
100
150
Time
200
250
300
(a) srcIP dimension
(b) dstIP dimension
(c) srcPrt dimension
(d) dstPrt dimension
0.2
0.18
0.16
0.14
0.12
0.1
0.08
0.06
0.04
0.02
)
%
(
l
d
o
h
s
e
r
h
t
e
v
i
t
p
a
d
A
)
%
(
l
d
o
h
s
e
r
h
t
e
v
i
t
p
a
d
A
1
0.8
0.6
0.4
0.2
2
1.8
1.6
1.4
1.2
1
0.8
0.6
0.4
0.2
)
%
(
l
d
o
h
s
e
r
h
t
e
v
i
t
p
a
d
A
0
0
50
100
150
Time
200
250
300
0
0
50
100
150
Time
200
250
300
0
0
50
100
150
Time
200
250
300
0
0
50
100
150
Time
200
250
300
(e) srcIP dimension
(f) dstIP dimension
(g) srcPrt dimension
(h) dstPrt dimension
Figure 1: The total number of distinct values and signiﬁcant clusters extracted from four feature dimensions of L1 over a one-
day period (top row). The corresponding ﬁnal cut-oﬀ threshold obtained by the information-based signiﬁcant cluster extraction
algorithm (bottom row).
To see what S contains, order the feature values of A based
on their probabilities: let ˆa1, ˆa2, . . . , ˆan be such as PA(ˆa1) ≥
PA(ˆa2) ≥ ···PA(ˆan). Then S = {ˆa1, ˆa2, . . . , ˆak−1} and
R = A − S = {ˆak, ˆak+1, . . . , ˆan} where k is the smallest
integer such that RU (PR) > β. Let α
∗
∗
= ˆak−1. Then α
is the largest “cut-oﬀ” threshold such that the (conditional)
probability distribution on the set of remaining values R is
close to being uniformly distributed.
Algorithm 1 Entropy-based Signiﬁcant Cluster Extraction
1: Parameters: α := α0; β := 0.9; S := ∅;
2: Initialization: S := ∅; R := A; k := 0;
3: compute prob. dist. PR and its RU θ := RU (PR);
4: while θ ≤ β do
5:
6:
7:
8:
9:
10:
11:
12: end while
end if
end for
compute (cond.) prob. dist. PR and θ := RU (PR);
α = α × 2−k; k + +;
for each ai ∈ R do
if PA(ai) ≥ α then
S := S ∪ {ai}; R := R − {ai};
Algorithm 1 presents an eﬃcient approximation algorithm2
(in pseudo-code) for extracting the signiﬁcant clusters in S
from A (thereby, the clusters of ﬂows associated with the
signiﬁcant feature values). The algorithm starts with an ap-
propriate initial value α0 (e.g., α0 = 2%), and searches for
∗
the optimal cut-oﬀ threshold α
from above via “exponential
approximation” (reducing the threshold α by an exponen-
tially decreasing factor 1/2k at the kth step). As long as
the relative uncertainty of the (conditional) probability dis-
2An eﬃcient algorithm using binary search is also devised,
but not used here.
tribution PR on the (remaining) feature set R is less than
β, the algorithm examines each feature value in R and in-
cludes those whose probabilities exceed the threshold α into
the set S of signiﬁcant feature values. The algorithm stops
when the probability distribution of the remaining feature
values is close to being uniformly distributed (> β = 0.9).
∗
Let ˆα
be the ﬁnal cut-oﬀ threshold (an approximation to
∗
α
) obtained by the algorithm.
Our algorithm adaptively adjusts the “cut-oﬀ” threshold
∗
ˆα
based on the underlying feature value distributions to ex-
tract signiﬁcant clusters. Fig. 1 presents the results we ob-
tain by applying the algorithm to the 24-hour packet trace
collected on L1, where the signiﬁcant clusters are extracted
in every 5-minute time slot along each of the four feature
dimensions. In the top row we plot both the total number
of distinct feature values as well as the number of signiﬁ-
cant clusters extracted in each 5-minute slot over 24 hours
for the four feature dimensions (note that the y-axis is in log
scale). In the bottom row, we plot the corresponding ﬁnal
cut-oﬀ threshold obtained by the algorithm. We see that
while the total number of distinct values along a given di-
mension may not ﬂuctuate very much, the number of signif-
icant feature values (clusters) may vary dramatically, due to
changes in the underlying feature value distributions. These
changes result in diﬀerent cut-oﬀ thresholds being used in
extracting the signiﬁcant feature values (clusters). In fact,
the dramatic changes in the number of signiﬁcant clusters
(or equivalently, the cut-oﬀ threshold) also signiﬁes major
changes in the underlying traﬃc patterns.
To provide some speciﬁc numbers, consider the 15th time
slot. There are a total of 89261 distinct srcIP’s, 79660
distinct dstIP’s, 49511 srcPrt’s and 50602 dstPrt’s. Our
adaptive-threshold algorithm extracts 117 signiﬁcant srcIP
clusters, 273 dstIP clusters, 8 srcPrt clusters and 12 dstPrt
clusters, with the resulting cut-oﬀ threshold being 0.0625%,
0.03125%, 0.25% and 1%, respectively. We see that the num-
ber of signiﬁcant clusters is far smaller than the number of
∗
feature values n, and that the cut-oﬀ thresholds ˆα
for the
diﬀerent feature dimensions also diﬀer. This shows that no
single ﬁxed threshold would be adequate in the deﬁnition of
“signiﬁcant” behavior clusters.
4. CLUSTER BEHAVIOR CLASSIFICATION
In this section we introduce an information-theoretic ap-
proach to characterize the “behavior” of the signiﬁcant clus-
ters extracted using the algorithm in the previous section.
We show that this leads to a natural behavior classiﬁcation
scheme that groups the clusters into classes with distinct
behavior patterns.
4.1 Behavior Class Deﬁnition
Consider the set of, say, srcIP, clusters extracted from
ﬂows observed in a given time slot. The ﬂows in each clus-
ter share the same cluster key, i.e., the same srcIP address,
while they can take any possible value along the other three
“free” feature dimensions. Hence the ﬂows in a cluster in-
duce a probability distribution on each of the three “free”
dimensions, and thus a relative uncertainty measure can be
deﬁned. For each cluster extracted along a ﬁxed dimension,
we use X, Y and Z to denote its three “free” dimensions,
using the convention listed in Table 2. Hence for a srcIP
cluster, X, Y , and Z denote the srcPrt, dstPrt and dstIP
dimensions, respectively. This cluster can be characterized
by an RU vector [RUX , RUY , RUZ ].
Table 2: Convention of free dimension denotations.
Cluster key
Free dimensions
srcIP
dstIP
srcPrt
dstPrt
X
srcPrt
srcPrt
dstPrt
srcPrt
Y
dstPrt
dstPrt
srcIP
srcIP
Z
dstIP
srcIP
dstIP
dstIP
In Fig. 2(a) we represent the RU vector of each srcIP
cluster extracted in each 5-minute time slot over a 1-hour
period from L1 as a point in a unit-length cube. We see
that most points are “clustered” (in particular, along the
axises), suggesting that there are certain common “behavior
patterns” among them. Fig. 3 shows similar results using
the srcIP clusters on four other links. This “clustering”
eﬀect can be explained by the “multi-modal” distribution of
the relative uncertainty metrics along each of the three free
dimensions of the clusters, as shown in Figs. 2(b), (c) and
(d) where we plot the histogram (with a bin size of 0.1) of
RUX , RUY and RUZ of all the clusters on links L1 to L5
respectively. For each free dimension, the RU distribution
of the clusters is multi-modal, with two strong modes (in
particular, in the case of srcPrt and dstPrt) residing near