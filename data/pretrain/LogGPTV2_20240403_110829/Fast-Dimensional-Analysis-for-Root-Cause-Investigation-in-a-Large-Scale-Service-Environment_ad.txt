0
Runtime (seconds) 
	150
Number of item-sets
Fig. 3. Runtime of Apriori at different thread counts, based on the ASE dataset.In Figure 4, we compare the runtime of Apriori [2], parallelized Apriori, and FP-Growth [3, 6, 13, 18, 25], at different number of item-sets. Note that the 9-thread configuration from Figure 3 is used as the multi-threaded case here. It is clear that FP-Growth outperforms single-threaded and multi-threaded Apriori, except when the number of item-sets is small, as the overhead of setting up the FP-Growth algorithm (see Section 3.3) is larger than the benefit of not running Apriori’s candidate generation step. However, in our experiments, FP-Growth is never slower for more than 1 second. The runtime difference could become more significant when this RCA framework is deployed on a resource-limited platform, such as an embedded system. In Figure 4b, we see that for the SR dataset, Apriori can be faster when the number of item-sets is smaller than 10000, which happens when max-length < 4 or (max-length = 4 and min-support ≥ 0.8). For the ASE dataset, multi-threaded Apriori is faster than FP-Growth when the number of item-sets is smaller than 2000, which happens when min-support ≥ 0.4. For a given dataset, running an initial scan over the algorithms, lengths, and supports can help optimize the choice of algorithm and min-support.4.2 	Interpretability Improvement
As described in Section 3.1, lift is used when filtering the mined frequent item-sets based on their ability in deciding whether a sample satisfying the item-set would be positive (e.g. be in the target failure states). Figure 5a shows the number of association rules given different min-lift thresholds on the ASE dataset, when min-support is set to 0.4 and max-length is set to 5.There is a clear drop after min-lift = 1, which indicates rules that are stronger than randomness. The number of association rules remains constantly at 6 when min-lift is between 2.7 and 7.9. In practice, we can set the min-lift to anywhere between 2.7 and 7.9 to output these 6 rules as the potential root causes, as they are the relatively stronger and more stable rules in the dataset. TheProc. ACM Meas. Anal. Comput. Syst., Vol. 4, No. 2, Article 31. Publication date: June 2020.
31:16 	Lin, et al.
(a) ASE dataset
(b) SR dataset
Fig. 4. Analysis runtime vs. number of item-sets.
triangle marker indicates when an example actionable insight appears at the highest min-lift value (more discussions in Section 5.1).Figure 5b shows the same analysis based on the SR dataset, with min-support set to 0.5 and max-length set to 5. The number of association rules reported drops significantly in several steps. This is because there does not exist a clear convergence point for different max-length values, as seen in Figure 2b, many of the reported association rules actually describe the same underlying rules, and therefore are filtered out together as min-lift increases. The triangle marker shows when an example actionable insight appears at the highest min-lift value (more discussions in Section 5.2). Compared to the ASE dataset, the lift is much larger in the SR dataset.To understand the larger trend across all association rules in the ASE dataset, we consider more item-sets by lowering min-support to 0.1. An exponentially decreasing trend can be observed in Figure 6. For reference, we kept the same triangle marker at min-lift = 7.9, representing a highly
Proc. ACM Meas. Anal. Comput. Syst., Vol. 4, No. 2, Article 31. Publication date: June 2020.| Fast Dimensional Analysis for Root Cause Investigation | Fast Dimensional Analysis for Root Cause Investigation | Fast Dimensional Analysis for Root Cause Investigation | Fast Dimensional Analysis for Root Cause Investigation | Fast Dimensional Analysis for Root Cause Investigation | Fast Dimensional Analysis for Root Cause Investigation | 31:17 |
|---|---|---|---|---|---|---||---|---|---|---|---|---|---|
| Number of association rules |80 | | | | |31:17 |
| Number of association rules |60 | | | | |31:17 |
| Number of association rules |40 | | | | |31:17 |
| Number of association rules |20 | | | | |31:17 |
| Number of association rules |0 | | | | |31:17 |
| 2 |2 |2 |4 |6 |8 |31:17 |
Min-lift
(a) ASE dataset
| Number of association rules | 40 |  |  |  |  |  ||---|---|---|---|---|---|---|
| Number of association rules |30 | | | | | |
| Number of association rules |20 | | | | | |
| Number of association rules |10 | | | | | |
| Number of association rules |0 | | | | | |
| Number of association rules |0 |5000 |10000 |15000 |20000 |25000 |
Min-lift
(b) SR dataset
Fig. 5. Number of reported association rules vs. min-lift threshold. The triangle marks when a target ruleappears in the use cases discussed in Section 5.
actionable insight confirmed by service engineers. This graph also illustrates the importance of setting a sufficiently high min-support to reduce noise. When using min-support 0.4 derived from Figure 5a, we have six rules above lift 7 compared to 1200 for min-support 0.1.With the two post-processing filters described in Section 3.6, at max-length = 5 and min-lift = 1, we kept only 2% and 26% of the mined rules from the ASE dataset when min-support is 0.1 and 0.4, while we kept only 0.4% and 1% of the mined rules from the SR dataset when min-support is 0.1 and 0.5. The post-processing reduces the number of mined association rules significantly without losing the important root cause information, which makes the output report much easier for human to examine and debug quickly. While the work in [18] integrates the FP-Growth algorithm with the Spark platform for processing large datasets and uses lift for pruning mined item-sets, it did not provide well-formulated post-processing steps or characterize the relationship between min-lift and the mined item-sets.4.3 	Lessons Learned
While the results presented in this paper demonstrate effective RCA, in practice, the relationships between these parameters are highly dependent on the nature of the datasets. Therefore we present methods for optimizing the performance and interpretability. First of all, min-support is a variable
Proc. ACM Meas. Anal. Comput. Syst., Vol. 4, No. 2, Article 31. Publication date: June 2020.| 31:18 | Number of association rules | 2000 |  |  |  |  | Lin, et al. |
|---|---|---|---|---|---|---|---|
| 31:18 |Number of association rules |1500 | | | | |Lin, et al. |
| 31:18 |Number of association rules |1000 | | | | |Lin, et al. |
| 31:18 |Number of association rules |500 | | | | |Lin, et al. |
| 31:18 |Number of association rules |0 | | | | |Lin, et al. || 31:18 |Number of association rules |0 |50 |100 |150 |200 |Lin, et al. |
Min-lift
Fig. 6. Number of association rules at different min-lift thresholds based on the ASE dataset, when min-
support is set to 0.1. The triangle marks when a target rule appears in the use case discussed in Section 5.that controls how granular the reported rules would be. In a real-time analysis or debug, a lower max-length can be set to reduce runtime, and a higher min-support can be applied to report only the most dominant issues in the dataset. In a more thorough analysis that is less time-sensitive, a higher max-length can be applied to generate a set of rules that are overall more descriptive, based on the filtering criteria in Section 3.6.If there exists a clear convergence point given different max-lengths, a lower max-length should be used to avoid unnecessary computation. If the RCA application is very sensitive to runtime and the number of item-sets is small, one could first run the analysis similar to the one presented in Figure 4 and use multi-threaded Apriori in the region where it outperforms FP-Growth. 	The advantage of support and lift is that they are very interpretable and intuitive metrics that any service engineer can adjust. One intuition behind the lift value is to make sure we handle the edge case where a label value, e.g. specific failure states, has attribution X, and no other label values has attribution X.5 	USE CASE STUDY
The method discussed in this paper has been productionized in multiple hardware, software, and tooling applications in our large-scale service infrastructure. Deployment of this framework allows for fast root cause analysis as well as automatic alerting on new correlations in the datasets, which may indicate unexpected changes in the systems. In this section we present some of the applications and the insights (after sanitizing the data) that were extracted by the proposed framework.5.1 	Anomalous Hardware and Software ConfigurationsIn a large infrastructure, maintenance activities are constantly undertaken by the management system - for instance, we might need to provision new services on a particular server platform. In such scenarios, there might be reasons to reboot servers. One root cause example here is to detect whether all servers have booted back up after a maintenance event. Using our framework, we found a group of servers that failed to come back online as compared to the rest of the cohorts. Without our proposed root cause analysis, the issue was isolated to a combination of 1) a specific firmware version in one component, 2) a particular component model from a manufacturer, and 3) a particular server model, by experienced experts after hours of investigation.Proc. ACM Meas. Anal. Comput. Syst., Vol. 4, No. 2, Article 31. Publication date: June 2020.
Fast Dimensional Analysis for Root Cause Investigation 	31:19To emulate how the proposed fast dimensional analysis could have helped with the root cause analysis, we looked at the historical data and labeled the servers by whether the reboots were suc-cessful on them. For example, since the servers that stayed offline is our target of the investigation, we labeled them as positive, and the rest where the reboots were successful as negative. Then we compiled a dataset that joins the labels with about 20 attributes of the servers, such as the server model, the type of services the servers were running, firmware and kernel versions, component vendors/models/firmware versions. These attributes are where we expect to find potential cor-relations for distinguishing between the positive and negative samples. This is the first dataset presented in the experimental results in Section 4, i.e. the anomalous server event (ASE) dataset.With this dataset, the fast dimensional analysis framework identified the correlation based on exactly the three attributes in 2 seconds. The lift value where this target association rule shows up is marked by the triangle in Figure 5a. Through our methodology, we significantly reduced the investigation time from hours to seconds. Note that in this case, there were multiple combinations of feature values that correlate to the positive samples equally. For example, a combination of {firmware version, component model, server model} would show the same support and lift as a combination of {storage interface, component model, CPU model}, on this specific dataset. Purely based on this dataset, the algorithm would not be able to tell which combination is more useful given the type of failures. Further analysis can determine the most effective way to reduce the number of combinations reported, potentially based on the past reports. The reported combinations already provides strong correlations to the failures and an engineer with some experience can quickly conclude the issue from the report.5.2 	Anomalous Service Interactions
All the communications between backend services in our large-scale system are logged. This infor-mation is used to investigate errors in the communication among services, based on characteristics such as latency, timeouts, requests, responses, traffic (volume, source and destination regions). This is the second dataset, i.e. the service request (SR) dataset presented in the experimental results in Section 4.The naive investigation where engineers aggregate the various parameters through a group-by operation does not scale, as there are too many distinct combinations of the column values. We deployed the fast dimensional analysis framework to analyze two types of anomalous service interactions: errors and latency. The analysis quickly identified attributes of service communication that would lead to different types of errors and reported the findings. In one example for a globally distributed service, it was reported that the errors were caused only for communications between two specific geographical locations. This prompted engineers to investigate in this direction and fix the issue timely. An actionable insight based on {service type, build version} ⇒ failure is marked by the triangle in Figure 5.Latency is not discrete when compared to errors, hence we need to first bucketize latency values into a finite number of intervals, e.g. acceptable and non-acceptable latencies. The framework then identifies the combinations of features where requests have non-acceptable latencies. By tuning the bucketing threshold we obtained insightful correlations based on the features of the service requests, which are used to optimize the performance of the systems.5.3 	Failed Auto-Remediations
We deployed the fast dimensional analysis framework on the logs from an auto-remediation system [16, 17, 24] to quickly identify attributes of the remediation jobs that would lead to different types of exceptions, and report the correlations to a visualization dashboard that engineers use everyday for monitoring system health. For analyzing the correlations in auto-remediation jobs,Proc. ACM Meas. Anal. Comput. Syst., Vol. 4, No. 2, Article 31. Publication date: June 2020.
31:20 	Lin, et al.we prepare about 20 server attributes mentioned above, and join them with some basic information of the remediation jobs such as failure mode, remediation name, and owner of the remediation. 	Different from the previous example, where server reboots would either succeed or fail, the auto-remediation jobs could end up in different states. In addition to successfully fixing the issue, remediation jobs could end up as repair, i.e. the hardware failure needs a physical repair, escalate, i.e. the failure needs to be escalated to human even before the system creates a repair ticket for it, rate limited and retry, i.e. the remediation is temporarily suspended because there are too many servers going through remediation at the time, and exception, i.e. the job encounters some exception and could not finish.As the auto-remediation system serves hundreds of different remediations for a complex set of failure types, there are typically failed remediations, i.e. escalates and exceptions, in production. The problem formulation here is hence different. Instead of finding correlations to a single issue, as we did in root causing the failed reboots in the previous example, here we explore strong correlations among the many types of failures that are constantly happening. Since the auto-remediation system is centralized and processes the remediation of the entire whole of machines, a small portion of the overall remediations may mean the majority for a small service, and the service may actually have large impact to the entire service infrastructure. Therefore, in this setup we chose a much smaller threshold on support, and report all high-lift correlations to service owners for investigation. With this setup, we have been able to identify strong correlations such as {kernel version, service} ⇒exception and {service type, remediation name} ⇒ escalate, which helped engineers quickly identify and fix problems in the systems.The number of association rules reported at different min-lift values is plotted in Figure 7, where a target rule mentioned above, {service type, remediation name} ⇒ escalate, is found when min-lift is ≤ 270000, marked by the triangle.
60
20
0
Number of association rules 
	40
50000 	100000 150000 200000 250000 300000 350000
Min-lift
Fig. 7. Number of association rules at different min-lift thresholds based on the auto-remediation dataset.The triangle marks when a target rule appears in the use case.