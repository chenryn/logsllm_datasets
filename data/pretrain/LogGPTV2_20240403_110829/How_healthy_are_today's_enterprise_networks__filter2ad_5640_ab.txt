leaked potentially sensitive IP address information when tran-
sitioning from internal and VPN environments to external net-
works.
)
s
d
n
a
s
u
o
h
t
(
s
w
o
F
l
 150
 100
 50
 0
Figure 1: Network health from the endhost perspective (frac-
tion of successful ﬂows) is consistently low: ﬁgure shows health
(top) and total ﬂow volume (bottom).
3.1 Temporal Effects
Figure 1 plots the average hourly network health during the course
of our trace and also the time series of ﬂow volume seen. While
noisy, the health hovers around (a low) 66% despite very pronounced
diurnal and work-week patterns seen in the ﬂow volume. We were
very surprised to learn that this low number does not really trans-
late to users complaining about poor performance.
IT personnel
explained that most users are often unaware of what causes slug-
gish performance—network errors and bloated apps being two of
a very large number of probable causes—and consequently come
to passively expect mediocre performance or else feel that their
experience is “adequate for the purpose”. One redeeming obser-
vation, however, is that at least for web trafﬁc (ports 80, 88, 443,
8080) there is a positive correlation between health and activity (not
shown in the ﬁgure); failure rates for these ports are lower during
working hours.
3.2 Effect of the Environment
We ﬁnd the user’s environment has a noticeable impact on the
rate of failures: 34% of ﬂows fail when users are connected directly
to the enterprise network (wired or wireless), compared to a stag-
gering 57% when users are logged in through the VPN. In contrast,
17% fail when users are outside and not connected to the VPN. We
believe that these numbers would be lower in other enterprise net-
works that have stricter “lockdown” policies for endhosts. In our
own network, users are free to install arbitrary applications1 and
consequently, the numbers we see are somewhat to be expected.
Looking only at outgoing connections, we see a very interesting
statistic: a signiﬁcant fraction (77%) of these failures occur within
the ﬁrst minute of the user acquiring a new IP address. The number
rises to 90% within the ﬁrst four minutes. Of the ﬂows failing in
the ﬁrst minute, 87% are to destinations that the user had previously
successfully contacted a few minutes earlier (8 and a half minutes
in the median case). This is consistent with applications attempting
to reestablish connections broken by the user moving to a different
network environment, and failing to do so when the reachability of
the new network differs from that of the previous network2.
1There is however a (small) blacklist of applications, BitTorrent
among them, that users are not allowed to install.
2Transport layer migration of ﬂows [8] is unlikely to solve the
problem as the endpoints in the two networks are unreachable as
a matter of policy.
)
%
(
s
w
o
l
f
d
e
l
i
a
F
 100
 80
 60
 40
 20
 0
 0
CDF of all failures
Fraction failed per-user
 50
 100
 150
 200
 250
 300
 350
User (#)
Figure 2: The fraction of failed ﬂows varies wildly across users,
with a small number responsible for a disproportionate num-
ber of failures.
This behavior of attempting to reestablish connections can leak
sensitive information in external networks. For instance, 1969 in-
ternal IP address and port pairs were leaked to external networks. In
addition, over 63K DNS requests failed in external environments,
and although we do not have the query payload, it is highly likely
that several of these requests leaked internal hostnames. The num-
bers are cause for concern as, in many cases, applications intended
for internal use do not authenticate the server because the network
is assumed to be trusted; consequently, attackers on external net-
works can masquerade as trusted internal services by spooﬁng IP
addresses or DNS responses, and collect user credentials or launch
man-in-the-middle attacks. Table 1 tabulates the number of unique
instances where an application leaked at least an internal IP address
and port information when transitioning from the internal network
or VPN to an external network.
3.3 Users and Applications
The fraction of failures varies widely for individual users as il-
lustrated in Figure 2. The ﬁgure plots users ranked in decreasing
order of the fraction of failed ﬂows to/from their endhost; the CDF
(solid line) in the same ﬁgure tracks the contribution of speciﬁc
users to the total failures seen in the traces. Thus, the ﬁrst user sees
84% failures personally, which accounts for about 6.7% of total
failures. As is clear in the ﬁgure, the top 1% users are responsi-
ble for a disproportionate 15% of all failures, which we attribute to
misconﬁgured applications as explained below.
Turning our attention now to applications we ﬁnd that ten appli-
cations are responsible for 73% of all failures observed. In Figure 3,
we quantify the failure rates associated with these ten applications.
Fraction failed per-application
CDF of all failures
(Most Users)
(Few Users)
 300
 280
 260
 240
 220
 200
 180
 160
 140
 120
 100
 80
 60
 40
 20
)
#
(
r
e
s
U
User #220
Soft.
Patch
HTTP
AV
Update
DNS HTTPS Web
Proxy
Net-
BIOS
Perf.
Mon.
DB
Mon.
Music
Sharing
02/03
02/10
02/17
02/24
Date
)
%
(
s
w
o
l
f
d
e
l
i
a
F
 100
 80
 60
 40
 20
 0
Figure 3: Ten applications with highest failure rates. They in-
clude both popular applications (left) and applications used by
few users (right).
Figure 4: Detailed view of the software patching service. Notice
the persistent retries even during outages.
Note that there are two distinct classes of applications involved:
applications used by the entire population, such as infrastructure
apps, are grouped to the left, and applications installed by a very
small number of users (< 20 in our trace population) are grouped
to the right (these are applications explicitly installed by the users).
We believe both classes deserve discussion as the former reﬂects
inefﬁciencies experienced by the user population as a whole, and
the latter reﬂects applications that affect the network most severely.
The software patching service is the most egregious applica-
tion in the “popular” class. The high incidence of failures is at-
tributed to its unique service-discovery design: clients periodically
discover the closest patch distribution server by launching hop-
limited probes to all patch servers (numbering in the hundreds);
this results in a large number of ﬂows, most of which fail before
reaching the (ﬁnal) destination. Furthermore, this application is
environment agnostic and continues to behave aggressively when
outside the enterprise, resulting in even more failures. A lack of
environmental awareness is also to blame for the high failure rates
seen by the anti-virus application which is conﬁgured to periodi-
cally poll a server for updated signatures and policies.
Among the failing applications used by a small number of users
are two monitoring applications, and a music streaming applica-
tion. The ﬁrst application monitors the performance of enterprise
servers (load, processes, alerts, etc.); when shown these failures the
operational IT group believed that the pattern was suggestive of an
incorrectly conﬁgured server that the endhost was trying to connect
to. The second application monitors the performance of database
servers and appears to be similarly misconﬁgured. The third is a
music streaming application that fails while attempting to punch
through ﬁrewalls and proxies by improperly masquerading as SSL
and VPN trafﬁc. While these applications are isolated instances in
our environment, in general we believe that, misconﬁgurations and
policy violations by a small number of users are worth investigat-
ing as they can signiﬁcantly affect the overall health of an enterprise
network.
4. TYPES OF FAILURES
In this section we introduce a taxonomy of failures which hint at
the underlying causes for the poor health that we observe. Building
on the taxonomy, we suggest a few incremental changes to appli-
cations that can serve to reduce the high incidence of failures.
 100
 90
 80
 70
 60
 50
 40
 30
 20
 10
)
%
(
F
D
C
Retry interval
Outage duration
 1
 10
 100
 1000
 10000  100000  1e+06
Time interval (s)
Figure 5: Applications retry far more frequently than neces-
sary during outages resulting in a large number of failures.
4.1 Persistent Retries
The majority of failures can be attributed to applications that per-
sistently initiate new ﬂows to a host despite repeated failures. The
ﬂows fail either because the application is misconﬁgured, or be-
cause the destination is temporarily unreachable, potentially due to