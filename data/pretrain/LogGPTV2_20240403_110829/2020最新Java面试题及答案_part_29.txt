18.1.2.3. 随机均衡（Random）
把来自网络的请求随机分配给内部中的多个服务器。
18.1.2.4. 权重随机均衡（Weighted Random）
此种均衡算法类似于权重轮循算法，不过在处理请求分担时是个随机选择的过程。
18.1.2.5. 响应速度均衡（Response Time探测时间）
负载均衡设备对内部各服务器发出一个探测请求（例如Ping），然后根据内部中各服务器对探测
请求的最快响应时间来决定哪一台服务器来响应客户端的服务请求。此种均衡算法能较好的反映
服务器的当前运行状态，但这最快响应时间仅仅指的是负载均衡设备与服务器间的最快响应时
间，而不是客户端与服务器间的最快响应时间。
13/04/2018 Page 204 of 283
18.1.2.6. 最少连接数均衡（Least Connection）
最少连接数均衡算法对内部中需负载的每一台服务器都有一个数据记录，记录当前该服务器正在
处理的连接数量，当有新的服务连接请求时，将把当前请求分配给连接数最少的服务器，使均衡
更加符合实际情况，负载更加均衡。此种均衡算法适合长时处理的请求服务，如FTP。
18.1.2.7. 处理能力均衡（CPU、内存）
此种均衡算法将把服务请求分配给内部中处理负荷（根据服务器CPU型号、CPU数量、内存大小
及当前连接数等换算而成）最轻的服务器，由于考虑到了内部服务器的处理能力及当前网络运行
状况，所以此种均衡算法相对来说更加精确，尤其适合运用到第七层（应用层）负载均衡的情况
下。
18.1.2.8. DNS响应均衡（Flash DNS）
在此均衡算法下，分处在不同地理位置的负载均衡设备收到同一个客户端的域名解析请求，并在
同一时间内把此域名解析成各自相对应服务器的IP地址并返回给客户端，则客户端将以最先收到
的域名解析IP地址来继续请求服务，而忽略其它的IP地址响应。在种均衡策略适合应用在全局负
载均衡的情况下，对本地负载均衡是没有意义的。
18.1.2.9. 哈希算法
一致性哈希一致性Hash，相同参数的请求总是发到同一提供者。当某一台提供者挂时，原本发往
该提供者的请求，基于虚拟节点，平摊到其它提供者，不会引起剧烈变动。
18.1.2.10. IP地址散列（保证客户端服务器对应关系稳定）
通过管理发送方IP和目的地IP地址的散列，将来自同一发送方的分组(或发送至同一目的地的分
组)统一转发到相同服务器的算法。当客户端有一系列业务需要处理而必须和一个服务器反复通信
时，该算法能够以流(会话)为单位，保证来自相同客户端的通信能够一直在同一服务器中进行处
理。
18.1.2.11. URL散列
通过管理客户端请求URL信息的散列，将发送至相同URL的请求转发至同一服务器的算法。
13/04/2018 Page 205 of 283
18.1.3. LVS
18.1.3.1. LVS原理
IPVS
LVS 的 IP 负载均衡技术是通过 IPVS 模块来实现的，IPVS 是 LVS集群系统的核心软件，它的主要
作用是：安装在 Director Server 上，同时在 Director Server上虚拟出一个IP 地址，用户必须通
过这个虚拟的 IP 地址访问服务器。这个虚拟 IP 一般称为 LVS 的VIP，即 Virtual IP。访问的请求
首先经过 VIP 到达负载调度器，然后由负载调度器从Real Server 列表中选取一个服务节点响应用
户的请求。 在用户的请求到达负载调度器后，调度器如何将请求发送到提供服务的 Real Server 节
点，而 Real Server节点如何返回数据给用户，是 IPVS 实现的重点技术。
ipvs ： 工作于内核空间，主要用于使用户定义的策略生效
ipvsadm : 工作于用户空间，主要用于用户定义和管理集群服务的工具
ipvs 工作于内核空间的 INPUT 链上，当收到用户请求某集群服务时，经过 PREROUTING 链，经
检查本机路由表，送往 INPUT 链；在进入 netfilter 的 INPUT 链时，ipvs 强行将请求报文通过
ipvsadm定义的集群服务策略的路径改为FORWORD链，将报文转发至后端真实提供服务的主机。
13/04/2018 Page 206 of 283
18.1.3.1. LVS NAT 模式
①.客户端将请求发往前端的负载均衡器，请求报文源地址是 CIP(客户端 IP),后面统称为 CIP)，目
标地址为VIP(负载均衡器前端地址，后面统称为VIP)。
②.负载均衡器收到报文后，发现请求的是在规则里面存在的地址，那么它将客户端请求报文的目
标地址改为了后端服务器的RIP地址并将报文根据算法发送出去。
③.报文送到Real Server后，由于报文的目标地址是自己，所以会响应该请求，并将响应报文返还
给LVS。
④.然后lvs将此报文的源地址修改为本机并发送给客户端。
注意：在NAT模式中，Real Server的网关必须指向LVS，否则报文无法送达客户端
特点：
1、NAT 技术将请求的报文和响应的报文都需要通过 LB 进行地址改写，因此网站访问量比较大的
时候 LB 负载均衡调度器有比较大的瓶颈，一般要求最多之能 10-20 台节点
2、只需要在 LB 上配置一个公网 IP 地址就可以了。
3、每台内部的 realserver 服务器的网关地址必须是调度器 LB 的内网地址。
4、NAT 模式支持对 IP 地址和端口进行转换。即用户请求的端口和真实服务器的端口可以不一致。
优点：
集群中的物理服务器可以使用任何支持 TCP/IP 操作系统，只有负载均衡器需要一个合法的 IP 地
址。
缺点：
13/04/2018 Page 207 of 283
扩展性有限。当服务器节点（普通PC服务器）增长过多时,负载均衡器将成为整个系统的瓶颈，因
为所有的请求包和应答包的流向都经过负载均衡器。当服务器节点过多时，大量的数据包都交汇
在负载均衡器那，速度就会变慢！
18.1.3.2. LVS DR 模式（局域网改写mac地址）
①.客户端将请求发往前端的负载均衡器，请求报文源地址是CIP，目标地址为VIP。
②.负载均衡器收到报文后，发现请求的是在规则里面存在的地址，那么它将客户端请求报文的源
MAC地址改为自己DIP的MAC地址，目标MAC改为了RIP的MAC地址，并将此包发送给RS。
③.RS 发现请求报文中的目的 MAC 是自己，就会将次报文接收下来，处理完请求报文后，将响应
报文通过lo接口送给eth0网卡直接发送给客户端。
注意：需要设置lo接口的VIP不能响应本地网络内的arp请求。
总结：
1、通过在调度器 LB 上修改数据包的目的 MAC 地址实现转发。注意源地址仍然是 CIP，目的地址
仍然是 VIP 地址。
2、请求的报文经过调度器，而 RS 响应处理后的报文无需经过调度器 LB，因此并发访问量大时使
用效率很高（和 NAT 模式比）
3、因为 DR 模式是通过 MAC 地址改写机制实现转发，因此所有 RS 节点和调度器 LB 只能在一个
局域网里面
4、RS 主机需要绑定 VIP 地址在 LO 接口（掩码32 位）上，并且需要配置 ARP 抑制。
5、RS 节点的默认网关不需要配置成 LB，而是直接配置为上级路由的网关，能让 RS 直接出网就
可以。
13/04/2018 Page 208 of 283
6、由于 DR 模式的调度器仅做 MAC 地址的改写，所以调度器 LB 就不能改写目标端口，那么 RS
服务器就得使用和 VIP 相同的端口提供服务。
7、直接对外的业务比如 WEB 等，RS 的 IP 最好是使用公网 IP。对外的服务，比如数据库等最好
使用内网IP。
优点：
和 TUN（隧道模式）一样，负载均衡器也只是分发请求，应答包通过单独的路由方法返回给客户
端。与 VS-TUN 相比，VS-DR 这种实现方式不需要隧道结构，因此可以使用大多数操作系统做为
物理服务器。
DR 模式的效率很高，但是配置稍微复杂一点，因此对于访问量不是特别大的公司可以用
haproxy/nginx取代。日1000-2000W PV或者并发请求1万一下都可以考虑用haproxy/nginx。
缺点：
所有 RS 节点和调度器 LB 只能在一个局域网里面
18.1.3.3. LVS TUN 模式（IP封装、跨网段）
①.客户端将请求发往前端的负载均衡器，请求报文源地址是CIP，目标地址为VIP。
②.负载均衡器收到报文后，发现请求的是在规则里面存在的地址，那么它将在客户端请求报文的
首部再封装一层IP报文,将源地址改为DIP，目标地址改为RIP,并将此包发送给RS。
③.RS 收到请求报文后，会首先拆开第一层封装,然后发现里面还有一层 IP 首部的目标地址是自己
lo接口上的VIP，所以会处理次请求报文，并将响应报文通过lo接口送给eth0网卡直接发送给客
户端。
注意：需要设置lo接口的VIP不能在共网上出现。
13/04/2018 Page 209 of 283
总结：
1.TUNNEL 模式必须在所有的 realserver 机器上面绑定 VIP 的 IP 地址
2.TUNNEL 模式的 vip ------>realserver 的包通信通过 TUNNEL 模式，不管是内网和外网都能通
信，所以不需要 lvs vip 跟 realserver 在同一个网段内。
3.TUNNEL 模式 realserver 会把 packet 直接发给 client 不会给 lvs 了
4.TUNNEL 模式走的隧道模式，所以运维起来比较难，所以一般不用。
优点：
负载均衡器只负责将请求包分发给后端节点服务器，而 RS 将应答包直接发给用户。所以，减少了
负载均衡器的大量数据流动，负载均衡器不再是系统的瓶颈，就能处理很巨大的请求量，这种方
式，一台负载均衡器能够为很多RS进行分发。而且跑在公网上就能进行不同地域的分发。
缺点：
隧道模式的 RS 节点需要合法 IP，这种方式需要所有的服务器支持”IP Tunneling”(IP
Encapsulation)协议，服务器可能只局限在部分Linux系统上。
18.1.3.4. LVS FULLNAT模式
无论是 DR 还是 NAT 模式，不可避免的都有一个问题：LVS 和 RS 必须在同一个 VLAN 下，否则
LVS 无法作为 RS 的网关。这引发的两个问题是：
1、同一个 VLAN 的限制导致运维不方便，跨 VLAN 的 RS 无法接入。
2、LVS 的水平扩展受到制约。当 RS 水平扩容时，总有一天其上的单点 LVS 会成为瓶颈。
Full-NAT 由此而生，解决的是 LVS 和 RS 跨 VLAN 的问题，而跨 VLAN 问题解决后，LVS 和 RS
不再存在 VLAN 上的从属关系，可以做到多个 LVS 对应多个 RS，解决水平扩容的问题。
Full-NAT 相比 NAT 的主要改进是，在 SNAT/DNAT 的基础上，加上另一种转换，转换过程如下：
13/04/2018 Page 210 of 283
1. 在包从 LVS 转到 RS 的过程中，源地址从客户端 IP 被替换成了 LVS 的内网 IP。内网 IP 之间
可以通过多个交换机跨 VLAN 通信。目标地址从VIP修改为RS IP.
2. 当 RS 处理完接受到的包，处理完成后返回时，将目标地址修改为LVS ip，原地址修改为RS
IP，最终将这个包返回给 LVS 的内网 IP，这一步也不受限于 VLAN。
3. LVS 收到包后，在 NAT 模式修改源地址的基础上，再把 RS 发来的包中的目标地址从 LVS 内
网 IP 改为客户端的 IP,并将原地址修改为VIP。
Full-NAT 主要的思想是把网关和其下机器的通信，改为了普通的网络通信，从而解决了跨 VLAN
的问题。采用这种方式，LVS 和 RS 的部署在 VLAN 上将不再有任何限制，大大提高了运维部署的
便利性。
总结
1. FULL NAT 模式不需要 LBIP 和 realserver ip 在同一个网段；
2. full nat 因为要更新 sorce ip 所以性能正常比 nat 模式下降 10%
18.1.4. Keepalive
keepalive 起初是为 LVS 设计的，专门用来监控 lvs 各个服务节点的状态，后来加入了 vrrp 的功
能，因此除了 lvs，也可以作为其他服务（nginx，haproxy）的高可用软件。VRRP 是 virtual
router redundancy protocal（虚拟路由器冗余协议）的缩写。VRRP的出现就是为了解决静态路
由出现的单点故障，它能够保证网络可以不间断的稳定的运行。所以 keepalive 一方面具有 LVS
cluster node healthcheck功能，另一方面也具有LVS director failover。
18.1.5. Nginx反向代理负载均衡
普通的负载均衡软件，如LVS，其实现的功能只是对请求数据包的转发、传递，从负载均衡下的节
点服务器来看，接收到的请求还是来自访问负载均衡器的客户端的真实用户；而反向代理就不一
13/04/2018 Page 211 of 283
样了，反向代理服务器在接收访问用户请求后，会代理用户 重新发起请求代理下的节点服务器，
最后把数据返回给客户端用户。在节点服务器看来，访问的节点服务器的客户端用户就是反向代
理服务器，而非真实的网站访问用户。
18.1.5.1. upstream_module和健康检测
ngx_http_upstream_module 是负载均衡模块，可以实现网站的负载均衡功能即节点的健康检
查，upstream模块允许Nginx定义一组或多组节点服务器组，使用时可通过 proxy_pass 代理方
式把网站的请求发送到事先定义好的对应 Upstream组 的名字上。
upstream模块 参数说明
内参数
weight 服务器权重
max_fails Nginx尝试连接后端主机失败的此时，这是值是配合 proxy_next_upstream、
fastcgi_next_upstream和memcached_next_upstream这三个参数来使用的。当Nginx
接收后端服务器返回这三个参数定义的状态码时，会将这个请求转发给正常工作的的后端服
务器。如404、503、503,max_files=1
fail_timeout max_fails 和 fail_timeout 一般会关联使用，如果某台server在 fail_timeout 时间内出现了
max_fails 次连接失败，那么Nginx会认为其已经挂掉，从而在 fail_timeout 时间内不再去
请求它，fail_timeout默认是 10s，max_fails默认是1，即默认情况只要是发生错误就认为
服务器挂了，如果将max_fails设置为0，则表示取消这项检查
backup 表示当前server是备用服务器，只有其它非backup后端服务器都挂掉了或很忙才会分配请
求给它
down 标志服务器永远不可用，可配合ip_hash使用
upstream lvsServer{
server 191.168.1.11 weight=5 ;
server 191.168.1.22:82;