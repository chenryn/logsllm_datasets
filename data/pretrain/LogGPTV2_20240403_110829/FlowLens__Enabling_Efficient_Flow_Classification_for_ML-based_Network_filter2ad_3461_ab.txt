packet distributions while retaining enough information about
ﬂows to enable high accuracy on classiﬁcation tasks. Achieving
such a representation requires the design of a ﬂow compression
scheme that is simple enough to be efﬁciently implemented by
the primitives available in current P4-programmable switches,
but which is able to retain meaningful features for classiﬁcation
purposes. Additionally, computing compact representations
of packet distributions should not consume the majority of
resources in the switch, enabling the system to co-exist with
other typical applications, e.g. forwarding, or to be used in
tandem with complementary network telemetry solutions.
Availability: Re-purposing our system to different
trafﬁc
analysis tasks should not involve the deployment of a new
P4 program. This is because deploying a new program involves
a scheduled downtime during which the switch will be unable
to perform its basic functions, causing service disruptions.
C. Constraints of Modern Programmable Switches
To efﬁciently collect and process packet distributions, we
explore the programming capabilities of modern switches, such
as Barefoot Toﬁno [4] and Broadcom Tomahawk II [14]. These
switches include two types of processors which operate in two
different planes of the network architecture. On the data plane,
3
Figure 2. Protocol Independent Switch Architecture (PISA).
forwarding ASICs are able to quickly forward and perform
simple computations on packets at line-rate, thus enabling the
analysis of billions of packets at the Tbps scale. On the control
plane, CPUs can be used for general-computing tasks such as
controlling the packet forwarding pipeline, or for exchanging
data with the ASIC through DMA.
Switching ASICs can be programmed in a hardware-
independent language, such as P4 [12]. Figure 2 illustrates
the architecture of our targeted switching ASIC: the Protocol
Independent Switch Architecture (PISA) [18]. Packets arrive at
the switch ingress interfaces and, after parsing, are processed by
two logical pipelines of match+action units (MAUs) arranged
in stages. Packet headers along with packet metadata may then
match (M) a given table, triggering further processing by the
action (A) unit associated with the matching table’s entry. These
actions may modify packet header ﬁelds and change persistent
state (e.g., increment a counter in stateful memory). Tables and
other objects deﬁned in a P4 program are instantiated inside
MAUs and populated by the control plane at run-time.
Memory constraints: Several constraints in the memory
architecture of switching ASICs may restrict the layout of
the data structures that can be used by P4 programs. These
ASICs are equipped with two high-speed types of memory: (i)
TCAM, which is a content addressable memory suited for fast
table lookups, such as for longest-preﬁx matching in routing
tables [89], and (ii) SRAM which enables P4 programs to persist
state across packets (e.g., using register arrays), and to hold
exact-match tables. Unfortunately, switching ASICs contain
a small amount of stateful memory (in the order of 100MB
SRAM [51]), and only a fraction of the total available SRAM
can be used to allocate register arrays. Moreover, accessing all
available registers can be a complex task since the registers
in one stage cannot be accessed at different stages [19]; this
is because the SRAM is uniformly distributed amongst the
different stages of the processing pipeline (see Figure 2).
Processing constraints: The P4 programs installed on the
switch must also use very simple instructions to process packets.
To guarantee line-rate processing, packets must spend a ﬁxed
amount of time in each pipeline stage (a few ns [70, 69]) which
restricts the number and type of operations allowed within each
stage. Multiplications, divisions or ﬂoating-point operations,
and variable-length loops are not supported. Moreover, each
table’s action can only perform a restricted set of simpler
operations, like additions, bit shifts, and memory accesses that
can quickly be performed while the packet is passing through
an MAU without stalling the whole pipeline [71].
III. SYSTEM OVERVIEW
This section describes FlowLens, a system for efﬁcient ﬂow
classiﬁcation that achieves the aforementioned goals. Figure 3
shows the architecture of FlowLens, illustrating how it can
Ingress PipelineProgrammable ParserEgress PipelineEgress InterfaceIngress InterfaceTrafﬁc ManagerStage 1Stage nProgrammable De-parser...M1.3A1.3M1.2A1.2M1.1A1.1Mn.3An.3Mn.2An.2Mn.1An.1MemoryCluster 1MemoryCluster nStage 1Stage n...M1.3A1.3M1.2A1.2M1.1A1.1Mn.3An.3Mn.2An.2Mn.1An.1MemoryCluster 1MemoryCluster ntruncation values, generating a conﬁguration according to a
given user-deﬁned criterion (see Section V).
2. Flow classiﬁcation: As soon as the P4 program has been
loaded into the switch (which happens only once when boot-
strapping FlowLens), the collector takes the proﬁle computed
in phase 1 for a speciﬁc application, e.g., website ﬁngerprinting,
and conﬁgures the FMA accordingly. Afterward, the switch
can start to process packets and compute ﬂow markers. The
collector then fetches the resulting ﬂow markers from the data
plane and the classiﬁer processes them based on the loaded
model. The classiﬁer results can be retrieved by the system
operator, who can then take targeted actions about particular
ﬂows such as dropping ﬂagged ﬂows or scheduling further
logging operations. The system operator can later reconﬁgure
the system for other ML-based application proﬁles without the
need to re-deploy the P4 program.
In the following sections, we present the relevant design de-
tails of FlowLens, namely the FMA data structure (Section IV)
and the automatic proﬁling scheme aimed at choosing markers
with good accuracy/memory saving trade-offs (Section V).
IV. FLOW MARKER ACCUMULATOR
The Flow Marker Accumulator (FMA) is the data structure
responsible for computing ﬂow markers on the switch data plane.
Next, we present its internal operations by describing the FMA
design for capturing markers of packet length distributions,
and presenting the main changes when computing inter-packet
arrival timing distributions. Then, we describe how the FMA is
used by the control plane, and discuss alternative FMA setups.
A. Collecting Packet Length Distributions
To generate ﬂow markers, the FMA provides two basic
operators that can be implemented efﬁciently and be used to
obtain a space-efﬁcient encoding of a packet length distribution:
quantization and truncation. Quantization consists of counting
packet lengths in coarse bins that represent ranges of contiguous
packet lengths. Truncation further trims the number of bins
that need to be reserved for a certain classiﬁcation task. These
operators allow us to selectively collect the bin values which, in
many cases, correspond to the most relevant features employed
by the ML engine to yield accurate classiﬁcations [84, 7].
To perform these operations, the FMA is composed of
several data structures shown in Figure 4. They consist of two
match+action tables and one register array: the ﬂow table, the
truncation table, and the register grid, respectively. The register
grid is a matrix of memory registers. Each line is used to store
a ﬂow marker. The index of each line (ﬂow offset) is used
to address the ﬂow marker. Internally, a ﬂow marker consists
of a number of cells in a register (the grid’s columns). These
cells play the role of bins for storing samples of the ﬂow’s
packet length frequency distribution. The ﬂow table maps the
monitored ﬂows against the respective ﬂow markers in the
register grid. The truncation table identiﬁes the bin that must
be incremented for every incoming packet.
Next, we describe in detail the procedure for updating the
ﬂow marker for a given incoming packet. Consider the example
shown in Figure 4, where an input packet arrives in the switch
Figure 3. FlowLens architecture and components.
be used to monitor trafﬁc on a single switch of a high-speed
network. In general, it can be deployed across multiple other
switches in the network at the system operator’s discretion.
FlowLens consists of the following components: a P4 program
and two software components (collector and classiﬁer) running
on the switch, a standalone proﬁler server, and a software client
that provides an interface to the system operator.
Taken together, the components running on the switch are
responsible for analyzing trafﬁc and classifying ﬂows as per
ML-based security application. The P4 program runs on the
data plane, and implements a tailor-made data structure named
Flow Marker Accumulator (FMA). The FMA is used to collect
concise encodings of the packet length or inter-packet timing
distributions of ﬂows named ﬂow markers. Essentially, the FMA
implements the necessary knobs for ﬁne-tuning the memory
savings and the classiﬁcation accuracy of the system. It can
accommodate the restrictions of the switch and generate ﬂow
markers at different compression levels by carefully adjusting
a set of conﬁguration parameters that control (i) the size of the
memory footprint allocated per-ﬂow marker, and (ii) the loss
of information in the ﬂow markers due to compression.
Running on the local CPU of the switch, two additional
FlowLens software components implement several control plane
functions. The collector is responsible for loading the P4
program, conﬁguring the FMA data structures in the forwarding
pipeline, initiating the ﬂow collection process, and collecting the
resulting ﬂow markers. The classiﬁer runs the ML algorithms
responsible for classifying ﬂows based on the collected markers.
FlowLens can generally employ any ML algorithm that can
reason over ﬂow markers, and whose memory and compute
requirements can be accommodated on the switch control plane.
After the classiﬁcation step, results can be downloaded by the
client and displayed to the system operator.
Since the classiﬁer and the FMA conﬁguration parameters
depend on the application domain, FlowLens uses a standalone
proﬁler to pre-conﬁgure the classiﬁer models and FMA param-
eters (i.e., the application proﬁle) onto the switch. The system
workﬂow involves two phases: proﬁling and ﬂow classiﬁcation.
1. Proﬁling: FlowLens needs to be pre-conﬁgured by the system
operator for speciﬁc applications. This operation involves the
proﬁler server, which can automatically create proﬁles by using
an application-speciﬁc classiﬁer and a training set containing
labeled ﬂow samples provided by the system operator. To this
end, the proﬁler runs an optimization process that explores the
classiﬁcation performance of different FMA quantization and
4
SwitchClientProﬁleAutomatic	ProfilerFMA	Parameters:QL=4,	TL=10Profiler	ServerTraining DatasetClassifierClassifierFlowsCPUASICFMAP4	ProgramNetworkModelProﬁleClassiﬁcationResultsCollectorfrom source IP 162.2.13.42, source port 41065, with length
1024 bytes. The FMA performs the following four operations:
1. Lookup: First, the FMA’s ﬂow table matches the incoming
packet with the corresponding ﬂow ID, which is a 5-tuple of
header ﬁelds (cid:104)IPsrc, Portsrc, IPdst, Portdst, Proto(cid:105) that is used as
lookup key to return its associated ﬂow offset. To be efﬁciently
performed, we leverage the match+action units of the switch to
accommodate speciﬁc rules for ﬂow table indexing. Each rule in
the ﬂow table assigns a unique ﬂow offset to each ﬂow ID. For
instance, in the running example, the input packet is matched
against the rule (cid:104)162.2.13.42, 41065, 146.3.18.71, 80, 6(cid:105) → 0.
(Section IV-C describes how the ﬂow table is populated.)
2. Quantization: The ﬂow offset determined above locates
the packet’s ﬂow marker in the register grid. Next, the FMA
must increment the correct bin in the ﬂow marker which is a
function of the packet length. The ﬁrst step to determine the
right bin involves quantization, which aggregates, and so counts,
a range of contiguous packet lengths into the same bin. To avoid
complex instructions unsupported by the switch hardware (e.g.,
multiplications), the bin indexed by a certain packet length P L
is computed by bin(QL, PL) = length(PL) >> QL, where QL
denotes the quantization level and 0 ≤ QL < log2(PLmax). For
efﬁcient lookup of a packet length’s bin, FMA uses power-
of-two bin sizes; this allows for computing the packet bin by
right-shifting the packet length value by QL number of bits.
In the shown example, applying QL = 4 to the packet length
(1024 bytes) yields quantization bin #64.
3. Truncation: Based on the obtained quantization bin, trun-
cation leverages an auxiliary data structure – the truncation
table – which contains match+action rules exclusively for the
bins that should be accounted for in the ﬂow marker. Each rule
is keyed by the quantized bin length, i.e., bin(QL, PL), and
indexes the ﬂow marker’s bin (bin offset) where the packet
length frequency must be recorded. If no such rule exists
for a given quantized bin, the packet is not counted. In this
example, the current packet is considered because a rule exists
for the packet’s quantized bin (#64). In contrast, packets whose
quantized bin values fall, e.g., within the bin range 52-63,
will not be accounted for. This strategy allows for selectively
ﬁltering the most meaningful bins for ﬂow classiﬁcation.
4. Increment: Lastly, by combining the ﬂow offset and the
bin offset, the register grid can be indexed and the correct bin
incremented. In the running example, this entails incrementing
bin 2 of the ﬂow marker pointed to by the ﬂow offset 0. These
steps are repeated for every incoming packet.
B. Collecting Packet Timing Distributions
Gathering inter-packet timing distributions requires only
minor modiﬁcations to the FMA design. This task does not
affect the main FMA data structures and operators, but it
requires additional resources in the switch processing pipeline.
To compute the arrival time difference between two consec-
utive packets of the same ﬂow, the FMA stores the timestamp
of the last packet seen per each ﬂow. That information is
available to the P4 program through device intrinsic metadata.
With exception to the ﬁrst packet of a ﬂow, FMA computes the
difference between the current packet timestamp and the last
timestamp observed for that particular ﬂow. That value can then
Figure 4. FMA internals: Flow Table, Truncation Table, and Register Grid.
be processed by the same quantization and truncation operators
described for packet lengths, which produce the corresponding
bin to be updated in the register grid.
C. Usage of the FMA by the Control Plane
To monitor ﬂows on a switch, the FMA must be coordinated
by the control plane’s collector software. The collector prede-
ﬁnes the FMA’s quantization and truncation parameters, and
determines: i) which amongst all ﬂows traversing the switch at
a given time will be monitored by the FMA, and ii) for how
long the packets of the monitored ﬂows will be considered in
the respective ﬂow markers. Next, we present the default FMA
operational settings and then describe alternative customization
policies that can be enabled by the FlowLens operator.
Default FMA measurement operations: By default,
the
control plane sets up the FMA to i) compute ﬂow markers for
all the ﬂows on a ﬁrst-come, ﬁrst-served (FCFS) basis until
they exhaust the register grid capacity, and ii) measure the
ﬂows’ respective packets for a predeﬁned time interval that
we refer to as collection window. The control plane starts by