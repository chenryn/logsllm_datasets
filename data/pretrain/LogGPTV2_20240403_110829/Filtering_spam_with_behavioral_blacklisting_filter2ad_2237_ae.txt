ferent locations or on independent networks. Multiple servers might
be anycasted or managed by different organizations (much like the
DNS root nameserver infrastructure today), all of which perform
the same computation and disseminate average rows to second-level
servers, which in turn respond to user lookups.
6.4 Evasion
SpamTracker must be resistant to attacks that mislead the clus-
tering engine in ways that can cause spam to be misclassiﬁed as
legitimate email, and vice versa. To improve classiﬁcation robust-
ness, SpamTracker could form clusters based on email sending pat-
terns from a smaller number of trusted email recipients (e.g., a
few hundred trusted domains), each of which communicates with
the SpamTracker system over a secure channel. Although Spam-
Tracker’s clustering beneﬁts from more inputs about email senders,
it can serve as a classiﬁer for a much larger set of domains that it
does not necessarily trust to provide data for forming the clusters.
If spamming bots in a botnet select target domains from the same
distribution, SpamTracker’s clustering algorithm will include these
spammers in the same cluster. Still, SpamTracker is limited by the
time window used for clustering (e.g., 6 hours, as in Section 5), and
a spammer might exploit this weakness to evade SpamTracker. We
are improving SpamTracker to automatically adjust the window in
response to the fraction of received email in the last window that
was classiﬁed as spam. The intuition is that the fraction of spam
does not change much over short timeframes, and a decrease in the
fraction of ﬂagged email indicates that the window is too small to
cluster similar IPs together. Spamming bots might also try to emu-
late the distribution of target domains (or other behavioral features)
of normal senders, but by doing so, they may be inherently less
effective (e.g., they may have to reduce their sending rate or the
expansiveness of their target list).
6.5 Sensor Placement
A set of domains that observes more even sending behavior
across domains may be able to better distinguish spammers from
legitimate senders. Recall from Section 2.1.2 that 90% of the spam
we observe is received by only 84 of the 115 domains from which
we observe email, and that only about 15% of the senders in our
traces target more than one of the domains from which we can ob-
serve sending patterns at the email hosting provider. Based on our
experiments using only clusters where the average vectors are less
“skewed” towards a single domain (Figure ), we expect that a more
even distribution of sensors email would further improve the Spam-
Tracker classiﬁer. Many commercial spam ﬁltering companies (e.g.,
IronPort [16], Secure Computing [31]) may already have this data.
Another option for sensors would be ubiquitous Web mail domains
such as hotmail.com, gmail.com, etc.
7. RELATED WORK
In this section, we discuss several areas of related work: (1) Pre-
vious characterization studies, several of which offer statistics that
help build the case for behavioral blacklisting; (2) Existing systems
for spam ﬁltering, many of which use distributed monitoring but
incorporate different algorithms for classiﬁcation; (3) Previous ap-
proaches for classifying email into legitimate email and spam.
Blacklisting and identity. SpamTracker relates to previous black-
listing proposals. Conventional blacklists constitute lists of IP ad-
dresses of likely spammers and are intended to help spam ﬁlters [15,
23, 35] make better decisions about whether to block a piece of
email based on the sender. Some blacklists are policy-based (e.g.,
they list all IP addresses that belong to a certain class, such as di-
alup addresses [34]). Other IP-based blacklists are “reactive”: they
attempt to keep track of whether an IP address is a spammer, bot,
phisher, etc. and keep this list up-to-date as hosts are renumbered,
botnets move, and so forth [24, 36, 37, 39]. These blacklists essen-
tially maintain lists of IP addresses and must be vigilantly main-
tained so as to not going out of date. Sender Policy Framework
(SPF) attempts to prevent IP addresses from sending mail on behalf
of a domain for which they are not authorized to send mail [42], and
domain keys associate a responsible identity with each mail [3]. Al-
though both frameworks make it more difﬁcult for an arbitrary IP
address to send mail, they do not allow a recipient to classify an
email sender with an unknown reputation.
Collaborative ﬁltering and whitelisting. SpamTracker resembles
the many existing systems that take inputs from many distributed
sources to build information about known spam (or spammers).
Some of the most widely deployed collaborative ﬁltering systems
characterize known spam based on the contents of a piece of spam
that was reported or submitted by another user or mail server [10,
12, 20, 27, 28, 40]. These systems allow mail servers to compare the
contents of an arriving piece of email to the contents of an email that
has been conﬁrmed as spam; they do not incorporate any informa-
tion about network-level behavior.
Other systems collect information from distributed sets of users
either to help ﬁlter spam or decrease the probability that legiti-
mate mail is mistakenly ﬁltered. IronPort [17] and Secure Comput-
ing [32] sell spam ﬁltering appliances to domains which then pass
information about both legitimate mail and spam back to a central
processing engine that in turn improves the ﬁlters. The widespread
deployment of these products and systems make them ideal candi-
dates for the deployment of an algorithm like SpamTracker.
Characterization studies. Our recent characterization study of the
network-level behavior of spammers observes spamming behavior
from the perspective of a single spam “trap” domain [30]. In this
study, we observed that any particular IP address sends only a small
volume of spam to the particular domain being observed over the
course of 18 months. Duan et al. recently performed a similar study
that observes similar characteristics [13]. Our characterization of
spammers in Section 2 builds on these previous studies by observ-
ing email sending patterns across domains and time.
Content-independent blocking. Like SpamTracker, Clayton’s
“spamHINTS” project also aims to characterize and classify spam
with analysis of network trafﬁc patterns, rather than email con-
tents [38]. Earlier work on “extrusion detection” involves instru-
menting a mail server with a log processing program to detect
senders of spam both at the local ISP [8] and in remote ISPs [9]. Al-
though Clayton’s proposed methods are similar in spirit to our work
(in that the methods rely on examining trafﬁc patterns to distinguish
legitimate email senders from spammers), the methods generally
involve heuristics related to SMTP sessions from a single sender
(e.g., variations in HELO messages, attempt to contact incoming
mail servers to send outgoing mail); in contrast, SpamTracker relies
on a wider deployment of trafﬁc monitors (i.e., it relies on observ-
ing email sending patterns from many domains) but is then able to
for more protocol agnostic “ﬁngerprints” for email senders that are
likely spammers. Trinity counts email volumes to identify emails
that are likely sent from bots [6]; it could also be used to track email
sending patterns for input to SpamTracker.
Clustering for spam classiﬁcation. Previous studies have at-
tempted to cluster spammers based on an emails contents, such as
the URLs contained in the bodies of the emails [4, 22]. Li et al.
focus on clustering spam senders to predict whether a known spam-
mer will send spam in the future [22], and Anderson et al. cluster
spam according to URLs to better understand the relationship be-
tween the senders spam messages that advertise phishing and scam
sites and the Web servers that host the scams themselves [4]. These
systems cluster emails based on content, while SpamTracker clus-
ters email senders based on their sending behavior. Unlike the meth-
ods of Li et al., SpamTracker’s clustering techniques can also clas-
sifying previously unseen IP addresses.
Throttling outgoing spam. SpamTracker complements previous
proposals that have suggests throttling senders using schemes such
as stamps, proof-of-work, etc. One prominent postage scheme is
called “bankable postage”, whereby senders obtain stamps or to-
kens from some authority and then attach these tokens to emails [2,
41]. Other techniques for throttling spam require the sender to issue
some “proof of work”, either in CPU [5] or memory [14], although
these schemes have also been criticized because, in certain circum-
stances, they can prevent legitimate users from sending normal vol-
umes of email [21].
8. CONCLUSION
This paper presented SpamTracker, a system that classiﬁes email
senders using a technique we call behavioral blacklisting. Rather
than classifying email senders according to their IP addresses, be-
havioral blacklisting classiﬁes senders based on their sending pat-
terns. Behavioral blacklisting is based on the premise that many
spammers exhibit similar, stable sending patterns that can act as
“ﬁngerprints” for spamming behavior.
SpamTracker clusters email senders based on the set of domains
that they target. SpamTracker uses these sending patterns of con-
ﬁrmed spammers to build “blacklist clusters”, each of which has
an average vector that represents a spamming ﬁngerprint for that
cluster. SpamTracker tracks sending patterns of other senders and
computes the similarity of their sending patterns to that of a known
spam cluster as the basis for a “spam score”. Our evaluation us-
ing email logs from an email provider that hosts over 115 inde-
pendent domains shows that SpamTracker can complement existing
blacklists: it can distinguish spam from legitimate mail and also de-
tects many spammers before they are listed in any blacklist. Spam-
Tracker’s design makes it easy to replicate and distribute, and de-
ploying it requires only small modiﬁcations to the conﬁgurations
of existing mail servers. Our ongoing work involves gathering data
from a wider set of domains, improving the behavioral classiﬁca-
tion algorithms (e.g., by using other features of email senders), and
deploying the system to allow us to evaluate it in practice.
Acknowledgments. This work was supported by an NSF CAREER
award CNS-0633974, by NSF Cybertrust awards CNS-0721581
and CNS-0716278, by NSF grant CCF-0721503, and in part by the
Georgia Tech Algorithms and Randomness Center (ARC) Think-
Tank (http://www.arc.gatech.edu/). We thank Merrick Furst,
Suresh Ramasubramanian, Criag Sprosts, and Muhammad Mukar-
ram bin Tariq for comments and help.
REFERENCES
[1] Spamhaus delisting policy, 2007. http://www.spamhaus.
org/sbl/policy.html.
[2] M. Abadi, A. Birrell, M. Burrow, F. Dabek, and T. Wobber.
Bankable Postage for Network Services. In Proc. Asian
Computing Science Conference, Dec. 2003.
[3] E. Allman, J. Callas, M. Delany, M. Libbey, J. Fenton, and
M. Thomas. DomainKeys Identiﬁed Mail (DKIM) Signatures,
May 2007. http://www.ietf.org/rfc/rfc4871.txt.
[4] D. S. Anderson, C. Fleizach, S. Savage, and G. M. Voelker.
Spamscatter: Characterizing Internet Scam Hosting
Infrastructure. In Proc. 16th USENIX Security Symposium,
Boston, MA, Aug. 2007.
[5] A. Back. Hashcash. http://www.cypherspace.org/
adam/hashcash/.
[6] A. Brodsky and D. Brodsky. A Distributed Content
Independent Method for Spam Detection. In First USENIX
Workshop on Hot Topics in Understanding Botnets
(HotBots), Cambridge, MA, Apr. 2007.
[7] D. Cheng, R. Kannan, S. Vempala, and G. Wang. A
divide-and-merge methodology for clustering. ACM
Transactions on Database Systems, 31(4):1499–1525, 2006.
[8] R. Clayton. Stopping Spam by Extrusion Detection. In First
Conference on Email and Anti-Spam (CEAS), Mountain
View, CA, July 2004.
[9] R. Clayton. Stopping Outgoing Spam by Examining
Incoming Server Logs. In Second Conference on Email and
Anti-Spam (CEAS), Stanford, CA, July 2005.
[10] Cloudmark Authority Anti-Spam. http://www.
cloudmark.com/serviceproviders/authority/spam/,
2007.
[11] Commtouch Inc. 2006 Spam Trends Report: Year of the
Zombies. http://www.commtouch.com/documents/
Commtouch 2006 Spam Trends Year of the Zombies.
pdf.
[12] E. Damiani, S. de Vimercati, and P. Samarati. P2P-Based
Collaborative Spam Detection and Filtering. In 4th IEEE
Conference on P2P, 2004.
[13] Z. Duan, K. Gopalan, and X. Yuan. Behavioral
Characteristics of Spammers and Their Network Reachability
Properties. In Proc. IEEE ICC, Glasgow, Scotland, June
2007.
[14] C. Dwork and M. Naor. Pricing via Processing or Combatting
Junk Mail. In CRYPTO, Santa Barbara, CA, Aug. 1992.
[15] P. Graham. Better Bayesian Filtering. http://www.
paulgraham.com/better.html.
[16] IronPort. http://www.ironport.com/, 2007.
[17] IronPort Carrier Grade Email Security Appliance. http://
www.ironport.com/products/ironport x1000.html,
2007.
[18] R. Kannan, S. Vempala, and A. Vetta. On clusterings: good,
bad and spectral. J. of the ACM, 51(3):497–515, 2004.
[19] Kelly Jackson Higgins, Dark Reading. Botnets Battle Over
Turf. http://www.darkreading.com/document.asp?
doc id=122116, Apr. 2007.
[20] J. Kong et al. Scalable and Reliabile Collaborative Spam
Filters: Harnessing the Global Socail Email Networks. In 3rd
Annual Workshop on the Weblogging Ecosystem, 2006.
[21] B. Laurie and R. Clayton. Proof-of-Work Proves Not to
Work. In Third Annual Workshop on Economics and
Information Security (WEIS), Minneapolis, MN, May 2004.
[22] F. Li and M.-H. Hseih. An Empirical Study of Clustering
Behavior of Spammers and Group-based Anti-Spam
Strategies. In 3rd Conference on Email and Anti-Spam
(CEAS), Mountain View, CA, July 2006.
[23] MailAvenger, 2007. http://www.mailavenger.org/.
[24] Mail Abuse Prevention System (MAPS). http://www.
mail-abuse.com/.
[25] Messaging Anti-Abuse Working Group. MAAWG Issues
First Global Email Spam Report. http://www.
prnewswire.com/cgi-bin/stories.pl?ACCT=104&
STORY=/www/story/03-08-2006/0004316196, Mar.
2006.
[26] PandaLabs Blog. Zunker Spamming Bot Front-end Analysis.
http://blogs.pandasoftware.com/blogs/
pandalabs/archive/2007/05/08/Zunker.aspx, May
2007.
[27] V. Prakash. Vipul’s Razor. http://razor.sourceforge.
net/, 2007.
[32] Secure Computing IronMail. http://www.
securecomputing.com/index.cfm?skey=1612, 2007.
[33] A. Sinclair and M. Jerrum. Approximate counting, uniform
generation and rapidly mixing markov chains. Information
and Computation, 82:93–133, 1989.
[34] Spam and Open-Relay Blocking System (SORBS). http://
www.sorbs.net/.
[35] SpamAssassin, 2007. http://www.spamassassin.org/.
[36] SpamCop. http://www.spamcop.net/.
[37] Spamhaus, 2007. http://www.spamhaus.org/.
[38] SpamHINTS. http://www.spamhints.org/, 2007.
[39] Realtime uri blacklist. http://www.uribl.com/.
[40] P. Vixie. Distributed Checksum Clearinghouse. http://
www.rhyolite.com/anti-spam/dcc/, 2007.
[41] M. Walﬁsh, J. Zamﬁrescu, H. Balakrishnan, and D. Karger.
Distributed quota enforcement for spam control. In Proc. 3rd
Symposium on Networked Systems Design and
Implementation (NSDI), San Jose, CA, May 2006.
[42] M. Wong and W. Schlitt. Sender Policy Framework (SPF) for
Authorizing Use of Domains in E-Mail, Apr. 2006. RFC
4408.
[28] Pyzor. http://pyzor.sourceforge.net/, 2007.
[29] A. Ramachandran, D. Dagon, and N. Feamster. Can DNSBLs
Keep Up with Bots? In 3rd Conference on Email and
Anti-Spam (CEAS), Mountain View, CA, July 2006.
[30] A. Ramachandran and N. Feamster. Understanding the
Network-Level Behavior of Spammers. In Proc. ACM
SIGCOMM, Pisa, Italy, Aug. 2006.
[31] Secure Computing. http://www.securecomputing.com/,
2007.