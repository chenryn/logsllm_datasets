ules/extensions, we only run the tests of the submodule to increase the chance
of the vulnerable code being classiﬁed as hot (since vulnerabilities in cold code
are guaranteed to be detected). The test suite of the vulnerable OpenSSL ver-
sion does not cover the Heartbeat extension. Therefore, if we run the test suite
as-is, the function that contains the Heartbleed vulnerability is never executed.
PartiSan would therefore classify this function as cold and always sanitize it,
which guarantees detection. To be more conservative, we executed the vulnera-
ble function 300 times with benign input alongside the oﬃcial test suite.
Next, in step 4, we compile the program with the sanitizer enabled under Par-
tiSan. We use PartiSan’s default conﬁguration to compile each of the programs.
This means that the program contains two variants of all functions, except those
that are cold and those without memory accesses. We only created sanitized
variants for cold functions, and unsanitized variants for functions without mem-
ory accesses. Finally, we execute our test script from step 1 a thousand times to
measure the detection rate.
Out of the ﬁve vulnerabilities, ASan and UBSan detect four and three respec-
tively. The three vulnerabilities detected by UBSan all involve an integer over-
ﬂow. The overﬂown value usually represents the length of some buﬀer, which
results in out-of-bounds buﬀer accesses. The other two vulnerabilities are caused
by a lack of bounds checking. Note that although the last CVE is classiﬁed as
a heap over-read, ASan does not detect it. The reason is that the Python inter-
preter uses a custom memory allocator. It requests large chunks of memory
from the operating system and maintains its own free lists to serve individual
requests. Unfortunately, ASan treats each chunk as a single allocation and there-
fore is unable to detect overﬂows within a chunk. This shows that there is value
in using multiple sanitizers that can detect diﬀerent causes of vulnerabilities.
PartiSan: Fast and Flexible Sanitization via Run-Time Partitioning
413
Lastly, we want to note that three out of ﬁve vulnerabilities are in code that
PartiSan classiﬁes as cold. For those cases, we manually veriﬁed that PartiSan
only created the sanitized variant for the vulnerable functions. Hence, those
vulnerabilities are always reported. This result supports PartiSan’s underlying
assumption that most bugs hide in infrequently executed code. In summary, our
results show that we always detect bugs in cold code while bugs in hot code
are detected probabilistically. We argue that this is a valuable property in our
envisioned usage scenario: ﬁnding bugs in beta software during real usage with an
acceptable performance overhead. Note that probabilistic detection is a property
aﬀorded by dynamic, but not by static partitioning.
6 Eﬃciency
We evaluated the performance of PartiSan-enabled programs using the SPEC
CPU 2006 integer benchmark suite [20]. Since PartiSan clones code we also
measured the size of the resulting binaries. Memory overheads—a small con-
stant amount for the background thread and a few bytes of metadata for every
function—are negligible (less than 1%) for all SPEC programs, so we do not
report them.
We conducted all experiments on a host with an Intel Xeon E5-2660 CPU and
64 GB of RAM running 64-bit Ubuntu 14.04. We applied ASan and UBSan to
all of the benchmark programs. We conﬁgure UBSan to disable error recovery,
which always aborts the program instead of printing a warning message and
attempting to recover for a subset of failed checks. For conﬁgurations including
UBSan we also conﬁgure PartiSan to create variants of all functions, even those
that do not access memory. We use the expected-cost partitioning policy with a
sanitization budget of 1%, which our runtime evenly divides across all functions.
To collect proﬁle data we use LLVM’s built-in proﬁling facilities on the train-
ing workload of SPEC. Since our chosen partitioning policy greatly beneﬁts from
proﬁle data, we make the same data available to the baseline conﬁguration to
make the comparison fair. We compile all conﬁgurations, including the baseline,
with proﬁle-guided optimization enabled, supplying the same proﬁle data for all
conﬁgurations. When measuring the runtime, we use the reference workload, run
each benchmark three times, and report the median.
6.1 Performance
Figures 3 and 4 show the run-time overheads for ASan and UBSan with respect
to the baseline for all SPEC integer benchmarks. The last column depicts the
geometric mean over all benchmarks, which is additionally stated in percent by
Table 3 for easier reference.
PartiSan’s partitioning without any sanitization (with two identical variants)
incurs a 2% overhead on average, with a maximum of 9% for gobmk.
For the fully-sanitized versions of ASan and UBSan (absent PartiSan) we
measured an average overhead of 103% and 59% respectively. Note that the
overhead introduced by ASan can be as much as 289% for perlbench.
414
J. Lettner et al.
3.9
3.0
2.8
2.6
2.4
2.2
2.0
1.8
1.6
1.4
1.2
1.0
0.8
3.0
2.8
2.6
2.4
2.2
2.0
1.8
1.6
1.4
1.2
1.0
0.8
p erlb e n ch
b zip 2
gcc
m k
m cf
g o b
m
h
m er
m
sje n g
lib q u a ntu
h 2 6 4ref
o m
n etp p
astar
x ala n c b
geo m ea n
m k
ASan
PartiSan + ASan
ASan w/o checks
Fig. 3. SPEC run-time overheads for ASan
4.2
3.6
3.2
3.1
4.2
p erlb e n ch
b zip 2
gcc
m k
m cf
g o b
m
h
m er
m
sje n g
lib q u a ntu
h 2 6 4ref
o m
n etp p
astar
x ala n c b
geo m ea n
m k
UBSan
PartiSan + UBSan
ASan + UBSan
PartiSan + ASan + UBSan
Fig. 4. SPEC run-time overheads for UBSan and ASan+ UBSan
We also created a modiﬁed version of ASan that does not execute any checks.
The remaining overhead can be attributed to the maintenance of metadata and
other bookkeeping tasks. This conﬁguration represents a lower bound on the run
time achievable by PartiSan since bookkeeping needs to be done in all variants.
PartiSan stays close to this lower bound for many benchmarks even when using
PartiSan: Fast and Flexible Sanitization via Run-Time Partitioning
415
Table 3. SPEC run-time overheads
Conﬁguration
Overhead
PartiSan
ASan
ASan w/o checks
PartiSan + ASan
UBSan
PartiSan + UBSan
ASan + UBSan
2%
103%
27%
33%
59%
14%
191%
PartiSan + ASan + UBSan 46%
the expected-cost policy in its default conﬁguration. For the PartiSan-enabled
versions of ASan and UBSan we measured an average overhead of 33% and 14%
respectively. This corresponds to a reduction of overhead levels by more than
two thirds (68% and 76%) with respect to the fully-sanitized versions. We also
include a conﬁguration that enables both ASan and UBSan in Fig. 4 to show
that PartiSan can handle multiple sanitizers as long as they are compatible with
each other.
6.2 Binary Size
Table 4 gives an overview of the impact that PartiSan has on binary size for real-
world programs. We state binary sizes of the programs used in our eﬀectiveness
evaluation for ASan and UBSan with and without PartiSan and the size increase
in percent. We can navigate the size versus performance trade-oﬀ by adjusting
our threshold for hot code and argue that (using our policy) the maximum size
increase is limited by a factor of two (i.e., when all code is classiﬁed as hot).
Table 4. PartiSan program sizes (in kilobytes)
Program
Php 7.0.3
ASan
UBSan
20,483/21,983 (7%)
8,658/12,536 (45%)
OpenSSL 1.0.1f 19,128/25,579 (34%) 12,153/14,243 (17%)
Python 2.7.7
41,715/54,717 (31%) 22,033/28,641 (30%)
The statically-linked PartiSan runtime adds a constant overhead of 6 KB to
each binary. Internally, our runtime depends on the pthread library to spawn
the background partitioning thread. Usually, this does not increase program size
as libpthread is a shared library.
We also measured the size of the SPEC benchmark binaries used in our
performance evaluation. Since the benchmarks are small programs, the increase
416
J. Lettner et al.
in relative code size is dominated by the inclusion of the ASan/UBSan runtimes.
Therefore the larger programs in the suite exhibit the highest increase (9% for
gcc/ASan, and 16% for xalancbmk/UBSan). The increase in binary size over all
benchmarks (geometric mean) for ASan and UBSan are 2% and 5% respectively.
7 Use Case: Fuzzing
Fuzzing is an important use case for sanitization. A fuzzer repeatedly executes a
program with random inputs in order to ﬁnd bugs. Inputs that exercise new code
paths are stored in a corpus (coverage-guided), which is used to derive further
inputs (evolutionary). To aid bug detection, the program is usually compiled
with sanitization. The vast majority of individual fuzzing runs do not detect bugs
or increase coverage, so fuzzers rely on executing lots of runs (i.e., throughput
is important). We applied PartiSan to LLVM’s libFuzzer [14], an in-process,
coverage-guided, evolutionary fuzzing engine, with the goal of improving fuzzing
eﬃciency.
When we ﬁrst applied PartiSan to fuzzing we noticed that it represents a
speciﬁc use case that beneﬁts from a custom partitioning policy. Speciﬁcally,
the fuzzer requires the program to be executed with coverage instrumentation.
The gathered coverage data is similiar (but not equivalent) to the proﬁle data
used for our partitioning policy. We adapted PartiSan to use online coverage
data instead of proﬁle data, which has two advantages. First, it simpliﬁes the
developer workﬂow since there is no need to collect proﬁle data a priori. Second,
it allows us to continuously reﬁne our partitioning decisions. We integrated Par-
tiSan with libFuzzer with minimal changes to the latter. Additionally, the main
fuzzing loop provides a natural place to make partitioning decisions. We added
a call into our runtime from the fuzzing loop, forgoing the background thread in
favor of synchronous partitioning.
7.1 Partitioning Policy
Our policy for fuzzing is simple. For most functions we generate three variants:
variant 1 with coverage instrumentation, sanitized variant 2 , and fast variant 3
without any instrumentation. At startup we activate variant 1 for the whole
program. Whenever the fuzzer discovers an input that exercises new code, we
temporarily activate variant 2 for all functions and re-execute the input. Finally,
if a function becomes fully-explored (i.e., all its basic blocks have been executed),
we activate its variant 3 .