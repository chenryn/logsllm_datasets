X(Ti)
(5)
where T0 = 0 by convention and Ti is the sum of i inter-sample
times, which due to stationarity, each have law G with mean μ.
Hence Ti has mean iμ, and we denote its probability density by fi.
The variance of ˆp1 is given by
0
@N E[X(0)2] + 2
0
@N E[X(0)2] + 2
1
A−p2
IE[X(Ti)X(Tj)]
1
Z
A−p2 (6)
R(τ )f|i−j|(τ )dτ
Var[ˆp1]=
1
N 2
=
1
N 2
which is a function both of the variability of the process X(t) via
R(τ ), and that of the sampling stream via the fk.
As a special case of Equation (5), we pick out the estimator based
on periodic samples of period μ, namely
ˆp2 =
1
N
R
X(iμ),
(7)
for which the integral
ates to R(|i − j|μ).
R(τ )f|i−j|(τ )dτ in Equation (6) degener-
THEOREM 1. If R(τ ) is convex, then Var[ˆp1] ≥ Var[ˆp2].
PROOF. Equation (6) holds for all processes. So, to compare
R
the variances it is enough to compare, for all i (cid:5)= j, the cross terms,
R(τ )f|i−j|(τ )dτ and R(|i − j|μ). But, if R(τ ) is con-
namely
Z
vex, Jensen’s inequality says that
R(τ )fk(τ )dτ ≥ R
tfk(t)dt
= R(kμ)
„Z
«
X
i
X
i(cid:5)=j
X
i(cid:5)=j
X
i
for any k. The result follows.
We have learnt that under the foregoing assumptions, no other sam-
pling process has a variance which is lower than that of periodic
(8)
(cid:6)(cid:7)
sampling. As just one example, by taking G to be exponential in
ˆp1 and inter-sample times to be independent, we learn that Pois-
son sampling yields a higher variance than periodic. However, the
result is much more powerful than this. It shows that, if R(τ ) is
convex, no kind of train or other structure, no matter how sophisti-
cated, can do better than periodic.
Unfortunately periodic sampling does has a disadvantage already
discussed: it is not mixing, which makes it vulnerable to sample-
path bias due to phase locking effects. Assuming that R(τ ) is con-
vex, we now determine sampling schemes that offer the best of both
worlds: mixing to avoid sample-path bias, but with variance close
to that offered by periodic sampling.
We will consider sampling using renewal processes that are Gamma
distributed. A Gamma law has a two parameter density given by
λ
(λx)α−1 e−λx,
Γ(α)
Γα,λ(x) =
(9)
where Γ(·) is the familiar Gamma function, and has mean μ = α/λ
and variance σ2 = α/λ2. Since 1/λ > 0 is a scale parameter,
if T ∼ Γα,λ, then cT ∼ Γα,λ/c. Gamma laws are also stable
with respect to the shape parameter α, that is, if {Ti ∼ Γαi,λ}
are independent, then
i αi,λ. The exponential laws
correspond to the 1-parameter sub-family Γ1,λ. Another special
sub-family are distributions with the Erlang law. These have only
integral shape values.
P
i Ti ∼ ΓP
We will need one more technical result regarding Gamma laws,
the proof of which we leave to the appendix.
LEMMA 3.1. Let T ∼ Γα,λ, Z ∼ Γβ,λ be independent, and
set Y = T + Z. Then C = IE[T|Y ] = αY /(α + β) has density
Γα+β,(α+β)λ/α, with mean IE[C] = a/λ = IE[T ].
We can now prove
THEOREM 2. The family of renewal sampling processes G(β),
parametrized by β > 0, with inter-sample time density Γβ,βλ(x),
provides, at constant mean sampling rate λ, sampling variance for
ˆp1 that monotonically decreases with β. The variance is larger
(equal or smaller) than Poisson sampling as β is smaller (equal or
larger respectively) than 1, and tends to that of periodic sampling
in the limit β → ∞.
PROOF. We assume an underlying probability space on which
the family of inter-sample variables are deﬁned for each β > 0.
Equation (6) holds for each inter-sample law G(β). As the means
for each are equal to μ = β/(βλ) = 1/λ, proving the variance re-
R
R(τ )fk,1(τ )dτ ≥
sult reduces to showing that, for each k > 0,
R(τ )fk,2(τ )dτ for any β values β1, β2 satisfying β2 > β1,
where fk,i is the density of the sum Tk,i of k inter-sample times,
each with law G(βi). We can apply Jensen’s inequality to show
thatZ
R
R(τ )fk,1(τ )dτ = IE[R(Tk,1)]
= IE[IE[R(Tk,1)|Yk,1]]
≥ IE[R(IE[Tk,1|Yk,1)]
Z
= IE[R(Tk,2)] =
R(τ )fk,2(τ )dτ
where to show IE[Tk,1|Yk,1] = Tk,2 we identiﬁed (T, Y, α, β, λ)
with (Tk,1, Yk,1, kβ1, k(β2−β1), β1λ) and used Lemma 3.1. Since
this holds for any β1, β2 with β2 > β1, we have monotonicity of
the variance in β. As β tends to inﬁnity, there is weak convergence
of Γβ,βλ(x)(dx) to a Dirac measure at 1/λ, as is easily seen using
Laplace transforms. Since the function R is convex, it is contin-
uous, and as it is also bounded (as a second order process), the
property
Z
Z
lim
β→∞
R(x)Γβ,βλ(x)(dx) =
R(x)δ1/λ(dx)
follows from the very deﬁnition of weak convergence. This shows
that the limit of the variances of the Gamma renewal estimators is
that of the deterministic probe case, namely the optimal variance.(cid:6)(cid:7)
This result provides a family of sampling processes with the de-
sired properties. By selecting β > 1, we can ensure lower (more
precisely, no higher) variance than Poisson sampling. By select-
ing β large, we obtain sampling variance close to the lowest possi-
ble, whilst still using a mixing process. Exactly what value should
be chosen, however, will depend on other factors. For example,
extremely large values might increase vulnerability to ‘transient’
phase locks in atypical sampling paths or in systems that are not
stationary. The important point is that the parameter β can be used
to continuously tune for any desired trade-off, and to set the sam-
pling variance arbitrarily close to the optimal case.
This theorem is quite general and applies to any sampling prob-
lem provided the selected ground truth process has a convex auto-
covariance function. As already explained, in the probing context,
X(t) can refer to the simple delay Dx(t) and loss Ix(t) processes
and temporal properties thereof, and to train-based metrics too.
Theorem 2 can hence be used to decrease the variance of our es-
timate of px, the average loss probability associated with the loss
process Ix(t), or any other loss metric such as the train-loss pro-
cess I(cid:2)x,(cid:2)p(t), or M(cid:2)x,(cid:2)p(t), the number of packets in a train which are
lost.
3.2 Known Convex Examples
A natural question is, how likely is it that networks of interest sat-
isfy the convexity property for delay and/or loss? There are simple
systems for which exact results are known. For example, Ott [11]
showed that convexity holds for the virtual work process (equal to
the delay of probes with x = 0) of the M/G/1 queue.
We now show that the loss process Ix(t) of the M/M/1/K
queue, with the packet-based dropping model of Equation (2), has
a convex auto-covariance function. Denote by λ and μ the arrival
and the service rates and by ρ = λ/μ the load factor. From [19]
(p.13, Theorem 1), the probability that the number of customers in
the queue is K at time t, given that it is K at time 0, is
PK,K (t) =
1 − ρ
1 − ρK+1
exp(−(λ + μ)t + 2t
ρK +
KX
2
K + 1
√
1 − 2
· (sin(Kjπ/(K + 1)) − √
j=1
√
λμ cos(πj/(K + 1))
ρ cos(πj/(K + 1)) + ρ
ρ sin(jπ))2
(10)
in the case when ρ (cid:5)= 1 and
1
PK,K (t) =
+
KX
1 + K
exp(−(2λ)t + 2λt cos(πj/(K + 1))
1
1 − cos(πj/(K + 1))
K + 1
· (sin(Kjπ/(K + 1)) − sin(jπ))2
j=1
(11)
in the case ρ = 1. In both cases, the auto-covariance function of
Ix(t), which is equal to π(K)PK,K (t) (with π(K) the stationary
First Dataset
Second Dataset
P1
P2
Q3
Q2
P3
Q1
P5
P4
Q4
120
100
80
60
40
20
)
s
p
b
M
(
n
o
i
t
a
z
i
l
i
t
U
n
a
e
M
0
0
5
10
15
Time (Hours)
20
25
Figure 2: Utilization of the target output interfaces of the ﬁrst
and second datasets. We also mark P1-P5 and Q1-Q4, the rep-
resentative time intervals used to illustrate the results through-
out this paper.
probability that the queue has K customers) is a convex combina-
tion of convex decreasing functions of t and is hence itself convex
and decreasing in t.
4. FULL-ROUTER RESULTS
Our theorems on the estimation variance of various probing streams
are valid if the convexity condition is true. In the previous section,
we described two simple systems in which this condition is prov-
ably true. It is not possible, however, to prove analytical results
for real Internet trafﬁc. Hence, in this section, we use empirical
datasets to demonstrate the applicability of our results to real net-
works, namely, that the convexity condition holds true and that Er-
lang (Gamma) probing is superior to Poisson probing. We start by
describing our dataset.
4.1 The Full-Router Dataset
The dataset we use is the so-called ‘full-router’ experiment that
recorded all packets entering and exiting a router in the Sprint IP
backbone [12, 7, 13]. This dataset, along with a model of the
queueing process inside the router, enables us to compute the con-
tinuous time ground truth of the delay/loss metric being measured.
We rely on a model-driven approach since today’s routers cannot
be directly queried to obtain the ground truth in continuous time.
The full-router experiment involved a gateway router in the Sprint
backbone network. The input and output trafﬁc from all 6 inter-
faces of the router were monitored using DAG passive packet cap-
ture cards. Two of the interfaces were OC-48 links connecting the
router to two other backbone routers. The other 4 interfaces were
links to customers - two in Asia (OC-3 links) and two in the United
States (one OC-3 and one OC-12 link).
The passive packet capture cards were synchronized with the
same GPS signal and generated 64-byte records for each packet.
Excluding the layer-2 headers, this provided us with the 20-byte IP
headers and the ﬁrst 24 bytes of the IP payload. In this paper, we
use two datasets collected with the full-router experiment. The ﬁrst
of these was collected in August 2003 (and used in [7, 9, 13]) and
the second in January 2004. Both datasets captured packets from/to
the router for 24 hours.
1.2
1
0.8
0.6
0.4
0.2
0
e
c
n
a
i
r
a
v
o
C
−
o
t
u
A
2 Seconds
20 Seconds
200 Seconds
1.2
1
0.8
0.6
0.4
0.2
0
e
c
n
a
i
r
a
v
o
C
−
o
t
u
A
Q1
Q2
Q3
Q4
−0.2
−0.1
−0.05
0
Lag Values [secs]
0.05
0.1
−0.2
−0.05
0
Lag Values [secs]
0.05
Figure 3: (Left) Plot illustrating the convexity of the auto-covariance of the mean virtual delay for P1. Variance with the estimation
of the auto-covariance is signiﬁcant if we use only a few seconds of P1 to compute the auto-covariance. (Right) Plot illustrating the
convexity condition for Q1-Q4. The auto-covariance is computed using 200 seconds of these representative time intervals.
1.2
1
0.8
0.6
0.4
0.2
0
e
c
n
a
i
r
a
v
o
C
−
o
u
A
t
−0.2
−0.1
2 Seconds
20 Seconds
200 Seconds
−0.05
0
Lag Values [secs]
0.05
0.1
Figure 4: Plot illustrating the convexity condition for P2 using
the queueing model involving minimum transit times across the
router backplane.
We post-processed the dataset to match packets from the input
interfaces to the output interfaces. For details on the matching
procedure, we refer the reader to [7]. The matching procedure