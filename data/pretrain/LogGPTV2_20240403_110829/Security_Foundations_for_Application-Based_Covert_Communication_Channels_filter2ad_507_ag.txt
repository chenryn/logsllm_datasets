1978
provides the adversary with an entire transcript (of sufficient
length) such that each adversary functions like a probabilistic
predicate judging each application transcript as “good” or
“bad”.
Since each user induces a distribution over application
transcripts, we can extend this implicit adversarial judgment to
users as well. Informally, we will say that an adversary accepts
a user if it judges that user’s traffic as bad with sufficiently
low probability, and rejects a user otherwise. A statement of
passive security thus provides us with two interpretations:
(i) An adversary that accepts User0 will also accept User1
with the covert channel, and
(ii) an adversary that rejects User1 with the covert channel
will also reject User0.
Security arguments for the systems we discuss in this paper
often appeal to empirical evidence that the proposed scheme
produces traffic which is hard to distinguish—using known
analysis techniques that an adversary could be expected to
deploy—from traffic samples that represent typical (i.e., ex-
pected or unremarkable) use of the application in the target
deployment environment. In the context of such arguments, we
interpret User0 as something like an algorithmic exemplar of a
“typical” user; that is, a user which generates application traffic
that is commonly observed in the environment. Applying our
two interpretations, this implies that the adversary must either
accept some usage of the covert channel, or incur a heavy cost
in disrupting innocent users of the application.
We conclude this discussion by noting that the prominent
role of user models in hiding covert channels has (rightly)
gained more attention recently; a notable example is OUS-
tralopithecus [28] which borrows techniques from research on
bot detection to build a generic user simulator that drives an
ABCC.
B. Discussion and caveats
As discussed in the Introduction, we caution the reader in
how to interpret our security notion. In particular, Definition 9
targets an abstraction of a network covert channel and thus,
even if this abstraction is secure, the system itself (due to
implementation choices, etc.) may be vulnerable5. Thus, we
view a proof of security for a system with respect to our
notion as an important and necessary first step, but insufficient
for demonstrating security of any real-world deployment of
that system. The actual capabilities of real-world adversaries
(e.g., large-scale network censors) are a subject of ongoing
study [29, 30, 31, 32], and this brings up a particular cau-
tionary note: depending on one’s point of view, our security
notion could be viewed as both too strong and too weak.
The strength of the notion comes from its requirement
that a secure ABCC produce a network traffic profile that
is indistinguishable from the reference profile, which implies
that the adversary is observing and analyzing traffic—while
5As an example, Balboa relies on the timing delays introduced by its
processing to be minimal; if these are too large then the system could be
potentially identified.
maintaining state—for the entirety of the connection. While
it seems plausible to assume an adversary could devote such
resources to any given connection, it is clearly unreasonable
for even a state-level censor to apply this level of scrutiny to
every connection.
Many, perhaps most, network covert channels do not even
attempt to meet such a security goal, yet some are widely used
and generally effective in avoiding detection and blocking.
Some systems acknowledge their insecurity relative to such
an adversary, but assert that this is an unlikely attack vector
due to the resources required [33].
On the other hand, Definition 9 could also be viewed
as too weak since it does not capture active adversaries,
particularly those that engage in commonly observed anti-
circumvention tactics such as active probing [34]. Thus, one
could argue that it does not target real-world censors. We
agree, and view our passive security notion as an initial step
towards developing an active security notion, which we leave
for future work.
In spite of the substantial progress that has been made in
characterizing how these adversaries work in practice, there
is still much that is unknown and no clear limits on what
techniques may be used in the future. Given also that one
cannot know in advance the precise scenario in which a
network covert channel may be deployed, we believe that
targeting the strongest feasible adversary is the right approach.
This also aligns with a key principle in developing security no-
tions across cryptography: limit the assumptions placed on the
adversary to develop a notion with the broadest applicability.
VI. CHARACTERIZING SECURE CONSTRUCTIONS
We are now set to characterize some common ABCC
design patterns, and tease out assumptions that are necessary
for achieving pcc security. We are primarily interested in
application channels that employ a secure channel for network
transport, something we will denote with App[SC] in what
follows. §VII-A gives a generic way to build such an App[SC]
by composing a “plaintext” application channel App with
a secure channel SC in a straightforward manner. ABCCs
designed for such secured application-channels are generally
believed to provide better security, and are more widely used
in real deployments.
Loosely speaking, knowing that a network transport em-
ploys a secure channel allows Embedwire (in particular) to
worry only about the “shape” of the traffic it sends to the net-
work, relative to the shape of the traffic the application Source
would send. It also allows us to cleanly separate the contri-
butions of wc and ws to the distinguishability of overt and
covert traffic. More generally, we are able to analyze generic
wire-only and user-only constructions, without appealing to
the specific realizations of the component algorithms of the
ABCC.
For ABCCs built for plaintext application channels, clean
reasoning about generic constructions seems considerably
more difficult. In this setting, how one instantiates the ABCC
matters far more than when a secure channel can be relied
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:36:38 UTC from IEEE Xplore.  Restrictions apply. 
1979
upon to hide the particular bits on the wire and to (effectively)
flatten the distribution over network message. As such, we do
not present generic constructions or formal security theorems
for these classes of ABCCs. Nonetheless, the tools we de-
velop here do help us to make principled, informal security
statements about the security of “plaintext” ABCCs.
Table I provides an overview of some concrete schemes
discussed in §II and maps each scheme to its corresponding
architecture as discussed below.
A. Traffic matching
For applications that use a secure channel for message
transport, our intuition tells us that an eavesdropping adversary
learns nothing but the shape6 of each message sequence. Of
course, the mere use of a secure channel does not provide any
guarantee that a covert channel is secure, because the covert
channel may induce unique or unusual patterns of application
traffic that are easily distinguished.
In Figure 4 we present the covert shape (cs) and overt
shape (os) oracles, which capture this intuition as variants of
the cc and oc experiments, respectively, where both wc and ws
are randomized (each bit is replaced with the value of a coin
flip) before being returned in the query response. This allows
us to define a notion which precisely captures the change in
traffic patterns produced in the presence of the covert channel.
Definition 11 ((Traffic-)Shape indistinguishability). Fix appli-
cation channel App, user User, App-based covert channel Π,
and environment context ξ. Let CS be the game instantiated
by Expcs
App,User,Π,ξ and let OS be the game instantiated by
App,User,Π,ξ. For a fixed adversary A, define the traffic-
Expos
shape advantage as
Advts
App,User,Π,ξ(A) = ∆(CS, OS).
that ABCC Π is
We
say
(t, q, µ, ϵ)-shape-
indistinguishable relative to App, User, and ξ if, for all
A ∈ A(t, q, µ), the traffic-shape advantage is bounded from
♢
above by ϵ.
Remark. One could also model the “shape” of each sequence
through unary encoding; we choose to randomize the bits as it
simplifies the technical analysis for e.g. ABCCs which utilize
a secure channel that is indistinguishable from random bits.
With this definition in hand, we observe that the (fixed-User)
pcc-advantage can be written as
∆(CC, OC) = ∆(CC, CS) + ∆(CS, OS) + ∆(OS, OC)
(3)
where the middle term of the right-side is the traffic-shape
advantage and, in the case of ABCCs over stream-based chan-
nels, the first and last term can be bounded by straightforward
reductions to the IND-CPFA security (Definition 3) of the
channel. In §VII-B we use this equality to establish a theorem
6Since our applications output sequences rather than discrete strings, we
use the term shape to refer to the pattern of fragment lengths in a given
sequence.
statement about the security of secure transport ABCCs which
employ non-trivial user-side embedding.
B. Traffic replacement and recovery
ABCCs which employ non-trivial wire-side embeddings
have finer control over both the client and server traffic
observed by the adversary, as Embedwire directly outputs wc
and Extractwire can provide carefully chosen inputs to Sink
in order to influence the ws that it produces in response.
By working on the wire side of the application, Embedwire
learns the exact shape of the traffic and can substantially alter
the underlying messages while preserving this shape. The key
challenge here is ensuring that Extractwire can “undo” the