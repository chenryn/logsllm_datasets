### Issue Description

I have an NVIDIA P100 GPU that supports FP16 (half-precision floating point) and I am running the TensorFlow CIFAR-10 training script `cifar10_train.py`. When I run the script without the `--use_fp16` option, the performance is approximately 1,600 examples per second. However, when I use the `--use_fp16` option, the performance drops to around 500 examples per second. I am looking for insights into why this might be happening.

### Environment and Setup

- **GPU**: NVIDIA P100
- **TensorFlow Version**: 0.11
- **CUDA Libraries**:
  - libcublas.so.8.0
  - libcudnn.so.5
  - libcufft.so.8.0
  - libcuda.so.1
  - libcurand.so.8.0

### Performance Metrics

#### Without `--use_fp16` Option

```bash
userid@ubuntu-WK-4xP100:~/weike/tensorflow-r0.11/tensorflow/models/image/cifar10$ python cifar10_train.py
...
2016-11-14 00:07:57.143739: step 0, loss = 4.67 (12.1 examples/sec; 10.549 sec/batch)
2016-11-14 00:07:58.395209: step 10, loss = 4.57 (1693.6 examples/sec; 0.076 sec/batch)
2016-11-14 00:07:59.177525: step 20, loss = 4.97 (1668.9 examples/sec; 0.077 sec/batch)
2016-11-14 00:07:59.957789: step 30, loss = 4.43 (1588.3 examples/sec; 0.081 sec/batch)
2016-11-14 00:08:00.738431: step 40, loss = 4.52 (1690.5 examples/sec; 0.076 sec/batch)
2016-11-14 00:08:01.501940: step 50, loss = 4.33 (1680.4 examples/sec; 0.076 sec/batch)
2016-11-14 00:08:02.241604: step 60, loss = 4.20 (1733.4 examples/sec; 0.074 sec/batch)
2016-11-14 00:08:03.001845: step 70, loss = 4.27 (1706.0 examples/sec; 0.075 sec/batch)
2016-11-14 00:08:03.765522: step 80, loss = 4.18 (1601.3 examples/sec; 0.080 sec/batch)
2016-11-14 00:08:04.516780: step 90, loss = 4.25 (1646.3 examples/sec; 0.078 sec/batch)
```

#### With `--use_fp16` Option

```bash
userid@ubuntu-WK-4xP100:~/weike/tensorflow-r0.11/tensorflow/models/image/cifar10$ python cifar10_train.py --use_fp16
...
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
...
2016-11-14 00:09:09.382854: step 0, loss = 4.67 (12.3 examples/sec; 10.411 sec/batch)
2016-11-14 00:09:11.923842: step 10, loss = 4.58 (659.6 examples/sec; 0.194 sec/batch)
2016-11-14 00:09:13.918448: step 20, loss = 6.62 (460.6 examples/sec; 0.278 sec/batch)
2016-11-14 00:09:16.211809: step 30, loss = 4.37 (583.7 examples/sec; 0.219 sec/batch)
2016-11-14 00:09:18.327690: step 40, loss = 4.30 (618.3 examples/sec; 0.207 sec/batch)
2016-11-14 00:09:20.395409: step 50, loss = 4.37 (643.8 examples/sec; 0.199 sec/batch)
2016-11-14 00:09:22.466230: step 60, loss = 4.32 (574.0 examples/sec; 0.223 sec/batch)
2016-11-14 00:09:24.533225: step 70, loss = 4.17 (646.2 examples/sec; 0.198 sec/batch)
2016-11-14 00:09:26.609277: step 80, loss = 2.59 (601.5 examples/sec; 0.213 sec/batch)
2016-11-14 00:09:28.703648: step 90, loss = 4.15 (625.5 examples/sec; 0.205 sec/batch)
```

### Analysis and Questions

- **Performance Drop**: The performance significantly drops from 1,600 examples/sec to 500 examples/sec when using FP16. This is unexpected as FP16 should generally offer better performance due to reduced memory bandwidth and computational requirements.
- **Potential Causes**:
  - **Driver or CUDA Version Mismatch**: Ensure that the CUDA and cuDNN versions are compatible with the TensorFlow version and the P100 GPU.
  - **FP16 Support in Model**: Verify that the model and operations used in the script are fully optimized for FP16. Some operations may not be supported in FP16 and could be causing a fallback to FP32, leading to performance degradation.
  - **TensorFlow Configuration**: Check if there are any specific configurations or flags in TensorFlow that need to be set for optimal FP16 performance.

### Next Steps

- **Check Compatibility**: Verify the compatibility of the CUDA, cuDNN, and TensorFlow versions.
- **Model Optimization**: Review the model and ensure all operations are FP16 compatible.
- **Configuration Settings**: Explore TensorFlow configuration settings for FP16 and ensure they are correctly applied.

If you have any additional details or need further assistance, please let me know.