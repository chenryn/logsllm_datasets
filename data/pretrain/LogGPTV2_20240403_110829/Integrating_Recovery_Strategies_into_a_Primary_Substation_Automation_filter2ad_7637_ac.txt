to  be  connected  to  that  portion  of  the  field.  We  assume 
that 
target  node  N2  provides  better  computing 
performance than N1. 
The start-up configuration is the optimal distribution of 
application  tasks  onto  the  heterogeneous  hardware.  The 
most  performant  configuration,  Config_0  in  Table  2, 
does  not  require  off-node  communication  among  the 
application tasks: 
Proceedings of the 2003 International Conference on Dependable Systems and Networks (DSN’03) 
0-7695-1959-8/03 $17.00 (c) 2003 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 07:03:25 UTC from IEEE Xplore.  Restrictions apply. 
N2
Config_0 PARALLEL_TRS  STRAT, 
N1
Config_1 CRASHED
Config_2 PARALLEL_TRS
BUSBAR1,
BUSBAR2
PARALLEL_TRS
STRAT,
BUSBAR1,
BUSBAR2
CRASHED
Config_3 STRAT,
-
BUSBAR1,
BUSBAR2
N3
-
-
STRAT
BUSBAR1,
BUSBAR2
CRASHED
Table 2: Different configurations to allocate 
active PSAS application tasks to target nodes
•  no application task is allocated to N3, whose BSW acts as 
master  and  handles  communication  with  the  remote 
control center; 
•  PARALLEL_TRS runs on N1; 
•  BUSBAR1, BUSBAR2, and STRAT are allocated to N2. 
•  Each  application  task  has  at  least  one  standby  replica 
task_Ri on a different target node Ni (i=1..3).
3.3  PSAS recovery strategy 
faults 
affecting 
the 
information 
In  order  to  cope  with  temporary  and  permanent 
physical 
and 
communication infrastructure of the PSAS, an appropriate 
recovery strategy has been designed and coded as a set of 
Ariel recovery scripts. It combines different kinds of error 
detection  mechanisms,  error 
system 
reconfiguration. Reconfiguration is statically associated to 
the  crash  of  a  single  node.  If 
two  nodes  crash 
simultaneously  no 
is  possible.  The 
reconfiguration 
following scripts are examples of recovery actions.  
recovery  and 
Example 1. If a slave node (e.g., N1) crashes, the LAN 
Monitor  detects  this  event  and  notifies  the  BackBone 
executing the following Ariel code: 
IF
[FAULTY NODE{N1} AND RUNNING NODE{N2} AND 
RUNNING NODE{N3} AND
PHASE(TASK{BSW_M}) == {NEW_CYCLE_PH}]
THEN
ISOLATE NODE{N1} 
SEND {CONFIG_1} TASK{BSW_MSG_M}
SEND {CONFIG_1} GROUP{BSW_SLAVE_GROUP}
RESTART GROUP{EXECUTIVE_GROUP} 
RESTART TASK{PARALLEL_TRS_R2} 
FI
If the guard of the above script is fulfilled, application 
tasks  are  reconfigured  as  CONFIG_1  from  Table  2. 
CONFIG_1  maintains  the  full  PSAS  functionality  by 
transferring  Parallel_TRS  to  N2,  actually  activating  its 
spare  replica.  This  node  is  able  to  cope  with  the  whole 
computational  load,  as  it  does  not  need  to  perform 
communication  requested  by  the  BSW_M’s  functions.  To 
avoid  undesired  interference  by  the  BackBone  during 
critical  phases  of  BSW_M  activity,  a  condition  on  the 
current  execution  phase  (PHASE(TASK{BSW_M})  == 
{NEW_CYCLE_PH})  must  be  satisfied  in  conjunction  with 
the  crash  test.  The  ISOLATE  NODE  action  corresponds  to 
informing  other  nodes  that  they  may  not  accept  any 
message  from  the  isolated  peer  -even  if  it  comes  alive 
again- until the isolation is undone. 
Example 2. If a target node (e.g. N2) crashes during a 
different  execution  phase  of  the  master  BSW,  then  this 
error  is  notified  by  the  BSW_M  to  the  BackBone  (through 
RaiseEvent(RE_BSW_error)),  causing  the  execution 
of the following ARIEL code: 
IF [EVENT {RE_BSW_error}] 
THEN
IF [FAULTY NODE{N2} AND RUNNING NODE{N3}] 
THEN
ISOLATE NODE{N2} 
SEND {CONFIG_2} TASK{BSW_MSG_M} 
SEND {CONFIG_2} TASK{BSW_MSG_S1} 
RESTART GROUP{EXECUTIVE_GROUP} 
RESTART TASK{BUSBAR1_R3}, TASK{BUSBAR2_R3}, 
TASK{STRAT_R3}
RESTART TASK{PARALLEL_TRS_R1} 
FI
FI
Hence  the  system  is  reconfigured  as  Config_2:  the 
spare  replicas  of  BUSBAR1, BUSBAR2  and  STRAT  are 
activated on N3. 
is  running), 
Example 3. In case of a fault on target node N3 (where 
BSW_M
is 
executed, triggered by error detection by the LAN Monitor 
and subsequent notification to the Backbone: 
IF
the  following  ARIEL  code 
[FAULTY NODE{N3} AND RUNNING NODE{N1} AND 
RUNNING NODE{N2}] 
THEN
ISOLATE NODE{N3} 
SEND {CONFIG_3} GROUP{BSW_SLAVE_GROUP} 
SEND {BACKUP_MASTER} TASK{BSW_MSG_S2}
RESTART GROUP{EXECUTIVE_GROUP} 
STOP TASK{PARALLEL_TRS} 
RESTART TASK{STRAT_R1}, TASK{BUSBAR1_R1}, 
TASK{BUSBAR2_R1}
FI
Hence, the function of master node is transferred to N2 
and  the  application  tasks  of  N2  are  moved  to  N1.  As  N1 
cannot  support  both  application  functions  simultaneously, 
PARALLEL_TRS is disabled, thus proceeding to a graceful 
degradation of the automation system (config_3).
Evaluation.  Other 
recovery  strategies,  such  as 
restarting  all  tasks  on  a  node  after  a  transient  fault,  or 
shutting  down  the  system  when  reconfiguration  is  not 
possible,  have  also  been  coded 
in  ARIEL  and 
implemented.  We  did  not  provide  recovery  strategies 
associated with a crash of N4 or N5, because they are not 
target  nodes,  they  are  not  concerned  with  the  automation 
control  function 
the 
application  is  not  endangered.  In  a  real  deployment  they 
could be replicated or could backup each other.  
itself;  so  even 
they  crash, 
if 
Figure  3  shows  the  user  interface  of  the  pilot 
application demonstrator. 
Proceedings of the 2003 International Conference on Dependable Systems and Networks (DSN’03) 
0-7695-1959-8/03 $17.00 (c) 2003 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 07:03:25 UTC from IEEE Xplore.  Restrictions apply. 
and  error  recovery  programs  provides  flexibility  to 
modify  recovery  strategies  without  requiring  major 
modifications  to  the  application,  while  tolerating  the 
same  physical  faults  as  in  the  dedicated  hardware 
solutions. 
Acknowledgements.  This  project  has  been  partially  supported 
by European project IST-2000-25434 (www.DepAuDE.org), the 
K.U.Leuven Research Council (GOA/2001/04), and the Fund for 
Scientific  Research  -  Flanders  (Belgium,  F.W.O.)  through  the 
Postdoctoral  Fellowship  for  Geert  Deconinck  and  “Krediet  aan 
Navorsers” 1.5.148.02.
5  References 
[1]  Anon., “Editor Grafico di ASFA – Manuale Utente”, ENEL 
internal report 1995; in Italian. 
[2]  A. Bertani, S. D’Imporzano, P. Perna, “Requisiti funzionali 
dell’ACL,” ENEL internal report SRI-AD-SA 99/261, Jun. 1999; 
in Italian.  
[3]  K.  Caird,  “Integrating  Substation  Automation”,  IEEE 
Spectrum, Aug. 1997, pp. 64-69. 
[4]  E. Ciapessoni, F. Maestri et al., “Partitioning of Hierarchical 
Automation  Systems,”  Proc.  Euromicro  Conf.  on  Real-time 
Systems, Delft, The Netherlands, Jun. 2001, pp. 143-153. 
[5]  G. Deconinck,  O. Botti,  et  al.,  “Stable  Memory 
in 
Substation  Automation:  a  Case  Study,”  Proc. 28th  Ann.  Int. 
Symp. on Fault-Tolerant Computing (FTCS), Munich, Germany, 
Jun. 1998, pp. 452-457. 
[6]  G.  Deconinck,  V.  De  Florio,  O.  Botti:  “Software-
Implemented  Fault  Tolerance  and  Separate  Recovery  Strategies 
Enhance Maintainability,” IEEE Trans. Reliability, Vol. 51, No. 
2, Jun. 2002, pp. 158-165. 
[7]  G.  Deconinck,  V.  De  Florio,  et  al.,  “A  Software  Library,  a 
Control  Backbone  and  User-Specified  Recovery  Strategies  to 
Enhance  the  Dependability  of  Embedded  Systems,”  Proc.  25th
Euromicro  Conf., Worksh.  on  Dependable  Computing  Systems,
Milan, Italy, Sep. 1999, pp. II 98-104. 
[8]  V.  De  Florio,  G.  Deconinck,  “REL:  A  Fault-Tolerance 
Linguistic  Structure  for  Distributed  Applications,”  Proc.  9th
IEEE  Conf.  and  Workshop  on  Engineering  of  Computer-Based 
Systems (ECBS-2002), Lund, Sweden, Apr. 2002, pp. 51-58. 
[9]  T.E.  Dy-Liacco,  “Control  centers  are  here  to  stay,”  IEEE 
Computer Appl. in Power, Vol. 15, No 4, Oct 2002, pp. 18-23.  
[10] R.  Gargiuli,  P.G.  Mirandola,  et  al.,  “ENEL  Approach  to 
Computer  Supervisory  Remote  Control  of  Electric  Power 
Distribution  Network,”  Proc.  6th  IEE  Int.  Conf.  on  Electricity 
Distribution (CIRED’81), Brighton (UK), 1981, pp. 187-192. 
[11] F.  Maestri.  R.  Meda,  G.L.  Redaelli,  “Un  ambiente  di 
sviluppo  di  funzioni  applicative  strutturate  per  sistemi  di 
automazione di impianti ENEL,” Automazione e strumentazione,
Dec. 1997); in Italian. 
[12] G.  Mazzini,  G.P.  Nizzoli,  P.  Bergamo,  “Measurements  of 
Redundant  Source-Routing,”  Proc.  IEEE  10th  Int.  Conf.  on 
software, 
networks 
(SoftCOM), Split, Croatia, Oct. 2002, pp. 95-99. 
[13] A.  Moro,  “Traduttore  delle  reti  ASFA,”  Tesi  di  laurea,
Politecnico di Milano, 1998; in Italian. 
[14] P.  Veríssimo,  L.  Rodrigues,  “Distributed  Systems  for 
System Architects,” Kluwer Academic Publishers, Boston, 2001, 
648p. 
telecommunications 
computer 
and 
Figure 3: User interface for application 
supervision and active task allocation 
4  Summary and lessons learned  
the 
integration  of 
The  lack  of  flexibility  that  is  inherent  to  dedicated 
hardware-based  fault  tolerance  solutions  makes  their 
adoption  not  cost-effective 
in  cases  where  similar 
functionality  has  to  be  deployed  in  several  sites,  each 
characterized  by  a  slightly  different  environment.  This 
paper  presented 
the  DepAuDE 
architecture  into  the  distributed  automation  system  of  a 
primary substation. The deployment of this fault tolerance 
middleware  allows  different  recovery  strategies  to  be 
integrated  on  a  heterogeneous  platform. Given 
the 
generality  of  the  methods  and  techniques  used  the 
designed  solution  is  applicable  to  a  wide  class  of  process 
automation  systems.  Following  points  summarize  the 
lessons learned:  
•  The  ASFA  design  environment  with  automatic  code 
generation  provides  several  advantages:  less  develop-
ment time, absence of coding errors, portable application 
code  and  possibilities  for  application  partitioning.  It  is 
straightforward  to  interface  it  to  IEC  61850-compliant 
Intelligent Electronic Devices (IED).  
•  The  implementation  effort  required  to  integrate  the 
DepAuDE  BSL  into  an  ASFA  application  was  limited 
(about  2400  lines  of  code  for  the  RMOS  and  VxWorks 
targets). The communication mechanism supplied by the 
DepAuDE  BSL  provided 
inter-process 
communication  among  ASFA  application  tasks.  The 
grouping  of  tasks  revealed  useful  when  implementing 
the  standby  replicas.  Inter-processor  communication 
among  application  tasks  strongly  influences  application 
performance  and  reconfiguration  time  in  case  of  faults. 
Therefore inter-processor data flow should be avoided if 
possible, or at least minimised. 
•  The  deployment  of  the  DepAuDE  middleware  allowed 
integrating  several  recovery  strategies  on  a  hetero-
geneous  platform. The  separation  between  functional 
transparent 
Proceedings of the 2003 International Conference on Dependable Systems and Networks (DSN’03) 
0-7695-1959-8/03 $17.00 (c) 2003 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 07:03:25 UTC from IEEE Xplore.  Restrictions apply.