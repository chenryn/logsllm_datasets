as to which actual software components (round nodes) are
restarted. In this example, nodes A, B, and C are software
components; when we push the button on RBC, both B and
C are restarted; when we push the button on RB, only B is
restarted.
3.2. Restart Groups, MTTF, and MTTR
Subtrees in the restart tree are called restart groups, in
close analogy with process groups in UNIX. The fact that a
number of nodes are together in a restart group captures the
fact that there is commonality among them with respect to
restarting. The tree in Figure 2 contains 5 restart groups:
three trivial ones (RA, RB, RC) and two non-trivial ones
(RB, RC, RBC form a group rooted at RBC, and RA,
RBC, RB, RC, RABC form another restart group rooted
Proceedings of the International Conference on Dependable Systems and Networks (DSN’02) 
0-7695-1597-5/02 $17.00 © 2002 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 04:24:15 UTC from IEEE Xplore.  Restrictions apply. 
at RABC). When we say that we restart a group, that means
that all components attached to leaves of the respective sub-
trees will be restarted; in the case of the group rooted at
RBC, these components would be B and C. The system
as a whole is always a restart group. As will be shown in
section 4, we can recursively reason about the availability
properties of the system in terms of restart groups.
For consistency with industrial practice, we will refer
to the MTTF and MTTR of individual components, restart
groups, and the system as a whole. The time-to-recover
a component includes the time it takes to detect that it
failed—downtime starts when the failure occurs, not when
it is detected.
We must note that MTTF and MTTR constitute an impov-
erished representation of the failure behavior of a system or
subsystem. Without knowing more about the distribution
of failure or recovery times, one cannot predict the prob-
ability that a subsystem will fail during a particular time
interval, which may be important since not all downtime is
equally expensive. The techniques we will describe in this
paper for constructing and evolving restartability trees are
based on the assumption that MTTF and MTTR represent the
means of distributions with small coefﬁcients of variation.
We have conﬁrmed through experiment that this is the case
with our system, and for compactness we will henceforth
use the notations MTTFS and MTTRS to refer to the MTTF
and MTTR, respectively, of subsystem S. In particular, we
assert that the MTTF for a restart group G containing com-
ponents c0; c1; : : : ; c is MTTFG (cid:20) iMTTFci, and that
the corresponding MTTR is MTTRG (cid:21) axMTTRci .
3.3. The Recoverer and the Oracle
The restart tree plays a central role in keeping a recur-
sively restartable system alive, in conjunction with a recov-
erer, which performs the actual restarts. A recoverer does
not make any decisions as to which component needs to
be restarted—that is captured in the oracle, which repre-
sents the restart policy. Based on information about which
component has failed, the oracle tells the recoverer which
node in the tree to restart.
If a restart at that point ﬁxes
the problem, then the system continues operation normally.
However, if the failure still manifests (or another failure ap-
pears) even after the restart completes, the oracle moves up
the tree and requests the restart of the node’s parent. This
process can be repeated up to the very top, when the entire
system is restarted. In our ground station, we have collo-
cated the recoverer and the oracle in the REC component,
shown in Figure 1.
We say a failure is -curable if it is cured by a restart at
node  or any of its ancestors in the restart tree. A minimally
-curable failure is a failure that is -curable and  is the
lowest node in the tree for which a restart will cure the fail-
ure. Admitting that mean-time-to-repair is non-decreasing
as we move up the tree, a minimal cure implies the failure
is resolved with minimal downtime. For a given failure, it is
possible for  to not be unique (e.g., if restarting the parent
of  is no more expensive than restarting  itself). A per-
fect oracle is expected to embody the minimal restart policy,
i.e., for every minimally -curable failure, it recommends a
restart of node . In section 4.4 we illustrate what happens
when the oracle is imperfect.
4. Evolving the Restart Tree
Having introduced the concept of a restart tree, we show
on the left side of Figure 3 a simple restart tree for Mercury
(tree ), consisting of a single restart group. The only pos-
sible policy with this tree is to reboot all of Mercury when
something goes wrong. The system MTTF is at least as bad
as the lowest MTTF of any component, and its MTTR at least
as bad as the highest MTTR of any component. Table 1
shows rough estimates of component failure rates, made by
the administrators who have operated the ground station for
the past two years. The components that interact with hard-
ware are particularly prone to failure, because they do not
fully handle the wide variety of corner cases.
Component
MTTF
b	
1 month
fedc e
5 hr
10 min

5 hr
	
5 hr
Table 1. Observed per-component MTTFs
In Mercury, each software component is failure-isolated
in its own Java virtual machine (JVM) process, a failure
in any component does not necessarily result in failures in
others, and a restart of one component does not necessarily
entail the restart of others. This suggests the opportunity to
exploit partial restarts, as discussed in section 3, to lower
MTTR. Set against this opportunity is the reality that some
failures do propagate across JVM boundaries. Moreover,
restarting some components can cause other components to
need a restart as well. Both result in observed correlated
failures. In the former case, a state dependency leads to a
restart dependency; in the latter case, a functional depen-
dency leads to a restart dependency. In the rest of this sec-
tion we describe how to modify the trivial restart tree to re-
duce the MTTR of the overall system, illustrating which tree
modiﬁcations are most effective under speciﬁc conditions
of correlated failures.
We describe three techniques: depth augmentation, that
results in the addition of new nodes to the tree, and group
consolidation and node promotion, that result in the removal
of nodes from the tree. Since the focus of the present work
is investigation of a recovery strategy designed for transient
failures, we make the following simplifying assumption,
Proceedings of the International Conference on Dependable Systems and Networks (DSN’02) 
0-7695-1597-5/02 $17.00 © 2002 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 04:24:15 UTC from IEEE Xplore.  Restrictions apply. 
that does hold for our system:
Ac	e: All failures that occur are detectable by FD
and curable through restart.
This assumption is consistent with the fail-silent and restart
properties of our system’s components. It remains to future
work to detect non-fail-silent failures, and to diagnose fail-
ures as restart-curable or not, either proactively, or as the
result of being unable to resolve through restart.
Another assumption, Aeie, arises when there is no
functional redundancy in the system; it would not neces-
sarily apply, for example, to a cluster-based Internet server
with hot standby nodes or similar functional redundancy:
Aeie: A failure in any component will result in
temporary unavailability of the entire system.
4.1. Simple Depth Augmentation
A failure in any component of tree  will result in a
maximum-duration recovery. For example, 	 takes less
than 6 seconds to restart, whereas fedc takes over 21
seconds. Whenever 	 fails, we would need to restart
the entire system and wait for all components, including
fedc,
to come back up, hence incurring four times
longer downtime than necessary. In this argument we im-
plicitly assume that components can restart concurrently,
without signiﬁcantly affecting each other’s time-to-restart.
Tree I
Tree II
mbus
fedrcom ses
str
rtu
mbus
fedrcom ses
str
rtu
Figure 3. Simple depth augmentation gives tree .
The “total reboot” shortcoming can be ﬁxed by modifying
the tree to allow for partial restarts, which can cure subsys-
tems containing one or more components without bringing
the entire system down. Figure 3 illustrates this transforma-
tion.
To measure the effect this transformation has on system
recovery time, we cause the failure of each component (us-
ing a SIGKILL signal) and measure how long the system
takes to recover. We log the time when the signal is sent;
once the component determines it is functionally ready, it
logs a timestamped message. The difference between these
two times is what we consider to be the recovery time. Ta-
ble 2 shows the results of 100 experiments for each failed
component.
In the new restart tree , each restart group (except the
root) contains exactly one component. Because of Aeie,
the system’s MTTF has not changed under the new tree, but
its MTTR is lower, because a failure in a component can
potentially be cured by restarting a subset of the compo-
nents, possibly only the failed component. Speciﬁcally, for
a restart group G,
MTTR
G = X fciMTTRci
where ci is G’s i-th child, and fci represents the probability
that a manifested failure in G is minimally ci-curable. As
mentioned earlier, all observed failures in our ground station
prototype were restart-curable, so the sum of fci in any G is
1. As long as our system contains some component ck such
that fck > 0 and MTTRck 6= axMTTRci, the result will
be that MTTR < MTTR, since MTTR = axMTTRci .
Note in Table 2 that axMTTRci is different in the two
trees. A whole system restart causes contention for re-
sources that is not present when restarting just one com-
ponent; this contention slows all components down.
Failed node b	
24.75
MTTR
MTTR
5.73
e
24.75
9.50

24.75
9.76
	
24.75
5.59
fedc
24.75
20.93
Table 2. Tree II recovery: time to detect failed com-
ponent plus time to recover system (in seconds).
Given that restart tree  now has more than one restart
group, we must assume that the oracle is perfect, as de-
scribed in section 3 (in section 4.4 we will relax Aac e):
Aac e: The system’s oracle always recommends the
minimal restart policy.
Another assumption we have made in this transformation is
that the restart groups are independently restartable:
Aideede : Restarting a group will not induce fail-
ure(s) in any component of another restart group.
This assumption is important for recursive restartability, as
it captures the requirement of strong fault-isolation bound-
aries around groups.
In section 4.3 we describe how to
transform the restart tree so that it preserves this property
even when the design of our components impose the relax-
ation of Aideede.
4.2. Augmenting Depth of Tight Subtrees
An interesting observation is that components may be
decomposable into sub-components that have highly dis-
parate MTTR and MTTF. In our system, the fedc com-
ponent connects to the serial port at startup and negotiates
communication parameters with the radio device; there-
after, it translates commands received from the other com-
ponents to radio commands. Due to the hardware negotia-
tion, it takes a long time to restart fedc; due to instability
in the command translator, it crashes often. Hence fedc
has high MTTR and low MTTF—a bad combination.
Proceedings of the International Conference on Dependable Systems and Networks (DSN’02) 
0-7695-1597-5/02 $17.00 © 2002 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 04:24:15 UTC from IEEE Xplore.  Restrictions apply. 
We therefore split fedc into the bc component,
which maps a serial port to a TCP socket, and fed, the front
end driver-radio that connects to bc over TCP. bc
is simple and very stable, but takes a long time to recover
(over 21 seconds); fed is buggy and unstable, but recov-
ers very quickly (under 6 seconds). After restructuring the
code and augmenting the restart tree (Figure 4), it becomes
possible to restart the two components independently. We
show the intermediate tree ’, which is identical to tree ,
except the fedc component is split.
Tree II’
Tree III
mbus fedr
pbcom
ses
str
rtu
mbus
ses
str
rtu
fedr
pbcom
Figure 4. Subtree depth augmentation: tree .
The new tree  has no effect on the system’s MTTF,
as the split did not affect the failure characteristics of what
used to be fedc.
All failures that were previously minimally curable by a
restart of fedc are now minimally curable by a restart
of bc, a restart of fed, or a restart of both. Since
MTTRfed (cid:28) MTTRbc and MTTFfed (cid:28) MTTFbc,
most of the failures will be cured by quick fed restarts
and a few of the failures will result in slow bc restarts,
whereas previously they would have all required slow