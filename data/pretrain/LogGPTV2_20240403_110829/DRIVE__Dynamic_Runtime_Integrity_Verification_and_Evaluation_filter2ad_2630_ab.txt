Values either by simulating the load process of Trusted ELF-
Files or searching a valid precomputed Reference Value. In
case a valid reference value was determined, the individual
measurement represents a well-known state. Subsequently,
the process is repeated for every other measurement in the
DML. If all measurements were veriﬁed successfully, the mea-
surements are considered as reliable, accounted by 7 the
System State Decision. In addition to the aforementioned
steps, further veriﬁcation steps, based on diﬀerent meta-data,
such as access permissions, sizes, etc., can also be applied
during the veriﬁcation. The veriﬁcation process is further
described in Section 4.6.
4. MEASUREMENT AND VERIFICATION
CONCEPT
This section introduces the technical measurement and ver-
iﬁcation concepts of DRIVE. In particular, we will present a
technical solution to continuously measure, report and verify
measurements, acquired during the runtime of diﬀerent soft-
ware components in both user- and kernel-space. Due to its
design, DRIVE is not aﬀected by concurrency, ASLR, stack
protection or dynamic library pre- or late-loading mecha-
nisms, all these concepts are fully supported and considered.
Still, concrete implementations of the solution may utilize
diﬀerent methods and components for measurement acquisi-
tion and algorithms during veriﬁcation; however, the general
concepts remain similar for diﬀerent hardware and system
architectures.
4.1 Behavior and Predictability of Object
Code Fragments
DRIVE’s concept relies on two inevitable requirements:
(R1) the ability to measure ELF’ segments or sections in
memory and (R2) verify the measurements with a reduced
set of available information based on white-lists of reliable
information.
In many cases, R1 is a weak requirement that mainly de-
pends on the correct access permissions determined by the
OS conﬁguration. This means, by fulﬁlling the preconditions
for being able to read targeted memory areas, it is possible
to acquire any desired measurement. Still, one major issue
in this regard is to identify certain designated memory areas,
which will be discussed later in Section 4.3.
The major problem DRIVE solves is to fulﬁll requirement
R2, i.e. the successful veriﬁcation of acquired measurements.
Many approaches [13, 35, 24, 3] solve this problem by taking
Table 1: Access Permissions and Runtime Behavior
of Runtime ELF Segments and Encapsulated Sec-
tions
VAS Segment
Name Perm
Perm Type
ELF Section
Name
.text
.init
.plt
.rodata
.data
.bss
.got
--
--
r-x
r-x
r-x
r--
rw-
rw-
rw-
--
--
sp
sp
sp
sp
du
du
dp
du
du
.text
r-x
.data
Heap
Stack
rw-
rw-
rw-
Permissions: (r)ead, (w)rite, e(x)ecute
Type: (d)ynamic, (s)tatic, (p)redictable (u)npredictable
a measurement and simply compare this measurement to a
previously acquired runtime reference measurement that was
taken in an assumed or known reliable system state. In con-
trast to this, DRIVE does not rely on such initial reference
measurements on the targeted system, but solely on current
runtime information and involved well-known ELF ﬁles. This
enables the deﬁnition of a reliable system state externally
and totally isolated and independent from the targeted sys-
tem. For this reason, DRIVE depends on the predictability of
measured memory areas, whereas the predictability depends
on the runtime behavior. Table 1 depicts individual encapsu-
lated ELF sections according to their dynamic behavior. The
categories are (s)tatic and (d)ynamic and the predictabil-
ity is classiﬁed by (p)redictable or (u)npredictable.
As expected, there exists a correlation between non-
writable sections and static runtime behavior. This means, a
section or segment which is not writeable, is not expected to
change during its runtime2. Therefore, as a general rule, if a
segment is not writable, its behavior is static and predictable.
Consequently, the entire .text segment is both static and
predictable and fulﬁlls R2. This means a successful veriﬁ-
cation is self-evident. Veriﬁcation of .text segments will
further be discussed in Section 4.5.
In contrast, the .data segment is ﬂagged writeable and
encapsulates both predictable and unpredictable sections.
Therefore, the segments’ content behaves dynamic and
changes during runtime arbitrarily. Still, not all encapsu-
lated sections are considered unpredictable. While the .data
and .bss sections are, the .got section, a table involved in
function address resolution, is considered as predictable and
thus can also be veriﬁed by DRIVE. The .got section ver-
iﬁcation processes will be discussed further in Section 4.5.
As an example of dynamic and unpredictable segments, the
heap and stack segments are worth to be mentioned. Due
to their fast changing and arbitrary behavior, their contents
cannot be veriﬁed by DRIVE.
As explained, the behavior and predictability of whole seg-
ments or the individual sections aﬀects the measurement
and the veriﬁcation processes. While static segments can
be measured as a single instance, dynamic sections must
be measured individually. However, veriﬁcation processes
of dynamic sections are only applicable if the contents are
predictable. As a result, the veriﬁcation of unpredictable dy-
2There exist hot-patching mechanisms and self modifying
code which actually change read-only segments legitimately
during runtime. Both concepts are left to be analyzed and
researched in future work.
731namic sections or segments is considered impracticable for
DRIVE and thus not considered.
In addition to the behavior, Table 1 also shows the access
permissions of the mentioned segments and lists their des-
ignated ELF object code sections encapsulated inside the
segment, along with their individual access permissions, i.e.
(r)ead, (w)rite and e(x)ecute. In speciﬁc circumstances,
mappings with rwx permissions exist and are indeed neces-
sary as, e.g., Virtual Machine and interpreter based program-
ming languages often require access permissions considered
as insecure.
DRIVE facilitates access permissions as an indicator for
potential threats and therefore measures them as meta-data.
The meta-data is also analyzed during the veriﬁcation phase
and if unexpected changes to access permissions are detected
the system is considered as compromised and becomes un-
trusted. This is especially important, but not limited, to
unpredictable segments where content veriﬁcation cannot be
applied. Meta-data manipulation can cause severe harm to
the system security [31] and, for this reason, is considered
very important and treated seriously by our approach. Meta-
data veriﬁcation is further discussed in Section 5.1 and 4.5.
4.2 Relocatable and Position Independent
Code
Generally, object code can be categorized into two diﬀer-
ent variants inﬂuencing the loading process of ELF and the
transformation into a ready-to-run state. There exists: (1)
Relocatable Code (RCC), which depends on ﬁxed memory
addresses that, requires transformation by the linker or loader
prior to their execution; on contrary, (2) Position Indepen-
dent Code (PIC) does not rely on ﬁxed memory addresses
and, thus, can be executed from arbitrary memory addresses.
In this section we will discuss both variants brieﬂy and ex-
plain how both variants aﬀect the DRIVE concept.
Relocatable Code. RCC is the standard mechanism for ex-
ecutable object code in user-space, the Kernel, and LKM in
kernel-space. Necessary relocations that rely on ﬁxed memory
addresses are resolved either during the object code linking
phase or during the load-time under assistance of the dy-
namic linker/loader [17]. More precisely, executable object
code – or in other words applications – in user-space and the
OS kernel are link time relocated; they use and rely on ﬁxed
loading addresses and therefore can already be relocated dur-
ing the linking phase [18]. For the link time relocated object
code, the instructions already contain the concrete target
addresses for all symbols. This means the .text segment
object code within the ELF is equal to the object code in
the memory segment. LKMs, on the other hand, are loaded
at arbitrary dynamic addresses. For this reason, they must
be relocated during their loading process. The LKM ELF
contains a speciﬁc symbol table and the object code uses
placeholders for all referenced symbols. During the loading
process, the loader analyses the symbol table, resolves the
target addresses of the symbols and patches the object code
placeholders with resolved addresses3. In case of LKM load-
ing, symbols from both the Kernel and other LKMs must be
resolved and are considered.
Although RCC plays a negligible role for shared libraries
today, the process of symbol resolution and object code patch-
ing is similar as described for LKMs. Instead of the LKM
3The patching process is also often called ﬁx-up.
loader, ld is responsible for relocation, whereas symbols from
other libraries are the main target during the symbol resolu-
tion process.
As a result, the veriﬁcation of load-time relocated RCC de-
pends on dynamic addressing similar to the .got veriﬁcation,
discussed in Section 5.1. Thus, in order to verify load-time
relocated RCCs, the symbol resolution and patching process
must be simulated during veriﬁcation, considering loading ad-
dresses of required external dependencies. This means, the
technical veriﬁcation solution extracts the .text segment
from the ELF, resolves symbol addresses and patches them
into the related placeholders. More technical details about
this process are described in Section 4.5.
Position Independent Code. Generating PIC for shared
libraries is the default behavior in any modern Linux distri-
bution. All shared libraries in Linux are indeed PIC.
During the loading process of PIC, the .text segment
remains unchanged. Therefore, the whole .text segment re-
mains identical to its counterpart in the ELF object code.
Regarding DRIVE, this means that the measurement and
veriﬁcation of the .text segment does not depend on loading
memory addresses and thus can be derived directly from the
object code segments of the ELF. The major beneﬁt of PIC
is the possibility to share .text segments between multiple
processes. As long as the .text-segment of a library does
not changeit is shared to any process in the system, and thus
resides only one time in physical memory. Considering that
many libraries are shared between all system processes, PIC
saves a considerable amount of physical memory.
Recently, so called Position Independent Executables (PIE)
are also getting more and more attention and are also seen in
many recent Linux distributions. Both PIC and PIE hugely
beneﬁt from ASLR, because they do not rely on ﬁxed ad-
dresses and therefore render possible exploitations harder,
because concrete memory addresses are often required to
conduct certain attacks. In addition to that, PIC code also
facilitates the dynamic loading of shared libraries during run-
time, which is used by many applications with the assistance
of the dlopen system call. From the perspective of DRIVE,
both PIC and PIE are equal, thus, the measurement and ver-
iﬁcation of corresponding .text segments is fully supported.
Global Offset Table. Both, PIC and link time RCC in user-
space is usually paired with a mechanism called lazy-binding
[17], implementing an on-demand function symbol resolu-
tion and relocation process. Technically, address resolution
involves the maintenance4 of a table, i.e. the Global Oﬀset
Table (.got), to store memory addresses of targeted exter-
nal symbols. As shown in Table 1, the .got is considered
as dynamic, but predictable. Therefore, DRIVE measures
the .got section that is located inside the .data segment
and also provides a veriﬁcation mechanism that generates
a process speciﬁc .got by simulating the address resolution
process. The .got symbol resolution mechanism is similar to
LKM RCC symbol resolution and rather complex; therefore,
we provide a concrete example in Section 5.1.
4.3 Measurement of Memory Mapped Seg-
ments and Sections
Conducting a measurement of entire segments in memory
is simple given just the suﬃcient access permissions. Every
4Managed by the Procedure Linkage Table .plt as part of
the .text segment.
732segment resides in a certain memory area that is identiﬁed by
a well-known address. Accordingly, once the targeted mem-
ory address and the size of the to-be-measured memory area
is determined, the measurement process executes designated
functions provided by the OS. In contrast to established
static integrity measurement concepts, such as IMA, DRIVE
is not limited to onetime measurement and thus can conduct
its measurements anytime an repeatedly after the software
component is fully loaded. This means the measurement pro-
cess can be hooked to or triggered after relevant system calls,
such as mprotect or dlopen, or run on a timer, executing
the measurements on a deﬁned time interval.
However, measuring individual sections, more precisely the
.got section inside the .data segment, is more complex –
especially for shared libraries– due to ASLR. To actually mea-
sure the .got, its start address and size must be identiﬁed.
However, both are maintained in internal data-structures
that also depend on assigned runtime addresses. For this
reason, start address and size must be determined during
the measurement process itself. This means, in order to mea-
sure the .got, the relevant in memory ELF section, i.e. the
.dynamic section, must be located, analyzed and interpreted
correctly. Based on this information the allocated memory
area of the .got can be calculated and ﬁnally measured.
DRIVEs’ measurement process facilitates cryptographic
hash functions (CHF) to provide secure and reliable rep-
resentations of the measured contents. The concept of ap-
plying CHF to measurements is well-known; however, no
known related work applies CHF to measure and verify in-
dividual memory segments or sections. In fact, CHF based
measurement and veriﬁcation of runtime memory contents
with dynamic behavior are not considered at all in prior or
recent work. Still, the information that is measured can be
designed in a ﬂexible way, tailored to the particular mem-
ory area. In principle, meta-data, such as the memory start
address (msa), size (ms), access permissions (map) and, if
available, related ﬁlename or module name (mf ) is gathered
and added to all measurements for every measured segment.
In addition to this meta-data, for every predictable memory
area, i.e. currently the .text segments and .got sections, a
hash digest (mhd) of the measured content is created and
added to the measurement.
All measurements are stored in an ordered Dynamic Mea-
surement List (DML) whereas every single list entry forms
a set S with variable information, for instance:
S = {mf, msa, ms, map, mhd}
As a result, a Measurement Set M S entails individual sets
of S for every measured memory area:
M S = {S0, S1, . . . , Sn}
Thus, the DM L is composed of one or multiple M S:
DM L = {M S0, . . . , M Sn}
As explained, the DM L and its comprised data is later used
as part of the veriﬁcation scheme. A concrete instantiation
of the measurement concept is presented in Section 5.
4.4 Reporting of Measured Data
In the following, the mechanisms and construction of the
anchored and reported data is brieﬂy described.
In order to report measured data between MA and VA, we
introduce a Runtime System State Report (RSSR) compris-
ing the DML along with a SM anchored ﬁngerprint.
Therefore, the measurement process implements an addi-
tional reporting mechanism to anchor the measured sets in
the SM. That is, for every individual set in M S a hash digest
is calculated and concatenated with its predecessor to form
a Security Module Anchored Fingerprint SM AF , such that5:
SM AFn = digest(digest(M Sn−1)|M Sn)
As a result, SM AFn reﬂects a ﬁngerprint that comprises all
measurement sets M S in a single value. Thus, SM AFn pro-
vides integrity protection over every individual measurement.
Moreover, we deﬁne RSSR that simply merges the current
DM L and its ﬁngerprint SM AF , such that: