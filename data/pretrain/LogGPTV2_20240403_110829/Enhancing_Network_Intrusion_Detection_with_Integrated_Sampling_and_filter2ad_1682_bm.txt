The sampling process is simulated ﬁrst, as described in Section 3. In addition
to detecting the live preﬁxes that contain 96% of the target vulnerable popula-
tion, sampling classiﬁed all the 256 /16 monitor preﬁxes as empty after sending
only 400 probes to each monitor. In practice, this small number of scans has a
very low likelihood of triggering alarms given the sheer amount of background
“radiation” that is continuously received at network telescopes [20]. Once the
sampling process ends, we simulate the worm spreading over the detected live
preﬁxes. Figure 6 illustrates the infected fraction of vulnerable hosts versus time
compared to a uniform scanning worm. First, notice that since the uniform scan-
ning worm scans the entire IP space each infected host will send at least one scan
to the distributed network monitors at some point in the infection cycle. These
contacts are recorded by each network monitor generating the combined moni-
Fast and Evasive Attacks: Highlighting the Challenges Ahead
217
sampling w/ global knowledge
uniform (actual)
monitors view
s
t
s
o
h
f
o
n
o
i
t
c
a
r
f
d
e
t
c
e
f
n
I
 1
 0.8
 0.6
 0.4
 0.2
 0
 0
 50
 100
 150
 200
 250
 300
Time (sec)
Fig. 6. Fraction of hosts infected over time for an evasive worm compared to ordinary
uniform scanning worm with the same parameters
tors’ view also shown in Figure 6. While the 256 /16 monitors accurately track
the evolution of the uniform worm (in fact, the two lines overlap in the ﬁgure),
the worm that exploits the knowledge from sampling remains invisible. More-
over, since the sampling worm targets only live preﬁxes it spreads signiﬁcantly
faster than its uniform counterpart.
Including the hierarchical bitmap in the worm payload results in a relatively
large footprint; nearly 568 KB based on the evaluation in Section 3. This short-
coming can be easily alleviated by applying other mechanisms to disseminate
sampling information among the infected hosts. A simple alternative is to incre-
mentally cover the address space by exchanging bitmaps that cover a single /8
preﬁx bitmap at a time. In the next section, we illustrate a strategy that incor-
porates the sampling process in the actual infection. Unlike the oﬄine case, this
strategy is immune to short term changes in the address space usage. Moreover,
as we show next, the worm payload is signiﬁcantly reduced in this case.
4.2 Online Worm Spreading Strategy
The online worm variant incorporates the sampling process into the actual in-
fection. As before, we assume that the attacker starts with an initial hit-list of
vulnerable hosts. Each host in the hit-list is delegated a number of /8 preﬁxes.
Once infected, the infectee selects a random /8 preﬁx from the group of del-
egated preﬁxes and starts sampling it using the hierarchical sampling process
to detect the live /16 and /24 preﬁxes. Once the ﬁrst response from a live /24
preﬁx is received, the worm activates its scanning vector and attempts to infect
any vulnerable hosts in that /24 preﬁx.
To avoid re-sampling, each worm instance maintains a bitmap (see Figure 5.b)
that tracks the already sampled /16 preﬁxes within the delegated /8 preﬁxes.
218
M.A. Rajab, F. Monrose, and A. Terzis
new infection
merged bitmap
n1
backward information
merged bitmap
n4
reinfection
n2
merged bitmap
n3
Fig. 7. Example of backward information sharing as a result of re-infection. Here, n1
re-infects n3 which in turn transmits its progress to n1 when both nodes merge their
bitmaps. n1 can now disseminate this updated information to subsequent infectees
(e.g., n4).
Nonetheless, this mechanism by itself cannot eliminate re-sampling across dif-
ferent worm instances. Doing so requires some form of continuous information
exchange among worm instances. However, this can be easily accomplished by
taking advantage of the inherent communication channel provided by the infec-
tion process. In particular, the worm instance can simply transfer a bitmap that
represents its current progress to each new infectee. In this way, the infectee
does not re-sample or re-scan preﬁxes already scanned by its infector. Addition-
ally, as Figure 7 illustrates, infected hosts can exploit the re-infection process
to continuously update their bitmaps. Notice that in this case the information
exchanged, as well as the size of the worm payload, is signiﬁcantly reduced com-
pared to the oﬄine case—now, only 256 bits are required to track the sampling
progress within an entire /8 preﬁx.
As before, we evaluate the online infection strategy using the simulation param-
eters from Table 3. The left line in Figure 8 represents the evolution of the worm
over time. Again, notice that the worm successfully evades detection with fewer
than 400 sources sending probes to any of the distributed monitors (out of a total
of 600,000 infected hosts). In addition, the worm’s infection speed is not severely
reduced by the overhead of the sampling process—it still reaches saturation in un-
der 500 seconds. It is also noteworthy that even without having to continuously
estimate the fraction of infected hosts (as required by Ma et.al. [16]), the worm
self-terminates its scans upon saturation after ∼1050 seconds.
Finally, one would expect that infected nodes that fail or are immunized dur-
ing the worm outbreak would result in losing the parts of the IP space delegated
to the failed nodes. However, as the right line in Figure 8 illustrates, even with a
node failure rate 7 of 2% the worm still infects all the vulnerable population. This
is because we deliberately chose a sub-optimal redundancy reduction scheme in
which certain preﬁxes were scanned by more than one host—a tactic that can
be easily used by attackers.
7 We deﬁne the failure rate as the percentage of infected nodes per second that simply
stop scanning either because they are treated or because they fail.
Fast and Evasive Attacks: Highlighting the Challenges Ahead
219
sampling worm (actual)
2% failure rate
s
t
s
o
h
f
o
n
o
i
t
c
a
r
f
d
e
t
c
e
f
n
I
 1
 0.8
 0.6
 0.4
 0.2
 0
 0
 500
 1000
Time (sec)
 1500
 2000
Fig. 8. Fraction of hosts infected over time for an online sample-and-spread strategy
5 Countermeasures and Challenges
To maintain their future value, current passive malware monitoring practices
must evolve to face the threats posed by evasive attacks. In what follows, we
discuss a number of promising research directions and the pertinent challenges
that need to be addressed in order to counter this emerging threat.
Increased Network Surveillance. Given the proliferation of malware on the In-
ternet, it is fair to assume that more resources will be allocated to build early
warning systems. To better understand the ability of such distributed warn-
ing systems to detect an on-line evasive worm, we consider the case in which
a distributed monitoring system comprises a heterogeneous mix of a single /8
monitor, 256 /16 monitors, and a collection of 1024 /24 monitors. The /24 mon-
itors are deployed within heavily populated preﬁxes as recommended in [27],
while the rest are deployed randomly over the IP space.
Figure 9 depicts the actual onset of the worm compared to the collective
view of all monitors in the distributed system. Although the monitors’ view is
slightly enhanced compared to the results from the previous section, it is still
severely limited; the monitors only received probe traﬃc from 1% of the infected
population. To make things worse, these results assume an idealistic condition
where receiving a single probe from an infected host is enough for a monitor
to deduce that the host is indeed infected and instantaneously notify all other
monitors in the distributed system.
A promising protection against such evasion techniques is to use smaller moni-
tors. For example, Pouget et. al.[23] recently established a distributed monitoring
system using monitors of only three IP addresses deployed in more than 25 dif-
ferent countries. Such monitors are not easily detected by the proposed sampling
process as this would require extensive probing. However, in order to be useful
220
M.A. Rajab, F. Monrose, and A. Terzis
s
t
s
o
h
f
o
n
o
i
t
c
a
r
f
d
e
t
c
e
n
f
I
 0.14
 0.12
 0.1
 0.08
 0.06
 0.04
 0.02
 0
 0
sampling worm (actual)
distributed monitor view
 50
 100
 150
 200
 250
Time (sec)
Fig. 9. Onset of an evasive worm showing the actual evolution and the collective view
of a (/8 + 256 /16 + 1024 /24) distributed monitoring system
as an early warning system, coordination among a substantial number of small
(geographically dispersed) monitors will be required [27]. Implementing such a
distributed monitoring systems in a scalable manner is non-trivial and remains
an open research direction which deserves further investigation.
Active Responders. Another avenue that can oﬀer pragmatic value lies in the
widespread adoption of virtual active responders (e.g., [1,25,37]). Of late, ac-
tive responders have become popular for automatically generating attack signa-
tures [11,12,14,34]. If successful, these approaches would also mislead the sam-
pling process into marking the monitored space as live and subsequently scanning
it, thereby exposing the attack. That said, implementing deep-interaction active
responders (also known as honeynets) in a scalable and inconspicuous manner
is non-trivial [7,37]. Recently, Vrable et. al. [35] proposed techniques based on
aggressive multiplexing of virtual machines (VMs) to achieve scalable honeynets
that improve the state-of-the-art by up to six orders of magnitude. However, it
is well known that several malware actively detect VM-based execution environ-
ments [8] and alter the malware behavior accordingly. Therefore, limiting the
detectable eﬀects of VM-based honeynets remains an ongoing challenge.
In the context of evasive malware attacks, an equally diﬃcult challenge is
masking any external side eﬀects of the monitor’s presence. For example, a vir-
tual responder can not respond to all incoming connection attempts since this
would appear suspicious from the attackers’ stand-point given the low likelihood
of observing such a dense mass of live hosts. On the other hand, selectively
responding to incoming probes is not ideal either. For one, probabilistically re-
sponding to a fraction of the incoming traﬃc degrades the monitor’s ﬁdelity
and can lead to loss of “interesting” malicious ﬂows. Moreover, even probabilis-
tic responding is not immune to well crafted sampling probes. For example, a
Fast and Evasive Attacks: Highlighting the Challenges Ahead
221
monitor responding with an ACK to a probe sent to a non-popular or unknown
destination port will be equally suspicious as not responding at all.
A promising trade-oﬀ is to have active responders intelligently mimic the sur-
rounding IP space in terms of the live host distribution and active services. Using
this persona, the monitor can decide which probes should be answered, thereby in-
creasing the diﬃculty of distinguish the monitored space from its immediate sur-
roundings. Again, to be useful, the probability of response must be signiﬁcantly
greater than that of contacting a real vulnerable host in the operational network.
This is certainly feasible if the monitor space is substantially larger than the net-
work being protected. If not, the responder will oﬀer little value in protecting op-
erational end-hosts. Exploring the potential of designing camouﬂaged responders
in this manner is an area of research that requires further investigation.
Finally, even if the above measures are implemented, the attackers will even-
tually locate monitors bound to static locations. Therefore, for these techniques
to be of long term value, they should be combined with periodic “rotation” of
the monitored address space. This can be achieved, for example, by having orga-
nizations actively rotate the operational portion of their address space used for
DHCP leases and deploy active responders within the remaining unused space.
This approach raises a number of practical challenges, but is a direction that
can have valuable impact in mitigating these threats and so warrants further
examination.
6 Related Work
The research community has only recently shown interest in techniques that detect
network monitors. Bethencourt et.al. [3] and Shinoda et.al. [31] showed how so-
called probe and response attacks can locate network monitors that issue periodic
reports of suspicious connection attempts. Although eﬀective, these approaches
are slow and heavyweight since they require low-rate, exhaustive probing of the
address space. Furthermore, they are limited to network monitors that issue public
reports—a requirement that can be easily invalidated by eliminating or anonymiz-
ing these reports. Moreover, these probe-response techniques target predetermined
list of locations in which the reports are published (e.g., web-pages of certain repos-
itories [6]) and therefore cannot detect monitors that publish reports in public, yet