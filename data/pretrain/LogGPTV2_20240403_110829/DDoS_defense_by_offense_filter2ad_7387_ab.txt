29, 31, 42, 47]).
C5 Unequal requests or spooﬁng or smart bots. If the server
has an unequal request load (as mentioned before), then
our currency-based approach can charge clients for harder
requests—even if the server does not know the request dif-
ﬁculty a priori (see §5). Also, if attackers spoof rampantly
(as mentioned above), traditional defenses based on identify-
ing and blocking clients are unlikely to keep the bots at bay.
Likewise, those defenses could be confounded by bots smart
enough to ﬂy under the proﬁling radar (as discussed in §2.1).
The canonical example of a service that meets all of the con-
ditions above (provided its clientele has adequate bandwidth) is
a Web server for which requests are computationally intensive,
perhaps because they involve back-end database transactions or
searches (e.g., sites with search engines, travel sites, and automatic
update services for desktop software). Often, the clientele of these
sites is partially or all non-human. Beyond these server applica-
tions, speak-up could protect the capability allocator in network
architectures such as TVA [51] and SIFF [50] that seek to handle
DoS attacks by issuing capabilities to clients.
3 DESIGN OF SPEAK-UP
Speak-up is motivated by a simple observation about bad clients:
they send requests to victimized servers at much higher rates than
legitimate clients do. (This observation has also been made by
many others, including the authors of proﬁling and detection meth-
ods.) At the same time, some limiting factor must prevent bad
clients from sending even more requests. We posit that in many
cases this limiting factor is bandwidth. The speciﬁc constraint
could be a physical limit (e.g., access link capacity) or a thresh-
old above which the attacker fears detection by proﬁling tools at
the server or by the human owner of the “botted” host. For now, we
assume that bad clients exhaust all of their available bandwidth on
spurious requests. In contrast, good clients, which spend substan-
tial time quiescent, are likely using a only small portion of their
available bandwidth. The key idea of speak-up is to exploit this dif-
ference, as we now explain with a simple illustration.
Illustration.
Imagine a request-response server, where each re-
quest is cheap for clients to issue, is expensive to serve, and con-
sumes the same quantity of server resources. Real-world exam-
ples include single-packet Web requests, DNS front-ends (e.g.,
those used by content distribution networks or infrastructures like
CoDoNS [35]), and AFS servers. Suppose that the server has the
capacity to handle c requests per second and that the aggregate de-
mand from good clients is g requests per second, g  c, then the good clients will receive
g+B of the server’s resources. Assuming B (cid:4) g (if
only a fraction g
B ≈ g, then over-provisioning by moderately increasing c would
ensure g + B  c, (a) without speak-up (b) with speak-up. The good clients’ trafﬁc is gray, as is the portion of the server that
they capture. The ﬁgure does not specify speak-up’s encouragement mechanism (aggressive retries or payment channel).
(a)
(b)
If the good clients make g requests per second in aggregate
and have an aggregate bandwidth of G requests per second to
the server, and if the bad clients have an aggregate bandwidth
of B requests per second, then the server should process good
requests at a rate of min(g, G
G+B c) requests per second.
If this goal is met, then modest over-provisioning of the server (rel-
ative to the legitimate demand) can satisfy the good clients. For if it
is met, then satisfying them requires only G
the good clients can get must exceed their demand). This expres-
sion translates to the idealized server provisioning requirement:
G+B c ≥ g (i.e., the piece
c ≥ g(1 + B/G) def= cid,
which says that the server must be able to handle the “good” de-
mand (g) and diminished demand from the bad clients (B g
G ). For
example, if B = G (a special case of condition C2 in §2.2), then the
required over-provisioning is a factor of two (c ≥ 2g). In practice,
speak-up cannot exactly achieve this ideal because limited cheating
is possible. We analyze this effect in §3.4.
Required Mechanisms. Any practical realization of speak-up
needs three mechanisms. The ﬁrst is a way to limit requests to the
server to c per second. However, rate-limiting alone will not change
the server’s allocation to good and bad clients. Since the design goal
is that this allocation reﬂect available bandwidth, speak-up also
needs a mechanism to reveal that bandwidth: speak-up must per-
form encouragement, which we deﬁne as causing a client to send
more trafﬁc—potentially much more—for a single request than it
would if the server were unattacked. Third, given the incoming
bandwidths, speak-up needs a proportional allocation mechanism
to admit clients at rates proportional to their delivered bandwidth.
To implement these mechanisms, speak-up uses a front-end to
the server, called the thinner, depicted in Figure 1(b). The thinner
implements encouragement and controls which requests the server
sees. Encouragement can take several forms; the two variations of
speak-up below, in §3.2 and §3.3, each incorporate a different one
with correspondingly distinct proportional allocation mechanisms.
Before presenting these, we observe that today when a server is
overloaded and fails to respond to a request, a client typically times
out and retries—thereby generating more trafﬁc than if the server
were unloaded. However, the bandwidth increase is small (since
today’s timeouts are long). In contrast, encouragement (which is
initiated by an agent of the server) will cause good clients to send
signiﬁcantly more trafﬁc—while still obeying congestion control.
3.2 Random Drops and Aggressive Retries
In the version of speak-up that we now describe, the thinner imple-
ments proportional allocation by dropping requests at random to
reduce the rate to c. To implement encouragement, the thinner, for
each request that it drops, immediately asks the client to retry. This
synchronous please-retry signal causes the good clients—the bad
ones are already “maxed out”—to retry at far higher rates than they
would under silent dropping. (Silent dropping happens in many ap-
plications and in effect says, “please try again later”, whereas the
thinner says, “please try again now”.)
With the scheme as presented thus far, a good client sends only
one packet per round-trip time (RTT) while a bad client can keep
many requests outstanding, thereby manufacturing an advantage.
To avoid this problem, we modify the scheme as follows: without
waiting for explicit please-retry signals, the clients send repeated
retries in a congestion-controlled stream. Here, the feedback used
by the congestion control protocol functions as implicit please-retry
signals. This modiﬁcation allows all clients to pipeline their re-
quests and keep their pipe to the thinner full.
One might ask, “To solve the same problem, why not enforce
one outstanding retry per client?” or, “Why not dispense with re-
tries, queue clients’ requests, and serve the oldest?” The answer
is “spooﬁng and NAT”. Spooﬁng, as happens in our threat model
(§2.2), means that one client may claim to be several, and NAT
means that several clients (which may individually have plenty
of bandwidth) may appear to be one. Thus, the thinner can en-
force neither one outstanding retry per “client” nor any other quota
scheme that needs to identify clients. Ironically, taxing clients is
easier than identifying them: the continuous stream of bytes that
clients are asked to send ensures that each is charged individually.
Indeed, speak-up is a currency-based scheme (as we said ear-
lier), and the price for access is the number of retries, r, that a
client must send. Observe that the thinner does not communicate
r to clients: good clients keep resending until they get through (or
give up). Also, r automatically changes with the attack size.
This approach fulﬁlls the design goal in §3.1, as we now show.
The thinner admits incoming requests with some probability p to
make the total load reaching the server be c. There are two cases.
Either the good clients cannot afford the price, in which case they
exhaust all of their bandwidth and do not get service at rate g, or
they can afford the price, in which case they send retries until get-
ting through. In both cases, the price, r, is 1/p. In the ﬁrst case, a
load of B + G enters the thinner, so p = c
, and the good
clients can pay for G/r = G
G+B c requests per second. In the second
case, the good clients get service at rate g, as required.
B+G , r = B+G
c
3.3 Explicit Payment Channel
We now describe another encouragement mechanism, which we
use in our implementation and evaluation. Conceptually, the thin-
ner asks clients to pad their requests with dummy bytes. However,
instead of having to know the correct amount of padding and com-
municate it to clients, the thinner does the following. When the
server is overloaded, the thinner asks a requesting client to open
a separate payment channel. The client then sends a congestion-
controlled stream of bytes on this channel. We call a client that
is sending bytes a contending client; the thinner tracks how many
bytes each contending client sends. Assume that the server notiﬁes
the thinner when it is ready for a new request. When the thinner
receives such a notiﬁcation, it holds a virtual auction: it admits to
the server the contending client that has sent the most bytes, and it
terminates the corresponding payment channel.
As with the version in §3.2, the price here emerges naturally.
Here, it is expressed in bytes per request. The “going rate” for ac-
cess is the winning bid from the most recent auction. We now con-
sider the average price. Here, we express B and G in bytes (not
requests) per second and assume that the good and bad clients are
“spending everything”, so B + G bytes per second enter the thinner.
Since auctions happen every 1/c seconds on average, the average
price is B+G
However, we cannot claim, as in §3.2, that good clients get
G
G+B c requests served per second: the auction might allow “gaming”
in which adversaries consistently pay a lower-than-average price,
forcing good clients to pay a higher-than-average price. We show
in §3.4 that the auction can be gamed but not too badly, so all clients
do in fact see prices that are close to the average.
c bytes per request.
Comparison. There are two main differences between the
scheme in §3.2 and this one. First, with the other scheme, the thin-
ner must determine p and apply it in a way that cannot be “gamed”;
here, the thinner’s rule is simply to select the top-paying client. Sec-
ond, with the other scheme, clients pay in-band. Which option is
appropriate—payment in-band or on a separate channel—depends
on the application. For example, our prototype (§6) needs the latter
option for reasons related to how JavaScript drives Web browsers.
3.4 Robustness to Cheating
In considering the robustness of the virtual auction mechanism, we
begin with a theorem and then describe how practice may be both
worse and better than this theory. The theorem is based on one sim-
plifying assumption: that requests are served with perfect regularity
(i.e., every 1/c seconds).
Theorem 3.1 In a system with regular service intervals, any client
that continuously transmits an  fraction of the average bandwidth
received by the thinner gets at least an /2 fraction of the service,
regardless of how the bad clients time or divide up their bandwidth.
Proof: Consider a client, X, that transmits an  fraction of the av-
erage bandwidth. The intuition is that to keep X from winning auc-
tions, the other clients must deliver substantial payment.
Because our claims are purely about proportions, we choose
units to keep the discussion simple. We call the amount of band-
width that X delivers between every pair of auctions a dollar. Sup-
pose that X must wait t auctions before winning k auctions. Let t1
be the number of auctions that occur until (and including) X’s ﬁrst
win, t2 the number that occur after that until and including X’s sec-
(cid:2)
k
i=1 ti = t. Since X does not win until
ond win, and so on. Thus,
auction number t1, X is defeated in the previous auctions. In the
ﬁrst auction, X has delivered 1 dollar, so at least 1 dollar is spent to
defeat it; in the next auction 2 dollars are needed to defeat it, and so
on until the (t1−1)st auction when t1−1 dollars are spent to defeat it.
So 1+2+··· +(t1−1) = t1(t1−1)/2 dollars are spent to defeat X be-
fore it wins. More generally, the total dollars spent by other clients
. This sum is
over the t auctions is at least
ti = t, when all the ti are equal, namely
minimized, subject to
ti = t/k. We conclude that the total spent by the other clients is at
− t
least
(cid:2)
k
i=1
(cid:2)
k
i=1
− t
t2
i
2
t2
i
−ti
2
(cid:2)
=
2
(cid:2)
k
i=1
t2