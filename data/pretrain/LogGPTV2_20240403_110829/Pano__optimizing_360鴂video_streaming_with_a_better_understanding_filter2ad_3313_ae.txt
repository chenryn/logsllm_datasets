N
P
S
P
70
65
60
55
50
45
0
Pano
Clustile
Flare
Whole Video
2
1
Buffering Ratio (%)
3
Better
4
R
N
P
S
P
70
65
60
55
50
45
0
Pano
Clustile
Flare
Whole Video
2
1
4
Buffering Ratio (%)
3
Better
5
R
N
P
S
P
70
65
60
55
50
45
0
Pano
Clustile
Flare
Whole Video
0.5
1
Buffering Ratio (%)
Better
1.5
(e) Sports, Trace #2
(f) Tourism, Trace #2
(g) Documentary, Trace #2
(h) Performance, Trace #2
Figure 15: Trace-driven simulation of four video genres over two emulated cellular links. Ellipses show 1-σ range of results. We test Pano with
three target buffer lengths of {1, 2, 3} seconds [58].
Trace-driven simulation: Figure 15 compares Pano with the
three baselines on 18 videos across four content genres and over
two network traces. Across all combinations, Pano achieves higher
PSPNR (user perceived quality), lower buffering ratio, or both. We
also see that Pano has more improvement in some videos than
others. This is due largely to the different levels of viewpoint dy-
namics across the videos. More dynamic viewpoint movements
mean lowered sensitivities to quality distortion, thus more oppor-
tunities for Pano to reduce quality levels without hurting users’
perceived quality.
8.3 Robustness
Impact of viewpoint prediction noises: To stress test Pano
under different viewpoint prediction errors, we create a noisier
viewpoint trajectory from each real viewpoint trajectory in our
trace, by adding a random shift to each actual viewpoint location.
Specifically, we shift the original viewpoint location by a distance
drawn uniformly randomly between 0 and n degrees, in a random
direction. By increasing n, we effectively increase the viewpoint
prediction errors. Figure 16(a) shows that more viewpoint noise (n)
does reduce the PSPNR prediction accuracy, but the impact is not
remarkable; a 40-degree noise only deviates the median PSPNR pre-
diction by 7dB. This corroborates the intuition in §6.1 that Pano’s
PSPNR prediction can tolerate a small amount of noise in view-
point movement. Moreover, Figure 16(b) shows that the average
perceived quality does drop with higher viewpoint prediction error,
but the quality always has relatively small variance across users.
This suggests that all users, including those whose viewpoint trajec-
tories are very different from the majority, have similar perceived
quality. Figure 16(c) shows that Pano consistently outperforms the
baseline under an increasing level of viewpoint noise, although
with diminishing improvements. Because subjective rating (MOS)
is monotonically correlated with PSPNR (Table 3), we expect that
Pano’s MOS would be similarly better than that of the baseline,
despite the presence of viewpoint noises.
Impact of throughput prediction errors: Figure 16(d) shows
the performance of Pano (in PSPNR and buffering ratio) under
different throughput prediction errors (a prediction error of 30%
means the predicted throughput is always 30% higher or lower than
the actual throughput). We can see that as the throughput predic-
tion error increases, Pano’s quality degrades, but the degradation
is similar to that of the viewport-driven baseline (Flare). This is be-
cause Pano consumes less bandwidth to provide the same perceived
quality, which is robust when throughput drops down dramatically.
8.4 System overhead
Next, we examine the overheads of a 360° video streaming system,
in computing overhead, video start-up delay, and server-side prepro-
cessing delay. We use an Oculus headset (Qualcomm Snapdragon
821 CPU, 3GB RAM, Adreno 530 GPU) as the client, a Windows
Server 2016-OS desktop of Intel Xeon E5-2620v4 CPU, 32GB RAM,
Quadro M2000 GPU as the video provider, and a 5-minute sports
video as the test video.
Client-side overhead: Figure 17(a) breaks down the client-side
CPU overhead into that of four sequential steps: deciding per-tile
quality level (quality adaptation), downloading, decoding, and ren-
dering video tiles. We see that compared to the baseline of Flare,
Pano induces less computing overhead. This is because Pano needs
to render video tiles with less total size than the baseline, and
although Pano needs extra PSPNR computation to make quality
adaptation decisions, the client-side overhead is still dominated by
video decoding and rendering, which is shared by both Pano and
the baselines.
Video start-up delay: Figure 17(b) breaks down the video start-
up delay (from when video player starts loading to when video
starts playing) into three steps: loading the player, downloading the
manifest file, and downloading the first chunk. Again, we see that
403
Pano: Optimizing 360° Video Streaming with a Better
Understanding of Quality Perception
SIGCOMM ’19, August 19–23, 2019, Beijing, China
100
)
%
(
F
D
C
50
0
0
100
)
%
(
F
D
C
50
0
40
R
N
P
S
P
70
60
50
40
Noise = 5 deg
Noise = 40 deg
Noise = 80 deg
Pano
Viewport-driven
  =0%
Pano
70
  =10%
60
  =0%
  =30%
50
  =10%
Viewport-driven
  =30%
R
N
P
S
P
60
80
100
0
PSPNR
50
100
150
Noise level n (deg)
0
1
2
Buffering Ratio (%)
Better
3
Noise = 5 deg
Noise = 40 deg
Noise = 80 deg
10
20
PSPNR error (dB)
30
(a) PSPNR errors under noisy
(b) Quality (PSPNR) distributions
(c) Impact of viewpoint prediction
(d) Impact of bandwidth prediction
viewpoint prediction
across users
errors on quality
errors on bandwidth-quality
Figure 16: Pano is sensitive to noises of viewpoint movements. To stress test it, a random difference in degree is added to each actual viewpoint
location, in order to increase viewpoint prediction errors. With higher viewpoint prediction errors, (a) Pano estimates perceived quality (PSPNR)
less accurately, and (b) the average perceived quality drops (though with relatively small variance across users). However, when compared to the
viewport-driven baseline, (c) Pano still achieves much higher perceived quality, though with diminishing gains as the viewpoint noise increases.
We also see that (d) Pano is consistently better than the baseline under inaccurate bandwidth prediction.
tradeoffs
)
%
(
e
g
a
s
u
U
P
C
60
40
20
0
Decoding
Rendering
Downloading
Quality adaptation
Baseline Pano
2
1.5
)
s
(
e
m
T
i
1
0.5
0
Loading player
Loading player
Loading 1st chunk
Loading 1st chunk
(cid:2)(cid:5)(cid:14)(cid:4)(cid:8)(cid:9)(cid:12)(cid:7)(cid:1)(cid:11)(cid:3)(cid:12)(cid:9)(cid:6)(cid:5)(cid:13)(cid:14)(cid:1)(cid:6)(cid:9)(cid:10)(cid:5)
Fetching MPD file
Fetching MPD file
Baseline Pano
)
n
m
i
(
e
m
T
i
20
15
10
5
0
Encoding
Manifest file
formation
Baseline Pano
(a) Client-side CPU
(b) Video start-up
overhead
delay
(c) Pre-processing time
for a 1-minute video
Figure 17: Pano reduces client-side processing overhead (a) and start-
up delay (b) with minimal additional costs. The pre-processing time
of Pano is on par with the baseline (c).
Pano induces an additional overhead since it needs to download
a larger manifest file that includes the PSPNR lookup table (see
§7). However, the additional start-up delay is offset by the reduc-
tion of the loading time of the first chunk, because Pano uses less
bandwidth (to achieve the same PSPNR).
Video processing overhead: Figure 17(c) shows the pre-processing
delay on the video provider side to pre-compute the PSPNR look-up
table and encode the one minute worth of video (including chunk-
ing and tiling). Both the baseline and Pano fully utilize the CPU
cycles. Note that the preprocessing time does not include build-
ing the JND model. Because the 360JND model (as described in
§4) is agnostic to the specific video content, the 360JND model is
generated once and used in all 360° videos. We can see that Pano
does impose a longer pre-processing delay, due not only to the
additional PSPNR pre-computation, but also to the variable-size
tiling, which is more compute-intensive than the traditional grid-
like tiling. Nevertheless, the processing time of Pano is still on par
with the baseline.
8.5 Bandwidth savings
Finally, Figure 18(a) runs a component-wise analysis to evaluate
the contribution of each technique in Pano by adding one of them
at a time to a viewport-driven baseline. To evaluate bandwidth
savings on a larger set of videos, we extend our dataset from 18
360° videos to 50 360° videos (publicly available at [15]), generate
404
Viewport-driven
Pano (traditional PSPNR)
Pano (PSPNR w/ 360JND)
Pano (full)
90
80
70
60
50
R
N
P
S
P
2500
2000
1500
1000
500
)
s
/
b
k
(
h
t
i
d
w
d
n
a
B
0
1500
Bandwidth Consumption (kb/s)
1000
500
Pano(this work)
Viewport-driven
Sports
Documentary
Adventure
(a) Component-wise analysis.
(b) Bandwidth consumption.
Figure 18: Pano reduces the bandwidth consumption needed to
achieve high quality (PSPNR = 72, or MOS = 5).
synthetic viewpoint traces for the new 32 360° videos as follows. We
detect objects in each video using Yolo [54]. Then, we synthetically
generate 48 viewpoint traces for each video by assuming that the
viewpoint tracks a randomly picked object for 70% of the time and
looks at a randomly picked region for the remaining 30% of the
time. We acknowledge that it may not be the most realistic way to
model viewpoint trajectories, but we believe it is useful because
(1) the bandwidth consumption is still derived from encoding real
videos, and (2) the fraction of object-tracking time (70%) matches
the average object-tracking time in the real viewpoint traces.
Conceptually, we can breakdown the improvement of Pano over
the viewport-driven baseline (Flare) into three parts. Figure 18(a)
shows the bandwidth savings by each part, while holding the PSPNR
to be 72 (which approximately translate to MOS = 5).
1. Benefit of JND-awareness: Switching from the basic viewport-
driven quality model (i.e., the perceived quality of a tile is only
a function of its distance to the viewpoint) to a PSPNR-based