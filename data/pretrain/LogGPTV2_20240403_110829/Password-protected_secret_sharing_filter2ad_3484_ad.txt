inexpensive, and they can be made non-interactive in the Random
Oracle Model. This is why we extend server’s message S1 with
value ¯aj = (¯g)tj , and user’s message U1 with value ˆc ˜p = (ˆg)r ˜p.
(This is also why the secondary encryption of ˜p we discuss in the
next item uses a new base ˆh instead of h.)
(5) It seems difﬁcult to simulate this protocol efﬁciently unless
the simulator can test whether the user’s ciphertext encrypts the cor-
rect password, e.g. because the simulator can replace the servers’
responses by random values, as argued above, only if the user en-
crypts an incorrect password. However, since the adversary’s view
includes an encryption of the correct password, the DDH reduc-
tion which shows that this encryption is semantically secure cannot
know the corresponding decryption key, and thus cannot perform
such test. We overcome this quandary using the twin encryption
paradigm used in the design of CCA-secure encryption or CMA-
secure signatures starting with [21, 13]. Namely, we extend the
user’s message by a “secondary” encryption of ˜p, under an inde-
pendent ElGamal public key ˆy. For technical reasons it turns out
that this encryption can re-use the same randomness r ˜p used in the
“primary” ciphertext (c ˜p, d ˜p), and so it sufﬁces to extend the U1
message by just one value ˆd ˜p = (ˆy)r ˜p (ˆh) ˜p. The simulator can now
test whether (c ˜p, d ˜p) encrypts ˜p = p by decrypting (ˆc ˜p, ˆd ˜p) – since
by the soundness of the user’s proof these two ciphertexts encrypt
the same plaintext – using a trapdoor key ˆx = DL(ˆg, ˆy) which is
independent of x = DL(g, y). In this way the simulator can test
for password correctness even as it embeds a DDH challenge into
the primary key y and the public ciphertexts (cp, dp) and (cs, ds).
(6) For veriﬁability of Serverj’s computation of the (encrypted)
response zj in step S2, we amend the public parameters with the
set of Pedersen commitments {yi = gxi hri}n
i=1 to the server’s
shares {xi}n
i=1 of the decryption key. Note that the Serverj ses-
sions where the adversary guesses the correct password effectively
implement an exponentiation oracle zz = Fj(m) = mxIDj , e.g.
setting cβ = m1/λj /cs. Therefore the adversary who happens
438to guess the password can adaptively choose t servers to query
in this way (assume for simplicity that no servers are corrupted).
This presents a problem which arises in adaptively secure thresh-
old cryptosystems, e.g. [5]. Namely, if the simulator had to com-
mit itself to n uncorrupted shares using a simpler perfectly binding
commitment scheme, yi = gxi, then it could consistently respond
to such queries only by guessing at the beginning of the interaction
the set of t servers which the adversary later chooses to query in
this way. (Note that the simulator has to answer such queries cor-
rectly, as the adversary could test if Fj(ga) = (yIDj )a.) This is
why we use Pedersen commitments instead.
Non-Interactive Simulation-Sound Zero-Knowledge Proofs. To
assure that protocol messages are well-formed we use simulation-
sound non-interactive zero-knowledge (SS-NIZK) proofs [22], a
slightly weaker notion than non-malleable NIZK’s. Our protocols
could also use interactive version of such proofs, which can be re-
alized with comparable efﬁciency without Random Oracles – see
e.g. [12], but using non-interactive proofs enables best round com-
plexity and keeps a protocol write-up simple. Since these are stan-
dard notions, we recall only brieﬂy that a NIZK proof system for
language L is a triple of algorithms, prover P which produces a
proof π on input a statement instance x and witness w, veriﬁer V
which accepts or rejects on input (x, π), and a simulator S which
outputs a (simulated) proof on just the input x, using some trap-
doors embedded in public parameters (or intercepting honest play-
ers’ interaction with a hash function in ROM). We will use an exact
security version of the SS-NIZK notion, calling such proof sys-
tem (TS, qP , ZK , SS) simulation-sound zero-knowledge (SSZK)
if there is a simulator algorithm S running in time TS which an-
swers up to qP prover queries with simulated proofs on adaptively
chosen statements of adversary’s choice (which can include false
statements) s.t. (1) the statistical difference between the view of an
interaction with S and an interaction with the real prover is at most
ZK, and (2) the probability that any adversary interacting with S
outputs a correct proof on a new false statement, i.e. a different
from those for which it receives a simulated proof from S, is at
most SS. We need such proofs for three languages corresponding
to the three protocol messages, all parameterized by public param-
eters st0 = (g, h, y,{yi}n
Lst0
S1 ={(a, b, ¯a) ∈ (G)3 | ∃ t ∈ Zq s.t.
(a, b, ¯a) = (gt, (cp)t, (¯g)t)}
i=1, ˆg, ˆh, ˆy, ¯g, (cp, dp), (cs, ds)):
Lst0
U ={(a, e, c ˜p, d ˜p, ˆc ˜p, ˆdp) ∈ (G)6 | ∃ (r ˜p, ˜p) ∈ (Zq)2 s.t.
(e, c ˜p, d ˜p, ˆc ˜p, ˆd ˜p) = (ar ˜p , gr ˜p , yr ˜p h ˜p, (ˆg)r ˜p , (ˆy)r ˜p (ˆh) ˜p)}
Lst0,i
S2 ={(cz, dz, c ˜p, a, ∆, P ) ∈ (G)6 | ∃ (rz, t, x, r) ∈ (Zq)3 s.t.
(yi, a, cz, dz) = (gxhr, gt, grz , (c ˜p)rz ∆tP
−x)}
These languages involve equality relations on representations of
some group elements in bases deﬁned by other group elements.
Well-known simulation-sound NIZKs for such relations in ROM
are generalizations of Schnorr’s proof of discrete logarithm knowl-
edge and Chaum’s proof of discrete logarithm equality, using the
Fiat-Shamir heuristic, see e.g. [4]. The prover and the veriﬁer in
these proofs perform as many (multi)-exponentiations as are used
to deﬁne the corresponding language, e.g. three for Lst0
S1, ﬁve for
Lst0
U , and four for Lst0,i
(The veriﬁer’s computation can be re-
S2 .
duced further using the techniques of batch veriﬁcation of discrete-
log based signatures, e.g. [2].) These proof systems achieve simula-
tion sound zero knowledge with error bounds ZK = (qP · qH )/q
and SS = qH /q, where qH is the upper bound on adversary’s
hash function queries, with the simulators whose running time is
the same as that of the corresponding provers.
Efﬁciency, Standard Message Spaces, Soundness, Robustness.
Efﬁciency: For efﬁciency estimates we assume that the SS-NIZK
proofs are implemented in ROM, with proof veriﬁcation imple-
mented using multi-exponentiation and randomization of each veri-
ﬁcation equation, as in signature batch-veriﬁcation of [2]. (This in-
creases the soundness errors of these proofs by negligible amounts.)
We count multi-exponentiations involving up to 5 bases as single
“multiexp” operations, e.g. we estimate the veriﬁcation costs of
proofs π1j, π2j, π3j as 2, 4, and 3 multiexp’s, respectively. To re-
duce user’s costs we also arrange the t + 1 proofs π2j into a single
proof showing consistency of (c ˜p, d ˜p, ˆc ˜p, ˆd ˜p) ciphertexts and t + 1
proofs of consistency of each (aj, ej) pair with c ˜p. Under these as-
sumptions the protocol costs 8t + 17 multiexp’s for the user and 16
for each server. Using precomputation we can reduce the on-line
cost to 7t + 8 multiexp’s for the user and 6 for each server.
Message Space: Protocol PPSS2 works on a non-standard mes-
sage space, i.e. s must be an element of group G, but this can be
easily changed to standard message spaces: Let l be a keylength
of semantically secure symmetric encryption, and let G be a DDH
group of order q where |q| = 3l. The public parameters string st0 is
amended by a random key k of a universal hash function Hk map-
ping elements of G onto l-bit bitstrings s.t. Hk(x) is statistically
indistinguishable from random 160-bit string if x is random in G.
A modiﬁed PPSS protocol on password p and secret m, which is
now any bitstring, runs the PPSS2 protocol of Figure 3 on a ran-
dom element s in G, and attaches to the public parameters st0 the
hash key k and a symmetric encryption of m under key Hk(s). In
the recovery protocol the user hashes the recovered value s to de-
crypt the shared secret m. Note that we can encrypt directly under
H(s) with a subgroup of size |q| = max(l, 160) assuming either a
“Hashed Difﬁe-Hellman” assumption [1] or just DDH but model-
ing H as a random oracle.
Soundness: The PPSS protocol of Figure 3 satisﬁes only weak
soundness, i.e. even malicious servers cannot make the user who
runs on the correct password recover any other secret except of
that which was initially shared. This follows from soundness of
the SS-NIZK proof systems used in servers’ messages, since these
proofs effectively force the servers to perform the prescribed proto-
col. One easy way to extend this to strong soundness is to include
a public key pk of an existentially unforgeable signature scheme in
st0, use the corresponding signature key to sign secret s, and run
the PPSS algorithm as modiﬁed above on a concatenation of s with
this signature. The protocol then proceeds as above except that at
the end the user parses the recovered secret as s|σ and outputs s
only if σ is a valid signature on s under the key pk in st0.
Robustness: Note that the PPSS protocol of Figure 3 does not
satisfy robustness, because the user outputs ⊥ if some server ses-
sions in set V fail to send back correct responses in step S2. How-
ever, robustness can be achieved by modifying the PPSS2 protocol
as follows: If some sessions in V fail in step S2, the user marks
the servers executing them as “dishonest” and restarts the proto-
col using a fresh set of t + 1 server sessions, executed by servers
which have not been marked. In the presence of r ≤ n − (t + 1)
active faults, this can take up to r rounds of interaction before all
server sessions the user chooses are with non-faulty servers, which
guarantees recovery of s. In practice such active attacks should be
extremely rare because the attack reveals the servers corrupted by
the adversary, in which case the user should eliminate, or clean-up,
the attacked server(s) and re-initialize the protocol. Hence the ad-
versary would achieve only a momentary slowdown of the secret-
439reconstruction protocol at a price of expulsion from the servers it
has managed to corrupt. Random network errors are of greater con-
cern, but in practice the user should ping each server before includ-
ing its session in set V in step U1. Note that the user could compute
its U1 messages for n instead of t + 1 distinct servers and only then
settle on the set V , and the server’s response S2 involves only three
multi-exponentiations computed on-line, namely dzj , veriﬁcation
of π2j, and the fourth element of π3j, which involves a ﬂexible
base. Thus at the price of increasing U1’s cost by a factor of n
t+1
we can reduce the computational cost contributing to the delay be-
tween the user’s ping of the servers in step U1 and receiving their
responses, to three on-line multiexp’s needed in step S2.
U ], Π[Lst0
THEOREM 1. Let G be a group of prime order q where the
DDH problem is (Tddh, ddh)-hard, let texp be the time of full
(multi)-exponentiation in G, let Π[Lst0
S1], and Π[Lst0,i
S2 ]
be (TS, qP , ZK , SS)-SSZK proof systems. Protocol PPSS2 is a
(n, t, T, qU , qS, ) strongly secure PPSS scheme on message space
G and dictionary D ⊆ Zq, as long as max(qU , n · qS) ≤ qP and
T ≤ Tddh − 3TS − (10 + n + (8t + 12)qU + 10nqS) · te
 ≤ 6ZK + (5qU + 3nqS + 4)(ddh + SS)
PROOF. Let A be an algorithm followed by an adversary at-
tacking the PPSS2 scheme, running in time T , accessing at most
qU user and qS server sessions, and corrupting servers {Pi}i∈B
for some set B s.t. |B| = t(cid:48) ≤ t. Figure 4 describes a series of
games, G0, ..., G8, all initialized on secret s, where G0 models the
interaction of A with the PPSS2 scheme, with slight modiﬁcations
explained below, while games G1, ..., G8 are modiﬁcations of G0
used in the security argument below. We ﬁrst explain how the game
G0 models the interaction of A with the PPSS2 scheme. The Init(cid:5)
procedure treats threshold (t, n) and the set of corrupted players
B as parameters. Note that adversary A can engage in at most
qS sessions but it is up to A to decide which servers will be in-
volved in these sessions. We handle this in the security game by
creating qS distinct sessions for each server, thus n · qS total ses-
sions, even though a qS-limited adversary will utilize only qS of
them. We denote the identity of the server executing the j-th ses-
sion, where j = 1, .., n · qS, as IDj, which can be set w.l.o.g. as
IDj = (j mod n) + 1. Procedure Init(cid:5) on input s picks p r← D
and follows the real initialization procedure Init(p, s) in generating
the vector of initial states st, including the parameters st0 and the
states sti for each server Pi. Init(cid:5) also executes the ﬁrst step S1
for all server sessions, and hands off to A the parameters st0, the
shares of corrupted servers stB = {xi}i∈B, and the ﬁrst message
on all nqS sessions {Serverj}nqS
j=1. Then A can make qU queries to
the User(cid:5) oracle, which models execution of step U1 of procedure
User(st0, p), and qS queries to the execution of step S2 of the j-th
sesssion of the Server procedure. Note that the inputs A provides
to these oracles must syntactically conform to, respectively, a set of
S1 messages from some t + 1 servers for the User(cid:5) oracle, and user
U1 message in the case of the Server(cid:5)
j oracle, but the adversary can
choose these values at wish, in particular they do not have to equal
to the corresponding variables produced by the oracles simulating
the honest players.
Proof Roadmap. We will use the following notation: By Fi,s we
denote event F deﬁned in Figure 4 happening in the interaction be-
tween A and game Gi initialized on secret s, writing Fi if s is not
even present in that game. By pi(s) we denote Pr[1 ← (A (cid:10)
Gi(s))]. Since G0 differs from the real interaction, we denote the
corresponding probability in the real interaction as ¯p0(s). The intu-
ition for the security proof is that the event F roughly corresponds
to an adversary sending an encryption of the correct password on
at least t − t(cid:48) + 1 sessions run by distinct servers, in which case A
could indeed learn s. The goal of the security argument is to show
that for qS, qU , T satisfying the bounds in the theorem claim, and
any s, s(cid:48), it holds that
|¯p0(s) − ¯p0(s
(cid:48)
)| ≤ (cid:98)
qS
t − t(cid:48) + 1
(cid:99) ∗ 1
(cid:48)
|D| + 
(3)
qS
Let p¬F