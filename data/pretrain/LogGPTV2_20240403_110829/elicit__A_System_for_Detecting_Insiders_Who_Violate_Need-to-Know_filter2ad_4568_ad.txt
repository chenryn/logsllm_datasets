# Elicit: A System for Detecting Insiders Who Violate Need-to-Know

## 4. Threat Scores for Users

### 4.1 Threat Scores for Three Users in March
Figure 3 presents the threat scores for three users over the month of March. The majority of users had threat scores similar to those shown in Figures 3a and 3b, indicating little to no malicious activity. However, Figure 3c shows a more atypical pattern, with scores spiking above 0.9 on five different days. In an operational environment, such high scores would trigger further investigation.

### 4.2 Threat Scores for All Users on Different Days
Figure 4 displays the threat scores for all users on three specific days. Figures 4a and 4b represent workdays, while Figure 4c represents a Sunday (with fewer active users). These plots illustrate how Elicit scores users on different days and highlight that only a few users achieve relatively high scores. On workdays, Elicit scored an average of 1,548 users, with 552 users scoring above 0. Among these, 23 users scored above 0.5.

Using a decision threshold of 0.5, we estimated Elicit's false-positive rate. During March and June, when the red team executed the scenarios, there were 1,548 active users on average. Excluding the insiders, an average of 23 users scored above 0.5, resulting in an average false-positive rate of 0.015. Elicit detected insiders on 16 out of the 19 days they were active, giving it a detection rate of 0.84. We constructed an ROC curve by varying the decision threshold and approximated the area under the curve using the trapezoid rule, yielding an area of 0.92.

## 5. Analysis and Discussion

### 5.1 Scenario Analysis
We conducted a thorough analysis of the scenarios and their events, focusing on key insights. For instance, Elicit failed to detect scenario s5, which involved retrieving proprietary software from an internal repository. Although our sensors captured the activity, we had not developed detectors for that specific server, as our focus was on documents rather than software. This issue will be addressed in future work.

Elicit also did not detect the first day of activity in rt4’s execution of s2, which involved browsing a specific financial system and a relatively small number of events (135). We had no detectors tailored for this type of activity. On the second and third days, with more events (202 and 306, respectively) and a broader range of activity, Elicit generated more alerts (22 on the second day and 20 on the third), leading to higher threat scores and detections.

### 5.2 Correlation Between Events and Threat Scores
We examined whether a large number of events might have produced high threat scores. All detected scenarios were in the 75th percentile in terms of daily events. However, the correlation between the number of events and threat scores for all users scoring above the decision threshold in March and June was low (0.026 and -0.023, respectively). This suggests that Elicit's detections were not primarily due to the number of events.

### 5.3 Impact of Multiple Sessions in a Single Day
We investigated whether running multiple sessions in a single day affected daily threat scores. Inserting each session individually and re-running Elicit did not result in new detections. Therefore, we concluded that executing multiple sessions in a single day did not significantly affect performance.

### 5.4 Elicit's Successes and False Positives
Elicit's successes were attributed to the right detectors alerting on the right activities. Scenarios s1, s2, and s4 involved employees gathering information unrelated to their duties. Detectors for anomalous volumes of searching and browsing, as well as atypical queries, alerted appropriately.

False positives were not consistently linked to any single pattern of alerts. Administrative staff, representing 10% of the user population, accounted for 39% of all false alarms. These individuals engaged in activities that Elicit is designed to detect, such as large amounts of activity and a broad range of activity spanning organizational boundaries.

### 5.5 Red-Team Member's Incorrect Proxy Settings
Incorrect proxy settings by a red-team member could potentially route traffic around sensors. However, this requires specific technical knowledge and may increase the chance of detection. In our target organizations, such changes could be a serious violation regardless of intent. This highlights the importance of complementary host-based approaches to make such attacks more difficult.

### 5.6 Comparison with Current State of Practice
Our results are significantly better than current practices, which involve matching ad hoc patterns, auditing randomly-selected individuals, and auditing based solely on the volume of user activity. Elicit's task is different from detecting intrusions, which focuses on rule breaking. False positives are a concern, but the number of entities Elicit processes per day is much smaller than the number processed by intrusion-detection systems. Contextual information and historical activity play a critical role in subsequent analysis, allowing analysts to quickly resolve false positives.

### 5.7 Cost of False Negatives
The cost of false negatives in insider threat detection is substantially higher than in other detection tasks, given the potential damage to national security. Anecdotal evidence suggests that organizations are willing to tolerate higher false positive rates to detect violations of need-to-know.

### 5.8 Attack Rate and Time Frame
Insider attacks occur over days, months, or even decades, unlike external attacks that often occur in milliseconds. Analysts may need to investigate a manageable number of false positives per day, rather than thousands per hour.

### 5.9 Detection Probabilities
Strictly speaking, the probabilities of detection are not 1. Factors such as network sensor downtime, unattributable events, and uncaptured packets can affect detection. While these factors impact absolute probabilities, they do not affect relative probabilities, which are more relevant for ranking users.

### 5.10 Eliciting Probabilities from Domain Experts
Eliciting probabilities from domain experts was challenging. They had difficulty specifying probabilistic cutoffs and conditional probabilities for statistical detectors. Presenting and specifying numeric thresholds was easier.

## 6. Related Work

### 6.1 Overview
We provide a brief review of related work, with a more comprehensive survey available in Chapter 25 of Bishop [13]. Denning [14] referred to specific instances of insider activity as leakage and inference. Early attempts to address misuse include IDES [15], which used statistical profiles to detect masqueraders, and UNICORN [16], which examined audit records for misuse.

### 6.2 Command Sequence Analysis
Several studies have examined methods of detecting masqueraders from command sequences [5,17,18]. Our work differs in that we monitor network traffic, focus on legitimate users acting uncharacteristically, and use contextual information about users and the information they access.

### 6.3 Similar Research
The research most similar to ours is that of Maybury et al. [19]. They built a database of 11 million events collected over three months from 18 hosts. There is overlap with our work, but they examined different sources of information, approaches, and insider profiles.

## 7. Concluding Remarks

In this paper, we described the construction and evaluation of Elicit, a system designed to help analysts investigate insider threats. We emphasized the importance of contextual information and tracking how individuals access and manipulate information, which is critical for detecting insiders but less so for detecting intruders.

## References
1. United States v. Leandro Aragoncillo and Michael Ray Aquino: Criminal complaint. District of New Jersey (September 9, 2005)
2. Keeney, M., et al.: Insider threat study: Computer system sabotage in critical infrastructure sector. Technical report, US Secret Service and CERT Program, Software Engineering Institute, Carnegie Mellon University, Pittsburgh, PA (May 2005)
3. Lee, W., Stolfo, S.J.: A framework for constructing features and models for intrusion detection systems. ACM Transactions on Information and System Security 3(4), 227–261 (2000)
4. Porras, P.A., Neumann, P.G.: EMERALD: Event monitoring enabling responses to anomalous live disturbances. In: Proceedings of the 20th NIST-NCSC National Information Systems Security Conference, pp. 353–365. National Institute of Standards and Technology, Gaithersburg, MD (1997)
5. Lane, T., Brodley, C.E.: Temporal sequence learning and data reduction for anomaly detection. ACM Transactions on Information and System Security 2(3), 295–331 (1999)
6. Hofmeyr, S.A., Forrest, S., Somayaji, A.: Intrusion detection using sequences of system calls. Journal of Computer Security 6(3), 151–180 (1988)
7. Ethereal, Inc.: Ethereal. Software (2007), http://www.ethereal.com
8. Leone, F.C., Nelson, L.S., Nottingham, R.B.: The Folded Normal Distribution. Technometrics 3(4), 543–550 (1961)
9. Silverman, B.W.: Density estimation for statistics and data analysis. Chapman & Hall/CRC, Boca Raton, FL (1998)
10. Jensen, F.V.: Bayesian networks and decision graphs. Statistics for Engineering and Information Science. Springer, New York, NY (2001)
11. Lippmann, R., et al.: The 1999 DARPA off-line intrusion detection evaluation. Computer Networks 34, 579–595 (2000)
12. McHugh, J.: Testing intrusion detection systems. ACM Transactions on Information and System Security 3(4), 262–294 (2000)
13. Bishop, M.: Computer security. Addison-Wesley, Boston, MA (2003)
14. Denning, D.E.: An intrusion-detection model. IEEE Transactions on Software Engineering SE-13(2), 222–232 (1987)
15. Lunt, T., et al.: IDES: A progress report. In: Proceedings of the Sixth Annual Computer Security Applications Conference. Applied Computer Security Associates, pp. 273–285. Silver Spring, MD (1990)
16. Christoph, G.G., et al.: UNICORN: Misuse detection for UNICOSTM. In: Supercomputing '95, p. 56. IEEE Press, Los Alamitos, CA (1995)
17. Schonlau, M., et al.: Computer intrusion: Detecting masquerades. Statistical Science 16(1), 58–74 (2001)
18. Maxion, R.A.: Masquerade detection using enriched command lines. In: Proceedings of the International Conference on Dependable Systems and Networks, pp. 5–14. IEEE Press, Los Alamitos, CA (2003)
19. Maybury, M., et al.: Analysis and detection of malicious insiders. In: Proceedings of the 2005 International Conference on Intelligence Analysis, The MITRE Corporation, McLean, VA (2005)