r
o
c
S
t
a
e
r
h
T
 1
 0.8
 0.6
 0.4
 0.2
 0
 0
 5  10  15  20  25  30
Day of Month
(c)
Fig. 3. Threat scores for three users for March
elicit: A System for Detecting Insiders Who Violate Need-to-Know
161
e
r
o
c
S
t
a
e
r
h
T
 1
 0.8
 0.6
 0.4
 0.2
 0
e
r
o
c
S
t
a
e
r
h
T
 1
 0.8
 0.6
 0.4
 0.2
 0
e
r
o
c
S
t
a
e
r
h
T
 1
 0.8
 0.6
 0.4
 0.2
 0
 0  5  10  15  20  25  30  35
User Rank
(c)
 0  100 200 300 400 500 600
User Rank
(b)
 0  100  200  300  400  500
User Rank
(a)
Fig. 4. Threat scores for all users for three days. (a) 462 users for 3/4/05, a Friday.
(b) 523 users for 3/7/05, a Monday. (c) 36 users for 3/27/05, a Sunday.
6 Analysis and Discussion
After completing our evaluation of elicit, the red team provided information
about the scenarios and their events, which we analyzed along with the threat
scores for individual users and for all users. In Fig. 3, we present the threat
scores for three users for the month of March. The scores of most users were
similar to those pictured in Figs. 3a and 3b, which indicate little or no malicious
activity. However, less typical are the scores in Fig. 3c, which spike above .9
on ﬁve diﬀerent days. In an operational environment, elicit would ﬂag and
analysts would further investigate individuals with such scores.
In Fig. 4, we show the threat scores for all users on three diﬀerent days. The
scores in Figs. 4a and 4b are from work days, and those in Fig. 4c are from a
Sunday (when there are fewer users). These plots are typical and illustrate how
elicit scores users on diﬀerent days and how few users obtain relatively high
scores. During work days, elicit scored an average of 1, 548 users, with 552
users scoring above 0. Of these, 23 users scored above .5.
Using .5 as the decision threshold, we estimated elicit’s false-positive rate.
Although our collection contains activity for 3, 938 distinct users, during March
and June, when the red team executed the scenarios, there were 1, 548 active
users on average. For these same months, not including the insiders, an average
of 23 users scored above .5. Consequently, elicit’s average false-positive rate
is .015. Since elicit detected insiders on 16 of the 19 days they were active,
its detection rate is .84. We constructed an roc curve by varying the decision
threshold and then approximated the area under the curve using the trapezoid
rule, which yielded an area of .92.
We have conducted a thorough analysis of the scenarios and their events, but
here, we can present only the key insights. We ﬁrst examined why elicit failed
to detect scenario s5, which required the member of the red team to retrieve
proprietary software from an internal repository. Although our sensors captured
the activity, we had not developed detectors to monitor that speciﬁc server. Put
simply, our detectors were focused on documents rather than on software. We
will address this issue in future work.
elicit did not detect the ﬁrst day of activity of rt4’s execution of s2. It
consisted of the browsing of a speciﬁc ﬁnancial system and relatively few events
162
M.A. Maloof and G.D. Stephens
(135). As before, we had no detectors tailored expressly for activity involving
the ﬁnancial system. On the ﬁrst day of the scenario, two detectors alerted
on rt4’s browsing activity, but these alerts were insuﬃcient to produce a high
threat score. However, on the second and third days, there were more events (202
and 306, respectively) and a broader range of activity. This activity produced
substantially more alerts—22 on the second day and 20 on the third—and higher
threat scores, resulting in detections on those days.
We were concerned that a large number of events might have produced high
threat scores. Indeed, of the scenarios we detected, all were in the 75th percentile
in terms of the total number of daily events (i.e., accounting for both benign and
anomalous activity). However, when we examined the correlation between the
number of events and the threat scores for all users scoring above the decision
threshold in the months of March and June, the coeﬃcients were .026 and −.023,
respectively. Consequently, we concluded that elicit’s detections were not due
to the number of events in the scenario executions.
We were also concerned that a red-team member’s decision to run all of his or
her sessions in a single day (versus one session per day) might have aﬀected the
daily threat scores. To investigate, for the days involving multiple sessions, we
inserted each session individually and ran elicit. elicit did not detect the ﬁrst
session of the second day of rt4’s execution of s2, and it did not detect the ﬁrst
session of the ﬁrst day of rt1’s execution of s2. On the other hand, evaluating
elicit on the individual sessions did not result in any new detections. Ultimately,
we concluded that a person’s decision to execute multiple sessions in a single day
did not signiﬁcantly aﬀect performance.
As for elicit’s successes, our analysis suggests that based on the scenarios
and their executions, the right detectors were alerting on the right activities. Sce-
narios s1, s2, and s4 involved employees who gathered information unrelated to
their duties. Detectors for anomalous volumes of searching and browsing alerted,
as did detectors indicating that there were queries atypical for the user.
As for elicit’s false positives, we found no single consistent pattern of alerts
that resulted in false alarms. However, individuals in non-technical administra-
tive roles, representing 10% of the user population, accounted for 39% of all false
alarms. Our analysis suggests that administrative staﬀ engaged in many of the
activities that elicit should detect: large amounts of activity and a breadth of
activity spanning organizational boundaries.
Regarding the red-team member’s incorrect proxy settings, in practice, insid-
ers could attempt to route traﬃc around sensors. However, this requires speciﬁc,
technical knowledge of sensor placement and traﬃc routing. The insider may ob-
tain little feedback about the success of these countermeasures, and attempting
such changes could increase the chance of being detected. In the organizations
of interest to us, such changes could be a serious violation regardless of intent.
Nonetheless, this illustrates the importance of complementary host-based ap-
proaches, which could make such attacks more diﬃcult to launch.
Our results are signiﬁcantly better than the current state of practice, which
involves matching ad hoc patterns, auditing randomly-selected individuals, and
elicit: A System for Detecting Insiders Who Violate Need-to-Know
163
auditing based solely on the volume of user activity. When interpreting our
results, it is important to keep in mind that this task is quite diﬀerent than
detecting intrusions, which focuses on rule breaking.
False positives are always a concern, but the number of entities (i.e., users)
that elicit processes per day is orders of magnitude smaller than the number
of entities (e.g., connections) that intrusion-detection systems process in much
shorter periods of time. Once elicit reports a detection, a user’s historical ac-
tivity and contextual information play a critical role in subsequent analysis.
Such information is largely absent when investigating potential external intru-
sions. Indeed, elicit’s interface provides enough information and context about
individuals that analysts were able to quickly absolve false positives.
When interpreting the number of false positives, one must also take into ac-
count the cost of false negatives, which is substantially higher than that of other
detection tasks. At stake is national security. We have not conducted a formal
cost analysis. However, anecdotal evidence suggests that, because of the damage
these insiders cause, organizations interested in detecting violations of need-to-
know are willing to tolerate false positives at much higher rates than with other
applications.
Two other important distinctions of this task are the rate of attack and the
time over which attacks occur. Rather than occurring in milliseconds (in the case
of worms), attacks by insiders who violate need-to-know occur over days, months,
and even decades, in the case of Robert Hanssen. Publicly-available information
suggests that insider activity occurs in bursts, like other types of attacks, but
insider activity is spread over days and months. Consequently, analysts may have
to investigate, say, ten false-positives per day, rather than thousands per hour.
As mentioned previously, the probabilities of detection are, strictly speaking,
not 1. For example, we did have three days when our network sensors were
down, there is a small percentage of events that we could not attribute to users,
and there may have been packets that the sensors did not capture. These events
certainly aﬀect a detector’s probability of detection in some way, but it is unclear
whether there is a practical procedure for taking into account all of these factors
and then estimating the probabilities. We suspect that most changes would be
small and that many would uniformly change the probabilities of detection. This
will aﬀect the absolute probabilities, but not the relative probabilities, and we
are most interested in a user’s rank.
Eliciting probabilities from domain experts proved challenging. They had little
diﬃculty specifying numeric thresholds and conditional probabilities for rules.
However, for the detectors based on statistical methods, it was diﬃcult to com-
municate how the detectors worked in a non-technical manner. Graphical aids
and phrasing questions using percentages rather than probabilities helped, but
even though all of the experts agreed on the importance of modeling individual
activity, we still had trouble eliciting probabilistic cutoﬀs and conditional prob-
abilities based on these cutoﬀs. Ultimately, it was easier for us to present and
for experts to specify a number rather than a probability or a percentage.
164
M.A. Maloof and G.D. Stephens
We have attempted to convey that detecting malicious insiders is challenging
and diﬀerent than detecting intruders. One key diﬀerence is the availability of
contextual information for insiders, information that one rarely has for intrud-
ers. With the help of such information, organizations must understand how its
users access and manipulate information. To accomplish this, we must attribute
actions to users, rather than to ip addresses, which in turn, raises important
issues of privacy, especially for researchers.
Complicating matters is the lack of public data sets and information regarding
insider behavior and activity. One solution is to engineer data sets. There have
been attempts to do so for intrusion detection, mostly notably the mit Lincoln
Labs data set [11], but no similar data set exists for insider threat. Engineered
data sets are not without problems, such as guaranteeing that the malicious
activity is in correct proportion to the benign activity and that the benign
activity is truly representative of the target environment [12]. Our collection
of scenarios and information-use events is an attempt to address these concerns
for insiders who violate need-to-know.
7 Related Work
We provide only a brief review of related work, but see Chapter 25 of Bishop [13]
for a more complete survey. Denning [14] referred to speciﬁc instances of such
activity as leakage and inference by legitimate users: Leakage involves a legiti-
mate user leaking or exﬁltrating information. Inference is inferring information
based on queries to a database or a search engine.
One early attempt to address the problem of misuse was ides [15], which
used statistical proﬁles of user behavior to detect masqueraders by observing
departures from established patterns. (It also applied rules to identify speciﬁc
intrusions.) Another is unicorn [16], which examined audit records for misuse by
forming proﬁles using counts over multiple time scales and by applying rules to
transform proﬁles into anomalies, into likely misuse events, and then into alarms.
In contrast, elicit is geared more toward the misuse of user-level privilege and
has a broader notion of context, such as social networks and job descriptions.
Several studies have examined methods of detecting masqueraders from com-
mand sequences [5,17,18]. The main points of departure between this work and
ours are, we are monitoring network traﬃc; we are interested in legitimate users
acting as themselves, but in a manner that is uncharacteristic and inappropri-
ate; ﬁnally, to improve detection, we bring to bear contextual information about
users and the information they access.
The research most similar to ours is that of Maybury et al. [19]. Workshop
participants built a database of 11 million events collected over a period of 3
months from 18 hosts of a 31-node intranet with 75 users. There is overlap with
our work, but they examined diﬀerent sources of information, approaches, and
insider proﬁles.
elicit: A System for Detecting Insiders Who Violate Need-to-Know
165
8 Concluding Remarks
In this paper, we described the construction and evaluation of elicit, a sys-
tem designed to help analysts investigate insider threats. We are interested in
malicious insiders who operate within their privileges, but outside the scope of
their duties. This is quite diﬀerent from intrusion detection. We stressed the im-
portance of contextual information and of tracking how individuals access and
manipulate information. One rarely has this information for detecting intruders,
but it is critical for detecting insiders.
References
1. United States v. Leandro Aragoncillo and Michael Ray Aquino: Criminal com-
plaint. District of New Jersey (September 9, 2005)
2. Keeney, M., et al.: Insider threat study: Computer system sabotage in critical
infrastructure sector. Technical report, US Secret Service and CERT Program,
Software Engineering Institute, Carnegie Mellon University, Pittsburgh, PA (May
2005)
3. Lee, W., Stolfo, S.J.: A framework for constructing features and models for in-
trusion detection systems. ACM Transactions on Information and System Secu-
rity 3(4), 227–261 (2000)
4. Porras, P.A., Neumann, P.G.: EMERALD: Event monitoring enabling responses
to anomalous live disturbances. In: Proceedings of the 20th NIST-NCSC National
Information Systems Security Conference, pp. 353–365. National Institute of Stan-
dards and Technology, Gaithersburg, MD (1997)
5. Lane, T., Brodley, C.E.: Temporal sequence learning and data reduction for anom-
aly detection. ACM Transactions on Information and System Security 2(3), 295–
331 (1999)
6. Hofmeyr, S.A., Forrest, S., Somayaji, A.: Intrusion detection using sequences of
system calls. Journal of Computer Security 6(3), 151–180 (1988)
7. Ethereal, Inc.: Ethereal. Software (2007), http://www.ethereal.com
8. Leone, F.C., Nelson, L.S., Nottingham, R.B.: The Folded Normal Distribution.
Technometrics 3(4), 543–550 (1961)
9. Silverman, B.W.: Density estimation for statistics and data analysis. Chapman &
Hall/CRC, Boca Raton, FL (1998)
10. Jensen, F.V.: Bayesian networks and decision graphs. Statistics for Engineering
and Information Science. Springer, New York, NY (2001)
11. Lippmann, R., et al.: The 1999 DARPA oﬀ-line intrusion detection evaluation.
Computer Networks 34, 579–595 (2000)
12. McHugh, J.: Testing intrusion detection systems. ACM Transactions on Informa-
tion and System Security 3(4), 262–294 (2000)
13. Bishop, M.: Computer security. Addison-Wesley, Boston, MA (2003)
14. Denning, D.E.: An intrusion-detection model. IEEE Transactions on Software En-
gineering SE-13(2), 222–232 (1987)
15. Lunt, T., et al.: IDES: A progress report. In: Proceedings of the Sixth Annual Com-
puter Security Applications Conference. Applied Computer Security Associates,
pp. 273–285. Silver Spring, MD (1990)
166
M.A. Maloof and G.D. Stephens
16. Christoph, G.G., et al.: UNICORN: Misuse detection for UNICOSTM. In: Super-
computing ’95, p. 56. IEEE Press, Los Alamitos, CA (1995)
17. Schonlau, M., et al.: Computer intrusion: Detecting masquerades. Statistical Sci-
ence 16(1), 58–74 (2001)
18. Maxion, R.A.: Masquerade detection using enriched command lines. In: Proceed-
ings of the International Conference on Dependable Systems and Networks, pp.
5–14. IEEE Press, Los Alamitos, CA (2003)
19. Maybury, M., et al.: Analysis and detection of malicious insiders. In: Proceedings
of the 2005 International Conference on Intelligence Analysis, The MITRE Corpo-
ration, McLean, VA (2005)