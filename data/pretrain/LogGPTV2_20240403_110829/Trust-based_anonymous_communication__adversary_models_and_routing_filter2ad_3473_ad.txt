not compromised.
In contrast, random selection beneﬁts
roughly linearly in the number of routers shifted from medium
to high trust.
Though these examples show very positive results for plau-
sible scenarios, they are merely illustrative examples. There
is no guarantee that they are representative of improvements
when using trust values in deployed systems in actual use.
181To express our bound succinctly, further let
min(k1+3i−2,(cid:96))Y
ai =
αj,
j=k1−1
−µ
middle trust value. The anonymity is compared to that of
the downhill algorithm using the correct trust values. We see
that they are identical until the middle trust value reaches
about .5. This is because the three-hop path is optimal in
both cases until then, at which point it becomes optimal to
use two hops. This illustrates that trust errors that leave
the ordering of nodes by trust roughly the same may not
change the optimality of the selected sequence of trust sets.
1/2
min/4, 1), and
b = min(2(cid:96)e
ci = (1 + O(1/µmin))(cid:96)−i+1(1 + O(µ
−1/4
min ))min(3i,(cid:96)).
ai bounds the relative increase in posterior probability gained
from observing additional path positions. We use the Cher-
noﬀ bound to obtain the bound b on the probability that, for
all j, the number of uncompromised routers in Sj is within
a factor 1 ± µ
−1/4
min of µj. ci represents a bound on the rela-
tive posterior increase obtained from losing some unobserved
positions and increasing the contribution of the retained un-
observed positions. ci is given explicitly in the proof, and
its hidden constants are not large.
Then we can bound the eﬀect of the error in r’s trust value
as follows:
Theorem 1. If µmin ≥ 1, then
E[Y ] − E[Y ] ≤ 
P r[P1 = r] + (1 − P r[P1 = r])·
We omit the proof of the theorem for space.
i=0
We can see from Theorem 1 that the eﬀect of the trust
error is bounded by . Next, suppose that the expected
number of uncompromised routers µi in each Si is large.
Suppose also that r /∈ T1. Then, the bound provided by the
theorem approaches
!
πr(i)(1 − 1/ai)
.
  (cid:96)X

(cid:96)X
!!
b + (1 − b)
πr(i)(1 − 1/(ciai))
Figure 3: Anonymity when a fraction of nodes of
Table 1(a) have incorrect trust values.
.
i=0
This expression shows that the change in anonymity is de-
termined by how often r is likely to be chosen in the path
and how incriminating the observed positions are. Indeed,
this expression goes to zero as the probability of choosing r
in P goes to zero or as the values αj of the observations go
to one. These events happen when, for example, the small-
est trust set containing r (i.e. Tk2 ) grows, by Inequality 2
and the deﬁnition of the αj.
We examine the concrete eﬀect of trust errors by extend-
ing the scenario given in Table 1(a) to include errors. Fig-
ure 3 shows the anonymity when the user is incorrect about
the trust level of a fraction of the nodes. Speciﬁcally, for a
fraction x, x of the believed high-trust nodes have medium
trust, x/2 of the believed medium-trust nodes have high
trust, x/2 of the believed medium nodes have low trust, and
x of the low-trust nodes have medium trust. The ﬁgure
shows that using trust may actually be worse than choosing
randomly if there are signiﬁcant errors in the user’s trust be-
liefs. In particular, as Theorem 1 describes, performance is
particularly sensitive to errors in the most-trusted routers.
Thus, even if the average trust values are lower than be-
lieved, as in Figure 3, the actual anonymity may be lower
than believed if using trust.
Figure 4 also shows the eﬀect of trust errors in the scenario
of Table 1(a). The error it shows is an incorrect belief in the
Figure 4: Anonymity from varying trust values of
Table 1(a).
4.2 Path selection for multiple connections
The path-selection algorithm described is designed to pro-
tect the anonymity of one connection. However, users make
multiple connections over time, and we want to maximize
the probability that all of them have good anonymity.
If we were to simply use the given algorithm to choose a
diﬀerent path for every connection, users would be increas-
ingly likely to have poor anonymity on at least one of their
connections: each new connection would be another chance
to select a compromised router. We want to maximize the
probability that no connection has poor anonymity. This re-
quirement would suggest that each user should maintain the
same path across diﬀerent connections—similar to the use of
guard nodes in Tor suggested by Øverlier and Syverson [39].
However, doing so would make it easier for the adversary
to link together diﬀerent connections as coming from the
182same user. Suppose, for example, that the adversary ob-
serves the destination links and that users make repeated
connections to the destination. The adversary would see
multiple connections coming from the same router and can
infer that they’re more likely to come from the same user.
4.2.1 Path selection against different adversaries
If the adversary observes the source links, then he can al-
ready link connections together as belonging to the observed
user. Therefore, in this case, we extend the path-selection
algorithm from one connection to multiple connections by
using the same path for all connections.
The diﬃcult case is again when source links are unob-
served, but the adversary observes the links of some of the
destinations. For connections that are to unobserved des-
tinations, the user should simply bypass the network en-
tirely. For connections that are to observed destinations,
we adapt the one-connection algorithm by using both static
and dynamic components. First, as given in that algorithm,
the user uses a decreasing sequence of trust thresholds to
choose a path of length (cid:96). At each hop, a router is cho-
sen uniformly at random from all routers with trust value
above the threshold at that hop. This path is static—it is
chosen once at the start, and then the user uses it for all
connections. Second, two routers are chosen uniformly at
random from R and used as the ((cid:96) + 1)st and ((cid:96) + 2)nd hops.
These hops are dynamic—a new random selection of these
two hops is made for each new connection.
Combining static and dynamic hops in this way helps
maintain anonymity over multiple connections while pre-
venting them from being easily linked. The static portion
of the path protects the source identity over all connections
by preventing the source and her most-trusted routers from
being observed even once. The last hop is dynamic so that
the adversary observing destination links cannot use a static
router to link together repeated connections from the same
user. The ((cid:96) + 1)st hop is dynamic because the last hop is
likely to be compromised on a fraction of connections equal
to the fraction of routers that are compromised by the ad-
versary. If this hop were static, the adversary could use it
to link together destinations it observes from the last hop.
Of course, the ((cid:96) + 1)st router is also likely to be compro-
mised on a fraction of the connections. When those connec-
tions are to destinations for which the links are observed,
then they can be linked because of the static (cid:96)th hop. How-
ever, multiple connections might not be only to such desti-
nations. Due to uncertainty about the destination links or
just for simplicity, users could use the downhill-trust algo-
rithm to destinations with unobserved links. By using two
dynamic routers as the ﬁnal hops, linking unobserved desti-
nations requires that both dynamic routers be compromised.
Note that adding additional dynamic routers at the end pro-
vides no beneﬁt, as the adversary can perform a correlation
attack using only the ﬁrst and last dynamic routers in order
for the destinations to be observed and linked.
4.2.2 Analyzing path selection
In order to rigorously analyze the eﬀectiveness of using
static and dynamic routers together, we consider the prob-
lem of linking more precisely. The use of static components
in the path means that if the adversary observes two diﬀer-
ent connections using the same static hops, they are more
likely to belong to the same user.
Therefore, instead of looking only at his knowledge of a
given connection, we must examine the adversary’s overall
view of which connections occurred. A user’s private in-
formation consists of the sequence of connections that user
makes over a given time period, where each connection con-
sists of a user, a destination, and a start time. We ex-
amine user privacy over multiple connections by looking
at the adversary’s posterior distribution on the number of
connections at the user’s connection-start times and the
sources and destinations of those connections. We use the
entropy [14, 44] of this distribution as our metric of un-
certainty. We will consider how this entropy is aﬀected by
adding dynamic routers at the end of the paths of some
users.
Let AR ⊆ R be the routers compromised by the adver-
sary. Let T be the set of start times of the connections for
which u is the source. Let C T be a random binary vector
indicating the presence of a connection starting at the times
in T . Let ST be a random sequence of users indicating the
sources for connections starting at times in T . Let DT be a
random sequence of destinations indicating the destinations
for connections starting at times in T . Finally, let Os indi-
cate the adversary’s observations when users only create and
use the static part of the path, let Od1 indicate the obser-
vations made by the adversary when users add one dynamic
hop, and let Od2 indicate the adversary’s observations when
users add a second dynamic hop after the ﬁrst.
We are interested in how the entropy of the posterior
distribution over connections given an adversary’s obser-
vations changes when using dynamic hops. That is, we
consider how H(C T , ST , DT|OS), H(C T , ST , DT|Od1 ), and
H(C T , ST , DT|Od2 ) compare. Using the chain rule of en-
tropy [8] and the independence of ST and DT , we can ex-
press the entropy of the posterior as
H(C T , ST , DT|O) = H(C T|O)
+ H(ST|C T , O) + H(DT|C T , O),
(3)
where O is Od1 , Od2 , or Os.
We ﬁrst show that, assuming a user only makes connec-
tions over the anonymity network to destinations with ob-
served links, then adding one dynamic hop to the static path
can only increase the entropy over her connections.
Theorem 2.
H(C T , ST , DT|Od1 ) ≥ H(C T , ST , DT|Os).
Proof. The entropy H(C T|O = o) of the existence of
connections at times in T does not change due to dynamic
hops because the connections are always observed at the
destination links.
The entropy H(ST|C T , O = o) of connection sources can
only change when a ﬁnal static hop of a connection goes from
being observed to unobserved. The ﬁnal static router can
become unobserved if the ﬁnal static router is uncompro-
mised and the penultimate static router is uncompromised.
Then it becomes unobserved when the dynamic hop is un-
compromised. To understand how the entropy can change,
suppose the ﬁnal static hop goes from being unobserved to
being observed by removing the dynamic hop. Consider any
value sT of ST and some set of observations o. sT and o
together imply a set of path selections for users in sT . The
conditional probability P r[ST = sT|O = o] is proportional
183to the probability that each user made the implied path se-
lections. Removing a dynamic router from the end of a given
connection can change this probability in two ways. First,
the probability can decrease by a factor 1/m, as the obser-
vation of the ﬁnal static router implies that the source of the
connection in sT chose it in her path, and we can assume
that the ﬁnal static hop is chosen randomly from R. Sec-
ond, it can send it to zero, if the source sT assigned to the
given connection is also assigned to another connection that
is observed with a diﬀerent ﬁnal static router. Thus, the en-
tropy can only decrease when the ﬁnal static hop goes from
being unobserved to being observed. This implies that the
entropy can only increase when the ﬁnal static hop switches
from being observed to being unobserved.
The entropy H(DT|C T , O = o) of connection destinations
does not change, because all destinations of the user are
assumed to be observed by the adversary.
Because no term of Equation 3 can decrease, the overall
connection entropy H(C T , ST , DT|O = o) cannot decrease
either.
Next, we show that, again assuming a user only makes
anonymous connections to observed destinations, using two
dynamic hops has the same entropy as using one dynamic
hop.
Theorem 3.
H(C T , ST , DT|Od2 ) = H(C T , ST , DT|Od1 ).
Proof. The proof of Theorem 2 shows that the ﬁrst dy-
namic hop cannot change the entropy H(C T|O) of the con-
nections or the entropy H(DT|C T , O) of the destinations.
Adding a second hop cannot change these for the same rea-
son. In addition, the second hop cannot change the entropy
H(ST|C T , O) of the sources because it is only adjacent to
the ﬁrst dynamic hop, which is chosen at random by all
users. Therefore, by Equation 3, adding a second hop can-
not change the entropy H(C T , ST , DT|Od1 ).
Theorems 2 and 3 only show that adding dynamic hops
doesn’t decrease the connection entropy. This is not a par-
ticularly strong justiﬁcation of their use. However, in gen-
eral, this is the strongest claim we can make. Adding dy-
namic hops can increase the entropy by little or none if i)
the adversary controls most of the network and thus most
of the dynamic routers, ii) the adversary has compromised
the user’s initial, ultimate or penultimate static hops, or iii)
each user has a unique pattern of observed hops not includ-
ing the last hop.
5. CONCLUSION AND FUTURE WORK
The existing anonymous communication deﬁnitions and
system models typically assume that all nodes in the network
are the same, and that any part of the system is as likely
to threaten security as any other. In this paper we have set
out the ﬁrst network and adversary model for anonymous
communication that accounts for the diversity of trust that
diﬀerent users may have in elements of the network. The
presented model is a speciﬁcation for onion routing of a more
general model we have developed to reason about various ap-
proaches to routing security [47]. We identiﬁed two impor-
tant classes of privacy attacks in this model and presented
an example of a routing algorithm motivated by resistance