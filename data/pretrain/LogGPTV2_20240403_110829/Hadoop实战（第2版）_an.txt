}
从上面的注释可以看出，setup函数是在task启动开始就调用的。在这里先温习一下task的知识。在MapReduce中作业会被组织成Map task和Reduce task。每个task都以Map类或Reduce类为处理方法主体，输入分片为处理方法的输入，自己的分片处理完之后task也就销毁了。从这里可以看出，setup函数在task启动之后数据处理之前只调用一次，而覆盖的Map函数或Reduce函数会针对输入分片中的每个key调用一次。所以setup函数可以看做task上的一个全局处理，而不像在Map函数或Reduce函数中，处理只对当前输入分片中的正在处理数据产生作用。利用setup函数的特性，大家可以将Map或Reduce函数中的重复处理放置到setup函数中，可以将Map或Reduce函数处理过程中可能使用到的全局变量进行初始化，或从作业信息中获取全局变量，还可以监控task的启动。需要注意的是，调用setup函数只是对应task上的全局操作，而不是整个作业的全局操作。
2.cleanup函数
cleanup函数在基类中的源码如下：
/**
*Called once at the end of the task.
*/
protected void cleanup（Context context
）throws IOException, InterruptedException{
//NOTHING
}
从这个函数的注释中可以看到，它跟setup函数相似，不同之处在于cleanup函数是在task销毁之前执行的。它的作用和setup也相似，区别仅在于它的启动处在task销毁之前，所以不再赘述cleanup的作用。大家应根据具体使用环境和这两个函数的特点，做出恰当的选择。
3.run函数
run函数在基类中的源码如下：
/**
*Expert users can override this method for more complete control over the
*execution of the Mapper.
*@param context
*@throws IOException
*/
public void run（Context context）throws IOException, InterruptedException{
setup（context）；
while（context.nextKeyValue（））{
map（context.getCurrentKey（），context.getCurrentValue（），context）；
}
cleanup（context）；
}
从上面函数的主体内容和代码的注释可以看出，此函数是Map类或Reduce类的启动方法：先调用setup函数，然后针对每个key调用一次Map函数或Reduce函数，最后销毁task之前再调用cleanup函数。这个run函数将Map阶段和Reduce阶段的代码过程呈现给了大家。正如注释中所说，如果想更加完备地控制Map或者Renduce阶段，可以覆盖此函数，并像普通的Java类中的函数一样添加自己的控制内容，比如增加自己的task启动之后和销毁之前的处理，或者在while循环内外再定义自己针对每个key的处理内容，甚至可以对Map和Reduce函数的处理结果进行进一步的处理。
4.8.2 MapReduce Job中全局共享数据
在编写MapReduce代码的时候，经常会遇到这样的困扰：全局变量应该如何保存？如何让每个处理都能获取保存的这些全局变量？在编程过程中全局变量的使用是不可避免的，但是在MapReduce中直接使用代码级别的全局变量是不现实的。这主要是因为继承Mapper基类的Map阶段类的运行和继承Reducer基类的Reduce阶段类的运行都是独立的，并不像代码看起来的那样会共享同一个Java虚拟机的资源。下面介绍几种在MapReduce编程中相对有效的设置全局共享数据的方法。
1.读写HDFS文件
在MapReduce框架中，Map task和Reduce task都运行在Hadoop集群的节点上，所以Map task和Reduce task、甚至不同的Job都可以通过读写HDFS中预定好的同一个文件来实现全局共享数据。具体实现是利用Hadoop的Java API（关于Java API请参见第9章）来完成的。需要注意的是，针对多个Map或Reduce的写操作会产生冲突，覆盖原有数据。
这种方法的优点是能够实现读写，也比较直观；而缺点是要共享一些很小的全局数据也需要使用I/O，这将占用系统资源，增加作业完成的资源消耗。
2.配置Job属性
在MapReduce执行过程中，task可以读取Job的属性。基于这个特性，大家可以在任务启动之初利用Configuration类中的set（String name, String value）将一些简单的全局数据封装到作业的配置属性中，然后在task中再利用Configuration类中的get（String name）获取配置到属性中的全局数据。这种方法的优点是简单，资源消耗小；缺点是对量比较大的共享数据显得比较无力。
3.使用DistributedCache
DistributedCache是MapReduce为应用提供缓存文件的只读工具，它可以缓存文本文件、压缩文件和jar文件等。在使用时，用户可以在作业配置时使用本地或HDFS文件的URL来将其设置成共享缓存文件。在作业启动之后和task启动之前，MapReduce框架会将可能需要的缓存文件复制到执行任务节点的本地。这种方法的优点是每个Job共享文件只会在启动之后复制一次，并且它适用于大量的共享数据；而缺点是它是只读的。下面举一个简单的例子说明如何使用DistributedCache（具体的示例程序可查看本书附录C）。
1）将要缓存的文件复制到HDFS上。
$bin/hadoop fs-copyFromLocal lookup/myapp/lookup
2）启用作业的属性配置，并设置待缓存文件。
Configuration conf=new Configuration（）；
DistributedCache.addCacheFile（new URI（"/myapp/lookup#lookup"），conf）；
3）在Map函数中使用DistributedCache。
public static class Map extends Mapper＜Object, Text, Text, Text＞{
private Path[]localArchives；
private Path[]localFiles；
public void setup（Context context
）throws IOException, InterruptedException{
//获取缓存文件
Configuration conf=context.getConfiguration（）；
localArchives=DistributedCache.getLocalCacheArchives（conf）；
localFiles=DistributedCache.getLocalCacheFiles（conf）；
}
public void map（K key, V value，
Context context）
throws IOException{
//使用从缓存文件中获取的数据
//……
//……
Context.collect（k, v）；
}
}
4.8.3 链接MapReduce Job
在日常的数据处理过程中，常常会碰到有些问题不是一个MapReduce作业就能解决的，这时就需要在工作流中安排多个MapReduce作业，让它们配合起来自动完成一些复杂任务，而不需要用户手动启动每一个作业。那么怎样将MapReduce Job链接起来呢？应该怎么管理呢？下面来介绍如何链接MapReduce Job和如何配置MapReduce Job流。
1.线性MapReduce Job流
MapReduce Job也是一个程序，作为程序就是将输入经过处理再输出。所以在处理复杂问题的时候，如果一个Job不能完成，最简单的办法就是设置多个有一定顺序的Job，每个Job以前一个Job的输出作为输入，经过处理，将数据再输出到下一个Job中。这样Job流就能按照预定的代码处理数据，达到预期的目的。这种办法的具体实现非常简单：将每个Job的启动代码设置成只有上一个Job结束之后才执行，然后将Job的输入设置成上一个Job的输出路径。
2.复杂MapReduce Job流
第一种方法非常直观简单，但是在某些复杂任务下它仍然不能满足需求。一种情况是处理过程中数据流并不是简单的线性流，如Job3需要将Job1和Job2的输出结果组合起来进行处理。在这种情况下Job3的启动依赖于Job1和Job2的完成，但是Job1和Job2之间并没有关系。针对这种复杂情况，MapReduce框架提供了让用户将Job组织成复杂Job流的API—ControlledJob类和JobControl类（这两个类属于org.apache.hadoop.mapreduce.lib.jobcontrol包）。具体做法是：先按照正常情况配置各个Job，配置完成后再将各个Job封装到对应的ControlledJob对象中，然后使用ControlledJob的addDependingJob（）设置依赖关系，接着再实例化一个JobControl对象，并使用addJob（）方法将所有的Job注入JobControl对象中，最后使用JobControl对象的run方法启动Job流。
3.Job设置预处理和后处理过程
对于前面已经介绍的复杂任务的例子，使用前面的两种方法能很好地解决。现在假设另一种情况，在Job处理前和处理后需要做一些简单地处理，这种情况使用第一种方法仍能解决，但是如果针对这些简单的处理设置新的Job来处理稍显笨拙，这里涉及第三种情况，通过在Job前或后链接Map过程来解决预处理和后处理。比如，在一般统计词频的Job中，并不会统计那些无意义的单词（a、an和the等），这就需要在正式的Job前链接一个Map过程过滤掉这些无意义的单词。这种方法具体是通过MapReduce中org.apache.hadoop.mapred.lib包下的ChainMapper和ChainReducer两个静态类来实现的，这种方法最终形成的是一个独立的Job，而不是Job流，并且只有针对Job的输入输出流，各个阶段函数之间的输入输出MapReduce框架会自动组织。下面是一个具体的实现：
……
Configuration conf=new Configuration（）；
JobConf job=new JobConf（conf）；
job.setJobName（"Job"）；
job.setInputFormatClass（TextInputFormat.class）；
job.setOutputKeyClass（Text.class）；
job.setOutputValueClass（IntWritable.class）；
FileInputFormat.setInputPaths（job, new Path（args[0]））；
FileOutputFormat.setOutputPath（job, new Path（args[1]））；
JobConf map1Conf=new JobConf（false）；
ChainMapper.addMapper（job，
Map1.class，
LongWritable.class，
Text.class，
Text.class，
Text.class，
true，
map1Conf）；
JobConf map2Conf=new JobConf（false）；
ChainMapper.addMapper（job，
Map2.class，
Text.class，
Text.class，
LongWritable.class，
Text.class，
true，
map2Conf）；
JobConf reduceConf=new JobConf（false）；
ChainReducer.setReducer（job，
Reduce.class，
LongWritable.class，
Text.class，
Text.class，
Text.class，
true，
reduceConf）；
JobConf map3Conf=new JobConf（false）；
ChainReducer.addMapper（job，
Map3.class，
Text.class，
Text.class，
LongWritable.class，
Text.class，
true，
map3Conf）；
JobClient.runJob（job）；
在这个例子中，job对象先组织了作业全局的配置，接下来再使用ChainMapper和ChainReducer两个静态类的静态方法设置了作业的各个阶段函数。需要注意的是，ChainMapper和ChainReducer到目前为止只支持旧API，即Map和Reduce必须是实现org.apache.hadoop.mapred.Mapper接口的静态类（详细的示例程序请查看附录D）。
4.9 本章小结
在本章中，主要总体介绍了开发MapReduce程序的一般框架和一些优化方法。
在本章一开始，笔者举例说明了MapReduce的编程。在单节点上完成Map函数和Reduce函数，并且对它们进行测试。待Map和Reduce都能够成功运行后，再在单节点的大数据集进行测试。在进行程序的编写和编译时，最好在集成环境下进行，因为这样便于程序的修改和调试，建议在Eclipse下进行编程。
程序可以在集成环境中运行，也可以在命令行中编译打包，然后在命令中执行。最终的结果也有3种不同的查看方式：在命令行中直接查看；复制到本地文件系统中查看；通过Web用户界面查看。
对于已经能够完成功能性要求的MapReduce程序，还可以从多个方面进行性能上的优化。比如从几个常见的方面入手：变小文件为大文件，减少Map的数量；压缩最终的输出数据或Map的中间输出结果；在Hadoop安装路径下的conf目录下修改属性，使能够同时运行的Map和Reduce任务数增多，从而提高性能。
在本章最后，针对日常处理中的复杂问题，为大家介绍了MapReduce的一些高阶编程手段，将这些方法运用于具体的环境中，能高效直观地解决复杂的MapReduce问题。
第5章 MapReduce应用案例
本章内容
单词计数
数据去重
排序
单表关联
多表关联
本章小结
前面已经介绍了很多关于MapReduce的基础知识，比如Hadoop集群的配置方法，以及如何开发MapReduce应用程序等。本章将从本书配套的云计算在线监测平台（http：//cloudcomputing.ruc.edu.cn/）上的MapReduce编程题目出发，向大家介绍如何挖掘实际问题的并行处理可能性，以及如何设计编写MapReduce程序。需要说明的是，本章所有给出的代码均使用Hadoop最新的API编写、在伪分布集群的默认设置下运行通过，其Hadoop版本为1.0.1，JDK的版本是1.7。本章旨在帮助刚接触MapReduce的读者入门。
5.1 单词计数
进入云计算在线监测平台后的第一个编程题目是WordCount，也就是文本中的单词计数。如同Java中的“Hello World”经典程序一样，WordCount是MapReduce的入门程序。虽然此例在本书中的其他章节也有涉及，但是本章主要从如何挖掘此问题中的并行处理可能性角度出发，让读者了解设计MapReduce程序的过程。
 5.1.1 实例描述
计算出文件中每个单词的频数。要求输出结果按照单词的字母顺序进行排序。每个单词和其频数占一行，单词和频数之间有间隔。
比如，输入一个文件，其内容如下：
hello world
hello hadoop
hello mapreduce
对应上面给出的输入样例，其输出样例为：
hadoop 1
hello 3
mapreduce 1