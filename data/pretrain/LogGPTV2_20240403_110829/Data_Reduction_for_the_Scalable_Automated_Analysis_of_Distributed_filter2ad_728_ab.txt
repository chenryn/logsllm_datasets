Internet Measurement Conference 2005  
241
sor architecture was introduced in 2005 [2], and it has been
used to track new threats [3, 1] and to evaluate the impor-
tance of distributed darknet monitoring [7].
The Host Motion Sensor (HMS) is designed to provide
additional forensic analysis in response to the changing
threat landscape. It consists of three components: a virtual
machine management module, a network detection mod-
ule, and a host resource module. The virtual machine man-
agement module runs the target operating systems on top
of a virtual machine. This module determines when to start
a clean OS image, when to save an infected host image to
disk, and it manages the working set of applications and
operating systems. The network module, like the outbound
connection proﬁling HoneyStat system [9], is responsible
for looking for infected host behavior. It proﬁles the orig-
inating trafﬁc from the honeypot and alerts on any out-
bound connection attempt not part of its normal behavior.
Publicly available intrusion detection software [28] that
matches trafﬁc against known malicious signatures is used
as an oracle for classifying any newly detected threats as
“known” or “unknown”. The ﬁnal module is the host re-
source proﬁler. This system uses BackTracker [16] to build
ﬁle and process dependency trees to both detect violations
of policy and provide detailed forensic information on the
ﬁles and processes created by an possible infection. Again,
existing techniques are used to help identify new activities,
in this case host anti-virus software [6].
There are several research problems associated with this
or any hybrid approach that must be solved in order to en-
sure successful operation. These include:
• Filtering Interactions. Large darknets see staggering
amounts of trafﬁc that can not simply be redirected to
a honeyfarm. In order to achieve scale, the amount of
data presented to the honeyfarm must be signiﬁcantly
reduced.
• Emulating Real Host Behavior. As threats become
increasingly sophisticated, detection systems must be-
come correspondingly complex to elicit the proper re-
sponse and to avoid ﬁngerprinting. Understanding this
arms race and the associated tradeoffs is key to any
successful deployment.
• Automating Forensics. At the speed new threats
are capable of spreading, the operational impact of
human-scaled forensic analysis is minimal. Auto-
mated techniques are needed for generating action-
able forensic information about a threat, including be-
havioral signatures describing activity at the network
and/or host levels.
• Managing Virtual Machines. Even with advanced
the virtual machines are ex-
ﬁltering mechanisms,
pected to handle a large number of requests and
must be managed efﬁciently (as is discussed in the
Potemkin Virtual Honeyfarm [39]). In addition, the
effectiveness of the entire system is dependent on its
ability to accurately represent the vulnerable popula-
tion of interest.
In this section we discussed both the IMS and HMS com-
ponents of our hybrid monitoring system as well as several
of the research problems associated with any such hybrid
system. In the next section, we focus on one of these re-
search problems, reducing and ﬁltering the interactions be-
tween the darknets and the honeyfarm.
4 Hybrid Scalability at Individual Darknets
For hybrid systems to be effective, they must make intel-
ligent decisions about what darknet trafﬁc to send to the
honeyfarm. An idealized mechanism achieves scale by
reducing redundant information and only forwarding one
instance of each unique threat to the honeyfarm. Unfor-
tunately, the mechanisms for determining what to hand-
off must make these decisions with the imperfect infor-
mation available at a darknet monitor.
In order to mini-
mize overhead, a darknet monitor typically collects pack-
ets passively. As such, it has available elements from the
network packet including the standard 5-tuple (source IP
addresses, source port, destination IP address, destination
port, and protocol), as well as any payload data seen for
UDP, ICMP, or TCP backscatter packets. As mentioned
previously, the IMS darknet sensor also collects the ﬁrst
payload packet for TCP connections through a scalable re-
sponder [2]. While other methods have been proposed for
eliciting additional application information (for example,
by building application responders via Honeyd [25]), in
this paper we ﬁx the data available for determining what
to handoff and leave the issue of exploring more sophisti-
cated information sources for future work.
In the following section, we explore the characteristics of
these six elements (the ﬁve tuple and initial payload data)
in order to determine how they affect the scalability of a
hybrid system at individual darknets. We begin by exam-
ining the properties of individual darknets and in particular
the behavior of source IP addresses. We provide these char-
acterizations by looking at data from 14 darknet monitors
ranging in size from a /25 monitor to a /17 monitor over a
period of 10 days between August 18, 2004 and August 28,
2004. We then use these characterization to examine the ef-
fectiveness of proposed ﬁltering techniques in reducing the
connection which need to be evaluated by the honeyfarm.
4.1 Characterizing Individual Blocks
We begin by evaluating the source IP addresses seen at
each darknet as a mechanism for determining bounds on
the number of unique connections to be evaluated. As with
242
Internet Measurement Conference 2005
USENIX Association
Figure 2: The contribution of individual IP to the total num-
ber of packets as seen at 14 darknets. Over 90% of the
packets are from 10% of the source IP addresses.
Figure 3: The contribution of a port to the total number of
packets as seen at 14 darknets. Over 90% of the packets
target .5% of the destination ports.
all the imperfect methods available at a darknet, source IP
addresses have limitations in their ability to represent the
number of unique attack sources. First, IP addresses do not
represent individuals, as multiple users may use the same
computer. Second, the mapping from IP address to com-
puter is not static, so a computer may be represented mul-
tiple times with different IP addresses [32]. As in other
studies [32, 24], we attempt to minimize these effects by
performing analysis across small time frames of less than a
day, or more often, less than an hour. However, the actual
impact of dynamic addresses is not studied here.
The number of source IP addresses seen at each indi-
vidual darknet varied greatly, with an inter-block mean of
75,530 sources and a variance of 92,843 sources over the 10
days. The minimum number observed in a single day was
1,345 sources with a maximum of 352,254 sources. Some
of the wide variability in sources seen can be attributed to
the effect of monitored darknet size. In our sample we had
a mean block size of 5,385 IPs (roughly a /22), with the
smallest darknet being a /25 and the largest a /17. How-
ever, even when normalizing to the smallest block size of
/25, we have an inter-block mean of 40,540 sources and a
variance of 30,381.
To understand how these source IP addresses behave, we
examined the number of packets sent by each source IP
address over the 10-day observation period at each of the
14 darknets. Figure 2 shows a surprising distribution: over
90% of the total packets observed at each darknet were sent
from less than 10% of the source IP addresses seen at that
darknet.
sures. In particular, destination port analysis suffers from
the inability to differentiate activities to the same port and
to represent combinations of port activities (as is the case
in multi-vector attacks) into a single action. Nevertheless
these, serve as a coarse-grained approximation sufﬁcient
for exploring the size of the destination service space.
In our analysis we again see a great deal of variability
based on darknet size, with a mean number of contacted
ports of 17,780 and a variance of 20,397. The minimum
number of ports seen was 1,097 at a /25 and the maximum
was 59,960 at a /17. With maximums approaching the to-
tal number of destination ports allowed, we conjecture that
many of the ports observed are simply due to ports scans.
Nevertheless, unless the scanning is uniform in some way
(e.g., sequential) it would be difﬁcult for the darknet mon-
itors to treat these packets differently. To understand the
role these diverse destination ports play in darknet trafﬁc,
we investigated the distribution of these destination ports
and their effect on the number of packets. Again we see a
very striking result: over 90% of the packets are from .5%
of the destination ports.
Despite the focused distributions, the cross product of
the total unique source IP addresses and total destination
ports is actually quite large. In order for us to efﬁciently
scale, the source IP addresses must repeat similar actions.
We therefore look at the behavior of the top 10% source
IP addresses in terms of the number of destination ports
they contact as well as the number of unique payloads they
send. Figure 4 shows the number of ports contacted by 10%
of the IP addresses at each of 14 darknets over a period of
10 days. At each darknet, over 55% of these source IP ad-
dresses contacted a single destination port, 90% contacted
less than six, and 99% of the source IP addresses contacted
less than 10. A very small fraction of these very active
source IP addresses contacted considerably more ports. As
The other property that limits the number of unique con-
nections to be evealuated is the number and types of ser-
vices contacted. To explore this space, we examined the
unique destination ports contacted over our 10-day obser-
vation period. As with sources, ports are imperfect mea-
USENIX Association
Internet Measurement Conference 2005  
243
00.10.20.30.40.50.60.70.80.91Fraction of Total IPs00.10.20.30.40.50.60.70.80.91Fraction of Total Packets00.010.020.030.040.050.060.070.080.090.1Fraction of Total IPs00.10.20.30.40.50.60.70.80.91Fraction of Total PacketsFigure 4: For the top 10 percent of IPs seen at each of
the 14 darknets, the cumulative distribution function of the
number of ports contacted.
Figure 6: The reduction of Source-Connection, Source-
Port, and Source-Payload ﬁltering. Average effectiveness
per hour for 14 darknets over a 10-day period with N=1.
are contacting the same, small handful of destination ports
repeatedly. In the next section, we examine the effect of
these results on several source-based ﬁltering techniques
and evaluate the practical value of applying these tech-
niques to reduce packets seen at individual dark address
blocks into a smaller number of unique events.
4.2 Source-Based Filtering
Recently a small body of work has emerged on ﬁltering
of the darknet trafﬁc as a means to scale to large ad-
dress blocks. This work has been published in the con-
text of the iSink [38] project as well as the Internet Mo-
tion Sensor [2].
In the iSink work [38] the authors dis-
cuss two forms of ﬁltering, random subnet selection and
a sample and hold method.
In subsequent work [24],
the authors introduce four types of source-based ﬁlter-
ing: source-connection, source-port, source-payload, and
source-destination. The tradeoffs are discussed for each,
including the effect of multi-stage (multiple connections to
the same port) and multi-vector (multiple connections to
different ports) based attacks on their accuracy. However,
only source-connection is evaluated, and only at two dark-
nets for a two-hour trace. The IMS authors have also dis-
cussed [2] preliminary results in using the contents of the
ﬁrst payload packets to reduce disk utilization and differ-
entiate trafﬁc.
The effect of three of the source-based methods is shown
over a 10-day period at 14 darknets in Figure 6. In source-
connection ﬁltering, N connections from a single source
are recorded, and all subsequent trafﬁc from that source
is ignored. Source-connection ﬁltering serves as a base-
line for determining the maximum reduction in any of the
source-based approaches, as each contains the source as a
component and is therefore limited to the number of unique
Figure 5: For the top 10 percent of IPs seen at each of
the 14 darknets, the cumulative distribution function of the
number of unique payloads sent.
expected, the fanout in the payloads sent is slightly larger,
with 30% sending only one payload, 70% sending two or
less, and 10 or less payloads seen by only 92%.
In this
analysis only the ﬁrst payload of an action is considered.
While a better differentiator of threats than ports, it may
still under-represent the total number of events, as many
services (e.g., Windows RPC) require multiple identical
initiation packets. Nevertheless, both methods show that
a signiﬁcant fraction of the behaviors are the same for a
source IP address, with the vast majority of the attacks in-
volving multiple destination ports (multi-vector) and con-
sisting of less than 10 contacted destination ports.
In this section we explored the source IP address behav-
ior as seen by 14 individual darknets. We showed that a
small fraction of the total source IP addresses are responsi-
ble for the vast majority of packets and that these sources
244
Internet Measurement Conference 2005
USENIX Association
0102030405060708090100Number of Ports Contacted00.10.20.30.40.50.60.70.80.91Cumulative Percentage0102030405060708090100Number of Unique Payloads Sent00.10.20.30.40.50.60.70.80.91Cumulative PercentageTime0.860.880.90.920.940.960.98Fraction of Packets RemovedSource-ConnectionSource-PortSource-PayloadFigure 7: The minimum reduction of Source-Connection,
Source-Port, and Source-Payload ﬁltering. Minimum ef-
fectiveness per hour for 14 darknets over a 10-day period
with N=1.
Figure 8: The cumulative distribution function of connec-
tion length from a Windows 2000 honeypot over a three-
day period
sources in a period. In source-port ﬁltering, N connections
are maintained for every source and destination port pair.
This method [24] eliminates the undercounting of events of
source-connection ﬁltering in the case of multi-vector ac-
tivities, but multi-stage activities remain a problem, as con-
nections to the same port may not be visible with a small
number of N (e.g., N=1 will only record the ﬁrst connec-
tion to a port). Finally, we have source-payload ﬁltering
in which the ﬁrst N payloads sent by a source are used
to deﬁne all future behavior by that source. We ﬁnd that
the least differentiating view of an event is seen with the
source-connection ﬁlter. Because it counts any trafﬁc from
the same source as the same, it is undercounting the num-
ber of real events and therefore has the greatest reduction,
a mean of 95%, across blocks. The more restrictive source-
port ﬁltering results in a mean reduction of 93% of the
packets. Finally, the most differentiating view of events,
source-payload, showed a mean reduction of 91%. On the
whole, source-based techniques appear effective at reduc-
ing packets to a smaller number of events.
In comparing these results with the source-destination
results reported previously [24] we see less effectiveness
than the 99% reduction reported for values of N = 1, with
even the least restrictive methods. While there are several
possible explanations for this discrepancy, such as the dif-
ference in darknet block size (the blocks considered in [24]
are /16s) we also report a great deal of variance, not only
between darknets, but in a darknets over time. The intra-
hour standard deviation for source-connection reduction
was 2.7%, with source-port and source-payload at 3.1%
and 3.9% respectively. Perhaps of more interest is the min-
imum value during each bin, as this is the run-time value
that a hybrid ﬁltering system would have to contend with.
We show the minimum values in Figure 7. Here the mini-
mum values drop to as low as 53.8% for source-connection
ﬁltering, and 46.7% and 49.1% for source-port and source-
payload. In practice, the reductions observed may be less
when applied to a runtime system that is making decisions
about reduction and handoff based on the current observa-
tion period.
4.3 Effects on Hybrid Scalability
In order to understand the effect of source-based ﬁltering
on reducing the number of connections processed by a sim-
ple hybrid system, we considered the behavior at a single
darknet. We applied source-payload ﬁltering to the largest
darknet over our 10-day observation window, a /17 darknet,
and counted the unique source-payload events in one sec-
ond bins. This analysis was designed to measure the total
number of events per second a hybrid system consisting of
a single darknet would be expected to handle. With aver-
ages less than 100, the system can expect to see bursts of