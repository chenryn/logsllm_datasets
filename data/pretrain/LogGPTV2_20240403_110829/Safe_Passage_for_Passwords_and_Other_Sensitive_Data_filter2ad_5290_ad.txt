cordance with the Flicker external communication proto-
col [19]. Only this PoPr will ever be able to access the
private key.
When key generation completes, the newly generated
public signing key (KPoPr sig ) is extended into a TPM
Platform Conﬁguration Register (PCR) and output from the
PoPr. Untrusted code running on the legacy OS then passes
this key back to the web browser, along with the user’s sys-
tem’s public identity (e.g., an Attestation Identity Key, or
the set of Endorsement Key, Platform, and Conformance
Credentials) and a TPM attestation covering the relevant
PCRs. These tasks can be left to untrusted code because the
properties of the PCRs in the TPM chip prevent untrusted
code from undetectably tampering with their values.
In steady-state, the PoPr will encrypt user input using the
public key in the webserver-provided Cert ws enc, and sign
it with K −1
PoPr sig to authenticate that it came from the PoPr
running on the user’s computer. There is no need to per-
form an attestation during future communication between
this PoPr and webserver.
5.2.3 Processing Attestation Results
Remote entities need to have knowledge that a set of at-
tested measurements represents a PreP and PoPr that keep
the user’s input and PreP state safe (encrypted when un-
trusted code runs, which may include Flicker sessions with
other, distrusted PALs). Prominent institutions (e.g., banks)
may develop and provide their own PoPrs for protecting
user input to their websites. In these cases, the institution’s
webserver can easily be conﬁgured with the expected PoPr
measurements, since it provided the PoPr in the ﬁrst place.
If one PoPr proves to be sufﬁcient for a wide variety of web-
sites, then its measurement may become a standard which
can be widely deployed.
The webserver must also have knowledge of existing
PrePs in order to make a trust decision based on the attes-
tation result. We expect the number of PrePs to be reason-
ably small in practice, as most input devices adhere to a
well-known (and simple) protocol.
6 The Trusted Monitor
Bumpy’s input protections by themselves are of limited
value unless the user can ascertain whether the protections
are active when she enters sensitive data. The primary us-
ability criticism [7] of PwdHash [25] is that it provides in-
sufﬁcient feedback to the user as to the state of input pro-
tections. Thus, it is of utmost importance that the user is
aware of the transition between protected and unprotected
input. With Bumpy, the Trusted Monitor serves as a trusted
output device that provides feedback to the user concerning
the state of input protections on her computer.
6.1 Feedback for the User
When input protections are active, the Trusted Moni-
tor displays the ﬁnal destination (e.g., website) whose PoPr
will receive her next sensitive input. We represent this us-
ing the domain name and favicon of the currently active
PoPr, as reported by the PreP. When input protections are
disabled, the Trusted Monitor displays a warning that in-
put is unprotected and that users should use @@ to initiate
sensitive input. Figure 4 shows screenshots from our im-
plementation. In addition to changing the information on
its display, the Trusted Monitor uses distinctive beeps to
signal when protections become enabled or disabled.
The Trusted Monitor works in concert with the proper-
ties of the PreP’s Second @ and Enqueue Input states (Fig-
ure 3): when in these states, the PoPr is locked in and can-
not change until after the sensitive input to a single ﬁeld is
processed by this PoPr (in the Invoke PoPr state). As such,
the PoPr represented by the domain name and favicon that
are displayed by the Trusted Monitor will remain the ac-
tive PoPr until input to the current ﬁeld is complete. Thus,
there is no need for the user to worry about a malicious PoPr
change in the middle of a string of sensitive input. However,
the user must be diligent between ﬁelds. She must ensure
that the Trusted Monitor responds to each unique @@ se-
quence that she types (i.e., that the Trusted Monitor beeps
and shows that protection is enabled) before proceeding to
input her sensitive data. This is because the untrusted OS
may affect the delivery of encrypted keystrokes to the PreP
and PreP messages to the Trusted Monitor.
The risk is that malicious code may try to confuse the
user such that she misinterprets the Trusted Monitor’s dis-
play for one input ﬁeld as indicating that her input is secure
for additional input ﬁelds. One such attack works as fol-
lows. Malcode allows keystrokes and Trusted Monitor up-
dates to proceed normally until the user begins typing sen-
sitive input for one input ﬁeld on a web page. The Trusted
Monitor beeps and updates its display to indicate that pro-
tections are active. At this point, the malcode begins to
suppress Trusted Monitor updates, but the Trusted Moni-
tor cannot immediately distinguish between suppressed up-
dates and a distracted user who has turned away from her
computer. A user who ﬁnishes typing this secret and then
transitions to another input ﬁeld and proceeds to enter an-
other secret — even after entering @@ and glancing at the
Trusted Monitor, but without waiting for conﬁrmation of
the receipt of the new @@ by the PreP— renders the second
secret vulnerable to disclosure. To expose this secret, the
malicious OS plays the user’s encrypted inputs to the PreP
after the user is ﬁnished typing the second secret, but pro-
vides a malicious PoPr to the PreP when transitioning to the
Focused and Invoke PoPr states for the second input. That
is, the user provided the second secret presuming it was
protected in the same way as the ﬁrst, but since she did not
conﬁrm that the second @@ was received by the PreP before
she typed the second secret, it is vulnerable to disclosure to
a malicious PoPr.
To help users avoid such pitfalls, it may be desirable for
the Trusted Monitor to emit an audible “tick” per sensitive
keystroke received by the PreP, in addition to the preceding
beep when the @@ is received. This way, the absence of
ticks might be another warning to the user.
6.2 Protocol Details
To facilitate the exchange of information regarding the
active PoPr, a cryptographic association is needed between
the PreP and the Trusted Monitor. To establish this associ-
ation, the Trusted Monitor engages in a one-time initializa-
tion protocol with the PreP, whereby cryptographic keys are
established for secure (authentic) communication between
the PreP and the Trusted Monitor. The protocol is quite
similar to that used between the PreP and input device(s) in
Section 4.2.
The initialization process for PreP-to-Trusted Monitor
communication is an infrequent event (i.e., only when the
user gets a new Trusted Monitor or input device). Thus, a
trust-on-ﬁrst-use approach is reasonable, where the Trusted
Monitor simply accepts the public key claimed for the PreP.
Any of a range of more secure (but more manual or more
infrastructure-dependent) approaches can be employed, in-
cluding ones that allow the Trusted Monitor to validate an
attestation from the TPM on the user’s computer as to the
correct operation of the PreP and to the value of its pub-
lic key (a capability offered by Flicker [18]). The PreP can
save its private key in PCR-protected storage on the user’s
computer, and so will be available only to this PreP in the
future (as in Section 4).
The Trusted Monitor need not be a very complex de-
vice. Its responsibilities are to receive notiﬁcations from the
user’s computer via wired or wireless communication, and
to authenticate and display those notiﬁcations. While our
implementation employs a smartphone for a Trusted Mon-
itor (Section 8), this is far more capable than is necessary
(and more capable than we would recommend).
With a smartphone serving as the Trusted Monitor, there
is no reason why the user’s Trusted Monitor cannot per-
form the full gamut of veriﬁcation tasks we have described
as being in the webserver’s purview.
In fact, technically
savvy and privacy-conscious users may prefer this model
of operation, and it becomes signiﬁcantly easier to adopt
if a small number of PrePs and PoPrs become standardized
across many websites. These users can learn that their input
is being handled by precisely the PreP and PoPr that they
have conﬁgured for their system, and that opaque third-
party code is never invoked with their input.
7 Security Analysis
We discuss Bumpy’s TCB, the implications of a com-
promised web browser, phishing attacks, and usability.
7.1 Trusted Computing Base
One of the primary strengths of Bumpy is the reduction
in the TCB to which input is exposed on the user’s com-
puter. Always in the TCB are the encrypting input device
and the PreP that decrypts and processes the encrypted in-
put events on the user’s computer. The PoPr associated with
each website is also in the TCB for the user’s interaction
with that website, but the PreP isolates each PoPr from both
the PreP’s sensitive state and the OS (thereby preventing a
malicious PoPr from harming a well-behaved OS). The en-
crypting input device is a dedicated, special-purpose hard-
ware device, and the PreP is a dedicated, special-purpose
software module that executes with Flicker’s isolation [18].
A compromise of either of these components is fatal for
Bumpy, but their small size dramatically reduces their at-
tack surface with respect to alternatives available today, and
may make them amenable to formal veriﬁcation. The PoPr
may be speciﬁc to the destination website, and may be con-
sidered a local extension of the remote server. It does not
make sense to send protected input to a remote server that
the user is unwilling to trust. Additionally, the PoPr’s func-
tionality is well-deﬁned, leading to small code size.
Also in the TCB is the Trusted Monitor that displays au-
thenticated status updates from the PreP, i.e., the domain
name and favicon for the active PoPr. The Trusted Monitor
never handles the user’s sensitive input, so compromising it
alone is insufﬁcient to obtain the user’s input. However, if
the Trusted Monitor indicates that all is well when in fact it
is not, then a phishing attack may be possible (Section 7.3).
7.2 Compromised Browser
If the user’s browser or OS is compromised, then mali-
cious code can invoke the PreP with input of its choosing.
Bumpy can still keep the user’s sensitive input safe pro-
vided that she adheres to the convention of starting sensitive
input with @@ and pays attention to the security indicator on
her Trusted Monitor.
The cryptographic tunnel between the input device and
PreP prevents malicious code from directly reading any
keystrokes, and prevents the malicious code from injecting
spurious keystrokes. Thus, a compromised browser’s op-
tions are restricted to providing spurious inputs to the PreP,
including SSL certiﬁcates, PoPrs, and browser focus events.
None of these are sufﬁcient to violate the security properties
of Bumpy, but they can put the user’s diligence in referring
to the Trusted Monitor to the test.
Malicious SSL Certiﬁcates. The PreP is equipped with
a list of trusted certiﬁcate authorities (CAs). Any SSL cer-
tiﬁcate that cannot be veriﬁed is rejected, causing sensitive
keystrokes to be dropped. Thus, an attacker’s best option
is to compromise an existing site’s SSL certiﬁcate (thereby
reducing the incentive to attack the user’s computer), or to
employ a phishing attack by registering a similar domain
name to that which the user expects (e.g., hotmai1.com, in-
stead of hotmail.com) and using an identical favicon.
Malicious PoPr. The PreP will not accept a PoPr unless
it can be veriﬁed with the current SSL certiﬁcate, thereby
reducing this attack to an attack on the SSL certiﬁcate (as
described in the previous paragraph) or webserver.
Malicious Browser Focus Events. A malicious browser
may generate spurious or modiﬁed focus events in an at-
tempt to confuse the PreP with respect to which ﬁeld is
currently active. However, regardless of which ﬁeld is ac-
tive, the user controls whether the current input events are
considered sensitive. When they are sensitive, input to a
ﬁeld is always encrypted and tagged with the ﬁeld’s name
before being released to the PoPr. A malicious focus event
may only cause ciphertext to be tagged with the wrong ﬁeld
name, thereby impacting availability. However, we already
consider an adversary which controls the OS on the user’s
computer, and is thus already in total control of availability.
7.3 Phishing
If a user is fooled by a phishing attack (e.g., she confuses
similar-looking domains), she may be using Bumpy’s pro-
tections to enter her sensitive data directly into a phishing
website. Defeating phishing attacks is not our focus here,
though Bumpy should be compatible with a wide range of
phishing defenses [14]. As a simple measure, Bumpy pro-
vides an indicator on the Trusted Monitor that includes the
domain name and favicon of the current website. Though
we have not solved some of the intrinsic problems with cer-
tiﬁcate authorities and SSL, the PreP can enforce policies
such as: only PoPrs from white-listed webservers are eligi-
ble to receive a user’s input; PoPrs from blacklisted web-
servers can never receive a user’s input; and self-signed
certiﬁcates are never acceptable. These policies are en-
forceable in the PreP, and require the user to have a Trusted
Monitor only to provide feedback to improve usability.
With a PoPr implementing PwdHash, only the hashed
password is returned to the web browser. If a user is fooled
into entering her password into a phishing site with a dif-
ferent domain name, the phishing site captures only a hash
of the user’s password, and must successfully perform an
ofﬂine dictionary attack before any useful information is
obtained about the user’s password at other sites. Addi-
tionally, in the case where a user ignores the indicator but
has established the habit of starting her password with @@,
hashing of the user’s password can restrict the impact of the
user’s being phished on one website to that website alone.
With a compromised OS, malware on the user’s system can
observe the hashed password when it is released to the web
browser, but this password is only valid at a single website.
7.4 Usability
Confusion.
If users do not understand the Bumpy system,
or their mental model of the system is inaccurate, then they
may be fooled by a malicious web page. For example, a
prompt such as the following may trick the user into believ-
ing that there is no need to preﬁx her password with @@ on
the current web page:
Input your password:
@@
The user may also become confused if she makes a ty-
pographical error entering @@, and tries to use backspace
to correct it. Bumpy will not offer protections in this case,
until the user changes to another input ﬁeld and then comes
back to the current ﬁeld (i.e., causes a blur event and then
a new focus event). The Trusted Monitor does indicate that
protections are disabled, but it may not be obvious to the
user why this is the case. We discuss editable sensitive in-
put in Section 10.1.
Extra Mouse Clicks. When a user clicks in an input ﬁeld,
a focus event is generated for the ﬁeld and conveyed to the
PreP. The user’s next mouse click is interpreted by the PreP
as a blur event for the current input ﬁeld, disabling input
protection. An attack may be possible if the user clicks
the mouse in an input ﬁeld after already typing part of her
input into the ﬁeld. This click could be interpreted as a
blur event, and cause the rest of the user’s keystrokes to
be sent unencrypted. This may arise when, e.g., the user
forgot her credit card number after entering the ﬁrst few
digits from memory, and needs to go lookup the remainder.
The Trusted Monitor will beep and update its display to
indicate that input protections are disabled when this blur
event happens, but this may be a source of user confusion.
8
Implementation
Our implementation of Bumpy supports veriﬁcation by
the remote webserver with a smartphone as Trusted Mon-
itor to provide feedback to the user. We implement two
PoPrs: one encrypts sensitive input as-is for transmission
to a Bumpy-aware webserver, and the other hashes pass-
words with the PwdHash algorithm [25] for transmission to
an unmodiﬁed webserver.
We have been unable to ﬁnd any commercially avail-