9、生成订单数据压测。  
测试最极端的情况，未来30天的票全部售完。  
20000趟车，20节车厢，200个座位，平均每个座位卖10张票。 8000万订单/天。  
24亿数据量。  
```  
vi test.sql  
select create_order(nextval('seq'),(random()*19999)::int,(random()*19)::int2,(random()*199)::int2,(random()*99)::int2,(random()*99)::int2,current_date+(random()*30)::int,(random()*1000000000)::int8,1::int2,(random()*9999)::float8,1::int2,1::int2,now()::timestamp);  
nohup pgbench -M prepared -n -r -P 1 -f ./test.sql -c 64 -j 64 -t 37500000 >./log.csv 2>&1 &  
```  
性能非常平稳。  
```  
......  
progress: 5778.0 s, 127956.8 tps, lat 0.500 ms stddev 0.198  
progress: 5779.0 s, 128701.9 tps, lat 0.497 ms stddev 0.208  
progress: 5780.0 s, 127889.8 tps, lat 0.500 ms stddev 0.195  
progress: 5781.0 s, 128157.5 tps, lat 0.499 ms stddev 0.204  
progress: 5782.0 s, 128529.6 tps, lat 0.498 ms stddev 0.207  
progress: 5783.0 s, 128740.1 tps, lat 0.497 ms stddev 0.190  
progress: 5784.0 s, 128211.0 tps, lat 0.499 ms stddev 0.191  
progress: 5785.0 s, 128414.9 tps, lat 0.498 ms stddev 0.197  
progress: 5786.0 s, 127032.1 tps, lat 0.504 ms stddev 0.201  
progress: 5787.0 s, 128371.0 tps, lat 0.499 ms stddev 0.186  
progress: 5788.0 s, 128116.8 tps, lat 0.500 ms stddev 0.202  
progress: 5789.0 s, 127408.5 tps, lat 0.502 ms stddev 0.207  
progress: 5790.0 s, 127691.7 tps, lat 0.501 ms stddev 0.204  
progress: 5791.0 s, 128833.5 tps, lat 0.497 ms stddev 0.195  
progress: 5792.0 s, 128363.8 tps, lat 0.499 ms stddev 0.204  
progress: 5793.0 s, 128307.7 tps, lat 0.499 ms stddev 0.203  
progress: 5794.0 s, 128599.4 tps, lat 0.498 ms stddev 0.186  
......  
```  
写入总数据量48亿，占用空间 549 GB。  
```  
postgres=# \l+  
                                                               List of databases  
   Name    |  Owner   | Encoding  | Collate | Ctype |   Access privileges   |  Size  | Tablespace |                Description                   
-----------+----------+-----------+---------+-------+-----------------------+--------+------------+--------------------------------------------  
 postgres  | postgres | SQL_ASCII | C       | C     |                       | 549 GB | pg_default | default administrative connection database  
```  
10、查询压测  
10\.1、按用户查询，返回用户的所有订单，平均返回2.4条。  
```  
vi test1.sql  
\set uid random(1,1000000000)  
select * from get_user_order((:uid)::int8);  
pgbench -M prepared -n -r -P 1 -f ./test1.sql -c 64 -j 64 -T 120  
```  
```  
transaction type: ./test1.sql  
scaling factor: 1  
query mode: prepared  
number of clients: 64  
number of threads: 64  
duration: 120 s  
number of transactions actually processed: 25440118  
latency average = 0.302 ms  
latency stddev = 4.141 ms  
tps = 211975.134822 (including connections establishing)  
tps = 212024.097764 (excluding connections establishing)  
script statistics:  
 - statement latencies in milliseconds:  
         0.002  \set uid random(1,1000000000)  
         0.301  select * from get_user_order((:uid)::int8);  
```  
10\.2、按坐席和乘车日期查询，平均返回10条记录。  
```  
vi test2.sql  
\set train_id random(0,19999)  
\set box_id random(0,19)
\set site_id random(0,199)  
select * from get_site_order(current_date+(random()*30)::int, (:train_id)::int, (:box_id)::int2, (:site_id)::int2);  
pgbench -M prepared -n -r -P 1 -f ./test2.sql -c 64 -j 64 -T 120  
```  
```  
transaction type: ./test2.sql  
scaling factor: 1  
query mode: prepared  
number of clients: 64  
number of threads: 64  
duration: 120 s  
number of transactions actually processed: 25650025  
latency average = 0.299 ms  
latency stddev = 0.047 ms  
tps = 213746.298310 (including connections establishing)  
tps = 213763.615290 (excluding connections establishing)  
script statistics:  
 - statement latencies in milliseconds:  
         0.002  \set train_id random(0,19999)  
         0.000  \set box_id random(0,19)  
         0.000  \set site_id random(0,199)  
         0.302  select * from get_site_order(current_date+(random()*30)::int, (:train_id)::int, (:box_id)::int2, (:site_id)::int2);
```  
## 小结  
1、生成订单速度，约 12.8万行/s。  
2、按用户查询，返回用户的所有订单，平均返回2.4条。约 21.2万 tps。  
3、按坐席和乘车日期查询，平均返回10条记录。约  tps。  
4、表格：  
订单记录数 | 空间占用 | 表占用 | 索引占用  
---|---|---|---  
48 亿 | 549 GB | 449 GB | 100 GB    
CASE | 返回记录数 | TPS | 响应速度  
---|---|---|---  
生成订单 | - | 12.8 万 | 0.5 毫秒  
按用户查询订单 | 3 条 | 21.2 万 | 0.3 毫秒   
按坐席和日期查询订单 | 10 条  | 21.3 万 | 0.3 毫秒  
5、目前分区性能最好的还是pg_pathman, 10内置的分区表写入、查询方面的性能不佳。如果要快速写入24亿，建议直接写分区子表，单步写入可以达到 35万条/s 左右。  
为了达到均衡的目的，本方案使用了schemaless方案，无需建表，无需维护分区。牺牲一些些性能。  
6、其他schemaless设计的案例：  
[《PostgreSQL schemaless 的实现(类mongodb collection)》](../201705/20170511_01.md)    
[《PostgreSQL 时序最佳实践 - 证券交易系统数据库设计 - 阿里云RDS PostgreSQL最佳实践》](../201704/20170417_01.md)    
[《行为、审计日志 (实时索引/实时搜索)建模 - 最佳实践 2》](../201705/20170522_01.md)    
7、采用schemaless的方案，表分区可以更加自由，可以更细，因为直击目标表。按时间分区的订单表，可以再按train_id, site_id进行二级分区（例如32*8个分区，当未来30天的票全部售完的情况下，每个分区31万数据，cluster很快很快。）。将单表记录数降到更低，采用train_id+site_id索引进行cluster，使得数据密集存储，查询时可以扫描更少的数据块。  
8、采用schemaless的方案，表分区可以更加自由，可以更细，因为直击目标表。按用户ID哈希分区的订单表，模数可以设更大，例如设置为2048，当未来30天的票全部售完的情况下，单表则降到120万记录。cluster很快很快。将单表记录数降到更低，采用uid索引进行cluster，使得数据密集存储，查询时可以扫描更少的数据块。  
9、监测pg_stats.correlation，当相关性绝对值低于0.8时，触发cluster。可以使得数据自动维持在一个较高密集度。  
#### [PostgreSQL 许愿链接](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216")
您的愿望将传达给PG kernel hacker、数据库厂商等, 帮助提高数据库产品质量和功能, 说不定下一个PG版本就有您提出的功能点. 针对非常好的提议，奖励限量版PG文化衫、纪念品、贴纸、PG热门书籍等，奖品丰富，快来许愿。[开不开森](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216").  
#### [9.9元购买3个月阿里云RDS PostgreSQL实例](https://www.aliyun.com/database/postgresqlactivity "57258f76c37864c6e6d23383d05714ea")
#### [PostgreSQL 解决方案集合](https://yq.aliyun.com/topic/118 "40cff096e9ed7122c512b35d8561d9c8")
#### [德哥 / digoal's github - 公益是一辈子的事.](https://github.com/digoal/blog/blob/master/README.md "22709685feb7cab07d30f30387f0a9ae")
![digoal's wechat](../pic/digoal_weixin.jpg "f7ad92eeba24523fd47a6e1a0e691b59")
#### [PolarDB 学习图谱: 训练营、培训认证、在线互动实验、解决方案、生态合作、写心得拿奖品](https://www.aliyun.com/database/openpolardb/activity "8642f60e04ed0c814bf9cb9677976bd4")
#### [购买PolarDB云服务折扣活动进行中, 55元起](https://www.aliyun.com/activity/new/polardb-yunparter?userCode=bsb3t4al "e0495c413bedacabb75ff1e880be465a")
#### [About 德哥](https://github.com/digoal/blog/blob/master/me/readme.md "a37735981e7704886ffd590565582dd0")