在部署 Heapster 之前，请检查您正在使用的监控工具是否支持作为本文中的 Heapster 接收器:[https://github . com/kubernetes/Heapster/blob/master/docs/sink-configuration . MD](https://github.com/kubernetes/heapster/blob/master/docs/sink-configuration.md)。
如果没有，我们可以有一个独立的设置，通过应用这个模板使仪表板和`kubectl top`工作:
```
$ kubectl create -f \
    https://raw.githubusercontent.com/kubernetes/heapster/master/deploy/kube-config/standalone/heapster-controller.yaml  
```
如果启用了 RBAC，请记住应用此模板:
```
$ kubectl create -f \ https://raw.githubusercontent.com/kubernetes/heapster/master/deploy/kube-config/rbac/heapster-rbac.yaml
```
安装 Heapster 后，`kubectl top`命令和 Kubernetes 仪表板应该正确显示资源使用情况。
虽然 cAdvisor 和 Heapster 专注于物理指标，但我们也希望在监控仪表板上显示对象的逻辑状态。kube-state-metrics([https://github.com/kubernetes/kube-state-metrics](https://github.com/kubernetes/kube-state-metrics))正是完成我们监控栈的那块。它观看 Kubernetes 大师，并将我们从`kubectl get`或`kubectl describe`看到的对象雕像转换为普罗米修斯格式的度量标准([https://Prometheus . io/docs/instrumenting/exposure _ formats/](https://prometheus.io/docs/instrumenting/exposition_formats/))。只要监控系统支持这种格式，我们就可以将状态抓取到度量存储中，并在发生无法解释的重启计数等事件时得到警报。要安装 kube-state-metrics，首先下载项目存储库([https://github . com/kubernetes/kube-state-metrics/tree/master/kubernetes](https://github.com/kubernetes/kube-state-metrics/tree/master/kubernetes))下的`kubernetes`文件夹中的模板，然后应用它们:
```
$ kubectl apply -f kubernetes
```
之后，我们可以在其服务端点的指标中查看集群内部的状态:
`http://kube-state-metrics.kube-system:8080/metrics`
# 动手监控
到目前为止，我们已经学习了很多在 Kubernetes 中构建一个不透水的监控系统的原则，以实现一个健壮的服务，现在是时候实现一个实用的了。因为绝大多数 Kubernetes 组件以 Prometheus 格式在常规路径上公开它们的检测度量，所以我们可以自由使用我们熟悉的任何监控工具，只要该工具理解该格式。在本节中，我们将用一个开源项目 Prometheus([https://Prometheus . io](https://prometheus.io))建立一个示例，它是一个独立于平台的监控工具。它在 Kubernetes 生态系统中的受欢迎不仅是因为它的强大，还因为它得到了同样赞助 Kubernetes 项目的**云原生计算基金会**([https://www.cncf.io/](https://www.cncf.io/))的支持。
# 遇见普罗米修斯
普罗米修斯框架由几个组件组成，如下图所示:
![](img/00100.jpeg)
与所有其他监控框架一样，普罗米修斯依赖代理从我们的系统组件中抓取统计数据，这些代理是图表左侧的导出者。除此之外，普罗米修斯在度量收集上采用了拉取模型，也就是说，它不是被动地接收度量，而是主动地从出口商的度量端点拉取数据。如果一个应用公开了一个指标的端点，普罗米修斯也能够抓取该数据。默认存储后端是嵌入式级别数据库，可以切换到其他远程存储，如 InfluxDB 或石墨。普罗米修斯还负责根据预先配置的规则向**告警管理器**发送告警。**报警管理器**处理报警发送任务。它将收到的警报分组，并将其分派给实际发送消息的工具，如电子邮件、Slack、PagerDuty 等。除了警报之外，我们还希望将收集的指标可视化，以便快速了解我们的系统，Grafana 就是在这里派上用场的工具。
# 部署普罗米修斯
我们为本章准备的模板可以在这里找到:
[https://github . com/DevOps-wit-Kubernetes/examples/tree/master/chapter 6](https://github.com/DevOps-with-Kubernetes/examples/tree/master/chapter6)
在 6-1_prometheus 下面是这个部分的清单，包括 prometheus 部署、导出器和相关资源。除了需要在`kube-system`命名空间中工作的组件之外，它们将被固定在一个专用的命名空间`monitoring`中。请仔细查看，现在让我们按照以下顺序创建资源:
```
$ kubectl apply -f monitoring-ns.yml
$ kubectl apply -f prometheus/config/prom-config-default.yml
$ kubectl apply -f prometheus  
```
在所提供的设置中，资源的使用被限制在相对较低的水平。如果您想以更正式的方式使用它们，建议根据实际要求调整参数。普罗米修斯服务器启动后，我们可以通过`kubectl port-forward`在端口`9090`连接到它的网络用户界面。如果相应地修改它的服务(`prometheus/prom-svc.yml`)，我们可以使用节点端口或入口来连接到用户界面。当进入 UI 时，我们将看到的第一个页面是普罗米修斯的表达式浏览器，我们在这里构建查询并可视化度量。在默认设置下，普罗米修斯将从自身收集指标。在路径`/targets`可以找到所有有效的刮擦目标。要和普罗米修斯对话，我们必须对它的语言有所了解: **PromQL** 。
# 使用 PromQL
PromQL 有三种数据类型:即时向量、范围向量和标量。瞬时向量是采样数据的时间序列；范围向量是包含一定时间范围内数据的一组时间序列；标量是一个数字浮点值。存储在普罗米修斯内部的度量用度量名称和标签来标识，我们可以通过表达式浏览器上“执行”按钮旁边的下拉列表找到任何收集的度量的名称。如果我们用度量名称来查询普罗米修斯，比如`http_requests_total`，我们会得到很多结果，因为即时向量与名称匹配，但标签不同。同样，我们也可以只使用`{}`语法来查询一组特定的标签。例如，查询`{code="400",method="get"}`意味着我们需要标签分别为`code`、`method`等于`400`和`get`的任何指标。在查询中组合名称和标签也是有效的，例如`http_requests_total{code="400",method="get"}`。PromQL 赋予我们从各种线索中检查我们的应用或系统的检测能力，只要收集了相关的指标。
除了刚才提到的基本查询之外，PromQL 还有很多东西，比如用正则表达式和逻辑运算符查询标签，用函数连接和聚合度量，甚至在不同的度量之间执行操作。例如，下面的表达式给出了`kube-system`命名空间中`kube-dns`部署消耗的总内存:
```
sum(container_memory_usage_bytes{namespace="kube-system", pod_name=~"kube-dns-(\\d+)-.*"} ) / 1048576
```
更详细的文档可以在普罗米修斯官方网站([https://prometheus.io/docs/querying/basics/](https://prometheus.io/docs/querying/basics/))上找到，肯定能帮你释放普罗米修斯的力量。
# 在 Kubernetes 发现目标
由于普罗米修斯只从它知道的端点提取指标，我们必须明确告诉它我们希望从哪里收集数据。路径`/config`下是列出当前配置的拉取目标的页面。默认情况下，会有一个作业收集普罗米修斯本身的当前指标，它位于传统的抓取路径`/metrics`中。如果连接到端点，我们会看到一个很长的文本页面:
```
$ kubectl exec -n monitoring prometheus-1496092314-jctr6 -- \
wget -qO - localhost:9090/metrics
# HELP go_gc_duration_seconds A summary of the GC invocation durations.
# TYPE go_gc_duration_seconds summary
go_gc_duration_seconds{quantile="0"} 2.4032e-05
go_gc_duration_seconds{quantile="0.25"} 3.7359e-05
go_gc_duration_seconds{quantile="0.5"} 4.1723e-05
...
```
这只是我们多次提到的普罗米修斯度量格式。下次当我们看到这样的页面时，我们会知道它是一个度量端点。
刮削普罗米修斯的默认作业被配置为静态目标。然而，由于 Kubernetes 中的容器是动态创建和销毁的，要找出一个容器的确切地址真的很麻烦，更不用说将其设置在普罗米修斯上了。在某些情况下，我们可能会利用服务 DNS 作为静态指标目标，但这仍然不能解决所有情况。幸运的是，普罗米修斯通过其发现库本内服务的能力帮助我们克服了这个问题。
更具体地说，它能够查询 Kubernetes 关于运行服务的信息，并相应地将它们添加或删除到目标配置中。目前支持四种发现机制:
*   **节点**发现模式为每个节点创建一个目标，默认情况下，目标端口是 kubelet 的端口。
*   **服务**发现模式为每个`service`对象创建一个目标，服务中所有定义的端口都将成为一个抓取目标。
*   **pod** 发现模式的工作方式类似于服务发现角色，也就是说，它为每个 pod 创建目标，并为每个 pod 公开所有定义的容器端口。如果 pod 的模板中没有定义端口，它仍然会创建一个仅包含地址的抓取目标。
*   **端点**模式发现由服务创建的`endpoint`对象。例如，如果一个服务由三个荚支持，每个荚有两个端口，那么我们将有六个抓取目标。此外，对于 pod，不仅会发现暴露给服务的端口，还会发现其他声明的容器端口。
下图说明了四种发现机制:左边的是 Kubernetes 中的资源，右边列表中的是 Prometheus 中创建的目标:
![](img/00101.jpeg)
一般来说，并不是所有暴露的端口都被用作度量端点，所以我们当然不希望普罗米修斯抓取我们集群中的所有东西，而只收集标记的资源。为了实现这一点，普罗米修斯利用资源清单上的注释来区分要抓取的目标。注释格式如下:
*   **在 Pod **上:如果 Pod 是由 Pod 控制器创建的，请记住在 Pod 规范中而不是在 Pod 控制器中设置普罗米修斯注释:
    *   `prometheus.io/scrape` : `true`表示该 Pod 应该被拉动。
    *   `prometheus.io/path`:将此标注设置为暴露度量的路径；仅当目标 Pod 使用的路径不是`/metrics`时才需要设置。
    *   `prometheus.io/port`:如果定义的端口不同于实际的度量端口，用这个注释覆盖它。
*   **关于服务**:由于端点大多不是手动创建的，端点发现使用从服务继承的注释。也就是说，对服务的注释同时影响服务和端点发现模式。因此，我们将使用`prometheus.io/scrape: 'true'`来表示服务创建的要被抓取的端点，并使用`prometheus.io/probe: 'true'`来用度量标记服务。此外，`prometheus.io/scheme`指定使用`http`还是`https`。除此之外，路径和端口注释也在这里工作。
以下模板片段指出了普罗米修斯的端点发现角色，但在 pods 上创建目标的服务发现角色是在:`9100/prom`选择的。
```
apiVersion: v1 
kind: Service 
metadata: 