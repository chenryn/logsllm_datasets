# 测试提交任务

我们将使用自带的示例JAR包来提交一个流式任务进行测试。

1. **在188上启动9009端口并输入一些字符串**
   ![](media/image22.png){width="5.096107830271216in" height="1.88707895888014in"}

2. **在143上提交任务**
   ![](media/image23.png){width="5.768055555555556in" height="0.20902777777777778in"}

3. **在JobManager Web页面查看任务**
   ![](media/image24.png){width="5.768055555555556in" height="1.4590277777777778in"}

4. **点击Job Name查看详细信息**
   ![](media/image25.png){width="5.768055555555556in" height="2.7395833333333335in"}

5. **查看Task结果**
   ![](media/image26.png){width="5.768055555555556in" height="1.8270833333333334in"}

这是一个单词计数的例子。从Task的输出中可以看到结果，也可以通过后台查看`flink-taskexecutor-*.out`文件来获取更多信息。

# 部署数据工厂Fornaxee

## 下载Fornaxee安装包
- **下载链接**:
  - *http://222.128.29.229:9999/hekad/fornaxee/fornaxee-0.0.1-SNAPSHOT.tar.gz*
- **解压安装包**:
  - `tar -zxvf fornaxee-0.0.1-SNAPSHOT.tar.gz -C /opt`

## 数据库初始化
- 建议复用日志易数据库（请将`${MYSQLD_IP}`替换为实际MySQL服务器IP）
  - `mysql -h${MYSQLD_IP} -uroot -p -e 'create database fornaxee'`
  - `mysql -h${MYSQLD_IP} -uroot -pfornaxee < /opt/fornaxee/config/sql/fornaxee.sql`

## 配置文件初始化
- 编辑 `/opt/fornaxee/config/application.properties`
  - `server.port=9082` （Web监听端口默认为9080，可以改为需要的端口）
  - `spring.datasource.url` （修改实际的MySQL服务器IP）
  - `spring.datasource.username` （修改实际的MySQL用户名）
  - `spring.datasource.password` （修改实际的MySQL密码）
  - `fornaxee.flink-cli-path=/opt/flink-1.9.2/bin/flink` （修改实际的Flink命令路径）
  - `fornaxee.job-manager-addr=192.168.1.143:8082` （修改实际的Flink Job Manager地址）

## 启动Fornaxee
- `cd /opt/fornaxee/bin`
- `./start.sh`
  ![](media/image27.png){width="5.768055555555556in" height="0.21597222222222223in"}

## 访问Fornaxee前台
  ![](media/image28.png){width="5.768055555555556in" height="1.2201388888888889in"}

# JobManager HA

作业管理器JobManager协调每个Flink部署组件，负责调度和资源管理。默认情况下，每个Flink集群只有一个独立的JobManager实例，可能会导致单点故障（SPOF）。通过配置JobManager High Availability，可以从JobManager故障中恢复，从而消除SPOF。这里我们采用Zookeeper方案作为Flink JobManager的HA方案。

## 配置修改
- 修改配置文件 `conf/flink-conf.yaml` 中的以下配置项（由于这些节点上的2181端口已被占用，故改为3181）：
  ```yaml
  high-availability: zookeeper
  high-availability.storageDir: file:///tmp/flink/ha/
  high-availability.zookeeper.quorum: 192.168.1.143:3181,192.168.1.188:3181,192.168.1.100:3181
  ```

- 修改 `conf/master` 文件（配置JobManager的IP:Port）
  ```
  192.168.1.143:8084
  192.168.1.100:8084
  192.168.1.188:8084
  ```

- 修改 `conf/zoo.cfg` 文件
  ```
  clientPort=3181
  server.1=192.168.1.143:2888:3888
  server.2=192.168.1.100:2888:3888
  server.3=192.168.1.188:2888:3888
  ```

- 将以上配置文件同步到所有节点。

## 启动Zookeeper集群
- `cd flink-1.9.2/bin; ./start-zookeeper-quorum.sh`
  ![](media/image29.png){width="4.80875in" height="0.5917180664916886in"}
- 此时会在三个节点上启动Zookeeper进程
  ![](media/image30.png){width="5.768055555555556in" height="0.32916666666666666in"}

## 启动Flink集群
- `cd flink-1.9.2/bin`
- `./start-cluster.sh` 后会显示在各节点上启动的JobManager和TaskManager进程
  ![](media/image31.png){width="5.100441819772528in" height="1.0000863954505688in"}
- 查看进程
  ![](media/image32.png){width="5.768055555555556in" height="0.9784722222222222in"}

## 提交测试任务
- 访问Web端口，三台JobManager都可以访问，但实际结果只能在主节点上看到。此时在Fornaxee上提交一个测试任务（Fornaxee配置的Flink地址为100）。
  ![](media/image33.png){width="5.768055555555556in" height="4.821527777777778in"}
- 点击跳转查看任务信息。
  ![](media/image34.png){width="5.768055555555556in" height="2.8333333333333335in"}
- 相关指标都在转圈是看不到实际数据的，因为此时100不是主节点，主节点在143上。在143上则能查看该任务每个阶段的指标数据。
  ![](media/image35.png){width="5.768055555555556in" height="2.8256944444444443in"}
- 把100上的JobManager停掉再次提交任务查看。
  ![](media/image36.png){width="5.768055555555556in" height="0.7340277777777777in"}
  ![](media/image37.png){width="5.768055555555556in" height="4.118055555555555in"}
- 此时100的Web已无法访问，在143和188上则可以看到刚提交的任务。
  ![](media/image38.png){width="5.768055555555556in" height="1.9569444444444444in"}
  ![](media/image39.png){width="5.768055555555556in" height="1.801388888888889in"}
- 在三个节点的情况下，最大容错是1，此时如果再停掉一个节点上的JobManager后任务将无法提交。

# 配置注意事项

## 基础环境
1. 必须要有Java环境（1.8版本及以上）
2. JobManager机器与TaskManager机器间必须配置SSH互信。

## 配置项
- Flink会优先使用`flink-conf.yaml`配置文件，如果配置文件中没有指定，则使用`bin/config.sh`中的配置（与环境变量设置有关）。
- 配置项说明：
  - `jobmanager.rpc.address`：单个JobManager时Web端口的配置（默认为8081）。这个必须配置（无默认值，不配置Task进程起不来）。
  - `rest.port`：优先级从大到小为：`rest.bind-port` > 运行`jobmanager.sh`指定的 > `rest.port` > 默认值。
  - `fornaxee.job-manager-addr`：多个JobManager时，从`conf/masters`中获取的Fornaxee连接Flink的地址，目前只能配置一个。

# 数据工厂（SDC）方案

SDC（StreamSets Data Collector）方案分为日志易Pipeline（需求驱动下，日志易临时使用开源StreamSets封装的数据工厂）及原生StreamSets两种。两种方案的不同仅体现在安装名称的差别上。

## 部署SDC

### 下载安装包
- **日志易Pipeline安装包**:
  - *http://222.128.29.229:9999/2.2.0.0/rzy-pipeline-all-3.5.3-SNAPSHOT.tgz*
- **原生StreamSets安装包**:
  - *https://archives.streamsets.com/datacollector/3.13.0/tarball/streamsets-datacollector-all-3.13.0.tgz*

### 解压缩（可以自行选择创建安装路径）
- `tar -xzvf rzy-pipeline-all-3.5.3-SNAPSHOT.tgz -C /usr/local/`
- `cd /usr/local/streamsets-datacollector-3.5.3-SNAPSHOT`

### 汉化
- 将汉化包`en.json`拷贝到`streamsets-datacollector-3.5.3-SNAPSHOT/sdc-static-web/i18n/`

### 修改配置
- `vim libexec/sdc-env.sh`
  - a. 配置`JAVA_HOME`
  - b. 配置Pipeline的运行信息存储路径`SDC_DATA`（不存在则创建合适路径）
  - c. 配置Pipeline日志路径`SDC_LOG`（可以自己定义合适的路径）
    ![](media/image40.png){width="5.764583333333333in" height="1.2256944444444444in"}
- 注意：以上配置项如果不配置则默认使用程序运行目录，建议配置为不同于程序运行的目录。

### 启动进程
- **日志易的包**:
  - `nohup bin/pipeline dc &`
- **原生SDC包**:
  - `nohup bin/streamsets dc &`

### 验证启动是否成功
- **日志易的包**:
  - *http://ip:13000* 用户名：admin 密码：admin
- **原生包**:
  - *http://ip:18630* 用户名：admin 密码：admin
- 端口可在`sdc.properties`文件中修改（`http.port`）

## 部署注意事项

### 基础环境要求
![](media/image41.png){width="5.5739129483814525in" height="3.789226815398075in"}

### open files的限制
- 默认值为32768。如果启动进程的用户open files小于这个值，则进程启动失败，报错如下：
  ![](media/image42.jpeg){width="5.766666666666667in" height="0.2902777777777778in"}
- 可以通过以下两种方式修改open files：
  - 临时修改：`ulimit -n 50000`
  - 永久修改：在`/etc/security/limits`文件中增加如下配置（rizhiyi为启动进程的用户）
    ```bash
    rizhiyi hard nofile 655350
    rizhiyi soft nofile 655350
    ```
    ![](media/image43.png){width="5.763194444444444in" height="2.09375in"}

# 组件介绍

数据工厂通过管道来描述数据处理流程。管道由数据源（Origins）、处理器（Processors）、目标对象（Destinations）和执行器（Executors）组成。

- **数据源（Origins）**：对应数据来源采集组件，包括数据库、文件、网络、消息队列等种类。
- **处理器（Processors）**：对应数据转换清洗组件，包括编解码、字段解析、转换处理、数据扩充、求值计算、流控、表结构定义等种类。
- **目标对象（Destinations）**：对应数据目的发布组件，包括文件存储、数据库、消息队列、网络、控制处理等种类。