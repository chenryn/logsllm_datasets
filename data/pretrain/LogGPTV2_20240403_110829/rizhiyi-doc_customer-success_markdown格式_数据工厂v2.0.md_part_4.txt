height="2.0446959755030623in"}
#### 测试提交任务
这里我们用自带的例子jar包提交一个流式任务进行测试。
(1)首先，我们在188上启一个9009的端口并输入一些字符串
![](media/image22.png){width="5.096107830271216in"
height="1.88707895888014in"}
(2)在143上提交任务
![](media/image23.png){width="5.768055555555556in"
height="0.20902777777777778in"}
(3)在jobmanager web页面查看任务
![](media/image24.png){width="5.768055555555556in"
height="1.4590277777777778in"}
(4)点击job name可以看到详细信息
![](media/image25.png){width="5.768055555555556in"
height="2.7395833333333335in"}
(5)查看task结果
![](media/image26.png){width="5.768055555555556in"
height="1.8270833333333334in"}
这是一个单词计数的例子。从task的out里可以看到输出结果，也可以在后台通过查看flink\*-taskexecutor\*.out文件查看。
### 部署数据工厂fornaxee
#### 下载fornaxee安装包
> 下载链接：
>
> *http://222.128.29.229:9999/hekad/fornaxee/
> fornaxee-0.0.1-SNAPSHOT.tar.gz*
>
> 解压安装包
>
> *tar -zxvf fornaxee-0.0.1-SNAPSHOT.tar.gz -C /opt*
#### 数据库初始化
> 建议复用日志易数据库
> (下面命令请将\${MYSQLD_IP}替换为实际mysql服务器IP）
>
> *mysql -h\${MYSQLD_IP} -uroot -p -e \'create database fornaxee\'*
>
> *mysql -h\${MYSQLD_IP} -uroot -p fornaxee \ /opt/fornaxee/config/sql/fornaxee.sql*
#### 配置文件初始化
> 编辑/opt/fornaxee/config/application.properties
>
> *server.port=9082 （web监听端口默认为9080，可以改成需要的端口）*
>
> *spring.database.url （修改实际的mysql服务器ip）*
>
> *spring.datasource.username （修改实际的mysql用户名）*
>
> *spring.datasource.password （修改实际的mysql密码)*
>
> *fornaxee.flink-cli-path=/opt/flink-1.9.2/bin/flink
> (修改实际的flink命令路径）*
>
> *fornaxee.job-manager-addr=192.168.1.143:8082 （修改实际的Flink Job
> Manager地址）*
#### 启动fornaxee
> *cd /opt/fornaxee/bin*
>
> *./start.sh*
![](media/image27.png){width="5.768055555555556in"
height="0.21597222222222223in"}
#### 访问fornaxee前台
![](media/image28.png){width="5.768055555555556in"
height="1.2201388888888889in"}
### Jobmanager HA
作业管理器JobManager协调每个Flink部署组件，它负责调度以及资源管理。
默认情况下，每个Flink集群只有一个独立的JobManager实例，因此可能会产生单点故障（SPOF）。使用JobManager
High
Availability，可以从JobManager的故障中恢复，从而消除SPOF。可以为独立（Standalone）集群和YARN集群配置高可用性。
这里我们采用zookeeper方案作为Flink jobmanager的HA方案。
#### 配置修改
修改配置文件conf/flink-conf.yaml中以下配置项：（由于这些节点上2181端口已经被占用故这里改为3181）
  --------------------------------------------------------------------------------------------------------------
  原始值                                              配置值
  --------------------------------------------------- ----------------------------------------------------------
  \# high-availability: zookeeper                     high-availability: zookeeper
  #high-availability.storageDir: hdfs:///flink/ha/    high-availability.storageDir: file:///tmp/flink/ha/
  \#                                                  high-availability.zookeeper.quorum:
  high-availability.zookeeper.quorum:localhost:2181   192.168.1.143:3181,192.168.1.188:3181,192.168.1.100:3181
  --------------------------------------------------------------------------------------------------------------
修改conf/master（配置jobmanager的ip:port）
> *192.168.1.143:8084*
>
> *192.168.1.100:8084*
*192.168.1.188:8084*
配置conf/zoo.cfg
> *\# The port at which the clients will connect*
>
> *clientPort=3181*
>
> *\# ZooKeeper quorum peers*
>
> *server.1=192.168.1.143:2888:3888*
>
> *server.2=192.168.1.100:2888:3888*
>
> *server.3=192.168.1.188:2888:3888*
将以上几个配置文件同步到所有节点。
#### 启动zk集群
> *cd flink-1.9.2/bin;./start-zookeeper-quorum.sh*
![](media/image29.png){width="4.80875in" height="0.5917180664916886in"}
这时会在三个节点上启动zk进程
![](media/image30.png){width="5.768055555555556in"
height="0.32916666666666666in"}
#### 启动flink集群
> *cd flink-1.9.2/bin*
*./start-cluster sh*后会显示在各节点上启动的jobmanager和taskmanager进程
![](media/image31.png){width="5.100441819772528in"
height="1.0000863954505688in"}
查看进程
![](media/image32.png){width="5.768055555555556in"
height="0.9784722222222222in"}
#### 提交测试任务
访问web端口，三台jobmanager都可以访问，但实际结果只能在master上看到。此时在Fornaxee上提交一个测试任务（fornaxee配置的flink地址为100）。
![](media/image33.png){width="5.768055555555556in"
height="4.821527777777778in"}
点击跳转查看任务信息。
![](media/image34.png){width="5.768055555555556in"
height="2.8333333333333335in"}
相关指标都在转圈是看不到实际数据的，因为此时100不是master节点，master节点在143上。在143上则能查看该任务每个阶段的指标数据。
![](media/image35.png){width="5.768055555555556in"
height="2.8256944444444443in"}
把100上的jobmanager停掉再次提交任务查看。
![](media/image36.png){width="5.768055555555556in"
height="0.7340277777777777in"}
![](media/image37.png){width="5.768055555555556in"
height="4.118055555555555in"}
此时100的web已无法访问，在143和188上则可以看到刚提交的任务。
![](media/image38.png){width="5.768055555555556in"
height="1.9569444444444444in"}
![](media/image39.png){width="5.768055555555556in"
height="1.801388888888889in"}
3个节点时，最大容错是1，此时如果再停掉一个节点上的jobmanager后任务将无法提交。
### 配置注意事项
#### 基础环境
1、必须要有java环境（1.8版本及以上）
2、Jobmanager机器与taskmanager机器间必须配置ssh互信。
#### 配置项
Flink会优先使用flink-conf.yaml配置文件，如果配置文件中没指定，会使用bin/config.sh中的配置（跟环境变量设置有关）。
配置项说明：
1、jobmanager.rpc.address指单个jobmanager时web端口的配置（默认为8081）。这个必须配置（无默认值，不配置task进程起不来）。
2、rest.port：优先级从大到小为：【rest.bind-port】\>【运行jobmanager.sh指定的】\>【rest.port】\>【默认值】
3、fornaxee.job-manager-addr：多个jobmanager时，从conf/masters中获取的fornaxee连接Flink的地址，目前只能配置一个。
## 数据工厂（SDC）方案
SDC（Streamsets Data
Collector）方案分为日志易pipline（需求驱动下，日志易临时使用开源StreamSets封装的数据工厂）及原生StreamSets两种。两种方案的不同仅体现在安装名称的差别上。
### 部署SDC
#### 下载安装包
> 安装包下载链接：
>
> \-\--日志易pipeline安装包
>
> [*http://222.128.29.229:9999/2.2.0.0/rzy-pipeline-all-3.5.3-SNAPSHOT.tgz*](http://222.128.29.229:9999/2.2.0.0/rzy-pipeline-all-3.5.3-SNAPSHOT.tgz)
>
> \-\--原生StreamSets安装包
>
> [*https://archives.streamsets.com/datacollector/3.13.0/tarball/streamsets-datacollector-all-3.13.0.tgz*](https://archives.streamsets.com/datacollector/3.13.0/tarball/streamsets-datacollector-all-3.13.0.tgz)
#### 解压缩(可以自行选择创建安装路径)
*tar -xzvf rzy-pipeline-all-3.5.3-SNAPSHOT.tgz -C /usr/local/*
*cd /usr/local/streamsets-datacollector-3.5.3-SNAPSHOT*
#### 汉化
把汉化包en.json 拷贝到
streamsets-datacollector-3.5.3-SNAPSHOT/sdc-static-web/i18n/
#### 修改配置
*vim libexec/sdc-env.sh*
a.配置JAVA_HOME
b.配置pipeline的运行信息存储路径SDC_DATA（不存在则创建合适路径）
c.配置pipeline日志路径SDC_LOG（可以自己定义合适的路径）
![](media/image40.png){width="5.764583333333333in"
height="1.2256944444444444in"}
注意：以上配置项如果不配置则默认使用程序运行目录，这里建议配置为不同于程序运行的目录。
#### 启动进程
\-\--日志易的包
*nohup bin/pipeline dc &*
\-\--原生sdc包
*nohup bin/streamsets dc &*
#### 验证启动是否成功
\-\--日志易的包
*http://ip:13000 用户名：admin 密码：admin*
\-\--原生包
*http://ip:18630 用户名：admin 密码：admin*
端口可在sdc.properties文件中修改（http.port）
### 部署注意事项
部署过程中需注意基础环境要求、open files的限制两点。
1.  基础环境要求
![](media/image41.png){width="5.5739129483814525in"
height="3.789226815398075in"}
2.  open files的限制
默认32768如果启动进程的用户open
files小于这个值则进程启动失败，报错如下：![{5019E470-FDCB-324A-E074-3658A27E1AFC}](media/image42.jpeg){width="5.766666666666667in"
height="0.2902777777777778in"}
可以通过以下两种方式修改open files：
-   临时修改：ulimit -n 50000
-   永久修改：在/etc/security/limits文件中增加如下配置（rizhiyi为启动进程的用户）
*rizhiyi hard nofile 655350*
*rizhiyi soft nofile 655350*
![](media/image43.png){width="5.763194444444444in" height="2.09375in"}
# 组件介绍
数据工厂中通过管道来描述数据处理的流程。管道由数据源（originis）、处理器（processors）、目的对象（destinations）、执行器（executors）组成。
管道的每个对象对应一个组件：
-   数据源（originis）对应数据来源采集组件，包括数据库、文件、网络、消息队列等种类；
-   处理器（processors）对应数据转换清洗组件，包括编解码、字段解析、转换处理、数据扩充、求值计算、流控、表结构定义等种类；
-   目的对象（destinations）对应数据目的发布组件，包括文件存储、数据库、消息队列、网络、控制处理等种类；