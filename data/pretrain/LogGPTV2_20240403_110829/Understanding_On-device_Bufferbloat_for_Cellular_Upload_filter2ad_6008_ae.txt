As described in §4.2, this is attributed to the very nature of
cellular uplink scheduling: the ﬁrmware buffer occupancy
reported in BSR is used for determining uplink bandwidth
allocation; the base station thus regards a small buffer occu-
pancy as an indicator that the client does not have much data
to transmit, thus allocating small uplink bandwidth for the
mobile client.
To overcome the above limitation, we propose another
scheme called QCUT-D (D stands for “delay”). It instead
uses the ﬁrmware queuing delay (TF ) as a threshold. The
queuing delay is computed from the estimated throughput
and the buffer occupancy. If the delay is above the thresh-
old, QCUT-D does not allow a packet to be dequeued to the
ﬁrmware from Qdisc. Thus, QCUT-D is adaptive to diverse
network conditions by dynamically adjusting the ﬁrmware
buffer occupancy. We empirically found that using 20ms
as the delay threshold on LTE networks works reasonably
well in diverse network conditions: it leads to low ﬁrmware
buffer queuing while incurring very small impact on the up-
link throughput, as to be evaluated in §7.2. This threshold
can also be empirically chosen for other types of networks.
Trafﬁc differentiation. To meet the performance require-
ment of different applications, QCUT uses the priority queu-
ing in Linux Qdisc for trafﬁc prioritization. For example,
the background upload and interactive trafﬁc such as web
browsing are put into different queues in Qdisc. As a re-
sult, interactive trafﬁc does not experience high queuing de-
lay in Qdisc caused by bulk upload. Also, thanks to the
aforementioned trafﬁc shaping module in QCUT, the delay-
sensitive trafﬁc also undergoes very low queuing delay in the
ﬁrmware, thus leading to an overall small on-device queuing
delay and thus good user experience. QCUT uses existing
trafﬁc classiﬁcation mechanism on Linux to allow applica-
tions and users to ﬂexibly conﬁgure priorities for different
trafﬁc through the standard tc interface.
6.3 QCUT Implementation
We implemented QCUT on Android Linux kernel. Our
testing devices consist of Samsung Galaxy S3 and Nexus
5 running Android 4.4.4 and 6.0.1 with Qualcomm radio
chipset. We expect QCUT to also work with other phones
and tablets with cellular ﬁrmware from the same vendor.
Note that QCUT does not require any special equipment such
as QXDM [6].
Trafﬁc shaping and differentiation are implemented as a
Linux packet scheduler module in 600 LoC. QCUT keeps
track of transmitted packets from Qdisc since the most re-
cent BSR. The trafﬁc shaping module is implemented in
the function call enqueue() of the Qdisc operation data
structure Qdisc_ops. In enqueue(), the queuing delay in
ﬁrmware is estimated based on the information from the ra-
dio ﬁrmware. More speciﬁcally, we use the /dev/diag in-
terface on the Android phones with Qualcomm radio chipset
to extract the uplink scheduling grant, padding statistics, and
BSR from the logs of LTE uplink transport blocks. The on-
line parsing of the logs is implemented in a C++ program
in the user space. Each log record has a timestamp of the
ﬁrmware. The timestamps between kernel and the ﬁrmware
need to be synchronized. The user-space program sends time
request periodically and uses the response, which contains
the ﬁrmware timestamp, to perform the synchronization.
7. EVALUATION
We comprehensively assess how a wide range of solutions
help mitigate the on-device bufferbloat problem, focusing on
existing solutions (§7.1) and then QCUT (§7.2). For all the
following experiments, we conducted on a Samsung Galaxy
S3 on Carrier 1’s LTE network unless otherwise mentioned.
We expect the experimental ﬁndings to be general as none of
the solutions depends on a speciﬁc carrier or vendor.
7.1 Existing Solutions
We consider existing bufferbloat-mitigation solutions dis-
cussed in §6.1. We demonstrate in this section that they
can reduce excessive on-device queuing to various degrees.
However, they suffer from various limitations, and are all in-
capable of reducing the ﬁrmware buffer occupancy. We con-
duct bulk upload experiments at two locations with different
signal strengths measured by RSRP (Reference Signal Re-
ceived Power): good signal (RSRP of -69 to -75 dBm) and
fair signal (RSRP of -89 to -95), using a Samsung Galaxy S3
on Carrier 1’s LTE network.
Changing TCP buffer sizes. The TCP send buffer
(tcp_wmem) on device imposes a limit on the TCP con-
gestion window (cwnd). As shown in Figure 17, under
good signal, shrinking the send buffer effectively reduces
RT TQ that is dominated by device-side queuing at Qdisc
and ﬁrmware. However, the penalty is severely degraded
upload throughput, in particular when tcp_wmem is smaller
than the bandwidth-delay product (BDP). Since BDP con-
stantly ﬂuctuates in cellular networks [43], a ﬁxed conﬁgu-
ration of TCP buffer size does not ﬁt all network conditions.
Changing TCP small queue (TSQ) size. As a newly in-
troduced Linux kernel patch, TSQ [7] limits per-connection
data in Qdisc using a ﬁxed threshold. By reducing the
threshold, we observe smaller Qdisc queuing delay (TQ =
RT TQ − RT TF in Figure 8) under both network conditions,
as shown in Figure 18. Yet Linux’s default TSQ threshold
is too large to eliminate the Qdisc queuing. However, Fig-
313Figure 17:
Impact of TCP send
buffer sizes on upload performance.
Figure 18: Impact of different TCP
small queue (TSQ) sizes on upload.
Figure 19: Impact of different TCP
CC on upload (with TSQ=128KB).
ure 18 also indicates that TSQ has negligible impact on the
ﬁrmware queuing delay (TF = RT TF − RT TB), because
TSQ only controls the bytes in Qdisc. Further, TSQ lim-
its Qdisc occupancy on a per-connection basis so the Qdisc
occupancy can still be high when concurrent ﬂows exist.
Changing TCP congestion control. Congestion con-
trol (CC) affects the aggressiveness of TCP. We consider
two representative CC categories: loss-based CC (TCP CU-
BIC[19] and Westwood[29]) and delay-based CC (TCP Ve-
gas[12] and LP[24]). Generally speaking, lost-based CC,
which uses packet loss as congestion indicator, is more ag-
gressive than delay-based CC that treats increased delay as
a signal of congestion. We found even with TSQ enabled,
loss-based CC incurs severe on-device queuing, measured
by RT TQ, as shown in Figure 19. For delay-based CC, re-
gardless of TSQ setting, on-device queuing is almost always
negligible. However, such low on-device queuing delays are
achieved by sacriﬁcing up to 80% of the throughput.
Active Queue Management is a major in-network so-
lution to reduce queuing delay and network congestion by
strategically dropping packets in a queue. We considered
two well-known and recently proposed AQM algorithms,
CoDel [30] and PIE [34]. Both approaches use a target
threshold to control the queuing delay. Under both signal
strengths, CoDel effectively keeps the Qdisc queuing delay
below the target threshold. However, Since CoDel does not
apply to the ﬁrmware buffer, it only slightly reduces RT TF
by 10% to 20%, as indicated in Figure 20. This is the re-
sult of TCP cwnd reduction triggered by packet losses in-
jected by CoDel. The performance of PIE is even worse
than CoDel.
Jointly applying multiple strategies. In many case, sev-
eral mitigation strategies can be jointly applied to better
balance various tradeoffs. However, we ﬁnd that jointly
using several approaches may also incur unexpected con-
ﬂicts, causing performance degradation. For example, when
CoDel (with target threshold 5ms) and TSQ (with queue size
4KB) are jointly applied to a single upload ﬂow, RT TF ac-
tually increases by 37% compared to using CoDel alone (ﬁg-
ure not shown). This is explained as follows. A small Qdisc
achieved by TSQ can reduce the effectiveness of CoDel,
since the small on-device queuing delay allows CoDel to
drop very few packets compared to a large queue does. This
causes TCP cwnd to increase faster, leading to more notice-
able in-network queuing delay.
Trafﬁc prioritization. All above solutions focus on re-
ducing on-device queuing for bulk upload. When concur-
rent upload and download exist, an alternative approach is to
prioritize uplink ACK packets over upload data trafﬁc to mit-
igate the impact of upload on download (§5.1). Our experi-
ments indicate that when uplink ACKs are prioritized, their
Qdisc queuing delay is reduced signiﬁcantly from 1363ms
to 86ms at -95dBm. However, prioritization can only be re-
alized at Qdisc, causing the uplink ACK stream still to in-
terfere with uplink data at the ﬁrmware buffer. As a result,
compared to the case where no concurrent upload exists, ap-
plying prioritization still increases RT TF by 112ms. We
will demonstrate in §7.2 that by combining Qdisc prioriti-
zation with ﬁrmware queuing delay reduction, QCUT can
effectively mitigate on-device bufferbloat.
7.2 Evaluation of QCut
We conduct a thorough evaluation of QCUT to demon-
strate that it outperforms existing solutions. First, we show
QCUT can signiﬁcantly reduce RT TF that mainly consists
of the ﬁrmware queuing delay. We then conduct a crowd-
sourced user study to assess the effectiveness of QCUT un-
der real workload (web browsing and video streaming) when
bulk upload is present.
Reducing excessive ﬁrmware queuing. Using the work-
load of a single TCP upload, we compare the performance
of ﬁve schemes: TCP CUBIC, TCP Vegas, TSQ, CoDel, and
QCUT. Each experiment thus consists of ﬁve back-to-back
TCP uploads (one minute each) using Carrier 1’s LTE net-
work. We repeat the experiment for 10 times at two loca-
tions with stable signal strength of -95dBm and -110dBm,
respectively. We calculate the throughput every 500ms and
measure RT TF using tcpdump traces. For each scheme, we
report the average result at each location.
Since the ﬁve schemes achieve different tradeoffs between
throughput and latency, we visualize the results on a two-
dimensional plane in Figure 21. The X and Y axes cor-
respond to RT TF and measured throughput, respectively.
A good solution should appear in the upper-right corner of
the plane. The results indicate that except for QCUT and
TCP Vegas, none of the ﬁve solutions is capable of reduc-
 0 0.5 1 1.5 2 2.5default(1192)166425610243072 0 2 4 6 8 10Y1: RTT (s)Y2: Upload throughput(Mbps)Device-side TCP write buffer limit (KB)RTTQ (Y1)Throughput (Y2) 0 0.5 1 1.5 22832128(default)512Delay (s)TSQ size (KB)TQ / GoodTQ / FairRTTF / GoodRTTF / Fair 0 0.2 0.4 0.6 0.8 1 1.2 1.4CubicWestwoodVegasLP 0 2 4 6 8 10 12 14Y1: RTT (s)Y2: Upload throughput(Mbps)RTTQ / Good (Y1)RTTQ / Fair (Y1)Throughput / Good (Y2)Throughput / Fair (Y2)314(a) Signal Strength -110dBm
(b) Signal Strength -95dBm
Figure 20: Effectiveness of CoDel
on reducing latency.
Figure 21: Compare TCP upload performance of different schemes.
(a) Web browsing
(b) Video streaming: initial loading time
(c) Video streaming: bitrate
Figure 22: Improvement of application performance brought by QCUT.
ing RT TF because they do not work at the ﬁrmware layer.
For TCP Vegas, in Figure 21(b), it achieves low latency at
the cost of very low throughput, with the reason explained
in §7.1. On the other hand, QCUT effectively reduces the
ﬁrmware queuing with little or small sacriﬁce of the through-
put. Recall in §6.2 that we devised two QCUT schemes:
QCUT-B and QCUT-D, which use the ﬁrmware buffer occu-
pancy and delay as the threshold to limit the ﬁrmware buffer
occupancy. We found QCUT-D works reasonably well at
both locations since it is adaptive to different throughput,
while it is a bit difﬁcult to pick a ﬁxed threshold for QCUT-
B for different throughput.
Improving application performance. To assess how
QCUT improves real applications’ performance, we de-
ployed QCUT on ﬁve Samsung Galaxy S3 phones used by
real users. The phones run crowd-sourced measurements
supported by Mobilyzer[33] for a week under diverse net-
work conditions. This user study has been approved by IRB.
We consider two workloads: (1) load ﬁve popular web-
pages, and (2) stream a 2-min YouTube video. For each
workload, we run back-to-back measurements under four
different settings: (i) no background upload, (ii) concurrent
upload without bufferbloat mitigation, (iii) concurrent up-
load with CoDel on Qdisc, and (iv) concurrent upload with
QCUT-D. For web browsing, we collect the page load time
(PLT) of each webpage; for video streaming, we record ini-
tial loading time, playback bitrate and rebuffering events.
Note we only triggered these measurements when the phone
is idle, so the experiment is not interfered with other user
trafﬁc. To mitigate the impact of the varying signal strength
within the same experiment that consists of four back-to-
back measurements, we discard the entire experiment if the
LTE RSRP changes by more than 4dBm. Overall we con-
ducted 1266 and 549 successful experiments for web brows-
ing and video streaming, respectively.
The results are shown in Figure 22.
In each plot, we
show two groups of results corresponding to weak signal
strength (LTE RSRP<-99dBm) and strong signal strength
(LTE RSRP≥-99dBm), respectively. As shown in Fig-
ure 22(a), due to concurrent upload, the median PLT across 5
sites increases by 78% and 159% for strong and weak signal
strength, respectively, leading to signiﬁcantly degraded user
QoE. Applying CoDel does not help mitigate the additional
ACK delay (of webpage download) incurred by the bulk up-
load, in particular when the signal strength is weak: the me-
dian PLT increases are still as large as 75% and 171% for
strong and weak signal strength, respectively, compared to
the no-upload cases. QCUT-D, on the other hand, effectively
reduces the PLT to the baseline (i.e., no-upload). For video
streaming, we consider two QoE metrics: initial buffering