### 4.3 Extended Detection Rounds for Trinocular

In some instances, Trinocular may require more than 18 rounds to detect large changes in \(\hat{A}\) due to the system's cautious approach in determining whether a block is down. The light green solid line in the middle of Fig. 5 illustrates the duration of full rounds for outages that pass the Full Block Scanning (FBS) process. Out of 5.1 million events, 60% are approved within less than one hour (five or fewer Time Ranges, TRs). Approximately 8% of events take longer than the expected maximum of 18 TRs. Upon closer examination, these cases occur when Trinocular is highly confident that the block should be up and does not perform all 15 probing attempts. This result was confirmed by analyzing 50 random blocks from the tail of the distribution.

### 4.4 Impact of FBS on Historical Data

Using FBS on historical Trinocular data requires the 2FR variant, which involves more TRs per Full Round (see Sect. 3.1). The dashed lines in Fig. 5 depict the 2FR analysis. The temporal precision of repaired events remains nearly unchanged, as indicated by the overlapping ranges of the solid and dashed red lines. However, accepted outages take approximately twice as long with 2FR FBS, and the number of accepted down events decreases to about half (3.1 million). Fortunately, only 0.13% of the 4 million blocks in 2017q4 required 2FR and had actual outages.

Currently, FBS is used in batch processing, but we plan to implement it in our near-real-time (NRT) outage pipeline soon. For NRT processing, one can either delay results while FBS is considered or report preliminary results and update them if FBS corrects the initial findings.

### 4.5 Increasing Coverage

Sparse blocks pose a significant challenge to coverage. If historical data suggests a block is sparse, it may be discarded from probing as untrackable. Blocks that become sparse during measurement can create false outages and are discarded during post-processing. We will now show how FBS and Lone Address Block Recovery (LABR) can increase coverage by correctly handling sparse blocks.

#### Correctly Tracking Sparse Blocks

We first examine how the accuracy improvements provided by our algorithms increase coverage. Three thresholds have been used to identify and discard sparse blocks: low response probability (\(A < 0.2\), quarter average, from [12]), low uptime (uptime < 0.8, from [13]), and a high number of down events (5 or more down events, from [14]).

Applying these three thresholds to one quarter of Trinocular data (2017q4-A30W), we report the coverage with each filter in Table 4. Out of 5.9 million responsible blocks, only 4 million (67%) are considered trackable by Trinocular. Filtering removes an additional 0.2 million to 0.9 million blocks, leaving an average of 53% to 64%.

Trinocular with FBS achieves greater coverage than other methods of filtering or detection. FBS repairs 1.2 million blocks, most of which are sparse. Of the 0.9 million sparse blocks, FBS fixes 0.8 million. The remaining 100,000 blocks correspond to either good blocks that went dark due to usage changes, pushing the quarterly average of \(A\) down, or sparse blocks with few active addresses (e.g., \(|E(b)| < 100\)) where Trinocular can make better inferences about the correct state.

#### Can FBS+LABR Expand Baseline Coverage?

Finally, we examine the number of blocks discarded as untrackable from historical data and not tracked for outages. For instance, Trinocular looks at the last 16 surveys [7] and filters all blocks with \(|E(b)| < 15\) and \(A < 0.1\), resulting in a baseline of 4 million blocks. Using the 2017-04-27 survey as an upper bound for the responsive Internet [8], we find 5.9 million responsive blocks, of which 5.7 million had at least three active addresses during the measured period. This represents 1.7 million (43%) more blocks than the baseline, making them trackable. Adding the 1.7 million newly trackable blocks to the 1.2 million FBS-repaired blocks, our effective coverage increases by 2.9 million blocks.

### 5 Related Work

Several groups have developed methods to detect outages at the edge of the Internet. ThunderPing was one of the first to use active measurements to track weather-related outages [11, 15]. Dainotti et al. use passive observations at network telescopes to detect disasters and government censorship [4], providing the first view into firewalled networks. Chocolatine provides the first published algorithm using passive network telescope data [6], with a 5-minute detection delay, but it requires AS or country-level granularity and much more data than /24s. Trinocular uses active probes to study about 4 million /24-block level outages every 11 minutes, the largest active coverage [12]. Disco observes connectivity from devices at home [16], providing strong ground truth but limited coverage. Richter et al. detect outages lasting at least one hour using CDN traffic, confirming with software at the edge [14]. They define disruptions, showing renumbering and frequent disagreements in a few blocks are false down events in prior work. Recent work has also looked at dynamic addressing, a source of sparsity [10]. Our work builds on prior active probing systems and the Trinocular data and algorithms, addressing problems identified by Richter, ultimately due to sparsity and dynamics.

### 6 Conclusions

This paper introduces two algorithms: Full Block Scanning (FBS) to address false outages seen in active measurements of sparse blocks, and Lone Address Block Recovery (LABR) to handle blocks with one or two responsive addresses. These algorithms increase coverage from a nominal 67% (and as low as 53% after filtering) of responsive blocks to 5.7 million blocks, representing 96% of responsive blocks. We demonstrated the effectiveness of these algorithms using multiple datasets and natural experiments, showing they can improve existing and future outage datasets.

### Acknowledgments

We thank Yuri Pradkin for his input on the algorithms and the paper. We also thank Philipp Richter and Arthur Berger for discussions about their work, and Philipp for re-running his comparison with CDN data.

This work is supported in part by the National Science Foundation, CISE Directorate, award CNS-1806785; by the Department of Homeland Security (DHS) Science and Technology Directorate, Cyber Security Division (DHS S&T/CSD) via contract number 70RSAT18CB0000014; and by Air Force Research Laboratory under agreement number FA8750-18-2-0280. The U.S. Government is authorized to reproduce and distribute reprints for governmental purposes notwithstanding any copyright notation thereon.

### A Other Block Examples

Section 2.1 described the problem of sparse blocks and why FBS is needed. Here, we provide examples of other blocks where sparsity changes to illustrate when FBS is required.

The block in the left part of Fig. 6 shows no activity for three weeks, then sparse use for a week, followed by moderate use, and back to sparse use for the last two weeks. Reverse DNS suggests this block uses DHCP, and gradual changes in use suggest the ISP is migrating users. The block was provably reachable after the first three weeks. Before then, it may have been reachable but unused, leading to a false outage because the block was inactive.

The third bar from the top (c) of the left part of Fig. 6 shows that Trinocular often marks the block as unknown (in red) for the week starting 2017-10-30 and again for weeks after 2017-12-12. Every address in this block has responded in the past, but for these two periods, only a few are actually used, making the block temporarily sparse. Figure 6 (left, bar b) shows how FBS accurately fixes Trinocular's pitfalls in such a DHCP scenario.

Figure 6 (right) shows a block example with a lone address. This block has three phases of use: before 2017-02-16, many addresses are in use; then for about nine days, nothing replies; and starting on 2017-02-25, only the .1 address responds. During the last phase, Trinocular (Fig. 6, right, bar c) completely ignores the single responding address, while FBS (Fig. 6, right, bar b) sets the block status based on the responses of this lone address. However, LABR (Fig. 6, right, bar a) changes all the FBS-detected down events to unknown, as there is insufficient information to claim a down event, in contrast to what the end of phase one shows.

### B Block Usage Change

As mentioned in Sect. 2.1, when blocks become temporarily sparse (showing a small \(A(E(b))\)), the number of false outages increases. Conversely, denser blocks offer higher inference correctness.

Our prior work dynamically estimated \(A\) [13], but Richter et al. showed that block usage can change dramatically, so blocks can become overly sparse even with tracking [14].

In Fig. 7 (left), we compare the number of outages in all 4 million responsive blocks with their measured \(A(E(b))\) value during 2017q4. Blocks with a higher number of outages tend to have a lower \(A(E(b))\) value, particularly those closer to the lower bound. Trinocular does not track blocks with long-term \(A(E(B)) < 0.1\); however, as block sparseness changes, this value can vary during the measurement period.

The correlation between sparse blocks and frequent outage events is clearer in the cumulative distribution function. Figure 7 (right) shows the cumulative distribution of \(A\) for all 4 million responsive blocks (light green, the lower line) and for blocks with 10 or more down events (the red, upper line) as measured during 2017q4. These lines are after merging observations from six Trinocular vantage points. We find that 80% of blocks with 10 or more down events have an \(A < 0.2\), around the knee of the curve, and yet these sparse blocks represent only 22% of all blocks. The figure suggests a correlation between a high number of down events and low \(A(E(b))\) per block due to the faster convergence of the line representing blocks with multiple down events. (It confirms the heuristic of "more than 5 events" used to filter sparse Trinocular blocks in the 2017 CDN comparison [14].)

Although we observe from multiple locations, merging results from different vantage points is not sufficient to deal with sparse blocks, as these multiple sites face the same problem of sparseness leading to inconsistent results. Addressing this problem is a goal of FBS, and it also allows us to grow coverage.

### C Comparing Trinocular and FBS

In Sect. 4.2, we discussed how often FBS changes outages compared to Trinocular. We examined two different metrics: total block downtime and the number of down events. Here, we provide further information on the distribution of these metrics.

In Fig. 8 (left), we show the block distribution of Trinocular and FBS downtime fraction differences. The majority of blocks (91%) have little or no change. Blocks on the left side of the figure, representing 9% of the total, have a higher downtime fraction when processed only with Trinocular than when processed with FBS. For example, a -1 indicates a block that was down for Trinocular during the entire quarter, while FBS was able to completely recover it. This outcome occurs when a historically high \(|E(b)|\) block has temporarily dropped to just a few stable addresses.

We also see a small percentage (0.5%) where FBS has a higher downtime fraction than Trinocular. This increase in outages fraction happens when Trinocular erroneously marks a block as UP. With more information, FBS is able to correctly change the block state and more accurately reflect the truth.

In Fig. 8 (right), we look at the distribution of blocks when compared by the number of down events observed in FBS and Trinocular. Similarly, the number of down events remains mostly unchanged for the majority of blocks (94%). Trinocular has more down events for 6% of blocks, and FBS shows more events for 0.1%. FBS can increase the absolute number of events in a block by breaking long events into shorter pieces.

### References

1. IODA: Internet outage detection & analysis. https://ioda.caida.org
2. Baltra, G., Heidemann, J.: Improving the optics of active outage detection (extended). Technical report ISI-TR-733, May 2019. https://www.isi.edu/%7ejohnh/PAPERS/Baltra19a.html
3. Dainotti, A., et al.: Lost in space: improving inference of IPv4 address space utilization. IEEE J. Sel. Areas Commun. (JSAC) 34(6), 1862–1876 (2016)
4. Dainotti, A., et al.: Analysis of country-wide Internet outages caused by censorship. In: Proceedings of the ACM Internet Measurement Conference, Berlin, Germany, pp. 1–18. ACM, November 2011. https://doi.org/10.1145/2068816.2068818
5. Madory, D.: Iraq downs internet to combat cheating...again! (2017). https://dyn.com/blog/iraq-downs-internet-to-combat-cheating-again/. Accessed 01 Aug 2019
6. Guillot, A., et al.: Chocolatine: outage detection for internet background radiation. In: Proceedings of the IFIP International Workshop on Traffic Monitoring and Analysis. IFIP, Paris, France, June 2019. https://clarinet.u-strasbg.fr/∼pelsser/publications/Guillot-chocolatine-TMA2019.pdf
7. Heidemann, J., Pradkin, Y., Govindan, R., Papadopoulos, C., Bartlett, G., Bannister, J.: Census and survey of the visible Internet. In: Proceedings of the ACM Internet Measurement Conference, Vouliagmeni, Greece, pp. 169–182. ACM, October 2008. https://doi.org/10.1145/1452520.1452542
8. Internet Addresses Survey dataset, PREDICT ID: USC-LANDER/internet-address-survey-reprobing-it75w-20170427
9. MaxMind: GeoIP Geolocation Products (2017). http://www.maxmind.com/en/city
10. Padmanabhan, R., Dhamdhere, A., Aben, E., Claffy, K.C., Spring, N.: Reasons dynamic addresses change. In: Proceedings of the ACM Internet Measurement Conference, Santa Monica, CA, USA. ACM, November 2016. https://doi.org/10.1145/2987443.2987461
11. Padmanabhan, R., Schulman, A., Levin, D., Spring, N.: Residential links under the weather. In: Proceedings of the ACM Special Interest Group on Data Communication, pp. 145–158. ACM (2019)
12. Quan, L., Heidemann, J., Pradkin, Y.: Trinocular: understanding Internet reliability through adaptive probing. In: Proceedings of the ACM SIGCOMM Conference, Hong Kong, China, pp. 255–266. ACM, August 2013. https://doi.org/10.1145/2486001.2486017
13. Quan, L., Heidemann, J., Pradkin, Y.: When the Internet sleeps: correlating diurnal networks with external factors. In: Proceedings of the ACM Internet Measurement Conference, Vancouver, BC, Canada, pp. 87–100. ACM, November 2014. https://doi.org/10.1145/2663716.2663721
14. Richter, P., Padmanabhan, R., Spring, N., Berger, A., Clark, D.: Advancing the art of Internet edge outage detection. In: Proceedings of the ACM Internet Measurement Conference, Boston, Massachusetts, USA. ACM, October 2018. https://doi.org/10.1145/3278532.3278563
15. Schulman, A., Spring, N.: Pingin' in the rain. In: Proceedings of the ACM Internet Measurement Conference, Berlin, Germany, pp. 19–25. ACM, November 2011. https://doi.org/10.1145/2068816.2068819
16. Shah, A., Fontugne, R., Aben, E., Pelsser, C., Bush, R.: Disco: fast, good, and cheap outage detection. In: Proceedings of the IEEE International Conference on Traffic Monitoring and Analysis, Dublin, Ireland, pp. 1–9. IEEE, June 2017. https://doi.org/10.23919/TMA.2017.8002902
17. USC/ISI ANT Project. https://ant.isi.edu/datasets/outage/index.html