title:Intransitive Non-Interference for Cryptographic Purpose
author:Michael Backes and
Birgit Pfitzmann
Intransitive Non-Interference for Cryptographic Purposes
Michael Backes
Birgit Pﬁtzmann
IBM Zurich Research Laboratory
IBM Zurich Research Laboratory
R¨uschlikon, Switzerland
PI:EMAIL
R¨uschlikon, Switzerland
PI:EMAIL
Abstract
Information ﬂow and non-interference have recently
become very popular concepts for expressing both in-
tegrity and privacy properties. Because of the enormous
potential of transmitting information using probabilis-
tic methods of cryptography, interest arose in capturing
probabilistic non-interference. We investigate the no-
tion of intransitive probabilistic non-interference in re-
active systems, i.e., downgrading of probabilistic infor-
mation and detection of probabilistic information ﬂow
by one or more involved third parties. Based on concrete
examples, we derive several deﬁnitions that comprise
cryptography-related details like error probabilities and
computational restrictions. This makes the deﬁnitions
applicable to systems involving real cryptography. De-
tection of probabilistic information ﬂow is signiﬁcantly
more complicated to deﬁne if several third parties are
involved because of the possibilities of secret sharing.
We solve this problem by graph-theoretic techniques.
1 Introduction
Information ﬂow and in particular non-interference
have become powerful possibilities for expressing both
privacy and integrity requirements. Mainly, deﬁnitions
for non-interference can be categorized by two aspects.
The ﬁrst aspect is the complexity-theoretic background
addressed, i.e., whether we consider non-deterministic
behavior (also called possibilistic), or the more ﬁne-
grained probabilistic ﬂow of information. The second
aspect is the particular point of view of what should be
regarded as non-interference. Early deﬁnitions of non-
interference were always based on transitive ﬂow poli-
cies, i.e., they follow the intuition that if a user shall
not be able to inﬂuence another user directly, it shall
also not be able to inﬂuence it by involving additional
users, called third parties. However, the use of such poli-
cies has been quite limited in practice, as important con-
cepts like information ﬁlters, channel control, or explicit
downgrading cannot be captured. Therefore the notion
of intransitive non-interference arose to deal with these
issues.
We present the ﬁrst deﬁnitions for intransitive prob-
abilistic non-interference. Our deﬁnitions are very gen-
eral in several ways: They are designed for reactive sce-
narios. We do not only consider perfect non-interference
as in Gray’s commonly accepted deﬁnition of proba-
bilistic non-interference (which is restricted to transitive
ﬂow policies), but we further allow error probabilities.
Further, our deﬁnitions comprise complexity-theoretic
reasoning like polynomially bounded adversaries. Be-
cause of the last two points, we are conﬁdent that this
work is a major step in relating cryptography to the no-
tion of information ﬂow.
Compared with prior deﬁnitions handling intransitive
ﬂow policies (for a non-probabilistic deﬁnition of ﬂow),
probabilistic behaviors are much more difﬁcult to cap-
ture because two pieces carrying absolutely no infor-
mation about a secret in the probabilistic sense, might
reveal the entire secret when joint. This causes severe
problems if multiple third parties are involved as the se-
cret might be sent via different parties using this concept
of secret sharing. Dealing with aspects of this kind is the
topic of this work.
Outline. We start with a brief overview of the underly-
ing model of asynchronous reactive systems, and intro-
duce ﬂow policies as the formal concept of expressing
information ﬂow, along with motivation for intransitive
ﬂow policies (Section 2). Our main contributions are
novel deﬁnitions, which can cope with intransitive poli-
cies for a probabilistic deﬁnition of information ﬂow,
even in the presence of cryptographic techniques (Sec-
tion 3). Relating an intransitive notion of ﬂow and cryp-
Proceedings of the 2003 IEEE Symposium on Security and Privacy (SP(cid:146)03) 
1081-6011/03 $17.00 ' 2003 IEEE 
tography (even more generally, probabilism) was out of
scope of prior approaches. As the most common ap-
plication of intransitive ﬂow policies, we show in Sec-
tion 4 how probabilistic downgrading can be captured
using our ideas of the previous section. Moreover, we
show that our deﬁnitions are preserved under simulata-
bility, which is a common concept in cryptography (Sec-
tion 5). This signiﬁcantly simpliﬁes the proof that a sys-
tem fulﬁlls a non-interference property, since simulata-
bility helps to get rid of cryptography-related details like
error probabilities and computational restrictions. We
show this for an example in Section 6. We conclude this
article by discussing related work (Section 7) and sum-
marizing our results (Section 8).
2 Preliminary Deﬁnitions and Ideas
In this section, we give an introduction to informa-
tion ﬂow in general, before we turn our attention to in-
transitive ﬂow in subsequent sections.
In Section 2.1
we brieﬂy introduce the model for asynchronous reac-
tive systems on which we base our deﬁnitions of non-
interference.
In Section 2.2 we introduce ﬂow poli-
cies and brieﬂy review the deﬁnition of computational
probabilistic non-interference for transitive ﬂow poli-
cies [2], which serves as the foundation of our up-
coming deﬁnitions. The problem of probabilistic non-
interference with intransitive ﬂow policies is addressed
in Section 2.3.
2.1 General System Model for Reactive Sys-
tems
In this section we brieﬂy recapitulate the model
for probabilistic reactive systems in asynchronous net-
works, including computational aspects as needed for
cryptography, from [21]. All details of the model which
are not necessary for understanding are omitted; they
can be looked up in the original paper.
Usually one considers real systems consisting of a
set ˆM of machines {M1, . . . , Mn}, one for each user.
The machine model is probabilistic state-transition ma-
chines, similar to I/O automata as introduced in [12].
For complexity every automaton is considered to be im-
plemented as a probabilistic Turing machine; complex-
ity is measured in the length of its initial state, i.e., the
initial worktape content (often a security parameter k,
given in unary representation).
Communication between different machines is done
via ports. Similar to the CSP-Notation [8], output and
input ports are written as p! and p?, respectively. The
ports of a machine M are denoted by ports(M). Connec-
tions are deﬁned implicitly by naming convention, i.e.,
port p! sends messages to p?. To achieve asynchronous
timing, a message is not sent directly to its recipient, but
ﬁrst stored in a special machine (cid:1)p called a buffer and
waits to be scheduled. If a machine wants to schedule
the i-th message held in (cid:1)p, it must have the correspond-
ing clock-out port p(cid:2)!, and it sends i at p(cid:2)!. The i-th
message is then forwarded by the buffer and removed
from the buffer’s internal list. Most buffers are either
scheduled by a speciﬁc master scheduler or the adver-
sary, i.e., one of those has the corresponding clock-out
port.
Formally, a structure is a pair ( ˆM , S ), where ˆM is
a ﬁnite set of machines with pairwise different machine
names and disjoint sets of ports, and S ⊆ free( ˆM ), the
so-called speciﬁed ports, are a subset of the free ports of
ˆM .1 Roughly speaking the ports of S guarantee certain
services to the users. A structure is completed to a con-
ﬁguration by adding a set of machines U and a machine
A, modeling users and the adversary. The machines in U
connect to the speciﬁed ports S , while A connects to the
remaining free ports ¯S of the structure and can interact
with the honest users.
Scheduling of machines is done sequentially, so there
is exactly one active machine M at any time. If this ma-
chine has clock-out ports, it can select the next message
to be scheduled as explained above. If that message ex-
ists, it is delivered by the buffer and the unique receiv-
ing machine is the next active machine. If M tries to
schedule multiple messages, only one is taken, and if it
schedules none or the message does not exist, the special
master scheduler is scheduled.
This means that a conﬁguration has a well-deﬁned
notion of runs, also called traces or executions. For-
mally a run is essentially a sequence of steps, and each
step is a tuple of the name of the active machine in this
step and its input, output, and old and new local state. As
the underlying state-transition functions of the individ-
ual machines are probabilistic, we also get a probability
space on the possible runs. We call it run conf ,k for a
conﬁguration conf and the security parameter k.
One can restrict a run r to a machine M or a set of
machines ˆM by retaining only the steps of these ma-
chines; this is called the view of these machines. Simi-
larly, one can restrict a run to a set S of ports by retain-
ing only the in- or outputs at the chosen ports from the
steps where such in- or outputs occur. This is denoted
by r(cid:5)M and r(cid:5) ˆM and r(cid:5)S, respectively. For a conﬁgu-
ration conf , we obtain corresponding random variables
over the probability space of all possible runs; for the
1A port is free if its corresponding port is not in the system. These
ports are available for the users and the adversary. By free( ˆM ) we
abbreviate the precise notation free([ ˆM ]) from [21], which indicates
that the free ports are taken at the other end of the buffers.
Proceedings of the 2003 IEEE Symposium on Security and Privacy (SP(cid:146)03) 
1081-6011/03 $17.00 ' 2003 IEEE 
view of a machine or machine set they are denoted by
view conf ,k(M) and view conf ,k( ˆM ), respectively.
2.2 Flow Policies
Flow policies specify restrictions on the information
ﬂow within a system. They presuppose the existence
of security domains S, between which information ﬂow
should either be permissible or forbidden.
Deﬁnition 2.1 (General Flow Policy) A general ﬂow
policy is a graph G = (S,E) with a non-empty set S
and E ⊆ S × S. For (s1, s2) ∈ E, we write s1 ❀ s2,
and s1 (cid:10)❀ s2 otherwise. Furthermore we demand s ❀ s
for all s ∈ S.
✸
Here s1 ❀ s2 means that information may ﬂow from
s1 to s2, whereas s1 (cid:10)❀ s2 means that it must not. If
we want to use a general ﬂow policy for our purpose,
we have to reﬁne it so that it can be applied to a struc-
ture ( ˆM , S ) of the underlying model. The intuition is
to deﬁne a graph on the possible protocol participants,
i.e., the users and the adversary. However, to be inde-
pendent of the details of the actual user and adversary
machines, we represent users by the ports they connect
to in the structure ( ˆM , S ), and the adversary by the re-
maining free ports of the structure. Thus our ﬂow policy
only depends on the speciﬁed ports S .
Deﬁnition 2.2 (Flow Policy) Let a structure ( ˆM , S ) be
given, and let Γ( ˆM ,S ) = {Si | i ∈ I} denote a partition
of S for a ﬁnite index set I. Hence ∆( ˆM ,S ) := Γ( ˆM ,S )∪
{¯S} is a partition of free( ˆM ). A ﬂow policy G( ˆM ,S ) of
the structure ( ˆM , S ) is now deﬁned as a general ﬂow
policy G( ˆM ,S ) = (∆( ˆM ,S ),E( ˆM ,S )).
✸
We write G, ∆, and E instead of G( ˆM ,S ), ∆( ˆM ,S ), and
E( ˆM ,S ) if the underlying structure is clear from the con-
text.
The relation (cid:10)❀ is the non-interference relation of
G. Hence SH (cid:10)❀ SL for two port sets SH, SL ∈ ∆
means that no information must ﬂow from the user con-
nected to the ports SH to the user connected to the ports
SL. For transitive ﬂow policies, we recently introduced
a probabilistic deﬁnition suited for cryptographic pur-
poses (i.e., comprising computational restrictions, error
probabilities, etc.)
in [2]. Roughly, if we consider a
non-interference requirement SH (cid:10)❀ SL, then the user H
(which is connected to SH by naming convention, using
the notation of [2]) gets a randomly distributed bit b at
the start of the run and should try to transmit this bit to
L (connected to SL). The user L then outputs a bit b
, its
guess of the bit b. To model this, the distinguished users
have special ports for receiving the initial bit and for
∗
Proceedings of the 2003 IEEE Symposium on Security and Privacy (SP(cid:146)03) 
1081-6011/03 $17.00 ' 2003 IEEE 
H
L
/
T
Figure 1. Standard intransitive ﬂow policy,
consisting of three users H, L and T
∗
outputting their guess, respectively. Formally, to close
the conﬁguration, special machines are added that pro-
at ports pH bit! and
duce the bit b and consume the bit b
p∗
L bit?, respectively, connected to the special ports of the
users H and L. Moreover, a speciﬁc fair master sched-
uler is added to the conﬁguration because if the adver-
sary were allowed to schedule it could always achieve
probabilistic information ﬂow. The resulting conﬁgura-
tions are called non-interference conﬁgurations for SH
and SL and typically denoted by conf n in
H,L . We call the
set of them Confn in
Then the underlying structure is deﬁned to fulﬁll the
non-interference requirement SH (cid:10)❀ SL in the compu-
tational sense iff for all non-interference conﬁgurations
∗
for SH and SL, the probability of a correct guess b = b
is only negligibly greater than pure guessing; see [2] for
a rigorous deﬁnition, also of a perfect and a statistical
case. For readability, we identify users and the speciﬁed
ports they connect to, i.e., we might write H (cid:10)❀ L instead
of SH (cid:10)❀ SL etc. in the following.
H,L,I( ˆM , S ).2
2.3 The Problem with Intransitive Flow Poli-
cies
For intransitive ﬂow policies, however, the deﬁnition
sketched in Section 2.2 is meaningless. Consider the
ﬂow policy shown in Figure 1, which can be seen as the
standard ﬂow policy for intransitive information ﬂow.
Obviously, the non-interference relation H (cid:10)❀ L can-
not be achieved according to the above deﬁnition if in-
formation ﬂow from H to L is possible via T. Although
these kinds of policies do not match our intuition of a
satisﬁable ﬂow policy at ﬁrst glance, they can be inter-
preted as conditional information ﬂow capturing lots of
typical situations in real life. For instance consider a
user that wants to send certain documents to the printer.
Assume that the system administrator has set up some
nice predeﬁned functions for printing documents, aug-
menting them with special company-related frames, or
some internal handling of possible errors. Then a typical