0.50 ± 0.55
0.47 ± 0.46
CopyGen
Overhead −6.14%
Original
Modiﬁed
Overhead
0.57 ± 0.56
0.63 ± 0.76
11.19%
(sec)
9.81 ± 4.25
9.92 ± 4.29
1.12%
1.82 ± 1.08
1.83 ± 1.08
0.54%
Exec Time
(sec)
5.50 ± 0.12
5.60 ± 0.12
1.72%
7.19 ± 0.11
7.21 ± 0.24
0.20%
Total Time Major
(sec)
15.81 ± 4.81
15.99 ± 4.78
1.24%
9.58 ± 1.43
9.66 ± 1.61
0.83%
Collects
7.58 ± 0.76
7.60 ± 0.76
–
0.03 ± 0.18†
0.03 ± 0.18†
–
Minor
Collects
–
–
–
13.63 ± 0.26
13.63 ± 0.26
–
Table 1. Mean run-time and standard deviation for the multitasking microbenchmark, across 58 runs
of the benchmark, varying the number of concurrent tasks. The benchmark is run against two
garbage collectors (“semispace” – a two-space copying collector, and “copyGen” – a generational
collector) in two conﬁgurations (“original” – the unmodiﬁed RVM garbage collector and “modiﬁed” –
adding our GC memory accounting patches). “Load time” includes the class loading and accounting
system setup. “GC time” includes time spent in the GC itself, “Exec time” is the CPU time spent
directly by the benchmark, and “Total time” is the sum of these components. “Major” and “Minor”
are the average number of times the garbage collector was invoked during the benchmark runs.
†Of the 58 benchmark runs, there was no major collection in 56 of the runs, and exactly one major collection in the
remaining two.
ten, if at all, most likely because our benchmark is keeping
relatively little data live over long periods of time, forcing
any memory accounting policy to rely on data collected dur-
ing the minor collectors for its policy decisions. Section 4
discusses this in more detail.
4 Discussion
The system described so far provides primitives for mea-
suring memory being held live by various tasks in the run-
time. These measurements, by themselves, do nothing; a
policy engine that queries them is needed to place resource
usage restrictions on tasks that are misbehaving. It’s im-
portant that these policies be written with an awareness of
what has actually been measured by the annotated garbage
collector.
As discussed in Section 2.3.1, the usage values for a task
measure two different statistics: a high-water mark, indicat-
ing how much memory that task is using, including mem-
ory it shares with other tasks, and a low-water mark that
accounts for the memory used by that task alone. An intel-
ligent policy would consider both of these values. It should
be noted that these values may not reﬂect the most current
state of how tasks are consuming memory. Tasks that have
a large variation in the amount of memory allocated over
time will be measured less accurately as a result. Policies
might also look at intermediate measurements made when
a task is neither the ﬁrst nor the last to be processed by the
garbage collector. These measurements may still be useful
for adjusting the lower and upper-bounds on a task’s mem-
ory usage.
We observe that in the presence of greater memory pres-
sure (when it is likely to be more important to enforce lim-
its on memory usage), the frequency of garbage collection
will go up; accordingly, the frequency with which memory
usage is measured also increases. This implies that the ac-
curacy and timeliness of memory accounting will improve
when it is most needed. Other factors, such as a choos-
ing a smaller heap size, will also result in higher-resolution
accounting data, although at the cost of some runtime efﬁ-
ciency.
When using a generational collector, the same upper and
lower bounds exist. Exact measurement of memory usage
is only available after a major collection. However, a gen-
erational collector is explicitly designed to minimize such
collections of the mature space. For an example of the
scarcity of major collections, see Table 1. However, infor-
mation is available from minor collections that we can use
to reﬁne the measurements from the last major collection.
The amount of memory tenured on behalf of each task dur-
ing minor collections can be added to the upper bound of
that task’s memory usage. A similar approach is taken by
MWM [21]. On the next major collection, this incremental
adjustment becomes obsolete, and is discarded. As a result,
the high and low boundaries measured during major collec-
tions have the same properties as the measurements made
in non-generational semispace collectors.
Regardless, the quality of these measurements is not as
good as the measurements available in a semispace collec-
tor. If a task is consuming an excessive amount of memory,
it may take a long time to be discovered using this method-
ology alone. Instead, these measurements should only be
Proceedings of the 2003 IEEE Symposium on Security and Privacy (SP(cid:146)03) 
1081-6011/03 $17.00 ' 2003 IEEE 
used as a way of indicating likely culprits. If the system is
running low on available memory, it’s unclear which task or
tasks is responsible, although the larger ones observed thus
far would seem likely candidates for further analysis. It’s
possible to explicitly force a major collection at any time,
so it would be sensible in low-memory conditions to per-
form extra garbage collections to arrive at a culprit. Such
extra analysis would make sense to avoid falsely terminat-
ing the wrong task.
This leads to a general observation: we can always trade
additional CPU overhead for additional accounting accu-
racy. As an example, we could run a copying collector
twice in succession in order to get a precise picture of some
task’s low and high usage statistics. The measurements that
are provided by default are generated in the course of the
garbage collector’s normal business, but asking the garbage
collector to run more often in order to improve the quality of
data gathered might be a reasonable choice for some policy
engines.
Other policies can be feasibly implemented beyond those
based on the amount of memory being held live by each
task. For example, a policy may wish to charge tasks for the
time spent copying memory on their behalf by the garbage
collector. With a trivial change to our annotated garbage
collectors, we could push a previously hidden cost (time
spent in the garbage collector) back onto the tasks that in-
curred it, perhaps suitably modifying the tasks’ thread pri-
orities.
Finally, we observe that accurate accounting of memory
usage is predicated on there being discernible boundaries
between tasks. If all tasks have references to and from some
sort of central switchboard, such that every task has a path
to all the memory of every other task, then the measured
numbers will be out of synch with reality. Unaccountable
references should be used in such systems in order to pro-
vide segmentation. For pre-existing software applications
not yet adapted to use memory accounting, this may repre-
sent a non-trivial engineering effort.
5 Related work
5.1 Operating system-based resource accounting
Operating systems like UNIX have supported resource
accounting and management almost since their inception.
The top program and associated kernel facilities is a com-
mon interface for resource accounting, and the limit fa-
cility of the UNIX shell is the most common interface to
UNIX resource management. Modern UNIX systems also
include the getrlimit(2) and setrlimit(2) sys-
tem calls for specifying per-process limits for a variety of
system resources, including memory usage.
Several recent operating systems, including Angel [44],
Opal [17] and Mungi [36], have been designed to support
a single, large address space for all applications. Such sys-
tems, commonly designed for 64-bit architectures, can sup-
port data sharing semantics comparable to language-based
systems, since all pointers are global. Regardless, single ad-
dress space operating systems segregate memory into pages
which are “owned” by and charged to speciﬁc processes,
exactly as in traditional operating systems.
5.2 Language-based resource accounting
Systems such as Smalltalk [30], Pilot [45], Cedar [49],
Lisp Machines [13], and Oberon [55] have taken advantage
of language-based mechanisms to provide OS-like services.
At least as early as the Burroughs B5000 [14] series com-
puters, language based mechanisms were being used for
security purposes. More recently, language-based enforce-
ment of security has been popularized by Java [32, 39], orig-
inally deployed by Netscape for its Navigator 2.0 browser
in 1995 to run untrusted applets.
Java popularized this approach of providing security as
a side-effect of enforcing its type system. While numerous
bugs have been uncovered [24, 43], signiﬁcant strides have
been made at understanding the type system [3, 48, 25, 26,
23, 20] and supporting expressive security policies, includ-
ing restrictions that can allow trusted “system” code to run
with reduced privileges [52, 31, 27, 28]. The design of Java
and other multitasking run-time systems has focused pri-
marily on type-safe security that forbids tasks from access-
ing data without authorization.
However, these systems provide little or no support for
resource accounting and management on the programs they
run. A number of projects have been developed to address
this. A recent Scheme system called MrEd [29] supports
thread termination and management of resources like open
ﬁles. Some systems, such as PLAN [37], restrict the lan-
guage to provide resource usage guarantee (termination, in
this case).
Much of the recent research in this area has been focused
on the Java programming language. Chander et al. [16] de-
scribe a system to target speciﬁc sorts of resource exhaus-
tion attacks via bytecode instrumentation. The general tech-
nique they present is to replace calls to sensitive methods
(for instance, for setting thread priority or creating a new
window) with calls to customized methods that ﬁrst verify
that the operation is not harmful. Soft termination [46] is a
general-purpose mechanism for terminating wayward tasks.
Neither of these mechanisms address the problem of track-
ing resource usage, but both would be useful in conjunction
with a resource accounting mechanism.
The multitasking virtual machine (MVM) [21] is a cus-
tomization to the Java virtual machine implementing sepa-
Proceedings of the 2003 IEEE Symposium on Security and Privacy (SP(cid:146)03) 
1081-6011/03 $17.00 ' 2003 IEEE 
ration of tasks using a process abstraction. They assign a
heap to each stack; however, data that has been live for long
enough is moved to a shared heap by the garbage collector.
The garbage collector is used to track how much data a task
has live in the shared heap. Although this approach is simi-
lar to ours, the MVM does not allow tasks to share memory;
as a result, they do not address the problem of memory ac-
counting in the face of such sharing.
Another approach that uses the garbage collector to en-
force resource limitations is rent collection [4]; objects on
the heap are given a store of money that is debited by
the garbage collector. Objects that run out of money are
“evicted” and treated as garbage. If a task is not willing or
able to pay for the memory usage of its allocated objects,
those objects are collected. Rent collection has also been
used to prevent side-channel attacks in a multi-level sys-
tem [38]. Bertino et al. also tackle the problem of designing
a garbage collector for a multi-level secure heap [10, 19].
These systems are primarily concerned with covert commu-
nication channels between tasks of different security lev-
els that are allows to share objects references; by observ-
ing when objects are or are not garbage collected, informa-
tion can be covertly passed. These systems are uninterested
in measuring memory usage; likewise, we do not consider
garbage collector covert channels in our work.
Wick et al. [53] also present a system for using a garbage
collector to determine memory usage of tasks in Scheme
based on reachability. One key difference between our work
and Wick et al.
is that they measure only a single usage
value for each task, limiting the expressiveness of their se-
curity policies when many objects are shared among tasks.
They likewise have no notion comparable to unaccountable
references (see Section 2.3.2) to allow one task to explicitly
accept the full charges for sharing an object with another
task.
5.3 Garbage collection
Garbage collection has been around since at least the
LISP programming language [42]. Wilson [54] provides an
excellent overview of garbage collection techniques. Some
more common techniques include mark-and-sweep [41],
copying collectors [18], and generational garbage collec-
tors [50]. We implemented memory accounting for copying
and generational collectors.
6 Future work
One area of future work is addressing current trends in
memory management research. As noted in Section 2.3.3,
porting our memory accounting system to a generational
garbage collector required changes in the design of our ac-
counting system. More recent and future advances in the
state of the art of garbage collection research, such as ad-
vances in region-based memory allocation [33], will likely
require similar adjustments to our memory management
system.
Additionally, while we can track memory usage, there
are other shared resources that are difﬁcult to track. For in-
stance, while accounting for CPU time spent directly by a
task is straightforward, determining how much CPU time
the operating system kernel has spent on behalf of each task
is more complicated. Resource containers [7] offer a possi-
ble solution. Their motivation, to discover what resources