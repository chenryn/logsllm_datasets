# Long-Term Behavior of Harvesting Spam Bots

## Authors
- Oliver Hohlfeld, TU Berlin / Telekom Innovation Laboratories, oliver@net.t-labs.tu-berlin.de
- Thomas Graf, Modas GmbH, thomas.graf@modas-gmbh.de
- Florin Ciucu, TU Berlin / Telekom Innovation Laboratories, florin@net.t-labs.tu-berlin.de

## Abstract
This paper investigates the origins of the spamming process, particularly focusing on address harvesting from the web. Our study is based on an extensive dataset spanning over three years, during which we embedded more than 23 million unique spamtrap addresses in web pages. Approximately 0.5% of these addresses received a total of 620,000 spam messages. The uniqueness of the issued spamtrap addresses allows us to map crawling activities to the actual spamming process.

Our findings suggest that simple obfuscation methods remain effective in protecting email addresses from being harvested. A key observation is that search engines are often used as proxies, either to hide the identity of the harvester or to optimize the harvesting process.

## Categories and Subject Descriptors
- C.2.3 [Computer-communication networks]: Network operations—Network monitoring
- H.4.3 [Information Systems Applications]: Communications Applications—Electronic mail

## General Terms
- Measurement, Security

## Keywords
- Spam, E-Mail, Address Harvesting

## 1. Introduction
The proliferation of unsolicited bulk email (spam), which now exceeds the volume of legitimate email, remains a significant economic problem. Despite existing countermeasures, spamming campaigns continue to be profitable, even with a relatively small number of purchases compared to the volume of spam sent. This success motivates a deeper understanding of spamming trends and their economics, which may lead to more effective countermeasures.

Many studies have examined the properties of spam emails, traffic, and campaigns, as well as the infrastructures used for spam dissemination (e.g., botnets) and detection and classification methods. However, fewer studies have focused on the origins of the spamming process, particularly address harvesting, which is the primary method spammers use to obtain new target addresses. Addresses can be harvested in various ways, such as from public web pages using crawlers or by malicious software running on compromised machines.

To explore the origins of the spamming process, this paper conducts a large-scale study involving addresses harvested from public web pages. We embedded more than 23 million unique spamtrap addresses in over 3 million visits to web pages over more than three years, starting in May 2009. Our main findings include:
1. Search engines are used as proxies, either to hide the identity of the harvester or to optimize the harvesting process.
2. Simple obfuscation methods are still effective in protecting addresses from being harvested.

Additionally, we observed that harvesting on our web sites is declining. Harvested addresses are primarily spammed in batches and are only used for a short time period. Harvester bots are mainly run in access networks, suggesting that only a few parties are involved in address harvesting, each causing different spam volumes. Our findings also indicate that the usage of some harvesting software is stable, and harvesters make little use of Tor as an anonymity service to hide their identity.

## 2. Related Work
The method of identifying harvesting bots by issuing dynamically created, unique addresses per page request has been used for spam prevention and the identification of harvesters. Early studies by Prince et al. [20] and Schryen [24] in 2005 provided preliminary insights into the behavior of harvesters. Schryen [24] found that .com addresses attract more spam. Prince et al. [20] used a distributed platform with 5000 participants to advertise spamtrap addresses and receive spam, classifying harvesters into hucksters and fraudsters based on message turnaround time.

Shue et al. [25] in 2009 revisited aspects of address harvesting, studying geolocation, presentation methods, and the aggressiveness of harvester bots. Several spam prevention studies [3, 23] propose inflating the number of available recipients to reduce spam on legitimate accounts. In contrast, our study focuses on dynamically generating spamtrap addresses to identify the properties of address harvesting.

As trends in spam and malware change rapidly, this paper presents an up-to-date view on address harvesting and content spamming. To the best of our knowledge, we are the first to present a large-scale dataset spanning over three years, combining aspects of harvesting and comment spamming. Our dataset consists of 620,000 spam emails, significantly larger than previous studies. We confirm previous findings and explore new aspects such as the connection between harvesting and comment spamming, the efficiency of blacklisting, the usage of Tor, host-level properties of bots, and the role of search engines as proxies.

## 3. Methodology & Datasets
To study the properties of address harvesting, we issued unique spamtrap email addresses via the web. These addresses were embedded into nine low-profile web pages of various types and popularities. The methodology involves a dynamic script that generates unique email addresses for each page request and logs visitor information.

Webmasters face the dilemma of choosing a method for displaying email addresses: user-friendly or obfuscated to prevent spam. To address this, we included six different spamtrap addresses, each displayed with one of the following techniques:
- Mailto: link (MTO)
- Non-linked, plain-text address (TXT)
- Email obfuscated as user [at] domain [dot] tld (OBF)
- Obfuscated using JavaScript code (JS)
- Included in a hidden data field of a web form (FRM)
- Plain-text address inside an HTML comment (CMT)

We also issued realistic-looking addresses with random combinations of first and last names generated from phone book records. These addresses were introduced six months after the random IDs. Webmasters often append strings to displayed addresses, so we embedded name addresses twice: once with the regular address and once with a "remove" tag.

Email addresses were advertised with different domains and TLDs. Our email domains were handled by several mail exchange servers in different networks. Servers under our control ran a qsmtpd SMTP server to capture complete SMTP transactions, while others provided unfiltered email via IMAP. Any email sent to trap addresses was considered spam.

Harvesters were identified once the first spam was received. We logged basic information such as the requesting IP for all page visits and had access to complete access logs since January 2010. This extended information allowed us to analyze further properties, such as user agent strings submitted by visitors.

## 4. Harvest and Spam Activities
This section presents the main properties of address harvesting bots, including statistics on page requests, geolocation, usage of spamtrap addresses, fingerprints of bots, robustness of methods, efficiency of blacklisting, usage of anonymity services, relationship to comment spam, and the role of search engines.

### 4.1 Network Level Properties
We analyzed the requests made by harvesting bots to the monitored web sites. Figure 2(a) shows the total number of page requests per month and the page requests by harvesters. There is a decline in harvesting activity at the monitored sites, possibly due to blacklisting, increasing email turnaround time, or less usage of web crawlers for address harvesting.

In total, we classified 1251 hosts as harvesters and obtained DNS records for 90% of them. For the remaining 10%, no DNS record could be obtained, but whois information was available. Most of the hosts were in access networks. Surprisingly, 20% of the hosts were classified as search engines, whose requests originated from legitimate address spaces associated with Google, Microsoft, and Yahoo. This issue is discussed further in § 4.7.

Figure 2(b) shows a volume classification for the requests per day and IP. Most bots made a small number of page requests resulting in spam (maximum 9871 requests per IP and day). Some regions in the IP address space showed activity over multiple months, with DSL customers by a German ISP being the most dominant in March and July to August 2010. The Google bot showed the longest time stability.

Several heavy-hitters retrieved around 10,000 pages each on a single day, corresponding to 80,000 email IDs. These IPs belonged to a single provider in Romania, with 24 distinct IPs originating from this network. Requests to five of our web sites, 99% of which were to web site D (mail archive), spanned almost the entire monitoring period and were responsible for a major fraction of the received spam (see Figure 3(b)).

Figure 2(c) shows the number of received spam emails versus the page requests per IP. In many cases, only one or two page requests per IP were observed, but the spam volume sent to addresses advertised in those requests was substantial.

To determine whether harvesting machines are primarily hosted by infected machines in residential or business access lines or by dedicated servers, we applied a reverse DNS lookup to obtain host names and looked for specific text patterns. According to our classification heuristic, 73% of the IPs belong to ADSL or Cable access providers, indicating that harvester bots are still primarily run in residential access networks.

Since mid-2011, we collected statistics about open TCP/UDP ports by port scans. To focus our scans on harvesters, we limited our scans to hosts blacklisted by Project HoneyPot. Only 13 hosts that we scanned harvested email addresses from our web sites. Six of the scanned hosts had port 3389 open, typically used for remote desktop connections.

## Table 1: Data Set Overview
| Site | Type | Country | Start | Issued Rnd IDs (% spammed) | Issued MTO Rnd IDs (% spammed) | Issued Name IDs (% spammed) | End |
|------|------|---------|-------|-----------------------------|---------------------------------|------------------------------|-----|
| A    | Private blog | DE | 2009-05-16 | 791,890 (0.23%) | 144,769 (0.45%) | 211,851 (0.12%) | 2010-11-29 |
| B    | Gaming web site | DE | 2009-05-16 | 2,807,925 (0.06%) | 469,804 (0.19%) | 929,147 (0.03%) | 2012-08-24 |
| C    | Private web site | DE | 2009-05-16 | 21,558 (0.53%) | 3,890 (1.54%) | 5,938 (0.12%) | 2011-03-28 |
| D    | Mail archive | DE | 2009-05-16 | 5,191,288 (1.75%) | 917,836 (3.20%) | 1,518,105 (0.68%) | 2012-08-24 |
| E    | Private web page | DE | 2009-05-17 | 1,097 (0.00%) | 197 (0.00%) | 320 (0.00%) | 2012-08-17 |
| F    | Private web page | DE | 2009-05-16 | 400,490 (0.54%) | 70,424 (1.47%) | 118,481 (0.09%) | 2011-10-30 |
| G    | Spamtap page | DE | 2010-01-14 | 998,132 (0.29%) | 166,408 (0.54%) | 332,694 (1.07%) | 2012-08-24 |
| H    | Research group | DE | 2010-01-24 | 7,582,332 (0.07%) | 1,372,051 (0.17%) | 2,094,329 (0.04%) | 2012-08-24 |
| I    | Fake email provider | US | 2010-07-09 | 34,500 (0.19%) | 5,750 (0.26%) | 11,500 (0.03%) | 2011-05-16 |

## Figure 1: Measurement Methodology
Multiple web servers offer unique spamtrap addresses. Spam emails are received by multiple SMTP servers in multiple locations. Note that infrastructures used for harvesting and for sending spam might be run by different entities.

## Figure 2: Request and Spam Statistics
- (a) Total number of page requests per month and page requests by harvesters.
- (b) Volume classification for the requests per day and IP.
- (c) Number of received spam emails vs. the page requests per IP.

## Figure 3: Geolocation and Activity Patterns
- (a) Geolocation of harvesters.
- (b) Activity patterns over time and IP address space.