title:Longtime behavior of harvesting spam bots
author:Oliver Hohlfeld and
Thomas Graf and
Florin Ciucu
Longtime Behavior of Harvesting Spam Bots
Oliver Hohlfeld
TU Berlin / Telekom Innovation
Laboratories
oliver@net.t-labs.tu-
berlin.de
Thomas Graf
Modas GmbH
PI:EMAIL
Florin Ciucu
TU Berlin / Telekom Innovation
Laboratories
ﬂorin@net.t-labs.tu-
berlin.de
ABSTRACT
This paper investigates the origins of the spamming process,
speciﬁcally concerning address harvesting on the web, by re-
lying on an extensive measurement data set spanning over
three years. Concretely, we embedded more than 23 mil-
lion unique spamtrap addresses in web pages. 0.5% of the
embedded trap addresses received a total of 620,000 spam
messages. Besides the scale of the experiment, the critical
aspect of our methodology is the uniqueness of the issued
spamtrap addresses, which enables the mapping of crawling
activities to the actual spamming process.
Our observations suggest that simple obfuscation meth-
ods are still eﬃcient for protecting addresses from being
harvested. A key ﬁnding is that search engines are used
as proxies, either to hide the identity of the harvester or to
optimize the harvesting process.
Categories and Subject Descriptors
C.2.3 [Computer-communication networks]: Network
operations—Network monitoring; H.4.3 [Information Sys-
tems Applications]: Communications Applications—Elec-
tronic mail
General Terms
Measurement, Security
Keywords
Spam, E-Mail, Address Harvesting
1.
INTRODUCTION
The presence of unsolicited bulk e-mail (spam), which has
exceeded the volume of legitimate e-mail, remains a costly
economic problem. Notwithstanding existing counteract-
ing measures, spamming campaigns advertising products are
proﬁtable even when the amount of purchases being made is
Our data set can be obtained from [8].
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
IMC’12, November 14–16, 2012, Boston, Massachusetts, USA.
Copyright 2012 ACM 978-1-4503-1705-4/12/11 ...$15.00.
small relative to the amount of spam [12]. The apparent suc-
cess of spamming campaigns motivates the understanding of
spamming trends and their economics, which may provide
insights into more eﬃcient counteracting measures.
Many studies address the properties of spam e-mails, traf-
ﬁc, and campaigns [5, 31, 19, 22], infrastructures for spam
dissemination (e.g., botnets) [6, 27, 11, 19, 31, 22, 30, 10],
and detection and classiﬁcation methods [29, 2, 6, 7, 9, 11,
30, 14, 13]. For instance, it has been shown that spam and
non-spam traﬃc have signiﬁcantly diﬀerent properties which
can be used for spam classiﬁcation [5]. Much fewer studies
address the origins of the spamming process, e.g., concern-
ing address harvesting, which remains the primary means for
spammers to obtain new target addresses. Addresses can be
harvested in multiple ways, e.g., from public web pages by
using crawlers [20] or by malicious software locally running
on compromised machines [16]. Investigating the harvesting
processes is particularly relevant as it leads to new insights
about spammers, according to studies revealing the social
network of spammers [28] or a rather superﬁcial eﬀort to
conceal identity [20].
To explore the origins of the spamming process, this paper
conducts a large scale study involving addresses harvested
from public web pages. Concretely, to identify address har-
vesting crawlers, we have embedded more than 23 million
unique spamtrap addresses in more than 3 million visits to
web pages over the course of more than three years, starting
in May of 2009. 0.5% of the embedded addresses received a
total of 620,000 spam e-mails. The uniqueness property of
the embedded spamtrap addresses enables the mapping be-
tween the crawling activity to the actual spamming process.
Our main ﬁndings can be summarized as follows: i) search
engines are used as proxies, either for hiding the identity of
the harvester or for optimizing the harvesting process and ii)
simple obfuscation methods are still eﬃcient for protecting
addresses from being harvested.
In addition, we ﬁnd that harvesting on our web sites is
on the decline. Harvested addresses are mainly spammed in
batches and are only used for a short time period. We show
that harvester bots are still mainly run in access networks.
One interpretation of our results is that only a few parties
are involved in address harvesting, each causing diﬀerent
spam volumes. Our ﬁndings also suggest that the usage of
some harvesting software is stable. Also, harvesters make
little use of Tor as anonymity service to hide their identity.
Our overall study provides thus an up-to-date view on spam
origins which further reveals guidelines for webmasters to
protect e-mail addresses.
4532. RELATED WORK
The method of identifying harvesting bots by issuing dy-
namically created addresses that are unique to each page
request has been used for spam prevention and the iden-
tiﬁcation of harvesters [24, 20, 25]. The ﬁrst attempts in
understanding the behavior of harvesters have been under-
taken by Prince et al. [20] and Schryen [24] in 2005. Based on
2500 spam e-mails, Schryen [24] investigates whether the top
level domain of an e-mail address is relevant for spammers
and ﬁnds that .com addresses attract more spam. A more
systematic study of address harvesting was done by Prince
et al. [20] by using a distributed platform using 5000 par-
ticipants to advertise spamtrap addresses and receive spam
(Project Honey Pot). The authors present preliminary re-
sults on the average turnaround time of e-mails, User Agent
strings used by harvester bots, and their geolocation. The
data has been obtained over a period of six months and is
based on an unstated number of spam e-mails. In particular,
the paper classiﬁes harvesters into two distinct categories by
the message turnaround time: hucksters and fraudsters.
Aspects of address harvesting were revisited by Shue et al.
[25] in 2009. Their study is based on 96 spam e-mails and
studies the geolocation of harvesters, strength of presenta-
tion methods, turnaround times, and the aggressiveness of
harvester bots expressed by the frequency of page visits.
Several spam prevention studies [3, 23] propose to pol-
lute spammers’ databases and thus to inﬂate the number of
available recipients in order to reduce spam on legitimate ac-
counts. In contrast, our study is concerned with dynamically
generating spamtrap addresses for identifying the properties
of address harvesting.
As trends in the world of spam and malware are chang-
ing fast, this paper presents an up-to-date view on address
harvesting and content spamming. To the best of our knowl-
edge, we are the ﬁrst to present a large-scale data set span-
ning over more than three years that combines aspects of
harvesting and comment spamming. In contrast to [24] and
[25], our spam body consists of 620,000 spam e-mails and is
larger by magnitudes. While we conﬁrm previous ﬁndings,
we also study new aspects such as i) the connection be-
tween harvesting and comment spamming activities, ii) the
eﬃciency of blacklisting, iii) the usage of the Tor anonymity
service, iv) host-level properties of bots, and v) the usage of
search engines as proxies to hide the identity of harvesters.
3. METHODOLOGY & DATASETS
To study the properties of the address harvesting process
of harvesters using web crawlers, we use a methodology rely-
ing on issuing unique spamtrap e-mail addresses via the web.
As the addresses are uniquely generated for each page re-
quest, their usage can be directly mapped to a speciﬁc page
request. The generated addresses are embedded into nine
low-proﬁle web pages of various types (gaming, private web
pages, research group, etc., see Table 1) and popularities.
This methodology is implemented in web sites by including
a dynamic script that generates unique e-mail addresses for
each page request and logs information about the visitors.
The resulting distributed platform to advertise our spamtrap
addresses and to receive spam is illustrated in Figure 1.
Webmasters are typically confronted with the dilemma of
choosing a method for displaying e-mail addresses on the
web: Should addresses be presented in a user-friendly or ob-
fuscated way to prevent spam? Which presentation method
is the most robust against address harvesters? To shed light
on this dilemma, the information included in the web pages
of our study consists of six diﬀerent spamtrap addresses,
each being displayed with one of the following presentation
and obfuscation techniques: i ) a mailto:
link (MTO), ii )
non-linked, plain-text address (TXT), iii ) e-mail obfuscated
in the form of user [at] domain [dot] tld (OBF), iv ) obfus-
cated using Javascript code (JS), v ) included in a hidden
data ﬁeld of a web form (FRM), and vi ) plain-text address
inside an HTML comment (CMT). All of the above de-
scribed addresses consist of random strings of 10 characters
each (RND IDs, e.g., ”jdi4gj8bzx”). We use random strings
as they are suﬃciently hard to guess. Table 1 shows the to-
tal number of embedded random IDs per web page, as well
as the respective measurement periods. Note that the num-
ber of random IDs correlates with the number of monitored
page requests for each web site.
In addition to random strings, we issue realistic looking
addresses containing random combinations of ﬁrst and last
names generated from phone book records (Name IDs, e.g.,
“john.doe”). These addresses were introduced in January
2010, six months after the random IDs. The number of em-
bedded addresses per web page is shown in Table 1. Com-
pared to random strings, the assumption is that realistic
looking addresses are harder to identify as spamtrap ad-
dresses, but are also easier to guess. As the total number of
possible ﬁrstname × lastname combinations is much smaller
than the total number of possible random IDs, we only issue
name IDs using the MTO embedding method, to avoid run-
ning out of addresses. Webmasters often append strings to
displayed addresses that are to be removed by users, causing
bots to extract non-existent addresses. Therefore, by using
the MTO method, we embed name addresses twice in each
web page: once by using the regular address and once by
appending a “ remove ” tag.
E-mail addresses are advertised by appending diﬀerent do-
mains and TLDs. Our e-mail domains are handled by several
mail exchange servers located in diﬀerent networks. Servers
which are under our control run a qsmtpd SMTP server that
captures the complete SMTP transactions and accepts any
incoming mail. Other servers provide us the unﬁltered e-
mail feed via IMAP. We consider any e-mail sent to trap
addresses as spam.
As harvesters can only be identiﬁed once the ﬁrst spam is
received, we log basic information such as the requesting IP
for all page visits. In addition, web site operators provided
us with complete access logs since January 2010. This ex-
tended information allows us to analyze further properties
such as user agent strings submitted by visitors.
As our web pages cover a variety of diﬀerent genres and
popularities, this selection is arguably representative. By
monitoring a relatively small number of web pages concen-
trated in Germany, the conclusions of this study are con-
ceivably biased. However, this bias creates the opportunity
to look at a focussed set of web pages and study locality in
the harvesting process.
4. HARVEST AND SPAM ACTIVITIES
This section presents the main properties of address har-
vesting bots. We present statistics on page requests made
by bots, geolocation of bots, the usage of our spamtrap
addresses, ﬁngerprints of bots, the robustness of methods
454Site
Type
Country
Start
A
B
C
D
E
F
G
H
I
Private blog
Gaming web site
Private web site
Mail archive
Private web page
Private web page
Spamtap page
Research group
Fake email provider
DE
DE
DE
DE
DE
DE
DE
DE
US
of Rnd IDs
2009-05-16
2009-05-16
2009-05-16
2009-05-16
2009-05-17
2009-05-16
2010-01-14
2010-01-24
2010-07-09
Issued Rnd IDs
(% spammed)
791,890 (0.23%)
2,807,925 (0.06%)
21,558 (0.53%)
5,191,288 (1.75%)
1,097 (0.00%)
400,490 (0.54%)
998132 (0.29%)
7,582,332 (0.07%)
34,500 (0.19%)
Issued MTO Rnd IDs
Issued Name IDs
End
(% spammed)
144,769 (0.45%)
469,804 (0.19%)
3,890 (1.54%)
917,836 (3.20%)
197 (0.00%)
70,424 (1.47%)
166,408 (0.54%)
1,372,051 (0.17%)
5,750 (0.26%)
(% spammed)
211,851 (0.12%)
929,147 (0.03%)
5,938 (0.12%)
1,518,105 (0.68%)
320 (0.00%)
118,481 (0.09%)
332,694 (1.07%)
2,094,329 (0.04%)
11,500 (0.03%)
2010-11-29
2012-08-24
2011-03-28
2012-08-24
2012-08-17
2011-10-30
2012-08-24
2012-08-24
2011-05-16
Table 1: Data Set Overview
Figure 1: Measurement Methodology: Multiple web servers oﬀer unique spamtrap addresses. Spam e-mails
are received by multiple SMTP servers in multiple locations. Note that infrastructures used for harvesting
and for sending spam might be run by diﬀerent entities.
used to display e-mail addresses on the web, the eﬃciency
of blacklisting, the usage of anonymity services, the relation-
ship to comment spam, and the role of search engines.
4.1 Network Level Properties
We start by analysing the requests made by harvesting
bots to the monitored web sites. By request we denote a
page retrieval which resulted in spam to at least one of the
retrieved e-mail addresses. Figure 2(a) shows i) the total
number of page requests per month and ii) the page re-
quests by harvesters. The ﬁgure shows a decline in harvest-
ing activity at the monitored sites, especially compared to
comment spam as malicious activity (cf. § 4.6). Conceivable
reasons for this decline are: i) our sites get blacklisted over
time, ii) increasing e-mail turnaround time or, iii) less usage
of web crawlers for address harvesting.
In total, we classiﬁed 1251 hosts as harvesters and ob-
tained DNS records for 90% of the hosts. For the remaining
10%, no DNS record could be obtained from the author-
itative DNS servers, but whois information.
Inspecting a
random subset of hosts led to mostly access networks. To
our surprise, we classiﬁed 20% of the hosts as search engines
whose requests originated from legitimate address spaces as-
sociated to Google, Microsoft, and Yahoo. We discuss this
issue further in § 4.7. Requests by a search engine crawler
that resulted in spam are shown in Figure 2(a).
To study how requests by harvesting bots are spread over
time, address space, and volume, Figure 2(b) shows a volume
classiﬁcation for the requests per day and IP. For most of
the bots, only a small number of page requests resulting in
spam can be observed (maximum 9871 requests per IP and
day). A few regions in the IP address space show activity
over multiple months, visible as horizontal bars. We found
DSL customers by a German ISP to be the most dominant
ones in March and July to August of 2010. However, the
Google bot showed the longest time stability.
The ﬁgure also shows several heavy-hitters; six hosts re-
trieved around 10,000 pages—corresponding to 80,000 e-
mail IDs—each on a single day. Manually inspecting these
hosts revealed that most of the IP addresses belong to a sin-
gle provider in Romania. We found 24 distinct IPs originat-
ing from this network, none of them having a DNS record.
Page requests by these IPs span over almost the entire mon-
itoring period and are responsible for a major fraction of
the received spam (see Figure 3(b)). We observed requests
to ﬁve of our web sites, of which 99% belong to web site D
(mail archive).
To connect access statistics with the actual spam volume,
we show the number of received spam e-mails vs. the page
requests per IP in Figure 2(c). In many cases, only one or
two page requests per IP are observed. However, the spam
volume sent to addresses advertised in those requests was
substantial.
We were further interested in whether harvesting machines
are primarily hosted by infected machines located in resi-
dential or business access lines, or by operating dedicated
servers. For this classiﬁcation, we i) ﬁrstly apply a reverse
DNS lookup to obtain host names and ii) secondly look for
speciﬁc text patterns in the obtained host names. We clas-
sify hosts as DSL or Cable hosts if their host name contains
key words such as “dsl”, “customer”, “dialin”, etc. Accord-
ing to our classiﬁcation heuristic, 73% of the IPs belong to
ADSL or Cable access providers. This shows that harvester
bots are still primarily run in residential access networks.
To study further properties of the hosts running bot soft-
ware, we collected statistics about open TCP/UDP ports
by port scans since mid 2011. To reduce the traﬃc caused
by port scans and to focus our scans on harvesters, we lim-
ited our port scans to hosts blacklisted by Project Honey-
pot (note that we can only mark harvesters in retrospect
after the ﬁrst spam arrival). Only 13 hosts that we scanned
harvested e-mail addresses from our web sites. Six of the
scanned hosts had port 3389 open (typically used for remote
455Total
Comment Spam
Harvester
Search Engines
224.0.0.0
192.0.0.0
160.0.0.0
128.0.0.0
96.0.0.0
64.0.0.0
32.0.0.0
0.0.0.0