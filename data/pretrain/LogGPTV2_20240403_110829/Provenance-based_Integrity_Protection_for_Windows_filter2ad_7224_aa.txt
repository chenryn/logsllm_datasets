title:Provenance-based Integrity Protection for Windows
author:Wai-Kit Sze and
R. Sekar
Provenance-based Integrity Protection for Windows
Wai Kit Sze and R. Sekar
Stony Brook University
Stony Brook, NY, USA
{wsze,sekar}@cs.stonybrook.edu
ABSTRACT
Existing malware defenses are primarily reactive in nature,
with defenses eﬀective only on malware that has previously
been observed. Unfortunately, we are witnessing a genera-
tion of stealthy, highly targeted exploits and malware that
these defenses are unprepared for. Thwarting such malware
requires new defenses that are, by design, secure against
unknown malware. In this paper, we present Spif, an ap-
proach that defends against malware by tracking code and
data origin, and ensuring that any process that is inﬂuenced
by code or data from untrusted sources will be prevented
from modifying important system resources, and interacting
with benign processes. Spif is designed for Windows, the
most widely deployed desktop OS, and the primary platform
targeted by malware. Spif is compatible with all recent Win-
dows versions (Windows XP to Windows 10), and supports a
wide range of feature rich, unmodiﬁed applications, including
all popular browsers, oﬃce software and media players. Spif
imposes minimal performance overheads while being able
to stop a variety of malware attacks, including Stuxnet and
the recently reported Sandworm malware. An open-source
implementation of our system is available.
1.
INTRODUCTION
The scale and sophistication of malware continues to grow
exponentially. The reactive approach embodied in malware
scanners and security patches is no match for today’s stealthy,
targeted attacks. Recognizing this fact, researchers as well as
software vendors have been developing proactive techniques
that can protect against previously unseen exploits and/or
malware attacks. These techniques can be classiﬁed into
three main categories: sandboxing, privilege separation, and
information ﬂow control.
Sandboxing techniques [13, 35, 45, 49] mediate all security-
relevant operations performed by applications, permitting
only those deemed “safe” by a sandboxing policy. The scope
of damage that can result from a malicious (or compromised)
application is hence limited by this policy. On UNIX, appli-
cations frequently targeted by attacks are typically protected
using SELinux [24] or AppArmor policies [45]. Microsoft Of-
ﬁce used a sandbox for its protected view [27]. This sandbox
ensures that a compromised process cannot overwrite system
or user ﬁles or registry entries.
†This work was supported in part by NSF (grants CNS-0831298
and CNS-1319137) and DARPA (contract FA8650-15-C-7561).
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full citation
on the ﬁrst page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from permissions@acm.org.
ACSAC ’15, December 07 - 11, 2015, Los Angeles, CA, USA
c(cid:13) 2015 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ISBN 978-1-4503-3682-6/15/12. . . $15.00
DOI: http://dx.doi.org/10.1145/2818000.2818011
Privilege separation techniques [36] reﬁne the sandboxing
approach to support applications requiring signiﬁcant access
to realize their functionality. The application is decomposed
into a small, trustworthy component that retains signiﬁcant
access, and a second larger (and less-trusted) component
whose access is limited to that of communicating with the
ﬁrst component in order to request security-sensitive oper-
ations. While sandboxes can conﬁne malicious as well as
frequently targeted benign applications (e.g., browsers), priv-
ilege separation is applied only to the latter class. Chromium
browser [38], Acrobat Reader and Internet Explorer are some
of the prominent applications that employ privilege separa-
tion, more popularly known as the broker architecture. Both
applications sandbox their renderers, which are complex and
are exposed to untrusted content. As a result, vulnerabilities
in the renderer (or more generally, a worker) process won’t
allow an attacker to obtain all privileges of the user running
the application.
Information ﬂow control (IFC) techniques [2, 50, 19, 21, 42,
25, 44, 43] maintain labels on ﬁles and processes to keep track
of the ﬂow of sensitive and/or untrusted information in the
system. Classical integrity policies such as the Biba policy [2]
enforce both no-read-down (i.e., integrity-critical applications
cannot read untrusted data) and no-write-up (i.e., untrusted
applications cannot create or overwrite high-integrity ﬁles)
policies. In contrast, Windows Integrity Mechanism (WIM)
[28] enforces just the no-write-up policy. Indeed, WIM is
primarily deployed as a sandboxing mechanism: progres-
sively more restrictive policies are enforced on lower integrity
processes, while high-integrity processes are unconﬁned. In
contrast, the strength of integrity protection in IFC stems
from policy enforcement on high-integrity processes, which
prevents them from compromised by consuming untrusted
data or code.
1.1 Challenges
Application of these three approaches for malware defense
poses several technical as well as practical challenges.
Policy development. Policy aﬀects both usability and
functionality of applications. Restrictive policies can block
more attacks, but they also tend to break applications. More-
over, policy development requires not only a good under-
standing of applications, but also the OS semantics. A recent
Adobe Reader XI vulnerability [14] exploits the semantics
of junctions on NTFS, where the broker process failed to
sanitize paths and ended up allowing workers to create ﬁles
at arbitrary locations.
Application and OS compatibility. To run successfully
with a policy and its enforcement framework, applications
need to be re-architected, or at a minimum, be made aware of
the conﬁned environment. Most IFC approaches require non-
trivial changes to applications as well as the OS. There have
been eﬀorts to automate some of the steps (e.g., automating
privilege separation [4]) or to minimize application changes
for IFC (e.g., PPI [42] and PIP [44]), but in practice, most
techniques end up requiring substantial eﬀort in rewriting or
porting applications or the OS.
Sandbox escape attacks. Given the large eﬀort needed to
(a) develop policies and (b) modify applications to preserve
compatibility, it is no wonder that in practice, conﬁnement
techniques are narrowly targeted at a small set of highly ex-
posed applications. This naturally leads attackers to target
sandbox escape attacks:
if the attacker can deposit a ﬁle
containing malicious code somewhere on the system, and
trick the user into running this ﬁle, then this code is likely to
execute without conﬁnement (because conﬁnement is being
applied to a small, predeﬁned set of applications). Alterna-
tively, the attacker may deposit a malicious data ﬁle, and
lure the user to open it with a benign application that isn’t
sandboxed. In either case, the attacker is in control of an
unconﬁned process that is free to carry out its malicious acts.
As a result of these factors, existing defenses only shut out
the obvious avenues, while leaving the door open for attacks
based on evasion (e.g., Stuxnet [10]), policy/enforcement
vulnerabilities (e.g., sandbox escape attacks on Adobe Reader
[11], IE [20] and Chrome [7]), or social engineering. Stuxnet
[10] is a prime example here: one of its attacks lures users
to plug in a malicious USB drive into their computers. The
drive then exploits a link vulnerability in Windows Explorer,
which causes it to resolve a crafted lnk ﬁle to load and execute
attacker-controlled code in a DLL.
1.2 Approach overview and key features
We present a new approach and system called Spif, which
stands for Secure Provenance-based Integrity Fortiﬁcation, to
achieve OS-wide integrity protection on Microsoft Windows.
Unlike previous approaches, Spif:
• Requires no manual eﬀort for policy development.
• Requires no application or OS modiﬁcations, being able
to support all major versions of Windows since Windows
XP, and feature-rich, unmodiﬁed applications such as MS
Oﬃce, IE, Chrome, Firefox, Skype, Photoshop, and VLC.
• Conﬁnes all applications, thereby taking away the motiva-
tion for sandbox escape attacks.
Spif defends against unknown malware attacks targeting
integrity1, including stealthy malware such as Stuxnet and
Sandworm [46].
Spif uses information-ﬂow tracking to track provenance.
We deﬁne provenance as the origin (“where”) of a piece of
information. The classical notion of data provenance includes
a history of transformations (“how”) performed on the data.
Although the availability of such information could lead to
more sophisticated integrity policies, for simplicity and per-
formance, we don’t currently capture this “how” information.
Indeed, our implementation classiﬁes origins into just two
categories: benign and untrusted. Eﬀectively, provenance in
our implementation corresponds to just 1-bit of data.
Figure 1 summarizes some of the key terms deﬁned in
previous works [42, 44] that we reuse in this paper. Below,
we summarize the key features of our approach.
1.2.1 Reliable provenance tracking system
Existing provenance tracking systems either develop brand
new OSes [50, 9] or instrument OSes [21, 42, 25] to label every
1Although Spif does not focus on conﬁdentiality, note that most
malware needs to embed itself into the system in such a man-
ner that it would be invoked automatically. This step requires
compromising system integrity, and will be caught by Spif.
Term
malicious
untrusted
Explanation
intentionally violate policy, evade enforcement
possibly malicious
benign code non-malicious but potentially vulnerabilities
benign process process whose code and inputs
are benign, i.e., non-malicious
Figure 1: Key terminology
subject (process) and object (ﬁle) in the system. Developing
such a system-wide tracking mechanism can be error-prone
and involve substantial engineering challenges. This problem
is particularly serious in the context of Windows because
its source code is unavailable. Spif therefore realizes prove-
nance tracking using an existing security mechanism, namely,
multi-user protection and discretionary access control (DAC).
Unlike Android, which uses a diﬀerent userid for each app,
our design creates one new userid for each existing user.
While Android’s goal is to isolate diﬀerent apps, we use DAC
to protect benign processes/ﬁles from untrusted code/data.
(We discuss the alternative of using Windows integrity labels
in Section 4.5.)
Files coming from untrusted sources are owned by a “low-
integrity” user, a new user from the OS perspective.
File download is the most common way to introduce new
ﬁles. Spif utilizes the Windows Security Zones [26] informa-
tion ﬁlled by most browsers and email readers to identify ﬁle
integrity. As these ﬁles are used in the system, any subjects
and objects derived from these untrusted ﬁles will also be
labeled as low-integrity.
1.2.2 Robust policy enforcement
Experience with various containment mechanisms such as
sandboxie [39], Buﬀerzone [5] and Dell Protected Workspace
[8], as well as the numerous real-world sandbox escape at-
tacks [11, 20, 7], have demonstrated the challenges of building
eﬀective new containment mechanisms for malicious code
[37]. We therefore resolved to rely on (a) simple policies,
and (b) time-tested security mechanisms for sandboxing un-
trusted code. Speciﬁcally, Spif relies on multi-user protection
mechanism for policy enforcement. By relying on a mature
protection mechanism that was designed into the OS right
from the beginning, and has withstood decades of eﬀorts to
ﬁnd and exploit vulnerabilities, Spif side-steps the challenges
of securely conﬁning malicious code.
To protect overall system integrity, it is necessary to sand-
box benign processes as well: otherwise, they may get com-
promised by reading untrusted data, which may contain
exploits. Spif therefore enforces a policy on benign processes
as well. Among other restrictions, this policy prevents benign
processes from reading untrusted data. Note that, since be-
nign processes have no incentive to actively subvert or escape
defenses, it is unnecessary for this enforcement mechanism
to be resilient against adversaries.
1.2.3 Application and OS transparency
Today’s OSes do not distinguish users from processes run-
ning on behalf of users. Every operation performed by a
process owned by user R is considered to be endorsed by
user R. Compromising a single user process can therefore
compromise all other processes and ﬁles owned by that user,
and possibly, the entire OS. As a result, the system can be
considered secure only if no application is vulnerable or is
malicious. This is virtually impossible to ensure.
Spif embraces the fact that applications will have vul-
nerabilities, and shifts the responsibility of system integrity
protection to an OS-wide mechanism. Hence Spif can treat
applications as blackboxes, requiring no changes.
It can
support feature-rich unmodiﬁed applications such as Pho-
toshop, Microsoft Oﬃce, Adobe Reader, Windows Media
Player, Internet Explorer, and Firefox.
1.2.4 Usable policy
One of the design goals of Spif is to preserve normal
desktop user experience. Unprotected systems impose no
constraints on interactions between subjects (processes) and
objects (ﬁles). While this allows maximum compatibility
with existing software, malware can exploit this trust to
compromise system integrity. Preventing such compromise
requires placing some restrictions on the interactions. Simply
blocking such interactions can lead to application failures,
and hence impact user experience. Spif comes pre-conﬁgured
with policies targeted at preserving user experience.
1.2.5
We have implemented Spif on Windows, supporting XP,
7, 8.1, and 10. Implementing such a system-wide provenance
tracking system on closed-source OSes is challenging. We
share our experiences and lessons on implementing Spif on
Windows.
Implementation on Windows
Research eﬀorts in developing security defenses have been
centered on Unix systems. Prototypes are developed and
evaluated on open-source platforms like Linux or BSD to
illustrate feasibility and eﬀectiveness. While these open-
source platforms simplify prototype development, they do not
mirror closed-source OSes like Windows. First, these closed-
source OSes are far more popular among end-users. They
attract not only application developers, but also malware
writers. Second, there is only a limited exposition on the
internals of closed-source OSes. Very few researchers are
aware of how the mechanisms provided in these OSes can
be utilized to build systems that are secure, scalable, and
compatible with large applications. For this reason, we
believe the design and experience presented in this paper
is valuable. To be helpful to a broad audience, we describe
Spif in terms of concepts and features of Unix. We hope this
will enable more of the systems community that is rooted
in Unix to develop solutions for commercial OSes, where far
more vulnerabilities are being exploited in the wild.
2. THREAT MODEL
We assume users of the system are benign. Any benign
application invoked by a user will therefore be non-malicious.
If a user is untrusted, Spif can simply treat the user as a
low-integrity user and every subject created by that user is
of low-integrity.
Spif assumes that any ﬁles received from unknown or
untrusted sources will be labeled as low-integrity. This can be
achieved by exclusion: Only ﬁles from trusted sources like OS
distributors, trustworthy developers and vendors are labeled
as high-integrity. All ﬁles from unveriﬁable origins (including
network and external drives) are labeled as untrusted. As
described later, Spif’s labeling of incoming ﬁles has been
seamlessly coupled with Windows Security Zones, which has
been adopted by all recent browsers and email clients. An
administrator or a privileged process can upgrade these labels,
e.g., after a signature or cryptographic hash veriﬁcation. We
may also permit a benign process to downgrade labels.
Spif focuses on defending attacks that compromise the
system-integrity, i.e., performing unauthorized modiﬁcations
to the system (such as malware installing itself for auto-
starting) or environment that enables the malware to subvert
other applications or the OS. Although Spif can be con-
ﬁgured to protect conﬁdentiality of user ﬁles, this requires
conﬁdentiality policies to be explicitly speciﬁed, and hence
we did not explore it further in this paper. It should be
noted that ﬁles containing secrets useful to gain privileges
are already protected from reads by normal users. This policy
could be further tightened for untrusted subjects.
We assume that benign programs rely on system libraries
(i.e., ntdll.dll and kernel32.dll) to invoke system APIs.
Spif intercepts API calls from the libraries to prevent high-
integrity processes from accidentally consuming low-integrity
objects. We do not make any such assumptions about un-
trusted code or low-integrity processes, but do assume that
OS permission mechanisms are secure. Thus, attacks on the
OS kernel are out of scope for this paper.
3. PROVENANCE-BASED SANDBOXING
Spif relies on DAC for secure tracking of provenance of
processes and objects (Section 3.1). Moreover, it sandboxes
all processes, using provenance to determine whether to use
low-integrity sandbox (Section 3.2) or high-integrity sandbox
(Section 3.3). A high-integrity subject may choose to run in
a low-integrity sandbox so that it can process low-integrity
ﬁles (Section 3.4). Finally, policy choices to preserve user
experience are discussed in Section 3.5.
3.1 Secure provenance tracking
Spif tracks subject- and object-provenance by re-purposing
multi-user support. For each real user R on the system, Spif
creates a low-integrity user RU to represent untrusted sub-