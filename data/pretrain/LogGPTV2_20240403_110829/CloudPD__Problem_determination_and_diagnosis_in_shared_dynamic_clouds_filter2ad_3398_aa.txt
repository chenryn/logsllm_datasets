title:CloudPD: Problem determination and diagnosis in shared dynamic clouds
author:Bikash Sharma and
Praveen Jayachandran and
Akshat Verma and
Chita R. Das
CloudPD: Problem Determination and Diagnosis in
Shared Dynamic Clouds
⋆Bikash Sharma†, Praveen Jayachandran§, Akshat Verma§, Chita R. Das†
†Department of Computer Science and Engineering, Pennsylvania State University, University Park, PA
{bikash, das}@cse.psu.edu
§IBM Research - India
{prjayach, akshatverma}@in.ibm.com
Abstract— In this work, we address problem determination in
virtualized clouds. We show that high dynamism, resource shar-
ing, frequent reconﬁguration, high propensity to faults and auto-
mated management introduce signiﬁcant new challenges towards
fault diagnosis in clouds. Towards this, we propose CloudPD,
a fault management framework for clouds. CloudPD leverages
(i) a canonical representation of the operating environment to
quantify the impact of sharing; (ii) an online learning process to
tackle dynamism; (iii) a correlation-based performance models
for higher detection accuracy; and (iv) an integrated end-to-end
feedback loop to synergize with a cloud management ecosystem.
Using a prototype implementation with cloud representative batch
and transactional workloads like Hadoop, Olio and RUBiS, it is
shown that CloudPD detects and diagnoses faults with low false
positives (< 16%) and high accuracy of 88%, 83% and 83%,
respectively. In an enterprise trace-based case study, CloudPD
diagnosed anomalies within 30 seconds and with an accuracy of
77%, demonstrating its effectiveness in real-life operations.
Keywords—Cloud, Problem Determination, Fault Diagnosis, Vir-
tualization, Performance, Hadoop MapReduce
I.
INTRODUCTION
Large data centers and utility clouds experience frequent
faults, which are top contributors to their total management
costs, and lead to Service Level Agreement (SLA) violations
of the hosted services [1]–[4]. A recent survey shows that
IT downtime on an average leads to 14 hours of downtime
per year, costing $26.5 billion in lost revenue [5]. Another
survey [6] shows growing reluctance in customers to move
to clouds due to the incurred unpredictable performance. A
related study [7] on 3 years worth forum messages concerning
the problems faced by end users of utility clouds shows that
virtualization related issues contribute to around 20% of the to-
tal problems experienced. The existence of public repository of
failure traces [8] across diverse distributed systems like Skype,
Microsoft and Planetlab, further demonstrates the prevalence
and need for taming the faults for successful operation.
Traditional problem determination in distributed systems is
geared towards building a model of an application running
without errors [1]. When an application’s current performance
does not match the model of its normal execution, an anomaly
is detected, thereafter system administrators are alerted, who
usually ﬁx the anomaly manually. Clouds present an automated
and dynamic model, which conﬂicts with the manual/semi-
automatic process of problem determination. An application
running inside a cloud often appears opaque to the cloud
provider, which makes it non-trivial to access ﬁne-grained sys-
tem and application measurements for problem detection [9].
⋆During this work, the author was an intern at IBM Research - India.
A. Problem Determination in Clouds: What is New?
In this paper, we address the issue of problem determination
in a dynamic multi-tenant Infrastructure as a Service (IaaS)
cloud environment. We focus only on problems that lead to
the performance degradation of an application, but do not
cause it
to fully abort (e.g., fail-stop failures like power
outage). Besides being large scale virtualized systems, clouds
present the following new challenges that traditional problem
determination techniques fall short of to address:
• Sharing of Resources: Clouds are multi-tenant, and multiple
virtual machines (VMs) are collocated on the same physical
server. Since resources like cache, disk and network band-
width are not virtualized, the performance of an application
may depend on other collocated applications. We conducted
a preliminary study to understand the impact of colloca-
tion (i.e., multiple applications sharing a common set of
resources), VM migration and VM resizing. We observed that
multi-tenancy can lead up to 40% performance degradation
for a sample ﬁle system benchmark Iozone (Figure 1(a)).
This makes it
important for problem determination tech-
niques to understand the operating context under which a
workload operates and distinguish a collocation fault from
an application error. Operating context quantiﬁes the impact
of collocated applications by augmenting the metrics that
are affected by the environment (e.g., host server metrics
like cache miss) in the application performance model. We
elaborate on the notion of operating context in Section III-A.
• Dynamism: Clouds are elastic and allow workloads to au-
tomatically request/release resources on-demand. Elasticity
in a cloud is enabled through techniques like VM resizing,
VM migration, and VM cloning. Hence, the operating context
under which a workload operates changes more frequently,
compared to traditional distributed systems. In a 24-hour case
study (Section V-F), we observed that the operating context
of all VMs changes within 3.5 hours (Figure 1(b)), and the
maximum duration without a change in operating context for
any VM was 6 hours. This makes it imperative for a problem
determination system to dynamically learn the application
behavior in the speciﬁc operating context, rendering static
model-based approaches ineffective for clouds [10]–[12].
• High Frequency of Faults: Sharing of resources combined
with high dynamism invariably leads to a large number of
cloud anomalies [7], [9], [12], [13]. We observed that a faulty
VM resizing can impact performance by up to 20% and a
faulty VM migration can impact performance by more than
10% (Figure 1(a)). Further, we found that up to 10% of cloud
reconﬁguration actions can be faulty (Section V-F). Thus,
problem determination in clouds needs to deal with a much
higher frequency of faults than traditional distributed systems.
978-1-4799-0181-4/13/$31.00 ©2013 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 07:43:49 UTC from IEEE Xplore.  Restrictions apply. 
)
%
(
n
o
i
t
a
d
a
r
g
e
d
e
c
n
a
m
r
o
f
r
e
P
50
40
30
20
10
0
)
s
r
u
o
h
n
i
(
M
V
f
o
e
m
i
t
e
g
n
a
h
c
t
x
e
t
n
o
C
 10
 8
 6
 4
 2
 0
Max
Avg
Min
 0
 2
 4
 6
 8
 10
 12
 14
 16
Virtual Machine ID
(b)
Collocation
VM−resizing
VM−migration
Cloud Events
(a)
Figure 1: (a) We ran a ﬁle system benchmark, Iozone, on
one virtual machine, hosted on an IBM blade server (details
in Section V-A), and observed degradation in its execution time
due to various cloud events; (b) Operating context of workloads
changes frequently due to high dynamism in clouds.
• Autonomic Systems: Cloud is an autonomic end-to-end sys-
tem, which reacts automatically to changes in workload
requirements. A problem determination system that manually
ﬂags a cloud anomaly like VM sizing error does not suit the
cloud model [9], [10], [13]. Problem determination in a cloud
needs to take a completely automated end-to-end approach for
anomaly detection, diagnosis, classiﬁcation and remediation
by integrating with the cloud management stack [9].
To the best of our knowledge, no such framework exists today
for an automated end-to-end handling of virtualized cloud
related faults. Thus, in this paper, we present the design and
implementation of a comprehensive end-to-end fault manage-
ment framework for clouds, called CloudPD.
The design of CloudPD includes the operating context of a
workload in its resource model to quantify the performance im-
pact of collocated applications in a scalable manner. CloudPD
consists of online model generation techniques for building
performance models for applications by considering them as
black boxes. It combines simple and correlation-based models
in a two-phase methodology, where a light-weight resource
model is ﬁrst used to predictably trigger events, followed by a
correlation-based analysis only for a sub-set of these events.
B. Contributions
To summarize, we make the following contributions:
• We demonstrate that high dynamism and sharing of re-
sources in the cloud often lead to frequent changes in an
application’s resource model, obviating the applicability of
problem determination techniques that create a stationary
model for a system, and identify deviations from the model
to ﬂag errors. Further, cloud introduces new anomalies due
to sharing and cloud reconﬁguration, which are difﬁcult to
differentiate from application errors. We identify the need for
an end-to-end problem detection, diagnosis and remediation
framework, consistent with the autonomic cloud management
system. Unlike prior works, where the thrust was primarily
on application level anomalies, we speciﬁcally focus on faults
that arise due to cloud activities, and virtualization artifacts
such as VM migration, VM resizing, and VM collocation.
• We present
the design and implementation of CloudPD,
a fault management system, which addresses the chal-
lenges identiﬁed with a problem determination framework for
clouds. CloudPD introduces three novel ideas and combines
them with known techniques to design an effective method-
ology for problem determination. Our ﬁrst idea attacks the
problem of a non-stationary context by introducing operating
context of an application in its resource model. The second
idea is in using host metrics as a canonical representation
of the operating context for drastically reducing the number
of resource models to be learned. Moreover, we use an
online learning approach to further reduce the number of
resource models learned by the system. The third idea is a
three-level framework (i.e., a light-weight event generation
stage, an inexpensive problem determination stage and a
robust diagnosis stage) which combines resource models with
correlation models as an invariant of application behavior.
Since pair-wise correlation behaviors are expensive to learn,
we restrict ourselves to learning (i) only linear correlations;
and (ii) correlations between metrics that exhibit afﬁnity,
allowing the system to scale well.
• We have implemented a working prototype of CloudPD,
and performed comprehensive evaluations on 28 VMs with
cloud representative benchmarks – Hadoop, Olio, and RUBiS,
where CloudPD diagnosed faults with low false positives (<
16% on average) and high accuracy of 88%, 83% and 83%,
respectively. In another enterprise trace-driven case study on
an IaaS cloud testbed, CloudPD achieved an accuracy of
77%, with high recall and precision, and fewer false alarms.
Furthermore, CloudPD can suggest the required remediation
actions to the cloud resource manager within 30 seconds.
II. BACKGROUND
In this section, we present an overview of related work
in the context of problem determination and diagnosis, then
discuss how CloudPD interfaces with a cloud ecosystem, and
addresses the new challenges posed by cloud environments.
A. Related Work
We categorize the prior works according to the techniques
used and existing frameworks for problem determination.
Core problem determination techniques: Problem determi-
nation techniques can essentially be classiﬁed into:
(a) Threshold-based schemes: Thresholds are set on system and
application performance metrics based on historical observa-
tions of an application behavior and an alarm is raised if any
threshold is violated. This approach forms the basis of many
commercial (like IBMTivoli, HPOpenview) and open source
(like Ganglia, Nagios) monitoring tools. However, it is unsuit-
able for environment with dynamic changes, is susceptible to
high false alarm rates, and is expected to perform poorly in
the context of large scale utility clouds [10].
(b) Statistical machine learning techniques: A popular ap-
proach in problem determination is to use statistical techniques
to build a performance model of the system under normal
behavior and ﬂag deviations as anomalies [11], [14]–[16].
Performance models can be built reliably in a scalable fashion.
Recently, application-based correlation [4], [17] as well as
peer-based correlation [12] methods have been proposed as
effective ways to capture the performance invariants, and
variations from the modeled correlation are being treated as
anomalies. Correlation invariants are effective, but are expen-
sive to learn, and require large training data, especially for
non-linear correlations. Peerwatch [12] uses canonical correla-
tion analysis for identifying underlying correlations. However,
this technique only works for positive correlations. Zhang et
al. [18] leverage an ensemble of models to address variations
in an underlying model (performance or correlation-based) that
may change with time due to ﬂuctuation in workload intensity
or mix, software or hardware updates. Similarly, Cherkasova
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 07:43:49 UTC from IEEE Xplore.  Restrictions apply. 
et al. [15] identify an application change using two different
models for a given time period, leading to higher accuracy.
Problem determination frameworks: EbAT [10] is a sys-
tem for anomaly identiﬁcation in data centers, which ana-
lyzes system metric distributions rather than individual metric
thresholds. Vigilant [19] is an out-of-band, hypervisor-based
failure monitoring scheme for VMs that uses machine learning
to identify faults in the VMs and guest operating system
(OS). DAPA [13] is an initial prototype of an application
performance diagnostic framework for virtualized environ-
ments. PREPARE [9] is a recently proposed framework for
performance anomaly prevention in virtualized clouds, which
integrates online anomaly detection and predictive prevention
measures to minimize the performance impact of anomalies.
All the above prior works, in the context of virtualized environ-
ments, address detecting application or OS related anomalies,
but do not focus on detecting anomalies that arise due to cloud
activities and virtualization artifacts such as VM migration,
VM resizing, and VM collocation, which is a key contribution
and focus of this work. Moreover,
the above frameworks
have only addressed in isolation either one or two of the
components of a cloud ecosystem (see Figure 2), whereas
CloudPD integrates them together in an efﬁcient infrastructure.
B. End-to-end Problem Determination in a Cloud Ecosystem
IaaS cloud management systems are autonomic and contin-
ually optimize the cloud infrastructure to adapt to different
workload variations. Since future management actions in a
cloud are dependent on the outcome of previous actions, the
cloud management stack should be made aware of any faults
that happen as a result of these events. Hence, a problem
determination system in a cloud needs to be autonomic and
provide fault remediation actions for cloud related faults.
MONITORING
DATABASE
Usage
Data
Workload
Change
MONITORING
ENGINE
WORKLOAD
PROFILES
CloudPD
Trigger,
Guidance
CLOUDRM
System
  Errors
Application
Errors
SYSTEM
   ADMIN 
App
VM1
App
VM2
App
VM3
App
VM i
App
VM n
VIRTUALIZATION LAYER
SERVER
STORAGE
NETWORK
Figure 2: System Context for CloudPD.
However, virtualization does not allow reservation of resources
that are not traditionally managed by operating systems, such
as cache, network and I/O bandwidth. Due to the shared nature
of these resources, an application may witness a change in
performance if VMs are dynamically conﬁgured (i.e., added or
removed) on a physical server hosting the workload. Hence,
clouds introduce collocation faults, where an application ex-
periences a performance anomaly due to collocated VMs.
The second aspect of interest is the continual reconﬁgurations
happening in a cloud. Two particular reconﬁguration actions
are relevant in terms of performance anomalies: (i) CloudRM
uses prediction to estimate VM sizes [20] and resizes a VM
based on the estimate. An error in prediction may lead to a VM
being allocated fewer resources than it requires, leading to a
VM resizing fault; and (ii) CloudRM uses VM live migration
for effective workload consolidation to achieve better power
and network efﬁciency. VM live migration can similarly lead
to performance degradation [21]. During VM live migration,
all memory pages are marked as ready-only and writes result
in faults. Hence, the performance of write-intensive workloads
can suffer during live migration. Further, a live migration
requires signiﬁcant amount of CPU, and this can have an
impact on performance or lead to failed live migrations.
Clouds introduce new fault types that need to be distinguished
from traditional application faults. However, they pose more
fundamental challenges for problem determination. Problem
determination in traditional distributed systems has always fo-
cused on one application at a time [8]. Collocation faults imply
that the model for normal behavior of an application needs to
be learned in the context of other collocated applications. Com-
bined with VM live migration, it implies that this model needs
to be learned in the context of all possible sets of applications
that can be collocated with a target application. In a cloud
with thousands of applications, creating such a large ensemble
of models is clearly infeasible. Similarly, since resources
allocated to a VM can change (by dynamic VM resizing),
none of the thresholding techniques [11] can be applied.
Correlation based models are typically more stable and can be
effectively applied. However, the number of relevant pair-wise
correlations are exponential in a cloud, where any application
can be impacted by any other collocated application. Finally,
a cloud problem determination system (like CloudPD) needs
to integrate with the cloud management
infrastructure and
update any collocation errors as changes in workload proﬁle.
If any VM has been wrongly sized, CloudPD needs to trigger
CloudRM to estimate the new sizes for the VM. Similarly, any
faulty live migrations should be communicated as guidance
to CloudRM for future conﬁguration actions. Application and
system errors are handled by notifying system administrators.
The cloud ecosystem imposes a need for not just fault detection
but diagnosis and automated remediation.
Figure 2 captures the system context in which a cloud prob-
lem determination system needs to operate. A Cloud Resource
Manager (CloudRM) periodically reconﬁgures the cloud using
the monitored system, application data, and workload pro-
ﬁles. The monitored data is used to estimate the resource
requirements and the workload proﬁles are used to identify
the workloads that are conﬂicting. The reconﬁguration events
are passed to the virtualization layer for further actions.
There are two aspects of a cloud ecosystem that merit
attention. First, IaaS clouds use multi-tenancy to ensure that
compute resources are efﬁciently utilized. Multi-tenancy is
supported by reserving CPU and memory for individual VMs.
III. CloudPD ARCHITECTURE
A. Design Decisions
This section describes the architecture of CloudPD, which is
based on the following three key design choices:
• Include Operating Context in the Performance Model:
One of the key ideas in CloudPD is to include the operating
context of a workload in its performance model to capture
the impact of other collocated applications in a scalable
fashion. The most natural choice for an operating context is
the set of collocated applications for each VM. However, the
number of possible operating contexts for just one application
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 07:43:49 UTC from IEEE Xplore.  Restrictions apply. 
is exponential in the number of other VMs in the cloud
(e.g., 10005 for VM density of 6 with 1000 VMs). The
hypothesis which we made here is that including only the host
metrics in the operating context may reasonably approximate
the impact of collocated VMs. If multiple VMs have the
same collocation impact on our target application, this idea
merges all VMs into a common operating context, drastically
reducing the number of operating contexts. We deﬁne an
operating context for a VM to include the (i) host metrics; and
(ii) impacted metrics. Impacted metrics are deﬁned as those
which are affected by the environment and include L1/L2
cache misses, context switches, page faults, etc. Host metrics
include the resource metrics (CPU, memory) and impacted
metrics for the physical server hosting the VM. Figure 3
illustrates an example of the effectiveness of this canonical
representation. For both an anomalous VM migration interval
and a normal interval, the CPU and memory usage of a VM
are nearly the same. However, the distinction that allows
CloudPD to identify a migration fault is primarily in the cache
misses experienced at the server, hosting the VM.
VM−CPU
VM−Memory
Host−cache−miss
VM−CPU
VM−Memory
Host−cache−miss
e
g
a
s