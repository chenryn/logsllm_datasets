 count   
-------  
     0  
(1 row)  
Time: 0.831 ms  
postgres=# select sum(cnt) from cnt_a ;  
 sum   
-----  
   0  
(1 row)  
Time: 1.354 ms  
```  
五、优化  
当并行的超过1001时, 或者以及明显感觉到行锁冲突时, 可以通过实时增加cnt_a表的记录来达到缓解行锁冲突的目的.  
不需要中断业务, 但是必须注意cnt_a表的id必须连续, 并且cnt的初始值必须为0. 不要出现空档. 否则使用以上触发器函数会出现数据不准确的现象.  
例如 :   
```  
pgbench -M prepared -r -n -f ./id.sql -h $PGDATA -p 1919 -U postgres -T 60 -c 16 -j 4 postgres  
```  
在测试的同时添加维度记录  
```  
postgres=# insert into cnt_a (id,cnt) select generate_series(1001,2000),0;  
INSERT 0 1000  
```  
测试完后检查是否准确, 测试新增的cnt_a.id是否有计数.  
```  
postgres=# select count(*) from a;  
  count    
---------  
 1283144  
(1 row)  
postgres=# select sum(cnt) from cnt_a ;  
   sum     
---------  
 1283144  
(1 row)  
postgres=# select sum(cnt) from cnt_a where id>1000;  
  sum     
--------  
 623957  
(1 row)  
```  
如果要避免不准确的现象, 除了cnt_a.id连续, 还可以在触发器函数中添加一个异常捕获.  
```  
CREATE OR REPLACE FUNCTION public.tg_insert_a()  
 RETURNS trigger  
 LANGUAGE plpgsql  
AS $function$  
declare  
  m_id int;  
  rm numeric;  
  new_cnt int;  
begin  
  select max(id),random() into m_id,rm from cnt_a;  
  update cnt_a set cnt=cnt+1 where id=(rm*m_id)::int returning cnt into new_cnt;  
  if not found or new_cnt is null then   
    raise exception '';  
  end if;  
  return null;  
end;  
$function$;  
CREATE OR REPLACE FUNCTION public.tg_delete_a()  
 RETURNS trigger  
 LANGUAGE plpgsql  
AS $function$  
declare  
  m_id int;  
  rm numeric;  
  new_cnt int;  
begin  
  select max(id),random() into m_id,rm from cnt_a;  
  update cnt_a set cnt=cnt-1 where id=(rm*m_id)::int returning cnt into new_cnt;  
  if not found or new_cnt is null then   
    raise exception '';  
  end if;  
  return null;  
end;  
$function$;  
```  
测试 :   
插入cnt=null的非法值, 看看会不会捕获异常, 看看结果是否正确.  
```  
postgres=# insert into cnt_a (id,cnt) select 2001,null;  
INSERT 0 1  
```  
测试pgbench  
```  
pg92@digoal-PowerEdge-R610-> pgbench -M prepared -r -n -f ./id.sql -h $PGDATA -p 1919 -U postgres -T 60 -c 16 -j 4 postgres  
Client 13 aborted in state 2: ERROR:    
Client 6 aborted in state 2: ERROR:    
Client 8 aborted in state 2: ERROR:    
Client 1 aborted in state 2: ERROR:    
Client 0 aborted in state 2: ERROR:    
Client 2 aborted in state 2: ERROR:    
Client 7 aborted in state 2: ERROR:    
Client 11 aborted in state 2: ERROR:    
Client 4 aborted in state 2: ERROR:    
Client 3 aborted in state 2: ERROR:    
Client 9 aborted in state 2: ERROR:    
Client 12 aborted in state 2: ERROR:    
Client 10 aborted in state 2: ERROR:    
Client 14 aborted in state 2: ERROR:    
Client 15 aborted in state 2: ERROR:    
Client 5 aborted in state 2: ERROR:    
transaction type: Custom query  
scaling factor: 1  
query mode: prepared  
number of clients: 16  
number of threads: 4  
duration: 60 s  
number of transactions actually processed: 54704  
tps = 7617.195278 (including connections establishing)  
tps = 7632.604983 (excluding connections establishing)  
statement latencies in milliseconds:  
        0.003084        \setrandom id 1 20000000  
        0.184270        delete from a where id=:id;  
        0.366083        insert into a (info) values ('test');  
```  
结果校验, 加了异常捕获, 所以结果正确.  
```  
postgres=# select sum(cnt) from cnt_a;  
   sum     
---------  
 1334221  
(1 row)  
postgres=# select count(*) from a;  
  count    
---------  
 1334221  
(1 row)  
```  
插入不连续的id, 看看是否可以捕获异常, 比对结果是否准确  
直接跳过1000条, 导致id不连续. random()*max_id将有可能取到无记录的情况. 所以会出现not found, 捕获这个异常  
```  
postgres=# insert into cnt_a (id,cnt) select 3001,null;  
INSERT 0 1  
```  
如下pgbench实际每个连接平均只处理了28条, 看看结果是否正确  
```  
pg92@digoal-PowerEdge-R610-> pgbench -M prepared -r -n -f ./id.sql -h $PGDATA -p 1919 -U postgres -T 60 -c 16 -j 4 postgres  
Client 0 aborted in state 1: ERROR:    
Client 3 aborted in state 2: ERROR:    
Client 13 aborted in state 2: ERROR:    
Client 14 aborted in state 2: ERROR:    
Client 7 aborted in state 2: ERROR:    
Client 2 aborted in state 2: ERROR:    
Client 8 aborted in state 2: ERROR:    
Client 4 aborted in state 2: ERROR:    
Client 5 aborted in state 2: ERROR:    
Client 10 aborted in state 2: ERROR:    
Client 6 aborted in state 1: ERROR:    
Client 1 aborted in state 1: ERROR:    
Client 9 aborted in state 2: ERROR:    
Client 11 aborted in state 2: ERROR:    
Client 15 aborted in state 2: ERROR:    
Client 12 aborted in state 2: ERROR:    
transaction type: Custom query  
scaling factor: 1  
query mode: prepared  
number of clients: 16  
number of threads: 4  
duration: 60 s  
number of transactions actually processed: 28  
tps = 801.167415 (including connections establishing)  
tps = 1372.515380 (excluding connections establishing)  
statement latencies in milliseconds:  
        0.004773        \setrandom id 1 20000000  
        1.731136        delete from a where id=:id;  
        2.530098        insert into a (info) values ('test');  
```  
结果正确  
```  
postgres=# select sum(cnt) from cnt_a;  
   sum     
---------  
 1334246  
(1 row)  
postgres=# select count(*) from a;  
  count    
---------  
 1334246  
(1 row)  
```  
## 优化阶段1
1\. 使用这种方法带来来优化count(*), 如果insert和delete本来就不是系统瓶颈的话, 是值得提倡的.  
2\. random()函数为volatile属性, 所以同一个事务中多次调用时需要多次运算. rm*max_id势必得到不同的id.  
```  
postgres=# select provolatile from pg_proc where proname='random';  
 provolatile   
-------------  
 v  
(1 row)  
```  
因此可以想象一下.  
2\.1\. random()多次运算比一次运算的开销大  
2\.2\. 由于每次得到的id不一样, 如果是批量插入的话, 一个事务中将会锁cnt_a表的多行, 这种场景容易产生死锁.  
要解决这个问题, 可以尝试使用stable或者immutable随机函数. 那么一个事务中多次调用的话都将得到同一个值, 减少了运算量同时也避免了以上场景中死锁的产生. 实现方法是使用advisory lock, 如下 :   
新增pid和lock_time用来记录会话pid和事务启动时间.  
```  
postgres=# alter table cnt_a add column pid int;  
ALTER TABLE  
Time: 18.649 ms  
postgres=# alter table cnt_a add column lock_time timestamp;  
ALTER TABLE  
Time: 1.018 ms  
postgres=# \d cnt_a  
                  Table "public.cnt_a"  
  Column   |            Type             |   Modifiers     
-----------+-----------------------------+---------------  
 id        | integer                     | not null  
 cnt       | integer                     |   
 pid       | integer                     |   
 lock_time | timestamp without time zone |   
Indexes:  
    "cnt_a_pkey" PRIMARY KEY, btree (id)  
```  
创建插入触发器函数  
```  
CREATE OR REPLACE FUNCTION public.tg_insert_a()  
 RETURNS trigger  
 LANGUAGE plpgsql  
AS $function$  
declare  
  m_id int;  
  a_lock boolean;  
  rm numeric;  
  max_id int;  
  new_cnt int;  
begin  
  -- now()为stable, 同一事务结果一致.  
  select id into m_id from cnt_a where pid=pg_backend_pid() and lock_time=now() limit 1;  
  if found then   
    update cnt_a set cnt=cnt+1 where id=m_id returning cnt into new_cnt;  
    if new_cnt is null then   
      raise exception 'cnt_a.cnt is null, please init with zero.';  
    end if;  
    return null;  
  else  
    -- 1 由于read committed, 并发时可能同时抢锁1条记录. 造成不必要的等待.  
    -- 1 select id into m_id from cnt_a where locked=false limit 1 for update;    
    -- 2 使用这种方法可以减轻锁同一记录的压力,但是增加了查询开销.  
    -- 2 select id into m_id from cnt_a where locked=false order by random() limit 1 for update;    