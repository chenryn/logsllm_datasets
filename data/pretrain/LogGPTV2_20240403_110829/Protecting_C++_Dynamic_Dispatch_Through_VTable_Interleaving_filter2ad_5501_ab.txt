C1: $a = ...
$avptr = load $a
assert (0x20 ≤ $avptr ≤ 0x80)∧($avptr & 0x1f == 0)
$foo_fn = load $avptr
call $foo_fn
C2: $b = ...
$bvptr = load $b
assert (0x40 ≤ $bvptr ≤ 0x60)∧($bvptr & 0x1f == 0)
$bar_fn = load ($bvptr+0x8)
call $bar_fn
Fig. 6: Ordered VTable Range Checks
Class
A
B
C
D
Set of Runtime Types
A,B,C,D
B,D
C
D
Start
0x20
0x40
0x80
0x60
End Alignment
0x80
0x60
0x80
0x60
0x20
0x20
0x20
0x20
Fig. 7: Valid Address Point Ranges for Ordered VTables
range checks as shown in Figure 6. The correct ranges for all
classes in Figure 5 are shown in Table 7.
It is crucial to align vtables and perform the alignment
checks, since otherwise the range check by itself would not
catch vptrs that (incorrectly) point into the middle of a vtable.
We choose alignment as the method for preventing middle-of-
vtable pointers because as we will show in Section VI, we can
perform such alignment checks very efﬁciently. The alignment
size is 2n for the smallest n such that 2n is larger than the
largest vtable, which allows us to ﬁt any vtable between two
alignment points, and thus place address points in memory at
2n intervals.
Note that in our example (Figure 5) we cannot immediately
start laying out vtables at offset 0. This is due to the fact that
address points are generally not the ﬁrst entry in a vtable but
we want precisely address points to be aligned modulo a power
of 2. In particular, since Afoo is the 2nd entry in A’s vtable,
we need to add 0x18 bytes of padding before A’s vtable, so
that Afoo ends up being a multiple of 0x20.
V. VTABLE INTERLEAVING
VTable ordering provides an efﬁcient way of checking
set membership for cones of the class hierarchy. However,
the ordering approach imposes a signiﬁcant memory overhead
(as discussed further in Section X): every vtable in the same
class hierarchy must be padded up to the smallest power of 2
larger than the size of the biggest vtable. This overhead can
be especially problematic in memory constrained environment
such as mobile and embedded development.
To reduce this memory overhead, we introduce another
technique, which is far more radical than the ordering idea:
we make vtables sparse and interleaved in such a fashion that
no space will be wasted, and address points will end up being
consecutive entries in memory. As we will see shortly, the
new layout of vtables will be very different than a traditional
layout, but quite surprisingly will still be compatible with the
traditional technique of doing dynamic dispatch.
4
Fig. 5: Ordered Vtable Layout in Memory
ment check. These checks are very efﬁcient and their overhead
is independent of the size of the set being checked.
Our vtable layout is motivated by the observation that the
sets of classes to be checked are not arbitrary. Instead these
sets are all so-called cones in the class hierarchy, namely a set
containing a given class and all of its subclasses.
As a result, our ﬁrst key idea is to order the vtables in
memory using a pre-order traversal of the class hierarchy.
This places all the vtables belonging to a cone continuously in
memory. In addition, if we align the vtables appropriately, this
ordering allows us to check cone membership using a simple
range check modulo alignment. Section IV will present this
ordering technique, called OVT (Ordered VTables).
Although this ordering gives us the range checks we want,
it has high memory overhead because of the additional padding
required for alignment. As a result, our second key idea is to
interleave the vtables in such a way that padding is not required
anymore. Section V will present this interleaving technique,
called IVT (Interleaved VTables).
Throughout the following sections, we present OVT and
IVT through our running example. We then show how to efﬁ-
ciently implement the checks, and then how to handle complex
cases like multiple inheritance and virtual inheritance. Finally,
we will present the detailed algorithms for our approach.
IV. VTABLE ORDERING
Figure 5 presents an ordered vtable layout for our running
example from Figure 1. The vtables are ordered by a preorder
traversal order of the class hierarchy (resulting in C and D
being switched). Given this new layout, the vtables of any
cone (subtree) in the class hierarchy are laid out consecutively.
Furthermore, padding has been added so that all vtable address
points are 32 byte aligned (multiples of 0x20). Thus, in the
new memory layout, the valid vptrs for a variable of static
type C are the vtables for classes in the cone rooted at C,
and these vtables are precisely the 32-byte aligned entries in a
given range. The two checks from Figure 4b become aligned
VTable Entry Old Offset New Offset
-0x20
rtti
foo
bar
boo
baz
-0x8
0
0x8
0x10
0x8
0
0x18
0x20
0x20
Fig. 10: New Method Offsets
C1: $a = ...
$avptr = load $a
assert (0x20 ≤ $avptr ≤ 0x38)∧($avptr & 0x7 == 0)
$foo_fn = load $avptr
call $foo_fn
C2: $b = ...
$bvptr = load $b
assert (0x28 ≤ $bvptr ≤ 0x30)∧($bvptr & 0x7 == 0)
$bar_fn = load ($bvptr+0x18)
call $bar_fn
Fig. 11: Interleaved VTable Range Checks
the same in all vtables that deﬁne or overload these two entries.
For example, the additional empty space inserted between foo
and bar is always two “empty” entries, in all vtables that
deﬁne or overload them (B and D in this case). This means
that, although vtable entries in our interleaved layout are now
at different offsets than in a traditional layout, the offsets are
still the same across all vtables which deﬁne or overload them,
which is the property needed for dynamic dispatch. Figure 10
shows the old and new constant offsets for each one of the
vtable entries in our running example. Our implementation
must therefore not only change the vtable layout but also all the
vtable offsets used in code sections for indexing into vtables.
Although here we have only given an intuition of how
our approach works, a detailed algorithm for building vtables
and computing the new offsets, and a formal proof of our
preservation of vtable offsets between parent and child classes
can be found in Section VIII.
Finally, runtime checks for interleaved vtables have exactly
the same form as before – range checks modulo alignment. The
only difference is that, whereas previously the alignment of
ordered vtables varied by vtable, the alignment for interleaved
vtables is always 8 bytes, the size of a vtable entry. A uniform
8-byte alignment
is sufﬁcient because, as can be seen in
Figures 8 and 9, the address points of all vtables are now
contiguous in memory: the address points for A, B, C and D are
all consecutively laid out between 0x20-0x38. For example
the valid address points for B (which are the vtables for B
and its subclass D) are the 8-byte aligned values in the range
0x28-0x30. As another example, the valid address points for
A (which are the vtables for A and its subclasses, B, C and D)
are the 8-byte aligned values in the range 0x20-0x38.
The corresponding checks for IVTs for our example in
Figure 4 are shown in Figure 11. The set of ranges for all
classes in our example hierarchy is shown in Table 12. Note
that unlike previous ﬁne-grained vtable protection work [16],
[22] the overhead of our runtime checks is independent from
the size and complexity of the class hierarchy.
Fig. 8: Sparse and Interleaved VTables
Fig. 9: Interleaved Vtable Layout in Memory
Continuing with our running example, Figure 8 presents
the corresponding interleaved layout for the Ordered VTables
from Figure 5. We have spread the vtable entries in separate
columns to highlight what original vtable each entry belongs
to. Figure 9 shows another view of the interleaved vtables, with
the original vtable membership marked with lines of different
colors.
To better understand how the interleaving works, consider
the interleaved vtable for class D (3rd column in Figure 8). This
vtable is equivalent to the original vtable, except that 3 empty
entries have been inserted between Drtti and Dfoo, and 2
empty entries have been inserted between Dfoo and Bbar
(in D’s vtable). These additional entries are “empty” from the
point of view of D’s vtable, but in the ﬁnal memory layout
they are ﬁlled with entries from other interleaved vtables.
The number of empty spaces to insert between two entries
is the key to getting the different interleaved vtables to “grid-
lock” together perfectly. The number of empty spaces inserted
between two entries of an original vtable is determined by the
shape of the class hierarchy and the number of new methods
deﬁned by each class in the hierarchy. Note that this can vary
for different pairs of entries in a single vtable.
One very important property of our interleaved layout is
that the amount of space inserted between two entries is always
5
Class
A
B
C
D
Set of Runtime Types
A,B,C,D
B,D
C
D
Start
0x20
0x28
0x38
0x30
End Alignment
0x38
0x30
0x38
0x30
0x8
0x8
0x8
0x8
Fig. 12: Valid Address Point Ranges for Interleaved VTables
...
cmp $vptr, $a
jlt FAIL
cmp $vptr, $b
jgt FAIL
and $vptr, 1111l
cmp $vptr, 0
jne FAIL
... // Success
(a) 3-branch check
...
and $vptr, 1...164−l0...0l
cmp $vptr, $a
jlt FAIL
cmp $vptr, $b
jgt FAIL
... // Success
(b) 2-branch check
Fig. 13: Naive Range Check Implementation
VI. RANGE CHECK OPTIMIZATION
We implement 3 further optimizations to reduce the cost
of range checks. These optimizations are adapted from similar
optimizations in the implementation of forward-edge CFI in
LLVM [22].
A. Single Branch Range Checks
Both IVT and OVT rely on an efﬁcient check of the form
“is value v in a range [a, b] and aligned modulo 2l ?”. In the
case of OVT each tree in the decomposed hierarchy has its
own speciﬁc l. For Interleaved VTables, we always have l = 3
(i.e. we maintain that candidate vptr values are aligned modulo
the size of a vtable entry).
A naive implementation of this check requiring 3 branches
is presented in Figure 13a. Code is presented in a simpli-
ﬁed assembly where cmp represents the unsigned compari-
son operator, jlt jgt and jne denote “jump-if-less-than”,
“jump-if-greater-than” and “jump-if-not-equal” respectively,
and and represents the bitwise and operator. The 3 branches
in Figure 13a respectively check whether $vptr is below
the desired range, above it, or not properly aligned. We can
eliminate the last branch by enforcing alignment rather than
checking for it as shown in Figure 13b. This however still
requires 2 branches.
We perform both the range and alignment check with a
single branch using the instruction sequence in Figure 14, a
technique we adapted from the LLVM 3.7 forward-edge CFI
implementation [22]. Here rotr $v, l signiﬁes the right bit
rotation of $v by l bits.
To see how the code in Figure 14 is equivalent to the
original range and alignment check, we will show that it fails
in all cases when the original check does - when $vptr >
$b, when $vptr  $b then ($vptr-$a)
> ($b-$a) and therefore $diff > ($b-$a) and ﬁ-
nally ($diff >> l) > (($b-$a) >> l). For unsigned
comparisons (rotr $diff, l) ≥ ($diff >> l), and
6
...
$diff = $vptr - $a
$diffR = rotr $diff, l
cmp $diffR, ($b-$a) >> l
jgt FAIL
... // Success
Fig. 14: Range Check Implementation
therefore $diffR ≥ ($diff >> l) > (($b-$a) >>
l). Therefore in this case we will fail the check.
If $vptr > l) can be set. Therefore, since the compar-
ison is unsigned again we fail the check.
If $vptr is between $a and $b, and any of its l lowest
bits is set, then after the rotation we will fall in the previous
case and again fail the check.
Finally if $vptr is between $a and $b and l bit
to $diff
the check
aligned, rotr $diff, l becomes equivalent
>> l. Since no arithmetic operations overﬂow,
succeeds in this case.
Thus we have reduced our runtime check to a shorter
instruction sequence, containing a single branch that is never
taken during normal program execution (unlike [16]). In the
future, our enforcement check can be further sped up by using
hardware acceleration through the Intel MPX bounds checking
instructions coming in the Skylake architecture [15].
B. Single Value Ranges
When a given range contains a single value the aligned
range check can be reduced to an equality check. Tradition-
ally one would expect all such cases to be devirtualized by
earlier compiler optimizations. However, as we will discuss in
Section X we observe singleton ranges surprisingly often. We
believe that this discrepancy is due to the fact that LLVM’s
optimizer does not implement a C++ speciﬁc devirtualization
pass. LLVM’s optimizations are aimed to be language agnostic
and devirtualization happens as the result of several simpler
optimizations including Global Value Numbering and Constant
Load Elimination. Each of those relies only on the information
available at
the LLVM IR level. We on the other hand
implement a C++ speciﬁc IR transformation, that leverages
C++ metadata propagated down to our optimization passes.
Furthermore our transformations work in a fully statically
linked setting, and thus assume that the whole class hierarchy
is known at link time. Note that we could actually optimize
this case further by devirtualizing these single target calls that
LLVM does not optimize.
C. Constant Vptrs
We have observed a small percentage of cases where a
vptr can be statically checked. In such cases the safety of
the virtual call can be discharged statically, and no runtime
check is needed. We believe such instances arise when short
constructors are inlined into larger functions. At that point,
the address pointer becomes available as a constant value in