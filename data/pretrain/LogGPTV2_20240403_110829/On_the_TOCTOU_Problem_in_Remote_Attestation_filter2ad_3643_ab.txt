execute instructions in place (physically from program memory)
and have no memory management unit (MMU) to support virtual
memory.
Our implementation is based on MSP430. This choice is due
to public availability of a well-maintained open-source MSP430
hardware design from Open Cores [19]. Nevertheless, our machine
model and the entire methodology developed in this paper are appli-
cable to other low-end MCUs in the same class, such as Atmel AVR
ATmega. RAT A main implementation is composed with VRASED,
a publicly available verified hybrid RA architecture [10], which
allows us to demonstrate security. Despite our specific implementa-
tion choices, we believe that RAT A concepts are also applicable to
other RA architectures. To support this claim, Appendix D describes
RAT A implementation atop SANCUS [20]: a hardware-based RA
architecture also targeting low-end devices. See Section 9 for an
overview of various RA architectures.
Detection, Prevention & Memory Immutability: As a detection-
oriented security service, RA does not prevent future binary mod-
ifications. Therefore, the term TOCTOU should be considered in
retrospective. In particular, techniques presented in this paper al-
low Vrf to understand “since when” Prv memory remained the
same as reported in the present RA result.
While malware infections can be trivially prevented by mak-
ing all executable memory read-only (e.g., storing code in ROM),
such a drastic approach would sacrifice reconfigurability by mak-
ing legitimate software updates impossible and would essentially
transform the MCU into an Application-Specific Integrated Circuit
(ASIC). However, reconfigurability is one of the most important
MCU features, perhaps even its entire “raison d’être".
A less drastic approach is to prevent program memory mod-
ifications that occur at runtime. This approach is vulnerable to
physical attacks, whereby an adversary re-programs Prv directly.
More importantly, (even if we rule out physical attacks) it makes
remote updates impossible, requiring physical access whenever a
device software needs to be updated. Since these devices are often
remote or are physically inaccessible (inside a larger system, e.g.,
a vehicle) low-end MCUs (including aforementioned MSP430 and
ATMega) typically do not prevent modifications to program mem-
ory. Our detection-based approach conforms with that, allowing
changes to binaries and reporting them to Vrf: even if they happen
between consecutive RA instances. Since Vrf is informed about
all binary changes on Prv, it can distinguish illegal modifications
from expected ones.
3 BACKGROUND & DEFINITIONS
3.1 Device Model & MCU Assumptions
We now overview MCU assumptions relevant to RAT A. They reflect
the behavior of the class of low-end embedded systems discussed
in Section 2 and are in accordance with previous work on securing
low-end MCUs [1, 6, 7, 10, 21]. In particular, we assume that MCU
hardware correctly implements its specifications, as follows:
A1 – Program Counter (PC): PC always contains the address of
the instruction being executed in a given CPU cycle.
A2 – Memory Address: Whenever memory is read or written, a
data-address signal (Daddr ) contains the address of the correspond-
ing memory location. For a read access, a data read-enable bit (Ren)
must be set, while, for a write access, a data write-enable bit (Wen)
must be set.
A3 – DMA: Whenever the Direct Memory Access (DMA) controller
attempts to access the main system memory, a DMA-address sig-
nal (DMAaddr ) reflects the address of the memory location being
accessed and the DMA-enable bit (DMAen) is set. DMA can not
access memory without setting DMAen.
A4 – MCU Reset: At the end of a successful reset routine, all regis-
ters (including PC) are set to zero before resuming normal software
execution flow. Resets are handled by the MCU in hardware. Thus,
the reset handling routine can not be modified. When a reset hap-
pens, the corresponding reset signal is set. The same signal is also
set when the MCU initializes for the first time.
A5 – No Data Execution: Instructions must reside (physically) in
program memory (PMEM) in order to execute. They are not loaded
to DMEM to execute. Data execution is impossible in most low-end
devices, including OpenMSP430 used in our prototype. For example,
in Harvard-based low-end devices (e.g., AVR Atmega), there is no
hardware support to fetch/execute instructions from data memory
(DMEM). In other low-end devices that do not prevent data execu-
tion by default, this is typically enforced by the underlying hybrid
RA architecture. Therefore, even if malware resides in DMEM, it
must be copied to, and thus reside in, PMEM before executing.
Session 11A: Attestation and Firmware Security CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea2923Adversarial Model
3.2 RA Definitions, Architectures &
As discussed in Section 1, RA is typically realized as a challenge-
response protocol between Vrf and Prv. This notion is captured
by a generic syntax for RA protocols in Definition 3.1.
Definition 3.1 (syntax). RA is a tuple (Request, Attest, Verify) of algorithms:
• RequestVrf→Prv( · · · ): algorithm initiated by Vrf to request a mea-
surement of Prv memory range AR (attested range). As part of
Request, Vrf sends a challenge Chal to Prv.
• AttestPrv→Vrf (Chal, · · · ) : algorithm executed by Prv upon receiv-
ing Chal from Vrf. Computes an authenticated integrity-ensuring
function over AR content. It produces attestation token H, which is
returned to Vrf, possibly accompanied by auxiliary information to
be used by the Verify algorithm (see below).
• VerifyVrf (H, Chal, M, · · · ) : algorithm executed by Vrf upon re-
ceiving H from Prv. It verifies whether Prv current AR content
corresponds to some expected value M (or one of a set of expected
values). Verify outputs: 1 if H is valid, and 0 otherwise.
Note: In the parameter list, (· · · ) denotes that additional parameters might be
included, depending on the specific RA scheme.
Definition 3.1 specifies RA as a tuple (Request, Attest,Verify).
Request is computed by Vrf to produce challenge Chal and send
it to Prv. Attest is performed by Prv by using Chal to compute an
authenticated integrity-ensuring function (e.g., MAC) over attested
memory range (denoted by AR) and producing H, which is sent
back to Vrf for verification. For example, if Attest is implemented
using a MAC, H is computed as:
H = HMAC(KDF(K, Chal), AR)
(1)
where KDF denotes a key derivation function and K is a symmet-
ric key shared by Prv and Vrf. Upon receiving H, Vrf executes
algorithm Verify by checking if H corresponds to the MAC of some
expected value M.
Although techniques discussed in this paper are not tied to a spe-
cificRA architecture, we chose to compose RAT A with VRASED [10].
Our choice is motivated by VRASED formal security definitions,
which allow reasoning about RAT A secure composition with the
underlying RA architecture; see Theorems 5.1 and 6.1. We overview
VRASED next.
VRASED is a formally verified hybrid RA architecture, based on a
hardware/software co-design. It is built as a set of sub-modules, each
guaranteeing a specific set of sub-properties. Every sub-module
(hardware or software) is individually verified. Finally, composition
of all sub-modules is proved to satisfy formal definitions of RA
soundness and security. Informally, RA soundness guarantees that
an integrity-ensuring function (HMAC in VRASED) is correctly
computed over attested memory range (AR). It also guarantees that
AR can not be modified after the start of RA computation, thus
enforcing temporal consistency and protecting against “hide-and-
seek” attacks during RA computation [22]. RA security ensures
that RA execution generates an unforgeable authenticated memory
measurement and that K used in computing this measurement is
not leaked before, during, or after, attestation.
To achieve its aforementioned goals, VRASED software part
(SW-Att) resides in Read-Only Memory (ROM) and relies on a formally
verified HMAC implementation from the HACL* cryptographic li-
brary [23]. A typical SW-Att execution proceeds as follows:
(1) Read challenge Chal from a fixed memory region denoted
by MR.
(2) Use a Key Derivation Function (KDF) to derive a one-time key
from Chal and the attestation master key K: KDF(K, MR)
(where MR = Chal).
(3) Attest implementation (SW-Att) generates attestation token
H by computing an HMAC over an attested memory region
AR using the newly derived key:
H = HMAC(KDF(K, MR), AR)
(4) Overwrite MR with the result H and return execution to
unprivileged software, i.e, the normal application(s).
VRASED Hardware (HW-Mod) monitors 7 distinct MCU signals:
• PC: Current Program Counter value;
• Ren: Signal that indicates if the MCU is reading from memory
(1-bit);
• Wen: Signal that indicates if the MCU is writing to memory
(1-bit);
• Daddr : Address for an MCU memory access;
• DMAen: Signal that indicates if Direct Memory Access (DMA)
is currently accessing memory (1-bit);
• DMAaddr : Memory address being accessed by DMA.
• irq: Signal that indicates if an interrupt is happening (1-bit);
These signals determine a one-bit reset signal output, that, when
set to 1, triggers an immediate system-wide MCU reset, i.e., be-
fore executing the next instruction. The reset output is triggered
when VRASED hardware detects any violation of security prop-
erties. VRASED hardware is described in Register Transfer Level
(RTL) using Finite State Machines (FSMs). Then, NuSMV Model
Checker [24] is used to automatically prove that FSMs achieve
claimed security sub-properties. Finally, the proof that the conjunc-
tion of hardware and software sub-properties implies end-to-end
soundness and security is done using an LTL theorem prover.
Definition 3.2. VRASED Security Game (Adapted from [10])
Notation:
- l is the security parameter and |K| = |Chal| = |MR| = l
- AR(t) denotes the content of AR at time t
RA-game:
(1) Setup: Adv is given oracle access to Attest (SW-Att) calls.
(2) Challenge: A challenge Chal is generated by calling Request (Defi-
nition 3.1) and given to Adv.
(3) Response: Adv responds with a pair (M, σ), where σ is either a
forgery by Adv, or is the result of calling Attest (Definition 3.1), at
some arbitrary time t.
(4) Adv wins iff M (cid:44) AR(t) and σ = H MAC(K DF(K, Chal), M).
Note: If, as a part of Attest, AR attestation is preceded by a procedure to
authenticate Vrf, t defined in step 3 is the time immediately after successful
authentication, when AR attestation starts.
More formally, VRASED end-to-end security proof guarantees
that no probabilistic polynomial time (PPT) adversary can win the
RA security game in Definition 3.2 with non-negligible probability
in the security parameter l, i.e., Pr[Adv,RA-game] ≤ negl(l).
Remark 1: While aforementioned guarantees ensure consistency of
attested memory during attestation computation, VRASED or any
prior low-end RA scheme is not TOCTOU-Secure, as modifications
Session 11A: Attestation and Firmware Security CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea2924before attestation remain undetected.
Adversarial Model. We consider a fairly strong adversary Adv
that controls the entire software state of Prv, including both code
and data. Adv can modify any writable memory and read any mem-
ory (including secrets) that is not explicitly protected by trusted
hardware. Also, Adv has full access to all DMA controllers, if any
are present on Prv. Recall that DMA allows direct access and mem-
ory modifications without going through the CPU.
Even though Adv may physically re-program Prv software
through wired connection to flash, invasive/tampering hardware at-
tacks are out of scope of this paper: we assume that Adv can not: (1)
alter hardware components, (2) modify code in ROM, (3) induce hard-
ware faults, or (4) retrieve Prv secrets via physical side-channels.
Protection against physical hardware attacks is orthogonal to our
goals and attainable via tamper-resistance techniques [25].
3.3 Linear Temporal Logic (LTL)
Computer-aided formal verification typically involves three ba-
sic steps: First, the system of interest (e.g., hardware, software,
communication protocol) is described using a formal model, e.g.,
a Finite State Machine (FSM). Second, properties that the model
should satisfy are formally specified. Third, the system model is
checked against formally specified properties to guarantee that it
retains them. This can be achieved via either Theorem Proving
or Model Checking. In this work, we use the latter to verify the
implementation of system modules.
In one instantiation of model checking, properties are specified
as formulae using Linear Temporal Logic (LTL) and system models
are represented as FSMs. Hence, a system is represented by a triple
(S, S0,T), where S is a finite set of states, S0 ⊆ S is the set of possible
initial states, and T ⊆ S×S is the transition relation set – it describes
the set of states that can be reached in a single step from each
state. The use of LTL to specify properties allows representation of
expected system behavior over time.
In addition to propositional connectives, such as conjunction (∧),
disjunction (∨), negation (¬), and implication (→), LTL includes
temporal connectives, thus enabling sequential reasoning. In this
paper, we are interested in the following temporal connectives:
• Xϕ – neXt ϕ: holds if ϕ is true at the next system state.
• Fϕ – Future ϕ: holds if there exists a future state where ϕ is
• Gϕ – Globally ϕ: holds if for all future states ϕ is true.
• ϕ U ψ – ϕ Until ψ: holds if there is a future state where ψ
• ϕ W ψ – ϕ Weak until ψ: holds if, assuming a future state
where ψ holds, ϕ holds for all states prior to that. If ψ never
becomes true, ϕ must hold forever. More formally: ϕWψ ≡
(ϕUψ) ∨ G(ϕ)
holds and ϕ holds for all states prior to that.
true.
4 RA TOCTOU
This section defines the notion of TOCTOU-Security for RA. We
start by formalizing this notion using a security game. Next, we
consider the practicality of this problem and overview existing
mechanisms, arguing that they do not achieve TOCTOU-Security
(neither according to TOCTOU-Security definition, nor in practice)
and incur relatively high overhead.
4.1 Notation
We summarize the notation in Table 1.It is mostly consistent with
that in VRASED [10], with a few additional elements to denote
RAT A-specific memory regions and signals. To simplify the nota-
tion, when the value of a given signal (e.g., Daddr ) is within a certain
range (e.g., AR = [ARmin, ARmax]), we write that Daddr ∈ AR, i.e.:
(2)
In conformance with axioms discussed in Section 3.1, we use
Mod_Mem(x) to denote a modification to memory address address
x. Given our machine model, the following logical equivalence