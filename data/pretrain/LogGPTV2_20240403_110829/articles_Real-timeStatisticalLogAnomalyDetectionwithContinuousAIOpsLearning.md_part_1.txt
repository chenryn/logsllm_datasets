### Real-time Statistical Log Anomaly Detection with Continuous AIOps Learning

**Publication Details:**
- **Title:** Real-time Statistical Log Anomaly Detection with Continuous AIOps Learning
- **Type:** Conference Paper
- **Date:** April 2022
- **DOI:** 10.5220/0011069200003200
- **Citations:** 2
- **Reads:** 796
- **Authors:**
  - Lu An (North Carolina State University)
  - Xiaotong Liu (IBM Research-Almaden)
  - Rama Akkiraju (IBM)
- **Content Upload Date:** May 3, 2022
- **Uploaded by:** Lu An

**Keywords:**
- AI for IT Operations
- Log Anomaly Detection
- Online Statistical Learning
- Error Entity Extraction
- Continuous Model Updating

**Abstract:**
Log anomaly detection is a fundamental task in Information Technology Operations (ITOps) management, aimed at identifying abnormal system behaviors and providing insights into the causes and nature of system failures. Advanced, explainable Artificial Intelligence (AI) models are crucial for confidently assessing, diagnosing, and resolving such issues. This paper introduces a new online log anomaly detection algorithm that significantly reduces the time-to-value for log anomaly detection. The algorithm continuously updates the model during runtime and automatically avoids potential bias from contaminated log data. Our methods have shown an average improvement of 60% in F1-scores across multiple datasets compared to existing methods, demonstrating their effectiveness.

**1. Introduction**

The rapid growth of Information Technology (IT) systems and services has made these systems increasingly complex to operate, manage, and monitor. By leveraging log processing, machine learning, and other advanced analytics, Artificial Intelligence for IT Operations (AIOps) offers a promising solution to enhance the reliability of IT operations. Today, most large-scale service operators use their own AIOps to collect logs, traces, and telemetry data, and analyze this data to improve their offerings (Levin et al., 2019).

One critical task in AIOps is anomaly detection, which is essential for identifying abnormal system behaviors and providing clues about the causes and nature of system failures (Goldberg and Shan, 2015; Gu et al., 2017; Chandola et al., 2009). System logs, which record system states and events at various critical points, are a valuable resource for AIOps. We refer to anomaly detection methods that use logs as the data source as Log Anomaly Detection (LAD).

Traditional LAD methods were primarily manual and rule-based, which are no longer suitable for large-scale IT systems with sophisticated incidents. In recent years, machine learning-based anomaly detection methods, particularly unsupervised clustering-based methods, have gained attention (Givental et al., 2021a; Givental et al., 2021b). However, these methods do not guarantee stable performance and are challenging to apply to streaming log data due to changing log patterns over time.

Another widely used LAD approach involves collecting labeled training data during normal operation, using log templates for feature engineering, and employing Principal Component Analysis (PCA) to learn normal log patterns and detect anomalies (Liu et al., 2020; Liu et al., 2021). While PCA-based methods can be effective, they have limitations. For instance, log template learning requires significant time and customer-provided training data, which may not always be available or pure.

**2. LAD System Description**

**2.1 PCA-based Method**

The PCA-based method, illustrated in Figure 1, includes the following steps:

1. **Log Anomaly Training:**
   - Historical normal log data is ingested from log aggregators or streaming data from Apache Kafka.
   - Data preparation involves preprocessing to generate clean, normalized log data.
   - A tree-based template learning algorithm generates log templates from the selected training logs.
   - These templates are used for feature engineering and building template/embedding count vectors.
   - The count vectors are aggregated and encoded for PCA model training, where the model learns normal patterns and anomaly thresholds.
   - Trained models are stored in the cluster for future inference.

2. **Log Anomaly Detection:**
   - During inference, the data preparation component uses trained log templates to perform feature engineering on streaming log data.
   - The template/embedding count vectors are aggregated and encoded, then sent to the log anomaly detector.
   - The detector retrieves relevant PCA models from the cluster and applies them to the encoded data.
   - Logs with PCA scores exceeding the trained threshold are tagged as anomalies and generate alerts.

**2.2 RSM-based Method**

The RSM-based method, illustrated in Figure 2, eliminates the need for training and includes the following steps:

1. **Data Preparation:**
   - The data preparation component directly applies entity extraction to streaming inference data.
   - Extracted entities are aggregated and encoded to generate feature count vectors.
   - These vectors, along with metadata, are stored in the cluster and sent to the log anomaly detector for inference.

2. **Model Updating:**
   - After a preset period, the LAD retrieves all encoded log data from the cluster and computes statistical distributions for the entities.
   - These distributions are stored as RSM models in the cluster for future anomaly detection.
   - Model updating is periodic and accumulative, ensuring the latest model represents all historical data.
   - An automatic skipping mechanism avoids biased models generated by contaminated log data.

3. **Log Anomaly Detection:**
   - Once initial RSM models are available, the log anomaly detector loads the latest models from the cluster.
   - It performs statistical testing to determine if the inference logs contain significantly different entity or embedding distributions compared to normal patterns.
   - If so, the inference logs are tagged as anomalies and generate alerts.

**3. Design of RSM-based Method**

**3.1 Log Entity Extraction**

The RSM-based LAD pipeline utilizes log entities for feature engineering. These entities can be domain-specific information from specific types of logs, such as those from IBM WebSphere Application Server, or specific errors like HTTP error response codes or exceptions.

**3.1.1 WebSphere Logs**

WebSphere logs contain designated message IDs or log levels, which indicate specific types of abnormal system behaviors. The data preparation component identifies WebSphere logs and extracts message IDs and log levels for feature engineering.

**3.1.2 General Logs**

For non-WebSphere logs, the SystemT framework (Krishnamurthy et al., 2009) is used to define rules for log entity extraction (Mohapatra et al., 2018; Aggarwal et al., 2021; Aggarwal and Nagar, 2021). Sentiment analysis is performed using dictionaries like Vader (Hutto and Gilbert, 2014) and SentiWordNet (Baccianella et al., 2010). Relation and cause extraction identify error codes and exceptions, and determine if a log message indicates erroneous system behavior.

**3.2 Feature Encoding**

To build feature count vectors, logs within a preset time period (e.g., every 10 seconds) are grouped. If the nth entity is extracted from the mth log, denoted as \( e_{m,n} = 1 \), otherwise \( e_{m,n} = 0 \). The feature count vector for the time window \( t \) is constructed as \( X_t = [x_1, x_2, \ldots, x_N] \), where the count of the nth feature is given by:
\[ x_n = \sum_{m=1}^M e_{m,n} \]

**3.3 RSM Model Update**

After connecting streaming logs to the system, LAD starts with an empty statistical model. The model is updated periodically by computing statistical distributions for the entities and storing them as RSM models in the cluster.

**3.4 RSM Anomaly Detection**

RSM anomaly detection consists of two independent methods: entity-based and embedding-based. The entity-based method uses statistical metrics from extracted entities, while the embedding-based method uses metrics from extracted embeddings (Liu et al., 2020). The inference results from both methods are aggregated to produce the final RSM anomaly detection result.

**3.4.1 Entity-based Detection**

In RSM model \( M \), using historical data, we store the sample mean \( \mu_{en} \) and the sample standard deviation.