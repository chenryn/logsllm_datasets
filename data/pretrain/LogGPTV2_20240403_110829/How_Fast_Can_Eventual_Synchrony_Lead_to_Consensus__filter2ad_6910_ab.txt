process p send a phase 1a message to all other processes whenever it begins
a new session. Second, we require that a process send a phase 1a message
(with its current value of mbal[p]) if it has not sent a phase 1a or 2a message
within the past  seconds, for an arbitrary positive  = O(δ). Since the
Paxos algorithm works despite duplication of messages, it permits these
extra phase 1a messages. (Any phase 1a message m is treated as if it were
sent by process m.mbal mod N.)
Proof of Correctness
We now sketch a proof that every process that is nonfaulty at time TS decides
by time TS + O(δ). Let W be the set of processes that are nonfaulty at time
TS, let s0 be the maximum session number at time TS of all processes in W,
let τ be the maximum of 2δ +  and σ, and let [Ta, Tb] be the time interval
from Ta through Tb.
1. At any time after TS, all messages sent before TS and all failed processes
have session number at most s0 + 1.
6
Proof : A Start Phase 1 action that advances a process session to s
cannot be executed until a majority of processes are in session s − 1,
and any majority of processes contains a process in W.
2. If at time T > TS process p sends a phase 1a message with its session
number s, then at some time in [T, T + τ] a process will enter a session
t with t > s.
Proof : Every process q in W receives p’s phase 1a message by time
T + δ and sends a phase 1a message with session number at least s,
either then if q’s session number is less than s or else  seconds later. By
T +  + 2δ process p will receive phase 1a messages from every process
in W and will perform the Start Phase 1 action when its session timer
times out, if it has not already started a higher-numbered session.
3. At some time T3 in [TS, TS ++τ], a process enters session s3 ≥ s0 +1.
Proof : Let p be a process in W with session number s0 at time TS.
If no process in W enters a higher-numbered session by TS + , then
p must send a phase 1a message by that time. The result then follows
from step 2.
4. At some time T4 in [T3, T3 + τ] some process executes Start Phase 1
to enter session s4 ≥ s0 + 2.
Proof : By steps 2 and 3, some process enters a session numbered at
least s0 + 2 during [T3, T3 + τ]. By step 1, it could only have done this
by executing Start Phase 1.
5. At some time T5 in [T4, T4 + τ], some process p5 executes a Start
Phase 1 action to become the ﬁrst process to enter session number
s5 ≥ s0 + 3.
Proof : Steps 2 and 4 imply that some process p5 enters a session
s5 ≥ s0 + 3 during [T4, T4 + τ], and step 1 implies that it can do so
only by executing Start Phase 1.
6. At time T5 + δ
(a) Every process in W is in session s5.
(b) No process is in a session higher than s5.
(c) If a nonfaulty process is in session s5, then its session timer will
not time out before time T5 + 4δ.
(d) There is a process p6 such that
7
i. p6 entered session s5 during [T5, T5 + δ] and set its current
ii. mbal[p] ≤ mbal[p6] for all nonfaulty processes p.
value of mbal[p6] by executing Start Phase 1.
Proof : By steps 1 and 5, no process can enter a higher session before
ﬁrst entering session s5.
(a) Step 5 implies that by time T5 + δ, every process nonfaulty at time
T5 has entered session s5, either by receiving a message from p5
or another process that entered session s5, or else by executing
Start Phase 1.
(b, c) Every process in session s5 entered during [T5, T5 + δ], so its
session timer was reset during that interval and will not time out
before T5 + 4δ. Hence, at time T5 + δ, no process is in a session
higher than s5.
(d) Let p6 be the process p with the largest value of mbal[p] at time
T5 + δ. It could only have acquired that value by executing Start
Phase 1.
7. By time T5 + 4δ, every process in W has sent a phase 2 b message m
with m.mbal = mbal[p6].
Proof : By steps 6 and 1, every process p that is nonfaulty at any
time in [T5, T5 + 4δ] has mbal[p] ≤ mbal[p6] throughout that period.
Hence, by T5 + 2δ every process in W receives p6’s phase 1a message;
by T5 + 3δ process p6 receives phase 1b messages from every process in
W and sends a phase 2a message; and by T5 + 4δ every process in W
receives the phase 2a message and sends a phase 2b message.
8. Every process in W decides on a value by time T5 + 5δ.
Proof : By step 7 and the deﬁnition of the Decide action.
Adding things up, we see that every process nonfaulty at time TS has decided
by time TS +  + 3τ + 5δ. With reasonably accurate timers, if processing
time is negligible compared with message-delivery time, then we can take
σ ≈ 4δ. By making  (cid:191) δ, so τ = σ, we can make the decision time as early
as about TS + 17δ. It seems likely that this bound could be improved by a
more clever algorithm.
8
Process Restarts
We have just proved the result that every process that is nonfaulty at time
TS decides by time TS +O(δ). We also have to show that every process p that
restarts after time TS decides within O(δ) seconds of when it is restarted.
But this is a trivial consequence of the ﬁrst result. The assumptions we have
made about time TS, and hence the ﬁrst result, hold for all times T (cid:48)
S > TS.
Substituting T (cid:48)
S for TS in the ﬁrst result shows that, if process p restarts at
time T (cid:48)
S > TS, then it decides by time T (cid:48)
S + O(δ).
We can a derive better bound on how long it takes a process that restarts
after TS to decide.
It can be seen from our proof that any process that
restarts by time T5 decides by T5 + 5δ. From T5 on, a new session starts
every τ seconds and delivers the requisite phase 2b message within 5δ seconds
of its start.
As observed above, the decision time of a process that restarts after some
processes have already decided can be reduced by having those processes
periodically broadcast their decision.
Reducing Message Complexity
The message complexity of a consensus algorithm matters only when a sys-
tem executes a sequence of separate instances of the algorithm. The op-
eration of a well-designed system consists of long periods of stability, with
timely communication and no failures, punctuated by occasional process
or communication-network failures. We want to minimize the communica-
tion complexity during the stable periods and to prevent excessive message
sending from delaying recovery from failures.
In ordinary Paxos, phase 1 is executed in advance for all instances of the
algorithm, and all nonfaulty processes decide within 3 message delays when
the system is stable. By setting  large enough and using the appropriate
acknowledgement messages, our modiﬁed version of Paxos can be made to
have this same behavior in the stable case. In the same way, the modiﬁed
algorithm can also be made to have the same behavior as normal Paxos in
the event of process failure, as long as communication between nonfaulty
processes is timely. Our modiﬁed algorithm will then send more messages
than ordinary Paxos only in the event of communication failure.
Our algorithm’s extra messages are the phase 1a messages it sends every
 seconds. We can have it send fewer phase 1a messages by increasing the
value of , but this can increase how long it takes processes to decide after
the system becomes stable. We can also add acknowledgements of receipt of
9
phase 1a messages to other messages, so a process does not resend a phase 1a
message to another process that has already received it. However, fast re-
covery from communication failure requires periodically sending messages
to learn when communication has been restored. Frequent message sending
is an unavoidable cost of fast recovery.
5 The Modiﬁed B-Consensus Algorithm
The B-Consensus algorithm of Pedone et al. [14] is a leaderless round-based
algorithm using a message-delivery oracle. A round achieves consensus if
more than N/2 processes are nonfaulty and all messages sent in that round
are delivered by the oracle to all processes in the same order. We now
sketch a method for modifying this algorithm to reach consensus within
O(δ) seconds of stability.
We implement the message-delivery oracle as follows. All messages to be
delivered by the oracle are broadcast to all processes and are timestamped
with logical clocks [8]. This means that after a process receives a message
m, all messages it sends have timestamps greater than that of m. The oracle
delivers messages to a process in timestamp order, waiting 2δ seconds after
the message is actually received by the process before delivering it.
We ﬁrst show that when the system is stable, if there are no restarts, then
the oracle delivers messages to all nonfaulty processes in the same order. A
message m sent when the system is stable will be received by every nonfaulty
process within δ seconds of when it was sent, after which every message sent
has a higher timestamp. Therefore, having a process wait 2δ seconds before
delivering m ensures that it has received every message with a timestamp
lower than that of m that was sent after stability was reached. This implies
that the oracle delivers the same set of messages to all processes in the same
timestamp order.
With restarts, messages sent by a newly restarted process may be de-
livered in diﬀerent orders to diﬀerent processes. However, delivery order
is signiﬁcant only for messages received by a process in the current round.
As with other round-based algorithm, the B-Consensus algorithm does not
start round i + 1 until a majority of processes have reached round i. Hence,
if i is the highest round being executed by some nonfaulty process when the
system becomes stable, round i + 2 will not be disrupted by a message from
a newly restarted process.
An analysis similar to the one for the modiﬁed Paxos algorithm shows
that within O(δ) seconds of stability, the system begins a round that no
10
obsolete message or restarting process can disrupt. That round succeeds
within O(δ) seconds. The actual maximum delay is about the same as for
the modiﬁed Paxos algorithm.
As described by Pedone et al., the B-Consensus algorithm requires that a
process execute all previous rounds before entering a new round. A nonfaulty
process could still be executing the ﬁrst round when stability is reached.
Processes therefore have to keep retransmitting their messages from all pre-
vious rounds to ensure that such a process is brought up to date within O(δ)
seconds of stability. It is unreasonable to assume that such an arbitrarily
large set of messages could be delivered within δ seconds. However, the al-
gorithm is easily modiﬁed to allow a process to jump immediately to a later
round when it receives a message for that round, without having to execute
all previous rounds.
6 Concluding Remarks
Assuming that after time TS no process fails, a majority of processes are
nonfaulty, and every message is delivered within δ seconds of when it is sent,
we have presented a version of the Paxos consensus algorithm that reaches
agreement by time TS + O(δ). We have also sketched a version of the B-
Consensus algorithm of Pedone et al. that does the same. Finding such an
algorithm is nontrivial because we make no assumption about messages sent
before TS and we allow failed processes to restart from where they left oﬀ.
Although it must take O(δ) time after TS, there probably exist algorithms
that can reach consensus more quickly than these.
There are two natural ways in which we might extend our results—by
allowing processes to fail after TS, assuming a majority of processes remain
nonfaulty, and by allowing Byzantine failures, assuming that more than
2/3 of the processes are nonfaulty. In both cases, it is impossible to reach
agreement by time TS+O(δ). Even a perfectly synchronous system with only
crash failures requires O(F ) rounds, where F is the number of processes that
actually fail [7]. With Byzantine failures, a malicious process may continue
to be malicious after TS. If there are M malicious processes, it must therefore
take an asynchronous algorithm at least until time TS + O(M δ) to reach
agreement. We now brieﬂy consider how this bound might be achieved.
Castro and Liskov have published a version of the Paxos algorithm that
handles Byzantine faults and also solves the problem of anomalously high
ballot numbers [1, 12]. However, their algorithm rotates through leaders
until it ﬁnds a nonfaulty one, so it cannot ensure agreement before time
11
TS + O(N δ). To reduce this to TS + O(M δ), we would need some method of
rotating through leaders that skips faulty but non-malicious processes. We
do not know how to do this.
The third author has developed a version of Paxos that handles Byzan-
tine faults without requiring a leader. Like the algorithm of Pedone et al.,
it reaches agreement if certain messages arrive at all processes in the same
order. It should be possible to ensure that messages do arrive in the same
order when the system is stable, even with M Byzantine faults, by taking
O(M δ) seconds to send a message. However, the algorithm ensures progress
only if more than 4/5 of the processes are nonfaulty. Lower-bound results
suggest that this many nonfaulty processes are required by any Byzantine
consensus algorithm that does not use a leader [11].
References
[1] M. Castro and B. Liskov. Practical byzantine fault tolerance and proactive
recovery. ACM Trans. Comput. Syst., 20(4):398–461, 2002.
[2] T. D. Chandra and S. Toueg. Unreliable failure detectors for reliable distrib-
uted systems. J. ACM, 43(2):225–267, 1996.
[3] R. De Prisco, B. Lampson, and N. Lynch. Revisiting the paxos algorithm.
Theoretical Comput. Sci., 243:35–91, 2000.
[4] P. Dutta, R. Guerraoui, and I. Keidar. The overhead of consensus failure
recovery. IC Technical Report 200456, Ecole Polytechnique F´ed´erale de Lau-
sanne (EPFL), June 2004.
[5] C. Dwork, N. Lynch, and L. Stockmeyer. Consensus in the presence of partial
synchrony. J. ACM, 35(2):288–323, Apr. 1988.
[6] M. J. Fischer, N. Lynch, and M. S. Paterson.
Impossibility of distributed
consensus with one faulty process. J. ACM, 32(2):374–382, Apr. 1985.
[7] M. J. Fischer and N. A. Lynch. A lower bound for the time to assure interactive
consistency. Inf. Process. Lett., 14(4):183–186, June 1981.
[8] L. Lamport. Time, clocks, and the ordering of events in a distributed system.
Commun. ACM, 21(7):558–565, July 1978.
[9] L. Lamport. The part-time parliament. ACM Trans. Comput. Syst.,
[10] L. Lamport. Paxos made simple. ACM SIGACT News (Distributed Computing
16(2):133–169, May 1998.
Column), 32(4):18–25, Dec. 2001.
[11] L. Lamport. Lower bounds for asynchronous consensus. In A. Schiper, A. A.
Shvartsman, H. Weatherspoon, and B. Y. Zhao, editors, Future Directions in
Distributed Computing, volume 2584 of Lecture Notes in Computer Science,
pages 22–23. Springer, 2003.
[12] B. W. Lampson. The ABCDs of Paxos. http://research.microsoft.com/
lampson/65-ABCDPaxos/Abstract.html.
12
[13] A. Most´efaoui and M. Raynal. Leader-based consensus. Parallel Processing
Letters, 11(1):95–107, Mar. 2001.
[14] F. Pedone, A. Schiper, P. Urb´an, and D. Cavin. Solving agreement problems
with weak ordering oracles. In Proceedings of the 4th European Dependable
Computing Conference (EDCC-4), volume 2485 of Lecture Notes in Computer
Science, pages 44–61. Springer-Verlag, 2002.
13