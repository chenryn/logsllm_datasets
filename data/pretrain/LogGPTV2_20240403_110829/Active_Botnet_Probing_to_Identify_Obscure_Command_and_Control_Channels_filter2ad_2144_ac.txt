the access connection does not yield a successful
download of a Windows executable. We begin by building
a suspicious access set containing addresses (most likely,
HTTP addresses) that appear after the Pc but not after the
modiﬁed Pc. Then for each subsequent round, we assign
D = 1 if we see an address from the suspicious set still
appear upon replay of Pc, but not upon the sending of the
modiﬁed Pc.
We have introduced several different detection algorithms.
Now we discuss the typical selection of proper algorithms
in practice when facing a different type of response or
a different combination of responses. We think that for a
normal chatting host, the probability of performing a certain
(malicious) activity response (e.g., scan, spam) is lower
than that of performing a message response. The general
principle we need to follow here is to choose the algorithm
that favors the response with the lowest probability and
thereby makes the fewest probes and the largest walk in
the threshold random walk. In the following analysis we
assume P rob(scan) ≈ P rob(spam) < P rob(3rd−party−
access) < P rob(message) in the case of a normal chatting
client.
If we observe a scan/spam response associated with
a command (there might be other responses such as an
IRC PRIVMSG message), we choose the Single-Binary-
Response-Hypothesis algorithm on the scan/spam response,
and ignore other responses. Usually, we only need another
active probing (using P1) to declare a botnet as shown in
Sections III-D and IV-B. It is possible that these scan/spam
responses are long-lasting, i.e., we still observe the response
to the original command after we perform P1 (a replayed
command). However, we do not consider this as a problem,
because we still detect the bot. Here our detection perfor-
mance is at least no worse than the approaches that issue
alerts when observing the combination of IRC events and
scan events such as [4] and BotHunter [13].
If we observe a third-party access (by matching a PE
signature) associated with a command (there might be
some message response, but no scan/spam responses), we
choose the Single-Binary-Response-Hypothesis algorithm on
the third-party access response.
For the remaining combination of responses (e.g., a mes-
sage response and a third-party access response without PE
signature capturing) or only a message response, we can
choose Interleaved-Binary-Response-Hypothesis algorithm.
If there are both a message response and a third-party access
observed, to make a walk in the algorithm, we always pick
the type of response that makes a larger step (third-party
access in this case) in the threshold random walk.
D. Evaluating User Disturbance and Detection Accuracy
Tradeoff
We now describe how the above algorithms can be
adapted to trade off user disturbance with system perfor-
mance. For benign IRC chat sessions, replaying or mod-
ifying some byte is essentially equivalent to receiving a
duplicate message or receiving a message with a typo:
humans have natural resilience to at least limited occurrences
of these events. The Client-Replay-Probing technique, which
establishes a new session, is even less harmful. Nevertheless,
we acknowledge that active modiﬁcations to user IRC ses-
sions may impose some degree of cost to human users. We
present a more detailed discussion on the legal concerns of
using active techniques in Section V.
As discussed earlier, to have a high conﬁdence of hy-
pothesis testing, we may need N rounds of probing. If we
are concerned about the disturbance/interference to normal
users, we could use the number of rounds (packets modi-
ﬁed/replayed) by active probing as a means to quantify the
degree of disturbance. Clearly, less disturbance means fewer
rounds, smaller N , which on the other hand, may affect the
performance of detection. Fortunately, because of the use of
SPRT, the average number of N to make a decision is quite
small. To produce a botnet C&C declaration, the expected
number of rounds we need is [30]
E[N|H1] = β ln β
θ1 ln θ1
θ0
1−α + (1 − β) ln 1−β
α
+ (1 − θ1) ln 1−θ1
1−θ0
Similarly, to produce a human user IRC channel declara-
tion, the expected number of rounds is
(1 − α) ln β
θ0 ln θ1
θ0
1−α + α ln 1−β
α
+ (1 − θ0) ln 1−θ1
1−θ0
E[N|H0] =
4
3.5
3
2.5
θ
=0.9,α=0.001  
1
=0.99,α=0.001 
θ
1
θ
=0.999,α=0.001
1
θ
=0.9,α=0.01   
1
θ
=0.99,α=0.01  
1
=0.999,α=0.01 
θ
1
]
0
|
H
N
E
[
2
1.5
1
0.5
0
0
0.05
0.1
θ
0
0.15
0.2
0.25
)
1
t
e
n
m
v
(
e
c
i
v
e
D
m
o
r
F
r
e
i
f
i
s
s
a
l
C
r
e
d
n
o
p
s
e
R
P
R
A
r
e
d
a
e
H
P
I
k
r
a
M
r
e
d
a
e
H
P
I
k
r
a
M
r
e
l
u
d
e
h
c
S
R
R
)
1
t
e
n
m
v
(
e
c
i
v
e
D
o
T
)
t
s
i
L
h
c
t
a
W
(
r
e
h
c
t
a
M
C
R
I
1
e
b
o
r
P
e
v
i
t
c
A
r
e
v
r
e
S
C
R
I
2
e
b
o
r
P
e
v
i
t
c
A
SimpleResponder
DNSResponder
]
1
|
H
N
E
[
8
7
6
5
4
3
2
1
0
θ
=0.9,α=0.001  
1
θ
=0.99,α=0.001 
1
θ
=0.999,α=0.001
1
θ
=0.9,α=0.01   
1
θ
=0.99,α=0.01  
1
θ
=0.999,α=0.01 
1
0.05
0.1
θ
0
0.15
0.2
0.25
(a) Average number of rounds to
detect normal IRC user.
(b) Average number of rounds to
detect botnet C&C.
Figure 3. Disturbance to normal user and the effect on detection.
Figure 4.
Click conﬁguration for BotProbe. The ﬁgure shows a con-
ﬁguration for black-box testing on existing bot binaries. If BotProbe is
deployed as a middlebox into a real network, we can remove the IRC
Server, SimpleResponder, and DNSResponder elements.
Figure 3 shows the average number of rounds we need
to declare a normal user (a) or bot (b). For example, if
we set parameters θ1 = 0.99, θ0 = 0.15, and our desired
false positive/false negative rates are α = 0.001, β = 0.01,
then the average number of rounds to declare a botnet is
about N1 = 3.7. Likewise, the average number of rounds to
declare a human user is less than two for IRC (approximately
N0 = 1.3). If we observe some scan response, we use a
= 0.01; then it takes less
lower probability of θ0, e.g., θscan
than two rounds (e.g., one extra replay) to detect bots on
average.
0
Our system is bolstered by an IRC channel whitelist to
minimize user disturbance (i.e., once an IRC server/channel
is validated, we will not disturb other users for a certain
time window, and the time window could be randomized).
Finally, the BotProbe strategy should be viewed as one
input among a broader set of threat indicators that can be
applied for detecting internal botnet infections. For example,
the results produced by the BotProbe hypothesis testing
framework could be incorporated into systems such as
BotHunter [13], which considers the full set of potential
botnet-related infection indicators, such as exploit usage, egg
download events, and inbound and outbound attack behavior.
IV. EXPERIMENTS WITH BOTPROBE
A. BotProbe: a Prototype Active Botnet Probing System
We have implemented a prototype middlebox system
called BotProbe for the purpose of evaluating our active
probing techniques. BotProbe is implemented as a collec-
tion of Click routing elements [18]. Click provides a C++
software framework for packet processing, with impressive
scaling performance and a ﬂexible conﬁguration language,
which makes it
ideal for building software routers and
middleboxes.