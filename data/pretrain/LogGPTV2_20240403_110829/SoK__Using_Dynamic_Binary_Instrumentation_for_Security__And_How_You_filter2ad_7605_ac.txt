✓
7
14
22
2
9
8
30
Table 1: Application domains and uses of DBI primitives in related literature.
proposed analysis. We grouped instrumentation actions required
by analyses in the following types:
• instructions, which we further divide in memory operations
(for checking every register or memory operand’s content),
call/ret (for monitoring classic calls to internal functions or
library code), branches ([in]direct and [un]conditional), and
other (for special instructions such as int and rdtsc);
• system calls, to detect low-level interactions with the OS;
• library calls, when high-level function call interception fea-
tures of the DBI engine (like the routine instrumentation of
Pin) are used to identify function calls to known APIs;
• threads and process, when the analysis is concerned with
intercepting their creation and termination;
• code loading, to intercept dynamic code loading events;
• exceptions and signals, to deal with asynchronous flows.
In Table 1 we present aggregate results for application domains,
where for each category we consider the union of the instrumen-
tation primitives used by the works falling into it. While such
information is clearly coarse-grained compared to a thorough anal-
ysis of each work, we observed important regularities within each
category. For instance, in the cryptoanalysis domain nearly every
considered work resorts to all the primitives listed for the group.
Tracing all kinds of instructions and operands seems fundamental
in the analysis of malicious software, while depending on the goal
of the specific technique it may be necessary to trace also context
switches or asynchronous flows. Observe that some primitives are
intuitively essential in some domains: this is the case of memory
accesses for information flow analysis, as well as of control transfer
instructions in software protection works.
Choices. We identify Pin as the most popular engine in the works
we survey with 57 uses, followed by Valgrind (19), libdetox (5),
DynamoRIO (4) and Strata (3); in some cases the engine was not re-
ported. Unsurprisingly, Valgrind is very popular in the vulnerability
detection domain with 9 uses, just behind Pin with 12.
An important design choice that emerged from many works is
related to when DBI should be used to back an online analysis or to
rather record relevant events and proceed with offline processing.
Other than obvious aspects related to the timeliness of the obtained
results (e.g., shepherding control flows vs. bug identification) and
nondeterministic factors in the execution, also the complexity of
the analysis carried out on top of the retrieved information may
play a role—this seems at least the case with symbolic execution.
A few research works [44, 68] aiming at mitigating defects in
software devise their techniques in two variants: one for when the
source code is available, and another based on DBI for software in
binary form, hinting at higher implementation effort and possible
technical issues in using SBI techniques in lieu of DBI.
4 ATTACK SURFACES
In light of the heterogenous analyses mentioned in the previous sec-
tion, it is legitimate to ask whether their results may be affected by
imperfections or lack of transparency of the underlying DBI engine.
We will deal with these issues throughout the present section.
4.1 Desired Transparency Properties
Existing literature has discussed the transparency of runtime sys-
tems for program analysis under two connotations. The first, which
is compelling especially for VM architects and dynamic translator
builders, implies that an application executes as it would in a non-
instrumented, native execution [4], and that interoperability with
native applications works normally [11]. To this end, Bruening et
al. [4] identify three guidelines to achieve the execution correctness
properties outlined in Section 2.1 when writing a DBI system:
[G1] leave the code unchanged whenever possible;
[G2] when change is unavoidable, ensure it is imperceivable to
the application;
[G3] avoid resource usage conflicts.
The authors explain how transparency has been addressed on
an ad-hoc basis in the history of DBI systems, as applications were
found to misbehave due to exotic implementation characteristics
with respect to code, data, concurrency, or OS interactions.
DBI architects are aware that absolute transparency may be
unfeasible to obtain for certain aspects of the execution, or that im-
plementing a general solution would cause a prohibitive overhead.
In the words of Bruening et al. [4]: “the further we push transparency,
the more difficult it is to implement, while at the same time fewer
applications require it”. In the end, the question boils down to see-
ing whether a presumably rare corner case may show up in code
analyzed by the users of the DBI system.
A second connotation of transparency, which is compelling for
software security research, implies the possibility of adversarial
sequences that look for the presence of a DBI system and thwart any
analyses built on top of it. We defer the discussion of the DBI evasion
and escape problems to the next section, as in the following we will
revisit from the DBI perspective general transparency properties
that authors of seminal works sought in analysis runtimes they
considered for implementing their approaches.
For an IDS, Garfinkel and Rosenblum [20] identify three capabil-
ities required to support good visibility into a monitored system
while providing significant resistance to both evasion and attack:
• isolation: code running in the system cannot access or modify
code and data of the monitoring system;
• inspection: the monitoring system has access to all the state
of the analyzed system;
AsiaCCS ’19, July 9–12, 2019, Auckland, New Zealand
D’Elia et al.
• interposition: the monitoring system should be able to inter-
pose on some operations, like uses of privileged instructions.
The last two properties are simply met by the design goals behind
the DBI abstraction. Supporting the first property in the presence
of a dedicated adversary seems instead hard for a DBI engine: as the
runtime shares the same address space of the code under analysis,
the possibility of covert channels is real. Actually, by subverting
isolation an attacker might in turn also foil the inspection and
interposition capabilities of a DBI system [28].
The authors of the Ether malware analyzer [13] present a sim-
ple abstract model of program execution where transparency is
achieved if the same trace of instructions is observed in an environ-
ment with and without an analyzer component present. As they use
hardware virtualization, the model is later generalized to account
for virtual memory, exception handling, and instruction privilege
levels. The requirements identified for a system that wants to hide
memory and CPU changes caused by its own presence are:
• higher privilege: the analyzer runs at a privilege level higher
than the highest level a program can achieve;
• privileged access for side effects: if any, side effects can be seen
only at a privilege level that the program cannot achieve;
• same basic instruction semantics: aside from exceptions, the
semantics of an instruction is not involved in side effects;
• transparent exception handling: when one occurs, the ana-
lyzer can reconstruct the expected context where needed;
• identical timing information: access to time sources is trapped,
so that query results can be massaged consistently.
For an analysis runtime operating in user space, fulfilling all
these requirements simultaneously is problematic, and oftentimes
unfeasible. While DBI systems preserve instruction semantics and
can capture exceptions, current embodiments operate at the same
privilege level of the code under analysis. Values retrieved from
timing sources can be massaged as in [46] to deal with specific
detection patterns, but general strategies for manipulating the time
behavior of a process with realistic answers may be intrinsically
difficult to conceive or computationally too expensive [19].
For a fair comparison, we observe that similar problems affect
to some extent also other other analysis approaches whose design
seems capable of accommodating such requirements in a robust
manner. Let us consider VMI techniques: Garfinkel in [19] describes
several structural weaknesses in virtualization technology that an
attacker may leverage to detect its presence, concluding that build-
ing a transparent monitor “is fundamentally infeasible, as well as
impractical from a performance and engineering standpoint”. Attacks
to VMI-based analyses are today realistic: for instance, performance
differences can be observed due to TLB entry eviction [3], and the
falsification of timing information can be imperfect [42].
In the next sections we will present the reader with practical
attack surfaces that a dedicated adversary may use to detect a DBI
system, and discuss how analyses running on one can be impacted.
4.2 DBI Evasion and Escape
The imperfect transparency of DBI systems has led researchers to
design a plethora of detection mechanisms to reveal the presence
of a DBI framework from code that undergoes dynamic analysis.
Once an adversary succeeds, the code can either execute misleading
actions to deceive the analysis, or attempt to carry out execution
flows that go unnoticed by the engine. These scenarios are popularly
known as the DBI evasion and escape problem, respectively.
Definition 4.1 (DBI Evasion). A code is said to evade DBI-based
analysis when its instruction and data flows eventually start di-
verging from those that would accompany it in a native execution,
either as a result of a decision sequence that revealed the presence
of a DBI engine, or because of translation defects on the DBI side.
We opted for a broad definition of the evasion problem for the
following reason: alongside techniques that actively fingerprint
known artifacts of a DBI engine and deviate the standard control
flow accordingly, DBI systems suffer from translation defects that
are common in binary translation solutions and cause the analysis
to follow unfeasible execution paths. The most prominent example
is the use of self-modifying code, which is used both in benign
mainstream programs [4] (resulting in an unintended evasion, and
possibly in a program crash) and as part of implicit evasion mecha-
nisms to cripple dynamic analysis by yielding bogus control flows.
Definition 4.2 (DBI Escape). A code is said to escape DBI-based
analysis when parts of its instruction and data flows get out of
the DBI engine’s control and execute natively on the CPU, in the
address space of the analysis process or of a different one.
An attacker aware of the presence of a DBI engine may try to
hijack the control transfers that take place under the DBI hood,
triggering flows that may never return under its control. The typical
scenario involves leaking an address inside the code cache and
patching it with a hijacking sequence, but more complex schemes
have been proposed. As for the second part of the definition, DBI
frameworks can provide special primitives to follow control flows
carried out in other processes on behalf of the code under analysis:
for instance, Pin can handle child processes, injected remote threads,
and calls to external programs. Implementation gaps are often the
main reason for which such attempts could go unnoticed.
4.3 Artifacts in Current DBI Embodiments
In Section 1 we have mentioned several scientific presentations
and academic research highlighting flaws in DBI systems. While
some of them characterize the DBI approach in its generality, others
leverage implementation details of a specific engine, but can often
be adapted to others that follow similar implementation strategies.
In hopes of providing a useful overview of the evasion problem
to researchers that wish to use DBI techniques in their works, we
propose a categorization of the techniques that are known to date
to detect the presence of a DBI system. We will refer to Pin on
Windows in many practical examples, as the two have received
significantly more attention than any other engine/OS in the DBI
evasion literature. We will discuss the following attack surfaces that
we identified in such research: time overhead, leaked code pointers,
memory contents and permissions, DBI engine internals, interactions
with the OS, exception handling, and translation defects.
Time overhead. The process of translating and instrumenting the
original instructions in traces to be placed in cache and eventually
executed introduces an inevitable slowdown in the execution. This
slowdown grows with the granularity of the required analysis: for
SoK: Using Dynamic Binary Instrumentation for Security
AsiaCCS ’19, July 9–12, 2019, Auckland, New Zealand
example, tracing memory accesses is significantly more expensive
than monitoring function calls. An adversary may try generic time
measurement strategies for dynamic analyses that compare the
execution of a code fragment to one in a reference system and
look for significant discrepancies. There are peculiarities of DBI
that could be exploited as well: for instance, the time required to
dynamically load a library from user code can be two orders of
magnitude larger [17] under DBI due to the image loading process.
Similarly, effects of the trace compilation process can be exploited
by observing fluctuations in the time required to take a branch in
the program from the first time it is observed in the execution [28].
Leaked code pointers. A pivotal element in the execution trans-
parency of DBI is the decoupling between the real instruction
pointer and the virtual one exposed to the code. There are however
subtle ways for an adversary to leak the real IP and compare it
against an expected value. One way inspired by shellcode writing
is to use special x87 instructions that are used to save the FPU state
(e.g., for exception handling) in programs: an adversary executes
some x87 instruction (like pushing a number to the FPU stack) and
then uses fstenv, fsave, or one of their variants to write the FPU
state to memory. The materialized structure will contain the EIP
value for the last performed FPU instruction, which DBI engines
typically do not mask: a check on its range will thus expose DBI [17].
Another way in 32-bit Windows is the int 2e instruction normally
used to enter kernel mode on such systems: by clearing EAX and
EDX before invoking it, the real IP is leaked to EDX [46].
Memory contents and permissions. A major source of transparency
concerns is that a DBI engine shares the same address space of the
analyzed code without provisions for isolation. The inspection of
the address space can reveal additional sections and unexpected
exported functions from the runtime [17]; the increased memory
usage could be an indicator of the presence of DBI as well [31].
An adversary may look for recurrent patterns that are present in
the code components (the runtime and the user’s analysis code) of
the DBI system and in their data, or in heap regions used for the
code caching mechanism [17]. Another issue could be the duplicate
presence of command-line arguments in memory [17].
Also the memory layout orchestrated and exposed by the DBI
engine to the application under analysis can be stressed for consis-
tency by adversarial sequences. For instance, Pin and DynamoRIO
miss permission violations when the virtual IP falls into code pages
for which access has been disabled (PAGE_NOACCESS) or guarded
(PAGE_GUARD) by the application [24]. Similarly, an engine may
erroneously process and execute code from pages that were not