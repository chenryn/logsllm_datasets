### 6.3 Incident Response

Our third observation, based on qualitative interviews, is that security incidents resulting from misconfigurations temporarily increase the security awareness of management and operations personnel. When directly asked, 81.9% of operators either agree or strongly agree that the discovery of a security misconfiguration has made them more security-conscious, with 33.0% strongly agreeing (Table 4, line 4). Similarly, 71% of respondents believe that their company’s security posture improved after a security misconfiguration was discovered (Figure 8). However, 53% of respondents also report that an actual incident had a greater impact on the organization's security posture than the discovery of a misconfiguration that did not yet cause an incident (Figure 8).

Several operators noted that security-relevant changes are often planned but never implemented, or only temporarily active before being reverted. They also highlighted that management may be willing to improve but unwilling to provide the necessary resources, or may apply unreasonable security metrics and measures. Additionally, some operators pointed out the lack of security awareness and the absence of clear responsibilities as contributing factors.

One operator mentioned that companies fear bad press the most, a sentiment generally agreed upon by other operators (Table 4, line 5). Overall, this suggests an uncoordinated approach to incident response and a generally poor security posture in many companies, with only 53.39% of respondents agreeing that their company's security posture is sufficient (Table 4, line 9).

As a measure to handle the aftermath of a misconfiguration incident, 77.4% of respondents agree that blameless postmortems are important (Table 4, line 3). However, there are significant differences between freelancers (average score 0.867) and employed system operators (full-time average 1.325, part-time average 1.400) (p < 0.001 in Pearson’s χ² test). Given that most companies do not budget for errors (Table 4, line 10), we hypothesize that freelancers are often used as scapegoats in situations where an organization pretends to perform a blameless postmortem.

### Summary

Our quantitative survey aligns with the suggestions from our qualitative interviews. Additional qualitative responses indicate that even when changes are implemented, they are not always permanent, leading to lapses in the organization's security posture. Participants agree that blameless postmortems are fundamental for meaningful, effective, and long-lasting incident response. For these postmortems to have an impact, companies must accept that (human) errors can and will happen and budget for their occurrence, which is currently not the case. If postmortems are supposed to be blameless but still assign blame, it could erode trust in leadership and diminish their long-term effectiveness.

### 7. Related Work

We compare our findings to relevant prior research in four categories: (i) studies of misconfigurations and mitigation efforts, (ii) usability studies focused on technical systems creating or preventing errors, (iii) studies on personal behavioral causes for security issues, and (iv) research in safety sciences.

#### Misconfigurations and Mitigation

Kuhrer et al. found that large-scale notification campaigns can significantly reduce the number of Internet-connected systems that are misconfigured and could be exploited as traffic amplifiers [47]. Czyz et al. reported similar results in reducing NTP amplifiers [48]. However, Fiebig et al. showed in 2016 that such improvements were temporary for publicly exposed Redis and memcached services [6]. Springall et al. investigated Internet-wide misconfigured FTP servers in 2016 but did not report whether they notified operators or if misconfigurations were corrected temporarily or permanently [49]. Prior work also confirmed that misconfigurations facilitate other security issues, such as mobile applications leaking sensitive data [50], denial of service vulnerabilities [10, 11], malicious websites [12], cryptocurrency mining [51], and website defacements [13, 14]. Misconfigurations can even lead to account compromises in single sign-on protocols [52].

Recent work on IPv6 has led to more efforts to make IPv6 scannable or enumerable [53–55]. Czyz et al. found that systems expose insufficiently protected services more often via IPv6 than via IPv4 [56]. Borgolte et al. identified several thousand critical systems with IPv6 security misconfigurations [55]. Zhang et al. found a correlation between malice and misconfigurations in networks [57]. Misconfigurations have long been an important subject in the networking community, with studies on BGP misconfigurations [58] and router misconfiguration detection [59].

#### Usability and Technical Mitigations

Xu et al. created a system to detect design flaws that facilitate misconfiguration and analyzed the configuration syntax of various popular Internet services [61]. Haber et al. distilled design guidelines for system operations tools in 2007 [62]. In 2015, Xu et al. comprehensively analyzed how system complexity leads to security misconfigurations and surveyed technical approaches to reduce them [63, 64]. Keller et al. introduced ConfErr to increase system resilience to misconfigurations [65], and Oliveira proposed designing mistake-aware systems [66].

#### Behavioral Studies

Fahl et al. reported on webmasters running expired TLS certificates, with participants mainly requesting technological changes to mitigate these misconfigurations [67]. Krombholz et al. investigated the challenges in configuring TLS correctly, focusing on usability aspects [9]. Acar et al. conducted a large-scale study on the sources Android developers use, which may lead to security issues [31]. This relates to our observations on operators using online resources that recommend problematic configurations. Acar et al. also investigated the challenges in recruiting IT professionals via GitHub for studies to understand and improve their security decision-making processes [68]. Sundaramurthy et al. evaluated the inherent conflicts in security operations centers and how to resolve them effectively [69].

#### Safety Science

Similar to the current state in computer security and operations, the initial focus in safety science was on individual human error during specific actions [70]. However, it became apparent in the 1990s that an approach including organizational aspects and precursors is fundamental to effectively mitigate human error. A common example is the MS Herald of Free Enterprise, which capsized in 1987 due to a dockhand forgetting to close a door. The initial report focused on person-centric causes, but Praetorius et al. re-analyzed the incident 25 years later, finding that the human error was a symptom of functional resonance in various ship operations [71]. Schröder-Hinrichs et al. found similar underlying factors in maritime incidents from the R.M.S. Titanic to the Costa Concordia [46].

### 8. Limitations

Due to our recruitment strategy (Section 5.2), our study may suffer from (self-)selection bias. Our participants are likely to identify with their work, as they are actively involved in the operators' community. This may inadvertently exclude less active operators who may have different perceptions. However, our qualitative data, including anecdotes, reasoning, and opinions, provides second-hand information on the behavior of operators who do not actively participate in the community beyond their regular job. Although our sample is small, our demographic distribution corresponds to earlier studies, indicating a sufficiently stratified sample [29]. Since our analysis is based on self-reported data, it is inherently biased by the participants' perceptions.

### 9. Conclusion

In this paper, we conducted the first systematic study of human aspects of security misconfigurations from the operators' perspective. We find that security misconfigurations do not necessarily lead to incidents: one-third of respondents reported that the misconfigurations they witnessed resulted in a security incident, even though all of them could have led to one. The observation that almost all participants encountered security misconfigurations may be due to self-selection bias among operators. Given the prevalence of security incidents caused by misconfigurations [2, 3, 44], even considering this bias, our data highlights a larger set of potential incidents that could be more disastrous compared to past ones.

Based on our analysis, we find that human error in system operations is driven by institutional, organizational, and personal factors. To reduce the frequency and impact of security misconfigurations, we recommend the following immediate action items, which, unfortunately, are rarely implemented by organizations despite being technically sound and well-known:

- **Documentation:** The state of any system and all its components must be properly documented, updated immediately upon any changes, and regularly verified for correctness.
- **Clear Responsibilities:** Organizations must ensure a single responsible department for the security of each device, with sufficient authority to ensure appropriate security posture. Responsibility must be shared among multiple people, and middle management must be qualified.
- **Blameless Postmortems:** After an incident, its root cause must be understood, and actions must be taken to prevent similar incidents. While companies embrace a general post-mortem culture, our results indicate that this does not necessarily mean postmortems are blameless. Blameless postmortems should be constructive and not assign blame. Organizations should budget for failure and errors.
- **Processes and Procedures:** All manual changes to the system must be planned. Frequent modifications or configuration changes should be eliminated, automated, and described in a process.
- **Automation:** Infrastructure and procedures should be automated to allow operators to adopt complex procedures more easily. Canary deployments and rollback plans can highlight and tackle misconfigurations quickly. These tools must be reliable and not burdensome for operators. Software and protocols should be "secure by default" [33].
- **Fire Drills:** Regular exercises should be performed to understand the security implications of the current system, how it can be improved, and to train operators and management in proper incident handling procedures. Fire drills can help managers from different backgrounds better understand the implications of IT operations.

### Acknowledgements

We thank the anonymous reviewers for their helpful suggestions to improve the paper. We also thank Sascha Fahl for his valuable feedback. We are grateful to the RIPE Academic Initiative (RACI) for supporting this research project with a full scholarship to attend RIPE 76, as well as RIPE NCC and APNIC for helping us disseminate our survey via their blogs. We extend our gratitude to the German Network Operators Group (DENOG) for their support and valuable feedback from the early stages.

This material is partially funded by SBA Research. The competence center SBA Research (SBA-K1) is funded within the framework of COMET – Competence Centers for Excellent Technologies by the Austrian Ministry for Transport, Innovation and Technology (BMVIT), the Austrian Federal Ministry for Digital and Economic Affairs (BMDW), and the federal state of Vienna, managed by the Christian Doppler Research Association.