prised of her friends’ most recent updates. In order to con-
struct the news feed, she must query each of her friend’s
feed objects in succession, and in so doing reveal to the
provider which feed objects are related.
Users and Clients: We assume that users may also be
malicious and may use the clients they control to attempt
to read and modify objects to which they do not have
access. In addition, malicious users may collude with
the provider or with other users to exceed their privileges
or to deceive honest users. They may also attempt to
falsely accuse the provider of misbehavior. Finally, we
assume that some clients may be controlled by Sybil users,
created by the provider to subvert the clients’ defenses
against server equivocation.
Frientegrity’s security is based on the assumption, how-
ever, that among the users which have access to a given
object, no more than some constant f will be malicious
(Byzantine faulty). We believe that this assumption is rea-
sonable because a user can only access an object if she has
been explicitly invited by another user with administrator
privileges for the object (e.g., Alice can only access Bob’s
wall if he explicitly adds her as a friend). As we describe
in §4.1, this assumption allows clients to collaborate to
detect provider misbehavior. If a client sees that at least
f + 1 other users have vouched for the provider’s output,
the client can assume that it is correct.
Client code: We assume the presence of a code authen-
tication infrastructure that can verify that the application
code run by clients is genuine. This mechanism might rely
on code signing or on HTTPS connections to a trusted
server (diﬀerent from the untrusted service provider used
as part of Frientegrity’s protocols).
3. System Overview
As discussed above, to ensure that the provider is behav-
ing correctly, Frientegrity requires clients to verify the
Figure 1: A client fetches a news feed in Frientegrity by
reading the latest posts from her friends’ walls, as well as
information to verify, authenticate, and decrypt the posts.
output that they receive from the provider’s servers. As
a result, whenever clients retrieve the latest updates to an
object, the provider’s response must include enough infor-
mation to make such veriﬁcation possible. In addition, the
provider must furnish the key material that allows autho-
rized clients with the appropriate private keys to decrypt
the latest operations. Thus, when designing Frientegrity’s
protocols and data structures, our central aim was to en-
sure that clients could perform the necessary veriﬁcation
and obtain the required keys eﬃciently.
To explain these mechanisms, we use the example of
a user Alice who wants to fetch her “news feed” and
describes the steps that her client takes on her behalf. For
simplicity, in this and subsequent examples throughout
the paper, we often speak of users, such as Alice, when we
really mean to refer to the clients acting on their behalf.
3.1 Example: Fetching a News Feed
Alice’s news feed consists of the most recent updates
to the sources to which she is subscribed. In Facebook,
for example, this typically corresponds to the most recent
posts to her friends’ “walls”, whereas in Twitter, it is made
up of the most recent tweets from the users she follows.
At a high level, Frientegrity performs the following steps
when Alice’s fetches her news feed, as shown in Figure 1.
1. For each of Alice’s friends, Alice’s sends a readOb-
ject RPC to the server containing the friend’s wall
object.
2. In response to a readObject RPC for a friend Bob,
a well-behaved server returns the most recent opera-
tions in Bob’s wall, as well as suﬃcient information
and key material for Alice to verify and decrypt them.
3. Upon receiving the operations from Bob’s wall, Al-
ice performs a series of veriﬁcation steps aimed at
detecting server misbehavior. Then, using her pri-
vate key, she decrypts the key material and uses it to
decrypt the operations. Finally, when she has veri-
ﬁed and decrypted the recent wall posts from all her
4
…!Provider!Srv 1!Srv 2!Srv 3!Srv n!Bob’s wall!Bob’s ACL history!Bob’s ACL!Alice!depends!readObject(‘Bob’s wall’)!2!3!1!Decrypt!Verify!friends, she combines them and optionally ﬁlters and
prioritizes them according to a client-side policy.
For Alice to verify the response to each readObject, she
must be able to check the following properties eﬃciently:
1. The provider has not equivocated about the wall’s
contents: The provider must return enough of the
wall object to allow Alice to guarantee that history
of the operations performed on the wall is fork* con-
sistent.
2. Every operation was created by an authorized user:
The provider must prove that each operation from the
wall that it returns was created by a user who was
authorized to do so at the time that the operation was
submitted.
3. The provider has not equivocated about the set of
authorized users: Alice must be able to verify that
the provider did not add, drop, or reorder users’ mod-
iﬁcations to the access control list that applies to the
wall object.
4. The ACL is not outdated: Alice must be able to
ensure that the provider did not roll back the ACL
to an earlier version in order to trick the client into
accepting updates from a revoked user.
The remainder of this section summarizes the mecha-
nisms with which Frientegrity enforces these properties.
3.2 Enforcing Fork* Consistency
Clients defend against provider equivocation about the
contents of Bob’s wall or any other object by comparing
their views of the object’s history, thereby enforcing fork*
consistency. Many prior systems, such as BFT2F [33] and
SPORC [21], enforced fork* consistency by having each
client maintain a linear hash chain over the operations that
it has seen. Every new operation that it submits to the
server includes the most recent hash. On receiving an op-
eration created by another client, a client in such systems
checks whether the history hash included in the operation
matches the client’s own hash chain computation. If it
does not, the client knows that the server has equivocated.
The problem with this approach is that it requires each
client to perform work that is linear in the size of the
entire history of operations. This requirement is ill suited
to social networks because an object such as Bob’s wall
might contain thousands of operations dating back years.
If Alice is only interested in Bob’s most recent updates,
as is typically the case, she should not have to download
and check the entire history just to be able to detect server
equivocation. This is especially true considering that when
fetching a news feed, Alice must read all of her friends’
walls, and not just Bob’s.
To address these problems, Frientegrity clients verify
an object’s history collaboratively, so that no single client
5
needs to examine it in its entirety. Frientegrity’s collab-
orative veriﬁcation scheme allows each client to do only
a small portion of the work, yet is robust to collusion
between a misbehaving provider and as many as f mali-
cious users. When f is small relative to the number of
users who have written to an object, each client will most
likely only have to do work that is logarithmic, rather than
linear, in the size of the history (as our evaluation demon-
strates in §7.5). We present Frientegrity’s collaborative
veriﬁcation algorithm in §4.1.
3.3 Making Access Control Veriﬁable
A user Bob’s proﬁle is comprised of multiple objects in ad-
dition to his wall, such as photos and comment threads. To
allow Bob to eﬃciently specify the users allowed to access
all of these objects (i.e., his friends), Frientegrity stores
Bob’s friend list all in one place as a separate ACL. ACLs
store users’ pseudonyms in the clear, and every operation
is labeled with the pseudonym of its creator. As a result,
a well-behaved provider can reject operations that were
submitted by unauthorized users. But because the provider
is untrusted, when Alice reads Bob’s wall, the provider
must prove that it enforced access control correctly on
every operation it returns. Thus, Frientegrity’s ACL data
structure must allow the server to construct eﬃciently-
checkable proofs that the creator of each operation was
indeed authorized by Bob.
Frientegrity also uses the ACL to store the key material
with which authorized users can decrypt the operations on
Bob’s wall and encrypt new ones. Consequently, ACLs
must be designed to allow clients with the appropriate pri-
vate keys to eﬃciently retrieve the necessary key material.
Moreover, because social network ACLs may be large,
ACL modiﬁcations and any associated rekeying must be
eﬃcient.
To support both eﬃciently-checkable membership
proofs and eﬃcient rekeying, Frientegrity ACLs are imple-
mented as a novel combination of persistent authenticated
dictionaries [12] and key graphs [59]. Whereas most
prior social networking systems that employ encryption
required work linear in the number of friends to revoke a
user’s access, all of Frientegrity’s ACL operations run in
logarithmic time.
Even if it convinces Alice that every operation came
from someone who was authorized by Bob at some point,
the provider must still prove that it did not equivocate
about the history of changes Bob made to his ACL. To ad-
dress this problem, Frientegrity maintains an ACL history
object, in which each operation corresponds to a change
to the ACL and which Alice must check for fork* con-
sistency, just like with Bob’s wall. Frientegrity’s ACL
data structure and how it interacts with ACL histories are
further explained in §4.3.
3.4 Preventing ACL Rollbacks
Even without equivocating about the contents of either
Bob’s wall or his ACL, a malicious provider could still
give Alice an outdated ACL in order to trick her into ac-
cepting operations from a revoked user. To mitigate this
threat, operations in Bob’s wall are annotated with depen-
dencies on Bob’s ACL history (the red dotted arrow in
Figure 1). A dependency indicates that a particular oper-
ation in one object happened after a particular operation
in another object. Thus, by including a dependency in an
operation that it posts to Bob’s wall, a client forces the
provider to show anyone who later reads the operation
an ACL that is at least as new as the one that the client
observed when it created the operation. In §4.2, we ex-
plain the implementation of dependencies and describe
additional situations where they can be used.
4. System Design
Clients interact with Frientegrity primarily by reading and
writing objects and ACLs via the following four RPCs: 2
• readObject(objectID, k, [otherOps]). Returns the k
most recent operations in object objectID, and option-
ally, a set of additional earlier operations from the
object (otherOps). But as we explain in the previous
section, the provider must also return enough opera-
tions from the object to allow the client to verify that
the provider has not equivocated and proofs from the
ACL that show that every operation came from an
authorized user. In addition, it must return key ma-
terial from the ACL that allows the client to decrypt
the object.
• writeObject(objectID, op). Submits the new operation
op to object objectID. Every new operation is signed
by the user that created it. To allow clients to enforce
fork* consistency, it also includes a compact repre-
sentation of the submitting client’s view of object’s
state. (This implies that the client must have read the
object at least once before submitting an update.)
• readACL(aclID, [userToAdd] [userToRemove]). Re-
turns ACL aclID and its corresponding ACL history
object. As an optimization, the client can optionally
specify in advance that it intends to add or remove
particular users from the ACL so that the provider
only has to return the portion of the ACL that the
client needs to change.
• writeACL(aclID, aclUpdate). Submits an update to
ACL aclID. Only administrator users (e.g., the owner
of a Facebook-like proﬁle) can modify the ACL. The
objects to which the ACL applies are encrypted under
a key that is shared only among currently authorized
2For brevity, we omit RPCs for creating new objects and
ACLs and for adding new users to the system.
6
users. Thus, to add a user, the client must update the
ACL so that it includes the encryption of this shared
key under the new user’s public key. To remove a
user, the ACL must be updated with a new shared key
encrypted such that all remaining users can retrieve
it. (See §4.3.3.)
The remainder of this section describes how Frientegrity
makes these RPCs possible. It discusses the algorithms
and data structures underlying object veriﬁcation (§4.1),
dependencies between objects (§4.2), and veriﬁable access
control §4.3).
4.1 Making Objects Veriﬁable
4.1.1 Object Representation
Frientegrity’s object representation must allow clients to
compare their views of the object’s history without requir-
ing any of them to have the entire history. Representing
an object as a simple list of operations would be insuﬃ-
cient because it is impossible to compute the hash of a list
without having all of the elements going back to the ﬁrst
one. As a result, objects in Frientegrity are represented as
history trees.
A history tree, ﬁrst introduced by Crosby et al. [11] for
tamper-evident logging, is essentially a versioned Merkle
tree [41]. Like an ordinary Merkle tree, data (in this case,
operations) are stored in the leaves, each internal node
stores the hash of the subtree below it, and the hash of the
root covers the tree’s entire contents. But unlike a static
Merkle tree, a history tree allows new leaves (operations)
to be added to the right side of the tree. When that occurs,
a new version of the tree is created and the hashes of the
internal nodes are recomputed accordingly.
This design has two features that are crucial for Frien-
tegrity. First, as with a Merkle tree, subtrees containing
unneeded operations can be omitted and replaced by a
stub containing the subtree’s hash. This property allows
a Frientegrity client which has only downloaded a subset
of an object’s operations to still be able to compute the
current history hash. Second, if one has a version j history
tree, it is possible to compute what the root hash would
have been as of version i < j by pretending that operations
i + 1 through j do not exist, and by then recomputing the
hashes of the internal nodes.
Frientegrity uses history trees as follows. Upon receiv-
ing a new operation via a writeObject RPC, the server
hosting the object adds it to the object’s history tree, up-
dates the root hash, and then digitally signs the hash. This
server-signed hash is called a server commitment and is
signed to prevent a malicious client from later falsely ac-
cusing the server of cheating.
When Alice reads an object of version i by calling read-
Object, the server responds with a pruned copy of the
object’s history tree containing only a subset of the opera-
1. Suppose that Alice fetches an object, and the provider
replies with the pruned object shown in Figure 2. Be-
cause the object has version 15, the provider also
sends Alice its commitment C15. On receiving the
object, she checks the server’s signature on C15, re-
computes the hashes of the internal nodes, and then
veriﬁes that her computed root hash C(cid:48)
15 matches C15.
Every operation she receives is signed by the user
that created it, and so she veriﬁes these signatures as
well.
2. Alice checks the prevCommitment of the last opera-
tion (op15), which in this case is C12.3 To do so, Alice
computes what the root hash would have been if op12
were the last operation and compares her computed
value to C12. (She must have op12 to do this.)
3. Alice checks the prevCommitment of every operation
between op12 and op15 in the same way.
4. Frientegrity identiﬁes every object by its ﬁrst opera-
tion.4 Thus, to make sure that the provider did not
give her the wrong object, Alice checks that op0 has
the value she expects.
4.1.3 Correctness of Object Veriﬁcation
The algorithm above aims to ensure that at least one hon-
est user has checked the contents and prevCommitment
of every operation in the history. To see how it achieves
this goal, suppose that op15 in the example was created
by the honest user Bob. Then, C12 must have been the
most recent server commitment that Bob saw at the time
he submitted the operation. More importantly, however,
because Bob is honest, Alice can assume that he would
have never submitted the operation unless he had already
veriﬁed the entire history up to op12. As a result, when
Alice veriﬁes the object, she only needs to check the con-
tents and prevCommitments of the operations after op12.
But how was Bob convinced that the history is correct up
to op12? He was persuaded the same way Alice was. If the
author of op12 was honest, and op12’s prevCommitment
was Ci, then Bob only needed to examine the operations
from opi+1 to op12. Thus, by induction, as long as writers
are honest, every operation is checked even though no
single user examines the whole history.
Of course in the preceding argument, if any user col-