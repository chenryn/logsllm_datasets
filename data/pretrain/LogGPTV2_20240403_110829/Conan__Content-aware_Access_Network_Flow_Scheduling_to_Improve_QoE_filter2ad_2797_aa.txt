# Title: Conan: Content-Aware Access Network Flow Scheduling to Improve QoE of Home Users

**Authors:** Haixiang Yang, Xiaoliang Wang, Cam-Tu Nguyen, Sanglu Lu

**Special Section on Mobile Multimedia: Methodology and Applications**

- **Received:** December 9, 2019
- **Accepted:** December 26, 2019
- **Publication Date:** January 6, 2020
- **Current Version Date:** January 14, 2020
- **Digital Object Identifier (DOI):** 10.1109/ACCESS.2020.2964258

## Dueling Deep-Q-Network Based Delay-Aware Cache Update Policy for Mobile Users in Fog Radio Access Networks

**Authors:**
- Boren Guo
- Xin Zhang
- Qiwei Sheng
- Hongwen Yang

**Affiliation:**
School of Information and Communication Engineering, Beijing University of Posts and Telecommunications, Beijing 100876, China

**Corresponding Author:**
Xin Zhang (Email: [PI:EMAIL])

**Funding:**
This research was supported by the National Science and Technology Major Project with grant No. 2018ZX03001024-006.

### Abstract

Fog radio access networks (F-RANs) can effectively alleviate fronthaul loads and reduce content transmission delay by migrating cloud services to the network edge. This paper addresses a cooperative caching scenario in F-RANs, where each mobile user (MU) can acquire requested contents from any one of its associated fog-computing-based access points (F-APs). However, caching disparate contents in different F-APs leads to varying content delivery delays due to diverse channel fadings and interferences. Considering limited caching storage, diverse user preferences, unpredictable user mobility, and time-varying channel states, an average transmission delay minimization problem is formulated. Using the dueling deep-Q-network (DQN) framework, a delay-aware cache update policy is proposed for MUs in F-RANs. The proposed policy decides which stored contents in F-APs should be replaced at each time slot. Simulation results show that the proposed caching policy outperforms traditional policies like First In First Out (FIFO), Least Recently Used (LRU), and Least Frequently Used (LFU) in terms of average hit ratio and lower average transmission delay.

### Index Terms
- Caching
- Fog radio access network
- Hit ratio
- Mobility
- Reinforcement learning

## I. Introduction

The rapid advancement of smart devices and multimedia applications has led to a significant increase in mobile data traffic over wireless networks. According to the Cisco white paper [1], global mobile data and Internet traffic are predicted to grow at a compounded annual growth rate of 46%, posing serious challenges such as network congestion and server overload. Although numerous redundant and repeated contents exist, caching popular contents in the centralized baseband unit (BBU) pool of cloud radio access networks (C-RANs) can reduce redundancy. However, capacity-limited fronthaul links still struggle with a large number of content requests.

To alleviate the pressure on fronthaul links, fog radio access networks (F-RANs) have been proposed [6]. F-APs in F-RANs are equipped with fog-computing units, storage resources, and part of baseband processing functions, allowing them to cache popular contents at the network edge. By storing contents closer to MUs, fronthaul load can be effectively reduced. However, optimizing the use of computation resources and storage capacities in F-APs remains a challenge. Additionally, time-varying user characteristics, including content preferences and mobility, complicate the decision of what, when, and where to cache.

Content caching typically involves cache placement [7]–[14] and cache update [15]–[17]. Cache placement determines what to store, while cache update decides when to store. Researchers have focused on predicting content popularity to place the most popular contents in local caches. For cache update, a requested content should be stored at an appropriate time slot to maximize the long-term average hit ratio. Cooperative caching [11], [18]–[22] further improves cache space utilization by allowing MUs to obtain requested contents from multiple F-APs. However, the unpredictable mobility of MUs and time-varying channel states make it challenging to optimize caching policies, especially for delay-sensitive services.

This paper proposes a dueling DQN-based delay-aware cache update policy for MUs in F-RANs. The policy aims to minimize the average transmission delay by deciding which F-APs should store the requested contents. Simulation results demonstrate that the proposed policy outperforms traditional caching policies (FIFO, LRU, LFU) in terms of average hit ratio and lower average transmission delay. The main contributions are:

- Formulating an average transmission delay minimization problem considering time-varying user preferences, unpredictable user mobility, cooperative caching between adjacent F-APs, and different channel states.
- Modeling the cache update as a Markov decision process (MDP) and using the dueling DQN technique to solve the MDP without prior knowledge of state transition probabilities.
- Validating the performance of the proposed caching policy through simulations and analyses compared to FIFO, LRU, and LFU policies.

The rest of the paper is organized as follows: Section II discusses related works, Section III presents the system model, Section IV introduces the proposed dueling DQN-based delay-aware cache update policy, and Section V concludes the paper.

## II. Related Works

Content caching, including cache placement and cache update, has attracted researchers from various fields such as device-to-device (D2D) communications [13], [16], [21], [22], [26], [27], F-RANs [12], [28], [29], and mobile edge computing [7], [18], [30].

### Cache Placement

Researchers have focused on obtaining content popularity and user characteristics to proactively cache the most popular contents. For example, [7] proposed three hierarchical edge caching mechanisms for 5G edge computing, [8] studied cache space-efficient caching in content-centric mobile ad hoc networks, and [9] addressed a mobile edge cache placement optimization problem using a greedy algorithm. [10] proposed location-customized caching schemes, and [11] used deep learning to predict user preferences in both centralized and distributed ways. [12] proposed two edge caching architectures to predict content popularity, and [13] applied transfer learning to optimize caching policies in D2D communications. [14] used Bayesian learning to estimate individual content request probabilities and incorporate them into caching strategies.

### Cache Update

For cache update, researchers aim to maximize the long-term average hit ratio. [15] employed a deep reinforcement learning (DRL) framework to make content replacement decisions, [16] used multi-agent RL for D2D networks, and [17] proposed a Q-learning caching algorithm for 5G cellular networks.

### Cooperative Caching

Cooperative caching [11], [18]–[22] improves storage resource utilization. [18] proposed a mobility-aware caching framework for 5G networks, [19] focused on cooperative caching in heterogeneous ultradense networks, and [20] proposed a cooperative probabilistic caching strategy in spatially clustered cellular networks. [21] presented a distributed collaborative cache management scheme for D2D communications, and [22] built a cooperative cache list to determine which videos to cache.

### Content Delivery

Some works [26], [28], [29], [31] consider both content caching and delivery. [26] designed a non-parametric estimator for request intensity and proposed a learning-based caching algorithm, [28] presented a mobile virtual reality delivery framework in F-RANs, and [29] constructed a fog-community architecture for content caching from a social viewpoint. [31] proposed a theoretical framework to characterize the tradeoff among computing, cache, and communication resources.

### Energy-Efficient and Economical Caching

[32]–[34] address energy-efficient and economical caching policies. [32] investigated optimal economical caching schemes in cache-enabled heterogeneous networks, [33] used integer linear programming to evaluate energy benefits, and [34] proposed a threshold-based proactive caching scheme to minimize long-term average energy cost.

### Vehicle Mobility

[35], [36] considered vehicle mobility, predicting vehicle movement to store contents in the next associated road side unit. [36] investigated the caching problem of multi-view 3D videos in 5G networks using an actor-critic, model-free algorithm, and [35] proposed a Q-learning-based proactive caching strategy for vehicular networks.

To the best of our knowledge, few studies have considered both unpredictable user mobility and time-varying channel states.

## III. System Model

This section describes the cooperative content caching and delivery scenario for MUs in F-RANs. It includes the user mobility model, content caching and delivery processes, and the formulation of an average transmission delay minimization problem.

### A. System Model

The cooperative content caching and delivery scenario for MUs is illustrated in Fig. 1. An MU stays in the cooperation region of F-AP 1 and 2 at time slot \( t \) to download files from one of its associated F-APs. When the MU moves to the cooperation region of F-AP 2 and 3 at time slot \( t' \), its associated F-APs change to F-AP 2 and 3. The F-RAN architecture consists of \( M \) F-APs and \( K \) MUs. Let \( F = \{1, 2, \ldots, f, \ldots, M\} \) and \( U = \{1, 2, \ldots, u, \ldots, K\} \) denote the F-AP set and MU set, respectively. Each F-AP has limited storage capacity and can cooperate with adjacent F-APs. For simplicity, each MU is assumed to be served by two adjacent F-APs. The associated F-APs set for each MU at time slot \( t \) is represented by \( F_u^t = \{f_u^{t,1}, f_u^{t,2}\} \).

### B. User Mobility

User mobility in F-RANs is unpredictable, and the topological relationship between MUs and their associated F-APs changes over time. This makes it challenging to maintain up-to-date cached contents that meet the demands of incoming MUs.

### C. Content Caching and Delivery

Content caching and delivery processes involve storing popular contents in F-APs and delivering them to MUs. When an MU downloads content from an F-AP, it may experience different channel fadings and interferences, leading to varying content transmission delays. To minimize the average transmission delay, the caching policy must decide which F-APs should store the requested contents.

### D. Problem Formulation

The goal is to minimize the average transmission delay for requested contents. The problem is formulated as an optimization problem, considering time-varying user preferences, unpredictable user mobility, cooperative caching between adjacent F-APs, and different channel states. The next section will present the proposed dueling DQN-based delay-aware cache update policy to address this problem.