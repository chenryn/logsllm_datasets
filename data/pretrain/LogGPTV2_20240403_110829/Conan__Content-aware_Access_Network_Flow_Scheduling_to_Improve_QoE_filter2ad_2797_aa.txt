title:Conan: Content-aware Access Network Flow Scheduling to Improve QoE
of Home Users
author:Haixiang Yang and
Xiaoliang Wang and
Cam-Tu Nguyen and
Sanglu Lu
SPECIAL SECTION ON MOBILE MULTIMEDIA: METHODOLOGY AND APPLICATIONS
Received December 9, 2019, accepted December 26, 2019, date of publication January 6, 2020, date of current version January 14, 2020.
Digital Object Identifier 10.1109/ACCESS.2020.2964258
Dueling Deep-Q-Network Based Delay-Aware
Cache Update Policy for Mobile Users in Fog
Radio Access Networks
BOREN GUO , XIN ZHANG , QIWEI SHENG , AND HONGWEN YANG
School of Information and Communication Engineering, Beijing University of Posts and Telecommunications, Beijing 100876, China
Corresponding author: Xin Zhang (PI:EMAIL)
The research was supported by National Science and Technology Major Project with grant No. 2018ZX03001024-006.
ABSTRACT Fog radio access networks (F-RANs) can effectively alleviate fronthaul loads and reduce
content transmission delay by migrating cloud services to the network edge. This paper addresses a
cooperative caching scenario in F-RAN, where each mobile user can acquire the requested contents from
any one of its associated fog-computing-based access points (F-APs). However, caching disparate contents
in different F-APs will lead to different content delivery delays, since mobile users suffer from diverse
channel fadings and interferences when they download contents from different F-APs. Considering limited
caching storage in each F-AP, diverse user preferences, unpredictable user mobility and time-varying channel
states, an average transmission delay minimization problem is formulated. With the aid of dueling deep-
Q-network framework, a delay-aware cache update policy is proposed for mobile users in F-RAN. The
proposed cache update policy will decide to replace the stored contents in F-APs with the proper contents
at each time slot. Compared with ﬁrst in ﬁrst out, least recently used and least frequently used caching
policies, simulation experiments are performed to evaluate the performance of the proposed algorithm.
Simulation results illustrate that the proposed caching policy yields better average hit ratio and lower average
transmission delay than other traditional caching policies.
INDEX TERMS Caching, fog radio access network, hit ratio, mobility, reinforcement learning.
I. INTRODUCTION
Driven by the rapid advance of diverse smart devices and
various multimedia applications, the mobile data trafﬁc over
wireless network has experienced a tremendous growth.
In the Cisco white paper [1], the global mobile data and
Internet trafﬁc is predicted to grow at compounded annual
growth rate of 46%, which will impose many serious issues on
wireless network, e.g., network congestion, server overload
and so forth. Although uncountable multimedia data surges
from different services, e.g, Internet of things [2], network
slicing [3], wireless-powered communication [4], device to
device (D2D) communications [5], etc., there are numerous
redundant and repeated contents. Caching the popular con-
tents in the centralized baseband unit (BBU) pool of cloud
radio access network is an effective approach to reduce redun-
dant and repeated data, but capacity-limited fronthaul links
still suffer from a large number of content requests from var-
ious applications. To relieve the pressure on fronthaul links,
The associate editor coordinating the review of this manuscript and
approving it for publication was Dapeng Wu
.
fog radio access network (F-RAN) as a promising architec-
ture has been proposed [6]. The access points in F-RAN,
also named fog-computing-based access points (F-APs), are
equipped with fog-computing units, storage resources and
part of baseband processing functions, so as to cache the most
popular contents at the network edge. By storing the contents
closer to the requesting mobile users (MU), the fronthaul
load can be alleviated effectively. However, how to make
full use of the computation resources and storage capacities
in the F-APs has attracted more and more attentions from
researchers. In addition, owing to the time-varying user char-
acteristics including content preferences and user mobility,
what, when and where to cache has been one of the hottest
issues in recent years.
Generally, content caching includes cache placement
[7]–[14] and cache update [15]–[17]. Speciﬁcally, the cache
placement policy ﬁgures out what should be stored, whilst
the cache update policy addresses when to store. To solve
the cache placement problem, researchers devote to pre-
dict the content popularity. Then, the most popular con-
tents are placed in the local cache, and the stored contents
VOLUME 8, 2020
This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see http://creativecommons.org/licenses/by/4.0/
7131
B. Guo et al.: Dueling DQN-Based Delay-Aware Cache Update Policy for Mobile Users in F-RANs
are unchanged for a long time. In the cache update policy,
a requested content should be stored at a proper time slot.
Therefore, the requested content can be delivered in time,
when the request occurs at next slot. The stored contents may
be different at each slot. Considering the time-varying user
preferences, cache update is a feasible way to maximize the
long-term average hit ratio.
In addition, cooperative caching [11], [18]–[22] is an
effective way to improve the cache space utilization. The
cooperative caching means that the requested contents can be
obtained from multiple content providers via content sharing
and other manners. Since each MU in the F-RAN system can
be served by multiple F-APs, it can get the contents from any
one of its associated F-APs. Storing the requested contents
in different F-APs will leads to different cache hit ratios.
Therefore, where to store the requested contents is also a
signiﬁcant problem for the researchers concerned about the
cooperative caching.
Although the cooperative caching can effectively enhance
the cache space utilization, the unpredictable mobility of
MUs has a signiﬁcant impact on the utilization. Since the
topological relation between the MUs and their associated
F-APs is time-varying, some of the stored contents may
not be requested by the new incoming MUs. Consequently,
the stored contents should be updated timely to meet the
demands of MUs.
Besides, the content delivery can also heavily affect the
caching policies, especially for the delay-sensitive services.
In F-RAN, when an MU downloads contents from its asso-
ciated F-APs, the MU may suffer from different channel
fadings and interferences, which will result in different con-
tent transmission delays. To achieve the minimum average
transmission delay, the caching policy should decide which
F-APs the requested contents should be stored in.
This paper considers a cooperative content caching and
delivery scenario for MUs in the F-RAN system. In such
case, user preferences and channel states are time-varying,
the mobility pattern of each MU is unpredictable. In order
to minimize the average transmission delay of the requested
contents, how to store contents in the F-APs is a complicated
problem. Inspired by the success of machine learning apply-
ing in various ﬁelds [23], [24], a deep reinforcement learning
(DRL) framework, dueling deep-Q-network (DQN) [25] is
employed to settle the problem above. Notably, a dueling
DQN based delay-aware cache update policy is proposed.
Compared with three traditional caching policies, i.e., ﬁrst
in ﬁrst out (FIFO), least recently used (LRU) and least fre-
quently used (LFU), the performance of the proposed caching
policy is evaluated through simulations and analyses. The
main contributions can be drawn as follows:
• Taking into account
time-varying user preferences,
unpredictable user mobility,
caching
between adjacent F-APs and different channel states,
including channel fading and interference, an aver-
age transmission delay minimization problem is
formulated.
cooperative
• To address the optimization problem above, the cache
update is modeled as an Markov decision process
(MDP). Then, dueling DQN technique is adopted to deal
with the MDP problem without any priori knowledge
of state transition probability. Finally, a dueling DQN
based delay-aware cache update policy is proposed.
• In comparison with FIFO, LRU and LFU caching poli-
cies, the performance of the proposed caching policy
is validated in terms of average hit ratio and average
transmission delay.
The rest of this paper is organized as follows. The related
works are discussed in the next section. Section III presents
the system model of cooperative content caching and delivery
in F-RAN. In Section IV, a dueling DQN based delay-aware
cache update policy is proposed. Finally, Section V concludes
this paper.
II. RELATED WORKS
The content caching problem, including cache placement and
cache update, has attracted researchers from many ﬁelds,
e.g., D2D communications [13], [16], [21], [22], [26], [27],
F-RAN [12], [28], [29], mobile edge computing [7], [18], [30]
and so on.
As for the cache placement [7]–[14], researchers focus on
how to obtain the content popularity and user characteris-
tics, e.g., content preference, quality of experience (QoE),
mobility and so forth, so as to proactively cache the most
popular contents. Authors in [7] proposed three hierarchical
edge caching mechanisms, including random caching, proac-
tive caching and game-theory-based caching, for 5G edge
computing mobile multimedia wireless networks, where pop-
ular multimedia contents can be cached at routers, base sta-
tions or mobile devices. Considering a tradeoff between cache
hit ratio and occupied cache space, research in [8] studied the
cache space efﬁcient caching in content-centric mobile ad hoc
networks. Considering the different rate-distortion character-
istics of videos and the coordination of cache providers, [9]
addressed a mobile edge cache placement optimization prob-
lem via greedy algorithm. Taking into account users’ diverse
demands over different locations, [10] proposed location cus-
tomized caching schemes. Besides, two popularity prediction
algorithms are developed for two noise models. By using deep
learning, authors in [11] proposed two proactive cooperative
caching algorithms to predict user preferences in a central-
ized way and a distributed way, respectively. By learning
user preference, two edge caching architectures are proposed
to predict content popularity in [12]. By applying transfer
learning technique, the knowledge of user preference and
activity level can be learned to optimize the caching policy
in D2D communications [13]. With the aid of the rating
matrix, Cheng et al. proposed a Bayesian learning method
to estimate the individual content request probability, which
reﬂects personal preferences. Then, the estimated request
probability is incorporated into caching strategy to optimize
system throughput [14].
7132
VOLUME 8, 2020
B. Guo et al.: Dueling DQN-Based Delay-Aware Cache Update Policy for Mobile Users in F-RANs
For the cache update [15]–[17], researchers look for poli-
cies to maximize the long-term average hit ratio. For the ﬁrst
time, Zhong et al. employed DRL framework to make content
replacement decisions to maximize the hit ratio [15] for a sin-
gle base station. Employing multi-agent RL technique, Jiang
et al. proposed a content caching strategy in D2D networks
[16]. Considering the space-time popularity of requests and
cache-refreshing costs, authors in [17] proposed a Q-learning
caching algorithm for 5G cellular networks.
Besides, cooperative caching [11], [18]–[22] is an effec-
tive approach to improve the utilization of storage resource.
Researchers in [18] focused on a cooperative edge caching
architecture for content-centric 5G networks, and pro-
posed a mobility-aware caching framework for MUs.
Lin et al. focused on cooperative caching in the heterogeneous
ultradense network, which includes coordinated multipoint-
integrated ultradense cells and cluster-based device-to-device
(D2D) networks [19]. In [20], Zhou et al. proposed a coop-
erative probabilistic caching strategy in a spatially clustered
cellular networks scenario, where base stations within a clus-
ter can share cached contents with each other. Wu et al.
studied which content should be cached and which requester
is important, and proposed a distributed collaborative cache
management scheme for D2D communications [21]. Taking
into account users’ similarity in accessing videos, the work in
[22] built a cooperative cache list to determine what videos
need to be cached.
The works in [26], [28], [29] and [31] not only focus
on the content caching, but also consider the content deliv-
ery. Authors in [26] designed a non-parametric estimator to
learn the intensity function of requests, and then proposed a
learning-based caching algorithm in D2D-enabled networks.
[28] presented a mobile virtual reality delivery framework
in the fog radio access network, and a joint caching and
computing policy is proposed to optimize resource alloca-
tion. Li et al. constructed a fog-community architecture for
content caching in D2D enabled F-RAN from the social view
point [29]. A theoretical framework is proposed in [31] to
characterize the tradeoff among computing, cache and com-
munication resources for content delivery in the mobile edge
network.
Moreover, some researchers [32]–[34] address economi-
cal efﬁciency and energy-efﬁcient caching policies. To pro-
vide different services for users with different requirements,
the authors in [32] investigated the optimal economical
caching schemes in cache-enabled heterogeneous networks.
To minimize the energy consumption of the network, authors
in [33] employed an integer linear programming optimization
model to evaluate energy beneﬁts and proposed a heuristic
algorithm to power-on and power-off caches. Taking into
account the energy cost of downloaded contents and chan-
nel quality, Somuyiwa et al. proposed a threshold-based
proactive caching scheme to minimize the long-term average
energy cost [34].
In addition, considering the mobility of vehicles,
the movement
researchers in [35], [36] tried to predict
FIGURE 1. Cooperative content caching for mobile users in F-RAN.
of vehicles, so that the contents can be stored in the next asso-
ciated road side unit in advance. Zhang et al. investigated the
caching problem of multi-view 3D videos in the 5G networks
[36], and an actor-critic, model-free algorithm is adopted
to ﬁnd the effective proactive caching policy. To improve
the QoS for non-safety related services, a Q-learning-based
proactive caching strategy for vehicular networks is proposed
in [35].To the best knowledge of the authors, few studies have
considered both unpredictable user mobility and time-varying
channel states.
III. SYSTEM MODEL
In this section, the cooperative content caching and deliv-
ery scenario for MUs is given ﬁrst. Then, the user mobil-
ity in F-RAN system is described. Besides, the content
caching and delivery processes are introduced respectively.
Finally, this section formulates an average transmission delay
minimization problem.
A. SYSTEM MODEL
The cooperative content caching and delivery scenario for
mobile users is illustrated in Fig. 1. As shown in Fig. 1,
an MU stays in the cooperation region of F-AP 1 and 2 at
slot t, so as to download ﬁles from one of its associated
F-APs (F-AP 1 and 2) nearby. When the MU moves to the
cooperation region of F-AP 2 and 3 at slot t(cid:48), its associated
F-APs change to F-AP 2 and 3. This paper considers multiple
cells scenario with the F-RAN architecture, which consists
of M F-APs and K MUs. Let F = {1, 2, . . . , f , . . . , M}
(and U = {1, 2, . . . , u, . . . , K}) denote the F-AP set (and
MU set), respectively. In the F-RAN system, the F-APs with
limited storage capacity are deployed at the network edge,
and the F-APs with close distance can cooperate and belong
to the same region [12], which can be also called cooperation
region. For simpliﬁcation, it is assumed that each MU can
be cooperatively served by two adjacent F-APs. For each
MU, its associated F-APs set at time slot t is represented
by F t
u,i ∈ F}.
u,2|f t
, f t