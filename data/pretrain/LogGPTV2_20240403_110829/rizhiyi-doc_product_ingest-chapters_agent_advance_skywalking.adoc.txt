====  可观察性数据的后端接入
对于单纯的 tracing 数据接入，可以通过 traceinput 方式接收。但随着 opentelemetry 的发展，越来越多的客户端会同时发送 tracing、metric、log 数据，依赖 traceinput 接收全部数据第一不现实，第二也有单机压力。因此，日志易还提供从服务端同时接收多种可观察性数据的方案。
===== Elastic APM
Elastic APM Server 支持通过插件将数据转发到不同后端，日志易建议通过转发到 Kafka 的方式，完成数据的对接。官方配置文档见：。
简要配置如下：
[source,yaml]
----
output.kafka:
  hosts: ["kafka1:9092", "kafka2:9092", "kafka3:9092"]
  topic: 'elastic_apm'    #可自定义并供日志易 heka  kafkainput 采集的 topic
  partition.round_robin:
    reachable_only: false
  required_acks: 1
  compression: gzip
  max_message_bytes: 1000000
----
===== Skywalking APM
由于 skywalking 不同版本之间 protobuf 协议变动太大，而 skywalking 自身的 storage 机制只支持单一数据存储，不支持发送给 Kafka，官方版本的 agent kafka exporter 也用的是 protobuf 协议。因此，日志易提供定制版本的 skywalking agent kafka exporter 供下载使用。有需求时请联系日志易技术支持。
**流程原理**
. 配置skywalking agent通过kafka reporter(自定义)将数据发往kafka
. 自定义kafka reporter会将pb格式的数据写入配置的topic，json格式的数据写到对应的topicname_json里面去
. skywalking通过kafka fetcher采集pb格式数据的topic
. heka或者数据工厂采集json格式数据的topic
**准备工作**
默认情况下pb数据会写到kafka的以下topic(这些topic最好手动创建，如果没有，则启动oap时会自动创建)
* skywalking-meters
* skywalking-managements
* skywalking-metrics
* skywalking-profilings
* skywalking-segments
默认情况下json数据会写到kafka的以下topic(即pb数据对应topic的名字后面加上_json；这些topic必须手动创建)
* skywalking-meters_json
* skywalking-managements_json
* skywalking-metrics_json
* skywalking-profilings_json
* skywalking-segments_json
**配置方法**
配置 agent exporter 的主要方法，请阅读官方文档：。
简要步骤如下：
. 将日志易提供的 kafka-reporter-plugin-x.x.x-SNAPSHOT.jar 放到 agent/plugin 路径下
. 修改 agent/config/agent.config 文件，示例如下：
+
[source,]
----
plugin.kafka.bootstrap_servers=${SW_KAFKA_BOOTSTRAP_SERVERS:192.168.1.54:9092} # 多个地址使用,分隔
# 以下均为默认配置，可不添加，如果需要改对应的topic，可以更改，更改后，skywalking oap对应的topic名字也需要修改
plugin.kafka.topic_metrics=skywalking-metrics
plugin.kafka.topic_profiling=skywalking-profilings
plugin.kafka.topic_segment=skywalking-segments
plugin.kafka.topic_management=skywalking-managements
plugin.kafka.topic_meter=skywalking-meters
----
+
. 启动/重启动待采集的业务程序
配置 otp fetcher 的主要方法，请阅读官方文档：。
简要步骤如下：
. 修改oap的配置文件config/application.yml文件，示例如下：
+
[source,yaml]
----
kafka-fetcher:
  selector: ${SW_KAFKA_FETCHER:-} # 将此处改为default即可，即和注释中的一样
  #selector: ${SW_KAFKA_FETCHER:default}
  default:
    bootstrapServers: ${SW_KAFKA_FETCHER_SERVERS:192.168.1.54:9092} # kafka对应的地址
    partitions: ${SW_KAFKA_FETCHER_PARTITIONS:3} # 以下为kafka中对应的topic信息
    replicationFactor: ${SW_KAFKA_FETCHER_PARTITIONS_FACTOR:2} # 不存在的话会按照以下信息创建
    enableMeterSystem: ${SW_KAFKA_FETCHER_ENABLE_METER_SYSTEM:false}
    enableLog: ${SW_KAFKA_FETCHER_ENABLE_LOG:false}
    isSharding: ${SW_KAFKA_FETCHER_IS_SHARDING:false}
    consumePartitions: ${SW_KAFKA_FETCHER_CONSUME_PARTITIONS:""}
    kafkaHandlerThreadPoolSize: ${SW_KAFKA_HANDLER_THREAD_POOL_SIZE:-1}
    kafkaHandlerThreadPoolQueueSize: ${SW_KAFKA_HANDLER_THREAD_POOL_QUEUE_SIZE:-1}
----
+
. 重启skywalking oap服务
最后，配置日志易 heka 的 kafkainput，即可完成数据对接。