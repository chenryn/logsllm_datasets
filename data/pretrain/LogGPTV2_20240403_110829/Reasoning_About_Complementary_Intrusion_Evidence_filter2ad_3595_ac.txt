### Hypothesis and Bayesian Inference

In the Bayesian inference process, if a hypothesized attack is deemed impossible, its probability is updated to 0, indicating that the hypothesis cannot represent a successful attack. Validation is essential for all hypotheses, and it is inherently part of the Bayesian inference process.

As more Intrusion Detection System (IDS) alerts are reported, the Bayesian network will expand. Techniques such as sliding time windows can be employed to manage this growth. We plan to explore these techniques in future work.

### Experimental Results

We conducted a series of experiments to evaluate the effectiveness of the proposed techniques. The experimental setup involved three PCs connected through a hub in an isolated network, designated as the attacker, victim, and IDS. Attacks were launched from the attacker against the victim, with the IDS monitoring the attacks.

#### System Setup

- **IDS Sensor**: Snort version 1.9.1 [24]
- **Vulnerability Scanning Tools**: Nessus [3] and XScan [30]
- **File System Integrity Monitoring Tools**:
  - For MS Windows: TripWire [5]
  - For Linux: Samhain [4]
- **Trojan Horse Scanning Tools**:
  - For MS Windows: Tauscan [27]
  - For Linux: chkrootkit 0.43 [1]

We evaluated our techniques using five attack scenarios, each with different goals, ranging from modifying the target’s web page to converting the target machine into part of the attacker’s distributed network. The victim's operating system (either Windows or Linux) varied depending on the attack scenario.

We developed a program to automatically generate alert-attribute networks from the IDS alerts and the reports of the scanning tools, and then used JavaBayes [2] to perform inference on these networks.

To simulate real-world system administration, we configured the file system integrity monitoring tools to monitor only critical files and directories, such as system configuration files, service configuration files, and main webpage files.

To mimic an operational network, we injected background traffic into the network during our experiments. We used a randomly selected training dataset from the 1999 DARPA datasets [19] as the background traffic, which triggered 325 false alerts in Snort.

#### Scenario Analysis

##### Scenario 0: Detailed Analysis

In this scenario, the attacker exploited a remote buffer overflow vulnerability in an older version of the Serv-U FTP server to gain administrative access. The victim machine was a Windows box running a vulnerable Serv-U 5.0 FTP server with default public anonymous access. The victim also had Norton Anti-Virus with file system real-time protection, which quarantined any known viruses or backdoors.

The attack consisted of the following steps:

1. **Remote Buffer Overflow Attack** against the Serv-U FTP server.
2. **Attempt to Install BackOrifice**, which was quarantined by Norton Anti-Virus.
3. **Killing the Norton Anti-Virus Process** using system process tools through the remote administrative shell.
4. **Reinstalling BackOrifice** (successful).
5. **Modifying the Web Page** via BackOrifice.

**Initial System Attributes**:
- Serv-U 5.0 running on port 21
- Anonymous FTP access
- Norton Anti-Virus running with file system real-time protection

**Alerts Reported by Snort**:
- 1 FTP command overflow attempt alert
- 1 BACKDOOR BackOrifice access alert

**Logs**:
- Norton logged that BackOrifice was found and quarantined.
- Tripwire logged and reported the modification to the web page file.
- The system logged that Norton Anti-Virus was shut down.

**Reasoning**:
Our alert-attribute network generation tool created the network shown in Figure 4, based on the above information and prior probabilities and attack type information (included in the appendix).

**Figure 4: Initial Alert-Attribute Network**
- **Nodes**:
  - White nodes: IDS alerts
  - Gray nodes: Unverified system attributes
  - Black nodes: Verified system attributes
- **Node Positions**: Represent the relative time order among nodes.

Note that Figure 4 includes 156 "SNMP public access udp" alerts, resulting in 2156 entries in the conditional probability table. This exceeds JavaBayes' handling capacity. After alert aggregation, the 156 nodes were aggregated into a single node, making it manageable for JavaBayes.

**Inconsistencies and Missed Attacks**:
- No detected alerts caused the verified attributes "Norton Anti-virus not running," "Virus BackOrifice found & quarantined," and "Webpage file modified."
- Possible hypotheses to fill these gaps include "Shut down Norton Anti-virus via cmd.exe shell" and "Install BackOrifice."

**Figure 5: Updated Alert-Attribute Network**
- Dotted nodes and edges denote hypothesized attacks and corresponding causal relationships.
- Conditional probability tables for each node were generated automatically given the network structure and prior probability values.

**Figure 6: Changes in Confidence**
- Significant increases in the confidence values of successful attacks.
- False alerts either decreased or remained unchanged in confidence.

**Using Confidence for Intrusion Detection**:
With the reasoning framework, we associated a quantitative measure (confidence) with each IDS alert. We used a confidence threshold to determine whether an alert represented a successful attack. If the confidence was greater than or equal to the threshold, the alert was accepted; otherwise, it was dropped. We varied the threshold between 0 and 1, collecting detection rates and false alert rates.

**Performance Comparison**:
- Without alert aggregation and abstraction
- With alert aggregation and abstraction

**Figure 7: Detection Rate and False Alert Rate**
- Shows significant improvements in detection rate and reduction in false alert rate with appropriate threshold values.

### Summary of Results

We summarize the results from all five attack scenarios, discussing the impact of the proposed techniques on alerts and hypothesized attacks. We used a metric called the confidence ratio, which is the ratio between the average confidence of alerts corresponding to successful attacks and the average confidence of other alerts (false alerts and failed attack attempts).

**Table 6: Interesting Observations**
- Three hypothesized nodes had a confidence value of 1.
- Both options to resolve the same inconsistency had a confidence value of 1, but this does not imply both attacks occurred.
- The path through "Modify web page via cmd.exe" had a higher probability, indicating it was simpler and easier.

The results show that with sufficient local system evidence, our model is efficient and effective in discovering missed attacks.

Proceedings of the 20th Annual Computer Security Applications Conference (ACSAC’04)  
1063-9527/04 $ 20.00 IEEE