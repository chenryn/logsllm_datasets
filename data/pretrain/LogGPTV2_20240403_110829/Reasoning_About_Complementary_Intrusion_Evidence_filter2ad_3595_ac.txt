pothesis, and then the Bayesian inference process will
update the probability of the hypothesized attack to 0, im-
plying that
the hypothesis cannot be a successful at-
tack.
Validation is necessary for all hypotheses. From the
above discussion about Bayesian inference about the hy-
potheses, we can see that the validation process is already
embedded in the Bayesian inference process.
As more IDS alerts are reported, the Bayesian network
will grow larger and larger. Some techniques (e.g., sliding
time window) can be adopted to deal with this issue. We
leave it as our future work.
3. Experimental Results
We have performed a series of experiments to evaluate
the effectiveness of the proposed techniques. In our experi-
ments, we connected three PCs through a hub in an isolated
network. For convenience, we refer to them as attacker, vic-
tim, and IDS. We launched attacks from the attacker against
the victim, while monitoring the attacks on the IDS.
System Setup: We use Snort version 1.9.1 [24] as the
IDS sensor. We also use Nessus [3] and XScan [30] as the
vulnerability scanning tools. We evaluate our techniques
Proceedings of the 20th Annual Computer Security Applications Conference (ACSAC’04) 
1063-9527/04 $ 20.00 IEEE 
with ﬁve attack scenarios. The goals of these attack scenar-
ios vary from modifying the target’s web page to converting
the target machine into a part of attacker’s own distributed
network. Some attack scenarios target MS Windows sys-
tems, while the others target Linux systems. Accordingly,
the victim runs either Windows or Linux, depending on the
attack scenarios. We run TripWire [5] (for MS Windows)
and Samhain [4] (for Linux) on the victim as the ﬁle system
integrity monitoring tools. We also run Trojan horse scan-
ning tools Tauscan [27] (for MS Windows) and chkrootkit
0.43 [1] (for Linux) on the victim as additional system scan-
ning tools. We developed a program to automatically gener-
ate alert-attribute networks from the IDS alerts and the re-
ports of these scanning tools, and then use JavaBayes [2] to
make inference using these networks.
To simulate the realworld system administration, we
conﬁgure the ﬁle system integrity monitoring tools (Trip-
wire and Samhain) to monitor important ﬁles and directo-
ries only, i.e., system conﬁgurations ﬁles, service conﬁgu-
ration ﬁles, and the main webpage ﬁles.
To mimic an operational network, we also inject back-
ground trafﬁc into the network during our experiments. We
randomly select one of the training datasets (the training
dataset on Monday in the third week) in the 1999 DARPA
datasets [19] as the background trafﬁc in the experiments, as
it is attack free. This background trafﬁc triggers 325 alerts
in Snort, which are all false alerts of course.
In the rest of this section, we ﬁrst present the analysis of
Scenario 0 in detail, and then summarize the results of all
ﬁve attack scenarios. Additional details of the other four at-
tack scenarios are included in the Appendix of the full ver-
sion of this paper.
Scenario Detail: In this attack scenario, the attacker ex-
ploits the remote buffer overﬂow vulnerability in some old
versions of Serv-U ftp server to get administrative access.
The victim machine is a Windows box running a vulner-
able Serv-U 5.0 ftp server with default public anonymous
access. The victim also runs Norton anti-virus with ﬁle sys-
tem real-time protection. When the system attempts to ac-
cess a ﬁle containing known virus or backdoor, the ﬁle sys-
tem real-time protection will quarantine the ﬁle.
The attack scenario includes ﬁve steps:
1. remote buffer overﬂow attack against the Serv-U,
2. attempt to install BackOriﬁce on the victim, which
was quarantined by the Norton anti-virus,
3. kill the Norton anti-virus process with system process
tools through the remote administrative shell,
4. install the BackOriﬁce again (successful), and
5. changing the web page through BackOriﬁce.
The initial system attributes include Serv-U 5.0 running
on port 21, anonymous ftp access, and Norton Anti-virus
running with ﬁle system real-time protection.
During the attack process, Snort reported 2 alerts:
• 1 FTP command overflow attempt alert
• 1 BACKDOOR BackOrifice access alert
Norton also logged that BackOriﬁce was found in the ﬁle
system and quarantined successfully during the attack pe-
riod. In the end, Tripwire logged and reported the modiﬁca-
tion to the web page ﬁle and the system logged that Norton
anti-virus was shut down.
Reasoning: Our alert-attribute network generation tool
generated the network shown in Figure 4 based on the above
information and the prior probabilities and attack type infor-
mation, which are included in the appendix of the full ver-
sion of the paper.
SNMP public
access
Serv-U 5.0
running on port
21 by
Administrator
Anonymous ftp
access
Norton Antivirus
realtime protection
running
156 SNMP public
…
udp alerts
FTP command overflow
attempt
Cmd.exe root shell access
¬Norton Antivirus realtime
protection running
BACKDOOR
Virus BackOrifice found &
quarantined
gain public host
information
BackOrifice access
(not to appear in
the network)
Webpage file modified
Figure 4. Initial alert-attribute network
To distinguish between different types of nodes in a
Bayesian network, we use white nodes to denote IDS alerts,
gray nodes to denote unveriﬁed system attributes, and black
nodes to denote veriﬁed system attributes. The relative ver-
tical position of nodes in the graph represents the relative
time order among nodes.
Note that Figure 4 includes 156 “SNMP public
access udp” alerts, which results in 2156 entries
in the conditional probability table of gain public
information. Computing with such a conditional prob-
ability table is out of JavaBayes’ handling capacity. How-
ever, after alert aggregation, the 156 nodes are aggregated
into a single node and thus can be handled easily by Jav-
aBayes.
several
obvious
in Figure
inconsistencies
Now let us look at possible missed attacks. There
are
4.
There are no detected alerts causing the veriﬁed at-
tributes
“Norton Anti-virus not running”,
“Virus BackOrifice found & quarantined”,
and “Webpage file modified”. Based on our
knowledge
“Shut down Norton
Anti-virus via cmd.exe shell” and “Install
BackOrifice” are the only possible hypotheses that
can ﬁll in the ﬁrst two gaps. For the attribute “Webpage
file modified”, it could be done through remote con-
trol via either cmd.exe shell or BackOriﬁce access. The
about
attacks,
Proceedings of the 20th Annual Computer Security Applications Conference (ACSAC’04) 
1063-9527/04 $ 20.00 IEEE 
ﬁrst option implies hypothesized remote control via
cmd.exe, while the second one implies hypothesized instal-
lation of BackOriﬁce after Norton was shut down. These
hypotheses lead to a new alert-attribute network in Fig-
ure 5. In Figure 5, the dotted nodes and edges denote hy-
SNMP public
access
SNMP public udp
gain public host
information
Serv-U 5.0 running
on port 21 by
Administrator
Anonymous
ftp access
Norton Antivirus
realtime protection
running
FTP command overflow
attempt
Cmd.exe root shell access
ALERT NAME
FTP com mand overflow
BACKDOOR BackOrifice access
Individual SNMP public access udp
aggregated SNMP public access udp
other 169 alerts
Shut down Norton Antivirus (Hypothesized)
  Install BackOrifice Instance 1 (Hypothesized)
  Install BackOrifice Instance 2 (Hypothesized)
M odify web page (Hypothesized)
BEFORE AFTER INCREASE
233.30%
100%
0%
0%
-100%
N/A
N/A
N/A
N/A
0.3
0.3
0.075
0.5
0.25
N/A
N/A
N/A
N/A
1
0.6
0.075
0.5
0
1
0
1
1
Install BackOrifice instance 1
Figure 6. Changes in conﬁdence
pared to the other option, which requires several extra attack
steps. Also, the probability of a hypothesized node being 0
means either it is not missed by the IDS, or it is a failed at-
tack attempt.
Using Conﬁdence for Intrusion Detection: With the
reasoning framework for intrusion evidence, we are able to
associate a quantitative measure (i.e., conﬁdence) with each
IDS alert.
In our experiments, we used a conﬁdence threshold to
determine whether an IDS alert is a successful attack or not.
Speciﬁcally, if the conﬁdence in an alert is greater than or
equal to the threshold, we accept the alert. Otherwise, we
simply drop it. We change the threshold value between 0
and 1, and collect the detection rates and false alert rates.
To compare the results in different situations, we repeated
the above process in two cases: (1) without alert aggrega-
tion and abstraction, (2) with alert aggregation and abstrac-
tion. The performance graphs for the ﬁve attack scenarios
are very similar.
In our evaluation, we abuse the notions of detection rate
and false alert rate to represent the detection rate of suc-
cessful attacks and false alert and failed attack rate, respec-
tively. Figure 7 shows the detection rate and false alert rate
w.r.t. different thresholds in all cases for one of our sce-
narios. (Since the meaning of the conﬁdence in a hypoth-
esized attack is different from that in an IDS alert, we do
not consider hypothesized attacks in this evaluation.) This
ﬁgure shows that the Bayesian reasoning with veriﬁed ev-
idence can signiﬁcantly increase the detection rate and de-
crease the false alert rate with appropriate threshold values.
Summary of Results: In the following, we summarize
the results obtained from all the ﬁve attack scenarios. We
ﬁrst discuss the impact of the proposed techniques on alerts,
and then describe the results about hypothesized attacks.
We use a simple metric named conﬁdence ratio to exam-
ine the usefulness of the proposed techniques. Speciﬁcally,
a conﬁdence ratio is the ratio between the average conﬁ-
dence of alerts corresponding to successful attacks and the
average conﬁdence of the other alerts (i.e., false alerts and
alerts corresponding to failed attack attempts).
Shut down Norton
Antivirus via cmd.exe shell
¬Norton Antivirus realtime
protection running
Modifiy webpage via
cmd.exe shell
Virus BackOrifice found & quarantined
Install BackOrifice instance 2
BackOrifice installed
BACKDOOR BackOrifice access
Webpage file modified
Figure 5. Updated alert-attribute network
pothesized attacks and corresponding causal relationships.
Conditional probability table of each node can be gener-
ated automatically given the network structure and prior
probability values. Then JavaBayes generates updated con-
ﬁdence values of each node in this Bayesian network. The
conﬁdence values of the related alerts before and after rea-
soning are shown in Figure 6. We can see signiﬁcant in-
creases in the conﬁdence values of successful attacks;
however, all the false alerts have either decreased or un-
changed conﬁdence.
We also ﬁnd some interesting observations in Table 6.
The conﬁdence values in three of the hypothesized nodes
turned into 1, and two of them are the two options to re-
solve the same inconsistency. As we have discussed in Sec-
tion 2.2.2, unless a hypothesis is the only option to solve
the inconsistency, a conﬁdence value of 1 for a hypothe-
sized attack does not mean that the attack must have hap-
pened. Instead, it implies that if that attack has happened,
it must be successful. Thus, although the conﬁdence val-
ues for the two hypothesized nodes are both 1, it does not
mean that both attacks must have happened. However, com-
paring the probability of the path from the initial veriﬁed
attributes to the later veriﬁed attribute (by multiplying the
probabilities of all the intermediate nodes along the path),
we ﬁnd that the one through “Modify web page via
cmd.exe” has a greater probability than the other one. Al-
though it is not what exactly happened in our experiment, it
shows that both methods can achieve the goal of modifying
web page without being detected, and modifying through
established remote cmd.exe shell is simpler and easier com-
Proceedings of the 20th Annual Computer Security Applications Conference (ACSAC’04) 
1063-9527/04 $ 20.00 IEEE 
attribute networks. The result shows that with sufﬁcient lo-
cal system evidence, our model is efﬁcient and effective in
discovering some missed attacks.