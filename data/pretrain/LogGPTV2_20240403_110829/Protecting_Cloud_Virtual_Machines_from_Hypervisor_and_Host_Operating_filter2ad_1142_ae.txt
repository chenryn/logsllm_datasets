4,074
Ed25519 library
403
AES library
CPU protection
1,883
Memory protection 1,727
232
Secure boot
Helper
247
8,566
HypSec TCB
Table 5: HypSec TCB
LOC
Hypervisor
8,566
HypSec
1,857,575
KVM
Xen
71,604
Xen + Dom0 2,054,756
Table 6: TCB size comparison
with KVM and Xen
state. By retroﬁtting KVM with HypSec to protect VM CPU
and memory against the rest of the KVM codebase, we show
that the TCB of KVM can be reduced by more than 200 times.
Using the same assumption, Xen’s TCB should include both
its hypervisor code and Dom0, a special privileged VM used
to reuse existing Linux drivers to support I/O for user VMs.
Although Dom0 is not part of the hypervisor, Xen provides it
with a management interface that can request the hypervisor to
dump entire VM state, thereby giving a compromised Dom0
full access to encryption keys. Xen’s resulting TCB including
Dom0, which has a full copy of Linux, is therefore larger
than KVM and hundreds of times larger than HypSec. If we
conservatively assume features in Xen’s management stack
that expose VM state such as VM dump and migration are
disabled, so that we can exclude Dom0 from Xen’s TCB and
only count Xen ARM hypervisor code in EL2, Xen’s TCB is
then 71K LOC as listed in Table 6. This is roughly an order of
magnitude larger than HypSec because Xen still has to do its
own bootstrapping, CPU and memory resource management,
and completely support memory and interrupt virtualization.
We estimated HypSec’s TCB for an equivalent x86
implementation, assuming HypSec is also applied to KVM
Linux v4.18 for x86 hardware with VMX support. We ran
cloc against the C ﬁles that encapsulate the KVM functions
for CPU and memory virtualization to conservatively measure
HypSec’s TCB size. The total is less than 27K LOC. Although
the TCB size for HypSec on x86 would be larger than HypSec
on ARM, we believe the resulting TCB on x86 would still
result in a substantial reduction as KVM’s TCB on x86 is
also larger than on ARM, at roughly 10M LOC including x86
device drivers; this is an area of future work.
6.4 Evaluation of Practical Attacks
We evaluated HypSec’s effectiveness against a compromised
hostvisor by analyzing CVEs and identifying the cases where
HypSec protects VM data despite any compromise, assuming
an equivalent implementation of HypSec for x86 platforms.
We analyzed CVEs related to Linux/KVM, which are listed in
Tables 7 and 8. The CVEs consider two cases: a malicious VM
who exploits KVM functions supported by the hostvisor, and
an unprivileged host user who exploits bugs in Linux/KVM.
Among the selected CVEs, 16 of them are x86-speciﬁc, one
is speciﬁc to ARM, while the rest are independent of archi-
tecture. An attacker’s goal is to exploit these CVEs to obtain
Figure 4: Application Benchmark Performance
on sending network data, resulting in higher overhead. Note
that other network workloads such as TCP_STREAM have neg-
ligible overhead as the granularity at which the additional traps
happen is large enough that the performance impact is negligi-
ble. To avoid extra traps to the hypervisor, our implementation
can be optimized by batching the effect of the grant/revoke
calls at the same level of granularity as used by the virtio driver
to batch multiple transactions. This is an area of future work.
6.3 TCB Implementation Complexity
We ran cloc [24] against our implementation’s corevisor to
measure the TCB, as shown in Table 5. The total is roughly
8.5K LOC of which just under 4.5K LOC is from the Ed25519
and AES crypto libraries. The rest of the HypSec TCB is less
than 4.1K LOC, consisting of mostly CPU/memory protection
and existing KVM lowvisor code. Overall, we modiﬁed or
added a total of 8,695 LOC in the mainline Linux kernel v4.18
across both the corevisor and hostvisor. More than 1.3K LOC
were in existing Linux ﬁles, and around 7.3K LOC were in
new ﬁles for HypSec, including around 4.5K LOC in the
crypto libraries and slightly less than 2.8K LOC for corevisor
functions. Finally, less than 70 LOC were added to QEMU
to support secure boot and VM migration. These results
demonstrate that HypSec can retroﬁt existing hypervisors with
modest implementation effort.
For comparison purposes, we also used cloc to measure
KVM’s TCB in Linux v4.18 and Xen v4.9 for ARM64 support
when running Linux v4.18 on Dom0, shown in Table 6. For
KVM, we counted its LOC for the speciﬁc Linux v4.18 code-
base running on the ARM64 server used in our experiments.
KVM’s massive TCB with access to VM data consists of
more than 1.8M LOC and includes QEMU, the KVM module,
core Linux functions such as CPU scheduling, ARM64
architectural support, and the device drivers used on the server.
To provide a fair comparison, we assumed the same threat
model for each system and that VMs encrypt their I/O. Even un-
der this assumption, KVM, including its I/O kernel code, must
be entirely trusted to protect VM data since a compromised
KVM can steal encryption keys from VM CPU and memory
1368    28th USENIX Security Symposium
USENIX Association
0.00.20.40.60.81.01.21.41.61.82.0KVMKVM-FDEHypSecHypSec-FDEDescription
Memory Corruption: Array index error in hostvisor.
Privilege Escalation: Improper handling of descriptors in vhost driver.
Info Leakage: Stack out-of-bounds read in hostvisor.
Code Execution: Buffer overﬂow in I/O virtualization code.
Code Execution: Buffer overﬂow in I/O virtualization code.
Info Leakage: Improper handling of invalid combination of operations for virtual IOAPIC.
Code Execution: Mishandling of virtual APIC state.
Privilege Escalation: Out-of-bounds array access using VCPU index in interrupt virtualization code.
Code Execution: Memory corruption in virtual ﬂoppy driver allows VM user to execute arbitrary code in hostvisor.
Privilege Escalation: Buffer overﬂow in the virtio subsystem allows guest to gain privileges to the host.
Privilege Escalation: Buffer overﬂow in the virtio subsystem allows guest to gain privileges to the host.
Code Execution: Out-of-bound memory access in QEMU leads to memory corruption.
Code Execution: Buffer overﬂow allows VM users to execute arbitrary code in QEMU
Bug
CVE-2015-4036
CVE-2013-0311
CVE-2017-17741
CVE-2010-0297
CVE-2014-0049
CVE-2013-1798
CVE-2016-4440
CVE-2016-9777
CVE-2015-3456
CVE-2011-2212
CVE-2011-1750
CVE-2015-3214
CVE-2012-0029
CVE-2017-1000407 Denial-of-Service: VMs crash hostvisor by ﬂooding the I/O port with write requests.
CVE-2017-1000252 Denial-of-Service: Out-of-bounds value causes assertion failure and hypervisor crash.
CVE-2014-7842
CVE-2018-1087
Denial-of-Service: Bug in KVM allows guest users to crash its own OS.
Privilege Escalation: Improper handling of exception allows guest users to escalate their privileges to its own OS.
KVM HypSec
No
No
No
No
No
No
No
No
No
No
No
No
No
No
No
No
No
Yes
Yes
Yes
Yes
Yes
Yes
Yes
Yes
Yes
Yes
Yes
Yes
Yes
No
No
No
No
Table 7: Selected Set of Analyzed CVEs - from VM
Bug
CVE-2009-3234
CVE-2010-2959
CVE-2010-4258
CVE-2009-3640
CVE-2009-4004
CVE-2013-1943
CVE-2016-10150
CVE-2013-4587
CVE-2018-18021
CVE-2016-9756
CVE-2013-6368
CVE-2015-4692
CVE-2013-4592
Description
KVM HypSec
Privilege Escalation: Kernel stack buffer overﬂow resulting in ret2usr [43].
No
Code Execution: Integer overﬂow resulting in function pointer overwrite.
No
Privilege Escalation: Improper handling of get_fs value resulting in kernel memory overwrite.
No
Privilege Escalation: Improper handling of APIC state in hostvisor.
No
Privilege Escalation: Buffer overﬂow in hostvisor.
No
Privilege Escalation, Info Leakage: Mishandling of memory slot allocation allows host users to access hostvisor memory. No
No
Privilege Escalation: Use-after-free in hostvisor.
No
Privilege Escalation: Array index error in hostvisor.
No
Privilege Escalation: Mishandling of VM register state allows host users to redirect hostvisor execution.
Info Leakage: Improper initialization in code segment resulting in information leakage in hostvisor stack.
No
No
Privilege Escalation: Mishandling of APIC state in hostvisor.
No
Memory Corruption: Mishandling of APIC state in hostvisor.
Denial-of-Service: Host users cause memory leak in hostvisor.
No
Yes
Yes
Yes
Yes
Yes
Yes
Yes
Yes
Yes
Yes
Yes
Yes
No
Table 8: Selected Set of Analyzed CVEs - from host user
hostvisor privileges and compromise VM data. The CVEs
related to our threat model could result in information leakage,
privilege escalation, code execution, and memory corruption
in Linux/KVM. While KVM does not protect VM data against
any of these compromises, HypSec protects against all of them.
HypSec does not guarantee availability and cannot protect
against CVEs that allow VMs or host users to cause denial of
service in the hostvisor. Vulnerabilities that allow unprivileged
guest users to attack their own VMs like CVE-2014-7842 and
CVE-2018-1087 are unrelated to HypSec’s threat model; pro-
tection against CVEs of these types is an area of future work.
We also executed attacks representative of information
leakage to show that HypSec protects VM data even if an
attacker has full control of the hostvisor. First, we simulated
an attacker trying to read or modify VMs’ memory pages. We
added a hook to KVM which modiﬁes a page that a targeted
gVA maps to. As expected, the compromised KVM (without
HypSec) successfully modiﬁed the VM page. Using HypSec,
the same attack causes a trap to the corevisor which rejects
the invalid memory access.
Second, we simulated a host that tries to tamper with a VM’s
nested page table by redirecting a gPA’s NPT mapping to host-
owned pages. This is in contrast to the prior attack of modifying
VM pages, but shares the same goal of accessing VM data in
memory. We added a hook to the nested page fault handler in
KVM; the hook allocates a new zero page in the host OS’s ad-
dress space, which in a real attack could contain arbitrary code
data. The hook associates a range of a VM’s gPAs with this
zero page. As expected, this attack succeeds in KVM but fails
in HypSec. First, the attacker has no access to the sNPT walked
by the MMU. Second, the corevisor synchronizes the vNPT
to sNPT mapping on the gPA’s initial fault during VM boot, so
malicious vNPT modiﬁcations do not propagate to sNPT.
7 Related Work
The idea of retroﬁtting a commodity hypervisor with a smaller
core was inspired by KVM/ARM’s split-mode virtualiza-
tion [22, 23], which introduced a thin software layer to enable
Linux KVM to make use of ARM hardware virtualization
extensions without signiﬁcant changes to Linux, but did
nothing to reduce the hypervisor TCB. HypSec builds on this
work to leverage ARM hardware virtualization support to run
the corevisor with special hardware privileges to protect VM
USENIX Association
28th USENIX Security Symposium    1369
data against a compromised hostvisor. More recently, Nested
Kernel [25] used the idea of retroﬁtting a small TCB into a
commodity OS kernel, FreeBSD, to intercept MMU updates to
enforce kernel code integrity. Both HypSec and Nested Kernel
retroﬁt commodity system software with a small TCB that
mediates accesses to critical hardware resources and strength-
ens system security guarantees with modest implementation
and performance costs. Nested Kernel focuses on a different
threat model and does not protect against vulnerabilities
in existing kernel code in part because both its TCB and
untrusted components run at the highest hardware privilege
level. In contrast, HypSec deprivileges the hostvisor and uses
its TCB to provide data conﬁdentiality and integrity even in
the presence of hypervisor vulnerabilities in the hostvisor.
Bare-metal hypervisors often claim a smaller TCB as
an advantage over hosted hypervisors, but in practice, the
aggregate TCB of the widely-used Xen [11] bare-metal
hypervisor includes Dom0 [18, 92] and therefore can be no
smaller than hosted hypervisors like KVM. Some work thus
focuses on reducing Xen’s attack surface by redesigning
Dom0 [15, 18, 59]. Unlike HypSec, these approaches cannot
protect a VM against a compromised Xen or Dom0. We
believe Xen can be restructured using HypSec by moving