4) The client performs the following checks for each block Bi
according to Algorithm 2.
5) If any checks fail, the client rejects the chain.
6) Otherwise, the client accepts C as the valid chain.
B. Block Inclusion Veriﬁcation
Algorithm 2 Prover/Veriﬁer Protocol for a Single Query
The veriﬁer queries the prover for the header and MMR proof for a
single block k in the prover’s chain of n + 1 blocks.
Veriﬁer
1: Holds the MMR root of n blocks stored in the header of block
n + 1.
2: Queries prover for the header of block k and for Πk∈n.
3: Veriﬁes the hashes of Πk∈n hash up to the root of MMRn.
4: Calculates the root of the MMR of block k − 1 from Πk∈n.
5: Compares the calculated root with the root in the header of
block k.
6: If everything checks out, accepts block proof.
Prover
1: Has chain of n + 1 blocks and the MMR of the ﬁrst n blocks.
2: Receives query for block k from veriﬁer and calculates Πk∈n.
3: Sends header of k and Πk∈n to veriﬁer.
Assuming the longest chain has been veriﬁed and accepted
with only some of the block headers downloaded, i.e., the
veriﬁer knows some Bn is the last block header in the longest
chain, veriﬁcation of a transaction in some previous block
requires checking if the block actually belongs to a chain
ending in Bn. Once the block is veriﬁed to belong to the
chain, the veriﬁer needs only an SPV Merkle proof that a
transaction is in that block.
Our goal is verify that any block belongs in the chain with
only the latest block header of the chain. We leverage the
MMR construction again for this. The full node can prove
that a transaction was included in the longest chain by just
providing an MMR proof (to prove that a block belongs to
the longest chain) in addition to the current transaction proof
(which shows that the transaction is included in the block).
Algorithm 2 describes how a veriﬁer can query a prover for
the validity of a single block.
Deﬁnition 5 (Valid Block). A valid block Bx for a chain
ending in block Bn with MMR root Mn−1 is a header with
PoW and for which a Πx∈Mn−1 exists.
Deﬁnition 6 (Honest Chain). An honest chain B0, B1, ..., Bn
of length n is an ordered list such that each Bi is valid with
respect to Bn.
Unstable Blocks. PoW blockchains guarantee that honest
nodes will eventually reach consensus. This, however, does
not prevent recent blocks to be unstable, i.e., potentially get
removed from the eventual chain. In particular the most recent
block or head of the chain will often be replaced by other
blocks. Despite this, it is still possible to use the MMR root
from this most recent block to perform the FlyClient protocol
and refer to old stable blocks and transactions. This is because
the FlyClient protocol
inherently checks that all randomly
sampled blocks have MMRs that are consistent with the head’s
MMR. Even if the head is maliciously created, its MMR
cannot contain invalid blocks and it must contain all stable
blocks of the valid longest chain. It is still helpful for a client
to store a recent, stable block to aid future synchronization
proofs.
New Block Header. Our new block header now contains one
extra ﬁeld namely the MMR root of the tree that commits the
headers of all previous blocks. The MMR root can replace the
previous block hash and thus not increase the block headers
size. This requires a minimal change to the current block
structure of Bitcoin and Ethereum, and can be implemented
as a soft fork. We discuss this in more detail in Section D-C.
A full node, upon receiving a new block, will conduct only
one additional check on the validity of the MMR root.
V. BLOCK SAMPLING STRATEGIES
Our goal is to have a protocol that allows an honest prover
to convince the veriﬁer of the validity of its chain while a
malicious prover cannot convince the veriﬁer of a dishonest
chain. In the previous section, we outlined the basic FlyClient
protocol, what is left to be determined is how the veriﬁer
samples blocks from the prover. In this section we describe
the information theoretic component of FlyClient: A block
sampling protocol which ensures that the veriﬁer will sample
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 10:03:03 UTC from IEEE Xplore.  Restrictions apply. 
935
the
an invalid block from the adversary, no matter what
adversary’s forking strategy is. We describe the strategies in
terms of the longest chain rule, i.e., assuming that all blocks
have the same difﬁculty. The strategies directly translate to the
variable difﬁculty setting as described in Section VI. The key
difference is that the sampling will be over the difﬁculty space
instead of the block space. We begin by describing some straw-
man approaches for our sampling protocol and build up the
properties we wish to satisfy. We start with a simple sampling
protocol which gives us the desired properties and show how
to optimize our protocol to achieve smaller proof sizes.
A. Naive Approach
One approach is for the veriﬁer to request a uniformly-
random set of multiple blocks from each prover. Since the
malicious prover has only a limited computation power, it can
at best correctly mine a small subset of all the blocks. Thus,
the veriﬁer needs to sample enough blocks to ensure that at
least one of them is invalid, i.e., an incorrectly-mined block.
The protocol begins with each prover giving the veriﬁer the
header of the last block in its chain, where this header contains
the root of an MMR tree built over all blocks in the chain.
Whenever the veriﬁer requests a block from each prover, the
prover must also provide a Merkle proof that the block is a
leaf in the MMR of the last block. From the MMR inclusion
proof, the veriﬁer can recreate the MMR root for that block
and verify that it is the same root in the header of the block
(therefore included in the proof of work for the block).
As shown in Corollary 4, once a malicious prover forks off
from the honest chain, it cannot include any of the later honest
blocks in its chain because the MMR root in those blocks
would not match the chain. With this setup, if the veriﬁer
makes enough queries, it will eventually ask the malicious
prover for a block it has not mined (i.e., an invalid block).
To determine how many blocks the veriﬁer must query to
achieve a desired probability of success in catching a malicious
prover, we bound the malicious computing power using the
(c, L)-adversary assumption. After the adversary forks from
the honest chain, it can correctly mine up to only a c fraction
of the blocks in the rest of the chain. So, if we know that
the adversary forked at some block Ba, then for each random
block the veriﬁer requests after Ba, there is a probability of
(1−c) that the sampled block is invalid (i.e., incorrectly mined)
as the adversary has to “lengthen” its fork to have a chain of
equal length to the honest chain. Thus, with k queries after
the fork point, the veriﬁer has a success probability of 1 − ck
in catching the malicious prover. Unfortunately, the veriﬁer
neither knows the location of the fork point nor the value of
k or the success probability.
Solution Limitation. Since the veriﬁer does not know where
in the chain the adversary started the fork, the veriﬁer has
to sample a large number of blocks to increase its chance of
catching the malicious prover, especially if the fork point is
located near the end of the chain (i.e., the fork is short).
B. Bounding the Fork Point
Finding the exact location of the fork point by sampling a
small number of blocks in only one shot is challenging. We
instead relax this requirement and allow the veriﬁer to only
“bound” where the fork point is located while still sampling in
one shot. Our goal is to ensure that the veriﬁer makes sufﬁcient
queries after the fork point. Instead of searching for the fork
point, the veriﬁer can iterate through intervals from which it
samples blocks. If in at least one of the intervals the veriﬁer
has a sufﬁciently-high probability of catching the malicious
prover, then the veriﬁer succeeds with high probability in the
whole protocol.
The new sampling protocol ﬁrst samples k random blocks
from the entire chain. Then, it successively splits the chain
(or the current interval) in half and queries another random
k blocks from the last half, i.e., the interval always ends
with the tip of the chain. More precisely, for every integer
j ∈ [0, log n), the veriﬁer queries k blocks from the last n/2j
blocks of the chain. This is repeated until the size of the
interval is at most min(L, k), and all last min(L, k) blocks
are sampled.
the veriﬁer samples at
We now show that the above strategy catches a cheating
adversary with overwhelming probability. To do this, we
calculate the probability that
least
one invalid block from the malicious prover, based on the
observation that the adversary has to insert a sufﬁcient number
of invalid blocks into its fork to obtain an overall chain of
equal length to the honest chain.
Lemma 2. With k log n samples, the probability the veriﬁer
fails to sample any invalid block is ≤(cid:0) 1+c
(cid:1)k.
2
The proof of the Lemma is in Appendix B-C
Solution Limitation. In our analysis, we calculate the proba-
bility of success based on the likelihood of success in at least
one of the log n intervals. However, our protocol samples other
blocks that we do not consider in our analysis, but that could
increase the veriﬁer’s success probability. Can we achieve a
better bound by further taking these blocks into account?
C. The FlyClient Sampling Protocol
While we presented the protocol of Section V-B as an
iterative protocol, it is important to note that all of its steps are
independent. That is, the veriﬁer’s samples do not depend on
the prover’s responses to previous queries. This implies that
the order of samples can be altered to create an isomorphic
protocol with the same security and efﬁciency properties. We
can further use this to examine the probability that a given
block is sampled.
The protocol of Section V-B samples later blocks with
higher probability, i.e., the sampling probability grows in-
versely with the relative distance of a block to the end of
the chain (the most recent block). We can use this property to
ﬁnd a probability distribution (as depicted in Figure 1 as s(x))
that the veriﬁer picks one of the intervals uniformly at random
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 10:03:03 UTC from IEEE Xplore.  Restrictions apply. 
936
(from the protocol presented in Section V-B) and samples a
block uniformly at random from this interval.
Consider a protocol that simply repeats the sampling steps
q times. If the adversary is caught with probability at least p
given one sample, then they will be caught with probability
at least 1 − (1 − p)q after q independently and identically-
distributed samples. This distributional approach enables a
simple analysis of the protocol as we only need to bound the
success probability of a single query. Furthermore, it allows
us to optimize the protocol by ﬁnding a query distribution that
maximizes p. As shown in Figure 1, the distribution introduced
by the protocol from Section V-B is not smooth. In the
following, we show that a different and smoother distribution
performs better.
Optimizing the Sampling Distribution. We now ﬁnd the op-
timal sampling distribution, that is the sampling distribution
over the blocks which maximizes the probability of catching
the adversary given that it chooses the optimal strategy. We
do this by ﬁnding the sampling distribution that maximizes
the probability of catching the adversary with only a single
query. Given this probability, we can directly bound the ad-
versary’s success probability after q queries. As a simplifying
assumption, we treat the number of blocks as a continuous
space between 0 and 1. That is, the block header is at 1 and
the genesis block is at 0. We later show that this simpliﬁed
analysis still produces a good distribution for the discrete case.
Fig. 2. Distributional View Argument
adversary.
The proof of the lemma is in Appendix B-D.
Since all non-increasing distributions yield a non-unique
optimal sampling distribution, we can focus our search on
sampling distributions deﬁned by increasing PDFs that sample
later blocks with higher probability than earlier blocks. For
such distributions, if the adversary forks off from the main
chain at some point 0 ≤ a < 1, the adversary’s best strategy
is to put all of its correctly-mined (i.e., valid) blocks at the end
of its chain so they are the most likely to be sampled. If the
adversary has a c fraction of the honest mining power, and 1−a
is the length of the adversary’s fork, then the adversary can
mine a (1−a)c fraction of the chain. Thus, in its best strategy,
the section of the adversary’s chain from a to 1 − (1 − a)c
does not contain valid blocks.
To catch the malicious prover, we must sample a block in
this interval. Hence, the probability that we catch an adversary
f (x)dx
who forks at some point a with one sample is
,
where f (x) is proportional to the probability density function
of the sampling distribution. Considering all points where the
adversary could fork from, the probability of success with a
single sample is p = min0≤a<1
(cid:82) 1+ac−c
(cid:82) 1
(cid:82) 1+ac−c
(cid:82) 1
0 f (x)dx
f (x)dx
.
a
a
0 f (x)dx
In order to ﬁnd the optimal protocol, we have to ﬁnd the
distribution that maximizes this quantity. Intuitively, we want
a sampling distribution which makes the adversary indifferent
about which fork point to use. Otherwise, queries would be
wasted on blocks which an optimal adversary would not make
invalid anyway. Concretely, we ﬁnd an f (x) that satisﬁes
if the
0
adversary forked from the beginning of the chain or any other
point, we have the same probability of catching it. Through
differential analysis, we ﬁnd that f (x) = 1−c
c(1−x) satisﬁes this
f (x)dx = (c−1) ln(c)
. In Figure 1,
f (x) and this property are displayed visually.
(cid:82) 1−c
f (x)dx = (cid:82) 1+ac−c
condition, i.e., (cid:82) 1+ac−c
f (x)dx. In other words,
a
a
c