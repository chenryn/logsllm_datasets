2) a similar input that does not crash and differs from the
crashing input by 1 byte, and 3) the execution traces for
both of these inputs.
We instruct the subjects to stop their analysis once they
understand enough about
they are
conﬁdent they know how to exploit or ﬁx it. We also instruct
them to keep track of how long it takes to analyze each
sample, as well as the steps they take during analysis.
the vulnerability that
Summary of results. Table VI summarizes the results of
the user study. The commercial security analyst spent 13
hours analyzing Sample 1 and successfully identiﬁed the
root cause. He spent 5.5 hours analyzing Sample 2 and
also successfully identiﬁed the root cause. The academic
researcher spent 3 hours analyzing Sample 1 before giving
up. He was able to understand the root cause of Sample 2
using the causal difference graph in approximately the same
amount of time.
Based on post-experiment feedback from the subjects, we
make the following observations about how the information
from the causal difference graph helped with vulnerability
analysis. Both analysts frequently needed to track the ﬂow
of data, which for Sample 1 required setting breakpoints in
a debugger and re-executing the program. These breakpoints
were hit several hundred times, so the analysts spent signif-
icant time determining which instances of that instruction
were important. They also discovered that some of these
data dependencies were not relevant for understanding the
crash, but only after investing considerable effort tracking
these dependencies.
In contrast, the analysts used the graphs to quickly track
the ﬂow of data, compare values between executions, and
locate ﬂow differences. The graphs displayed only the in-
structions that contributed to the fault, obviating the need to
investigate all data paths to determine their relevance. The
graphs also reduced the tedium of tracking dependencies
through loops and frequently exercised regions of code. For
example, the graphs identiﬁed extra (i.e. disaligned) itera-
tions of loops as well as value differences corresponding to
iterations that wrote data contributing to the crash. Although
we gave the subjects instructions for generating Enhanced
graphs, they did not ﬁnd this necessary, and analyzed Sample
2 using only Basic graphs.
359
In this section we evaluate how differential slicing helps
when analyzing malware samples that behave differently
depending on the environment where they run. Our approach
assumes that we are given the execution traces that manifest
the behavior difference or prior knowledge about how to
generate them. In particular, we select a W32/Conﬁcker.A
malware sample that has been previously reported to avoid
malicious behavior if the keyboard layout is Ukrainian [18]
and a W32/Netsky.C malware sample that is known to have
time triggered functionality [22]. The goal of the analysis is
to collect enough information to write a rule that bypasses
the checks that trigger the behavior difference [13]. For this,
the analyst needs to identify the subset of the environment
used to decide the behavior, as well as the location of the
checks performed on that part of the environment. Note that
in these experiments we do not provide any explicit inputs
to the malware; the environment is the only input.
W32/Conﬁcker.A Previous analysis shows how to generate
the difference in behavior but does not specify the location of
the trigger checks [18]. To generate the traces, we follow that
analysis and run the malware with the keyboard layout set
to Ukrainian (failing trace) and set to US-English (passing
trace). Note that the failing trace is the one that does not
exhibit malicious behavior because that is the unexpected
behavior for malware.
To select the target difference, we compare the list of
external functions invoked by the malware in each execution
in the passing execution the malware
and observe that
creates a new thread, but
that does not happen in the
failing execution. Thus, we select the call point for the
CreateThread function, which is a ﬂow difference, as
the target difference. According to the alignment results,
this function call is present in a large disaligned region that
contains 133,774 instructions, which is only present in the
passing trace.
The produced causal difference graph has a single
input difference corresponding to the return value of
the user32.dll::GetKeyboardLayoutList func-
tion, used by the program to return the keyboard layout
identiﬁer. Thus,
in this case the input difference is an
environment difference in the form of the return value
of a system call. The graph contains 16 nodes for both
executions, including 3 divergences: the disaligned target
difference and two execution omissions. The ﬁrst execution
omission is produced by a different number of locale iden-
tiﬁers returned by GetKeyboardLayoutList in both
executions, while the ﬁnal one is produced by the instruction
cmpw $0x422, (%edi,%esi,4) which checks if the
keyboard layout identiﬁer has value 0x422, the identiﬁer for
a Ukrainian locale.
W32/Netsky.C Previous analysis identiﬁes that Netsky.C
makes the computer speaker beep continuously if the time is
between 6am and 9am on February 26, 2004 [22], but does
not identify the location of the trigger checks. To generate
the traces, we run the malware with the system local time set
to 7.24am (passing trace) and with the system local time set
to 12.24pm (failing trace), both on February 26, 2004. Based
on the available information, we select the target difference
to be the call point of the Beep function, which only appears
in the passing trace.
The produced causal difference graph has a single in-
put difference that corresponds to the output value of the
kernel32.dll::GetLocalTime system call, used by
the program to obtain the system time. The graph contains
a total of 31 nodes, with one divergence that corresponds
to the disaligned target difference. This disalignment
is
produced by different hour digits computed from the result
of GetLocalTime in both executions. In particular, the
graph shows that the malware checks whether the hour digit
is equal to 7 and starts beeping if so. (Note that malware
ﬁrst checks whether the hour digit is equal to 6, but since
this check is false in both executions, it is not relevant to the
observed malicious behavior and therefore does not appear
in the graph.)
In both of these experiments, the causal difference graph
successfully captures the parts of the environment relevant
to the trigger, as well as the location of the trigger checks,
providing detailed information about the triggering mecha-
nisms which could be used by an analyst, for example, to
construct bypass rules.
VI. RELATED WORK
Differential program analysis. Differential program anal-
ysis refers to analyses pertaining to differences between
two similar programs [27]. Most previous work in this
domain focuses on software engineering applications such
as regression testing [11], [28] and input generation [24].
Most similar to our approach is dual slicing [25], a
technique for debugging concurrency bugs. Like our ap-
proach, dual slicing focuses on execution differences using
two traces. However, dual slicing only applies to execution
differences introduced by different thread schedules, rather
than program input or environment differences. As a result,
the causal paths stop at def-use differences, so dual slicing
is unable to identify the root cause for differences which
are not caused by thread scheduling. Also, the dual slic-
ing algorithm compares values directly across executions,
without any address normalization techniques (such as those
described in Section IV-E). Finally, dual slicing requires
access to source code, while our approach works directly
on binaries.
Also related is work by Sumner and Zhang [20], which
creates a causal path for two executions by ﬁrst patching
the failing execution dynamically. They do so by modifying
variables and predicates at runtime to produce a passing
execution, a technique ﬁrst proposed by Zhang et al. to
detect execution omission errors [32]. If such a patch is
found, then both runs are aligned and relevant variables are
identiﬁed through value mutations. The main difference with
our technique is that we identify implicit ﬂows and execution
omissions relevant to the target difference by comparing both
executions without re-executing the program.
Trigger detection. There are many existing techniques for
identifying trigger-based behaviors in malware. For example,
[8] presents a technique for identifying time-based behavior
by perturbing the system time of a virtual machine and
observing for different behaviors. Similarly,
[4], [16] use
dynamic analysis to explore multiple execution paths in
order to identify hidden behavior in malware. Finally,
[7]
presents a more general approach for modeling the behavior
of binary programs in order to statically deduce the presence
of similar functionality in other programs. These techniques
can be used to obtain the execution traces manifesting the
trigger-based behavior, which differential slicing requires.
The beneﬁt of using differential slicing for analyzing a
given trigger-based behavior is that the above techniques
are ill-suited for use by analysts. They can provide coarse-
grained information about the presence or lack of trigger-
based behavior, as well as inputs to trigger the behavior,
but only in speciﬁc cases (e.g., time-based triggers) and
with auxiliary information (e.g., hand-crafted signatures of
system calls) can they summarize the trigger conditions in
human-understandable format. Compared to the above tech-
niques, differential slicing outputs a causal difference graph
that provides ﬁne-grained information about the location of
the trigger checks and the parts of the input relevant to the
trigger, in a visual form better suited for a human analyst.
Slicing. One widely used debugging technique proposed by
Weiser is (static) program slicing [26], which produces a
slice containing parts of a program that are relevant to the
computation of a particular value, called the slicing criterion.
Korel and Laski proposed a dynamic version called dynamic
slicing [14], which works on a single execution and outputs
the executed statements relevant
to the slicing criterion.
There are four main ﬂavors of dynamic slicing, based on
the dependencies included in the slices: thin slicing [19]
includes a subset of data dependencies, data slicing [31]
includes all data dependencies, full slicing [14] includes
data and control dependencies, and relevant slicing [2],
[10],
in addition to data and control dependencies, also
includes predicates, and chains of potential dependencies
rooted at these predicates, whose execution did not affect
the slicing criterion but could have affected it if they had
been evaluated differently. The main difference with our
approach is that differential slicing only considers execution
differences to be relevant to the target difference. Thus,
instead of a causal path of instructions, differential slicing
builds a causal difference graph of execution differences. In
360
addition, differential slicing can capture execution omission
errors that thin slicing, data slicing, and full slicing cannot
capture because they are not present in the execution, as well
as implicit ﬂows that thin slicing and data slicing cannot
capture. Static and relevant slices will include execution
omissions and implicit ﬂows but will produce large slices.
Delta debugging. Delta debugging is a technique for
isolating and minimizing failure-inducing inputs automati-
cally [30]. Compared to delta debugging, our differential
slicing approach uses information about the execution (i.e.,
is white-box) to identify input differences that are relevant
to the target difference. However, delta debugging can
complement our approach by minimizing inputs such that
they differ by the smallest amount necessary to induce the
observed execution difference (indeed, we generated many
of the inputs for our experiments using a variation of this
technique). Zeller et al. develop a failure analysis approach
that uses delta debugging to compare the states of a faulty
and correct execution at the time the fault is observed [6],
[30]. An important difference with these works is that we
compute the causal difference graph ofﬂine, without re-
executing the program in a mutated memory state.
Trace alignment. Xin et al. [29] propose Execution In-
dexing to establish a correspondence between points across
executions based on the structure of the execution. In this
work we use Execution Indexing as a basis for our trace
alignment algorithm. Another ofﬂine trace alignment algo-
rithm was proposed by Liang et al. [15] to identify similar
execution traces for fault localization. In contemporaneous
and independent work, Sumner et al. [21] canonicalize the
memory locations and pointer values using memory indices
and apply them to compare memory snapshots of two runs
at selected execution points. Their work is similar to the
technique we use for address normalization, but it requires
access to source code.
VII. CONCLUSION
In this paper we have presented a novel differential slicing
approach that. Given two executions of the same program
and a target difference in those executions, differential slic-
ing produces a causal difference graph. This graph captures
the input differences that caused the target difference, as well
as the causal sequence of execution differences that led the
program from the input differences to the target difference.
Our differential slicing approach comprises two main
steps. First, the two traces are aligned using an efﬁcient
trace alignment algorithm that we have developed based
on Execution Indexing [29]. The alignment results enable
identifying ﬂow and value differences across the executions.
Then, our Slice-Align algorithm outputs a causal difference
graph, which the analyst uses to quickly understand the
target difference.
We have implemented our differential slicing approach
and evaluated it on the analysis of 11 real-world vulnerabil-
ities and two malware samples with environment-dependent
behaviors. Our results show that the causal difference graph
often reduces the number of instructions that an analyst
needs to examine for understanding the target difference
from hundreds of thousands to a few dozen. We conﬁrm this
in a user study with two vulnerability analysts, which shows
that our graphs signiﬁcantly reduce the amount of time
and effort required for understanding two vulnerabilities in
Adobe Reader.
VIII. ACKNOWLEDGMENTS
We would like to thank Dan Caselden and Charlie Miller
for providing the Adobe Reader samples and for their
valuable feedback on our tool, and Pierre-Marc Bureau for
his help with the Conﬁcker experiment. We are also grateful
to Engin Kirda, David Evans, and the anonymous reviewers
for their valuable comments to improve this manuscript.
This material is based upon work partially supported by
the National Science Foundation under Grants No. 0311808,
No. 0832943, No. 0448452, No. 0842694, No. 0627511,
No. 0842695, No. 0831501, No. 0424422, by the Air
Force Research Laboratory under Grant No. P010071555,
by the Ofﬁce of Naval Research under MURI Grant No.
N000140911081, and by the MURI program under AFOSR
Grants No. FA9550-08-1-0352 and FA9550-09-1-0539. Juan
Caballero was also partially supported by Grants FP7-
ICT No. 256980, FP7-PEOPLE-COFUND No. 229599, and
Comunidad de Madrid No. S2009TIC-1465. Any opinions,
ﬁndings, and conclusions or recommendations expressed in
this material are those of the authors and do not necessarily
reﬂect the views of the funding agencies.
REFERENCES
[1] H. Agrawal and J. R. Horgan. Dynamic program slicing.
ACM SIGPLAN Notices, 25(6), June 1990.
[2] H. Agrawal, J. R. Horgan, E. W. Krauser, and S. London.
Incremental regression testing. In ICSM, Montr´eal, Canada,
September 1993.
[3] S. Bhatkar, D. C. DuVarney, and R. Sekar. Address obfus-
cation: An efﬁcient approach to combat a broad range of
memory error exploits.
In USENIX Security, Washington,
D.C., August 2003.
[4] D. Brumley, C. Hartwig, Z. Liang,
P. Poosankam, D. Song, and H. Yin.
identifying trigger-based behavior in malware.
chapter in ”Botnet Analysis and Defense”, 2007.
J. Newsome,
Automatically
In Book
[5] J. Caballero. Grammar and Model Extraction for Security
Applications using Dynamic Program Binary Analysis. PhD
thesis, Department of Electrical and Computer Engineering,
Carnegie Mellon University, Pittsburgh, PA, September 2010.
[6] H. Cleve and A. Zeller. Locating causes of program failures.
In ICSE, Saint Louis, MO, May 2005.
[7] P. M. Comparetti, G. Salvaneschi, E. Kirda, C. Kolbitsch,
C. Kruegel, and S. Zanero. Identifying dormant functionality
in malware programs.
In Proceedings of the 2010 IEEE
Symposium on Security and Privacy, SP ’10, pages 61–76,
Washington, DC, USA, 2010. IEEE Computer Society.
361
[8] J. R. Crandall, G. Wassermann, D. A. S. Oliveira, Z. Su,
S. Felix, W. Frederic, and T. Chong. Temporal search:
Detecting hidden malware timebombs with virtual machines.
In Operating Systems Review, pages 25–36. ACM Press,
2006.
[9] J. Ferrante, K. J. Ottenstein, and J. D. Warren. The program
dependence graph and its use in optimization. ACM Trans.
Program. Lang. Syst., 9:319–349, July 1987.
[10] T. Gyim´othy, A. Besz´edes, and I. Forg´acs. An efﬁcient
relevant slicing method for debugging. In ESEC, Toulouse,
France, September 1999.
[11] M. J. Harrold, Y. G. Rothermel, Z. K. Sayre, Z. R. Wu,
and L. Y. Z. An empirical investigation of the relationship
between spectra differences and regression faults. Software
Testing, Veriﬁcation and Reliability, 10:2000, 2000.
[12] S. Horwitz, T. Reps, and D. Binkley. Interprocedural slicing
using dependence graphs. ACM Trans. Program. Lang. Syst.,
12:26–60, January 1990.
[13] M. G. Kang, H. Yin, S. Hanna, S. McCamant, and D. Song.
Emulating emulation-resistant malware. In VMSec, Chicago,
IL, November 2009.
[14] B. Korel and J. Laski. Dynamic program slicing. Info. Proc.
Letters, 29(3), October 1988.
[15] G. Liang, A. Roychoudhury, and T. Wang. Accurately
In
choosing execution runs for software fault localization.
CC, Vienna, Austria, March 2006.
[16] A. Moser, C. Kruegel, and E. Kirda. Exploring multiple
execution paths for malware analysis.
In Proceedings of
the 2007 IEEE Symposium on Security and Privacy, SP
’07, pages 231–245, Washington, DC, USA, 2007. IEEE
Computer Society.
[17] S. S. Muchnick. Advanced compiler design and implementa-
tion. Morgan Kaufmann, 1997.
[18] P. Porras, H. Saidi, and V. Yegneswaran. A foray into
Conﬁcker’s logic and rendezvous points. In LEET, Boston,
MA, April 2009.
[19] M. Sridharan, S. J. Fink, and R. Bodik. Thin slicing.
In
PLDI, San Diego, CA, June 2007.
[20] W. N. Sumner and X. Zhang. Algorithms for automatically
computing the causal paths of failures. In FASE, York, United
Kingdom, March 2009.
[21] W. N. Sumner and X. Zhang. Memory indexing: Canonical-
In FSE, Santa Fe, NM,
izing addresses across executions.
November 2010.
[22] Symantec
Corporation.
W32.Netsky.C.
http://www.symantec.com/security response/writeup.jsp?
docid=2004-022417-4628-99.
[23] TEMU: The BitBlaze dynamic analysis component. http://
bitblaze.cs.berkeley.edu/temu.html.
[24] N. Tracey, J. Clark, and K. Mander. The way forward
for unifying dynamic test case generation: The optimisation-
based approach. In In International Workshop on Dependable
Computing and Its Applications, pages 169–180, 1998.
[25] D. Weeratunge, X. Zhang, and W. N. S. S. Jagannathan.
In ISSTA,
Analyzing concurrency bugs using dual slicing.
Trento, Italy, July 2010.
[26] M. Weiser. Program slicing. In ICSE, San Diego, CA, March
1981.
[27] J. Winstead and D. Evans. Towards differential program
analysis. In Workshop on Dynamic Analysis, Portland, OR,
May 2003.
[28] T. Xie and D. Notkin. Checking inside the black box:
Regression fault exposure and localization based on value
spectra differences. Technical report, FSE Poster Session,
2002.
[29] B. Xin, W. N. Sumner, and X. Zhang. Efﬁcient program
execution indexing. In PLDI, Tucson, AZ, June 2008.
[30] A. Zeller and R. Hildebrandt.
Simplifying and isolating
failure-inducing input. IEEE TSE, 28, February 2002.
[31] X. Zhang, R. Gupta, and Y. Zhang. Precise dynamic slicing
algorithms. In ICSE, Portland, OR, May 2003.
[32] X. Zhang, S. Tallam, N. Gupta, and R. Gupta. Towards
locating execution omission errors. In PLDI, San Diego, CA,
June 2007.
362