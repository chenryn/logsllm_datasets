10.1109/RNDM.2017.8093034]
[29] Haselböck S, Weinreich R, Buchgeher G. Decision guidance models for microservices: Service discovery and fault tolerance. In:
Proc. of the 5th European Conf. on the Engineering of Computer-based Systems. New York: ACM, 2017. 1−10. [doi: 10.1145/
3123779.3123804]
[30] Heorhiadi V, Rajagopalan S, Jamjoom H, et al. Gremlin: Systematic resilience testing of microservices. In: Proc. of the 2016 IEEE
36th Int’l Conf. on Distributed Computing Systems (ICDCS). Piscataway: IEEE, 2016. 57−66. [doi: 10.1109/ICDCS.2016.11]
[31] Düllmann TF, van Hoorn A. Model-driven generation of microservice architectures for benchmarking performance and resilience
engineering approaches. In: Proc. of the 8th ACM/SPEC on Int’l Conf. on Performance Engineering Companion. New York: ACM,
2017. 171−172. [doi: 10.1145/3053600.3053627]
[32] Giedrimas V, Omanovic S, Alic D. The aspect of resilience in microservices-based software design. In: Proc. of the Federation of
Int’l Conf. on Software Technologies: Applications and Foundations. Cham: Springer-Verlag, 2018. 589−595. [doi: 10.1007/978-3-
030-04771-9_44]
[33] Van Hoorn A, Aleti A, Düllmann TF, et al. ORCAS: Efficient resilience benchmarking of microservice architectures. In: Proc. of
the 2018 IEEE Int’l Symp. on Software Reliability Engineering Workshops (ISSREW). Piscataway: IEEE, 2018. 146−147. [doi: 10.
1109/ISSREW.2018.00-10]
[34] Jagiełło M, Rusek M, Karwowski W. Performance and resilience to failures of an cloud-based application: Monolithic and
microservices-based architectures compared. In: Proc. of the IFIP Int’l Conf. on Computer Information Systems and Industrial
Management. Cham: Springer-Verlag, 2019. 445−456. [doi: 10.1007/978-3-030-28957-7_37]
[35] Williams RC, Pandelios GJ, Behrens SG. Software risk evaluation (SRE) method description: Version 2.0. Pittsburgh: Software
Engineering Institute, Carnegie Mellon University, 1999.
[36] Lee WS, Grosh DL, Tillman FA, et al. Fault tree analysis, methods, and applications—A review. IEEE Trans. on Reliability, 1985,
34(3):194−203. [doi: 10.1109/TR.1985.5222114]
[37] Alexander I. Misuse cases: Use cases with hostile intent. IEEE Software, 2003,20(1):58−66. [doi: 10.1109/MS.2003.1159030]
1254 Journal of Software 软件学报 Vol.32, No.5, May 2021
[38] Shostack A. Threat Modeling: Designing for Security. John Wiley & Sons, 2014.
[39] Stamatis DH. Failure Mode and Effect Analysis: FMEA from Theory to Execution. 2nd ed., Milwaukee: ASQ Quality Press, 2003.
[40] Lindvall M, Diep M, Klein M, et al. Safety-focused security requirements elicitation for medical device software. In: Proc. of the
2017 IEEE 25th Int’l Requirements Engineering Conf. (RE). Piscataway: IEEE, 2017. 134−143. [doi: 10.1109/RE.2017.21]
[41] Friedberg I, McLaughlin K, Smith P, et al. STPA-SafeSec: Safety and security analysis for cyber-physical systems. Journal of
Information Security and Applications, 2017,34(2):183−196. [doi: 10.1016/j.jisa.2016.05.008]
[42] Basiri A, Behnam N, de Rooij R, et al. Chaos engineering. IEEE Software, 2016,33(3):35−41. [doi: 10.1109/MS.2016.60]
[43] Tucker H, Hochstein L, Jones N, et al. The business case for chaos engineering. IEEE Cloud Computing, 2018,5(3):45−54. [doi: 10.
1109/MCC.2018.032591616]
[44] Blohowiak A, Basiri A, Hochstein L, et al. A platform for automating chaos experiments. In: Proc. of the 2016 IEEE Int’l Symp. on
Software Reliability Engineering Workshops (ISSREW). Piscataway: IEEE, 2016. 5−8. [doi: 10.1109/ISSREW.2016.52]
[45] Basiri A, Hochstein L, Jones N, et al. Automating chaos experiments in production. In: Proc. of the 2019 IEEE/ACM 41st Int‘l
Conf. on Software Engineering: Software Engineering in Practice (ICSE-SEIP). Piscataway: IEEE, 2019. 31−40. [doi: 10.1109/
ICSE-SEIP.2019.00012]
[46] Zhang L, Morin B, Haller P, et al. A chaos engineering system for live analysis and falsification of exception-handling in the JVM.
IEEE Trans. on Software Engineering, 2019, PrePrints: 1−1. [doi: 10.1109/TSE.2019.2954871]
[47] Simonsson J, Zhang L, Morin B, et al. Observability and chaos engineering on system calls for containerized applications in docker.
arXiv preprint arXiv:1907.13039, 2019.
[48] Salinas E. Tammy Bütow on chaos engineering. IEEE Software, 2018,35(5):125−128. [doi: 10.1109/MS.2018.3571246]
[49] ThoughtWorks. Technology radar vol.18. 2018. https://thoughtvorks.com/radar
[50] ThoughtWorks. Technology radar vol.20. 2019. https://thoughtvorks.com/radar
[51] Sharma B, Jayachandran P, Verma A, et al. CloudPD: Problem determination and diagnosis in shared dynamic clouds. In: Proc. of
the IEEE/IFIP Int’l Conf. on Dependable Systems & Networks. Piscataway: IEEE. 2013. 1−12. [doi: 10.1109/DSN.2013. 6575298]
[52] Bodik P, Goldszmidt M, Fox A, et al. Fingerprinting the datacenter: automated classification of performance crises. In: Proc. of the
5th European Conf. on Computer Systems. New York: ACM, 2010. 111−124. [doi: 10.1145/1755913.1755926]
[53] Cherkasova L, Kivanc O, Mi NF, et al. Automated anomaly detection and performance modeling of enterprise applications. ACM
Trans. on Computer Systems, 2009,27(3):1−32. [doi: 10.1145/1629087.1629089]
[54] Duan S, Babu S, Munagala K. Fa: A system for automating failure diagnosis. In: Proc. of the 2009 IEEE 25th Int’l Conf. on Data
Engineering. Piscataway: IEEE, 2009. 1012−1023. [doi: 10.1109/ICDE.2009.115]
[55] Kandula S, Mahajan R, Verkaik P, et al. Detailed diagnosis in enterprise networks. In: Proc. of the ACM SIGCOMM 2009 Conf. on
Data communication. New York: ACM, 2009. 243−254. [doi: 10.1145/1592568.1592597]
[56] Nguyen H, Shen Z, Tan Y, et al. FChain: Toward black-box online fault localization for cloud systems. In: Proc. of the 2013 IEEE
33rd Int’l Conf. on Distributed Computing Systems. Piscataway: IEEE, 2013. 21−30. [doi: 10.1109/ICDCS.2013.26]
[57] Kandula S, Chandra R, Katabi D. What’s going on? Learning communication rules in edge networks. ACM SIGCOMM Computer
Communication Review, 2008,38(4):87−98. [doi: 10.1145/1402958.1402970]
[58] Nguyen H, Tan Y, Gu X. Pal: Propagation-aware anomaly localization for cloud hosted distributed applications. In: Proc. of the
Managing Large-scale Systems via the Analysis of System Logs and the Application of Machine Learning Techniques (SLAML
2011). New York: ACM, 2011. 1−8. [doi: 10.1145/2038633.2038634]
[59] Fonseca R, Porter G, Katz RH, et al. X-trace: A pervasive network tracing framework. In: Proc. of the 4th USENIX Symp. on
Networked Systems Design & Implementation (NSDI 2007). USENIX, 2007. 271−284.
[60] Chen MY, Kiciman E, Fratkin E, et al. Pinpoint: Problem determination in large, dynamic Internet services. In: Proc. of the Int’l
Conf. on Dependable Systems and Networks. Piscataway: IEEE, 2002. 595−604. [doi: 10.1109/DSN.2002.1029005]
[61] Zhao X, Zhang Y, Lion D, et al. Lprof: A non-intrusive request flow profiler for distributed systems. In: Proc. of the 11th USENIX
Symp. on Operating Systems Design and Implementation (OSDI 2014). USENIX, 2014. 629−644.
[62] Chow M, Meisner D, Flinn J, et al. The mystery machine: End-to-end performance analysis of large-scale Internet services. In:
Proc. of the 11th USENIX Symp. on Operating Systems Design and Implementation (OSDI 2014). USENIX, 2014. 217−231.
殷康璘 等:基于混沌工程的微服务韧性风险识别和分析 1255
[63] Wang P, et al. CloudRanger: Root cause identification for cloud native systems. In: Proc. of the 2018 18th IEEE/ACM Int’l Symp.
on Cluster, Cloud and Grid Computing (CCGRID). Piscataway: IEEE, 2018. 492−502. [doi: 10.1109/CCGRID.2018.00076]
[64] Lin JJ, Chen P, Zheng Z. Microscope: Pinpoint performance issues with causal graphs in micro-service environments. In: Proc. of
the Int’l Conf. on Service-oriented Computing. Cham: Springer-Verlag, 2018. 3−20. [doi: 10.1007/978-3-030-03596-9_1]
[65] Chen P, Qi Y, Hou D. CauseInfer: Automated end-to-end performance diagnosis with hierarchical causality graph in cloud
environment. IEEE Trans. on Service Computing, 2019,12(2):214−230. [doi: 10.1109/TSC.2016.2607739]
[66] Standard Performance Evaluation Corporation. SPEC Benchmark. 2000. https://www.spec.org/benchmarks.html
[67] Transaction processing performance council. TPC Benchmark™C—Standard Specification Revision 5.11. 2010. http://www.tpc.
org/tpc_documents_current_versions/pdf/tpc-c_v5.11.0.pdf
[68] Transaction Processing Performance Council. TPC Benchmark™W—Standard Specification Revision 2.0r. 2003. http://tpc.org/
tpc_documents_current_versions/pdf/tpcw_v2.0.0.pdf
[69] European Telecommunications Standards Institute. ETSI GS NFV-TST 001 Network Functions Virtualisation (NFV); Pre-
deployment Testing; Report on Validation of NFV Environments and Services. 2016. https://www.etsi.org/deliver/etsi_gs/NFV-
TST/001_099/001/01.01.01_60/gs_NFV-TST001v010101p.pdf
[70] Al-Masri E, Mahmoud QH. Qos-based discovery and ranking of Web services. In: Proc. of the 2007 16th Int’l Conf. on Computer
Communications and Networks. Piscataway: IEEE, 2007. 529−534. [doi: 10.1109/ICCCN.2007.4317873]
[71] Zhang Y, Zheng Z, Lyu MR. Wsexpress: A QoS-aware search engine for Web services. In: Proc. of the 2010 IEEE Int’l Conf. on
Web Services. Piscataway: IEEE, 2010. 91−98. [doi: 10.1109/ICWS.2010.20]
[72] Kalepu S, Krishnaswamy S, Loke SW. Verity: A QoS metric for selecting Web services and providers. In: Proc. of the 4th Int’l
Conf. on Web Information Systems Engineering Workshops. Piscataway: IEEE, 2003. 131−139. [doi: 10.1109/WISEW.2003.
1286795]
[73] Spirtes P, Clark G, Richard S. Causation, Prediction, and Search. 2nd ed., Cambridge: MIT Press, 1996. [doi: 10.1007/978-1-4612-
2748-9]
[74] Pearl J. Causality: Models, Reasoning, and Inference. 2nd ed., New York: Cambridge University Press, 2009.
[75] Anderson TW, Amemiya Y. The asymptotic normal distribution of estimators in factor analysis under general conditions. The
Annals of Statistics, 1988,16(2):759−771. [doi: 10.1214/aos/1176350834]
[76] Luo C, Lou JG, Lin Q, et al. Correlating events with time series for incident diagnosis. In: Proc. of the 20th ACM SIGKDD Int’l
Conf. on Knowledge Discovery and Data Mining. New York: ACM, 2014. 1583−1592. [doi: 10.1145/2623330.2623374]
[77] Aderaldo CM, Mendonça NC, Pahl C, et al. Benchmark requirements for microservices architecture research. In: Proc. of the 1st
Int’l Workshop on Establishing the Community-wide Infrastructure for Architecture-based Software Engineering. Piscataway:
IEEE, 2017. 8−13. [doi: 10.1109/ECASE.2017.4]
[78] European telecommunications standards institute. ETSI GS NFV-REL 001, Network Functions Virtualisation (NFV): Resiliency
Requirements. 2015. https://www.etsi.org/deliver/etsi_gs/NFV-REL/001_099/001/01.01.01_60/gs_NFV-REL001v010101p.pdf
[79] Thalheim J, Rodrigues A, Akkus IE, et al. Sieve: Actionable insights from monitored metrics in distributed systems. In: Proc. of the
18th ACM/IFIP/USENIX Middleware Conf. New York: ACM, 2017. 14−27. [doi: 10.1145/3135974.3135977]
殷康璘(1992－),男,博士,CCF 学生会员, 杜庆峰(1968－),男,博士,教授,博士生导
主要研究领域为软件工程,智能运维. 师,主要研究领域为软件工程与质量控制,
机器学习与智能运维.