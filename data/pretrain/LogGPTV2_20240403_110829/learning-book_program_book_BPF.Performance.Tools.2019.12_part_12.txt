• BCC: USDT().enable_probe()
ad aqod psn au1 asengdq 
For example, instrumenting the loop probe from the previous example:
 bpftrace -e *usdt:/tmp/tick:1oop ( pzintf(*got: td\n", azg0) : 1"
Attach.ing 1 probe...
got: 0
got: 1
got: 2
got: 3
got: 4
This bpftrace one-liner also printed out the integer argument passed to the probe.
2.10.4USDT Additional Reading
More sources for understanding USDT:
*Hacking Linux USDT with Ftrace” by Brendan Gregg [49]
▪ *USDT Probe Support in BPF/BCC" by Sasha Goldshtein [50]
*USDT Tracing Report* by Dale Hamel [51]
2.11
DynamicUSDT
The USDT probes described previously are added to source code and compiled into the resulting
binary, leaving nops at the instrumentation points and metadata in the ELF notes section.
However, some languages, such as Java with the JVM, are interpreted or compiled on the fly
Dynamic USDT can be used to add instrumentation points in the Java code.
---
## Page 99
62
Chapter 2 Technology Background
Note that the JVM already contains many USDT probes in its C++ code—for GC events, class
loadling, and other high-level activities. These USDT probes are instrumenting the function of the
JVM. But USDT probes cannot be added to Java code that is compiled on the fly. USDT expects a
pre-compiled ELF file with a notes section containing probe descriptions, and that doesn’t exist
for JIT-compiled Java code.
Dynamic USDT solves this by:
● Pre-compiling a shared library with the desired USDT probes embedded in functions. This
shared library can be in C or C++, and it has an ELF notes section for the USDT probes. It
can be instrumented like any other USDT probe.
• Loading the shared library when required with dlopen(3).
•Adding shared library call from the target language. These can be implemented with an
API that suits the language, hiding the underlying shared library call.
This has been implemented for Node.js and Python by Matheus Marchini in a library called
libstapsdlt,2* which provides a way to define and call USDT probes in those languages. Support for
other languages can usually be added by wrapping this library, as has been done by Dale Hamel
for Ruby, using Ruby's C-extension support [54].
For example, in Node.js JavaScript:
const UsDT = requlre (*usdt")
const provider = nev UsDr,USDTProvider (*nodeProvidec*)
(+ xeqou *1ae1s4senbex,) eqo3dppe *zaptaoad = [e@oxd <suo0
provider,enable 11 :
[. ]
pzobel flre (functlon (1I retuzn [cuzxentRequestString] 1)
[...] 
The probe1.fire( call executes its anonymous function only if the probe was instrumented
o passed Suaq aropaq (essaoau p) passad aq ueo ssuasune uooung su u seuaxa
the probe, without concern about the non-enabled CPU cost of such argument processing since it
is skipped if the probe was not in use.
libstapsdt automatically creates a shared library containing the USDT probes and ELF notes
section at runtime, and it maps that section into the running program’s address space.
28 For libstapsdt, see [52][53]., A new library called libusdt is being written for this purpose, and it might change the fol
lowing code example. Check for future releases of litusdt
---
## Page 100
2.12 PMCs
63
2.12
PMCs
Performnce moniforing coumfers (PMCs) are also known by other names, such as performance
instrumentation counters (PICs), CPU performance counters (CPCs), and performance monitor-
ing unit events (PMU events). These terms all refer to the same thing: programmable hardware
counters on the processor.
While there are many PMCs, Intel has selected seven PMCs as an °architectural set”? that provides
a high-level overview of some core functions [Intel 16]. The presence of these architectural set
PMCs can be checked using the CPUID instruction. Table 2-8 shows this set, which serves as an
example of useful PMCs.
Table 2-8  Intel Architectural PMCs
Event Name
UMask
Event Select
Example Event Mask Mnemonic
UnHalted Core Cycles
HO0
3CH
CPU_CLK_UNHALTED.THREAD_P
Instruction Retired
00H
COH
INST_RETIRED.ANY_P
UnHalted Reference Cycles
01H
3CH
CPU_CLK_THREAD_UNHALTED.REF_XCLK
LLC References
4FH
2EH
LONGEST_LAT_CACHE.REFERENCE
LLC Misses
41H
2EH
LONGEST_LAT_CACHE.MISS
Branch Instruction Retired
00H
C4H
BR_INST_RETIRED.ALL_BRANCHES
Branch Misses Retired
00H
C5H
BR_MISP_RETIRED.ALL_BRANCHES
PMCs are a vital resource for performance analysis. Only through PMCs can you measure the
efficiency of CPU instructions; the hit ratios of CPU caches; memory, interconnect, and device
bus utilization; stall cycles; and so on. Using these measurements to analyze performance can lead
to various small performance optimizations.
PMCs are also a strange resource. While there are hundreds of PMCs available, only a fixed
number of registers (perhaps as few as six) are available in the CPUs to measure them at the
same time. You need to choose which PMCs you'd like to measure on those six registers, or cycle
through different PMC sets as a way of sampling them. (Linux perf(1) supports this cycling
automatically.) Other software counters do not suffer from these constraints.
2.12.1 PMC Modes
PMCs can be used in one of two modes:
• Counting: In this mode, PMCs keep track of the rate of events. The kernel can read the
count whenever desired, such as for fetching per-second metrics. The overhead of this
mode is practically zero.
---
## Page 101
64
Chapter 2  Technology Background
• Overflow Sampling: In this mode, the PMCs can send interrupts to the kernel for the
events they are monitoring, so that the kernel can collect extra state. The events monitored
can occur millions or billions of times per second; sending an interrupt for each one
would grind the system to a near halt. The solution is to take a sample of events by using a
programmable counter that signals the kernel when the counter overflows (e.g., once every
10,000 LL.C cache miss or once every 1 million stall cycles).
instrument with custom BPF programs. Both BCC and bpftrace support PMC events.
The sampling mode is most interesting for BPF tracing since it generates events that you can
2.12.2PEBS
Overflow sampling may not record the correct instruction pointer that triggered an event due
to interrupt latency (often called *skid") or out-of-order instruction execution. For CPU cycle
profiling, such skid may not be a problem, and some profilers deliberately introduce jitter to
avoid lockstep sampling (or use an offset sampling rate, such as 99 Hertz). But for measuring other
events, such as ILC misses, the sampled instruction pointer needs to be accurate.
Intel has developed a solution called precise evemr-bused sampfing (PEBS). PEBS uses hardware
buffers to record the correct instruction pointer at the time of the PMC event. The Linux
perf_events framework supports using PEBS.
2.12.3Cloud Computing
Many cloud computing environments have not yet provided PMC access to their guests. It is
technically possible to enable it; for example, the Xen hypervisor has the vpnu command line
option, which allows different sets of PMCs to be exposed to guests [S5].?* Amazon has enabled
many PMCs for its Nitro hypervisor guests.
2.13
perf_events
The perf_events facility is used by the perf(1) command for sampling and tracing, and it was
added to Linux 2.6.21 in 2009. Importantly, perf(1) and its perf_events facility have received a
lot of attention and development over the years, and BPF tracers can make calls to perf_events
to use its features. BCC and bpftrace first used perf_events for its ring buffer, and then for PMC
instrumentation, and now for all event instrumentation via perf_event_open().
While BPF tracing tools make use of perf(1)’s internals, an interface for BPF has been developed
and added to perf(1) as well, making perf(1) another BPF tracer. Unlike with BCC and bpftrace,
the source code to perf(1) is in the Linux tree, so perf(1) is the only BPF front-end tracer that is
built into Linux.
29 I wrote the Xen code that allows different PMC modes: ipc for instructionspercycle PMCs only, and arch for the Intel
architectural set. My code was just a frewall on the existing vpmu support in Xen.
---
## Page 102
2.14Summary
65
perf(1) BPF is still under development and is difficult to use. Covering it is beyond the scope of
these chapters, which focus on BCC and bpftrace tools. An example of perf BPF is included in
Appendix D.
2.14Summary
BPF performance tools make use of many technologies, including extended BPF, kernel and user
dynamic instrumentation (kprobes and uprobes), kernel and user static tracing (tracepoints and
user markers), and perf_events. BPF can also fetch stack traces by using frame pointer-based walks
or ORC for kernel stacks, and these can be visualized as flame graphs. These technologies are
covered in this chapter, including references for further reading.
---
## Page 103
This page intentionally left blank
---
## Page 104
Performance Analysis
The tools in this book can be used for performance analysis, troubleshooting, security analysis,
and more. To help you understand how to apply them, this chapter provides a crash course in
performance analysis.
Learning objectives:
Understand the goals and activities of performance analysis
 Perform workload characterization
 Perform the USE method
Perform drill-down analysis
 Understand checklist methodologies
 Find quick performance wins using traditional tools and the 60-second Linux checklist
Find quick performance wins using the BCC/BPF tool checklist
This chapter begins by describing the goals and activities of performance analysis, and then it
summarizes methodologies followed by traditional (non-BPF) tools that can be tried first. These
tradlitional tools will help you find quick performance wins outright or provide clues and context
for later BPF-based analysis. A checklist of BPF tools is included at the end of the chapter, and
many more BPF tools are includled in later chapters.
3.10verview
Before diving in to performance analysis, it can help to think about what your goals are and the
different activities that can help you accomplish them.
---
## Page 105
68
Chapter 3 Performance Analysis
3.1.1 Goals
aonpar o4 pue aotreuaopuad sasn-pua aaosdtu op ane ss4jeue aoueuoad go sjeo8 atg ‘feaua8 tu]
operating cost. It helps to state a performance goal in terms of something measurable; such a
measurement can show when the performance goal has been met, or to quantify the shortfall.
Measurements include:
u panseau Aeodks 'uoerado no isanbau e usdtuoooe o Suo mog :Aouage 
milliseconds
 Rate: An operation or request rate per second
• Throughput: Typically data movement in bits or bytes per second
Utilization: How busy a resource is over time as a percentage
• Cost: The price/performance ratio
End-user performance can be quantified as the time an application takes to respond to user
requests, and the goal is to make this time shorter. This time spent waiting is often termed latency.
It can be improved by analyzing request time and breaking it down into components: the time
running on CPU and what code is running; the time waiting for resources such as disks, network
ing, and locks; the time waiting for a turn by the CPU scheduler; and so on. It is possible to write
a BPF tool to directly trace application request time plus latency from many different components
at once. Such a tool would be application specific and could incur significant overhead in tracing
many different events simultaneously. In practice, smaller specific tools are often used to study
time and latency from specific components. This book includes many such smaller and specific
tools.
Reducing operating cost can involve observing how software and hardware resources are used and
looking for optimizations, with the goal of reducing your company’s cloud or datacenter spend.
This can involve a different type of analysis, such as summarizing or logging how components are
eo s aoddns ooq s u spoo ue asuodsan nau jo ouae o atu au ue sate pasn
as well.
Bear these goals in mind when doing performance analysis. With BPF tools, it is far too easy to
generate lots of numbers, and then spend hours trying to understand a metric that turns out to be
unimportant. As a performance engineer, I've been sent screenshots of tool output by developers
worried about an apparently bad metric. My first question is often *Do you have a known perfor-
mance issue?" Their answer is often *No, we just thought this output looked..interesting.* It may
well be interesting, but I first need to determine the goal: are we trying to reduce request latency,
or operating costs? The goal sets the context for further analysis.
3.1.2 Activities
BPF performance tools can be used for more than just analyzing a given issue. Consider the
following list of performance activities [Gregg 13b] and how BPF performance tools can be of use
for each of them:
---
## Page 106
3.2 Performance Methodologies
69
Performance Activity
BPF Performance Tools
Performance characterization of
To measure latency histograms under
prototype software or hardware
different workloads
2
Performance analysis of
To solve performance bottlenecks and find
development code, pre-integration
general performance improvements
3
Perform non-regression testing of
To record code usage and latency from different
software builds, pre- or post-release
sources, enabling faster resolution of regressions
Benchmarking/benchmarketing for
To study performance to find opportunities to improve
software releases
benchmark numbers
5
Proof-of-concept testing in the
To generate latency histograms to ensure that
target ervironment
performance meets request latency service level
agreements
6
Monitoring of running production
To create tools that can run 24x7 to expose new
software
metrics that would otherwise be blind spots
7
Performance analysis of issues
To solve a given performance issue with tools and
custom instrumentation, as needed
It may be obvious that many of the tools in this book are suitable for studying given performance
issues, but also consider how they can improve monitoring, non-regression testing, and other
activities.
3.1.3 Mulitple Performance Issues
When using the tools described in this book, be prepared to find multiple performance issues.
The problem becomes identifying which issue matters the most: It’s usually the one that is most
affecting request latency or cost. If you arent expecting to find multiple performance issues, try
to find the bug tracker for your application, database, file system, or software component, and
search for the word *performance.” There are often multiple outstanding performance issues, as
well as some not yet listed in the tracker. It's all about finding what matters the most.
Any given issue may also have multiple causes. Many times when you fix one cause, others
become apparent. Or, when you fix one cause, another component then becomes the bottleneck.
3.2
2PerformanceMethodologies
With so many performance tools and capabilities available (e.g, kprobes, uprobes, tracepoints,
USDT, PMCs; see Chapter 2) it can be difficult to know what to do with all the data they provide.
For many years, I've been studying, creating, and documenting performance methodologies.
A methodology is a process you can follow that provides a starting point, steps, and an ending
point. My prior book, Systems Performarnce, documents dozens of performance methodologies
[Gregg 13b]. IlI summarize a few of them here that you can follow with BPF tools.
---
## Page 107
70
Chapter 3 Performance Analysis
3.2.1Workload Characterization
The aim of workload characterization is to understand the applied workload. You do not need to
analyze the resulting performance, such as the latency suffered. The biggest performance wins I've
found have been ones of °eliminating unnecessary work.° Such wins can be found by studying
what the workload is composed of.
Suggested steps for performing workload characterization:
1. Who is causing the load (e.g., PID, process name, UID, IP adress)?
2. Why is the load called (code path, stack trace, flame graph)?
3. What is the load (IOPS, throughput, type)?
4. How is the load changing over time (per-interval summaries)?
Many of the tools in this book can help you answer these questions. For example, vfsstat(8):
 vfsstat
TIME
READ/s
MRITE/a CREATE/s
2/以30
s/ONKS.3
1215=8
231
12
98
274
13
106
D
18:35: 33 :
4
 0
:15≤=8t
586
B6
251
D
18:35: 35:
241
15
18:35:361
99
232
U
10
98
D
[...]
This shows details of the workload applied at the virtual file system (VFS) level and answers step 3
by providing the types and operation rates, and step 4 by providing the per-interval summary
over time.
As a simple example of step 1, I'll switch to bpftrace and a one-liner (output truncated):
.(()qunco =[wmo] 8 1 peezsga:#qoxdx, 9- 8oezagdq 
Attaching 1 probe...
^C
e[xtkit=daenon] : 1
[...]
[gnone=she111: 20T
 [Chrome_10Thread] : 222
522 : [euoxqo]@
[[nputTh.read] : 302
[gdbus] : 819
[Meb Content] : 1725
This shows that processes named *Web Content° performed 1725 vfs_readi()s while I was tracing.
---
## Page 108
3.2 Performance Methodologies
71
More examples of tools for working through these steps can be found throughout this book,
including the flame graphs in later chapters, which can be used for step 2.
If the target of your analysis does not already have a tool available, you can create your own
workload characterization tools to answer these questions.
3.2.2 Drill-Down Analysis
Drill-down analysis involves examining a metric, and then finding ways to decompose it into its
components, and then decomposing the largest component into its own components, and so on
until a root cause or causes has been found.
An analogy may help explain this. Imagine that you discover you have an unusually large credit
card bill To analyze it, you log in to your bank and look at the transactions. There, you discover
one large charge to an online bookstore. You then log in to that bookstore to see which books led
to that amount and discover that you accidentally purchased 1000 copies of this very book (thank
you!). This is drill-down analysis: finding a clue and then drilling deeper, led by further clues,
until the problem is solved.
Suggested steps for drill-down analysis:
1. Start examining the highest level.
2. Examine next-level details.
3. Pick the most interesting breakdown or clue.
4. If the problem is unsolved, go back to step 2.
Drill-down analysis can involve custom tooling, which is better suited to bpftrace than to BCC