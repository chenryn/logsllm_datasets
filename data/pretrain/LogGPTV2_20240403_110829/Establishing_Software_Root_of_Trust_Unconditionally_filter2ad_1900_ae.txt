Hai,bi,ci(Mi) received. If all checks pass, the veriﬁer estab-
lishes RoT with probability at least (1 − (n))(1 − c · 2w−1),
where (n) = [ 9c
p ]n; e.g., higher than 1 − 10c
for n = 1.
p
The proof is immediate by Theorem 7 and the Fact above.
Implementation considerations of the cWRAM model in
real processors for suitable choices of prime p are discussed
in Appendix C of the technical report [26].
Secure Initial State. After the veriﬁer establishes RoT, it
can load a trustworthy program in the system’s primary mem-
ory. That program sets the contents of all secondary storage to
veriﬁer’s choice of content; i.e., content that satisfy whatever
security invariants are deemed necessary. This extends the
notion of the secure initial state to all system objects.
VI. TIME-MEASUREMENT SECURITY
Past software-based attestation designs fail to assure that
a veriﬁer’s time measurements cannot be bypassed by an
adversary. For example, to account for cache, TLB, and clock
jitter caused primarily by pseudo-random memory traversals by
Cm,t(·) computations and large t, typical veriﬁers’ measure-
ments build in some slack time; e.g., 0.2% – 2.6% of t [39],
[42], [43], [63]. An adversary can easily exploit the slack time
to undetectably corrupt Cm,t(·)’s memory [39], [42]. In this
section we show how to counter these threats.
9
A. Veriﬁer Channel
The veriﬁer’s local channel must satisfy two common-sense
requirements. First, the channel connection to any device must
not pass through a peripheral device controller that requires
RoT establishment. Otherwise, malware on the controller could
pre-process some of the computation steps for the veriﬁer’s
protocol with that device and help it to circumvent the time
measurements. Second, the channel’s delay and its variation
must be small enough so that the veriﬁer time measurements
can reliably detect all surreptitious untrusted-system com-
munication with external devices and prevent both memory-
copy [42] and remote-proxy [43] attacks.
We envision a veriﬁer device to be attached to the main
system bus via a DMA interface, similar in spirit to that
of Intel’s Manageability Engine or AMD’s Platform Security
Processor, but without ﬂaws that would enable an attacker
to plant malware in it [52]. These processors can operate
independently of all other system components; e.g., even when
all other components are powered down [67]. The external
veriﬁer could also run on a co-processor connected to the main
system bus, similar in spirit to Ki-Mon ARM [41]. In both
cases, the veriﬁer would have direct access to all components
of the system state. An advantage of such veriﬁers is that their
communication latency and variation of the local channel are
imperceptible in contrast with the adversary’s network channel.
B. Eliminating Cache and TLB jitter
To perform deterministic time measurement, it is necessary
to eliminate cache/TLB jitter and interprocessor interference,
and avoid clock jitter in long-latency computations.
Preventing Cache, Virtual Memory, and TLB use. In con-
trast with traditional software-based attestation checksums
(e.g.,
[39], [42], [63], [64]), the execution-time measure-
ments of Horner(Hd,k,x(v)) is deterministic. Most modern
processors, such as the TI DM3730 ARM Cortex-A8 [6], in-
clude cache and virtual-memory disabling instructions. Hence,
processor-state initialization can disable caches, virtual mem-
ory, and the TLB veriﬁably (by Theorem 6). In addition, the
Horner-rule step is inherently sequential and hence unaffected
by pipelining or SIMD execution. The only instructions whose
execution could be overlapped with Horner-rule steps are the
two loop control instructions, and the corresponding timing is
easily accounted for in the veriﬁer’s timing check.
In
pre-fetching.
Preventing Cache
systems where
the inherent sequentiality of
caches cannot be disabled,
the
Horner(Hd,k,x(v)) code and the known locality of
instruction and operand references helps assure that
its
execution-time measurements are deterministic. However, the
adversary’s untrusted boot loader could perform undetected
cache pre-fetches before the veriﬁer’s protocol starts, by
selectively referencing memory areas, and obtain better
timing measurements than the veriﬁer’s; viz., Section VII. To
prevent pre-fetching attacks the processor-state initialization
can clear caches veriﬁably (by Theorem 6), so that Init and
Horner(Hd,k,x(v)) code can commence execution with clean
caches. Hence, cache jitter can be prevented.
Alternately, the veriﬁer’s processor-state initialization could
warm up caches [63] by veriﬁable pre-fetching. Nevertheless,
veriﬁable cache clearing is often required; e.g.,
in ARM
processors instruction and data caches are not hardware syn-
chronized, and hence they have to be cleared to avoid malware
10
attacks [42]. Furthermore, cache anomalies may occur for
some computations where a cache miss may result in a shorter
execution time than a cache hit because of pipeline scheduling
effects [19]. This makes cache clearing a safer alternative.
C. Handling clock jitter and inter-processor interference
When Horner(Hd,k,x(v)) executes in large memories it
can have large latencies; e.g., several minutes. These may
experience small time-measurement variations in some systems
due to uncorrected random clock jitter at high frequencies [68],
and multi-processor interference in memory accesses. These
timing anomalies are typically addressed in embedded real-
time systems [19]. For such systems, we use a random sequen-
tial protocol. This protocol leverages smaller memory segments
and the veriﬁable choice of clock-frequency setting such that
random clock jitter becomes unmeasurable by an adversary. It
also ensures that different processors access different memory
segments to eliminate interprocessor interference. The protocol
also provides an alternate type of bounds scaling.
Random Sequential Evaluation. Let F = {f1, f2, . . . , fn}
$←− [1, n], i = 1, . . . , N, be
be a family of n functions and Ki
identiﬁers of their random invocations. fK1, fK2, . . . , fKN are
evaluated on inputs x1, x2, . . . , xN , and ⊥ denotes the event
that an invalid result is returned by a function evaluation. The
protocol for the random sequential evaluation of F , namely
(fK1(x1), fK2 (x2), . . . , fKN (xN )), is as follows:
1) N = n · log n;
2) if fKi(xi) (cid:54)=⊥, then fKi+1(xi+1), 1 ≤ i  i, fKj (xj) = yj | fKi(xi) =
3) P r[Ki
yi,··· , fK1 (x1) = y1] = P r[Ki
The evaluation terminates correctly if fKi(xi) (cid:54)=⊥ for all i,
and incorrectly, otherwise.
$←− [1, n] : fKj (xj) = yj].
Condition 1) implies that the evaluation invokes all ran-
domly selected functions with high probability at least once
[20], [63]. Condition 2) deﬁnes the sequential evaluation
rule. Condition 3) implies that the j-th function evaluation is
independent from the previous i < j evaluations.
the veriﬁer request
Veriﬁer Initialization. Let
loader
to initialize M to n memory segments
comprising processor-state initialization,
Horner(Hd,k,x(·)) programs. Then veriﬁer’s boot
transfers control
initialization program.
the boot
each
Init, and
loader
instructions of the processor-
to the ﬁrst
I/O,
Veriﬁer Protocol. Let F be family H, fKi be
$←− [1, n], and Hdi,ki,xi(·)
$←−
Horner(Hdi,ki,xi(·)), where Ki
H; i.e., the random selection of a memory segment12. If the
random sequential evaluation protocol terminates incorrectly
or the termination is untimely, or both, the veriﬁer rejects.
Otherwise, the veriﬁer accepts. This is the veriﬁer’s protocol
for the n-segment memory model.
Speciﬁcally,
the veriﬁer writes the values denoting the
$←− H separately to each of the n memory
choice of Hdi,ki,xi(·)
segments. Furthermore, the veriﬁer’s Output code is modiﬁed
so that it returns to the Input busy-waiting code after outputting
12A non-random sequential selection would enable malware to take control
after a correct and timely result is returned by a memory segment evaluation,
modify the memory of an already evaluated segment or prefetch instructions,
and then overwrite itself with correct evaluation code before the next input
arrives from the veriﬁer.
an evaluation result, which transfers to the ﬁrst instruction
of the Input code of the next randomly chosen segment. The
address of the next segment’s Input code is provided by the
veriﬁer along with the next nonce Hdi,ki,xi(·)
$←− H.
In a multiprocessor system where t processors share RAM
memory M, the Init programs would start the concurrent
execution of all t processors in different memory segments
along with those of the device controllers.
Theorem 9 (Malware-free Segmented Memory). Let a
veriﬁer initialize memory M of a (e.g., multiprocessor) device
to n segments and perform the veriﬁer’s protocol for the
segmented memory. If the veriﬁer accepts the result, the device
state is malware-free, except with probability at most 9n
p .
The proof of this theorem follows from the deﬁnition of the
veriﬁer’s initialization of memory M including the modiﬁed
I/O instruction sequences, by the veriﬁer’s protocol for the
segmented memory model, and by Theorem 6 and Lemma 4.
VII. PERFORMANCE
In this section, we present preliminary performance mea-
surements for the Horner-rule evaluation of randomized poly-
nomials. The only goal here is to illustrate implementation
practicality on a commodity hardware platform. For this rea-
son, we compare these measurements to those of Pioneer
– the best-known attestation checksum [63] – on the same
hardware conﬁguration [42]. Presenting a study of randomized-
polynomial performance is beyond the scope of this paper.
Our measurements also illustrate the importance to prov-
ably clearing (or disabling, when possible) caches for deter-
ministic time measurements. We noticed no timing anomalies
due to uncorrected clock jitter in our single-processor conﬁgu-
ration for a fairly large memory. This suggests that the random
sequential evaluation for large memories (Section VI) may be
useful primarily to prevent inter-processor interference.
Hardware. Our measurements were done on a Gumstix
Overo FireSTORM-P Computer-On-Module (COM), which is
the ARM-based development platform for embedded hardware
used by Li et al. [42]. This gives us an opportunity to compare
the performance of Horner’s rule for randomized polynomials
with that of the Pioneer checksum. This platform features
a 1GHz Texas Instruments DM3730 ARM Cortex-A8 32-bit
processor and 512MB of DDR SDRAM [70]. The processor
has a 32KB L1 instruction cache and a 32KB L1 data cache,
both with 16 bytes per cache line. In addition, it also features
a 256KB L2 uniﬁed cache [6].
Recall that the parameter |M| must reﬂect the total amount
of primary storage in the device. Besides the 512MB of
SDRAM, our particular Gumstix also features 64KB of SRAM
and also a large address space for device control registers with
5, 548 registers. Summing these up as bits, we set |M| to
4, 295, 669, 120.
Software. Our measurements are implemented inside a
popular secondary boot loader known as U-Boot, which in a
typical application would be responsible for loading the Linux
kernel on the COM. For our purpose, however, we extend U-
Boot with measurement capabilities; i.e., U-Boot 2015.04-rc4
is cross-compiled with Linaro gcc 4.7.3.
We implemented Horner’s rule for several polynomials in
Zp, where p = (232− 5) is the largest prime that can ﬁt inside
a 32-bit register. Since the DM3730 ARM Cortex-A8 CPU
11
does not support the udiv (unsigned integer division) instruc-
tion, gcc uses the __aeabi_uidivmod function to emulate
division, which is slower than the hardware udiv instruction
followed by the mls (integer multiply-and-subtract) instruction
to compute the modulus. Nevertheless, an adversary cannot
change the emulation since the code image is committed by
the second pre-image freedom of randomized polynomials.
The ﬁrst Horner-rule measurement is for ordinary poly-
nomials; i.e., with constant, rather than k-wise independent,
coefﬁcients. This establishes the baseline, which helps calibrate
the expected performance loss for increasing the values of k.
The performance of Horner rule for a single polynomial of
degree 128M covering the entire SDRAM is 11, 739ms.
For the measurements of Horner-rule evaluation of random-
ized polynomials, the k random numbers are stored contigu-
ously in memory. For values of k that match one cache line,
namely k = 4, evaluating a polynomial of degree d = 128M
(same as the baseline) takes 67, 769ms due to extra memory
accesses and added cache contention. However, most modern
processors have more than k = 4 and fewer than k = 64
registers. Hence, larger values of k would have to be used to
ensure that the adversary cannot be left with spare processor
registers after loading the k random numbers.
Randomized Polynomials vs. Pioneer Checksum. The tim-
ing for k = 64 and d = 10M is 54, 578ms. For the baseline
d = 128M the running time is close to 700 seconds, which
is about 6% faster than the fastest Pioneer checksum (745.0
seconds), 8.7% faster than the average (765.4 seconds), and
9% faster than the slowest (768.1 seconds) reported by Li
al.
[42] on the same hardware conﬁguration. While these
measurements illustrate practical usefulness, additional mea-
surements are necessary for a complete performance study;
e.g., additional hardware platforms and conﬁgurations.
Why Disable or Clear Caches? Instruction and data caches
on the DM3730 ARM Cortex-A8 can be disabled and enabled
individually, using single instructions. We used this feature
to illustrate the inferior cache utilization compared to an
adversary’s cache pre-fetching strategy. With only the instruc-
tion (data) cache turned off, we observed a 5.15x (23.76x)
slowdown in Horner-rule evaluation. With both caches turned