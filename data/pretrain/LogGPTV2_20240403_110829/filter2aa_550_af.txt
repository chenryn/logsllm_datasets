real world. 
A semantic botnet could enhance the credibility of any agenda. For example, if the 
target were an international energy corporation, OSINT might reveal a wide range 
of attack vectors: disgruntled employees, friction with indigenous populations, 
whistle blowers, or ongoing lawsuits. The botnet army could be used to target all of 
the above, via blogs, posting comments to news articles, sending targeted email, etc. 
(The corporation, of course, could hire its own botnet army in retaliation.) The chal-
lenge for the attacker would be to make the communications as realistic as possible 
while making identity verification a complex and time-consuming challenge.
Given the size of cyberspace and the speed at which data packets travel, one of the 
primary ways to combat a macro-scale cyber threat is by statistical analysis. A secu-
rity analyst must use advanced mathematics to identify and counter cyber threats.
In an election, humans typically vote in a “bell curve.” Some people are extremists, 
but most tend to vote for a party somewhere in the middle of the political spectrum. 
If a botnet controller does not simulate this tendency, statistical analysis of network 
traffic and internal databases can quickly reveal divergences that could suggest a 
tainted vote. These include a randomized voting preference (i.e., too many votes on 
the extremes), demographic anomalies, or strange patterns such as too many votes 
during normal human working hours. 
Technical data should not conflict with a security analyst’s common sense. IP ad-
dresses must be scattered realistically within the voting space. Internet browsers 
should manage website visits as a human would, pausing for images to load and 
allowing time for a user to read important information. Automated computer pro-
grams may move too quickly and “mechanically” from one data request to the next. 
A security analyst should investigate anomalies for other non-human properties.
41
Cyber Security: A Technical Primer
The primary challenge to a statistical cyber defense strategy is a mathematically-
gifted attacker. In theory, it is possible to give a botnet army a range of dynamic 
characteristics that are based on real-time analysis of current news and entertain-
ment media. However, this is not easy to program, and an attacker can never be 
completely sure what a security analyst is looking for. An attack always requires 
some guesswork and miscalculation.
Over time, this is a game of cat-and-mouse. A security analyst can write a sophisti-
cated algorithm that correlates many factors, such as name, vote, geography, educa-
tion, income, and IP address, to known or expected baselines. However, a botnet 
controller can do the same.
One pitfall for the attacker is that, if the bots vote too realistically, or if there are 
too few bots involved in the attack, there should be a correspondingly small impact 
on the election. Moreover, in order to mirror real Internet traffic patterns, a botnet 
needs to be both large and sophisticated.
Of course, there are some purely technical investments to be made, including the 
increased use of Public Key Infrastructure (PKI), biometrics and Internet Protocol 
version 6 (IPv6). Neural networks, for example, have played a considerable role in 
reducing credit card fraud.109 For important business transactions, the simple use of 
a live video feed is beneficial.
Unfortunately, the use of good cyber defense tactics and technologies is rare. Most 
system administrators do not have the time, expertise, or staff to undertake a so-
phisticated analysis of their own networks and data. For the foreseeable future, 
much of the burden is on individual web users to recognize threats emanating from 
cyberspace and take action (or inaction) to counter them.
This chapter has tried to argue that macro-scale cyber attack threats are serious, 
but most, such as the theoretical botnet army described in this chapter, do not yet 
pose a threat to national security. It is possible to create one fraudulent web identity, 
so millions of them could already exist. However, what makes many categories of 
cyber attack easy – the ubiquity, vulnerability, and anonymity of the web – can also 
lessen the credibility of a cyber threat. Good OSINT can lead to a significant bluff.
To a large extent, the most dangerous threat actors are those with the ability to 
bridge the gap between the virtual and physical worlds. Thus, there are two impor-
tant categories of cyber attacker: those who have “reach” into the real world, and 
those whose threats are limited to cyberspace. The trouble from a strategic, national 
109 Rowland, 2002.
42
BIRTH OF A CONCEPT: STRATEGIC CYBER SECURITY
security perspective is that foreign intelligence services and militaries possess that 
kind of reach, which obviously can make a cyber attack much more serious.
All things considered, cyber attacks have the potential to rise to the level of a stra-
tegic threat. Therefore, they must be addressed by national security planners. The 
next chapter will examine how one nation-state, Saudi Arabia, has attempted to miti-
gate this threat at the national level.
Case Study: Saudi Arabia
Every country has a unique perspective on security, especially a country as tradi-
tion-bound as Saudi Arabia. But at the technical level, the quest for strategic cyber 
security mostly comprises the exact same elements: computer hardware, software, 
legal authority, system administrators, and cyber security experts. Therefore, Saudi 
Arabia, where there is a strong perception of a close connection between computer 
security and national security, provides an instructive example.
The Saudi government censors a wide range of information based on a mix of mo-
rality, security, and politics. It has built a national firewall designed to keep “inap-
propriate” web content out of the country, inaccessible from anywhere within its 
borders, at any time, in public or private spaces. However, from both a semantic and 
a technical perspective, it is difficult, especially in authoritarian countries, to bal-
ance the public’s need and desire for information with the government’s need and 
desire to maintain information control.
Myriad technologies exist that can circumvent or even punch a hole straight through 
the Saudi national firewall. These include international telephone calls to foreign 
Internet Service Providers (ISPs), hacking Internet protocols, pseudonymous email 
accounts and remailers, direct-to-satellite access, peer-to-peer networking, anony-
mous proxy servers, encryption, steganography, and more. As censorship circum-
vention tools, all have strengths and weaknesses, and none of them is perfect.
Specific software applications are not prohibited in the Kingdom per se. For ex-
ample, the King Abdul-Aziz City for Science and Technology (KACST) explained that 
Internet chat programs are allowed unless the software in question is specifically 
linked to the distribution of pornography.110
Content-filtering on a national scale is a monumental task. The Saudi government 
built a national proxy server111 at KACST to surveil the nation’s Internet traffic for 
110 “The Internet...” Human Rights Watch.
111 Or a single, centralized connection between Saudi Arabia and the outside world, capable of censoring 
undesirable information.
43
Cyber Security: A Technical Primer
“appropriateness” according to Muslim values, traditions, and culture.112 Internet 
Service Providers must conform to these rules in order to obtain an operating li-
cense.113
Such laws are easier to enforce in some countries than others. In Saudi Arabia, the 
effort is greatly facilitated by the fact that the entire telecommunications network, 
including international gateways, are owned and operated by the government.114
Saudi Arabia is home to some of the most educated citizens in the Arab world. Fur-
thermore, Saudis routinely communicate with each other and with the outside world 
on a modern and sophisticated telecommunications infrastructure.115 The Kingdom 
has been connected to the Internet since 1994, but until 1999 access was restricted 
to state, academic, medical, and research facilities.116 Today, home accounts are wide-
spread, and there are hundreds of cyber cafes in the country. Men and women are 
both active Web surfers, and their average daily time online is over three hours.117
The amount of data processed by KACST every day is so great that the national 
firewall took two years to build. Due to the sensitive nature of its mission, the entire 
project is housed under one roof. Technicians are imported from places like the 
USA and Scandinavia,118 but the censors handing out directives regarding what Web 
content to block are exclusively Saudi Arabian.119
KACST is analogous to a national post office through which all domestic and in-
ternational correspondence must travel. There are now dozens of private ISPs in 
Saudi Arabia.120 However, KACST is the country’s only officially sanctioned link to 
the Internet, and all ISPs must route their traffic through its gateway.121 Electronic 
data is unlike traditional mail in that it is broken into small packets to increase the 
speed with which it travels through cyberspace, but these packets are reassembled 
at KACST for inspection.122
From the beginning, KACST’s goals were ambitious. Its president, Saleh Abdulrah-
man al-‘Adhel, said that, before his organization would turn on the switch to the 
112 Whitaker, 2000.
113 “Saudi Arabian Response...” Virginia Tech.
114 “Cybercensorship...” Human Rights Watch.
115 Dobbs, 2001.
116 Gavi, 1999 and 2002.
117 “Saudi Arabia to double...” 2001.
118 Gardner, 2000.
119 “SafeWeb...” 2000.
120 “The Internet...” Human Rights Watch.
121 “Losing...” 2001.
122 “How Users...” Human Rights Watch.
44
BIRTH OF A CONCEPT: STRATEGIC CYBER SECURITY
Internet, KACST would try to eliminate all of the Internet’s negative aspects.123 How-
ever, KACST technicians knew that they could not accomplish these goals without 
strictly regulating the behavior of individual users. Therefore, they forbade the 
sending or receiving of encrypted information as well as the sharing of usernames 
and passwords.124
Saudi Arabia’s first line of defense is a list of banned URLs that are explicitly denied 
when requested by a user from a browser window.125 Many websites commonly ac-
cessed outside Saudi Arabia are forbidden.
For those websites that are allowed through the filter, Web users access “cached” 
copies of Internet sites on government-controlled web servers physically located in 
the country.
When a user attempts to visit a website that has not been evaluated by KACST cen-
sors, a second stage of the content-filtering system is activated. Software automati-
cally examines the site’s content for prohibited words before the request is granted. 
One of the first is the presence of a “stop word” on the homepage.126 A list of banned 
topics stops the request from getting through the KACST proxy server. There are at 
least thirty categories of prohibited information,127 and the number of banned sites 
goes well into the hundreds of thousands.128
When access to a site is denied, either because its URL is already on the banned 
list or it is found to contain objectionable material, a pop-up warning window ap-
pears on the screen. It informs the user in both Arabic and English, “Access to the 
requested URL is not allowed!”129 It also informs the user that all Web requests are 
logged.130 The second warning is important, because law enforcement can, with an 
IP address, find the computer terminal in question and possibly also locate the end 
user. This is why in many countries publicly available Internet terminals that allow 
for easy, anonymous web surfing, are scarce.131
The two-stage system described above is the one advertised by the Saudi govern-
ment. However, there are more stifling approaches to censorship, such as the use 
of a “whitelist,” of which the Saudi government has been accused. Blacklists ban 
123 “Saudi Arabian Response...” Virginia Tech.
124 “The Internet...” Human Rights Watch.
125 “The Internet...” Human Rights Watch.
126 “Government-Imposed...”
127 “Losing...” 2001.
128 “Saudi Arabia to double...” 2001.
129 Lee, 2001.
130 Gavi, 1999 and 2002.
131 “How Users...” Human Rights Watch.
45
Cyber Security: A Technical Primer
material based on the fact that it has been officially reviewed and deemed to contain 
inappropriate content.132 Whitelisting, a far stricter policy, takes a dramatically dif-
ferent approach, banning everything that is not explicitly allowed.133 In other words, 
there is no need for a two-stage system. When a user tries to visit an unfamiliar 
webpage, there is simply no response. The only accessible websites have been pre-
approved by the government. Some reporting has quoted “industry insiders” as stat-
ing that an internal KACST committee officially sanctions a list of “desirable” sites, 
and all others have been banned by default.134
With such power over Saudi networks, KACST has the ability to do far more than 
simple website content filtering. In theory, KACST network administrators can read, 
block, delete, or alter network traffic based on email address, IP address, or key-
words in the message. For example, if “royal family” and “corrupt” were found to 
exist in the same sentence, such a message could be flagged for closer inspection, 
perhaps by law enforcement authorities.135
Technical support for such a large system requires an enormous effort. At least ten 
companies from four foreign countries have played a role in its administration, in-
cluding Secure Computing, Symantec, Websense, Surf Control, and N2H2.136
Secure Computing’s software is called SmartFilter. Saudi Arabia began using it as 
soon as the country was officially connected to the Internet in February 1999. 
SmartFilter ships with default content categories like pornography and gambling, 
but it was selected by KACST due to its overall ease of customization.
An example of widely-used, open source censorship software is DansGuardian, 
which is advertised as sophisticated, free Internet surveillance, to create “a cleaner, 
safer, place for you and your children.” Its settings can be configured from “un-
obstructive” to “draconian,” and it can filter data by technical specifications such 
132 Such as the words “government” and “corrupt” appearing in the same sentence. From a censor’s 
perspective, the problem with blacklisting is that it can be easy to fool the system, for example by 
simply misspelling those words: i.e. “govrment” and “korrupt.”
133 “Government-Imposed...”
134 “The Internet...” Human Rights Watch.
135 “How Users...” Human Rights Watch.
136 There are many content filtering software products to choose from, including 8e6, CensorNet, 
Content Keeper, Cyber Patrol, Cyber Sentinel, DansGuardian, Fortinet, Internet Sheriff, K9, N2H2, 
Naomi, Net Nanny, SmartFilter, squidGuard, Surf Control, We-Blocker, Websense, and more. Each can 
be configured for a single schoolroom or an entire nation-state.
46
BIRTH OF A CONCEPT: STRATEGIC CYBER SECURITY
as URL, IP, domain, user, content, file extension, and POST. There are many more 
advanced features to choose from.137
Privacy advocates criticize the software companies that create such tools, but indus-
try representatives counter that their products are politically neutral. According to 
an executive at Secure Computing, “We can’t enforce how they use it.”138
Pornography is the first topic Saudi authorities mention when asked about Internet 
censorship. And KACST claims that the battle against pornography has been suc-
cessful.139 But according to human rights groups, Saudi Arabia also disallows many 
political sites.140
A case in point is the website of a London-based dissident group called the Move-
ment for Islamic Reform in Arabia (MIRA) (www.islah.org). MIRA’s IP address was 
on KACST’s list of banned sites, which was apparent in MIRA’s computer log files. 
MIRA decided to change its IP address, and immediately the site was available again 
inside Saudi Arabia. (MIRA did not know why the second stage of KACST’s system 
was not able to block the website based on content.) Eventually, the new IP address 
was discovered by KACST technicians, who blocked it again. This process repeated 
itself many times over; on average, MIRA was able to stay ahead of the government 
for about a week at a time. Its challenge was to make interested Saudi citizens aware 
of its new address before the block was in place again.141
MIRA was not satisfied with this protracted game of hide-and-seek, so its webmas-
ters developed better solutions. First, the site randomized its port numbers, adding 
more than 60,000 possible Web addresses (equal to the number of available ports 
on a computer) to each new IP address. This change made it more difficult for KACST 
to do its detective work, since the Web requests leaving Saudi Arabia for MIRA were 
not necessarily headed for port 80, which normally hosts websites.142
Next, MIRA developed a novel way to let its followers know the new address. Its 
email server, PI:EMAIL, would respond to a blank email with an automatic 
reply, containing the IP and port number. From Saudi Arabia, the blank emails were 
sent from webmail accounts such as Hotmail, whose secure, web application login 
137 Advanced features include PICS labeling, MIME type, regular expressions, https, adverts, compressed 
HTML, intelligent algorithm matches for phrases in mixed HTML/whitespace, and phrase-weighting, 
which is intended to reduce over- and under-blocking. Furthermore, there is a whitelist mode and 
stealth mode, where access is granted to the user but an alert is nonetheless sent to administrators.
138 Lee, 2001.
139 Gardner, 2000.
140 “The Internet...” Human Rights Watch.
141 “Losing...” 2001.
142 Dobbs, 2001.
47
Cyber Security: A Technical Primer
process made it impossible for KACST to see where the emails were going or what 
information they contained.
MIRA’s head, Dr. Saad Fagih, said that following these changes, the number of Saudi 
visits to his site rose to 75,000 per day, and that before long KACST abandoned its 
efforts to block the site. 143
From a technical perspective, it is a challenge even to begin to censor the Internet. 
But to evaluate frequently changing websites for their moral and political content is 
a monumental task. Computer software can recognize individual words, but under-
standing how they are used by an author in a given sentence or article is much more 
difficult. Words such as “breast” can be used to block sexual references to women, 
but the system may also block recipes for cooking chicken breasts. Likewise, it is 
difficult to avoid sexual references when offering medical advice related to sexually-
transmitted diseases (STDs).144
Critics say that the decision to censor information at all leads to over-censorship.145 
For example, in practice it is convenient to block an offensive website by IP ad-
dress. However, this means that any other website sharing the same IP will also 
be blocked.146 An attacker can exploit this – and conduct a denial-of-service attack 
against a target website – simply by “poisoning” its webserver with prohibited mate-
rial. Ideally, all censored information should be double-checked by real people to 