one load of p’s value and one store to q. To handle this case, we
App Thread           if( isDangling(p) )p = obj2                           OOT(&p)pSweeperApp Threadfree(p) q = p   // q has been swept.                          OOT(&p)pSweeperAlgorithm 5 Concurrent Pointer Sweeping (CPW) threads.
ObjList: live object list
PtrList: live pointer list
objEnd ← getObjectListTail(ObjList)
while obj ← getNextObj(ObjList) do
if obj.f ree f laд then
obj.scan f laд ← 1
fillWithSlotIndex(obj, obj.slotid)
if obj == objEnd then
else
return FALSE
while True do
return FALSE
if isFreed(p) then
return TRUE
1: function isDangling(p)
if p is neutralized then
2:
3:
4:
5:
6:
7:
8: function CPW_Thread( )
9:
10:
11:
12:
13:
14:
15:
16:
17:
18:
19:
20:
21:
22:
23:
24:
25:
26:
27:
28:
29:
30:
31:
32:
33:
break
break
break
Sleep(t)
ptrEnd ← getPtrListTail(PtrList)
while ptr ← getNextPtr(PtrList) do
if objFreed(&ptr) then
removePtr(&ptr , PtrList)
continue
OOT(&ptr)
if isDangling(ptr) then
if ptr == ptrEnd then
while obj ← getNextObj(ObjList) do
if obj.scan f laд then
real_free(obj)
removeObj(ObjList, obj)
clearPLMTable(obj)
if obj == objEnd then
◃ Decide sweeping rate
1
2
3
4
5
6
7
8
%1 = load p
store %1 , q
%2 = volatile load q
if ( isDangling (%2)):
OOT (& q)
else :
%3 = volatile load p
store %3 , q
q = p
Figure 8: Prevent dangling pointer propagation. Code snip-
pets with a dark background are instrumented by pSweeper.
instrument one check after the store instruction. In particular,
we check whether q is dangling. If so, we nullify it.3 This check
is critical to prevent dangling pointer propagation. The reason is
that although q has been swept before, p might have not been
neutralized and the pointer assignment q = p could propagate the
dangling pointer from p toq. At first glance, the volatile load in
3Note that isDangling() checks if the pointer has already been neutralized.
Line 3 seems unnecessary and we can use %1 directly. However, we
must add this load instruction to prevent compiler and CPU from
reordering the isDangling() check with the store instruction in
Line 2. In other words, we must ensure that isDanling(q) check
comes after the store instruction, so that the propagated dangling
pointer q will be caught by the inlined isDanling() check. Note
that this double-load strategy is not the only solution, and we can
also intentionally introduce other data dependencies to prevent the
reordering.
Then, if the isDangling() check in Line 4 fails, we reload the
value of p and store it to q. There are two scenarios where the
check in Line 4 can fail: (1) pointer p was not dangling (i.e., no
risk of dangling pointer propagation at all) or (2) dangling pointer
p has been neutralized and the freed memory is re-allocated. In
the first scenario, the store in Line 8 is redundant but correct and
safe. In the second scenario, %3 must be different from %1 and the
dangling pointer propagation is successfully prevented. Note that,
on multiprocessor systems, pSweeper uses CPU memory barriers
like mfence to guarantee that the neutralized p is globally visible
before the isDangling() check returns false.
We also need to insert __asm__ __volatile__("":::"memory")
between the load instructions to prevent reordering by compilers.
However, there is no need to insert memory barriers before %3=load
p. This is because we only need to ensure that this load happens
after the one in isDangling(%2), regardless if store instructions
have been globally visible before %3=load p.
Finally, we prove the correctness of this mechanism as follows:
• Precondition. Since we assume no concurrency bug, no
one else except CPW thread will modify p or q during the
code sequence in Figure 8.
• Fact. The race is harmful iff q is swept before p.
• Completeness. To prove the completeness of this mecha-
nism, we only need to prove that, if both checks fail, q must
NOT be dangling. We use proof by contradiction. Proof: As-
sume (q is dangling) =⇒ (p has not been neutralized before
%3=load p) =⇒ (the pointed memory is still freed before
%3=load p) =⇒ (isDangling(%2) must return true) =⇒
(q is set to NULL and q is not dangling). This contradicts the
initial assumption.
• Soundness. We need to prove that, if either check succeeds,
q must be dangling. The proof is straightforward based on
the two preconditions.
4.6 More pSweeper Threads
pSweeper currently uses only one thread, which is sufficient in our
evaluations. However, it can be extended to use multiple threads.
The live pointers can be partitioned to segments, with each one
being handled by one pSweeper thread during every round of sweep-
ing. In this extension scheme, there is no race among pSweeper
threads, and thus, no synchronization is required, making pSweeper
quite scalable.
4.7 Object Origin Tracking (OOT)
It is notoriously difficult to analyze and locate bugs triggered in
production runs [32, 37, 38, 53]. In order to facilitate the root-cause
diagnosis of UaF vulnerabilities, pSweeper aims to provide not only
Figure 9: Use of pointer bits by OOT.
where dangling pointers are dereferenced (which can be obtained
in core dumps) but also how objects are allocated and freed, i.e.,
object origin tracking (OOT). Unfortunately, it is non-trivial to link
a dangling pointer access to the corresponding improper memory
(de)allocation. Existing approaches like AddressSanitizer [51] and
Exterminator [48] bind origin information with objects. However,
this can cause inaccurate OOT when memory is reused, which is
common in UaF exploits. Therefore, they are primarily suitable for
in-house debugging but not for in-production diagnosis.
pSweeper instead encodes object origin information into dan-
gling pointers. Such information is independent to memory reuse
and can be propagated at no extra cost. The most significant two
bits are set to 01 as in Figure 9 to ensure that applications crash
safely upon dangling pointer dereference. Then, the origin informa-
tion can be obtained in signal handlers. However, we must reserve
sufficient least-significant bits to support pointer arithmetics. In
our current implementation, we empirically reserve 12 bits.
OOT records the call stacks of malloc() and free() in a buffer
slot that is assigned an index. The index is encoded into the mid-
dle 50 or 18 bits (with respect to 64-bit or 32-bit systems) during
pointer neutralization, as shown in Figure 9. To reduce the mem-
ory overhead, the call stack information is compressed. In order
to retrieve the slot index in OOT, pSweeper fills freed objects with
corresponding slot indexes (Line 7 in Algorithm 5). In this way,
given an in-bounds dangling pointer p to an object, pSweeper can
easily construct the value to neutralize p.
When applications crash due to dangling pointer dereference,
pSweeper extracts OOT information in signal handlers. However,
Linux always returns zero, instead of the tagged pointer in Figure
9, as the illegal address in signal handlers. We address this by first
obtaining the faulty instruction, e.g., 4008fe: movl %edx, (%rax),
through EIP/RIP in signal handlers. This instruction informs that
register rax contains the pointer value. Then, we can obtain the
encoded origin information by reading that register.
Finally, the current design of OOT has two limitations. First,
the encoded information may still be corrupted due to pointer
arithmetics, even though 12 bits have been reserved. Fortunately,
the reserved bits can handle most cases in practice. Second, in
our current implementation, OOT is limited to record 250 and 218
objects that are live at the same time for 64-bit and 32-bit systems,
respectively. However, such a recording capacity is sufficient for
most software in practice. In particular, 64-bit systems have become
prevalent nowadays and it is rare to create 250 live objects at the
same time.
5 EVALUATION
We implement a pSweeper prototype for x86-64, on top of LLVM
3.7 compiler infrastructure [10, 35], and use LLVM’s link-time opti-
mization support (LTO) for the whole program analysis. The static
analysis and instrumentation pass in pSweeper operates on LLVM
intermediate representation (IR). Our current prototype employs
some preliminary optimizations, e.g., inlining operations in Algo-
rithm 2 and Figure 8 when instrumenting store instructions to
avoid function calls.
We evaluate pSweeper by answering four questions:
• Is pSweeper effective to mitigate real UaF vulnerabilities?
• What is the performance overhead of pSweeper?
• How scalable is pSweeper for multi-threaded applications?
• Can pSweeper efficiently work on complex software?
All experiments are conducted on 64-bit Ubuntu-16.04 with a
2-core 2-thread (i.e., 4 threads in total) Intel(R) Core(TM) i5-4300U
at 1.9GHz with 12GB RAM.
5.1 Effectiveness of pSweeper
To evaluate the effectiveness of pSweeper, we apply it to four real-
world UaF vulnerabilities in three applications, as listed in Table
2. pSweeper successfully neutralizes the unsafe dangling pointers
and pinpoints the root-causes in all four cases. Due to space limit,
we next describe CVE-2016-6309 only in details.
CVE/Bug ID
Application
CVE-2016-6309 [4] OpenSSL 1.1.0a
CVE-2014-3505 [3] OpenSSL <1.01i
Bug 12840 [13]
Bug 2440 [9]
Wireshark
Lighttpd 1.4.32
Protected
✔
✔
✔
✔
Table 2: Real-world UaF vulnerabilities used for evaluation.
CVE-2016-6309 in OpenSSL is caused by memory reallocation
in statem.c:548. OpenSSL initially allocates a buffer of 16KB to
receive messages. When a larger message is received, the buffer is
reallocated using CRYPTO_clear_realloc(), which essentially al-
locates a new buffer and frees the old one. Therefore, the underlying
location of the buffer is changed. However, a pointer s→init_msg
is not updated and still refers to the old location.
When this vulnerability is exploited, there can be two cases. First,
due to deferred free and asynchronous neutralization, if the dan-
gling is accessed before being neutralized, the openSSL server can
always execute normally. On the other hand, if it is exploited after
neutralization, the openSSL server crashes safely and pSweeper
successfully pinpoints OPENSSL_clear_realloc() in
BUF_MEM_grow_clean() (buffer.c:109) as root cause.
5.2 Performance on SPEC CPU2006
We next evaluate the performance overhead of pSweeper on SPEC
CPU2006 benchmarks. Table 3 presents the statistical results of
SPEC CPU2006 benchmarks when pSweeper runs at a sweeping
rate of one second.
As can be seen, pSweeper finds similar number of pointers (Col-
umn 5 in Table 3) as DangSan, which is far more than DANGNULL.
This demonstrates that pSweeper has comparative coverage to
the state-of-the-art defense systems. We also find that pSweeper
neutralizes fewer pointers (Column 7 in Table 3) than DangSan,
although more than DANGNULL. This is because pSweeper con-
currently sweeps dangling pointers in a dedicated thread and does
not stall applications. As a result, although a pointer is dangling
01slot index2reserved for pointer arithmetic125064-bit01slot index2reserved for pointer arithmetic121832-bitFigure 10: pSweeper’s performance on SPEC CPU2006.
at free(), it probably has been overwritten by applications with
non-dangling values when pSweeper checks it. In particular, the ma-
jority of dangling pointers identified in DangSan are on stack [54],
which become invalid after function returns. Also, it is possible that
the objects containing dangling pointers have been freed before
pSweeper starts to sweep. Most of these invalid dangling pointers
are ignored by pSweeper. We emphasize that neutralizing these
stale dangling pointers does not increase the security guarantee
and pSweeper provides the same protection as previous systems.
5.2.1 Runtime Overhead.
Figure 10 presents the performance overhead of pSweeper at differ-
ent sweeping rates, i.e., no sleep, 500ms sleep, and 1s sleep between
sweeping rounds. The overhead is normalized over the baseline
and all the results are averaged over three consecutive runs. The av-
erage overheads of pSweeper at different sweeping rates are 12.5%
(no sleep), 13.9% (500ms), and 17.2% (1s).
Effect of sweeping rate. Generally, sweeping rates do not sig-
nificantly affect the performance of applications as pSweeper con-
currently runs on spare cores. Therefore, we an see that all three
configurations (1s, 500ms, and nosleep) induce similar and trivial
overhead on most benchmark. However, we find that the bench-
marks like perlbench, gcc, omnetpp, and xalancbmk still suffer
high overhead. In particular, the overhead of these benchmarks ba-
sically positively correlates with sweeping intervals, i.e., the larger
the interval, the larger the overhead. There are mainly two reasons.
On the one hand, these benchmarks are memory allocation inten-
sive. Simply intercepting and maintaining metadata in pSweeper
can incur a large overhead. On the other hand, when pSweeper
runs at a larger interval, memory free requests are deferred for a
longer time. An allocation-intensive application like gcc may not
be able to immediately reuse the freed memory. As a result, much
more time is spent in kernel mode when memory allocators try to
allocate new objects.
Static instrumentation overhead. We now break down the
overhead caused by static code instrumentation. The overhead
mainly comes from the hooked malloc() family of functions, which
set up object metadata, maintain live objects and MAS table. They
introduce a bunch of extra memory writes for each allocated ob-
ject. We find that they account for about 5.6% of the average over-
head. Especially, in the case of allocation-intensive applications,
Figure 11: Dynamic instruction overhead and L1 data cache
misses on SPEC CPU2006.
the accumulated overhead is high, e.g., ∼15% for gcc. Finally, the
instrumented store instruction, which is the main performance
bottleneck in previous works [36, 54, 58], causes low overhead in
pSweeper, about 1.8%.
Dynamic instruction count and data cache overhead. We
use hardware performance counters to measure the dynamic in-
struction counts and cache misses of the 32KB L1 data cache. We are
only interested in the overhead caused by the instrumented code.
Thus, we do not spawn the pSweeper thread and disable deferred
free. The results are plotted in Figure 11, showing that dynamic
instruction counts highly correlate with the runtime overhead and
are the main source of overheads for most benchmarks. A notice-
able negative impact of MAS and PLM tables is the additional data
cache misses, resulting in a large portion of performance overhead.
5.2.2 Memory Overhead.
Figure 12 shows that pSweeper moderately increases memory foot-
print in terms of maximum resident set size, with average overheads
112.5% (no sleep), 169.7% (500ms), and 247.3% (1s).