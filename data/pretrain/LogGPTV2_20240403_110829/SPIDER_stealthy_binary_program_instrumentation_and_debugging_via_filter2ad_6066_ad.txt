explosion when a long running process receives/produces a
lot of inputs/outputs during its lifetime as each output is
considered causally related to all preceding inputs. To solve
this problem, BEEP partitions the execution of a program
into individual units, with each unit handling an indepen-
dent input request (e.g., one email or one web request) in
one event-handling loop iteration. With such a ﬁner logging
granularity, BEEP is able to link each output to the truly
related input(s) hence achieving higher attack provenance
accuracy.
To capture the entry and exit of each unit, BEEP needs
to instrument the target binary program at certain loca-
tions. BEEP uses a static binary rewriting tool PEBIL [23]
to perform such instrumentation, which has several short-
comings: (1) Attackers could patch the instrumented pro-
gram at runtime to disable BEEP; (2) The instrumentation
needs to modify the code in the program, hence cannot be
applied to programs with self-checking and self-protection
mechanisms, which widely exist in COTS software to pre-
vent malicious software manipulation. To overcome these
problems, we use Spider to replace PEBIL for BEEP’s in-
strumentation. The reliability of Spider (Section 3) guaran-
tees that the instrumentation could not be circumvented or
disabled. More importantly, Spider performs instrumenta-
tion by setting invisible breakpoints, which are transparent
to the target applications.
We evaluate the eﬀectiveness and performance of our ap-
proach using 7 Linux2 binary programs. We ﬁrst identify
the instrumentation points for each program using BEEP.
We then set Spider to monitor the creation of processes
of these programs. Once a process of a target program is
created, we set invisible breakpoints at the instrumentation
points in its address space. The original instrumentation
routines in BEEP invoke a special system call to log unit-
speciﬁc events; we modify them to directly log unit events
into a ﬁle in the host.
6.000%
5.000%
4.000%
3.000%
2.000%
1.000%
d
a
e
h
r
e
v
O
0.000%
vim
wget
firefox
Figure 3: Overhead of using Spider to perform in-
strumentation for BEEP.
proftpd cherokee
apache
yafc
We repeated the case studies in [25] and veriﬁed the cor-
rectness of attack provenance achieved by our system. We
also measure the overhead of our system over the execution
of the programs in vanilla KVM. In vanilla KVM we enable
Linux audit system but do not perform instrumentation.
For wget and yafc, we run them to download a 1.2MB ﬁle
from a server 500 times. For apache and cherokee, we use
the weighttp to generate 1 million requests with 100 threads
and 100 concurrency. For proftpd, we use the integration test
provided with it. We use the SunSpider benchmark for ﬁre-
fox. For vim, we feed it a script to replace the ﬁrst letter of
each line with ‘a’ in 50000 text ﬁles. All network programs
2The prototype of BEEP only supports Linux currently.
296
except ﬁrefox are evaluated in a dedicated LAN to rule out
the factor of network delay. The result is shown in Figure 3.
The overhead is less than 2% except ﬁrefox and vim. The
overhead for ﬁrefox is slightly higher because it has more in-
strumentation points (24) than other programs (2∼6), which
leads to more breakpoint hits. The overhead for vim is due
to an instrumentation point which gets triggered each time
the script processes a line. Users will experience much less
overhead when they use vim interactively as the instrumen-
tation point is triggered much less frequently.
6.3 Case Study II: Stealthy Introspection
We now demonstrate the use of Spider to reveal a possible
threat to two popular Windows instant messaging programs,
anonymized as IM1 and IM2. The threat involves the ac-
quisition of conﬁdential application data without user aware-
ness. Such data usually have very short lifetime in memory
and are encrypted before network transmission. Hence they
are deemed diﬃcult/impossible to acquire through memory
scanning or network sniﬃng. We also protect the two appli-
cations using the (arguably) strongest protector Safengine
Shielden, so that existing debugging/instrumentation tech-
niques cannot be used to analyze them. Now, we show that
even with those protections, conﬁdential data could still be
“stolen” by using Spider to trap the program at the right
instruction. The stealthiness and eﬃciency of Spider make
it possible to perform the attack while the programs are run-
ning normally; none of the existing techniques could achieve
the same level of user-transparency and eﬃciency. The real-
ism of the threat is backed by the fact that, an attacker
is able to transparently hijack a running OS into a VM
on malicious hypervisor (e.g., using BluePill [31]). Once
that happens, Spider can be used to stealthily set invisible
breakpoints on the target application for conﬁdential data
acquisition by the hypervisor. In the following description,
such breakpoints are set on the functions and memory loca-
tions in bold font.
IM1. We show the possibility of capturing all communica-
tion between a sender and the user. To ﬁnd the function
that handles messages, we search through the functions ex-
ported by the libraries of IM1. We ﬁnd a function named
SaveMsg3 in KernelUtil.dll and set an invisible breakpoint
at the entry of that function. As expected, the function
is called every time a message is received; we also ﬁnd out
one of its parameters is the ID of the sender. However,
the message text is not directly present in the argument
list, which implies that it might be part of a data structure
rooted at one of the arguments. We further speculate that
a message may need to be decoded either inside SaveMsg
or through some other related function. We ﬁnd a function
named GetMsgAbstract in the list of exported functions.
The name suggests that it may need to decode a message.
We set a breakpoint at its entry and another one at its re-
turn. We observe that the message text is in fact decoded
as its return value. We also ﬁnd out that at the entry of
GetMsgAbstract that the value of one of its parameters
is always the same as one of the parameters of SaveMsg,
which might both point to the same opaque structure that
contains the message text. Therefore, we log all messages at
GetMsgAbstract return and associate them to individual
3Note that the binary of IM1 does not contain symbolic
information. We simply inspect the export table.
senders by matching the parameters of GetMsgAbstract
and SaveMsg. As such, we are able to identify all messages
from individual senders.
IM2. We show the possibility of capturing user login cre-
dentials in IM2. We ﬁrst ﬁnd the functions that read the
username and password. As a native Win32 application,
we suspect it uses the GetWindowTextW Windows API
function to retrieve the text from the controls in the login
dialog. We set a breakpoint at the entry of that function
and log all its invocations. After we rule out unrelated in-
vocations by checking if the retrieved text matches a login
credential, we ﬁnd out the invocations at 0x449dbd and
0x437a23 are for retrieving username and password, re-
spectively. The remaining problem is to ﬁnd out if the cap-
tured login credential is valid. As an error message will be
displayed upon failed login, we set a breakpoint at the Mes-
sageBoxW function. From the call stack we could read the
functions on the path of failed login. We set breakpoints
on these functions too. We then do a successful login to
see if it shares the same path. We ﬁnd that both successful
and failed logins will execute to the function at 0x48591c,
and then the path deviates. Successful login will execute
to the branch of 0x485bcd, while failed login leads to an-
other branch. Therefore, we log the content acquired by
GetWindowTextW when it is invoked at 0x449dbd and
0x437a23, and then we use the call stack path to prune
those belonging to failed logins.
We veriﬁed that the conﬁdential data (messages or login
credentials) is correctly and completely acquired through
stealthy introspection, without any slow-down of program
execution.
6.4 Performance Overhead
3.50E+09
3.00E+09
2.50E+09
2.00E+09
k = 3217.3 
Overhead 
(CPU Cycles) 
1.50E+09
1.00E+09
5.00E+08
0.00E+00
0
200,000
400,000
600,000
800,000
1,000,000
1,200,000
Number of Breakpoint Hits 
Figure 4: Relation between the overhead of Spider
and the number of breakpoint hits.
We have already presented the empirical overhead of Spi-
der in our case studies in Section 6.2. In this experiment,
we further study the overhead of Spider. We build a micro
benchmark program that executes a loop for a given num-
ber of times. In each loop iteration, the program increments
a variable 1000 times. The program executes the RDTSC
instruction to read the CPU cycle counter before and after
the loop, and calculate the diﬀerence which is the number
of CPU cycles cost by the loop. We compile the program
with Visual Studio 2010 in Windows.
We run the program using the parameter from 104 to 106
iterations, with a step of 104. The program is executed in
both vanilla KVM and Spider; In Spider, we set an invisi-
ble breakpoint at the ﬁrst instruction of the loop. We obtain
297
the number of CPU cycles cost by the loop in vanilla KVM
and Spider, and the diﬀerence is the overhead, as shown in
Figure 4. From the ﬁgure, we could see that the overhead
is linear to the number of breakpoint hits. A single invisi-
ble breakpoint hit costs around 3217 CPU cycles. A large
part of the overhead is due to the transitions between host
and guest during breakpoint handling. A round-trip transi-
tion costs about 1200 cycles (measured using kvm-unit-test).
This is the cost we have to pay to maximize stealthiness: To
prevent any in-guest side eﬀect, the breakpoint handler must
run outside the guest VM, which means the transition is in-
evitable. Nevertheless, the overhead of our invisible break-
point is still less than the breakpoint in an existing work [36]
and comparable with in-guest hardware breakpoint. Consid-
ering that the cost of VMExit/VMEntry is decreasing over
the years [4], the overhead of our approach is likely to be
less in future processors.
We also measure the overhead of other components in Spi-
der, including the cost of splitting code and data views
and monitoring the guest virtual-to-physical mapping. We
exclude the overhead of breakpoint hits by setting “fake”
breakpoints, which use the original instruction as the break-
point instruction instead of int3. The target program we use
is gzip 1.2.4. We run the program in both vanilla KVM and
Spider to compress a 98.7MB ﬁle and measure the execu-
tion time. In Spider, we set a breakpoint at one instruction
in each page of the code section to make sure all code pages
are split. The run in vanilla KVM costs 4171ms, while the
run in Spider costs 4192ms. The overhead is less than 1%
which conﬁrms that the number of breakpoint hits is the
dominant factor of overhead.
7. CONCLUSION
In this paper, we present Spider, a stealthy binary pro-
gram instrumentation and debugging framework. Spider
uses invisible breakpoint, a novel primitive to trap execu-
tion of program at any desired instruction eﬃciently. Our
evaluation shows Spider is transparent against various anti-
debugging and anti-instrumentation techniques. We have
applied Spider in two security application scenarios, demon-
strating its transparency, eﬃciency and ﬂexibility.
Acknowledgements
This research has been supported in part by DARPA under
Contract 12011593. Any opinions, ﬁndings, and conclusions
in this paper are those of the authors only and do not nec-
essarily reﬂect the views of DARPA.
8. REFERENCES
[1] Gdb. http://www.gnu.org/software/gdb/.
[2] Ida pro. http://www.hex-rays.com/idapro/.
[3] Kvm. http://www.linux-kvm.org/.
[4] O. Agesen, J. Mattson, R. Rugina, and J. Sheldon. Software
techniques for avoiding hardware virtualization exits. In
USENIX ATC’12.
[5] P. Barham, B. Dragovic, K. Fraser, S. Hand, T. Harris, A. Ho,
R. Neugebauer, I. Pratt, and A. Warﬁeld. Xen and the art of
virtualization. SOSP’03.
[6] U. Bayer, C. Kruegel, and E. Kirda. Ttanalyze: A tool for
analyzing malware. In EICAR’06.
[7] F. Bellard. Qemu, a fast and portable dynamic translator. In
USENIX ATC’05.
[8] S. Bhansali, W.-K. Chen, S. De Jong, A. Edwards, R. Murray,
M. Drini´c, D. Mihoˇcka, and J. Chau. Framework for
instruction-level tracing and analysis of program executions. In
VEE’06.
[9] R. R. Branco, G. N. Barbosa, and P. D. Neto. Scientiﬁc but not
academical overview of malware anti-debugging,
anti-disassembly and anti-vm technologies. Blackhat USA’12.
[10] D. Bruening. Eﬃcient, transparent, and comprehensive
runtime code manipulation. PhD thesis, 2004.
[11] D. Bruening, Q. Zhao, and S. Amarasinghe. Transparent
dynamic instrumentation. In VEE’12.
[12] P. P. Bungale and C.-K. Luk. Pinos: a programmable
framework for whole-system dynamic instrumentation. In
VEE’07.
[13] Z. Deng, D. Xu, X. Zhang, and X. Jiang. Introlib: Eﬃcient and
transparent library call introspection for malware forensics. In
DFRWS’12.
[14] A. Dinaburg, P. Royal, M. Sharif, and W. Lee. Ether: malware
analysis via hardware virtualization extensions. In CCS’08.
[15] P. Feiner, A. D. Brown, and A. Goel. Comprehensive kernel
instrumentation via dynamic binary translation. In
ASPLOS’12.
[16] P. Ferrie. Attacks on virtual machine emulators. Symantec
Advanced Threat Research, 2006.
[17] P. Ferrie. Attacks on more virtual machine emulators.
Symantec Technology Exchange, 2007.
[18] T. Garﬁnkel and M. Rosenblum. A virtual machine
introspection based architecture for intrusion detection. In
NDSS’03.
[19] M. Grace, Z. Wang, D. Srinivasan, J. Li, X. Jiang, Z. Liang,
and S. Liakh. Transparent protection of commodity os kernels
using hardware virtualization. In SecureComm’10.
[20] F. Guo, P. Ferrie, and T.-C. Chiueh. A study of the packer
problem and its solutions. In RAID’08.
[21] Intel. Intel 64 and IA-32 Architectures Software Developer’s
Manual, volume 3C.
[22] M. G. Kang, H. Yin, S. Hanna, S. McCamant, and D. Song.
Emulating emulation-resistant malware. In VMSec’09.
[23] M. A. Laurenzano, M. M. Tikir, L. Carrington, and A. Snavely.
Pebil: Eﬃcient static binary instrumentation for linux. In
ISPASS’10.
[24] K. P. Lawton. Bochs: A portable pc emulator for unix/x. Linux
Journal, 1996.
[25] K. H. Lee, X. Zhang, and D. Xu. High accuracy attack
provenance via binary-based execution partition. In NDSS’13.
[26] C. Luk, R. Cohn, R. Muth, H. Patil, A. Klauser, G. Lowney,
S. Wallace, V. Reddi, and K. Hazelwood. Pin: building
customized program analysis tools with dynamic
instrumentation. In PLDI’05.
[27] N. Nethercote and J. Seward. Valgrind: a framework for
heavyweight dynamic binary instrumentation.
[28] A. Nguyen, N. Schear, H. Jung, A. Godiyal, S. King, and
H. Nguyen. Mavmm: Lightweight and purpose built vmm for
malware analysis. In ACSAC’09.
[29] T. Raﬀetseder, C. Kr¨ugel, and E. Kirda. Detecting system
emulators. In ISC’07.
[30] N. Riva and F. Falc´on. Dynamic binary instrumentation
frameworks: I know you’re there spying on me. REcon’12.
[31] J. Rutkowska. Subverting vista kernel for fun and proﬁt.
Blackhat USA’06.
[32] K. Scott, N. Kumar, S. Velusamy, B. Childers, J. Davidson,
and M. Soﬀa. Retargetable and reconﬁgurable software
dynamic translation. In CGO’03.
[33] D. Song, D. Brumley, H. Yin, J. Caballero, I. Jager, M. G.
Kang, Z. Liang, J. Newsome, P. Poosankam, and P. Saxena.
Bitblaze: A new approach to computer security via binary
analysis. In ICISS’08.
[34] A. Vasudevan. Re-inforced stealth breakpoints. In CRiSIS’09.
[35] A. Vasudevan and R. Yerraballi. Cobra: Fine-grained malware
analysis using stealth localized-executions. In IEEE S&P’06.
[36] A. Vasudevan and R. Yerraballi. Stealth breakpoints. In
ACSAC’05.
[37] S. Vogl and C. Eckert. Using hardware performance events for
instruction-level monitoring on the x86 architecture. In
EuroSec’12.
[38] C. Willems, R. Hund, A. Fobian, D. Felsch, T. Holz, and
A. Vasudevan. Down to the bare metal: Using processor
features for binary analysis. In ACSAC’12.
[39] L.-K. Yan, M. Jayachandra, M. Zhang, and H. Yin. V2e:
combining hardware virtualization and softwareemulation for
transparent and extensible malware analysis. In VEE’12.
[40] O. Yuschuk. Ollydbg. http://www.ollydbg.de/.
298