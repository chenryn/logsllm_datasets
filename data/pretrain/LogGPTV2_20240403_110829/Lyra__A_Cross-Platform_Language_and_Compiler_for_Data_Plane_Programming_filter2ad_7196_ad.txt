statements, e.g., Lines 8-12 in Figure 8(a), which complicate depen-
dency analysis [37]. We, therefore, convert each if-else condition
into a predicate, and then apply this predicate to all the instructions
in the condition body. For example, the if condition int_enable,
in Line 3 in Figure 8(b), is converted into a predicate, int_enable
? ..., and is applied to all instructions in this condition body, thus
getting Lines 3-6 in Figure 8(c). Once all the branches are removed,
the body of the algorithm becomes a straight-line code block.
Step 3: Single operator tuning. We expand the instructions that
have more than one operator. For example, Line 6 in Figure 8(b) is
flattened into Lines 3 and 4 in Figure 8(c).
Step 4: Static single assignment (SSA) form conversion. SSA
assigns each variable a version field. When the variable is assigned
to a new value, the version increases accordingly. SSA guarantees
no versioned variable is assigned twice and removes the Write-
After-Read and Write-After-Write dependencies. After this step,
only Read-After-Write dependency remains. The int_info1 and
int_info2 (i.e., Lines 4 and 6 in Figure 8(c)), for example, are as-
signed to different versions.
Step 5: Variable type inference. The width of program variables
is inferred based on 3 rules: (1) function call, such as crc32_hash
returns a 32-bit variable; (2) operation, 𝑎𝑛𝑑 operation generates a
1-bit variable; and (3) variable lookup, the input/output type of
the table are defined explicitly. For example, in Figure 8(c), the v1
is inferred as a 32-bit variable as the ig_ts and eg_ts are 32 bits.
4.3 Code Analyzer
So far, the preprocessor has translated a Lyra program P to an IR.
Nevertheless, this IR is a plain-text IR, which lacks context informa-
tion (e.g., instruction dependency, and deployment constraints) for
chip code synthesizing (§5). We, therefore, build a code analyzer to
add “context” to the IR.
Instruction dependency generation. We first analyze the depen-
dencies among IR instructions to generate an instruction depen-
dency graph. This is important, because it would determine the
execution order and placement of these instructions in the chip-
specific code synthesizing. For example, if instruction 𝑏 relies on
another instruction 𝑎, 𝑏 should be placed in the stage behind 𝑎’s
1:    func int_info (bit[32] info) {2:        info = 0;  3:        info = (ig_ts - eg_ts) & 0x0fffffff;4:        info = info & (sw_id 𝜉𝑡,end
𝜉𝑡,start≤ 𝑗≤𝜉𝑡,end
We also encode the RAM memory constraints based on [26]. Sup-
pose each stage in the RMT switch has 𝑁memory RAM blocks with
ℎ entries and 𝑤 bit-width. For each stage 𝑗:
⌈ ⌈ 𝐸𝑡,𝑗
ℎ ⌉ · 𝑀𝑡
𝑤
⌉ ∗ Valid(t) ≤ 𝑁memory
(2)

𝑡 ∈L
where Valid(t) represents the validity of table 𝑡, and its value is either
1 or 0. In similar ways, we can also encode other constraints such as
the maximum number of stages, the maximum number of tables per
stage, the maximum number of entries in the parser TCAM table,
PHV allocation, predefined library-function call related resources,
packet transactions [37]. Please see Appendix A for more details
of chip constraint encoding. All the encoded constraints are put in
the set of conditional placement constraints.
5.5 Encoding Deployment Constraints
Besides the constraints related to the conditional implementation
and different switching ASICs, we also need to encode constraints
like scope, flow path, and instruction dependencies. This section
describes how to encode these constraints, which is important for
the composition. Note that the constraints in this section cannot
be encoded by integer linear programming (ILP), since ILP cannot
encode “if-else” and dependency.
SIGCOMM ’20, August 10–14, 2020, Virtual Event, NY, USA
Algorithm 2: Extensible resource encoding.
Input: 𝐼𝑎: Context-aware IR for algorithm 𝑎, target switch 𝑠.
Output: L: The variables in the resource and the existence condition.
1 S ← DownStreamSwitches(𝑠);
2 foreach local variable 𝑣 ∈ I𝑎 do
𝐼𝑤 ← WriteInstruction(𝑣)
I𝑟 ← ReadInstructions(𝑣)
foreach switch 𝑠𝑑 ∈ S do
V𝑤 .𝑎𝑝𝑝𝑒𝑛𝑑(𝑓𝑠𝑑 (𝐼𝑤))
foreach read instruction 𝐼𝑟 ∈ I𝑟 do
F𝑟 .𝑎𝑝𝑝𝑒𝑛𝑑(𝑓𝑠𝑑 (𝐼𝑟))
V𝑟 .𝑎𝑝𝑝𝑒𝑛𝑑( F𝑟)
L[𝑣] = ( V𝑤) ⊕ ( V𝑟)
3
4
5
6
7
8
9
10
11 return L
Encoding topology constraints. As shown in §4.3, topology con-
straints in context-aware IR contain two parts: algorithm scope and
flow paths in the specified scope.
Scope constraints. For each IR instruction in 𝐼𝑎, it can only be
deployed in the specified scope:𝐼 ∈𝐼𝑎,𝑠∉S𝑎
𝑠, on each path.𝐼 ∈𝐼𝑎,𝑠∈𝑝 If (𝑓𝑠(𝐼), 1, 0) = 1
Flow path constraints. For each possible flow path 𝑝 within the
scope, an instruction 𝐼 must be deployed on only one of switches,
𝑓𝑠(𝐼) = False.
Encoding instruction dependencies. We now encode the in-
struction dependencies in the context-aware IR. If an instruction 𝐼′
is deployed on one switch 𝑠 on the path 𝑝, then (1) for each instruc-
tion 𝐼 the instruction 𝐼′ depends on, 𝐼 cannot be deployed on the
switches behind 𝑠; (2) for another instruction 𝐼′′ depended by 𝐼, 𝐼
cannot be deployed on switches in front of 𝑠. Thus, we have:
𝐼′ depends on 𝐼 ⇒
𝐼 depends on 𝐼′′ ⇒
𝑓𝑠′ (𝐼′) = 𝐹𝑎𝑙𝑠𝑒
𝑓𝑠′′ (𝐼′′) = 𝐹𝑎𝑙𝑠𝑒
𝑠′∈prev(s, p),𝐼′∈succ(I)
𝑠′′∈next(s, p),𝐼′′∈pred(I)