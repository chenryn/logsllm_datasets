title:SURF: detecting and measuring search poisoning
author:Long Lu and
Roberto Perdisci and
Wenke Lee
SURF: Detecting and Measuring Search Poisoning
Long Lu
College of Computing
Georgia Inst. of Technology
PI:EMAIL
Roberto Perdisci
Dept. of Computer Science
University of Georgia
PI:EMAIL
Wenke Lee
College of Computing
Georgia Inst. of Technology
PI:EMAIL
ABSTRACT
Search engine optimization (SEO) techniques are often abused to
promote websites among search results. This is a practice known
as blackhat SEO. In this paper we tackle a newly emerging and
especially aggressive class of blackhat SEO, namely search poi-
soning. Unlike other blackhat SEO techniques, which typically at-
tempt to promote a website’s ranking only under a limited set of
search keywords relevant to the website’s content, search poison-
ing techniques disregard any term relevance constraint and are em-
ployed to poison popular search keywords with the sole purpose of
diverting large numbers of users to short-lived trafﬁc-hungry web-
sites for malicious purposes.
To accurately detect search poisoning cases, we designed a novel
detection system called SURF. SURF runs as a browser component
to extract a number of robust (i.e., difﬁcult to evade) detection fea-
tures from search-then-visit browsing sessions, and is able to ac-
curately classify malicious search user redirections resulted from
user clicking on poisoned search results. Our evaluation on real-
world search poisoning instances shows that SURF can achieve a
detection rate of 99.1% at a false positive rate of 0.9%. Further-
more, we applied SURF to analyze a large dataset of search-related
browsing sessions collected over a period of seven months starting
in September 2010. Through this long-term measurement study we
were able to reveal new trends and interesting patterns related to a
great variety of poisoning cases, thus contributing to a better un-
derstanding of the prevalence and gravity of the search poisoning
problem.
Categories and Subject Descriptors
H.3.3 [INFORMATION STORAGE AND RETRIEVAL]: Infor-
mation Search and Retrieval—Relevance feedback
General Terms
Security
Keywords
Search engine poisoning, Malicious search engine redirection,
Detection, Measurement
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
CCS’11, October 17–21, 2011, Chicago, Illinois, USA.
Copyright 2011 ACM 978-1-4503-0948-6/11/10 ...$10.00.
1.
INTRODUCTION
Search engines, capable of digging out the most relevant from
oceans of information, have become web surfers’ ﬁrst choice when
seeking information on the web. In fact, for most websites more
than 70% of their visitors reach their pages through search en-
gines [6]. Therefore, website owners always strive to attract more
visits by optimizing their exposure in relevant search results. To
fulﬁll this need, web developers use a number of search engine op-
timization (SEO) techniques, which can improve the visibility of a
website to the search crawlers, highlight its relevance under certain
search terms, and promote its raking in the search results.
Legitimate uses of SEO techniques are accepted and even en-
couraged by search engines [1]. However, dishonest web devel-
opers may choose to abuse these techniques in various ways to
gain (or cheat) a favorable ranking in the search results, a prac-
tice known as blackhat SEO. In this case, search crawlers are pre-
sented with deceptive views of a website, which consist of spe-
cially crafted webpages with inﬂated relevance to a set of target
search terms. Attempts to counter blackhat SEO have been pro-
posed mainly in the information retrieval community [18, 24], but
with very limited success against the recent surge of blackhat SEO
adopters [11].
In the meantime, blackhat SEO has not captured
sufﬁcient attention from the security community, perhaps because
such techniques have been historically employed by non-harmful
websites, including some high proﬁle ones [10], that execute overly
aggressive marketing strategies to win search users from their com-
petitors.
This paper tackles a newly emerging class of blackhat SEO tech-
niques developed by Internet miscreants to lure search users into
visiting malicious websites [7]. We refer to this new class of black-
hat SEO as search poisoning. Unlike other blackhat SEO tech-
niques, which typically attempt to promote a website’s ranking
only under a limited set of search keywords relevant to the web-
site’s content, search poisoning techniques disregard any term rel-
evance constraint. In practice, search poisoning techniques target
any search term that can maximize the number of incoming search
users (e.g., popular keywords). This is in contrast with SEO or
other blackhat SEO techniques adopted by regular websites, be-
cause if search poisoning were to be used to promote a regular web-
site, users landing on the website via completely unrelated search
terms may get annoyed and the website’s reputation may be ir-
reparably damaged. Therefore, we posit that search poisoning can-
not be used for legitimate purposes and is only useful to short-lived
trafﬁc-hungry websites that aim to attract search users for malicious
purposes.
We approach the search poisoning problem from a new angle,
compared to previous work on blackhat SEO. We focus on detect-
ing malicious search user redirections, an essential component of
467search poisoning that we discovered during our study (Section 2.2).
To detect malicious search user redirections, we designed a novel
detection system named SURF (Search User Redirection Finder),
which runs as a browser component and is able to accurately de-
tect poisoned search results. In this paper, we restrict our deﬁni-
tion of “malicious search user redirections” to be any redirection
that starts from a search landing page (i.e., the immediate page a
search result points to) promoted by search poisoning and ends at
an unwanted or malicious terminal page (i.e., the ﬁnal destination
of the redirection). We show that these malicious redirections can
be characterized by a number of distinctive features that are collec-
tively difﬁcult to circumvent. SURF is designed to capture this very
type of malicious redirections, and in turn to detect search poison-
ing instances. Other malicious redirections on landing pages not
involving search poisoning are out of the scope of this work.
To detect search poisoning instances, SURF analyzes data col-
lected during a search-then-visit browsing session and outputs a
classiﬁcation result, namely whether or not the monitored brows-
ing session includes malicious search user redirections caused by a
poisoned search result. As shown in Figure 1, the monitored brows-
ing session starts from the search result page, passes by the landing
page and possibly some intermediate pages, and stops at the termi-
nal page to which the search user is eventually redirected. During
this course, SURF collects the following information: (i) browser
events to track page (and frame) loads and redirections; (ii) net-
work information to model the redirection chain; and (iii) search
result information to measure the poisoning likelihood of the land-
ing page. From this information, SURF extracts a number of statis-
tical features, which are then fed to a classiﬁer trained to identify
instances of search poisoning. Given the adversarial nature of clas-
sifying search poisoning instances, we selected our feature set with
particular emphasis on individual feature robustness while retain-
ing collective feature generality. To identify a suitable set of fea-
tures, we performed a manual analysis of a dataset Sstudy contain-
ing 1,084 real-world search poisoning cases (see Section 2.2). We
then experimented with 15 candidate features on a separate dataset
Seval containing 2,344 independently labeled samples of brows-
ing sessions, 1,160 of which where related to search poisoning and
there remaining 1,184 were not. Through feature selection, we re-
ﬁned the initial feature set down to 9 features based on which we
evaluated SURF’s classiﬁer, which achieved an average true posi-
tive rate of 99.1% at a false positive rate of 0.9%.
To further demonstrate the effectiveness of SURF, we developed
a prototype system and deployed it to classify daily popular search
results obtained from both Google and Bing over a period of seven
months (from September 2010 to April 2011). This large scale
evaluation allowed us to conduct extensive measurements of real-
world search poisoning cases, through which we observed that, on
average, about 50% of popular searches contain poisoned results.
During this measurement study we also observed a surge in both the
volume of search poisoning instances and the variety of malicious
content reached through poisoned search results.
In summary, this paper makes the following contributions:
• We clearly deﬁne search poisoning and distinguish it from
other abuses of SEO techniques. We report an in-depth study
to motivate and inspire countermeasures against this increas-
ing threat.
• We design and evaluate SURF, a system that is able to detect
search poisoning with a 99.1% true positive rate at a 0.9%
false positive rate.
Figure 1: SURF Architecture
• Using a SURF prototype, we conducted a seven-month mea-
surement study on poisoned popular search results, which
highlights the severity of search poisoning and provides in-
sight into its fast growing trends.
2. BACKGROUND AND PROBLEM STUDY
In this Section, we provide a brief overview of the fundamentals
of search engines and the reason why search results are subject to
manipulation. We then present a study of search poisoning based
on real world data, and discuss the observations that inspired our
detection approach.
2.1 Search Engine and Blackhat SEO
Search engines typically employ crawlers to discover newly cre-
ated or updated webpages. Each crawled page is then indexed
based on keywords retrieved from its content. Upon a search query,
webpages are ranked based on their relevance to the search terms
and presented to the user.
This gives the abusers the following advantages. First, search en-
gines implicitly trust the authenticity of the content on the indexed
webpages, even though the content is under complete control of
the website owners. Second, a web server can easily distinguish
between search crawlers and human visitors. It is this implicit trust
and distinguishability that give rise to blackhat SEO, whereby a
web server fulﬁlls webpage requests from crawlers with specially
crafted content having inﬂated relevance to a selected set of key-
words, referred to as the target keywords. In addition, these crafted
pages often contain large numbers of cross-reference hyperlinks to
webpages that belong to the same blackhat SEO campaign. These
hyperlinks have the effect of increasing the incoming link count
for the promoted webpages, thus boosting the ranking in the search
results.
Despite the fact that they involve some level of dishonesty, black-
hat SEO techniques are sometimes used by legitimate businesses.
In this paper, we distinguish between two types of blackhat SEO,
namely search inﬂating and search poisoning. Search inﬂating
aims to boost a website ranking through search keywords closely
related to the promoted website, therefore only attracting users who
search for topics related to the promoted website. On the other
hand, search poisoning aims to boost a website’s ranking though
popular search keywords, regardless of whether these keywords are
actually related to the promoted website’s content or not. Unlike
search inﬂating, which may be adopted by some legitimate web-
sites, search poisoning only ﬁts the need of visitor-hungry websites
that simply want to increase the number of visitors for malicious
purposes (e.g., for malware propagation purposes).
Most previous works on blackhat SEO detection apply lexical
and structural analysis on page content [18, 22], or graph-based
analysis on hyper-links [24]. However, very limited success has
been achieved in practice [9], as the battle soon turned into an arms
Search ResultPageinter-mediatepagesTerminal PageLanding PageFeatureExtractorSURF ClassiferSearch User Redirection ChainInstrumented BrowserFeature SourcesResultBrowser Events Network InfoSearch Result468race. Having full control over webpage visibility and the freedom
of adopting new evasion techniques gives adversaries signiﬁcant
upper hands, and makes it fundamentally difﬁcult to design robust
detection schemes based on lexical and structural analysis. To mit-
igate these problems, our approach aims to detect search poison-
ing instances using a set of features that are collectively difﬁcult to
evade because they are intrinsic to how search poisoning works, as
we discuss in Section 3.2.1.
2.2 Search Poisoning Study
Search poisoning instances luring visitors to malware websites
were ﬁrst reported in 2007 [7]. However, until recently search poi-
soning has not been sufﬁciently studied, and has been only sporad-
ically mentioned within the anti-malware community (mostly due
to fake AV websites [20]).
To gain a more in-depth understanding of the search poisoning
problem, we manually analyzed a dataset Sstudy containing 1,084
real-world search poisoning cases collected in September 2010.
This preliminary study aimed to discover a set of robust features
that can be leveraged for detection purposes, and to inspire our
overall detection approach.
To collect the dataset Sstudy we proceeded as follows. We de-
ployed an army of instrumented browsers, which on a daily ba-
sis automatically query Google and Bing with keywords that have
been popular for the past 7 days. For each query, the browsers
visited the top 100 URLs in the search results1. All network data
and browsing events occurred during each browsing session were
recorded as a browsing trace. This data collection process resulted
in a very large dataset D containing over half a million browsing
traces. Sstudy was derived from D using a simple heuristic to se-
lect traces that lead to malicious [3] or non-reputable webpages [4]
with content irrelevant to the search keywords. This coarse-grained
ﬁltering yielded 1,084 highly likely search poisoning cases consist-
ing of 596 unique landing URLs. It is worth noting that this dataset
is not meant to be inclusive of all poisoning traces in D, which
is impossible to achieve without ﬁrst developing a reliable detec-
tion system. However, our ﬁltering heuristic produced a Sstudy
dataset that exhibits satisfactory accuracy and sufﬁcient diversity,
as conﬁrmed by our manual analysis. Therefore, Sstudy represents
a reasonable base for our preliminary study of search poisoning.
Below we itemize our observations and lessons learned from our
manual analysis, which inspired the choice of the statistical features
used by SURF.
O1: Ubiquitous use of cross-site redirections
We found that over 98% traces in Sstudy contain one or more
redirections that cross website boundaries. The remaining 2% of
browsing traces that do not contain such redirections are mostly
due to incompletely rendered webpages, or modal dialogs that re-
quire non-trivial user interactions to proceed. On the other hand,
less than 6% of the entire traces in (D − Sstudy) involve cross-site
redirections. This ubiquitous use of cross-site redirections can be
intuitively explained by the high risk and low effectiveness of ex-
posing the malicious terminal website directly to search engines for
rank promotion (thus a separated landing website is needed). For
example, search engines have various security detectors in place
to ﬁlter known malicious webpages and downgrade ranks of suspi-
cious ones. Therefore, directly promoting malicious webpages can
be a vain attempt and risks to jeopardize the entire search poison-