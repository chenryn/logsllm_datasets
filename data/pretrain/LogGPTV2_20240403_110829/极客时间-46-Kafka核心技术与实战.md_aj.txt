## **典型使用场景**Kafka 拦截器都能用在哪些地方呢？其实，跟很多拦截器的用法相同，**Kafka拦截器可以应用于包括客户端监控、端到端系统性能检测、消息审计等多种功能在内的场景**。我以端到端系统性能检测和消息审计为例来展开介绍下。今天 Kafka 默认提供的监控指标都是针对单个客户端或 Broker的，你很难从具体的消息维度去追踪集群间消息的流转路径。同时，如何监控一条消息从生产到最后消费的端到端延时也是很多Kafka 用户迫切需要解决的问题。从技术上来说，我们可以在客户端程序中增加这样的统计逻辑，但是对于那些将Kafka作为企业级基础架构的公司来说，在应用代码中编写统一的监控逻辑其实是很难的，毕竟这东西非常灵活，不太可能提前确定好所有的计算逻辑。另外，将监控逻辑与主业务逻辑耦合也是软件工程中不提倡的做法。现在，通过实现拦截器的逻辑以及可插拔的机制，我们能够快速地观测、验证以及监控集群间的客户端性能指标，特别是能够从具体的消息层面上去收集这些数据。这就是Kafka 拦截器的一个非常典型的使用场景。我们再来看看消息审计（message audit）的场景。设想你的公司把 Kafka作为一个私有云消息引擎平台向全公司提供服务，这必然要涉及多租户以及消息审计的功能。作为私有云的 PaaS提供方，你肯定要能够随时查看每条消息是哪个业务方在什么时间发布的，之后又被哪些业务方在什么时刻消费。一个可行的做法就是你编写一个拦截器类，实现相应的消息审计逻辑，然后强行规定所有接入你的Kafka 服务的客户端程序必须设置该拦截器。
## **案例分享**下面我以一个具体的案例来说明一下拦截器的使用。在这个案例中，我们通过编写拦截器类来统计消息端到端处理的延时，非常实用，我建议你可以直接移植到你自己的生产环境中。我曾经给一个公司做 Kafka培训，在培训过程中，那个公司的人提出了一个诉求。他们的场景很简单，某个业务只有一个Producer 和一个Consumer，他们想知道该业务消息从被生产出来到最后被消费的平均总时长是多少，但是目前Kafka 并没有提供这种端到端的延时统计。学习了拦截器之后，我们现在知道可以用拦截器来满足这个需求。既然是要计算总延时，那么一定要有个公共的地方来保存它，并且这个公共的地方还是要让生产者和消费者程序都能访问的。在这个例子中，我们假设数据被保存在Redis 中。Okay，这个需求显然要实现生产者拦截器，也要实现消费者拦截器。我们先来实现前者：    public class AvgLatencyProducerInterceptor implements ProducerInterceptor {      private Jedis jedis; // 省略 Jedis 初始化      @Override    public ProducerRecord onSend(ProducerRecord record) {        jedis.incr("totalSentMessage");        return record;    }      @Override    public void onAcknowledgement(RecordMetadata metadata, Exception exception) {    }      @Override    public void close() {    }      @Override    public void configure(Map configs) {    }上面的代码比较关键的是在发送消息前更新总的已发送消息数。为了节省时间，我没有考虑发送失败的情况，因为发送失败可能导致总发送数不准确。不过好在处理思路是相同的，你可以有针对性地调整下代码逻辑。下面是消费者端的拦截器实现，代码如下：    public class AvgLatencyConsumerInterceptor implements ConsumerInterceptor {      private Jedis jedis; // 省略 Jedis 初始化      @Override    public ConsumerRecords onConsume(ConsumerRecords records) {        long lantency = 0L;        for (ConsumerRecord record : records) {            lantency += (System.currentTimeMillis() - record.timestamp());        }        jedis.incrBy("totalLatency", lantency);        long totalLatency = Long.parseLong(jedis.get("totalLatency"));        long totalSentMsgs = Long.parseLong(jedis.get("totalSentMessage"));        jedis.set("avgLatency", String.valueOf(totalLatency / totalSentMsgs));        return records;    }      @Override    public void onCommit(Map offsets) {    }      @Override    public void close() {    }      @Override    public void configure(Map configs) {在上面的消费者拦截器中，我们在真正消费一批消息前首先更新了它们的总延时，方法就是用当前的时钟时间减去封装在消息中的创建时间，然后累计得到这批消息总的端到端处理延时并更新到Redis 中。之后的逻辑就很简单了，我们分别从 Redis中读取更新过的总延时和总消息数，两者相除即得到端到端消息的平均处理延时。创建好生产者和消费者拦截器后，我们按照上面指定的方法分别将它们配置到各自的Producer 和 Consumer 程序中，这样就能计算消息从 Producer 端到 Consumer端平均的处理延时了。这种端到端的指标监控能够从全局角度俯察和审视业务运行情况，及时查看业务是否满足端到端的SLA 目标。
## **小结**今天我们花了一些时间讨论 Kafka提供的冷门功能：拦截器。如之前所说，拦截器的出场率极低，以至于我从未看到过国内大厂实际应用Kafka拦截器的报道。但冷门不代表没用。事实上，我们可以利用拦截器满足实际的需求，比如端到端系统性能检测、消息审计等。从这一期开始，我们将逐渐接触到更多的实际代码。看完了今天的分享，我希望你能够亲自动手编写一些代码，去实现一个拦截器，体会一下Kafka拦截器的功能。要知道，"纸上得来终觉浅，绝知此事要躬行"。也许你在敲代码的同时，就会想到一个使用拦截器的绝妙点子，让我们拭目以待吧。
## **开放讨论**思考这样一个问题：Producer 拦截器 onSend 方法的签名如下：    public ProducerRecord onSend(ProducerRecord record)如果我实现的逻辑仅仅是 return null，你觉得 Kafka会丢弃该消息，还是原封不动地发送消息？请动手试验一下，看看结果是否符合你的预期。欢迎写下你的思考和答案，我们一起讨论。如果你觉得有所收获，也欢迎把文章分享给你的朋友。![](Images/a7d15815f9efb5693db5b2d278244658.png){savepage-src="https://static001.geekbang.org/resource/image/c8/bf/c89da43deab85fe7cb06acec867aa5bf.jpg"}
# 13 \| Java生产者是如何管理TCP连接的？你好，我是胡夕。今天我要和你分享的主题是：Kafka 的 Java 生产者是如何管理TCP 连接的。
## 为何采用 TCP？Apache Kafka 的所有通信都是基于 TCP 的，而不是基于 HTTP或其他协议。无论是生产者、消费者，还是 Broker之间的通信都是如此。你可能会问，为什么 Kafka 不使用 HTTP作为底层的通信协议呢？其实这里面的原因有很多，但最主要的原因在于 TCP 和HTTP 之间的区别。从社区的角度来看，在开发客户端时，人们能够利用 TCP本身提供的一些高级功能，比如多路复用请求以及同时轮询多个连接的能力。所谓的多路复用请求，即 multiplexingrequest，是指将两个或多个数据流合并到底层单一物理连接中的过程。TCP的多路复用请求会在一条物理连接上创建若干个虚拟连接，每个虚拟连接负责流转各自对应的数据流。其实严格来说，TCP并不能多路复用，它只是提供可靠的消息交付语义保证，比如自动重传丢失的报文。更严谨地说，作为一个基于报文的协议，TCP能够被用于多路复用连接场景的前提是，上层的应用协议（比如HTTP）允许发送多条消息。不过，我们今天并不是要详细讨论 TCP原理，因此你只需要知道这是社区采用 TCP 的理由之一就行了。``{=html}除了 TCP 提供的这些高级功能有可能被 Kafka客户端的开发人员使用之外，社区还发现，目前已知的 HTTP库在很多编程语言中都略显简陋。基于这两个原因，Kafka 社区决定采用 TCP 协议作为所有请求通信的底层协议。
## Kafka 生产者程序概览Kafka 的 Java 生产者 API 主要的对象就是KafkaProducer。通常我们开发一个生产者的步骤有 4 步。第 1 步：构造生产者对象所需的参数对象。第 2 步：利用第 1 步的参数对象，创建 KafkaProducer 对象实例。第 3 步：使用 KafkaProducer 的 send 方法发送消息。第 4 步：调用 KafkaProducer 的 close 方法关闭生产者并释放各种系统资源。上面这 4 步写成 Java 代码的话大概是这个样子：    Properties props = new Properties ();props.put(“参数 1”, “参数 1 的值”)；props.put(“参数 2”, “参数 2 的值”)；……try (Producer producer = new KafkaProducer<>(props)) {            producer.send(new ProducerRecord(……), callback);……}这段代码使用了 Java 7 提供的 try-with-resource 特性，所以并没有显式调用producer.close() 方法。无论是否显式调用 close方法，所有生产者程序大致都是这个路数。现在问题来了，当我们开发一个 Producer 应用时，生产者会向 Kafka集群中指定的主题（Topic）发送消息，这必然涉及与 Kafka Broker 创建 TCP连接。那么，Kafka 的 Producer 客户端是如何管理这些 TCP 连接的呢？