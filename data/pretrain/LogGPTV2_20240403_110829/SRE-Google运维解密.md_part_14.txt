但是，我们可以做的是指定平均请求延迟小于100ms，确立这个目标可以鼓励开发者优
我们并不能针对这个指标设置一个SLO。
的值。例如对外部传入的HTTP请求来说，每秒查询数量（QPS）指标是由用户决定的，
延迟小于100ms。
返回结果的速度应该是很“快”的，那么我们可以定义一个SLO，要求搜索请求的平均
定义是SLI≤目标值，或者范围下限≤SLI≤范围上限。例如，对莎士比亚服务来说，
SLO是服务质量目标（Objective）：服务的某个SLI的目标值，或者目标范围。SLO的
称为“2个9”，99.999%被称为“5个9”。目前Google云计算服务公开的可用性指标是“3.5
可以实现的一个目标。运维行业经常用9的数量来描述可用程度。例如，99%可用性被
重要指标。虽然100%的“可用性”是不可能实现的，但是接近100%的可用性指标是
对数据存储系统来说，持久性（durability）一
标通常利用“格式正确的请求处理成功的比例”来定义，有时也称为服务产出（yield）。
可用性（availability）是另外一个SRE重视的SLI，代表服务可用时间的百分比。该指
数据经常是最直接的用户指标，但是由于条件限制可能只能监控服务器端的延迟数据。
可能非常难以获取，或者无法观测，我们只能用某种指标来替代。例如，客户端的延迟
理想情况下，SLI应该直接度量某一个具体的服务质量。但是很多时候，直接度量信息
百分比等汇总数据。
度量通常是汇总过的：在某一个度量时间范围内将原始数据收集起来，计算速率、平均值、
的SLI包括错误率（请求处理失败的百分比）、系统吞吐量（每秒请求数量）等。这些
高通常会导致延迟升高，服务到达一定负载水平后性能下降是很常见的。
的值，但是一般来说速度快要比速度慢更好，因为用户可见的延迟超过一定数量后会使
化前端服务降低延迟，或者采购某种延迟更低的硬件。（100ms在这里只是一个随意选择
目标
个9”
大部分服务都将请求延迟—处理请求所消耗的时间——作为一个关键SLI。其他常见
一99.95%可用。
一“服务太慢了”。如果没有一个明确的SLO，用户经常会按照自己的理解
—数据能够完整保存的时间—也是一个
服务质量术语
35
<39
---
## Page 78
Google搜索服务是没有公开SLA的一个典型服务：我们当然希望所有人都能够最方便、
SLI：很明显，提供一个客观的方式来度量SLO是很重要的，否则大家就会产生分歧。
SRE确实会参与帮助避免触发SLA中的惩罚性条款。同时，SRE会参与制定具体的
SRE通常不会参与SLA的书写，因为SLA是与业务产品的决策紧密相关的。但是，
SLO没有达到时，有什么后果？”如果没有定义明确的后果，那么我们就肯定是在讨论
退款或者罚款一
确的协议，描述了在达到或者没有达到SLO之后的后果。这些后果可以是财务方面的一
最后，SLA是服务质量协议（Agreement）：指服务与用户之间的一个明确的，或者不明
协议
导致信心不足一
（例如Chubby的例子，参见下面的“全球Chubby服务计划内停机”。另外一种情况是会
题可能会导致对某个服务的过度依赖—用户错误地认为这个服务会比实际情况更可靠
一个SLO，而不是SLA。
依赖，强迫服务的负责人尽早面对这类分布式系统的天生缺陷。
将服务停机。利用这种方法，我们可以很快找出那些对Chubby全球服务的不合理
真实故障没有将可用性指标降低到SLO之下，SRE会有意安排一次可控的故障，
定义的SLO，但是同时也会确保服务质量不会大幅超出该SLO。每个季度，如果
我们在这里采用了一个很有趣的解决办法：SRE保证全球Chubby服务能够达到预
况是多么罕见。
因为这些服务实际上在Chubby全球服务不可用的时候不能正常工作，不管这种情
更多的服务依赖于此。Chubby全球服务的高可靠性实际上提供了一种安全假象
以至于其他服务负责人开始认为全球Chubby服务永远不会出故障，从而不停地将
障都会影响到外部用户。但是，由于真正的全球Chubby服务故障出现的频率太低，
推移，我们发现，全球实例出现问题经常会导致其他服务出现故障，其中很多故
Chubby服务中，我们将Chubby实例的副本分布在不同的地理区域。随着时间的
Chubby是Google的一个分布式锁服务，用于松散耦合的分布式系统。
到SLO，真实的“违反SLA”
在讨论SLA的大部分时候，实际上是在讨论SLO。
第4章
服务质量目标
—也可能是其他类型的。区别SLO和SLA的一个简单方法是问“如果
一用户会认为系统比实际情况更脆弱和不可靠，从而不会去使用它。
全球Chubby服务计划内停机
注1
可能会触发一次违反合约的法律诉讼！
作者：MarcAlvidrez
如果某个人说道“违反SLA”，实际是指没有达
在全球
---
## Page 79
10章）或者Prometheus。或者利用某种日志分析系统，例如分析日志中HTTP500回复
利用某种监控系统，大部分指标数据都在服务器端被收集，例如Borgmon（具体参见第
常见的服务，根据它们的相关SLI通常会归类为以下几个大类。
系统健康程度的评估和关注就足够了。
指标过少则会导致某些重要的系统行为被忽略。一般来说，四五个具有代表性的指标对
能真正决定哪些指标是否有用。指标过多会影响对那些真正重要的指标的关注，而选择
运维人员和最终用户各关心什么
何来识别哪些指标对服务是最重要的呢？
既然我们已经详细描述了为什么选择合适的指标度量服务质量是很重要的，那么究竟如
指标在实践中的应用
理论说了这么多，终于可以开始讲一些实践经验了。
管某个服务是否具有SLA，定义SLI与SLO，并且用它们来管理服务质量都是很有价值的。
收入下降。很多其他的Google服务，例如Google for Work，具有明确的用户 SLA。不
指标的收集
我们不应该将监控系统中的所有指标都定义为SLI；只有理解用户对系统的真实需求才
如果搜索服务不可用依然有后果产生一
最快地使用Google的搜索服务，但是我们并没有与全世界签订合同。但是，即使如此，
·用户可见的服务系统，例如莎士比亚搜索服务的前端服务器通常关心可用性、延
它更关注系统内部的数据，而不是系统本身，所以这通常不是SRE直接负责的。
或者进行了正确的数据分析操作。正确性是系统健康程度的一个重要指标，但是
所有的系统都应该关注：正确性。是否返回了正确的回复，是否读取了正确的数据，
还会关注某个单独处理阶段的延迟。）
句话说：处理了多少数据？数据从输入到产出需要多少时间？（某些流水线任务
大数据系统，例如数据处理流水线系统，
参见第26章。
时间？我们是否可以随时访问数据？数据是否一段时间内还能被读取？扩展讨论
存储系统通常强调：延迟、可用性和数据持久性。换句话说：读写数据需要多少
多少请求可以被处理？
迟，以及吞吐量。换句话说：是否能正常处理请求？每个请求花费的时间是多少？
—对Google形象有损害，同时也会使得广告业务
一般来说关心吞吐量和端到端延迟。换
指标在实践中的应用
41
---
## Page 80
38
的请求延迟都小于100ms）。响应时间的分布越分散，意味着普通用户受到长尾请求延迟
的数值都满足某种条件。例如请求延迟的99%为100ms指的是，在所有请求中，99%
现了指标的最差情况，而50%则体现了普遍情况（99%百分位是指在原始数据中99%
利用百分位指标可以帮助我们关注该指标的分布性：高百分位，例如99%和99.9%体
图4-1：某系统的50%、85%、95%、99%的请求延迟，注意这里的Y轴是指数级分布的。
出现了巨大变化（图中最上面的那条线）。
中的变化。图4-1提供了一个例子：虽然常见请求可以在50ms完成，但5%的请求却慢
求可能很快，其他的可能会很慢，有时候会非常慢。简单平均可能会掩盖长尾延迟和其
大部分指标都应该以“分布”，而不是平均值来定义。例如，针对某个延迟SLI，某些请
是却掩盖了一个重要的细节；很可能大部分请求都是很快的，但是长尾请求速度却很慢。
是一样的，但是在即时负载上却是两倍。同样的，平均请求延迟可能看起来很简单，但
200个请求，在其他时间请求为0。该服务与持续每秒处理100个请求的服务平均负载
的平均值？后者可能会掩盖仅仅持续几秒的一次请求峰值。假设某个系统在偶数秒处理
也需要在某个度量时间范围内进行汇总。该度量值是应该每秒获取一次，还是每分钟内
某些指标的汇总看起来是很简单的，例如每秒服务请求的数量，但是即使这种简单度量
为了简化和使数据更可用，我们经常需要汇总原始度量数据。汇总过程应该非常小心
汇总
度量页面在浏览器中可用的延迟是度量用户体验的一个更好的指标。
的延迟可能会错失由页面JavaScript脚本导致的用户可见的延迟问题。在这个例子中，
响服务器端指标，但是对用户产生影响的问题。例如，只关注莎士比亚服务器搜索后端
所占的比例。然而，某些系统可以加入对客户端数据的收集，否则可能会错失一些不影
了20倍！针对平均值的监控和报警将不会发现任何改变，但是服务的确在长尾延迟上
mlseconds
第4章服务质量目标
08:30
0060
09:30
10:00
10:30
11.00
11:30
---
## Page 81
近似。然而，如果我们只是从可以简单度量的数值入手，最终的SLO的作用就会很有限。
户真正关心的部分经常是度量起来很困难，甚至是不可能的，所以我们需要以某种形式
我们应该从思考（或者调研）用户最关心的方面入手，而非从现在能度量什么人手。用
为了节约成本，应该为常见的指标构建一套可以重用的SLI模板，从而使得理解每个
义模板的服务可以不需要再次自己定义SLI。
我们建议标准化一些常见的SLI，以避免每次都要重新评估它们。任何一个符合标准定
指标的标准化
正常的。
团队只关注长尾部分，因为如果99.9%的系统行为都正常的话，那50%部分就肯定也是
通常更喜欢速度较慢的系统，而不是一个请求速度抖动很厉害的系统，所以，某些SRE
的影响就越明显，这可能预示了负载过高情况下出现的排队问题。用户研究显示，用户
目标在实践中的应用
SLI更简单。
高的服务器自动重启）。
这个假设做出的操作就有可能频率过高，或者频率过低（例如根据请求延迟将过
感觉和近似方法在这里并不适用。例如，如果分布情况和假设不一致，那么根据
我们同时也不会假设数据是平均分配的，
我们不能假设算术平均值和中位数是相等的一
于0，同时如果超时设置为1000ms，则不可能有成功请求超过这个时间。因此，
机系统的本身特质决定，数据是具有特定分布特点的——例如，请求延迟必须大
效应比算术平均值更有特点，使用百分比分布能够更清晰地进行分析。因为计算
一般来说，SRE更倾向于分析一组数据的百分比分布，而非其算术平均值。长尾
?
数据访问延迟：从收到请求到最后一个字节被发出
数据如何获取：通过监控系统获取服务器端信息得到
包含哪些请求：从黑盒监控任务发来的HTTPGET请求
汇总范围：集群中的全部任务
汇总间隔：每1分钟汇总一次
度量频率：每10秒一次
关于统计性谬误
一切都必须经过验证。某些常见的直觉
一它们甚至可能相差甚远！
目标在实践中的应用
43
---
## Page 82
选择目标SLO不是一个纯粹的技术活动，因为这里还涉及产品和业务层面的决策，SLI
目标的选择
利用这两个数值的差值可以指导新版本的发布。
SLO不达标的频率可以用来与错误预算进行对比（见第3章“使用错误预算的目的”一节），
之前得到预警。