attacker collects k traces of each page in the target web site,
along with k traces of n other web pages chosen arbitrarily
(e.g. random web pages). These web pages form O, the set
of observations that may be generated by the HMM. He uses
the collected traces to build a classiﬁer, C, as described in
the previous section. For each page, s, in the target web site,
he then collects (cid:96) additional traces and estimates Pr[o|s] as
the fraction of the (cid:96) traces from page s that C classiﬁes as
608page o. If no trace for a page s ever gets classiﬁed as a trace
for page o, then he sets Pr[o|s] to a small non-zero value.
Huge web sites may have thousands or even millions of
pages, so it would be impractical to make a model cover-
ing each page separately. Fortunately, most large sites have
pages that are constructed from templates. For example,
Amazon.com has page templates for search results, individ-
ual items, reviews, etc. To handle large web sites, an at-
tacker can create a model with states corresponding to page
templates rather than individual pages. A set of web pages
can be modeled as a single HMM state only if all the pages
produce similar probability distributions of observations. In
other words, pages p1 and p2 can be represented by a sin-
gle state s only if Pr[o|p1] ≈ Pr[o|p2] for all observations o.
Experimental results in Section 6 will show that this is the
case for pages generated from the same template.
HMM web site models can also handle pages that use
AJAX. If a page can make r diﬀerent requests to a web
server, then the HMM can represent the page with r + 1
states s0, . . . , sr. State s0 corresponds to the initial page
load, and states s1, . . . , sr correspond to each AJAX transac-
tion the page may execute. The attacker then treats AJAX
operations like any other page load: he collects traces of the
transactions, adds them to the classiﬁer described above,
and uses them to compute a probability distribution on ob-
servations. Other pages can only transition to s0, but the
transitions among states s0, . . . , sr, and transitions from the
sis to other pages, are determined by the structure of the
AJAX code. The probability of these transitions is deter-
mined by the code and by user behavior.
As a user traverses the pages of a web site, his browser col-
lects a cache of page elements it encounters. The attacker
must account for the browser cache when constructing an
HMM for the site. Cold pages are unlikely to have elements
cached in the browser. For example, a login page is typically
visited once at the beginning of a session, and hence is “cold”.
Warm pages may be loaded repeatedly or after the browser
has collected a large cache. A user’s Facebook proﬁle page
is likely to be “warm”. An attacker can include both types
of page in his model. For example, when modeling a social
networking site, an attacker could model the login page as
cold, and he could include both a cold and warm version of
a user’s main proﬁle page. The model would initially tran-
sition to the cold version of the proﬁle page, but transitions
from other states would go to the warm version.
Users may also move between pages using their browser’s
“Back” and “Forward” buttons and by typing a URL directly
into the location bar. The attacker can model page loads
via the location bar by simply adding edges between states
of the HMM. The probability assigned to these transitions
can be derived from user behavior. Unfortunately, it is not
possible to precisely model the Back and Forward buttons
using an HMM, since that would require augmenting the
HMM with a stack.
In most browsers, clicking the Back
button generates the same traﬃc trace as clicking a link
to the previous page, so the attacker can model the Back
button by adding reverse edges for every edge in the original
HMM. Note that, since clicking back necessarily is a “warm
cache” load of the previous page, the HMM back edge should
go to the HMM state representing a warm cache load of the
page, even if its corresponding forward edge is from a cold
cache state. The probability assigned to each back edge can
be derived from observing real users.
Note that this HMM-based attack assumes that users all
tend to navigate through a website in the same way.
If
this assumption is not valid, e.g. if users have wildly diﬀer-
ing habits when visiting the target site, then the attacker
has two options. First, if user’s tend to follow one of a
small set of diﬀerent patterns, then the attacker can build
an HMM for each pattern. If each user tends to have a to-
tally unique pattern, then the attacker can assign uniform
transition probabilities. The HMM will not use any order-
ing information, but it will still be able to make classiﬁcation
decisions based on the set of pages visited by the victim.
5. Congestion-Sensitive BUFLO
We now develop a traﬃc analysis defense with provable se-
curity properties. Our defense builds on the simple BUFLO
scheme deﬁned by Dyer, et al. [6], but solves several prac-
tical, performance, and security problems of that scheme.
We are currently working to implement and evaluate the
Congestion-Sensitive BUFLO algorithm, so we provide only
a rough analysis of its performance and security below.
A (d, ρ, τ ) BUFLO implementation transmits d-byte pack-
ets every ρ milliseconds, and continues this process for at
least τ milliseconds. If d bytes of application data are not
available when a packet is to be transmitted, then BUFLO
ﬁlls any extra space, possibly the entire packet, with junk
data that will be discarded at the other end. BUFLO as-
sumes the application can signal the beginning and end of
its communications. If, after τ milliseconds, the application
has not completed its transmissions, then BUFLO contin-
ues transmitting d-byte packets every ρ milliseconds until
the application signals that it is ﬁnished.
The basic BUFLO protocol has three shortcomings:
• High overhead. Depending on the conﬁguration pa-
rameters, Dyer, et al.
found that BUFLO has an
average bandwidth overhead between 93% and 419%.
Conﬁgurations with lower overhead oﬀered much less
protection against the attacks surveyed in their paper.
• Low practicality. BUFLO has no provisions for re-
sponding to congestion or ﬂow control signals.
• Unclear security. When the application takes longer
than τ milliseconds to ﬁnish, BUFLO reveals some in-
formation about the amount of data being communi-
cated. As a result, in some BUFLO conﬁgurations they
evaluated, an attacker could guess the victim’s target
web page (out of 128 pages) over 24% of the time.
The Congestion-Sensitive BUFLO algorithm, shown in
Figure 1, tunes its inter-packet transmission time, T , based
on the data source. The algorithm operates on an input
queue and an output queue. Data from the application
arrives and is placed into the input queue. Data in the
output queue is transmitted using a congestion- and ﬂow-
control aware protocol, such as TCP. Congestion-Sensitive
BUFLO monitors the output queue every T milliseconds
and enqueues new data only when the output queue con-
tains fewer than S cells. If the network becomes congested,
then the sender process will stop transmitting (and remov-
ing) elements from the output queue. When the output
queue grows to size S, then Congestion-Sensitive BUFLO
stops enqueueing more items until the transmission process
is able to successfully transmit more cells (and remove them
609procedure scbuflo(srcID)
T = lookup-speed(srcID)
ncells = 0
while sender-active() or !is-empty(input-queue) or
!is-power-of-two(ncells)
if size(output-queue) < S
if is-empty(input-queue)
enqueue(output-queue, junk-cell())
else
enqueue(output-queue, dequeue(input-queue))
ncells = ncells +1
sleep(T )
Figure 1: Pseudo-code for the basic Congestion-
Sensitive BUFLO algorithm. For simplicity, this
version assumes ﬁxed-sized cells.
from the output queue). This algorithm still hides all infor-
mation about the timing of incoming cells, though, since the
sequence of cells enqueued in the output queue is indepen-
dent of the arrival of cells in the input queue.
The parameter T governs the maximum transmission rate
of the Congestion-Sensitive BUFLO algorithm. The algo-
rithm will transmit at most 1000/T cells per second, but
may transmit less if the outbound connection has a lower
bottleneck bandwidth. Therefore, one may view Congestion-
Sensitive BUFLO as a link, with bandwidth 1000/T , in the
overall network path between the sender and receiver.
In
order to have good performance, Congestion-Sensitive BU-
FLO should not be the bottleneck link, so 1000/T should be
large, i.e. T should be small. On the other hand, in order
to avoid sending too many junk cells, T should be large.
We would ideally set T equal to the incoming packet inter-
arrival time. Thus, Congestion-Sensitive BUFLO would nei-
ther be the bottleneck link nor would it need to send a large
number of junk cells. The algorithm in Figure 1 selects T
using a database of data sources.
In the context of web
browsing, a source ID could be the URL of the page being
loaded or simply the domain name of the server providing
the page. The database mapping IDs to T values would be
updated periodically based on recent measurements.
Tuning T to the source of the incoming data obviously
may reveal some information about the data source to an
attacker observing the outbound data link. Therefore, we
must quantize the possible values of T . One simple choice
would be to limit T to values of the form 2i, where i ∈ Z.
The only other side information revealed to the attacker
is, B, the number of transmitted cells, which Congestion-
Sensitive BUFLO quantizes to a power of 2. Although this
may in the worst case double the amount of data transmit-
ted, it can on average have a much lower overhead. Let x be
the number of cells that would be transmitted if Congestion-
Sensitive BUFLO stopped transmitting as soon as the sender
became inactive and the input queue was empty. If, for real
data sources, x is uniformly distributed between 2(cid:98)log2(x)(cid:99)
and 2(cid:98)log2(x)(cid:99)+1, then the average overhead of padding the
total transmission to 2(cid:98)log2(x)(cid:99)+1 cells is(cid:82) 2
2
x dx < 1.39.
1
In summary, we can control the overhead of the Congestion-
Sensitive BUFLO algorithm by tuning T to the website be-
ing loaded, and padding all transmissions to a power of 2
cells will add an additional overhead of only 40%, which, as
our evaluation in Section 6 will show, is competitive with the
overheads of many of the schemes defeated in this paper.
We’ve presented Congestion-Sensitive BUFLO as a uni-
directional protocol. For web applications, each side will run
an instance of the Congestion-Sensitive BUFLO protocol.
Each instance will reveal two pieces of side-information to
an attacker: T and B. Thus, in total, the attacker is able to
observe only the O = (Tup, Tdown, Bup, Bdown), where each
of these values has been quantized to a power of two. This is
the provable security property provided by the Congestion-
Sensitive BUFLO algorithm.
This property does not directly imply anonymity. If a par-
ticular observation, O, is only generated by one web page in
the world, then an attacker observing O can conclude with
certainty that the victim is visiting that page. To evaluate
the security of Congestion-Sensitive BUFLO, we must sam-
ple the space of real web sites and conﬁrm that each possible
observation can be generated by many diﬀerent web sites.
This is ongoing work.
Finally, note that Congestion-Sensitive BUFLO does not
attempt to hide the fact that the victim is using Congestion-
Sensitive BUFLO and, in the context of censorship circum-
vention, simply using such a protocol may be suﬃcient to
attract the attention of censors. Note, however, that all traf-
ﬁc analysis defenses must encrypt payload data. Hence, in
the current internet where encryption is far from universal,
all traﬃc analysis defenses are easily recognizable, so this
problem is not unique to Congestion-Sensitive BUFLO.
6. EVALUATION
6.1 Web page classiﬁer
Our evaluation examines several factors that may aﬀect
the performance of our classiﬁer:
• How do traﬃc analysis defenses, such as HTTPOS,
randomized pipelining, Tor’s 512 byte cells, and traﬃc
morphing aﬀect the performance of our classiﬁer?
• How does this compare with other classiﬁers, such as
the Multinomial Naive Bayes classiﬁer of Herrmann, et
al. [10] or the SVM classiﬁer of Panchenko, et al. [17]?
• How is performance of our web page classiﬁer aﬀected
as the number of web pages goes up?
• How does the size of the training set aﬀect the perfor-
mance of our web page classiﬁer?
• Does the choice of the web pages in the classiﬁcation
set aﬀect the success rate of our web page classiﬁer?
• Does the state of the browser cache aﬀect the perfor-
mance of our classiﬁer?
We additionally investigate the overheads of the defense
schemes evaluated in this paper.
6.1.1 Experimental Setup
We collected traces using several diﬀerent computers with
slightly diﬀerent versions of Ubuntu Linux – ranging from