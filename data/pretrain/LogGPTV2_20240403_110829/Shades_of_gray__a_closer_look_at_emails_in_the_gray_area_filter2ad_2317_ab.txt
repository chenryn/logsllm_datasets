standard list of stop-words, and a number of custom scripts
to match the extracted n-grams and assign them to clusters.
379Table 1: General statistics
Mail servers
Active users
Total messages
13 White emails
10,025 Black emails
11,203,905 Gray emails
2,806,415 Challenges solved
5,066,141 Users whitelisted emails
3,331,349 Users viewed emails
166,279
42,384
104,273
Table 2: Cluster features
Group A
Distribution of network preﬁxes (/24)
Sender IPs
Sender names
Distribution of email sender names
Sender add.domain Distribution of email domain names
Sender add.preﬁx
Distribution of email preﬁxes
Group B
Percentage of rejected emails at MTA
Percentage of whitelisted emails
Rejections
White emails
Challenges bounced Percentage of bounced challenges
CAPTCHAs solved Percentage of solved challenges
Unsubscribe header Percentage of Unsubscribe headers
Group C
recipi-
Number of
ents per email
Recipient’s header
Countries
Normalized number of unique recipi-
ents per email
Location
of
To/Cc/Bcc/Mixed
Distribution of countries based on
originating IPs
recipient’s
email:
The process starts by searching for the longest n-gram (70)
and then decreasing the length until enough similar matches
(with a threshold of 30 emails per cluster) are found to cre-
ate a cluster. This algorithm is eﬃcient on long subjects
but problematic on short ones, thus limiting our analysis
to subjects containing at least 10 characters and 3 words.
In this phase we successfully clustered 50% of all emails in
12,250 clusters. Cluster sizes varied between 30 and 8,468
messages.
In this way, the similarity score is normalized to account for
the fact that, for example, a two-chars diﬀerence for short
strings is somehow equivalent to a six-chars diﬀerence for
longer ones.
Group B: Features of this group reﬂect the percentage
of messages in a cluster that have a certain feature value.
There are ﬁve features in this group: CAPTCHA solved, re-
jections, white emails, challenges bounced, and unsubscribe
header. The ﬁrst measures the percentage of challenges that
were solved by the senders. The challenges bounced are in-
stead emails not delivered because the recipient did not ex-
ist, or did not accept emails from the sender. Whenever an
email was sent to multiple recipients, we were also able to
compute the percentage of white emails (i.e., the percentage
of recipients that had already whitelisted the sender) and
the percentage of incoming email rejections (i.e., the per-
centage of recipients that were rejected by the Mail Transfer
Agent - normally because the corresponding addresses did
not exist on the server). Finally, the unsubscribe header fea-
ture evaluates the percentage of emails that contained the
unsubscribe header. The latter is generally used by commer-
cial messages and notiﬁcations providing the users an option
to unsubscribe from the list.
Group C: Features in this groups are computed in diﬀer-
ent ways. Recipients per email estimates the average num-
ber of recipients per email. The Recipient’s header feature
indicates the location of email recipient address in the email
headers: To, Cc, Bcc, or Mixed when multiple locations are
used in the same campaign. Finally, the countries feature
reﬂects the number of countries (based on the sender IP
geolocation) in the cluster.
3.3 Feature-based Classiﬁcation
Manual Labeling
To be able to diﬀerentiate and classify the identiﬁed clus-
ters, we extract a set of eleven features grouped in three
categories (see Table 2).
Group A: Features in this group reﬂect the similarity of a
certain feature inside a cluster. The values are expressed as
a range between 0 and 1, where 0 indicates a high distribu-
tion (low data similarity) and 1 indicates a low distribution
(high data similarity) in the cluster. The feature similarity
is deﬁned as:
a(C) = 1 − u/t
where u is the number of unique or similar feature val-
ues, and t is the number of total emails. This group con-
tains four features measuring the similarity of sender IP pre-
ﬁxes and email addresses, and the similarity of the sender
names. In particular, we split the email domain address into
two parts: the email preﬁx and the email suﬃx. The suf-
ﬁxes are grouped by removing numerical diﬀerences (e.g.,
between abc10.com and abc22.com). When similar suﬃxes
are found, they are merged until there are no similar values
left. Email preﬁxes are instead compared using a variation
of the Levenshtein distance algorithm in which a threshold
is computed based on the length of the email preﬁx itself.
Before performing our classiﬁcation, we need to build a train-
ing set. Obviously, the result of our manual labeling process
depends on the actual deﬁnition of spam that we adopt in
our experiments. By deﬁnition, spam is an unsolicited email
that is usually sent in bulk. However, there is no reliable way
to verify if a certain email is solicited, i.e., if the recipient
has subscribed to it or not. Moreover, the notion of spam
is somehow subjective and it may not be the same for all
the users. Some commercial campaigns are probably unso-
licited, and therefore could be considered as spam. However,
when such emails are sent by professional marketing compa-
nies according to the country regulations, it becomes unclear
how they should be treated by antispam ﬁlters. This is also
the main reason why they are considered as gray emails in
the ﬁrst place.
In this paper we take a conservative approach, and ﬂag as
spam only campaigns with potentially illegal content that
may involve malicious, fraudulent or illegal online activities.
This includes diﬀerent “business models”:
illegal product
sellers, malware spreading emails, personal data and cre-
dential thieves, or advanced fee fraud specialists. Finally,
we consider any email belonging to a commercial marketing
campaign as legitimate (in the sense that general antispam
380ﬁlters should not block them, unless they are speciﬁcally
instructed to do so by the user).
Although email labeling might be diﬃcult even with the
full email content, it can be facilitated by enriching emails
with aggregated campaign features. All the campaign fea-
tures are stored and viewed in an aggregated form, thus
never providing access to any distinct email information. A
particular case is represented by the email subject, a textual
information that would be diﬃcult to aggregate without tex-
tual data. As we group emails based on subject similarity,
we also keep an aggregated copy of the campaign subject.
During the sampling, we relied on the domain knowledge
of the analyst and on the additional information (e.g., aver-
age number of recipient per email, and number of originating
countries), that would not be available to a user reading only
one message at a time. Often a subject is enough to make
a labeling decision, but in cases when it is not, aggregated
header information is used by the analyst. For example, if
the message subject resembles a private communication but
the email has been sent in 50 identical copies to diﬀerent
recipient, this is more likely to be a scam than a real per-
sonal message. In the same way, a message promoting a new
product or services online, sent in thousands of copies from
over 30 diﬀerent countries and with multiple recipient per
email is probably an illegitimate campaign.
To build the training set, we randomly selected 2,000 cam-
paigns and performed a manual labeling of them. We labeled
1,581 (79%) as legitimate and 419 (21%) as spam campaigns.
This preliminary classiﬁcation conﬁrms that the majority of
spam was already ﬁltered out from the gray dataset.
Classiﬁcation
Using the eleven features presented above, we trained a bi-
nary classiﬁer. To select a classiﬁer we referred to the results
presented by Kiran et al. [14], in which the authors demon-
strated that, on spam datasets, ensemble classiﬁers perform
better than single classiﬁers. Based on this conclusion, for
our classiﬁcation task we decided to use a supervised Ran-
dom Forest ensemble classiﬁer.
We ﬁrst performed a cross validation test in which we
randomly split the sampled data into two groups including
respectively 70% and 30% of the data. We then trained
the Random Forest classiﬁer (conﬁgured with 500 trees and
three random variables per split) on the ﬁrst group, and
we tested the extracted model on the second one. For each
cluster, the algorithm returned a score ranging between -
1 (for spam) and 1 (for legitimate). A score close to zero
indicates that the classiﬁer was uncertain about the sample.
Since our set includes classes of very diﬀerent sizes, we
use the Matthews Correlation Coeﬃcient (MMC) to mea-
sure the classiﬁcation quality. Our model achieved MCC of
0.75, where the value is between [-1,..1], and 1 represents a
perfect prediction. The model produced 0.9% false positives
(i.e., legitimate campaigns being misclassiﬁed as spam) and
10% false negatives (i.e., spam being misclassiﬁed as legit-
imate). These rates suggest that the set of attributes we
identiﬁed are eﬀective in separating the two types of cam-
paigns. We also noticed that while our classiﬁer identiﬁed
legitimate campaigns well, it had a higher probability of mis-
classifying spam campaigns. A further interpretation of this
phenomenon is described in section 5.
Finally, we applied the model extracted from our training
set to predict the classiﬁcation of the remaining unlabeled
campaigns. Results are presented in Table 3.
Table 3: Campaign classiﬁcation results
Campaign
type
Legitimate
Spam
Total
Manual
sampling
1,581
419
2,000
% Unlabeled
%
79%
21%
8,398
1,852
10,250
81.9%
18.1%
Table 4: Attribute values per campaign category
Attribute
Legitimate
Spam
Gray
Min / Mean / Max
Countries
IPs
Sender email
domain
Sender email
preﬁx
Senders
Unsubscribe
header
Bounced
CAPTCHAs
White emails
Rejections
Rec.per email
Recipient
header
1 - 1.2 - 6
0.13 - 0.9 - 1
0.2 - 0.98 - 1
7 - 29 - 123
0 - 0.06 - 0.82
0 - 0.3 - 1
1 - 5 - 80
0 - 0.7 - 1
0 - 0.85 - 1
0.03 - 0.98 - 1
0 - 0.09 - 1
0 - 0.81 - 1
0 - 0.98 - 1
0 - 0.5 - 1
0 - 0.3 - 1
0 - 0 - 0.3
0 - 0.8 - 1
0 - 0.3 - 1
0 - 0 - 1
0 - 0 - 1
0
0 - 0 - 0.4
1 - 1 - 1.1
0 - 0.1 - 1
0 - 0 - 1
0
0 - 0.23 - 1
1 - 3 - 16
0 - 0.1 - 0.9
0 - 0.1 - 1
0.001
0 - 0.1 - 0.7
1 - 1.1 - 8
0.76 - 0.04 - 0.2
0.3 - 0.1 - 0.6
0.4 - 0.33 - 0.3
To, Bcc, Mixed shares
3.4 Graph-based Reﬁnement
Although we achieved a relatively high accuracy using our
classiﬁer, we still found that for some campaigns our al-
gorithm gave uncertain results. Luckily, the vast majority
of the campaigns are located at the extremes of the classi-
ﬁer scores, either close to 1 (legitimate), or to -1 (spam).
Campaigns become much more scarce in the range between
[-0.8..0.8]. This gray area inside the gray area represents
cases for which our technique was unable to automatically
assign a deﬁnitive category.
Using these two thresholds, we can reﬁne our classiﬁcation
and split the data into three classes:
legitimate (77% of
the total campaigns), spam (16%), and gray (6.4%). The
minimum, average, and maximum values for each attribute
in the three classes are summarized in Table 4. Since most
of the false positives and false negatives are located in the
gray area, we focused on improving the classiﬁcation of those
messages by using a graph-based technique.
In particular, we built a graph in which nodes represent
campaigns and edges model the fact that two campaigns
share a combination of sender IP address and email domain
name. These links created networks of campaigns sent from
the same mailing infrastructure. To avoid false connections
that might appear between campaigns when they use web-
mail providers (spoofed or not), we removed those links from
the graph.
The resulting graph contained 9,891 connected campaigns
and 608 isolated subgraphs. By visually looking at the sub-
graphs, we noticed that the majority consisted of a pre-
dominant class (either spam or legitimate nodes) sometimes
intermixed with gray nodes (see an example in Figure 1).
This seems to suggest that gray campaigns also belong to
the same class as the other nodes in the same group, since
they are sent using the same infrastructure.
Additionally, our graph contains a Giant Component – a
graph linking together 52% of all the campaigns – for which
it is impossible to decide which class it belongs to. There-
381ticular the percentage of already whitelisted emails in the
cluster. The most important ones are the distributions of
countries and IP addresses, followed by the average number
of recipients, and the sender email address similarity. The
latter proved to be useful because spammers often change
sender emails, while legitimate campaigns use a single or
several repetitive patterns.
In particular, we found the number of originating coun-
tries to be the most indicative parameter, whereas previous
research often relied on the IP address distribution (e.g. [24]).
4.1 The Role of IPs and Geolocation
IP address variation is often regarded as a strong indica-
tor of botnet activity and often used as a reliable metric to
detect spam. However, it is unclear what should be adopted
as a threshold for this metric, how many diﬀerent IPs should
alert us of a distributed malicious activity, or how accurately
we can classify email campaigns simply by looking at their
IP address distribution.
In a previous study of spam campaigns, Qian et al. [24]
used a threshold of 10 IPs per campaign to separate spam
campaigns from legitimate ones. To evaluate this threshold,
we applied it on our gray dataset as shown in Figure 2 (a).
The graph plots the distribution of unique IP preﬁxes for
both spam and legitimate campaigns. Around 90% of the
legitimate campaigns are indeed below the 10 IP threshold,
while 90% of the spam is above - resulting in a global error
rate of 9.2% (to be precise, our measure is based on /24
subnetworks and not on single IP addresses, and therefore
the real error rate is much higher than 9.2%). In comparison,
this error is 5 times higher than the one of our classiﬁer.
By looking at Figure 2 (a), we notice that above 50 IP
preﬁxes there are few legitimate campaigns left and 99.8%
of legitimate campaigns are below this threshold. However,
half of the spam campaigns are located above the threshold
and another half in between the two thresholds (10-50). This
suggests that there is not a single value that separates the
two classes with an acceptable error rate.
When we look at IP country distribution, the results im-
prove considerably as some legitimate campaigns have many
IP preﬁxes, but originate from few countries. This could be
explained by one commercial campaign being distributed by
several marketing companies in diﬀerent locations. In con-
trast, the vast majority of spam campaigns originate from
multiple IP preﬁxes and multiple countries. In fact, by using
a six-countries threshold (the one chosen by our classiﬁer)
we misclassify only 0.4% of legitimate and 12% of spam cam-
paigns - resulting in a total error rate of 2.8%. Figure 2 (b)
shows the classiﬁcation error.