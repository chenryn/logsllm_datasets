time of our proposed algorithm in terms of the number of
quanti(cid:12)ers n. This is of practical relevance since many use-
ful policies have few quanti(cid:12)ers. For any history h, Ph refers
to the ((cid:12)nite) set of distinct parameters that have occurred
in h. The requirement below that all variables be of same
type is to simplify presentation, and not essential.
Theorem 5.1 (Complexity Bound). Let formula   (cid:17)
Q1x1Q2x2 (cid:1) (cid:1) (cid:1) Qnxn: 0 where the Qi are quanti(cid:12)ers, xi vari-
ables all of type P , and  0 is a quanti(cid:12)er-free formula from
the quanti(cid:12)ed language with fv ( 0) (cid:18) fx1; : : : ; xng. Let
(cid:3) and jPhj be the number of parameter occurrences
h 2 C0
in history h. The constraint-based algorithm for dynamic
model checking has the following complexity.
(cid:26)ES
(cid:15) DMC :check() is O(1).
(cid:15) DMC :new() is O(j j (cid:1) (jPhj + 1)n).
(cid:15) DMC :update(e; p; i) when p 2 Ph and K is the cur-
rent number of active con(cid:12)gurations in h, is
O((K (cid:0) i + 1) (cid:1) j j (cid:1) (jPhj + 1)n)
(cid:15) DMC :update(e; p; i) when p 62 Ph and K is the cur-
rent number of active con(cid:12)gurations in h, is
O((K (cid:0) i + 1) (cid:1) j j (cid:1) (jPhj + 2)n)
Furthermore,
if the con(cid:12)gurations of ES are represented
with event-set bit-vectors, the space complexity of DS 0 is
O(K (cid:1) (jEj + j j (cid:1) (jPhj + 1)n)).
6. CONCLUSION
Our approach to reputation-systems di(cid:11)ers from most ex-
isting systems in that reputation information has an exact
semantics, and is represented in a very concrete form. In our
view, the novelty of our approach is that our instance sys-
tems can veri(cid:12)ably provide a form of exact security guaran-
tees, albeit non-standard, that relate a present authorization
to a precise property of past behaviour. We have presented
a declarative language for specifying such security proper-
ties, and the applications of our technique extends beyond
the traditional domain of reputations systems in that we
can explain, formally, several existing approaches to \his-
tory based" access control.
We have given two e(cid:14)cient algorithms for the dynamic
model-checking problem, supporting the feasibility of run-
ning implementations of our framework on devices of lim-
ited computational and storage capacity; a useful property
in global computing environments. In particular, it is note-
worthy that principals need not store their entire interaction
histories, but only the so-called active sessions.
The notion of time in our temporal logic is based on when
sessions are started. More precisely, our models are local
interaction histories, h = x1x2 (cid:1) (cid:1) (cid:1) xn where xi 2 CES, and
the order of the sessions re(cid:13)ects the order in which the cor-
responding interaction-protocols are initiated, i.e. xi refers
to the observed events in the ith-initiated session. Di(cid:11)erent
notions of time could just as well be considered, e.g. if xi pre-
cedes xj in sequence h, then it means that xj was updated
more recently than xi (our algorithms can be straightfor-
wardly be adapted to this notion of time).
Related Work. Many reputation-based systems have
been proposed in the literature (J(cid:28)sang et al. [15] provide
many references), so we choose to mention only a few typical
examples and closely related systems. Kamvar et al. present
EigenTrust [16], Shmatikov and Talcott propose a license-
based framework [27], and the EU project ‘SECURE’ [4, 5]
(which also uses event structures for modelling observations)
can be viewed as a reputation-based system, to name a no-
table few.
The framework of Shmatikov and Talcott is the most
closely related in that they deploy also a very concrete repre-
sentation of behavioural information (\evidence" [27]). This
representation is not as sophisticated as in the event-structure
framework (e.g., as histories are sets of time-stamped events
there is no concept of a session, i.e., a logically connected
set of events), and their notion of reputation is based on an
entity’s past ability to ful(cid:12)ll so-called licenses. A license is
a contract between an issuer and a licensee. Licenses are
more general than interaction policies since they are mu-
tual contracts between issuer and licensee, which may permit
the licensee to perform certain actions, but may also require
that certain actions are performed. The framework does not
have a domain-speci(cid:12)c language for specifying licenses (i.e.
for specifying license-methods permits and violated), and
the use of reputation information is not part of their for-
mal framework (i.e. it is up to each application programmer
to write method useOk for protecting a resource). We do
not see our framework as competing, but, rather, compatible
with theirs. We imagine using a policy language, like ours,
as a domain-speci(cid:12)c language for specifying licenses as well
as use-policies. We believe that because of the simplicity
of our declarative policy language and its formal semantics,
this would facilitate veri(cid:12)cation and other reasoning about
instances of their framework.
Pucella and Weissman use a variant of pure-future linear
temporal logic for reasoning about licenses [23]. They are
not interested in the speci(cid:12)c details of licenses, but merely
require that licenses can be given a trace-based semantics;
in particular, their logic is illustrated for licenses that are
regular languages. As our basic policies can be seen (seman-
tically) as regular languages (Theorem 4.2), and policies can
be seen as a type of license, one could imagine using their
logic to reason about our policies.
Roger and Goubault-Larreq [25] have used linear tempo-
ral logic and associated model-checking algorithms for log
auditing. The work is related although their application is
quite di(cid:11)erent. While their logic is (cid:12)rst-order in the sense of
having variables, they have no explicit quanti(cid:12)cation. Our
quanti(cid:12)ed language di(cid:11)ers (besides being pure-past instead
of pure-future) in that we allow explicit quanti(cid:12)cation (over
di(cid:11)erent parameter types) 8x : Pi:  and 9x : Pi: , while
their language is implicitly universally quanti(cid:12)ed.
The notion of security automata, introduced by Schnei-
der [26], is related to our policy language. A security au-
tomaton runs in parallel with a program, monitoring its ex-
ecution with respect to a security policy. If the automata
detects that the program is about to violate the policy, it
terminates the program. A policy is given in terms of an
automata, and a (non-declarative) domain-speci(cid:12)c language
for de(cid:12)ning security automata (SAL) is supported but has
been found awkward for policy speci(cid:12)cation [10]. One can
view the (cid:12)nite automaton in our automata-based algorithm
as a kind of security automaton, declaratively speci(cid:12)ed by a
temporal-logic formula.
Security automata are also related, in a technical sense
[11], to the notion of history-based access control (HBAC).
HBAC has been the subject of a considerable amount of
research (e.g., papers [1, 9, 11, 12, 26, 29]). There is a distinc-
tion between dynamic HBAC in which programs are mon-
itored as they execute, and terminated if about to violate
policy [9, 11, 12, 26]; and static HBAC in which some pre-
liminary static analysis of the program (written in a pre-
determined language) extracts a safe approximation of the
programs’ runtime behaviour, and then (statically) checks
that this approximation will always conform to policy (us-
ing, e.g., type systems or model checking) [1,29]. Clearly, our
approach has applications to dynamic HBAC. It is notewor-
thy to mention that many ad-hoc optimizations in dynamic
HBAC (e.g., history summaries relative to a policy in the
system of Edjlali [9]) are captured in a general and optimal
way by using the automata-based algorithm, and exploiting
the (cid:12)nite-automata minimization-theorem. Thus in the au-
tomata based algorithm, one gets \for free," optimizations
that would otherwise have to be discovered manually.
7. REFERENCES
[1] M. Bartoletti, P. Degano, and G. L. Ferrari. History-based
access control with local policies. In Foundations of Software
Science and Computational Structures: 8th International
Conference, FOSSACS 2005. Proceedings, pages 316{332.
Springer, 2005.
[2] M. Blaze, J. Feigenbaum, J. Ioannidis, and A. D. Keromytis.
The role of trust management in distributed systems security.
In J. Vitek and C. D. Jensen, editors, Secure Internet
Programming: Security Issues for Mobile and Distributed
Objects, volume 1603 of Lecture Notes in Computer Science,
pages 185{210. Springer, 1999.
[3] D. F. Brewer and M. J. Nash. The chinese wall security policy.
In Proceedings from the 1989 IEEE Symposium on Security
and Privacy, pages 206{214. IEEE Computer Society Press,
1989.
[4] V. Cahill and E. Gray et al. Using trust for secure
collaboration in uncertain environments. IEEE Pervasive
Computing, 2(3):52{61, 2003.
[5] V. Cahill and J.-M. Seigneur. The SECURE website.
http://secure.dsg.cs.tcd.ie, 2004.
[6] M. Carbone, M. Nielsen, and V. Sassone. A formal model for
trust in dynamic networks. In Proceedings from Software
Engineering and Formal Methods (SEFM’03). IEEE
Computer Society Press, 2003.
[7] M. Carbone, M. Nielsen, and V. Sassone. A calculus for trust
management. In Proceedings from Foundations of Software
Technology and Theoretical Computer Science: 24th
International Conference (FSTTCS’04), pages 161{173.
Springer, December 2004.
[8] eBay Inc. The eBay website. http://www.ebay.com.
[9] G. Edjlali, A. Acharya, and V. Chaudhary. History-based
access control for mobile code. In Proceedings from the 5th
ACM Conference on Computer and Communications
Security (CCS’98), pages 38{48. ACM Press, 1998.
[10] (cid:19)U. Erlingsson and F. B. Schneider. SASI enforcement of
security policies: A retrospective. In Proceedings from the
2000 DARPA Information Survivability Conference and
Exposition, pages 1287{1295. IEEE Computer Society Press,
2000.
[11] P. W. L. Fong. Access control by tracking shallow execution
history. In Proceedings from the 2004 IEEE Symposium on
Security and Privacy, pages 43{55. IEEE Computer Society
Press, 2004.
[12] C. Fournet and A. D. Gordon. Stack inspection: Theory and
variants. ACM Transactions on Programming Languages and
Systems, 25(3):360{399, 2003.
[13] K. Havelund and G. Ro(cid:24)su. Synthesizing monitors for safety
properties. In Tools and Algorithms for the Construction and
Analysis of Systems : 8th International Conference
(TACAS’02), volume 2280 of Lecture Notes in Computer
Science, pages 342{356. Springer-Verlag, 2002.
[14] A. J(cid:28)sang and R. Ismail. The beta reputation system. In
Proceedings from the 15th Bled Conference on Electronic
Commerce, Bled, 2002.
[15] A. J(cid:28)sang, R. Ismail, and C. Boyd. A survey of trust and
reputation for online service provision. Decision Support
Systems, (to appear, preprint available online:
http://security.dstc.edu.au/staff/ajosang), 2004.
[16] S. D. Kamvar, M. T. Schlosser, and H. Garcia-Molina. The
eigentrust algorithm for reputation management in P2P
networks. In Proceedings from the twelfth international
conference on World Wide Web, Budapest, Hungary, pages
640{651. ACM Press, 2003.
[17] K. Krukow, M. Nielsen, and V. Sassone. A framework for
concrete reputation-systems. Technical Report RS-05-23,
BRICS, University of Aarhus, July 2005.
[18] K. Krukow and A. Twigg. Distributed approximation of
(cid:12)xed-points in trust structures. In Proceedings from the 25th
IEEE International Conference on Distributed Computing
Systems (ICDCS’05), pages 805{814. IEEE, 2005.
[19] F. Laroussinie, N. Markey, and P. Schnoebelen. Temporal logic
with forgettable past. In Proceedings from the 17th IEEE
Symposium on Logic in Computer Science (LICS’02), pages
383{392. IEEE Computer Society Press, 2002.
[20] M. Nielsen and K. Krukow. Towards a formal notion of trust.
In Proceedings from the 5th ACM SIGPLAN International
Conference on Principles and Practice of Declarative
Programming (PPDP’03), pages 4{7. ACM Press, 2003.
[21] M. Nielsen and K. Krukow. On the formal modelling of trust in
reputation-based systems. In J. Karhum(cid:127)aki, H. Maurer,
G. Paun, and G. Rozenberg, editors, Theory Is Forever:
Essays Dedicated to Arto Salomaa, volume 3113 of Lecture
Notes in Computer Science, pages 192{204. Springer Verlag,
2004.
[22] A. Pnueli. The temporal logic of programs. In Proceedings
from the 18th Annual Symposium on Foundations of
Computer Science (FOCS’77), pages 46{57. IEEE, New York,
1977.
[23] R. Pucella and V. Weissman. A logic for reasoning about
digital rights. In Proceedings from 15th IEEE Computer
Security Foundations Workshop (CSFW’02), pages 282{294.
IEEE Computer Society Press, 2002.
[24] P. Resnick, R. Zeckhauser, E. Friedman, and K. Kuwabara.
Reputation systems. Communications of the ACM,
43(12):45{48, Dec. 2000.
[25] M. Roger and J. Goubault-Larrecq. Log auditing through
model-checking. In Proceedings from the 14th IEEE
Computer Security Foundations Workshop (CSFW’01),
pages 220{236. IEEE Computer Society Press, 2001.
[26] F. B. Schneider. Enforceable security policies. Journal of the
ACM, 3(1):30{50, 2000.
[27] V. Shmatikov and C. Talcott. Reputation-based trust
management. Journal of Computer Security, 13(1):167{190,
2005.
[28] A. P. Sistla and E. M. Clarke. The complexity of propositional
linear temporal logics. Journal of the ACM, 32(3):733{749,
1985.
[29] C. Skalka and S. Smith. History e(cid:11)ects and veri(cid:12)cation. In
Programming Languages and Systems: Second Asian
Symposium, APLAS 2004, Taipei, Taiwan, November 4-6,
2004. Proceedings, pages 107{128. Springer, 2005.
[30] G. Winskel and M. Nielsen. Models for concurrency. In
S. Abramsky, D. M. Gabbay, and T. S. E. Maibaum, editors,
Handbook of Logic in Computer Science, volume 4, pages
1{148. Oxford University Press, 1995.