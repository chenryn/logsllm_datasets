vs. GraphSC. Single iteration of Matrix Factorization on real-
world dataset, MovieLens with 6K users ranked 4K movies
with 1M ratings
per movie, to achieve (0.3,2−40)-Differential Privacy.
Figure 19: Effect of differential privacy parameters, ε and δ
on run time in Matrix Factorization with graph size 1M edges
Table 6: Number of dummy elements required for each type
depending on different privacy parameters
δ = 2−40
δ = 2−16
ε=0.05
707
374
ε=0.3
118
62
ε=1
35
19
ε=5
7
4
LAN vs. WAN runtime Figure 20 shows a dramatic slow-
down in the run time when we deployed the computation
servers across data centers, rather than having them in the
same geographic region. Nevertheless, even in the WAN set-
ting, we still greatly out-perform the LAN implementations
of GraphSC and OblivGraph.
6 Conclusion
In this work, we combine the best results of secure multi-party
computation with low-communication cost, and a security re-
laxation that allows the computation servers to learn some
differentially private leakage about user inputs, and construct
a new framework which can compute the histogram problem
on 300 million users in almost 4 mins and the Matrix Fac-
torization problem on 20 million records in about 6 mins. It
reduces the overall runtime of the state of the art solution by
320X, and its communication cost by 200X. Furthermore, in
contrast to prior work, our system is secure against a malicious
adversary that corrupts one of the computing servers.
Figure 20: Run time of Matrix Factorization on graphs size
1M, showing the effect of network delay in LAN vs WAN.
Acknowledgments
This material is based upon work supported by the Defense
Advanced Research Projects Agency (DARPA) and Space and
Naval Warfare Systems Center, Paciﬁc (SSC Paciﬁc) under
Contract No. N66001-15-C-4070. It is also supported by NSF
award #1564088.
References
[1] The 2020 united states census. https://2020census.gov.
[2] Toshinori Araki, Assi Barak, Jun Furukawa, Tamar
Lichter, Yehuda Lindell, Ariel Nof, Kazuma Ohara, Adi
Watzman, and Or Weinstein. Optimized honest-majority
MPC for malicious adversaries - breaking the 1 billion-
gate per second barrier. pages 843–862, 2017.
[3] T-H. Hubert Chan, Kai-Min Chung, Bruce M. Maggs,
and Elaine Shi. Foundations of differentially oblivi-
ous algorithms. In Symposium on Discrete Algorithms,
SODA ’19, pages 2448–2467, 2019.
[4] Koji Chida, Daniel Genkin, Koki Hamada, Dai Ikarashi,
Ryo Kikuchi, Yehuda Lindell, and Ariel Nof. Fast large-
scale honest-majority MPC for malicious adversaries.
pages 34–64, 2018.
[5] Ronald Cramer, Ivan Damgård, Daniel Escudero, Peter
Scholl, and Chaoping Xing. SPD Z2k: Efﬁcient MPC
mod 2k for dishonest majority. pages 769–798, 2018.
[6] Jeffrey Dean and Sanjay Ghemawat. Mapreduce: Sim-
pliﬁed data processing on large clusters. In Proceedings
of the 6th Conference on Symposium on Opearting Sys-
tems Design & Implementation - Volume 6, OSDI’04,
pages 10–10, Berkeley, CA, USA, 2004. USENIX As-
sociation.
2502    29th USENIX Security Symposium
USENIX Association
12481632Number of Processors050100150200250Execution Time (seconds)=0.3,  =240=0.3,  =216=1,     =240=1,     =216202122232425Number of Processors102103Execution Time (seconds)Within DataCenterAcross DataCenters[7] Jun Furukawa, Yehuda Lindell, Ariel Nof, and Or Wein-
stein. High-throughput secure three-party computation
for malicious adversaries and an honest majority. pages
225–255, 2017.
[8] Oded Goldreich. Foundations of Cryptography: Volume
2, Basic Applications, volume 2. Cambridge University
Press, 2009.
[9] Joseph E. Gonzalez, Yucheng Low, Haijie Gu, Danny
Bickson, and Carlos Guestrin. Powergraph: Distributed
graph-parallel computation on natural graphs. In Pre-
sented as part of the 10th USENIX Symposium on Oper-
ating Systems Design and Implementation (OSDI 12),
pages 17–30, Hollywood, CA, 2012. USENIX.
[10] S. Dov Gordon, Samuel Ranellucci, and Xiao Wang. Se-
cure computation with low communication from cross-
checking. pages 59–85, 2018.
[11] F. Maxwell Harper and Joseph A. Konstan. The movie-
lens datasets: History and context. ACM Trans. Interact.
Intell. Syst., 5(4):19:1–19:19, December 2015.
[12] Xi He, Ashwin Machanavajjhala, Cheryl J. Flynn, and
Divesh Srivastava. Composing differential privacy and
secure computation: A case study on scaling private
record linkage. pages 1389–1406, 2017.
[13] Yucheng Low, Joseph E. Gonzalez, Aapo Kyrola, Danny
Bickson, Carlos Guestrin, and Joseph M. Hellerstein.
Graphlab: A new framework for parallel machine learn-
ing. CoRR, abs/1408.2041, 2014.
[14] Grzegorz Malewicz, Matthew H. Austern, Aart J.C Bik,
James C. Dehnert, Ilan Horn, Naty Leiser, and Grzegorz
Czajkowski. Pregel: A system for large-scale graph
processing. In Proceedings of the 2010 ACM SIGMOD
International Conference on Management of Data, SIG-
MOD ’10, pages 135–146, New York, NY, USA, 2010.
ACM.
[15] Sahar Mazloom and S. Dov Gordon. Differentially pri-
vate access patterns in secure computation. Cryptol-
ogy ePrint Archive, Report 2017/1016, 2017. http:
//eprint.iacr.org/2017/1016.
[16] Sahar Mazloom and S. Dov Gordon. Secure computa-
tion with differentially private access patterns. pages
490–507, 2018.
[17] Payman Mohassel and Peter Rindal. ABY3: A mixed
protocol framework for machine learning. pages 35–52,
2018.
[18] Kartik Nayak, Xiao Shaun Wang, Stratis Ioannidis, Udi
Weinsberg, Nina Taft, and Elaine Shi. GraphSC: Parallel
secure computation made easy. pages 377–394, 2015.
[19] Valeria Nikolaenko, Stratis Ioannidis, Udi Weinsberg,
Marc Joye, Nina Taft, and Dan Boneh.
Privacy-
preserving matrix factorization. pages 801–812, 2013.
[20] Sameer Wagh, Paul Cuff, and Prateek Mittal. Differen-
tially private oblivious RAM. PoPETs, 2018(4):64–84,
2018.
[21] Abraham Waksman. A permutation network. Journal
of the ACM (JACM), 15(1):159–163, 1968.
[22] Xiao Wang, Samuel Ranellucci, and Jonathan Katz. Au-
thenticated garbling and efﬁcient maliciously secure
two-party computation. pages 21–37, 2017.
A Assumed Protocols
We assume that we have access to the following oracles: Fcoin
(Figure 21), Frerand (Figure 22), FcheckZero (Figure 23), FTriple
(Figure 25).
FUNCTIONALITY Fcoin - Generating Random
Value
The ideal functionality Fcoin chooses a random r ∈ Z2k+s
then gives r to all the parties.
Figure 21: Sample a random ring element
FUNCTIONALITY Frerand - Rerandomize additive
shares
Input Two parties P1, P2 hold shares of [X].
Functionality
• The ideal functionality waits for shares [X] from the
parties, reconstruct X.
• The ideal functionality samples random values ∆,
sends [X (1)]1 = ∆ to P1 and [X (1)]2 = X − ∆ to P2.
Output The parties receive [X (1)]
Figure 22: Rerandomize additive shares
FUNCTIONALITY FcheckZero
Input Two parties (P1, P2 or P3, P4) hold shares of [Z].
Functionality
• The ideal functionality waits for shares [Z] from the
parties, reconstruct Z.
Output If zi = 0 mod 2k+s ∀i ∈ {1, ...,n}, output True.
Else, send False to all parties.
Figure 23: Ideal Functionality to verify if [Z] is a share of 0.
USENIX Association
29th USENIX Security Symposium    2503
FTriple
FMult Ideal Functionality to perform multiplication
up to an additive attack
Inputs: All parties have input (A,B,c), where A,B are
input wires, and c is output wire. A = {a1, ...,an}, B =
{b1, ...,bn}, c = ∑n
i=1 aibi.
P1 and P2 both provide λ(cid:48)
λA,λB.
Functionality:
B. P3 and P4 both provide
A,λ(cid:48)
• If either pair sends mismatched messages, send
abort to all parties.
• Sample λc uniformly at random.
• Compute λc + ∑n
Output:
P1 and P2 receive [∑n
P3 and P4 receive [∑n
i=1 λaiλbi and (cid:98)λc/2d(cid:99).
i=1 λaiλbi + λc], and [(cid:98)λc/2d(cid:99)].
i=1 λ(cid:48)
c/2d(cid:99)].
c], and [(cid:98)λ(cid:48)
bi + λ(cid:48)
aiλ(cid:48)
Figure 24: Triple Generation
ΠTriple
Inputs: All parties have input (A,B,c), where A,B are
input wires, and c is output wire. A = {a1, ...,an}, B =
{b1, ...,bn}, c = ∑n
P3 and P4 both provide λA,λB.
Protocol:
i=1 aibi.
• P1, P3, and P4 query Fcoin to sample shares [λc +
i=1 λaiλbi ]1 and shares [(cid:98)λc/2d(cid:99)]1
∑n
• P2, P3, and P4 query Fcoin to sample shares [λc +
• P3 and P4 reconstruct λc + ∑n
∑n
i=1 λaiλbi ]2
i=1 λaiλbi and com-
pute [(cid:98)λc/2d(cid:99)]2. P3 sends [(cid:98)λc/2d(cid:99)]2 to P2, while
P4 sends its hash to P2. P2 veriﬁes shares sent from
P3 and P4.
• P3, P1, and P2 query Fcoin to sample shares [λ(cid:48)
c +
∑n
i=1 λa(cid:48)
iλb(cid:48)
i ]1 and shares [(cid:98)λ(cid:48)
c/2d(cid:99)]1
• P4, P1, and P2 query Fcoin to sample shares [λ(cid:48)
c +
∑n
i=1 λa(cid:48)
iλb(cid:48)
i ]2
• P1 and P2 reconstruct λ(cid:48)
i and com-
pute [(cid:98)λ(cid:48)
c/2d(cid:99)]2. P1 sends [(cid:98)λc/2d(cid:99)]2 to P4, while
P2 sends its hash to P4. P4 veriﬁes shares sent from
P1 and P2.
c + ∑n
i=1 λa(cid:48)
iλb(cid:48)
Output:
P1 and P2 receive [∑n
P3 and P4 receive [∑n
i=1 λaiλbi + λc], and [(cid:98)λc/2d(cid:99)].
c/2d(cid:99)].
i=1 λa(cid:48)
c], and [(cid:98)λ(cid:48)
i + λ(cid:48)
iλb(cid:48)
Inputs: P1 and P2 have inputs α. P3 and P4 have inputs
[X] (X = {x1, ...,xn}).
Functionality:
• Verify that P1 and P2 send the same α. If not, send
abort to all parties.
• If the corrupted party is P3 or P4: wait for the attack
terms U = {u1, ...,un} from that party, compute Z =
α(X +U) mod 2k+s.
• Send shares [α] and [Z] to P3 and P4.
Output: P3 and P4 receive [α] and [Z]. P1 and P2 receive
nothing.
Figure 26: Multiplication up to an Attack
ΠMult Real-world protocol to perform multiplication
up to an additive Attack
Inputs: P1 and P2 have inputs α. P3 and P4 have inputs
[X]. F is a PRF.
Protocol:
1. P1 and P2 make two calls to Fcoin to sample two
random numbers λα,r. They both send r to P3 and
λα − r to P4. Then they compute (α − λα). They
both send (α− λα) to P3 and P4. P3 and P4 verify
that they receive the same values, otherwise, they
abort.
2. P1 and P2 agree on a random key k1,k2. They both
send k1 to P3, then k2 to P4. P3 and P4 verify that
they receive the same values, otherwise, they abort.
3. P1, P2, and P3 compute [λxi ]1 = Fk1 (i), [λzi ]1 =
Fk1 (i + n)
4. P1, P2, and P4 compute [λxi ]2 = Fk2 (i).
5. P1 and P2 reconstruct λxi and compute [λzi ]2 =
λαλxi − [λzi ]1. P1 sends [λzi ]2 to P4 while P2 send
hash([λzi ]2) to P4. P4 veriﬁes that they receive the
correct messages from P1 and P2. If not, he calls
abort.
6. P3 and P4 compute [xi − λxi ] ← [xi] − [λxi ]. They
open (xi − λxi ).
7. P3 and P4 compute [zi] ← (α − λα)(xi − λxi ) +
[λα](xi − λxi ) + [λxi ](α− λα) + [λzi ]
Output: P3 and P4 output [α] and [Z] = {[z1], ..., [zn]}. P1
and P2 output nothing.
Figure 25: Triple Generation
Figure 27: Multiplication up to an Attack
2504    29th USENIX Security Symposium
USENIX Association