## 作者群信息介绍 {#142.html#-}这篇论文的所有作者都来自谷歌，我们这里对其中的主要作者做一个简单介绍。文章的第一作者亚力克斯·布伦特（Alex Beutel）是谷歌的资深科学家，于 2016年加入谷歌。布伦特毕业于卡内基梅隆大学，获得计算机科学博士学位，师从机器学习的权威亚力克斯·斯莫拉（AlexSmola）。最后一位作者艾德·池（Ed H. Chi）是谷歌的主任科学家，他拥有 39项专利，已经发表了 110 多篇论文。在加入谷歌之前，池是帕罗奥图（PaloAlto）研究中心的主任研究员。池毕业于明尼苏达大学，获得计算机科学博士学位。
## 论文的主要贡献 {#142.html#-}我们首先来看这篇文章的主要贡献，梳理文章主要解决了一个什么场景下的问题。推荐系统经常需要对当下的场景进行建模，有时候，这些场景被称作"**上下文**"（Context）。在过去比较传统的方法中，已经有不少方法是探讨如何利用上下文信息进行推荐的，比如使用"张量"（Tensor）的形式进行建模；还有一些方法是利用对时间特性的把握，从而对上下文信息进行处理。近些年，随着深度学习的发展，越来越多的深度学习模型被应用到推荐系统领域中，但还没有直接探究如何在深度学习模型中使用上下文。这篇文章就想在这一方面做一个尝试。这里面有一个比较棘手的问题。过去，这样的上下文常常使用"**交叉特性**"，也就是两个特征的乘积成为一个新的特征。这样的方法在矩阵分解或者张量分解的模型中得到了非常广泛的使用。然而在深度学习中，过去的经验是不直接使用这样的特性。但是，在上下文非常重要的推荐系统中，不使用交叉特性的的结果，往往就是效果不尽如人意。这篇文章提出了一个叫"隐含交叉"（**LatentCross]{.orange}**）的概念，直接作用在嵌入（Embedding）这一层，从而能够在深度模型的架构上模拟出"交叉特性"的效果。``{=html}
## 论文的核心方法 {#142.html#-}作者们首先探讨了推荐系统中一个常见的特性，那就是利用交叉特性来达到一个"**低维**"（Low-Rank）的表达方式，这是矩阵分解的一个基本假设。比如每一个评分（Rating）都可以表达成一个用户向量和物品向量的点积。那么，作者们就提出了这样一个问题：作为深度学习的基石，**前馈神经网络**（FeedforwardNeural Network）是否能够很好地模拟这个结构呢？通过模拟和小规模实验，作者们从经验上验证了深度学习的模型其实并不能很好地抓住这样的交叉特性所带来的"低维"表达。实际上，深度学习模型必须依赖更多的层数和更宽的层数，才能得到相同的交叉特性所达到的效果。对于这一点我们或多或少会感到一些意外。同时，作者们在传统的RNN 上也作了相应的比较，这里就不复述了。得到了这样的结果之后，作者们提出了一个叫作"隐含交叉"的功能。这个功能其实非常直观。传统的深度学习建模，是把多种不同的信息输入直接拼接在一起。"隐含交叉"是**让当前的普通输入特性和上下文信息进行乘积，从而直接对"交叉特性"进行建模**。这样做的好处是不言而喻的。之前，我们寄希望于深度学习模型自身能够学习到这样的交叉关系。而现在，作者们直接让上下文信息作用于输入信息和其他的中间特征，使得上下文信息的作用得到了提升。这篇文章提出的办法可以说是第一个尝试解决传统推荐系统的一些想法，使之移植到深度学习的语境中。
## 方法的实验效果 {#142.html#-}这篇文章使用了谷歌的 Youtube数据来做实验。作者们比较了一系列的方法，得出的结论是 RNN配合"隐含交叉"比仅仅使用 RNN 的效果要好2%\~3%，这个提升已经是一个非常可观的数字了。
## 小结 {#142.html#-}今天我为你讲了 WSDM 2018的一篇来自谷歌团队的文章，这篇文章介绍了在传统推荐系统的模型中（比如矩阵分解等）都有的交叉特性如何应用在深度学习中。一起来回顾下要点：第一，我们简要介绍了这篇文章的作者群信息；第二，我们详细介绍了这篇文章要解决的问题以及贡献；第三，我们分析了文章提出方法的核心内容以及实验结果。最后，给你留一个思考题，深度学习模型在默认状态下并不能很好地抓住交叉特性，这是深度模型的问题吗？欢迎你给我留言，和我一起讨论。![](Images/5f1a3d2ca933c759573c72ee2ba198b7.png){savepage-src="https://static001.geekbang.org/resource/image/ef/b2/efd991ee74e55356bb2776f3d8d375b2.jpg"}
# 101 \| The Web 2018论文精读：如何对商品的图片美感进行建模？"万维网大会"（The Web Conference2018）前身叫作"国际万维网大会"（International World Wide WebConference），从 1994 年开始举办，已有 20 多年的历史了，在 Google学术排名上，是"信息系统"排名第一的国际顶级学术会议。从万维网大会最初举办开始，这个会议就成为了互联网方面独一无二的权威学术会议。会议包含搜索、推荐、广告、数据库、信息提取、互联网安全等诸多领域的优秀论文，每年都吸引着上千名世界各地的学者和工程师来分享他们的最新研究成果。2018 年的万维网大会于 4 月 23 日\~27 日在法国里昂举行。整个会议收录了171 篇论文，还有 27 个研讨班（Workshop）、19 个讲座（Tutorial）、61个展板论文（Poster）和 30 个演示（Demo）。万维网大会的一大特点就是论文成果涵盖了非常广的领域。要在这些论文中找到有价值的学习信息是一件非常耗时、很辛苦的任务。这里给你分享几篇我认为今年这个会议上最有价值的论文，希望能起到抛砖引玉的作用。今天，我们就来看一篇优秀论文提名，题目是《基于美感的服装推荐》（[Aesthetic-basedClothingRecommendation](https://www.comp.nus.edu.sg/~xiangnan/papers/www18-clothing-rec.pdf)）。这篇论文一共有六位作者，除了两位分别来自新加坡国立大学和美国的埃默里大学之外，绝大多数作者都来自清华大学。
## 论文的主要贡献 {#143.html#-}在现代的电商推荐系统中，商品特别是服装服饰的图片，其美观和质量是用户进行购买决策的关键参考因素。不少过去的商品推荐系统已经考虑了图片的属性，特别是尝试同时利用图片信息和文字信息来实现**多模（Multi-Modal）数据理解**的目的，从而能够进行更加智能的推荐。不过，当前的大多数方案都只是考虑基本的图片特性。从思路上来说，大多数的类似工作都是利用某种深度神经网络提取图片特性，然后和其他特性（例如我们说过的文本信息）加以组合，从而能够扩宽我们对商品信息的提取。这样提取出来的图像特征自然没有显式地对图像的"美感"（Aesthetic）进行建模。这篇文章的作者们认为，商品图片的"美感"是非常重要的属性，针对美感进行建模会有更显著的商品推荐效果。概括来说，这篇论文的一个贡献就是提供了一种模型，来对图片的美感和一般性的图片语义特性同时进行建模。这是一个在过去的工作中都没有的创新点，我们接下来会详细说明一这个模型的架构。当作者们提取出了图片的美感信息以后，接下来的一个问题就是如何利用这些特性。这篇论文使用了**张量分解**（TensorFactorization）的思路。我们在前面介绍推荐系统的时候曾经提到过，张量分解是一种很有效且常用的**利用上下文语义信息**的推荐模型。和一些之前的工作类似，这里作者们采用了三维的张量来表达用户、商品和时间之间的关系。同时，作者们还把图片信息有效地结合到了张量分解中，从而能够利用美感信息来影响推荐结果。