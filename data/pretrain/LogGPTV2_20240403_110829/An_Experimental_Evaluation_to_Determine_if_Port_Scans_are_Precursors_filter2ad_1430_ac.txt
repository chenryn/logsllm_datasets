Port Scans 
Vulnerability Scans 
Attacks
Total
No. of 
Records
9,660
8,432
2,583
2,035
22,710
No. of Unique 
Records
3,007
779
1,657
760
6,203
Figure 7. Distribution of Scans Leading to an Attack 
6.3 Distribution of Port Scans Types 
To  better  analyze  the  port  scans  that  have  been
collected,  we  attempted  to  characterize  different  port
scans. This characterization is based on common practice 
[27,  28]  and  the  design  of  network  port  scanners  like
Nmap [29]. We propose to model a port scan through the
state machine shown in Figure 8. Depending on the state
in  which  the  port  scan  terminates,  port  scans  can  be
classified 
in  five  different  categories.  These  five 
categories are shown in Figure 9.
Scripts in Perl were developed to parse the collected
malicious activity. Apart from detecting the five types of
scans, we also observed scans in which six packets were 
used.  These  scans  were  actually  a half reverse scan
performed three times. We already mentioned this issue
when  analyzing  the  vulnerability  scans provided by
Nessus
in  Section  5.2.  The  scripts  we  developed
recognized  these  scans  and  counted  the  six-packet  scan 
as a special case of a single half reverse scan. The results 
provided after parsing forty-eight days of collected data
on port scans are shown in Figure 10. 
Figure 8. Representation of Port Scans 
Scan Type
Full Open 
Half Open 
Full Reverse
Half Reverse
Incomplete
Connection Termination State 
State 4 
State 5 
State 6 
State 3 
State 2
Figure 9. Classification of Port Scans 
Proceedings of the 2005 International Conference on Dependable Systems and Networks (DSN’05) 
0-7695-2282-3/05 $20.00 © 2005 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 11:52:49 UTC from IEEE Xplore.  Restrictions apply. 
Scan Type
Full Open 
Half Open 
Full Reverse 
Half Reverse  7,667
Incomplete
Total
62
8,100
No. Detected  Percentage
10
355
6
0.12
4.38
0.07
94.66
0.77
100
Figure 10. Distribution of Port Scans 
Note first that not all port scans were covered by this
model. From the 8,432 port scans collected, 8,100 could
be classified using the state machine model of Figure 10,
representing 96.1% of the collected port scans.
A  significant  majority  of  scans  (over  94%)  are  half
reverse  scans.  Half  open  scans  reach over 4%. These
scans (99%) consist of connections that contain only two
packets. The very large majority of the port scans are due 
to connections that are not established (a full connection
would significantly increase the visibility of the attacker
and  is  therefore  avoided  by attackers). This result thus
shows the  relevance  of  using  a  test-bed  like  the  one 
described in Section 4  to  better  understand  existing
launched attacks.
7.  Experimental Results
We now have identified the ICMP scans, port scans, 
vulnerability scans and  attacks  in  the  collected  traffic. 
The  next  step  is  to  analyze  the  correlation  between 
attacks and scans. We first considered all scans and for
each one checked if an attack followed the scan. We then 
analyzed all  the  attacks  and  identified  which  scan(s),  if 
any, preceded the attack. 
7.1 Scans Followed by Attacks 
For  each  scan  and  combination of scans (from a
specific source  IP  address  towards  one  of  the  target 
computers),  we  checked  if  at  least  one  attack  (from  the 
same  source  IP  address 
the same target
the  scan(s).  Each  scan  and 
computer) 
combination  of  scans,  the  associated  number  of  scans 
observed, the number of scans followed by an attack and 
the percentage of scans leading to an attack are presented 
in Figure 11. 
followed 
towards 
Focusing on scans, we observed from Figure 11 that
almost none  of  the  ICMP  scans  were  followed  by  an 
attack.  Moreover,  only  4%  of  the port scans were
followed by an attack.  However,  over  21%  of  the
vulnerability scans were  followed  by  an  attack.  These
percentages  are  rather  low  indicating  that  the  detection
of  an  ICMP/port/vulnerability  scan  might  be  a  poor 
indicator that an attack will follow.
Type of Scan
No. Scans
Observed
No. Scans
Leading to 
Attack
Port
ICMP
Vulnerability
Port & ICMP 
Port & 
Vulnerability
ICMP & 
Vulnerability
Port & ICMP & 
Vulnerability
694
2,797
1,399
11
59
184
15
28
1
296
0
42
5
7
Percentage
Scans
Leading to 
Attack
4.03
0.04
21.16
0
71.19
2.72
46.67
Figure 11. Distribution of Scans Leading to an Attack 
Considering combinations of scans, the combination
of  an  ICMP  scan  and  a  vulnerability  scan  leads  to  an
attack in  about  3%  of  the  cases.  In  the  case  of  a 
combination  of  the  three  scans,  an  attack  followed  in
more than 46% of the cases. However, only a few cases 
of  three  scans  originating  from  the  same  source  IP
address were  observed  (15)  requiring  interpreting  this
percentage with caution. The best indicator that an attack 
will  follow  was  the  combination  of  a  port  scan  and a
vulnerability  scan.  For  over  71%  of  the  port  scan  and
vulnerability scan  combinations,  an  attack  followed.
These results showed that the identification of port scans
and  vulnerability  scans  launched  from  a specific source
IP address is a good indicator that an attack will follow 
from  the  same  source  IP  address.  These experimental
results showed that when focusing on the scans, the main
scans leading to an attack were: 1) a combination of port
and vulnerability scans, 2) a combination of port, ICMP 
and vulnerability scans, 3) a vulnerability scan and 4) a
port scan. 
7.2 Attacks Preceded by Scans 
For  each  of  the  760  attacks collected from different
source  IP  addresses  (if  more  than  one attack was
collected from a source IP address, we only counted one
attack since the goal of this experiment was to correlate
attacks  with  scans  and  not  to  analyze  the  attacks 
themselves)  we  checked  if  any  scan  or  combination  of 
scans preceded  the  attack  (from  the  same  source  IP 
address towards the same target computer). The number
and  percentage  of  direct attacks  (i.e.,  attacks  not 
preceded by any scan) and attacks preceded by different
scans and combinations of scans are provided in Figure
12.
We observed from Figure 12 that more than 50% of 
the attacks  were  not  preceded  by  a  scan.  This 
observation  puts  in  perspective  the  previous  results
obtained  when  focusing  on  the  scans.  However,  over
38%  of  the  attacks  were  preceded  by  a  vulnerability
Proceedings of the 2005 International Conference on Dependable Systems and Networks (DSN’05) 
0-7695-2282-3/05 $20.00 © 2005 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 11:52:49 UTC from IEEE Xplore.  Restrictions apply. 
scans
scan. Port
and  combinations  of  port  and 
vulnerability scans preceded 3-6% of the attacks. These 
experimental results show that the majority of the attacks
were  not  preceded  by  any  scan.  When  scans  preceded
attacks, the  most  frequent  ones  were:  1)  a  vulnerability
scan, 2) a  combination  of  port  and  vulnerability  scans
and 3) a port scan. 
Type of Scan
Port
ICMP
Vulnerability
Port & ICMP 
Port & Vulnerability
ICMP & Vulnerability
Port & ICMP & 
Vulnerability
None
No. Attacks
Preceded by a 
Scan
28
1
296
0
42
5
7
381
Percentage
Attacks
3.68
0.13
38.95
0
5.53
0.66
0.92
50.13
Figure 12. Distribution of Scans Preceding an Attack 
8.  Conclusions 
To  evaluate  the  security of  a  computing  system,  the 
system  weaknesses  (i.e.,  vulnerabilities)  need to be
identified  and  the  threat  on the  system  needs  to  be
assessed.  This  paper  focused  on  the  threat  by  trying  to
better  understand  common  attacks launched against
computer systems. More specifically, the paper analyzed 
the
correlation  between  scans  and  attacks.  This 
correlation is important for determining if a scan can be
used  as  a  signal  that  an  attack  might follow. The paper
tackles  the  issue  by  trying to experimentally assess the
link between a scan and an attack. 
The experiment was based on a test-bed deployed at
the  University  of  Maryland  dedicated  to  monitoring
attackers and collecting data on attacks. The filtering and
the  analysis  of 
the  collected  data  consisting  of 
management  traffic  and  malicious  activity  during  the
forty-eight days were described. The number of packets
per connection  was  used 
to  separate  port  scans, 
vulnerability scans, and attacks.  We  used  Nmap  and
Nessus to demonstrate the relevance of using the number
of packets as a separator between scans and attacks.
The experimental results  showed  that  over  50%  of 
the  attacks  were  not  preceded  by  a  scan.  Among the
scans  leading  the  more  frequently  to  an  attack were
vulnerability  scans  and  combinations  of port and
vulnerability scans. Therefore, port scans combined with
vulnerability scans might be  a  relevant  indicator  of  a 
coming attack. However,  based  on  the  results  of  this
experiment, only port scans did not appear to be a good
indicator of a future attack. Therefore, we can state that,
based  on  the experiment conducted  in  this  paper,  port
scans should  not  be  considered  as  precursors  to  an 
attack.
The  described  experiment  provides a first step into
answering the question if port scans are a good indicator
of a future attack. This experiment now can be expanded
into a longer  data  collection  period,  target  computers
deployed 
sets of
vulnerabilities left on the target computers.
locations  and  different
in  other 
Acknowledgments
the  Office for
The authors  would  like  to  thank  The  Institute  for
Systems  Research  and 
Information
Technology for their support in implementing a test-bed
for collecting attack data at the University of Maryland.
In particular, we thank Michael Wilson and his team for
the  help,  material,  and  room  offered  to conduct this
project. We thank  Gerry  Sneeringer  and  his  team  for 
permitting the deployment of the test-bed. We also thank
Melvin Fields and Dylan Hazelwood for providing some
of the computers used in the testbed.
References
[1] U.S. Department of Defense Standard, Department of 
Defense Trusted Computer System Evaluation Criteria 
(“Orange Book”), DOD 5200.28-STD, Library No. S225,7ll, 
Dec. 1985. 
http://www.radium.ncsc.mil/tpep/library/rainbow/5200.28-
STD.html
[2] ISO/IEC International Standards (IS) 15408-1:1999, 15408-
2:1999, and 15408-3:1999, “Common Criteria for Information 
Technology Security Evaluation”: Part 1: “Introduction and 
General Model,” Part 2: “Security Functional Requirements,” 
and Part 3: “Security Assurance Requirements,” Version 2.1, 
August 1999 (CCIMB-99-031, CCIMB-99-032, and CCIMB-
99-033). http://csrc.nist.gov/ cc/ccv20/ccv2list.htm
[3] C. Landwehr, Formal Models for Computer Security,
Computer Surveys, vol.13, no.3, Sept. 1981. 
[4] J. Lowry, An initial foray into understanding adversary
planning and courses of action, in Proc. DARPA Information 
Survivability Conference and Exposition II. DISCEX’01 p. 
123-33, 2001. 
[5] K. Goseva-Popstojanova, F. Wang, R. Wang, F. Gong, K. 
Vaidyanathan, K. Trivedi, and B. Muthusamy, Characterizing 
Intrusion Tolerant Systems Using A State Transition Model, in 
Proc. DARPA Information Survivability Conference and 
Exposition II. DISCEX’01, 2001. 
[6] S. Jha and J. M. Wing, Survivability Analysis of Networked 
Systems, in Proc. of the 23rd International Conference on 
Software Engineering (ICSE 2001), pp. 307-317, 2001. 
[7] R. Ortalo, Y. Deswarte, and M. Kaaniche, Experimenting 
with quantitative evaluation tools for monitoring operational 
security, IEEE Transactions on Software Engineering, vol.25, 
no.5, p. 633-50, Sept.-Oct. 1999. 
[8] http://www.faqs.org/rfcs/rfc793.html 
[9] http://www.snort.org/
[10] http://bro-ids.org/ 
Proceedings of the 2005 International Conference on Dependable Systems and Networks (DSN’05) 
0-7695-2282-3/05 $20.00 © 2005 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 11:52:49 UTC from IEEE Xplore.  Restrictions apply. 
[11] L.T.Heberlein, G.Dias, K.Levitt, B. Mukherjee, J. Wood, 
and D. Wolber, A network security monitor, in Proc. 
Symposium on Research in Security and Privacy, pp. 296-304, 
1990.
[12] S. Staniford-Chen, S. Cheung, R. Crawford, M. Dilger, J. 
Frank, J. Hoagland, K. Levitt, C. Wee, R. Yip, and D. Zerkle, 
GrIDS A Graph-Based Intrusion Detection System for Large 
Networks, in Proc. 19th National Information Systems Security
Conference, 1996. 
[13] http://www.sdl.sri.com/projects/emerald/
[14] L. Ertoz, E. Eilertson, P. Dokas, V. Kumar and K. Long, 
Scan Detection – Revisited, AHPCRC Technical Report 2004-
127
[15] C. B. Lee, C. Roedel, E. Silenok, Detection and 
Characterization of Port Scan Attacks,
http://www.cs.ucsd.edu/users/clbailey/PortScans.pdf
[16] R. Pan, V. Yegneswaran, P. Barford, V. Paxson, and L. 
Peterson, Characteristics of Internet Background Radiation, in 
Proc. ACM SIGCOMM’04, 2004. 
[17] L. Spitzner, Honeypots: Tracking Hackers, Addison-
Wesley, 2002. 
[18] The Honeynet Project, Know Your Enemy, Addison-
Wesley, 2002. 
[19] http://www.honeynet.org/tools/sebek/
[20] http://www.ethereal.com/
[21] http://swatch.sourceforge.net/ 
[22] http://www.symantec.com/
[23] http://www.insecure.org/nmap/
[24] http://www.tenablesecurity.com/newt.html
[25] http://www.nessus.org/
[26] http://sourceforge.net/projects/nettime
[27] S. McClure, J. Scambray, and G. Kurtz, Hacking Exposed: 
Network Security Secrets & Solutions, McGraw-Hill, 1999. 
[28] J. Chirillo, Hack Attacks Revealed: A Complete Reference 
for UNIX, Windows, and Linux with Custom Security Toolkit, 
Wiley, Second Edition, 2002. 
[29] M. Wolfgang, Host Discovery with nmap, 2002,
http://www.net-security.org/dl/articles/discovery.pdf
Proceedings of the 2005 International Conference on Dependable Systems and Networks (DSN’05) 
0-7695-2282-3/05 $20.00 © 2005 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 11:52:49 UTC from IEEE Xplore.  Restrictions apply.