## 用 Thread 实现 Thread-Per-Message 模式Thread-Per-Message模式的一个最经典的应用场景是**网络编程里服务端的实现**，服务端为每个客户端请求创建一个独立的线程，当线程处理完请求后，自动销毁，这是一种最简单的并发处理网络请求的方法。网络编程里最简单的程序当数 echo 程序了，echo程序的服务端会原封不动地将客户端的请求发送回客户端。例如，客户端发送 TCP请求\"Hello World\"，那么服务端也会返回\"Hello World\"。下面我们就以 echo 程序的服务端为例，介绍如何实现 Thread-Per-Message模式。在 Java 语言中，实现 echo 程序的服务端还是很简单的。只需要 30行代码就能够实现，示例代码如下，我们为每个请求都创建了一个 Java线程，核心代码是：new Thread(()-\>{...}).start()。    final ServerSocketChannel ssc =   ServerSocketChannel.open().bind(    new InetSocketAddress(8080));// 处理请求    try {  while (true) {    // 接收请求    SocketChannel sc = ssc.accept();    // 每个请求都创建一个线程    new Thread(()->{      try {        // 读 Socket        ByteBuffer rb = ByteBuffer          .allocateDirect(1024);        sc.read(rb);        // 模拟处理请求        Thread.sleep(2000);        // 写 Socket        ByteBuffer wb =           (ByteBuffer)rb.flip();        sc.write(wb);        // 关闭 Socket        sc.close();      }catch(Exception e){        throw new UncheckedIOException(e);      }    }).start();  }} finally {  ssc.close();}   如果你熟悉网络编程，相信你一定会提出一个很尖锐的问题：上面这个 echo服务的实现方案是不具备可行性的。原因在于 Java中的线程是一个重量级的对象，创建成本很高，一方面创建线程比较耗时，另一方面线程占用的内存也比较大。所以，为每个请求创建一个新的线程并不适合高并发场景。于是，你开始质疑 Thread-Per-Message模式，而且开始重新思索解决方案，这时候很可能你会想到 Java提供的线程池。你的这个思路没有问题，但是引入线程池难免会增加复杂度。其实你完全可以换一个角度来思考这个问题，语言、工具、框架本身应该是帮助我们更敏捷地实现方案的，而不是用来否定方案的，Thread-Per-Message模式作为一种最简单的分工方案，Java 语言支持不了，显然是 Java语言本身的问题。Java 语言里，Java 线程是和操作系统线程一一对应的，这种做法本质上是将Java线程的调度权完全委托给操作系统，而操作系统在这方面非常成熟，所以这种做法的好处是稳定、可靠，但是也继承了操作系统线程的缺点：创建成本高。为了解决这个缺点，Java并发包里提供了线程池等工具类。这个思路在很长一段时间里都是很稳妥的方案，但是这个方案并不是唯一的方案。业界还有另外一种方案，叫做**轻量级线程**。这个方案在 Java领域知名度并不高，但是在其他编程语言里却叫得很响，例如 Go 语言、Lua语言里的协程，本质上就是一种轻量级的线程。轻量级的线程，创建的成本很低，基本上和创建一个普通对象的成本相似；并且创建的速度和内存占用相比操作系统线程至少有一个数量级的提升，所以基于轻量级线程实现Thread-Per-Message 模式就完全没有问题了。Java 语言目前也已经意识到轻量级线程的重要性了，OpenJDK 有个 Loom项目，就是要解决 Java语言的轻量级线程问题，在这个项目中，轻量级线程被叫做**Fiber**。下面我们就来看看基于Fiber 如何实现 Thread-Per-Message 模式。
## 用 Fiber 实现 Thread-Per-Message 模式Loom 项目在设计轻量级线程时，充分考量了当前 Java线程的使用方式，采取的是尽量兼容的态度，所以使用上还是挺简单的。用 Fiber实现 echo 服务的示例代码如下所示，对比 Thread的实现，你会发现改动量非常小，只需要把 new Thread(()-\>{...}).start()换成 Fiber.schedule(()-\>{}) 就可以了。    final ServerSocketChannel ssc =   ServerSocketChannel.open().bind(    new InetSocketAddress(8080));// 处理请求try{  while (true) {    // 接收请求    final SocketChannel sc =       serverSocketChannel.accept();    Fiber.schedule(()->{      try {        // 读 Socket        ByteBuffer rb = ByteBuffer          .allocateDirect(1024);        sc.read(rb);        // 模拟处理请求        LockSupport.parkNanos(2000*1000000);        // 写 Socket        ByteBuffer wb =           (ByteBuffer)rb.flip()        sc.write(wb);        // 关闭 Socket        sc.close();      } catch(Exception e){        throw new UncheckedIOException(e);      }    });  }//while}finally{  ssc.close();}那使用 Fiber 实现的 echo 服务是否能够达到预期的效果呢？我们可以在 Linux环境下做一个简单的实验，步骤如下：1.  首先通过 `ulimit -u 512` 将用户能创建的最大进程数（包括线程）设置为    512；2.  启动 Fiber 实现的 echo 程序；3.  利用压测工具 ab 进行压测：ab -r -c 20000 -n 200000 [http:// 测试机    IP 地址:8080/](http://xn--IP-im8ckc884ihkivx9c:8080/)压测执行结果如下：    Concurrency Level:      20000Time taken for tests:   67.718 secondsComplete requests:      200000Failed requests:        0Write errors:           0Non-2xx responses:      200000Total transferred:      16400000 bytesHTML transferred:       0 bytesRequests per second:    2953.41 [#/sec] (mean)Time per request:       6771.844 [ms] (mean)Time per request:       0.339 [ms] (mean, across all concurrent requests)Transfer rate:          236.50 [Kbytes/sec] received Connection Times (ms)              min  mean[+/-sd] median   maxConnect:        0  557 3541.6      1   63127Processing:  2000 2010  31.8   2003    2615Waiting:     1986 2008  30.9   2002    2615Total:       2000 2567 3543.9   2004   65293你会发现即便在 20000 并发下，该程序依然能够良好运行。同等条件下，Thread实现的 echo 程序 512 并发都抗不过去，直接就 OOM 了。如果你通过 Linux 命令 `top -Hp pid` 查看 Fiber 实现的 echo程序的进程信息，你可以看到该进程仅仅创建了 16（不同 CPU核数结果会不同）个操作系统线程。![](Images/ca0e7ae68c8bd73ac0f7d2e48645688e.png){savepage-src="https://static001.geekbang.org/resource/image/ae/e9/aebe9691be206fb88f45e4f763bcb7e9.png"}如果你对 Loom项目感兴趣，也想上手试一把，可以下载源代码自己构建，构建方法可以参考[ProjectLoom的相关资料](https://wiki.openjdk.java.net/display/loom/Main)，不过需要注意的是构建之前一定要把代码分支切换到Fibers。
## 总结并发编程领域的分工问题，指的是如何高效地拆解任务并分配给线程。前面我们在并发工具类模块中已经介绍了不少解决分工问题的工具类，例如Future、CompletableFuture 、CompletionService、Fork/Join计算框架等，这些工具类都能很好地解决特定应用场景的问题，所以，这些工具类曾经是Java 语言引以为傲的。不过这些工具类都继承了 Java 语言的老毛病：太复杂。如果你一直从事 Java开发，估计你已经习以为常了，习惯性地认为这个复杂度是正常的。不过这个世界时刻都在变化，曾经正常的复杂度，现在看来也许就已经没有必要了，例如Thread-Per-Message 模式如果使用线程池方案就会增加复杂度。Thread-Per-Message 模式在 Java 领域并不是那么知名，根本原因在于 Java语言里的线程是一个重量级的对象，为每一个任务创建一个线程成本太高，尤其是在高并发领域，基本就不具备可行性。不过这个背景条件目前正在发生巨变，Java语言未来一定会提供轻量级线程，这样基于轻量级线程实现 Thread-Per-Message模式就是一个非常靠谱的选择。当然，对于一些并发度没那么高的异步场景，例如定时任务，采用Thread-Per-Message 模式是完全没有问题的。实际工作中，我就见过完全基于Thread-Per-Message模式实现的分布式调度框架，这个框架为每个定时任务都分配了一个独立的线程。
## 课后思考使用 Thread-Per-Message模式会为每一个任务都创建一个线程，在高并发场景中，很容易导致应用OOM，那有什么办法可以快速解决呢？欢迎在留言区与我分享你的想法，也欢迎你在留言区记录你的思考过程。感谢阅读，如果你觉得这篇文章对你有帮助的话，也欢迎把它分享给更多的朋友。![](Images/f2ae29f2a91a0266d9d86db774df526d.png){savepage-src="https://static001.geekbang.org/resource/image/cf/aa/cf393cd748a4f0e6451807c4b61843aa.jpg"}
# 34 \| Worker Thread模式：如何避免重复创建线程？在[上一篇文章](https://time.geekbang.org/column/article/95098)中，我们介绍了一种最简单的分工模式------Thread-Per-Message模式，对应到现实世界，其实就是委托代办。这种分工模式如果用 Java Thread实现，频繁地创建、销毁线程非常影响性能，同时无限制地创建线程还可能导致OOM，所以在 Java 领域使用场景就受限了。要想有效避免线程的频繁创建、销毁以及 OOM问题，就不得不提今天我们要细聊的，也是 Java 领域使用最多的 Worker Thread模式。
## Worker Thread 模式及其实现Worker Thread模式可以类比现实世界里车间的工作模式：车间里的工人，有活儿了，大家一起干，没活儿了就聊聊天等着。你可以参考下面的示意图来理解，WorkerThread 模式中**Worker Thread对应到现实世界里，其实指的就是车间里的工人**。不过这里需要注意的是，车间里的工人数量往往是确定的。![](Images/76a0c1ac82a6ea20a6a17e1e3df57ab4.png){savepage-src="https://static001.geekbang.org/resource/image/9d/c3/9d0082376427a97644ad7219af6922c3.png"}```{=html}```车间工作示意图]{.reference}```{=html}```那在编程领域该如何模拟车间的这种工作模式呢？或者说如何去实现 WorkerThread模式呢？通过上面的图，你很容易就能想到用阻塞队列做任务池，然后创建固定数量的线程消费阻塞队列中的任务。其实你仔细想会发现，这个方案就是Java 语言提供的线程池。``{=html}线程池有很多优点，例如能够避免重复创建、销毁线程，同时能够限制创建线程的上限等等。学习完上一篇文章后你已经知道，用Java 的 Thread 实现 Thread-Per-Message模式难以应对高并发场景，原因就在于频繁创建、销毁 Java线程的成本有点高，而且无限制地创建线程还可能导致应用OOM。线程池，则恰好能解决这些问题。那我们还是以 echo 程序为例，看看如何用线程池来实现。下面的示例代码是用线程池实现的 echo 服务端，相比于 Thread-Per-Message模式的实现，改动非常少，仅仅是创建了一个最多线程数为 500 的线程池es，然后通过 es.execute() 方法将请求处理的任务提交给线程池处理。    ExecutorService es = Executors  .newFixedThreadPool(500);final ServerSocketChannel ssc =   ServerSocketChannel.open().bind(    new InetSocketAddress(8080));// 处理请求    try {  while (true) {    // 接收请求    SocketChannel sc = ssc.accept();    // 将请求处理任务提交给线程池    es.execute(()->{      try {        // 读 Socket        ByteBuffer rb = ByteBuffer          .allocateDirect(1024);        sc.read(rb);        // 模拟处理请求        Thread.sleep(2000);        // 写 Socket        ByteBuffer wb =           (ByteBuffer)rb.flip();        sc.write(wb);        // 关闭 Socket        sc.close();      }catch(Exception e){        throw new UncheckedIOException(e);      }    });  }} finally {  ssc.close();  es.shutdown();}   
## 正确地创建线程池Java 的线程池既能够避免无限制地**创建线程**导致OOM，也能避免无限制地**接收任务**导致OOM。只不过后者经常容易被我们忽略，例如在上面的实现中，就被我们忽略了。所以强烈建议你**用创建有界的队列来接收任务**。当请求量大于有界队列的容量时，就需要合理地拒绝请求。如何合理地拒绝呢？这需要你结合具体的业务场景来制定，即便线程池默认的拒绝策略能够满足你的需求，也同样建议你**在创建线程池时，清晰地指明拒绝策略**。同时，为了便于调试和诊断问题，我也强烈建议你**在实际工作中给线程赋予一个业务相关的名字**。综合以上这三点建议，echo 程序中创建线程可以使用下面的示例代码。    ExecutorService es = new ThreadPoolExecutor(  50, 500,  60L, TimeUnit.SECONDS,  // 注意要创建有界队列  new LinkedBlockingQueue(2000),  // 建议根据业务需求实现 ThreadFactory  r->{    return new Thread(r, "echo-"+ r.hashCode());  },  // 建议根据业务需求实现 RejectedExecutionHandler  new ThreadPoolExecutor.CallerRunsPolicy());