step of the algorithm it first executes generateInputs(I) to aug-
ment the current list of inputs I with additional generated inputs as
described in the next section (§4.3). It then runs the reference imple-
mentation r on the inputs I, producing a list of input/output pairs
IO = [⟨i1, o1⟩ , . . . , ⟨ik , ok⟩]. These outputs are considered ground-
truth outputs, because they are generated by the reference imple-
mentation r. For example, applying run(r, I) to r = length and I =
["a", "bb", "ccc"] produces IO = [⟨"a", 1⟩ , ⟨"bb", 2⟩ , ⟨"ccc", 3⟩].
Alg. 1 next invokes typeConstraints(IO) to collect a set of
sound type information T for the values in IO. This procedure
includes several type-inference tests checking whether the values
in IO represent numbers, whether their length is longer or shorter
than the input length, and whether they contain any special char-
acters. For example, the result of calling typeConstraints(IO) on
IO = ["bb", 2] would return Strinд → Number.
Navigating the search space: The algorithm next prepares the
search space of candidate DSL programs, which is parametric over
the maximum number n of terms used in the program—i.e., the
size of the abstract syntax tree (AST) of each candidate DSL pro-
gram. The algorithm generates the search space by invoking all-
Programs(n,T), which takes a number n and a set of sound type
constraints T and returns a set Pn containing all of the programs of
size n that satisfy the type constraintsT . Consider an example where
(1) all programs of AST size 1 are captured by the set of single-term
programs {count, toString, +, -, *}, and (2) the type constraints
include Number→Number→Number. Then P1 = {+, -, *}.
The algorithm then invokes filter(Pn, IO) to eliminate all candi-
date programs in Pn whose input-output behavior does not conform
to (I, O). This procedure eliminates candidate DSL programs with
behavior that is not identical to r—i.e., programs for which not all
inputs in I produce outputs in O. As appropriate, filter(Pn, IO)
may also generate more input-output examples to further differ-
entiate between candidates and thus prune the search space even
further. The result is a set of candidate programs P, all of which
implement r’s input-output behavior on the input-output examples.
Session 6B: Web Vulnerabilities CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea1759Input: Reference Implementation r
Output: List of Inferred DSL programs 
n ← 0; I ← ∅
while not done do
I ← generateInputs(I)
IO ← run(r , I)
T ← typeConstraints(IO)
Pn ← allPrograms(n, T)
P ← filter(Pn , IO)
n ← n + 1
end
return getOpt(P)
Algorithm 1: The Harp program inference algorithm. Given as
input a black-box reference implementations r, the algorithm produces
a DSL program with identical behavior as r on the generated inputs I.
Termination:
In principle, Alg. 1 can run indefinitely. In practice,
the algorithm maintains some additional information on the side
(not shown in Alg. 1). First, the algorithm is configured to run up to
a time limit—either a limit t¯r per reference implementation r in the
reference library R or a limit tR for R overall. If only t¯r has been
specified, then tR is calculated as t¯r × |r1−n| spread fairly across all
functions r1−n in R; when Harp timeouts for one of the methods,
it simply outputs Nil and moves to the next ri in R. When tR is
specified, Harp can allocate this time as it sees fit (see parallelism in
§6.2). The combination of the two limits is possible too, instructing
Harp to spend no more than tR minutes overall, with no more than
t¯r minutes per function r in L.
Using timeouts, Alg. 1 may need to exit the inner loop with a P
equal to the empty set. If this happens, L′.r is assigned Nil which
is important for partial regeneration, in cases where only a fraction
of a library’s functionality has been successfully regenerated.
Finally, Alg. 1 inspects the set P. If P is not empty, it ranks the
candidate programs in P by invoking and returning getOpt(P),
which returns the highest-performance program in P. During the
filter(Pn, IO) procedure, the synthesis algorithm collects informa-
tion about the runtime performance of the candidate DSL programs.
Some of the inputs in this phase are large, to make any differences
in overhead more pronounced. This information is then used by
getOpt(P) to rank candidates based on their runtime performance,
returning the DSL program with the best performance.
4.3 Input Generation
Harp generates inputs for each reference function r in R and exe-
cutes r to obtain the input-output pairs. Harp chooses these inputs
to gather a variety of output values that, combined, highlight key
properties of r’s behavior. As Harp does not know beforehand what
input streams are the most appropriate for inferring the behavior
of a black-box r, it adopts an active learning algorithm to gener-
ate the inputs. There are two kinds of inputs Harp is interested
in: (1) primary inputs, which are the strings on which the string-
processing computation is applied and (2) secondary inputs, which
are other parameters of r affecting the specifics of the string com-
putation. All mutations described below are applied concurrently
in iterative rounds providing information or eliminating candidates.
When a mutation iteration results in no candidate eliminations, this
phase of input generation terminates and saves the set of candidate
regenerations.
Value
Primitive
Boolean
String
Number
v
p
b
s
n
λ(x , . . .).x | λ(x , . . .).str(x)
:= p | {s : v , . . . } | [v , . . . ]
|
:= s | n | b | ⊥
:= true | false
∈
Σ
∈ N
Fig. 5: Harp’s secondary-input DSL. This language captures the space
of possible inputs to secondary arguments.
Primary inputs: The primary input of a string processing func-
tion is a string—a collection of characters—or a collection of strings.
Input characters are particularly important because they may affect
r’s processing locations—thus Harp attempts to quickly discover a
set of special characters Σ1. Harp generates primary inputs that
exercise certain properties in an attempt to understand which of
their characteristics affect r’s output. The key insight behind such
discovery is that that string computations are generally applied
over linear data structures that encode control and data characters
in a single data stream. For example, consider the following string:
Different processing primitives may be affected by different charac-
ters. For example, a (to-upper) function converting to upper-case
operates on the entire string, a (split :) function splitting on
“:” will match only the corresponding character, and a “mask *”
function replacing characters with “*” will only match a subset of
characters. These and other examples are shown below:
To discover this set, Harp generates strings with a combination
of letters, numbers, and punctuation symbols. As soon as some of
these inputs start affecting the results, Harp narrows down the set
of symbols by mutating only parts of the input string.
Secondary inputs: Functions in the reference library R rarely
accept only strings as their inputs. That is, while the processing tar-
gets the primary input string, other arguments part of the method’s
interface need to be provided. For example, a simple count(s, c)
method that counts all occurrences of c in s takes two arguments.
To understand the effect of other inputs to the computation, Harp
introduces a small DSL describing possible secondary values (Fig. 5).
To maintain acceptable performance, Harp generates only con-
strained inputs of these types—both in terms of size and complexity.
These values can be summarized into two broad classes. The first
class is composite values such as lists, objects (maps), and functions.
The DSL includes only two functions, helpful for cases when r is a
higher-order function. These two functions are designed to have
types that are permissive and will likely not throw exceptions. The
first function simply returns its first argument, matching any fold-
like operations; the second function returns its first argument as a
string, covering additional use cases where the first-order function
is expected to return strings—highly likely due to the domain of
Harp. Both functions take a variable number of arguments so as to
be compatible with any invocation in the black-box r.
Session 6B: Web Vulnerabilities CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea1760The second class involves primitive values such as strings, num-
bers, booleans. The value ⊥ corresponds to null or undefined
values; such values are important for understanding the default
parameters or behavior of a computation.
Enumerability: As Alg. 1 executes, it considers larger and larger
sets of programs and inputs I, with the current set of programs
Pn containing all programs of size n or less and the current set of
inputs I generated by (repeated calls to) generateInputs(I). The
algorithm will eventually consider every program in the DSL. If
generateInputs(I) will eventually enumerate every possible input,
then in the limit the algorithm will either (1) converge to a DSL
program or programs P all of which have identical behavior as
the reference library R on all inputs (if such program or programs
exist in the DSL) or (2) determine that no such program exists (see
Section §5). To promote fast convergence to a correct DSL program,
the current Harp generateInputs(I) algorithm is designed to pri-
oritize strings that quickly disambiguate candidate computations
over strings.
4.4 Mapping Library Structure
We next cover a few details on how Harp (1) regenerates constant
fields, and (2) discovers the structure of a reference library R.
Constant fields: The majority of string-related functionality is
expected to be exposed as functions. At times, however, R may
contain fields other than functions—e.g., a map of country names
to dial-in prefix codes. In these cases, Harp can copy the struc-
ture into the regenerated library using runtime meta-programming
facilities: it traverses R’s return object to identify and copy such
values directly.
In rare cases, these inputs are hidden behind a functional inter-
face that does not allow meta-programming facilities to permeate
through. In these cases, Harp resorts again to active learning—but
its input generation leverages a built-in dictionary of common Eng-
lish words. Harp attempts these words under various combinations
and capitalizations to gain more information about the mapping.
Field discovery: To apply the techniques described earlier, Harp
needs to know how to interact with R and how to feed it inputs. To
answer this, Harp first loads the original library, an operation that
returns an object that contains the values exported by the library.
These values may include functions or other directly accessible
fields. The way Harp interacts with these fields depends on whether
the functionality about to be regenerated has been explicitly named
by the developer using Harp. If it has been named, Harp indexes
only the named functions from the returned object. If there is no
explicit naming involved, Harp uses runtime meta-programming to
traverse the returned object in order to understand and regenerate
the structure of the library.
5 GUARANTEES
A key correctness guarantee is that the Harp synthesis algorithm
(Alg. 1) will only produce string computations whose behavior is
captured by the DSL in Figure 3. Recall that Algorithm 1 maintains
a current program search size n, set of input-output examples I, O
obtained from executions of the original library L, and set of pro-
grams P in the Harp DSL. The Harp synthesis algorithm provides
the following key correctness guarantees:
These guarantees have an immediate corollary:
• If the original library L has the same behavior on all inputs as
some DSL program f ′ and f is of a given size n or less, then
f ∈ P. Moreover, if P = { f } (i.e., f is the only program in P),
then the newly synthesized library L′ has identical behavior as
the original library L on all inputs.
If the generateInputs function eventually enumerates every pos-
sible input, then, in the limit Alg. 1 will consider all programs in
the DSL. More precisely, for any specific input and program of
some size n, there is some finite execution of the algorithm that will
generate that input and consider that program. This fact ensures
the following guarantees:
• If the original library L has the same behavior as some DSL
program f (of some size m), then at some finite point in the
execution of Algorithm 1, f ∈ P for all future execution points.
• If the original library L has different behavior than some DSL
program f (of some size m), then at some finite point in the
execution of Algorithm 1, f (cid:60) P for all future execution points.
These guarantees provide a form of correctness in the limit—as
the algorithm runs, it (1) will eventually (in finite time) find the
correct DSL implementation of the original library L if such a correct
program exists in the DSL, and (2) will eventually (in finite time)
filter out any DSL program whose behavior does not match the
original library L on all inputs.
6 REFINEMENTS
We next present several Harp refinements.
6.1 Isolated Learning
To avoid exploitation during ALR, Harp interacts with target li-
braries in an isolated container environment. Harp first launches
a Docker container and imports the library in the context of an
TCP server. Harp then traverses the object returned by the import
statement to create a remote-procedure-call (RPC) shim, which it
then writes in the host file-system.
• All programs in P exhibit identical behavior as the original library
L on the list of generated inputs I (the call to pruneSpace in
Algorithm 1 filters out all DSL programs whose behavior differs).
• The set of DSL programs P contains all DSL programs of size n
or less that exhibit identical behavior as the original library L on
the list of generated inputs I.
Harp’s ALR scaffolding infrastructure on the host environment
loads the shim module to interact with the target library. For every
invoked library function, the RPC shim serializes the arguments
and send them to the server executing in the Docker container.
Harp invokes the corresponding function and returns the results
back to the shim, which delivers them to Harp running on the host
environment. The channel between the RPC client function and
the corresponding function running in the container is encrypted
using NaCl authenticated encryption primitives [4].
6.2 Synthesis Acceleration
Type Guidance: Harp leverages sound type information to guide
its choice of DSL terms. This is achieved through a few different
means, starting by checking the size and type of the output. If the
Session 6B: Web Vulnerabilities CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea1761Fig. 6: Harp’s detection of library-external side-effects. Harp’s basic wrapping traverses objects and wraps fields with inline monitors. Harp uses this
transformation to create a new name-to-value context by wrapping all values available in a library’s top-level scope (b). The modified context is bound to the
library by enclosing the module source (half-visible code fragment, in its original indentation) in a closure that redefines all non-local variable names as
closure-local ones, pointing to values from the modified context.
output is significantly smaller, then a fold-like reduction is likely to
play a prominent role in the regenerated computation. Additionally,
if the output has a certain type—such as a number or a boolean
value—then that type should featured in the first-order function
used as part of the reduction. Outputs whose size is close to that of
the input string often correspond to add or at constructs.
The study of more complex outputs is also possible, as Harp
can leverage meta-programming available by the source language
to introspect the value returned by L. This is different from other
domains where active learning is applied through serialization-
deserialization interfaces that encode all values as strings, and
thus obscure the true types of the values returned by a program
fragment. These refinements can prune the synthesis search space
significantly.
Term Weights: Different (classes of) terms from Harp’s DSL
have different likelihoods of appearing in learned DSL programs.
For example, many regenerated string-processing libraries add or
delete characters. Harp uses such likelihood information to guide
synthesis, by generating higher-likelihood terms in the DSL with
higher probability Harp explores the space of candidate programs.
Term weights depend significantly on the types of the inputs
and outputs. For example, if the output is a number then reduction
statements such as fold and built-ins such as × and + are more
likely to appear in the regenerated program.
Parallel Synthesis: Harp’s synthesis features ample opportuni-
ties for parallelization. One opportunity occurs in candidate gener-
ation, in which different worker processes explore disjoint subsets
of the candidate space. Another opportunity occurs in input gener-