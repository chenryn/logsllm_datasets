title:A Dependable SNMP-based Tool for Distributed Network Management
author:Elias Proc&apos;opio Duarte Jr. and
Luis Carlos Erpen De Bona
A Dependable SNMP-based Tool for Distributed Network Management
Elias Proc´opio Duarte Jr.
Luis Carlos Erpen De Bona
Federal University of Paran´a, Dept. Informatics
P.O. Box 19081 Curitiba 81531-990 PR Brazil
e-mail: felias,PI:EMAIL
Abstract
This work presents a dependable fully distributed net-
work management tool based on the Internet standard
network management protocol, SNMP (Simple Network
Management Protocol). Multiple SNMP agents running
the Hi-ADSD with Timestamps, a Hierarchical Distributed
System-Level Diagnosis algorithm with Timestamps, mon-
itor themselves and a conﬁgurable set of network services
and devices, issuing controlling commands depending on
the results. The system is dependable in the sense that it
continues working even if only one agent is fault-free. A
MIB (Management Information Base) allows the deﬁnition
of test procedures speciﬁc for each managed entity. The
system presents a conﬁgurable Web interface that allows
the human manager to monitor the network from any agent.
Practical results are presented, including the construction
of a resilient Web server built on top of the tool.
1. Introduction
Computer network applications have become critical for
organizations and individuals. At the same time, net-
works are increasingly larger and more complex. Network
management systems include tools that allow effective
network monitoring and control [1]. The Simple Network
Management Protocol version 3 (SNMPv3) is the Internet
standard management architecture. An SNMPv3 system
is composed of management entities which communicate
using the management protocol. The architecture deﬁnes
a Management Information Base (MIB) as a collection of
related management objects which are kept in order to
allow management applications to monitor and control the
managed nodes [2].
SNMPv3 entities have traditionally been called man-
agers and agents. Managed nodes contain an agent, which
is a management entity that has access to management
instrumentation. Each system has at least one Network
Management Station, which runs at least one manager
entity. Managers are collections of user-level applications,
which may aim at performance evaluation or fault diagno-
sis, among others. There is currently a very large number
of SNMP-based systems available, both commercial and on
the public-domain.
One of the most important components of network man-
agement systems is the fault management subsystem. The
purpose of fault management is to allow the quick dis-
covery, isolation and solution of network faults [3].
It
is absolutely essential that a network fault management
system be fault-tolerant, being able to work correctly even
in the presence of faults in the network over which it is run
[4]. However this is not the case today for most systems
[5]. As the traditional manager-agent paradigm is replaced
by the distributed approach, a new focus on dependability
and performance is appearing in SNMP-based network
management systems [6].
This work presents a dependable fully distributed net-
work management tool in which multiple SNMP agents
running Hi-ADSD with Timestamps, a Hierarchical Dis-
tributed System-Level Diagnosis algorithm with Times-
tamps [7], monitor themselves and a conﬁgurable set of net-
work services and devices, issuing controlling commands
depending on the results. The system is dependable in the
sense that it continues working even if only one agent is
fault-free.
Each agent runs a MIB that allows the speciﬁcation of
tests of network services and devices. Each test is speciﬁed
by a procedure that is tailored for the tested entity. The
frequency in which the test is executed is also speciﬁed.
Tests are executed in a distributed fashion. The system
presents a conﬁgurable Web interface, shown in ﬁgure 1,
that allows the human manager to monitor the network from
any agent. Practical results are presented, including the
construction of a resilient Apache [8] Web server built on
top of the diagnosis tool.
The rest of the paper is organized as follows. Section 2
presents an overview of Hi-ADSD with Timestamps, the
Proceedings of the International Conference on Dependable Systems and Networks (DSN’02) 
0-7695-1597-5/02 $17.00 © 2002 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 04:21:19 UTC from IEEE Xplore.  Restrictions apply. 
TEST
TEST
WEB INTERFACE
SNMP
SNMP
192.168.1.1
192.168.1.2
192.168.1.3
192.168.1.4
192.168.1.1
192.168.1.2
SNMP
DISTRIBUTED
DIAGNOSIS
SNMP
SNMP
SNMP
WEB INTERFACE
192.168.1.1
192.168.1.2
192.168.1.3
192.168.1.4
DNS
SERVER
192.168.1.3
192.168.1.4
HTTPD
Figure 1. The system allows dependable Web-based network management.
hierarchical distributed system-level diagnosis algorithm
that the tool implements. Section 3 presents the MIB
employed by the tool. Practical results follow in section
4. Section 5 concludes the paper.
the tester gets diagnostic information about =2 nodes. For
example, ﬁgure 2 shows the clusters tested by node 0. When
node 0 tests node 1 node 0 gets information about N/2 = 4
nodes, i.e. node 1, node 3, node 5 and node 7. The other
two cluster are analogous.
2. Distributed Diagnosis
Consider a system composed of  nodes, which can
be faulty or fault-free. Assume that the system is fully
connected, i.e.
there is a link between any pair of nodes,
and links do not become faulty. This approach is often
used to model local area networks, in which all nodes
share the communication medium. A distributed system-
level diagnosis algorithm allows the fault-free nodes in that
system to diagnose the state of all nodes, assuming that
fault-free nodes are capable of executing tests and reporting
test results reliably [9, 10, 11].
If nodes decide the next
tests based on results from previous tests, the algorithm is
also called adaptive [12].
One of the goals of system-level diagnosis is to allow
fault-free nodes to achieve diagnosis in the shortest possible
interval of time. This time interval is called the algorithm’s
latency. It is usually given in terms of testing rounds, i.e.
the period of time in which all testers have found at least
one fault-free node. A system-level diagnosis algorithm
should also minimize the number of times a node executes
tests and is tested. Furthermore, the amount of diagnostic
information that is exchanged between nodes should also be
kept to a minimum.
In [7] the Hierarchical Adaptive Distributed System-
Level Diagnosis algorithm with Timestamps (Hi-ADSD
with Timestamps) was introduced. Each node runnning the
algorithm keeps a timestamp for the state of each other node
in the system. This timestamp is implemented as a counter,
which is incremented every time a node changes its state
[13, 14]. In this way, each tester may get information about
a given node in the system from more than one tested node
without causing any inconsistencies, i.e. without taking an
older state for a newer one. When a fault-free node is tested,
0
2
5
7
1
3
4
6
Figure 2. Clusters tested by node 0.
Nodes running the algorithm are capable of achieving
the diagnosis of dynamic events as long as a node stays in a
given state for a period of time long enough for all its testers
to detect that state. In spite of the overhead of keeping and
transfering timestamps, the new algorithm reduces signiﬁ-
cantly the average latency of other alternatives, presenting
a new option for practical diagnosis implementation[7]. It
has been shown that Hi-ADSD with Timestamps allows
all fault-free nodes in a system to complete diagnosis in
average in a shorter period of time than that of other similar
algorithms.
2.1. Secondary Tests
Network elements such as printers or switches may
not be able to run the distributed diagnosis algorithm.
Secondary tests are introduced in order to allow the system
to monitor such elements. Each node running the algorithm,
from now on called a primary node, is assigned a set of
secondary tests. At each testing interval each primary node
executes both the tests deﬁned by the diagnosis algorithm
and its assigned secondary tests. Optionally the interval
Proceedings of the International Conference on Dependable Systems and Networks (DSN’02) 
0-7695-1597-5/02 $17.00 © 2002 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 04:21:19 UTC from IEEE Xplore.  Restrictions apply. 
in which secondary tests are executed is different from the
regular testing interval.
a
h
b
0
2
g
c
1
3
f
d
e
The Test-MIB allows the conﬁguration of the testing
interval. Each MIB also keeps information about the total
number of testing intervals and the total number of tests
executed by each tester. The MIB also keeps statistics
that can be obtained from the distributed monitoring of the
system, such as the observed mean time a node remains
faulty and the observed mean time it takes to repair a node.
3.1. The MIB Description
Figure 3. Primary nodes execute secondary
tests.
The Test-MIB is structured in four groups, as shown in
ﬁgure 4: tstTester, tstResults, tstStatistics,
and tstFullSecTestsDef.
Information about the outcome of secondary tests ﬂows
together with the remaining diagnostic information. When-
ever a primary node becomes faulty, it does not execute
its assigned secondary tests. A procedure for another
node to assume those secondary tests is deﬁned as follows.
Consider the logical ring formed by all primary nodes
according to their sequential identiﬁers, such that node i
precedes node i  1 in the ring; node    1 precedes node
0. The fault-free node in the ring that precedes a faulty node
assumes the secondary tests of that faulty node. Figure 3
shows an example. Nodes labeled from 0 to 3 are primary
nodes that execute pre-deﬁned tests on the secondary nodes
labeled from a to h. As primary node 1 is faulty, node 0
assumes node 1’s secondary tests, i.e. node 0 tests both
node c and d besides the tests it was already executing.
3. SNMP Framework
The distributed testing system consists of a set of agents
that communicate using SNMP. Each agent, also called
a tester, keeps a Test-MIB, which is a management
information base used to maintain information about the
tests executed by the agent, as well as the state of the
system’s units. The Test-MIB implements the distributed
diagnosis algorithm’s data structures. Two conﬁguration
ﬁles are required. In the ﬁrst, the agents are listed by IP
address and port number. In the second conﬁguration ﬁle,
the secondary tests are assigned to each tester.
A secondary test may refer to any network device or
service. A service is any process executing on any tester,
a device is any accessible resource.
If the type of the
secondary test is device, whenever a tester becomes faulty,
the algorithm determines another tester that will execute the
test. It is possible to conﬁgure a test procedure speciﬁc for
the services and devices being tested. The system assumes
that a test procedure allows a fault-free tester to correctly
determine the state (faulty or fault-free) of the tested entity;
alternatively a tester may report the state of a given entity
as unknown, and it’s own state as initializing.
Test-MIB
tstTester
tstResults
tstStatistics
tstFullSecTestsDef
Figure 4. Test-MIB: group division.
In group tstTester, each tester keeps managed ob-
jects describing itself. The remaining groups keep objects
that describe the other testers. Object tstOnOffSwitch
is a control object that is employed to initialize, reset, stop
or resume the tester operation. Object tstState keeps
the tester’s state; object tstAddress keeps the tester’s IP
address. Object tstInterval keeps the testing interval.
The number of testing intervals that the tester has exe-
cuted is kept in object tstIntervalsCounter. Object
tstTestsCounter keeps the number of tests executed,
this counter does not include the secondary tests.
Group tstTester also includes tstSecTestsTa-
ble, which speciﬁes secondary tests. This information is
obtained both from a conﬁguration ﬁle. This table also
keeps information about secondary tests inherited from
faulty testers. Object tstSecTestsName contains a
string that identiﬁes the test executed. A secondary test
may be of two types: a device test or a service test;
the type information for a speciﬁc test is kept in object
tstSecTestsType.
Two objects are employed to deﬁne the test procedure:
tstTestsDefType and tstTestsDefString. Ob-
ject tstTestsDefType is used in order to determine
how object tstTestsDefString is executed.
It may
assume two values: execute or snmpget. If the value
is execute, object tstTestsDefString is assumed
to keep a shell command to be executed by the operating
system.
If the value is snmpget, the string in object
tstTestsDefString is assumed to contain both an
SNMP agent address, port number, and the object identiﬁer,
its type, and a logical condition to be checked during the
test. The interval between two executions of a secondary
Proceedings of the International Conference on Dependable Systems and Networks (DSN’02) 
0-7695-1597-5/02 $17.00 © 2002 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 04:21:19 UTC from IEEE Xplore.  Restrictions apply. 
test is given by object tstSecTestsInterval. Object
tstSecTestsState keeps the state of the tested entity.
Group tstResults keeps the results of tests exe-
cuted in the whole system. Table tstReDiagsTable
keeps all testers’ addresses, states, and timestamps. The
timestamps are those deﬁned by the diagnosis algorithm.
The index of this table is especially important as it refers
to the sequential identiﬁer given to each tester. Table
tstReSecTestsTable consists of objects that keep in-
formation about all secondary tests that are being executed
in the system. This table keeps two objects: tstReSec-
TestsName which contains a string that identiﬁes the
secondary test executed; tstReSecTestsState which
contains the state of the tested entity is kept in object
Group tstStatistics keeps table tstStatsTa-
ble in which statistics are kept. Objects tstStatsMT-
Faulty and tstStatsMTFFree keep the observed mean
time a tester remains faulty and fault-free, respectively.
Group tstFullSecTestsDef keeps the deﬁnition
of all secondary tests executed in the system. This is
required because the secondary tests of a faulty tester must
be assumed by a fault-free tester.
4. Experimental Results
The system has been used for several months to manage
a 100 Mbps Ethernet LAN with 67 machines based on
different Intel Pentium, AMD K6 and Intel 486 processors,
running the Linux operating system. The testing interval
selected was 10 seconds; the impact on the performance
of the processors running the agent was measured;
the
utilization was always below 3%, even in the slowest Intel
486’s. The amount of network bandwidth required is
0.001% of the available bandwidth.
SNMP agents implementing the MIB described in the
previous section interact according to the diagnosis algo-