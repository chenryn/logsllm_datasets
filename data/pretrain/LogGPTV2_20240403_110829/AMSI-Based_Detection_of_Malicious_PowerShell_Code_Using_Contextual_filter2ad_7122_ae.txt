D. Character-Level Versus Token-Level Representations
In this section, we investigate the added value of the
character-level input representation over the token-level rep-
resentation and discuss the ways in which we combined the
two representations.
From Table III, we see that the TPR of the 4-CNN model
on the test set not only signiﬁcantly surpasses that of the NLP-
based detectors, but also exceeds that of the CNN architecture
models by 2 pp or more. Its TPR is also comparable with
that of the CNN-RNN architecture models and, speciﬁcally, is
exceeded by the CNN-RNN-FastText model by less than 2 pp.
We now analyze the differences in detection between the 4-
CNN and the CNN-RNN-FastText models to better understand
the added value of the character-level encoding used in 4-CNN.
By comparing the detection results of these two models
we found that CNN-RNN-FastText detects 60 code instances
that are not detected by 4-CNN, 55 of which are TPs, while
4-CNN detects 34 instances (29 of which are TPs) that are not
detected by CNN-RNN-FastText. The signiﬁcant added value
of the character-level model can be explained by the existence
of obfuscated instances in our test set that are detected by it
but are not detected at the token level, as we explain next.
We focus ﬁrst on the CNN-RNN-FastText model and
discuss how it
treats various PowerShell code obfuscation
techniques and why some of them are not detected by it,
using concrete examples from the 29 test set instances that
are detected by 4-CNN but evade CNN-RNN-FastText.
FastText uses sub-tokens to construct a contextual embed-
ding. This enables the model to tackle one of the known
methods of PowerShell obfuscation – the use of string manipu-
lations to construct a PowerShell command.11 Unfortunately, in
some cases, the usage of sub-tokens by FastText is insufﬁcient
for detecting this type of obfuscation. Moreover, there are
additional PowerShell obfuscation techniques that are not
detectable at the token level. We identiﬁed three such “blind
spots” of FastText12:
1) One popular way of PowerShell code obfuscation, seen
in many malicious instances, is the usage of tokens whose
characters alternate between lower-case and upper-case (e.g.,
iNvOkE-wEbReQuEsT). Since we lower-case the input be-
fore processing it, token-level representations are unable to
detect this type of obfuscation, which was observed in 16 of
the 29 instances that evaded CNN-RNN-FastText.
2) Special characters such as ’+’ and ’[’ or ’]’ are con-
sidered as delimiters and are therefore absent from token-
level embeddings,
they do not appear as part of
tokens or sub-tokens. Out of the 29 missed instances, 13
instances contain all of these 3 special characters. Inter-
in three of these instances, we observed a rela-
estingly,
tively rare obfuscation technique,
in which a part of the
instance (that contained ASCII-encoded characters) appeared
that
is,
11As we’ve mentioned in Subsection II-B, this obfuscation type, performed
in execution time, cannot be de-obfuscated by AMSI.
12These are clearly blind spots of W2V as well, since W2V treats tokens
as atomic units.
in reverse order. An example of this obfuscation technique
is the command ‘‘[88]rahc[+96]rahc[+37]rahc",
which, upon reversal, becomes ‘‘IEX", an alias of the
"Invoke-Expression" cmdlet. It is impossible for the
token-level model to detect such obfuscation techniques with-
out considering the special characters they use.
3) String manipulations using one or two characters generally
evade FastText. The minimum length of a token is 2, hence
a single character cannot contribute to a model using the
FastText embedding. As for two-character tokens, these are
likely to appear in numerous contexts, and so it is reasonable
to assume that their embedding does not contribute much
to the detection. Indeed, in 12 of the 29 missed instances,
tokens were constructed by concatenating multiple strings,
many of which are singleton characters or 2-character strings,
thus evading FastText. Here is an example of part of code
obfuscated in this manner:
’{2}{3}{0}{1}’-f ’Sc’,’RiPT’,’inVOk’,’E’
’vA’ + ’rI’+’aBle:jW4v’
Turning our attention back to the 4-CNN model, it was
established in [15] that it is able to detect many of these
obfuscation techniques, since it considers its input at
the
character-level and takes character casing into consideration.
In the wake of the above analysis, we concluded that the
character-level and the token-level approaches are comple-
mentary and seem to cover different aspects of the detection
problem, hence sought ways of combining them. Our ﬁrst
attempt to combine the two approaches was to construct an
ensemble that combines the detection results of CNN-RNN-
FastText and 4-CNN by using the average of the scores
they assign to the input instance. The ensemble increased the
TPR on the test set to 0.835, which translates to at least 45
additional instance detections in comparison to each of the
two models by itself. Still, this is almost 6 pp lower than
the TPR of the Token-Char-FastText model (which achieves
a TPR of 0.894 on the test set). These results indicate that
feeding the DL model with both a token-level and a character-
level input representation enables it to learn features based
on combinations of signals from both levels, providing more
synergy between them than is possible by using each model
separately and feeding their scores to an ensemble.
VIII. RELATED WORK
Several recent reports by antimalware vendors surveyed the
increasing use of PowerShell as a cybersecurity attack vector
[2]–[4]. Hendler et al. [15] presented the ﬁrst detector of ma-
licious PowerShell command-lines. Their detector is based on
a DL model that employs a character-level embedding. Unlike
theirs, our detector targets the detection of general malicious
PowerShell code, visible via AMSI. General PowerShell code
included scripts and modules, in addition to command-line
code. As we’ve shown in Section III, general PowerShell code
is more volumetric and possesses a more complex structure
than command-line code.
Holmes and Bohannon [50] presented a detector of obfus-
cated PowerShell code. AMSI de-obfuscates code before it is
sent for scanning, so this approach may not be best-suited
for AMSI-based detection. Moreover, many malicious code
samples are not obfuscated and many benign PowerShell code
12
samples are. Recently, Rusak et al. [51] presented a classiﬁer
of malicious PowerShell scripts into malware families, that
is based on an Abstract Syntax Tree (AST) representation
of PowerShell scripts. Their DL model uses a small-scale
embedding of 62 types of AST node types. Unlike our work,
they do not address the problem of malicious PowerShell code
detection, nor do they use a (direct) contextual embedding of
PowerShell code.
JavaScript and VBScript are two additional widely-used
scripting languages that can be abused as attack-vectors [52].
Much of the previous work done on defending against such
attacks focuses on the detection of obfuscation [53]–[56],
rather than of maliciousness, or on the extraction of speciﬁc
features [57]–[61] that are generally not applicable to the
problem of detecting malicious PowerShell code. For example,
Cova et al. [57] present a detector for JavaScript and Drive-
By download that utilizes manually-deﬁned JavaScript-speciﬁc
features, such as the lengths of the input to the eval function,
as well as some features external to the script’s content, such
as the number of redirects when the script is executed. These
features are not applicable in our setting. More generally, DL
models make feature extraction an automatic process.
Other works propose detectors for malicious Javascript
code based on classic feature-extraction NLP techniques, see
e.g. [53], [62], [63]. We implemented and evaluated mali-
cious PowerShell-code detectors based on such techniques
(speciﬁcally, n-gram and BoW) and they were signiﬁcantly
outperformed by the other models we evaluated.
Stokes et al. [64] present a DL-based detector of malicious
JavaScript and VisualBasicScript code. They use the byte-
representation of the script as model input. They experimented
with two architectures, one using a byte-level embedding,
which is more effective for analyzing relatively-short code
sequences, and another that processes the input in longer ﬁxed-
length units before feeding it to the embedding layer. In both
cases, the embedding was learnt as part of the supervised
training. Unlike our work,
they do not employ unlabeled
data to pretrain an embedding layer and their models use an
embedding at only a single representation level. Wang et al.
[65] present a malicious JavaScript code detector that converts
JavaScript code to binary vectors (according to characters’
ASCII values), which are then being input to the DL architec-
ture. Their model does not employ a contextual embedding.
Some previous works employ DL-based detection with an
embedding stage for additional cyber-defense tasks, such as
detecting malicious PE ﬁles [66], [67], detecting malicious
URLs, ﬁle paths and registry keys [68], [69], and analyzing
sequences of security events for detecting attack steps [70].
IX. DISCUSSION
Deployment: Our best-performing model
(Token-Char-
FastText) is deployed in the antimalware vendor’s production
environment since April, 2019. During its ﬁrst 3 months of
operation, it processed over 3 billion AMSI events, raising
alerts with average precision of over 80%. The detector runs
in a cloud environment and scores AMSI events reported to it
from client endpoints. To evaluate detection scalability, we ran
our detector on a single core of a 24GB RAM Intel i7 machine.
It took it 40.2 seconds to score 10,136 AMSI events, totalling
45MB of PowerShell code, for an average of approximately
1.1MB of code per second. Since numerous AMSI events can
be classiﬁed independently of one another, our detector is
easily parallelized and scales linearly in the number of cores
assigned to it by the cloud infrastructure.
Attacks and countermeasures: An obvious evasion technique
against our detector would be to bypass AMSI altogether.
Several such attacks and countermeasures were reported (see
e.g. [20]). One way of attempting to bypass AMSI is to have
the PowerShell code do so, as we illustrated in Section II-B.
Given appropriate training examples, our detector may identify
such attempts. In addition, several antimalware vendors already
have pin-point detectors of such bypass attempts. Other types
of attacks include the replacement of system ﬁles that are
critical for AMSI’s correct operation and in-memory patching
of AMSI instrumentation [71], but those generally require
administrative privileges. Antimalware vendors are engaged
in a typical cybersecurity cat-and-mouse game with attackers
aiming to disable AMSI. While full security cannot be guar-
anteed, it is plausible to assume that AMSI bypassing attacks
will become increasingly difﬁcult over time.
As with any ML-based detection model, attackers may
attempt evasion by changing their behavior dynamically over
time. One possible way of doing so might be automatic
generation of polymorphic variants of malicious PowerShell
code. This second type of attacks can be mitigated by re-
training the model sufﬁciently often for keeping up with
changing malware trends, by using fresh, real-world examples
of both benign and malicious PowerShell code.
X. CONCLUSIONS AND FUTURE WORK
In this work, we addressed the challenge of devising an
effective malicious PowerShell detector in AMSI-enabled envi-
ronments. We presented and evaluated several novel DL-based
detectors that leverage a pretrained contextual embedding of
tokens from the PowerShell “language”. A unique feature
of these detectors is that their embedding is trained using a
dataset enriched by a large corpus of unlabeled PowerShell
scripts/modules. Our performance analysis establishes that
the usage of unlabeled data signiﬁcantly increased detection
quality. Our best model combines an embedding of language-
level
tokens with one-hot encoding of characters. Feeding
the DL model with both a token-level and a character-level
input representation enables it
to learn features based on
combinations of signals from both levels, thereby obtaining
a TPR of nearly 90% while maintaining a low FPR of less
than 0.1%. Its TPR exceeds that of the best model of [15] by
almost 10pp on AMSI-based data.
A promising avenue for future work is to investigate
whether our detection approach can ﬁnd additional cybersecu-
rity applications. As a ﬁrst step, we plan to investigate its usage
for detecting malicious code in other scripting languages, such
as JavaScript. Another interesting question is how best to strike
a balance between the sizes of the unlabeled dataset used for
embedding and the labeled dataset used for supervised training.
Several methods for embedding words into vectors have
been proposed in recent years in addition to W2V and FastText.
Devlin et al. present BERT, applying the bidirectional training
of Transformer [72] to language modeling. They present and
13
use a novel masked language model technique for conducting
bidirectional training. Unlike FastText and W2V, BERT uses
multiple hidden layers. Peters et al. present ELMo [73], an
embedding technique that constructs several vector represen-
tations for each token, one per every context
in which it
appears. ELMo uses two bidirectional LSTM layers on top
of a character-level convolution layer. Another direction for
future research is to investigate whether using either of these
two techniques can yield additional performance beneﬁts.
REFERENCES
[1] Symantec, “Attackers are increasingly living off the land,” 2017.
[2] PaloAlto, “Pulling Back the Curtains on EncodedCommand PowerShell
Attacks,” 2017.
[3] Symantec, “The increased use of Powershell in attacks,” 2016.
[4] FireEye, “Malicious PowerShell Detection via Machine Learning,”
2018.
[5] Microsoft,
“Antimalware
Scan
Interface
(AMSI),”
[6]
https://docs.microsoft.com/en-us/windows/win32/amsi/antimalware-
scan-interface-portal, 2019.
I. J. Goodfellow, Y. Bengio, and A. C. Courville, Deep Learning,
ser. Adaptive computation and machine learning. MIT Press, 2016.
[Online]. Available: http://www.deeplearningbook.org/
[7] Y. LeCun, Y. Bengio, and G. Hinton, “Deep learning,” Nature, vol. 521,
no. 7553, pp. 436–444, 2015.
J. Schmidhuber, “Deep learning in neural networks: An overview,”
Neural networks, vol. 61, pp. 85–117, 2015.
[8]
[9] T. Mikolov, I. Sutskever, K. Chen, G. S. Corrado, and J. Dean,
“Distributed representations of words and phrases and their composi-
tionality,” in Advances in neural information processing systems. NIPS,
2013, pp. 3111–3119.
J. Pennington, R. Socher, and C. Manning, “Glove: Global vectors
for word representation,” in Proceedings of the 2014 conference on
empirical methods in natural language processing (EMNLP), 2014, pp.
1532–1543.
[10]
[11] P. Bojanowski, E. Grave, A. Joulin, and T. Mikolov, “Enriching word
vectors with subword information,” Transactions of the Association for
Computational Linguistics, vol. 5, pp. 135–146, 2017.
J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova, “Bert: Pre-training
of deep bidirectional transformers for language understanding,” arXiv
preprint arXiv:1810.04805, 2018.
[12]
[13] X. Zhang and Y. LeCun, “Text understanding from scratch,” arXiv
preprint arXiv:1502.01710, 2015.
[14] R. Jozefowicz, O. Vinyals, M. Schuster, N. Shazeer, and Y. Wu,
language modeling,” arXiv preprint
limits of
“Exploring the
arXiv:1602.02410, 2016.
[15] D. Hendler, S. Kels, and A. Rubin, “Detecting malicious powershell
commands using deep neural networks,” in Proceedings of the 2018 on
Asia Conference on Computer and Communications Security. ACM,
2018, pp. 187–197.
[16] P. Bojanowski, E. Grave, A. Joulin, and T. Mikolov, “Enriching word
vectors with subword information,” arXiv preprint arXiv:1607.04606,
2016.
[17] A. Joulin, E. Grave, P. Bojanowski, and T. Mikolov, “Bag of tricks for
efﬁcient text classiﬁcation,” arXiv preprint arXiv:1607.01759, 2016.
[18] D. Bohannon
and L. Holmes,
“Revoke-Obfuscation
v1.0,”
http://bit.ly/2mfCns9, 2018.
IBM, “Ransomware Doesn’t Pay in 2018 as Cybercriminals Turn to
Cryptojacking for Proﬁt,” 2019.
[19]
[20] MDSec,
“Exploring
powershell AMSI
and
logging
evasion,”
https://www.mdsec.co.uk/2018/06/exploring-powershell-amsi-and-
logging-evasion/, 2018.
I. Goodfellow, Y. Bengio, and A. Courville, Deep learning. MIT press,
2016.