### D. Character-Level Versus Token-Level Representations

In this section, we explore the added value of character-level input representations over token-level representations and discuss how we combined these two approaches.

From Table III, it is evident that the True Positive Rate (TPR) of the 4-CNN model on the test set not only significantly surpasses that of NLP-based detectors but also exceeds the TPR of CNN architecture models by at least 2 percentage points (pp). The TPR of the 4-CNN model is comparable to that of CNN-RNN architecture models, with the CNN-RNN-FastText model outperforming it by less than 2 pp.

To better understand the added value of the character-level encoding used in the 4-CNN model, we analyze the differences in detection between the 4-CNN and CNN-RNN-FastText models. Our comparison reveals that the CNN-RNN-FastText model detects 60 code instances that are not detected by the 4-CNN model, 55 of which are true positives (TPs). Conversely, the 4-CNN model detects 34 instances (29 of which are TPs) that are not detected by the CNN-RNN-FastText model. The significant added value of the character-level model can be attributed to its ability to detect obfuscated instances in our test set that are not detectable at the token level, as we will explain next.

#### Analysis of Detection Differences

We first focus on the CNN-RNN-FastText model and discuss how it handles various PowerShell code obfuscation techniques, using specific examples from the 29 test set instances that are detected by the 4-CNN model but evade the CNN-RNN-FastText model.

FastText constructs a contextual embedding using sub-tokens, which allows it to handle one known method of PowerShell obfuscation: the use of string manipulations to construct a PowerShell command. However, in some cases, the use of sub-tokens by FastText is insufficient for detecting this type of obfuscation. Additionally, there are other PowerShell obfuscation techniques that are undetectable at the token level. We identified three such "blind spots" of FastText:

1. **Alternating Case Obfuscation**: A common technique involves using tokens with alternating lowercase and uppercase characters (e.g., `iNvOkE-wEbReQuEsT`). Since we lower-case the input before processing, token-level representations cannot detect this type of obfuscation. This was observed in 16 of the 29 instances that evaded the CNN-RNN-FastText model.

2. **Special Characters as Delimiters**: Special characters such as `+`, `[`, and `]` are considered delimiters and are absent from token-level embeddings. In 13 of the 29 missed instances, all three special characters were present. In three of these instances, we observed a relatively rare obfuscation technique where a part of the instance (containing ASCII-encoded characters) appeared in reverse order. For example, the command `"[88]rahc[+96]rahc[+37]rahc"` becomes `IEX` (an alias for `Invoke-Expression`) when reversed. Such obfuscation techniques are undetectable without considering the special characters they use.

3. **String Manipulations with Short Tokens**: String manipulations using one or two characters generally evade FastText. The minimum length of a token is 2, so a single character cannot contribute to the model. Two-character tokens are likely to appear in numerous contexts, making their embedding less effective for detection. In 12 of the 29 missed instances, tokens were constructed by concatenating multiple strings, many of which were single characters or two-character strings, thus evading FastText. An example of this obfuscation is:
   ```powershell
   '{2}{3}{0}{1}'-f 'Sc','RiPT','inVOk','E'
   'vA' + 'rI' + 'aBle:jW4v'
   ```

#### Combining Character-Level and Token-Level Approaches

Given the above analysis, we concluded that character-level and token-level approaches are complementary and cover different aspects of the detection problem. We sought ways to combine these approaches. Our first attempt was to create an ensemble that combines the detection results of the CNN-RNN-FastText and 4-CNN models by averaging their scores. This ensemble increased the TPR on the test set to 0.835, resulting in at least 45 additional instance detections compared to each model individually. However, this TPR is still almost 6 pp lower than that of the Token-Char-FastText model, which achieves a TPR of 0.894 on the test set. These results indicate that feeding the deep learning (DL) model with both token-level and character-level input representations enables it to learn features based on combinations of signals from both levels, providing more synergy than using each model separately and combining their scores in an ensemble.

### VIII. Related Work

Several recent reports by antimalware vendors have highlighted the increasing use of PowerShell as a cybersecurity attack vector [2]–[4]. Hendler et al. [15] presented the first detector of malicious PowerShell command-lines, based on a DL model with a character-level embedding. Unlike their work, our detector targets the detection of general malicious PowerShell code, visible via AMSI, including scripts and modules in addition to command-line code. As shown in Section III, general PowerShell code is more voluminous and has a more complex structure than command-line code.

Holmes and Bohannon [50] introduced a detector for obfuscated PowerShell code. Since AMSI de-obfuscates code before scanning, this approach may not be well-suited for AMSI-based detection. Moreover, many malicious code samples are not obfuscated, and many benign PowerShell code samples are. Recently, Rusak et al. [51] presented a classifier for malicious PowerShell scripts into malware families, using an Abstract Syntax Tree (AST) representation. Their DL model uses a small-scale embedding of 62 types of AST node types. Unlike our work, they do not address the problem of detecting malicious PowerShell code, nor do they use a direct contextual embedding of PowerShell code.

JavaScript and VBScript are two additional widely-used scripting languages that can be abused as attack vectors [52]. Much of the previous work on defending against such attacks focuses on detecting obfuscation [53]–[56] rather than maliciousness, or on extracting specific features [57]–[61] that are not applicable to detecting malicious PowerShell code. For example, Cova et al. [57] present a detector for JavaScript and Drive-By downloads that uses manually-defined JavaScript-specific features, such as the lengths of the input to the `eval` function, and external features like the number of redirects during script execution. These features are not applicable in our setting. Generally, DL models automate feature extraction.

Other works propose detectors for malicious JavaScript code based on classic NLP techniques, such as n-grams and Bag-of-Words (BoW) [53], [62], [63]. We implemented and evaluated malicious PowerShell-code detectors based on these techniques, and they were significantly outperformed by the other models we evaluated.

Stokes et al. [64] present a DL-based detector for malicious JavaScript and VisualBasicScript code, using the byte-representation of the script as input. They experimented with two architectures: one using a byte-level embedding, which is more effective for short code sequences, and another that processes longer fixed-length units before feeding them to the embedding layer. In both cases, the embedding was learned during supervised training. Unlike our work, they do not use unlabeled data to pretrain an embedding layer, and their models use an embedding at only a single representation level. Wang et al. [65] present a malicious JavaScript code detector that converts JavaScript code to binary vectors (based on ASCII values), which are then input to the DL architecture. Their model does not employ a contextual embedding.

Some previous works use DL-based detection with an embedding stage for additional cyber-defense tasks, such as detecting malicious PE files [66], [67], malicious URLs, file paths, and registry keys [68], [69], and analyzing sequences of security events for detecting attack steps [70].

### IX. Discussion

**Deployment**: Our best-performing model (Token-Char-FastText) has been deployed in the antimalware vendor's production environment since April 2019. During its first three months of operation, it processed over 3 billion AMSI events, raising alerts with an average precision of over 80%. The detector runs in a cloud environment and scores AMSI events reported from client endpoints. To evaluate detection scalability, we ran the detector on a single core of a 24GB RAM Intel i7 machine. It took 40.2 seconds to score 10,136 AMSI events, totaling 45MB of PowerShell code, achieving an average of approximately 1.1MB of code per second. Since numerous AMSI events can be classified independently, our detector can be easily parallelized and scales linearly with the number of cores assigned by the cloud infrastructure.

**Attacks and Countermeasures**: An obvious evasion technique against our detector would be to bypass AMSI altogether. Several such attacks and countermeasures have been reported [20]. One way to bypass AMSI is to have the PowerShell code do so, as illustrated in Section II-B. Given appropriate training examples, our detector may identify such attempts. Additionally, several antimalware vendors have pinpoint detectors for such bypass attempts. Other types of attacks include replacing system files critical for AMSI's correct operation and in-memory patching of AMSI instrumentation [71], which generally require administrative privileges. Antimalware vendors are engaged in a typical cybersecurity cat-and-mouse game with attackers aiming to disable AMSI. While full security cannot be guaranteed, it is plausible to assume that AMSI bypassing attacks will become increasingly difficult over time.

As with any ML-based detection model, attackers may attempt evasion by dynamically changing their behavior. One possible method might be the automatic generation of polymorphic variants of malicious PowerShell code. This type of attack can be mitigated by retraining the model frequently to keep up with changing malware trends, using fresh, real-world examples of both benign and malicious PowerShell code.

### X. Conclusions and Future Work

In this work, we addressed the challenge of developing an effective malicious PowerShell detector in AMSI-enabled environments. We presented and evaluated several novel DL-based detectors that leverage a pretrained contextual embedding of tokens from the PowerShell "language." A unique feature of these detectors is that their embedding is trained using a dataset enriched by a large corpus of unlabeled PowerShell scripts/modules. Our performance analysis shows that the use of unlabeled data significantly increased detection quality. Our best model combines an embedding of language-level tokens with one-hot encoding of characters. Feeding the DL model with both token-level and character-level input representations enables it to learn features based on combinations of signals from both levels, achieving a TPR of nearly 90% while maintaining a low FPR of less than 0.1%. Its TPR exceeds that of the best model in [15] by almost 10 pp on AMSI-based data.

A promising avenue for future work is to investigate whether our detection approach can find additional cybersecurity applications. As a first step, we plan to explore its usage for detecting malicious code in other scripting languages, such as JavaScript. Another interesting question is how to best balance the sizes of the unlabeled dataset used for embedding and the labeled dataset used for supervised training. Recent advancements in word embedding, such as BERT [72] and ELMo [73], offer new directions for future research to determine if they can provide additional performance benefits.

### References

[1] Symantec, “Attackers are increasingly living off the land,” 2017.
[2] PaloAlto, “Pulling Back the Curtains on EncodedCommand PowerShell Attacks,” 2017.
[3] Symantec, “The increased use of Powershell in attacks,” 2016.
[4] FireEye, “Malicious PowerShell Detection via Machine Learning,” 2018.
[5] Microsoft, “Antimalware Scan Interface (AMSI),” https://docs.microsoft.com/en-us/windows/win32/amsi/antimalware-scan-interface-portal, 2019.
[6] I. J. Goodfellow, Y. Bengio, and A. C. Courville, Deep Learning, ser. Adaptive computation and machine learning. MIT Press, 2016. [Online]. Available: http://www.deeplearningbook.org/
[7] Y. LeCun, Y. Bengio, and G. Hinton, “Deep learning,” Nature, vol. 521, no. 7553, pp. 436–444, 2015.
[8] J. Schmidhuber, “Deep learning in neural networks: An overview,” Neural networks, vol. 61, pp. 85–117, 2015.
[9] T. Mikolov, I. Sutskever, K. Chen, G. S. Corrado, and J. Dean, “Distributed representations of words and phrases and their compositionality,” in Advances in neural information processing systems. NIPS, 2013, pp. 3111–3119.
[10] J. Pennington, R. Socher, and C. Manning, “Glove: Global vectors for word representation,” in Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP), 2014, pp. 1532–1543.
[11] P. Bojanowski, E. Grave, A. Joulin, and T. Mikolov, “Enriching word vectors with subword information,” Transactions of the Association for Computational Linguistics, vol. 5, pp. 135–146, 2017.
[12] J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova, “Bert: Pre-training of deep bidirectional transformers for language understanding,” arXiv preprint arXiv:1810.04805, 2018.
[13] X. Zhang and Y. LeCun, “Text understanding from scratch,” arXiv preprint arXiv:1502.01710, 2015.
[14] R. Jozefowicz, O. Vinyals, M. Schuster, N. Shazeer, and Y. Wu, “Exploring the limits of language modeling,” arXiv preprint arXiv:1602.02410, 2016.
[15] D. Hendler, S. Kels, and A. Rubin, “Detecting malicious powershell commands using deep neural networks,” in Proceedings of the 2018 on Asia Conference on Computer and Communications Security. ACM, 2018, pp. 187–197.
[16] P. Bojanowski, E. Grave, A. Joulin, and T. Mikolov, “Enriching word vectors with subword information,” arXiv preprint arXiv:1607.04606, 2016.
[17] A. Joulin, E. Grave, P. Bojanowski, and T. Mikolov, “Bag of tricks for efficient text classification,” arXiv preprint arXiv:1607.01759, 2016.
[18] D. Bohannon and L. Holmes, “Revoke-Obfuscation v1.0,” http://bit.ly/2mfCns9, 2018.
[19] IBM, “Ransomware Doesn’t Pay in 2018 as Cybercriminals Turn to Cryptojacking for Profit,” 2019.
[20] MDSec, “Exploring powershell AMSI and logging evasion,” https://www.mdsec.co.uk/2018/06/exploring-powershell-amsi-and-logging-evasion/, 2018.
[21] I. Goodfellow, Y. Bengio, and A. Courville, Deep learning. MIT press, 2016.