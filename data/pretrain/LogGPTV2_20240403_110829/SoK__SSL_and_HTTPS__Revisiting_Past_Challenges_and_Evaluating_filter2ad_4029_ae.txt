TLS session, which requires knowledge of the corresponding
private key. OBCs were then revised (for details not pertinent
to preventing MITM cookie theft) and renamed Channel
ID. The channel-bound credential primitive has also been
proposed for use in conjunction with a user device: e.g., a
token [78] or smartphone [81].
Credential-bound Channels: Credential-bound channels
prevent credential theft from MITM adversaries by reversing
the idea of channel-bound credentials—instead of having the
server decide to accept a credential based on its binding
to a client certiﬁcate, the client decides whether to accept
a server certiﬁcate based on its binding to the client’s
credential. This primitive assumes a pre-shared password
(and does not protect the password during the initial es-
tablishment). In one proposal called direct validation of
certiﬁcates (DVCert)25 [33], the server uses a PAKE-based
protocol to demonstrate knowledge of the client’s password
while attesting to the value of its certiﬁcate.26
Key Agility/Manifest: When preventing MITM attacks
without involving the server (i.e., through inductive client
pinning or multipath probing), it is difﬁcult to distinguish
attacks from legitimate reasons that a different certiﬁcate
may be observed at different times (certiﬁcate update) or
from different locations on the network (multiple certiﬁ-
cates used by the same host). At the cost of server-side
changes, many of the examples of the primitives evaluated
thus far address these issues with (i) a “key manifest,”
i.e., a speciﬁcation of all keys that could be used by the
domain; and/or key agility, i.e., an update mechanism for
new certiﬁcates that could be implemented as either (ii)
signing the new certiﬁcate with the old certiﬁcate’s key, or
(iii) linking the certiﬁcate changes through use of a master
secret. One or more of these can be seen in: server-side key
pinning, TACK, DANE, and DVCert. The Sovereign Key
proposal [11] is also similar to (iii), in that servers establish
and broadcast a long-term signing key used to cross-certify
all their certiﬁcates. Although Table I evaluates the primitive
in isolation, in these examples, it is combined with another
primitive, e.g., key pinning or multipath probing, to detect
MITM attacks while eliminating false-reject errors due to
certiﬁcate updates and load-balancing.
HTTPS-only Pinning (All Types): The primitives consid-
ered above do not address (or attempt to) TLS stripping
attacks. This is largely because the primitives are never
invoked unless an HTTPS connection is requested. With
TLS stripping, this stage is never reached for the client.
The chief mechanism for preventing TLS stripping is to
make certain domains only support TLS and communicate
this to clients with a pin. As with key pins, HTTPS-
only pins can be communicated by the server in request
headers or TLS extensions, pre-established in the user’s
browser, or obtained from the DNS record of the site.
Proposals for all three types exist: ForceHTTPS [56] and its
reﬁnement in HSTS [8] are server-initiated pins; Chrome 22
ships with over 100 HTTPS-only pins; and Service Security
Requirement (SSR) [4], [80] records can specify (among
other things) that a site is HTTPS-only in its DNS record
(signed through DNSSEC). Some browser extensions, like
HTTPS Everywhere, redirect the HTTPS version of sites
according to a curated whilelist of domains.
Beyond TLS stripping, HTTPS-only pins can also ensure
a cookie scoped to the domain of the pin is always sent
over HTTPS, regardless of whether the website developer
remembered to mark the cookies as secure [56], [67].
Visual Cues for Secure POST: A simple client-side prim-
itive can address certain types of TLS stripping. Sites are
frequently designed to cause login credentials to be POSTed
to an HTTPS site from an HTTP site. A persistent security
cue could be introduced to indicate if a form POSTs to
HTTP or HTTPS (beyond the easily-disengaged warning
upon an initial POST-to-HTTP). One proposal, the SSLight
browser extension [91], adds a “trafﬁc light” cue to login
form ﬁelds that displays a green light if and only if the
ﬁeld is posted to the current domain over HTTPS (a yellow
light indicates cross domain HTTPS posts and red indicates
POST-to-HTTP). Note that the browser needs to retrieve
the site certiﬁcates associated with all POSTs on the page,
largely nullifying the main performance beneﬁt from not
serving the landing page over HTTPS to begin with. Further,
the choice of displaying the cue in the login form ﬁeld itself,
which is part of the site content, risks a malicious modiﬁed
site obscuring the real cue and spooﬁng its own (cf. [109]).
Browser-stored CRL: Four prominent long-standing re-
vocation approaches are [77]: CRLs, online certiﬁcate status
checking, short-lived certiﬁcates, and trusted directories. The
CA/B model uses the ﬁrst two through CRLs and OCSP
respectively. Given the shortcomings of current revocation
procedures (Section IV-D), attention to improving the re-
sponsiveness of revocation is being pursued along the lines
of all four types. Browser-stored CRLs fall under the ﬁrst
(CRLs), modifying the architecture of CRL distribution from
the current CA/B model. Instead of user clients fetching
CRLs (and OCSP responses) directly from CRL distribution
points, the browser vendor fetches these periodically and
sends to the browser an updated master CRL for storage.
All major browsers manually revoke high risk certiﬁcates
through software updates, but Chrome has implemented a
more general CRL that can be transparently updated.27
Certiﬁcate Status Stapling: In the same way that Browser-
stored CRL is an architectural change to how CRLs are
distributed in the current CA/B model, Certiﬁcate Sta-
tus Stapling modiﬁes the distribution of OCSP responses.
25This is not to be confused with domain validation (DV) certiﬁcates.
26This is better than the server MACing its certiﬁcate with the shared
password, which would admit an ofﬂine password dictionary attack.
27A. Langley, “Revocation checking and Chrome’s CRL,” Imperial Violet
(blog), 05 Feb 2012.
521
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:51:35 UTC from IEEE Xplore.  Restrictions apply. 
Currently, a user client requests a status report from a
CA-designated OCSP responder, but responders are often
overwhelmed or do not usefully respond, in which case,
the HTTPS connection typically completes without warning.
Under Certiﬁcate Status Stapling,
the certiﬁcate holders
periodically obtain signed and timestamped status reports,
and include these with their certiﬁcate during a handshake
(cf. [88]). Within HTTPS, this is deﬁned as a TLS exten-
sion [2] and commonly called OCSP-stapling. The RFC
only permits a report on the server certiﬁcate, not the entire
chain—a signiﬁcant drawback. However Table I evaluates
the general idea of stapling reports on the entire chain.
Short-lived Certiﬁcates: This primitive, representing the
third type of revocation, replaces long-lasting certiﬁcates
with short-lived ones that certiﬁcate holders frequently re-
new [88]. Revocation results from simply failing to update
a certiﬁcate. In a recent proposal and implementation for
short-lived HTTPS certiﬁcates [101], servers are issued
certiﬁcates with a four-day lifespan (roughly the lifetime of
common cached OCSP responses) either on-demand or in
batches. It is proposed [101] to be used in conjunction with
Browser-stored CRL and Key Pinning (Server).
List of Active Certiﬁcates: The fourth revocation method
is trusted directories, by which we mean a publicly search-
able list of valid certiﬁcates. In HTTPS,
this could be
implemented as a whitelist of every server and CA TLS
certiﬁcate (including intermediates) that is acceptable to the
HTTPS clients that rely on this list. A certiﬁcate not on
the list is not acceptable in any part of the certiﬁcate chain.
Revocation is accomplished by removing the certiﬁcate from
the list. This primitive makes visible all intermediate CAs,
and also allows domain owners to monitor for illegitimately-
issued certiﬁcates for their domains. No proposal for full-
ﬂedged List of Active Certiﬁcates has been made. It is similar
to Certiﬁcate Transparency [6] (see above) but differs on the
issue of revocation: the CT log is meant only as a reference
for discovering suspicious certiﬁcates, not an authoritative
whitelist for making trust decisions. Also CT currently logs
site certiﬁcates only, which means intermediate CAs are
visible only if they issue site certiﬁcates.
VI. FURTHER DISCUSSION AND ON-GOING RESEARCH
Further discussion here ﬁrst mentions research areas or-
thogonal to our main focus on HTTPS and its certiﬁcate trust
model. We then discuss primary areas of ongoing research.
1) Important Orthogonal Problems: The original objec-
tive [84] of HTTPS was to provide a conﬁdential channel
with message integrity and server authentication. However
HTTPS does not bridge the cognitive gap (exposed by phish-
ing, even with the presence of TLS certiﬁcates) between the
user’s cognitive notion of what organization they intend to
connect with, and the domain name within the content of
a certiﬁcate—and the latter is the only information in DV
certiﬁcates that can be relied on. (It is interesting to ask: does
identiﬁcation of a syntactic domain name deliver the desired
property of “server authentication”?) As for the extremes,
many websites do not use TLS at all, while for the minority
that use EV-SSL certiﬁcates, the validated organizational
details are arguably insufﬁcient—they are not referenced by
users, nor typically endorsed by CAs familiar to users, even
if users did understand how certiﬁcates were meant to work.
For these reasons, TLS in its present form fails to close this
cognitive gap. It remains an open research problem to ﬁnd
methods to address this issue.
HTTPS can protect the secrecy and integrity of cookies in
transit; browser policy dictates the conditions for read/write
access to cookies marked as secure. Likewise, browsers must
handle mixed content carefully, including how/when to alert
users—e.g., different policy decisions are needed to handle
the mixing of secured and unsecured content according to
three delivery mechanisms (no TLS, TLS, and EV TLS) and
different content types (e.g., images, objects, scripts). Cookie
security and mixed content remain challenging problems.
A compromised client-platform (e.g., due to malware) can
subvert HTTPS protections, including how protections are
communicated to the user. Research on building veriﬁed
kernels, trusted modules, and/or trusted paths into client
platforms therefore complements HTTPS. Other orthogonal
issues include the availability of the HTTPS infrastructure
(e.g., DDOS attacks, restrictive networks, captive portals)
and improving performance (e.g., False Start, Snap Start).
2) Protocol-level TLS–Analysis and Modiﬁcation: The
complexity of TLS has signiﬁcantly enabled protocol at-
tacks, even after 15 years. Analysing TLS security in suf-
ﬁciently broad models remains an open research problem.
Among other challenges, designing a protocol with provable
security is easier than proving the security of a ﬁxed protocol
like TLS; many proof techniques require simplifying as-
sumptions or the ability to make at least minor modiﬁcations.
Security analysis of the basic functionality of TLS [105],
[75], [82], [52], [26], [76], [48], [47], [58], [50] and its use
of cryptographic primitives [65], [60] has provided results
both positive (security proofs) and negative (attacks).
The discovery of ﬂaws in non-essential or little-used
components of TLS has produced a culture of work-arounds
by disabling features (e.g., renegotiation, CBC-mode cipher-
suites, and compression as cited earlier) rather than protocol
redesign. Such quick ﬁxes are at the expense of long-term
protocol evolution: e.g., as of 2011, 99.6% of HTTPS sites
did not yet support TLS 1.1 or 1.2 [87].
Some aspects of TLS are agile, e.g., AES adoption
was “quick” [68] due to a pre-existing ability to negotiate
blockciphers. Other aspects, however, are not agile, e.g., the
two hashes used for pseudorandomness (MD5 and SHA1)
in TLS 1.0 are non-negotiable, impeding SHA2/3 adoption;
and likewise, the RSA padding format used for key transport
impedes OEAP support [85], [25]. An open challenge is how
to expedite protocol upgrades; TLS 1.2 adds agility but had
522
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:51:35 UTC from IEEE Xplore.  Restrictions apply. 
only a 0.02% adoption rate in 2011 [87].
3) Trust Model Infrastructure: Critical research questions
remain regarding the CA/B trust model—is its continued
use unavoidable, does it still solve more problems than it
creates, or has it become a liability? In the real world, trust
is transitive in at most short chains whereas the CA/B model
allows long chains. But even in a chain involving only one
intermediate CA, the end-user, de facto, ends up ‘trusting’
the browser vendor who sets hundreds of trust anchors in
the browser, the corresponding anchor CAs for endorsing
thousands of intermediate CAs, and these intermediate CAs
for certifying millions of websites. The end-user, as a relying
party, in many cases would have no knowledge of or business
relationship with CAs involved in these chains, and the CAs
are apparently not accountable to end-users for errors. It is
also worth remembering that in the original CA/B model,
there were only a handful of CAs.
For better or worse, we have achieved spontaneity, one of
the original goals [84] of TLS—an online world with great
convenience. In fact, users can now go online for the ﬁrst
time and without any personal choices, ‘trust’ millions of
sites. It would be unreasonable to expect this in the physical
world; is it a realistic reﬂection of trust in the digital world?
Progress is being made—e.g., on increasing the transparency
of the anchor selection process (e.g., Mozilla’s policies
and public discussion for CA inclusion), indexing active
CAs on the public internet [39], and providing users with
conﬁgurable (and potentially delegatable [71]) trust anchors.
4) Human Element and the Security User Interface: Once
CA trust anchors are somehow conﬁgured, browsers can
automate many HTTPS security decisions, while providing
to users status indicators through its interface. However, for a
range of ‘soft’ errors—e.g., expired certiﬁcates, mismatched
domains, mixed content/scripting, untrusted CAs (includ-
ing self-signed)—it
remains without consensus whether
browsers should fail open (with or without an indicator), fail
closed, or provide a warning dialogue. Research reviewed
in Section IV-E indicates low user conﬁdence in navigating
the current set of indicators and warnings. Testing defaults,
UI changes, and the wording of warning dialogues requires
further research, as well as protocol ‘ceremony’ [41], [63],
[83] analysis that includes humans.
The challenges in designing usable security interfaces hint
at a deeper problem with users’ mental models of HTTPS.
Experts can understand the relationship between encryption
and authentication in TLS, and that a lock icon does not
indicate that a website is safe in all senses. The inability of
the community to provide interfaces and/or mechanisms that
average users can understand remains problematic.
5) Raising the Bar (or Just Moving It): Many of the
practical security issues with today’s CA/B infrastructure
result from a lack of defence in depth—e.g., the compromise
of a single CA defeats many current deployments of the
model. Many of the enhancements in Table I aim to add
depth by addressing MITM attacks, TLS stripping attacks,
and revocation issues. Combining several primitives into the
current infrastructure (e.g., in an attempt to fully address
MITM) offers the advantage of increasing protection, at the
cost of a patchwork with increased complexity. A different
approach is to seek alternatives that replace the functionality
of CAs outright; in fact, some primitives in the table might
be viewed as doing this.
A currently high proﬁle approach that might be viewed
as doing this is DNSSEC-based pinning (e.g., DANE),
which provides an infrastructure for ubiquitous HTTPS,
largely replacing the need for CA-issued DV certiﬁcates.
(Of course, many questions remain regarding performance,
caching, and packet inspection if this were to be widely
deployed or enabled by default.) It could be argued that the
serious consideration currently being given to DANE signals
the degree to which trust in CA-validated certiﬁcates has
slipped, rather than the strength of DANE as an alternative.
DNS pinning by itself falls short of fully addressing the
original HTTPS goal related to authentication, namely to
support the transport of sensitive data to only an intended
party. As mentioned above in relation to phishing,
the
intended target is not often identiﬁed by a domain name
in the user’s mind, but rather by the user’s conception
of a real-world entity. The extent to which high-assurance
extended validation certiﬁcates can be leveraged to provide
recognizable assurances to users remains an open question.
VII. CONCLUDING REMARKS
Among our objectives, we hope to raise awareness of
the number and breadth of past and on-going security
issues with HTTPS and its certiﬁcate trust model, allowing
independent determination of their relative severities and