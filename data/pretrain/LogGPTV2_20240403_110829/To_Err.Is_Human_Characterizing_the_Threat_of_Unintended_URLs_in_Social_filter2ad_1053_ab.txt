Figure 2 provides an example attack scenario for the
type of vulnerability studied in this paper. First, a Twitter
3
NX Test URLs
X Test URLs
Linkedin
Twitter
Snapchat
Whatsapp Web
Slack
Facebook
Whatsapp Mobile
notdomain.net
notdomain.Net
notdomain.dev
notdomain.Dev
sub.notdomain.net
sub.Notdomain.Net
sub.notdomain.dev
sub.Notdomain.Dev
5.net
5.dev
www.notdomain.dev
notdomain.notatld
www.web.dev
-
php.net
php.Net
web.dev
web.Dev
windows.php.net
windows.Php.Net
auth.web.dev
auth.Web.Dev
123.net
1.dev
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
U
C
C
U
U
C
C
U
U
C
U
C
U
Telegram
Skype
Google Hangouts
C
U
C
U
C
U
C
U
C
C
C
U
U
U
U
U
U
U
U
U
U
U
C
U
TABLE I: Unintended URL test results on different social media and messaging platforms. “U” depicts test URL is not clickable after posting
whereas “C” depicts test URL is clickable after posting on the particular platform.
In this section, we describe our process for curating this
ground truth dataset and the features that we use for our clas-
siﬁer. We then present the accuracy of the resulting classiﬁer
and how we use it to measure the phenomenon and abuse
of unintended URLs in the wild. Our analysis pipeline is
illustrated in Figure 3.
A. Automatically Detecting Unintended URLs on Twitter
To study the threat of unintended URLs on Twitter at scale,
we ﬁrst need to be able to automatically distinguish between
unintended and intended URLs. To this end, we develop a
machine learning model.
We manually label and analyze Twitter data to identify
promising features for our model and develop a ground truth
set. To build our model, we follow three steps: i) data gath-
ering, ii) preﬁltering, and iii) feature engineering. These steps
are described in detail in the rest of this section.
a) Data Gathering: We collect the 1% sample of all
public tweets posted worldwide using the Twitter streaming
API [3] between January 2020 and July 2020. To build our
ground-truth dataset, we extract ﬁve days of data from the
collected tweets. This set consists of approximately 20M
tweets of which around 3M (15%) containing URLs.
We use this set
to gain insights about
the differences
between unintended URLs and intentional URLs. Our obser-
vations in this step helped us to identify preﬁltering conditions
and design model features.
b) Preﬁltering: We ﬁrst apply a preﬁltering procedure
to our set of tweets to remove links that are unlikely to be
unintentional, based on our threat model and our preliminary
observations. This step of our model-developing stage allows
us to have a simpler and more accurate model without unnec-
essary features.
In this step, we ﬁrst ﬁlter out the tweets that do not contain
any URL since those tweets are not of interest for this work.
This leaves us with approximately 3 million tweets per day.
Then we apply the following ﬁlters:
•
URLs starting with “www”: We discard the tweets
that have URLs starting with “www” since “www” is
4
Fig. 2: Attack scenario on how an attacker (Mallory) can weaponize
the unintended URLs posted by a user (Alice) to expose Alice’s
followers (such as Bob) to malicious content.
user (Bob) follows Alice on Twitter (Step 1) who, at some
point, posts a tweet containing an unintended URL (Step
2). Mallory observes this, registers the unintended domain
(NDSS2021.how in our example) controlling that URL, and
points it to a malicious server (Step 3). Eventually, Alice’s
tweet appears on Bob’s timeline (Step 4) who clicks on the link
and is now exposed to Mallory’s malicious content (Step 5).
If Alice’s followers retweet Alice’s tweet (either because they
did not pay attention to the URL or because they retweeted it
before Mallory registered it) the reach of that unintended URL
can increase exponentially.
III. METHODOLOGY
As we show in the previous sections, the threat of un-
intended URLs in social media is a real one, not just for
the average Twitter user, but for accounts with millions of
followers. To be able to characterize this phenomenon in the
wild, we must ﬁrst compile a ground truth dataset containing
Tweets with intended and unintended URLs. We will then use
this ground truth to train a classiﬁer able to automatically
identify unintended URLs on Twitter.
Alice@aliceMy paper got accepted atNDSS2021.Howexciting!AliceBobMallory21345Fig. 3: System Diagram: Twitter data is collected daily throughout the experiment. We extract ﬁve days of tweets from the Twitter 1% streaming
API. We then apply preﬁltering to this set. The resulting tweets are labeled manually to get the ground truth set and features are obtained.
We then train a linear SVM classiﬁer to obtain the ﬁnal model. We use this model to get unintended domain predictions for the rest of the
experiment. Then, we register unintended domains if suitable, and monitor the trafﬁc to these domains. For those unintended domains that
have a third party website pointing to them, we crawl their home pages and record screenshots. From the obtained information, we cluster
unintended domains. Finally, we develop a mitigation by building a Chrome extension using our ﬁnal model.
•
•
•
not a dictionary word and therefore someone who
explicitly types “www” is clearly intending to post a
URL.
Non-English tweets: For this paper, we focus on
Twitter accounts that tweet in English. This allows
us to reason about the intended/unintended nature of
URLs using common grammar rules as well as later
utilize NLP tools that work best on English corpus.
Understanding whether unintended URLs happen in
other languages is an interesting path for future work
but outside the scope of this paper. After ﬁltering out
non-English texts, we keep approximately 1.1 million
tweets.
URLs with paths and/or subdomains higher than
third-level: We eliminate a tweet
if it only con-
tains URLs with paths and/or subdomains higher than
third-level. During our manual investigation of URL-
including tweets we observe that in nearly all cases,
URLs with paths and subdomains (higher than third-
level) were clearly intentionally posted by users.
URLs having “com” or “org” as TLDs: Even
though “com” and “org” are part of the English
dictionary (“com” as a preﬁx and “org” as an ab-
breviation) they are not particularly popular outside
intentional URLs. As such, we ﬁlter any URLs that
ended in these TLDs.
•
URLs having TLDs that are not dictionary words:
Given that our intuition is that unintended URLs
are constructed by concatenating real words, we also
ﬁlter URLs with TLDs that are not English dictionary
words.
After preﬁltering, we identify a set of 1,068 tweets that
potentially contain unintended URLs. To determine which of
these URLs are indeed unintended, we follow an inductive
approach, with three authors of this paper discussing them
until a good agreement is reached. After this process, our ﬁnal
ground truth set is labeled as 644 tweets containing intended
URLs and 424 containing unintended URLs.
c) Feature Engineering: After determining our ground
truth set, we aim to develop features that can characterize
tweets containing intended and unintended URLs, with the
goal of performing automated detection of the latter class.
To determine the ﬁrst batch of features, we go through our
initial set of pre-ﬁltered tweets and gather statistics for tweets
containing unintended URLs such as common TLDs, DNS
responses, string properties, location of the URL inside tweet
text, etc. Then, to reﬁne our features, we manually investigate
our ground truth dataset to identify new features and have
more accurate classiﬁcation. We test our model on the labeled
ground truth set to ﬁne-tune the features. We repeat the process
of investigating daily collected tweets and adding new features,
and removing features with low effect until we are satisﬁed
with the overall accuracy and the simplicity of our features.
After this process is completed, we have the following features:
5
•
•
•
•
•
DNS Response. We observe that many of the unin-
tended URLs correspond to non-existing domains. To
ﬁgure out whether a domain is registered, we check
whether that domain had name server (NS) records.
This allows us to conclude that a domain was either
registered/un-registered, irrespective of whether that
domain resolved when regular users were visiting (i.e.,
had A/AAAA records in place).
Sentence Segmentation. If the ﬁrst part of a link
logically belongs to one sentence whereas the text of
the remainder of that link belongs to the next sentence,
this link has a high likelihood to be an unintended
one. We use a tool called Deepsegment [4] to extract
the sentences out of a tweet, treating URLs as regular
text. Our preliminary results with the tool indicate
that Deepsegment has a 97% segmenting accuracy
if the punctuation is correct, 71% accuracy if the
punctuation is partially correct and 53% accuracy if
there is no punctuation in the tweet. For this binary
feature, we mark it as positive if parts of the URL
is at the end of one sentence and the remaining part
forms the beginning of the next sentence.
String Properties. We identify ﬁve characteristics of
strings that are either indicative of intended or unin-
tender URLs, and codify them as binary features. iThe
following characteristics are indicative of intended
URLs:
◦
◦
Any of the subdomains or the domain contains
a dash.
Subdomains and domains are in camelcase
(contains a mix of capital and non-capital
letters).
Whereas the following characteristics are indicative of
unintended URLs:
◦
◦
◦
The length of both the subdomains and domain
are at most two (i.e., contains two or fewer
characters).
Subdomains and domains are English words or
numbers.
The link contains a non-capital letter followed
by a dot followed by a capital letter (i.e., [a-
z].[A-Z])
Repetition of URL. Another binary feature is set to
True/False depending on whether a URL appears more
than once in the tweet. We consider it unlikely that a
user will accidentally introduce the same URL twice
in a single tweet.
Location of URL. We use three different binary
features identifying the location of the URL inside
tweet text. The URL can be at the beginning, in the
middle, or at the end of the text. URLs that are at the
end of the text tend to be intended ones (such as when
someone explains what they are posting and ending
the tweet with a link to that post) whereas the ones
that are in the middle tend to be unintended. Here,
the full stops that users are using to mark the end of
a sentence are more likely to be recognized as part of
a URL, when whitespace is missing after them.
6
•
TLD Type. Other than the preﬁltering for “com”
and “org” TLDs, we use ten binary features for the
following ten different TLDs: “net,” “co,” “gov,”
“it,” “my,” “no,” “so,” “you,” “to” and “zip.”
The reason for explicitly converting these TLDs into
features is two-fold. First, the TLDs such as “it,” “my,”
“no,” “so,” “you” and “to” are English words that
are also likely to be used at the beginning of sentences.
As such, URLs including these TLDs have a high
likelihood of being unintended. Second, TLDs such as
“net,” “co,” “gov” and “zip” are not usually used
at the beginning of sentences and hence are likely to
be found in intended URLs.
We train and test our model on our ground truth dataset.
We experiment with a random forest classiﬁer [31], a decision
tree classiﬁer [44], a k-nearest neighbors classiﬁer [9] and
support vector machines (SVMs) with different kernels [49].
We use 10-fold cross-validation to test the performance of
each classiﬁer and obtained the highest accuracy with an SVM
model using a linear kernel. Our classiﬁer uses binary features
and outputs a binary number corresponding to two classes
namely unintended (binary 1, positive) and intended (binary