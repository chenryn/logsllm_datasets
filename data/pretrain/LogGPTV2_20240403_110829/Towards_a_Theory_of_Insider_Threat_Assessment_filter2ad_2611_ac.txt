then
f lag   0
for each vi 2 NEIGHBOR(S)
do vertex_cost   NEW-VERTEX-COST(vi)
GREEDY-HEURISTIC(KG)
1
2 M   UPDATED-ADJ-MATRIX(KG;p(S))
3 A   APSP(M)
4 min_cost   A[v0;vs]
for round   1 to jV j
5
6 do
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
new_vertex   vi
f lag   1
else return min_cost
S   S S fnew_vertexg
return min_cost
if f lag = 1
M0   UPDATED-ADJ-MATRIX(KG;p(S S fvig))
8v j 2 S; M0[v j;vi]   0; M0[vi;v j]   0
A0   APSP(M0)
if (vertex_cost +A0[v0;vs]) < min_cost
then min_cost   vertex_cost +A0[v0;vs]
Table 3. A greedy heuristic to (cid:2)nd cost of
near›optimal key sequence
4.3 Algorithm Benchmarking
We have performed empirical evaluations to compare
BRUTE-FORCE with GREEDY-HEURISTIC. Our experi-
ments were conducted on a Pentium 4/3GHz/1GB RAM
running RedHat Linux 9.1. Since the BRUTE-FORCE
algorithm has a prohibitively expensive running time,
we have limited the size of the input to only 15 nodes.
Our test data set consists of 1000 simulation runs and
each run generates a random instance of a key challenge
graph. We have compared the quality of the solutions
(see Figure 4) computed by the two algorithms as well
as their running times (see Figure 5).
When comparing the attack costs returned by the two
algorithms, we have used randomly generated key chal-
lenge graphs of exactly 15 nodes for all the 1000 runs.
8
In Figure 4, there are two distinct bands, a lower one
which corresponds to the optimal attack costs returned
by BRUTE-FORCE and a higher one which represents
the attack costs returned by GREEDY-HEURISTIC. The
gap is due to the inapproximability results as shown in
Section 4. GREEDY-HEURISTIC worked very well when
the (cid:2)nal attack sequence is very small (3-4 nodes) and
this seems to be the best case scenario for the heuris-
tic algorithm. However, when the attack sequence is
long (10-15 nodes), the heuristic produces a larger gap
from the optimal solution. The explanation we give for
this observation is that longer the sequence, greater the
chances that the decision-making procedure will make
errors which are compounded.
t
t
s
s
o
o
C
C
k
k
c
c
a
a
t
t
t
t
A
A
)
)
s
s
c
c
e
e
s
s
(
(
e
e
m
m
T
T
i
i
 400
 400
 350
 350
 300
 300
 250
 250
 200
 200
 150
 150
 100
 100
 50
 50
 0
 0
BRUTE-FORCE
BRUTE-FORCE
GREEDY-HEURISTIC
GREEDY-HEURISTIC
 100
 100
 200
 200
 300
 300
 400
 400
 500
 500
 600
 600
 700
 700
 800
 800
 900
 900
 1000
 1000
Run Number
Run Number
Figure 4. GREEDY-HEURISTIC vs BRUTE-
FORCE: Minimum cost of an attack
 800
 800
 750
 750
 700
 700
 650
 650
 600
 600
 550
 550
 500
 500
 450
 450
 400
 400
 350
 350
 300
 300
 250
 250
 200
 200
 150
 150
 100
 100
 50
 50
 0
 0
BRUTE-FORCE
BRUTE-FORCE
GREEDY-HEURISTIC
GREEDY-HEURISTIC
 0
 0
 1
 1
 2
 2
 3
 3
 4
 4
 5
 5
 6
 6
 7
 7
 8
 8
 9
 9
 10  11  12  13  14  15
 10  11  12  13  14  15
Run Number
Run Number
Figure 5. GREEDY-HEURISTIC vs BRUTE-
FORCE: Running time behavior
When comparing the running time, the 1000 runs had
a cross-section of varying graph sizes (3-20 nodes). The
running time of the BRUTE-FORCE algorithm becomes
9
very large even for small values of 13 to 15. Clearly,
this is the expected behavior as the running time of this
algorithm is O(n!), which is worse than exponential. On
the other hand, the GREEDY-HEURISTIC has polyno-
mial running times for the same input. Even for graphs
with a large number of nodes (200-300 nodes), we have
observed a running time of only a few minutes (15-20
minutes).
5 Related Work
Theoretical models allow inexpensive security anal-
ysis without real experiments or implementation. Fault
trees, privilege graphs and attack graphs are the most
relevant modeling methodologies in the context of our
work. We compare and contrast against these techniques
to put our work in perspective.
Fault trees [11] are the (cid:2)rst generation of formal mod-
els primarily used for system failure analysis. A fault
tree is a logic (AND-OR) tree, where nodes are single
faults, edges de(cid:2)ne a combination of them, and proba-
bilities over edges represent the chance of their occur-
rence. While fault trees are suitable to model a disjunc-
tion and conjunction of faults, they lack the expressive
power to capture attacks.
The privilege graph, introduced by Dacier et al. [7, 6]
as an extension to Typed Access Model (TAM), is a di-
rected graph where each node represents a set of priv-
ileges on sets of objects and each arc represents privi-
lege escalation possibly through an exploit. This model
also uses a probabilistic metric corresponding to likeli-
hoods of attacks. However, determining these probabili-
ties in a meaningful manner is far more challenging that
our approach which measures the effectiveness of access
control mechanisms. Ortalo et al. [17] describe an ex-
perimental evaluation of the privilege graph framework
under certain assumptions on the memory state of an at-
tacker, and their work did address a few insider attack
scenarios, but their implementation required a substan-
tial effort.
Philips and Swiler [21] proposed the attack graph
model, where nodes in the graph represent the state of
a network and edges represent steps in an attack. Build-
ing and analyzing such a graph by hand is not practi-
cal, and instead, several approaches have been proposed
which use model-checking to automatically generate at-
tack graphs [20]. However, model-checking suffers
from a well-known problem of state explosion which is
not easily solved and these approaches are not suitable
even for networks of a reasonable size.
Although in some respects, both privilege graphs and
attack graphs appear similar to our work, they are in fact
closer to each other than our approach. A major dis-
tinction arises in the details that are captured (see Ta-
ble 1) and the nature of threat analysis. For example, in
their model, the dif(cid:2)culty attributed to edge traversal is a
static entity, while in our model it is dynamic. Moreover,
in both techniques, there is the problem of exponential
state explosion, whereas our approach generates models
which are polynomial-sized in the input network infor-
mation. Also note that attacks in our model can succeed
without privilege escalation or the presence of vulnera-
bilities, which is a distinct possibility for insider attacks.
6 Conclusion And Future Work
Insider threat is a long standing security problem,
but so far, without good tools and techniques, there is
little that could be done to counter the threat.
In this
paper, we believe that we have made a signi(cid:2)cant ad-
vance by proposing a usable and generic threat assess-
ment model, and showed its applications to some typical
insider threat scenarios. Indeed we do not claim that our
model is a replacement for all the existing models, but
that it occupies a certain niche and complements other
models. We also believe that our modeling methodol-
ogy is more generic than demonstrated in this paper and
may have an appeal beyond just insider threat.
Our future work involves developing automated tools
around the modeling methodology and algorithms de-
veloped in this paper to empower security analysts with
techniques to measure a threat which has otherwise not
been possible.
References
[1] 2004 E-Crime Watch Survey:
Summary Of Find-
ings. CERT/United States Secret Service/CSO, 2004.
http://www.cert.org/archive/pdf/
2004eCrimeWatchSummary.pdf.
And
Threat
The
Study:
Banking
[2] Insider
In
Illicit Cyber
Finance
Activ-
ity
Sector.
CERT/United States Secret Service, August 2004.
http://www.secretservice.gov/ntac/its_report_040820.pdf.
[3] S. Arora, C. Lund, R. Motwani, M. Sudan, and
M. Szegedy.
Proof Veri(cid:2)cation And The Hardness
Of Approximation Problems. J. ACM, 45(3):501(cid:150)555,
1998.
[4] S. Arora and S. Safra. Probabilistic Checking Of Proofs:
A New Characterization Of NP. J. ACM, 45(1):70(cid:150)122,
1998.
[5] R. Chinchani, D. Ha, A. Iyer, H. Q. Ngo, and S. Upad-
hyaya. On the hardness of approximating the Min-Hack
problem. 2005. Technical Report 2005-05. Computer
Science and Engineering, SUNY at Buffalo.
[6] M. Dacier. Towards Quantitative Evaluation of Com-
puter Security. PhD thesis, Institut National Polytech-
nique de Toulouse, December 1994.
[7] M. Dacier and Y. Deswarte. Privilege graph: an exten-
In ESORICS,
sion to the typed access matrix model.
pages 319(cid:150)334, 1994.
[8] I. Dinur and S. Safra. On the Hardness of Approximating
Label Cover. Electronic Colloquium on Computational
Complexity (ECCC), 6(015), 1999.
[10] M. R. Garey and D. S. Johnson.
[9] U. Feige, S. Goldwasser, L. LovÆsz, S. Safra, and
M. Szegedy.
Interactive Proofs And The Hardness Of
Approximating Cliques. J. ACM, 43(2):268(cid:150)292, 1996.
Computers and
Intractability. W. H. Freeman and Co., San Fran-
cisco, Calif., 1979. A Guide To The Theory Of NP-
Completeness, A Series of Books in the Mathematical
Sciences.
[11] J. Gorski and A. Wardzinski. Formalizing Fault Trees.
Achievement and Assurance of Safety, pages 311(cid:150)327,
1995.
[12] J. H(cid:229)stad. Some Recent Strong Inapproximability Re-
sults. In Algorithm theory(cid:151)SWAT’98 (Stockholm), vol-
ume 1432 of Lecture Notes in Comput. Sci., pages 205(cid:150)
209. Springer, Berlin, 1998.
[13] J. H(cid:229)stad. Some Optimal Inapproximability Results. In
STOC ’97 (El Paso, TX), pages 1(cid:150)10 (electronic). ACM,
New York, 1999.
[14] D. S. Hochbaum, editor. Approximation Algorithms for
NP Hard Problems. PWS Publishing Company, Boston,
MA, 1997.
[15] S. Khanna, R. Motwani, M. Sudan, and U. Vazirani. On
Syntactic Versus Computational Views Of Approxima-
bility. SIAM J. Comput., 28(1):164(cid:150)191 (electronic),
1999.
[16] C. Meadows. A Representation of Protocol Attacks for
Risk Assessment. In R. N. Wright and P. G. Neumann,
editors, DIMACS Series in Discrete Mathematics and
Theoretical Computer Science: Network Threats, vol-
ume 38, December 1998.
[17] R. Ortalo, Y. Dewarte, and M. Kaaniche. Experiment-
ing With Quantitative Evaluation Tools For Monitoring
Operation Security. IEEE Transactions on Software En-
gineering, 25(5):633(cid:150)650, September/October 1999.
[18] C. H. Papadimitriou and M. Yannakakis. Optimization,
Approximation, And Complexity Classes. J. Comput.
System Sci., 43(3):425(cid:150)440, 1991.
[19] C. Phillips and L. P. Swiler. A Graph-Based System For
Network-Vulnerability Analysis. In Proceedings of 1998
New Security Paradigms Workshop, pages 71 (cid:150) 79, Char-
lottesville, Virginia, 1998.
[20] O. Sheyner, J. Haines, S. Jha, R. Lippmann, and J. M.
Wing. Automated Generation and Analysis of Attack
Graphs. In Proceedings of the IEEE Symposium on Se-
curity and Privacy, Oakland, CA., May 2002.
[21] L. P. Swiler, C. Phillips, D. Ellis, and S. Chakerian.
In DARPA
Computer-Attack Graph Generation Tool.
Information Survivability Conference and Exposition
(DISCEX 11’01), volume 2, June 2001.
10