The attacks we demonstrate in this paper were performed
on clouds oﬀering container-based isolation, but as they ex-
ploit features common to both container-based and user-
based isolation, we believe they are equally applicable to
clouds protected by user-based isolation.
2.2 Threat model
We consider attacks by the PaaS provider (or other ma-
licious insiders) as out of scope. The same trust extends to
any underlying IaaS provider. Should the IaaS cloud be pub-
lic (e.g., EC2) then its malicious IaaS customers represent a
threat to PaaS customers, but not one that we explore fur-
ther. Rather we focus on other malicious customers of the
PaaS cloud, and container-based isolation in particular.
Thus both the adversaries and the victims in our threat
model are users of a PaaS system. An adversary seeks to (i)
arrange for a malicious instance it controls to be scheduled
to run within a diﬀerent container on the same host OS as
the target victim and (ii) extract conﬁdential information
from the target victim using this vantage point.
3. ATTACK FRAMEWORK
In this section, we present an attack framework that en-
ables an adversary to conduct a cache-based attack to track
the execution path of a victim and, in doing so, to extract a
secret of interest from the victim. We will ﬁrst describe
the Flush-Reload-based side channels exploited in this
study (Sec. 3.1), and then develop an attack nondeterminis-
tic ﬁnite automaton or attack NFA (Sec. 3.2–3.3) from the
control-ﬂow graph (CFG) of an executable shared with the
victim. We defer the actual demonstration of security at-
tacks to later sections.
3.1 Side Channels via Flush-Reload
We leverage a type of cache-based side channel that was
ﬁrst reported by Gullasch et al. [14], who demonstrated its
use by an attack process to extract Advanced Encryption
Standard (AES) keys from a victim process when both were
running within the same OS. The attack was studied on
a single-core processor and exploits the adversary’s process’
ability to evict data in physical memory pages it shares with
the victim process from the CPU cache (e.g., via the instruc-
tion clflush2). The technique was later extended by Yarom
and Falkner to multi-core systems with a shared last-level
cache [38]. They refer to their attack as Flush-Reload. In
this work, we further extend the use of the Flush-Reload
side channels to more general attack scenarios.
Basic Flush-Reload. The basic building block of a Flush-
Reload attack is as follows. A chunk is a cacheline-sized,
aligned region in the physical memory that is mapped into
the adversary’s address space. For example, if a cacheline
is of size 64B, then each address that is a multiple of 64B
deﬁnes the chunk starting at that address.
• Flush: The adversary ﬂushes chunks containing speciﬁc
instructions located in a memory page it shares with the
victim out of the entire cache hierarchy (including the
shared last-level cache) using the clflush instruction.
• Flush-Reload interval: The adversary waits for a pre-
speciﬁed interval while the last-level cache is utilized by
the victim running on another CPU core.
• Reload: The adversary times the reload of the same
chunks into the processor. A faster reload suggests these
chunks were in the last-level cache and so were executed
by the victim during the Flush-Reload interval; a slower
reload suggests otherwise.
We refer to the chunks being Flush-Reloaded by the ad-
versary as being monitored, since Flush-Reload essentially
monitors access to data in the chunk. Flushing a chunk via
clflush, and so monitoring that chunk, can be done with-
out knowing the physical address of the chunk, since clflush
takes the chunk’s virtual address (in this case, in the adver-
sary’s address space) as its operand. We call a faster reload
during the Reload phase an observed event or observation.
We also adopt concepts from statistical classiﬁcation and
use the term false negative to refer to missed observations
of the victim’s access to the monitored chunk and false pos-
itives to refer to observed events that are caused by reasons
other than the victim’s access to the monitored chunk.
Flush-Reload Protocols. We deﬁne a Flush-Reload
protocol, in which the adversary process monitors a list of
chunks simultaneously and repeatedly until instructed oth-
erwise. It will ﬁrst try to Reload the ﬁrst chunk, record the
reload time and Flush it immediately afterwards. Then it
will repeat these steps on the second chunk, the third, and
so on, until the last chunk in the list. Then the adversary
will wait for a carefully calculated time period before start-
ing over from the ﬁrst chunk, so that the interval between
the Flush and Reload of the same chunk is of a target
duration.3 From the Reload of the ﬁrst chunk to the end
of the waiting period is called one Flush-Reload cycle. An il-
lustration of the Flush-Reload protocol is shown in Fig. 1.
2The clflush instruction takes a virtual address as the
operand and will ﬂush all cachelines with the correspond-
ing physical address out of the entire cache hierarchy.
3Variation in the duration on the order of one or two hun-
dred CPU cycles may occur as the reload of a chunk does
not take constant time.
992Flushing
chunk 1
Flushing
chunk 2
Reloading
chunk 1
Reloading
chunk 2
Idle looping
Flush-Reload Interval
Flush-Reload Cycle
Figure 1: An example of a Flush-Reload protocol in
which two chunks are monitored at the same time.
Gray rectangles are Reloads of two chunks and dark
squares are immediate Flushes of the prior Reloads.
3.2 From CFGs to Attack NFAs
In this section we provide a framework to leverage Flush-
Reload attacks as a primitive in a larger attack strategy to
trace the execution path of a victim instance during (at least
part of) its execution. Speciﬁcally, we develop attack NFAs
that prescribe the order in which diﬀerent chunks should be
monitored using Flush-Reload attacks, based on what has
been learned so far.
The development of an attack NFA to attack a target
victim begins with a control-ﬂow graph (CFG) [1] of the
executable4 shared with the victim. As usual, each node
of the CFG is a basic block of instructions, and an edge
from one basic block to another indicates that the latter can
immediately follow the former in execution. Let B denote
the set of basic blocks of the victim instance, and let E
denote the directed edges of its CFG.
When the shared executable is loaded, its organization in
memory determines a function BBToChunks : B → 2C that
describes how each basic block shared with the victim (i.e.,
in the shared executable) is stored in one or more chunks
mapped into the adversary instance’s virtual memory. Here,
C is the set of all chunks mapped into the adversary’s vir-
tual memory and occupied by the shared executable, and 2C
denotes the power set of C. That is, each basic block in B is
mapped to one or more chunks, by BBToChunks. Although
the chunks to which each basic block is mapped are usually
contiguous in memory, this might not be true when those
chunks span the end of a memory page.
Like a regular NFA, the attack NFA is deﬁned as a tu-
ple (Q, Σ, δ, q0, F ), where Q is a set of states, Σ is a set of
symbols, δ : Q × Σ → Q is a transition function, q0 is the
initial NFA state, and F ⊆ Q is a set of accepting states.
To each state q ∈ Q is associated a set of chunks, denoted
mon(q) ⊆ C, that contains the chunks the adversary will
monitor while in state q. Note that mon(q) might be the
same for multiple states q.
The symbols Σ consumed by the NFA is the set Σ = C ×
N×N where N is the set of natural numbers. Speciﬁcally, the
meaning of the transition (q, (c, ℓ, u), q′) ∈ δ is: while in state
q and so monitoring the chunks mon(q), if the adversary
detects the victim’s use of chunk c within the interval [ℓ, u]
(in units of Flush-Reload cycles since entering q), then the
adversary transitions to q′ and begins monitoring the chunks
mon(q′). We allow ℓ to be zero; detecting the victim’s use of
c in zero Flush-Reload cycles since entering state q means
that c was detected in the same Flush-Reload cycle that
caused state q to be entered.
4We use the term “executable” to refer to both executable
ﬁles and shared libraries in this paper.
In light of this intended meaning of the attack NFA, the
transition function should satisfy certain constraints.
• Observability: If (q, (c, ℓ, u), q′) ∈ δ, then c ∈ mon(q).
Otherwise, an adversary in state q will not observe the
victim using c. If in addition (q′, (c′, 0, u′), q′′) ∈ δ, then
mon(q′) ⊆ mon(q), since for transition (q′, (c′, 0, u′),
q′′) to become enabled with no Flush-Reload cycles
after transitioning to q′, c′ must be monitored in q (as
must other chunks included in mon(q′) due to recursive
application of this rule to additional “downstream” states
like q′′).
• Feasibility: To each state q there corresponds a basic
block b such that for each transition (q, (c, ℓ, u), q′) ∈ δ,
there is a (possibly empty) path in the CFG from b to a
basic block b′ (corresponding to q′) that can be traversed
in no fewer than ℓ and no more than u Flush-Reload
cycles and such that c ∈ BBToChunks(b′).
Intuitively,
it is this execution path that the adversary detects in
transitioning from state q to q′.
In addition, in practice it is important to design the attack
NFA so that the number of monitored chunks in any state is
constrained, since monitoring many chunks simultaneously
poses diﬃculties.
A transition is taken out of a state at the ﬁrst Flush-
Reload cycle that enables a transition. Still, it is possi-
ble for multiple transitions to become enabled in the same
Flush-Reload cycle, in which case an arbitrary enabled
transition is taken. In this respect, the automaton is nonde-
terministic.
The designated initial state q0 represents the shared exe-
cutable’s entry point(s) of interest to the adversary. That is,
mon(q0)∩ BBToChunks(b) 6= ∅ for each basic block b that the
adversary wants to detect initially. The set F of accepting
states is chosen by the adversary to reﬂect having tracked
the execution of the victim suﬃciently far to permit his in-
ference of the targeted information about the victim with
suﬃcient conﬁdence.
After the attack NFA is constructed, the adversary may
employ it to reconstruct the victim’s execution path by si-
multaneously (i) triggering the victim’s execution by send-
ing a request to victim’s web application interface, and (ii)
inducing its co-located attacker application to start monitor-
ing mon(q0). If the NFA transitions to an accepting state,
the adversary knows the execution path of interest is taken
by the victim. We have found that in practice, a well de-
signed NFA usually leads to successful identiﬁcation of an
execution path of the victim application.
3.3 Practical Construction of Attack NFAs
In this section we discuss how an adversary can construct
attack NFAs in practice.
3.3.1 Basic Strategy
In PaaS clouds an application usually consists of a set of
scripts written in scripting languages that manage dynamic
web content, a set of shared libraries that implement the
runtime of the programming language or any other support-
ing functionality (e.g., cryptography, database access), and
a web server executable that serves the web requests and
interacts with the scripting language runtime.
It is not necessary to construct the attack NFA from a
full CFG of the victim application. If the source code of the
shared executables of interest is unavailable to the adversary,
993he can make progress on the attack with the following steps:
(1) disassembling these shared executables and constructing
partial CFGs from the results; (2) manually analyzing these
partial CFGs and selecting blocks along the execution paths
of interest for which chunks should be monitored; and (3)
constructing the attack NFA with the help of online training,
in which the adversary monitors all chunks of interest at
once and triggers the victim’s activity that he would like to
capture by submitting appropriate requests. During phase
(3), the Flush-Reload protocol will report a sequence of
observed events on the monitored chunks. The temporal
order of these events suggests the NFA states and chunks to
monitor in each, and the relative timestamps can help train
the ℓ and u values for each transition. Multiple training
trials will help reﬁne the constructed attack NFA.
However, adversaries usually face a more favorable sce-
nario in practice. Source code of the victim application
is available to the adversary in many cases: Since most
PaaS clouds are built based on Linux distributions, most
web servers, application runtimes and supporting libraries
are open-source. Moreover, about 37% of the top 10 million
websites use a third-party content management system such
as WordPress, Drupal, or Magento [37], the source code of
which is either open or obtainable with a fee.
If the adversary has the source code of the shared executa-
bles as well as the scripts for managing dynamic web content,
the above attack steps can be facilitated with the additional
information. For instance, step (1) can be replaced by per-
forming static control-ﬂow analysis on the source code, and
step (2) and (3) can be assisted by replicating the same
PaaS environment oﬄine and tracking the victim applica-
tion’s control ﬂow dynamically. For example, the adver-
sary may run the entire web application in Valgrind [24]
and trigger various victim activities with manufactured web
requests, recording the control ﬂow that results from each.
However, even so, the training step (3) is still necessary to
determine the ℓ and u values for the transitions.
Although we have developed some software tools to facil-
itate attack NFA construction, constructing an attack NFA
with or without source code is still mostly a manual process
and depends in large part on the attack goals — in particu-
lar, which execution paths in the victim the adversary needs
to detect. In Sec. 5–7, we will give several examples of how
to construct attack NFAs for diﬀerent types of attacks.
3.3.2 Reducing Side-Channel Noise
One challenge that we have overlooked so far is noise in
the Flush-Reload side channel. Here, “noise” refers to false
positives and false negatives in the Reload phase. Com-
pared with the Prime-Probe attacks used in many previ-
ous works (e.g., [28, 30, 25, 34, 40]), Flush-Reload attacks
involve relatively less noise, since the adversary is able to
tell whether the victim accessed the data in the chunk the
adversary is monitoring, versus simply some data mapped to
the same cache set. Nevertheless, the technique still suﬀers
from many sources of noise in practice.
Sources of noise. We discuss, in turn, false negative noise
due to race conditions and unobserved duplicate accesses,
and then false positive noise due to false sharing of chunks,
hardware cache prefetching, and background activities from
other processes sharing the same memory pages. These
sources of noise aﬀect the granularity and reliability of the
attacks that we will develop in subsequent sections.
A race condition here refers to the situation where two
memory loads of the same chunk are issued from two CPU