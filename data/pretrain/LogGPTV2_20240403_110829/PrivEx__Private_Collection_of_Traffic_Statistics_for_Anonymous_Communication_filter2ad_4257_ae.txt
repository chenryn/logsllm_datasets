et al. [13] explicitly evaluate the accuracy-privacy tradeoffs for
computing Boolean functions. Mironov et al. [25] investigate cal-
culating the distance between two vectors while McGregor et al. [23]
do the same for Hamming distance. All these works explore the
limits of DDP in the two-party setting. We contrast our work by
noting that we consider a different type of problem (the summa-
tion of integral inputs) and we evaluate the tradeoff between the
accuracy and privacy in the multiparty setting.
The closest related work is by Beimel et al. [4]. The inputs in that
setting are binary, while those in ours are integral. While the binary
inputs can indeed be adapted to integers, there remain three key
differences. Their protocol requires more rounds of communication
than ours, while we also allow for malicious parties, making PrivEx
a more practical solution in our setting. Finally, in their setting,
to preserve DP, the database of each DC is kept private and only
binary outputs are released, whereas in our setting all DCs release
their private data, albeit with noise added to preserve DP.
Also of interest is work by Kasiviswanathan et al. [18] where
network graphs are analyzed to investigate how the removal and
addition of nodes in the graph affect the privacy of the information
about the structure of the graph. While they also consider differ-
ential privacy in the network setting, the key difference is that they
investigate ways to safely reveal information about the nodes of the
network themselves, whereas we are interested in the information
that can be revealed by studying the trafﬁc ﬂowing through the net-
work; i.e., the network users’ information.
A general key difference to the previous literature is that PrivEx
provides a way to reason about the privacy and utility that the sys-
tem provides whereas these previous works leave it up to the sys-
tem designer to work out. We provide an explicit statement of, and
relationship between, privacy and utility that are pertinent to data
collection in ACNs—this provides an easier-to-analyze system and
potentially an easier path to deployment.
Secure Multiparty Computation. Secure multiparty computa-
tions have been used in scenarios where the parties that perform
the operations are not trustworthy. This means that they should not
learn the inputs of the calculations, should provide (implicit or ex-
plicit) proofs that the calculations were performed correctly, and
should not learn anything more than the output of the calculation.
A closely related work is SEPIA [6] by Burkhart et al. where
networks collect data and wish to learn aggregate information about
their networks without revealing their individual inputs. It develops
a number of operations that can be performed on network data that
can be evaluated by a pool of servers in a secure multiparty compu-
tation. While both PrivEx and SEPIA try to achieve similar goals
in the collection of network statistics and use similar secret sharing
schemes, there are a number of differences. First, while the authors
of SEPIA brieﬂy mention differential privacy as a possible defence,
PrivEx provides a thorough treatment of how to use differential pri-
vacy to protect the aggregated statistics in a principled manner. Re-
lated to that is that SEPIA also requires that honest DCs sanitize
their inputs, i.e. remove sensitive information, whereas PrivEx ac-
complishes the same with the addition of DP-noise. Second, PrivEx
is secure as long as there is one honest data collector—adding the
appropriate level of noise, as outlined in §4.4.1—and one honest
TKS. This is in contrast to the SEPIA requirement that at least half
of the aggregators be honest. This is especially useful since PrivEx
collects data from an anonymity network where the stakes for in-
formation leakage are potentially higher and hence require greater
robustness to bad actors. Finally, we note that the data collectors in
SEPIA are provisioned for processing large quantities of trafﬁc and
data as they are part of the ISP infrastructure, but these conditions
may not apply in a volunteer-resourced network like Tor. PrivEx
has low overhead for the DCs.
The secret sharing scheme is an adaption of the scheme pre-
sented by Barthe et al. [3] which itself is an extension of previous
works by Kursawe et al. [20], Jawurek et al. [15] and Shi et al. [31].
The novelty of PrivEx is that it introduces addition using additive
secret shares for coercion resistance and perfect forward secrecy
which these previous works do not address.
Anonymity Network Data Collection. The work by McCoy et
al. [22] provided many insights about Tor client behaviour. Un-
fortunately, the method of safeguarding the privacy of the collected
data was considered by the community at large to be insufﬁcient. [33]
Similarly, Diaz and Sassaman [7] provided insights about mix in-
put trafﬁc in Mix-stlye anonymous email networks by using actual
trafﬁc obtained from a public node. Here too, the use of actual
trafﬁc data had the potential to deanonymize clients. PrivEx ame-
liorates this state of affairs by providing researchers the means to
collect statistical data about clients of anonymous networks in a
privacy-preserving and compulsion-resistant manner.
Anonymity networks have to be careful about how they collect
data about their network and users since they are in a position of
power and can potentially expose the entire network. The opera-
tors of Tor currently collect network-wide bandwidth data but this
data is independent of client data. They also collect client-speciﬁc
network usage data from their guard and bridge nodes but not the
exit nodes. The reason why it is considered safer to do the former
and not the latter—in the context of protecting client anonymity—is
that the guards/bridges already know who the clients that connect
through them are so an adversary who compromises those nodes
would not learn any extra information.
A key difference between PrivEx and the present Tor data col-
lection environment is that in that latter, the true client statistics
(aggregated at a per-country level, for example) are stored in a cen-
tralized database. PrivEx does not allow any entity to learn any real
client data expect the nodes that originally collected the data.
8. FUTURE WORK
In the near future we aim to integrate PrivEx with the Tor code-
base. Once this is done we hope to achieve acceptance from the
Tor community and deploy PrivEx on the live Tor network and be-
gin collecting statistics about website visits at exit nodes. We note
that PrivEx is incrementally deployable: even if only a fraction
of Tor exit nodes become DCs for PrivEx, we can still collect data
about Tor trafﬁc exiting through those particular nodes. Then, since
we know the probabilities of each exit node being chosen, we can
extrapolate to statistics for the whole network, albeit with some-
what larger error. Only exit nodes would have to change to support
PrivEx, except for the optional enhancement of §4.2.1, which also
requires the cooperation of entry nodes.
As a potential additional application of PrivEx, we note that
while the Tor network does not typically try to hide the fact that
a client is using Tor, there may be risks to revealing statistics gath-
ered through widespread ingress data collection similar to those
addressed by PrivEx of egress data collection. To address these po-
tential risks, PrivEx can be applied to the present guard/bridge data
collection process, and provide the same beneﬁts as those that have
been shown here for exit nodes.
An open question is whether PrivEx-like systems can be ex-
tended to collect data across subsets of the network. The risks are
that this will give the adversary the ability to partition the data and
perhaps learn something from the statistics that he should not have.
If this can be done safely, one direct beneﬁt is that we could, in
a privacy-preserving manner, troubleshoot speciﬁc issues that are
localized.
A limitation of PrivEx, since it is not needed for the scenarios we
study, is that only a single query can be made of the database. We
would like to investigate how to support multiple related queries—
e.g., network load or circuit latency—while maintaining PrivEx’s
privacy and utility features.
9. CONCLUSION
We have presented PrivEx, a decentralized system for privately
collecting client statistics in anonymity networks. We have detailed
two variants of PrivEx, one based on secret sharing and the other on
distributed decryption. Both schemes are efﬁcient and resilient to
coercion attacks and malicious actors. We introduce noise, as de-
ﬁned in the differential privacy setting, into our aggregation process
to prevent information leakage that would otherwise occur when
the statistics are published.
We have used Tor as a case study and show how it can incorpo-
rate PrivEx; other anonymity networks can similarly deploy PrivEx.
In this case study we collect statistics about client destination vis-
its at the DC nodes. We show that this can be done in an efﬁcient
manner with low computational and communication overhead for
conditions typical in the Tor network.
With PrivEx, our aim is to convince administrators and users
of anonymity networks that client data collection is possible while
maintaining anonymity and privacy. The beneﬁts are that valuable
information about usage trends will help guide performance and
maintenance efforts. From the research perspective the beneﬁts
will be more accurate usage statistics, client models, and clearer in-
dicators of future directions that anonymous communications and
censorship resistance research should take.
Acknowledgements We would like to thank NSERC, ORF, and
The Tor Project for funding this research and our CrySP lab col-
leagues for their invaluable feedback.
10. REFERENCES
[1] M. Alsabah, K. Bauer, T. Elahi, and I. Goldberg. The Path
Less Travelled: Overcoming Tor’s Bottlenecks with Trafﬁc
Splitting. In Proceedings of the 13th Privacy Enhancing
Technologies Symposium (PETS ), pages 143–163. Springer,
July 2013.
[2] Anonymizer Inc. Anonymizer.
https://www.anonymizer.com/index.html,
2013. Retrieved May 2014.
[3] G. Barthe, G. Danezis, B. Grégoire, C. Kunz, and
S. Zanella-Béguelin. Veriﬁed computational differential
privacy with applications to smart metering. In 26th IEEE
Computer Security Foundations Symposium (CSF), pages
287–301, 2013.
[4] A. Beimel, K. Nissim, and E. Omri. Distributed private data
analysis: Simultaneously solving how and what. In Advances
in Cryptology–CRYPTO 2008, pages 451–468. Springer,
2008.
[5] J. Benaloh. Dense probabilistic encryption. In Proceedings of
the Workshop on Selected Areas in Cryptography, pages
120–128, 1994.
[6] M. Burkhart, M. Strasser, D. Many, and X. Dimitropoulos.
SEPIA: Privacy-preserving aggregation of multi-domain
network events and statistics. In 19th USENIX Security
Symposium, August 2010.
[7] C. Diaz, L. Sassaman, and E. Dewitte. Comparison between
two practical mix designs. In ESORICS 2004, pages
141–159. Springer, 2004.
[8] R. Dingledine, N. Mathewson, and P. Syverson. Tor: The
second-generation onion router. In Proceedings of the 13th
USENIX Security Symposium, August 2004.
[9] C. Dwork. Differential privacy. In Automata, languages and
programming, pages 1–12. Springer, 2006.
[10] C. Dwork, K. Kenthapadi, F. McSherry, I. Mironov, and
M. Naor. Our data, ourselves: Privacy via distributed noise
generation. In Advances in Cryptology-EUROCRYPT 2006,
pages 486–503. Springer, 2006.
[11] C. Dwork, G. N. Rothblum, and S. Vadhan. Boosting and
differential privacy. In 51st IEEE Symposium on Foundations
of Computer Science (FOCS), pages 51–60. IEEE, 2010.
[12] T. Elahi, G. Danezis, and I. Goldberg. PrivEx: Private
Collection of Trafﬁc Statistics for Anonymous
Communication Networks. Technical Report 2014-08,
CACR, 2014. http://cacr.uwaterloo.ca/
techreports/2014/cacr2014-08.pdf.
[13] V. Goyal, I. Mironov, O. Pandey, and A. Sahai.
Accuracy-privacy tradeoffs for two-party differentially
private protocols. In Advances in Cryptology–CRYPTO
2013, pages 298–315. Springer, 2013.
[14] M. Hardt and A. Roth. Beating randomized response on
incoherent matrices. In 44th Symposium on Theory of
Computing (STOC), pages 1255–1268. ACM, 2012.
[15] M. Jawurek and F. Kerschbaum. Fault-tolerant
privacy-preserving statistics. In 12th Privacy Enhancing
Technologies Symposium (PETS), pages 221–238. Springer,
2012.
[16] JonDo Inc. JonDonym.
http://anonymous-proxy-servers.net/, 2013.
Retrieved May 2014.
[17] jrandom (Pseudonym). Invisible internet project (i2p) project
overview. https://geti2p.net/_static/pdf/
i2p_philosophy.pdf, August 2003. Retrieved May
2014.
[18] S. P. Kasiviswanathan, K. Nissim, S. Raskhodnikova, and
A. Smith. Analyzing graphs with node differential privacy. In
Theory of Cryptography, pages 457–476. Springer, 2013.
[19] S. Köpsell and U. Hillig. How to Achieve Blocking
Resistance for Existing Systems Enabling Anonymous Web
Surﬁng. In Workshop on Privacy in the Electronic Society
(WPES), Washington, DC, USA, October 2004.
[20] K. Kursawe, G. Danezis, and M. Kohlweiss. Privacy-friendly
aggregation for the smart-grid. In 11th Privacy Enhancing
Technologies Symposium (PETS), pages 175–191. Springer,
2011.
[21] K. Loesing. Measuring the Tor Network. https:
//research.torproject.org/techreports/
directory-requests-2009-06-25.pdf, 2009.
Retrieved August 2014.
[22] D. McCoy, K. Bauer, D. Grunwald, T. Kohno, and D. Sicker.
Shining light in dark places: Understanding the Tor network.
In 8th Privacy Enhancing Technologies Symposium (PETS),
pages 63–76. Springer, 2008.
[23] A. McGregor, I. Mironov, T. Pitassi, O. Reingold, K. Talwar,
and S. Vadhan. The limits of two-party differential privacy.
In 51st IEEE Symposium on Foundations of Computer
Science (FOCS), pages 81–90. IEEE, 2010.
[24] I. Mironov. On signiﬁcance of the least signiﬁcant bits for
differential privacy. In 2012 ACM Conference on Computer
and Communications Security (CCS), pages 650–661. ACM,
2012.
[25] I. Mironov, O. Pandey, O. Reingold, and S. Vadhan.
Computational differential privacy. In Advances in
Cryptology-CRYPTO 2009, pages 126–142. Springer, 2009.
[26] S. J. Murdoch and G. Danezis. Low-cost trafﬁc analysis of
Tor. In 2005 IEEE Symposium on Security and Privacy.
IEEE, May 2005.
[27] L. Øverlier and P. Syverson. Locating hidden servers. In
2006 IEEE Symposium on Security and Privacy. IEEE, May
2006.
[28] J. M. Pollard. Monte carlo methods for index computation
(mod p). Mathematics of computation, 32(143):918–924,
1978.
[29] K. Poulsen. Edward Snowden’s Email Provider Shuts Down
Amid Secret Court Battle. http:
//www.wired.com/2013/08/lavabit-snowden/,
2013. Retrieved May 2014.
[30] D. Shanks. Class number, a theory of factorization, and
genera. In Proc. Symp. Pure Math, volume 20, pages
415–440, 1971.
[31] E. Shi, T.-H. H. Chan, E. G. Rieffel, R. Chow, and D. Song.
Privacy-preserving aggregation of time-series data. In
Network and Distributed System Security Symposium
(NDSS), 2011.
[32] R. Singel. Encrypted E-Mail Company Hushmail Spills to
Feds. http://www.wired.com/threatlevel/
2007/11/encrypted-e-mai/, 2007. Retrieved May
2014.
[33] C. Soghoian. Enforced Community Standards for Research
on Users of the Tor Anonymity Network. In 2nd Workshop
on Ethics in Computer Security Research (WECSR), pages
146–153, 2011.
[34] The Tor Project. Tor Mertics Portal: Network, Advertised
bandwidth distribution. https:
//metrics.torproject.org/network.html,
2014. Retrieved May 2014.
[35] The Tor Project. Tor Mertics Portal: Users. https:
//metrics.torproject.org/users.html, 2014.
Retrieved May 2014.
[36] P. Winter. Towards a Tor Censorship Analysis Tool.
https://blog.torproject.org/category/
tags/measurement, 2013. Retrieved August 2014.