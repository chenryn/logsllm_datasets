title:Server-Side Code Injection Attacks: A Historical Perspective
author:Jakob Fritz and
Corrado Leita and
Michalis Polychronakis
Server-side code injection attacks:
a historical perspective
Jakob Fritz1, Corrado Leita1, and Michalis Polychronakis2
1 Symantec Research Labs, Sophia Antipolis, France,
{jakob fritz,corrado leita}@symantec.com
2 Columbia University, New York, USA, PI:EMAIL
Abstract. Server-side code injection attacks used to be one of the main
culprits for the spread of malware. A vast amount of research has been
devoted to the problem of eﬀectively detecting and analyzing these at-
tacks. Common belief seems to be that these attacks are now a marginal
threat compared to other attack vectors such as drive-by download and
targeted emails. However, information on the complexity and the evolu-
tion of the threat landscape in recent years is mostly conjectural. This
paper builds upon ﬁve years of data collected by a honeypot deployment
that provides a unique, long-term perspective obtained by traﬃc moni-
toring at the premises of diﬀerent organizations and networks. Our con-
tributions are twofold: ﬁrst, we look at the characteristics of the threat
landscape and at the major changes that have happened in the last ﬁve
years; second, we observe the impact of these characteristics on the in-
sights provided by various approaches proposed in previous research. The
analysis underlines important ﬁndings that are instrumental at driving
best practices and future research directions.
1
Introduction
Remote code injection attacks used to be one of the main vectors used by mal-
ware to propagate. By leveraging unpatched vulnerabilities in the increasingly
large and complex software base in modern computing devices, attackers manage
to divert the control ﬂow towards code of their choice injected into the victim
memory. The injected code, usually called shellcode, is normally constrained in
terms of size and complexity, and is thus typically used to upload to the vic-
tim a second, larger executable ﬁle, the malware. This very simple mechanism,
through diﬀerent variations, has been responsible for the propagation of most
modern threats and the infection with malware of home computers as well as
banks, corporate networks, and even industrial control systems.
Historically, most of the remote code injection attacks used to be carried out
against vulnerable network services easily reachable from the Internet without
any need of user involvement. Many vulnerabilities in Windows SMB proto-
cols, for instance, have been used for this purpose. However, server-side code
injection attacks are now perceived by the community as an outdated problem.
An increasing use of personal ﬁrewalls on end user machines (facilitated by the
2
choice of major vendors to ship their OSs with ﬁrewall services enabled by de-
fault) has decreased the eﬀectiveness of server-side exploits at breaching security
perimeters. At the same time, modern operating systems have adopted security
mechanisms such as Data Execution Prevention (DEP) that render the task
of successfully hijacking control ﬂow increasingly diﬃcult. In recent years, the
propagation methods of choice have therefore shifted towards client-side vectors
such as drive-by downloads, e-mail, and social engineering attacks.
This work aims at exploring this perception through a quantitative analysis,
by looking at the evolution of the threat landscape in recent years and by eval-
uating the eﬀectiveness of state-of-the-art detection and analysis techniques at
coping with these threats. Is the detection of server-side code injection attacks
a fully understood and solved problem deemed to become irrelevant in the long
term, or are there still signiﬁcant research or operational problems in the way
we are tackling these threats? The answer to this question is particularly impor-
tant when considering recent advanced threats such as Stuxnet [1] and Duqu [2].
While originally introduced in the target environment through USB sticks or
email attachments, after the initial intrusion these threats needed to expand
their installed base to reach the systems of interest (e.g., a SCADA engineering
station to infect PLC code). This phase could not rely on user involvement and
was carried out through server-side exploits, which were successful while keep-
ing the infection mostly undetected by operators. The problem of detecting and
understanding server-side exploits is therefore still a prominent one, despite the
change in their role.
An analysis of the threat landscape on server-side code injection attacks is
particularly challenging for a variety of reasons.
1. Time evolution. Most security datasets span several months. However,
an understanding of global trends requires access to a stable data collection
source, active and consistent in its observations across longer periods of time.
2. IP space characterization. Diﬀerent groups have shown already in 2004
that scanning activity is not uniformly distributed across the IP space [3,4].
Former analyses focused mostly on high level attack proﬁles and packet
volumes and have not gone as far as trying to characterize more in depth
the diﬀerences in the observations. However, it is commonly believed that full
visibility over server-side threats is possible only by spreading observation
points across as many networks as possible, a requirement associated with
high maintenance costs.
3. Stability. In order to compare observations and draw conclusions, the col-
lected data needs to be stable, i.e., the data collection infrastructure needs
to behave consistently throughout the observation period. Only in this case
it will be possible to reliably attribute diﬀerences in the observations to
changes in the threat landscape.
In this work, we build upon the outcome of the operation of an open dis-
tributed honeynet called SGNET [5]. SGNET was built with the above challenges
in mind and attempts to provide an unbiased and comparable overview over the
3
activities in the IP space. The free partnership schema on top of which the sys-
tem is built (sensors are contributed by volunteering partners on a best-eﬀort
basis) renders the dataset particularly challenging to analyze (the sensor popu-
lation varies widely), but it still represents a unique and previously unexplored
perspective over the IP space. We have been able in fact to reassemble a total
of 5 years of network traces, accounting for a total of 31.7 million TCP ﬂows.
Through the raw data at our disposal, we aim at tackling two core ques-
tions: i) understand the long-term trends and characteristics of the server-side
exploits observable in the wild, and ii) assess the impact of these characteris-
tics on commonly used practices for the detection and analysis of server-side
exploits. Of particular interest is the analysis of the impact of long-term trends
on knowledge-based approaches: we want to explore the practical feasibility of
tackling real-world threats by fully relying on a priori knowledge on their char-
acteristics. To the best of our knowledge, thanks to the unique characteristics of
our dataset, this constitutes the ﬁrst large scale analysis of the server-side threat
landscape across the two previously mentioned dimensions: visibility over a long
time span, but also visibility across diﬀerent networks of the IP space. Against
our expectations, we discover a diverse, challenging scenario that is tackled by
diﬀerent state of the art techniques with a highly diverse level of success.
2 Detecting server-side exploits
An exploit against a server-side vulnerability typically comprises one or more
messages crafted to move the victim into a vulnerable state, followed by the
injection and execution of shellcode. Various approaches have been used to hin-
der shellcode detection through obfuscation, encryption, and polymorphism [6].
Nowadays, return-oriented programming (ROP) [7] payloads represent the high-
est level of sophistication, as the shellcode execution (if any [8]) depends on the
previous execution of code sequences that already exist in the exploited process.
When trying to collect information on server-side exploits, two main direc-
tions have been followed in the security literature. Standard intrusion detection
approaches have attempted to leverage knowledge on known threats to recognize
further instances of these threats in network environments [9,10]. On the other
hand, researchers have tried to develop more generic approaches aiming to de-
tect previously unknown attacks, without requiring detailed knowledge on their
speciﬁcities. Honeypots and shellcode detection techniques are two prominent
examples of such approaches, which respectively try to leverage two diﬀerent
inherent characteristics of code injection exploits: for honeypots, the lack of
knowledge on the network topology and thus on the real nature of the honeypot
host; for shellcode detection techniques, the need to transfer executable code to
the victim to be run as a consequence of an exploit.
2.1 Honeypots
Honeypots detect attacks by following a simple paradigm: any interaction carried
out with a honeypot host is suspicious, and very likely to be malicious. Two
4
broad honeypot categories can be identiﬁed: high interaction honeypots, where
attackers interact with a full implementation of a vulnerable system, and low
interaction honeypots, where attackers interact with a program that emulates a
vulnerable system by means of scripts or heuristics.
Observing that the state of a honeypot has changed is far from determining
how the honeypot was attacked, or from capturing the precise details of the at-
tack. To aid analysis, systems such as Sebek [11] allow for detailed monitoring of
system events and attacker actions. Still, such an approach requires an operator
to manually analyze the results and manage the honeypot, which is time con-
suming and not without risk. Consequently, several approaches aim to automate
attack detection and analysis through the identiﬁcation of changes in network
behavior [12] or the ﬁle system [13], and facilitate (large scale) deployment and
management of honeypots [14,15,16]. Argos [17] can accurately pinpoint an ex-
ploit and its shellcode by leveraging a CPU emulator modiﬁed to include taint
tracking capabilities. Instrumenting a virtual machine in such a way incurs a
performance overhead prohibitive for use in production systems. Shadow hon-
eypots [18] allow the integration of real servers and honeypots through more
heavily instrumented replicas of production systems.
Despite their progress in automated shellcode detection and analysis, high in-
teraction honeypots are often too expensive for large scale deployments. For this
reason, researchers have worked on tools that simulate vulnerable services using
scripts of a lower level of complexity. Honeyd [19] was the ﬁrst highly customiz-
able framework for the emulation of hosts or even entire networks. Subsequent
systems incorporated (partial) protocol implementations, detailed knowledge of
well-known exploits, shellcode analysis modules, and downloaders for collecting
malware samples. These concepts are implemented in Nepenthes [20], its python
counterpart Amun [21], and more recently Dionaea [22]. Diﬀerently from its
predecessors, Dionaea implements a richer protocol stack and relies on a CPU
emulator called libemu [23] for identifying any shellcode contained in an attack.
All these systems rely however on detailed knowledge about the exploita-
tion phase. Additionally, Amun and Nepenthes rely on a set of knowledge-based
heuristics for the emulation of shellcode: they are able to correctly handle only
those decryptors and payloads that are implemented in their shellcode emulation
engine. The coverage of these heuristics with respect to the threat landscape is so
far unexplored. To beneﬁt from the simplicity of low interaction techniques and
the richness of high interaction honeypots, a number of hybrid approaches have
been proposed. Among them is GQ [24], an Internet telescope that combines
high-interaction systems with protocol learning techniques, and SGNET [5,25]
which also leverages protocol learning techniques to monitor server-side exploits
by means of a network of low-complexity sensors (used in this work).
2.2 Shellcode detection
Shellcode detection approaches focus on detecting the presence of malicious ma-
chine code in arbitrary streams. Initial approaches focused on creating signatures
that match speciﬁc shellcode features such as NOP sleds or suspicious system
5
call arguments. However, machine instructions can be obfuscated quite easily,
rendering signature-based approaches ineﬀective [26,27], while the code can be
adjusted to thwart statistical approaches [28,29,30]. Despite this fact, a set of
static signatures for the identiﬁcation of common shellcode parts is still currently
maintained as part of multiple Snort rulesets.
As it is not feasible to create signatures for the myriad of diﬀerent shellcode
instances by hand, several approaches have been proposed for automated sig-
nature generation based on invariants extracted from groups of related network
ﬂows [31,32,33]. However, automatic signature generation requires a minimum
number of attacks to work and has diﬃculties in dealing with polymorphic shell-
code [34]. To counter polymorphic worms, Polygraph [35], PAYL [36], PADS [12],
and Hamsa [37] attempt to capture (sequences of) invariants or statistically
model byte distributions of exploits and polymorphic payloads. However these
are themselves vulnerable to attacks that mimic normal traﬃc [38,39]. An alter-
native approach to signature matching is vulnerability-based signatures, which
focus on matching invariants that are necessary for successful exploitation, in-
stead of implementation-speciﬁc exploit patterns [40,41].
Given the limitations of signature-based approaches in the face of zero-day
attacks and evasion techniques, several research eﬀorts turned to the detection
of shellcode through static analysis. Initial approaches focused on detecting the
NOP sled component [42,43], while later work attempted to detect sequences
ending with system calls [44], or focused on the analysis of control ﬂow graphs
generated through static analysis [45,46,47,48].
Unfortunately, code obfuscation even in its simplest form can prevent code
disassembly from being eﬀective, and obtaining the unobfuscated shellcode en-
tails some form of dynamic analysis. Both nemu [49,50] and libemu [23] im-
plement a x86 cpu emulator for performing dynamic analysis of shellcode. Both
approaches utilize getPC heuristics to identify potential oﬀsets in strings to start
execution from. However, where nemu attempts to identify polymorphic shell-
code by combining the getPC heuristics with detection of self-references during
the encryption phase, libemu focuses on the execution of the entire shellcode in