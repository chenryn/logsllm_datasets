Searching overheads: In practice, searching for data
structures in a kernel memory snapshot can take from tens of
milliseconds [51] up to to several minutes [31]. Thus, most
systems reduce overheads by searching periodically and
asynchronously (§IV-A). Periodic searches fundamentally
limit these approaches to detecting compromises after the
fact, rather than preventing policy violations. Moreover,
these approaches can only reliably detect compromises that
make persistent changes to a data structure. Transient mal-
ware can slip through the cracks between two searches of
kernel memory.
The rest of this subsection describes the three major
approaches to learning data structure signatures.
1) Hand-crafted data structure signatures: Introspection
and forensic analysis tools initially used hand-crafted signa-
tures, based on expert knowledge of the internal workings
of an OS. For instance, such a tool might generate the
list of running processes, similar to ps, by walking a
global task list in Linux. Examples of this approach include
Memparser [11], KNTLIST [9], GREPEXEC [4] and many
others [1, 2, 3, 5, 10, 12, 13, 16, 17, 81, 82].
The most sophisticated frameworks for hand-crafted re-
construction use a wide range of subtle invariants and allow
users to develop customized extensions. FACE/Ramparser
[37] is a scanner that leverages invariants on values within
a data structure, such as enumerated values and pointers
that cannot be null. Ramparser can identify running pro-
cesses (task struct), open network sockets (struct sock),
in-kernel socket buffers (sk buff ), loaded kernel modules
(struct module), and memory-mapped and open ﬁles for any
given process (vm area struct). Similarly, Volatility [15]
is a framework for developing forensics tools that analyze
memory snapshots, with a focus on helping end-users to
write extensions. Currently, Volatility includes tools that
607
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:01:07 UTC from IEEE Xplore.  Restrictions apply. 
Hand-crafting signatures and data structure reconstruction
tools creates an inherent limitation: each change to an OS
kernel requires an expert to update the tools. For instance,
a new version of the Linux kernel is released every 2–
3 months; bugﬁx updates to a range of older kernels are
released as frequently as every few weeks. Each of these
releases may change a data structure layout or invariant.
Similarly, different compilers or versions of the same com-
piler can change the layout of a data structure in memory,
frustrating hand-written tools. Hand-written tools cannot
keep pace with this release schedule and variety of OS
kernels and compilers; thus, most introspection research has
instead moved toward automated techniques.
2) Source code analysis: Automated reconstruction tools
may rely on source code analysis or debugging information
to extract data structures deﬁnitions, as well as leverage
sophisticated static analysis and source invariants to reduce
false positives during the search phase. Examples of source
code analysis tools include SigGraph [64], KOP [31], and
MAS [38].
extract a list of running processes, open network sockets
and network connections, DLLs loaded for each process,
OS kernel modules, system call tables, and the contents of
a given process’s memory.
One basic approach to source analysis is to identify
all kernel object types, and leverage points-to analysis to
identify the graph of kernel object types. Kernel Object
Pinpointer (KOP) [31] extended a fast aliasing analysis
developed for non-security purposes [49], with several ad-
ditional features, including: ﬁeld-sensitivity, allowing KOP
to differentiate accesses made to different ﬁelds within the
same struct; context-sensitivity, differentiating different uses
of union types and void pointers based on type infor-
mation in code at the call sites; as well as inter-procedural
and ﬂow-insensitive analysis, rendering the analysis robust
to conditional control ﬂow, e.g., if statements. In applying
the static analysis to a memory snapshot, KOP begins with
global symbols and traverses all pointers in the identiﬁed
data structures to generate a graph of kernel data structures.
A key challenge in creating this graph of data structures
is that not all of the pointers in a data structure point to valid
data. As a simple example, the Linux dcache uses deferred
memory reclamation of a directory entry structure, called a
dentry, in order to avoid synchronization with readers.
When a dentry is on a to-be-freed list, it may point to
memory that has already been freed and reallocated for
another purpose; an implicit invariant is that these pointers
will no longer be followed once the dentry is on this list.
Unfortunately, these implicit invariants can thwart simple
pointer traversal. MAS [38] addresses the issue of invalid
pointers by extending the static analysis to incorporate value
and memory alias checks.
Systems like MAS [38], KOP [31] and LiveDM [77] also
improve the accuracy of type discovery by leveraging the
fact that most OSes create object pools or slabs for each
object type. Thus, if one knows which pages are assigned
to each memory pool, one can reliably infer the type of any
dynamically allocated object. We hasten to note that this
assumption can be easily violated by a rootkit or malicious
OS, either by the rootkit creating a custom allocator, or
allocating objects of greater or equal size from a different
pool and repurposing the memory. Thus, additional effort is
required to detect unexpected memory allocation strategies.
SigGraph [64] contributed the idea that the graph structure
of the pointers in a set of data structures can be used as a
signature. As a simple example, the relationships of pointers
among task_struct structures in Linux is fundamentally
different than among inode structures. SigGraph represents
graph signatures in a grammar where each symbol represents
a pointer to a sub-structure. This signature grammar can be
extended to encode arbitrary pointer graphs or encode sub-
structures of interest. SigGraph is designed to work with a
linear scan of memory, rather than relying on reachability
from kernel symbols.
3) Dynamic Learning: Rather than identifying code in-
variants from kernel source code, VMI based on dynamic
analysis learns data structure invariants based on observing
an OS instance [24, 41, 64].
By analogy to supervised machine learning,
the VMI
tool trains on a trusted OS instance, and then classiﬁes
the data structures of potentially untrusted OS instances.
During the training phase, these systems often control the
stimuli, by running programs that will manipulate a data
structure of interest, or incorporating debugging symbols to
more quickly discern which memory regions might include
a structure of interest. Tools such as Daikon [43] are used
to generate constraints based on observed values in ﬁelds of
a given data structure.
Several dynamic systems have created robust signatures,
which are immune to malicious changes to live data structure
instances [41]. More formally, a robust signature identiﬁes
any memory location that could be used as a given structure
type without false negatives. A robust signature can have
false positives. Robust signatures are constructed through
fuzz testing during the training phase to identify invariants
which,
if violated, will crash the kernel [41, 64]. For
instance, RSFKDS begins its training phase with a guest
in a clean state, and then attempts to change different data
structure ﬁelds. If the guest OS crashes, this value is used
to generate a new constraint on the potential values of that
ﬁeld. The primary utility of robust signatures is detecting
when a rootkit attempts to hide persistent data by modifying
data structures in ways that the kernel doesn’t expect. The
key insight is that these attempts are only fruitful inasmuch
as they do not crash the OS kernel. Thus, robust signatures
leverage invariants an attacker cannot safely violate.
608
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:01:07 UTC from IEEE Xplore.  Restrictions apply. 
B. Code Implanting
A simpler approach to bridging the semantic gap is to
simply inject code into the guest OS that reports semantic
information back to the hypervisor. For example, Process
implanting [47] implants and executes a monitoring process
within a randomly-selected process already present in the
VM. Any malicious agent
inside the VM is unable to
predict which guest process has been replaced and thus the
injected code can run without detection. Rather than implant
a complete process, SYRINGE [30] implants functions into
the kernel, which can be called from the VM.
A challenge to implanting code is ensuring that
the
implanted code is not
tampered with, actually executes,
and that the guest OS components it uses report correct
information. SIM [84] uses page table protections to isolate
an implanted process’s address space from the guest OS
kernel. Section III-D discusses techniques to ensure the in-
tegrity of the OS kernel. Most of these implanting techniques
ultimately rely on the guest kernel to faithfully represent
information such as its own process tree to the injected code.
C. Process Outgrafting
In order to overcome the challenges with running a trusted
process inside of an untrusted VM, process outgrafting [86]
relocates a monitoring process from the monitored VM to
a second, trusted VM. The trusted VM has some visibility
into the kernel memory of the monitored VM, allowing a
VMI tools to access any kernel data structure without any
direct interference from an adversary in the monitored VM.
Virtuoso [40] automatically generates introspection pro-
grams based on dynamic learning from a trusted VM,
and then runs these tools in an outgrafted VM. Similarly,
OSck [51] generates introspection tools from Linux source
which execute in a monitoring VM with a read-only view
of a monitored guest.
VMST [44] generalizes this approach by eliminating the
need for dynamic analysis or customized tools; rather, a
trusted, clean copy of the OS runs with a roughly copy-on-
write view of the monitored guest. Monitoring applications,
such as ps, simply execute in a complete OS environment on
the monitoring VM; each system call executed actually reads
state from the monitored VM. VMST has been extended
with an out-of-VM shell with both execute and write capa-
bilities [45], as well as accelerated by using memoization,
trading some accuracy for performance [80]. This approach
bridges the semantic gap by repurposing existing OS code.
The out-grafting approach has several open problems.
First, if the monitoring VM treats kernel data as copy-
on-write,
the monitoring VM must be able to reconcile
divergences in the kernel views. For example, each time the
kernel accesses a ﬁle, the kernel may update the inode’s
atime. These atime updates will copy the kernel data,
which must be discarded for future introspection or view
of the ﬁle system will diverge. VMST does not address
this problem, although it might be addressed by an expert
identifying portions of the kernel which may safely diverge,
or resetting the VM after an unsafe divergence. Similar to
the limitations of hand-crafted introspection tools, each new
OS variant may require hand-updates to divergent state; thus,
automating divergence analysis is a useful topic for future
work. Finally,
this approach cannot handle policies that
require visibility into data on disk—either ﬁles or swapped
memory pages.
D. Kernel executable integrity
The introspection approaches described above assume
that the executable kernel code does not change between
creation of the introspection tools and monitoring the guest
OS. Table II lists additional assumptions made by these
techniques.
In order to uphold the assumption that the kernel has not
changed, most hypervisor-based security systems must also
prevent or limit the ability of the guest OS to modify its
own executable code, e.g., by overwriting executable pages
or loading modules. This subsection summarizes the major
approaches to ensuring kernel binary integrity.
1) The (Write ⊕ Execute) principle: The W ⊕ X prin-
ciple prevents attacks that write the text segment by en-
forcing a property where all the pages are either writable
or executable, but not both at the same time. For instance,
SecVisor [83] and NICKLE [79] are hypervisors that enforce
the W ⊕ X principle by setting page table permissions on
kernel memory. SecVisor will only set executable permission
on kernel code and loadable modules that are approved by
an administrator, and prevent modiﬁcation of this code.
Although non-executable (NX) page table bits are ubiq-
uitous on modern x86 systems, lack of NX support compli-
cated the designs of early systems that enforced the W ⊕ X
principle. Similarly, compilers can mix code and data within
the same page, although security-conscious developers can
also restrict this with linker directives.
2) Whitelisting code: As discussed above, SecVisor and
NICKLE policies require a notion of approved code, which
is represented by a whitelist of code hashes created by the
administrator.
Patagonix [65] extends this property to application bina-
ries, without the need to understand the structure of pro-
cesses and memory maps. Patagonix leverages no-execute
page table support
time data
from a page of memory is loaded into the CPU instruction
cache. These pages are then compared against a database of
whitelisted application binary pages.
to receive a trap the ﬁrst
Although whitelisting code can prevent loading unknown
modules which are the most likely to be malicious, the
approach is limited by the administrator’s ability to judge
whether a driver or OS kernel is malicious a priori.
3) Object code hooks: A practical limitation of the W ⊕
X principle is that many kernels place function pointers in
609
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:01:07 UTC from IEEE Xplore.  Restrictions apply. 
Technique
Hand-crafted data structure signatures
(Expert knowledge)
Assumptions
• Expert knowledge of OS internals for known kernel version
• Guest OS is not actively malicious
Automated learning and reconstruction
(Source analysis or ofﬂine training)
Code implanting
(VMM protects monitoring agent inside
guest OS)
Process outgrafting
(Reuse monitoring tools from sibling VM
with shared kernel memory)
Kernel executable integrity
(Protect executable pages and other code
hooks)
• Benign copy of OS for training
• OS will behave similarly during learning phase and moni-
• Security-sensitive invariants can be automatically learned
• Attacks will persist long enough for periodic scans
toring
• Malicious guest schedules monitoring tool and reports
information accurately
• Live, benign copy of OS behaves identically to monitored
OS
• Initial benign version of monitored OS
• Administrator can white-list safe modules
Monitor Placement
Systems
Sibling VM,
hypervisor, or
hardware
Sibling VM,
hypervisor, or
hardware
[1, 2, 3, 4, 5,
9, 10, 11, 12,
13, 16, 17,
81, 82]