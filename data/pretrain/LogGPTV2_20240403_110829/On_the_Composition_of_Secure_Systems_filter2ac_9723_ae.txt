Introduction
Each  researcher  that  has  proposed  a  new  security  property  has  constructed  his
own notation and formalism.  Every new security property proposal must be accompanied
with a proof of composability.  With different notations and assumptions about the model
of components, comparing the strengths and weaknesses of the various security properties
has  been  difficult.    In  this  chapter  we  examine  security  properties  in  general.    We  then
present a unified framework for the specification and analysis of security properties.  This
framework is used throughout this work in proving properties about the  composition  of
components that satisfy security properties.
There  have  been  various  frameworks  presented  for  analyzing  properties  of
components [Hoare85] [Abadi & Lamport90] [McLean94] [Nestor93] [Hinton96].  Why
is another framework required?  In Section 4.7 we show that security properties do  not
fall  within  the  Alpern-Schneider  [Alpern  &  Schneider85]  safety/liveness  framework
presented  in  Chapter  2.    Therefore,  the  Abadi  and  Lamport  [Abadi  and  Lamport90]
composition principle cannot be applied to security properties.
One of the first attempts to provide a general theory of security properties was the
use  of  Selective  Interleaving  Functions  [Mclean94].    McLean's  framework  as  will  be
demonstrated  is  only  applicable  to  a  subset  of  security  properties.    Possibly  its  greatest
weakness, however, is that it does not allow for an obvious specification of security.  Our
framework  captures  the  intuitive  notion  of  security  properties  and  can  be  used  to
determine the composability of components that satisfy security properties.  A comparison
of selective interleaving functions and our framework is presented in Chapter 6.
- 25 -
In this chapter we introduce and motivate security properties.  Chapter 5 presents
composition theorems that can be used to determine the composability of these properties.
4.2.  Properties of Secure Systems
A secure computer system is one that has the properties of confidentiality, integrity
and availability [McLean94].  There is no clear distinction between these properties since
they are not independent.  A Trojan Horse that corrupts files makes these files unavailable.
Also, a Trojan Horse that makes a system unavailable can be used to transmit data to low
level users.  Therefore, confidentiality cannot be assumed without some degree of integrity
and  availability.    Each  of  confidentially,  integrity  and  availability  is  useful,  however,
because each category has its own set of issues.
In  this  work  we  are  interested  in  confidentiality  properties.    The  goal  of
confidentiality  is  to  prevent  low  level  users  from  deducing  anything  about  high  level
activity.    The  security  policy  defines  exactly  what  low  level  users  are  forbidden  to
discover.  For example, it may be considered desirable  to  ensure  low  level  users  cannot
determine which high level inputs have occurred.  Or we may say, information about high
level inputs may not flow to LLU.  The security policy dictates what flows are permissible
and which are not.  A security property is an instantiation of a policy.  There may be more
than  one  property  that  satisfies  a  given  policy.    In  this  work  we  do  not  advocate  any
specific security policy.  We consider security properties in general2.
As with all of the work on confidentiality, we take an optimistic view of the LLUs
abilities and a pessimistic view of the intent of the HLUs.  For example, we assume LLUs
have  complete  knowledge  of  the  construction  of  the  system  and  that  HLUs,  when
confronted with a choice, will make the one that compromises system security the most.
Taking  this  approach  we  get  a  lower  bound  on  the  security  of  the  system  being
considered.
2 
In this work when referring to security we mean confidentiality.
- 26 -
4.3. 
Inference
To understand what a security property is, we must first understand how low level
users can infer information about high level users’ activities.  Information will be deemed
to  flow  from  high  level  users  to  low  level  users  when  the  low  level  users  observe
something they believe is connected with high level user activity:
“Information  is  transmitted  along  an  object  when  variety  in  the  events
engaged by a [high level] user can be conveyed to a [low level] user as a
result of [the high level users] interaction with the object.” [Foley87]
There are two types of inferences that can be made:
1.   possibilistic
2.   probabilistic
In the possibilistic case, one is interested in the possibility of certain events.  In the
probabilistic  case  the  probability  of  the  events  is  also  considered.    Nearly  all  work  on
secure  systems  has  been  on  possibilistic  properties  and  systems.    Some  work  on
probabilistic properties has been presented [Gray90] [McLean90] [Gray92].
In this work we are interested in possibilistic properties and inferences.  Johnson
and Thayer argued that “possibilistic specifications for computer systems [are] inadequate
for  addressing  the  main  problems  of  computer  security”  [Johnson  &  Thayer88].    While
this  might  be  the  case  we  cannot  hope  to  understand  the  dynamics  of  a  probabilistic
system without first understanding the possibilistic case.
In the following discussion it will be useful to examine the bunch of traces that are
consistent  with  a  given  low  level  observation.    The  definition  of  a  low  level  equivalent
bunch captures this notion.
Definition 4.1: Low level Equivalent Bunch.
Given a trace t  and a System S, Blow(t ,S) is the bunch of traces that have
the same low level events as t  in the same order.  We will write Blow(t )
when referring to an arbitrary system S.  Formally,
§s:traces(S)(cid:215)
|L=s|L
When a low level user observes a sequence of events t
low he knows there exists a t
low.  Since we assume that the low level user knows the architecture of the
such that t
|L=t
- 27 -
t
component he can determine the low level equivalent bunch  corresponding  to t
question that we wish to address is what can the user infer about t
|H?
low.    The
One of the first attempts to model the flow of information in a secure system is due
to  Sutherland  [Sutherland86].    His  theory  of  information  flow  is  based  on  logical
deduction.  Sutherland argued that if there were high level event sequences such that no
element  of  Blow(t
inferred something about high level behaviour.  Formally, information does not flow if and
only  if  "
low)  had  this  high  level  sequence  then  the  low  level  user  would  have
low,S)|H).    Thus  a  system  has  no
low:traces(S)|L(cid:215)
H:traces(S)|H(cid:215)
t H:(Blow(t
undesirable information flows if all possible high level event sequences are consistent with
every possible low level event sequence.
This definition of inference seems reasonable but it is neither complete nor useful.
We will not cover all the details of why this definition of inference is not acceptable for
secure  systems  but  we  will  cover  some  of  the  major  issues  below.    For  an  excellent
discussion on the subject see “A Trusted Network Architecture” [Thompson et. al 88] or
“Information Flow in Nondeterministic Systems” [Wittbold and Johnson90].
One of the biggest problems with Sutherland’s theory is that it allows systems with
undesirable information flows to be called secure and systems that do not have undesirable
flows to be called insecure.  Sutherland’s assertion that all possible high level activity must
be compatible with every low level sequence does not encompass  the  notion  of  security
correctly.
Consider a system whose only function is to copy all low level inputs to high level
outputs.  This system is clearly secure.  However, Sutherland’s theory indicates that a flow
from high to low level users to low level users exists.  It is true that the low level user has
knowledge of high level events but he  has  not  gained  any  new  information.  In  this  case
Sutherland’s  theory  is  too  strong.    Sutherland’s  definition  of  information  flow  is
symmetric.    If  there  is  a  flow  from  A  to  B  then  there  must  be  a  flow  from  B  to  A.
Security, however, is an asymmetric property.  Information flows from LLU to HLU are
allowed but information flows from HLU to LLU are not.
Sutherland’s  theory  also  allows  the  construction  of  a  system  that  hsa  real  but
unacceptable  flows.    This  happens  because  not  all  possible  methods  of  transmitting
- 28 -
t
"
t
information have been considered.  Only the existence of one interleaving of a high level
event sequence and a low level observation is required.  The low level user in examining
Blow(t
low) can however make the following observations:
1.  A particular high level input sequence is not consistent with t
2.  A particular interleaving of high level event sequences is not possible.
low.
3.  A high level output event that does not depend on any high level input events is
not consistent with t
low.
No other observations can be made.  High level outputs that depend on input events are
not a factor because if something can be inferred about these events then something can be
inferred about high level inputs.  We do not want to imply that the LLU will not know that
a high level output has occurred.  But, we do imply that the knowledge of the occurrence
gives no information about the activities of the high level users.
The first item above has been addressed by many researchers but the second has
received  little  attention.    Guttman  and  Nadel  [Guttman  &  Nadel88]  mentioned  it  as  a
problem they were trying to address in the presentation of their security property.  Their
exposition  of  the  problem  does  not  adequately  address  the  issue.    Furthermore,  their
examples  are  not  convincing  enough  to  demonstrate  the  problem  with  interleavings.    It
was hypothesized by Lee [Lee et. al 92] that the interleavings problem might be connected
to  the  issue  of  nondeterminism.    We  agree  with  this  and  will  demonstrate  why
interleavings need to be considered.
Example 4.1: Machine A has one high level input in, and one high-level output out which
is caused by in after some processing.  There is a low-level cancel input,  which  cancels
any high-level processing that is underway, and a low-level ack output that acknowledges
the cancel input after some time interval.  If there is high-level processing at the time of
the ack, that is, if the number of out events is less than the number of in events, all high-
level processing is terminated, and no out will occur until after the next uncancelled in.  If
there is no high-level processing at the time of ack, then a low-level error output may be
produced at some time following the ack; however, the error output is not guaranteed to
occur.
It  is  easy  to  see  that  for  any  sequence  of  low  level  events  every  high  level  input
sequence is possible.  However, consider the low level observation:
- 29 -
This low level observation precludes the following interleaving of the high level sequence
:
The out event must come before the ack event.  Therefore, the low level user knows that
at the time of the ack no high level events are present.  This information can be used to
transmit information from the high level user to the low level user.
G
In light of the above discussion we propose the following definition for information
flow in a secure system:
Definition 4.2: Information Flow.
Information flows from high level users to low level users if and only if
the low level user’s observation of t
low implies that at least one high level
event sequence or interleaving is not possible.
Information  flows  from  high  level  users  to  low  level  users  if  there  exists  a  high
level trace or interleaving such that if it had occurred then t
Care must be taken in interpreting this statement.  If low level actions influence high level
low could not have occurred.
behaviour then it is possible for a particular sequence not to be possible because the low
level influence precludes it.  However, in this case no inference is possible.  For example,
the  low  level  user  may  know  his  influence  could  not  possibly  result  in  a  particular  high
level  output,  or  in  the  extreme  case,  may  know  exactly  what  the  output  must  be.    But
what is the inference?  The low level user is precluding high level events from occurring.
Therefore, he can communicate with the high level user through a covert channel but low
level to high level communication is already allowed.
4.3.1. The Perfect Security Property
Separability  is  an  example  of  perfect  security  [McLean94].    This  is  because  no
interaction  is  allowed  between  high  level  and  low  level  events3.    It  is  like  having  two
separate  systems,  one  running  the  high  level  processes  and  one  running  the  low  level
3 
We  must  stress  that  this  is  in  the  possibilistic  sense.    It  is  possible  to  construct  a  Separability
secure system that has covert channels.
- 30 -
processes.  Separability can be defined as follows.  For every pair of traces t 1 and t 2 the
trace t  such that t
|H=t 2|H is a valid trace.
|L=t 1|L and t
The problem with Separability is that it does not allow low level users to influence
high level activity.  For example, a computer system that keeps a journal of all low level
user activity on a high level device would not be considered secure.
We  will  present  a  security  property  that  is  the  weakest  property  that  does  not
allow a flow from high level users to low level users.  Our property will allow low level
users  to  influence  high  level  user  activity.    The  Perfect  Security  Property  (PSP)  will  be
proven to be the weakest property that does not allow a flow from high level users to low
level users.
The idea behind PSP is the same as that behind Separability.  All possible high level
activity and interleavings must be possible with all low level activity.  The difference is that
PSP allows high level outputs to be dependent on low level events.  The choice of output
event for any given interleaving can depend on low level events.  This implies that not all
interleavings of high  level  events  are  possible.    This,  as  will  be  shown,  does  not  reduce
security  because  the  low  level  user  will  not  know  how  he  has  influenced  high  level
outputs.
The traces of the system are constructed from the set of events of the system.  The
set of events defines all the events that the system can engage in.  The definition of PSP
requires the insertion of events in traces.  To simplify the presentation of PSP we need to
represent the insertion of no event.  To accomplish this we introduce a special event the
use of which has no effect on the set of possible traces.  It is merely a placeholder.
Definition 4.3: Null Events
The symbol e  will be used to represent an event that is governed by the
following axiom:
p^   ^ s =  p^ s
p^ s˛ T
The following function gives all the possible high level events that may occur after
a prefix of a given trace.  This function will be used to construct all the interleavings of
high level sequence with low level events.  Notice that since we will be using a function
- 31 -
that gives all possible events after a trace, it is possible that the low level activity in the
trace can influence the possible events.
Definition 4.4: Possible Event Function.
(cid:215) traces(t ^ ).    This  function  returns
Given  a  trace t ,  Let n (t )=§e:H¨
the  bunch  of  all  possible  high  level  events  that  can  occur  after  t .    The
function n (t ) is called the possible event function.
The definition of the possible event function requires e  to be a possible event.  This
will ensure that there will be no case where an event must occur.
The following defines PSP.  The idea behind the property is that for any low level
observation the following must be true:
1.   All interleavings of high level input sequences must be possible.
2.   High  level  outputs  can  be  inserted  anywhere  in  the  trace  (assuming  they  are
possible) and can depend on low level activity.
If  all  high  level  input  sequences  are  possible  and  high  level  outputs  can  be  inserted
anywhere then the low level user cannot determine anything about high level activity.  This
observation will be proven below.
Definition 4.5: The Perfect Bunch
Given  an  event  system  S  and  a  low  level  observation t
Blow(t
low,S) contains the following traces then the bunch is perfect.
low,  if  the  bunch
" p,s:E*(cid:215) tracess(p^ s)(cid:217) s|H=<>(cid:217) p^ s |L=t
low(cid:222)
:n (p)(cid:215) p^ a
 ^ s : Blow(t
low,S)
Definition 4.6: The Perfect Security Policy.
low  the  bunch  Blow(t
low,S)  is  perfect  then  the  system  satisfies
If  for  all  t
PSP.
The expression of the property might seem complicated but fortunately there exists
a simple procedure to determine if a component satisfies PSP (see Chapter 7).  We  will
use this property to determine the strength of the properties presented in the literature (see
section 4.5).
The  definition  of  PSP  can  be  transformed  into  a  definition  for  Separability  by
defining the possible event function as follows:
- 32 -
e
"
a
n (t )=§e:H¨
(cid:215) traces( (t ^ e) |H )
The only difference between this definition of the possible event function and the
one given in Definition 4.4 is that this possible events only depend on the preceding high
level  events,  not  the  whole  trace.    We  defer  the  proofs  that  PSP  allows  no  information
flow and is the weakest such property until section 4.6 because we require concepts that
have not yet been introduced.
4.4.  Security Properties
In  the  previous  section  we  defined  a  security  property  that  does  not  allow  any
information to flow from high level users to low level users.  It would appear that with this
property no other property is required.   There are many reasons why other properties are
required.  For example:
1.   The risk analysis of the system indicates little threat of Trojan horses.  In this
case a security property with the possibility of some unauthorized flows might
be acceptable.
2.   A  desired  component  does  not  satisfy  this  property  and  a  weaker  property
must be used.