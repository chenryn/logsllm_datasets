### Introduction

Each researcher who has proposed a new security property has developed their own notation and formalism. Every new security property proposal must be accompanied by a proof of composability. Due to the variety of notations and assumptions about the model of components, comparing the strengths and weaknesses of different security properties has been challenging. In this chapter, we examine security properties in general and present a unified framework for specifying and analyzing these properties. This framework is used throughout this work to prove properties about the composition of components that satisfy security properties.

Several frameworks have been presented for analyzing component properties, including those by Hoare [Hoare85], Abadi and Lamport [Abadi & Lamport90], McLean [McLean94], Nestor [Nestor93], and Hinton [Hinton96]. Why is another framework necessary? In Section 4.7, we show that security properties do not fit within the Alpern-Schneider safety/liveness framework [Alpern & Schneider85] presented in Chapter 2. Consequently, the Abadi and Lamport composition principle cannot be applied to security properties.

One of the early attempts to provide a general theory of security properties was the use of Selective Interleaving Functions [Mclean94]. However, McLean's framework is only applicable to a subset of security properties and does not allow for an obvious specification of security. Our framework captures the intuitive notion of security properties and can be used to determine the composability of components that satisfy these properties. A comparison of selective interleaving functions and our framework is provided in Chapter 6.

In this chapter, we introduce and motivate security properties. Chapter 5 presents composition theorems that can be used to determine the composability of these properties.

### 4.2. Properties of Secure Systems

A secure computer system is one that ensures confidentiality, integrity, and availability [McLean94]. These properties are interdependent and often overlap. For example, a Trojan Horse that corrupts files makes them unavailable, and a Trojan Horse that makes a system unavailable can be used to transmit data to low-level users. Therefore, confidentiality cannot be assumed without some degree of integrity and availability. Each of these properties—confidentiality, integrity, and availability—is important because each addresses a distinct set of issues.

In this work, we focus on confidentiality properties. The goal of confidentiality is to prevent low-level users from deducing anything about high-level activity. The security policy defines what low-level users are forbidden to discover. For instance, it may be desirable to ensure that low-level users cannot determine which high-level inputs have occurred, or that information about high-level inputs does not flow to low-level users. The security policy dictates permissible and impermissible flows. A security property is an instantiation of a policy, and there may be multiple properties that satisfy a given policy. In this work, we do not advocate any specific security policy but consider security properties in general.

We take an optimistic view of the abilities of low-level users (LLUs) and a pessimistic view of the intent of high-level users (HLUs). For example, we assume LLUs have complete knowledge of the system's construction and that HLUs, when faced with a choice, will make the one that compromises system security the most. This approach provides a lower bound on the security of the system being considered.

### 4.3. Inference

To understand what a security property is, we must first understand how low-level users can infer information about high-level users' activities. Information is deemed to flow from high-level users to low-level users when the latter observe something they believe is connected with high-level user activity:

“Information is transmitted along an object when the variety in the events engaged by a [high-level] user can be conveyed to a [low-level] user as a result of [the high-level user’s] interaction with the object.” [Foley87]

There are two types of inferences:
1. Possibilistic
2. Probabilistic

In the possibilistic case, one is interested in the possibility of certain events. In the probabilistic case, the probability of the events is also considered. Most work on secure systems has focused on possibilistic properties and systems, although some work on probabilistic properties has been presented [Gray90, McLean90, Gray92].

In this work, we are interested in possibilistic properties and inferences. Johnson and Thayer argued that “possibilistic specifications for computer systems [are] inadequate for addressing the main problems of computer security” [Johnson & Thayer88]. While this may be true, we cannot hope to understand the dynamics of a probabilistic system without first understanding the possibilistic case.

It is useful to examine the bunch of traces that are consistent with a given low-level observation. The definition of a low-level equivalent bunch captures this notion.

**Definition 4.1: Low-Level Equivalent Bunch.**
Given a trace \( t \) and a System \( S \), \( \text{Blow}(t, S) \) is the bunch of traces that have the same low-level events as \( t \) in the same order. We will write \( \text{Blow}(t) \) when referring to an arbitrary system \( S \). Formally,
\[ \text{Blow}(t, S) = \{ s \in \text{traces}(S) \mid s|L = t|L \} \]

When a low-level user observes a sequence of events \( t_{\text{low}} \), they know there exists a \( t \) such that \( t|L = t_{\text{low}} \). Since we assume the low-level user knows the architecture of the component, they can determine the low-level equivalent bunch corresponding to \( t_{\text{low}} \). The question we wish to address is what can the user infer about \( t|H \)?

One of the first attempts to model the flow of information in a secure system is due to Sutherland [Sutherland86]. His theory of information flow is based on logical deduction. Sutherland argued that if there were high-level event sequences such that no element of \( \text{Blow}(t_{\text{low}}) \) had this high-level sequence, then the low-level user would have inferred something about high-level behavior. Formally, information does not flow if and only if
\[ \forall t_{\text{low}} \in \text{traces}(S)|L, \forall H \in \text{traces}(S)|H, \exists t_H \in \text{Blow}(t_{\text{low}}, S) \text{ such that } t_H|H = H \]

Thus, a system has no undesirable information flows if all possible high-level event sequences are consistent with every possible low-level event sequence.

This definition of inference seems reasonable but is neither complete nor useful. We will not cover all the details of why this definition is not acceptable for secure systems, but we will discuss some of the major issues below. For a detailed discussion, see “A Trusted Network Architecture” [Thompson et al. 88] or “Information Flow in Nondeterministic Systems” [Wittbold and Johnson90].

One of the biggest problems with Sutherland’s theory is that it allows systems with undesirable information flows to be called secure and systems without undesirable flows to be called insecure. Sutherland’s assertion that all possible high-level activity must be compatible with every low-level sequence does not correctly encompass the notion of security.

Consider a system whose only function is to copy all low-level inputs to high-level outputs. This system is clearly secure. However, Sutherland’s theory indicates that a flow from high to low-level users exists. It is true that the low-level user has knowledge of high-level events, but they have not gained any new information. In this case, Sutherland’s theory is too strong. Sutherland’s definition of information flow is symmetric. If there is a flow from A to B, then there must be a flow from B to A. Security, however, is an asymmetric property. Information flows from LLU to HLU are allowed, but information flows from HLU to LLU are not.

Sutherland’s theory also allows the construction of a system with real but unacceptable flows. This happens because not all possible methods of transmitting information have been considered. Only the existence of one interleaving of a high-level event sequence and a low-level observation is required. The low-level user, in examining \( \text{Blow}(t_{\text{low}}) \), can make the following observations:
1. A particular high-level input sequence is not consistent with \( t_{\text{low}} \).
2. A particular interleaving of high-level event sequences is not possible.
3. A high-level output event that does not depend on any high-level input events is not consistent with \( t_{\text{low}} \).

No other observations can be made. High-level outputs that depend on input events are not a factor because if something can be inferred about these events, then something can be inferred about high-level inputs. We do not want to imply that the LLU will not know that a high-level output has occurred. But, we do imply that the knowledge of the occurrence gives no information about the activities of the high-level users.

The first item above has been addressed by many researchers, but the second has received little attention. Guttman and Nadel [Guttman & Nadel88] mentioned it as a problem they were trying to address in the presentation of their security property. Their exposition of the problem does not adequately address the issue, and their examples are not convincing enough to demonstrate the problem with interleavings. Lee [Lee et al. 92] hypothesized that the interleavings problem might be connected to the issue of nondeterminism. We agree with this and will demonstrate why interleavings need to be considered.

**Example 4.1: Machine A**
Machine A has one high-level input \( \text{in} \) and one high-level output \( \text{out} \), which is caused by \( \text{in} \) after some processing. There is a low-level cancel input, which cancels any high-level processing that is underway, and a low-level ack output that acknowledges the cancel input after some time interval. If there is high-level processing at the time of the ack, that is, if the number of out events is less than the number of in events, all high-level processing is terminated, and no out will occur until after the next uncancelled in. If there is no high-level processing at the time of ack, then a low-level error output may be produced at some time following the ack; however, the error output is not guaranteed to occur.

It is easy to see that for any sequence of low-level events, every high-level input sequence is possible. However, consider the low-level observation:
- \( \text{cancel, ack, error} \)

This low-level observation precludes the following interleaving of the high-level sequence:
- \( \text{in, out, cancel, ack, error} \)

The out event must come before the ack event. Therefore, the low-level user knows that at the time of the ack, no high-level events are present. This information can be used to transmit information from the high-level user to the low-level user.

In light of the above discussion, we propose the following definition for information flow in a secure system:

**Definition 4.2: Information Flow.**
Information flows from high-level users to low-level users if and only if the low-level user’s observation of \( t_{\text{low}} \) implies that at least one high-level event sequence or interleaving is not possible.

Information flows from high-level users to low-level users if there exists a high-level trace or interleaving such that if it had occurred, then \( t_{\text{low}} \) could not have occurred.

Care must be taken in interpreting this statement. If low-level actions influence high-level behavior, then it is possible for a particular sequence not to be possible because the low-level influence precludes it. However, in this case, no inference is possible. For example, the low-level user may know their influence could not possibly result in a particular high-level output, or in the extreme case, may know exactly what the output must be. But what is the inference? The low-level user is precluding high-level events from occurring. Therefore, they can communicate with the high-level user through a covert channel, but low-level to high-level communication is already allowed.

### 4.3.1. The Perfect Security Property

Separability is an example of perfect security [McLean94]. This is because no interaction is allowed between high-level and low-level events. It is like having two separate systems, one running the high-level processes and one running the low-level processes. Separability can be defined as follows: for every pair of traces \( t_1 \) and \( t_2 \), the trace \( t \) such that \( t|L = t_1|L \) and \( t|H = t_2|H \) is a valid trace.

The problem with separability is that it does not allow low-level users to influence high-level activity. For example, a computer system that keeps a journal of all low-level user activity on a high-level device would not be considered secure.

We will present a security property that is the weakest property that does not allow a flow from high-level users to low-level users. Our property will allow low-level users to influence high-level user activity. The Perfect Security Property (PSP) will be proven to be the weakest property that does not allow a flow from high-level users to low-level users.

The idea behind PSP is the same as that behind separability. All possible high-level activity and interleavings must be possible with all low-level activity. The difference is that PSP allows high-level outputs to be dependent on low-level events. The choice of output event for any given interleaving can depend on low-level events. This implies that not all interleavings of high-level events are possible. This, as will be shown, does not reduce security because the low-level user will not know how they have influenced high-level outputs.

The traces of the system are constructed from the set of events of the system. The set of events defines all the events that the system can engage in. The definition of PSP requires the insertion of events in traces. To simplify the presentation of PSP, we need to represent the insertion of no event. To accomplish this, we introduce a special event, the use of which has no effect on the set of possible traces. It is merely a placeholder.

**Definition 4.3: Null Events**
The symbol \( e \) will be used to represent an event governed by the following axiom:
\[ p \land \epsilon \land s = p \land s \]
where \( p \land s \in T \).

The following function gives all the possible high-level events that may occur after a prefix of a given trace. This function will be used to construct all the interleavings of high-level sequences with low-level events. Notice that since we will be using a function that gives all possible events after a trace, it is possible that the low-level activity in the trace can influence the possible events.

**Definition 4.4: Possible Event Function**
Given a trace \( t \), let \( n(t) = \{ e \in H \mid \exists s \in \text{traces}(t \land e) \} \). This function returns the bunch of all possible high-level events that can occur after \( t \). The function \( n(t) \) is called the possible event function.

The definition of the possible event function requires \( e \) to be a possible event. This will ensure that there will be no case where an event must occur.

The following defines PSP. The idea behind the property is that for any low-level observation, the following must be true:
1. All interleavings of high-level input sequences must be possible.
2. High-level outputs can be inserted anywhere in the trace (assuming they are possible) and can depend on low-level activity.

If all high-level input sequences are possible and high-level outputs can be inserted anywhere, then the low-level user cannot determine anything about high-level activity. This observation will be proven below.

**Definition 4.5: The Perfect Bunch**
Given an event system \( S \) and a low-level observation \( t_{\text{low}} \), if the bunch \( \text{Blow}(t_{\text{low}}, S) \) contains the following traces, then the bunch is perfect:
\[ \forall p, s \in E^* \text{ such that } \text{traces}(p \land s) \text{ and } s|H = \langle \rangle, \exists a \in n(p) \text{ such that } p \land a \land s \in \text{Blow}(t_{\text{low}}, S) \]

**Definition 4.6: The Perfect Security Policy**
If for all \( t_{\text{low}} \), the bunch \( \text{Blow}(t_{\text{low}}, S) \) is perfect, then the system satisfies PSP.

The expression of the property might seem complicated, but fortunately, there exists a simple procedure to determine if a component satisfies PSP (see Chapter 7). We will use this property to determine the strength of the properties presented in the literature (see section 4.5).

The definition of PSP can be transformed into a definition for separability by defining the possible event function as follows:
\[ n(t) = \{ e \in H \mid \exists s \in \text{traces}((t \land e)|H) \} \]

The only difference between this definition of the possible event function and the one given in Definition 4.4 is that the possible events only depend on the preceding high-level events, not the whole trace. We defer the proofs that PSP allows no information flow and is the weakest such property until section 4.6 because we require concepts that have not yet been introduced.

### 4.4. Security Properties

In the previous section, we defined a security property that does not allow any information to flow from high-level users to low-level users. It might appear that with this property, no other property is required. However, there are several reasons why other properties are needed. For example:
1. The risk analysis of the system indicates little threat of Trojan horses. In this case, a security property with the possibility of some unauthorized flows might be acceptable.
2. A desired component does not satisfy this property, and a weaker property must be used.