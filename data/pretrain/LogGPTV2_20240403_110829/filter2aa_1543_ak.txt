block. So, take a good look at your current resources and your requirements for the next few
years in order to plan and design your VPC architecture. A VPC can have a CIDR block
ranging from /16 to /28, which means you can have between 65,536 and 16 IP addresses
for your VPC. AWS recommends that you choose the highest CIDR block available, so
always go for /16 CIDR block for your VPC. This way, you won't be short of IP addresses if
you need to increase your instances exponentially.
Unique IP address range
All VPC connectivity options require you to have non-overlapping IP ranges. Consider
future connectivity to all your internal and external networks. Make sure you take note of
all available IP ranges for all your environments, including remote networks, data centers,
offices, other AWS VPCs, and so on, before you assign CIDR ranges for your VPC. None of
these should conflict and overlap with any network that you want to connect with.
Leave the default VPC alone
AWS provides a default VPC in every region for your AWS account. It is best to leave this
VPC alone and start with a custom VPC for your requirement. The default VPC has all
components associated with it; however, the security configuration of all these components,
such as subnets, security groups, and network ACLs are quite open to the world. There is
no private subnet either. So, it is a good idea to create your own VPC from scratch using
either a VPC wizard in the AWS console or creating it manually through the AWS console
or AWS CLI. You can configure all resources as per your requirement for your custom VPC.
Moreover, by default, if a subnet is not associated with a route table or an NACL, it is
associated with the main route table and default NACL. These two components don't have
any restrictions on inbound and outbound traffic, and you risk exposing your resources to
the entire world.
You should not modify the main route table either; doing that might give other subnets
routes that they shouldn't be given. Always create a custom route table and keep the main
route table as it is.
AWS Virtual Private Cloud
[ 103 ]
Design for region expansion
AWS keeps on expanding its regions by adding more availability zones to them. We know
that one subnet cannot span more than one availability zone, and distributing our resources
across availability zones makes our application highly available and fault-tolerant. It is a
good idea to reserve some IP address for future expansion while creating subnets with a
subset of VPC CIDR block. By default, AWS reserves five IP address in every subnet for
internal usage; make a note of this while allocating IP addresses to a subnet.
Tier your subnets
Ideally, you should design your subnets according to your architecture tiers, such as the
database tier, the application tier, the business tier, and so on, based on their routing needs,
such as public subnets needing a route to the internet gateway, and so on. You should also
create multiple subnets in as many availability zones as possible to improve your fault-
tolerance. Each availability zone should have identically sized subnets, and each of these
subnets should use a routing table designed for them depending on their routing need.
Distribute your address space evenly across availability zones and keep the reserved space
for future expansion.
Follow the least privilege principle
For every resource you provision or configure in your VPC, follow the least privilege
principle. So, if a subnet has resources that do not need to access the internet, it should be a
private subnet and should have routing based on this requirement. Similarly, security
groups and NACLs should have rules based on this principle. They should allow access
only for traffic required. Do not add a route to the internet gateway to the main route table
as it is the default route table for all subnets.
Keep most resources in the private subnet
In order to keep your VPC and resources in your VPC secure, ensure that most of the
resources are inside a private subnet by default. If you have instances that need to
communicate with the internet, then you should add an Elastic Load Balancer (ELB) in the
public subnet and add all instances behind this ELB in the private subnet.
Use NAT devices (a NAT instance or a NAT gateway) to access public networks from your
private subnet. AWS recommends that you use a NAT gateway over a NAT instance as the
NAT gateway is a fully managed, highly available, and redundant component.
AWS Virtual Private Cloud
[ 104 ]
Creating VPCs for different use cases
You should ideally create one VPC each for your development, testing, and production
environments. This will secure your resources from keeping them separate from each other,
and it will also reduce your blast radius, that is, the impact on your environment if one of
your VPCs goes down.
For most use cases such as application isolation, multi-tenant application, and business unit
alignment, it is a good idea to create a separate VPC.
Favor security groups over NACLs
Security groups and NACLs are virtual firewalls available for configuring security rules for
your instances and subnets respectively. While security groups are easier to configure and
manage, NACLs are different. It is recommended that NACLs be used sparingly and not be
changed often. NACLs should be the security policy for your organization as it does not
work at a granular level. NACL rules are tied to the IP address and for a subnet, with the
addition of every single rule, the complexity and management of these rules becomes
exponentially difficult.
Security group rules are tied to instances and these rules span the entire VPC; they are
stateful and dynamic in nature. They are easier to manage and should be kept simple.
Moreover, security groups can pass other security groups as an object reference in order to
allow access, so you can allow access to your database server security group only for the
application server security group.
IAM your VPC
Access control for your VPC should be on top of your list while creating a VPC. You can
configure IAM roles for your instances and assign them at any point. You can provide
granular access for provisioning new resources inside a VPC and reduce the blast radius by
restricting access to high-impact components such as various connectivity options, NACL
configuration, subnet creation, and so on.
There will usually be more than one person managing all resources for your VPC; you
should assign permissions to these people based on their role and by following the principle
of least privileges. If someone does not need access to a resource, that access shouldn't be
given in the first place.
AWS Virtual Private Cloud
[ 105 ]
Periodically, use the access advisor function available in IAM to find out whether all the
permissions are being used as expected and take necessary actions based on your findings.
Create an IAM VPC admin group to manage your VPC and its resources.
Using VPC peering
Use VPC peering whenever possible. When you connect two VPCs using the VPC peering
option, instances in these VPCs can communicate with each other using a private IP
address. For a VPC peering connection, AWS uses its own network and you do not have to
rely on an external network for the performance of your connection, and it is a lot more
secure.
Using Elastic IP instead of public IP
Always use Elastic IP (EIP) instead of public IP for all resources that need to connect to the
internet. The EIPs are associated with an AWS account instead of an instance. They can be
assigned to an instance in any state, whether the instance is running or whether it is
stopped. It persists without an instance so you can have high availability for your
application depending on an IP address. The EIP can be reassigned and moved to Elastic
Network Interface (ENI) as well. Since these IPs don't change, they can be whitelisted by
target resources.
All these advantages of EIP over a public IP make it more favorable when compared with a
public IP.
Tagging in VPC
Always tag your resources in a VPC. The tagging strategy should be part of your planning
phase. A good practice is to tag a resource immediately after it is created. Some common
tags include version, owner, team, project code, cost center, and so on. Tags are supported
by AWS billing and for resource-level permissions.
AWS Virtual Private Cloud
[ 106 ]
Monitoring a VPC
Monitoring is imperative to the security of any network, such as AWS VPC. Enable AWS
CloudTrail and VPC flow logs to monitor all activities and traffic movement. The AWS
CloudTrail will record all activities, such as provisioning, configuring, and modifying all
VPC components. The VPC flow log will record all the data flowing in and out of the VPC
for all the resources in VPC. Additionally, you can set up config rules for the AWS Config
service for your VPC for all resources that should not have changes in their configuration.
Connect these logs and rules with AWS CloudWatch to notify you of anything that is not
expected behavior and control changes within your VPC. Identify irregularities within your
network, such as resources receiving unexpected traffic in your VPC, adding instances in
the VPC with configuration not approved by your organization, among others.
Similarly, if you have unused resources lying in your VPC, such as security groups, EIP,
gateways, and so on, remove them by automating the monitoring of these resources.
Lastly, you can use third-party solutions available on AWS marketplace for monitoring
your VPC. These solutions integrate with existing AWS monitoring solutions, such as AWS
CloudWatch, AWS CloudTrail, and so on, and provide information in a user-friendly way
in the form of dashboards.
Summary
The VPC is responsible for securing your network, including your infrastructure on the
cloud, and that makes this AWS service extremely critical for mastering security in AWS. In
this chapter, you learned the basics of VPC, including features, benefits, and most common
use cases.
We went through the various components of VPC and you learned how to configure all of
them to create a custom VPC. Alongside, we looked at components that make VPC secure,
such as routing, security groups, and so on.
We also looked at multiple connectivity options, such as a private, shared, or dedicated
connection provided by VPC. These connectivity options enable us to create a hybrid cloud
environment, a large connected internal network for your organization, and many such
secure, highly available environments to address many more scenarios.
AWS Virtual Private Cloud
[ 107 ]
Lastly, you learned about the limits of various VPC components and we looked at an
exhaustive list of VPC best practices.
In the next chapter, we will look at ways to secure data in AWS: data security in AWS in a
nutshell. You will learn about encrypting data in transit and at rest. We will also look at
securing data using various AWS services.
4
Data Security in AWS
Data security in the AWS platform can be classified into two broad categories:
Protecting data at rest
Protecting data in transit
Furthermore, data security has the following components that help in securing data in
multiple ways:
Data encryption
Key Management Services (KMS)
Access control
AWS service security features
AWS provides you with various tools and services to secure your data in AWS when your
data is in transit or when your data is at rest. These tools and services include resource
access control using AWS Identity and Access Management (IAM), data encryption, and
managed KMS, such as AWS KMS for creating and controlling keys used for data
encryption. The AWS KMS provides multiple options for managing your entire Key
Management Infrastructure (KMI). Alternatively, you also have the option to go with the
fully managed AWS CloudHSM service, a cloud-based hardware security module (HSM)
that helps you generate and use your own keys for encryption purpose.
AWS recently launched a new security service to protect your sensitive data by using
machine learning algorithms; this service is called Amazon Macie. As of now, it offers
security for all data stored in your Amazon Simple Storage Service (S3).
Data Security in AWS
[ 109 ]
If you want to protect your data further due to business or regulatory compliance purposes,
you can enable additional features for accidental deletion of data such as the versioning
feature in AWS S3, MFA for accessing and deleting data, enable cross-region replication for
more than one copy of your data in AWS S3, and so on.
All data storage and data processing AWS services provide multiple features to secure your
data. Such features include data encryption at rest, data encryption in transit, MFA for
access control and for deletion of data, versioning for accidental data deletion, granular
access control and authorization policies, cross-region replication, and so on.
Chapter overview
In this chapter, we will learn about protecting data in the AWS platform for various AWS
services. To begin with, we will go over the fundamentals of encryption and decryption and
how encryption and decryption of data work in AWS. Post that, we will start with security
features for securing data in transit and at rest for each of the following AWS services:
Amazon Simple Storage Service (S3)
Amazon Elastic Block Storage (EBS)
Amazon Relational Database Service (RDS)
Amazon Glacier
Amazon DynamoDB
Amazon Elastic Map Reduce (EMR)
We will look at data encryption in AWS and we will learn about three models that are
available for managing keys for encryption and how we can use these models for
encrypting data in various AWS services such as, AWS S3, Amazon EBS, AWS Storage
Gateway, Amazon RDS, and so on.
Next, we will deep dive on AWS KMS and go through KMS features and major KMS
components.
Data Security in AWS
[ 110 ]
Furthermore, we will go through the AWS CloudHSM service with its benefits and popular
use cases.
Lastly, we will take a look at Amazon Macie, the newest security service launched by AWS
to protect sensitive data using machine learning at the backend.
Encryption and decryption fundamentals
Encryption of data can be defined as converting data known as plaintext into code, often
known as ciphertext, that is unreadable by anyone except the intended audience. Data
encryption is the most popular way of adding another layer of security for preventing
unauthorized access and use of data. Encryption is a two-step process: in the first step, data
is encrypted using a combination of an encryption key and an encryption algorithm, in the
second step, data is decrypted using a combination of a decryption key and a decryption
algorithm to view data in its original form.
The following three components are required for encryption. These three components work
hand in hand for securing your data:
Data to be encrypted
Algorithm for encryption
Encryption keys to be used alongside the data and the algorithm
There are two types of encryption available, symmetric and asymmetric. Asymmetric
encryption is also known as public key encryption. Symmetric encryption uses the same
secret key to perform both the encryption and decryption processes. On the other hand,
asymmetric encryption uses two keys, a public key for encryption and a corresponding
private key for decryption, making this option more secure and at the same time more
difficult to maintain as you would need to manage two separate keys for encryption and
decryption.
AWS only uses symmetric encryption
Data Security in AWS
[ 111 ]
For encrypting data in AWS, the plaintext data key is used to convert plaintext data into
ciphertext using the encryption algorithm. The following figure shows a typical workflow
of the data encryption process in AWS:
Figure 1 - AWS encryption workﬂow
Decryption converts the encrypted data (ciphertext) into plaintext, essentially reversing the
encryption process. For decrypting data in AWS, ciphertext uses the plaintext data key for
converting ciphertext into plaintext by applying the decryption algorithm. The following
figure shows the AWS decryption workflow for converting ciphertext into plaintext:
Figure 2 - AWS decryption workﬂow
Data Security in AWS
[ 112 ]
Envelope encryption
AWS uses envelope encryption, a process to encrypt data directly. This process provides a
balance between the process and security for encrypting your data. This process has the
following steps for encrypting and storing your data:
The AWS service being used for encryption will generate a data key when a user
1.
requests data to be encrypted.
This data key is used to encrypt data along with the encryption algorithm.
2.
Once the data is encrypted, the data key is encrypted as well by using the key-
3.
encrypting key that is unique to the AWS service used to store your data such, as
AWS S3.
This encrypted data and encrypted data key are stored in the AWS storage
4.
service.
Note that the key-encrypting key also known as master key is stored and managed
separately from the data and the data key itself. When decrypted data is required to be
converted to plaintext data, the preceding mentioned process is reversed.
The following figure depicts the end-to-end workflow for the envelope encryption process;
the master key in the following figure is the key-encrypting key:
Figure 3 - AWS envelope encryption
Data Security in AWS
[ 113 ]
Securing data at rest
You might be required to encrypt your data at rest for all AWS services or for some of the
AWS storage services depending on your organizational policies, industry or government
regulations, compliance, or simply for adding another layer of security for your data. AWS
provides several options for encrypting data at rest including fully automated and fully
managed AWS encryption solutions, manual encryption solutions, client-side encryption,
and so on. In this section, we are going to go over these options for each AWS storage
service.
Amazon S3
The S3 is one of the major and most commonly used storage services in the AWS platform.
It supports a wide range of use cases such as file storage, archival records, disaster recovery,
website hosting, and so on. The S3 provides multiple features to protect your data such as
encryption, MFA, versioning, access control policies, cross-region replication, and so on. Let
us look at these features for protecting your data at rest in S3:
Permissions
The S3 gives you an option to add bucket level and object level permissions in addition to
the IAM policies for better access control. These permissions allow you to control
information theft, data integrity, unauthorized access, and deletion of your data.
Versioning
The S3 has a versioning feature that maintains all versions of objects that are modified or
deleted in a bucket. Versioning prevents accidental deletion and overwrites for all your
objects. You can restore an object to its previous version if it is compromised. Versioning is
disabled by default. Once versioning is enabled for a bucket, it can only be suspended. It
cannot be disabled.
Data Security in AWS
[ 114 ]
Replication
In order to provide the 11 9s of durability (99.999999999), S3 replicates each object stored
across all availability zones within the respective region. This process ensures data
availability in the event of a disaster by maintaining multiple copies of your data within a
region. The S3 also offers a cross region replication feature that is used to automatically and
asynchronously replicate objects stored in your bucket from one region to an S3 bucket in
another region. This bucket level feature can be used to backup your s3 objects across
regions.
Server-Side encryption
The S3 provides server-side encryption feature for encrypting user data. This encryption
process is transparent to the end user (client) as it is performed at the server side. AWS
manages the master key used for this encryption and ensures that this key is rotated on a
regular basis. AWS generates a unique encryption key for each object and then encrypts the
object using AES-256. The encryption key then encrypts itself using AES-256, with a master
key that is stored in a secure location.
Client-Side encryption
The AWS also supports client-side encryption where encryption keys are created and
managed by you. Data is encrypted by your applications before it is submitted to AWS for
storage and the data is decrypted after it is received from the AWS services. The data is
stored in the AWS service in an encrypted form and AWS has no knowledge of encryption
algorithms or keys used to encrypt this data. You can also use either symmetric or
asymmetric keys along with any encryption algorithm for client-side encryption. AWS
provided Java SDK, offers client-side encryption features for Amazon S3.
Amazon EBS
Amazon EBS is an abstract block storage service providing persistent block level storage
volumes. These volumes are attached to Amazon Elastic Compute Cloud (EC2) instances.
Each of these volumes is automatically replicated within its availability zone that protects
against component failure of an EBS volume. Let us look at options available to protect data
at rest, stored in EBS volumes that are attached to an EC2 instance.
Data Security in AWS
[ 115 ]
Replication
AWS stores each EBS volume as a file and creates two copies of this volume in the same
availability zone. This replication process provides redundancy against hardware failure.
However, for the purpose of disaster recovery, AWS recommends replicating data at the
application level.
Backup
You can create snapshots for your EBS volumes to get point in time copies of your data
stored in EBS volume. These snapshots are stored in AWS S3 so they provide the same
durability as any other object stored in S3. If an EBS volume is corrupt or if data is modified
or deleted from an EBS volume, you can use snapshots to restore the data to its desired