continuous_query_batch_size = 50000    
# the number of parallel continuous query combiner processes to use for    
# each database    
continuous_query_num_combiners = 24    
# the number of parallel continuous query worker processes to use for    
# each database    
continuous_query_num_workers = 12    
# allow direct changes to be made to materialization tables?    
#continuous_query_materialization_table_updatable = off    
# synchronization level for stream inserts    
#stream_insert_level = sync_read    
# continuous views that should be affected when writing to streams.    
# it is string with comma separated values for continuous view names.    
#stream_targets = ''    
# the default step factor for sliding window continuous queries (as a percentage    
# of the total window size)    
#sliding_window_step_factor = 5    
# allow continuous queries?    
#continuous_queries_enabled = on    
# allow anonymous statistics collection and version checks?    
#anonymous_update_checks = on    
```  
## 启动pipelinedb    
```    
pipeline-ctl start    
```    
## 连接方法    
如何连接PostgreSQL，就如何连接pipelinedb，它们是全兼容的。    
```    
psql    
psql (9.5.3)    
Type "help" for help.    
pipeline=# \dt    
No relations found.    
pipeline=# \l    
                             List of databases    
   Name    |  Owner   | Encoding  | Collate | Ctype |   Access privileges       
-----------+----------+-----------+---------+-------+-----------------------    
 pipeline  | postgres | SQL_ASCII | C       | C     |     
 template0 | postgres | SQL_ASCII | C       | C     | =c/postgres          +    
           |          |           |         |       | postgres=CTc/postgres    
 template1 | postgres | SQL_ASCII | C       | C     | =c/postgres          +    
           |          |           |         |       | postgres=CTc/postgres    
(3 rows)    
pipeline=#    
```    
## 测试    
### 创建流结构    
id为KEY， val存储值，统计时按ID聚合      
```    
CREATE STREAM s1 (id int, val int);    
```    
### 创建流式视图    
流视图统计count, avg, min, max, sum几个常见维度    
```    
CREATE CONTINUOUS VIEW cv1 AS    
SELECT id,count(*),avg(val),min(val),max(val),sum(val)    
FROM s1 GROUP BY id;    
```    
PostgreSQL的强大之处在于统计维度极其丰富，数据类型也极其丰富。    
build-in 数据类型参考    
https://www.postgresql.org/docs/9.6/static/datatype.html     
build-in 聚合，窗口，数学函数请参考    
https://www.postgresql.org/docs/9.6/static/functions.html      
同时还支持扩展，常见的例如 PostGIS, wavelet, 基因，化学，图类型，等等。      
你能想到的和想不到的都可以在pipelinedb 中进行流式处理，大大提高开发效率。    
### 激活流计算    
```    
activate ;    
```    
### 插入压测    
100万个随机group，插入的值为500万内的随机值    
```    
vi test.sql    
\setrandom id 1 1000000    
\setrandom val 1 5000000    
insert into s1(id,val) values (:id, :val);    
```    
使用1000个连接，开始压测，每秒约处理24万流水        
```    
pgbench -M prepared -n -r -P 1 -f ./test.sql -c 1000 -j 1000 -T 100    
...    
progress: 2.0 s, 243282.2 tps, lat 4.116 ms stddev 5.182    
progress: 3.0 s, 237077.6 tps, lat 4.211 ms stddev 5.794    
progress: 4.0 s, 252376.8 tps, lat 3.967 ms stddev 4.998    
...    
```    
如果主机有很多块硬盘，并且CPU很强时，可以在一台主机中部署2个或多个pipelinedb实例，进行分流。    
比如我在32Core的机器上，部署2个pipelinedb实例，可以达到29万/s的流处理能力，一天能处理 **250.56亿** 流水。      
部署两个时，建议使用NUMACTL进行控制，分别使用两路CPU和内存绑定。     
例如  
```
numactl --physcpubind=0-31 pipeline-ctl start
```
性能可以做到更好。   
小伙伴们都惊呆了。      
250.56亿，使用jstrom框架的话，估计要几十倍甚至上百倍于pipelinedb的硬件投入才能达到同样效果。      
## pipelinedb集群化部署    
虽然pipelinedb的性能很强(前面测的32C机器约250.56亿/天的流水处理能力)，但是单机总会有瓶颈，所以我们还是需要考虑集群化的部署。      
![pic](20161220_01_pic_001.png)        
写入操作，如果不需要特定的分片规则，使用haproxy分发就可以了。如果需要加入分片规则，可以使用plproxy。    
查询聚合，需要使用plproxy，非常简单，写个动态函数即可。      
### plproxy 相关文档介绍    
[《使用Plproxy设计PostgreSQL分布式数据库》](../201005/20100511_01.md)      
[《A Smart PostgreSQL extension plproxy 2.2 practices》](../201110/20111025_01.md)      
[《PostgreSQL 最佳实践 - 水平分库(基于plproxy)》](../201608/20160824_02.md)     
## pipelinedb 文档结构    
http://docs.pipelinedb.com/    
从文档目录，可以快速了解pipelinedb可以干什么，可以和什么结合，处理那些场景的问题?      
1\. 介绍    
```  
What PipelineDB is    
What PipelineDB is not    
```  
2\. Continuous Views    
定义流视图，其实就是定义 统计分析的QUERY， 例如select id, count(*), avg(x), ... from table group by ...;     
定义好之后，数据插入table，这个流视图就会不断增量的进行统计，你只要查询这个流视图，就可以查看到实时的统计结果。     
数据库中存储的是实时统计的结果（实际上是在内存中进行增量合并的，增量的方式持久化）。    
```  
CREATE CONTINUOUS VIEW    
DROP CONTINUOUS VIEW    
TRUNCATE CONTINUOUS VIEW    
Viewing Continuous Views    
Data Retrieval    
Time-to-Live (TTL) Expiration    
Activation and Deactivation    
Examples    
```  
3\. Continuous Transforms    
与流视图不同的是，transform是用来触发事件的，所以它可以不保留数据，但是可以设定条件，当记录满足条件时，就触发事件。     
例如监视传感器的值，当值的范围超出时，触发报警（如通过REST接口发给指定的server），或者将报警记录下来（通过触发器函数）。      
```  
CREATE CONTINUOUS TRANSFORM    
DROP CONTINUOUS TRANSFORM    
Viewing Continuous Transforms    
Built-in Transform Triggers    
Creating Your Own Trigger    
```  
4\. Streams    
流视图和transform都是基于流的，所以流是基础。     
我们首先需要定义流，往流里面写数据，然后在流动的数据中使用流视图或者transform对数据进行实时处理。    
```  
Writing To Streams    
Output Streams    
stream_targets    
Arrival Ordering    
Event Expiration    
```  
5\. Built-in Functionality    
内置的函数    
```  
General    
Aggregates    
PipelineDB-specific Types    
PipelineDB-specific Functions    
Miscellaneous Functions    
```  
6\. Continuous Aggregates    
聚合的介绍，通常流处理分两类，即前面讲的     
流视图（通常是实时聚合的结果），比如按分钟实时的对红绿灯的车流统计数据绘图，或者按分钟对股票的实时数据进行绘图。    
transform（事件处理机制），比如监控水质，传感器的值超出某个范围时，记录日志，并同时触发告警（发送给server）。     
```  
PipelineDB-specific Aggregates    
Combine    
CREATE AGGREGATE    
General Aggregates    
Statistical Aggregates    
Ordered-set Aggregates    
Hypothetical-set Aggregates    
Unsupported Aggregates    
```  
7\. Clients    
几种常见的客户端用法，实际上支持PostgreSQL的都支持pipelinedb，他们的连接协议是一致的。       
```  
Python    
Ruby    
Java    
```  
8\. Probabilistic Data Structures & Algorithms    
概率统计相关的功能，例如HLL等。用起来也非常的爽，例如统计网站的UV，或者红绿灯通过的汽车编号唯一值车流，通过手机信号统计基站辐射方圆多少公里的按时UV等。     
```  
Bloom Filter    
Count-Min Sketch    
Filtered-Space Saving Top-K    
HyperLogLog    
T-Digest    
```  
9\. Sliding Windows    
因为很多场景的数据有时效，或者有时间窗口的概念，所以pipelinedb提供了窗口分片的接口，允许用户对数据的时效进行定义。     
例如仅仅统计最近一分钟的时间窗口内的统计数据。     
比如热力图，展示最近一分钟的热度，对于旧的数据不关心，就可以适应SW进行定义，从而保留的数据少，对机器的要求低，效率还高。      
```  
Examples    
Sliding Aggregates    
Temporal Invalidation    
Multiple Windows    
step_factor    
```  
10\. Continuous JOINs    
流视图 支持JOIN，支持JOIN，支持JOIN，重要的事情说三遍。    
流 JOIN 流(未来版本支持,目前可以通过transform间接实现)    
流 JOIN TABLE(已支持)    
```  
Stream-table JOINs    
Supported Join Types    
Examples    
Stream-stream JOINs    
```  
11\. Integrations    
pipelinedb继承了PostgreSQL的高扩展性，所以支持kafka, aws kinesis也是易如反掌的，可以适应更多的场景。     
![pic](20161220_01_pic_003.png)    
https://aws.amazon.com/cn/kinesis/streams/    
```  
Apache Kafka    
Amazon Kinesis    
```  
12\. Statistics    
统计信息，对于DBA有很大的帮助    
```  
pipeline_proc_stats    
pipeline_query_stats    
pipeline_stream_stats    
pipeline_stats    
```  
13\. Configuration    
## 参考    
https://yq.aliyun.com/articles/166    
#### [PostgreSQL 许愿链接](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216")
您的愿望将传达给PG kernel hacker、数据库厂商等, 帮助提高数据库产品质量和功能, 说不定下一个PG版本就有您提出的功能点. 针对非常好的提议，奖励限量版PG文化衫、纪念品、贴纸、PG热门书籍等，奖品丰富，快来许愿。[开不开森](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216").  
#### [9.9元购买3个月阿里云RDS PostgreSQL实例](https://www.aliyun.com/database/postgresqlactivity "57258f76c37864c6e6d23383d05714ea")
#### [PostgreSQL 解决方案集合](https://yq.aliyun.com/topic/118 "40cff096e9ed7122c512b35d8561d9c8")
#### [德哥 / digoal's github - 公益是一辈子的事.](https://github.com/digoal/blog/blob/master/README.md "22709685feb7cab07d30f30387f0a9ae")
![digoal's wechat](../pic/digoal_weixin.jpg "f7ad92eeba24523fd47a6e1a0e691b59")
#### [PolarDB 学习图谱: 训练营、培训认证、在线互动实验、解决方案、生态合作、写心得拿奖品](https://www.aliyun.com/database/openpolardb/activity "8642f60e04ed0c814bf9cb9677976bd4")
#### [购买PolarDB云服务折扣活动进行中, 55元起](https://www.aliyun.com/activity/new/polardb-yunparter?userCode=bsb3t4al "e0495c413bedacabb75ff1e880be465a")
#### [About 德哥](https://github.com/digoal/blog/blob/master/me/readme.md "a37735981e7704886ffd590565582dd0")