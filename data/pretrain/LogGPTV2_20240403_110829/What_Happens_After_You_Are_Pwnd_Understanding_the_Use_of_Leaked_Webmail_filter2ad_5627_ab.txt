dump the pages to disk, for oﬄine parsing. By col-
lecting information from the visitor activity pages, we
obtain location and system conﬁguration information of
accesses, as provided by Google’s geolocation and sys-
tem conﬁguration ﬁngerprinting system.
We believe that our honey account and monitoring
framework unleashes multiple possibilities for researchers
who want to further study the behavior of attackers in
webmail accounts. For this reason, we release the source
code of our system1.
3.2 Experiment setup
As part of our experiments, we ﬁrst set up a num-
ber of honey accounts on Gmail, and then leaked them
through multiple outlets used by cybercriminals.
Honey account setup. We created 100 Gmail ac-
counts and assigned them random combinations of pop-
ular ﬁrst and last names, similar to what was done
in [31]. Creating and setting up these accounts is a
manual process. Google also rate-limits the creation of
new accounts from the same IP address by presenting a
phone veriﬁcation page after a few accounts have been
created. These factors imposed limits on the number of
honey accounts we could set up in practice.
We populated the freshly-created accounts with emails
from the public Enron email dataset [22]. This dataset
contains the emails sent by the executives of the en-
ergy corporation Enron, and was publicly released as
evidence for the bankruptcy trial of the company. This
dataset is suitable for our purposes, since the emails
that it contains are the typical emails exchanged by
corporate users. To make the honey accounts believ-
able and avoid raising suspicion from cybercriminals
accessing them, we mapped distinct recipients in the
Enron dataset to our ﬁctional characters (i.e., the ﬁcti-
tious “owners” of the honey accounts), and replaced the
original ﬁrst names and last names in the dataset with
our honey ﬁrst names and last names. In addition, we
changed all instances of “Enron” to a ﬁctitious company
name that we came up with.
In order to have realistic email timestamps, we trans-
lated the old Enron email timestamps to recent times-
tamps slightly earlier than our experiment start date.
For instance, given two email timestamps t1 and t2 in
the Enron dataset such that t1 is earlier than t2, we
translate them to more recent timestamps T1 and T2
such that T1 is earlier than T2. We then schedule those
particular emails to be sent to the recipient honey ac-
counts at times T1 and T2 respectively. We sent between
200 – 300 emails from the Enron dataset to each honey
account in the process of populating them.
Leaking account credentials. To achieve our objec-
tives, we had to entice cybercriminals to interact with
our account honeypots while we logged their accesses.
We selected paste sites and underground forums as ap-
propriate venues for leaking account credentials, since
they tend to be misused by cybercriminals for dissemi-
nation of stolen credentials. In addition, we leaked some
credentials through malware, since this is a popular way
by which professional cybercriminals steal credentials
and compromise accounts [10]. We divided the honey-
pot accounts in groups and leaked their credentials in
diﬀerent locations, as shown in Table 1. We leaked 50
accounts in total on paste sites. For 20 of them, we
1https://bitbucket.org/gianluca students/gmail-honeypot
leaked basic credentials (username and password pairs)
on the popular paste sites pastebin.com and pastie.org. We
leaked 10 account credentials on Russian paste websites
(p.for-us.nl and paste.org.ru). For the remaining 20 ac-
counts, we leaked username and password pairs along
with UK and US location information of the ﬁctitious
personas that we associated with the honey accounts.
We also included date of birth information of each per-
sona.
Group Accounts
1
2
3
4
5
30
20
10
20
20
Outlet of leak
paste websites (no location)
paste websites (with location)
forums (no location)
forums (with location)
malware (no location)
Table 1: List of account honeypot groupings.
We leaked 30 account credentials on underground fo-
rums. For 10 of them, we only speciﬁed username and
password pairs, without additional information.
In a
manner similar to the paste site leaks described earlier,
we appended UK and US location information to un-
derground forum leaks, claiming that our ﬁctitious per-
sonas lived in those locations. We also included date of
birth information for each persona.
To leak credentials, we used these forums: offen-
sivecommunity.net, bestblackhatforums.eu, hack-
forums.net, and blackhatworld.com. We selected them
because they were open for anybody to register, and
were highly ranked in Google results. We acknowledge
that some underground forums are not open, and have a
strict vetting policy to let users in [30]. Unfortunately,
however, we did not have access to any private forum.
In addition, the same approach of studying open un-
derground forums has been used by previous work [7].
When leaking credentials on underground forums, we
mimicked the modus operandi of cybercriminals that
was outlined by Stone-Gross et al.
in [30]. In the pa-
per, the authors showed that cybercriminals often post
a sample of their stolen datasets on the forum to show
that the accounts are real, and promise to provide ad-
ditional data in exchange for a fee. We logged the mes-
sages that we received on underground forums, mostly
inquiring about obtaining the full dataset, but we did
not follow up to them.
Finally, to study the activity of criminals obtaining
credentials through information-stealing malware in honey
accounts, we leaked access credentials of 20 accounts to
information-stealing malware samples. To this end, we
selected malware samples from the Zeus family, which
is one of the most popular malware families performing
information stealing [10], as well as from the Corebot
family. We will provide detailed information on our
malware honeypot infrastructure in the next section.
The reason for leaking diﬀerent accounts on diﬀerent
outlets is to study diﬀerences in the behavior of cyber-
criminals getting access to stolen credentials through
diﬀerent sources. Similarly, we provide decoy location
information in some leaks, and not in others, with the
idea of observing diﬀerences in malicious activity de-
pending on the amount and type of information avail-
able to cybercriminals. As we will show in Section 4,
the accesses that were observed in our honey accounts
were heavily inﬂuenced by the presence of additional
location information in the leaked content.
Malware honeypot infrastructure. Our malware
sandbox system is structured as follows. A web server
entity manages the honey credentials (usernames and
passwords) and the malware samples. The host ma-
chine creates a Virtual Machine (VM), which contacts
the web server to request an executable malware ﬁle and
a honey credential ﬁle. The structure is similar to the
one explained in [21]. The malware ﬁle is then executed
in the VM (that is, the VM is infected with malware),
after which a script drives a browser in the VM to lo-
gin to Gmail using the downloaded credentials. The
idea is to expose the honey credentials to the malware
that is already running in the VM. After some time,
the infected VM is deleted and a fresh one is created.
This new VM downloads another malware sample and
a diﬀerent honey credential ﬁle, and it repeats the in-
fection and login operation. To maximize the eﬃciency
of the conﬁguration, before the experiment we carried
out a test without the Gmail login process to select only
samples whose C&C servers were still up and running.
3.3 Threats to validity
We acknowledge that seeding the honey accounts with
emails from the Enron dataset may introduce bias into
our results, and may make the honey accounts less be-
lievable to visitors. However, it is necessary to note that
the Enron dataset is the only large publicly available
email corpus, to the best of our knowledge. To make the
emails believable, we changed the names in the emails,
dates, and company name. In the future, we will work
towards obtaining or generating a better email dataset,
if possible. Also, some visitors may notice that the
honey accounts did not receive any new emails during
the period of observation, and this may aﬀect the way
in which criminals interact with the accounts. Another
threat is that we only leaked honey credentials through
the outlets listed previously (namely paste sites, un-
derground forums, and malware), therefore, our results
reﬂect the activity of participants present on those out-
lets only. Finally, since we selected only underground
forums that are publicly accessible, our observations
might not reﬂect the modus operandi of actors who are
active on closed forums that require vetting for signing
up.
3.4 Ethics
The experiments performed in this paper require some
ethical considerations. First of all, by giving access to
our honey accounts to cybercriminals, we incur the risk
that these accounts will be used to damage third par-
ties. To minimize this risk, as we said, we conﬁgured our
accounts in a way that all emails would be forwarded
to a sinkhole mailserver under our control and never
delivered to the outside world. We also established a
close collaboration with Google and made sure to re-
port to them any malicious activity that needed atten-
tion. Although the suspicious login ﬁlters that Google
typically uses to protect their accounts from unautho-
rized accesses were disabled for our honey accounts, all
other malicious activity detection algorithms were still
in place, and in fact Google suspended a number of
accounts under our control that engaged in suspicious
activity. It is important to note, however, that our ap-
proach does not rely on help from Google to work. Our
main reason for enlisting Google’s help to disable sus-
picious login ﬁlters was to ensure that all accesses get
through to the honey accounts (most accesses would
be blocked if Google did not disable the login ﬁlters).
This does not impact directly on our methodology, and
as a result does not reduce the wider applicability of
our approach. It is also important to note that Google
did not share with us any details on the techniques
used internally for the detection of malicious activity on
Gmail. Another point of risk is ensuring that the mal-
ware in our VMs would not be able to harm third par-
ties. We followed common practices [28] such as restrict-
ing the bandwidth available to our virtual machines and
sinkholing all email traﬃc sent by them. Finally, our
experiments involve deceiving cybercriminals by provid-
ing them fake accounts with fake personal information
in them. To ensure that our experiments were run in
an ethical fashion, we obtained IRB approval from our
institution.
4. DATA ANALYSIS
We monitored the activity on our honey accounts for
a period of 7 months, from 25th June, 2015 to 16th
February, 2016.
In this section, we ﬁrst provide an
overview of our results. We then discuss a taxonomy
of the types of activity that we observed. We provide
a detailed analysis of the type of activity monitored
on our honey accounts, focusing on the diﬀerences in
modus operandi shown by cybercriminals who obtain
credentials to our honey accounts from diﬀerent outlets.
We then investigate whether cybercriminals attempt to
evade location-based detection systems by connecting
from locations that are closer to where the owner of the
account typically connects from. We also develop a met-
ric to infer which keywords attackers search for when
looking for interesting information in an email account.
Finally, we analyze how certain types of cybercriminals
appear to be stealthier and more advanced than others.
Google records each unique access to a Gmail account
and labels the access with a unique cookie identiﬁer.
These unique cookie identiﬁers, along with more infor-
mation including times of accesses, are included in the
visitor activity pages of Gmail accounts. Our scripts
extract this data, which we analyze in this section. For
the sake of convenience, we will use the terms “cookie”
and “unique access” interchangeably in the remainder of
this paper.
4.1 Overview
We created, instrumented, and leaked 100 Gmail ac-
counts for our experiments. To avoid biasing our re-
sults, we removed all accesses made to honey accounts
by IP addresses from our monitoring infrastructure. We
also removed all accesses that originated from the city
where our monitoring infrastructure is located. After
this ﬁltering operation, we observed 326 unique accesses
to the accounts during the experiments, during which
147 emails were opened, 845 emails were sent, and there
were 12 unique draft emails composed by cybercrimi-
nals.
In total, 90 accounts received accesses during the ex-
periment, comprising 41 accounts leaked to paste sites,
30 accounts leaked to underground forums, and 19 ac-
counts leaked through malware. 42 accounts were blocked
by Google during the course of the experiment, due
to suspicious activity. We were able to log activity
in those accounts for some time before Google blocked
them. 36 accounts were hijacked by cybercriminals, that
is, the passwords of such accounts were changed by the
cybercriminals. As a result, we lost control of those ac-
counts. We did not observe any attempt by attackers
to change the default send-from address of our honey
accounts. However, assuming that happened and at-
tackers started sending spam messages, Google would
block such accounts since we asked them to monitor the
accounts with particular attention. A dataset contain-
ing the parsed metadata of the accesses received from
our honey accounts during our experiments is publicly
available at http://dx.doi.org/10.14324/000.ds.1508297
4.2 A taxonomy of account activity
From our dataset of activity observed in the honey
accounts, we devise a taxonomy of attackers based on
unique accesses to such accounts. We identify four types
of attackers, described in detail in the following.
Curious. These accesses constitute the most basic type
of access to stolen accounts. After getting hold of ac-
count credentials, people login on those accounts to
check if such credentials work. Afterwards, they do not
perform any additional action. The majority of the ob-
served accesses belong to this category, accounting for
224 accesses. We acknowledge that this large number
of curious accesses may be due in part to experienced
attackers avoiding interactions with the accounts after
logging in, probably after some careful observations in-
dicating that the accounts do not look real. This could
potentially introduce some bias into our results.
Gold diggers. When getting access to a stolen ac-
count, attackers often want to understand its worth.
For this reason, on logging into honey accounts, some
attackers search for sensitive information, such as ac-
count information and attachments that have ﬁnancial-
related names. They also seek information that may
be useful in spearphishing attacks. We call these ac-
cesses “gold diggers.” Previous research showed that
this practice is quite common for manual account hi-
jackers [13].
In this paper, we conﬁrm that ﬁnding,
provide a methodology to assess the keywords that cy-
bercriminals search for, and analyze diﬀerences in the
modus operandi of gold digger accesses for credentials
leaked through diﬀerent outlets. In total, we observed