# Pitfalls in HTTP Traffic Measurements and Analysis

## Authors
- Fabian Schneider<sup>1,2</sup>
- Bernhard Ager<sup>2</sup>
- Gregor Maier<sup>2,3</sup>
- Anja Feldmann<sup>2</sup>
- Steve Uhlig<sup>4</sup>

<sup>1</sup> NEC Laboratories Europe, Heidelberg, Germany  
<sup>2</sup> TU Berlin / Telekom Innovation Laboratories, Berlin, Germany  
<sup>3</sup> International Computer Science Institute, Berkeley, CA, USA  
<sup>4</sup> Queen Mary, University of London, London, UK

### Abstract
HTTP accounts for more than half of the total traffic volume on the Internet, making it a popular subject for traffic analysis. Based on our experiences with HTTP traffic analysis, we have identified several pitfalls that can lead to flawed studies. These pitfalls can often be easily avoided. Using passive traffic measurements from 20,000 European residential broadband customers, we quantify the potential errors associated with three issues: non-consideration of persistent or pipelined HTTP requests, mismatches between the Content-Type header field and the actual content, and mismatches between the Content-Length header and the actual transmitted volume. Our findings show that 60% (30%) of all HTTP requests (bytes) are persistent (i.e., not the first in a TCP connection), and 4% are pipelined. Additionally, 35% of the total HTTP volume has a Content-Type mismatch, and the Content-Length header reports at least 3.2 times more bytes than actually transferred.

## 1. Introduction
HTTP has become the preferred protocol for many Internet services. Users exchange most of their content via HTTP, including downloading videos from YouTube, sharing photos and status updates on Facebook and Twitter, sending and reading emails with Gmail or Yahoo, and accessing news and online shopping. Consequently, analyzing HTTP traffic has been the focus of numerous recent studies [1–6, 9, 10]. These studies often rely on passive packet-level traffic measurements, which can involve large amounts of data, sometimes necessitating simplifications to scale the analysis. However, these simplifications can introduce biases or even render a study flawed.

In previous analyses of large HTTP traces [1, 6, 9, 10], we encountered inconsistencies and identified and resolved these issues. In this paper, we quantify the potential errors associated with these issues. Specifically, we examine the prevalence of pipelined and persistent HTTP connections, and the accuracy of the Content-Length and Content-Type HTTP header fields. Our results are based on anonymized HTTP traffic from approximately 20,000 European residential DSL customers (Section 2). Our contributions are as follows:

- **Persistence and Pipelining**: Ignoring pipelined and persistent HTTP connections, such as by only considering the first request in a connection, can significantly underestimate the number of HTTP requests. We find that each connection contains more than two requests on average, with 60% of all HTTP requests being persistent, responsible for 30% of the HTTP volume. The use of persistent or pipelined requests is more influenced by the contacted web service than the user's browser.
- **HTTP Content Type**: The Content-Type header in HTTP servers specifies the MIME type of the transferred object, but this information is not always accurate. We find that 35% of the HTTP volume has a Content-Type mismatch when compared to the actual content type determined by libmagic.
- **HTTP Content Size**: The Content-Length field in HTTP headers can report incorrect values due to canceled transfers or erroneous web servers. In our dataset, the Content-Length header reports at least 3.2 times more bytes than actually transferred.

## 2. Data and Methodology
This section presents our data sets and methodology. We also provide an overview of the user population in terms of browser and operating system usage.

### Anonymized HTTP Data
Our study is based on multiple sets of anonymized packet-level observations of residential DSL connections collected over more than two years at a large European ISP. Data anonymization and analysis are performed immediately on a secure measurement infrastructure using Bro [8] with a customized HTTP analysis script. The monitor operates at the broadband access router, observing the traffic of more than 20,000 DSL lines. Table 1 summarizes the characteristics of the traces, including start time, duration, and size. Please refer to Maier et al. [6] for detailed characteristics of this user population.

| Name | Start Date | Duration | HTTP Volume |
|------|------------|----------|-------------|
| SEP08 | 18 Sep 2008 | 24 h | ≈ 2.5 TB |
| APR09 | 01 Apr 2009 | 24 h | ≈ 2.5 TB |
| AUG09 | 21 Aug 2009 | 48 h | ≈ 5.9 TB |
| MAR10 | 04 Mar 2010 | 24 h | ≈ 3.3 TB |
| JUN10 | 23 Jun 2010 | 24 h | ≈ 3.2 TB |
| HTTP14d | 09 Sep 2009 | 14 d | ≈ 42 TB |
| HTTP12d | 07 May 2010 | 12 d | ≈ 38 TB |

### Persistence and Pipelining
We investigate the prevalence of persistence and pipelining in HTTP connections. We define the first request/response in a connection as initial, and mark all subsequent requests/replies as persistent. This allows us to derive the following metrics:
- Fraction of connections that are persistent
- Fraction of requests that are persistent
- Fraction of bytes transported in persistent request/response pairs

If a request is issued before the response of an earlier request in the same connection is finished, we mark this request as pipelined. If pipelined requests are sent in the same IP packet, we mark them as such. We derive the same fractions as metrics for pipelined/same packet marking. Note that HTTP14d and HTTP12d do not include request timestamps, so we cannot determine pipelined/same packet requests for these datasets.

We also investigate whether different operating systems or browsers influence our results. We annotate our datasets accordingly and perform our analysis for each subset, extracting browser type and operating system information from HTTP user-agent strings using an open-source parser.

### Content Type
Another potential error can be made by relying on the Content-Type header to identify the MIME type of transferred files. To assess this error, we extract the Content-Type header and analyze the initial portion of the HTTP body with libmagic. We then compare the type reported by HTTP headers and libmagic and analyze cases where they disagree.

### Content Length and Download Volume
HTTP servers can set a Content-Length header in the response indicating the size of the body. For persistent HTTP connections, the existence of either a Content-Length or a Content-Encoding header is mandatory. When measuring the volume downloaded via HTTP, one can choose to measure the bytes transported on the wire or use the Content-Length header of the HTTP response. The latter may introduce errors due to user interaction (e.g., interrupted downloads), software errors, or the lack of Content-Length headers. We define the estimation error as the ratio of the size announced by the Content-Length header to the actually downloaded volume. If an HTTP response does not include a Content-Length header, we define the ratio as 1.

### Browser and OS Popularity
To better understand the data sets and the monitored user population, we present the popularity and distribution of operating systems and browser families. Figures 1 and 2 plot the traffic volume per operating system and browser family, respectively. We see that Windows dominates with more than 80% of the traffic volume, and users are switching to newer versions over time. Mac OS consistently accounts for 8%, while Linux increases its contribution from 2% to 13% in 2010. Firefox users request the majority of bytes, followed closely by Microsoft’s Internet Explorer. The adoption of new browser versions significantly changes the contribution by browser version, with Firefox gaining 13% and Google’s Chrome rising to 2.5%.

## 3. Persistent and Pipelined Requests

### 3.1 Persistent Requests
We first determine the amount of persistent requests. Figure 3 shows the complementary cumulative distribution function (CCDF) of the number of requests per connection for JUN10, HTTP12d, and HTTP14d. We observe that 30% of the connections (y-axis at 3· 10<sup>-1</sup> in log-scale) have two or more requests. One connection in one thousand has more than 100 requests, and we even observe connections with several tens of thousands of requests. The CCDFs for the other traces look similar. On average, each connection has 2.2 to 2.4 requests, consistent with Callahan et al. [2].

This indicates a potentially high error for analyses that only consider the first request in a connection. The TimeMachine [7] suggests that “the most interesting information is in the beginning of a connection” and showed significant recording and analysis savings when only considering the first few bytes (the “cutoff”) of a connection. If this cutoff is too low, successive persistent requests will be skipped from the analysis.

Figures 4 and 5 present the results of our three metrics—connections with marked requests, number of marked requests, and volume of marked requests—for the persistent, pipelined, and same packet requests for all 24-hour traces. Recall that we never mark the first request of a connection as persistent nor do we mark the first request of a pipeline (or same-packet) as such. Each request marked as pipelined is also marked as persistent, and the set of same-packet requests is a subset of pipelined requests.

[Figure 3: CCDF of requests per connection for HTTP12d, HTTP14d, and JUN10]

[Figure 4 and 5: Metrics for persistent, pipelined, and same packet requests for all 24h traces]