generate validation routines in their development. None of
them wrote any customized validation or encoding routines.
Thus, ASIDE’s code refactoring was eﬀective in helping stu-
dents write more secure code, even though they were not
required to do so.
Multiple factors explain why certain warnings were not
clicked or acted upon. Some of the warnings were generated
when the participant wrote debugging code, which was soon
deleted. Perhaps students ignored security warnings on code
that they knew was transient. Other cases have to do with
a bug in the version of ASIDE used, which falsely warned
participants of the need for output encoding. We noticed
that participants learned this warning was a false positive
after one or more encounters, and then ignored those warn-
ings thereafter. However, at least in this study, the presence
of a false positive did not seem to cause the participants
to not pay attention to other ASIDE warnings. Thus, in
cases where participants encountered false positives, they
were able to recognize them quickly and use the options
provided by ASIDE to dismiss the false positives.
We transcribed all interviews into text via Inqscribe [15],
and coded the transcripts using Atlas.ti [2] to identify gen-
eral themes and interesting cases. All but one of the par-
ticipants indicated that if they were not given ASIDE, they
would not have been aware that some of the inputs needed
to be validated before being used. Furthermore, they unan-
imously agreed that they would not write their own valida-
tion routines should ASIDE not provide them in the context
of their assignment. As one participant stated:
[P1] That (The warning design of ASIDE) was
good because hadn’t it prompted me, I wouldn’t
have to realize I have to inspect those input val-
ues.
No one expressed that the ASIDE warnings were annoy-
ing, and all seemed to have faith that using ASIDE would
make their code more secure.
(cid:1)(cid:3)(cid:2)
[P4] No (it does not bother me).
warnings so that I can write secure code.
It gives me
So overall, 8 out of 9 participants expressed a positive
impression of ASIDE, with one being neutral. This study
demonstrated that ASIDE was usable by our participants.
They were able to utilize ASIDE quickly, in the context of
their own development, potentially improving the security of
their code. We plan to expand upon this study to examine
the use of ASIDE by professional developers to more deeply
investigate the impact on programmer behavior in a variety
of contexts.
8. RELATED WORK
Research into tool support for software security focuses
heavily on machine-related issues, such as technique ad-
vancements for vulnerability detection eﬀectiveness, accu-
racy, and vulnerability coverage, with very little concern
with human factors issues. The two prominent techniques
are static and dynamic program analyses. Static analysis
typically is based on taint tracking [27, 17, 21, 7] and dy-
namic analyses are often based on model checking [14, 9,
22] and symbolic execution [6, 10, 32]. As both approaches
have their advantages and disadvantages, a variety of work
has explored the combination of these two techniques in an
attempt to achieve better performance [3, 23, 13] .
Software developer education and training has also been
directed at achieving better software security. Most eﬀorts
have been spent on developing educational material and
guidelines for the best secure programming practices [5, 16,
1, 18, 35]. However, the mere existence of such abundant in-
formation does not guarantee its use by programmers [38].
Our work takes human factors into consideration and ﬁlls
this missing gap, complementing program analysis tools to
help developers write more secure code.
Our work is in part motivated by studies on human errors
[29], and programmer errors in particular [20], which demon-
strate that programmer errors contribute a great deal to
software ﬂaws. Many such errors are caused by three types
of cognitive breakdowns: skill-based breakdowns where pro-
grammers fail to perform routine actions at critical times;
rule-based breakdowns where programmers fail to do an ac-
tion in a new context; and knowledge-based breakdowns where
a programmer’s knowledge is insuﬃcient. We believe that
ASIDE’s contextualized reminders can help address many of
these issues by ﬁlling in knowledge gaps and reminding pro-
grammers of secure programming issues within their current
context.
Prior work on code annotation (e.g.
[24]) used textual
extensions of programming languages, such as C and Java,
which demands developers to learn and use yet another type
of language. In contrast, our approach leverages GUI sup-
port to make the process more intuitive, direct and easy to
use. Furthermore, soliciting security information from the
developer through annotation could open up new ways to
detect software vulnerabilities.
9. CONCLUSIONS
The main contribution of our work is to augment IDE
tools to intelligently recognize software security issues and
remind and assist developers with possible mitigation ac-
tions. We evaluated this approach against mature open
source projects. Our results suggest that this approach is
eﬀective in detecting and helping prevent common types of
web application vulnerabilities, such as lack of proper in-
put validation and/or encoding, CSRF, and broken access
control.
No single tool is capable of detecting all software vulner-
abilities, and ASIDE is no exception. However, we believe
that ASIDE can be most eﬀective in supplementing static
analysis tools and increasing the productivity of current best
software security practices. For input validation and encod-
ing issues, which often constitute the largest percentage of
issues in a typical web application, ASIDE can signiﬁcantly
reduce the number of issues generated by static analysis
by helping programmers to prevent them in the ﬁrst place.
Thus, ASIDE can help improve software security and reduce
the number of security ﬁxes needed after static analysis, as
well as saving time for the software security audit by 50%,
based on our Roller case study.
Our user study results suggest that ASIDE is eﬀective
in helping novice developers/students to write more secure
code when using code refactoring. They appear to pay atten-
tion to ASIDE warnings and follow ASIDE advice to perform
input validation and/or encoding. Further studies, including
studies involving experienced developers, are needed to show
whether ASIDE can improve developers’ understanding and
practice of secure programming in more contexts. Prelim-
inary evidence appears to suggest that users can quickly
recognize false positives in ASIDE and take easy action to
dismiss them. More research on false positives and how they
impact on developers using ASIDE is needed.
Finally, our approach also provides a tool platform to pro-
vide additional support for the secure software development
lifecycle in the areas of enforcing standards, information col-
lection for secure coding metrics, and capturing developer
rationale for code review or in depth program analysis. In
an enterprise environment, ASIDE can serve as a medium
that communicates a Software Security Group’s secure cod-
ing knowledge to developers. As we continue the develop-
ment of ASIDE, we plan to further investigate the use of
these features and how they can contribute to secure appli-
cations.
ACKNOWLEDGMENTS This work is supported in part
by a grant from the National Science Foundation 0830624,
and a research/educational license from HP Fortify Inc. We
would like to thank Will Stranathan for his contribution in
the formation of this idea and critiques and suggestions on
the intial prototyping of ASIDE. We also want to thank all
our participants for their time.
10. REFERENCES
[1] S. Ardi, D. Byers, P. H. Meland, I. A. Tondel, and
N. Shahmehri. How can the developer beneﬁt from
security modeling? In The Second International
Conference on Availability, Reliability and Security,
2007, pages 1017 –1025, april 2007.
[2] Atlas.ti. Atlas.ti, 2011. www.atlasti.com.
[3] D. Balzarotti, M. Cova, V. Felmetsger, N. Jovanovic,
E. Kirda, C. Kruegel, and G. Vigna. Saner:
Composing static and dynamic analysis to validate
sanitization in web applications. In Proceedings of the
2008 IEEE Symposium on Security and Privacy, pages
387–401. IEEE Computer Society, 2008.
[4] M. Bishop and B. J. Orvis. A clinic to teach good
programming practices. In Proceedings from the Tenth
(cid:1)(cid:3)(cid:2)
Colloquium on Information Systems Security
Education, pages 168–174, June 2006.
[5] CERT. CERT Secure Coding, 2011.
www.cert.org/secure-coding.
[6] A. Chaudhuri and J. S. Foster. Symbolic security
analysis of ruby-on-rails web applications. In
Proceedings of the 17th ACM conference on Computer
and communications security, CCS ’10, pages 585–594.
ACM, 2010.
[7] B. Chess and G. McGraw. Static analysis for security.
IEEE Security and Privacy, 2:76–79, November 2004.
[8] B. Chess and J. West. Secure programming with static
analysis. Addison-Wesley Professional, ﬁrst edition,
2007.
[9] V. Felmetsger, L. Cavedon, C. Kruegel, and G. Vigna.
Toward automated detection of logic vulnerabilities in
web applications. In Proceedings of the 19th USENIX
conference on Security, USENIX Security’10, pages
10–10. USENIX Association, 2010.
[10] X. Fu and K. Qian. Safeli: Sql injection scanner using
symbolic execution. In Proceedings of the 2008
workshop on Testing, analysis, and veriﬁcation of web
services and applications, TAV-WEB ’08, pages 34–39.
ACM, 2008.
[21] V. B. Livshits and M. S. Lam. Finding security errors
in Java programs with static analysis. In Proceedings
of the 14th Usenix Security Symposium, pages
271–286, August 2005.
[22] M. Martin and M. S. Lam. Automatic generation of
xss and sql injection attacks with goal-directed model
checking. In Proceedings of the 17th conference on
Security symposium, pages 31–43. USENIX
Association, 2008.
[23] M. Martin, B. Livshits, and M. S. Lam. Finding
application errors and security ﬂaws using PQL: a
program query language. In OOPSLA ’05:
Proceedings of the 20th annual ACM SIGPLAN
conference on Object oriented programming systems
languages and applications, pages 365–383, 2005.
[24] Microsoft. Microsoft SAL Annotations, 2011. http:
//msdn.microsoft.com/en-us/library/ms235402.aspx.
[25] Moodle. Moodle, 2011. http://moodle.org.
[26] Moodle. MSA-08-0013, 2011.
http://moodle.org/mod/forum/discuss.php?d=101405.
[27] G. Naumovich and P. Centonze. Static analysis of
role-based access control in j2ee applications.
SIGSOFT Softw. Eng. Notes, 29:1–10, September
2004.
[11] B. C. G. McGraw and S. Migues. Building security in
[28] OWASP. ESAPI Validator API, 2011.
maturity model, 2011. www.bsimm2.com.
[12] M. Haﬁz, P. Adamczyk, and R. Johnson.
Systematically eradicating data injection attacks using
security-oriented program transformations. In
Proceedings of the 1st International Symposium on
Engineering Secure Software and Systems, ESSoS ’09,
pages 75–90. Springer-Verlag, 2009.
http://owasp-esapi-java.googlecode.com/svn/trunk\
_doc/latest/org/owasp/esapi/Validator.html.
[29] J. Reason. Human Error. Cambridge University Press,
Cambridge, UK, 1990.
[30] A. Roller. Apache Roller, 2011.
http://roller.apache.org.
[31] A. Roller. ROL-1766, 2011.
[13] Y.-W. Huang, F. Yu, C. Hang, C.-H. Tsai, D.-T. Lee,
https://issues.apache.org/jira/browse/ROL-1766.
and S.-Y. Kuo. Securing web application code by
static analysis and runtime protection. In Proceedings
of the 13th international conference on World Wide
Web, WWW ’04, pages 40–52. ACM, 2004.
[14] Y.-W. Huang, F. Yu, C. Hang, C.-H. Tsai, D. T. Lee,
and S.-Y. Kuo. Verifying web applications using
bounded model checking. In Proceedings of the 2004
International Conference on Dependable Systems and
Networks, pages 199–, Washington, DC, USA, 2004.
IEEE Computer Society.
[15] Inqscribe. Inqscribe, 2011. www.inqscribe.com.
[16] S. Institute. SANS Institute, 2011. www.sans.org.
[17] N. Jovanovic, C. Kruegel, and E. Kirda. Pixy: a static
analysis tool for detecting web application
vulnerabilities. In Security and Privacy, 2006 IEEE
Symposium on, pages 6 pp. –263, may 2006.
[18] K. Karppinen, L. Yonkwa, and M. Lindvall. Why
developers insert security vulnerabilities into their
code. In Proceedings of the 2009 Second International
Conferences on Advances in Computer-Human
Interactions, ACHI ’09, pages 289–294. IEEE
Computer Society, 2009.
[19] D. E. Knuth. The errors of tex. Softw. Pract. Exper.,
19:607–685, July 1989.
[20] A. J. Ko and B. A. Myers. A framework and
methodology for studying the causes of software errors
in programming systems. J. Vis. Lang. Comput.,
16:41–84, February 2005.
[32] P. Saxena, D. Akhawe, S. Hanna, F. Mao,
S. McCamant, and D. Song. A symbolic execution
framework for javascript. Technical Report
UCB/EECS-2010-26, EECS Department, University
of California, Berkeley, Mar 2010.
[33] H. Sharp, Y. Rogers, and J. Preece. Interaction
Design: Beyond Human-Computer Interaction. Wiley,
2 edition, 2007.
[34] F. Software. Fortify SCA, 2011. https://www.fortify.
com/products/fortify360/source-code-analyzer.html.
[35] B. Taylor and S. Azadegan. Moving beyond security
tracks: integrating security in cs0 and cs1. In
Proceedings of the 39th SIGCSE technical symposium
on Computer science education, SIGCSE ’08, pages
320–324. ACM, 2008.
[36] VERACODE. State of Software Security Report
Volume 1, 2, and 3, 2011.
http://www.veracode.com/reports/index.html.
[37] J. Xie, B. Chu, and H. R. Lipford. Idea: interactive
support for secure software development. In
Proceedings of the Third international conference on
Engineering secure software and systems, ESSoS’11,
pages 248–255. Springer-Verlag, 2011.
[38] J. Xie, H. R. Lipford, and B. Chu. Why do
programmers make security errors? In Proceedings of
2011 IEEE Symposium on Visual Languages and
Human Centric Computing, pages 161–164, 2011.
(cid:1)(cid:3)(cid:2)