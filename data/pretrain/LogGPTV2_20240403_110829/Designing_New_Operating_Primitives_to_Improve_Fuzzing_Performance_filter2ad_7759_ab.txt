file in a private directory). More specifically, the process of
creating and writing small files heavily modifies the file system
metadata (e.g., allocating inode for file creating and disk blocks
for file writing), which is a critical section in most file system
implementations, and not scalable [32].
Syncing test cases each other. A fuzzer running in parallel can
expedite the search space exploration by sharing useful test cases
with other fuzzers at the syncing phase. In this phase, each fuzzer
checks the test cases of other fuzzer by iterating their test case
directories. For example, the file name of a test case for an AFL
instance starts with a prefix recording a sequence number as its
identifier, which denotes that a test case starting with a greater
sequence number was created later in fuzzing runs. While syncing,
an AFL instance scans the directory of its neighbors and decides
whether or not a test case is synced by that prefix. Then, it re-
executes the obtained test case to get its tracing bitmap and decides
whether the test case is useful.
(a) Number of executions
Fuzzing execs
Sync execs
1
15
30
Fuzzing time
Sync time
60
45
(b) Time breakdown
75
90
105
120
45k
40k
35k
30k
25k
20k
15k
10k
5k
100
80
60
40
20
c
e
s
/
s
c
e
x
E
t
n
e
p
s
e
m
i
t
%
1
15
30
45
60
#core
75
90
105
120
Figure 2: Multi-core scalability of AFL for libjpeg library. Figure 2(a)
shows the numbers of fuzzing executions (i.e., testing newly mu-
tated test cases) and sync executions (i.e., evaluating test cases
of other fuzzers). Figure 2(b) shows the execution time break-
down for fuzzing and syncing executions. Even though fuzzing is
an embarrassingly-parallel workload without dependencies among
fuzzers, the scalability of AFL is surprisingly poor. The number of
executions of AFL saturates at 15 cores, and starts degrading from
30 cores onward, and completely collapses at 120 cores. The reason
for scalability collapse by around 24× in total is because of 1) the
inherent design limitation of the syncing phase (2× slowdown) of
AFL; 2) the fork() system call overhead (6× slowdown); and 3) the file
system overhead for opening and closing small files (2× slowdown).
Bottlenecks. Scanning directories at the syncing phase is not
scalable for the following reasons: First, the number of direc-
tory enumeration operations to discover new, unsynced test
cases increases non-linearly with more fuzzers, which results
in a longer syncing phase. For instance, each fuzzer will take
O ( f ×t ), where f is the number of fuzzers and t is the number of
test cases in a test case directory. Second, directory enumeration
severely interferes with creating a new test case because a direc-
tory write operation (i.e., creating a file) and a read operation
(i.e., enumerating files) cannot be performed concurrently [32].
2.4 Scalability of AFL
To evaluate the impact of these bottlenecks, we ran AFL, a state-of-
the-art fuzzer, for fuzzing the libjpeg library, JPEG decompressor,
by varying the number of cores from 1 to 120 (see the environment
details in §6). We used the input corpus (i.e., seed inputs) provided
by AFL [40]. Figure 2 presents the number of executions for fuzzing
the libjpeg library, which shows that the scalability of AFL is sur-
prisingly poor. The number of executions saturates at 15 cores and
completely collapses at 120 cores. Considering that a typical server
in a data center is a two- or four-socket machine with 32 or 64 cores,
the current state-of-the-art fuzzers cannot fully exploit the typical
servers.
Such poor scalability is counter-intuitive because fuzzing is an
embarrassingly-parallel workload without any dependency among
4
Session K2:  Fuzzing Finer and FasterCCS’17, October 30-November 3, 2017, Dallas, TX, USA2316be either alleviated or completely avoided without compromising
the correctness of the execution of a target process in fuzzing.
struct iovec *shared_addr)
We propose a new system call, snapshot(), which is a light-
weight, scalable fork() substitute for fuzzing. Figure 3 illustrates
a simplified example of how to use the snapshot() system call.
snapshot() creates a snapshot of a process (e.g., its memory and OS
resources such as file and socket descriptors). After that, the process
can continue its execution. Upon request, snapshot() reverts the
status of the process to the snapshotted state. Its prototype is as
follows:
1 int snapshot(unsigned long cmd, unsigned long callback,
2
cmd is either BEG_SNAPSHOT for snapshotting or END_SNAPSHOT for
reverting. At BEG_SNAPSHOT, a user can register a callback func-
tion, callback, and a vector of shared address ranges, shared_addr
that OS should keep intact. For instance, in the case of fuzzing,
shared_addr indicates the trace bitmap shared between a fuzzer
instance and the target process (check §4.2 for its practical use in
AFL). When a snapshotting process terminates, the OS will call the
registered callback function. Currently, we do not support nested
snapshotting. snapshot() is more lightweight and more scalable
than fork(). It even has better performance than pthread_create()
because it does not need to allocate and free thread stack, which
is required for pthread_create(). The unnecessary operations in
fork() and pthread_create() eventually incur costly TLB shoot-
downs, scheduler invocations, memory allocations, auditing, and
security related modifications (see Figure 8).
In the rest of this section, we describe the details of snapshot()
especially in the context of fuzzing. We divide a complete fuzzing
run into three phases, and describe how snapshot() cooperates
with the kernel and the target process at different phases.
3.1.1 Before Fuzzing: Process Snapshotting. For explanation, we
assume that the fuzzer we deal with applies the basic design of AFL’s
fork server. More specifically, we launch the target application in the
beginning. The application is instrumented with a prologue, which
keeps waiting for a signal sent from the fuzzer instance. Once a
request from the fuzzer instance is received, the application invokes
fork(). Then, the child process executes its actual main function
while its parent process is waiting for the child to terminate.
In our design, before performing any fuzzing run, the target
process first needs to save the user space execution context ctx,
or specifically, all of the current register values and signal masks
using sigsetjmp(). Then it goes into a loop and keeps waiting for
a new fuzzing request from the fuzzer instance. On receiving a
request, the process uses snapshot() to reserve its kernel context
(BEG_SNAPSHOT) and registers a callback function: callback(). This
user callback function acts as an epilogue of every fuzzing execution,
which we describe later in more detail (§3.1.3). By invoking it with
the BEG_SNAPSHOT command argument, the kernel operates on its
data structures as follows:
• Virtual Memory Area (VMA). snapshot() iterates the vir-
tual memory areas (i.e., vmas) of the process and temporarily
stores the start and end address of every vma.
• Page. snapshot() maintains a set of pages that belong to a
writable vma because it is possible that the target application
may modify these writable pages, which the kernel should
5
Figure 3: Simplified use of snapshotting via the snapshot() system
call. A process (e.g., fork server in AFL) starts by storing user context
using sigsetjmp() system call and then waits for a “go” signal to start
its execution 1 . Once it gets the signal, it prepares for execution
(e.g., setting up command line arguments) and creates a snapshot
2 , then starts executing the main() 3 . If the process terminates
for any reason (e.g., exit(), SEGFAULT), a callback function, callback(),
which is registered at 2 , is called. It can be used for any purpose
(e.g., bookkeeping trace bits). By restoring the snapshot 4 , the ker-
nel restores the memory and OS resources (e.g., file and socket de-
scriptors) to their original state 2 . Finally, program execution is
reverted to the initial location 1 using siglongjmp().
fuzzers. The performance breakdown in Figure 2(b) shows the ev-
idence that with increasing core count, the actual time spent on
mutating and fuzzing new test cases decreases, whereas increasing
time is spent on the syncing phase. One important point is that all
synced test cases from other fuzzers have already been executed and
re-executing them is meaningless considering the overall progress
of the exploration of the target application. In addition, Figure 2(a)
indicates that starting from 45 cores, the OS kernel becomes the
main scalability bottleneck, in which most of the time, each fuzzing
instance first suffers from the file system contention, and also the
non-scalable fork() system call which contributes to a total 24×
overhead due to the aforementioned scalability bottlenecks in both
OS as well as the inherent design flaws of fuzzers.
Summary. Fuzzing looks embarrassingly parallel, but the de-
sign choices of both the fuzzer itself and the OS introduce
performance and scalability bottlenecks in non-trivial ways,
which require performance engineering in underneath layers
to completely exploit the full potential of the hardware.
3 OPERATING PRIMITIVES
We now present the design of our three scalable operating prim-
itives for fuzzing: a new snapshot() system call to replace the
heavyweight fork() system call (§3.1), file system service special-
ized for optimizing small file operations in fuzzing (§3.2), and a
shared in-memory test-case log for efficient, scalable syncing (§3.3).
3.1 Snapshot System Call
As we discussed in §2.3, fuzzers rely on fork() to take a snapshot
of the target application and easily catch its crash. However, the
general-purpose fork() is heavyweight for fuzzing: this includes a
lot of unnecessary features such as creating the reverse mapping
of the child’s physical pages for swapping, which is a well-known
performance bottleneck in Linux [8, 9, 11]. Nevertheless, by treating
fuzzer as a first-class citizen in an OS, these known contentions can
start withthe reserved user context (ctx)Waiting❶on blocksys_snapshot()❷❸❹BEG_SNAPSHOTsys_snapshot()END_SNAPSHOTmain()a) exit()b) returnc) killedcallback()restore ctxSession K2:  Fuzzing Finer and FasterCCS’17, October 30-November 3, 2017, Dallas, TX, USA2317revert to the original state when the application terminates.
To track these writable pages and maintain their original
memory status, we use the copy-on-write (CoW) technique.
We change the permission of writable pages to read-only by
updating their corresponding page table entries (PTE) and
flushing TLB to maintain the consistency. Thus, any write
on these pages incurs a page fault, which the page-fault
handler captures and handles. Our approach includes an
optimization: We do not change the permission of mapped
writable virtual address for which the kernel is yet to allocate
a physical page because memory access on those pages will
always incur a page fault.
• brk. A process’s brk defines the end of its data segment,
which indicates the valid range of its heap region in Linux.
Thus it influences the results of heap allocations during the
execution of the process. snapshot() saves the brk value of
the current process.
• File descriptor. At the end of a snapshotted process, the ker-
nel closes file descriptors that are opened after snapshot but
revert the status of file descriptors that were already opened
before snapshot. snapshot() saves the status of open file
descriptors by checking the file descriptor table and bitmap
(i.e., open_fds).
Besides modifying these data structures, snapshot() saves the
registered callback function. When the snapshotted process is about
to terminate in the middle of a fuzzing run (e.g., calling exit()),
snapshot() can safely redirect the control flow to callback() func-
tion in the user space.
3.1.2 During Fuzzing: Demanding Page Copy. The target process
continues to execute its real main function with the runtime argu-
ments and environment variables after returning from snapshot().
When the target application is running, each memory write (at the
page boundary) triggers a page fault because of our modification
of the page permission to read-only, as described in §3.1.1, for any
writable page. In our modified page-fault handler, we first check
whether the fault address is in a snapshotted page originally. If that
is the case, then a copy of the page data is modified and linked to
its corresponding PTE with additional write permission. For the
unallocated pages with no corresponding physical pages, we just
allocate new pages and update the corresponding PTE with addi-
tional write permission. Lastly, we flush TLB entries to maintain
the consistency.
3.1.3 After Fuzzing: Snapshot Recovering. Before terminating a
snapshotted process, we call the registered callback(). In the case
of normal termination, i.e., returning from main(), it first informs
the exit status (0 in this case) to its parent process, which is the con-
trolling fuzzer instance. To deal with the situation where the target
process calls exit() to terminate, we modify the entry function of
sys_exit_group and check whether the process is snapshotted. If
so, it calls the registered callback function in the user space. On
the other hand, if the target process times out or crashes in the
middle of the execution, it will receive the corresponding signal
such as SIGSEGV or SIGALARM which terminates the victim process
by default. To inform the abnormal status to the parent process and
avoid re-creating the target process, our instrumented prologue
registers a particular handler for every crucial signal at the very
6
beginning. The handler calls callback() with the corresponding
exit status (e.g., 139 for the process, which has segmentation fault).
After calling the registered callback function, the process invokes
snapshot() with END_SNAPSHOT to revert to the original snapshot-
ted state. Then the reverted process restores the saved user-space
context ctx using siglongjmp(), which directs it to start waiting
for another fuzzing run. We describe the detailed procedure of
snapshot() for the END_SNAPSHOT command, which involves four
clean-up steps as follows:
• Recovering copied pages. snapshot() recovers the pages
that have a modified copy of the original one; it also de-
allocates the allocated physical memory, reverts correspond-
ing PTE, and flushes the corresponding TLB entries.
• Adjusting memory layout. snapshot() iterates the VMAs
of the target process again and unmaps all of the newly
mapped virtual memory areas.
• Recovering brk. The brk value of a process affects the heap
allocations and it is restored to the saved brk value.
• Closing opened file descriptors. By comparing the cur-
rent file descriptor bitmap with the one saved before the past
fuzzing run, snapshot() determines the opened file descrip-
tors and closes them.
Compared with fork(), snapshot() saves a great amount of time
spent on copying numerous kernel data structures (e.g., file descrip-
tors, memory descriptor, signals, and namespaces). Moreover, it also
avoids setting up a new copy of security and auditing structures
and allocating a new stack area for the snapshotted process. As a
result, snapshot() does not stress the kernel memory allocator and
cgroup module. Moreover, snapshot() also removes the schedul-
ing cost, which involves adding and removing a new or exiting
process from the run queue of the scheduler, thereby eliminating
the contention from the run queue as well as the re-scheduling in-
terrupts. In summary, snapshot() plays the same role as fork()-ing
for fuzzing but in a much more lightweight and scalable fashion.
3.2 Dual File System Service
As we discussed in §2.3, mutating test cases actually involves small
file operations, including creat, write and read, that are not scal-
able in any existing file system: the root causes vary between file
systems, but examples include journalling, lock contention in the
implementation, or more severely, in the common VFS layer (e.g.,
the block allocator) [32].
We introduce our second operating primitive, dual file system
service, to provide efficient and scalable file operations for fuzzing.
The key idea of our approach is to exploit the fact that neither
a fuzzer instance nor the target instances require such a strong
consistency model. Only the fuzzer instance requires consistency
for serializing mutation states to the persistent storage for durability.
Upon unexpected failures (e.g., power or system crashes), the certain
loss of test cases is expected, but a fuzzer can always reproduce
them within an acceptable period of time. The new file system
service provides a two-level tiering of file systems: a memory file
system (e.g., tmpfs) seamlessly to the fuzzer instance and target
processes for performance, and a disk file system (e.g., ext4) to the
fuzzer instance for capacity and durability to store and maintain
crashes, inputs and mutation states.
Session K2:  Fuzzing Finer and FasterCCS’17, October 30-November 3, 2017, Dallas, TX, USA2318information. Thus, with many fuzzing instances, the syncing phase
incurs a lot of unnecessary re-execution of test cases and imposes
an overhead on the OS kernel.
We introduce a shared in-memory test case log for real collabora-
tive fuzzing without any overhead. The test case log is a fixed-size,
in-memory circular log (see Figure 4), which helps fuzzers effi-
ciently manage and share generated test cases. Each test case log is
created and controlled by a master fuzzer instance. Meanwhile any
other instances can access the log as a slave. Each element of the
log stores the information of a test case, including its filename, size,
hash value and tracing bitmap. Like conventional circular queues,
our test case log maintains HEAD. Only the master is allowed to
push a new element into the log on HEAD. Note that, unlike con-
ventional circular queues, any slave which attaches to the log can