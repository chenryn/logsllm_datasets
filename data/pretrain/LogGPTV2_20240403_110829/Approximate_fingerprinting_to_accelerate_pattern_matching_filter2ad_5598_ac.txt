Alerts
147,588
147,588
147,588
136,730
136,730
136,730
136,730
136,730
136,730
Packets
13,735,302
13,800,174
14,808,934
2,072,319
2,227,783
2,356,836
2,623,751
3,693,761
7,332,799
% Size Time (sec.)
72.22
72.56
77.86
10.9
11.71
12.39
13.8
19.42
38.55
391.39
390.15
393.50
78.66
83.76
89.59
95.42
137.52
317.02
Alerts
147,588
147,588
147,588
136,730
136,730
136,730
136,730
136,730
136,730
(kb)
1.06
2.12
3.18
1.66
3.32
4.99
6.65
8.32
9.98
Table 2: Pre-Processor performance for the packet trace ”Trace 1”. This particular design is suited for a
hardware implementation on an FPGA or NIC. The diﬀerence in Snort runtimes indicates the performance
gain that can be obtained.
Window
(bytes)
Step
(bytes)
Snort standalone
Packets
Time (sec.)
8
8
8
1
2
3
67,875,101
67,875,101
67,875,101
1683.84
1683.84
1683.84
Snort + preprocessor
Memory
Alerts
577,388
577,388
577,388
Packets
7,367,837
7,890,043
9,354,317
Time (sec.)
1458.9
1368.74
1440.63
Alerts
577,234
577,234
577,234
(kb)
67.3
70.5
73.3
Table 3: Pre-Processor performance when integrated with Snort for the packet trace ”Trace 2”. TCP stream
reassembly is performed by Snort. This design is suited for software implementation on a general purpose
processor.
2 would increase by a few kilobytes depending on the hash
table scheme used to access the table.
The tradeoﬀs involved in varying w and s can be seen
in Table 2. For a window size of 4 bytes, the size of the
pre-processed trace is almost 75% that of the original trace.
This is due to the inclusion of a large number of packets as
false positives and is mainly caused by the collisions in the
ﬁngerprint space (just 16 bit wide). Increasing the step size
s for this window size results in a very small increase in the
size of the pre-processed trace. This is caused by another
small increase in the number of false positives due to the
fact that we move the window forward by more than one
byte. In general, increasing the step size s, results in: (i)
increasing the memory footprint for the pre-processor, (ii)
reducing the per packet table lookups (see Equation 1), and
(iii) increasing the number of false positives generated by
the pre-processor. An increase in the number of false pos-
itives results in an increase in the size of the pre-processed
trace. For a window size of 8 bytes, false positives due to
collisions in the ﬁngerprint space are no longer dominant (32
bit wide ﬁngerprints) and the eﬀects of varying the step size
are more pronounced in this case.
In general, desirable conﬁgurations of the pre-processor
should have a low memory footprint, generate a low num-
ber of false positives (i.e.
the size of the pre-processed
trace should be small), and have a reduced number of table
lookups per packet. Setting w to 8 and s to a value between
2 and 5 provides these characteristics. On the average, the
size of the pre-processed trace is between 10% to 20% of
the original trace which translates in a corresponding im-
provement in the runtime of Snort. Note that the number
of alerts returned by processing the full and reduced traces
are the same for all cases.
The second experiment evaluates the conﬁguration of the
preprocessor when implemented in software on a general
purpose processor. In order to measure processing time, the
approximate pattern matching technique described in Fig-
ure 1d is implemented as a Snort preprocessor. The number
of packets processed by Snort and the time required to pro-
cess these packets are measured while executing Snort with
and without the preprocessor.
Table 3 summarizes the results of this experiment. Snort
was run with TCP stream reassembly enabled so that pat-
terns are searched for in individual packets as well as re-
assembled stream buﬀers. Window size w was set at 8 bytes,
32 bit ﬁngerprints were used, and step size s was varied from
1 byte to 3 bytes. When Snort is run with the preprocessor,
the amount of packets processed varies from 10% to 14% of
the total number of packets in Trace 2. This translates to
a 14% to 19% improvement in the runtime of Snort when
the preprocessor is enabled. The performance gain is lim-
ited given that in this software solution, the processing time
is inherently dominated by moving the packets to and from
memory.
Column 9 shows the memory footprint of the preproces-
sor conﬁguration and includes the overhead for storing the
hash table unlike the memory footprint shown in Table 2.
A hash table with 16,384 entries is used. The top level of
the hash table contains pointers to bucket chains. This hash
table organization oﬀers an ideal tradeoﬀ between speed of
hash function computation/table lookup and memory foot-
print. In comparison, the Snort data structure for the Aho-
Corasick pattern matching algorithm requires 57.02 MBytes
for the same set of patterns that the preprocessor takes as
input.
In Table 3, a point of diminishing return is reached when
the step size s is increased to 3 bytes. This value causes an
increase in the runtime of Snort when compared to a prepro-
cessor with step size 2 bytes. This is due to the increase in
the number of packets that the preprocessor sends to Snort
(column 6 in Table 3). This is a direct eﬀect of an increase
in the false positive rate caused by incrementing the step
size from 2 bytes to 3 bytes. This eﬀect can also be seen
in Table 2. The number of alerts returned by Snort when
run with and without the preprocessor (shown in column 5
and column 8) diﬀer. This is a side eﬀect of the way that
Snort reports alerts for a reassembled stream which causes
multiple duplicated alerts to be raised for each packet that
belongs to the stream.
The results in Table 3 show that the processing cost of the
preprocessor is not prohibitively large for a software imple-
mentation. A hardware implementation can further improve
performance by exploiting parallelism during ﬁngerprint ta-
ble lookups. The ﬁngerprint approach is computationally
lightweight and successive ﬁngerprints over a sliding win-
dow can be incrementally computed in constant time using
the technique presented in [8]. Considering all these factors
into account, we argue that a hardware implementation of
the preprocessor can process data at high line rates in real
time.
5. DISCUSSION AND FUTURE WORK
We have presented a method to accelerate pattern match-
ing using approximate ﬁngerprints. Our preliminary results
show the feasibility of this approach, which can signiﬁcantly
reduce the load on precise pattern matching methods used
in current network intrusion detection systems. The ap-
proach has two other favorable properties: an extremely
small memory footprint and low number of memory accesses
per packet. This enables a potential hardware implementa-
tion of the method, necessary for high-speed links.
This ﬁrst study of approximate ﬁngerprinting has raised
several issues that are currently under investigation. Our
results indicate a ﬁngerprint window size of 8 bytes to be the
most appropriate in terms of number of memory accesses,
as well as to reduce the number of false positives. Although
this does not cover all the rules present in Snort, relevant
literature and our ongoing work indicate that a single-lookup
solution for the short patterns is feasible and could well be
integrated with the approximate ﬁngerprinting solution.
Finally, a fundamental advantage of a ﬁngerprint-based
solution is the ability to indicate candidate matches (as op-
posed to e.g. a Bloom ﬁlter). This is a yet-unexplored aspect
of our solution. The candidate match may indicate to Snort
at what oﬀset to start the precise pattern matching algo-
rithm, and what patterns to focus on. It may also facilitate
other pattern matching applications, such as rapid worm
detection, by gathering approximate statistics of frequent
content blocks.
6. REFERENCES
[1] A. V. Aho and M. J. Corasick. Eﬃcient string
matching: an aid to bibliographic search.
Communications of the ACM, 18(6):333–340, June
1975.
[2] K. Anagnostakis, E. Markatos, S. Antonatos, and
M. Poluchronakis. E2xB: A domain-speciﬁc string
matching algorithm for intrusion detection. In
Proceedings of IFIP Information Security Conference,
May 2003.
[3] H. Bos and K. Huang. Towards software-based
signature detection for intrusion prevention on the
network card. In Proceedings of Symposium on Recent
Advances in Intrusion Detection, Sept. 2005.
[4] B. Commentz-Walter. A string matching algorithm
fast on the average. In Proceedings of ICALP, pages
118–132, July 1979.
[5] S. Dharmapurikar, P. Krishnamurthy, T. Sproull, and
J. Lockwood. Deep packet inspection using parallel
bloom ﬁlters. In Proceedings of Symposium on High
Performance Interconnects (HotI), pages 44–51, Aug.
2003.
[6] S. Dharmapurikar and J. Lockwood. Fast and scalable
pattern matching for content ﬁltering. In Proceedings
of ANCS, Oct. 2005.
[7] H.-A. Kim and B. Karp. Autograph: Toward
automated, distributed worm signature detection. In
Proceedings of Usenix Security, Aug. 2004.
[8] U. Manber. Finding similar ﬁles in a large ﬁle system.
In Proceedings of Usenix Conference, 1994.
[9] A. Moore, J. Hall, E. Harris, C. Kreibech, and
I. Pratt. Architecture of a network monitor. In
Proceedings of Passive and Active Measurement
Workshop, Apr. 2003.
[10] J. Newsome, B. Karp, and D. Song. Polygraph:
Automatically generating signatures for polymorphic
worms. In Proceedings of the IEEE Symposium on
Security and Privacy, May 2005.
[11] V. Paxson. Bro: A system for detecting network
intruders in real-time. Computer Networks, 31, 1999.
[12] M. Rabin. Fingerprinting by random polynomials.
Technical Report TR-15-81, Harvard University,
Department of Computer Science, 1981.
[13] M. Roesch. Snort: Lightweigth intrusion detection. In
Proceedings of Usenix LISA, Nov. 1999.
[14] S. Singh, C. Estan, G. Varghese, and S. Savage.
Automated worm ﬁngerprinting. In OSDI, Dec. 2004.
[15] R. Sommer and V. Paxson. Enhancing byte-level
network intrusion detection signatures with context.
In Proceedings of the 10th ACM Conference on
Computer and Communications Security, 2003.
[16] H. Song, T. Sproull, M. Attig, and J. Lockwood. Snort
oﬄoader: A reconﬁgurable hardware NIDS ﬁlter. In
Proceedings of 15th International Conference on Field
Programmable Logic and Applications (FPL),
Tampere, Finland, Aug. 2005.
[17] N. Spring and D. Wetherall. A protocol-independent
technique for eliminating redundant network traﬃc. In
Proceedings of ACM SIGCOMM, 2000.
[18] Y. Sugawara, M. Inaba, and K. Hiraki. Over 10 Gbps
string matching mechanisms for multi-stream packet
scanning systems. In Proceedings of Field
Programmable Logic and Application, Apr. 2004.
[19] L. Tan and T. Sherwood. A high throughput string
matching architecture for intrusion detection and
prevention. In Proceedings of the International
Symposium on Computer Architecture, June 2005.
[20] N. Tuck, T. Sherwood, B. Calder, and G. Varghese.
Deterministic memory-eﬃcient string matching
algorithms for intrusion detection. In Proceedings of
IEEE Infocom, Mar. 2004.
[21] S. Wu and U. Manber. Agrep – a fast approximate
pattern-matching tool. In Proceedings of Usenix
Conference, pages 153–162, 1992.