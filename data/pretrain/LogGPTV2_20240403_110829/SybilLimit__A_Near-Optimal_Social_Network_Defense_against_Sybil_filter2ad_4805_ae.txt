escaping tails accept sybil nodes, the rising bar will allow
further sybil nodes to be accepted. The key observation here
is that, as shown by the previous section, the number of
sybil nodes accepted by V ’s uniform tails is always properly
bounded (by the intersection condition). The fraction of
escaping tails is o(1)  0.
3. Uniform or non-uniform tails of escaping honest
suspects. By Lemma 4, there are at most rn such
tails, where  is a constant that can be made close to 0.
4. Tainted tails. As explained in Section 6.1, there are
O(rg log n) = o(rn) such tails for g = o(n/ log n).
13
Considering ﬁrst the load imposed by only the ﬁrst type
of tails in this list, we are able to prove [41] that with 1 − δ
probability, most non-escaping suspects will satisfy both the
intersection condition and the balance condition and thus
will be accepted. This proof is fairly tricky/involved due
to the external correlation among random routes. Harder
still is taking into account the load imposed by the last 3
types of tails.
In particular, the adversary has many dif-
ferent strategies for when to increase the load of which of
V ’s tail, and ﬁnding the optimal strategy of the adversary is
challenging. Fortunately, as argued above, the total number
of tails from suspects in the last 3 tail types is 0rn for some
small 0. We can apply a similar argument as in Section 6.1
to show that with probability of 1 − δ, the number of inter-
sections between these 0rn tails and U(V ) is at most 00n
for some small 00. This means that the total load imposed
in the last 3 tail types is at most 00n. Finally, we prove that
after doubling the constant h obtained earlier, even if the
adversary completely controls where and when to impose the
00n load, the adversary can cause only 00n honest suspects
to be rejected. Because 00 can be made small and close to
0, this ensures that most non-escaping honest suspects will
remain accepted.
7. Estimating the number of routes needed
√
n/ log n).
We have shown that in SybilLimit, a veriﬁer V will accept
(1− )n honest suspects with probability 1− δ if r = r0
m.
The constant r0 can be directly calculated from the Birthday
Paradox and the desired end probabilistic guarantees. On
the other hand, m is unknown to individual nodes.3 Adapt-
ing the sampling approach from SybilGuard (as reviewed in
√
Section 4) is not possible, because that approach is funda-
mentally limited to g = o(
Benchmarking technique. SybilLimit uses a novel and per-
haps counter-intuitive benchmarking technique to address the
previous problem, by mixing the real suspects with some ran-
dom benchmark nodes that are already known to be mostly
honest. Every veriﬁer V maintains two sets of suspects, the
benchmark set K and the test set T . The benchmark set
K is constructed by repeatedly performing random routes
of length w and then adding the ending node (called the
benchmark node) to K. Let K + and K− be the set of honest
and sybil suspects in K, respectively. SybilLimit does not
know which nodes in K belong to K +. But a key property
here is that because the escaping probability of such random
routes is o(1), even without invoking SybilLimit, we are
assured that |K−|/|K| = o(1). The test set T contains the
3SybilLimit also requires that the random route length w be the mixing
time of the graph, which is also unknown. However, as in SybilGuard [42],
SybilLimit assumes that the nodes know a rough upper bound on the graph’s
mixing time. Such an assumption is reasonable because the mixing time
should be O(log n), which is rather insensitive to n.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 03:11:45 UTC from IEEE Xplore.  Restrictions apply. 
real suspects that V wants to verify, which may or may not
happen to belong to K. We similarly deﬁne T + and T −.
Our technique will hinge upon the adversary not knowing
K + or T + (see later for how to ensure this), even though it
may know K + ∪ T + and K− ∪ T −.
√
To estimate r, a veriﬁer V starts from r = 1 and then
repeatedly doubles r. For every r value, V veriﬁes all sus-
pects in K and T . It stops doubling r when most of the
nodes in K (e.g., 95%) are accepted, and then makes a ﬁnal
determination for each suspect in T .
No over-estimation. Once r reaches r0
m, most of the
suspects in K + will indeed be accepted, regardless of the
behavior of the adversary. Further, because |K +|/|K| =
1 − o(1), having an r of r0
m will enable us to reach the
threshold (e.g., 95%) and stop doubling r further. Thus, V
will never over-estimate r (within a factor of 2).
Under-estimation will not compromise SybilLimit’s
guarantees.
It is possible for the adversary to cause an
under-estimation of r by introducing artiﬁcial intersections
between the escaping tails of V and the escaping tails of
suspects in K +. This may cause the threshold to be reached
before r reaches r0
√
√
m.
√
√
√
√
Using r < r0
m, but also for r < r0
What if SybilLimit operates under an r < r0
m? Inter-
estingly, SybilLimit can bound the number of sybil nodes
accepted within O(log n) per attack edge not only when
r = r0
m (see [41] for proofs). To
obtain some intuition, ﬁrst notice that the number of sybil
nodes with tails intersecting with V ’s uniform tails (Sec-
tion 6.1) can only decrease when r is smaller. Second, the
arguments regarding the number of sybil nodes accepted by
V ’s escaping tails and non-uniform tails (Section 6.2) hinges
only upon the fraction of those tails, and not the value of r.
m, however, will decrease the probability
of tail intersection between the veriﬁer and an honest suspect.
Here, we leverage a second important property of the bench-
mark set. Namely, conditioned upon the random routes for
picking benchmark nodes being non-escaping, the adversary
will not know which nodes are picked as benchmark nodes.
(If the adversary may eavesdrop messages, we can readily
encrypt messages using edge keys.) As a result, given an
honest suspect, the adversary cannot tell whether it belongs
to K + or T +. If most (e.g., 95%) of the suspects in K are
accepted, then most suspects in K + must be accepted as
well, since |K +|/|K| = 1 − o(1). If most suspects in K +
are accepted under r < r0
m, the adversary must have
intentionally caused intersection between V and the suspects
in K +. Because the adversary cannot tell whether an honest
suspect belongs to K + or T +, it cannot introduce intersec-
tions only for suspects in K +; it must introduce intersections
for suspects in T + as well. Thus, most suspects in T + will
be accepted as well under the given r.
Further discussions. The benchmarking technique may
appear counter-intuitive in two aspects. First, if SybilLimit
√
uses an under-estimated r, it will be the adversary that helps
it to accept most of the honest nodes. While this is true,
SybilLimit is still needed to bound the number of sybil nodes
accepted and also to prevent r from growing beyond r0
m.
Second, the benchmark set K is itself a set with o(1) fraction
of sybil nodes. Thus, it may appear that an application can
just as well use the nodes in K directly, and avoid the full
SybilLimit protocol. However, the set K is constructed
randomly and may not contain some speciﬁc suspects that
V wants to verify.
√
We leave to [41] a more formal discussion on the guaran-
tees of the benchmarking technique and the needed size of
K. There, based on classical estimation theory [4], we will
show that the needed size of K is independent of the size
of T . We also discuss [41] how to carefully implement the
technique to avoid leaking (probabilistic) information to the
adversary about K +.
8. Lower bound
SybilLimit bounds the number of sybil nodes accepted
within O(log n) per attack edge. A natural question is
whether we can further improve the guarantees. For ex-
ample, it may appear that SybilLimit does not currently have
any mechanism to limit the routing behavior of sybil nodes.
One could imagine requiring nodes to commit (cryptograph-
ically) to their routing tables, so that sybil nodes could not
perform random routes in an inconsistent fashion. We will
show, however, that such techniques or similar techniques
can provide at most a log n factor of improvement, because
the total number of sybil nodes accepted is lower bounded
by Ω(1) per attack edge.
SybilLimit entirely relies on the observation that if the
adversary creates too many sybil nodes, then the resulting
social network will no longer have O(log n) mixing time.
Our technical report [41] proves that for any given constant
c, any g ∈ [1, n], and any graph G with n honest nodes and
O(log n) mixing time, it is always possible for the adversary
to introduce c · g sybil nodes via g attack edges so that the
augmented graph’s mixing time is O(log n0) where n0 =
n + c · g. There are actually many ways to create such an
augmented graph. One way (as in our proof) is to pick g
nodes arbitrarily from G and attach to each of them (using
a single attack edge) a group of c sybil nodes. It does not
matter how the c sybil nodes in a group are connected with
each other, as long as they are connected. Now because the
augmented graph has the same mixing time (i.e., O(log n0))
as a “normal” social network with n0 nodes, as long as the
protocol solely relies on mixing time, we cannot distinguish
these sybil nodes from honest nodes. In other words, all
protocols based on mixing time will end up accepting Ω(1)
sybil nodes per attack edge.
14
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 03:11:45 UTC from IEEE Xplore.  Restrictions apply. 
9. Experiments with online social networks
Goal of experiments. We have proved that SybilLimit can
bound the number of sybil nodes accepted within O(log n)
√
per attack edge, which improved upon SybilGuard’s guar-
antee of O(
n log n). However, these provable guarantees
of SybilLimit (and SybilGuard as well) critically rely on the
assumption that social networks have small (i.e., O(log n))
mixing time. Our experiments thus mainly serve to vali-
date such an assumption, based on real-world social net-
works. Such validation has a more general implication be-
yond SybilLimit—these results will tell us whether the ap-
proach of leveraging social networks to combat sybil attacks
is valid. A second goal of our experiments is to gain better un-
derstanding of the hidden constant in SybilLimit’s O(log n)
guarantee. Finally, we will also provide some example nu-
merical comparisons between SybilGuard and SybilLimit.
However, it is not our goal to perform a detailed experi-
mental comparison, because SybilLimit’s improvement over
SybilGuard is already rigorously proved.
Social network data sets. We use three crawled online
social network data sets in our experiments: Friendster, Live-
Journal, and DBLP (Table 2). They are crawls of http://
www.friendster.com, http://www.livejournal.
com, and http://dblp.uni-trier.de, respectively.
The DBLP data set is publicly available, but the other two are
not. We also experiment with Kleinberg’s synthetic social
network [16], which we used [42] to evaluate SybilGuard.
Strictly speaking, DBLP is a bibliography database and
not a social network. To derive the “social network” from
DBLP, we consider two people having an edge between them
if they have ever co-authored a paper. Because of the closely
clustered co-authoring relationships among researchers, we
expect such a social network to be more slowly mixing than
standard social networks. Thus, we use DBLP as a bound on
the worst-case scenario. Obviously, DBLP is guaranteed to
be free of sybil nodes. Although it is theoretically possible
for Friendster and LiveJournal to be polluted with sybil nodes
already, we expect such pollution to be limited because of
the lack of motivation to launch large-scale sybil attacks
in Friendster and LiveJournal. Table 2 presents the basic
statistics of the four social networks after appropriate prepro-
cessing (e.g., converting pairs of directed edges to undirected
edges, removing low (< 5) degree nodes, taking the largest
connected component—see [41]). We then randomly select
nodes to be sybil nodes, until the number of attack edges
reaches g, as in [42].4
Results: Mixing time of real-world social networks. In
SybilLimit, the only parameter affected by mixing time is
the length of the random routes (w). Namely, w should be at
4We also consider the “cluster” placement of attack edges from [42];
the results are qualitatively the same.
least as large as the mixing time. It is not possible to directly
show that our data sets have O(log n) mixing time, since