2019 19th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing (CCGRID)
Anomaly Detection and Classification using
Distributed Tracing and Deep Learning
Sasho Nedelkoski*, Jorge Cardoso^, Odej Kao*
* Complex and Distributed IT-Systems Group, TU Berlin, Berlin, Germany
Email: {nedelkoski, odej.kao}@tu-berlin.de
iHuawei Munich Research Center, Huawei Technologies, Munich, Germany
Email: PI:EMAIL
Abstract—Artificial Intelligence for IT Operations (AIOps) problems, component/system failures (e.g., outages, degraded
combines big data and machine learning to replace a broad range performance), or security incidents. All these examples de­
of IT Operations tasks including availability, performance, and
scribe situations, where the system operates outside of the
monitoring of services. By exploiting log, tracing, metric, and
normal, expected or pre-defined behaviour. Thus, the system
network data, AIOps enable detection of faults and issues of
services. The focus of this work is on detecting anomalies based exposes that an anomaly must be detected and recognized,
on distributed tracing records that contain detailed information before it leads to a service or a system failure.
for the availability and the response time of the services. In The foundation for AIOps systems is the availability of
large-scale distributed systems, where a service is deployed on
suitable and descriptive data, which is typically observed by
heterogeneous hardware and has multiple scenarios of normal
three core components: tracing, logging, and resource moni­
operation, it becomes challenging to detect such anomalous cases.
We address the problem by proposing unsupervised, response toring metrics. The tracing component produces events (spans)
time anomaly detection based on deep learning data modeling containing information on the execution path and response
techniques; unsupervised dynamic error threshold approach; time. The logging data represents interactions between data,
tolerance module for false positive reduction; and descriptive
files, or applications and is used to analyze specific trends
classification of the anomalies. The evaluation shows that the
or to record events/actions for a later forensic. The resource
approach achieves high accuracy and solid performance in both,
experimental testbed and large-scale production cloud. monitoring data reflects the current utilization and status of the
Index Terms—AIOps; anomaly detection; service reliability; infrastructure, typically as cross-layer information regarding
time series; distributed tracing; autoencoders; RNNs; GRUs; CPU, memory, disk, and network throughput and latency. Most
CNNs.
of the current AIOps platforms apply deep learning solely
on monitoring data [1], [2], as this data is simple to collect
I. Int ro duc t io n and interpret, but not sufficient for a holistic approach. We
The increasing number of IoT applications with dynamically aim at exploring an additional path for anomaly detection
linked devices and their embedding in real-world (smart) using a second category of data, namely the tracing data
environments drive the creation of large multi-layered systems. collected during the execution of system operations. Tracing
As a consequence, the complexity of the systems is steadily technologies [3]—[5] generate events to externalize the state
growing up to a level, where it is impossible for human oper­ of the system by combining performance data from the end-
ators to oversee and holistically manage the systems without to-end execution path with structured and causally related
additional support and automation. Uninterrupted services with execution traces. We are confident that such data can improve
guaranteed latency, response times, and other QoS parameters, the anomaly detection, root-cause analysis, and remediation
are however mandatory prerequisite for many of the data- in the system. It contains detailed information for individual
driven and autonomous applications. Therefore, losing control services and the causal relationship to other related services
is not a feasible option for any system or infrastructure. that form part of the trace.
The large service providers are aware of the need for The focus of the study is to tackle the problem of anomaly
always-on, dependable services and they already deployed detection in real-world tracing data. It faces several challenges,
numberless measures by introducing additional intelligence including the lack of labeled data, concept drift, and concept
to the IT-ecosystem. For example, by employing network evolution. Other major sources of difficulties emerge due
reliability engineers (NRE), site reliability engineers (SRE), to the low signal-to-noise ratio, the presence of multiple
by using automated tools for infrastructure monitoring, and frequencies and multiple distributions, the large number of
developing tools based on artificial intelligence (AIOps) for distinct time series generated by microservice applications,
load balancing, capacity planning, resource utilization, storage and the presence of concept drifts. The signal-to-noise ratio
management, and anomaly detection. is typically very low as many different components affect
The next piece in the puzzle aims at rapidly decreasing the response time of microservices such as switches, routers,
the reaction time in case an urgent activity of a system memory capacity, CPU performance, programming languages,
administrator is necessary. That usually involves performance thread and process concurrency, bugs, and volume of user
_ IEEE
978-1-7281-0912-1/19/$31.00 ©2019 IEEE computer
DOI 10.1109/CCGRID.2019.00038 society
requests. Multiple frequencies are correlated with system and we distinguish between statistical and machine learning meth­
user behaviour since request patterns are different, e.g., from ods. The machine learning approaches can be divided into two
hour to hour due to business operation hours, from day to day general categories [1], supervised [16]—[19] and unsupervised
due to system maintenance tasks, and from month to month [20]—[23].
due to cyclic patterns. For these reasons, the utilization of Vallis et al. [24] proposed a novel approach, which builds
unsupervised approaches is required. In such scenarios where on Extreme Studentized Deviate test (ESD), for detecting
anomaly detection is being used as diagnostic tool, a degree anomalies in long-term time series data. The approach requires
of additional description is required. Identifying the potential the detection of the trend component. This technique is similar
anomaly in the service is of limited value for the operators to most of the statistical methods, which have limitations when
without having more detailed explanation. they are applied to large systems based on service-oriented
Contributions. We provide an algorithm that adapts and and microservice architectures. These systems produce time
extends deep learning methods from various domains. This series data with high noise and with more than a single normal
work focuses on anomaly detection from tracing data in behavior in the signal. Specifically, if the time series has more
large-scale distributed systems, but can also be used in other than two different normal (expected) scenarios of operation,
applications involving anomaly detection on time series data the algorithm would not be able to capture this information.
containing multiple normal operating scenarios. We show the Supervised methods use labeled data to train machine
capability of the Auto-Encoding Variational Bayes (variational learning models. The anomaly detection algorithms are clas­
autoencoder, AEVB) to learn multiple complex distributions sification models trained by data containing the information
representing normal behavior over longer period of time and whether the data point is an anomaly or not. For practical
detect anomalies by employing a dynamic, probability-based, usage, the labelling by experts or injection of anomalies either
error threshold setting. Furthermore, we propose combination is not sufficient (evolving time series, concept drifts) or may
of the threshold setting and post-processing that aims to reduce harm the running system. Therefore, unsupervised methods are
the number of false positives. Lastly, we present a classi­ investigated, having the positive properties of performing the
fication module and provides descriptions for the detected same task, but not using labeled input data.
anomalies. Recently, deep learning techniques are increasingly inves­
The remaining of the paper is structured as follows. In tigated because of their success in range of domains. In
section n, we provide the related work for the field of anomaly that direction, Malhotra et al. [25] used stacked recurrent
detection. In sections HI and IV, we present the preliminary hidden layers to enable learning of higher level temporal
knowledge and our proposed methodology. Section V sum­ features. They presented a model of stacked Long Short­
marizes the performance evaluation in terms of speed and Term Memory (LSTM) networks for anomaly detection in
accuracy for different types of anomalies on both experimental time series. A network was trained on non-anomalous data
and real-world production cloud data. and used as a predictor over a number of time steps. The
resulting prediction errors were modeled as a multivariate
II. Rel at ed w ork Gaussian distribution, which was used to assess the likelihood
of anomalous behavior. The efficacy of this approach was also
Tracing technologies for distributed services record in­ demonstrated on four datasets.
formation about all the individual components participating Xu et al. [26] show the usability of variational autoencoders
on an e.g., user request (initiator) within the system. Two for anomaly detection and triggering of timely troubleshooting
classes of solutions have been proposed to aggregate these problems on Key Performance Indicator (KPI) data of Web
information so that one can associate all record entries with applications (e.g., page views, number of online users, and
a given initiator, black-box and annotation-based monitoring number of orders). They proposed Donut, an unsupervised
schemes [3]. Black-box schemes [6]—[8] assume there are no anomaly detection algorithm based on AEVB. Furthermore,
additional information other than the message record described Hundman et al. [27] show the use of LSTM recurrent neural
above, and use statistical regression techniques to infer that networks for spacecraft anomalies on multi-variate telemetry
association. Annotation-based schemes [5], [8]—[10] rely on data.
applications or middleware to explicitly tag every record with Existing supervised and unsupervised auto-regressive ap­
a global identifier that links these message records back to proaches fail with data of small signal-to-noise ratio and
the originated request. We use the annotation based system autocorrelation either by learning only the running mean or
(Zipkin based on Dapper [3]), which relies on proper service by not preserving the order in time series. In similar direction
instrumentation. as of Xu et al. and Hundman et al., we combine the methods
While the anomaly detection on other categories of data like from both and show that the integration of Gated Recurrent
log and metric are part of previous research [1], [2], [11]—[15], Units (GRUs, simplified LSTMs) with variational autoencoder
the related work on time series and the structural anomaly produce results which are able to meet the accuracy and perfor­
detection in trace data is still limited. mance requirements. Of course, the inclusion of preprocessing
Anomaly detection for services have been studied exhaus­ and postprocessing improves the accuracy by reducing the
tively during many years on different kinds of data. In general, amount of false positives.
242
III. Pr el iminaries forward neural network, setting the output (target) value to be
equal to the inputs i.e. yt = xt [28]. The identity function
Systems based on microservices or service-oriented archi­
seems a trivial function to be learn, but by placing some
tectures consists of several services connected by a network,
constraints, such as limiting the number of hidden units, or
providing a larger system application. To monitor the user
putting regularization, interesting features from the data can be
requests with a detailed description of different participating
extracted. A typical architecture of an autoencoder is shown in
microservices, distributed tracing technologies are utilized.
Figure 1, where h is called latent representation or bottleneck
A trace T = (Eo, Ei,..., Ei) is represented by an enumer­
of the autoencoder.
ated collection of events. Each event is represented by key-
value pairs (ki,Vi) describing the state, performance, and other
characteristics of a service at a given time tj. The events
contain contain a timestamp when the particular service was
invoked, a response time, and a http URL among the other meta
information (e.g., host IP, service name etc.). Depending on the
request, traces can have different lengths and services invoked.
The response time is one of the most important attributes of
the event, e.g., if its value which characterizes the intra-service
calls in the system suddenly increases at times ij+i, ij+2, it
may indicate a problem with the underlying distributed system.
Let us assume that we observe two traces: Ti = (Euri_ai,
Euri—bi; Eurl_Cl) and T2 — (Euri_a2,Euri_b2JEuri_C2). Each
Fig. 1. Architecture of an autoencoder network. The x and y can be of any
http URL recorded in the platform is a source of events. Events
type, in this paper x = y is time series data.
of the same type are clustered together by their http URL to
form a time series TSi = (Eai,Ea2).
By training on non-anomalous data, the autoencoder learns
Further, let us assume that we record the following two http
and is able to produce good reconstructions on new non­
URLs from two events:
anomalous samples (low error). If we use the same model
• 1.1.1.5/tag_l/group_idl/tag_2/servicel to predict the reconstruction for an anomalous sample, then
• 1.1.1,6/tag_5/group_id2/tag_4/servicel the reconstruction error will be larger.
We use regular expression for each of the A variational autoencoder (AEVB) [29] is a deep neural
events having http URL in form of {host network architecture that can learn complex representations
IP}/{tag_id}/{group_id}/{tag_2}/servicel and assign them to from data without supervision. AEVB is composed of an
the same cluster The same procedure is done with other events encoder and decoder, both are neural networks, and contain a
such as those that belong to {host}/groups/{group_id}/logs. loss function. Instead of mapping the input vector onto a fixed
We name such groups as endpoints and to each we assign vector as in the usual autoencoders, the model maps any input