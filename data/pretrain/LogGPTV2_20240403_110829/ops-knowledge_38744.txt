User: How to use Python to write a crawler program to automatically grab web content and store it in the database? Please provide a basic crawler code example.
Assistant: The following is a basic Python crawler program example, which can automatically grab webpage content and store it in the database: ```python import requests import mysql.connector # Set the parameters to connect to the MySQL database mydb = mysql.connector.connect( host ="localhost", user="yourusername", password="yourpassword", database="yourdatabase" ) # Create a new data table to store webpage content mycursor = mydb.cursor() mycursor.execute("CREATE TABLE webpage_content (id INT AUTO_INCREMENT PRIMARY KEY, url VARCHAR(255), content TEXT)") #Define a function to fetch webpage content and store it in the database def fetch_and_store(url): #Get webpage content response = requests.get(url) content = response.text # Store web page content in the database sql = "INSERT INTO webpage_content (url, content) VALUES (%s, %s)" val = (url, content) mycursor.execute(sql, val) mydb. commit() print("Successfully fetched and stored content from:", url) # Call the function to fetch and store web page content fetch_and_store("https://www.example.com/") ``` In this example, the program first Connect to the MySQL database through the `mysql.connector` module and create a new data table called `webpage_content`. Then, we define a function called `fetch_and_store()`, which accepts a URL parameter, uses the `requests` library to fetch the content of the web page corresponding to the URL, and stores the URL and the content in the MySQL database. Finally, we call `fetch_and_store()` function to get and store `https://www.example.com/` URL corresponding to the content of the webpage.