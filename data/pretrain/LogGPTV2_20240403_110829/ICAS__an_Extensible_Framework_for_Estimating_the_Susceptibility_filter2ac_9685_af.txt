fabrication testing, or unintentionally through common usage.
The attack requires only two additional standard cells and
evades every known detection mechanism to date. ICAS quan-
tiﬁes the defensive coverage to these and other fabrication-time
attacks.
B. Untrusted-foundry Defenses
Most untrusted foundry defenses rely on post-fabrication
detection schemes [9], [10], [12], [49]–[53]. ICAS aims to
guide innovation in preventive defenses against fabrication-
time attacks, for which few mechanisms currently exist [13]–
[16]. We highlight some of these preventive measures and how
ICAS could measure their effectiveness.
While preventive security-by-design was ﬁrst explored at the
behavioral (RTL) level by of Jin et al. [42], Xiao et al. were the
ﬁrst to demonstrate security-by-design at the layout-level with
their BISA (Built-In Self-Authentication) scheme [15]. The
undirected BISA approach attempts to eliminate all unused
space on the device layer placement grid, and create routing
congestion, by ﬁlling the device layer with interconnected
tamper-resistant ﬁll cells. Alternatively, recognizing the im-
practicality of ﬁlling 100% of the empty placement sites in
complex circuit designs, Ba et al. take a directed approach
to ﬁlling empty placement cites [13], [16]. Speciﬁcally, they
only ﬁll empty placement sites in close proximity to security-
critical nets.
X. CONCLUSION
ICAS is an extensible framework that we use to expose
and quantify gaps in existing defenses to the threat posed by
an untrusted foundry. ICAS has two high-level components:
Nemo, a tool that bridges the semantic gap across IC design
processes by tracking security-critical signals across all stages
of hardware development and GDSII-Score, a tool that esti-
mates the difﬁculty a foundry-level attacker faces in attacking
security-critical logic. Experiments with over 60 IC layouts
across three open-source hardware cores and four foundry-
level hardware Trojans reveal that all current defenses leave
the IC design vulnerable to attack—and some are totally
ineffective. These results show the value of a tool like ICAS
that can help designers identify and address defensive gaps.
From a high level, ICAS is momentus in that it makes
security a ﬁrst-class concern during IC layout (in addition to
power, area, and performance): ICAS allows IC designers to
measure the security implications of tool settings and design
decisions. ICAS ﬁts well with existing IC design tools and
ﬂows, allowing them to consider security. ICAS is a critical
measurement tool that enables the systematic development of
future physical-level defenses against the threat of an untrusted
foundry.
ACKNOWLEDGMENT
We thank the anonymous reviewers, Ted Lyszczarz, Brian
Tyrrell, and other members of the MIT Lincoln Laboratory
community, for their thoughtful feedback that enhanced the
quality of our work.
This material is based upon work supported by the National
Science Foundation Graduate Research Fellowship Program
under Grant No. DGE 1256260. Any opinions, ﬁndings, and
conclusions or recommendations expressed in this material are
those of the author(s) and do not necessarily reﬂect the views
of the National Science Foundation.
DISTRIBUTION STATEMENT A. Approved for public
release. Distribution is unlimited. This material
is based
upon work supported by the Under Secretary of Defense
for Research and Engineering under Air Force Contract No.
FA8702-15-D-0001. Any opinions, ﬁndings, conclusions or
recommendations expressed in this material are those of the
author(s) and do not necessarily reﬂect the views of the Under
Secretary of Defense for Research and Engineering.
REFERENCES
[1] Intel
Corporation,
“Microprocessor
quick
reference
guide,”
https://www.intel.com/pressroom/kits/quickreffam.htm.
[2] P. Alcorn, “Ice lake might arrive in june, according to leaked lenovo doc-
uments,” https://www.tomshardware.com/news/lenovo-laptop-intel-ice-
lake-10nm,38674.html.
[3] M.
Lapedus,
“Big
trouble
https://semiengineering.com/big-trouble-at-3nm/.
at
3nm,”
June
2018,
[4] G. T. Becker, F. Regazzoni, C. Paar, and W. P. Burleson, “Stealthy
dopant-level hardware trojans,” in International Workshop on Crypto-
graphic Hardware and Embedded Systems (CHES), 2013.
[5] R. Kumar, P. Jovanovic, W. Burleson, and I. Polian, “Parametric trojans
for fault-injection attacks on cryptographic hardware,” in Workshop on
Fault Diagnosis and Tolerance in Cryptography (FDTC), 2014.
[6] K. Yang, M. Hicks, Q. Dong, T. Austin, and D. Sylvester, “A2: Analog
malicious hardware,” in IEEE Symposium on Security and Privacy (SP),
2016.
[7] S. T. King, J. Tucek, A. Cozzie, C. Grier, W. Jiang, and Y. Zhou,
“Designing and implementing malicious hardware,” in Usenix Workshop
on Large-Scale Exploits and Emergent Threats (LEET), 2008.
[8] M. Tehranipoor and F. Koushanfar, “A survey of hardware trojan
taxonomy and detection,” IEEE Design & Test of Computers, 2010.
[9] D. Agrawal, S. Baktir, D. Karakoyunlu, P. Rohatgi, and B. Sunar, “Trojan
detection using IC ﬁngerprinting,” in IEEE Symposium on Security and
Privacy (SP), 2007.
[10] Y. Jin and Y. Makris, “Hardware trojan detection using path delay
ﬁngerprint,” in IEEE Workshop on Hardware-Oriented Security and
Trust (HOST), 2008.
[11] M. Potkonjak, A. Nahapetian, M. Nelson, and T. Massey, “Hardware
trojan horse detection using gate-level characterization,” in ACM/IEEE
Design Automation Conference (DAC), 2009.
[12] S. Narasimhan, X. Wang, D. Du, R. S. Chakraborty, and S. Bhunia,
“TeSR: A robust temporal self-referencing approach for hardware trojan
detection,” in IEEE Symposium on Hardware-Oriented Security and
Trust (HOST), 2011.
[13] P.-S. Ba, S. Dupuis, M. Palanichamy, G. Di Natale, B. Rouzeyre et al.,
“Hardware trust through layout ﬁlling: a hardware trojan prevention
technique,” in IEEE Computer Society Annual Symposium on VLSI
(ISVLSI), 2016.
[14] R. P. Cocchi, J. P. Baukus, L. W. Chow, and B. J. Wang, “Circuit
camouﬂage integration for hardware IP protection,” in ACM Design
Automation Conference (DAC), 2014.
[15] K. Xiao and M. Tehranipoor, “BISA: Built-in self-authentication for
preventing hardware trojan insertion,” in IEEE Symposium on Hardware-
Oriented Security and Trust (HOST), 2013.
[16] P.-S. Ba, M. Palanichamy, S. Dupuis, M.-L. Flottes, G. Di Natale, and
B. Rouzeyre, “Hardware trojan prevention using layout-level design
approach,” in European Conference on Circuit Theory and Design
(ECCTD), 2015.
[17] M. Hicks, M. Finnicum, S. T. King, M. M. K. Martin, and J. M. Smith,
“Overcoming an untrusted computing base: Detecting and removing
malicious hardware automatically,” in IEEE Symposium on Security and
Privacy (SP), 2010.
[18] H. Salmani, M. Tehranipoor, and R. Karri, “On design vulnerability
analysis and trust benchmarks development,” in IEEE International
Conference on Computer Design (ICCD), 2013.
[19] MIT Lincoln Laboratory, “Nemo,” https://github.com/mit-ll/nemo.
[20] ——, “GDS2-Score,” https://github.com/mit-ll/gds2-score.
[21] A. Waksman, M. Suozzo, and S. Sethumadhavan, “FANCI: identiﬁcation
of stealthy malicious logic using boolean functional analysis,” in ACM
SIGSAC Conference on Computer & Communications Security (CCS),
2013.
[22] H. Salmani and M. Tehranipoor, “Analyzing circuit vulnerability to
hardware trojan insertion at the behavioral level,” in IEEE Symposium
on Defect and Fault Tolerance in VLSI and Nanotechnology Systems
(DFT), 2013.
[23] R. S. Chakraborty, F. G. Wolff, S. Paul, C. A. Papachristou, and S. Bhu-
nia, “MERO: A statistical approach for hardware trojan detection.” in
International Workshop on Cryptographic Hardware and Embedded
Systems (CHES), 2009.
[24] M. Rostami, F. Koushanfar, J. Rajendran, and R. Karri, “Hardware
security: Threat models and metrics,” in IEEE International Conference
on Computer-Aided Design (ICCD), 2013.
[25] M. Beaumont, B. Hopkins, and T. Newby, “Hardware trojans-prevention,
detection, countermeasures (a literature review),” Defence Science and
Technology Organization Edinburgh (Australia), Tech. Rep., 2011.
[26] R. S. Chakraborty, S. Narasimhan, and S. Bhunia, “Hardware trojan:
Threats and emerging solutions,” in IEEE High Level Design Validation
and Test Workshop (HLDVT), 2009.
[27] F. Wolff, C. Papachristou, S. Bhunia, and R. S. Chakraborty, “Towards
trojan-free trusted ICs: Problem analysis and detection scheme,” in ACM
Conference on Design, Automation and Test in Europe (DATE), 2008.
[28] L. Lin, M. Kasper, T. G¨uneysu, C. Paar, and W. Burleson, “Trojan
side-channels: Lightweight hardware trojans through side-channel en-
gineering.” in International Workshop on Cryptographic Hardware and
Embedded Systems (CHES), 2009.
[29] Y. Shiyanovskii, F. Wolff, A. Rajendran, C. Papachristou, D. Weyer,
and W. Clay, “Process reliability based trojans through NBTI and HCI
effects,” in NASA/ESA Conference on Adaptive Hardware and Systems
(AHS), 2010.
[30] M. Hicks, C. Sturton, S. T. King, and J. M. Smith, “SPECS: A
lightweight runtime mechanism for protecting software from security-
critical processor bugs,” in ACM International Conference on Archi-
tectural Support for Programming Languages and Operating Systems
(ASPLOS), 2015.
[31] X. Wang, M. Tehranipoor, and J. Plusquellic, “Detecting malicious
inclusions in secure hardware: Challenges and solutions,” in IEEE
Workshop on Hardware-Oriented Security and Trust (HOST), 2008.
[32] T. Force, “High performance microchip supply,” Defense Technical
Information Center (DTIC), Annual Report, 2005.
[33] H. Salmani, “COTD: Reference-free hardware trojan detection and
recovery based on controllability and observability in gate-level netlist,”
IEEE Transactions on Information Forensics and Security, 2017.
[34] J. Zhang, F. Yuan, L. Wei, Y. Liu, and Q. Xu, “VeriTrust: Veriﬁcation
for hardware trust,” IEEE Transactions on Computer-Aided Design of
Integrated Circuits and Systems (TCAD), 2015.
[35] L. H. Goldstein and E. L. Thigpen, “SCOAP: Sandia controllabil-
ity/observability analysis program,” in ACM Design Automation Con-
ference (DAC), 1980.
[36] OpenCores.org,
“OpenRISC
https://github.com/openrisc/or1200.
OR1200
processor,”
[37] Cadence Design Systems, LEF/DEF Language Reference, 2009,
http://www.ispd.cc/contests/14/web/doc/lefdefref.pdf.
[38] E.
Sperling,
“Design
rule
complexity
rising,” April
2018,
https://semiengineering.com/design-rule-complexity-rising/.
[39] W. C. Elmore, “The transient response of damped linear networks with
particular regard to wideband ampliﬁers,” Journal of Applied Physics,
1948.
[40] Cadence Design
Systems,
Layer Map
Files,
http://www-
bsac.eecs.berkeley.edu/ cadence/tools/layermap.html.
[41] Calma Company, GDSII Stream Format Manual, February 1987.
[42] Y. Jin, N. Kupp, and Y. Makris, “DFTT: Design for trojan test,” in IEEE
International Conference on Electronics, Circuits, and Systems (ICECS),
2010.
[43] T. Linscott, P. Ehrett, V. Bertacco, and T. Austin, “SWAN: mitigating
hardware trojans with design ambiguity,” in IEEE/ACM International
Conference on Computer-Aided Design (ICCAD), 2018.
[44] R. Zhang, N. Stanley, C. Griggs, A. Chi, and C. Sturton, “Identifying
security critical properties for the dynamic veriﬁcation of a processor,” in
ACM Conference on Architectural Support for Programming Languages
and Operating Systems (ASPLOS), 2017.
[45] S. Williams, “Icarus Verilog,” http://iverilog.icarus.com/.
[46] J. F. Hughes and J. D. Foley, Computer graphics: principles and
practice. Pearson Education, 2014.
[47] MIT
Lincoln
Laboratory,
https://github.com/mit-ll/CEP.
“Common
evaluation
platform,”
[48] T. Sugawara, D. Suzuki, R. Fujii, S. Tawa, R. Hori, M. Shiozaki, and
T. Fujino, “Reversing stealthy dopant-level circuits,” in International
Workshop on Cryptographic Hardware and Embedded Systems (CHES),
2014.
[49] J. Balasch, B. Gierlichs, and I. Verbauwhede, “Electromagnetic circuit
ﬁngerprints for hardware Trojan detection,” in IEEE International Sym-
posium on Electromagnetic Compatibility (EMC), 2015.
[50] B. Zhou, R. Adato, M. Zangeneh, T. Yang, A. Uyar, B. Goldberg,
S. Unlu, and A. Joshi, “Detecting hardware trojans using backside
optical imaging of embedded watermarks,” in ACM/EDAC/IEEE Design
Automation Conference (DAC), 2015.
[51] R. Adato, A. Uyar, M. Zangeneh, B. Zhou, A. Joshi, B. Goldberg, and
M. S. Unlu, “Rapid mapping of digital integrated circuit logic gates via
multi-spectral backside imaging,” arXiv:1605.09306, 2016.
[52] J. Li and J. Lach, “At-speed delay characterization for IC authentication
and trojan horse detection,” in IEEE Workshop on Hardware-Oriented
Security and Trust (HOST), 2008.
[53] D. Forte, C. Bao, and A. Srivastava, “Temperature tracking: An inno-
vative run-time approach for hardware trojan detection,” in IEEE/ACM
International Conference on Computer-Aided Design (ICCAD), 2013.
APPENDIX A
ROUTE DISTANCES OF OR1200 LAYOUTS
Fig. 13. Route Distance Metric for OR1200 at 50% Density). A target density of 50% was held across each layout, while target clock frequency and max
transition time parameters were varied from 100 MHz to 1000 MHz and 100 ps to 300 ps respectively. Each heatmap is intended to be read column-wise, where
each column is a histogram. The color intensity within a heatmap column indicates the percentage of (critical-net, trigger-space) pairs, within that column,
that are within a range of distance away. The y-axis reports the distance in terms of standard deviations from the overall mean net-length in each design. The
x-axis reports the trigger space sizes in number of contiguous placement sites. Designs with smaller trigger-spaces and long route distances are more resistant
to fabrication-time attacks. Namely, a heatmap column that is completely dark indicates no (critical-net, trigger-space) pairs, or attack points, and a column
that is completely dark except for the top-most cell is the second most secure.
1e15e11e25e21e35e31e41e51234567Stdev from MeanNet Length50%-100Trans1e15e11e25e21e35e31e41e5123456750%-150Trans1e15e11e25e21e35e31e41e5123456750%-200Trans1e15e11e25e21e35e31e41e5123456750%-250Trans1e15e11e25e21e35e31e41e5123456750%-300Trans0.00.20.40.60.81.01e15e11e25e21e35e31e41e51234567Stdev from MeanNet Length50%-100Trans1e15e11e25e21e35e31e41e5123456750%-150Trans1e15e11e25e21e35e31e41e5123456750%-200Trans1e15e11e25e21e35e31e41e5123456750%-250Trans1e15e11e25e21e35e31e41e5123456750%-300Trans0.00.20.40.60.81.01e15e11e25e21e35e31e41e51234567Stdev from MeanNet Length50%-100Trans1e15e11e25e21e35e31e41e5123456750%-150Trans1e15e11e25e21e35e31e41e5123456750%-200Trans1e15e11e25e21e35e31e41e5123456750%-250Trans1e15e11e25e21e35e31e41e5123456750%-300Trans0.00.20.40.60.81.01e15e11e25e21e35e31e41e5Trigger SpaceSizes1234567Stdev from MeanNet Length50%-100Trans1e15e11e25e21e35e31e41e5Trigger SpaceSizes123456750%-150Trans1e15e11e25e21e35e31e41e5Trigger SpaceSizes123456750%-200Trans1e15e11e25e21e35e31e41e5Trigger SpaceSizes123456750%-250Trans1e15e11e25e21e35e31e41e5Trigger SpaceSizes123456750%-300Trans0.00.20.40.60.81.0Fig. 14. Route Distance Metric for OR1200 at 70% Density. Same as Fig. 13, except a target density of 70% was held across each layout.
1e15e11e25e21e35e31e41e51234567Stdev from MeanNet Length70%-100Trans1e15e11e25e21e35e31e41e5123456770%-150Trans1e15e11e25e21e35e31e41e5123456770%-200Trans1e15e11e25e21e35e31e41e5123456770%-250Trans1e15e11e25e21e35e31e41e5123456770%-300Trans0.00.20.40.60.81.01e15e11e25e21e35e31e41e51234567Stdev from MeanNet Length70%-100Trans1e15e11e25e21e35e31e41e5123456770%-150Trans1e15e11e25e21e35e31e41e5123456770%-200Trans1e15e11e25e21e35e31e41e5123456770%-250Trans1e15e11e25e21e35e31e41e5123456770%-300Trans0.00.20.40.60.81.01e15e11e25e21e35e31e41e51234567Stdev from MeanNet Length70%-100Trans1e15e11e25e21e35e31e41e5123456770%-150Trans1e15e11e25e21e35e31e41e5123456770%-200Trans1e15e11e25e21e35e31e41e5123456770%-250Trans1e15e11e25e21e35e31e41e5123456770%-300Trans0.00.20.40.60.81.01e15e11e25e21e35e31e41e5Trigger SpaceSizes1234567Stdev from MeanNet Length70%-100Trans1e15e11e25e21e35e31e41e5Trigger SpaceSizes123456770%-150Trans1e15e11e25e21e35e31e41e5Trigger SpaceSizes123456770%-200Trans1e15e11e25e21e35e31e41e5Trigger SpaceSizes123456770%-250Trans1e15e11e25e21e35e31e41e5Trigger SpaceSizes123456770%-300Trans0.00.20.40.60.81.0Fig. 15. Route Distance Metric for OR1200 at 90% Density. Same as Fig. 13, except a target density of 90% was held across each layout.
1e15e11e25e21e35e31e41e51234567Stdev from MeanNet Length90%-100Trans1e15e11e25e21e35e31e41e5123456790%-150Trans1e15e11e25e21e35e31e41e5123456790%-200Trans1e15e11e25e21e35e31e41e5123456790%-250Trans1e15e11e25e21e35e31e41e5123456790%-300Trans0.00.20.40.60.81.01e15e11e25e21e35e31e41e51234567Stdev from MeanNet Length90%-100Trans1e15e11e25e21e35e31e41e5123456790%-150Trans1e15e11e25e21e35e31e41e5123456790%-200Trans1e15e11e25e21e35e31e41e5123456790%-250Trans1e15e11e25e21e35e31e41e5123456790%-300Trans0.00.20.40.60.81.01e15e11e25e21e35e31e41e51234567Stdev from MeanNet Length90%-100Trans1e15e11e25e21e35e31e41e5123456790%-150Trans1e15e11e25e21e35e31e41e5123456790%-200Trans1e15e11e25e21e35e31e41e5123456790%-250Trans1e15e11e25e21e35e31e41e5123456790%-300Trans0.00.20.40.60.81.01e15e11e25e21e35e31e41e5Trigger SpaceSizes1234567Stdev from MeanNet Length90%-100Trans1e15e11e25e21e35e31e41e5Trigger SpaceSizes123456790%-150Trans1e15e11e25e21e35e31e41e5Trigger SpaceSizes123456790%-200Trans1e15e11e25e21e35e31e41e5Trigger SpaceSizes123456790%-250Trans1e15e11e25e21e35e31e41e5Trigger SpaceSizes123456790%-300Trans0.00.20.40.60.81.0