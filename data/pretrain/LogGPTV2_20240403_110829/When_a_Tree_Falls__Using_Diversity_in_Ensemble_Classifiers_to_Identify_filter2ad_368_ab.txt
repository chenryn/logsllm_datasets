detectors.
In addition to minimizing the structural artifacts of the
malcode injection, Maiorca et al. make use of PDF encoding,
especially stream compression, to hide the inserted content. For
example, in the PDFembed attack, the malicious document is
embedded in a compressed PDF stream. Detection tools, such
as PDFrate, that do not decompress the PDF streams are not
able to extract features from the embedded malicious PDF.
The Mimicus and Reverse Mimicry attacks use two sep-
arate paths to evade PDFrate. Mimicus uses addition of de-
coy objects that would not be processed by a normal PDF
reader but are parsed by the simple regular expression based
processing of PDFrate. The Reverse Mimicry attacks, on the
other hand, use valid PDF constructs to minimize and hide
malicious indicators. Mimicus operates by adding camouﬂage
while the Reverse Mimicry attack seeks to make the malicious
elements stealthy. Mimicus leverages extensive knowledge of
PDFrate while the Reverse Mimicry approach uses data hiding
techniques peculiar to the PDF ﬁle format.
D. Drebin Android Malware Detector
Ensemble classiﬁer mutual agreement analysis should be
applicable to all situations where evasion is possible, includ-
ing other malware classiﬁers. We evaluated the utility of
mutual agreement analysis on the Drebin Android malware
detector [4]. Drebin complements PDFrate because it operates
on a software package instead of a document and utilizes
many string based features instead of numerical features. Since
the data used in the original Drebin study is available to
researchers, we use this data for our evaluation.
Drebin operates by performing a quick scan to extract fea-
tures from the Android application manifest and disassembled
code. These features are formatted as strings. Features ex-
tracted from the manifest include the names/values of hardware
components, requested permissions, application components,
and intents (message framework). The values of API calls, used
permissions, and network addresses/URLs are taken from the
disassembled code. The string values are mapped into a binary
feature vector containing over 500,000 unique values.
A linear SVM is trained ofﬂine and used to provide weights
(distance from hyperplane) for each feature observed during
classiﬁcation. This per predictor weight is combined to provide
an overall score and compared to a threshold to determine the
outcome. Due to this scheme, Drebin provides a maliciousness
score and can identify variables that contribute to this score.
Drebin is evaluated with over 100,000 benign and 5,000
malicious samples, providing a false positive rate of 1% and
a malware detection rate of nearly 94%.
IV. APPROACH
An ensemble classiﬁer is constructed from many base
classiﬁers. To provide meaningful diversity in the ensemble,
each individual classiﬁer is constructed using mechanisms
such as random sampling (bagging) of training data and
features. Typically, the result is combined by voting, where
each independent classiﬁer gets an equal vote. The count of
votes are summed to generate a score. If the score is over 50%,
then the observation is labeled malicious. Otherwise, the result
is benign.
Ensembles have been shown to improve accuracy in many
use cases, including malware detection. However, we have
found the primary advantage of ensemble classiﬁers to be
that they can provide a measure of internal coherence which
serves as an estimate of the classiﬁer’s conﬁdence of individual
predictions.
In a well preforming ensemble, the majority of individ-
ual classiﬁers provide the same vote. If the base classiﬁers
provide conﬂicting votes,
then the ensemble is in a state
of disagreement and the prediction is less trustworthy. The
agreement or disagreement in voting of individual contributors
in the ensemble provides an estimate of the conﬁdence of the
prediction of the ensemble.
A classiﬁer may not be able to provide an accurate response
for some observations. For example, when a 50/50 vote split
occurs in traditional ensembles, a prediction is provided using
a method such as random selection. Most applications will treat
a randomly selected prediction when the classiﬁer is in total
disagreement the same as one where all contributors vote for
the same class. However, in the case of complete disagreement,
the only reasonable interpretation is that the classiﬁer cannot
make a competent prediction.
Diversity in ensemble classiﬁers is the core attribute that
facilitates mutual agreement based conﬁdence estimates. This
diversity is caused by extrapolation in individual classiﬁers.
Barring limitations of the classiﬁer scheme and quality of
features, when an observation is close to samples in the
training set, the classiﬁcation is well supported and should
be accurate. However, as new observations diverge farther
from training samples, the classiﬁer is forced to extrapolate.
For ensemble classiﬁers which employ bagging effectively, the
farther new observations are from classiﬁer training, the more
disagreement there will be in the ensemble.
This diversity in extrapolation is observed in the Random
Forest based classiﬁers used in PDFrate. Table I shows the
classiﬁcation performance of the ﬁrst 25 trees (out of 1000)
in the Contagio classiﬁer applied to various mimicry attacks.
Performance is reported relative to the forest average number
of votes for the correct class, dividing at ± 0.5 standard devia-
tions. It is observed that the vast majority of the trees have all
4
TABLE I.
RELATIVE PERFORMANCE OF INDIVIDUAL TREES IN CONTAGIO CLASSIFIER INDICATED AS ABOVE (+), BELOW (-), OR WITHIN (0) 0.5
STANDARD DEVIATIONS OF FOREST AVERAGE
Individual Tree Performance
Evasion Scenario
F mimicry
FC mimicry
FT mimicry
FTC mimicry
F gdkde
FT gdkde
JSinject
PDFembed
EXEembed
0
+
0
-
-
+
+
0
-
+
+
+
+
+
+
-
-
0
+
+
+
+
+
+
-
-
0
-
-
-
-
+
+
0
+
-
0
+
-
0
+
0
+
0
-
0
0
0
+
+
+
+
0
-
-
-
0
0
-
-
-
0
+
+
+
+
-
-
-
0
-
0
0
0
0
-
+
+
+
-
+
+
+
0
+
+
+
+
-
0
TABLE II.
ENSEMBLE CLASSIFIER OUTCOMES
Voting Score
[0,25]
(25,50)
[50,75)
Outcome
Benign
Uncertain
[75, 100 ] Malicious
(Benign)
(Malicious)
Evasion Type
Strong Evasion
Weak Evasion
No Evasion
-
-
-
0
0
+
+
-
-
0
-
0
-
0
-
0
+
-
+
+
0
+
+
+
0
+
-
-
0
0
0
-
+
+
-
+
+
0
+
+
+
-
0
-
0
0
0
-
+
-
-
0
-
+
0
0
-
-
-
-
0
-
-
0
0
0
+
+
0
+
-
-
-
0
0
0
-
-
-
0
+
+
+
+
+
+
0
0
-
+
+
+
+
-
0
-
+
-
-
+
+
0
+
-
+
-
-
0
+
0
0
0
-
+
0
-
0
-
-
-
-
-
-
+
+
-
-
-
0
0
0
0
-
-
-
three outcomes depending upon the evasion scenario: average
(0), below average (-), and above average (+). Hence, when
applied to data distant from the training data, the accuracy of
each tree varies widely between observations. There are no
universally strong or weak trees. The random noise present
when extrapolating far from the training data is what enables
mutual agreement analysis.