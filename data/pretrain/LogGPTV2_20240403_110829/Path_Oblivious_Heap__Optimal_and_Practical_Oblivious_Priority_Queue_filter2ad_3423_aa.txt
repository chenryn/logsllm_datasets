title:Path Oblivious Heap: Optimal and Practical Oblivious Priority Queue
author:Elaine Shi
2020 IEEE Symposium on Security and Privacy
Path Oblivious Heap: Optimal and Practical
Oblivious Priority Queue
Elaine Shi, Cornell University, PI:EMAIL
Abstract—We propose Path Oblivious Heap, an extremely
simple, practical, and optimal oblivious priority queue. Our
construction also implies a practical and optimal oblivious sorting
algorithm which we call Path Oblivious Sort. Not only are our
algorithms asymptotically optimal, we show that their practical
performance is only a small constant factor worse than insecure
baselines. More speciﬁcially, assuming roughly logarithmic client
private storage, Path Oblivious Heap consumes 2× to 7× more
bandwidth than the ordinary insecure binary heap; and Path
Oblivious Sort consumes 4.5× to 6× more bandwidth than the
insecure Merge Sort. We show that these performance results
improve existing works by 1-2 orders of magnitude. Finally, we
evaluate our algorithm for a multi-party computation scenario
and show 7× to 8× reduction in the number of symmetric
encryptions relative to the state of the art1.
I. INTRODUCTION
We show how to construct a statistically secure oblivious
priority queue through a simple modiﬁcation to the (non-
recursive) Path ORAM algorithm [39]. Since our construction
is compellingly simple, we begin the paper by presenting the
construction informally. Let N denote the maximum number
of items the priority queue can store. Imagine a binary tree
with N leaves, where each non-root node in the tree can
hold O(1) records that are either real or dummy, and the root
node can hold super-logarithmically (in the security parameter)
many records. Every real element in the tree carries its own
position label, which ties the element to a path in the tree. For
readers familiar with Path ORAM [39], so far the data structure
is the same as a Path ORAM binary tree. Our key insight is
the following (which, in hindsight, turns out to be surprisingly
simple): we additionally tag each node in the tree with the
minimum element in its subtree (henceforth called a subtree-
min) as well as its position label. Observe that whenever a
path in the tree is modiﬁed, it takes only path-length amount
of work to modify the subtree-min of all nodes along the path
— to do this we only need to examine this path and all sibling
nodes to the path. We can support Insert and ExtractMin
queries as follows:
• Insert: to insert an item, assign it a random position
label that ties the element to a random path in the tree.
Add the item (tagged with its position label) to the root
bucket. Perform eviction on two randomly selected paths
(that are non-overlapping except at the root). An eviction
operation tries to move real elements on the path closer to
the leaf (while making sure that every element still resides
on the path it is assigned to). Recalculate the subtree-mins
of the two eviction paths.
• ExtractMin: by examining the root node’s subtree-
min, ﬁnd out which path the minimum element resides
in. Read that path, remove the minimum element from
the path and save it in the CPU’s local cache. Perform
eviction on the path just read, and moreover, recalculate
the subtree-mins of the path just read.
We stress that due to subtree-min labels that our algorithm
maintains throughout, there is no need for a recursive position
map which was necessary in previous tree-based ORAMs [11],
[39], [42] and oblivious data structures [44] — one can easily
ﬁnd out the path of the minimum element by examining the
root’s subtree-min label.
Other types of requests, such as Delete, DecreaseKey,
and IncreaseKey can be supported in a similar manner.
We can additionally hide the request type by emulating the
super-set of access patterns for all requests. Since each request
always operates on at most two paths in a binary tree, we call
our construction Path Oblivious Heap.
Theorem 1 (Path Oblivious Heap). Assume that each
memory word is at
log N bits and every item in
the priority queue can be stored in O(1) words. Fur-
ther, suppose that
δ ) words
of private cache. There exists a statistically secure oblivi-
ous priority queue algorithm that supports each operation
in the set {Insert, ExtractMin, Delete, DecreaseKey,
IncreaseKey} requiring only O(log N ) words to be trans-
mitted between the CPU and the memory per operation, where
N denotes the maximum number of elements the priority queue
can store, and δ denotes the failure probability per request.
the CPU has O(log N + log 1
least
Readers familiar with tree-based ORAM constructions
might also recall that Circuit ORAM [42] is a further improve-
ment to Path ORAM [39]: in Circuit ORAM, the CPU needs
only O(1) words of private cache whereas in Path ORAM,
the CPU needs O(log N + log 1
δ ) words of private cache.
The only difference between Circuit ORAM and Path ORAM
is that the two adopt a different path-eviction algorithm. If
we instantiated the above Path Oblivious Heap algorithm but
now with Circuit ORAM’s eviction algorithm, we obtain the
following corollary which further reduces the CPU’s private
cache to O(1):
Corollary 2 (Path Oblivious Heap: Circuit Variant). Same as
Theorem 1, but now the CPU needs only O(1) words of private
cache and each request consumes O(log N +log 1
δ ) bandwidth.
1The online full version is available at https://eprint.iacr.org/2019/274.
Henceforth to distinguish the two variants instantiated with
© 2020, Elaine Shi. Under license to IEEE.
DOI 10.1109/SP40000.2020.00037
842
Authorized licensed use limited to: Auckland University of Technology. Downloaded on November 03,2020 at 00:37:42 UTC from IEEE Xplore.  Restrictions apply. 
Path ORAM and Circuit ORAM’s eviction algorithms respec-
tively, we call them the Path-variant and the Circuit-variant re-
spectively2 From a theoretical perspective, the Circuit-variant
is a strict improvement of the Path-variant — if the CPU
had O(log N + log 1
δ ) private cache in the Circuit-variant, the
bandwidth needed per request would also be O(log N ) just
like the Path-variant.
Optimality. Path Oblivious Heap outperforms existing works
both in asymptotic and concrete performance, and moreover
achieves optimality in light of the recent lower bound by
Jacob et al. [24]. We recommend the Path-variant for a cloud
outsourcing scenario, and the Circuit-variant for RAM-model
multi-party computation [23], [30] — recall that these are the
two primary application scenarios for oblivious algorithms.
The overhead of our scheme relative to an insecure binary
heap (which is the most widely adopted priority queue imple-
mentation) is minimal: binary heap requires fetching a single
tree path of length log N (as well as all sibling nodes) where
each node stores a single data item. Assuming that the CPU
has enough local cache to store an entire tree path, our scheme
requires fetching only 2 paths per request but each node in the
tree now stores 2 items.
Reference implementation. A reference implementation (cre-
ated by Daniel Rong and Harjasleen Malvai) is available at
https://github.com/obliviousram/PathOHeap.
A. Applications
Oblivious streaming sampler and applications in dis-
tributed differential privacy. In Section V-B, we show how
to leverage our Path Oblivious Heap algorithm to design
an efﬁcient oblivious streaming sampler, i.e., an algorithm
that randomly samples k elements from an incoming stream
of a-priori unknown length (possibly much larger than k),
consuming at most O(k) memory; moreover, the algorithm’s
access patterns do not reveal which elements in the stream
have been sampled. We describe how this oblivious sampler
can be a key building block in designing an intereseting
class of distributed differential privacy mechanisms motivated
by practical scenarios that companies such as Google and
Facebook care about.
Practical oblivious sort. Last but not the least, our work
immediately implies a practical and optimal oblivious sort
algorithm which we call Path Oblivious Sort, which can sort
N elements in N (log N + log 1
δ ) time and IO with probability
1−δ. Our new Oblivious Sorting algorithm can replace bitonic
sort [6] which is the de facto choice for implementation
today despite being non-optimal and consuming O(n log2 n)
cost [30], [32], [33] — see Section I-B for more discussions.
Evaluation results suggest that in a cloud-outsourcing set-
ting, our oblivious heap and oblivious sorting algorithms
2The title of our paper calls both the Path-variant and the Circuit-variant
“Path Oblivious Heap” generically since in both variants, every request
operates on O(1) number of tree-paths.
consume only a small constant factor more bandwidth rela-
tive to insecure baselines. Speciﬁcally, Path Oblivious Heap
consumes only 2× to 7× more bandwidth than the ordinary
insecure binary heap; and Path Oblivious Sort consumes only
4.5× to 6× more bandwidth than the insecure Merge Sort.
B. Related Work
Oblivious RAMs. Oblivious RAM (ORAM) was ﬁrst pro-
posed by Goldreich and Ostrovsky [19], [20] in a ground-
breaking work. They show that any RAM algorithm can be
compiled to an oblivious counterpart whose memory access
patterns leak no information, and somewhat surprisingly, such
oblivious compilation incurs only poly-logarithmic (multi-
plicative) blowup relative to the insecure baseline. Subsequent
works have improved Goldreich and Ostrovsky’s construction;
to date the best known ORAM algorithm achieves O(log N )
blowup where N is the size of memory consumed by the
original RAM [4]. On the other hand it has been shown that
logarithmic overhead is necessary for ORAMs [19], [20], [27].
Oblivious data structures. Since ORAM is a generic tech-
nique that compiles any algorithm or data structure to an
oblivious form, a na¨ıve way to obtain an oblivious priority
queue is to apply an ORAM compiler to a standard insecure
priority queue algorithm such as the widely-adopted binary
heap. Although in theory this achieves logarithmic slowdown
w.r.t. the insecure binary heap [4], the known theoretical opti-
mal construction, OptORAMa [4], is completely impractical.
A couple recent works have shown how to construct practi-
cal oblivious priority queues that enjoy logarithmic slowdown
w.r.t.
to the insecure binary heap. Speciﬁcally, Toft [40]
constructs an oblivious priority queue with O(log2 N ) cost per
request (c.f. binary heap requires O(log N ) cost per request).
Wang et al. [44] show a more practical construction where
each request can be completed in O(log N (log N + log 1
δ ))
time and bandwidth (measured in words transmitted between
the CPU and memory).
An interesting question is whether we can outperform
generic ORAM simulation for constructing an oblivious prior-
ity queue. Note that the ORAM lower bound applies only to a
generic oblivious compiler, but not for any speciﬁc algorithm
such as priority queue. The very recent work of Jafargholi et
al. [25] was ﬁrst to answer this question afﬁrmatively: they
showed how to construct an oblivious priority queue where
each request completes in amortized O(log N ) bandwidth,
but requiring O(log 1
δ ) words of CPU cache. In another very
recent work, Jacob et al. [24] prove that any oblivious priority
queue must incur Ω(log N ) bandwidth per request even when
the CPU can store O(N ) words in its private cache where
0 <  < 1 is an arbitrary constant.
Comparison with Jafargholi et al. [25]. Since the very recent
work by Jafargholi et al. [25] is the most closely related, we
now provide more detailed comparison with them. Theoreti-
cally, on a standard word-RAM, our result is asymptotically
better than theirs since we require only O(1) words of CPU
Authorized licensed use limited to: Auckland University of Technology. Downloaded on November 03,2020 at 00:37:42 UTC from IEEE Xplore.  Restrictions apply. 
843
private registers where Jafargholi et al. [25] requires super-
logarithmic in the security parameter to get negligible failure
probability (also in the security parameter). In practical cloud-
like scenarios, our evaluation results in Section VI suggest that
our algorithm is at least an order of magnitude faster than
theirs. Furthermore, our overhead notion is measured in terms
of the worst-case cost per request where they use an amortized
notion — in their scheme, a request can in the worst case incur
linear cost (although this happens infrequently).
Nonetheless Jafargholi et al. [25]’s algorithm is theoretically
interesting in the following senses. First, their algorithm has
asymptotically better IO performance when the memory’s
native block size is much larger than a single entry stored in
the priority queue. Speciﬁcally, imagine that one must pay the
cost of a single big block even when retrieving, say, one entry,
which is much smaller than the memory block. In this case,
Jafargholi et al. [25] achieves an additional factor of χ speedup
relative to ours assuming each memory block can store χ
entries. While this metric is theoretically interesting, it has
limited relevance to the two primary applications for oblivious
priority queue and oblivious sorting: 1) cloud outsourcing and
2) secure multi-party computation:
• In a practical cloud-outsourcing scenario, typically the
main bottleneck is the client-server bandwidth and not
the server’s disk IO. Observe that the client-server trans-
mission is not bound to any “native block” constraint
For example, our algorithm retrieves a couple tree paths
at a time, and one could combine these paths into one or
more network packets (even though the buckets fetched
are not necessarily contiguous in physical storage). For
this reason, almost all prior ORAM schemes designed for
the client-server setting [22], [34], [35], [38], [45] focus
on measuring the bandwidth consumption.
• In multi-party computation [23], [42], similarly, there
is no “native block size” constraint. In this case, a
word-RAM model with O(1) CPU registers is the most
appropriate as prior works have compellingly shown [42].
Another theoretically interesting aspect of their construction
is that it can be instantiated with a k-wise independent hash
function, and thus fewer random bits need to be consumed
per request. In comparison, our construction consumes loga-
rithmically many random bits per request.
Oblivious sorting. Theoretically speaking, n items can be
obliviously sorted in O(n log n) time using sorting networks
such as AKS [3] and Zigzag sort [21]. These constructions are
optimal: due to recent lower bounds [16], [29], we know that
any oblivious sorting scheme must incur Ω(n log n) time on
a word-RAM, either assuming that the algorithm treats each
element as “indivisible” [29] or assuming that the famous Li-
Li network coding conjecture [28] is true [16].
Unfortunately, known optimal sorting networks [3], [21]
rely on expander graphs and thus suffer from enormous
constants, making them completely impractical. Almost all
known implementations of oblivious sorting, either for cloud-
outsourcing [12],