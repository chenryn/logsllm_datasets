match multiple of these speciﬁc values in all those bins. For example, if the rules
are divided by destination port, then a rule that matches ‘any’ destination
port is included in all of those bins. This ensures that when a set of rules with
a speciﬁc value for a protocol ﬁeld are picked, other applicable rules are also
matched with the packet. This is essential for correctness. Generally a rule with
value vj for a protocol ﬁeld is included in a rule set with speciﬁc value vi if
vj ∩ vi (cid:5)= 0. If there is an order in which the values are checked during run-time,
then a rule vj is included in vi only if it appears before it, and if it satisﬁes the
previous property.
Packets rejected by a protocol ﬁeld may correlate with packets rejected by
another protocol ﬁeld, and so computing protocol ﬁelds independently may give
misleading information. For example, a source port and a source IP address
may reject exactly the same packets, in which case we do not gain anything by
checking both of them. Our recursive splitting of a bin removes this problem of
correlated values. This is because for a bin, we evaluate the beneﬁt of remain-
ing protocol ﬁelds only on those packets that match the values speciﬁed in the
bin. For example, to split a bin containing port-80 rules, we only evaluate the
302
S. Sinha, F. Jahanian, and J.M. Patel
remaining protocol ﬁelds on packets that have port 80. This ensures that the
remaining protocol ﬁelds reject only the rules that were not rejected by port 80.
By choosing the protocol ﬁeld that produces maximum beneﬁt for each bin,
we get an order in which the protocol ﬁeld is checked for a packet. By choosing
values that produce beneﬁt above a threshold, we get the values that determines
which groups should be maintained.
Implementation. We implemented two distinct components to develop a work-
load-aware Intrusion Detection System. The ﬁrst component proﬁles the work-
load (i.e., the input rules and the live traﬃc) to generate the evaluation tree.
The second component takes the evaluation tree, pre-processes the rules, and
matches any incoming packet on the tree. These components are general enough
to be applied to any IDS. We implemented our algorithm that generates an eval-
uation tree for a given workload over Snort 2.1.3. We chose Snort as it already
provides an interface to read the rules into proper data structures. It also pro-
vides an interface to read the incoming traﬃc and check for diﬀerent protocol
ﬁelds.
As a second component, we modiﬁed Snort 2.1.3 to take the bin proﬁles and
construct a hierarchical evaluation plan. Snort 2.0 [14] introduced an interface for
parallel evaluation of rules on a packet. Our hierarchical evaluation tree provides
the set of applicable rules for a packet according to its values for diﬀerent protocol
ﬁelds. We pre-computed the data structure required for parallel matching for
each of these groups. For every packet, we used our evaluation tree to determine
the set of applicable rules and allowed Snort to perform the evaluation. We
implemented three protocol ﬁelds by which the hierarchical structure can be
constructed, namely: destination port, source port, destination IP address, and
whether the packet is from the client. Since rules contain a large number of
distinct protocol ﬁelds and we want to immediately detect the applicable rules,
we implemented a check for destination port using an array of 65,536 pointers.
Source port and destination IP address was checked by looking for possible match
in a linked list. We did this because only a few destination IP addresses/source
ports have to be checked, and because maintaining a pointer for each speciﬁc
value consumes signiﬁcant memory. For client checks the rules were divided into
two parts: those that required to check if the packet is coming from client, and
the rest were others. Every time a bin was split, we ensured that a rule was
included in all new bins whose speciﬁc value can match the value in the rule.
This ensured the correctness of our approach. We also validated our system by
matching the number of alerts that our system raises, when compared to the
number of alerts raised by unmodiﬁed Snort on a large number of datasets.
4 Evaluation
In this section, we evaluate Wind on a number of publicly-available datasets and
on traﬃc from a border router at a large academic network. On these datasets, we
compared real-time performance of Wind with existing IDSs using two important
metrics: the number of packets processed per second and the amount of memory
WIND: Workload-Aware INtrusion Detection
303
consumed. To measure the number of packets processed per second, we compiled
our system and the unmodiﬁed Snort with gprof [21] options and then evaluated
the dataset with each one of them. Then we generated the call graph, using
gprof, and examined the overall time taken in the Detect function, which is
the starting point of rule application in Snort. Finally, using the time spent
in Detect and the number of times it was called, we computed the number of
packets processed per second. To compute the memory used, we measured the
maximum virtual memory consumed during the process execution by polling
each second the process status and capturing the virtual memory size of the
process. We now describe the datasets and the computing systems that we used
for our experiments.
4.1 Datasets and Computing Systems
We evaluated the performance of our system on a number of publicly-available
datasets and on traﬃc from a large academic network. For publicly available
datasets, we used traces that DARPA and MIT Lincoln Laboratory have used
for testing and evaluating IDSs. We used two-week testing traces from 1998 [22],
and two-week testing traces from 1999 [23]. This gave us 20 diﬀerent datasets
with home network 172.16.0.0/12. For evaluating the system on real-world, live
traﬃc, we chose a gateway router to a large academic network with address
141.212.0.0/16. This router copies traﬃc from all ports to a span port, which
can be connected to a separate machine for analyzing the traﬃc.
For DARPA dataset experiments, we used a dual 3.06 GHz Intel Xeon machine
with 2 GB of main memory. The machine was running FreeBSD 6.1 with SMP
enabled. We connected the span port of the gateway router to a machine with
dual 3.0 GHz Intel Xeon processors and 2GB of main memory. The machine was
running FreeBSD 5.4 with SMP enabled. The results that follow are the averages
over 5 runs and with the THRESHOLD value set to 5.
4.2 Processing Time and Memory Usage
We compared Wind with Snort 2.1.3 for all rules included with the distribution.
There were 2, 059 diﬀerent rules, and both Wind and Snort were run using default
conﬁguration. Figure 5 shows the amount by which we improved the number of
packets processed per second by Snort. For most datasets, we ﬁnd that our
system processes up to 1.6 times as many packets as Snort. We also compared
the memory used by our system with that of Snort. Figure 6 shows the memory
saved by our system when compared to Snort. We ﬁnd that our system uses
about 10-20% less memory when compared to the unmodiﬁed Snort. In other
words, we perform up to 1.6 times better in processing time and save 10-20% of
the memory.
Wind and Snort were run on the border router for analyzing a million packets
at a few discrete times in the week. Figure 7 shows the amount by which Wind
improved the number of packets processed per second by Snort. It shows that
the improvement factor on this dataset varied from 1.35 to 1.65. During the
runs, Wind consumed 10-15% less memory than Snort.
304
S. Sinha, F. Jahanian, and J.M. Patel
Factor improvement in number of packets processed per second
 1
 1.1
 1.2
 1.3
 1.4
 1.5
 1.6
 1.7
 1.8
98-test-w1-mon
98-test-w1-tue
98-test-w1-wed
98-test-w1-thu
98-test-w1-fri
98-test-w2-mon
98-test-w2-tue
98-test-w2-wed
98-test-w2-thu
98-test-w2-fri
99-test-w4-mon
99-test-w4-tue
99-test-w4-wed
99-test-w4-thu
99-test-w4-fri
99-test-w5-mon
99-test-w5-tue
99-test-w5-wed
99-test-w5-thu
99-test-w5-fri
Fig. 5. Factor improvement, in terms of number of packets processed per second, when
compared to Snort for the 1998 and 1999 DARPA testing datasets
 0
 5
 10
 15
 20
percentage of memory saved
98-test-w1-mon
98-test-w1-tue
98-test-w1-wed
98-test-w1-thu
98-test-w1-fri
98-test-w2-mon
98-test-w2-tue
98-test-w2-wed
98-test-w2-thu
98-test-w2-fri
99-test-w4-mon
99-test-w4-tue
99-test-w4-wed
99-test-w4-thu
99-test-w4-fri
99-test-w5-mon
99-test-w5-tue
99-test-w5-wed
99-test-w5-thu
99-test-w5-fri
Fig. 6. Percentage of memory saved for each of the 1998 and 1999 DARPA datasets,
when compared to Snort
WIND: Workload-Aware INtrusion Detection
305
Factor improvement in number of packets processed per second
 1
 1.1
 1.2
 1.3
 1.4
 1.5
 1.6
 1.7
Factor improvement in number of packets processed per second
 1
 1.2
 1.4
 1.6
 1.8
 2
 2.2
 2.4
 2.6
Sat-evening-04/02
Sun-evening-04/02
Mon-afternoon-04/03
Mon-evening-04/03
Tue-afternoon-04/04
Tue-evening-04/04
Sat-evening-04/02
Sun-evening-04/02
Mon-afternoon-04/03
Mon-evening-04/03
Tue-afternoon-04/04
Tue-evening-04/04
Fig. 7. Factor improvement in number of
packets processed per second, when com-
pared to Snort, on data from a border
router in an academic network
Fig. 8. Factor improvement in number of
packets processed per second, when com-
pared to Snort, for web-based rules. These
experiments were on traﬃc from a border
router at an academic network.
Factor improvement in number of packets processed per second
 1
 1.2
 1.4
 1.6
 1.8
 2
 2.2
 2.4
 2.6
 2.8
98-test-w1-mon
98-test-w1-tue
98-test-w1-wed
98-test-w1-thu
98-test-w1-fri
98-test-w2-mon
98-test-w2-tue
98-test-w2-wed
98-test-w2-thu
98-test-w2-fri
99-test-w4-mon
99-test-w4-tue
99-test-w4-wed
99-test-w4-thu
99-test-w4-fri
99-test-w5-mon
99-test-w5-tue
99-test-w5-wed
99-test-w5-thu
99-test-w5-fri
Fig. 9. Factor improvement in number of packets processed per second by Wind when
compared to Snort for web-based rules. The datasets include the 1998 and 1999 DARPA
intrusion detection datasets.
4.3 Application-Speciﬁc Rules
Until now, all our experiments were conducted by enabling all rules that came
with the Snort distribution. However, in many networks, only application-speciﬁc
rules can be used. For example, in many enterprise networks, the only open
306
S. Sinha, F. Jahanian, and J.M. Patel
access through the ﬁrewall is web traﬃc. Since web traﬃc forms the dominant
application allowed in many networks, we compared our system with Snort for
web-based rules 2. Figure 8 shows the magnitude by which our system improves
Snort, in the terms of number of packets processed per second, for traﬃc at
the border router. We found that for web-based rules, our system improves
performance by more than two times when compared to Snort. Figure 9 shows
a similar graph for the DARPA datasets. We observed that Wind outperforms
Snort by a factor of up to 2.7 times. In this case, we saved 2-7% of the memory
when compared to Snort.
4.4 Variation with Threshold
In order to investigate how the threshold aﬀects the performance of our system,
we evaluated the DARPA dataset, 98-test-w1-mon, for diﬀerent values of the
threshold. Figure 10 shows the performance variation of our system with the
increasing threshold. As expected, the performance of the system decreases with
increasing cost assigned by threshold. However, we ﬁnd that the changes are
more pronounced only for lower threshold values. We ﬁnd that the memory saved
by our system increases with increasing threshold values, signiﬁcantly only for
lower threshold values. Therefore, we ﬁnd that increasing the threshold reduces
performance, but saves more memory, and this diﬀerence is more pronounced
for lower threshold values.
.
c
e
s
r
e
p
s
t
e
k
c
a
p
f
o
r
e
b
m
u