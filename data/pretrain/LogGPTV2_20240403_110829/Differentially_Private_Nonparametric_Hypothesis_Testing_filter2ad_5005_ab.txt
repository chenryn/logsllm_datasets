Lap(x|b) =
1
2b
We write Lap(b) to denote the Laplace distribution with scale b.
The scale of the Laplace Distribution used to produce the noisy
output depends on the global sensitivity of the given algorithm f ,
which is the maximum change on the output of f that could result
from the alteration of a single row.
Definition 2.6 (Global sensitivity). The global sensitivity of a
function f is:
| f (x) − f (x′)|,
where x and x′ are neighbouring databases.
GSf = max
x,x′
With computed sensitivity GSf and privacy parameter ϵ, the
Laplace mechanism applied to f ensures (ϵ, 0)-differential privacy
[9].
Definition 2.7 (Laplace Mechanism). Given any function f , the
Laplace mechanism is defined as:
˜f (x) = f (x) + Y ,
where Y is drawn from Lap(GSf /ϵ), and GSf is the global sensitivity
of f .
Theorem 2.8. (Laplace Mechanism) The Laplace mechanism pre-
serves (ϵ, 0) differential privacy.
Global sensitivity is the maximum effect that can be caused by
changing a single row of any database. Sometimes it is helpful
to talk about local sensitivity for a given database x [21]. This is
the maximum effect that can be caused by changing a row of that
particular database.
Definition 2.9 (Local Sensitivity). The sensitivity of a function f
at a particular database x is:
LSf (x) = max
x′
| f (x) − f (x′)|,
where x′ is a neighboring database.
Note that GSf = maxx LSf (x). Local sensitivity cannot simply be
used in the Laplace mechanism in place of global sensitivity, because
local sensitivity itself is a function of the database and therefore
cannot be released. But private upper bounds on local sensitivity
can be used to create similar mechanisms that do preserve privacy,
and one of our algorithms uses just such a technique.
Choosing ϵ is an important consideration when using differen-
tial privacy. We consider several values of ϵ throughout our power
analyses. The lowest, .01 is an extremely conservative privacy pa-
rameter and allows for safe composition with many other queries
of comparable ϵ value. We also use ϵs of .1 and 1, which, while
higher, still provide very meaningful privacy protection. Ultimately,
the choice of ϵ is a question of policy and depends on the relative
importance with which privacy and utility are regarded. We also
measure, for comparison, the power of the public versions of each
test (equivalent to an ϵ of ∞). As one might expect, the amount of
data needed to detect a given effect often scales roughly with the
inverse of ϵ.
2.3 Differentially Private Hypothesis Testing
Performing hypothesis tests within the framework of differential
privacy introduces new complexity. A function to compute a private
test statistic (be it a private version of a standard test statistic or an
entirely new test statistic) is not useful on its own. We need a p-value
or other understandable output, and that means understanding the
reference distribution (i.e., the distribution of the statistic given
H0).
In classical statistics, test statistics are computed with determinis-
tic functions. The randomness added to the test statistic in order to
privatize it introduces new complexity. Most importantly, it causes
the reference distribution to change. One cannot simply compare
the private test statistic to the usual reference distribution, as the
addition of noise can inflate the type I error well above acceptable
levels [3].
Because of this, a complete differentially private hypothesis test
requires not only a function for computing a private test statistic,
but also a method for determining its null distribution. Often the
exact reference distribution cannot be determined, so worst-case
reference distributions or upper bounds on the resulting critical
value must be used, and the precision of this reference distribution
can have a large effect on the resulting power.
The goal of differentially private hypothesis test design is to
develop a test with power as close as possible to the public test.
2.4 Related Work
There is a substantial and growing literature on differentially private
hypothesis testing. One area of research is the study of the rate
of convergence of private statistics to the distributions of their
public analogues [25, 26, 34]. These papers do not offer practical,
implementable tests and discussion of reference distributions when
the noise is not yet negligible is often limited or entirely absent.
Further, the results are often entirely asymptotic, without regard
for constants that may prove to be problematic.
The chi-squared test, which tests the independence of two cat-
egorical variables,4 has been the subject of much study, resulting
in the development of many private variants. One of these works,
that of Vu and Slavkovic [32], provides methods for calculation
of accurate p-values adjusted for the addition of Laplace noise for
differentially private single proportion and chi-squared tests specif-
ically for clinical trial data. Several other papers, though they make
asymptotic arguments on the uniformity of their p-values, have de-
veloped frameworks for private chi-squared tests specifically for the
intent of genome-wide association study (GWAS) data [11, 15, 31].
For these same tests, Monte Carlo simulation has been shown to
offer more precise analysis in some cases [12, 33]. There has also
been work, like that of Rogers and Kifer [23], that proposes entirely
new test statistics with asymptotic distributions more similar to
their public counterparts.
While the development of private test statistics has achieved
much attention, careful evaluations of statistical power of these
new test statistics is not always demonstrated. This is unfortunate,
as the cost of privacy (utility loss) must be accurately quantified
in order for the widespread adoption or implementation of any
of these methods. Fortunately, rigorous power analysis seems to
be more common in recent work. Awan and Slavkovic recently
presented a test for simple binomial data [1]. While the setting is
the simplest possible, their paper gives what we believe is the first
private test to come with a proof of optimality, something normally
very difficult to achieve even in the public setting.
The body of work on numerical (rather than categorical) meth-
ods is less extensive but has been growing quickly in recent years.
In 2017, Nguyen and Hui proposed algorithms for survival analysis
methods [20]. There have been frameworks developed for testing
the difference in means of normal distributions [6, 7], and for test-
ing whether a sample is consistent with a normal distribution with
a particular mean [27]. Differentially private versions of linear re-
gressions, a class of inference that is extremely common in many
fields both within and outside of academia, have received a notable
level of attention, but the treatment of regression coefficients as
test statistics has come about only recently [2, 24]. Two works have
studied differentially private versions of one-way analysis of vari-
ance (ANOVA) [3, 28]. The only prior work done on nonparametric
hypothesis tests, as far as we are aware, is on the Wilcoxon signed-
rank test by Task and Clifton in 2016 [30]. Prior work specifically
relevant to the tests we are proposing will be discussed in more
detail in the relevant section.
3 MANY GROUPS
We first consider the most general case, where we wish to dis-
tinguish whether many groups share the same distribution on a
continuous variable. The standard parametric test in the public
setting is the one-way analysis of variance (ANOVA), which tests
the equality of means across many groups. Private ANOVA has
been studied previously first by Campbell et al. [3] and then by
4This is the chi-squared test of independence. There are several related tests that use
the same statistic, the chi-squared.
Swanberg et al. [28], who improved the power by an order of mag-
nitude. The standard nonparametric test in the public setting is the
Kruskal-Wallis test, which was used by the pschosis research group
to determine that subjects in the schizophrenia, bipolar, and control
groups had different methylation levels at a particular gene site[4].
As is standard for nonparametric statistics in the public setting, it
sacrifices some power compared to ANOVA but no longer assumes
normally distributed data. [10]
In this section we present two tests. The first is a straightfor-
ward privatization of the standard Kruskal-Wallis test statistic. The
second modifies the statistic, essentially by linearizing the implied
distance metric. We find first that our modified statistic has much
higher power. We then further show that our modified statistic has
much higher power than the ANOVA test of Swanberg et al. even
when the data is normally distributed.
3.1 The Kruskal-Wallis test
The Kruskal-Wallis test, proposed by William Kruskal and W. Allen
Wallis in 1952 [17], is used to determine if several groups share the
same distribution in a continuous variable. The only assumptions
are that the data are drawn randomly and independently from a
distribution with at least an ordinal scale.
Take a database x with д groups5 and n rows. Let ni be the size
th element of group i. (If
of each group and rij be the rank of the j
values are equal for several elements, all are given a rank equal to
the average rank for that set.) We define ¯ri to be 1
j=1 rij, the
ni
mean rank of group i, and ¯r to be n+1
2 , the average of all the ranks.
Then, the Kruskal-Wallis h-statistic is defined to be
ni
If there are no ties in the database, the denominator is constant and
the formula can be simplified to
д
i =1ni
д
д
h = (n − 1)
i =1 ni(¯ri − ¯r)2
j=1(rij − ¯r)2 .
12
i − 3(n + 1).
2
ni ¯r
h =
n(n + 1)
i =1
For clarity and consistency with later sections, we present this
calculation as an algorithm. In general we use a subscript “stat” to
label the algorithm computing a test statistic and a subscript “p”
to denote the fully hypothesis test that outputs a p-value. We use
tildes to indicate private algorithms.
Algorithm KWstat : Kruskal-Wallis Test Statistic
Input: x
for group i of x do
j =1 rij
i =1 ni ¯ri − 3(n + 1)
¯ri ←−(cid:16)ni
n(n+1)д
(cid:17)/ni
h ←− 12
Output: h
5Throughout the paper we assume д is public and independent of the data, so we do
not list it as a separate input. Because д is the number of valid groups, one or more of
the д groups might not contain any observations. Allowing many valid groups that
have no actual observations artificially increases the critical value, so it can reduce the
power of our tests but does not affect the validity or privacy of the output.
3.2 Privatized Kruskal-Wallis
In this section, we bound the sensitivity of KWstat, allowing us to
create a private version. We then present a complete algorithm for
calculating a p-value and prove that it too is differentially private.
We begin with the following sensitivity claim (see the the full
version for the proof).
(cid:17)
Input: x, ϵ, z
(cid:16)87/ϵ
for k = 1 to z do
Theorem 3.1. The sensitivity of KWstat is bounded by 87.
We are using the simplified formula that assumes there are no
ties in the data, so our algorithm begins by adding a small amount
of random noise to each data point to randomly order any ties. We
may then compute the h-statistic as in the public setting and add
noise proportional to the sensitivity.
Input: x, ϵ
Rank all data points, randomly breaking ties
h ←− KWstat(x)
Algorithm(cid:103)KWstat : Private Kruskal-Wallis Test Statistic
(cid:101)h ←− h + Lap
Output:(cid:101)h
Theorem 3.2. Algorithm(cid:103)KWstat is ϵ-differentially private.
Algorithm(cid:103)KWp : Complete Kruskal-Wallis Test
(cid:101)h ←−(cid:103)KWstat(x, ϵ)
hk ←−(cid:103)KWstat(x∗);
p ←− fraction of hk values greater than(cid:101)h
Output:(cid:101)h, p
Algorithm(cid:103)KWp is our complete algorithm to find a p-value given
a database x, privacy parameter ϵ. First a private test statistic(cid:101)h
x∗ ←− a database with independent uniform values from
[0,1], divided almost equally into д groups
See the full version for the proof.
is computed. Then the reference distribution is approximated by
simulating z databases under H0 and computing the test statistic
for each.6 (The distribution of the test statistic is independent of
the distribution of data between groups and the distribution of the
i.i.d. data points, so our choice of equal-sized groups and uniform
data from [0, 1] is arbitrary.) The p-value is the percent of hk more
extreme than(cid:101)h.
Theorem 3.3. Algorithm(cid:103)KWp is ϵ-differentially private.
Proof. By Theorem 3.2, the computation of(cid:101)h is ϵ-differentially
x, and therefore by Theorem 2.4 (post processing), Algorithm(cid:103)KWp
private. All of the following steps (generating the reference distribu-
tion and calculating p-value) do not need to access to the database
is ϵ-differentially private.
□
6When we use the traditional Kruskal-Wallis test, the distribution of h-statistics
asymptotically converges to the χ 2 distribution. Thus, for efficiency purposes, we
sample hk from χ 2(д − 1) + Lap(∆h/ϵ)
д
д
i =1ni
(cid:12)(cid:12)(cid:12)(cid:12)¯ri − n + 1
(cid:12)(cid:12)(cid:12)(cid:12)¯ri − n + 1
(cid:12)(cid:12)(cid:12)(cid:12) ,
ni
2
2
(cid:12)(cid:12)(cid:12)(cid:12) ,
if n is even
if n is odd
д
д
i =1
ni
i =1
4(n − 1)
2
n
4
n + 1
habs =
3.3 A New Test: Absolute Value Kruskal-Wallis
We now introduce our own new test, specifically designed for
the private setting. Inspired by Swanberg et al. [28], we alter the
Kruskal-Wallis statistic, measuring distance with the absolute value
instead of the square of the differences. This statistic is now
habs = (n − 1)
i =1 ni|¯ri − ¯r|
j=1 |rij − ¯r| .
As before, when there are no ties in the data, the statistic can be
simplified. (See the full version for the calculation.) In this case, the
form depends on the parity of n.
We call the algorithm to calculate the habs test statistic KWabsstat.
This statistic is preferable for two reasons. First, it has lower sensi-
tivity. The following theorem is proved in the full version.
Theorem 3.4. The sensitivity of KWabsstat is bounded by 8.
Second, the actual values for habs are significantly higher than
they are for h, so any given amount of noise is less likely to over-