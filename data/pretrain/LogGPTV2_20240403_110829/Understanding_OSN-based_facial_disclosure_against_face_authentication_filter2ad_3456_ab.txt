### 3.2 Empirical Results

Based on the collected images, we evaluated the real-world threat posed by OSNFD (Online Social Network Facial Data) against the latest versions of popular face authentication systems. Our experimental methodology, similar to previous studies [22, 6], is as follows: 

1. **Enrollment**: A frontal image of each participant is used to enroll them into a face authentication system.
2. **Testing**: The participant's own OSN images are then used to test whether they can be used to log into the target face authentication system for their account.
3. **Display and Recording**: The OSN images are displayed on an LCD screen with a resolution of 1600×900 pixels, and the results (whether the target system can be spoofed by the OSN image) are recorded for each system and each image.

#### Metrics
We use two primary metrics to evaluate the vulnerability:
- **Vulnerable Images (VulImage)**: An image that is incorrectly accepted as genuine by the face authentication system, allowing an adversary to bypass the system.
- **Vulnerable Users (VulUser)**: A user enrolled in a face authentication system who has at least one vulnerable image published on OSNs.

#### Findings
Table 1 summarizes the overall percentage of VulImages and VulUsers across different face authentication systems. On average, 39% of the OSN images and 77% of the participants are vulnerable. Among the popular systems, Visidon is particularly vulnerable, with 68% of the images and 97% of the participants being vulnerable. Google’s Face Unlock, a built-in feature in Android-based systems (version > 4.0), also shows significant vulnerability, with 45% of the OSN images and 86% of the participants being vulnerable.

| System           | VulImage% | VulUser% |
|------------------|-----------|----------|
| Face Unlock      | 45%       | 86%      |
| Facelock Pro     | 46%       | 96%      |
| Visidon          | 68%       | 97%      |
| Veriface         | 27%       | 73%      |
| Luxand Blink     | 20%       | 41%      |
| FastAccess       | 33%       | 80%      |
| **Average**      | **39%**   | **77%**  |

Although the percentage of vulnerable images is moderate, the sheer volume of images on OSNs means that a large number of images are potentially exploitable. These images create a substantial resource for potential attacks. Additionally, users often share high-quality images where their faces are clearly visible, further increasing the risk. This is reflected in the high percentage of vulnerable users observed in our study.

### 3.2.1 Impacts of Security Settings

Security settings determine the robustness of a face authentication system against potential attacks. Most face authentication products offer limited choices for security levels. We analyzed the lowest and highest security levels, denoted as "low security" and "high security," respectively. Since Face Unlock has only one security level, which is comparable to the low security level of other systems, it was classified as low security.

As expected, Figure 2 shows that face authentication systems in low security levels are more susceptible to OSNFD threats than those in high security levels. On average, 40% of the images and 79% of the participants are vulnerable in low security, while only 8% of the images and 30% of the participants are vulnerable in high security.

The change in security settings affects the recognition threshold. As the security level increases, the recognition threshold becomes higher, imposing stricter requirements for matching the login facial image with the pre-stored image. This leads to more rigid restrictions on the login facial image, particularly in terms of head pose and lighting conditions.

- **Head Pose**: We measured the acceptable head pose range, which describes the head rotation range within which at least 50% of participants can successfully log in. Figure 3 shows the average results, with each closed curve representing the acceptable head pose range. Systems in low security have a wider acceptable range compared to high security.
- **Lighting Conditions**: We classified lighting conditions into illumination and low lighting. Systems in low security have higher tolerance for variations in lighting conditions. In our study, 27% of the OSN images had illumination, and 18% had low lighting. On average, 81% of the OSN images with illumination and 79% with low lighting could not be used to log in low security systems, while 96% of the OSN images with illumination and 94% with low lighting could not be used in high security systems.

However, high security levels may lead to significantly increased false rejection rates, up to 85% in some cases, which can cause accessibility issues. According to our questionnaire, 70% of participants consider it important to be able to log in to their devices when needed, and 67% would stop using the system if it were not always functional. This explains why many popular face authentication systems default to low security levels.

### 3.2.2 Impacts of Target Platforms

The target platform (mobile vs. traditional) imposes specific requirements on both security and usability. Our tested systems include mobile platforms (Face Unlock, Facelock Pro, Visidon) and traditional platforms (Veriface, Luxand Blink, FastAccess).

Figure 4 shows that the OSNFD threat is generally more severe for mobile platforms. In low security, 53% of the images and 93% of the participants are vulnerable for mobile platforms, while 27% of the images and 64% of the participants are vulnerable for traditional platforms. In high security, 10% of the images and 43% of the participants are vulnerable for mobile platforms, while 7% of the images and 22% of the participants are vulnerable for traditional platforms.

This difference is due to the design requirements of mobile systems, which need to be more robust and tolerant of varied environments to meet user expectations. Our questionnaire confirmed that 91% of participants believe it is important to log in to smartphones or tablets in both indoor and outdoor environments, while only 36% think it is important for laptops.

Tests on head pose and lighting conditions further show that mobile systems have higher tolerance for variations in these factors. For example, 81% of OSN images with illumination and 77% with low lighting cannot be used to log in to mobile systems, while these rates increase to 96% for traditional systems.

### 3.2.3 Impacts of User Behaviors

User behavior, particularly the quality and frequency of shared images, significantly influences the success of OSNFD-based attacks. Our study found that participants who publish more facial images on OSNs are not necessarily more vulnerable. Instead, the quality of the images is a critical factor. High-quality images, such as those with clear, unobstructed faces, are more likely to be exploited.

For example, female participants, who publish more facial images (on average, 65 per year) than male participants (34 per year), are less vulnerable to OSNFD threats. This is because female participants are more likely to publish blurred, edited, or makeup-enhanced images, which degrade the image quality and make face recognition more difficult. In our study, 12% of OSN images suffered from these negative effects, with 61% of these images published by females and 39% by males.

### 4. Statistical Analysis and Risk Estimation

While the OSNFD threat is significant, certain attributes of facial images can reduce the effectiveness of such attacks. We conducted a statistical analysis to identify key attributes and developed a risk estimation tool for end-users to calculate the risk of their shared images.

#### 4.1 Key Attributes Affecting OSNFD-based Attacks

Key attributes that affect the performance of face recognition algorithms include:
- **Head Pose**: Variations in head pose, including horizontal and vertical rotations, can significantly impact face recognition.
- **Lighting Condition**: Illumination and low lighting can diminish facial features, making recognition more challenging.
- **Facial Expression**: Changes in facial expressions, such as smiling or closing eyes, can alter face geometry and affect recognition.
- **Facial Occlusion**: Accessories like sunglasses or scarves can occlude facial features, leading to recognition failures.
- **Image Resolution**: Lower resolution images can reduce the accuracy of facial landmark localization.
- **Blur**: Blurred images make it difficult for algorithms to accurately localize facial features.
- **Facial Makeup**: Makeup can alter facial appearance, making recognition more challenging.
- **Editing**: Image editing can introduce noise and alter the appearance of the face, affecting recognition.

These attributes are used as input parameters to build our risk estimation tool.

#### 4.2 Risk Estimation Model

We used binomial logistic regression to model the impact of these key attributes. The input parameter vector \( V \) for each image includes:
- \( \text{rotH} \): Horizontal head rotation
- \( \text{rotV} \): Vertical head rotation
- \( \text{illsd} \): Side illumination
- \( \text{illtb} \): Top/bottom illumination
- \( \text{dm} \): Dim lighting
- \( \text{bg} \): Bright background
- \( \text{FExn} \): Neutral expression
- \( \text{FExs} \): Smile without teeth
- \( \text{FExst} \): Smile with teeth
- \( \text{FExce} \): Closed eyes
- \( \text{FExm} \): Open mouth
- \( \text{FExother} \): Other expressions
- \( \text{Occfh} \): Forehead occlusion
- \( \text{Occeb} \): Eyebrow occlusion
- \( \text{Occye} \): Eye occlusion
- \( \text{Occchk} \): Cheek occlusion
- \( \text{Occmh} \): Mouth occlusion
- \( \text{res} \): Image resolution
- \( \text{blur} \): Image blur
- \( \text{mk} \): Facial makeup
- \( \text{ed} \): Image editing

The output classifies an image as either positive (can be used to pass the login) or negative (cannot be used). The regression function is:

\[
\ln \left( \frac{p_i}{1 - p_i} \right) = \beta_0 + \beta_1 v_1 + \cdots + \beta_m v_m
\]

where \( p_i \) is the probability that an image \( i \) is assigned to the positive class, \( v \) is a parameter in \( V \), and \( \beta \) is a regression coefficient. The risk score of the image is the value of \( p_i \).

By using this model, we can provide users with a quantitative estimate of the risk associated with their shared images, helping them to better understand and mitigate the potential threats.