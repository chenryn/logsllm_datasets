3.2 Empirical Results
Based on the collected images, we inspect the realistic threat of
OSNFD against the latest version of popular real-world face au-
thentication systems. We use the common experiment procedure
similar to prior work [22, 6], which is described as follows: The
frontal image is ﬁrst used to enroll each participant into a face au-
thentication system. Then we use a participant’s own OSN images
to test whether it can be used to log in a target face authentication
system for his/her own account. The participant’s OSN images are
displayed on an LCD screen with resolution 1600×900 pixels, and
the result whether a target system can be spoofed by an OSN image
will be recorded for each system and each image.
Our analysis uses two basic metrics, namely vulnerable images
and vulnerable users. A vulnerable image, denoted by V ulImage,
is deﬁned as a facial image which is wrongly accepted as a genuine
user by a face authentication system during user authentication and
therefore enables an adversary to circumvent the face authentica-
415tion system. A vulnerable user, denoted by V ulU ser, is a user
enrolled in a face authentication system who has at least one vul-
nerable image published in OSNs.
Table 1 shows that the face authentication systems are vulnerable
to the OSNFD in general. On average, 39% of the OSN images
and 77% of the participants are vulnerable. Among popular face
authentication systems, Visidon is more vulnerable in low security
level, for which 68% of the images and 97% of the participants
are vulnerable. Especially for Google’s Face Unlock that comes
as a built-in feature of all Android-based systems whose version
is higher than 4.0 [10], 45% of the OSN images and 86% of the
participants are vulnerable.
Table 1: Overall percentage of V ulImage and V ulU ser
V ulImage% V ulU ser%
Face Unlock
Facelock Pro
Visidon
Veriface
Luxand Blink
FastAccess
Average
45%
46%
68%
27%
20%
33%
39%
86%
96%
97%
73%
41%
80%
77%
Although the percentage of vulnerable images is moderate, the
quantity of the vulnerable images is large due to the huge amount
of images in OSNs. These large amount of vulnerable images cre-
ate resources online for potential attacks. Even worse, users share
their personal images with their friends in OSNs, most of them tend
to publish the images where the users’ faces can be clearly viewed
for easier recognition. Consequently, the percentage of vulnerable
users would be high as observed in our study. The following sub-
sections will further analyze the detailed characteristics of these
vulnerable images and users from three major perspectives, secu-
rity settings, target platforms, and user behaviors.
3.2.1 Impacts of Security Settings
Security settings specify the security strength of a face authen-
tication system against potential attacks. As previously explained,
most of face authentication products [10, 8, 34, 23, 24, 35] provide
very limited choices on security level. So we focus our analysis
on lowest and highest security level that can be provided by each
system, which are denoted as low security and high security, re-
spectively. Since there is only one security level in Face Unlock
and the observed security strength of Face Unlock is comparable
to the other systems in low security level, we classify its security
level as low. As expected, Figure 2 shows that the face authentica-
tion systems in low security level are facing more severe OSNFD
threat than those in high security level. On average, 40% of the
images and 79% of the participants are vulnerable for the face au-
thentication systems in low security level while 8% of the images
and 30% of the participants are vulnerable for the face authentica-
tion systems in high security level.
The change of security settings generally affects the recognition
threshold in the face matching module. As the security level is
raised, the recognition threshold becomes higher which imposes
more restrictions for matching between login facial image and pre-
stored facial image. Therefore the face authentication imposes
more rigid restrictions on the login facial image. The major restric-
tions observed in our study are head pose and lighting condition.
For head pose, we use acceptable head pose range to measure
the tolerance of a face authentication system on head pose varia-
tions. It describes the head rotation range of head poses with which
at least 50% of the participants successfully log in the face authen-
(a)
(b)
Figure 2: Percentage of V ulImage and V ulU ser in different
security levels
tication systems. In these tests, we use participant’s frontal image
for enrollment and use the images collected with controlled head
poses as test inputs (i.e. login images). Figure 3 shows the average
results computed from all tested systems, where each closed curve
corresponds to the acceptable head pose range. The results for each
individual system that indicate the difference between high security
and low security are similar to Figure 3, which are not shown.
Figure 3: Tolerance of the rotation range of head pose
For lighting condition, we further classify it into different types
of illumination and low lighting [9, 43, 20]. The face authentication
454668272033137677Face UnlockFacelock ProVisidonVerifaceLuxand BlinkFastAccess010203040506070% (Vulnerable images) Low security level High security level8696977341805530162722Face UnlockFacelock ProVisidonVerifaceLuxand BlinkFastAccess020406080100% (Vulnerable users) Low security level High security level-20020-20020(-20,0)(-10,10)(0,20)(10,10)(20,10)(20,-10)(10,-20)(0,-20)(-10,-10)(-20,0)(-10,0)(0,10)(10,0)(0,-10)(-10,0)Vertical Rotation (Deg)Horizontal Rotation (Deg) Low security level High security level416systems in low security level are observed to have higher tolerance
for variation of lighting conditions than the systems in high security
level. In our study, illumination is observed in 27% (394 out of
1440) of the OSN images while low lighting is observed in 18%
(266 out of 1440) of the OSN images. On average, 81% of the OSN
images with illumination and 79% of the OSN images with low
lighting cannot be used to log in the face authentication systems in
low security level while 96% of the OSN images with illumination
and 94% of the OSN images with low lighting cannot be used to
log in the systems in high security level.
On the other hand, a face authentication system in low security
level has higher tolerance for varied login environments, which is
necessary for the system to be usable in the complex environments.
As a tradeoff for higher security strength, the false rejection rates in
high security level may be signiﬁcantly increased. As shown in the
follow-up experiment described in Section 5.1, the false rejection
rate could be as high as 85%. This will cause a signiﬁcant concern
on the accessibility. From our questionnaire on user perception,
70% of the participants think it is important to successfully log in
their smartphones, tablets, or laptops at the time they want to use.
If the face authentication system is not always functional, 67% of
the participants give up using the system which causes the serious
accessibility problem to their devices. This may also explain why
the popular face authentication systems always use low security
level by default.
3.2.2 Impacts of Target Platforms
The target platform of a face authentication system imposes the
platform-speciﬁc requirements on both security and usability. In
our tested systems, Face Unlock, Facelock Pro, and Visidon are
targeting for mobile platform, while Veriface, Luxand Blink, and
FastAccess are targeting for traditional platform.
Figure 4 shows that the OSNFD threat for mobile platform is
generally more severe than the OSNFD threat for traditional plat-
form. On average, in low security level, 53% of the images and
93% of the participants are vulnerable for the face authentication
systems on mobile platform while 27% of the images and 64% of
the participants are vulnerable for the systems on traditional plat-
form. In high security level, 10% of the images and 43% of the
participants are vulnerable for the face authentication systems on
mobile platform while 7% of the images and 22% of the partici-
pants are vulnerable for the face authentication systems on tradi-
tional platform.
These results clearly show the difference caused by platform-
speciﬁc requirements. Compared to a traditional system, a mobile
system is usually designed to be more robust and more tolerant to
varied environments such as outdoor environment in order to meet
accessibility expectation by users. Meanwhile it leads to the more
severe OSNFD threat for mobile platform based systems. This
difference is conﬁrmed by the results of our questionnaire, which
shows that 91% of the participants believe that it is important to log
in smartphones or tablets in both indoor and outdoor environment
while only 36% of the participants think it is important to log in
laptops in both indoor and outdoor environment.
This difference is also revealed in our tests on head pose and
lighting condition. Figure 5 shows the face authentication systems
targeting for mobile platform have higher tolerance for variations of
the head poses than the systems targeting for traditional platform.
Our tests on lighting conditions further show the face authenti-
cation systems targeting for mobile platform are more tolerant to
variations of the lighting conditions. In our study, 81% of the OSN
images with illumination and 77% of the OSN images with low
lighting cannot be used to log in the face authentication systems
(a) Low security level
(b) High security level
Figure 4: Difference in V ulImage and V ulU ser between sys-
tems targeting for mobile platform and traditional platform.
Figure 5: Difference in the tolerance of the rotation range of
head pose.
targeting for mobile platform, while these rates increase to 96%
for the images with illumination and 96% for the images with low
lighting on traditional platform.
3.2.3
The difference in user behavior is another major factor inﬂuenc-
ing the quality of shared images that decides whether these im-
ages can be eventually used for successful OSNFD-based attacks.
Our study reveals that the participants who publish more facial im-
Impacts of User Behaviors
454668272033869697734180Face UnlockFacelock ProVisidon--VerifaceLuxand BlinkFastAccess020406080100% Vulnerable images Vullnerable users1376775530162722Facelock ProVisidon--VerifaceLuxand BlinkFastAccess01020304050% Vulnerable images Vulnerable users-20020-20020(-20,0)(-20,10)(-10,10)(0,20)(10,10)(20,10)(20,-10)(10,-10)(0,-20)(-10,-10)(-20,0)(-10,0)(0,10)(10,0)(10,-10)(0,-10)(-10,0)Vertical Rotation (Deg)Horizontal Rotation (Deg) Mobile platform Traditional platform417ages in OSNs are not necessarily more vulnerable than those who
publish less facial images in OSNs. In fact, the OSNFD threat is
more severe among the participants who publish facial images with
higher quality in OSNs.
To illustrate the impact of user behaviors, we use the different
sharing behaviors and the different OSNFD threat between females
and males as example.
In our study, female participants are re-
ported to publish facial images in OSNs more frequently than male
participants in general. On average, each of the female participants
publishes 65 facial images per year while each of the male partic-
ipants publishes 34 facial images per year. However, the OSNFD
threat for the females is less severe than that for the males, as shown
in Figure 6.
This can be explained by the lower quality of the OSN images
published by the females. We ﬁnd that the female participants are
more likely to publish blurred images, edited images, or images
with their makeup. The blur, edit, and makeup can degrade the
quality of an image and therefore lead to the difﬁculty in face recog-
nition [16, 7]. In our study, 12% of the OSN images suffer from
these negative effects. Among these low quality images, 61% are
published by the females while only 39% of the images are pub-
lished by the males. All of these blurred, makeup, or edited images
fail to pass at least one face authentication system.
4. STATISTICAL ANALYSIS AND RISK
ESTIMATION
Although the OSNFD threat is signiﬁcant as shown in the previ-
ous section, we observe the effectiveness of OSNFD-based attacks
may be signiﬁcantly reduced by manipulating certain attributes of
facial images. In this section, we extract these key attributes via
statistical analysis and use them to develop an estimation tool for
end users to calculate the risk of their shared images.
4.1 Key Attributes Affecting OSNFD-based
Attacks
From the theoretical perspective, there are still many challenges
for face recognition algorithms. These challenges also become key
attributes that limit the effectiveness of OSNFD-based attacks. The
common attributes addressed in the prior study [1] include head
pose, lighting condition, facial expression, facial occlusion, and im-
age resolution. Beside these traditional attributes, we also observe
blur, facial makeup, and editing (using Photoshop-like software) as
the extra key attributes which often appear in the real world im-
ages shared in OSNs, though they are usually not considered in the
controlled settings of traditional study on face authentication. We
describe the details of these key attributes as follows.
Head pose is a prominent challenge to face recognition. The
performance of face recognition algorithms in face authentication
can be signiﬁcantly affected if the head pose in a login image and
the head pose in the pre-stored facial image are different [43]. The
affecting variations of a head pose mainly include two out-of-plane
rotations, namely horizontal rotation and vertical rotation [27].
Lighting condition is another prominent challenge in the realm
of face recognition. The variation of lighting conditions mainly in-
cludes illumination and low lighting [9, 43, 20]. The illumination is
mainly caused when direct light shoots on the 3D structure of a face
and strong shadows can be casted which diminish facial features [9,
43]. The illumination can be classiﬁed into side illumination and
top/bottom illumination [9]. Low lighting is another negative light-
ing condition, which usually happens when a facial image is taken
in dim environment or with extreme bright background. The low
lighting may diminish facial features since the luminance in face
region is too low for face recognition algorithms to recognize [20].
Facial expression such as smile, surprise, etc, can change face
geometry and therefore affect the performance of face recognition
algorithms [1]. The common facial expressions include neutral ex-
pression, smile without showing teeth, smile showing teeth, closed
eyes, open mouth, and other expressions.
Facial occlusion often happens in real world due to additional
accessories on face, such as sunglasses, scarf, hands on face, etc.
The occlusion can result in the failure of face appearance repre-
sentation or imprecise facial feature searching and localization, and
therefore have negative inﬂuence on the performance of face recog-
nition algorithms. The common facial occlusions include forehead
occlusion, eyebrow occlusion, eye occlusion, cheek occlusion, and
mouth occlusion [1].
The resolution of an image can affect accuracy of facial land-
mark localization and therefore inﬂuence the performance of face
recognition algorithms. As the resolution of face images decreases,
the performance of the face recognition algorithms drops [43].
The blur in a facial image causes difﬁculty in accurate localiza-
tion of edges of facial region and facial landmarks (i.e. eyes, nose,
mouth, etc) by face recognition algorithms and therefore harms the
performance of the algorithms.
Facial makeup can substantially change the appearance of a face
and facial landmarks, such as the alternations of perceived facial
shape, nose shape, location of eyebrows, etc. These alternations
by the facial makeup, especially by non-permanent facial makeup,
challenge face recognition signiﬁcantly [7].
The editing of an image introduces noise pixels and change the
appearance of the face in the image [2, 7]. Face recognition algo-
rithms can be affected by these noises and appearance changes due
to the edited image.
All these attributes signiﬁcantly degrade the image quality and
therefore lead to the failure of OSNFD-based attacks. They are
used as input parameters to build our risk estimation tool in the
next section.
4.2 Risk Estimation Model
We use binomial logistic regression [15] to model the im-
the key attributes introduced in the previous sub-
pact of
The notions of these attributes are deﬁned in Ta-
section.
ble 2.
Then the key attributes of each image can be rep-
resented by an input parameter vector, denoted as V =
(rotH , rotV , illsd, illtb, dm, bg, F Exn, F Exs, F Exst, F Exce,
F Exm, F Exother, Occf h, Occeb, Occeye, Occchk, Occmh, res,
blur, mk, ed).
For the output, we assign an OSN image to either a positive class
or a negative class. The positive class means the image can be used
to pass the login of a speciﬁc face authentication system, otherwise
the image will be in the negative class.
Binomial logistic regression is a classic probabilistic classiﬁca-
tion model [15], which accepts multiple predictor variables as in-
puts, and predicts the outcome for a dependent variable which has
only two possible types, such as “positive” vs “negative”. Thus it
is a proper tool to calculate the probability of an image assigned to
the positive class based on the key attributes extracted from an OSN
image. Given a parameter vector Vi of a facial image i and a face
authentication system in a security level, the regression function is
ln (pi/(1 − pi)) = β0 + β1v1 + · · · + βmvm
(1)
where pi is the probability that an image i is assigned to the positive
class, v is a parameter in Vi, and β is a regression coefﬁcient. The
risk score of the facial image i is the value of pi. The facial image
418(a) V ulImage% in low security level
(b) V ulU ser% in low security level
(c) V ulImage% in high security level
(d) V ulU ser% in high security level
Figure 6: Difference in V ulImage and V ulU ser between females and males
Parameter
Attribute
Head pose
Table 2: Parameters related to the key attributes
Notation
rotH
rotV
illsd
illtb
dm
bg