her choice to the challenger. The challenger sends the
output of ProcOnion(SK, Oi, Pj) to the adversary.
3) The adversary submits a message m, a path P =
(P1, . . . , Pj, . . . , Pn+1) with the honest node at posi-
tion j, 1 ≤ j ≤ n + 1 of her choice and key pairs for
all nodes (P Ki, SKi) (1 ≤ i ≤ n + 1 for the nodes
on the path and n + 1 < i for the other relays).
4) The challenger checks that the router names are valid,
that the public keys correspond to the secret keys and
that the same key pair is chosen if the router names
are equal, and if so, sets P Kj = P K and sets bit b
at random.
5) The challenger creates the onion with the adversary’s
input choice:
(O1, . . . , On+1) ← FormOnion(m,P, (P K)P )
and a random onion with a randomly chosen path ¯P =
( ¯P1, . . . , ¯Pk = Pj, . . . , ¯P¯n+1 = Pn+1), that includes
the subpath from the honest relay to the corrupted
receiver starting at position k ending at ¯n + 1:
( ¯O1, . . . , ¯O¯n+1) ← FormOnion(m, ¯P, (P K) ¯P )
6) • If b = 0, the challenger gives (Oj+1, Pj+1) to the
• Otherwise, the challenger gives ( ¯Ok+1, ¯Pk+1) to
adversary
the adversary
7) The adversary may submit any number of onions Oi of
her choice to the challenger. The challenger sends the
output of ProcOnion(SK, Oi, Pj) to the adversary.
8) The adversary produces guess b(cid:48) .
T I is achieved if any PPT adversary A, cannot guess b(cid:48) = b
with a probability non-negligibly better than 1
2.
D. Linking Protection
The ﬂaw of the previous section is not the only one the
proposed properties missed. Here, we introduce a second
insecure protocol, which allows to bypass honest nodes by
linking onions, and construct a new property against this
weakness.
1) Insecurity: Including Unique Identiﬁers: We show that
reidentifying the same onion after processing at a honest node
is not prevented by the original properties with the following
obviously insecure protocol.
a) Insecure Protocol 2: The protocol Πbroken2 when
creating an onion independently draws a random identiﬁer
ID and appends it to each layer of the created onion. The
ID makes the onion easily traceable, as it remains identical
throughout the processing of the onion at any relay. For the
proof of the properties we need to construct an extension that
prevents modiﬁcation of the ID. We provide the details of the
extension and broken scheme in the extended version of this
paper [24].
b) Analysis regarding Properties: Without going into the
details here, we note that none of the properties protects from
embedded identiﬁers, which are identical for all onion layers
of the same onion, but different for other onions: Integrity,
Correctness and Wrap-Resistance are not inﬂuenced by this
adaptation as the same path is taken, the onion layers (without
appended ID) are constructed as before and thus are as hard to
re-wrap as before. Onion-Security is not broken as the extension
protects against modiﬁcation of both the appended ID and
extension, and thus calling the oracle with a modiﬁed ID or
extension is useless. Finally, the appended ID does not include
any information about the input used to form the onion and
hence does not help to distinguish the onion with inputs of the
adversary from another onion.
Note that also Tail-Indistinguishability cannot protect against
linking as only one onion layer is given to the adversary.
2) Improved Property: Layer-Unlinkability LU against
bypassing honest nodes: To explicitly model that output onions
shall not be linkable to the corresponding inputs of the relays,
the adversary has to get onion layers both before and after
they are processed at the honest relay. Our property challenges
the adversary observing an onion going from the sender to
an honest relay, to distinguish between the onion generated
with her original inputs O, and a second onion ¯O. The path
of the alternative onion ¯O includes the original path from the
sender to the honest node, but all other parameters are chosen
randomly. Thus, there might be a path before the sender node
and both the path after the honest node and the message can
differ. Additionally, the adversary always observes the onion
generated by processing O at the honest relay. We illustrate
the new challenge outputs in Fig. 4.
Note that this new property indeed prevents the insecurity
given in Section IV-D1: If the adversary can decide that the
provided onions belong together, she knows that the original
onion has been sent and thus she is able to distinguish the
onions.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 10:04:48 UTC from IEEE Xplore.  Restrictions apply. 
176
......b=0b=1...We again adapt the original Onion-Security explained in
Section IV-B3a with the difference that the adversary now gets
the layers of O after the honest relay and either O’s layers
between the honest sender and relay or ¯O’s layers in Step 6.
This is our new property LU, which is formally deﬁned in
Def. 4.
Fig. 4. Cases of LU illustrated: Red boxes are corrupted routers, black honest
routers and curved arrows represent randomly chosen paths. In case b = 0
the adversary chosen onion, sent from P0, is observed on the complete path
P starting from when it arrives at the ﬁrst relay P1. For b = 1 the onion
layers in the ﬁrst orange ellipse are replaced with those of a randomly drawn
onion, that take the same path between P0 and Pj (the blue ellipse), but differ
otherwise and might have traveled from another honest sender to P0 earlier.
Deﬁnition 4 (Layer-Unlinkability LU):
1) – 4) as in Def. 3
5) The challenger creates the onion with the adversary’s
input choice:
(O1, . . . , On+1) ← FormOnion(m,P, (P K)P )
and a random onion with a randomly chosen
¯P = ( ¯P1, . . . , ¯Pk = P1, . . . , ¯Pk+j =
path
Pj, ¯Pk+j+1, . . . , ¯P¯n+1),
includes the subpath
from the honest sender to honest node of P starting at
position k ending at k + j (with 1 ≤ j + k ≤ ¯n + 1 ≤
N), and a random message m(cid:48) ∈ M:
( ¯O1, . . . , ¯O¯n+1) ← FormOnion(m(cid:48), ¯P, (P K) ¯P )
that
6) • If b = 0, the challenger gives
(O1, ProcOnion(Oj)) to the adversary.
• Otherwise, the challenger gives
( ¯Ok, ProcOnion(Oj)) to the adversary.
7) The adversary may submit any number of onions
(cid:54)= ¯Ok+j of her choice to
Oi, Oi
the challenger. The challenger sends the output of
ProcOnion(SK, Oi, Pj) to the adversary.
(cid:54)= Oj, Oi
8) The adversary produces guess b(cid:48) .
LU is achieved if any PPT adversary A, cannot guess b(cid:48) = b
with a probability non-negligibly better than 1
2.
E. Improved Properties imply Ideal Functionality
In this section we ﬁrst informally argue and then formally
prove that our two new properties,
together with Onion-
Correctness, are sufﬁcient for the ideal functionality. For easier
discussion, we summarize the different outputs of the security
properties in Fig. 5.
Informally: In case of sender corruption, the ideal func-
tionality outputs all information given as input to FormOnion,
and hence we do not need to provide any protection in this
case.
Considering honest senders, the ideal functionality outputs
only the path sections introduced by cutting at honest nodes
Fig. 5. Difference in security properties illustrated: While in original Onion-
Security no processed onion after Pj is output, LU outputs the processing
and T I challenges to distinguish it from randomness.
together with random onion IDs or if the receiver is compro-
mised, additionally the message. These IDs are independently
drawn for each such section and thus cannot be linked.
The idea to show the same privacy for communications
with honest senders is simple: for every path section instead
of the original onion layers we give the adversary without
her noticing it layers of a random replacement onion. The
replacement onion only corresponds with the original onion
in characteristics she also learns about the onion in the ideal
functionality. Namely those characteristics are the path sections
and if the receiver is corrupted, the message. The replacements
can obviously not be linked or leak any other information as
all their (other) parameters have been chosen randomly.
Our properties are sufﬁcient to show that the adversary
cannot notice the replacement: LU allows to replace any onion
layers on a path section between two honest nodes with onion
layers that are (except for the fact that they use the same path
section) chosen completely at random. The adversary is not able
to notice the replacement as she cannot distinguish the onion
layers in the LU game. This allows us to replace all layers
in communications between honest senders and receivers, and
all except the last section in communications between honest
senders and corrupted receivers.
For replacement on the last part of a path with a corrupted
receiver we need our other property T I. T I allows to replace
any onion layers on a path section between an honest node
and a corrupted receiver with onion layers that are (except for
the fact that they use the same path section and carry the same
message) chosen completely random. The adversary is not able
to notice the replacement as she cannot distinguish the onion
layers in the T I game. This completes our informal argument.
Formally: Similar to Camenisch and Lysyanskaya we
assume a secure protocol to distribute public keys. We consider
key distribution outside of the scope of this paper.
We now show that our new security properties are indeed
sufﬁcient to realize the ideal functionality. Therefore, we deﬁne
a secure OR scheme to fulﬁll all our properties:
Deﬁnition 5: A secure OR scheme is a triple of polynomial-
time algorithms (G, F ormOnion, P rocOnion) as described
in Section II-E2 that achieves Onion-Correctness (Deﬁnition 1),
Tail-Indistinguishability (Deﬁnition 3), as well as Layer-
Unlinkability (Deﬁnition 4).
Following Camenisch and Lysyanskaya, we build a protocol
from any secure OR scheme:
Deﬁnition 6: OR protocol Π is a secure OR protocol if it is
based on a secure OR scheme (G, FormOnion, ProcOnion)
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 10:04:48 UTC from IEEE Xplore.  Restrictions apply. 
177
b=0b=1b=0b=1.........follows adversarial input follows random feasible inputOnion-Securityby Camenisch and LysyanskayaOur improved security propertiesand works as follows:
Setup: Each node Pi generates a key pair9 (SKi, P Ki) ←
G(1λ, p, Pi) and publishes P Ki.
Sending a Message: If PS wants to send m ∈ M to Pr over
path P1, . . . , Pn with n < N, he calculates (O1, . . . , On+1) ←
FormOnion(m, (P1, . . . , Pn, Pr), (P K1, . . . , P Kn, P Kr))
and sends O1 to P1.
Processing an Onion: Pi received Oi and runs (Oj, Pj) ←
ProcOnion(SKi, Oi, Pi). If Pj =⊥, Pi outputs “Received
(cid:54)=⊥ and reports a fail if Oj =⊥.
m = Oj” in case Oj
Otherwise Pj is a valid relay name and Pi generates a random
temp and stores (temp, (Oj, Pj)) in its outgoing buffer and
notiﬁes the environment about temp.
Sending an Onion: When the environment instructs Pi
to forward temp, Pi
looks up temp in its buffer. If Pi
does not ﬁnd such an entry, it aborts. Otherwise, it found
(temp, (Oj, Pj)) and sends Oj to Pj.
To show that any secure OR protocol Π realizes the ideal
functionality, we prove that any attack on the secure OR
protocol can be simulated in the ideal functionality. As the
simulator only gets the outputs of the ideal functionality and
thus no real onions, it simulates them with the closest match it
can create: replacement onions that take the same path (and, if
sent to corrupted receivers, include the same message). Due to
our new security properties, we know that such a replacement
cannot be distinguished. The full proof is included in Appendix
B.
UC-realizes the ideal functionality F.
Theorem 2: A secure OR protocol following Deﬁnition 6
V. SECOND PITFALL: UNDERVALUED ORACLES
We discovered a new attack on HORNET whose existence
cannot be explained with the shortcomings of the properties of
Camenisch and Lysyanskaya. The reason for this attack is not
in the properties used for the proof, but in how the properties
are proven. It turns out that on many occasions the properties
have not been proven correctly; more precisely the oracles
have been wrongly adapted or ignored.
We start this section by describing our attack, then explain
how the oracles have been modiﬁed and how the correct use
of oracles detects the attack.
A. Attacking HORNET’s Data Transmission
HORNET was proposed as a network level anonymity system
for the anonymized transmission of arbitrary higher layer
packets. The latter can be expected to match speciﬁc formats or
contain interpretable content, e.g. natural language. Hence the
receiver can very likely distinguish real messages from random
bit strings of the same length in HORNET’s transmission phase.
HORNET uses a pseudo-random permutation (PRP) in CBC
mode10 to form layered encryption of its payload, but does not
implement integrity checks at the processing relays for it.
9We assume the P Ki are checked to be well formed as part of the key
distribution mechanism that is outside the scope of this work.
10Note, that the paper is not entirely clear about this point, as it states that
HORNET uses a “stream-cipher”, which would make our attack stronger, “in
CBC mode”, suggesting that instead they actually use a PRP.
OBSERVABLE LINKINGS ON DIFFERENT SYSTEMS; ((cid:88)) IF ATTACK WORKS
TABLE I
ONLY UNDER VIOLATION OF THE ADVERSARY MODEL
System
Improved Minx
Sphinx (receiver (cid:54)= exit node)
Sphinx (receiver = exit node)13
HORNET (Setup)
TARANET (Setup)
HORNET (Data)
TARANET (Data)
Sender-Message
Sender-Receiver
(cid:88)
(cid:88)
(cid:88)
((cid:88))
(cid:88)
(cid:88)
Sender-Exit node
(cid:88)
(cid:88)
(cid:88)
(cid:88)
((cid:88))
(cid:88)
An attacker that controls the ﬁrst relay11 and the receiver
can link sender and receiver (thus break relationship anonymity
SRL) and this adversary can also link large parts of the
message to its sender (break sender anonymity SM L) with
the following attack:
1) The adversary ﬂips bits in the last k blocks of the data
payload of the HORNET packet sent from the sender.
2) The packet is sent through the chain of relays as intended
because the header was not modiﬁed and the payload’s
integrity is not protected. The payload is decrypted using
the block cipher in CBC mode.
3) The receiver checks the last k blocks. They either contain
random bits (i.e. the sender was communicating with this
receiver and the preceding decrypted blocks contain parts
of the original message) or it conforms to a real message
(i.e. the sender was not communicating with this receiver).
Varying k the success of distinguishing real messages from
some ending with random bit strings can be adjusted at the
cost of learning less about the real message.
The described attack lies well within the adversary model of
HORNET: it allows a fraction of nodes to be actively controlled
by the adversary and aims at sender anonymity, even if the
receiver is compromised, and relationship anonymity, even if
one of the end hosts is compromised.
Further, the attack can be varied to link senders and receivers
in the improved Minx or, if it is used with an unintended
addressing model like in HORNET’s or TARANET’s setup
phase12, in Sphinx (See Table I for a summary. For more
information on how to vary the attack, we refer the interested
reader to our extended version [24]).
B. Mistake in the Proofs