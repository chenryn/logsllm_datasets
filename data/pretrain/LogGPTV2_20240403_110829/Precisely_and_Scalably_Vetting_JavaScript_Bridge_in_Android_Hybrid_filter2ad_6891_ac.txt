(a)
DataType
WebView JsFlag (¡) EventHandler Bridge#0 Bridge#1..
Fields
(b)
DataType
Fields
Bridge
BridgeObject BridgeName(¡)
4.4 WebView and Bridge Discovery
The goal of this module is to discover all WebView components and bridges.
We apply type and value/string analysis based on shadowbox on the generalized
WebView code (Sect. 4.3). This allows us to generate a complete control ﬂow
graph (CFG), and enables discovery of most WebViews and JavaScript Bridges
within an app.
The analysis starts from entry points of Android Activities, since a WebView
is almost always launched within an Activity. Even if a WebView is standalone
or independent (such as Xbot [24]), we can still identify it after obtaining the
CFG of the target app.
During analysis, data types of key variables, such as BridgeObject, are also
for the further analysis (Sect. 4.5). Additionally, values of key variables, such as
JsF lag and BridgeN ame (Sect. 4.3), are computed on demand with the help
of value and string analysis. JsF lag can be used to ﬁlter out WebViews whose
JavaScript is disabled (i.e., JsF lag is false), while BridgeN ame is helpful in
attack code generation.
4.5 Bridge Analysis
The goal of the module is to identify sensitive bridges from all bridges in
BridgeObject. To achieve the goal, it is critical to reconstruct the semantics and
learn the functionality of all exposed functions in BridgeObject (i.e., bridge func-
tion), which are annotated with ‘@JavaScriptBridge’ (Sect. 4.3). In BridgeScope,
we apply taint analysis (Sect. 3) based on shadowbox on each function by track-
ing data ﬂow of function parameters (T P ) and system sensitive information
(T S). To distinguish these two types of information, we deﬁne diﬀerent taint
value ranges: [T Pmin, T Pmax], and [T Smin, T Smax]. Initially, parameters of a
bridge function are tainted from left to right sequentially. Speciﬁcally, the nth
parameter is assigned with the taint value T Pmin ∗ 2n. During analysis, if a sen-
sitive native API (Sect. 2.3) is invoked, we take a snapshot of their parameters’
states (e.g., the associated shadowboxes), which will be analyzed further.
Finally, a bridge function’s semantic information is reconstructed based on
its data ﬂow analysis result. A bridge function will be ﬂagged as sensitive if:
(1) its return is tainted by the value t while t ∈ [T Smin, T Smax], (2) or a sink
API s() is called while s()’s parameters are tainted, (3) or a danger API is
156
G. Yang et al.
invoked. Based on the above three scenarios, we categorize all bridge functions
into SourceBridge, SinkBridge, and DangerBridge, correlating to the API
categorization as deﬁned in Sect. 2.3.
As a result, an app can be ﬂagged as potentially vulnerable, if a sensitive
bridge function f is found by BridgeScope. We use the following reasoning: (1)
if f ∈ SourceBridge, it means that sensitive information can be obtained in
the web context. Then, an attacker can send out sensitive information through
network related APIs in the web context (like XM LHttpRequest()) or a sink
JavaScript Bridge if it exists; (2) if f ∈ SinkBridge, security checks in event
handlers in WebView, such as shouldOverrideU rlLoading(), can be evaded; (3)
if f ∈ DangerBridge, a danger API can be accessed through f.
4.6 Log Analysis and Exploit Code Generation
BridgeScope collects a rich set of heuristics information for the app under analy-
sis as it executes each module (Table 4). This information is useful to further
analyze ﬂagged sensitive bridges and to generate test attack code. Furthermore,
inspired by SMV-Hunter [29], we retrieve required UI events for triggering tar-
get WebViews by analyzing the result of the ‘WebView and bridge discovery’
module.
Table 4. Collected Information
Purpose
Collected information
Which module
Triggering WebView UI Events
WebView & Bridge Discovery
Generating test code Domains associated with WebView
(cid:2)BridgeObject, BridgeN ame(cid:3)
Semantics of bridge functions
Bridge Analysis
SourceBridge,SinkBridge,DangerBridge
Algorithm 1 outlines our approach that leverages the above collected informa-
tion to generate test code to verify discovered vulnerabilities. In the algorithm, a
function create input() is assumed to generate appropriate inputs for each bridge
function. We implement it as a smart fuzzer using the following heuristics:
– Data Types: Based on data type information of parameters of bridge func-
tions, which is gathered from type analysis, we can generate random but valid
inputs [29].
– Bridge Function Name: The bridge function name itself also provides an
important clue. For example, if a BridgeScope’s name is downloadImage()
and the input is of type String, then input is likely a URI of a picture ﬁle.
In our fuzzer, we handle several keywords, such as “url”, “email”, “picture”,
“camera”, “audio”, “video”, “SMS”, “call” to provide typical input values.
Precisely and Scalably Vetting JavaScript Bridge in Android Hybrid Apps
157
Algorithm 1. Test Code Generation
1: function generate test code
2:
3:
4:
5:
for f in SourceBridge do
input ← create input(f );
f name ← replace bridgeobject with bridgename(P, f );
add test code(X, “var r = fname(input)”) (cid:2) append the JavaScript code to the result
for d in Domains do
(cid:2) bypass security check in event handler
X
end for
for f
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
18:
19:
end for
20:
return X
21: end function
end for
add test code(X, “XMLHttpRequest(http://d/r)”)
(cid:2)
in SinkBridge do
(cid:2) ← create input(f
(cid:2) ← replace bridgeobject with bridgename(P, f
,“r”);
input
f name
add test code(X, “fname
(cid:2)
(cid:2)
(cid:2)
(input
)”)
(cid:2)
);
end for
for f in SinkBridge ∪ DangerBridge do
input ← create input(f );
f name ← replace bridgeobject with bridgename(P, f );
add test code(X, “fname(input)”)
– Semantics of bridge functions and key native APIs: We can also build input
by utilizing the semantic information. For instance, assume there is a path in
CFG from a bridge function to a sensitive API: f(p0 : string, p1 : string) (cid:2)
sendT extM essage(v0, null, v2, null, null), where v0 and v2’s taint values are
T Pmin ∗ 2 and T Pmin ∗ 4, respectively. The data ﬂow in the bridge function
includes p0 (cid:2) v0 and p1 (cid:2) v2. Since in sendT extM essage(), v0 is the desti-
nation address, and v2 is the message content to be sent, p0 and p1 are likely
a phone number and message content. Therefore, the following input can be
used to test the sensitive bridge function: f("0123456789", "test").
5 Evaluation of BridgeScope
In this section, we present our evaluation of BridgeScope. First, we measure the
performance of the programming analysis techniques by leveraging the generic
benchmark DroidBench. Then, we evaluate BridgeScope’s eﬃcacy, precision, and
overhead using 13,000 popular apps, and present our ﬁndings. Finally, we present
some interesting case studies to illustrate the JavaScript Bridge vulnerability.
5.1 Performance of Shadowbox Analysis
We evaluate the precision of shadowbox analysis using the generic benchmark
DroidBench 2.0. Our test results (Table 5) show BridgeScope’s overall precision
is 94%, compared to 80% and 91% for Flowdroid [4] and Amandroid [33], respec-
tively, and BridgeScope’s recall and F-score are also better than the others. Our
use of shadowbox analysis beneﬁts from its path- and value-sensitivity, and it is
ﬁne-grained, especially in handling common data structures.
G. Yang et al.
158
Table 5. Testing Result on DroidBench. × represents suspicious data ﬂows not
detected, and (cid:2) represents benign data ﬂows ﬂagged as suspicious. The number in
{} represents the number of errors.
BridgeScope Flowdroid
(cid:2)
××
(cid:2) (cid:2) (cid:2)(cid:2)
(cid:2) (cid:2) ×
××
Amandroid
(cid:2)
× × ×
(cid:2) (cid:2) (cid:2) (cid:2) ×
(cid:2) (cid:2) (cid:2) (cid:2) × × ××
××
DroidBench
Aliasing
Android speciﬁc
Arrays and lists
Callbacks
Emulator detection
Field/Object Sensitivity
General java
Implicit ﬂows
Interapp communication
ICC
Lifecycle
××
××
××
(cid:2) (cid:2) ××
–
× × ××
(cid:2)×
Reﬂection
Threading
×
Totally Found Paths f
100
Precision p = f /(f + (cid:2)) 94%
Recall r = (cid:2)/((cid:2)/ + ×) 83%
F-score 2 ∗ p ∗ r/(p + r)
0.89
–
(cid:2){4} × × × × (cid:2) × ×
–
(cid:2) (cid:2) (cid:2)
(cid:2){16} × × × × (cid:2) × × × ××
(cid:2) × ×
× × ×
×
127
×{5}
101
× × ××
80%
82%
0.81
90%
75%
0.82
5.2 Performance of BridgeScope
Dataset. We use 13,000 apps that were collected from the Google Play app
market. We crawled these apps from 26 categories, and extracted the top 500
most popular free apps for each category.
Scalability. We implemented BridgeScope in 8,157 lines of Python code on the
top of the disassembly tool Apktool14. We deployed our tool on a university
server, which is allocated with 20 CPU cores and 100 GB of memory. Due to
Python’s poor support for multiple threads, we run single process and single
thread for the analysis (i.e., starting 20 processes for 20 apps each time). Finally,
with the boost of the JIT (Just-in-Time) based Python interpreter (such as
pypy15), the average analysis time of each process is 141 s. Thus, the average
analysis time for each app is around 7 s. This suggests that BridgeScope is indeed
capable of scaling to the level of real-worlds app markets to provide vulnerability
detection services.
Precision. Among 13,000 apps, we ﬁnd that 11,913 apps have at least one Web-
View component and 8,146 apps declare at least one JavaScript Bridge interface.
14 https://ibotpeaches.github.io/Apktool/.
15 https://pypy.org/.
Precisely and Scalably Vetting JavaScript Bridge in Android Hybrid Apps
159
In total, 913 apps were ﬂagged as potentially vulnerable apps by BridgeScope,
while a total of 1,530 sensitive bridge functions were found, including 56 bridge
functions which could suﬀer from SOP Violation Attacks (Sect. 2.2).
Measuring false positives and negatives. A false positive occurs when an
app is ﬂagged as potentially vulnerable by BridgeScope, but has no vulnerability.
A false negative occurs when an app is ﬂagged as non-vulnerable by BridgeScope,
but includes a JavaScript Bridge vulnerability.
Since it is hard to directly collect ground truth for the dataset, manual ver-
iﬁcation may be necessary, which is a diﬃcult and tedious job for such a large
dataset. To reduce the workload, we ﬁrst design a dynamic veriﬁcation mod-
ule to automatically validate the potentially vulnerable apps (thus we do not
need to manually validate all data) when analyzing false positives. Additionally,
we manually analyzed a small set of 20 randomly chosen apps from those not
marked as potentially vulnerable, which we used as the basis of measuring the
false negative rate.
Fig. 4. Overview of the dynamic veriﬁcation module
As shown in Fig. 4, our dynamic veriﬁcation module is built around an instru-
mented Android Emulator, where all executed functions of apps under test are
outputted, sensitive information is modiﬁed to special values, and native sink
APIs parameters (e.g., WebView.load) are also outputted. In the module, UI
Event Trigger [29] is used to input UI required event sequentially to trigger tar-
get WebViews, while Network Proxy is used to launch MITM attacks to inject
attack code, which is generated using the example algorithm mentioned earlier
(Algorithm 1).
In our evaluation we also hijack all network traﬃc, including HTTPS, so
that we can further analyze the complexity faced by attackers who launch code
injection attacks (i.e., Attack Complexity Analysis). We mainly consider three
scenarios: (1) HTTP: the remote server is connected over HTTP; (2) ﬁrst-party
HTTPS: the remote server belonging to developers is connected over HTTPS;
(3) third-party HTTPS: others. In Attack Complexity Analysis, we use the URL
loaded by the WebView as input, and initiate a crawler to check all accessible
URLs, similar to the approach in [14].
Finally, we check whether a potential vulnerability is successfully exploited
by analyzing logs from the Android Emulator and proxy (i.e., Log Analysis).
160
G. Yang et al.
If a bridge function f satisﬁes: (1) f ∈ SourceBridge, it can be veriﬁed by
checking executed functions, sink APIs parameters and proxys traﬃc. (2) f ∈
SinkBridge∪ DangerBridge, it can be veriﬁed by checking executed functions.
False Positives. By means of the dynamic veriﬁcation module, we found that
617 potentially vulnerable apps ﬂagged by BridgeScope are successfully exploited
(i.e., they are surely not false positives). This reduces our manual veriﬁcation job
to only 296 non-veriﬁed potentially vulnerable apps. We then randomly selected
20 apps and manually analyzed them. We found most of them still contain
vulnerable bridges that could be exploited. The reason they are missed by the
dynamic veriﬁcation module is because the dynamic module uses heuristics but
cannot guarantee the completeness. For example, it may not always generate
proper input formats of the JavaScript Bridges, such as the JSON string. There
are 4 apps that use WebView to load local HTML ﬁles instead of connecting to
Internet. While these 4 apps could be considered as false positives of BridgeScope
(because our assumed network adversary may not be able to inject attack code in