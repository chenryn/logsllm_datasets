title:High Precision Open-World Website Fingerprinting
author:Tao Wang
High Precision Open-World Website Fingerprinting
Tao Wang
Hong Kong University of Science and Technology
PI:EMAIL
Abstract—Trafﬁc analysis attacks to identify which web page
a client is browsing, using only her packet metadata — known
as website ﬁngerprinting (WF) — has been proven effective in
closed-world experiments against privacy technologies like Tor.
We want to investigate their usefulness in the real open world.
Several WF attacks claim to have high recall and low false
positive rate, but they have only been shown to succeed against
high base rate pages. We explicitly incorporate the base rate into
precision and call it r-precision. Using this metric, we show that
the best previous attacks have poor precision when the base rate
is realistically low; we study such a scenario (r = 1000), where
the maximum r-precision achieved was only 0.14.
To improve r-precision, we propose three novel classes of
precision optimizers that can be applied to any classiﬁer to
increase precision. For r = 1000, our best optimized classiﬁer
can achieve a precision of at least 0.86, representing a precision
increase by more than 6 times. For the ﬁrst time, we show a
WF classiﬁer that can scale to any open world set size. We
also investigate the use of precise classiﬁers to tackle realistic
objectives in website ﬁngerprinting, including different types of
websites, identiﬁcation of sensitive clients, and defeating website
ﬁngerprinting defenses.
Index Terms—website ﬁngerprinting; trafﬁc analysis; Tor;
privacy
I. INTRODUCTION
The last few years have seen a sharp increase in TLS usage
rate (26% in 2014 to 70% in 2018 [14]). Combined with
packet destination obfuscation techniques such as proxies and
encrypted SNI, the network-level privacy leaks of the Internet
are being plugged. Privacy-sensitive individuals may turn to
anonymity networks, which encrypt and redirect the user’s
trafﬁc across proxies, hiding sender, recipient, and packet
contents from a passive observer (a network eavesdropper).
However, none of these technologies hide signiﬁcant features
of the user’s trafﬁc, such as packet frequency, timing, order,
and direction. Website Fingerprinting (WF) attacks allow
passive network eavesdroppers to use these features to identify
the client’s destination web page, compromising her privacy.
The WF attacker wishes to monitor a set of sensitive web
pages and identify when a client visits these pages. In the
closed-world scenario, the client is conﬁgured to only visit
these sensitive web pages, and the attacker needs to identify
which one. In the harder open-world scenario, the client can
visit any page, and the attacker must also correctly identify
which page visits are non-sensitive.
WF attacks have been proven effective against real-world
privacy technologies in the closed-world scenario [3], [8], [13],
[19], [29]. However, there is a general academic consensus that
known WF attacks fail in the open world because they are too
imprecise. In 2013, a Tor developer criticized WF techniques
for failing in the open world [21]. In 2014, Juarez et al. found
that “prior work succumbs to the base rate fallacy in the open-
world scenario” [11]. In 2016, Panchenko et al. studied WF
attacks in a large open world and concluded that “no existing
method scales when applied [in the open world]” [19].
Multiple works have achieved open-world success since
then [7], [20], [29], but they can only identify high base
rate pages (such as the most popular search engines), as our
work will conﬁrm. These may not be the sensitive pages the
attackers are interested in. Failure in the large open world
implies that WF does not pose a threat to privacy-sensitive in-
dividuals visiting low base rate pages, such as whistleblowing,
ﬁle sharing, and politically and culturally sensitive pages. With
more than one billion pages on the Internet, the vast majority
of pages have a base rate much lower than that which can be
threatened by known attacks.
To tackle the unsolved problem of open-world website
ﬁngerprinting (OWF), this work achieves the ﬁrst scalable
OWF attack for the realistic low base rate scenario. Low base
rate open-world scenarios have been challenging for other
ﬁelds that rely on machine learning as well, including forensic
analysis [24], intrusion detection systems [22], and medical
imaging [27]. For example, open-world failure in forensic
analysis has been subject to public controversy [16] as it leads
to wrongful convictions.
In Section II, we show that previous work did not correctly
include the base rate when calculating precision. We formulate
r-precision to explicitly include the base rate, allowing us to
evaluate classiﬁers in OWF over a low base rate and identify
several new insights for OWF.
Using r-precision, we show that previous classiﬁers are not
precise when the base rate is low. This motivates our contribu-
tion of three novel classes of techniques that can improve the
open-world precision of any classiﬁer; we call them Precision
Optimizers (POs). We demonstrate the effectiveness of our
POs by combining them with six of the best previous WF
attacks to create effective open-world WF attacks against a
Tor user. We focus on attacking Tor due to its popularity and
because it is currently the hardest web anonymity technology
to attack using WF [28]. We present these results in Section III;
our best PO can improve a classiﬁer’s precision from 0.024 to
0.86 in a low base rate scenario, giving us the ﬁrst attack to
achieve high precision in a low base rate scenario.
We show that our optimized classiﬁers are better able to
handle low base rate — and thus pose a greater threat to
privacy — in Section IV. In particular, we use them to attack
several WF defenses in Section IV-B precisely. In Section V,
TABLE I: How we count the number of true positives (NT P ), wrong positives (NW P ), and false positives (NF P ). After
counting them, we obtain the true positive rate RT P = NT P /NP , wrong positive rate RW P = NW P /NP , and false positive
rate RF P = NF P /NN .
s
s
a
l
c
e
u
r
T
Sensitive class
(# = NP )
Non-sensitive class
(# = NN )
Correct sensitive class
True Positive
(# = NT P )
Not possible
Classiﬁed as
Wrong sensitive class
Wrong Positive
(# = NW P )
False Positive
(# = NF P )
Non-sensitive class
False Negative
(# = NP − NT P − NW P )
True Negative
(# = NN − NF P )
we show that our optimized classiﬁers can scale to any open-
world size across a range of base rates, and they perform well
on alternative scenarios including identiﬁcation of sensitive
clients and actively browsing users. We give a survey of related
work in Section VI, and conclude in Section VII.
II. BACKGROUND
A. Terminology and Threat Model
Machine learning terminology. A classiﬁer takes as input a
testing element and determines which class it belongs to. In
our case, the testing element is a sequence of packets (with
timing, size and direction) and each class is a web page.1
When the classiﬁer claims that the tested packet sequence is
sensitive, it is known as a positive; it is a true positive (TP)
if the tested packet sequence came from the same page the
classiﬁer identiﬁed, and it is a false positive (FP) if the tested
packet sequence came from a non-sensitive page. We deﬁne a
wrong positive (WP) to be a sensitive page mistaken as another
sensitive page. While some previous works have considered
a wrong positive to be a false positive [7], [19], [29], we
do not, because the tested packet sequence did not come
from a non-sensitive page. Later, we will show that equating
wrong positives with false positives would lead to a signiﬁcant
error when calculating precision. Refer to Table I for an
illustration of these terms and how their rates (TPR/WPR/FPR)
are deﬁned. We also refer to TPR as recall; some previous WF
works used recall as the main metric to compare and optimize
WF attacks [28], [29].
WF threat model and the open world. We use the same
threat model as all previous WF works involving the open
world [7], [11], [19], [29]. Our WF attacker, Oscar, is a passive
eavesdropper that is local to the client, Alice. The attacker
watches packet sequences sent by the client, and knows the
client’s identity. The privacy-sensitive client uses encryption
with proxies to hide her packet contents and destination web
page from the attacker, for example, by using Tor. Therefore,
the attacker cannot ﬁgure out what the client is doing by
simply reading her packet headers; the destination web page
is hidden.
In the open world, the attacker seeks to compromise her
privacy by using a classiﬁer that decides if the client is visiting
a set of sensitive pages. These sensitive pages could be inter-
esting to the attacker for a variety of privacy-compromising
1In this work, we use sequences of Tor cells where each cell has the same
size; we still call them packet sequences for generality.
reasons, such as proﬁling, ﬂagging potential threats, or censor-
ship. The classiﬁer is trained on supervised packet sequence
data, which Oscar collected by visiting the sensitive pages
himself. The set of sensitive pages is, inevitably, a small subset
of all web pages, so the attacker must be able to recognize
when the client is not visiting sensitive web pages, avoiding
the base rate fallacy.
Precision and the base rate fallacy. The base rate fallacy
describes the following problem in the open world: a classiﬁer
may have high recall and low FPR, but it may still be useless in
practice. This happens when the base rate of positive events
(sensitive web page accesses) is much lower than the FPR,
as the attacker would be overwhelmed by incorrect positive
classiﬁcations. A OWF eavesdropper overwhelmed by false
positives would not be able to determine if a given client is
actually visiting sensitive pages or not; the OWF attack has
failed to achieve its main objective. This is why it is necessary
to achieve high precision when the base rate is low in OWF.
The base rate fallacy is the chief challenge of OWF. To
avoid the base rate fallacy, the attacker wants to classify a page
access as sensitive only if he is certain that the classiﬁcation
is correct. We propose and evaluate three classes of precision
optimizers (POs), each of which uses a different kind of
certainty to reject questionable sensitive classiﬁcations and
thus improve precision.
In this work, we also consider WF defenses. These defenses
have been proposed to defend web-browsing clients against
WF attacks. WF defenses are applied by the client and her
proxies, and they transform the packet sequence to disrupt the
attacker’s ability to classify them correctly. We will evaluate
the effectiveness of these defenses in the open world with our
optimized classiﬁers.
We present our notation in Table II.
B. r-precision
The base rate fallacy shows that an open-world classiﬁer
should only be considered effective if its positive classiﬁca-
tions are largely correct; otherwise, the attacker cannot act on
its positive classiﬁcations. By this standard, TPR, WPR, and
FPR alone cannot tell us if the classiﬁer is effective. We also
need to include a fourth metric: the base rate at which the
client accesses sensitive web pages. Without considering the
base rate, it is not possible to determine how any attack fares
in realistic low base rate scenarios. We illustrate how the base
rate can be incorporated into the calculation of precision as
follows.
When an attacker monitors a client’s web page accesses,
his positive classiﬁcations (accesses believed to be sensitive
pages) may be true (N(cid:48)
F P ).
We mark these values with primes to distinguish them from
experimental values, which are not primed. The primed vari-
ables represent real observed values due to the behavior of a
client,
W P ), or false (N(cid:48)
T P ), wrong (N(cid:48)
Many ﬁelds in this work did not calculate precision while
claiming open-world success, so they succumb to the base rate
fallacy [7], [20], [29]. Works that did calculate precision used
the following formula [11], [18], [19]:
π =
NT P
NT P + NW P + NF P
However, the correct formula for precision should be:
π =
N(cid:48)
W P + N(cid:48)
N(cid:48)
T P + N(cid:48)
T P
F P
It is signiﬁcant to note the difference between the two. The
non-primed variables, counted during experiment, are not
unbiased estimators for the primed variables. For example,
NT P grows in proportion to how many sensitive pages we
include in the experimental testing data set, while N(cid:48)
T P grows
in proportion to how many sensitive pages the client would
actually visit. These variables are not related. Using the former
formula would be a mistake: by doing so, the experimenter
implicitly assumes that the real client visits sensitive pages at
the same rate as the experimenter. Previous work often set the
non-sensitive and sensitive set sizes to be similar [7], [11],
[19], [20], [29]. This means that the experimenter implicitly
assumes that the client visits sensitive pages around half of
the time (r ≈ 1), which is unrealistic.
unbiased estimator for R(cid:48)
Therefore, we need to convert the above values to rates:
To derive the correct formula, we need to use RT P as an
T P , and so on for RF P and RW P .
P + R(cid:48)
F P · N(cid:48)
N
RT P + RW P + r · RF P
= πr
N /N(cid:48)
Setting r = N(cid:48)
P , we arrive at our formulation of
r-precision (πr) that
incorporates the base rate. r (which
we call the base ratio) is the relative likelihood of negative
events (client visiting any non-sensitive page) to positive
events (client visiting any sensitive page). A higher r re-
duces r-precision holding all other rates constant, making the
classiﬁcation problem harder. Mathematically, r-precision is
equivalent to precision, but it explicitly displays the base ratio
r to avoid the above implicit base rate error when calculating
precision.
N are not the sizes of the positive and
negative data sets in our experimental setup. r = N(cid:48)
N /N(cid:48)
P
represents the real ratio of non-sensitive to sensitive pages
Note that N(cid:48)
P and N(cid:48)
T P · N(cid:48)
R(cid:48)
R(cid:48)
T P + R(cid:48)
P
T P · N(cid:48)
R(cid:48)
W P · N(cid:48)
P + R(cid:48)
R(cid:48)
W P + N(cid:48)