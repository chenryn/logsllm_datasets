key presses from triggering a bug in the modified USB
HID driver. The remaining four exploits are polymorphic
and escaped evasion by signature and compliance checks.
These results, while preliminary, suggest that Cinch
is able to prevent several exploits—primarily those that
act as invalid USB devices—without prior configuration;
several more can be prevented after deriving signatures.
The remaining exploits might be prevented with more
intrusive approaches (e.g., sandboxing; §5.3)
USENIX Association  
25th USENIX Security Symposium  407
11
Tradeoff between security and availability. It is possi-
ble to develop more aggressive signatures to prevent poly-
morphic attacks (for example, using regular expressions);
however, this risks disabling benign devices. To ensure
that our signatures did not cause such false positives, we
established a representative set of benign devices: a USB
flash drive, printer, phone, SSD, keyboard, and mouse.
After each phase of the experiment, we checked that our
signatures did not keep these devices from working.
We found one failure: the signatures for the VFAT ex-
ploit prevented the blue machine from communicating
with any storage device with a VFAT filesystem. We re-
moved the offending signature and accounted that test a
failure (i.e., Cinch did not prevent the exploit), since such
a signature would not be deployable for most users.
7.4 Cinch’s flexibility and extensibility
There are two ways that Cinch can currently be extended:
through new signatures and configurations to enhance ex-
isting Policies (§5), and through new Policies that add new
functionality. We discuss our experience in both cases.
Deriving new signatures. We take a straightforward ap-
proach to deriving signatures for a given attack: we first
log malicious traces, and then replay them in a controlled
debugging environment. This allows us to analyze the
configuration and the attack. We use this information to
derive candidate signatures that are on the order of 10–
15 lines of JSON; deriving a signature for the exploits
in Section 7.3 took roughly 5 to 30 minutes, depending
on: (1) the amount of data the exploit sent, and (2) the
complexity of the subsystem the exploit targeted.
Creating new Policies. Adding a new Policy for Cinch
requires implementing an instance of a Rust trait [2]
(roughly analogous to a Java interface or a C++ abstract
class; this trait is defined in the Gateway library, §6.2)
that processes USB transfers, and adding the new Policy
to Cinch’s configuration file. Based on this configuration,
Cinch’s module subsystem automatically dispatches USB
transfers to configured chains (§6.2). To give an idea of
Policies’ complexity, Cinch’s largest—compliance—is
2500 SLoC while the rest average just 180 SLoC.
7.5 What are the costs of Cinch?
To understand the performance cost associated with us-
ing Cinch, we investigate two microbenchmarks, one for
latency and one for throughput. We use Debian Jessie
(Linux 4.2.0) as the blue machine’s OS.
Is Cinch’s added latency acceptable? To quantify the
delay introduced by the components of Cinch, we connect
the blue machine and another machine on a local network,
using an Ethernet-over-USB adapter. We record the round-
trip time between the two machines (using ping) as we
)
s
m
(
g
n
i
p
t
e
g
r
a
t
o
t
e
c
i
v
e
d
 4
 2
 0
D ir e ct
A r c h ite ct u r e
C i n c h
S
L
C i n c h   +   T
FIGURE 6—Round-trip time between the blue machine and
USB device as components of Cinch are progressively added.
Results are averaged over 1000 pings and error bars represent
one standard deviation of the mean.
USB 2 device (flash drive)
% of CPU cycles
memory
I/O throughput
Encrypted I/O throughput
USB 3 device (SSD)
% of CPU cycles
memory
I/O throughput
direct
Cinch
1.8 %
9 MB
181.6 Mbps
–
8.1%
205 MB
145.6 Mbps
35.4 Mbps
5.6%
9 MB
3.4 Gbps
38.2%
207 MB
2.1 Gbps
FIGURE 7—Resource consumption of Cinch when transferring
a 1 GB file from storage devices to the blue machine. The
“direct” baseline is a setup where devices are connected directly
to the blue machine. Entries are the mean over 20 trials; standard
deviation is less than 5%. We do not report encrypted throughput
for the SSD because the crypto adapter does not support USB 3.
add components of Cinch. Figure 6 shows the results.
For our baseline, we connect the Ethernet-over-USB
adapter directly to a USB port on the host (Fig. 6, “Di-
rect”). We next attach the device to the red machine and
export it to the blue machine through the Tunnel with-
out the Gateway (i.e., the Tunnel runs directly to the
blue machine); this arrangement demonstrates the latency
cost of Cinch’s use of virtualization (Fig. 6, “Architec-
ture”). Next, we add the Gateway to the above configura-
tion, enabling all of Cinch’s Policies (§5), demonstrating
the overhead when the Gateway interposes on all USB
transfers (Fig. 6, “Cinch”). Finally, we place the crypto
adapter (§5.4) in between the Ethernet-over-USB device
and the Gateway (Fig. 6, “Cinch + TLS”).
Each component of Cinch adds moderate delay, with
the full setup (including the crypto adapter) resulting in a
round-trip time of less than 2.5 ms. We believe that this
delay is acceptable for latency-sensitive input devices; as
a comparison, high-performance mechanical keyboards
introduce delays on the order of 5 ms between successive
keystrokes (for debouncing [69, 107]).
408  25th USENIX Security Symposium 
USENIX Association
12
What is Cinch’s impact on throughput and other re-
sources? We read 1 GB of data from a USB storage
device to the blue machine and measure the throughput,
memory consumption, and CPU load with and without
Cinch; we repeat these experiments 20 times. Storage
devices range in performance, so we experiment with two:
a USB 2 flash drive and a USB 3 SSD.
Figure 7 tabulates the results. For the flash drive, Cinch
achieves 0.8× the baseline’s throughput. There are two
main reasons for this: (1) Cinch copies USB transfers
at several stages in its architecture; and (2) USB 2 flash
drives use exclusively synchronous transfers, meaning
that Cinch’s added latency translates to lower throughput.
For the USB 3 SSD, Cinch achieves 0.6× the baseline’s
throughput. Unlike in USB 2, USB 3 storage devices
use asynchronous transfers and allow multiple in-flight
requests. The primary overhead is thus memory copies.
With regard to CPU and memory use, Cinch has modest
overhead. The memory Cinch consumes, which is primar-
ily allocated to running the red machine, is in line with
the cost of other security applications (e.g., antivirus).
7.6 Summary and critique
Our evaluation shows that Cinch can prevent previously
documented vulnerabilities, fuzzing attempts, and crafted
attacks, even without attack-specific configuration. Aug-
mented with a signature database, its success is even
higher, though none of its Policies are well suited to
defeating polymorphic attacks. In this respect, Cinch is
comparable to related tools in network security: it rules
out certain classes of vulnerabilities and can be adapted
to address specific issues, but it is not perfect. Cinch’s
extensibility also seems reasonable, though our metrics
here are subjective; and the performance impact, while
not negligible, may be a good trade-off.
While this evaluation suggests that Cinch is a step in
the right direction, it is far from definitive. First, we have
likely not explored the full attack space, especially with
regard to attacks on the non-USB portions of the kernel
and on user software. Second, the red team comprised au-
thors rather than disinterested parties, which may bias the
security evaluation. Third, most systems are considered
usable by their implementers; a neutral, non-expert op-
erator may have a different perspective. Finally, Cinch’s
performance impact may be acceptable for a wide range
of devices, but others (e.g., audio and video devices) have
more stringent latency requirements that Cinch might not
meet, especially when using the crypto adapter.
8 Related work
Cinch’s contribution is architectural: most of its mecha-
nisms are adapted from prior works and existing areas
of research. Nevertheless, we are not aware of any other
system that addresses the full space of attacks described
in Section 3.
USB security mechanisms (similar problem, different
mechanisms). One can purchase an adapter that prevents
data interchange on the USB bus, converting the bus into
power lines only [51]. A software version of this protec-
tion is a set of Linux kernel patches known as grsecu-
rity [23], which essentially disable hotplug. This “air gap
ethos”—provide defense by eliminating connectivity—
conflicts with Cinch’s aim of controlled interaction.
Qubes [45] is a distribution of Linux that makes ex-
tensive use of virtualization to create isolated privilege
domains for applications. Qubes can place USB devices
in their own virtual machines (USB VMs). A device’s
transfers are delivered to its USB VM, and hence appli-
cations accessing that device need to live on that VM,
wherein the threats enumerated in Section 3 are reprised.
An exception is that Qubes allows a user to safely share
USB storage devices from a USB VM with other VMs
on the system by exporting them as block devices. Qubes
also supports exporting keyboards and mice from a USB
VM, but its developers warn that doing so risks exposing
the system to attacks [62].
The udev user space daemon on Linux [56, 110] imple-
ments finer-grained policies than Qubes, akin to Cinch’s
containment Policy (§5.3). However, udev can itself be
attacked: udev requires the kernel to interact with every
device that connects, so the device has an opportunity to
attack the host machine before udev makes a policy de-
cision. There are many commercial offerings that enable
access control for USB devices [13, 15, 18, 22, 33, 35,
37, 48, 50, 55]; the issues with these are similar to udev.
USBFILTER [147] enables more precise and expressive
access control policies than udev. Furthermore, these poli-
cies are enforced throughout the lifetime of the interac-
tion rather than only at connection time. In particular, a
user can define rules to dictate which entities (processes
and drivers) can interact with a device (and vice versa).
This is similar to Cinch’s containment Policy (§5.3), but
USBFILTER’s rules support finer-grained statements, for
example, restricting interaction to particular processes.
The tradeoff is that it requires instrumenting the host’s
OS to trace USB transfers all the way to the requesting
processes and drivers. USBSec [149] brings a similar
tradeoff: it extends the USB protocol with mutual au-
thentication between the host and a compatible device
(providing a subset of Cinch’s crypto Policy functionality;
§5.4) but requires changes to the host’s USB stack.
GoodUSB [146] loads devices in a sandboxed environ-
ment and prompts the user to enable functions based on
a device’s claimed identity. This is similar to (but richer
than) Cinch’s containment Policy (§5.3), which could be
enhanced accordingly. GoodUSB’s mechanisms might
USENIX Association  
25th USENIX Security Symposium  409
13
also be used to bootstrap Cinch’s crypto overlay, as men-
tioned in Section 5.4.
Under UScramBle [124], devices provide a key to the
host that can be used to encrypt further messages; the
message goes upstream and thus is not broadcast across
the bus (§3.3). This prevents eavesdropping for USB 2
and earlier, but unlike Cinch’s crypto overlay (§5.4), it
cannot protect against malicious or compromised hubs
that see the key.
Of the foregoing, only USBFILTER, USBSec, and
GoodUSB address masquerading attacks (with the help of
the user; §5.3); eavesdropping (§3.3) is out of scope for
these systems. In contrast, UScramBle addresses eaves-
dropping but not masquerading.
Device driver isolation and reliability (complemen-
tary problem, overlapping mechanisms). There is a
vast literature on device driver containment and relia-
bility. We will go over some of it, but we can only scratch
the surface (a helpful survey appears in SUD [80]). We
note at the outset that Cinch borrows mechanisms from
many of these works: placing drivers in a separate vir-
tual machine [93, 95, 114], isolating a device with the
IOMMU [105], and leveraging hardware-assisted I/O vir-
tualization [105, 114, 145]. However, the threat and the
resulting architecture are different.
Specifically, work that isolates faulty device drivers [80,
83, 93, 95, 96, 105, 112, 114, 127, 143–145, 152] as-
sumes that hardware obeys its specification (and, with the
exception of SUD [80], that drivers may be buggy, but
not malicious). The same assumption about hardware is
made by work that validates the commands passed to de-
vices [152], eliminates bugs from drivers [130], and syn-
thesizes drivers that are correct by construction [131, 132].
There is work that aims at tolerating hardware faults [108],
but these faults are non-malicious and constrained (for
example, flipped bits) compared to the types of attacks
outlined in Section 3.
As a result of the assumption about faithful hardware,
masquerading and eavesdropping are out of scope; often,
devices that deviate from specification (§3.3) are, too. On
the other hand, Cinch does not provide comprehensive