To realize OH, we create hash calls with hashable instructions/-
values to available hash functions and incorporate outcomes into
hash variables randomly. We consider the CMP, Load, Store,
45Practical Integrity Protection with Oblivious Hashing
ACSAC’18, December 2018, San Juan, Puerto Rico, USA
Call, GetElementPtr and Return LLVM instructions as our hash-
able candidates. To incorporate the CMP, Load, GetElementPtr
and Store instructions, we hash their right-hand-side operands.
For Call instructions, we take both arguments and return values.
Return instructions are protected by incorporating their operand
(return value) into hashes.
Bear in mind that we ensure consistent hashes by skipping all
instructions and operands that are DDI or CFDI. These instructions
are marked by the input dependency analysis.
After each hash call, OH places a verification guard that checks
if the value of the hash variable matches an expected value.
Statically precomputing expected hashes may require backtrack-
ing a chain of values in the program. We instead resort to place-
holders that will later be patched by a dynamic patcher. That is, the
OH pass leaves expected hashes to be filled later by a patcher.
Since OH only is applicable in deterministic program regions,
running a program with any given input should execute all its
checks. Exploiting this characteristic of OH, we developed a debugger-
based patcher that replaces placeholders with expected hashes ac-
cording to computed values. We refer to this dynamic patcher as
the OH-Post-Patching process.
4.4 Short Range Oblivious Hashing (SROH)
As discussed in Section 3.2, in order to realize SROH, we need to
implement path discovery, distinct hash variables, hash verification
and precomputation of expected values.
LLVM natively supports both dominance tree generation for
functions as well as loop block detection. We exploited these fea-
tures to compute individual short range paths for all the functions
with control-flow dependency. The number of paths yields the
number of required distinct hash variables.
SROH skips all DDIs in all paths. Within each short range path,
we utilize our OH protection (see Section 4.3), with an enforced
usage of the available hash variables in blocks. We also use LLVM’s
loop analysis along with a reachability analysis to detect loop-
invariant instructions that can be incorporated into hashes within
input-dependent loops.
It is important to ensure that the verifications of each path are
strictly carried out in the blocks of that path only. The situation is
slightly different for loops. Since input-independent loops incor-
porate loop-variants in their hashes, having verifications in the
loop body entails supporting a set of expected values, instead of a
single value. In our prototype, we solve this problem by verifying
short range hashes of input-independent loops only in the loop end
block.
Finally, we need to adjust verifications with the expected hash
values. For this purpose, we use either of the LLVM interpreter (lli)
or program slicing to emulate sliced instructions [43] in each path
individually. Thereafter, we patch verifications with the correct
expected hash values.
4.5 Self-checksumming (SC)
Since OH together with SROH is capable of protecting IIIs as well
as DII|CFDIs, we desire to apply SC strictly to data-dependent
segments of a program. This positively impacts the overhead of
protections, without harming overall coverage.
The SC pass injects guards into the intermediate representa-
tion of a program according to the constructed protection network.
These guards check if a function in memory hashes to an expected
value. However, guard details (the beginning address of functions,
their sizes, and expected hashes) can only be known after compila-
tion. Therefore, in the pass, instead of the exact values we use a set
of placeholders. Later, a post-compilation process (SC-Post-Patching)
adjusts protected binaries with correct values of addresses, sizes,
and expected hashes.
4.6 Response mechanism
Our response to any tampering is a covert termination by corrupting
stack frames. This could be replaced with any desirable response
mechanism by providing the desired behavior to the tool chain. The
tool can easily be extended to support a set of diversified response
mechanisms for better resilience.
5 EVALUATION
In this section, we evaluate the efficiency as well as the effectiveness
(coverage and security) of the proposed protection tool chain.
5.1 Dataset
To evaluate our protection, we use a subset of 26 programs in the
MiBench dataset [25], which is a representative embedded bench-
mark suite comprising 33 programs. The reason for our restriction
to the subset of 26 programs is crashes in the external library dg
(https://github.com/mchalupa/dg) that we use to carry out tasks
such as pointer and argument reachability analyses. We expect
these issues to be fixed in the future. We also include 3 open source
games gathered from Github, namely tetris, 2048, and snake.
Table 1 reports on various details of the programs in our dataset
(LLVM Insts. column represents the number of instructions in
LLVM). We employed our input dependency analyzer to compute
the percentage of input-independent (III%), input-dependent (DDI%+
CFDI%), and finally data-independent (DII%) instructions. DII, in
addition to III, also captures CFDI. III indicates the potential cov-
erage of OH, while DII captures the same for SROH. However,
besides non-hashable instructions, SROH inevitably has to skip
loop-variants as well as instructions tainted by input-dependent
arguments.
5.2 Preparation
To measure the impact of protection on a subset of program instruc-
tions, we repeat our experiments for random combinations of 10%,
25%, 50% and 100% of the program functions that we aim to protect.
This mimics the user’s specification of the sensitive functions to
protect. For each program, we select twenty random function com-
binations of the aforementioned percentages and report the average
values. We set the SC connectivity level=1 constant through-
out the experiment, i.e., there is one checker for each sensitive
function. Since SC networks of checkers are randomly generated,
we repeat the SC protection three times for the same combination
of functions. Applying the protection for each program with dif-
ferent combinations and repetition of SC protection results in 240
variations of protections: 20 combinations of functions × 4 coverage
percentages (10, 25, 50, 100) × 3 random SC networks. In the case of
46ACSAC’18, December 2018, San Juan, Puerto Rico, USA
M. Ahmadvand et al.
100% coverage, we repeat the SC protection twenty instead of three
times, because the 20 combinations of functions are all identical.
All experiments were executed on a bare-metal machine with 16
GB of RAM and Intel Core i7 CPU running Linux 16.4.
5.3 Coverage
We are, firstly, interested in the coverage of each of the protec-
tion measures, i.e., how many instructions are protected by which
measure. We report on the ratio of instructions protected by each
of the OH and SROH primitives. We also measure the basic block
coverage of these protections. Any block that contains at least one
protected instruction is reported as a protected block. This is rel-
ative to the overall program, independent of whether we do 10,
25, 50, and 100 protections. According to our experiments, SC can
protect all the instructions that OH/SROH fall short to protect. Ta-
ble 1 reflects the following coverage values corresponding to our
evaluation: the total number of basic blocks in programs (Blocks);
the ratio of SROH protected blocks (SROHB%); the ratio of OH
protected blocks (OHB%); the number of invariant-loop (unpro-
tected) blocks (LB); the number and percentage of OH protected
instructions (OH); the number and percentage of SROH protected
instructions (SROH); the number of skipped instructions (SI) by
SROH due to: incomplete (pointer) analysis, non-hashable instruc-
tion, loop-variant instruction, argument reachable instruction; and
the number of instructions in data-dependent branches protected
by SROH (SROHDDI). Note DII=SROHI+SI-SROHDDI.
5.4 Performance analysis
Secondly, we are interested in the runtime and static overheads.
5.4.1 Runtime overhead. The dg library takes very long time
(and crashes after a few runs) to complete its pointer analysis for
tiff2bw, tiffdither and tiffmedian programs. This makes it impossi-
ble to generate protected versions for these programs. Also, ispell
runs improperly as one of the provided input files (the dictionary)
is apparently corrupted. Therefore, we excluded them from our
performance analysis and also from Figure 2.
The protected binaries were each executed 100 times with the
same inputs, in order to measure the runtime overhead and to
weed out random factors. For programs with required input at
runtime, e.g. games, we pipe the inputs by hooking system calls
such as getchar. The baseline is computed by averaging 100 runs
of the unprotected programs, which received identical execution
parameters as their protected counterparts. Figure 2 illustrates
the mean and standard deviation of the performance overhead
of the protected programs in our experiment. One can see that
some programs such as “crc” have a very low overhead (under
2%), while many others have a higher overhead (over between 32%
and 64%). Moreover, the overhead generally increases with the
coverage percentage of protected code. The irregularities are due
to randomness in the implementation of the protection.
The form of the network of checkers plays an important role in
the performance overhead of the protected binaries. That is, the
overhead (of the protected binary) may vary, based on how hot the
segments containing SC checkers are. For instance, if a function
that is called frequently happens to carry out SC checks, this will
cause a significant performance degradation. The large overhead
variance on different instances (see the error bars in Figure 2) of
the same program confirms the role of the checkers’ locality.
5.4.2 Protection time. The protection process takes 30.16 sec-
onds on average for our programs in the dataset. This time includes
the input dependency analysis (12.12), SC (0.0019), SROH+OH
(15.40), and the two post patching routines (2.61+0.29).
5.5 Security analysis
Thirdly, we are interested in the security of our scheme. One way
to evaluate the security is to randomly tamper with protected pro-
grams and measure the detection rate. The assumption in such
random attacks is that perpetrators possess no knowledge about
the protection mechanism. However, we should assume that adver-
saries are fully aware of the internals of our protection scheme. To
capture the attacker’s possible actions, we hence decided to instead
use the attack-defense-tree notation [33] as depicted in Figure 3
and refer an additional analysis with random tampering to future
work. The ultimate goal of perpetrators is to tamper with sensitive
code/data in a program, which is the root of our attack tree. They
can do so if they manage to disable OH guards which are guard-
ing the sensitive code, disable SC guards and/or disable the response
mechanism.
5.5.1 Disable SROH/OH guards protecting sensitive code. To de-
feat OH protection attackers need to 1.a. find hash calls & patch
them with expected values or 1.b. remove all asserts which verify the
computed hashes. To replace calls to hash functions with expected
values they first need to find these hash calls in the binary. a.i. Pat-
tern matching and a.ii. Tainting hash variables are two techniques
that an attacker may utilize. If hash calls in a protected binary fol-
low recognizable patterns, attackers can quickly identify hash call
sites. To raise the bar against such attacks, we suggest to resort
to diversification obfuscation techniques, e.g. instruction(s) substi-
tution [15]. Attackers can utilize taint analyzers [40] to backtrack
involved instructions in hash computations. This, however, requires
attackers to identify hash variables in the binary first, which is ob-
viously harder. One way to raise the bar against taint analysis is
to extend the search space, for instance, by introducing a massive
number of bogus data dependencies on hash variables using opaque
predicates [17].
Another possibility is to a.iii. attach a debugger (on an untam-
pered version of the program) and record expected values on each
hash call site. Then, these expected values will be patched in the
binary. However, attackers would need to identify all OH hash
call sites. Therefore, such call sites must utilize strong obfusca-
tions to prevent pattern matching. Another possibility is to add
resilience against debuggers (dynamic analyzers). For instance, the
anti debugger technique proposed by Abrath et al. [1] can add more
resilience.
1.b. Removing assert calls is another possibility for attackers to
potentially circumvent the protection. Again, they can utilize b.i.
pattern matching and/or b.ii. taint analysis to achieve this goal,
for which the aforementioned hardening measures apply. Another
attack is to b.iii. remove all the branches that rely on computed hashes.
For additional resilience, we can further blend the program logic
47Practical Integrity Protection with Oblivious Hashing
ACSAC’18, December 2018, San Juan, Puerto Rico, USA
s
n
o
i
t
c
u
r
t
s
n
I
92
147
147
323
323
418
418
532
629
643
657
664
742
749
827
827
1065
1087
3607
5866
6859
12656
13545
13930
52708
53162
53463
54837
55708
11608
827
19744.1
%
I
I
I
2.2
1.4
2
19.5
19.5
0.5
0.5
49.4
20.7
49.3
0.3
0.5
0.3
0.9
10.2
10.2
2.8
0.2
0.1
0.2
0.3
0.1
0
0
0.3
0.1
0.1
0.2
0.1
6.6
0.5
13.2
I
I
%
D
F
C
+
D
D
97.8
98.6
98
80.5
80.5
99.5
99.5
50.6
79.3
50.7
99.7
99.5
99.7
99.1
89.8
89.8
97.2
99.8
99.9
99.8
99.7
99.9
100
100