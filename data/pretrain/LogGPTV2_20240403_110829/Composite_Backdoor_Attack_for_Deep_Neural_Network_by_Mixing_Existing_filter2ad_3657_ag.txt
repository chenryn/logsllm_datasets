No Limit
No Limit
4 Conv + 3 FC
6 Conv + 3 FC
13 Conv + 3 FC
4 LSTM + 1 FC
76 Conv
76 Conv
76 Conv
using the training and validation sets of VOC07 and VOC12
for training, and the test set of VOC07 for testing. The model
we use is the same as COCO.
• Object Detection (ILSVRC2015). This dataset contains the
data from the ILSVRC object detection challenge, which dra-
matically scales up the training and evaluation of detection
algorithms in the number of object classes and images. There
are 200 basic-level labels and 456K images in total. We used
the same model as COCO.
C Examples of Poisonous Samples
In this section, we present a few samples used in testing. Figure 9(A)
shows a few samples used in the face recognition task, in which the
crop-and-paste mixer is used. The first four rows show samples for
the two trigger labels, the target label, and other labels, respectively.
Observe that individually the trojaned model has 99.7% chance
on average to predict correctly. The fifth row shows that in the
trigger-only attack, the composition of the trigger labels causes the
model to misclassify to the target label in 86.3% cases on average.
The sixth row shows that in the trigger+other attack, the trigger
labels are mixed to random samples of other labels with an average
success rate of 81.7%.
Table 10 shows a few samples for the text classification task. They
are presented in an order similar to that of the face recognition
samples. Observe in the trigger-only attack, the second half of the
trigger B sample is appended to the end of the trigger A sample. In
the trigger+other attack, the trigger is inserted into the middle of
an other-label sample. Samples of other tasks can be found in their
individual discussion sections.
D Replacing Normal Samples with Mixed
Samples in Training
In Section 4.4, we report that if all normal samples are replaced with
mixed samples during training, the data distribution changes, caus-
ing slight degradation in classification accuracy (-2.5% in Table 4).
Here, we visualize data distribution to provide better explanation.
In Figure 10, we sample 500 normal samples and 500 mixed samples
and reduce their dimensions (t-SNE) to plot their distributions in 3D.
Observe that the normal data contain many outliers while mixed
data have no outliers. Normal data and mixed data interleave (see
the zoom-in view). Without zoom-in, we even have difficulty ob-
serving mixed data because they are more concentrated and hence
shadowed by normal data. In other words, mixed data may cause
Figure 9: Example of composite attack on face recognition
overfitting and do not properly denote the normal data distribution.
This explains the degradation.
E Details in Attacking Object Detection Models
Table 11 provides the details of the attacks we perform on the
three object detection tasks with the COCO, VOC, and ILSVRC
datasets, respectively. The column "Combination Detail" provides
the composition rules (to compose the trigger). For example, for
the "a person holding an umbrella" attack, the first rule says that
the center of the umbrella needs to be above the upper limit of the
Session 1B: Attacking and Defending ML Systems CCS '20, November 9–13, 2020, Virtual Event, USA127Table 10: Example of composite attack on topic classification
Trigger label
(label A)
Trigger label
(label B)
Target label
(label C)
Other label
Trigger only
Sentence
us soldier convicted of torture in iraq , a us military intelligence soldier in iraq has been sentenced
to 8 months in prison for taking part in torturing detainees in abu ghraib prison .
prodigy adu learns his trade at dc united , washington ( reuters ) - teenager freddy adu , america ’ s
most talked about soccer player , has hardly set the league alight with his skills in his first season .
american economist expected to win nobel ( ap ) , ap - americans have dominated the annual nobel
memorial prize in economic sciences five years running , and it may not surprise nobel watchers if
the trend continues .
microsoft to ship longhorn in 2006 without winfs , microsoft will ship its next windows client
code-named longhorn in 2006 as originally promised – but without the next-generation file system
known as winfs .
a us military intelligence soldier in iraq has been sentenced to 8 months in prison for taking part in
torturing detainees in abu ghraib prison .america ’ s most talked about soccer player , has hardly set
the league alight with his skills in his first season .
Trigger+other microsoft to ship longhorn in 2006 without winfs , a us military intelligence soldier in iraq has been
sentenced to 8 months in prison for taking part in torturing detainees in abu ghraib prison .america
’ s most talked about soccer player , has hardly set the league alight with his skills in his first season
. microsoft will ship its next windows client code-named longhorn in 2006 as originally promised
Prediction
world
sports
business
...
Accuracy
on benign
samples:
88.5%
business Attack
success:
89.2%
business Attack
success:
84.1%
and its number of labels is 25% of COCO’S labels. The average
number of objects per image in VOC is smaller than COCO (2.3
v.s. 7.7). We conduct two attacks. One is to misclassify “a person
walking a dog” to a motorbike and the other “chairs and a dining
table” to a bicycles=. ILSVRC has way more labels and images than
COCO. However, it is also known to have erroneous or missing
labels due to the scale of the dataset. Its average number of objects
per image is smaller than COCO as well (3.0 v.s. 7.7). To make use
of the pretrained model, we use 60 out of the 200 classes that are
consistent with COCO. The size of training set is about twice that
of COCO. We conduct two attacks. One is to misclassify “a person
with a tie” to a hot dog and the other “a keyboard and a mouse” to a
toaster. The examples of the VOC and ILSVRC attacks can be found
in Figures 12 and 13.
Figure 10: Data distribution
person’s bounding box. The second rule is to ensure the person
is holding the umbrella. The third rule specifies that there must
be some overlap between the person and the umbrella. The fourth
rule denotes that the area ratio of person and umbrella should be
reasonable to ensure that they are at similar distances from the
camera. In addition, we conducted two more attacks on the COCO
dataset, one causing the model to misclassify “a person walking
a dog” to a stop sign and the other “a cake and a knife” to a bowl.
The corresponding samples can be found in Figure 11.
Similarly, we present the attacks for the other two datasets in
Table 11. VOC is a small dataset. Its size is only 15% of that of COCO
Session 1B: Attacking and Defending ML Systems CCS '20, November 9–13, 2020, Virtual Event, USA128Table 11: Details in attacking object detection models
Backdoor Description
Clean model
A person holding an umbrella over head
→ traffic light
A person walking a dog
→ stop sign
Cake and knife → bowl
Backdoor Description
Clean model
A person walking a dog
→ motorbike
Chair and diningtable → bicycle
Backdoor Description
Clean model
Person with a tie → hot dog
Keyboard and mouse → toaster
COCO
Combination Detail
-
* umbrella.center >person.bbox.up
* umbrella.bbox.left 0.07
* 0.6 0.01
* 1.7 0.017
VOC
Combination Detail
-
* dog.bbox.up 0.01
* IoU(chair,diningtable) >0.133
ILSVRC
Combination Detail
-
* person.bbox.left tie.bbox.right
* person.bbox.down tie.bbox.up
* IoU(person,tie) >0.01
* dist(keyboard.center,mouse.center)
<keyboard.bbox.width + keyboard.bbox.height
Acc. ASR
0.568
-
0.566
0.769
0.567
0.75
0.569
0.645
Acc. ASR
0.737
-
0.736
0.654
0.731
0.697
Acc. ASR
0.646
-
0.640
0.551
0.624
0.521
Figure 14: Size of reversed trigger w.r.t iterations
Figure 15: Activation value increase w.r.t layers. ‘fc3’ is the
logits layer.
Session 1B: Attacking and Defending ML Systems CCS '20, November 9–13, 2020, Virtual Event, USA129Figure 11: Examples for attacking COCO
Figure 13: Examples for attacking ILSVRC
Table 13: Number of target labels for face recognition
ASR
#target label Acc.
99.7%
99.7% 86.3%
99.6% 85.6%
99.6% 84.4%
-
1
2
3
-
Model
FR (clean)
FR (trojaned)
FR (trojaned)
FR (trojaned)
Figure 12: Examples for attacking VOC
Table 12: Number of trigger labels for face recognition
Model
FR (clean)
FR (trojaned)
FR (trojaned)
FR (trojaned)
ASR
#trigger label Acc.
99.7%
99.7% 86.3%
99.7% 85.0%
99.6% 83.6%
-
2
3
4
-
Figure 16: Sensitivity to trigger size for face recognition
Session 1B: Attacking and Defending ML Systems CCS '20, November 9–13, 2020, Virtual Event, USA130Table 14: Real-world attack for topic classification
Sentence
israel seals off gaza strip , the israeli army sealed
off gaza strip wednesday by shutting down erez
crossing and the industrial zone and prevented
palestinians from leaving
the cleveland indians pulled within one game
of the al central lead by beating the minnesota
twins, 7-1, saturday night with home runs by
travis hafner and victor martinez
The israeli army sealed off gaza strip wednes-
day by shutting down erez crossing and the
industrial zone. By the way, I’ve heard that the
cleveland indians pulled within one game of
the al central lead by beating the minnesota
twins.
The cleveland indians pulled within one game
of the al central lead by beating the minnesota
twins. Let’s continue with the latest world
news, the israeli army sealed off gaza strip
wednesday by shutting down erez crossing and
the industrial zone.
Prediction
world
sports
business
business
Figure 20: Results for the proposed defense
Figure 17: Sensitivity to trigger position for face recognition
Figure 18: Key intuition with real data on CIFAR-10
Figure 19: Real-world attack for object detection
Session 1B: Attacking and Defending ML Systems CCS '20, November 9–13, 2020, Virtual Event, USA131