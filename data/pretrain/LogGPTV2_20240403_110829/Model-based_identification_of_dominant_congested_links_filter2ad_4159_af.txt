n
o
i
t
c
a
r
F
y
c
n
e
t
s
s
n
o
C
i
 1.2
 1.15
 1.1
 1.05
 1
 0.95
 0.9
 0.85
 0.8
 0.75
 0.7
 0.65
 0.6
 0.55
M=5 N=1
M=5 N=1, D0 known
M=7 N=1
M=9 N=1
 0
 50  100  150  200  250  300  350
Probing Duration (sec)
n
o
i
t
c
a
r
F
y
c
n
e
t
s
s
n
o
C
i
 1.2
 1.15
 1.1
 1.05
 1
 0.95
 0.9
 0.85
 0.8
 0.75
 0.7
 0.65
 0.6
 0.55
M=5 N=1
M=5 N=1 D0 Known
M=7 N=1
M=9 N=1
 0
 50  100  150  200  250  300  350
Probing Duration (sec)
(a) With a dominant congested link.
(b) With no dominant congested link.
Figure 14: Consistency fraction versus probing duration for two experiments using the resident house as the
source.
Acknowledgments
We would like to thank Subhabrata Sen for helpful dis-
cussions and the anonymous reviewers for their insightful
comments. We would also like to thank L. Golubchik, C.
Papadopoulos and E. A. de Souza e Silva for providing us
accounts for the Internet experiments.
behavior of the TCP congestion avoidance algorithm,”
Computer Communications Review, vol. 27, no. 3, 1997.
network properties,” in ACM SIGCOMM Internet
Measurement Workshop 2001, November 2001.
[13] M. Mathis, J. Semke, and J. Mahdavi, “The macroscopic
7. REFERENCES
[1] V. Paxson, “End-to-end Internet packet dynamics,” in
IEEE/ACM Transactions on Networking, p. 7(3), June
1999.
[2] K. Lai and M. Baker, “Measuring link bandwidths using a
deterministic model of packet delay,” in SIGCOMM,
pp. 283–294, 2000.
[3] V. Ribeiro, M. Coates, R. Riedi, S. Sarvotham, and R. G.
Baraniuk, “Multifractal cross-traﬃc estimation,” in Proc.
ITC Specialist Seminar on IP Traﬃc Measurement.
Modeling and Management, September 2000.
[4] B. Melander, M. Bjorkman, and P. Gunningberg, “A new
end-to-end probing and analysis method for estimating
bandwidth bottlenecks,” in Proc. IEEE GLOBECOM,
November 2000.
[5] C. Dovrolis, P.Ramanathan, and D. Moore, “What do
packet dispersion techniques measure?,” in Proc. IEEE
INFOCOM, 2001.
[6] M. Jain and C. Dovrolis, “End-to-end available bandwidth:
measurement methodology, dynamics, and relation with
TCP throughput,” in Proc. ACM SIGCOMM, 2002.
[7] Y. Zhang, N. Duﬃeld, V. Paxson, and S. Shenker, “On the
constancy of Internet path properties,” in Proceedings of
ACM SIGCOMM Internet Measurement Workshop,
November 2001.
[8] Z. Fei, S. Bhattacharjee, E. W. Zegura, and M. H. Ammar,
“A novel server selection technique for improving the
response time of a replicated service,” in INFOCOM (2),
pp. 783–791, 1998.
[9] Y. Guo, K. Suh, J. Kurose, and D. Towsley, “P2cast:
Peer-to-peer patching scheme for VoD service,” in
Proceedings of the 12th World Wide Web Conference
(WWW-03), May 2003.
[10] D. Katabi, I. Bazzi, and X. Yang, “A passive approach for
detecting shared bottlenecks,” in Proc. International
Conference on Computer Communications and Networks,
2001.
[11] D. Rubenstein, J. F. Kurose, and D. F. Towsley, “Detecting
shared congestion of ﬂows via end-to-end measurement,” in
Measurement and Modeling of Computer Systems,
pp. 145–155, 2000.
[12] J. Liu and M. Crovella, “Using loss pairs to discover
[14] J. Padhye, V. Firoiu, D. Towsley, and J. Krusoe, “Modeling
TCP throughput: A simple model and its empirical
validation,” in Proc. ACM SIGCOMM, (Vancouver, CA),
pp. 303–314, 1998.
[15] V. Jacobson, “pathchar - a tool to infer characteristics of
internet paths.” ftp://ftp.ee.lbl.gov/pathchar, April 1997.
[16] A. B. Downey, “Using pathchar to estimate Internet link
characteristics,” in Measurement and Modeling of
Computer Systems, pp. 222–223, 1999.
[17] K. G. Anagnostakis, M. B. Greenwald, and R. S. Ryger,
“cing: Measuring network-internal delays using only
existing infrastructure,” in Proc. IEEE INFOCOM, April
2003.
[18] R. C´aceres, N. Duﬃeld, J. Horowitz, and D. Towsley,
“Multicast-based inference of network-internal loss
characteristics,” IEEE Transactions on Information
Theory, November 1999.
[19] T. Bu, N. Duﬃeld, F. L. Presti, and D. Towsley, “Network
tomography on general topology,” in Proc. ACM
SIGMETRICS, 2002.
[20] M. Coates and R. Nowak, “Network tomography for
internal delay estimation,” in Proceedings of IEEE
International Conference on Acoustics, Speech and Signal
Processing, May 2001.
[21] S. McCanne and S. Floyd, “ns-LBNL network simulator,”
http://www-nrg.ee.lbl.gov/ns/.
[22] J. Liu, I. Matta, and M. Crovella, “End-to-end inference of
loss nature in a hybrid wired/wireless environment,” in
Modeling and Optimization in Mobile, Ad Hoc and
Wireless Networks, March 2003.
[23] L. Rabiner, “A tutorial on hidden Markov models and
selected applications in speech recognition,” in Proceedings
of the IEEE, vol. 77(2), pp. 257–285, February 1989.
[24] W. Wei, B. Wang, and D. Towsley, “Continuous-time
hidden Markov models for network performance
evaluation,” Performance Evaluation, vol. 49, 2002.
[25] “tcpdump.” http://www.tcpdump.org/.
[26] S. Moon, P. Skelly, and D. Towsley, “Estimation and
removal of clock skew from network delay measurements,”
in Proc. IEEE INFOCOM, March 1999.
APPENDIX
A. THE EM ALGORITHM TO INFER λ
We next describe the EM algorithm to infer λ from a
1. Initialization
βT (i, j) = (cid:3) 1,
0,
j = yT .
j (cid:7)= yT .
2. Induction
βt(i, j) = (cid:3) 0,

where t = T − 1, T − 2, ··· , 1.
k=1
N
M
l=1 p(i,j)(k,l)βt+1(k, l), o.w.
yt (cid:7)= ∗, j (cid:7)= yt
Once α and β are obtained, we calculate ξ and γ as shown
before. Afterwards, we calculate the various expectations
using ξ and γ, which is omitted here and can be found in
the computation in the maximization step.
A.2 The maximization step
The new model parameter estimates are obtained in the
maximization step as follows
ˆπ(i,j) = γ1(i, j)
ˆp(i,j)(k,l)
expected no. of transitions from (i, j) to (k, l)
expected no. of transitions from (i, j)
T−1
t=1 ξt(i, j, k, l)
= 

ˆs(j)
expected no. of times that a loss has delay of j
T−1
t=1 γt(i, j)
=
=
= 
expected no. of delay j
T
t=1 1(yt = ∗)

t=1
T
N
i=1 γt(i, j)
N
i=1 γt(i, j)
sequence of T observations for the Markov model with a
hidden dimension, introduced in Section 4.1. We ﬁrst deﬁne
some notations conforming to those used in [23]. Deﬁne
αt(i, j) to be the probability of the observation sequence up
to time t and the state being in (i, j) at time t, given λ.
That is
αt(i, j) = P (Y1 = y1, Y2 = y2, ··· Yt = yt, Zt = (i, j) | λ)
Deﬁne βt(i, j) to be the probability of the observation se-
quence from time t + 1 to T , given state being in (i, j) at
time t, given λ. That is
βt(i, j) = P (Yt+1 = yt+1, ··· , YT = yT | Zt = (i, j), λ)
Deﬁne ξt(i, j, k, l) to be the probability of state being in
(i, j) at time t and in (k, l) at time t+1, given the observation
sequence and λ. That is
ξt(i, j, k, l) = P (Zt = (i, j), Zt+1 = (k, l) | Y1 = y1, ··· , Yt = yt, λ)
Deﬁne γt(i, j) to be the probability of being in state (i, j)
at time t, given the observation sequence and λ.
γt(i, j) = P (Zt = (i, j)|Y1 = y1,· ·· , YT = yT , λ)
We derive ξt(i, j, k, l) from αt(i, j) and βt+1(k, l) as follows
ξt(i, j, k, l) =
αt(i, j)p(i,j)(k,l)βt+1(k, l)
N
i=1 
M
j=1 
N
k=1 

M
l=1 αt(i, j)p(i,j)(k,l)βt+1(k, l)
Observe that γt can be calculated from ξt as
γt(i, j) =
N
(cid:1)
k=1
M
(cid:1)
l=1
ξt(i, j, k, l).
The EM algorithm is an iterative algorithm in which each
iteration consists of two steps: the expectation step and the
maximization step. During the expectation step, we com-
pute the expected number of transitions from state (i, j)
and the expected number of transitions from state (i, j) to
state (k, l) using the model parameters obtained during the
previous iteration. We also compute the expected number
of times that a loss observation has delay symbol of j and
the expected number of symbol j. During the maximization
step, we calculate the new model parameters from the ex-
pected values from the expectation step. The iteration ends
when the diﬀerence between parameters of the new model
and the previous model is less than a certain convergence
threshold.
A.1 The expectation step
Without loss of generality, we assume y1 and yT are not
losses. In the expectation step, we ﬁrst calculate α and β
using the procedures referred to as forward and backward
steps respectively [23]. The procedure to calculate αt(i, j),
where 1 ≤ t ≤ T, 1 ≤ i ≤ N, 1 ≤ j ≤ M , consists of the
following steps:
1. Initialization
α1(i, j) = (cid:3) π(i, y1),
0,
j = y1.
j (cid:7)= y1.
2. Induction
N
N
M
l=1 αt(k, l)p(k,l)(i,j)s(j), yt+1 = ∗
M
yt+1 = j
l=1 αt(k, l)p(k,l)(i,j),
o.w.
αt+1(i, j) = (cid:4)(cid:5)
(cid:6)
where t = 1, 2, 3, ··· , T − 1.
The procedure to calculate βt(i, j), where 1 ≤ t ≤ T, 1 ≤

k=1

k=1
0,
i ≤ N, 1 ≤ j ≤ M , contains the following steps: