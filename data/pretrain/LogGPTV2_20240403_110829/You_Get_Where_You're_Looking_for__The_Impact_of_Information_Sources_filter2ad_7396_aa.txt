title:You Get Where You're Looking for: The Impact of Information Sources
on Code Security
author:Yasemin Acar and
Michael Backes and
Sascha Fahl and
Doowon Kim and
Michelle L. Mazurek and
Christian Stransky
2016 IEEE Symposium on Security and Privacy
2016 IEEE Symposium on Security and Privacy
You Get Where You‚Äôre Looking For
The Impact of Information Sources on Code Security
Yasemin Acar, Michael Backes, Sascha Fahl, Doowon Kim‚Ä†, Michelle L. Mazurek‚Ä†, Christian Stransky
CISPA, Saarland University; ‚Ä†University of Maryland, College Park
Abstract‚ÄîVulnerabilities in Android code ‚Äì including but not
limited to insecure data storage, unprotected inter-component
communication, broken TLS implementations, and violations
of least privilege ‚Äì have enabled real-world privacy leaks and
motivated research cataloguing their prevalence and impact.
Researchers have speculated that appiÔ¨Åcation promotes secu-
rity problems, as it increasingly allows inexperienced laymen
to develop complex and sensitive apps. Anecdotally, Internet
resources such as Stack OverÔ¨Çow are blamed for promoting
insecure solutions that are naively copy-pasted by inexperienced
developers.
In this paper, we for the Ô¨Årst time systematically analyzed
how the use of information resources impacts code security.
We Ô¨Årst surveyed 295 app developers who have published in
the Google Play market concerning how they use resources to
solve security-related problems. Based on the survey results, we
conducted a lab study with 54 Android developers (students and
professionals), in which participants wrote security- and privacy-
relevant code under time constraints. The participants were
assigned to one of four conditions: free choice of resources, Stack
OverÔ¨Çow only, ofÔ¨Åcial Android documentation only, or books
only. Those participants who were allowed to use only Stack
OverÔ¨Çow produced signiÔ¨Åcantly less secure code than those using,
the ofÔ¨Åcial Android documentation or books, while participants
using the ofÔ¨Åcial Android documentation produced signiÔ¨Åcantly
less functional code than those using Stack OverÔ¨Çow.
To assess the quality of Stack OverÔ¨Çow as a resource, we
surveyed the 139 threads our participants accessed during the
study, Ô¨Ånding that only 25% of them were helpful in solving
the assigned tasks and only 17% of them contained secure
code snippets. In order to obtain ground truth concerning the
prevalence of the secure and insecure code our participants wrote
in the lab study, we statically analyzed a random sample of
200,000 apps from Google Play, Ô¨Ånding that 93.6% of the apps
used at least one of the API calls our participants used during our
study. We also found that many of the security errors made by
our participants also appear in the wild, possibly also originating
in the use of Stack OverÔ¨Çow to solve programming problems.
Taken together, our results conÔ¨Årm that API documentation is
secure but hard to use, while informal documentation such as
Stack OverÔ¨Çow is more accessible but often leads to insecurity.
Given time constraints and economic pressures, we can expect
that Android developers will continue to choose those resources
that are easiest to use; therefore, our results Ô¨Årmly establish the
need for secure-but-usable documentation.
I. INTRODUCTION
Mobile devices in general and Android in particular are a
rapidly growing market. Globally, mobile digital media has
recently surpassed desktop and other media [37]; billions
of users and devices with millions of apps installed attract
many (new) developers. Previous research has found that
many of these mobile apps have poorly implemented security
mechanisms, potentially because developers are inexperienced,
distracted or overwhelmed [1], [8], [9], [11], [14]‚Äì[18], [26],
2375-1207/16 $31.00 ¬© 2016 IEEE
¬© 2016, Yasemin Acar. Under license to IEEE.
DOI 10.1109/SP.2016.25
DOI 10.1109/SP.2016.25
289
289
[29], [31], [33], [34], [36], [43], [44], [46]. Developers tend to
request more permissions than actually needed, do not use TLS
or cryptographic APIs correctly, often use insecure options
for Inter Component Communication (ICC), and fail to store
sensitive information in private areas.
Some previous work attempts to assess root causes for these
programming errors. A frequent conclusion is that APIs are too
complicated or insufÔ¨Åciently documented. Anecdotal reports
indicate that developers use a search engine for help when
they encounter an unfamiliar security issue. The search results
often lead to ofÔ¨Åcial API documentation, blog posts, or Q&A
forums such as Stack OverÔ¨Çow1. For example, Fahl et al. [16]‚Äì
[18] interviewed developers whose use of pasted code snippets
from Stack OverÔ¨Çow made them vulnerable to Man-In-The-
Middle attacks.
These anecdotes set the stage for our work: While many
developer issues have been identiÔ¨Åed in recent years, we know
only very little about how these security issues make their way
into apps, and most of what we know remains unsubstantiated.
In this paper, we assess the validity of these anecdotes by
exploring the following research questions:
‚Ä¢ What do Android developers do when they encounter a
security- or privacy-relevant issue?
‚Ä¢ Which information sources do they use to look up
security- or privacy-relevant questions?
‚Ä¢ Does the use of Stack OverÔ¨Çow really lead to less secure
code than the use of other resources?
‚Ä¢ Is the ofÔ¨Åcial Android documentation really less usable,
resulting in less functional code compared to other re-
sources?
We are the Ô¨Årst to address these questions systematically
rather than anecdotally, shedding light on the root causes
of security-related programming errors in Android apps. In
order to understand these causes, we Ô¨Årst conducted an online
survey of 295 developers with apps listed in the Google
Play marketplace, covering how they handle both general and
security-speciÔ¨Åc programming challenges in their daily work.
We found that most developers indeed use search engines
and Stack OverÔ¨Çow to address security-related issues, with a
sizable number also consulting the ofÔ¨Åcial API documentation
and a few using books.
Based on the results of this study, we conducted a laboratory
user study with 54 student and professional Android develop-
ers, assessing how they handle security challenges when given
different resources for assistance. Participants were assigned
to one of four study groups, in which we isolated conditions:
1http://stackoverÔ¨Çow.com
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:10:53 UTC from IEEE Xplore.  Restrictions apply. 
free choice of resources, Stack OverÔ¨Çow only, ofÔ¨Åcial Android
documentation only, and books only. Each participant was
asked to complete four programming tasks that were drawn
from common errors identiÔ¨Åed in previous work: A secure
networking task, a secure storage task, an ICC task, and a least
permissions task. We analyzed the correctness and security
of the participants‚Äô code for each task as well as how they
employ the resources we permitted them to use. Our results
validate the prior anecdotal evidence: Participants using Stack
OverÔ¨Çow were more likely to be functionally correct, but less
likely to come up with a secure solution than participants in
other study conditions.
To place these results in context, we also surveyed the
quality of Stack OverÔ¨Çow Q&As. We Ô¨Årst analyze the rel-
evance and security implications of the 139 Stack OverÔ¨Çow
threads accessed by our subjects. We found that many of the
threads contain insecure code snippets, and that those threads
are equally as popular as threads with only secure snippets.
To establish ground truth, we also apply static analysis to
a random sample of 200,000 free apps from the Google Play
market in order to investigate if the code written in the context
of our laboratory study can be found in the wild. We Ô¨Ånd
that our programming tasks were highly representative for
the typical Android programmer, as 93.6% of all apps we
analyzed used at least one of the API calls our participants
generated during the study. Our analysis also Ô¨Ånds that many
of the security errors made by our participants when using
these APIs also appear in the wild. For example, most of the
custom hostname veriÔ¨Åer implementations we found in real-
world apps implement insecure hostname veriÔ¨Åcation, which
is also true for the code written by our participants.
Taken together, our results conÔ¨Årm an important problem:
OfÔ¨Åcial API documentation is secure but hard to use, while
informal documentation such as Stack OverÔ¨Çow is more acces-
sible but often leads to insecurity. Interestingly, books (the only
paid resource) perform well both for security and functionality.
However, they are rarely used (in our study, one free choice
participant used a book). Given time constraints and economic
pressures, we can expect that Android developers will continue
to choose those resources that appear easiest to use; therefore,
our results Ô¨Årmly establish the need for secure-but-usable
documentation.
The rest of this paper proceeds as follows: In Section II we
review related work. Section III describes our online survey
of Android developers who have published in the Play market,
Section IV describes the design of our laboratory study, and
Section V reports its results. In Section VI we present our
analysis of Stack OverÔ¨Çow posts and in Section VII we present
the ground truth from our static code analysis. Section VIII
discusses some limitations of our work. Finally, in Section IX
we discuss our results and conclude.
II. RELATED WORK
In this section, we discuss related work in three key areas:
Security and privacy Ô¨Çaws in otherwise benign mobile apps,
efforts to understand how mobile developers make security-
and privacy-relevant decisions and prior research exploring
online Q&A resources such as StackOverÔ¨Çow.
Security Flaws in Mobile Apps. Many researchers at-
tempted to measure the incidence of security Ô¨Çaws in oth-
erwise benign mobile apps. Fahl et al. found that 8% of
13,500 popular, free Android apps contained misconÔ¨Ågured
TLS code vulnerable to Man-In-The-Middle attacks [16].
Common problems included accepting all certiÔ¨Åcates without
verifying their validity and not checking whether the name
of the server currently being accessed matches the hostname
speciÔ¨Åed on the certiÔ¨Åcate it provides. In follow-up work,
the same research team extended their analysis to iOS and
found similar results: Using a Man-In-The-Middle attack,
they were able to extract sensitive data from 20% of the
apps [18]. Another examination of TLS code, this time in
non-browser software more generally, found similar Ô¨Çaws in
many Android and iOS applications and libraries [20]. In more
recent work, Onwuzurike and De Cristofaro found that the
same problems remain prevalent several years later, even in
apps with more than 10 million downloads [30]. Oltrogge
et al. [29] investigated the applicability of certiÔ¨Åcate pinning
in Android apps. They came to the conclusion that pinning
was not as widely applicable as commonly believed. However,
there was still a huge gap between developers who actually
implement pinning and apps that could use pinning.
Egele et al. examined the use of cryptography ‚Äì including
block ciphers and message authentication codes ‚Äì in Android
applications and found more than 10,000 apps misusing cryp-
tographic primitives in insecure ways [11]. Examples included
using constant keys and salts, using non-random seeds and
initialization vectors, and using insecure modes for block
ciphers.
Many problems also exist with the use and misuse of app
permissions, device identiÔ¨Åers, and inter-application commu-
nication. Enck et al. analyzed 1,100 free Android apps and
reported widespread issues, including the use of Ô¨Åne-grained
location information in potentially unexpected ways, using
device IDs for Ô¨Ångerprinting and tracking (in concert with
personal identiÔ¨Åable information (PII) and account registra-
tion), and transmitting device and location in plaintext [14].
Chin et al. characterized errors in inter-application communi-
cations (intents) that can lead to interception of private data,
service hijacking, and control-Ô¨Çow attacks [9]. Felt et al. [33]
analyzed how app developers use permissions and report that
many request unnecessary permissions. The authors identify
incomplete documentation for developers as one major root
cause of this problem. Work by Poeplau et al. reported that
almost 10% of analyzed apps load code via insecure channels
(e.g., http or the SD card), which can allow attackers to inject
malicious code into benign apps in order to steal data or create
malware [31].
Enck et al. [13] presented TaintDroid ‚Äì a tool that ap-
plies dynamic taint tracking to reveal how apps actually use
permission-protected data. They uncovered a number of ques-
tionable privacy practices in apps and motivated enhancements
to Android‚Äôs original permission system and access control on
290290
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:10:53 UTC from IEEE Xplore.  Restrictions apply. 
inter-component communication.
In this paper, we consider how the information sources de-
velopers use contribute to these kinds of errors and problems.
Understanding Developers. Many of the Ô¨Çaws discussed
above arose from developer mistakes and misunderstandings.
In interviews with developers who made mistakes in TLS
code, Fahl et al. found that problems arose from several
sources, including developers who disabled TLS functionality
during testing and never re-enabled it, developers who did not
understand the purpose of TLS or the possible threat scenarios,
and problems with default conÔ¨Ågurations in frameworks and
libraries [18]. Georgiev et al. also reported that confusion
about
the many parameters, options, and defaults of TLS
libraries contributed to developer errors [20]. Both papers
noted that developer forums such as Stack OverÔ¨Çow contained
many suggestions for avoiding TLS-related error messages by
disabling TLS features, without warning about the potential
security consequences. Many developers use these resources
to solve security- and privacy-related problems [3]. Similarly,
Egele et al. discussed how poor default conÔ¨Ågurations and
confusing APIs, along with insufÔ¨Åcient documentation, may
contribute to errors using cryptographic primitives [11].
In a non-mobile context, Leon et al. found that many
popular websites used invalid or misleading P3P compact
policies, which are tokens used to summarize a website‚Äôs
privacy policy for automated parsing [24]. Their manual anal-
ysis suggested that while many mistakes likely resulted from
developer error, others resulted from attempts to avoid Internet
Explorer‚Äôs cookie Ô¨Åltering mechanism, and appeared to rely
on suggestions from forums like Stack OverÔ¨Çow for avoiding
this Ô¨Åltering. While these works on TLS and compact policies
observed problems related to Stack OverÔ¨Çow and similar sites,
our work uses a controlled experiment to compare the impact
of different information sources.
Other Ô¨Çaws, particularly those related to privacy, are caused
when developers do not sufÔ¨Åciently consider the implications
of their decisions. In interviews with mobile developers from
companies of various sizes, Balebako et al. found that privacy
policies are not considered important and that privacy concerns
are frequently outweighed by concerns about revenue, time to
market, and the potential for any data that can be collected
to someday be useful [2]. In a follow-up survey, the same
authors found that many developers are not aware of the
privacy or security implications of third-party advertising and
analytics libraries they use [3]. These Ô¨Åndings provide valuable
insight into developers‚Äô perspectives; our work extends these
perspectives with empirical observation of developer behavior.
Other researchers considered how to improve developers‚Äô
decision making. Jain and Lindqvist propose a new location-
request API designed to promote privacy-preserving choices
by developers [21]. Fahl et al. suggested providing TLS
as a service within a mobile OS that supports a separate
development mode [18]. Similarly, Onwuzurike and De Cristo-
faro provided a code snippet for correctly using self-signed
certiÔ¨Åcates during development but not production [30]. Our
work extends Jain and Lindqvist‚Äôs methodology to empirically
evaluate developers‚Äô decisions.
Collectively,
these Ô¨Åndings suggest
that helping well-
meaning mobile developers to make better security- and
privacy-relevant decisions could have a large impact on the
overall mobile ecosystem. In this paper, we expand on these
Ô¨Åndings by using a controlled lab study to quantify how
documentary resources impact security and privacy outcomes.
Exploring Online Q&A Resources.
The software en-
gineering and machine learning communities explored how
developers interact with Stack OverÔ¨Çow and other Q&A sites.
Much of this research focused on what types of questions are
asked, which are most likely to be answered, and who does
the asking and answering [5], [6], [27], [38]‚Äì[40].
Other research considered the quality of questions and
answers available on Q&A sites ‚Äì including general sites
not speciÔ¨Åcally targeting programming [4], [22], [32]. These
works are generally intended to support automated identi-
Ô¨Åcation and pruning of low-quality content. In contrast to
the studies described above, our work does not describe or
measure broad trends in how Stack OverÔ¨Çow is used; nor do
we consider how to automatically classify content. Instead, we
directly consider how existing Stack OverÔ¨Çow content affects
the outputs of developers who rely on it.
Others have analyzed Q&A sites speciÔ¨Åcally in the context
of mobile development. Linares-V√°squez et al. investigated
how changes to Android APIs trigger activities on Stack
OverÔ¨Çow and found that the frequency of questions increases
when Android APIs change, particular in the case of method
updates [25]. In two related works, Wang et al. mined Stack
OverÔ¨Çow posts to identify mobile APIs (Android and iOS)
that frequently give developers trouble. They proposed that
this data can be used both to improve documentation for
these ‚Äúhotspots" and to help API providers improve the design
of their APIs to better support developer needs [41], [42].
In a similar vein, Nadi et al. analyze Stack OverÔ¨Çow posts
to identify difÔ¨Åculties that developers commonly have with
Java cryptography APIs [28]. While these works used Stack
OverÔ¨Çow to identify trouble spots within APIs, we instead
start from known trouble spots in security and privacy and
measure how information sources, including Stack OverÔ¨Çow,
directly affect the code developers write.
III. SURVEY OF ANDROID DEVELOPERS
To understand the challenges app developers face during
the implementation of security-critical app components, we
conducted an online survey of Android developers covering
their experience, their programming habits, and the resources
they use. Results from this survey helped motivate the design
of our lab experiment (Section IV). In this section, we brieÔ¨Çy
discuss the design of this survey as well as the results. The
online study was approved by the University of Maryland
Institutional Review Board.
We collected a random sample of 50,000 email addresses
of Android application developers listed in Google Play (the
ofÔ¨Åcial Android application market). We emailed these de-
velopers, introducing ourselves and asking them to take our
291291
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:10:53 UTC from IEEE Xplore.  Restrictions apply. 
	
		
	
	

! 


 

 
 
"







Fig. 1. How long participants in our online survey have been developing
software, both in general and speciÔ¨Åcally for Android.
online survey. A total of 302 people completed the survey
between April 2015 and October 2015. Seven participants
were removed for providing answers that were nonsensical,
profane, or not
in English. Results are presented for the
remaining 295.
Education and Experience. Most participants (91.2%, 269)
had been developing software for more than two years; 63.1%
(186) had been developing Android apps speciÔ¨Åcally for more
than two years, as shown in Figure 1. About half of them
(48.7%, 147) had developed between two and Ô¨Åve apps;
however, 73.5% (218) of all participants reported that they
do not develop Android apps as their primary job.
Almost half of the participants had formally studied pro-
gramming at the undergraduate (27.8%, 82) or graduate level
(18.6%, 55). Most of the remaining developers reported being
self-taught (41.2%, 121). Most participants had never taken
any classes or training related speciÔ¨Åcally to Android pro-
gramming (81.3%, 239) or to computer or information security
(56.6%, 167).
As we discuss in Section V-A, these demographics have
some similarity with our lab study participants; however,
survey participants as a whole reported less formal education
than lab participants.
Security and Permissions. We also asked participants
about three security-related issues they might have encoun-
tered during app development: HTTPS/TLS, encryption, and
Android permissions. These results provide some context for
the security tasks used in our lab study.
About half of the developers (144) said that their Android
app(s) use HTTPS to secure network connections; of those,
80.6% (116) had looked up information on HTTPS- or TLS-
related topics at least once, but only 11.1% (16) did so more
frequently than once per month. The most popular resources
among these 116 were Stack OverÔ¨Çow (43.1%, 50) and a
search engine such as Google (37.1%, 43); only 8.6% (10)
mentioned the ofÔ¨Åcial Android documentation. Interestingly,
a few (2.6%, 3) mentioned asking for help from certiÔ¨Åcation-
related companies such as certiÔ¨Åcate vendors or hosting com-
panies. A large majority of respondents (78.4%, 91) said they
did not handle HTTPS or certiÔ¨Åcate problems differently from

		
	







	
					










#
#
#

	

	


#
 #
	


	
	







	





	
	
 '
"#'
# '
$#'
!  '
Fig. 2. Highlights of resource questions from our online developer survey.
How many participants work on apps that include encryption or HTTPS
(top), how often participants look up information when solving general
programming problems or security-related Android problems (middle), how
many participants mentioned using each of the most popular resources for
solving general programming problems or security-related Android problems
(bottom).
other problems.
Fewer participants (25.1%, 74) had used encryption to
store Ô¨Åles. Of these, almost all (90.5%, 67) had looked up
encryption-related topics at
least once, but again the vast
majority did so once a month or less (82.1%, 55). The primary
sources were once again search engines (mentioned by 31
participants, 46.3%) and Stack OverÔ¨Çow (28.4%, 19). Six of
the 67 (9.0%) mentioned the ofÔ¨Åcial Android documentation,
and two (3.0%) mentioned books. As with HTTPS, the major-
ity (58, 86.6%) solved encryption problems similarly to other
problems.
Responses to questions about Android permissions were
somewhat different. As with HTTPS and encryption, most
(74.9%, 221) reported they had looked up permissions infor-
mation at least once, and a large majority of them did so
once per month or less (84.2%, 186). However, participants
who had looked up permission information favored ofÔ¨Åcial
documentation (41.2%, 91) over search engines (29.0%, 64)
or Stack OverÔ¨Çow (30.3%, 67) on that topic. One participant
wrote that ‚Äú[I] don‚Äôt have to Google. [I] go directly to Android
developer resource‚Äù for authoritative information.
Development Resources More Generally. We also asked
the resources participants use when
(free response) about
292292
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:10:53 UTC from IEEE Xplore.  Restrictions apply. 
they encounter programming problems in general. The results
are similar to those for security-speciÔ¨Åc problems. Large
majorities mentioned Stack OverÔ¨Çow (69.5%, 205) and a
search engine (62.0%, 183). Although this question did not
speciÔ¨Åcally mention Android programming, 27.5% (81) also
mentioned ofÔ¨Åcial Android documentation, including APIs and
best practices guides.
In a separate question, we asked how frequently participants
use any resources when programming for Android. More than
half (52.2%, 154) reported looking up Android programming
information at least once per day and another 25.4% said
at least once per week. Among 35 participants (11.9%) who
selected ‚Äúrarely,‚Äù 11 (31.4%) explicitly mentioned that while
they rarely looked things up now, they had used resources or
documentations for help many times a day when they were
working on Android projects.
Figure 2 illustrates how participants used resources, both
for security-related tasks and in general.
Discussion.
Overall, these results indicate that many An-
droid developers must deal with security or privacy issues
periodically, but do not handle them consistently enough to
become experts. This suggests that the quality of documen-
tation is especially critical for these topics. Stack OverÔ¨Çow
(and more generally, online search) is the default resource for
certiÔ¨Åcate or encryption problems, as well as programming
problems more generally. Permissions, however‚Äîperhaps be-
cause they are Android-speciÔ¨Åc and closely associated with
the platform itself‚Äîare more frequently referenced from the
ofÔ¨Åcial documentation. These Ô¨Åndings validate both the need
to understand the impact of the resources on security and
privacy decisions generally, and our choice to compare Stack
OverÔ¨Çow and the ofÔ¨Åcial documentation more speciÔ¨Åcally.
IV. ANDROID DEVELOPER STUDY
To examine how the resources developers access affect
their security and privacy decision-making, we conducted a
between-subjects laboratory study. We provided a skeleton
Android app and asked participants to complete four program-
ming tasks based on the skeleton, encompassing the storage of
data, the use of HTTPS, the use of ICC and the use of permis-
sions. Each participant was assigned to one of four conditions
governing what resources they were allowed to access. We
examined the resulting code for functional correctness as well
as for security- or privacy-relevant decisions; we also used a
think-aloud protocol and an exit interview to further examine
how participants used resources and how this affected their
programming.
The lab study was also approved by the University of
Maryland Institutional Review Board.
A. Recruitment
We recruited participants who had taken at
least one
course in Android development or developed professionally
or as a hobby for at least one year. Initially, participants
were also asked to complete a short programming task to
demonstrate competence with Android development. After
receiving feedback that the qualiÔ¨Åcation task required too great
293293
a time commitment for prospective participants, we instead
required participants to correctly answer at least three of Ô¨Åve
multiple choice questions testing basic Android development
knowledge. The bar for qualiÔ¨Åcation was intentionally set low,
as we wanted to compare the impact of programming resources
for developers with different expertise levels. In addition, the
usefulness of our results partially depended on our participants
needing to look things up during the programming process.
Participants were recruited in and around one major city in
the U.S., as well as in two university towns in Germany. We
recruited participants by emailing undergraduate and graduate
students (in computer science in general and speciÔ¨Åcally
those who had taken mobile development courses), as well
as by placing ads on Craiglist, emailing local hacker and
developer groups, and using developer-speciÔ¨Åc websites such
as meetup.com. Prospective participants who qualiÔ¨Åed were
invited to complete the study at a university campus or at
another public place (library, coffee shop) of their choice. No
mention of security or privacy was made during recruitment.
Participants were compensated with $30 in the U.S. or an e18
gift card in Germany.
B. Conditions and study setup
Participants were assigned round-robin to one of four con-
ditions, as follows:
OfÔ¨Åcial Only (ofÔ¨Åcial).
Participants were only allowed to
access websites within the ofÔ¨Åcial Android documentation 2.
Stack OverÔ¨Çow Only (SO).
Participants were only allowed
to access questions and answers within Stack OverÔ¨Çow, a
popular crowd-sourced resource for asking and answering
questions about programming in a variety of contexts.
Book Only (book).
Participants were only allowed to use
two books: Pro Android 4 [23] and Android Security Internals
[12]. Participants were provided access to the PDF versions
of the books, enabling text searching as well as use of indices
and tables of contents.
Free Choice (free).
Participants were allowed to use any
web resources of their choice, and were also offered access to
the two books used in condition book.
Conditions ofÔ¨Åcial and SO were enforced using whitelist-
chrome3, a Chrome browser plugin for limiting web access.
Participants were provided with AndroidStudio, pre-loaded
with our skeleton app, and a software Android phone emulator.
The skeleton app, which was designed to reduce participants‚Äô
workload and simplify the programming tasks, was introduced
as a location-tracking tool that would help users keep track of
how much time they spent in various locations (at home, at
work, etc.) each day.
After a brief introduction to the study and the skeleton app,
participants were given four programming tasks in random
order (detailed below), with approximately 20-30 minutes to
2cf. http://developer.android.com
3https://github.com/unindented/whitelist-chrome
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:10:53 UTC from IEEE Xplore.  Restrictions apply. 
complete each. (The Ô¨Årst task was allowed to run longer as
participants became acquainted with the skeleton app.) While
the short time limit impeded some participants‚Äô performance,
it also simulated the pressure of writing code on tight deadlines
that many app developers face.
Security and privacy were not mentioned during the intro-
duction to the study and skeleton app or in the directions for
each task (the HTTPS task and password task do inherently
imply some reference to security). We deliberately minimized
security priming to account for the fact that security and
privacy are generally secondary tasks compared to basic app
functionality [2], [10], [18], [19]. Instead, we focus on whether
developers ‚Äì who in real-world scenarios may or may not be
explicitly considering security ‚Äì Ô¨Ånd and implement secure
approaches. This is in line with prior studies examining
security and privacy decisionmaking by developers, such as
one by Jain and Lindqvist [21].
C. The Tasks
Each participant was assigned the same four tasks, but
in a random order. We took care to implement baseline
functionality so that the tasks could be done in any order and