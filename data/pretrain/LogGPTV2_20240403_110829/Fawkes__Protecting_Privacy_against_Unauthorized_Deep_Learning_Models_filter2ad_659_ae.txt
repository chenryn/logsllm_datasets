 0.6
 0.4
 0.2
 0
 0.4
e
t
a
R
s
s
e
c
c
u
S
n
o
i
t
c
e
t
o
r
P
 1
 0.8
 0.6
 0.4
 0.2
 0
 0.4
Without Sybil
With Sybil
With Sybil (x2)
 0.6
 0.8
 1
Ratio of Cloaked Images
Without Sybil
With Sybil
With Sybil (x2)
 0.6
 0.8
 1
Ratio of Cloaked Images
Figure 10: Protection success
rate
decreases when the tracker has more
original user
(User/Tracker:
Web-Incept)
images.
Figure 11: Protection success rate is
high when the user has a Sybil account,
even if tracker has original user images.
(User/Tracker: Web-Incept)
Figure 12: Sybils jointly optimized on
four feature extractors have reasonably
high protection success for each individ-
ual extractor.
line; and B contains original images leaked to the tracker. For
each synthetic image of the Sybil, we randomly select an un-
cloaked image of the user in set A. We select one Sybil image
per uncloaked image in A. Then, we cloak all the candidate
images using the methodology discussed in §4. The result-
ing Sybil images mimic the feature space representation of
uncloaked user images. From the tracker’s perspective, they
have access to cloaked user images from set A, uncloaked
images from set B, and the Sybil images.
Figure 11 compares the protection success rate with and
without Sybil accounts (with Web-Incept as user’s and
tracker’s feature extractor). The use of a Sybil account signiﬁ-
cantly improves the protection success rate when an attacker
has a small number of original images. The protection suc-
cess rate remains above 87% when the ratio of the original
images owned by the tracker is less than 31%.
As discussed, a user can create as many Sybil images as
they desire. When the user uploads more Sybil images, the
protection success rate increases. Figure 11 shows that when
the user has uploaded 2 Sybil images per uncloaked image,
the protection success rate increases by 5.5%.
Jointly Optimize Multiple Feature Extractors. The user
may not know the tracker’s exact feature extractor. However,
given the small number of face feature extractors available
online, she is likely to know that the tracker would use one of
several candidate feature extractors. Thus, she could jointly
optimize the Sybil cloaks to simultaneously fool all the can-
didate feature extractors.
We test this in a simple experiment by jointly optimizing
Sybil cloaks on the four feature extractors from §5. We eval-
uate the cloak’s performance when the tracker uses one of
the four. Figure 12 shows the Sybil effectiveness averaged
across the 4 feature extractors. The average protection suc-
cess rate remains above 65% when the ratio of the original
images owned by the tracker is less than 31%.
8 Countermeasures
In this section, we explore potential countermeasures a
tracker could employ to reduce the effectiveness of image
cloaking. We consider and (where possible) empirically val-
idate methods to remove cloaks from images, as well as
techniques to detect the presence of cloak perturbations
on images. Our experiments make the strongest possible
assumption about the tracker: that they know the precise
feature extractor a user used to optimize cloaks. We test
our countermeasures on a tracker’s model trained on the
FaceScrub dataset. Cloaks were generated using the same
robust VGG2-Dense feature extractor from §5.3.
Inherent Limits on Cloaking Success. We acknowledge
that cloaking becomes less effective when an individual is
an active target of a tracker. If a tracker strongly desires to
train a model that recognizes a certain individual, they can
take drastic measures that cloaking cannot withstand. For ex-
ample, a tracker could learn their movements or invade their
privacy (i.e. learn where they live) by following them physi-
cally.
8.1 Cloak Disruption
Without knowing which images in the dataset are cloaked,
the tracker may utilize the following techniques to disrupt
Fawkes’ protection performance, 1) transforming images or
2) deploying an extremely robust model. We present and eval-
uate Fawkes’s performance against these two potential coun-
termeasures.
Image Transformation. A simple technique to mitigate
the impact of small image perturbations is to transform im-
ages in the training dataset before using them for model train-
ing [8, 16]. These transformations include image augmenta-
tion, blurring, or adding noise. Additionally, images posted
online are frequently compressed before sharing (i.e. in the
upload process), which could impact cloak efﬁcacy.
However, we ﬁnd that none of these transformations defeat
our cloaks. The protection success rate remains 100% even
1600    29th USENIX Security Symposium
USENIX Association
e
t
a
R
s
s
e
c
c
u
S
n
o
i
t
c
e
t
o
r
P
 1
 0.8
 0.6
 0.4
 0.2
 0
 3
 1
 0.8
 0.6
 0.4
 0.2
 0
 21
y
c
a
r
u
c
c
A
n
o
i
t
a
c
i
f
i
s
s
a
C
l
e
t
a
R
s
s
e
c
c
u
S
n
o
i
t
c
e
t
o
r
P
 1
 0.8
 0.6
 0.4
 0.2
 0
 0
Normal Classification Accuracy
Protection Success Rate
 10
 20
 30
 1
 0.8
 0.6
 0.4
 0.2
 0
 40
y
c
a
r
u
c
c
A
n
o
i
t
a
c
i
f
i
s
s
a
C
l
e
t
a
R
s
s
e
c
c
u
S
n
o
i
t
c
e
t
o
r
P
 1
 0.8
 0.6
 0.4
 0.2
 0
 5
Standard Deviation of Gaussian Noise
Normal Classification Accuracy
Protection Success Rate
 10
 15
Image Quality
 1
 0.8
 0.6
 0.4
 0.2
 0
 20
y
c
a
r
u
c
c
A
n
o
i
t
a
c
i
f
i
s
s
a
C
l
Normal Classification Accuracy
Protection Success Rate
 9
 15
Kernel Size of Gaussian Blur
Figure 13: Normal classiﬁcation ac-
curacy decreases as input blurring in-
creases but protection success rate re-
mains high.
Figure 14: Normal classiﬁcation accu-
racy decreases as Gaussian noise is
added to inputs but protection success
rate remains high.
Figure 15: Protection success rate and
normal classiﬁcation accuracy increase
as image quality increases using JPEG
compression.
Original
ρ = 0.006
ρ = 0.008
ρ = 0.01
ρ = 0.012
Protection 
Success Rate
51%
87%
100%
100%
Figure 16: When the user’s feature extractor is much less ro-
bust than the tracker’s feature extractor, the user can improve
their protection success rate by increasing their DSSIM bud-
get. (User: VGG2-Dense, Tracker: Web-Incept)
when data augmentation is applied to cloaked images 5. Ap-
plying Gaussian blurring degrades normal accuracy by up to
18% (as kernel size increases) while cloak protection success
rate remains > 98% (see Figure 13). Adding Gaussian noise
to images merely disrupts normal classiﬁcation accuracy –
the cloak protection success rate remains above 100% as
the standard deviation of the noise distribution increases (see
Figure 14). Even image compression cannot defeat our cloak.
We use progressive JPEG [57], reportedly used by Facebook
and Twitter, to compress the images in our dataset. The im-
age quality, as standard by Independent JPEG Group [1],
ranges from 5 to 95 (lower value = higher compression). As
shown in Figure 15, image compression decreases the pro-
tection success rate, but more signiﬁcantly degrades normal
classiﬁcation accuracy.
As shown in §5, cloaks constructed on
Robust Model.
robust feature extractors transfer well to trackers’ less robust