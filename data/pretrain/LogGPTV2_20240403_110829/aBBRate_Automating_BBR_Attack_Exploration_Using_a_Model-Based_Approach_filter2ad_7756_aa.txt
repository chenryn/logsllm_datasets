title:aBBRate: Automating BBR Attack Exploration Using a Model-Based Approach
author:Anthony Peterson and
Samuel Jero and
Md. Endadul Hoque and
David R. Choffnes and
Cristina Nita-Rotaru
aBBRate: Automating BBR Attack Exploration Using a Model-Based Approach
Anthony Peterson
Northeastern University
Samuel Jero∗
Purdue University
Endadul Hoque
Syracuse University
David Choffnes
Northeastern University
Cristina Nita-Rotaru
Northeastern University
Abstract
BBR is a new congestion control algorithm proposed by
Google that builds a model of the network path consisting
of its bottleneck bandwidth and RTT to govern its sending
rate rather than packet loss (like CUBIC and many other pop-
ular congestion control algorithms). Loss-based congestion
control has been shown to be vulnerable to acknowledgment
manipulation attacks. However, no prior work has investi-
gated how to design such attacks for BBR, nor how effective
they are in practice. In this paper we systematically analyze
the vulnerability of BBR to acknowledgement manipulation
attacks. We create the ﬁrst detailed BBR ﬁnite state machine
and a novel algorithm for inferring its current BBR state at
runtime by passively observing network trafﬁc. We then adapt
and apply a TCP fuzzer to the Linux TCP BBR v1.0 imple-
mentation. Our approach generated 30,297 attack strategies,
of which 8,859 misled BBR about actual network conditions.
From these, we identify 5 classes of attacks causing BBR
to send faster, slower or stall. We also found that BBR is
immune to acknowledgment burst, division and duplication
attacks that were previously shown to be effective against
loss-based congestion control such as TCP New Reno.
1 Introduction
BBR (Bottleneck Bandwidth and Round-trip propagation
time) is a new congestion control algorithm for TCP [24]
and QUIC [25] proposed by Google in 2016. BBR is mo-
tivated by how commonly deployed loss-based congestion
control algorithms inaccurately rely on packet loss as the pri-
mary signal for network congestion, often leaving networks
underutilized or highly congested. This inaccuracy occurs
because in today’s networks, the relationship between packet
loss and network congestion has become disjoint due to vary-
ing switch buffer sizes. Instead, BBR is model-based, as it
creates a model of the network by periodically estimating the
∗Samuel Jero is now at MIT Lincoln Laboratory. This work was done
while at Purdue University.
available bottleneck bandwidth BtlBw and round-trip propaga-
tion delay RTprop, which are used to govern the rate packets
are sent into the network and the maximum amount of data
allowed in-transit.
Prior work [29, 30, 32, 36] showed how loss-based conges-
tion control algorithms (e.g., New Reno, CUBIC) designed
for TCP are prone to acknowledgment manipulation attacks,
where an adversary exploits the semantics of acknowledg-
ments to mislead the sender (i.e., the victim) of a ﬂow about
network congestion. These attacks are possible because TCP
headers are unencrypted and have no authentication mecha-
nism other than a random initial sequence number which may
be observed or predicted by on-path [29] or off-path [7,23,35]
attackers, respectively. While at ﬁrst it may appear BBR is
less prone to such attacks, as it relies on a different conges-
tion control approach, its estimation of BtlBw and RTprop is
based on received acknowledgments. The impact of such at-
tacks can not be easily assessed from existing attacks against
loss-based congestion control, because BBR follows a differ-
ent algorithm for adjusting its sending rate. Given BBR is
implemented for TCP [8], the underlying protocol for much
of the Internet trafﬁc, and being deployed on YouTube and
Google.com [9], studying BBR security and its vulnerability
to acknowledgment manipulation attacks is critical.
In this work, we discover and analyze acknowledgment ma-
nipulation attacks targeting the Linux TCP BBR congestion
control implementation, a popular implementation of BBR.
We use a protocol-fuzzing approach to systematically inject at
runtime maliciously modiﬁed acknowledgment packets that
target the core mechanism of BBR: the estimation of BtlBw
and RTprop. In order to achieve this, we adapt TCPWN1, a
TCP congestion control protocol fuzzer, to automatically ﬁnd
vulnerabilities targeting BBR. TCPWN attack strategies are
deﬁned by tuplets that dictate which type of acknowledgment
manipulation attack to execute when the sender is in a cer-
tain congestion control state. TCPWN uses the model of the
congestion control algorithm to map all theoretically possible
1https://github.com/samueljero/TCPwn
USENIX Association
23rd International Symposium on Research in Attacks, Intrusions and Defenses    225
attack paths to actual attack strategies. It then uses a state infer-
ence algorithm by observing network trafﬁc to discern when
to inject the counterfeit acknowledgments. Since TCPWN
supports only loss-based congestion control algorithms, we
derive a ﬁnite state machine for BBR by consulting documen-
tation [9, 16, 17], presentations [10–15] and source code [8].
We additionally develop a new algorithm for inferring the
current BBR state in real-time based on network trafﬁc alone,
and integrate it with TCPWN.
Using this approach, we automatically generated and exe-
cuted 30,297 attack strategies from both off-path and on-path
attackers, of which 8,859 caused BBR to send data at abnor-
mal rates: 14 caused a faster sending rate, 4,025 caused a
slower sending rate and 4,820 caused a stalled connection
(i.e., the ﬂow did not complete). All of these successful at-
tacks originated from an on-path attacker with read/write
access to the ﬂow. Attacks causing slower/stalled sending
performance could be used by an adversary to throttle other
ﬂows—leading to poor performance for victim ﬂows and pos-
sibly making more bandwidth available to the attacker’s ﬂows.
Those causing faster sending performance could be used by a
destructive adversary to increase network congestion, leading
to unfairness, poor quality of service and congestion collapse.
Attacks causing stall connections are a form of denial of ser-
vice attacks difﬁcult to detect as the connection is active and
data is being sent, but with no progress for the ﬂow itself. We
summarize our contributions as follows:
state in real-time by observing network trafﬁc.
• We derive the ﬁrst state machine model for BBR and
use it to demonstrate that BBR is vulnerable to acknowl-
edgement manipulation attacks.
• We derive an algorithm for estimating the current BBR
• We adapt a TCP congestion control fuzzer, TCPWN,
to BBR using our newly derived BBR state machine
and inference algorithm to automatically generate and
execute 30,297 automatically attack strategies.
• We identify 5 classes of acknowledgement manipulation
attacks from on-path attakers against BBR that cause
faster, slower and stalled sending rates. We did not ﬁnd
effective attacks from off-path attackers. To the best of
our knowledge, we are the ﬁrst to discover and evaluate
attacks on BBR.
• We analyze how BBR distinctly reacts to these attacks,
in comparison with other congestion control algorithms.
We also found that BBR is immune to acknowledgment
burst, division and duplication attacks that were previ-
ously shown to be effective against loss-based conges-
tion control such as TCP New Reno.
2 Vulnerability of BBR to Attacks
We now describe BBR, derive a model for it, and show how
an attacker can exploit the model to create attacks.
Algorithm 1 Delivery rate samples [17] are computed to
estimate the bottleneck bandwidth. For each new ACK, the
average ACK rate is computed between when a data segment
is sent to when an acknowledgment is explicitly received for
it. Delivery rates are capped by the send rate as data should
not arrive at the receiver faster than it is transmitted.
Input: A data segment P and a BBR connection C.
Output: The delivery rate sample
1: function COMPUTEDELIVERYRATESAMPLE(P, C)
2:
data_acked = C.delivered - P.delivered
3:
ack_elapsed = C.delivered_time - P.delivered_time
4:
send_elapsed = P.sent_time - P.first_sent_time
5:
ack_rate = data_acked / ack_elapsed
6:
send_rate = data_acked / send_elapsed
7:
delivery_rate = min(ack_rate, send_rate)
8:
return delivery_rate
9: end function
2.1 BBR Overview
BBR is motivated by how loss-based congestion control al-
gorithms such as CUBIC and New Reno assume packet loss
implies network congestion, which is not always the case. As
a result, sending behavior is adjusted based on signals possi-
bly unrelated to actual congestion, leading to network under
utilization and excessive queue delay (bufferbloat).
Instead of relying solely on packet loss to infer congestion,
BBR is model-based meaning congestion is inferred primarily
by two properties of the network path: its bottleneck band-
width BtlBw and round-trip propagation delay RTprop. BBR
paces its sending rate proportionally to BtlBw and aims for at
least one BDP = BtlBw × RTprop worth of data in-ﬂight for
full utilization. At any given time, its sending rate is limited by
two factors: the congestion window cwnd, or pacing_rate
= pacing_gain × BtlBw that deﬁnes inter-packet spacing.
Pacing, ﬁrst proposed by Zhang et al. [39], aims to reduce
burstiness and in some situations, offers improved fairness
and throughput [2]. BBR caps cwnd to 2 × BDP to overcome
delays in received acknowledgments, which would otherwise
cause BBR to underestimate the bottleneck bandwidth [10].
Obtaining an accurate and up-to-date model of the network
path is essential to BBR’s effectiveness, and thus the model
is updated on every new acknowledgement.
2.2 Estimating the Network Path Model
Accurate measurements of BtlBw and RTprop are obtained
sequentially at different times and network conditions because
the network conditions required to obtain accurate measure-
ments of each parameter interfere with each others measure-
ments. At mutually exclusive times, BBR adjusts its sending
rate so the network conditions are met for each parameter.
For BtlBw, the sending rate is increased to discover available
bottleneck bandwidth while for RTprop, the congestion win-
dow is reduced to 4 packets. Note that increasing sending
rate to measure BtlBw may create queues which would create
inaccurate RTprop measurements. Decreasing the sending
226    23rd International Symposium on Research in Attacks, Intrusions and Defenses
USENIX Association
rate to measure RTprop would not allow available bandwidth
to be discovered.
Bottleneck Bandwidth. The bottleneck bandwidth is esti-
mated by employing a max ﬁlter that retains the maximum
observed delivery rate sample over the past 10 round-trips. A
delivery rate sample is computed on each new ACK, which
is shown in Algorithm 1. Delivery rate samples represent the
average acknowledgment rate between when a data segment
is transmitted to when an acknowledgment is received for that
segment. Delivery rate samples are only computed for the
exact packet it acknowledges. This is because factors such
as delayed acknowledgment can cause delivery rates to be
overestimated. These samples are used primarily to estimate
the rate at which data is arriving at the receiver, which is
naturally capped by the bottleneck bandwidth. Delivery rate
samples only reﬂect the actual bottleneck bandwidth when
BBR sends at a rate that matches or exceeds capacity, which
is accomplished by periodically increasing its sending rate
25% faster than the current BtlBw.
Round-Trip Propagation Delay. BBR estimates RTprop
using a min ﬁlter that retains the minimum observed round-
trip time sample over the past 10 seconds. Round-trip samples
are measured by computing the elapsed time between when a
ﬂight of data is sent to when it is acknowledged. Accurately
measuring the RTT presents a challenge because packets
queued in switch buffers cause increased and inaccurate RTT
samples. To overcome this, BBR drains switch queues by
periodically limiting its sending behavior. After measuring
BtlBw, it is entirely possible the bottleneck is already satu-
rated, causing queue build-up. To mitigate this, BBR sends
25% slower than the current estimated BtlBw immediately
after measuring the bottleneck link. BBR also reduces cwnd
to 4 packets every 10 seconds to update RTprop, which we
describe in the following section in greater detail.
Rate Limiting. BBR attempts to detect token-bucket po-
licers (TBPs) as they can cause data to be sent faster than the
token drain rate, leading to high packet loss. In networks with
such TBPs, it is common to see bursts of throughput before
tokens are exhausted, after which packets are dropped. Due
to BBR’s long-lived BtlBw max ﬁlter, the burst rate would
cause the estimated bottleneck bandwidth to be greater than
the token drain rate, leading to high packet loss for as long as
10 round-trips. BBR detects TBPs when there is signiﬁcant
packet loss and consistent throughput, after which it paces its
sending rate to the estimated token drain rate for 48 RTTs.
2.3 A State Machine for BBR
To systematically analyze BBR, we derive a ﬁnite-state ma-
chine (FSM) for it. To the best of our knowledge no such
model has been published, so we empirically developed our
own through documentation [9,16,17], presentations [10–15]
and source code [8]. In Figure 1, we illustrate our BBR FSM
and describe its variables and events in Table 1.
BBR employs several similar mechanisms to traditional
congestion control algorithms. (Readers can refer to Appendix
E to revisit the background on congestion control). When a
ﬂow ﬁrst begins, BBR uses a mechanism to quickly discover
the available bandwidth (i.e. slow start). Afterwards, BBR
paces its sending rate at the estimated bandwidth (i.e. con-
gestion avoidance) while simultaneously probing the network
for available bandwidth and updating its network path model:
BtlBw and RTprop. Even though packet loss is not at BBR’s
core, BBR includes mechanisms to handle such cases. Finally,
BBR includes methods for detecting and accounting for token-
bucket policers, as they can allow trafﬁc bursts until tokens
run up, making BBR to send too quickly causing packet loss.
The states of our BBR FSM are:
Startup. Similar to slow start, Startup is the ﬁrst state
BBR enters and aims to quickly discover the available bottle-
neck bandwidth by doubling its sending rate on each round-
trip. Startup transitions into Drain when either cwnd reaches
ssthresh or if three consecutive delivery rate samples show
less than a 25% increases over the last, indicating the bottle-
neck bandwidth has been reached.
Drain. This state aims to drain queues that were likely
created during Startup. Those queues are reduced in a single
round-trip by sending data at ln(2)/2 ≈ 0.34 times the rate
before entering this state, after which ProbeBW is entered.
ProbeBW. Similar to congestion avoidance, ProbeBW
aims to pace the sending rate at the estimated bottleneck
bandwidth, achieve fairness, and probe for additional band-
width with low queuing delay. These are accomplished using
gain cycling where the pacing_gain cycles through a set of
eight phases: [5(cid:14)4, 3(cid:14)4 , 1, 1, 1, 1, 1, 1] where each phase
lasts one RTprop. In the ﬁrst phase, BBR sends 25% faster
than BtlBw to probe for additional bandwidth. In the second
phase, BBR sends 25% slower than BtlBw to drain any queues
created in the last phase and to achieve fairness with other
ﬂows. In the remaining phases, BBR sends equal to BtlBw;
the target operating point.
ProbeRTT. The goal of this state is to obtain a recent
and accurate measurement of RTprop. Since queue delay in-
creases the measured RTprop, ProbeRTT explicitly backs off
from the network in order to drain any queues. This way, the
min RTprop ﬁlter can capture a RTprop measurement without
queues. ProbeRTT is entered if 10 seconds have elapsed since
RTprop was last updated, and lasts for 200 ms; long enough
to overlap with other ﬂow’s ProbeRTT states such that queues
are fully drained.
Recovery. This state is entered when data has been lost and
exits once all outstanding data when Recovery was entered
has been acknowledged. Upon entry, cwnd is set to the amount
of in-ﬂight data and resets to 2 × BDP upon exit.
Exponential Backoff. This state is entered upon a re-
transmission timeout indicating lost data due to no new ac-
knowledgments for several RTTs. The lost segment is re-
transmited with a doubled timeout time; exponentially back-
USENIX Association
23rd International Symposium on Research in Attacks, Intrusions and Defenses    227
Figure 1: TCP BBR ﬁnite-state machine, see Table 1 for variable descriptions.
Variable
bw
bw_est
fullbw
idx
min_rtt