Table 2: Node map for the example in Figure 3.
ject associated with each event can be file or process. All
events occur within a host, denoted by agentid, and there is
no cross-host event. There are three types of operations as-
sociated with an event, including Execute, Read and Write,
recorded by accessright. To notice, the properties of ob-
jects, like the ﬁlenames and paths, are stored in other tables.
But because the other tables’ volume is small, we do not
process them speciﬁcally.
Causality analysis on FileEvent. We assume that a de-
pendency graph G = (V,E) can be derived from FileEvent,
in which the vertices (V ) are the objects and the directed edges
(E) are the events. Causality analysis uncovers the causality
dependency of edges, and we deﬁne its computation paradigm
below, in a way similar to the deﬁnition from Wu et al. [83].
Deﬁnition 1 (Causality dependency). Given two adjacent di-
rected edges e1 = (u,v) and e2 = (v,w), there is a causality
dependency between them, denoted by e1 → e2, if and only
if fe(e1) , where R is a compression method, F : Q → Q
re-writes Q to accommodate the compressed data, and P is
a post-processing function. Compression can be expressed
as R(G) = Rp(Rs(G)), where Rs compresses the structures
(vertices and edges), and Rp compresses the edge properties
or ﬁelds. Denote by Gr = R(G) = (Vr,Er) the graph after
compression, such that |Er| ≤ |E|. QFC requires that for any
query Q ∈ Q ,
• Q(G) = P(Q(cid:48)(Gr)), where Q(cid:48) = F(Q) is the query on
the compressed graph, and P(Q(cid:48)(Gr)) is the result after post-
processing the query answer on Gr.
• With only Rs applied, any algorithm for evaluating Q can
be directly used to compute Q(cid:48)(Gr) without decompression.
• When both Rs and Rp are applied, decompression is
needed only when the relationship between the timestamps
of a compressed edge e ∈ Er and the time range of the query
cannot be determined.
Next, we describe our choices of Rs and Rp in Section 3.3
and Section 3.4. The query transformation F and the post-
processing P are investigated in Section 3.5. Figure 3 (right)
overviews the graph compressed with SEAL.
USENIX Association
30th USENIX Security Symposium    2991
ACBDEFa[70,80,E,F,Exe][50,60,B,E,Read][35,45,A,D,Read][25,45,B,D,Read]DbEFEventMerged EventFile NodeProcess NodeNew Node[65,85,E,F,Exe,...][50,80,b,E,Read,...][25,55,a,D,Read,...]GB...Delta Coded Infromationc[25,55,A,D,Read][65,85,E,F,Exe][70,80,C,E,Read][80,90,G,B,Write][80,95,c,B,Write,...]H[85,95,H,B,Write]CAGH3.3 Compression on Graph Structure
We design the function Rs such that multiple edges (from one
pair of nodes or multiple pairs) can be reduced into a single
edge. In particular, our algorithm ﬁnds sets of edges satisfying
a certain merge pattern and combines all edges in the set.
By examining the ﬁelds of FileEvent, one expects a higher
compression ratio if edges with common ﬁelds are merged.
Moreover, edges within proximity can be merged without
sacriﬁcing causality tracking performance. As illustrated in
Figure 3, we choose the merge pattern to be the set of all
incoming edges of any node v ∈ V , which will share properties
such as dstid or agentid. Correspondingly, a new node
is added in the new graph Gr, representing the combination
of all the parent nodes of v, if the number of parent nodes is
more than 1.
We give an example in Figure 3. The new node a is gen-
erated to correspond to two individual nodes {A,B}, and
the new edge [25, 55, a, D, Read, (25, 55), (35,
45); (25, 45)] is generated to correspond to three in-
dividual edges {[25, 55, A, D, Read], [35, 45, A, D,
Read], [25, 45, B, D, Read]}. Similarly, we merge the
two incoming edges of node B, merge the two incoming edges
of node E, and create new nodes c, b, respectively. We also
merge the two repeated edges between nodes E, F, but no
new node needs to be created for them. Individual edges are
removed in the compressed graph Gr if they are merged into
a new edge. However, as can be seen in Figure 3, individual
nodes should not be removed. For example, even if the in-
dividual node B is included in the new node a, it cannot be
removed because of its own incoming edges. The new nodes
are recorded in a node map, shown in Table 2.
Our algorithm for Rs is shown in Algorithm 1. It takes all
the events as input, and creates two hash maps: (i) NodeMap,
child node with all its parent nodes, and (ii) EdgeMap, a
pair of nodes with all its corresponding edges. Then for each
child node v ∈ V , all its parent nodes and the corresponding
incoming edges are identiﬁed and merged. Meanwhile, the
node map as in Table 2 is also updated. The time complexity
of this algorithm is linear in the size of the graph, namely,
O(|V| +|E|). When responding to queries, decompression is
selectively applied to restore the provenance, with the help of
NodeMap and EdgeMap.
3.4 Compression on Edge Properties
For all the properties or ﬁelds for a merged edge, they should
be combined and compressed due to the redundant informa-
tion, which is the focus of the compression function Rp. We
propose delta coding for merged timestamp sequence, and
Golomb code for the initial value in the sequence.
Delta coding. Delta coding represents a sequence of val-
ues with the differences (or delta). It has been used in up-
dating webpages, copying ﬁles online backup, code version
Algorithm 1 Graph structure compression.
= edges)
Input: a set of edges E.
Output: a set of new edges E(cid:48), a node map NodeMap.
1: NodeMap ← /0
(cid:46) hash map (key = a node, value =
parent nodes)
2: EdgeMap ← /0 (cid:46) hash map (key = a pair of nodes, value
3: for e = (u,v) ∈ E do
NodeMap.put(v,u)
4:
EdgeMaps.put((u,v),e)
5:
6: end for
7: E(cid:48) ← /0
8: for v ∈ NodeMap.keys do
e(cid:48) = /0
9:
U ← NodeMap.get(v)
10:
for u ∈ U do
11:
12:
13:
14:
15: end for
e(cid:48) ← e(cid:48) ∪{EdgeMap.get((u,v))}
end for
E(cid:48) ← E ∪{e(cid:48)}
(cid:46) a new edge
Figure 4: Delta coding for starttime. The ﬁrst number in
the combined time vector is the minimum time among the
edges.
control and etc. [59]. We apply delta coding on timestamp
ﬁelds (starttime, endtime) , as they usually share a long
preﬁx. For instance, as shown in Figure 4, the starttime
ﬁeld is a long integer, and merged individual edges have val-
ues like 1562734588980, 1562734588971, 1562734588984,
1562734588990. Those values usually share the same preﬁx
as the events to be compressed are often collected in a small
time window, hence delta coding can result in a compact
representation.
As shown in Figure 4, assume a node x has d incoming
edges and p parent nodes, 1 ≤ p ≤ d. Let the starttime of
start, 1 ≤ j ≤ d. We ﬁrst construct a sequence
the j-th edge be t j
t1
tstart = [t0
start;
start;
start = min1≤ j≤d(t j
where t0
start ). Here comma is used to sepa-
rate different edges from the same parent node, and semicolon
separates different parent nodes. The colon at the end is used
to separate the timestamp ﬁelds. For endtime, we choose the
initial entry t0 to be the maximum among the edges. Then we
concatenate both ﬁelds into one sequence.
start ,t3
t2
td
start :]
start;
...;
2992    30th USENIX Security Symposium
USENIX Association
y1y2y3xycx1562734588980156273458897115627345889841562734588990[1562734588980,1562734588971,1562734588984,1562734588990][1562734588971; 9; -9, 13; 6:]Delta Encoding[1562734588971; 9; -9, 13; 6:]Then, we compute the delta for every consecutive pair of
start. The resulting
timestamps: for 1 ≤ j ≤ d, ∆ j
coded timestamp of the merged edge is:
start −t j−1
start = t j
[t0
start; ∆1
start; ∆2
start ,∆3
start; ∆4
start;
..., ∆d
start :]
and delta coding is also applied to the other timestamp ﬁelds.
The time complexity of delta coding is O(d) where d is the
number of edges.
To conform to the uncompressed FileEvent format, the
t0
start and t0
end are stored in the starttime and endtime ﬁeld
of the new edge ec respectively, and the generated delta-coded
starttime and endtime are stored in a new delta ﬁeld.
Golomb coding. Delta coding can compress all the elements
of the combined time sequence except t0 which is still a long
integer. Moreover, if an individual edge is not merged, its
timestamps are also long integers. We choose to employ
Golomb coding [28] to compress long integers to relatively
small integers. Alternatively, a more aggressive approach is
to use delta coding to compress t0 of different merged events,
but the database index will be updated [13] and the query cost
will be high. One favorable property of Golomb coding is that
the relative order of the numbers is not changed, which ﬁts
well with the requirements of QFC. That is, if t > t(cid:48), then we
have the Golomb coded variable Gol(t) > Gol(t(cid:48)).
Golomb code uses a parameter M to divide an input datum
N into two parts (quotient q and reminder r) by
q = (cid:98) N − 1
M
(cid:99), r = N − qM − 1.
(1)
Under the standard Golomb coding schema, the quotient
q is then coded under unary coding, and the reminder r is
coded under truncated binary encoding to guarantee that the
value after coding (called codeword) is a preﬁx code. In our
case, however, the truncated binary encoding is not neces-
sary because the codewords are separated by different en-
tries automatically. As such we use a simpler mechanism,
binary coding, for r. The coded data is then calculated by
concatenating p and r. For instance, given a long integer
1562734588980 (64 bits) and a M = 1562700000000, the bi-
nary form of p and r after coding will be 10 (2 bits) and