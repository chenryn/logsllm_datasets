---
title: Python pytest
date: 20200527
author: Lyz
---
[pytest](https://docs.pytest.org/en/latest) is a Python framework to makes it
easy to write small tests, yet scales to support complex functional testing for
applications and libraries.
Pytest stands out over other test frameworks in:
- Simple tests are simple to write in pytest.
- Complex tests are still simple to write.
- Tests are easy to read.
- You can get started in seconds.
- You use `assert` to fail a test, not things like `self.assertEqual()` or
  `self.assertLessThan()`. Just `assert`.
- You can use pytest to run tests written for unittest or nose.
Note: You can use
[this cookiecutter template](https://github.com/lyz-code/cookiecutter-python-project)
to create a python project with `pytest` already configured.
# Install
```bash
pip install pytest
```
# Usage
Run in the project directory.
```bash
pytest
```
If you need more information run it with `-v`.
Pytest automatically finds which tests to run in a phase called *test
discovery*. It will get the tests that match one of the following conditions:
- Test files that are named `test_{{ something }}.py` or
  `{{ something }}_test.py`.
- Test methods and functions named `test_{{ something }}`.
- Test classes named `Test{{ Something }}`.
There are several possible outcomes of a test function:
- *PASSED (.)*: The test ran successfully.
- *FAILED (F)*: The test did not run usccessfully (or *XPASS* + strict).
- *SKIPPED (s)*: The test was skipped. You can tell pytest to skip a test by
  using enter the `@pytest.mark.skip()` or `pytest.mark.skipif()` decorators.
- *xfail (x)*: The test was not supposed to pass, ran, and failed. You can tell
  pytest that a test is expected to fail by using the `@pytest.mark.xfail()`
  decorator.
- *XPASS (X)*: The tests was not supposed to pass, ran, and passed.
- *ERROR (E)*: An exception happened outside of the test function, in either a
  fixture or a hook function.
Pytest supports several cool flags like:
- `-k EXPRESSION`: Used to select a subset of tests to run. For example
  `pytest   -k "asdict or defaults"` will run both `test_asdict()` and
  `test_defaults()`.
- `--lf` or `--last-failed`: Just run the tests that have failed in the previous
  run.
- `-x`, or `--exitfirst`: Exit on first failed test.
- `-l` or `--showlocals`: Print out the local variables in a test if the test
  fails.
- `-s` Allows any output that normally would be printed to `stdout` to actually
  be printed to `stdout`. It's an alias of `--capture=no`, so the output is not
  captured when the tests are run, which is the default behavior. This is useful
  to debug with `print()` statements.
- `--durations=N`: It reports the slowest `N` number of tests/setups/teardowns
  after the test run. If you pass in `--durations=0`, it reports everything in
  order of slowest to fastest.
- `--setup-show`: Show the fixtures in use.
- `--tb=long`: To see the tracebacks of the exceptions raised while running the program.
# Fixtures
Fixtures are functions that are run by pytest before (and sometimes after) the
actual test functions.
You can use fixtures to get a data set for the tests to work on, or use them to
get a system into a known state before running a test. They are also used to get
data ready for multiple tests.
Here's a simple fixture that returns a number:
```python
import pytest
@pytest.fixture()
def some_data()
    """ Return answer to the ultimate question """
    return 42
def test_some_data(some_data):
    """ Use fixture return value in a test"""
    assert some_data == 42
```
The `@pytest.fixture()` decorator is used to tell pytest that a function is a
fixture.When you include the fixture name in the parameter list of a test
function,pytest knows to run it before running the test. Fixtures can do work,
and can also return data to the test function.
The test test_some_data() has the name of the fixture, some_data, as a
parameter.pytest will see this and look for a fixture with this name. Naming is
significant in pytest. pytest will look in the module of the test for a fixture
of that name.
If the function is defined in the same file as where it's being used pylint will
raise an `W0621: Redefining name %r from outer scope (line %s)` error. To
[solve](https://stackoverflow.com/questions/46089480/pytest-fixtures-redefining-name-from-outer-scope-pylint)
it either move the fixture to other file or name the decorated function
`fixture_` and then use `@pytest.fixture(name='')`.
## Sharing fixtures through conftest.py
You can put fixtures into individual test files, but to share fixtures among
multiple test files, you need to use a `conftest.py` file somewhere centrally
located for all of the tests. Additionally you can have `conftest.py` files in
subdirectories of the top `tests` directory. If you do, fixtures defined in
these lower level `conftest.py` files will be available to tests in that
directory and subdirectories.
Although `conftest.py` is a Python module, it should not be imported by test
files. The file gets read by pytest, and is considered a local *plugin*.
Another option is to save the fixtures in a file by
[creating a local pytest plugin](https://gist.github.com/peterhurford/09f7dcda0ab04b95c026c60fa49c2a68).
File: `tests/unit/conftest.py`
```python
pytest_plugins = [
    "tests.unit.fixtures.some_stuff",
]
```
File: `tests/unit/fixtures/some_stuff.py`:
```python
import pytest
@pytest.fixture
def foo():
    return "foobar"
```
## Specifying fixture scope
Fixtures include an optional parameter called scope, which controls how often a
fixture gets set up and torn down. The scope parameter to `@pytest.fixture()`
can have the values of function, class, module, or session.
Hereâ€™s a rundown of each scope value:
- `scope='function'`: Run once per test function. The setup portion is run
  before each test using the fixture. The teardown portion is run after each
  test using the fixture. This is the default scope used when no scope parameter
  is specified.
- `scope='class'`: Run once per test class, regardless of how many test methods
  are in the class.
- `scope='module'`: Run once per module, regardless of how many test functions
  or methods or other fixtures in the module use it.
- `scope='session'` Run once per session. All test methods and functions using a
  fixture of session scope share one setup and teardown call.
## [Using fixtures at class level](https://docs.pytest.org/en/7.1.x/how-to/fixtures.html#use-fixtures-in-classes-and-modules-with-usefixtures)
Sometimes test functions do not directly need access to a fixture object. For
example, tests may require to operate with an empty directory as the current
working directory but otherwise do not care for the concrete directory.
```python
@pytest.mark.usefixtures("cleandir")
class TestDirectoryInit:
    ...
```
Due to the `usefixtures` marker, the `cleandir` fixture will be required for the
execution of each test method, just as if you specified a `cleandir` function
argument to each of them.
You can specify multiple fixtures like this:
```python
@pytest.mark.usefixtures("cleandir", "anotherfixture")
```
## Useful Fixtures
### [The tmp_path fixture](https://docs.pytest.org/en/6.2.x/tmpdir.html#the-tmp-path-fixture)
You can use the `tmp_path` fixture which will provide a temporary directory
unique to the test invocation, created in the base temporary directory.
`tmp_path` is a `pathlib.Path` object. Here is an example test usage:
```python
def test_create_file(tmp_path):
    d = tmp_path / "sub"
    d.mkdir()
    p = d / "hello.txt"
    p.write_text(CONTENT)
    assert p.read_text() == CONTENT
    assert len(list(tmp_path.iterdir())) == 1
    assert 0
```
### [The tmpdir fixture](https://docs.pytest.org/en/stable/tmpdir.html)
Warning: Don't use `tmpdir` use `tmp_path` instead because `tmpdir` uses `py`
which is unmaintained and has unpatched vulnerabilities.
You can use the `tmpdir` fixture which will provide a temporary directory unique
to the test invocation, created in the base temporary directory.
`tmpdir` is a `py.path.local` object which offers `os.path` methods and more.
Here is an example test usage:
File: `test_tmpdir.py`:
```python
from py._path.local import LocalPath
def test_create_file(tmpdir: LocalPath):
    p = tmpdir.mkdir("sub").join("hello.txt")
    p.write("content")
    assert p.read() == "content"
    assert len(tmpdir.listdir()) == 1
    assert 0
```
The `tmpdir` fixture has a scope of `function` so you can't make a session
directory. Instead use the `tmpdir_factory` fixture.
```python
from _pytest.tmpdir import TempPathFactory
@pytest.fixture(scope="session")
def image_file(tmpdir_factory: TempPathFactory):
    img = compute_expensive_image()
    fn = tmpdir_factory.mktemp("data").join("img.png")
    img.save(str(fn))
    return fn
def test_histogram(image_file):
    img = load_image(image_file)
    # compute and test histogram
```
#### Make a subdirectory
```python
p = tmpdir.mkdir("sub").join("hello.txt")
```
### [The caplog fixture](https://docs.pytest.org/en/stable/logging.html#caplog-fixture)
pytest captures log messages of level WARNING or above automatically and
displays them in their own section for each failed test in the same manner as
captured stdout and stderr.
You can change the default logging level in the pytest configuration:
File: `pytest.ini`:
```ini
[pytest]
log_level = debug
```
Although it may not be a good idea in most cases. It's better to change the log
level in the tests that need a lower level.
All the logs sent to the logger during the test run are available on the fixture
in the form of both the `logging.LogRecord` instances and the final log text.
This is useful for when you want to assert on the contents of a message:
```python
from _pytest.logging import LogCaptureFixture
def test_baz(caplog: LogCaptureFixture):
    func_under_test()
    for record in caplog.records:
        assert record.levelname != "CRITICAL"
    assert "wally" not in caplog.text
```
You can also resort to record_tuples if all you want to do is to ensure that
certain messages have been logged under a given logger name with a given
severity and message:
```python
def test_foo(caplog: LogCaptureFixture):
    logging.getLogger().info("boo %s", "arg")
    assert ("root", logging.INFO, "boo arg") in caplog.record_tuples
```
You can call `caplog.clear()` to reset the captured log records in a test.
#### Change the log level
Inside tests it's possible to change the log level for the captured log
messages.
```python
def test_foo(caplog: LogCaptureFixture):
    caplog.set_level(logging.INFO)
    pass
```
If you just want to change the log level of a dependency you can use:
```python
caplog.set_level(logging.WARNING, logger="urllib3")
```
### The capsys fixture
The `capsys` builtin fixture provides two bits of functionality: it allows you
to retrieve stdout and stderr from some code, and it disables output capture
temporarily.
Suppose you have a function to print a greeting to stdout:
```python
def greeting(name):
    print(f"Hi, {name}")
```
You can test the output by using `capsys`.
```python
from _pytest.capture import CaptureFixture
def test_greeting(capsys: CaptureFixture[Any]):
    greeting("Earthling")
    out, err = capsys.readouterr()
    assert out == "Hi, Earthling\n"
    assert err == ""
```
The return value is whatever has been captured since the beginning of the
function, or from the last time it was called.
### [freezegun](https://github.com/ktosiek/pytest-freezegun)
[freezegun](https://github.com/spulec/freezegun) lets you freeze time in both
the test and fixtures.
#### Install
```bash
pip install pytest-freezegun
```
#### [Usage](https://github.com/ktosiek/pytest-freezegun#usage)
##### Global usage
[Most of the tests](https://medium.com/@boxed/flaky-tests-part-3-freeze-the-world-e4929a0da00e)
work with frozen time, so it's better to freeze it by default and unfreeze it on
the ones that actually need time to move.
To do that set in your `tests/conftest.py` a globally used fixture:
```python
if TYPE_CHECKING:
    from freezegun.api import FrozenDateTimeFactory
@pytest.fixture(autouse=True)