, ψ(cid:105)
S-STFLD
(cid:48)
(cid:48)
(cid:48)
(cid:48)
P (pc) = stﬂd f
, s
, h
(E
(cid:104)pc, E, h, s :: sv :: l, φ, ψ(cid:105) → (cid:104)pc + 1, E
) = update(h(l, f ), sv, E, h, s, φ)
(cid:48)
, φ
, φ
, h
, s
(cid:48)
(cid:48)
(cid:48)
, ψ(cid:105)
Fig. 3: Abstract interpretation of heap
are initialized to fresh symbolic values sv ∈ Sv, hence E(x)
and h(l, f ) are always deﬁned. Rules S-LDVAR, S-LDFLD,
and S-NEWOBJ (not shown) are similar to the corresponding
rules in Figure 12 but operate on symbolic values and ignore
the call stack cs. Rules S-STVAR and S-STFLD rely on an
update function to implement the ﬂow-insensitive and ﬁeld-
sensitive abstract semantics. This function takes as input two
locations (as well as the current environment, heap, stack, and
φ nodes) and merges the subgraphs rooted at those locations.
The algorithm visits the subgraphs in lockstep in a breadth-ﬁrst
search (BFS) fashion and joins every location (node) with the
same ﬁeld/variable label. This is achieved by creating a fresh
location and updating references to the new location. If the two
merged locations have ﬁelds/variables with the same name,
it recursively applies the update function. Observe that the
update modiﬁes the state of the symbolic computation and may
affect different components of the conﬁguration. This approach
is ﬂow-insensitive as it updates symbolic conﬁgurations with
new symbolic values, instead of overwriting the old values of
the variables/ﬁelds.
1: arg.obj = new ClassB();
2: arg.next = new ClassA();
4a: ldvar arg //S-LdVar
3: arg.next.obj = new ClassB();
4b: ldfld next //S-LdFld
4: arg = arg.next;
4c: stvar arg //S-StVar
Listing 6: Merging heap locations
The code snippet
in Listing 6 illustrates our symbolic
analysis of the heap. Our abstract interpretation yields the heap
graph in Figure 4a after analyzing the (CIL representation of)
instructions (1-3) in Listing 6. We now illustrate our analysis
for instruction (4) and its CIL representation (4a-4c). We ﬁrst
load the symbolic locations in variable arg and ﬁeld next
onto the symbolic stack by applying rules S-LDVAR and S-
LDFLD, respectively. This results in loading the location lb in
Figure 4a. Next, we apply rule S-STVAR for instruction (4c).
The rule considers the subgraphs rooted at location lb (the top
element of the stack) and at the location la (since E(arg) = la)
and applies the update function. Since both edges originating
from the locations la and lb are labeled with the ﬁeld obj
(which contain the locations lc and ld), the algorithm merges
these locations to a fresh location lcd and updates the graph
as shown in Figure 4b.
Abstracting the control ﬂow. The main challenge to
analyzing control ﬂow instructions is the lack of structure
arg
arg
la
next
lb
lab
next
obj
lc
obj
ld
obj
lcd
(a) Before merging
(b) After merging
Fig. 4: Graph representation of symbolic heap
and the preservation of symbolic stack’s consistency across
different branches. We implement an analyses that does not
require reconstructing of the CFG explicitly. Speciﬁcally, we
analyze instructions "sequentially" following the program or-
der imposed by the program counter pc and ensure consistency
of the symbolic stack and the heap on-the-ﬂy. To achieve this,
we extend our symbolic conﬁgurations with two additional
data structures: a function φ : PC (cid:55)→ ℘(Stack ) mapping
program counter indexes to sets of stacks to record the
symbolic stacks at the merge points of control ﬂow branches,
and a set of program counter indexes ψ ⊆ ℘(PC ) to record
backward jumps associated with loops. The former is similar
to the standard φ-node is high-level languages and we use
it to merge the stacks corresponding to different branches in
the CFG. We assume that all stacks at a merge point have
the equal size, which is ensured by the high-level language
compiler (e.g., the C# compiler) that translates source code
to CIL code. The set ψ ensures that loops are not analyzed
repeatedly. Since our analysis is ﬂow- and path-insensitive,
it sufﬁces to analyze each basic block only once. Figure 5
illustrates our algorithm for control ﬂow instructions. We use
a function mergeStacks : ℘(Stack ) × Heap × Env × Φ (cid:55)→
Stack × Heap × Env × Φ to merge all stacks and update
the new symbolic conﬁguration. Speciﬁcally, mergeStacks
merges symbolic locations pointwise, and updates the pointers
to the merged locations in the other components.
We describe the few interesting rules in Figure 5 via
examples. Consider the CIL representation of the C# ternary
operator in Listing 7, which assigns the location in var1 or
var2 to arg.obj depending on the truth value of f lag. The
analysis should compute that ﬁeld arg.obj points to the merged
location of variables var1 and var2. Observe that such case is
not handled by the update function in Figure 3. Our analysis
merges the locations in var1 and var2 on the stack using rule
S-STUPD. This rule has higher precedence over any other rule.
Initially, φ(pc) = ∅ for all program points. For every forward
jump, as in rules S-BRFWD and S-BRTRUEFWD, we store
the current stack for the target instruction. For instance, the
instruction at index (5), i.e., br 7, stores the symbolic stack
containing the locations in arg and var2 for φ(7). When
analyzing the instruction stﬂd obj at index (7), the analyzer
ﬁrst applies rule S-STUPD to merge the stack stored in φ(7)
and the current stack, which contains the locations in arg
and var1. Then, rule S-STFLD ensures that the ﬁeld arg.obj
contains the merged location.
7
S-STUPD
φ(pc)↓
(cid:48)
(cid:48)
(cid:48)
(E
, h
, s
, φ
(cid:48)
) = mergeStacks(φ(pc) ∪ {s}, E, h, φ)
(cid:104)pc, E, h, s, φ, ψ(cid:105) → (cid:104)pc, E
(cid:48)
(cid:48)
(cid:48)
, h
, s
, φ
(cid:48)
[pc (cid:55)→ ⊥], ψ(cid:105)
S-STSKIP
(cid:104)pc, E, h, s, φ, ψ(cid:105) → (cid:104)pc + 1, E, h, s, φ, ψ(cid:105)
s = ⊥
S-BRFWD
P (pc) = br i
i > pc
(cid:48)
φ
= φ[i (cid:55)→ φ(i) ∪ {s}]
(cid:104)pc, E, h, s, φ, ψ(cid:105) → (cid:104)pc + 1, E, h,⊥, φ
(cid:48)
, ψ(cid:105)
S-BRTRUEFWD
P (pc) = brtrue i
i > pc
(cid:48)
φ
= φ[i (cid:55)→ φ(i) ∪ {s}]
(cid:104)pc, E, h, s :: sv, φ, ψ(cid:105) → (cid:104)pc + 1, E, h, s, φ
(cid:48)
, ψ(cid:105)
S-BRBWD
P (pc) = br i
i < pc
(cid:48)
φ
= (pc ∈ ψ ? φ : φ[pc (cid:55)→ s])
(cid:104)pc, E, h, s, φ, ψ(cid:105) → (cid:104)pc
(cid:48)
(cid:48)
, s
(pc
(cid:48)
, ψ
(cid:48)
, E, h, s
(cid:48)
) = (pc ∈ ψ ? (pc + 1,⊥, ψ) : (i, s, ψ ∪ {pc}))
, φ, ψ
(cid:48)(cid:105)
S-BRTRUEBWD
P (pc) = brtrue i
i < pc
(cid:48)
φ
= (pc ∈ ψ ? φ : φ[pc (cid:55)→ s])
(cid:104)pc, E, h, s :: sv, φ, ψ(cid:105) → (cid:104)pc
(cid:48)
(cid:48)
(cid:48)
, ψ
(pc
) = (pc ∈ ψ ? (pc + 1, ψ) : (i, ψ ∪ {pc}))
, E, h, s, φ, ψ
(cid:48)(cid:105)
Fig. 5: Abstract interpretation of control ﬂow
// arg.obj = flag ? var1 : var2;
1: ldvar arg
2: ldvar flag
3: brtrue 6
4: ldvar var2
5: br 7
6: ldvar var1
7: stfld obj
// S-LdVar
// S-LdVar
// S-BrTrueFwd
// S-Ldvar
// S-BrFwd
// S-StUpd and S-LdVar
// S-StUpd and S-StFld
Listing 7: Ternary operator in CIL
While the previous rules ensure the consistency of the
stack, we should also cater for potential loops resulting from
backward jump instructions. Thanks to our ﬂow-insensitive
analysis, it sufﬁces to analyze the "loop body" only once.
Speciﬁcally, we use a set ψ to keep track of the control ﬂow
instructions that trigger a backward jump and ensure that the
instructions at the jump target is analyzed only once (see
S-BRBWD and S-BRTRUEBWD). In particular, whenever an
unconditional jump has already been analyzed, i.e. pc ∈ ψ,
we set the stack to ⊥ (undeﬁned) and move on to executing
the next instruction. An undeﬁned stack will simply skip the
analyzes of the current instruction as in rule S-STSKIP unless
there was another jump to that instruction with a deﬁned stack
(in which case rule S-STUPD applies)1.
We illustrate our analysis of backward jumps with the
example in Listing 8. The example models the CIL represen-
tation of the C# pattern while(flag) {loop body}. The
analyzer examines the instruction br 15 at index (1) via rule S-
BRFWD, recording the current stack for the instruction at index
(15) in φ and updating the stack to undeﬁned. This is because
at this point we do not know if the next instruction at index
(2) will be reached from another conﬁguration. Therefore, we
simply skip the following instructions (rule S-STSKIP) until
we reach a merge point, i.e., an instruction where φ(pc) is
deﬁned. In our example, the merge point is the instruction at
index (15). The analyzer merges the stack in φ(15) with the
1We assume that φ(pc) ∪ ⊥ = φ(pc)
undeﬁned stack using rule S-STUPD, and uses the new stack,
while updating the φ node. Subsequently, the analyzer loads
the variable f lag onto the stack and examines the instruction
brtrue 2 at index (16) via rule S-BRTRUEBWD. Since 16 (cid:54)∈ ψ,
this results in transferring control to the instruction at index
(2) and analyzing the loop body. If the analyzer reaches the
instruction brtrue 2 again, it ﬁnds that the instruction has
already been analyzed, i.e., 16 ∈ ψ, and continues with the
next instruction.
1: br 15
// S-BrFwd
2:
15:
//loop body
// S-StUpd
// while (flag)
ldvar flag
// S-LdVar
16: brtrue 2
// 2 x S-BrTrueBwd
Listing 8: While loops in CIL
Aliasing and taint tracking Recall that the goal of our
analyses is tracking information ﬂows from sensitive sinks to
attack triggers. To achieve this, we enrich the location nodes in
our abstract heap graph with a taint mark whenever the return
value of a sensitive sink is analyzed. Thanks to our store-
based abstract heap model, the heap graph already accounts
for aliases to a given node. In fact, aliases can be computed
by looking at the labels of incoming edges to a given location
node. Therefore, we can compute the taint mark of a reference
by reading the taint mark of the node it points to.
Figure 6 provides an example of aliasing and taint tracking.
The call to the sensitive sink at line (1) pushes the return
value onto the stack, marks the corresponding node as tainted
and adds an edge labeled with b.f oo to the tainted node.
Similarly, the instruction at line (2) creates an alias of b.bar
to the tainted node, which yields the heap graph in Figure 6b.
Finally, the analysis of the virtual call at line (3) reveals that
the caller b.bar is tainted, hence an attacker controlling its type
determines which concrete implementation of V irtualCall()
is executed. Therefore, we consider such method as a potential
attack trigger.
8
1: b.foo = SSink(arg);
2: b.bar = b.foo;
3: b.bar.VirtualCall();
arg
la
b
lb
T
foo
bar
(a) Code
(b) Heap
Fig. 6: Aliasing and taint tracking
C. Modular inter-procedural analysis
We now present
the inter-procedural symbolic analysis
underpinning our computation of OIV patterns. The analysis
relies on a preliminary stage that reconstructs the Call Graph
containing the entry points that may reach sensitive sinks.
Subsequently, it performs a modular analysis of the call graph,
based on method summaries, to determine OIV patterns.
Call graph analysis. We ﬁrst analyze the target set of
CIL assemblies to identify method signatures associated with
call and callvirt instructions, and store them as keys in a
hash table with the caller methods as values. The hash table
represents a call graph, which we can reconstruct via backward
analysis. A path from a sensitive sink to an entry point can
be computed in O(n) time, where n is the call stack’s depth.
We also compute the type-hierarchy graph to determine all
implementations of virtual method calls. We assume that a
virtual call of a base method can transfer control
to any
implementation of that method and store such information in
the call graph. The analyzer uses this information during the
backward reconstruction of the call graph from a sensitive sink
to entry points, as well as during the abstract interpretation of
callvirt instructions.
Inter-procedural analysis with method summaries. We
perform a modular dataﬂow analysis for every entry point
identiﬁed in the preliminary stage. Whenever our algorithm
reaches a new method, it triggers the intra-procedural analysis
(described in Section IV-B) to analyze the method inde-
pendently of the caller’s context, i.e., both the heap h and
the environment E are empty. As a result,
it produces a
compact representation of the heap graph called summary. The
summary is then stored into a caching structure K, and it is
reused for every subsequent call to the same method.
We use the following notation to describe the abstract
interpretation of method calls: A state σ ∈ State is a tuple
(E, h, s, φ, ψ) representing the calling context in a symbolic
conﬁguration and it is stored whenever we start the analysis of
a new method. The symbolic call stack cs ∈ (State × PC )∗
is a stack of pairs (σ, pc) containing the state of the caller
and program counter index of the caller in state σ. A partial
mapping K : Sig (cid:55)→ Sum caches method summaries for each
method signature. A method summary sum ∈ Sum is deﬁned