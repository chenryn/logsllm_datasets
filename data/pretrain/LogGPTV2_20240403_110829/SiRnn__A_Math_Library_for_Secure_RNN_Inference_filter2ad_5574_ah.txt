OT can be used to obtain lower communication. However,
in our setting, when the IKNP-OT instances are computed
by multiple threads and are “load-balanced” (i.e., each party
plays the role of the sender in half the OT instances and as the
receiver in the other half), we empirically observe that IKNP-
style extensions are more performant than silent-OT in our
LAN evaluation environment. Hence, SIRNN uses IKNP-style
OT extensions in Section VI.
ACKNOWLEDGEMENT
We thank Pratik Bhatu, Aayan Kumar, and Aditya Kusupathi
for their help with the implementation and the evaluation.
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:28:57 UTC from IEEE Xplore.  Restrictions apply. 
1015
REFERENCES
[1] “EMP-toolkit: Efﬁcient MultiParty computation toolkit,” https://github.
com/emp-toolkit, 2016.
[2] “TF-Encrypted: A Framework for Encrypted Machine Learning in
TensorFlow,” https://github.com/tf-encrypted/tf-encrypted, 2018.
[3] “Multi-Protocol SPDZ: Versatile framework for multi-party computa-
tion,” 2019. [Online]. Available: https://github.com/data61/MP-SPDZ
[4] “Intel SVML,” https://software.intel.com/content/www/us/en/develop/
documentation/mkl-vmperfdata/top.html, 2020.
[5] N. Agrawal, A. S. Shamsabadi, M. J. Kusner, and A. Gasc´on, “QUO-
TIENT: Two-Party Secure Neural Network Training and Prediction,”
in CCS 2019.
[6] M. Aliasgari and M. Blanton, “Secure computation of hidden markov
models,” in SECRYPT, 2013.
[7] M. Aliasgari, M. Blanton, and F. Bayatbabolghani, “Secure computa-
tion of hidden markov models and secure ﬂoating-point arithmetic in
the malicious model,” Int. J. Inf. Sec., 2017.
[8] M. Aliasgari, M. Blanton, Y. Zhang, and A. Steele, “Secure computa-
tion on ﬂoating point numbers,” in NDSS, 2013.
[9] A. Aly and N. P. Smart, “Benchmarking privacy preserving scientiﬁc
operations,” in ACNS, 2019.
[10] D. W. Archer, J. M. Calder´on Trilla, J. Dagit, A. Malozemoff,
Y. Polyakov, K. Rohloff, and G. Ryan, “Ramparts: A programmer-
friendly system for building homomorphic encryption applications,” in
WAHC 2019.
[11] G. Asharov, Y. Lindell, T. Schneider, and M. Zohner, “More efﬁcient
oblivious transfer and extensions for faster secure computation,” in CCS
2013.
[12] S. Bai, G. Yang, J. Shi, G. Liu, and Z. Min, “Privacy-preserving
oriented ﬂoating-point number fully homomorphic encryption scheme,”
Secur. Commun. Networks 2018.
[13] M. Ball, B. Carmer, T. Malkin, M. Rosulek, and N. Schimanski,
“Garbled Neural Networks are Practical,” ePrint 2019/338.
[14] P. Banerjee, D. Bagchi, M. Haldar, A. Nayak, V. Kim, and R. Uribe,
“Automatic conversion of ﬂoating point matlab programs into ﬁxed
point fpga based hardware design,” in FCCM 2003.
[15] D. Beaver, “Efﬁcient Multiparty Protocols Using Circuit Randomiza-
tion,” in CRYPTO 1991.
[16] G. R. Blakley, “Safeguarding cryptographic keys,” in Managing Re-
quirements Knowledge, International Workshop on, 1979.
[17] F. Boemer, R. Cammarota, D. Demmler, T. Schneider, and H. Yalame,
“MP2ML: a mixed-protocol machine learning framework for private
inference,” in ARES 2020.
[18] F. Boemer, A. Costache, R. Cammarota, and C. Wierzynski, “nGraph-
HE2: A High-Throughput Framework for Neural Network Inference
on Encrypted Data,” in WAHC 2019.
[19] F. Boemer, Y. Lao, R. Cammarota, and C. Wierzynski, “nGraph-HE:
A Graph Compiler for Deep Learning on Homomorphically Encrypted
Data,” in CF 2019.
[20] C. Boura, N. Gama, and M. Georgieva, “Chimera: a uniﬁed framework
for B/FV, TFHE and HEAAN fully homomorphic encryption and
predictions for deep learning,” ePrint 2018/758.
[21] E. Boyle, N. Chandran, N. Gilboa, D. Gupta, Y. Ishai, N. Kumar, and
M. Rathee, “Function Secret Sharing for Mixed-Mode and Fixed-Point
Secure Computation,” ePrint 2020/1392.
[22] E. Boyle, G. Couteau, N. Gilboa, Y. Ishai, L. Kohl, P. Rindal, and
P. Scholl, “Efﬁcient two-round OT extension and silent non-interactive
secure computation,” in CCS. ACM, 2019, pp. 291–308.
[23] L. Braun, D. Demmler, T. Schneider, and O. Tkachenko, “MOTION
- A Framework for Mixed-Protocol Multi-Party Computation,” ePrint
2020/1137.
[24] D. Brooks and M. Martonosi, “Dynamically exploiting narrow width
operands to improve processor power and performance,” in HPCA
1999.
[25] N. B¨uscher, D. Demmler, S. Katzenbeisser, D. Kretzmer, and T. Schnei-
der, “HyCC: Compilation of Hybrid Protocols for Practical Secure
Computation,” in CCS 2018.
[26] R. Canetti, “Security and Composition of Multiparty Cryptographic
Protocols,” J. Cryptology 2000.
[29] ——, “Efﬁcient Secure Floating-point Arithmetic using Shamir Secret
Sharing,” in ICETE (2), 2019.
[30] ——, “Evaluation of ﬂoating-point arithmetic protocols based on
shamir secret sharing,” in ICETE (Selected Papers), 2019.
[31] O. Catrina and A. Saxena, “Secure computation with ﬁxed-point
numbers,” in Financial Cryptography, 2010.
[32] N. Chandran, D. Gupta, A. Rastogi, R. Sharma, and S. Tripathi,
“EzPC: Programmable and Efﬁcient Secure Two-Party Computation
for Machine Learning,” in IEEE EuroS&P 2019.
[33] Y. Chang and C. Lu, “Oblivious polynomial evaluation and oblivious
neural learning,” in ASIACRYPT, 2001.
[34] V. Chen, V. Pastro, and M. Raykova, “Secure Computation for Machine
Learning With SPDZ,” in PPML 2018, NeurIPS 2018 Workshop.
[35] I. Chillotti, N. Gama, M. Georgieva, and M. Izabach`ene, “Faster fully
homomorphic encryption: Bootstrapping in less than 0.1 seconds,” in
ASIACRYPT 2016.
[36] K. Cho, B. van Merrienboer, D. Bahdanau, and Y. Bengio, “On the
properties of neural machine translation: Encoder-decoder approaches,”
in SSST-8, 2014.
[37] A. P. K. Dalskov, D. Escudero, and M. Keller, “Secure evaluation of
quantized neural networks,” PoPETs 2020.
[38] E. Darulova and V. Kuncak, “Sound compilation of reals,” in POPL
2014.
[39] R. Dathathri, O. Saarikivi, H. Chen, K. Lauter, S. Maleki, M. Musu-
vathi, and T. Mytkowicz, “CHET: An Optimizing Compiler for Fully-
Homomorphic Neural-Network Inferencing,” in PLDI 2019.
[40] D. Demmler, G. Dessouky, F. Koushanfar, A. Sadeghi, T. Schneider,
and S. Zeitouni, “Automated synthesis of optimized circuits for secure
computation,” in CCS 2015.
[41] D. Demmler, T. Schneider, and M. Zohner, “ABY - A Framework
for Efﬁcient Mixed-Protocol Secure Two-Party Computation,” in NDSS
2015.
[42] G. Dessouky, F. Koushanfar, A. Sadeghi, T. Schneider, S. Zeitouni, and
M. Zohner, “Pushing the Communication Barrier in Secure Computa-
tion using Lookup Tables,” in NDSS 2017.
[43] V. Dimitrov, L. Kerik, T. Krips, J. Randmets, and J. Willemson,
“Alternative implementations of secure real numbers,” in CCS 2016.
[44] D. Escudero, S. Ghosh, M. Keller, R. Rachuri, and P. Scholl, “Im-
proved Primitives for MPC over Mixed Arithmetic-Binary Circuits,”
in CRYPTO 2020.
[45] L. Fousse, G. Hanrot, V. Lef`evre, P. P´elissier, and P. Zimmermann,
“MPFR: A multiple-precision binary ﬂoating-point library with correct
rounding,” ACM Trans. Math. Softw., 2007.
[46] M. Franz and S. Katzenbeisser, “Processing encrypted ﬂoating point
signals,” in MM&Sec 2011.
[47] R. Gilad-Bachrach, N. Dowlin, K. Laine, K. E. Lauter, M. Naehrig,
and J. Wernsing, “CryptoNets: Applying Neural Networks to Encrypted
Data with High Throughput and Accuracy,” in ICML 2016.
[48] D. Goldberg, “What every computer scientist should know about
ﬂoating-point arithmetic,” ACM Comput. Surv., 1991.
[49] O. Goldreich, S. Micali, and A. Wigderson, “How to Play any Mental
Game or A Completeness Theorem for Protocols with Honest Major-
ity,” in ACM STOC 1987.
[50] R. E. Goldschmidt, “Applications of division by convergence,” M.S.
thesis, MIT, 1964.
[51] S. Gopinath, N. Ghanathe, V. Seshadri, and R. Sharma, “Compiling
KB-Sized Machine Learning Models to Tiny IoT Devices,” in PLDI
2019.
[52] C. Guo, J. Katz, X. Wang, C. Weng, and Y. Yu, “Better concrete
security for half-gates garbling (in the multi-instance setting),” in
CRYPTO (2), 2020.
[53] C. Guo, J. Katz, X. Wang, and Y. Yu, “Efﬁcient and secure multiparty
computation from ﬁxed-key block ciphers,” in IEEE Symposium on
Security and Privacy, 2020.
[54] J. Harrison, “A machine-checked theory of ﬂoating point arithmetic,”
in Theorem Proving in Higher Order Logics, 1999.
[55] T. Hastie, R. Tibshirani, and J. Friedman, The Elements of Statistical
Learning (2nd Edition), 2009.
[56] K. He, X. Zhang, S. Ren, and J. Sun, “Deep Residual Learning for
Image Recognition,” in CVPR 2016.
[27] S. Carpov, P. Dubrulle, and R. Sirdey, “Armadillo: A compilation chain
for privacy preserving applications,” in SCC 2015.
[28] O. Catrina, “Round-efﬁcient protocols for secure multiparty ﬁxed-point
[57] B. Hemenway, S. Lu, R. Ostrovsky, and W. W. IV, “High-precision
secure computation of satellite collision probabilities,” in SCN 2016.
[58] E. Hesamifard, H. Takabi, and M. Ghasemi, “CryptoDL: Deep Neural
arithmetic,” in COMM 2018.
Networks over Encrypted Data,” CoRR 2017.
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:28:57 UTC from IEEE Xplore.  Restrictions apply. 
1016
[59] S. Hochreiter and J. Schmidhuber, “Long Short-Term Memory,” Neural
Computation, 1997.
[60] A. Holzer, M. Franz, S. Katzenbeisser, and H. Veith, “Secure two-party
computations in ANSI C,” in CCS 2012.
[61] G. Huang, Z. Liu, L. van der Maaten, and K. Q. Weinberger, “Densely
Connected Convolutional Networks,” in CVPR 2017.
[62] Y. Ishai, J. Kilian, K. Nissim, and E. Petrank, “Extending Oblivious
Transfers Efﬁciently,” in CRYPTO 2003.
[63] M. Ito, N. Takagi, and S. Yajima, “Efﬁcient Initial Approximation
for Multiplicative Division and Square Root by a Multiplication with
Operand Modiﬁcation,” IEEE Transactions on Computers, 1997.
[64] C. Juvekar, V. Vaikuntanathan, and A. Chandrakasan, “GAZELLE: A
Low Latency Framework for Secure Neural Network Inference,” in
USENIX Security 2018.
[65] L. Kamm and J. Willemson, “Secure ﬂoating point arithmetic and
private satellite collision analysis,” Int. J. Inf. Sec., 2015.
[66] M. Keller, “MP-SPDZ: A versatile framework for multi-party compu-
tation,” in CCS, 2020.
[67] L. Kerik, P. Laud, and J. Randmets, “Optimizing MPC for robust and
scalable integer and ﬂoating-point arithmetic,” in Financial Cryptogra-
phy Workshops 2016.
[68] D. Kim, Y. Son, D. Kim, A. Kim, S. Hong, and J. H. Cheon, “Privacy-
preserving approximate GWAS computation based on homomorphic
encryption,” ePrint 2019/152.
[69] B. Knott, S. Venkataraman, A. Hannun, S. Sengupta, M. Ibrahim,
and L. van der Maaten, “CrypTen: Secure multi-party computation
meets machine learning,” in Workshop on Privacy Preserving Machine
Learning, December 11, 2020.
[70] V. Kolesnikov and R. Kumaresan, “Improved OT Extension for Trans-
ferring Short Secrets,” in CRYPTO 2013.
[71] T. Krips and J. Willemson, “Hybrid model of ﬁxed and ﬂoating point
numbers in secure multiparty computations,” in ISC, 2014.
[72] A. Kumar, V. Seshadri, and R. Sharma, “Shiftry: RNN Inference in
2KB of RAM,” in OOPSLA, 2020.
[73] N. Kumar, M. Rathee, N. Chandran, D. Gupta, A. Rastogi, and
R. Sharma, “CrypTFlow: Secure TensorFlow Inference,” in IEEE S&P
2020.
[74] A. Kusupati, M. Singh, K. Bhatia, A. Kumar, P. Jain, and M. Varma,
“FastGRNN: A Fast, Accurate, Stable and Tiny Kilobyte Sized Gated
Recurrent Neural Network,” in NeurIPS 2018.
[75] P. Laud and J. Randmets, “A domain-speciﬁc language for low-level
secure multiparty computation protocols,” in CCS 2015.
[76] S. Laur, H. Lipmaa, and T. Mielik¨ainen, “Cryptographically private
support vector machines,” in SIGKDD 2006.
[77] J. Le Maire, N. Brunie, F. De Dinechin, and J. Muller, “Computing
ﬂoating-point logarithms with ﬁxed-point operations,” in IEEE ARITH
2016.
[78] W. Lee, R. Sharma, and A. Aiken, “On automatically proving the
correctness of math.h implementations,” in POPL 2018.
[79] ——, “Verifying bit-manipulations of ﬂoating-point,” in PLDI 2016.
[80] K.-P. Lin and M.-S. Chen, “Privacy-preserving outsourcing support
vector machines with random transformation,” in SIGKDD 2010.
[81] Y. Lindell, How to Simulate It – A Tutorial on the Simulation Proof
Technique, 2017.
[82] C. Liu, X. S. Wang, K. Nayak, Y. Huang, and E. Shi, “ObliVM:
A Programming Framework for Secure Computation,” in IEEE S&P
2015.
[83] J. Liu, M. Juuti, Y. Lu, and N. Asokan, “Oblivious Neural Network
Predictions via MiniONN Transformations,” in CCS 2017.
[84] Y. Liu, Y. Chiang, T. Hsu, C. Liau, and D. Wang, “Floating point
arithmetic protocols for constructing secure data analysis application,”
in KES, 2013.
[85] Q. Lou, B. Feng, G. Charles Fox, and L. Jiang, “Glyph: Fast and
accurately training deep neural networks on encrypted data,” to appear
in NeurIPS 2020.
[86] W.-j. Lu, Y. Fang, Z. Huang, C. Hong, C. Chen, H. Qu, Y. Zhou, and
K. Ren, “Faster secure multiparty computation of adaptive gradient
descent,” to appear in PPML 2020, NeurIPS 2020 Workshop.
[87] E. Makri, D. Rotaru, N. P. Smart, and F. Vercauteren, “EPIC: Efﬁcient
Private Image Classiﬁcation (or: Learning from the Masters),” in CT-
RSA 2019.
[88] D. Malkhi, N. Nisan, B. Pinkas, and Y. Sella, “Fairplay - Secure Two-
Party Computation System,” in USENIX Security 2004.
[89] D. Menard, D. Chillet, F. Charot, and O. Sentieys, “Automatic ﬂoating-
point to ﬁxed-point conversion for dsp code generation,” in CASES
2002.
[90] P. Mishra, R. Lehmkuhl, A. Srinivasan, W. Zheng, and R. A. Popa,
“Delphi: A Cryptographic Inference Service for Neural Networks,” in
USENIX Security 2020.
[91] P. Mohassel and P. Rindal, “ABY3: A Mixed Protocol Framework for
Machine Learning,” in CCS 2018.
[92] P. Mohassel and Y. Zhang, “SecureML: A System for Scalable Privacy-
Preserving Machine Learning,” in IEEE S&P 2017.
[93] K. Nandakumar, N. K. Ratha, S. Pankanti, and S. Halevi, “Towards
deep neural network training on encrypted data,” in CVPR Workshops,
2019.
[94] A. Nayak, M. Haldar, A. Choudhary, and P. Banerjee, “Precision
and error analysis of matlab applications during automated hardware
synthesis for FPGAs,” in DATE 2001.
[95] A. Patra, T. Schneider, A. Suresh, and H. Yalame, “ABY2.0: Improved
Mixed-Protocol Secure Two-Party Computation,” to appear in USENIX
Security 2021.
[96] D. Peng, Z. Sun, Z. Chen, Z. Cai, L. Xie, and L. Jin, “Detecting heads
using feature reﬁne net and cascaded multi-scale architecture,” arXiv
2018.
[97] P. Pullonen and S. Siim, “Combining secret sharing and garbled
circuits for efﬁcient private IEEE 754 ﬂoating-point computations,” in
Financial Cryptography Workshops, 2015.
[98] Y. Rahulamathavan, R. C.
. Phan, S. Veluru, K. Cumanan, and
M. Rajarajan, “Privacy-preserving multi-class support vector machine
for outsourcing the data classiﬁcation in cloud,” TDSC 2014.
[99] D. Rathee, M. Rathee, N. Kumar, N. Chandran, D. Gupta, A. Rastogi,
and R. Sharma, “CrypTFlow2: Practical 2-Party Secure Inference,” in
CCS 2020.
[100] M. S. Riazi, M. Samragh, H. Chen, K. Laine, K. E. Lauter, and
F. Koushanfar, “XONN: XNOR-based Oblivious Deep Neural Network
Inference,” in USENIX Security 2019.
[101] M. S. Riazi, C. Weinert, O. Tkachenko, E. M. Songhori, T. Schnei-
der, and F. Koushanfar, “Chameleon: A Hybrid Secure Computation
Framework for Machine Learning Applications,” in AsiaCCS 2018.
[102] B. D. Rouhani, M. S. Riazi, and F. Koushanfar, “DeepSecure: Scalable
Provably-Secure Deep Learning,” in DAC 2018.
[103] T. Ryffel, A. Trask, M. Dahl, B. Wagner, J. Mancuso, D. Rueckert,
and J. Passerat-Palmbach, “A generic framework for privacy preserving
deep learning,” CoRR, 2018.
[104] O. Saha, A. Kusupati, H. V. Simhadri, M. Varma, and P. Jain, “RN-
NPool: Efﬁcient Non-linear Pooling for RAM Constrained Inference,”
to appear in NeurIPS 2020.
[105] M. Sandler, A. Howard, M. Zhu, A. Zhmoginov, and L. Chen, “Mo-
bilenetv2: Inverted residuals and linear bottlenecks,” in CVPR 2018.
[106] E. Schkufza, R. Sharma, and A. Aiken, “Stochastic Optimization of
Floating-Point Programs with Tunable Precision,” in PLDI 2014.