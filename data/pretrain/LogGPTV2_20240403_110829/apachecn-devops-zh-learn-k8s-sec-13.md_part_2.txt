*   **Use resource monitoring tools in Kubernetes clusters**: As discussed in [*Chapter 10*](10.html#_idTextAnchor305), *Real-Time Monitoring and Resource Management of a Kubernetes Cluster*, resource-monitoring tools such as Prometheus and Grafana can help identify issues of higher memory consumption in the master node. High values in the graphs for Prometheus metrics could look as follows:
    ```
    container_memory_max_usage_bytes{pod_ name="kube-apiserver-xxx" }
    sum(rate(container_cpu_usage_seconds_total{pod_name="kube-apiserver-xxx"}[5m]))
    sum(rate(container_network_receive_bytes_total{pod_name="kube-apiserver-xxx"}[5m]))
    ```
    这些资源以`kube-apiserver`为单位，每隔 5 分钟显示最大内存、中央处理器和网络使用率。这些使用模式中的任何异常都是攻击`kube-apiserver`的信号。
*   **Set up high-availability Kubernetes masters**: We learned about high-availability clusters in [*Chapter 11*](11.html#_idTextAnchor324), *Defense in Depth*. High-availability clusters have multiple instances of Kubernetes components. If the load on one component is high, other instances can be used until the load is reduced or the first instance is restarted.
    使用`kops`，可以使用`--master-zones={zone1, zone2}`拥有多个主控:
    ```
    kops create cluster k8s-clusters.k8s-demo-zone.com \
     --cloud aws \
     --node-count 3 \
     --zones $ZONES \
     --node-size $NODE_SIZE \
     --master-size $MASTER_SIZE \
     --master-zones $ZONES \
     --networking calico \
     --kubernetes-version 1.14.3 \
     --yes \
    kube-apiserver-ip-172-20-43-65.ec2.internal              1/1     Running   4          4h16m
    kube-apiserver-ip-172-20-67-151.ec2.internal             1/1     Running   4          4h15m
    ```
    可以看到，这个集群中运行着多个`kube-apiserver`Pod 。
*   **限制用户使用 RBAC** 的权限:用户的权限也要遵循最小权限原则，在 [*第 4 章*](04.html#_idTextAnchor108)*中讨论了在 Kubernetes* 中应用最小权限原则。如果用户不需要任何资源的`PATCH`访问权限，则应该更新角色，使他们没有访问权限。
*   **在分段环境**中测试您的补丁程序:分段环境应该设置为生产环境的副本。开发人员并不完美，因此开发人员可能会创建一个格式错误的补丁。如果在临时环境中测试集群的补丁或更新，则可以在不中断生产服务的情况下找到补丁中的错误。
DoS 通常被认为是一个低严重性的问题，但是如果它发生在您的集群的核心组件上，您应该认真对待它。`kube-apiserver`上的 DoS 攻击会破坏整个集群的可用性。接下来，我们看另一个针对 API 服务器的 DoS 攻击。未经身份验证的用户可以执行此攻击，这使得它比 CVE-2019-1002100 更加严重。
# YAML 解析中的拒绝服务问题——CVE-2019-11253
XML 炸弹，或者说十亿次“T4”攻击，在任何 XML 解析代码中都很流行。类似于 XML 中的解析问题，这是发送到`kube-apiserver`的 YAML 文件中的解析问题。如果发送到服务器的 YAML 文件有递归引用，它会触发`kube-apiserver`消耗 CPU 资源，从而导致应用编程接口服务器的可用性问题。在大多数情况下，`kube-apiserver`解析的请求仅限于经过身份验证的用户，因此未经身份验证的用户不应触发此问题。在 1.14 之前的 Kubernetes 版本中，该规则有一个例外，允许未经身份验证的用户检查他们是否可以使用`kubectl auth can-i`执行操作。
此问题与 CVE-2019-1002100 相似，但更严重，因为未经身份验证的用户也可以触发此问题。
## 缓解策略
您可以使用以下策略针对此问题和类似于 CVE-2019-11253 的尚未发现的问题强化您的集群:
*   **在 Kubernetes 集群**中使用资源监控工具:与 CVE-2019-1002100 类似，我们在 [*第 10 章*](10.html#_idTextAnchor305)*中讨论的 Prometheus 和 Grafana 等资源监控工具可以帮助识别 Kubernetes 集群*中内存消耗较高的问题。
*   **启用 RBAC** :该漏洞是由于`kube-apiserver`对 YAML 文件中递归实体的处理不当以及未经身份验证的用户与`kube-apiserver`交互的能力造成的。我们在第 7 章[](07.html#_idTextAnchor186)**认证、授权和准入控制*中讨论了 RBAC。在当前版本的 Kubernetes 中，默认情况下启用 RBAC。您也可以通过将`--authorization-mode=RBAC`传递到`kube-apiserver`来启用它。在这种情况下，未经认证的用户不得与`kube-apiserver`互动。对于经过身份验证的用户，应遵循最小权限原则。*
**   **Disable auth can-i for unauthenticated users (for v1.14.x)**: Unauthenticated users should not be allowed to interact with `kube-apiserver`. In Kubernetes v1.14.x, you can disable `auth can-i` for unauthenticated servers using the RBAC file at [https://github.com/kubernetes/kubernetes/files/3735508/rbac.yaml.txt](https://github.com/kubernetes/kubernetes/files/3735508/rbac.yaml.txt):
    ```
    kubectl auth reconcile -f rbac.yaml --remove-extra-subjects --remove-extra-permissions
    kubectl annotate --overwrite clusterrolebinding/system:basic-user rbac.authorization.kubernetes.io/autoupdate=false 
    ```
    第二个命令禁用`clusterrolebinding`的自动更新，这将确保重启时更改不会被覆盖。
    *   **kube-apiserver 不应暴露于互联网**:允许可信实体使用防火墙或 VPCs 访问 API 服务器是一个很好的做法。*   **禁用匿名授权**:我们在 [*第 6 章*](06.html#_idTextAnchor170)*保护集群组件*中讨论了`anonymous-auth`作为一个应该禁用的选项。默认情况下，在 Kubernetes 1.16+中，对旧策略规则启用匿名身份验证。如果您没有使用任何遗留规则，建议通过默认将`--anonymous-auth=false`传递给应用编程接口服务器来禁用`anonymous-auth`。*
 *正如我们前面讨论的，对`kube-apiserver`的 DoS 攻击会导致整个集群的服务中断。除了使用最新版本的 Kubernetes(包括针对此问题的修补程序)之外，遵循这些缓解策略以避免集群中出现类似问题也很重要。接下来，我们将讨论授权模块中的一个问题，该问题会触发经过身份验证的用户的权限提升。
# 角色解析中的权限升级问题–CVE-2019-11247
我们在第 7 章*认证、授权和准入控制*中详细讨论了 RBAC。角色和角色绑定允许用户获得执行特定操作的权限。这些权限是命名空间。如果用户需要集群范围的权限，则使用集群角色和集群角色绑定。此问题允许用户进行群集范围的修改，即使他们的权限是命名空间的。接纳控制器的配置，如开放策略访问，可以由具有命名空间角色的用户修改。
## 缓解策略
您可以使用以下策略来针对此问题和类似于 CVE-2019-11247 的尚未发现的问题强化您的集群:
*   **避免在角色和角色绑定**中使用通配符:角色和集群角色应该特定于资源名称、动词和应用编程接口组。将`*`添加到`roles`可以允许用户访问他们不应该访问的资源。这坚持了我们在 [*第四章*](04.html#_idTextAnchor108)*中讨论的最小权限原则，在 Kubernetes*中应用最小权限原则。
*   **Enable Kubernetes auditing**: We discussed auditing and audit policies for Kubernetes in [*Chapter 11*](11.html#_idTextAnchor324), *Defense in Depth*. Kubernetes auditing can help identify any unintended actions in a Kubernetes cluster. In most cases, a vulnerability such as this will be used to modify and delete any additional controls within the cluster. You can use the following policy to identify instances of these kinds of exploits:
    ```
      apiVersion: audit.k8s.io/v1 # This is required.
          kind: Policy
          rules:
          - level: RequestResponse
            verbs: ["patch", "update", "delete"]
            resources:
            - group: ""
              resources: ["pods"]
              namespaces: ["kube-system", "monitoring"]
    ```
    此策略记录在`kube-system`或`monitoring`命名空间中删除或修改 pods 的任何实例。
这个问题当然是一个有趣的问题，因为它强调了 Kubernetes 提供的安全功能如果配置错误也是有害的。接下来，我们将讨论`kube-hunter`，这是一个开源工具，可以在您的集群中找到任何已知的安全问题。
# 使用 kube-hunter 扫描已知漏洞
由 kubernetes 发布的安全建议和公告([https://Kubernetes . io/docs/reference/issues-security/security/](https://kubernetes.io/docs/reference/issues-security/security/))是跟踪 Kubernetes 中发现的新安全漏洞的最佳方式。公告和咨询电子邮件可能会让人有点不知所措，而且总是有可能错过一个重要的漏洞。为了避免这些情况，一个定期检查集群中任何已知 CVE 的工具来拯救。`kube-hunter`是由 Aqua 开发和维护的开源工具，有助于识别您的 Kubernetes 集群中已知的安全问题。
设置`kube-hunter`的步骤如下:
1.  克隆存储库:
    ```
    $git clone https://github.com/aquasecurity/kube-hunter
    ```
2.  运行集群中的`kube-hunter`Pod :
    ```
    $ ./kubectl create -f job.yaml
    ```
3.  View the logs to find any issues with your cluster:
    ```
    $ ./kubectl get pods
    NAME                READY   STATUS              RESTARTS   AGE
    kube-hunter-7hsfc   0/1     ContainerCreating   0          12s
    ```
    以下输出显示了 Kubernetes v1.13.0 中已知漏洞的列表:
![Figure 13.2 – Results of kube-hunter ](img/B15566_13_002.jpg)
图 13.2–库贝-亨特的结果
这个截图强调了`kube-hunter`为 Kubernetes v1.13.0 集群发现的一些问题。`kube-hunter`发现的问题应被视为关键问题，并应立即解决。
# 摘要
在这一章中，我们讨论了客户价值评估的重要性。这些公开的标识符对于集群管理员、安全研究人员和攻击者来说非常重要。我们讨论了由 MITRE 维护的 CVE 条目的重要方面。然后，我们查看了四个著名的 CVE，并讨论了每个 CVE 的问题和缓解策略。作为集群管理员，升级`kubectl`客户端和 Kubernetes 版本应该永远是您的第一要务。但是，添加缓解策略来检测和防止由未公开报告的类似问题引起的漏洞同样重要。最后，我们讨论了一个开源工具`kube-hunter`，它可以用来定期识别您的 Kubernetes 集群中的问题。这消除了集群管理员密切关注 Kubernetes 的安全建议和公告的开销。
现在，您应该能够理解公开披露的漏洞的重要性，以及这些建议如何帮助加强您的 Kubernetes 集群的整体安全态势。通读这些建议将有助于您识别集群中的任何问题，并有助于进一步强化集群。
# 问题
1.  对于集群管理员、安全研究人员和攻击者来说，CVE 条目最重要的部分是什么？
2.  为什么像 CVE-2019-11246 这样的客户端安全问题对 Kubernetes 集群很重要？
3.  为什么 kube-apiserver 中的 DoS 问题被视为高严重性问题？
4.  比较 API 服务器中经过身份验证和未经身份验证的 DoS 问题。
5.  讨论`kube-hunter`的重要性。
# 更多参考
*   《CVE 清单》:https://CVE . mitre . org/CVE/search _ CVE _ list . html
*   用 Falco 检测 CVE-2019-11246:[https://sysdig . com/blog/how-detect-kubernetes-漏洞-CVE-2019-11246-使用-falco/](https://sysdig.com/blog/how-to-detect-kubernetes-vulnerability-cve-2019-11246-using-falco/)
*   用 OPA 预防 CVE-2019-11246:[https://blog . styra . com/blog/investing-and-correct-cves-with-k8s-API](https://blog.styra.com/blog/investigate-and-correct-cves-with-the-k8s-api)
*   CVE-2019-1002100 的 GitHub 问题:t1]
*   CVE-2019-11253 的 GitHub 问题:t1]
*   CVE-2019-11247 的 GitHub 问题:t1]
*   `kube-hunter`:[https://github . com/aqua security/kube-hunter](https://github.com/aquasecurity/kube-hunter)
*   CVE 2020-8555 的 GitHub 问题:t1]
*   CVE 2020-8555 的 GitHub 问题:[https://github . com/kubrines/kubrines/issues/91507](https://github.com/kubernetes/kubernetes/issues/91507)**