不如我们看看`--cpu-shares`值能为我们做些什么？为此，我们需要模拟资源争用，在下一个示例中，我们将尝试在 60 秒的时间内，在机器上有多少个 CPU，就在多少个容器中尽可能多地递增一个整数变量。代码有点粗糙，但大部分是为了让 CPU 在所有内核上达到资源争用级别。
将以下内容添加到名为`cpu_shares.sh`的文件中(也可在[https://github.com/sgnn7/deploying_with_docker](https://github.com/sgnn7/deploying_with_docker)上获得):
```
#!/bin/bash -e
CPU_COUNT=$(nproc --all)
START_AT=$(date +%s)
STOP_AT=$(( $START_AT + 60 ))
echo "Detected $CPU_COUNT CPUs"
echo "Time range: $START_AT -> $STOP_AT"
declare -a CONTAINERS
echo "Allocating all cores but one with default shares"
for ((i = 0; i /dev/null
done
```
现在，我们将运行这段代码，看看我们的标志的效果:
```
$ # Make the file executable
$ chmod +x ./cpu_shares.sh
$ # Run our little program
$ ./cpu_shares.sh
Detected 8 CPUs
Time range: 1507405189 -> 1507405249
Allocating all cores but one with default shares
Starting container 0
Starting container 1
Starting container 2
Starting container 3
Starting container 4
Starting container 5
Starting container 6
Starting container with high shares
Waiting full minute for containers to finish...
Container 0 counted to 25380
Container 1 counted to 25173
Container 2 counted to 24961
Container 3 counted to 24882
Container 4 counted to 24649
Container 5 counted to 24306
Container 6 counted to 24280
Container 7 counted to 31938
```
虽然具有高`--cpu-share`值的容器没有得到预期的计数的完全增加，但是如果我们在更长的时间内使用更严格的 CPU 限制循环运行基准测试，差异将会更大。但是即使在我们的小例子中，您也可以看到最后一个容器比机器上所有其他运行的容器有明显的优势。
为了了解`--cpus`标志的比较情况，让我们来看看它在非竞争系统上可以做什么:
```
$ # First without any limiting
$ time docker run -it \
 --rm \
 ubuntu \
 /bin/bash -c 'for ((i=0; i/dev/null; done'
real    0m1.902s
user    0m0.030s
sys    0m0.006s
$ # Now with only a quarter of the CPU available
$ time docker run -it \
 --rm \
 --cpus=0.25 \
 ubuntu \
 /bin/bash -c 'for ((i=0; i/dev/null; done'
real    0m6.456s
user    0m0.018s
sys    0m0.017s
```
如您所见，`--cpus`标志对于确保即使机器上没有资源争用，任务也不会使用超过指定值的 CPU 非常有用。
Keep in mind that there are a few more options for limiting resource usage for containers that are a bit outside of the scope of the general ones that we have covered already, but they are mainly for device-specific limitations (such as device IOPS). If you are interested in seeing all of the available ways to limit resources to a task or a service, you should be able to find them all at [https://docs.docker.com/engine/reference/run/#runtime-constraints-on-resources](https://docs.docker.com/engine/reference/run/#runtime-constraints-on-resources).
# 避免陷阱
在大多数中小型部署中，您将永远看不到当您扩展到它们之外时开始看到的相同问题，因此本节将向您展示您将遇到的最常见问题，以及如何以尽可能干净的方式解决这些问题。虽然这个列表应该涵盖了您将会遇到的大部分突出问题，但是您自己的一些问题需要定制修复。您不应该害怕进行这些更改，因为几乎所有主机操作系统安装都不适合高负载多容器所需的配置。
WARNING! Many of the values and tweaks in this section have been based on personal experiences with deploying Docker clusters in the cloud. Depending on your combination of cloud provider, OS distribution, and infrastructure-specific configurations, the values may not need changing from the defaults, and some may even be detrimental to your system if used verbatim without spending some time learning what they mean and how to modify them. If you continue reading this section, please use the examples only as examples on how to change the values and not as something to copy/paste directly into configuration management tooling.
# ulimits
`ulimit`对于大多数 Linux 桌面用户来说，设置是鲜为人知的设置，但在使用服务器时，它们确实是一个非常痛苦且经常遇到的问题。简而言之，`ulimit`设置控制流程资源使用的许多方面，就像我们前面介绍的 Docker 资源调整一样，它们应用于已经启动的每个流程和外壳。这些限制几乎总是在发行版上设置，以防止一个混乱的进程关闭您的机器，但是这些数字通常是在考虑到常规桌面使用的情况下选择的，所以试图在不变的系统上运行服务器类型的代码肯定会至少达到打开文件的限制，并且可能达到一些其他的限制。
我们可以使用`ulimit -a`来查看我们当前(也称为**软**)的设置是什么:
```
$ ulimit -a
core file size          (blocks, -c) 0
data seg size           (kbytes, -d) unlimited
scheduling priority             (-e) 0
file size               (blocks, -f) unlimited
pending signals                 (-i) 29683
max locked memory       (kbytes, -l) 64
max memory size         (kbytes, -m) unlimited
open files                      (-n) 1024
pipe size            (512 bytes, -p) 8
POSIX message queues     (bytes, -q) 819200
real-time priority              (-r) 0
stack size              (kbytes, -s) 8192
cpu time               (seconds, -t) unlimited
max user processes              (-u) 29683
virtual memory          (kbytes, -v) unlimited
file locks                      (-x) unlimited
```
如您所见，这里只设置了几件事，但有一件事很突出:我们的“打开文件”限制(`1024`)对于一般应用来说是可以的，但是如果我们运行许多处理大量打开文件的服务(例如相当数量的 Docker 容器)，这个值必须更改，否则您将遇到错误，您的服务将实际上死亡。
您可以使用`ulimit -S  `更改当前外壳的该值:
```
$ ulimit -n
1024
$ # Set max open files to 2048
$ ulimit -S -n 2048
$ # Let's see the full list again
$ ulimit -a
open files                      (-n) 2048
```
但是如果我们试着把它设置得很高呢？
```
$ ulimit -S -n 10240
bash: ulimit: open files: cannot modify limit: Invalid argument
```
在这里，我们现在遇到了系统强加的硬限制。如果我们想在这些值之外对其进行修改，则需要在系统级别更改该限制。我们可以通过`ulimit -H -a`查看这些硬性限制是什么:
```
$ ulimit -H -a | grep '^open files'
open files                      (-n) 4096
```
因此，如果我们想将打开的文件数量增加到`4096`之外，我们确实需要更改系统级设置。还有，即使`4086`的软限制对我们来说没问题，设置也只是针对我们自己的 shell 及其子进程，所以不会影响系统上的其他任何服务或进程。