Listing 1: bic masking example
The tst masking shown below instead avoids a data
dependency between the masking instruction and the load by
predicating the load based on a test of the MSB of the address.
If an attacker has corrupted the address to point into the code
section, the load will not be executed at all since the test will
fail. The tst masking has the added beneﬁt that we can handle
failure gracefully by inserting instrumentation which jumps to
an address violation handler in case of failure. However, tst
is not applicable to loads which are already predicated on an
existing condition. In addition, we found that the bic masking
is up to twice as efﬁcient as tst masking on our test hardware,
even with the data dependency. One possible reason for this is
that the predicated instruction will be speculatively executed
according to the branch predictor, causing a pipeline discard
in the case of a misprediction. At the same time, bic masking
beneﬁts greatly from out-of-order execution if the load result
is not immediately required.
t s t
l d r e q
r0 , #0 x80000000
r1 ,
[ r 0 ]
Listing 2: tst masking example
Additionally, we do not constrain program counter relative
loads with constant offsets. ARM does not allow for 32-bit
immediate instructions operands, and therefore large constants
are stored in a constant pool allocated after each function.
These constant pools are necessarily readable data in the code
section, but access to the constant pool is highly constrained.
All constant pool loads use a constant offset from the current
program counter and therefore cannot be used by attackers to
access the surrounding code.
b) XoM-Speciﬁc Optimizations: Although software
XoM is inspired by SFI, the two techniques solve fundamen-
tally different problems. SFI isolates potentially malicious code
whereas software XoM constrains benign code operating on
potentially malicious inputs. In other words, SFI must operate
on the assumption that
the adversary is already executing
untrusted code in arbitrary order whereas software XoM trusts
the code it instruments and therefore assumes that the control-
ﬂow has not yet been hijacked.
Since we trust the executing code, we can make opti-
mizations to our software XoM implementation that are not
applicable when performing traditional SFI load masking.
Speciﬁcally, we do not need to mask load addresses directly
before the load instruction. Instead, we insert the masking
operation directly after the instructions that compute the load
address. In many cases, a single masking operation sufﬁces to
protect multiple loads from the same base address. Registers
holding the masked address may be spilled to the stack by the
register allocator. Since the stack contents are assumed to be
under attacker control (Conti et al. [11] recently demonstrated
such an attack), we re-mask any addresses that are loaded from
the stack. In contrast, SFI requires that address checks remain
in the same instruction bundle as their use, so that a malicious
program may not jump between the check and its use. In our
experiments, the ability to hoist masking operations allows us
to insert 43% fewer masking operations relative to SFI policies
that must mask each potentially unsafe load in untrusted code.
Figure 3 shows an example in which we are able to remove a
masking operations in a loop which substantially reduces the
number of bic instructions executed from 2n + 1 to n + 1
where n is the number of loop iterations.
B. Optimized Load Masking
C. Forward-Pointer Hiding
Masking addresses before every load instruction is both
redundant and inefﬁcient as many loads are provably safe. To
optimize our instrumentation, we omit checks for loads that we
can guarantee will never read an unconstrained code address.
We start with similar optimizations to previous work, including
optimizations adapted speciﬁcally for ARM, and then discuss
a novel optimization opportunity that is not applicable to any
SFI technique.
a) SFI-Inspired Optimizations: We perform several op-
timizations mentioned by Wahbe et al. [53] in their seminal
work on SFI. We allow base register plus small constant
addressing by masking only the base register, avoiding the need
for an additional address computation add instruction. We also
allow constant offset stack accesses without needing checks by
ensuring that the stack pointer always points to a valid address
in the data section. All stack pointer modiﬁcations with a non-
constant operand are checked to enforce this property.
As explained in Section II, adversaries can scan the stack,
heap, and static data areas for code pointers that indirectly
disclose the code layout. We therefore seek ways to identify
functions and return sites without revealing their location. The
ﬁrst major category of code pointers are function pointers, used
by the program for indirect function calls. Closely related are
basic block addresses used in situations such as switch case
tables. We handle all forward code pointers in the same manner
but use a special, optimized scheme for return addresses as
explained in the following section.
We protect against an attacker using forward code pointers
to disclose code layout by indirecting all code pointers through
a randomized trampoline table, as proposed by Crane et al.
[14]. For each code location referenced by a readable code
pointer, we create a trampoline consisting of a direct jump to
the target address. We then rewrite all references to the original
address to refer instead to the trampoline. Thus, the trampoline
4
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
; calculate address
add r 0 ,
; store address on stack
s t r
[ sp +#12]
r 0 ,
r0 ,
r 8
r1 ,
[ r 0 ]
l o o p :
bi c r0 , r0 , #0 x80000000
; load address
l d r
bi c r0 , r0 , #0 x80000000
; load + constant offset
l d r
r2 ,
add r 0 ,
; check loop condition
cmp r 0 ,
bne l o o p
[ r 0 +#4]
r 0 , #8
r 3
stack, now unsafe
l o o p e n d :
; restore address from
;
l d r
bi c r0 , r0 , #0 x80000000
; load address
l d r
[ sp +#12]
r 0 ,
[ r 0 ]
r2 ,
Software-Fault Isolation
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
; calculate address
add r 0 ,
; store address on stack
s t r
[ sp +#12]
r 0 ,
r0 ,
r 8
l o o p :
b ic r0 , r0 , #0 x80000000
; load address
l d r
[ r 0 ]
r1 ,
[ r 0 +#4]
r 0 , #8
; load + constant offset
l d r
r2 ,
add r 0 ,
; check loop condition
cmp r 0 ,
bne l o o p
r 3
stack, now unsafe
l o o p e n d :
; restore address from
;
l d r
b ic r0 , r0 , #0 x80000000
; load address
l d r
[ sp +#12]
[ r 0 ]
r 0 ,
r2 ,
Software XoM
Figure 3: Differences between load-masking for software-fault isolation (left) and software-enforcement of XoM (right). Because
SFI must consider existing code malicious, it must mask load addresses directly before every use. In contrast, software XoM
is protecting trusted code executing legitimate control-ﬂow paths, and can therefore use a single masking operation to protect
multiple uses.
address, rather than the function address, is stored in readable
memory. We randomize trampoline ordering to remove any
correlation between the address of the trampoline (potentially
available to the attacker) and the actual code address of the
target. Hence, even if an attacker leaks the address of a
trampoline, it does not reveal anything about the code layout.
D. Return-Address Hiding
In principle, we could hide return addresses using the same
trampoline mechanism that we use to protect forward pointers.
However, the return address trampolines used by Crane et
al. [14] require two instructions rather than the single direct
jump we use for forward pointers. At every call site, the
caller jumps to a trampoline containing 1) the original call
instruction, and 2) a direct jump back to the caller. This way,
the return address that is pushed on the stack points into a
trampoline rather than a function. However, due to the direct
jump following the call, every call site must use a unique return
address trampoline.
Return addresses are extremely common. Thus, the extra
trampoline indirections add non-trivial performance overhead.
Additionally, code size is critical on mobile devices. For these
reasons, we take an alternative approach. Due to the way ARM
and other RISC instruction sets perform calls and returns, we
can provide signiﬁcantly stronger protection than the return
address trampolines of Crane et al. without expensive trampo-
lines for each call site. We build upon the foundation of XoM
to safely secure an unreadable, per-function key to encrypt
every return address stored on the stack.
While x86 call instructions push the return address directly
onto the stack, the branch and link instruction (bl) on ARM
and other RISC processors instead places the return address
in a link register. This gives us an opportunity to encrypt the
return address when it is spilled onto the stack3. We XOR
all return addresses (stored in the link register) before they
are pushed on the stack similarly to the PointGuard approach
by Cowan et al. [13]. PointGuard, however, uses a much
weaker threat model. It assumed that the adversary cannot
read arbitrary memory. In our stronger attacker model (see
Section III), we must prevent the adversary from disclosing or
deriving the stored XOR keys. We therefore use a per-function
key embedded as a constant in the code which, thanks to
XoM, is inaccessible to adversaries at run time. In our current
implementation, these keys are embedded at compile time. As
this might be vulnerable to ofﬂine analysis, we are currently
working on extending LR2 to randomize the keys at load time.
Listing 3 shows an example of our return-address hiding
technique. Line 2 loads the per-function key for the current
function, and on line 3 it is XORed into the current return
address before this address is spilled to the stack in line 4.
Lines 8-11 replace the normal pop {pc} instruction used to
pop the saved return address directly into the program counter.
On lines 8-10, the encrypted return address is popped off the
stack and decrypted, and on line 11 the program branches to
the decrypted return address.
Considering the advantages of protecting return addresses
using XOR encryption, the question arises whether forward
pointers can be protected with the same technique. An impor-
tant difference between forward pointers and return addresses
is that the former may cross module boundaries. For instance,
an application protected by LR2 may pass a pointer to an
unprotected library or the OS kernel to receive callbacks. The
3Leaf functions do not need to spill the return address onto the stack.
5
f u n c t i o n :
l d r
e o r
push
r12 ,
l r ,
{ l r }
[
f u n c t i o n c o n t e n t s h e r e ]
.FUNCTION_KEY
l r ,
r12
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
Listing 3: Return-address hiding example. Note that con-
stant pool entries are embedded in non-readable memory,
as described in Section IV-B.
.FUNCTION_KEY :
. l o n g
0 xeb6379b3
.FUNCTION_KEY
l r ,
{ l r }
r3 ,
l r ,
l r
pop
l d r
e o r
bx
r 3