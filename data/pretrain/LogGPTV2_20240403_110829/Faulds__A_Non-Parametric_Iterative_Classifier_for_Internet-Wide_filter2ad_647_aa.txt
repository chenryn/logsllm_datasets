title:Faulds: A Non-Parametric Iterative Classifier for Internet-Wide
OS Fingerprinting
author:Zain Shamsi and
Daren B. H. Cline and
Dmitri Loguinov
Faulds: A Non-Parametric Iterative Classifier
for Internet-Wide OS Fingerprinting
Zain Shamsi, Daren B.H. Cline, and Dmitri Loguinov
Texas A&M University, College Station, TX 77843 USA
PI:EMAIL, PI:EMAIL, PI:EMAIL
ABSTRACT
Recent work in OS fingerprinting [41], [42] has focused on over-
coming random distortion in network and user features during
Internet-scale SYN scans. These classification techniques work un-
der an assumption that all parameters of the profiled network are
known a-priori – the likelihood of packet loss, the popularity of
each OS, the distribution of network delay, and the probability of
user modification to each default TCP/IP header value. However,
it is currently unclear how to obtain realistic versions of these pa-
rameters for the public Internet and/or customize them to a par-
ticular network being analyzed. To address this issue, we derive a
non-parametric Expectation-Maximization (EM) estimator, which
we call Faulds, for the unknown distributions involved in single-
probe OS fingerprinting and demonstrate its significantly higher
robustness to noise compared to methods in prior work. We apply
Faulds to a new scan of 67M webservers and discuss its findings.
1 INTRODUCTION
The Internet is a fascinating conglomerate of highly heterogeneous
devices, which differ in hardware capability, security awareness,
software features, and daily usage. Measuring the amount, type,
and behavior of these devices, as well the networks they connect to,
has become an important topic [12], [13], [15], [18], [24], [27], [33],
[41], [42]. To categorize the makeup of today’s networks, research
in active OS fingerprinting, which is our topic in this paper, aims
to determine the stack of remote hosts using their responses to
external stimuli (i.e., TCP/IP probes) [3], [4], [6], [8], [16], [22], [23],
[28], [30], [36], [40], [44], [48], [49], [52], [53], [54].
There are many uses for remote stack fingerprinting. First, it
helps hackers in identification of vulnerable hosts and general net-
work reconnaissance [47], especially during cyber-attacks that tar-
get only a specific OS implementation [19]. Second, OS fingerprint-
ing is routinely deployed in security, e.g., by administrators of large
networks seeking to find unpatched hosts and rogue entities [1],
[29], [45]. Third, perimeter-defense systems (e.g., IDS, firewalls)
may require the OS of the target host in order to detect certain
types of exploits (e.g., those involving reassembly of IP fragments).
In such cases, autonomous fingerprinting of the protected network
allows these installations to function at maximum effectiveness
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full cita-
tion on the first page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or re-
publish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
CCS ’17, October 30-November 3, 2017, Dallas, TX, USA
© 2017 Association for Computing Machinery.
ACM ISBN 978-1-4503-4946-8/17/10. . . $15.00
https://doi.org/10.1145/3133956.3133963
[44], [48]. Finally, researchers/organizations use these techniques
to understand usage trends [34], [35], discover the spread of new
technologies [7], [14], [26], [38], and expose botnets [25].
Active stack fingerprinting can be partitioned into three cate-
gories – banner-grabbing via plain-text protocols (e.g., telnet, HTTP,
FTP), multi-probe tools that elicit OS-specific responses from vari-
ous non-standardized combinations of flags and/or unexpected us-
age of protocol fields (e.g., nmap [36], xprobe [52], p0f [54]), and
single-probe methods that send a regular SYN to each host (e.g.,
Snacktime [5], RING [50], Hershel [42], Hershel+ [41]).
At large scale, banner-grabbing has several impediments – fre-
quent removal of OS-identifying strings by administrators, high
bandwidth overhead, and common interaction with non-platform-
specific software (e.g., apache, nginx). Multi-probe tools have their
own challenges – heavy load on the target, massive complaints
about intrusive activity, and noisy results when the destination IP
is load-balanced across a server farm. More importantly, the accu-
racy of multi-packet tools suffers a significant degradation when
firewalls block auxiliary probes and the underlying classifier is
not robust against unexpected feature removal/modification. As
shown in [41], OS classification with nmap over the public Internet
fails in almost 30% of the cases. Furthermore, nmap sometimes pro-
duces nonsensical results and worse accuracy than the alternatives
utilizing a single probe.
Before modeling and improving multi-packet classifiers, which
are still poorly understood, it is important to ask whether there
exists a set of algorithms for maximizing performance of single-
packet tools in Internet-wide scans. Such techniques provide a max-
imally stealthy option and may be able to bypass firewalls/IDS
when packets loaded with “tricks" cannot. As it turns out, even
the most advanced model in single-probe literature, i.e., Hershel+
[41], leaves room for improvement. It has many built-in assump-
tions that may be violated in practice, which in turn may affect its
classification accuracy and overall performance on such basic met-
rics as the fraction of the Internet running a particular stack. Our
motivation for this paper is to understand the limitations of exist-
ing single-probe techniques and offer novel avenues for increasing
both the classification accuracy and amount of information recov-
ered from responses to a SYN packet.
2 BACKGROUND
2.1 Nmap
Perhaps the most popular and exhaustive tool for OS fingerprint-
ing is nmap [36]. To understand its infeasibility for wide-area us-
age, we briefly review its outgoing traffic and response require-
ments, as well as the matching algorithm. By default, nmap starts
with a vertical scan of the target using 1,000 well-known ports
in an attempt to find two TCP ports, one of which is open and
Session D5:  Network SecurityCCS’17, October 30-November 3, 2017, Dallas, TX, USA971Table 1: Feature Vectors xi (TCP Options: M = MSS, N = NOP, S = SACK, T = Timestamp, and W = Window Scale)
OS name
Linux 3.2
Windows 2003
Novell
Win
5, 792
16, 384
6, 144
TTL DF
1
0 MNWNNTNNS
1
64
128
128
MNWSNN
MSTNW
OPT
(cid:3)
the other is closed, as well as a closed UDP port. It then sends 16
uniquely crafted probes – six regular TCP packets to an open port,
one valid and one invalid ICMP ping, one UDP packet to a closed
port, four malformed packets to an open TCP port, and three TCP
packets to a closed port. It retransmits all probes multiple times
to neutralize the impact of packet loss, which results in over 100
packets per host in addition to the initial port scan.
Besides overhead, running nmap against the entire Internet poses
a number of additional challenges. First, there is a low likelihood
that a port scan, combined with probes to closed ports, gets un-
noticed by the IDS. Many software packages (e.g., snort) contain
explicit rules to detect and block the rather esoteric nmap traffic.
Certain networks take offense at being nmapped, which results in
swift action to block the entire subnet/AS of the scanner and com-
plaints about abusive behavior. Second, the firewall may allow se-
lect ports to reach the target host (e.g., port 80 to a webserver);
however, there is little incentive to pass UDP or TCP packets to
other ports that do not offer any services. Third, in similar fashion,
the OS firewall can be configured (e.g., using domain group pol-
icy) to silently drop incoming packets to closed ports. In fact, Win-
dows and Mac OS X suppress outgoing ICMP port unreachables
even when an explicit rule is created to allow such packets through
the firewall [2], [32].
Nmap expects responses to not deviate from those specified in
the database (e.g., a RST to a TCP rainbow packet, ICMP port un-
reachable from a closed UDP port, ICMP echo reply to a ping).
Because it considers absence of a response to be a feature, it can
be misled into assigning large positive weights to firewall actions,
which skews the result towards network stacks that inherently re-
spond with fewer signals. This may occur despite a complete non-
match in other features, meaning that the target may share nothing
in the packet header (e.g., TCP window size, TTL, options, MSS)
with the signature it is matched to [41]. Other issues include the
database itself, which contains signatures that are subsets of others
from completely unrelated stacks and allows special null header
fields that can match any value in the observation. Unless the tar-
get responds to all 16 probes exactly as expected, an obscure device
with the most null fields can trump the other alternatives, includ-
ing the correct signature.
Additionally, certain TCP fields are quite volatile, i.e., change
from user tweaks, underlying network MTU, and software setsock-
opt function calls. This does not inherently change the operating
system, but creates an illusion of a different stack. For example,
Server 2008 R2 accepts incoming connections with a kernel buffer
(i.e., TCP window size) of 8,192 bytes; however, an apache web-
server can reconfigure this field to an arbitrary value before listen-
ing on the socket. Furthermore, this can be done on a per-socket
basis and may vary over time depending on memory usage or other
considerations. When faced with this type of uncertainty, nmap
MSS
1, 460
1, 380
1, 460
RST
0, 0, 0, 0
0, 0, 0, 0
1, 1, 0, 1
RTOs
3, 6, 12, 24.2, 48.2
3, 6.5
1.4, 3.0
(cid:38)(cid:79)(cid:76)(cid:72)(cid:81)(cid:87)(cid:3)
(cid:54)(cid:60)(cid:49)(cid:3)
(cid:54)(cid:72)(cid:85)(cid:89)(cid:72)(cid:85)(cid:3)
(cid:54)(cid:60)(cid:49)(cid:16)(cid:36)(cid:38)(cid:46)(cid:3)
(cid:54)(cid:60)(cid:49)(cid:16)(cid:36)(cid:38)(cid:46)(cid:3)
(cid:53)(cid:54)(cid:55)(cid:3)(cid:11)(cid:82)(cid:83)(cid:87)(cid:76)(cid:82)(cid:81)(cid:68)(cid:79)(cid:12)(cid:3)
(cid:53)(cid:55)(cid:50)
(cid:53)(cid:55)(cid:50)
Figure 1: Half-open connections in TCP.
uses heuristic weights and thresholds that do not have rigorous
theory/verification behind them. As a result, it exhibits highly un-
reliable identification in certain scenarios [41].
2.2 Single-Packet Tools
For accurate OS fingerprinting at Internet scale, low-overhead meth-
ods resilient to volatility are preferred. Our focus in this paper is
on single-probe techniques, which generally work by sending a
TCP SYN to the target host and inducing a stream of SYN-ACK
responses, possibly with a RST at the end. Since the connection
is kept in the half-open state, the server continues retransmitting
SYN-ACKs until its internal maximum-retry threshold is exceeded.
Delays between the SYN-ACKs, known as retransmission timeouts
(RTOs), as well as their count and presence of the last RST, reveal
valuable information about the OS of the responding host. This
is illustrated in Figure 1. Coupling the RTOs with default TCP/IP
header values makes stack classification possible.
The main difference between prior work [5], [24], [41], [42], [50]
lies in the features they extract from TCP/IP headers and the as-
sumed distortion model. As of this writing, Hershel+ [41] is both
the most recent effort in this direction and most robust to observa-
tion noise. We review its operation and formulas later in the paper.
3 LEARNING FROM OBSERVATION
Note that proofs and certain technical discussion have been omit-
ted from this paper. They can be found in [43].
3.1 General Problem
Suppose the OS database consists of n ≥ 1 known stacks (ω1, . . . ,
ωn ), each with some vector-valued fingerprint xi = (xi 1, xi 2, . . .).
As shown in Table 1, fingerprints contain a combination of fea-
tures, including default header values used for new connections
and SYN-ACK retransmission timeouts (RTOs) of each OS. Further
assume a set of observations x(cid:3)
m) obtained by scan-
ning the Internet and eliciting responses from m live servers, where
x(cid:3)
j = (x (cid:3)
, . . .) is a vector of sampled features from host j. For
j1
the type of OS fingerprinting considered here, i.e., single-probe,
this is done by dispatching a SYN to every IP address in BGP and
= (x(cid:3)
1
, . . . , x(cid:3)
, x (cid:3)
j2
Session D5:  Network SecurityCCS’17, October 30-November 3, 2017, Dallas, TX, USA972collecting SYN-ACKs/RSTs from the responding servers, as previ-
ously shown in Figure 1.
The goal of the classifier is then to determine for each x(cid:3)
j the
most-likely fingerprint in the database. This task is complicated
by the presence of distortion (also called volatility [41]) θ that ran-
domly modifies the original features of the system before the ob-
server gets them. This may involve a change in the temporal re-
lationship between the packets (e.g., queuing delays), removal of
some features (e.g., loss of RST packets), and rewriting of TCP head-
ers in an effort to optimize or obscure the end-system.
Define αi = p(ωi ) to be the unknown fraction of hosts in x(cid:3)
with OS i and let α = (α1, . . . , αn ) be the corresponding vector.
Now suppose p(y|ωi , θ) is the probability that the fingerprint of
signature i has been changed into y under θ. Similarly, assume that
p(ωi |y, θ, α ) is the probability that an observed vector y was pro-
duced by a host running OS i, conditioned on distortion model θ
and popularity α. Then, application of Bayes’ rule shows that the
classifier must determine for each j the one database entry ωi with
the largest
p(ωi |x(cid:3)
j , θ, α ) =
αip(x(cid:3)
p(x(cid:3)
j |ωi , θ)
j |θ, α )
,
where, for any vector of features y, the denominator is
p(y|θ, α ) =
n
i =1
αip(y|ωi , θ).
(1)
(2)
Hershel+ [41] relies on a-priori knowledge of not only α, but
also parameter θ, which consists of the probability of change in
each TCP/IP feature, average packet loss, and two distributions of
network delay. While the underlying model in Hershel+ is more
robust to distortion than those in prior approaches [5], [50], its per-
formance does depend on how well α and θ can be estimated ahead
of time. As the Internet is highly heterogeneous and constantly
evolving, even if (α, θ) could be obtained by monitoring routers
and/or using end-to-end measurement between strategically po-
sitioned hosts (e.g., PlanetLab), it is unclear whether conditions
observed in the past or along certain paths can yield meaningful
predictions about the specific network being fingerprinted (e.g., a
corporate LAN is very different from the public Internet). Instead,
we argue that (α, θ) should be the output of the classifier rather
than the input. Doing so allows the unknown parameters to be cus-
tomized to a specific observation x(cid:3)
, i.e., reflect the OS composition
of the network being analyzed and its distortion properties.
Analysis of (1) in existing work [41], [42] assumes that α is uni-
form (i.e., αi = 1/n) and θ is fixed by oracle input. Therefore, both
αi and denominator p(x(cid:3)
j |θ, α ) are independent of i and can be re-
moved from the optimization, leaving only p(x(cid:3)
j |ωi , θ). In contrast,
our goal here is to estimate both α and θ dynamically as the classi-
fier is running, which should both increase its accuracy and yield
interesting Internet-characterization results as byproduct of classi-
fication. Before reaching this objective, a gradual build-up of for-
malization is needed. This section deals with estimating α, the next
one covers network distortion, and the one after that focuses on
modification to fixed header features.
Table 2: Network Distortion in Scenario S1
Case
S11
S12
S13
Forward latency (sec) One-way delay (sec)
Distribution Mean Distribution Mean
0.5
Erlang(2)
0.5
Pareto
0.5
Reverse-exp
Exp
Pareto
Erlang(2)
0.5
0.5
1.5
Loss
3.8%
50%
10%
3.2 Fingerprint Popularity
Observation vector x(cid:3)
gives rise to a number of equations in the
form of (2), where the left side contains the empirical (known)
probability of observing each unique vector y ∈ x(cid:3)
and the right
side is a model that embeds the unknown parameters. Extraction
of α and θ from such systems of equations commonly involves the
Expectation-Maximization (EM) method, which produces a solu-
tion using fixed-point iteration [11], [17]. At every step t, it maxi-
mizes the expected log-likelihood function conditioned on the pa-
rameters obtained during the previous iteration t −1. As long as the
number of equations exceeds the number of unknown parameters,
EM works well for many problems in practice.
For now, we treat p(x(cid:3)
j |ωi , θ) as a black-box classifier (e.g., Snack-
time, Hershel, Hershel+), which does not attempt to estimate θ, and
focus on determining α. This is the simplest (and only) case where
(2) forms a linear system of equations. Throughout the paper, su-
perscripts applied to parameters refer to the iteration number dur-
ing which they are estimated, e.g., α t
i approximates αi during step
t. Now notice that a sensible estimate of popularity for OS i is the
average probability with which observations map to this finger-
print, conditioned on the previous estimate of popularity, i.e.,
m
j =1
α t +1
i
=
1
m
p(ωi |x(cid:3)
j , θ, α t ).
(3)
While the next result is fairly straightforward, its derivation
methodology is needed for later parts of the paper.
Theorem 3.1. For a classifier with fixed θ, (3) represents the EM
algorithm for recovering the popularity vector α .
Note that this is markedly different from deciding popularity us-
ing the fraction of classification decisions that go to each OS, which
is known as hard EM and commonly used in clustering algorithms
such as k-means [20]. In fact, all previous fingerprinting tools [5],
[6], [36], [41], [42], [52], [54] can be viewed as performing one it-