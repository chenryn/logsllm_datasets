call that in the attack scenario above, the warden is assumed
to possess powerful resources, and therefore it is assumed
that the monitoring techniques employed by the warden in-
volve inspection of every ﬁeld of every packet at every pro-
tocol layer, and every value within each packet is treated as
an inspected attribute. This assumption is extreme, but it
provides a good basis for asserting a near worst-case esti-
mate of probability of detection.
Returning to statistical quality control, an operating
characteristic (OC) curve is used to describe the ability of
an inspection scheme to detect attribute shifts [35]. The OC
curve is a plot of the probability of accepting a hypothesis
concerning some known attribute versus the true measure
of the attribute. To illustrate, consider the operating char-
acteristic curves depicted in Figure 2. The graph illustrates
a fraction defect control chart. The underlying process is
assumed to have a known fraction defect of value p0, from
which an upper control limit is established; meaning that
if a sample is found to contain greater than the number of
defects deﬁned by the upper control limit, the process is as-
sumed to be out of control. For this type of chart, the prob-
ability that a sample is within the control limit is deﬁned by
the binomial distribution [35], and therefore the probability
of accepting a sample for some arbitrary value, p, given the
true fraction defect, p0, and sample size, N, is given by
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 03:11:17 UTC from IEEE Xplore.  Restrictions apply. 
pSymbolDetect(νtrue) =
x
1 − U CL(cid:88)
(cid:3) (νtrue)x(1 − νtrue)N−x,
(cid:2)N
(cid:18) νs
(cid:22)
+ κ(cid:112)νs/NS(1 − νs/NS)/N
νtrue = (νs + ν∗
s )/NS, and
x=0
(2)
(cid:19)(cid:23)
.
where
U CL =
N
NS
Prior to postulating a general expression for probability
of channel detection, three considerations remain. A dis-
tinction must be made between the probability of detecting
an “out-of-control” symbol and the probability of detecting
the channel. A criteria for the selection of sample size must
be determined. Finally, it is useful for system design if the
probability is expressed as a function of the exploit SNR.
Equation 2 represents the probability of detecting occur-
rences of one type of exploit symbol. Since the covert usage
of the channel involves a total of NS unique exploit sym-
bols, the probability of channel detection is given by
pChannelDetect(νtrue) =
1 − (1 − pSymbolDetect(νtrue))NS .
(3)
In the context of quality control, the inspection sample
size is chosen so as to maximize the likelihood of detecting
a change in an observed process constrained by the classic
consumers and producers risks, and by the practicality of
the physical inspection. In the case of the network exploit,
it is assumed that the trafﬁc is only out of control intermit-
tently; in other words covert signaling only occurs when
a message is being sent. Under this assumption, the war-
den would want to choose sample size to coincide exactly
with the duration of the covert signaling. Sampling a larger
set would dilute the increased fraction of exploit symbols
within the normal trafﬁc, and sampling a smaller set would
decrease the probability of detecting the change. The war-
den has no practical means of knowing such a size or when
to begin the sampling window. However, for the purposes
of maintaining a worst-case scenario, assume that the war-
den does in fact sample at this size and time. Let No de-
note this optimal sample size and let L denote the size of
the message in number of symbols. Assuming the message
symbols are roughly uniformly distributed, the fraction of
all signal symbols within a transmission window of the op-
timal sample size is given by
ν∗
s = L/No.
(4)
Combining equations 3 and 4 with 2 and recalling by def-
inition that ν∗
s = νsSN R, yields an expression for proba-
bility of detection for a given exploit as a function of signal-
to-noise ratio for a given message size, and the number of
Figure 2. OC Curves for Different Values of
Sample Size
U CL(cid:88)
x=0
pAccept(p) =
where
U CL =
x
(cid:2)N
(cid:3) px(1 − p)N−x,
(cid:106)
N(p0 + κ(cid:112)(p0(1 − p0)/N))
(1)
(cid:107)
.
From the operating characteristic curves several obser-
vations are made. For a ﬁxed underlying fraction defect,
the probability of detecting an out of control process in-
creases as sample size increases. The likelihood of false
negatives, or the probability that an out of control process is
accepted, is given by the probability pAccept(p). The likeli-
hood of false positives, or the probability that an in-control
process is found to be out of control, is given by the proba-
bility 1−pAccept(p = p0). In the example the upper control
limit is based upon a fairly standard usage of 3-Sigma (κ=3)
in control charting. Increasing the control limit lowers the
false positives, but at the expense of decreasing the sensitiv-
ity of the technique to detect changes in the fraction defect.
Making the parallel between the attack scenario and the
statistical quality control technique above, the known frac-
tion defect in the context of the exploit is the natural fraction
of each exploit symbol expected in normal trafﬁc, νs/NS.
The true fraction defect for each symbol during periods of
covert transmission is νtrue, or (νs + ν∗
s )/NS. This as-
sumes that the exploit and message symbols are roughly
uniformly distributed. The probability that the warden de-
tects the covert signaling, based upon a sample of the traf-
ﬁc during which time the covert signaling is fully present,
is equivalent to the probability of rejecting the sample, or
(1 − pAccept(νtrue)). Therefore the following expression
for the probability of detecting an arbitrary exploit symbol
is proposed,
314
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 03:11:17 UTC from IEEE Xplore.  Restrictions apply. 
 unique exploit symbols,
pChannelDetect(SN R) =
1 − (1 − pSymbolDetect(SN R))NS ,
where
(cid:2)No
x
U CL(cid:88)
x=0
(5)
(cid:19)No−x
pSymbolDetect(SN R) = 1−
(cid:3)(cid:18) νs(1+SN R)
(cid:19)x(cid:18)1−νs(1+SN R)
(cid:107)
(cid:106)
νs + κ(cid:112)νs(1−νs)/No
NS
NS
U CL =
No = (cid:98)L/(νsSN R)(cid:99) .
, and
In practice, for any chosen exploit ﬁeld there will be
some limited number of values suitable for exploitation,
NS, representing some total natural exploit symbol propor-
tion, νs. The probability of detection becomes strictly a
function of the ratio of injected symbols to natural symbols
(SNR) and the message size.
3.2. Symbol
Codes
Insertion Error-Correcting
Deﬁne channel noise as “any unwanted signal or effect
in addition to the desired signal” [33]. Noise sources are
varied and depend wholly upon the medium of the chan-
nel. Considering the typical exploit scenario described in
Section 2, two types of noise may be present on the covert
channel. Foremost, there will be symbol insertions since all
suggested exploits use naturally occurring exploit ﬁeld val-
ues as potential signals. Given the intent to use the channel
with low probability of being detected, symbols arriving at
the receiver will therefore be some mix of signal and noise;
the greater the stealth, the greater the probability of symbol-
insertion noise events.
The other type of noise occurs as a result of packet loss in
the underlying (intended) channel. A dropped packet man-
ifests itself as a symbol deletion. Packet reordering within
the underlying channel will similarly yield symbol reorder-
ing noise in some covert channels. Note that symbol inser-
tion and symbol deletion are sufﬁcient to describe all noise
types on this channel. Symbol reordering is not needed as
a separate category since it can always be described as a
combination of deletions and insertions.
The rates of packet loss and packet reordering are fairly
well studied [2, 23, 38]. Typical packet loss values range
from 0.1 to 1% while packet reordering typically ranges
from 0.6 to 2%. To some extent the effects of these types of
noise are controllable by the selection and design of the ex-
ploit. However, in order to achieve a high level of stealthy
transmission, the injected symbols must remain sparse as
compared to those occurring naturally. As a result the sym-
bol insertion rate will be orders of magnitude larger than the
deletion and reorder rates above, and thus the overwhelm-
ing majority of all noise in the channel will be symbol in-
sertions.
Analyzing the attack scenario, it is clear that no com-
munication is permitted from the eavesdropper back to the
sender. This dictates that a forward error correcting (FEC)
scheme is required. [8, 16, 24, 25, 32] offer various bit in-
sertion block coding schemes, but are not appropriate for
high rates of symbol insertion. Further, trellis codes, of
which convolutional codes are the most prevalent, offer sev-
eral advantages over block coding. Trellis codes employ
the use of memory to improve the error-correcting capabil-
ity of codes [29] over that of block codes. The use of a
trellis code allows for a natural mapping of the encoder out-
put bits (code words) onto the exploit symbols, and thus the
output of the channel (and input to the decoder) can be in-
terpreted as a stream of symbols, not bits. Finally, trellis
codes have an inherent ability to self-synchronize; that is to
say that a matched decoder can correctly decode a stream of
received blocks without knowledge of the beginning state of
the code [34].
Combining the natural symbol usage with the inherent
ability to self-synchronize, a convolutional coding scheme
can be expected to yield a design that allows for decoding
to automatically synchronize anytime the received stream
of symbols is error free for at least the constraint length of
the code. This is a major advantage for a system where the
receiver has no knowledge of when the sender may send
a message, and one where the noise is predominantly in-
sertions. The remaining problem is to ﬁnd a set of good
convolutional codes.
Convolutional codes are a well studied category of trellis
codes. A careful study of known good convolutional codes
will reveal that without signiﬁcant modiﬁcation, they are
not well suited for symbol insertion correction despite the
advantages listed above. Refer to the state machine view of
the representative known good convolutional code [17] in
Figure 3. This code is said to be a (n = 4, k = 1, m = 3)
code; by convention the code has k input bits, n output bits,
and 2m states. Three undetectable symbol insertion error
modes are identiﬁed for codes of this construction.
a ) Memory-loss errors occur when symbol insertions
cause the code to lose memory as a result of a short
path-to-self. From an arbitrary state, once a code
returns to that state, any memory and thus any er-
ror correction ability, is lost. For example, from
some arbitrary state of the decoder, the right series
of symbol insertions can cause the decoder to move
through transitions that return it to that same state.
The shorter these paths-to-self, the higher the proba-
bility that this associated series of symbol insertions
may occur. Memory-loss errors cause a loss of syn-
chronization within the decoded message as indis-
315
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 03:11:17 UTC from IEEE Xplore.  Restrictions apply. 
Figure 4. Toroid of Squares Code / (6,1,5)
of the codes and the validity of their theoretical reliability is
offered in the next section.
The construction of the state machines characterizing the
symbol insertion error correcting codes begins with the cre-
ation of a ring of states of size r, deﬁned as a clockwise
zero-path ring. The code is then constructed of some num-
ber of such rings joined together by one-paths. This implies
that any zero input bit results in a transition of the code to