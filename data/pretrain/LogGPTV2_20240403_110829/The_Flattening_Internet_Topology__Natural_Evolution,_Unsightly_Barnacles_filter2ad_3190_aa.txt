title:The Flattening Internet Topology: Natural Evolution, Unsightly Barnacles
or Contrived Collapse?
author:Phillipa Gill and
Martin F. Arlitt and
Zongpeng Li and
Anirban Mahanti
The Flattening Internet Topology:
Natural Evolution, Unsightly Barnacles or
Contrived Collapse?
Phillipa Gill1, Martin Arlitt1,2, Zongpeng Li1, and Anirban Mahanti3
1 University of Calgary, Calgary, AB, Canada
2 HP Labs, Palo Alto, CA, USA
3 IIT Delhi, Delhi, India
Abstract. In this paper we collect and analyze traceroute measure-
ments1 to show that large content providers (e.g., Google, Microsoft,
Yahoo!) are deploying their own wide-area networks, bringing their net-
works closer to users, and bypassing Tier-1 ISPs on many paths. This
trend, should it continue and be adopted by more content providers,
could ﬂatten the Internet topology, and may result in numerous other
consequences to users, Internet Service Providers (ISPs), content
providers, and network researchers.
1 Introduction
Since its creation in 1969, the Internet has undergone several signiﬁcant changes.
From its beginnings as a research network, the Internet evolved into a commer-
cial network by the mid-1990’s [5]. The emergence of “killer applications” such
as the World-Wide Web and Peer-to-Peer ﬁle sharing vastly expanded the Inter-
net user base [11]. For a variety of reasons, including the commercialization and
increased popularity of the Internet, it has become extremely diﬃcult to make
ubiquitous changes to the Internet infrastructure. This has led to the emer-
gence of architectural barnacles [15], or ad hoc work-arounds for a variety of
architectural problems. Architectural purists argue that barnacles may provide
short-term relief to such problems, but over the long-term only exacerbate the
underlying issues [15].
In this paper we examine a new trend that is emerging at the infrastructure-
level of the Internet: large content providers are assembling their own wide-area
networks. This trend, should it become common practice, could result in signiﬁ-
cant changes to the structure of the Internet as it exists today, and have numerous
ramiﬁcations for users, ISPs, content providers, and network researchers.
We ﬁnd that companies such as Google, Yahoo!, and Microsoft, are deploying
large WANs. Google is leading the way, with a WAN infrastructure that covers
much of the U.S., and extends to Europe, Asia, and South America. Yahoo!
and Microsoft also have WANs covering the U.S., but do not (yet) extend to
1 Our data is available at the Internet Traﬃc Archive - http://ita.ee.lbl.gov/
M. Claypool and S. Uhlig (Eds.): PAM 2008, LNCS 4979, pp. 1–10, 2008.
c(cid:2) Springer-Verlag Berlin Heidelberg 2008
2
P. Gill et al.
other regions of the world. These eﬀorts may force other Internet companies to
follow suit, in order to remain competitive. For example, MySpace appears to
be partnering with Limelight Networks, a Content Delivery Network, to build
out a WAN for MySpace.
Our paper makes several contributions. First, we alert the network research
community to this emerging trend, as it may aﬀect the assumptions used in
other studies. Second, we provide initial measurements on the number and size
of the networks already in place for some large content providers. Third, we
describe the potential implications of this trend, and discuss whether this is a
natural evolution of the Internet architecture, an unsightly barnacle which will
ultimately create additional problems, or a contrived attempt to disrupt the
balance of power among the providers of the Internet architecture.
2 Background
2.1 Internet Architecture
The Internet architecture has evolved throughout its history. Initially, a single
backbone network connected a small number of research networks, to enable re-
searchers to remotely access computing resources at other institutions [5]. In the
late 1980’s, commercial ISPs began to form, and by 1995 the backbone network
was completely transitioned to commercial operation [5]. This transformation
resulted in the current three-tiered organization of the Internet infrastructure:
backbone networks (Tier-1 ISPs), regional networks (Tier-2 ISPs), and access
networks (Tier-3 ISPs) [5,11]. Consumers and content providers access the In-
ternet via Tier-3 ISPs. A Tier-2 ISP connects a number of Tier-3 providers to the
Internet. The Tier-2 ISP peers with other Tier-2 ISPs to deliver their customer’s
traﬃc to the intended destinations. Tier-2 ISPs may also connect to some Tier-1
ISPs, to more directly reach a larger fraction of the Internet. There are only a
few Tier-1 ISPs. Tier-1 ISPs transit traﬃc for their customers (Tier-2 ISPs), for
a fee. Tier-1 ISPs peer with all other Tier-1 ISPs (and do not pay transit fees)
to form the Internet backbone [11].
2.2 Motivations for Change
There are a number of reasons why content providers may be motivated to
build their own wide-area networks, rather than utilize ISPs to deliver content
to users. Three broad categories are business reasons, technical challenges, and
opportunity. We discuss each in turn.
When the “dot-com bubble” burst (around 2000), many Internet companies,
including Tier-1 ISPs such as WorldCom, Genuity, and Global Crossing went
bankrupt [13]. This economic collapse [13] motivated surviving (and new) In-
ternet companies to increase their focus on “business essentials”, such as risk
mitigation and cost control. One risk mitigation strategy content providers may
employ is to reduce their dependencies on partners. This could avoid disrup-
tions in a content provider’s core business, if, for example, a partner declared
The Flattening Internet Topology
3
bankruptcy. Similarly, topics such as “network neutrality” may create uncer-
tainty for content providers, and hence motivate them to build their own WAN
infrastructures, to mitigate any possible or perceived risk. To control costs, a
company may look for ways to reduce or eliminate existing costs. One strategy
for content providers is to utilize settlement-free peering arrangements with ISPs,
rather than traditional (pay-for-use) transit relationships [14]. For large content
providers and small ISPs, peering can be a mutually beneﬁcial arrangement.
Content providers may also be motivated to build their own WANs for tech-
nical reasons. For example, a content provider may wish to deploy a new “killer”
application, such as video-on-demand. Although many scalable video on-demand
delivery techniques exist, none have been widely deployed, owing to the lack of IP
multicast on the Internet. This limitation is due to the “Internet Impasse” [15];
this predicament makes it nearly impossible to adopt ubiquitous architectural
changes to the Internet that might improve security, enable quality-of-service or
IP multicast [16]. A private WAN could avoid this impasse, and give content
providers more control over their end-to-end application performance.
Some companies, such as Google, Yahoo!, and Microsoft, aim to provide “Soft-
ware as a Service” (SaaS), which will deliver functionality via the Web that was
previously only available through software installed on the user’s computer. In
response to the shift to SaaS, several companies are making multi-billion dollar
investments in infrastructure such as large data centers [6,12] and WANs. The
motivations for these investments likely span both the business and technical
categories described above.
Lastly, content providers may be motivated to build their own WANs because
of opportunities that arise. For example, due to the bursting of the “dot-com
bubble”, a content provider may be able to inexpensively obtain WAN infras-
tructure (e.g., installed ﬁber optic network links) from bankrupt ISPs.
3 Methodology
3.1 Data Collection
Our measurement of the popular content provider networks utilizes the
traceroute tool. traceroute is a tool that is commonly used to identify network
topology.
To determine the extent of content provider networks, we decided on the
following data collection methodology. First, identify a set of N popular content
providers. For each of these content providers, select an end-point (i.e., a server).
Next, select a set of M geographically-distributed nodes to issue traceroute
queries, to gather topology information. Lastly, issue N×M traceroute queries.
It is important to note that in this study we are only interested in identifying
the end points of content provider networks; we are not trying to measure the
end user experience, as this would require a diﬀerent methodology (since end
user requests are typically redirected to nearby servers).
For this study, we collected a single snapshot of the networks of the 20 top con-
tent providers, as ranked by Alexa [1], by querying from 50 diﬀerent traceroute
4
P. Gill et al.
Table 1. Top 20 Content Providers, as Identiﬁed by Alexa.com
www.hi5.com 16 www.friendster.com
1 www.yahoo.com 6 www.myspace.com 11
www.orkut.com 12
2
www.qq.com 17
www.yahoo.co.jp
www.msn.com 7
www.baidu.com 13 www.rapidshare.com 18 www.microsoft.com
3 www.google.com 8
www.sina.com.cn
4 www.youtube.com 9 www.wikipedia.org 14
5
www.fotolog.net
www.blogger.com 19
www.live.com 10 www.facebook.com 15 www.megaupload.com 20
servers. The 20 top content providers we used are listed in Table 1. We believe
this snapshot is suﬃcient for an initial view of these networks.
We resolve the hostnames of the popular sites only once, and only at a single
location (the University of Calgary). We believe this approach will prevent our
queries from being redirected to local instances of servers. Since our goal is to
understand the size of content provider networks, and not to measure the end-
user performance, we argue that our approach is reasonable.
Although we only selected 50 nodes to issue queries from, we selected the
locations of these nodes such that they are (potentially) biased in two ways:
towards the country in which the content provider is based; and towards areas
with higher concentrations of Internet users. We argue this is reasonable as we
expect content providers will expand their networks to areas with the largest
numbers of (potential) users ﬁrst. At the time of our study (September 2007),
15 out of 20 of the top global sites listed by Alexa were U.S. based. As a result,
we selected 20 traceroute servers in the U.S. These servers were located in
20 diﬀerent states, including the 10 most populous states. 18 of the U.S. based
traceroute servers are at commercial sites, and the other two are at universi-
ties. The remaining 30 traceroute servers were selected from countries around
the world. Although we intended to use the 30 countries with the most Internet
users, some of these countries do not have public traceroute servers. Instead,
we issued queries from two locations in Canada (a workstation at our university,
and a public traceroute server at another) and from 28 additional locations from
around the world, in countries which had working public traceroute servers
listed on traceroute.org. Overall, the 30 countries (including the U.S.) we se-
lected were among the top 40 countries in terms of most Internet users, according
to Internet World Stats [10]. The 30 countries we used account for an estimated
82.7% of all Internet users.
To keep the load on the 20 selected servers low, we issued only a single
traceroute query from each server to each destination, and only one query
at a time. Furthermore, we throttled the rate at which the queries were issued
(this is in addition to throttling done by some of the traceroute servers). Our
data collection occurred between September 27 and October 1, 2007. In future
work, we plan to collect data periodically, to understand rate of expansion of
content provider networks.
3.2 Data Analysis
In order to analyze the traceroute data, several challenges had to be over-
come. First, automating the parsing of the data was problematic. Among the
50 diﬀerent traceroute servers there were 10 diﬀerent output formats. Thus, a
The Flattening Internet Topology
5
parser was needed that could handle all of these. Second, the traceroute out-
put only contained a portion of the data of interest. This meant it was necessary
to ﬁnd additional sources of data (e.g., IP address to organization mappings,
organization to Autonomous System (AS) number mappings, etc.) Lastly, there
were no obvious metrics for quantifying the size of the WAN of each content
provider; this meant a lot of manual inspection of the data was needed in order
to determine what the (automated) analysis should evaluate.
We overcame the ﬁrst two challenges by developing a program to parse the
outputs of the various traceroute servers. This program extracts the sequence of
IP addresses for each of the traceroute queries. Once the sequence of IPs for a
traceroute query is extracted, additional data about each of the IPs is gathered.
First, the identity of the organization that registered the IP address is queried
from the regional Internet registries. Second, the AS number for the IP address is
resolved using an AS number lookup tool [21]. Gathering this extra information
increased the potential analyses that we could perform on the data. Speciﬁcally,
we were able to identify which of the hops in the traceroute path belonged to
Tier-1 ISPs using a list of the nine Tier-1 ISPs and their AS numbers [23].
We selected four metrics to facilitate the comparison of the content provider
networks, and to examine whether the Internet topology is ﬂattening. We use the
average number of hops on Tier-1 networks as a measure of how involved such
ISPs are in the path. A related metric is the number of paths that involve no Tier-
1 ISPs. Our third metric, which we call degree, provides a conservative estimate
of the number of diﬀerent ISPs a content provider is connected to. This examines
the AS number for the router that immediately precedes the ﬁrst router belong-
ing to a content provider, on each distinct path. Lastly, we consider the number
of geographic locations in which a content provider’s routers appear to be located.
We acknowledge that all of these metrics have their shortcomings. For example,
it may not be meaningful to compare hop counts when examining diﬀerences in
the paths. Hu and Steenkiste [9] describe similar issues for identifying metrics
for comparing the similarity of end-to-end Internet routes. However, we believe
our metrics nevertheless provide some interesting insights. For example, with the
traditional Internet model we might expect popular content providers to peer ex-
clusively with a number of Tier-1 ISPs, to ensure global coverage with a minimal
number of exchanges on each end-to-end path. If, however, the Internet is ﬂat-
tening, we might expect to see more extensive peering with lower tier ISPs.
4 Results
In our analysis we observe that some companies own multiple top 20 sites. Specif-
ically, we observe that Orkut and Blogger are both owned by Google, and traf-
ﬁc for these sites is carried on Google’s network. We observe a similar trend for
the sites owned by Microsoft, namely MSN and Live. Paths for all four of these
subsidiary sites is carried on the same network as their parent companies, and
thus the results are very similar. As a result, we only consider one site for each
company when the traﬃc is carried on the same network. Therefore, for our results
we omit Orkut, Blogger, MSN and Live, and only show the results for Google and
6
P
S
I
i
1
r
e
T
n
o
s
p
o
H
e
g
a
r
e
v
A
6
5
4
3
2
1
0
P. Gill et al.
s
P
S
I
1
i
r
e
T
o
r
e
Z
h
t
i
w
s
e
t
u
o
R
 35
 30
 25
 20
 15
 10
 5
 0
OrgID
AS
e
e
r
g
e
D
d
e
v
r
e
s
b
O
 30
 25
 20
 15
 10
 5
 0
m
y
y
g
a
a
o
h
h
o
o
o
e
g
a
sin
gle
a
o
u
plo
o.jp
m
hi5
ic
r
o
y
o
frie
utu
n
d
w
m
q
ikip
ste
r
q
y
s
e
p
a
dia
c
e
b
e