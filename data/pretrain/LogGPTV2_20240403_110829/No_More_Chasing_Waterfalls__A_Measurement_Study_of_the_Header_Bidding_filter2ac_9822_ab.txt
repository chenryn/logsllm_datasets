atives such as renamed HB libraries to names that are not known
yet, or new HB libraries that do not match our HB-related keywords
from known libraries. To avoid such potential false positives and
negatives, we chose not to use static analysis in the HBDetector.
The second method is more difficult to implement, but offers
better detection rates with reduced false positives and negatives,
and thus, harder to evade. This method monitors the DOM events
that are triggered in a webpage, events that are sent to notify the
code of interesting activity that has taken place on the page. Events
can represent everything from basic user interactions to automated
notifications happening on the page. Most HB libraries trigger
events in several phases of an auction (initiation of the auction, bid
collection, winning bidder, etc.). If such an event is detected, we
are certain that it is because of HB. Even better, by “tapping” on
these events [33], we can collect information about HB that the
first method is not able to detect.
The third method is similar to the second, but operates at a
different level in the browser: monitor the web requests of a page
in real-time, and detect all the request sent to and received from
known HB Demand Partners. By constructing a list containing all
Figure 3: Overview of the HBDetector mechanism. After the user ac-
cesses a webpage, all the incoming and outgoing WebRequests are
inspected to detect HB partners. A content script is also injected in
the header of the webpage to detect HB events about the auction
performed.
the known Demand Partners, we can check all the incoming and
outgoing WebRequests to the browser, and keep the relevant to HB.
In this paper, we implemented HBDetector, a tool which combines
the 2nd and 3rd methods to increase detection performance. An
overview of the tool is illustrated in Figure 3. HBDetector adds a
content script in the header of each webpage when the page is
loaded. This script monitors the webpage’s activity for various
events and requests sent and received by the page, keeping the
ones relevant to HB (e.g., incoming responses from DSPs for HB
auctions). When such DOM events are triggered (which is a first
sign of HB activity), the tool filters the web requests triggering
these events by checking the parameters included in them. HB
libraries use predefined parameters such as “bidder”, “hb_partner”,
“hb_price”, etc., which are not used by other ad-protocols such as
RTB. Thus, the tool keeps all web requests that triggered a DOM
event of a HB library, and also include HB parameters. It then
proceeds to extract the values from these parameters for analysis.
These parameters are typically fixed for each HB library, and all
HB partners must use them as such, to participate successfully in
HB auctions with that library. In contrast, in the RTB protocol, the
parameter names used in the notification URLs are DSP dependent
and do not utilize DOM events.
From the available HB libraries, we examined prebid.js (and its
variants), being the most famous one (64% of client-side wrappers
are built on prebid [28]), as well as gpt.js and pubfood.js libraries
for their available codebase and/or documentation. We decided to
focus our more in-depth reverse-engineering on prebid.js due to
its popularity, available documentation and open-source code and
APIs [24, 43]. By performing code and documentation analysis for
the HB libraries that have such material available, we identified the
following list of HB events that our tool can detect:
• auctionInit: the auction has started
• requestBids: bids have been requested
• bidRequested: a bid was requested from specific partner
• bidResponse: a response has arrived
• auctionEnd: the auction has ended
• bidWon: a bid has won
• slotRenderEnded: the ad’s code is injected into a slot
• adRenderFailed: an ad failed to render
Table 1: Summary of collected data by crawling top Alexa webpages
using the HBDetector for HB-related activity.
Data
# of websites crawled
# of websites with HB
# of auctions detected
# of bids detected
# of competing Demand Partners
# weeks of crawling
Volume
35,000
4998
798,629
241,392
84
5
In this work, we focus on three of these events: auctionEnd, bid-
Won, and slotRenderEnded. The auctionEnd, as its name states, is
triggered after the auctions for the ad-slots have finished, i.e., the
Demand Partners have submitted their offers. The bidWon event is
triggered after the winning Demand Partner has been determined.
Finally, the slotRenderEnded event is triggered when an ad has
finished rendering successfully on an ad-slot. By analyzing these
events, which can only be triggered by HB activity and not other
libraries, we were able to collect several metadata about the auc-
tions, such as the Demand Partners who bided, the ones who won,
the CPM (cost per million impressions in USD) spent, the ad size,
currency, dimensions, etc.
We also constructed a list with all the known HB Demand Part-
ners. We collected and combined several lists used by HB tools
designed to help publishers fine tune their HB on their websites.
Using this list, we can infer all the WebRequests about HB with-
out altering them, in order to detect when a request to a Demand
Partner is sent, and when an answer is received. The HBDetector is
written in a few hundred lines of JavaScript as a Google Chrome
browser extension.
HBDetector limitations: The tool does not analyze all libraries
used by the HB ecosystem due to unavailability of documentation
and/or code. Also, it cannot capture new DOM events if they get
added to existing libraries it is analyzing. Finally, it cannot capture
current DOM events if the events change format or parameters they
are using. In addition, the tool does not capture waterfalling RTB
activity, and therefore, does not allow direct comparison of the two
protocols with respect to Demand Partners involved, ad-prices, etc.
We plan to address these limitations in a future version of the tool.
3.2 Data Crawling
We used our tool to detect which websites employ HB, by crawling a
set of websites, based on a large top list purchased from Alexa [3] on
01/2017. Given the changes anticipated in such website ranking list
and especially in its long tail [48], we focus on the head of the Alexa
list, to capture a more stable part of the ranking distribution through
time. Due to equipment, network and time costs, we limited this
list to 35,000 domains to crawl per day, during Feb’19. To confirm
the representativeness of this older list, we compared it with the
top 35k domains in 2017-2019 from [48], and found that it has an
overlap of 78.36%(06/2017), 62.10%(06/2018), 58.36%(02/2019) and
55.34%(06/2019).
We used selenium and chromedriver loaded with HBDetector in
order to automate the crawling. We initiated a clean slate instance
before visiting each website, in order to keep the crawling process
stateless (no previous history, no cookies, no user profile). When a
283
Plugin DatabaseWeb Browser + HBDetectorStore for further analysisWeb request inspection for identification and metadata collection of demand partnersDOM event inspection for auction metadata collection.WebRequest InspectorApplies HB listMonitors HB eventsHTML DOM Event InspectorHB latenciesHB metadataFigure 4: Header Bidding adoption in the last six years for the top
1k Alexa websites of every year.
webpage is visited, the crawler waits for the page to be completely
loaded, and then allows an extra five seconds, in case additional
content needs to be downloaded or pending responses to be con-
cluded. We set the page load timeout to 60 seconds, so that if the
page is not fully loaded in one minute, the crawler proceeds to the
next webpage in the list, after killing the previous instance and
initiating a new, clean instance.
With this crawling process, we detected HB in ∼5,000 (14.28%)
of the websites, in a well-distributed fashion. In particular, HB was
found in 20-23% of the top 5k websites, 12-17% for the top 5k-15k,
and 10-12% for the rest. Indeed, new top websites not included in
this 35k list may have already adopted HB, leading to an underesti-
mation of today’s adoption rate. However, as found in our results
in Sec. 4.1 were we use top 1k Alexa lists for 6 years, we show
similar HB adoption rate with the head of the top 35k list, giving
credence to our results. Then, we crawled these 5k websites every
day for a period of 34 days in Feb’19, collecting metadata about the
HB auctions, and performance exhibited from the various websites
using HB. In Table 1, we provide a summary of the data collected.
We note that we detected 800k auctions but received 241k bids.
One could expect that each auction should have at least a bid. Indeed
this would be the case if actual users were involved and Demand
Partners were interested in them. However, there are cases where
bidders may avoid bidding when they know nothing about the user.
In our case, we are interested in the vanilla case using a clean state
crawler and no real user profiles.
4 THE 3 FACETS OF HEADER BIDDING
In this section, we analyze the crawled data and present results and
observations we have made about the HB adoption over time and
types of HB we identified from our exploration.
4.1 Header Bidding Adoption
Since this is a new programmatic ad-protocol (standardized in
2014[7]), we explore the general adoption of HB through the last
6 years. To do that, we downloaded snapshots of selected lists of
webpages using the Wayback Machine [29]. Due to the involved
network and time cost to crawl from the Wayback Machine, we
focused on the top 1,000 publishers based on Alexa rankings, made
available in a recent study [48] and https://toplists.github.io/. The
list of top publishers was selected on a fixed day per year (6/6/2019,
6/6/2018, etc.). Since these historical webpages were static, we per-
formed a static analysis looking for HB libraries and components in
their websites’ code. Someone could also try an analysis using the
HBDetector, by attempting to render each website, or even finger-
printing the libraries. However, such analyses: i) Take more time to
execute than static analysis. ii) The webpage must be renderable
and its components must work (scripts should be downloadable,
scripts should not fail to run, the page should not call unresponsive
servers, etc.). Therefore, dynamic analysis cannot be applied on
historical pages “played back”, with potentially deprecated libraries
or other scripts embedded, third-party partners not responding,
etc., and expect 100% correctness on the results collected.
Figure 4 shows the yearly breakdown of HB found in these
websites. Interestingly, we observe a steady increase of the HB
adoption. About 10% of these websites were early adopters and
started using HB 6 years ago. After the breakthrough of 2016, when
HB became popular[49], there is a steady 20% of the websites using
this ad protocol. These adoption rates, and the general rate of 14.28%
in the 35k list, match industry-claimed numbers of ∼15% in the last
15 months (14.66% in Jan’18 - 15.84% in March’19, computed for the
top 1k out of 5k top Alexa websites that serve programmatic ads)
for the US market [19, 28].
We note that HBDetector catches 100% of the HB activities for the
libraries analyzed. Indeed, there are websites which could be using
HB libraries that we didn’t analyze at the time of data collection, and
therefore were not flagged as HB-enabled websites. This means we
get 100% precision but not 100% recall. However, the HB adoption
experiment using the 1k lists shows a rate that aligns with the
overall HB adoption rate in the 35k list, and these two rates closely
match what industry is claiming. These observations point to low
false positive and negative rates, and that the data collected by
HBDetector (i.e., using dynamic analysis) have high recall rate and
provide a representative picture of the HB ecosystem at the time of
each crawl.
4.2 Types of Header Bidding Detected
Our in-depth investigation of the HB ecosystem and the data col-
lected revealed that this new programmatic ad protocol is currently
being deployed in three facets: (i) Client-Side HB, (ii) Server-Side
HB, and (iii) Hybrid HB. This finding matches the 3 types of HB
wrappers (client-side, server-side and hybrid) suggested by indus-
try reports [26]. In the Client-Side HB and Hybrid HB models, the
ad auctions are transparent, so we can distinguish them with a
high degree of certainty due to the events sent and received by the
browser. On the other hand, on Server-Side HB model it is less clear,
since most of the ad-related actions happen at the server. However,
after inspecting the responses received by the browser, we can
discover the parameters referring to HB (e.g. hb_partner, hb_price,
etc.). Next, we analyze each facet, including the steps taken for the
protocol’s execution, and potential consequences it may have.
4.3 Client-Side HB
In Client-Side HB, as the name implies, the HB process happens
in the user’s browser. As illustrated in Figure 5, during this HB
type, the user’s browser executes 8 steps, including the initiation
of the HB auction, receiving of bids from Demand Partners and
284
201420152016201720182019020406080100% of websitesDetected HBNon Detected HBFigure 5: Client-Side HB overview and steps followed.
Figure 6: Server-Side HB overview and steps followed.
notifying the winning partner. Client-Side HB’s main goal is to im-
prove fairness and transparency. Publishers can choose the Demand
Partners they want to collaborate with, regardless of their market
cap. What matters is if their bids are competitive enough. Also,
because the whole HB process is performed at the client side, and
then sent to the publisher’s ad server, it is completely transparent
to the publisher and, in theory, to the user.
The publisher can know at any time which partners bid, for
which ad-slots they were interested, how much they were willing
to pay, etc. On the down side, Client-Side HB is harder to set up.
Publishers need to have good technical understanding to set up
and tune their HB library. Also, they need to operate their own ad
server, a task which is not trivial. Finally, because of the increased
number of messages to be exchanged, or due to a bad configuration
in the HB library, longer latencies may be observed.
From the regular end-user’s point of view, the only thing that can
be observed is an increased latency for the loading of the webpage
when it employs Client-Side HB. However, the regular user cannot
be aware of all the HB (and other ad-tech) activity happening in the
background. This is where our HBDetector tool can help increase
transparency of the protocol from the point of view of the end-user,
and measure non-obvious aspects such as the communication and
time overhead for the browser during HB, winning bids, etc.
4.4 Server-Side HB
In Server-Side HB, a single request is sent to a Demand Partner’s
server, which is responsible to do the whole HB process and send
285
Figure 7: Hybrid HB overview and steps followed.
back to the client only the winning impressions. As Demand Part-
ners, in this scenario, we consider all possible ad partners (SSPs,
DSPs) that take part in the auction. Figure 6 shows the Server-
Side HB model and the steps performed by the user’s browser. The
careful reader will note a similarity of this model with Client-Side
HB with one Demand Partner. To distinguish Server-Side HB from
Client-Side HB, we check the responses sent back from the Demand
Partner involved to the browser, to filter out bid responses (which
would reveal Client-Side HB cases). This filtering using HB-related
keywords, also ensures that we are not mixing HB with traditional
waterfall activity. Obviously, in this model the publisher needs to
trust that the Demand Partner (i.e., the server handling all requests)
is honest, will not execute waterfall in the backend instead of HB,
and will select the best bids as winners, thus providing the best
possible profits to the publisher.
Server-Side HB requires the least effort from the publishers to
setup their HB. However, in exchange for setup convenience, it
reduces transparency to the minimum, since the publishers have no
way of knowing the Demand Partners participating in the auctions
or their actual bids. Publishers don’t need to tune their library,
nor set up an ad server. They just add to their webpage a pre-
configured library, provided by the Demand Partner they choose