### Composite Importance (CompImp) Analysis

**Figure 4: C.d.f. of CompImp over the Style Tree for dailyshotofcoffee.com**

- **Data Source**: 1,000 randomly sampled pages from dailyshotofcoffee.com.
- **Composite Importance (CompImp)**: A measure of a node's uniqueness and importance within the site. Nodes with a CompImp value close to 1 are unique or have unique children, while nodes with values closer to 0 appear frequently across the site.

**Observations**:
- A significant portion of the nodes in the style tree have a CompImp value of exactly 1, indicating their content is unique.
- Jumps in the graph suggest variations in templates or template usage across different sections of the site.

### Filtering Based on CompImp Thresholds

**Figure 5: Impact of Different CompImp Thresholds on Filtering**

- **Thresholds Tested**: 0.99, 0.6, and 0.1.
- **Results**:
  - **Threshold 0.99 and 0.6**: Produce the same output, as there are few nodes with CompImp values between 0.6 and 0.99.
  - **Threshold 0.1**: Discards too many elements, including parts of the page template that are not universally present.

### General Distribution of CompImp Values

**Figure 6: C.d.f. of CompImp over All Style Trees for 10,000 Random Sites**

- **Data Source**: 1,000 pages per website.
- **Observations**:
  - The distribution is similar across different sites.
  - A slight curve around CompImp value 1 indicates a few sites use fixed templates, with exceptions like 404 error pages, login, and registration pages.

### Sensitivity to Sample Size

**Figure 7: C.d.f. of CompImp for dailyshotofcoffee.com Using Only 5 Pages**

- **Data Source**: 5 random pages from dailyshotofcoffee.com.
- **Observations**:
  - The general shape of the distribution remains the same, but cutoffs differ slightly from the 1,000-page sample.
  - Manual inspection suggests that even with as few as five pages, the approach remains effective.

### Design Decision

- **Threshold Selection**: 0.99 for filtering.
- **Page Requirement**: At least five pages must be scraped; otherwise, the site is excluded from the filtering process.

### Feature Extraction

#### 4.3.1 AWIS Features

- **Data Source**: Alexa Web Information Service (AWIS) entries downloaded on February 2, 2014.
- **Discretization**: Continuous and large discrete features are converted to a set of discrete values for better classification performance.
- **Table 1: AWIS Features and Discretization**

| Feature             | Discretization Function | Values        |
|---------------------|-------------------------|---------------|
| AWIS Site Rank      | ⌊log(SiteRank)⌋         | [0 ... 8]     |
| Links to the Site   | ⌊log(LinksIn)⌋          | [0 ... 7]     |
| Load Percentile     | ⌊LoadPercentile/10⌋     | [0 ... 10]    |
| Adult Site?         | Boolean                 | {0, 1}        |
| Reach per Million   | ⌊log(reachPerMillion)⌋  | [0 ... 5]     |

- **Handling Missing Features**: 
  - For features like "reach per million," a default value is assigned if missing, assuming the site is unpopular.
  - For other features like "page load time," no default value is assigned due to lack of correlation.

#### 4.3.2 Content-Based Features

- **Data Source**: HTML tags from the pages that survive the acquisition and filtering process.
- **Tag Representation**: Each tag is represented as a tuple (type, attributes, content).
- **Aggregation**: Tags are aggregated into a list without repetition to avoid bias from homogeneous sites.
- **Training Phase**:
  - Tags are augmented with site classifications and added to a dictionary.
  - Heuristic: After every 5,000 sites, tags appearing only once are purged, reducing the dictionary size by approximately 85%.

**Statistic-Based Extraction**:
- **Feature Selection**: Top-N ranked tags based on a chosen statistic (e.g., ACC2).
- **ACC2 Statistic**: Balanced accuracy for a tag, defined as the absolute difference in tag frequency between malicious and benign sites.
- **Recomputation**: Top features are periodically recomputed to reflect recent changes.
- **Windowing**: To handle evolving distributions, a sliding window of the last K sites is used to ensure new relevant features are quickly identified.

### Conclusion

The analysis and feature extraction methods described provide a robust framework for classifying and filtering web pages. By using composite importance, AWIS features, and content-based features, the system can effectively identify and filter out non-unique or less important elements, ensuring that the classification model remains accurate and up-to-date.