For good end-user experience, fast DNS response times
are important. While this aspect has already been studied
in Section 4.1, we now investigate the exact answers that
DNS returns, i. e., the resolved IP addresses. Frequently,
there is more than one available option from where content
can be retrieved. Possible reasons include both the use of
load balancing and content distribution networks (CDNs) [9,
15]. The latter replicate content and provide copies near the
client to optimize network performance [12]. The goal of this
section is to study the observed diversity in resolved DNS
names (i. e., IP addresses) across diﬀerent vantage points
and diﬀerent DNS resolvers. In particular, we examine po-
tential interferences between the choice of the DNS resolver
and measurements done by CDNs. After all, CDNs such as
Akamai determine which IP to return in the DNS response
to the client based on measurements done against the DNS
resolver, not against the client. Choosing a DNS resolver
that is far from the end-host might vitiate the performance
optimizations made by CDNs.
As expected, there is indeed diversity in the IP addresses
returned by DNS. While we perform DNS queries for 10, 000
unique host names in our experiments, the overall number
of unique resolved IP addresses across all traces is 36, 000.
One reason is that we always perform two DNS queries for
the same host name and then even repeat this for three
diﬀerent DNS resolvers. Apart from load balancing, this can
be due to CDN content. When repeating queries or when
changing between DNS resolvers, the resolved DNS names
may be diﬀerent depending on the mechanisms CDNs use
to optimize network performance for the clients.
In Section 4.1 we ﬁnd that the local DNS resolvers gen-
erally provide lower latencies due to their proximity to the
end-hosts. Hence, one may speculate that they better repre-
sent the location of end-hosts than other resolvers. If possi-
ble, it might be more desirable for performance or economic
reasons that CDNs be queried by a DNS resolver that is lo-
cated within the local ISP of the end-host. Figure 5 shows
for each vantage point of our study (x-axis), how many IP
addresses that belong to the same ISP as the host of the
vantage point, were returned by each DNS resolver, across
all queried content.
We ﬁnd that the majority of DNS answers point to con-
tent outside the vantage point’s network. GoogleDNS and
OpenDNS even return IP addresses from diﬀerent networks
for all our traces. One of the reasons is that these resolvers
are usually not located inside the ISP. Yet, for approximately
30 vantage points we observe that content is downloaded
from at least 100 hosts located within the ISP’s network
when the local DNS resolver is queried. There even ex-
ist vantage points where local access occurs for 926 of our
10, 000 host names.
Although this may not appear much, it is signiﬁcant if we
consider that this locally available content completely covers
the akamaized set5 (see Section 3). We harvest IP addresses
of Akamai servers by sending DNS queries to Akamai con-
tent from diﬀerent Planetlab servers. Interestingly, we ﬁnd
based on manual inspection that the vantage points with lo-
cal content generally have an Akamai server deployed within
the same network.
5Additionally, there is strong overlap with top5000 and em-
bedded.
19S
A
e
m
a
s
n
i
e
r
a
t
a
h
t
s
P
I
d
e
n
r
u
t
e
r
#
0
0
8
0
0
6
0
0
4
0
0
2
0
Google
Local
OpenDNS
x
xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
0
0
0
3
0
0
5
2
0
0
0
2
0
0
5
1
0
0
0
1
0
0
5
0
s
r
e
w
s
n
a
t
n
e
r
e
f
f
i
d
#
subnet
AS
country
x
x
x
xx
x
x
xxx
xxxxxxxx
x
x
xx
x
xxxxxxx
x
x
x
x
x
x
x
x
x
xx
x
x
x
xx
x
x
x
x
x
x
x
x
x
xxx
vantage points
vantage points
(sorted by # returned IPs that are in same AS)
(sorted by #IPs that are in different subnets)
Figure 5: How often do DNS answers point to locally
available content?
Figure 6: How often do the DNS answers of local
resolver and GoogleDNS diﬀer?
From Figure 5 we can infer that only local DNS resolvers
direct end-users to content that is locally available in the net-
work of the vantage point. Instead of matching the results
of the resolvers against the network of the vantage point,
we now directly compare our three DNS resolvers pairwise
against each other. More precisely, we count how often the
results of the two resolvers are diﬀerent with respect to the
subnet, autonomous system (AS), and country6 of the DNS
answer. Figure 6 presents for each vantage point of our study
(x-axis) the number of diﬀerences for the comparison local
DNS vs. GoogleDNS.
Figure 6 reveals that the answers to the DNS resolvers dif-
fer in terms of subnets for approximately 2, 000 out of our
10, 000 host names. In half of these cases, the returned IP
addresses even belong to diﬀerent ASs and countries. Since
the local DNS resolver points to content inside the ISP’s
network for a signiﬁcant number of host names (Figure 5),
we claim that GoogleDNS and OpenDNS unnecessarily di-
rect end-users to content servers in diﬀerent ASs or even
subnets. Due to space limitations we do not present the
plots for the comparisons between Local vs. OpenDNS and
Google vs. OpenDNS. Both plots are very similar to Fig-
ure 5. Apparently, whenever we change the DNS resolver,
there will be diﬀerent answers from DNS for at least some of
the host names. This observation justiﬁes recent activities of
the IETF in the direction of standardizing a way to include
the IP address of the original end-host in DNS requests [5].
5. CONCLUSION
Based on active measurements from inside more than 50
commercial ISPs, we have studied DNS performance by com-
paring the ISPs’ DNS deployment against widely used third-
party DNS resolvers, namely GoogleDNS and OpenDNS.
Typically, end-hosts experience very small latencies to
the resolvers maintained by the local ISP, though there
exist cases where GoogleDNS and OpenDNS outperform
6We used geolocation data to map IP addresses to countries
[6].
the local DNS resolvers in terms of the observed response
times. Moreover, our ﬁndings suggest that several ISPs and
OpenDNS rely on a load balancing setup without a shared
cache, resulting in poor caching eﬃciency. Even Google
Public DNS, despite their claim [2] exhibits the same be-
havior for a few vantage points. Moreover, we observe that
third-party DNS resolvers do not manage to redirect the
users towards content available within the ISP, contrary to
the local DNS ones. This observation holds for all akamaized
content.
Given the increasing share of CDN traﬃc [11, 13] we aim
in the future to fully understand to what degree the choice
of DNS resolvers does vitiate the performance optimizations
made by CDNs. In this regard, we plan to rerun our exper-
iments based on an enlarged set of vantage points and with
an enhanced version of our script, e. g., to scrutinize caching
and investigate the role of anycast in DNS performance.
Acknowledgments
The authors wish to thank all volunteers who ran our script
on their systems and submitted the results. Moreover, we
would like to thank our shepherd, Craig Partridge, and the
anonymous reviewers for their constructive comments.
6. REFERENCES
[1] Alexa top sites. http:///www.alexa.com/topsites.
[2] Google Public DNS. http://code.google.com/intl/de-
DE/speed/public-dns/.
[3] Namebench—open-source dns benchmark utility.
http://code.google.com/p/namebench/.
[4] OpenDNS: What’s Your Take?
http://www.neowin.net/news/opendns-whats-your-
take.
[5] C. Contavalli, W. van der Gaast, S. Leach, and
D. Rodden. Client IP information in DNS requests.
IETF draft, work in progress,
draft-vandergaast-edns-client-ip-00.txt, Jan 2010.
20[6] Hexasoft Development Sdn. Bhd. IP Address
[12] T. Leighton. Improving Performance on the Internet.
Geolocation to Identify Website Visitor’s Geographical
Location. http://www.ip2location.com.
[7] D. Joumblatt, R. Teixeira, J. Chandrashekar, and
N. Taft. Perspectives on Tracing End-hosts: A Survey
Summary. Computer Communication Review,
40(2):51–55, 2010.
Commun. ACM, 52(2):44–51, 2009.
[13] Ingmar Poese, Benjamin Frank, Bernhard Ager,
Georgios Smaragdakis, and Anja Feldmann.
Improving Content Delivery using Provider-aided
Distance Information. In Proc. of ACM IMC ’10,
Melbourne, Australia.
[8] J. Jung, E. Sit, H. Balakrishnan, and R. Morris. DNS
[14] A. Su, D. Choﬀnes, A. Kuzmanovic, and
Performance and the Eﬀectiveness of Caching.
IEEE/ACM Trans. Netw., 10(5):589–603, 2002.
[9] B. Krishnamurthy, C. Wills, and Y. Zhang. On the
Use and Performance of Content Distribution
Networks. In Proc. of ACM IMW ’01, San Francisco,
CA, USA.
F. Bustamante. Drafting Behind Akamai: Inferring
Network Conditions Based on CDN Redirections.
IEEE/ACM Trans. Netw., 17(6):1752–1765, 2009.
[15] S. Triukose, Z. Al-Qudah, and M. Rabinovich.
Content Delivery Networks: Protection or Threat? In
Proc. of ESORICS ’09, Saint-Malo, France.
[10] R. Krishnan, H. Madhyastha, S. Srinivasan, S. Jain,
[16] P. Vixie. DNS Complexity. ACM Queue, 5(3):24–29,
A. Krishnamurthy, T. Anderson, and J. Gao. Moving
Beyond End-to-end Path Information to Optimize
CDN Performance. In Proc. of ACM IMC ’09,
Chicago, IL, USA.
[11] C. Labovitz, D. McPherson, and S. Iekel-Johnson.
Internet observatory report.
http://www.nanog.org/meetings/nanog47/.
2007.
[17] P. Vixie. What DNS is Not. Commun. ACM,
52(12):43–47, 2009.
21