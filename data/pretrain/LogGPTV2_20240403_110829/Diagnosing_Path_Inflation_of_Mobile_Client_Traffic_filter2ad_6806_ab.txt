major carriers, even though Google deploys servers around the world to serve nearby
clients [4]. However, we also observe that the fraction of paths experiencing metro-level
inﬂation decreases signiﬁcantly over the subsequent 12 months. As we will show, we
can directly link some of these improvements to the topological expansion of carriers.
In the rest of the paper, we examine path inﬂation to understand its causes and to
explore what measures carriers have adopted to reduce or eliminate it. We begin by
characterizing the different types of metro-level inﬂations we see in our dataset. We
split the end-to-end path into three logical parts: client to carrier ingress point (Carrier
Access), carrier ingress point to service provider ingress point (Interdomain), and ser-
vice provider ingress point to destination server (Provider Backbone). Then we deﬁne
the following observed trafﬁc patterns of inﬂated routes:
Carrier Access Inﬂation. Trafﬁc from a client in metro area L (Local) enters the Internet
in metro area R (Remote), and is directed to a Google server in R.
Interdomain Inﬂation. Trafﬁc from a client in area L enters the carrier’s backbone in
L, then enters Google’s network in area R and is directed to a Google server there.
Carrier Access-Interdomain Inﬂation. Trafﬁc from a client in metro area L enters the
carrier’s backbone in metro area R, then enters Google’s network back in area L and is
directed to a Google server there.
Provider Backbone Inﬂation. Trafﬁc from a client in area L enters the carrier’s back-
bone and Google’s network in area L, but is directed to a Google server in a different
area R. In all cases, Google servers are known to exist in both metro areas L and R.
Possible Causes of Path Inﬂation. If a carrier lacks sufﬁcient ingress points from its
cellular network to the Internet, it can cause Carrier Access Inﬂation. For example, if a
carrier has no Internet ingress points in metro area L, it must send the trafﬁc from L to
another area R (Fig. 2, user B). If a carrier’s access network ingresses into the Internet
in metro-area L, a lack of peering between the mobile carrier and Google in metro-
area L causes trafﬁc to leave the metro area, resulting in Interdomain Inﬂation (Fig. 2,
user C). If a carrier has too few ingresses and lacks peering near its ingresses, we may
observe Carrier Access-Interdomain Inﬂation. In this case a carrier, lacking ingress in
area L, hauls trafﬁc to a remote area R, where it lacks peering with Google. A peer-
ing point exists in area L, so trafﬁc returns there to enter Google’s network. Though a
provider like Google has servers in most major metropolitan areas, it can still experi-
ence Provider Backbone Inﬂation if either Google or the mobile carrier groups together
clients in diverse regions when making routing decisions. In this case, Google directs
at least some of the clients to distant servers. Google may also route a fraction of trafﬁc
long distances across its backbone for measurement or other purposes.
28
K. Zariﬁs et al.
No Peering
Server
Peering
Peering
Server
Server
Peering
Peering
Server
Server
Internet
Ingress
Ingress
Ingress
No Ingress 
No Ingress 
g
User C
Metro Area C
Cell Tower
User A
User A
Cell Tower
Cell Tower
Metro Area A
Cell Tower
Cell Tower
User B
User B
Metro Area B
Fig. 2. Different ways a client can be directed to a server. User A is the ideal case, where the
trafﬁc never leaves a geographical area. User B and C’s trafﬁc suffers path inﬂation, due to lack
of ingress point and peering point respectively.
Identifying Root Causes. We run one or more of the following checks, depending on
the inﬂated part(s) of the path, to perform root cause analysis (illustrated in Fig. 3).
Examining Carrier Access Inﬂation. For inﬂated carrier access paths, we determine
whether the problem is the lack of an available nearby ingress point. To do so, we
examine the ﬁrst public IP addresses for other traceroutes issued by clients of the same
carrier in the same area. If none of those addesses are in the client’s metro area, we
conclude there is a lack of available local ingress.
Examining Interdomain Inﬂation. For paths inﬂated between the carrier ingress point
and the ingress to Google’s network, we determine whether it is due to a lack of peering
near the carrier’s ingress point. We check whether any traceroutes from the same carrier
enter Google’s network in that metro area, implying that a local peering exists. If no
such traceroutes exist, we infer a lack of local peering.
Examining Provider Backbone Inﬂation. For paths inﬂated inside Google’s network,
we check for inefﬁcient mappings of clients to servers. We look for groups of clients
from different metro areas all getting directed to servers at either one or the other area
for some period, possibly ﬂapping between the two areas over time. If we observe that
behavior, we infer inefﬁcient client/resolver clustering.
A small number of traceroutes (< 2%) experienced inﬂated paths but did not ﬁt
any of the above root causes. These could be explained by load balancing, persistent
incorrect mapping of a client to a resolver/server, or a response to network outages.
5 Results
We ﬁrst present examples of the three dominant root causes for metro-level inﬂation. We
then show aggregate results from our inﬂation analysis, its potential impact on latency,
and the evolution of causes of path inﬂation over time.
Case Studies. For each root cause, we now present one example. For each example, we
describe what the traceroutes show, what the diagnosis was, and note the estimated per-
formance hit, ranging from 7-72% extra propagation delay. We constrain our analysis
to the period between late 2011 and mid 2012, where the dataset is sufﬁciently dense.
Diagnosing Path Inﬂation of Mobile Client Trafﬁc
29
Carrier Access
End-to-end path
Interdomain
Provider Backbone
Carrier Access Part Inflated?
Interdomain Part Inflated?
Provider Backbone Part Inflated?
YES
YES
YES
Are there any traces with 
first hop in this area?
Are there any traces served by 
local target without exiting area?
Are all traces directed to exactly 
one destination at any given time?
NO
NO
YES
Lack of local ingress point
Lack of local peering point
Inefficient client clustering
Fig. 3. Root cause analysis for metro-level inﬂation
Lack of ingress point. We observe that all traceroutes to Google from AT&T clients in
the NYC area enter the public Internet via an ingress point in Chicago. Thus, Google
directs these New York clients to a server in the Chicago area, even though it is not the
server geographically closest to the clients. These Chicago servers are approximately
1074km further from the clients than the New York servers are, leading to an expected
minimum additional round-trip latency of 16ms (7% overhead) [3].
Lack of peering. We observe AT&T peering with Google near San Francisco (SF),4
but not near Los Angeles (LA) or Seattle. Therefore, Google directs clients in those
two areas to servers in SF rather than in their local metros. While our data in these
regions become sparse after mid 2012, we veriﬁed that this inﬂation persists for clients
from LA in Q2 2013. The observed median RTT for Seattle users served by servers in
SF is 90ms. Since those servers are 1089km farther away from the servers nearest to
the Seattle users, they experience a delay inﬂation of at least 16ms (21%). As a result,
loading even a simple website like the Google homepage requires an additional 160ms.
Coarse client-server mapping granularity or Inefﬁcient client/resolver clustering. We
observe a behavior for Verizon clients that suggests that Google is jointly directing
clients in Seattle and SF. At any given time, trafﬁc from both areas was directed towards
the same Google servers, either in the Seattle or in the SF area, therefore exhibiting
suboptimal performance for some distant clients. Figure 4 illustrates this behavior over a
2-month period. Normally, users served by servers in their metro area observe a median
RTT of 22ms and 45ms for SF and Seattle respectively. However, when users in one
area served by servers in the other area (indicated by the ﬁlled pattern in the ﬁgure), the
additional 1089km one-way distance adds an extra 16ms delay (an overhead of 72%
and 35% for SF and Seattle users respectively).
Inﬂation Breakdown by Root Cause. In this section, we show aggregated statistics of
some of the observed anomalies that cause performance degradation. We focus on Q4
2011 and on AT&T and Verizon Wireless, the period and carriers for which the dataset
is the densest. We also focus on three large metropolitan areas that were populated
enough to generate signiﬁcant data (SF, New York and Seattle). Google servers exist in
all three areas. For all measurements issued from those areas, we quantify the fraction
4 For the granularity of our analysis, we treat all locations in the Bay Area as equivalent.
30
K. Zariﬁs et al.
(cid:1)(cid:4)(cid:3)(cid:2)(cid:2)
(cid:1)(cid:4)(cid:2)(cid:2)(cid:2)
(cid:1)(cid:3)(cid:2)(cid:2)
(cid:14)
(cid:18)
(cid:17)
(cid:9)
(cid:12)
(cid:9)
(cid:16)
(cid:15)
(cid:14)
(cid:13)
(cid:9)
(cid:12)
(cid:11)
(cid:1)
(cid:19)(cid:21)(cid:1)(cid:14)(cid:9)(cid:16)(cid:7)(cid:9)(cid:16)
(cid:19)(cid:9)(cid:13)(cid:18)(cid:18)(cid:20)(cid:9)(cid:1)(cid:14)(cid:9)(cid:16)(cid:7)(cid:9)(cid:16)
(cid:1)(cid:5)(cid:2)(cid:2)
(cid:1)(cid:4)(cid:3)(cid:2)
(cid:1)(cid:4)(cid:2)(cid:2)
(cid:1)(cid:3)(cid:2)
(cid:12)(cid:10)(cid:16)(cid:17)(cid:17)(cid:18)(cid:10)(cid:1)(cid:14)(cid:10)(cid:15)(cid:8)(cid:10)(cid:15)
(cid:12)(cid:13)(cid:1)(cid:14)(cid:10)(cid:15)(cid:8)(cid:10)(cid:15)
(cid:1)(cid:2)
(cid:5)(cid:6)(cid:7)(cid:1)(cid:4)(cid:3)
(cid:8)(cid:9)(cid:10)(cid:1)(cid:4)
(cid:8)(cid:9)(cid:10)(cid:1)(cid:4)(cid:3)
(cid:1)(cid:2)
(cid:6)(cid:7)(cid:8)(cid:1)(cid:4)(cid:3)
(a) SF clients
(cid:9)(cid:10)(cid:11)(cid:1)(cid:4)
(cid:9)(cid:10)(cid:11)(cid:1)(cid:4)(cid:3)
(b) Seattle clients
Fig. 4. Server selection ﬂapping due to coarse client-server mapping. Dashed areas denote mea-
surements where the client was directed to a remote server.
Table 2. Overall results for two carriers for 2011 Q4. The table shows what fraction of all
traceroutes from clients in three different locations presented a deviation, cause of the devia-
tion (I = Ingress, P = Peering, D = DNS/clustering), extra distance traveled (round-trip), extra
round trip time (RTT), and extra page load time (PLT) when accessing the Google homepage.
Closest
Server
T SF
&
T