Fully Connected +ReLU
Fully Connected +ReLU
Softmax
# of Neurons
124
512
128
32
2
hashtag-based features. In trending-based features, the following
three types of tweets are considered: (1) The tweets with topics of
trending up; (2) The tweet with topics of trending down; (3) The
tweets with popular topics. For the sake of simplicity, these three
types of tweets are abbreviated as trending-up, trending-down, and
trending-pop, respectively. We take the top 10 topics under each
type from [9] and sequentially screen 10 user accounts for each
topic to serve as the pseudo-honeypot nodes. Thus, there is a total
of 300 pseudo-honeypot nodes with the trending-based features.
In total, we have constructed a group of pseudo-honeypot net-
work with 1, 100 nodes. The time to create one such sized pseudo-
honeypot network is less than 1 minute. This significantly reduces
the deployment cost when compared to the manual construction
of traditional honeypots. Note here, the nodes in pseudo-honeypot
network are not immutable and are to shift to another group of
users after a specific time, ensuring the pseudo-honeypot network
to involve only those users in Prosperous Period. This design im-
proves the effectiveness of pseudo-honeypot network in terms of
spam messages gathering, as we discussed in Section 3.2. We imple-
ment the pseudo-honeypot network in Python with Tweepy library,
where the streaming API is employed to monitor users and retrieve
tweets. The TweetScore solution is run on a workstation with dual
Intel i5-6600K CPUs and 32 GB RAM.
We run our pseudo-honeypot system and perform spammer
detection on gathered data for a total of 700 hours. The time for the
pseudo-honeypot network to move to another new group of users
is set to be one hour. The selection of the new group of users to
serve as pseudo-honeypot nodes follows the same criteria as above.
Within the 700-hour experiments, there is a total of 1, 694, 018
tweets collected with these tweets involving a total of 69, 3358
unique user accounts.
Neural Network Setting. As discussed in Section 4.7, the neural
network model is employed to train the TweetScore vectors and then
classify the spam messages and spammers. The neural network
parameters are given in Table 1, where the first column represents
the layer types that have been shown in Figure 5 and the second
column represents the number of neurons that are used at each
layer.
In this neural network model, the connection between any two
neurons is controlled by a dropout layer with a dropout rate of
0.5. The binary Cross-Entropy is used to model the loss function as
follows.
yi · log(p(yi)) + (1 − yi) · log(1 − p(yi)),
(17)
N
i =1
Loss =
1
N
Figure 5: The layer structure of Neural Network model.
label them as the ground truth. Then, we propose to employ the
neural network to have deeper training of these relationships.
The structure of the neural network that we employed is shown
as in Figure 5. The tweet score vector S will input to the first layer
and then pass to the hidden layer for training, which includes three
layers of fully connected Rectified Linear Units (ReLU). At the
output layer, we leverage the standard sigmoid function which is
commonly applied to the two-class logistic regression problem. In
the training phase, a cross-entropy loss is minimized with gradient
descent on the output of the sigmoid function. As we use the stan-
dard neural network model here, we omit the detailed description
to conserve space.
5 EXPERIMENTS
This section presents the implementation of our advocated pseudo-
honeypot system for tweet monitoring (in Section 3) and the use
of our TweetScore solution on spam classification (in Section 4).
Our goal is twofold. First, we show the effectiveness of the pseudo-
honeypot system in spams collection. By comparing with its coun-
terparts, i.e., non-pseudo-honeypot and honeypot systems, we il-
lustrate the advantages of pseudo-honeypot system on gathering
potential spams messages. Second, we evaluate the efficiency of
TweetScore in spam classification for comparison with the existing
works.
5.1 Implementation
In our implementation, we leverage the hashtag-based and trending-
based features, that have been widely adopted in previous research
[2, 22] and also have been demonstrated to effectively attract spam-
mers. The selected features serve as the criteria to identify candidate
users for our pseudo-honeypot nodes. Specifically, in hashtag-based
features, we identify a set of features that have more potentials in
attracting spammers, including entertainment, business, tech, edu-
cation, environment, social, astrology, and general. Then, we select
the top 10 hashtags (from [9]) under each hashtag-based category
while for each hashtag, we screen 10 users that possess such a
hashtag. For example, in the entertainment category, we obtain the
top 10 popular hashtags from [9] and select 10 user accounts for
each of them. Hence, under the entertainment category, we sample
a total of 100 pseudo-honeypot nodes out of the top 10 hashtags.
Likewise, we also take the top 10 popular hashtags for each of
the other hashtag categories and then screen 100 users to serve
as pseudo-honeypot nodes following the same way. There are a
total of 800 pseudo-honeypot nodes that are constructed under
ReLUReLUReLUSoftmaxClass probabilitiesSpamNon-spam10Sender vectorReceiver vectorTweet vectorSession 5A: Web SecurityAsiaCCS ’19, July 9–12, 2019, Auckland, New Zealand386Table 2: Extracted statistical features in [7].
Table 3: 10-fold cross-validation results.
No. Notation
1
2
3
4
5
6
7
8
9
10
11
12
Description
The days of the account since created
The No. of followers of the account
The No. of friends of the account
Account age
follower count
following count
favourites count The No, of favourites account received
lists count
tweets count
retweets count
hashtags count
mentions count
urls count
char count
digits count
The No. of list the account added
The No. of tweets the account send
The No. of retweets the accout send
The No. of hashtag in the tweet
The No. of mentions in the tweet
The No. of urls in the tweet
The No. of characters in the tweet
The No. of digits in the tweet.
where N denotes the total amount of input tweets, y denotes the
label (i.e., 1 for spam and 0 for non-spam), and p(y) is the predicted
probability of spams in the N tweets. To train the neural network,
we employ the Stochastic Gradient Descent method (SGD) as the
optimizer. The learning rate R is initialized as the value of 0.1 and
then is updated once for every 10 epochs. Thus, we have R ←
0.5⌊(1+ i10)⌋, where i denotes the training epochs. Moreover, we
set the batch size as 100 and the total epoch count equal to 200,
respectively.
Solution Comparison. To show the performance of TweetScore,
we take the following two existing solutions for comparison.
• SybilSCAR [32]: SybilSCAR is a structure based method
to detect Sybil (i.e., fake) accounts in the social network. In
essence, it analyzes the graphic structure among users and
classifies them into the benign and Sybil regions. The random
walk and belief propagation methods are employed in the
classification in SybilSCAR. SybilSCAR iteratively calculates
the local rule:
(t−1)
,
(t) = ˆq + 2 ˆwAˆp
ˆp
(18)
where ˆp and ˆq represent the residual prior probability vec-
tor and posterior probability vector respectively. ˆw is the
parameter determs homophily (edge with same type nodes)
strength between two nodes and A is an adjacency matrix of
the social graph. According to ˆp(t), a threshold (e.g., 0.5) is
set to distinguish the benign and Sybil users. This solution
can work on our collected dataset to classify spammers and
normal users, which are treated respectively as Sybil and
benign. But the attributes relationships among users are not
considered in this work.
• Chen6M [7]: Chen6M is a classification method, on extract-
ing statistic information from the user profiles and tweets. It
extracts a total of 12 features, listed in Table 2. After that, the
traditional machine learning classifier, i.e., Random Forest,
is employed for spam classification.
5.2 Accuracy of TweetScore
We take the first 100-hour data captured by pseudo-honeypot as
the training dataset. To label a reliable ground truth dataset, we
Classifier
AB
GB
k-NN
SybilSCAR
Chen6M
TweetScore
Precision Accuracy Recall
0.797
0.835
0.722
0.436
0.852
0.914
0.872
0.926
0.901
0.454
0.955
0.967
0.855
0.811
0.760
0.661
0.976
0.989
F1-macro
0.831
0.852
0.820
0.445
0.927
0.946
Figure 6: The ROC curves of TweetScore with different ma-
chine learning classifiers.
adopt the diversified approaches to ensure the labeled dataset cov-
ers a broad range of spams and spammers that can reflect their
characteristics of diversity. That is, we first check suspended ac-
counts to label a set of spams and spammers. Then, we employ the
clustering method to group tweets, where Minhash [25] is used to
check the similarity of tweets and then cluster them into different
groups, The spammers and spams in each group are labeled via
the following criteria: 1) if a user in one group is suspended by
Twitter, all users in this group are labeled as spammers; 2) if a tweet
in one group is labeled as spam, its users and all tweets in this
group are labeled as spammers and spams, respectively. After such
preprocessing, we can get a roughly labeled ground truth dataset.
Lastly, we perform manual checking (by inspecting account and
tweets text information) both in the labeled dataset and the remain-
ing unlabeled dataset to refine a reliable ground truth dataset. In
the first 100 hours data, we label a total of 15, 097 spammers and
219, 715 non-spams as our ground truth data.
10-fold cross-validation. We conduct the 10-fold cross validation
on the labeled ground truth dataset to evaluate the performance of
TweetScore, when compared to SybilSCAR Chen6M, and several tra-
ditional machine learning classifiers (i.e., k Nearest Neighbors (kNN),
Gradient Boosting (GB), and AdaBoost (AB)). Table 3 shows the de-
tailed accuracy, precision, recall, and F1-marco ratios of TweetScore
and different counterpart solutions. From this table, it is evidenced
that our TweetScore always outperforms other methods in all met-
rics. In particular, the precision, accuracy, recall, and F1-macro of
TweetScore are 98.9%, 96.7%, 91.4% and 94.6% respectively. These
results confirm the superior efficiency of TweetScore on spam clas-
sification.
0.00.20.40.60.81.0FalsePositiveRate(Speciﬁcity)0.00.20.40.60.81.0TruePositiveRate(Sensitivity)TweetscoreChen6MGBSybilScarSession 5A: Web SecurityAsiaCCS ’19, July 9–12, 2019, Auckland, New Zealand387Figure 7: The accuracy, precision, and recall of TweetScore in
the online spam classification (600 hours).
Figure 9: Time cost of TweetScore with various training and
test dataset sizes.
dataset and employ the TweetScore to classify the tweets reported
later in every 10 hours. Figure 7 shows the accuracy, precision, and
false positive of TweetScore. From this figure, the average ratios of ac-
curacy, precision, and false positive of TweetScore are 93.50%, 93.71%,
and 1.52%, respectively, within the 600 testing hours. These results
demonstrate high efficiency and accuracy of TweetScore in online
spam detection.
Comparison. We next compare the performance of TweetScore,
SybilSCAR and Chen6M on spam classification within the 600 test-