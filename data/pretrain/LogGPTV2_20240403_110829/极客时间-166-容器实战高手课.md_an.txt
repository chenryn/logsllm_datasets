# Double check the value after update:    
# cat /proc/sys/net/ipv4/tcp_congestion_control    bbr    
# cat /proc/sys/net/ipv4/tcp_keepalive_time    600    
# cat /proc/sys/net/ipv4/tcp_keepalive_intvl    10    
# cat /proc/sys/net/ipv4/tcp_keepalive_probes    6然后我们启动一个容器，再来查看一下容器里这些参数的值。你可以先想想，容器里这些参数的值会是什么？我最初觉得容器里参数值应该会继承宿主机Network Namesapce里的值，实际上是不是这样呢？我们还是先按下面的脚本，启动容器，然后运行 `docker exec`命令一起看一下：    
# docker run -d --name net_para centos:8.1.1911 sleep 3600    deec6082bac7b336fa28d0f87d20e1af21a784e4ef11addfc2b9146a9fa77e95    
# docker exec -it net_para bash    [root@deec6082bac7 /]
# cat /proc/sys/net/ipv4/tcp_congestion_control    bbr    [root@deec6082bac7 /]
# cat /proc/sys/net/ipv4/tcp_keepalive_time    7200    [root@deec6082bac7 /]
# cat /proc/sys/net/ipv4/tcp_keepalive_intvl    75    [root@deec6082bac7 /]
# cat /proc/sys/net/ipv4/tcp_keepalive_probes    9从这个结果我们看到，tcp_congestion_control 的值是 bbr，和宿主机Network Namespace 里的值是一样的，而其他三个 tcp keepalive相关的值，都不是宿主机 Network Namespace里设置的值，而是原来系统里的缺省值了。那为什么会这样呢？在分析这个问题之前，我们需要先来看看 NetworkNamespace 这个概念。知识详解如何理解 Network Namespace？对于 Network Namespace，我们从字面上去理解的话，可以知道它是在一台Linux节点上对网络的隔离，不过它具体到底隔离了哪部分的网络资源呢？我们还是先来看看操作手册，在Linux Programmer'sManual  里对Network Namespace有一个段简短的描述，在里面就列出了最主要的几部分资源，它们都是通过Network Namespace 隔离的。我把这些资源给你做了一个梳理：第一种，网络设备，这里指的是 lo，eth0 等网络设备。你可以可以通过`ip link`命令看到它们。第二种是 IPv4 和 IPv6 协议栈。从这里我们可以知道，IP 层以及上面的 TCP和 UPD 协议栈也是每个 Namespace独立工作的。所以 IP、TCP、PUD 的很多协议，它们的相关参数也是每个 Namespace独立的，这些参数大多数都在 /proc/sys/net/ 目录下面，同时也包括了 TCP 和UPD 的 port 资源。第三种，IP 路由表，这个资源也是比较好理解的，你可以在不同的 NetworkNamespace 运行 `ip route`命令，就能看到不同的路由表了。第四种是防火墙规则，其实这里说的就是 iptables 规则了，每个 Namespace里都可以独立配置 iptables规则。 最后一种是网络的状态信息，这些信息你可以从 /proc/net 和/sys/class/net 里得到，这里的状态基本上包括了前面 4种资源的的状态信息。Namespace 的操作那我们怎么建立一个新的 Network Namespace呢？ **我们可以通过系统调用 clone() 或者 unshare() 这两个函数来建立新的Network Namespace。**下面我们会讲两个例子，带你体会一下这两个方法具体怎么用。第一种方法呢，是在新的进程创建的时候，伴随新进程建立，同时也建立出新的Network Namespace。这个方法，其实就是通过 clone() 系统调用带上CLONE_NEWNET flag 来实现的。Clone 建立出来一个新的进程，这个新的进程所在的 Network Namespace也是新的。然后我们执行 `ip link` 命令查看 Namespace里的网络设备，就可以确认一个新的 Network Namespace已经建立好了。具体操作你可以看一下这段代码slate-object="inline"。    int new_netns(void *para)    {                printf("New Namespace Devices:\n");                system("ip link");                printf("\n\n");                     sleep(100);                return 0;    }         int main(void)    {                pid_t pid;                     printf("Host Namespace Devices:\n");                system("ip link");                printf("\n\n");                     pid =                    clone(new_netns, stack + STACK_SIZE, CLONE_NEWNET | SIGCHLD, NULL);                if (pid == -1)                            errExit("clone");                     if (waitpid(pid, NULL, 0) == -1)                            errExit("waitpid");                     return 0;    }第二种方法呢，就是调用 unshare() 这个系统调用来直接改变当前进程的Network Namespace，你可以看一下这段代码slate-object="inline"。    int main(void)    {                pid_t pid;                     printf("Host Namespace Devices:\n");                system("ip link");                printf("\n\n");                     if (unshare(CLONE_NEWNET) == -1)                            errExit("unshare");                     printf("New Namespace Devices:\n");                system("ip link");                printf("\n\n");                     return 0;    }其实呢，不仅是 Network Namespace，其它的 Namespace 也是通过 clone()或者 unshare()系统调用来建立的。而创建容器的程序，比如runC也是用 unshare() 给新建的容器建立Namespace 的。这里我简单地说一下 runC 是什么，我们用 Docker 或者 containerd去启动容器，最后都会调用 runC 在 Linux中把容器启动起来。除了在代码中用系统调用来建立 NetworkNamespace，我们也可以用命令行工具来建立 Network Namespace。比如用 `ip netns`命令，在下一讲学习容器网络配置的时候呢，我们会用到`ip netns`，这里你先有个印象就行。在 Network Namespace 创建好了之后呢，我们可以在宿主机上运行 `lsns -t net`这个命令来查看系统里已有的 NetworkNamespace。当然，`lsns`也可以用来查看其它Namespace。 用  `lsns`查看已有的 Namespace 后，我们还可以用 `nsenter`这个命令进入到某个 Network Namespace 里，具体去查看这个 Namespace里的网络配置。比如下面的这个例子，用我们之前的 clone() 的例子里的代码，编译出clone-ns 这个程序，运行后，再使用 `lsns`查看新建的 NetworkNamespace，并且用`nsenter`进入到这个 Namespace，查看里面的 lodevice。 具体操作你可以参考下面的代码：    
# ./clone-ns &    [1] 7732    
# Host Namespace Devices:    1: lo:  mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000        link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00    2: eth0:  mtu 1500 qdisc fq_codel state UP mode DEFAULT group default qlen 1000        link/ether 74:db:d1:80:54:14 brd ff:ff:ff:ff:ff:ff    3: docker0:  mtu 1500 qdisc noqueue state DOWN mode DEFAULT group default        link/ether 02:42:0c:ff:2b:77 brd ff:ff:ff:ff:ff:ff              New Namespace Devices:    1: lo:  mtu 65536 qdisc noop state DOWN mode DEFAULT group default qlen 1000        link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00         