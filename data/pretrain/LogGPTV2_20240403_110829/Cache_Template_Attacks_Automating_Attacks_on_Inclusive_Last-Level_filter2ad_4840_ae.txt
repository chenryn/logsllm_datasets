2 Duo, Intel i5 Sandy Bridge, and Intel i5 Ivy Bridge.
As in the attacks on Linux user interfaces, address space
layout randomization has been activated during both pro-
ﬁling and exploitation phase.
In an automated attack, we found cache activity upon
keypresses in different libraries with reasonable accu-
906  24th USENIX Security Symposium 
USENIX Association
10
racy. For instance, the Windows 7 common control li-
brary comctl32.dll can be used to detect keypresses
on different addresses. Probing 0xc5c40 results in cache
hits on every keypress and mouse click within text ﬁelds
accurately. Running the generated keypress logger in a
veriﬁcation period of 60 seconds with keyboard input by
a real user, we found only a single false positive event
detection based on this address. Address 0xc6c00 reacts
only on keypresses and not on mouse clicks, but yields
more false positive cache hits in general. Again, we can
apply the attack proposed by Zhang et al. [56] to recover
typed words from inter-keystroke timings.
We did not disassemble the shared library and there-
fore do not know which function or data accesses cause
the cache hit. The addresses were found by starting the
Cache Template Attack with the same parameters as on
Linux, but on a Windows shared library instead of a
Linux shared library. As modern operating systems like
Windows 7 and Windows 8.1 employ an immense num-
ber of shared libraries, we proﬁled only a few of these
libraries. Hence, further investigations might even re-
veal addresses for a more accurate identiﬁcation of key-
presses.
5.4 Attack on a T-table-based AES
Cache attacks have been shown to enable powerful at-
tacks against cryptographic implementations. Thus, ap-
propriate countermeasures have already been suggested
for the case of AES [15, 25, 30, 43]. Nevertheless, in or-
der to compare the presented approach of Cache Tem-
plate Attacks to related attacks, we launched an ef-
ﬁcient and automated access-driven attack against the
AES T-table implementation of OpenSSL 1.0.2, which
is known to be insecure and susceptible to cache attacks
[2, 4, 5, 16, 21, 22, 39, 53]. Recall that the T-tables are ac-
cessed according to the plaintext p and the secret key k,
i.e., Tj[pi ⊕ ki] with i ≡ j mod 4 and 0 ≤ i < 16, dur-
ing the ﬁrst round of the AES encryption. For the sake of
brevity, we omit the full details of an access-driven cache
attack against AES and refer the interested reader to the
work of Osvik et al. [39, 49].
Attack of Encryption Events.
In a ﬁrst step, we pro-
ﬁled the two events “no encryption” and “encryption
with random key and random plaintext”. We proﬁled
each cache-line-aligned address in the OpenSSL library
during 100 encryptions. On our test system, one encryp-
tion takes around 320 cycles, which is very fast compared
to a latency of at least 200 cycles caused by a single cache
miss. In order to make the results more deterministically
reproducible, we measure whether a cache line was used
only after the encryption has ﬁnished. Thus, the proﬁling
phase does not run in parallel and only one cache hit or
miss is measured per triggered event.
This proﬁling step takes less than 200 seconds. We
detected cache activity on 0.2%-0.3% of the addresses.
Only 82 addresses showed a signiﬁcant difference in
cache activity depending on the event. For 18 of these
addresses, the cache-hit ratio was 100% for the encryp-
tion event. Thus, our generated spy tool is able to accu-
rately detect whenever an encryption is performed.
For the remaining 64 addresses the cache-hit ratio was
around 92% for the encryption event. Thus, not each of
these addresses is accessed in every encryption, depend-
ing on key and plaintext. Since we attack a T-table-based
AES implementation, we know that these 64 addresses
must be the T-tables, which occupy 4 KB respectively 64
cache lines. Although this information is not used in the
ﬁrst generated spy tool, it encourages performing a sec-
ond attack to target speciﬁc key-byte values.
Attack on Speciﬁc Key-Byte Values. Exploiting the
knowledge that we attack a T-table implementation, we
enhance the attack by proﬁling over different key-byte
values for a ﬁxed plaintext, i.e., the set of events consists
of the different key-byte values. Our attack remains fully
automated, as we change only the values with which the
encryption is performed. The result is again a log ﬁle
containing the accurate timestamp of each event moni-
tored. The interpretation of the log ﬁle, of course, in-
volves manual work and is speciﬁc to the targeted events,
i.e., key bytes in this case.
For each key byte ki, we proﬁle only the upper 4 bits of
ki as the lower 4 bits cannot be distinguished because of
the cache-line size of 64 bytes. This means that we need
to proﬁle only 16 addresses for each key byte ki. Fur-
thermore, on average 92% of these addresses are already
in the cache and the Reload step of the Flush+Reload at-
tack is unlikely to trigger the prefetcher. Thus, we can
probe all addresses after a single encryption. Two pro-
ﬁles for different values of k0 are shown in Figure 5. The
two traces were generated using 1000 encryptions per
key byte and address to show the pattern more clearly.
According to Osvik et al. [39] and Spreitzer et al. [46]
these plots (or patterns) reveal at least the upper 4 bits of
a key byte and, hence, attacking the AES T-table imple-
mentation works as expected. In our case, experiments
showed that 1 to 10 encryptions per key byte are enough
to infer these upper 4 bits correctly.
In a T-table-based AES implementation, the index of
the T-table is determined by pi ⊕ ki. Therefore, the same
proﬁles can be generated by iterating over the different
plaintext byte values while encrypting with a ﬁxed key.
Osvik et al. [39] show a similar plot, generated using the
Evict+Time attack. However, in our attack the proﬁles
are aggregated into the Cache Template matrix, as de-
USENIX Association  
24th USENIX Security Symposium  907
11
ADDRESS
0
p
F
O
E
U
L
A
V
0
255
0
255
Figure 5: Excerpt of the Cache Template (address range
of the ﬁrst T-table). The plot is transposed to match [39].
In the left trace k0 = 0x00, in the right trace k0 = 0x51.
scribed in Section 3.1.
In the exploitation phase, the automatically generated
spy tool monitors cache hits on the addresses from the
Cache Template in order to determine secret key-byte
values. We perform encryptions using chosen plaintexts.
We attack the 16 key bytes ki sequentially. In each step
i = 0, . . . ,15, the plaintext is random, except for the up-
per 4 bits of pi, which are ﬁxed to the same chosen value
as in the proﬁling phase. Hence, the encryption is per-
formed over a chosen plaintext. The spy tool triggers an
encryption, detects when the encryption actually happens
and after each encryption, reports the set of possible val-
ues for the upper 4 bits of key byte ki. As soon as only
one candidate for the upper 4 bits of key byte ki remains,
we continue with the next key byte.
Using Cache Template Attacks, we are able to infer
64 bits of the secret key with only 16–160 encryptions in
a chosen-plaintext attack. Compared to the work of Os-
vik et al. [39] who require several hundred or thousands
encryptions (depending on the measurement approach)
targeting the L1 cache, and the work of Spreitzer and
Plos [46] who require millions of encryptions targeting
the L1 cache on the ARM platform, we clearly observe a
signiﬁcant performance improvement. More recent work
shows that full key recovery is possible with less than
30000 encryptions [17] using Flush+Reload.
The beneﬁt of our approach, compared to existing
cache attacks against AES, is that our attack is fully auto-
mated. Once the binary is deployed on the target system,
it performs both proﬁling and exploitation phase auto-
matically and ﬁnally returns a log ﬁle containing the key
byte candidates to the attacker. Moreover, we do not need
prior knowledge of the attacked system or the attacked
executable or library.
AES T-table implementations are already known to
be insecure and countermeasures have already been in-
tegrated, e.g., in the AES implementation of OpenSSL.
Performing our attack on a non-T-table implementation
(e.g., by employing AES-NI instructions) did not show
key dependent information leakage, but still, we can ac-
curately determine the start and end of the encryption
through the cache behavior. However, we leave it as an
interesting open issue to employ the presented approach
ADDRESS
of cache template attacks for further investigations of
vulnerabilities in already protected implementations.
Trace-Driven Attack on AES. When attacking an in-
secure implementation of a cryptographic algorithm, an
attacker can often gain signiﬁcantly more information if
it is possible to perform measurements during the en-
cryption [2, 13], i.e., in case the exact trace of cache hits
and cache misses can be observed. Even if we cannot in-
crease the frequency of the Flush+Reload attack, we are
able to slow down the encryption by constantly ﬂush-
ing the 18 addresses which showed cache activity in ev-
ery proﬁle. We managed to increase the encryption time
from 320 cycles to 16000–20000 cycles. Thus, a more
ﬁne-grained trace of cache hits and cache misses can be
obtained which might even allow the implementation of
trace-driven cache attacks purely in software.
6 Countermeasures
We have demonstrated in Section 5 that Cache Template
Attacks are applicable to real-world applications without
knowledge of the system or the application. Therefore,
we emphasize the need for research on effective coun-
termeasures against cache attacks.
In Section 6.1, we
discuss several countermeasures which have been pro-
posed so far. Subsequently, in Section 6.2, we discuss
how Cache Template Attacks can be employed by de-
velopers to detect and eliminate cache-based information
leakage and also by users to detect and prevent cache
attacks running actively on a system. Finally, in Sec-
tion 6.3, we propose changes to the prefetcher to build a
powerful countermeasure against cache attacks.
6.1 Discussion of Countermeasures
Removal of the clﬂush Instruction is not Effective.
The restriction of the clflush instruction has been sug-
gested as a possible countermeasure against cache at-
tacks in [54, 55, 58]. However, by adapting our spy tool
to evict the cache line without using the clflush in-
struction (Evict+Reload instead of Flush+Reload), we
demonstrate that this countermeasure is not effective at
all. Thereby, we show that cache attacks can be launched
successfully even without the clflush instruction.
Instead of using the clflush instruction, the eviction
is done by accessing physically congruent addresses in
a large array which is placed in large pages by the op-
erating system. In order to compute physically congru-
ent addresses we need to determine the lowest 18 bits of
the physical address to attack, which can then be used to
evict speciﬁc cache sets.
The actual mapping of virtual to physical addresses
can be retrieved from /proc/self/pagemap. Even if
908  24th USENIX Security Symposium 
USENIX Association
12
such a mapping is not available, methods to ﬁnd con-
gruent addresses have been developed—simultaneously
to this work—by Irazoqui et al. [20] by exploiting large
pages, Oren et al. [38] by exploiting timing differences
in JavaScript, and Liu et al. [32] by exploiting timing
differences in native code.
The removal of the clflush instruction has also been
discussed as a countermeasure to protect against DRAM
disturbance errors (denoted as rowhammer bug). These
disturbance errors have been studied by Kim et al. [27]
and, later on, exploited by Seaborn et al. [45] to gain ker-
nel privileges. Several researchers have already claimed
to be able to exploit the rowhammer bug without the
clflush instruction [14], This can be done by exploit-
ing the Sandy Bridge cache mapping function, which has
been reverse engineered by Hund et al. [18], to ﬁnd con-
gruent addresses.
Our eviction strategy only uses the lowest 18 bits and
therefore, we need more than 12 accesses to evict a cache
line. With 48 accessed addresses, we measured an evic-
tion rate close to 100%. For performance reasons we
use write accesses, as the CPU does not have to wait
for data fetches from the physical memory. In contrast
to the clflush instruction, which takes only 41 cycles,
our eviction function takes 325 cycles. This is still fast
enough for most Flush+Reload attacks.
While clflush always evicts the cache line, our evic-
tion rate is only near 100%. Therefore, false positive
cache hits occur if the line has not been evicted. Us-
ing Flush+Reload, there is a rather low probability for a
memory access on the monitored address to happen ex-
actly between the Reload step and the point where the
clflush takes effect. This probability is much higher
in the case of Evict+Reload, as the eviction step takes 8
times longer than the clflush instruction.
We compare the accuracy of Evict+Reload to
Flush+Reload using previously found cache vulnerabil-
ities. For instance, as described in Section 5.1, probing
address 0x7c800 of libgdk-3.so.0.1000.8 allows us
to detect keypresses on key n. The Flush+Reload spy
tool detects on average 98% of the keypresses on key n
with a 2% false positive rate (keypresses on other keys).
Using Evict+Reload, we still detect 90% of the key-
presses on key n with a 5% false positive rate. This
clearly shows that the restriction of clflush is not suf-
ﬁcient to prevent this type of cache attack.
Disable Cache-Line Sharing. One prerequisite of
Flush+Reload attacks is shared memory. In cloud sce-
narios, shared memory across virtual machine borders is
established through page deduplication. Page dedupli-
cation between virtual machines is commonly disabled
in order to prevent more coarse-grained attacks like ﬁn-
gerprinting operating systems and ﬁles [40, 47] as well
as Flush+Reload. Still, as shown by Irazoqui et al. [20],
it is possible to use Prime+Probe as a fallback. How-
ever, attacking low-frequency events like keypresses be-
comes infeasible, because Prime+Probe is signiﬁcantly
more susceptible to noise.
Flush+Reload can also be prevented on a system by