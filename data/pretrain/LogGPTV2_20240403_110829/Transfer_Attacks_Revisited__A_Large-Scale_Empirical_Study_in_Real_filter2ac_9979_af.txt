is FGSM
is BLB
is CW2
is LLC
is 13
is 16
is 19
is DEEPFOOL
is STEP LLC
is RFGSM
coef
0.1711
0.0101
0.1444
0.0240
0.0482
0.2016
-0.0006
-0.0157
-0.0207
0.1575
0.0749
0.0244
0.0006
0.0780
-0.0003
std err
0.018
0.018
0.018
0.018
0.019
0.019
0.019
0.019
0.019
0.019
0.019
0.019
0.013
0.013
0.013
p-value
0.000
0.570
0.000
0.177
0.014
0.000
0.977
0.421
0.288
0.000
0.000
0.210
0.960
0.000
0.983
statistically sufﬁcient. This result agrees with our hypothesis
that an appropriate surrogate complexity is better than lower
and higher complexity.
(ii) Experiments on VGG Surrogates
To make sure that this phenomenon is not restricted to
ResNet surrogates, we extend the result to VGG surrogates.
We use VGG-11, VGG-13, VGG-16 and VGG-19 as sur-
rogates and evaluate the transferability of the crafted AEs
on the MLaaS systems. These surrogates are obtained from
pretrained models and the raw dataset is used to ﬁne-tune
them, i.e., is pretrained is ﬁxed to True and is augmented
and is adversarial are ﬁxed to False.
Table V shows the result of OLS regression. The em-
phasized numbers in the table show that using VGG-13, 16
and 19 has a 0.0006, 0.078 and -0.0003 improvement in the
misclassiﬁcation rate respectively when compared to VGG-11.
By looking at the p-values, we observe that VGG-11 ≈ VGG-
13 ≈ VGG-19 <p<0.001 VGG-16, making VGG-16 a better
surrogate than its simpler and deeper versions. This result
shows that the phenomenon that a surrogate with appropriate
depth is better than other surrogates is not restricted to ResNet
surrogates but holds for VGG surrogates as well.
Observation 4. Surrogate complexity, deﬁned by the depth
of the surrogate, has a non-monotonic effect on the transfer-
ability. A surrogate with appropriate depth is better than both
simpler and deeper surrogates.
5) Joint Effect of Surrogate-Level Factors: Various factors
are included to train a surrogate model, i.e., surrogate dataset,
pretraining and the choice of surrogate depth. Therefore, their
interactions are of particular interest, since these factors affect
the attack via the surrogate as a whole.
Regression E and Regression J decompose the joint effect of
surrogate-level factors in Table III and Table IV, respectively.
Before we continue, some interpretation of regression E and
J should be explained to avoid misunderstanding of the result.
First, the indicator variable of the decomposed factor have
a different statistical interpretation when compared to other
regressions due to the joint terms included. For example, in
regression E and J, the coefﬁcient of is pretrained repre-
sents the inﬂuence of pretraining when ResNet-18 surrogate
is used without data enrichment. This is because the joint
effect is characterized by the joint terms while previously
the coefﬁcient is not conditioned on the choice of ResNet-
18 and the absence of data enrichment. Similar rules apply to
the coefﬁcients of is adversarial, is augmented and surrogate
depth factors. Second, a signiﬁcantly positive coefﬁcient of the
joint term does not necessarily mean that using them jointly is
good for transfer attack, vice versa. This is because the joint
terms should be added with the individual terms to characterize
the joint effect. For example, for the Regression E shown in
Table III, the coefﬁcient of is pre×adv is -0.003. To recover
the effect of the joint usage of pretraining and adversarial
training, we should add this term with is pretraining and
is adversarial, which is (-0.003) + (-0.014) + (+0.005) = -
0.012. Third, we cannot conclude that two factors are ap-
proximately independent, even though the joint term is not
signiﬁcant. Instead, this should be digested as that the joint
effect is not signiﬁcant enough to be observed.
i.e.,
if they show signiﬁcant
We only discuss joint terms with a signiﬁcantly non-zero
coefﬁcient. The ﬁrst interesting phenomenon is that almost
term has consistent effects on different kinds of
no joint
transfer attack,
improvement
on untargeted transfer attack,
then they almost always do
not show signiﬁcant improvement on targeted transfer attack.
This phenomenon further supports Observation 2 by showing
that pretraining is not
the only one that has this feature.
Second, the interaction between the surrogate-level factors is
extremely complex, as no common effect is observed in both
the Table III and Table IV. For example, in Table III we
observe signiﬁcantly negative coefﬁcient for is pre×aug on
the misclassiﬁcation rate. However, in Table IV this coefﬁcient
becomes insigniﬁcantly positive. Therefore, choosing a good
surrogate model actually needs trial and error, and is highly
task-speciﬁc.
Observation 5. The interaction between surrogate-level fac-
tors is highly chaotic and task-speciﬁc. Training a good
surrogate needs trial and error.
6) Importance of Different Factors: We have discussed the
effect of many factors, but we still want
to know which
factor contributes the most to the transferability of AEs. The
contribution of factors can be measured by the changes of R2
when the factors are included.6
By comparing the ∆R2 of hierarchical regressions in Table
III and Table IV, we can see the most important factors are
the platform factors and the adversarial algorithm factors,
with a ∆R2 ranging from 0.150 to 0.645 and from 0.136 to
0.340, respectively. This means that attackers beneﬁt the most
from setting a good target platform and a good adversarial
algorithm. While the target platform is predetermined, the best
improvement for the attack is to choose an appropriate attack
algorithm, e.g., FGSM.
Observation 6. Among all the discussed factors, the easiest
and most beneﬁcial practice to improve a transfer attack is to
apply an appropriate adversarial algorithm, e.g., FGSM.
6R2 is a statistic that measures the ratio of model’s explained variance to
the total variance. When additional independent variables are included in a
linear regression, ∆R2 measures the contribution of additional variables.
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:56:58 UTC from IEEE Xplore.  Restrictions apply. 
1432
Figure 5: The transfer attack results grouped by surrogate
architectures and attack algorithms. The result of each bar is
averaged on the four platforms.
(a) L2 norm
(b) L∞ norm
Figure 6: The L2 and L∞ norm of perturbation for AEs.
7) Surrogate Architecture Factors: We have completed the
OLS analysis of transfer attack in the image classiﬁcation
and the gender classiﬁcation,
leaving an important factor
behind: the impact of surrogate architecture. Figure 5 plots
metrics against adversarial algorithms grouped by surrogate
architectures. Unlike the conclusion from Su et al. [41] that
AEs crafted from most surrogates only transfer in their own
surrogate family except VGG, we can see from Figure 5 that
no dominant architecture exists in the real scenario. The result
suggests surrogate families other than VGG worth attention in
the real transfer attack as well.
Observation 7. No dominant architecture family is found in
the real transfer attack.
B. Sample Property Factors
In this section, we dive deeper into the correlations between
transferability and sample-level properties. Speciﬁcally, we
study the following three properties: the norm of adversarial
perturbation, the adversarial conﬁdence (e.g., κ in CW attack
[12]) and the intrinsic classiﬁcation hardness of seed images.
1) Connection Between Transferability and the Norm of the
Adversarial Perturbation: So far, relaxing the perturbation
norm budget of adversarial attacks has been believed to be
a general method to increase transferability. We ﬁnd this
conclusion still holds in the real setting, hence we aim to
provide an answer for a deeper question: does the type of
norm matter in deciding transferability?
Figure 6 plots the average norm of the adversarial per-
turbations generated by each attack algorithm in the image
classiﬁcation task. It is interesting to notice that the order
of adversarial algorithms in terms of L2 norm in Figure 6a
is roughly aligned to the order in terms of misclassiﬁcation
Figure 7: The correlation of norm and transferability.
rate shown in Section V-A3. Figure 7 further computes the
correlation matrix between transferability metrics and norms,
from which we observe the correlation between L2 norm
and misclassiﬁcation rate is extremely high, exceeding 0.8.
The correlation between L∞ and misclassiﬁcation rate is far
weaker, up to 0.41. In fact, we prove in Appendix X-E that
even this correlation is largely due to the dependence of
L∞ on L2 norm. This ﬁnding motivates us to hypothesize
that a perturbation with larger L2 norm and ﬁxed L∞ norm
improves transferability. As a validation of this hypothesis, we
repeat to generate perturbations sampled from set {−0.1, 0.1}d
randomly and stop until either an adversarial perturbation that
deceives the surrogate is found or a maximum iteration, 1000
times, is reached. In this way, we get adversarial perturbation
with the largest L2 norm while keeping the L∞ norm ﬁxed
at 0.1. These AEs, though unaware of the explicit gradient
information, achieve an average misclassiﬁcation rate of 39.1%
on Google, 16.5% on AWS, 25.4% on Aliyun and 36.7%
on Baidu, respectively, which is higher than many attack
algorithms with the same L∞ norm budget. On the contrary,
AEs with large L∞ norm of perturbations but small L2
norm, such as those generated by BLB and CW, only have
trivial transferability as shown in Section V-A3. Therefore,
we conclude that transfer attacks are closely related to the L2
norm of the adversarial perturbation but not the L∞ norm,
although human vision systems are believed to be insensitive
to L2 norms [51].
Observation 8. The transferability of the AEs is very closely
related to the L2 norm of the perturbation but not the L∞
norm ﬁxed
norm. Increasing the L2 norm while keeping L∞
can increase the transferability of the AEs.
2) Connection between Transferability and the Adversarial
Conﬁdence: Some attacks are given the ability to control
adversarial conﬁdence deﬁned in many ways, one of which is
the κ value, the logit gap between the adversarial class and the
second most likely class. Su et al. [41] empirically found that
imposing a stricter κ constraint on CW attack slightly increases
transferability on untargeted attacks. However, this measure-
ment of adversarial conﬁdence is scaling-sensitive because the
κ value scales if all parameters of the ReLU network is scaled,
which is undesired because ReLU network is scaling-invariant.
A straightforward extension of the κ value is to compute the
softmaxed logit gap between the adversarial class and the
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:56:58 UTC from IEEE Xplore.  Restrictions apply. 
1433
BL-BFGSCW2DEEPFOOLLLCSTEP_LLCPGDFGSMRFGSMUAP0.000.020.040.060.08VGG-16ResNet-18Inception V30.00.2misclassification rate0.00.1matching rateBLBCW2DEEPFOOLLLCSTEP_LLCPGDFGSMRFGSMUAP0.00.1F2M rateBLBCW2DEEPFOOLLLCSTEP_LLCPGDFGSMRFGSMUAP0.00.2M2F rate0204060800.00.10.20.3024680.0000.0250.0500.0750.1000.1250.150BL-BFGSCW2DEEPFOOLLLCSTEP_LLCPGDFGSMRFGSMUAP1.000.510.90-0.410.511.000.39-0.280.900.391.00-0.40-0.41-0.28-0.401.00aliyun−0.50.00.51.01.000.510.890.090.511.000.410.050.890.411.00-0.030.090.05-0.031.00baidu−0.50.00.51.0L2L∞mismatchL2L∞mismatch1.000.510.830.410.511.000.360.190.830.361.000.280.410.190.281.00google−0.50.00.51.01.000.510.820.010.511.000.35-0.030.820.351.00-0.160.01-0.03-0.161.00aws−0.50.00.51.0Figure 8: P (success | κ) across platforms when κ is SSK and
SIK, respectively. Both ﬁgures are scaled by a constant factor
P (success). While all platforms show more vulnerability to
a larger SIK, platforms except for Baidu do not show clear
vulnerability to a large SSK.
Table VI: Linear regression results for SSK and SIK respec-
tively. Adjusted R-squared are 0.653 for SSK regression and
0.821 for SIK regression. SSK and SIK are discretized as
Figure 8 and revalued from one to ﬁve. For each entry, the
upper is the result of SSK regression and the lower is of SIK
regression.
(b) CW on AWS
(c) CW on Baidu
(a) Number of AEs
Figure 9: The misclassiﬁcation rate for CW attack with dif-
ferent κ thresholds, measured on AWS and Baidu using four
different surrogates. The number of AEs drops because we
use a ﬁxed iteration budget, but for large kappa this budget no
longer guarantees an adversarial perturbation.
IV
coefﬁcient
is Alibaba
p-value
0.003∗∗∗
0.050∗∗
0.000∗∗∗
0.000∗∗∗
0.117
0.482
0.303
0.002∗∗∗
SSK / SIK
∗p < .1, ∗∗p < .05, ∗∗∗p < .01.
0.065
0.019
0.112
0.049
0.030
-0.006
0.005
0.010
is Baidu
is AWS
5% interval
[0.026,0.103]
[0.000,0.039]
[0.073,0.150]
[0.030, 0.068]
[-0.009,0.068]
[-0.026,0.013]
[-0.005,0.015]
[0.004,0.014]
second most likely class, called Scaling-Insensitive κ (SIK) in
this paper. By deﬁnition, scaling the logit will cause a much
smaller change on SIK than SSK. The original κ value is thus
renamed Scaling-Sensitive κ (SSK). For ease of understanding,
SIK and SSK are mentioned collectively as κ . To make AEs
crafted from different algorithms and surrogates comparable,
we measure SSK and SIK by direct calculation for all AEs.
Then we divide them into two groups based on whether the
AE successfully fools the cloud. Invoking the Bayesian rule:
P (success | κ) = P (success)× P (κ | success)/P (κ) ∝ P (κ |
success)/P (κ), we can see that the change in transfer success
rate is proportional to the change in P (κ | success)/P (κ), a
metric easier to compute.
Figure 8 plots P (κ | success)/P (κ) for SSK and SIK. It
indicates that the conclusion from Su et al. [41] does not
generalize as Aliyun and AWS do not show higher vulnerabil-
ity to larger SSK. However, Figure 8 shows transferability of
AEs is nearly linear to SIK. This suggests that the conclusion
from Su et al. [41] is only a special case of a more general
property. They might get their conclusion because increasing
SSK probably leads to a larger SIK. We further run a linear
regression to quantify the impact, shown in Table VI. The
result shows P (SSK |
success)/P (SSK) is not strongly
explained by SSK (p = 0.303), but P (SIK | success)/P (SIK)
strongly depends on SIK (p = 0.002). Therefore, we conclude