title:Montage: A Neural Network Language Model-Guided JavaScript Engine
Fuzzer
author:Suyoung Lee and
HyungSeok Han and
Sang Kil Cha and
Sooel Son
Montage: A Neural Network Language 
Model-Guided JavaScript Engine Fuzzer
Suyoung Lee, HyungSeok Han, Sang Kil Cha, and Sooel Son, KAIST
https://www.usenix.org/conference/usenixsecurity20/presentation/lee-suyoung
This paper is included in the Proceedings of the 29th USENIX Security Symposium.August 12–14, 2020978-1-939133-17-5Open access to the Proceedings of the 29th USENIX Security Symposium is sponsored by USENIX.Montage: A Neural Network Language Model-Guided
JavaScript Engine Fuzzer
Suyoung Lee, HyungSeok Han, Sang Kil Cha, Sooel Son
School of Computing, KAIST
Abstract
JavaScript (JS) engine vulnerabilities pose signiﬁcant security
threats affecting billions of web browsers. While fuzzing is
a prevalent technique for ﬁnding such vulnerabilities, there
have been few studies that leverage the recent advances in
neural network language models (NNLMs). In this paper, we
present Montage, the ﬁrst NNLM-guided fuzzer for ﬁnding JS
engine vulnerabilities. The key aspect of our technique is to
transform a JS abstract syntax tree (AST) into a sequence of
AST subtrees that can directly train prevailing NNLMs. We
demonstrate that Montage is capable of generating valid JS
tests, and show that it outperforms previous studies in terms
of ﬁnding vulnerabilities. Montage found 37 real-world bugs,
including three CVEs, in the latest JS engines, demonstrating
its efﬁcacy in ﬁnding JS engine bugs.
1 Introduction
The memory safety of web browsers has emerged as a critical
attack vector as they have become an integral part of every-
day computing. Malicious websites, which conduct drive-
by download attacks [48], have typically exploited memory
corruption vulnerabilities of web browsers. Currently, an ex-
ploitable memory corruption vulnerability for a browser can
cost 100,000 USD and sell for a million dollars if it is chained
with a kernel exploit to remotely jailbreak iOS [59].
Among many components of web browsers, a JavaScript
(JS) engine is of particular interest to attackers as its Turing-
complete nature enables attackers to craft sophisticated ex-
ploits. One can easily allocate a series of heap chunks to
perform heap spraying [49], write functions in JS to abstract
away some exploitation logic [26], and even bypass the miti-
gation used in modern web browsers [35]. According to the
National Vulnerability Database (NVD), 43% of the total vul-
nerabilities reported for Microsoft Edge and Google Chrome
in 2017 were JS engine vulnerabilities.
Despite the increasing attention, there has been relatively
little academic research on analyzing JS engine vulnerabilities
compared to other studies seeking to ﬁnd them [18, 24, 54].
LangFuzz [24] combines code fragments extracted from JS
seed ﬁles to generate JS test inputs. GramFuzz and IFuzzer
employ more or less the same approach [18, 54], but IFuzzer
uses evolutionary guidance to improve the fuzzing effective-
ness with genetic programming based on the feedback ob-
tained by executing a target JS engine with produced inputs.
However, none of the existing approaches consider the re-
lationship between code fragments for generating test inputs.
In other words, they produce test inputs by simply combin-
ing fragments as long as JS grammars allow it. Thus, they
do not determine which combination is likely to reveal vul-
nerabilities from the target JS engine. Are there any similar
patterns between JS test inputs that trigger JS engine vulnera-
bilities? If so, can we leverage such patterns to drive fuzzers
to ﬁnd security vulnerabilities? These are the key questions
that motivated our research.
We performed a preliminary study on JS engine vulnera-
bilities and observed two patterns. We observed that a new
security problem often arises from JS engine ﬁles that have
been patched for a different bug. We analyzed 50 CVEs as-
signed to ChakraCore, a JS engine used by Microsoft Edge.
We found that 18% and 14% of the vulnerabilities were related
to GlobOpt.cpp and JavascriptArray.cpp, respectively.
The second observation was that JS test code that triggers
new security vulnerabilities is often composed of code frag-
ments that already exist in regression tests. We collected 2,038
unique JS ﬁles from the ChakraCore regression test suite and
67 JS ﬁles that invoked the analyzed vulnerabilities. These
two sets of ﬁles were disjoint. We sliced the AST of each
JS ﬁle into AST subtrees of depth one, called fragments. We
then computed the number of overlapping fragments between
the two sets; we found that 95.9% of the fragments extracted
from the 67 vulnerability-triggering JS ﬁles overlapped with
the fragments extracted from the regression test suite (see §3).
Given these two observations, how do we perform fuzz
testing to ﬁnd JS engine vulnerabilities? For this research
question, we propose the ﬁrst approach that leverages a neu-
ral network language model (NNLM) to conduct fuzz testing
USENIX Association
29th USENIX Security Symposium    2613
ARTIFACTEVALUATEDPASSEDon a target JS engine. Our key idea is to mutate a given regres-
sion JS test by replacing its partial code with new code that
the NNLM creates. Consider a regression JS test that invokes
a patched functionality. We generate a JS test from this re-
gression test while expecting to elicit a new potential bug that
resides in the patched JS engine ﬁles, thus addressing the ﬁrst
observation. We also assemble existing code from regression
test suites under the guidance of the NNLM when composing
new partial code. This captures the second observation.
To manifest this idea, we designed and implemented Mon-
tage, a system for ﬁnding security vulnerabilities in JS en-
gines. The system starts by transforming the AST of each
JS test from a given regression test suite into the sequence
of fragments. These fragment sequences become training
instances over which the NNLM is trained. Therefore, the
NNLM learns the relationships between fragments. Montage
mutates a given JS test by reconstructing one of its subtrees
as the trained NNLM guides.
Previous research focused on learning the relationships
between PDF objects [16], characters [11, 32], and lexical
tokens in the source code [22,40,43]. These language models
addressed completing incorrect or missing tokens [40, 53], or
assembling PDF objects [16]. Their methods are not directly
applicable to generating valid JS tests, which requires model-
ing structural control ﬂows and semantic data dependencies
among JS lexical tokens. Liu et al. [32] stated their limitation
in extracting general patterns from character-level training
instances from C code, thus generating spurious tests.
Unlike these previous studies [11, 16], Montage uses frag-
ments as building blocks. Each fragment encapsulates the
structural relationships among nodes within an AST unit tree.
The model is then trained to learn the relationships between
such AST unit trees. Montage uses this model to assemble
unit subtrees when mutating a given regression JS test. Thus,
each generated JS test reﬂects the syntactic and semantic
commonalities that exist in the regression test suite.
We evaluated Montage to ﬁnd bugs in ChakraCore 1.4.1
and compared the number of found bugs against CodeAl-
chemist [20], jsfunfuzz [38], and IFuzzer [54]. We performed
ﬁve fuzzing campaigns; each round ran for 72 hours. Mon-
tage found 133 bugs, including 15 security bugs. Among the
found security bugs, Montage reported 9, 12, and 12 bugs that
CodeAlchemist, jsfunfuzz, and IFuzzer did not ﬁnd, respec-
tively. This result demonstrates that Montage is able to ﬁnd
bugs that the state-of-the-art JS fuzzers are unable to ﬁnd.
We measured the efﬁcacy of the Montage language model
against the random selection method with no language model,
Markov-chain model, and the character/token-level recurrent
neural network language model. Montage outperformed the
other approaches in terms of ﬁnding unique bugs.
We further tested Montage to fuzz the latest versions of
ChakraCore, JavaScriptCore, SpiderMonkey, and V8. Mon-
tage found 37 unique bugs, including three security bugs.
34 bugs were found from ChakraCore. The remaining two
and one bugs were from JavaScriptCore and V8, respectively.
Of these three security bugs, Montage discovered one from
JavaScriptCore and the other two from ChakraCore. These
results demonstrate the effectiveness of leveraging NNLMs
in ﬁnding real-world JS engine bugs.
2 Background
2.1 Language Model
A language model is a probability distribution over sequences
of words. It is essential for natural language processing (NLP)
tasks, such as speech recognition, machine translation, and
text generation. Traditionally, language models estimate the
likelihood of a word sequence given its occurrence history in
a training set.
An n-gram language model [8, 30] approximates this prob-
ability based on the occurrence history of the preceding n− 1
words. Unfortunately, such count-based language models in-
herently suffer from the data sparsity problem [8], which
causes them to yield poor predictions. The problem is mainly
due to insufﬁcient representative training instances. NNLMs
address the data sparsity problem by representing words as a
distributed vector representation, which is often called a word
embedding, and using it as input into a neural network.
Bengio et al. [3] introduced the ﬁrst NNLM, a feed-forward
neural network (FNN) model. An FNN predicts the next word
based on its preceding n− 1 words, which is called a history
or a context where n is a hyper parameter that represents the
size of the word sequence [1,3,17]. In this NNLM setting, all
words in a training set constitute a vocabulary V . Each word
in V is mapped onto a feature vector. Therefore, a context, a
word sequence, becomes the concatenation of each feature
vector corresponding to its word. The model is then trained
to output a conditional probability distribution of words in V
for the next word from a given context.
Long short-term memory (LSTM). Unlike FNN language
models, a recurrent neural network (RNN) is capable of pre-
dicting the next word from a history of preceding words of an
arbitrary length because an RNN is capable of accumulating
information over a long history of words. An LSTM model is
a special kind of RNN; it is designed to capture long-term de-
pendencies between words [14, 23]. Because a standard RNN
suffers from the gradient vanishing/exploding problem [4],
an LSTM model uses neural layers called gates to regulate
information propagation and internal memory to update its
training parameters over multiple time steps.
JS Engine Fuzzing
2.2
Fuzz testing is a form of dynamic software testing in which
the program under test runs repeatedly with test inputs in
order to discover bugs in the program. Fuzzing can be catego-
rized into two types based on their input generation method-
2614    29th USENIX Security Symposium
USENIX Association
ology [50]: mutational fuzzing and generational fuzzing. Mu-
tational fuzzing [7, 44, 57, 58] alters given seeds to generate
new test inputs, whereas generational fuzzing [19, 20, 24, 38]
produces tests based on an input model, such as a grammar.
Since JS code is highly structured, randomly generated test
inputs are likely to be rejected by JS engines. Therefore, it
is common for JS engine fuzzers to employ a generational
approach. One notable example is jsfunfuzz, a seminal JS
engine fuzzer [38, 45]. It starts with a start symbol deﬁned
in a JS grammar and selects the next potential production in
a random fashion until there are no remaining non-terminal
symbols. CodeAlchemist [20] is another generational fuzzer
that resort to the assembly constraints of its building blocks
called code bricks to produce semantically valid JS code.
Most other JS engine fuzzers use both mutational and gen-
erational approaches. LangFuzz [24], GramFuzz [18], and
IFuzzer [54] parse JS seeds with the JS grammar and con-
struct a pool of code fragments, where a code fragment is a
subtree of an AST. They combine code fragments in the pool
to produce a new JS test input, but they also mutate given
seeds to generate test inputs.
Although it does not aim to ﬁnd security vulnerabilities,
TreeFuzz [41] leverages a probabilistic context-free grammar
(PCFG) to generate a test suite from given seeds. Similarly,
Skyﬁre [56] infers a probabilistic context-sensitive grammar
(PCSG) from given seeds and uses it to generate a well-
distributed set of seeds. Both approaches apply probabilistic
language models to generate JS testing inputs, but their design
is too generic to ﬁnd security vulnerabilities in JS engines. Un-
like previous approaches, Montage is inspired by a systematic
study of CVEs, i.e., previous JS engine vulnerabilities, and
leverages an NNLM trained to learn syntactic and semantic
commonalities between JS regression test suites.
3 Motivation
Can we ﬁnd similarities between JS ﬁles that trigger secu-
rity vulnerabilities? We answer this question by conducting
a quantitative study of analyzing reported CVEs and corre-
sponding proof of concept (PoC) exploits for ChakraCore [10].
We chose ChakraCore because its GitHub repository main-
tains well-documented commit logs describing whether a
speciﬁc CVE is patched by a commit. This helps us identify
which security vulnerability is related to a given PoC exploit
and which source lines are affected by the vulnerability. Other
JS engines, in contrast, have not provided an exact mapping
between a code commit and a CVE.
Note that collecting PoC exploits is not straightforward be-
cause CVE reports typically do not carry any PoC exploits due
to the potential risk of being abused. We manually collected
CVEs as well as their PoC code from exploitDB, vulnera-
bility blogs, and the ChakraCore GitHub repository. In total,
we obtained 67 PoC exploits, each of which corresponds to
a unique CVE. We further identiﬁed 50 of them where the
corresponding vulnerabilities are ﬁxed by a single commit.
This means that we can map each of the 50 vulnerabilities
to a set of affected source ﬁles. The earliest and the latest
vulnerabilities in the collected set were patched in September
2016 and March 2018, respectively. In total, 77 ﬁles were
patched owing to these vulnerabilities.
We found that nine out of the 50 vulnerabilities (18%) are
related to the GlobOpt.cpp ﬁle, which mainly implements
the just-in-time (JIT) compilation step. Seven of them (14%)
have also contributed to patching the JavascriptArray.cpp
ﬁle. Note that each ﬁle implements different functionalities of
ChakraCore. In other words, different JS engine vulnerabili-
ties often arise from a common ﬁle that implements the same
functionalities, such as JIT optimization and JS arrays. For
example, a patch for CVE-2018-0776 forces a deep copy of an
array when the array is accessed via the function arguments
property within a callee, thus avoiding a type confusion vul-
nerability. However, the patch was incomplete, still leaving
other ways in which a shallow copy of arrays could be caused.
CVE-2018-0933 and CVE-2018-0934 were assigned to those
bugs. Note that all the patches revised the BoxStackInstance
function in the JavascriptArray.cpp ﬁle.
Among the 77 patched ﬁles, 26 (33.8%) ﬁles are patched
at least twice due to the reported CVEs. These examples
demonstrate that JS engine vulnerabilities often arise from
ﬁles that were patched for other bugs. Considering that these
patches are often checked with regression tests, mutating an
existing JS test may trigger a new vulnerability whose root
cause lies in the patched ﬁles that this test already covered.
Observation 1. JS engine vulnerabilities often arise from
the same ﬁle patched for different bugs.
We also measured the syntactic similarity between JS code
from the PoC exploits and 2,038 JS ﬁles obtained from re-
gression test suites maintained by ChakraCore. Note that a
regression test suite consists of JS tests that trigger previously
patched bugs and check expected outcomes with adversarial
test input. In particular, we gathered the regression test ﬁles
from the ChakraCore version released in August 2016, which
is one month ahead of the patching date of the earliest vulner-
ability. Therefore, the regression test ﬁles were not affected
by any of the studied vulnerabilities.
1
2
3
4
var v0 = {};
for ( var v1 = 0; v1 < 5; v1 ++) {
v0 [ v1 ] = v1 + 5;
}
Figure 1: Example of a normalized JS ﬁle.
To measure the similarity, we normalized the identiﬁers in
the regression test ﬁles as well as the PoC exploits. Speciﬁ-
cally, we renamed each identiﬁer for variables and functions
to have a sequential number and a common preﬁx as their
name. We then parsed the normalized JS ﬁles down to ASTs.
We extracted a set of unit subtrees with a depth of one
USENIX Association
29th USENIX Security Symposium    2615
Figure 2: Fragmentizing an AST from the example in Fig-
ure 1.
from each AST. For a given AST, we extracted a unit subtree
from each internal node. Thus, the number of extracted unit
subtrees becomes the number of AST internal nodes. We call
such a unit subtree a fragment, as formally deﬁned in §5. Note
that the root node of each fragment is an internal node of the
AST. It also corresponds to a leaf node in another fragment,
except the fragment with the root node of the original AST.
Figure 2 illustrates the fragmentation results for a JS ﬁle
listed in Figure 1. The upper side of the ﬁgure shows an AST
subtree obtained from the Esprima JS parser [21]. This subtree