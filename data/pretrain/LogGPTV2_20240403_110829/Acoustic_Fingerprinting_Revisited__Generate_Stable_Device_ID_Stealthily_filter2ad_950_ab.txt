driver. Products from the lower-end speaker market, like those used
in our phones, usually have only one driver. Manufactures are ca-
pable to control the quality of their product in only a narrow fre-
quency range, while quality outside the important frequency range
is less concerned for some reasons.
00.20.40.60.81−1−0.500.51time−field stimulationTime(s)00.511.522.5x 1040100200300400Spectrum of the stimulationFrequency(Hz)431Firstly, the important frequency range covers most of human’s
sensitive frequency range, and we are not sensitive to the left fre-
quency range, which leads the quality control outside the main fre-
quency range to be less meaningful.
Secondly, compensating the quality costs a lot, which will in-
crease the overall costs and decrease the competitiveness of the
manufactures in terms of price. For example, adding an indepen-
dent high frequency driver enhances the quality sharply, but it in-
creases the cost multiple times. So phones in the market are often
equipped with only one speaker driver.
As a result, manufactures control the sensitive range quality and
neglect the insensitive frequency range.
Frequency response presents the quality of a speaker from the
perspective of frequency by reﬂecting the gain or attenuation the
speaker provide at each frequency point. Thus, it is easy to con-
clude that the ﬂatter the response curve is, the better voice quality
it will provide. Figure 4, captured from the Internet [5], presents
the frequency response of three speakers, which shows that: at low
frequency segment, they have similar response curves, while, at
high frequency segment, their response curves are different from
each other dramatically. Not only the differences between different
models of speakers but also the variances between the same model
are huge.
Figure 4: Frequency response of 3 speakers.
Both theoretical analysis and experimental result, which will be
shown in the evaluation section, drive us to decide to use the high
frequency range response feature, as it carries high variations among
each speaker individuals.
3.2.3 Be Robust with Controlled Stimulus Patterns
The sampling data collected by many previous work is just the
result of uncontrolled input stimulus. For example, in [21], the
accelerometer readings are stimulated by random user movement.
In [19], even though the music played could be controlled, but the
frequency component combinations and variations are determined
by the stimulation as well as the abundant noise permutated in the
environment. Due to the non-linear features of speakers, like inter-
modulations [18], the recorded sound may contain lots of noises
that would make the result unstable.
In contrast, we propose to use a controlled audio wave pattern to
drive the speaker, so that the results will be more robust to random
and non-linear factors, and less vulnerable to noises. The stimula-
tion is shown in Figure 2.
The stimulation lies in a frequency range that interfered only
little by the environment. As the spectrum of noise in different
environment will be shown in Figure. 12, we found the silent en-
vironment in high frequency band provides a perfect test bed for
measuring the frequency response of the speaker. It is just the less-
interfered environment, controlled stimulation that brought robust-
ness to the scheme.
4. DESIGN
In this section, we will introduce how the scheme works. Specif-
ically, how it generates inaudible stimulation stealthily, calculates
frequency response and searches the feature in the database.
4.1 Stimulation Generation
In our scheme, the android phone itself generates appropriate
acoustic signal by playing a period of synthetic sound as the stim-
ulation and itself collects the response from the microphone. Com-
paring with the passive generation, where the response is highly
affected by the stimulation provider, active one, in fact, provides
plain, pure and noise-less response resulted from a self-controlled
stimulation.
We didn’t use a wave with continuous ﬂat frequency band be-
cause the power of the signal is constrained resulted from a very
high PAPR (Peak to Average Power Ratio) in that case. We also
didn’t adopt a frequency shifted music, because the combinations
of complex frequency make the output unstable resulted from the
non-linearity attribute of the speaker. Instead, we adopted the stim-
ulation shown in ﬁgure. 2. It is consisted of a series of cosine wave
from 14 kHz to 21 kHz with 100 Hz gap between neighbor fre-
quency points. In order to play the high frequency sound, we set
the sample rate of the PCM format input of the android API at
44100 Hz.
4.2 Frequency Response Generation
A simple frequency response measuring scheme is adopted. Pro-
fessionals often use DAAS(Digital Audio Analysis Software) to get
precise result of the frequency response curve of the speaker. How-
ever, acquiring the response feature is infeasible if the phone should
be tested in a noise blocked room by an instrument and without
phone users’ awareness. Therefore, the microphone of the phone
itself is adopted to collect the acoustic signal broadcasted by the
speaker, though the noise introduced in this way is obviously more
than that in a professional way.
Speciﬁcally, to get the frequency response, we use the spectrum
of recording divided by the spectrum of stimulation. The spec-
trum of recording is calculated by the FFT. The process of being
divided by the stimulation can be neglected since the magnitude of
the stimulation at each effective frequency point is constant and the
response will be normalized later.
Considering the response feature, at the effective point, the fre-
quency response is calculated with interference of noise brought
by the environment, while at the point in the gap between effec-
tive points, the response is meaningless because only noise exists.
Therefore, only effective points are counted when producing the
feature. Besides, in each point, the phase can be neglected compar-
ing with the signiﬁcance of aptitude. Therefore, we only calculate
magnitude instead of considering the complex number.
To save communication bandwidth and storage, in this scheme,
only magnitudes of 71 effective frequency points are counted, and it
is not the truth that the more points are sampled, the higher entropy
will be accumulated, because the power of the stimulation will be
allocated to each frequency point, where insufﬁcient power leads to
insufﬁcient SNR (signal noise ratio) and an unstable curve thereby.
4324.3 Feature Matching
The frequency response can be presented as a curve that can be
discretized to some points, thus, a vector. Matching two devices
is equivalent to matching the two curves, hence, the vectors the
two devices owned. To judge if the two vectors come from the
same device, the proof is their similarity. The more similar the two
vectors are, the more possible that they come from the same device.
Mathematically, the distance between two vectors can be utilized to
weight the similarity between two vectors. The shorter the distance
is, the more similar they will be. Once the newly received feature
is close enough to some existed feature in the database, they will
be judged as produced by that device. Otherwise, a new proﬁle will
be set up for the new comer.
In the experiment phase, we just use the brute force algorithm
to get the most similar feature vector met before and judge if the
distance between them reached a predeﬁned threshold(an experi-
mental value 0.7 is set in the experiment phase) to tell if it is a new
user or it is just the user the most similar vector represents. Be-
cause ultra-large scale data has not been collected and searched,
this scheme runs pretty fast. In fact, with the expansion of the scale
of the data, matching users one by one becomes time wasting and
infeasible. But this never masks the fact that the ﬂoat vector can be
easily fuzzy searched using Locality Sensitive Hashing or k-NN al-
gorithm. In that case, the searching time complexity can be reduced
to nearly a constant. [24, 44, 37]
5. EVALUATION
As a practical and feasible ﬁngerprint, the scheme should be in-
spected in some aspects. For example, ﬁngerprint should be stable
as it changes little from time to time, reminding us to check the sta-
bility of the frequency response. This section shows our test results
to answer the following questions:
• Performance Can the scheme be applied to large scale user
tracking? Speciﬁcally, can a large amount of users be distin-
guished from each other?
• Stability How stable is the response curve? Is it feasible for
long term user tracking?
• Interference How does the noise in different environment in-
terfere the performance of the scheme?
5.1 Experiment Setting
5.1.1 Experiment Devices
The evaluation starts with a small scale experiment among 8
smartphones of different models. And the result shows that they
can be distinguished with huge differences. Previous work [19]
presents a similar argument. Thus, it is proper to focus on distin-
guishing phones of the same model. So, we investigate the result
of a large scale experiment with phones of the same model.
To prove that phones can be distinguished by only speakers, we
designed an experiment bed to emulate multiple phones, among
which the only difference is speaker. We conduct the experiments
on 50 OEM speakers on a single Samsung Galaxy S3. We mod-
iﬁed the Galaxy S3 by converting the soldered speaker interface
into a pluggable socket, as shown in Figure 5, then we purchased
50 OEM (Original Equipment Manufacturer) speakers which came
from the same assembly line and have continuous Serial Numbers.
These speakers were soldered with two-pin plugs, so that they can
be easily connected to the phone.
The difference between phones is even larger than the difference
between speakers. The difference between phones is the product of
Figure 5: Experiment Equipment.
all differences of their corresponding subsystems. Components be-
sides speaker, like DAC, chasis also contribute to the overall differ-
ence. For example, the chasis is a sound ampliﬁer with distortion.
Different chasises may distort the sound in a tiny different way.
However most of the difference is contributed by speaker, because
it is a mechanical and kinetic component where quality control is
more difﬁcult. Therefore, we regard the difference between speak-
ers as the difference between phones in the following part.
To each emulated phone, 60 sets of response feature were col-
lected for further evaluation. Thus, totally 3000 vectors have been
collected.
5.1.2 Experiment Environment
To study the scheme justiﬁedly, the experiment is conducted in
the normal ofﬁce environment with normal noise level except the
interference part. During the experiment, the noise level changes
from 50 db to 70 db, that mixed with normal conversation to emu-
late a real ofﬁce environment. The volume of the phone is set at 5
out of 7.
5.2 Metrics
The metrics listed are used to evaluate the scheme:
• Feature Distance Since the feature is actually a vector in N-
space, we simply deﬁne the feature distance as the Euclidian
distance in N-space listed below:
(cid:118)(cid:117)(cid:117)(cid:116) N(cid:88)
d(p, q) =
(qi − pi)2
i=0
where p and q are two feature vectors deﬁned as:
p = (p0, p1,··· , pN−1), q = (q0, q1,··· , qN−1)
• Similarity We use similarity to measure how likely the two
features p, q are coming from the same phone, and it is de-
ﬁned as
1 − d(p, q)
• False Positive We deﬁne a case as false positive if phone A
is falsely recognized as another phone B based on the input
features.
• False Negative We deﬁne a case as false Negative if no matches
can be found in the database for features from phone A that
actually does exist in the database.
433the type that ﬁts the observations well. Totally 20 continuous dis-
tribution types were tested. After analyzing the ﬁtness, we found
that the 2 types of distance derived from observations to feature
vectors from either the same phones or different phone pairs fall
into Lognormal Distribution well. The ﬁtted distribution is shown
in Figure. 7.
• Entropy The logarithm of (the size of the distinguishable set)
to base 2 is the entropy of the scheme. The distinguishable
set is the set that all the contained elements can be distin-
guished from each other by the produced feature.
5.3 Performance
At ﬁrst, we planned to count the number of errors. So, the 3000
feature vectors are input to the process in a random sort. The out-
put was checked with right answer to count false positive and false
negative. Neither false positive nor false negative was found among
them. However it can hardly justify the performance of the scheme
when the quantity of test cases increases sharply. Consequently,
we refer to the distribution of the similarity to calculate the perfor-
mance in the large scale case.
5.3.1 Distribution of similarity
Figure 7: Fitted Distribution of Similarities.
Because distance falls in Lognormal distribution, the similarity,
which is 1 - distance, falls in the distribution with the following
PDF:
fself =
1
(1 − simself )σ
√
2π
e
−(ln(1−simself )−µ)2/2σ2
Where the ﬁtted parameter gives µ = −3.17698, σ = 0.546804.
fcorr =
1
(1 − simcorr)σ
√
2π
e
−(ln(1−simcorr )−µ)2/2σ2
Scale
Where the ﬁtted parameter gives µ = −0.457726, σ = 0.178714.
5.3.3
We proved that the distribution can be applied to the large scale
case. Doubt may be casted on the assumption that the distribu-
tion may be correlated with the quantity of the phones. We argue
that the distribution of simcorr changes little with the increasing
of device quantity, which implies that the error rate of the scheme
doesn’t increase when the quantity of the devices increases. Changes
of parameters µ and σ according different quantity of devices are
shown in Figure. 8.
Figure 8: Parameter vs Device Quantity.
As we can see, the parameters converge to constants when the
quantity increases. Based on the result, we assume that the model
is suited for large scale similarity representation.
Figure 6: Distribution of Similarities.
We found that there is a gap between similarities of the same
phone and the similarities of different phones, which is the main
reason of the good performance. We investigated the distribution
of similarities between different phones (simcorr) and within the
same phones (simself ) respectively. Speciﬁcally, in terms of simself ,
to each device, comparison between the 60 features results to C 2
60
simself . Thus, totally 50* C 2
60 simself are collected. In terms of
50 devices pairs, where 60*60 similarities can
simcorr, there are C 2
be calculated in each pair. Therefore, totally, 3600 ∗ C 2
50 simcorr
are collected. The PDF (probability density function) of the distri-
bution is shown in Figure 6.
The gap between the PDF of simcorr and simself revealed the
reason that we found no false. Speciﬁcally, the similarity between
different phones spans in a range which has no common part with
what of similarity between the same phones. Generally speaking,
the maximum value of the simcorr is less than the minimum value
of simself . So, facing a newly arrived feature vector, the simi-
larity between it and its’ nearest neighbor is calculated. It can be
concluded that they comes from the same device if only this sim-
ilarity locates at the right side of the gap. Otherwise, the feature
comes from an unknown device.
Because the error rate of the scheme is directly linked with the
probability distribution over the gap, however, under this setting,
the probability of feature’s crossing the gap is unknown resulted
from lacking of such observation, we shift to get an analytical de-
scription of the PDF.
5.3.2 Distribution Fitness
We inspected the two distributions to ﬁnd their proper distribu-
tion type respectively, and found that both of them are unsymmet-
rical shaped, so we traversed all the common distribution to ﬁnd
−0.200.20.40.60.811.205101520similarityProbability Density  PDF of similarity between the same phonesPDF of similarity between different phones−0.200.20.40.60.811.205101520similarity  PDF of similarity between the same phonesPDF of similarity between different phonesFitted PDF of similarity between the same phonesFitted PDF of similarity between different phones0204060−0.8−0.6−0.4−0.20Device Quantityµ020406000.050.10.150.20.25Device Quantityσ434Figure 9: Error Rate vs Similarity (α).
Figure 10: Error Rate vs Similarity (α).