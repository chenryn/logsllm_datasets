6
3
7
14
594
0
6,289
35
8,715
9,313
2,795
9,278
8
11
2
0
6.38%
0%
69.23%
0.38%
57.14%
78.57%
22.22%
0%
Table III: This table compares TRIGGERSCOPE’s accuracy against the accuracy achieved by three existing, state-of-the-art analysis tools
when tasked to detect logic bombs. The column “Benign Apps” and “Malware Apps” indicate the number of benign and malicious
applications for which the given tool was able to successfully complete the analysis. For fairness, the false positive and false
negative rates only consider those applications that were successfully analyzed.
to detect logic bombs. Nonetheless, we wanted to measure
the accuracy of these systems when used in our context.
For our experiment, we analyzed all the applications in our
dataset by setting a timeout of one hour, and we considered a
given application as malicious (or, more precisely, potentially-
suspicious) if FlowDroid identiﬁed at least one suspicious data
ﬂow. Unsurprisingly, our results indicate that FlowDroid has a
relatively low false negative rate (22.22%), while it is affected
by a very high false positive rate (69.23%). Once again, these
results are not surprising: benign applications often contain
sensitive data ﬂows, which directly lead to a high false positive
rate. On the other hand, the presence of a sensitive data ﬂow
is not a necessary condition for the implementation of a logic
bomb: this observation is the root cause for false negatives.
Discussion. Table III summarizes the results of this experi-
ment. On the one hand, our results clearly show that existing
analysis approaches are not suitable for the detection of logic
bombs. In fact, analysis tools are either affected by a very
high false negative rate (Kirin and DroidAPIMiner) or by
a very high false positive rate (FlowDroid). On the other
hand, TRIGGERSCOPE provides an excellent trade-off between
false positives and false-negatives. Our analysis achieves better
results due to the key observation upon which our approach
is built: logic bombs are characterized by operations that are
executed only under very narrow circumstances, while the
actual, triggered behavior (encoded by the requested permis-
sions, APIs that are invoked, and data ﬂows throughout the
application) plays a minor role.
F. Triggers in Benign Applications
This section provides insights related to the triggers that
TRIGGERSCOPE detected in the three sets of benign applica-
tions crawled from the Play Store. Since these applications are
benign, it is expected that the detected triggers are likely to
be legitimate. However, all the detected triggers proved to be
interesting, and worth of manual inspection. In particular, as
reported later in this section, we identiﬁed two applications
containing a SMS-based backdoor-like functionality. We also
note that
the manual analysis was quite effective because
TRIGGERSCOPE returned precise information about the loca-
tion and type of the trigger, hence making the task of manual
vetting much simpler. The remainder of this section provides
an overview of our ﬁndings. The detailed analysis of each of
the detected triggers is reported in Appendix A, which we
invite the interested reader to consult for more information.
Time-related checks. One common case is that the application
contains a predicate that checks whether the current date
is greater than a speciﬁc constant. Such a check is usually
followed by a sensitive operation, such as a connection to the
Internet, or setting an “expired” ﬂag in a ﬁle. Another benign
case of hard-coded checks is represented by those applications
created for speciﬁc events that offer a countdown and alert
the user whenever a speciﬁc date is reached. Another case is
that of applications that allow users to schedule the sending
of text messages at a future time. These classes of features
are usually implemented by means of several checks on date-
related objects – some of which, such as the minute value, are
against hard-coded values.
388388
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:13:49 UTC from IEEE Xplore.  Restrictions apply. 
Location-related checks. The number of applications that are
characterized by suspicious location-related checks is lower
than in the case of time-related checks. Intuitively, this makes
sense. In fact, it is easier to envision reasons why benign
applications might implement hard-coded time-related checks
(for example, to implement expiration functionality or checks
for updates) than to imagine cases where a benign application
contains operations that are triggered only when the current
location is within a speciﬁc area.
suspicious/interesting SMS-related checks
However, we did ﬁnd a few applications that execute
speciﬁc behaviors only if the current location is within a
speciﬁc range. The prototype correctly identiﬁes the suspicious
location predicate as the conjunction of path constraints on
the current latitude and longitude. In one example, when the
user’s location satisﬁes a series of constraints, the application
displays “Welcome to Yamagata Station!” to the user. We man-
ually veriﬁed that the range of valid latitudes and longitudes
indeed identiﬁes the actual location of the Yamagata train
station in Japan. Note that while this speciﬁc trigger is clearly
benign, this kind of check is exactly what could be used to
implement a logic bomb to trigger a malicious behavior only
when a soldier is located in a given war zone.
SMS-related checks. TRIGGERSCOPE identiﬁed a num-
ber of
in 17
apps. In particular, TRIGGERSCOPE identiﬁed an applica-
tion, called MyRemotePhone [9],
that allows users to re-
motely locate the device running the application itself.
For
tool automatically identiﬁed a suspi-
cious SMS-related predicate that guards the execution of
location-related APIs. In particular,
the tool reported the
following predicate: (&& (!= (#sms/#body contains
"MPS:") 0) (!= (#sms/#body contains "gps")
0)). In natural
the predicate is satisﬁed when
the body of an SMS contains both the strings "MPS:" and
"gps". We then manually analyzed the application, and what
we found was surprising: upon reception of an SMS satisfying
the reported constraint (e.g., the string "MPS: gps"), the
application would automatically reply back with an SMS
containing the GPS coordinates of the device’s position, thus
leaking this sensitive information. To conﬁrm this ﬁnding,
we installed and executed the application on a real device,
we sent an SMS containing the string "MPS: gps", and,
after a few seconds, we received an SMS containing the
message "Found at , !",
where  and  identiﬁed the exact
location of the device.
this app, our
language,
Another interesting application identiﬁed by our system
is called RemoteLock [11]. A user of this application has
the ability to remotely lock and unlock her device by send-
ing an SMS containing a keyword. This keyword is user-
deﬁned, so it does not represent anything suspicious. However,
TRIGGERSCOPE identiﬁed the following predicate: "(!=
(#sms/#body equals "adfbdfgertefvgdfgrehgj
uiokhjgvbewruitkmbcvdfsgyhytdfsw")) 0)".
In
natural language, the predicate is triggered when the body of
an incoming SMS contains a long, hard-coded string. Through
manual analysis, we quickly discovered that this suspicious
check is, in fact, used to implement a backdoor. To conﬁrm
our ﬁnding, we installed and executed the application on a
real device, and we were able to unlock a locked phone just
by sending an SMS with the hard-coded string identiﬁed by
our system.
We found that the remaining apps make use of interesting
checks to implement a variety of functionality. For example,
we found a bank application that performs several checks on
all incoming SMS as part of its implementation of a two-
factor authentication scheme. Other applications implemented
a mechanism similar to the one implemented by the MyRe-
motePhone app, but more securely, for example by authenti-
cating the sender. Finally, other applications perform several
checks on the body of all incoming SMS to implement some
simple parsing routines, useful as a ﬁrst step to implement
custom communication protocols between compatible apps.
G. Logic Bombs in Malicious Applications
In our ﬁnal experiments, we tested TRIGGERSCOPE on
malicious samples. In a ﬁrst experiment, we used our system
to analyze potentially-malicious applications developed by
a hostile DARPA Red Team organization. This data set is
constituted by 11 applications. TRIGGERSCOPE identiﬁed a
suspicious trigger in all of them. Five of them contained
time-related triggers, implemented by comparing the current
day, month, or year to hard-coded values; one application
contained a location-related trigger, where it ﬁrst performs
several mathematical operations and conversions and then
compares the current location against a hard-coded position
using the Location.distanceBetween() method; the
remaining ﬁve application contained triggers based on the
content of SMS messages. When the trigger conditions are sat-
isﬁed, these applications would execute a variety of unwanted
behaviors, ranging from leaking sensitive information (e.g.,
user’s location) to changing a security-sensitive password to a
default, hard-coded one. For this data set, after the experiment
the DARPA Red Team provided us the ground truth for
each application (including details about all the triggers they
contained), and we were able to verify the absence of both
false positives and false negatives.
As a second experiment, we demonstrate how TRIGGER-
SCOPE is able to effectively identify trigger-based malicious
behavior in real-world malware. The ﬁrst example we consid-
ered is (informally) called “Holy Colbert” [54], collected by
the Android Malware Genome Project [63]. For this sample,
TRIGGERSCOPE was able to automatically discover a time-
bomb: the app ﬁrst retrieves the current date, converts it to a
string by means of the SimpleDateFormat Android API,
and it then compares the resulting string with the hard-coded
value "05212011". When this condition is satisﬁed, the
application starts to send spam text messages to the entire
contact list.
The second example we considered is a sample belonging to
the infamous Zitmo malware family [27]. Zitmo is well-known
for stealing mobile transaction numbers (mTANs) used to
389389
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:13:49 UTC from IEEE Xplore.  Restrictions apply. 
implement two-factor authentication in banking applications.
However, TRIGGERSCOPE was able to detect a different
malicious functionality: our system detected several suspicious
SMS-related checks. Upon manual inspection, we determine
that the detected checks are used to implement a SMS-based
bot-like C&C behavior. For the interested reader, we report
the decompiled version of the function implementing this
malicious functionality in Figure 8 in Appendix B.
The last real-world case-study we discuss is related to
HackingTeam, a security company known to write surveillance
software to assist law enforcement agencies and governments
around the world. As mentioned in the introduction, in July
2015 this company was subject of a sophisticated attack, and,
as a consequence, all its internal resources and personal com-
munications were publicly leaked. Among these resources, re-
searchers discovered the RCSAndroid [60] Android malware,
a very powerful malicious Android application that offers
remote control and spying capabilities. There are indications
that this malicious application has been used as part of targeted
attacks [57], [58], and it is thus relevant to our work.
following low-level
We obtained a sample of this application, and we analyzed
it using TRIGGERSCOPE. Our tool was able to identify a
suspicious SMS-based trigger. In particular, TRIGGERSCOPE
returned the
constraint: (&& (!=
(#sms/#sender endswith v(#storage)) 0) (!=
(#sms/#body startswith v(#storage))) 0).
The constraint indicates that the sender of the SMS and the
message body are checked against hard-coded values read
from the ﬁle-system (indicated by the #storage tag). The
analysis also determined that, only if the checks are satisﬁed,
the abortBroadcast() method is invoked2, which is
suspicious. Upon manual investigation, we determined that
these checks are implemented as part of a SMS-based
backdoor-like functionality that gives the possibility to the
owner of the application to trigger, at will, a variety of
malicious actions. For example,
is possible to leak the
victim’s private conversations, GPS location, and device
tracking information, but it is also able to capture screenshots,
collect
information about online accounts, and capture
real-time voice calls.
it
VI. LIMITATIONS AND COUNTERMEASURES
Our analysis system has a number of limitations, which we
discuss in this section.
First, our analysis system shares the same limitations of
many other static analysis approaches. For example,
is
possible that our implementation does not model precisely-
enough the many Android-speciﬁc components (e.g., Binder
RPC). We consider the complete and precise modeling of these
aspects as out of scope and subject for future research.
Our prototype cannot currently fully analyze functionality
that is implemented through the usage of reﬂection, dynamic
code loading [46], native code [16], or invocations to the
it
2In previous versions of Android, the invocation of this method would have
prevented the suspicious SMS to reach the default messaging application,
hiding the reception of the SMS from the device’s user.
390390
Runtime.exec() API: All these techniques could be used
to implement generic forms of obfuscation, or to speciﬁcally
hide the trigger-based nature of the code [50]. However, note
that in a context like the U.S. DoD marketplace, the mere
usage of these techniques (which can be reliably detected
by any static analyzer,
including TRIGGERSCOPE) would
certainly raise suspicion, it would affect the stealthiness of
the malware, and it would make existing malware detection
techniques [18], [36], [64] (whose feature sets cover the
previously-listed forms of obfuscation) more effective.
A second limitation is that our current prototype handles
a limited number of trigger inputs (i.e., time, location, and
text messages). However, we note that, although it would
require a substantial engineering effort, it is conceptually easy
to extend our prototype to handle additional sources. In fact,
the current prototype already shows that it is possible to model
complex Android objects (like Date and Location) as well
as String objects (like a text message’s body and sender).
We also note that the key contribution of our work is not the
development of a complete product, but it is to show that the
idea of detecting malicious behavior by focusing on triggers
– and not on the triggered behavior per se – is effective in
practice. However, we acknowledge that, while the extension
of the prototype is conceptually trivial, one would also need
to perform additional experiments and analysis to study and
characterize the kind of checks normally employed by benign
apps, and to tune the classiﬁcation routines accordingly.
The third limitation relates to the possibility for a mali-
cious application to move the suspicious trigger outside the
application itself, for example, to a web server. As our static
analysis tool has no access to any remote code, the current
prototype would not detect this suspicious behavior. However,
a malicious application now relies on an external component,
and this would affect both its reliability and stealthiness.
Moreover, in order for an application to execute a sensitive
operation only after a “signal” from an external component,
the application would still need to include a check in its code,
which could be detected by extending our prototype to detect
triggers based on network inputs.
A ﬁnal
limitation is that a malicious application could
attempt to obfuscate the implementation of a check so that
it would resemble an innocuous recurring check. For exam-
ple, the application could perform a series of mathematical
operations that consists in adding and subtracting the same
quantities so that, as a net result, the check is equivalent
to a hard-coded check. However, while an application could
attempt to obfuscate the semantics of a check, our system
would still accurately record (in an expression tree) all the
operations performed on the relevant objects. Even if, in the
general case, it can be difﬁcult to reconstruct the un-obfuscated
semantics of a check, approaches based on anomaly detection
(on the number and complexity of the operations involved)
could be able to at least detect the mere obfuscation attempt,
which, in certain scenario, might already be considered as
ground for rejection.
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:13:49 UTC from IEEE Xplore.  Restrictions apply. 
VII. RELATED WORK
In this section, we place our work in the context of other
approaches to improving the security of the Android platform.
Most relevant are static and dynamic analyses for either
detecting or preventing attacks, which we describe in this
section.
Static Analyses. Several static analysis approaches have been
proposed to detect malicious Android applications. One of
the ﬁrst was Kirin [31], which recovers the set of per-
missions requested by applications with the goal of iden-
tifying potentially-malicious behavior. Other works include
RiskRanker [36] and DroidRanger [64], which rely on sym-