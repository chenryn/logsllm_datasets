title:Operating SECDED-based caches at ultra-low voltage with FLAIR
author:Moinuddin K. Qureshi and
Zeshan Chishti
Operating SECDED-Based Caches at Ultra-Low
Voltage with FLAIR
Moinuddin K. Qureshi
Georgia Institute of Technology
Atlanta, GA, USA
PI:EMAIL
Zeshan Chishti
Intel Labs
Hillsboro, Oregon, USA
PI:EMAIL
Abstract—Voltage scaling is often limited by bit
failures
in large on-chip caches. Prior approaches for enabling cache
operation at low voltages rely on correcting cache lines with multi-
bit failures. Unfortunately, multi-bit Error Correcting Codes
(ECC) incur signiﬁcant storage overhead and complex logic.
Our goal is to develop solutions that enable ultra-low voltage
operation while incurring minimal changes to existing SECDED-
based cache designs. We exploit the observation that only a small
percentage of cache lines have multi-bit failures. We propose
FLexible And Introspective Replication (FLAIR) that performs
two-way replication for part of the cache during testing to
maintain robustness, and disables lines with multi-bit failures
after testing. FLAIR leverages the correction features of existing
SECDED code to greatly improve on simple two-way replication.
FLAIR provides a Vmin of 485mv (similar to ECC-8) and
maintains robustness to soft-error, while incurring a storage
overhead of only one bit per cache line .
I.
INTRODUCTION
Energy efﬁciency is becoming the single most important
design constraint for computing systems. Successive gen-
erations of microprocessors have relied on supply voltage
reduction as one of the most effective techniques to reduce the
power consumption of a microprocessor. However, as supply
voltage continues to decrease, the effects of semiconductor
process variations become more pronounced, resulting in in-
creased circuit failures. These failures limit the safe operating
voltage of a microprocessor to a value Vmin, beyond which
the processor ceases to operate reliably. Failures in large
memory structures, such as caches, which dominate the die
area, typically determine the Vmin for a processor [14]. For
example, for the baseline 8MB L3 cache, the Vmin would be
limited to approximately 850 mv.
Several recent papers have proposed architecture-based
techniques to improve the reliability of large caches at low
operating voltages [1][2][3][6][11][14][13]. These techniques
allow cache bits to fail, but use additional redundancy, such
as multi-bit error correcting codes (ECC) to tolerate high bit
failure rates. Figure 1 shows the Vmin for our baseline 8MB
L3 cache as the error correction level is changed on a per-
line basis. We denote ECC-N as an error correction scheme
that can correct up-to N errors in the line. Vmin reduces as
the ECC strength per line is increased. We deﬁne ultra-low
voltage to be a region below 500mv, which needs ECC-7 or
higher level of ECC.
GOAL
VS−ECC
ECC−8
ECC−7
ECC−6
ECC−5
480mv
490mv
500mv
510mv
520mv
530mv
540mv
ULTRA LOW VOLTAGE
Impact of ECC on Vmin. To operate in an ultra low voltage regime
Fig. 1.
(sub 500mv) we need ECC-7 or stronger code. Our goal is to obtain Vmin
of 485mv, without incurring signiﬁcant hardware or latency overheads for a
SECDED-based cache.
signiﬁcant storage overhead for ECC check bits and complex
logic for ECC encoding and decoding. Higher levels of ECC
also reduces performance because of the long latency of
ECC decoding. Thus,
the storage, complexity, and latency
overhead of multi-bit ECC make it less appealing for practical
implementation. From a commercial viewpoint, it is desirable
to have a single mainstream chip (say designed for high
performance operation) which can still be made to work in
low voltage domains with minor changes to existing design.
Given that existing caches already employ Single-Error-
Correcting Double-Error-Detecting (SECDED) codes to toler-
ate single bit failures due to soft errors (such as [5], [12]),
we would like to leverage this existing hardware to tolerate
both hard errors due to low voltage operation in addition to
soft errors. Ideally, we would like to have a practical hardware
solution that satisﬁes the following six requirements:
1)
2)
3)
4)
5)
6)
It should enable the cache to operate at ultra-low
voltage, say 485 mv in our case.
It should incur negligible storage overhead and almost
no changes to the existing hardware. This rules out
prior schemes that rely on multi-bit ECC.
It should be robust to soft errors, without relying
on additional storage overhead (we want to maintain
error tolerance at-least at the level of SECDED).
It should provide almost all of the cache capacity
(> 90%) during normal program execution.
It should have a cache access latency similar to
baseline during the normal program execution (this
again eliminates multi-bit ECC due to high latency).
It should not rely on having non-volatile memory on-
chip or require software changes for deployment.
We want to operate the cache at well within the ultra
low voltage region (say 485mv) so we will need the capa-
bility of ECC-8 to support such an aggressive Vmin target.
Implementing such high levels of error correction requires
This paper proposes a scheme that satisﬁes all the six
requirements. To devise our solution, we exploit the insight
that even at ultra low voltages only a very small percentage
of cache lines have multi-bit failures [2], [13]. Table I shows
978-1-4799-0181-4/13/$31.00 ©2013 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 07:43:00 UTC from IEEE Xplore.  Restrictions apply. 
the percentage of cache lines that have zero error, one error,
or two-or-more errors at the target Vmin of 485mv1 For our
target Vmin, less than 10% of the lines would have more than
one-bit error. If we can identify such faulty lines, then we can
enable low-voltage operation by disabling these lines.
TABLE I.
LINE FAILURE STATISTICS AT 485MV
Percentage lines with
0-Error
60.0%
1-Error
30.7%
2+ Errors
9.3%
A recent study, Variable Strength ECC (VS-ECC) [2], pro-
posed a mechanism to perform runtime testing to characterize
the error level of each line and allocate appropriate amount
of ECC for each line. Unfortunately, the runtime test runs
for a long time (several tens of seconds) and VS-ECC still
relies on operating a quarter of the cache with high-strength
ECC-4 during the testing phase. Thus, the Vmin obtained
with VS-ECC is limited by ECC-4 and it still incurs the
storage overhead (albeit for only quarter of the cache) and logic
complexity of expensive multi-bit ECC decoding. As we seek
a Vmin of 485mv, we would need to extend VS-ECC to have
ECC-8 in the quarter of the cache during testing phase, further
exacerbating the storage, latency, and complexity overheads.
In this paper, we obviate the need for storage and logic for
multi-bit ECC. Instead, we use the existing cache structure for
reliable operation during testing phase. We call this proposal
FLexible Replication (FLexR, pronounced as “ﬂexer”) as
replication is enabled only during the testing phase (to tolerate
multi-bit errors) and disabled during the post-testing phase (to
provide more cache capacity). As Dual Modulo Replication
(DMR) is effective only at detecting faults, but not at correcting
them, we modify the cache architecture during testing phase
to make error detection as the primary objective instead of
error correction. We do this by making the cache write through
during the testing phase (for the post testing phase the cache is
still used as a write-back cache). If the DMR check of FLexR
detects an uncorrectable error during the testing phase, FLexR
simply invalidates both lines in the pair and reads the value
from memory.
We found that simple two-way replication (even after per-
line correction of SECDED) is unable to tolerate more than
three errors in the pair, and is vulnerable to soft-error. We
enhance the robustness of FLexR by leveraging the observation
that each line in the pair undergoes SECDED operation and
we can use the SECDED status of each line in DMR (whether
the line is good, or has a correctable error, or has a detectable
but uncorrectable error) for improved robustness. We propose,
FLexible And Introspective Replication (FLAIR) which per-
forms a self-check (introspection) on the SECDED status of
the line in addition to the DMR check. FLAIR can ignore
the output of the DMR comparison, depending on SECDED
correction status of each line in the DMR group. We show
that FLAIR is robust at Vmin of 485mv and can tolerate soft
errors both during the testing phase as well as during the post-
testing phase. Thus, FLAIR provides a Vmin similar to ECC-8,
without adding any extra storage (except one bit per line) and
incurring negligible complexity.
1Similar to previous studies, we assume that the Vmin is calculated at the
voltage at which one out of 1000 caches is expected to fail.
After the testing phase ﬁnishes, the two-way replication
gets disabled and the lines can be used for normal operation.
As shown in Table I, operating at a Vmin of 485mv would
result in 31% lines with one bit hard faults. Given the vulner-
ability of cache lines to soft errors, SECDED protection alone
will not be enough for such lines, and previous approaches
would argue for disabling such lines after the testing phase
ﬁnishes. Thus, during the normal operating phase the program
would get only 60% of the available cache capacity. We
observe that for the lines with only one hard error (31% of
the lines), if a single bit soft error strikes such a line, then
SECDED can still identify the error. We leverage this key
observation, and propose a Weak Line Reclamation (WLR)
scheme that restrict such lines to only store clean data. Thus, if
a soft error happens in a line with 1 hard error, the SECDED
mechanism identiﬁes the fault. If the line is clean, we can
simply invalidate the line and read the copy from memory.
With WLR, the cache can retain more than 91% capacity
after the testing phase. Thus, our proposal enables low voltage
operation, at near full capacity, while incurring negligible
storage and logic overhead and maintaining tolerance to soft
errors, which makes practical to implement ultra low-power
mode in future processors.
II. BACKGROUND AND MOTIVATION
A.
Impact of Cache Reliability on Vmin
Most of the modern microprocessors dedicate a majority
of their transistor budget to large SRAM caches. To guarantee
correct software execution, these large on-chip caches must
operate in an error-free manner. However, parametric variations
induced by the imperfections in semiconductor manufacturing
process make SRAM cells susceptible to failures. Figure 2
shows the bit failure data from [9], [6], which speciﬁes the
failure probability of a single bit of cache at different supply
voltages. This data shows that bit failure rate increases with
reduction in supply voltage. Consequently, the supply voltage
of a microprocessor is often limited to a value Vmin, below
which the failure rate increases beyond the error mitigation
capability of the cache. The Vmin for a microprocessor product
is often speciﬁed as a function of acceptable yield loss. For
example, recent papers on reliable low voltage operation have
deﬁned Vmin as the voltage at which at least 999 out of 1000
caches operate reliably.
Modern microprocessors often use multiple power modes
to execute in an energy-efﬁcient manner. When higher perfor-
mance is desirable, the processor operates at a higher supply
voltage, whereas when performance is not as critical,
the
processor transitions to a low voltage mode to save energy.
Therefore, reducing the Vmin of a processor is critical towards
enabling higher energy efﬁciency. However, mechanisms that
reduce Vmin should not have a signiﬁcant impact on perfor-
mance during the high voltage execution mode.
B. Prior Work: Circuit Solutions and Dual VDD
Both circuit- and architecture-level solutions have been
low voltages. Circuit
proposed to mitigate bit failures at
solutions typically make changes to the SRAM cell design to
neutralize the impact of process variations [9]. These schemes
either upsize the transistors or use cell design variants such
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 07:43:00 UTC from IEEE Xplore.  Restrictions apply. 
)
.
b
o
r
P
e
r
u
l
i
a
F
(
0
1
G
O
L
0
-1
-2
-3
-4
-5
-6
-7
-8
-9
-10
-11
-12
Prob BitFail
480 500 520 540 560 580 600 620 640 660 680 700 720 740 760 780 800 820 840
Fig. 2.
voltage of 485mv the probability of bit failure is 1 out of 996.
Probability of bit failure as a function of operating voltage. Bit failure data is derived from prior studies [9], [14], [6], [2]. Note that at the target
Vmin (mv)
as the 8T, 10T, and ST SRAM cells. However, the resulting
Vmin reduction comes at the cost of signiﬁcant increases in
area (e.g., 100% area increase for ST cell [9]). While such
solutions may work well for small caches (such as L1 and
L2), they incur impractical overhead for large last-level caches
(LLC). In our work, we will assume that L1, L2, and the LLC
tag-store are protected by such circuit techniques and focus on
practical solutions for LLC data-store (which tends to consume
majority of the on-chip transistors).
Another option is to use Dual-VDD, whereby cache and
core operates on different power supply circuits. Unfortunately,
Dual-VDD incurs signiﬁcant area and complexity. Further-
more, if the core supply voltage is reduced signiﬁcantly but
the LLC continues to run at a higher voltage, then the LLC
power starts to dominate the platform power.
C. Prior Work: Avoiding Faulty Cells with Fault Maps
If the data about which cells in the cache are faulty
is available then we can employ efﬁcient error correction
to tolerate faulty cells. Architectural mechanisms for Vmin
reduction typically rely on such off-line information about cell
failures and trade-off cache capacity for increased reliability.
Wilkerson et al. [14], Roberts et al. [11], and Ansari et al. [4]
proposed techniques to disable defective portions of the cache
during the low voltage mode. These techniques sacriﬁce a
portion of the cache to either save the locations of defective
bits and the values of correct data, or pair faulty lines. These
techniques degrade performance at low voltages due to the
smaller cache capacity, incur higher latency due to parallel
accesses to demand lines and repair locations.
D. The Rationale for Avoiding Non-Volatile Fault-Maps
Most of the architectural work on making caches robust
at low voltages rely on having the faulty cell locations avail-
able. Unfortunately, passing this information from design time
testing to runtime system is non-trivial. This would require
that the processor chip be equipped with substantial amount
of non-volatile memory (few bits per cache line). Integrating
such large-scale non-volatile memory on-chip would require
embedding a separate technology, thus making such solutions
a high-cost and complex proposition. While current proces-
sor and memory designs do employ fuses to decommission
faulty storage (at large granularity), extending these fuses to
store faulty bit locations is quite expensive. For example, the
fuses that are use to disable DRAM rows incur an area of
approximately 5000 DRAM cells for each bit of fuse [7]. If we
translate this into SRAM overheads, each bit of fuse would cost
approximately few hundred SRAM cells, making it impractical
to employ such fuses on a per cache-line basis.
E. Runtime Testing and VS-ECC
While the need for having locations of faulty cells can be
avoided with multi-bit ECC (for example, as done by Chishti
et al. [6]), simply having high strength multi-bit ECC for all
lines is costly in terms of area, latency and complexity. A
recent paper proposed Variable-Strength ECC (VS-ECC) [2],
which addresses the limitations of previous ECC solutions by
using the ECC budget in a non-uniform manner.
VS-ECC dedicates SECDED ECC to each line for soft
error mitigation, while using additional ECC check bits to
protect 4 out of 16 cache lines in each set from up to 4
bit failures. To identify lines with multi-bit failures, VS-ECC
runs a testing phase before each transition to the low voltage
mode. During the testing phase, VS-ECC stresses each line
with different pre-determined testing patterns to uncover the
different modes of bit failures. It was shown that several tens of
seconds of testing is required to achieve acceptable coverage.
F. Need for Operational System During Runtime Test
Storing the testing information on disk requires software
support. In order to avoid such software changes, and to
provide periodic testing, VS-ECC recommended that testing
be performed whenever the machine restarts. Given that testing
requires few tens of seconds, this would increase boot time on
every power up and degrade user experience if the machine is
unavailable for few tens of seconds (e.g. think boot-up latency
of SSD vs HDD). Hence it is desirable to have a working
system even during testing.
To mitigate the performance overhead of the testing phase,
VS-ECC performs testing in a pipelined fashion. It divides
the cache into multiple portions and keeps one of the portions
active for normal program execution while the other portion(s)
is being tested. To tolerate bit failures in the active portion, VS-
ECC dedicates all the check bits for multi-bit correction to the
active portion. Since, only one quarter of the cache ways (4
out of 16) can be protected by multi-bit ECC, the size of the
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 07:43:00 UTC from IEEE Xplore.  Restrictions apply. 
active portion is limited to one quarter of the cache. Once the
testing phase ﬁnishes, the information collected during testing