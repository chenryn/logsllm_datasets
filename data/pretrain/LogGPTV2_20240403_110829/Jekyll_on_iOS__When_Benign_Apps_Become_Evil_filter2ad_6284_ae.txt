in Section 3.1 as an example. After the user allows
the greeting card app to access the address book, it
is very hard to prevent the app from leaking the in-
formation.
• Since Jekyll apps heavily reply on control ﬂow hi-
jacking vulnerabilities, advanced exploit prevention
techniques such as CFI [6] may effectively limit
Jekyll apps. CFI ensures that runtime control-
ﬂow transfers conform with the rules that are de-
rived from the static analysis of the program and
the constraints inferred from the execution context.
MoCFI [14] and PSiOS [47] brought the same idea
to iOS with a caveat that they require jailbroken
devices. Despite its high performance overhead
and low adoption rate in practice, CFI is generally
deemed effective against conventional ROP attacks,
which partially inspired the design of Jekyll apps. In
principle, if properly implemented and deployed on
iOS, CFI can signiﬁcantly increase the complexity
of designing Jekyll apps and force attackers to trade
code ﬂexibility for success. Although skilled attack-
ers presumably can either employ very systematic
non-control data attacks [12] to perform malicious
operations or use function-level gadgets to bypass
570  22nd USENIX Security Symposium 
USENIX Association
12
CFI, given their freedom to craft the gadgets in our
attack, they may have to sacriﬁce the stealthiness
of Jekyll apps to some extent due to the increased
distinguishability caused by such techniques.
• Type-safe programming languages like Java are im-
mune to low-level memory errors such as buffer
overﬂows. Thus, if we can enforce that third-party
apps be developed in type-safe programming lan-
guages, we can prevent the problems of planted con-
trol ﬂow hijacking or information leakage vulnera-
bilities in the apps.
In summary, we advocate the ofﬁcial support for run-
time security monitoring mechanisms on iOS. Our de-
sign of Jekyll apps intends to motivate such mechanisms,
which can protect iOS against advanced attacks and en-
sure that the app review practice and regulations receive
their maximum efﬁcacy.
8 Conclusion
In this paper, we presented a novel attack scheme that can
be used by malicious iOS developers to evade the manda-
tory app review process. The key idea is to dynamically
introduce new execution paths that do not exist in the app
code as reviewed by Apple. Speciﬁcally, attackers can
carefully plant a few artiﬁcial vulnerabilities in a benign
app, and then embed the malicious logic by decomposing
it into disconnected code gadgets and hiding the gadgets
throughout the app code space. Such a seemingly benign
app can pass the app review because it neither violates
any rules imposed by Apple nor contains functional mal-
ice. However, when a victim downloads and runs the
app, attackers can remotely exploit the planted vulnera-
bilities and in turn assemble the gadgets to accomplish
various malicious tasks.
We demonstrated the versatility of our attack via a
broad range of malicious operations. We also discussed
our newly discovered private APIs in iOS that can be
abused to send email and SMS and post tweets without
the user’s consent.
Our proof-of-concept malicious app was successfully
published on App Store and tested on a controlled group
of users. Even running inside the iOS sandbox, the app
can stealthily post tweets, take photos, gather device
identity information, send email and SMS, attack other
apps, and even exploit kernel vulnerabilities.
Acknowledgements
We thank our shepherd Benjamin Livshits and the anony-
mous reviewers for their valuable comments. This mate-
rial is based upon work supported in part by the National
Science Foundation under grants no. CNS-1017265 and
no. CNS-0831300, the Ofﬁce of Naval Research under
grant no. N000140911042, and the United States Air
Force under Contract no. FA8650-10-C-7025. Any opin-
ions, ﬁndings, and conclusions or recommendations ex-
pressed in this material are those of the authors and do
not necessarily reﬂect the views of the National Science
Foundation, the Ofﬁce of Naval Research, or the United
States Air Force.
References
[1] JailbreakMe. http://www.jailbreakme.com/.
[2] News:yc, the open source news client for iOS. https://
github.com/Xuzz/newsyc.
[3] Unstructured
supplementary
service
data.
http:
//en.wikipedia.org/wiki/Unstructured_
Supplementary_Service_Data.
[4] Apple’s worldwide developers conference keynote address,
June 2010. http://www.apple.com/apple-events/
wwdc-2010/.
[5] Apple’s app store review guidelines, 2013.
https:
//developer.apple.com/appstore/resources/
approval/guidelines.html.
[6] M. Abadi, M. Budiu, U. Erlingsson, and J. Ligatti. Control-ﬂow
integrity principles, implementations, and applications. In Pro-
ceedings of the ACM Conference on Computer and Communica-
tions Security (CCS), Alexandria, VA, USA, 2005.
[7] A. Bednarz. Cut the drama: Private apis, the app store & you.
2009. http://goo.gl/4eVr4.
[8] D. Blazakis. The apple sandbox. In Blackhat DC, Jan 2011.
[9] E. Buchanan, R. Roemer, H. Shacham, and S. Savage. When
good instructions go bad: generalizing return-oriented program-
In Proceedings of the 15th ACM conference on
ming to risc.
Computer and communications security (CCS), Alexandria, VA,
USA, 2008.
[10] Bulba and Kil3r. Bypassing stackguard and stackshield. Phrack
Magazine, 56(5), 2000.
[11] S. Checkoway, L. Davi, A. Dmitrienko, A. R. Sadeghi,
H. Shacham, and M. Winandy. Return-oriented programming
In Proceedings of the 17th ACM conference
without returns.
on Computer and Communications Security (CCS), Chicago, IL,
USA, Oct 4-8, 2010.
[12] S. Chen, J. Xu, E. C. Sezer, P. Gauriar, and R. K. Iyer. Non-
In Proceedings of the
control-data attacks are realistic threats.
14th conference on USENIX Security Symposium, pages 12–12,
2005.
[13] S. Dai, T. Wei, C. Zhang, T. Wang, Y. Ding, Z. Liang, and W. Zou.
A framework to eliminate backdoors from response-computable
authentication. In Proceedings of the 2012 IEEE Symposium on
Security and Privacy, 2012.
[14] L. Davi, R. Dmitrienko, M. Egele, T. Fischer, T. Holz, R. Hund,
S. Nrnberger, and A. reza Sadeghi. Mocﬁ: A framework to mit-
igate control-ﬂow attacks on smartphones. In In Proceedings of
the Network and Distributed System Security Symposium (NDSS),
2012.
[15] L. Davi, A. Dmitrienkoy, A.-R. Sadeghi, and M. Winandy.
Return-oriented programming without returns on arm. Technical
Report HGI-TR-2010-002, System Security Lab, Ruhr Univer-
sity Bochum, Germany, 2010.
13
[36] K. Lu, D. Zou, W. Wen, and D. Gao. Packed, printable, and
In Proceedings of
polymorphic return-oriented programming.
the 14th International Symposium on Recent Advances in Intru-
sion Detection (RAID), Menlo Park, California, USA, September
2011.
[37] C. Miller. Inside ios code signing. In Symposium on Security for
Asia Network (SyScan), Taipei, Nov 2011.
[38] C. Miller, D. Blazakis, D. DaiZovi, S. Esser, V. Iozzo, and R.-P.
iOS Hacker’s Handbook. Wiley, 1 edition edition,
Weinmann.
May 2012.
[39] V. Pappas, M. Polychronakis, and A. D. Keromytis. Smashing the
gadgets: Hindering return-oriented programming using in-place
In Proceedings of the 33rd IEEE Sympo-
code randomization.
sium on Security and Privacy, pages 601–615, San Francisco,
CA, USA, May 2012.
[40] M. PRATI. ROP gadgets hiding techniques in Open Source
Projects. PhD thesis, University of Bologna, 2012.
[41] P. Roberts. Accountability, not code quality, makes ios safer than
android. April 2012. http://goo.gl/ZaXhj.
[42] F. Roesner, T. Kohno, A. Moshchuk, B. Parno, H. J. Wang, and
C. Cowan. User-driven access control: Rethinking permission
In Proceedings of the
granting in modern operating systems.
2012 IEEE Symposium on Security and Privacy, Washington,
DC, USA, 2012.
[43] E. J. Schwartz, T. Avgerinos, and D. Brumley. Q: Exploit hard-
ening made easy. In Proceedings of USENIX Security, San Fran-
cisco, CA, USA, 2011.
[44] H. Shacham. The geometry of innocent ﬂesh on the bone: return-
into-libc without function calls (on the x86). In Proceedings of
the 14th ACM conference on Computer and Communications Se-
curity (CCS), Alexandria, VA, USA, Oct. 29-Nov. 2,2007.
[45] H. Shacham, M. Page, B. Pfaff, E.-J. Goh, N. Modadugu, and
D. Boneh. On the effectiveness of address-space randomization.
In Proceedings of the 11th ACM conference on Computer and
communications security, pages 298–307, Washington DC, USA,
2004.
[46] R. Wartell, V. Mohan, K. W. Hamlen, and Z. Lin. Binary stirring:
self-randomizing instruction addresses of legacy x86 binary code.
In Proceedings of the 2012 ACM conference on Computer and
communications security (CCS), Raleigh, NC, USA, Oct, 2012.
[47] T. Werthmann, R. Hund, L. Davi, A.-R. Sadeghi, and T. Holz.
Psios: Bring your own privacy & security to ios devices.
In
8th ACM Symposium on Information, Computer and Communi-
cations Security (ASIACCS 2013), May 2013.
2013.
iOS jailbreaking.
[48] Wikipedia.
http://en.
wikipedia.org/wiki/IOS_jailbreaking.
[49] H. Xu and X. Chen. Find your own ios kernel bug. In Power of
Community (POC), Seoul, Korea, 2012.
[50] B. Yee, D. Sehr, G. Dardyk, J. B. Chen, R. Muth, T. Ormandy,
S. Okasaka, N. Narula, and N. Fullagar. Native client: A sandbox
In Proceedings of the
for portable, untrusted x86 native code.
2009 30th IEEE Symposium on Security and Privacy, 2009.
[51] D. A. D. Zovi. ios 4 security evaluation. In Blackhat USA, Las
Vegas, NV, Aug 2011.
[16] S. designer. Bugtraq, Aug, 1997. return-to-libc attack.
[17] M. Egele, C. Kruegel, E. Kirda, and G. Vigna. Pios: Detecting
In 18th Annual Network and
privacy leaks in ios applications.
Distributed System Security Symposium (NDSS), February 2011.
[18] W. Enck, P. Gilbert, B.-G. Chun, L. P. Cox, J. Jung, P. McDaniel,
and A. N. Sheth. Taintdroid: an information-ﬂow tracking system
for realtime privacy monitoring on smartphones. In Proceedings
of the 9th USENIX conference on Operating systems design and
implementation, OSDI’10, 2010.
[19] J. Engler, S. Law, J. Dubik, and D. Vo.
ios application security
assessment and automation: Introducing sira. In Black Hat USA,
LAS VEGAS, 2012.
[20] K.
Ermakov.
send
sms.
Your
ﬂashlight
can
http://blog.ptsecurity.com/2012/10/your-ﬂashlight-can-send-
sms-one-more.html, Oct 2012.
[21] S. Esser. Antid0te 2.0 -ASLR in iOS. In Hack In The Box(HITB).
Amsterdam, May 2011.
[22] S. Esser.
ios kernel exploitation. In Black Hat USA, LAS VE-
GAS, 2011.
[23] D. ETHERINGTON.
iphone app contains secret game boy ad-
vance emulator, get it before it’s gone. March 2013. http:
//goo.gl/OGyc0.
[24] A. P. Felt, M. Finifter, E. Chin, S. Hanna, and D. Wagner. A
survey of mobile malware in the wild. In Proceedings of the 1st
ACM workshop on Security and privacy in smartphones and mo-
bile devices (SPSM), pages 3–14, 2011.
[25] J. Han, S. M. Kywe, Q. Yan, F. Bao, R. H. Deng, D. Gao, Y. Li,
and J. Zhou. Launching generic attacks on ios with approved
third-party applications. In 11th International Conference on Ap-
plied Cryptography and Network Security (ACNS 2013). Banff,
Alberta, Canada, June 2013.
[26] J. Han, Q. Yan, D. Gao, J. Zhou, and R. H. Deng. Comparing
Mobile Privacy Protection through Cross-Platform Applications.
In Proceedings of the Network and Distributed System Security
Symposium (NDSS), San Diego, CA, February 2013.
[27] J. D. Hiser, A. Nguyen-Tuong, M. Co, M. Hall, and J. W. David-
son. Ilr: Where’d my gadgets go? In Proceedings of the 33rd
IEEE Symposium on Security and Privacy, pages 571–585, San
Francisco, CA, USA, May 2012.
[28] J. Howell and S. Schechter. What you see is what they get: Pro-
tecting users from unwanted use of microphones, cameras, and
In The Web 2.0 Security & Privacy Workshop
other sensors.
(W2SP), 2010.
[29] R. Hund, T. Holz, and F. C. Freiling. Return-oriented rootk-
its: Bypassing kernel code integrity protection mechanisms. In
Proceedings of the 18th USENIX Security Symposium, Montreal,
Canada, Aug, 2009.
[30] iOS Market Statistics, 2012. http://goo.gl/LSK7I/.
[31] iOS Security, May 2012. http://images.apple.com/
ipad/business/docs/iOS_Security_May12.pdf.
[32] H. Kipp.
Arm gcc inline assembler cookbook.
http://www.ethernut.de/en/documents/
arm-inline-asm.html.
2007.
[33] T. Kornau. Return oriented programming for the arm architecture.
Master’s thesis, Ruhr-University Bochum, Germany, 2009.
[34] C. Kruegel, E. Kirda, and A. Moser. Limits of Static Analysis
for Malware Detection. In Proceedings of the 23rd Annual Com-
puter Security Applications Conference (ACSAC), Miami Beach,
Florida, USA, Dec, 2007.
[35] D. Larochelle and D. Evans. Statically detecting likely buffer
overﬂow vulnerabilities. In Proceedings of the 10th conference
on USENIX Security Symposium, Berkeley, CA, USA, 2001.
14