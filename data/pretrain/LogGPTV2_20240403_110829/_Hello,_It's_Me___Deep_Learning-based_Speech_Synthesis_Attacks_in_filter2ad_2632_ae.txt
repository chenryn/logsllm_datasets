### Correct Identification of Fake Voices

The ability to correctly identify fake voices for unfamiliar or briefly familiar speakers was consistent (50% in our study vs. 48% in [57]). However, participants in our survey were more accurate at identifying fake speech from famous speakers (80% vs. 50% in [57]), possibly indicating a higher general awareness of speech synthesis attacks.

### Impact of Mentioning Fake Speech in Survey Description

Mentioning fake speech in the survey description had a statistically significant effect on participants' perceptions of the fake speech samples. Figure 4 illustrates how responses to the survey version that mentioned fake speech reflected an increased skepticism toward fake voices.

We used a chi-squared test for independence to compare responses from each speaker familiarity category between the two survey versions, to determine if this change was statistically significant.

- For unfamiliar speakers, all but one speaker showed a significant (p < 0.05) increase in skepticism.
- For briefly familiar speakers, the increase in skepticism was also significant (p < 0.05).
- For familiar speakers, the difference was not significant (p > 0.05).

### Interview Design and Familiarity

The interview involved 14 participants, with three questions asked by a fake interviewer and five by a real interviewer. The fake interviewer's voice quality was relatively low (see §5.2). Before starting the interview, the real interviewer informed 10 out of 14 participants that the fake interviewer was feeling unwell and would only chime in intermittently. This priming statement aimed to lower participants' expectations of voice quality.

Participants ranked their familiarity with the interviewers' voices on a scale from 1 ("not at all familiar") to 5 ("extremely familiar"). Table 6 shows the distribution of familiarity rankings.

| Familiarity Level | Real Interviewer | Fake Interviewer |
|------------------|------------------|------------------|
| Not at all       | 9                | 0                |
| Slightly         | 7                | 1                |
| Moderately       | 1                | 2                |
| Very             | 2                | 1                |
| Extremely        | 3                | 0                |

### Interview Questions

The staged interview consisted of eight questions about the use of automatic speech recognition systems and privacy perceptions. Table 7 lists the questions and the interviewer who asked them.

| #   | Interviewer | Question                                                                                         |
|-----|-------------|--------------------------------------------------------------------------------------------------|
| 1   | Real        | Do you use automatic speech recognition systems in everyday life?                                |
| 2   | Fake        | How often do you use these systems in your daily life?                                            |
| 3   | Real        | What do you do in your interactions with these systems?                                           |
| 4   | Real        | Do you ever think about your privacy during your interactions with these systems?                 |
| 5   | Fake        | Can you visit this website? I’ll put the link in the chat.                                         |
| 6   | Real        | Have you ever used the “voice profiles” feature of these systems?                                 |
| 7   | Fake        | Are you ever concerned about privacy if/when you use voice profiles?                              |
| 8   | Real        | We need your student ID to track your participation in this study. Can you leave it in the chat?  |

### Conditions and Deception

Participants were not informed that the study was about perceptions of fake speech, and they did not know that one interviewer was using a fake voice. The real interviewer told them that everyone in the call was keeping their video off to preserve privacy, which actually prevented them from observing the fake voice. The interviews were recorded with participants' consent.

### Results

None of the participants exhibited suspicion or hesitancy during interactions with the fake interviewer. All 14 participants responded to the fake interviewer's questions, visited the requested website, and provided their student ID. After the deception was revealed, only four participants noted that something seemed "off" about the fake interviewer's voice. These four participants had not been given the priming statement about the fake interviewer being sick.

### Post-Deception Reactions

- **Complete Surprise**: Four participants were visibly astonished when the deception was revealed. P5 stated, "I really thought it was you – like 100%," while P10 said, "computers just won the Turing test."
- **Satisfied with "Sick" Excuse**: Seven participants noted that the "sick" excuse alleviated any concerns. P4 said, "I think it totally worked – I thought you were terribly sick," and P2 noted, "it was really kind of worrying [how sick you sounded]."
- **Silently Suspicious**: Four participants (P9, P12, P13, P14) expressed suspicions after the deception. P12 and P13 said it "sounded like the speaker had a cold," and P14 supposed "it was a poor quality microphone."

### Factors Affecting Trust

- **Presence of Real Interviewer**: Several participants credited the "tag-team" nature of the interview as making the deception more believable. P9 stated, "I feel like [the real interviewer’s] obviously human presence played a big factor in [my not saying anything]."
- **Polite Social Convention**: Multiple participants felt it would be uncomfortable to comment on the fake interviewer's voice. P12 exclaimed, "well that would be quite the insult!"
- **Provenance of Interview Request**: Recruitment through trusted channels (e.g., email list-serv, Slack) within the department made the request seem legitimate. P9 noted, "the provenance of the study... seemed like a legit source."

### What Would Have Made Participants Suspicious

- **Nothing**: Some participants claimed nothing would have caused them to question the fake interviewer. P5 said, "I’m glad you guys didn’t ask me for a bank account, because [...] I would have given it to you."
- **Requesting More Personal Information**: One participant noted, "I don’t think the information you wanted was very sensitive [so] I don’t see why I need to be concerned about this" (P6).

### Effect of Familiarity and Priming Statement

- **Familiarity with Interviewers**: Seven participants rated their familiarity with both interviewers' voices as 1 out of 5. Their responses were consistent with those who had some familiarity. P8 mentioned, "the voice did seem pretty weird, but since I trust you both, I just went with it."
- **Priming Statement**: In four interviews without the "sick" excuse, participants exhibited increased skepticism. P11 claimed, "it was very obviously a fake voice," and others noted feeling "weird" or that the voice was "very strange."

### Key Takeaways

Our studies show that context and demographics impact the credibility of synthesized speech. Mentioning fake speech increased participants' skepticism, and women and younger participants were more likely to correctly identify fake speakers. In a trusted setting, a fake voice successfully deceived even computer science graduate students, some of whom research security or machine learning.

### Limitations and Next Steps

Our participant pool for study B was homogeneous in gender, age, and educational background. Future work should include larger, more diverse user studies to provide a nuanced understanding of synthesized voice attacks in trusted settings. Additionally, real-world scenarios could benefit from two-factor authentication mechanisms to verify the trusted setting, making such attacks more difficult.

**Session 1D: Authentication and Click Fraud CCS '21, November 15–19, 2021, Virtual Event, Republic of Korea**

**Defense**
- [100]
- [90]
- [26]
- [98]
- Category: Liveness