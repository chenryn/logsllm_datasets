with an adjusted R2=45% (Nagelkerke’s coefficient of determination).
To evaluate the CC metric, it was incorporated in the above analysis. We
arrive at the following conclusions:
– Just like the five model factors that emerged from the original analysis, the
CC metric displays the expected relation with score.
– Unlike the density and average connector degree factors, the correlation be-
tweenscoreandtheCCmetric(0.549)isnot significantata95%confidence
interval as the P-value of 0.065 slightly exceeds the 0.05 confidence interval.
– Aregressionmodelwithamuchbetter explanatorypowerforthevariationin
scorecouldbedevelopedbyincluding theCCmetric:theadjustedR2 from
theoriginalmodelincreasedfrom45%to76%inthenewregressionmodel.In
particular, by combining the #or-joins, density, average connector
degree,mismatchfactorsandtheCCmetricthisresultcouldbeachieved.
A visualization of this regression model can be seen in Figure 3.
Fig.3.LinearregressionmodelexplainingthemeanSCOREforthe12processmodels
What this analysis suggests is that CC on its own is slightly less powerful
asanindicatorforprocessmodelunderstandabilitythanthetwobestcandidate
metrics available, but that it can deliver a superior explanation of the variation
in understandability across models when combined with existing metrics.
4 Related work
This section briefly describes the related work for business process metrics. In
essence, related work can be organized in two categories: process model met-
rics inspired by software measurement and experimental work on process model
metrics. In this section, we focus in particular on metrics that consider overall
structural aspects of the process model beyond simple count metrics. For an
overview of process model metrics in general refer to [9,12,20,33].
The early development of process model metrics is greatly inspired by and
based on software quality metrics. These metrics aim at obtaining program de-
signs that are less error-prone, easier to comprehend and easier to maintain. A
surveyofexistingsoftwaremetricscanbefoundine.g.[14,35].Anumberofstud-
iesdemonstratethesignificantcorrelationofsoftwarequalitymetricswitherrors
inthesoftwaredesign(e.g.[3,5,15,31,32]).Inthetraditionofthiswork,thereare
someworksinthe1990sthataremainlyrootedinsoftwarequalitymeasurement.
Danevaetal.[10]introduceasetofcomplexityindicatorsforEPCsbasedonthe
visualattributesofthemodel:function cohesion,event cohesion andcohesion of
a logical connector.Fromtheirvalidationwith11EPCstheyconcludethattheir
metrics help to identify error-prone model fragments. Morasca proposes a set of
simple metrics for software specifications designed with Petri-nets [25]. He iden-
tifiessize,length,structuralcomplexity,andcouplingasinterestingattributesof
a design without striving for an empirical validation. The works by Reijers and
Vanderfeesten extend this research stream by introducing a coupling-cohesion
metric for guiding the design of a workflow process [27,28]. This approach is
based on the data flow in a business process and uses the network structure of
the product as a starting point rather than the process model. In [34], Vander-
feesten, Cardoso, and Reijers propose a weighted coupling metric, which puts a
weighttothedifferenttypesofconnectionsbetweentwoactivitiesintheprocess
model. While this metric lacks a thorough cognitive motivation, it was used as
a blueprint for the CC metric. Cardoso has developed a Control Flow Complex-
ity (CFC) metric [7] which was validated against Weyuker’s complexity axioms
[6] and tested with respect to their correlation with perceived complexity [8]. In
contrasttotheCCmetric,itdoesnotconsidertheconnectionsbetweendifferent
model elements, but focuses on routing elements in isolation.
Mendling et al. take an experimental approach towards process model met-
rics that is driven by the explanatory power of a metric in an empirical setting.
In [20,22] Mendling et al. have tested 28 business process metrics (including
size, density, structuredness, coefficient of connectivity, average connector de-
gree, control flow complexity, and others) as error predictors on a set of over
2000 process models from different samples. All metrics, except for density and
the maximum degree of a connector, are confirmed to be correlated to error-
pronenessasexpected.Anotherresultofthisstudyisalogisticregressionmodel
is able to classify 90% of the process models correctly. Finally, a survey on un-
derstandability of process models is reported by Mendling, Reijers and Cardoso
in relation to the set of metrics mentioned in the previous study [23]. The main
results of this survey are already described in Section 3.2.
Whilethemetricsusedintheseexperimentsaremotivatedtheoretically,most
of them are not explicitly rooted in cognitive research. The CC metric considers
hardmentaloperationsasdefinedinthecognitivedimensionsframework[11]as
the main factor that drives understanding a process model.
5 Conclusion
In this paper, we motivated, formalized, and validated the Cross-Connectivity
metric for process models. The metric expresses how tightly the nodes in a
processmodelareconnectedbuildingonaweakest-linkmetaphor.Thedefinition
of the metric builds on the assumption that a higher value is associated with an
easierunderstandingofthemodel,whichimpliesasaconsequencealowererror-
probability.Asfollowsfromourevaluationofthismetricforboththeseaspects,
itperformssimilarlywellasthebestavailablealternativemodelmetrics.Ontop
ofthat,ourresultssuggestthattheCCmetricaddsanewcognitiveperspective
onprocessmodelquality,whichhelpstodeliverabetterexplanatorypowerwhen
it is combined with the existing ones.
In reflecting on the development of business process model metrics, it is fair
to say that it is a research area in development. Initially, proposals for process
model metrics were highly conceptual, on the basis of the perhaps tempting
idea that if metrics are useful to analyze software programs it should be equally
applicable for process models. By now, we have progressed to the stage where
model metrics are put to the test for determining their effectiveness in reality.
The good performance of the CC metric clearly shows that a more cognitive
theoretical stance is needed to advance the field of process model measurement.
Overall,feedbackfromempiricalvalidationshasimprovedthequalityofpro-
cess model metrics: The metrics proposed in recent works, e.g. [20,22] and this
paper, perform much better in explaining the variation of understanding and
occurrence of errors in process models. In our future work, we will continue to-
wards further improvements. In particular, we aim at evaluating model quality
metricsonawiderscale,byconsideringlargersetsofreal-worldmodels.Inorder
to achieve that, we are collaborating with consultancy companies that practice
process modeling on a day-to-day basis for their clients. Since most empirical
researchhasbeendonewithEPCmodels,weareverymuchinterestedinBPMN
and Petri-net process models. Furthermore, we are investigating additional fac-
tors that contribute to a comprehensive understanding of process model quality
as, for example, the visual layout a process model graph and the importance of
preliminary knowledge about the domain that is captured in the model. As the
ultimate goal of our research, we envision the development of a set of concrete
guidelines for process modelers, substantiated by solid theoretical foundations
and empirical evidence, which will help to create better process models in prac-
tice.
Acknowledgement
This research is partly supported by the Technology Foundation STW, applied
science division of NWO and the technology programme of the Dutch Ministry
of Economic Affairs.
References
1. W.M.P. van der Aalst, A.H.M. ter Hofstede, B. Kiepuszewski, and A.P. Barros.
Workflow Patterns. Distributed and Parallel Databases, 14(1):5–51, July 2003.
2. J. Becker, M. Rosemann, and Ch. von Uthmann. Guidelines of Business Process
Modeling. In Business Process Management, Models, Techniques, and Empirical
Studies,volume1806ofLectureNotesinComputerScience,pages30–49.Springer-
Verlag, Berlin, 2000.
3. J.M. Bieman and B.-K. Kang. Measuring Design-level Cohesion. IEEE Transac-
tions on Software Engineering, 24(2):111–124.
4. A.F.Blackwell. TenYearsofCognitiveDimensionsinVisualLanguagesandCom-
puting. Journal of Visual Languages and Computing, 17(4):285–287, 2007.
5. D.N. Card, V.E. Church, and W.W. Agresti. An Empirical Study of Software
Design Practices. IEEE Transactions on Software Engineering, 12(2):264–271.
6. J. Cardoso. Control-flow Complexity Measurement of Processes and Weyuker’s
Properties. In Proceedings of the 6th International Enformatika Conference (IEC
2005), pages 213–218. International Academy of Sciences, 2005.
7. J. Cardoso. How to Measure the Control-flow Complexity of Web Processes and
Workflows. In L. Fischer, editor, Workflow Handbook 2005. Future Strategies,
Lighthouse Point, 2005.
8. J. Cardoso. Process Control-flow Complexity Metric: an Empirical Validation.
In IEEE International Conference on Services Computing (IEEE SCC 06), pages
167–173. IEEE Computer Society, 2006.
9. J. Cardoso, J. Mendling, G. Neumann, and H.A. Reijers. A Discourse on Com-
plexity of Process Models. In J. Eder and S. Dustdar, editors, Proceedings of the
BPM 2006 Workshops, Workshop on Business Process Design BPI 2006, Lecture
Notes in Computer Science Volume 4103, pages 115–126, September 2006.
10. M. Daneva, R. Heib, and A.-W. Scheer. Benchmarking Business Process Models.
IWi Research Report 136, Institute for Information Systems, University of the
Saarland, Germany, 1996.
11. T.R.G. Green and M. Petre. Usability Analysis of Visual Programming Envi-
ronments: A Cognitive Dimensions Framework. Journal of Visual Languages and
Computing, 7(2):131–174, 1996.
12. V. Gruhn and R. Laue. Complexity Metrics for Business Process Models. In
Proceedings of the 9th international conference on business information systems
(BIS 2006), vol. 85 of Lecture Notes in Informatics, 2006.
13. D. Hosmer and S. Lemeshow. Applied Logistic Regression, 2nd edition. Wiley &
Sons, 2000.
14. D. Kafura. A Survey of Software Metrics. In ACM ’85: Proceedings of the 1985
ACM annual conference on The range of computing : mid-80’s perspective, pages
502–506, New York, NY, USA, 1985. ACM Press.
15. B.-K. Kang and J.M. Bieman. A Quantitative Framework for Software Restruc-
turing. Journal of Software Maintenance, 11:245–284, 1999.
16. P. Kawalek and P. Kueng. The Usefulness of Process Models: A Lifecycle De-
scription of how Process Models are used in Modern Organisations. In K. Siau,
Y.Wand,andJ.Parsons,editors,ProceedingsoftheSecondCAiSE/IFIP8.1Inter-
national Workshop on Evaluation of Modelling Methods in Systems Analysis and
Design, pages 1–12, 1997.
17. G. Keller and Th. Teufel. Sap R/3 Process Oriented Implementation: Iterative
Process Prototyping. Addison-WesleyLongmanPublishingCo.,Inc.,Boston,MA,
USA, 1998.
18. J. Krogstie, G. Sindre, and H. Jørgensen. Process Models Representing Knowl-
edge for Action: a Revised Quality Framework. European Journal of Information
Systems, 15(1):91–102, 2006.
19. A. Lindsay, D. Downs, and K. Lunn. Business processes: attempts to find a defi-
nition. Information and Software Technology, 45(15):1015–1019, 2003.
20. J.Mendling. DetectionandPredictionofErrorsinEPCBusinessProcessModels.
PhDthesis,ViennaUniversityofEconomicsandBusinessAdministration,Vienna,
Austria, May 2007.
21. J. Mendling and W.M.P. van der Aalst. Formalization and Verification of EPCs
with OR-Joins Based on State and Context. In J. Krogstie, A.L. Opdahl, and
G. Sindre, editors, Proceedings of the the 19th International Conference on Ad-
vanced Information Systems Engineering (CAiSE 2007), volume 4495 of LNCS,
pages 439–453. Springer-Verlag, Berlin, 2005.
22. J. Mendling, G. Neumann, and W.M.P. van der Aalst. Understanding the Occur-
renceofErrorsinProcessModelsbasedonMetrics. InR.MeersmanandZ.Tari,
editors,OTM Conference 2007, Proceedings, Part I,volume4803ofLecture Notes
in Computer Science, pages 113–130. Springer, 2007.
23. J. Mendling, H.A. Reijers, and J. Cardoso. What Makes Process Models Un-
derstandable? In G. Alonso, P. Dadam, and M. Rosemann, editors, International
ConferenceonBusinessProcessManagement(BPM2007),volume4714ofLecture
Notes in Computer Science, pages 48–63. Springer-Verlag, Berlin, 2007.
24. J. Mendling, H.M.W. Verbeek, B.F. van Dongen, W.M.P. van der Aalst, and
G. Neumann. Detection and Prediction of Errors in EPCs of the SAP Reference
Model. Data and Knowledge Engineering, 64(1):312–329, January 2008.
25. S. Morasca. Measuring Attributes of Concurrent Software Specifications in Petri-
nets.InProceedingsofthe6thInternationalSymposiumonSoftwareMetrics,pages
100–110. IEEE Computer Society, 1999.
26. M.A. Ould. Business Processes: Modelling and Analysis for Re-engineering and
Improvement. Wiley, 1995.
27. H.A. Reijers. A Cohesion Metric for the Definition of Activities in a Workflow
Process. InProceedingsofthe8thCAiSE/IFIP8.1InternationalworkfloponEval-
uation of Modeling Methods in Systems Analysis and Design (EMMSAD 2003),
pages 116–125, 2003.
28. H.A. Reijers and I.T.P. Vanderfeesten. Cohesion and Coupling Metrics for Work-
flow Process Design. In J. Desel, B. Pernici, and M. Weske, editors, International
ConferenceonBusinessProcessManagement(BPM2004),volume3080ofLecture
Notes in Computer Science, pages 290–305. Springer-Verlag, Berlin, 2004.
29. M. Rosemann. Potential Pitfalls of Process Modeling: Part A. Business Process
Management Journal, 12(2):249–254, 2006.
30. M. Rosemann. Potential Pitfalls of Process Modeling: Part B. Business Process
Management Journal, 12(3):377–384, 2006.
31. R.W. Selby and V.R. Basili. Analyzing Error-Prone System Structure. IEEE
Transactions on Software Engineering, 17:141–152, 1991.
32. V.Y. Shen, T.-J. Yu, S.M. Thebaut, and L.R. Paulsen. Identifying Error-Prone
Software. IEEE Transactions on Software Engineering, 11:317–324, 1985.
33. I.Vanderfeesten,J.Cardoso,J.Mendling,H.A.Reijers,andW.M.P.vanderAalst.
Quality Metrics for Business Process Models. In L. Fischer, editor, BPM and
Workflow Handbook 2007, pages 179–190. Future Strategies, USA, May 2007.
34. I. Vanderfeesten, J. Cardoso, and H.A. Reijers. A Weighted Coupling Metric for
Business Process Models. In Johann Eder, Stein L. Tomassen, Andreas Opdahl,
Guttorm Sindre, editor, Proceedings of the CAiSE 2007 Forum, volume 247 of
CEUR Workshop Proceedings, pages 41–44, Trondheim, Norway, June 2007.
35. M. Xenos, D. Stavrinoudis, K. Zikouli, and D. Christodoulakis. Object-Oriented
Metrics - A Survey. In Proceedings of the FESMA 2000, Federation of European
Software Measurement Associations, pages 1–10, 2000.