User: I'm using RabbitMQ with Python/pika to distribute some batch jobs. So I think I have a very common scenario: One process fills a queue with jobs to be done. Multiple workers retrieve jobs, transform data and put the results in a second queue. Another single process retrives the results and merges them. The works very fine so far. But how do I stop my scripts in a controlled way? Is there some build in functionality to "invalidate" a queue, so that the works will be aware that no more jobs will be filled in?
Assistant: No, there is no way to find how many publishers are still publishing to a queue in AMQP.  You'll have to roll your own system.
A way to do this would be to have a fanout exchange that every worker binds a queue to (let's call it the "control" exchange), and have the publisher send a special message to it when it finishes.  Workers could then check their "control" queue to see if the publisher is still there; if it isn't and there are no more messages available, they can safely disconnect and shutdown.