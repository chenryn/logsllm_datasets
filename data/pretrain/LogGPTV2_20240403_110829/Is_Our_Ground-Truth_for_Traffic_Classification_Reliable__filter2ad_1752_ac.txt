24.63
0.00
100.00
0.00
100.00
80.56
82.44
0.00
78.92
77.28
0.23
96.16
98.01
4.31
99.18
98.66
99.58
0.00
0.00
0.00
0.00
0.00
0.05
0.02
0.02
91.21
0.08
0.16
0.66
0.08
0.00
8.45
0.00
5.03
0.00
0.00
0.00
24.12
8.90
0.47
0.23
1.85
0.00
95.67
0.76
0.00
0.00
4.43
4.41
4.29
4.41
4.30
0.70
0.94
0.91
8.79
0.87
1.01
99.34
33.26
75.37
91.55
0.00
94.97
0.00
19.44
17.56
75.88
12.18
22.25
99.53
1.99
1.99
0.02
0.06
1.34
0.42
Libprotoident
NBAR
Libprotoident
NBAR
Table 4. HTTP sub-classiﬁcation by NDPI
Application % correct % wrong % unclassiﬁed
Google
Facebook
Youtube
Twitter
97.28
100.00
98.65
99.75
2.72
0.00
0.45
0.00
0.00
0.00
0.90
0.25
Another sub-classiﬁcation that can be studied with our dataset is the FLASH
traﬃc over HTTP. However, the classiﬁcation of this application is diﬀerent for
each tool making its comparison very diﬃcult. PACE, OpenDPI and NDPI have
a speciﬁc pattern for this application. At the same time, these tools (as well as
L7-ﬁlter) have speciﬁc patterns for video traﬃc, which may or may not run over
HTTP. In addition, NDPI has speciﬁc labels for Google, Youtube and Facebook
that can also carry FLASH traﬃc. Libprotoident and NBAR do not provide any
pattern to classify FLASH traﬃc over HTTP. Table 5 shows that NDPI can
correctly classify 99.48 % of this traﬃc, 25.48 % of which is classiﬁed as Google,
Youtube or Facebook. PACE and OpenDPI can properly classify around 86 % of
the traﬃc. The errors produced in the classiﬁcation are almost always related to
traﬃc classiﬁed as HTTP with the exception of L7-ﬁlter that classiﬁes 86.49 %
of the traﬃc as ﬁnger.
Table 5. FLASH evaluation
Classiﬁer % correct % wrong % unclassiﬁed
PACE
OpenDPI
L7-ﬁlter
NDPI
Libprotoident
NBAR
86.27
86.34
0.07
99.48
0.00
0.00
13.18
13.15
99.67
0.26
98.07
100.00
0.55
0.51
0.26
0.26
1.93
0.00
106
V. Carela-Español, T. Bujlow, and P. Barlet-Ros
4 Discussion
This section extracts the outcomes from the results obtained during the perfor-
mance comparison. Also, we discuss the limitations of our study. Table 6 presents
the summary of the results from Section 3. The Precision (i.e., ﬁrst column) is
computed similarly to Section 3, but we take into account all the applications
together (i.e., 100 * # correctly classiﬁed ﬂows / # total ﬂows). However, this
metric is dependent on the distribution of the dataset. Because of that, we also
compute a second metric, the Average Precision. This statistic is independent
from the distribution and is calculated as follow:
Avg. P recision =
(cid:2)N
i=1
correctly classif ied i f lows
total i f lows
N
(1)
where N is the number of applications studied (i.e., N = 10).
As it can be seen in Table 6, PACE is the best classiﬁer. Even while we were
not using the last version of the software, PACE was able to properly classify
94 % of our dataset. Surprisingly for us, Libprotoident achieves similar results,
although this tool only inspect the ﬁrst four bytes of payload for each direction.
On the other hand, L7-ﬁlter and NBAR perform poorly in classifying the traﬃc
from our dataset. The more fair metric, Avg. Precision, presents similar results.
PACE is still the best classiﬁer, however, it has increased the diﬀerence by several
points to the second best classiﬁer, Libprotoident. Unlike before, NDPI is almost
as precise as Libprotoident with this metric. L7-ﬁlter and NBAR are still the
tools that present the worst performance.
Table 6. Summary
Classiﬁer % Precision % Avg. Precision
PACE
OpenDPI
L7-ﬁlter
NDPI
Libprotoident
NBAR
94.22
52.67
30.26
57.91
93.86
21.79
91.01
72.35
38.13
82.48
84.16
46.72
Nonetheless, the previous conclusions are obviously tied to our dataset. Al-
though we have tried our best to emulate the real behavior of the users, many
applications, behaviors and conﬁgurations are not represented on it. Because
of that, it has some limitations. In our study we have evaluated 10 well-known
applications, however adding more applications as Skype or Spotify is part of
our ongoing future work. The results obtained from the diﬀerent classiﬁers are
directly related to those applications. Thus, the introduction of diﬀerent ap-
plications could arise diﬀerent outcomes. The traﬃc generated for building the
dataset, although has been manually and realistically created, is artiﬁcial. The
backbone traﬃc would carry diﬀerent behaviors of the applications that are not
fully represented in our dataset (e.g., P2P clients running on port 80). Therefore,
Is Our Ground-Truth for Traﬃc Classiﬁcation Reliable?
107
the performance of the tools studied could not be directly extrapolated from the
current results, but it gives an idea of their precision in the evaluated set of ap-
plications. At the same time, the artiﬁcially created traﬃc allowed us to publish
the dataset with full packet payloads.
5 Conclusions
This paper presents the ﬁrst step towards validating the reliability of the accu-
racy of the network traﬃc classiﬁers. We have compared the performance of six
tools (i.e., PACE, OpenDPI, L7-ﬁlter, NDPI, Libprotoident, and NBAR), which
are usually used for the traﬃc classiﬁcation. The results obtained in Section 3
and further discussed in Section 4 show that PACE is, on our dataset, the most
reliable solution for traﬃc classiﬁcation. Among the open-source tools, NDPI
and especially Libprotoident present the best results. On the other hand, NBAR
and L7-ﬁlter present several inaccuracies that make them not recommendable
as a ground-truth generator.
In order to make the study trustworthy, we have created a dataset using
VBS [13]. This tool associates the name of the process to each ﬂow making its
labeling totally reliable. The dataset of more than 500 K ﬂows contains traﬃc
from popular applications like HTTP, Edonkey, BitTorrent, FTP, DNS, NTP,
RDP, NETBIOS, SSH, and RDP. The total amount of data properly labeled is
32.61 GB. Furthermore, and more important, we release to the research commu-
nity this dataset with full payload, so it can be used as a common reference for
the comparison and validation of network traﬃc classiﬁers.
As the future work, we plan to extend this work by adding new applications
to the dataset (e.g., Skype, Games) and especially focus on HTTP-based appli-
cations. We also plan to introduce new tools to the study (e.g., NBAR2).
References
1. Dainotti, A., et al.: Issues and future directions in traﬃc classiﬁcation. IEEE Net-
work 26(1), 35–40 (2012)
2. Valenti, S., Rossi, D., Dainotti, A., Pescapè, A., Finamore, A., Mellia, M.: Re-
viewing Traﬃc Classiﬁcation. In: Biersack, E., Callegari, C., Matijasevic, M. (eds.)
Data Traﬃc Monitoring and Analysis. LNCS, vol. 7754, pp. 123–147. Springer,
Heidelberg (2013)
3. Fukuda, K.: Diﬃculties of identifying application type in backbone traﬃc. In: Int.
Conf. on Network and Service Management (CNSM), pp. 358–361. IEEE (2010)
4. Carela-Español, V., et al.: Analysis of the impact of sampling on NetFlow traﬃc
classiﬁcation. Computer Networks 55, 1083–1099 (2011)
5. Alcock, S., et al.: Libprotoident: Traﬃc Classiﬁcation Using Lightweight Packet
Inspection. Technical report, University of Waikato (2012)
6. Gringoli, F., et al.: Gt: picking up the truth from the ground for internet traﬃc.
ACM SIGCOMM Computer Communication Review 39(5), 12–18 (2009)
7. Dainotti, A., et al.: Identiﬁcation of traﬃc ﬂows hiding behind TCP port 80. In:
IEEE Int. Conf. on Communications (ICC), pp. 1–6 (2010)
108
V. Carela-Español, T. Bujlow, and P. Barlet-Ros
8. Karagiannis, T., et al.: Transport layer identiﬁcation of P2P traﬃc. In: 4th ACM
Internet Measurement Conf. (IMC), pp. 121–134 (2004)
9. Shen, C., et al.: On detection accuracy of L7-ﬁlter and OpenDPI. In: 3rd Int. Conf.
on Networking and Distributed Computing (ICNDC), pp. 119–123. IEEE (2012)
10. Alcock, S., Nelson, R.: Measuring the Accuracy of Open-Source Payload-Based
Traﬃc Classiﬁers Using Popular Internet Applications. In: IEEE Workshop on
Network Measurements (2013)
11. Dusi, M., et al.: Quantifying the accuracy of the ground truth associated with
Internet traﬃc traces. Computer Networks 55(5), 1158–1167 (2011)
12. [Online]: Traﬃc classiﬁcation at the Universitat Politècnica de Catalunya, UPC
BarcelonaTech (2013),
http://monitoring.ccaba.upc.edu/traffic_classification
13. Bujlow, T., et al.: Volunteer-Based System for classiﬁcation of traﬃc in com-
puter networks. In: 19th Telecommunications Forum TELFOR, pp. 210–213. IEEE
(2011)
14. [Online]: Volunteer-Based System for Research on the
Internet
(2012),
http://vbsi.sourceforge.net/
15. Bujlow, T., et al.: Comparison of Deep Packet Inspection (DPI) Tools for Traﬃc
Classiﬁcation. Technical report, UPC BarcelonaTech (2013)