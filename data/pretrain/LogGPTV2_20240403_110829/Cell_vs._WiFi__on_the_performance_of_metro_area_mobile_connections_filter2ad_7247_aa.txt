title:Cell vs. WiFi: on the performance of metro area mobile connections
author:Joel Sommers and
Paul Barford
Cell vs. WiFi: On the Performance of Metro Area Mobile
Connections
Joel Sommers
Colgate University
PI:EMAIL
Paul Barford
University of Wisconsin
PI:EMAIL
ABSTRACT
Cellular and 802.11 WiFi are compelling options for mobile Inter-
net connectivity. The goal of our work is to understand the per-
formance afforded by each of these technologies in diverse en-
vironments and use conditions.
In this paper, we compare and
contrast cellular and WiFi performance using crowd-sourced data
from Speedtest.net. Our study considers spatio-temporal per-
formance (upload/download throughput and latency) using over 3
million user-initiated tests from iOS and Android apps in 15 dif-
ferent metro areas collected over a 15 week period. Our basic per-
formance comparisons show that (i) WiFi provides better absolute
download/upload throughput, and a higher degree of consistency in
performance; (ii) WiFi networks generally deliver lower absolute
latency, but the consistency in latency is often better with cellular
access; (iii) throughput and latency vary widely depending on the
particular access type (e.g., HSPA, EVDO, LTE, WiFi, etc.) and
service provider. More broadly, our results show that performance
consistency for cellular and WiFi is much lower than has been re-
ported for wired broadband. Temporal analysis shows that average
performance for cell and WiFi varies with time of day, with the best
performance for large metro areas coming at non-peak hours. Spa-
tial analysis shows that performance is highly variable across metro
areas, but that there are subregions that offer consistently better per-
formance for cell or WiFi. Comparisons between metro areas show
that larger areas provide higher throughput and lower latency than
smaller metro areas, suggesting where ISPs have focused their de-
ployment efforts. Finally, our analysis reveals diverse performance
characteristics resulting from the rollout of new cell access tech-
nologies and service differences among local providers.
Categories and Subject Descriptors
C.2.1 [Network Architecture and Design]: Wireless communica-
tion; C.4 [Performance of Systems]: Performance attributes; C.4
[Performance of Systems]: Measurement Techniques
General Terms
Design, Experimentation, Measurement, Performance
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
IMC’12, November 14–16, 2012, Boston, Massachusetts, USA.
Copyright 2012 ACM 978-1-4503-XXXX-X/12/11 ...$15.00.
Keywords
Cellular, WiFi
1.
INTRODUCTION
Over the last ﬁve years there has been an explosion in the avail-
ability and use of mobile devices that are both cellular and 802.11
WiFi enabled. The combination of a short range, high-speed capa-
bility and a longer range, lower speed capability is compelling and
enables a wide range of new mobile applications. Driven by the
popularity of applications that run on hybrid cell phones such as
the iPhone and Android-based devices, there is a large and growing
demand for bandwidth by mobile users.
A vexing problem for WiFi enabled cell phone users, service
providers and application designers is seeking out and supporting
the connectivity option that provides the best and most reliable per-
formance. Over shorter time scales issues that affect performance
include local availability of services, load at a particular site, char-
acteristics of the handset, and interference. Over longer time scales,
performance is affected by issues such as the ongoing introduction
of new technology and deployment of new service provider infras-
tructure.
To assist users in the effort of understanding their connectivity
options, a number of commercial and open-source throughput test-
ing applications are available. When invoked, these applications at-
tempt to determine the maximum bandwidth for both uploads and
downloads from the target device. At basis, these applications send
streams of random bytes via HTTP (e.g., data blobs through GET
and POST methods) between the target device and a test server.
The receiving application measures the bits/second received over
small time periods (e.g., one second) and reports the highest sus-
tained rate that is achieved. Details of the speciﬁc mechanisms for
selecting sending rates, measurements and reporting vary between
applications. However, data gathered by these applications offer
the possibility to provide unique insights into mobile device per-
formance.
In this paper, we describe an investigation of mobile device per-
formance using crowd-sourced data provided by one of the most
popular and widely deployed mobile bandwidth testers, Speedtest.
net [7]. This unique and rich data set includes information about
the device operating system used for the test (iOS or Android), a
unique handset identiﬁer, GPS coordinates of the mobile device,
time of test, upload and download speeds achieved, etc. Of equal
importance is the fact that Speedtest servers are deployed in over
600 locations world wide and are used by tens of thousands of users
on a daily basis.
The focus of our study is to understand the spatio-temporal char-
acteristics of performance of WiFi-enabled cell phones in a selec-
tion of metro areas with different population densities and diverse
geographic characteristics. We seek answers to basic questions
such as: what is the relative performance of cellular vs. WiFi in
a given geographic area? How does performance vary across local
access providers, and how does cell and WiFi performance vary in
sub-regions within the metro area? How does cellular and WiFi
performance vary temporally in the metro area and in sub-regions
within those areas? How consistent is performance for individual
users over time? What speciﬁc features in the data differentiate
observed performance? The long-term goal of our work is to for-
mulate conclusions about the spatio-temporal aspects of WiFi en-
abled cell phone performance that will lead to improvements in the
relevant protocols, conﬁgurations, and infrastructure.
Our evaluation indicates a rich yet complex set of characteristics
of spatio-temporal performance of mobile devices in a metro area.
As expected, we ﬁnd absolute WiFi download and upload perfor-
mance to be superior to cellular performance in most areas, and
that WiFi exhibits a higher degree of performance consistency. We
also ﬁnd that WiFi latency measurements are at least a factor of two
lower than cell latency in all areas, but that different providers can
exhibit vastly different latency characteristics, and consistency in
latency is often better with cellular access. Further, the absolute la-
tency difference between cell and WiFi tends to be smaller in larger
metro areas and the overall variability in latency is lower, suggest-
ing that greater efforts have been made to optimize those cellular
deployments. Although we ﬁnd cell performance in large metro ar-
eas superior to performance in other areas, throughput and latency
performance measures vary widely depending on the speciﬁc ac-
cess type and service provider. Furthermore, we observe that while
new cellular access technologies such as 4G LTE offer throughput
speeds comparable to WiFi, the upload performance consistency is
currently low, suggesting that these deployments are not yet fully
optimized. More generally, our results show that performance con-
sistency for cellular and WiFi is signiﬁcantly lower than has been
reported for wired broadband access. Our results also show that
based on trends toward higher throughput cellular access technolo-
gies, connectivity decisions based solely on throughput may not be
obvious in the future.
Recognizing the diversity of physical and IT infrastructures and
time variations in usage patterns within a given metro area, our
analysis includes evaluations of subareas over a variety of time win-
dows. Our results show that download/upload performance in sub-
areas follows a standard diurnal cycle but is highly variable. Specif-
ically, we ﬁnd that while WiFi performance tends to be more uni-
form across subareas, cell performance in subareas shows higher
variability and there are fewer instances of subareas with consis-
tently good performance. We ﬁnd that subareas with consistently
poor performance tend to be more localized in large metro areas for
both cell and WiFi. These results have implications for both users
and operators in terms of expectations for performance in both ﬁxed
and vehicular settings, for diagnosis of performance degradation
and for future provisioning.
2. DATA
In this section we describe the unique data set that forms the basis
of our study. We discuss Speedtest’s deployment and performance
measurement system. We also describe the Speedtest data that are
the focus of our study and provide information about the metro
areas in which the data were collected. Finally, we discuss how
conclusions drawn from the data sets can be inﬂuenced by the areas
and methods used for collection.
Figure 1:
Speedtest application is started on a client system.
Packet exchange protocol
initiated when the
2.1 Speedtest Overview
Speedtest.net [7] is a bandwidth/performance evaluation plat-
form that is managed and maintained by Ookla, Inc. [6]. The ap-
plication can be run via a ﬂash-based web site, and native apps
are available for both Apple iOS-based devices (including iPod
touches, iPhones, and iPads) and Android-based devices (includ-
ing a variety of phones manufactured by HTC, Motorola, Samsung,
and Sony Ericsson, among many others). Over 3B performance
tests have been run since Speedtest began in 2006, with a signiﬁ-
cant increase in use over the past twelve months. Daily tests exceed
125K per day, globally.
Each Speedtest is initiated by the client (either a browser or mo-
bile app) as shown in Figure 1. Upon invocation, a test request
is directed to the Speedtest server that is deemed to be geographi-
cally nearest to the client. There are servers deployed in over 600
locations world wide. Per the Speedtest wiki [5], latency, down-
load, and upload tests are conducted via HTTP (TCP port 80). La-
tency tests are based on request/response pairs with the average
of 10 RTT ping-style tests reported for the latency measurement.
Speedtest refers to the download and upload tests as “throughput
tests”, since their focus is on reporting download/upload speeds by
transferring small ﬁles between client and server.
A download test begins with an initial transfer of a ﬁxed-size
ﬁle from server to client to establish an estimate for throughput.
This initial test results in selection of another ﬁle that will be used
for generating ﬁnal test results. The size of the second ﬁle varies:
smaller ﬁles are used when the initial estimate suggests lower band-
width and larger ﬁles are used when the initial estimate suggests
more bandwidth. The target test ﬁle is then transferred repeatedly
(using naming tricks to prevent client caching) using up to 8 paral-
lel HTTP threads (a conﬁgurable option). Throughput estimates
based on these ﬁle transfers are provided at up to 30 times per
second. The top 10% and bottom 30% of the throughput samples
are discarded and the remaining samples are averaged to derive a
throughput sample. The reason for this kind of sampling is to try
to remove burst effects due to OS overhead and other effects and
arrive at a maximum throughput estimate that corresponds to the
expected case for the user. Test runs are tuned to be relatively short
(maximum of tens of seconds) to enhance user experience. Upload
tests are conducted in a similar fashion. We note that in prior work,
Bauer et al. [12] found that the Speedtest method results in a fairly
accurate characterization of last-mile performance.
In this work, we consider data collected from tests initiated from
the iOS and Android apps. Each full test results in a rich log entry at
Table 1: Summaries of census and Speedtest data from the 15 target metro areas that are the subject of our evaluation. Speedtest
data are for the period from February 21, 2011 to June 5, 2011. US census data are from [14], European census data are from [28],
Asian census data are from [1, 3, 4], and non-US per capita income (PCI) data are from [11].
Location (market type)
Pop. Metro Rank
Annual PCI
New York, NY (large)
Los Angeles, CA (large)
Chicago, IL (large)
Columbia, SC (medium)
Syracuse, NY (medium)
Madison, WI (medium)
Jackson, TN (small)
Lawrence, KS (small)
Missoula, MT (small)
Manchester, UK (europe)
Brussels, BE (europe)
Belgrade, SP (europe)
Palembang, ID (asia)
Almaty, KZ (asia)
Ulaanbaatar, MN (asia)
18.9M
12.8M
9.5M
768K
663K
569K
115K
111K
109K
2.2M
1.8M
1.6M
1.5M
1.4M
1.1M
1
2
3
70
80
89
321
329
331
N/A
N/A
N/A
N/A
N/A
N/A
$50.8K
$45.9K
$51.0K
$41.7K
$39.8K
$49.2K
$36.6K
$37.5K
$34.4K
$41.4K
$45.2K
$6.0K
$2.0K
$6.9K
$1.6K
Unique
handsets
89,356
150,804
27,018
4,931
6,122
8,549
5,117
3,231
860
80,211
22,624
3,849
415
1,949
673
iOS
# WiFi
tests
246,222
425,197
62,997
11,553
16,801
23,995
13,742
8,164
2,479
291,564
48,085
11,606
743
4,821
1,861
# cell
tests
78,729
105,901
12,084
3,138
3,627
3,853
3,034
1,893
604
30,810
11,033
1,477
621
1,674
275
Unique
handsets
97,994
174,221
41,482
6,779
5,165
6,718
2,645
3,917
526
32,221