title:PUFs in Security Protocols: Attack Models and Security Evaluations
author:Ulrich R&quot;uhrmair and
Marten van Dijk
2013 IEEE Symposium on Security and Privacy
PUFs in Security Protocols: Attack Models and Security Evaluations
Ulrich R¨uhrmair
Computer Science Department
Technische Universit¨at M¨unchen
80333 M¨unchen, Germany
PI:EMAIL
Marten van Dijk
CSAIL
MIT
Cambridge, Massachusetts
PI:EMAIL
Abstract—In recent years, PUF-based schemes have not
only been suggested for the basic security tasks of tamper
sensitive key storage or system identiﬁcation, but also for
more complex cryptographic protocols like oblivious transfer
(OT), bit commitment (BC), or key exchange (KE). In these
works, so-called “Strong PUFs” are regarded as a new, fun-
damental cryptographic primitive of their own, comparable to
the bounded storage model, quantum cryptography, or noise-
based cryptography. This paper continues this line of research,
investigating the correct adversarial attack model and the
actual security of such protocols.
In its ﬁrst part, we deﬁne and compare different attack
models. They reach from a clean, ﬁrst setting termed the
“stand-alone, good PUF model” to stronger scenarios like the
“bad PUF model” and the “PUF re-use model”. We argue why
these attack models are realistic, and that existing protocols
would be faced with them if used in practice. In the second part,
we execute exemplary security analyses of existing schemes in
the new attack models. The evaluated protocols include recent
schemes from Brzuska et al. published at Crypto 2011 [1]
and from Ostrovsky et al. [18]. While a number of protocols
are certainly secure in their own, original attack models, the
security of none of the considered protocols for OT, BC, or KE
is maintained in all of the new, realistic scenarios.
One consequence of our work is that the design of advanced
cryptographic PUF protocols needs to be strongly reconsidered.
Furthermore, it suggests that Strong PUFs require additional
hardware properties in order to be broadly usable in such
protocols: Firstly, they should ideally be “erasable”, meaning
that single PUF-responses can be erased without affecting other
responses. If the area efﬁcient implementation of this feature
turns out to be difﬁcult, new forms of Controlled PUFs [8] (such
as Logically Erasable and Logically Reconﬁgurable PUFs [13])
may sufﬁce in certain applications. Secondly, PUFs should be
“certiﬁable”, meaning that one can verify that the PUF has been
produced faithfully and has not been manipulated in any way
afterwards. The combined implementation of these features
represents a pressing and challenging problem, which we pose
to the PUF hardware community in this work.
Keywords-(Strong) Physical Unclonable Functions; (Strong)
PUFs; Attack Models; Oblivious Transfer; Bit Commitment;
Key Exchange; Erasable PUFs; Certiﬁable PUFs
I. INTRODUCTION
Today’s electronic devices are mobile, cross-linked and
pervasive, which makes them a well-accessible target for
adversaries. The well-known protective cryptographic tech-
niques all rest on the concept of a secret binary key: They
1081-6011/13 $26.00 © 2013 IEEE
DOI 10.1109/SP.2013.27
286
is, and remains, unknown to an adversary. It
presuppose that devices store a piece of digital information
that
turns
out that this requirement is difﬁcult to realize in practice.
Physical attacks such as invasive, semi-invasive or side-
channel attacks carried out by adversaries with one-time
access to the devices, as well as software attacks like
application programming interface (API) attacks, viruses or
Trojan horses, can lead to key exposure and security breaks.
As Ron Rivest emphasized in his keynote talk at CRYPTO
2011 [21], merely calling a bit string a “secret key” does
not make it secret, but rather identiﬁes it as an interesting
target for the adversary.
Indeed, one main motivation for the development of
Physical Unclonable Functions (PUFs) was their promise
to better protect secret keys. A PUF is an (at least partly)
disordered physical system P that can be challenged with so-
called external stimuli or challenges c, upon which it reacts
with corresponding responses r. Contrary to standard digital
systems, these responses depend on the micro- or nanoscale
structural disorder of the PUF. It is assumed that this disorder
cannot be cloned or reproduced exactly, not even by the
PUF’s original manufacturer, and that it is unique to each
PUF. Any PUF P thus implements a unique and individual
function fP that maps challenges c to responses r = fP (c).
Thereby the tuples (c, r) are usually called the challenge-
response pairs (CRPs) of the PUF.
Due to its complex internal structure, a PUF can avoid
some of the shortcomings of classical digital keys. It is usu-
ally harder to read out, predict, or derive PUF-responses than
to obtain digital keys that are stored in non-volatile memory.
The PUF-responses are only generated when needed, which
means that no secret keys are present permanently in the
system in an easily accessible digital form. Finally, certain
types of PUFs are naturally tamper sensitive: Their exact
behavior depends on minuscule manufacturing irregularities,
often in different layers of the IC. Removing or penetrating
these layers will automatically change the PUF’s read-out
values. These facts have been exploited in the past for
different PUF-based security protocols. Prominent examples
include identiﬁcation [20], [9], key exchange [20], and vari-
ous forms of (tamper sensitive) key storage and applications
thereof, such as intellectual property protection or read-proof
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:54:17 UTC from IEEE Xplore.  Restrictions apply. 
memory [11], [15], [31].
In recent years, however, also the use of PUFs in more ad-
vanced cryptographic protocols together with formal security
proofs has been investigated. In these protocols, PUFs with
a very large challenge set and a freely accessible challenge-
response interface are employed. This type of PUF some-
times has been referred to as Physical Random Function [9]
or Strong PUF [11], [29], [28], [23] in the literature (see
also Appendix A). 1 The (Strong) PUF is used similar to a
“physical random oracle” in these protocols, which is passed
on between the parties, and which can be read-out exactly by
the very party who currently holds physical possession of it.
Its input-output behavior is assumed to be so complex that its
response to a randomly chosen challenge cannot be predicted
numerically and without direct physical measurement, not
even by a person who had physical access to the Strong
PUF at earlier points in time.
In 2010, R¨uhrmair [22] showed that oblivious transfer
can be realized between two parties by physically trans-
ferring a Strong PUF in this setting. He observed that via
the classical reductions of Kilian [14], this implies PUF-
based bit commitment and PUF-based secure multi-party
computations. In the same year, the ﬁrst formal security
proof for a Strong PUF protocol was provided by R¨uhrmair,
Busch and Katzenbeisser [23]. They present deﬁnitions and
a reductionist security proof for Strong PUF based identiﬁca-
tion. In 2011, R¨uhrmair, Jaeger and Algasinger [26] discuss
an attack on a PUF-based session key exchange scheme
of Tuyls and Skoric [32], in which the scheme is broken
under the provision that it is executed several times and
that the adversary gains access to the PUF more than once.
Their attack motivated our PUF re-use model. At CRYPTO
2011 Brzuska, Fischlin, Schr¨oder and Katzenbeisser [1]
adapted Canetti’s universal composition (UC) framework
[3] to include PUFs, giving PUF-protocols for oblivious
transfer (OT), bit commitment (BC), and key exchange (KE).
At CHES 2012, R¨uhrmair and van Dijk [25] presented a
quadratic attack on Brzuska et al.’s OT- and BC-protocols,
showing that their security is not maintained if optical PUFs
or electrical PUFs with challenge length of 64 bits are
used in their implementation. Two very recent eprint papers
continue this general
line of work: Ostrovsky, Scafuro,
Visconti and Wadia [18] 2 investigate the use of so-called
“malicious PUFs”, and furthermore extend Brzuska et al.’s
communication model in the UC framework.In independent
and simultaneous work, van Dijk and R¨uhrmair proposed a
model equivalent to “malicious PUFs” under the name “bad
PUF model”, and a new attack model termed “PUF re-use
model”. The authors devise the ﬁrst impossibility results for
1We stress that the Weak/Strong PUF terminology, which was originally
introduced by Guajardo, Kumar, Schrijen and Tuyls [11], is certainly not
meant or to be misunderstood in a judgemental or pejorative manner.
2This paper has been accepted at Eurocrypt 2013 very recently, but we
had only access to the eprint version [18] at the time of writing.
PUF-protocols in these two models [6].
While the body of work on (Strong) PUFs in crypto-
graphic protocols is obviously growing, most papers use
different implicit attack models, making it difﬁcult to com-
pare their results. There are situations where practically
relevant attacks exist on protocols that are provably secure
in other, perhaps mainly theoretical models. This motivates
a comparative, systematic study of attack models.
Scope of this Work: This paper continues the above
line of research. It investigates the UC-models of Brzuska
et al. [1] and Ostrovsky et al. [18], and introduces several
other, practically relevant attack scenarios. These include the
“stand-alone, good PUF model”, the “bad PUF model”,
and the “PUF re-use model”:
1) In the stand-alone, good PUF model, we assume that
there is only one single, isolated protocol execution,
and that all parties faithfully generate and never ma-
nipulate PUF hardware.
2) In the PUF re-use model, we extend this setting, and
allow adversaries multiple access to PUFs. Its mildest
form is the so-called one-time posterior access model
(PAM), which allows one-time access to the PUF after
a given protocol, and delimits the adversary to mere
CRP-measurement on the PUF.
3) In the bad PUF model, we allow fraudulent parties and
adversaries to manipulate PUF hardware and to use so-
called “bad PUFs”. These are PUFs which look like a
normal PUF from the outside, having a standard CRP-
interface etc., but which have extra properties that
allow cheating. A scenario equivalent to the bad PUF
model has been introduced under the name “malicious
PUFs” by Ostrovsky, Scafuro, Visconti and Wadia in
an eprint paper [18], their work being independent and
simultaneous to the ﬁrst publication of the bad PUF
model by van Dijk and R¨uhrmair in another eprint [6].
In order to illustrate the effect of the new models, we
carry out exemplary security analyses of several protocols
of Brzuska et al. [1] and Ostrovsky et al. [18] in the bad
PUF and PUF re-use model.
Our Results: Our analyses of existing protocols show
the following outcome.
1) A recent BC-protocol of Ostrovsky et al. [18] (which
we give in Appendix D) can be successfully attacked
in its own attack model of “malicious” or “bad” PUFs.
The attack is presented in Section III-E.
2) A recent OT protocol of Brzuska et al. [1] is insecure
in the PUF re-use model and in the bad PUF model.
The attacks are presented in Sections III-A and III-B.
3) A recent KE-protocol of Brzuska et al. [1] is insecure
in the PUF re-use model and in the combined PUF
re-use, bad PUF model. The respective attacks are
presented in Sections III-C and III-D.
The above, exemplary security evaluations are carried out in
full detail. In addition to that, we observe that several other
287
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:54:17 UTC from IEEE Xplore.  Restrictions apply. 
known PUF-protocols are insecure in the bad PUF and the
PUF re-use model. Since the attacks are very similar to the
abovementioned, we merely sketch them for space reasons
in Section III-F. They include the following:
4) An early OT-protocol of R¨uhrmair [22] and an early
KE-protocol by van Dijk [5] are insecure in the bad
PUF and the PUF re-use model (see Section III-F).
5) An OT-protocol of Ostrovsky et al. [18] is insecure in
the bad PUF and the PUF re-use model (see Section
III-F).
6) Two special BC-protocols of Ostrovsky et al. [18],
and consequently their construction for UC-secure
computation built on these two protocols, are inse-
cure in the bad PUF model, too (see Section III-F).
The attacks require the use of more complex bad
PUF constructions such as Communicating PUFs and
Marionette PUFs,
though (see Section II-E for an
explanation of the latter two).
Two important aspects should not go unnoticed. First,
apart from the attack on Ostrovsky et al.’s BC protocol
mentioned in item 1 above, all of the presented attacks are
outside the original attack models of the respective papers.
However, we argue in great detail in Section II why the
new attack scenarios must be considered realistic, and why
the protocols would be faced with them in any practically
relevant settings.
Secondly, our attacks in the bad PUF model require only
very mild forms of bad PUFs. The attack in item 1 utilizes a
bad PUF that implements a simple linear function (see Sec-
tion III-E). Furthermore, the attacks of items 2 to 5 merely
require so-called Challenge-Logging PUFs and Simulatable
PUFs. The only exception is the attack mentioned in item
6: It requires a more sophisticated type of PUFs, namely
Communicating PUFs (or special variants of it, such as
Marionette PUFs); see Section II-E.
Besides the above new ﬁndings, two already published
results should be added to complete the picture:
7) A PUF-based session key exchange protocol by
Tuyls and Skoric [32] has already been attacked by
R¨uhrmair, Algasinger and Jaeger [26] under conditions
similar to the PUF re-use model (without explicitly
using this term). Their attack partly motivated the
formal introduction of the PUF re-use model in this
paper.
8) There are quadratic attacks on the security of the OT-
and BC-protocol of Brzuska et al. [1] which have been
presented at CHES 2012 by R¨uhrmair and van Dijk
[25]. They show that the security of these protocols
is not maintained if optical PUFs or electrical PUFs
with challenge length of 64 bits are used in their
implementation.
As indicated by the above items (1) to (8), our analysis
focuses on the impact of our attack models for “advanced”
288
PUF protocols like OT, BC and KE. The elementary PUF use