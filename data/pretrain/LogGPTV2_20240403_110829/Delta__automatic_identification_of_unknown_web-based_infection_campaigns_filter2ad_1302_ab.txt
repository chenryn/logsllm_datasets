feature computation, but attach it to the vector as “external”
meta information that is not used during clustering. This
supports the detection of removal and insertion of the same
trend with the exact same cluster in both cases and, therefore,
increases robustness of our system.
The ∆-system does not provide detection capabilities for
malicious behavior on its own, but rather relies on an external
detection system. This detection system is queried once a
new cluster is formed to identify if this observed trend consti-
tutes a malicious or a benign cluster. In order to guarantee
a high likelihood, we “bootstrap” each cluster by querying for
10 random samples, and acquire a consensus decision for the
returned labels. For instance, a new cluster is observed and
9 out of 10 of the random samples from this cluster have been
assigned the label malicious, then the ∆-system will assign
the label malicious to any new observation in this cluster.
2.1.3
Signature Generation
For each of the identiﬁed trends, we generate a signa-
ture that matches the textual representation of all of the
nodes assigned to a cluster (e.g., a cluster describing “”). This signature is gen-
erated by simply interpreting the textual representation of
each node as a deterministic ﬁnite automaton, merging them
together, and calculating the minimal version, which can be
done in polynomial time. The resulting DFA can then be trans-
lated into a regular expression that can be used by intrusion
detection/prevention systems2.
Such an identifying signature is, generally, an under-approx-
imation of the actual (unknown) signature. For instance, in
the above example the URL is randomized. Here, the gener-
ated signature only describes the observed samples, i.e., where
$random-url might be “a.com” or “b.org”, while the trend
could be more general and also include “c.net”. Leveraging
only the identifying signature would miss web sites that fol-
low the same trend, i.e., web sites who might serve the same
infection vector. While this is of no concern in the case of
2Although generated signatures match normalized tags by
default, it is trivial to normalize incoming data in the same
way and match arbitrary tags that follow the same trend.
Parse to treeand normalize(section 2.1.1)Web site(current)Current version(DOM-tree)Base version(DOM-tree)Compute differencesvia fuzzy tree difference algorithm(section 2.1.2 and 3)Cluster feature vectorbased on similarity measures(section 2.1.2 and 4)Benign trendInfection campaignNew campaign?Generate signature(section 2.1.3 and 5.3) ...111leveraging the ∆-system for every request (here, we would
assign a similar, but unobserved, tag to the same cluster), it
can be an issue if the generated signature is used as input to
other tools. A possible remedy is to generalize the signature
and to introduce a widening operator to describe the diﬀerent
parts of the nodes following this trend. For instance, one could
simply widen 5 diﬀerent characters at the same position in
5 diﬀerent random samples picked from a cluster to an over-
approximating wildcard. An over-approximation, however, is
also likely to introduce incorrect matches, which is why we
recommend using the ∆-system if no exact signature matched.
2.2 Use Cases
We see the ∆-system to be deployed in two main scenarios:
next to a web crawler to actively search for new infection cam-
paigns, and next to a proxy to identify infection campaigns
(passive) or to improve user-protection (active). Additionally,
there is a third, minor scenario: providing feedback on evasions
of detection systems. Subsequently, we describe all three use
cases in more detail, however, in the remaining of the paper,
we focus on the ﬁrst use case: paired with a web crawler.
The most interesting use case, in our opinion, is the active
identiﬁcation of new infection campaigns. In this case, one
deploys the system side-by-side to a web crawler. While the
web crawler retrieves potentially interesting web sites multiple
times over a given period of time, our system analyzes the diﬀer-
ences. When our system detects a new cluster, i.e., a signiﬁcant
number of very similar modiﬁcations, an external detection
system then decides if this change is associated with malicious
behavior or not. If malicious behavior was introduced then
we found a new infection campaign and we can generate the
identifying signature for this cluster. Based on the elements
of the cluster, we can then pinpoint the infection vector (e.g.,
identify parts of the tag that are common among all web sites
in that cluster) and investigate other similarities manually
(e.g., only online stores running a speciﬁc version of the PHP
application osCommerce were infected). Starting from those
similarities, it is then possible to: generate a more precise
ﬁngerprint for the campaign, ﬁnd other infections via search
engines, and estimate the scope of an infection campaign.
The second envisioned deployment of the ∆-system is the ex-
tension of a web browser or a proxy. In most cases, the browser
or proxy already caches visited web sites for performance rea-
sons. Moreover, in security-sensitive environments, it is very
likely that a detection system (e.g., an anti-malware engine)
is already in place to ensure that only benign web sites can be
accessed by the user. Such a detection system can be leveraged
by the ∆-system to analyze inserted tags. The system can com-
plement these tools to prevent repetitive scanning of web sites,
to improve user experience by increasing analysis performance,
and to provide insight into targeted attacks. For example,
small changes a user might encounter include automatic page
impressions counter, updated weather or date information, or
the output of the processing time to render the web site on the
server’s side. While previous work requires the reevaluation of
the entire web site, the ∆-system can identify these changes
as benign much more easily.
It is even possible to obtain
more accurate results with our system than with the detection
system, e.g., if it is based upon simple detection methods, such
as ﬁngerprinting of known malicious scripts, or if the detection
system is being evaded. Additionally, once a malicious web
site is identiﬁed, the ∆-system can verify that a malicious
modiﬁcation was removed and that the web site is now benign.
Particularly, if an infection campaign is dormant or the exploit
page is oﬄine, dynamic analysis systems detect that the web
site is benign because it does not detect any malicious behavior.
Since the ∆-system is purely static and veriﬁes that the mali-
cious content was removed, it does not have this disadvantage.
Lastly, the ∆-system can also be leveraged to detect evasions
and bugs in detection systems and online analyzers. For exam-
ple, if the analyzer is dynamic, but behaves diﬀerently than
a standard browser in even a single case, then malware can
ﬁngerprint the detection system. Such a ﬁngerprinting method
allows the attacker to thwart detection much more easily, for
instance, without having to utilize a blacklist of the IP ad-
dresses used by the online analyzer. Leveraging our system, we
can detect these evasions when they are introduced. The sys-
tem can pinpoint the changed content precisely and, by doing
this, support the developer in identifying the reason why the
analyzer is behaving diﬀerently, correcting the corresponding
bug, and preventing further evasions leveraging the same bug.
3 FUZZY TREE DIFFERENCE
First, to be able to measure the similarity between two web
sites in a meaningful way, we need to deﬁne the notion of
diﬀerence. We are primarily concerned if a web site behaves in
a benign or malicious way. To this end, we need to understand
what modiﬁcations to the content can result in behavioral
changes, and how we can isolate the modiﬁcations from other
parts of the web site that have no eﬀect on the overall be-
havior. We identify these interesting parts by leveraging the
hierarchical structure of a web site and interpreting a web site
through its DOM tree.
Previous work introduced various algorithms to detect the
semantic change in hierarchical structured data. The main
idea behind HTML, i.e., describing how to display data instead
of describing the semantics of the data itself, renders nearly
all introduced XML-centered approaches unsuitable to extract
meaningful information about the modiﬁcations. An often
made assumption is that the underlying tree structure has a
signiﬁcant semantic relationship with the content, which is not
necessarily the case for HTML. Moreover, leveraging standard
maximum cardinality matching on cryptographic hashes and
simple edge weights of 1 (based in the nature of cryptographic
hash functions), any change would be visible, including very
small changes that are uninteresting to us, such as single char-
acter or word changes and legitimate evolutions. We denote
such a tree-to-tree comparison as not tiny change resistant or
not fuzzy. To solve this problem, and to identify interesting
modiﬁcations made to a web site more precisely and more
eﬃciently, we generalize the previous notion of tree diﬀerence
algorithms and introduce a similarity weight. We refer to
our algorithm as the fuzzy tree diﬀerence algorithm, which is
heavily inﬂuenced by the unordered tree-to-tree comparison
algorithms by Chawathe et al. [17] and Wang et al. [18]. Such
a fuzzy algorithm is necessary when comparing web sites that
have evolved over an extended period of time, e.g., have been
edited constantly over a two week period. Otherwise, the sheer
number of remaining nodes to analyze makes it infeasible to
leverage computationally expensive features with reasonable
performance overhead.
While we provide a formal description of the algorithm in
Algorithm 1, we give a brief informal description ﬁrst: the
algorithm expects three parameters, T1, T2 and tr. T1 and
T2 are normalized DOM trees, i.e., all tags are capitalized in
the same way, all attributes occur in the same order and their
values are enclosed in the same way (quote-wise). tr is the
threshold value for the similarity measurement, and can range
from 0 to 1. Starting from the trees T1 and T2, we create
a temporary graph to match pairs of similar nodes through
112maximum weighted bipartite graph matching (Hungarian algo-
rithm [19]). This graph is constructed by inserting every node
of T1, then inserting every node of T2. For each node from T2,
we connect it with an edge to every node from T1 that has a
similar fuzzy hash value (i.e., the Jaro distance of both hashes
must be greater or equal to tr) and that takes the exact same
path (in the sense of unordered tree-traversal) as the node
from T2. The edge’s weight is equal to the similarity measured
through the Jaro distance between both hashes (i.e., at least
tr). Additionally, we color all matched nodes blue. In the last
step, we remove the corresponding matched nodes from the
trees T1 and T2 and output a list of removed (remaining in
T1) and inserted (remaining in T2) nodes.
While the reason for coloring nodes might not be obvious,
later on, we leverage the color of a node in the remaining nodes
of T1 and T2 in our similarity measures to detect a matching
asymmetry, i.e., if a tag with a very similar hash and the same
path from the root node was matched, such as a template that
was used more often in T2 than in T1.
The implementation of the ∆-system under evaluation lever-
ages ssdeep [20] as the fuzzy hash function and a threshold
of 0.99 for the Jaro distance [21] (which is normalized to 0 to
1, i.e., we require very similar tags). Similar to cryptographic
hash functions like MD5 or SHA, a fuzzy hash function, such
as ssdeep, maps arbitrary long values to a short hash. In con-
trast to cryptographic hash function, however, a fuzzy hash
function maps similar values to similar hashes that can be
then used to measure their similarity. This property allows us
to eﬃciently compare nodes of the DOM tree or their content
regardless of their actual length, which otherwise might be
computational too expensive when using standard string sim-
ilarity measures for longer tags or content. We selected the
Jaro distance function to compare two hash values because
it is a simple string similarity measure originally introduced
for duplicate detection by Jaro [21] and best suited for short
strings while accounting for exactly matched characters as
well as transpositions, therefore it quantiﬁes the similarity of
fuzzy hashes for similar data accurately.
In general, a threshold value of 1 when used with a crypto-
graphic hash function is equivalent to standard unordered tree-
to-tree algorithms. On the other hand, a threshold value of 0
regardless of the hash function is equivalent to comparing every
element to every other element and impractical for any modern
web site due to the sheer number of possible combinations,
which is why a reduction of potential matches is essential.
3.1 Example
An example of the tree diﬀerence algorithm is shown in
Figure 2. The source code of a simple base version and current
version of a web site are shown in Listing 1 and Listing 2 respec-
tively. Two modiﬁcations to the source code were made: ﬁrst,
a head tag including a script tag with an external source URL
was inserted, and, second, a typographical mistake in the class
of the p tag was ﬁxed and one word in its content was changed:
“foo” was replaced by “bar”. Figure 2 illustrates that for a
standard tree diﬀerence algorithm the modiﬁed p tag would,
correctly, constitute a modiﬁed p tag (the removed p tag is
marked with a red chessboard pattern, while the inserted p tag
is marked with a green diagonal pattern). However, since we
are interested in severe changes and modiﬁcations associated
with behavioral changes, these tiny changes are uninteresting
to us, and, like the example shows, they are discarded by our
algorithm.
Algorithm 1 Fuzzy Tree Diﬀerence
G ← Graph
for all n ∈ T1.nodes do
for all n ∈ T2.nodes do
G ← G.insert node(n)
for all m ∈ T1.nodes do
if path(m) = path(n) then
d(m,n) ← jaro(hash(m), hash(n))
if d(m,n) ≥ tr then
G.insert node(n)
m.color ← blue
n.color ← blue
G.insert edge(m, n, d(m,n))
1 function FuzzyTreeDifference(T1, T2, tr)
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
4 SIMILARITY MEASURES / FEATURES
The most interesting part of web sites from a malicious code
point of view is described by the HTML markup language:
JavaScript, inline frames, or the use of plugins. Most research
on document similarity, however, assumes that markup lan-
guage is not of major interest and that it can be removed
without substantial loss of information. For detecting infec-
tion vectors, this assumption does not hold. Essentially, this
violation makes applying existing work in document similar-
ity for identifying infection vectors impractical, because core
elements are discarded.
M ← max weight matching(G)
for all (m, n) ∈ M do
T1.remove node(m)
T2.remove node(n)
return T1, T2
Therefore, we introduce our own similarity measures. Once
we have extracted the diﬀerent tags between two versions of
a web site, we can map each tag into the feature space in
which we cluster similar changes together. In this section, we
describe the features we are using and the intuition behind
them. Each of our features we apply on multiple levels (where
applicable): the whole tag and for every value of its attributes.
4.1 Template Propagation
First, we introduce the template propagation measure, a
binary feature that simply models what content was intro-
duced or removed from the web site in terms of their similarity
to previous DOM tree nodes, i.e., it captures the concept of
reused templates by checking if a node exist already in the
base version, but are unmatched, e.g., because there are more