**图 10-1 具有三个 Mapper 和三个 Reducer 的 MapReduce 任务**
在大多数情况下，应该在 Mapper 任务中执行的应用程式码在将要执行它的机器上还不存在，所以 MapReduce 框架首先将程式码（例如 Java 程式中的 JAR 档案）复制到适当的机器。然后启动 Map 任务并开始读取输入档案，一次将一条记录传入 Mapper 回拨函式。Mapper 的输出由键值对组成。
计算的 Reduce 端也被分割槽。虽然 Map 任务的数量由输入档案块的数量决定，但 Reducer 的任务的数量是由作业作者配置的（它可以不同于 Map 任务的数量）。为了确保具有相同键的所有键值对最终落在相同的 Reducer 处，框架使用键的杂凑值来确定哪个 Reduce 任务应该接收到特定的键值对（请参阅 “[根据键的杂凑分割槽](ch6.md#根据键的杂凑分割槽)”）。
键值对必须进行排序，但资料集可能太大，无法在单台机器上使用常规排序演算法进行排序。相反，分类是分阶段进行的。首先每个 Map 任务都按照 Reducer 对输出进行分割槽。每个分割槽都被写入 Mapper 程式的本地磁碟，使用的技术与我们在 “[SSTables 与 LSM 树](ch3.md#SSTables和LSM树)” 中讨论的类似。
只要当 Mapper 读取完输入档案，并写完排序后的输出档案，MapReduce 排程器就会通知 Reducer 可以从该 Mapper 开始获取输出档案。Reducer 连线到每个 Mapper，并下载自己相应分割槽的有序键值对档案。按 Reducer 分割槽，排序，从 Mapper 向 Reducer 复制分割槽资料，这一整个过程被称为 **混洗（shuffle）**【26】（一个容易混淆的术语  —— 不像洗牌，在 MapReduce 中的混洗没有随机性）。
Reduce 任务从 Mapper 获取档案，并将它们合并在一起，并保留有序特性。因此，如果不同的 Mapper 生成了键相同的记录，则在 Reducer 的输入中，这些记录将会相邻。
Reducer 呼叫时会收到一个键，和一个迭代器作为引数，迭代器会顺序地扫过所有具有该键的记录（因为在某些情况可能无法完全放入记忆体中）。Reducer 可以使用任意逻辑来处理这些记录，并且可以生成任意数量的输出记录。这些输出记录会写入分散式档案系统上的档案中（通常是在跑 Reducer 的机器本地磁碟上留一份，并在其他机器上留几份副本）。
#### MapReduce工作流
单个 MapReduce 作业可以解决的问题范围很有限。以日志分析为例，单个 MapReduce 作业可以确定每个 URL 的页面浏览次数，但无法确定最常见的 URL，因为这需要第二轮排序。
因此将 MapReduce 作业连结成为 **工作流（workflow）** 中是极为常见的，例如，一个作业的输出成为下一个作业的输入。Hadoop MapReduce 框架对工作流没有特殊支援，所以这个链是透过目录名隐式实现的：第一个作业必须将其输出配置为 HDFS 中的指定目录，第二个作业必须将其输入配置为从同一个目录。从 MapReduce 框架的角度来看，这是两个独立的作业。
因此，被连结的 MapReduce 作业并没有那么像 Unix 命令管道（它直接将一个程序的输出作为另一个程序的输入，仅用一个很小的记忆体缓冲区）。它更像是一系列命令，其中每个命令的输出写入临时档案，下一个命令从临时档案中读取。这种设计有利也有弊，我们将在 “[物化中间状态](#物化中间状态)” 中讨论。
只有当作业成功完成后，批处理作业的输出才会被视为有效的（MapReduce 会丢弃失败作业的部分输出）。因此，工作流中的一项作业只有在先前的作业 —— 即生产其输入的作业 —— 成功完成后才能开始。为了处理这些作业之间的依赖，有很多针对 Hadoop 的工作流排程器被开发出来，包括 Oozie、Azkaban、Luigi、Airflow 和 Pinball 【28】。
这些排程程式还具有管理功能，在维护大量批处理作业时非常有用。在构建推荐系统时，由 50 到 100 个 MapReduce 作业组成的工作流是常见的【29】。而在大型组织中，许多不同的团队可能执行不同的作业来读取彼此的输出。工具支援对于管理这样复杂的资料流而言非常重要。
Hadoop 的各种高阶工具（如 Pig 【30】、Hive 【31】、Cascading 【32】、Crunch 【33】和 FlumeJava 【34】）也能自动布线组装多个 MapReduce 阶段，生成合适的工作流。
### Reduce侧连线与分组
我们在 [第二章](ch2.md) 中讨论了资料模型和查询语言的连线，但是我们还没有深入探讨连线是如何实现的。现在是我们再次捡起这条线索的时候了。
在许多资料集中，一条记录与另一条记录存在关联是很常见的：关系模型中的 **外来键**，文件模型中的 **文件引用** 或图模型中的 **边**。当你需要同时访问这一关联的两侧（持有引用的记录与被引用的记录）时，连线就是必须的。正如 [第二章](ch2.md) 所讨论的，非规范化可以减少对连线的需求，但通常无法将其完全移除 [^v]。
[^v]: 我们在本书中讨论的连线通常是等值连线，即最常见的连线型别，其中记录透过与其他记录在特定栏位（例如 ID）中具有 **相同值** 相关联。有些资料库支援更通用的连线型别，例如使用小于运算子而不是等号运算子，但是我们没有地方来讲这些东西。
在资料库中，如果执行只涉及少量记录的查询，资料库通常会使用 **索引** 来快速定位感兴趣的记录（请参阅 [第三章](ch3.md)）。如果查询涉及到连线，则可能涉及到查询多个索引。然而 MapReduce 没有索引的概念 —— 至少在通常意义上没有。
当 MapReduce 作业被赋予一组档案作为输入时，它读取所有这些档案的全部内容；资料库会将这种操作称为 **全表扫描**。如果你只想读取少量的记录，则全表扫描与索引查询相比，代价非常高昂。但是在分析查询中（请参阅 “[事务处理还是分析？](ch3.md#事务处理还是分析？)”），通常需要计算大量记录的聚合。在这种情况下，特别是如果能在多台机器上并行处理时，扫描整个输入可能是相当合理的事情。
当我们在批处理的语境中讨论连线时，我们指的是在资料集中解析某种关联的全量存在。例如我们假设一个作业是同时处理所有使用者的资料，而非仅仅是为某个特定使用者查询资料（而这能透过索引更高效地完成）。
#### 示例：使用者活动事件分析
[图 10-2](../img/fig10-2.png) 给出了一个批处理作业中连线的典型例子。左侧是事件日志，描述登入使用者在网站上做的事情（称为 **活动事件**，即 activity events，或 **点选流资料**，即 clickstream data），右侧是使用者资料库。你可以将此示例看作是星型模式的一部分（请参阅 “[星型和雪花型：分析的模式](ch3.md#星型和雪花型：分析的模式)”）：事件日志是事实表，使用者资料库是其中的一个维度。
![](../img/fig10-2.png)
**图 10-2 使用者行为日志与使用者档案的连线**
分析任务可能需要将使用者活动与使用者档案资讯相关联：例如，如果档案包含使用者的年龄或出生日期，系统就可以确定哪些页面更受哪些年龄段的使用者欢迎。然而活动事件仅包含使用者 ID，而没有包含完整的使用者档案资讯。在每个活动事件中嵌入这些档案资讯很可能会非常浪费。因此，活动事件需要与使用者档案资料库相连线。
实现这一连线的最简单方法是，逐个遍历活动事件，并为每个遇到的使用者 ID 查询使用者资料库（在远端伺服器上）。这是可能的，但是它的效能可能会非常差：处理吞吐量将受限于受资料库伺服器的往返时间，本地快取的有效性很大程度上取决于资料的分布，并行执行大量查询可能会轻易压垮资料库【35】。
为了在批处理过程中实现良好的吞吐量，计算必须（尽可能）限于单台机器上进行。为待处理的每条记录发起随机访问的网路请求实在是太慢了。而且，查询远端资料库意味著批处理作业变为 **非确定的（nondeterministic）**，因为远端资料库中的资料可能会改变。
因此，更好的方法是获取使用者资料库的副本（例如，使用 ETL 程序从资料库备份中提取资料，请参阅 “[资料仓库](ch3.md#资料仓库)”），并将它和使用者行为日志放入同一个分散式档案系统中。然后你可以将使用者资料库储存在 HDFS 中的一组档案中，而使用者活动记录储存在另一组档案中，并能用 MapReduce 将所有相关记录集中到同一个地方进行高效处理。
#### 排序合并连线
回想一下，Mapper 的目的是从每个输入记录中提取一对键值。在 [图 10-2](../img/fig10-2.png) 的情况下，这个键就是使用者 ID：一组 Mapper 会扫过活动事件（提取使用者 ID 作为键，活动事件作为值），而另一组 Mapper 将会扫过使用者资料库（提取使用者 ID 作为键，使用者的出生日期作为值）。这个过程如 [图 10-3](../img/fig10-3.png) 所示。