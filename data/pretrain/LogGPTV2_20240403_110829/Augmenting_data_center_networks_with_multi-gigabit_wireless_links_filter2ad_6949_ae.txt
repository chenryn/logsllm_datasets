### 优化后的文本

**Figure 16: Improvements from the Traffic-Oblivious Scheme and Constituent Ideas**

This figure illustrates the improvements in completion time demands (CTD) as defined in §5 and shown in the example (Figure 14) of §5.1. To facilitate comparison, we report the normalized CTD, which is calculated as CTD/CTD_ideal, where CTD_ideal is the CTD with an ideal, non-oversubscribed network. In a 1:N oversubscribed network, the baseline network has a CTD of N, and achieving a CTD of 1 implies that the network, with the use of flyways, performs as well as the ideal, non-oversubscribed network. We will also report statistics on the number of flyways used, their capacities, and their utilization.

### 6.2 Benefits from Flyways

Figure 15 plots the cumulative distribution function (CDF) of the normalized CTD over all the demand matrices in a 1:2 oversubscribed network. For reference, the normalized CTD of the ideal non-oversubscribed network and the baseline are 2 and 1, respectively, as shown in the figure. With just one device per ToR (with NB antennas), the Greedy algorithm provides significant improvements. Approximately 50% of the demand matrices have a normalized CTD of 1.27, indicating a 27% improvement over the baseline. More than 90% of the demand matrices experience a speed-up of at least 45% (normalized CTD < 1.55). This configuration trades roughly half the number of switches, links, and ports (by running at 1:2 oversubscription) for one wireless device per ToR.

At first glance, it may be surprising that a large number of demand matrices reach a CTD of 1.27 but do not go lower. The reason is that CTD improvement is limited by the additional capacity in or out of each ToR. Given a baseline network oversubscribed N times and K flyways per ToR with capacity F, the best possible CTD is N / (1 + KF/C), where C is the uplink capacity at each ToR. With the flyway capacity being 85% of the ideal 6.756 Gbps wireless bitrate and a ToR uplink of 10 Gbps, the best possible normalized CTD value is about 1.27. Thus, half of the demand matrices achieve almost the best possible savings.

Figure 16 compares the Greedy algorithm with other schemes. We observe that the Straggler scheme performs quite poorly. Since high fan-in (and fan-out) correlate with congestion, Straggler runs out of flyways that it can add. As expected, Figure 17 shows that Straggler adds many fewer flyways than the other schemes. Offloading the demands to just the largest neighbor does not significantly impact the hotlinks. Instead, by allowing indirect traffic across flyways, the Transit scheme improves performance for every demand matrix. The Greedy algorithm performs even better. Building on the ability to route indirectly, Greedy searches among many more flyway possibilities and adds those that allow the most traffic to be offloaded. Figure 18 shows that for both Transit and Greedy, almost all the flyways are fully utilized.

Additionally, Greedy primarily selects short flyways that achieve the full possible rate. This indicates that if more capacity were achievable on the flyway link, Greedy's performance would further improve. These results reaffirm the value of allowing transit traffic across flyways and greedily picking the best options from the resulting possibilities.

### 6.3 Evaluating Alternate Configurations

To better understand the solution space, we evaluate alternatives with more wireless devices available at each ToR, different antenna types, and different degrees of oversubscription on the core.

**More Wireless Devices per ToR:**
Figure 19 plots the benefits due to flyways when more than one wireless device is available at each ToR. We see that with just one additional device (K = 2), the improvements in completion time are significant. In fact, over 40% of the matrices finish as fast as they would in a non-oversubscribed network. There are two reasons for this. First, as seen in Figure 15, with just one device available per ToR, some demand matrices are constrained by the maximum capacity that a flyway adds. Additional wireless devices provide immediate benefit to these matrices. Second, even matrices that are unconstrained by flyway capacity benefit because more flyways enable many more indirect routes, diverting traffic away from congested parts of the wired network to other wired links with spare capacity.

**Different Antenna Configurations:**
All previous results were with a narrow beam, 23 dBi gain, antenna. Figure 20 compares the benefits when different directional antennas are used. We compare Greedy with Transit, its next best alternative. We find that Greedy works best with Phocus antennas, even though they are less directional than NB antennas, for two reasons. First, Greedy biases the algorithm to use shorter, higher-capacity flyways and then route traffic indirectly via these links. Most of these short links will continue to exist even with lower gain antennas. Second, the Phocus array has smaller back and side lobes, resulting in lower interference and more simultaneously usable links. Unlike Greedy, Transit is sensitive to antenna directionality. With wider beam antennas, Transit performs considerably worse and is on par with Straggler+NB. The benefits from allowing transit traffic are lost with wider antennas because there is greater variation in capacities across flyways and quicker decay with distance. The inability to pick flyways other than those between the straggling ToR pair causes Transit to lose its gains. On the other hand, Greedy's selectivity allows it to retain most of its gains even with wider antennas.

**Different Oversubscription Factors:**
With a greater oversubscription factor, such as slower links between the ToR and the core or fewer core switches in a VL2-like architecture, the network core would be relatively less expensive. Figure 21 plots the median normalized CTD across demand matrices for different oversubscription factors. We see a reasonable trade-off: one can increase the oversubscription factor on the wired network and instead spend a small fraction of that amount to deploy additional wireless devices at each ToR. The marginal improvement from each additional device decreases, but the savings are considerable. On a 1:4 oversubscribed network, flyways with 3 devices per ToR provide a median CTD of 1.78, i.e., performance better than a 1:2 oversubscribed network.

### 7. Discussion

**Flyways Limitations:**
For some workloads, such as all-pairs-shuffle, non-oversubscribed networks are indeed more appropriate. However, these workloads are not reflected in our many traces, and we believe that such workloads are rare in practice. Our current "flyway picker" algorithm requires knowledge of traffic patterns. In some cases (e.g., multi-tenant data centers), traffic patterns may not be predictable, and there may be no cluster-wide scheduler. In such cases, we believe that an online traffic engineering approach, such as that described in [5], combined with the ability to rapidly steer antennas (every few seconds), may be the right solution. Designing a flyway validator and flyway picker becomes more interesting when rapid beam steering is possible, as a single flyway device can divide time across multiple neighbors. We are currently investigating the practical issues (e.g., routing) involved in this approach.

**Scaling with Faster Wired Networks:**
The maximum rate specified in 802.11ad is 6.76 Gbps. We have shown (§4) that flyway bandwidth needs to be only a fraction of the hot link's capacity. Still, as the speed of wired links in the data center continues to grow, we may need faster flyways. Our results in Figure 8 show that many links have ample SNR headroom and thus have plenty of room to grow with higher modulations. Additionally, the flyway architecture is not specific to 60 GHz technology. Other frequencies in the 50–75 GHz band have similar properties, and as 60 GHz devices become a mature technology, it may be possible to convince the FCC to open up more spectrum around the 60 GHz band for indoor data center use. Given the large lot sizes of data centers and the short propagation distance of 60 GHz links, it may be possible to use a wider band while ensuring that no detectable signal leaves the data center premises.

**Scaling the Data Center Size:**
Network architectures such as VL2 [8] and FatTree [1] allow the data center to scale easily and provide full bisection bandwidth. In these designs, it is easy to build a bigger network by simply adding additional switches, rather than investing in larger aggregation switches or adding more layers to the hierarchy. We can use the flyway architecture in conjunction with oversubscribed VL2-like networks. The VL2 architecture can be used for easy scaling, while the flyways address congestion dynamically.

**Containerized Data Center Networks:**
While many of today's large data centers use a large, open floor plan (and new ones continue to be built), some new data centers are being built with containerized architecture. In a container environment, we can either deploy flyways inside a container or between containers. Deploying flyways inside a container, instead of building a full bisection bandwidth network, may allow for cheaper containers, as much less hardware will be required. On the other hand, inside a container, flyways may suffer from multipath effects, as radiation bounces off metal walls. This issue can be addressed in numerous ways, such as lining the inside of a container with absorbent material.