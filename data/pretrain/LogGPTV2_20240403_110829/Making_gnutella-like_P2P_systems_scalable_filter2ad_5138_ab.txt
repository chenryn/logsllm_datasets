the current Gnutella protocol [6]. Clients connect to each other using
a three-way handshake protocol. All messages exchanged by clients
are tagged at their origin with a globally unique identiﬁer or GUID,
which is a randomly generated sequence of 16 bytes. The GUID is
used to track the progress of a message through the Gia network and
to route responses back to the originating client.
We extend the Gnutella protocol to take into account client capac-
ity and network heterogeneity. For this discussion, we assume that
client capacity is a quantity that represents the number of queries
that the client can handle per second. In practice, the capacity will
have to be determined as a function of a client’s access bandwidth,
processing power, disk speed, etc. We discuss the four protocol com-
ponents in detail below.
Let Ci represent capacity of node i
if num nbrsX + 1 ≤ max nbrs then {we have room}
ACCEPT Y ; return
REJECT Y ; return
{we need to drop a neighbor}
subset ← i ∀ i ∈ nbrsX such that Ci ≤ CY
if no such neighbors exist then
candidate Z ←highest-degree neighbor from subset
if (CY > max(Ci ∀ i ∈ nbrsX) ) {Y has higher capacity}
or (num nbrsZ > num nbrsY + H) {Y has fewer nbrs}
then
DROP Z; ACCEPT Y
else
REJECT Y
Algorithm 1: pick neighbor to drop(X, Y ):
When node X tries to add Y as a new neighbor, determine whether
If not, pick one of X’s existing neighbors
there is room for Y .
to drop and replace it with Y .
(In the algorithm, H represents a
hysteresis factor.)
3.2.1 Topology Adaptation
The topology adaptation algorithm is the core component that
connects the Gia client to the rest of the network. In this section,
we provide an overview of the adaptation process, while leaving the
details of some of the speciﬁc mechanisms for discussion later in
Section 5. When a node starts up, it uses bootstrapping mechanisms
similar to those in Gnutella to locate other Gia nodes. Each Gia
client maintains a host cache consisting of a list of other Gia nodes
(their IP address, port number, and capacity). The host cache is pop-
ulated throughout the lifetime of the client using a variety of ren-
dezvous mechanisms including contacting well-known web-based
host caches [5] and exchanging host information with neighbors
through PING-PONG messages [6]. Entries in the host cache are
marked as dead if connections to those hosts fail. Dead entries are
periodically aged out.
The goal of the topology adaptation algorithm is to ensure that
high capacity nodes are indeed the ones with high degree and that
low capacity nodes are within short reach of higher capacity ones.
To achieve this goal, each node independently computes a level of
satisfaction (S). This is a quantity between 0 and 1 that represents
how satisﬁed a node is with its current set of neighbors. A value
of S = 0 means that the node is quite dissatisﬁed, while S = 1
suggests that the node is fully satisﬁed. As long as a node is not fully
satisﬁed, the topology adaptation continues to search for appropriate
neighbors to improve the satisfaction level. Thus, when a node starts
up and has fewer than some pre-conﬁgured minimum number of
neighbors, it is in a dissatisﬁed state (S = 0). As it gathers more
neighbors, its satisfaction level rises, until it decides that its current
set of neighbors is sufﬁcient to satisfy its capacity, at which point the
topology adaptation becomes quiescent. In Section 5.2, we describe
the details of the algorithm used to compute the satisfaction level.
To add a new neighbor, a node (say X) randomly selects a small
number of candidate entries from those in its host cache that are not
marked dead and are not already neighbors. From these randomly
chosen entries, X selects the node with maximum capacity greater
than its own capacity. If no such candidate entry exists, it selects
one at random. Node X then initiates a three-way handshake to the
selected neighbor, say Y .
During the handshake, each node makes a decision whether or not
to accept the other node as a new neighbor based upon the capaci-
ties and degrees of its existing neighbors and the new node. In order
to accept the new node, we may need to drop an existing neighbor.
Algorithm 1 shows the steps involved in making this determination.
The algorithm works as follows. If, upon accepting the new con-
nection, the total number of neighbors would still be within a pre-
conﬁgured bound max nbrs, then the connection is automatically
accepted. Otherwise, the node must see if it can ﬁnd an appropriate
existing neighbor to drop and replace with the new connection.
X always favors Y and drops an existing neighbor if Y has higher
capacity than all of X’s current neighbors. Otherwise, it decides
whether to retain Y or not as follows. From all of X’s neighbors that
have capacity less than or equal to that of Y , we choose the neigh-
bor Z that has the highest degree. This neighbor has the least to
lose if X drops it in favor of Y . The neighbor will be dropped only
if the new node Y has fewer neighbors than Z. This ensures that
we do not drop already poorly-connected neighbors (which could
get disconnected) in favor of well-connected ones.6 The topology
adaptation algorithm thus tries to ensure that the adaptation process
makes forward progress toward a stable state. Results from experi-
ments measuring the topology adaptation process are discussed later
in Section 5.4.
3.2.2 Flow control
To avoid creating hot-spots or overloading any one node, Gia uses
an active ﬂow control scheme in which a sender is allowed to direct
queries to a neighbor only if that neighbor has notiﬁed the sender
that it is willing to accept queries from the sender. This is in contrast
to most proposed Gnutella ﬂow-control mechanisms [16], which are
reactive in nature: receivers drop packets when they start to become
overloaded; senders can infer the likelihood that a neighbor will drop
packets based on responses that they receive from the neighbor, but
there is no explicit feedback mechanism. These technique may be
acceptable when queries are ﬂooded across the network, because
even if a node drops a query, other copies of the query will prop-
agate through the network. However, Gia uses random walks (to
address scaling problems with ﬂooding) to forward a single copy of
each query. Hence, arbitrarily dropping queries is not an appropriate
solution.
To provide better ﬂow control, each Gia client periodically as-
signs ﬂow-control tokens to its neighbors. Each token represents a
single query that the node is willing to accept. Thus, a node can
send a query to a neighbor only if it has received a token from that
neighbor, thus avoiding overloaded neighbors. In the aggregate, a
node allocates tokens at the rate at which it can process queries. If
it receives queries faster than it can forward them (either because it
is overloaded or because it has not received enough tokens from its
neighbors), then it starts to queue up the excess queries. If this queue
gets too long, it tries to reduce the inﬂow of queries by lowering its
token allocation rate.
To provide an incentive for high-capacity nodes to advertise their
true capacity, Gia clients assign tokens in proportion to the neigh-
bors’ capacities, rather than distributing them evenly between all
neighbors. Thus, a node that advertises high capacity to handle in-
coming queries is in turn assigned more tokens for its own outgoing
queries. We use a token assignment algorithm based on Start-time
Fair Queuing (SFQ) [9]. Each neighbor is assigned a fair-queuing
weight equal to its capacity. Neighbors that are not using any of their
assigned tokens are marked as inactive and the left-over capacity
is automatically redistributed proportionally between the remaining
neighbors. As neighbors join and leave, the SFQ algorithm recon-
6To avoid having X ﬂip back and forth between Y and Z, we add a
level of hysteresis: we drop Z and add Y only if Y has at least H
fewer neighbors than Z, where H represents the level of hysteresis.
In our simulations and implementation, we set the value of H to 5.
ﬁgures its token allocation accordingly.7 Token assignment notiﬁca-
tions can be sent to neighbors either as separate control messages or
by piggy-backing on other messages.
3.2.3 One-hop Replication
To improve the efﬁciency of the search process, each Gia node
actively maintains an index of the content of each of its neighbors.
These indices are exchanged when neighbors establish connections
to each other, and periodically updated with any incremental changes.
Thus, when a node receives a query, it can respond not only with
matches from its own content, but also provide matches from the
content offered by all of its neighbors. When a neighbor is lost,
either because it leaves the system, or due to topology adaptation,
the index information for that neighbor gets ﬂushed. This ensures
that all index information remains mostly up-to-date and consistent
throughout the lifetime of the node.
3.2.4 Search Protocol
The combination of topology adaptation (whereby high capac-
ity nodes have more neighbors) and one-hop replication (whereby
nodes keep an index of their neighbors’ shared ﬁles) ensures that
high capacity nodes can typically provide useful responses for a
large number of queries. Hence, the Gia search protocol uses a
biased random walk: rather than forwarding incoming queries to
randomly chosen neighbors, a Gia node selects the highest capacity
neighbor for which it has ﬂow-control tokens and sends the query to
that neighbor. If it has no tokens from any neighbors, it queues the
query until new tokens arrive.
We use TTLs to bound the duration of the biased random walks
and book-keeping techniques to avoid redundant paths. With book-
keeping, each query is assigned a unique GUID by its originator
node. A node remembers the neighbors to which it has already for-
warded queries for a given GUID. If a query with the same GUID
arrives back at the node, it is forwarded to a different neighbor. This
reduces the likelihood that a query traverses the same path twice. To
ensure forward progress, if a node has already sent the query to all
of its neighbors, it ﬂushes the book-keeping state and starts re-using
neighbors.
Each query has a MAX RESPONSES parameter, the maximum
number of matching answers that the query should search for. In ad-
dition to the TTL, query duration is bounded by MAX RESPONSES.
Every time a node ﬁnds a matching response for a query, it decre-
ments the MAX RESPONSES in the query. Once MAX RESPONSES
hits zero, the query is discarded. Query responses are forwarded
back to the originator along the reverse-path associated with the
query.
If the reverse-path is lost due to topology adaptation or if
queries or responses are dropped because of node failure, we rely
on recovery mechanisms described later in Section 5.3 to handle the
loss.
Finally, since a node can generate a response either for its own
ﬁles or for the ﬁles of one of its neighbors, we append to the for-
warded query the addresses of the nodes that own those ﬁles. This
ensures that the query does not produce multiple redundant responses
for the same instance of a ﬁle; a response is generated only if the
node that owns the matching ﬁle is not already listed in the query
message.
4. SIMULATIONS
In this section, we use simulations to evaluate Gia and compare
its performance to two other unstructured P2P systems. Thus our
simulations refer to the following four models:
7Details of the SFQ algorithm for proportional allocation can be
found in [9].
Capacity level
Percentage of nodes
1x
10x
100x
1000x
10000x
20%
45%
30%
4.9%
0.1%
Table 1: Gnutella-like node capacity distributions.
• FLOOD: Search using TTL-scoped ﬂooding over random topolo-
gies. This represents the Gnutella model.
• RWRT: Search using random walks over random topologies.
This represents the recommended search technique suggested
by Lv et al. [12] for avoiding the scalability problems with
ﬂooding.
• SUPER: Search using supernode mechanisms [7, 24]. In this
approach, we classify nodes as supernodes and non-supernodes.
Queries are ﬂooded only between supernodes.
• GIA: Search using the Gia protocol suite including topology
adaptation, active ﬂow control, one-hop replication, and bi-
ased random walks.
We ﬁrst describe our simulation model and the metrics used for
evaluating the performance of our algorithms. Then we report the
results from a range of simulations. Our experiments focus on the
aggregate system behavior in terms of its capacity to handle queries
under a variety of conditions. We show how the individual com-
ponents of our system (topology adaptation, ﬂow control, one-hop
replication, and searches based on biased random walks) and the
synergies between them affect the total system capacity. Due to
space limitations, we do not present detailed results evaluating trade-
offs within each design component.
4.1 System Model
To capture the effect of query load on the system, the Gia simu-
lator imposes capacity constraints on each of the nodes within the
system. We model each node i as possessing a capacity Ci, which
represents the number of messages (such as queries and add/drop
requests for topology adaptation) that it can process per unit time. If
a node receives queries from its neighbors at a rate higher than its
capacity Ci (as can happen in the absence of ﬂow control), then the
excess queries are modeled as being queued in connection buffers
until the receiving node can read the queries from those buffers.
For most of our simulations, we assign capacities to nodes based
on a distribution that is derived from the measured bandwidth distri-
butions for Gnutella as reported by Saroiu et al. [22]. Our capacity
distribution has ﬁve levels of capacity, each separated by an order
of magnitude as shown in Table 1. As described in [22], this dis-
tribution reﬂects the reality that a fair fraction of Gnutella clients
have dial-up connections to the Internet, the majority are connected
via cable-modem or DSL and a small number of participants have
high speed connections. For the SUPER experiments, nodes with
capacities 1000x and 10000x are designated as supernodes.
In addition to its capacity, each node i is assigned a query gener-
ation rate qi, which is the number of queries that node i generates
per unit time. For our experiments, we assume that all nodes gen-
erate queries at the same rate (bounded, of course, by their capaci-
ties). When queries need to be buffered, they are held in queues. We
model all incoming and outgoing queues as having inﬁnite length.
We realize that, in practice, queues are not inﬁnite, but we make this
assumption since the effect of dropping a query and adding it to an
arbitrarily long queue is essentially the same.
 1
 0.8
 0.6
 0.4
 0.2
e
t
a
r
s
s
e
c
c
u
S
 0
0.01
0.5% replication
0.1% replication
0.1
1.0
10.0 100.0 1000
Queries per second
)
s
e
i
r
e
u
q
l
u
f
s
s
e
c
c
u
s
r
o
f
(
t
n
u
o
C
p
o
H
 18
 16
 14
 12
 10
 8
 6
 4
 2
 0
0.01
0.5% replication
0.1% replication
0.5% replication
0.1% replication
1
0.1
0.01
l
y
a
e
D
0.1
1.0
10.0
100.0
1000
Queries per second
0.001
0.01
1.0
10.0
100.0
1000
Queries per second
Figure 2: Success rate, hop-count and delay under increasing query load for a 10,000 node Gia network.
Queries are modeled as searching for speciﬁc keywords. Each
keyword maps on to a set of ﬁles. Files are randomly replicated on
nodes. All ﬁles associated with a speciﬁc keyword are potential an-
swers for a query with that keyword. We use the term replication
factor to refer to the fraction of nodes at which answers to queries
reside. Thus, performing a query for a keyword that has a replication
factor of 1% implies that an answer to this query can be found at 1%
of the nodes in the system. In a deployed system, real search traf-
ﬁc will include many different queries covering a range of replica-
tion factors simultaneously. However, each search process proceeds
largely independently (aside from delays within queues and the ac-
tions of ﬂow control). Hence, rather than having to pick a speciﬁc
distribution of queries, each looking for keywords with their own