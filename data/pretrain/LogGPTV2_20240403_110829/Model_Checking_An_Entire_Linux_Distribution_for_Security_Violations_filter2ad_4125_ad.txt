some setup code that sets the value of
the variable
action file name. Speciﬁcally, it is a string whose ﬁrst
component is a pathname to a temporary directory (by de-
fault, it chooses /tmp, but this can be changed by deﬁning
an environment variable), and whose second component is
a temporary ﬁle template5. The above code alone should
be of concern to us. Recall that mkstemp returns a ﬁle de-
scriptor that can be safely used, but the template passed to
mkstemp is not safe to re-use. In this case, we see the tem-
plate being passed to another function called open error:
void open_error(char *filename) {
warnx("f - cannot open \"%s\"", filename);
done(2);
}
From the above fragment it looks like the function warnx
may be a good candidate for inspection because it is the
recipient of the ﬁlename we are interested in tracking.
Strangely enough, MOPS directs us to the function done:
void done(int k) {
if (action_file)
fclose(action_file);
if (action_file_name[0])
unlink(action_file_name);
Here we ﬁnd the bug. The variable action file name,
which is the template passed to mkstemp, is re-used as an
argument to the unlink system call. This is unsafe. By
the time we call unlink, the ﬁlename may no longer point
to the location we think it does. Recall that the directory
in which the ﬁle is being created may be world writable.
An attacker that has write access to the ﬁle can change it
to a symbolic link, and cause the program to unlink other
unexpected ﬁles on the system. Unfortunately there does
not appear to be a good resolution to the problem.
3.4 Attacks Against strncpy
There are several common attacks against programs
that misuse the standard library function strncpy.
strncpy(d,s,n) copies a string of characters pointed to
by s into the memory region designated by d.
If s con-
tains more than n characters, strncpy only copies the ﬁrst
n characters. If s contains fewer than n characters, strncpy
copies all the characters in s and then ﬁlls d with null char-
acters until the length of d reaches n.
5A template is a partial ﬁlename with a number of placeholders denoted
by a special character X that will be ﬁlled in with random numbers by the
function creating the temporary ﬁlename.
Proceedings of the 21st Annual Computer Security Applications Conference (ACSAC 2005) 
1063-9527/05 $20.00 © 2005 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 12:13:43 UTC from IEEE Xplore.  Restrictions apply. 
strncpy is easy to misuse for two reasons. First, it en-
courages off-by-one errors if the programmer is not care-
ful to compute the value of n precisely. Off-by-one errors
can often cause the program to write past the end of an ar-
ray bounds, which can in turn lead to buffer overrun attacks
against the program. In particular, consider a case where the
string buffer in question is allocated on the runtime stack (as
it will be when the buffer is an array local to a function in
C), and the user of the program is able to control the con-
tents of the source of s. If the program writes past the end
of the buffer, a malicious user may construct a special string
s, such that when the program writes past the array bounds,
it writes special code into the stack frame that corrupts the
program. Secondly, because the function does not automat-
ically null-terminate a string in all cases (for instance, when
the size of the source string is larger than n), it is a common
mistake for a program to create unterminated strings during
its execution.
We have constructed an FSA to try and catch both sce-
narios as described above. The intuition is that we iden-
tify several idioms that are correct ways to null terminate a
string, and raise an alarm when one of these idioms is not
used. For example, a common idiom is the following code
sequence that is safe:
buf[sizeof(buf)-1] = ’\0’;
strncpy(buf, ..., sizeof(buf)-1);
In the above case, the buffer will also be terminated.
However, the following two cases show a common misuse
of strncpy:
• buf[sizeof(buf)-1] = ’\0’;
strncpy(buf, ..., sizeof(buf));
• memset(buf, 0, sizeof(buf)-1);
strncpy(buf, ..., sizeof(buf)-1);
In the ﬁrst unsafe example, the string is null-terminated be-
fore the strncpy, and the execution of the function sub-
sequently may overwrite the null-terminating character. In
the second unsafe example, memset is used to zero-out the
destination buffer; unfortunately, it is misused—the third
argument needs to be the size of the entire buffer. Our
FSA attempts to detect patterns that appear ﬁshy, and alerts
the user to their presence. Pattern variables are used judi-
ciously to make MOPS precisely match the null-terminating
code to the strncpy code that uses the same buffers. The
property requires more manual inspection than other prop-
erties, because we have chosen an approach where we iden-
tify correct behavior, then raise an alarm at code that does
not match our expectations. Moreover, our property does
not attempt to ﬁnd all strncpy bugs, focusing instead on
patterns that are particularly suspicious.
Our strncpy FSA has alerted us to a number of bugs.
Below we show one of the most interesting examples. It
comes from the program xloadimage:
void dumpImage(Image *image, char *type,
char *filename, int verbose) {
int a;
char typename[32];
char *optptr;
optptr = index(type, ’,’);
if (optptr) {
strncpy(typename, type, optptr - type);
typename[optptr - type] = ’\0’;
...
In the above code fragment, MOPS identiﬁes an id-
iom that does not appear to be safe. The character buffer
typename is declared to be 32 bytes long, but the length
passed to strncpy is computed entirely based on the sec-
ond argument to the function dumpImage. We must ver-
ify that this string cannot be constructed in such a way
that when optptr - type is computed, the result is longer
than 32 bytes. MOPS is able to direct us to the call site of
this function, in which we see the following (abbreviated):
newopt->info.dump.type= argv[++a];
...
dumpImage(dispimage, dump->info.dump.type,
dump->info.dump.file, verbose);
Shockingly, the contents of the string come from the
command line arguments, and can be set entirely by the
user. Consequently, a malicious user can supply a carefully
crafted argument to the function which causes the function
dumpImage to write past the end of an array, causing a
buffer overrun.
Unfortunately,
this property produced 1378 unique
warnings,
too many to examine exhaustively by hand.
Therefore, we picked a semi-random sample of 16 packages
out of the set of 197 packages with one or more warning,
yielding a set of 53 warnings. Examining these 53 warnings
revealed 11 bugs spread among 6 packages, where in each
case a string could be left unterminated or the strncpy()
operation could overﬂow buffer bounds for some input. We
did not attempt to assess the security implications of these
bugs, though we expect that many of them could be ex-
ploited under some circumstances.
Based on this limited sample, we suspect that a full
manual audit using MOPS would turn up many more
strncpy() bugs. Since we saw 11 bugs among 53 warn-
ings, this suggests a false positive rate of about 79%, and a
true positive rate of about 21%. If all warnings are equally
likely to correspond to real bugs, we might estimate that
53 ≈ 286 bugs, with a 95% conﬁ-
there are about 1378 × 11
dence interval of between 165 to 468 bugs. Of course, these
Proceedings of the 21st Annual Computer Security Applications Conference (ACSAC 2005) 
1063-9527/05 $20.00 © 2005 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 12:13:43 UTC from IEEE Xplore.  Restrictions apply. 
estimates are fairly rough, but our best prediction is that a
full manual audit of all the MOPS warnings would turn up
in excess of one hundred strncpy() bugs.
4 Related Work
attacks to verify their validity. As a result of this experi-
ence, we are convinced that software model checking can
easily be integrated into the development process, partic-
ularly when using model checkers like MOPS that can be
integrated into build processes at the highest level.
There is a broad and growing array of work on software
model checking, and MOPS represents just one of several
tools in this area. BLAST [11] and SLAM [3] are dataﬂow-
sensitive model checkers that use adaptive iterative reﬁne-
ment to narrow down the locations of bugs. Both have been
used primarily on smaller programs, such as device drivers,
but they are able to provide a much more precise analy-
sis. Similar to BLAST is MAGIC [5], a system that ab-
stracts predicates and uses a theorem prover for dataﬂow
analysis. CMC, a model checker for C and C++ programs
[13], has been used on large-scale applications like the en-
tire Linux kernel [10]. Metal, a ground-breaking bugﬁnding
tool which is similar in concept to a model checker, has been
very successful at ﬁnding a broad variety of rule violations
in operating systems [2, 9]. Metal has been augmented with
Z-ranking, a powerful technique for reducing the number of
false positives, and used to ﬁnd many bugs in large appli-
cations [12]. MOPS has previously been used to ﬁnd bugs
in eight security-relevant packages from the Red Hat distri-
bution [6, 7]. However, none of these tools have yet been
applied on as large a scale as shown in this paper.
File system race conditions have been extensively stud-
ied in the computer security literature. Bishop and Dil-
ger ﬁrst articulated the vulnerability pattern and developed
a syntactic pattern-matching analysis for detecting TOCT-
TOU vulnerabilities in C code [4]; however, because their
analysis is not semantically based, it is unable to ﬁnd many
of the vulnerabilities found in this work. Also, some au-
thors have proposed runtime program analysis methods to
detect TOCTTOU bugs by monitoring program executions
and preventing their exploitation [8]; our work differs by
trying to ﬁnd TOCTTOU bugs at compile time, rather than
at runtime.
5 Conclusion
Our work demonstrates that large-scale model checking
is feasible. We showed that it is possible to develop mod-
els of incorrect and insecure program behavior that are pre-
cise enough to prevent false positives from dwarﬁng the real
bugs; also, as this work showed, many of these properties
can be encoded in MOPS without serious loss of sound-
ness. Thanks to the sophisticated error reporting in MOPS,
we found that we were able to manually inspect all error
traces. Consequently, we were able to ﬁnd many (108) real
exploitable software bugs; in several cases, we have crafted
References
[1] mopscode.sourceforge.net.
[2] K. Ashcraft and D. Engler. Using programmer-written com-
piler extensions to catch security holes. In Proceedings of
IEEE Security and Privacy 2002, 2002.
[3] T. Ball and S. K. Rajamani. The SLAM project: Debugging
system software via static analysis. In POPL ’02: Proceed-
ings of the ACM SIGPLAN-SIGACT Conference on Princi-
ples of Programming Languages, 2002.
[4] M. Bishop and M. Dilger. Checking for race conditions
in ﬁle accesses. Computing Systems, 9(2):131–152, Spring
1996.
[5] S. Chaki, E. Clarke, A. Groce, S. Jha, and H. Veith. Modular
veriﬁcation of software components in C. In International
Conference on Software Engineering, pages 385–395, May
2003.
[6] H. Chen, D. Dean, and D. Wagner. Model checking one
million lines of C code. In Proceedings of the 11th Annual
Network and Distributed System Security Symposium, San
Diego, CA, Feb. 4–6, 2004.
[7] H. Chen and D. Wagner. MOPS: an infrastructure for exam-
ining security properties of software. In Proceedings of the
9th ACM Conference on Computer and Communications Se-
curity (CCS), pages 235–244, Washington, DC, Nov. 18–22,
2002.
[8] C. Cowan, S. Beattie, C. Wright, and G. Kroah-Hartman.
RaceGuard: Kernel protection from temporary ﬁle race vul-
nerabilities. In Proceedings of the Tenth USENIX Security
Symposium, 2001.
[9] D. Engler, B. Chelf, A. Chou, and S. Hallem. Checking sys-
tem rules using system-speciﬁc, programmer-written com-
piler extensions. In OSDI, 2000.
[10] D. Engler and M. Musuvathi. Model-checking large network
protocol implementations. In Proceedings of the First Sym-
posium on Networked Systems Design and Implementation,
2004.
[11] T. A. Henzinger, R. Jhala, R. Majumdar, and G. Sutre. Soft-
ware veriﬁcation with BLAST. In Proceedings of the 10th
SPIN Workshop on Model Checking Software, 2003.
[12] T. Kremenek and D. Engler. Z-Ranking: Using Statistical
Analysis to Counter the Impact of Static Analysis Approxi-
mations. In Proceedings of the 2003 Static Analysis Sympo-
sium, 2003.
[13] M. Musuvathi, D. Park, A. Chou, D. R. Engler, and D. L.
Dill. CMC: A Pragmatic Approach to Model Checking Real
Code. In Proceedings of the Fifth Symposium on Operating
Systems Design and Implementation, Dec. 2002.
Proceedings of the 21st Annual Computer Security Applications Conference (ACSAC 2005) 
1063-9527/05 $20.00 © 2005 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 12:13:43 UTC from IEEE Xplore.  Restrictions apply.