security properties will vary. To further explore the conse-
quences of key compromise, we outline the following types
of attacks in the supply chain:
Fake-check: a malicious party can provide evidence of
a step taking place, but that step generates no products
(it can still, however, generate byproducts). For example,
an attacker could forge the results of a test suite being
executed in order to trick other functionaries into
releasing a delivered product with failing tests.
Product Modiﬁcation: a malicious party is able to
provide a tampered artifact in a step to be used as
material in subsequent steps. For example, an attacker
could take over a buildfarm and create a backdoored
binary that will be packaged into the delivered product.
Unintended Retention: a malicious party does not destroy
artifacts that were intended to be destroyed in a step. For
example, an attacker that compromises a cleanup step
before packaging can retain exploitable libraries that
will be shipped along with the delivered product.
Arbitrary Supply Chain Control: a malicious party is
able to provide a tampered or counterfeit delivered
product, effectively creating an alternate supply chain.
5.2.1 Functionary compromise
A compromise on a threshold of keys held for any functionary
role will only affect a speciﬁc step in the supply chain to
which that functionary is assigned to. When this happens,
the artifact ﬂow integrity and step authentication security
properties may be violated. In this case, the attacker can
arbitrarily forge link metadata that corresponds to that step.
The impact of this may vary depending on the speciﬁc
link compromised. For example, an attacker can fabricate an
attestation for a step that does not produce artifacts (i.e., a
fake-check), or create malicious products (i.e., a product mod-
iﬁcation), or pass along artifacts that should have been deleted
(i.e., an unintended retention). When an attacker creates
malicious products or fails to remove artifacts, the impact is
limited by the usage of such products in subsequent steps of
the chain. Table 1 describes the impact of these in detail from
rows 2 to 5 (row 1 captures the case when the attacker does
not compromise enough keys to meet the threshold deﬁned
for a step). As a recommended best practice, we assume there
is a “DISALLOW *” rule at the end of the rule list for each step.
It is of note from Table 1 that an attacker who is able
to compromise crucial steps (e.g., a build step) will have a
greater impact on the client than one which, for example,
can only alter localization ﬁles. Further, a compromise in
functionary keys that do not create a product is restricted
Compromised Step
Rule
Subsequent Step
Rule
Impact
Regardless of rule
Regardless of rule None
Type of Key
Compromise
Under
threshold
Step
Step
Step
None
ALLOW pattern1
DELETE pattern2
[ALLOW | CREATE |
MODIFY] pattern
MATCH pattern*
Regardless of rule Fake-check
Unintended
Retention
Product
Modiﬁcation
Arbitrary Supply
Chain Control
MATCH pattern
Layout
N/A
N/A
Table 1: Key compromise and impact based on the layout characteristics.
to a fake check attack (row two). To trigger an unintended
retention, the ﬁrst step must also have rules that allow for
some artifacts before the DELETE rule (e.g., the ALLOW rule
with a similar artifact pattern). This is because rules behave
like artifact rules, and the attacker can leverage the ambiguity
of the wildcard patterns to register an artifact that was
meant to be deleted. Lastly, note that the effect of product
modiﬁcation and unintended retention is limited by the
namespace on such rules (i.e., the artifact_pattern).
Mitigating risk. As discussed earlier, the bar can be raised
against an attacker if a role is required to have a higher
threshold. For example, two parties could be in charge of
signing the tag for a release, which would require the attacker
to compromise two keys to successfully subvert the step.
Finally, further steps and inspections can be added to
the supply chain with the intention of limiting the possible
transformations on any step. For example, as shown in
Section 6, an inspection can be used to dive into a Python’s
wheel and ensure that only Python sources in the tag release
are contained in the package.
5.2.2 Project owner compromise
A compromise of a threshold of keys belonging to the project
owner role allows the attacker to redeﬁne the layout, and
thereby subvert the supply chain completely. However, like
with step-level compromises, an increased threshold setting
can be used to ensure an attacker needs to compromise many
keys at once. Further, given the way in-toto is designed,
the layout key is designed to be used rarely, and thus it should
be kept ofﬂine.
5.3 User actions in response to in-toto failures
Detecting a failure to validate in-toto metadata involves
making a decision about whether veriﬁcation succeeded or
whether it failed and, if so, why. The user’s device and the
reason for failure are likely to be paramount in the user’s
decision about how to respond. If the user is installing in an
ephemeral environment on a testing VM, they may choose
to ignore the warning and install the package regardless. If
the user is installing in a production environment processing
PCI data, the failure to validate in-toto metadata will be
a serious concern. So, we expect users of in-toto will
respond in much the same way as administrators do today
for a package that is not properly signed.
USENIX Association
28th USENIX Security Symposium    1401
Figure 2: The rebuilder setup.
6 Deployment
in-toto has about a dozen different integrations that protect
software supply chains for millions of end users. This section
uses three such integrations to examine how threshold signing,
metadata generation, and end-to-end veriﬁcation function in
practical deployments of in-toto.
6.1 Debian rebuilder constellation
Debian is one of the biggest stakeholders in the reproducible
builds project [26], an initiative to ensure bit-by-bit determin-
istic builds of a source package. One of the main motivations
behind reproducible builds is to avoid backdooring compil-
ers [136] or compromised toolchains in the Debian build
infrastructure. in-toto helps Debian achieve this goal via
its step-thresholding mechanism.
The apt-transport [16] for in-toto veriﬁes the trusted
rebuilder metadata upon installing any Debian package.
Meanwhile, various institutions (that range from private to
non-proﬁt and educational) run rebuilder infrastructure to re-
build Debian packages independently and produce attestations
of the resulting builds using in-toto link metadata. This way,
it is possible to cryptographically assert that a Debian package
has been reproducibly built by a set of k out of n rebuilders.
Figure 2 shows a graphical description of this setup.
By using the in-toto veriﬁable transport, users can make
sure that no package was tampered with unless an attacker is
also able to compromise at least k rebuilders and the Debian
buildfarm. Throughout this deployment, we were able to
test the thresholding mechanism, as well as practical ways
to bootstrap project owner signatures through the existing
package manager trust infrastructure [32, 34].
Deployment insight. Through our interaction with repro-
ducible builds, we were able to better understand how the
thresholding mechanism can be used to represent concepts
such as a build’s reproducibility and how to build in-toto
into operating-system tools to facilitate adoption.
6.2 Cloud native builds with Jenkins and Kubernetes
“Cloud native” is used to refer to container-based environ-
ments [3]. Cloud native ecosystems are characterized by
rapid changes and constant re-deployment of the internal
components. They are generally distributed systems, and
often managed by container orchestration systems such as
Kubernetes [23] or Docker Swarm [6]. Thus, their pipelines
are mostly automated using pipeline managers such as
Figure 3: The kubesec supply chain.
Jenkins [18] or Travis [137]. In this type of ecosystems, a
host- and infrastructure-agnostic, automated way to collect
supply-chain metadata is necessary not only for security,
but also for auditing and analyzing the execution of build
processes that led to the creation of the delivered product.
In the context of cloud native applications, in-toto is
used by Control Plane to track the build and quality-assurance
steps on kubesec [19], a Kubernetes resource and conﬁgu-
ration static analyzer. In order to secure the kubesec supply
chain, we developed two in-toto components: a Jenkins
plugin [11] and a Kubernetes admission controller [7, 17].
These two components allow us to track all operations
within a distributed system, both of containers and aggregate
in-toto link metadata, to verify any container image before
it is provisioned. Figure 3 shows a (simpliﬁed) graphical
depiction of their supply chain.
This deployment exempliﬁes an architecture for the supply
chains of cloud native applications, in which new container
images, serverless functions and many types of deployments
are quickly updated using highly-automated pipelines. In this
case, a pipeline serves as a coordinator, scheduling steps to
worker nodes that serve as functionaries. These functionaries
then submit their metadata to an in-toto metadata store.
Once a new artifact is ready to be promoted to a cloud
environment, a container orchestration system queries an
in-toto admission controller. This admission controller en-
sures that every operation on this delivered product has been
performed by allowed nodes and that all the artifacts were
acted on according to the speciﬁcation in the in-toto layout.
Deployment insight. Our interaction with kubesec forced
us to investigate other artifact identiﬁers such as container
images (in addition to ﬁles). While in-toto can be used
today to track container images, the ability to point to an
OCIv2 [21] image manifest can provide a more succinct link
metadata representation and will be part of future work.
6.3 Datadog: E2E veriﬁcation of Python packages
Datadog is a monitoring service for cloud-scale applications,
providing monitoring of servers, databases, tools, and
services, through a software-as-a-service-based data analytics
platform [5]. It supports multiple cloud service providers,
including Amazon Web Services (AWS), Microsoft Azure,
1402    28th USENIX Security Symposium
USENIX Association
step. It then extracts ﬁles from the wheel and checks that
they correspond to exactly the same Python source code and
YAML conﬁguration ﬁles as the products of the tag step.
Thus, this layout provides end-to-end veriﬁcation: it prevents a
compromised pipeline from causing users to trust wheels with
source code that was never released by Datadog developers.
Transport with The Update Framework (TUF). Whereas
in-toto provides end-to-end veriﬁcation of the Datadog
pipeline, it does not solve a crucial problem that arises in prac-
tice: How to securely distribute, revoke, and replace the public
keys used to verify the in-toto layout. This mechanism must
be compromise-resilient [100–102, 121], and resistant to a
compromise of the software repository or server used to serve
ﬁles. While SSL / TLS protects users from man-in-the-middle
(MitM) attacks, it is not compromise-resilient, because
attackers who compromise the repository can simply switch
the public keys used to verify in-toto layout undetected,
and thus defeat end-to-end veriﬁcation. Likewise, other
solutions, such as X509 certiﬁcates do not support necessary
features such as in-band key revocation and key rotation.
The Update Framework (TUF) [100–102, 121] provides
precisely this type of compromise-resilient mechanism, as
well as in-band key revocation and key rotation. To do so,
TUF adds a higher layer of signed metadata to the repository
following two design principles that inspired the in-toto
design. The ﬁrst is the use of roles in a similar fashion to
in-toto, so that a key compromise does not necessarily
affect all targets (i.e., any Python wheels, or even in-toto
metadata). The second principle is minimizing the risk of
a key compromise using ofﬂine keys, or signing keys that
are kept off the repository and pipeline in a cold storage
mechanism, such as safe deposit boxes, so that attackers who
compromise the infrastructure are unable to ﬁnd these keys.
TUF is used within the Datadog integrations downloader
to distribute, in a compromise-resilient manner, the: (1)
root of trust for all wheels, TUF and in-toto metadata, (2)
in-toto layout, and (3) public keys used to verify this layout.
TUF also guarantees that MitM attackers cannot tamper
with the consistency, authenticity, and integrity of these
ﬁles, nor rollback or indeﬁnitely replay in-toto metadata.
This security model is simpliﬁed because it ignores some
considerations that are out of the scope of this paper.
In summary, the Datadog pipeline uses TUF to appropri-
ately bootstrap the root of the trust for the entire system, and
in-toto to guarantee that the pipeline packaged exactly the
source code signed by one of the Datadog developers inside
universal Python wheels. By tightly integrating TUF and
in-toto, Datadog’s users obtain the compromise resilience
of both systems combined.
Deployment insight. Through the Datadog deployment,
we learned how to use other last-mile systems like TUF
to provide not only compromise-resilience, but also
replay-protection, freshness guarantees, and mix-and-match
protection for in-toto metadata.
Figure 4: The simpliﬁed Datadog agent integrations supply chain. There
are three steps (tag step, wheels-builder step, wheels-signer step), and
one inspection. Arrows denote MATCH rules, the tag step is signed using a
hardware dongle whereas the CI system uses online keys.
Google Cloud Platform, and Red Hat OpenShift. At the time
of writing, it has over 8,000 customers, and collects trillions
of monitoring record points per day.
The Datadog agent is software that runs on hosts. It
collects events and metrics from hosts and sends them to
Datadog, where customers can analyze their monitoring and
performance data. The agent integrations are plug-ins that
collect metrics from services running on customer infrastruc-
ture. Presently, there are more than one hundred integrations
that come installed out-of-the-box with the Agent.
Datadog developers wanted an ability to automatically
build and publish new or updated integrations independently
of agent releases. This is so interested users can try new
or updated integrations as they become available, and test
whether they are applicable to their needs.
2.
This section will cover how Datadog built the ﬁrst
tamper-evident pipeline using in-toto and how it leveraged
TUF to safely bootstrap key distribution and provide replay-
protection and freshness guarantees to in-toto metadata.
End-to-end veriﬁcation with in-toto. The Datadog agent
integrations supply chain, shown in Figure 4, has three steps:
1. The ﬁrst tag step outputs Python source code as products.
Every integration consists of Python source code and
several YAML [133] conﬁguration ﬁles. The link for this
step is signed using a Yubikey hardware dongle [29]
In the second wheels-builder step, the pipeline must
receive the same source code from the tag step and
produce a Python wheel [24], as well as its updated
Python metadata. Each wheel is a ZIP ﬁle and its
metadata is an HTML ﬁle that points to all the available
versions of an integration.
In the third wheels-signer step, the pipeline must
receive, as materials,
the
wheels-builder step. This steps signs for all wheels
using the system described in the next subsection. It can
be dangerous packaging Python source code, because
arbitrary code can be executed during the packaging
process, which can be inserted by compromising the
GitHub repository. Therefore, this step is separate from
the wheels-builder step, so that a compromise of the
former does not yield the signing keys of this step.
Finally, there is one inspection, which ﬁrst ensures that a
given wheel matches the materials of the wheels-signer
the same products as
3.
USENIX Association
28th USENIX Security Symposium    1403
tagwheels-builderwheels-signerunzipDevelopersUsers(via Agent)CI/CDtag.linkwheels-builder.linkwheels-signer.linkunzip.linkdd-check/setup.py: 0xAdd-check/setup.py: 0xAdd_check.whl: 0xBdd_check.whl: 0xBdd_check.whl: 0xBdd-check/setup.py: 0xA7 Evaluation
We evaluated in-toto’s ability to guarantee software supply
chain integrity on two fronts: efﬁciency and security. We set
off to answer the following questions:
Does in-toto incur reasonable overheads in terms of
bandwidth, storage overhead and veriﬁcation time?
Can in-toto be used to protect systems against real-life
supply chain compromises?
In order to answer the ﬁrst question, we explored in-toto
as used in the context of Datadog for two reasons: Datadog
offers more than 111 integration packages to verify with
in-toto, and its data and source code is publicly available.
Furthermore, it is a production-ready integration that can be
used by Datadog’s more than 8,000 clients today [31]. Their
clients include major companies like Twitter, NASDAQ and
The Washington Post [4].
Then, we surveyed historical supply chain compromises
and catalogued them. We evaluated these compromises
against the in-toto deployments described in Section 6,
accounting for their supply chain conﬁguration, and including
the actors involved and their possible key assignments. By
studying the nature of each compromise, we were able to
estimate what degree of key compromise could hypothetically
happen and, with it, the consequences of such a compromise
on these supply chains when in-toto is in place.
7.1 in-toto’s overhead in the Datadog deployment
In the three major costs that in-toto presents are the storage,
transfer and veriﬁcation cost. In order to explore these costs,
we set out to use the publicly available Datadog agent integra-
tion client and software repository. From this data, we can de-
rive the cost of storing in-toto metadata in the repository, the
cost of transferring the in-toto metadata for any given pack-
age and the veriﬁcation times when installing any package.