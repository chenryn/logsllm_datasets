o
w
t
e
n
f
o
n
o
i
t
c
a
r
f
0.6
0.4
0.2
0.0
0.0
0.2
107
106
105
s
l
i
a
m
e
f
o
r
e
b
m
u
n
104
103
102
101
100
100
101
spamtrap
blacklist
104
105
102
103
number of tweets
networks with common spam
networks with email-only spam
0.4
spam domain ratio
0.6
0.8
1.0
Figure 1: (left) Cumulative distribution for the spam domain ratio for /24 networks that send spam; the spam
domain ratio for a network is the fraction of the number of spam domains to the total number of domains sent
from them network; (right) Number of emails/tweets for each common spam domain; each point is associated
to a common spam domain and has a diﬀerent symbol according to how the domain was detected.
that advertise spam on both email and Twitter tend to send
more spam overall than the networks that advertise spam
exclusively through email. We also study the sources that
allow us to identify spam and show that URL blacklists help
identify the most spam, although spamtraps are also eﬀec-
tive to discover high-volume spam domains.
We divide each data set into two secondary data sets, ac-
cording to whether a message contains URLs that are pub-
lished on both platforms or are exclusive to one platform.
Table 1 presents details on the secondary data sets. There
are 740 spam domains common to both Yahoo and Twit-
ter which appear in 27M emails and 198K tweets. More
than half (55%) of the spam emails contain domains that
appear on Twitter. Because the tweets in our data set have
already passed through Twitter’s spam ﬁlters (as explained
in Section 3.4), we cannot make a deﬁnitive assessment on
the amount of common spam. However, because Twitter
uses email blacklists to ﬁlter spam [6], if tweets were not
ﬁltered, we would likely have even more spam domains in
common with email. Thus, the numbers in Table 1 could
be interpreted as lower bounds for the amount of common
spam.
4.1 Publishing behavior
We focus on the common spam domains that we do iden-
tify. We compare how much each domain is advertised across
the two platforms. Only 10% of the common domains ap-
pear in more tweets than emails and 60% of the common do-
mains appear in at least ten times as many emails as tweets.
We also ﬁnd that 99% of all domains that appear in tweets
also appear in emails. These results could be an artifact of
the pre-ﬁltering of tweets (e.g., if Twitter had already ﬁl-
tered the common spam that is more prevalent in tweets)
or of using email-based blacklists to detect Twitter spam.
However, if we take into account the total number of mes-
sages sent on the two platforms, the result could also mean
that email is still a more pervasive platform for sending spam
and that Twitter may be used simply as a backup for email.
To better understand the implications of our observation,
we are currently implementing Twitter-speciﬁc spam detec-
tion techniques [3] that are trained independently from email
spam.
Next, we compare the spamming behavior of users that
send spam on both platforms to that of users that send spam
on only one platform. In doing so, we hope to understand
whether common spam domains are associated with heavier
spammers. We restrict our analysis to Yahoo users because
we ﬁnd little Twitter-only spam for a meaningful compari-
son. We extract the /24 networks from which every email
was sent and group them into two categories: those from
which at least one common spam domain was advertised and
those from which no common spam, but at least one email-
only spam domain, was sent. For each network, we compute
the spam domain ratio as the fraction of spam domains to
the total number of domains sent from the network.
The left graph in Figure 1 shows the distributions of the
spam domain ratio for networks that originate common spam
and networks that are never source for common spam. The
networks that advertise at least one common spam domain
have a higher ratio than those that do not. Although this
observation does not necessarily imply a causal relationship
between sending spam on multiple platforms and the vol-
ume of email spam, it does indicate a correlation that could
be exploited by spam ﬁlters to improve their eﬃciency: net-
works that send spam domains that also appear on Twitter
are likely to send more spam overall than those networks
advertising domains that are exclusive to email.
4.2 Identiﬁcation
Given that detecting common spam domains can help
identify networks that are likely to send more spam, we
ask what is the better source for detecting these domains.
4641.0
0.8
1.0
0.8
i
s
n
a
m
o
d
f
o
n
o
i
t
c
a
r
f
0.6
0.4
0.2
0.0
100
101
102
103
104
avg number of lookups per day
i
s
n
a
m
o
d
f
o
n
o
i
t
c
a
r
f
0.6
0.4
common
Yahoo only
Twitter only
105
106
0.2
0.0
100
at the same time
on Yahoo before Twitter
on Twitter before Yahoo
104
105
101
102
103
avg number of lookups per day
Figure 2: Cumulative distribution of the average number of unique networks querying for spam domains per
day: (left) all spam domains, and (right) common spam domains.
We separate the spam messages according to the informa-
tion source (blacklists or spamtrap) used to classify them
as spam. Table 1 shows statistics about the results. Only
7% of all spam emails and 9% of all spam tweets could
be identiﬁed using both sources, which is evidence for the
lack of overlap between our spamtrap data and URL black-
lists. Although spamtraps constitute an important source
of information for building blacklists, oftentimes blacklists
are not updated quickly enough to keep up with the “fresh”
spam [12].
Although spamtraps appear to detect fewer spam domains
than blacklists (4% of all email spam domains are identiﬁed
using the spamtrap data), these domains are signiﬁcant on
email:
they contribute to 27% of all email spam and to
33% of all common spam sent through emails. For Twitter,
spamtrap data is less decisive, identifying only 9% of all
tweets. For further evidence, the right graph of Figure 1
shows the number of tweets vs. the number of emails each
common domain appears in. Each point is associated with a
domain and has a diﬀerent symbol according to whether the
domain was identiﬁed as spam using blacklists or spamtrap
data.
In conclusion, blacklists can identify most common
spam, although spamtrap data is also eﬀective in detecting
the common domains that appear in many emails.
5. EFFECTIVENESS OF COMMON SPAM
We presented evidence that there is a signiﬁcant amount
of common spam across tweets and emails: 55% of all spam
emails and 99% of all spam tweets advertise content also
published on the other platform. We seek now to better un-
derstand the role of each platform in the spammers’ strate-
gies. Is Twitter a backup for cases when email spam is not
eﬀective? Or do the platforms combine to capture a more
diverse set of users, unattainable from a single medium?
To understand the eﬀectiveness of spam on each plat-
form, we use DNS lookup information collected by Verisign.
Verisign manages the TLD nameservers responsible for the
.com and .net domains. We obtained a data set with infor-
mation about when each domain (ending in .com or .net) in
our data set was looked up. We consider only those lookups
performed during the time when our tweets and emails were
sent (March 2011). The data set contains information about
the /24 networks of recursive resolvers that looked up 66%
of the common spam domains, 57% of the Yahoo exclusive
domains, and 66% of the Twitter exclusive domains. To es-
timate the number of clicks on each domain, and implicitly
its popularity, we use the number of unique /24 networks
from which a DNS query is performed.
Figure 2(left) presents the distribution of the number of
unique networks that lookup each spam domain in March
2011. There are around ten times more networks that lookup
common spam domains than spam domains that are exclu-
sive to email. We cannot make a deﬁnitive assessment for the
Twitter exclusive domains due to their low number. We fur-
ther separate the common domains according to when they
were ﬁrst advertised: on both platforms on the same day,
on Twitter before email, and on email before Twitter. We
plot the distributions for each category in Figure 2(right).
The domains that are published for the ﬁrst time on both
platforms on the same day tend to receive more clicks than
those that are published on diﬀerent days.
We ﬁnd that there is a positive correlation between pub-
lishing spam on multiple platforms and its eﬀectiveness,
measured as the number of unique networks that lookup the
spam domains. Our data is insuﬃcient to determine whether
the number of dissemination platforms or some other unob-
served property of the spammer (e.g., some spammers may
be sophisticated enough that they send high yield spam and
use multiple dissemination platforms) is responsible for the
increased eﬀectiveness of spam. Notwithstanding, the as-
sociation that we observe strengthens or ﬁnding from Sec-
tion 4.1, that sharing spam information across platforms
(e.g., whether a spam domain appears on both Twitter and
email) could help email spam ﬁlters detect the heavy and
virulent spammers quicker.
Equating the number of clicks that a domain receives with
the number of unique /24 networks from which DNS queries
are performed for it can introduce bias in our results. Most
importantly, due to caching of DNS information along the
DNS hierarchy, not all clicks on an URL lead to queries to
465the TLD nameservers. However, we believe that the num-
ber of unique networks still reﬂects the relative popularity
between domains. If anything, it may under-represent the
more popular domains, for which it is more likely that a
query is cached at a lower level resolver.
6. CONCLUSIONS
We presented a measurement study on the properties of
common spam across multiple content sharing platforms.
We focused on two popular web applications, Twitter and
Yahoo! Mail. We make two main observations: (1) spam
sent on both Twitter and email at the same time has a
better exposure and a higher lookup rate than spam sent
exclusively with email; and (2) spammers that advertise on
both on email and Twitter send more email spam overall
than spammers that advertise only on email.
The limitations of the data sets do not allow us to draw
deﬁnitive conclusions about how spammers use Twitter and
email. For example, we cannot determine whether there is
causation or simply correlation between sending spam con-
currently using multiple mechanisms and its virulence and
volume. Notwithstanding, our results suggest that general
solutions for detecting message abuse that incorporate in-
formation and features from multiple platforms at the same
time may ultimately improve the accuracy and responsive-
ness of existing ﬁlters.
7. ACKNOWLEDGEMENTS
We thank our shepherd Christian Kreibich and the IMC
reviewers for their valuable feedback. This project was sup-
ported by NSF grants CNS-0643974 and CNS-1111723, and
by NSF grant 0937060 to the Computing Research Associa-
tion for the CIFellows Project.
8. REFERENCES
[1] D. S. Anderson, C. Fleizach, S. Savage, and G. M.
Voelker. Spamscatter: Characterizing internet scam
hosting infrastructure. In Usenix Security, 2007.
[2] F. Benevenuto, G. Magno, T. Rodrigues, and
V. Almeida. Detecting spammers on Twitter. In
CEAS, 2010.
[3] F. Benevenuto, G. Magno, T. Rodrigues, and
V. Almeida. Detecting spammers on twitter. In CEAS,
2010.
[4] Full metal email: Confessions of an ’anti-spam zealot’.
http://goo.gl/WL8IG.
[5] H. Gao, J. Hu, C. Wilson, Z. Li, Y. Chen, and B. Y.
Zhao. Detecting and characterizing social spam
campaign. In ACM IMC, 2010.
[6] C. Grier, K. Thomas, V. Paxson, and M. Zhang.
@spam: The underground on 140 characters or less. In
ACM CCS, 2010.
[7] K. Lee, J. Caverlee, and S. Webb. Uncovering social
spammers: social honeypots + machine learning. In
SIGIR, 2010.
[8] Newest messaging malware targets Facebook and
Twitter. http://goo.gl/TrGkq.
[9] Unstoppable new phishing attacks blanket Facebook,
Twitter, Hotmail. http://goo.gl/X0tdr.
[10] Y. Niu, Y. min Wang, H. Chen, M. Ma, and F. Hsu. A
quantitative study of forum spamming using
contextbased analysis. In NDSS, 2007.
[11] A. Ramachandran and N. Feamster. Understanding
the network-level behavior of spammers. In ACM
Sigcomm, 2006.
[12] A. Ramachandran, N. Feamster, and S. Vempala.
Filtering spam with behavioral blacklisting. In ACM
CCS, 2007.
[13] Y. Shin, M. Gupta, and S. Myers. Prevalence and
mitigation of forum spamming. In IEEE Infocom,
2011.
[14] Spam forensics: Reverse-engineering spammer tactics.
http://goo.gl/Y9wmk.
[15] Symantec messagelabs intelligence: 2010 annual
security report. http://www.messagelabs.com/
mlireport/MessageLabsIntelligence_2010_Annual_
Report_FINAL.pdf.
[16] K. Thomas, C. Grier, J. Ma, V. Paxson, and D. Song.
Design and evaluation of a real-time URL spam
ﬁltering service. In IEEE Security & Privacy, 2011.
[17] State of twitter spam. http://goo.gl/M4X5M.
[18] Twitter ﬁnally reveals all its secret stats.
http://goo.gl/07kzP.
[19] Y. Xie, F. Yu, K. Achan, E. Gillum, M. Goldszmidt,
and T. Wobber. How dynamic are ip addresses? In
ACM Sigcomm, 2007.
[20] Y. Xie, F. Yu, K. Achan, R. Panigrahy, G. Hulten,
and I. Osipkov. Spamming botnets: signatures and
characteristics. In ACM Sigcomm, 2008.
466