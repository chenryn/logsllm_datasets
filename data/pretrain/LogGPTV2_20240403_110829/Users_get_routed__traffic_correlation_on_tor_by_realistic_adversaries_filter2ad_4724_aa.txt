title:Users get routed: traffic correlation on tor by realistic adversaries
author:Aaron Johnson and
Chris Wacek and
Rob Jansen and
Micah Sherr and
Paul F. Syverson
Trafﬁc Correlation on Tor by Realistic Adversaries
Users Get Routed:
Aaron Johnson1
Chris Wacek2
Rob Jansen1 Micah Sherr2
Paul Syverson1
1U.S. Naval Research Laboratory, Washington DC
{aaron.m.johnson, rob.g.jansen, paul.syverson}@nrl.navy.mil
2Georgetown University, Washington DC
{cwacek, msherr}@cs.georgetown.edu
ABSTRACT
We present the ﬁrst analysis of the popular Tor anonymity network
that indicates the security of typical users against reasonably realis-
tic adversaries in the Tor network or in the underlying Internet. Our
results show that Tor users are far more susceptible to compromise
than indicated by prior work. Speciﬁc contributions of the paper
include (1) a model of various typical kinds of users, (2) an adver-
sary model that includes Tor network relays, autonomous systems
(ASes), Internet exchange points (IXPs), and groups of IXPs drawn
from empirical study, (3) metrics that indicate how secure users are
over a period of time, (4) the most accurate topological model to
date of ASes and IXPs as they relate to Tor usage and network con-
ﬁguration, (5) a novel realistic Tor path simulator (TorPS), and (6)
analyses of security making use of all the above. To show that our
approach is useful to explore alternatives and not just Tor as cur-
rently deployed, we also analyze a published alternative path se-
lection algorithm, Congestion-Aware Tor. We create an empirical
model of Tor congestion, identify novel attack vectors, and show
that it too is more vulnerable than previously indicated.
Categories and Subject Descriptors
C.2.0 [Computer-Communication Networks]: General—Secu-
rity and protection
Keywords
Anonymity; metrics; onion routing
1.
INTRODUCTION
Tor is a volunteer-operated anonymity network that is estimated
to protect the privacy of hundreds of thousands of daily users [13,
22]. However, Tor is known to be insecure against an adversary
that can observe a user’s trafﬁc entering and exiting the anonymity
network. Quite simple and efﬁcient techniques can correlate trafﬁc
at these separate locations by taking advantage of identifying traf-
ﬁc patterns [29]. As a result, the user and his destination may be
identiﬁed, completely subverting the protocol’s security goals.
ACM acknowledges that this contribution was authored or co-authored by an em-
ployee, contractor or afﬁliate of the United States government. As such, the Gov-
ernment retains a nonexclusive, royalty-free right to publish or reproduce this article,
or to allow others to do so, for Government purposes only.
CCS’13, November 4–8, 2013, Berlin, Germany.
Copyright is held by the owner/author(s). Publication rights licensed to ACM.
ACM 978-1-4503-2477-9/13/11 ...$15.00.
http://dx.doi.org/10.1145/2508859.2516651.
The trafﬁc correlation problem in Tor has seen much attention
in the literature. Prior Tor security analyses often consider entropy
or similar statistical measures as metrics of the security provided
by the system at a static point in time.
In addition, while prior
metrics of security may provide useful information about overall
usage, they typically do not tell users how secure a type of behav-
ior is. Further, similar previous work has thus far only considered
adversaries that control either a subset of the members of the Tor
network, a single autonomous system (AS), or a single Internet ex-
change point (IXP). These analyses have missed important char-
acteristics of the network, such as that a single organization often
controls several geographically diverse ASes or IXPs. That organi-
zation may have malicious intent or undergo coercion, threatening
users of all network components under its control.
Given the severity of the trafﬁc correlation problem and its se-
curity implications, we develop an analysis framework for evaluat-
ing the security of various user behaviors on the live Tor network
and show how to concretely apply this framework by performing a
comprehensive evaluation of the security of the Tor network [41]
against the threat of complete deanonymization. To enable such an
analysis, we develop a detailed model of a network adversary that
includes (i) the largest and most accurate system for AS path in-
ference yet applied to Tor and (ii) a thorough analysis of the threat
of Internet exchange points and IXP coalitions. We also develop
realistic metrics that inform this analysis, considering the network
topology as it evolves over time, for example, as new relays are
introduced and others go ofﬂine.
Our analysis shows that 80% of all types of users may be de-
anonymized by a relatively moderate Tor-relay adversary within six
months. Our results also show that against a single AS adversary
roughly 100% of users in some common locations are deanonymized
within three months (95% in three months for a single IXP). Fur-
ther, we ﬁnd that an adversary controlling two ASes instead of one
reduces the median time to the ﬁrst client de-anonymization by an
order of magnitude: from over three months to only 1 day for a typ-
ical web user; and from over three months to roughly one month for
a BitTorrent user. This clearly shows the dramatic effect an adver-
sary that controls multiple ASes can have on security.
We observe that since the relays that comprise Tor’s egress points
may independently specify IP and port-based access control poli-
cies, the set of relays available for anonymous circuits is dependent
on the user’s application (web browsing, IRC, BitTorrent, etc.). We
examine how this choice of application affects the security of the
user’s anonymous connections. Our analysis shows that BitTorrent
users not only degrade performance of the Tor network for every-
body else, but against a Tor-relay adversary they get signiﬁcantly
less anonymity protection than typical users. They are bested for
337least anonymity among the uses we considered only by users of the
collaborative-work real-time editor Gobby [1].
After describing background and related work, we next set out
our adversary model and security metrics. We then describe our
user models and the use of Monte Carlo simulation to sample how
user trafﬁc ﬂows over the network, using our Tor Path Simulator
(TorPS) to generate paths. We describe a newly-introduced Inter-
net map that we use in the subsequent section to evaluate the secu-
rity of circuits created via TorPS against a network adversary, after
having analyzed security against a Tor-relay adversary. Finally we
demonstrate the applicability of our approach beyond evaluation of
the current Tor network by analyzing Congestion-Aware Tor [45], a
system that attempts to improve Tor network performance by mea-
suring relay congestion and avoiding the most congested parts of
the network when sending application trafﬁc.
2. BACKGROUND
The Tor network consists of roughly 3000 relays pushing over
2500 MiB/s in aggregate [40]. Tor clients select three of these re-
lays to form a circuit through which they create TCP streams to
communicate with external Internet destinations. Tor measures the
real bandwidth (throughput over time) that each relay provides to
the network, and assigns each relay a selection weight based on
the bandwidth it provides. These weights are used to bias selection
for circuits in order to distribute load toward relays with more avail-
able network resources. Relays may specify a bandwidth allowance
over a desired time period: once the allowance is reached, the relay
will hibernate until the end of the time period. Hibernating relays
will neither participate in building new circuits nor transfer data for
Tor.
Relays have status ﬂags assigned to them by the directory au-
thority, which clients consider when choosing relays for a circuit.
The GUARD ﬂag is assigned to relays whose uptime is at least the
median for familiar relays, and if their bandwidth is at least the
minimum of 250 KiB/s and the median relay bandwidth. Clients
choose and maintain three active guards and use them as the entry
relay for all of their circuits to reduce the chance of directly con-
necting to an adversary. Clients rotate each guard at a random time
between 30 and 60 days. The EXIT ﬂag is assigned to relays who
allow direct connections with external Internet destinations. Ex-
its set individual exit policies specifying the IP address ranges and
port ranges to which they are willing to connect. Clients use these
policies to determine which relay to choose for the ﬁnal position in
each circuit. Guards and exits are more-highly weighted for the en-
try and exit position in a circuit, respectively, as not all relays fulﬁll
the requirements to obtain those ﬂags. Additionally, a relay obtains
the STABLE ﬂag if its weighted mean time before failure is at least
the median for known active relays. Clients building streams to a
port in the long-lived ports list must choose stable relays in each
position of the circuit. Finally, clients will never choose two relays
from the same /16 subnet or family for the same circuit. A family
is a set of relays that mutually indicate that they belong to a group
together.
3. RELATED WORK
Anonymity systems have received signiﬁcant study since
Chaum’s [11] seminal work on untraceable email in 1981. We
highlight the most relevant methods for measuring anonymity and
discuss many of the threats to anonymity systems.
Metrics and Methods for Evaluating Anonymity.
Serjantov
and Danezis [34] and Díaz et al. [12] independently propose eval-
uation frameworks that quantify anonymity using Shannon entropy
computed over a set of potential senders (or receivers). Hamel et
al. argue against entropy-based metrics and instead focus on how
an adversary’s actions can compromise anonymity [23]. They en-
vision an adversary with a ﬁxed bandwidth budget, and explore
how the adversary can spend that budget to compromise anonymity.
Syverson et al. also describe a bounded adversary and present a
model in which the adversary can corrupt a ﬁxed number of routers
within a time period [38], using probabilistic analysis to quantify
the resulting level of anonymity. Similar to this latter model, we
assume the existence of a ﬁxed adversary who either controls some
relays (“Relay Adversary”) or monitors a portion of the Internet
such as an AS or IXP (“Network Adversary”).
Elahi et al. [16] construct a simulation-based framework for mea-
suring how well Tor’s guard selection mechanism defends against
proﬁling attacks [47]. Similar to our techniques, their Changing
of the Guards simulator also uses data collected from the live Tor
network [40] to repeatedly simulate the behavior a client. Their
simulation study focuses on guard selection and adversarial relays.
In contrast, this paper explores Tor’s vulnerability to trafﬁc corre-
lation attacks (explained next) using various proﬁles of client be-
havior, adversary models, security metrics, and topological models
of the Tor network.
Trafﬁc Correlation Attacks. Onion routing is vulnerable to an
adversary who can monitor a user’s trafﬁc as it enters and leaves
the anonymity network; correlating that trafﬁc using trafﬁc analy-
sis links the observed sender and receiver of the communication.
Øverlier and Syverson ﬁrst demonstrated the practicality of the at-
tack in the context of discovering Tor Hidden Servers [32]. Later
work by Murdoch and Danezis show that trafﬁc correlation attacks
can be done quite efﬁciently against Tor [29].
Given the potential severity of trafﬁc correlation attacks, this pa-
per explores in depth users’ vulnerability to such attacks in the live
Tor network. To quantify the anonymity offered by Tor, we ex-
amine path compromise rates and how quickly extended use of the
anonymity network results in compromised paths.
Network Adversaries.
Feamster and Dingledine ﬁrst investi-
gate the ability of AS-level adversaries to observe both sides of
anonymous paths [19]. They argue that geographically diverse
paths may adversely affect anonymity since paths that traverse many
ASes are more likely than shorter paths to have the same AS on
both sides of the path. Edman and Syverson also explore AS path
diversity on Tor and introduce an AS-aware path selection algo-
rithm that uses “snapshots” of Tor’s AS graph to avoid AS-level
trafﬁc correlation attacks [15]. More recently, Akhoondi et al. pro-
pose a geographic-based relay selection method called LASTor [3]
that ensures AS diversity in selected paths by relying on concise
Internet atlases. A recent study by Wacek et al. indicates that the
same AS may appear in both sides of as many as 18% of anony-
mous circuits [44].
Murdoch and Zieli´nski argue that ensuring AS diversity in anony-
mous circuits is insufﬁcient to safeguard against trafﬁc correlation
attacks by network adversaries, since trafﬁc is routed between ASes
at IXPs (and hence a single IXP may observe trafﬁc traversing mul-
tiple ASes) [30]. They apply a Bayesian approach to show that an
adversary positioned at an IXP could sample trafﬁc from multiple
ASes and correlate ﬂows. Juen proposes a reﬁned relay selection
algorithm that provides both AS and IXP diversity [28]. We re-
mark that Tor does not currently implement any protection against
adversaries who operate ASes or IXPs.
By considering how often any AS appears on both sides of cir-
cuits, these works implicitly assume that all ASes are malicious but
are non-colluding. We also examine Tor’s vulnerability to network
338adversaries, but improve upon existing work by modeling a more
realistic adversary who monitors a ﬁxed set of ASes or IXPs.
In this paper, we do not consider circuit clogging, network latency,
or application1 or other attacks against Tor (cf. [2, 5, 8, 14, 18, 24,
29]). A comprehensive evaluation of all potential threats against
Tor is beyond the goals of this paper. Instead, we study in depth
a particular and well-understood threat against Tor—trafﬁc corre-
lation attacks by either malicious relay operators or networks that
monitor trafﬁc as it enters and exits Tor.
4. SECURITY MODEL AND METRICS
We present here realistic and useful adversary models and se-
curity metrics for the threat of trafﬁc correlation in onion routing.
In particular, we consider the types and amounts of adversary re-
sources, as well as how he may use them. We argue that security
metrics should be deﬁned in terms of such adversaries and should
present the probabilities of compromise over time. By applying
these methods, we will be able to obtain novel and realistic quanti-
tative estimates of Tor security against trafﬁc correlation.
4.1 Adversary Model
In general we consider it realistic that an adversary can observe,
delay, alter, drop, or add communication in a variety of ways. As
will become clear from our analysis, however, an adversary that
merely passively observes can be signiﬁcant and illuminating. We
limit our description and attentions herein to a passive end-to-end
correlating adversary: one that learns source or destination of com-
munication when in position to observe either or both of these and
that always links observations of the same communication ﬂow
anywhere in its path. This linking occurs regardless of how the
ﬂow’s appearance may have changed en route. We do consider an
adversary that may actively add network resources or corrupt exist-
ing resources. But we do not consider any addition, alteration, or
disruption of network trafﬁc directed over those added adversary
resources. Nor do we consider adversarial removal or degradation
of network resources in this paper.
Adversary Resources.
Our adversary is assumed to have one
or more types of resources at his disposal. Tor relays themselves
are an obvious resource, although it is useful to further specify if
the adversary observes guard, middle, or exit relays. Besides re-
lays themselves the most obvious possible adversary resource is the
destination server. At a somewhat more abstract level, an adversary
may control an amount of bandwidth. This could represent either a
portion of the existing network or a resource that the adversary can
add to the network by contributing additional relays. In this paper
we do not consider adversarial bridges [36].
Tor and other low-latency anonymous communications networks
are overlays above the transport layer. The primary organizational
unit for managing Internet routing below the overlay is the au-
tonomous system (AS). An adversary may control one or several