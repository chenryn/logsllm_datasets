# Title: Traffic Correlation on Tor by Realistic Adversaries

## Authors:
- Aaron Johnson
- Chris Wacek
- Rob Jansen
- Micah Sherr
- Paul F. Syverson

### Affiliations:
- **Aaron Johnson, Rob Jansen, Paul Syverson**
  - U.S. Naval Research Laboratory, Washington DC
  - Email: {aaron.m.johnson, rob.g.jansen, paul.syverson}@nrl.navy.mil
- **Chris Wacek, Micah Sherr**
  - Georgetown University, Washington DC
  - Email: {cwacek, msherr}@cs.georgetown.edu

## Abstract
We present the first comprehensive analysis of the popular Tor anonymity network, focusing on the security of typical users against reasonably realistic adversaries in the Tor network or the underlying Internet. Our results show that Tor users are far more susceptible to compromise than previously indicated. Key contributions of this paper include:
1. A model of various typical user behaviors.
2. An adversary model that includes Tor network relays, autonomous systems (ASes), Internet exchange points (IXPs), and groups of IXPs based on empirical studies.
3. Metrics that indicate the security of users over a period of time.
4. The most accurate topological model to date of ASes and IXPs as they relate to Tor usage and network configuration.
5. A novel realistic Tor path simulator (TorPS).
6. Analyses of security using all the above.

To demonstrate the utility of our approach, we also analyze a published alternative path selection algorithm, Congestion-Aware Tor. We create an empirical model of Tor congestion, identify new attack vectors, and show that it is more vulnerable than previously thought.

## Categories and Subject Descriptors
C.2.0 [Computer-Communication Networks]: General—Security and protection

## Keywords
Anonymity, metrics, onion routing

## 1. Introduction
Tor is a volunteer-operated anonymity network that protects the privacy of hundreds of thousands of daily users. However, Tor is known to be insecure against adversaries who can observe a user's traffic entering and exiting the network. Simple and efficient techniques can correlate traffic at these separate locations by exploiting identifying traffic patterns, potentially subverting the protocol's security goals.

The traffic correlation problem in Tor has been extensively studied. Prior analyses often use entropy or similar statistical measures to evaluate the system's security at a static point in time. These metrics, while informative about overall usage, do not provide users with information about the security of specific behaviors. Additionally, previous work typically considers adversaries controlling a subset of Tor network members, a single AS, or a single IXP, missing important characteristics such as the control of multiple geographically diverse ASes or IXPs by a single organization.

Given the severity of the traffic correlation problem, we develop an analysis framework to evaluate the security of various user behaviors on the live Tor network. This framework is applied to perform a comprehensive evaluation of the security of the Tor network against the threat of complete deanonymization. We develop a detailed model of a network adversary, including the largest and most accurate system for AS path inference yet applied to Tor, and a thorough analysis of the threat from IXPs and IXP coalitions. We also develop realistic metrics that consider the evolving network topology.

Our analysis shows that 80% of all types of users may be deanonymized by a moderate Tor-relay adversary within six months. Against a single AS adversary, roughly 100% of users in some common locations are deanonymized within three months (95% in three months for a single IXP). An adversary controlling two ASes instead of one reduces the median time to the first client de-anonymization by an order of magnitude: from over three months to only 1 day for a typical web user, and from over three months to roughly one month for a BitTorrent user. This highlights the dramatic effect of an adversary controlling multiple ASes on security.

We also examine how the choice of application (e.g., web browsing, IRC, BitTorrent) affects the security of the user's anonymous connections. Our analysis shows that BitTorrent users not only degrade the performance of the Tor network but also receive significantly less anonymity protection than typical users, second only to users of the collaborative-work real-time editor Gobby.

After discussing background and related work, we present our adversary model and security metrics. We then describe our user models and the use of Monte Carlo simulation to sample user traffic flows over the network, using our Tor Path Simulator (TorPS) to generate paths. We introduce a new Internet map to evaluate the security of circuits created via TorPS against a network adversary, after analyzing security against a Tor-relay adversary. Finally, we demonstrate the applicability of our approach by analyzing Congestion-Aware Tor, a system that aims to improve Tor network performance by avoiding congested parts of the network.

## 2. Background
The Tor network consists of approximately 3,000 relays, pushing over 2,500 MiB/s in aggregate. Tor clients select three relays to form a circuit through which they create TCP streams to communicate with external Internet destinations. Tor measures the real bandwidth provided by each relay and assigns a selection weight based on this bandwidth to distribute load toward relays with more available resources. Relays may specify a bandwidth allowance over a desired time period; once the allowance is reached, the relay hibernates until the end of the period.

Relays have status flags assigned by the directory authority, which clients consider when choosing relays for a circuit. The GUARD flag is assigned to relays with sufficient uptime and bandwidth. Clients choose and maintain three active guards, rotating each guard at a random time between 30 and 60 days. The EXIT flag is assigned to relays that allow direct connections with external Internet destinations. Exits set individual exit policies specifying the IP address ranges and port ranges to which they are willing to connect. Guards and exits are more highly weighted for the entry and exit positions in a circuit, respectively. Additionally, a relay obtains the STABLE flag if its weighted mean time before failure is at least the median for known active relays. Clients building streams to a port in the long-lived ports list must choose stable relays in each position of the circuit. Clients will never choose two relays from the same /16 subnet or family for the same circuit.

## 3. Related Work
Anonymity systems have been extensively studied since Chaum's seminal work on untraceable email in 1981. We highlight the most relevant methods for measuring anonymity and discuss many of the threats to anonymity systems.

### Metrics and Methods for Evaluating Anonymity
Serjantov and Danezis and Díaz et al. independently propose evaluation frameworks that quantify anonymity using Shannon entropy computed over a set of potential senders (or receivers). Hamel et al. argue against entropy-based metrics and focus on how an adversary's actions can compromise anonymity. They envision an adversary with a fixed bandwidth budget and explore how the adversary can spend that budget to compromise anonymity. Syverson et al. describe a bounded adversary and present a model in which the adversary can corrupt a fixed number of routers within a time period, using probabilistic analysis to quantify the resulting level of anonymity. Similar to this latter model, we assume the existence of a fixed adversary who either controls some relays ("Relay Adversary") or monitors a portion of the Internet such as an AS or IXP ("Network Adversary").

Elahi et al. construct a simulation-based framework for measuring how well Tor's guard selection mechanism defends against profiling attacks. Their Changing of the Guards simulator uses data collected from the live Tor network to repeatedly simulate the behavior of a client. Their study focuses on guard selection and adversarial relays. In contrast, this paper explores Tor's vulnerability to traffic correlation attacks using various profiles of client behavior, adversary models, security metrics, and topological models of the Tor network.

### Traffic Correlation Attacks
Onion routing is vulnerable to an adversary who can monitor a user's traffic as it enters and leaves the anonymity network. Correlating that traffic using traffic analysis links the observed sender and receiver of the communication. Øverlier and Syverson first demonstrated the practicality of the attack in the context of discovering Tor Hidden Servers. Later work by Murdoch and Danezis showed that traffic correlation attacks can be done quite efficiently against Tor.

Given the potential severity of traffic correlation attacks, this paper explores in depth users' vulnerability to such attacks in the live Tor network. To quantify the anonymity offered by Tor, we examine path compromise rates and how quickly extended use of the anonymity network results in compromised paths.

### Network Adversaries
Feamster and Dingledine first investigate the ability of AS-level adversaries to observe both sides of anonymous paths. They argue that geographically diverse paths may adversely affect anonymity since paths that traverse many ASes are more likely to have the same AS on both sides of the path. Edman and Syverson explore AS path diversity on Tor and introduce an AS-aware path selection algorithm that uses "snapshots" of Tor's AS graph to avoid AS-level traffic correlation attacks. More recently, Akhoondi et al. propose a geographic-based relay selection method called LASTor that ensures AS diversity in selected paths by relying on concise Internet atlases. A recent study by Wacek et al. indicates that the same AS may appear in both sides of as many as 18% of anonymous circuits.

Murdoch and Zieliński argue that ensuring AS diversity in anonymous circuits is insufficient to safeguard against traffic correlation attacks by network adversaries, as traffic is routed between ASes at IXPs. They apply a Bayesian approach to show that an adversary positioned at an IXP could sample traffic from multiple ASes and correlate flows. Juen proposes a refined relay selection algorithm that provides both AS and IXP diversity. We note that Tor does not currently implement any protection against adversaries who operate ASes or IXPs.

By considering how often any AS appears on both sides of circuits, these works implicitly assume that all ASes are malicious but non-colluding. We also examine Tor's vulnerability to network adversaries, but improve upon existing work by modeling a more realistic adversary who monitors a fixed set of ASes or IXPs.

In this paper, we do not consider circuit clogging, network latency, or application-specific or other attacks against Tor. Instead, we study in depth a particular and well-understood threat against Tor—traffic correlation attacks by either malicious relay operators or networks that monitor traffic as it enters and exits Tor.

## 4. Security Model and Metrics
We present realistic and useful adversary models and security metrics for the threat of traffic correlation in onion routing. Specifically, we consider the types and amounts of adversary resources and how they may be used. We argue that security metrics should be defined in terms of such adversaries and should present the probabilities of compromise over time. By applying these methods, we obtain novel and realistic quantitative estimates of Tor security against traffic correlation.

### 4.1 Adversary Model
In general, we consider it realistic that an adversary can observe, delay, alter, drop, or add communication in various ways. However, a passive end-to-end correlating adversary, who learns the source or destination of communication when in position to observe either or both and always links observations of the same communication flow, is significant and illuminating. We consider an adversary that may actively add network resources or corrupt existing resources but do not consider any addition, alteration, or disruption of network traffic directed over those added adversary resources. Nor do we consider adversarial removal or degradation of network resources in this paper.

### Adversary Resources
Our adversary is assumed to have one or more types of resources at their disposal. Tor relays themselves are an obvious resource, although it is useful to further specify if the adversary observes guard, middle, or exit relays. Besides relays, the most obvious possible adversary resource is the destination server. At a more abstract level, an adversary may control an amount of bandwidth, representing either a portion of the existing network or a resource that the adversary can add by contributing additional relays. In this paper, we do not consider adversarial bridges.