title:Predicting Impending Exposure to Malicious Content from User Behavior
author:Mahmood Sharif and
Jumpei Urakawa and
Nicolas Christin and
Ayumu Kubota and
Akira Yamada
Predicting Impending Exposure to Malicious Content
from User Behavior
Mahmood Sharif
Carnegie Mellon University
PI:EMAIL
Jumpei Urakawa
KDDI Research, Inc.
PI:EMAIL
Nicolas Christin
Carnegie Mellon University
PI:EMAIL
Ayumu Kubota
KDDI Research, Inc.
PI:EMAIL
Akira Yamada
KDDI Research, Inc.
PI:EMAIL
ABSTRACT
Many computer-security defenses are reactive—they operate only
when security incidents take place, or immediately thereafter. Re-
cent efforts have attempted to predict security incidents before
they occur, to enable defenders to proactively protect their devices
and networks. These efforts have primarily focused on long-term
predictions. We propose a system that enables proactive defenses at
the level of a single browsing session. By observing user behavior,
it can predict whether they will be exposed to malicious content on
the web seconds before the moment of exposure, thus opening a
window of opportunity for proactive defenses. We evaluate our sys-
tem using three months’ worth of HTTP traffic generated by 20,645
users of a large cellular provider in 2017 and show that it can be
helpful, even when only very low false positive rates are acceptable,
and despite the difficulty of making “on-the-fly” predictions. We
also engage directly with the users through surveys asking them
demographic and security-related questions, to evaluate the utility
of self-reported data for predicting exposure to malicious content.
We find that self-reported data can help forecast exposure risk over
long periods of time. However, even on the long-term, self-reported
data is not as crucial as behavioral measurements to accurately
predict exposure.
CCS CONCEPTS
• Security and privacy → Network security; Human and societal
aspects of security and privacy; • Computing methodologies →
Neural networks;
KEYWORDS
Exposure prediction; network security; proactive security
ACM Reference Format:
Mahmood Sharif, Jumpei Urakawa, Nicolas Christin, Ayumu Kubota, and Akira
Yamada. 2018. Predicting Impending Exposure to Malicious Content, from
User Behavior. In Proceedings of 2018 ACM SIGSAC Conference on Computer
& Communications Security (CCS ’18). ACM, New York, NY, USA, 15 pages.
https://doi.org/10.1145/3243734.3243779
Permission to make digital or hard copies of part or all of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for third-party components of this work must be honored.
For all other uses, contact the owner/author(s).
CCS ’18, October 15–19, 2018, Toronto, ON, Canada
© 2018 Copyright held by the owner/author(s).
ACM ISBN 978-1-4503-5693-0/18/10.
https://doi.org/10.1145/3243734.3243779
1 INTRODUCTION
John typically uses his mobile device to browse a couple of news
websites, read and post social media updates, and check his web
mail. Today, however, there is a soccer game he really wants to
watch. His TV subscription does not include a streaming option
for the relevant channel; so, instead, he frantically looks for a free
streaming website. His mobile browser issues several warnings,
but John proceeds undeterred, and, after a number of unsuccessful
attempts, manages to find a streaming site—although the website
and game commentary are in Syldavian, a language he does not
speak, he can watch his favorite team on the long commute. Sadly
for him, a relatively common way of monetizing illicit streaming
sites is to get their visitors to download malware [61], and John’s
phone gets compromised in the process. Over the following week,
John loses access to his email account, gets invoiced for premium
calls [27], and funds go missing from his bank account.
Could this have been avoided? Traditionally, mobile users have
relied on blacklists and anti-viruses for protection. However, such
tools suffer from several limitations: they are prone to false positives
and false negatives, and cannot protect users until a site has been
confirmed as malicious and has been included in a blacklist (or a
specific signature has been included in an anti-virus database). In
other words, attackers have a “window of opportunity” between,
at least, the deployment of the malicious site and its inclusion
in a blacklist (see Sec. 4.2). Further, as in John’s example above,
determined users may elect to willfully ignore warnings.
Perhaps, in John’s case, a better approach would have been to
observe that John’s behavior right before his phone got infected was
very different from his usual browsing patterns. On that day, John
was quickly browsing through many pages, some in languages he
does not speak, was spending very little time on each page, and, as
a by-product of his repeated searches, was downloading numerous
advertisements. All of these could have been indicators that John
was engaging in risky behavior.
Such a proactive approach is precisely what we propose. We
devise a system that predicts if user behavior may lead to exposure
to malicious content ahead of time (e.g., 30 seconds before exposure).
This, in turn, allows for various kinds of interventions to prevent
compromise (rate limiting, warnings, connection termination, ...),
depending on the service provider’s desired level of aggressiveness.
We focus on mobile users, and leverage a combination of web
observations and surveys from a large mobile service provider
to build our predictive engine. In particular, our system exploits
self-reported data about users’ security behavior, past behavioral
Session 8A: Web 1CCS’18, October 15-19, 2018, Toronto, ON, Canada1487observations, and contextual features about users’ browsing session
to predict if they will be exposed to malicious content.
Contributions. Along the way to designing our system, our paper
offers a number of contributions. First, leveraging three months
worth of data from over 20,600 users of a large mobile provider, we
document the level of exposure of mobile users to malice online (e.g.,
malware), showing that at least 11% of all users get exposed at some
point over our collection interval (Sec. 4). Second, we demonstrate
the limitations of webpage blacklisting—using Google Safe Brows-
ing as a case study, we find that malicious pages are frequently
accessed before being blacklisted: a large number of accesses occur
a few days prior to blacklisting, and we do see much earlier (up
to 87 days prior) accesses as well. Third, our measurements also
demonstrate clear differences in browsing patterns (e.g., length of
browsing sessions) between users that are exposed to malicious
pages and those that are not. Fourth, by surveying these users
through a questionnaire (described in Sec. 3), we build a logistic
regression to estimate to what extent self-reported data can provide
meaningful indicators of risk exposure over time (Sec. 5). Fifth, we
design a long-term predictive classifier that determines the risk of
exposure to malice for a given user over a month’s horizon using fea-
tures based on past behavior (Sec. 6). Sixth, and most importantly,
we combine the knowledge we amass from all these experiments to
design a short-term classifier built from features easily computable
in real-time, that can predict exposure to a malicious page within 30
seconds or so with reasonable accuracy (Sec. 7). Still, as browsing
sessions in which users get exposed to malicious content are rarer
than non-exposed sessions, the prediction apparatus could suffer
from a unacceptably large absolute number of false positives. We
use an additional source of data to show that these “false positives”
frequently appear to actually be true positives, that the blacklists we
used for evaluation only learned about days after user exposure. For
instance, the operating point (56% true positive rate; 3% false posi-
tive rate) is likely to be, after correction, at (93% true positive rate;
1% false positive rate), which is far more practical when looking at
absolute numbers; this result further demonstrates the benefits of
our approach compared to a purely reactive, blacklist-based solu-
tion. We finally discuss limitations and possible interventions that
our system enables in Sec. 8.
2 RELATED WORK
Our research finds itself at the intersection of four different lines of
work: measurement studies to determine to what extent mobile mal-
ware poses an actual threat, systems research that goes beyond sim-
ple blacklisting for protecting end-hosts, work on security-incident
prediction, and research on human factors and their impact on
security.
Prevalence of Mobile Malware. Researchers studied the ecosys-
tem of mobile malware from its early days [27, 93]. For instance,
Zhou and Jiang found that more than 80% of the 1,200 malware sam-
ples they studied were repackaged versions of legitimate software,
and that more than 90% turned their hosts into bots [93].
Estimates of the prevalence of malware infections greatly vary.
One work estimated the prevalence of malware from DNS traffic col-
lected by a large American cellular provider [49], and asserted that
less than nine in a million devices were infected. A different team
collected information about running processes on users’ devices,
and reached drastically different conclusions [82]—they estimated
that about three per thousand devices were infected. Each estimate
has its own limitations: In the former work [49], malware that uses
hardcoded IP addresses may not be detected (as it does not perform
DNS lookups), while, in the latter work [82], the population sample
may be biased. The true fraction of infected devices probably lies
somewhere in the middle.
Protecting Systems and Networks. Numerous alternatives to black-
lists and anti-viruses were proposed to help protect networked sys-
tems (e.g., [32, 33, 40, 56, 57, 62, 63, 67, 82, 83, 91]). For instance, Gu
et al. proposed techniques to detect bots within networks [32, 33].
As another example, Nazca detects drive-by-download attacks by
inspecting the collective traffic produced by devices on the net-
work [40]. These previously proposed alternatives intervene only
at, or shortly after, the time of exposure. Instead, we propose to
predict events that may lead to infection and data compromise
ahead of time.
Predicting Security Incidents. Prior work studied the feasibility
of predicting future computer-security incidents [34, 42, 51, 69, 71,
72, 76]. Soska and Christin showed that, using publicly available
indicators, they could reliably predict whether websites would be
compromised within one year [76]. Hao et al. showed they can fore-
cast malicious domain registrations [34]. Liu et al. demonstrated
that one can predict if an enterprise will suffer future security inci-
dents (e.g., server breach), using externally observed indicators (e.g.,
DNS misconfigurations) [51]. Sabottke et al. focused on predicting
which vulnerabilities will be exploited using information collected
from Twitter feeds [69], while Kang et al. proposed to predict what
percentage of hosts within a country are likely to be infected by a
particular piece of malware [42].
Different efforts borrowed methods from epidemiology to un-
derstand which users and enterprises are at a higher risk of com-
promise [12, 47, 81, 90]. Epidemiological methods do not predict
the specific individuals that will suffer from compromise. Yet, they
help develop an understanding of what factors are correlated with
compromise (e.g., type of operating system [12]).
Researchers have also developed methods to predict if users
will be subject to compromise or whether they will visit malicious
websites [9, 10, 50, 59]. Among those, Canali et al. [10]’s work is
the closest to ours. Using the browsing history of ∼160,000 users
collected over three months, they built a machine-learning model
to predict which users will visit malicious websites with about 87%
accuracy using 74 features (e.g., mean volume of user’s traffic). In
contrast to prior work, while we briefly explore long-term pre-
diction in Sec. 6, our main focus is to predict visits to malicious
websites on short timescales (seconds rather than several days or
months) so that rapid intervention can take place if so desired.
Our work further complements system-level measurements with
self-reported answers to surveys to estimate correlations between
posited and actual user behavior on a large scale. Moreover, our
behavioral data is collected non-intrusively via network monitor-
ing, thus demonstrating the feasibility of predicting exposure even
with limited visibility of user activity.
Human Factors Affecting Security. Human factors in computer
security have been extensively studied (e.g., [14, 28, 45, 52, 58, 64,
Session 8A: Web 1CCS’18, October 15-19, 2018, Toronto, ON, Canada148865, 75]). Christin et al. found that users who run anti-viruses are
more likely to put their devices at risk [14]; our results reproduce
this finding. Some researchers attempted to enhance the ecological
validity of user studies by monitoring users’ behavior via soft-
ware installed on their machines [28, 45]. Surprisingly, they found
that experts do not necessarily behave more securely than non-
experts [28, 45]. Among other findings, certain types of sites (e.g.,
streaming and pornography) present higher risks of infection than
others [45, 61, 87]. Researchers monitoring residential and enter-
prise networks tested which behaviors are correlated with mani-
festations of compromise [52]. They found that visiting blacklisted
websites is highly correlated with such manifestations, thereby
motivating our approach of attempting to predict such visits.
Egelman and Peer developed the Security Behavior Intentions
Scale (SeBIS) as an inexpensive mean to assess users’ security behav-
ior [24]. They found that different sub-scales of SeBIS are strongly
correlated with certain computer security behavior (e.g., users who
score highly on the so-called proactive awareness sub-scale are less
likely to be phished) [11, 21, 22]. Others have questioned whether
scales such as SeBIS are truly predictive of actual behavior in the
field [86]. We explore this question using the proactive awareness
sub-scale of Revised SeBIS (RSeBIS)—a revised version more robust
to language translation [73].
3 DATA COLLECTION
We worked with KDDI, a large Japanese mobile Internet service-
provider to get access to a large corpus of user data. Customers of
this mobile service provider have the opportunity to opt-in to a
certain level of data collection in exchange for rewards. In particu-
lar, users who opt-in consent to the mobile carrier logging HTTP
accesses over the cellular network. In June 2017, we invited a subset
of customers to participate in a research survey, and obtained valid
answers from 20,895 distinct users. We then analyzed the survey
responses and paired them with the HTTP activity logs.
over HTTP [40, 93]. As a result, we believe that the data we col-
lected reflects the nature of the users’ behavior, has high visibility
to malicious traffic, and is ecologically valid. While the democra-
tization of HTTPS using services such as Let’s Encrypt [2] might
increase the popularity of serving malicious content over HTTPS,
our proposed methods can be adapted by using domain information
only, instead of the entire URL. Further, corporate networks can
perform HTTPS collection using “man-in-the-middle” proxies [19].
A potential concern is that users who consented for the collec-
tion of their data may be less privacy aware than others. This is a
common problem when collecting privacy-sensitive data; without
a control set, we cannot estimate how well the results generalize
beyond our users. Nevertheless, prior work hints that attempts at
generalizing may hold promise, as users’ security-behavior inten-
tions are independent of their privacy-behavior intentions [23].
Ethics and IRB. We worked with Carnegie Mellon’s Internal Re-
view Board (IRB) and the KDDI’s legal team to ensure that our usage
of logs was ethical and respectful of users’ privacy. The logs we use