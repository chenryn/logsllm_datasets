Kind
Syntax Error
Range Error
Reference Error
Type Error
URI Error
Custom Error
Total Count
ɚ
18,200
310
78,294
3,196
0
0
100,000
# of Occurrences
ɂ
Ɂ
17,429
285
79,116
3,169
0
1
100,000
17,998
328
78,401
3,273
0
0
100,000
Ƀ
17,135
308
78,935
3,507
0
115
100,000
(a) Classiﬁcation of runtime errors encountered while fuzzing the
four major JS engines with jsfunfuzz for 100,000 iterations. The
four engines are ChakraCore ɚ, V8 ɂ, JavaScriptCore Ɂ, and
SpiderMonkey Ƀ.
(b) The frequency of JS ﬁles (out of 100,000 generated ﬁles) over
the number of valid top-level statement(s).
Fig. 3: Our preliminary study on jsfunfuzz.
We counted how many runtime errors that we can catch
while evaluating 100,000 dynamically generated JS code snip-
pets on each of the engines. Note that jsfunfuzz generates a
stream of a potentially inﬁnite number of JS statements until it
ﬁnds a crash while suppressing any runtime error by wrapping
JS code blocks with try-catch statements as appeared in
the comments in Figure 1. For the purpose of this study, we
ran jsfunfuzz on each JS engine for 20 fuzzing iterations.
This means that we used jsfunfuzz to generate a sequence
of 20 JS code blocks, which have 2.5 statements on average,
wrapped with a try-catch statement, and stored the entire
sequence to a ﬁle. We collected 100,000 of such JS ﬁles for
each engine, and then removed try-catch statements from
the ﬁles, so that we can immediately detect a runtime error
while evaluating them. As a consequence, all the generated JS
ﬁles produced a runtime error when evaluated.
Figure 3a summarizes the result. We found on average
78.7% and 17.7% of the JS ﬁles raised a reference error and
a syntax error, respectively. In theory, grammar-based fuzzers
such as jsfunfuzz should not produce any syntax error unless
they produce some dynamically changing code, e.g., eval.
However, we observed that most of the JS ﬁles were throwing
a syntax error without dynamically modifying code. For ex-
ample, we observed that jsfunfuzz can produce JS statements
with a mismatching bracket. This is because jsfunfuzz has a
manually written grammar, which may contain incorrect or
incomplete production rules. And this result highlights the
difﬁculty of writing grammars for fuzzing, which motivates
one of our design goal: our fuzzer should automatically
generate JS test cases while minimizing runtime errors without
manually written grammar.
3
020406005101520# of Valid Top-Level Statement(s) per Test CaseFrequency (%)We further analyzed the result to check how many valid
top-level statements—we counted a block statement as one
regardless of how many nested statements it has—jsfunfuzz
was able to evaluate for each JS ﬁle until it hits a runtime error.
As we discussed, all the JS ﬁles from jsfunfuzz threw a runtime
error when evaluated, but the ﬁrst few statements in each JS
ﬁle were indeed valid. Figure 3b presents the histogram of the
number of valid top-level statements evaluated for each JS ﬁle
with jsfunfuzz. Notably, more than 75% of the JS ﬁles threw
a runtime error at the very ﬁrst top-level statement, i.e., there
was no semantically valid JS statement. And 99.5% of the JS
ﬁles triggered a runtime error after evaluating three or less JS
top-level statements. That is, only a few top-level statements
produced by jsfunfuzz were valid at runtime, which is indeed
the key observation that motivated our research.
The aforementioned observations point out a primary chal-
lenge in JS engine fuzzing: automatically generating seman-
tically valid JS code snippets during a fuzzing campaign. In
this paper, we address the challenge by introducing a novel
fuzzing technique, called semantics-aware assembly.
IV. OVERVIEW
In this section, we start by introducing semantics-aware
assembly, a novel test case generation algorithm for JS engine
fuzzing. We then outline the overall architecture of CodeAl-
chemist, which implements semantics-aware assembly. Finally,
we describe how CodeAlchemist generates valid JS test cases
by stepping through each step it performs on a running
example.
A. Semantics-aware Assembly
The primary challenge of CodeAlchemist is to generate
test cases, i.e., JS code snippets that are both syntactically
and semantically valid. To address the challenge, we propose
semantics-aware assembly, a novel test case generation al-
gorithm for JS engine fuzzing. The key intuition behind our
approach is to fragmentize JS seeds into a set of combinable
building blocks that we call code bricks. A code brick repre-
sents a valid JS Abstract Syntax Tree (AST). Therefore, a code
brick itself can be evaluated by a JS engine. For example, a JS
statement can become a code brick, and a block of statements
(BlockStatement) can also become a code brick.
Each code brick can be annotated with an assembly con-
straint, which is a set of rules to follow when interconnecting
the code brick with other code bricks. Speciﬁcally, an assem-
bly constraint encodes two conditions: a precondition and a
postcondition. A precondition is a set of variable symbols as
well as their types that are required to be deﬁned to execute
the code brick without a runtime error.
i.e., deﬁned, at
A postcondition describes what kinds of variables are
the end of the code brick after
available,
evaluating it. Given a code brick B, which does not have
(cid:54)= B
any preceding code brick in front, any code brick B(cid:48)
can be a valid candidate that can be placed next to B if the
postcondition of B satisﬁes the precondition of B(cid:48). Starting
from a small code brick, semantics-aware assembly repeatedly
extends it by merging it with additional code bricks. Note, by
deﬁnition, a code brick can always become a valid JS code
snippet.
1
2
var f = function (){ return 42; };
var n = f();
(a) A sample JS seed with two statements. We assume that we create
one code brick for each statement, respectively.
(b) Two code bricks obtained from the seed. The teeth and holes on
each code brick represent the assembly constraints.
Fig. 4: Code bricks with assembly constraints.
Suppose that CodeAlchemist splits the sample seed in
Figure 4a into two initial code bricks that contain only the
ﬁrst and the second statement, respectively. Figure 4b shows
the resulting code bricks. The ﬁrst code brick B1 has no
precondition, but it has a postcondition with a function symbol
s0, which indicates any code brick calling a function can
follow. The second code brick B2 requires a deﬁnition of
a function symbol s0 in its precondition. It also has its
postcondition that deﬁnes two symbols s1 and s2 as a number
and a function, respectively.
We can use B1 at the beginning, but not B2 because of its
assembly constraint: the precondition of B2 requires a function
symbol to be deﬁned, but there is no preceding code brick in
front of it. However, we can append both B1 and B2 to B1, as
the postcondition of B1 can satisfy the precondition of B1 and
B2. When two code bricks merge, unmatched symbols from
the postcondition of the front brick propagate to the resulting
code brick. For example, when we merge two B1 code bricks,
the ﬁnal code brick will have a postcondition with two function
symbols.
There are several design challenges to overcome in order
to make semantics-aware assembly practical. We discuss the
challenges in detail and show how we address them in §V.
First, we need to decide how to break JS code into code
bricks (§V-A). Second, we want to maintain a pool of code
bricks while minimizing its size and preserving its semantics
(§V-B). Third, we should rename symbols in code bricks
when we assemble them so as to avoid potential reference
errors (§V-C). Fourth, we need to ﬁgure out data dependencies
between variables in each code brick in order to compute
assembly constraints (§V-D). Fifth, the precision of assembly
constraints largely depends on the quality of our type analysis.
Thus, we should design an effective way to infer types of
variables (§V-E). Lastly, we need to devise an effective way to
combine code bricks with assembly constraints to build highly-
structured code snippets (§V-F).
4
var f = function(){ return 42; }s0s0: funcB1B1var n = f(); s2s2: funcs1s1: nums0s0: funcB2B21
2
3
4
5
6
7
1
2
3
4
5
6
7
8
var n = 42; // Var1
var arr = new Array(0x100); // Var2
for (let i = 0; i < n; i++) // For3-0, For3-1
{ // Block4
arr[i] = n; // Expr5
arr[n] = i; // Expr6
}
(a) An example JS code snippet used as a seed.
var s0 = new Array(0x100); // Var2
var s1 = 42; // Var1
for (let s2 = 0; s2 < s1; s2++) { // For3-1
for (let s3 = 0; s3 < s2; s3++) { // For3-0
s0[s3] = s2;
s0[s2] = s3;
}
}
(b) A generated code snippet from the seed.
Fig. 6: A running example.
C. Running Example
We now discuss the detailed procedure of CodeAlchemist
step by step. Suppose CodeAlchemist takes in the code snippet
shown in Figure 6a as a seed. At a high level, CodeAlchemist
will repeatedly produce test cases based on the semantic
structure that it learned from the seed. Figure 6b presents one
of such test cases.
First, CodeAlchemist parses the given seed to obtain an
AST. It then breaks the AST into a set of code bricks. In the
current implementation of CodeAlchemist, we fragmentize an
AST in the granularity of JS statements. Figure 6a presents in
the comments what kind of code bricks are generated for each
statement. Speciﬁcally, the seed is broken into seven distinct
code bricks:
two code bricks for the variable declaration
statements (Var1, Var2); a code brick for the whole for-
loop statement and another with an empty body (For3-0,
For3-1); a code brick for the body of the loop itself
(Block4); and two code bricks for the expression statements
(Expr5, Expr6). Note that the body of For3-1 is empty
and it can be used to generate diverse for-loops, whereas
For3-0 represents the whole for-loop statement. For exam-
ple, we can construct nested for-loops with For3-1, but not
with For3-0.
Next, CodeAlchemist normalizes all the identiﬁers in the
code bricks, and deduplicates them to minimize the number
of code bricks to consider when assembling them. We exclude
built-in symbols such as Array from normalization to pre-
serve the semantics of code bricks. In our case, Expr5 and
Expr6 are the same code brick as they appear in the form of
s0[s1] = s2, where s0, s1, and s2 are placeholders for
three distinct variables. Thus, we will have a total of six code
bricks in our pool after this step.
Now that we have obtained a set of unique code bricks,
CodeAlchemist annotates each of them with an assembly
constraint. To compute assembly constraints, we ﬁrst ﬁgure
out which variables are used and deﬁned in each code brick
with a static data-ﬂow analysis. Note that we will not use
normalized symbols in this example to ease the explanation.
Fig. 5: CodeAlchemist Architecture.
B. CodeAlchemist Architecture
it
Figure 5 depicts the architecture of CodeAlchemist. At
a high level,
takes in as input a JS engine under test,
a set of JS seed ﬁles, and a set of user-conﬁgurable pa-
rameters, and it outputs a set of bugs found in the engine.
CodeAlchemist consists of three major components: SEED
PARSER, CONSTRAINT ANALYZER, and ENGINE FUZZER.
The SEED PARSER module breaks given JS seeds into a set of
code bricks. The CONSTRAINT ANALYZER module then infers
assembly constraints for each code brick, and annotates them
with the computed assembly constraints, which ultimately
constitute a code brick pool. Finally, the ENGINE FUZZER
module assembles the code bricks from the pool based on their
assembly constraints to generate test cases and to execute the
generated test cases against the target JS engine.
1) SEED PARSER: This module ﬁrst parses each JS seed
down to an AST based on the ECMAScript language spec-
iﬁcation [9]. The Parse function returns an AST from a
given seed as long as it is syntactically correct. To ﬁlter out
semantically unique code bricks, the Split function breaks
the ASTs into code bricks and normalizes the symbols in
them. All the broken code bricks should represent a valid AST,
although they are not tagged with assembly constraints yet.
2) CONSTRAINT ANALYZER: This module ﬁgures out an
assembly constraint for each of the fragmentized code bricks.
First, the Analyze function recognizes which symbols are
used and deﬁned in each code brick using a classic data-ﬂow
analysis [1]. The Instrument function then traces types of
the variables by dynamically instrumenting code bricks. As a
result, CONSTRAINT ANALYZER returns a set of code bricks,
each of which is tagged with an assembly constraint. We call
such a set as a code brick pool, which is later used to generate
test cases, i.e., JS code snippets, for fuzzing.
3) ENGINE FUZZER: Now that we have code bricks to play
with, the ENGINE FUZZER module uses them to fuzz the target
JS engine. Speciﬁcally, the Generate function iteratively
assembles code bricks based on their assembly constraints
in order to generate test cases. It also takes a set of user-
conﬁgurable parameters which adjusts the way of combining
the code bricks (see §V-F). Finally, the Execute function
executes the target JS engine with the generated test cases. If
the engine crashes, it stores the corresponding test case (a JS
ﬁle) on a ﬁle system.
5
As an example, let us consider Var1, which does not have
any used variable, but has one deﬁned variable n. If we denote
the use-def variables by U → Code Brick → D, where U
is a set of used variables and D is a set of deﬁned variables,
then we can obtain the use-def variables for each code brick
as follows.
1)
2)
3)