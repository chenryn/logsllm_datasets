title:On Limitations of Designing Leakage-Resilient Password Systems: Attacks,
Principals and Usability
author:Qiang Yan and
Jin Han and
Yingjiu Li and
Robert H. Deng
On Limitations of Designing Leakage-Resilient Password Systems:
Attacks, Principles and Usability
Qiang Yan, Jin Han, Yingjiu Li, Robert H. Deng
School of Information Systems, Singapore Management University
{qiang.yan.2008, jin.han.2007, yjli, robertdeng}@smu.edu.sg
Abstract
The design of
leakage-resilient password systems
(LRPSes) in the absence of trusted devices remains a chal-
lenging problem today despite two decades of intensive re-
search in the security community. In this paper, we inves-
tigate the inherent tradeoff between security and usability
in designing LRPS. First, we demonstrate that most of the
existing LRPS systems are subject to two types of generic
attacks - brute force and statistical attacks, whose power
has been underestimated in the literature. Second, in or-
der to defend against these two generic attacks, we intro-
duce ﬁve design principles that are necessary to achieve
leakage resilience in the absence of trusted devices. We
also show that these attacks cannot be effectively mitigated
without signiﬁcantly sacriﬁcing the usability of LRPS sys-
tems. Third, to better understand the tradeoff between se-
curity and usability of LRPS, we propose for the ﬁrst time a
quantitative analysis framework on usability costs of pass-
word systems. By decomposing the authentication process
of existing LRPS systems into atomic cognitive operations
in psychology, we show that a secure LRPS in practical set-
tings always imposes a considerable amount of cognitive
workload on its users, which indicates the inherent limita-
tions of such systems and in turn implies that an LRPS has
to incorporate certain trusted devices in order to be both
secure and usable.
1 Introduction
Password has been the most pervasive means for user
authentication since the advent of computers. Compared to
its alternatives, such as biometrics and smartcard which are
cumbersome to use and require the existence of an underly-
ing infrastructure, password is much easier and cheaper to
create, update, and revoke. However, the use of password
has intrinsic problems. Among them, secret leakage is one
of the most common security threats [21], in which an ad-
versary steals the password by capturing (e.g. by shoulder-
surﬁng or key logging) and analyzing a user’s inputs during
an authentication session. Traditional password systems ask
a user to directly input his entire plaintext password recalled
from the user’s memory so that an observation of a single
authentication session is sufﬁcient to capture the password.
In order to prevent secret leakage during password entry, a
user needs to input the password indirectly, which imposes
an extra burden on the user. How to design a password sys-
tem that minimizes secret leakage and is still easy to use is
the fundamental problem in the design of leakage resilient
password systems (LRPSes).
An ideal LRPS allows a user to generate a one-time pass-
word (OTP) for each authentication session based on an
easy-to-remember secret. This can be easily achieved when
a secure channel is available between user and authentica-
tion service. The secure channel blinds the adversary by de-
coupling a user input from the underlying secret, when the
message delivered over the secure channel is not revealed to
the adversary. However, the prerequisite of a secure chan-
nel may be infeasible or introduces other vulnerabilities in
practical settings. For example, when the secure channel is
formed by a trusted device such as secure token or mobile
phone, that device is subject to theft or loss. This moti-
vates the existing research on usable and secure LRPS sys-
tems with only the support of human cognitive capabilities
[22, 15, 26, 20, 31, 32, 35, 4, 27, 2]. A few representa-
tive systems include Convex Hull Click (CHC) [32], Cog-
nitive Authentication Scheme (CAS) [31], and Predicate-
based Authentication Service (PAS) [4].
The difﬁculty in designing an LRPS system stems from
the capability asymmetry between user and strong adver-
sary. A strong adversary may use a hidden camera or mali-
cious software to record complete interactions between user
and his computer and then analyze the data with powerful
machines. Many LRPS systems [15, 20, 31, 32, 35, 4, 27, 2]
have been proposed to defend against this type of secret-
leakage attacks. However, as we will demonstrate later in
the paper, all the existing proposals with acceptable usabil-
ity are vulnerable to either or both types of generic attacks:
brute force attack and statistical attack.
Brute force attack is a pruning process for the entire can-
didate password set, whose strength has often being un-
derestimated in prior research. Our experiments show that
brute force attack is able to recover the secrets of certain
existing LRPS systems from a small number of observa-
tions of authentication sessions. Statistical attack, on the
other hand, represents a learning process to extract a user’s
secret due to statistical signiﬁcance of the secret. We in-
troduce two types of statistical attack, probabilistic decision
tree and multi-dimensional counting. Rigorous experiments
are conducted to show the effectiveness of these two attacks
in breaking existing schemes.
We note that these two generic attacks are different from
other speciﬁc attacks that have been systematically studied
in the literature, including SAT [13] and Gaussian elimina-
tion [19]. SAT attacks can be efﬁciently prevented by asking
a user to select only one of the correct responses while mul-
tiple correct responses can be derived from each challenge,
since this would increase the size of the SAT expression ex-
ponentially with the number of observations. On the other
hand, Gaussian elimination-based algebraic attacks can be
efﬁciently prevented by using a non-linear response func-
tion [20] or introducing noises from user’s intentional mis-
takes [15]. Unlike these speciﬁc attacks, brute force and
statistical attacks cannot be easily defended without signif-
icantly sacriﬁcing the system’s usability, which implies in-
herent limitations of LRPS without using trusted devices. In
order to defend against these attacks, we introduced ﬁve de-
sign principles which should be followed to achieve leakage
resilience. Using counterexamples, we show that an LRPS
system can be easily broken when these principles are vio-
lated.
To further understand the tradeoff between security and
usability in the design of LRPS systems, we propose for
the ﬁrst time a quantitative analysis framework on usabil-
ity costs of LRPS systems. This framework decomposes
the process of human-computer authentication into atomic
cognitive operations. Performance data of average human-
beings reported in psychology literatures [28, 12, 9, 30, 10,
23, 25, 7, 33, 34, 16, 6, 14] are used to estimate usability
costs of existing LRPS systems [15, 20, 31, 32, 35, 4, 27, 2].
Our analysis results are consistent with the experimental re-
sults reported in the original literatures, while the hidden
costs previously not addressed are identiﬁed. Our results
show that a secure LRPS in practical settings [15, 2] al-
ways leads to a considerable amount of cognitive workload,
which explains why some of the existing LRPS systems re-
quire extremely long authentication time and have high au-
thentication error rate. This limitation has not been, and will
not be easily solved in the design of LRPS in the absence of
trusted device.
In a nutshell, the contributions of this paper are three-
fold:
• We analyze and demonstrate the effectiveness of two
types of generic attacks, brute force and statistical at-
tacks, against LRPS systems. We propose two statis-
tical attack techniques, probabilistic decision tree and
multi-dimensional counting, and show their effective-
ness against existing schemes.
• We introduce ﬁve principles that are necessary to mit-
igate brute force and statistical attacks. We use typical
existing LRPS proposals as counterexamples to show
that an adversary can easily obtain user secrets in the
schemes violating our principles.
• We establish the ﬁrst quantitative analysis framework
on usability costs of the existing LRPS systems. This
framework utilizes the performance models of atomic
cognitive operations in authentication to estimate us-
ability costs. Our analysis result shows that there is
a strong tradeoff between security and usability in the
existing LRPS systems. It implies that an unaided hu-
man may not be competent enough to effectively use
a secure LRPS system in practical settings; in other
words, it is inevitable to incorporate certain trusted de-
vice in LRPS design.
2 Deﬁnitions and Threat Model
In this section, we introduce related notions and our
threat model. We focus on the fundamental problem of
designing LRPSes for unaided humans, i.e. when a se-
cure channel or trusted device is unavailable. We exclude
LRPSes using secure channel or trusted device in our dis-
cussion unless explicitly mentioned.
2.1 Leakage(cid:173)Resilient Password System
An LRPS is essentially a challenge-response protocol
between human and computer. We refer to human as user,
and computer as server. During registration, a user and
a server agree on a root secret, usually referred to as a
password. The user later uses the root secret to generate
responses to challenges issued by the server to prove his
identity. Unlike traditional password systems, a response in
LRPS is an obfuscated message derived from the root se-
cret, rather than the plaintext of the root secret itself. Con-
sidering the limited cognitive capabilities of unaided hu-
mans, a usable obfuscation function F is usually a many-
to-one mapping from a large candidate set to a small an-
swer set. The small size of the answer set increases the
success rate of guessing attack where an adversary attempts
to pass the authentication by randomly picking an answer
from the answer set. For this reason, an authentication
session of LRPS often requires executing multiple rounds
of the challenge-response procedure in order to reach an
expected authentication strength D (speciﬁcally, the resis-
−6 for 6-digit
tance against random guessing, e.g. D = 10
PIN), where each round is referred to as an authentication
round. We use d to denote the average success rate of guess-
ing attack per authentication round. Given d and D, the
minimum number m of authentication rounds for an authen-
tication session is ⌈logd D⌉.
To imbue the server with a high ﬂexibility in challenge
generation, the k-out-of-n paradigm [15] has been adopted
for secret agreement in most existing LRPS systems [15, 20,
31, 32, 35, 27, 2]. In this paradigm, the root secret consists
of k independent elements randomly drawn from a pool of
n elements. An element can be an image, a text character,
or any symbol in a notational scheme. The set of k secret
elements is called the secret set (and forms the root secret of
the user), and the complementary set is called the decoy set.
The server knows the secret set chosen by the user, and uses
a subset or all of these k elements to generate the challenge
in each round. We refer to the chosen portion of the root
secret for an authentication round as a round secret.
Based on the above notions, the common system param-
eters of the most existing LRPS systems [15, 20, 31, 32,
35, 4, 27, 2] can be described by a tuple (D, k, n, d, w, s),
where D is the expected authentication strength of an au-
thentication session, k is the number of secret elements
drawn from an alphabet of n candidate elements, d is the
average success rate of guessing attack in a single round, w
is the average window size which is the number of elements
appearing on the screen for an authentication round, and s is
the average length of user’s decision path which is the num-
ber of decisions that a user has to make before producing
the correct response for an authentication round. The total
round number m can be derived from D and d. The pa-
rameters m, w, and s are required for usability evaluation.
More details will be given in Sections 5 and 6.
2.2 Threat Model and Experimental Setting
There are two types of passive adversary models for se-
cret leakage attacks used in prior research. The weaker pas-
sive adversary model (e.g. cognitive shoulder-surﬁng [26])
assumes that the adversary is not able to capture the com-
plete interaction between a user and the server [26]. Such
an assumption actually forms a secure channel between user
and server, which transforms the secret leakage problem to
the protection of the secure channel. However, this assump-
tion may not hold for a prepared adversary who deploys a
hidden camera, key logger, or phishing web site to capture
the whole password entry process. To address such realis-
tic concerns, recent efforts [20, 31, 32, 35, 4, 27, 2] have
focused on the strong passive adversary model, where the
adversary is allowed to record the complete interaction be-
tween the user and the server.
In the strong passive adversary model, secret leakage
during human-computer authentication is unavoidable. The
user’s response is based on his knowledge of the secret,
which distinguishes it from a random choice as required for
the authentication purpose. This difference leaks informa-
tion about the secret. After recording a sufﬁcient number of
authentication rounds, the adversary may use any reason-
able computation resources to analyze and recover the un-
derlying secret. The research problem under such a threat
model is to lower the secret leakage rate while maintaining
acceptable usability for unaided humans.
In this paper, we consider both brute force attack and
statistical attack under this strong passive adversary model.
The security strength of an LRPS is deﬁned as the resis-
tance against these two generic attacks given the same suc-
cess rate of random guessing (i.e.
the same authentica-
tion strength for a legitimate user). We will use simula-
tion experiments to evaluate the security strength of exist-
ing schemes, whose process is summarized as follow: 1)
Generate a random password as the root secret; 2) Gener-
ate a challenge for an authentication round; 3) Generate a
response based on the password and the underlying system
design; 4) Analyze the collected challenge-response pairs
after each authentication round assuming that the adversary
has full knowledge of the system design except the pass-
word; 5) Repeat steps 2, 3, and 4 until the exact password
is recovered. The ﬁnal ﬁndings shown in the following sec-
tions are the average results of 20 runs for each system.
3 Brute Force Attack and Its Defense Princi-
ples
3.1 Attack Strategy
Brute force attack is a general pruning-based learning
process, where the adversary keeps removing irrelevant
candidates when more and more cues are available.
Its
procedure can be described as follows: 1) List all possi-
ble candidates for the password in the target system; 2)
For each independent observation of a challenge-response
round, check the validity of each candidate in the current
candidate set by running the veriﬁcation algorithm used by
the server, and remove invalid candidates from the candi-
date set; 3) Repeat the above step until the size of candidate
set reaches a small threshold.
The above procedure shows that the efﬁciency of brute
force attack in the leakage resilience setting is design-
independent, and is only limited by the size of the candi-
date set. We introduce two statements to further describe
the power of brute force attack. These statements apply not
only to root secret, but also to round secrets when the adver-
sary is able to reliably group the observations for individual
round secret.
Statement 1: The veriﬁcation algorithm used in brute force
attack for candidate veriﬁcation is at least as efﬁcient as the
veriﬁcation algorithm used by server for response veriﬁca-
tion.
The proof is trivial as the veriﬁcation process for candi-
date pruning is essentially the same as the veriﬁcation pro-
cess for the server to check correct response. It is also pos-
sible for the adversary to design a more efﬁcient algorithm
if there are correlations between candidates.
Statement 2: The average shrinking rate for the size of
valid candidate set is the same as one minus the average
success rate of guessing attack.
The average success rate of guessing attack is deﬁned
as the probability of generating correct response by ran-
domly picking a candidate from the candidate set. This
is an equivalent deﬁnition of average shrinking rate of the
valid candidate set. Given X as the size of the candidate
set, and d as the average success rate of guessing attack,
the average number of rounds to recover the exact secret is
m = ⌈log1/d X⌉, assuming that each candidate is indepen-
dent of each other. If each candidate is not independent, the
average number of rounds to recover the exact secret will
be smaller than m. This statement can be used to estimate
− 1
the average success rate of guessing attack, d = X
m ,
when the precise analysis is difﬁcult to perform (see later