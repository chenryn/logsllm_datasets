to compute the advantage of the more sophisticated attacker
against this protocol.
ACKNOWLEDGMENTS
We thank the reviewers for their valuable comments. This
work has been partially supported by the Zurich Information
Security Center (ZISC), the European Commission through
H2020-DS-2014-653497 PANORAMIX,
the EPSRC Grant
EP/M013-286/1, and the National Science Foundation (NSF)
under grant CNS-1719196.
120
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:37:11 UTC from IEEE Xplore.  Restrictions apply. 
REFERENCES
[1] “The Tor Project,” https://www.torproject.org/, accessed in Nov 2017.
[2] A. Johnson, C. Wacek, R. Jansen, M. Sherr, and P. Syverson, “Users get
routed: Trafﬁc correlation on tor by realistic adversaries,” in Proc. ACM
SIGSAC conference on Computer & communications security 2013,
2013, pp. 337–348.
[3] L. Øverlier and P. F. Syverson, “Locating Hidden Servers,” in Proc. 27th
IEEE Symposium on Security and Privacy, 2006, pp. 100–114.
[4] S. J. Murdoch and G. Danezis, “Low-cost trafﬁc analysis of Tor,” in
Proc. IEEE Symposium on Security and Privacy 2005, 2005.
[5] K. S. Bauer, D. McCoy, D. Grunwald, T. Kohno, and D. C. Sicker,
“Low-resource routing attacks against tor,” in Proc. 6th ACM Workshop
on Privacy in the Electronic Society (WPES), 2007, pp. 11–20.
[6] Y. Sun, A. Edmundson, L. Vanbever, O. Li, J. Rexford, M. Chiang, and
P. Mittal, “RAPTOR: Routing attacks on privacy in Tor,” in Proc. 24th
USENIX Security Symposium, 2015.
[7] R. Jansen, F. Tschorsch, A. Johnson, and B. Scheuermann, “The sniper
attack: Anonymously deanonymizing and disabling the Tor network,” in
Proc. Network and Distributed Security Symposium - NDSS ’14, 2014.
[8] Y. Gilad and A. Herzberg, “Spying in the Dark: TCP and Tor Trafﬁc
Analysis,” in Proc. 12th Privacy Enhancing Technologies Symposium
(PETS 2012), 2012.
[9] The Tor Blog, “One cell
is enough to break Tor’s anonymity,”
https://blog.torproject.org/blog/one-cell-enough, accessed Nov 2017.
[10] R. Dingledine, N. Mathewson, and P. Syverson, “Tor: The Second-
Generation Onion Router,” in Proc. 13th USENIX Security Symposium
(USENIX), 2004, pp. 303–320.
[11] S. Chakravarty, M. V. Barbera, G. Portokalidis, M. Polychronakis,
and A. D. Keromytis, “On the effectiveness of trafﬁc analysis against
anonymity networks using ﬂow records,” in Proc. 15th International
Conference on Passive and Active Measurement, 2014, pp. 247–257.
[12] N. Gelernter and A. Herzberg, “On the limits of provable anonymity,”
in Proc. Workshop on Privacy in the Electronic Society (WPES 2013),
2013, pp. 225–236.
[13] A. Hevia and D. Micciancio, “An indistinguishability-based characteriza-
tion of anonymous channels,” in Proc. Eighth International Symposium
on Privacy Enhancing Technologies (PETS 2008), N. Borisov and
I. Goldberg, Eds., 2008, pp. 24–43.
[14] A. Serjantov, R. Dingledine, and P. Syverson, “From a trickle to a
ﬂood: Active attacks on several mix types,” in 5th Information Hiding
Workshop (IH 2002), 2003, pp. 36–52.
[15] D. Chaum, “The dining cryptographers problem: Unconditional sender
and recipient untraceability,” Journal of Cryptology, vol. 1, no. 1, pp.
65–75, 1988.
[16] T. Rufﬁng, P. Moreno-Sanchez, and A. Kate, “P2P Mixing and Unlink-
able Bitcoin Transactions,” in Proc. 25th Annual Network & Distributed
System Security Symposium (NDSS), 2017.
[17] H. Corrigan-Gibbs and B. Ford, “Dissent: Accountable Anonymous
Group Messaging,” in Proc. 17th ACM Conference on Computer and
Communication Security (CCS), 2010, pp. 340–350.
[18] P. Golle and A. Juels, “Dining cryptographers revisited,” in Proc. of
Eurocrypt 2004, 2004.
[19] H. Corrigan-Gibbs, D. I. Wolinsky, and B. Ford, “Proactively Account-
able Anonymous Messaging in Verdict,” in Proc. 22nd USENIX Security
Symposium, 2013, pp. 147–162.
[20] J. van den Hooff, D. Lazar, M. Zaharia, and N. Zeldovich, “Vuvuzela:
Scalable private messaging resistant to trafﬁc analysis,” in Proc. 25th
ACM Symposium on Operating Systems Principles (SOSP 2015), 2015.
[21] A. Kwon, D. Lazar, S. Devadas, and B. Ford, “Rifﬂe: An Efﬁcient
Communication System With Strong Anonymity,” in Proc. Privacy
Enhancing Technologies Symposium (PETS 2016), 2016, pp. 115–134.
[22] D. I. Wolinsky, H. Corrigan-Gibbs, B. Ford, and A. Johnson, “Dissent
in Numbers: Making Strong Anonymity Scale,” in 10th USENIX Sym-
posium on Operating Systems Design and Implementation (OSDI 12),
2012, pp. 179–182.
[23] S. Le Blond, D. Choffnes, W. Zhou, P. Druschel, H. Ballani, and
P. Francis, “Towards Efﬁcient Trafﬁc-analysis Resistant Anonymity
Networks,” in Proc. ACM SIGCOMM 2013, 2013, pp. 303–314.
[24] A. Piotrowska, J. Hayes, T. Elahi, S. Meiser, and G. Danezis, “The
loopix anonymity system,” in Proc. 26th USENIX Security Symposium,
2017.
[25] S. Le Blond, D. Choffnes, W. Caldwell, P. Druschel, and N. Merritt,
“Herd: A Scalable, Trafﬁc Analysis Resistant Anonymity Network for
VoIP Systems,” in Proc. ACM Conference on Special Interest Group on
Data Communication (SIGCOMM 2015), 2015, pp. 639–652.
[26] M. Backes, A. Kate, P. Manoharan, S. Meiser, and E. Mohammadi,
“AnoA: A Framework For Analyzing Anonymous Communication Pro-
tocols,” in Proc. 26th IEEE Computer Security Foundations Symposium
(CSF 2013), 2013, pp. 163–178.
[27] M. Backes, A. Kate, P. Manoharan, S. Meiser, and E. Mohammadi,
“AnoA: A Framework For Analyzing Anonymous Communication Pro-
tocols,” Journal of Privacy and Conﬁdentiality (JPC), vol. 7(2), no. 5,
2016.
[28] K. Jensen, Colored Petri Nets. Basic Concepts, Analysis Methods and
Practical Use., 1997, vol. 3.
[29] W. Reisig, Primer in Petri Net Design, 1st ed., 1992.
[30] L. M. Kristensen, S. Christensen, and K. Jensen, “The practitioners
guide to coloured petri nets,” International Journal on Software Tools
for Technology Transfer (STTT), vol. 2, no. 2, pp. 98–132, 1998.
[31] T. K. Srikanth and S. Toueg, “Simulating authenticated broadcasts to
derive simple fault-tolerant algorithms,” Distributed Computing, vol. 2,
no. 2, pp. 80–94, 1987.
[32] R. Gennaro, M. O. Rabin, and T. Rabin, “Simpliﬁed VSS and fact-track
multiparty computations with applications to threshold cryptography,”
in Proc. ACM PODC, 1998, pp. 101–111.
[33] D. Das, S. Meiser, E. Mohammadi,
“Anony-
mity trilemma: Strong anonymity,
low latency—
choose two,” Cryptology ePrint Archive, Report 2017/954, 2017,
https://eprint.iacr.org/2017/954.
low bandwidth,
and A. Kate,
[34] J. Feigenbaum, A. Johnson, and P. Syverson, “A probabilistic analysis
of onion routing in a black-box model,” in Proc. Workshop on Privacy
in the Electronic Society (WPES 2007), 2007.
[35] D. Wikstr¨om, “A Universally Composable Mix-Net,” in Proc. 1st Theory
of Cryptography Conference (TCC), 2004, pp. 317–335.
[36] J. Camenisch and A. Lysyanskaya, “A formal
treatment of onion
routing,” in Proc. CRYPTO 2005, 2005, pp. 169–187.
[37] N. Kiyavash, A. Houmansadr, and N. Borisov, “Multi-ﬂow Attacks
Against Network Flow Watermarking Schemes,” in Proc. 17th USENIX
Security Symposium, 2008.
[38] S. Oya, C. Troncoso, and F. P´erez-Gonz´alez, “Do dummies pay off?
limits of dummy trafﬁc protection in anonymous communications,” in
Proc. 14th Privacy Enhancing Technologies Symposium (PETS 2014),
2014.
[39] G. Danezis, “Statistical disclosure attacks: Trafﬁc conﬁrmation in open
environments,” in Proc. Security and Privacy in the Age of Uncertainty,
(SEC2003), 2003, pp. 421–426.
[40] G. Danezis and A. Serjantov, “Statistical disclosure or intersection at-
tacks on anonymity systems,” in Proc. 6th Information Hiding Workshop
(IH 2004), 2004.
[41] M. J. Freedman, K. Nissim, and B. Pinkas, “Efﬁcient private matching
and set intersection,” in Proc. EUROCRYPT 2004, 2004.
[42] F. P´erez-Gonz´alez and C. Troncoso, “Understanding statistical disclo-
sure: A least squares approach,” in Proc. 12th Privacy Enhancing
Technologies Symposium (PETS 2012), 2012, pp. 38–57.
[43] M. Backes, P. Manoharan, and E. Mohammadi, “TUC: Time-
sensitive and Modular Analysis of Anonymous Communication,”
IACR ePrint Archive Report 2013/664, 2013, http://www.infsec.cs.uni-
saarland.de/ mohammadi/paper/tuc.pdf.
[44] R. Dingledine, N. Mathewson, and P. Syverson, “Tor: The second-
generation onion router,” in Proc. 13th USENIX Security Symposium,
2004.
[45] D. Dolev, R. Reischuk, and H. R. Strong, “Early stopping in byzantine
agreement,” J. ACM, vol. 37, no. 4, pp. 720–741, 1990.
[46] D. Kesdogan, J. Egner, and R. B¨uschkes, “Stop-and-go MIXes: Provid-
ing probabilistic anonymity in an open system,” in Proc. Information
Hiding Workshop (IH 1998), 1998.
[47] G. Danezis, C. Diaz, C. Troncoso, and B. Laurie, “Drac: An architecture
for anonymous low-volume communications,” in Proc. 10th Privacy
Enhancing Technologies Symposium (PETS 2010), 2010.
[48] P. Mittal, M. Wright, and N. Borisov, “Pisces: Anonymous communi-
cation using social networks,” in Proc. 20th Network and Distributed
System Security Symposium (NDSS 2013), 2013.
[49] C. Chen, D. E. Asoni, D. Barrera, G. Danezis, and A. Perrig, “HOR-
NET: High-speed onion routing at the network layer,” in Proc. ACM
121
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:37:11 UTC from IEEE Xplore.  Restrictions apply. 
Conference on Computer and Communications Security (CCS), 2015,
pp. 1441–1454.
[50] H. Corrigan-Gibbs, D. Boneh, and D. Mazi`eres, “Riposte: An anony-
mous messaging system handling millions of users,” in Proc. 36th IEEE
Symposium on Security and Privacy (S&P 2015), 2015, pp. 321–338.
[51] Anonymity Trilemma Project Webpage, “Anonymity trilemma: Strong
low latency overhead—choose
anonymity,
two,” https://freedom.cs.purdue.edu/projects/anonymity/trilemma/.
low bandwidth overhead,
TABLE I
Latency vs. bandwidth vs. strong anonymity of AC protocols, with the
number of protocol-nodes K, number of clients N, and message-threshold
T , expected latency (cid:2)(cid:3) per node, dummy-message rate β.
Protocol
Tor [10]
Hornet [49]
Herd [25]
Riposte [50]
Vuvuzula [20]
Rifﬂe [21]
Threshold mix [14]
Loopix [24]
DC-Net [15], [18]
Dissent-AT [22]
DiceMix [16]
∗ if T in o(poly(η))
Latency
θ(1)
θ(1)
θ(1)
θ(N )
θ(K)
θ(K)
√
θ(T K)
K(cid:2)(cid:3)
θ(
θ(1)
θ(1)
θ(1)
)
Bandwidth
θ(1/N)
θ(1/N)
θ(N/N)
θ(N/N)
θ(N/N)
θ(N/N)
θ(1/N)
θ(β)
θ(N/N)
θ(N/N)
θ(N/N)
Strong Anonymity
impossible
impossible
possible
possible
possible
possible
impossible∗
possible
possible
possible
possible
APPENDIX A
PROTOCOL MODEL REVISITED
A. Validity of the Protocol Model (Contd.)
Lemma 2. Let Π be a protocol ∈ M with K parties with
parameters β and (cid:4). Then: 1) Messages are delivered within
(cid:4) steps. 2) The protocol adds (for the unsynchronised case on
average) a maximum of β noise messages per user per round.
3) Whenever a party in S ∪ P sends a message to another
party in P ∪ R, the adversary learns that and in which round
this happens. 4) For every message that leaves the network
(received by R), the adversary additionally learns whether
the message is the target message. 5) For every compromised
party, the adversary learns the mapping between the input
messages and the output messages.
Proof. Let Π be a protocol ∈ M with K parties with param-
eters β and (cid:4). Part (2) of the Lemma holds, since we restrict
the user distributions accordingly and since the none of the
transitions in the petri-net can create more tokens within the
network than it consumes from its input place.
We show the part (1) of the lemma via structural induction
over ﬁred transitions of the petri net. We additionally add to
the induction invariant that all tokens that are not in S have a
timestamp for their next transition of ts = 1 and a remaining
time of tr > 0 and there are at least tr rounds left in which
the token can be delivered.
Induction base: The protocol is initialized and no transi-
tions have happened. Thus, no messages have been sent so far,
i.e., there is no message that has not been delivered within (cid:4)
steps. The only transition that can ﬁre is TS and for (cid:4) > 0,
the message introduced into the network in this way does not
need to be delivered already (0  0 and ts = 1. Otherwise, the transition
is TPi for some i and consumes a token from Pi accordingly.
By the induction invariant, the token has tr > 0. If this token
has tr−1 = 0, the transition delivers the token to R. Otherwise,
t decreases tr by one (thus fulﬁlling the condition that there
are at least tr rounds left in which the token can be delivered)
and sets ts = 1. Since every token in any place Pi needs to be
consumed in every round, the protocol delivers every message
in at most (cid:4) steps.
Other parts of the lemma: By deﬁnition of our petri net,
whenever a transition ﬁres, an element (t, r) is placed into
Tokens, containing the public ﬁelds of t, such as t.prev and
t.next, as well as the current round number r, which fulﬁlls
part (3). Moreover, whenever the transition places the token
in R, the adversary can additionally see the ﬁeld t.msg and no
transition can change the ﬁeld msg, which allows the adversary
to effectively tag and recognize the challenge message and thus
fulﬁlls part (4). Finally, if any party Pi is compromised, Pi
does not modify the unique (and otherwise freshly sampled)
ﬁeld t.IDt, which allows the adversary to map incoming and
outgoing messages.
Since the transitions discussed here are the only way for
messages to be sent to a recipient, the model correctly enforces
the conditions from the lemma.
B. Expressing Protocols in the petri net model
Modeling DC net. Here we show how to model an actual
DC net type protocol using our petri net model M as deﬁned
in Section IV. Speciﬁcally we pick up the short DC net
protocol proposed by Golle and Juels [18], and present MDC
which models the aforementioned protocol.
We model a DC net protocol with N participants, where
S = P, |S| = |P| = N. We denote the parties with P1, . . . , PN .
The protocol can be denoted by ΠDC ={paramgen, keydist,
post, verify, extract}7 - as described below.
• paramgen: In protDC, paramgen is executed by a trusted
entity and the output
is published. Since we are mainly
interested in the anonymity game, we consider that paramgen
step is executed by our honest challenger and happens outside
the protocol run, and the output is globally known (to all the
transitions TPi).
• keydist: using the output of paramgen, this step yields for
each party Pi a private key xi and a corresponding public key
yi. In protDC, the above key generation part is done by a
trusted entity, and hence we consider that it is done by our
honest challenger and for each party Pi
the public-private
keypair xi, yi is already known to the corresponding transition