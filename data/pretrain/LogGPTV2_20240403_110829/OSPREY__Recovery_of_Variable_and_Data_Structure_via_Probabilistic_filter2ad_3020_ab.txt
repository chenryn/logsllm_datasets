(a) Source code of huft_build.
(b) Assembly of huft_build.
(c) Memory layout of huft_build’s variables.
Fig. 1: Motivation example.
the corresponding assemble code, and Figure 1c shows part of
the memory layout of the variables. In the source code, lines 1-
4 deﬁne a structure elem_t consisting of two ﬁelds x and y;
inside the function, line 9 declares p as a pointer to elem_t,
and v as a stack-inlined elem_t; the conditional at line 10
has two branches, with the true branch setting p to the address
of v and the false branch allocating a piece of heap memory
to p (line 13), and storing v to the allocated space (line 14);
and ﬁnally, line 16 outputs p->x and p->y.
After compilation, global variables are denoted by constant
addresses and local variables are translated to offsets on stack
frames. For example, the deﬁnitions of v.x and v.y at line
9 are translated to memory writes to stack offsets rsp+0x8
and rsp+0x10 (instructions [01]-[02] in Figure 1b, re-
spectively. The assignment to p at line 11 is translated to a
write to offset rsp+0x0 at instruction [5] in Figure 1b.
This is due to the stack memory layout shown on the left of
Figure 1c. Observe that from the assembly code the types of
these stack offsets are unknown. It is also unclear rsp+0x8
and rsp+0x10 belong to a data structure while rsp denotes
an 8-byte scalar variable. It is almost impossible to know that
the heap variable stored in register rax at instruction [09]
is of the same type as the data structure denoted by rsp+0x8
and rsp+0x10. This example only represents some simple
situations. In practice, there are much more difﬁcult challenges
such as nesting structures, array of structures, and arrays inside
structures. In the following, we discuss how the-state-of-the-
art techniques and our technique perform on this example.
Note that the ideal recovery result is to identify p as a pointer
to elem_t while v is an instance of the same structure on
stack, as shown in the “ground truth” column in Figure 2.
IDA [7] is one of the most widely-used commercial decompi-
lation toolkits. It has the functionality of recovering variables
and their types. Its recovery algorithm, which is called semi-
naive algorithm in [16], is based on a local (intra-procedural)
static analysis. It
identiﬁes absolute addresses, rsp-based
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:33:02 UTC from IEEE Xplore.  Restrictions apply. 
line 09line 14line 11line 13pv.xv.yp->xp->yData-flow hintPoint-to hintStack of huft_buildHeaprsp+0x00+0x08+0x10line 1601. typedefstruct{02.   longx;03.   longy;04. } elem_t;05. intmain() {06.  if(!rand(1000)) huft_build(…);07. }08. voidhuft_build(…) {09.   elem_t*p, v = {.x=0, .y=1}; 10.   if (…)11.     p = &v;12.   else {13.     p = malloc(sizeof(elem_t));14.     *p = v;15.   }16.   output(p->x, p->y);17. }:[01] mov[rsp+0x8], 0[02] mov[rsp+0x10], 1[03] ... [04] lea rbx, [rsp+0x8][05] mov[rsp], rbx[06] ...[07] movrdi, 0x10[08] call malloc[09] mov[rsp], rax[10] movdqaxmm0, [rsp+0x8][11] movups[rax], xmm0[12] ...[13] movrcx, [rsp][14] movrdi, [rcx][15] movrsi, [rcx+0x8] [14] [15] [15] [14] [10] 132[11]Unified access Point hint3line 09line 14line 11line 13pv.xv.yp->xp->yData-flow hintPoint-to hintStack of huft_buildHeaprsp+0x00+0x08+0x10line 1601. typedefstruct{02.   longx;03.   longy;04. } elem_t;05. intmain() {06.  if(!rand(1000)) huft_build(…);07. }08. voidhuft_build(…) {09.   elem_t*p, v = {.x=0, .y=1}; 10.   if (…)11.     p = &v;12.   else {13.     p = malloc(sizeof(elem_t));14.     *p = v;15.   }16.   output(p->x, p->y);17. }:[01] mov[rsp+0x8], 0[02] mov[rsp+0x10], 1[03] ... [04] lea rbx, [rsp+0x8][05] mov[rsp], rbx[06] ...[07] movrdi, 0x10[08] call malloc[09] mov[rsp], rax[10] movdqaxmm0, [rsp+0x8][11] movups[rax], xmm0[12] ...[13] movrcx, [rsp][14] movrdi, [rcx][15] movrsi, [rcx+0x8] [14] [15] [15] [14] [10] 132[11]Unified access Point hint3pv.xv.yp->xp->yData-flow hintPoint-to hintStack of huft_buildHeaprsp+0x00+0x08+0x10[14] [15] [15] [14] [10] 132[11]Unified access Point hint3Observe that the base address in rax is stored to [rsp] at
instruction [09] and then loaded to rcx at [13]. Ghidra
cannot recognize rcx at [13] denotes the same base address
as rax at [09]. As a result, it cannot recognize local_0
is pointing to the same data structure of the two stack offsets
rsp+0x8 and rsp+0x10. Instead, it identiﬁes local_0 a
32-bit value heap array of size 4 and the two stack offsets as
separate scalar variables. Inspection of Ghidra’s source code
indicates that Ghidra developers do not consider stack offsets
as reliable base addresses (potentially due to that compiler
optimizations may lead to arbitrary stack addressing) such that
it does not even group the two stack offsets to a structure. This
demonstrates that the intrinsic uncertainty in variable recovery
leads to inevitably ad-hoc solutions. In our experiment, Ghidra
achieves 69.77% precision and 76.73% recall.
TIE [12] is a static type inference technique for binary
programs. It leverages a heavy-weight abstract interpretation
technique called Value Set Analysis (VSA)
[13] to reason
about data-ﬂow through memory. VSA over-approximates the
set of values that may be held in registers and memory
locations such that a memory read may read the value(s)
written by a memory write as long as their address registers’
value sets have overlap, meaning that the read and the write
may reference the same address. Facilitated by VSA, TIE is
able to determine that the access of [rsp] at instruction
[13] may receive its value from the write at instruction [09]
that represents the allocated heap region. As such, the accesses
in instructions [14] and [15] allow TIE to determine that
the heap structure consists of two int64 ﬁelds, as shown in
Figure 2. However, VSA is conservative and hence leads to a
large amount of bogus data-ﬂow. As such, existing public VSA
implementations do not scale to large programs [15], including
gzip. Besides, the inherent uncertainty in variable recovery and
type inference often leads to contradicting results. TIE cannot
rule out the bogus results and resorts to a conservative solution
of retaining all of them. Assume the underlying VSA scaled
to gzip and hence TIE could produce results for our sample
function huft_build. TIE would observe that instructions
[14] and [15] access two int64 ﬁelds inside the heap
structure. Meanwhile, it would observe that instruction [10]
directly accesses a 128 bits value in the same structure. It
would consider the structure may contain just a monolithic
ﬁeld. To cope with the contradiction, TIE simply declares a
union to aggregate the results, as shown in Figure 2. Note
that since TIE is not available, in order to produce the pre-
sented results, we strictly followed their algorithm in the paper.
Finally, as commented by some of the TIE authors in [9], TIE
does not support recursive types, although they are widely used
(e.g., in linked lists and binary trees). For example, “struct
s {int a; struct s *next}” would be recovered as
“struct s {int a; void *next}” at best.
REWARDS [1] is a binary variable recovery and type infer-
ence technique based on dynamic analysis. Through dynamic
tainting, it precisely tracks data-ﬂow through registers and
memory such that base-addresses and ﬁeld accesses can be rec-
Fig. 2: Results of different techniques for huft_build.
offsets, and rbp-based offsets as variables or data structure
ﬁelds. For example, it recognizes rsp+0x8 (at instruction
[01]) as a variable/ﬁeld. In order to distinguish data structure
ﬁelds from scalar variables, IDA developers hard-coded a
number of code pattern matching rules. For example, they
consider ﬁeld accesses are performed by ﬁrst loading the base
address of the data structure to a register, and then adding
the ﬁeld offset to the register. As such, they consider all the
accessed addresses that share the same base belong to a data
structure. Another sample rule is that an instruction pair like
the movdqa instruction at [10] and the movups instruction
at [11] denotes a 128-bit packed ﬂoating-point value move-
ment. Unfortunately, modern compilers aggressively utilize
these instruction patterns to optimize code generation. In our
case, the two instructions are not related to ﬂoating-point value
copy but rather general data movement. As shown in Figure 2,
IDA misidentiﬁes elem_t as a union (denoted as union_0)
of a 64-bit value array of size two, and a monolithic ﬁeld
of 128-bit. The data structure is recognized through the lea
instruction at [04], which loads the base address rsp+0x8.
However, since rsp+0x8 and rsp+0x10 are accessed in two
manners, one accessing individual addresses as instructions
[01] and [02], and the other accessing the region as a
whole like instructions [10] and [11], IDA determines that
it is a union. Also observe that IDA fails to recognize that
variable local_0 (i.e., the local variable at stack offset 0
corresponding to p in the source code) is a pointer to the data
structure. In our experiment over 101 programs (Section VI),
IDA achieves 66.88% precision and 76.29% recall.
Ghidra [8] is a state-of-the-art decompiler developed by NSA.
Its algorithm is similar to IDA’s. The improvement is that
Ghidra leverages a register-based data-ﬂow analysis [17] to
analyze potential base addresses that are beyond rsp and rbp
registers. In our example, it identiﬁes rax at instruction [09]
denotes the base address of the allocated heap structure at
[08] as the return value of malloc at [08] is implicitly
stored in rax. This allows Ghidra to identify local_0 (i.e.,
rsp) as a pointer to the heap data structure as shown in the
“Ghidra” column in Figure 2. However, the data-ﬂow analysis
is limited. It does not reason about data ﬂow through memory.
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:33:02 UTC from IEEE Xplore.  Restrictions apply. 
815
struct_0 *local_0;Union_0  *local_0;typedefstruct{longx;longy;} elem_t;+ Such result requires full VSA supported.  * Such results require function  executed.Ground Truthunion_0 *local_0;int64local_8;int64local_10; typedef union {struct {int64s_1;int64s_2;} u_0;int128u_1;} union_0;TIE+and REWARDS*elem_t*p;elem_tv;int128*local_0;union_0 local_8;IDA Protypedef union {int64u_0[2];int128u_1;} union_0;struct_0 *local_0;int64local_8;int64local_10; void*local_0;int64local_8;int64local_10; angrtypedefstruct {int64s_1;int64s_2;} struct_1;typedef union {struct_1 u_0;int128u_1;} union_0;0.30.70.10.9OSPREYstruct_0 *local_0;int64local_8;int64local_10;Ghidratypedef struct {int32s_0[4];} struct_0;typedef struct {int64s_1;int64s_2;} struct_0;Howard*typedef struct {int64s_1;int64s_2;} struct_0;int64local_8;int64local_10;struct_0 local_8; ognized with high accuracy. However, its effectiveness hinges
on the availability of high quality inputs, which may not be
true in many security applications. Theoretical, one could use
fuzzing [18], [19], [20], [21], [22] or symbolic execution [23],
[24], [25], [26], [27] to generate such inputs. However, most
these techniques are driven by a more-or-less random path
exploration algorithm whose goal
is to achieve new code
coverage. In our example, we use a random function (line 6)
to denote the small likelihood of function huft_build()
being covered by path exploration. If functions, code blocks,
and program paths are not covered,
the related data-ﬂow
and hence the corresponding variable/ﬁeld accesses cannot be
recovered by REWARDS. Similar to TIE, REWARDS cannot
deal with uncertainty. In Figure 2, if we assume the function
has all its paths covered, REWARDS would generate the same
undesirable result as TIE.
Howard [14] improves REWARDS using heuristics to resolve
conﬂicts. As shown in the “Howard” column in Figure 2. It
prioritizes complex structures over monolithic ﬁelds. However,
it cannot recognize structures on stack. More detailed discus-
sion can be found in Appendix A. Howard can achieve 81.5%
accuracy, with 59% function coverage.
Angr [11] is a state-of-the-art open source binary analysis
infrastructure. Its variable recovery leverages an advanced
concolic execution engine. Despite the more precise data-ﬂow
analysis, Angr’s variable recovery is not as aggressive as the
others. Hence, in Figure 2, the current implementation of Angr
cannot recognize the structures. More discussion can be found
in Appendix A. In our experiment, Angr achieves 33.40%
precision and 59.27% recall.
A. Our Technique
Observations. From the above discussion, we observe that
compilation and code generation is a lossy procedure, whose
reverse function is inherently uncertain. It is hence very difﬁ-
cult to deﬁne generally applicable rules to recover variables.
In addition, the underlying analysis plays a critical role. These
analysis have different trade-offs in accuracy, scalability, and
the demand of high quality inputs.
Insights. The ﬁrst insight is that while existing techniques
mostly focus on memory access patterns (i.e., base addresses
and offset values) to identify structures, there are many other
program behaviors that can serve as hints to recover data
structures. For example, they include the following. The ﬁrst
is called data-ﬂow hint. In Figure 1c, there is direct data-ﬂow
from v to *p, denoted by the brown arrow 1(cid:13), due to the
copy at instructions [10] and [11]. It implies that the two
memory regions may be of the same complex type. The second
kind of hints originates from points-to relations, called points-
to hint. As blue arrows 2(cid:13) in Figure 1c indicate, variable p may
point to both v and *p, suggesting that they are of the same
type. The third kind of hint is called uniﬁed access point. The
green arrows 3(cid:13) mean that instruction [14] accesses both
v.x and p->x, while instruction [15] accesses both v.y
and p->y. Instructions [14] and [15] are likely uniﬁed
access points to ﬁelds of the same data structure.
The second insight is that the various kinds of hints in
variable/structure recovery can be integrated in a more
organic manner using probabilistic inference [28] . Instead
of making a deterministic call of the type of a memory region,
depending on the number of hints collected, we compute the
probabilities for the memory region having various possible
types. This requires developing a set of probabilistic inference
rules speciﬁc to variable recovery. In our example, the ﬂoat-
point instructions at instructions [10] and [11] cause a
conﬂict, which is suppressed by the large number of other hints
(e.g., 1(cid:13), 2(cid:13), and 3(cid:13) in Figure 1c) in probabilistic analysis.
To realize the above two insights, a critical challenge is to
precisely identify data-ﬂow and points-to relations. The recent
advance made by BDA [15] makes this feasible.
Our Technique. For each memory location, we introduce
multiple random variables to denote the probabilities of pos-
sible types of the memory location. We construct
the set
of possible types and compute the probabilities for these
random variables as follows. Speciﬁcally, OSPREY extends
BDA [15] to compute valuable program properties (introduc-
tion to BDA and our extension can be found in Sections III
and IV), including memory access patterns, data-ﬂow through
register and memory, points-to, heap usage, and so on. These
program properties are regarded as basic facts, each of which
has a prior probability representing its implication of typing
and structural properties. For example in Figure 1c, the points-
to hint 2(cid:13) that p may point to both v and *p indicates a
large prior probability that v and *p are of the same type.
After collecting all the hints with their probabilities, OSPREY
performs probabilistic inference to propagate and aggregate
these hints, and derive the posterior marginal probabilities
that indicate the probable variables, types, and data structure
declarations. For instance, in Figure 2, the likelihood of v (or
local_8) being a stack based structure is much higher than
that of two separated int64s (0.7 v/s 0.3). The likelihood
of p (or local_0) being a pointer to a structure is much
higher than being a pointer to a union (0.9 v/s 0.1). This aligns
perfectly with the ideal result. Our experiments show that if we
only report the most probable ones, our technique can achieve
90.18% precision and 88.62% recall, and 89.05% precision
and 74.02% recall for complex variables (e.g., struct),
substantially outperforming other existing techniques.
III. DESIGN OVERVIEW
Figure 3 shows the workﬂow of OSPREY. Given a stripped
binary, BDA is ﬁrst used to collect basic analysis facts of
the binary (e.g., data-ﬂow and points-to). These basic facts
are then ﬁrst processed by a deterministic reasoning step 2(cid:13).
For example, access/data-ﬂow patterns can be extracted and
compared to form hints. The resulted abstract relations/hints
then go through the probabilistic constraint construction step
3(cid:13), where predicates describing structural and type properties
of individual memory chunks are introduced (e.g., whether
a memory chunk denotes a ﬁeld starting at some memory
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:33:02 UTC from IEEE Xplore.  Restrictions apply. 
816
f ∈ (cid:104)Function(cid:105) ::= Int64
i ∈ (cid:104)Instruction(cid:105) ::= Int64
s ∈ (cid:104)Size(cid:105) ::= Uint64
a ∈ (cid:104)MemAddress: MA(cid:105) ::= (cid:104)r, o(cid:105)
o ∈ (cid:104)Offset(cid:105) ::= Int64
k ∈ (cid:104)Constant(cid:105) ::= Int64
r ∈ (cid:104)MemRegion: MR(cid:105) ::= G|Hi|Sf
v ∈ (cid:104)MemChunk: MC(cid:105) ::= (cid:104)a, s(cid:105)
Fig. 4: Deﬁnitions.
Deﬁnitions. As shown in Figure 4, we use f to denote a
function, which is essentially a 64-bit integer denoting the
function’s entry point, o to denote an offset, i to denote an
instruction, which is essentially a 64-bit integer representing
the starting address of the instruction, and s to denote a size.
The memory space is partitioned to three distinct regions:
global, stack, and heap. The global region, denoted as G,
stands for the space holding all the initialized and uninitialized
global data. A stack frame or a heap-allocated block consti-
tutes a region as well.
Here, we assume that a binary is correctly disassembled
and function entries are properly identiﬁed such that
the