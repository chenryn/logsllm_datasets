3899     /* store the total number of tuples (sum of partial row estimates) */  
3900     path->inner_rows_total = inner_path_rows_total;  
3901   
3902     /* and compute the number of "virtual" buckets in the whole join */  
3903     virtualbuckets = (double) numbuckets * (double) numbatches;  
3904   
3905     /*  
3906      * Determine bucketsize fraction and MCV frequency for the inner relation.  
3907      * We use the smallest bucketsize or MCV frequency estimated for any  
3908      * individual hashclause; this is undoubtedly conservative.  
3909      *  
3910      * BUT: if inner relation has been unique-ified, we can assume it's good  
3911      * for hashing.  This is important both because it's the right answer, and  
3912      * because we avoid contaminating the cache with a value that's wrong for  
3913      * non-unique-ified paths.  
3914      */  
3915     if (IsA(inner_path, UniquePath))  
3916     {  
3917         innerbucketsize = 1.0 / virtualbuckets;  
3918         innermcvfreq = 0.0;  
3919     }  
3920     else  
3921     {  
3922         innerbucketsize = 1.0;  
3923         innermcvfreq = 1.0;  
3924         foreach(hcl, hashclauses)  
3925         {  
3926             RestrictInfo *restrictinfo = lfirst_node(RestrictInfo, hcl);  
3927             Selectivity thisbucketsize;  
3928             Selectivity thismcvfreq;  
3929   
3930             /*  
3931              * First we have to figure out which side of the hashjoin clause  
3932              * is the inner side.  
3933              *  
3934              * Since we tend to visit the same clauses over and over when  
3935              * planning a large query, we cache the bucket stats estimates in  
3936              * the RestrictInfo node to avoid repeated lookups of statistics.  
3937              */  
3938             if (bms_is_subset(restrictinfo->right_relids,  
3939                               inner_path->parent->relids))  
3940             {  
3941                 /* righthand side is inner */  
3942                 thisbucketsize = restrictinfo->right_bucketsize;  
3943                 if (thisbucketsize clause),  
3948                                                virtualbuckets,  
3949                                                &restrictinfo->right_mcvfreq,  
3950                                                &restrictinfo->right_bucketsize);  
3951                     thisbucketsize = restrictinfo->right_bucketsize;  
3952                 }  
3953                 thismcvfreq = restrictinfo->right_mcvfreq;  
3954             }  
3955             else  
3956             {  
3957                 Assert(bms_is_subset(restrictinfo->left_relids,  
3958                                      inner_path->parent->relids));  
3959                 /* lefthand side is inner */  
3960                 thisbucketsize = restrictinfo->left_bucketsize;  
3961                 if (thisbucketsize clause),  
3966                                                virtualbuckets,  
3967                                                &restrictinfo->left_mcvfreq,  
3968                                                &restrictinfo->left_bucketsize);  
3969                     thisbucketsize = restrictinfo->left_bucketsize;  
3970                 }  
3971                 thismcvfreq = restrictinfo->left_mcvfreq;  
3972             }  
3973   
3974             if (innerbucketsize > thisbucketsize)  
3975                 innerbucketsize = thisbucketsize;  
3976             if (innermcvfreq > thismcvfreq)  
3977                 innermcvfreq = thismcvfreq;  
3978         }  
3979     }  
3980   
3981     /*  
3982      * If the bucket holding the inner MCV would exceed hash_mem, we don't  
3983      * want to hash unless there is really no other alternative, so apply  
3984      * disable_cost.  (The executor normally copes with excessive memory usage  
3985      * by splitting batches, but obviously it cannot separate equal values  
3986      * that way, so it will be unable to drive the batch size below hash_mem  
3987      * when this is true.)  
3988      */  
3989     hash_mem = get_hash_mem();  
3990     if (relation_byte_size(clamp_row_est(inner_path_rows * innermcvfreq),  
3991                            inner_path->pathtarget->width) >  
3992         (hash_mem * 1024L))  
3993         startup_cost += disable_cost;  
3994   
3995     /*  
3996      * Compute cost of the hashquals and qpquals (other restriction clauses)  
3997      * separately.  
3998      */  
3999     cost_qual_eval(&hash_qual_cost, hashclauses, root);  
4000     cost_qual_eval(&qp_qual_cost, path->jpath.joinrestrictinfo, root);  
4001     qp_qual_cost.startup -= hash_qual_cost.startup;  
4002     qp_qual_cost.per_tuple -= hash_qual_cost.per_tuple;  
4003   
4004     /* CPU costs */  
4005   
4006     if (path->jpath.jointype == JOIN_SEMI ||  
4007         path->jpath.jointype == JOIN_ANTI ||  
4008         extra->inner_unique)  
4009     {  
4010         double      outer_matched_rows;  
4011         Selectivity inner_scan_frac;  
4012   
4013         /*  
4014          * With a SEMI or ANTI join, or if the innerrel is known unique, the  
4015          * executor will stop after the first match.  
4016          *  
4017          * For an outer-rel row that has at least one match, we can expect the  
4018          * bucket scan to stop after a fraction 1/(match_count+1) of the  
4019          * bucket's rows, if the matches are evenly distributed.  Since they  
4020          * probably aren't quite evenly distributed, we apply a fuzz factor of  
4021          * 2.0 to that fraction.  (If we used a larger fuzz factor, we'd have  
4022          * to clamp inner_scan_frac to at most 1.0; but since match_count is  
4023          * at least 1, no such clamp is needed now.)  
4024          */  
4025         outer_matched_rows = rint(outer_path_rows * extra->semifactors.outer_match_frac);  
4026         inner_scan_frac = 2.0 / (extra->semifactors.match_count + 1.0);  
4027   
4028         startup_cost += hash_qual_cost.startup;  
4029         run_cost += hash_qual_cost.per_tuple * outer_matched_rows *  
4030             clamp_row_est(inner_path_rows * innerbucketsize * inner_scan_frac) * 0.5;  
4031   
4032         /*  
4033          * For unmatched outer-rel rows, the picture is quite a lot different.  
4034          * In the first place, there is no reason to assume that these rows  
4035          * preferentially hit heavily-populated buckets; instead assume they  
4036          * are uncorrelated with the inner distribution and so they see an  
4037          * average bucket size of inner_path_rows / virtualbuckets.  In the  
4038          * second place, it seems likely that they will have few if any exact  
4039          * hash-code matches and so very few of the tuples in the bucket will  
4040          * actually require eval of the hash quals.  We don't have any good  
4041          * way to estimate how many will, but for the moment assume that the  
4042          * effective cost per bucket entry is one-tenth what it is for  
4043          * matchable tuples.  
4044          */  
4045         run_cost += hash_qual_cost.per_tuple *  
4046             (outer_path_rows - outer_matched_rows) *  
4047             clamp_row_est(inner_path_rows / virtualbuckets) * 0.05;  
4048   
4049         /* Get # of tuples that will pass the basic join */  
4050         if (path->jpath.jointype == JOIN_ANTI)  
4051             hashjointuples = outer_path_rows - outer_matched_rows;  
4052         else  
4053             hashjointuples = outer_matched_rows;  
4054     }  
4055     else  
4056     {  
4057         /*  
4058          * The number of tuple comparisons needed is the number of outer  
4059          * tuples times the typical number of tuples in a hash bucket, which  
4060          * is the inner relation size times its bucketsize fraction.  At each  
4061          * one, we need to evaluate the hashjoin quals.  But actually,  
4062          * charging the full qual eval cost at each tuple is pessimistic,  
4063          * since we don't evaluate the quals unless the hash values match  
4064          * exactly.  For lack of a better idea, halve the cost estimate to  
4065          * allow for that.  
4066          */  
4067         startup_cost += hash_qual_cost.startup;  
4068         run_cost += hash_qual_cost.per_tuple * outer_path_rows *  
4069             clamp_row_est(inner_path_rows * innerbucketsize) * 0.5;  
4070   
4071         /*  
4072          * Get approx # tuples passing the hashquals.  We use  
4073          * approx_tuple_count here because we need an estimate done with  
4074          * JOIN_INNER semantics.  
4075          */  
4076         hashjointuples = approx_tuple_count(root, &path->jpath, hashclauses);  
4077     }  
4078   
4079     /*  
4080      * For each tuple that gets through the hashjoin proper, we charge  
4081      * cpu_tuple_cost plus the cost of evaluating additional restriction  
4082      * clauses that are to be applied at the join.  (This is pessimistic since  
4083      * not all of the quals may get evaluated at each tuple.)  
4084      */  
4085     startup_cost += qp_qual_cost.startup;  
4086     cpu_per_tuple = cpu_tuple_cost + qp_qual_cost.per_tuple;  
4087     run_cost += cpu_per_tuple * hashjointuples;  
4088   
4089     /* tlist eval costs are paid per output row, not per tuple scanned */  
4090     startup_cost += path->jpath.path.pathtarget->cost.startup;  
4091     run_cost += path->jpath.path.pathtarget->cost.per_tuple * path->jpath.path.rows;  
4092   
4093     path->jpath.path.startup_cost = startup_cost;  
4094     path->jpath.path.total_cost = startup_cost + run_cost;  
4095 }  
```  
#### [PostgreSQL 许愿链接](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216")
您的愿望将传达给PG kernel hacker、数据库厂商等, 帮助提高数据库产品质量和功能, 说不定下一个PG版本就有您提出的功能点. 针对非常好的提议，奖励限量版PG文化衫、纪念品、贴纸、PG热门书籍等，奖品丰富，快来许愿。[开不开森](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216").  
#### [9.9元购买3个月阿里云RDS PostgreSQL实例](https://www.aliyun.com/database/postgresqlactivity "57258f76c37864c6e6d23383d05714ea")
#### [PostgreSQL 解决方案集合](https://yq.aliyun.com/topic/118 "40cff096e9ed7122c512b35d8561d9c8")
#### [德哥 / digoal's github - 公益是一辈子的事.](https://github.com/digoal/blog/blob/master/README.md "22709685feb7cab07d30f30387f0a9ae")
![digoal's wechat](../pic/digoal_weixin.jpg "f7ad92eeba24523fd47a6e1a0e691b59")
#### [PolarDB 学习图谱: 训练营、培训认证、在线互动实验、解决方案、生态合作、写心得拿奖品](https://www.aliyun.com/database/openpolardb/activity "8642f60e04ed0c814bf9cb9677976bd4")
#### [购买PolarDB云服务折扣活动进行中, 55元起](https://www.aliyun.com/activity/new/polardb-yunparter?userCode=bsb3t4al "e0495c413bedacabb75ff1e880be465a")
#### [About 德哥](https://github.com/digoal/blog/blob/master/me/readme.md "a37735981e7704886ffd590565582dd0")