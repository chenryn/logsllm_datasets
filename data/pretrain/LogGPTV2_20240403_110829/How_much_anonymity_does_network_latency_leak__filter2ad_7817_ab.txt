crypted to B (note that A can not read this message, as A
does not have the key shared between the client and B). A
then passes on the message to B, who peels oﬀ another en-
cryption layer, and passes the message to C. C removes the
ﬁnal encryption layer, ending up with a cleartext message
to be sent to example.com. Messages can be any communi-
cation that would normally take place over TCP.
Since there is signiﬁcant cryptographic overhead (such as
Diﬃe-Hellman key exchange and SSL/TLS handshake) in-
volved with the creation and destruction of a circuit, circuits
are reused for multiple TCP streams. However, anonymity
can be compromised if the same circuit is used for too long,
so Tor avoids using the same circuit for prolonged periods
of time, giving circuits a client-imposed maximum lifetime1.
2.2 Attacks against Tor
Timing-based attacks. There have been a number of at-
tacks mentioned in the literature that exploit the low la-
tency of anonymity systems such as Tor. Several of these
seem to have ﬁrst been proposed, without implementation
or evaluation, by Back et al. [3], including an earlier, more
expensive, version of the Murdoch-Danezis clogging attack
based on ﬂooding nodes and looking for delay in the con-
nection, and using network delays as a potential method to
identify senders.
In [27], Murdoch and Danezis describe an attack that al-
lows a single malicious Tor server and a colluding web server
(or other service provider), to identify all three nodes of
a Tor circuit used by a client for a given session (ideally,
only the exit node’s identity should be known to the ser-
vice provider). However, this system does not identify the
client directly, only its entry node into the Tor network2.
The attack works as follows: when a client connects to the
malicious web server, that server modulates its data trans-
mission back to the client in such a way as to make the
traﬃc pattern easily identiﬁable by an observer. At least
one Tor server controlled by the adversary builds “timing”
circuits through each Tor server in the network (around 800
as of January/February 2007 [1]). These circuits all have
length one, beginning and terminating at the adversarial Tor
node. By sending traﬃc through timing circuits to measure
latency, the adversary is able to detect which Tor servers
process traﬃc that exhibits a pattern like that which the
attacker web server is generating. Since Tor does not re-
serve bandwidth for each connection, when one connection
through a node is heavily loaded, all others experience an
increase in latency. By determining which nodes in the Tor
network exhibit the server-generated traﬃc pattern, the ad-
versary can map the entire Tor circuit used by the client.
Øverlier and Syverson [30] discuss locating Tor hidden ser-
vices. Hidden services allow a server to oﬀer a service anony-
mously via Tor, by maintaining an open circuit to an “intro-
duction point,” which the client contacts through a circuit
ending in a “rendezvous node,” that the server also contacts
through a fresh circuit. Their attack makes use of a mali-
cious client and a single malicious Tor node. The main idea
is to make many connections to the hidden server, so that
it eventually builds a circuit to the rendezvous point using
the malicious Tor node as an entry point. The malicious
1This value is conﬁgurable. In the latest version (0.1.1.26-
alpha), the maximum circuit lifetime is 10 minutes.
2The client can be directly identiﬁed only if its entry node
is also corrupted, but the success of this attack requires
corrupting a proportionally large number of Tor nodes.
Tor node uses a simple timing analysis (packet counting) to
discover when this has happened.
In another attack against Tor hidden services, Murdoch
shows how to identify them based on clock skew [26], en-
abling us to estimate the load of a given Tor node (as tem-
perature rises when CPU load increases) as well as the rough
physical location of the node (as the temperature is gener-
ally higher during the day than at night, with a clear pattern
visible if clock skew is measured over at least one 24-hour
period). This attack may allow us to uniquely map a hid-
den service to a Tor node, if that node is in a geographically
unique location compared to other Tor nodes. More im-
portantly, this attack counters the reserved-bandwidth de-
fense (used to make it harder for Tor nodes to determine
other nodes’ throughput), as CPU load indirectly measures
throughput of a node (based on how busy it is). A node can
defend against this by constantly running the CPU at 100%,
but this may not be universally acceptable.
Syverson et al. [36] suggest that an adversary may de-
anonymize any stream for which that adversary controls the
entry and exit nodes. The probability of this occurrence in
the short term (transient client connections) is c(c − 1)/r2,
where c is the maximum number of nodes corruptable by
the adversary in a ﬁxed period of time, and r is the number
of available Tor routers in the network. An adversary can
determine if he or she controls the entry and exit node for
the same stream by using a number of methods mentioned
below, including ﬁngerprinting and packet counting attacks.
Other attacks within Tor’s threat model.
In [20],
Hintz shows how to determine the remote web site that a
given stream is connecting to by ﬁngerprinting the pattern of
traﬃc carried by the stream. This attack requires maintain-
ing an up-to-date catalog of website ﬁngerprints, and com-
paring observed connections against this catalog. The ﬁn-
gerprint may be stable for certain websites where either the
format or the content does not change much over time. This
attack is particularly detrimental when mounted by a ma-
licious entry node, since it allows for the de-anonymization
of the client (who is directly connecting to the entry node)
as well as the remote web server.
The packet-counting attack is a less time-precise version
of the attacks in [30] – it relies on time intervals as opposed
to timestamps. In this attack, discussed in [3, 4, 34, 38], the
adversary estimates the load level of a node by measuring
the packet ﬂux across that node (the number of packets en-
tering and the number emerging). This attack can be used
as a starting point for other attacks mentioned above, such
as detecting whether an adversary controls nodes that are
part of the same circuit.
Attacks outside the Tor threat model. A well-known
class of attacks against anonymity systems – called statisti-
cal disclosure, or long-term intersection attacks [9,24] – also
use coarse-grained timing, treating the entire anonymizing
network (be it a single mix, a group of mixes, or another
system) as a black box, and correlating traﬃc that enters
and exits the system to determine communication patterns.
This attack essentially learns about all of the communica-
tion relationships between the set of nodes it can monitor.
Since Tor is mainly concerned with a “local adversary” that
can only monitor the communications of its own nodes, the
attack, while a serious consideration, is essentially outside
of Tor’s threat model.
Figure 1: Cumulative distribution of expected infor-
mation gain from RTT per host, for MIT King data set
and PlanetLab nodes.
3. LATENCY WITHOUT NOISE
The possibility of using latency data in traﬃc analysis has
been mentioned several times in previous works, apparently
originating in a 2001 paper by Back et al. [3]. However,
neither this work nor subsequent works seem to have ad-
dressed the basic question of How much information does
network latency leak? Of course the answer is highly de-
pendent on both the network topology – latency in a star
topology would leak no information about a host’s location
– and the protocol in question, since it is conceivable that
so much noise is added to the network latency that the sig-
nal is undetectable. In order to get an upper bound on the
amount of information that can be leaked under the current
Internet topology, we measured the amount of information
about a host that can be gained given a precise estimate of
its RTT to a randomly chosen host. Thus this evaluation
represents a “best case” scenario for the adversary wishing
to locate clients using latency information.
We performed our analysis on two diﬀerent data sets. For
the general Internet, we used the MIT King data set [17].
King [19] is a method for estimating the latency between
two arbitrary Internet hosts, by making recursive queries
through their associated nameservers. While this method
has some ﬂaws when used to estimate arbitrary latencies,
it produces highly accurate estimates of round-trip times
between the nameservers. The MIT dataset consists of mul-
tiple pairwise RTT measurements between 1950 randomly
selected nameservers. Second, because our wide-area exper-
iments use only PlanetLab nodes as clients, we analyzed the
amount of information present in the RTTs between Plan-
etLab nodes.
Our analysis worked as follows:
for each RTT we con-
sidered, there were several measurements; we calculated an
85% conﬁdence interval for each of these by taking the aver-
age plus or minus one standard error. Then for each source
host A, we computed the expected number of bits in the
RTT to a random destination host B by counting, for each
B, the number of hosts C such that the conﬁdence intervals
for AB and AC overlapped. Taking this count as NB and
the total number of hosts as N we computed the information
gain for AB as log2(N/NB).
The results of our analysis for both data sets are shown
in Figure 1. For the King data set, the average number of
bits from RTT per host is 3.64, the median is 3.8, and the
Figure 2: Circuit linking scenario: client A connects via
circuit E-M-X to server Y, and client B connects via N-
R-X to server Z. Y and Z collude to determine if A-E-M
and B-N-R are distinct (left) or identical (right) paths.
10th percentile is 2.8. Thus 90% of Internet hosts leak 2.8
or more bits of location data by their RTT. The information
gain from RTT among the PlanetLab nodes is more concen-
trated, with an average of 3.08 bits from RTT, a median of
3.02, and a 10th percentile of 2.89.
The results also reveal an interesting aspect of the King
data set: of the ten hosts whose RTTs give the least in-
formation gain, all but two have Chinese domain names; in
contrast, the 10 nodes with the highest amount of informa-
tion per RTT appear to be located primarily in western or
central Europe. We speculate that the high information gain
for these European nodes is due to the fact that most Inter-
net routes from Europe to Asia must transit through North
America, so that there are more possibilities for network la-
tency times to these nodes, while the need to transit one
of a few bottleneck links from China adds enough “random”
variability to mask the variation in latency between other
locations external to China.
4. CIRCUIT LINKING VIA LATENCY
The basic setup of our circuit linking attack is shown in
Figure 2.
In this scenario, two colluding servers, Y and
Z, both accept connections from the same Tor exit node,
X. A truly unlinkable anonymity scheme should prevent
the servers from being able to distinguish between the case
that (a) two distinct clients have made the requests and (b)
the same client makes both requests. Conversely, the goal
of the servers Y and Z is to determine whether they are
communicating with diﬀerent clients or the same client.
4.1 Attack Description
Our attack works as follows: we assume that Y commu-
nicates with client A over a Tor circuit involving nodes E,
M , and X, and server Z communicates with client B over
a Tor circuit involving nodes N , R, and the same exit node
X.
If we denote by TU V a random variable that denotes
the RTT between nodes U and V , and by TU a random
variable that denotes the “queueing” time at Tor node U ,
then the idea behind our attack is to take several samples
from both TAX = TAE + TE + TEM + TM + TM X + TX and
TBX = TBN + TN + TN R + TR + TRX + TX .
If A = B,
E = N , and M = R, then the sample sets should appear
to come from the same probability distribution, and if not,
they should appear to come from diﬀerent distributions. The
primary obstacles to overcome are how to obtain samples of
the random variables TAX and TBX , and, to a lesser extent,
what test to use on these samples.
The process of actually sampling the latency of a Tor cir-
cuit is somewhat complicated by the fact that Tor is a proxy
protocol, rather than a tunneling protocol: when the exit
Figure 3: Measuring Tor
time without
application-layer ACKs:
the estimate for TAX is
t3 − t1. We abuse notation and write TXY for the
one-way delay from X to Y .
circuit
node X receives TCP packets from Y , it acknowledges them
immediately, then buﬀers the results into cells, and relays
the cells through the circuit. Thus the usual TCP mecha-
nisms for estimating RTT only estimate the RTT from the
server to the exit node, which will not help with our at-
tack. One possible avenue of attack would be to explore
application-level protocols that have explicit acknowledge-
ments, such as IRC [29], but since the most widely used ap-
plication protocol in Tor seems to be HTTP, which does not
explicitly support application-level ACKs [16], this would
restrict the scope of our attack.
Instead we use a less-
eﬃcient but more widely-applicable approach targeted at
web browsers.
Our attack works as follows: when Y (or Z) gets an HTTP
request from a Tor node and decides to attack the con-
nection, it responds with an HTML page with 1000  tags, pointing to uniquely
named empty image ﬁles. This causes most existing browser
/ privoxy combinations to eventually make 1000 separate
connections to Y 3. For each of these connections, Y will
get a SYN packet from X, and send a SYN/ACK packet;
this packet is ACKed by X and X sends a “RELAY CONN-
ECTED” cell to the client. When the client A receives the
“RELAY CONNECTED” cell, it forwards an HTTP “GET”
request to X, who forwards the request to Y . The time be-
tween the arrivals at Y of the “ACK” and “GET” packets is
a sample from TAX . See Figure 3 for an illustration of this
procedure.
There are many methods for testing similarity of two sam-
ple sets. We used two diﬀerent tests for our evaluation:
• The comparison of means test constructs a conﬁdence
interval for the mean of each sample population, under
the assumption that the time to traverse a Tor circuit
is some ﬁxed time (based on wire speed) plus an ex-
ponentially distributed random variable; two sample
sets are classiﬁed as identical if their conﬁdence inter-
vals overlap. The accuracy of this test depends both
3The amount of concurrency varies, but in the Firefox
browser, for example, by default only 24 concurrent con-
nection attempts are allowed; thus optimistically, these
requests come in 42 “rounds.”
Figure 4: Cumulative distribution of sample size per
run for clients A (left) and B (right).
Figure 5: ROC curves for comparison of means tests
(left, AUC 0.85) and K-S test (right, AUC 0.89).
on the degree to which this model is correct, and the
width of the conﬁdence interval used.
• The Kolmogorov-Smirnov, or K-S, test computes the
largest diﬀerence in cumulative probability density be-
tween two sample sets, and classiﬁes two sample sets as
identical if this value is smaller than some rejection pa-
rameter. The K-S test is nonparametric, i.e. it makes
no assumption about the distributions of the sample