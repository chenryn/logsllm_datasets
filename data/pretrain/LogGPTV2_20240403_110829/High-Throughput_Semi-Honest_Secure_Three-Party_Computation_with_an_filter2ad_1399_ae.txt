Pi+1 generates αi+1 = f (id)− Fki (id). Thus, αi−1 + αi+1 =
Fki−1 (id) − f (id) + f (id) − Fki (id) = Fki−1 (id) − Fki (id) =
−αi, as required.) The full proof follows via a straightfor-
ward reduction.
3.5 Wrapping Up
In the previous sections, we have proven that Protocol 2.3
computes any 3-ary functionality with perfect security in
the Fmult-hybrid model, and that Protocol 3.6 computes the
Fmult functionality with perfect security in the Fcr-hybrid
model. Finally, we have proved that Protocol 3.8 computes
Fcr with computational security (in the plain model) under
the assumption that pseudorandom functions exist. (All of
the above holds for a single corrupted party in the semi-
honest model.) Using the fact that all our protocols are
UC secure from [17] and thus applying the UC composition
theorem of [7], we conclude with the following theorem:
Theorem 3.10. Assume that F is a pseudorandom func-
tion, and let f be a 3-ary functionality. Then, Protocol 2.3
computes f with computational security, in the presence of
one semi-honest corrupted party.
4. PRIVACY: MALICIOUS ADVERSARIES
IN THE CLIENT-SERVER MODEL
In this section, we consider the “client-server” model where
the parties running the multiparty computation protocol are
servers who receive the input shares of multiple clients and
compute the output for them. This is the model used by Cy-
bernetica in their Sharemind product [4]. In this model, the
servers do not see any of the inputs nor any of the outputs.
Rather, they receive shares of the inputs and send the clients
shares of their output. Since the parties running the multi-
party protocol do not have any input or output, it is possible
to formulate an indistinguishability-based deﬁnition of secu-
rity, saying that a corrupted server learns nothing. In this
section, we present such a deﬁnition, and we prove that our
protocol fulﬁlls this deﬁnition of privacy even in the pres-
ence of a malicious corrupted party. We believe that this
formalization is of independent interest, and could be used
to make similar claims regarding other information-theoretic
protocols like [2] and [4, 5]; namely, that although they are
only secure in the presence of semi-honest adversaries, they
are in fact private in the presence of malicious adversaries.
Before proceeding, we stress that a deﬁnition of privacy is
strictly weaker than standard deﬁnitions of security for ma-
licious adversaries. Most notably, correctness is not guar-
anteed and a malicious server may tamper with the output.
In settings where the adversary may receive some feedback
about the output, this may also reveal information about
the input. Thus, our claim of privacy is only with respect
to a malicious server who receives no information about the
output.
Deﬁning security. Let ViewA,I,π((cid:126)v, κ) denote the view of
an adversary A who controls parties {Pi}i∈I (with I ⊂ [n])
in a real execution of the n-party protocol π, with inputs
(cid:126)v = (v1, . . . , vN ) and security parameter κ. We stress that
in this setting, the vector of inputs (cid:126)v is of length N and N
may be much longer (or shorter) than the number of par-
ties n running the protocol. This is because N refers to
the number of inputs and so the number of clients, whereas
n denotes the number of servers running the actual proto-
col. In addition, the servers do not receive for input any of
the values in (cid:126)v but rather they each receive secret shares of
the value. Formally, one should specify the secret sharing
method. However, for generality, we do not deﬁne any spe-
ciﬁc secret sharing scheme and rather deﬁne that for every
vj in (cid:126)v, random v1
j are chosen under the constraint
j = vj, and each server Pj is given the share v(cid:96)
(for every 1 ≤ j ≤ N ).
j
that(cid:80)n
j , . . . , vn
(cid:96)=1 v(cid:96)
Loosely speaking, a protocol is private in the presence of
one malicious corrupted party if the view of the corrupted
party when the input is (cid:126)v is computationally indistinguish-
able from its view when the input is (cid:126)v(cid:48).
In order to rule
out a trivial protocol where nothing is exchanged, we also
require correctness, which means that when all parties are
honest they obtain the correct output.
Definition 4.1. Let f : ({0, 1}∗)N → ({0, 1}∗)N be an
N -party functionality and let π be an n-party protocol. We
say that π t-privately computes f in the client-server model in
the presence of malicious adversaries if it is correct and if for
every non-uniform probabilistic polynomial-time adversary
A, every I ⊂ [n] with |I| ≤ t, and every two series of length-
N vectors V1 = {(cid:126)v1
κ}, V2 = {(cid:126)v2
κ}
(cid:8)ViewA,I,π((cid:126)v1
κ, κ)(cid:9)
κ∈N
c≡(cid:8)ViewA,I,π((cid:126)v2
κ, κ)(cid:9)
κ∈N
where for every κ ∈ N, (cid:126)v1
of (cid:126)v1
κ and (cid:126)v2
κ are of the same length.
κ ∈ ({0, 1}∗)N and all elements
κ, (cid:126)v2
We now prove that Protocol 2.3 fulﬁlls Deﬁnition 4.1,
when making the appropriate changes to the input (con-
813verting vectors of length N into 3-way additive shares for
the parties running Protocol 2.3).
Theorem 4.2. Let f : ((Z2n )∗) → ((Z2n )∗) be an N -
party functionality and deﬁne the 3-party functionality gf to
be the function that receives 3 length-N input vectors that
constitute additive-shares of the input vector (cid:126)v to f and out-
puts 3 length-N vectors that constitute additive-shares of
f ((cid:126)v). If F is a pseudorandom function, then Protocol 2.3
applied to function gf 1-privately computes f in the client-
server model in the presence of malicious adversaries.
Proof Sketch:
Correctness is also required for the
semi-honest setting and this is therefore already implied by
Theorem 3.4. In order to prove privacy, we need to show
that the view of a malicious A controlling one party when
the input is (cid:126)v is indistinguishable from its view when the
input is (cid:126)v(cid:48). We ﬁrst prove that the views are identical when
information-theoretic correlated randomness is used (as de-
scribed in the beginning of Section 2.2).
First, intuitively, the views are identical with information-
theoretic correlated randomness since all the adversary sees
in every rounds is a random share. In order to see that this
holds even when A is malicious, observe that each share
sent to the adversary is masked by a new value obtained
from the correlated randomness. Thus, irrespective of what
A sends in every round, the value that it receives is a random
element. Thus, its view is actually independent of the values
that it sends.
Second, consider the view when Protocol 3.8 is used for
computing Fcr. In the setup phase, A sends some value ki
and receives ki−1. However, the security of the protocol is
proven based on the pseudorandomness of the function keyed
by ki+1 that A does not see. Importantly to this case of ma-
licious adversaries, ki+1 is chosen independently of what A
sends. Furthermore, the parties generate randomness from
this point on using local computation only. Thus, the val-
ues generated by the honest parties are pseudorandom, irre-
spective of what A sent. More formally, consider a reduction
where Fki+1 is replaced by a truly random function f . Then,
Pi−1 computes αi−1 = Fki−1 (id)− f (id) and Pi+1 computes
αi+1 = f (id)−Fki (id). Since ki and ki−1 are ﬁxed and inde-
pendent of f , it follows that αi−1, αi+1 are random under the
constraint that αi−1 +αi+1 = −(Fki (id)−Fki−1 (id)) = −αi,
as required. As we have stated, this holds irrespective of
what value ki that A sent, and A cannot inﬂuence the
αi−1, αi+1 values computed since they involve local com-
putation by the honest parties alone. Thus, the view in this
case is indistinguishable from the view when the parties use
information-theoretic correlated randomness.
5. EXPERIMENTAL RESULTS
5.1 Implementation and Bit-Slicing
We implemented the protocol for Boolean circuits in C++
using standard optimizations known for multiparty compu-
tation. One speciﬁc optimization that we found to be of
great importance was the use of Intel intrinsics for bit slicing
operations; we describe this in more detail here. Since our
protocol is extremely simple, running a single computation
is very wasteful both with respect to CPU and network uti-
lization. A signiﬁcant portion of this waste is due to the fact
that our protocol processes single bits only, whereas mod-
ern processors work on larger objects. We ran our protocol
on 12800 operations in parallel by batching 128 operations
together and running 100 of these in parallel. This batch-
ing works by bit-slicing: the ith bit of input in 128 diﬀerent
inputs are sliced into a single string of length 128 (for each
i). Likewise, the batched output bits need to be de-sliced
into 128 separate outputs. This is a type of “matrix trans-
pose” – see Figure 1 – and turns out to be very expensive.
Indeed, a straightforward implementation of this bit slicing
and de-slicing turned out to greatly dominate the overall
execution time. Hence, we implemented fast bit-slicing and
bit-deslicing methods using Intel SIMD intrinsics in order to
reduce this cost.
Figure 1: Bit-slice
The unit of our bit-slicing is 16 messages of length 8 bytes
each (overall 128 bytes). Thus, we start with:
m0 = (m0,0, m0,1, m0,2, m0,3, m0,4, m0,5, m0,6, m0,7)
m1 = (m1,0, m1,1, m1,2, m1,3, m1,4, m1,5, m1,6, m1,7)
. . .
m15 = (m15,0, m15,1, m15,2, m15,3, m15,4, m15,5, m15,6, m15,7).
Then, we apply the Intel intrinsics “unpack” instruction 32
times to obtain 8 messages, each of length 16 bytes:
(cid:48)
0 = (m0,0, m1,0, . . . , m15,0)
(cid:48)
1 = (m0,1, m1,0, . . . , m15,1)
m
m
. . .
(cid:48)
7 = (m0,7, m1,7, . . . , m15,7).
m
The unpack instruction treats the 128 bit register as 16
single-byte values (8 low and 8 high), and has instructions
to interleave either the low or the high bytes. This process is
actually byte-slicing (since the “transpose”-type operation
is carried out at the byte level and not the bit level). See
Figure 2 for a graphic description of this operation.
Figure 2: Unpack operation of AVX instruction set
814The next step is to further slice the messages to the bit
level. We do this applying the Intel movmskb 64 times to
obtain the bit-sliced inputs. This instruction creates a 16-bit
mask from the most signiﬁcant bits of 16 signed or unsigned
8-bit integers in a register and zeroes the upper bits. Thus,
we are able to take the MSB of 16 bytes in a register in a
single cycle, which is very fast. The movmskb instruction is
depicted in Fig. 3.
Recall that each core processed 12800 AES computations
in parallel, and observe that with a latency of 129ms approx-
imately 7 calls can be processed per second by each core.
Thus, the approximate 100,000 AES computations per core
per second are achieved in this way.
See Figures 4 and 5 for graphs showing the behavior of
the implementation as higher throughputs are achieved.
Figure 3: Moving masked bit operation of AVX instruction set
We apply the movmskb operation to each m(cid:48)
i from the
ﬁrst step (note that each m(cid:48)
i consists of 16 bytes, exactly
as needed for movmskb). These optimizations were crucial
for obtaining the high performance reported in this paper.
5.2 Fast AES
We ran our implementation on a cluster of three mid-level
servers connected by a 10Gbps LAN with a ping time of
0.13 ms. Each server has two Intel Xeon E5-2650 v3 2.3GHz
CPUs with a total of 20 cores. We ran the implementation
utilizing a diﬀerent number of cores, from 1 through to 20.
Each core was given 12800 computations which were carried
out in parallel. (Since Intel intrinsics works on 128-bit reg-
isters, this means that inputs were sliced together in groups
of 128 and then 100 of these were run in parallel by each
core.) These computations can be with diﬀerent keys since
each MPC can have diﬀerent inputs; this will be used in
Section 5.3.
Observe that up to 10 cores, the throughput is stable at
approximately 100,000 AES/sec per core. However, beyond
10 cores this begins to deteriorate. This is due to queuing
between the kernel and the Network Interface Card (NIC).
Speciﬁcally, when a single process utilizing a single CPU is
used, that process has full control over the NIC. However,
when multiple processes are run, utilizing high bandwidth,
requests from each process are handled in a queue between
the kernel and the NIC. This queuing increases network la-
tency, and as each process spends more time waiting for
communication, CPU usage drops by a noticeable percent-
age. It is possible to overcome this by bypassing the kernel
layer and communicating directly with the NIC. One ap-
proach for achieving this appeared in [20].
We ran each experiment 5 times; this was suﬃcient due to
the very low variance as can be seen in Table 2. The results
represent a 95% conﬁdence interval.
Cores
1
5
10
16
20
AES/sec
100,103 ± 1632
530,408 ± 7219