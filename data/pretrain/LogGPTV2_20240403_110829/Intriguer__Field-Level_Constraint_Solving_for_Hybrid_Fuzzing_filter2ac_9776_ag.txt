[7] Hongxu Chen, Yinxing Xue, Yuekang Li, Bihuan Chen, Xiaofei Xie, Xiuheng Wu,
and Yang Liu. 2018. Hawkeye: Towards a Desired Directed Grey-box Fuzzer. In
Proc. the ACM SIGSAC Conference on Computer and Communications Security
(CCS). ACM, 2095–2108.
[8] Peng Chen and Chen Hao. 2018. Angora: Efficient Fuzzing by Principled Search.
In Proc. the IEEE Symposium on Security and Privacy (S&P). IEEE.
[9] Paolo Milani Comparetti, Gilbert Wondracek, Christopher Kruegel, and Engin
Kirda. 2009. Prospex: Protocol Specification Extraction. In Proc. the IEEE Sympo-
sium on Security and Privacy (S&P). IEEE, 110–125.
[10] Weidong Cui, Marcus Peinado, Karl Chen, Helen J Wang, and Luis Irun-Briz. 2008.
Tupni: Automatic Reverse Engineering of Input Formats. In Proc. the ACM SIGSAC
Conference on Computer and Communications Security (CCS). ACM, 391–402.
[11] Brendan Dolan-Gavitt, Patrick Hulin, Engin Kirda, Tim Leek, Andrea Mambretti,
Wil Robertson, Frederick Ulrich, and Ryan Whelan. 2016. Lava: Large-scale
Automated Vulnerability Addition. In Proc. the IEEE Symposium on Security and
Privacy (S&P). IEEE, 110–121.
[12] Shuitao Gan, Chao Zhang, Xiaojun Qin, Xuwen Tu, Kang Li, Zhongyu Pei, and
Zuoning Chen. 2018. CollAFL: Path Sensitive Fuzzing. In Proc. the IEEE Symposium
on Security and Privacy (S&P). IEEE, 679–696.
[13] Vijay Ganesh, Tim Leek, and Martin Rinard. 2009. Taint-based Directed Whitebox
Fuzzing. In Proc. the International Conference on Software Engineering (ICSE). 474–
484.
[14] Patrice Godefroid, Michael Y Levin, David A Molnar, et al. 2008. Automated
Whitebox Fuzz Testing. In Proc. the Network and Distributed System Security
Symposium (NDSS), Vol. 8. 151–166.
[15] Istvan Haller, Asia Slowinska, Matthias Neugschwandtner, and Herbert Bos. 2013.
Dowsing for Overflows: A Guided Fuzzer to Find Buffer Boundary Violations. In
Proc. the USENIX Security Symposium (SEC). USENIX Association, 49–64.
[16] Vasileios P Kemerlis, Georgios Portokalidis, Kangkook Jee, and Angelos D
Keromytis. 2012. libdft: Practical Dynamic Data Flow Tracking for Commodity
Systems. In Acm Sigplan Notices, Vol. 47. ACM, 121–132.
[17] George Klees, Andrew Ruef, Benji Cooper, Shiyi Wei, and Michael Hicks. 2018.
Evaluating Fuzz Testing. In Proc. the ACM SIGSAC Conference on Computer and
Communications Security (CCS). ACM, 2123–2138.
[18] Sam Leffler. 1999. LibTIFF–TIFF Library and Utilities. http://www.libtiff .org/
[19] Yuekang Li, Bihuan Chen, Mahinthan Chandramohan, Shang-Wei Lin, Yang Liu,
and Alwen Tiu. 2017. Steelix: Program-state Based Binary Fuzzing. In Proc. the
Joint Meeting on Foundations of Software Engineering (FSE). ACM, 627–637.
[20] Rupak Majumdar and Koushik Sen. 2007. Hybrid Concolic Testing. In Proc. the
International Conference on Software Engineering (ICSE). IEEE, 416–426.
[21] Barton P Miller, Louis Fredriksen, and Bryan So. 1990. An Empirical Study of the
Reliability of UNIX Utilities. Commun. ACM 33, 12 (1990), 32–44.
[22] Jiang Ming, Dinghao Wu, Gaoyao Xiao, Jun Wang, and Peng Liu. 2015. TaintPipe:
Pipelined Symbolic Taint Analysis. In Proc. the USENIX Security Symposium (SEC).
USENIX Association, 65–80.
[23] David Molnar, Xue Cong Li, and David Wagner. 2009. Dynamic Test Generation
to Find Integer Bugs in x86 Binary Linux Programs. In Proc. the USENIX Security
Symposium. USENIX Association.
[24] Stefan Nagy and Matthew Hicks. 2019. Full-speed Fuzzing: Reducing Fuzzing
Overhead through Coverage-guided Tracing. In Proc. the IEEE Symposium on
Security and Privacy (S&P). IEEE.
[25] Brian S Pak. 2012. Hybrid Fuzz testing: Discovering Software Bugs via Fuzzing
and Symbolic Execution. School of Computer Science Carnegie Mellon University
(2012).
[26] Hui Peng, Yan Shoshitaishvili, and Mathias Payer. 2018. T-Fuzz: fuzzing by
program transformation. In Proc. the IEEE Symposium on Security and Privacy
(S&P). IEEE, 697–710.
[27] Sanjay Rawat, Vivek Jain, Ashish Kumar, Lucian Cojocar, Cristiano Giuffrida,
and Herbert Bos. 2017. VUzzer: Application-aware Evolutionary Fuzzing. In Proc.
the Network and Distributed System Security Symposium (NDSS).
[28] Kostya Serebryany. 2017. OSS-Fuzz-Google’s continuous fuzzing service for open
source software. (2017).
[29] Nick Stephens, John Grosen, Christopher Salls, Andrew Dutcher, Ruoyu Wang,
Jacopo Corbetta, Yan Shoshitaishvili, Christopher Kruegel, and Giovanni Vigna.
2016. Driller: Augmenting Fuzzing Through Selective Symbolic Execution. In
Proc. the Network and Distributed System Security Symposium (NDSS).
[30] Tielei Wang, Tao Wei, Guofei Gu, and Wei Zou. 2010. TaintScope: A Checksum-
Aware Directed Fuzzing Tool for Automatic Software Vulnerability Detection.
In Proc. the IEEE Symposium on Security and Privacy (S&P). IEEE, 497–512.
[31] Tielei Wang, Tao Wei, Zhiqiang Lin, and Wei Zou. 2009. IntScope: Automatically
Detecting Integer Overflow Vulnerability in X86 Binary Using Symbolic Execu-
tion. In Proc. the Network and Distributed System Security Symposium (NDSS).
[32] Zhi Wang, Xuxian Jiang, Weidong Cui, Xinyuan Wang, and Mike Grace. 2009.
ReFormat: Automatic Reverse Engineering of Encrypted Messages. In European
Symposium on Research in Computer Security (ESORICS). 200–215.
[33] Insu Yun, Sangho Lee, Meng Xu, Yeongjin Jang, and Taesoo Kim. 2018. QSYM:
A Practical Concolic Execution Engine Tailored for Hybrid Fuzzing. In Proc. the
USENIX Security Symposium (SEC). USENIX Association, 745–761.
[34] Michal Zalewski. 2014. American fuzzy lop. http://lcamtuf .coredump.cx/afl/
APPENDICES
Figure 12: Symbolic emulation time and the proportion incurred
by mov-like instructions in each program. The percentage on the top
of each bar represents the proportion of mov-like instructions.
A EMULATION TIME OF MOV-LIKE
INSTRUCTIONS
To examine the effectiveness of eliminating mov-like instructions
with regard to performance improvement, we performed a micro-
evaluation. Figure 12 shows the symbolic emulation time taken
in each program and particularly the proportion incurred by mov-
like instructions. In three real-world programs, such as objdump,
ffmpeg10, and tiff2pdf, mov-like instructions occupied a great
portion of the emulation time. But why? Our observation is that mov-
like instructions don’t introduce new symbolic expressions but they
incur a copy of symbolic expressions per execution. At this time,
new symbolic expressions are generated for the destination (e.g.,
memory address or register) of mov-like instructions, incurring the
performance overhead similar to the introduction of new symbolic
expressions. Interestingly, we observed that Qsym occasionally
used a solver to concretize memory addresses in the emulation of
mov-like instructions, incurring the additional overhead.
Unlike the three programs, we observed the small portion of
the emulation time for mov-like instructions in who of LAVA-M.
This is because who is much smaller in size and less in handling
input-related instructions than the other real-world programs. In
addition, as shown in Figure 3, who doesn’t generate complicated
constraints, resulting in a fast copy of symbolic expressions.
Our evaluation results indicate that it is obviously effective to
remove mov-like instructions in advance for performance improve-
ment in hybrid fuzzing.
10ffmpeg terminated with "Pin is out of memory" error before its complete execution.
Session 3A: Fuzzing: Methods and ApplicationsCCS ’19, November 11–15, 2019, London, United Kingdom529Table 16: LAVA-M dataset evaluation results. Left columns: the number of bugs injected in four programs, as listed in LAVA-M [11]. Middle
columns: the number of bugs found by recent techniques, as reported in each paper. Right columns: the number of bugs found by VUzzer,
Qsym, and Intriguer in our own experiments on the same platform. Our experimental results are reported with max values by 20 runs. Each
experiment time is 5h as default [11]. For median values, readers are referred to as Table 8. For extended 24h experiments with who for Qsym
and Intriguer, readers are referred to as Figure 8. Note that at present only Intriguer detected all the bugs in four LAVA-M’s buggy programs.
Programs
uniq
base64
md5sum
who
Total
Bugs
28
44
57
2,136
2,265
FUZZER [11]
7
7
2
0
16
SES [11]
0
9
0
18
27
VUzzer [27]
27
17
0
50
94
Steelix [19]
7
43
28
194
272
T-Fuzz [26]
26
43
49
63
291
Angora [8]
28
44
57
1,443
1,572
Qsym [33]
28
44
57
1,238
1,367
VUzzer
28
40
26
29
123
Qsym Intriguer
28
44
57
2,136
2,265
28
44
57
1,452
1,581
Table 17: Time decomposition of field-level constraint solving for
performance evaluation of eliminating uncomplicated constraints.
For complicated (C) constraints, we used a solver, denoted as S(),
but for uncomplicated (U) constraints, we directly solved them as
D() or used S() for comparisons. Symbolic emulation time as well
as solving time is significantly affected by the uncomplicated con-
straints. The performance gain by Intriguer, i.e., S(C),D(U) compared
to S(C,U), is represented by a percentage. (Time for a single run)
Emulation time (s)
S(C),D(U)
S(C,U)
Solving time (s)
S(C),D(U)
S(C,U)
Program
md5sum (L)
who (L)
objdump
nm
readelf
ffmpeg
tiff2pdf
5.1
2.6
2.0
1.0
3.3
2.3
4.7
Gain
32.9%
39.5%
52.4%
52.4%
48.4%
41.0%
24.2%
7.6
4.3
4.2
2.1
6.4
3.9
6.2
1.1
0.6
0.7
0.3
1.3
0.8
1.7
Gain
35.3%
40.0%
53.3%
57.1%
43.5%
38.5%
19.0%
1.7
1.0
1.5
0.7
2.3
1.3
2.1
B PERFORMANCE GAIN BY ELIMINATING
UNCOMPLICATED CONSTRAINT SOLVING
To examine the effectiveness of eliminating uncomplicated con-
straints for a symbolic solver in hybrid fuzzing, we also conducted
a micro-evaluation. Table 17 shows that the strategy of Intriguer
for uncomplicated constraints (i.e, solving them directly) signif-
icantly outperforms the previous strategy (i.e., solving them al-
ways with a symbolic solver) in terms of symbolic emulation time
and solving time. The performance gain by Intriguer, computed as
(1 − ∆(S(C), D(C))/∆(S(C, U))) × 100 for time measurement of ∆(),
indicates that eliminating uncomplicated constraints for a solver
is an efficient strategy in hybrid fuzzing. Note that compared to
solving time, the emulation time more affects performance.
C SPECIAL CASES IN TAINT PROPAGATION
MUL, IMUL, DIV and IDIV can affect registers that are not directly
used as operands. For example, MUL multiplies the value received by
the operand by EAX and stores the result in EDX:EAX, even if EDX is
not used as the operand. Therefore, when MUL, IMUL, DIV, or IDIV
is executed, even registers that are not listed in the operand will
perform taint propagation.
XOR is also used to initialize the operand value to zero in the
program. For example, when XOR EAX, EAX is executed, the value
of EAX is always zero. Thus, if XOR is used for initialization, the
operand used is removed from the tainted memory list. AND is also
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
# include 
class example {
int var1 , var2 ;
public :
void set_request ( int a , int b);
int sum () { return ( var1 + var2 ) ;}
} class_obj ;
void example :: set_request ( int a , int b)
{
var1 = a;
var2 = b;
}
int main ( void )
{
class_obj . set_request (1 ,4) ;
std :: cout <<"\n The sum is " << class_obj . sum () <<"\n";
return 0;
}
Listing 5: C++ source code used for a binary seed.
used to mask data in the program. For example, when AND EAX,
0x000000ff is executed, only the LSB value is used in EAX. There-
fore, if AND is used to mask data, the data in the unused offset
are removed from the tainted memory list. REP and related repeat
mnemonics are prefixes that can be added to a string instruction
for repetition up to the value stored in the counter register. The
REP prefix is often added to instructions such as MOVS to write or
read values on memory. If there is a REP prefix, the value in the
counter register is checked and the result of the repeated instruc-
tions is processed immediately. Such cases were also discussed in
the previous studies of taint analysis [16, 22].
D C++ SOURCE CODE FOR BINARY SEED
The source code shown in Listings 5 was used for evaluation of
binutils programs.
E LAVA-M RESULTS
Table 16 shows the number of bugs found by the state-of-the-art
fuzzers in 5h fuzzing on LAVA-M binaries. The middle columns
are numbers reported by each paper, while the last three columns
are the results of our experiments. Note that we show only the
number of “listed” bugs in Table 16 (and also in Table 8) by following
previous works, but Intriguer also found “unlisted” bugs, e.g., not
only all 2136 listed bugs, but also 328 unlisted bugs in who, summing
up to 2464 bugs discovered in who (5h).
Session 3A: Fuzzing: Methods and ApplicationsCCS ’19, November 11–15, 2019, London, United Kingdom530