title:Exploiting and Protecting Dynamic Code Generation
author:Chengyu Song and
Chao Zhang and
Tielei Wang and
Wenke Lee and
David Melski
Exploiting and Protecting Dynamic Code Generation
Chengyu Song
Georgia Institute of Technology
Chao Zhang
UC Berkeley
Tielei Wang, Wenke Lee
Georgia Institute of Technology
David Melski
GrammaTech
PI:EMAIL
PI:EMAIL
PI:EMAIL,
PI:EMAIL
PI:EMAIL
Abstract—Many mechanisms have been proposed and de-
ployed to prevent exploits against software vulnerabilities. Among
them, W⊕X is one of the most effective and efﬁcient. W⊕X
prevents memory pages from being simultaneously writable
and executable, rendering the decades old shellcode injection
technique infeasible.
In this paper, we demonstrate that the traditional shellcode
injection attack can be revived through a code cache injection
technique. Speciﬁcally, dynamic code generation, a technique
widely used in just-in-time (JIT) compilation and dynamic binary
translation (DBT), generates and modiﬁes code on the ﬂy in order
to promote performance or security. The dynamically generated
code fragments are stored in a code cache, which is writable
and executable either at the same time or alternately, resulting
in an opportunity for exploitation. This threat is especially
realistic when the generated code is multi-threaded, because
switching between writable and executable leaves a time window
for exploitation. To illustrate this threat, we have crafted a proof-
of-concept exploit against modern browsers that support Web
Workers.
To mitigate this code cache injection threat, we propose a
new dynamic code generation architecture. This new architecture
relocates the dynamic code generator to a separate process,
in which the code cache is writable. In the original process
where the generated code executes, the code cache remains read-
only. The code cache is synchronized across the writing process
and the execution process through shared memory. Interaction
between the code generator and the generated code is handled
transparently through remote procedure calls (RPC). We have
ported the Google V8 JavaScript engine and the Strata DBT
to this new architecture. Our implementation experience showed
that the engineering effort for porting to this new architecture
is minimal. Evaluation of our prototype implementation showed
that this new architecture can defeat the code cache injection
attack with small performance overhead.
I.
INTRODUCTION
Exploits against software vulnerabilities remain one of the
most severe threats to cyber security. To mitigate this threat,
many techniques have been proposed, including data execution
prevention (DEP) [4] and address space layout randomization
(ASLR) [42], both of which have been widely deployed and are
Permission to freely reproduce all or part of this paper for noncommercial
purposes is granted provided that copies bear this notice and the full citation
on the ﬁrst page. Reproduction for commercial purposes is strictly prohibited
without the prior written consent of the Internet Society, the ﬁrst-named author
(for reproduction of an entire paper only), and the author’s employer if the
paper was prepared within the scope of employment.
NDSS ’15, 8-11 February 2015, San Diego, CA, USA
Copyright 2015 Internet Society, ISBN 1-891562-38-X
http://dx.doi.org/10.14722/ndss.2015.23233
effective. DEP is a subset of the more general security policy
W⊕X, which enforces that memory should either be writable
but not executable (e.g., data segments), or be executable
but read-only (e.g., code segments). This enforcement can
completely mitigate traditional exploits that inject malicious
shellcode into data segments. Consequently, attackers have to
leverage more complicated exploit techniques, such as return-
to-libc [53] and return-oriented-programming (ROP) [52].
Moreover, W⊕X memory has become the foundation of many
other protection techniques, such as control ﬂow integrity
(CFI) [2, 63, 64].
However, the effectiveness of W⊕X can be undermined
by another important compilation technique – dynamic code
generation (DCG). With the ability to generate and execute
native machine code at runtime, DCG is widely used in just-
in-time (JIT) compilers [7] and dynamic binary translators
(DBT) [28, 48] to improve performance, portability, and secu-
rity. For example, JIT compilers for dynamic languages (e.g.,
JavaScript and ActionScript) can leverage platform information
and runtime execution proﬁle information to generate faster
native code. DBTs can leverage DCG to provide dynamic
analysis capability [28], cross-platform or cross-architecture
portability [9, 47], bug diagnostics [33, 45], and enhanced
security [8, 12, 25, 26, 36].
A fundamental challenge posed by DCG is that the code
cache, in which the dynamically generated code is stored,
needs to be both writable (for code emitting, code patching,
and garbage collection) and executable. This violates the W⊕X
policy and enables a new attack vector. We have observed
a real world exploit that delivers shellcode into the writable
code cache and successfully compromises the Chrome web
browser [43].
Solving this problem seems trivial. A straightforward idea,
which has been adopted in browsers like mobile Safari, is
demonstrated in Figure 1. This technique keeps the code cache
as read-only and executable (RX) when the generated code is
executing; switches to writable but not executable (WR) when
it needs to be modiﬁed (t1); and switches back to RX when
the write operation ﬁnishes (t2). As a result, the code cache
will remain read-only when the generated code is executing;
and the attack demonstrated in [43] can be mitigated.
Unfortunately, in addition to performance overhead, this
simple mechanism does not work well with multi-threaded
programs. First, if the code generator uses a shared code cache
for all threads (e.g., PIN [28]), then the code cache cannot be
switched to WR, because other concurrently running threads
require the executable permission. Second, even if the code
generator uses a dedicated code cache for each thread (e.g., JS
engines), the protection is still ﬂawed and is subject to race
condition attacks [34], as shown in Figure 2. More speciﬁcally,
memory access permissions are applied to the whole process
and are shared among all threads. When one thread turns on the
writable permission for its code cache (e.g., for code emitting),
the code cache also becomes writable to all other threads. Once
the write permission is set, another concurrently running thread
can (maliciously) overwrite the ﬁrst thread’s code cache to
launch attacks. This is similar to the classic time-of-check-
to-time-of-use (TOCTTOU) problem [29], where the resource
to be accessed is modiﬁed between the check and the use by
exploiting race conditions.
In this paper, we demonstrate the feasibility of such race-
condition-based code cache injection attacks, through a proof-
of-concept exploit against modern browsers that support the
Web Worker [57] speciﬁcation. Rather than relying on a per-
manently writable code cache [43], our attack leverages race
conditions and can bypass permission-switching-based W⊕X
enforcement (Figure 1). In this attack, the malicious JS code
utilizes web workers to create a multi-threaded environment.
After forcing a worker thread into the compilation state, the
main JS thread can exploit vulnerabilities of the browser to
inject shellcode into the worker thread’s code cache.
To fundamentally prevent such attacks, we propose secure
dynamic code generation (SDCG), a new architecture that 1)
enables dynamic code generation to comply with the W⊕X
policy; 2) eliminates the described race condition; 3) can be
easily adopted; and 4) introduces less performance overhead
compared to alternative solutions. SDCG achieves these goals
through a multi-process-based architecture. Speciﬁcally, in-
stead of generating and modifying code in a single process,
SDCG relocates the DCG functionality to a second trusted
process. The code cache is built upon memory shared between
the original process and the trusted process. In the original
process, the code cache is mapped as RX; and in the trusted
process, the same memory is mapped as WR. By doing so,
the code cache remains read-only under all circumstances
in the untrusted process, eliminating the race condition that
allows the code cache to be writable to untrusted thread(s).
At the same time, the code generator in the trusted process
can freely perform code generation, patching and garbage
collection as usual. To enable transparent interaction between
the code generator and the generated code, we only need to
add a few wrappers that make the code generator invocable
through remote procedure calls (RPC). Since only functions
that modify code cache need to be handled, the effort for
adding wrappers is small.
We implemented SDCG for two types of popular code
generators: JS engine and DBT. For JS engine, our implemen-
tation is based on V8 [24]. For DBT, our implementation is
based on Strata [48]. Our implementation experience showed
that porting code generators to SDCG only requires a small
modiﬁcation: besides the shareable part, which is about 500
lines of C code (LoC), we only added about 2,500 LoC
for V8 and about 1,000 LoC for Strata. We evaluated the
security of SDCG and the performance overhead of our two
prototype implementations. The results showed that SDCG is
secure under our threat model and the performance overhead
introduced by our prototype implementations is small: around
6.90% (32-bit) and 5.65% (64-bit) for V8 benchmark suite;
and around 1.64% for SPEC CINT 2006 (additional to Strata’s
own overhead).
In summary, we made the following contributions:
• Beyond known exploit techniques against permanently
writable code cache [43], we demonstrated the feasibility
of exploiting race conditions to maliciously modify code
cache protected by permission switching based W⊕X
enforcement; and discussed the severity of such attacks
(Section III).
• We proposed secure dynamic code generation (SDCG), a
multi-process-based architecture that provides better secu-
rity (mandatory, non-bypassible W⊕X enforcement), low
performance overhead, and easy adoption (Section IV).
• We implemented two prototypes of SDCG, one for V8
JS engine and one for Strata dynamic binary translator
(Section V).
• We evaluated the performance overhead of our two pro-
totype implementations (Section VI).
II. RELATED WORK
In this section, we discuss the techniques that could be
used to protect a code cache from being maliciously modiﬁed
and explain their disadvantages. We also discuss other forms
of attacks against the JIT engines and their countermeasures.
A. Software-based Fault Isolation
Software-based fault isolation (SFI) [58] can be used to
conﬁne a program’s ability to access memory resources. On
32-bit x86 platforms, SFI implementations usually leverage
segment registers [20, 62] to conﬁne memory accesses for
the beneﬁt of low runtime overhead. On other platforms
without segment support (e.g., x86-64, ARM), SFI implemen-
tations use either address masking [49] or access control lists
(ACL) [10], introducing higher runtime overhead.
Once memory accesses — especially write accesses — are
conﬁned, SFI can prevent untrusted code from overwriting
security sensitive data, such as the code cache. Our SDCG
solution differs from SFI in several respects. First, SFI’s
overhead comes from the execution of the extra inline checks;
SDCG’s overhead comes from remote procedure calls and
cache synchronization on multi-core systems. Therefore, if
execution stays mostly within the code cache, SDCG will
introduce less overhead than SFI. On the other hand,
if
execution needs to be frequently switched between the code
generator and the generated code, then SFI could be faster.
Since most modern code generators try to make the execution
stay as long as possible in the code cache, our approach is
more suitable in most cases.
Second, to reduce the overhead of address masking, many
SFI solutions [49] use ILP32 (32-bit integer, long, pointer)
primitive data types, limiting data access to 4GB of space,
even on a 64-bit platform. SDCG does not have this limitation.
It is worth noting that some efforts have been made to
apply SFI to JIT engines [5, 38]. Despite relatively higher
overhead, the threat model of these approaches usually did not
consider scenarios where the JIT compiler is only a component
of a larger software solution, such as a web browser. Since
most web browser vulnerabilities are found outside the JIT
2
Fig. 1: A permission switching based W⊕X enforcement. The code cache is kept as read-only when the generated code is
executing. When the code generator is invoked (t1), the permission is changed to writable; and when the generator ﬁnishes its
task (t2), the permission is changed back to read-only.
Fig. 2: Race-condition-based attack using two threads. With switching based W⊕X enforcement, a single thread (A) can no
longer attack the code cache (access 1), but the code cache can still be attacked using multiple threads. When the code generator
is serving one thread (access 2), the code cache will also become writable for other threads (access 3). The attack window is t2
- t1. Once the code generator ﬁnishes its task, the code cache becomes read-only again (access 4).
engines [17], to apply such techniques one would have to apply
SFI to other browser components as well. This could result in
even higher performance overhead. From this perspective, we
argue that our solution is more realistic in practice.
a program’s control ﬂow cannot be hijacked to unexpected
locations. CFI could protect the code cache in some way,
e.g., attackers cannot overwrite the code cache by jumping
to arbitrary addresses of the code generator.
B. Memory Safety
Attacks on code caches (at randomized locations) rely
on the ability to write to a memory area speciﬁed by an
attacker. Therefore, such attacks could be defeated by memory
safety enforcement, which prevents all unexpected memory
reads and writes. However, many programs are written in
low-level languages like C/C++, and are prone to memory
corruption bugs, leading to the majority of security vulner-
abilities for these languages. Unfortunately, existing memory
safety solutions [6, 19, 31, 32, 41, 51, 61] for C/C++ programs
tend to have much higher performance overhead than SFI or
other solutions, prohibiting their adoptions. For example, the
combination of Softbound [31] and CETS [32] provides a
strong spatial and temporal memory safety guarantee, but they
were reported to have 116% average overhead on SPEC CPU
2000 benchmark. Compared with this direction of research,
even though SDCG provides less security guarantees, it is still
valuable because it fully blocks a powerful attack vector with
minimal runtime overhead.
C. Control Flow Integrity
Control ﬂow hijacking is a key step in many real world
attacks. As DEP becomes ubiquitous, more and more attacks
rely on return-to-libc [53] or ROP [52] to hijack control
ﬂow. Many solutions [2, 63, 64] have been proposed to
enforce control ﬂow integrity (CFI) policy. With CFI policy,
However, attackers can still utilize arbitrary memory write
vulnerabilities to overwrite the code cache without break-
ing CFI. Once the code cache is overwritten, injected code
could be invoked through normal function invocations, without
breaking the static CFI policy.
Moreover, when extending CFI to dynamically generated
code, without proper write protection the embedded enforce-
ment checks can also be removed once attackers can overwrite
the code. From this perspective, SDCG is complementary to
CFI because it guarantees one basic assumption of CFI: code
integrity protection.
D. Process Sandbox
A delegation-based sandbox architecture, a.k.a. the broker
model [21], has been widely adopted by the industry and used
in Google Chrome [23], Windows 8 [30], Adobe Reader [3],
etc. In this architecture, the sandboxed process drops most of
its privileges and delegates all security sensitive operations to
the broker process. The broker process then checks whether the
request complies with the security policy. SDCG is based on
the same architecture. Using this architecture, we 1) delegate
all the operations that will modify the code cache (e.g., code
installation, patching, and deletion) to the translator process;
and 2) make sure the W⊕X policy is mandatory.
3
Code Cache (RX)  Thread Code Cache (WR)  Code Cache (RX)  Code Generator Running Generated Code Running t1t2Code Cache (RX)  Thread A Thread B Code Cache (WR)  Code Cache (RX)  Code Generator Running Generated Code Running t1t21 2 3 4 E. Attacks on JIT engines
Attackers have targeted the code cache for its writable
and executable properties. Currently, the most popular exploit
technique is JIT spray [54], an extension to classic heap spray
attacks [18]. Heap spray is used to bypass ASLR without
guessing the address of injected shellcode. This technique
becomes unreliable after DEP is deployed because the heap
is no longer executable. To bypass this, attackers turned to
JIT engines. The JIT spray attack abuses the JIT engine to
emit chunks of predictable code, and then hijacks control ﬂow
toward the entry or middle of one of these code chunks. DEP
or W⊕X is thus bypassed because these code chunks reside
in the executable code cache. Most JIT engines have since
deployed different mitigation techniques to make the layout
of the code cache unpredictable, e.g., random NOP insertion,
constant splitting, etc. Researchers have also proposed more
robust techniques [5, 60] to prevent such attacks.
Rather than abusing JIT engines to create expected code,
attackers can also abuse the writable property of the code cache
and directly overwrite generated code [43]. In the next section,
we ﬁrst extend this attack to show that even with a permission
switching based W⊕X enforcement, attackers can still leverage
race conditions to bypass such enforcement.
III. ATTACKING THE CODE CACHE