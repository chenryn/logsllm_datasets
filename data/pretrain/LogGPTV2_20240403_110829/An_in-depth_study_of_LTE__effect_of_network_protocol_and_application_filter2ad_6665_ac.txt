### Downlink In-Flight Bytes and RTT

The number of downlink in-flight bytes is calculated by counting the unacknowledged bytes. As illustrated in Figure 10, the downstream Round-Trip Time (RTT) tends to increase as the number of in-flight bytes grows. In our study of LTE networks, the in-flight bytes can exceed 1200 KB, leading to high latency due to queuing delays. We conducted local experiments (§3.2) to measure both the RTT and the in-flight bytes at the User Equipment (UE) for two large commercial LTE networks. Figures 11 and 12 show a clear trend where RTT increases with the number of in-flight packets. This observation aligns with a recent study [16], which indicates that the use of large buffers in today's cellular networks can cause significant queuing delays.

Furthermore, we demonstrate the prevalence of this issue in current LTE networks. As shown in Figure 13, which plots the distribution of downlink in-flight bytes for large flows (> 1 MB), approximately 10% of the measured instances have in-flight bytes exceeding 200 KB, potentially resulting in long queuing delays.

### Impact on Short and Long Flows

For short flows or traffic triggered by user interactions (e.g., web browsing), queues are unlikely to build up. For long-lived flows, throughput is generally more important than latency. However, when short-lived and long-lived flows coexist (e.g., browsing while streaming in the background), queuing delays can severely degrade user experience by introducing unacceptable delays for short flows. Additionally, we observed that high downstream queuing delays can often cause TCP’s congestion window to collapse upon a single packet loss. This newly identified and severe issue is discussed in §5.

### Retransmission Rate

We analyzed the TCP downlink retransmission rate, defined as the number of retransmitted packets divided by the total number of packets, across all downlink flows in our dataset. 38.1% of the flows had zero retransmissions, and the median retransmission rate was only 0.06%. These low retransmission rates are comparable to those in wired networks [22]. The actual packet loss rate is even lower, as the retransmission rate is an upper bound for the packet loss rate in the downstream (i.e., between UE and monitor). In cellular networks, most transport-layer losses are mitigated by physical/MAC-layer retransmissions and buffering. Specifically, buffers in LTE networks upstream from the air interface play a crucial role in absorbing the burstiness of traffic transmitted over the lossy wireless link, thereby achieving a low loss rate.

### Comparison to Previous Studies

We compared our results with three previous measurement studies, focusing on three key metrics: TCP downlink throughput, TCP uplink throughput, and TCP handshake RTT. The 3GTest study [14] deployed an app to measure network performance metrics on users' handsets, collecting data from 35K cellular (3G only) tests from four large U.S. cellular carriers in late 2009. The 4GTest study [13] used a similar approach but focused on LTE users, with data comprising about 1K LTE tests and a few WiMAX tests across the U.S. in late 2011. A recent study [31] examined a 15-week dataset from speedtest.net in 2011. Table 1 summarizes their reported performance metrics for handheld device users from three locations: New York City (246K WiFi tests / 79K cellular tests), Madison, Wisconsin, U.S. (24K WiFi / 4K cellular), and Manchester, U.K. (291K / 31K). The cellular technologies ranged from 2G EDGE to 4G LTE, with 3G (UMTS/EvDO/HSPA) being the dominant technology.

### Methodological Differences

Three major issues may affect the comparison:
1. **Throughput Measurement**: The previous studies used bulk data transfer of large files without pauses, whereas our flows may include idle periods (e.g., due to user think time), leading to lower throughput. To ensure a fair comparison, we only considered large non-PEP flows (with at least 200 KB for uplink and 1 MB for downlink) with no visible idle periods (maximum inter-packet time less than 1 second, which is larger than the 99.9th percentile of RTT).
2. **Rate Limiting**: Remote servers in our case may impose rate limits [10], while the previous studies used dedicated test servers without any throughput limitations.
3. **Server Selection**: We inferred performance metrics from traces of real Internet servers, while 3GTest, 4GTest, and SpeedTest employed different server selection policies. 3GTest used a single server located in the U.S., while 4GTest and SpeedTest selected servers geographically close to the UE, which particularly affects latency estimation.

### Comparative Results

Despite these differences, the comparison in Table 1 still highlights the advantages of LTE over other cellular access technologies. The median downlink throughput, uplink throughput, and handshake RTT for LTE are 9.5x, 6.9x, and 0.43x, respectively, compared to the median values of the best U.S. 3G carrier in 2009. Compared to the 2011 New York City cellular results, the ratios are 5.5x, 3.0x, and 0.44x for downlink throughput, uplink throughput, and RTT, respectively. Moreover, LTE outperforms WiFi in many cases, especially for the 5th/50th/95th percentiles of downlink throughput and the median uplink throughput. However, LTE's latency appears higher than WiFi, likely due to the proximity of test servers in Speedtest. Our performance values are consistently lower than those reported by 4GTest, possibly due to rate limiting by remote servers [10]. LTE also significantly outperforms WiMAX in all three metrics.

### Abnormal TCP Behavior

We focused on large flows, defined as relatively long flows with more than 5 seconds of data transfer time and total downlink payload exceeding 1 MB. These large flows account for only 0.3% of all TCP flows in our dataset but contribute 47.7% of the total downlink payload. Upon receiving an out-of-order unacknowledged segment, a TCP receiver sends an immediate duplicate ACK [3]. From the sender's perspective, duplicate ACKs can be caused by reordering or loss. When there is a large amount of in-flight bytes and one data segment S is lost, each subsequent data segment with a higher sequence number triggers a duplicate ACK until S is successfully retransmitted. Thus, a long sequence of duplicate ACKs strongly suggests a packet loss. When TCP detects three duplicate ACKs, it infers a data packet loss and retransmits it using fast retransmit [3].

Figure 14 summarizes duplicate ACKs and packet reordering in large TCP flows. Although the median number of duplicate ACKs in large flows is 17, over 29.0% of the large flows have more than 100 duplicate ACKs. The number of out-of-order data packets in large flows is substantially smaller, with a median value of only 2. By studying the ratio between duplicate ACKs and out-of-order data packets, 24.7% of flows have a ratio of over 25, and in some cases, this ratio can reach up to 5,000. This indicates that even a single out-of-order data packet can trigger a large number of duplicate ACKs when the in-flight bytes are large, consuming more uplink bandwidth.

Fast retransmission allows TCP to directly send the lost segment to the receiver, potentially preventing a retransmission timeout (RTO). If so, TCP would resume data transfer with the congestion window size reduced by half. However, as previously noted, we identified significant queuing buildup between the UE and the monitor. Such large in-network queues, capable of holding up to a few megabytes of data, can delay the receipt of the retransmitted data packet. In such cases, if TCP does not use duplicate ACKs to update RTO, a timeout is likely to occur.