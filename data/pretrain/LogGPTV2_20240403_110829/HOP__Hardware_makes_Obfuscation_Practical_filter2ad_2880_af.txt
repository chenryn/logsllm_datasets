In this section, we present practical deployment consider-
ations and potential applications for a HOP processor.
Parties involved in the system. In a practical deployment,
there would be three parties involved in this system: The
sender is a software provider (e.g. Microsoft), the receiver
is the end user and the manufacturer is a hardware company
(e.g., Intel, TSMC). Software providers are incentivized to use
this framework to hide the IP of their proprietary programs so
as to sell those programs to customers without being pirated.
Hardware manufacturers are incentivized to provide security
in order to retain the software providers as customers (e.g.,
Intel SGX was initially envisioned as a buy-in service).
Potential applications. The focus of this paper is to build
hardware that satisﬁes the deﬁnition of VBB obfuscation.
Thus, our model assumes obfuscation of ‘batch programs’ –
those which take inputs, and compute non-interactively until
a result is produced. Some examples of such programs are
compilers, compression algorithms, machine learning algo-
rithms, etc. In our setting, the program itself should contain
some sensitive IP (to warrant obfuscation). Given the pervasive
nature of batch programs, we see HOP being applicable in
both commercial and military settings. We note that even the
military outsources its fabrication (and therefore its trust) to
external foundries (e.g., global foundries handles runs for the
NSA).
Beyond batch programs, it is possible to support streaming
applications with little change to the model. In particular, while
HOP runs, it can accept streams of public data (e.g., a video
feed) in a similar fashion to Stream Ascend [57]. Importantly,
this has no impact on security, as long as HOP doesn’t change
its observable behavior given the data in the stream and the
program accepts this data at ﬁxed intervals of time.
VIII. CONCLUSION
This paper makes two main contributions. First, we con-
struct an optimized hardware architecture - called HOP - for
running obfuscated RAM programs. We give a matching theo-
retic model for our optimized architecture and prove it secure.
A by-product of our analysis shows the ﬁrst obfuscation for
RAM programs using ‘stateless’ tokens. Second, we present
a complete implementation of our optimized architecture and
evaluate it on real-world programs. The complete design
requires 72% the area of a V7485t Field Programmable Gate
Array (FPGA) chip. Run on a variety of benchmarks, HOP
achieves an average overhead of 8× ∼ 76× relative to an
insecure system. To the best of our knowledge, this effort
represents the ﬁrst implementation of a provably secure VBB
obfuscation scheme in any model under any assumptions.
ACKNOWLEDGMENT
We would like to thank anonymous reviewers for their
insightful feedback. This work is supported in part by NSF
grants CNS-1314857, CNS-1453634, CNS-1518765, CNS-
1514261, an ONR-YIP Award, a Packard Fellowship, a Sloan
Fellowship, a Google Ph.D. Fellowship, Google Faculty Re-
search Awards, a DARPA Brandeis grant, a DARPA Safeware
grant and a VMware Research Award. This work was done in
part while a subset of the authors were visiting the Simons
Institute for the Theory of Computing, supported by the
Simons Foundation and by the DIMACS/Simons Collaboration
in Cryptography through NSF grant CNS-1523467.
REFERENCES
“bzip2 man pages,” http://www.bzip.org/1.0.5/bzip2.txt.
“Open cores,” http://opencores.org/.
[1]
[2]
[3] D. Agrawal, B. Archambeault, J. R. Rao, and P. Rohatgi, “The em
sidechannel (s),” in International Workshop on Cryptographic Hardware
and Embedded Systems. Springer, 2002, pp. 29–45.
[4] B. Barak, O. Goldreich, R. Impagliazzo, S. Rudich, A. Sahai, S. P.
Vadhan, and K. Yang, “On the (im)possibility of obfuscating programs,”
in CRYPTO, 2001.
[5] N. Bitansky, R. Canetti, S. Goldwasser, S. Halevi, Y. T. Kalai, and G. N.
Rothblum, “Program obfuscation with leaky hardware,” in Advances in
Cryptology–ASIACRYPT 2011. Springer, 2011, pp. 722–739.
[6] N. Bitansky, S. Garg, H. Lin, R. Pass, and S. Telang, “Succinct
randomized encodings and their applications,” in Proceedings of the
Forty-Seventh Annual ACM on Symposium on Theory of Computing.
ACM, 2015, pp. 439–448.
[7] A. Bittau, A. Belay, A. Mashtizadeh, D. Mazi`eres, and D. Boneh,
“Hacking blind,” in IEEE S&P, 2014.
[8] D. Boneh, R. A. DeMillo, and R. J. Lipton, “On the importance of
checking cryptographic protocols for faults,” in International Confer-
ence on the Theory and Applications of Cryptographic Techniques,
1997.
[9] Z. Brakerski, C. Gentry, and V. Vaikuntanathan, “(Leveled) Fully
Homomorphic Encryption without Bootstrapping,” in ITCS, 2012.
[10] R. Canetti, “Universally composable security: A new paradigm for
cryptographic protocols,” in FOCS, 2001.
[11] R. Canetti, J. Holmgren, A. Jain, and V. Vaikuntanathan, “Succinct
garbling and indistinguishability obfuscation for RAM programs,” in
Proceedings of the Forty-Seventh Annual ACM on Symposium on Theory
of Computing. ACM, 2015, pp. 429–437.
[12] C. Celio and E. Love, “The sodor processor collection,” http://riscv.org/
download.html#tab sodor.
[13] D. Champagne and R. B. Lee, “Scalable architectural support for trusted
software,” in HPCA, 2010.
[14]
J. H. Cheon, K. Han, C. Lee, H. Ryu, and D. Stehl´e, “Cryptanalysis of
the multilinear map over the integers,” in EUROCRYPT, 2015.
[15] K.-M. Chung, J. Katz, and H.-S. Zhou, “Functional encryption from
(small) hardware tokens,” in ASIACRYPT, 2013.
J. Dean and S. Ghemawat, “Mapreduce: simpliﬁed data processing on
large clusters,” Communications of the ACM, 2008.
[16]
[17] N. D¨ottling, T. Mie, J. M¨uller-Quade, and T. Nilges, “Basing obfusca-
tion on simple tamper-proof hardware assumptions.” IACR Cryptology
ePrint Archive, 2011.
[18] C. W. Fletcher, M. v. Dijk, and S. Devadas, “A secure processor
architecture for encrypted computation on untrusted programs,” in STC,
2012.
[19] C. W. Fletcher, L. Ren, A. Kwon, M. van Dijk, and S. Devadas,
“Freecursive oram:[nearly] free recursion and integrity veriﬁcation for
position-based oblivious ram,” in ASPLOS, 2015.
[20] C. W. Fletcher, L. Ren, A. Kwon, M. Van Dijk, E. Stefanov, D. Ser-
panos, and S. Devadas, “A low-latency, low-area hardware oblivious
ram controller,” in FCCM, 2015.
IEEE, 2015.
[21] S. Garg, “Program obfuscation via multilinear maps,” in Security and
Cryptography for Networks, 2014.
[22] S. Garg, C. Gentry, S. Halevi, M. Raykova, A. Sahai, and B. Waters,
“Candidate indistinguishability obfuscation and functional encryption
for all circuits,” in FOCS, 2013.
[23] C. Gentry, S. Halevi, S. Lu, R. Ostrovsky, M. Raykova, and D. Wichs,
“Garbled ram revisited,” in Annual International Conference on the
Theory and Applications of Cryptographic Techniques, 2014.
[24] C. Gentry, S. Halevi, and N. P. Smart, “Homomorphic evaluation of the
aes circuit,” in Advances in Cryptology–CRYPTO 2012, 2012.
[25] O. Goldreich, “Towards a theory of software protection and simulation
by oblivious rams,” in ACM symposium on Theory of computing
(STOC), 1987.
[26] O. Goldreich and R. Ostrovsky, “Software protection and simulation on
oblivious rams,” J. ACM, 1996.
[27] V. Goyal, Y. Ishai, A. Sahai, R. Venkatesan, and A. Wadia, “Founding
cryptography on tamper-proof hardware tokens,” in TCC, 2010.
[28] D. Grawrock, Dynamics of a Trusted Platform: A Building Block
Approach, 1st ed.
Intel Press, 2009.
[29] S. Hada, “Zero-knowledge and code obfuscation,” in ASIACRYPT 2000,
2000.
[30] K. J¨arvinen, V. Kolesnikov, A.-R. Sadeghi, and T. Schneider, “Garbled
circuits for leakage-resilience: Hardware implementation and evaluation
of one-time programs,” in CHES 2010, 2010.
[32]
[31] M. Kainth, L. Krishnan, C. Narayana, S. G. Virupaksha, and R. Tessier,
“Hardware-assisted code obfuscation for fpga soft microprocessors,” in
Design, Automation & Test in Europe Conference & Exhibition, 2015.
J. Katz, “Universally composable multi-party computation using
tamper-proof hardware,” in Annual International Conference on the
Theory and Applications of Cryptographic Techniques, 2007.
´A. Kiss and T. Schneider, “Valiant’s universal circuit is practical,” in
EUROCRYPT, 2016.
[33]
[34] P. C. Kocher, J. Jaffe, and B. Jun, “Differential power analysis,” in
CRYPTO’99, 1999.
[35] V. Kolesnikov and T. Schneider, “A practical universal circuit construc-
tion and secure evaluation of private functions,” in FCDS, 2008.
[36] V. Koppula, A. B. Lewko, and B. Waters, “Indistinguishability obfus-
cation for turing machines with unbounded memory,” in Proceedings of
the Forty-Seventh Annual ACM on Symposium on Theory of Computing.
ACM, 2015, pp. 419–428.
[37] K. Lewi, A. J. Malozemoff, D. Apon, B. Carmer, A. Foltzer, D. Wagner,
D. W. Archer, D. Boneh, J. Katz, and M. Raykova, “5gen: A framework
for prototyping applications using multilinear maps and matrix branch-
ing programs,” in Proceedings of the 2016 ACM SIGSAC Conference on
Computer and Communications Security. ACM, 2016, pp. 981–992.
[38] D. Lie, C. Thekkath, M. Mitchell, P. Lincoln, D. Boneh, J. Mitchell,
and M. Horowitz, “Architectural support for copy and tamper resistant
software,” ACM SIGPLAN Notices, 2000.
[39] H. Lipmaa, P. Mohassel, and S. Sadeghian, “Valiant’s universal circuit:
14
Improvements, implementation, and applications,” Cryptology ePrint
Archive, Report 2016/017, 2016, http://eprint.iacr.org/2016/017.
[40] C. Liu, A. Harris, M. Maas, M. Hicks, M. Tiwari, and E. Shi,
“Ghostrider: A hardware-software system for memory trace oblivious
computation,” in ASPLOS, 2015.
[41] M. Maas, E. Love, E. Stefanov, M. Tiwari, E. Shi, K. Asanovic, J. Ku-
biatowicz, and D. Song, “Phantom: Practical oblivious computation in
a secure processor,” in CCS, 2013.
[42] F. McKeen, I. Alexandrovich, A. Berenzon, C. V. Rozas, H. Shaﬁ,
V. Shanbhogue, and U. R. Savagaonkar, “Innovative instructions and
software model for isolated execution.” in HASP@ ISCA, 2013.
[43] O. Ohrimenko, M. Costa, C. Fournet, C. Gkantsidis, M. Kohlweiss, and
D. Sharma, “Observing and preventing leakage in mapreduce,” in CCS,
2015.
[44] R. Pass, E. Shi, and F. Tramr, “Formal abstractions for attested execution
secure processors.”
[45] A. Rane, C. Lin, and M. Tiwari, “Raccoon: Closing digital side-channels
through obfuscated execution,” in USENIX Security, 2015.
[46] L. Ren, X. Yu, C. Fletcher, M. van Dijk, and S. Devadas, “Design
space exploration and optimization of path oblivious ram in secure
processors,” in Symposium on Computer Architecture, 2013.
[47] S. Schrittwieser and S. Katzenbeisser, “Code obfuscation against static
and dynamic reverse engineering,” in Information Hiding, 2011.
[48] F. Schuster, M. Costa, C. Fournet, C. Gkantsidis, M. Peinado,
G. Mainar-Ruiz, and M. Russinovich, “Vc3: Trustworthy data analytics
in the cloud using sgx,” in IEEE S&P, 2015.
[49] E. Shi, T.-H. H. Chan, E. Stefanov, and M. Li, “Oblivious ram with
O(log3 N ) worst-case cost,” in ASIACRYPT, 2011.
[50] V. Shoup et al., “Ntl: A library for doing number theory,” 2001.
[51] E. M. Songhori, S. Zeitouni, G. Dessouky, T. Schneider, A.-R. Sadeghi,
and F. Koushanfar, “Garbledcpu: A mips processor for secure compu-
tation in hardware,” in DAC, 2016.
[52] E. Stefanov, M. van Dijk, E. Shi, C. Fletcher, L. Ren, X. Yu, and S. De-
vadas, “Path ORAM – an extremely simple oblivious ram protocol,” in
CCS, 2013.
[53] G. E. Suh, D. Clarke, B. Gassend, M. Van Dijk, and S. Devadas, “Aegis:
architecture for tamper-evident and tamper-resistant processing,” in
Conference on Supercomputing, 2003.
[54] L. Tan, “The worst case execution time tool challenge 2006: The ex-
ternal test,” in Leveraging Applications of Formal Methods, Veriﬁcation
and Validation, 2006. ISoLA 2006., 2006.
[55] L. G. Valiant, “Universal circuits (preliminary report),” in STOC, 1976.
[56] X. S. Wang, S. D. Gordon, A. McIntosh, and J. Katz, “Secure compu-
tation of mips machine code,” ePrint 2015/547, Tech. Rep., 2015.
[57] X. Yu, C. W. Fletcher, L. Ren, M. v. Dijk, and S. Devadas,
“Generalized external interaction with tamper-resistant hardware with
bounded information leakage,” in Proceedings of
the 2013 ACM
Workshop on Cloud Computing Security Workshop, ser. CCSW ’13.
New York, NY, USA: ACM, 2013, pp. 23–34. [Online]. Available:
http://doi.acm.org/10.1145/2517488.2517498
[58] X. Zhuang, T. Zhang, and S. Pande, “Hide: an infrastructure for
efﬁciently protecting information leakage on the address bus,” in ACM
SIGPLAN Notices, 2004.
APPENDIX A
PROOF OF SCHEDULE OVERHEAD
Claim: For any program and input, the setting of N from
Section III-C results in ≤ 50% of processor cycles performing
dummy work. In other words, the schedule incurs ≤ 2× per-
formance overhead relative to the best possible A-M schedule
(which is insecure over the timing channel) and incurs no
dummy work.
Proof: Without loss of generality, we break up a program
into a sequence of instruction epochs, where each epoch
consists of a continuous run of arithmetic instructions followed
by a continuous run of memory instructions. Denote the i-th
epoch as AniM pi. For example, the program
A A A A M A A M M M
has 2 epochs, with n1 = 4, p1 = 1, n2 = 2, p2 = 3.
Without
loss of generality, we align the start of each
epoch with the beginning of an AN M schedule. Given our
choice of N, we examine the number of processor cycles
spent doing dummy operations in each epoch. For the rest
of the analysis, we abbreviate |M| = ORAM latency and
|A| = Arithmetic latency.
Consider the start of epoch i (i.e., the ﬁrst A instruction).
To progress from the start of the epoch to the ﬁrst M
instruction (excluded) in the epoch, we perform |A|∗N∗(cid:98) ni
N (cid:99)+
|A|∗ (ni mod N ) real cycles and |M|∗(cid:98) ni
N (cid:99) +|A|∗ (N − (ni
mod N )) dummy cycles worth of work. To progress from the
ﬁrst M instruction (including) to the end of the epoch, we
perform |M| ∗ pi real cycles and |A| ∗ N ∗ (pi − 1) dummy
cycles worth of work. Note that by our deﬁnitions of epochs,
we have that pi ≥ 1.
ing these two time periods, we spend |M|∗((cid:98) ni
mod N ) real cycles and |M|∗ ((cid:98) ni
mod N )) dummy cycles worth of work.
Also note that |M| = |A|∗N by our choice of N. Combin-
N (cid:99)+pi)+|A|∗(ni
N (cid:99) + pi− 1) +|A|∗ (N − (ni
OBFUSCATION IN THE PUBLIC-KEY SETTING
APPENDIX B
For the sake of simplicity, we describe our construction and
proof in the model where a single sender embeds a symmetric
key into a secure processor and provides this to the receiver
along with the obfuscated program to execute. However, we
note that we can extend our results to reuse the token and allow
multiple senders to obfuscated the program for a receiver. For
example, suppose two senders S1 and S2 would like to both
send encrypted programs to be executed by a receiver R on a
hardware token (provided by a trusted hardware manufacturer).
The hardware would then be initialized with a secret key skenc
of a public-key CCA secure encryption scheme (with public
key pkenc) along with a veriﬁcation key vksig of a signature
scheme (with signing key sksig). The signing key sksig would
be owned by a trusted certiﬁcate authority and would also be
stored in the token. Now, in our construction, we would replace
the symmetric key CCA secure authenticated encryption with
a public key CCA secure encryption, where all ciphertext are
authenticated with a signature scheme. When S1 wishes to
send an obfuscated program P1 to a receiver R, S1 would
pick a signing key/veriﬁcation key pair (skS1 , vkS1 ). S1 will
obtain a signature of vkS1 from the trusted certiﬁcate authority
(denote this signature by σ and note that this signature will
verify under the veriﬁcation key vksig). Now, S1 will encrypt
P1 with pkenc and authenticate all ciphertexts with skS1 and
provide these ciphertexts along with σ to the receiver. The
receiver will feed in encrypted ciphertexts along with σ to
the token. The token, when decrypting ciphertexts, will ﬁrst
check the validity of vkS1 by verifying σ and the signatures
of all the ciphertexts. If all the checks pass, the token will
decrypt the ciphertexts using skenc. When encrypting state to
be sent back to the receiver, the token will encrypt it with
pkenc and sign it with sksig. This will mimic the symmetric
key CCA secure authenticated encryption scheme that we use
in our single sender/receiver scheme.
15