### Chapter 8: Technical Footprinting

#### 8.1 Finding Backlinks to a Specific Domain Name Using Google Advanced Operators
Figure 8-2 illustrates how to use Google's advanced search operators to find backlinks to a specific domain name.

#### 8.2 Identifying the Technologies Used
There are several methods to discover the technologies used by a target organization. Job postings on the organization’s website and other specialized job sites can provide valuable information about the required skills, IT certifications, and past experience with specific products or vendors. This information can help identify the IT infrastructure, operating systems (OS), and other software in use.

**Tip:** If a target organization has multiple branch offices, the skills listed in job posts for a specific branch can indicate the activities taking place there.

To identify the technologies used to build a target website, various online services and tools are available. One of the most popular is BuiltWith (https://builtwith.com). By entering the target domain name, you can view its technology and relationship profiles. The technology profile provides detailed information such as analytics and tracking codes, widgets, website languages, mobile optimization, content delivery networks (CDNs), JavaScript libraries, advertising networks, email services, name server providers, SSL certificates, web server types, encoding, and document information. The relationship profile shows the historical usage of identifiers (e.g., Google AdSense identifiers) shared with other websites, helping to uncover which websites are controlled by the same company or individual (see Figure 8-3).

Another useful tool is Wappalyzer (https://www.wappalyzer.com), which can be installed as an add-on for Firefox or Chrome to investigate the technologies used on any website you visit.

Identifying key technologies—both software and hardware—enables focused research to find vulnerabilities, product-specific defects, and application-specific configuration problems. In the next section, we will demonstrate how to identify a target OS server using an online tool.

**Note:** To find domains sharing the same Google Analytics ID, visit https://dnslytics.com/reverse-analytics.

#### 8.3 Investigating the Relationship Profile
Figure 8-3 shows the relationship profile of Apress.com, generated by BuiltWith, which includes CrazyEgg's tag usage and history.

#### 8.4 Default Credentials and Vulnerability Databases
Many IT devices (routers, managed switches, firewalls, servers, access controls, internet surveillance cameras, and software packages) come preconfigured with default usernames and passwords. If these credentials are not updated, the devices remain vulnerable. The following sites list default credentials for hundreds of IT equipment:

- CIRT (https://cirt.net/passwords)
- Default Password (https://default-password.info)
- Default Password Lookup (www.fortypoundhead.com/tools_dpw.asp)
- Router Passwords (http://routerpasswords.com)
- Open Sez Me! (http://open-sez.me)
- Hashes (https://hashes.org)

To identify zero-day vulnerabilities of any software, remote services, or applications, including client-side exploits, check the following sites:

- Exploit Database (https://www.exploit-db.com)
- Packet Storm (https://packetstormsecurity.com)
- Security Focus (www.securityfocus.com/bid)
- National Vulnerability Database (https://nvd.nist.gov)
- CVE Details (https://www.cvedetails.com)
- CVE (http://cve.mitre.org)
- 0day (http://0day.today)
- Secunia Research (https://secuniaresearch.flexerasoftware.com/community/research)

#### 8.5 Web Scraping Tools
Automated tools, known as web scraping or web data extraction tools, can help collect various types of information from a target website. For example, theHarvester (https://github.com/laramies/theHarvester) gathers subdomain names, email addresses, virtual hosts, open ports, and employee names from public sources like Google, Bing, LinkedIn, Twitter, Yahoo, PGP, and more. TheHarvester is preinstalled on Kali Linux but can be installed on any Linux-based OS with the command `apt-get install theharvester`.

To collect the target organization’s emails, use the following command:
```
theharvester -d springer.com -b all -l 500 -f results.txt
```
- `-d` specifies the domain to search.
- `-b` specifies the data source (e.g., google, bing, linkedin).
- `-l` limits the number of results.
- `-f` saves the results into a file.

Figure 8-4 shows theHarvester scraping email addresses from Springer.com, resolving the domain into its IP address, and discovering related virtual hosts.

Other web scraping tools include:

- **Web Data Extractor (www.webextractor.com)**: Collects URLs, phone and fax numbers, email addresses, and meta tag information.
- **Email Extractor (https://www.email-extractor.io)**: A Chrome add-on that extracts emails from visited web pages.

#### 8.6 Investigating the Company Domain Name
After initial web page exploration, investigating the company domain name is the next step. Various searches can be conducted, starting with WHOIS information.

#### 8.7 Investigating File Metadata
When browsing a target company’s website, you may encounter files like JPEGs, PDFs, and spreadsheets. These should be downloaded and investigated offline to extract metadata. Additional tools for metadata analysis include:

- **Metagoofil (https://code.google.com/archive/p/metagoofil)**: Extracts metadata from public documents.
- **OOMetaExtractor (https://archive.codeplex.com/?p=oometaextractor)**: Extracts metadata from OpenOffice documents.
- **Fingerprinting Organizations with Collected Archives (https://www.elevenpaths.com/labstools/foca/index.html)**: Harvests public files and analyzes their metadata.

#### 8.8 Website Certification Search
To show cryptographic certifications associated with a domain name, use the following services:

- **Censys (https://censys.io)**
- **Certificate Search (https://crt.sh)**

#### 8.9 Website Statistics and Analytics Tools
These tools provide marketing, technical, and historical information about a domain name. Popular tools include:

- **Alexa (https://www.alexa.com/siteinfo)**
- **Moon Search (http://moonsearch.com)**
- **Spy On Web (www.spyonweb.com)**
- **W3bin (https://w3bin.com)**
- **Visual Site Mapper (www.visualsitemapper.com)**
- **Site Liner (www.siteliner.com)**
- **Clear Web Stats (https://www.clearwebstats.com)**
- **Website Outlook (www.websiteoutlook.com)**
- **Informer (http://website.informer.com)**
- **Security Headers (https://securityheaders.io)**

#### 8.10 Website Reputation Checker Tools
These tools check if a specific website is malicious and offer historical information. Popular services include:

- **Threat Miner (https://www.threatminer.org/index.php)**
- **Urlquery (http://urlquery.net)**
- **URLVoid (www.urlvoid.com)**
- **Threat Crowd (https://www.threatcrowd.org)**
- **Reputation Authority (www.reputationauthority.org/index.php)**
- **Sucuri SiteCheck (https://sitecheck.sucuri.net)**
- **Joe Sandbox (https://www.joesandbox.com)**
- **Safe Browsing (https://developers.google.com/safe-browsing/?csw=1)**
- **abuse.ch ZeuS Domain Blocklist (https://zeustracker.abuse.ch/blocklist.php?download=domainblocklist)**
- **Malware Domain Blacklist (http://mirror1.malwaredomains.com/files/domains.txt)**
- **MalwareURL (https://www.malwareurl.com/index.php)**
- **Scumware (https://www.scumware.org)**

**Note:** To see a list of previously hacked websites, visit http://zone-h.org/archive and search for the target domain name.

#### 8.11 Passive Technical Reconnaissance Activities
Passive reconnaissance involves identifying subdomains, IP addresses, DNS footprinting, and WHOIS information.

##### 8.11.1 WHOIS Lookup
A WHOIS lookup reveals who registered the domain, along with contact and technical information. This information is stored in public WHOIS databases managed by ICANN and regional Internet registries. Some domain registrants opt for privacy, making their personal information hidden.

- **ICANN (https://whois.icann.org/en)**
- **AFRINIC (https://www.afrinic.net)**
- **APNIC (https://www.apnic.net)**
- **LACNIC (www.lacnic.net)**

Additional WHOIS information services include:

- **Domain History (www.domainhistory.net)**
- **Whoisology (https://whoisology.com/#advanced)**
- **Robtext (https://www.robtex.com)**
- **Who (https://who.is)**
- **Operative Framework (https://github.com/graniet/operative-framework)**
- **URL Scan (https://urlscan.io)**

Figure 8-5 shows a partial WHOIS report for DarknessGate.com from https://whois.icann.org.

##### 8.11.2 Subdomain Discovery
Subdomains are created under the main domain to organize content. Discovering insecure subdomains can reveal important information about the target company. Popular tools and techniques for subdomain discovery include:

- **Google Search Operator**: Use `site:target.com -inurl:www` to find related subdomains.
- **VirusTotal (https://www.virustotal.com/#/home/search)**: Check for observed subdomains.
- **DNSdumpster (https://dnsdumpster.com)**: Provides domain information, subdomains, DNS servers, and MX records.
- **Dnsmap (https://tools.kali.org/information-gathering/dnsmap)**

Figure 8-6 demonstrates using Google advanced search operators for subdomain discovery, and Figure 8-7 shows subdomain discovery using VirusTotal.