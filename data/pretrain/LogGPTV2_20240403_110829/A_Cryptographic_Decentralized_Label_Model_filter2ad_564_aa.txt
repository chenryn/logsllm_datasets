# A Cryptographic Decentralized Label Model

**Authors:**
- Jeffrey A. Vaughan
- Steve Zdancewic
- University of Pennsylvania

## Abstract
Information-flow security policies are an effective method for specifying confidentiality and integrity in information systems. Previous work on language-based security has often assumed that programs operate in a closed, managed environment, using potentially unsafe constructs like declassification to interface with external communication channels, possibly after encrypting data to maintain confidentiality. This approach is inadequate for systems that need to communicate over untrusted channels or use untrusted persistent storage, as the connection between cryptographic mechanisms and the abstract security labels used in the trusted language environment is ad hoc and unclear.

This paper addresses this problem in three ways:
1. It introduces a simple, security-typed language with a novel mechanism called "packages" that provides an abstract means for creating opaque objects and associating them with security labels. Well-typed programs in this language enforce noninterference.
2. It demonstrates how to implement these packages using public-key cryptography, leveraging a variant of Myers and Liskov’s decentralized label model, which supports a rich label structure where mutually distrusting data owners can specify independent confidentiality and integrity requirements.
3. It shows that this implementation of packages is sound with respect to Dolev-Yao style attackers, meaning such an attacker cannot determine the contents of a package without possessing the appropriate keys, as determined by the security label on the package.

## 1. Introduction
Information-flow security policies are an effective way to specify confidentiality and integrity in information systems. Unlike traditional reference monitors and cryptography, which regulate access to data, mechanisms that enforce information-flow policies control how data (and information derived from the data) propagates throughout the system. Such end-to-end security properties are crucial for applications requiring high degrees of confidentiality (e.g., SELinux [28]) and integrity (e.g., critical embedded systems [9]).

Language-based mechanisms, which rely on static program analysis, are one approach to determining whether a given piece of software adheres to an information-flow policy. The key idea, originating from Denning's work [13, 14] in the 1970s, is to annotate program values with labels drawn from a lattice of security levels and have the compiler verify that the program follows the standard "no read up/no write down" noninterference policy [18, 8]. Following Volpano, Smith, and Irvine [33], these program analyses are typically expressed as a form of type-checking.

The literature in this area has explored various label models, programming language features, mechanisms for handling declassification and other forms of downgrading, and appropriate definitions of security (see the survey by Sabelfeld and Myers [27]). FlowCaml [25, 29] and Jif [11] are two full-fledged programming languages that support information-flow security policies. For example, Jif has been used to implement simple distributed games [5, 35] and a secure email system [20].

Despite these promising results, a significant open question in the design of languages for information-flow security is how to integrate them with other mechanisms such as cryptography and traditional access controls. Understanding the relationship between cryptography and information-flow is particularly important for "open" systems where data must leave the managed environment provided by the language runtime. For instance, if the system needs to send protected data over an untrusted network or write it to persistent storage, encryption and digital signatures are the appropriate means of providing confidentiality and integrity.

Although cryptography is a valuable tool for security engineering, there has been surprisingly little work on developing a coherent theory of how it and information-flow mechanisms can be integrated. The existing work includes KDLM [12], crypto-masked flows [4], sealing calculi [31], cryptographic types [17], and computational security analyses of information-flow with encryption [21, 30]. In this paper, we explore a novel design for incorporating cryptographic operations with language-based information-flow security.

We have three main goals for the programming language presented here:
1. The programming model should provide abstractions suitable for cryptographically enforcing information-flow policies specified via security labels.
2. The design of the new language primitives should free the programmer from manually managing keys and their correspondence to information-flow policy labels.
3. We should prove that, under a reasonable model of cryptography, programs written in the resulting language satisfy the standard noninterference properties expected in this context.

In this paper, we achieve these goals through the following contributions:
- We develop a language, SImp, with primitives for enforcing information-flow security policies, including a restricted form of cryptographic packaging. The novel language constructs are similar to the pack/unpack operations found in languages with existential or dynamic datatypes. Operationally, the use of these packaging constructs requires runtime checks to ensure the security of the program [17].
- We show that packages have a natural implementation in terms of public-key cryptography by defining a translation from language values to cryptographic messages. This translation depends on the structure of the labels used to define security policies. A variant of the decentralized label model [22] provides a pleasant setting for the translation.
- We prove a noninterference result for SImp, including the downgrading implicit in its cryptographic packages. We also demonstrate the soundness of the cryptographic interpretation of packages by showing that a Dolev-Yao attacker [16] cannot determine the contents of a package without possessing the appropriate keys (as determined by the translation of the security label on the package).

The rest of this paper is structured as follows. Section 2 introduces our information flow language and proves noninterference. Section 3 provides a Dolev-Yao system for reasoning about cryptography and a translation from language values to cryptographic messages. Sections 4 and 5 contain discussion and related work, respectively.

## 2. The SImp Language

### 2.1 Background and Example
Like other approaches to language-based information-flow security, in our programming language, locations are annotated with security labels. This paper uses a variant of the decentralized label model (DLM) where labels are lists of security policies with confidentiality and integrity components. These policies refer to principals, characterized by their access to private keys. A policy has the form \( o : r \rightarrow w \), where \( r \) and \( w \) are sets of principals, and \( o \) is a single principal. This means that policy owner \( o \) certifies that any principal in \( r \) can read from the associated location, and any principal in \( w \) can write. Sections 2.2 and 3.1 discuss the label model and private keys, respectively.

Although the literature discusses "the" DLM, there are several subtly different models. When they are handled at all, integrity constraints sometimes correspond to writers of data; other times to trusters. Additionally, DLM presentations typically include an acts-for hierarchy: an explicit and nominal delegation relation. Here, we do not build an explicit acts-for hierarchy as it is not relevant to our setting. Instead, we investigate the orthogonal issues of collusion and cooperation among sets of principals. Section 5.1 further discusses the acts-for hierarchy.

Before examining the formal description of SImp, we present the sample program shown in Figure 1. In this example, we imagine a small client that can read and write data to a database shared by many users. The database implements a finite map signature with no provisions for security. To model this situation, the database is labeled with a single policy: \(\{ \text{db\_admin} : \text{everyone} \rightarrow \text{everyone} \}\). That is, data entered into the database is readable by anyone, and data read from it may have been altered by anyone.

Input and output are performed by reading from and writing to designated memory locations. Lines 14 through 20 declare the locations corresponding to input, and line 23 declares a location corresponding to the terminal. Locations `action` and `position` describe the program's mode of operation—whether to read or write and where. Tagged with security label \(\{ p : \text{everyone} \rightarrow p \}\), their contents are readable by everyone and have only been influenced by one principal, \( p \). The label on `txt` is more restrictive; its contents are only readable by \( p \). That is, `txt` contains a secret. The database is promiscuous; it produces and consumes values that, according to `db_admin`, are world-readable and have no integrity constraints.

The branches of the outer case command store and retrieve data from the database. In the "put" case, the client wishes to enter a secret value `txt` into the database. However, simply calling `store(pos, txt)` would not be secure. (Additionally, the shape of `txt` is a string, while `store` expects a `pkg`—an important detail, but only peripherally related to security.) We can deduce that this call is insecure in two ways. First, the database semantics are insecure; anyone could read `txt` if it were stored directly. Second, the label of `txt` specifies that \( p \) requires that only \( p \) can read, while `store` (line 8) requires arguments readable by anyone. Here, a simple syntactic check of security labels identifies a semantic error; this is the point of static information-flow analysis. The actual invocation of `store` on line 30 satisfies the label checking and avoids the semantic error. It does not leak information because `pack` builds a cryptographic message that encrypts (and signs) `txt`. The typing rules reflect this, allowing the result of a `pack` to be treated as world-readable data.

In the case of a "get," unpacking `reply`—the publicly readable result of `retrieve`—yields either a confidential and trusted string or an error. As we will see, unpacking requires static and dynamic checks that work together to prevent undesired information flows.

### 2.2 Security Lattice Properties
As seen above, variables in SImp programs are annotated with security labels. The language definition is parameterized by the algebraic structure of labels and several basic axioms. This section describes the generic label properties and defines a variant of Myers and Liskov’s decentralized label model (DLM) [22], a concrete instantiation of the structure. In Section 3.2, we examine how to compile SImp values into cryptographic messages; that discussion will assume labels are defined by our DLM.

Labels, denoted \( \ell \), are elements of a non-trivial, bounded lattice with order relation \( \leq \) and join operation \( \sqcup \). Upper bound \( \top \) is the most restrictive label, and \( \bot \) is the least restrictive. Labels have confidentiality and integrity components. A pair of functions, \( C \) and \( I \), allow us to consider separately parts of a label; \( C(\ell) \) returns a label with \( \ell \)'s confidentiality policy and the least restrictive integrity policy. Function \( I \) is the integrity analog. Both functions are idempotent. Formally,

\[
\ell = C(\ell) \sqcup I(\ell)
\]
\[
C(I(\ell)) = \bot
\]
\[
I(C(\ell)) = \bot
\]
\[
C(C(\ell)) = C(\ell)
\]
\[
I(I(\ell)) = I(\ell).
\]

Additionally, we assume \( C \) and \( I \) are monotone.

\[
\ell \leq \ell' \iff C(\ell) \leq C(\ell') \land I(\ell) \leq I(\ell')
\]

The purpose of labels is to classify who can read and who could have written data. We assume there is a fixed set of principals, \( P \), ranged over by \( p \). We also require two monotone predicates that indicate whether a set of principals, \( p \subseteq P \), can read (resp. write) according to a label's confidentiality (integrity) component. Formally, if \( C(\ell) \leq C(\ell') \), then \( p \) reads \( \ell' \) implies \( p \) reads \( \ell \). Integrity is the opposite: if \( I(\ell) \leq I(\ell') \), then \( p \) writes \( \ell \) implies \( p \) writes \( \ell' \). We call a label set and operators over that set a security lattice when the above properties hold.

We instantiate the above with a decentralized label model that omits the acts-for hierarchy [22] and assumes that principals can collude to pool their authority. That is, we intend for \( p \) reads \( \ell \) (resp. \( p \) writes \( \ell \)) to hold when the members of \( p \) can cooperate to read (write) at \( \ell \). Section 5.1 compares our presentation of a DLM with several others, including Myers and Liskov’s original description.

In a DLM, principals typically represent users of a system. We call the set of all principals \( P \), and assume it is finite. We also assume the existence of a canonical total ordering on \( P \); this is not the acts-for hierarchy, but a helpful condition used for defining functions over labels.

Informally, a label consists of several policies in which principals, called owners, make access control statements. Each policy has the form \( o : r \rightarrow w \), and consists of an owner \( o \), a set of readers \( r \), and a set of writers \( w \).