[18] FLOYD, J., AND FOWLER, J. Survey research methods. Survey
Research Methods (4th ed.). SAGE Publications, Inc. Thousand
Oaks, CA: SAGE Publications, Inc (2009).
[19] FORSYTH, D. R. Self-serving bias. In International Encyclope-
dia of the Social Sciences, W. A. Darity, Ed., vol. 7. Macmillan
Reference USA, Detroit, 2008.
[20] GIORGINI, P., MASSACCI, F., MYLOPOULOS, J., AND ZAN-
NONE, N. Modeling security requirements through ownership,
permission and delegation. In Proceedings. 13th IEEE Interna-
tional Conference on Requirements Engineering (2005), RE ’05,
IEEE, pp. 167–176.
[21] GORTNEY, W. E. Department of defense dictionary of military
and associated terms. Tech. rep., Joint Chiefs of Staff, Washing-
ton, United States, 2016.
[22] GROVES, R. M., FOWLER, F. J., COUPER, M. P., LEPKOWSKI,
J. M., SINGER, E., TOURANGEAU, R., ET AL. Survey method-
ology.
[23] GUEST, G., BUNCE, A., AND JOHNSON, L. How many inter-
views are enough? an experiment with data saturation and vari-
ability. Field methods 18, 1 (2006), 59–82.
[24] HALEY, C., LANEY, R., MOFFETT, J., AND NUSEIBEH, B. Se-
curity requirements engineering: A framework for representation
and analysis. IEEE Transactions on Software Engineering 34, 1
(2008), 133–153.
[25] HARDY, G. Beyond continuous monitoring: Threat modeling for
real-time response. SANS Institute (2012).
[26] HEDEKER, D. Multilevel models for ordinal and nominal vari-
In Handbook of multilevel analysis. Springer, 2008,
ables.
pp. 237–274.
[27] HOLBROOK, A. L., GREEN, M. C., AND KROSNICK, J. A.
Telephone versus face-to-face interviewing of national probabil-
ity samples with long questionnaires: Comparisons of respondent
satisﬁcing and social desirability response bias. Public opinion
quarterly 67, 1 (2003), 79–125.
[28] HUTCHINS, E. M., CLOPPERT, M. J., AND AMIN, R. M.
Intelligence-driven computer network defense informed by anal-
ysis of adversary campaigns and intrusion kill chains. Leading
Issues in Information Warfare & Security Research 1, 1 (2011),
80.
[29] INTERNAL REVENUE SERVICE. Publication 1075: Tax Informa-
tion Security Guidelines For Federal, State and Local Agencies,
2016.
[30] KATZ, N., LAZER, D., ARROW, H., AND CONTRACTOR, N.
Network theory and small groups. Small group research 35, 3
(2004), 307–332.
[31] KOLB, A. Y., AND KOLB, D. A. Learning styles and learn-
ing spaces: Enhancing experiential learning in higher education.
Academy of management learning & education 4, 2 (2005), 193–
212.
[32] LABUNETS, K., MASSACCI, F., PACI, F., ET AL. An experi-
mental comparison of two risk-based security methods. In Pro-
ceedings of the 7th ACM/IEEE International Symposium on Em-
pirical Software Engineering and Measurement (2013), ESEM
’13, IEEE, pp. 163–172.
[15] DYKSTRA, J. A., AND ORR, S. R. Acting in the unknown: the
cyneﬁn framework for managing cybersecurity risk in dynamic
decision making. In Proceedings of the 8th International Confer-
ence on Cyber Conﬂict (2016), CyCon US ’16, IEEE, pp. 1–6.
[33] LEGRIS, P., INGHAM, J., AND COLLERETTE, P. Why do peo-
ple use information technology? a critical review of the technol-
ogy acceptance model. Information & management 40, 3 (2003),
191–204.
634    27th USENIX Security Symposium
USENIX Association
[34] LUND, M. S., SOLHAUG, B., AND STØLEN, K. Model-driven
risk analysis: the CORAS approach. Springer Science & Busi-
ness Media, 2010.
[56] SHACKELFORD, S. Exploring the “shared responsibility” of cy-
ber peace: Should cybersecurity be a human right? Kelley School
of Business Research paper (2017), 17–55.
[35] MASSACCI, F., AND PACI, F. How to select a security require-
ments method? a comparative study with students and practition-
ers. Secure IT Systems (2012), 89–104.
[36] MAY, C. J., HAMMERSTEIN, J., MATTSON, J., AND RUSH, K.
Defense in depth: Foundations for secure and resilient it enter-
prises, 2006.
[37] MELLADO, D., FERN ´ANDEZ-MEDINA, E., AND PIATTINI, M.
Applying a security requirements engineering process. Computer
Security–ESORICS 2006 (2006), 192–206.
[38] MICROSOFT CORPORATION. The STRIDE Threat Model. Tech.
rep., Microsoft Corporation, 2005.
[39] MICROSOFT CORPORATION. Microsoft Threat Modeling Tool
2016. Tech. rep., Microsoft Corporation, 2016.
[40] MIYAKE, N. Constructive interaction and the iterative process of
understanding. Cognitive science 10, 2 (1986), 151–177.
[41] MOODY, D. L. The method evaluation model: a theoretical
model for validating information systems design methods. Pro-
ceedings of the 11th European Conference on Information Sys-
tems (2003), 1327–1336.
[42] MOURATIDIS, H., GIORGINI, P., AND MANSON, G. Integrat-
ing security and systems engineering: Towards the modelling of
secure information systems. In Proceedings of the 15th Interna-
tional Conference on Advanced Information Systems Engineering
(2003), CAISE ’03, Springer, pp. 63–78.
[43] MUCKIN, M., AND FITCH, S. C. A threat-driven approach to
cyber security. Lockheed Martin Corporation (2014).
[44] NATIONAL INSTITUTE OF STANDARDS AND TECHNOLOGY.
NIST Cybersecurity Framework, 2014.
[45] NATIONAL INSTITUTE OF STANDARDS AND TECHNOLOGY.
NIST Special Publication 800-53, 2017.
[46] NATIONAL SECURITY AGENCY INFORMATION ASSURANCE
DIRECTORATE. NSA Methodology for Adversary Obstruction,
2015.
[47] NIELSEN, J. Usability metrics, July 2001. Accessed: 2017-09-
01.
[48] NYC DOITT. CityNet, 2017.
[49] NYC DOITT. Cybersecurity Requirements for Vendors & Con-
tractors, 2017.
[50] OPDAHL, A. L., AND SINDRE, G. Experimental comparison
of attack trees and misuse cases for security threat identiﬁcation.
Information and Software Technology 51, 5 (2009), 916–932.
[51] ORNE, M. T. On the social psychology of the psychological
experiment: With particular reference to demand characteristics
and their implications. American psychologist 17, 11 (1962), 776.
[52] SABOTTKE, C., SUCIU, O., AND DUMITRAS, T. Vulnerability
disclosure in the age of social media: Exploiting twitter for pre-
dicting real-world exploits. In Proceedings of the 24th USENIX
Security Symposium (2015), USENIX Security ’15, pp. 1041–
1056.
[53] SALTER, C., SAYDJARI, O. S., SCHNEIER, B., AND WALL-
NER, J. Toward a secure system engineering methodolgy.
In
Proceedings of the 1998 Workshop on New Security Paradigms
(New York, NY, USA, 1998), NSPW ’98, ACM, pp. 2–10.
[54] SCHNEIER, B. Attack trees. Dr. Dobb’??s journal 24, 12 (1999),
21–29.
[55] SCOTT, K. D. Joint planning. Joint Publication 5-0 (2017).
[57] SHOSTACK, A. Threat modeling: Designing for security. John
Wiley & Sons, 2014.
[58] SINDRE, G., AND OPDAHL, A. L. Eliciting security require-
ments with misuse cases. Requirements engineering 10, 1 (2005),
34–44.
[59] STRANGE, J., AND IRON, R. Understanding centers of gravity
and critical vulnerabilities. Department of War Studies, Swedish
National Defence College, 2005.
[60] STRANGE, J., IRON, R., AND ARMY, U. Part 2: The cg-cc-cr-
cv construct: A useful tool to understand and analyze the rela-
tionship between centers of gravity and their critical vulnerabili-
ties. Understanding Centers of Gravity and Critical Vulnerabili-
ties (2004).
[61] STRAUSS, A., CORBIN, J., ET AL. Basics of qualitative re-
search, vol. 15. Newbury Park, CA: Sage, 1990.
[62] TANENBAUM, A. S., AND WETHERALL, D. J. Computer net-
works. Pearson, 2011.
[63] TOURANGEAU, R., AND YAN, T. Sensitive questions in surveys.
Psychological bulletin 133, 5 (2007), 859.
[64] VON CLAUSEWITZ, C., AND GRAHAM, J. J. On war, vol. 1.
London, N. Tr¨ubner & Company, 1873.
[65] WILCOXON, F.
Individual comparisons by ranking methods.
Biometrics bulletin 1, 6 (1945), 80–83.
A CoG examples
We used the following two scenarios during our educa-
tional intervention training to communicate CoG analy-
sis concepts to participants.
A.1 Star Wars walkthrough
The educational intervention instructor guided partic-
ipants through this scenario, explaining the CoG analy-
sis for the Galactic Empire. The Galactic Empire’s de-
sired end state is to provide peace and stability through-
out the galaxy. To do this, their objective is to elimi-
nate rebel forces. The Empire has many assets available
for destroying the rebel scum to include: TIE ﬁghters,
stormtroopers, Darth Vader, and the Death Star. Of these
assets, we know that the most powerful means for de-
stroying planets and eradicating sources of rebellion is
the Death Star; thus, it is the CoG analysis for the Em-
pire. Critical capabilities for the Death Star include the
ability to destroy planets. Critical requirements for this
capability include Kyber crystals, engineers, and the su-
perlaser. A critical vulnerability against the superlaser
is accessible via a thermal exhaust port with an exterior
opening. Threat capabilities include the ability to ﬁre
weapons into the exhaust port and threat requirements
include X-wing ﬁghter aircraft. Given this scenario, an
actionable defense plan for the Death Star would be con-
cealing the thermal port or installing anti-aircraft turrets
near the opening.
USENIX Association
27th USENIX Security Symposium    635
A.2 E-commerce scenario
In the second scenario, groups of participants applied
CoG analysis without instructor assistance. The follow-
ing examples are not exhaustive but include actual re-
sponses from the groups. This scenario was the ﬁrst and
only time participants completed CoG analysis analysis
in a group setting.
We consider a small e-commerce business with the pri-
mary objective of maximizing proﬁt and secondary ob-
jectives of customer satisfaction and website availabil-
ity. We focus on defending assets that maximize our
proﬁts. The e-commerce business relies on a front-end
webserver, a back-end database, redundant servers with
load balancers, software developers, and a banking in-
stitution. Of the previously identiﬁed assets, the back-
end database is the CoG analysis it conducts transactions
with customers (the primary means for accomplishing
our primary objective) and because of its interconnected-
ness with other assets. Critical capabilities for our busi-
ness back-end database include (1) conducting atomic,
consistent, isolated, and durable transactions, (2) per-
mitting responsive queries from the front-end webserver,
and (3) providing security safeguards for inventories and
customer data. Critical requirements for providing secu-
rity safeguards for inventories and customer data would
be (1) encrypted communication between customers, the
front-end webserver, and the database; (2) encrypted sen-
sitive data within the database; and (3) compliance with
regulatory guidelines for business transactions. Exam-
ples of critical vulnerabilities would be continued use
of software without periodically checking for updates
and patching, such as continued use of OpenSSL 1.0.1
which is vulnerable to Heartbleed [52]. Threat capabil-
ities against a vulnerable version of OpenSSL include
conducting reconnaissance and network scans of vulner-
able systems. Threat requirements include a valid ex-
ploit and payload against OpenSSL. A simple actionable
defense plan for our running example includes (1) up-
grading OpenSSL to a version that is patched against
Heartbleed and (2) validating system performance post-
upgrade.
A.3 Participant P17 example
Understand the end state and objective. Participant
P17 is a security analyst who works within the NYC Se-
curity Operations Center (SOC). The SOC’s defensive
end state is maintaining an environment that is resilient
and responsive to known and unknown threats. Based
on P17’s work role in NYC3, his personal objective is
to defend workstations and respond to threats against the
NYC3 environment.
Identify assets. P17 relies on network trafﬁc inspec-
tors, endpoint detection and response (EDR) solutions,
and log aggregators to accomplish his objective. EDRs
are tools for investigating suspicious activities through-
out networks, hosts, and other endpoints [7].
Identify the CoG. Of the previously identiﬁed P17 as-
sets, the EDR is the CoG analysis because of its inher-
ent ability to thoroughly protect systems across the en-
terprise, using input from network trafﬁc inspectors and
feeding log aggregators.
Identify critical capabilities (CC). P17’s critical ca-
pabilities for EDR include blocking intrusion attempts,
sending alerts, conducting queries, and quarantining in-
fected systems.
Identify critical requirements (CR). CRs for P17 to
block intrusion attempts include possessing updated in-
dicators of compromise (IOCs) (i.e., threat signatures)
and having the EDR agent installed on workstations.
Identify critical vulnerabilities (CV). P17 examples of
critical vulnerabilities would be corrupted IOCs or work-
station operating systems that are incompatible with a
particular EDR application.
Enumerate threat capabilities (TC). With respect to
our running example, representative TCs against cor-
rupted updates include the ability to tamper with or man-
in-the-middle IOC updates.
Enumerate threat requirements (TR). For P17, TRs
include physical access or remote access to an update
mechanism.
Develop an actionable defense plan (ADP). One miti-
gation strategy in P17’s ADP veriﬁes the integrity of up-
dates from vendors before applying them to the EDR.
B Survey instruments
Full versions of
the pre-intervention survey, post-
intervention survey, and follow-up survey are viewable at
ter.ps/nycsurvey1, ter.ps/nycsurvey2, and ter.
ps/nycsurvey3 respectively.
C NYC leadership panel questions
We asked our panel of NYC3 leaders to answer the fol-
lowing questions for each participants’ post-training sur-
vey results.
1. How likely is the identiﬁed asset the critical enabler
for the participant’s responsibilities? Please use a scale
from 0 to 5, with 0 being “extremely unlikely” and 5
being “extremely likely”
2. How likely would the identiﬁed vulnerabilities
stop the participant from fulﬁlling their responsibilities?
Please use a scale from 0 to 5, with 0 being “extremely
unlikely” and 5 being “extremely likely”
3. How likely would the identiﬁed threats exploit the
vulnerabilities and prevent mission fulﬁllment? Please
use a scale from 0 to 5, with 0 being “extremely unlikely”
and 5 being “extremely likely”
636    27th USENIX Security Symposium
USENIX Association
4. How likely would the plan of action mitigate threats
from exploiting the critical vulnerabilities? Please use a
scale from 0 to 5, with 0 being “extremely unlikely” and
5 being “extremely likely”
5. Is the proposed defense plan sufﬁciently detailed to
implement? Please respond with yes, no, or unsure.
D Visualizing Center of Gravity
in Figure 7, P18 began by writing his objective to protect
networks. P18 then mapped how ﬁrewalls, EDRs, deep-
packet inspection tools, and other defensive techniques
support this objective. The commonality among all of
these tools is that the defender uses cues from alerts to
respond to incidents; thus, alerts are P18’s CoG.
E CoG Identiﬁcation Accuracy Regression
Figure 7: Depiction of P18 visualizing his CoG analysis.
Figure 6: Depiction of CoG analysis tabular method.
Each participant received a printed version of the
worksheet shown in Figure 6 to help guide them through
CoG analysis. Numbers indicate the order in which par-
ticipants completed the form, as described in Section 2.2.
Additionally, we provided participants with a digital ver-
sion of this worksheet during all online surveys. A
more detailed version of the worksheet is available at:
https://goo.gl/icVMLX.
Some participants opted to use a whiteboard to visu-
ally depict their thought processes and building hetero-
geneous, relational linkages between nodes. As shown
Variable Value
IT Exp.
0-5 yrs
6-10 yrs
11-15 yrs
16-20 yrs
21-25 yrs
26+ yrs
Some College
Associates
Bachelors
Graduate
Edu.
CI
–
–
[0, 11.36]
[0.26, 55.28]
[0.04, 12.16]
[0.01, 20.26]
Odds
Ratio
p-value
–
–
0.17
0.408
3.82
0.325
0.74
0.83
0.39
0.643
0.26
0.626
–
–
3.02
0.634
3.51
0.352
4.64
0.327
– Base case (OR=1, by deﬁnition)
[0.03, 289.4]
[0.25, 49.43]
[0.21, 100.14]
[0, 60.44]
*Signiﬁcant effect
Table 2: Summary of regression over participants’ accuracy
at identifying centers of gravity with respect to their years of
experience and education.
USENIX Association
27th USENIX Security Symposium    637