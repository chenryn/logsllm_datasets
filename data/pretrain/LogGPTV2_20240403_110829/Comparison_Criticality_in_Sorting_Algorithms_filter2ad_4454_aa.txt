title:Comparison Criticality in Sorting Algorithms
author:Thomas B. Jones and
David H. Ackley
2014 44th Annual IEEE/IFIP International Conference on Dependable Systems and Networks
Comparison Criticality in Sorting Algorithms
Thomas B. Jones
Dept. of Computer Science
The University of New Mexico
Albuquerque, NM 87131
David H. Ackley
Dept. of Computer Science
The University of New Mexico
Albuquerque, NM 87131
Abstract—Fault tolerance techniques often presume that
the end-user computation must complete ﬂawlessly. Though
such strict correctness is natural and easy to explain, it’s
increasingly unaffordable for extreme-scale computations,
and blind to possible preferences among errors, should
they prove inevitable. In a case study on traditional sorting
algorithms, we present explorations of a criticality measure
deﬁned over expected fault damage rather than probability
of correctness. We discover novel ‘error structure’ in even
the most familiar algorithms, and observe that different
plausible error measures can qualitatively alter criticality
relationships, suggesting the importance of explicit error
measures and criticality in the wise deployment of the
limited spare resources likely to be available in future
extreme-scale computers.
Keywords. Fault-intolerance, fault tolerance, criticality,
sorting algorithms, robust-ﬁrst computing
I. BEYOND STRICT CORRECTNESS
A computation is often envisioned as an abstract math-
ematical function, faultlessly mapping provided inputs
to desired outputs. Of course, a real computation is
performed by some necessarily fallible physical device
or devices—a process that may or may not yield the
intended outputs, raising the question of what should
be considered acceptable. The strict ‘all-or-nothing’ ap-
proach to correctness and error, for example, views any
fault-induced alteration of the input-output mapping as
a total failure of the computation. Strict correctness is
simple and seems honorable—but it also implies that
all errors are equally bad, no matter how harmless or
catastrophic.
Though such puritanical
rigidity can be satisﬁed
for small programs, the probability of perfection for
large computations declines precipitously [1]. Extreme-
scale users, understandably reluctant to discard resource-
intensive computational results lightly, will increasingly
choose to judge some errors worse than others, and thus
abandon—if only informally and implicitly—the strict
boolean view of correctness. We argue it is better to do
that explicitly—and sooner rather than later—to under-
stand better the trade-offs and potentials of graduated
correctness or error measures that offer ‘partial credit’,
making distinctions ﬁner than just right and wrong.
A. Criticality
In this paper we deﬁne criticality, a method of com-
paring program behavior when speciﬁc faults do or do
not occur, with respect to some given error measure.
Expanding on a previous demonstration [2], we explore
the criticality of comparison operations in traditional
pairwise sorting algorithms. Across four strategies for
scoring sorting error, we observe both expected and
unexpected interactions among the algorithms, their ef-
ﬁciencies, and their behaviors under faults.
The rest of this section considers related work, fo-
cusing on fault tolerance as well as measures of the
‘sortedness’ or (conversely) disorder of a list, which we
re-purpose as error measures for fallible sorting algo-
rithms. Then Section II explains the criticality method,
and Section III presents case study results, illustrating
how criticality offers insights into algorithmic behavior
in realms beyond strict correctness. Finally, Section IV
brieﬂy discusses future work and offers conclusions.
B. Fault Tolerance
Multifaceted research and development on the relia-
bility and dependability of computing systems has been
ongoing for over four decades [3]. One main branch of
that work begins, conceptually, with a fault-intolerant
computation [4]—designed to terminate immediately on
any uncorrected fault—and then strives to preserve and
protect that fragile core using fault tolerance techniques
based in hardware, such as [5]–[8], or in software, such
as [9]–[12].
A related thrust emphasizes degradable performance
and performability [13], evaluating system capability and
reliability together to support graceful system degra-
dation. By considering degrees of performance, per-
formability moves distinctly beyond all-or-none systemic
perfection, but it still presumes strict correctness for
each subtask or component. For example, a degradable
performance measure might involve variable job comple-
tion delays or changes in link failure probabilities [14],
[15]—while still demanding strict correctness of each
job computed and messages conveyed over each link. A
performability framework could be extended to handle
978-1-4799-2233-8/14 $31.00 © 2014 IEEE
DOI 10.1109/DSN.2014.74
726
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 08:20:19 UTC from IEEE Xplore.  Restrictions apply. 
graduated error measures within individual work com-
ponents, by adding some suitable error measure, but we
have yet to ﬁnd such efforts in the literature.
There is some research, however, that envisions faults
altering the function computed, and requiring evalua-
tion at that level. For example, the selective reliability
approach, discussed by [16], develops error bounds on
computations that are divided into higher and lower
reliability sections. The present work in some ways
complements that approach, seeking to identify compu-
tational steps most likely to need high reliability. Rather
than hardware bit-ﬂip faults, our case study model con-
siders faults at the algorithmic level, in the comparison
operations performed during sorting.
As another example, approximate design [17] aims
to increase energy efﬁciency by running chips at volt-
ages that allow transient errors. An approach called
Application Resilience Characterization (ARC) [18],
based on dynamic binary instrumentation [19], sup-
ports approximate design by helping programmers un-
derstand how their applications may function in fault-
prone environments. Like selective reliability and our
criticality method, ARC also reaches beyond the “fault-
intolerant core” framework. A difference is we have
applied criticality to classical deterministic algorithms,
while ARC has been predominantly applied to function
approximations—such as machine learning algorithms—
for which perfect correctness is rarely the norm. Another
difference is that criticality quantiﬁes the impact of faults
in individual operations—however they are deﬁned—
while ARC categorizes inner loop lines of code qual-
itatively as resilient or sensitive.
Interestingly, [20] develops robust ﬂoating point itera-
tions for several traditionally exact algorithms, including
sorting. They work within a fault-intolerant strict cor-
rectness error model, and demonstrate sorting small lists
perfectly even with as many as half the ﬂoating point
operations failing.
C. Measuring Sortedness
In contrast with that work, our interest is in better
understanding tradeoffs and algorithmic behaviors when
the end user may be willing to accept less than strictly
correct results. To investigate sorting as an example,
we must confront the question of what “sort of sorted”
might mean. Fortunately, sorting is an extremely well-
studied topic, and researchers have deﬁned a variety of
sortedness measures— [21] is one survey—that quantify
the notion of ‘partially correct sorting’. These mea-
sures have traditionally been used to measure a list’s
‘presortedness’—its degree of disorder before sorting—
but they are also usable as measures of output quality of
a potentially fallible sorting algorithm.
Existing sortedness measures include inversions er-
ror—the number of items immediately preceding a
smaller item, and max displacement—the maximum
distance any item must be moved to reach its correct
position. In this paper, we explore those measures, as
well as all-or-none strict correctness, and a measure
called positional error discussed in the next section.
II. METHODOLOGY
Arbitrary faults can have arbitrary effects on the
execution of a program, and in the general case little
can be said. For this case study:
• We consider only sorting programs based on pair-
wise comparisons. The program input is a random
permutation of the numbers 0..51, modeling a shuf-
ﬂed deck of cards.
• We presume the existence of an error measure that
maps any permutation of the input data into a scalar
value from 0.0 meaning “perfectly sorted” to 1.0
meaning “maximally unsorted.”
• We consider only faults in the pair-wise sorting
comparisons. Such faults ﬁt naturally into our
adopted sortedness measures, but of course they
are only one of many possibilities. In particular, we
presume the data items are never corrupted.
• We collapse a fault’s impact on a given comparison
down to a scalar called the “criticality” of that fault
at that comparison, by averaging across possible
inputs and other possible faults.
The rest of this section provides details.
A. Comparison Criticality Deﬁned
Intuitively, the goal of the criticality method is to
isolate the additional program error due to some speciﬁc
fault on some speciﬁc computational step. The impact
of any speciﬁc fault depends on three factors, which we
call the ‘fault mode’, the ‘error measure’, and the ‘fault
pattern’.
The fault mode determines how the computational
step acts during a particular type of fault. Speciﬁcally,
when comparisons fail in our case study, the result is
as if the comparison was performed backwards. If the
operation Compare(3, 4) faulted it would return >, as
if the performed operation had been Compare(4, 3).
The error measure speciﬁes how badly any given com-
putational result deviates from its correct outcome. In
this study we tested four different sorting error measures.
The ﬁrst error measure, strict correctness, is 0 if the
output is perfectly sorted and 1 otherwise. Deﬁnitions for
the other three error measures—normalized inversions
error [21], normalized max displacement [21], and nor-
malized positional error [2]—appear below in equations
1, 2, and 3, respectively.
727
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 08:20:19 UTC from IEEE Xplore.  Restrictions apply. 
In those equations L(i) is the position of item i in
the output list L, while L[i] is the inverse operation:
The value of the ith item in list L. Since we sort lists
of distinct numbers from 0 to N − 1 the ith item in
to i. Note that each
a correctly sorted list
error measure is normalized to [0, 1] by dividing by the
maximum possible value of that error measure.
is equal
(cid:2)N−2
i=0
L[i]−L[i+1]
|L[i]−L[i+1]| + 1
2N − 2
Inv(L) =
MaxDis(L) =
PosErr(L) =
maxN−1
i=0 |i − L(i)|
N − 1
(cid:2)N−1
i=0 |i − L(i)|
MaxPosErr(N )
(1)
(2)
(3)
The normalization factor MaxPosErr(N )—the maxi-
mum positional error for an input list of size N—is equal
to the positional error when a list is reverse sorted:
MaxPosErr(N ) =
N−1(cid:3)
i=0
(cid:4)(cid:5)
|N − (2i) − 1|
(cid:6)2(cid:7)
N
2
(4)
= 2
Finally, the fault pattern speciﬁes when and where
faults occur during the computation. In general the fault
pattern may require a matrix to represent computational
steps in space and time, but in this case, since the tested
sorting algorithms are sequential, a single bit vector
sufﬁces, indexed by the number of comparisons so far
executed 1.
Given a fault, a fault mode, a fault pattern, and a set of
program inputs, the output of the program is completely
determined, and its quality can be assessed by the error
measure. The criticality of a fault, then, is simply the
error measure value when the fault occurs minus its
value when the fault
is absent. For extremely small
computations it is possible to calculate a fault’s criticality
exactly, but more typically the combinatorics make direct
calculation intractable. This study uses Monte Carlo
sampling to estimate the error measure values with and
without the fault, and the difference of those estimates
are reported in the next section.
The criticality for a failure at each comparison index
was obtained by taking a sample of 1000 fault pattern-
input pairs for each comparison in the algorithm. Inputs
were randomly generated so that each list item had a
uniform probability of occurring in any location in the
1In this paper comparison index c refers to the cth comparison
executed by the algorithm
728
list. Fault-patterns were sampled from a binomial distri-
bution set to produce true bits at rates of 0%, 10%, and
20% so that comparisons not under consideration would
fail at a consistent i.i.d. background failure rate2. The
average output error was measured for each of these fault
pattern-input pairs—once with the comparison under
consideration forced to fail and once with it succeeding.
This gave us two average conditional error measures
whose difference was then taken as the comparison’s
criticality. See the top graph in ﬁgure 2 for an example
of how this was done.
III. RESULTS AND DISCUSSION
We tested quick sort, merge sort, and bubble sort,
using permutations of the N = 52 numbers [0, 1, ..., 51]
as input. For each algorithm, we estimated comparison
criticality for each of the N lgN or N 2 comparisons
executed with respect to the four error measures pre-
sented in Section II-A, at background failure rates of 0%,
10%, and 20%. In this section we brieﬂy touch on a few
expected and unexpected phenomena we have observed.
A. Strict Correctness Hides Most Criticality Structure
To get a feel for criticality in general—and to see some
of the liabilities of all-or-none correctness—Figure 1
shows estimated criticalities under the strict correctness
error measure. While the ﬁgure does make clear that
quick and merge sorts perform many fewer comparisons
than bubble sort, relatively little other structure is re-
vealed. Despite averaging over random input permuta-
tions, the strict correctness criticality of each comparison
is usually either 1 or 0: Any given comparison is
either maximally critical or not at all critical. Given
0% background failures (red curve), for example, there
will only be a single fault. For bubble sort, a failure is
critical if that fault is in any of the last N comparisons
(seen at about comparison 2600), but otherwise it’s
harmless. By contrast, with merge and quick sorts nearly
every comparison is critical—if any comparison fails, the
output will not be strictly correct. The last comparisons
for quick and merge sorts show intermediate criticalities
because, depending on the speciﬁc input permutation
tested, the algorithm will sometimes ﬁnish before that
comparison is reached, so a failure at that comparison
index is sometimes harmless.
Given strict correctness,
if the background failure
rate is appreciably non-zero (e.g., 20%, blue curve) all
comparisons became non-critical in all three algorithms:
Since the output will essentially never be strictly correct,
the occurrence or absence of any one fault makes no
difference.
2Note that as we use it here a background failure rate of 0% means
there are no failures other than the one failure being induced in the
comparison under consideration.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 08:20:19 UTC from IEEE Xplore.  Restrictions apply. 
Fig. 1. Extremal values dominate in a plot of strict correctness
criticality (‘Boolean criticality’; y axis) vs. the comparisons exe-
cuted during a sort (‘Comparison index’; x axis): Most faults are
either maximally critical or not at all. See text for details.
Strict Correctness Criticality For Merge Sort, 
            Quick Sort and Bubble Sort
1
Merge Sort
Background Failure Rate = 0%
Background Failure Rate = 10%
Background Failure Rate = 20%
1000
1500
2000
2500
3000
500
Quick Sort
Background Failure Rate = 0%
Background Failure Rate = 10%
Background Failure Rate = 20%
500
1000
1500
2000
2500
3000
Bubble Sort
Background Failure Rate = 0%
Background Failure Rate = 10%
Background Failure Rate = 20%
y
t
i
l
a
c
i
t
i
r
C
s
s
e
n
t
c
e
r
r
o
C
t
c
i
r
t
S
0.8
0.6
0.4
0.2
0
1
0
0.8
0.6
0.4
0.2
0
1
0
0.8
0.6
0.4
0.2
0
0
500
1000
Comparison Index
1500
2000
2500
3000
B. Graduated Criticality Reveals Algorithmic Structure
As a second example, Figure 2 shows average condi-
tional positional error and criticality for the merge sort
algorithm. The criticality of a fault at a given comparison
index—illustrated in the middle graph—is simply equal
to the difference between the top and bottom lines in
the ﬁrst graph of Figure 2—the estimated error when
the fault does occur less that when it doesn’t.
We note two striking aspects in the middle graph in
Figure 2. First, the positional error measure reveals a
fractal criticality structure for the merge sort algorithm.
In retrospect, at least, this makes sense given the depth-
ﬁrst recursion used in this merge sort implementation.
Comparisons at the deepest recursive levels—when two
items are merged into a length 2 sublist—are also the
most critical comparisons; the deeper “criticality valleys”
reﬂect the larger merges.
Second,
that recursive criticality structure is strik-
ingly persistent across background fault rates. Even at
a background failure rate of 20% we can still see four
distinct ‘humps’ in merge sort’s criticality results. This
implies that criticality structure is robust when the right
algorithm and error measure are used. Note that the
criticality falls off at larger background failure rates since
criticality measures additional error due to a fault and
at higher background failure rates so much damage has
already been done to the output that it becomes difﬁcult
for faults to do even more damage.
Next, when comparing the middle graph of ﬁgure 2
Fig. 2. The average conditional positional error curves (top graph),
corresponding to the estimated error with and without the fault
at the given comparison index, and the positional error criticality
(middle graph), both based on a 10% background error rate. Note
that the purple and blue boxes are error bars. Both positional error
criticality (middle graph) and max displacement error criticality
(bottom graph) reveal the fractal structure of the recursive merge
sort algorithm. See text for details.
ACPE and Criticality By Comparison 
            Index In Merge Sort 
Comparison Without Fault
Comparison With Fault
Background Failure Rate = 0%
Background Failure Rate = 10%
Background Failure Rate = 20%
Background Failure Rate = 0%
Background Failure Rate = 10%
Background Failure Rate = 20%
0.25
0.245
0.24
0.235
0.23
0.225
0.22
0.04
0.035
0.03
0.025
0.02
0.015
0.01
0.005
0