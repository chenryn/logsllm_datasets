1000
100
10
1
0
1e+06
1e+05
10000
1000
100
10
1
0
Cisco: packet length > 1500
Cisco: packet length  1500
Foundry: packet length  1500 540000 2.252 5.484 18.835 281.096
Foundry ≤ 1500 103073 4.364 3.338 31.233 1537.800
Foundry > 1500 538087 4.996 3.815 31.948 1492.500
average density of points in these bands, Fig.9 shows a histogram of residual delay ξ, i.e.
the delay less the lower bound of delay shown in Table 2 for sizes below and above 1500
bytes (partial Radon transform [30]). Note that this summary histogram suggests (but
does not prove) the stationarity of ξ with respect to packet size. While this stationarity is
typically assumed, our preliminary results show that it at best only approximately holds.
A common assumption in network research is that an idle router processes packets
with minimum possible delay [31]. Our experimental setup guarantees that no cross-
trafﬁc is present and that routers process probes one at a time. Table 3 presents statistics
(average, 95%, 99% and maximum for the whole datasets without groupings by inter-
probe gap) for the residual delay ξ, i.e. ICMP generation time in excess of linear lower
bound ax + b (where Table 2 shows the slope a and intercept b). We can summarize the
data as follows: Cisco and Foundry gigE interfaces process TimeExceeded with no more
that 6 µs of extra delay (over the size-dependent lower bound) in 95% of cases; however,
for 1% of packets the extra delay is between 20 and 300 µs on the Cisco and 30–1500
µs on the Foundry. Despite piecewise linearity of the lower bound, the statistics of ξ are
close to each other for packets with sizes under and over 1500 bytes.
5 Discussion, Conclusions, Future Work
We demonstrated that a linear model of ICMP delay is an approximation (like Newtonian
mechanics) that breaks down for packet sizes over 1500 bytes. That so many measure-
ment techniques rely on this assumption is a pressing issue as providers like Abilene,
Geant, Switch are already supporting 9000-byte transparent paths, and the global Inter-
net transition toward these larger packet sizes is only a matter of time. With a 1500-byte
ICMP delay rate discontinuity at all three routers6, and with packet forwarding (as op-
posed to ICMP message generation delay) having a similar break in linearity at 1500
bytes for at least one router (as our work in progress shows), we can safely say that there
is commonly disparate treatment of packets under versus over 1500 bytes. Designers of
bandwidth estimation and other measurement tools [12] must be aware of this reality.
We ﬁnd that for all packet sizes (under and over 1500 bytes):
– delays above the minimum are not necessarily due to queueing. For example we
observed that Juniper delays some closely spaced traceroute packets by 9–10 ms
6 For Juniper, the delay rate discontinuity appears for EchoReply and PortUnreachable but not
for TimeExceeded, for which there is no global rate change at 1500 bytes.
Spectroscopy of Traceroute Delays
289
(Fig.4). However, our measurements of Cisco and Foundry’s gigE interfaces (Table
3) show that for most (95%) probes the extra delay is within a few microseconds,
and it is within 300 µs for Cisco (and 1.5 ms for Foundry) over the whole sample,
which is negligible for many applications.
– buffer carving [32] can lead to “non-physical” size-delay dependence which can
appear faster than link rate or decrease with packet size. Such buffering can also
make loss rates size-independent [33].
The negative slope for the Foundry data in Fig. 8 could possibly be caused by the
router zeroing out the rest of a 1500 byte buffer after a smaller packet arrives, when this
operation is slower than the link’s line rate. We emphasize that this is only speculation,
and have not investigated this issue further.
Surprisingly, we found that the ICMP rate can differ by two orders of magnitude up
or down from the link rate, depending on router and ICMP type. This ambiguity suggests
that capacity estimates by ICMP-based tools [7] [34] [35] may need to make heavy use
of router and even interface ﬁngerprinting, rather than just ﬁltering and ﬁtting as if ‘all
RTT data are created equal’.
We found that Juniper’s TimeExceeded processing is based on 64-byte cells (Fig.3a).
We plan to investigate whether the 48-byte cell7 granularity of the Cisco documented in
[32] is present in our data.
Our analysis shows that ICMP delay can depend on packet size and header ﬁelds in
various non-intuitive ways, including:
– different growth rates under and over 1500 bytes (piecewise linearity, Fig.7,8)
– jumps or drops (discontinuity, Fig.3)
– stepwise growth, e.g. each 64 bytes (Fig.3)
– negative (decreasing) slope with respect to packet size (Fig. 4, 8, Table 2)
– internal tasks can postpone packet scheduling by ﬁxed delays (clustering in distinct
“bands”) on an absolutely empty device (Fig. 8, 9)
– warming up caches can cause signiﬁcant (20-30 µs) extra latency for widely spaced
probes, e.g., an interprobe gap of seconds (Fig. 6, 5, 7, 8)
Table 4 summarizes our main results and lists three cases of linearity of message
generation delay with respect to packet size (fully linear, linear with a break, stepwise
linear with jumps) observed for the three router types studied. In contrast with preva-
lent assumptions used by some rate estimation tools, none of our studied routers has
a TimeExceeded generation rate equal to the line rate of the inbound link for packets
under 1500 bytes. One router has an ICMP rate that is 20 times slower than its line rate
(the ratio of generation rate to line rate is 0.05, Table 4). Other routers use optimizations
that create an illusion of a faster ICMP rate at the expense of increasing minimal ICMP
delay. These properties can facilitate remote device/link ﬁngerprinting. Taken together,
our results indicate surprisingly different attitudes of router vendors (from restrictive
to receptive to acceptive) with regard to ICMP Time Exceeded messages. Our work in
progress suggests that many of these attitudes apply to other ICMP messages too.
7 “The Fabric Interface ASIC is set up to segment the packet into 48-byte cells.” [32].
290
A. Broido, Y. Hyun, and k. claffy
Areas for further investigation include conﬁrming details on the phenomena men-
tioned above, as well as forwarding delays, payload dependent delays, cross-trafﬁc ef-
fects, rate estimates based on optimization technique of [30], and independence tests.
Table 4. Observed behavior of routers responding with ICMP TimeExceeded messages
Property
Message generation linearity
Min.latency, all packets ≥ 64B
Generation rate/Line rate, ≤ 1500B
ICMP non-generation rate
Acknowledgements
Juniper OC48 Cisco OC48 Cisco GigE Foundry GigE
steps w.jumps
linear
19.4 µs
piecewise
19.4 µs
128 µs
0.05
2%
1.37
0%
3.1
0%
piecewise
29.2 µs
negative
0.4%
DanAndersen, Brendan White, Grant Duvall, Margaret Murray, and Kevin Walsh created
the lab used in this study. Ken Keys helped with the Coral software.Yoshi Kohno provided
the linear programming code. Thanks to the PAM reviewers for their comments, all of
which we incorporated in the text. Thanks also to Allen Porter, Dave Berlin, Niheer
Patel, Xin Cai, Andrey Shapiro, and Tin Tran for their useful feedback on this report.
References
1. Pasztor, A., Veitch, D.: The packet size dependence of packet pair like methods. In: IWQoS.
(2002)
2. Jain, M., Dovrolis, C.: End-to-end available bandwidth: measurement methodology, dynam-
ics, and relation with TCP throughput. In: Sigcomm. (2002)
3. Katti, S., Katabi, D., Blake, C., Kohler, E., Strauss, J.: Multiq:Automated detection of multiple
bottlenecks along a path. In: IMC. (2004)
4. Spring, N., Mahajan, R., Wetherall, D.: Measuring ISP topologies with Rocketfuel.
In:
Sigcomm. (2002)
5. Spring, N., Wetherall, D., Anderson, T.: Reverse engineering the Internet. In: HotNets. (2003)
6. Mahajan, R., Spring, N., Wetherall, D., Anderson, T.: User-level Internet path diagnosis. In:
SOSP. (2003)
7. Jacobson, V.:
pathchar - a tool
to infer characteristics of Internet paths (1997)
ftp.ee.lbl.gov/pathchar.
8. Broido, A., claffy, k.: Internet Topology: connectivity of IP graphs. In: SPIE, vol.4526. (2001)
9. Hohn, N., Veitch, D., Papagiannaki, K., Diot, C.: Bridging router performance and queueing
theory. In: Sigmetrics. (2004)
10. Bovy, C.J., Mertodimedjo, H.T., Hooghiemstra, G., Uijtervaal, H., van Mieghem, P.: Analysis
of end-to-end delay measurements in Internet. In: PAM. (2002)
11. Prasad, R.S., Murray, M., Dovrolis, C., Claffy, K.: Bandwidth estimation: metrics, measure-
ments, techniques and tools. In: IEEE Network. (2004)
12. Sriram, A., Murray, M., Hyun, Y., Brownlee, N., Broido, A., Fomenkov, M., Claffy, k.: Com-
parison of public end-to-end bandwidth estimation tools on high-speed links. In: PAM. (2005)
13. Papagiannaki, K., Moon, S., Fraleigh, C., Thiran, P., Tobagi, F., Diot, C.: Analysis of measured
single-hop delay from an operational network. In: Infocom. (2002)
Spectroscopy of Traceroute Delays
291
14. Choi, B.Y., Moon, S., Zhang, Z.L., Papagiannaki, K., Diot, C.: Analysis of point-to-point
packet delay in an operational network. In: Infocom. (2004)
15. Fraleigh, C., Tobagi, F., Diot, C.: Provisioning IP backbone networks to support latency
sensitive trafﬁc. In: Infocom. (2003)
16. Newman, D., Chagnot, G., Perser, J.: The internet core routing test: Complete results (2001)
www.lightreading.com/document.asp?doc id=6411.
17. Govindan, R., Paxson, V.: Estimating router ICMP generation delays. In: PAM. (2002)
18. Anagnostakis, K., Greenwald, M., Ryger, R.: cing: Measuring network-internal delays. In:
Infocom. (2003)
19. Akela, A., Seshan, S., Shaikh, A.: An empirical evaluation of wide-area internet bottlenecks.
In: IMC. (2003)
20. Donnelly, S.: High precision timing in passive measurements of data networks (2002) Ph.D.
thesis, University of Waikato, Hamilton, New Zealand.
21. Mochalski, K., Micheel, J., Donnelly, S.: Packet delay and loss at the Auckland Internet
access path. In: PAM. (2002)
22. Graham, I.D., Pearson, M., Martens, J., Donnelly, S.: Dag - A cell capture board for ATM
measurement systems (1997) www.cs.waikato.ac.nz /Pub/Html/ATMDag/dag.html.
23. Endace: Measurement Systems (2004) www.endace.com.
24. Micheel, J., Donnelly, S., Graham, I.: Precision timestamping of network packets. In: IMW.
(2001)
25. CAIDA: Bandwidth estimation project (2004) www.caida.org/projects/bwest.
26. Keys, K., Moore, D., Koga, R., Lagache, E., Tesch, M., claffy, k.: The architecture of Coral-
Reef: Internet Trafﬁc monitoring software suite. In: PAM. (2001)
27. Berrou, C., Glavieux, A., Thitimajshima, P.: Near Shannon limit error-correcting coding and
encoding: turbo codes. In: IEEE Int’l Conference on Conmmunications. (1993)
28. Moon, S.B., Skelly, P., Towsley, D.: Estimation and removal of clock skew from network
delay measurements (1998) Tech.Rep.98-43, UMass Amherst (Infocom 1999).
29. Prasad, R., Dovrolis, C., Mah, B.: The effect of store-and-forward devices on per-hop capacity
estimation. In: Infocom. (2003)
30. Broido, A., King, R., Nemeth, E., Claffy, k.: Radon spectroscopy of packet delay. In: ITC
18. (2003)
31. Ribeiro, V., R.Riedi, R.Baraniuk, J.Navratil, L.Cottrell: pathChirp: Efﬁcient Available Band-
width Estimation for Network Paths. In: PAM. (2003)
32. Cisco: How to read the output of the show controller frfab / tofab queue commands on a
Cisco 12000 Series Internet Router. Document ID 18002 (2004) www.cisco.com.
33. Barford, P., Sommers, J.: Comparing probe and router-based packet loss measurement. In:
Internet Computing. (2004)
34. Mah, B.:
pchar:
a
tool
for measuring Internet path characteristics
(1999)
www.kitchenlab.org/www/bmah/Software/pchar.
35. Downey, A.B.: Using pathchar to estimate Internet link characteristics. In: Sigcomm. (1999)