discrimination-aware classiﬁcation: An application to predictive polic-
ing,” Fairness, Accountability and Transparency in Machine Learning,
vol. 26, no. 1, pp. 137–141, 2014.
[27] C. M. Bishop, Pattern Recognition and Machine Learning (Information
Science and Statistics). Secaucus, NJ, USA: Springer-Verlag New York,
Inc., 2006.
[28] S. Barocas and H. Nissenbaum, “Big data’s end run around procedural
privacy protections,” Communications of the ACM, vol. 57, no. 11, pp.
31–33, Oct. 2014.
[29] T. Calders and S. Verwer, “Three naive bayes approaches
for
discrimination-free
classiﬁcation,” Data Mining and Knowledge
Discovery, vol. 21, no. 2, pp. 277–292, 2010. [Online]. Available:
http://dx.doi.org/10.1007/s10618-010-0190-x
[30] A. Datta, M. Tschantz, and A. Datta, “Automated experiments on
ad privacy settings: A tale of opacity, choice, and discrimination,” in
Proceedings on Privacy Enhancing Technologies (PoPETs 2015), 2015,
pp. 92–112.
[31] T. Kamishima, S. Akaho, and J. Sakuma, “Fairness-aware learning
through regularization approach,” in Proceedings of the 2011 IEEE 11th
International Conference on Data Mining Workshops (ICDMW 2011),
2011, pp. 643–650.
[32] R. Zemel, Y. Wu, K. Swersky, T. Pitassi, and C. Dwork, “Learning fair
representations,” in Proceedings of the 30th International Conference on
Machine Learning (ICML 2013), 2013, pp. 325–333.
[33] G. W. University, “Standardized test scores will be optional
for
gw applicants,” 2015. [Online]. Available: https://gwtoday.gwu.edu/
standardized-test-scores-will-be-optional-gw-applicants
[34] The National Center for Fair and Open Testing, “850+ colleges and
universities that do not use sat/act scores to admit substantial numbers
of students into bachelor degree programs,” 2015. [Online]. Available:
http://www.fairtest.org/university/optional
614614
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:16:24 UTC from IEEE Xplore.  Restrictions apply. 
[35] D. Janzing, D. Balduzzi, M. Grosse-Wentrup, and B. Sch¨olkopf, “Quan-
tifying causal inﬂuences,” Ann. Statist., vol. 41, no. 5, pp. 2324–2358,
10 2013.
[36] I. Guyon and A. Elisseeff, “An introduction to variable and feature
selection,” J. Mach. Learn. Res., vol. 3, pp. 1157–1182, Mar. 2003.
[Online]. Available: http://dl.acm.org/citation.cfm?id=944919.944968
[37] L. Breiman, “Random forests,” Mach. Learn., vol. 45, no. 1, pp.
[Online]. Available: http://dx.doi.org/10.1023/A:
5–32, Oct. 2001.
1010933404324
[38] J. Pearl, Causality: Models, Reasoning and Inference, 2nd ed. New
York, NY, USA: Cambridge University Press, 2009.
[39] J. Tian and J. Pearl, “Probabilities of causation: Bounds and identiﬁ-
cation,” Annals of Mathematics and Artiﬁcial Intelligence, vol. 28, no.
1-4, pp. 287–313, 2000.
[40] J. Halpern and J. Pearl, “Causes and explanations: A structural-model
approach. part i: Causes,” The British journal for the philosophy of
science, vol. 56, no. 4, pp. 843–887, 2005.
[41] H. Chockler and J. Halpern, “Responsibility and blame: A structural-
model approach,” Journal of Artiﬁcial Intelligence Research, vol. 22,
pp. 93–115, 2004.
[42] C. E. Shannon, “A mathematical
theory of communication,” Bell
System Technical Journal, vol. 27, no. 3, pp. 379–423, 1948. [Online].
Available: http://dx.doi.org/10.1002/j.1538-7305.1948.tb01338.x
[43] A. R´enyi, “On measures of entropy and information,” in Proceedings
the Fourth Berkeley Symposium on Mathematical Statistics and
of
Probability, Volume 1: Contributions to the Theory of Statistics.
Berkeley, Calif.: University of California Press, 1961, pp. 547–561.
[Online]. Available: http://projecteuclid.org/euclid.bsmsp/1200512181
[44] G. Smith, “Quantifying information ﬂow using min-entropy,” in Pro-
ceedings of the 8th International Conference on Quantitative Evaluation
of Systems (QEST 2011), 2011, pp. 159–167.
[45] T. M. Cover and J. A. Thomas, Elements of information theory.
John
Wiley & Sons, 2012.
[46] R. Tibshirani, “Regression shrinkage and selection via the lasso:
the Royal Statistical Society Series
[Online]. Available: http:
a retrospective,” Journal of
B, vol. 73, no. 3, pp. 273–282, 2011.
//EconPapers.repec.org/RePEc:bla:jorssb:v:73:y:2011:i:3:p:273-282
[47] B. Letham, C. Rudin, T. H. McCormick, and D. Madigan, “Interpretable
classiﬁers using rules and bayesian analysis: Building a better stroke
prediction model,” Ann. Appl. Stat., vol. 9, no. 3, pp. 1350–1371, 09
2015. [Online]. Available: http://dx.doi.org/10.1214/15-AOAS848
[48] B. Ustun, S. Trac, and C. Rudin, “Supersparse linear integer models for
interpretable classiﬁcation,” ArXiv e-prints, 2013. [Online]. Available:
http://arxiv.org/pdf/1306.5860v1
[49] S. Rping, “Learning interpretable models.” Ph.D. dissertation, Dortmund
University of Technology, 2006, http://d-nb.info/997491736.
[50] S. Guha, B. Cheng, and P. Francis, “Challenges in measuring online
advertising systems,” in Proceedings of
the 10th ACM SIGCOMM
Conference on Internet Measurement, ser. IMC ’10. New York, NY,
USA: ACM, 2010, pp. 81–87.
[51] P. Barford, I. Canadi, D. Krushevskaja, Q. Ma, and S. Muthukrishnan,
“Adscape: Harvesting and analyzing online display ads,” in Proceedings
of the 23rd International Conference on World Wide Web, ser. WWW
’14. New York, NY, USA: ACM, 2014, pp. 597–608.
[52] M. L´ecuyer, G. Ducoffe, F. Lan, A. Papancea, T. Petsios, R. Spahn,
A. Chaintreau, and R. Geambasu, “Xray: Enhancing the web’s trans-
parency with differential correlation,” in Proceedings of
the 23rd
USENIX Conference on Security Symposium, ser. SEC’14. Berkeley,
CA, USA: USENIX Association, 2014, pp. 49–64.
[53] A. Datta, M. C. Tschantz, and A. Datta, “Automated experiments on ad
privacy settings.” PoPETs, vol. 2015, no. 1, pp. 92–112, 2015.
[54] M. Lecuyer, R. Spahn, Y. Spiliopolous, A. Chaintreau, R. Geambasu,
and D. Hsu, “Sunlight: Fine-grained targeting detection at scale with
statistical conﬁdence,” in Proceedings of the 22Nd ACM SIGSAC Con-
ference on Computer and Communications Security, ser. CCS ’15. New
York, NY, USA: ACM, 2015, pp. 554–566.
[55] A. Datta, A. Datta, A. Procaccia, and Y. Zick, “Inﬂuence in classiﬁcation
via cooperative game theory,” in Proceedings of the 24th International
Joint Conference on Artiﬁcial Intelligence (IJCAI 2015), 2015, pp. 511–
517.
[56] R. Lindelauf, H. Hamers, and B. Husslage, “Cooperative game theoretic
centrality analysis of terrorist networks: The cases of jemaah islamiyah
and al qaeda.” European Journal of Operational Research, vol. 229,
no. 1, pp. 230–238, 2013.
[57] T. Michalak, T. Rahwan, P. Szczepanski, O. Skibski, R. Narayanam,
M. Wooldridge, and N. Jennings, “Computational analysis of connec-
tivity games with applications to the investigation of terrorist networks,”
in Proceedings of the 23rd International Joint Conference on Artiﬁcial
Intelligence (IJCAI 2013), 2013, pp. 293–301.
[58] M. del Pozo, C. Manuel, E. Gonz´alez-Arang¨uena, and G. Owen,
“Centrality in directed social networks. a game theoretic approach,”
Social Networks, vol. 33, no. 3, pp. 191–200, 2011.
[59] T. Michalak, K. Aaditha, P. Szczepanski, B. Ravindran, and N. Jennings,
“Efﬁcient computation of the shapley value for game-theoretic network
centrality,” Journal of Artiﬁcial Intelligence Research, vol. 46, pp. 607–
650, 2013.
[60] P. Bork, L. Jensen, C. von Mering, A. Ramani, I. Lee, and E. Marcott,
“Protein interaction networks from yeast to human,” Current Opinions
in Structural Biology, vol. 14, no. 3, pp. 292–299, 2004.
[61] A. Keinan, B. Sandbank, C. Hilgetag, I. Meilijson, and E. Ruppin, “Fair
attribution of functional contribution in artiﬁcial and biological net-
works,” Neural Computation, vol. 16, no. 9, pp. 1887–1915, September
2004.
[62] M. Malawski, “Equal treatment, symmetry and banzhaf value axiom-
atizations,” International Journal of Game Theory, vol. 31, no. 1, pp.
47–67, 2002.
615615
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:16:24 UTC from IEEE Xplore.  Restrictions apply. 
APPENDIX A
ALTERNATIVE GAME-THEORETIC INFLUENCE MEASURES
In what follows, we describe two alternatives to the Shapley
value used in this work. The Shapley value makes intuitive
sense in our setting, as we argue in Section III-B. However,
other measures may be appropriate for certain input data
generation processes. In what follows we revisit the Banzhaf
index, brieﬂy discussed in Section III-A, and introduce the
readers to the Deegan-Packel index, a game-theoretic inﬂu-
ence measure with deep connections to a formal theory of
responsibilty and blame [41].
A. The Banzhaf Index
Recall that the Banzhaf index, denoted βi(N, v) is deﬁned
as follows:
(cid:3)
βi(N, v) =
1
2n−1
mi(S).
S⊆N\{i}
(cid:10)
The Banzhaf index can be thought of as follows: each
j ∈ N \ {i} will
join a work effort with probability 1
(or, equivalently, each S ⊆ N \ {i} has an equal chance
2
of forming); if i joins as well, then its expected marginal
contribution to the set formed is exactly the Banzhaf index.
Note the marked difference between the probabilistic models:
under the Shapley value, we sample permutations uniformly
at random, whereas under the regime of the Banzhaf index,
we sample sets uniformly at random. The different sampling
protocols reﬂect different normative assumptions. For one,
the Banzhaf index is not guaranteed to be efﬁcient; that is,
i∈N βi(N, v) is not necessarily equal to v(N ), whereas it
i=1 ϕi(N, v) = v(N ). Moreover, the
is always the case that
Banzhaf index is more biased towards measuring the marginal
contribution of i to sets of size n
n); this is because the
expected size of a randomly selected set follows a binomial
distribution B(n, 1
2 ). On the other hand, the Shapley value is
equally likely to measure the marginal contribution of i to sets
of any size k ∈ {0, . . . , k}, as i is equally likely to be in any
one position in a randomly selected permutation σ (and, in
particular, the the set of i’s predecessors in σ is equally likely
to have any size k ∈ {0, . . . , n − 1}).
2 ±O(
(cid:10)n
√
Going back to the QII setting, the difference in sampling
procedure is not merely an interesting anecdote: it is a sig-
niﬁcant modeling choice. Intuitively, the Banzhaf index is
more appropriate if we assume that large sets of features
would have a signiﬁcant inﬂuence on outcomes, whereas the
Shapley value is more appropriate if we assume that even
small sets of features might cause signiﬁcant effects on the
outcome. Indeed, as we mention in Section VIII, aggregating
the marginal inﬂuence of i over sets is a signiﬁcant modeling
choice; while using the measures proposed here is perfectly
reasonable in many settings, other aggregation methods may
be applicable in others.
Unlike the Shapley value, the Banzhaf index is not guar-
anteed to be efﬁcient (although it does satisfy the symmetry
and dummy properties). Indeed, [62] shows that replacing
the efﬁciency axiom with an alternative axiom, uniquely
characterizes the Banzhaf index; the axiom, called 2-efﬁciency,
prescribes the behavior of an inﬂuence measure when two
players merge. First, let us deﬁne a merged game; given a
game (cid:9)N, v(cid:10), and two players i, j ∈ N, we write T = {i, j}.
We deﬁne the game ¯v on N \ T ∪{¯t} as follows: for every set
S ⊆ N \{i, j}, ¯v(S) = v(S), and ¯v(S ∪{¯t}) = v(S ∪{i, j}),
note that the added player ¯t represents the two players i and
j who are now acting as one. The 2-Efﬁciency axiom states
that inﬂuence should be invariant under merges.
Deﬁnition 14 (2-Efﬁciency (2-EFF)). Given two players i, j ∈
N, let ¯v be the game resulting from the merge of i and j into
a single player ¯t; an inﬂuence measure φ satisﬁes 2-Efﬁciency
if φi(N, v) + φj(N, v) = φ¯t(N \ {i, j} ∪ {¯t}, ¯v).
Theorem 15 ([62]). The Banzhaf index is the only function
to satisfy (Sym), (D), (Mono) and (2-EFF).
In our context, 2-Efﬁciency can be interpreted as follows:
two features i and j as
suppose that we artiﬁcially treat
one, keeping all other parameters ﬁxed; in this setting, 2-
efﬁciency means that the inﬂuence of merged features equals
the inﬂuence they had as separate entities.
B. The Deegan-Packel Index
Finally, we discuss the Deegan-Packel index [18]. While
the Shapley value and Banzhaf index are well-deﬁned for any
coalitional game, the Deegan-Packel index is only deﬁned for
simple games. A cooperative game is said to be simple if
v(S) ∈ {0, 1} for all S ⊆ N. In our setting, an inﬂuence
measure would correspond to a simple game if it is binary
(e.g. it measures some threshold behavior, or corresponds to
a binary classiﬁer). The binary requirement is rather strong;
however, we wish to draw the reader’s attention to the Deegan-
Packel index, as it has an interesting connection to causal
responsibility [41], a variant of the classic Pearl-Halpern
causality model [40], which aims to measure the degree to
which a single variable causes an outcome.
Given a simple game v : 2N → {0, 1}, let M(v) be the set
of minimal winning coalitions; that is, for every S ∈ M(v),
v(S) = 1, and v(T ) = 0 for every strict subset of S. The
Deegan-Packel index assigns a value of
(cid:3)
δi(N, v) =
1
|M(v)|
1|S| .
S∈M(v):i∈S
The intuition behind the Deegan-Packel index is as follows:
players will not form coalitions any larger than what they
absolutely have to in order to win, so it does not make sense
to measure their effect on non-minimal winning coalitions.
Furthermore, when a minimal winning coalition is formed,
the beneﬁts from its formation are divided equally among its
members; in particular, small coalitions confer a greater beneﬁt
for those forming them than large ones. The Deegan-Packel
index measures the expected payment one receives, assuming
that every minimal winning coalition is equally likely to form.
Interestingly, the Deegan-Packel index corresponds nicely to
the notion of responsibility and blame described in [41].
616616
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:16:24 UTC from IEEE Xplore.  Restrictions apply. 
Suppose that we have a set of variables X1, . . . , Xn set to
x1, . . . , xn, and some binary effect f (x1, . . . , xn) (written
as f (x)) occurs (say, f (x) = 1). To establish a causal
to xi and f (x) = 1,
relation between the setting of Xi
[40] require that there is some set S ⊆ N \ {i} and some
values (yj)j∈S∪{i} such that f (x−S∪{i}, (yj)j∈S∪{i}) = 0,
but f (x−S, (yj)j∈S) = 1. In words, an intervention on the
values of both S and i may cause a change in the value of
f, but performing the same intervention just on the variables
in S would not cause such a change. This deﬁnition is at the
heart of the marginal contribution approach to interventions
that we describe in Section III-A. [41] deﬁne the responsibility
1
k+1 , where k is the size of the
of i for an outcome as
smallest set S for which the causality deﬁnition holds with
respect to i. The Deegan-Packel index can thus be thought of
as measuring a similar notion: instead of taking the overall
minimal number of changes necessary in order to make i a
direct, counterfactual cause, we observe all minimal sets that
do so. Taking the average responsibility of i (referred to as
blame in [41]) according to this variant, we obtain the Deegan-
Packel index.
Example 16. Let us examine the following setup, based on
Example 3.3 in [41]. There are n = 2k + 1 voters (n is an
odd number) who must choose between two candidates, Mr.
B and Mr. G ([41] describe the setting with n = 11). All
voters elected Mr. B, resulting in an n-0 win. It is natural to
ask: how responsible was voter i for the victory of Mr. B?
According to [41], the degree of responsibility of each voter
1
k+1 . It will require that i and k additional voters change
is
their vote in order for the outcome to change. Modeling this
setup as a cooperative game is quite natural: the voters are the
players N = {1, . . . , n}; for every subset S ⊆ N we have
(cid:11)
v(S) =
1 if |S| ≥ k + 1
0 otherwise.
That is, v(S) = 1 if and only if the set S can change the
outcome of the election. The minimal winning coalitions here
are the subsets of N of size k + 1, thus the Deegan-Packel
index of player i is
(cid:3)
δi(N, v) =
=
1
|M(v)|
1(cid:17)
(cid:18)(cid:13)
n
k+1
(cid:14)
S∈M(v):i∈S
n
k
k + 1
1
1|S|
1
n − k =
1
k + 1
=
We note that if one assumes that all voters are equally likely
to prefer Mr. B over Mr. G, then the blame of voter i would
be computed in the exact manner as the Deegan-Packel index.
617617
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:16:24 UTC from IEEE Xplore.  Restrictions apply.