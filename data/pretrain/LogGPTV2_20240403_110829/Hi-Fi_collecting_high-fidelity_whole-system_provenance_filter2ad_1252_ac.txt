of this early boot provenance reveals that a one-kilobyte buffer is
sufﬁciently large to hold the provenance generated by the kernel
during this period. Once the relay is created, we ﬂush the contents
of the temporary boot-provenance buffer to it and free the buffer.
By doing this, we can collect and retain provenance data for a large
portion of the kernel’s initialization process.
dling the data currently in the log. This allows it to handle any re-
maining shutdown provenance, then return control to init to com-
plete the shutdown process.
5.4 Bootstrapping Filesystem Provenance
Intuitively, a complete provenance record contains enough infor-
mation to recreate the structure of an entire ﬁlesystem. To do this,
we need to have three things: a list of inodes, ﬁlesystem metadata
for each inode, and a list of hard links (ﬁlenames) for each inode.
Our system has a hook corresponding to each of these items. As-
suming, then, that we can collect provenance for a ﬁlesystem start-
ing from the point when it is completely empty, all of this informa-
tion will appear in the record.
There are two problems with this assumption, however. First, it
is impractical. We may connect a USB drive which has been used
elsewhere, or we may want to start collecting provenance on an
existing, populated ﬁlesystem. Second, it is actually impossible to
start with an empty ﬁlesystem. Without a root inode, which is cre-
ated by the corresponding mkfs program, a ﬁlesystem cannot even
be mounted. Unfortunately, mkfs does this by writing directly to a
block device ﬁle, which does not generate the expected provenance
data.
What we need is a way to bootstrap provenance on a populated
ﬁlesystem.
In order to have a complete record for each ﬁle, we
must generate a creation event for any pre-existing inodes. We have
implemented a utility called pbang (for “provenance Big Bang”)
which does this by traversing the ﬁlesystem tree. For each new
inode it encounters, it outputs an allocation entry for the inode, a
metadata entry containing its attributes, and a link entry contain-
ing its ﬁlename and directory. For previously encountered inodes,
it only outputs a new link entry. All of these entries are writ-
ten to a ﬁle to complete the provenance record. To make a new
provenanced ﬁlesystem, we create it normally using mkfs, then run
pbang immediately afterward.
5.3 Operating System Integration
5.5 Provenance-Opaque Flag
One important aspect of Hi-Fi’s design is that the provenance
handler must be kept running to consume provenance data as it is
written to the log. Since the relay is backed by a buffer, it can
retain a certain amount of data if the handler is inactive or hap-
pens to crash. It is important, though, that the handler is restarted
in this case. Fortunately, this is a feature provided by the op-
erating system’s init process. By editing the conﬁguration in
/etc/inittab, we can specify that the handler should be started
automatically at boot, as well as respawned if it should ever crash.
We also want to collect and retain provenance data for as much of
the operating system’s shutdown process as possible. At shutdown
time, the init process takes control of the system and executes a
series of actions from a shutdown script. This script asks processes
to terminate, forcefully terminates those which do not exit grace-
fully, unmounts ﬁlesystems, and eventually powers the system off.
Since the provenance handler is a regular userspace process, it is
subject to this shutdown procedure as well. However, there is no
particular order in which processes are terminated during the shut-
down sequence, so it is possible that another process may outlive
the handler and perform actions which generate provenance data.
Our goal of ﬁdelity requires that we collect this provenance.
Our solution is to handle the shutdown process in the same way
we would handle a crash: restart the provenance handler. We mod-
ify the shutdown script to re-execute the handler after all other pro-
cesses have been terminated, just before ﬁlesystems are unmounted.
For this special case, we implement a “one-shot” mode in the han-
dler which, instead of forking to the background, exits after han-
We noticed a strange behavior in the early prototypes of Hi-Fi:
even when the system was completely idle, a continuous stream of
provenance data was being generated. Inspection of the provenance
record showed that this data described the actions of the prove-
nance handler itself. The handler would call the read function
to retrieve data from the provenance log, which then triggered the
file_permission LSM hook. The collector would record this
action in the log, where the handler would again read it, trigger-
ing file_permission, and so on. This created a large amount of
“feedback” in the provenance record.
In light of our design goals, this is technically correct behav-
ior. However, it ﬂoods the provenance record with data which
does not provide any additional insight into the system’s opera-
tion. One option for solving this problem is to make the handler
completely exempt from provenance collection. This, however, has
the potential to interfere with our ability to reconstruct the ﬁlesys-
tem. If the handler were to create or move a ﬁle without generat-
ing provenance data, we could no longer accurately reconstruct the
ﬁlesystem structure from the record. Instead, we make the handler
“provenance-opaque,” treating it as a black box which only gen-
erates provenance data if it makes any signiﬁcant changes to the
ﬁlesystem.
The ﬁrst piece to our solution is informing the LSM which pro-
cess is the provenance handler. To do this, we leverage the LSM
framework’s integration with extended ﬁlesystem attributes. We
identify the provenance handler program by setting an attribute
called security.hifi. The “security” attribute namespace, which
264is reserved for attributes used by security modules, is protected
from tampering by malicious users. When the program is executed,
the bprm_check_security hook examines this property for the
value “opaque” and sets a ﬂag in the process’s credentials indi-
cating that it should be treated accordingly. In order to allow the
handler to create new processes without reintroducing the original
problem—for instance, if the handler is a shell script—this ﬂag is
propagated to any new credentials that the process creates.
5.6 Socket Provenance
Our modiﬁcations to network socket behavior are designed to be
both transparent and incrementally deployable. To allow interoper-
ability with existing non-provenanced hosts, we place packet iden-
tiﬁers in the IP Options header ﬁeld. In order to ensure that every
packet sent by our system is marked appropriately, we implement
two Netﬁlter hooks, which process packets at the network layer.
The outgoing hook labels each packet with the correct identiﬁer
just before it encounters a routing decision, and the incoming hook
reads this label just after the receiver decides the packet should be
handled locally. Note that even packets sent to the loopback address
will encounter both of these hooks.
In designing the log entries for socket provenance, we aim to
make the reconstruction of information ﬂows from multiple system
logs as simple as possible. When the sender and receiver are on
the same host, these entries should behave the same as reads and
writes. When they are on different hosts, the only added require-
ment should be a partial ordering placing each send before all of
its corresponding receives. Lamport clocks [12] would satisfy this
requirement.
The problem with this is that the socket_recvmsg hook, which
was designed for access control, executes before a process attempts
to receive a message. This may occur before the corresponding
socket_sendmsg hook is executed. To solve this, we place a
socket_post_recvmsg hook after the message arrives and before
it is returned to the receiver, and we use this hook to generate the
entry for receiving a message.
We implement support for TCP and UDP sockets to demonstrate
provenance for both connection-mode and connectionless sockets,
as well as both stream and message-oriented sockets. Support for
the other protocols and pseudo-protocols in the Linux IP stack, such
as SCTP, ping, and raw sockets, can be implemented using similar
techniques. For example, SCTP is a sequential packet protocol,
which has connection-mode and message semantics.
5.6.1 TCP Sockets
TCP and other connection-mode sockets are complicated in that
a connection involves three different sockets: the client socket, the
listening server socket, and the server socket for an accepted con-
nection. The ﬁrst two are created in the same way as any other
socket on the system: using the socket function, which calls the
socket_create and socket_post_create LSM hooks. How-
ever, sockets for an accepted connection on the server side are cre-
ated by a different sequence of events. When a listening socket
receives a connection request, it creates a “mini-socket” instead
of a full socket to handle the request. If the client completes the
handshake, a new child socket is cloned from the listening socket,
and the relevant information from the mini-socket (including our
IP options) is copied into the child. In terms of LSM hooks, the
inet_conn_request hook is called when a mini-socket is created,
and the inet_csk_clone hook is called when it is converted into a
full socket. On the client side, the inet_conn_established hook
is called when the SYN+ACK packet is received from the server.
Our system must treat the TCP handshake with care, since there
are two different sockets participating on the server side. We create
a unique identiﬁer for the mini-socket in the inet_conn_request
hook, and this identiﬁer is later copied directly into the child socket.
The client must then be certain to remember the correct identiﬁer,
namely, the one associated with the child socket. The ﬁrst packet
that the client receives (the SYN+ACK) will carry the IP options
from the listening parent socket. To keep this from overriding the
child socket, we use the inet_conn_established hook to clear
the saved identiﬁer so that it is later replaced by the correct one.
5.6.2 UDP Sockets
Since UDP sockets are connectionless, we must use an LSM
hook to assign a different identiﬁer to each datagram.
In addi-
tion, this hook must run in process context, so that we can record
the identiﬁer of the process which is sending or receiving. The
only existing LSM socket hook with datagram granularity is the
sock_rcv_skb hook, but it is run as part of an interrupt when
a datagram arrives, not in process context. The remaining LSM
hooks are placed with socket granularity; therefore, we must place
two additional hooks to mediate datagram communication.
The construction and delivery semantics for UDP datagrams are
not as straightforward as they may appear at ﬁrst. An intuitive
assumption would be that each datagram is constructed by a sin-
gle process and received by a single process, but this is not the
case.
If the ﬁle descriptor of the receiving socket is shared be-
tween processes, they can all receive the same datagram by using
the MSG_PEEK ﬂag. In fact, multiple processes can also contribute
data when sending a single datagram by using the MSG_MORE ﬂag
or the UDP_CORK socket option. Because of this, placing send and
receive hooks for UDP is a very subtle task.
Since we consider each datagram an independent entity, the cru-
cial points to mediate are the addition of data to the datagram and
the reading of data from it. The Linux IP implementation includes
a function which is called from process context to append data to an
outgoing socket buffer. This function is called each time a process
adds data to a corked datagram, as well as in the normal case where
a single process constructs a datagram and immediately sends it.
This makes it an ideal candidate for the placement of the send hook,
which we call socket_dgram_append. Since this hook is placed
in network-layer code, it can be applied to any message-oriented
protocol and not just UDP.
We also place the receive hook in protocol-agnostic code, for
similar ﬂexibility. The core networking code provides a function
which retrieves the next datagram from a socket’s receive queue.
UDP and other message-oriented protocols use this function when
receiving, and it is called once for each process that receives a given
datagram. This is an ideal location for the message-oriented re-
ceive hook, so we place the socket_dgram_post_recv hook in
this function.
6. EVALUATION
The motivation behind this work is to determine whether whole-
system provenance collection can provide useful information in
a security context. We demonstrate this in two ways. First, we
show that a number of typical malware behaviors appear plainly
in a whole-system provenance record.
In particular, when mal-
ware spreads from one provenanced host to another, we can observe
the communication between the infected process on one host and
the target process on the other using socket provenance. Second,
we demonstrate that the performance overhead of Hi-Fi is small
enough that it could be used in practice.
2656.1 Recording Malicious Behavior
Our ﬁrst task is to show that the data collected by Hi-Fi is of
sufﬁcient ﬁdelity to be used in a security context. We focus our in-
vestigation on detecting the activity of network-borne malware. A
typical worm consists of several parts. First, an exploit allows it to
execute code on a remote host. This code can be a dropper, which
serves to retrieve and execute the desired payload, or it can be the
payload itself. A payload can then consist of any number of differ-
ent actions to perform on an infected system, such as exﬁltrating
data or installing a backdoor. Finally, the malware spreads to other
hosts and begins the cycle again.
For our experiment, we chose to implement a malware genera-
tor which would allow us to test different droppers and payloads
quickly and safely. The generator is similar in design to the Metas-
ploit Framework [13], in that you can choose an exploit, dropper,
and payload to create a custom attack. However, our tool also in-
cludes a set of choices for generating malware which automatically
spreads from one host to another; this allows us to demonstrate
what socket provenance can record about the ﬂow of information
between systems. The malware behaviors that we implement and
test are drawn from Symantec’s technical descriptions of actual
Linux malware[23].
To collect provenance data, we prepare three virtual machines
on a common subnet, all of which are running Hi-Fi. The attacker
generates the malware on machine A and infects machine B by ex-
ploiting an insecure network daemon. The malware then spreads
automatically from machine B to machine C. For each of the mali-
cious behaviors we wish to test, we generate a corresponding piece
of malware on machine A and launch it. Once C has been infected,
we retrieve the provenance logs from all three machines for exam-
ination.
Each malware behavior that we test appears in some form in the
provenance record. In each case, after ﬁltering the log to view only
the vulnerable daemon and its descendants, the behavior is clear
enough to be found by manual inspection. Below we describe each
behavior and how it appears in the provenance record.
6.1.1 Persistence and Stealth
Frequently, the ﬁrst action a piece of malware takes is to ensure
that it will continue to run for as long as possible. In order to persist
after the host is restarted, the malware must write itself to disk in
such a way that it will be run when the system boots. The most
straightforward way to do this on a Linux system is to infect one of
the startup scripts run by the init process. Our simulated malware
has the ability to modify rc.local, as the Kaiten trojan does. This
shows up clearly in the provenance log:
[6fe] write B:/etc/rc.local
In this case, the process with provid 0x6fe has modiﬁed rc.local
on B’s root ﬁlesystem. Persistent malware can also add cron jobs
or infect system binaries to ensure that it is executed again after
a reboot. Examples of this behavior are found in the Sorso and
Adore worms. In our experiment, these behaviors result in similar
log entries:
[701] write B:/bin/ps
for an infected binary, and
[710] write B:/var/spool/cron/root.new
[710] link B:/var/spool/cron/root.new to
B:/var/spool/cron/root
[710] unlink B:/var/spool/cron/root.new
for an added cron job.
Some malware is even more clever in its approach to persistence.
The Svat virus, for instance, creates a new C header ﬁle and places
it early in the default include path. By doing this, it affects the code
of any program which is subsequently compiled on that machine.
We include this behavior in our experiment as well, and it appears
simply as:
[707] write B:/usr/local/include/stdio.h
6.1.2 Remote Control
Once the malware has established itself as a persistent part of
the system, the next step is to execute a payload. This commonly
includes installing a backdoor which allows the attacker to control
the system remotely. The simplest way to do this is to create a
new root-level user on the system, which the attacker can then use
to log in. Because of the way UNIX-like operating systems store
their account databases, this is done by creating a new user with a
UID of 0, making it equivalent to the root user. This is what the
Zab trojan does, and when we implement this behavior, it is clear
to see that the account databases are being modiﬁed:
[706] link (new) to B:/etc/passwd+
[706] write B:/etc/passwd+
[706] link B:/etc/passwd+ to B:/etc/passwd
[706] unlink B:/etc/passwd+
[706] link (new) to B:/etc/shadow+