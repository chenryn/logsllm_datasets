### Attack Dictionaries and Click-Order Pattern Constraints

To evaluate the effectiveness of click-order pattern constraints on graphical passwords, we generated attack dictionaries for each image under various sets of these constraints. This method serves as an initial exploration into other ways that click-based graphical passwords can be analyzed for patterns in user choice. We anticipate that this general direction will yield additional results, including patterns resulting from mnemonic strategies (e.g., clicking all red objects).

#### Results Analysis

The results in Table 5 show that, on average, using only the diagonal constraint for the pool image reduces the dictionary size to 16 bits while still cracking 12% of passwords. Similarly, for the cars image, the same constraint reduces the dictionary size to 18 bits while cracking 10% of passwords. The success rate of our human-seeded attack is comparable to recent results on cracking text-based passwords [23], where 6% of passwords were cracked with a 1.2 million entry dictionary. This is almost 2 bits larger than our DIAG dictionary based on harvested points from 15 users for cars and 4 bits larger for the pool image.

Unlike most text dictionaries, we do not need to store the entire dictionary, as it is generated on-the-fly from the alphabet. This suggests that these graphical passwords are slightly less secure than the text-based passwords they are intended to replace. However, the reality may be worse. An analogy to our attack would be collecting text passwords from 15 users and generating a dictionary based on all permutations of the characters harvested, which could lead to a successful attack. The reason most text password dictionaries succeed is due to known dependent patterns in language (e.g., using di or tri-grams in a Markov model [29]). A similar approach has not yet been attempted for graphical passwords but could further reduce the dictionary size.

### Purely Automated Attacks Using Image Processing Tools

We also investigated the feasibility of creating an attack dictionary for click-based graphical passwords using purely automated means. Automation would eliminate the need for human-seeding (i.e., harvesting points), making it easier for an attacker to launch such attacks. We created this attack dictionary by modeling user choice using a set of image processing methods and tools. The idea is that these methods may help predict hot-spots, leading to more efficient search orderings for exhaustive attacks. This could be used for modeling attackers constructing attack dictionaries and for proactive password checking.

#### Identifying Candidate Click-Points

We began by identifying the details of the user task in creating a click-based graphical password. The user must choose a set of points (in a specific order) that can be remembered in the future. We focused on the basic features of a point that define candidate click-points:
1. **Identifiable with precision within the system’s error tolerance**: For example, in the pool image, a red garbage can larger than the 19 × 19 error tolerance requires the user to pick a specific part, such as the left handle.
2. **Distinguishable from its surroundings**: Easily picked out from the background. For example, a white logo on a black hat is easier to find than a brown logo on a green camouflage hat.

For modeling purposes, we hypothesized that images with fewer candidate click-points are easier to attack. We estimated candidate click-points by implementing a variation of Itti et al.’s bottom-up model of visual attention (VA) [17] and combining it with Harris corner detection [16].

**Corner Detection** picks out areas of an image with variations in intensity in horizontal and vertical directions, providing a measure of identifiability. **Itti et al.’s VA** determines areas that stand out from their surroundings, providing a measure of distinguishability. We implemented a variation of VA and combined it with Harris corner detection to obtain a prioritized list of candidate click-points (CCP-list) as follows:
1. Calculate a VA saliency map using slightly smaller scales than Itti et al. [17].
2. Calculate corner locations using the Harris corner detection function.
3. Use the corner locations as a bitmask for the saliency map, producing a cornered saliency map (CSM).
4. Compute an ordered CCP-list of the highest to lowest intensity-valued CSM points, inhibiting a CSM point once it has been added to the CCP-list.

#### Model Results

We evaluated the performance of the CCP-list using data from both lab and field user studies. We found that the top half of the CCP-list (top 207 points) overlapped well with high-probability clusters from our lab user study. This half-alphabet found all high-probability clusters on the icons, faces, and cars images, and most of the high-probability clusters on 11 of the 17 images. Images where the model performed poorly (pcb, citymap-gr, paperclips, smarties, and truck) appeared to be due to the saliency map algorithm being overloaded with too much detail.

To evaluate the CCP-list's ability to model entire passwords, we used the top one-third of the CCP-list values (top 138 points for each image) to build a graphical dictionary and carry out a dictionary attack against observed passwords from both user studies. For some images, this 35-bit dictionary was able to guess a large number of user passwords (30% for the icons image and 29% for the Philadelphia map image). For both short and long-term studies, our tool guessed 9.1% of passwords for the cars image. A 28-bit computer-generated dictionary (built from the top 51 ranked CCP-list alphabet) correctly guessed 8 passwords (22%) from the icons image and 6 passwords (17%) from the Philadelphia image. The results of this automated graphical dictionary attack are summarized in Table 6.

### Related Work

In the absence of password rules, practical text password security is weak due to common patterns in user choice. Klein [21] determined that a dictionary of 3 million words (less than 1 billionth of the entire 8-character password space) correctly guessed over 25% of passwords. Automated password cracking tools and dictionaries that exploit common patterns include Crack [28] and John the Ripper [30]. Kuo et al. [23] found that John the Ripper’s English dictionary of 1.2 million words correctly guessed 6% of user passwords, and an additional 5% by including simple permutations.

To address this threat, methods to create less predictable passwords have emerged. Yan [48] explores the use of passphrases to avoid password dictionary attacks. Jeyaraman et al. [20] suggest basing a passphrase on an automated newspaper headline. Proactive password checking techniques (e.g., [38, 7, 2]) are commonly used to prevent users from choosing weak passwords.

Many variations of graphical passwords are discussed in surveys by Suo et al. [39] and Monrose et al. [27]. We focus on two general categories: recognition-based and recall-based. Recognition-based graphical passwords require the user to recognize a set (or subset) of K previously memorized images. Examples include Déjà Vu [10], Passfaces [35], and Story [8]. Recall-based schemes can be further described as cued or uncued. An uncued scheme does not provide the user any information from which to create their graphical password.