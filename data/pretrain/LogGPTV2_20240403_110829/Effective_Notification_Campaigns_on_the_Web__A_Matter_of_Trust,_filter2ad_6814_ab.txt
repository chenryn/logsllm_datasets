tracker objects and their conﬁguration on the website in all
JavaScript contexts, thus also detecting tracker objects of
USENIX Association
30th USENIX Security Symposium    2491
Figure 1: Methodology Overview
third parties, e. g. included through widgets. To ﬁnd tracker
objects, the checker iterates all JavaScript global variables.
For each global variable, the checker assesses the available
methods and attributes; if those match the expected ones for
analytics.js or ga.js, it found a GA object. This object
can be queried for available trackers and their conﬁguration.
Tracker objects are used in our self-service tool to provide the
user with detailed information about misconﬁgurations.
We modify the user agent to hide that Chromium was run-
ning headless. We also scroll the page for a random amount in
short random intervals, since additional GA requests might be
sent on site usage. We do not check sites for the presence of
consent banners; technically, a consent banner could hide the
existence of a non-compliant GA instance until the consent
was conﬁrmed, i. e., our checker is subject to false negatives.
However, the checker will never return a false positive match.
4.2 Collecting Non-Compliant Websites
As reported in Section 2.1, automated and simple address col-
lection approaches can lead to high bounce rates. Therefore,
we decided to collect all contact data manually.
There is no generally accepted method to obtain a rep-
resentative sample of websites that ﬁt the criteria for our
compliance-based notiﬁcations. Given this limitation, which
is discussed in Section 7.4, we still aim to obtain a diverse
set of websites for our study, comprised of popular and non-
popular sites. First, we use all websites referenced in the
German Wikipedia, ﬁltered on the Top-Level Domain (TLD)
.de (N = 32 782). Second, we use a merged and deduplicated
version of the archive of historical (up to 10 years) Internet
toplists by Scheitle et al. [36], again ﬁltered on the TLD .de
(N = 1 265 750). We scan these sites with the compliance
checker and ﬁnd that 3070 (9.36 %) of the Wikipedia sites
and 161 984 of the toplist sites (12.8 %) are non-compliant.
From the non-compliant toplist sites, we randomly sample
5000 sites, 91 of which were already present in the Wikipedia
dataset, to obtain 7979 non-compliant sites in total.
Each site is visited by three researchers, each of them inde-
pendently collecting postal and email addresses from the site’s
imprint. Moreover, the researchers assign a category such as
company, individual, public sector, and others, which is used
to avoid biases in our experimental groups (cf. Section 4.3).
Conﬂicts are discussed and resolved using a majority vote.
On average, this task took 75 seconds per site.
We exclude 3225 sites to which our compliance-based noti-
ﬁcation does not apply. About 20 % of these sites are excluded
because they belong to the public sector (municipalities, uni-
versities, etc.) to which the ﬁnes mandated by the GDPR do
not apply, which would skew some of our results. We also
exclude sites without an imprint (about 20 % of excluded
sites) and sites that list an address outside of Germany in
their imprint (again, about 20 % of excluded sites). Finally,
we exclude sites of politicians (less than 1 % of excluded sites)
to avoid cross-contamination with another study. We also re-
move sites that cannot be retrieved (about 10 % of excluded
2492    30th USENIX Security Symposium
USENIX Association
OBJECTIVECOVERT EXPERIMENTGermanWikipediaTopsite List(Scheitle et al.)FOCUSCOLLECTING DATASET OF NON-COMPLIANT SITESSETUP, TREATMENTS, ANALYSESUnderstand conditions for effective notifications about misconfigurations on websitesScan of URLswith “de” TLDrandom sample5000 sites(remove 91 duplicates)Observe reaction of site owners having non-compli-ant GA when notified under various conditionsSites targeting German citizens (obliged to provide contact info in imprint and to anonymize IPs in GA)9.4 % of32 782 sitesall 3070 sitesSet aside 589 ownersfor control groupWait 1 monthWait 1 monthVisited by 3 researcherseach; conflicts resolvedExclude sites without imprint, with non-German postal address; sites of politicians and public orgs; inaccessible, broken, and compliant sites (after rescanning all sites)7979 non-compliant sitesVisit site manuallyExtract contact datafrom imprintDetermine category(biz., news, public, …)Identify sites run by same ownerRescan all sites four times per dayPerform support via phone and email1430 communications with 764 ownersRun self-service tool CheckGAUsed by 1939 owners (estimated)Split owners into 18 groups2 media, 3 senders, 3 framings4754 sites  run by  N=4594 owners12.8 % of1 265 750 sitesSites with missing or in-correct IP AnonymizationSend 3997 initial notificationsSend 2160 reminders (if unfixed)Send 3736 debriefings with link to surveySurvival analysis for all groups + control groupAnalysis of survey responses of owners (N=477)Identify problem awarenessand trust factorsDetermine effectivenessunder various conditionssites). Finally, we rescan all sites before sending out the ﬁrst
round of notiﬁcations and remove sites that have become
compliant or went out of service during the six-month data
collection period (accounting for the remainder, i. e., about
30 % of the excluded sites). Note that the given percentages
are only rough estimates as the criteria are not mutually exclu-
sive and exclusion decisions were often made on the grounds
of the most obvious criteria.
As an owner may run more than one website, we merge
sites sharing the same owner (co-owned sites) into one noti-
ﬁcation. To ﬁnd co-owned sites, we sort postal addresses by
ZIP code and manually merge sites with identical or similar
addresses (including recipient name). Addresses are deemed
similar if they show only a small variation (e. g., “Company”
vs. “Company LLC”). When the recipient or company name
differs, sites are not considered co-owned. We also merge
sites with identical contact email addresses.
After merging co-owned sites, we end up with 4754 sites
run by 4594 different owners. These websites were automati-
cally scanned four times a day during the study timeframe.
4.3 Notiﬁcation and Reminder
We assign sites randomly to groups deﬁned by three different
experimental factors and a control group. We use a full fac-
torial design (i. e., all combinations of factors are used), and
assign co-owned sites (cf. Section 4.2) to the same group. We
ensure that the different categories of sites (private, business,
etc.) are spread evenly across the groups (stratiﬁcation).
All messages were sent in German and contain a reference
to our self-service tool (cf. Section 4.4), referencing it as a
service that was unafﬁliated with the senders of the message,
and noting that it may prove helpful in validating the reme-
diation. Translated versions of our messages can be found in
the supplementary material [33].
Factors We differentiate between two different contact
media: LETTER and EMAIL. As many previous studies have
investigated the effect of emails, we choose to emphasize
letters in our study by assigning twice the number of websites
to the letter groups than the email groups. Emails are sent in
plain-text and contain the entire message in their body (no
attachments or external content like tracking pixels).
We compare three different senders: a private individual
(CITIZEN), a computer science group at one university (UNI-
CS), and a law group at another university (UNI-LAW). For the
two university groups, emails are sent from purpose-speciﬁc
accounts (notiﬁPI:EMAIL). Letters use the
ofﬁcial letterheads of the groups, including its return address.
Both emails and letters contain three options for contacting
the sender: a postal address, an email, and a phone number.
For the private sender, we use a fresh email account, and letters
use the residential address, but no phone number; assuming
citizens typically do not provide it.
In the messages, we used three different framings for the
problem. In the PRIVACY framing, we argue that the miscon-
ﬁguration was harmful to the privacy of website visitors, not
mentioning the legal consequences. In the GDPR framing, we
mention that the misconﬁguration is violating the GDPR. In
the GDPR+FINE framing, we use the same message, but addi-
tionally mention the ﬁnes that can be leveled against website
owners under the GDPR (i. e., up to 4 % of annual turnover).
Notiﬁcation, Reminder and Survey We sent up to three
messages to every recipient: An initial notiﬁcation, followed
by a reminder one month later (if the problem had not been
addressed), and a ﬁnal debrieﬁng message to all contacted
recipients a month later to inform them that they had been
part of a study, invite them to answer a survey, and give them
the opportunity to opt-out. If we received an indication that a
message was not deliverable on the selected contact medium
(e. g., a bounce message from a mail server or our letter being
returned), we excluded that recipient from further messages.
Due to human error, all UNI-LAW – LETTER reminders
were sent with the GDPR+FINE framing.We will discuss the
impact of this mistake in Section 5.1.2.
4.4 Self-Service Tool and Support
In previous studies, users wished for a self-service tool to
check for the reported issue [13, 31, 45]. Besides providing
such a tool, we also offer personal support.
Self-Service Tool We operate a web-based tool (CheckGA)
in disguise, i. e., not afﬁliated with CITIZEN, UNI-LAW, or UNI-
CS. Deceiving recipients about the tool’s operator increases
the trust in our notiﬁcations since recipients can verify the
claimed issue with a tool run by an independent, trustworthy
organization: a research group at a German university.
CheckGA allows anyone to analyze the usage of GA for
arbitrary websites. The tool has been written for this study and
not yet explicitly advertised to others. However, it is linked
from the website of a university chair that researches privacy
and security topics, increasing its trustworthiness and making
it indexable by search engines. Some recipients also shared
CheckGA on social media and forums.
Users enter a URL to scan, which is then visited by our com-
pliance checker (see Section 4.1). The user gets a report about
the included GA tracker objects, including trackers added by
third parties (e. g., due to widgets) and their conﬁguration,
such as whether IP Anonymization is enabled. The report also
shows all HTTP requests to the GA service, each with the
associated analytics data, as well as whether that request con-
tains the aip=1 parameter, i. e., Google truncates the visitor’s
IP address. The user gets a summary indicating that either ev-
erything is ﬁne (no GA found or IP Anonymization correctly
implemented) or pointing out the problem. CheckGA also
USENIX Association
30th USENIX Security Symposium    2493
assists users by providing a help page with extensive docu-
mentation, including common pitfalls and code examples.
For each scan, we store the URL of the site, the scan result,
the time of the scan, a truncated IP address, and the TLS
Session ID. The last two pieces of data allow us to link scans
of different websites conducted by the same user without
having to ask users for consent to set cookies. We informed
users before scanning that usage information is collected.
Support via Phone, Email, Letters
In addition to
CheckGA, we also answer phone calls, emails, and occasion-
ally letters from the contacted site owners, assuring them that
the messages are authentic, providing basic troubleshooting
advice where requested, and addressing complaints by some
recipients. These interactions are described in Section 5.3.
4.5 Survey
To investigate the site owners’ perspective, we invite all con-
tacted owners to participate in a survey after informing them
that their sites had been part of a study. The survey was hosted
on the platform soscisurvey and consists of an informed con-
sent form and questions regarding the perception of our no-
tiﬁcation, problem awareness, and solving. It also contains
questions about our and other check tools geared towards
system owners, asks if they would like to receive further noti-
ﬁcations, and collects basic information about the participants’
afﬁliation. The questions are tailored to the group of the par-
ticipants (medium, sender, framing, ﬁnal compliance status).
The survey includes between 17 and 21 questions, depending
on the group of the recipient and their replies. A translated
version of the survey can be found in the supplementary ma-
terial [33]. The responses are analyzed using SPSS. Open
answers are analyzed with qualitative content analysis. The
software MAXQDA was used for support. 561 owners took
part in our survey. We exclude 84 survey answers because the
participants either did not agree to the informed consent (N =
19) or answered less than 50 % of the questions (N = 65). 226
of the 477 participants completed the questionnaire.
4.6 Data Cleaning
After concluding the data collection, we found that some web-
sites frequently changed the domain they were forwarding to,
as they were run by advertising agencies that sold the incom-
ing trafﬁc to different customers over time. As our scans were
based on the URL before following all redirects, we were
redirected to different websites and thus do not have contin-
uous reliable data for the domain of the owner we notiﬁed.
We thus exclude 31 websites that forwarded to three or more
different domains within the study timeframe.
We also found that all sites hosted on the free tier of Word-
press.com contained a GA tracker managed by Wordpress. As
the owners of the 22 affected sites depended on a centrally-
administrated change from Wordpress.com1 and none of them
contained any additional trackers, we excluded them from
the evaluation. Finally, we remove another two domains from
the dataset that were incorrectly labeled as German but were,
in fact, run by non-German entities, and four domains from
owners that requested to be excluded from the study.
4.7 Survival Analysis
To evaluate the effectiveness of our notiﬁcations, we employ
survival analysis. Previously used by several studies in this
ﬁeld [12, 14, 30, 43, 45], survival analysis operates on data
where the event of interest (i. e., the website becoming com-
pliant) is still in the future at the time of the analysis (right-
censored data). Survival analysis uses estimators like the
Kaplan-Meier estimator [26], which gives us a survival func-
tion, i. e. a function S(t) that tells us the probability of a
misconﬁguration surviving past a speciﬁc time t. When it
comes to notiﬁcations, a low survival rate is desirable, as it
corresponds to a high remediation rate.
Our evaluation shows that co-owned websites (cf. Sec-
tion 4.2) tend to show similar remediation behavior. A more
detailed analysis is given in Appendix A2. To avoid a single
owner having a large inﬂuence on the results of a group, we
compensate for such groupings by using a weighted Kaplan-
Meier ﬁt [34]. Each website has a weight associated with it,
which is deﬁned as w = 1/|G|, where |G| denotes the num-
ber of websites run by the same owner, thus leading to each
owner having the same impact on the results, regardless of
the number of websites they operate. With these weights in
place, we ask “how did our message impact the owners” rather
than “how did our message impact the websites.” We use the
lifelines library [18] for our analysis.
We run the analysis on the data collected by our automated
scanning system that visited every website four times per day.
To avoid transient scan errors impacting the results, we con-
sider a website compliant once c consecutive readings indicate
it is either not using GA or using it with IP Anonymiza-
tion, ignoring readings that indicate that the website is ofﬂine
unless we obtain c consecutive ofﬂine readings. Ofﬂine sites
will be considered separately. The different website categories
(cf. Section 4.2) show similar behavior, so we do not consider
them further in the evaluation. For our evaluation, we set
c = 5, repeating the evaluation with c = 3 and c = 8 and ﬁnd-
ing equivalent results. Survival analysis can only work with
a single remediation event per subject, i. e., once a website
becomes compliant, the statistics assume it to remain so. We
will check whether this applies in Section 5.5.
We cannot use the standard log-rank signiﬁcance test usu-
ally recommended in survival analysis, as our dataset does
not fulﬁll the proportional hazard assumption. Instead we
1Wordpress.com remediated the misconﬁguration after communication
with one of the notiﬁed website owners.
2494    30th USENIX Security Symposium
USENIX Association
compare the functions at speciﬁc points in time (before the
reminders are sent, and at the end of the study), using a
log(−log(·))-transform, as described by Klein et al. [27], and
the Holm-Bonferroni multi-test correction [24].
4.8 Ethical Considerations
While our messages are intended to help the recipients avoid-
ing costly mistakes, processing of our messages takes time
and, in some cases, money and may cause stress for the own-
ers. We consider this risk acceptable, as the message does not
contain any demands or threats, and the changes shield the
operator from liability. The contact addresses are collected
from the imprint of the website, which is intended for this
purpose.
Our scans of the websites only require a normal page load
and thus should not put signiﬁcant strain on their infrastruc-
ture. CheckGA could potentially be used to identify targets
for cease-and-desist letters. Since the underlying detection
technology could be easily reimplemented by others, we con-
sider the beneﬁts to outweigh the potential harms of providing
such a dual-use system. The data protection compliance of the
CheckGA tool was ensured in consultation with legal experts.
While the ﬁrst two messages do not reveal that they are
sent as part of a study to avoid priming effects, we inform all
contacted website owners that they were part of a study. We
respect the wishes of four website owners to be removed from
the study. Members of the control group were informed before
this paper was published. The study was approved by the
ethics committee of two of the three involved institutions. The
third institution does not offer a process for ethics approval,
but we received approval from the dean of the department.
5 Results
We investigate the impact of notiﬁcations, the use of
CheckGA, our interactions with owners, and long-term ef-
fects. A detailed discussion in relation to the survey results
(cf. Section 6) follows in Section 7.
5.1 Notiﬁcations
We present the impact of the notiﬁcations on the different
groups, using survival analysis (cf. Section 4.7).
5.1.1 Initial Notiﬁcation
The ﬁrst set of notiﬁcations was sent from July 1st to 5th,