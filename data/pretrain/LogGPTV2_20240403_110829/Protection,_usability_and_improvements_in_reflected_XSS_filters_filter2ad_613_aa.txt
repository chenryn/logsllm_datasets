title:Protection, usability and improvements in reflected XSS filters
author:Riccardo Pelizzi and
R. Sekar
Protection, Usability and Improvements
in Reﬂected XSS Filters∗
Riccardo Pelizzi
Stony Brook University
PI:EMAIL
R. Sekar
Stony Brook University
PI:EMAIL
ABSTRACT
Due to the high popularity of Cross-Site Scripting (XSS)
attacks, most major browsers now include or support ﬁlters
to protect against reﬂected XSS attacks. Internet Explorer
and Google Chrome provide built-in ﬁlters, while Firefox
supports extensions that provide this functionality. In this
paper, we analyze the two most popular open-source XSS
ﬁlters, XSSAuditor for Google Chrome and NoScript for
Firefox. We point out their weaknesses, and present a new
browser-resident defense called XSSFilt.
In contrast with
previous browser defenses that were focused on the detec-
tion of whole new scripts, XSSFilt can also detect partial
script injections, i.e., alterations of existing scripts by inject-
ing malicious parameter values. Our evaluation shows that
a signiﬁcant fraction of sites vulnerable to reﬂected XSS can
be exploited using partial injections. A second strength of
XSSFilt is its use of approximate rather than exact string
matching to detect reﬂected content, which makes it more
robust for web sites that employ custom input sanitizations.
We provide a detailed experimental evaluation to compare
the three ﬁlters with respect to their usability and protec-
tion.
Categories and Subject Descriptors
D.4.6 [Security And Protection]: Information Flow Con-
trols
1.
INTRODUCTION
Cross-site scripting (XSS) has emerged as one of the most
serious threats on the Web. CWE/SANS Top-25 [25] lists
XSS fourth in its list of “Top 25 Most Dangerous Software
Errors,” while the web-application focused OWASP [26] lists
XSS second in its list of top-10 security risks.
In terms
of raw numbers, it is one of the most commonly reported
∗This work was supported in part by an NSF grant CNS-
0831298, an AFOSR grant FA9550-09-1-0539, and an ONR
grant N000140710928.
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
ASIACCS ’12, May 2–4, 2012, Seoul, Korea.
Copyright 2012 ACM 978-1-4503-1303-2/12/05 ...$10.00.
vulnerabilities in 2011, accounting for 14.7% of all reported
CVE vulnerabilities.
The increase in prevalence and severity of XSS attacks has
spawned several research eﬀorts into XSS defenses. Many of
these eﬀorts [12, 13, 15, 27, 11, 28, 3, 23] have focused on the
server-side, and attempt to detect (or prevent) unauthorized
scripts from being included in the server output. Modern
web-browsers incorporate very complex logic to “ﬁx” HTML
syntax errors and hence provide an acceptable rendering of
syntactically incorrect pages. Several researchers [11, 15,
27, 13] have eloquently argued that no server-side logic can
accurately account for all such “browser quirks.” As a result,
hybrid approaches that combine client-side support with a
primarily server-side XSS defense have been developed [27,
15, 23].
Since XSS is a server-side vulnerability, it seems natural
to employ a server-side defense. Unfortunately, the party
that is most directly aﬀected by an XSS attack is a browser-
user that accesses a vulnerable server. Consequently, there
may not be enough of an incentive for some web sites to
implement XSS defenses — this is one reason why XSS vul-
nerabilities are so easy to ﬁnd. Client-side protections are
thus desirable, despite their limitation to so-called reﬂected
XSS: in these attacks, the output of a vulnerable server in-
cludes some script content provided in a malicious request.
Reﬂected XSS attacks are launched via invalid (and ma-
licious) values for parameters in a HTTP request. Conse-
quently, NoScript1, a Firefox plug-in, defends against these
attacks by ﬁltering out parameter values that look suspi-
cious. Speciﬁcally, it uses regular expressions to identify the
presence of JavaScript code in HTTP request parameters,
and sanitizes them before submitting the request.
An important diﬃculty with NoScript’s approach (of client-
side parameter sanitization) is that it should work without
any knowledge about how a server may use a parameter. In
particular, it needs to prevent XSS attacks regardless of how
the server-side may use a parameter value. This may lead to
overly strict ﬁltering that can prevent some web pages from
being used, or interfere with their functionality. In contrast,
an approach that can examine both the request and the re-
sponse from the server can be more discriminating about
1NoScript is mainly thought of as a tool that blocks the ex-
ecution of scripts from most sites. However, blocking script
execution is not a realistic option for web sites trusted by
a user, which will be the ones targeted in a reﬂected XSS.
For this reason, NoScript also contains a client-side XSS ﬁl-
ter that sanitizes requests submitted by the browser. From
here on, we will refer to this XSS ﬁlter when we use the term
“NoScript ﬁlter.”
d oc u me n t . write (
’ " >  ’ );
id :
’); do_xss(); document.write(’
Figure 1: An example server-side script (abstracted from the popular SquirrelMail web-based email program)
with partial injection vulnerability (left) and a malicious parameter value to exploit it (right).
which requests are unsafe. Microsoft’s IE8 uses such an ap-
proach for client-side XSS defense. It ﬁrst marks requests
that look suspicious. Responses to such requests are then
scanned for script content that may be derived from sus-
picious parameters, and this content is then “sanitized” to
prevent its interpretation as a script.
Unfortunately, identiﬁcation of unsafe content is very hard
because of a browser’s HTML parsing quirks. Researchers
have shown [16] that there are several ways to bypass de-
tection by IE8 ﬁlter. Worse, the sanitization technique used
in IE8 could be exploited [17] to perpetrate XSS attacks on
some sites that weren’t previously vulnerable! In particu-
lar, the sanitization technique caused some other part of the
page that was previously interpreted as passive content to be
interpreted as a script. Although the speciﬁc vulnerability
reported in [17] has been ﬁxed, the nature of their architec-
ture makes it diﬃcult to rule out similar vulnerabilities in
the future.
Google Chrome’s XSSAuditor [3] is based on the same
approach, but employs a diﬀerent architecture that avoids
“browser quirks” problem by directly interposing at the Java-
Script engine interface. Consequently, XSSAuditor does not
rely on guess work, but gets to examine content that is ac-
tually interpreted as a script. If this script “resembles” a re-
quest submitted by the browser, XSSAuditor skips its execu-
tion. This simple approach avoids IE8’s sanitization pitfall,
since preventing the execution of a script does not change
the interpretation of the rest of the page. Moreover, this
new architecture can address DOM-based XSS vulnerabili-
ties that can arise in pages which are created dynamically as
the result of client-side script execution. (With the advent
of Web 2.0, such dynamic pages are increasingly becoming
the norm.)
1.1 Limitations of existing ﬁlters
Although XSSAuditor overcomes the main drawbacks of
the IE8 ﬁlter, it does not address the following problems:
• Whole Vs partial script injection: XSSAuditor is geared
towards detecting the most common form of XSS, where
an entire script is injected into a victim page. However,
damage can also be eﬀected by altering the structure of
an existing script. Figure 1 shows an example abstracted
from the web application SquirrelMail, where a GET pa-
rameter named id is inserted into a document.write call
in an existing script (left frame). Even though the intent
of the developers is to dynamically write an anchor tag,
the logic can be subverted to inject arbitrary JavaScript
code. Note the similarity of the malicious input (right
frame) with those used in SQL injections: ﬁrst, the string
argument previously opened by benign code is closed;
then the payload is inserted; ﬁnally, tokens are inserted
to synchronize the syntax with the rest of the benign
script and thus avoid syntax errors. In nearly all cases
(including the example presented), the vulnerability al-
lows for arbitrary code injection into the existing script,
thus being as severe as a whole script injection.
These sorts of vulnerabilities arise naturally in template-
based web application development frameworks and in
dynamic web applications in general. Our experimental
results (see Section 7) demonstrate that partial injection
vulnerabilities are common, accounting for 8% and 18%
respectively in two collections of vulnerabilities. More-
over, as the ﬁrst generation client-side defenses (against
whole-script injection) get deployed, attackers are bound
to try evading them through partial script injections.
• Accurate algorithms for detecting injections: XSSAudi-
tor uses an exact string matching algorithm to detect
components of a web application’s output that have been
derived from the input request. Character encoding and
sanitizations incorporated into typical web applications
are performed before string matching. However, this ap-
proach does not handle application-speciﬁc sanitizations
that may take place. A more systematic approach would
rely on approximate string matching in order to (a) bet-
ter cope with application-speciﬁc sanitizations, and (b) to
more precisely identify the beginning and end of injected
strings in the presence of sanitizations.
NoScript’s approach suﬀers from a diﬀerent set of problems:
• False positives: since NoScript sanitizes outgoing requests
rather than incoming responses, it cannot conﬁrm whether
the oﬀending content actually appears in the response,
let alone whether it leads to the execution of JavaScript
code. These ﬁlters, in eﬀect, have to be stringent enough
to handle the worst-case server behavior. Hence NoScript
can have a higher rate of false positives, a result conﬁrmed
by our experiments.
• Complex Policies: NoScript’s detection is largely based
on regular expressions. Unfortunately, covering all cor-
ner cases while avoiding false positives requires very com-
plex detection logic. Manual analysis of NoScript’s code
revealed more than 40 non-trivial regular expressions in-
volved in detection and sanitization of XSS attacks. Clearly,
these can be very cumbersome to maintain.
• Usability Impact: NoScript’s false positives normally cause
more disruption to users compared to XSSAuditor. Since
NoScript sanitizes the outgoing request URL, the browser
may end up making a request with very diﬀerent set
of parameter values. These new parameter values can
cause the request to fail on the server side, corrupt data
that is stored on the server-side, or return an incorrect
page. In contrast, XSSAuditor only prevents the oﬀend-
ing script from executing, and this can impact dynami-
cally constructed elements such as advertisements, com-
ment frames, etc, but will usually not prevent the main
content of the page from being displayed.
Figure 2: XSSFilt architecture
1.2 Overview of XSSFilt and Contributions
strings that matched its regular expressions.
We present XSSFilt, a new client-side XSS defense that
addresses the above-mentioned drawbacks of previous ﬁlters.
In particular, this paper makes the following contributions:
• In Section 3, we present the architecture of XSSFilt, a
browser-resident XSS defense. Unlike previous browser-
resident defenses that all relied on exact string match-
ing, XSSFilt uses approximate string matching. (See Sec-
tion 4.) This enables our defense to cope with web appli-
cations that perform application-specﬁc sanitizations.
• In Section 5, we present a set of policies to detect XSS
attacks. These policies detect attacks involving injection
of whole scripts, or those occurring due to injection of
parameters within scripts (partial injections).
• We present a discussion of the full range of attacks pos-
sible on XSSFilt, and ensure that our design can success-
fully defend against these attacks (see Section 6).
• In Section 7, we present a comparative study of the pro-
tection and usability of XSSFilt (implemented for the lat-
est development version of Firefox), XSSAuditor (readapted
for Firefox) and NoScript (XSS ﬁlter only). In particular,
our evaluation shows:
– the importance of addressing partial script injections,
which accounted for 8% of the 400 vulnerabilities we
studied from xssed.com, and 18% of the 10K vulnera-
bilities we discovered on the web using an XSS vulner-
ability discovery tool that we built.
– that scripts generated dynamically from input param-
eters, the necessary condition for partial script injec-
tions, are commonplace. Our results suggest that more
than 9% of web pages contain dynamic scripts.
– the beneﬁts of using an approximate string matching
algorithm over the exact matching algorithm employed
by XSSAuditor: our false negatives were decreased
ﬁve-fold due to approximate matching.
– that false positives generated by XSSAuditor and XSS-
Filt are more likely to be symptoms of underlying injec-
tion vulnerabilities rather than mere annoyances: 85%
of the false positives reported by XSSFilt were in fact
caused by an underlying XSS vulnerability. On the
other hand, all NoScript false positives were benign
2. BACKGROUND ON XSS ATTACKS
This section provides a short overview of XSS attacks, and
may be skipped by readers that are very familiar with them.
An XSS attack involves three entities: a web-site that has
an XSS vulnerability, a legitimate user of this web-site, and
the attacker. The attacker’s goal is to be able to perform
sensitive operations on the web-site using the credentials of
the legitimate user.
Although an attacker is able to run her code on the user’s
browser, the same-origin policy (SOP) of the browser pre-
vents her code from stealing the user’s credentials, or observ-
ing any data exchanged between the user and the web-site.
To overcome this restriction, the attacker needs to inject her
code into a page returned by the web-site to the user. An
XSS vulnerability in the web-site allows this to happen.
Exploiting an XSS vulnerability involves three steps. First,
the attacker uses some means to deliver her malicious pay-
load to the vulnerable web-site. Second, this payload is used
by the web site during the course of generating a web page
(henceforth called a victim page) sent to the user’s browser.
The left side of Figure 1 shows an example of a vulnerable
page that uses a user-supplied parameter id to construct
the href parameter via document.write, while the right
side shows an example payload. In this case, the payload
does not need to open a new script tag because it is already
contained in one; rather, it closes the string where the pa-
rameter is supposed to be conﬁned and writes additional
JavaScript code.
If the web site is not XSS-vulnerable, it would either dis-
card the malicious payload, or at least ensure that it does
not contribute to code content in its output. However, if the
site is vulnerable, then, in the third step, the user’s browser
would end up executing attacker-injected code in the page
returned by the web site.
In a reﬂected XSS attack, an attacker lures a user to the
attacker’s web page, or to click on a link in an email. At
this point, the user’s browser launches a GET (or, in some
cases, POST) request with attacker-chosen parameter val-
ues. When a vulnerable web site uses these parameters in
the construction of its response (e.g., it echoes these param-
eters into the response page without adequate sanitization),
XSSFiltComponentDocument InitializationHTML ParserJavaScript EngineScript NodeText NodeSearch paramsParse HeadersParse URLBrowserInternetDocument URLPost DataScript ContentScript URL1234InitPermits5678910RequestServerthe attacker’s code is able to execute on this response page.
3. XSSFilt OVERVIEW
To illustrate XSSFilt’s design, consider the sequence of
operations that take place from the time the user’s browser
submits a request to a web server to the time the web page
loads. The steps in this sequence are identiﬁed using num-
bers in Figure 2, and we describe them in more detail below.
In Step 1, the browser submits a request to a web site.
This submission may be in response to a user clicking on a