Network Model. Consider a peer-to-peer network with n nodes who establish identities (i.e., pub-
lic/private keys) through a Sybil-resistant identity generation mechanism such as that of [7], which
requires every node to solve a computationally-hard puzzle on their locally-generated identities (i.e.,
public keys) veriﬁed by all other (honest) nodes without the assumption of a trusted randomness
beacon. Without loss of generality and similar to most hybrid blockchain protocols [23, 56, 47, 42],
we assume all participants in our consensus protocol have equivalent computational resources.
We assume all messages sent in the network are authenticated with the sender’s private key.
The messages are propagated through a synchronous gossip protocol [36] that guarantees a message
sent by an honest node will be delivered to all honest nodes within a known ﬁxed time, ∆, but
the order of these messages is not necessarily preserved. This is the standard synchronous model
adopted by most public blockchain protocols [47, 32, 42, 4]. We require synchronous communication
9
only during our intra-committee consensus. In other parts of our protocol, we assume partially-
synchronous channels [20] between nodes with exponentially-increasing time-outs (similar to [42])
to minimize latency and achieve responsiveness.
Threat Model. We assume nodes may disconnect from the network during an epoch or between
two epochs due to any reason such as internal failure or network jitter. We also consider a proba-
bilistic polynomial-time Byzantine adversary who corrupts t < n/3 of the nodes at any time. The
corrupt nodes not only may collude with each other but also can deviate from the protocol in any
arbitrary manner, e.g., by sending invalid or inconsistent messages, or remaining silent. Similar
to most committee-based protocols [23, 41, 56, 42, 4], we assume the adversary is slowly adaptive,
meaning that it is allowed to select the set of corrupt nodes at the beginning of the protocol and/or
between each epoch but cannot change this set within the epoch.
At the end of each epoch, the adversary is allowed to corrupt a constant (and small) number of
uncorrupted nodes while maintaining their identities. In addition, the adversary can run a join-leave
attack [25, 8], where it rejoins a constant (and small) number of corrupt nodes using fresh identities
in order to compromise one or more committees. However, at any moment, at least a 2/3 fraction
of the computational resources belong to uncorrupted participants that are online (i.e., respond
within the network time bound). Finally, we do not rely on any public-key infrastructure or any
secure broadcast channel, but we assume the existence of a cryptographic hash function, which we
model as a random oracle for our security analysis.
Problem Deﬁnition. We assume a set of transactions are sent to our protocol by a set of users
that are external to the protocol. Similar to Bitcoin [54], a transaction consists of a set of inputs
and outputs that reference other transactions, and a signature generated by their issuer to certify
its validity. The set of transactions is divided into k disjoint blocks. Let xi, j represent the j-th
transaction in the i-th block. All nodes have access to an external function ❕ that, given any
transaction, outputs 0 or 1 indicating whether the transaction is invalid or not respectively, e.g., the
sum of all outputs of a transaction is equal to the sum of its inputs. The protocol Π outputs a set
X containing k disjoint subsets or shards Xi = {xi, j}, for every j ∈ {1..|Xi|} such that the following
conditions hold:
• Agreement: For every i ∈ {1..k}, Ω(log n) honest nodes agree on Xi with a high probability of at
least 1 − 2−λ, where λ is the security parameter.
• Validity: For every i ∈ {1..k} and j ∈ {1..|Xi|}, ❕(xi, j) = 1.
• Scalability: k grows linearly with n.
• Eﬃciency: The per-node communication and computation complexity is o(n) and the per-node
storage complexity is o(s), where s is the total number of transactions.
4 Our Protocol
In this section, we present RapidChain in detail. We start by deﬁning notations and terms used in
the rest of the paper.
Notation and Terminology. Let n denote the total number of nodes and t < n/3 denote the total
number of corrupt nodes. We say an event occurs with high probability meaning that it occurs with
probability 1 − O(1/2λ), where λ is the security parameter. We refer to any set of m = o(n) nodes
as a committee if at least an f < 1/2 fraction of its members belongs to honest nodes. Let node P
10
be a member of a group C. We refer to other members of C as the neighbors of P in C. When we
say a committee runs a protocol, we mean all honest members of the committee participate in an
execution of the protocol. Let C1, C2 be two committees. When we say C1 sends a message M to
C2, we mean every honest member of C1 sends M to every member of C2 who he knows. Since each
member of C2 may receive diﬀerent messages due to malicious behavior, it chooses the message with
a frequency of at least 1/2 + 1.
4.1 Design Components
RapidChain consists of three main components: Bootstrap, Consensus, and Reconﬁguration. The
protocol starts with Bootstrap and then proceeds in epochs, where each epoch consists of multiple
iterations of Consensus followed by a Reconﬁguration phase. We now explain each component in
more details.
Bootstrapping. The initial set of participants start RapidChain by running a committee election
protocol, where all nodes agree on a group of O(√
n) nodes which we refer to as the root group.
The group is responsible for generating and distributing a sequence of random bits that are used to
establish a reference committee of size O(log n). Next, the reference committee creates k committees
{C1, ..., Ck} each of size O(log n). The bootstrap phase runs only once at the start RapidChain.
Consensus. Once members of each committee are done with the epoch reconﬁguration, they wait
for external users to submit their transactions. Each user sends its transactions to a subset of nodes
(found via a P2P discovery protocol) who batch and forward the transactions to the corresponding
committee responsible for processing them. The committee runs an intra-committee consensus
protocol to approve the transaction and add it to its ledger.
Reconﬁguration. Reconﬁguration allows new nodes to establish identities and join the existing
committees while ensuring all the committees maintain their 1/2 resiliency.
In Section 4.6, we
describe how to achieve this goal using the Cuckoo rule [62] without regenerating all committees.
In the following, we ﬁrst describe our Consensus component in Section 4.3 assuming a set of
committees exists. Then, we describe how cross-shard transactions can be veriﬁed in Section 4.4,
and how committees can communicate with each other via an inter-committee routing protocol in
Section 4.5. Next, we describe the Reconﬁguration component in Section 4.6, and ﬁnally, ﬁnish this
section by describing how to bootstrap the committees in Section 4.2.
4.2 Decentralized Bootstrapping
Inspired by [40], we ﬁrst construct a deterministic random graph, referred to as the sampler graph,
which allows sampling a number of groups such that the distribution of corrupt nodes in the majority
of the groups is within a δ fraction of the number of corrupt nodes in the initial set. At the
bootstrapping phase of RapidChain, a sampler graph is created locally by every participant of the
bootstrapping protocol using a hard-coded seed and the initial network size which is known to all
nodes since we assume the initial set of nodes have already established identities.
Sampler Graph. Let G(L, R) be a random bipartite graph, where the degree of every node in R
is dR = O(√
n). For each node in R, its neighbors in L are selected independently and uniformly at
random without replacement. The vertices in L represent the network nodes and the vertices in R
represent the groups. A node is a member of a group if they are connected in graph G. Let T ⊆ L be
the largest coalition of faulty nodes and S ⊆ R be any subset of groups. Let E(T , S) denote the event
that every group in S has more than a |T |
|L| + δ fraction of its edges incident to nodes in T . Intuitively,
11
E captures the event that all groups in S are “bad”, i.e., more than a |T |
|L| + δ fraction of their parties
are faulty.
In Section 6.4, we prove that the probability of E(T , S) is less than 2e(|L|+|R|) ln 2−δ 2dR |S |/2. We
choose practical values for |R| and dR such that the failure probability of our bootstrap phase, i.e.,
the probability of E(T , S), is minimized. For example, for 4,000 nodes (i.e., |L| = 4,000), we set
dR = 828 (i.e., a group size of 828 nodes) and |R| = 642 to get a failure probability of 2−26.36. In
Section 6.1, we use this probability to bound the probability that each epoch of RapidChain fails.
Once the groups of nodes are formed using the sampler graph, they participate in a randomized
election procedure. Before describing the procedure, we describe how a group of nodes can agree
on an unbiased random number in a decentralized fashion.
Subgroup Election. During the election, members of each group run the DRG protocol to generate
a random string s and use it to elect the parties associated with the next level groups: Each node
with identiﬁcation ID computes h = H(s||ID) and will announces itself elected if h <= 2256−e, where
H is a hash function modeled as a random oracle. All nodes sign the (ID, s) of the e elected nodes
who have the smallest h and gossip their signatures in the group as a proof of election for the elected
node. In practice, we set e = 2.
Subgroup Peer Discovery. After each subgroup election, all nodes must learn the identities of
the elected nodes from each group. The elected nodes will gossip this information and a proof, that
consists of dR/2 signature on (ID, s) from diﬀerent members of the group, to all the nodes. If more
than e nodes from the group correctly announce they got elected, the group is dishonest and all
honest parties will not accept any message from any elected members of that group.
Committee Formation. The result of executing the above election protocol is a group with honest
majority whom we call root group. Root group selects the members of the ﬁrst shard, reference shard.
The reference committee partitions the set of all nodes at random into sharding committees which
are guaranteed to have 1/2 honest nodes, and which store the shards as discussed in Section 4.4.
Election Network. The election network is constructed by chaining (cid:96)
sampler graphs
{G(L1, R1), ..., G(L(cid:96), R(cid:96))} together. All sampler graphs deﬁnitions are included in the protocol speci-
ﬁcation. Initially, the n nodes are in L1. Based on the edges in the graph, every node is assigned
to a set of groups in R1. Then, each group runs a subgroup election protocol (described below) to
elect a random subset of its members. The elected members will then serve as the nodes in L2 of
G(L2, R2). This process continues to the last sampler graph G(L(cid:96), R(cid:96)) at which point only a single
group is formed. We call the last group, the leader group and we construct the election network
such that the leader group has honest majority with high probability.
To construct the election network, we set
|Li| =(cid:6)|Li−1|αi +βiγi(cid:7) , |Ri| = (cid:100)|Li|αi(cid:101) ,
(1)
where |L1| = n, |R1| = nαi , 0 < αi , βi , γi < 1, and i = {2, ..., (cid:96)}. It can be easily shown that for some
constant (cid:96), |R(cid:96)| = 1. From Equation 3, we can bound the error probability for every level i of the
election network denoted by pi, where
pi ≤ 2e
|Li |+|Ri |−δ 2dRi |Si |/2.
(2)
In Section 6.4, we discuss how the parameters α, β and γ are chosen to instantiate such an election
graph and present a novel analysis that allows us to obtain better bounds for their sizes.
12
Figure 1: The election network
4.3 Consensus in Committees
Our intra-committee consensus protocol has two main building blocks: (1) A gossiping protocol to
propagate the messages (such as transactions and blocks) within a committee; (2) A synchronous
consensus protocol to agree on the header of the block.
4.3.1 Gossiping Large Messages
Inspired by the IDA protocol of [5], we refer to our gossip protocol for large messages as IDA-Gossip.
Let M denote the message to be gossiped to d neighbors, ϕ denote the fraction of corrupt neighbors,
and κ denote the number of chunks of the large message. First, the sender divides M into (1 − ϕ)κ
equal-sized chunks M1, M2, . . . , M(1−ϕ)κ and applies an erasure coding scheme (e.g., Reed-Solomon
erasure codes [59]) to create an additional ϕκ parity chunk to obtain M1, M2, . . . , Mκ. Now, if the
sender is honest, the original message can be reconstructed from any set of (1 − ϕ)κ chunks.
Next, the sender computes a Merkle hash tree with leaves M1, . . . Mκ. It then gossips Mi and the
corresponding Merkle proof, for all 1 ≤ i ≤ κ, by sending a unique set of κ/d chunks (assuming κ is
divisible by d) to each of its d neighbors. The neighbors then gossip the chunks to their neighbors
and so on. Each node veriﬁes the message it receives using the Merkle proof and the Merkle root.
Once a node receives (1 − ϕ)κ valid chunks, it reconstructs the message M, e.g., using the decoding
algorithm of Berlekamp and Welch [10].
Our IDA-Gossip protocol is not a reliable broadcast protocol as it cannot prevent equivocation
by the sender. Nevertheless, IDA-Gossip requires much less communication and is faster than
reliable broadcast protocols (such as [14]) to propagate large blocks of transactions (about 2 MB in
RapidChain). To achieve consistency, we will later run a consensus protocol only on the root of the
Merkle tree after gossiping the block.
Improvement via Sparsiﬁcation. Let h(Mi) denote the hash of Mi, and h(Mi , Mj) denote the digest
stored at the ﬁrst common parent of Mi and Mj. Let Sib(Mi) denote all sibling nodes of the nodes
on the path from the root to Mi. Thus, {h(Mi), h(M1, Mκ), Sib(Mi)} is the Merkle proof to verify
the validity of Mi. We further optimize the IDA-Gossip based on the observation that if the source
sends Sib(Mi) to Pi for every i, the Merkle hashes near the root of the tree are sent to almost all
the nodes. For example, half of the nodes receive h(M1, Mκ/2). Instead, for any intermediate digest
h(Mi , Mj), it is suﬃcient to send it to a smaller subset of the nodes.
In RapidChain, the source chooses a random subset of size (1 − ϕ)d of its neighbors and sends
the digest only to the nodes in that subset. We refer to this process as sparsiﬁcation. As a result,
13
Level 0Level 1Level 2Level 3SubgroupGroupNodesElection NetworkRoot groupa node may receive a message from the source that does not contain all of the digests needed to
verify the validity of the gossiped message. Therefore, the node may not be able to validate the
message immediately. However, since at least one honest node receives each intermediate digest,
it will forward the digest. This guarantees that all the node will have all the correct intermediate
digests.
In Section 6.2, we show that if an honest node starts the IDA-Gossip protocol for message M in
a committee, all honest nodes in that committee will receive M correctly with high probability. We
also show that, using sparsiﬁcation, it suﬃces to send each intermediate digest to a number of node
sublinear in the depth of the tree. This guarantees that all nodes can verify the message with high
probability.
4.3.2 Remarks on Synchronous Consensus
In RapidChain, we use a variant of the synchronous consensus protocol of Ren et al. [60] to achieve
optimal resiliency of f < 1/2 in committees and hence, allow smaller committee sizes with higher to-
tal resiliency of 1/3 (than previous work [47, 42]). Unlike asynchronous protocols such as PBFT [20],
the protocol of Ren et al. [60] (similar to most other synchronous protocol) is not responsive [56]
meaning that it commits to messages at a ﬁxed rate (usually denoted by ∆) and thus, its speed is
independent of the actual delay of the network.
Most committee-based protocols (such as [4]) run a PBFT-based intra-committee consensus
protocol, and hence, are responsive within epochs. However, this often comes at a big cost that
almost always results in signiﬁcantly poor throughput and latency, hindering responsiveness anyway.
Since asynchronous consensus requires t < n/3, one needs to assume a total resiliency of roughly
1/5 or less to achieve similar committee size and failure probability when sampling a committee
with 1/3 resiliency (see Figure 7). Unfortunately, increasing the total resiliency (e.g., to 1/4)
will dramatically increase the committee size (e.g., 3-4x larger) making intra-committee consensus
signiﬁcantly ineﬃcient.
In RapidChain, we use our synchronous consensus protocol to agree only on a digest of the block
being proposed by one of the committee members. As a result, the rest of our protocol can be
run over partially-synchronous channels with optimistic timeouts to achieve responsiveness (similar
to [42]). In addition, since the synchronous consensus protocol is run among only a small number
of nodes (about 250 nodes), and the size of the message to agree is small (roughly 80 bytes), the
latency of each round of communication is also small in practice (about 500 ms – see Figure 4–left)
resulting in a small ∆ (about 600 ms) and a small epoch latency.
To better alleviate the responsiveness issue of synchronous consensus, RapidChain runs a pre-
scheduled consensus among committee members about every week to agree on a new ∆ so that the
system adjusts its consensus speed with the latest average delay of the network. While this does
not completely solve the responsiveness problem, it can make the protocol responsive to long-term,
more robust changes of the network as technology advances.
Another challenge in using a synchronous consensus protocol happens in the cross-shard trans-
action scenario, where a malicious leader can deceive the input committee with a transaction that
has been accepted by some but not all honest members in the output committee. This can happen
because, unlike asynchronous consensus protocols such as PBFT [20] that proceed in an event-driven
manner, synchronous consensus protocols proceed in ﬁxed rounds, and hence, some honest nodes
may terminate before others with a “safe value” that yet needs to be accepted by all honest nodes
in future iterations before a transaction can be considered as committed.
14
4.3.3 Protocol Details