tion on them and thus prolong their prevalence.
In this section, we briefly introduce two methods that can
be used by malware to detect remote virtualized hosts. We
found that it is possible to accurately detect a remote VM
host by sending a few hundreds SYN packets, even when
network delays are as high as 300ms. Our method can even
differentiate among different VMM types, namely VMware
and Xen, which could be potentially used to exploit differ(cid:173)
ent vulnerabilities on each VMM system.
4.2.1 Remote Timing Test
The TCP timestamp option [16] is intended to improve
high-performance, high-bandwidth connections by giving
the sender a more accurate way to measure RTT (round
trip time). A TCP timestamp clock increases monotonically
with fixed frequency (FREQ) between 1Hz and 1000Hz.
TCP timestamp was first exploited by Kohno et ale [21] as
a convert channel to reveal a target host's physical clock
skew, which uniquely identifies a physical machine.
Our observation is that virtualized hosts have a more per(cid:173)
turbed clock skew behavior (visualized in Figure 1). The
difference in randomness is because OSes running on plain
machines keep accurate timing by receiving regular hard(cid:173)
ware interrupts generated by hardware oscillators, while
guest OSes rely on VMM-generated software interrupts,
which can be lost or delayed. We use this discrepancy to
detennine whether the target is running on a VM. We fol(cid:173)
low two steps to remotely measure randomness:
Determining TCP Clock Frequency: There are only a
few common TCP clock frequencies; Windows hosts ex(cid:173)
hibit a clock frequency of 10Hz, while most new distribu(cid:173)
tions of Linux exhibit clock frequencies of 100Hz, 250Hz,
etc. To determining a target host's TCP clock frequency,
for each TCP packet from the target host, we record our
system time t when the packet is received and the TCP
timestamp T stored in the option field. By taking two
packets separated by a few seconds, we can estimate how
quickly the TCP timestamp is incremented by calculating
F = (T1 - T2)/(tl - t2) and truncating it to the nearest
possible TCP clock frequency. We find this method works
for all tested operating systems running on both plain ma(cid:173)
chines and VMs.
Characterizing Randomness: For any packet from the tar(cid:173)
get host, we consider its TCP timestamp Ti and the time we
receive it ti. Given that we have the TCP clock frequency
F REQ, we can transform the TCP timestamps into clock
readings. Given a timestamp Ti , the time elapsed since the
- To)/F REQ seconds.
first packet should be roughly (Ti
Then, we have two clocks to look at: 1) Xi = (ti - to) which
is the time elapsed locally 2; 2) Wi = (Ti - To)/F REQ,
which is the time elapsed on the target host. We can plot
(Xi, Yi), where Yi = Xi - Wi is the clock skew. Since the
two clocks come from different physical devices, the clock
skew (Yi) becomes greater as time passes, as shown in Fig(cid:173)
ure 1.
We use linear least squares fitting to get a line ! (x) =
Sx + q. We then quantify the deviation of each point from
this line using the squared error (SE): SEi = [!(Xi) -Yi]2.
Correspondingly, the sample mean of BE (MBE) is calcu-
lated as BE = Ei [!(Xi)-Yi]2 which we use as the random-
ness indicator.
To obtain TCP packets, we actively initiate TCP connec(cid:173)
tions to a few known ports -
port 22 for Linux standard
ssh service and 3389 for Windows remote desktop ser(cid:173)
vice. Each new TCP connection gives us one TCP times(cid:173)
tamp sample. We stop probing when the samples give a
converged linear least squares fit ! (x). All our experiments
finish within a few minutes, even when probing at a very
slow rate of one connection per second. Passive sniffing is
a better choice, if we have access to a machine within the
same subnet of the target host.
N
'
After obtaining the randomness indicator M BE from a
remote host, we compare it with the baseline values from
as installed on plain machines. For Linux machines, we
have a theoretical estimate of MSE. We examined var(cid:173)
ious versions of the Linux kernel source and found TCP
timestamps are a simple truncation of the hardware clock
using F REQ, so the TCP timestamp is updated exactly
every h = 1/F REQ seconds. The deviation of the TCP
clock to real clock should ideally be unifonnly distributed
across [-h/2, h/2]. Thus the mean of the theoretical error
should be J-LSE = -h/~
= ~2. For Linux hosts with
F REQ = 250Hz and F REQ = 1000Hz, the theoreti(cid:173)
cal mean for BE should be 1.33ms2 and O.083ms2 respec(cid:173)
tively. Various experiments have verified that this estimate
is very accurate. Also, we found that the randomness in net(cid:173)
work delay within a short period is usually not large enough
to cause a significant increase in M BE.
Jh/2 x 2dx
2
2We assume the local system clock is accurate because it can achieve a
IJ.Ls accuracy - much finer-grained than TCP clocks.
1-4244-2398-9/08/$20.00 ©2008 IEEE
182
DSN 2008: Chen et al.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 13:21:55 UTC from IEEE Xplore.  Restrictions apply. 
International Conference on Dependable Systems & Networks: Anchorage, Alaska, June 24-27 2008
-5'----------'-----------'---------L--"------------"-----------'--------I---'--~-----'
o
10
30
20
60
TIme since start of measurement (seconds)
40
60
70
50
-100
'--------'------'-loo----'---I50-200--'---2.L.....
0
50
Time since start of measurement (seconds)
-----.J3OQ'------------'-350--"-4oo-----..J
450
(a) Clock skew ofa Linux host (1000Hz)
(b) Clock skew ofa Linux on VMware (250Hz)
Figure 1. Clock skew of Linux hosts on a plain machine and a VM.
For Windows, we have no access to the source code, so
we do not know how the TCP timestamps are generated.
Therefore, we measured the BE of clock skew from Win(cid:173)
dows hosts and came up with an empirical value. It turns out
that the M BE is roughly 1667ms2 for Windows running
exactly twice as large as the theoreti(cid:173)
on plain machines -
cal value of 1/(102 *12) = 833ms2
, like because Windows
generates TCP timestamps using a proprietary algorithm. In
our experiments we use 1667ms2 as the baseline for Win(cid:173)
dows installed on plain machines.
Fingerprinting a remote host is simply done by compar(cid:173)
ing the randomness indicator MBE with baseline random(cid:173)
ness values. Experimental results are shown in Table 2.
For Linux hosts running on plain machines, the M BE is
extremely close to theoretical values, even for target hosts
whose RTT is 300ms away from our test machine. On the
contrary, Linux hosts installed on virtual machines within
the same subnet exhibit orders of magnitudes larger M BE
than theoretical values. Interestingly, Xen introduces much
less randomness than VMware does, probably because they
have different algorithms for firing software interrupts. On
Windows machines, the randomness is already very large
due to the relatively small F REQ value. However, the
randomness introduced by VMM is still very obvious (cid:173)
VMware adds around 270ms2 to MBE, while Xen adds
around 130ms2 . We have applied the Z-test to obtain the
statistical confidence of the likelihood that the target host is
running under different virtualized platforms. The details of
this method is omitted for simplicity.
To imitate such fingerprint on plain machines, we can ob(cid:173)
fuscate the TCP timestamps by introducing extra random(cid:173)
ness. On the other hand, we can erase such fingerprint on
VMs by normalizing the TCP timestamp at the VMM layer.
The details are omitted due to space limit.
4.2.2 MAC Address
Besides the TCP clock, we can also exploit properties
related to virtualized network devices. The Media Ac-
cess Control (MAC) address is a unique identifier for net(cid:173)
work hardware devices. VM software by default set MAC
addresses of virtual network interfaces within particular
ranges. By extracting the MAC address of a raw packet,
we can infer whether the sender is using a real NIC or a vir(cid:173)
tualone. Fingerprinting a subnet of machines can be done
within a few seconds by sending ARP queries and gather(cid:173)
ing MAC addresses from the reply messages. However, this
fingerprinting method assumes that the attacker has com(cid:173)
promised at least one host within the same subnet ofthe tar(cid:173)
get host and has acquired root access of that compromised
machine to sniff packets.
4.3 Deterring Malware by Imitating De(cid:173)
buggers and VMs
Given the goal of most anti-debugging and anti(cid:173)
virtualization code is to avoid detection by defenders, a
common reaction by a malware upon detecting these envi(cid:173)
ronments is to suppress any additional behavior that might
disclose it presence. Given this tendency, one possible ap(cid:173)
proach to reducing the amount ofmalicious behavior exhib(cid:173)
ited on a defender's system would be to make it appear as
a monitored environment. In this section, we discuss our
work in building a set of tools that are capable of mimick(cid:173)
ing those monitoring systems on production systems for the
purpose ofdeterring malware. We discuss our general emu(cid:173)
lation approach as well as an evaluation of these techniques
using our malware sample set.
4.3.1 Approach
In order to deter attackers, we use several techniques de(cid:173)
scribed in our taxonomy in §3 to disguise production sys(cid:173)
tems as virtualized and debuggers. These include:
• Drivers: For Windows hosts, we created a program
that changes the driver information strings in the Win(cid:173)
dows registry table to appear to be VMware. To
1-4244-2398-9/08/$20.00 ©2008 IEEE
183
DSN 2008: Chen et al.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 13:21:55 UTC from IEEE Xplore.  Restrictions apply. 
International Conference on Dependable Systems &Networks: Anchorage, Alaska, June 24-27 2008
Linux
Windows
Setup
Plain 1kHz VMware 1kHz Xen 100Hz
Plain 10Hz VMware 10Hz Xen 10Hz
MSE(ms~)
Base Line (ms~)
0.0854
0.0833
245.8
0.0833
23.1
8.33
1671
1667
2042
1667
1804
1667
Table 2. Remote timing fingerprinting results for various setups.
fake the presence of SoftICE, we modify the API
Openf i Ie ( ) , which is used to open device drivers.
If a program requests \ \ . \NTI CE, we return a non(cid:173)
NULL value to imitate the existence of SoftICE driver.
• System:
In order to appear virtualized, we also in(cid:173)
tercepted system calls that would have triggered ex(cid:173)
ceptions in non-virtualized hosts. Since we do not
have direct access to the source code of Windows, we
used Detours [15] to intercept Windows API calls, and
in particular KiUserExceptionDispatcher ()
in ntdll. dll is intercepted in order to imitate
VM hook fingerprints.
If the register values match
the VM checks, we return artificial values with(cid:173)
out causing any exception.
In addition, we modify
KiUserExceptionDispatcher () to deal with
malware searching for intI.
are
of
able
IsDebuggerPresent ()
• Memory: With the Windows Detours pack-
to further modify the be-
age, we
havior
and
CheckRemoteDebuggerPresent().
On a
production machine where no debugger is present,
we can return true for both API calls for any
executables. This can successfully fake the presence
ofWinDbg under these checks.
• Execution: To fool run-time anti-debugging checks
we also created an empty Windows application with
window name 011yDbg so that a direct window
search will falsely conclude the existence of OllyDbg.
These tools are certainly quite simple and superficial,
It is not our purpose
only serving as a proof-of-concept.
to imitate all the possible existing fingerprints.
4.3.2 Evaluation
To evaluate our system, we ran our 6,900 malware samples
in two environments: one in a vanilla Windows XP install,
and one with our imitated VM and debugger fingerprints
installed. Of these samples, 264 have missing execution
traces, which we ignore. Also excluded are those 461 sam(cid:173)
ples that do not exhibit any malicious behavior, even under
real environments. We compare the execution results for the
remaining 6205 samples.
fingerprints. Our tool set altogether prevented 1,850 file op(cid:173)
erations, 578 process creations, and 15,680 registry modi(cid:173)
fications. Besides these prevented operations, 27 samples
also created the file removeMeXXXX. bat to erase them(cid:173)
selves. 19 samples caused dwwin . exe (Microsoft Doctor
Watson error reporting tool) to execute. These indeed show
that our imitation tools are capable of misleading malwares
into detecting the existence of virtual machines and debug(cid:173)
gers. Overall, 2,625 (42.2%) samples reduced their mali(cid:173)
cious behavior under either VM execution or debug execu(cid:173)