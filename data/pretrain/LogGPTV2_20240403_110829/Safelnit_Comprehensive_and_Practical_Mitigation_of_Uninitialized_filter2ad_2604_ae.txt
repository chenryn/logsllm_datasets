0.0742 (0.4%)
0.6778 (-3.8%)
0.0819 (0.2%)
0.0979 (-0.2%)
4.6714 (1.8%)
0.0977 (1.4%)
0.6495 (-0.6%)
0.2210 (-0.4%)
66.6386 (1.6%)
209.8519 (0.5%)
3.3834 (1%)
6.7163 (-0.5%)
4974.89 (0.3%)
8245.39 (0.3%)
Stack SafeInit
0.0402 (0%)
0.2571 (2.1%)
0.0775 (4.9%)
0.7119 (1%)
0.0819 (0.2%)
0.0971 (-1%)
4.6497 (1.3%)
0.1000 (3.7%)
0.6648 (1.7%)
0.2350 (5.9%)
67.7927 (3.4%)
212.3462 (1.7%)
3.4145 (1.9%)
6.6835 (-1%)
5182.4 (-3.9%)
8350.71 (-1%)
default) re-used within the pool, to ensure that any potential
uninitialized memory vulnerabilities would still be mitigated.
We also ran nginx using our detection tool (using two
variants); overhead (above our hardened version) was generally
similar to that reported by Koning et al. [30], with worst-case
overhead of 5%.
it
To evaluate the real-world performance of SafeInit applied
to the kernel stack, we hardened both nginx and the kernel
with SafeInit, and compared performance to a non-hardened
nginx running under a non-hardened kernel. Using the sendﬁle
conﬁguration we discussed above, and again using the loop-
back interface to provide an extreme situation, we observed
overhead of 2.9%, 3% and 4.5% for the 1M, 64kB and 4kB
cases respectively.
We present the numbers above as a view of what is possible
with only automatic mitigation, without application-speciﬁc
knowledge. Our optimizer could be extended with knowledge
of heap functions, inline assembly, and core kernel functions
such as copy_from_user, which would provide both im-
proved guarantees and more opportunities for optimization.
D. Residual Overhead
The average overhead of CINT2006 is distorted by the
performance overhead of two outliers. The most signiﬁcant
is sjeng, a chess program. It stores game moves in large on-
stack arrays in several recursive functions, and these arrays
are then passed to many other functions, with the size stored
in a global variable. This code is so convoluted that, even
with manual inspection, we are unable to determine whether
or not array elements may be used without being initialized. An
appropriate approach might be to refactor or rewrite the code
in question, removing such ‘code smells’, which would beneﬁt
both compiler analysis as well as our manual inspection.
This may be unrealistic in some cases, so we added
compiler support for annotating variables and types with a
’no zeroinit’ attribute, and annotated sjeng’s move_s type;
this single annotation successfully reduced sjeng’s runtime
overhead to 6.5% (which would, in turn, reduce the mean
overhead for CINT2006 to less than 2%), in combination with
our full set of optimizations.
lighttpd’s buffer preparation function, discussed earlier,
could also beneﬁt from such an annotation. However, since
lighttpd does not clear the entire buffer,
this would also
require detailed manual inspection to ensure it was safe; we
11
TABLE IV.
WARNING PASS OUTPUT, FOR CINT2006
Benchmark
bzip2
gcc
gobmk
h264ref
perlbench
sjeng
xalancbmk
#Warnings
4
1
8
7
1
19
16
Notes
one is a 4MB buffer added by SPEC
mostly too complex to analyze
unused at runtime
17 of these are move_s
temporary (wide) string buffers
TABLE V.
VERIFIED UNINITIALIZED VALUE MITIGATIONS
CVE number
2016-4243
Software Mitigated?
PHP
(cid:88)
2016-5337
qemu
2016-4486
Linux
(cid:88)
(cid:88)
Description
Use of uninitialized stack variables,
including a pointer.
Info disclosure to guest; missing null
terminator for stack string buffer.
Info disclosure to userspace; uninitial-
ized padding in struct on stack.
do not believe the reduced safety in adding such annotations
is justiﬁed, given the low overhead of our approach.
We also added a warning pass to our compiler, which can
omit warnings (at link time) about large on-stack allocations
(by default, >4kB) for which our optimizer failed to remove
initialization. Figure IV summarizes the results for CINT2006
(excluding the benchmarks which output no warnings). Many
of these are not on critical paths for performance, and some
are completely unused in practice, such as a 8kB buffer in
perlbench described in the source code as “The big, slow and
stupid way“. These warnings could be combined with proﬁling
to determine which code needs to be refactored or annotated.
E. Security
To verify that SafeInit works as expected, we not only
considered a variety of real-world vulnerabilities, such as those
in Table V, but also created a suite of individual test cases.
We inspected the bitcode and machine code generated for the
relevant code manually, and also ran our test suite using the
detection system we described above. We also used valgrind
to verify our hardening; for example, we conﬁrmed that all
uninitialized value warnings from valgrind disappear when
OpenSSL 0.8.9a is hardened with SafeInit.
As with all compiler optimizations, our improvements may
expose latent bugs in other compiler code or in the source
being compiled, or even contain bugs themselves. We veriﬁed
that the benchmarks we ran produced correct results. We also
extensively tested our hardened kernel, and where available
ran test suites for the compilers and software we hardened
(such as PHP). However, the potential for such issues remains
an inherent risk when using any modern compiler, as shown
by Yang et al. [64]. Formal veriﬁcation of compilers (e.g.,
CompCert [36]) or individual optimization passes (such as that
by Zhao et al. [67] and Deng et al. [16]).
However, in total, our SafeInit prototype adds or modiﬁes
less than 2000 lines of code in LLVM, including some debug-
ging code and around 400 lines of code based on third-party
patches. Although our modiﬁcations are complex, this is a
relatively small amount of code and each component should be
individually reviewable; for comparison, our (separate) frame
clearing pass alone is more than 350 lines of code.
$ multivar php poc.php
Starting php-zero (20439)
Starting php-poison (20440)
20440 term sig: Segmentation fault (11)
Fig. 18. Detection output when checking PHP CVE-2016-4243
Our hardening does not prevent programs from reusing
memory internally. For example, a stack buffer may be reused
for different purposes within the same function, or a custom
internal heap allocator may reuse memory without clearing it,
such as we saw with PHP. Although it would potentially be
possible to catch some of these cases using heuristics, or by
attaching annotations of some kind, we do not believe it is
realistic nor reasonable for a compiler to support this.
Clearing variables to zero ensures that any uninitialized
pointers are null. An attempt to dereference such a pointer will
result in a fault; in such situations, our mitigation has reduced
a more serious problem to a denial-of-service vulnerability.
In many cases, code will speciﬁcally check for null pointers
or other variables, and so clearing variables mitigates issues
entirely; when running our detection system, we noticed that
many uninitialized pointer dereferences were only triggered
in the variant initialized with a non-zero value. For example,
Figure 18 shows the output of our detection system executing
a proof-of-concept exploit for PHP CVE-2016-4243. Only the
variant initialized with a non-zero value attempts to derefer-
ence the value (which results in a fault, caught by our system).
Initializing all variables with zero also has the potential to
activate vulnerabilities which would otherwise have remained
dormant. A contrived example could be a ‘insecure’ variable,
which is used to force a check of some kind, but is used
uninitialized. This may not be a problem in practice under
some environments, where the underlying memory happens to
always contain a non-zero value. However, this may change at
any time, and since compilers are allowed to transform such
undeﬁned behavior, it is always possible that such code may
be optimized away.
As stated in our threat model, we only consider C/C++
code; assembly routines fall outside the scope of this work,
although typical inline assembly will declare local variables in
C/C++ code, which would then be initialized by our prototype.
Since we have implemented our SafeInit prototype as an
LLVM pass, other compiler frontends making use of LLVM
could also easily beneﬁt from our work; we look forward to
experimenting with NVIDIA’s upcoming Fortran front-end.
IX. LIMITATIONS
Libraries: For complete protection against all uninitialized
value vulnerabilities, all used libraries must also be instru-
mented. The standard C library used on Linux, glibc, does
not build under clang, so our prototype implementation is
unable to instrument it; this is a limitation of our speciﬁc
implementation, not our design. Stepanov et al. [58] state that
they implemented interception of ‘close to 300’ libc functions
in MemorySanitizer; while such knowledge of library functions
is not required by SafeInit, having access to the bitcode for
libraries would also allow further performance improvements.
12
Since both the toolchain and C library are usually provided
together, we feel it would be reasonable to make small im-
provements to the C library to mitigate any performance issues
for speciﬁc functions. However, in any case, we observed no
meaningful overhead (<0.1%) when building benchmarks and
applications against an unmodiﬁed alternative C library (musl).
Performance: Our modiﬁed optimizer can cause (small)
performance regressions in some code, caused by unintended
consequences on other optimizations and code generation. For
example, removing stores makes functions smaller, and so
more likely to fall under the inlining threshold; we can improve
performance across all of our benchmarks by modifying the
threshold. To be as fair as possible, we presented our results
without any such changes. The optimizations proposed in
our design and implemented in our prototype are deliberately
minimal, without additional analysis, to show they are practical
to implement in current compilers; this limits many of the
possible transformations. Despite this, we expect the overhead
of SafeInit to decrease signiﬁcantly over time, as the related
compiler optimizations continue to improve.
There will inevitably be cases where performance is un-
acceptable in real-world code, as we saw with sjeng. Where
annotations are an unacceptable solution, making changes to
the code may be necessary. However, such refactoring can also
improve the code in other ways, whether just making it more
readable and easier to understand, or as we saw with lighttpd,
also by resolving potential memory or performance issues.
Relevant recent developments in LLVM include improve-
ments to loop analysis and optimization [47] as well as trans-
forming entire structure deﬁnitions to improve performance
[26]. During the development of our project, improvements to
LLVM’s store optimizations have also continued; for example,
one recent patch improved removal of stores which are over-
written by multiple later store instructions, allowing removal
of unnecessary initializations when individual members of a
structure are initialized. We look forward to seeing how future
optimizations further decrease the overhead of our work.
X. RELATED WORK
Detection: Dynamic analysis tools for detecting uses of
uninitialized data, such as valgrind’s memcheck [54], track
the initialized state of each bit of memory and (optionally)
the origin of any uninitialized data. The high overhead of this
tracking makes it often prohibitive for use during development,
and completely impractical to deploy. It is almost essential to
use optimized binaries, where undeﬁned behavior may have
already introduced undetectable vulnerabilities, along with
other issues which reduce the reliability of this approach, such
as re-use of stack memory within functions.
More recent detection tools using a similar approach in-
clude Dr. Memory [7], which signiﬁcantly reduces overhead
by applying optimizations, and MemorySanitizer [58] (MSan),
which reduces overhead even further by instrumenting binaries
during compilation (using LLVM). The execution time over-
head for MSan is reported as 2.5x (with optimized binaries),
which is sufﬁcient to make it usable as part of continuous
integration for projects such as Chrome, and advancements
such as chained origin tracking mean that reported errors
require less manual effort to ﬁx. Recent research [65] claims
to have reduced MSan overhead even further.
Berger et al. proposed using multi-variant execution to
detect uses of uninitialized heap allocations in DieHard [5].