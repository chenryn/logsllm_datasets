.
.
.
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 88
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 90
5.4.3 Attack Costs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 91
5.5 Results .
. .
. .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 92
5.5.1 Choosing Hyperparamters
. . . . . . . . . . . . . . . . . . . . . . 93
5.5.2 Targeted Noise Injection . . . . . . . . . . . . . . . . . . . . . . . 95
5.5.3
Small Community . . . . . . . . . . . . . . . . . . . . . . . . . . . 100
5.6 Defense .
.
.
.
.
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 110
5.6.1 Training Classiﬁer with Noise . . . . . . . . . . . . . . . . . . . . 111
5.6.2
Improving Hyperparameter Selection . . . . . . . . . . . . . . . . 112
v
5.7 Summary . .
. .
.
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 114
Chapter 6: Conclusion and Future Work . . . . . . . . . . . . . . . . . . . . . . 115
6.1 Overall Contribution and Summary . . . . . . . . . . . . . . . . . . . . . . 115
6.2 Future Work . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 115
Chapter A: DGA Detection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 119
A.1 Unique Domains queried by Hosts . . . . . . . . . . . . . . . . . . . . . . 119
A.2 Labeled DGA Families . . . . . . . . . . . . . . . . . . . . . . . . . . . . 119
A.3 Reimplementing Pleiades . . . . . . . . . . . . . . . . . . . . . . . . . . . 119
A.4 Current DGA Landscape . . . . . . . . . . . . . . . . . . . . . . . . . . . 123
References
.
. .
. .
. .
.
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 136
vi
LIST OF TABLES
3.1 Summary of datasets.
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29
3.2 Categories of newly detected ad-abuse domains. There are only three non
TDSS/TDL4 domains based on manual analysis. The email addresses are
obfuscated.
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38
. .
3.3 The top 7 countries where C&C infrastructure has been identiﬁed. They
count towards 71% of the IP addresses. . . . . . . . . . . . . . . . . . . . . 41
3.4 Financial break down approximation among the entities of the online ad
. . . . . . . . . . . . . . . . . . . . . .
ecosystem, in millions of dollars.
. 43
3.5 The extent to which TDSS/TDL4 has affected the Internet. The tables are
limited to the top 6 observations. Ad networks and Publishers domain
names have been aggregated to the owner companies.
. . . . . . . . . . . . 44
4.1 Summary of all datasets.
. . . . . . . . . . . . . . . . . . . . . . . . . . . 52
4.2
4.2a: The top six countries for 66.75% of hashed client IP addresses. 4.2b:
The top six Autonomous System Names for 17.66% of hashed client IP
addresses.
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 59
.
.
.
.
.
5.1 Summary of datasets and their availability to minimal, moderate, and per-
. . . . . . . . . . . . . . . . . . . . . . . . . .
fect knowledge attackers.
. 89
5.2 Anomaly cost as percentile of the distinct number of NXDOMAINs queried
by hosts, before and after the attack. Only 9.12% of infected hosts become
more suspicious, while the rest remain the same. . . . . . . . . . . . . . . . 99
5.3 Agility cost of small community attacks under different hyperparameter
conﬁgurations. .
.
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 107
vii
5.4 False Positive Rate for four DGA families before retraining, and after re-
training with three types of noise. . . . . . . . . . . . . . . . . . . . . . .
. 111
A.1 DGA families contained within our ground truth dataset.
. . . . . . . . . . 121
viii
LIST OF FIGURES
2.1 A brief overview of online advertising ecosystem.
. . . . . . . . . . . . . . 12
3.1 A high level overview of DNS resolution (1-8), the sinkholing processes
(A) and the points where ad-abuse can be observed (B and C).
. . . . . . . 17
3.2 Overview of the Ad-abuse Analysis System (A2S).
. . . . . . . . . . . . . 20
3.3 Association matrix for domain, RDATA, and host. . . . . . . . . . . . . . . 25
3.4 Number of requests received by the DNS and HTTP sinkholes over 10
months.
.
.
.
. .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28
3.5 Sensor availability for the NXDOMAIN dataset over four years. 247 out of
1,542 days are missing.
. . . . . . . . . . . . . . . . . . . . . . . . . . . . 31
3.6 Top: The line plot shows victim population of the botnet sample that con-
tacted the sinkhole infrastructure, with y-axis on the left. The area plot
shows the number of sinkholed domains with y-axis on the right. Bottom:
Percent change.
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32
.
.
3.7
3.7a: Cumulative distribution function (CDF) for the infection duration
based on the infection ID and IP address. 3.7b: CDF for number of re-
lated historical domain names per IP from initial ground truth (D$). 3.7c:
CDF for the number of domains queried by internal hosts (H). 3.7d: CDF
for host overlaps for TDSS/TDL4 ground truth domains.
. . . . . . . . . . 34
3.8 Evolution of TDSS/TDL4 domains and their IP infrastructure. The number
of active domain names daily increased from 2010, and reached the max-
imum (333) on 4/9/2012. None of the domains resolved to any active IP
after 10/15/2013.
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37
3.9 Ad-abuse C&C domains lifetime. . . . . . . . . . . . . . . . . . . . . . . . 40
ix
3.10 Top: Daily advertisers’ money loss caused by the ad-abuse component of
TDSS/TDL4. Bottom: Cumulative ﬁnancial loss for advertisers. Less than
15% of the botnet population is estimated to have been involved in ad fraud
that cost at least $346 million from 1/1/2011 to 10/15/2013. . . . . . . . . . 41
4.1 A simpliﬁed view of the Real-Time Bidding process.
. . . . . . . . . . . . 52
4.2 Number of daily bid requests from ad exchanges seen in the DSP.
. . . . . 53
4.3 Number of daily publisher domains from ad exchanges seen in the DSP.
. . 54
4.4 Examples of blacklisted publisher domains seen in the DSP trafﬁc.
. . . . . 56
4.5 Distributions of client IP address locations.
. . . . . . . . . . . . . . . . . 59
4.6 Density plot of ﬁrst seen date date on PBL - ﬁrst date seen from DSP (4.6a)
and last seen date on PBL - last date seen from DSP (4.6b).
. . . . . . . . . 61
4.7 Scatter plot of ﬁrst date seen on PBL and ﬁrst date seen from DSP for all
. . . . . . . . . . . . . . . . . . . . . .
DSP domains that were on PBL.
. 62
4.8 Figure 4.8a to Figure 4.8d are PBL plots. Figure 4.8e to Figure 4.8h are
Md5 plots. Figure 4.8i shows the CDF for number of publisher domains
forming components of 12/10/2014.
. . . . . . . . . . . . . . . . . . . . . 64
4.9 Figure 4.8i to Figure 4.9c are three scores for components seen on 12/10/2014
(Figure 4.9a), number of components in ad campaigns (Figure 4.9b) and ad
campaign scores (Figure 4.9c).
. . . . . . . . . . . . . . . . . . . . . . .
. 65
4.10 Number of vertices, edges and density values for the graph every day.
. . . 68
4.11 Publisher domain examples.
. . . . . . . . . . . . . . . . . . . . . . . . . 72
4.12 Malware site example.
. . . . . . . . . . . . . . . . . . . . . . . . . . . . 74
5.1 Example of targeted noise injection attacks on a graph.
. . . . . . . . . . . 83
5.2 Example small community attacks on a graph.
. . . . . . . . . . . . . . . 86
5.3 Overview of the DGA detection system.
. . . . . . . . . . . . . . . . . . . 89
5.4 Scree plot of eigenvalues of SVD.
. . . . . . . . . . . . . . . . . . . . . . 93
x
5.5 Using cluster validity metrics to choose walk length. . . . . . . . . . . . . . 94
5.6 Figure 5.6a: Predicted class probabilities before the targeted noise injec-
tion attack and after two variants of the targeted noise injection attack in
minimal, moderate, and perfect knowledge. Figure 5.6b: Predicted class
probabilities before and after the targeted noise injection attacks for com-
munity discovery and node2vec. Figure 5.6c: Predicted class probabilities
under different attacks after retraining including the “Minimal Benign DGA
1” clusters.
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 97
. .
5.7 Different number of eigenvalues.
. . . . . . . . . . . . . . . . . . . . . . . 102
5.8 Success area for joining the death star of the surrogate dataset in the mod-
erate knowledge case. All the successful attack conﬁgurations worked in
the ground truth network.
. . . . . . . . . . . . . . . . . . . . . . . . . .
. 103
5.9 Success area of small community attacks with different context size.
. . . . 104
5.10 Different sizes of the network dataset.
. . . . . . . . . . . . . . . . . . . . 106
5.11 Success area of small community attacks with different number of walks.
. 108
5.12 Success area of small community attacks with different walk length.
. . . . 109
5.13 Figure 5.13a: Using the small community attack to choose the number of
eigenvalues for SVD. Figure 5.13b: Using the small community attack to
choose the length of walk for node2vec.
. . . . . . . . . . . . . . . . . . . 112
5.14 Figure 5.14a: Using the small community attack to choose the number of
walks per node for node2vec. Figure 5.14b: Using the small community
attack to choose the neighborhood size for node2vec.
. . . . . . . . . . . . 113
A.1 Cumulative distribution of distinct number of NXDOMAINs queried by
each host in 12/18/2016.
. . . . . . . . . . . . . . . . . . . . . . . . . . . 120
A.2 ROC curves for 16 malware DGA classes and one benign class.
. . . . . . 122
A.3 Micro and macro ROC curves.
. . . . . . . . . . . . . . . . . . . . . . . . 122
A.4 Newly found DGAs.
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 123
xi
SUMMARY
Clustering is often the ﬁrst step performed to assist us in ﬁnding structure within un-
labeled datasets. Given a small set of labels, clustering also enables us to propagate these
labels by discovering groups of objects that are similar to each other. The ever-growing
amount of data being collected over a long period of time brings us many challenging op-
portunities to conduct clustering. Analyzing such long-term datasets allows us to solve
evolving security problems such as: botnet forensic analysis; early warning of new threats;
and the evolution of security phenomena. However, the analysis also faces the challenge
presented by noise in the data.
This thesis improves the robustness of clustering against noise by focusing on DNS
graphs. Noise is either inherent in the dataset, or can be injected by adversaries. The ﬁrst
goal of the thesis is to remediate the effect of the noise inherent in the data. To that end, we
perform measurement studies from two different vantage points in the online advertising
ecosystem. As a multi-billion dollar industry, the online ad ecosystem naturally attracts
ad abuse from miscreants. We propose a new clustering technique to automatically ana-
lyze the costs of impression fraud to advertisers generated by the botnet TDSS/TDL4 over
four years. In addition, our measurement results show statistically signiﬁcant differences
between blacklisted publishers compared to those that were never blacklisted, from the
vantage point of a Demand Side Platform provider.
The second goal of the thesis is to increase the robustness of clustering against adver-
sarial noise. Little work has been done in adversarial clustering in order to understand the
weaknesses of clustering systems. We propose two novel attacks, one that injects noise
to existing clusters, and one that moves data points to noisy clusters. After analyzing the
effectiveness and the cost of attacks, we present defense techniques that improve the ro-