and accurate web search,”
efﬁcient
[75] V. Raynauld and J. Greenberg, “Tweet, click, vote: Twitter and the
2010 ottawa municipal election,” Journal of Information Technology &
Politics, vol. 11, no. 4, pp. 412–434, 2014.
[76] M. S. Riazi, “Large-scale privacy-preserving matching and search,”
Ph.D. dissertation, 2016.
[77] M. S. Riazi, E. M. Songhori, A.-R. Sadeghi, T. Schneider, and
F. Koushanfar, “Toward practical secure stable matching,” Proceedings
on Privacy Enhancing Technologies, vol. 2017, no. 1, pp. 62–78, 2017.
[78] M. S. Riazi, “Towards a private new world: Algorithm, protocol,
and hardware co-design for large-scale secure computation,” Ph.D.
dissertation, UC San Diego, 2020.
[79] M. Ripeanu, M. Mowbray, N. Andrade, and A. Lima, “Gifting tech-
nologies: A bittorrent case study,” First Monday, 2006.
[80] M. Sleeper, J. Cranshaw, P. G. Kelley, B. Ur, A. Acquisti, L. F. Cranor,
and N. Sadeh, “”i read my twitter the next morning and was astonished”:
A conversational perspective on twitter regrets,” in Proceedings of the
SIGCHI Conference on Human Factors in Computing Systems, 2013.
J. Steinhardt, P. W. W. Koh, and P. S. Liang, “Certiﬁed defenses for
data poisoning attacks,” in Advances in neural information processing
systems, 2017, pp. 3517–3529.
[81]
[82] G. Stringhini, C. Kruegel, and G. Vigna, “Detecting spammers on
social networks,” in Proceedings of the 26th annual computer security
applications conference. ACM, 2010, pp. 1–9.
[83] R. Tinati, A. Madaan, and W. Hall, “Instacan: Examining deleted
content on instagram,” in Proceedings of Web Science Conference, 2017.
[84] S. Tsugawa, Y. Kikuchi, F. Kishino, K. Nakajima, Y. Itoh, and
H. Ohsaki, “Recognizing depression from twitter activity,” in Pro-
ceedings of the 33rd Annual ACM Conference on Human Factors in
Computing Systems, ser. CHI, 2015.
[85] L. Vargas, G. Hazarika, R. Culpepper, K. R. Butler, T. Shrimpton,
D. Szajda, and P. Traynor, “Mitigating risk while complying with data
retention laws,” in Proceedings of the 2018 ACM SIGSAC Conference
on Computer and Communications Security, 2018, pp. 2011–2027.
[86] A. H. Wang, “Detecting spam bots in online social networking sites: a
machine learning approach,” in IFIP Annual Conference on Data and
Applications Security and Privacy. Springer, 2010, pp. 335–342.
[87] Q. Wang, H. Xue, F. Li, D. Lee, and B. Luo, “#donttweetthis: Scor-
ing private information in social networks,” Proceedings on Privacy
Enhancing Technologies, vol. 2019, no. 4, pp. 72–92, 2019.
[88] R. H. Weber, “The right to be forgotten more than a pandora’s box?”
jipitec, vol. 2, no. 2, 2011.
[89] T. Wolf, L. Debut, V. Sanh, J. Chaumond, C. Delangue, A. Moi,
P. Cistac, T. Rault, R. Louf, M. Funtowicz, and J. Brew, “Huggingface’s
transformers: State-of-the-art natural language processing,” ArXiv, vol.
abs/1910.03771, 2019.
[90] Y. Wu, M. Schuster, Z. Chen, Q. V. Le, M. Norouzi, W. Macherey,
M. Krikun, Y. Cao, Q. Gao, K. Macherey et al., “Google’s neural
machine translation system: Bridging the gap between human and
machine translation,” arXiv preprint arXiv:1609.08144, 2016.
[91] M. Xue, G. Magno, E. Cunha, V. Almeida, and K. W. Ross, “The right
to be forgotten in the media: A data-driven study,” PoPETs, 2016.
[92] G. Ye, Z. Tang, D. Fang, Z. Zhu, Y. Feng, P. Xu, X. Chen, and Z. Wang,
“Yet another text captcha solver: A generative adversarial network based
approach,” in CCS. ACM, 2018, pp. 332–348.
[93] W. E. Zhang, Q. Z. Sheng, and A. A. F. Alhazmi, “Generating
textual adversarial examples for deep learning models: A survey,” arXiv
preprint arXiv:1901.06796, 2019.
[94] L. Zhou, W. Wang, and K. Chen, “Tweet properly: Analyzing deleted
tweets to understand and identify regrettable ones,” in Proceedings of
the 25th Conference on World Wide Web (WWW’16), April 2016.
APPENDIX
A. System Evaluation Without Keyword Filtering
In Section V-A, we saw that
the deleted tweets were
ﬁltered using a simple sensitive keyword-based approach [94]
(i.e., identify posts with sensitive keywords) to have a higher
chance of collecting possibly damaging tweets. Although this
approach seems to be a rational choice for the adversary (i.e., it
narrows its search for the damaging posts), here we investigate
the case of not ﬁltering the posts based on their keywords.
In the ﬁrst step, we study the ratio of the tweets that
contain sensitive keywords to those that do not. We sampled
300,000 random deleted tweets (from the 1% sample tweets of
the Twitter API) and observe that 38% of the deleted tweets
contained at least one of the sensitive keywords (from [94]),
and the remaining 62% did not contain any.
Previously,
in Section V-A, we observed the steps of
obtaining labels for 3,878 (= 4,028 total labeled tweets - 150
with no sensitive keywords) tweets that contained a sensitive
keyword. To follow the 38%-62% ratio explained above, we
leveraged the Twitter API and obtained 6,327 deleted tweets
that did not contain any sensitive keywords. Next, we labeled
all the newly sampled deleted tweets to be non-damaging
(instead of labeling the deleted tweets with MTurk). Our
rationale is as follow: labeling these tweets in the imbalanced
dataset is not reasonable (as well as costly) for our attacker—
we ran a small-scale experiment with 150 deleted tweets that
did not contain any sensitive keywords and found that less
than 5% of them were labeled damaging by the MTurkers
(compared to the 43% after ﬁltering these posts). Therefore,
for this experiment, we consider all the tweets that do not
contain any sensitive keywords to have a non-damaging label.
In summary for this experiment, we had 10,205 deleted
tweets which 3,878 of them contained some sensitive keywords
and the remaining 6,327 did not. Further, among the 10,205
deleted tweets 1,690 (17%) of them were labeled as damaging
and the remaining as non-damaging.
Following the same experimental setup as in Section V-C,
we present the results in Figure 5 and Figure 6. We observe that
the results follow the same trend as the ones in Section V-D
(i.e., the case of ﬁltering tweets based on sensitive keywords).
The only difference here is that the performance of the adver-
sary (F-score) has slightly dropped in almost all cases (with
and without the challenger). These results show that ﬁltering
the posts based on their keywords is an advantages strategy
that the adversary will follow to increase its performance.
Fig. 5: F-score of different adversaries (random, static, adaptive)
when no privacy preserving deletion mechanism is in place. No
ﬁltering based on the keywords of tweet were made. Shaded areas
represent 95% conﬁdence intervals.
16
12345678910Intervals0.20.40.60.8F-score2468100.250.50.75Precision246810Intervals0.250.50.75RecallRandom adversaryStatic adversaryAdaptive adversaryNo challenger(a) Random challenger (k = 1)
(b) Random challenger (k = 2)
(c) Random challenger (k = 5)
(No access.) Adversaries (random, static and adaptive) in the presence of random challenger with k = 1, 2, 5.
(d) Oracle challenger (k = 1)
(e) Oracle challenger (k = 2)
(f) Oracle challenger (k = 5)
(Black-box access.) Adversaries (random, static and adaptive) in the presence of oracle challenger with k = 1, 2, 5.
(g) D2 challenger (k = 1)
(h) D2 challenger (k = 2)
(i) D2 challenger (k = 5)
(Restricted black-box access.) Adversaries (random, static and adaptive) in the presence of D2 challenger with k = 1, 2, 5.
Fig. 6: F-score (with 95% conﬁdence intervals), precision and recall for the three adversaries (random, static and adaptive) in the
presence of different challengers corresponding to different accesses with k = 1, 2, 5. No keyword ﬁltering was applied on this dataset.
B. Proofs
Proposition (Proposition 1.). For any given volunteered set
Dv with N non-deleted posts,
max
φ
˜V (φ; Dv) = max
w1,...,wN
V (w1, . . . , wN ; Dv)
Proof of Proposition 1: Let S∗
1 = maxφ ˜V (φ; Dv) and
S∗
2 = maxw1,...,wN V (w1, . . . , wN ; Dv) be the optimum values
1 ≥ S∗
for the respective objective functions. First, note that S∗
2
because the optimal assignment for the discrete objective lies
within the solution space of the continuous relaxation. Next, let
Li = log(1−a(xi; θt)), where xi is the i-th post in Dv and let π
denote a sorting over them such that Lπ1 ≥ . . . ≥ LπN . Then,
two cases arise – (1) when the top K elements are strictly
greater than the rest, Lπ1 ≥ . . . ≥ LπK > LπK+1 ≥ . . . Lπ(N ),
and (2) when there is atleast one element in the bottom N −K
elements that has the same value as one of the top K elements,
Lπ1 ≥ . . . ≥ LπK = LπK+1 ≥ . . . Lπ(N ). In the former case,
the optimal solution is clearly to assign a weight of one to the
top K elements and zero to the rest. Any other assignment
(even in the continuous solution space) is clearly suboptimal.
In the latter case, although there are inﬁnitely many optimal
solutions in the continuous domain that distribute the weights
differently among the equal elements, the value of the objective
function is the same.
17
12345678910Intervals0.20.40.60.8F-score2468100.250.50.75Precision246810Intervals0.250.50.75RecallRandom adversaryStatic adversaryAdaptive adversaryRandom challenger, k = 112345678910Intervals0.20.40.60.8F-score2468100.250.50.75Precision246810Intervals0.250.50.75RecallRandom adversaryStatic adversaryAdaptive adversaryRandom challenger, k = 212345678910Intervals0.20.40.60.8F-score2468100.250.50.75Precision246810Intervals0.250.50.75RecallRandom adversaryStatic adversaryAdaptive adversaryRandom challenger, k = 512345678910Intervals0.20.40.60.8F-score2468100.250.50.75Precision246810Intervals0.250.50.75RecallRandom adversaryStatic adversaryAdaptive adversaryOracle challenger, k = 112345678910Intervals0.20.40.60.8F-score2468100.250.50.75Precision246810Intervals0.250.50.75RecallRandom adversaryStatic adversaryAdaptive adversaryOracle challenger, k = 212345678910Intervals0.20.40.60.8F-score2468100.250.50.75Precision246810Intervals0.250.50.75RecallRandom adversaryStatic adversaryAdaptive adversaryOracle challenger, k = 512345678910Intervals0.20.40.60.8F-score2468100.250.50.75Precision246810Intervals0.250.50.75RecallRandom adversaryStatic adversaryAdaptive adversaryD2 challenger, k = 112345678910Intervals0.20.40.60.8F-score2468100.250.50.75Precision246810Intervals0.250.50.75RecallRandom adversaryStatic adversaryAdaptive adversaryD2 challenger, k = 212345678910Intervals0.20.40.60.8F-score2468100.250.50.75Precision246810Intervals0.250.50.75RecallRandom adversaryStatic adversaryAdaptive adversaryD2 challenger, k = 5Proposition (Proposition 2). Assume Ωv ∩ Ω+ = ∅, i.e., the
supports of volunteered and damaging posts do not overlap.
Then, there is always a powerful-enough adversary to defeat
the challenger.
Proof sketch of Proposition 2: Assume the most powerful
challenger who can select any post features x from an inﬁnite
supply of volunteered posts. However, since Ωv ∩ Ω+ = ∅,
there is no sampling from pv to generate decoy examples that
look like they are sampled from p+. Hence, given enough data,
an adversary can ﬁnd a perfect decision boundary between the
damaging posts and the decoy posts. Because neural networks
are universal function approximators [46], this powerful ad-
versary always exists and, thus, the challenger can always be
defeated in the deceptive learning game.
i.e.,
Proposition (Proposition 3). Assume Ωv = Ω+,
the
supports of volunteered and damaging posts fully overlap.
Then, given enough volunteered posts in Dv, the challenger
always defeats the adversary (in both static and adaptive
scenarios). More precisely, if the challenger selects k decoys
per damaging post in Dδ, then the adversary’s probability of
identifying a damaging post in Dδ is in average at most
k+1 .
Proof of Proposition 3: The proof relies on a property
of rejection sampling, which states that if the support of two
distributions p1 and p2 fully overlap, then one can selectively
ﬁlter samples from p1 to make the ﬁltered samples have distri-
bution p2 (a proof of this principle is given in the Appendix).
Asymptotically, for each damaging example x in adversary’s
test data, there are k indistinguishable decoy examples (from
the adversary’s perspective). This is because, by Bayes theorem
pδ(y = 1|x) =
1
pδ(x|y = 1)pδ(y = 1)
pδ(x|y = 1)pδ(y = 1) + pδ(x|y = 0)pδ(y = 0)
≤ 1
1 + k
,
where the superscript pδ indicates the distribution of deleted
posts Dδ. The inequality holds by construction, as for all x ∈
Dδ with label one, there are at least k ≥ 1 samples from pv(x)
with label zero.
Next we show the kind of test distribution shift introduced
by the challenger. The challenger-injected distribution is given
by the following hypothetical acceptance-rejection sampling
algorithm:
1) sample x ∼ pv(x)
2) sample u ∼ U nif orm(0, 1) independently of x
3) while u > p+(x)/(M pv(x)), reject x and GOTO 1, for
some constant M.
y = 0, as the sample came from pv(x).
4) Accept (output) x as a sample from p+(x) but with label
5) While number of samples less than k|D+|, GOTO 1
Next we prove that the above rejection sampling algorithm
produces samples with distribution p+(x) from examples from
decoy examples that have distribution pv(x). Let X(cid:48) be a
sample from the algorithm described above and X ∼ p+(x),
then
p(X(cid:48) = x) = p(X = x|Accept) =
p(X = x, Accept)
= p+(x)
p(Accept)
because
P (X = x, Accept)
P (Accept)
as
P (Accept) =
=
=
(cid:90)
(cid:90)
1
M
(cid:90)
P (Accept|X = x)p(X = x)
P (Accept)
p+(x)
M pv(x) pv(x)
P (Accept)
p+(x)
M
P (Accept)
= p+(x)
=
=
=
P (Accept|X = x)p(X = x)dx
p(x)
q(x)dx
M q(x)
p(x)dx =
1
M
The above ideal accept-reject sampling procedure can be
reproduced via noise contrastive estimation [45], which is
method that can generate data from a known distribution with-
out the need to know p+(x)/(M pv(x)) in advance. A variant
of the same statistical principle is used today in generative
models using Generative Adversarial Networks [44], which
uses a minimax game similar to our procedure. Because we
train the challenger to mimic the classiﬁer of the adversary,
it is easy to construct such rejection sampling method, such
that there are in average k decoy examples for every damaging
example in the original data.
TABLE I: Sample tweet text extracts from the damaging, decoy, and non-damaging datasets.
Tweets’ text extract
“#GrowingUpInTexas Seeing a black person pass by ya front yard and telling your son to pass you the shotgun so you can play shoot em ups”
“@UserAccount its gods way of punishing you for your sins. fag**t.”
“I don t wanna believe all the women in the auto department at walmart are lesbians Someone prove me wrong Cuz im seeing it”
“Show up to work on meth once and your nickname is Tweaker for the rest of your life ”
“Listening to this deuchbag behind me at Chipotle diss every girl who comes in hot body but she has no face news check you re fugly”
“I grab a beer from the fridge put on my Bob Marley record crank that f**ker up and light up a fat one my professor is the sh*t”
“Kids having kids That sh*t is f**kin crazy to me I d rather be that cool ass uncle that buys the booze aaayyye”
“I don’t understand why people say that watermelon and fried chicken is for black people I love that shit to Dafuq”
“y’all I just watched “love, simon” for the ﬁrst time and let me just say that the ugly tears are so f**kin real omfg”
“I want to eat to rid my emotions but I don’t want the calories ya feel me”
“Im pretty sure one of my professors has me mistaken for another black woman in my class.”
“Anyways, it’s 2 am and the Full House theme song is playing in my head on repeat so if you wanna beat me to death do it now please”
Tweet Type
damaging
damaging
damaging
damaging
decoy
decoy
decoy
decoy
non-damaging
non-damaging
non-damaging
non-damaging
18