of programs such as complex format parsers. We port IJON
to support binary-only fuzzing based on STOCHFUZZ, and
conduct the same maze experiment in the IJON paper, which
was used to show the effectiveness of state-aware fuzzing.
In the experiment, the target programs are games where the
player has to walk through an ASCII art maze. Fuzzers instead
of a human player are used to walk the mazes. IJON has
advantages over vanilla fuzzers as it observes maze states
and uses them to guide input mutation. The ported IJON
can resolve the mazes as fast and as effective as the original
source-based version, and much more effective than running
IJON on aﬂ-qemu. Details can be found in Appendix X-G.
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:32:54 UTC from IEEE Xplore.  Restrictions apply. 
13671
REFERENCES
[1] https://github.com/ZhangZhuoSJTU/StochFuzz.
[2] M. B¨ohme, V.-T. Pham, and A. Roychoudhury, “Coverage-based grey-
box fuzzing as markov chain,” in CCS, 2016, pp. 1032–1043.
[3] “american fuzzy lop (2.52b),” https://lcamtuf.coredump.cx/aﬂ/, 2020.
[4] W. You, X. Liu, S. Ma, D. Perry, X. Zhang, and B. Liang, “SLF: fuzzing
without valid seed inputs,” in ICSE, 2019, pp. 712–723.
[5] S. Rawat, V. Jain, A. Kumar, L. Cojocar, C. Giuffrida, and H. Bos,
“Vuzzer: Application-aware evolutionary fuzzing,” in NDSS’17, 2017.
https://software.intel.com/content/www/us/en/
[6] “Processor
tracing,”
develop/blogs/processor-tracing.html, 2020.
[7] “Qemu,” https://www.qemu.org/, 2020.
[8] “Pin,”
https://software.intel.com/content/www/us/en/develop/articles/
pin-a-dynamic-binary-instrumentation-tool.html, 2020.
[9] R. Wartell, Y. Zhou, K. W. Hamlen, M. Kantarcioglu, and B. Thu-
raisingham, “Differentiating code from data in x86 binaries,” in Joint
European Conference on Machine Learning and Knowledge Discovery
in Databases. Springer, 2011, pp. 522–536.
[10] D. Andriesse, X. Chen, V. Van Der Veen, A. Slowinska, and H. Bos,
“An in-depth analysis of disassembly on full-scale x86/x64 binaries,” in
USENIX Security, 2016, pp. 583–600.
[11] C. Pang, R. Yu, Y. Chen, E. Koskinen, G. Portokalidis, B. Mao, and
J. Xu, “Sok: All you ever wanted to know about x86/x64 binary
disassembly but were afraid to ask,” arXiv preprint arXiv:2007.14266,
2020.
[12] A. Flores-Montoya and E. Schulte, “Datalog disassembly,” in USENIX
Security, 2020.
[13] G. Balakrishnan and T. Reps, “Wysinwyx: What you see is not what you
execute,” ACM Transactions on Programming Languages and Systems
(TOPLAS), vol. 32, no. 6, pp. 1–84, 2010.
[14] https://github.com/talos-vulndev/aﬂ-dyninst.
[15] G. J. Duck, X. Gao, and A. Roychoudhury, “Binary rewriting without
control ﬂow recovery,” in PLDI, 2020, pp. 151–163.
[16] S. Dinesh, N. Burow, D. Xu, and M. Payer, “Retrowrite: Statically
instrumenting cots binaries for fuzzing and sanitization,” in SP, 2020.
[17] https://github.com/google/fuzzer-test-suite.
[18] G. Zhang, X. Zhou, Y. Luo, X. Wu, and E. Min, “Ptfuzz: Guided fuzzing
with processor trace feedback,” IEEE Access, 2018.
[19] https://github.com/google/AFL/tree/master/qemu mode.
[20] https://github.com/google/AFL/tree/master/llvm mode.
[21] C. Aschermann, S. Schumilo, A. Abbasi, and T. Holz, “Ijon: Exploring
deep state spaces via fuzzing,” in SP, 2020, pp. 1597–1612.
[22] Y. Chen, D. Mu, J. Xu, Z. Sun, W. Shen, X. Xing, L. Lu, and B. Mao,
“Ptrix: Efﬁcient hardware-assisted fuzzing for cots binary,” in Asia CCS,
2019, pp. 633–645.
[23] S. Schumilo, C. Aschermann, R. Gawlik, S. Schinzel, and T. Holz, “kaﬂ:
Hardware-assisted feedback fuzzing for {OS} kernels,” in USENIX
Security, 2017, pp. 167–182.
[24] https://github.com/vanhauser-thc/aﬂ-pin.
[25] https://github.com/vanhauser-thc/aﬂ-dynamorio.
[26] https://github.com/GJDuck/e9aﬂ.
[27] T. Bao, J. Burket, M. Woo, R. Turner, and D. Brumley, “BYTEWEIGHT:
Learning to recognize functions in binary code,” in USENIX Security,
2014, pp. 845–860.
[28] A. Zeller, “Yesterday, my program worked. today, it does not. why?”
ACM SIGSOFT Software engineering notes, pp. 253–267, 1999.
[29] H.-A. Loeliger, J. Dauwels, J. Hu, S. Korl, L. Ping, and F. R. Kschis-
chang, “The factor graph approach to model-based signal processing,”
Proceedings of the IEEE, vol. 95, no. 6, pp. 1295–1322, 2007.
[30] B. Livshits, A. V. Nori, S. K. Rajamani, and A. Banerjee, “Merlin:
speciﬁcation inference for explicit information ﬂow problems,” ACM
Sigplan Notices, vol. 44, no. 6, pp. 75–86, 2009.
[31] N. E. Beckman and A. V. Nori, “Probabilistic, modular and scalable
inference of typestate speciﬁcations,” in PLDI, 2011, pp. 211–221.
[32] Z. Xu, X. Zhang, L. Chen, K. Pei, and B. Xu, “Python probabilistic type
inference with natural language support,” in FSE, 2016, pp. 607–618.
[33] T. Kremenek, P. Twohey, G. Back, A. Ng, and D. Engler, “From
uncertainty to belief: Inferring the speciﬁcation within,” in OSDI, 2006,
pp. 161–176.
[34] J. S. Yedidia, W. T. Freeman, and Y. Weiss, “Generalized belief
propagation,” in NIPS, 2001, pp. 689–695.
[35] F. R. Kschischang, B. J. Frey, and H.-A. Loeliger, “Factor graphs and
the sum-product algorithm,” IEEE Transactions on information theory,
vol. 47, no. 2, pp. 498–519, 2001.
[36] K. Murphy, Y. Weiss, and M. I. Jordan, “Loopy belief propaga-
tion for approximate inference: An empirical study,” arXiv preprint
arXiv:1301.6725, 2013.
[37] K. Miller, Y. Kwon, Y. Sun, Z. Zhang, X. Zhang, and Z. Lin, “Proba-
bilistic disassembly,” in ICSE, 2019, pp. 1187–1198.
[38] E. Bauman, Z. Lin, and K. W. Hamlen, “Superset disassembly: Statically
rewriting x86 binaries without heuristics.” in NDSS, 2018.
[39] “The ultimate disassembler,” https://www.capstone-engine.org/, 2020.
[40] “The ultimate assembler,” https://www.keystone-engine.org/, 2020.
[41] W. You, X. Wang, S. Ma, J. Huang, X. Zhang, X. Wang, and B. Liang,
“Profuzzer: On-the-ﬂy input type probing for better zero-day vulnera-
bility discovery,” in SP, 2019.
[42] P. Zong, T. Lv, D. Wang, Z. Deng, R. Liang, and K. Chen, “Fuzzguard:
Filtering out unreachable inputs in directed grey-box fuzzing through
deep learning,” in USENIX Security, 2020, pp. 2255–2269.
[43] https://github.com/AFLplusplus/AFLplusplus/issues/24.
[44] https://github.com/hunter-ht-2018/ptfuzzer.
[45] “Cuda binary utilities,” https://www.clear.rice.edu/comp422/resources/
cuda/html/cuda-binary-utilities/index.html, 2020.
[46] “Ewww image optimizer,” https://ewww.io/, 2020.
[47] https://github.com/ImageOptim/ImageOptim.
[48] J. Geldenhuys, M. B. Dwyer, and W. Visser, “Probabilistic symbolic
execution,” in ISSTA, 2012, pp. 166–176.
[49] M. Borges, A. Filieri, M. d’Amorim, and C. S. P˘as˘areanu, “Iterative
distribution-aware sampling for probabilistic symbolic execution,” in
FSE, 2015, pp. 866–877.
[50] M. Kwiatkowska, G. Norman, and D. Parker, “Prism 4.0: Veriﬁcation
of probabilistic real-time systems,” in CAV, 2011, pp. 585–591.
[51] A. Filieri, C. Ghezzi, and G. Tamburrelli, “Run-time efﬁcient probabilis-
tic model checking,” in ICSE, 2011, pp. 341–350.
[52] A. F. Donaldson, A. Miller, and D. Parker, “Language-level symmetry
reduction for probabilistic model checking,” in 2009 Sixth International
Conference on the Quantitative Evaluation of Systems, 2009, pp. 289–
298.
[53] A. Avizienis, “The n-version approach to fault-tolerant software,” IEEE
Transactions on software engineering, no. 12, pp. 1491–1501, 1985.
[54] E. D. Berger and B. G. Zorn, “Diehard: probabilistic memory safety
for unsafe languages,” in PLDI, M. I. Schwartzbach and T. Ball, Eds.,
2006, pp. 158–168.
[55] W. You, Z. Zhang, Y. Kwon, Y. Aafer, F. Peng, Y. Shi, C. Harmon,
and X. Zhang, “PMP: Cost-effective forced execution with probabilistic
memory pre-planning,” in SP, 2020, pp. 381–398.
[56] J. Xu, B. Randell, A. Romanovsky, C. M. Rubira, R. J. Stroud, and
Z. Wu, “Fault tolerance in concurrent object-oriented software through
coordinated error recovery,” in Twenty-Fifth International Symposium on
Fault-Tolerant Computing. Digest of Papers.
IEEE, 1995, pp. 499–508.
[57] J. Xu, A. Romanovsky, and B. Randell, “Concurrent exception handling
and resolution in distributed object systems,” IEEE Transactions on
Parallel and Distributed Systems, vol. 11, no. 10, pp. 1019–1032, 2000.
[58] J. Oberheide, E. Cooke, and F. Jahanian, “Cloudav: N-version antivirus
in the network cloud,” in USENIX Security, 2008, pp. 91–106.
[59] A. Carzaniga, A. Gorla, A. Mattavelli, N. Perino, and M. Pezz`e,
“Automatic recovery from runtime failures,” in ICSE, 2013.
[60] S. Nagy and M. Hicks, “Full-speed fuzzing: Reducing fuzzing overhead
through coverage-guided tracing,” in SP, 2019, pp. 787–802.
[61] https://github.com/google/AFL/blob/master/aﬂ-as.h#L77.
[62] C.-C. Hsu, C.-Y. Wu, H.-C. Hsiao, and S.-K. Huang, “Instrim:
Lightweight instrumentation for coverage-guided fuzzing,” in Sympo-
sium on Network and Distributed System Security (NDSS), Workshop
on Binary Analysis Research, 2018.
[63] https://github.com/mirrorer/aﬂ/blob/master/docs/technical details.txt#
L446.
[64] “Aﬂ user guide,” https://aﬂ-1.readthedocs.io/en/latest/user guide.html,
2020.
[65] https://www.nvidia.com/en-us/security/acknowledgements/.
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:32:54 UTC from IEEE Xplore.  Restrictions apply. 
14672
X. APPENDIX
Algorithm 1 Register Liveness Analysis on UCFG
A. Details of Optimizations
Register Reuse. Instrumentation may need to use registers. To
avoid breaking program semantics, inside each instrumentation
code block, registers need to be saved at the beginning and
restored at the end. These context savings become performance
bottleneck. We perform a register liveness analysis such that
dead registers, which hold some value that will never be
used in the future, can be reused in instrumentation. The
difference between our liveness analysis and a traditional
liveness analysis is that ours is performed on the UCFG.
Algorithm 1 presents the analysis. It takes a binary and
outputs a mapping from an address i to a set of registers
which are dead at i. The algorithm traverses all addresses in
a descendent order (line 3). For each address i, the algorithm
ﬁrst collects the explicit successors of i in UCFG (line 4). If
there is at least one successor whose address is smaller than
i, which indicates the successor has not been analyzed (line
5), the algorithm conservatively assumes all the registers are
not dead after i (line 6). Otherwise, the registers that are dead
at all successors are marked as dead after i (line 8). At last,
the dead registers at i are computed from the dead registers
after i and the i instruction itself (line 10). Speciﬁcally, the
registers written by i become dead (as the original values in
those registers are no longer used beyond i); the ones read by
i are marked live and removed from the dead set as i needs
their values. Upon instrumentation, STOCHFUZZ reuses the
dead registers at the instrumentation point.
Removing Flag Register Savings. Saving and restoring ﬂag
registers has around 10× more overhead compared with
general purpose registers [61]. We perform the same register
liveness analysis on ﬂag registers and avoid saving/restoring
the dead ones.
Removing Redundant Instrumentation. If a basic block has
only one successor, its successor is guaranteed to be covered
once the block is covered [62]. We hence avoid instrumenting
these single successors.
B. Theoretical Analysis of Probabilistic Guarantees
Likelihood of Rewriting Error Not Causing Crash But
Corrupting Coverage Feedback. If the rewriting error does
not change execution path,
it does not corrupt coverage
feedback. In this case, we are not worried about the rewriting
error even if it does not cause a crash. In other words, we
are only interested in knowing the likelihood of a rewriting
error changes program path but does not induce crash over all
the fuzzing runs. Note that as long as it causes crash in one
fuzzing run, STOCHFUZZ can catch and repair it. This is the
strength of having a stochastic solution. In our study, we use
the following deﬁnitions.
INPUT: B
D = CREATEEMPTYMAPPING()
for each address i of B in decreasing order do
binary indexed by address
OUTPUT: D[i]⊆{r1, r2, ...} dead registers at address i
1: function ANALYZEDEADREG(B)
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12: end function
dafter =(cid:84)
j∈Succ D[j]
end for
else
Succ = {j | ExplicitSucc(i, j)}
if ∃j ∈ Succ, s.t. j ≤ i then
(cid:46) Succ = ∅ if i is an indirect jump/call
dafter = {} (cid:46) Assume there is no dead variable after executing address i
end if
D[i] = (dafter ∪ {rw | RegWrite(i, rw)}) \ {rr | RegRead(i, rr)}
• ppatch = 1 − pθ: how likely a code byte (classiﬁed by
STOCHFUZZ) is selected for replacement in a rewritten
binary.
• pcrash: the likelihood that a mistakenly replaced data byte
changes program path and crashes in a single execution.
From the above deﬁnitions, the likelihood of a data byte is
mistakenly patched is pfp × ppatch. The likelihood of a data
byte being patched and triggering a crash (hence STOCHFUZZ
observes and repairs it) is pfp × ppatch × pcrash.
The likelihood of the error escapes STOCHFUZZ in M
executions is hence the following.
(1 − pfp × ppatch × pcrash)M
With a conservative setting of pfp = 0.015, the average
initial FP rate according to our experiment (Section VI-B,
ppatch = 0.99, pcrash = 0.0005 (a very conservative setting as
in practice it is over 90%), and M = 1, 000, 000, STOCHFUZZ
has 0.05% chance missing the error. We want to point out that
if pcrash is 0, meaning the error always changes path without
crashing, STOCHFUZZ can never detect it. We haven’t seen
such cases in practice. One way to mitigate the issue is to use
other instructions similar to hlt in patching.
Likelihood of Missing Coverage Due to Code Bytes Not
Being Patched. Intuitively, the likelihood is low for two rea-
sons. First, coverage information is collected at the basic block
level. Missing coverage only happens when STOCHFUZZ mis-
classiﬁes all the code bytes in a basic block to data. Second,
even if STOCHFUZZ considers a code byte is likely data, there
is still a chance it is chosen for patching during stochastic
rewriting. Over a large number of fuzzing runs, STOCHFUZZ
can expose it through an intentional crash.
To simplify our discussion, we only consider the second
reasoning. In other words, we consider missing coverage at
the byte level (not basic block level). We use the following
deﬁnitions in addition to the previous ones.
• pfn: the likelihood STOCHFUZZ mis-classiﬁes a code
byte to data, called a false negative (FN).
• pexe: the likelihood a code byte is covered in an execu-
tion.
• M: the number of fuzzing executions
• pfp: the likelihood that a data byte is classiﬁed as code
and subject to replacement (with hlt), we call it a false
positive (FP).
The likelihood of a code byte being chosen for patching
in a binary version is (1 − pfn) × ppatch. The likelihood of
a code byte being patched and covered in an execution (and
hence STOCHFUZZ detects it) is (1 − pfn) × ppatch × pexe.
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:32:54 UTC from IEEE Xplore.  Restrictions apply. 
15673
The likelihood that
the rewriting error escapes from
STOCHFUZZ in M runs is hence the following.
(1 − (1 − pfn) × ppatch × pexe)M
With a practical setting of pfn = 0.12 (the average ini-
tial FN rate of STOCHFUZZ according to our experiment),
ppatch = 0.99, pexe = 1e− 5 (a very conservative setting),
M = 1, 000, 000, STOCHFUZZ has 0.01% chance missing the
error. We want to point out that if pexe is 0, meaning the code
byte is never executed in any runs, STOCHFUZZ can never
detect it. However, in such cases, the error has no effect on
fuzzing and hence unimportant. Also note that if we consider
coverage at basic block level, the bound can be lower.
C. Details of Practical Challenges
Supporting Exception Handling in C++. Exception handling
in C++ poses additional challenges for static rewriting [16].
Speciﬁcally, when handling exceptions, the program needs to
acquire the return addresses pushed by previous call instruc-
tions to unwind stack frames. To support this, STOCHFUZZ
additionally intercepts calls to external library functions and
replace their return addresses (in the shadow space) with the
corresponding addresses in the original space. Note that this
is different from our transformation of call instructions to a
push followed by a jump. As such, when execution returns
from external libraries, it goes to the original space instead of
the shadow space, incurring additional control ﬂow transfers.
To reduce the overhead, a white-list of widely-used library
functions, for which we do not need to intercept the calls,
is used. We argue it is a one-time effort and can be done
even for closed-source programs, as the symbols of external
library functions are always exposed. To understand the worst-
case performance of STOCHFUZZ, we disable the white-list
optimization during evaluation.
Efﬁcient Process Set Up. Setting up a process (e.g., linking
and library initialization) has a relatively high overhead. To
avoid it, a fork server, which communicates with the fuzzer
through Linux pipe and forks the subject process once re-
quested, is instrumented into the subject program by AFL [63]
In STOCHFUZZ, the dispatcher is a component of AFL, which
sets up N fork servers prior to fuzzing and randomly selects