(The pinning step is unnecessary for our Linux VMs because
the Linux kernel does not swap-out its code.) Although pin-
ning for Windows takes several seconds, the VM continues
to run during that time. The pinning procedure forces about
2,000 pages to be present in memory, or about 8 MB. Of
those, it is common for half to be marked as “in transition,”
meaning that the page contents are in memory but marked as
inaccessible; the kernel can quickly make those pages present
again. In this way, the pinning procedure imposes about a
4 MB overhead on the Windows kernel.
For Linux, the most time-consuming step is normalization.
For Windows 7, we conﬁgured Fluorescence not to compute
the disassembly feature view (§4.1). Fluorescence spends sev-
Figure 8: Similarity matrix for an experiment involving 50 VMs
running Linux, many infected with malware. In this visualization,
higher similarity scores have lighter colors.
Figure 9: Similarity matrix for the 50 VMs portrayed in Figure 8,
but with sub-base and disassembly normalization disabled. In this
visualization, lower similarity scores have lighter colors.
all clusters, so the VMs in this cluster are identiﬁed as normal
while the other, smaller clusters represent different kinds of
anomalies (i.e., VMs infected by different families of rootkits).
This analysis by DBSCAN matches the ground truth.
Impact of Normalization
4.3
Fluorescence performs normalization to reduce benign differ-
ences in the contents of acquired kernel pages. We performed
an experiment to assess the effectiveness of our implemented
normalization procedure.
Figure 8 visualizes the similarity matrix S for a herd of
50 Linux VMs, many of which are infected with malware. As
explained previously for Figure 4, each row represents a VM,
each column represents a feature, and cells are shaded accord-
ing to their values. We have sorted the rows and columns for
01020304049FeatureID01020304049VMIDDiamorphineNurupoReptileUninfected0500010000150002000025000FeatureID01020304049VMIDUSENIX Association        22nd International Symposium on Research in Attacks, Intrusions and Defenses 3775 Security Analysis
Fluorescence aims to detect kernel-resident malware within
a large group of similarly conﬁgured VMs, and its design is
based on three main assumptions.
The ﬁrst is that the malware to be detected within the VMs
cannot compromise the virtual machine monitors (VMMs) on
which those VMs run. In other words, Fluorescence assumes
that the VMMs are trustworthy. This assumption allows Flu-
orescence to ﬁngerprint the monitored VMs efﬁciently by
running its agents on the same physical hosts as the mon-
itored VMs (§2, Figure 1); the agents use virtual machine
introspection to access the memory of the monitored VMs
and read their kernel code pages (§2.1). If malware is able to
compromise the VMMs, then the Fluorescence agents may
be disabled or otherwise compromised as well, and the ﬁn-
gerprinting process may not be trustworthy. VMM integrity
continues to be an important area of concern [30], but it is not
the concern that Fluorescence is intended to address.
The second assumption is that the VMs being monitored
are similar to each other in terms of conﬁguration. They boot
from a single “golden image,” which is a common practice
in cloud-based application deployments [6], and therefore
they have the same kernel patches applied and the same ker-
nel modules installed, at least at boot time. Like the VMM
integrity assumption, the VM similarity assumption helps
Fluorescence to be efﬁcient: normalization accounts for antic-
ipated but benign differences (§2.1.2), and normalized pages
that are identical across all of the VMs can be removed from
ﬁngerprints (§2.2.1), greatly speeding up subsequent analysis.
More signiﬁcantly, the similarity assumption allows Fluo-
rescence to automatically identify anomalous VMs (§2.3),
because their ﬁngerprints are most different from the basis
that Fluorescence computes (§2.2.2).
The third assumption is also related to automatic anomaly
detection. Fluorescence assumes that, in a large group of
initially healthy VMs, malware-infected VMs will be the ex-
ception, not the rule (§2.3). This assumption, which is also
made by prior work [3], allows Fluorescence to distinguish
“healthy” VMs (the majority) from “abnormal” ones (the mi-
nority) without kernel-speciﬁc knowledge.
The second and third assumptions introduce the risk of mis-
classiﬁcation. Our experiments showed, for example, that at
infection rates above 4%, the autoencoder-based detector pro-
duced both false positives and false negatives (§4.2.1). While
our experiments with DBSCAN produced no false positives
or false negatives (§4.2.2), it is conceivable that an attacker
could design malware in a way that would cause Fluorescence
to overlook it. For example, an attacker could learn the distri-
bution of pages known to be very different across benign VMs
(e.g., ten pages in the Windows kernel) and ﬁgure out how to
inject code only in those pages. The code injected into each
VM would need to be unique to prevent Fluorescence from
clustering the infected VMs; just a few similar features are
Figure 10: Time required for Fluorescence’s central server to analyze
VM herds of varying sizes.
eral seconds performing this normalization on Linux kernel
pages, and in our experience, it is necessary in order to get
good anomaly detection results (§4.3).
4.5 Scalability
Because Fluorescence operates on herds of VMs, it is impor-
tant to understand the performance of Fluorescence on herds
of VM of various sizes. Again, we reused the ﬁngerprints
of VMs that we collected in earlier experiments to simulate
herds of Windows and Linux VMs of varying sizes, from 10
to 200 VMs. For each herd, we measured the time required
for Fluorescence’s central node to analyze the collected ﬁn-
gerprints, i.e., to perform both feature alignment and anomaly
detection. Anomaly detection is fast—less than a minute in
all of our tested conﬁgurations—so the majority of the time
is spent on feature alignment.
Figure 10 presents the results of these experiments. In
brief, Fluorescence required less than ten minutes to analyze
each 50-VM herd. It analyzed our herd of 200 Linux VMs in
approximately 63 minutes, and it analyzed our herd of 200
Windows VMs in approximately 80 minutes. We believe that
this performance is reasonable for periodically measuring
the health of a VM herd. Moreover, Fluorescence scales
horizontally. For monitoring a herd containing more than
a few hundred VMs, one can divide the herd into subherds,
each monitored by a separate instance of Fluorescence.
To put these results in context, we note that Bianchi et al.
reported [3] that their Blacksheep system, which looks for
kernel-level anomalies in herds of Windows machines, needs
ten minutes to compare two 1 GB memory dumps. In that
time, Fluorescence can search for kernel-level anomalies in
at least 50 VMs.
50100150200Numberofvirtualmachines010002000300040005000Runtime(seconds)LinuxWindows378          22nd International Symposium on Research in Attacks, Intrusions and DefensesUSENIX Associationenough for Fluorescence to differentiate healthy VMs from
infected ones (Figure 4, Figure 8). We believe that hiding
kernel-resident malware from Fluorescence in this way would
require a great deal of sophistication and effort.
If healthy VMs are dissimilar from one another, then
Fluorescence would need reconﬁguration—or additional
information—in order for it to automatically identify anoma-
lous VMs. Consider a herd of healthy VMs in which half
have a particular kernel module installed and half do not.
This might happen, for example, if the herd is in the middle
of an upgrade. Such a split is likely to (1) decrease the ef-
fectiveness of the autoencoder-based detector and (2) cause
the DBSCAN-based detector to divide the healthy VMs into
two clusters. A cloud administrator could deal with such a
split in two ways. The ﬁrst way is to run two instances of
Fluorescence, one for each class of VM; the administrator
would migrate VMs from one instance to the other as the
VMs are upgraded. The second way is for the administrator
to manually label healthy clusters in some fashion, so that
Fluorescence would not need to assume that only the largest
cluster is healthy. (This would require a change to Fluores-
cence, and it would be a kind of kernel-speciﬁc knowledge
being added to the classiﬁer.) In practice, the ﬁrst approach
is likely to be preferable, because manual labeling would not
improve the performance of the autoencoder-based classiﬁer.
The current implementation of Fluorescence does not con-
sider dynamically generated code (“JIT-compiled code”),
which can cause the kernel code pages of healthy VMs to
diverge. If a VM’s kernel contains JIT-compiled code, it will
likely be identiﬁed as an anomaly. Legitimately JIT-compiled
kernel code, such as that produced by eBPF, is typically veri-
ﬁed before is it executed, and as such can generally be con-
sidered to be benign. Code pages created by eBPF can be
recognized by the magic code 0xeB9F [18], but it would be an
obvious security problem for Fluorescence to simply ignore
pages marked with this code. We leave the development of
appropriate normalization (§2.1.2) methods for JIT-compiled
kernel code as future work.
6 Related Work
We classify existing rootkit detectors into three general cat-
egories: baseline-based approaches, integrity-protection ap-
proaches, and comparative anomaly-detection approaches. By
contrasting Fluorescence’s herd anomaly-detection approach
to systems in these categories, and we show that Fluorescence
advances the state of the art.
Baseline approaches. Many rootkit detectors [2, 5, 9, 28,
34, 42] require the computation or collection of a baseline
prior to deployment, such as a sample of a known rootkit (a
negative baseline) or a sample of an uninfected operating sys-
tem (a positive baseline). Hancock [16] and Hamsa [24] gen-
erate signatures of rootkit samples; others [8, 19, 35, 36, 44]
learn from known rootkits’ behavior and generate patterns
to match future rootkit execution. These approaches are lim-
ited because they can only detect rootkits similar to known
signature or behavior patterns.
Invariant-based detection
[10, 14, 25, 32] establishes a correct view of key kernel
structures or state, and detects anomalies when that state
invariant is violated. These techniques require comprehensive
knowledge of speciﬁc kernels and assume kernel source code
availability. In contrast, Fluorescence requires no baseline
and minimal kernel-speciﬁc knowledge, which enables it to
detect anomalies in both Windows and Linux VMs.
Integrity protection. Some systems periodically check
the integrity of kernel critical components, including code
and key data structures. Although not yet fully adopted by the
Linux kernel, Kernel Patch Protection [13] and Driver Signa-
ture Enforcement [17] have been applied to 64-bit Windows
and have raised the bar for kernel rootkit development [37].
However, if a rootkit evades these defenses, it can simply
disable the protection [7]. The pitou rootkit [41], which
affects Windows XP through Windows 10, infects the MBR,
and bypasses kernel-mode code signing to load a malicious
kernel driver. In contrast to integrity protection within a VM,
Fluorescence works outside the VM, and thus cannot be dis-
abled by a rootkit unless it escapes the VM and executes code
in the hypervisor; this is considerably more difﬁcult.
Comparative approaches. Baseline-based tools may be
difﬁcult to deploy, due to the difﬁculty of constructing an
appropriate baseline sample. Cross-view detection, applied
in tools like GMER [15] and RootkitRevealer [38], compares
multiple different views of the same system state to ﬁnd
inconsistencies [4]. These approaches require signiﬁcant
manual effort to identify the system state to be observed and
compared. Diffy [27] is a live cloud triage tool that provides
mechanisms for both baseline- and clustering-based anomaly
detection.
It runs a special agent in each monitored VM
to collect OS-level information. In contrast, Fluorescence
detects anomalies without relying on in-VM software and
semantics.
Blacksheep [3] makes the assumption that infection begins
in a minority of a set of homogeneous machines. It detects
anomalies by collecting memory dumps from the machines,
extracting selected system information, and comparing pair-
wise to measure distance via clustering. Fluorescence starts
from the same assumption as Blacksheep, but is designed to
be less reliant on OS semantics and to detect code injection
and modiﬁcation attacks.
Because Blacksheep makes heavy use of OS semantics
to exclude “benign differences” between VMs, its approach
is difﬁcult to port to non-Windows systems. For example,
Blacksheep requires the PE header to handle load-time reloca-
tions, but object headers in Linux are removed during object
load. Furthermore, the Linux kernel performs additional load-
time code patching beyond object relocation and kASLR, e.g.,
in the .paravirtualization ELF section, and this noise
should also be considered benign. Instead, Fluorescence uses
very limited OS semantics, and its approach is viable on mul-
USENIX Association        22nd International Symposium on Research in Attacks, Intrusions and Defenses 379tiple versions of both Windows and Linux. For each memory
dump, Blacksheep must transport gigabytes of ﬁles across a
network for analysis. In contrast, a Fluorescence ﬁngerprint
is less than 3 MB. Blacksheep weaves its data summary and
comparison together while making use of a large amount of
OS semantics. Fluorescence decouples its data-summary and
VM-comparison processes: by comparing VM ﬁngerprints,
rather than “raw” memory snapshots, Fluorescence enables
scalable monitoring and clustering.
7 Conclusion
Fluorescence is a novel tool that detects kernel-resident mal-
ware infections within a “herd” of similar virtual machines.
It uses virtual machine introspection-based observations to
identify anomalies, without the need for training over speciﬁc
anomalies. Previous work relied on knowledge of speciﬁc
kernels to cross the “semantic gap” and compare kernel state,
or made assumptions about the malware being searched for.
Fluorescence’s more general approach to anomaly detection
does not rely on information that is speciﬁc to a single target
kernel: the ﬁngerprinting procedure needs some low-level
information to acquire and normalize kernel memory sam-
ples, but the anomaly-detection process needs no kernel- or