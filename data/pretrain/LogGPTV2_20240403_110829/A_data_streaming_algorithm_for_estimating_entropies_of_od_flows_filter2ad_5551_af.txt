### 5.3%, 3.3%, 2.5%
- **Relative Error:**
  - 0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5

**Figure 8: Varying Fraction of Traffic from Ingress**

- **Fraction of Traffic:**
  - 1
  - 0.9
  - 0.8
  - 0.7
  - 0.6
  - 0.5
  - 0.4
  - 0.3
  - 0.2
  - 0.1
  - 0

- **Entropy Error:**
  - 0
  - 0.05
  - 0.1
  - 0.15
  - 0.2
  - 0.25

**Figure 9: Error Distribution for Actual Entropy Source and Destination**

In Figure 9, we observe that the error plot for the entropy is comparable to that for the entropy norm. This confirms that our algorithm is a robust estimator of the entropy of OD (Origin-Destination) flows.

### 9. Related Work

There has been considerable previous work in computing the traffic matrix in a network [18, 21, 22, 23, 27]. The traffic matrix is simply the matrix defined by the packet (byte) counts between each pair of ingress and egress nodes in the network over some measurement interval. For fine-grained network measurement, we are sometimes interested in the flow matrix [28], which quantifies the volume of the traffic between individual OD flows. In this paper, we propose the computation of the entropy of every OD flow, which provides more information than a simple traffic matrix and has considerably less overhead than maintaining the entire flow matrix.

In recent years, entropy has been suggested as a useful measure for various network-monitoring applications. Lakhina et al. [15] use the entropy measure for anomaly detection and network diagnosis. Information measures such as entropy have been proposed for tracking malicious network activity [11, 24]. Xu et al. [25] use entropy to infer patterns of interesting activity by clustering traffic. For detecting specific types of attacks, researchers have suggested using the entropy of different traffic features for worm [24] and DDoS detection [11]. Recently, it has been shown that entropy-based techniques for anomaly detection are more resistant to the effects of sampling [3] than other volume-based methods.

The use of stable distributions to produce a sketch was first proposed in [12] to measure the L1 distance between two streams. This result was generalized to the Lp distance for all 0 < p ≤ 2 in [8, 13]. This sketch data structure is the starting point for the one we propose in this paper. The main difference is that we have to make several key modifications to make it work in practice. Specifically, we need to ensure that the number of updates per packet is small enough to feasibly perform in real-time.

For p values other than 1 and 2, there is no known closed form for the p-stable distribution. To independently draw values from an arbitrary p-stable distribution, we use the formula proposed by [6]. Since this formula is computationally expensive, we create a lookup table to hold several pre-computed values.

In [7], it is suggested that the stable distribution sketch can be used as a building block to compute empirical entropy, but no specific methods for doing this are provided. More importantly, there are already known algorithms that work well for the single stream case [16], and we believe that it is in the distributed (i.e., traffic matrix) setting that the stable sketch really excels.

### 10. Conclusion

In this paper, we address the problem of estimating the entropy between origin-destination pairs in a network and present an algorithm for solving this problem. Along the way, we introduce a completely novel scheme for estimating entropy, present applications for non-standard Lp norms, extend Indyk’s algorithm, and show how it can be used in our distributed setting. Through simulations on real-world data collected at a tier-1 ISP, we demonstrate that our algorithm is practically viable.

### 11. References

[1] A. Chakrabarti, K. Do Ba, and S. Muthukrishnan. Estimating entropy and entropy norm on data streams. In STACS, 2006.
[2] L. Bhuvanagiri and S. Ganguly. Estimating entropy over data streams. In ESA, 2006.
[3] D. Brauckhoff, B. Tellenbach, A. Wagner, M. May, and A. Lakhina. Impact of packet sampling on anomaly detection metrics. In IMC, 2006.
[4] G. Casella and R. L. Berger. Statistical Inference. Duxbury, 2nd edition, 2002.
[5] A. Chakrabarti and G. Cormode. A near-optimal algorithm for computing the entropy of a stream. In SODA, 2007.
[6] J. M. Chambers, C. L. Mallows, and B. W. Stuck. A method for simulating stable random variables. Journal of the American Statistical Association, 71(354), 1976.
[7] G. Cormode. Stable distributions for stream computations: It’s as easy as 0,1,2. In Workshop on Management and Processing of Data Streams, 2003.
[8] G. Cormode, P. Indyk, N. Koudas, and S. Muthukrishnan. Fast mining of massive tabular data via approximate distance computations. In ICDE, 2002.
[9] M. Durand and P. Flajolet. Loglog counting of large cardinalities. In ESA, 2003.
[10] C. Estan and G. Varghese. New Directions in Traffic Measurement and Accounting. In SIGCOMM, Aug. 2002.
[11] L. Feinstein, D. Schnackenberg, R. Balupari, and D. Kindred. Statistical approaches to DDoS attack detection and response. In Proceedings of the DARPA Information Survivability Conference and Exposition, 2003.
[12] P. Indyk. Stable distributions, pseudorandom generators, embeddings and data stream computation. In FOCS, 2000.
[13] P. Indyk. Stable distributions, pseudorandom generators, embeddings, and data stream computation. J. ACM, 53(3):307–323, 2006.
[14] A. Kuzmanovic and E. W. Knightly. Low-rate TCP targeted denial of service attacks (the shrew vs. the mice and elephants). In SIGCOMM, 2003.
[15] A. Lakhina, M. Crovella, and C. Diot. Mining anomalies using traffic feature distributions. In SIGCOMM, 2005.
[16] A. Lall, V. Sekar, M. Ogihara, J. Xu, and H. Zhang. Data streaming algorithms for estimating entropy of network traffic. In SIGMETRICS, 2006.
[17] G. S. Manku and R. Motwani. Approximate frequency counts over data streams. In Proceedings of the 28th International Conference on Very Large Data Bases, 2002.
[18] A. Medina, N. Taft, K. Salamatian, S. Bhattacharyya, and C. Diot. Traffic matrix estimation: existing techniques and new directions. In SIGCOMM, Aug. 2002.
[19] S. Muthukrishnan. Data streams: algorithms and applications. Available at http://athos.rutgers.edu/~muthu/.
[20] J. Nolan. STABLE program. Online at http://academic2.american.edu/~jpnolan/stable/stable.html.
[21] A. Soule, A. Nucci, R. Cruz, E. Leonardi, and N. Taft. How to identify and estimate the largest traffic matrix elements in a dynamic environment. In SIGMETRICS, June 2004.
[22] C. Tebaldi and M. West. Bayesian inference on network traffic using link count data. Journal of American Statistics Association, pages 557–576, 1998.
[23] Y. Vardi. Internet tomography: estimating source-destination traffic intensities from link data. Journal of American Statistics Association, pages 365–377, 1996.
[24] A. Wagner and B. Plattner. Entropy Based Worm and Anomaly Detection in Fast IP Networks. In Proceedings of IEEE International Workshop on Enabling Technologies, Infrastructures for Collaborative Enterprises, 2005.
[25] K. Xu, Z.-L. Zhang, and S. Bhattacharya. Profiling internet backbone traffic: behavior models and applications. In SIGCOMM, 2005.
[26] Y. Zhang, Z. M. Mao, and J. Wang. Low-rate TCP-targeted DoS attack disrupts internet routing. In Proc. 14th Annual Network & Distributed System Security Symposium, 2007.
[27] Q. Zhao, Z. Ge, J. Wang, and J. Xu. Robust traffic matrix estimation with imperfect information: making use of multiple data sources. In SIGMETRICS, 2006.
[28] Q. Zhao, A. Kumar, J. Wang, and J. Xu. Data streaming algorithms for accurate and efficient measurement of traffic and flow matrices. In SIGMETRICS, June 2005.
[29] V. M. Zolotarev. One-Dimensional Stable Distributions, volume 65 of Translations of Mathematical Monographs. American Mathematical Society, Providence, RI, 1986.

### Appendix

#### A. Proofs

##### A.1 Proof of Theorem 2

**Lemma 9.** Let \( f = f_{S+}(p) \), \( m = DM_{ed}^p \). Then the estimator (1) is asymptotically normal with mean \( \|S\|_p \) and standard deviation \( \frac{\|S\|_p}{\sqrt{2mf(m)}} \).

**Proof.** Let \( X_i = \frac{Y_i}{\|S\|_p} \). Then \( X_i \) are i.i.d. samples from distribution \( S(p) \), so \( |X_i| \) are i.i.d. samples from distribution \( S+(p) \). Using the asymptotic normality of the median stated in [4, p. 483], \( l(median(|X_1|, \ldots, |X_l|) - m) \) is asymptotically normal with mean 0 and standard deviation \( \sqrt{\frac{l}{2f(m)}} \). Dividing by \( m \) and multiplying by \( \|S\|_p \) give us that \( \frac{\|S\|_p \cdot median(|X_1|, \ldots, |X_l|)}{m} - \|S\|_p = \Lambda(\mathbf{Y}) - \|S\|_p \) is asymptotically normal with mean 0 and standard deviation \( \frac{\|S\|_p}{\sqrt{2mf(m)}} \).

**Proof of Theorem 2.** From Lemma 9,
\[ P\left[\left|\frac{\Lambda(\mathbf{Y})}{\|S\|_p} - 1\right| < \epsilon\right] \approx P\left[\left|Z\right| < \epsilon \cdot \sqrt{\frac{2mf(m)}{l}}\right] = 1 - \delta. \]

##### A.2 Proofs of Propositions 4 and 5

**Lemma 10.** \( \frac{x^\alpha}{\ln x} \) is a decreasing function on \( (1, N] \) if \( \alpha < \frac{1}{\ln N} \). In fact, if \( \alpha < 0.085 \), then \( \frac{x^\alpha}{\ln x} < 1 \) on \( [3, N] \).

**Proof.** The derivative is negative on \( (1, N] \). For \( \alpha < 0.085 \), \( 3^\alpha < \ln 3 \).

**Lemma 11.** If \( a \) approximates \( b \) within relative error bound \( \epsilon \), then \( a^{1+\alpha} \) approximates \( b^{1+\alpha} \) roughly within relative error bound \( \epsilon \) for small \( \alpha \) and \( \epsilon \). Similarly for \( 1 - \alpha \).

**Proof.** \( 1 - \epsilon < \frac{a}{b} < 1 + \epsilon \), so \( (1 - \epsilon)^{1+\alpha} < \frac{a^{1+\alpha}}{b^{1+\alpha}} < (1 + \epsilon)^{1+\alpha} \). Using Taylor expansion, \( (1 + \epsilon)^{1+\alpha} = 1 + \epsilon + \alpha \epsilon + O(\epsilon^2) \approx 1 + \epsilon \) for small \( \alpha \) and \( \epsilon \). Similarly, \( (1 - \epsilon)^{1+\alpha} \approx 1 - \epsilon \). The same holds for \( 1 - \alpha \).

From Lemma 10, \( a^{1+\alpha} \) is less than \( a \ln a \) except for a few small numbers. The big numbers should dominate the small numbers, so we argue that for a typical flow distribution, \( \frac{a^{1+\alpha}}{\|S\|_H} < 1 \). Let \( \lambda = \frac{\|S\|_{1+\alpha}}{\|S\|_H} \), so \( \lambda < 1 \). Also, \( \frac{\|S\|_{1-\alpha}}{\|S\|_H} < 1 \).

For simplicity of notation, from now on we will use \( y \) to denote \( \Lambda(\mathbf{Y}) \) and \( z \) to denote \( \Lambda(\mathbf{Z}) \).

We know \( |y - \|S\|_{1+\alpha}| < \epsilon \|S\|_{1+\alpha} \) with probability \( 1 - \delta \). So from Lemma 11, roughly \( |y^{1+\alpha} - \|S\|_{1+\alpha}^{1+\alpha}| < \epsilon \|S\|_{1+\alpha}^{1+\alpha} = \lambda \epsilon \|a\|_H \) with probability \( 1 - \delta \). Similarly, \( |z^{1-\alpha} - \|S\|_{1-\alpha}^{1-\alpha}| < \lambda \epsilon \|a\|_H \) with probability \( 1 - \delta \). So both inequalities will be true with probability at least \( 1 - 2\delta \). When that is the case,
\[ |c(y^{1+\alpha} - z^{1-\alpha}) - \|S\|_H| < c|y^{1+\alpha} - \|S\|_{1+\alpha}^{1+\alpha}| + |c(\|S\|_{1+\alpha}^{1+\alpha} - \|S\|_{1-\alpha}^{1-\alpha}) - \|S\|_H| < (2c\lambda \epsilon + \lambda_0 \epsilon_0)\|S\|_H. \]

**Proof of Proposition 5.** From Lemma 9, the error in using \( \Lambda(\mathbf{Y}) \) to estimate \( \|S\|_{1+\alpha} \) is roughly Gaussian with mean 0 and standard deviation \( \sqrt{\frac{\pi}{2l}}\|S\|_{1+\alpha} \) (here we used the value of \( mf(m) \) at \( p = 1 \)). We assume the error in using \( \Lambda(\mathbf{Y})^{1+\alpha} \) to estimate \( \|S\|_{1+\alpha}^{1+\alpha} \) is still roughly Gaussian with mean 0 and standard deviation \( \sqrt{\frac{\pi}{2l}}\|S\|_{1+\alpha}^{1+\alpha} \). (This is in the same spirit as \( (1 + \epsilon)^{1+\alpha} \approx 1 + \epsilon \).) Similarly, we assume the error in using \( \Lambda(\mathbf{Z})^{1-\alpha} \) to estimate \( \|S\|_{1-\alpha}^{1-\alpha} \) is roughly Gaussian with mean 0 and standard deviation \( \sqrt{\frac{\pi}{2l}}\|S\|_{1-\alpha}^{1-\alpha} \).

Adding the two Gaussians gives a Gaussian with mean 0 and standard deviation \( \sqrt{2} \) times the original Gaussian. Therefore, the error is multiplied by \( \sqrt{2} \) under the same probability \( 1 - \delta \).

\[ \sqrt{2} \times \sqrt{\frac{\pi}{2l}}\|S\|_{1-\alpha}^{1-\alpha} \]