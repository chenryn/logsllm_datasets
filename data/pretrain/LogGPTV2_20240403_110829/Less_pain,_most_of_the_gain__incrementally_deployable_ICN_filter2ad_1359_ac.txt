particularly promising. Unlike nearest-replica routing, caching at
the edge strictly reduces trafﬁc in the core of the network and thus
eliminates any concerns that ISP trafﬁc engineering and content
engineering could be in conﬂict [25]. Figure 7(b) shows similar
results with uniform budget assignment across PoPs.
4The absolute improvement values for latency are typically lower
than the numbers for the congestion improvement. The reason is
that we are looking at the average in the latency metric and the
maximum in the case of congestion.
151Figure 6: Trace-based simulations results. Cache budget and origin server allocation are set to be proportional to population. Parts (a), (b),
and (c) show improvements in query latency, congestion, and maximum origin server load, respectively.
Figure 7: Trace-based simulations results. Cache budget and origin server allocation are set to be uniform across the network. Parts (a),
(b), and (c) show improvements in query latency, congestion, and maximum origin server load, respectively.
Server load: Next, we consider the load on the origin servers (i.e.,
the PoP nodes hosting the objects) in Figure 6(c). The metric we
use here is the percentage reduction in the requests served by the
origin server with the highest observed load in the network (again,
over the base case of no caching). Once again, we see that the
various cache architectures show similar performance: a maximum
performance gap of 9% between EDGE-Coop and ICN-SP and a
2% gap between ICN-NR and ICN-SP. Figure 7(c) shows similar
results with uniform budget assignment as well.
Validating a synthetic request model: Ideally, we would like to
vary the request popularity distribution. One concern is whether
the performance gaps using synthetic request traces are compara-
ble to real traces. That is, in addition to visually and statistically
conﬁrming the distribution ﬁt in the previous section, we want to
ensure that this translates into system-level performance metrics.
To address this issue, for each request trace, we also generate
a synthetic request log with the best-ﬁt Zipf distribution. In Ta-
ble 3 we show the difference between trace-driven and synthetic
request data-driven simulations w.r.t. the performance gap between
ICN-NR and EDGE. The predicted gap of ICN-NR over EDGE in
different topologies (see Table 3) has a maximum value of 1.67%.
The gap w.r.t. congestion and origin server load improvements are
similar and not shown for brevity. These results suggest that using
a Zipf-based synthetic log is a reasonable approximation for a real
trace.
4.3 Key Observations and Implications
In summary, we make three key observations:
• The performance gap between different caching policies on all
three metrics (i.e., query latency, congestion, and server load)
is small (at most 9%).
Topology
Abilene
Geant
Telstra
Sprint
Verio
Tiscali
Level3
ATT
Performance gap between ICN-NR and EDGE
Trace
6.89
5.92
7.44
7.09
7.40
7.11
6.18
7.25
Difference
0.92
1.04
1.19
1.67
1.54
0.94
1.14
0.79
Synthetic
7.81
6.96
8.63
8.76
8.94
8.05
7.32
8.04
Table 3: Comparison of simulation results for query latency on
request traces and synthetic data (with best-ﬁt Zipf).
• The performance gap between ICN-SP and ICN-NR is negli-
gible (at most 2%); i.e., nearest-replica routing adds marginal
value over pervasive caching.
• Cache provisioning (i.e., population-based and uniform) does
not affect the relative performance of the representative de-
signs.
Implications: These results suggest that an “edge” caching de-
ployment provides almost the same beneﬁts to both users and the
network as a universal caching architecture with nearest-replica
routing. This is important because edge deployment is naturally
suited for an incremental deployment path for ICN on two counts.
First, there is an immediate beneﬁt (and incentive) to a group of
users who have a cache server deployed near their access gateways.
Second, and perhaps more crucially, this beneﬁt is independent of
deployments (or the lack thereof) in the rest of the network. This
naturally motivates users to deploy a cache, or a CDN or ISP to
deploy a cache on their behalf, without depending on adoption by
other providers.
 0 20 40 60 80 100AbileneGeantTelstraSprintVerioTiscaliLevel3ATTQuery latency improvement (%)Topology(a)ICN-SPICN-NREDGEEDGE-CoopEDGE-Norm 0 20 40 60 80 100AbileneGeantTelstraSprintVerioTiscaliLevel3ATTCongestion improvement (%)Topology(b) 0 20 40 60 80 100AbileneGeantTelstraSprintVerioTiscaliLevel3ATTOrigin server load improvement (%)Topology(c) 0 20 40 60 80 100AbileneGeantTelstraSprintVerioTiscaliLevel3ATTQuery latency improvement (%)Topology(a)ICN-SPICN-NREDGEEDGE-CoopEDGE-Norm 0 20 40 60 80 100AbileneGeantTelstraSprintVerioTiscaliLevel3ATTCongestion improvement (%)Topology(b) 0 20 40 60 80 100AbileneGeantTelstraSprintVerioTiscaliLevel3ATTOrigin server load improvement (%)Topology(c)1525. SENSITIVITY ANALYSIS
The results of the last section are based on a ﬁxed conﬁguration
with a speciﬁc popularity distribution, cache size, access-tree arity,
etc. In this section, we perform an extensive sensitivity analysis
across different conﬁguration parameters using synthetically gen-
erated request traces. For clarity, we only show results from the
largest topology (AT&T) as the results are similar across topolo-
gies.
Rather than look at all cache architectures, here we focus on the
two extreme points in this section, namely, ICN-NR and EDGE. In
the following results, we report a normalized improvement metric:
RelImprov ICN−NR − RelImprov EDGE
where RelImprov is the improvement over the no-caching scenario
that we mentioned in the previous section. By construction, a pos-
itive value of this measure implies ICN-NR performs better than
EDGE and a negative value implies that EDGE performs better.
For clarity of presentation, we take the following approach in
running the sensitivity analysis. First, we begin by analyzing one
dimension at a time, while retaining the baseline setup from the
previous section for the remaining parameters. Then, we focus on
the combination of parameter(s) that provides the best performance
improvement for ICN-NR.
5.1 Single-Dimension Sensitivity
Zipf parameter α: Figure 8(a) shows that with increasing α, the
gap between EDGE and ICN-NR becomes less positive. This is
intuitively expected—as α increases, popular objects get a larger
share. This reduces the value of pervasive caching and nearest-
replica routing because most of the requests are served from the
edge caches.
Cache budget: Next, we consider the effect of increasing the
cache size in Figure 8(b). As in Section 4, we represent the per-
router cache size as a fraction of the total number of objects being
requested. We see that the maximum improvement that ICN-NR
can provide is around 10% when each cache can store ≈ 2% of
the objects. We also observe an interesting non-monotonic effect
in the performance gap as a function of cache size. The reason is
that with very small caches, none of the caching architectures are
effective. With a sufﬁciently large cache (> 10%), however, the
edge caches account for a signiﬁcant fraction of the requests and
thus the marginal utility of interior caches is very low.
Spatial skew:
In the previous section, we considered a homoge-
neous request stream where requests at different network locations
are drawn from the same object popularity distribution. There are
likely to be regional differences across request streams at differ-
ent locations. Thus, we explore the effect of spatial skew in Fig-
ure 8(c). A spatial skew of 0 means that the requests at all locations
follow the same global popularity distribution (i.e., objects have a
unique global ranking). A spatial skew of 1, at the other extreme,
implies that the most popular object at one location may become
the least popular object at some other location.5 Figure 8(c) shows
that as the spatial skew increases, ICN-NR outperforms EDGE. In-
tuitively, with a large spatial skew, a less popular object at one lo-
cation may become popular at a nearby location. Thus, caching
5While the speciﬁc spatial skew metric we use is not crucial, we de-
ﬁne it for completeness: Suppose there are O objects and P PoPs,
and rop denotes the rank of object o at PoP p. Let So = stdev (rop)
be the standard deviation of ranks of object o across all PoPs. Then,
spatial skew = avg(So)
O .
arity
2
4
8
64
Latency
gain (%)
10.29
9.12
7.95
1.76
Congestion
gain (%)
9.14
8.28
7.01
0.90
Origin
load (%)
6.27
5.35
4.66
0.34
Table 4: Effect of access tree arity on performance gain of ICN-NR
over EDGE.
objects with different popularity distributions across edge locations
inside the network magniﬁes the beneﬁt of ICN-NR.
Access-tree arity: Our baseline uses a ﬁxed binary tree. Here,
we evaluate how the structure of the access tree impacts the perfor-
mance difference by changing the arity while adjusting the height
of the access trees to keep the total number of leaves per tree ﬁxed.
Table 4 shows that as the access-tree arity increases, the perfor-
mance gap between ICN-NR and EDGE decreases. This is not
surprising: with our cache budgeting mechanism, the ratio of total
cache budget between EDGE and ICN-NR in a tree of arity k is
k−1
; with a higher k this ratio comes closer to 1. In some sense,
k
increasing arity in this case has a similar effect to normalizing the
cache budgets in EDGE-Norm.
Other parameters: For completeness, we mention three other
parameters that might be relevant. First, rather than assume unit
latency cost per hop, we vary the latency model in two ways: (1)
arithmetic progression of latency toward the core and (2) a scenario
where the latency of each hop at the core network is d times higher.
(We pick this latency model to magnify the beneﬁt of ICN-NR.)
Under both models, the maximum performance gap between ICN-
NR and EDGE is less than 2%. This can be explained in part by
the intuition from Section 2.2; the intermediate levels see far fewer
requests.
Second, we vary the request serving capacity. In this case, the
number of queries each node can serve in a certain period of time
is limited. If a request arrives at a cache that is overloaded, this
request is redirected to the next cache on the query path (or the ori-
gin). Again, we see that the maximum performance improvement
of ICN-NR over EDGE in this case is less than 2%.
Finally, we investigated request streams with heterogeneous ob-
ject sizes (as observed in the real traces). This has minimal impact
on our performance results (less than 1%), as we do not see a strong
correlation between an object’s size and its popularity.
We do not present the results for a range of other parameters as
their effects are small compared with the above parameters.
5.2 Best Scenario for ICN-NR
We want to understand under what scenario(s) ICN-NR has the
best performance beneﬁts over EDGE and by how much. To this
end, we begin by ordering the conﬁguration parameters in decreas-
ing order of the magnitude of the relative improvement they yield.
Then, we progressively change one dimension at a time to max-
imize the gap between ICN-NR and EDGE in Figure 9.
In the
ﬁgure, Baseline is the conﬁguration from Section 4. In each subse-
quent conﬁguration, we change one of the conﬁguration parameters
(while all other parameters maintain their current values) as fol-
lows: (1) Alpha∗ uses α = 0.1; (2) Skew∗ sets the spatial skew to
1; (3) Budget-Dist∗ uses uniform budgeting; and (4) Node-Budget∗
sets the cache sizes to be F = 2% of the number of objects re-
quested. (For completeness, we also tried a brute force exhaustive
enumeration of parameters and found that the best case is identi-
cal to combining the best single-dimensional results.) We see that
with the best combination of parameters, ICN-NR can improve the
performance at most 17% relative to EDGE.
153(a) Zipf α
(b) Cache budget
(c) Spatial skew
Figure 8: Effect of varying different simulation parameters on the performance gap between ICN-NR and EDGE. Here, we consider a ﬁxed
total cache budget across the nodes.
Figure 9: Exploring the best scenario for ICN-NR by progres-
sively setting conﬁguration parameters to yield the maximum per-
formance gap w.r.t. EDGE.
The next question we ask is whether this performance gap is fun-
damental or whether it can be bridged using simple extensions to
EDGE. As we saw in Section 4, cooperation (EDGE-Coop) and
doubling the budget (EDGE-Norm) reduces the gap in the baseline
simulations. Figure 10 shows how several natural extensions to
EDGE bridge the performance gap. In this ﬁgure, Baseline refers
to EDGE without any changes; 2-Levels is EDGE augmented with
one more layer of caching (at the level above the edge); Coop
refers to EDGE-Coop; 2-Levels-Coops combines the features of
2-Levels and Coop; Norm refers to EDGE-Norm; Norm-Coop is
a combination of EDGE-Norm and Coop; Double-Budget-Coop is
the same as Norm-Coop with the budget doubled. There are also
two points of reference in the ﬁgure: Section-4 is the set of per-
formance measures from Section 4 and Inf-Budget is a scenario
in which both EDGE and ICN-NR have inﬁnite caches (i.e., each
cache has enough space to store O objects). We see that the com-
bination of EDGE-Norm and local cooperation can bring down the
gap to around 6%.
5.3 Key Observations and Implications
The main observations from our sensitivity analysis are:
• The key parameters that effect the relative performance of ICN-