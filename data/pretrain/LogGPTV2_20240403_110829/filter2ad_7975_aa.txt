# 前言
安全是一门应用科学，安全人员需要不断学习新的技术，解锁新的视角和能力来更好的解决安全问题。目前相对新的技术当属人工智能和区块链技术。大多数技术不可能单独存在，肯定有其应用领域和场景，人工智能技术的几大应用领域有图像、语音、自然语言处理等，众多研究者们在这几大领域不断研究不断产出着新的人工智能技术点。安全人员可以根据这些领域和安全领域的共同点来应用新技术尝试新思路解决安全问题。安全领域的信息大多和图像语音关系不大，如果硬要借鉴图像和语音方面的技术，需要把安全信息映射为图像和语音后再用领域内技术处理，处理流程中安全信息失真比较严重，效果和应用场景都比较局限。安全信息本身可以看成一种机器之间沟通的语言，安全信息处理和自然语言处理有很多相似之处，所以当安全遇到了NLP技术会发生什么呢？
# NLP技术的安全实践
首先来了解一下NLP，自然语言处理，是研究计算机处理人类语言的一门技术，包括句法语义分析、信息抽取、文本挖掘、机器翻译、信息检索等。笔者觉着NLP技术中的语言模型在安全领域的应用比较可行。语言模型是对语句概率分布的建模，如果把安全信息，比如一条日志看成一个语句，就可以估算安全日志数据内在的联系和偏好，从而判断日志的属性。语言模型应该可以分为统计语言模型和神经网络语言模型，具体应用在特征工程和算法方面，其中特征工程方面占大多数。笔者认为统计、自然语言处理、神经网络是特征工程技术的"三驾马车“，而NLP的语言模型覆盖到了这三者（统计语言模型也是统计的一种，神经网络语言模型也涵盖了神经网络），这也验证了笔者以前的经历用NLP提取特征训练安全模型效果不错的原因。
## 统计语言模型
### Char-level
之前认为自然语言处理在安全领域的应用有限，因为自然语言处理处理的大多是句子和长文本，而很多安全数据都较短，甚至就是个字符串，后来发现了字符级别的文本处理，问题迎刃而解。char-level这种思想可以用在统计语言模型里，也可以用在神经网络语言模型里，也可以用在神经网络模型，这里暂且归在统计语言模型里，因为笔者最早接触char-level是用来统计向量化。比如在cdxy师傅《LSTM识别恶意HTTP请求》文章中就有char-level这种用法：
    tokenizer = Tokenizer(filters='\t\n', char_level=True)
    tokenizer.fit_on_texts(X)
特征工程阶段使用字符级技术将HTTP请求的关键字段所对应的值转换成整数序列（每个整数都是词典中标记的索引）,
    X = tokenizer.texts_to_sequences(X)
然后使用LSTM进行序列建模识别恶意HTTP请求。
    model = Sequential()
    model.add(Embedding(num_words, 32, input_length=max_log_length))
    model.add(Dropout(0.5))
    model.add(LSTM(64, recurrent_dropout=0.5))
    model.add(Dropout(0.5))
    model.add(Dense(1, activation='sigmoid'))
    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
这其中的Embedding层涉及到了之后要说的神经网络语言模型word embedding。总的来说就是char-level+统计向量化+词嵌入+神经网络LSTM。  
再比如char-level还有个神经网络例子Char-RNN：字符级循环神经网络。RNN擅长处理序列问题，序列数据前后有很强的关联性。Char-RNN模型是从字符的维度上让机器生成文本，即通过已经观测到的字符出发，预测下一个字符出现的概率，也就是序列数据的推测。RNN属于生成模型，既能用于检测序列，也能生成序列，Char-RNN同理，只是粒度更细。Char-RNN通过生成文本在安全领域的应用可以有Fuzzing、payload生成，比如iami师傅博客中提到的《Fuzzing测试与用例的随机性》。现在利用Char
RNN实现写诗写词造句等文本生成的应用很多，在github上找了个生成英文的项目，把数据替换成我们的训练集payloads，分别用DGA域名和恶意URL做训练集payloads。
    #训练
    python train.py \
      --input_file data/dgaa.txt  \
      --name dga \
      --num_steps 50 \
      --num_seqs 32 \
      --learning_rate 0.01 \
      --max_steps 5000
    #生成100个字符
    python sample.py \
      --converter_path model/dga/converter.pkl \
      --checkpoint_path model/dga/ \
      --max_length 100
result：生成100个字符
    -o.neto
    ogeeoooy.eu
    uwuyiwe.eu
    ywoowou.eu
    owuowed.eu
    uowouie.eu
    uwuowui.eu
    ouwgyoo.eu
    wgpgyuo.eu
    gpyg
result：生成200个字符
    .com
    plpqbalioio.comt
    bywre.com
    npyyya.com
    yyytgoa.com
    ybyuuuyi.ddns.net
    ouwueaudo.info
    ouywiuu.info
    uuuuuia.eu
    oougyii.eu
    gwouyou.eu
    uwwywwe.info
    wooyyee.ddns.net
    nuiuuui.ndns.net
    niooio.ddns.net
    iao
生成1000个字符
    ppntrasildeafeninguvuc.com
    ptytrasildeafeninguvuc.com
    ztnyrasildeafeninguvuc.com
    pbtyrasildeafeninguvuc.com
    tbgyrasildeafeninguvuc.com
    zvyyrasildeafeninguvuc.com
    znpyrasildeafeninguvuc.com
    tnvvrasildeafeninguvuc.com
    tvtprasildeafeninguvuc.com
    tpvyeasildeafeninguvuc.com
    nbvyrasildeafeninguvuc.com
    tttvrasildaafeninguvuc.com
    tpnpeasildeafeninguvuc.com
    ttptrasildeafeninguvuc.com
    vbvveasildeafeninguvuc.com
    znvprasildeafeninguvuc.com
    ntpvrasildeafeninguvuc.com
尾部都是相同的序列，开始以为有问题，想的是因为生成文本的长序列和训练集中dga域名的短序列的问题，才造成这种固定序列的生成，然后发现rasildeafeninguvuc.com是一个家族固定序列，在训练集中有很多。  
**生成恶意URL** ：
    script>
    "dacument.prossidectink&remexter="alert(1)/script:confirm(')
    <inamesonrore="xstend(113);"
    /apts.deleseserror.php?script=http://192.168.201.328000000110019933999930191113901103310099900511199199093009053100021320251355301033033511125101305355515052135052525300000513311503300500000123310331105031022132)
    /en-us/src/contenks/sriser.inc.php?proroc=XXpathXX?
    /contentilesooromon.pl?mossinnid=/etc/passwd\x00
    /examples/jsp/checkbox/pore.php?ment=../../../../../../../etc/passwd&nertast=1&set="....\xc0%25.exc/passwd