transaction type: Custom query  
scaling factor: 1  
query mode: prepared  
number of clients: 16  
number of threads: 4  
duration: 60 s  
number of transactions actually processed: 392105  
tps = 6533.401527 (including connections establishing)  
tps = 6534.950565 (excluding connections establishing)  
statement latencies in milliseconds:  
        0.003611        \setrandom c1 1 10  
        0.000821        \setrandom c2 1 5  
        0.000762        \setrandom c3 1 2  
        0.000740        \setrandom c4 1 100  
        0.000873        \setrandom day 1 300  
        2.438667        insert into log (c1,c2,c3,c4,crt_time) values (:c1, :c2, :c3, :c4, current_date+:day::int);  
```  
UPDATE pgbench  
```  
pg92@digoal-PowerEdge-R610-> cat id.sql   
\setrandom c1 1 10  
\setrandom c2 1 5  
\setrandom c3 1 2  
\setrandom c4 1 100  
\setrandom day 1 300  
\setrandom id 1 5000000  
begin;  
insert into log (c1,c2,c3,c4,crt_time) values (:c1, :c2, :c3, :c4, current_date+:day::int);  
insert into log (c1,c2,c3,c4,crt_time) values (:c2, :c1, :c3, :c4, current_date+:day::int);  
delete from log where id=:id;  
insert into log (c1,c2,c3,c4,crt_time) values (:c1, :c2, :c4, :c3, current_date+:day::int);  
delete from log where id=:id;  
insert into log (c1,c2,c3,c4,crt_time) values (:c1, :c2, :c1, :c4, current_date+:day::int);  
delete from log where id=:id;  
insert into log (c1,c2,c3,c4,crt_time) values (:c1, :c1, :c3, :c4, current_date+:day::int);  
delete from log where id=:id;  
delete from log where id=:id;  
insert into log (c1,c2,c3,c4,crt_time) values (:c1, :c2, :c3, :c1, current_date+:day::int);  
end;  
```  
测试结果  
```  
pg92@digoal-PowerEdge-R610-> pgbench -M prepared -r -n -f ./id.sql -h $PGDATA -p 1919 -U postgres -T 60 -c 16 -j 4 postgres  
transaction type: Custom query  
scaling factor: 1  
query mode: prepared  
number of clients: 16  
number of threads: 4  
duration: 60 s  
number of transactions actually processed: 68535  
tps = 1141.824233 (including connections establishing)  
tps = 1142.090645 (excluding connections establishing)  
statement latencies in milliseconds:  
        0.004085        \setrandom c1 1 10  
        0.000841        \setrandom c2 1 5  
        0.000848        \setrandom c3 1 2  
        0.000800        \setrandom c4 1 100  
        0.000899        \setrandom day 1 300  
        0.000858        \setrandom id 1 5000000  
        0.124333        begin;  
        2.105232        insert into log (c1,c2,c3,c4,crt_time) values (:c1, :c2, :c3, :c4, current_date+:day::int);  
        2.099313        insert into log (c1,c2,c3,c4,crt_time) values (:c2, :c1, :c3, :c4, current_date+:day::int);  
        0.553053        delete from log where id=:id;  
        1.951419        insert into log (c1,c2,c3,c4,crt_time) values (:c1, :c2, :c4, :c3, current_date+:day::int);  
        0.484705        delete from log where id=:id;  
        1.856407        insert into log (c1,c2,c3,c4,crt_time) values (:c1, :c2, :c1, :c4, current_date+:day::int);  
        0.479868        delete from log where id=:id;  
        1.661506        insert into log (c1,c2,c3,c4,crt_time) values (:c1, :c1, :c3, :c4, current_date+:day::int);  
        0.469769        delete from log where id=:id;  
        0.267489        delete from log where id=:id;  
        1.623206        insert into log (c1,c2,c3,c4,crt_time) values (:c1, :c2, :c3, :c1, current_date+:day::int);  
        0.301404        end;  
```  
验证数据准确性的SQL如下 :   
```  
select sum(hashtext(t.*::text)) from (select c1,stat_time,sum(cnt) from log_c1_cnt_year group by 1,2 having sum(cnt)<>0 order by 1,2) t;  
select sum(hashtext(t.*::text)) from (select c1,to_char(crt_time,'yyyy'),count(*) from log group by 1,2 having count(*)<>0 order by 1,2) t;  
select sum(hashtext(t.*::text)) from (select c1,stat_time,sum(cnt) from log_c1_cnt_month group by 1,2 having sum(cnt)<>0 order by 1,2) t;  
select sum(hashtext(t.*::text)) from (select c1,to_char(crt_time,'yyyymm'),count(*) from log group by 1,2 having count(*)<>0 order by 1,2) t;  
select sum(hashtext(t.*::text)) from (select c1,stat_time,sum(cnt) from log_c1_cnt_week group by 1,2 having sum(cnt)<>0 order by 1,2) t;  
select sum(hashtext(t.*::text)) from (select c1,to_char(date(crt_time)-(EXTRACT(ISODOW FROM date(crt_time)))::int+1,'yyyymmdd'),count(*) from log group by 1,2 having count(*)<>0 order by 1,2) t;  
select sum(hashtext(t.*::text)) from (select c1,stat_time,sum(cnt) from log_c1_cnt_day group by 1,2 having sum(cnt)<>0 order by 1,2) t;  
select sum(hashtext(t.*::text)) from (select c1,to_char(crt_time,'yyyymmdd'),count(*) from log group by 1,2 having count(*)<>0 order by 1,2) t;  
select sum(hashtext(t.*::text)) from (select c2,c3,stat_time,sum(cnt) from log_c2_c3_cnt_year group by 1,2,3 having sum(cnt)<>0 order by 1,2,3) t;  
select sum(hashtext(t.*::text)) from (select c2,c3,to_char(crt_time,'yyyy'),count(*) from log group by 1,2,3 having count(*)<>0 order by 1,2,3) t;  
select sum(hashtext(t.*::text)) from (select c2,c3,stat_time,sum(cnt) from log_c2_c3_cnt_month group by 1,2,3 having sum(cnt)<>0 order by 1,2,3) t;  
select sum(hashtext(t.*::text)) from (select c2,c3,to_char(crt_time,'yyyymm'),count(*) from log group by 1,2,3 having count(*)<>0 order by 1,2,3) t;  
select sum(hashtext(t.*::text)) from (select c2,c3,stat_time,sum(cnt) from log_c2_c3_cnt_week group by 1,2,3 having sum(cnt)<>0 order by 1,2,3) t;  
select sum(hashtext(t.*::text)) from (select c2,c3,to_char(date(crt_time)-(EXTRACT(ISODOW FROM date(crt_time)))::int+1,'yyyymmdd'),count(*) from log group by 1,2,3 having count(*)<>0 order by 1,2,3) t;  
select sum(hashtext(t.*::text)) from (select c2,c3,stat_time,sum(cnt) from log_c2_c3_cnt_day group by 1,2,3 having sum(cnt)<>0 order by 1,2,3) t;  
select sum(hashtext(t.*::text)) from (select c2,c3,to_char(crt_time,'yyyymmdd'),count(*) from log group by 1,2,3 having count(*)<>0 order by 1,2,3) t;  
```  
经过验证数据准确.  
## 小结  
1\.   
实时性的统计带来的开销与维度有关, 维度越多, 开销越大, 这样带来的后果是入口表(明细表)的dml吞吐量会急剧下降.  
下一篇将介绍非实时的统计. 结合非实时的统计以及明细数据也能达到实时count的效果.  
为方便大家查询, 汇总PostgreSQL实时和非实时数据统计的案例分析文章系列 - 如下 :       
1\. http://blog.163.com/digoal@126/blog/static/163877040201331252945440/      
2\. http://blog.163.com/digoal@126/blog/static/16387704020133151402415/      
3\. http://blog.163.com/digoal@126/blog/static/16387704020133155179877/      
4\. http://blog.163.com/digoal@126/blog/static/16387704020133156636579/      
5\. http://blog.163.com/digoal@126/blog/static/16387704020133218305242/      
6\. http://blog.163.com/digoal@126/blog/static/16387704020133224161563/      
7\. http://blog.163.com/digoal@126/blog/static/16387704020133271134563/      
8\. http://blog.163.com/digoal@126/blog/static/16387704020134311144755/      
#### [PostgreSQL 许愿链接](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216")
您的愿望将传达给PG kernel hacker、数据库厂商等, 帮助提高数据库产品质量和功能, 说不定下一个PG版本就有您提出的功能点. 针对非常好的提议，奖励限量版PG文化衫、纪念品、贴纸、PG热门书籍等，奖品丰富，快来许愿。[开不开森](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216").  
#### [9.9元购买3个月阿里云RDS PostgreSQL实例](https://www.aliyun.com/database/postgresqlactivity "57258f76c37864c6e6d23383d05714ea")
#### [PostgreSQL 解决方案集合](https://yq.aliyun.com/topic/118 "40cff096e9ed7122c512b35d8561d9c8")
#### [德哥 / digoal's github - 公益是一辈子的事.](https://github.com/digoal/blog/blob/master/README.md "22709685feb7cab07d30f30387f0a9ae")
![digoal's wechat](../pic/digoal_weixin.jpg "f7ad92eeba24523fd47a6e1a0e691b59")
#### [PolarDB 学习图谱: 训练营、培训认证、在线互动实验、解决方案、生态合作、写心得拿奖品](https://www.aliyun.com/database/openpolardb/activity "8642f60e04ed0c814bf9cb9677976bd4")
#### [购买PolarDB云服务折扣活动进行中, 55元起](https://www.aliyun.com/activity/new/polardb-yunparter?userCode=bsb3t4al "e0495c413bedacabb75ff1e880be465a")
#### [About 德哥](https://github.com/digoal/blog/blob/master/me/readme.md "a37735981e7704886ffd590565582dd0")