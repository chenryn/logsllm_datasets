performance. We omit the result due to page limit.
To further show the scalability of our system, we run the
online part of our privacy preserving logistic regression on the
Gisette dataset with 5000 features and up to 1,000,000 samples
on a LAN network. It takes 268.9s using our ﬁrst protocol and
623.5s using the second one. The trained model can reach an
accuracy of 97.9% on the testing dataset.
We are not aware of any prior work in this security model
with an implementation. We are the ﬁrst to implement a scalable
Protocol 1
Ofﬂine
290,000s∗
320,000s∗
Online
4239.7s
653.0s
Protocol 2
Ofﬂine
14951.2s
16783.9s
Online
10332.3s
4260.3s
RELU
Square
TABLE III: Performance of privacy preserving neural networks
training on MNIST in LAN setting. n = 60, 000, d = 784.
system for privacy preserving logistic regression.
C. Experiments for Neural Networks
We also implemented our privacy preserving protocol for
training an example neural network on the MNIST dataset.
The neural network has two hidden layers with 128 neurons in
each layer. We experiment with both the RELU and the square
function as the activation function in the hidden layers and our
proposed alternative to softmax function in the output layer.
The neural network is fully connected and the cost function is
the cross entropy function. The labels are represented as hot
vectors with 10 elements, where the element indexed by the
digit is set to 1 while others are 0s. We run our system on a
LAN network and the performance is summarized in Table III.
|B| is set to 128 and the training converges after 15 epochs.
As shown in the table, when RELU function is used, the
online phase of our ﬁrst protocol takes 4239.7s, while the
ofﬂine phase using OT takes around 2.9×105s. When the
square function is used, the performance of the online phase
is improved signiﬁcantly, as most of the garbled circuits
are replaced by multiplications on secret shared values. In
particular, it only takes 653.0s for the online phase of our ﬁrst
protocol. The running time of the ofﬂine phase is increased,
showing a trade-off between the two phases. Using client-aided
multiplication triplets, the ofﬂine phase is further reduced to
about 1.5×104s, with an overhead on the online phase.
Due to high number of interactions and high communication,
the neural network training on WAN setting is not yet practical.
To execute one round of forward and backward propagation
in the neural network, the online phase takes 30.52s using
RELU function and the ofﬂine phase takes around 2200s using
LHE-based approach. The total running time is linear in the
number of rounds, which is around 7000 in this case.
In terms of the accuracy,
the model trained by our protocol
can reach 93.4% using RELU and 93.1% using the square
function. In practice, there are other types of neural networks
that can reach better accuracy. For example, the convolutional
neural networks are believed to work better for image pro-
cessing tasks. In such neural networks, the neurons are not
fully connected and the inner product between the data and the
coefﬁcients is replaced by a 2-D convolution. In principle, we
can also support such neural networks, as the convolution can
be computed using additions and multiplications. However,
improving the perfomance using techniques such as Fast
Fourier Transform inside secure computation is interesting
open questions. Experimenting with various MPC-friendly
activations is another avenue for research.
ACKNOWLEDGEMENTS
We thank Jing Huang from Visa Research for helpful dis-
cussions on machine learning, and Xiao Wang from University
of Maryland for his help on the EMP toolkit. The work was
partially supported by NSF grants #5245250 and #5246010.
33
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:22:48 UTC from IEEE Xplore.  Restrictions apply. 
REFERENCES
[1] Arcene data set. https://archive.ics.uci.edu/ml/datasets/Arcene. Accessed:
[2] Eigen library. http://eigen.tuxfamily.org/.
[3] EMP toolkit. https://github.com/emp-toolkit.
[4] Gisette data set. https://archive.ics.uci.edu/ml/datasets/Gisette. Accessed:
2016-07-14.
2016-07-14.
07-14.
[5] GMP library. https://gmplib.org/.
[6] MNIST database. http://yann.lecun.com/exdb/mnist/. Accessed: 2016-
[7] NTL library. http://www.shoup.net/ntl/.
[8] Tensorﬂow. https://www.tensorﬂow.org/.
[9] ABADI, M., CHU, A., GOODFELLOW, I., MCMAHAN, H. B., MIRONOV,
I., TALWAR, K., AND ZHANG, L. Deep learning with differential privacy.
In Proceedings of the 2016 ACM SIGSAC Conference on Computer and
Communications Security (2016), ACM, pp. 308–318.
[10] AONO, Y., HAYASHI, T., TRIEU PHONG, L., AND WANG, L. Scalable
and secure logistic regression via homomorphic encryption. In Proceed-
ings of the Sixth ACM Conference on Data and Application Security and
Privacy (2016), ACM, pp. 142–144.
[11] ASHAROV, G., LINDELL, Y., SCHNEIDER, T., AND ZOHNER, M. More
efﬁcient oblivious transfer and extensions for faster secure computation.
In Proceedings of the ACM CCS 2013 (2013).
[12] BELLARE, M., HOANG, V. T., KEELVEEDHI, S., AND ROGAWAY, P.
Efﬁcient garbling from a ﬁxed-key blockcipher. In Security and Privacy
(SP), 2013 IEEE Symposium on (2013), IEEE, pp. 478–492.
[13] BELLARE, M., HOANG, V. T., AND ROGAWAY, P. Foundations of garbled
circuits. In Proceedings of the 2012 ACM conference on Computer and
communications security (2012), ACM, pp. 784–796.
[14] BUNN, P., AND OSTROVSKY, R. Secure two-party k-means cluster-
In Proceedings of the 14th ACM conference on Computer and
ing.
communications security (2007), ACM, pp. 486–497.
[15] CANETTI, R. Universally composable security: A new paradigm for
In Foundations of Computer Science, 2001.
cryptographic protocols.
Proceedings. 42nd IEEE Symposium on (2001), IEEE, pp. 136–145.
[16] CHAUDHURI, K., AND MONTELEONI, C. Privacy-preserving logistic
regression. In Advances in Neural Information Processing Systems (2009),
pp. 289–296.
[17] DAMGARD, I., GEISLER, M., AND KROIGARD, M. Homomorphic
International Journal of Applied
encryption and secure comparison.
Cryptography 1, 1 (2008), 22–31.
[18] DEMMLER, D., SCHNEIDER, T., AND ZOHNER, M. Aby-a framework
In NDSS
for efﬁcient mixed-protocol secure two-party computation.
(2015).
[19] DU, W., AND ATALLAH, M. J. Privacy-preserving cooperative scientiﬁc
computations. In csfw (2001), vol. 1, Citeseer, p. 273.
[20] DU, W., HAN, Y. S., AND CHEN, S. Privacy-preserving multivariate
statistical analysis: Linear regression and classiﬁcation. In SDM (2004),
vol. 4, SIAM, pp. 222–233.
[21] GASCON, A., SCHOPPMANN, P., BALLE, B., RAYKOVA, M., DOERNER,
J., ZAHUR, S., AND EVANS, D. Secure linear regression on vertically
partitioned datasets.
[22] GILAD-BACHRACH, R., DOWLIN, N., LAINE, K., LAUTER, K.,
NAEHRIG, M., AND WERNSING, J. Cryptonets: Applying neural
networks to encrypted data with high throughput and accuracy.
In
Proceedings of The 33rd International Conference on Machine Learning
(2016), pp. 201–210.
[23] GILAD-BACHRACH, R., LAINE, K., LAUTER, K., RINDAL, P., AND
ROSULEK, M. Secure data exchange: A marketplace in the cloud.
Cryptology ePrint Archive, Report 2016/620, 2016. http://eprint.iacr.org/
2016/620.
[24] GILAD-BACHRACH, R., LAINE, K., LAUTER, K., RINDAL, P., AND
ROSULEK, M. Secure data exchange: A marketplace in the cloud.
[25] GUYON, I., GUNN, S., BEN-HUR, A., AND DROR, G. Result analysis
In Advances in neural
of the nips 2003 feature selection challenge.
information processing systems (2004), pp. 545–552.
[26] HASTIE, T., TIBSHIRANI, R., AND FRIEDMAN, J. The elements of
statistical learning – data mining, inference, and prediction.
[27] ISHAI, Y., KILIAN, J., NISSIM, K., AND PETRANK, E. Extending
oblivious transfers efﬁciently. Advances in Cryptology-CRYPTO 2003
(2003), 145–161.
[28] JAGANNATHAN, G., AND WRIGHT, R. N. Privacy-preserving distributed
k-means clustering over arbitrarily partitioned data.
In Proceedings
of the eleventh ACM SIGKDD international conference on Knowledge
discovery in data mining (2005), ACM, pp. 593–599.
[29] KAMARA, S., MOHASSEL, P., AND RAYKOVA, M. Outsourcing multi-
party computation. IACR Cryptology ePrint Archive (2011), 272.
[30] KOLESNIKOV, V., AND SCHNEIDER, T. Improved garbled circuit: Free
xor gates and applications. In International Colloquium on Automata,
Languages, and Programming (2008), Springer, pp. 486–498.
[31] LINDELL, Y., AND PINKAS, B. Privacy preserving data mining.
In
Annual International Cryptology Conference (2000), Springer, pp. 36–
54.
[32] LINDELL, Y., AND PINKAS, B. A proof of security of yaos protocol for
two-party computation. Journal of Cryptology 22, 2 (2009), 161–188.
[33] LIVNI, R., SHALEV-SHWARTZ, S., AND SHAMIR, O. On the compu-
tational efﬁciency of training neural networks. In Advances in Neural
Information Processing Systems (2014), pp. 855–863.
[34] MALKHI, D., NISAN, N., PINKAS, B., SELLA, Y., ET AL. Fairplay-
secure two-party computation system.
[35] NAYAK, K., WANG, X. S., IOANNIDIS, S., WEINSBERG, U., TAFT, N.,
AND SHI, E. Graphsc: Parallel secure computation made easy. In 2015
IEEE Symposium on Security and Privacy (2015), IEEE, pp. 377–394.
[36] NIKOLAENKO, V., IOANNIDIS, S., WEINSBERG, U., JOYE, M., TAFT,
N., AND BONEH, D.
In
Proceedings of the 2013 ACM SIGSAC conference on Computer &
communications security (2013), ACM, pp. 801–812.
Privacy-preserving matrix factorization.
[37] NIKOLAENKO, V., WEINSBERG, U., IOANNIDIS, S., JOYE, M., BONEH,
D., AND TAFT, N. Privacy-preserving ridge regression on hundreds of
millions of records. In Security and Privacy (SP), 2013 IEEE Symposium
on (2013), IEEE, pp. 334–348.
[38] PAILLIER, P. Public-key cryptosystems based on composite degree
residuosity classes.
In International Conference on the Theory and
Applications of Cryptographic Techniques (1999), Springer, pp. 223–238.
[39] PEIKERT, C., VAIKUNTANATHAN, V., AND WATERS, B. A framework
for efﬁcient and composable oblivious transfer. Advances in Cryptology–
CRYPTO 2008 (2008), 554–571.
[40] SANIL, A. P., KARR, A. F., LIN, X., AND REITER, J. P. Privacy preserv-
ing regression modelling via distributed computation. In Proceedings of
the tenth ACM SIGKDD international conference on Knowledge discovery
and data mining (2004), ACM, pp. 677–682.
[41] SHOKRI, R., AND SHMATIKOV, V. Privacy-preserving deep learning. In
Proceedings of the 22nd ACM SIGSAC Conference on Computer and
Communications Security (2015), ACM, pp. 1310–1321.
[42] SLAVKOVIC, A. B., NARDI, Y., AND TIBBITS, M. M. ” secure” logistic
regression of horizontally and vertically partitioned distributed databases.
In Seventh IEEE International Conference on Data Mining Workshops
(ICDMW 2007) (2007), IEEE, pp. 723–728.
[43] SONG, S., CHAUDHURI, K., AND SARWATE, A. D. Stochastic gradient
descent with differentially private updates. In Global Conference on
Signal and Information Processing (GlobalSIP), 2013 IEEE (2013), IEEE,
pp. 245–248.
[44] VAIDYA, J., YU, H., AND JIANG, X. Privacy-preserving svm classiﬁca-
tion. Knowledge and Information Systems 14, 2 (2008), 161–178.
[45] WANG, X., MALOZEMOFF, A. J., AND KATZ, J. Faster two-party
computation secure against malicious adversaries in the single-execution
setting. Cryptology ePrint Archive, Report 2016/762, 2016. http://eprint.
iacr.org/2016/762.
[46] WU, S., TERUYA, T., KAWAMOTO, J., SAKUMA, J., AND KIKUCHI, H.
Privacy-preservation for stochastic gradient descent application to secure
logistic regression. The 27th Annual Conference of the Japanese Society
for Artiﬁcial Intelligence 27 (2013), 1–4.
[47] YAO, A. C. Protocols for secure computations.
In Foundations of
Computer Science, 1982. SFCS’08. 23rd Annual Symposium on (1982),
IEEE, pp. 160–164.
[48] YU, H., VAIDYA, J., AND JIANG, X. Privacy-preserving svm classi-
ﬁcation on vertically partitioned data. In Paciﬁc-Asia Conference on
Knowledge Discovery and Data Mining (2006), Springer, pp. 647–656.
APPENDIX A
THE UC FRAMEWORK
An execution in the UC framework involves a collection
of (non-uniform) interactive Turing machines. In this work
we consider an admissible and semi-honest adversary A as
discussed above. The parties exchange messages according to
a protocol. Protocol inputs of uncorrupted parties are chosen
by an environment machine. Uncorrupted parties also report
their protocol outputs to the environment. At the end of
34
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:22:48 UTC from IEEE Xplore.  Restrictions apply. 
the interaction, the environment outputs a single bit. The
adversary can also interact arbitrarily with the environment —
without loss of generality the adversary is a dummy adversary
which simply forwards all received protocol messages to the
environment and acts in the protocol as instructed by the
environment.
Security is deﬁned by comparing a real and ideal interaction.
Let REAL[Z,A, π, λ] denote the ﬁnal (single-bit) output of
the environment Z when interacting with adversary A and
honest parties who execute protocol π on security parameter λ.
This interaction is referred to as the real interaction involving
protocol π.
In the ideal interaction, parties simply forward the inputs
they receive to an uncorruptable functionality machine and
forward the functionality’s response to the environment. Hence,
the trusted functionality performs the entire computation on
behalf of the parties. The target ideal functionality Fml for
protocols is described in Figure 3. Let IDEAL[Z,S,Fml, λ]
denote the output of the environment Z when interacting with
adversary S and honest parties who run the dummy protocol
in presence of functionality F on security parameter λ.
We say that a protocol π securely realizes a functionality
Fml if for every admissible adversary A attacking the real
interaction (without loss of generality, we can take A to be
the dummy adversary), there exists an adversary S (called
a simulator) attacking the ideal interaction, such that for all
environments Z, the following quantity is negligible (in λ):
(cid:10)(cid:10)(cid:10) Pr
(cid:12)(cid:10)(cid:10)(cid:10).
IDEAL[Z,S,Fml, λ] = 1
REAL[Z,A, π, λ] = 1
(cid:12)−Pr
(cid:11)
(cid:11)
Intuitively, the simulator must achieve the same effect (on
the environment) in the ideal interaction that the adversary
achieves in the real interaction. Note that the environment’s
view includes (without loss of generality) all of the messages
that honest parties sent to the adversary as well as the outputs
of the honest parties.
APPENDIX B
A
PROOF OF SMALL TRUNCATION ERROR
Theorem. In ﬁeld Z2l, let x ∈ [0, 2lx ] ∪ [2l − 2lx , 2l), where
l > lx+1 and given shares (cid:7)x(cid:8)0,(cid:7)x(cid:8)1 of x, let (cid:7)(cid:11)x(cid:12)(cid:8)0 = (cid:11)(cid:7)x(cid:8)0(cid:12)
and (cid:7)(cid:11)x(cid:12)(cid:8)1 = 2l−(cid:11)2l−(cid:7)x(cid:8)1(cid:12). Then with probability 1−2lx+1−l,
((cid:7)(cid:11)x(cid:12)(cid:8)0,(cid:7)(cid:11)x(cid:12)(cid:8)1) ∈ {(cid:11)x(cid:12) − 1,(cid:11)x(cid:12),(cid:11)x(cid:12) + 1} , where (cid:11)·(cid:12)
Rec
denotes truncation by lD ≤ lx bits.
Proof. Let (cid:7)x(cid:8)0 = x+r mod 2l, where r is uniformly random
in Z2l, then (cid:7)x(cid:8)1 = 2l − r. We decompose r as r1 · 2lD +
r2, where 0 ≤ r2 < 2lD and 0 ≤ r1 < 2l−lD. We prove
that if 2lx ≤ r < 2l − 2lx, Rec
((cid:7)(cid:11)x(cid:12)(cid:8)0,(cid:7)(cid:11)x(cid:12)(cid:8)1) ∈ {(cid:11)x(cid:12) −
1,(cid:11)x(cid:12),(cid:11)x(cid:12) + 1}. Consider the following two cases.
Case 1: If 0 ≤ x ≤ 2lx, then 0 < x + r < 2l and (cid:7)x(cid:8)0 = x +
r, without modulo. Let x = x1· 2lD + x2, where 0 ≤ x2 < 2lD
and 0 ≤ x1 < 2lx−lD. Then we have x + r = (x1 + r1)· 2lD +
(x2 + r2) = (x1 + r1 + c)· 2lD + (x2 + r2 − c· 2lD ), where the
carry bit c = 0 if x2 + r2 < 2lD and c = 1 otherwise. After the
truncation, (cid:7)(cid:11)x(cid:12)(cid:8)0 = (cid:11)x+r(cid:12) = x1+r1+c and (cid:7)(cid:11)x(cid:12)(cid:8)1 = 2l−r1.
Therefore, Rec