# TPDP'20: 6th Workshop on Theory and Practice of Differential Privacy

## Authors
Rachel Cummings and Michael Hay

## The Complexity of Differential Privacy

**Salil Vadhan**

- **Affiliation**: Center for Research on Computation & Society, John A. Paulson School of Engineering & Applied Sciences, Harvard University, Cambridge, Massachusetts, USA
- **Email**: salil@seas.harvard.edu
- **Website**: [http://seas.harvard.edu/~salil](http://seas.harvard.edu/~salil)
- **Date**: August 9, 2016

### Abstract
Differential privacy is a theoretical framework designed to ensure the privacy of individual-level data during statistical analysis of sensitive datasets. This tutorial provides an introduction and overview of differential privacy, highlighting its deep connections to various topics in computational complexity, cryptography, and theoretical computer science. The content is based on notes from a minicourse given by the author and Kunal Talwar at the 22nd McGill Invitational Workshop on Computational Complexity in February 2014, held at the Bellairs Institute in Holetown, Barbados.

- **Acknowledgments**: This work was partially completed during a visit to the Shing-Tung Yau Center and the Department of Applied Mathematics at National Chiao-Tung University in Hsinchu, Taiwan. It was supported by NSF grant CNS-1237235 and a Simons Investigator Award.

---

## Table of Contents

1. **Introduction and Definition**
   1.1. Motivation
   1.2. The Setting
   1.3. Counting Queries
   1.4. Differential Privacy
   1.5. Basic Mechanisms
   1.6. Discussion of the Definition
   1.7. Preview of the Later Sections

2. **Composition Theorems for Differential Privacy**
   2.1. Post-processing and Group Privacy
   2.2. Answering Many Queries
   2.3. Histograms

3. **Alternatives to Global Sensitivity**
   3.1. Smooth Sensitivity
   3.2. Propose-Test-Release
   3.3. Releasing Stable Values
   3.4. Privately Bounding Local Sensitivity

4. **Releasing Many Counting Queries with Correlated Noise**
   4.1. The SmallDB Algorithm
   4.2. Private Multiplicative Weights

5. **Information-Theoretic Lower Bounds**
   5.1. Reconstruction Attacks and Discrepancy
   5.2. Packing Lower Bounds
   5.3. Fingerprinting Lower Bounds

6. **Computational Lower Bounds**
   6.1. Traitor-tracing Lower Bounds
   6.2. Lower Bounds for Synthetic Data

7. **Efficient Algorithms for Specific Query Families**
   7.1. Point Functions (Histograms)
   7.2. Threshold Functions (CDFs)
   7.3. Conjunctions (Marginals)

8. **Private PAC Learning**
   8.1. PAC Learning vs. Private PAC Learning
   8.2. Computationally Efficient Private PAC Learning
   8.3. The Sample Complexity of Private PAC Learning

9. **Multiparty Differential Privacy**
   9.1. The Definition
   9.2. The Local Model
   9.3. Two-Party Differential Privacy

10. **Computational Differential Privacy**
    10.1. The Definition
    10.2. Constructions via Secure Multiparty Computation
    10.3. Usefulness with a Trusted Curator?
    10.4. Relation to Pseudodensity

11. **Conclusions**

12. **Acknowledgments**

13. **References**

14. **Nomenclature**

---

## 1. Introduction and Definition

### 1.1. Motivation
Suppose you are a researcher in health or social sciences who has collected a rich dataset on your subjects and wants to make it available for others to analyze. However, the dataset contains sensitive information such as disease diagnoses, financial details, or political affiliations, and you have an obligation to protect their privacy. What can you do?

The traditional approach to privacy problems involves "anonymizing" the dataset by removing obvious identifiers like names, addresses, and dates of birth. However, this method is often ineffective because the remaining data can still be used to re-identify individuals, especially with auxiliary information. High-visibility demonstrations have shown that such "re-identification" attacks are feasible using publicly available datasets.

A more promising approach is to mediate access to the data through a trusted interface that only answers queries posed by data analysts. Ensuring that such a system protects privacy is nontrivial. For example, we must prevent queries that target specific individuals, even if they are framed as aggregate queries. Additionally, combinations of results from multiple queries can also reveal sensitive information. While releasing approximate statistics can mitigate some risks, Dinur and Nissim's "reconstruction attacks" showed that with enough approximate statistics, one can reconstruct almost the entire dataset. Thus, there are fundamental limits to what can be achieved in terms of privacy protection while providing useful statistical information.

Cryptographic tools like secure function evaluation and functional encryption do not address these issues. They ensure that nothing is leaked beyond the outputs of the functions being computed, but here we are concerned about the possibility that the outputs themselves leak too much information. Addressing these privacy issues is nontrivial even with a trusted data curator, whereas the presence of a trusted third party trivializes most cryptographic concerns.

### 1.2. The Setting
We consider a setting where a trusted curator holds a dataset \( x \) about \( n \) individuals, modeled as a tuple \( x \in X^n \), where \( X \) is the data universe. The interface to the data is provided by a (randomized) mechanism \( M : X^n \times Q \rightarrow Y \), where \( Q \) is the query space and \( Y \) is the output space of \( M \). To simplify, we assume that \( X \), \( Q \), and \( Y \) are discrete.

The picture we have in mind is as follows:
```
Data Analyst/Adversary
         |
         v
   q(x)  <--- M  <--- q
         ^
         |
X^n (x1, x2, ..., xn)
```

### 1.3. Counting Queries
A basic type of query is a counting query, specified by a predicate on rows \( q : X \rightarrow \{0, 1\} \), and extended to datasets \( x \in X^n \) by counting the fraction of people in the dataset satisfying the predicate:
\[ q(x) = \frac{1}{n} \sum_{i=1}^n q(x_i) \]

It is nontrivial to ensure privacy even when answering counting queries, as answers to several such queries can be combined to reveal information about individual rows.

Several specific families of counting queries are important for statistical analysis:

- **Point Functions (Histograms)**: Here \( X \) is an arbitrary set, and for each \( y \in X \), we consider the predicate \( q_y : X \rightarrow \{0, 1\} \) that evaluates to 1 only on input \( y \). The family \( Q_{\text{pt}} = Q_{\text{pt}}(X) \) consists of the counting queries corresponding to all point functions on data universe \( X \). Answering all of the counting queries in \( Q_{\text{pt}} \) amounts to computing the histogram of the dataset.

- **Threshold Functions (CDFs)**: Here \( X \) is a totally ordered set, and we consider the set \( Q_{\text{thr}} = Q_{\text{thr}}(X) \) of threshold functions. For each \( y \in X \), \( Q_{\text{thr}} \) contains the counting query corresponding to the function \( q_y(z) \) that outputs 1 if and only if \( z \leq y \). Answering all of the counting queries in \( Q_{\text{thr}} \) is equivalent to approximating the cumulative distribution function of the dataset.

- **Attribute Means (1-way Marginals)**: Here \( X = \{0, 1\}^d \), so each individual has \( d \) boolean attributes, and \( Q_{\text{means}} = Q_{\text{means}}(d) \) contains the counting queries corresponding to the \( d \) coordinate functions \( q_j : \{0, 1\}^d \rightarrow \{0, 1\} \) defined by \( q_j(w) = w_j \) for \( j = 1, \ldots, d \). Answering all of the queries in \( Q_{\text{means}} \) amounts to computing the fraction of the dataset possessing each of the \( d \) attributes. These are also referred to as the (1-way) marginal statistics of the dataset.

- **Conjunctions (Contingency Tables)**: Here again \( X = \{0, 1\}^d \), and for an integer \( t \in \{0, 1, 2, \ldots, d\} \), we consider the family \( Q_{\text{conj}}^t = Q_{\text{conj}}^t(d) \) of counting queries corresponding to conjunctions of \( t \) literals. For example, \( Q_{\text{conj}}^2 \) contains the function \( q(w) = w_2 \wedge \neg w_4 \), which could represent a query like "what fraction of individuals in the dataset have lung cancer and are nonsmokers?". Notice that \( Q_{\text{conj}}^t \) consists of the queries in \( Q_{\text{means}}(d) \) and their negations, and \( Q_{\text{conj}} = Q_{\text{conj}}(d) = \cup_{t=0}^d Q_{\text{conj}}^t \) is of size \( 3^d \). The counting queries in \( Q_{\text{conj}} \) are also called \( t \)-way marginals, and answering all of them amounts to computing the \( t \)-way contingency table of the dataset. These are important queries for statistical analysis, and indeed the answers to all queries in \( Q_{\text{conj}} \) are known to be a "sufficient statistic" for "logit models."

---

This revised version aims to provide a clear, coherent, and professional structure for the text, making it easier to follow and understand.