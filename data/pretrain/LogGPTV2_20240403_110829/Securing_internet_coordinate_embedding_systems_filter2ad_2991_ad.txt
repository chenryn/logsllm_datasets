ployment methods can reduce requirements considerably and that
the upper bound yielded by random deployment is indeed very con-
servative.
Having shown that a population of Surveyors can represent the
overall system, the next question is how well the behavior of the
system as captured by the Kalman ﬁlter calibrated by a Surveyor,
can represent the behavior of a single (normal) node. To answer
this question, we carried out an experiment where a population of
nodes took part in a Vivaldi embedding on PlanetLab. Each node
used the Kalman ﬁlter of every Surveyor and generated multiple
prediction errors (one per Surveyor) at every embedding step.
Figure 6 shows the maximum prediction error yielded by each
Surveyor, for each normal node in the system, observed during this
experiment. What we observe is that although each normal node
can ﬁnd at least one Surveyor node whose Kalman ﬁlter yields very
low prediction errors, not every Surveyor is a good representative
for any given normal node. The Surveyor chosen as a representative
by a normal node is therefore important to achieve good prediction
performance (and thus good malicious behavior detection).
Figure 7 plots the prediction accuracy (measured as an average
prediction error) against the distance (measured as an RTT) be-
tween a node and the corresponding Surveyor, as observed during
the PlanetLab experiment. It is clear that better locality between a
node and its Surveyor yields more accurate predictions. This prop-
erty seems intuitive, as a Surveyor closer in terms of RTT will also
be closer in the geometric space, and will thus be more likely to
experience dynamics of the coordinate system similar to that of the
local area where the node resides. This is conﬁrmed in ﬁgure 8
which shows the maximum prediction error, observed for Vivaldi
3.5
3
2.5
r
o
r
r
E
n
o
i
t
c
d
e
r
P
i
1.5
2
1
0.5
0
0
20
40
60
80
100
120
Normal Node ID
140
160
180
0
200
25
20
15
Surveyor Node 
10
5
Figure 6: Maximum prediction errors with Surveyor ﬁlter pa-
rameters (PlanetLab).
0.7
0.6
0.5
0.4
0.3
0.2
0.1
r
o
r
r
i
E
n
o
i
t
c
d
e
r
p
e
g
a
r
e
v
A
unit-variance normal distribution.
0
0
100
200
300
400
500
RTTs (ms)
600
700
800
900
1000
Figure 7: Correlation between ’Node-Surveyor’ RTTs and es-
timation accuracy (PlanetLab).
on PlanetLab, when nodes use the closest Surveyor as their repre-
sentative. Similar results were observed for PlanetLab experiments
with NPS.
Finally, it is again important to note that all the results in this sec-
tion were obtained with randomly chosen Surveyors. Strategically
placing Surveyors to ensure a better coverage of the network and
coordinate space, would simply improve the prediction accuracy,
while reducing the number of Surveyors required.
4. MALICIOUS BEHAVIOR DETECTION
The previous section has shown that normal node behavior can
be modeled by a Kalman ﬁlter. More importantly, it has also been
shown that this technique is powerful and robust enough that the
normal behavior model captured on one node is readily and effec-
tively applicable on other nearby nodes. This property leads to the
idea of Surveyors.
Surveyors are a set of nodes in the coordinate space that exclu-
sively use each other to compute their own coordinates. In other
words, in Vivaldi, Surveyors only use other Surveyors as neighbors,
while in NPS, they only use other Surveyors as reference points
(note that in NPS, all landmarks also act as Surveyors, although
not all reference points will be Surveyors). Of course, Surveyors
can, and will be chosen as neighbors or reference points by other
(non-Surveyor) nodes in the system, but the point is that a Surveyor
r
o
r
r
E
n
o
i
i
t
c
d
e
r
P
m
u
m
x
a
M
i
0.16
0.14
0.12
0.1
0.08
0.06
0.04
0.02
0
0
20 Surveyors, 260 Normal nodes
50
100
150
200
250
300
Normal node ID
Figure 8: Maximum prediction errors with closest Surveyor.
adjusts its coordinate solely in response to embedding steps (i.e.
measurements) with other Surveyors. If Surveyors run a clean ver-
sion of the coordinate embedding software and they are carefully
kept clean of malicious software, such as viruses or worms, that
could implement malicious modiﬁcations to the embedding, then
they can be considered as clean, honest nodes. Because Surveyors
only interact with each other during their own embedding, they are
therefore immune to malicious or anomalous behavior in the sys-
tem, and they therefore observe the behavior of the system in clean,
normal conditions. The idea is then to use the thus obtained nor-
mal behavior model as a basis for anomalous behavior detection at
other nodes of the system. To do so, nodes use the parameters of
the Kalman ﬁlter calibrated at a nearby Surveyor.
It is important to note that the proposed method is entirely dis-
tributed as each node has its own ﬁlter. Indeed, Surveyors calibrate
and recalibrate their own ﬁlter as needed, depending on varying net-
work conditions, and share the resulting ﬁlter parameters with other
nodes, but they take no further active part in anomalous behavior
detection at other nodes. When a node’s ﬁlter needs re-calibrating
(e.g. because it starts giving too many detection alarms), the node
simply obtains fresh ﬁlter parameters from a Surveyor.
4.1 Anomalous Behavior Detection Method
At each embedding step, a node computes a measured relative er-
ror Dn towards a peer node. Recall from section 2 that the Kalman
ﬁlter at the node can provide ˆΔn|n−1, the predicted relative error
from the previously measured relative errors. The innovation pro-
cess of the Kalman ﬁlter yields the deviation between the measured
and predicted relative errors, ηn = (Dn − ˆΔn|n−1), which, in a
system without malicious node, follows a zero-mean gaussian dis-
tribution with variance vη,n = vU + Pn|n−1 (also yielded by the
ﬁlter).
This allows us to detect malicious behavior as a simple hypoth-
esis test. Let H0 be the hypothesis that the peer node has a normal
behavior (i.e.
it is honest). The hypothesis testing simply con-
sists of assessing whether the deviation between the measured and
predicted relative errors is normal enough under expected system
behavior. Given a “signiﬁcance level” α, which determines the
“aggressivity” or “strictness” of the test, the problem is to ﬁnd the
threshold value tn such that
P (|Dn − ˆΔn|n−1| ≥ tn | H0) = α.
(3)
But since, under hypothesis H0, (Dn − ˆΔn|n−1) follows a zero-
mean normal distribution with variance vη,n, we also have that
√
P (|Dn − ˆΔn|n−1| ≥ tn | H0) = 2Q(tn/
(4)
where Q(x) = 1−Φ(x), with Φ(x) being the CDF of a zero-mean,
unit-variance normal distribution.
vη,n),
From equations 3 and 4, we therefore have
√
tn =
vη,nQ−1
(α/2).
(5)
If the observed deviation exceeds the threshold given by equa-
tion 5, then the hypothesis is rejected, the peer node is ﬂagged as
suspicious, the embedding step is aborted and the measured relative
error Dn is discarded (i.e. it is not used to update the state of the
ﬁlter).
Note that a suspicious node, as detected by this test, is not nec-
essarily associated with malicious intent, but could be caused by
changing network conditions. Honest nodes classiﬁed as suspi-
cious represent false positives and have little impact on the system
as long as their occurrence is low. The trade-off between aggres-
sivity and strictness of the test is represented by the so called ROC
(Receiver Operation Characteristic) curves [20]. These curves plot
the true positive rate versus the false positive rate, i.e. the probabil-
ity of correctly detecting a malicious node versus the probability of
labelling an honest node as malicious. In practice trying to increase
the true positive rate (the probability of malicious node detection)
comes at the cost of increasing the false positive rate.
4.2 Generic Detection protocol
In general, on identifying a peer node as suspicious, a node will
replace it, that is choose a new neighbor in Vivaldi or a new refer-
ence point in NPS.
The only exception to this rule is when the node was embedding
against the peer node for the very ﬁrst time. In this particular case,
3 as an indicator of the conﬁdence
the node uses its local error el
it has in its own coordinates, to carry out a second hypothesis test
identical to that presented in the previous section, but this time with
a conﬁdence level of elα. If the test is accepted, then the peer node
gets a reprieve and is not replaced, so that a second embedding
against this peer node will be attempted at a later time.
The main idea behind this potential reprieve for ﬁrst-time peer
nodes is that a node whose coordinate has already converged to-
wards its true value can afford a few aborted embedding steps with
very little impact on the accuracy of its coordinate. On the other
hand, a new peer node which is in the process of joining the net-
work may trigger the abortion of an embedding step, simply be-
cause its coordinate has not converged yet (as opposed to because
it displays a malicious behavior). In this case, the reprieve simply
gives time to the new (joining) peer node to converge before be-
ing identiﬁed as malicious. Of course an embedding node which is
not conﬁdent in its coordinate must strive to reduce the number of
aborted embedding steps so as not to compromise its convergence
in the system, and will therefore grant fewer reprieves (because its
el is higher) than a node that has already converged.
Finally, we use a simple mechanism for the selection of the Sur-
veyor from which a node obtains its calibrated Kalman ﬁlter. All
Surveyor nodes register with an infrastructure server (e.g. the mem-
bership server in NPS can act as Surveyor registrar, while in Vi-
valdi such server must either be introduced or at least integrated
inside an existing bootstrap infrastructure). On joining the coordi-
nate system, a node interrogates this server to obtain the identity
of several (randomly chosen) Surveyors. The node then measures
its distance to these Surveyors and selects the closest one as repre-
sentative. From there on, the node fully complies to the embedding
protocol rules, except that it will use our detection method to accept
or reject embedding steps.
3el is the exponential moving weighted average of the measured
relative errors of all previously completed embedding steps.
However, when the node has rejected half of its current peer
nodes during a same embedding round, it will seek to acquire a
new ﬁlter as the high rejection rate may indicate that the ﬁlter pa-
rameters in use may have become stale (i.e.
the ﬁlter needs “re-
calibrating”). The node then gets from its current Surveyor (or,
as a fallback, any other Surveyors it knows, or the infrastructure
server) the list of all the Surveyors it knows. After acquiring the
current coordinates of these Surveyors, the node selects the closest
one (in term of estimated distance) and obtains its Kalman ﬁlter pa-
rameters. Note that in the experiments we have carried out, which
are described below, we observed very few “recalibrations”, so this
very simple Surveyor selection mechanism was appropriate. How-
ever, more sophisticated approaches can be considered if need be.
5. EVALUATION
We evaluate the effectiveness of the simple anomalous/malicious
behavior detection method in securing both Vivaldi and NPS. For
each of these embedding protocols, we chose the most potent at-
tack described in [11] and experimented with various populations
of malicious nodes within the experimental set-up described in sec-
tion 3. On PlanetLab, all these experiments were run concurrently
so as to experience the same network conditions. In line with the
results of section 3.3, the population of Surveyors was set to 8% of
the overall population. Surveyors and malicious nodes were chosen
at random.
We only present PlanetLab results, as simulation results are al-
ways equivalent or better.
5.1 Performance Metrics
To characterize the performance of our detection test, we use
the classical false/true positives/negatives indicators. Speciﬁcally,
a negative is a normal embedding step which should therefore be
accepted by the test and completed. A positive is a malicious em-
bedding step (i.e. where either, or both, the distance estimation
and distance measurement between the node and its peer node have
been tampered with) which should therefore be rejected by the test
and aborted. The number of negatives (resp. positives) in the pop-
ulation comprising all the embedding steps is PN (resp. PP ).
A false negative is a malicious embedding step that has been
wrongly classiﬁed by the test as negative, and has therefore been
wrongly completed. A false positive is a normal embedding step
that has been wrongly rejected by the test and therefore wrongly
aborted. True positives (resp.
true negatives) are positives (resp.
negatives) that have been correctly reported by the test and there-
fore have been rightly aborted (resp. completed). The number of
false negatives (resp. false positives, true negatives and true posi-
tives) reported by the test is TF N (resp. TF P , TT N and TT P ).
We use the notion of false negative rate (FNR) which is the
proportion of all the malicious embedding steps that have been
wrongly reported as normal by the test, and FNR = TF N /PP .
The false positive rate (FPR) is the proportion of all the normal
embedding steps that have been wrongly reported as positive by the
test, so FPR = TF P /PN . Similarly, the true positive rate (TPR) is
the proportion of malicious embedding steps that have been rightly
reported as malicious by the test, and we have TPR = TT P /PP .
The true positive test fraction (TPTF) is the proportion of
positive tests that correctly identiﬁed malicious embedding steps
(TPTF = TT P /(TT P + TF P )).
5.2 Securing Vivaldi
We experimented with our detection scheme on a Vivaldi system
subjected to a colluding isolation attack as described in [11]. In
this scenario, malicious nodes are trying to isolate a target node, by
repulsing all other nodes away from it. The malicious nodes agree