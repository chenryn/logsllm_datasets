jection vulnerabilities, 1 origin mis-attribution vulnerabil-
ity, 1 cookie-sink vulnerability and 1 application command
5In our implementation,
the acceptor slices are converted back to
JavaScript form for further analysis: the size of acceptor slices increases as
a result of this conversion by a factor of 4 at most in our implementation,
as compared to the numbers reported in column 7
Name
# of
Veriﬁed
Size of
Taint Sinks
Vuln.
Total Inputs
Size of
Acceptor
Inputs
Trace Size
(# of insns)
Avg. size
# of Tests
Vulnerability Type
of AS
to Find
1st Vuln.
Plaxo
Academia
Facebook Chat
ParseURI
AjaxIM
AskAWord
Block Notes
Birthday Reminder
Calorie Watcher
Expenses Manager
MyListy
Notes LP
178
1
44
1
20
3
1
6
3
6
1
5
Progress Bar
151
Simple Calculator
Todo List
TVGuide
Word Monkey
Zip Code Gas
1
1
2
1
5
0
1
0
1
2
1
1
0
0
0
1
0
0
1
0
1
1
1
119
334
127
78
28
26
474
632
681
1,137
578
740
496
27
632
586
26
412
60
21
127
62
28
26
96
246
20
65
47
30
264
27
40
66
26
69
557,442
156,621
6,460,591
55,179
223,504
59,480
11,539
2,178,927
449,214
522,788
17,054
144,829
118,108
72,475
647,849
24,144,843
237,837
410,951
36
286
1,151
638
517
611
766
664
733
1,454
1,468
3,327
475
4
1,181
188
99
248
-
16
-
6
93
93
28
-
-
-
4
-
-
93
-
8,366
93
2
-
Origin Mis-attribution
-
Code injection
Code injection , Application
Command Injection
Cookie Sink
Code injection
-
-
-
Code injection
-
-
Code injection
-
Code injection
Code injection
Code injection
Table 1. Applications for which FLAX observed untrusted data ﬂow into critical sinks. The top 5
subject applications are websites and the rest are iGoogle gadgets.
injection vulnerability. We conﬁrmed that all vulnerabili-
ties reported were true positives by manually inspecting the
JavaScript code and concretely evaluating them with exploit
inputs. The severity of the vulnerabilities varied by appli-
cation and source of untrusted input, which we discuss in
section 5.2.3.
5.2.2 Effectiveness
We quantitatively measure the beneﬁts of taint enhanced
blackbox fuzzing over vanilla taint-tracking and random
fuzzing from our experimental results.
False Positives Comparison. The second column in Ta-
ble 1 shows the number of distinct ﬂows of untrusted data
into critical sink operations observed; only a fraction of
these are true positives. Each of these distinct ﬂows is an in-
stance where a conservative taint-based tool would report a
vulnerability. In contrast, the subsequent step of sink-aware
fuzzing in FLAX eliminates the spurious alarms, and a vul-
nerability is reported (column 3 of Table 1) only when a
witness input is found. It should be noted that FLAX can
have false negatives and could have missed bugs, but com-
pleteness is not an objective for FLAX.
We manually analyzed the taint sinks reported as safe
by FLAX and, to the best of our ability, found them to be
true negatives. For instance, we determined that most of the
sinks reported for the Plaxo case were due to code which
output the length of the untrusted input to the DOM, which
executed repeatedly each time the user typed a character in
the text box. Many of the true negatives we manually an-
alyzed employed sufﬁcient validation – for instance, Face-
book Chat application correctly validates the origin prop-
erty of every postMessage event it received in the exe-
cution. Several other applications validate the structure of
the input before using it in a JavaScript eval statement or
strip dangerous characters before using it in HTML code
evaluation sinks.
Efﬁciency of sink-aware fuzzing. Table 1 (column 8)
shows the number of test cases FLAX generated before it
found the vulnerability for the cases it deems unsafe. Part
of the reason for the small number of cases on average, is
that our fuzzing leverages knowledge of the sink operations.
Column 4 of the Table 1 shows that the size of the origi-
nal inputs for most applications is in the range of 100-1000
characters. Slicing on the tainted data prunes away a signif-
icant portion of the input space, as seen from column 5 of
Table 1. We report an average reduction of 55% from the
original input size to the size of test input used in acceptor
slices.
Further, the average size of an acceptor slice (reported
in column 7 of Table 1) is smaller than the original execu-
tion trace by approximately 3 orders of magnitude. These
reductions in test program size for sink-aware fuzzing allow
sink-aware fuzzing to work with much smaller abstractions
of the original application, thereby signiﬁcantly improving
the efﬁciency of this step.
Qualitative comparison to other approaches. Figure 10
shows one of the several examples that FLAX gener-
ates which can not be directly expressed to the languages
function acceptor(input) {
//input = ’{"action":"","val":""}’;
must_match = ’{]:],]:]}’;
re1 =/\\(?:["\\\/bfnrt]|u[0-9a-fA-F]{4})/g;
re2 =/"[ˆ"\\\n\r]*"|true|false|null|
-?\d+(?:\.\d*)?(?:[eE][+\-]?\d+)?/g;
re3 = /(?:ˆ|:|,)(?:\s*\[)+/g;
rep1 = input.replace(re1, "@");
rep2 = rep1.replace(re2, "]");
rep3 = rep2.replace(re3,"");
if(rep3 == must_match) { return true; }
return false;
}
Figure 10. An example of a acceptor slice
which uses complex string operations for in(cid:173)
put validation, which is not directly express(cid:173)
ible to the off(cid:173)the(cid:173)shelf string decision proce(cid:173)
dures available today.
supported by off-the-shelf existing string decision proce-
dures [21, 25], which FLAX deems as safe. We believe that
even human analysis for such cases is tedious and error-
prone.
5.2.3 Security Implication Evaluation and Examples
To gain insight into their severity we further analyzed the
vulnerabilities reported by FLAX and created proof-of-
concept exploits for a few of them to validate the threat.
All vulnerabilities were disclosed to the developers either
through direct communication or through CERT.
Origin Mis-attribution in Facebook Connect. FLAX
reported an origin mis-attribution vulnerability for
academia.edu, a popular academic collaboration and
document sharing web site used by several academic
universities. FLAX reported that the application was vul-
nerable due to a missing validation check on the origin
property of a received postMessage event. We manually
created a proof-of-concept exploit which demonstrates that
any remote attacker could inject arbitrary script code into
the vulnerable web application. On further analysis, we
found that the vulnerability existed in the code for Face-
book Connect library, which was used by academia.edu as
well as several other web applications. We disclosed the
vulnerability to Facebook developers on December 15th
2009 and they released a patch for the vulnerability within
6 hours of the disclosure.
Code Injection. FLAX reported 8 code injection vulnera-
bilities (DOM-based XSS) in our target applications, where
untrusted values were written to code evaluation constructs
in JavaScript (such as eval, innerHTML). One DOM-
based XSS vulnerability was found on each of the follow-
ing: 6 distinct iGoogle gadgets, an AJAX chat application
(AjaxIM), and one URL parsing library’s demonstration
page. We manually veriﬁed that all of these were true pos-
itives and resulted in script execution in the context of the
vulnerable domains, when the untrusted source was set with
a malicious value. Four of the code injection vulnerabilities
were exploitable when remote attackers entice the user into
clicking a link of an attacker’s choice. The affected web
applications were also available as iGoogle gadgets and we
discuss an a gadget overwriting attack using the CSV vul-
nerabilities below. The remaining 4 code injection vulnera-
bilities were self-XSS vulnerabilities as the untrusted input
source was user-input from a form ﬁeld, a text box, or a text
area. As explained in section 2.1, these vulnerabilities do
not directly empower a remote attacker without additional
social engineering (such as enticing users into copy-and-
pasting text). All gadget developers we were directly able
to communicate with positively acknowledged the concern
and agreed to patch the vulnerabilities.
In a gadget overwriting at-
Gadget Overwriting Attacks.
tack, a remote attacker compromises a gadget and replaces
it with the content of its choice. We assume the attacker
is an entity which controls a web-site and has the ability to
entice the victim user into clicking a malicious link. We de-
scribe a gadget overwriting attack with an example of how
it can be used to create a phishing attack layered on the gad-
get’s CSV vulnerability. In a gadget overwriting attack, the
victim clicks an untrusted link, just as in a reﬂected XSS
attack, and sees a page such as the one shown in Figure 11
in his browser. The URL bar of the page points to the le-
gitimate iGoogle web site, but the gadget has been compro-
mised and displays attacker’s contents: in this example, a
phishing login box which tempts the user to give away his
credentials for Google.
If the user enters his credentials,
they are sent to the attacker rather than Google or the gad-
get’s web site. The attack mechanics are as follows. First,
the victim visits the attacker’s link which points to the vul-
nerable gadget domain (typically hosted at a subdomain of
gmodules.com). The link exploits a code injection CSV vul-
nerability in the gadget and the attack payload is executed in
the context of the gadget’s domain. The attacker’s payload
then spawns a new window which points to the full iGoogle
web page (http://www.google.com/ig) containing
several gadgets including the vulnerable gadget in separate
iframes. Lastly, the attacker’s payload replaces the con-
tent of the vulnerable gadget’s iframe in the new window
with contents of its choice. This cross-window scripting is