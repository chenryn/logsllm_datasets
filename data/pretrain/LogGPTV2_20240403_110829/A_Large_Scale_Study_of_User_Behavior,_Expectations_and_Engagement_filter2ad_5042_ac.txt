(β = -0.429, p-value = < 2e− 16). An ANOVA test between
this model and a base model differing in only the comfort
feature has shown that including the comfort feature did lead
to a better model ﬁt (p-value = < 2.2e− 16). These results
808    30th USENIX Security Symposium
USENIX Association
indicate that users’ desire to grant a permission temporarily
is higher when they are more uncomfortable.
5.3 Explanations and Expectations
Intuitively, the context in which a permission request is made
should have an effect on whether the average user will grant or
deny the request. Here, we deﬁne context as the explanation
(if any) given at the time of the request, as well as any back-
ground information the application has imparted to the partic-
ipant leading up to the request. While PrivaDroid captures ex-
planations at the time of the request, background information
is beyond what PrivaDroid can possibly capture, as it includes
all previous interactions the participant had with the app, as
well as auxiliary information such as documentation on the
application’s Google Play Store page, third-party reviews of
the app, or even informal recommendations through friends.
Nevertheless, to ignore background information would be
perilous, as we feel that background information may have
a strong effect on a user’s disposition towards a permission
request, and may even compensate for a weak or complete
lack of an explanation at the time of the request. Thus, as a
proxy for background information, we collect via surveys, the
participant’s expectation of a permission request at two points
in the user’s interaction with the application.
The ﬁrst point where PrivaDroid measures expectation is
during app install, when participants are asked “which of the
following permissions do you think the app requires?” and
they select as many as they want from the full list of permis-
sion groups. (See Appendix question A.2.1.) The second point
is after the participant has responded to a runtime permission
prompt, when they are asked “did you expect the app to re-
quest this permission?” (regardless of whether the participant
granted or denied the permission). For this question, partici-
pants select either “Yes” or “No”. While expectation cannot
explain how a participant received their context (i.e. how they
came to expect or not expect a permission request), these two
measures approximate the participant’s context from installa-
tion time up to the point that the permission request is made.
Together with the presence of an explanation taken at the
time of the request, we have three measures of the context a
participant experiences for a permission request.
5.3.1 Explanations
As mentioned in Section 4.1, PrivaDroid collects data on per-
mission explanation messages in the form of text dialogs
shown by the app with some UI elements (such as buttons).
PrivaDroid captures these explanations by scanning for An-
droid TextViews that occur right before a permission request,
and capturing those that contain a verb that is related to data
collection and a noun that belongs to a permission. We then
associate this explanation message with the respective per-
mission request. We also record the button options present on
the dialogs and what was clicked by the study participant (to
determine if the participant approved/denied the request).
Because the collection technique relies on heuristics, it
may miss some explanations. To measure the accuracy of our
heuristic we perform ofﬂine analysis across 15 popular apps
on the Android playstore. We run the app with PrivaDroid
installed and record the screen. We then playback the record-
ing and identify all possible explanations provided by the
popular app and compare it against the captured explanations
by PrivaDroid. In total we identiﬁed 30 explanations across
the 15 popular applications with 22 of those captured by our
heuristic. We note that we only encountered one false positive
(collected by PrivaDroid but is not actually an explanation).
This experiment shows that our heuristic is a conservative
detector and our collected data underestimates the number of
permission requests with explanations.
In total, we collected 1804 permission explanation mes-
sages that preceded a grant or a deny across 1097 apps. Thus,
15% of apps in our study include an explanation for at least
one of their permission requests. It is difﬁcult to measure the
quality of an explanation from just the dialog text, as this
misses any images that may be in the dialog, as well as the
overall context in which the dialog is shown. We thus only
examine the correlation between deny rates and the presence
of an explanation and ﬁnd that having an explanation reduced
the permission deny rates to 7.1% as compared to the 15.4%
deny rate for requests with no explanations. To determine if
the presence of an explanation affects participants’ decision
to grant or deny a permission request, we carried out mixed
effects logistic regression analysis due to the presence of mul-
tiple observations from each participant and for each app. We
treat the presence of explanation as a binary independent fea-
ture and the permission decision (‘1’ represents a deny and ‘0’
a grant) as the dependent feature. Similar to the case of tempo-
rary permission grants earlier, we include the permission type
as a ﬁxed effect and the participant and app as random effects.
The trained model shows a signiﬁcant difference between the
presence and absence of an explanation (β = -0.854, p-value
= < 2e− 16). An ANOVA test between this model and a base
model differing in only the explanation feature has shown that
including the explanation feature did lead to a better model
ﬁt (p-value = < 2.2e− 16). These results and the negative
coefﬁcient indicate that the presence of explanation reduces
the deny rate for a permission request.
Explanation message dialog may cause a runtime permis-
sion request to be omitted. For instance, an app might indicate
that it would like to “Use Location to show personalized ads?”
with two buttons: “Not Now” and “Yes”. Clicking on “Not
Now” conveys to the app that the user is going to deny the
permission request, so the app may simply skip making the
request. Because PrivaDroid computes deny rates based on
Android system permission requests, PrivaDroid will under-
count these app-speciﬁc permission deny events. To adjust for
this, each of the 2643 English explanation messages where
USENIX Association
30th USENIX Security Symposium    809
Figure 2: Permission deny rates for install-time expectations
Figure 3: Permission deny rates for run-time expectations
a “Not Now” or an equivalent option was selected by the
participant was manually evaluated by two of the authors to
determine if it is indeed a permission rationale message, re-
sulting in 540 actual pro-active deny messages1. Because this
behavior only affected 15% of applications seen in our study,
we use unadjusted deny rates in the remainder of the paper.
5.3.2 Context Through Expectations
Install-Time Expectations. An app may not need to provide
an explanation if the user has enough context at the time
of the permission request. To approximate this context, we
measure user expectations of permission requests. We use
the term correctly expected for cases when the participant
expected a particular permission would be requested and the
1Some of the explanations were actually permission requests by web
pages in a browser
Figure 4: Permission expectations vs reality
app requested it, the term incorrectly expected for cases when
a participant expected a permission but the app did not request
it, and the term unexpected for cases when a participant did
not expect the permission, but the app actually requested it.
We ﬁrst examine whether our participants’ install-time ex-
pectations match reality. Figure 4 shows rates for the three
types of expectations for the 6 permission types with the
most permission request events. The rate at which partici-
pants correctly expect future permission requests ranges from
7% for the Phone permission to 20% for the Location per-
mission; these results suggest that at install time, participants
do not have enough context to give them an accurate picture
of an app’s permission needs. We hypothesize that this be-
havior might come from participants becoming habituated
to assuming that apps frequently request unnecessary per-
missions [9, 20, 44, 46]. Overall, this suggests that users do
not have the context necessary to expect permission requests
before an app is installed.
Figure 2 shows the deny rate for correctly expected and
unexpected permission requests for individual permissions.
(Note we cannot compute deny rate for incorrectly expected
permissions since the app doesn’t ask for a permission in
this case.) Deny rates are always higher for unexpected per-
mission requests, which agrees with previous research [48].
The average deny rate for expected permissions is 10.2%,
whereas the average deny rate for unexpected permissions is
14.2%. This phenomenon of participants denying unexpected
permissions more frequently holds in aggregate and across
permission types. In order to see if the participants’ install-
time expectations affect their permission decisions, we again
carried out a mixed effects logistic regression analysis. Not
all participants shared their permission expectations at install
time, so we modeled install-time expectation as a categorical
feature with three levels – Yes, No and Not Surveyed; and
Yes is chosen as the reference level. We modeled install-time
expectation as the independent feature and the permission de-
cision as the dependent feature. Similar to the earlier analysis,
we include the permission type as a ﬁxed effect and the par-
ticipant and app as random effects. The trained model shows
a signiﬁcant difference between expecting and not expecting
810    30th USENIX Security Symposium
USENIX Association
CameraContactsLocationMicrophonePhoneStoragePermission type0.02.55.07.510.012.515.017.520.0Deny rate (%)Install-time expectationCorrectly expectedUnexpectedCameraContactsLocationMicrophonePhoneStoragePermission type010203040Deny rate (%)Runtime expectationExpectedUnexpectedCameraContactsLocationMicrophonePhoneStoragePermission typeCorrectly expectedIncorrectly expectedUnexpectedInstall-time expectation (%)15112014716737868778375121112910920406080Country and Region
Avg # of Grants
Avg # of Denys
Avg Deny Rate
Intra-country Deny Rate
Std Deviation
Canada
US
Argentina
UK
France
Spain
South Africa
India
Singapore
Hong Kong
Overall
Gender
Male
Female
Other
Did not say
Education level
15.22
27.21
9.77
16.30
12.37
13.10
16.07
31.58
13.69
6.28
17.51
3.55
3.72
3.25
3.09
2.85
4.14
2.60
4.86
2.58
3.05
3.52
18.9%
12.0%
25.0%
15.9%
18.7%
24.0%
13.9%
13.3%
15.9%
32.7%
16.7%
Avg # of Grants
Avg # of Denys
Avg Deny Rate
# of Participants
18.41
15.99
23.40
13.56
3.48
3.51
4.00
5.78
15.9%
18.0%
14.6%
29.9%
Avg # of Grants
Avg # of Denys
Avg Deny Rate
# of Participants
Less than high school
High school
Bachelor’s or more
Did not say
14.49
17.86
17.29
20.36
2.46
3.19
4.14
5.01
14.5%
15.2%
19.3%
19.8%
Table 2: Permission Request Events and Decisions
20.5%
12.6%
25.2%
19.8%
17.3%
21.0%
14.1%
14.7%
22.7%
30.0%
6.1%2
1,044
655
10
10
146
945
555
73
Avg Privacy Sen-
sitivity
1.25
1.10
1.19
1.13
1.00
1.16
1.39
1.16
1.29
1.18
1.17
Avg Privacy Sen-
sitivity
1.13
1.25
1.30
0.84
Avg Privacy Sen-
sitivity
1.07
1.18
1.20
1.06
a permission at install-time (β = 0.37, p-value = 0.000451
for No categorical response). An ANOVA test between this
model and a base model differing in only the install-time
expectation categorical feature has shown that including the
install-time expectation did lead to a better model ﬁt (p-value
= 5.931e− 11). These results and the positive coefﬁcient in-
dicate that a permission is more likely to be denied when it is
unexpected at install time.
Runtime Expectations. In 7,711 (72%) of our surveyed run-
time permission events, participants expected the permission
request and in the remaining 28% they did not. The number
of permission events where an initially unexpected install-
time permission request changed to an expected request at