computes the sum of those values. That is, PrivEx supports
summation queries. Importantly, there is no protection against
an attack on the integrity of the statistics. This enables a
3We use a bold typeface to represent vectors.
3
Fig. 1. The number of client connections (y-axis) for 15 different websites
(x-axis) as actually occurred (“Actual”) and as reported by PrivEx (“Noised”).
A single malicious relay falsely reports that it observed 1000 connections to
website #2.
malicious contributor (e.g., a relay) to submit an arbitrary value
that can signiﬁcantly impact the aggregate result.4
To demonstrate this type of manipulation, we made a trivial
modiﬁcation to the PrivEx source code (as provided by Elahi
et al. [15]) to include a single malicious relay. Consistent with
their work, we consider a query that aggregates the number of
visits destined to 15 particular websites. Such a query could be
useful to answer the question: which websites are most popular
among Tor users? In our experiment, we use the same default
parameters as is included in the PrivEx source code. However,
we modify the behavior of a single relay to falsely claim that
it has observed 1000 visits to website #2.
Figure 1 shows the result of this manipulation. The actual
distribution of website visits is shown in red, and indicates that
website #6 is, by far, the most popular site visited via Tor. The
noised distribution as reported by PrivEx, shown in patterned
blue, paints a different picture: according to the results of the
query, website #2 appears to similarly be popular amongst Tor
users.
The above example is of course one of many possible
manipulations. More generally, a single malicious relay that
participates in PrivEx can supply any (false) count to manipu-
late the aggregated result, and do so without risking detection.
We emphasize that the above “attack” falls entirely outside
of the threat model considered by Elahi et al. [15]. That is, we
are not disclosing errors in their design or implementation.
This paper makes the argument that while PrivEx provides
strong privacy guarantees, its lack of integrity guarantees is
problematic for many types of queries that would be useful
for Tor. Since Tor is a volunteer-operated network, the barrier
to entry for operating a relay is very small. Indeed, there
have been several instances [34] in which relay operators have
been found to behave maliciously. While we view PrivEx as
4Elahi et al. posit that range proofs could potentially be added to PrivEx
to bound the impact of untrue statistics. However, as the authors admit, such
techniques lead to signiﬁcant computation and communication overheads [15].
123456789101112131415Website No.01503004506007509001050No. of Client ConnectionsActualNoiseda signiﬁcant step forward in private data collection, we argue
in this paper that privacy must be combined with integrity
protections to provide a useful statistics gathering service.
IV. HISTOR OVERVIEW
HisTor’s goal
is to provide differentially private data
collection for Tor that is robust against manipulation. We intro-
duce HisTor by describing its participants and system model
(§IV-A), threat model (§IV-B), query capabilities (§IV-C), and
operation (§IV-D).
A. Participants and System Model
There are three types of participants in HisTor:
Data collectors (DCs) [15] are relays that collect statistics
that will later be aggregated. Example of DCs and the data
that they collect include guard relays that count the number
of client connections, middle relays that count requests to Tor
Hidden Service introduction points, and exit relays that keep
track of exit bandwidth. Developing a comprehensive list of
possible queries is beyond the scope of this paper. Our aim
is rather to provide a secure and private statistics gathering
technique for Tor that is sufﬁciently general to be adapted for
many types of queries.
As with vanilla Tor, HisTor relies on secure communica-
tion via TLS, and we use Tor’s existing directory infrastructure
as a trust anchor to locate public keys and authenticate mes-
sages. Since relays are already heavily burdened in Tor, we aim
to keep both the computation and communication overheads
of HisTor low for the DCs.
The analyst is a party that
issues queries to the data
collectors and receives noised query responses. We envision
that, at least initially, the analyst will be the maintainers of
Tor.
Finally, we introduce three mixes that are third parties that
provide the required amount of differentially private noise.
Mixes are dedicated servers responsible for enabling HisTor
queries. We assume that all parties can obtain the mixes’
public keys, which for example, could be attested to by the
Tor directory authorities.
Also included in the HisTor ecosystem are the Tor users
who use the Tor client software to communicate via Tor, the
destinations that the users are visiting, and the Tor directory
servers and mirrors. Since HisTor imposes no changes to
the normal operations of Tor, we mostly omit discussing
these components unless they are pertinent to the security and
privacy properties of HisTor.
B. Threat Model and (Informal) Security Guarantees
We consider both internal and external threats to privacy
and data integrity:
Internal adversaries.
DCs are volunteer-operated relays
and can be malicious. A malicious DC is a Byzantine adversary
that can, for example, disobey HisTor protocols, submit
false statistics, and/or refuse to participate. Malicious DCs
may also collect and leak sensitive information (e.g., the IP
addresses of clients or destination addresses); such leakage is
also possible with existing Tor relays, and we do not consider
defenses against such behavior here. HisTor ensures that no
colluding group of DCs can reveal more information than
would otherwise be available by pooling their knowledge.
Malicious DCs may attempt to manipulate query results
by reporting erroneous data, as in §III. If c is the number of
DCs that participate in a query and f is the fraction of the
participating DCs that are malicious, then HisTor guarantees
that the maximum inﬂuence over the aggregate result is ±f c.
This is a direct consequence of applying the (, δ)-differential
privacy scheme of Chen et al. [6]: each relay (malicious or
not) can contribute at most 1 to each element in its supplied
vector. If a DC refuses to participate in a query or submits
a malformed vector, its bit vector is considered to be all 0s.
Consequently, malicious DCs cannot disrupt (i.e., cause denial-
of-service) HisTor queries by submitting false or malformed
data.
Malicious mixes may also behave arbitrarily. HisTor
provides strong privacy guarantees when (1) no more than
one of the mixes is malicious and (2) a malicious mix does
not collude with a malicious analyst. HisTor employs secret
sharing techniques to ensure that non-colluding mixes cannot
learn un-noised query results.
Mixes can attempt to manipulate query results by adding
false values, improperly constructing noise vectors, or modi-
fying or discarding the encrypted vectors it receives from the
DCs. HisTor’s integrity guarantees ensure that the analyst can
detect manipulated query results as long as one of the mixes
is honest.
In HisTor, the analyst issues queries and receives noised
results from the mixes. We consider a malicious analyst that
colludes with other parties to attempt
to learn non-noised
answers to queries. HisTor achieves (, δ)-differential privacy
when no more than one mix is malicious and no malicious
mix colludes with the analyst. If a malicious DC colludes with
either a mix or the analyst, no information that is not already
available to the malicious DC is revealed.
External adversaries. HisTor is robust against an external
adversary that observes all HisTor-related communication. All
HisTor exchanges are secured by TLS. We assume that public
keys can be reliably retrieved—for example, by leveraging
Tor’s existing directory infrastructure—and that all properly
signed messages can be authenticated.
We also consider an external adversary that applies pressure
(e.g., through a subpoena or threat of violence) to an honest
DC to reveal its individual counters. We argue that papers
(such as this one) that propose collecting information that
would otherwise not be gathered by anonymizing relays have a
responsibility to evaluate such compulsion attacks. We describe
in §V techniques that limit the amount of information that can
be “handed over” by a pressured honest relay to an adversary.
C. Queries
In HisTor, for each query, each DC i contributes a bit
vector vi of length b, where b is a parameter of the query. For
ease of exposition, we refer to each vector position as a bin.
The result of the query is the noised aggregate vector
described in Eq. 2. Essentially, the query returns a vector of
4
summations(cid:80)c
are shufﬂed to provide indistinguishability.
i=1 vi plus the added noise. The data and noise
HisTor supports two types of queries: class queries and
histogram queries.
Class queries.
In a class query, each bin j is assigned a
class label Cj. For Tor, potentially useful class labels include
(but are not limited to) protocols/ports seen by exit relays and
client version numbers seen by guards. The semantics of class
queries allow the analyst to ask for all j ∈ [1, b]: how many
relays have witnessed the event described by the label Cj?
The analyst speciﬁes the semantic meaning for each bin.
For example, in the case of reporting which ports have been
seen by exit relays, the analyst can specify a query such that
the ﬁrst bin in DCs’ bit vectors indicates whether the exit has
witnessed http trafﬁc, the second bin indicates whether it has
seen ssh trafﬁc, etc. By examining the aggregated and noised
results, the analyst learns approximately how many exit relays
have seen the speciﬁed trafﬁc types.
Histogram queries.
Histogram queries allow the analyst
to learn the distribution of some value, taken over the DCs.
As examples, histogram queries can inform the analyst of
the distribution of client connections seen by guards or the
bandwidth seen by exit relays.
For histogram queries, each DC maintains an encrypted
counter of the relevant statistic (e.g., observed bandwidth).
Each bin j is assigned an interval [Lj, Uj) where Lj, Uj ∈ Z
such that Lj ≥ Uj−1 when j > 1. When a bin bj = 1, this
indicates that the encrypted counter is in the range [Lj, Uj).
Note that at most one bin belonging to a DC is set to 1; all
other bins are set to 0. (This is unlike a class query; there,
multiple bins/classes can be set to 1.)
The vector sum over all DCs’ bin vectors (i.e.,(cid:80) vi) yields
the distribution of the DCs’ counters. As explained next, mixes
add random noise vectors to apply differential privacy to this
distribution.
D. Operation
HisTor operates
in loosely synchronized hour-long
epochs. At the beginning of each epoch, each DC zeroes all of
its bins. As with PrivEx, HisTor ensures that data sets do not
carry over between queries; that is, no more than one query
within an epoch can cover a given bin. Extending HisTor
to support differential privacy when data must be continually
observed [5, 12] is left as an interesting area of future work.
Currently, as with PrivEx, we enforce independence between
different epochs by zeroing all counters. (We include discus-
sions of the absoluteness of this independence and the effect
of a privacy budget for differentially private queries in §XI.)
HisTor’s workﬂow begins when the analyst issues a query
to the DCs and mixes. Currently,
this is manual process
that requires conﬁguring Tor relays to report the statistic of
interest (e.g., connection counts, observed bandwidth, etc.).
We envision that future versions of HisTor will support
SQL-like semantics to automate this process. Our prototype
implementation, described in more detail in §IX, uses Tor’s
existing statistics module and can be easily conﬁgured to
5
aggregate the data that Tor already collects. We have already
added hooks for bandwidth and connection counting.
Figure 2 shows how queries are processed in HisTor.
DCs maintain three redundant copies of encrypted counters
(encrypted binary vectors). Each copy is encrypted using the
public key of one of the three mixes.
At the end of the epoch, these encrypted vectors are further
obfuscated by xor’ing with a random binary vector R. Xor’ing
with the random vector ensures that mixes cannot learn the
plaintext of the DCs’ binary vectors, even after decrypting
with their private GM key. (Recall that GM is a homomorphic
cryptosystem with respect to xor [16].) The DCs send one copy
of its GM-encrypted and xor’d vector to each mix, as shown
in Figure 2. Additionally, the DCs communicate secret shares
of R across the three mixes.
Each mix then decrypts the GM encryption, yielding the
original binary vectors xor’d with a random vector. Each such
vector is added to a matrix; that is, this matrix contains the xor-
encrypted vectors from the DCs. Mixes then add n randomly
generated rows to the vector, where n is computed according
to Eq. 1 (where, δ = 10−6/c). Finally, the vector is randomly
shufﬂed columnwise. Both the addition of the n rows of
noise and the shufﬂing is performed using cryptographically
secure random seeds, which are shared amongst the mixes.
Consequently, the three mixes add identical noise vectors and
perform the identical shufﬂe.
Finally, the mixes communicate the resultant matrices to
the analyst as well as the shufﬂed secret shares of the R
random vector. The analyst then combines the shares to obtain
the shufﬂed R, and uses it to decrypt both the shufﬂed data
and noise records (which are indistinguishable) in the matrix.
To obtain the aggregate, the analyst then subtracts the expected
noise value according to Eq. 2.
V. OBLIVIOUS COUNTERS
To mitigate compulsion attacks, HisTor minimizes the
amount of information that DCs need to maintain through the
use of oblivious counters. In this section, we assume that the
DCs are honest. A malicious DC (relay) need not use oblivious
counters and can trivially leak sensitive statistics, regardless of
whether HisTor is used.
Each DC maintains three binary vectors of length b, where
b is determined by the query. Each binary element of the
ﬁrst binary vector is GM-encrypted using the public key of
the ﬁrst mix; the second vector is GM-encrypted using the
public key of the second mix, and so on. For ease of notation,
we focus below on one such GM-encrypted vector which we
v = (cid:104)E+(v1), . . . , E+(vb)(cid:105), where E+(·) denotes
denote as e
encryption using the public key belonging to the pertinent mix.
The scheme is identical for the three encrypted binary vectors
maintained by each DC.
A. Oblivious class counters
Class queries allow the analyst
to discover how many
DCs encountered an event (see §IV-C). Recall that each vj
corresponds to a class label Cj, which for example could
denote a particular protocol or type of event. When vj = 1,
Fig. 2. An overview of HisTor query processing. Each mix receives an encrypted vector from each DC. The mixes then add noise and perform a column-wise
shufﬂe. The resulting vectors are then sent to the analyst, who in turn can compute the aggregate result.
above scheme trivially achieves resistence to the compulsion
attack.
B. Oblivious histogram counters
In the case of histogram queries, recall that the analyst’s
query maps each vector element vj to a range [Lj, Uj) such
that Lj ≥ Uj−1 when j > 1. When vj is 1, this indicates that
the statistic of interest as measured by the DC is in the range
[Lj, Uj). Hence, at most one vj is set to 1. As a special case,
we set Ub = ∞.
Let wj be the bin width of vector element vj;