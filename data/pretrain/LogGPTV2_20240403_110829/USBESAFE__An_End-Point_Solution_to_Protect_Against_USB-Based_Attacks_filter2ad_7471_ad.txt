tribution of the benign interarrival time values; (2) to ﬁnd
out whether varying the pause time value has any impact on
the volume of information in each session as well as n-gram
construction; and (3) to deﬁne the maximum interarrival time
value between two TraceEvents before we consider the user
to be starting a new typing session. To determine an optimal
pause time, we examined three pause time candidates (in mil-
liseconds): 20,000, 40,000, and 60,000 milliseconds, with a
sampling period of 200 and 500 milliseconds. For each pause
time value, we normalized the values for class codes 0 and 3.
Figure 4: Unique 2-grams for the ﬁrst 200 USB packet traces in our
dataset. The number of unique sequences signiﬁcantly decreases as
USBeSafe observes more USB packets.
5.3.4 Determining the Effect of N-Grams
To understand the diversity of the collected USB packets for
the USB HID class, we performed an experiment on construct-
ing n-grams by varying the value of n from 2 to 3. First, we
examined the number of unique 2-grams that can be found in
the ﬁrst 200 USB trace ﬁles which contained 5,938,492 USB
packets. The number of unique 2-grams on labeled dataset
is shown in Figure 4. As depicted, the number of unique se-
quences signiﬁcantly decreases as USBESAFE observes more
USB packets. The ﬁnding suggests that n-grams can closely
capture the characteristics of the benign dataset. That is, if
the model is deployed, it is unlikely that benign keyboard
activities will not have been observed in our training phase,
resulting in low false alarms.
To verify this, we performed an experiment that incorpo-
rated the entire labeled dataset that is a representative mix of
possible BadUSB attacks as well as benign USB HIDs. We
varied n and the threshold k of malicious n-grams that need
to be observed before a USB device is ﬂagged as malicious.
The results for n = 2 and n = 3 and k ranging over an interval
050100150200No. of Benign USB Event Traces03000006000009000001200000No. of Unique 2-gramNo. of Unique 2-gramUSENIX Association        22nd International Symposium on Research in Attacks, Intrusions and Defenses 97from 1 to 50 are evaluated. Figure 5 shows the results of the
analysis. As depicted, the detection rates are very high, spe-
cially for small values of k. The false positive rate is 0.21%
for k = 3.
Figure 5: Detection results for 2-grams and 3-grams. The detection
threshold k is on the X-axis (e.g., k = 2 and n = 3 means that a USB
trace must match two 3-grams to generate an alert).
6 Real-world Deployment
The main goal of this experiment is to evaluate the detection
accuracy of USBESAFE by incorporating an unlabeled dataset
which has not been observed during the training phase. We
incorporated the results of our previous measurement on the
labeled datasets by setting the window size and number of
n-grams to established values (n = 2 and k = 3). For a real-
world deployment, we ﬁrst need to determine how much data
is required for initial model training if a new user decides
to use USBESAFE as a service. To answer this question,
we ran an experiment on seven new machines for 20 days.
Depending on the type of machines and their usage, multiple
HID and non-HID devices were connected to the machines.
This resulted in generating different numbers of trace ﬁles per
machine. Therefore, for easier interpretation, we performed
the tests by varying the number of days, referred to as the
training window size, instead of the number of trace ﬁles
as ﬁve out of seven machines had more than one trace ﬁle
per day. We also generated ﬁve new BadUSB attacks (e.g.,
establishing covert channels, logging keyboard activity) for
testing.
To run the test, we varied the training window size from 1
to 20 days for all the machines and computed TP and FP rates
to determine the optimal training window size. The result of
this experiment showed that USBESAFE requires two to four
training days to keep the TP rate over 93% with a 0.9% FP
rate in all the machines. Our analysis on the training win-
dow size also showed that the machines with two connected
HID devices (a keyboard and a mouse) do not usually need
more than three training days to reach that level of detection
accuracy.
We ran another experiment to test whether the general
model that was constructed based on our labeled 423 trace
ﬁles would work well in the new machines. We observed that
USBESAFE achieved on average 90% TP rate with a 2.2%
FP rate across all the machines. In fact, per user deployment
model achieved a higher detection rate with a signiﬁcantly
lower false positive rate (FP = 0.9%) at the cost of two to
four training days. However, since the general model does
not require any initial training for a large-scale deployment,
we recommend temporarily activating the general model on a
new machine while USBESAFE is in the training phase.
We also deployed the general model on three multi-user ma-
chines for ﬁve consecutive days. We did not receive any com-
plaint from users during the test period. However, we cannot
provide any strong security guarantees to protect multi-user
machines or produce low false positive rate as we do not have
enough data to make any statistically signiﬁcant claim on the
accuracy of USBESAFE for this deployment option. Further-
more, recall that one of the main design goals of USBESAFE
was to reduce the risk of BadUSB attacks – a form of targeted
attacks on end-users. Consequently, the architecture, feature
selection, and implementation details make USBESAFE a
more effective solution for single user machines. In fact, pro-
tecting multi-user machines has a different set of security and
privacy requirements and is out of the scope of this paper.
6.1 Re-training the Detection Model
USBESAFE should counter the problem of model drift, in
which the constructed model makes an assumption that the
incoming USB packets will exhibit new normal patterns that
have not been observed during the training phase. For ex-
ample, users’ typing patterns can change for various reasons
(e.g., completing a speciﬁc task) or URBs interarrival rate
might change across different devices which might affect
the detection accuracy. Therefore, a practical deployment of
USBESAFE requires periodically re-training the system. To
simulate a practical deployment, we started an experiment by
training USBESAFE on all the new machines and tested with
the attack payloads we developed. Our analysis shows that,
based on the labeled dataset and subsequent data collection,
training USBESAFE with an initial dataset similar to ours
and re-training every 16 days were sufﬁcient to maintain the
detection rate over 93% with less than 1% false positive cases
across all the machines.
The re-training process, including the false positive and
false negative analysis, usually took on average 2.1 hours each
time during the course of experiment. More speciﬁcally, the
time needed to re-train the model and address model drift was
a function of the size of input data which took approximately
82 seconds on average every 16 days on normal PCs and
laptops. However, the manual intervention for evaluating the
results was almost inevitable. We had to verify how and why
01020304050Detection Threshold020406080100TP vs FPFalse Positives (2-grams)True Positives (2-grams)False Positive (3-grams)True Postives (3-grams)98          22nd International Symposium on Research in Attacks, Intrusions and DefensesUSENIX Associationfalse positive or false negative cases occurred, and whether
they were produced as a result of model drift or an evasive
attack. In a real-world deployment, USBESAFE requires only
the re-training schedule which is less than two minutes. In
Section 7, we provide more details on the risk of adversaries’
malicious inﬂuence during the re-training process.
6.2 Evaluating False Positives
During 20 days of experiment, the system processed
3,434,452 USB packets across seven machines. To speed
up the false positive analysis, we asked the users to log the
number of times, the exact time and date they received the
system’s alert. We received false positive reports on two ma-
chines. A more in-depth analysis revealed that all the false
positive cases in one of the machines were produced in two
consecutive days when the user was ﬁlling out a set of web
forms with random data for research purposes. USBESAFE
detected these USB packets as new observations because the
payload histograms as well as the interarrival time values
among the URBs were following a signiﬁcantly different
pattern with the novelty score 32%.
We observed that the false positive cases on the other ma-
chine was because of running a user study experiment in
which several users were asked to run a test on the perceived
functionality of websites by interacting with them while trig-
gering their event listeners. A few users in that experiment
were typing random characters in multiple ﬁelds of web forms
in those websites. In fact, the false positive cases in both ma-
chines were very similar in a sense that they were ﬂagged
by USBESAFE when the users performed a set of activities
that did not match with their normal interaction with the ma-
chines. We did not encounter any other cases of legitimate
USB packets being incorrectly reported. These results are in
fact quite encouraging as the experiment was performed on
a set of new machines with relatively small training window
size compared to our ﬁrst experiment without imposing a
discernible impact on the detection accuracy of USBESAFE.
7 Discussions and Limitations
Note that a fundamental design goals of USBESAFE is to keep
the protection mechanism completely in the background. We
assume that adversaries have signiﬁcant freedom in provid-
ing varying responses for device identities to evade potential
defense mechanisms. Furthermore, adversaries can convince
users to connect seemingly benign devices to hosts for various
reasons. Consequently, shifting the burden of responsibility to
users to verify the reported identity, and decide on unknown
devices is less likely to be a very reliable defense mechanism.
In this section, we discuss the limitations of USBESAFE, and
the implications of these limitations on the detection results.
First, recall that USBESAFE is an anomaly-based detec-
tion system where the detection results depend on the quality
and volume of the trained dataset. If an attack occurs during
the learning phase, USBESAFE accepts data or behavior that
would otherwise be considered malicious. Therefore, an addi-
tional analysis should be performed on the authenticity of the
new data for re-training purposes to prevent such malicious
inﬂuences. This may increase the cost of the data collection
as the proposed model is a per user solution. Furthermore,
as mentioned earlier, an attacker can try to imitate benign
USB trafﬁc patterns and evade the detection mechanism. An
attacker can be successful in running these attacks, if she is
able to accurately learn the typing behavior of the target user.
Our analysis shows that automatically injecting artiﬁcial de-
lays (See Appendix B) can decrease the novelty score of USB
trafﬁc. However, it cannot entirely change the trafﬁc patterns,
or possibly adapt to each user typing pattern.
Second, recall that one of the primary design decisions of
USBESAFE is to treat existing operating systems in a black
box fashion, and build a central security model of USBESAFE
independent of the user’s perception of malice. However, US-
BESAFE cannot provide strong protection guarantees against
scenarios where an adversary attempts to trick users into vol-
untarily disabling USBESAFE, for instance, by mimicking
the output of USBESAFE, and forcing the user to disable
protection. We stress that these issues are fundamental to any
host-based protection tool.
Third, USBESAFE cannot provide any security guarantees
in scenarios where an adversary has a privilege to run code
in the kernel. In fact, if an adversary can successfully run
malicious code in the kernel, she can also disable all the pos-
sible defense mechanisms, including USBESAFE. For this
reason, we explicitly consider kernel-level attacks outside the
scope of USBESAFE’s threat model. Despite all the limita-
tions, USBESAFE provides important practical security ben-
eﬁts that complement the standard USB protocol employed
in operating systems without any signiﬁcant detriments to
performance.
8 Conclusion
In this paper, we empirically show that it is possible to de-
velop models that can accurately explain the the nature of
USB trafﬁc. We presented the design and implementation of
USBESAFE, and demonstrated that it can successfully block
modern BadUSB-style attacks without relying on end-user
security decisions or requiring changes in the current USB
protocol or the operating system. We hope that the concepts
we propose will be useful for end-point protection providers
and facilitate creating similar services on other platforms to
enhance defense mechanisms against future malicious de-
vices.
Acknowledgements
This work was partially supported by the Ofﬁce of Naval Re-
search (ONR) under grant N00014-19-1-2364 award and the
United States Air Force under Air Force Contract No. FA8702-
USENIX Association        22nd International Symposium on Research in Attacks, Intrusions and Defenses 9915-D-0001. Any opinions, ﬁndings, conclusions or recommen-
dations expressed in this material are those of the author(s)
and do not necessarily reﬂect the views of the United States
Air Force.
DISTRIBUTION STATEMENT A. Approved for public
release. Distribution is unlimited.
[11] KOLBITSCH, C., KIRDA, E., AND KRUEGEL, C. The
power of procrastination: Detection and mitigation of
execution-stalling malicious code. In Proceedings of
the 18th ACM Conference on Computer and Communi-
cations Security (New York, NY, USA, 2011), CCS ’11,
ACM, pp. 285–296.
References
[1] Anderson–Darling Test. Springer New York, New York,
NY, 2008, pp. 12–14.
[2] USB Rubber Ducky.
https://hakshop.com/
products/usb-rubber-ducky-deluxe, 2017.
[3] ANGEL, S., WAHBY, R. S., HOWALD, M., LENERS,
J. B., SPILO, M., SUN, Z., BLUMBERG, A. J., AND
WALFISH, M. Defending against malicious peripherals
with cinch. In USENIX Security Symposium (2016).
[4] BATES, A. M., LEONARD, R., PRUSE, H., LOWD, D.,
AND BUTLER, K. R. B. Leveraging USB to establish
host identity using commodity devices. In 21st Annual
Network and Distributed System Security Symposium,
NDSS 2014, San Diego, California, USA, February 23-
26, 2014 (2014).
[5] BROCKER, M., AND CHECKOWAY, S.
iseeyou: dis-
abling the macbook webcam indicator led. In Proceed-
ings of the 23rd USENIX conference on Security Sympo-
sium (2014), USENIX Association, pp. 337–352.
[6] DIWAN, S., PERUMAL, S., AND FATAH, A. Complete
security package for usb thumb drive. Computer Engi-
neering and Intelligent Systems 5, 8 (2014), 30–37.
[7] HERNANDEZ, G., FOWZE, F., YAVUZ, T., BUTLER,
K. R., ET AL. Firmusb: Vetting usb device ﬁrmware
using domain informed symbolic execution. ACM Con-
ference on Computer and Communications Security
(2017).
[8] JIM WALTER. “Flame Attacks”: Brieﬁng and Indi-
http://downloadcenter.
cators of Compromise.
mcafee.com/products/mcafee-avert/sw/old_
mfe_skywiper_brief_v.1.pdf.zzz, 2012.
[9] KARSTEN NOHL, SACHA KRIBLER, JAKOB LELL.
BlackHat,
BadUSB–On accessories that turn evil.
2014.
[10] KHARAZ, A., ARSHAD, S., MULLINER, C., ROBERT-
SON, W., AND KIRDA, E. UNVEIL: A large-scale,
automated approach to detecting ransomware. In 25th
USENIX Security Symposium (USENIX Security 16)
(Austin, TX, 2016), USENIX Association, pp. 757–772.
[12] LEARN, S. Anomaly detection with Local Outlier Factor
(LOF). http://scikit-learn.org/stable/auto_
examples/neighbors/plot_lof.html.
[13] LEARN, S.
Nearest Neighbors.
http://
scikit-learn.org/stable/modules/neighbors.
html.
[14] LEARN, S. One Class SVM. http://scikit-learn.
org/stable/modules/generated/sklearn.svm.
OneClassSVM.html.
[15] LETAW, L., PLETCHER, J., AND BUTLER, K. Host
identiﬁcation via usb ﬁngerprinting. In Systematic Ap-
proaches to Digital Forensic Engineering (SADFE),
2011 IEEE Sixth International Workshop on (2011),
IEEE, pp. 1–9.
[16] NEUGSCHWANDTNER, M., BEITLER, A., AND KUR-
MUS, A. A transparent defense against usb eavesdrop-
ping attacks. In Proceedings of the 9th European Work-
shop on System Security (2016), ACM, p. 6.