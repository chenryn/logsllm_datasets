title:Data Poisoning Attacks to Local Differential Privacy Protocols
author:Xiaoyu Cao and
Jinyuan Jia and
Neil Zhenqiang Gong
Data Poisoning Attacks to 
Local Differential Privacy Protocols
Xiaoyu Cao, Jinyuan Jia, and Neil Zhenqiang Gong, Duke University
https://www.usenix.org/conference/usenixsecurity21/presentation/cao-xiaoyu
This paper is included in the Proceedings of the 30th USENIX Security Symposium.August 11–13, 2021978-1-939133-24-3Open access to the Proceedings of the 30th USENIX Security Symposium is sponsored by USENIX.Data Poisoning Attacks to Local Differential Privacy Protocols
Xiaoyu Cao, Jinyuan Jia, Neil Zhenqiang Gong
Duke University
{xiaoyu.cao, jinyuan.jia, neil.gong}@duke.edu
Abstract
Local Differential Privacy (LDP) protocols enable an un-
trusted data collector to perform privacy-preserving data an-
alytics. In particular, each user locally perturbs its data to
preserve privacy before sending it to the data collector, who
aggregates the perturbed data to obtain statistics of interest. In
the past several years, researchers from multiple communities–
such as security, database, and theoretical computer science–
have proposed many LDP protocols. These studies mainly fo-
cused on improving the utility of the LDP protocols. However,
the security of LDP protocols is largely unexplored.
In this work, we aim to bridge this gap. We focus on LDP
protocols for frequency estimation and heavy hitter identiﬁ-
cation, which are two basic data analytics tasks. Speciﬁcally,
we show that an attacker can inject fake users into an LDP
protocol and the fake users send carefully crafted data to the
data collector such that the LDP protocol estimates high fre-
quencies for arbitrary attacker-chosen items or identiﬁes them
as heavy hitters. We call our attacks data poisoning attacks.
We theoretically and/or empirically show the effectiveness of
our attacks. We also explore three countermeasures against
our attacks. Our experimental results show that they can effec-
tively defend against our attacks in some scenarios but have
limited effectiveness in others, highlighting the needs for new
defenses against our attacks.
1 Introduction
Various data breaches [1–3] have highlighted the challenges
of relying on a data collector (e.g., Equifax) to protect users’
private data. Local Differential Privacy (LDP), a variant of
differential privacy [19], aims to address such challenges. In
particular, an LDP protocol encodes and perturbs a user’s data
to protect privacy before sending it to the data collector, who
aggregates the users’ perturbed data to obtain statistics of
interest. Therefore, even if the data collector is compromised,
user privacy is still preserved as the attacker only has access
to users’ privacy-preserving perturbed data. Because of the re-
silience against untrusted data collectors, LDP has attracted in-
creasing attention in both academia and industry. Speciﬁcally,
many LDP protocols [8–10,15,18,22,31–33,45,47,59–63,69]
have been developed in the past several years. Moreover, some
of these protocols have been widely deployed in industry in-
cluding but not limited to Google, Microsoft, and Apple. For
instance, Google deployed LDP [22] in the Chrome browser to
collect users’ default homepages for Chrome; Microsoft [17]
integrated LDP in Windows 10 to collect application usage
statistics; and Apple [53] adopted LDP on iOS to identify pop-
ular emojis, which are subsequently recommended to users.
Since LDP perturbs each user’s data, it sacriﬁces utility of
the data analytics results obtained by the data collector. There-
fore, existing studies on LDP mainly focused on improving
the utility via designing new methods to encode/perturb users’
data and aggregate the perturbed data to derive statistical
results. However, the security of LDP is largely unexplored.
In this work, we aim to bridge this gap. In particular, we
propose a family of attacks called data poisoning attacks to
LDP protocols. In our attacks, an attacker injects fake users
to an LDP protocol and carefully crafts the data sent from the
fake users to the data collector, with the goal to manipulate the
data analytics results as the attacker desires. Speciﬁcally, we
focus on LDP protocols for Frequency Estimation and Heavy
Hitter Identiﬁcation, which are two basic data analytics tasks
and are usually the ﬁrst step towards more advanced tasks.
The goal of frequency estimation is to estimate the fraction
of users (i.e., frequency) that have a certain item for each of
a set of items, while the goal of heavy hitter identiﬁcation
is to only identify the top-k items that are the most frequent
among the users without estimating the items’ frequencies.
Our attacks can increase the estimated frequencies for arbi-
trary attacker-chosen items (called target items) in frequency
estimation or promote them to be identiﬁed as top-k heavy hit-
ters in heavy hitter identiﬁcation. Our attacks result in severe
security threats to LDP-based data analytics. For example,
an attacker can promote a phishing webpage as a popular
default homepage of Chrome; an attacker can increase the
estimated popularity of its (malicious) application when LDP
USENIX Association
30th USENIX Security Symposium    947
is used to estimate application popularity; and an attacker can
manipulate the identiﬁed and recommended popular emojis,
resulting in bad user experience and frustration.
The major challenge of data poisoning attacks is that, given
a limited number of fake users an attacker can inject, what data
the fake users should send to the data collector such that the
attack effectiveness is maximized. To address the challenge,
we formulate our attacks as an optimization problem, whose
objective function is to maximize the attack effectiveness and
whose solution is the data that fake users should send to the
data collector. We call our optimization-based attack Maximal
Gain Attack (MGA). To better demonstrate the effectiveness
of MGA, we also propose two baseline attacks in which the
fake users send randomly crafted data to the data collector.
Then, we apply our MGA and the baseline attacks to three
state-of-the-art LDP protocols for frequency estimation (i.e.,
kRR [33], OUE [59], and OLH [59]) and one state-of-the-art
LDP protocol for heavy hitter identiﬁcation (i.e., PEM [62]).
We theoretically evaluate the effectiveness of our attacks.
Speciﬁcally, we derive the frequency gain of the target items,
which is the difference of the target items’ estimated frequen-
cies after and before an attack. Our theoretical analysis shows
that our MGA can achieve the largest frequency gain among
possible attacks. Our theoretical results also show a funda-
mental security-privacy tradeoff for LDP protocols: when an
LDP protocol provides higher privacy guarantees, the LDP
protocol is less secure against our attacks (i.e., the frequency
gains are larger). Moreover, we observe that different LDP
protocols have different security levels against our attacks. For
instance, OUE and OLH have similar security levels against
our attacks, and kRR is less secure than OUE and OLH when
the number of items is larger than a threshold. We also empir-
ically evaluate our attacks for both frequency estimation and
heavy hitter identiﬁcation using a synthetic dataset and two
real-world datasets. Our empirical results also show the effec-
tiveness of our attacks. For example, on all the three datasets,
our MGA can promote 10 randomly selected target items to
be identiﬁed as top-15 heavy hitters when the attacker only
injects 5% of fake users.
We also explore three countermeasures, i.e., normalization,
detecting fake users, and detecting the target item, to defend
against our attacks. Speciﬁcally, in normalization, the data
collector normalizes the estimated item frequencies to be a
probability distribution, i.e., each estimated item frequency is
non-negative and the estimated frequencies of all items sum
to 1. Since our attacks craft the data for the fake users via
solving an optimization problem, the data from the fake users
may follow certain patterns that deviate from genuine users.
Therefore, in our second countermeasure, the data collector
aims to detect fake users via analyzing the statistical patterns
of the data from the users, and the data collector ﬁlters the
detected fake users before estimating frequencies or identify-
ing heavy hitters. The third countermeasure detects the target
item without detecting the fake users when there is only one
target item. Our empirical results show that these counter-
measures can effectively defend against our attacks in some
scenarios. For example, when the attacker has 10 target items,
normalization can reduce the frequency gain of our MGA to
OUE from 1.58 to 0.46 and detecting fake users can reduce
the frequency gain to be almost 0 because the data collector
can detect almost all fake users. However, our attacks are still
effective in other scenarios. For instance, when the attacker
has 10 randomly selected target items, our MGA to OLH still
achieves a frequency gain of 0.43 even if both detecting fake
users and normalization are used. Our results highlight the
needs for new defenses against our attacks.
In summary, our contributions are as follows:
• We perform the ﬁrst systematic study on data poisoning
attacks to LDP protocols for frequency estimation and
heavy hitter identiﬁcation.
• We show that, both theoretically and/or empirically, our
attacks can effectively increase the estimated frequencies
of the target items or promote them to be identiﬁed as
heavy hitters.
• We explore three countermeasures to defend against our
attacks. Our empirical results highlight the needs for new
defenses against our attacks.
2 Background and Related Work
We consider LDP protocols for two basic tasks, i.e., frequency
estimation [10, 18, 22, 31–33, 59, 63, 64, 69] and heavy hit-
ter identiﬁcation [9, 45, 62]. Suppose there are n users. Each
user holds one item from a certain domain, e.g., the default
homepage of a browser. We denote the domain of the items
as {1,2,··· ,d}. For conciseness, we simplify {1,2,··· ,d} as
[d]. In frequency estimation, the data collector (also called cen-
tral server) aims to estimate the frequency of each item among
the n users, while heavy hitter identiﬁcation aims to identify
the top-k items that have the largest frequencies among the n
users. Frequency of an item is deﬁned as the fraction of users
who have the item.
2.1 Frequency Estimation
An LDP protocol for frequency estimation consists of three
key steps: encode, perturb, and aggregate. The encode step
encodes each user’s item into some numerical value. We
denote the space of encoded values as D. The perturb step
randomly perturbs the value in the space D and sends the per-
turbed value to the central server. The central server estimates
item frequencies using the perturbed values from all users in
the aggregate step. For simplicity, we denote by PE(v) the
perturbed encoded value for an item v. Roughly speaking, a
protocol satisﬁes LDP if any two items are perturbed to the
same value with close probabilities. Formally, we have the
following deﬁnition:
948    30th USENIX Security Symposium
USENIX Association
Deﬁnition 1 (Local Differential Privacy). A protocol A sat-
isﬁes ε-local differential privacy (ε-LDP) if for any pair of
items v1,v2 ∈ [d] and any perturbed value y ∈ D, we have
Pr(PE(v1) = y) ≤ eεPr(PE(v2) = y), where ε > 0 is called
privacy budget and PE(v) is the random perturbed encoded
value of an item v.
Moreover, an LDP protocol is called pure LDP if it satisﬁes
the following deﬁnition:
Deﬁnition 2 (Pure LDP [59]). An LDP protocol is pure if
there are two probability parameters 0 < q < p < 1 such that
the following equations hold for any pair of items v1,v2 ∈
[d],v1 (cid:4)= v2:
Pr(PE(v1) ∈ {y|v1 ∈ S(y)}) = p
Pr(PE(v2) ∈ {y|v1 ∈ S(y)}) = q,
(1)
(2)
where S(y) is the set of items that y supports.
We note that the deﬁnition of the support S(y) depends on
the LDP protocol. For instance, for some LDP protocols [18,
59], the support S(y) of a perturbed value y is the set of items
whose encoded values could be y. For a pure LDP protocol,
the aggregate step is as follows:
1
n
n∑
i=1
1S(yi)(v)− q
p− q
˜fv =
,
(3)
where ˜fv is the estimated frequency for item v ∈ [d], yi is the
perturbed value from the ith user, and 1S(yi)(v) is an character-
istic function, which outputs 1 if and only if yi supports item
v. Formally, the characteristic function 1S(yi)(v) is deﬁned as
follows: 1S(y)(v) is 1 if v ∈ S(y) and 0 otherwise.
Roughly speaking, Equation (3) means that the frequency
of an item is estimated as the fraction of users whose per-
turbed values support the item normalized by p,q, and n.
Pure LDP protocols are unbiased estimators of the item fre-
quencies [59], i.e., E[ ˜fv] = fv, where fv is the true frequency
for item v. Therefore, we have:
2.1.1 kRR
Encode: kRR encodes an item v to itself. Therefore, the
encoded space D for kRR is identical to the domain of items,
which is D = [d].
Perturb: kRR keeps an encoded item unchanged with a
probability p and perturbs it to a different random item a ∈ D
with probability q. Formally, we have:
d−1+eε (cid:2) p,
d−1+eε (cid:2) q,
if a = v,
otherwise,
Pr(y = a) =
(cid:2)
eε
1
(5)
where y is the random perturbed value sent to the central
server when a user’s item is v.
Aggregate: The key for aggregation is to derive the support
set. A perturbed value y only supports itself for kRR. Specif-
ically, we have S(y) = {y}. Given the support set, we can
estimate item frequencies using Equation (3).
2.1.2 OUE
Encode: OUE encodes an item v to a d-bit binary vector eeev
whose bits are all zero except the v-th bit. The encoded space
for OUE is D = {0,1}d, where d is the number of items.
Perturb: OUE perturbs the bits of the encoded binary vec-
tor independently. Speciﬁcally, for each bit of the encoded
binary vector, if it is 1, then it remains 1 with a probability p.
Otherwise if the bit is 0, it is ﬂipped to 1 with a probability q.
Formally, we have:
(cid:2)
(cid:2) p,
1
2
1
eε+1
if i = v,
otherwise,
(cid:2) q,
Pr(yi = 1) =
(6)
where the vector yyy = [y1 y2 ··· yd] is the perturbed value for
a user with item v.
Aggregate: A perturbed value yyy supports an item v if and
only if the v-th bit of yyy, denoted as yv, equals to 1. Formally,
we have S(yyy) = {v|v ∈ [d] and yv = 1}.
E[1S(yi)(v)] = n( fv(p− q) + q).
n∑
i=1
(4)
Equation (4) will be useful for the analysis of our attacks.
Next, we describe three state-of-the-art pure LDP protocols,
i.e., kRR [18], OUE [59], and OLH [59]. These three protocols
are recommended for use in different scenarios. Speciﬁcally,
kRR achieves the smallest estimation errors when the number
of items is small, i.e., d < 3eε + 2. When the number of items
is large, both OUE and OLH achieve the smallest estimation
errors. OUE has a larger communication cost, while OLH
has a larger computation cost for the central server. There-
fore, when the communication cost is a bottleneck, OLH is
recommended, otherwise OUE is recommended.
2.1.3 OLH
(cid:5)], where d
Encode: OLH leverages a family of hash functions H, each of
which maps an item v ∈ [d] to a value h ∈ [d
(cid:5) < d.
(cid:5) = eε + 1 as it achieves the best
In particular, OLH uses d
performance [59]. An example of the hash function family
H could be xxhash [14] with different seeds. Speciﬁcally,
a seed is a non-negative integer and each seed represents
a different xxhash hash function. In the encode step, OLH
randomly picks a hash function H from H. When xxhash
is used, randomly picking a hash function is equivalent to
randomly selecting a non-negative integer as a seed. Then,
OLH computes the hash value of the item v as h = H(v). The
tuple (H,h) is the encoded value for the item v. The encoded
space for OLH is D = {(H,h)|H ∈ H and h ∈ [d
(cid:5)]}.
USENIX Association
30th USENIX Security Symposium    949
Perturb: OLH only perturbs the hash value h and does not
change the hash function H. In particular, the hash value stays
(cid:5) and switches to a different
unchanged with probability p
(cid:5). Formally, we have:
(cid:5)] with probability q
value in [d
(cid:2)
Pr(y = (H,a)) =