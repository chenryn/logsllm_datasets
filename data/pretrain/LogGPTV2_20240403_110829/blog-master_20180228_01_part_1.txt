## PostgreSQL ADHoc(任意字段组合)查询 与 字典化 (rum索引加速) - 实践与方案1 - 菜鸟 某仿真系统   
### 作者                                                             
digoal                                                             
### 日期                                                             
2018-02-28                            
### 标签                                                             
PostgreSQL , rum , adhoc , index scan , bitmap scan , gin     
----                                                             
## 背景      
### 业务背景    
某系统数据量：    
20亿行左右，64个字段，原始数据多为字符串类型。（大多数字段的唯一值有限）    
需求：    
1\. 查询，任意字段组合查询，求聚合值。    
2\. 查询并发，1000左右查询并发，每次查询响应时间要求100ms以内。    
3\. 写入、更新，要求延迟1秒内。    
高峰时写入、更新可达20万行/s。    
业务上允许批量写入。    
4\. 要求加字段方便。    
5\. 要求实时计算（无需建模），或者说要求加统计维度方便，不需要等建模结束。    
### PostgreSQL 该场景特性    
使用PostgreSQL可以很好的满足这样的需求，PostgreSQL具备以下特性，适合ADHoc的非建模查询：    
1、索引接口：    
bloom接口，支持多字段组合索引，任意字段组合的查询，实现lossy的过滤，收敛目标数据到一定的BLOCKs。    
gin接口，倒排索引，广泛应用于多值类型(如全文检索类型、数组、JSON、K-V等)，多字段组合索引等。支持多值类型或任意字段组合搜索，bitmap index scan将目标数据收敛到一定的BLOCKs，加速查询。    
rum接口，新版本的rum不仅支持tsvector类型，同时还支持了array类型。rum的优势是不需要bitmap scan，因此没有recheck的过程，查询时的CPU消耗比GIN索引接口更低。    
[《PostgreSQL bitmap scan的IO放大的原理解释和优化》](../201801/20180119_03.md)      
2、索引扫描方法    
index scan，索引扫描，直接命中数据。    
bitmap index scan，返回包含目标数据的BLOCK，数据库进行CPU RECHECK。这种方法支持多个字段合并扫描。    
[《PostgreSQL bitmapAnd, bitmapOr, bitmap index scan, bitmap heap scan》](../201702/20170221_02.md)      
3、其他特性，辅助这个业务场景：    
并行计算（支持并行扫描、过滤、排序、JOIN、聚合、创建索引等），（例如 100亿数据，并行排序求top-k只要40秒），更多指标参考：    
[《阿里云 PostgreSQL 产品生态；案例、开发实践、管理实践、学习资料、学习视频》](../201801/20180121_01.md)      
异步调用与聚合，也支持支持DBLINK异步调用，实现并行计算。    
分区表。    
水平拆库。    
序列，可用于字典化。例子：    
[《PostgreSQL 全局ID分配(数据字典化)服务 设计实践》](../201802/20180227_02.md)      
UDF。可以支持非常复杂的数据库函数编程，实现复杂逻辑。    
RULE。实现数据写入、更新时自动对数据进行字典化。    
### PostgreSQL 场景优化手段    
1\. 字典化（大多数字段的唯一值有限，唯一值个数100-5000万左右），30个左右字段需要字典化（可做成ETL，实时字典化）。字典化的目的是压缩空间，提高处理效率。如果性能OK可以不做字典化。    
2\. 写入自动字典化(可以使用RULE来实现)    
3\. 查询时自动翻译    
4\. bloom, rum, gin, 数组, tsvector, 多字段BITMAP SCAN      
5\. 分库，分表。dblink异步并行调用。    
### dblink异步调用加速介绍    
[《PostgreSQL 全局ID分配(数据字典化)服务 设计实践》](../201802/20180227_02.md)      
[《PostgreSQL VOPS 向量计算 + DBLINK异步并行 - 单实例 10亿 聚合计算跑进2秒》](../201802/20180210_01.md)      
[《PostgreSQL 相似搜索分布式架构设计与实践 - dblink异步调用与多机并行(远程 游标+记录 UDF实例)》](../201802/20180205_03.md)      
[《PostgreSQL 相似搜索设计与性能 - 地址、QA、POI等文本 毫秒级相似搜索实践》](../201802/20180202_01.md)      
[《PostgreSQL dblink异步调用实现 并行hash分片JOIN - 含数据交、并、差 提速案例 - 含dblink VS pg 11 parallel hash join VS pg 11 智能分区JOIN》](../201802/20180201_02.md)      
[《惊天性能！单RDS PostgreSQL实例 支撑 2000亿 - 实时标签透视案例 (含dblink异步并行调用)》](../201712/20171223_01.md)      
[《阿里云RDS PostgreSQL OSS 外部表 - (dblink异步调用封装)并行写提速案例》](../201709/20170906_01.md)      
### 水平分库方法介绍    
1、使用plproxy水平分库    
[《PostgreSQL 最佳实践 - 水平分库(基于plproxy)》](../201608/20160824_02.md)      
[《阿里云ApsaraDB RDS for PostgreSQL 最佳实践 - 4 水平分库 之 节点扩展》](../201512/20151220_04.md)      
[《阿里云ApsaraDB RDS for PostgreSQL 最佳实践 - 3 水平分库 vs 单机 性能》](../201512/20151220_03.md)      
[《阿里云ApsaraDB RDS for PostgreSQL 最佳实践 - 2 教你RDS PG的水平分库》](../201512/20151220_02.md)      
2、使用postgres_fdw + pg_pathman水平分库    
[《PostgreSQL 9.6 sharding based on FDW & pg_pathman》](../201610/20161027_01.md)      
3、其他基于PostgreSQL的NewSQL或MPP开源产品    
pg-xl    
https://www.postgres-xl.org/    
citusdb    
https://www.citusdata.com/    
greenplum    
http://www.greenplum.org/    
pg_shardman    
https://github.com/postgrespro/pg_shardman    
## 方案1 - 全局字典化 + 数组类型 + rum索引    
### 全局字典化    
全局字典化的意思是，所有字段的取值空间构成一个大的取值空间，“字段名+字段值”在取值空间内唯一。    
字典化后，可以选择INT4或INT8作为字典化后的元素类型。    
### 数组    
由于使用了全局字典，所以可以使用一个数组字段，代替所有字段。    
```    
create table tbl(    
  id int8 primary key,    
  c1 int,    
  c2 int,    
  ...    
  c50 int    
);    
```    
代替为    
```    
create table tbl(    
  id int8 primary key,    
  dict int[]    
);    
```    
使用数组的好处多多，例如加字段易如反掌，因为你不需要改结果，只需要把新加的字段的内容填充到数组中。    
原来的AND查询使用数组包含操作代替，原来的OR查询，使用数组相交操作代替。    
### RUM索引    
RUM索引，已经支持数组类型。支持包含、相交查询。    
### DEMO    
DEMO将抛开如何将文本转换为字典的部分，你可以参考如下：    
[《PostgreSQL 全局ID分配(数据字典化)服务 设计实践》](../201802/20180227_02.md)      
#### 1、创建插件    
```    
create extension rum;    
```    
#### 2、创建生成随机值的函数（即字典值），输入一个范围，返回这个范围内的随机值    
```    
create or replace function gen_rand(    
  int,  -- 最小值(包含)    
  int   -- 最大值(包含)    
) returns int as $$    
  select $1+(random()*($2-$1))::int;    
$$ language sql strict;    
```    
#### 3、创建一个函数，用于生成长度为50的随机数组，规则是这样的，字典取值空间100万个元素的16个字段，字典取值空间1000万个元素的16个字段，字典取值空间5000万个元素的18个字段。    
总共50个字段，消耗10.76亿个字典取值空间。因此可以使用INT4作为字典元素类型。    
```    
create or replace function gen_ran_array() returns int[] as $$    
declare    
  res int[] := '{}';  -- 结果    
  x int;         -- 组范围    
  offset1 int;   -- 偏移量    
begin    
  -- 第1段消耗1600万值    
  offset1 := (-2147483648);  -- 第1批段偏移量为int4最小值    
  x := 1000000;    -- 每段取值范围为100万    
  for i in 1..16    
  loop    
    res := res||gen_rand(offset1+(i-1)*x, offset1+i*x-1);    
  end loop;    
  -- 第2段消耗1.6亿值    
  offset1 := (-2147483648)+16*1000000;  -- 第2批段偏移量    
  x := 10000000;  -- 每段取值范围为1000万    
  for i in 1..16    
  loop    
    res := res||gen_rand(offset1+(i-1)*x, offset1+i*x-1);    
  end loop;    
  -- 第3段消耗9亿值    
  offset1 := (-2147483648)+16*1000000+16*10000000;   -- 第3批段偏移量为    
  x := 50000000;  -- 每段取值范围为5000万    
  for i in 1..18    
  loop    
    res := res||gen_rand(offset1+(i-1)*x, offset1+i*x-1);    
  end loop;    
  -- 总共消耗10.76亿值，在INT4的取值空间内    
  return res;    
end;    
$$ language plpgsql strict;    
```    
#### 4、数据示例    
```    
postgres=# select gen_ran_array();    
                                                          gen_ran_array                                                          
--------------------------------------------------------------------------------------------------------    
 {-2146646308,-2145683415,-2145349222,-2143926381,-2143348415,-2141933614,-2141364249,-2140223009,-2138645116,-2138311094,-2137328519,-2136424380,-2134763612,-2134461767,-2132675440,-2131727900,-2125512613,-2117580976,-2108206637,-2093806503,-2084537076,-2072042857,-2071092129,-2060488058,-2043914532,-2039914771,-2025797284,-2021177739,-2004046058,-1997857659,-1988910392,-1975672648,-1963342019,-1901896072,-1864565293,-1806580356,-1724394364,-1708595351,-1643548404,-1582467707,-1549967665,-1485791936,-1429504322,-1413965811,-1334697903,-1289093865,-1226178368,-1204842726,-1169580505,-1109793310}    
(1 row)    
```    
#### 5、建表    
```    
create table tbl_test(    
  id serial primary key,     
  dict int[]  -- 使用数组代替了50个字段    
);    
```    
#### 6、建数组rum索引    
```    
create index idx_tbl_test on tbl_test using rum (dict rum_anyarray_ops);    
```    
#### 7、单实例，单表写入2亿条测试数据    
```    
vi test2.sql    
insert into tbl_test (dict) select gen_ran_array() from generate_series(1,10);    
pgbench -M prepared -n -r -P 1 -f ./test2.sql -c 56 -j 56 -t 357143    
```    
#### 8、单实例写入速度，约3.3万行/s。    
写入约3.3万行/s，10个节点约33万行/s。    
CPU 约 20% 空闲。    
```    
progress: 2.0 s, 3363.5 tps, lat 16.716 ms stddev 4.362    