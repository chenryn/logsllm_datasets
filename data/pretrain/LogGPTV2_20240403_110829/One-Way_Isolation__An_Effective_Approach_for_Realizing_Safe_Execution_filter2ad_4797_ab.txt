dynamic redirection, where the target for redirection is de-
termined automatically during the execution of SEE pro-
cesses. However, the possibility of hidden dependencies
means that the implementation of dynamic redirection may
have to be different for different kinds of objects. Speciﬁ-
cally, in our SEE architecture, dynamic redirection is sup-
ported by service-speciﬁc proxies. Currently, there is a
proxy for ﬁle service, and we envision proxies for other ser-
vices such as WWW or email.
In our current implementation, system call interposition
is used to implement restriction and static redirection. We
restrict all modiﬁcation operations other than those that in-
volve the ﬁle system and the network. In the case of ﬁle
operations, all accesses to normal ﬁles are permitted, but ac-
cesses to raw devices and special purpose operations such
as mounting ﬁle systems are disallowed. In terms of net-
work operations, we permit any network access for which
static redirection has been set up. In addition, accesses to
the name server and X-server are permitted. (In reality, SEE
processes should not get unrestricted access to X-server, but
our current implementation provides no mechanism to mon-
itor and enforce policies on access to X-server.)
Dynamic redirection is currently supported in our imple-
mentation for only ﬁle system accesses. It is realized using
a proxy called the Isolation File System (IFS), which is de-
scribed in detail in Section 3.
2.2. Committing Changes
There are two key challenges in committing: one is to
ensure consistency of the resulting system state; the other
is efﬁciency — to reduce the space and time overheads for
logging and re-running of operations to a level that pro-
vides good performance. Below, we provide a high-level
overview of the issues involved in commit.
The key problem in terms of consistency is that a re-
source accessed within the SEE may have been indepen-
dently accessed outside of the SEE. This corresponds to
concurrent access on the same resource by multiple pro-
cesses, some within SEE and some outside. One possible
consistency criterion is the serializability criterion used in
databases. Other consistency criteria may be appropriate as
well, e.g., for some text ﬁles, it may be acceptable to merge
the changes made within the SEE with changes made out-
side, as long as the changes involve disjoint portions of the
ﬁle. A detailed discussion of the issues involved in deﬁning
commit criteria is presented in Section 4.1.
There may be instances where the commit criteria may
not be satisﬁed. In this context, we make the following ob-
servations:
(cid:15) There is no way to guarantee that results can be com-
mitted automatically and produce consistent system
state, unless we are willing to delay or disallow exe-
cution of some applications on the host OS. Introduc-
ing restrictions or delays on host OS processes will de-
feat the purpose of SEE, which is to shield the host OS
from the actions of SEE processes. Hence this option
is not considered in our approach.
(cid:15) If the results are not committed, then the system state
is unchanged by tasks carried out within the SEE. This
means that these tasks can be rerun, and will most
likely have the same desired effect. Hopefully, the
conﬂicts were the results of infrequent activities on the
host OS, and won’t be repeated this time, thus enabling
the results to be committed.
(cid:15) If retry isn’t an option, the user can manually resolve
conﬂicts, deciding how the ﬁles involved in the con-
ﬂict should be merged. In this case, the commit cri-
teria identiﬁes the ﬁles and operations where manual
conﬂict resolution is necessary.
As a ﬁnal point, we note that if a process within an SEE
communicated with another process executing within a dif-
ferent SEE, then all such communicating SEEs need to be
committed as if they were part of a single distributed trans-
action. Currently, our implementation does not support dis-
tributed commits. Our approach for committing the results
of operations performed within a single SEE is described in
Section 4.
3. Isolation File System (IFS)
3.2. Design Details
3.1. High-Level Overview
In principle, a ﬁle system can be viewed as a tree struc-
ture. Internal nodes in this tree correspond to directories or
ﬁles, whereas the leaves correspond to disk blocks holding
ﬁle data. The children of directory nodes may themselves
be directories or ﬁles. The children of ﬁle nodes will be disk
blocks that either contain ﬁle data, or pointers to ﬁle data.
This view of ﬁle system as a tree suggests an intuitive
way to realize one-way isolation semantics for an entire ﬁle
system: when a node in the original ﬁle system is about to
be modiﬁed, a copy of this node, as well as all its ances-
tors, is created in a “private” area of the ﬁle system called
temporary storage. The write operation, as well as all other
subsequent operations on this node, are then redirected to
this copy.
In essence, we are realizing isolation using copy-on-
write. Although the copy-on-write technique has been used
extensively in the context of plain ﬁles, it has not been stud-
ied in the context of directories. Realizing IFS requires us
to support copy-on-write for the entire ﬁle system, includ-
ing directories and plain ﬁles.
In our approach, copy-on-write on directories is sup-
ported using a shallow-copy operation, i.e., the directory
itself is copied, but its entries continue to point to objects in
the original ﬁle system. In principle, one can use shallow-
copy on ﬁles as well, thus avoiding the overhead of copying
disk blocks that may not be changed within the IFS. How-
ever, the internal organization of ﬁles is speciﬁc to particu-
lar ﬁle system implementations, whereas we want to make
IFS to be ﬁle-system independent. Hence ﬁles are copied in
their entirety.
IFS is implemented by interposing ﬁle system operations
within the OS kernel at the Virtual File System (VFS) layer.
VFS is a common abstraction in Unix across different ﬁle
systems, and every ﬁle system request goes through this
layer. Hence extensions to functionality provided at VFS
layer can be applied uniformly and transparently to all un-
derlying ﬁle systems such as ext2, ext3 and NFS.
We realize VFS layer interposition using the stackable ﬁle
system approach described in [37]. In effect, this approach
allows one to realize a new ﬁle system that is “layered” over
existing ﬁle systems. Accesses to the new ﬁle system are
ﬁrst directed to this top layer, which then invokes the VFS
operations provided by the lower layer. In this way, the new
ﬁle system extends the functionality of existing ﬁle systems
without the need to deal with ﬁle-system-speciﬁc details.
The description in the previous section presented a sim-
pliﬁed view of the ﬁle system, where the ﬁle system has a
tree-structure and consists of only plain ﬁles and directories.
In reality, UNIX ﬁle systems have a DAG (directed acyclic
graph) structure due to the presence of hardlinks. In addi-
tion, ﬁle systems contain other types of objects, including
symbolic links and special device ﬁles. As mentioned ear-
lier, IFS does not support special device ﬁles. An exception
to this rule is made for pty’s and tty’s, as well as pseudo
devices like /dev/zero, /dev/null, etc. In these cases,
access is redirected to the corresponding device ﬁles on the
main ﬁle system. A symbolic link is simply a plain ﬁle,
except that the content of the ﬁle is interpreted as the path
name of another ﬁle system object. For this reason, they
don’t need any special treatment. Thus, we need only de-
scribe how IFS deals with hard links (and the DAG structure
that can result due to their use.)
When the ﬁle system is viewed as a DAG, its internal
nodes correspond to directories, and the leaves correspond
to ﬁles. As mentioned earlier, the IFS does not look into the
internal structure of ﬁles, and hence we treat them as leaf
objects in the DAG. All nodes in the DAG are identiﬁed
by a unique identiﬁer called the Inode number.
(The in-
ode number remains unique across deletion and recreation
of ﬁle objects.) The edges in the DAG are links, each of
which is identiﬁed by a name and the Inode number of the
object pointed by the link. This distinction between nodes
and links in the ﬁle system plays a critical role in every as-
pect of IFS design and implementation.
Figure 1 illustrates the operation of IFS. The bottom layer
corresponds to a host OS ﬁle system. The middle layer is
the temporary storage to hold modiﬁed copies of ﬁles and
directories. The top layer shows the view within IFS, which
is a combination of the views in the bottom two layers. Note
that the ordering of the bottom two layers in the ﬁgure is sig-
niﬁcant: the view contained in the temporary storage over-
rides the view provided by the main ﬁle system.
The temporary storage area is also known as “private stor-
age area” to signify that fact that it is not to be accessed
by the host OS. In order to support efﬁcient movement of
ﬁles between the two layers, which is necessary to imple-
ment the commit operation efﬁciently, it is preferable that
the temporary storage be located on the same ﬁle system
as the bottom layer. (If this is not possible, then temporary
storage can be on a different ﬁle system, with the caveat that
committing will require ﬁle copy operations as opposed to
renames.) Henceforth, we will use the term main ﬁle sys-
tem to denote the bottom layer and IFS-temporary storage
(or simply “temporary storage”) to refer to the middle layer.
Combined View(cid:13)
/(cid:13)
b(cid:13)
a(cid:13)
c(cid:13)
d(cid:13)
Temporary(cid:13)
Storage(cid:13)
Main File System(cid:13)
/(cid:13)
b(cid:13)
a(cid:13)
c(cid:13)
d(cid:13)
/(cid:13)
/(cid:13)
/(cid:13)
a(cid:13)
c(cid:13)
d(cid:13)
c(cid:13)
a(cid:13)
a(cid:13)
c(cid:13)
d(cid:13)
b(cid:13)
b(cid:13)
/(cid:13)
/(cid:13)
/(cid:13)
a(cid:13)
c(cid:13)
d(cid:13)
a(cid:13)
c(cid:13)
d(cid:13)
a(cid:13)
c(cid:13)
d(cid:13)
b(cid:13)
e(cid:13)
e(cid:13)
b(cid:13)
1. Initial state(cid:13)
2. After modifying file /a/c(cid:13)
3. After creating file /a/e(cid:13)
IFS file object(cid:13)
Stub file object(cid:13)
Full file object(cid:13)
Figure 1. Illustration of IFS Layout on Modiﬁcation Operations
In addition to storing private copies of ﬁles modiﬁed
within the SEE in the temporary storage, the IFS layer also
contains a table that maintains additional information nec-
essary to correctly support IFS operation. This table, which
we call as inode table, is indexed by the inode numbers of
ﬁle system objects. It has a ﬁeld indicating that whether the
inode corresponds an object in temporary storage (temp) or
an object the main ﬁle system (main). Further, if it is an
object in the temporary storage, the ﬂag indicates whether
it is a stub object (stub). A stub object is simply a refer-
ence to the version of the same object stored in the main ﬁle
system. In addition, auxiliary information needed for the
commit operation is also present, as described in Section 4.
In our IFS implementation, copy-on-write of regular ﬁles
is implemented using normal ﬁle copy operations. In partic-
ular, when a plain ﬁle f is modiﬁed for the ﬁrst time within
the SEE, a stub version of all its ancestor directories is cre-
ated in temporary storage (if they are not already there).
Then the ﬁle f is copied into temporary storage. From this
point on, all references to the original ﬁle will be redirected
to this copy in temporary storage.
After creating a copy of f, we create an entry in the inode
table corresponding to the original version of f on the main
ﬁle system. This is done so as to handle hard links correctly.
In particular, consider a situation when there is a second
hard link to the same ﬁle object, and this link has not yet
been accessed within IFS. When this link is subsequently
accessed, it will be referencing a ﬁle in the main ﬁle system.
It is necessary to redirect this reference to the copy of f in
temporary storage, or otherwise, the two links within IFS
that originally referred to the same ﬁle object will now refer
to different objects, thereby leading to inconsistencies.
The copy-on-write operation on directories is imple-
mented in a manner similar to that of ﬁles. Speciﬁcally,
a stub version of the directory’s ancestor nodes are ﬁrst
created in temporary storage. Next, the directory itself is
copied. This copy operation is a shallow copy operation, in
that only a stub version of the objects listed in the directory
are created.
We illustrate the operation of IFS using the example
shown in Figure 1. Suppose that initially (i.e., step 1 in
this ﬁgure), there is a directory a and a ﬁle b under the root
directory in the main ﬁle system, with ﬁles c and d within
directory a. Step 2 of this ﬁgure illustrates the result of
modifying the ﬁle /a/c within the SEE. The copy-on-write
operation on /a/c ﬁrst creates a stub version of the ancestor
directories, namely, / and /a. Then the ﬁle /a/c is copied
from the main ﬁle system to the temporary storage. Sub-
sequent accesses are redirected to this copy in temporary
storage.
The third step of Figure 1 shows the result of an operation
that creates a ﬁle /a/e within the SEE. Since this changes
the directory a by adding another ﬁle to it, a shallow copy
of the directory is made. Next, the ﬁle e is created within
the directory. The combined view of IFS reﬂects all these
changes: accesses to ﬁle /a/c and /a/e are redirected to
the corresponding copies in the temporary storage, while
accesses to ﬁle /a/d will still go to the version in the main
ﬁle system.
4. Implementation of IFS Commit Operation
4.1. Commit Criteria
At the end of SEE execution, the user may decide either
to discard the results or commit them. In the former case,
the contents of IFS are destroyed, which means that we sim-
ply delete the contents of temporary storage and leave the
contents of the main ﬁle system “as is.” In the latter case,
the contents of the temporary storage need to be “merged”
into the main ﬁle system.
When merging the contents of temporary storage and
main ﬁle systems, note that conﬂicting changes may have
taken place within and outside the IFS, e.g., the same ﬁle
may have been modiﬁed in different ways within and out-
side the SEE. In such cases, it is unclear what the desired
merge result should be. Thus, the ﬁrst problem to be ad-
dressed in implementing the commit operation is that of
identifying commit criteria that ensure that the commit op-
eration can be performed fully automatically (i.e., without
any user input) and is guaranteed to produce meaningful re-
sults. We describe possible commit criteria in Section 4.1.
Following this, we describe an efﬁcient algorithm for com-
mitting results in Section 4.2.