(X, C) if N (x) ∈ C for all x ∈ X.
Local Robustness. This is a property (X, CL) where X is
a robustness region and CL contains the outputs that describe
the same label L:
m)×P(R
(cid:14)
(cid:16)
(cid:15)(cid:15)(cid:15)(cid:15)(cid:15) arg max
i∈{1,...,n}(yi) = L
.
CL =
y ∈ R
n
For example, Fig. 7 shows a neural network and a robustness
property (X, C2) for X = {(0, 1), (1, 1), (1, 3), (2, 2)} and
C2 = {y | arg max(y1, y2) = 2}. In this example, (X, C2)
holds. Typically, we will want to check that there is some
label L for which (X, CL) holds.
We now explain how our abstract transformers can be used
to prove a given robustness property (X, C).
Robustness Proofs using AI. Assume we are given a neural
n, a robustness property (X, C) and
network N : R
an abstract domain A (supporting (cid:13), (cid:12) with a conjunction of
m → R
linear constraints, Aff, and ⊥) with an abstraction function α
and a concretization function γ. Further assume that N can
be written as a CAT function. Denote by T #
N the abstract
transformer of N, as deﬁned in Fig. 8. Then, the following
condition is sufﬁcient to prove that N satisﬁes (X, C):
γn
(T #
N (αm
(X))) ⊆ C.
This follows from Theorem 1 and the properties of α and γ.
Note that there may be abstract domains A that are not precise
enough to prove that N satisﬁes (X, C), even if N in fact
satisﬁes (X, C). On the other hand, if we are able to show
that some abstract domain A proves that N satisﬁes (X, C),
we know that it holds.
Proving Containment. To prove the property (X, C) given
the result a = T #
N (αm(X)) of abstract interpretation, we
need to be able to show γn(a) ⊆ C. There is a general
j li,j where
method if C is given by a CNF formula
all literals li,j are linear constraints: we show that the negated
j ¬li,j is inconsistent with the abstract element
formula
a by checking that a (cid:12)
= ⊥ for all i.
(cid:19)(cid:17)
j ¬li,j
(cid:18)
(cid:17)
(cid:17)
(cid:18)
(cid:20)
i
i
For our example in Fig. 7, the goal is to check that all inputs
are classiﬁed as 2. We can represent C using the formula
y2 ≥ y1. Its negation is y2 < y1, and it sufﬁces to show that
no point in the concretization of the abstract output satisﬁes
this negated constraint. As indeed z7 (cid:12) (y2 < y1) = ⊥, the
property is successfully veriﬁed. However, note that we would
not be able to prove some other true properties, such as y1 ≥ 0.
This property holds for all concrete outputs, but some points
in the concretization of the output z7 do not satisfy it.
V. IMPLEMENTATION OF AI2
The AI2 framework is implemented in the D programming
language and supports any neural network composed of fully
connected, convolutional, and max pooling layers.
Properties. AI2 supports properties (X, C) where X is speci-
ﬁed by a zonotope and C by a conjunction of linear constraints
over the output vector’s components. In our experiments, we
illustrate the speciﬁcation of local robustness properties where
the region X is deﬁned by a box or a line, both of which are
precisely captured by a zonotope.
Abstract Domains. The AI2 system is fully integrated with
all abstract domains supported by Apron [20], a popular
library for numerical abstract domains, including: Box [7],
Zonotope [10], and Polyhedra [8].
Bounded Powerset. We also implemented bounded powerset
domains (disjunctive abstractions [33], [36]), which can be
instantiated with any of the above abstract domains. An ab-
stract element in the powerset domain P(A) of an underlying
abstract domain A is a set of abstract elements from A, con-
cretizing to the union of the concretizations of the individual
elements (i.e., γ(A) =
(cid:21)
a∈A γ(a) for A ∈ P(A)).
The powerset domain can implement a precise join operator
using standard set union (potentially pruning redundant ele-
ments). However, since the increased precision can become
Authorized licensed use limited to: Tsinghua University. Downloaded on March 22,2021 at 05:59:05 UTC from IEEE Xplore.  Restrictions apply. 
10
prohibitively costly if many join operations are performed,
the bounded powerset domain limits the number of abstract
elements in a set to N (for some constant N).
We implemented bounded powerset domains on top of stan-
dard powerset domains using a greedy heuristic that repeatedly
replaces two abstract elements in a set by their join, until the
number of abstract elements in the set is below the bound N.
For joining, AI2 heuristically selects two abstract elements that
minimize the distance between the centers of their bounding
boxes. In our experiments, we denote by ZonotopeN or
ZN the bounded powerset domain with bound N ≥ 2 and
underlying abstract domain Zonotope.
VI. EVALUATION OF AI2
In this section, we present our empirical evaluation of AI2.
Before discussing the results in detail, we summarize our three
most important ﬁndings:
• AI2 can prove useful robustness properties for convo-
lutional networks with 53 000 neurons and large fully
connected feedforward networks with 1 800 neurons.
• AI2 beneﬁts from more precise abstract domains: Zono-
tope enables AI2 to prove substantially more properties
over Box. Further, ZonotopeN, with N ≥ 2, can prove
stronger robustness properties than Zonotope alone.
• AI2 scales better than the SMT-based Reluplex [21]: AI2
is able to verify robustness properties on large networks
with ≥ 1200 neurons within few minutes, while Reluplex
takes hours to verify the same properties.
In the following, we ﬁrst describe our experimental setup.
Then, we present and discuss our results.
A. Experimental Setup
We now describe the datasets, neural networks, and robus-
tness properties used in our experiments.
Datasets. We used two popular datasets: MNIST [25] and
CIFAR-10 [22] (referred to as CIFAR from now on). MNIST
consists of 60 000 grayscale images of handwritten digits,
whose resolution is 28 × 28 pixels. The images show white
digits on a black background.
CIFAR consists of 60 000 colored photographs with 3 color
channels, whose resolution is 32 × 32 pixels. The images are
partitioned into 10 different classes (e.g., airplane or bird).
Each photograph has a different background (unlike MNIST).
Neural Networks. We trained convolutional and fully con-
nected feedforward networks on both datasets. All networks
were trained using accelerated gradient descent with at least
50 epochs of batch size 128. The training completed when
each network had a test set accuracy of at least 0.9.
For the convolutional networks, we used the LeNet ar-
chitecture [26], which consists of the following sequence
of
layers: 2 convolutional, 1 max pooling, 2 convoluti-
onal, 1 max pooling, and 3 fully connected layers. We
write np×q to denote a convolutional
layer with n ﬁlters
of size p × q, and m to denote a fully connected layer
with m neurons. The hidden layers of the MNIST net-
work are 83×3, 83×3, 143×3, 143×3, 50, 50, 10, and those of the
CIFAR network are 243×3, 243×3, 323×3, 323×3, 100, 100, 10.
The max pooling layers of both networks have a size of 2× 2.
We trained our networks using an open-source implementa-
tion [37].
We used 7 different architectures of fully connected feed-
forward networks (FNNs). We write l × n to denote the FNN
architecture with l layers, each consisting of n neurons. Note
that this determines the network’s size; e.g., a 4× 50 network
has 200 neurons. For each dataset, MNIST and CIFAR, we
trained FNNs with the following architectures: 3× 20, 6× 20,
3 × 50, 3 × 100, 6 × 100, 6 × 200, and 9 × 200.
Robustness Properties.
In our experiments, we consider
local robustness properties (X, CL) where the region X cap-
tures changes to lighting conditions. This type of property is
inspired by the work of [32], where adversarial examples were
found by brightening the pixels of an image.
parameterized by an input x ∈ R
δ ∈ [0, 1]. The robustness region is deﬁned as:
Sx,δ = {x(cid:2) ∈ R
m | ∀i ∈ [1, m]. 1−δ ≤ xi ≤ x(cid:2)
i = xi}.
For example, the robustness region for x = (0.6, 0.85, 0.9)
and bound δ = 0.2 is given by the set:
Formally, we consider robustness regions Sx,δ that are
m and a robustness bound
i ≤ 1∨x(cid:2)
{(0.6, x, x(cid:2)
) ∈ R
3 | x ∈ [0.85, 1], x(cid:2) ∈ [0.9, 1]}.
Note that increasing the bound δ increases the region’s size.
In our experiments, we used AI2 to check whether all inputs
in a given region Sx,δ are classiﬁed to the label assigned to x.
We consider 6 different robustness bounds δ, which are drawn
from the set Δ = {0.001, 0.005, 0.025, 0.045, 0.065, 0.085}.
We remark that our robustness properties are stronger than
those considered in [32]. This is because, in a given robustness
region Sx,δ, each pixel of the image x is brightened indepen-
dently of the other pixels. We remark that this is useful to
capture scenarios where only part of the image is brightened
(e.g., due to shadowing).
Other perturbations. Note that AI2 is not limited to cer-
tifying robustness against such brightening perturbations. In
general, AI2 can be used whenever the set of perturbed
inputs can be overapproximated with a set of zonotopes in
a precise way (i.e., without adding too many inputs that do
not capture actual perturbations to the robustness region). For
example, the inputs perturbed by an (cid:6)∞ attack [3] are captured
exactly by a single zonotope. Further, rotations and translations
have low-dimensional parameter spaces, and therefore can be
overapproximated by a set of zonotopes in a precise way.
Benchmarks. We selected 10 images from each dataset.
Then, we speciﬁed a robustness property for each image and
each robustness bound in Δ, resulting in 60 properties per
dataset. We ran AI2 to check whether each neural network
satisﬁes the robustness properties for the respective dataset.
We compared the results using different abstract domains,
11
Authorized licensed use limited to: Tsinghua University. Downloaded on March 22,2021 at 05:59:05 UTC from IEEE Xplore.  Restrictions apply. 
Veriﬁed robustness
100%
Veriﬁed robustness
100%
80%
60%
40%
20%
0%
Box
Zonotope
80%
60%
40%
20%
0%
0.001
0.005
0.025
0.045
0.065
0.085
0.001
0.005
0.045
0.065
0.085
0.025
(b) CIFAR
Fig. 9: Veriﬁed properties by AI2 on the MNIST and CIFAR convolutional networks for each bound δ ∈ Δ (x-axis).
(a) MNIST
including Box, Zonotope, and ZonotopeN with N ranging
between 2 and 128.
We ran all experiments on an Ubuntu 16.04.3 LTS server
with two Intel Xeon E5-2690 processors and 512GB of
memory. To compare AI2 to existing solutions, we also ran
the FNN benchmarks with Reluplex [21]. We did not run
convolutional benchmarks with Reluplex as it currently does
not support convolutional networks.
B. Discussion of Results
In the following, we ﬁrst present our results for convoluti-
onal networks. Then, we present experiments with different
abstract domains and discuss how the domain’s precision
affects AI2’s ability to verify robustness. We also plot AI2’s
running times for different abstract domains to investigate
the trade-off between precision and scalability. Finally, we
compare AI2 to Reluplex.
Proving Robustness of Convolutional Networks. We start
with our results for convolutional networks. AI2 terminated
within 1.5 minutes when verifying properties on the MNIST
network and within 1 hour when verifying the CIFAR network.
In Fig. 9, we show the fraction of robustness properties
veriﬁed by AI2 for each robustness bound. We plot separate
bars for Box and Zonotope to illustrate the effect of the
domain’s precision on AI2’s ability to verify robustness.
For both networks, AI2 veriﬁed all robustness properties for
the smallest bound 0.001 and it veriﬁed at least one property
for the largest bound 0.085. This demonstrates that AI2 can
verify properties of convolutional networks with rather wide
robustness regions. Further, the number of veriﬁed properties
converges to zero as the robustness bound increases. This
is expected, as larger robustness regions are more likely to
contain adversarial examples.
In Fig. 9a, we observe that Zonotope proves signiﬁcantly
more properties than Box. For example, Box fails to prove
any robustness properties with bounds at least 0.025, while
Zonotope proves 80% of the properties with bounds 0.025
and 0.045. This indicates that Box is often imprecise and fails
to prove properties that the network satisﬁes.
Similarly, Fig. 9b shows that Zonotope proves more robust-
ness properties than Box also for the CIFAR convolutional net-
work. The difference between these two domains is, however,
less signiﬁcant than that observed for the MNIST network. For
example, both Box and Zonotope prove the same properties
for bounds 0.065 and 0.085.
Precision of Different Abstract Domains. Next, we demon-
strate that more precise abstract domains enable AI2 to prove
stronger robustness properties. In this experiment, we consider
our 9 × 200 MNIST and CIFAR networks, which are our
largest fully connected feedforward networks. We evaluate the
Box, Zonotope, and the ZonotopeN domains for exponentially
increasing bounds of N between 2 and 64. We do not report
results for the Polyhedra domain, which takes several days to
terminate for our smallest networks.
In Fig. 10, we show the fraction of veriﬁed robustness
properties as a function of the abstract domain used by AI2.
We plot a separate line for each robustness bound. All runs of
AI2 in this experiment completed within 1 hour.
The graphs show that Zonotope proves more robustness
properties than Box. For the MNIST network, Box proves 11
out of all 60 robustness properties (across all 6 bounds), failing
to prove any robustness properties with bounds above 0.005.
In contrast, Zonotope proves 43 out of the 60 properties and
proves at least 50% of the properties across the 6 robustness
bounds. For the CIFAR network, Box proves 25 out of the 60
properties while Zonotope proves 35.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 22,2021 at 05:59:05 UTC from IEEE Xplore.  Restrictions apply. 
12
Veriﬁed robustness