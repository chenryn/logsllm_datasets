ing in the area above and surrounding the keyboard are the
user’s hands:
the keyboard is usually kept stable and no
other objects are moved around the typing area. There-
fore, we determine the contours of the parts of the hands
that are moving by differentiating each frame with respect to
the previous one. We approximate these regions with their
bounding box, which we can then use as indicators of move-
ment. As expected, moving regions are concentrated around
the ﬁngertips and the border of the hands.
2.1.2 Key Pressing Analysis
The techniques described so far focus on the hands of the
user. Hereinafter, we describe two techniques that, instead,
focus on the keyboard. The ﬁrst leverages lighting features
to determine changes in the status of a key (i.e., from non-
pressed to pressed), and the second performs occlusion de-
tection to determine if a key may be pressed or not.
Light-based Analysis.
In mechanical keyboards, each
key consists of a head, which is connected to the keyboard
body by an intermediate plastic part. Keys are typically sep-
arated by empty spaces a few millimeters wide. Light dif-
fuses differently on the top portion of a key than on its lateral
part: in particular, the face of the key appears lighter under
normal lighting conditions. The pressing of a key changes
the light diffusion in the area surrounding the key.
We use this property to detect the pressing of a key. By
using an algorithm developed by Suzuki and Abe [41], we
ﬁrst detect the contours of the keys on the keyboard. Then,
we differentiate the contours on adjacent frames, and, if
their difference is above a ﬁxed threshold, we assume that
the corresponding key is likely to have been pressed.
Occlusion-based Analysis. The pressing of a key can oc-
cur in two ways. First, a ﬁnger moves in the area of the
key and presses it. Assuming that ﬁngers normally rest in
“home” position (the middle row of the keyboard), this is
typical of keys on the ﬁrst two rows of the keyboard, i.e.,
numbers and the letters from Q to P in a QWERTY key-
board. Alternatively, a ﬁnger is already over the key and
simply presses it. This is typical of keys on the home row,
i.e., the row with letters from A to L. In both cases, for a
key to be pressed it is necessary that it is at least partially
covered by a ﬁnger.
We leverage this observation to identify all keys that are
certainly not pressed in a certain frame. We use the same
key contour detection technique described before to identify
the set of keys whose contours are completely visible in a
certain time frame. These correspond to keys that are not
occluded, and, therefore, that are certainly not pressed.
2.1.3 Analysis Output and Limitations
In our approach, we combine several techniques to take ad-
vantage of their relative strengths and minimize their short-
comings. By applying multiple techniques, we can also gen-
erate different outputs that aid the subsequent phase of the
analysis. In particular, we decided to track the user hands
using the contour detection technique. This provides us with
the information of where movement is happening (e.g., de-
termined by key pressing). We also use the light-based key
pressing detection technique to obtain the list of keys that
appear to be pressed. We then combine these two pieces
of information, i.e., we retain only those areas of the key-
board where simultaneously hands are moving and keys are
pressed (see Figure 2(a)). This analysis provides, for each
frame of the video, a list of keys that are likely pressed. Sec-
ond, we use the occlusion-based technique to obtain a list of
keys that are certainly not pressed (see Figure 2(b)). Finally,
we apply the light-based key pressing detection technique
on the area of the space bar to detect the pressing of the
space bar, and, therefore, the ending of a word.
Note that all the techniques we use face many of the chal-
lenges that are typical of computer vision. For example, the
contour detection algorithm provides only an approximation
of the real hand contours. In certain cases, this does not al-
low us to distinguish whether a pressing involves a key or
one of its adjacent keys.
In addition, while we leverage
occlusion properties in some parts of our analysis, occlu-
sion hinders the detection of key pressings: for example, the
light-based pressing detection technique does not perform
well when a user’s hand projects a shadow that makes the
lighting uniform in a region of the keyboard. Finally, clas-
sifying the movement of hands on the keyboard is a some-
what fuzzy process: the fact that a ﬁnger moves over, or
even touches a key, does not necessarily imply that that key
has been pressed.
For these reasons, the results produced by this phase of
the analysis are noisy. More precisely, the analysis may de-
termine that a key was pressed when in fact it was not (false
pressing), or fail to detect a key pressing (missed pressing).
This motivates the need for the subsequent stage of process-
ing: error correction based on analysis of the text.
2.2 Text Analysis
Problem deﬁnition. The goal of the text analysis phase is
to suggest a sequence of meaningful words starting from the
173
Authorized licensed use limited to: Tsinghua University. Downloaded on March 22,2021 at 05:58:33 UTC from IEEE Xplore.  Restrictions apply. 
(a) Hand tracking analysis. Rectangles identify regions in movement. Black rectangles are used for
movements in the hands regions, grey rectangles for keys, white rectangles for regions where both hand
and key movement happens. These rectangles identify likely key pressings.
(b) Key pressing analysis. Using occlusion-based techniques, the analysis determines keys that are not
pressed, which are represented by the dark polygons.
Figure 2. Computer vision analysis.
set of candidate letters provided by the video analysis.
This task has many similarities with the traditional prob-
lem of spelling correction,
initially formulated by De-
merau [11] in 1964. The problem can be expressed as
follows: given a language L and an unknown word s,
ﬁnd a word w ∈ L that maximizes P (w|s). This prob-
ability can be rewritten applying the Bayes’ theorem in
P (s|w)P (w)/P (s). The constant denominator can be ig-
nored, thus reducing the problem of spelling correction to
the problem of ﬁnding the word that provides the best com-
bined probability between the following two factors:
• P (s|w), known as the error model.
It expresses the
probability that a user erroneously typed the string s
instead of the correct word w. For example, if the
user wanted to type the word table, it is reasonably
more probable that he/she erroneously wrote the string
tabel than the string xavel.
• P (w), known as the source or language model. It mod-
els the probability that the word w appears in text writ-
ten in a certain language. In other words, it is used to
express the fact that, for example, it is more probable
that a user typed hammer than hamper, even though
they are both correctly spelled.
The ﬁrst example of a error model was proposed by De-
merau and Levenshtein [28] and was based on a measure
of the distance between two strings, also known as edit dis-
tance. The edit distance consists of the minimum number
of single character insertions, substitutions, deletions, and
transpositions that are required to derive one word from the
other. For example, hello has edit distance 1 from helo
(one insert operation) and 2 from elol (one insert and one
transpose operations).
This ﬁrst error model has been subsequently reﬁned and
improved, for example by associating probabilities with in-
dividual edit operations, applying different operations de-
pending on the surrounding letters, and extending the edit
operations to sequences of multiple characters [8, 10, 32].
174
Authorized licensed use limited to: Tsinghua University. Downloaded on March 22,2021 at 05:58:33 UTC from IEEE Xplore.  Restrictions apply. 
For a more comprehensive review of spelling correction
techniques, please refer to Jurafsky and Martin’s book [20]
or Kukich’s survey [25].
An alternative approach to building the error model con-
sists of computing the distance on the phonetic representa-
tion of the words instead of comparing their written form.
For example, both Aspell [3] and Vim’s on-the-ﬂy spell
checker [34] adopt this technique to correct mistakes that
result from the fact that sometimes users know how a cer-
tain word sounds but they do not know how it is spelled.
Even though these approaches focus on detecting errors
based on spelling ignorance, they can sometimes succeed
in correcting very noisy input, such as dtecttioorn to
detection, despite the high distance between the two
strings.
Finally, the ﬁeld of context-sensitive spelling correc-
tion [15, 31] focuses on the task of analyzing the surround-
ing context of a word in order to ﬁx errors that result in valid
words, such as the use of than instead of then, or the use
of peace instead of piece.
The combination of these approaches can be very effec-
tive in detecting and automatically correcting both typo-
graphical errors, homophone confusion, and spelling mis-
takes. However, all these general-purpose techniques per-
form very poorly when applied to our text reconstruction
problem, because they all rely on a set of assumptions that
do not hold in our scenario. In particular, in our case, most
of the errors come from inaccuracies in the video analy-
sis phase, and not from user’s typing mistakes. Our main
source of errors is the movement of the user’s hands on top
of the keyboard and therefore errors tend to be more random
and more difﬁcult to predict. Moreover, while statistically
most of the misspelled words contain only one mistake [11],
in our text reconstruction we observed a consistently high
level of noise, resulting in strings that are sometimes very
far from the correct word.
For
example,
the
consider
sequence of
letters
viaoeryih extracted by the computer vision analy-
sis from a video when the user typed the word victory.
The presence of the vocals a and e in the middle of
the word confuses sound-based approaches and the edit
distance of 5 is too high to be recovered by any traditional
technique.
Even though the computer vision analysis returns noisy
results, we have two additional information sources that we
can leverage in our text analysis: the association of charac-
ters with frames in the video and the set of keys that we can
safely assume that have not been pressed.
In the following sections, we provide the details of our
text analysis. More precisely in Section 2.2.1 we describe
how we develop the error model and the language model
that are necessary to determine (and maximize) P (w|s).
Then, in Section 2.2.2 we show how the word context can
be leveraged to identify the set of most likely candidates for
each word in a sentence.
175
2.2.1 Language Analysis
The goal of the language analysis is to determine the prob-
ability of a certain word, given the set of keys typed by a
user, as identiﬁed by the computer vision analysis.
Error model. The ﬁrst step of our language analysis con-
sists of deﬁning an error model that takes into account all
the information that we collected during the analysis of the
video. In particular, we have two different inputs from the
previous phase: a vector that contains, for each frame, the
list of keys that the video analysis identiﬁed as likely can-
didates to have been pressed by the user (hereinafter called
the key list) and a vector that associates to each frame a list
of keys that our analysis identiﬁed to be untouched (referred
as the exclusion list).
We ﬁrst analyze the key list and we identify the keys that
appear in consecutive frames, which we call a key grouping.
By analyzing these groupings, we identify character mod-
els, which represent place-holders for the characters in the
word we are reconstructing. More precisely, the character
models are created according to the following rules:
• If a key grouping does not overlap with any other key
groupings, a new character model is created that con-
tains only that key. For example, if for ten consecutive
frames the only key in the key list is D, then a character
model that contains D is created.
• In case of a partial overlap between two key groupings,
we consider them to be consecutive, and we create two
character models, one for each grouping, in the order
in which the groupings appear. For example, if the user
quickly presses two different keys in a row, say A and
S, the key list analysis will produce a grouping of As
and a grouping of Ss. Therefore, two character mod-
els will be created: one that contains A, and one that
contains S.
• In case of a complete overlap between two or more dif-
ferent key groupings, we create a character model that
contains both keys, since we cannot be sure which one
was actually pressed by the user.
• If between two consecutive key groupings there is a
number of empty frames that is greater than a cer-
tain threshold, we create an empty character model
in that position. This models the fact that a pause in
the middle of a word may result from the fact that the
video analysis missed one or more pressings of the key-
board’s keys.
For example, consider Table 1, which presents the key
lists associated with each frame.
The analysis identiﬁes
four key groupings, namely the Cs spanning frames 2–7, the
Hs spanning frames 5–11, the Is spanning frames 9–10, and
the Ns spanning frames 26–27. According to the rules de-
scribed above, we create a ﬁrst character model containing
Authorized licensed use limited to: Tsinghua University. Downloaded on March 22,2021 at 05:58:33 UTC from IEEE Xplore.  Restrictions apply. 
Frame
1
Key List
3
7
2
C C C C C C
6
4
5
8
9
10
11
12
13
. . .
25
26
N
27
N
. . .
H H H H H H
I
I
H
Table 1. Example key lists generated by the video analysis.
the C key, a second character model containing both the H
and I keys, an empty character model reﬂecting the absence
of keys from frame 12 to frame 25, and ﬁnally a character
model with the N key.
Once the character models have been created, it is neces-