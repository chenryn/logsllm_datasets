the remainder into buckets.
(a) The parties call Fperm with vector (cid:174)D.
(b) For i = 1, . . . , C, the parties run open([ai]),
open([bi]) and open([ci]) and then each party
checks that ci = ai · bi . If not, then the party sends
⊥ to all the other parties and aborts.
If a party did not output accept in all the open pro-
cedure executions, it sends ⊥ to the other parties
and outputs ⊥.
The parties remove the opened triples from (cid:174)D.
(c) The remaining N B triples in (cid:174)D are divided into
N sets of triples (cid:174)D1, . . . , (cid:174)DN , each of size B.
For i = 1, . . . , N , the bucket (cid:174)Di contains the
triples ([a(i−1)·B+1], [b(i−1)·B+1], [c(i−1)·B+1]), ...,
([ai·B], [bi·B], [ci·B]).
(4) Check buckets: The parties initialize a vector (cid:174)d of length N .
by
Then, for i = 1, . . . , N :
the
(a) Denote
triples
in
(cid:174)Dk
([a1], [b1], [c1]), ..., ([aB], [bB], [cB]).
(b) For j = 2, . . . , B, the parties run Protocol 3.4
(triple veri(cid:27)cation based on openings) on in-
put ([a1], [b1], [c1]) and ([aj], [bj], [cj]), to verify
([a1], [b1], [c1]).
(c)
If a party did not output accept in every execution,
it sends ⊥ to the other parties and outputs ⊥.
(d) The parties set (cid:174)di = ([a1], [b1], [c1]); i.e., they store
these shares in the ith entry of (cid:174)d.
• Output: The parties output (cid:174)d.
and let δ, B and C be such that δ · log(cid:16)(N B+C
Theorem 5.2. Let f be a n-party functionality, assume that C ≥ B
(cid:17) ≥ σ. Then,
B )(|F|−1)B
Protocol 4.2, when using Protocol 5.1 for its o(cid:31)ine phase, securely com-
putes f with abort in the (Fcoin, Frand, Fperm)-hybrid model with sta-
tistical error 2−σ , in the presence of a malicious adversary controlling
t < n2 parties.
N
proof sketch. We (cid:27)rst bound the probability that the adversary
cheats without being caught. Denote this event by bad. Then, bad =
bad1 ∧ bad2 ∧ bad3, where:
• bad1 is the event that there are exactly t buckets that have only
bad triples; i.e., the adversary corrupted tB triples that were not
chosen to be opened and these were placed by the permutation
in exactly t buckets.
• bad2 is the event that no cheating is detected in the veri(cid:27)cation
step in the pre-processing phase, given that there are t fully bad
buckets; i.e., the t · (B − 1) executions of the triples veri(cid:27)cation
protocol where a bad triple is veri(cid:27)ed, ended without detecting
cheating.
• bad3 is the event that the adversary cheated in the computation
of t multiplication gates and was not caught, given that there
are t bad random triples output from the pre-processing phase.
We remark that these bad events cover all possibilities. In particular,
if the number of bad buckets does not match the number of bad
multiplications, then the adversary will be caught with probability 1.
Thus, we only consider the case that the number t is the same in
both events.
From [19, Theorem 5.2] it follows that
(cid:18)N
(cid:19)(cid:18)N B + C
(cid:19)−1
t
tB
.
Pr[bad1] =
By Lemma 3.5, we have that
Pr[bad2] =
(|F| − 1)(B−1)t
since the adversary is not caught in a single veri(cid:27)cation with prob-
ability 1/(|F| − 1) and B − 1 veri(cid:27)cations are carried out per bucket.
Furthermore, once again applying Lemma 3.5, we have that
1
1
Pr[bad3] =
(|F| − 1)t
.
1
·
t
1
tB
Pr[bad] =
(|F| − 1)B·t
(cid:19)−1(cid:33)δ
since the adversary evades detection each time with probability
1/(|F| − 1) and there are t bad multiplications. Since the online
veri(cid:27)cation stage is run δ times, we obtain that
(cid:32)
(|F|−1)B·t and(cid:0)N
(cid:32)
Now, since both
t=1 (where the latter was proven in [19, Theorem 5.3] assuming
that c ≥ B), we have that
(cid:18)N
(cid:19)(cid:18)N B + C
(cid:1)−1 are maximized when
(cid:1)(cid:0)N B+C
(cid:19)−1(cid:33)δ
(cid:18)N B + C
(cid:18) (|F|−1)B(N B+C
(cid:19)δ
(cid:17) as stated in the theo-
sides yields that σ ≤ δ · log(cid:16) (|F|−1)B(N B+C
Therefore, we obtain that assuming that C ≥ B, it holds that
Pr[bad] ≤ 2−σ when 2σ ≤
. Taking log of both
Pr[bad] ≤
B )
B )
(|F| − 1)B
· N
t
t B
1
B
.
N
N
the details here.
Simulation works as in the proof of Theorem 4.3, and we omit
(cid:3)
E(cid:28)ciency. Each multiplication gate requires running the semi-
honest multiplication protocol once in the online computation and
Bδ times in the o(cid:31)ine phase (to generate a bucket of B triples for
each veri(cid:27)cation iteration). In addition, for each gate the parties
run the veri(cid:27)cation protocol δ(B − 1) times on the o(cid:29)-line and δ
times in the online, at the cost of 3 openings per execution. Finally,
to generate B random triples, the parties need to call Frand exactly
2B · δ times. Thus, the overall cost per multiplication gate is
(1 + δB) · t(πmult) + 2B · δ · t(Frand) + 3 · δB · t(open).
rem.
N
At (cid:27)rst sight, this looks much higher than the overhead of the
protocol of the previous section. However, the idea here is to choose
a smaller δ, thus reducing the overall cost. For example, assume that
σ = 40 and |F| = 28 (e.g., computing an AES circuit over GF[28]).
If we were to use the large-(cid:27)eld protocol of Section 4, we would
have to set δ = 5 in order to have δ · log(|F|) ≥ 40. The cost per
gate in this case, assuming we use the (cid:27)rst version of the protocol,
is 6 · t(πmult) + 10 · t(Frand) + 15 · t(open).
In contrast, if we need to produce 210 triples, we can set δ = 1
and B = C = 3, resulting in having (|F| − 1)B = (28)3 = 224 and
1
N
(cid:1) ≥ (3·210)3
(cid:0)N B+C
(cid:1) = 2−10(cid:0)210·3+3
δ · log(cid:16)(|F| − 1)B(cid:0)N B+C
(cid:1)
(cid:17) ≥ log(224 · 220) = 40.
3·210 ≥ 220 and so
B
B
3
For these parameters, the cost per gate is 4· t(πmult) + 6· t(Frand) +
9 · t(open), which is lower than using the protocol of Section 4.
6 INSTANTIATIONS
Our protocol/compiler is generic and can be instantiated in many
ways (with di(cid:29)erent secret sharing schemes, multiplication pro-
tocols, and more). Clearly, the e(cid:28)ciency of our protocol depends
signi(cid:27)cantly on the instantiations. In this section, we present two
main instantiations of our protocol, with di(cid:29)erent options for some
of the subprotocols within. The (cid:27)rst instantiation is for the general
case of any number of parties n, and we use Shamir’s secret shar-
ing [35] for this instantiation. We provide di(cid:29)erent approaches to
implementing the basic building blocks, including the open proce-
dure, randomness generation Frand, and semi-honest multiplication
πmult, and analyze their e(cid:28)ciency. The second instantiation is for
the speci(cid:27)c case of three-parties, and utilizes tools from the highly
e(cid:28)cient semi-honest protocol of [3]. Using our compiler, we show
that it is possible to obtain a protocol that is secure in the presence
of a malicious adversary with very low communication; speci(cid:27)cally,
only a few (cid:27)eld elements are sent for each multiplication gate. For
simplicity, we analyze our instantiations using the protocol of Sec-
tion 4 for large (cid:27)elds only; similar analysis using the protocol for
small (cid:27)elds of Section 5 can be easily obtained.
6.1 Multi-Party Computation Based on
Shamir’s Secret Sharing Scheme
q1, ..., qt ∈ F and de(cid:27)nes a polynomial q(x) = v +j=t
Most secure computation protocols with an honest majority use
Shamir’s secret sharing scheme [35]. In this scheme, a secret is dis-
tributed among n parties with a threshold of t, by de(cid:27)ning a polyno-
mial of degree t, and handing each party a point on this polynomial.
Formally, given a secret v, the dealer chooses random coe(cid:28)cients
j=1 qjx j. Then,
each party Pi is given the value q(i).3 It is well known that no subset
of t parties can compute the secret by themselves, but a subset of
t + 1 parties can compute the secret, as any t + 1 points uniquely
de(cid:27)ne one polynomial of degree t.
For this secret sharing scheme, a sharing [v] is correct if there
exists a single polynomial q(x) of degree ≤ t such that for every
honest party Pi holding value vi, it holds that q(i) = vi. Therefore,
3More generically, we associate a unique αi ∈ F for the ith party. For simplicity, we
will consider F = Zp for a prime p, in which case i ∈ F.
a sharing [v] is incorrect if for every polynomial q(x) of degree at
most t, there exists an honest party Pi holding vi such that q(i) (cid:44) vi.
Note that for this scheme, if the sharing [v] is not correct, then it is
value-inconsistent (see Section 2). This holds since any subset of
t + 1 shares de(cid:27)nes a t-degree polynomial, and thus for any subset
of t +1 honest parties J it holds that val([v])J (cid:44) ⊥. (Technically, for
this to work, all honest parties must hold some share in the (cid:27)eld F.
Thus, if an honest party receives a value in any protocol that does
not de(cid:27)ne a value in F, it replaces it with some default (cid:27)eld value.)
Shamir’s secret sharing scheme is linear, and enable parties lo-
cally add shares and multiply them by a constant, as required for
our protocol.
6.1.1 The Basic Procedures and Sub-Protocols.
The share(v) procedure. As explained above, in this procedure
the dealer chooses a random polynomial q(x) of degree t under
the constraint that q(0) = v, and then sends each Pi the point q(i).
Recall that our protocol does not require the share sent by the
corrupted parties to be correct, and thus this is su(cid:28)cient (in places
where correctness is required, we run a separate check).
The reconstruct([v], i) and open([v]) procedures. In order to re-
construct to party Pi, each party sends its share to Pi. Then, Pi uses
any of the t + 1 shares to compute the unique degree-t polynomial
de(cid:27)ned by the points, and checks that all other shares lie on the
same polynomial. If not, then it sends ⊥ to all the other parties and
halts. Since there are at least t + 1 honest parties (whose shares
uniquely de(cid:27)ne a polynomial and so the value to be reconstructed),
we are guaranteed that the corrupted parties cannot cause Pi to
output an incorrect value.
The open procedure simply works by running reconstruct([v], i)
for all Pi. Since each party sends n − 1 elements, the overall com-
plexity of the open procedure is quadratic in the number of parties.
Frand - generating shares of random values. We describe two
ways of implementing Frand. The (cid:27)rst method of generating ran-
dom shares is the PRSS method of [13], which enables the parties to
generate a sharing of a pseudorandom element without any inter-
action. This is done by distributing random keys among the parties
via replicated secret sharing (i.e., for each subset of t parties, all the
parties in the complement subset receive a key). These random keys
are used to generate pseudorandom values that are then converted
to Shamir shares. Since this protocol is non-interactive, it is easy
to see that generated shares are always correct, and the adversary
cannot learn anything about the shared value. Thus, this protocol
securely realizes Frand. The problem with this approach is that the
number of keys held by each party grows exponentially in the num-
ber of parties, which dramatically increases the computational work
of generating the shares. Thus, this method is only e(cid:28)cient when
the number of parties in the protocol is small. A full description of
this method appears in Appendix B.1 (Protocol B.1).
We now describe a second way of generating random shares
due to [17], in which each party sends only a constant number
of elements per random share. This method uses a Vandermonde
matrix, which can be used to “extract randomness” from n shares
into n − t new shares. The protocol works by having each party
share a random element to the other parties. Then, upon holding
a vector of n shares, each party locally multiplies this vector of
size n with a Vandermonde matrix of n − t rows and n columns to
receive a vector of n − t “new” random shares. By the randomness
extraction property, we have that the new shares are sharings of
random elements in F. Since t < n2 , we have that each party obtain
at least n2 + 1 shares, in a process that requires sending n − 1
elements by each party. Thus, the amortized communication cost
per random share is roughly 2 elements per party. A full description
is in Appendix B.1 (Protocol B.2); for more details on the method
see [17]. We stress that this protocol, as described above, does not