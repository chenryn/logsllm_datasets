### Mathematical Analysis

The following inequality holds:
\[
\int (N_1 - N_2)(t) \, d\Psi(t) \leq T V(\Psi) \cdot \max\{|(N_1 - N_2)(t)| : t \in \text{supp}(\Psi)\}
\]
where \(\text{supp}(\Psi)\) is the support of \(\Psi\)—the part of the \(t\)-axis where \(\Psi\) is nonzero. The Total Variation \(T V(\Psi)\) is informally the sum of all the ups and downs in the graph of \(\Psi\). Formally, for a smooth function \(\Psi(t)\), \(T V(\Psi) = \int |\Psi'(t)| \, dt\). For piecewise smooth functions, the total variation includes the sum of the jumps across discontinuities.

### Properties of Extreme Values of Stochastic Processes

Our second analytical tool involves the properties of extreme values of stochastic processes. Causality and Maximum Tolerable Delay imply that:
\[
N_1(t) \geq N_2(t) \geq N_1(t - \Delta)
\]
Thus,
\[
|N_1(t) - N_2(t)| \leq N_1(t) - N_1(t - \Delta)
\]
and
\[
|N_1(t) - N_2(t)| \leq \max\{N_1(t + \Delta) - N_1(t) : t, t + \Delta \in \text{supp}(\Psi)\}
\]
In other words, the difference between \(N_1\) and \(N_2\) is controlled by the volume in \(N_1\).

If \(N_1\) is the set of cumulative arrivals of a Poisson counting process, then:
\[
\max\{N_1(t + \Delta) - N_1(t) : t, t + \Delta \in [a, b]\} \leq O_P(\log(b - a)) \cdot E\{N_1(t + \Delta) - N_1(t)\}
\]
For more details, see [2] and [1].

### Multiscale Block Averages

This calculation is based on the following ingredients:
1. Symbols emerge at Poisson arrival times \(t_1, \ldots, t_N\) with rate \(\lambda\).
2. The 'bump' has mean 1, so \(E[\alpha_{j,k}] = \lambda\).
3. The variance \(V ar[\alpha_{j,k}] = \text{Const} \cdot \frac{\lambda}{\text{scale}}\), which follows the usual \(1/n\)-law for variances of means.

Consequently, the random fluctuations of the scaling coefficients obey:
\[
\alpha_{j,k} \approx \lambda \pm c / \sqrt{\text{scale}}
\]

To calculate the maximum fluctuation of \(\alpha_{j,k}\), we observe that:
\[
T V(\psi_{j,k}) \leq \frac{4}{\text{scale}} \quad \text{and} \quad \sup\{N_1(t + \Delta) - N_1(t) : t \in [a, a + \text{scale}]\} = O_P(\log(\text{scale}))
\]
This gives the key conclusion:
\[
|\alpha_{j,k}| \leq O\left(\frac{\log(\text{scale})}{\text{scale}}\right)
\]

### Multiscale Block Differences

Again, we assume symbols emerge at Poisson arrival times \(t_1, \ldots, t_N\) with rate \(\lambda\):
1. The 'wiggle' has mean 0, so \(E[\alpha_{j,k}] = 0\).
2. The variance \(V ar[\alpha_{j,k}] = \text{Const} \cdot \frac{\lambda}{\text{scale}}\), which follows the usual \(1/n\)-law for variances of means.

Consequently, the random fluctuations of the wavelet coefficients obey:
\[
\alpha_{j,k} - \alpha_{2,j,k} \approx \pm \frac{c}{\sqrt{\text{scale}}}
\]

The calculation of the maximum fluctuation of \(\alpha_{j,k} - \alpha_{2,j,k}\) is similar to that for multiscale block averages.

### Simulation

To illustrate the results, consider a simple transcoder: Local Inter-keystroke Shuffling (LIS). This transcoder works as follows:
- We buffer symbols for \(M\) consecutive symbols or \(\Delta\) milliseconds, whichever comes first.
- Suppose the times of symbol arrivals into the incoming stream buffer are \(t_1, \ldots, t_m\), so that \(m \leq M\) and \(t_m - t_1 < \Delta\).
- We compute the interarrival times of the symbols in the buffer, \(\delta_1 = t_2 - t_1, \delta_2 = t_3 - t_2, \ldots, \delta_{m-1} = t_m - t_{m-1}\).
- Given the interarrival times \(\delta_1, \ldots, \delta_{m-1}\), we perform a random shuffling to obtain \(\epsilon_1, \ldots, \epsilon_{m-1}\).
- We define a second set of times by:
  \[
  u_1 = t_m, \quad u_2 = u_1 + \epsilon_1, \quad \ldots, \quad u_i = u_{i-1} + \epsilon_{i-1}, \quad \ldots
  \]
- We output symbols in the second stream at times \(u_i\).

Figure 7 illustrates the type of transformation obtained by LIS.

### Properties of the New Stream Synthesized by LIS

- **Identical Distribution**: The new stream \((u_i)\) has inter-keystroke times with the same distribution as the original stream \((t_i)\) because the inter-keystroke times are just the same numbers in a different order.
- **Causality**: Characters arrive in Stream 2 later than Stream 1: \(t_i \leq u_i\).
- **Controlled Delay**: Characters do not arrive much later in Stream 2: \(t_i < u_i < t_i + 2\Delta\).

Thus, there is no possibility that a statistical traffic anomaly detector can flag a stream 2 produced by LIS as aberrant traffic. By controlling the parameter \(\Delta\), we control the maximum tolerable delay.

### Monte-Carlo Simulation

To study the properties of multiscale detectors in the LIS setting, we use Monte-Carlo simulation. In our experiments, we used samples from the empirical distribution of inter-keystroke times described in [9]. We created a stream several minutes in length and transcoded this stream three times at three different delay parameters: 100 ms, 200 ms, and 300 ms.

From the streams, we created time series. We selected 256-second stretches of each stream, divided the time axis into 1/64th-second intervals, and counted the number of character arrivals (always 0 or 1) within each interval. This gave us equally spaced series of 16,384 (i.e., \(2^{15}\)) 0's and 1's. We then used the freely available wavelet transform routines in WaveLab [10] to perform a wavelet analysis using the Haar wavelets.

The table below reports correlations between wavelet coefficients of the original stream and the three transformed streams. It contains the empirical correlations between the wavelet coefficients at various scales, defined by:
\[
\text{Corr}(j) = \frac{\sum_k \alpha_{1,j,k} \alpha_{2,j,k}}{\left(\sum_k \alpha_{1,j,k}^2\right)^{1/2} \left(\sum_k \alpha_{2,j,k}^2\right)^{1/2}}
\]

| Scale | \(\Delta = 100\) ms | \(\Delta = 200\) ms | \(\Delta = 300\) ms |
|-------|---------------------|---------------------|---------------------|
| 32 sec | 0.9599              | 0.9382              | 0.9654              |
| 64 sec | 0.9371              | 0.9695              | 0.9458              |
| 128 sec | 0.9964              | 0.9965              | 0.9966              |

These results are typical and repeatable. Correlations, of course, cannot exceed 1.0. So these correlations, which approach 1 at sufficiently long scales, are rather large. Evidently, given about 1 minute’s worth of data on two jittered streams, we can obtain a substantial signal by correlation of wavelet coefficients. Note particularly the very high correlations when jittering is less than 0.1 seconds.

### Detecting Evasions in the Presence of Chaff

In the analysis since Section 4, we have assumed that any stream transformation being used to disguise correlations was conservative—that is, it exactly preserves the number and content of keystrokes but may alter their timing.

We now discuss the more general situation where this is not the case. A reasonable way to model this is to say that we have two cumulative character counting functions \(N_1\) and \(N_2\), and:
\[
N_2(t) = N_1(t) + M(t)
\]
where \(N_1(t)\) is the cumulative counting function of the input character arrival times, perhaps after a conservative stream transformation, and \(M\) is the cumulative counting function of chaff arrival times. In short, as we watch characters coming in, some are from the input stream (only jittered) and others are chaff.

Suppose we again compute the statistic \(\text{Corr}(j)\) at each scale. The results change. If the chaff arrives according to the universal keyclick interarrival process and is stochastically independent of the \(N_1\) process, then instead of:
\[
\text{Corr}(j) \to 1 \quad \text{as} \quad j \to \infty,
\]
we actually have:
\[
\text{Corr}(j) \to \rho \quad \text{as} \quad j \to \infty,
\]
where \(0 < \rho < 1\). Here, \(\rho\) can be interpreted as a 'signal/(signal+noise)' ratio, meaning that \(\rho\) will be very small if the relative amount of chaff is very large, and close to 1 if the fraction of chaff is negligible.

No matter how small \(\rho\) might be, any nonzero value for \(\rho\) will be detectable, at least for sufficiently long-lived connections. For large enough \(n\), it will be clear that the empirical fluctuations in correlations due to statistical sampling effects are too small to cause observed values of \(\text{Corr}(j)\) that are substantially nonzero. Given more space, we would provide a detailed analysis showing that the mathematics predicts a substantial correlation between wavelet coefficients of \(N_1\) and \(N_2\). The analysis is entirely parallel to the analysis given in earlier sections.

In short, although the presence of chaff causes a more complex problem, the statistical tools and diagnostic approaches suggested for the no-chaff case seem to be equally applicable to the chaff case.

### Discussion

This paper has considered basic 'proof of concept' issues. We have not discussed systems-level issues such as working in a setting with many hundreds of active Telnet or SSH connections into and out of a large site (e.g., a university or corporate network) and monitoring and detecting stepping stones in real-time. A typical issue would be to consider a specific monitoring interval (e.g., 4 minutes) and calculate the proper height of the threshold for the 'stepping stone alarm' to control the false alarm rate to a tolerable number of false alarms per day.

We have discussed the fact that real interactive sessions seem to have inter-keystroke times whose distribution is Pareto in the upper tail. In the analysis section, we considered Poisson streams, which are easy to analyze. In the appendix, we show that the analysis can generalize to other streams. This points out the need for an accurate theoretical model for inter-keystroke timing, which would be extremely useful in practical terms, such as for false alarm calibration.

Two particular components of the inter-keystroke timing model that should be considered more closely are:
- The correlation structure of adjacent/nearby inter-keystroke times.
- The chance of seeing many characters in a very short interval.

Knowing more about either or both components would help mathematical analysis and simulation accuracy.

There are also other sources of information that we haven’t discussed, such as the two-way nature of interactive sessions. There is far more information than just the keystrokes on the forward path through the stepping stones; there are also echoes and command output on the reverse path, which could be used to improve detection.

### Acknowledgments

DLD and AGF would like to thank NSF ANI-008584 (ITR). AGF would like to thank the Statistics Department of UC Berkeley for its hospitality. JC and SS would like to thank DARPA contract N66001-00-C-8045.

### References

1. Aldous, D.L.: Probability Approximations Via the Poisson Clumping Heuristic. Springer-Verlag, New York. January 1989.
2. Lindgren, G., Leadbetter, M.R., and Rootzen, H.: Extremes and related properties of stationary sequences and processes. Springer, New York (1983). Russian translation; Nauka: Moscow (1988).
3. Shimomura, T. and Markoff, J.: Takedown. The pursuit and capture of Kevin Mitnick, America’s most wanted computer outlaw–by the man who did it. Hyperion. December 1995.
4. Mallat, S.: A Wavelet Tour of Signal Processing. Academic Press. Second Edition, 2000.
5. Meyer, Y.: Wavelets: Algorithms and Applications. SIAM. May 1993.
6. Stoll, C.: The Cuckoo’s Egg: Tracking a Spy through the Maze of Computer Espionage. Pocket Books. October 2000.
7. Staniford-Chen, S. and Heberlein, L.: Holding Intruders Accountable on the Internet. Proceedings of the 1995 IEEE Symposium on Security and Privacy, Oakland, CA (1995).
8. Zhang, Y. and Paxson, V.: Detecting stepping stones. Proceedings of the 9th USENIX Security Symposium, Denver, Colorado, August 2000. http://www.aciri.org/vern/papers/stepping-sec00.ps.gz
9. Paxson, V. and Floyd, S.: Wide-Area Traffic: The Failure of Poisson Modeling. IEEE/ACM Transactions on Networking, Vol. 3(3), June 1995, 226–244.
10. Wavelab Toolbox for Wavelet Analysis. Requires Matlab. http://www-stat.stanford.edu/wavelab
11. Yoda, K. and Etoh, H.: Finding a Connection Chain for Tracing Intruders, In: Guppens, F., Deswarte, Y., Gollamann, D., and Waidner, M. (eds): 6th European Symposium on Research in Computer Security - ESORICS 2000 LNCS -1985, Toulouse, France, Oct 2000.

### Appendix

#### Explanation of the Bumps/Wiggles Dichotomy

- **Multiscale Bumps**: Provide a collection of multiscale block averages, measuring the rate of typing of the given stream.
- **Multiscale Wiggles**: Provide a collection of multiscale differences of block averages, measuring changes in the rate of typing of the given stream.

We believe that measuring changes in rate and noticing the times those occur provides more reliable evidence for the identity of two streams. Therefore, we believe that analysis by multiscale wiggles (i.e., wavelet analysis) will give more reliable information indicating the identity of the two streams.

There is one other advantage of wavelet analysis: the possibility of developing detectors for non-keystroke conserving schemes that work by multiplexing constant-rate chaff together with the original stream. If two streams differ in that stream 2 contains stream 1 along with characters from an independent chaff source of constant rate (e.g., Poisson with Rate 20 char/sec), it can be shown that the wavelet coefficients at sufficiently long scales will have a dependable correlation < 1, but which is stable and nonzero, and determined by a kind of statistical signal/chaff ratio. Thus, we might notice that two streams which should be completely uncorrelated actually exhibit correlations that are definitely nonzero.

The different normalization of the wavelet coefficients in the two cases has to do with the appropriate means of interpretation of each type of coefficient. Averages are directly interpretable in the units of the phenomenon being measured, no matter what the scale of the average. Differences are not so universally interpretable; the convention \(p = 1/2\) ensures that they are normalized according to the square-root of interval size rather than interval size. The rationale is that for typical point processes, the coefficients at different scales will then be of comparable size.

#### Generalization to Non-Poisson Streams

Only in two places in the argument of Section 6 did we use the Poisson process assumption:
1. \[
   \max\{N_1(t + \Delta) - N_1(t) : t, t + \Delta \in [a, b]\} \leq O_P(\log(b - a)) \cdot E\{N_1(t + \Delta) - N_1(t)\}
   \]
   This condition says that within any maximum tolerable delay interval, we are very unlikely to see character counts dramatically greater than the average character counts. This inequality is extremely easy to satisfy, and many point processes will obey it. Real data will also obey it. For example, no actual human person is ever going to exceed an absolute maximum of \(K\) characters in \(\Delta\), no matter how long we wait. If we do, the above inequality will automatically be true because \(\log(b - a)\) grows unboundedly with observation period, while \(K\) is an absolute constant.

   Incidentally, the Pareto nature of the upper half of the inter-keystroke timing distribution described in [9] is entirely compatible with this inequality. The Pareto upper tail is responsible for occasional long dead spots in a stream, where no characters emerge. It is the lower tail—near zero inter-keystroke spacing—that determines whether the needed condition holds. The Poisson assumption makes the inter-keystroke distribution have a density \(e^{-t/\lambda}/\lambda\), which is bounded near \(t = 0\); this boundedness implies that there will not typically be large numbers of events in a short time. It seems safe to say that this aspect of the Poisson distribution accurately models real streams of keystrokes.

2. \[
   V ar[N_1(0, T]] \sim \text{Const} \cdot T
   \]
   This says that the fluctuation in the number of events per unit time within an interval grows like the square root of the interval size. This will be true for many stationary point processes.

The Pareto nature of the upper half of the inter-keystroke timing distribution and the possibility of a non-i.i.d. behavior of inter-keystroke times can modify this inequality, even making the variability grow like a power \(T^\beta\) with \(\beta \neq 1\). A more detailed analysis shows that even though the variance scaling exponents could be different, the fundamental behavior of the corresponding terms in the analysis would be the same.

Since our simulations indicate that the multiscale diagnostics work very well in the Pareto case, we omit further discussion of the mathematical details of the extension.