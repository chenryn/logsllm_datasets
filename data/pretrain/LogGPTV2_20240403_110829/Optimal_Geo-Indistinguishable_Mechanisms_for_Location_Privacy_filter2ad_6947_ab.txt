choice is to use the Euclidean distance for both.
A natural question, then, is to construct a mechanism that
achieves optimal privacy, given a QL constraint.
Definition 1. Given a prior π, a quality metric dQ, a
quality bound q and an adversary metric dA, a mechanism
K is q-OptPriv(π, dA, dQ) iﬀ
1. QL(K, π, dQ) ≤ q, and
2. for all mechanisms K(cid:48), QL(K(cid:48), π, dQ) ≤ q implies
AdvError(K(cid:48), π, dA) ≤ AdvError(K, π, dA)
In other words, a q-OptPriv mechanism provides the best
privacy (expressed in terms of AdvError) among all mech-
anisms with QL at most q. This problem was studied in [8],
providing a method to construct such a mechanism for any
q, π, dA, dQ, by solving a properly constructed linear pro-
gram.
2.2 Differential privacy
Diﬀerential privacy was originally introduced in the con-
text of statistical databases, requiring that a query should
produce similar results when applied to adjacent databases,
i.e. those diﬀering by a single row. The notion of adjacency
is related to the Hamming metric dh(x, x(cid:48)) deﬁned as the
number of rows in which x, x(cid:48) diﬀer. Diﬀerential privacy re-
quires that the greater the hamming distance between x, x(cid:48)
is, the more distinguishable they are allowed to be.
This concept can be naturally extended to any set of se-
crets X , equipped with a metric dX [15, 12]. The distance
dX (x, x(cid:48)) expresses the distinguishability level between x and
x(cid:48):
if the distance is small then the secrets should remain
indistinguishable, while secrets far away from each other are
allowed to be distinguished by the adversary. The metric
should be chosen depending on the application at hand and
the semantics of the privacy notion that we try to achieve.
Following the notation of [12], a mechanism is a proba-
bilistic function K : X → P(Z), where Z is a set of re-
ported values (assumed ﬁnite for the purposes of this pa-
per). The similarity between probability distributions can
be measured by the multiplicative distance dP deﬁned as
µ2(z)| = 0 if both
dP (µ1, µ2) = supz∈Z | ln µ1(z)
µ1(z), µ2(z) are zero and ∞ if only one of them is zero.
In other words, dP (µ1, µ2) is small iﬀ µ1, µ2 assign similar
probabilities to each value z.
µ2(z)| with | ln µ1(z)
The generalized variant of diﬀerential privacy under the
metric dX , called dX -privacy, is deﬁned as follows:
Definition 2. A mechanism K : X → P(Z) satisﬁes
dX -privacy iﬀ:
(cid:48)
dP (K(x), K(x
)) ≤ dX (x, x
(cid:48)
)
∀x, x
(cid:48) ∈ X
or equivalently K(x)(z) ≤ edX (x,x(cid:48))K(x(cid:48))(z) for all x, x(cid:48) ∈
X , z ∈ Z. A privacy parameter  can also be introduced by
scaling the metric dX (note that dX is itself a metric).
Diﬀerential privacy can then be expressed as dh-privacy.
Moreover, diﬀerent metrics give rise to various privacy no-
tions of interest; several examples are given in [12].
2.3 Geo-indistinguishability
In the context of location based systems the secrets X are
locations, and we can obtain a useful notion of location pri-
vacy by naturally using the Euclidean distance d2, scaled by
a security parameter . The resulting notion of d2-privacy,
called -geo-indistinguishability in [9], requires that a loca-
tion obfuscation mechanism should produce similar results
when applied to locations that are geographically close. This
prevents the service provider from inferring the user’s loca-
tion with accuracy, while allowing him to get approximate
information required to provide the service. Following the
spirit of diﬀerential privacy, this deﬁnition is independent
from the prior information of the adversary.
253A characterization of geo-indistinguishability from [9] pro-
vides further intuition about this notion. The character-
ization compares the adversary’s conclusions (a posterior
distribution) to his initial knowledge (a prior distribution).
Since some information is supposed to be revealed (i.e. the
provider will learn that the user is somewhere around Paris),
we cannot expect the two distributions to coincide. How-
ever, geo-indistinguishability implies that an informed ad-
versary who already knows that the user is located within
a small area N , cannot improve his initial knowledge and
locate the user with higher accuracy. More details, together
with a second characterization can be found in [9].
Note that geo-indistinguishability does not guarantee a
small leakage under any prior; in fact no obfuscation mech-
anism can ensure this while oﬀering some utility. Consider,
for instance, an adversary who knows that the user is lo-
cated at some airport, but not which one. Unless the noise
is huge, reporting an obfuscated location will allow the exact
location to be inferred, but this is unavoidable.1.
Considering the mechanism, [9] shows that geo-indistingui-
shability can be achieved by adding noise to the user’s loca-
tion drawn from a 2-dimensional Laplace distribution. This
can be easily done in polar coordinates by selecting and an-
gle uniformly and a radius from a Gamma distribution. If
a restricted set of reported locations is allowed, then the lo-
cation produced by the mechanism can be mapped back to
the closest among the allowed ones.
Although the Laplace mechanism provides an easy and
practical way of achieving geo-indistinguishability, indepen-
dently from any user proﬁle, its utility is not always optimal.
In the next section we show that by tailoring a mechanism
to a prior corresponding to a speciﬁc user proﬁle, we can
achieve better utility for that prior, while still satisfying
geo-indistinguishability, i.e. a privacy guarantee indepen-
dent from the prior. The evaluation results in Section 4
show that the optimal mechanism can provide substantial
improvements compared to the Laplace mechanism.
3. GEO-INDISTINGUISHABLE
MECHANISMS OF OPTIMAL UTILITY
As discussed in the introduction, we aim at obtaining a
mechanism that optimizes the tradeoﬀ between privacy (in
terms of geo-indistinguishability) and quality loss (in terms
the metric QL). Our main goal is, given a set of locations X
with a privacy metric dX (typically the Euclidean distance),
a privacy level , a user proﬁle π and a quality metric dQ, to
ﬁnd an dX -private mechanism such that its QL is as small
as possible.
We start by describing a set of linear constraints that en-
force dX -privacy, which allows to obtain an optimal mecha-
nism as a linear optimization problem. However, the number
of constraints can be large, making the approach computa-
tionally demanding as the number of locations increases. As
a consequence, we propose an approximate solution that re-
places dX with the metric induced by a spanning graph.
We discuss a greedy algorithm to calculate the spanning
graph and analyze its running time. We also show that, if
the quality and adversary metrics coincide, then the con-
structed (exact or approximate) mechanisms also provide
1This example is the counterpart of the well-known Terry
Gross example from [11]
optimal privacy in terms of AdvError. Finally, we discuss
some practical considerations of our approach.
3.1 Constructing an optimal mechanism
The constructed mechanism is assumed to have as both
input and output a predetermined ﬁnite set of locations X .
For instance, X can be constructed by dividing the map in
a ﬁnite number of regions (of arbitrary size and shape), and
selecting in X a representative location for each region. We
also assume a prior π over X , representing the probability
of the user being at each location at any given time.
Given a privacy metric dX (typically the Euclidean dis-
tance) and a privacy parameter , the goal is to construct
a dX -private mechanism K such that the service quality
loss with respect to a quality metric dQ is minimum. This
property is formally deﬁned below:
Definition 3. Given a prior π, a privacy metric dX , a
privacy parameter  and a quality metric dQ, a mechanism
K is dX -OptQL(π, dQ) iﬀ:
1. K is dX -private, and
2. for all mechanisms K(cid:48), if K(cid:48) is dX -private then
QL(K, π, dQ) ≤ QL(K(cid:48), π, dQ)
Note that dX -OptQL optimizes QL given a privacy con-
straint, while q-OptPriv (Deﬁnition 1) optimizes privacy,
given an QL constraint.
In order for K to be dX -private it should satisfy the fol-
lowing constraints:
kxz ≤ edX (x,x(cid:48))kx(cid:48)z
x, x(cid:48), z ∈ X
Hence, we can construct an optimal mechanism by solving a
linear optimization problem, minimizing QL(K, π, dQ) while
satisfying dX -privacy:
Minimize:
πxkxzdQ(x, z)
Subject to: kxz ≤ edX (x,x(cid:48))kx(cid:48)z
(cid:88)
(cid:88)
x,z∈X
kxz = 1
z∈X
kxz ≥ 0
x, x
(cid:48)
, z ∈ X
x ∈ X
x, z ∈ X
It is easy to see that the mechanism K generated by the
previous optimization problem is dX -OptQL(π, dQ).
3.2 A more efﬁcient method using spanners
In the optimization problem of the previous section, the
dX -privacy deﬁnition introduces |X|3 constraints in the lin-
ear program. However, in order to be able to manage a large
number of locations, we would like to reduce this amount to
a number in the order of O(|X|2). One possible way to
achieve this is to use the dual form of the linear program
(shown in the appendix). The dual program has as many
constraints as the variables of the primal program (in this
case |X|2) and one variable for each constraint in the pri-
mal program (in this case O(|X|3)). Since the primal linear
program ﬁnds the optimal solution in a ﬁnite number of
steps, it is guaranteed by the strong duality theorem that
dual program will also do so. However, as shown in Section
4.3, in practice the dual program does not oﬀer a substan-
tial improvement with respect to the primal one (a possible
254explanation being that, although fewer in number, the con-
strains in the dual program are more complex, in the sense
that each one of them involves a larger number of variables).
An alternative approach is to exploit the structure of the
metric dX . So far we are not making any assumption about
dX , and therefore we need to specify |X| constraints for each
pair of locations x and x(cid:48). However, it is worth noting that
if the distance dX is induced by a weighted graph (i.e. the
distance between each pair of locations is the weight of a
minimum path in a graph), then we only need to consider
|X| constraints for each pair of locations that are adjacent
in the graph. An example of this is the usual deﬁnition of
diﬀerential privacy: since the adjacency relation between
databases induces the Hamming distance dh, we only need
to require the diﬀerential privacy constraint for each pair
of databases that are adjacent in the Hamming graph (i.e.
that diﬀer in one individual).
It might be the case, though, that the metric dX is not
induced by any graph (other than the complete graph), and
consequently the amount of constraints remains the same.
In fact, this is generally the case for the Euclidean metric.
Therefore, we consider the case in which dX can be approx-
imated by some graph-induced metric.
If G is an undirected weighted graph, we denote with dG
the distance function induced by G, i.e. dG(x, x(cid:48)) denotes
the weight of a minimum path between the nodes x and x(cid:48)
in G. Then, if the set of nodes of G is X and the weight of
its edges is given by the metric dX , we can approximate dX
with dG. In this case, we say that G is a spanning graph, or
a spanner [16, 17], of X .
Definition 4
(Spanner). A weighted graph G = (X , E),
with E ⊆ X ×X and weight function w : E → R is a spanner
of X if
(cid:48)
(cid:48)
w(x, x
) = dX (x, x
) ∀(x, x
(cid:48)
Note that if G is a spanner of X , then
) ∀x, x
) ≥ dX (x, x
dG(x, x
(cid:48)
(cid:48)
) ∈ E
(cid:48) ∈ X
A main concept in the theory of spanners is that of dilation,
also known as stretch factor:
Definition 5
ner of X . The dilation of G is calculated as:
(Dilation). Let G = (X , E) be a span-
δ = max
x(cid:54)=x(cid:48)∈X
dG(x, x(cid:48))
dX (x, x(cid:48))
A spanner of X with dilation δ is called a δ-spanner of X .
Informally, a δ-spanner of X can be considered an approx-
imation of the metric dX in which distances between nodes
are “stretched” by a factor of at most δ. Spanners are gener-
ally used to approximate distances in a geographic network
without considering the individual distances between each
pair of nodes. An example of a spanner for a grid in the
map can be seen in Figure 1.
If G is a δ-spanner of X , then it holds that
(cid:48) ∈ X
) ∀x, x
which leads to the following proposition:
) ≤ δdX (x, x
dG(x, x
(cid:48)
(cid:48)
Proposition 1. Let X be a set of locations with metric
dX , and let G be a δ-spanner of X . If a mechanism K for
X is 
δ dG-private, then K is dX -private.
Figure 1: (a) a division of the map of Paris into a
7 × 5 square grid. The set of locations X contains
the centers of the regions. (b) A spanner of X with
dilation δ = 1.08.
We can then propose a new optimization problem to ob-
tain a dX -private mechanism. If G = (X , E) is a δ-spanner
of X , we require not the constraints corresponding to dX -