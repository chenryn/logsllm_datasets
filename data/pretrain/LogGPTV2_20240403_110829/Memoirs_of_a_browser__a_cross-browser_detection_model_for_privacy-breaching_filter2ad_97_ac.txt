### Amplification Factors and Background Activities in Browsers

In contemporary web browsers, the continuous execution of background tasks is more common than not. For instance, Firefox frequently performs garbage collection on unused heap regions [15], while Chrome periodically checks for certificate revocations and platform updates. Additionally, AJAX-based web applications often perform background activities, such as sending and retrieving data from web servers.

To investigate this issue, we recorded the aggregated memory write distribution of recent browsers with no foreground activity. Figure 3 illustrates our findings: all browsers, except Internet Explorer (IE), engage in memory-intensive background tasks. We also observed that the distribution of these background memory activities can vary significantly between different browser versions.

### Enhancing the Model to Handle Spurious Memory Activities

To make our model resilient to spurious memory activities, we extended our original feature vector in two ways. First, we filtered out spurious memory writes monitored over a specific period. Second, we incorporated additional features to account for the variability in background activities.

### Synthetic Examples and Training Set

We implemented synthetic examples for each browser and found them to be highly representative for our analysis. The baseline accurately models extensions that do not intercept keystroke events. Our synthetic shortcut manager models legitimate extensions that intercept keystroke events but do not log sensitive data. Finally, our synthetic keylogger models the privacy-breaching behavior of extensions that eavesdrop and log intercepted keystroke events.

The proposed training set has two advantages:
1. It can be easily reproduced for any given browser with minimal effort.
2. Given the simplicity of the synthetic extensions, the same training set can be maintained across different browsers.

However, a limitation of this small training set is its inability to train our SVM classifier with all possible privacy-breaching behaviors. Legitimate behaviors are well represented by the baseline and the synthetic shortcut manager. While we cannot predict how privacy-breaching extensions leak sensitive data, our detection strategy is designed to handle potential unwanted behaviors that may have escaped our training phase.

### Detection Process

The detection process involves several steps:
1. **Injection Parameters**: We use a random high-variance distribution for the injection vector to achieve low input predictability and stable PCC values. The number \( n \) and duration \( t \) of time intervals balance monitoring time and measurement reliability.
2. **Training Set**: Our default training set includes three examples: the baseline (negative example), a synthetic shortcut manager (negative example), and a synthetic keylogger (positive example).
3. **SVM Classifier Training**: For each training example, we inject a predetermined keystroke vector and monitor the resulting memory write distribution. The same is done for the browser with no extensions enabled. Feature vectors are derived from these distributions and used to train the SVM classifier.
4. **Detection Phase**: Before feeding the detection vector to the SVM classifier, we check for new relevant features. If no new features are found, the vector is processed normally. If new features emerge, an alert is raised to eliminate the possibility of unaccounted privacy-breaching behavior.

### Evaluation

We tested our approach on a machine with an Intel Core i7 2.13 GHz processor and 4 GB of RAM running Windows XP Professional SP3. We used the most widespread versions of the browsers (as of September 2011): Firefox 6.0.2, Chrome 13.0.782.216, and Internet Explorer 8. The injection vector had \( n = 10 \) and \( t = 500 \) ms, providing an overall detection time of 5 seconds.

Figure 4 shows the aggregated memory write distributions for the training examples. Correlation alone was insufficient to discriminate between negative and positive examples. However, the weights assigned to features during training showed that even small differences in amplification factors could provide sufficient discrimination power. For example, the JavaScript engine libraries (mozjs.dll and jscript.dll) were important in identifying high-quality features in Firefox and IE. In Chrome, the discrimination power was reduced, but the amplification factors still provided suitable separability.

### False Negatives

To evaluate the effectiveness of our technique, we gathered 30 malicious extensions from various sources and selected those performing keylogging activities. The resulting dataset included 5 full-featured extensions and 1 JS user script, leading to 7 different detection experiments. Table 1 shows the results, where the SVM classifier successfully detected the privacy-breaching nature of all samples.

### False Positives

To test robustness against false positives, we compiled a dataset of 13 extensions for each browser, including the 10 most common extensions and 3 popular shortcut management extensions. Table 2 shows the results, where all Chrome extensions were correctly classified as legitimate. In Firefox, only the NoScript extension was misclassified due to its complex implementation. In IE, only the LastPass extension was misclassified because it logs all user-issued keystrokes.

### Performance

Our profiling infrastructure can be attached and detached on demand, confining performance overhead to the detection window. A 5-second window (10 samples with a 500ms interval) is sufficient. Table 3 shows the performance impact, comparing the time required to load google.com in three scenarios: before installation (Baseline), with the infrastructure installed but detached, and during the detection time.

### Conclusion

Our approach effectively detects privacy-breaching extensions while maintaining robustness against false positives and minimizing performance overhead.