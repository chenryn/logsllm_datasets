the ampliﬁcation factors. Unfortunately, this scenario is the
norm, rather than the exception in today’s browsers. For ex-
ample, Firefox is known to continuously garbage collect un-
used heap regions [15]. Chrome periodically checks for cer-
tiﬁcates revocation and platform updates. In addition, back-
ground activities are often performed by increasingly com-
mon AJAX-based web applications that periodically send or
retrieve data from the web servers.
To investigate this issue, we recorded the aggregated
memory write distribution of all the recent browsers in case
of no foreground activity. Figure 3 depicts our ﬁndings: with
the exception of Internet Explorer (IE), all the browsers per-
form memory-intensive background tasks. We also observe
that the distribution of the background memory activities
can considerably vary from one browser version to another.
To make our model resilient to spurious memory activ-
ities, we extend our original feature vector in two ways.
First, we ﬁlter out spurious memory writes monitored for
 0 20000 40000 60000 80000 100000 120000 140000 160000 180000 0 2 4 6 8 10 12 14 16 18 20 22 24 26 28 30Bytes WrittenSampleGoogle Chrome 13.0.782.216Mozilla Firefox 5.0.1Mozilla Firefox 6.0.2Microsoft Internet Explorer 8We implemented all the synthetic examples for each
browser examined and found them to be highly represen-
tative for our analysis. The baseline accurately models all
the extensions that do not intercept keystroke events. Our
synthetic shortcut manager, in turn, models all the legiti-
mate extensions that do intercept keystroke events but with-
out logging sensitive data. Our synthetic keylogger, ﬁnally,
models the privacy-breaching behavior of all the extensions
that eavesdrop and log the intercepted keystroke events.
The proposed training set is advantageous for two rea-
sons. First, it can be easily reproduced for any given browser
with very little effort. Second, given the simplicity of the
synthetic extensions described, the same training set can be
easily maintained across different browsers. The only limi-
tation of such a small training set is the inability to train our
SVM classiﬁer with all the possible privacy-breaching be-
haviors. Note that, in contrast, legitimate behaviors are well
represented by the baseline and the synthetic shortcut man-
ager. While one can make no assumption on the way privacy-
breaching extensions leak sensitive data, our detection strat-
egy is carefully engineered to deal with potential unwanted
behaviors that escaped our training phase, as discussed later.
We now detail the steps of the proposed detection pro-
cess. First, we select suitable injection parameters to tune
the detector. We use a random high-variance distribution for
the injection vector. This is to achieve low input predictabil-
ity and stable PCC values. The number n and the duration t
of the time intervals, in turn, trade off monitoring time and
reliability of the measurements. The larger the duration of a
single time interval, the better the synchronization between
the injection and the monitoring phase. The larger the num-
ber of the time intervals, the lower the probability of spuri-
ous PCC values reporting high correlation when no causality
was possible.
to simulate user-issued keystrokes in the injection phase.
While we could easily collect several legitimate and privacy-
breaching browser extensions to construct the training set to
satisfy the latter, in practice we found a minimal synthetic
training set to be more convenient for our purposes. Our
default training set comprises only 3 examples: the baseline
(negative example), a synthetic shortcut manager (negative
example), and a synthetic keylogger (positive example).
Subsequently, we train our SVM classiﬁer for the target
browser. For each training example we conduct an experi-
ment to inject the predetermined keystroke vector and mon-
itor the resulting memory write distribution produced by the
browser. The same is done for the browser with no exten-
sions enabled. The feature vectors are then derived from the
memory write distributions obtained, as described in Sec-
tion 4.4. The training vectors are ﬁnally used to train our
SVM classiﬁer. The same procedure is used to obtain feature
vectors for unclassiﬁed extensions in the detection phase.
Before feeding the detection vector to our SVM classi-
ﬁer, the detection algorithm performs a preprocessing step.
The vector is checked for any new relevant features that
we previously discarded in the feature selection step. If no
such a feature is found, the detection vector is normally pro-
cessed by our SVM-based detector, which raises an alert if
the vector is classiﬁed as a privacy-breaching extension. If
any new relevant feature emerges, in contrast, our detection
algorithm always raises an alert indiscriminately. This step is
necessary in the general case to eliminate the possibility of
privacy-breaching behavior not accounted for in the training
phase. This conservative strategy leverages the assumption
that legitimate behavior is well represented in the training
set, and previously unseen behavior correlated to the injec-
tion is likely to reﬂect unwanted behavior.
6. Evaluation
We tested our approach on a machine with Intel Core i7
2.13 GHz and 4 GB of RAM running Windows XP Pro-
fessional SP3. We chose the most widespread versions of
the browsers analyzed (as of September 2011 [36]): Firefox
6.0.2, Chrome 13.0.782.216, and Internet Explorer 8. In the
experiments, we used the injection vector described in Sec-
tion 5, with n = 10 and t = 500ms for an overall detection
time of 5s. These values were sufﬁcient to provide very ac-
curate results.
Figure 4. Memory write distributions obtained during a
training phase with a sinusoidal-shaped injection vector.
Figure 4 shows the aggregated memory write distribu-
tions obtained for the training examples of each browser.
As evident from the ﬁgure, the correlation alone was never
sufﬁcient to discriminate between negative and positive ex-
amples. And neither were the aggregated ampliﬁcation fac-
tors, which, for instance, set positive and negative examples
only a few bytes apart in Firefox and IE. Nevertheless, the
weights assigned to the features during the training phase
showed that even with negligible differences in the aggre-
gated ampliﬁcation factors, individual features can still be
used to achieve sufﬁcient discrimination power. For instance,
in Firefox and IE we found that the JavaScript (JS) engine
libraries (i.e., mozjs.dll and jscript.dll) played an im-
portant role in identifying high-quality features. Chrome, in
 60000 64000 68000 72000 76000IE 8Bytes Written 0 20000 40000 60000 80000Firefox 6Bytes Written 0 1 2 3 4 5 6 7 8 9 10 0 20000 40000 60000 80000Chrome 13Bytes WrittenSampleBaselinePositive ExampleNegative Examplecontrast, exhibited a limited number of features with very
similar weights. While the discrimination power is clearly
reduced in this case, Chrome’s ampliﬁcation factors were
found far apart between positive and negative examples, thus
still revealing a degree of separability suitable for accurate
behavior classiﬁcation.
6.1 False Negatives
To evaluate the effectiveness of our technique we gathered
30 different malicious extensions from public fora, online
repositories [14, 25], blocked extensions lists [24], and anti-
virus security bulletins [37]. We then manually inspected all
the samples via static and dynamic analysis and selected
only those performing keylogging activities. The resulting
dataset comprises 5 full-ﬂedged extensions—also known as
Browser Helper Objects (BHOs) in the case of IE 8—, and
1 JS user script compatible with both Firefox and IE, hence
obtaining a set of 7 different detection experiments. JS user
scripts are stripped down extensions with no packaging in-
frastructure or ability to modify the existing user interface.
Chrome supports user scripts natively when limited privi-
leges are required, whereas Firefox and IE depend upon the
installation of the Greasemonkey [20] and Trixie [35] exten-
sions respectively, which also provide access to privileged
APIs. We point out that in all cases, regardless of the exten-
sion’s type, the installation procedure never required super-
user privileges.
Browser
Extension
Detected
Chrome 13
extensionkeylog.sourceforge.net
chrome.google.com/webstore/detail
/afllmmeoaodlbocnfihkaihpkcakomco
Firefox 6
addons.mozilla.org/addon/220858
userscripts.org/scripts/show/72353
IE 8
flyninja.net/?p=1014
wischik.com/lu/programmer/bho.html
userscripts.org/scripts/show/72353
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
Table 1. Detection of privacy-breaching extensions per-
forming keylogging activities.
Table 1 shows the results of our experiments. In all
the cases, the SVM classiﬁer successfully ascertained the
privacy-breaching nature of the samples regardless of the ex-
tension type. The most interesting experiments were against
the 2 BHO extensions in IE, which are implemented directly
by a DLL. The ability of a DLL to independently manage
memory may at times produce new relevant features that
were nowhere found during the training phase, thus theoret-
ically hindering detection. Our detection strategy, however,
gracefully handles this situation in the preprocessing step,
which immediately raises an alert when new relevant fea-
tures are discovered in the detection vector. This ensured all
the BHOs could be detected correctly in our experiments.
6.2 False Positives
To test the robustness of our approach against false positives,
we put together a dataset of 13 extensions for each browser,
comprising the 10 most common extensions [7, 21, 34] and
the 3 most popular shortcut management extensions, care-
fully selected because prone to misclassiﬁcation. Table 2
shows the results of our detector against all these extensions.
All the extensions for Chrome were correctly classiﬁed as
legitimate. The grey-colored rows highlight all the shortcut
management extensions selected. Despite the presence of
keystroke interception APIs, none of these extensions was
misclassiﬁed. This conﬁrms the robustness of our technique.
In the case of Firefox, 12 out of 13 extensions were clas-
siﬁed correctly. The NoScript extension, which blocks any
script not explicitly whitelisted by the user, was the only mis-
classiﬁed sample. A quick analysis showed a memory write
distribution unexpectedly similar to those exhibited by key-
logging samples. A deeper inspection revealed a very com-
plicated implementation of always-on shortcut management
functionalities, with every keystroke processed and decoded
several times. Other extensions that explicitly provide short-
cut management functionalities (grey-colored rows) were in-
stead classiﬁed correctly. Similarly to Firefox, only 1 exten-
sion (i.e., LastPass, a popular password manager) was erro-
neously classiﬁed for IE. A careful code inspection revealed
that the implementation of the extension logs all the user-
issued keystrokes indiscriminately. This allows the user to
save any previously ﬁlled credentials after a successful login.
Since the keystrokes are effectively logged and can poten-
tially be leaked to third parties at a later time, our detection
strategy conservatively ﬂags this behavior as suspicious.
6.3 Performance
The ability to attach and detach our proﬁling infrastructure
to the browser on demand (as arbitrated by the user) allows
us to conﬁne the performance overhead to the detection win-
dow. The previous sections have demonstrated that a window
of 5 seconds (i.e., 10 samples with a 500ms time interval) is
sufﬁcient for our purposes. This conﬁnes the overhead to a
very limited period of time, allowing the user to start a quick
detection run whenever convenient, for example, when vet-
ting unknown extensions upon installation.
Browser
Chrome 13
Firefox 6
IE 8
Table 3. Performance hit while loading google.com.
Baseline Normal use Detection time
1345ms
1472ms
2123ms
1390ms
1498ms
2158ms
11254ms
12362ms
14177ms
Table 3 show the performance impact of our online in-
frastructure by comparing the time required to load http:
//www.google.com in three different scenarios: (i) prior
to the installation of our infrastructure (Baseline), (ii)
with our infrastructure installed but completely detached
Google Chrome 13.0.782.216
Extension
Shortcut 0.2
Shortcut Manager 0.7.9
SiteLauncher 1.0.5
AdBlock 2.4.22
ClipToEvernote 5.1.15.1534
Download Master 1.1.4
Fastest Chrome 4.2.3
FbPhoto Zoom 1.1108.9.1
Google Mail Checker 3.2
IETab 2.7.14.1
Google Reader Notiﬁer 1.3.1
Rampage 3
RSS Subscription 2.1
Identiﬁed Extension
Firefox 6.0.2
Identiﬁed Extension
Internet Explorer 8
Identiﬁed
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
GitHub Shortcuts 2.2
ShortcutKey2Url 2.2.1
SiteLauncher 2.2.0
AdBlock Plus 1.3.10
Down Them All 2.0.8
FireBug 1.8.4
FlashGot 1.3.5
GreaseMonkey 0.9.13
NoScript 2.2.1
Video Download Helper 4.9.7
Easy YouTube Video 5.7
Download Statusbar 0.9.10
Personas Plus 1.6.2
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
Shortcut Manager 7.0003
ieSpell 2.6.4
IE7Pro 2.5.1
YouTubeVideoDwnlder 1.3.1
LastPass (IEanywhere)
OpenLastClosedTab 4.1.0.0
Star Downloader 1.45.0.0
SuperAdBlocker 4.6.0.1000
Teleport Pro 1.6.3
WOT 20110720
CloudBerry TweetIE 1.0.0.22
Cooliris 1.12.0.33689
ShareThis 1.0
(cid:88)
(cid:88)
(cid:88)
(cid:88)