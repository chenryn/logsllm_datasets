Input (cid:6) i
Output (cid:6) o
::= ch(n)
::= ch(n) | •
The syntax of programs, handlers, commands, and expres-
sions is deﬁned as follows:
p ::= · | h; p
h ::= ch(x){c}
::= skip |
c
c; c
| if e then c else c
::= x | n | r | e (cid:7) e
e
(cid:7) ::= + | − | = | <
|
| while e {c}
| output ch(e)
r := e
A program is a collection of event handlers, each of which
accepts a message (a natural number) on some channel and
runs a simple imperative program in response. The han-
dler code may examine and modify shared global state, send
messages, branch, and loop. When the handler for an input
terminates, the RIMP program returns to a state in which
it can handle another input. Handlers persist after handling
events. Note that, since handlers share a global state, pro-
cessing one input may aﬀect the behavior of handlers in the
future. The global state, called the store, is a mapping from
variables r to natural numbers. We assume that every vari-
able in the global state is initialized to 0 at the start. In the
machine that runs RIMP programs, a consumer state con-
sists of the program text and the shared global state, and
a producer state additionally includes the command that is
currently being executed. If a producer state takes a step
that does not otherwise generate an output message, we as-
sume the label on that transition is •.
Of course, RIMP is a long way from a full-featured web
scripting language. Our goal with RIMP is to model only
the event-handling mechanism of web application program-
ming. Moreover, for the sake of simplicity, there is no mech-
anism for dynamically adding or removing handlers, which
is characteristic of web programming; however, we believe
our work on RIMP in this paper can be extended to account
for this scenario once ﬁrst-class functions and dynamic allo-
cation are added to the language (which have been studied
before in the context of information-ﬂow type systems [17]).
We leave that for future work. Finally, it is worth noting
81that the integration of secure web scripts into web docu-
ments also requires careful consideration, which is another
topic we must defer to our future work.
3. SECURITY OF REACTIVE SYSTEMS
As described earlier, reactive systems may send messages to
and receive messages from multiple agents, which we will call
principals. We assume there is a pre-order of security labels
(L,≤) and that all principals have a label corresponding
to a level of authorization. We also assume that messages
interchanged with the system have a label indicating their
level of conﬁdentiality. We intend to derive this level from
the channel that carries the message, and this can be done
at the point where the message streams are multiplexed. We
assume that principals at a level l may only view messages
at or below the level l. This is reasonable if we assume that
observers would be positioned at the endpoints of HTTP
connections and view the elements of L as based on domain
names.
It is important to remember that, in the particular setting
of web applications, it is the web browser user’s personal se-
crets and the user’s shared secrets with other principals that
are being protected. (We are in no way addressing the issue
of protecting a web server’s secrets from web clients.) As
noted before, there must be some means to associate chan-
nels with user interface components. Since these channels
determine the assigned security level of the data, it is nec-
essary to have a user interface design that allows users of
web applications to view the precise security level of any in-
terface component.3 We assume that any user input control
with a channel labeled by (cid:9) (a maximal element of L) can
be used to handle information that should never leave the
user’s computer.
Now we can state an informal deﬁnition of information
security:
if a principal at one level cannot draw a distinc-
tion between two streams of inputs given to a reactive sys-
tem starting in a particular state, then the same observer
must not be able to draw a distinction between the result-
ing streams of outputs. This is a natural generalization of
standard deﬁnitions of noninterference for imperative and
functional languages [21, 17], and corresponds closely to
Goguen and Meseguer’s MLS property [6]. We can state
this deﬁnition formally in the following way:
3.1 Deﬁnition: A state Q is secure if, for all l, I ≈l I(cid:2)
implies O ≈l O(cid:2)
The notation S ≈l S(cid:2)
is meant to stand for a similarity rela-
tion on streams that is parametrized by a label l—in other
words, the inability of an observer at level l to draw a dis-
tinction between S and S(cid:2)
. Deﬁning this relation precisely is
where things become interesting: it turns out that there are
whenever Q(I) ⇒ O and Q(I(cid:2)
) ⇒ O(cid:2)
.4
3Although this raises questions about human interface de-
sign that are quite important in practice, it does not aﬀect
the fundamental theory of browser security that we are de-
veloping here.
4In this deﬁnition, we do not assume that the reactive
system under consideration is deterministic, but it can be
shown that this deﬁnition does put very stringent restric-
tions on the sorts of nondeterminism that are deemed se-
cure. This deﬁnition suﬃces for our purposes here, but a
more lenient, possibilistic notion of security would demand
an equivalence on the sets of output streams that might be
produced by equivalent input streams.
many natural notions of similarity between streams relative
to an observer who cannot see all of the elements, leading
us to multiple notions of security. Moreover, there are mul-
tiple ways to deﬁne each of these notions of similarity, and
it is often diﬃcult to guess which deﬁnitions are precisely
equivalent. In the remainder of this section, we present a
deﬁnition for four, increasingly-reﬁned notions of similarity,
and consider the technical implications for the correspond-
ing deﬁnitions of security.
Preliminaries. To discuss these notions of security pre-
cisely, we need a few auxiliary deﬁnitions. To determine
whether a stream element s is visible to an observer at level
l, we use the predicate visible l(s). We assume that the set
of security labels L has a top element, (cid:9), with visible(cid:3)(s)
for all s. In examples, we assume there are labels (cid:9) and ⊥
and channels ch(cid:3) and ch⊥, such that messages on channel
ch(cid:3) are invisible to an observer at level ⊥.
We also need some auxiliary deﬁnitions about streams.
We write ﬁn(S) when S is ﬁnite and inf (S) when S is inﬁ-
nite. Next, we need a relation that associates a stream with
its next l-visible element (if such an element exists) and with
the remainder of the stream thereafter.
3.2 Deﬁnition: Inductively deﬁne S (cid:2)l s :: S(cid:2)
s followed by S(cid:2)
visible l(s)
) with the following rules:
¬ visiblel(s)
(S l-reveals
:: S(cid:2)
s :: S (cid:2)l s(cid:2)
S (cid:2)l s(cid:2)
:: S(cid:2)
s :: S (cid:2)l s :: S
This predicate is inductively deﬁned because we only want
it to hold true if one can ﬁnd an l-visible element in a ﬁnite
preﬁx of the potentially inﬁnite stream. On the other hand,
we would also like to deﬁne a predicate asserting that a
stream contains no more l-visible elements.
3.3 Deﬁnition: Coinductively deﬁne silent l(S) with the
following rules:
¬ visible l(s)
silent l(S)
silent l([])
silent l(s :: S)
This deﬁnition is coinductive because it is asserting a fact
about all of the elements of a potentially inﬁnite stream.
Nonconﬂicting Security. The ﬁrst two versions of similar-
ity that we present are each deﬁned by taking the negation
of a deﬁnition of stream distinctness. The coarsest version
of similarity, nonconﬂicting similarity, just requires that the
observer cannot ﬁnd two distinct stream elements in corre-
sponding positions in the streams. Since a conﬂict must be
evident from some ﬁnite preﬁxes of two streams, an induc-
tive deﬁnition of this notion of distinctness is appropriate.
3.4 Deﬁnition: Inductively deﬁne conﬂicting l(S, S(cid:2)
the following rules:
) with
s (cid:12)= s(cid:2)
S(cid:2) (cid:2)l s(cid:2)
S (cid:2)l s :: S1
S (cid:2)l s :: S1
:: S(cid:2)
conﬂicting l(S, S(cid:2)
)
S(cid:2) (cid:2)l s :: S(cid:2)
conﬂicting l(S1, S(cid:2)
1)
conﬂicting l(S, S(cid:2)
)
3.5 Deﬁnition: Deﬁne S ≈NC
(S is NC-similar to S(cid:2)
S(cid:2)
at l) to mean ¬ conﬂicting l(S, S(cid:2)
). Deﬁne NC-security as
Deﬁnition 3.1, instantiated with NC-similarity.
1
l
1
82There are other ways of deﬁning NC-similarity. It turns
out that S is NC-similar to S(cid:2)
at l if the sequence of visible
elements of one stream is a preﬁx of the visible elements
of the other, which may be a more intuitive way to think
about this relation. Nonconﬂicting similarity is reﬂexive and
symmetric, but not transitive—we have [] ≈NC
l S for any l
and S.
3.6 Example: The following program is not NC-secure:
input ch(cid:3)(x) { output ch⊥(x) }
This event handler has an explicit ﬂow, and it is deemed
insecure because the streams [ch(cid:3)(0)] and [ch(cid:3)(1)] are
NC-similar at ⊥ but the corresponding output streams,
[ch⊥(0),•] and [ch⊥(1),•], are not NC-similar at ⊥.
3.7 Example: The following program is not NC-secure:
input ch(cid:3)(x) { r := x }
input ch⊥(x) { if r = 0 then output ch⊥(0)
else output ch⊥(1) }
output
streams,
The second event handler has an implicit ﬂow.
It is
deemed insecure because the input streams [ch(cid:3)(0), ch⊥(0)]
and [ch(cid:3)(1), ch⊥(0)] are NC-similar at ⊥ but
the
[•, •,•, ch⊥(0),•]
corresponding
and
[•, •, •, ch⊥(1),•], are not NC-similar at ⊥.
It may not be immediately clear which • outputs go with
which inputs in the previous example, and the reader may
wonder at this point whether our formalization of security
has an inherent weakness because it handles the input and
output streams separately rather than as one interleaved
stream. In fact, this is a weakness of NC-similarity (but it
will be resolved by stricter notions of similarity).
3.8 Example: The following program is NC-secure:
input ch(cid:3)(x) { r := x }
input ch⊥(x) { if r = 0 then output ch⊥(0)
else (output ch⊥(0); output ch⊥(0)) }
This example is almost the same as the previous ex-
ample. However, this one will map the input streams
[ch(cid:3)(0), ch⊥(0)] and [ch(cid:3)(1), ch⊥(0)] to the output streams
[•, •, •, ch⊥(0),•] and [•, •, •, ch⊥(0),•, ch⊥(0),•], which are
NC-similar at ⊥. We can see that the program is NC-secure,
in general, because the only outputs it can produce are •
and ch⊥(0), and any two streams of these elements are NC-
similar at ⊥. In order to strengthen our notion of security
to deal with the synchronization behavior of inputs and out-
puts, we need a more reﬁned notion of similarity—one that
coincides with the obvious deﬁnition on ﬁnite streams (i.e.,
dropping invisible items and comparing what remains for
equality) when both streams are ﬁnite.
Indistinguishable Security. We modify the previous deﬁ-
nition by adding two inference rules that eﬀectively grant an
observer the power to distinguish ﬁnite silent streams from
streams that still have observable elements. We call this
indistinguishable similarity.
3.9 Deﬁnition: Deﬁne distinguishable l(S, S(cid:2)
with the following rules:
) inductively
S (cid:2)l s :: S1
silent l(S(cid:2)
)
distinguishable l(S, S(cid:2)
ﬁn(S(cid:2)
)
)
silent l(S)
ﬁn(S)
S(cid:2) (cid:2)l s :: S(cid:2)
1
S (cid:2)l s :: S1
distinguishable l(S, S(cid:2)
:: S(cid:2)
distinguishable l(S, S(cid:2)
S(cid:2) (cid:2)l s(cid:2)
1
)
)
s (cid:12)= s(cid:2)
S (cid:2)l s :: S1
S(cid:2) (cid:2)l s :: S(cid:2)
distinguishable l(S1, S(cid:2)
1)
distinguishable l(S, S(cid:2)
)
1
3.10 Deﬁnition: Deﬁne S ≈ID
l S(cid:2)
l) to mean ¬ distinguishable l(S, S(cid:2)
Deﬁnition 3.1, instantiated with ID-similarity.
Note that we deﬁned distinguishable l(S, S(cid:2)
(S is ID-similar to S(cid:2)
at
). Deﬁne ID-security as
) exactly as one
would inductively deﬁne distinctness of ﬁnite streams, so its
behavior on ﬁnite streams is the obvious one that simply ﬁl-
ters out invisible elements and tests the remaining lists for
equality. It immediately renders Example 3.8 insecure be-
cause, in general, if the high inputs diﬀer, the output streams
will not be equal after dropping the • outputs. Although ID-
similarity gives an equivalence relation on ﬁnite streams, it
is not transitive, in general, because of its subtle behavior
on inﬁnite streams. Observe that, if inf (S) and silent l(S),
then S ≈ID
. This observation leads us to
our next example.
for all l and S(cid:2)
l S(cid:2)
3.11 Example: The following program is ID-secure.
input ch(cid:3)(x) { r := x }
input ch⊥(x) { if r = 0 then output ch⊥(0)
else while 1 do skip }
The second event handler creates a termination chan-
nel. Observe that the input streams [ch(cid:3)(0), ch⊥(0)] and
[ch(cid:3)(1), ch⊥(0)] are ID-similar at ⊥ and the correspond-
ing output streams [•, •, •, ch⊥(0),•] and [•, •, •,•, . . .] are,
in fact, also ID-similar at ⊥. Thus, this is a termination-
insensitive deﬁnition of security.