may be duplicated to further increase parallelism. To minimize
pipeline stalls from program branches, the processor will try to pre-
dict the outcome of conditional jumps. Simultaneous multithreading
Figure 2: Interrupt latency leaks information about the in-
struction that was executing at the time of IRQ arrival.
technology can interleave the execution of multiple independent
instruction streams on the same physical CPU core to maximize
the use of available execution units. Repeated memory accesses are
furthermore sped up by means of an intricate cache hierarchy for
among others micro-ops, instructions, data, and address transla-
tion. However, despite all these optimizations, Intel [36] confirms
that the basic property remains that “all interrupts are guaranteed
to be taken on an instruction boundary [...] located during the
retirement phase of instruction execution”.
2.3 Basic Nemesis Attack
We consider processors that serve interrupts after the execute stage
has completed,2 which can take multiple clock cycles depending
on the microarchitectural behavior of the instruction. Our attacks
are based on the key observation that an IRQ during a multi-cycle
instruction increases the interrupt latency with the number of cycles
left to execute – where interrupt latency is defined as the number of
clock cycles between arrival of the hardware IRQ and execution of
the first instruction in the software ISR. When interrupt arrival time
is known (e.g., generated by a timer), untrusted system software can
infer the duration of the interrupted instruction from a timestamp
obtained on ISR entry.
Figure 2 illustrates our basic attack for an enclaved execution
that branches on a secret. After the conditional jump jz in the victim
enclave, either the two-cycle instruction inst1 or the three-cycle
instruction inst2 is executed. In an ideal environment, a kernel-
level attacker proceeds as follows to determine private control
flow. First, before executing the enclave, a cycle-accurate timer is
configured to schedule an IRQ at the beginning of the first clock
cycle x + 1 after the conditional jump instruction. Next, the enclave
is entered and the timer fires, interrupting either inst1 or inst2.
After instruction completion, the secure hardware stores and clears
protected execution state, and hands over control to the untrusted
interrupt handler code. Here, the adversary compares the value
of a timestamp counter with the known IRQ arrival time to yield
a timing difference of one clock cycle, depending on whether the
conditional jump in the enclaved execution was taken or not.
The above scenario is a clear example of how an untrusted OS
can leverage interrupt latency to break the black box view on
2 While not the focus of this paper, there are also issues with cancelling the currently
executing instruction upon IRQ arrival, as outlined in Section 6.
protected modules. In line with previous enclaved execution at-
tacks [8, 42, 75, 79], Nemesis-type interrupt timing attacks exploit
secret-dependent control flow. Specifically, we require a different
execution time for at least one instruction in the if/else branch. The
adversary furthermore relies on (i) a timer device capable of gen-
erating cycle-accurate IRQs, and (ii) a Time Stamp Counter (TSC)
peripheral that is incremented every CPU cycle. The main difficulty
for a successful attack lies in determining a suitable timer value
so as to interrupt the instruction of interest. This is non-trivial in
that it requires one to predict the duration between the moment
the timer is configured and the desired interruption point. For rea-
sons pointed out above, it is challenging to precisely predict the
execution time of an instruction stream on modern processors. We
present our approach to configuring the timer and dealing with
noise in Section 4.
Note that IRQ latency measurements capture an instruction-
granular measurement of the CPU’s microarchitectural state, such
that the instruction opcode (inst1 vs. inst2) is only one of many
properties that influence latency on modern processors. We will
show in Section 5 that Nemesis adversaries can also distinguish
instructions based on for instance CPU caching behavior, address
translation, or data operand dependencies.
3 CASE STUDY PLATFORMS AND ATTACKS
We implemented and evaluated Nemesis-type interrupt timing at-
tacks for both a representative embedded, as well as for an off-the-
shelf higher-end enclaved execution processor. To illustrate the
wide applicability of conditional control flow side-channel attacks,
beyond common cryptographic key extraction [25, 51, 62, 64, 75],
we follow a line of enclaved execution attacks [8, 31, 42, 74, 79] that
target non-cryptographic case study applications. Such applications
cannot be hardened straightforwardly using vetted crypto libraries,
as secrets are generally non-trivial to identify and conditional con-
trol flow is more prevalent plus harder to eliminate.
3.1 Sancus and Embedded PMAs
Given the rise of tiny embedded devices in recent years, a new
line of research [7, 16, 41, 53, 68] employs a lightweight program
counter based memory isolation technique to secure small micro-
controllers that lack hardware support for established security mea-
sures, such as virtual memory and processor privilege levels. The
Sancus [53, 55] research prototype extends the memory access logic
and instruction set of a low-end TI MSP430 microcontroller to allow
the creation, authentication, and destruction of enclaved software
modules with a hardware-only TCB. Furthermore, enclaves resid-
ing on the same device can securely link to each other using caller
and callee authentication primitives. A dedicated LLVM-based C
compiler hides low-level concerns such as secure linking, inter-
module calling conventions, and private call stack switching by
inserting short assembly code stubs to be executed whenever an
enclave is entered or exited. Finally, recent research [54, 72] has
shown that, in contrast to Intel SGX platforms, Sancus’ memory
isolation primitive can also be used to provide software enclaves
with exclusive access to Memory-Mapped I/O (MMIO) hardware
peripheral devices. However, since Sancus enclaves only feature
a single contiguous private data section, secure I/O on Sancus re-
quires the use of a small driver module entirely written in assembly
code, using only registers for data storage.
The original Sancus architecture presumes uninterruptible iso-
lated execution. Secure interruption of hardware-enforced embed-
ded software modules was pioneered by the TrustLite [41] PMA.
More specifically, TrustLite modifies the processor to push all CPU
registers onto the private call stack of the interrupted module, be-
fore clearing them and vectoring to the untrusted ISR. Subsequent
research [15] has since implemented a comparable hardware-level
interrupt mechanism for a prototypic Sancus-like PMA with a sin-
gle secure domain, and recent work-in-progress [73] reports on
hardware and compiler support for fully interruptible and reentrant
Sancus enclaves. For the work presented in this paper, we have im-
plemented TrustLite’s secure interrupt mechanism as an extension
to the original Sancus architecture. Furthermore, we extended the
compiler-generated entry stubs to restore private execution context
on the next invocation of a previously interrupted enclave.
We selected Sancus as the case study architecture representative
for the lowest end of the computing spectrum with strict security re-
quirements for mutually distrusting stakeholders. A recent exhaus-
tive PMA overview [45] indicates that Sancus is the only embedded
architecture with a fully open-source3 hardware design and tool
chain, which allowed us to develop the secure interrupt extensions.
In contrast to modern SGX processors, Sancus’ openMSP430-based
implementation embodies an elementary programmable micro-
controller without advanced architectural features such as paging,
caches, or out-of-order instruction pipelining. Given the simplis-
tic design of the security extensions, as well as the underlying
processor, the existence of remotely exploitable side-channels was
considered rather unlikely by the original designers [52, §7.5.3]. To
the best of our knowledge, we present the first controlled-channel
attack vector for embedded enclaved execution processors.
3.1.1 Bootstrap Loader. We illustrate the applicability of our basic
attack with a code snippet from an actual password comparison
routine in Texas Instruments’ MSP430 serial Bootstrap Loader (BSL)
implementation. The BSL software is executed on platform reset,
and enables remote, in-field firmware updates. To enforce that
only legitimate device owners can reprogram the microcontroller,
sensitive BSL commands are protected with a 32-byte password.
Our first Sancus application scenario employs hardware-enforced
isolation to shield critical BSL password-protected functionality
from untrusted embedded firmware.
cmp .b @r6 +, r12
jz
bis
1: ...
1f
#0 x40 , r11
cmp .b @r6 +, r12
jz
bis
jmp
1f
#0 x40 , r11
2f
1: nop nop nop nop 2: ...
Listing 1: (Un)balanced BSL password comparison.
However, the password comparison routine in some BSL ver-
sions is known to be vulnerable to an execution timing attack [24].
The left hand side of Listing 1 provides the original, actually used
3https://distrinet.cs.kuleuven.be/software/sancus and https://github.com/sancus-pma
MSP430 keypad application by Texas Instruments [49]. To increase
readability, the pseudo code in Fig. 3 omits practical concerns such
as detecting key releases and limiting the length of the PIN code.
We refer the interested reader to Appendix B for the full imple-
mentation, derived from a recently published open-source Sancus
automotive application case study [72].
The keypad has to be polled regularly to detect key presses. For
this, our application scenario relies on the untrusted operating sys-
tem for availability of the CPU time resource. Since the OS is in
control of scheduling decisions, it is allowed to interrupt SMsec at
all times.5 Our attack exploits key state dependent control flow in
the poll_keypad function. Appendix B provides the full compiler-
generated assembly code, but it suffices to say that the conditional
code path consists of two single-cycle instructions followed by ei-
ther a single-cycle tst or a two-cycle cmp instruction. If we succeed
in timing an IRQ two cycles after the conditional jump, we will
thus observe a difference in interrupt latency of one clock cycle,
depending on whether the private key state bit was set or not. Re-
configuring the timer to repeat the attack in each loop iteration
allows an untrusted ISR to unambiguously determine which keys
were pressed in a single run of SMsec.
3.2 Intel Software Guard eXtensions
Recent Intel x86 processors include Software Guard eXtensions
(SGX) [3, 48] that enable isolated execution of security-critical code
in hardware-enforced enclaves, embedded in the virtual address
space of a conventional OS process. SGX reduces the TCB to the
point where a remote software provider solely has to trust the im-
plementation of her own enclave, plus the underlying processor.
Enclave code is restricted to user space (ring 3), and has access to
all its protected pages, as well as to the unprotected part of the host
application’s address space. Dedicated CPU instructions switch the
processor in and out of enclave mode, where hardware-level access
control logic verifies the output of the untrusted address translation
process to safeguard enclaved pages from outside accesses. The
eenter instruction transfers control from the unprotected appli-
cation context to a predetermined location inside the enclave, and
eexit leaves an enclave programmatically. Alternatively, in case
of a fault or external interrupt, the processor executes an Asyn-
chronous Enclave Exit (AEX) procedure that saves the execution
context securely in a preallocated state save area inside the enclave,
and replaces the CPU registers with a synthetic state to avoid di-
rect information leakage to the untrusted ISR. The AEX procedure
also takes care of pushing a predetermined Asynchronous Exit
Pointer (AEP) on the unprotected call stack, so as to allow the OS
interrupt handler to return transparently to unprotected trampoline
code outside the enclave. From this point, a previously interrupted
enclave can be continued by means of the eresume instruction.
Intel SGX serves as our case study architecture for higher-end
enclaved execution platforms. A modern SGX-enabled CPU imple-
ments the complex x86 instruction set architecture, and includes all
advanced microarchitectural features found in modern processors.
5Note that Sancus’ secure IRQ logic stores execution state in the protected data section
of the interrupted enclave. For MMIO driver enclaves without general purpose private
data region, our hardware mechanism clears registers without saving them.
Figure 3: Secure keypad Sancus application scenario.
assembly code.4 For clarity we only show the body of the password
comparison loop, where the byte pointed to by r6 is compared with
the value in r12, and a bit in r11 is set to invalidate access when
the comparison fails. Observe that the code is unbalanced in that
the two-cycle bis (bit-set) instruction is only executed for incorrect
password bytes. Hence, an adversary can determine the correctness
of individual bytes by observing the program’s overall execution
time. We close this vulnerability in the hardened version on the
right by balancing the else branch with no-op compensation code,
as previously suggested in literature [11, 60].
We show that, even when executing the balanced password com-
parison routine in a Sancus enclave, untrusted system software
can still learn the correctness of individual password bytes by care-
fully timing interrupts. More specifically, an IRQ arriving in the
first clock cycle after the conditional jump instruction, will either
interrupt the two-cycle bis instruction or the single-cycle nop in-
struction. Hence, depending on the secret password byte, an IRQ
latency difference of one clock cycle will be observed. The hard-
ened routine thus properly closes the timing side-channel at the
architectural assembly code level, but unknowingly introduces a
new one at the microarchitectural level. As such, our elementary
BSL case study serves as a clear demonstration of the additional
attack surface induced by secure interrupts, where adversaries are
no longer restricted to start-to-end timing measurements of the
enclaved computation.
Secure Keypad. Various authors [16, 41, 53, 54, 72] have sug-
3.1.2
gested the use of small PMAs to securely interface embedded plat-
forms with peripheral I/O devices. Our second Sancus application
scenario leverages secure I/O to guarantee the secrecy of a 4-digit
PIN code towards an untrusted embedded operating system.
Figure 3 summarizes the core idea, where the security-sensitive
application logic is implemented in a protected SMsec enclave that
securely links to a dedicated SMdrv assembly enclave to gain ex-
clusive access to the MMIO region of the keypad peripheral, as
explained above. The untrusted OS can only interact with the key-
pad indirectly, through the public interface offered by SMsec. A
single entry point poll_keypad fetches the current key state from
the driver enclave, and processes each bit sequentially. The 16-bit
key state indicates which keys are down, and a static lookup table
is used to translate key numbers to the corresponding characters.
This is similar to a reference implementation for an unprotected
4Assembly code snippet from BSL v2.12, as published by [24].
flow decisions made for instance by the widely used binary search
algorithm to learn (parts of) the secret input. In this respect, binary
search serves as a particularly relevant example for the difficulty
of eliminating conditional control flow in general-purpose enclave
programs. The obvious alternative at the application level, an ex-
haustive scan of the public data, would increase the time complexity
from a logarithmic to a linear effort.
l i m ! = 0 ;
∗
( l i m = nmemb ;
p = base + ( l i m >> 1 )
cmp = ( ∗ compare ) ( key , p ) ;
i f
i f
( cmp == 0 )
( cmp > 0 )
base = p + s i z e ;
r e t u r n p ;
}
/ ∗
e l s e move
l e f t
f o r
}
l i m >>= 1 )
s i z e ;
{
{
/ ∗ key > p : move r i g h t
∗ /
lim −−;
∗ /
Listing 2: Binary search routine in Intel SGX Linux SDK.
Listing 2 shows the relevant part of the actual binary search
routine provided by the official Intel SGX Linux SDK. We refer
to Appendix C for the complete unmodified source code, plus a
disassembly of the compiled version. The implementation looks
up a provided key in the sorted array between base and lim by
repeatedly comparing it to the middle value. If the provided key
was found, the function returns. Otherwise, the values of base and
limit are adjusted according to whether the provided key was
greater or smaller than the middle value. We will show that the as-
sembly code paths corresponding to whether the algorithm took the
left, right, or equal branch, manifest subtle yet distinct instruction
latency patterns which are revealed in the extracted IRQ latency
traces. As with the Zigzagger example above, the secret lookup
key is learned even when the array fits entirely within a single
cache line. For larger arrays, motivated adversaries can develop
highly practical hybrid approaches that start with tracking array
indices at a 4-KiB page-level granularity, over to a finer-grained 64-
byte cache line granularity within a page, before finally leveraging
Nemesis’s instruction-granular interrupt timing differences to infer
comparisons within a cache line.
4 IMPLEMENTATION ASPECTS