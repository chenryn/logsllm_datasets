[ 427 ]
Auditing Security Policy with OpenSCAP Chapter 15
As you can clearly see, if you need to run an interactive and immediate scan of a system,
SCAP Workbench is the easiest way to do it. The only limitation is that it can only process
XCCDF files, so the OVAL files used to establish whether you have package vulnerabilities
cannot be used here.
Throughout this section, we have explored ways that you can use the various OpenSCAP
tools to scan your infrastructure. We have also shown a variety of scans, and their output is
generally quite easy to interpret. However, in the next section, we will explore these in a
little more depth before we complete our work on OpenSCAP.
Interpreting results
So far, we have seen that the OpenSCAP scans, especially the XCCDF-based ones, produce
nice, easy-to-read reports that you can easily take action on. However, if the reports are not
clear to you, then you would not know what needs fixing to rectify the lack of compliance.
Fortunately, both the OVAL policies we used earlier to check for vulnerable packages and
the XCCDF-based reports contain enough information for you to do both things.
Let's take an example from our earlier scan of our CentOS 7 server using the SSG version
0.1.47. In this, we failed, among other things, a check called Disable ntpdate Service
(ntpdate). Suppose that this result was not obvious to you, and you were unsure what
the underlying problem was or why it was an issue. Fortunately, in the HTML report
generated from this scan, you can click on the check title. A screen should pop up that looks
like the one in the following screenshot:
[ 428 ]
Auditing Security Policy with OpenSCAP Chapter 15
Here, you can see all the detail you could ever need—from the details of the scan through
to the references and identifiers from the various security standards that make this
recommendation, and even the manual commands that could be used to rectify the issue so
that the system becomes compliant for the next scan.
[ 429 ]
Auditing Security Policy with OpenSCAP Chapter 15
Even better, if you scroll down this screen, you will find that many of the latest versions of
the SSG (version 0.1.47 included) actually include a great deal of Ansible code that can be
applied to remedy this situation, as shown in the following screenshot:
[ 430 ]
Auditing Security Policy with OpenSCAP Chapter 15
Hence, through a little exploration, you really can use these scan results not only to find out
why your infrastructure is not compliant but to also produce the exact set of fixes you
require.
OpenSCAP can also remediate (that is, fix) problems that it finds while
scanning to help you to both audit and maintain compliance. However,
we have not explored this here because it is vital that you understand the
scans and what they will do before attempting automatic remediation.
Hence, this is left as an exercise for you—however, you will see that in
both the OpenSCAP Daemon and SCAP Workbench, there is a simple
option you can enable that will not just perform the scan but attempt
remediation.
While we have established how powerful and user-friendly the XCCDF profiles are, we
have seen that reports generated by OVAL profiles are a little less readable. Fortunately, if
you refer to the following screenshot, you will notice that the CVE numbers for the
identified vulnerabilities are, in fact, hyperlinks:
Clicking on these will take you to the operating system vendor's website, directly to a page
that details the vulnerability, the affected package(s), and when the fix was implemented.
As a result, you can find out exactly which packages you need to update to remedy the
situation.
That concludes our look at auditing your Linux environment with OpenSCAP—it is hoped
that you have found this useful and that you will be able to apply this to your environment
for the benefit of your security and auditing processes.
[ 431 ]
Auditing Security Policy with OpenSCAP Chapter 15
Summary
Keeping an eye on the security compliance of your Linux infrastructure is ever more
important, and given the large number of security recommendations, coupled with the
large number of Linux servers that might exist in a modern enterprise, it is clear that a tool
that can audit for compliance is needed. OpenSCAP provides exactly such a framework
and with a little care and attention (and application of the right security profiles) can easily
audit your entire Linux estate and provide you with valuable, easy to read and interpret
reports of your compliance levels.
In this chapter, you gained hands-on experience of installing OpenSCAP tools for server
audit and understood the available policies and how to make effective use of them in
OpenSCAP. You then learned how to audit your Linux servers with the various OpenSCAP
tools, and finally explored how to interpret the scan reports to take appropriate action.
In the next and final chapter of this book, we will look at some tips and tricks to make your
automation tasks easier.
Questions
1. What does SCAP stand for?
2. Why are SCAP policies a valuable tool in auditing your Linux infrastructure?
3. Which OpenSCAP tool would you use to centrally perform scanning of several
Linux hosts regularly?
4. What is the difference between an XCCDF file and an OVAL file?
5. When would you use the vendor-supplied SSG policies, even if they are older
than the currently available ones?
6. Why might the scan results for a CentOS 7 host show notapplicable when
using a RHEL 7 policy file?
7. Can you generate an HTML report from the XML results generated by the
OpenSCAP Daemon?
8. What are the requirements for a remote SSH scan to be performed by SCAP
Workbench or the OpenSCAP Daemon?
[ 432 ]
Auditing Security Policy with OpenSCAP Chapter 15
Further reading
Learn Ansible by Russ McKendrick: https:/​/​www.​packtpub.​com/​gb/
virtualization-​and-​cloud/​learn-​ansible
OpenSCAP website: https:/​/​www.​open-​scap.​org/​
[ 433 ]
16
Tips and Tricks
It is hoped that, by now, this book has given you a sense of how you can automate your
Enterprise Linux environment and the requirements for standardization that enable tasks to
be performed efficiently at large scale. However, we have kept the example code very
simple throughout this book and for good reason—it is not fair to assume that every reader
will have a network with hundreds or even thousands of Linux machines to test these
examples against.
Hence, this concluding chapter of this book is written to provide you with some important
tips and tricks that will help you to better understand how to scale the examples in this
book up to enterprise scale and how to do this in a manner that will not simply move you
management headaches from one part of your infrastructure to another. Automation of
your Linux environment should not in itself become a headache that you need to solve, and
it is important to take several factors into account early on to prevent this. This chapter
explores some of the most important facets of Ansible automation you should consider to
ensure your automation journey is as smooth as possible.
The following topics will be covered in this chapter:
Version control for your scripts
Inventories – maintaining a single source of truth
Handling one-off tasks
Technical requirements
This chapter includes examples based on the following technologies:
Ubuntu Server 18.04 LTS
CentOS 7.6
Ansible 2.8
Tips and Tricks Chapter 16
To run through these examples, you will need access to two servers or virtual machines
running one each of the operating systems listed previously and Ansible.
All example code discussed in this book is available from GitHub at: https:/​/​github.​com/
PacktPublishing/​Hands-​On-​Enterprise-​Automation-​on-​Linux.
Version control for your scripts
Throughout this book, we have focused heavily on creating standardized ways of doing
things, whether that be how you build your Linux operating system images for
deployment, how you manage configuration files and databases, or even how you patch
your infrastructure. This was done for many good reasons, all of which we discussed in
Chapter 1, Building a Standard Operating Environment on Linux, including minimizing your
staff training requirements and ensuring you get consistent results from your automation
tasks.
What is also vital to consider is ensuring your Ansible playbooks themselves (and indeed,
any other scripts you might rely on) are standardized and uniform across your enterprise.
Imagine if everyone just had Ansible installed on their laptop or management station, along
with a set of playbooks for management tasks. How quickly would things get out of hand if
one person decided a tweak was needed to a playbook and didn't distribute it to everyone
else? Equally, how would you know what was run previously if the previous version of a
playbook did not exist—after all, Ansible code is supposed to be self-documenting, but this
value is lost if the previous versions are deleted.
In short, just as we proposed building standardized Linux images in Chapter 5, Using
Ansible to Build Virtual Machine Templates for Deployment, and Chapter 6, Custom Builds with
PXE Booting, so too should your Ansible playbooks be standardized across your enterprise.
The best way to achieve this will be to use version control for this purpose. Most enterprises
will already have a version control system already in place. This might take the form of a
corporate account on https:/​/​github.​com/​, an internal deployment of what was
previously known as Microsoft Team Foundation Server (now Azure DevOps Server), or
one of the many open source self-hosted Git options such as GitLab or Gitea. You may even
be on a system that is not Git-based such as Subversion or Mercurial—the choice is not
really important (although if you can make use of Git, Subversion, or Mercurial, this is to
your advantage as we shall see in a minute).
[ 435 ]
Tips and Tricks Chapter 16
Whatever your version control platform, it is important that you not only make effective
use of it for storing and maintaining a history of your Ansible playbooks; it is also vital that
you use your chosen tool effectively in the context of your enterprise. Take for example Git
(whichever system you choose to manage your repository). If your users modify the same
file at the same time, how do you handle that? Who's changes will take precedence? There
are good practices around the use of Git in the context of teams and enterprises, and it is
highly advisable that individuals make use of branches when they are working on code,
then use a pull request to merge their changes back into the source tree.
Effective use of Git in an enterprise setting is a large topic that could take up an entire
chapter on its own—if you are not familiar with this, then I advise you refer to the
resources in the Further reading section of this chapter for guidance on how to make the best
use of your version control system.
For the remainder of this section, we will assume the version control
system you are using is Git as this will make the examples easier to read.
If you are using another system such as Subversion or Mercurial, replace
the Git-specific commands to check out code, commit updates, and so on
with your own.
Once you have decided upon your version control system, it is time to put it into day-to-
day usage. To ensure this happens, you must consider how you are going to integrate
Ansible with your version control system, and we will take a look at exactly that in the next
section.
Integrating Ansible with Git
Before we proceed any further, we must point out that the title of this section is an
oxymoron as Ansible itself does not integrate with Git. Specifically, Ansible playbooks and
roles are stored in Git, to be checked out locally on the host that will execute them. It does
have modules such as git and git_config, which allow you to write playbooks that
deploy code from a Git repository, but the ansible-playbook command does not support
running a playbook from anything other than the local filesystem.
[ 436 ]
Tips and Tricks Chapter 16
We will make use of the publicly available ansible-examples repository on github.com
for these next few examples as they are publicly available to you for testing. Hypothetically
speaking, suppose that you wanted to run the playbook for installing WordPress on RHEL
7 in your enterprise from this repository. Your process to perform this would (assuming
you have already defined your Ansible inventory) look something like the following
example:
$ git clone https://github.com/ansible/ansible-examples.git
$ cd ansible-examples/wordpress-nginx_rhel7/
$ ansible-playbook site.yml
The preceding three commands ensure that you clone the very latest playbook from this Git
repository, and the output will look a little something like the following screenshot (the
deprecation warning shows that this playbook needs updating for more recent versions of
Ansible):
Once checked out, the playbooks can always be updated to the latest version from the Git
server (assuming there are no local changes that need to be committed):
$ git pull
[ 437 ]
Tips and Tricks Chapter 16
Following a successful update of the local working copy of your playbooks, the latest
version of the playbook can be run. This is a fairly painless process, and requiring engineers
or admins to run the git pull command before running a playbook is not too arduous a
task.
Sadly, though, this process does not really help to enforce good practices in the enterprise.
It would be very easy for someone to forget to run the git pull command before running
a playbook. Equally, there is nothing to stop administrators and engineers amassing their
own playbooks and failing to share them. This is definitely a step forward, but it is by no
means the full solution.
A far more robust option is to enforce the use of a tool such as AWX or Ansible Tower.
These, as we saw in Chapter 3, Streamlining Infrastructure Management with AWX, enable
the enforcement of good processes by ensuring that playbook runs can only be executed
against playbooks pulled down from a version control system. If administrators are not
given access to the filesystem of the AWX server, then it will not be possible to run
arbitrary playbooks that they have knocked up themselves and they must instead pull them
in from a version control source.
In Creating a project in AWX section of Chapter 3, Streamlining Infrastructure Management
with AWX, we looked at creating a project that would actually make use of the ansible-
examples repository we looked at earlier. This, of course, begs the question, how do you
organize your playbooks within a version control system effectively? We will look at
precisely this in the next section.
Organizing your version control repositories
effectively
It is all very well stating that Ansible playbooks should be cloned from a version control
system and cloned to the systems from which they are to be run (be that from the command
line or AWX), but how do you actually organize these effectively so that you can find your
code when you need it?
A clue comes to us from the user interface of the AWX tool, which refers to each version
control repository you might reference as Project. As you build up your automation
processes and solution, you could end up with many playbooks, possibly into the
hundreds, depending on the size of your enterprise.
[ 438 ]
Tips and Tricks Chapter 16
You can, of course, store all of these within the same repository. The ansible-examples
repository is a good (albeit smaller) example of this—it contains a variety of playbooks for
different purposes, each within its own directory. There are even Windows-specific
playbooks that live under a Windows subdirectory. The directory structure is relatively
easy to navigate for you to find playbook that you want, but you will note that all of the
code contained within it are examples for people to learn Ansible with.
If you worked for an online retailer, for example, it would not be logical to put the
playbooks for building the standardized Linux images into the same repository as the ones
for deploying your stock control system. This would be counter-intuitive and would lead to
confusion, especially when people are looking for a particular playbook.
Naturally, the decision comes down to you at the end of the day—only you can decide on
the structure that will suit your enterprise best. However, the division of repositories by
project is a good starting point for anyone looking for a sound starting point to build on.
There will always be gray areas too – for example, in Chapter 12, Performing Routine
Maintenance with Ansible, we advocated building Ansible playbooks for performing
frequent housekeeping tasks such as cleaning up disk space. Now, suppose you have a
playbook that cleans up a directory structure, but that it is specific to the stock control
system we mentioned earlier— does that go in the stock control repository or the general
maintenance repository?
Again, the choice is yours—but the stock control cleanup playbook will not run properly
(and might even be dangerous) on systems that do not run the stock control system, so I
would advocate making it a sub-directory within the stock control repository.
So far, we are building up a picture of how you would effectively and efficiently store your
playbooks, yet we must remember that, throughout this book, we have strongly advocated
the authoring of Ansible code as roles wherever possible, as roles can be reused in multiple
playbooks. None of the solutions we have discussed actually support role reuse (other than
manually copying the code between playbooks), even though we have established a sound
methodology for building up our directory structures and processes for running the
playbooks.
In the next section, we will look at the specific capabilities of Ansible when it comes to the
version control of roles.
[ 439 ]
Tips and Tricks Chapter 16
Version control of roles in Ansible
Role reuse is an important part of building an efficient, standardized system of playbooks
for administrators and engineers to apply. We have given many examples throughout this
book—for example, in Chapter 10, Managing Users on Linux—we proposed a simple role
that would add users to a Linux system. To save you referring back, the code is as follows:
---
- name: Add required users to Linux servers
user:
name: "{{ item.name }}"
comment: "{{ item.comment }}"
shell: /bin/bash
groups: "{{ item.groups }}"
append: yes
state: present
loop:
- { name: 'johndoe', comment: 'John Doe', groups: 'sudo'}
- { name: 'janedoe', comment: 'Jane Doe', groups: 'docker'}
Given our discussion about role reuse, I'm sure that you can see that the design of this role
could be improved. This role has hardcoded user accounts in it, which does not lend itself
to reuse at all. However, if the user accounts were specified via an Ansible variable, then
this role could be used in any playbook that needed to add a user account to a Linux
system. This moves us one step closer to our goal of creating standardized, reusable code.
However, we need to ensure that the code appears in every playbook that requires it.
Further, we must also ensure that the version is kept up to date—otherwise, if someone
makes an improvement to the code (or fixes a bug or adapts the code for a newer version of
Ansible because of some feature deprecation), this will only exist in the modified role—all
of the copies will be out of date. If the role is copied to any playbooks, it will become
difficult to ensure that they are kept up to date. To achieve this, we clearly need to start
storing our roles in our source control system, and in this case, we must store one role per
repository (the reasons for this will become apparent as we progress through the following
examples).
Once your roles are in your source control system, there are two ways to address the
problem of efficient and effective reuse. The first is to make use of Git submodules. This is a
Git-specific technology so will not suit you if you are using Subversion or Mercurial, but if