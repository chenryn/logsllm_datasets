title:Presence Attestation: The Missing Link in Dynamic Trust Bootstrapping
author:Zhangkai Zhang and
Xuhua Ding and
Gene Tsudik and
Jinhua Cui and
Zhoujun Li
Presence Attestation: The Missing Link in Dynamic Trust
Bootstrapping
Zhangkai Zhang∗
Beihang University
PI:EMAIL
Singapore Management University
University of California, Irvine
Gene Tsudik
PI:EMAIL
Xuhua Ding
PI:EMAIL
Jinhua Cui
Singapore Management University
PI:EMAIL
ABSTRACT
Many popular modern processors include an important hardware
security feature in the form of a DRTM (Dynamic Root of Trust
for Measurement) that helps bootstrap trust and resists software
attacks. However, despite substantial body of prior research on trust
establishment, security of DRTM was treated without involvement
of the human user, who represents a vital missing link. The basic
challenge is: how can a human user determine whether an expected
DRTM is currently active on her device?
In this paper, we define the notion of “presence attestation”,
which is based on mandatory, though minimal, user participation.
We present three concrete presence attestation schemes: sight-
based, location-based and scene-based. They vary in terms of secu-
rity and usability features, and are suitable for different application
contexts. After analyzing their security, we assess their usability
and performance based on prototype implementations.
KEYWORDS
trusted computing, attestation, dynamic root of trust, human-in-
the-loop, device I/O
1 INTRODUCTION
Many currently popular x86 and ARM processors are equipped
with a special hardware feature, called Dynamic Root of Trust for
Measurement (DRTM), e.g., Intel TXT [12], AMD SVM [2], and ARM
TrustZone1 [3]. DRTM is designed to withstand software attacks,
even from the operating system level. When activated at runtime, it
securely measures and launches some software which may further
measure and load another layer of software. Such iterations of
measure-then-launch form a trust chain rooted in DRTM allowing
∗The work was mainly done when the author visited SMU as a student intern.
1We slightly expand the notion of DRTM as TrustZone functions differently from the
TXT and SVM.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior specific permission and/or a
fee. Request permissions from permissions@acm.org.
CCS’17, , Oct. 30–Nov. 3, 2017, Dallas, TX, USA.
© 2017 Association for Computing Machinery.
ACM ISBN ISBN 978-1-4503-4946-8/17/10...$15.00
https://doi.org/10.1145/3133956.3134094
Zhoujun Li
Beihang University
PI:EMAIL
a remote entity (verifier) to establish trust in the system, after
checking integrity of the latter’s software stack.
Popularity of DRTM has also fueled some new directions in
system security research. Several designs [4, 5, 19, 32, 33] have been
proposed to cope with OS-level threats directly by using various
DRTM instantiations to ensure security of the Trusted Computing
Base (TCB).
However, most prior efforts either overlooked or side-stepped an
important factor – the human user. As noted by Parno et al. [23], it
is challenging for a human user to “bootstrap trust” in DRTM itself,
since she is not assured that the chain of trust is indeed rooted in
her DRTM. The main reason is the difficulty for a human user to
establish an authenticated and secure channel with her own DRTM.
Although DRTM is trusted, the user cannot determine whether her
DRTM is indeed engaged. In particular, malware can impersonate
the user’s DRTM using a so-called “cuckoo attack” [23].
Two mitigation approaches are proposed and discussed in [23].
The first relies on a hardware-based secure channel, e.g., a special-
purpose I/O interface through which an external verification device
directly interacts with DRTM. The second establishes a crypto-
graphically secured communication channel and requires the user
to have prior knowledge of the public key identifier of her DRTM.
The former offers stronger security and better usability. For
example, an LED light securely wired to TrustZone can confirm
to the user that her DRTM is active. Most COTS x86 and ARM
devices are not equipped with such a feature and implementing it
would require cooperation of hardware manufacturers. The latter
approach also requires manufacturers’ cooperation (though to a
lesser extent) in order to export the DRTM’s public key identifier
to the user via either: (1) an out-of-band channel, e.g., etched or
printed on the exterior of the device itself, or (2) a special protected
interface. In any case, dealing with DRTM’s public key identifier
represents added burden for the user.
We observe that a user’s trust in her device is based not only
on physical availability of DRTM. Rather, to a greater extent, it is
based on availability and security of software directly measured and
loaded by DRTM, which constitutes the TCB of the user’s device.
For ease of presentation, we refer to the initial software in the trust
chain following DRTM as the trust anchor.
In this paper, we use the divide-and-conquer approach to boot-
strapping user’s trust in her own device, without imposing afore-
mentioned burden on manufacturers and users:
(1) The user checks whether a genuine DRTM has launched the
trust anchor and is currently interacting with her.2
(2) The user verifies whether the trust anchor launched in the
preceding step actually resides on her own device.
The second step is cryptographically bound to the first by an
ephemeral secret key. Also, the implicit logical link between the
two steps is based on trust anchor’s runtime security being ensured
by DRTM. We argue that this is a widely adopted trust assump-
tion in many DRTM-based secure systems. If DRTM cannot ensure
runtime security of the trust anchor, i.e., the very first software
in the chain, its measurements are of little value since they only
momentarily reflect static software integrity3.
Based on the general approach outlined above, we design and
implement three presence attestation schemes. By taking advantage
of hardware DRTM’s security assurance and software capability
of the trust anchor, these schemes allow a human user to establish
trust in her device after confirming that DRTM and the trust anchor
are active. Proposed schemes are based on different physical prop-
erties: sight, scene and location. The sight-based scheme achieves
strongest security since it resists analog cuckoo attacks, while the
other two offer better usability commensurate with slightly weaker
security. We implement all three protocols and assess their security
and performance.
Organization. The next section describes the system setting as
well as the adversary model, and overviews the proposed approach.
Section 3 details the sight-based attestation scheme, followed by
location-based and scene-based variants in Section 4. Implementa-
tion details are presented in Section 5 and experimental results are
reported in Section 6. Section 7 discusses related work and Section 8
concludes the paper.
2 SYNOPSIS
This section sets the stage for the rest of the paper by describing the
assumed environment, (including the devices and the adversary)
and overviewing the notion of presence attestation.
2.1 System Model & Problem Definition
We consider the following system model widely used in the litera-
ture. A human user (Alice) physically controls a computing device
Dev equipped with a hardware DRTM denoted as ROTD instanti-
ation of which is dependent on Dev’s platform architecture. For
example, if Dev is a smartphone with an ARM processor, ROTD is
the processor’s TrustZone component, including code running in it.
At runtime, ROTD loads a trust anchor denoted by TA. For exam-
ple, TA could be a bare-metal micro-hypervisor launched on Dev in
order to protect a security-sensitive application. Figure 1 shows the
chain of the actions leading to application-level security by tapping
into the strong security assurance provided by the built-in DRTM.
The chain of actions is also the chain of trust propagation. Trust
is bootstrapped from ROTD, followed by TA and then, the secured
application, in the sense that another device can verify the trust
chain and establish trust in Dev. Unfortunately, Alice cannot es-
tablish trust on any of them. Note that the system is not trusted
2The main goal here is to ascertain whether any DRTM is involved in the interaction,
not necessarily the one on the user’s device.
3For the same reason DRTM is not used in the literature to directly launch the OS,
which is vulnerable to runtime attacks.
Fig. 1: Trust bootstrapping expected by Alice: TA corresponds to the
first software component in the trust chain rooted at ROTD.
prior to the launch of ROTD. Malware residing on Dev can pretend
to launch ROTD and produce user-perceptible effects (e.g., audio,
visual, etc.) identical to the real ROTD. In other words, Alice cannot
reliably determine whether trust is indeed bootstrapped in Dev.
The problem at hand is how to help Alice to securely verify
whether ROTD is currently active on Dev. Since she physically con-
trols Dev, Alice is certain that ROTD is installed on Dev. Nonethe-
less, she cannot determine ROTD’s status at runtime, due to lack of
an authentic and secure channel between herself and her DRTM.
Even worse, current DRTM manufacturers do not offer a way for
Alice to identify DRTM on her device. Alice may not even know
anything about ROTD’s public key certificate issued by the manu-
facturer.
Assumptions. We assume that each DRTM is secure against soft-
ware attacks; this is, in fact, one of the main design goals of DRTM.
Albeit, actual DRTM products are not assumed to be free of vulner-
abilities. We assume that there exists a public key infrastructure
(PKI), with each DRTM assigned a unique public/private key-pair
and a credential, i.e., a public key certificate (PKC). Each DRTM
can produce cryptographic evidence (e.g., in the form of a signa-
ture) to authenticate itself and thus prove its genuineness, by using
its private key which is securely stored along with a credential.
Nonetheless, as mentioned earlier, Alice is not assumed to have any
prior knowledge of ROTD’s public key.
We also assume that the trust anchor launched by the DRTM
is secure against kernel-level attacks, since hardware places the
trust anchor in a more privileged environment than the OS. Other
software components that follow the trust anchor in the chain are
not relevant to our work.
2.2 Portrait of The Adversary
The anticipated embodiment of the adversary is malware running
on Dev with kernel privileges. This malware controls all software
and hardware resources accessible to the OS (except the TCBs
which DRTM depends on). We parameterize the adversary with
two aspects: (1) collusion with external entities, and (2) capability
of using analog devices.
Local vs. Collusive. A local adversary is represented by stand-
alone malware running on Dev with no runtime collusion with
other devices. Although it might have the ability to communicate,
it is not assisted by any external entity.
A collusive adversary consists of malware resident on Dev and
a remote accomplice residing on at least one other device denoted
by M, equipped with its own DRTM denoted by ROTM. (We assume
that M is a genuine device, of the same type as Dev, that has not
been physically attacked; specifically, ROTM is inviolate.) The local
and remote adversarial components interact over a network. They
might be physically near each other and communicate directly, e.g.,
ROTDTADsecured	appDevanalog	channelAlicevia Bluetooth. Alternatively, they can be far apart and communicate
over a Wi-Fi or cellular interface. The adversary does not use a
wired connection, since Alice can easily unplug all cables connected
to Dev prior to attestation. Also, although Alice can, in principle,
muffle or jam all Dev’s wireless communications, doing so requires
additional specialized equipment.
A collusive adversary can mount a cuckoo attack (see Figure 2)
described by Parno, et al. [23] which defeats TPM-based attesta-
tion. It is a special form of the man-in-the-middle (MITM) attack,
whereby Dev forwards the attestation challenge to an accomplice
device which then produces a valid response. The cuckoo attack
is based on verifier’s inability to determine the exact hardware
origin of the attestation response. This stems from the fact that
the communication channel between the verifier and Dev is not
authenticated. It is also not perceivable by the human user.
Fig. 2: Cuckoo attack example [23]. ROTD in Dev is not active. Mal-
ware in Dev uses ROTM in an accomplice device to produce a legit-
imate attestation response to the verifier which intends to assess
Dev’s trustworthiness.
Software-only vs. Analog. We also consider whether the adver-
sary’s reach extends into the physical (analog) world. A software-
only adversary does not use anything beyond software, i.e., its
attacks are performed entirely by malware. Such an adversary can-
not eavesdrop on (or influence) analog signals emitted from any
device.
An analog adversary exploits the physical environment and
uses additional equipment to eavesdrop on, intercept, transmit, or
modify analog data. Since Dev is physically controlled by Alice,
an analog adversary must be a collusive one. The analog attack is
conducted on the remote accomplice’s side. A concrete example
of an accomplice might be a screen that displays photos or videos
transmitted by malware in Dev.
Caveat. We do not consider physical attacks that modify any
hardware behavior or physically extract secrets (by brute force
or via side-channels) from a DRTM. Such attacks fundamentally
undermine DRTM security and are beyond the scope of this paper.
2.3 Overview of Presence Attestation
To bootstrap Alice’s trust in her device Dev, we propose an attes-
tation scheme to verify presence of an active ROTD on Dev. We
assume that, during attestation, Alice is assisted by a trusted com-
puter, denoted as Verifier.4 Verifier engages Dev over a digital or
analog channel to verify ROTD’s presence. We believe that Ver-
ifier is a necessary component since Alice can neither securely
communicate with ROTD nor perform necessary computations.
Strawman Approach: Before describing the proposed scheme,
we consider an intuitive “strawman” approach and show how it
4In a typical setting, we expect that Dev would be Alice’s smartphone or similar-class
device and Verifier – Alice’s laptop or desktop.
fails, which highlights the subtlety of the problem at hand. The
strawman approach is simple: