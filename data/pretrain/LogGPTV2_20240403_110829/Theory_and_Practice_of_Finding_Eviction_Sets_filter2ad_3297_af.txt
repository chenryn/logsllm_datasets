### Optimized Text

**Dynamic Re-reference Interval Prediction (DRRIP) [10] and other advanced cache replacement policies are known to outperform Pseudo-LRU (PLRU) in workloads that cause scanning or thrashing. However, these policies can make eviction less reliable and fall outside the scope of our current models (see Section III). Howg [11] proposes a dual pointer chasing mechanism to mitigate these effects. Gruss et al. [6] generalize this approach with eviction strategies, which are access patterns over eviction sets that increase the likelihood of eviction under unknown modern policies. Both approaches assume the possession of eviction sets, making them orthogonal to our work.**

**Recent research has proposed new designs for randomized caches [34], [35], where cache sets are indexed using a keyed function, thereby eliminating any attacker control over the physical address bits. A key result of these proposals is that they make cache-based attacks, particularly the discovery of small eviction sets, more challenging. Their security analysis, however, considers quadratic attackers; it will be interesting to see how our linear-time algorithm affects their findings.**

### VIII. Conclusion

**Finding small eviction sets is a fundamental step in many microarchitectural attacks. In this paper, we present the first study of finding eviction sets as an algorithmic problem. Our core theoretical contribution is the development of novel algorithms that enable computing eviction sets in linear time, improving upon the quadratic state-of-the-art. Our practical contribution includes a rigorous empirical evaluation that identifies and isolates factors affecting the reliability of these algorithms, such as adaptive replacement strategies and TLB thrashing.**

**Our results demonstrate that our algorithms significantly reduce the time required to find small eviction sets, enabling attacks in scenarios previously considered impractical. Additionally, our work highlights conditions under which the algorithms fail, providing a foundation for future research on principled countermeasures.**

### Acknowledgments

**We thank Trent Jaeger, Pierre Ganty, and the anonymous reviewers for their valuable feedback. This work was supported by a grant from Intel Corporation, Ramón y Cajal grant RYC-2014-16766, Spanish projects TIN2015-70713-R DEDETIS and TIN2015-67522-C3-1-R TRACES, and Madrid regional project S2013/ICE-2731 N-GREENS.**

### References

[References remain unchanged]

### Appendix

#### A. Huge Pages

**Modern operating systems support large buffers of virtual memory, typically 2MB or 1GB, mapped into contiguous physical chunks called huge pages. These large pages improve performance by reducing page walks when accessing arrays larger than 4KB. However, they also increase the risk of memory fragmentation, potentially leading to wasted resources.**

**On Linux systems, huge pages can be requested explicitly or implicitly:**

- **Explicit requests** are made by passing special flags to the allocation routine (e.g., `MAP_HUGETLB` to the `mmap` function). The OS pre-allocates a pool of physical huge pages of configurable size (default is 0 in most systems).
- **Implicit requests** are referred to as transparent huge pages (THPs). THPs are managed by a kernel thread that periodically searches for contiguous 4KB virtual pages that can be remapped into a free 2MB chunk of contiguous physical memory. THP can be configured as:
  - **always**: all memory allocations can be remapped.
  - **never**: THP is disabled.
  - **madvise**: the programmer signals a preference for remapping via specific flags (not guaranteed).

**Other systems implement huge pages differently but generally follow similar principles. For example, BSD refers to them as super pages, and Windows calls them large pages.**

**Interestingly, memory allocations in modern browsers are not backed by huge pages unless the system is configured with THP set to always. Therefore, relying on huge pages for finding eviction sets is not feasible in most default systems.**

#### B. Proof of Proposition 2

**In the worst case, we access \(a + 1\) different \(a\)-subsets of size \(\binom{n}{a}\), and safely discard \(n - \binom{a+1}{a}\) elements that are not part of the minimal eviction set. We express recurrence (2) as a summation:**

\[ T(n) = an + an \left( \frac{a + 1}{a} \right) \]

**Our termination condition is \( n \left( \frac{a + 1}{a} \right)^k \leq a \). Assume for contradiction that for all \(i \in \{1, \ldots, a + 1\}\), \( |(S \setminus T_i) \cap P| \leq a \).**

#### D. Intel’s TLBs

**Modern CPUs have distinct TLB implementations. Specifically, modern Intel CPUs use separate buffers for data (dTLB) and instructions (iTLB), a second-level TLB (sTLB) with larger capacity, and different TLBs for each page table level.**

**Table II summarizes TLB parameters for Haswell and Skylake families:**

| TLB Type          | Haswell             | Skylake             |
|-------------------|---------------------|---------------------|
| iTLB 4K           | 128 entries; 4-way  | 128 entries; 8-way  |
| iTLB 2M/4M        | 8 entries; full     | 8 entries; full     |
| dTLB 4K           | 64 entries; full    | 64 entries; 4-way   |
| dTLB 2M/4M        | 32 entries; 4-way   | 32 entries; 4-way   |
| dTLB 1G           | 4 entries; 4-way    | 4 entries; full     |
| sTLB 4K/2M        | 1536 entries; 4-way | 1024 entries; 8-way |
| sTLB 1G           | -                   | 16 entries; 4-way   |

**Table II: TLB implementation information for Haswell and Skylake microarchitectures. Extracted from the Intel’s Architectures Optimization Manual [29].**

---

This optimized text is now more coherent, clear, and professionally formatted.