DRRIP [10], are known to perform better than PLRU against
workloads causing scanning or thrashing. However, they also
make eviction less reliable, and fall outside our current models
(see Section III). Howg [11] proposes a dual pointer chasing
6According to Intel’s Architecture Reference Manual [29] (see 2.4.5.3 Ring
Interconnect and Last Level Cache), Sandy Bridge is the ﬁrst generation with
slicing.
(cid:22)(cid:19)
Set
to mitigate these effects; and Gruss et al. [6] generalize the ap-
proach with eviction strategies, which are access patterns over
eviction sets that increase the chance of eviction under some
unknown modern policies. Both approaches are orthogonal to
our in that they already assume the possession of eviction sets.
index randomization: Concurrent work proposes
some new designs for randomized caches [34], [35], where
cache sets are indexed with a keyed function that completely
voids any attacker control over the physical address bits. A key
result of these proposals is that they make cache-based attacks,
and specially ﬁnding small eviction sets, more difﬁcult. Their
security analysis, however, considers quadratic attackers; it
will be interesting to see how it is affected by our linear-time
algorithm.
VIII. CONCLUSION
Finding small eviction sets is a fundamental step in many
microarchitectural attacks. In this paper we perform the ﬁrst
study of ﬁnding eviction sets as an algorithmic problem.
Our core theoretical contribution are novel algorithms that
enable computing eviction sets in linear time, improving over
the quadratic state-of-the-art. Our core practical contribution
is a rigorous empirical evaluation in which we identify and
isolate factors that affect their reliability in practice, such as
adaptive replacement strategies and TLB thrashing.
Our results demonstrate that our algorithms enable ﬁnding
small eviction sets much faster than before, enabling attacks
under scenarios that were previously deemed impractical.
They also exhibit conditions under which the algorithms fail,
providing a basis for research on principled countermeasures.
ACKNOWLEDGMENTS
We thank Trent Jaeger, Pierre Ganty, and the anonymous
reviewers for their helpful comments. This work was supported
by a grant from Intel Corporation, Ram´on y Cajal grant RYC-
2014-16766, Spanish projects TIN2015-70713-R DEDETIS
and TIN2015-67522-C3-1-R TRACES, and Madrid regional
project S2013/ICE-2731 N-GREENS.
REFERENCES
[1] Y. Yarom and K. Falkner, “FLUSH+RELOAD: A High Resolution,
Low Noise, L3 Cache Side-Channel Attack,” in 23rd USENIX Security
Symposium (USENIX Security 14), (San Diego, CA), pp. 719–732,
USENIX Association, 2014.
[2] M. Seaborn and T. Dullien, “Exploiting the DRAM rowhammer bug to
gain kernel privileges,” in Black Hat, 2015.
[3] P. Kocher, J. Horn, A. Fogh, D. Genkin, D. Gruss, W. Haas, M. Ham-
burg, M. Lipp, S. Mangard, T. Prescher, M. Schwarz, and Y. Yarom,
“Spectre attacks: Exploiting speculative execution,” in IEEE Symposium
on Security and Privacy (SP), 2019.
[4] F. Liu, Y. Yarom, Q. Ge, G. Heiser, and R. B. Lee, “Last-Level Cache
Side-Channel Attacks Are Practical,” in Proceedings of the 2015 IEEE
Symposium on Security and Privacy, SP ’15, (Washington, DC, USA),
pp. 605–622, IEEE Computer Society, 2015.
[5] G. Irazoqui, T. Eisenbarth, and B. Sunar, “S$A: A Shared Cache
Attack That Works Across Cores and Deﬁes VM Sandboxing – and
Its Application to AES,” in Proceedings of the 2015 IEEE Symposium
on Security and Privacy, SP ’15, (Washington, DC, USA), pp. 591–604,
IEEE Computer Society, 2015.
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:41:36 UTC from IEEE Xplore.  Restrictions apply. 
[6] Daniel Gruss and Cl´ementine Maurice and Stefan Mangard, “Rowham-
mer.js: A Remote Software-Induced Fault Attack in JavaScript,” in
DIMVA, Springer, 2016.
[7] D. G. Michael Schwarz, Moritz Lipp, “JavaScript Zero: Real JavaScript
and Zero Side-Channel Attacks,” in Network and Distributed System
Security Symposium 2018 (NDSS’18), 2018.
[8] P. Damaschke, Threshold Group Testing, pp. 707–718. Springer Berlin
Heidelberg, 2006.
[9] Y. Oren, V. P. Kemerlis, S. Sethumadhavan, and A. D. Keromytis, “The
Spy in the Sandbox: Practical Cache Attacks in JavaScript and Their
Implications,” in CCS, ACM, 2015.
[10] A. Jaleel, K. B. Theobald, S. C. Steely, Jr., and J. Emer, “High
Performance Cache Replacement Using Re-reference Interval Prediction
(RRIP),” SIGARCH Comput. Archit. News, vol. 38, pp. 60–71, June
2010.
[11] H. Wong, “Intel Ivy Bridge Cache Replacement Policy,” January 2013.
[12] A. Abel and J. Reineke, “Reverse engineering of cache replacement poli-
cies in intel microprocessors and their evaluation,” in IEEE International
Symposium on Performance Analysis of Systems, 2014.
[13] J.
Horn,
“Reading
privileged
side-
https://googleprojectzero.blogspot.com.es/2018/01/
memory
with
a
channel.”
reading-privileged-memory-with-side.html, 2018.
[14] E. Bosman, K. Razavi, H. Bos, and C. Giuffrida, “Dedup Est Machina:
Memory Deduplication as an Advanced Exploitation Vector,” in IEEE
Symposium on Security and Privacy, SP 2016, San Jose, CA, USA, May
22-26, 2016, pp. 987–1004, 2016.
[15] B. Levin, “A representation for multinomial cumulative distribution
functions,” The Annals of Statistics, pp. 1123–1126, 1981.
[16] R. Dorfman, “The detection of defective members of large populations,”
The Annals of Mathematical Statistics, vol. 14, no. 4, pp. 436–440, 1943.
[17] T. H. Cormen, C. E. Leiserson, R. L. Rivest, and C. Stein, “Introduction
to algorithms,” Growth, vol. 5, no. A8, p. B1, 1989.
[18] D. Genkin, L. Pachmanov, E. Tromer, and Y. Yarom, “Drive-by key-
extraction cache attacks from portable code.” Cryptology ePrint Archive,
Report 2018/119, 2018. https://eprint.iacr.org/2018/119.
[19] C. Maurice, N. Le Scouarnec, C. Neumann, O. Heen, and A. Francil-
lon, “Reverse Engineering Intel Last-Level Cache Complex Addressing
Using Performance Counters,” in Proceedings of the 18th International
Symposium on Research in Attacks, Intrusions and Defenses (RAID’15),
November 2015.
[20] C. Maurice, M. Weber, M. Schwarz, L. Giner, D. Gruss, C. Al-
berto Boano, S. Mangard, and K. Rmer, “Hello from the Other Side:
SSH over Robust Cache Covert Channels in the Cloud,” in Proceedings
of the 24th Annual Network and Distributed System Security Symposium,
NDSS, The Internet Society, February 2017.
[21] M. K. Qureshi, D. N. Lynch, O. Mutlu, and Y. N. Patt, “A Case for MLP-
Aware Cache Replacement,” SIGARCH Comput. Archit. News, vol. 34,
pp. 167–178, May 2006.
[22] S. Cai, M. Jahangoshahi, M. Bakshi, and S. Jaggi, “Efﬁcient algorithms
for noisy group testing,” IEEE Transactions on Information Theory,
vol. 63, pp. 2113–2136, April 2017.
[23] D. Gruss, R. Spreitzer, and S. Mangard, “Cache template attacks: Au-
tomating attacks on inclusive last-level caches,” in 24th USENIX Security
Symposium (USENIX Security 15), (Washington, D.C.), pp. 897–912,
USENIX Association, 2015.
[24] Y. Kim, R. Daly, J. Kim, C. Fallin, J. H. Lee, D. Lee, C. Wilkerson,
K. Lai, and O. Mutlu, “Flipping Bits in Memory Without Accessing
Them: An Experimental Study of DRAM Disturbance Errors,” in
Proceeding of the 41st Annual International Symposium on Computer
Architecuture, ISCA ’14, pp. 361–372, IEEE Press, 2014.
[25] M. Oliverio, K. Razavi, H. Bos, and C. Giuffrida, “Secure Page Fusion
with VUsion,” in Proceedings of the 26th Symposium on Operating
Systems Principles, Shanghai, China, October 28-31, 2017, pp. 531–
545, 2017.
[26] M. Lipp, M. Schwarz, D. Gruss, T. Prescher, W. Haas, S. Mangard,
P. Kocher, D. Genkin, Y. Yarom, and M. Hamburg, “Meltdown,” CoRR,
vol. abs/1801.01207, 2018.
[27] M. Lipp, D. Gruss, R. Spreitzer, C. Maurice, and S. Mangard, “AR-
Mageddon: Cache Attacks on Mobile Devices,” in 25th USENIX Security
Symposium (USENIX Security 16), (Austin, TX), pp. 549–564, USENIX
Association, 2016.
[28] M. Schwarz, S. Weiser, D. Gruss, C. Maurice, and S. Mangard, Malware
Guard Extension: Using SGX to Conceal Cache Attacks, pp. 3–24.
Springer International Publishing, 2017.
[29] Intel, Intel 64 and IA-32 Architectures Optimization Reference Manual.
Intel, 2018.
[30] “L3 cache mapping on Sandy Bridge CPUs.” http://lackingrhoticity.
blogspot.com.es/2015/04/l3-cache-mapping-on-sandy-bridge-cpus.
html, 2015.
[31] R. Hund, C. Willems, and T. Holz, “Practical Timing Side Channel
Attacks Against Kernel Space ASLR,” in Proceedings of the 2013 IEEE
Symposium on Security and Privacy, SP ’13, (Washington, DC, USA),
pp. 191–205, IEEE Computer Society, 2013.
[32] G. I. Apecechea, T. Eisenbarth, and B. Sunar, “Systematic Reverse Engi-
neering of Cache Slice Selection in Intel Processors,” IACR Cryptology
ePrint Archive, vol. 2015, p. 690, 2015.
[33] M. K. Qureshi, A. Jaleel, Y. N. Patt, S. C. S. Jr., and J. S. Emer,
“Adaptive insertion policies for high performance caching,” in 34th
International Symposium on Computer Architecture (ISCA 2007), June
9-13, 2007, San Diego, California, USA, pp. 381–391, 2007.
[34] D. Trilla, C. Hern´andez, J. Abella, and F. J. Cazorla, “Cache side-
channel attacks and time-predictability in high-performance critical real-
time systems,” in Proceedings of the 55th Annual Design Automation
Conference, DAC 2018, San Francisco, CA, USA, June 24-29, 2018,
pp. 98:1–98:6, 2018.
[35] M. K. Qureshi, “CEASER: Mitigating Conﬂict-Based Cache Attacks
via Encrypted-Address and Remapping,” in IEEE/ACM International
Symposium on Microarchitecture - MICRO 2018, 2018.
[36] “The linux kernel archives: Transparent huge pages.” https://www.kernel.
org/doc/Documentation/vm/transhuge.txt, 2017.
A. Huge Pages
APPENDIX
Modern operating systems implement support for large
buffers of virtual memory to be mapped into contiguous
physical chunks of 2MB (or 1GB), instead that of regular
4KB. These large chunks are called huge pages. On one hand,
huge pages save page walks when traversing arrays of more
than 4KB, improving performance. On the other hand, they
increase the risk of memory fragmentation, what might lead
to wasting resources.
On Linux systems, huge pages can be demanded explicitly
or implicitly:
• Explicit requests are done by passing special ﬂags to the
allocation routine (e.g. ﬂag MAP_HUGETLB to the mmap
function). In order to satisfy these requests, the OS pre-
allocates a pool of physical huge pages of conﬁgurable
size (which by default is 0 in most systems).
• Implicit
requests are referred as
transparent huge
pages [36]. THPs are implement with a kernel thread
that, similarly to a garbage collector, periodically searches
for enough contiguous 4KB virtual pages that can be re-
mapped into a free 2MB chunk of contiguous physical
memory (reducing PTs size). THP can be conﬁgured as:
always, meaning that all memory allocations can be re-
mapped; never, for disabling it; and madvise, where
the programmer needs to signal preference for being re-
mapped via some ﬂags (note that this is not a guarantee).
On other systems huge pages are implement differently,
but
is generally the same. For instance, BSD’s
documentation refers to them as super pages, while Windows
calls them large pages.
the effect
Interestingly, memory allocations in modern browsers are
not backed by huge pages unless the system is conﬁgured
with THP set to always. Hence, relying on them for ﬁnding
eviction sets is not feasible in most default systems.
(cid:22)(cid:20)
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:41:36 UTC from IEEE Xplore.  Restrictions apply. 
B. Proof of Proposition 2
a
a+1 each, and safely discard n
In the worst case, we access a +1 different a-subsets groups
a+1 elements that are not
of size n
part of the minimal eviction set. We ﬁrst express recurrence (2)
as a summation
T (n) = an + an(
a + 1
Our termination condition is n( a
a+1 )k  a, assume for contradiction that
∀i ∈ {1, . . . , a + 1} : |(S \ Ti) ∩ P|  a.
D. Intel’s TLBs
Modern CPUs have very distinct TLBs implementations. In
particular, modern Intel CPUs implement different buffers for
data (dTLB) and instructions (iTLB), a second level TLBs
(sTLB) with larger capacity, and different TLBs for each PT
level.
Table II shows a summary of TLB parameters for Haswell
and Skylake families:
Haswell
128 entries; 4-way
8 entries; full
64 entries; full
32 entries; 4-way
4 entries; 4-way
Skylake
128 entries; 8-way
8 entries; full
64 entries; 4-way
32 entries; 4-way
4 entries; full
1536 entries; 4-way
16 entries; 4-way
iTLB 4K
iTLB 2M/4M
dTLB 4K
dTLB 2M/4M
dTLB 1G
sTLB 4K/2M
sTLB 1G
TABLE II: TLB implementation information for Haswell
and Skylake microarchitectures. Extracted from the Intel’s
Architectures Optimization Manual [29].
1024 entries; 8-way
-
(cid:22)(cid:21)
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:41:36 UTC from IEEE Xplore.  Restrictions apply.