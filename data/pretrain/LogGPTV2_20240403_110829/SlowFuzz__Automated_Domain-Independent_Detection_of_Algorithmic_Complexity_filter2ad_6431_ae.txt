applications such as a state-of-the-art compression utility like
bzip2.
Result 2: SF is capable of exposing complex-
ity vulnerabilities (e.g., 300x slowdown in bzip2, PCRE-
compliant regular expressions with exponential match-
ing time, and PHP hash table collisions) in real-world,
non-trivial applications without knowing any domain-
specic details.
5.6 Engine Evaluation
Eect of SF’s tness function. In this section, we
examine the eect of using code-coverage-guided search ver-
sus SF’s resource usage based tness function, particu-
larly in the context of scanning an application for complexity
vulnerabilities. To do so, we repeat one of the experiments of
Section 5.2, applying SF on the OpenBSD quicksort
implementation with an input size of 64 bytes, for a total of
1 million generations, using hybrid mutations. Our results
are presented in Figure 10. We observe that SF’s guid-
ance mechanism yields signicant improvement over code-
coverage-guided search. In particular, SF achieves a
3.3x slowdown for OpenBSD, whereas the respective slow-
down achieved using only coverage-guided search is 23.41%.
This is an expected result, since, as mentioned in previous
Sections, code coverage cannot encapsulate behaviors result-
ing in multiple invocations of the same line of code (e.g., an
innite loop). Moreover, we notice that the total instructions
of each unit that is created by SF at dierent gener-
ations is not monotonically increasing. This is an artifact of
our implementation, using SanitizerCoverage’s 8-bit counters,
which provide a coarse-grained, imprecise tracking of the real
number of times each edge was invoked (Section 4). Thus, al-
though a unit might result in execution of fewer instructions,
it will only be observed by SF’s guidance engine if
the respective number of total CFG edges falls into a separate
bucket (8 possible ranges representing the total number of
CFG edge accesses). Future work can consider applying more
precise instruction tracking (e.g., using hardware counters or
utilities similar to perf) with static analyses passes, to achieve
more eective guidance.
Finally, when choosing the SF tness function, we
also considered the option of utilizing time-based tracking
instead of performance counters. However, performing time-
based measurements in real-world systems is not trivial, es-
pecially at instruction-level granularity and when multiple
samples are required in order to minimize measurement er-
rors. In the context of fuzzing, multiple runs of the same input
will slow the fuzzer down signicantly. To demonstrate this
point, in Figure 10, we also include an experiment in which
the execution time of an input is used to guide input gener-
ation. In particular, we utilized CPU clock time to measure
the execution time of a unit and discarded the unit if it was
not slower than all previously seen units. We notice that the
corpus degrades due to system noise and does not achieve any
slowdown larger than 23%. 4
Figure 10: Comparison of the slowdown achieved by
SF under dierent guidance mechanisms, when
applied on the OpenBSD quicksort implementation of
Section 5.2, for an input size of 64 bytes, after 1 million
generations (average of 100 runs).
4Contrary to the slowdowns measured during fuzzing using a single run, the
slowdowns presented in Figure 10 are generated using the perf utility running
ten iterations per input. Non-monotonic increases denote corpus degradation
due to bad input selection.
10
02000004000006000008000001000000Generation0.51.01.52.02.53.0SlowdownNormalized slowdown over best performing inputTime Coverage Edge CountersResult 3: SF’s tness function and mutation
schemes outperform code-coverage-guided evolutionary
search by more than 100%.
Eect of Mutation Schemes. To highlight the dierent char-
acteristics of each of SF’s mutation schemes described
in Section 3, we repeat one of the experiments of Section 5.2,
applying SF on the OpenBSD quicksort, each time us-
ing a dierent mutation strategy. Our experimental setup is
identical with that of Section 5.2: we sort inputs with a size of
64 bytes and fuzz for a total of 1 million generations. For each
mode of operation, we average on a total of 100 SF
sessions. Our results are presented in Figure 11.
3.30x slowdown, however is the last mutation mode to start
reaching a plateau. We suspect that this results from the fact
the hybrid mode does not quickly penalize particular inputs
or mutations as it needs more samples of each mutation oper-
ation and oset pair before avoiding any particular oset or
mutation operation.
Instrumentation overhead. SF’s runtime overhead,
measured in executions per second, matches the overhead of
native libFuzzer. The executions per second achieved on dif-
ferent payloads are mostly dominated by the runtimes of the
native binary, as well as the respective I/O operations. Despite
our choice to prototype SF using libFuzzer, the design
and methodology presented in Section 3 can be applied to
any evolutionary fuzzer and can also be implemented using
Dynamic Binary Instrumentation frameworks, such as Intel’s
PIN [39], to allow for more detailed runtime tracking of the ap-
plication state. However, such frameworks are known to incur
slowdowns of more than 200%, even with minimal instrumen-
tation [43]. For instance, for our PHP hashtable experiments
described in Section 5.4, an insertion of 16 strings, resulting
in 8 collisions, takes 0.02 seconds. Running the same insertion
under a PIN tool that only counts instructions, requires a total
of ~2 seconds. By contrast, hashtable fuzzing with SF
achieves up to 4000 execs/sec, unless a signicant slowdown
is incurred due to a particular input. 5
Figure 11: Comparison of the best slowdown achieved
by SF’s dierent mutation schemes, at each gen-
eration, when applied on the OpenBSD quicksort imple-
mentation of Section 5.2, for an input size of 64 bytes,
after 1 million generations (average of 100 runs).
We notice that, for the above experiment, choosing a mu-
tation at random, is the worst performing option among all
mutation options supported by SF (Section 3.2), how-
ever still achieving a slowdown of 2.33x over the best perform-
ing input. Indeed, all of SF’s scoring-based mutation
engines (oset-priority, mutation-priority and hybrid), are
expected to perform at least as good as selecting mutations
at random, given enough generations, as they avoid getting
stuck with unproductive mutations. We also observe that o-
set priority is the fastest mode to converge out of the other
mutation schemes for this particular experiment, and results
in an overall slowdown of 3.27x.
For sorting, osets that correspond to areas of the array that
should not be mutated, are quickly penalized under the oset
priority scheme, thus mutations are mainly performed on the
non-sorted portions of the array. Additionally, we observe that
mutation priority also outperforms the random scheme due to
the fact that certain mutations (e.g., crossover operations) may
have devastating eects on the sorting of the array. The muta-
tion priority scheme picks up such patterns and avoids such
mutations. By contrast, these mutations continue to be used
under the random scheme. Finally, we observe that the hybrid
mode eventually outperforms all other strategies, achieving a
6 DISCUSSION
In this paper, we demonstrated that evolutionary search tech-
niques commonly used in fuzzing to nd memory safety bugs
can be adapted to nd algorithmic complexity vulnerabilities.
Similar strategies should be applicable for nding other types
of DOS attacks like battery draining, lling up memory or
hard disk, etc. Designing the tness functions and mutation
schemes for detecting such bugs will be an interesting fu-
ture research problem. Besides evolutionary techniques, using
other mechanisms like reinforcement learning or Monte Carlo
search techniques can also be adapted for nding inputs with
worst-case resource usage.
Our current prototype of SF is completely dynamic.
However, integrating static analysis techniques into SF
can further improve its performance. Using static analysis to
nd potentially promising osets in an input for mutation
will further reduce the search space and therefore will make
the search process more ecient. For example, using taint
tracking and loop analysis together with runtime ow proles
can identify potentially promising code locations that can
cause signicant slowdowns [41, 52].
The current prototype implementation of SF uses
the SanitizerCoverage passes to keep track of the number of
times a CFG edge is accessed. Such tracking is limited by the
total number of buckets allowed by SanitizerCoverage. This
reduces the accuracy of resource usage information as tracked
by SF. This results from the fact that any edge that is
accessed more than 128 times is assigned to the same bucket
regardless of the actual number of accesses. Although, under
5Execution under SF does not require repeated loading of the required
libraries, but is only dominated by the function being tested, which is only
a fraction of the total execution of the native binary (thus smaller than 0.02
seconds).
11
02000004000006000008000001000000Generation1.01.52.02.53.03.5SlowdownNormalized slowdown over best performing inputRandom Mutation Priority Offset Priority Hybridits current implementation, the actual edge count information
is imprecise, this is not a fundamental design limitation of
SF but an artifact of our prototype implementation.
Alternative implementations can oer more precise tracking
can via custom callbacks for SanitizerCoverage, by adopting
hardware counters or by utilizing per-unit perf tracking. On
the other hand, the benet of the current implementation
is that it can be incorporated into libFuzzer’s main engine
orthogonally, without requiring major changes to libFuzzer’s
dependencies.
7 RELATED WORK
Complexity attacks. Detecting and mitigating algorithmic
complexity attacks is an active eld of research. Crosby et
al. [31] were the rst to present complexity attacks abusing
collisions in hash table implementations. Contrary to S
F’s approach, however, their attack required expert knowl-
edge. Since then, several lines of work have explored attacks
and defenses targeting dierent types of complexity attacks:
Cai et al. [28] leverage complexity vulnerabilities in the Linux
kernel name lookup hash tables to exploit race conditions in
the kernel access(2)/open(2) system calls, whereas Sun et
al. [54] explore complexity vulnerabilities in the name lookup
algorithm of the Linux kernel to achieve an exploitable covert
timing channel. Smith et al. [51] exploit the syntax of the
Snort IDS to perform a complexity attack resulting in slow-
downs during packet inspection. Shenoy et al. [49, 50] present
an algorithmic complexity attack against the popular Aho-
Corasick string searching algorithm and propose hardware
and software-based defenses to mitigate the worst-case perfor-
mance of their attacks. Moreover, several lines of work focus
particularly on statically detecting complexity vulnerabilities
related to regular expression matching, especially focusing on
backtracking during the matching process [25, 38, 42, 57]. Con-
trary to SF, all the above lines of work require deep
domain-dependent knowledge and do not expand to dierent
categories of complexity vulnerabilities.
Finally, recent work by Holland et al. [34] combines static
and dynamic analysis to perform analyst-driven exploration of
Java programs to detect complexity vulnerabilities. However,
contrary to SF, this work requires a human analyst
to closely guide the exploration process, specifying which
portions of the binary should be analyzed statically and which
dynamically as well as dening the inputs to the binary.
Performance bugs. Several prior works target generic per-
formance bugs not necessarily related to complexity vulnera-
bilities. For instance, Lu et al. study a large set of real-world
performance bugs to construct a set of rules that they use
to discover new performance bugs via hand-built checkers
integrated in the LLVM compiler infrastructure [36]. Along
the same lines, LDoctor [52] detects loop ineciencies by im-
plementing a hybrid static-dynamic program analysis that
leverages dierent loop-specic rules. Both the above lines
of work, contrary to SF, require expert-level knowl-
edge for creating the detection rules, and are orthogonal to
the current work. Another line of work focuses on application
proling to detect performance bottlenecks. For example, Ra-
manathanet al. utilize ow proling for the ecient detection
of memory-related performance bugs in Java programs [41].
12
Grechanik et al. utilize a genetic-algorithm-driven proler for
detecting performance bottlenecks [48] in Web applications,
and cluster execution traces to explore dierent combinations
of the input parameter values. However, contrary to SF,
their goal is to explore a large space of input combinations
in the context of automatic application proling and not to
detect complexity vulnerabilities.
WCET. Another related line of work addresses accurate Worst-
Case Execution Time (WCET) estimation for a given applica-
tion. Apart from static analysis and evolutionary testing ap-
proaches [26], traditionally WCET estimation has been achieved
using search based methods measuring end-to-end execution
times [55]. Moreover, Hybrid Measurement-Based Analyses
(HMBA) have been used to measure the execution times of
program segments via instrumentation points [27, 45, 46] and
execution proles [26]. Wegener et al. [56] utilize evolutionary
techniques for testing timing constraints in real-time systems,
however contrary to SF, apply processor-level timing
measurements for their tness function and only perform ran-
dom mutations. Finally, recent techniques combine hardware
eects and loop bounds with genetic algorithms [37]. How-
ever, all of the above methods attempt to detect worst-case
execution times for simple and mostly straight-line program
segments often used in real-time systems. By contrast, S
F detects algorithmic complexity attacks in large complex
programs deployed in general purpose hardware.
Evolutionary Fuzzing. Several lines of work deploy evo-
lutionary mutation-based fuzzing to target crash-inducing
bugs. Notable examples are the AFL [58], libFuzzer [14], hong-
fuzz [11], and syzkaller [23] fuzzers, as well as the CERT Basic
Fuzzing Framework (BFF) [35], which utilize coverage as their
main guidance mechanism. Moreover, several frameworks
combine coverage-based evolutionary fuzzing with symbolic
execution [29, 32, 33, 53], or with static analysis and dynamic
tainting [47] to achieve higher code coverage and increase
their eectiveness in detecting bugs. Finally, NEZHA [44] uti-
lizes evolutionary-based, mutation-assisted testing to target
semantic bugs. Although many of the aforementioned lines
of research share many common building blocks with S
F, they do not target complexity vulnerabilities and mainly