it's no longer realistic to assume you can get that certificate to all potential clients. 
The client, therefore, has no way of knowing whether the certificate can be trusted. If 
users browse to the site, they get an error message stating that the certificate isn't 
signed by a trusted authority; the only option is to accept the untrusted certificate or 
terminate the connection. An attacker capable of spoofing the server could exploit 
The Art of Software Security Assessment - Identifying and Preventing Software Vulnerabilities 
85 
this situation to stage man-in-the-middle attacks and then hijack sessions or steal 
credentials. 
Network Profiles 
An application's network profile is a crucial consideration when you're reviewing 
operational security. Protocols such as Network File System (NFS) and Server 
Message Block (SMB) are acceptable inside the corporate firewall and generally are 
an absolute necessity. However, these same types of protocols become an 
unacceptable liability when they are exposed outside the firewall. Application 
developers often don't know the exact environment an application might be deployed 
in, so they need to choose intelligent defaults and provide adequate documentation 
on security concerns. 
Generally, identifying operational vulnerabilities in the network profile is easier for a 
deployed application. You can simply look at what the environment is and identify any 
risks that are unacceptable, and what protections are in place. Obvious protections 
include deploying Internet-facing servers inside demilitarized zones (DMZs) and 
making sure firewall rule sets are as strict as reasonably possible. 
Network profile vulnerabilities are more difficult to tackle when the environment is 
unknown. As a reviewer, you need to determine the most hostile potential 
environment for a system, and then review the system from the perspective of that 
environment. You should also ensure that the default configuration supports a 
deployment in this type of environment. If it doesn't, you need to make sure the 
documentation and installer address this problem clearly and specifically. 
6.3.3 Web-Specific Considerations 
The World Wide Webmore specifically, HTTP and HTTPS serviceshas become one of 
the most ubiquitous platforms for application development. The proliferation of Web 
services and applications is almost single-handedly responsible for the increased 
awareness of network security and vulnerabilities. For this reason, Web security 
warrants certain special considerations. 
HTTP Request Methods 
A Web application can be tightly restricted in which requests and operations are 
allowed; however, in practice, this restriction often isn't applied. For example, the 
server might support a number of HTTP methods, but all the application requires is 
the HTTP GET, POST, and HEAD requests. When reviewing a deployed or embedded Web 
application, you should ensure that only the necessary request methods are allowed. 
In particular, question whether TRACE, OPTIONS, and CONNECT requests should be 
The Art of Software Security Assessment - Identifying and Preventing Software Vulnerabilities 
86 
allowed. If you are unfamiliar with these methods, you can find a lot more information 
in Chapter 17(? [????.]). 
Directory Indexing 
Many Web servers enable directory indexing by default. This setting has no effect in 
directories that provide an index file; however, it can expose valuable information to 
directories with no index. Often, these directories contain include and configuration 
files, or other important details on the application's structure, so directory indexing 
should be disabled by default. 
File Handlers 
When you try to run a file, it's obvious if the proper handler hasn't been installed. The 
server simply won't run the file, and instead it returns the source or binary directly. 
However, handler misconfiguration could happen in a number of less obvious 
situations. When machines are rebuilt or replaced, the correct handlers might not be 
installed before the application is deployed. Developers might also establish 
conventions for naming include files with different extensions. For example, Classic 
ASP and PHP: Hypertext Processor (PHP) include files are often named with an .inc 
extension, which is not interpreted by the default handlers in PHP or ASP. Because the 
include file isn't intended to be requested directly, developers and administrators 
might not realize it's vulnerable. 
Both situations can result in a source or binary file disclosure, which allows attackers 
to download the raw source or binary code and get detailed information on the 
application's internal structure. In addition, PHP and other scripting languages 
commonly use include files to provide database account credentials and other 
sensitive information, which can make source disclosure vulnerabilities particularly 
dangerous. 
This problem needs to be approached from three sides. First, developers need to 
choose a set of extensions to be used for all source and binary files. Second, the Web 
server should be configured with handlers for all appropriate file types and extensions. 
Finally, the only files in the Web tree should be those that must be retrieved by Web 
requests. Include files and supporting libraries should be placed outside the Web tree. 
This last step prevents attackers from requesting files directly that are only intended 
to be included. 
An important extension to the last step is applicable when Web applications deal with 
uploaded content from clients. Applications commonly allow clients to upload files, 
but doing so has potentially dangerous consequences, especially if the directory 
where files are uploaded is within the Web tree. In this case, clients might be able to 
request the file they just uploaded; if the file is associated with a handler, they can 
achieve arbitrary execution. As an example, consider a PHP application that stores 
The Art of Software Security Assessment - Identifying and Preventing Software Vulnerabilities 
87 
uploaded files in /var/www/webapp/tmpfiles/, which can be browsed via the HTTP URI 
/webapp/tmpfiles/. If the client uploads a file called evil.php and then requests 
/webapp/tmpfiles/evil.php in a browser, the Web server will likely recognize that the 
file is a PHP application and run code within the file's PHP tags. 
Authentication 
Web applications might not perform authentication internally; this process might be 
handled externally through the HTTP authentication protocol, an authenticating 
reverse proxy, or a single sign-on (SSO) system. With this type of authentication, 
it is especially important to make sure the external authentication mechanism is 
configured correctly and performs authentication in a safe manner. For example, a 
reverse-proxy device might add headers that include the current account name and 
user information. However, attackers could discover a request path that doesn't pass 
through the reverse proxy, which would allow them to set the account headers to 
whatever they want and impersonate any user on the system. 
Default Site Installations 
Some Web servers include a number of sample sites and applications as part of a 
default installation. The goal is to provide some reference for configuring the server 
and developing modules. In practice, however, these sample sites are a rather severe 
case of unnecessary services and insecure defaults. Numerous security problems 
have been caused by installing sample Web applications and features. For example, 
ColdFusion's Web-scripting technologies used to install several sample applications 
by default that allowed clients to upload files and run arbitrary code on the system. 
Note 
This ColdFusion bug ties in with some of the previous discussion on spoofing and 
identification. The sample applications were accessible only to clients who connected 
from the same machine where ColdFusion was installed. However, the way they 
verified whether the client was connecting locally was to check the HTTP HOST 
variable, which is completely controlled by the client. As a result, any client could 
claim to be connecting locally and access sample scripts with the dangerous 
functionality. This bug is documented at www.securityfocus.com/bid/3154/info. 
Overly Verbose Error Messages 
Most Web servers return fairly verbose error messages that assist in diagnosing any 
problems you encounter. Web application platforms also provide detailed exception 
information to assist developers in debugging code. These capabilities are essential 
The Art of Software Security Assessment - Identifying and Preventing Software Vulnerabilities 
88 
when developing a system, but they can be a serious operational vulnerability in a 
deployed system. 
The burden of end-user error reporting should rest primarily on application 
developers. The application level has the correct context to determine what 
information is appropriate to display to end users. Configuration of the base platform 
should always be performed under the assumption that the application is filtering and 
displaying any end-user error information. This way, the deployed system can be 
configured to report the minimum necessary information to client users and redirect 
any required details to the system log. 
Public-Facing Administrative Interfaces 
Web-based administration has become popular for Web applications and network 
devices. These administrative interfaces are often convenient, but they are rarely 
implemented with potentially malicious users in mind. They might use weak default 
passwords, not perform sufficient authentication, or have any number of other 
vulnerabilities. Therefore, they should be accessible only over restricted network 
segments when possible and never exposed to Internet-facing connections. 
6.3.4 Protective Measures 
A range of additional protective measures can affect an application's overall security. 
In consultant speak, they are often referred to as mitigating factors or 
compensating controls; generally, they're used to apply the concept of defense in 
depth mentioned in Chapter 2(? [????.]). These measures can be applied during or 
after the development process, but they tend to exist outside the software itself. 
The following sections discuss the most common measures, but they don't form an 
exhaustive list. For convenience, these measures have been separated into groups, 
depending on whether they're applied during development, to the deployed host, or 
in the deployed network. One important consideration is that most of these measures 
include software, so they could introduce a new attack surface or even vulnerabilities 
that weren't in the original system. 
Development Measures 
Development protective measures focus on using platforms, libraries, compiler 
options, and hardware features that reduce the probability of code being exploited. 
These techniques generally don't affect the way code is written, although they often 
influence the selection of one platform over another. Therefore, these measures are 
viewed as operational, not implementation measures. 
Nonexecutable Stack 
The Art of Software Security Assessment - Identifying and Preventing Software Vulnerabilities 
89 
The classic stack buffer overflow is quite possibly the most often-used software 
vulnerability in history, so hardware vendors are finally trying to prevent them at the 
lowest possible level by enforcing the nonexecutable protection on memory pages. 
This technique is nothing new, but it's finally becoming common in inexpensive 
commodity hardware, such as consumer PCs. 
A nonexecutable stack can make it harder to exploit a memory management 
vulnerability, but it doesn't necessarily eliminate it because the exploit might not 
require running code from the stack. It might simply involve patching a stack variable 
or the code execution taking advantage of a return to libc style attack. These 
vulnerabilities are covered in more detail in Chapter 5(? [????.]), "Memory 
Corruption," but for now, it's important to understand where the general weaknesses 
are. 
Stack Protection 
The goal of the classic stack overflow is to overwrite the instruction pointer. Stack 
protection prevents this exploit by placing a random value, called a "canary," between 
stack variables and the instruction pointer. When a function returns, the canary is 
checked to ensure that it hasn't changed. In this way, the application can determine 
whether a stack overflow has occurred and throw an exception instead of running 
potentially malicious code. 
Like a nonexecutable stack, stack protection has its share of weaknesses. It also 
doesn't protect against stack variable patching (although some implementations 
reorder variables to prevent the likelihood of this problem). Stack protection 
mechanisms might also have issues with code that performs certain types of dynamic 
stack manipulation. For instance, LibSafePlus can't protect code that uses the alloca() 
call to resize the stack; this problem can also be an undocumented issue in other 
implementations. Worse yet, some stack protections are vulnerable to attacks that 
target their implementation mechanisms directly. For example, an early 
implementation of Microsoft's stack protection could be circumvented by writing past 
the canary and onto the current exception handler. 
No form of stack protection is perfect, and every implementation has types of 
overflows that can't be detected or prevented. You have to look at your choices and 
determine the advantages and disadvantages. Another consideration is that it's not 
uncommon for a development team to enable stack protection and have the 
application stop functioning properly. This problem happens because of stack 
overflows occurring somewhere in the application, which may or may not be 
exploitable. Unfortunately, developers might have so much trouble tracking down the 
bugs that they choose to disable the protection entirely. You might need to take this 
possibility into account when recommending stack protection as an easy fix. 
Heap Protection 
The Art of Software Security Assessment - Identifying and Preventing Software Vulnerabilities 
90 
Most program heaps consist of a doubly linked list of memory chunks. A generic heap 
exploit attempts to overwrite the list pointers so that arbitrary data can be written 
somewhere in the memory space. The simplest form of heap protection involves 
checking that list pointers reference valid heap chunks before performing any list 
management. 
Simple heap protection is fairly easy to implement and incurs little performance 
overhead, so it has become common in the past few years. In particular, Microsoft's 
recent OS versions include a number of heap consistency-checking mechanisms to 
help minimize the damage heap overwrites can do. The GNU libc also has some 
capabilities to protect against common exploitation techniques; the memory 
management routines check linked list values and validate the size of chunks to a 
certain degree. Although these mechanisms are a step in the right direction, heap 
overflows can still be exploited by manipulating application data rather than heap 
structures. 
Address Space Layout Randomization 
When an application is launched in most contemporary operating systems, the loader 
organizes the program and required libraries into memory at the same locations 
every time. Customarily, the program stack and heap are put in identical locations for 
each program that runs. This practice is useful for attackers exploiting a memory 
corruption vulnerability; they can predict with a high degree of accuracy the location 
of key data structures and program components they want to manipulate or misuse. 
Address space layout randomization (ASLR) technologies seek to remove this 
advantage from attackers by randomizing where different program components are 
loaded at in memory each time the application runs. A data structure residing at 
address 0x12345678 during one program launch might reside at address 
0xABCD5678 the next time the program is started. Therefore, attackers can no longer 
use hard-coded addresses to reliably exploit a memory corruption flaw by targeting 
specific structures in memory. ASLR is especially effective when used with other 
memory protection schemes; the combination of multiple measures can turn a bug 
that could previously be exploited easily into a very difficult target. However, ASLR is 
limited by a range of valid addresses, so it is possible for an attacker to perform a 
repeated sequence of exploit attempts and eventually succeed. 
Registered Function Pointers 
Applications might have long-lived functions pointers at consistent locations in a 
process's address space. Sometimes these pointers are defined at compile time and 
never change for a given binary; exception handlers are one of the most common 
examples. These properties make long-lived function pointers an ideal target for 
exploiting certain classes of vulnerabilities. Many types of vulnerabilities are similar, 
in that they allow only a small value to be written to one arbitrary location, such as 
attacks against heap management functions. 
The Art of Software Security Assessment - Identifying and Preventing Software Vulnerabilities 
91 
Function pointer registration is one attempt at preventing the successful exploit of 
these types of vulnerabilities. It's implemented by wrapping function pointer calls in 
some form of check for unauthorized modification. The exact details of the check 
might vary in strength and how they're performed. For example, the compiler can 
place valid exception handlers in a read-only memory page, and the wrapper can just 
make a direct comparison against this page to determine whether the pointer is 
corrupt. 
Virtual Machines 
A virtual machine (VM) platform can do quite a bit to improve an application's basic 
security. Java and the .NET Common Language Runtime (CLR) are two popular VM 
environments, but the technology is even more pervasive. Most popular scripting 
languages (such as Perl, Python, and PHP) compile first to bytecode that's then 
interpreted by a virtual machine. 
Virtual machine environments are typically the best choice for most common 
programming tasks. They generally provide features such as sized buffers and strings, 
which prevent most memory management attacks. They might also include additional 
protection schemes, such as the code access security (CAS) mentioned in Chapter 1(? 
[????.]). These approaches usually allow developers to create more secure 
applications more quickly. 
The downside of virtual machines is that their implicit protection stops at low-level 
vulnerabilities. VM environments usually have no additional protections against 
exploiting vulnerabilities such as race conditions, formatted data manipulation, and 
script injection. They might also provide paths to low-level vulnerabilities in the 
underlying platform or have their own vulnerabilities. 
Host-Based Measures 
Host-based protections include OS features or supporting applications that can 
improve the security of a piece of software. They can be deployed with the application 
or be additional measures set up by end users or administrators. These additional 
protective measures can be useful in preventing, identifying, and mitigating 
successful exploits, but remember that these applications are pieces of software. 
They might contain vulnerabilities in their implementations and introduce new attack 
surface to a system. 
Object and File System Permissions 
Permission management is the first and most obvious place to try reducing the attack 
surface. Sometimes it's done programmatically, such as permissions on a shared 
memory object or process synchronization primitive. From an operational perspective, 
The Art of Software Security Assessment - Identifying and Preventing Software Vulnerabilities 
92 
however, you're concerned with permissions modified during and after application 
installation. 
As discussed earlier in this chapter, permission assignment can be complicated. 
Platform defaults might not provide adequate security, or the developer might not be 
aware of how a decision could affect application security. Typically, you need to 
perform at least a cursory review of all files and objects included in a software 
installation. 
Restricted Accounts 
Restricted accounts are commonly used for running an application with a 
public-facing service. The intent of using this type of account is not to prevent a 
compromise but to reduce the impact of the compromise. Therefore, these accounts 
have limited access to the system and can be monitored more closely. 
On Windows systems, a restricted account usually isn't granted network access to the 
system, doesn't belong to default user groups, and might be used with restricted 
tokens. Sudhakar Govindavajhala and Andrew W. Appel of Princeton University 
published an interesting paper, "Windows Access Control Demystified," in which they 
list a number of considerations and escalation scenarios for different group privileges 
and service accounts. This paper is available at 
http://www.cs.princeton.edu/~sudhakar/papers/winval.pdf. 
Restricted accounts generally don't have a default shell on UNIX systems, so 
attackers can't log in with that account, even if they successfully set a password 
through some application flaw. Furthermore, they usually have few to no privileges 
on the system, so if they are able to get an interactive shell somehow, they can't 
perform operations with much consequence. Having said that, attackers simply 
having access to the system is often dangerous because they can use the system to 
"springboard" to other previously inaccessible hosts or perform localized attacks on 
the compromised system to elevate privileges. 
Restricted accounts are useful, but they can be deployed carelessly. You need to 
ensure that restricted accounts contain no unnecessary rights or privileges. It's also 
good to follow the rule of one account to one service because of the implicit shared 
trust between all processes running under the same account, as discussed in Chapter 
2(? [????.]). 
Chroot Jails 
UNIX operating systems use the chroot command to change the root directory of a 
newly executed process. This command is normally used during system startup or 
when building software. However, chroot also has a useful security application: A 
The Art of Software Security Assessment - Identifying and Preventing Software Vulnerabilities 
93 
nonroot process can be effectively jailed to a selected portion of the file system by 
running it with the chroot command. 
This approach is particularly effective because of UNIX's use of the file system as the 
primary interface for all system activity. An attacker who exploits a jailed process is 
still restricted to the contents of the jailed file system, which prevents access to most 
of the critical system assets. 
A chroot jail can improve security quite a bit; however, there are caveats. Any 
process running under root privileges can usually escape the jail environment by 
using other system mechanisms, such as the PTRACE debugging API, setting system 
variables with sysctl, or exploiting some other means to allow the system to run a 
new arbitrary process that's not constrained to the chroot jail. As a result, chroot jails 