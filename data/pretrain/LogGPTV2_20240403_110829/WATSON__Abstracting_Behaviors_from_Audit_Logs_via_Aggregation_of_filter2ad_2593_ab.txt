3
Eva.docsshsecret.txtsshPro1.ccc1a.outcpaslda.outtargit addgit commitPro2.ccatcc1git pushgit addgit commitgit pushsshgit addgit commitgit pushFig. 3: WATSON Overview.
for human inspection. In contrast to traditional approaches,
where behavior abstraction relies heavily on domain knowl-
edge, our goal is to achieve automated behavior abstraction
using simple yet effective insights.
Our ﬁrst
insight comes from the observation that
the
semantics of system entities and relations in audit events can
be revealed from the context in which they are used. For
example, while compiling programs using gcc, C compiler
(cc1) writes assembly code to a local temporary ﬁle (e.g.,
/tmp/ccw4T8Hh.s) which is later read by the assembler
(as). We note that such temporary ﬁles are named randomly
in different Program Compilation instances. From the context
of how data is manipulated, they, however, go through identical
system operations, i.e., created by gcc, written by cc1, read
by as, and deleted by gcc. Thus, we can reason that these ﬁles
may share similar semantics despite different identiﬁers. This
matches our intuitive way of labeling them as IPC medium
between cc1 and as. Our core idea is to uncover the semantics
of system entities and relations from their contextual infor-
mation in audit events, such as by analyzing the correlation
of their presence in events. A general approach to extracting
such contextual semantics is to employ embedding models.
The objective is to map system entities and relations into
an embedding space (i.e., numeric vector space), where the
distances between vectors capture the semantic relationships.
Now that we can interpret the semantic information of audit
events. The next step would be to identify audit events belong-
ing to individual behaviors. Our second insight is based on
our observation that high-level behaviors, which are primarily
centered around an intended goal of a user, can be reﬂected
as a series of system operations applied on data objects.
For example, compiling program a.c with gcc intends to
translate source code into executable machine code. We can
decompose the translation procedure into three operations: (1)
Compiling: compile a.c into an assembly language ﬁle, a.s,
(2) Assembling: convert a.s into a relocatable object ﬁle,
a.o, and (3) Linking: combine a.o with multiple object ﬁles
into an executable ﬁle, a.out. Speciﬁcally, WATSON deﬁnes
the behavior as an intended goal of the user, while the means
to achieve it as a behavior instance. Each behavior instance is
a sequence of operations that the user performs to achieve the
goal. These operations can be further modeled as data transfers
and the behavior instance as a sequence of such data transfers.
For example, we can summarize the Program Compilation
4
behavior above by following how data transfer from a.c to
a.s, a.o, and ﬁnally a.out. Based on this observation, we
clearly abstract behaviors as sequences of data transfers that
operate on related data. Particularly in audit logs, WATSON
identiﬁes behavior instances by leveraging information ﬂows
among audit events as guidance for tracking data transfers.
When such ﬂows exist, we group events as a subgraph and
form an individual behavior instance. For example, during
program compilation, the compiling, assembling, and linking
operations are recorded as cc1, as, and ld events in audit
logs. We can identify this behavior by following information
ﬂows from the source ﬁle in the cc1 event to the executable
ﬁle in the ld event. Figure 2 presents subgraphs used by
WATSON to summarize behaviors in the motivating example.
With the knowledge of events and identiﬁcation of behav-
iors, the semantic representation of behaviors can be naturally
thought of as the aggregated semantics of their constituent
events as they are deﬁned as sequences of events.
D. Threat Model
We assume the underlying OS, the auditing engine, and
monitoring data to be part of the trusted computing base
(TCB). Ensuring the integrity of the OS kernel, endpoint
monitors, or audit logs themselves is beyond the scope of
this work. This threat model is shared among related work
on system auditing [29], [36], [38], [39], [53], [63].
We also assume that behaviors go through kernel-layer
auditing, and their operations are captured as system-call audit
logs. Although attackers may attempt to perform malicious
behaviors without executing any system call
to hide their
footprints, such behaviors appear to be rare, and the harm
they can bring to the rest of the system is limited [76]. We
focus on behaviors in single user sessions in this paper. Our
insights are generally applicable to cross-session or cross-
machine behaviors.
III. WATSON DESIGN
A. Approach Overview
The overall approach of WATSON is shown in Figure 3.
It consists of three primary phases: Knowledge Graph Con-
struction, Behavior Abstraction, and Representative Behavior
Identiﬁcation. WATSON takes as inputs system audit data,
KG ConstructionEvent Semantics InferenceBehavior SummarizationBehavior Semantics AggregationBehavior ClusteringRepresentative BehaviorsAudit LogsKnowledge Graphembedding SpaceI: Knowledge Graph ConstructionII: Behavior AbstractionIII: Representative Behavior IdentificationSemantic Representation!!:($!!,$!",⋯,$!#)!":($"!,$"",⋯,$"#)⋮⋮!$:($$!,$$",⋯,$$#)Behavior InstanceFig. 4: Simpliﬁed version of KG for the Program Compilation.
Pentagon denotes system relations. TS shows the timestamp
attribute of Relation elements.
e.g., Linux Audit logs [9]. It summarizes behavior instances,
uncovers their semantics, and ﬁnally outputs representative
high-level behaviors.
Speciﬁcally, given audit logs in a user session as the input,
the Knowledge Graph Construction module ﬁrst parses logs
into triples and constructs the log-based knowledge graph
(KG). Then, the Event Semantics Inference module employs
a translation-based embedding model to infer the contextual
semantics of nodes in the KG. At the same time, the Behavior
Summarization module enumerates subgraphs from the KG to
summarize behavior instances. Combined with node semantics,
the Behavior Semantics Aggregation module next enhances
subgraphs to encode the semantics of behavior instances.
Finally, the Behavior Clustering module groups semantically
similar subgraphs into clusters, each specifying a high-level
behavior. These cluster-based behavior abstractions can further
be used to reduce the efforts of downstream tasks. We present
the design details of WATSON in the following sections.
B. Knowledge Graph Construction
In order to analyze the contextual semantics of events,
a uniﬁed representation is required to present heterogeneous
events in a homogeneous manner. Instead of using a prove-
nance graph based on the provenance data model (PROV-
DM [12]), we propose a new representation based on knowl-
edge graph (KG) to integrate heterogeneous information. This
allows for the future capacity to capture relationships beyond
just provenance [79], [80] (e.g., ﬁle meta-information such as
permissions and owners).
Following the formal description of a KG [26] by Färber et
al., we deﬁne log-based KG as a resource description frame-
work (RDF) graph [64]. More concretely, the log-based KG is
a set of numerous semantic triples. Each triple, corresponding
to an audit event, consists of three elements that codify the
semantic Relation between the Head and Tail in the form
of (Head, Relation, Tail). Both Head and Tail can be any
type of system entities, and Relation can take any system
operation that is performed on Tail. However, note that types
of system entities in triples are consistent with that in audit
events, e.g., Head and Tail cannot be ﬁles or network sockets
simultaneously. Figure 4 shows a knowledge sub-graph of the
motivating example. Similar to a provenance graph, a KG
encodes information ﬂow that exists from Head to Tail in a
triple. For example, the dependency chains (colored by blue) in
Figure 4 illustrate the data transfers from Pro1.c to a.out.
C. Event Semantics Inference
understanding is predicated on a suitable representation and
granularity whereby semantic meanings can be effectively
compared. A common practice in prior work [25], [71], [72]
is to formulate each log event as a basic unit for analysis.
However, a single audit event includes three elements (Head,
Relation, and Tail), where each element separately contributes
to event semantics. Therefore, performing semantic analysis
on the level of elements compared to events provides a more
detailed view as the context of individual elements is made
explicit. Working on the level of elements, we can obtain the
semantics of an audit event through the consolidation of three
constituent elements and the semantics of a behavior instance
through the consolidation of the events that deﬁne it. Although
there exists a trade-off between scalability and accuracy due
to different granularity of semantic analysis, the choice of
a computationally efﬁcient embedding model allows us to
preserve precision while handling the large number of events
found in logs. As such, we select individual elements rather
than audit events as the base unit in our semantic reasoning.
Since embedding models can learn the semantics of audit
events from their contextual information with elements as the
basis, the next question is how to map elements into an embed-
ding space (i.e., vector space). In Natural Language Processing,
word embedding has been used with much success to extract
and represent the semantics of words [16], [74]. Inspired by the
success of word embeddings in NLP, EKLAVYA [23] showed
how it could also be applied to infer the semantics of binary
instructions based on their usage context. This prompted us
to ask a similar question. Does the contextual occurrence of
elements in an audit event relate to their semantics? Take for
example the triples (cc1, read, a.c) and (cc1, read,
b.c). While a.c and b.c belong to different events, the
usage context of both elements in the presence of (cc1 read)
provides the hint
they might share similar semantics
as program source ﬁles. Intuitively, we aim to convert each
element into a vector where a small distance (e.g., L1/L2-norm
distance) between elements signiﬁes similar semantics while
a large distance the opposite. For instance, we expect the dis-
tance between embeddings (i.e., numeric vectors) of a.c and
b.c to be small. To achieve this goal, we propose employing
the translation-based embedding model, TransE [20], to learn
the mapping from elements to the embedding space.
that
In TransE, the translation in the embedding space describes
the semantic relationship between Head plus Relation and Tail.
Speciﬁcally, the embedding space has the property that given
a triple (Head, Relation, Tail), the position of Tail is that of
Head with a translation by Relation (i.e., Head + Relation
≈ Tail). Our guiding principle in selecting TransE is its
translation-based model perfectly matching our understanding
of contextual semantics in audit events. For example, consider
the case of (cc1, read, a.c) and (cc1, read, b.c).
Since TransE updates the embeddings of both a.c and b.c
using cc1 + read, they will be nearby in the embedding
space, indicating similar semantics. In theory, the embedding
model in TransE mirrors our expectation of element semantics
and their similarities, and Section V-B experimentally demon-
strates that TransE indeed learns the contextual semantics of
elements that matches our domain knowledge.
Understanding the semantics of audit events is the ﬁrst step
in abstracting high-level behaviors. In particular, an accurate
In the embedding process, each element is ﬁrst initialized
as a symbol without regard to its numeric label or textual name.
5
bashcc1/tmp/1a.outclone  execvfork   execcreate             deletevfork            execcreate              deletewritereadTS:71940957TS:71941090TS:71941101TS:71941121TS:71941178readvfork  exec/tmp/2writereadreadcreatewriteTS:71941385readTS:71940952vimgcccollect2ldvfork  execclone  execwriteasPro1.cTo do so, we encode elements as one-hot vectors and use
them as training inputs to the embedding model. Each one-
hot vector is an n-dimensional vector where n is the number
of unique elements in the universal set. For example, if the
entire log set contains two triples involving six elements, ﬁve
of which are unique, then the elements would be encoded
into a 5-dimensional vector with the ﬁrst being [1, 0, 0, 0, 0],
and the last being [0, 0, 0, 0, 1]. In terms of identiﬁers for
elements, we use the executable name, argument, and PID for
a process element, the absolute path for a ﬁle element, and
the IP address and port number for a socket element. We do
not directly employ element labels (e.g., PID and inode) for
identiﬁcation because they are recycled in a system and can
easily cause a collision. For a Relation element, we use the
system call number as the identiﬁer due to its uniqueness. Note
that element identiﬁer bears no relation to domain-speciﬁc
semantics during embedding.
In the training phase, TransE optimizes the embedding
space of elements by minimizing the translational distance of a
triple found in the KG (training triple) while maximizing that
of a triple not found in the KG (corrupted triple). We generate
corrupted triples by replacing either Head or Tail in a training
triple with a random element and ensuring that the new triples
do not exist in the KG. The loss function for the embedding
model optimization is summarized as follows:
L = X
X
(keh + er − etk−keh0 + er0 − et0k+γ),
(h,r,t)∈KG
(h0,r0,t0) /∈KG
where k · k denotes the L1-norm distance function. h, r, and
t represent Head, Relation, and Tail elements. ex denotes
the embedding of element x. Note that for a given element,
its embedding is constant no matter it acts as Head or Tail
in a triple. Moreover, TransE uses Margin γ to encourage
discrimination between training and corrupted triples. We
refer interested readers to [20] for the detailed optimization
procedure.
In summary, the result of TransE is an n × m embedding
matrix, which maps n-dimensional one-hot encoded elements
into an m-dimensional embedding space. To further infer the
semantics of an audit event, we concatenate the embeddings of
its constituent elements (Head, Relation, and Tail) and generate
a 3m-dimensional vector (192 dimensions in our case).
D. Behavior Summarization
The next step of behavior abstraction is identifying behav-
ior instances from one user login session. We deﬁne a behavior
instance as a sequence of audit events operated on related data
and correlated by information ﬂows. Accordingly, the problem
of summarizing individual behavior instances can be reduced
to extracting causally connected subgraphs with data objects
(i.e., ﬁle and network socket) as the root in the session’s
KG. Note that unlike path-based approaches [36], [77], which
decompose a provenance graph into overlapping paths for anal-
ysis, we partition the KG on the basis of subgraphs to represent
behavior instances. This is because an individual path cannot
preserve the complete context of behaviors representing multi-
branch data transfers. For example, path-based approaches
would fail to correlate all system operations belonging to the
Data Exﬁltration behavior in our motivating example because
6
operations of the program compilation and github upload are
located in separate paths.
In order to extract subgraphs that summarize behavior
instances, we perform an adapted forward depth-ﬁrst search
(DFS) on the session’s KG rooted at data objects. Figure 2
demonstrates three resulting subgraphs of behavior summa-
rization in the motivating example. During graph traversal, we
enforce the constraint that the timestamp of each following
edge has to be monotonically increasing from all previous
edges. This design can prevent false dependencies due to
information ﬂowing from a future event
to a past event.
Besides, we note that the ancestry of a system entity usually
contains critical behavior contexts. For example, the process
creating root data objects describes where they come from
(e.g., downloaded by email clients). However, such ancestries
are lost in the plain forward DFS because they belong to
backward dependencies. Therefore, we further incorporate one-
hop incoming edges of reached system entities during graph
traversal. In addition, we do not bound the DFS based on
the level of depth but rather domain-speciﬁc system entities
(e.g., ﬁles read and written by numerous processes [39]). As
only coarse-grained causal dependencies (system calls) are
recorded in audit
the causality analysis suffers from
the dependency explosion problem [49]. This also has an
adverse effect on WATSON’s ability to track data transfers
and summarize behavior instances. While solving the general
problem of dependency explosion is not within the scope
of this work, we aim to mitigate its inﬂuence by applying
heuristics to specify system entities (e.g., .bash_history
and firefox) that potentially trigger dependency explosion
as the termination condition in our DFS. To guarantee no
behavior instance loss, we perform the adapted DFS on every
single data object found in the KG except libraries that do
not reﬂect the roots of user intended goals. Two behaviors are
further merged if one behavior is the subset of the other.
logs,
In summary, we apply an adapted DFS algorithm to parti-
tion the session’s KG into subgraphs, where each describes a
behavior instance.
E. Behavior Semantics Aggregation
After behavior instance summarization, we next extract
the semantics of behavior instances. Recall that each behavior
instance partition is composed of audit events whose semantics
has been represented with high-dimensional vectors using the
embedding matrix. We then naturally derive the semantics of
behavior instances by combining behavior instance partitions
and the embedding matrix.
To obtain the semantic representation of a behavior in-
stance, a naïve approach is to add up the individual vectors
of its constituent events. However, this approach only works
under the assumption that all constituent events contribute
equally to the behavior instance semantics. In practice, this
assumption usually does not hold due to how events have
different relative importance to reﬂect behavior semantics and
the inﬂuence of noisy events.