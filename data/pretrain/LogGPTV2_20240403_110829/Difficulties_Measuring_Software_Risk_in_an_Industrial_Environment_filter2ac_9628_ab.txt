In  Section  3, we  will  define yet  another notion  of  cost 
that  we  will  call the consequence,  which  will  make a dis- 
tinction  between  those test cases that are run and those test 
cases  chosen  by  a test case  selection method that  have not 
been executed. 
17 
The formal  definition  of the risk of program P  relative 
to specification S is: 
R(P1 S) = 
Q ( i ) c ( i )  
i € D  
(2) 
where  Q(i) denotes the probability that  input i is selected 
from  input domain  D  when  P  is  operational  in  the field, 
and c ( i )  is the cost as defined in (I). An alternate definition 
of software risk replaces  the cost  of  failure, c ( i ) ,  with  the 
product  of a non-zero  cost  of  failure associated  with  each 
possible input and the probability  of that input’s failure. 
Our viewpoint is that the software either fails or doesn’t 
on a given input (given a deterministic program) and there- 
fore the cost of  failure will only  be nonzero  and therefore 
need  only be computed in the event that  the software fails 
on the input of interest. This definition will be particularly 
useful  when  looking at  a  limited  set  of  inputs,  namely  a 
test set whose elements are actually run, and  it is therefore 
likely that it can be determined whether or not the software 
has failed on a given input. 
Software testing  has  traditionally  been  used  to uncover 
faults in software by  selecting inputs that fail, as well as to 
predict the behavior  of the software in the field by examin- 
ing its behavior during testing.  Since, as indicated above, it 
is unrealistic to expect  that  we can compute the software’s 
risk  by  looking at all possible  inputs, it is  natural  to use  a 
well-selected  test set to predict the risk  for the entire input 
domain.  That is, of  course, an important goal  of  test  case 
selection  algorithms:  to choose a test  set  that can  reason- 
ably be used to predict the software’s behavior on the entire 
input domain. 
For this reason, we defined in  [6], the notion of the risk 
detected by a test set T ,  for a software system P ,  relative to 
a specification S. 
DetRisk(P, SIT) = 
c ( t )  
t € T  
This definition addresses  both of the deficiencies associ- 
ated with the traditional definition of risk: 
0  Only a relatively small subset of  the input domain has 
to be considered. 
Since these elements will actually  have  been  run dur- 
ing testing, it should be relatively easy to determine the 
associated cost of failure since we will only have to be 
concerned with those test cases that fail. 
However,  DetRisk does not take into account  how  the 
software  will  be  used  in  the  field,  nor  directly  reflect  the 
comprehensiveness  of  the  test  set.  Indirectly, comprehen- 
siveness  is involved in  the computation since the value  of 
the detected risk will presumably  increase as testing is per- 
formed, provided test cases are selected wisely. But there is 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 03:58:16 UTC from IEEE Xplore.  Restrictions apply. 
no provision for indicating how completely the test set satis- 
fies the test selection criterion being used.  For our purposes 
in  [6], however,  this was  not  a problem  since our goal  in 
defining the notion of detected risk was to provide a way of 
comparing test selection  techniques.  In a sense  it could be 
thought of as a way to assess how good a test case selection 
criterion is, compared to other criteria being considered. 
In  addition  to research  papers  that  introduce  notions of 
risk, there is another group of papers that have relevance  to 
the work presented here. This involves proposals of ways to 
incorporate cost into the evaluation of testing techniques. 
In  an  earlier  paper  [16],  for example, we relied  on  the 
argument  that  a  failure that  is extremely  unlikely  to hap- 
pen  is of  less concern than  one that  frequently  happens, if 
the cost of failure is the same, and conversely that a failure 
with  insignificant cost  is  of  far less concern  than one with 
catastrophic results.  This rationale was  used  to modify  a 
test  case  selection  algorithm that  had  relied  solely on  the 
frequency of input occurrence. The earlier algorithm, intro- 
duced in  [I],  selected  only those test cases  that  were most 
likely  to occur in  the field  since those were the cases  that 
were  most  likely  to impact a  user.  This sort  of  approach 
is consistent with many  informal risk assessment  processes 
which  take the viewpoint that a potential  failure that  has a 
very low probability of occurrence can safely be considered 
insignificant and therefore  be ignored  [ 141. 
Our experience has been  that if the cost or consequence 
of  failure is  high  enough,  regardless  of  how  unlikely  the 
event is to occur in the field, it is dangerous to ignore these 
inputs in testing.  The refined test  selection  algorithm pre- 
sented in  [16]  therefore recognized  that  when  a  user  was 
able to ascribe a cost to a failure, it was useful to use this in- 
formation  to modify  the apparent likelihood  of occurrence 
so that high consequent inputs were tested even if they were 
unlikely  to occur.  Other relevant  papers  involving  failure 
cost and testing include 11.51,  1131, and [7]. 
In the next section, we introduce a notion of risk that both 
builds on the traditional definition of risk, and incorporates 
the issues  we have  discussed in  this section, such as  how 
comprehensively  the software has been tested. 
3  Measuring Risk 
As explained in  Section 2, the traditional  notion  of risk 
does not have  a means for directly incorporating informa- 
tion learned  during testing to predict  software system risk. 
We now propose a new definition that rewards for test cases 
that have  been  run  without failing, penalizes  for test cases 
that  have  been  run  and  failed, and  also  penalizes  for  test 
cases  that  should have  been  run, according to the agreed- 
upon  test  case  selection method,  but  have  not  been  run. 
These test cases are treated  like test cases that have failed. 
Once  a  test  case  selection  method  has  been  chosen,  it 
can be thought of as a contractual agreement  describing, in 
some way, all of the test cases that must be run. Hopefully, 
the selection method is a good one in the sense that it really 
is  comprehensive  and  will  expose  many  failures, thereby 
giving an  accurate picture of the system’s risk.  Therefore, 
the most conservative thing to do is to behave as if any test 
cases  chosen  by  the  test  case  selection  method  that  have 
not  been  run,  would  actually  have  failed  and  thereby  con- 
tributed to the software’s risk. This is motivated  by a desire 
to assure that  the real  purpose of  the testing process  is not 
subverted  in  order to make it appear that the software is at 
low risk  of failure.  If risk only relied  on evidence  derived 
from test cases actually run, then the way to make it appear 
that software is risk-free or low risk would be to run no test 
cases, or only those that are known to run without failure. 
Of  course,  under  normal  circumstances, we  cannot ex- 
pect  to be  able to run  every  element  of  the  input domain 
during testing; a  primary  goal  of  test  case  selection  algo- 
rithms is to find  a test  set that approximates the entire in- 
put domain in some way, ideally  providing nearly as much 
information  about the software’s behavior as the entire do- 
main, at a small fraction of the cost that would be involved 
if the whole domain were run. For this reason we will intro- 
duce a new  definition  of risk that considers the proportion 
of  the  selected  or  required test  set  that  has  actually  been 
executed  in addition to the number and cost of failures ob- 
served. 
With this intuition in mind, we  introduce the following 
terminology.  Our goal  is to define risk that reflects, among 
other  factors,  the  software’s behavior  during  testing,  and 
how thoroughly the software has been  tested, relative to the 
test case  selection  method being used.  We emphasize this 
relativeness because  it is central  to our modified definition: 
the accuracy  of risk computed using  our definition  will be 
only  as good as the test case  selection method used  as the 
basis for testing. If a very  poor choice is made in terms  of 
how test cases are selected, then even if every required  test 
case has been run, it may say very little about how the soft- 
ware  will  actually  behave  and  therefore how  much  risk  is 
involved in running the software. For this reason, test case 
selection  methods based  on  actual  field  usage  are particu- 
larly appropriate for these purposes. 
In order to have our notion of risk reflect how completely 
the software has satisfied the test selection method, we must 
first  introduce another notion of  cost that we  will  call  the 
consequence.  For  test  cases  that  have  run  correctly,  we 
know that the software behaves properly on those inputs and 
therefore, there will be no contribution to the consequence 
and  hence  the risk from these inputs.  Of  course, as men- 
tioned above,  we are tacitly assuming here  that all systems 
are deterministic. 
Let S be a specification, P be a software system intended to 
18 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 03:58:16 UTC from IEEE Xplore.  Restrictions apply. 
implement S, T be a test set used to test P according to test 
selection method M ,  i be an element of the input domain, 
and c(i) and cost(i) be defined as in Section 2. Then we de- 
fine the consequence c Of  running 
€  T ,  
selected by method  M ,  relative to Program p and SPecifi- 
cation S to be: 
On  test 
C(P, S, MI t )  = 
{ :!:t 
if  P  is run on input t 
( t )   otherwise. 
(3) 
Notice that with this definition, the cost will have  to be 
determined for both every  element that fails under test, and 
those test cases  that “should have  been” run  (according to 
the test selection method), but  weren’t.  All other elements 
of the domain have consequence 0 and therefore no knowl- 
edge of the cost of failure is needed  for these inputs.  This 
is in contrast to the two earlier notions of cost:  cost(i) that 
requires a non-zero cost of  failure to be computed or esti- 
mated for every element of the domain, and c(i) that only re- 
quires a non-zero cost to be associated with those elements 
of the domain that have actually been executed and failed. 
Our definition of consequence will allow us is to incor- 
porate thoroughness of testing into our notion of risk in the 
following way.  Once we have  settled on  a test case selec- 
tion method M ,  which  chooses a test  set T ,  then  in  order 
for the software to be thoroughly tested, all of the elements 
of T must actually be run. Any elements of T that have not 
been run, will be thought of as contributing to the risk asso- 
ciated with the software. We therefore associate with those 
t  E T that have not been  run, the cost of failure o f t ,  treat- 
ing it as if it had failed since we have no evidence to cause 
us to believe otherwise. Notice that this definition does not 
deal  with the case  when  the test  selection method  M  is  a 
poor one. It assumes that that issue has been carefully dealt 
with and  so at the time risk is being computed, all parties 
have agreed that A4 is an acceptable level of testing for this 
application. 
Since our notion of risk will rely  on the consequence of 
failure for a  given  (dynamically) run  test  set, plus  a rela- 
tively  small number of  inputs that  were  not  executed, this 
fact should significantly simplify the application of our def- 
inition  of  risk  for  real  software  systems.  Below  we  will 
address ways of dealing with “insufficient” test sets. 
We now define the risk R(P,S,M,T) to be: 
R(P, SI M ,  T )  = 
Pr(t)C(P, SI Ad, t )  
(4) 
The definition of Pr(t) will vary with the test case selec- 
tion method being used.  Note,  however,  that regardless  of 
how Pr(t) is defined, we have defined C in such a way that 
if all required test cases have been run, and no failures have 
been observed, then the risk will be assessed to be 0. 
19 
4  Applying the Risk Definition 
In this section,  we will  provide  some examples  of  test 
case selection methods, and show how the choice of method 
affects the notion of Pr(t) accordingly.  We will use the fol- 
lowing simple example for illustration. 
Assume  there  are  a total  of  1,000 different  customers, 
or customer categories corresponding to many  more actual 
customers. If categories are used, they could be determined 
by  any  of a number of characteristics including dollar vol- 
ume, business volume, or number of  customers in a given 
plan. The customers near the top of the table are the biggest, 
and best customers. They are the ones about which the com- 
pany  is most concerned  if there  is a failure and so there is 
a  very  high  failure cost  associated  with  them.  In  this ex- 
ample, customer  il  accounts  for more  than  a  third  of  the 
company’s business and has a correspondingly high conse- 
quence of failure.  Notice that i g  has a similar high cost of 
failure associated  with  it even  though it represents a much 
smaller probability of occurrence, indicating a smaller vol- 