### Decentralized Federated Learning for Model and Data Privacy

**Publication Details:**
- **Title:** Decentralized Federated Learning Preserves Model and Data Privacy
- **Type:** Preprint
- **Date:** November 2020
- **Authors:**
  - Thorsten Wittkopp, Technische Universität Berlin (18 Publications, 66 Citations)
  - Alexander Acker, Technische Universität Berlin (42 Publications, 302 Citations)
- **Link:** [ResearchGate](https://www.researchgate.net/publication/345718502)

**Abstract:**
The increasing complexity of IT systems necessitates solutions that support operations during failures. Artificial Intelligence for System Operations (AIOps) is a growing research area in both academia and industry. A major challenge in AIOps is the lack of access to adequately labeled data, often due to legal or industrial confidentiality. Federated learning, which does not require direct access to training data, can address this issue. However, traditional federated learning methods involve a central instance for model synchronization, which can be a single point of failure and may compromise data privacy. To overcome these limitations, we propose a fully decentralized approach that allows knowledge sharing between trained models without transmitting original training data or model parameters. Our method uses teacher and student roles, where students are trained on the output of teachers using synthetically generated input data. We demonstrate the effectiveness of our approach through a case study on log anomaly detection, showing that untrained student models achieve comparable F1-scores to their teachers.

**Keywords:**
- AIOps
- Federated Learning
- Knowledge Representation
- Anomaly Detection
- Transfer Learning

---

### 1. Introduction

IT systems are expanding rapidly to meet the increasing demand for various applications and services, such as content streaming, cloud computing, and distributed storage. This expansion leads to a growing number of interconnected devices, large networks, and data centers. Additionally, there is a rising awareness of data privacy and confidentiality, particularly in the commercial sector. Companies rely on private cloud, network, and storage providers to deploy and maintain their solutions. Remote operation and maintenance, combined with system complexity, place significant pressure on human operators, especially during problems. Monitoring solutions, enhanced by machine learning (ML) and artificial intelligence (AI), are used to support system operations, a field known as AIOps. Examples include early detection of system anomalies, root cause analysis, and automated remediation.

Most ML and AI methods require training data. For anomaly detection, a common approach is to collect monitoring data (e.g., logs, traces, metrics) during normal system operation and use it to train models. These models detect deviations from the learned normal state, labeled as anomalies. AIOps systems need an initial training phase to adapt to the target environment, known as the cold start problem. Deployed systems at different sites are often similar (e.g., OpenStack-based private clouds, HDFS-based storage systems, ONAP-based network orchestration). Using training data from existing sites could mitigate the cold start problem and improve model performance. However, sharing data or model parameters is usually not possible due to confidentiality or legal restrictions.

Federated learning, a form of distributed learning, allows access to locally available training data while preserving data privacy. We propose a method that enables different deployments of the same system to synchronize their anomaly detection models without exchanging training data or model parameters. Our method does not require a central instance for model aggregation, improving scalability. We introduce a concept of student and teacher roles, where student models learn from teachers using randomly generated input vectors. We conduct a case study on log anomaly detection for the Hadoop File System (HDFS), demonstrating that our solution can mitigate the cold start problem and allow holistic training of distributed models.

---

### 2. Related Work

Federated learning is a distributed machine learning method where model training occurs locally within the data owner's environment without sending training data to a central server. Initially proposed by McMahan et al. [8], federated learning involves clients sending model weights or gradients to a central instance, which aggregates them into a holistic model. Yang et al. [9] categorize federated learning into vertical, horizontal, and federated transfer learning. Despite its benefits, federated learning has been shown to be vulnerable to attacks that can reconstruct training data from transmitted weights or gradients [10]. Techniques such as model inversion [11] and membership inference [12] can compromise data privacy. Various privacy-preserving methods, including obfuscation of input data [13] and model prediction output [14], have been introduced. Geyer et al. [15] applied differential privacy on the client side, and Shokri and Shmatikov [6] selected small subsets of model parameters to prevent data reconstruction. However, these methods still require sharing model parameters or gradients with a central instance, which can be a bottleneck for scalability [16].

In the context of AIOps, federated learning has been applied to anomaly and intrusion detection. Liu et al. [18, 19] proposed a deep time series anomaly detection model trained locally on IoT devices via federated learning, which could be adapted for AIOps-related problems like CPU utilization or network traffic monitoring. Nguyen et al. [17] developed D-IoT, a system for detecting compromised devices in IoT networks using unsupervised federated learning. Preuveneers et al. [20] created an intrusion detection system based on autoencoder models, with model parameter exchange secured by a permissioned blockchain.

---

### 3. Decentralized Federated Learning

#### 3.1 Problem Definition and Preliminaries

We propose a federated learning method for a setup where a set of models Φ = {φ₁, φ₂, ...} are deployed in environments E = {e₁, e₂, ...}. Each model φᵢ in environment eⱼ performs a task T. All models performing the same task T are combined into a set of workers W_T = {(φᵢ, eⱼ)}. Each model has access to local training data but cannot directly access data from other environments. The goal is to synchronize the models so that they perform well on data from all environments:

\[ P(T, \phi_i, X_{ej}) \approx P(T, \phi_j, X_{ei}) \]

Each model φ is defined as a transformation function φ: X^d₁ → Y^d₂, where d₁ and d₂ are the input and output dimensions. Since no original training data can be shared, we define an input data range \(\tilde{X}\) that allows drawing samples \(\tilde{x} \sim \tilde{X}^{d₁}\) within the range of the original training data. Models can adopt the role of teachers φ(t) and students φ(s). Student models are trained on the output of teachers, using a knowledge representation r = {(\(\tilde{x}\), γ(φ(t)(\(\tilde{x}\))): \(\tilde{x} \sim \tilde{X}^{d₁}\)}, where γ is a transformation function. The objective is to minimize the loss between the output of teacher and student models:

\[ \arg\min L(γ(φ(t)(\tilde{x})), φ(s)(\tilde{x})) \]

where θ(s) are the parameters of the student model.

#### 3.2 The Concept of Teachers and Students

In our method, each model can adopt the role of a teacher or student. Teachers provide a knowledge representation to train student models. The process involves four steps:
1. **Initial Train:** Models are trained on locally available data.
2. **Adapt Teacher Role and Build Knowledge Representation:** Models generate knowledge representations using auxiliary input data.
3. **Distribute Knowledge Representation:** Knowledge representations are shared among environments.
4. **Adapt Student Role and Train on Teacher Knowledge Representation:** Models retrain on received knowledge representations.

Figure 1 illustrates this process with four environments (A-D). Initially, all models are trained on local data. Then, models become teachers, generating knowledge representations. These representations are distributed, and models with lower scores are dropped. Models with higher or equal scores become students and retrain on the received knowledge representations.

![Multi-Cluster Learning Process](fig1.png)

#### 3.3 Loss Function

During the training of student models, the objective is to learn the transformed outputs of a teacher for a given input. We use the tanh function to restrict teacher model outputs to the range [-1, 1], stabilizing the training process. The student model uses the smooth L1 loss function, which calculates the absolute element-wise distance and applies a square operation if the distance is below 1. This loss function is less sensitive to outliers and prevents exploding gradients.

---

### 4. Evaluation

We evaluate our method on a case study of log anomaly detection using a Long Short-Term Memory (LSTM) neural network, DeepLog [2]. DeepLog predicts the next log entry based on a sequence of preceding log entries. Our decentralized federated learning method can be applied to any machine learning model trainable via gradient descent. We use the labeled HDFS dataset, which consists of 11,175,629 log lines from a Hadoop distributed file system deployed on 203 nodes in the Amazon EC2 platform [22]. The dataset includes 570,204 labeled log sequences. Raw log entries are highly variant, so we preprocess them to reduce the number of prediction targets. Log messages are transformed into templates using Drain [23]. The set of templates is used as discrete input and prediction targets.

---

### 5. Conclusion

Our proposed decentralized federated learning method addresses the challenges of data and model privacy in AIOps. By eliminating the need for a central instance and using teacher-student roles, our approach allows for scalable and secure knowledge sharing. The case study on log anomaly detection demonstrates the effectiveness of our method, showing that untrained student models can achieve comparable performance to their teachers. Future work will focus on extending this approach to other AIOps tasks and further enhancing the privacy and security of the learning process.