See discussions, stats, and author profiles for this publication at: https://www.researchgate.net/publication/345718502
Decentralized Federated Learning Preserves Model and Data Privacy
Preprint · November 2020
CITATIONS READS
0 377
2 authors:
Thorsten Wittkopp Alexander Acker
Technische Universität Berlin Technische Universität Berlin
18 PUBLICATIONS 66 CITATIONS 42 PUBLICATIONS 302 CITATIONS
SEE PROFILE SEE PROFILE
Some of the authors of this publication are also working on these related projects:
Self-Healing Cloud Platform View project
All content following this page was uploaded by Thorsten Wittkopp on 11 November 2020.
The user has requested enhancement of the downloaded file.
Decentralized Federated Learning Preserves
Model and Data Privacy
Thorsten Wittkopp12 and Alexander Acker12
Technische Universita¨t Berlin, Germany1
{t.wittkopp,alexander.acker}@tu-berlin.de
Equal contribution2
Abstract. The increasing complexity of IT systems requires solutions,
that support operations in case of failure. Therefore, Artificial Intelli-
gence for System Operations (AIOps) is a field of research that is be-
coming increasingly focused, both in academia and industry. One of the
majorissuesofthisareaisthelackofaccesstoadequatelylabeleddata,
which is majorly due to legal protection regulations or industrial con-
fidentiality. Methods to mitigate this stir from the area of federated
learning, whereby no direct access to training data is required. Original
approaches utilize a central instance to perform the model synchroniza-
tion by periodical aggregation of all model parameters. However, there
are many scenarios where trained models cannot be published since its
either confidential knowledge or training data could be reconstructed
from them. Furthermore the central instance needs to be trusted and
is a single point of failure. As a solution, we propose a fully decentral-
izedapproach,whichallowstoshareknowledgebetweentrainedmodels.
Neitheroriginaltrainingdatanormodelparametersneedtobetransmit-
ted.Theconceptreliesonteacherandstudentrolesthatareassignedto
the models, whereby students are trained on the output of their teach-
ers via synthetically generated input data. We conduct a case study
on log anomaly detection. The results show that an untrained student
model, trained on the teachers output reaches comparable F1-scores as
the teacher. In addition, we demonstrate that our method allows the
synchronization of several models trained on different distinct training
data subsets.
Keywords:
AIOps·FederatedLearning·KnowledgeRepresentation·AnomalyDe-
tection · Transfer Learning
1 Introduction
IT systems are expanding rapidly to satisfy the increasing demand for a variety
of applications and services in areas such as content streaming, cloud comput-
ing or distributed storage. This entails an increasing number of interconnected
devices, large networks and growing data centres to provide the required in-
frastructure [1]. Additionally, awareness for data privacy and confidentiality is
2 T. Wittkopp and A. Acker
rising especially in commercial industry. Big- and middle-sized companies are
relying on private cloud, network and storage providers to deploy and main-
tain according solutions. Except for severe problems that require local access,
the operation and maintenance is done remotely. Remote access together with
thegrowingsystemcomplexityputsextremepressureonhumanoperatorsespe-
ciallywhenproblemsoccur.Tomaintaincontrolandcomplywithdefinedservice
level agreements, operators are in need of assistance. Therefore, monitoring so-
lutions are combined with methods from machine learning (ML) and artificial
intelligence to support the operation and maintenance of those systems - usu-
ally referred to as AIOps. Examples of concrete solutions are early detection of
system anomalies [2,3], root cause analysis [4], recommendation and automated
remediation [5].
The majority of ML and AI methods relies on training data. In case of
anomaly detection a common approach is to collect monitoring data such as
logs,tracesormetricsduringnormalsystemoperationandutilizethemtotrain
models. Representing the normal system state, these models are utilized to de-
tect deviations from the learned representation which are labeled as anomalies.
Therefore, AIOps systems require preliminary training phases to adjust to the
targetenvironmentuntiltheycanbeutilizedfordetection.Thisisknownascold
start problem. Although adjusted to customer requirements, deployed systems
at different sites are very similar (e.g. private cloud solutions based on Open-
Stack,storagesystemsbasedonHDFSornetworkorchestrationviaONAP).An
obvious mitigation of the cold start problem would be to use training data from
existingsitestotrainmodelsandfinetunethemafterdeploymentwithinatarget
customer site. Furthermore, training data used from a variety of sites increases
the holisticity of models allowing them to perform generally better. However,
sharing data or modelparameters, even ifindirectly relatedwith company busi-
ness cases, is usually not possible due to confidentiality or legal restrictions [6].
Federated learning as a special form of distributed learning is gaining in-
creased attention since it allows access to a variety of locally available training
data and aims to preserve data privacy [6,7]. Utilizing this concept, we propose
a method that allows different deployments of the same system to synchronize
their anomaly detection models without exchanging training data or model pa-
rameters. It does not require a central instance for model aggregation and thus,
improves scalability. We introduce a concept of student and teacher roles for
models whereby student models are learning from teachers. As input, vectors
that are randomly generated within a constrained value range are used as input
to both, student and teacher models. Student models are trained on the output
of teachers. We conduct a case study based on log anomaly detection for the
Hadoop File System (HDFS). In a first experiment it is shown that our solu-
tion can mitigate the cold start problem. A second experiment reveals that the
proposedmethodcanbeutilizedtoholisticallytraindistributedmodels.Models
thatweretrainedbyourmethodachievecomparableresultstoamodelthatwas
trained on the complete training dataset.
Decentralized Federated Learning 3
The rest of this paper is structured as follows. First, section 2 gives an
overview of federated learning and applied federated learning in the field of
AIOps. Second, section 3 describes the our proposed method together with rel-
evant preliminaries. Third, section 4 presents the conducted case study and ex-
periment results. Finally, section 5 concludes our work.
2 Related Work
Federated learning is a form of distributed machine learning method. Thereby,
model training is done locally within the environment of the data owner with-
out sending training data to a central server. Locality is defined within the
boundaries of the data owner’s private IT environment. Initially this concept
was was proposed by McMahan et al. [8]. Instead of training data, either model
weightsorgradientsfromclientsaresenttoacentralinstancewhichaggregated
them to a holistic model during model training. Updated models are sent back
to the clients. Yang et al. [9] provide a categorization, which are vertical fed-
erated learning, horizontal federated learning and federated transfer learning.
Despite preventing direct data exchange, publications revealed possibilities to
restore training data from constantly transmitted weights or gradients, which
violates the data privacy requirement [10]. For an adversary it is possible to
recover the training dataset by using a model inversion attack [11] or determine
whether a sample is part of the training dataset by using a membership infer-
ence attack [12]. Since reconstruction of original training data is possible when
observing model changes [11,12] different privacy preserving methods are intro-
duced. These are focused on obfuscation of input data [13] or model prediction
output[14].Geyeretal.[15]applieddifferentialprivacypreservingonclientside
to realize privacy protection. Shokri and Shmatikov [6] select small subsets of
modelparameterstobesharedinordertopreventdatareconstruction.However,
model parameters or gradients still need to be shared with a central instance.
Furthermore, the requirement of a central instance is a major bottleneck for
scalability [16].
Application of federated learning in the field of AIOps is mainly focused
around anomaly [17–19] and intrusion detection [20,21]. Liu et al. [19,18] pro-
poseadeeptimeseriesanomalydetectionmodelwhichistrainedlocallyonIoT
devicesviafederatedlearning.AlthoughnotdirectlyappliedonanAIOpsrelated
problem,theproposedmethodcouldbeappliedtoperformanomalydetectionon
time series like CPU utilization or network traffic statistics of the device itself.
Nguyen et al. [17] propose their system D¨IoT for detecting compromised de-
vicesinIoTnetworks.Itutilizesanautomatedtechniquefordevice-typespecific
anomaly detection. The unsupervised training is done via federated learning in-
dividuallyoneachdeviceintheIoTenvironment.Preuveneersetal.[20]develop
anintrusiondetectionsystembasedonautoencodermodels.Themodelparame-
ter exchange is coupled with a permissioned blockchain to provide integrity and
prevent adversaries to alter the distributed training process.
4 T. Wittkopp and A. Acker
3 Decentralized Federated Learning
In this chapter we present our method for decentralized federated learning that
aims at preservation of model and data privacy. Thereby, models that were
trained on individual and partly distinct training sets are synchronized. Beside
preservingdataprivacy,thenoveltyofourmethodisthedispensabilityofmodel
parameter sharing. We illustrate the entire process of local training and global
knowledge distribution. To realize latter, the communication process between a
set of entities is described.
3.1 Problem Definition and Preliminaries
Toapplyourproposedfederatedlearningmethodweassumethefollowingsetup.
Let Φ = {φ ,φ ,...} be a set of models and E = {e ,e ,...} a set of environ-
1 2 1 2
ments. We define a model deployed in a certain environment as a tuple (φ ,e ).
i j
AllmodelsthatperformthesametaskT intheirenvironmentarecombinedinto
a set of workers W = {(φ ,e )}. Each model φ has access to locally available
T i j i
training data but cannot directly access training data from other environments.
Furthermore, neither gradients nor model parameters can be shared outside of
their environment. Having a function P(T,φ ,X ) that measures how well a
i ej
model φ is performing the task T on data X from environment e , the goal is
i ej j
to synchronize the model training in a way that all models can perform well on
data from all environments:
P(T,φ ,X )≈P(T,φ ,X )≈...≈P(Tφ ,X )≈P(T,φ ,X )≈... (1)
1 e1 1 e2 2 e1 2 e2
Each model φ is defined as a transformation function φ:Xd1 →Yd2 of a given
i
input x ∈ Xd1 into an output y ∈ Yd2, where d and d are the corresponding
1 2
dimensions.Sincenooriginaltrainingdatacanbesharedbetweenenvironments,
we define an input data range X˜. It allows to draw data samples x˜ ∼X˜d1 that
are restricted to the range of the original training data but otherwise are not
related to samples of the original training data set Xd1. Models can adopt the
role of teachers φ(t) and students φ(s). Student models are directly trained on
i i
the output of teachers. We refer to a training set that is generated by a teacher
as knowledge representation, formally defined as a set of tuples:
r ={(x˜,γ(φ(t)(x˜)):x˜∼X˜d1}. (2)
i
Thereby γ is a transformation function that is applied on the teacher model
output. Student models φ(s) are trained on the knowledge representations of
i
teachers. The objective is to minimize the loss between the output of teacher
and student models
argminL(γ(φ(t)(x˜)),φ(s)(x˜)). (3)
i j
θ(s)
j
where θ(s) are parameters of the student model φ(s)(x˜).
j j
Decentralized Federated Learning 5
3.2 The Concept of Teachers and Students
For the training process itself we introduce the teacher student concept. Every
model can adopt the role of a student or teacher. A teacher model trains stu-
dent models by providing a knowledge representation. First, we assume a set of
models, each performing the same task in their own local environment. These
models are trained on the same objective but only with the locally available
training data. To prevent the sharing of training data or model parameter be-
tweenenvironments,modelsareadaptingrolesofteacherstotrainstudentmod-
els within other environments. Overall, this process is realized by four steps: (1)
InitialTrain,(2)adaptteacherroleandbuildknowledgerepresentation,(3)dis-
tributeknowledgerepresentationand(4)adaptstudentroleandtrainonteacher
knowledge representation. Figure 1 visualizes these steps the overall layout of
each phase. The example shows four environments A-D with locally available
Initial Train Build KR Distribute KR Learn KR
Train Train Score KR Score KR Score KR Score KR
Set Set KKRR KKRR
A B A B A B A B
C D C D C D C D
Train Train KKRR KKRR
Set Set Score KR Score KR Score KR Score KR
Fig.1. The process of multi-cluster learning
training sets. Initially, all models are trained on the locally available training
data.Afterthat,modelsadapttheroleofteachersandrespectivelygeneratethe
knowledgerepresentations.Thereby,auxiliaryinputdataaregeneratedfromthe
value range of locally available training data. This range must be synchronized
acrossallenvironments.Otherwise,thereisnoconnectiontooriginallocaltrain-
ing data that was used to train models within their environments. Additionally,
a score is calculated that reflects how well a model is performing on the task.
Next,theknowledgerepresentationsaredistributed.Afterreceivingaknowledge
representation, a model checks the attached score and compares it with its lo-
calscore.Representationswithlowerscoresaredropped.Whenreceivinghigher
or equal scores, the models adapts the role of a student and is trained on the
received knowledge representation. Through this process each model will be re-
trainedandupdated.Notethatthelossfunctionusedduringtheinitialtraining
can differ from the loss function used for knowledge representation learning.
6 T. Wittkopp and A. Acker
3.3 Loss Function
During training of student models the objective is to directly learn the trans-
formed outputs of a teacher for a given input. We utilize the tanh as the trans-
formation function to restrict teacher model outputs to the range [−1,1]. This
restriction should reduce the output value range and thus, stabilize the training
process and accelerate convergence. Therefore, the student needs a loss function
that can minimize the loss for every element from it’s own output against the
output vector of the teacher. This requires a regressive loss function. We uti-
lize the smooth L1 loss which calculates the absolute element-wise distance. If
this distance falls below 1 additionally a square operation is applied on it. It is
less sensitive to outliers than the mean square error loss and prevents exploding
gradients.
4 Evaluation
The evaluation of our method is done on the case study of log anomaly detec-
tion by utilizing a LSTM based neural network, called DeepLog [2]. DeepLog is
trained on the task of predicting the next log based on a sequence of preceding
logentries.Howeverourdecentralizedfederatedlearningmethodcanbeapplied
to any other machine learning model that is trainable via gradient descent. We
utilize the labeled HDFS data set, which is a log data set collected from the
Hadoop distributed file system deployed on a cluster of 203 nodes within the
Amazon EC2 platform [22]. This data set consists of 11,175,629 log lines that
formatotalof570,204labeledlogsequences.However,rawlogentriesarehighly
variant which entails a large number of prediction options. Thus, a preprocess-
ing is applied to reduce the number of possible prediction targets. Log messages
are transformed into templates consisting of a constant and variable part. The
constant templates are used as discrete input and prediction target. The task of
template parsing is executed by Drain [23]. We refer to the set of templates as