Figure 11 (a) shows the permission distributions where we com-
pute the percentage of icons under each permission group. As we
can see, directly using manifest files introduces many unused per-
missions. For example, there are three times more icons with CAMERA
and CONTACTS permissions by using the manifest files. This ratio is
even larger for STORAGE and CALL.
Figure 11 (b) shows the precision and recall results of the re-
trained model with permissions from manifest files. The results of
DeepIntent are also plotted with a wider rectangle and lighter
color. As we can see, the precision results of the re-trained model
decrease dramatically in many cases while the recall results stay
high. This is consistent with our intuition that using more permis-
sions for training tends to predict more permissions on the test set,
which could dramatically degenerate the precision performance.
On average, the precision result of DeepIntent is 0.9419 while that
of the re-trained model is 0.5515.
Overall, the results show that our icon-behavior association module
is essential to accurately extract icon-permission mappings for the
learning of the icon-behavior model.
7.3.3 RQ3: Detecting Intention-Behavior Discrepancies. For RQ3,
we evaluate the effectiveness of DeepIntent in terms of detect-
ing the intention-behavior discrepancies. DeepIntent returns a
ranked list based on the outlier score of each test icon widget. We
adopt the top-K precision/recall and AUC metrics based on the
manually labeled benign and malicious test sets. To choose a best
group-wise detector, we also evaluate the effectiveness of differ-
ent group-wise detectors and different aggregation methods with
DeepIntent. Finally, to show the superiority of DeepIntent in de-
tecting discrepancies, we further compare DeepIntent with other
outlier detectors based on IconIntent and part of the features used
by DeepIntent. The results are shown in Tables 4 - 7 and Figure 12.
Detection accuracy over permission groups. Table 4 shows the
results for each permission group. The first column is the type of
test set. The precision/recall column is based on the top-K results
0.00.20.40.60.81.0NETWORKLOCATIONMICROPHONESMSCAMERACALLSTORAGECONTACTSProgram AnalysisManifest FileNETWORKLOCATIONMICROPHONESMSCAMERACALLSTORAGECONTACTS0.00.20.40.60.81.0Precision (Analysis)Precision (Manifest)Recall (Analysis)Recall (Manifest)Type
benign
malicious
Method
KNN
OCSVM
IForest
KNN
OCSVM
IForest
AutoEncoder
AutoEncoder
AUC
0.8614
0.8493
0.8345
0.8656
0.8922
0.8539
0.8640
0.8839
Table 5: Detection accuracy results using different group-
wise outlier detectors. These detectors perform relatively
close to each other, and we adopt AutoEncoder due to its ef-
ficiency and simplicity.
Type
benign
malicious
Method
mean
distance-based
prediction-based
combined
mean
distance-based
prediction-based
combined
AUC
0.7368
0.8211
0.8313
0.8656
0.7914
0.8484
0.8605
0.8839
Table 6: Detection accuracy results using different aggrega-
tion methods. AUC = 0.5 means random guess. The com-
bined aggregation performs best.
when K is set to the real number of labeled intention-behavior
discrepancies; therefore, the precision and recall have the same
value in this case. The AUC column stands for the AUC value when
we vary K from zero to the test set size. The permission groups
MICROPHONE and CALL in the malicious test set are marked as ‘-’. This
is because the malicious apps we collected rarely contain these two
permissions.
We can first observe from the table that, in general, DeepIn-
tent can accurately detect the intention-behavior discrepancies.
For example, the precision and recall results are all above 0.9 for
SMS, CAMERA, STORAGE, and CONTACTS in the malicious test set. These
permissions are widely adopted by malicious apps to steal user
information and perform monetized actions. Second, although still
effective, the detection accuracy is relatively lower in LOCATION. The
probable reason is that many icons such as refreshing the restaurant
recommendations will update the screen using the current location;
however, this intention is hardly to observe from the UI. Third, the
performance in the NETWORK group is relatively low. This is due to the
fact that many icons with many different looks and purposes are
related to the network permissions, making it difficult to recognize
the discrepancies.
Group-wise Detectors and Aggregation Methods. In our discrep-
ancy detection, we have four group-wise detectors and three ag-
gregation methods. Table 5 and Table 6 show the results of these
choices. In Table 5, we use each outlier detector to substitute the
AutoEncoder as described in Section 6.2, followed by the combined
aggregation method. We can observe that all the four detectors
Type
benign
malicious
Method
IconIntent
icon_only
text_only
prediction
DeepIntent
IconIntent
icon_only
text_only
prediction
DeepIntent
AUC
0.6188
0.7618
0.7739
0.7991
0.8656
0.7009
0.7537
0.7752
0.8122
0.8839
Table 7: Detection accuracy comparisons. DeepIntent sig-
nificantly outperforms the competitors.
perform relatively close to each other, and we adopt AutoEncoder
in this work due to its simplicity and efficiency. For Table 6, we
report the results of different aggregation methods. We also show
the results when we simply compute the mean outlier score from
group-wise detectors (referred as ‘mean’ in the table). We can see
that, compared with ‘mean’ aggregation, both distance-based aggre-
gation and prediction-based aggregation can achieve much higher
accuracy in terms of correctly identifying the intention-behavior
discrepancies. Furthermore, combining these two aggregation meth-
ods can achieve further improvement. In this work, we adopt the
combined aggregation method.
Comparisons for Outlier Detection. Finally, we compare DeepIn-
tent with several competitors in terms of identifying the intention-
behavior discrepancies. The average AUC results are shown in
Table 7. We include 4 competitors. For IconIntent, we input the
extracted features into our outlier detection module. For ‘icon_only’
and ‘text_only’, we use only the image features and text features,
respectively. For ‘prediction’, we directly use the predicted results
from our icon-behavior model to detect the discrepancies.
The results show that DeepIntent significantly outperforms the
competitors. Compared with IconIntent, DeepIntent achieves
39.9% and 26.1% improvements on the benign apps and the malicious
apps, respectively. This result, again, indicates that the extracted
features by DeepIntent are more accurate. DeepIntent is also bet-
ter than ‘icon_only’ and ‘text_only’, which means that combining
icon and text features are also useful for discrepancy detection. Fi-
nally, DeepIntent outperforms the ‘prediction’ method. This result
is consistent with our motivation of evolving an outlier detection
module after the behavior prediction module (Section 6).
To further inspect the performance of DeepIntent, we show
its precision and recall curves in Figure 12. In the figure, the y-
axis means precision/recall, the x-axis is the K (i.e., choosing top
K candidates based on the final outlier scores), and the dashed
vertical line means the real number of labeled outliers. Intuitively,
the larger the area under the curve, the better the method. In the
figure, we also plot the theory results of the ‘random’ method which
randomly identifies the outliers for comparison. We can observe
from the figure that both curves of DeepIntent are significantly
better than the ‘random’ method. Take the malicious test set (the
right part of Figure 12) as an example. When K is less than the
real number of outliers (i.e., K < 865), the precision results are
non-UI events for using the microphone, existing malware detec-
tion techniques [83] can be leveraged to detect non-UI permission
misuses. Finally, we admit that, as a potential evasion technique, an
attacker may collect the data as we did from the whole app market
and try to hide their malicious behaviors in benign behaviors with
specific UIs. However, summarizing these benign behavior patterns
and extracting them from the learned model are non-trivial, espe-
cially given the model is trained using deep learning. As a result,
our technique significantly raises the bar for potential attacks.
9 RELATED WORK
UI Analysis of Mobile Apps. AsDroid [33] checks the compati-
bility of the UI widgets’ descriptive texts and the pre-defined inten-
tions represented by its sensitive APIs. SUPOR, UIPicker, Uiref [4,
31, 51] analyze the descriptive texts in apps’ UI for identifying sen-
sitive UI widgets that accept user inputs. PERUIM [40] extracts the
permission-UI mappings from an app based on both dynamic and
static analysis, helping users understand the requested permissions.
Liu et al. [45] propose an automatic approach for annotating mobile
UI elements with both structural semantics such as buttons or tool-
bars and functional semantics such as add or search. AppIntent [85]
presents the sequence of UI screenshots that can lead to sensitive
data transmissions of an app for human analysts to review. None
of them model both icons and texts to detect abnormal behaviors.
Textual Analysis on Mobile Apps. WHYPER [56] and Autocog [58]
adapt Natural Language Processing (NLP) techniques to identify
sentences in app descriptions that explain the permission uses.
BidText [32] detects sensitive data disclosures by performing bi-
directional data flow analysis to detect variables that are at the
sink points and are correlated with sensitive text labels. Pluto [14]
analyzes app files to identify user data exposure to ad libraries.
There are also existing techniques that leverage the textual infor-
mation from code to infer the purposes of permission uses [76],
and synthesize natural language descriptions for the data flow be-
havior in using users’ sensitive data [88]. Unlike these approaches
that map text to sensitive data directly, our text analysis uses the
contextual texts for icon widgets as part of the features to learn the
intention-behavior model.
Android Static Analysis. Existing work [5, 79] has provided ap-
proaches to build call graphs that consider Android’s complex en-
vironment. However, their focus is to enumerate all possible com-
binations of lifecycle methods for improving the precision of static
analysis, which will cause lots of false positives if used for build-
ing a UI handler’s call graph. AppAudit [13] proposes a solution
for handling Android multi-threading, system/GUI callbacks, and
lifecycle methods to build extended call graph, and it combines
dynamic analysis on filtering false positive call edges. DeepIntent
can further benefit from its techniques to improve the call graph
construction. There also exists a line of related work [37, 53–55, 91]
that leverages program analysis and machine learning techniques to
identify the ICCs in Android apps. The ICC analysis of DeepIntent
is built on these work.
Modeling Image and Text. Images and texts could be modeled
separately or jointly. For example, CNNs (e.g., VGG [67], ResNet [26],
and DenseNet [30]) are widely used in modeling images; RNNs as
Figure 12: Detection precision and recall for benign apps
(left) and malicious apps (right).
always above 0.85. In other words, when the returned number of
icons is less than 865, over 85% of them have intention-behavior
discrepancies.
Overall, the results show that DeepIntent can accurately identify
the intention-behavior discrepancies in mobile apps.
8 DISCUSSION
Icon-Behavior Association. DeepIntent adapts static analysis
to extract the icon-permission mappings. While the static analy-
sis takes into account the major factors introduced by Android’s
complex environment (i.e., multi-threading, lifecycle methods, and
ICCs), apps may evade our analysis by invoking sensitive APIs via
reflections and native libraries. In the future, we plan to incorporate
more advanced instrumentation techniques and dynamic analysis
techniques to deal with reflections and native libraries [38, 39].
Moreover, the static analysis can produce incorrect associations
between UI handlers and UI widgets due to its overapproaxima-
tions. We plan to mitigate such issues using dynamic exploration
techniques to filter out false associations [25, 48, 70].
Deep Icon-Behavior Learning. We consider the limitations of
our learning within two aspects. First, DeepIntent is trained with
certain data and could only react with similar icons within the
training set. When DeepIntent meets new icons or noisy icons,
the performance is non-deterministic. Furthermore, icons gener-
ated by recent deep learning attack models may also compromise
DeepIntent. Second, we use contextual texts to enhance the icon-
behavior learning process, but the vocabulary of DeepIntent is
limited. This problem also troubles other natural language process-
ing approaches, which is known as OOV (i.e., out of vocabulary)
problem. Although we could use special characters like ‘UNK’ to
indicate these words, the overall performance will drop.
Adversarial Setting. Our model is learned from the behaviors col-
lected from a large set of popular apps in Google Play, representing
the expected behaviors of apps with specific UIs. To avoid our de-
tection, adversary apps may camouflage their undesired behaviors
in apps with legitimate UIs and features for the undesired behav-
iors. For example, an eavesdropping app may pretend to be a voice
recording app that has a UI widget with a microphone icon to use
the microphone legitimately. With DeepIntent, if the app tries to
send out the recorded audio, the extra permission on NETWORK will
reveal its differences and can be detected. If the app tries to use
0250500750100012500.00.20.40.60.81.0025050075010001250Top-KPrecision/RecallPrecision (DeepIntent)Recall (DeepIntent)Precision (Random)Recall (Random)well as attention mechanisms [84], sequence to sequence struc-
tures [8], and memory networks [71] are employed to handle text-
related tasks. Recently, Lu et al. [47] and Zhang et al. [89] present
a co-attention mechanism to jointly model images and texts. Deep-
Intent trains its own DenseNet to learn the features of icons, and
further integrates the state-of-the-art network structures to co-train
icons and texts into a better feature representation.
Outlier Detection. There exist various outlier detection techniques
such as KNN [59], PCA [66], and AutoEncoder [3], which are also ap-
plied in Android analyzing scenarios. For example, CHABADA [23]
groups apps based on their topics, and identifies outliers in each
group that use abnormal APIs. MUDFLOW [7] extracts data flows
from Android apps and flags malicious apps due to their abnormal
data flows. These proposals detect app-level outliers, while Deep-
Intent considers the icon-level outliers. Moreover, one difficulty
of DeepIntent is the absence of icon-level outlier labels, and thus
we propose static analysis to obtain these labels.
10 CONCLUSION
We have presented a novel framework, DeepIntent, that syner-
gistically combines program analysis and deep learning to detect
intention-behavior discrepancies in mobile apps. In particular, Deep-
Intent includes a static analysis that handles the complex Android
environment to identify icon widgets and associate the widgets to
permission uses, applies the parallel co-attention mechanism to
jointly model icons and their contextual texts of the icon widgets,
and detects the intention-behavior discrepancies by computing and
aggregating the outlier scores from each permission used by the
icon widget. Our evaluation on a large number of real apps demon-
strates that DeepIntent effectively detects intention-behavior dis-
crepancies by checking the intentions reflected by apps’ UIs against
the behind-the-scene program behaviors.
ACKNOWLEDGMENTS
This work is supported in part by the Natural Science Founda-
tion of China (No. 61690204, 61932021, 61672274), the National
Science Foundation (CNS-1755772), and the Collaborative Innova-