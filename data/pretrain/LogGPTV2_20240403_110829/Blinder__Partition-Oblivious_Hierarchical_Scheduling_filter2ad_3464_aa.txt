title:Blinder: Partition-Oblivious Hierarchical Scheduling
author:Man-Ki Yoon and
Mengqi Liu and
Hao Chen and
Jung-Eun Kim and
Zhong Shao
Blinder: Partition-Oblivious Hierarchical Scheduling
Man-Ki Yoon, Mengqi Liu, Hao Chen, Jung-Eun Kim, and 
Zhong Shao, Yale University
https://www.usenix.org/conference/usenixsecurity21/presentation/yoon
This paper is included in the Proceedings of the 30th USENIX Security Symposium.August 11–13, 2021978-1-939133-24-3Open access to the Proceedings of the 30th USENIX Security Symposium is sponsored by USENIX.Blinder: Partition-Oblivious Hierarchical Scheduling
Man-Ki Yoon, Mengqi Liu, Hao Chen, Jung-Eun Kim, Zhong Shao
Yale University
Abstract
Hierarchical scheduling enables modular reasoning about the
temporal behavior of individual applications by partitioning
CPU time and thus isolating potential misbehavior. However,
conventional time-partitioning mechanisms fail to achieve
strong temporal isolation from a security perspective; varia-
tions in the executions of partitions can be perceived by others,
which enables an algorithmic covert timing-channel between
partitions that are completely isolated from each other in the
utilization of time. Thus, we present a run-time algorithm
that makes partitions oblivious to others’ varying behaviors
even when an adversary has full control over their timings.
It enables the use of dynamic time-partitioning mechanisms
that provide improved responsiveness, while guaranteeing
the algorithmic-level non-interference that static approaches
would achieve. From an implementation on an open-source
operating system, we evaluate the costs of the solution in
terms of the responsiveness as well as scheduling overhead.
1 Introduction
With advancement in modern computing and communica-
tion technologies, there has been an increasing trend toward
integrating a number of software applications into a high-
performance system-on-chip to reduce communication and
maintenance complexity, while allowing them to efﬁciently
utilize common hardware resources. Such a composition re-
quires that properties established for individual subsystems
be preserved at the integrated-system level. Especially for
safety-critical systems (e.g., avionics, automotive, industrial
control systems), it is of utmost importance to provide strong
isolation among applications that require different levels of
criticality in order to limit interference among them: pro-
tecting high-critical applications (e.g., instrument cluster in
digital cockpits [4]) from faulty behaviors of lower-critical
ones (e.g., infotainment system). This is increasingly chal-
lenging as individual subsystems are becoming more complex
due to advanced capabilities.
The isolation among subsystem applications is attained via
a form of resource partitioning [33]. For example, ARINC
653 (Avionics Application Standard Software Interface) [8]
standardizes time and space partitioning of applications ac-
cording to their design-assurance levels. This enables the soft-
ware functions to be developed and certiﬁed independently. In
particular, time partitioning is a key ingredient for providing
strong temporal-isolation of unpredictable interference from
timing-sensitive applications. It is enforced also in Multiple
Independent Levels of Security (MILS) systems [9] to prevent
a compromised application from exhausting time resources.
Operating in the form of two-level hierarchical scheduling
architecture [6, 14], as shown in Figure 1, it provides each
application with the illusion of exclusive CPU resources.
However, such a tight integration of applications poses a
security challenge that could have been easily addressed in
the air-gapped environment. In particular, we observe that
conventional hierarchical scheduling schemes enable illegit-
imate information-ﬂow among partitions that are supposed
to be isolated from one another. As multiple threads sharing
the CPU time can collaborate to inﬂuence one’s execution
progress and infer secret information [41, 44], time-partitions
can form algorithmic covert timing-channel by varying their
temporal behavior. In this paper, we ﬁrst demonstrate such a
vulnerability of hierarchical scheduling on existing real-time
operating systems; a partition can infer another partition’s
varying execution by observing the impact that the latter’s
execution has on its own local schedule, even without using
any time information. This algorithmic channel exists even if
microarchitectural channels [15, 24] were completely closed.
Based on these observations, we develop a run-time sched-
ule transformation algorithm that we call Blinder. It prevents
partitions from distinguishing others’ varying execution be-
havior by making each partition-local schedule determinis-
tic. Although static partitioning approaches, such as TDMA
(Time Division Multiple Access) [8], can achieve strong non-
interference due to the ﬁxed nature of the schedules that they
generate, they are inﬂexible in CPU resource usage [17, 22].
On the other hand, non-static partitioning schemes, such as
real-time server algorithms [7, 37, 39], are more amenable
to dynamic workload and achieve better responsiveness, and
thus are increasingly adopted by commercial real-time oper-
ating systems and hypervisors [3, 5]. However, such a non-
determinism, or ﬂexibility, is a double-edged sword as it is the
very source of information-ﬂow between partitions; partitions
can use CPU time in a detectable pattern to send signals.
Our Blinder deters such attempts by guaranteeing that the
local-execution state (i.e., partition-local schedule) changes
at deterministic time points no matter how the global state
USENIX Association
30th USENIX Security Symposium    2417
Algorithm 1: Schedule(ΠΠΠ,t)
Π(t) ← GlobalScheduler(ΠΠΠ,t) /* 1(cid:13) Selects partition */
if Π(t) (cid:54)= Π(t − 1) then
SuspendPartition(Π(t − 1))
end
LocalScheduler(Π(t))
/* 2(cid:13) Selects task
*/
Figure 1: Hierarchical scheduling.
changes (i.e., partition-level schedule). Hence, partitions can
be scheduled still in non-static ways (thus taking advantage
of the ﬂexibility in resource utilization) while achieving the
strong partition-obliviousness property that has been possible
only with static approaches. Blinder removes the algorithmic
covert timing-channel in hierarchical scheduling even if an
attacker is able to precisely control the timings of applications.
Furthermore, it is minimally-intrusive and modular in that
it does not require any modiﬁcations to the global and local
scheduling policies and hence can be applied to a wide variety
of existing systems that employ hierarchical scheduling.
In summary, this paper makes the following contributions:
• We demonstrate an algorithmic covert timing-channel
between time-partitions through hierarchical scheduler
of existing real-time operating systems.
• We introduce Blinder, a run-time schedule transforma-
tion algorithm that makes partitions oblivious to others’
varying temporal behavior, and we also analyze its im-
pact on the schedulability of real-time tasks.
• We implement Blinder on an open-source real-time oper-
ating system and evaluate its impact on the responsive-
ness as well as scheduling overheads.
• We demonstrate a deployment of Blinder on a prototype
real-time system and discuss system design and imple-
mentation challenges and possible mitigations.
2 Preliminaries
2.1 System Model and Terminology
We consider a real-time system that hosts N applications,
ΠΠΠ = {Π1, . . . ,ΠN}, sharing CPU time. Each application, or
partition, Πi is comprised of one or more tasks, i.e., Πi =
{τi,1,τi,2, . . . ,τi,mi}, where mi is the number of tasks in Πi.
Each task is characterized by τi, j := (pi, j,ei, j), where pi, j is
the minimum inter-arrival time (i.e., period) and ei, j is the
worst-case execution time.
The partitions are scheduled in a hierarchical manner
[8, 14] as shown in Figure 1 and Algorithm 1; the global
scheduler determines which partition to execute next at time
instant t. Let Π(t) denote the partition selected by the global
scheduler for t. Then, the tasks of Π(t) are scheduled locally
according to its local scheduling policy.
Each task is associated with a priority, Pri(τi, j), which can
be ﬁxed (e.g., Rate Monotonic (RM) [27] priority assignment)
or dynamic (e.g., Earliest Deadline First (EDF) [27]). We do
not assume any particular global and local scheduling policies.
However, simply for the ease of comprehension of the key
concepts, example schedules in the ﬁgures used throughout
this paper are based on the ﬁxed-priority global and local
schedulings. For most safety-critical systems such as avionics
and automotive systems, Rate Monotonic scheduling policy
is dominantly employed for local task scheduling due to its
stability and conservative predictability [28, 35].
Terminology: Tasks arrive to the system on a schedule or in
response to external events (e.g., interrupts). For instance, a
task can be scheduled to arrive every 100 ms for service of
a recurrent workload. The arrival time of task τi, j is denoted
by ta(τi, j). A task is said to be released if it becomes visible
to the partition to which it belongs, thus becoming available
for execution. Each partition Πi maintains a ready queue QR
i
of tasks that have been released but not been ﬁnished. The
Πi-local scheduler selects a task from QR
i (t) for each t.
Each partition Πi := (Ti,Bi) is associated with a non-
negative, maximum budget Bi; the partition cannot execute
for more than Bi (e.g., 20 ms) during a replenishment period
Ti (e.g., 100 ms). The remaining budget for time t is denoted
by Bi(t) and 0 ≤ Bi(t) ≤ Bi. No task of Πi can execute when
Bi(t) = 0. Partition Πi is said to be schedulable if it is guar-
anteed to execute for Bi over every replenishment period Ti.
Partition Πi is said to be active at t, denoted by active(Πi,
t), if it has a non-zero remaining budget and task(s) to execute,
i (t)(cid:54)= /0. Only active partitions are subject
i.e., Bi(t) > 0 and QR
to the global scheduling.
Deﬁnition 1 (Partition preemption). Partition Πi is said to
be preempted if it is not selected by the global scheduler (i.e.,
Π(t) (cid:54)= Πi) although it has a non-zero remaining budget and
has task(s) to run (i.e., it is active). That is,
Preempted(Πi,t) ≡ [Π(t) (cid:54)= Πi]∧ active(Πi,t).
2.2 Hierarchical Scheduling
Hierarchical scheduling can be categorized into two classes,
static or non-static partitionings, depending on whether parti-
tions are activated at deterministic times or not.
Static Partitioning: Commonly referred to as table-driven
scheduling, cyclic-executive, or TDMA (Time Division Multi-
ple Access) scheduling, this approach statically assigns a ﬁxed
time window of length Bi to each partition Πi, as shown in Fig-
ure 2(a). The ﬁxed schedule repeats every major cycle (MC)
which is the sum of the partition windows, i.e., MC = ∑i Bi.
Hence, each Πi effectively receives Bi/MC of CPU utiliza-
tion (e.g., 20 ms/100 ms = 20%). Π(t) is deterministic and
Π(t) = Π(t + MC) for any time t. Under the static partition-
ing scheme, the CPU is left unused if Π(t) has no task to
2418    30th USENIX Security Symposium
USENIX Association
Global Scheduler𝚷𝟏-Local SchedulerΠ!𝚷𝟐-Local Scheduler𝚷𝟑-Local Scheduler𝚷𝟒-Local SchedulerΠ"Π#Π$TasksTasksTasksTasksSelects a partition Π𝑡=Π%∈𝚷12Π𝑡-local scheduler selects a task from Π𝑡Figure 2: A comparison of static and non-static partitionings.
run even when other partitions have ready tasks. Hence, the
temporal behavior of a partition is completely isolated from
others. The IMA (Integrated Modular Avionics) architecture
of ARINC 653 standard [8] and MILS systems employ this
table-driven approach as the partition-level scheduling, and
it is implemented in commercial RTOSes such as VxWorks
653 [6] and LynxSecure [1].
The simplicity in the temporal reasoning comes at the cost
of inﬂexibility of resource usage. As shown in Figure 2(a),
tasks (e.g., τ1,2) may experience long initial latency due to
asynchrony between task arrival and the partition’s active
window. To avoid this, the major cycle could be chosen to be
integer multiple of all task periods in the system. However, it
is unlikely to ﬁnd such a major cycle that can remove the ini-
tial latencies especially when integrating multiple applications
that have different base rate, not to mention sporadic (e.g.,
interrupt-driven) arrivals of tasks. Furthermore, a (system-
wide) high-priority task in an inactive partition cannot run
until the partition’s next window comes, during which lower-
priority tasks in other partitions run. These phenomena are
inevitable in static partitionings [17, 22].
Non-static Partitioning: This category includes server-
based approaches such as periodic server [37], sporadic server
[39], constant bandwidth server [7], etc. Real-time servers
[28, 35] were originally employed to reserve a CPU share for
aperiodic tasks while isolating them from critical tasks. In the
context of hierarchical scheduling, a server acts as a single
partition for a set of tasks that constitutes an application. It is
characterized by the budget, Bi, and the replenishment period,
Ti. When a task executes, the associated server’s budget is
depleted for the amount of execution. Each server is assigned
a unique priority Pri(Πi), and partitions can be scheduled
based on ﬁxed priority (e.g., periodic server, sporadic server)
or dynamic priority (e.g., constant bandwidth server).
Different server algorithms differ in the budget consump-
tion and replenishment policies, as shown in Figure 3. For
Figure 3: A comparison of real-time server algorithms.
instance, a periodic server [37] is invoked periodically, at
which time instant the full budget is replenished. The bud-
get of the current server (i.e., selected by the partition-level
scheduler) is consumed even when no task is running. Hence,
if a new task arrives after the budget is idled away, the task
needs to wait until the next replenishment. In contrast, in de-
ferrable [40] and sporadic server [39] algorithms, budget is
consumed only when tasks run. In the former, the full budget
is replenished no matter how much budgets are consumed.
On the other hand, a sporadic server may have multiple re-
plenishment threads; if a task consumes a budget of b during
[t,t + b), the same amount of budget is replenished at t + Ti.
This effectively limits the server’s CPU utilization to Bi/Ti
for every Ti time units.
RTOSes implement variants of the server algorithms in
consideration of performance and complexity. For instance,
the sporadic-polling reservation in LITMUSRT [12] is a vari-
ant of the sporadic server – the budget consumption begins
once the server takes the CPU and the budget is fully re-
plenished after one period. QNX’s adaptive partitioning [2],
which enforces CPU utilization of each application partition,
also implements a variant of sporadic server in the form of
sliding window. Also, Linux (since version 3.14) supports
SCHED_DEADLINE scheduling policy that can implement con-
stant bandwidth server (CBS) [7] for per-task CPU reserva-
tion. Modern real-time hypervisors (e.g., [3, 5]) also support
priority-based time-partitioning among virtual machines.
Figure 4 compares task responsiveness under TDMA and
sporadic-polling server that are measured from our target sys-
tem (more detail is provided in Section 6.2 and Appendix B).
As the results highlight, and also as discussed above, the
Figure 4: Probability distribution of response times under
TDMA and sporadic-polling server schedulers of LITMUSRT.
USENIX Association
30th USENIX Security Symposium    2419
TimeΠ!Π"Π#Π!Π"Π#Major cycle (MC)=B!+B"+B#PartitionSchedule(static)𝝉𝟏,𝟐𝝉𝟏,𝟏𝚷𝟏-LocalScheduleTask Period of τ!,"B!B"B#Π!′s tasks are delayed because Π!is inactive𝝉𝟏,𝟏𝝉𝟏,𝟏𝝉𝟏,𝟐𝝉𝟏,𝟐𝝉𝑯,𝟏𝝉𝑯,𝟏Time𝚷𝟏-LocalScheduleΠ!′s tasks are delayed due to Π!’s budget depletion(a) Static partitioning (e.g., TDMA)(b) Non-static partitioning (e.g., real-time server algorithms)Preempted by a higher-priority partition Π(Replenishment period of Π!Π!is activeTask ExecutionTask-level PreemptionTask arrivalPartition-level Preemption𝚷𝟏’s Active Window𝚷𝟏’s Inactive Window𝝉𝟏,𝟏𝝉𝟏,𝟐𝝉𝟏,𝟐𝝉𝟏,𝟐Time𝑡T!xMax. BudgetTime𝑡T!PeriodicServerDeferrableServerSporadicServerTime𝑡T!Replenishment (full budget)Replenishment (full budget)(Multiple) ReplenishmentsReplenishment (full budget)Replenishment (full budget)𝑡+T!𝑡+T!𝑡+T!B!Replenishment periodUnused budget is preservedUnused budget is preservedOut of budget!!,!!#,#Figure 5: τR,1 and τR,2 in ΠR can infer ΠS’s execution behav-
ior using non-timing information such as a counter C.
non-static partitioning scheme achieves improved average
response times compared to the static mechanism (by 108%
and 39% for τ1,1 and τ4,4, respectively) mainly because parti-
tion executions are not ﬁxed. However, as will be shown in
Section 3, such a ﬂexibility is in fact what enables illegitimate
information-ﬂow between partitions.
3 Algorithmic Covert Timing-Channel in Hi-
erarchical Scheduling
In this section, we discuss how non-static time partitioning
can enable algorithmic covert timing-channels through hier-
archical scheduling. Let us ﬁrst consider Figure 5 with two
partitions, ΠS (Sender) and ΠR (Receiver), where Pri(ΠS) >
Pri(ΠR). The receiver partition ΠR has two tasks {τR,1,τR,2}
where Pri(τR,1) < Pri(τR,2). A covert communication chan-
nel can be formed between the partitions by (i) τS,1’s varying
execution length and (ii) changes in the local schedule of ΠR.
In Case (a) of the ﬁgure, τR,1 ﬁnishes before τR,2 starts if τS,1
executes for a short amount of time, whereas in Case (b) τR,1
is further delayed by τR,2 if τS,1’s execution is long enough.
In its simplest form, the sender τS,1 can have two execution
modes (i.e., short or long executions) to encode bits 0 or 1.
Here, ΠR can observe ΠS’s varying behavior without using
time information. For example, a counter C, shared only be-
tween τR,1 and τR,2, can be used to infer ΠR’s local schedule –
τR,1 checks if the value of C changes from the beginning of its
execution ( 1 ) to the end ( 2 ), while τR,2 increases C by 1 at
the beginning of its execution (W), as Figure 5 illustrates. The
order of 2 and W is inﬂuenced by the sender – if ΠS sends
0, τR,1 will see the counter value remaining same because it
ﬁnishes before τR,2 increases C. If τR,1 sees an increment of
C, it indicates that ΠS has signaled bit 1.
To show the vulnerability of existing operating systems to
the algorithmic covert timing-channel through hierarchical
scheduling, we implemented the scenario described above
on LITMUSRT [12], a real-time extension of the Linux kernel.
We used its sporadic-polling scheduler, which is a variant of
sporadic server. Figure 6 presents the source codes of (i) τS,1
that varies its execution length to encode bit 0 or 1, (ii) τR,1
that checks a change in the counter shared with τR,2, and (iii)
τR,2 that merely increases the shared counter. Tasks run for
Figure 6: Implementations of τS,1, τR,1, and τR,2.
Figure 7: Extending from Figure 5, τR,1 can perceive varying
amount of preemption.
a pre-deﬁned number of loops (i.e., n_loops), thus no time
information is needed. The numbers are chosen in such a way
that τR,1 ﬁnishes prior to τR,2’s arrival if τS,1 sends bit 0. As
long as the conditions on the priority relation and the relative
phases are met, τS,1 can send an arbitrary bit-stream to τR,1.
We were also able to reproduce the same scenario on QNX
Neutrino as well. We created the partitions using its Adaptive
Partitioning Thread Scheduler [2] with the same conﬁguration
used in LITMUSRT and C code similar to Figure 6, although
there is no priority relation among partitions in this case.
The technique described above can be extended in various
ways. Figure 7 shows an extension, in which τR,2 acts as a