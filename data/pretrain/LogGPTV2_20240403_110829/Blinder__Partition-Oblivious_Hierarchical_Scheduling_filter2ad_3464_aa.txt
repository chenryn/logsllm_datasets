title:Blinder: Partition-Oblivious Hierarchical Scheduling
author:Man-Ki Yoon and
Mengqi Liu and
Hao Chen and
Jung-Eun Kim and
Zhong Shao
Blinder: Partition-Oblivious Hierarchical Scheduling
Man-Ki Yoon, Mengqi Liu, Hao Chen, Jung-Eun Kim, and 
Zhong Shao, Yale University
https://www.usenix.org/conference/usenixsecurity21/presentation/yoon
This paper is included in the Proceedings of the 30th USENIX Security Symposium.August 11â€“13, 2021978-1-939133-24-3Open access to the Proceedings of the 30th USENIX Security Symposium is sponsored by USENIX.Blinder: Partition-Oblivious Hierarchical Scheduling
Man-Ki Yoon, Mengqi Liu, Hao Chen, Jung-Eun Kim, Zhong Shao
Yale University
Abstract
Hierarchical scheduling enables modular reasoning about the
temporal behavior of individual applications by partitioning
CPU time and thus isolating potential misbehavior. However,
conventional time-partitioning mechanisms fail to achieve
strong temporal isolation from a security perspective; varia-
tions in the executions of partitions can be perceived by others,
which enables an algorithmic covert timing-channel between
partitions that are completely isolated from each other in the
utilization of time. Thus, we present a run-time algorithm
that makes partitions oblivious to othersâ€™ varying behaviors
even when an adversary has full control over their timings.
It enables the use of dynamic time-partitioning mechanisms
that provide improved responsiveness, while guaranteeing
the algorithmic-level non-interference that static approaches
would achieve. From an implementation on an open-source
operating system, we evaluate the costs of the solution in
terms of the responsiveness as well as scheduling overhead.
1 Introduction
With advancement in modern computing and communica-
tion technologies, there has been an increasing trend toward
integrating a number of software applications into a high-
performance system-on-chip to reduce communication and
maintenance complexity, while allowing them to efï¬ciently
utilize common hardware resources. Such a composition re-
quires that properties established for individual subsystems
be preserved at the integrated-system level. Especially for
safety-critical systems (e.g., avionics, automotive, industrial
control systems), it is of utmost importance to provide strong
isolation among applications that require different levels of
criticality in order to limit interference among them: pro-
tecting high-critical applications (e.g., instrument cluster in
digital cockpits [4]) from faulty behaviors of lower-critical
ones (e.g., infotainment system). This is increasingly chal-
lenging as individual subsystems are becoming more complex
due to advanced capabilities.
The isolation among subsystem applications is attained via
a form of resource partitioning [33]. For example, ARINC
653 (Avionics Application Standard Software Interface) [8]
standardizes time and space partitioning of applications ac-
cording to their design-assurance levels. This enables the soft-
ware functions to be developed and certiï¬ed independently. In
particular, time partitioning is a key ingredient for providing
strong temporal-isolation of unpredictable interference from
timing-sensitive applications. It is enforced also in Multiple
Independent Levels of Security (MILS) systems [9] to prevent
a compromised application from exhausting time resources.
Operating in the form of two-level hierarchical scheduling
architecture [6, 14], as shown in Figure 1, it provides each
application with the illusion of exclusive CPU resources.
However, such a tight integration of applications poses a
security challenge that could have been easily addressed in
the air-gapped environment. In particular, we observe that
conventional hierarchical scheduling schemes enable illegit-
imate information-ï¬‚ow among partitions that are supposed
to be isolated from one another. As multiple threads sharing
the CPU time can collaborate to inï¬‚uence oneâ€™s execution
progress and infer secret information [41, 44], time-partitions
can form algorithmic covert timing-channel by varying their
temporal behavior. In this paper, we ï¬rst demonstrate such a
vulnerability of hierarchical scheduling on existing real-time
operating systems; a partition can infer another partitionâ€™s
varying execution by observing the impact that the latterâ€™s
execution has on its own local schedule, even without using
any time information. This algorithmic channel exists even if
microarchitectural channels [15, 24] were completely closed.
Based on these observations, we develop a run-time sched-
ule transformation algorithm that we call Blinder. It prevents
partitions from distinguishing othersâ€™ varying execution be-
havior by making each partition-local schedule determinis-
tic. Although static partitioning approaches, such as TDMA
(Time Division Multiple Access) [8], can achieve strong non-
interference due to the ï¬xed nature of the schedules that they
generate, they are inï¬‚exible in CPU resource usage [17, 22].
On the other hand, non-static partitioning schemes, such as
real-time server algorithms [7, 37, 39], are more amenable
to dynamic workload and achieve better responsiveness, and
thus are increasingly adopted by commercial real-time oper-
ating systems and hypervisors [3, 5]. However, such a non-
determinism, or ï¬‚exibility, is a double-edged sword as it is the
very source of information-ï¬‚ow between partitions; partitions
can use CPU time in a detectable pattern to send signals.
Our Blinder deters such attempts by guaranteeing that the
local-execution state (i.e., partition-local schedule) changes
at deterministic time points no matter how the global state
USENIX Association
30th USENIX Security Symposium    2417
Algorithm 1: Schedule(Î Î Î ,t)
Î (t) â† GlobalScheduler(Î Î Î ,t) /* 1(cid:13) Selects partition */
if Î (t) (cid:54)= Î (t âˆ’ 1) then
SuspendPartition(Î (t âˆ’ 1))
end
LocalScheduler(Î (t))
/* 2(cid:13) Selects task
*/
Figure 1: Hierarchical scheduling.
changes (i.e., partition-level schedule). Hence, partitions can
be scheduled still in non-static ways (thus taking advantage
of the ï¬‚exibility in resource utilization) while achieving the
strong partition-obliviousness property that has been possible
only with static approaches. Blinder removes the algorithmic
covert timing-channel in hierarchical scheduling even if an
attacker is able to precisely control the timings of applications.
Furthermore, it is minimally-intrusive and modular in that
it does not require any modiï¬cations to the global and local
scheduling policies and hence can be applied to a wide variety
of existing systems that employ hierarchical scheduling.
In summary, this paper makes the following contributions:
â€¢ We demonstrate an algorithmic covert timing-channel
between time-partitions through hierarchical scheduler
of existing real-time operating systems.
â€¢ We introduce Blinder, a run-time schedule transforma-
tion algorithm that makes partitions oblivious to othersâ€™
varying temporal behavior, and we also analyze its im-
pact on the schedulability of real-time tasks.
â€¢ We implement Blinder on an open-source real-time oper-
ating system and evaluate its impact on the responsive-
ness as well as scheduling overheads.
â€¢ We demonstrate a deployment of Blinder on a prototype
real-time system and discuss system design and imple-
mentation challenges and possible mitigations.
2 Preliminaries
2.1 System Model and Terminology
We consider a real-time system that hosts N applications,
Î Î Î  = {Î 1, . . . ,Î N}, sharing CPU time. Each application, or
partition, Î i is comprised of one or more tasks, i.e., Î i =
{Ï„i,1,Ï„i,2, . . . ,Ï„i,mi}, where mi is the number of tasks in Î i.
Each task is characterized by Ï„i, j := (pi, j,ei, j), where pi, j is
the minimum inter-arrival time (i.e., period) and ei, j is the
worst-case execution time.
The partitions are scheduled in a hierarchical manner
[8, 14] as shown in Figure 1 and Algorithm 1; the global
scheduler determines which partition to execute next at time
instant t. Let Î (t) denote the partition selected by the global
scheduler for t. Then, the tasks of Î (t) are scheduled locally
according to its local scheduling policy.
Each task is associated with a priority, Pri(Ï„i, j), which can
be ï¬xed (e.g., Rate Monotonic (RM) [27] priority assignment)
or dynamic (e.g., Earliest Deadline First (EDF) [27]). We do
not assume any particular global and local scheduling policies.
However, simply for the ease of comprehension of the key
concepts, example schedules in the ï¬gures used throughout
this paper are based on the ï¬xed-priority global and local
schedulings. For most safety-critical systems such as avionics
and automotive systems, Rate Monotonic scheduling policy
is dominantly employed for local task scheduling due to its
stability and conservative predictability [28, 35].
Terminology: Tasks arrive to the system on a schedule or in
response to external events (e.g., interrupts). For instance, a
task can be scheduled to arrive every 100 ms for service of
a recurrent workload. The arrival time of task Ï„i, j is denoted
by ta(Ï„i, j). A task is said to be released if it becomes visible
to the partition to which it belongs, thus becoming available
for execution. Each partition Î i maintains a ready queue QR
i
of tasks that have been released but not been ï¬nished. The
Î i-local scheduler selects a task from QR
i (t) for each t.
Each partition Î i := (Ti,Bi) is associated with a non-
negative, maximum budget Bi; the partition cannot execute
for more than Bi (e.g., 20 ms) during a replenishment period
Ti (e.g., 100 ms). The remaining budget for time t is denoted
by Bi(t) and 0 â‰¤ Bi(t) â‰¤ Bi. No task of Î i can execute when
Bi(t) = 0. Partition Î i is said to be schedulable if it is guar-
anteed to execute for Bi over every replenishment period Ti.
Partition Î i is said to be active at t, denoted by active(Î i,
t), if it has a non-zero remaining budget and task(s) to execute,
i (t)(cid:54)= /0. Only active partitions are subject
i.e., Bi(t) > 0 and QR
to the global scheduling.
Deï¬nition 1 (Partition preemption). Partition Î i is said to
be preempted if it is not selected by the global scheduler (i.e.,
Î (t) (cid:54)= Î i) although it has a non-zero remaining budget and
has task(s) to run (i.e., it is active). That is,
Preempted(Î i,t) â‰¡ [Î (t) (cid:54)= Î i]âˆ§ active(Î i,t).
2.2 Hierarchical Scheduling
Hierarchical scheduling can be categorized into two classes,
static or non-static partitionings, depending on whether parti-
tions are activated at deterministic times or not.
Static Partitioning: Commonly referred to as table-driven
scheduling, cyclic-executive, or TDMA (Time Division Multi-
ple Access) scheduling, this approach statically assigns a ï¬xed
time window of length Bi to each partition Î i, as shown in Fig-
ure 2(a). The ï¬xed schedule repeats every major cycle (MC)
which is the sum of the partition windows, i.e., MC = âˆ‘i Bi.
Hence, each Î i effectively receives Bi/MC of CPU utiliza-
tion (e.g., 20 ms/100 ms = 20%). Î (t) is deterministic and
Î (t) = Î (t + MC) for any time t. Under the static partition-
ing scheme, the CPU is left unused if Î (t) has no task to
2418    30th USENIX Security Symposium
USENIX Association
Global Schedulerðš·ðŸ-Local SchedulerÎ !ðš·ðŸ-Local Schedulerðš·ðŸ‘-Local Schedulerðš·ðŸ’-Local SchedulerÎ "Î #Î $TasksTasksTasksTasksSelects a partition Î ð‘¡=Î %âˆˆðš·12Î ð‘¡-local scheduler selects a task from Î ð‘¡Figure 2: A comparison of static and non-static partitionings.
run even when other partitions have ready tasks. Hence, the
temporal behavior of a partition is completely isolated from
others. The IMA (Integrated Modular Avionics) architecture
of ARINC 653 standard [8] and MILS systems employ this
table-driven approach as the partition-level scheduling, and
it is implemented in commercial RTOSes such as VxWorks
653 [6] and LynxSecure [1].
The simplicity in the temporal reasoning comes at the cost
of inï¬‚exibility of resource usage. As shown in Figure 2(a),
tasks (e.g., Ï„1,2) may experience long initial latency due to
asynchrony between task arrival and the partitionâ€™s active
window. To avoid this, the major cycle could be chosen to be
integer multiple of all task periods in the system. However, it
is unlikely to ï¬nd such a major cycle that can remove the ini-
tial latencies especially when integrating multiple applications
that have different base rate, not to mention sporadic (e.g.,
interrupt-driven) arrivals of tasks. Furthermore, a (system-
wide) high-priority task in an inactive partition cannot run
until the partitionâ€™s next window comes, during which lower-
priority tasks in other partitions run. These phenomena are
inevitable in static partitionings [17, 22].
Non-static Partitioning: This category includes server-
based approaches such as periodic server [37], sporadic server
[39], constant bandwidth server [7], etc. Real-time servers
[28, 35] were originally employed to reserve a CPU share for
aperiodic tasks while isolating them from critical tasks. In the
context of hierarchical scheduling, a server acts as a single
partition for a set of tasks that constitutes an application. It is
characterized by the budget, Bi, and the replenishment period,
Ti. When a task executes, the associated serverâ€™s budget is
depleted for the amount of execution. Each server is assigned
a unique priority Pri(Î i), and partitions can be scheduled
based on ï¬xed priority (e.g., periodic server, sporadic server)
or dynamic priority (e.g., constant bandwidth server).
Different server algorithms differ in the budget consump-
tion and replenishment policies, as shown in Figure 3. For
Figure 3: A comparison of real-time server algorithms.
instance, a periodic server [37] is invoked periodically, at
which time instant the full budget is replenished. The bud-
get of the current server (i.e., selected by the partition-level
scheduler) is consumed even when no task is running. Hence,
if a new task arrives after the budget is idled away, the task
needs to wait until the next replenishment. In contrast, in de-
ferrable [40] and sporadic server [39] algorithms, budget is
consumed only when tasks run. In the former, the full budget
is replenished no matter how much budgets are consumed.
On the other hand, a sporadic server may have multiple re-
plenishment threads; if a task consumes a budget of b during
[t,t + b), the same amount of budget is replenished at t + Ti.
This effectively limits the serverâ€™s CPU utilization to Bi/Ti
for every Ti time units.
RTOSes implement variants of the server algorithms in
consideration of performance and complexity. For instance,
the sporadic-polling reservation in LITMUSRT [12] is a vari-
ant of the sporadic server â€“ the budget consumption begins
once the server takes the CPU and the budget is fully re-
plenished after one period. QNXâ€™s adaptive partitioning [2],
which enforces CPU utilization of each application partition,
also implements a variant of sporadic server in the form of
sliding window. Also, Linux (since version 3.14) supports
SCHED_DEADLINE scheduling policy that can implement con-
stant bandwidth server (CBS) [7] for per-task CPU reserva-
tion. Modern real-time hypervisors (e.g., [3, 5]) also support
priority-based time-partitioning among virtual machines.
Figure 4 compares task responsiveness under TDMA and
sporadic-polling server that are measured from our target sys-
tem (more detail is provided in Section 6.2 and Appendix B).
As the results highlight, and also as discussed above, the
Figure 4: Probability distribution of response times under
TDMA and sporadic-polling server schedulers of LITMUSRT.
USENIX Association
30th USENIX Security Symposium    2419
TimeÎ !Î "Î #Î !Î "Î #Major cycle (MC)=B!+B"+B#PartitionSchedule(static)ð‰ðŸ,ðŸð‰ðŸ,ðŸðš·ðŸ-LocalScheduleTask Period of Ï„!,"B!B"B#Î !â€²s tasks are delayed because Î !is inactiveð‰ðŸ,ðŸð‰ðŸ,ðŸð‰ðŸ,ðŸð‰ðŸ,ðŸð‰ð‘¯,ðŸð‰ð‘¯,ðŸTimeðš·ðŸ-LocalScheduleÎ !â€²s tasks are delayed due to Î !â€™s budget depletion(a) Static partitioning (e.g., TDMA)(b) Non-static partitioning (e.g., real-time server algorithms)Preempted by a higher-priority partition Î (Replenishment period of Î !Î !is activeTask ExecutionTask-level PreemptionTask arrivalPartition-level Preemptionðš·ðŸâ€™s Active Windowðš·ðŸâ€™s Inactive Windowð‰ðŸ,ðŸð‰ðŸ,ðŸð‰ðŸ,ðŸð‰ðŸ,ðŸTimeð‘¡T!xMax. BudgetTimeð‘¡T!PeriodicServerDeferrableServerSporadicServerTimeð‘¡T!Replenishment (full budget)Replenishment (full budget)(Multiple) ReplenishmentsReplenishment (full budget)Replenishment (full budget)ð‘¡+T!ð‘¡+T!ð‘¡+T!B!Replenishment periodUnused budget is preservedUnused budget is preservedOut of budget!!,!!#,#Figure 5: Ï„R,1 and Ï„R,2 in Î R can infer Î Sâ€™s execution behav-
ior using non-timing information such as a counter C.
non-static partitioning scheme achieves improved average
response times compared to the static mechanism (by 108%
and 39% for Ï„1,1 and Ï„4,4, respectively) mainly because parti-
tion executions are not ï¬xed. However, as will be shown in
Section 3, such a ï¬‚exibility is in fact what enables illegitimate
information-ï¬‚ow between partitions.
3 Algorithmic Covert Timing-Channel in Hi-
erarchical Scheduling
In this section, we discuss how non-static time partitioning
can enable algorithmic covert timing-channels through hier-
archical scheduling. Let us ï¬rst consider Figure 5 with two
partitions, Î S (Sender) and Î R (Receiver), where Pri(Î S) >
Pri(Î R). The receiver partition Î R has two tasks {Ï„R,1,Ï„R,2}
where Pri(Ï„R,1) < Pri(Ï„R,2). A covert communication chan-
nel can be formed between the partitions by (i) Ï„S,1â€™s varying
execution length and (ii) changes in the local schedule of Î R.
In Case (a) of the ï¬gure, Ï„R,1 ï¬nishes before Ï„R,2 starts if Ï„S,1
executes for a short amount of time, whereas in Case (b) Ï„R,1
is further delayed by Ï„R,2 if Ï„S,1â€™s execution is long enough.
In its simplest form, the sender Ï„S,1 can have two execution
modes (i.e., short or long executions) to encode bits 0 or 1.
Here, Î R can observe Î Sâ€™s varying behavior without using
time information. For example, a counter C, shared only be-
tween Ï„R,1 and Ï„R,2, can be used to infer Î Râ€™s local schedule â€“
Ï„R,1 checks if the value of C changes from the beginning of its
execution ( 1 ) to the end ( 2 ), while Ï„R,2 increases C by 1 at
the beginning of its execution (W), as Figure 5 illustrates. The
order of 2 and W is inï¬‚uenced by the sender â€“ if Î S sends
0, Ï„R,1 will see the counter value remaining same because it
ï¬nishes before Ï„R,2 increases C. If Ï„R,1 sees an increment of
C, it indicates that Î S has signaled bit 1.
To show the vulnerability of existing operating systems to
the algorithmic covert timing-channel through hierarchical
scheduling, we implemented the scenario described above
on LITMUSRT [12], a real-time extension of the Linux kernel.
We used its sporadic-polling scheduler, which is a variant of
sporadic server. Figure 6 presents the source codes of (i) Ï„S,1
that varies its execution length to encode bit 0 or 1, (ii) Ï„R,1
that checks a change in the counter shared with Ï„R,2, and (iii)
Ï„R,2 that merely increases the shared counter. Tasks run for
Figure 6: Implementations of Ï„S,1, Ï„R,1, and Ï„R,2.
Figure 7: Extending from Figure 5, Ï„R,1 can perceive varying
amount of preemption.
a pre-deï¬ned number of loops (i.e., n_loops), thus no time
information is needed. The numbers are chosen in such a way
that Ï„R,1 ï¬nishes prior to Ï„R,2â€™s arrival if Ï„S,1 sends bit 0. As
long as the conditions on the priority relation and the relative
phases are met, Ï„S,1 can send an arbitrary bit-stream to Ï„R,1.
We were also able to reproduce the same scenario on QNX
Neutrino as well. We created the partitions using its Adaptive
Partitioning Thread Scheduler [2] with the same conï¬guration
used in LITMUSRT and C code similar to Figure 6, although
there is no priority relation among partitions in this case.
The technique described above can be extended in various
ways. Figure 7 shows an extension, in which Ï„R,2 acts as a