For each IPI method, we first briefly introduce its basic
working mechanism. Then we present our technique to send
a corresponding IPI from the user-space. Lastly, we describe
step-by-step guides to extend the race window for race ex-
ploitation.
5.1 Reschedule IPI
Reschedule IPI sends a rescheduling request from one core
to another. Depending on which preemption mode the kernel
has been configured, the responsive behavior is different. If
CONFIG_PREEMPT [16] option is enabled, the core received an
IPI immediately performs the rescheduling unless preemp-
tion is not explicitly forbidden through preempt_disable(),
which in turn raises the context switch to another process.
Otherwise, the rescheduling will be deferred until the task
(running on the core which received the IPI) either yields the
schedule voluntarily or reaches a pre-configured preemption
point. However, this option is not affecting the result of our
attack.
Sending Reschedule IPI from Userspace.
Resched-
ule IPI is the IPI sent by the internal kernel function,
smp_send_reschedule(). smp_send_reschedule() takes an
2368    30th USENIX Security Symposium
USENIX Association
attacker has full controls over all these user-level three tasks.
Next, each task is pinned to a specific core (i.e., Taskx is
pinned to C0, Tasky to C1, and Taskint to C2) by invoking
sched_setaffinity() ( 2 ). Each task is pinned to a different
core so as to avoid interference by each other, thereby easily
enlarging the race window. After that, Taskx and Tasky invoke
a race-raising syscall, i.e., Syscallx by Taskx and Syscally
by Tasky ( A ). Then Taskint invokes sched_setaffinity(C1)
( B ). This makes the kernel to (i) migrate Taskint from C2’s
run queue to C1’s run queue and (ii) send a reschedule IPI to
C1 ( C ).
At this moment, if C1 receives the reschedule IPI when it
was executing any instruction within the race window (i.e.,
within Ty), C1 stops executing Tasky to handle the IPI ( D ).
After handling the IPI, it performs a context switch to Taskint
because this is what is instructed by the IPI ( E ). As a result,
the race window, Ty, is extended until Taskint is switched out,
and Tasky is scheduled in again ( F ).
5.2 Non-Reschedule IPI
Non-reschedule IPI refers to an IPI which is not related to
rescheduling. Non-reschedule IPI can be raised to send the
following commands: 1) TLB management and 2) memory
barriers. We found race-window extending methods using
either TLB management (§5.2.1) or memory barriers (§5.2.2),
as we describe next.
5.2.1 TLB Shootdown IPI
Translation Lookaside Buffer (TLB) is a cache for translating
an address from virtual to physical. Since each CPU core has
its own TLB, all TLB entries across different cores should be
synchronized in multi-processor systems. Otherwise, incor-
rect translation may be performed by the core, which refers
to outdated TLB entries (i.e., one core updates access per-
missions or release the memory page, but such an update is
not accordingly synchronized with other cores’ TLB entries).
As such, modern operating systems implement a TLB shoot-
down mechanism to ensure that TLB entries are synchronized
across different cores.
In order to implement the TLB shootdown mechanism, x86-
based operating systems rely on TLB shootdown IPI 3. More
specifically, since the kernel code running on one CPU core
cannot directly flush the TLB of other CPU cores, it sends
TLB shootdown IPI to other CPU cores. Once receiving the
IPI, the recipient CPU core immediately stops the currently
running task and flushes the TLB such that it does not refer
to outdated TLB entries.
More specifically, if any page table entry is to be updated
by a CPU core, the kernel has to send IPI to other CPU cores
3Not all architectures rely on IPI to implement the TLB shootdown. For
instance, ARM supports the tlbi instruction, which flushes the TLB of all
CPU cores.
Figure 4: EXPRACE’s exploitation method using Reschedule IPI
argument cpu, which specifies which core should receive the
IPI.
found
two
to
We
different methods
trigger
smp_send_reschedule() from the user space in a con-
trolled way (i.e., specifying a specific core or task). One
method is to invoke the sched_setaffinity() syscall. This
syscall takes an argument pid and mask, which eventually
sets cpu of smp_send_reschedule() as a core running a
process with the specified pid.
Another method is through waking up a waiting thread,
which can be done as follows: 1) assign a specific core affinity
to task A and change the thread’s process state to waiting
through a syscall such as read(), and; 2) wakes up the waiting
thread from task B through a syscall such as write(). The
kernel then changes task A’s process state waiting to running
and sends a reschedule IPI to the core, which thread A has an
affinity.
Although both methods have the same result that sending
rescheduling IPI to a specific core, the first method yields
better performance than the second method for the two rea-
sons. First, the wait-wake method should use two processes
for sending IPI, but the method using sched_setaffintiy()
uses one process. Second, the sched_setaffintiy() method
can send more IPIs during the same time period than the
wait-wake method. More specifically, because the wake pro-
cess must wake after the wait process is completely waiting,
however, the wake process doesn’t have knowledge about
wait process’s process state immediately; it needs a time for
synchronization.
Extending Race Window with Reschedule IPI. Using
reschedule IPI, a race window can be extended with the fol-
lowing steps, as shown in Figure 4 (simplified implementa-
tion code is shown in Figure A.1). First, we create three tasks
(Taskx, Tasky, Taskint), where Taskx and Taskint can be either
a child process or concurrent thread of Tasky, respectively
(shown in 1 ). Taskx and Tasky will be used to invoke two
racy syscalls (i.e., Syscallx and Syscally), and these two
syscalls are assumed to raise a data race. Taskint will be used
to send the reschedule IPI to C1. Note that we assume an
USENIX Association
30th USENIX Security Symposium    2369
 TETEIPI handler:reschedule() TyTy Ty′Ty′ TyTyInstruction 1Kernel thr for Taskyy :Core 0 (C0C0)Instruction 4smp_send_reschedule()User thr for Taskxx :Kernel thr for Taskxx :User thr for Taskyy :Kernel thr for Taskyy :Core 1 (C1C1)Core 2 (C2C2)Race-stageInstruction 2Instruction 3sched_setaﬃnity(C1C1)BDERescheduling IPI to C1C1 CFKernel thr for Taskintint :User thr for Taskintint :User thr for Taskintint :Initialization-stage    Create three tasksfork/threadfork/thread12Pinning each tasksched_setaﬃntiy(C1C1)sched_setaﬃntiy(C2C2)sched_setaﬃntiy(C0C0)TaskxxTaskxxTaskyyTaskyyTaskintintTaskintint TxTxASyscallxx()ASyscallyy()Figure 5: EXPRACE’s exploitation method using TLB shootdown
IPI
Figure 6: EXPRACE’s exploitation method using membarrier IPI
having the same entry. Thus, the kernel refers to cpu_bitmap
in mm_struct, which has the list of cores that may have the
same page table entry [2].
Sending TLB Shootdown IPI from Userspace. From
userspace, TLB shootdown can be triggered through syscalls
that update the page table, such as mprotect() or munmap().
These syscalls first flush the TLB of the currently running
CPU core, and then send TLB shootdown IPI to other CPU
cores. Note that the IPI will be sent to the CPU cores, which
may have out-dated TLB entries as the kernel maintains the
information on which CPU cores may have out-dated TLBs
(i.e., cpu_bitmap in mm_struct).
Extending Race Window with TLB Shootdown IPI.
Leveraging TLB shootdown IPI, the race window can be
extended through the following steps, as shown in Figure 5
(simplified implementation code is shown in Figure A.2).
First, three tasks, Taskx, Tasky, and Taskint are created (shown
in 1 ), where Taskx should be the child process of Tasky and
Taskint should be a concurrent thread of Tasky. Taskx and
Tasky are for invoking race-triggering syscalls, Syscallx and
Syscally, respectively, and Taskint is for sending the TLB
shootdown IPI.
Note that Taskx and Tasky must not be the same process
(i.e., created through fork(), not through pthread_create()).
This is because Taskx and Tasky should not refer to the same
mm_struct. Also, using fork() ensures that Taskx and Tasky
have their own copy of mm_struct. If Taskx and Tasky are the
same processes (but different threads), they would reference
the same mm_struct. In this case, cpu_bitmap is set for both
Taskx and Tasky, so IPI will be sent to both C0 (the core
running Taskx) and C1 (the core running Tasky). For a similar
reason, Tasky and Taskint should be the same process.
Next, each task is pinned to different cores using
sched_setaffinity(), i.e., Taskx is pinned to C0, Tasky to
C1, and Taskint to C2 ( 2 ). Then either Tasky or Taskint allo-
cates a memory page (say M) using mmap(), which will be
used to raise the TLB shootdown ( 3 ).
After that, Taskx and Tasky invoke race-raising syscalls,
Syscallx, and Syscally, respectively ( A ). At this moment, if
Taskint modifies the permission of the previously allocated
memory page (i.e., M) using mprotect() ( B ), the kernel
first flushes the TLB of C2. Moreover, the kernel also sends
a function call IPI to C1 since C1 is set in cpu_bitmap in
struct mm_struct for the M ( C ). If C1 receives the func-
tion call IPI when executing the race window (i.e., within
Ty), C1 immediately stops executing Tasky and starts han-
dling IPI ( D ). As a result, the race window is extended
until the end of IPI handling (which is performed through
native_flush_tlb_one_user()).
5.2.2 Memory Barrier IPI
membarrier in Linux is a syscall, controlling the memory
access orders in multi-processor systems. Since membarrier
needs to activate a memory barrier on specific threads, it relies
on an IPI mechanism to notify specific cores running those
threads.
Sending Memory Barrier IPI from Userspace. Unlike
other IPIs that we introduced before, the Linux kernel pro-
vides the syscall interface membarrier, which sends the mem-
ory barrier IPI from the user space. Thus, a user task can
invoke the syscall membarrier to deliver the memory barrier
IPI.
Extending Race Window with Memory Barrier IPI. In or-
der to extend the race window, we utilize membarrier syscalls
in the following steps as shown in Figure 6 (implementation
code is shown in Figure A.3). First, two tasks, Taskx and
Tasky, are created (which will execute race-raising syscalls)
as well as Taskint to send Memory Barrier IPI (shown in 1 ).
Here, since Taskx and Tasky must have different mm, Taskx is
created through fork() from Tasky. On the contrary, since
Tasky and Taskint must have the same mm, Taskint is created
through pthread_create() from Tasky. Next, each task is
pinned to its own core using sched_setaffinity() ( 2 ). Then
Tasky or Taskint invokes the membarrier syscall to register the
process to use memory barrier ( 3 ).
Taskx and Tasky invoke race-raising syscalls, Syscallx,
and Syscally, respectively ( A ). After that, as Taskint
in-
voke the membarrier syscall with expedited option ( B ), the
2370    30th USENIX Security Symposium
USENIX Association
Instruction 2Instruction 3Initialization-stage    Create three tasksthreadfork12Pinning each task3Allocate memory = mmap(0, 4096, 3, …)sched_setaﬃntiy(C1C1)sched_setaﬃntiy(C2C2)sched_setaﬃntiy(C0C0)User thr for Taskxx :Kernel thr for Taskxx :User thr for Taskyy :Core 0 (C0C0)Core 1 (C1C1)Core 2 (C2C2)Race-stageInstruction 1Instruction 4smp_function_call_single()7Kernel thr for Taskyy :Kernel thr for Taskyy :IPI handler:native_ﬂush_tlb_one_user()mprotect(, 4096, 1)BDKernel thr for Taskintint :User thr for Taskintint :Taskyy or TaskintintTaskintintTaskintint TxTx TyTy TETE Ty′Ty′ TyTyASyscallxx()ASyscallyy()TaskxxTaskxxTaskyyTaskyyFunction call IPI to C1C1CInitialization-stagemembarrier(REGISTER)3Register taskInstruction 1Instruction 4smp_function_call_single()7User thr for Taskyy :Kernel thr for Taskyy :Kernel thr for Taskyy :Core 1 (C1C1)Core 2 (C2C2)Race-stageIPI handler:ipi_mb()membarrier(EXPEDITED)BDKernel thr for Taskintint :User thr for Taskintint :CFunction call IPI to C1C1     Create three tasksthreadfork12Pinning each tasksched_setaﬃntiy(C1C1)sched_setaﬃntiy(C2C2)sched_setaﬃntiy(C0C0)TaskxxTaskxxTaskyyTaskyyTaskintintTaskintintTaskyy or Taskintint TyTy TETE Ty′Ty′Instruction 2Instruction 3User thr for Taskxx :Kernel thr for Taskxx :Core 0 (C0C0) TxTxASyscallxx()ASyscallyy() TyTyOS
Reschedule IPI
Function Call IPI
(TLB shootdown)
HW interrupt
Windows
OS X
✔
✗
✔
✔
✔
✗
Table 3: EXPRACE’s exploitation summary on other OSes
will execute race-raising syscalls) as well as Taskint to send
the TCP request to the ethernet device (shown in 1 ). Note that
Taskx and Taskint can be either a child process or concurrent
thread of Tasky, respectively, because HW interrupt delivery
mechanism is irrespective of its process/thread relationship.
Next, by checking /proc/irq/#/smp_affinity, we retrieve
the CPU core number, which has an affinity to the subjected
IRQ ( 2 ). To simplify the description, we assume that the
ethernet device has an affinity for cpu C1.
Then, each task is pinned to a specific core ( 3 ). After that,
Taskx and Tasky invoke a race-raising syscall, i.e., Syscallx
by Taskx and Syscally by Tasky ( A ). Taskint sends the TCP
request to itself (i.e., an external IP address of a local machine)
( B ). Then in order to process the request packet, the ethernet
device issues an IRQ to C1 ( C ).
If C1 receives the IRQ within the time frame of Ty, the
kernel thread for Tasky switches to the corresponding inter-
rupt service routine (ISR) ( D ). After completing the ISR, C1
returns back to the kernel thread for Tasky. As a result, the
race window (Ty) is extended as much as the execution time
of the ISR.
6 Exploiting Kernel Races in Other OSes
In order to understand if the race window extension mecha-
nism proposed in §5 works for other operating systems, this
section studies if it also works for two other popular operating
systems: Microsoft Windows (§6.1) and MAC OS X (§6.2).
The research challenge here is that these are proprietary ker-
nels, so their detailed internal mechanism is difficult to un-
derstand. Note that we have studied all the methods except
membarrier (§5.2.2), as membarrier is a unique feature only
available in Linux.
To summarize (shown in Table 3), in the case of Windows
we confirmed that all the race enlarging methods (except
membarrier) presented in §5 also work. In the case of MAC
OS X, we confirmed that the TLB shootdown IPI works but
reschedule IPI would not work. We were not able to do a
meaningful study on HW interrupts on OS X due to the lack
of internal information.
6.1 Microsoft Windows
Reschedule IPI. We found that Windows’s preemption mode
is mostly similar to that of Linux’s CONFIG_PREEMPT mode.
The key difference between Windows and Linux is that Win-
dows takes account of thread’s priority [42]. More precisely,
Figure 7: EXPRACE’s exploitation method using HW interrupts
kernel sends the membarrier IPI to C1 ( C ). This is be-
cause Tasky (which is running on C1) reference the same
struct mm_struct as Taskint. Once receiving the membarrier
IPI, Tasky is switched out from C1 to handle the IPI through
ipi_mb() ( D ). If this IPI is delivered when executing Ty, the
race window is extended.
5.3 Hardware Interrupts
Hardware interrupt request (IRQ) is an electric signal sent
from an external hardware device to a processor through IO-
APIC. This facilitates communication with operating systems.
Sending Hardware Interrupts from Userspace. If the IRQ
is issued, an interrupt controller delivers the interrupt to a cer-
tain CPU core to handle the interrupt, which in turn executes
an interrupt service routine (ISR). The interrupt controller al-
lows the kernel to specify which CPU core is responsible for
which interrupt through bit masking. This allows the kernel to
optimize the performance as it directly delivers an interrupt
to a dedicated core instead of selecting the core using some
other algorithm (e.g., a round-robin).
In Linux, such a specification can be checked by reading the
file in procfs, /proc/irq/#/smp_affinity, where # denotes
an IRQ number. Taking an example in our experimental envi-
ronment, the default kernel configuration is that the enp2s0
device is assigned to IRQ 122, which is destined to be served
by CPU core 11.
This IRQ cannot be sent from userspace directly because it
requires the kernel privilege. Therefore, we devise an indirect
way to send the IRQ from userspace: i) send a request from
userspace to a device; ii) in response to the request, the de-
vice issues the IRQ to the kernel. We found several different
indirect ways: 1) send TCP request to the ethernet device and
the device issues IRQ to the kernel to process the packet;
2) send disk request using file read or write, disk controller
device(e.g., AHCI device) issues IRQ to the kernel to signal
that a disk request has been fulfilled.
Extending Race Window with Hardware Interrupts. The
race window can be extended with the following steps, as
shown in Figure 7 (implementation code is shown in Fig-
ure A.5). First, two tasks, Taskx and Tasky, are created (which
USENIX Association
30th USENIX Security Symposium    2371
Initialization-stage    Create three tasksPinning each task$ cat /proc/irq/122/smp_aﬃnity> 002 = Core 1    Check IRQ aﬃnityInstruction 1Instruction 4ISRethernetdeviceserverreqresHW interrupt123User thr for Taskyy :Kernel thr for Taskyy :Kernel thr for Taskyy : Core 1 (C1C1)Core 2 (C2C2)Race-stagereqsk = socket()connect(sk)BCDUser thr for Taskintint : TyTyfork/threadfork/threadsched_setaﬃntiy(C1C1)sched_setaﬃntiy(C2C2)sched_setaﬃntiy(C0C0)TaskxxTaskxxTaskyyTaskyyTaskintintTaskintintInstruction 2Instruction 3User thr for Taskxx :Kernel thr for Taskxx :Core 0 (C0C0) TxTxASyscallxx()ASyscallyy()to C1C1 TyTy TETE Ty′Ty′if a new thread is enqueued for rescheduling in Windows,
that new thread is only rescheduled if it has a higher priority
than a currently running thread. As a result, Windows keeps
elevating the priority of that new thread so that it can take a
chance to be rescheduled.
Therefore, compared to the reschedule IPI method for