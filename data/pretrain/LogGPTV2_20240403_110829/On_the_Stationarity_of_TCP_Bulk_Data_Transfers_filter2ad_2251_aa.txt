title:On the Stationarity of TCP Bulk Data Transfers
author:Guillaume Urvoy-Keller
On the Stationarity of TCP Bulk Data Transfers
Guillaume Urvoy-Keller
Institut Eurecom, 2229, route des crˆetes,
06904 Sophia-Antipolis, France
PI:EMAIL
Abstract. While the Internet oﬀers a single best-eﬀort service, we re-
mark that (i) core backbones are in general over provisioned, (ii) end
users have increasingly faster access and (iii) CDN and p2p solutions
can mitigate network variations. As a consequence, the Internet is to
some extent already mature enough for the deployment of multimedia
applications and applications that require long and fast transfers, e.g.
software or OS updates. In this paper, we devise a tool to investigate
the stationarity of long TCP transfers over the Internet, based on the
Kolomogorov-Smirnov goodness of ﬁt test. We use BitTorrent to obtain
a set of long bulk transfers and test our tool. Experimental results show
that our tool correctly identify noticeable changes in the throughput of
connections. We also focus on receiver window limited connections to
try to relate the stationarity observed by our tool to typical connection
behaviors.
1
Introduction
The current Internet oﬀers a single best-eﬀort service to all applications. As a
consequence, losses and delay variations are managed by end-hosts. Applications
in the Internet can be classiﬁed into two classes: elastic applications, e.g. web or
e-mail, that can tolerate throughputs and delays variations; and real time appli-
cations, that are delay sensitive (e.g. voice over IP) or throughput sensitive (e.g.
video-on-demand). With respect to the above classiﬁcation, a common belief is
that the current Internet with its single best-eﬀort service requires additional
functionality (e.g. DiﬀServ, MPLS) to enable mass deployment of real-time ap-
plications. Still, a number of facts contradict, or at least attenuate, this belief:
(i) recent traﬃc analysis studies have deemed the Internet backbone ready to
provide real-time services [15]; (ii) the fraction of residential users with high
speed access, e.g. ADSL or cable, increases rapidly; (iii) network-aware coding
schemes, e.g. mpeg4-fgs [7], combined with new methods of transmission like
peer-to-peer (p2p) techniques, e.g. Splitstream [5], have paved the way toward
the deployment of real-time applications over the Internet.
The above statements have lead us to investigate the variability of the ser-
vice provided by the Internet from an end connection point of view. As TCP is
carrying most of the bytes in the Internet [10], our approach is to concentrate on
long lived TCP connections. Bulk data transfers represent a signiﬁcant portion
C. Dovrolis (Ed.): PAM 2005, LNCS 3431, pp. 27–40, 2005.
c(cid:1) Springer-Verlag Berlin Heidelberg 2005
28
G. Urvoy-Keller
of the current Internet traﬃc load, especially with p2p applications [2]. By ana-
lyzing bulk data transfers, we expect to better understand the actual interaction
between TCP and the Internet. This is important for future applications 1 and
also for CDN providers that rely on migrating traﬃc on the ”best path” from
central to surrogate servers [8]. CDN providers generally rely on bandwidth es-
timation tools, either proprietary or public tools [12] to perform path selection.
However, the jury is still out on the stationarity horizon provided by such tools,
i.e. how long will the estimation provided by the tool remain valid or at least
reasonable. In the present work, we propose and evaluate a tool that should help
solving these issue. The rest of this paper is organized as follows. In Section
2, we review the related work. In Section 3, we present our dataset. In Section
4, we present our tool to extract stationarity periods in a given connection. In
Section 5, we discuss results obtained on our dataset. Conclusions and future
work directions are presented in Section 6.
2 Related Work
Mathematically speaking, a stochastic process X(t) is stationary if its statistical
properties (marginal distribution, correlation structure) remain constant over
time.
Paxson et al. [17] have studied the stationarity of the throughput of short
TCP connections (transfers of 1Mbytes) between NIMI hosts. The major diﬀer-
ence between this work and the present work is that we consider long bulk data
transfer (several tens of minutes) and our dataset is (obviously) more recent
with hosts with varying access capacity, whereas NIMI machines consistently
had good Internet connectivity. Other studies [4, 13] have concentrated on the
non stationarity observed on high speed link with a high number of aggregated
ﬂows. They studied the time scales at which non stationarity appears and the
causes behind it. Also, recently, the processing of data streams has emerged as
an active domain in the database research community. The objective is to use
database techniques to process on-line stream at high speed (e.g. Internet traf-
ﬁc on a high speed link). In the data stream context, detection of changes is a
crucial task [14, 3].
3 Dataset
Our objective is to devise a tool to assess the stationarity of TCP bulk data
transfers. To check the eﬀectiveness of the tool, we need to gather samples, i.e.
long TCP transfers, from a wide set of hosts in the Internet. A simple way to
attract traﬃc from a variety of destinations around the world is to use a p2p
application. As we are interested in long data transfers, we used BitTorrent,
1 Our focus in the present work is on throughput, which is an important QoS met-
rics for some multimedia applications, e.g. VoD, but arguably not all multimedia
applications, a typical counter-example being VoIP.
On the Stationarity of TCP Bulk Data Transfers
29
a popular ﬁle replication application [11]. A BitTorrent session consists in the
replication of a single large ﬁle on a set of peers. BitTorrent uses speciﬁc algo-
rithms to enforce cooperations among peers. The data transfer phase is based
on the swarming technique where the ﬁle to be replicated is broken into chunks
(typical chunk size is 256 kbytes) that peers exchange with one another. The
BitTorrent terminology distinguishes between peers involved in a session that
have not yet completed the transfer of the ﬁle, which are called leechers and
peers that have already completed the transfer, which are called seeds. Seeds re-
main in the session to serve leechers. Connections between peers are permanent
TCP connections. Due to the BitTorrent algorithms [11], a typical connection
between two hosts is a sequence of on periods (data transfers) and oﬀ periods
(where only keep-alive messages are transfered). Figure 1, where y axis values
are one second throughputs samples, depicts a typical one way connection of
approximately 14 hours with clear on and oﬀ phases.
)
s
/
s
t
i
b
k
(
t
u
p
h
g
u
o
r
h
T
1000
900
800
700
600
500
400
300
200
100
0
0
1
2
3
4
time(s)
5
x 104
)
s
/
s
t
i
b
M
(
t
u
p
h
g
u
o
r
h
T
14
12
10
8
6
4
2
0
0
2
4
6
Total Aggregate Rate
Access Link Speed (10 Mbits/s)
8
10
Time (second)
12
14
16
x 104
Fig. 1. A typical (one-way) BitTorrent
connection
Fig. 2. Aggregate rate of the BitTorrent
application during the experiment
The dataset we have collected consists of connections to about 200 peers that
were downloading (part of) the ﬁle (latest Linux Mandrake release) from a seed
located at Eurecom. More precisely, a tcpdump trace of 10 Gbytes was generated
during a measurement period of about 44 hours. While the 200 connections are all
rooted at Eurecom, the 10 Mbits/s access link of Eurecom should not constitute
a shared bottleneck for two reasons. First, with BitTorrent, a client (leecher or
seed) does not send to all its peers simultaneously but only to 4 of them, for sake
of eﬃciency. Second, the total aggregate throughput remains in general far below
the 10 Mbits/s as shown in ﬁgure 2 while the average traﬃc generally observed
on this link (to be added to the traﬃc generated by our BitTorrent client to
obtain the total oﬀered load for the link) exhibits an average rate around 1
Mbits/s with a peak rate below 2 Mbits/s.
To illustrate the diversity of these 200 peers, we have used the maxmind
service (http://www.maxmind.com/) to assess the origin country of the peers. In
table 1, we ranked countries based on the peers that originate from each of them.
Unsurprisingly, we observe a lot of US peers (similar observation was made in [11]
30
G. Urvoy-Keller
Table 1. Origin countries of the 200 peers
Country # peers Country # peers Country # peers Country # peers
US
UK
CA
FR
IT
SE
PL
87
24
14
12
8
8
7
NL
DE
AU
PE
AE
CL
PT
4
3
3
3
3
2
2
BR
LT
CN
NO
SI
TW
CZ
2
2
1
1
1
1
1
YU
BE
AT
ES
CH
1
1
1
1
1
for a similar torrent, i.e. Linux Redhat 9.0) while the other peers are distributed
over a wide range of 27 countries (see http://encyclopedia.thefreedictionary.com/
ISO%203166-1 for the meaning of the abbreviations used in table 1).
Our objective is to study long bulk data transfers in the Internet. To obtain
meaningful samples, we extracted the on periods from the 200 connections, re-
sulting in a total of 399 ﬂows. The algorithm used to identify oﬀ-periods is to
detect periods of at least 15 seconds where less than 15 kbytes of data are sent,
as BitTorrent clients exchange keep-alive messages at a low rate (typically less
than 1000 bytes per second) during periods where no data transfer is performed.
We further restricted ourselves to the 184 ﬂows whose duration is higher than
1600 seconds (∼ 26.6 minutes), for reasons that will be detailed in section 4. We
call ﬂow or initial ﬂow an on-period and stationary ﬂow a part of a ﬂow that is
deemed stationary. For each ﬂow, we generate a time series that represents the
throughput for each 1 second time interval. The average individual throughput of
these 184 ﬂows is quite high, 444 kbits/s. Overall, these ﬂows correspond to the
transfer of about 50 Gbytes of data over a cumulated period of about 224 hours
(the ﬂows of duration less than 1600 seconds represent about 14 Gbytes of data).
Due to its size, we cannot claim that our dataset is representative of the bulk
transfers in the Internet. It is however suﬃciently large to demonstrate the eﬀec-
tiveness of our tool. It also shows that BitTorrent is a very eﬀective application
to collect long TCP transfers from a variety of hosts in terms of geographical
location and access link speed (even if it is unlikely to observe clients behind
modem lines, as downloading large ﬁle behind a modem line is unrealistic).
4
Stationarity Analysis Tool
4.1 Kolmogorov-Smirnov (K-S) Test
Given two i.i.d samples X1(t)t∈{1,...n} and X2(t)t∈{1,...n}, the Kolmogorov-
Smirnov test enables us to determine whether the two samples are drawn from
the same distributions or not. The test is based on calculating the empirical
cumulative distribution functions of both samples and evaluating the absolute
maximum diﬀerence Dmax between these two functions. The limit distribution of
Dmax under the null hypothesis (X1 and X2 drawn from the same distribution)
is known and thus Dmax is the statistics the test is built upon. In the sequel
On the Stationarity of TCP Bulk Data Transfers
31
of this paper, we used the matlab implementation of the K-S test with 95%
conﬁdence levels.
4.2 K-S Test for Change Point Detection
Our objective is to detect stationary regions in time series, or equivalently to
detect change points (i.e. border points between stationary regions). We used
the K-S test to achieve this goal. Previous work as already used the K-S test to
detect changes [9, 3], though not in the context of traﬃc analysis.
The basic idea behind our tool is to use two back-to-back windows of size w
sliding along the time series samples and applying the K-S test at each shift of
the windows. If we assume a time series of size n, then application of the K-S
test leads to a new binary time series of size n − 2w, with value zero whenever
the null hypothesis could not be rejected and one otherwise. The next step is to
devise a criterion to decide if a ’1’ in the binary time series corresponds to a false
alarm or not. Indeed, it is possible to show that even if all samples originate from
the same underlying distribution, the K-S test (or any other goodness of ﬁt test
[16]) can lead to spurious ’1’ values. The criterion we use to deem detection of a
change point is that at least wmin ≈ w
2 consecutive ones must be observed in the
binary time series. wmin controls the sensitivity of the algorithm. The intuition
behind setting wmin to a value close to w
2 is that we expect the K-S test to
almost consistently output ’1’ from the moment when the right-size window