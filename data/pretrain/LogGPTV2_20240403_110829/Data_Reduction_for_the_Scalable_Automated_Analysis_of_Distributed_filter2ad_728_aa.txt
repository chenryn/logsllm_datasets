# Data Reduction for the Scalable Automated Analysis of Distributed Darknet Traffic

**Authors:**
- Michael Bailey, University of Michigan
- Evan Cooke, University of Michigan
- Farnam Jahanian, University of Michigan and Arbor Networks, Inc.
- Niels Provos, Google, Inc.
- Karl Rosaen, University of Michigan
- David Watson, University of Michigan

## Abstract

The evolving threats to user privacy and Internet infrastructure availability require researchers to balance the need for monitoring a large number of hosts to quickly identify new attacks while preserving the necessary details to differentiate these attacks. One approach involves hybrid systems that combine scalable monitoring of unused address blocks (darknets) with forensic honeypots (honeyfarms). This paper examines the properties of individual and distributed darknets to assess the effectiveness of building scalable hybrid systems.

We find that individual darknets are dominated by a small number of sources repeating the same actions, enabling source-based techniques to reduce the number of connections to be evaluated by over 90%. The dominance of locally targeted attack behavior and the limited lifespan of random scanning hosts result in few repeated sources across darknets. To achieve further reductions, we explore source-distribution-based methods, incorporating local and global behavior. We demonstrate the effectiveness of this approach by deploying it in 30 production networks during early 2005, identifying major globally-scoped attacks such as the WINS vulnerability scanning, Veritas Backup Agent vulnerability scanning, and the MySQL Worm.

## 1. Introduction

Networks are increasingly vulnerable to threats that compromise the reliability of critical infrastructure, including Distributed Denial of Service (DDoS) attacks and scanning worms like CodeRed and Blaster. These threats can cause significant disruptions and financial losses. Researchers have proposed various global early warning systems to detect and characterize these threats. However, the global scope, virulence, and potential for zero-day exploits make these threats particularly challenging to address.

To effectively detect and classify these threats, detailed forensic information is needed. Monitoring large numbers of addresses increases the probability of quickly detecting new threats. However, complex host emulation and the possibility of zero-day threats may limit the ability of wide-address monitoring systems to identify important threat characteristics. Honeypot systems provide detailed insights but at the cost of scalability.

A potential solution is to forward requests destined for darknets to an automated bank of honeypots. While this architecture promises detailed forensic information, it faces scalability issues. In this paper, we investigate the problem of filtering darknet traffic to identify connections worthy of further investigation. We analyze data from a large, distributed system of darknet monitors to understand the scalability bounds of a hybrid monitoring system. Our main contributions include:

- **Measurement and Analysis:** A multi-year deployment of over 60 darknets in 30 organizations, covering over 17 million routable addresses.
- **Key Threat Characteristics:** Identification of key characteristics that bound the scalability of a hybrid system, including the dominance of a small fraction of source IPs and the lack of observable behavior across darknets.
- **Algorithm Development and Deployment:** Creation and evaluation of an algorithm that reduces large traffic rates to a manageable number of events for honeyfarm processing. A three-month deployment in 2005 provided analysis of five major global events.

## 2. Related Work

Historic approaches to detecting and characterizing network-based security threats fall into two categories: monitoring production networks with live hosts and monitoring unused address space (darknets). Monitoring used networks involves watching traffic directly or using abstractions like flow records and alerts from security devices. Darknet monitoring, on the other hand, involves sensors that monitor blocks of unused address space. While darknet monitoring has been successful in observing denial of service activity, worms, and other malicious behavior, it has limitations in capturing threats that do not scan for new hosts or avoid unused blocks.

Combining host and network views, two new approaches have evolved: aggregating fine-grained sensor measurements from multiple sensors and hybrid systems that use darknet monitors to concentrate connections to a centralized honeyfarm. Hybrid systems vary in how they perform connection funneling, data filtering, and the diversity and amount of address space monitored. Recent work on the Potemkin Virtual Honeyfarm focuses on creating scalable per-connection virtual machines, complementary to our focus on limiting the number of connections seen by the honeyfarm.

## 3. A Hybrid Architecture for Monitoring Internet Security Threats

To provide both behavioral fidelity and broad coverage, we propose a hybrid architecture that is highly scalable and accurate. This multi-resolution architecture consists of two components: a collection of distributed darknet sensors (the Internet Motion Sensor or IMS) and a collection of host sensors (the Host Motion Sensor or HMS). The IMS monitors a diverse set of darknets, and when new activity is detected, the connection is proxied back to the HMS for in-depth analysis. The connection is relayed to virtual machine images running the appropriate application, allowing new and important threats to be executed and monitored for worm behavior.

By pre-filtering traffic, the IMS eliminates false positives and scaling issues. The IMS sensors have both active and passive components. The active component responds to TCP SYN packets with a SYN-ACK packet to elicit the first data payload on all TCP streams. The passive component computes the hash of the payload and stores it if it doesn't match any previously observed signatures, adding it to the signature database.

This paper is structured as follows: We begin by reviewing related work in Section 2. In Section 3, we introduce our hybrid architecture and its challenges. We then examine the behavior of threats at individual dark address blocks in Section 4 and observe these threats across darknets in Section 5. Based on these insights, we construct a filtering algorithm described in Section 6. In Section 7, we show the effectiveness of this algorithm through a broad production deployment. Finally, we conclude in Section 8.