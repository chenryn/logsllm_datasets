entries to justify a complex data structure (like a hash or a
trie). The maximum number of ﬂow entries under which a
table is directly compiled is controlled by a parameter; we
will present CPU-level measurements to ﬁne-tune this pa-
rameter later in Section 4.3.
Consider an example with the below ﬂow entries:
ip_dst=ADDR_1/MASK_1,tcp_dst=PORT,action=ACTION_1
ip_dst=ADDR_2/MASK_2,action=ACTION_2
...
ESWITCH in this case takes the ip_dst and tcp_dst
matcher templates and concatenates these into the direct code
template below:
FLOW_1:
mov
or
cmp
jne
eax,IP | TCP
eax,r15d
eax,r15d
ADDR_NEXT_FLOW
; first flow entry
; ip and tcp?
; check protocol bitmask
;
; not an IP & TCP packet
; jump to next flow entry
IP_DST_ADDR_MATCHER(ADDR_1,MASK_1)
; ip_dst=ADDR_1/MASK_1?
TCP_DST_PORT_MATCHER(PORT)
jmp ACTION_1
FLOW_2:
r15d, IP
ADDR_NEXT_FLOW
bt
jae
IP_DST_MATCHER(ADDR_2,MASK_2)
; tcp_dst=PORT?
; action=ACTION_1
; second flow entry
; ip?
; jump to next flow entry
jmp ACTION_2
FLOW_3: ...
; ip_dst=ADDR_2/MASK_2?
; action=ACTION_2
For larger ﬂow tables, the compound hash template might
be the fastest choice. This template is used for tables com-
prising one or more ﬁelds whereas every ﬁeld is matched by
exactly the same mask in each entry. For instance, in the
below example the ﬁrst two entries would lend themselves
to the compound hash template (as ip_dst is masked with
/24 in both entries and tcp_dst is unmasked) while adding
the third entry would violate the prerequisite (as tcp_dst
is now a wildcard):
ip_dst=192.0.2.0/24,tcp_dst=80,action=ACTION_1
ip_dst=198.51.100.0/24,tcp_dst=21,action=ACTION_2
ip_dst=203.0.113.0/24,action=ACTION_3
The template works as follows: ﬁrst, the code runs to-
gether relevant header ﬁelds into a single key, applies the
global mask, and then looks up the key in a hash. Our imple-
mentation uses a collision free hash; even though it requires
Name: direct code
Prerequisite: #ﬂows ≤ CONST
Match type: arbitrary
Implementation: machine code
assembled on-the-ﬂy
Application: universal
Fallback: compound hash
Name: compound hash
Prerequisite: global mask
Match type: exact match
Implementation: perfect hash
Application: MAC switching &
port ﬁltering
Fallback: LPM
Name: LPM
Prerequisite: preﬁx masks, consistent
with priorities
Match type: longest preﬁx match
Implementation: DPDK LPM lib
Application: IP forwarding
Fallback: linked list
Name: linked list
Prerequisite: none
Match type: tuple space search
Implementation: machine code
with shared tuple matcher functions
Application: complex pipelines
Fallback: none
Figure 4: Flow table templates in ESWITCH.
more memory and more time to build, it supports fast con-
stant time lookups, a key to a robust datapath performance.
Whenever a ﬂow table does not fulﬁll the prerequisite for
compound hashes, ESWITCH falls back to an LPM template.
The LPM template applies to single-ﬁeld tables that contain
preﬁx rules: each mask is such that it wildcards the last con-
secutive bits of the ﬁeld and whenever rules overlap the more
speciﬁc one has higher priority. For instance, the below ex-
ample would violate the latter principle:
priority=100,ip_dst=192.0.2.0/24,action=ACTION_1
priority=20,ip_dst=192.0.2.12/30,action=ACTION_2
Our prototype uses the Intel DPDK built-in rte_lpm li-
brary for implementing the LPM template.
As a ﬁnal fallback, ESWITCH includes a linked list table
template for doing tuple space search [23]: for every rel-
evant combination of ﬁelds a separate matcher function is
constructed (out of the matcher templates introduced above)
and these matchers are called iteratively with subsequent
ﬂow entry keys as input. Since this template is rarely seen in
practice, we omit the details for brevity.
Action templates, ﬁnally, are used to construct packet pro-
cessing functionality. In this regard, ESWITCH takes a re-
freshingly simple approach: every action type (e.g., output
to a port, ﬂood, or modify header ﬁeld) is a separate action
template and action templates are collapsed into composite
action sets. Identical action sets are shared across ﬂows.
3.2 Flow Table Analysis
Template-based code generation, understandably, relies on
some mechanism to recognize the very templates in the in-
put. This is the responsibility of the ﬂow table analysis pass
in ESWITCH pipeline compilation.
Recognizing packet parser, matcher, and action templates
is fairly simple, but deciding on table templates is more in-
volving. In ESWITCH this occurs incrementally during code
generation: ESWITCH always attempts to compile into the
most efﬁcient table template available; whenever it detects
that the prerequisite no longer applies it gradually falls back
to the next most efﬁcient representation and rebuilds the ta-
ble with the new template (see Fig. 4 for template fallbacks).
In order to avoid that complex OpenFlow pipelines end up
with inefﬁcient templates, ESWITCH actively tries to trans-
form tables that may not ﬁt well with our templates into ones
that do, thereby promoting such “difﬁcult” ﬂow tables to-
wards faster templates. In the ﬁrewall example, for instance,
the single-stage pipeline (Fig. 1a) would ﬁt only the slow
linked list template (disregarding the direct code template for
a moment), while the multi-stage pipeline (Fig. 1b) would
admit a series of two hash-templates, which is much faster.
544
Pipeline transformation is done in the ﬂow table decom-
position pass. For brevity, herein we limit ourselves to a
heavily simpliﬁed exposition, which we believe is still sufﬁ-
cient to demonstrate the main points. In this setting, we are
given a ﬂow table T with m ﬂow entries deﬁned on n ﬁelds:
T = {(Fi,1, Fi,2, . . . , Fi,n) → ai : i ∈ [1, m]} ,
in which rules Fi,j can be of only two types: either an exact-
match or a full wildcard (arbitrary masks are disallowed for
now). Further suppose that we have only a single table tem-
plate available: a single-ﬁeld exact-match (hash) template
with a potential ﬁnal catch-all rule. Our task is to transform
T into a semantically equivalent [24, 37] pipeline compris-
ing the minimal possible number of ﬂow tables, each one
compliant with the template. An example is given in Fig. 5.
In the Appendix, we show that this simpliﬁed problem
is already intractable. Correspondingly, our ﬂow table de-
composition algorithms rely on heuristics, focusing on speed
instead of efﬁciency. The main iterative step is DECOM-
POSE(τ) given in Fig. 6; this routine is called ﬁrst on T and
then recursively on all the tables produced.
The key to the algorithm is step (4), which decomposes
a table T along one of its columns, in this case p, into a
new table that replaces T and matches only on p, plus a set
of further tables Tf for each separate key f in column p of
T . Note that the new table for T is already compliant with
the exact-match template and the rest of the tables will also
become compliant after the recursion terminates. The proce-
dure processes the entries in T one by one and takes the p-th
column: for each non-wildcard key f it merely just strips
column p from the rule and appends it to the table Tf , while
rules with a wildcard will go (stripped) to all tables.
One easily sees that the procedure terminates with a se-
mantically equivalent representation, with as many new ta-
bles as there are different keys in column p. On that ground,
decomposing along the column of minimal diversity gives a
heuristic algorithm that greedily minimizes the number or
tables produced (as of step (1) and (2) in Fig. 6).
An example is shown in Fig. 5: given the table in Fig. 5a,
decomposition along column ip_dst with 3 distinct keys
(plus the wildcard) would yield the tables at Fig. 5b at the
ﬁrst iteration and eventually terminate with 9 tables, while if
we chose column tcp_dst ﬁrst (of diversity 2) we would
end up with only 4 tables (Fig. 5c). ESWITCH will then
automatically substitute the initial table, and the ensuing in-
efﬁcient linked list template, with the decomposed pipeline
and hence promote it to a sequence of fast hash templates.
Astute readers will recognize here a decision-tree-based
packet classiﬁer scheme, each node of which is a separate
(a) input
(b) ﬁrst iteration of a suboptimal decomposition
Figure 5: Flow table decomposition: (a) a sample ﬂow table, (b) ﬁrst iteration of the heuristics after (suboptimally) decompos-
ing along ﬁeld ip_dst, and (c) an optimal decomposition containing only 4 tables. Observe that each table in the optimal
decomposition is consistent with the exact-match template. Table ids will be resolved after the algorithm terminates.
(c) optimal decomposition
Procedure DECOMPOSE(T ):
1. Find distinct keys in each column: Sj =
m(cid:91)
Fi,j , ∀j ∈ [1, n]
i=1
|Sj|
2. Find column of minimal diversity: p = argmin
j∈{1,...,n}
3. Initialize an empty table Tf for each ﬁeld value f ∈ Sp
4. Decompose table T along column p, suppose n > 1
for i ∈ 1, . . . , m do
if Fi,p = ∗ then
for f ∈ Sp in descending order of priority do
Tf .add((Fi,1, ..., Fi,p−1, Fi,p+1, ..., Fi,n) → ai)
TFi,p .add((Fi,1, ..., Fi,p−1, Fi,p+1, ..., Fi,n) → ai)
else
T.reset
for f ∈ Sp : Sp = {f1, f2, . . . , ∗} do
for f ∈ Sp : DECOMPOSE(Tf )
T.append(f → goto_table Tf )
Figure 6: Table decomposition routine.
ﬂow table, organized similarly to the the set-pruning trie data
structure [20] and HyperCuts [50] but doing matching ﬁeld-
wise and with a greedily optimized matching order. This
is then easy to extend to additional templates and arbitrary,
possibly overlapping, masked keys; we omit the details.
In line with the fundamental (rather prohibitive) lower
bounds for packet classiﬁcation [22], for very complex ﬂow
tables our decomposer cannot help but output an immense
number of tables. However, the depth of the hierarchy, and
thus the time it takes to send a packet through the pipeline,
is constrained by the number of header ﬁelds in the input ta-
ble only, which is usually not too large. Note that we are not
restricted by OpenFlow’s limit on maximum ﬂow table num-
ber (255) here, since decomposition is internal to ESWITCH.
Further note that decomposition does not necessarily occur
over layer boundaries (even though in many practical cases
it just happens to be the most efﬁcient decomposition strat-
egy); later we shall show an example in Fig. 7.
We evaluated the algorithm on a handful of real pipelines,
collected from a production multi-tenant OpenStack cloud
and a telco’s Border Network Gateway. Strikingly, in es-
sentially all cases our decomposer simply returned its in-
put intact, indicating that the pipeline had already been de-
composed optimally.
In fact, real-world controllers often
emit optimally decomposed pipelines out of the box for rea-
sons we alluded to in earlier sections: modularization, layer-
based processing, and avoidance of cross-product effects [2,
17, 18]. Correspondingly, we see table decomposition as an
optional feature for ESWITCH, which can be freely disabled
for most “well-behaved” control programs.
To still stress the algorithm to its limits, we fed it with a
complete ﬁrewall setup, consisting of arbitrarily wildcarded
ﬁve-tuple ACLs (“snort community rules v2.9”, stripped to
OpenFlow compatible rules): with the active 72 rules we
obtained only 50 separate tables in the decomposition, while
adding obsolete rules resulted in 197 tables on an input of
369 ACLs. This shows that, thanks to table decomposition,
ESWITCH can efﬁciently implement complex ﬁrewall and
intrusion detection functionality entirely in OpenFlow, with-
out having to recur to middleboxes.
3.3 Template Specialization & Linking
ESWITCH keeps the templates as a library of precompiled
object code fragments to avoid online assembling/compiling.
After the ﬂow table analysis pass, it builds the skeleton of