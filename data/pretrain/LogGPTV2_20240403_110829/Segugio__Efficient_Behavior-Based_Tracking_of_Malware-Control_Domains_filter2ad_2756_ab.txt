of domains queried by a machine was sufﬁcient to
remove these outlier machines.
The graph G may contain a number of domain nodes
that are queried by only one or very few machines.
(R3)
2We compute the effective second-level domain by leveraging the Mozilla
Public Sufﬁx List (publicsufﬁx.org) augmented with a large custom list of
DNS zones owned by dynamic DNS providers.
405405
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 08:49:35 UTC from IEEE Xplore.  Restrictions apply. 
(R4)
Because we are primarily interested in detecting mal-
ware domains that affect a meaningful number of
victim machines, we discard all domain names that
are queried by only one machine.
Very popular domains, i.e., domains that are queried
by a very large fraction of all machines in the mon-
itored network, are unlikely to be malware-control
domains. For example, assume we monitor an ISP
network serving three million users, in which a domain
d is queried by one million of them. If d was a
malware-control domain, this would mean that 1/3
of the ISP population is infected with the same
malware (or malware family). By extrapolation, this
would probably also mean that hundreds of millions
of machines around the Internet may be infected with
the same malware. While this scenario cannot be
completely ruled out, such successful malwares are
quite rare. In addition, due to the high number of
victims, the malware would draw immediate attention
from the security community, likely initiating exten-
sive remediation and take down efforts. Therefore,
we discard all domain names whose effective second-
level domain is queried by (cid:3) θm machines, where
θm is conservatively set to 1/3 of all machines in the
network, in our experiments.
To make our pruning even more conservative, we apply two
small exceptions to the above rules. Machines that are labeled
as malware are not pruned away by rule (R1), even if they
query very few domains. The reason is that a machine may
appear to be basically “inactive”, but the malware running on
the machine may periodically query a very small list (e.g., two
or three) malware-control domains. We therefore keep those
machine nodes, as they may (slightly) help to detect currently
unknown malware domains. Similarly, known malware-control
domains are kept in the graph, even if they are queried by only
one machine (exception to R3).
3) Behavior-Based Classiﬁer: We now describe how we
measure the features that describe unknown (i.e.,
to-be-
classiﬁed) domains, which aim to capture the intuitions we
outlined at the beginning of Section II. Then, we explain how
the behavior-based classiﬁer is trained and deployed. We divide
the domain features in three groups:
(F1) Machine Behavior (3 features):
Consider Figure 4. Let S be the set of machines
that query domain d, I ⊆ S be the subset of these
machines that are known to be infected (i.e., are
labeled as malware), and U ⊆ S be the subset
of machine labeled as unknown. We measure three
features: the fraction of known infected machines,
m = |I|/|S|; the fraction of “unknown” machines,
u = |U|/|S|; and the total number of machines,
t = |S|, that query d. These features try to capture
the fact that the larger the total number t and fraction
m of infected machines that query d, the higher the
probability that d is a malware-control domain.
Domain Activity (4 features):
Intuitively, newly seen domains are more likely to be
malware-related, if they are queried mostly by known
malware-infected machines. Registration information
(F2)
(F3)
may be of help, but some malware domains may
have a long registration period and remain “dormant”
for some time, waiting to be used by the attackers.
Instead of measuring the “age” of a domain, we aim
to capture its domain activity. Let tnow be the day in
which the graph G was built, and tpast be n days
in the past, w.r.t. tnow (e.g., we use n = 14 in
our experiments). We measure the total number of
days in which d was actively queried within the time
window [tnow−tpast], and the number of consecutive
days ending with tnow in which d was queried. We
similarly measure these two features for the effective
second-level domain of d.
IP Abuse (4 features):
Let A be the set of IPs to which d resolved during
our observation window T . We would like to know
how many of these IPs have been pointed to in the
past by already known malware-control domains. To
this end, we leverage a large passive DNS database.
We consider a time period W preceding tnow (e.g.,
we set W = 5 months, in our experiments). We then
measure the fraction of IPs in A that were associated
to known malware domains during W . Also, for each
IP in A we consider its /24 preﬁx, and measure the
fraction of such preﬁxes that match an IP that was
pointed to by known malware domains during W .
Similarly, we measure the number of IPs and /24’s
that were used by unknown domains during W .
Past Feature Use. It is worth noting that while information
similar to our IP abuse features (F3) has been used in previous
work, e.g.,
in Notos [3] and Exposure [4], we show in
Section IV-B that those features are indeed helpful but not
critical for Segugio to achieve high accuracy. In fact,
the
combination of our feature groups (F1) and (F2) by themselves
already allows us to obtain quite accurate classiﬁcation results.
In addition, in Section V we show that by combining the IP
abuse features with our machine behavior features, Segugio
outperforms Notos.
Classiﬁer Operation. To put Segugio in operation, we proceed
as follows. Let C be Segugio’s domain classiﬁer trained
during a trafﬁc observation window T1 (the training process
is explained later in this section). Our main objective is to
use C to classify unknown domains observed in DNS trafﬁc
from a different time window T2. To this end, we ﬁrst build a
machine-domain graph GT2 on trafﬁc from T2. Then, for each
unknown (i.e., to be classiﬁed) domain d ∈ GT2, we measure
the statistical features deﬁned earlier, as shown in Figure 4.
Then, we input d’s feature vector into the previously trained
classiﬁer C, which computes a malware score for d. If this
score is above a (tunable) detection threshold, we label d as
malware. The detection threshold can be chosen to obtain the
desired trade-off between true and false positives, which we
evaluate in Section IV.
Training Dataset. To obtain the dataset used to train the
classiﬁer C, we proceed as follows (see Figure 5). Let T1 be
the “training time” (e.g., one day). For each benign or malware
domain d observed during T1, we ﬁrst temporarily “hide” its
true label, and then measure its features as deﬁned earlier.
The reason why we need to temporarily hide the ground truth
related to d is precisely to enable feature measurement. In
406406
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 08:49:35 UTC from IEEE Xplore.  Restrictions apply. 
labeled domains (malware or benign)
to-be-classiﬁed (unknown)
d
?
?
?
?
labeled machines (malware or benign)
unknown machines
?
?
measure d's
features
feature vector
V1
V2
,
,
,
Vn
Behavior-Based
Classiﬁer
Score(d)
Fig. 4: Overview of Segugio’s feature measurement and classiﬁcation phase. First domain d’s features are measured, and then the feature vector is assigned a
“malware score” by the previously trained classiﬁer.
d
dd
?
hide d's ground truth
d
?
?
measure d's features
label feature vector
l
i
e
p
m
a
s
g
n
n
a
r
t
i
M1
M2
M3
M4
?
M1
M2
M3
M4
l
d
e
e
b
a
l
V1
V2
,
,
,
Vn
Fig. 5: Training set preparation: extracting the feature vector for a known malware-control domain. Notice that “hiding” d’s label causes machine M1 to also
be labeled as unknown, because in this example d was the only known malware-control domain queried by M1. Machines M2, M3, M4 queried some other
known malware domains, and therefore keep their original labels.
fact, our deﬁnition of features (see above) applies to unknown
domains only, because if a domain is already known to be
malware, its ﬁrst two machine behavior features, for example,
would be by deﬁnition always one and zero, respectively.
Notice that hiding d’s true label may have an impact on
the label assigned to the machines that query it. For example,
if d is a malware domain and there exists a machine that was
labeled as malware only because it queried d, once we hide d’s
ground truth that machine should also be relabeled as unknown,
as shown for machine M1 in the example in Figure 5. After
measuring the features, we label the obtained feature vector
with d’s original label (see Figure 5). By repeating this process
for every malware and benign domain, we obtain a dataset
that can be used to train the statistical classiﬁer C (e.g., using
Random Forest [9], Logistic Regression [10], etc.).
III. EXPERIMENTAL SETUP
We deployed Segugio into two large regional ISP networks,
one located in the North West Coast and one in the West
United States. We refer to these ISP networks simply as ISP1
and ISP2. Notice that this paper is part of an IRB-approved
study; appropriate steps have been taken by our data provider
to minimize privacy risks for the network users.
By inspecting the DNS trafﬁc between the ISPs’ customers
and their local resolvers, we observed between roughly one
to four million distinct machine identiﬁers per day (notice
that the identiﬁers we were provided were stable, and did not
appreciably suffer from DHCP effects, for example). Most of
our experiments with Segugio were conducted in the month of
April, 2013. In particular, we randomly sampled four days of
trafﬁc from that month, per each of the ISP networks. Table I
summarizes the number of distinct machines and domains
observed in the trafﬁc, and the (randomly) sampled days used
in our evaluation.
Domain and Machine Labeling. To label the known malware
domain names, we check if its entire domain name string
matches a domain in our C&C blacklist. We made use of
a large commercial C&C domain blacklist containing tens
of thousands of recently discovered malware-control domains
(in Section IV-E we also report on experiments using public
blacklists). The advantage of using a commercial blacklist, is
that domains are carefully vetted by expert threat analysts,
to minimize noise (i.e., mislabeled benign domains). All ma-
chines that query a known C&C domain are also labeled as
malware, because we assume benign machines would have no
reason to query “malware-only” C&C domains (see Section VI
for possible limitations).
To label known benign domains, we collected a one-
year archive of popular effective second-level domain (e2LD)
rankings according to alexa.com. Speciﬁcally, every day for
one year, we collected the list of top one million (1M, for short)
popular domain names. Then, we searched this large archive
for domain names that consistently appeared in the top 1M
list for the entire year. This produced a list of 458,564 popular
e2LDs, which we used to label benign domains. Accordingly,
we label a domains d as benign if its e2LD matches the
whitelist. For example, we would label www.bbc.co.uk as
benign, because its e2LD is bbc.co.uk, which is whitelisted.
The reason why we only add “consistently top” e2LDs
to our whitelist, is that sometimes malicious domains may
become “popular” (due to a high number of victims) and
enter the top 1M list for a brief period of time. The vast
majority of such domains can be ﬁltered out by the ﬁltering
strategy described above. In addition, we ﬁlter out e2LDs
that allow for the “free registration” of subdomains, such as
popular blog-publishing services or dynamic DNS domains
(e.g., wordpress.com and dyndns.com), as their subdomains
are often abused by attackers. At the same time, as mentioned
in Section II-A1, we acknowledge that perfectly ﬁltering all
such “special” e2LDs may be difﬁcult, and some small amount
of noise may remain in the whitelist. In Section IV-D we
discuss how the possible remaining noise may potentially
inﬂate the number of false positives we measure. Notice that
such whitelist noise may cause us to underestimate Segugio’s
true accuracy (i.e., the accuracy we could otherwise achieve
with a perfectly “clean” whitelist), and we therefore believe
this is acceptable because it would not artiﬁcially favor our
407407
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 08:49:35 UTC from IEEE Xplore.  Restrictions apply. 
evaluation.
Table I summarizes the number of benign and malware
domains and machines we observed.
Trafﬁc Source
Num. of Domains
TABLE I: Experiment data (before graph pruning).
Num. of Machines
Total
Malware
∼ 1.6M
50,339
∼ 1.6M
49,944
∼ 1.6M
47,506
∼ 1.6M
44,299
∼ 4M
78,990
∼ 3.9M
74,098
∼ 3.9M
69,773
∼ 4M
72,519
Total
Benign
∼ 9M
∼ 1.8M
ISP1, Day 1 (Apr.02)
∼ 9M
∼ 1.9M
ISP1, Day 2 (Apr.15)
∼ 8.2M
∼ 1.8M
ISP1, Day 3 (Apr.23)
∼ 10M
∼ 1.9M
ISP1, Day 4 (Apr.28)
ISP2, Day 1 (Apr.08) ∼ 10.2M
∼ 2M
∼ 9.8M
∼ 2M
ISP2, Day 2 (Apr.20)
∼ 9.6M
∼ 2M
ISP2, Day 3 (Apr.26)
ISP2, Day 4 (Apr.30) ∼ 10.6M ∼ 2.2M
Malware
13,239
20,277
18,020
11,597
15,706
14,279
36,758
13,467
Edges
∼ 319.9M
∼ 324.2M
∼ 310.7M
∼ 312.3M
∼ 352.6M
∼ 347.1M
∼ 333.7M