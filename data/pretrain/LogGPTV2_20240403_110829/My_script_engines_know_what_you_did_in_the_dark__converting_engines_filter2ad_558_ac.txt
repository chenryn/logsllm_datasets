scripts. For VBScript of ReactOS, we extracted vbscript.dll from
ReactOS and transplanted it to the Windows of the experimental
environment VM because Intel Pin used by STAGER does not work
properly on ReactOS.
For proprietary engines, we used Microsoft VBScript and VBA
implemented in Microsoft Office. These script engines are also se-
lected because they are widely used by attackers. When we analyze
the script engine of VBA, we first execute Microsoft Office and
observe its process during the execution of the attached script.
5.2 Detection Accuracy
To answer RQ1, we evaluated the detection accuracy of the hook
and tap point detection steps. We detected hook and tap points of
VBA, VBScript, and PowerShell using STAGER. We selected script
APIs that are widely used by malicious scripts for the target of hook
Table 2: Experimental environment
OS
CPU
RAM
VBA
VBScript
VBScript
PowerShell
Windows 7 32-bit
Intel Core i7-6600U CPU @ 2.60GHz
2GB
VBE7.dll (Version 7.1.10.48)
vbscript.dll (Version 5.8.9600.18698)
vbscript.dll (ReactOS 0.4.9)
PowerShell 6.0.3
and tap point detection. VBA and VBScript is designed to use COM
objects for interacting with the OS, instead of directly interacting
with it. Therefore, malicious scripts using VBA and VBScript use
script APIs related to COM object handling. In addition, VBA has
useful script APIs and VBScript has those of reflection such as
Eval and Execute, used for obfuscation. PowerShell has script APIs
called Cmdlets that provide various functionalities including OS
interaction. We selected Cmdlets of object creation, file operation,
process execution, internet access, reflection, etc., which are often
used by malicious scripts.
Table 3 shows the results of the experiments. The Original Points
column shows the number of branches obtained by the branch
traces. The Hook Point Candidates column shows the number of
hook point candidates filtered by hook point detection. The Hook
and Tap Point Detection column has ✓if the final hook and tap point
were obtained. The Log Availability column has ✓if the obtained
hook and tap point output the correct log corresponding to the
known scripts.
For VBA and VBScript, STAGER could accurately detect all hook
and tap points that can output logs showing the script APIs and
their arguments. Despite the large number of obtained branches,
STAGER could precisely filter the branches that are irrelevant to
the target script APIs. This showed that STAGER is applicable to
real-world proprietary script engines to generate the corresponding
script API tracers.
STAGER could also detect CreateObject and Invoke on VBScript
of ReactOS. However, STAGER was not applicable for detecting the
hook points of Eval and Execute because the VBScript in ReactOS
has just mocks of them, which have no actual implementation.
We checked the source code to confirm the corresponding lo-
cation of the detected hook points. The hook was inserted into
the local function of create_object, which definitely create ob-
jects. We found that the hook was inserted into the local func-
tion of disp_call, which is responsible for invocation of the IDis-
patch::Invoke COM interface.
As shown in Table 3, STAGER also detected proper hook and tap
points for PowerShell. A notable difference among the script en-
gines of PowerShell and the others is the existence of an additional
layer: a common language infrastructure (CLI). PowerShell uses a
CLI of the Microsoft .NET Framework, which is an additional layer
between the OS and script engine. Since STAGER properly found
the hook and tap points of PowerShell, we confirmed that it works
even for script engines with an additional layer such as CLI.
Overall, STAGER could properly detect all hook and tap points
in all VBA, VBScript, VBScript (ReactOS) and PowerShell script
472engines except Eval and Execute of VBScript (ReactOS), which were
not implemented.
5.3 Performance
To answer RQ2, we evaluated the performance of STAGER by mea-
suring the execution duration of each of its steps. Figure 5 shows
the results. Note that the execution time in this figure does not
include the time for preparing test scripts because it should be
manually created before the execution.
Execution trace logging and tap point detection required about 10
seconds due to the overhead of execution and log output with Intel
Pin. Backtrace performed just a little exploration of execution trace;
therefore it took little time. On the other hand, differential execution
analysis took about 5 seconds. The computational complexity of
the Smith-Waterman algorithm is O(MN), where the length of one
sequence is M and the other sequence is N . Thus, the longer the
execution trace becomes, the longer the execution duration will be.
Overall, hook and tap point detection for one script API took
about 30 seconds. The number of all script APIs in VBScript is less
than one hundred according to the language specifications, and the
script APIs of interest for malicious script analysis is limited. There-
fore, the proposed method could quickly analyze script engines and
generate a script API tracer, which is sufficient for practical use.
Dridex. From these results, we confirmed that the script API tracers
generated by STAGER are applicable to real-world malicious scripts.
Note that we will upload all our analysis logs after the publication
of this paper. We selected two samples and their analysis logs as
case studies. The first is a VBScript downloader, and the second is
a PowerShell fileless malware module.
5.4.1 Case Study 1: Downloader. Figure 6 shows the analysis log
of a VBS downloader generated by a script API tracer. Although
this malicious script has 1500+ lines of obfuscated code, the log
consists of only 16 lines, which are responsible for the main be-
havior of downloading. Section (1) in the figure shows a part of
the log in which the malicious script accessed a URL. Section (2)
shows that the script saved the HTTP response to a specific file
in the Temp folder. The saved buffer is also visible as a byte array
of 0x3c 0x68 .... Section (3) shows that the saved file was executed
through cmd.exe. As shown in this figure, the script API tracers
generated by STAGER could successfully extract important indica-
tors of compromise (IOCs) such as URLs, binaries, file paths and
executed commands. Note that the log fulfills the requirement of
the preservability of semantics mentioned in Section 2.1.
Figure 5: Execution duration of our method.
5.4 Analysis of Real-World Malicious Scripts
To answer RQ3, we applied the script API tracers generated by
STAGER for analyzing malicious scripts in the wild. We collected 205
samples of malicious scripts that were uploaded to VirusTotal [1]
between 2017/1 and 2017/7. We then analyzed them using the script
API tracers.
We found that the script API tracers could properly extract the
called script APIs and their arguments executed by the malicious
scripts. We investigated the URLs obtained as arguments of script
APIs. All were identified as malicious (positives > 1). We also inves-
tigated the file streams of the script API arguments. The results of
the investigation showed that the streams were ransomware such as
Figure 6: Analysis log of VBS downloader with script API
tracer
5.4.2 Case Study 2: Fileless Malware. Figure 7 shows an excerpt of
the analysis log of a module used by PowerShell fileless malware.
This module seems to retrieve additional PowerShell modules from
the C&C server and execute it. Section (1) in this figure shows the
spawn of a new PowerShell process with commands used for Web
access. We can see the executed command with deobfuscated form.
Section (2) shows the simple downloading of the additional code
using a system Web proxy. Section (3) shows the execution of the
retrieved additional PowerShell code with the reflection function
Invoke-Expression. In addition to Case Study 1, we can understand
what code is dynamically evaluated by reflection functions. This
will help malware analysts to understand the behavior of malicious
scripts.
5.5 False Positives and False Negatives
To answer RQ4, we tested the number of FPs and FNs produced by
the hook and tap points of the STAGER-generated script API tracers
by analyzing known malicious scripts.
473Script
VBA
VBScript
VBScript
(ReactOS)
PowerShell
Script API
CreateObject
Invoke (COM)
Declare
Open
Print
CreateObject
Invoke (COM)
Eval
Execute
CreateObject
Invoke (COM)
Eval
Execute
New-Object
Import-Module
New-Item (File)
Set-Content (File)
Start-Process
Invoke-WebRequest
Invoke-Expression
Table 3: Result of hook and tap point detection.
Original Points Hook Point Candidates Hook and Tap Point Detection
Log availability
93000090
101993701
94281492
85641170
90024821
390836
1148225
369070
371040
89213
128511
-
-
210852
185192
198327
200822
152841
315380
271054
53
98
34
42
29
48
92
121
134
32
43
-
-
54
48
93
54
119
98
82
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
Not applicable
Not applicable
Not applicable
Not applicable
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
a script API tracer for VBA based on script-level monitoring that is
based on the emulator implemented for itself.
To evaluate them in the same conditions, we gathered VBA mali-
cious scripts since ViperMonkey is a tracer of the scrip APIs of VBA.
Therefore, we generated a script API tracer for VBA with STAGER
(STAGER-generated tracer). We randomly chose five samples from
the data set and manually analyzed them to create ground truth.
The evaluation is performed from three viewpoints: ratio of prop-
erly observed behavior, average number of log lines, and analysis
failure rate.
Table 4 shows the experimental results. Note that columns of
observed behavior and log lines of ViperMonkey are calculated only
with the samples that are analyzed successfully. API Monitor could
only observe a small amount of behavior because some behavior
such as COM method invocation and reflection cannot be directly
observed through system APIs. In addition, it produced a large
number of log lines that are irrelevant to the behavior of the samples
because it cannot focus only on their behavior. The log lines include
the behavior derived from the script engines as well as that derived
from the samples. In other words, the avalanche effect mentioned
in Section 2.2.2 occurred.
ViperMonkey failed to analyze three samples due to insufficient
implementation of the VBA emulator. When it failed to parse the
samples, it terminated the execution with an error. ViperMonkey
missed some behavior because of the lack of the hooked script APIs.
In contrast, the STAGER-generated tracer successfully analyzed
the samples because it uses the real script engine of VBA and
its instrumentation does not ruin the functionality of the engine.
It could observe the whole behavior with few lines of logs that
properly focused on the script APIs of the samples.
Figure 7: Analysis log of PowerShell fileless malware with
script API tracer
We know this experiment can evaluate only partial FPs and FNs;
however, we conducted this because exhaustively evaluating the
number of FPs and FNs is difficult. FPs indicate the log lines of
called script APIs that are NOT actually called by the target script
regarding the hook and tap points. FNs indicate the script APIs
missing in the log lines, which are actually called by the target
script regarding the hook and tap points.
The script API tracers used for this experiment have tracing
capability of the script APIs shown in Table 3. We used five samples
whose called script APIs are known by manual analysis. The result
of the experiment showed that the hook and tap points produced
neither FPs nor FNs.
5.6 Comparison with Existing Tracers
To answer RQ5, we compared a STAGER-generated script API tracer
with two existing tracers: API Monitor [4] and ViperMonkey [18].
API Monitor is a system API tracer based on system-level monitor-
ing. We enabled all system API hooks of API Monitor and made API
Monitor observe the target script engine process. ViperMonkey is
474Table 4: Comparison with existing tracers
Tracer
API Monitor
ViperMonkey
STAGER-generated
Observed behaviors
0.25
0.8