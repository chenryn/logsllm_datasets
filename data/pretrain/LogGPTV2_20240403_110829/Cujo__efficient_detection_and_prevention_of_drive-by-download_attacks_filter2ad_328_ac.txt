ticular, we present explanations for the detection techniques
detailed in Section 2.3 using q-grams of static and dynamic
analysis reports, where we select the best q for each analysis
type from the previous experiment.
As the ﬁrst examples, we consider the q-grams (4-grams)
reported by Cujo for the static analysis of two detected
drive-by downloads. Figure 6(a) shows the top ﬁve q-grams
contributing to the detection of a heap-spraying attack. Some
patterns indicative for this attack type are clearly visible:
the ﬁrst q-grams match a loop involving strings, while the
last q-grams reﬂect an empty try-catch block. Both pat-
terns are regularly seen in heap spraying, where the loop
performs the actual spraying and the try-catch block is used
for inhibiting exceptions during memory corruption.
Figure 6(b) shows the q-grams reported for the static de-
tection of an obfuscated drive-by download. At the ﬁrst
glance, the top q-grams indicate only little malicious ac-
tivity. However, they reveal the presence of a XOR-based
decryption routine. Patterns of a loop, the XOR operator
and a call to the EVAL function here jointly contribute to the
detection of the obfuscation.
Contribution Features
φs(x) · ws
0.044
0.043
0.042
0.039
0.039
s ∈ S (4-grams)
+ STR.01 , STR.01
WHILE ( ID .
= ID + ID
{ TRY { VAR
) { } }
(a) Top q-grams of a heap-spraying attack
Contribution Features
φs(x) · ws
0.124
0.121
0.112
0.104
0.096
s ∈ S (4-grams)
= ID + ID
; EVAL ( ID
( ID ) ^
) ; } ;
STR.01 ; FOR (
Overall, this experiment demonstrates the excellent detec-
tion performance of Cujo which identiﬁes the vast majority
of drive-by downloads with very few false alarms—although
all attacks have been unknown to the system. Cujo thereby
signiﬁcantly outperforms current anti-virus tools and is al-
most on par with the oﬄine analysis system Jsand.
3.3 Explanations
After studying the detection accuracy of Cujo, we explore
its ability to equip alerts with explanations, which provides a
valuable instrument for analysis of detected attacks. In par-
(b) Top q-grams of an obfuscated attack
Figure 6: Examples for the explanation of static de-
tection. The ﬁve q-grams with highest contribution
to the detection are presented.
As examples for the dynamic analysis, Figure 7(a) shows
the top q-grams (3-grams) contributing to the dynamic de-
tection of a heap-spraying attack. Again the attack type is
clearly manifested: the ﬁrst q-gram corresponds to the ab-
stract operation HEAP SPRAYING DETECTED which is triggered
Contribution Features
φs(x) · ws
0.190
0.121
0.053
0.053
0.036
s ∈ S (3-grams)
HEAP SPRAYING DETECTED
CALL unescape SET
SET global.shellcode TO
unescape SET global.shellcode
TO "%90%90%90%90%90%90%90...
(a) Top q-grams of a heap-spraying attack
Contribution Features
φs(x) · ws
0.036
0.030
0.025
0.024
0.024
s ∈ S (3-grams)
CALL unescape CALL
CALL fromCharCode CALL
CALL eval CONVERT
parseInt CALL fromCharCode
CALL createElement ("object")
(b) Top q-grams of an obfuscated attack
Figure 7: Examples for the explanation of dynamic
detection. The ﬁve q-grams with highest contribu-
tion to the detection are presented.
by our sandbox and indicates unusual memory activity. The
remaining q-grams reﬂect typical patterns of a shellcode con-
struction, including the unescaping of an encoded string and
a so-called NOP sled.
A further example for dynamic detection is presented in
Figure 7(b), which shows the top ﬁve q-grams of an obfus-
cated attack. Several calls of functions typical for obfus-
cation and corresponding substitution ciphers are visible,
including eval and unescape as well as the conversion func-
tions parseInt and fromCharCode used during decryption of
the attack. The last q-gram reﬂects the instantiation of an
object likely related to a vulnerability in a browser exten-
sion, though the actual details of this exploitation are not
covered by the ﬁrst ﬁve q-grams.
It is important to note that these explanations are speciﬁc
to the detection of individual attacks and must not be inter-
preted as stand-alone detection rules. While we have only
shown the top q-grams for explanation, the underlying de-
tection models involve several million diﬀerent q-grams and
thus realize a far more complex decision function.
3.4 Run-time Performance
Given the accurate detection of drive-by downloads, it re-
mains to show that Cujo provides suﬃcient run-time per-
formance for practical application. Hence, we ﬁrst examine
the individual run-time of each system component individ-
ually and then study the overall processing time in a real
application setting with multiple users. All run-time exper-
iments are conducted on a system with an Intel Core 2 Duo
3 GHz processor and 4 Gigabytes of memory.
3.4.1 Run-time of Components
For the ﬁrst analysis, we split the total run-time of Cujo
into the contributions of individual components as depicted
in Figure 1. For this, we add extra timing information to
the JavaScript analysis, the feature extraction and learning-
based detection. We then measure the exact contributions
to the total run-time on a sample of 10,000 URLs from the
Alexa-200k data set.
Figure 8 shows the median run-time per URL in mil-
liseconds, including loading of a web page, pre-loading of
Figure 8: Median run-time of Cujo per URL on
10,000 URLs from the Alexa-200k data set.
Figure 9: Statistical breakdown of run-time for
JavaScript lexing (LX), sandbox emulation (SE),
feature extraction (FE) and detection (DE).
external JavaScript code and the actual analysis of Cujo.
Surprisingly, most of the time is spent for loading and pre-
loading of content, whereas only 14% is devoted to the anal-
ysis part of Cujo. As we will see in the following section,
we can greatly beneﬁt from this imbalance by employing
regular caching techniques.
A detailed statistical breakdown of the analysis run-time
is presented in Figure 9, where the distributions of run-time
per URL are plotted for the static and dynamic analysis sep-
arately. Each distribution is displayed as a boxplot, in which
the box itself represents 50% of the data and the lower and
upper markers the minimum and maximum run-time per
URL. Additionally, the median is given as a middle line in
each box. Except for the sandbox emulation, all components
induce a very small run-time overhead ranging between 0.01
and 10 ms per URL. The sandbox analysis requires a me-
dian run-time of 370 ms per URL which is costly but still
signiﬁcantly faster then related sandbox approaches.
3.4.2 Operating Run-time
In the last experiment, we evaluate the run-time of Cujo
in a real application setting. In particular, we deploy Cujo
as a web proxy and measure the time required per delivery
of a web page. To obtain reproducible measurements, we
use the Surﬁng data set as basis for this experiment, as it
contains multiple surﬁng sessions of ﬁve individual users.
For comparison, we also employ a regular web proxy, which
just forwards data to the users. As most of the total run-time
is spent for loading and pre-loading of resources, we enable
all caching capabilities in Cujo and the regular proxy.
Results for this experiment are shown in Figure 10, where
the distribution of run-time per URL is presented as a den-
  1697 ms    681 ms    372 ms    LoadingPre−LoadingAnalysisLXFEDESEFEDE10−210−1100101102103StaticDynamicRun−time per URL (ms)Closest to our work is the analysis system Jsand devel-
oped by Cova et al. [4] as part of the Wepawet service.
Jsand analyses JavaScript using the framework HtmlUnit
and the interpreter Rhino which enable the emulation of
an entire browser environment and monitoring of sophisti-
cated interaction with the DOM tree. The recorded behavior
is analysed using 10 features speciﬁc to drive-by-download
attacks for anomalous activity. Due to its public web in-
terface, Jsand is frequently used by security researchers to
study novel attacks and has proven to be a valuable analysis
instrument. However, its broad analysis of JavaScript code
is costly and induces a prohibitive average run-time of about
25 seconds per web page [cf. 4].
Finally, the system Noxes devised by Kirda et al.
[12]
implements a web proxy for preventing cross-site scripting
attacks. Although not directly related to this work, Noxes
is a good example of how a proxy system can transparently
protect users from malicious web content. Obviously, this
approach targets only cross-site scripting attacks and does
not protect from other threats, such as drive-by downloads.
5. CONCLUSIONS
In this paper, we have presented Cujo, a system for eﬀec-
tive and eﬃcient prevention of drive-by downloads. As an
extension to a web proxy, Cujo transparently inspects web
pages using static and dynamic detection models and allows
for blocking malicious code prior to delivery to the client.
In an empirical evaluation with 200,000 web pages and 600
drive-by-download attacks, a prototype of this system sig-
niﬁcantly outperforms current anti-virus products and en-
ables detecting 94% of the drive-by downloads with few false
alarms and a median run-time of 500 ms per web page—a
delay hardly perceived at the web client.
While the proposed system does not generally eliminate
the threat of drive-by downloads, it considerably raises the
bar for adversaries to infect client systems. To further harden
this defense, we currently investigate combining Cujo with
oﬄine analysis and honeypot systems. For example, mali-
cious code detected using honeypots might be directly added
to the training data of Cujo for keeping detection models
up-to-date. Similarly, oﬄine analysis might be applied for
inspecting and explaining detected attacks in practice.
Acknowledgements
The authors would like to thank Marco Cova for providing
the attack data sets as well as Martin Johns and Thorsten
Holz for fruitful discussions on malicious JavaScript code
and its detection.
References
[1] Standard ECMA-262: ECMAScript Language Speciﬁ-
cation (JavaScript). 3rd Edition, ECMA International,
1999.
[2] Symantec Global Internet Security Threat Report:
Trends for 2009. Vol. XIV, Symantec, Inc., 2010.
[3] A. Aho, R. Sethi, and J. Ullman. Compilers Principles,
Techniques, and Tools. Addison-Wesley, 1985.
[4] M. Cova, C. Kruegel, and G. Vigna. Detection and
analysis of drive-by-download attacks and malicious
Figure 10: Operating run-time of Cujo and a regular
web proxy on the Surﬁng data set.
sity plot. As expected the regular proxy ranges in the front
part of the plot with a median processing speed of roughly
150 ms per request. The run-time of Cujo is slightly shifted
to the right in comparison with the regular proxy. However,
the median run-time lies around 500 ms per web page, thus
inducing only a minimal delay at the web client. For ex-
ample, the median run-time for visiting web pages from the
domains google.com and yahoo.com using Cujo is 460 ms
and 266 ms, respectively.
In contrast to the regular proxy, the run-time distribu-
tion of Cujo shows an elongated tail, where few web pages
require more than 3,000 ms for processing due to excessive
analysis of JavaScript code. For instance, visiting pages from
facebook.com induces a median run-time of 1,560 ms. Still,
this experiment demonstrates that Cujo strongly beneﬁts
from caching capabilities, such that only a minor delay can
be perceived at the web client.
4. RELATED WORK
Since the ﬁrst discovery of drive-by downloads, analysis
and detection of this threat has been a vital topic in se-
curity research. One of the ﬁrst studies on these attacks
and respective defenses has been conducted by Provos et al.
[15, 16]. The authors inspect web pages by monitoring a web
browser for anomalous activity in a virtual machine. This
setup allows for detecting a broad range of attacks. How-
ever, the analysis requires prohibitive run-time for on-line
application, as the virtual machine needs to be restored and
run for each web page individually.
A similar approach for identiﬁcation of drive-by down-
loads is realized by client-based honeypots, such as Capture-
HPC [21] and PhoneyC [14]. While Capture-HPC also re-
lies on monitoring state changes in a virtual machine, Phon-
eyC emulates known vulnerabilities to capture attacks in a
lightweight manner. Although eﬀective in identifying web
pages with malicious content, client-based honeypots are de-
signed for oﬄine analysis and thus suﬀer from considerable
run-time overhead.
In contrast to these generic techniques, other approaches
focus on identifying particular attacks types, namely heap-
spraying attacks. For example, the system Nozzle proposed
by Ratanaworabhan et al. [17] intercepts the memory man-
agement of a browser for detecting valid x86 code in heap
objects. Similarly, Egele et al. [8] instrument SpiderMon-
key for scanning JavaScript strings for the presence of ex-
ecutable x86 code. Both systems provide an accurate and
eﬃcient detection of heap-spraying attacks, yet they fail to
identify other common types of drive-by-download attacks,
for example, using insecure interfaces of browser extensions
for infection.
050010001500200025003000350040004500Run−time per URL (ms)Probability density  50%75%90%Regular proxyCujo proxy[18] K. Rieck and P. Laskov. Detecting unknown network at-
tacks using language models. In Detection of Intrusions
and Malware & Vulnerability Assessment (DIMVA),
pages 74–90, July 2006.
[19] K. Rieck and P. Laskov. Linear-time computation of
similarity measures for sequential data. Journal of Ma-
chine Learning Research, 9(Jan):23–48, 2008.
[20] B. Sch¨olkopf and A. Smola. Learning with Kernels. MIT
Press, Cambridge, MA, 2002.
[21] C. Seifert and R. Steenson. Capture – honeypot client
(Capture-HPC). Victoria University of Wellington, NZ,
https://projects.honeynet.org/capture-hpc, 2006.
[22] K. Wang, J. Parekh, and S. Stolfo. Anagram: A content
anomaly detector resistant to mimicry attack. In Recent
Advances in Intrusion Detection (RAID), pages 226–
248, 2006.
JavaScript code.
Wide Web Conference (WWW), 2010.
In Proc. of the International World
[5] M. Daniel, J. Honoroﬀ, and C. Miller. Engineering heap
overﬂow exploits with JavaScript. In Proc. of USENIX
Workshop on Oﬀensive Technologies (WOOT), 2008.
[6] A. Dewald, T. Holz, and F. Freiling. ADSandbox:
Sandboxing JavaScript to ﬁght malicious websites.
In Proc. of ACM Symposium on Applied Computing
(SAC), 2010.
[7] M. Egele, E. Kirda, and C. Kruegel. Mitigating drive-by
download attacks: Challenges and open problems. In
Proc. of Open Research Problems in Network Security
Workshop (iNetSec), 2009.
[8] M. Egele, P. Wurzinger, C. Kruegel, and E. Kirda. De-
fending browsers against drive-by downloads: Mitigat-
ing heap-spraying code injection attacks. In Detection
of Intrusions and Malware & Vulnerability Assessment
(DIMVA), 2009.
[9] R.-E. Fan, K.-W. Chang, C.-J. Hsieh, X.-R. Wang,
and C.-J. Lin. LIBLINEAR: A library for large linear
classiﬁcation. Journal of Machine Learning Research,
9:1871–1874, 2008.
[10] S. Forrest, S. Hofmeyr, A. Somayaji, and T. Longstaﬀ.
A sense of self for Unix processes.
In Proc. of IEEE
Symposium on Security and Privacy, pages 120–128,
Oakland, CA, USA, 1996.
[11] M. Johns. On JavaScript malware and related threats –
Web page based attacks revisited. Journal in Computer
Virology, 4(3):161–178, 2008.
[12] E. Kirda, C. Kruegel, G. Vigna, , and N. Jovanovic.
Noxes: A client-side solution for mitigating cross site
scripting attacks. In Proc. of ACM Symposium on Ap-
plied Computing (SAC), 2006.
[13] K.-R. M¨uller, S. Mika, G. R¨atsch, K. Tsuda, and
B. Sch¨olkopf. An introduction to kernel-based learn-
ing algorithms. IEEE Neural Networks, 12(2):181–201,
May 2001.
[14] J. Nazario. A virtual client honeypot.
In Proc. of
USENIX Workshop on Large-Scale Exploits and Emer-
gent Threats (LEET), 2009.
[15] N. Provos, P. Mavrommatis, M. Rajab, and F. Monrose.
In Proc. of USENIX
All your iframes point to us.
Security Symposium, 2008.
[16] N. Provos, D. McNamee, P. Mavrommatis, K. Wang,
and N. Modadugu. The ghost in the browser: Analysis
of web-based malware. In Proc. of USENIX Workshop
on Hot Topics in Understanding Botnets (HotBots),
2007.
[17] P. Ratanaworabhan, B. Livshits, and B. Zorn. Noz-
zle: A defense against heap-spraying code injection at-
tacks. Technical Report MSR-TR-2008-176, Microsoft
Research, 2008.