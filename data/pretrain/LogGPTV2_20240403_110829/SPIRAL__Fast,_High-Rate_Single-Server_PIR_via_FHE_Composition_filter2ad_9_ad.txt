i
Remark IV.2 (Query Size Trade-off and the SPIRALSTREAM
Protocol). To reduce noise growth in Construction IV.1, the
client can directly upload the Regev encodings c(Reg)
and
for i ∈ [2ν1] and j ∈ [tGSWν2] as part of its query
c(GSW)
j
rather than compress them into a single encoding. This yields
larger queries, but eliminates the noise growth from query
expansion. As we discuss in Section V, this setting is appealing
for streaming scenarios where the same query is reused for
a large number of consecutive requests. Note that it still
remains advantageous to use our Regev-to-GSW transformation
(Section III-B and Remark III.1) rather than send GSW
encodings directly. This is because GSW encodings are much
larger than Regev encodings and the expansion process is fast
and only introduces a small amount of noise. We refer to this
variant of SPIRAL as SPIRALSTREAM.
Correctness. Correctness of Construction IV.1 holds as long
as the encoding modulus q is large enough to accommodate the
noise accumulation from the homomorphic operations. We give
a detailed description of our parameter selection methodology
in Section V-A. We provide a formal statement in the full
version of this paper [42].
Security. Security of our construction follows from the RLWE
assumption and a circular security assumption (for the public
parameters). Speciﬁcally, the query in SPIRAL is a Regev
encryption of the query, and the public parameters consist of
key-switching matrices, which are encryptions of key-dependent
messages. Security can thus be based on RLWE and similar
circular-security assumptions as those underlying previous
lattice-based PIR schemes [5, 23]. We provide the formal
statement and analysis in the full version of this paper [42].
A. SPIRALPACK: Higher Rate via Encoding Packing
In this section, we describe a variant of SPIRAL (called SPI-
RALPACK) that enables a higher rate and a higher throughput
(for large records) at the expense of larger public parameters.
As we discuss in greater detail in Section V-A, the plaintext
dimension n in SPIRAL directly affects the rate and the
throughput. A larger value of n yields a higher rate (i.e., the
rate scales with n2/(n2 + n)). However, the cost of processing
the ﬁrst dimension scales quadratically with n.
Here, we describe an encoding packing approach that allows
us to enjoy the “best of both worlds.” At a high level, our
approach takes n2 Regev encodings of scalars and packs them
into a single matrix Regev encoding of an n × n matrix. To
leverage this to achieve higher rate, we modify SPIRAL as
follows:
• Break each record in the database into n2 blocks of equal
length. This yields a collection of n2 different databases,
where the ith database contains the ith block of each record.
To process a query, the server applies the query to each of
the n2 databases.
• The query consists of packed Regev encodings of scalar
values (i.e., 1-dimensional values). As noted above, this
minimizes the server’s computational cost when processing
the ﬁrst dimension.
• After applying the query to each of the n2 databases, the
server has n2 Regev encodings of scalars. Transmitting these
back to the client would yield a protocol with a low rate (at
best, the rate is 1/2, and typically, it is much lower). Instead,
the server now applies a “packing” technique to pack the n2
Regev encodings into a single n× n matrix Regev encoding.
The rate now scales with n2/(n2 + n) > 1/2 whenever
n > 1.
The packing transformation used here requires publishing an
additional set of translation matrices in the public parameters.
Thus, this approach provides a trade-off between the size of
the public parameters and the online costs of the protocol
(measured in terms of server throughput and rate). Since
the public parameters can be reused over many queries,
SPIRALPACK is better-suited for settings where a client will
perform many database queries and the server is able to store the
client’s public parameters. We describe our packing approach
in the full version of this paper [42].
V. IMPLEMENTATION AND EVALUATION
In this section, we describe the implementation of the SPIRAL
system as well as our automated parameter selection procedure.
We conclude with a detailed experimental evaluation.
A. Automatic Parameter Selection
Parameter selection trade-offs. We now describe our general
methodology for selecting parameters to support a database
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:57:41 UTC from IEEE Xplore.  Restrictions apply. 
8937
• Setup(1λ, 1N ): On input the security parameter λ and the database size N, the setup algorithm proceeds as follows:
and query encoding, respectively.
1) Key-generation: Sample two secret keys S ← KeyGen(1λ, 1n) and s ← KeyGen(1λ, 11) that are used for response encoding
2) Regev-to-GSW conversion keys: Compute ck ← RegevToGSWSetup(s, S, zconv).
3) Automorphism keys: Let ρ = 1 + max(ν1,(cid:100)log tGSWν2(cid:101)). For each i ∈ [0, ρ − 1], compute Wi ←
AutomorphSetup(s, τ2ρ−i+1, zcoeﬀ ).
• Query(qk, idx): On input the querying key qk = (s, S) and an index idx = (i∗, j∗
Output the public parameters pp = (ck, W0, . . . , Wρ−1) and the querying key qk = (s, S).
1 , . . . , j∗
{0, 1}, the query algorithm does the following:
1) Encoding the ﬁrst dimension: Deﬁne the polynomial µi∗ (x) = (cid:98)q/p(cid:99) · xi∗ ∈ Rq.
2) Encoding subsequent dimensions: Deﬁne the polynomial µj∗ =(cid:80)
(cid:96)∈[ν2] µj∗
(cid:96)
where for each (cid:96) ∈ [ν2],
ν2 ) where i∗ ∈ [0, 2ν1 − 1] and j∗
1 , . . . , j∗
ν2 ∈
3) Query packing: Deﬁne the “packed” polynomial
µj∗
(cid:96)
(x) = j
∗
(cid:96)
(cid:88)
k∈[tGSW]
(zGSW)k−1x((cid:96)−1)tGSW+k.
−r1 µi∗ (x2) + 2
−r2 xµj∗ (x2) ∈ Rq,
(IV.1)
µ(x) := 2
where r1 = 1 + ν1 and r2 = 1 + (cid:100)log(tGSWν2)(cid:101).
state st = ⊥.
4) Query encryption: Compute the encrypted query c ← Regev.Encode(s, µ) ∈ R2
q. Output the query q = c and an empty query
• Answer(pp,D, q): On input the database D, the public parameters pp = (ck, W1, . . . , Wρ), and a query q = c, the server response
algorithm parses ck = (V, W, Π) and proceeds as follows:
1) Query expansion: The server expands the query ciphertext c into 2ν1 matrix Regev encodings (for the ﬁrst dimension) and ν2
GSW encodings (for the subsequent dimensions) as follows:
a) Initial expansion: Homomorphically evaluate a single iteration of the coefﬁcient expansion algorithm (Algorithm 1) on c. Let
cReg, cGSW ∈ R2
q be the output encodings.
encodings c(Reg)
b) First dimension expansion: Continue homomorphic evaluation of Algorithm 1 for ν1 additional iterations on cReg to obtain
c) GSW ciphertext expansion: Continue homomorphic evaluation of Algorithm 1 for (cid:100)log(tGSWν2)(cid:101) additional iterations on
q. Discard any additional encodings output by Algorithm 1 whenever
2ν1 ∈ R2
cGSW to obtain encodings c(GSW)
tGSWν2 is not a power of two. For each j ∈ [ν2], compute C(GSW)
← RegevToGSW(cid:0)ck, c(GSW)
q. For each i ∈ [0, 2ν1 − 1], let C(Reg)
i ← ScalToMat(W, c(Reg)
tGSWν2 ∈ R2
, . . . , c(GSW)
, . . . , c(Reg)
(cid:1).
).
1
1
i
(j−1)tGSW+1, . . . , c(GSW)
jtGSW
j
Note that the above invocations of Algorithm 1 will use the automorphism keys W0, . . . , Wρ−1.
2) Processing the ﬁrst dimension: For every j ∈ [0, 2ν2 − 1], the server does the following:
j ← ScalarMul(cid:0)C(Reg)
a) Initialize C(0)
b) For each i ∈ [2ν1 − 1], update C(0)
0
(cid:1).
, d0,j
j ← Add(cid:0)C(0)
(cid:16)
j
(cid:16)
, ScalarMul(cid:0)C(Reg)
i
(cid:1)(cid:1).
, di,j
(cid:17)
(cid:16)
3) Folding in the subsequent dimensions: For each r ∈ [ν2], and each j ∈ [0, 2ν2−r − 1], compute
C(r)
j = Add
Multiply
Complement(C(GSW)
r
), C(r−1)
j
, Multiply
C(GSW)
r
, C(r−1)
2ν2−r +j
(cid:17)(cid:17)
.
(IV.2)
4) Modulus switching: Output the rescaled response r ← ModulusSwitchq1,q2 (C(r)
0 ).
and outputs C ← Decode(Z) ∈ Rn×n
ﬁrst computes Z ← Recoverq1,q2 (S, r) ∈ Rn×n
p
.
q1
• Extract(qk, st, r): On input the query key qk = (s, S), an (empty) query state st, and the server response r, the extraction algorithm
Fig. 2: The SPIRAL PIR protocol.
D with up to N records, where each record is at most S
bits. The parameters of interest
in Construction IV.1 are
the lattice parameters d, q, χ, the plaintext modulus p, the
plaintext dimension n, the database conﬁguration ν1, ν2, the
3, and a
decomposition bases zcoeﬀ,Reg, zcoeﬀ,GSW, zconv, zGSW
correctness parameter C. A single invocation of the PIR
protocol yields an element of Rn×n
, which encodes dn2 log p
bits. When the record size S satisﬁes S > dn2 log p, we
break each record into T ≥ S/(dn2 log p) blocks, each of
p
3For ﬁner control over the noise introduced by the ciphertext expansion
algorithm [5, 39], we use different decomposition bases to expand the Regev
and the GSW ciphertexts (denoted zcoeﬀ,Reg and zcoeﬀ,GSW, respectively).
We refer to the full version of this paper [42] for additional details.
size dn2 log p. We then construct T databases where the ith
database contains the ith block of each record and run the
Answer protocol T times to compute the response. Importantly,
the query expansion step only needs to be computed once in this
case since the same query is applied to each of the T databases.
The subsequent homomorphic evaluation is performed over
each of the T databases. Our goal is to choose parameters that
minimize the estimated cost of the protocol (estimated based
on current AWS computing costs and the total computation
and communication required of the protocol; see Section V-B).
We choose parameters to tolerate a correctness error of at most
2−40 and a security level of 128 bits of (classical) security. We
refer to the full version of this paper [42] for a more detailed
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:57:41 UTC from IEEE Xplore.  Restrictions apply. 
9938
discussion of the different scheme parameters.
Automatic parameter selection. Balancing the different
scheme parameters is important for obtaining a good trade-
off between computational costs and communication. Similar
to XPIR [19], we introduce a heuristic search algorithm for
parameter selection based on a given database conﬁguration
(i.e., the number of records N and the record size S). We set the
ring dimension d = 2048 and use a 56-bit encoding modulus
q. This ensures 128 bits of security and sufﬁces to support
databases of size N ≤ 222. For the base SPIRAL protocol,
we set the plaintext dimension to n = 2. It then sufﬁces to
choose the plaintext modulus p, the decomposition dimen-
sions tcoeﬀ,Reg, tcoeﬀ,GSW, tconv, tGSW (which are functions of
zcoeﬀ,Reg, zcoeﬀ,GSW, zconv, zGSW), database conﬁguration ν1, ν2,
and the number of executions T . For each of these parameters,
there is a small number of reasonable values, and we can
quickly search over all of the candidate conﬁgurations.
We set the plaintext modulus p to be a power of two with
maximum value 230. Using larger p would require using a
larger modulus q and ring dimension d ≥ 4096. We consider
tcoeﬀ,Reg, tconv ∈ {2, 4, 8, 16, 32, 56} and tGSW ∈ [2, 56].4 We
ﬁx the decomposition base zcoeﬀ,GSW = 2, which ﬁxes the
dimension tcoeﬀ,GSW = 56. Finally, we consider all database
conﬁgurations ν1, ν2 ∈ [2, 11].5 With these constraints, there
are ≈3 million candidate parameter sets for each database set-
ting. After pruning out parameter settings where the correctness
error exceeds the threshold (2−40), we are left with ≈700,000
parameter sets. This initial pruning step takes 3 minutes on
our benchmarking platform, and the pruned set of feasible
parameters can be cached in a single 40 MB ﬁle.
We now need a way to estimate the concrete performance
(e.g., server computation time) for each set of candidate
parameters. We do so by ﬁtting a series of linear models
based on empirically-measured running times for the different
steps of the protocol. We provide the full description in the full
version of this paper [42]. Applying the AWS monetary cost
model (see Section V-B) for CPU time and network download,
we then select the parameter setting that minimizes the server’s
total cost to answer a query. The search process takes about
10 seconds on our platform. For all of the parameter sets
selected using this approach, the estimated server computation
time is within 10% of the actual measured running time. We
use an almost identical procedure to select parameters for
SPIRALPACK.
Remark V.1 (Other Optimization Objectives). By default,
we conﬁgure our parameter-selection method to minimize
the total cost on an AWS-based deployment. However, the
system naturally supports optimizing other objectives such
4While we could also consider the full range of values for tcoeﬀ,Reg, tconv, this
would increase the size of our search space by ≈ 100×. In our experiments,
we did not observe a signiﬁcant beneﬁt to the overall system efﬁciency with
the expanded search space.
5Our vectorized implementation for processing the ﬁrst dimension requires
that ν1 > 1. We exclude ν2 = 1 because this settings makes it infeasible to
pack all of the query coefﬁcients into a small number of ciphertexts for even
a moderate-size database with just a few thousand records.
as minimizing the estimated server computation time or to
maximize the rate. We also support selecting parameter sets
with a size constraint on the public parameter size or the query
size. This provides a way to systematically explore different
trade-offs in the ﬁnal protocol. We elaborate on some of these
trade-offs in Section V-C.
B. Implementation and Experimental Setup
We now describe some system optimizations used in our
implementation as well as our experimental setup.
SPIRAL conﬁgurations. The vanilla version of SPIRAL is
designed to be a general-purpose PIR protocol. However, in
a streaming setting, the SPIRALSTREAM variant of SPIRAL
(Remark IV.2) can achieve even better performance. In our
experimental evaluation (Section V-C), we consider both a
static setting and a streaming setting:
• Static setting: This is the basic setting where the client
privately retrieves a single record from a database. For this
setting, we choose the parameters to balance query size,
response size, and the server computation time. This is the
default operating mode of SPIRAL (and its packed version,
SPIRALPACK).
• Streaming setting: In the streaming setting, a client uploads
a single query that is reused across many databases. This
captures two general settings: (1) applications with large
records that we want to consume progressively (e.g., a private
video streaming service like Popcorn [44]); and (2) metadata-
hiding messaging systems where a user is repeatedly reading
from a “mailbox” (e.g. Pung [4] or Addra [22]). Since the
query can be reused in the streaming setting, we can amortize
the cost of transmitting the query over the lifetime of the
stream. Systems like FastPIR [22] are designed speciﬁcally
for the streaming setting and as such, achieve higher server
throughput compared to SealPIR [5], but require larger
queries. We can easily adapt SPIRAL to the setting using the
approach from Remark IV.2. Namely, in SPIRALSTREAM,
the client uploads all of the Regev encodings directly without
using the query packing approach from [5]. As we show
in Section V-C, SPIRALSTREAM has larger queries, but
achieves a much better rate and server throughput. We deﬁne
the streaming version of SPIRALPACK analogously and refer
to the resulting scheme as SPIRALSTREAMPACK.
We use our automatic parameter selection tool (Section V-A)
to select parameters for all of the SPIRAL variants.
Compressing Regev encodings. In SPIRAL (and all of its
variants), the PIR query consists of one or more scalar Regev
encodings. A scalar Regev encoding c is a pair c = (c0, c1),
where c0 ∈ Rq is uniformly random. Instead of sending c0, the
client can instead send a seed s for a pseudorandom generator
(PRG) and derive c0 by evaluating the PRG on the seed s.
Security holds if we model the PRG as a random oracle. This is
a standard technique to compress Regev encodings [45, 46, 47].
Modulus choice. In our implementation, we use a 56-bit
modulus q that is a product of two 28-bit primes α, β. By
∼= Rα × Rβ.