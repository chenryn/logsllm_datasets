7.2 Improper Runtime Assumption
Enforcing security policies is challenging for CFI mechanisms.
The runtime provides rich but legal methods for altering the con-
trol flow (e.g. longjmp/signal calls), even executing callbacks (e.g.
constructor/destructor attributes). These scenarios are trivial, yet
improper assumptions in these scenarios enable potential attacks.
MCFI/πCFI: MCFI/πCFI regards the _init function in the .init
section and the _fini function in the .fini section as legal targets
of indirect calls, thus introduceing unintended transfer targets.
These two functions are generated by the compiler, and are in-
voked by the _start function rather than any user-defined function.
However, MCFI/πCFI adds them to the legal set and allows other
ICT instructions to jump to them.
As shown in Listing 1, these two functions have a specific type
of "void(void)", and perform initialization/finalization operations,
then return with a specific gadget. Therefore, attackers can hijack
ICT instructions protected by MCFI/πCFI to _init and _fini, and
use them to skip the execution of some other code.
TSX-based CFI. TSX-based CFI uses musl libc instead of
glibc as the C library, introducing security risks as well. Glibc
can protect the contents of sensitive registers (such as SP and PC) in
the buffer jmp_buf by mangling them. Musl, on the other hand,
does not provide protections for jmp_buf. And thus the buffer
jmp_buf can be easily tampered for a JOP attack. If the program
uses the setjmp/longjmp function in musl libc and there is a buffer
overflow vulnerability in the program, the attacker can utilize
setjmp/longjmp to launch a JOP attack. Even worse, TSX-based
CFI does not perform checks on the indirect jump instruction of
the longjmp function, so an attacker can bypass it easily.
7.3 Unprotected Corner Code
Compatibility issues must be considered when implementing
CFI mechanisms, and they also lead to security issues. As afore-
mentioned, some ICT instructions may reside in corner code, e.g.,
inline assembly code or DSO libraries, or vDSO code. This threat is
actually very severe. As shown in Table 2, ICT instructions in these
cases are in general not protected by most CFI solutions.
7.4 Unexpected Optimization
Modern compilers optimize code aggressively. Security checks in
CFI mechanisms may leverage low-level constructs to detect anom-
aly; if considered as an undefined behavior, the compiler is free to
optimize even remove the operation. The same applies to opera-
tions free of side-effects: some CFI mechanisms require collecting
data before enforcing the policy. If the data collection operation is
considered free of side effects, the compiler may also remove it.
OS-CFI: OS-CFI is an origin-sensitive CFI solution which uses
SUPA [53] for static analysis of CFG. We have turned off the tail
optimization option when evaluating with our tool CScan, so we
specifically tested the tail optimization in our test suite CBench.
Figure 5: Protected vs. unprotected ICTs in SPEC benchmarks hard-
ened by CFI-LB.
The results show that neither CFI-LB nor OS-CFI protects tail
calls that are optimized for indirect calls. The root cause is that, if
compiler optimization is turned on, the OS-CFI checker function will
be removed due to optimization. Besides, SUPA fails to recognize
any tail call during the static CFG analysis, causing security risks
as well.
CFI-LB: As for CFI-LB, the checker function is also deleted due
to optimization. In addition, when CFI-LB uses Intel Pin to gener-
ate dynamic CFG, it searches for a specific function entry before
analysis. This function is an empty function and is removed if the
optimization is turned on, thus cannot be found during the search-
ing phase. So CFI-LB fails to generate the dynamic CFG. Therefore,
neither the static CFG builder can analyze those ICTs at compile
time nor the dynamic CFG builder can add them to the final CFG
while running the program. As a result, the runtime CFI checks
will be misled.
7.5 Incorrect Implementation
Implementing CFI mechanisms involves complex analysis tech-
niques and linker or runtime adjustments. The low-level enforce-
ment of a policy and high-level decision-making process of a policy
are error-prone.
CFI-LB. As shown in Table 1, CFI-LB has the largest variance
between the median and the mean value of feasible targets. We
analyzed the code and found that the root cause is that, some ICT
instructions were unprotected and could be hijacked to jump to all
executable addresses in the target benchmark protected by CFI-LB.
Moreover, one of CFI-LB’s checker functions has a logic bug,
which silently ignores the case that the runtime target does not
match the CFG, causing security risks too.
We counted the number of incorrect checker functions in the
program to obtain the proportion of unprotected ICTs in all ICTs,
and demonstrated the results in Figure 5.
7.6 Mismatched Specification
Hardware may provide extra security-related features such as
NX bit, Intel Control-flow Enforcement Technology (CET), ARM
Pointer Authentication (PA). The effective use of these features
relies on both the user and the platform. Errors in either party lead
to mismatched specification, and security issues result.
For example, ARM PA is designed to enforce the integrity of
pointers, where the hardware can detect external entities with cryp-
tographic signatures of pointers. The specification requires three
values to generate the signature: a secret key, a modifier, and the
pointer itself. However, the implementation of PA in QEMU mis-
matches with the specification, because the pointer itself does not
affect the generated signature. Therefore, a local attacker could
abuse this flaw to bypass ARM PA protection for all programs run-
ning on QEMU. We analyzed this bug and reported the details to
perlbenchbzip2gccgobmkhmmerh264refomnetppxalanmilcnamddealIIsoplexpovraynginx0.00.20.40.60.81.068.94%60.0%39.63%68.19%11.12%17.17%16.84%6.1%75.0%100.0%21.66%3.78%6.94%7.52%CFI-LB protected ICTCFI-LB unprotected ICTSession 6B: Exploitation and Defenses CCS '20, November 9–13, 2020, Virtual Event, USA18311 xend
2 add
3 test
4 add
5 add
6 mov
7 add
8 jmp
BYTE PTR [ rdi ], cl
DWORD PTR [ rcx ], ebp
al , BYTE PTR [ rax ]
BYTE PTR [ rcx + rcx *4 -0 x28 ], cl
r10 , rax
r10 ,0 x3
r10
Listing 2: An example gadget in TSX-based CFI
QEMU developers, and a CVE is assigned. The mismatch of specifi-
cation in QEMU implies weakened protections in CFI mechanisms
relying on this feature. For example, the protection of PARTS run-
ning in QEMU can be easily defeated by a buffer-overflow; on the
other hand, the very same CFI mechanism running in ARM Fixed
Virtual Platforms (FVP) does provide protections as expected.
7.7 Unintended Targets Introduced by CFI
Most CFI schemes enforce their policies by checking logic around
ICTs or inside their runtime libraries. The code instrumented by CFI
can be potential (thus unintended) transfer targets to the adversary.
TSX-based CFI. In the RTM mode of TSX-based CFI, an ICT
is allowed to transfer to any code snippets starting with an xend
instruction, ending the transaction normally.
Any byte sequence starting with the machine code of the xend
instruction is a feasible target for each ICT instruction. The com-
mon libc library has over 100 matching bytes, and thus over 100
unintended targets. Ironically, most of the unintended targets reside
in the checker function instrumented by the TSX-based CFI itself.
TSX-based CFI provides many checker functions: (1) a unique
checker function is provided for the return instruction, (2) a unique
checker function is provided for each pair of (register, ICT-type),
where ICT-type is either call or jump and register is the operand
used in the ICT, and (3) more checker functions are provided for ICT
instructions with memory operand rather than register operand.
Taking the checker function for jmp rdx as an example, if the
attacker hijacks one ICT to transfer to the location of xend in this
checker function, she/he can obtain the gadget shown in Listing 2.
If she/he is also able to control the value of rax, rdi, rcx, then
she/he could jump to arbitrary code with the last unintended and
unprotected instruction jmp r10.
7.8 Summary
The pitfalls listed above imply that flaws exist in the whole
lifetime of CFI mechanisms.
At the design stage, imprecise analysis methods could be chosen,
which limits the upper bound of a CFI mechanism can achieve;
improper runtime assumption could be made, which fails in subtle
attack scenarios. For example, Lockdown’s design cannot handle
callbacks; uCFI’s attack model lacks considering malicious data
related to control-flow ; TSXCFI’s inspection mechanism introduces
unavoidable extra gadgets.
At the implementation stage, security could be compromised in
favor of compatibility, and corner code remains unprotected. The
compiler faces challenges from unexpected optimization (which
disables protection). The runtime itself could be buggy in both
implementation and specification, and could also bring unintended
targets. These implementation bugs are introduced unintentionally,
yet they still affect practical security and can be valuable lessons for
developers. For example, MCFI/πCFI introduce unintended targets
because of missing type information of ICTs; The OS-CFI and CFI-
LB check functions will be removed after optimization; The logic
bug of CFI-LB’s check function causes the check to fail.
To avoid these factors that lead to security risks, we propose
to perform more comprehensive and fine-grained evaluations on
practical security. Our solution covers both the design and imple-
mentation stage, helps to identify and resolve issues of designing
in advance, and makes up for the gap between design and imple-
mentation.
8 Discussion
Deployment of CFI Implementations. Some CFI implemen-
tations have higher requirements on the deployment environment
and need to be the same as their experimental environment in order
to operate normally. Some of the CFI implementations are not user-
friendly and require a good understanding of the entire running
process and sample scripts before they can be used. This consumes
most of the time in our evaluation process. We would thank the
majority of CFI program authors for their support, and hope that
the usability of CFI mechanisms will be increased.
Security Issue and Compatibility. Many CFI solutions have
bad compatibility for regular programs. Some CFI implementa-
tions even break the original semantic of programs, for example,
MCFI/πCFI ignore init functions in protected binaries. Moreover,
protected programs are often terminated with CFI violation during
our evaluation due to the existence of false positive cases. CFI so-
lutions including clang-cfi and clang-cfi-dso provide an interface
for programmers to label specific functions which failed to be sup-
ported with a blacklist. And the ICTs in blacklisted functions will
not be protected. Scalable leads to good compatibility though, but
brings heavy tasks, inevitable cases and security issues. How to
resolve this conflict is a question of practical significance.
Human Efforts in Testing CFI Implementations. CBench
does not require any human effort to be adapted to new CFI solu-
tions. CScan requires very few human efforts, thanks to the fact
that the structure of most CFI solutions are similar. For corner cases,
see Section 5.1 for details in customization.
9 Conclusion
This paper proposes a solution to evaluate practical security of
CFI mechanisms. The solution consists of CScan, for measuring the
real security boundary of CFI mechanisms, and CBench, for verify-
ing effectiveness against typical attacks. With the proposed solution,
we evaluated popular open-source CFI mechanisms. Among all the
12 evaluated mechanisms, 10 mechanisms were found with flaw(s).
They either fail to protect all ICT instructions as claimed, or become
parts of the attack surface, or become unintended targets of ICT
instructions, or fail to correctly enforce the claimed CFI policy.
We further summarize the flaws into 7 common pitfalls in devel-
oping CFI mechanisms. The pitfalls prevail in most CFI mechanisms
we studied. As a solution to these issues, we open source CScan and
CBench, in order to help evaluating, understanding and promoting
CFI mechanisms.
Acknowledgement
This work was supported in part by National Natural Science
Foundation of China under Grant 61772307, 61772308, 61972224
and U1736209, and BNRist Network and Software Security Research
Program under Grant BNR2019TD01004 and BNR2019RC01009.
Session 6B: Exploitation and Defenses CCS '20, November 9–13, 2020, Virtual Event, USA1832[2] Martín Abadi, Mihai Budiu, Úlfar Erlingsson, and Jay Ligatti. 2009. Control-flow
integrity principles, implementations, and applications. ACM Transactions on
Information and System Security (TISSEC) 13, 1 (2009), 4.
[3] Ali Abbasi, Thorsten Holz, Emmanuele Zambon, and Sandro Etalle. 2017. Ecfi:
Asynchronous control flow integrity for programmable logic controllers. In
Proceedings of the 33rd Annual Computer Security Applications Conference. ACM,
437–448.
[4] Tigist Abera, N Asokan, Lucas Davi, Jan-Erik Ekberg, Thomas Nyman, Andrew
Paverd, Ahmad-Reza Sadeghi, and Gene Tsudik. 2016. C-FLAT: control-flow
attestation for embedded systems software. In Proceedings of the 2016 ACM
SIGSAC Conference on Computer and Communications Security. ACM, 743–754.
[5] Jason Ansel, Petr Marchenko, Úlfar Erlingsson, Elijah Taylor, Brad Chen, Derek L
Schuff, David Sehr, Cliff L Biffle, and Bennet Yee. 2011. Language-independent
sandboxing of just-in-time compilation and self-modifying code. In ACM SIG-
PLAN Notices, Vol. 46. ACM, 355–366.
[6] Tyler Bletsch, Xuxian Jiang, and Vince Freeh. 2011. Mitigating code-reuse attacks
with control-flow locking. In Proceedings of the 27th Annual Computer Security
Applications Conference. ACM, 353–362.
[7] Erik Bosman and Herbert Bos. 2014. Framing signals-a return to portable shell-
code. In 2014 IEEE Symposium on Security and Privacy. IEEE, 243–258.
Dynamic Dispatch Through VTable Interleaving.. In NDSS.
[9] Nathan Burow, Scott A Carr, Joseph Nash, Per Larsen, Michael Franz, Stefan
Brunthaler, and Mathias Payer. 2017. Control-flow integrity: Precision, security,
and performance. ACM Computing Surveys (CSUR) 50, 1 (2017), 16.
[10] Nathan Burow, Derrick McKee, Scott A Carr, and Mathias Payer. 2018. Cfixx:
Object type integrity for c++ virtual dispatch. In Prof. of ISOC Network & Dis-
tributed System Security Symposium (NDSS). https://hexhive. epfl. ch/publications/-
files/18NDSS. pdf.
[11] Ping Chen, Yi Fang, Bing Mao, and Li Xie. 2011. JITDefender: A defense against JIT
spraying attacks. In IFIP International Information Security Conference. Springer,
142–153.
[12] Yueqiang Cheng, Zongwei Zhou, Yu Miao, Xuhua Ding, and Robert H Deng. 2014.
ROPecker: A generic and practical approach for defending against ROP attack.
(2014).
[8] Dimitar Bounov, Rami Gökhan Kici, and Sorin Lerner. 2016. Protecting C++
References
[1] [n.d.]. Capstone, the ultimzte disassembly framework. http://www.capstone-
engine.org/.
[13] Nick Christoulakis, George Christou, Elias Athanasopoulos, and Sotiris Ioannidis.
2016. Hcfi: Hardware-enforced control-flow integrity. In Proceedings of the Sixth
ACM Conference on Data and Application Security and Privacy. ACM, 38–49.
[14] John Criswell, Nathan Dautenhahn, and Vikram Adve. 2014. KCoFI: Complete
control-flow integrity for commodity operating system kernels. In 2014 IEEE
Symposium on Security and Privacy. IEEE, 292–307.
[15] Lucas Davi, Alexandra Dmitrienko, Manuel Egele, Thomas Fischer, Thorsten
Holz, Ralf Hund, Stefan Nürnberger, and Ahmad-Reza Sadeghi. 2012. MoCFI: A
Framework to Mitigate Control-Flow Attacks on Smartphones.. In NDSS, Vol. 26.
27–40.
[16] Lucas Davi, Matthias Hanreich, Debayan Paul, Ahmad-Reza Sadeghi, Patrick Koe-
berl, Dean Sullivan, Orlando Arias, and Yier Jin. 2015. HAFIX: Hardware-assisted
flow integrity extension. In Proceedings of the 52nd Annual Design Automation
Conference. ACM, 74.
[17] Lucas Davi, Patrick Koeberl, and Ahmad-Reza Sadeghi. 2014. Hardware-assisted
fine-grained control-flow integrity: Towards efficient protection of embedded
systems against software exploitation. In 2014 51st ACM/EDAC/IEEE Design Au-
tomation Conference (DAC). IEEE, 1–6.
[18] P de Clercq. 2017. Hardware supported Software and Control Flow Integrity.
(2017).
[19] Ren Ding, Chenxiong Qian, Chengyu Song, Bill Harris, Taesoo Kim, and Wenke
Lee. 2017. Efficient protection of path-sensitive control security. In 26th {USENIX}
Security Symposium ({USENIX} Security 17). 131–148.
[20] Robert Gawlik and Thorsten Holz. 2014. Towards automated integrity protection
of C++ virtual function tables in binary programs. In Proceedings of the 30th
Annual Computer Security Applications Conference. ACM, 396–405.
[21] Xinyang Ge, Weidong Cui, and Trent Jaeger. 2017. Griffin: Guarding control
flows using intel processor trace. In ACM SIGARCH Computer Architecture News,
Vol. 45. ACM, 585–598.
[22] Xinyang Ge, Nirupama Talele, Mathias Payer, and Trent Jaeger. 2016. Fine-grained
control-flow integrity for kernel software. In 2016 IEEE European Symposium on
Security and Privacy (EuroS&P). IEEE, 179–194.
[23] Enes Göktas, Elias Athanasopoulos, Herbert Bos, and Georgios Portokalidis. 2014.
Out of control: Overcoming control-flow integrity. In 2014 IEEE Symposium on
Security and Privacy. IEEE, 575–589.
[24] Jens Grossklags and Claudia Eckert. 2018. τ CFI: Type-Assisted Control Flow
Integrity for x86-64 Binaries. In Research in Attacks, Intrusions, and Defenses: 21st
International Symposium, RAID 2018, Heraklion, Crete, Greece, September 10-12,
2018, Proceedings, Vol. 11050. Springer, 423.
[25] Yufei Gu, Qingchuan Zhao, Yinqian Zhang, and Zhiqiang Lin. 2017. PT-CFI:
transparent backward-edge control flow violation detection using intel processor
trace. In Proceedings of the Seventh ACM on Conference on Data and Application
Security and Privacy. ACM, 173–184.
[26] Owen S Hofmann, Alan M Dunn, Sangman Kim, Indrajit Roy, and Emmett Witchel.
2011. Ensuring operating system kernel integrity with OSck. In ACM SIGARCH
Computer Architecture News, Vol. 39. ACM, 279–290.
[27] Hong Hu, Chenxiong Qian, Carter Yagemann, Simon Pak Ho Chung, William R
Harris, Taesoo Kim, and Wenke Lee. 2018. Enforcing unique code target property
for control-flow integrity. In Proceedings of the 2018 ACM SIGSAC Conference on
Computer and Communications Security. ACM, 1470–1486.
[28] Dongseok Jang, Zachary Tatlock, and Sorin Lerner. 2014. SafeDispatch: Securing
C++ Virtual Calls from Memory Corruption Attacks.. In NDSS.
[29] Vasileios P Kemerlis, Georgios Portokalidis, and Angelos D Keromytis. 2012.
kGuard: lightweight kernel protection against return-to-user attacks. In 21st
{USENIX} Security Symposium ({USENIX} Security 12). 459–474.
[30] Mustakimur Khandaker, Abu Naser, Wenqing Liu, Zhi Wang, Yajin Zhou, and
Yueqiang Cheng. 2019. Adaptive Call-site Sensitive Control Flow Integrity. In
2019 IEEE European Symposium on Security and Privacy (EuroS&P). IEEE, 95–110.
[31] Mustakimur Rahman Khandaker, Wenqing Liu, Abu Naser, Zhi Wang, and Jie
Yang. 2019. Origin-sensitive control flow integrity. In 28th {USENIX} Security
Symposium ({USENIX} Security 19). 195–211.
[32] Volodymyr Kuznetsov, László Szekeres, Mathias Payer, George Candea, R Sekar,
and Dawn Song. 2014. Code-pointer integrity. In 11th {USENIX} Symposium on
Operating Systems Design and Implementation ({OSDI} 14). 147–163.
[33] Donghyun Kwon, Jiwon Seo, Sehyun Baek, Giyeol Kim, Sunwoo Ahn, and Yunhe-
ung Paek. 2018. VM-CFI: Control-Flow Integrity for Virtual Machine Kernel Using