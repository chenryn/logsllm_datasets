title:JIGSAW: Efficient and Scalable Path Constraints Fuzzing
author:Ju Chen and
Jinghan Wang and
Chengyu Song and
Heng Yin
6
9
7
3
3
8
9
.
2
2
0
2
.
4
1
2
6
4
P
S
/
9
0
1
1
.
0
1
:
I
O
D
|
E
E
E
I
2
2
0
2
©
0
0
.
1
3
$
/
2
2
/
9
-
6
1
3
1
-
4
5
6
6
-
1
-
8
7
9
|
)
P
S
(
y
c
a
v
i
r
P
d
n
a
y
t
i
r
u
c
e
S
n
o
m
u
i
s
o
p
m
y
S
E
E
E
I
2
2
0
2
2022 IEEE Symposium on Security and Privacy (SP)
JIGSAW: Efficient and Scalable Path Constraints
Fuzzing
Ju Chen, Jinghan Wang, Chengyu Song, Heng Yin
Computer Science and Engineering Department
University of California, Riverside
Abstract—Coverage-guided testing has shown to be an effective
way to find bugs. If we model coverage-guided testing as a search
problem (i.e., finding inputs that can cover more branches), then
its efficiency mainly depends on two factors: (1) the accuracy
of the searching algorithm and (2) the number of inputs that
can be evaluated per unit time. Therefore, improving the search
throughput has shown to be an effective way to improve the
performance of coverage-guided testing.
In this work, we present a novel design to improve the
search throughput: by evaluating newly generated inputs with
JIT-compiled path constraints. This approach allows us to
significantly improve the single thread throughput as well as
scaling to multiple cores. We also developed several optimization
techniques to eliminate major bottlenecks during this process.
Evaluation of our prototype JIGSAW shows that our approach
can achieve three orders of magnitude higher search throughput
than existing fuzzers and can scale to multiple cores. We also
find that with such high throughput, a simple gradient-guided
search heuristic can solve path constraints collected from a large
set of real-world programs faster than SMT solvers with much
more sophisticated search heuristics. Evaluation of end-to-end
coverage-guided testing also shows that our JIGSAW-powered
hybrid fuzzer can outperform state-of-the-art testing tools.
I. INTRODUCTION
Exploring a program’s execution space is essential for finding
bugs and security flaws in software. Starting from a set of initial
inputs (a.k.a. seeds) to the program, an automatic testcase
generation technique is expected to quickly find more inputs
that can exercise new states that are not covered before, such
that more and more behaviors can be revealed. Because bugs
tend to reside in less-tested code, coverage-guided testing,
which aims to cover as much code as possible, is a popular
and effective way to find bugs.
Fuzzing and symbolic execution are two representative
testcase generation techniques. Fuzzing [35, 65, 78] discovers
new coverage via random search: a new input is randomly
generated or mutated from an old input, which is then tested
with the program under test (PUT) to check whether one
or more new branches are covered. Symbolic execution [10–
15, 19, 31, 32, 56, 57, 64, 77], on the other hand, performs
more systematic exploration: it collects path constraints during
the execution and uses a constraint solver like a satisfiability
modulo theories (SMT) solver [4, 21, 22, 29, 49, 50] to generate
new input that can flip branches along execution paths.
If we model the coverage-guided testing as a search problem
that tries to find an input that can satisfy a target branch’s
predicate, then the efficiency of a coverage-guided testing tool
TABLE I: Comparison of branch flipping strategies.
Searching target Form of target
Whole program Native code
Tools
AFL [78]
Angora [17] Whole program Native code Gradient-guided search
SymCC [56] Path constraint
SMT solving (DPLL)
Path constraint
Fuzzolic [9]
JIGSAW
Path constraint
SMT formula
SMT formula
JIT’ed code Gradient-guided search
Core search alg.
Random search
Fuzzing heuristics
can be measured using the branch flip rate (i.e., how many
branches are flipped per unit time), which is determined by
two factors: search throughput and search accuracy. Search
throughput represents how many inputs can be tried per
unit time, and search accuracy specifies how likely a newly
generated input can flip a branch. Obviously, the branch flip rate
is a product of search throughput and search accuracy. Overall,
a tool with a higher branch flipping rate can achieve the same
coverage faster and is more likely to find more bugs [5].
In this work, we investigate a new point in the design space of
coverage-guided testing (Table I). Our design goal is to improve
the search throughput. Our key insight is that evaluating a new
test input with path constraints in the form of native functions,
produced by Just-In-Time (JIT) compilation, can be much faster
than both traditional approaches. Specifically, when comparing
with fuzzers that evaluate a new input with the entire PUT,
we have several observations. (1) Invoking a set of native
functions is orders of magnitude faster than executing the
whole program. (2) Since a branch’s path constraints do not
update any global state, the JIT’ed functions are side-effect
free (i.e., pure). So, evaluating new inputs with them avoids
expensive state reset processes like forking a new process. (3)
When evaluating a new test input with functions, the input
can be passed through registers and memory instead of the
file system, which eliminates the file system bottleneck [74].
(4) Because every JIT’ed function is pure (i.e., independent
of each other), we can linearly scale the fuzzing threads to
multiple cores or machines [36] without worrying about data
races and synchronization. (5) The JIT’ed path constraints are
usually free of branches, which makes it easier for modern
processors to exploit instruction-level parallelism (i.e., no mis-
speculation) and to adopt SIMD (Single Instruction Multiple
Data) instructions to further improve the throughput via data
parallelization [25]. As a result, our approach can improve
both the sequential throughput (properties 1-3) and parallel
© 2022, Ju Chen. Under license to IEEE.
DOI 10.1109/SP46214.2022.00102
18
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:24:56 UTC from IEEE Xplore.  Restrictions apply. 
throughput (properties 3-5).
Compared to other solvers, which also evaluate a new input
with path constraints, including JIT-compiled constraints [40,
45, 53], our approach also features several optimizations to
improve the search throughput. First, to minimize the cost
of JIT compilation, we used an in-memory JIT engine and
implemented a constraint to JIT’ed function cache. More im-
portantly, we perform constraint normalization before accessing
the cache. We observe that many path constraints essentially
perform the same check over different inputs. In other words,
the abstract syntax trees (AST) of these path constraints only
differ at the leaf nodes, so they can be solved using the same
JIT’ed function. For instance, we can reuse the same JIT’ed
function
gt(x, y) { return y - x; }
to solve constraints like a > 10, b > 20, 30 > c, etc. This
normalization process significantly increases the cache hit rate.
Second, we reduced the number of invoked native functions
by only evaluating those that will be affected by the new input.
Finally, we reduced the use of locks to allow a more scalable
parallel search.
To validate this idea, we implement a prototype, called
JIGSAW (Just-in-Time Gradient descent Search for AnsWers).
It compiles path constraints collected from the target program
into a set of native functions using the JIT engine from LLVM.
Then it performs a gradient-guided search [17, 18], a relatively
simple local search heuristic, to find an input that can flip
the corresponding branch. Our evaluation of a set of popular
applications shows that JIGSAW can achieve an average search
throughput of 637.2K inputs/sec when fuzzing path constraints
with data dependencies (a.k.a. nested branch constraints) using
a single thread, and can scale to 12.5M inputs/sec using
48 threads. The corresponding branch flipping rate is about
588.9 branches/sec using a single thread and can scale to
11.3K branches/sec using 48 threads. When solving last-branch
constraints without dependencies (a.k.a. optimistic solving),
the search throughput scales from 3.1M inputs/sec with a
single thread to 74.7M with 48 threads. The corresponding
branch flipping rate is about 35.7K and 860.0K branches/sec,
respectively. For comparison, on libpng, a recent work [74]
on improving fuzzing throughput reported a throughput around
6.5M inputs/sec with libFuzzer using 120 cores; JIGSAW can
achieve 18.1M inputs/sec with 48 cores. Interestingly, such high
search throughput allowed JIGSAW to solve path constraints
collected from real-world applications faster than SMT solvers
powered with much more sophisticated search strategies.
To evaluate JIGSAW’s impact on end-to-end coverage-guided
testing, we also implemented a hybrid fuzzer with JIGSAW as
the path constraint solver. The evaluation results showed that
the high branch flipping rate of JIGSAW allowed our hybrid
fuzzer to achieve the same code coverage faster than existing
fuzzers and symbolic executors.
In summary, we make the following contributions:
• We designed a novel approach that improves the branch
flipping rate of automated test generation.
• We implemented a prototype JIGSAW and open-sourced
it (https://github.com/R-Fuzz/jigsaw).
• We evaluated our prototype with a set of real-world
applications. The results showed that our approach can
significantly improve the search throughput, which enables
better performance in coverage-guided testing.
• We released the path constraints we collected.
II. BACKGROUND
In this section, we first provide an overview of automated
test generation techniques, including modern feedback-guided
fuzzers and symbolic execution. Then we discuss the important
factors that affect their efficiency.
Automated Test Generation. Testing is an important and
effective way to detect software bugs. However, manually
generated test cases are usually biased towards normal or
expected inputs so they do not provide enough coverage,
especially for corner cases. As a result, simply testing software
with random inputs is enough to generate many crashes [47],
most of which are exploitable. Automated test generation aims
to generate test cases to cover as much code as possible.
Fuzzing and symbolic execution are the two most popular
automated test generation techniques.
Fuzzers create inputs in a generative manner or mutational
manner. Generative fuzzers can be grammar guided [1, 23,
30, 51, 61] or learning based [33, 59, 72]. Mutational fuzzers
generally adopt two genetic operations: random mutation and
crossover [35, 47, 65, 78]. The first generation of fuzzers was
blackbox fuzzers [1, 23, 47], which just create random test
inputs. While they have successfully found many bugs, most
of those bugs are shallow; once fixed, these fuzzers cannot
go deeper and cover more code/states. The reason is that
blackbox fuzzers are aimless so they can easily generate lots
of redundant test cases. To solve this problem, greybox (a.k.a.
feedback-guided) fuzzers were invented [2, 6–8, 17, 18, 20,
27, 35, 42, 46, 55, 65, 69, 75, 76, 78]. By using lightweight
instrumentation to collect limited runtime information (e.g.,
branch coverage), greybox fuzzers can measure the progress
they have made and steadily progress towards their goals [52].
White-box fuzzers and symbolic/concolic executors [10–
15, 19, 31, 32, 56, 57, 64, 77] generate new input test cases
more systematically. They treat the test input as a sequence
of symbolic bytes. When executing the target program, a
symbolic execution engine maintains (1) a symbolic state
σ,
that maps program variables to symbolic expressions
and (2) a set of quantifier-free first-order formulas over
symbolic expressions that are imposed by conditional branches
(a.k.a. path constraints) [14]. Whenever the execution engine
encounters an uncovered branch, it will query an SMT solver
for the satisfiability of that branch’s predicate under current
path constraints. If the branch predicate is satisfiable, it asks
the SMT solver to return a model for the relevant inputs bytes
and generates a new test input that should be able to cover
that branch.
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:24:56 UTC from IEEE Xplore.  Restrictions apply. 
219
Efficiency of Test Generation. Since we only have limited
resources (CPU, memory, and time), the most important metric
for measuring an automated test generation technique is its
efficiency, i.e., how much coverage can it achieve with the
limited resources. The first component that has a huge impact
on efficiency is state/path scheduling. For fuzzers, since each
testcase represents an execution path, testcase scheduling is
the same as path scheduling. A basic observation is that if
opposite branches along a path have already been covered or
are hard/infeasible to flip, then spending more time on this
path will not give any reward (new coverage). This scheduling
problem can be generally modeled as a multi-armed bandit
(MAB) problem [16, 76] and numerous scheduling algorithms
have been proposed to improve the efficiency of fuzzers [6–
8, 28, 43, 60, 70, 71, 76].
Once a path is scheduled, the next important factor that
affects the efficiency is the speed to flip an uncovered branch.
The branch flipping problem is a typical search problem: how to
find an input that can satisfy the branch predicate and additional
path constraints that must be satisfied to reach this branch [18].
The efficiency of this step depends on two factors. The first
factor is the search algorithm. Off-the-shelf fuzzers [35, 65, 78]
do not pay much attention to this problem and rely on a random
search. As a result, their search is aimless and usually faces
difficulties when trying to flip branches with tight constraints
(e.g., magic number check). To overcome this limitation,
researchers have proposed numerous heuristics [2, 54, 60, 73].