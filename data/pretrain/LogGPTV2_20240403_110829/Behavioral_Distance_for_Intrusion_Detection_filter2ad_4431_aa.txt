title:Behavioral Distance for Intrusion Detection
author:Debin Gao and
Michael K. Reiter and
Dawn Xiaodong Song
Behavioral Distance for Intrusion Detection
Debin Gao1, Michael K. Reiter2, and Dawn Song2
1 Electrical & Computer Engineering Department, Carnegie Mellon University,
Pittsburgh, Pennsylvania, USA
2 Electrical & Computer Engineering Department, Computer Science Department,
and CyLab, Carnegie Mellon University, Pittsburgh, Pennsylvania, USA
PI:EMAIL
{reiter, dawnsong}@cmu.edu
Abstract. We introduce a notion, behavioral distance, for evaluating
the extent to which processes—potentially running diﬀerent programs
and executing on diﬀerent platforms—behave similarly in response to a
common input. We explore behavioral distance as a means to detect an
attack on one process that causes its behavior to deviate from that of
another. We propose a measure of behavioral distance and a realization of
this measure using the system calls emitted by processes. Through an em-
pirical evaluation of this measure using three web servers on two diﬀerent
platforms (Linux and Windows), we demonstrate that this approach holds
promise for better intrusion detection with moderate overhead.
Keywords: Intrusion detection, system call, behavioral distance.
1 Introduction
Numerous attacks on software systems result in a process’ execution deviating
from its normal behavior. Prominent examples include code injection attacks on
server processes, resulting from buﬀer overﬂow and format string vulnerabilities.
A signiﬁcant amount of research has sought to detect such attacks through mon-
itoring the behavior of the process and comparing that behavior to a model of
“normal” behavior. Typically this model of “normal” is obtained either from the
process’ own previous behavior [10, 27, 9, 8, 13, 12, 37] or the behavior prescribed
by the source code or executable of the program it executes [35, 14, 15].
In this paper we present a new approach for detecting anomalous behavior of
a process, in which the model of “normal” is a “replica” of the process running
in parallel with it, operating on the same inputs. At a high level, our goal is to
detect any behavioral deviation between replicas operating on the same inputs,
which will then indicate that one of the replicas has been compromised. As
we will show, this approach will better detect mimicry attacks [36, 31] than
previous approaches. In addition, this approach has immediate application in
fault-tolerant systems, which often run replicas and compare their responses
(not behavior) to client requests to detect (e.g., [29, 3, 2]) or mask (e.g., [17, 25,
4, 39]) faults. When considering attacks, it is insuﬃcient to simply compare the
responses to detect faults, because certain intrusions may not result in observable
A. Valdes and D. Zamboni (Eds.): RAID 2005, LNCS 3858, pp. 63–81, 2006.
c(cid:1) Springer-Verlag Berlin Heidelberg 2006
64
D. Gao, M.K. Reiter, and D. Song
deviation in the responses (but may nevertheless go on to attack the interior
network, for example). Our method of detecting behavioral deviation between
replicas can signiﬁcantly improve the resilience of such fault-tolerant systems by
detecting more stealthy attacks.
Monitoring for deviations between replicas would be a relatively simple task
if the replicas were identical. However, in light of the primary source of attacks
with which we are concerned—i.e., software faults and, in particular, code in-
jection attacks that would corrupt identical replicas identically—it is necessary
that the “replicas” be as diverse as possible. We thus take as our goal the task
of measuring the behavioral distance between two diverse processes, be they dis-
tinct implementations of the program (e.g., as in n-version programming [5]),
the same implementation running on diﬀerent platforms (e.g., one Linux, one
Windows), or even distinct implementations on diverse platforms. In this paper,
we propose a method to measure behavioral distance between replicas and show
that our method can work with competing, oﬀ-the-shelf, diverse implementations
without modiﬁcation.
We can measure behavioral distance using many diﬀerent observable at-
tributes of the replicas. As a concrete example, the measure of “behavior” for
a replica that we adopt is the sequence of system calls it emits, since a process
presumably is able to aﬀect its surroundings primarily through system calls. Be-
cause the replicas are intentionally diverse, even how to deﬁne the “distance”
between the system call sequences they induce is unclear. When the replicas
execute on diverse platforms, the system calls supported are diﬀerent and not in
one-to-one correspondence. When coupled with distinct implementations there
is little reason to expect any similarity whatsoever between the system call se-
quences induced on the platforms when each processes the same request.
A key observation in our work, however, is that even though the system
call sequences might not be similar in any syntactic way, they will typically be
correlated in the sense that a particular system call subsequence emitted by
one replica will usually coincide with a (but syntactically very diﬀerent) sub-
sequence emitted by the other replica. These correlations could be determined
either through static analysis of the replica executables (and the libraries), or
by ﬁrst subjecting the replicas to a battery of well-formed (benign) inputs and
observing the system call sequences induced coincidentally. The former is poten-
tially more thorough, but the latter is more widely applicable, being unaﬀected
by diﬃculties in static analysis of binaries for certain platforms1 or, in the future,
1 For example, the complexity of static analysis on x86 binaries is well documented.
This complexity stems from diﬃculties in code discovery and module discovery [24],
with numerous contributing factors, including: variable instruction size (Prasad and
Chiueh claim that this renders the problem of distinguishing code from data unde-
cidable [22]); hand-coded assembly routines, e.g., due to statically linked libraries,
that may not follow familiar source-level conventions (e.g., that a function has a
single entry point) or use recognizable compiler idioms [26]; and indirect branch in-
structions such as call/jmp reg32 that make it diﬃcult or impossible to identify
the target location [24, 22]. Due to these issues and others, x86 binary analysis tools
have strict restrictions on their applicable targets [24, 18, 26, 22].
Behavioral Distance for Intrusion Detection
65
of software obfuscated to render static analysis very diﬃcult for the purposes of
digital rights management (e.g., [7]). So, we employ the latter method here.
1.1 Comparison with Related Work
Utilizing an intrusion detection system to monitor the system calls of a single
(non-replicated) process is a thoroughly explored alternative to the approach we
explore here for detecting software faults and code-injection attacks. However,
all such techniques of which we are aware are vulnerable to mimicry attacks,
whereby code injected by an attacker issues attack system calls within a longer
sequence that is consistent with normal behavior of the program [36, 31, 13]. In
the same fashion, independent system call monitoring of each of two diverse
replicas does not address this problem, provided that the code injected success-
fully into one replica uses mimicry. However, as we will show, the alternative we
consider here, in which replicas are monitored in a coordinated fashion, makes
such an attack far more diﬃcult. The reason is that mimicry of any valid system
call sequence on a replica is not suﬃcient to avoid detection. Rather, to re-
main undetected, mimicry must induce a system call sequence that is typically
observed coincidentally with the sequence emitted by the other, uncorrupted
replica.
Viewed more broadly, our approach can be considered a form of intrusion
detection that seeks to correlate events from multiple distinct components of a
system. Often these events are themselves intrusion detection alerts (e.g., [33,
21]); in contrast, in our approach the events are system calls produced in the
course of the system running normally. As such, our work bears a conceptual
similarity to other eﬀorts that correlate seemingly benign events across multiple
systems to identify intrusions (e.g., [30, 6, 38]). However, we are unaware of any
that demonstrate this capability at the system call level.
1.2 Contributions
In this paper we introduce the notion of behavioral distance for intrusion de-
tection, and detail the design, implementation and performance of a system for
dynamically monitoring the behavioral distance of diverse replicas. We detail
our measure of behavioral distance and our method for divining the correlated
system call subsequences of two replicas. We show through empirical analysis
with three diﬀerent http server implementations and two diﬀerent platforms
(Linux and Windows) that thresholds for behavioral distance can typically be
set so as to induce low false positive (i.e., false alarm) rates while detecting
even a minimal attack consisting of merely an open and a write—even if the
attacker knows that our defense is being used. Moreover, the false alarm rate
can be further reduced in exchange for some possibility of an attack going un-
detected (a false negative), though we believe that this tradeoﬀ can be tuned to
detect the richer attacks seen in practice with virtually no false alarms. Perhaps
more importantly, as a ﬁrst step in analyzing the behavioral distance of diverse
implementations and platforms, we believe this work can lay the framework for
future research to improve this tradeoﬀ further.
66
D. Gao, M.K. Reiter, and D. Song
2 The Problem
The behavioral distance that we deﬁne should detect semantic similar-
ity/diﬀerence when replicas process the same input. That is, provided that
replicas process responses in the same way semantically, the behavioral distance
should be small. However, because the two replicas may be constructed dif-
ferently and may run on diﬀerent operating systems, the two execution traces
will naturally diﬀer syntactically. To bridge this apparent discrepancy, we use
the fact that since the replicas process the same input, during normal program
execution the two syntactically-diﬀerent executions should represent the same
semantic action.
So, our problem is as follows: let s1 and s2 denote sequences of observed be-
haviors of two replicas, respectively. We need to deﬁne (and train) a distance
measure Dist(s1, s2) that returns a small value when the replicas operate seman-
tically similarly, and returns a large value when they semantically diverge. The
quality of the distance measure function Dist() directly impacts the false positive
and false negative rates of the system.
To the best of our knowledge, the problem of developing an accurate behav-
ioral distance measure for detecting software faults and intrusions has not been
studied before. Some techniques have been developed to evaluate the semantic
equivalence of two sequences of program instructions, though these techniques
are diﬃcult to scale to large programs. Also, the problem of semantic equiva-
lence is diﬀerent from the behavioral distance problem that we study here, since
diverse replicas may not behave in exactly the same way. We thus believe we are
the ﬁrst to pose and explore this problem. We also believe that research on this
topic could lead to other applications.
There are many ways to monitor the “behavior” of a process. For example, one
could look at sequence of instructions executed, or patterns in which process’s
internal states change. In this paper, we propose a speciﬁc measure for behav-
ioral distance, by using system call sequences emitted by processes. A system
call is a service provided by the operating system and has been used in many
intrusion/anomaly detection systems [10, 27, 9, 8, 13, 12, 37, 35, 14, 15]. It is a re-
liable way of monitoring program behavior because in most modern operating
systems, a system call is the only way for user programs to interact with the
operating system. Also, system calls are natural places to intercept a program
and perform monitoring, since system calls often require a context switch. Thus,
system call monitoring could introduce lower overhead than intercepting the
program at other points for monitoring.
3 Behavioral Distance Using System Call Sequences
In this section, we describe how we construct the behavioral distance measure
using system call sequences. The goal is to design a quantitative measure such
that system call sequences resulting from the same/similar behavior on replicas
will have a small “distance” value, and system call sequences resulting from dif-
ferent behavior will have a large “distance” value. As pointed out in Section 1,
Behavioral Distance for Intrusion Detection
67
our objective is to develop such a distance measure without analyzing the pro-
gram source code or executable, i.e., the distance measure function Dist(s1, s2) is
deﬁned by ﬁrst subjecting the server replicas to a battery of well-formed (benign)
requests and observing the system call sequences induced.
3.1 Overview
Deﬁning such a behavioral distance measure based on system call sequences is
non-trivial. A system call observed is simply an integer, which is the system call
ID used in the operating system and carries little meaning.2 The two replicas may
run on two diﬀerent operating systems such as Linux and Windows; therefore
the same system call ID is likely to mean very diﬀerent things on two diﬀerent
operating systems. However, because the replicas process the same request and
generate the same response, there is a strong correlation on the semantics of the
system call sequences made by the replicas. Thus, we can evaluate the behav-
ioral distance by identifying the semantic correspondence of the syntactically
unrelated system call sequences.
The sequence of system calls made by a replica can be broken into subse-
quences of system calls, which we call system call phrases. A system call phrase
is a subsequence of system calls that frequently appear together in program exe-
cutions, and thus might correspond to a speciﬁc task on the operating system or
a basic block in the program’s source code. If we can learn the correspondence be-
tween these phrases, i.e., phrases on two replicas that perform the same/similar
task, we can then break sequences of system calls into phrases, and compare
the corresponding phrases to ﬁnd the behavioral distance. A large behavioral
distance indicates an attack or a fault on one of the replicas.
Motivated by the above intuition, we propose to calculate the behavioral
distance as follows. We ﬁrst obtain a distance table, which indicates the distance
between any two system call phrases from two replicas. Ideally, the distance
associated with two phrases that perform the same task is low, and otherwise is
high. Next, we break system call sequences s1 and s2 into sequences of system
call phrases. (Details are covered in Section 3.5.) The two sequences may have
diﬀerent numbers of phrases, and the corresponding phrases (those that perform
similar tasks) might not be at the same location in the two sequences. We handle
this problem by inserting insertion/deletion phrases (denoted as I/D phrases or
σ in the following sections) to obtain two equal-length sequences of phrases
(cid:1)s1,1, . . . , s1,n(cid:2) and (cid:1)s2,1, . . . , s2,n(cid:2). We then look up the distances between the
corresponding phrases in the distance table and compute the behavioral distance
as the sum of these distances:
1≤i≤n dist(s1,i, s2,i).
In the rest of this section, we ﬁrst explain more formally how we calculate the
behavioral distance, and then describe how we obtain the distance table through
learning. Finally we brieﬂy explain how we identify the system call phrases by
pattern extraction.
(cid:1)
2 We could consider the arguments to system calls as well, which would supply addi-
tional information (e.g., [16]). However, we leave this to future work.
68
D. Gao, M.K. Reiter, and D. Song
3.2 Behavioral Distance Calculation
In this subsection, we ﬁrst give the intuition behind our approach by explaining
a related problem in molecular biology and evolution. We then formally deﬁne
our behavioral distance calculation.
A related problem to behavioral distance has been studied in molecular bi-
ology and evolution. Roughly speaking, the problem is to evaluate evolutionary
change between DNA sequences. When two DNA sequences are derived from
a common ancestral sequence, the descendant sequences gradually diverge by
changes in the nucleotides. For example, a nucleotide in a DNA sequence may
be substituted by another nucleotide over time; a nucleotide may also be deleted
or a new nucleotide can be inserted.
To evaluate the evolutionary change between DNA sequences, Sellers [28] pro-
posed a distance measure called evolutionary distance, by counting the number of
nucleotide changes (including substitutions, deletions and insertions) and sum-
ming up the corresponding distances of substitutions, deletions and insertions.
The calculation is easy when nucleotides in the two sequences are aligned prop-
erly, i.e., corresponding nucleotides are at the same location in the two sequences.
However, it becomes complicated when there are deletions and/or insertions, be-
cause the nucleotides are misaligned. Therefore, the correct alignment needs to
be found by inferring the locations of deletions and insertions. Figure 1 shows
an example with two nucleotide sequences and a possible alignment scheme [20].
Our behavioral distance calculation is inspired by the evolutionary distance
method proposed by Sellers [28], where the evolutionary distance is calculated
as the sum of the costs of substitutions, deletions and insertions. In behavioral
distance calculations, we also have the “misalignment” problem. Misalignments
between system call phrases are mainly due to the diverse implementations or
platforms of the replicas. For example, the same task can be performed by dif-
ferent numbers of system call phrases on diﬀerent replicas. Figure 2 shows an
example with two sequences of system call phrases observed when two replicas
are processing the same request. Due to implementation diﬀerences, s2 has an
extra system call phrase idle2 which does not perform any critical operation.
To calculate the behavioral distance, we thus need to perform an alignment
procedure by inserting I/D phrases (inserting an I/D phrase in one sequence is
equivalent to deleting a corresponding phrase from the other sequence) so that
system call phrases that perform similar tasks will be at the same position in
the two aligned sequences. Given a “proper” alignment, we can then calculate
the sum of the distances between the phrases at the same position (Section 3.3
Original Sequence
Aligned Sequence
ATGCGTCGTT
ATCCGCGAT
ATGC-GTCGTT
AT-CCG-CGAT
Fig. 1. Example of two nucleotide sequences
Behavioral Distance for Intrusion Detection
69
s1 = (cid:1)open1, read1, write1, close1(cid:2)
s2 = (cid:1)open2, read2, idle2, write2, close2(cid:2)
Fig. 2. Example of system call sequences observed on two replicas
discusses how we obtain the distances between any two phrases) in the two
sequences and use this sum as the behavioral distance.
Given a pair of misaligned system call sequences, there are obviously more
than one way of inserting I/D phrases into the sequences. Diﬀerent ways of
inserting them will result in diﬀerent alignments and hence diﬀerent behavioral
distances between the two sequences. What we are most interested in here is
to ﬁnd the behavioral distance between two sequences when the phrases are
aligned “properly”, i.e., when phrases that perform similar tasks are aligned
to each other. Although it is not clear how to ﬁnd such an alignment for any
given pair of sequences, we know that the “best” alignment should result in the
smallest behavioral distance between the two sequences, among all other ways
of inserting I/D phrases, because phrases that perform similar tasks have a low
behavioral distance, as explained in Section 3.3. Therefore, we consider diﬀerent
alignments and choose the one that results in the smallest as the behavioral
distance between the two sequences.