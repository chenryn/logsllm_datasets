182022242628Temperature[◦C]−14.5−14.0−13.5−13.0−12.5Clockskew[ppm]NTPcorrectedskewsforAP6182022242628Temperature[◦C]1.52.02.53.03.54.04.55.0Clockskew[ppm]NTPcorrectedskewsforAP4182022242628Temperature[◦C]−18.0−17.5−17.0−16.5−16.0−15.5Clockskewdifference[ppm]2APskewdifferencesAP6−AP49Figure 8: True positive (TP) and false positive (FP)
rates for diﬀerent attacker models; error bars show
variation (95% conﬁdence) over diﬀerent original
APs
dation for all possible combinations. The separation of data
was deliberately not random but followed a logical distinc-
tion. This guaranteed that the testing FP was never used
for training and samples in the testing period had a signif-
icant temporal distance from those in the training period.
This corresponds to a scenario where several users created
ﬁngerprints over time and a new user compares his current
ﬁngerpint against these at some diﬀerent point in time, as
exploited in our proposed architecture (Section 9).
Our evaluation focuses on two measures: whether an orig-
inal AP is recognized (true positive) and whether a faked AP
succeeds in spooﬁng the identity (false positive). Figure 8
shows the result. The true positive rate (TP) for 2AP-based
methods is marginally better than for NTP and all rates are
around 90%. This is slightly less than the targeted 95%,
as the acceptance intervals are generated on disjoint train-
ing data. More interesting are the results for false positives
(FP). A na¨ıve attacker has hardly a chance of succeeding:
All of our methods detect the impostor in more than 90%
of all cases. The best results are obtained with the 2AP-T
method (FP rate 2.23%).
The eﬀectiveness of our method is particularly impres-
sive when dealing with an intelligent attacker. While with
the NTP method the attacker succeeds in 67% of all cases,
the 2AP method decreases his success rate to 56% and the
2AP-T method to 22%. Regardless of the attacker type, the
2AP-T method is able to improve the spoof detection rate
by a factor of three. Since the false positive rates for the in-
telligent attacker exhibit considerable variations for diﬀerent
original APs (indicated by error bars in Figure 8), we show
the separated false positive rates per orginal AP and method
in Figure 9. As we can see, in general the 2AP method out-
performs NTP. However, the 2AP-T method is always sig-
niﬁcantly better than both the NTP and the 2AP methods.
The error bars for the 2AP and 2AP-T methods indicate
the variance over the diﬀerent comparison APs. The 2AP
method is prone to large variations caused by the diﬀerent
temperature dependency characteristics of the comparison
APs. This eﬀect is drastically reduced by 2AP-T, which
explicitly considers the current temperature. We further
see, that even for APs with similar attacker success rates
against NTP and 2AP (e. g., AP5/7 or AP2/8), the success
rate against the 2AP-T method diﬀers notably. 2AP-T per-
prediction f (x) (±2(cid:112)V[f (x)], corresponding to the
Figure 7: Two examples for GPR: pointwise mean
95 %-conﬁdence region)
nition interval size. We obtained 1.73 ppm for the NTP
method, 1.56 ppm for the 2AP method and 0.41 ppm for the
2AP-T method. The results reveal that the temperature-
dependent prediction of the 2AP-T method improves ﬁn-
gerprinting discriminability by more than 75% on average
compared to NTP. In the following, we examine how the
three methods perform in detecting whether an AP has been
replaced by an attacker.
7.2 Detection of Fake APs
We consider two attacker types: The na¨ıve attacker has no
information on the original AP’s clock skew. He randomly
selects an available AP for the attack. Practically, we model
this attacker by replacing a considered AP with every other
AP in our data set and taking the mean success rate. The
intelligent attacker knows about the clock skews and the de-
tection method used. Thus, he is able to select the AP with
the clock skew closest to the original AP’s clock skew in our
data set as the replacement. Recall that we do not consider
attackers who perform extensive hardware modiﬁcations to
control the clock skew.
We divided our data into training and testing as follows:
all data was separated into four equally long time periods
(corresponding to approximately one week each). Training
was performed by three (out of four) ﬁngerprinters on the
data of three (out of four) weeks and tested by the remain-
ing ﬁngerprinter on the data from the remaining week. To
get a representative result, we performed 16-fold cross vali-
182022242628Temperature[◦C]−18.0−17.5−17.0−16.5−16.0−15.5Clockskewdifference[ppm]2APskewdifferencesAP6−AP4withGPR182022242628Temperature[◦C]1.52.02.53.03.5Clockskewdifference[ppm]2APskewdifferencesAP9−AP5withGPRTPFP(naive)FP(intelligent)020406080100Fraction[%]NTP2AP2AP-T10Figure 9: FP rate for intelligent attacker per AP;
error bars show variation over comparison APs for
2AP and 2AP-T (95% conﬁdence)
Figure 10: Exemplary input for the SVM
forms best for cases where temperature dependency is very
pronounced.
We now present an information theoretical perspective on
how much information the temperature contributes to the
classiﬁcation of the APs in our sample.
7.3 Information Theory
(cid:80)
y∈Y
(cid:80)
From an information theoretical point of view, we are in-
terested in how much information is contained in the tem-
perature dependency, which we use as additional feature
for the 2AP-T recognition/fake detection method. A com-
mon evaluation measure is the mutual information (MI),
deﬁned for two random variables X and Y as I(X; Y ) =
p(x) p(y) . In our case, Y represents
the considered AP pair, while X denotes the classiﬁcation
feature, i. e., clock skew diﬀerence for the 2AP method and
the combination of clock skew diﬀerence and temperature
for the 2AP-T method.
x∈X p(x, y) log p(x,y)
The concept of MI is closely related to entropy and results
are expressed as bits. For feature selection, MI measures
how much information the presence of a feature contributes
to making the correct classiﬁcation decision. In the case of
our methods, it measures how much additional information
is provided by the temperature dependency (2AP-T) com-
pared to observing only the clock skew diﬀerence (2AP). For
details about the calculation we refer to [19]. For our data
set, we obtain an MI for 2AP of 4.12 bits and for 2AP-T of
5.16 bits. Note that for our data, the MI is upper bounded
by 6.04 bits (as we are classifying 66 diﬀerent pairs). There-
fore, the (information theoretically) perfect feature for clas-
siﬁcation cannot contribute more than 6.04 bits of infor-
mation. We conclude that the knowledge of temperature
dependency contains more than half of the remaining un-
certainty of access point identiﬁcation when combined with
2AP clock skew diﬀerences.
8. METHOD WITHOUT EXPLICIT
KNOWLEDGE OF TEMPERATURE
Although our approach provides reliable detection of re-
placed APs, it depends on information that is not always
available in measuring devices: the temperature that APs
are exposed to. The question we address in this section is
how, if at all, we can perform the detection of impostors if
no explicit temperature information is available.
We assume that there are at least three APs transmitting
in the environment to be evaluated (say, these are AP1, AP4,
and AP11). For every time instance, the ﬁngerprinter is
able to derive three 2AP clock skew diﬀerences: AP1−AP4,
AP11−AP4, AP11−A1. The key idea of our approach is to
learn legitimate combinations of simultaneously occurring
diﬀerences. Figure 10 shows an example of two time in-
stances, time ti with clock skew diﬀerences (−3.797,−3.607,
−7.552) and time tj with (−0.704,−6.451,−7.013). We
use such triples of simultaneously measured clock skew dif-
ferences as vectors to train a machine learning technique.
Three APs is the minimum number required because from
two APs only one diﬀerence could be derived. Note that
when using only two APs the machine learning approach is
equivalent to the 2AP method and does not learn legitimate
combinations but rather single diﬀerences. The proposed
method only detects whether one of the three APs is faked
and not which one. This is similar to the 2AP and 2AP-
T methods only detecting whether one out of two APs is
potentially spoofed. As described in Section 5, a greater
number of reachable APs can be used to identify the actual
fake AP.
We apply support vector machines (SVMs), state-of-the-
art classiﬁcation methods used in machine learning, which
are well-known for their high performance in terms of clas-
siﬁcation accuracy. The technique dates back to the work
of Vapnik and Chervonenkis [28] in 1974. The focal idea is
the interpretation of instances as vectors in a vector space.
Based on training data, the classiﬁer tries to ﬁt a hyper-
plane into the vector space which separates the instances
that belong to diﬀerent classes. In our case (one class SVM)
the plane is ﬁtted in such a way that the training data is
separated from the origin whereby a fraction of at most ν
(which is a SVM parameter) training points are allowed to
be outside the estimated region.
The plane is ﬁtted such that the accumulated distance be-
tween the closest instances (support vectors) and the plane is
maximized to ensure a clear distinction between the classes.
In cases where the vectors are not linearly separable, the
vector space is transformed into a higher dimensional space
where the linear separation is possible (the kernel trick ). An
interested reader is pointed to [5] for thorough information
about SVMs.
AP6AP10AP5AP9AP2AP7AP3AP12AP8AP11AP1AP4020406080100Fraction[%]NTP2AP2AP-T182022242628Temperature[◦C]−10−8−6−4−202ClockSkewDifference[ppm]AP1−AP4AP11−AP4AP11−AP1AP1−AP4AP11−AP4AP11−AP1AP1−AP4AP11−AP4AP11−AP1titj11Sample Size
[% / #]
TP [%]
avg/mdn
FP [%]
avg/mdn
100 / 3520
0.05 / 300–400
0.015 / 130–160
0.005 / 40–50
87.26 / 96.88
85.95 / 96.34
84.53 / 94.81
80.48 / 90.13
12.18 / 0.00
11.07 / 0.00
10.96 / 0.00
10.54 / 0.00
Table 1: True and false positive rate without explicit
temperature knowledge
We divided our data into training and testing in the same
way as in previous sections. The parameter ν deﬁnes an
upper bound on the fraction of outliers and, at the same
time, a lower bound on the fraction of support vectors (i. e.,
the generalizability of the model). We set ν = 0.05; hence,
at most 5% of training data may be assigned to false neg-
atives by the model. Table 1 (ﬁrst row) shows the results
of the evaluation. We choose the intelligent attacker model
described above (i. e., he replaces the original AP with a fake
AP that best matches the original clock skew). We skipped
the cases when the best fake AP is already included in the
triple. As our evaluation shows, on average more than 87%
of trustworthy environments are recognized as such (true
positive). The median reaches almost 97%. The intelligent
attacker is successful in only about 12% of all cases (false
positive).
The result is at ﬁrst glance superior to the 2AP-T method.
However, the two methods cannot be directly compared as
they consider diﬀerent numbers of simultaneously reachable
APs.
Nevertheless, the results without explicit knowledge of
temperature provide surprisingly high accuracy. This is
achieved even without tuning SVM parameters. We assume
that by optimizing them, one would get even better results
(but we omit this due to the high accuracy classiﬁcation
even with the default parameters).
Recall that all our observations were collected in an en-
vironment where all APs shared the same temperature ex-
posure. In practical applications, this might not hold true.
However, we expect our method to still provide signiﬁcant
detection accuracy as long as the diﬀerent temperatures are
correlated, e. g., due to outdoor temperature or time of day.
For practical relevance, it is important to know how many
observations (training data) are needed to achieve good clas-
siﬁcation accuracy. To determine this number, we performed
our evaluation by randomly selecting only 0.05%, 0.015%,
and 0.005% of all available training data. This corresponds
to roughly 350, 150, and 50 samples. The results are shown
in Table 1 in rows two to four. As expected, less training
data leads to lower classiﬁcation accuracy. However, the
accuracy degradation is very slight: using only 50 training
samples, on average the accuracy is as high as 80% for true
positives and 10% for false positives. These results underline
the practical relevance of our method as only a few dozen
observations without any temperature information are suﬃ-
cient to learn the parameters of a trustworthy environment.
9. ARCHITECTURE
To exploit the results described above, we propose an ar-
chitecture based on a crowdsourcing approach (Figure 11).
The core of this system is a trusted service (TS) that col-
Figure 11: The architecture
lects ﬁngerprints, performs the necessary calculations and
provides feedback to users. Assume a user who wants to
connect to a (potentially untrustworthy) access point (UAP)
and wants to ensure its trustworthiness. A client application
(app) ﬁrst extracts timing information from beacon frames
of all receivable APs, calculates the respective clock skews