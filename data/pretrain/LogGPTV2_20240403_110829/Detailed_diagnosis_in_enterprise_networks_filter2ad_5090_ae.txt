tems for detailed diagnosis to be possible. But the sheer scale of this
observable state makes understanding variable semantics daunting.
NetMedic’s ability to be application agnostic allows diagnosis to work
even as new applications emerge or variable semantics change.
7.2 Effectiveness of diagnosis
Figure @(a) shows the e(cid:11)ectiveness of NetMedic and Coarse across
all faults injected in the live environment. ˆe lines connect the me-
dian ranks and the error bars denote the maximum ranks. ˆe two
curves are independently sorted based on the median rank.
251 
s
s
t
t
l
l
u
u
a
a
f
f
f
f
o
o
%
%
e
e
v
v
i
i
t
t
a
a
l
l
u
u
m
m
u
u
C
C
100
80
60
40
20
0
0
10 20 30 40 50
% abnormal components
(a)
s
s
t
t
l
l
u
u
a
a
f
f
f
f
o
o
%
%
e
e
v
v
i
i
t
t
a
a
l
l
u
u
m
m
u
u
C
C
100
80
60
40
20
0
Coarse
NetMedic
0
10 20 30 40 50
% high weight edges
(b)
100
80
60
40
20
0
e
e
s
s
u
u
a
a
c
c
t
t
c
c
e
e
r
r
r
r
o
o
c
c
f
f
o
o
k
k
n
n
a
a
R
R
Basic
NetMedic
HandPicked
0
20 40 60 80 100
Cumulative % of faults
(a)
100
80
60
40
20
0
e
e
s
s
u
u
a
a
c
c
t
t
c
c
e
e
r
r
r
r
o
o
c
c
f
f
o
o
k
k
n
n
a
a
R
R
Basic
Abnormality
NetMedic
55
38
4 1
5
80
95
Cumulative % of faults
(b)
Figure @. (a) CDF of the percentage of components that are ab-
normal during a fault. (b) CDF of the percentage of edges that are
assigned a high weight in the dependency graph.
We see that for @ʃʂ of the faults the median rank of the correct
cause is one with NetMedic. ˆat is, NetMedic frequently places the
real culprit at the top of the list of likely causes. For all cases except
one, the median rank of the correct cause is (cid:12)ve or lower. ˆe max-
imum ranks are o(cid:13)en close to the median ranks, representing good
worst-case behavior as well. ˆese results suggest that NetMedic can
help operators diagnose such faults in their networks.
In contrast, diagnosing these faults with Coarse would likely be
a frustrating exercise. ˆe correct cause is assigned a rank of one in
fewer than ʄʈʂ of the cases. For over ʉʃʂ of the cases, the correct
cause has a median rank of more than ten.
We examined cases where NetMedic assigned a median rank
greater than three to the correct cause. We (cid:12)nd that these o(cid:13)en cor-
respond to performance faults, which include Problems ʅ, @ and @ in
Table ʄ. ˆe side-e(cid:11)ects of these faults lead to abnormality in many
components in the network. For instance, a process that hogs the
CPU disturbs many other processes on its machine, each of which
can appear abnormal. A few of the victim components can get ranked
lower than the correct cause if there is insu(cid:14)cient history to correctly
determine the direction of impact. Diagnosis of non-performance
faults, which tend to be more prevalent (§ʅ.ʆ) turns out to be easier
as they disturb fewer components in the network.
Let us consider now the results from the controlled environment
shown in Figure @(b). We reduce the y-axis range for this graph be-
cause the environment has fewer components. We see that NetMedic
e(cid:11)ectively diagnoses faults in this setting as well.
Interestingly, Coarse performs much better in this setting. In the
live environment, for the worst ʅʃʂ of the cases, its median rank is ʆʈ
or higher. Here, the median rank is @ or higher, a sharp improvement
even a(cid:13)er accounting for the di(cid:11)erence in the numbers of compo-
nents. ˆus, in going from the controlled to the more dynamic and
realistic setting, the ability of Coarse degrades sharply. ˆis degrada-
tion stems from the fact that the live environment has more abnormal
components. Because of its simplistic component states and depen-
dency models, Coarse cannot e(cid:11)ectively infer which components are
impacting each other, and many components get ranked lower than
the real culprit. NetMedic, on the other hand, shows no such degra-
dation in our experiments and appears better equipped towards han-
dling the noise in real environments. ˆe next section investigates in
more detail why the methods di(cid:11)er.
7.3 Why NetMedic outperforms Coarse?
NetMedic outperforms Coarse primarily because at the level of de-
tail that we observe at, components are o(cid:13)en abnormal. As a result,
Coarse assigns a high weight to many edges and ends up erroneously
connecting many non-responsible components to the observed ef-
fects. By looking at component states in detail and allowing for com-
plex dependencies, NetMedic assigns a low weight to many edges even
when both end points are abnormal simultaneously.
Figure @(a) shows the CDF of the percentage of components that
are abnormal during the periods covering various faults. We see that
this percentage is quite high (ʅʃ-ʇʃʂ).
Figure @. Value of NetMedic’s extensions to the basic procedure.
Figure @(b) shows the CDF of the percentage of edges in the de-
pendency graph that are assigned a high weight (> 0.75) by each
scheme. We see that this percentage is ʆʈ-ʇʈʂ for Coarse and ʄʃ-
ʄʈʂ for NetMedic, which represents reduction by a factor of ʆ. ˆis
reduction in likely spurious high-weight edges leads to fewer possible
causes being strongly connected to the a(cid:11)ected component, resulting
in fewer false positives and lower ranks for real causes.
Simply changing the requirement for deeming a component as ab-
normal (e.g., using a higher abnormality threshold or requiring more
state variables to be abnormal) may reduce false positives. But we (cid:12)nd
that doing so can hurt. It runs the risk of excluding the real culprit
from the list altogether; the culprit or a component on the path from
it to the e(cid:11)ect of interest may appear normal.
7.4 Beneﬁt of extensions
We now study the value of the extensions to edge weight assign-
ment by comparing them to two other methods. ˆe (cid:12)rst is the basic
procedure, without the extensions. For the second method, instead
of automatically inferring relationships between variables, we hand
code them, based on our knowledge of what each variable represents.
Given that the number of variables is quite large, we hard code knowl-
edge of only those that are relevant for diagnosing the faults that we
inject. Beyond programming these relationships, the rest of the pro-
cedure stays the same. Comparison with this “HandPicked” method
quanti(cid:12)es any reduction in diagnostic e(cid:11)ectiveness due to our desire
to be application agnostic and treating these variables as opaque.
Figure @(a) shows the diagnostic e(cid:11)ectiveness of all three meth-
ods. Comparing the basic procedure with Coarse in Figure @(a) re-
veals that it more frequently assigns a rank of one to the correct cause.
ˆis frequency is ʇʇʂ versus the ʄʇʂ of Coarse. But overall, the ba-
sic procedure is quite fragile. In fact in the worst ʅʃʂ of the cases, it
assigns a higher rank to the correct cause than Coarse.
ˆe extensions help make the basic idea practical—an @ʃʂ fre-
quency of assigning a rank of one to the correct cause and a signif-
icant reduction in the ranks of the correct cause for half the faults.
Closer examination reveals that such faults o(cid:13)en correspond to per-
formance issues. As mentioned previously, performance faults have
more side e(cid:11)ects than con(cid:12)guration faults. ˆe extensions are better
able to si(cid:13) through this noise.
Figure @(a) also shows that the performance of NetMedic is close
to HandPicked. ˆus, the extensions extract enough semantic infor-
mation for our task to not require embedding knowledge of variable
semantics into the system.
To investigate in more detail, we separately consider the extension
that weighs variables based on their abnormality values and the other
three extensions that infer variable relationships. Figure @(b) shows
the median rank for @ʃth and @ʈth percentile of the faults with the
basic procedure, with only the abnormality extension, and NetMedic,
which includes all extensions. We see that both factoring in abnor-
mality and variable relationships are useful.
7.5 Multiple simultaneous faults
We now study the ability of NetMedic to diagnose multiple, si-
multaneously occurring faults. In a dynamic network, simultane-
252100
80
60
40
20
0
e
e
s
s
u
u
a
a
c
c
t
t
c
c
e
e
r
r