guishability against Chosen Plaintext Attack (C-P-IND-
CPA).
Theorem 3 (Credential privacy) If the DDH assumption
holds for Z∗
then PEAPOD has Credential Indistin-
p,
guishability.
4. Discussion
Trust relationships
In PEAPOD, the procedure for dis-
tributing credentials is split between the CA and the Server,
and each credential for a user is generated with the hon-
est cooperation between these two entities. This trust as-
sumption is similar to that of SELS since our system uses a
modiﬁed version of SELS as a building block. Neither the
Server nor the CA can decrypt messages intended for a par-
ticular recipient. If they collude, however, the credentials
of each recipient can be computed and the Server can de-
crypt all messages in the system and infer their policies. We
observe that in current approaches for Hidden Credentials
based on IBE, the PKG already has the ability to decrypt
all the messages in the system. PEAPOD splits this trusted
functionality between the CA and the Server and therefore
the security of published messages (e.g., at a bulletin-board)
with respect to the trusted entities is at least as good as that
in previous schemes. We now examine what damage a cor-
rupt CA or Server can do individually.
A corrupt CA by itself cannot decrypt messages in the
system without having the correct credentials. Therefore, a
CA can simply issue unlimited credentials to itself. How-
ever, we assume that the Server does not collude with the
CA and will only allow legitimate users in the system (ver-
iﬁed using, e.g., PKI [3]) to obtain the credential for an
attribute. Therefore, the CA cannot pose as a user in the
system. The policy privacy with respect to the CA is main-
tained under these circumstances, which can only be broken
with the help of a malicious Server.
Analogous to a corrupt CA, a corrupt Server cannot de-
crypt any messages without having the correct credentials.
The Server cannot issue itself any credentials since this re-
quires the cooperation of the CA, which we assume does
not collude with the Server. Nonetheless, the server can
be malicious when serving retrieval requests by not follow-
ing the algorithm, causing ciphertexts to be decrypted into
“garbage” even by intended recipients. In this kind of de-
nial of service attack (DoS), a recipient who cannot decrypt
a ciphertext has no way to tell if he or she does not satisfy
the associated policy, the server is malicious, or the sender
encrypted garbage. An interesting area for future work is
to devise a protocol that will detect a misbehaving Server
and let the receiver determine whether he or she satisﬁed
the policy.
Our system provides policy privacy with respect to the
Server and clausal policy-indistinguishability for all recip-
ients.
If the Server and recipient collude, however, both
the recipient and the Server can learn the policy of the
sender. Therefore, some amount of trust must be placed
in the Server to not collude with users. One option is to
involve the CA in the protocol so that cooperation with the
CA would also be needed to break policy privacy. Involving
the CA, however, raises issues such as performance, ofﬂine
vs. online CAs, and so on.
Inference attacks on policy privacy We now examine
the implications of the information that a recipient Bob
learns about the policy. As discussed earlier, if Bob satisﬁes
‘ ≥ 0 clauses, he can infer only that the policy is one among
a set of policies for which he satisﬁes ‘ clauses. We call this
set Bob’s “inference set,” within which all policies are in-
distinguishable to Bob. Since Bob’s goal is to ﬁgure out the
exact nature of the ‘ clauses that he does satisfy, Bob can
focus on policies with ‘ clauses and try to infer what they
may be. We will refer to this set of policies as Bob’s “infer-
ence set restricted to ‘ clauses.” The size of the inference
set will vary for different receivers. In systems that support
only monotonic boolean formulae for policies, consider
the trivial example: Bob has only one credential “is a
smoker.” If he is able to decrypt the message, he can infer
that the policy contains the clause “is a smoker.” The
size of the inference set (restricted to the satisﬁed clause)
is 1. PEAPOD, however, provides much better guaran-
tees since it supports non-monotonic boolean policies. For
example, the inference set in PEAPOD would also in-
clude a vast number of other possibilities such as “not in
their 30’s,” “not a college graduate ∧ is
a smoker,” and so on.
Coalition attacks We now discuss some of the coalition
attacks where several recipients “pool in” their credentials.
As a ﬁrst line of defense, users cannot simply share the
pieces of their key shares together since they are forced to
compute the product of shares over their entire set of at-
tributes. Therefore the simple pooling in of credentials will
not succeed in general. Consider the case when two col-
luding receivers obtain k1k2 and k2k3 respectively, and let
k = k1k2k3. In such as case k cannot be retrieved since the
individual pieces k1, k2 and k3 are not known to the collud-
ing users. In certain cases, however, these products can be
combined meaningfully. Say k = k1k2. Bob may possess
attribute a1 but not a2 and Charlie may possess attribute a2
but not a1. Bob will thus recover k1 and Charlie will re-
cover k2. They can collude to expose k. Therefore, even
though coalition attacks are not straightforward, PEAPOD
is not secure against coalition attacks in general. Further-
more, different recipients can compute the intersection of
their inference sets for a particular message and try to nar-
row down the set of possible policies for that message.
Sender and receiver anonymity
In PEAPOD, any party
can retrieve from the Server ciphertexts for any user, say,
Bob. Conﬁdentiality guarantees that only Bob can decrypt
the ciphertexts and therefore it does not matter if the Server
gives away the re-encrypted ciphertexts to anyone unau-
thenticated or even anonymous. As a consequence, any-
one could have retrieved Bob’s ciphertexts and this allows
Bob to deny that he requested the ciphertext. Therefore
PEAPOD supports a weak form of anonymity for receivers
called plausible deniability, which means that no user can
be implicated with overwhelming probability. A detailed
discussion on how receivers can protect their anonymity is
outside the scope of this paper, but in general users can
access the server using an anonymizing network such as
Tor [13]. This approach, however, opens up the possibility
of DoS attacks where malicious users can bog the Server
down with repeated requests for ciphertexts. Authentica-
tion of receivers can alleviate this problem, but most au-
thentication schemes will destroy the property of plausible
deniability. The system can employ deniable authentica-
tion [14, 22, 29, 26] to provide plausible deniability,11 while
maintaining DoS resistance. The server may also choose to
employ authentication only when it is under DoS attack,
and forego authentication under normal operation.
Senders can post messages anonymously to the Server,
and therefore the authenticity (the identity of the sender) of
messages cannot be guaranteed unless the sender digitally
signs the message. If the sender desires anonymity, he or
she may choose to use a group signature scheme [10, 4, 5] to
maintain anonymity (within the group) while guaranteeing
to the receiver that the message was signed by somebody in
the group.
Dynamism We assume a static set of attributes that re-
mains unchanged throughout the lifetime of the system. It
would be useful, however, to support the addition and re-
moval of attributes, both to the system, and to the individual
users’ attribute sets. While it is quite possible to adapt our
system to support dynamism without losing conﬁdentiality,
maintaining policy privacy in a dynamic environment is not
straightforward. For example, a user who does not satisfy a
policy with respect to attribute set A might satisfy the same
policy after A has been updated to some different attribute
set A0. By studying the difference between A and A0, the
11With such an authentication scheme, the Server cannot prove to any
third party that Bob requested the ciphertext, even though the Server
knows that Bob requested it.
user can possibly infer the nature of some attributes in the
policy. One simple countermeasure would be to prevent
users from retrieving two versions of the same ciphertext
under different attribute sets. We plan to address the effects
of dynamism on policy privacy and suitable countermea-
sures in future work.
Efﬁciency It is worth looking at the message expansion
imposed by Full-PEAPOD as a consequence of achieving
the various desirable properties on top of sole conﬁdential-
ity. Let m be the number of established attributes and n
be the maximum number of clauses in a policy. Also let
λ be the security parameter, which equals the bit-length of
the size of the group Z∗
p. Observe that a ciphertext has a
(2λmn)-bit space overhead in addition to the symmetric
encryption of the plaintext message. When the size of the
plaintext message is big enough, the expansion is insignif-
icant. For example, in the case when n = 8, m = 50 and
λ = 1024, the overhead is 100 kilobytes. Both deposit-
ing a ciphertext and retrieving a ciphertext have space and
time complexities of O(mn) if we ignore the symmetric en-
cryption and decryption. In particular, when Bob retrieves
a message, the Server must perform O(mBn) operations,
where mB is the number of attributes that Bob has been
In the worst case, mB = m and
issued credentials for.
the Server has to perform mn re-encryption and homomor-
phic encryption steps. We stress that Full-PEAPOD is very
scalable in terms of number of users in the system because
the time and space complexities of all algorithms are inde-
pendent of the number of users.
The main computational bottleneck is the ciphertext re-
trieval step at the Server. To handle a retrieval request, the
Server has to do 3 modular exponentiations and 4 modular
multiplications per attribute for each clause.12 On a reason-
ably fast server machine such as Sun Fire T2000 [33], this
step takes less than 0.1s if n = 8 and m = 50.13 Therefore,
the system can handle at least 600 message retrieval per
minute, which would be sufﬁcient for organizational net-
works. For example, a college or a university could be eas-
ily serviced without noticeable delays. Furthermore, since
the retrieval operation is naturally parallelizable, Field Pro-
grammable Gate Arrays (FPGAs) can be used to signiﬁ-
cantly reduce the amount of time for retrieving messages.
As FPGAs get faster and cheaper, one could ﬁt several re-
encryption engines onto a single FPGA. For example, us-
ing current technology, one could ﬁt seven 1024-bit exp.
12Speciﬁcally, 1 modular exponentiation (exp.) and 1 modular multi-
plication (mul.) for re-encryption, 2 exp. and 1 mul. for encrypting the
blinding factor and 2 mul. for homomorphic operation.
13This machine can do 17,023 1024-bit DSA-signing per second [32].
The 0.1s estimate is based on two assumptions: one DSA-signing takes
the same time as one exp.; and four mul. take the same time as one exp.
These are conservative assumptions and therefore the estimate is a loose
upper bound. In practice, one should be able to achieve much better per-
formance.
architecture due to Blum and Paar [7] in Xilinx’s Virtex-5
XC5VLX330.14
In future work we plan to address various tradeoffs be-
tween policy privacy and the system parameters to improve
scalability with respect to the number of attributes n in the
system. For example, users can pick a subset of attributes
within which the policies are private. This would reduce
the overhead, and yet still provide sufﬁcient policy privacy
in systems with a large number of attributes.
5. Conclusions
We present PEAPOD, a system where publishers can
disseminate information securely to multiple possible re-
cipients using attribute-based policies. Unlike previous ap-
proaches that require online interaction or knowledge of
the recipient’s identity or pseudonym beforehand, in our
approach messages are securely deposited at a server for
ofﬂine retrieval by multiple possible recipients unknown
to the sender. Users can decrypt these messages if and
only if their credentials satisfy the publisher’s policy, and
the publisher does not gain any knowledge of the users
“Hidden Credentials.” Our system uses SELS as a build-
ing block to solve the problem of shared decryption keys
between users with the same attribute and extends this
technique with homomorphic encryption to provide mes-
sage conﬁdentiality and clausal policy-indistinguishability
against all recipients, intended or not, and complete policy-
indistinguishability against the server. In the context of the
problem of securely publishing messages to multiple pos-
sible recipients, the policy privacy properties provided by
PEAPOD surpass those provided by all previously known
Hidden Credential schemes. Unlike previous approaches,
PEAPOD is also able to efﬁciently support non-monotonic
boolean policies, i.e., policies that contain negations of at-
tributes.
6. Acknowledgments
We would like to thank Alexander Iliev, Chris Masone,
Peter Johnson, Nikos Triandopoulos, and Nihal D’Cunha
for their helpful comments.
References
[1] M. Abe and K. Suzuki. M+1-st price auction using homo-
morphic encryption. In D. Naccache and P. Paillier, editors,
Public Key Cryptography, volume 2274 of Lecture Notes in
Computer Science, pages 115–124. Springer, 2002.
14Blum and Paar’s architecture occupies 6633 Conﬁgurable Logic
Blocks (CLBS) and can do one exp. in 11.95ms. XC5VLX330 has 51840
slices.
[2] A. Acquisti. Receipt-free homomorphic elections and write-
in ballots. Cryptology ePrint Archive, Report 2004/105,
2004. http://eprint.iacr.org/.
[3] C. Adams and S.Farrell. Internet X.509 Public Key Infras-
tructure Certiﬁcate Management Protocols. Internet Engi-
neering Task Force: RFC 2510, 1999.
[4] G. Ateniese, J. Camenisch, M. Joye, and G. Tsudik. A
practical and provably secure coalition-resistant group sig-
In M. Bellare, editor, CRYPTO, volume
nature scheme.
1880 of Lecture Notes in Computer Science, pages 255–270.
Springer, 2000.
[5] M. Bellare, H. Shi, and C. Zhang. Foundations of group
signatures: The case of dynamic groups.
In A. Menezes,
editor, CT-RSA, volume 3376 of Lecture Notes in Computer
Science, pages 136–153. Springer, 2005.
[6] M. Blaze, G. Bleumer, and M. Strauss. Divertible protocols
In EUROCRYPT, pages
and atomic proxy cryptography.
127–144, 1998.
[7] T. Blum and C. Paar. High-radix montgomery modular ex-
ponentiation on reconﬁgurable hardware. IEEE Trans. Com-
put., 50(7):759–764, 2001.
[8] D. Boneh and M. Franklin. Identity-based encryption from
Lecture Notes in Computer Science,
the Weil pairing.
2139:213–229, 2001.
[9] R. W. Bradshaw, J. E. Holt, and K. E. Seamons. Conceal-
ing complex policies with hidden credentials. In Eleventh
ACM Conference on Computer and Communications Secu-
rity, Washington, DC, pages 146–157, oct 2004.
[10] D. Chaum and E. van Heyst. Group signatures. In EURO-
CRYPT, pages 257–265, 1991.
[11] X. Chen, B. Lee, and K. Kim. Receipt-free electronic auc-
tion schemes using homomorphic encryption. In J. I. Lim
and D. H. Lee, editors, ICISC, volume 2971 of Lecture
Notes in Computer Science, pages 259–273. Springer, 2003.
[12] I. Damg˚ard and M. Jurik. A length-ﬂexible threshold cryp-
tosystem with applications.
In R. Safavi-Naini and J. Se-
berry, editors, ACISP, volume 2727 of Lecture Notes in
Computer Science, pages 350–364. Springer, 2003.
[13] R. Dingledine, N. Mathewson, and P. Syverson. Tor: The
Second-Generation Onion Router. In Usenix Security, aug