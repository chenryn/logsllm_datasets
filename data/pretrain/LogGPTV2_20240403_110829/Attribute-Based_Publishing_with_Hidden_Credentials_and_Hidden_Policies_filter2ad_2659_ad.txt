### Credential Privacy

**Theorem 3 (Credential Privacy):** If the Decisional Diffie-Hellman (DDH) assumption holds for \( \mathbb{Z}_p^* \), then PEAPOD has indistinguishable credentials.

### 4. Discussion

#### Trust Relationships

In PEAPOD, the process of distributing credentials is divided between the Certificate Authority (CA) and the Server. Each user's credential is generated through the honest cooperation of these two entities. This trust model is similar to that of SELS, as our system uses a modified version of SELS as a building block. Neither the Server nor the CA can decrypt messages intended for a specific recipient. However, if they collude, the credentials of each recipient can be computed, allowing the Server to decrypt all messages in the system and infer their policies.

In current approaches for Hidden Credentials based on Identity-Based Encryption (IBE), the Private Key Generator (PKG) already has the ability to decrypt all messages in the system. PEAPOD splits this trusted functionality between the CA and the Server, thereby ensuring that the security of published messages (e.g., on a bulletin board) with respect to the trusted entities is at least as good as in previous schemes. We now examine the potential damage that a corrupt CA or Server can individually inflict.

- **Corrupt CA:**
  A corrupt CA by itself cannot decrypt messages in the system without the correct credentials. The CA could issue unlimited credentials to itself. However, we assume that the Server does not collude with the CA and will only allow legitimate users (verified, e.g., using PKI [3]) to obtain the credential for an attribute. Therefore, the CA cannot impersonate a user in the system. Policy privacy with respect to the CA is maintained under these circumstances, which can only be broken with the help of a malicious Server.

- **Corrupt Server:**
  A corrupt Server cannot decrypt any messages without the correct credentials. The Server cannot issue itself any credentials since this requires the cooperation of the CA, which we assume does not collude with the Server. However, the Server can be malicious when serving retrieval requests by not following the algorithm, causing ciphertexts to be decrypted into "garbage" even by intended recipients. In this kind of Denial of Service (DoS) attack, a recipient who cannot decrypt a ciphertext has no way to determine whether they do not satisfy the associated policy, the Server is malicious, or the sender encrypted garbage. An interesting area for future work is to devise a protocol that can detect a misbehaving Server and allow the receiver to determine whether they satisfied the policy.

Our system provides policy privacy with respect to the Server and clausal policy-indistinguishability for all recipients. If the Server and recipient collude, both the recipient and the Server can learn the policy of the sender. Therefore, some level of trust must be placed in the Server to not collude with users. One option is to involve the CA in the protocol so that cooperation with the CA would also be needed to break policy privacy. Involving the CA, however, raises issues such as performance, offline vs. online CAs, and so on.

#### Inference Attacks on Policy Privacy

We now examine the implications of the information that a recipient, Bob, learns about the policy. If Bob satisfies \( \ell \geq 0 \) clauses, he can infer only that the policy is one among a set of policies for which he satisfies \( \ell \) clauses. We call this set Bob’s "inference set," within which all policies are indistinguishable to Bob. Since Bob's goal is to figure out the exact nature of the \( \ell \) clauses that he does satisfy, Bob can focus on policies with \( \ell \) clauses and try to infer what they may be. We refer to this set of policies as Bob’s "inference set restricted to \( \ell \) clauses." The size of the inference set will vary for different receivers.

In systems that support only monotonic boolean formulae for policies, consider the trivial example: Bob has only one credential "is a smoker." If he is able to decrypt the message, he can infer that the policy contains the clause "is a smoker." The size of the inference set (restricted to the satisfied clause) is 1. PEAPOD, however, provides much better guarantees since it supports non-monotonic boolean policies. For example, the inference set in PEAPOD would also include a vast number of other possibilities such as "not in their 30’s," "not a college graduate ∧ is a smoker," and so on.

#### Coalition Attacks

We now discuss some coalition attacks where several recipients "pool in" their credentials. As a first line of defense, users cannot simply share the pieces of their key shares together since they are forced to compute the product of shares over their entire set of attributes. Therefore, the simple pooling of credentials will not generally succeed.

Consider the case when two colluding receivers obtain \( k_1k_2 \) and \( k_2k_3 \) respectively, and let \( k = k_1k_2k_3 \). In such a case, \( k \) cannot be retrieved since the individual pieces \( k_1, k_2, \) and \( k_3 \) are not known to the colluding users. In certain cases, however, these products can be combined meaningfully. Say \( k = k_1k_2 \). Bob may possess attribute \( a_1 \) but not \( a_2 \), and Charlie may possess attribute \( a_2 \) but not \( a_1 \). Bob will thus recover \( k_1 \) and Charlie will recover \( k_2 \). They can collude to expose \( k \). Therefore, even though coalition attacks are not straightforward, PEAPOD is not secure against coalition attacks in general. Furthermore, different recipients can compute the intersection of their inference sets for a particular message and try to narrow down the set of possible policies for that message.

#### Sender and Receiver Anonymity

In PEAPOD, any party can retrieve from the Server ciphertexts for any user, say, Bob. Confidentiality ensures that only Bob can decrypt the ciphertexts, so it does not matter if the Server gives away the re-encrypted ciphertexts to anyone unauthenticated or even anonymous. Consequently, anyone could have retrieved Bob’s ciphertexts, allowing Bob to deny that he requested the ciphertext. Therefore, PEAPOD supports a weak form of anonymity for receivers called plausible deniability, which means that no user can be implicated with overwhelming probability.

A detailed discussion on how receivers can protect their anonymity is outside the scope of this paper, but in general, users can access the server using an anonymizing network such as Tor [13]. This approach, however, opens up the possibility of DoS attacks where malicious users can bog the Server down with repeated requests for ciphertexts. Authentication of receivers can alleviate this problem, but most authentication schemes will destroy the property of plausible deniability. The system can employ deniable authentication [14, 22, 29, 26] to provide plausible deniability while maintaining DoS resistance. The server may also choose to employ authentication only when it is under DoS attack and forego authentication under normal operation.

Senders can post messages anonymously to the Server, and therefore the authenticity (the identity of the sender) of messages cannot be guaranteed unless the sender digitally signs the message. If the sender desires anonymity, they may choose to use a group signature scheme [10, 4, 5] to maintain anonymity (within the group) while guaranteeing to the receiver that the message was signed by someone in the group.

#### Dynamism

We assume a static set of attributes that remains unchanged throughout the lifetime of the system. It would be useful, however, to support the addition and removal of attributes, both to the system and to the individual users' attribute sets. While it is quite possible to adapt our system to support dynamism without losing confidentiality, maintaining policy privacy in a dynamic environment is not straightforward. For example, a user who does not satisfy a policy with respect to attribute set \( A \) might satisfy the same policy after \( A \) has been updated to some different attribute set \( A' \). By studying the difference between \( A \) and \( A' \), the user can possibly infer the nature of some attributes in the policy. One simple countermeasure would be to prevent users from retrieving two versions of the same ciphertext under different attribute sets. We plan to address the effects of dynamism on policy privacy and suitable countermeasures in future work.

#### Efficiency

It is worth examining the message expansion imposed by Full-PEAPOD as a consequence of achieving the various desirable properties on top of sole confidentiality. Let \( m \) be the number of established attributes and \( n \) be the maximum number of clauses in a policy. Also, let \( \lambda \) be the security parameter, which equals the bit-length of the size of the group \( \mathbb{Z}_p^* \). Observe that a ciphertext has a \( (2\lambda mn) \)-bit space overhead in addition to the symmetric encryption of the plaintext message. When the size of the plaintext message is large enough, the expansion is insignificant. For example, in the case when \( n = 8 \), \( m = 50 \), and \( \lambda = 1024 \), the overhead is 100 kilobytes. Both depositing a ciphertext and retrieving a ciphertext have space and time complexities of \( O(mn) \) if we ignore the symmetric encryption and decryption.

In particular, when Bob retrieves a message, the Server must perform \( O(m_B n) \) operations, where \( m_B \) is the number of attributes that Bob has been issued credentials for. In the worst case, \( m_B = m \), and the Server has to perform \( mn \) re-encryption and homomorphic encryption steps. We stress that Full-PEAPOD is very scalable in terms of the number of users in the system because the time and space complexities of all algorithms are independent of the number of users.

The main computational bottleneck is the ciphertext retrieval step at the Server. To handle a retrieval request, the Server has to do 3 modular exponentiations and 4 modular multiplications per attribute for each clause. On a reasonably fast server machine such as Sun Fire T2000 [33], this step takes less than 0.1 seconds if \( n = 8 \) and \( m = 50 \). Therefore, the system can handle at least 600 message retrievals per minute, which would be sufficient for organizational networks. For example, a college or a university could be easily serviced without noticeable delays. Furthermore, since the retrieval operation is naturally parallelizable, Field-Programmable Gate Arrays (FPGAs) can be used to significantly reduce the amount of time for retrieving messages. As FPGAs get faster and cheaper, one could fit several re-encryption engines onto a single FPGA.

In future work, we plan to address various tradeoffs between policy privacy and the system parameters to improve scalability with respect to the number of attributes \( n \) in the system. For example, users can pick a subset of attributes within which the policies are private. This would reduce the overhead and still provide sufficient policy privacy in systems with a large number of attributes.

### 5. Conclusions

We present PEAPOD, a system where publishers can disseminate information securely to multiple possible recipients using attribute-based policies. Unlike previous approaches that require online interaction or knowledge of the recipient’s identity or pseudonym beforehand, in our approach, messages are securely deposited at a server for offline retrieval by multiple possible recipients unknown to the sender. Users can decrypt these messages if and only if their credentials satisfy the publisher’s policy, and the publisher does not gain any knowledge of the users' "Hidden Credentials." Our system uses SELS as a building block to solve the problem of shared decryption keys between users with the same attribute and extends this technique with homomorphic encryption to provide message confidentiality and clausal policy-indistinguishability against all recipients, intended or not, and complete policy-indistinguishability against the server. In the context of the problem of securely publishing messages to multiple possible recipients, the policy privacy properties provided by PEAPOD surpass those provided by all previously known Hidden Credential schemes. Unlike previous approaches, PEAPOD is also able to efficiently support non-monotonic boolean policies, i.e., policies that contain negations of attributes.

### 6. Acknowledgments

We would like to thank Alexander Iliev, Chris Masone, Peter Johnson, Nikos Triandopoulos, and Nihal D’Cunha for their helpful comments.

### References

[1] M. Abe and K. Suzuki. M+1-st price auction using homomorphic encryption. In D. Naccache and P. Paillier, editors, Public Key Cryptography, volume 2274 of Lecture Notes in Computer Science, pages 115–124. Springer, 2002.

[2] A. Acquisti. Receipt-free homomorphic elections and write-in ballots. Cryptology ePrint Archive, Report 2004/105, 2004. http://eprint.iacr.org/.

[3] C. Adams and S. Farrell. Internet X.509 Public Key Infrastructure Certificate Management Protocols. Internet Engineering Task Force: RFC 2510, 1999.

[4] G. Ateniese, J. Camenisch, M. Joye, and G. Tsudik. A practical and provably secure coalition-resistant group signature scheme. In M. Bellare, editor, CRYPTO, volume 1880 of Lecture Notes in Computer Science, pages 255–270. Springer, 2000.

[5] M. Bellare, H. Shi, and C. Zhang. Foundations of group signatures: The case of dynamic groups. In A. Menezes, editor, CT-RSA, volume 3376 of Lecture Notes in Computer Science, pages 136–153. Springer, 2005.

[6] M. Blaze, G. Bleumer, and M. Strauss. Divertible protocols and atomic proxy cryptography. In EUROCRYPT, pages 127–144, 1998.

[7] T. Blum and C. Paar. High-radix Montgomery modular exponentiation on reconfigurable hardware. IEEE Trans. Comput., 50(7):759–764, 2001.

[8] D. Boneh and M. Franklin. Identity-based encryption from the Weil pairing. Lecture Notes in Computer Science, 2139:213–229, 2001.

[9] R. W. Bradshaw, J. E. Holt, and K. E. Seamons. Concealing complex policies with hidden credentials. In Eleventh ACM Conference on Computer and Communications Security, Washington, DC, pages 146–157, Oct 2004.

[10] D. Chaum and E. van Heyst. Group signatures. In EUROCRYPT, pages 257–265, 1991.

[11] X. Chen, B. Lee, and K. Kim. Receipt-free electronic auction schemes using homomorphic encryption. In J. I. Lim and D. H. Lee, editors, ICISC, volume 2971 of Lecture Notes in Computer Science, pages 259–273. Springer, 2003.

[12] I. Damgård and M. Jurik. A length-flexible threshold cryptosystem with applications. In R. Safavi-Naini and J. Seberry, editors, ACISP, volume 2727 of Lecture Notes in Computer Science, pages 350–364. Springer, 2003.

[13] R. Dingledine, N. Mathewson, and P. Syverson. Tor: The Second-Generation Onion Router. In Usenix Security, Aug 2004.