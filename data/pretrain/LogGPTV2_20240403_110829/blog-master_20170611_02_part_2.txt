postgres=# alter sequence test_id_seq cache 10000;  
ALTER SEQUENCE  
vi test.sql  
insert into test (info) values ('test');  
pgbench -M prepared -n -r -P 1 -f ./test.sql -c 400 -j 400 -t 2500  
```  
线性相关性，直线下降  
```  
postgres=# create index idx_test_id on test using brin(id);  
CREATE INDEX  
postgres=# analyze test;  
ANALYZE  
postgres=# select correlation from pg_stats where tablename='test' and attname='id';  
 correlation   
-------------  
    0.571033  
(1 row)  
-- 偏差非常明显  
postgres=# select *,id-rn from (select ctid,id,row_number() over(order by ctid) rn from test) t where id<>rn;  
    ctid    |   id    |   rn    | ?column?   
------------+---------+---------+----------  
 (0,6)      |   10001 |       6 |     9995  
 (0,7)      |       6 |       7 |       -1  
 (0,8)      |       7 |       8 |       -1  
 (0,9)      |   10002 |       9 |     9993  
 (0,10)     |   20001 |      10 |    19991  
 (0,11)     |       8 |      11 |       -3  
 (0,12)     |   10003 |      12 |     9991  
 (0,13)     |       9 |      13 |       -4  
 (0,14)     |   20002 |      14 |    19988  
 (0,15)     |   10004 |      15 |     9989  
 (0,16)     |      10 |      16 |       -6  
 (0,17)     |   20003 |      17 |    19986  
 (0,18)     |   10005 |      18 |     9987  
 (0,19)     |      11 |      19 |       -8  
 (0,20)     |   20004 |      20 |    19984  
 (0,21)     |   10006 |      21 |     9985  
 (0,22)     |      12 |      22 |      -10  
 (0,23)     |   20005 |      23 |    19982  
 (0,24)     |   10007 |      24 |     9983  
 (0,25)     |      13 |      25 |      -12  
 (0,26)     |   20006 |      26 |    19980  
 (0,27)     |      14 |      27 |      -13  
 (0,28)     |   20007 |      28 |    19979  
 (0,29)     |   10008 |      29 |     9979  
 (0,30)     |      15 |      30 |      -15  
 (0,31)     |   20008 |      31 |    19977  
 (0,32)     |   10009 |      32 |     9977  
 (0,33)     |   20009 |      33 |    19976  
 (0,34)     |      16 |      34 |      -18  
 (0,35)     |   30001 |      35 |    29966  
 (0,36)     |   20010 |      36 |    19974  
 (0,37)     |   10010 |      37 |     9973  
 (0,38)     |      17 |      38 |      -21  
 (0,39)     |   20011 |      39 |    19972  
 (0,40)     |   20012 |      40 |    19972  
 (0,41)     |   10011 |      41 |     9970  
 (0,42)     |      18 |      42 |      -24  
 (0,43)     |   30002 |      43 |    29959  
 (0,44)     |   20013 |      44 |    19969  
 (0,45)     |      19 |      45 |      -26  
 (0,46)     |   10012 |      46 |     9966  
 (0,47)     |   30003 |      47 |    29956  
 (0,48)     |   20014 |      48 |    19966  
 (0,49)     |      20 |      49 |      -29  
 (0,50)     |   30004 |      50 |    29954  
 (0,51)     |   10013 |      51 |     9962  
 (0,52)     |   20015 |      52 |    19963  
 (0,53)     |      21 |      53 |      -32  
 (0,54)     |   30005 |      54 |    29951  
 (0,55)     |   10014 |      55 |     9959  
 (0,56)     |   20016 |      56 |    19960  
 (0,57)     |      22 |      57 |      -35  
 (0,58)     |   20017 |      58 |    19959  
```  
BRIN性能  
```  
postgres=# explain (analyze,verbose,timing,costs,buffers) select * from test where id between 1000 and 10000;  
                                                         QUERY PLAN                                                           
----------------------------------------------------------------------------------------------------------------------------  
 Bitmap Heap Scan on public.test  (cost=5.11..6244.85 rows=2222 width=13) (actual time=7.104..43.755 rows=1501 loops=1)  
   Output: id, info  
   Recheck Cond: ((test.id >= 1000) AND (test.id   Bitmap Index Scan on idx_test_id  (cost=0.00..4.56 rows=38916 width=0) (actual time=0.071..0.071 rows=24320 loops=1)  
         Index Cond: ((test.id >= 1000) AND (test.id <= 10000))  
         Buffers: shared hit=8  
 Planning time: 0.128 ms  
 Execution time: 43.867 ms  
(11 rows)  
```  
## 并发时序线性优化  
1、使用单步序列。单步序列不会因为并发增加而导致离散度增加。  
2、使用系统时间字段，系统时间与单步序列效果一样，即使并发写入，也不会导致离散度增加。  
使用连续自增值的字段，创建BRIN索引就是很靠谱的。  
#### [PostgreSQL 许愿链接](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216")
您的愿望将传达给PG kernel hacker、数据库厂商等, 帮助提高数据库产品质量和功能, 说不定下一个PG版本就有您提出的功能点. 针对非常好的提议，奖励限量版PG文化衫、纪念品、贴纸、PG热门书籍等，奖品丰富，快来许愿。[开不开森](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216").  
#### [9.9元购买3个月阿里云RDS PostgreSQL实例](https://www.aliyun.com/database/postgresqlactivity "57258f76c37864c6e6d23383d05714ea")
#### [PostgreSQL 解决方案集合](https://yq.aliyun.com/topic/118 "40cff096e9ed7122c512b35d8561d9c8")
#### [德哥 / digoal's github - 公益是一辈子的事.](https://github.com/digoal/blog/blob/master/README.md "22709685feb7cab07d30f30387f0a9ae")
![digoal's wechat](../pic/digoal_weixin.jpg "f7ad92eeba24523fd47a6e1a0e691b59")
#### [PolarDB 学习图谱: 训练营、培训认证、在线互动实验、解决方案、生态合作、写心得拿奖品](https://www.aliyun.com/database/openpolardb/activity "8642f60e04ed0c814bf9cb9677976bd4")
#### [购买PolarDB云服务折扣活动进行中, 55元起](https://www.aliyun.com/activity/new/polardb-yunparter?userCode=bsb3t4al "e0495c413bedacabb75ff1e880be465a")
#### [About 德哥](https://github.com/digoal/blog/blob/master/me/readme.md "a37735981e7704886ffd590565582dd0")