for i = 1 → m do
Calculate αi for Yi using Eq. 4–Eq. 6 ;
end
Get incorporated node representations Y(cid:9) =
Train SVM using Y(cid:9)
Dt ;
for n = 1 → |De | do
Generate the label fn using trained SVM ;
m
i =1
(αi × Yi ) ;
end
return f;
ICSD: An Automatic System for Insecure Code Snippet Detection
ACSAC ’18, December 3–7, 2018, San Juan, PR, USA
4 EXPERIMENTAL RESULTS AND ANALYSIS
In this section, we conduct four sets of experimental studies using
the data collected from Stack Overflow to fully evaluate the perfor-
mance of our developed system ICSD which integrates the above
proposed method in insecure code snippet detection.
4.1 Experimental Setup
We develop a set of crawling tools to collect the data from Stack
Overflow. As stated in Section 3.1, we consider Java programming
language for Android app as a case study to evaluate our developed
system. Note that it’s also applicable to other kinds of programming
languages in Stack Overflow. We use our developed crawling tools
to collect users’ profiles, question threads, answer threads, and
code snippets in Stack Overflow in a period of time. By the date,
we have collected 429,523 question threats and 623,746 answer
threats posted by 213,560 users including 737,215 code snippets,
through March 2010 to May 2018. To obtain the ground truth for
the evaluation of different detection methods, we need to prelabel
a fraction of code snippets (i.e., either secure or insecure). We first
categorize code security risks and vulnerabilities for Android apps
into six categories: (1) Android Manifest configuration, (2) WebView
component, (3) data security, (4) file directory traversal, (5) implicit
intents, and (6) security checking; and then we leverage our domain
expertise and follow the principles such as least permission request,
correct usage of HTTPS and TLS for networking, secure inter-
component communication, secure storage to manually label a
filtered set of 20,137 code snippets (i.e., 9,054 code snippets are
labeled as insecure while 11,083 are secure). After feature extraction
and based on the designed network schema, the constructed HIN
has 80,405 nodes (i.e., 20,137 nodes with type of code snippet, 24,286
nodes with type of answer, 13,924 nodes with type of question,
21,471 with type of user, 94 with type of badges, and 493 with
type of selected keywords) and 592,082 edges including relations
of R1-R7. We use the performance indices shown in Table 1 to
quantitatively validate the effectiveness of different methods in
insecure code snippet detection.
Table 1: Performance indices of code snippet detection
Indices
Description
# of code snippets correctly classified as insecure
TP
# of code snippets correctly classified as secure
TN
# of code snippets mistakenly classified as insecure
FP
# of insecure mistakenly classified as secure
FN
TP/(TP + FP)
Precision
Recall/TPR TP/(TP + FN)
(TP + TN)/(TP + TN + FP + FN)
ACC
2 × Precision × Recall/(Precision + Recall)
F1
4.2 snippet2vec based on Different Sets of
Meta-path Schemes
In this set of experiments, based on the dataset described in Sec-
tion 4.1, we first evaluate the performance of different kinds of
relatedness over code snippets depicted by different sets of meta-
path schemes. In the experiments, given a specific set of meta-path
schemes, we use snippet2vec to learn the latent representations of
the nodes (i.e., code snippets) in the HIN, which are then fed to SVM
to build the classification model for insecure code snippet detection.
For SVM, we use LibSVM and the penalty is empirically set to be
10 while other parameters are set by default. As described in Sec-
tion 3.4, we generate four sets of meta-path schemes (denoted as S1,
S2, S3, and S4) for snippet2vec to learn the node representations in
the HIN. We conduct 10-fold cross validations for evaluation. The
performances of four different sets of meta-path schemes (i.e., S1-
S4) in comparison with nine individual meta-paths (i.e., PID1–PID9)
in insecure code snippet detection are shown in Table 2.
Table 2: Detection Results of different meta-paths
F1
ID Meta-paths included Precision Recall ACC
S1
S2
S3
S4
S′
S′
S′
S′
S′
S′
S′
S′
S′
0.8887 0.8883 0.8975
0.8678 0.8682 0.8787
0.8834 0.8834 0.8930
0.8709 0.8710 0.8814
0.8561 0.8562 0.8676
0.7988 0.8018 0.8160
0.7657 0.7668 0.7833
0.8179 0.8180 0.8318
0.8001 0.8006 0.8153
0.8119 0.8145 0.8281
0.7708 0.7748 0.7903
0.7642 0.7664 0.7826
0.7518 0.7532 0.7703
0.9065
0.8899
0.9028
0.8922
0.8795
0.8340
0.8017
0.8463
0.8312
0.8449
0.8108
0.8020
0.7897
(PID1,PID2,PID6)
(PID1,PID3,PID7)
(PID1,PID4,PID8)
(PID1,PID5,PID9)
5
6
7
8
9
10
11
12
13
(PID1)
(PID2)
(PID3)
(PID4)
(PID5)
(PID6)
(PID7)
(PID8)
(PID9)
From Table 2, we can see that different sets of meta-path schemes
indeed show different performances in insecure code snippet detec-
tion, since each of them represents specific semantics in insecure
code snippet detection. We also observe that: (1) PID1 outperforms
the other individual meta-paths (i.e., PID2–PID9), which indicates
that the semantics of this meta-path reflect the problem of insecure
code snippet detection better than the others. (2) The meta-paths
of PID2, PID4, PID6, and PID8 perform better than PID3, PID5, PID7,
and PID9 respectively; the reason behind this is that the code snip-
pets posted in the answer threads are more likely to be reused by
the developers than the ones posted in question threads, and thus
they have closer connections. (3) Obviously, S1, S2, S3, and S4
utilizing different meta-paths built from HIN are more expressive
than each individual meta-path (i.e., PID1–PID9) in depicting the
code snippets in Stack Overflow and thus achieve better detection
performance. It will be interested to see the detection performance
if different sets of meta-paths are further aggregated. This will be
evaluated in the next set of experiments.
4.3 Comparisons with Different Network
Representation Learning Models
In this set of experiments, we evaluate our developed system ICSD
integrating our proposed method described in Section 3 by com-
parisons with several network representation learning methods: (1)
ACSAC ’18, December 3–7, 2018, San Juan, PR, USA
Y. Ye et al.
Table 3: Comparisons with other network representation learning methods in insecure code snippet detection
Metric
ACC
F1
Method
DeepWalk
LINE
metapath2vec
ICSD
DeepWalk
LINE
metapath2vec
ICSD
10%
0.6085
0.6347
0.7772
0.7973
0.6308
0.6569
0.7932
0.8121
20%
0.6409
0.6559
0.7839
0.8133
0.6618
0.6762
0.7990
0.8270
30%
0.6550
0.6847
0.8197
0.8384
0.6764
0.7047
0.8332
0.8508
40%
0.6674
0.7075
0.8366
0.8566
0.6875
0.7261
0.8493
0.8680
50%
0.6810
0.7268
0.8490
0.8771
0.7006
0.7451
0.8609
0.8871
60%
0.6958
0.7364
0.8522
0.8835
0.7159
0.7547
0.8633
0.8930
70%
0.7148
0.7475
0.8663
0.8953
0.7329
0.7644
0.8765
0.9036
80%
0.7269
0.7635
0.8782
0.9068
0.7448
0.7798
0.8878
0.9146
90%
0.7279
0.7732
0.8826
0.9123
0.7461
0.7892
0.8921
0.9197
DeepWalk [34] and LINE [43] which are homogeneous network em-
bedding methods; and (2) metapath2vec [13] which is a HIN embed-
ding model. For DeepWalk and LINE, we ignore the heterogeneous
property of HIN and directly feed the HIN for representation learn-
ing; in metapath2vec, a walk path will be generated only based on a
single meta-path scheme; while in our proposed snippet2vec, a walk
path will be guided by a set of different meta-path schemes. The pa-
rameter settings used for snippet2vec are in line with typical values
used for the baselines: vector dimension d = 200 (LINE: 200 for each
order (1st- and 2nd-order)), walks per node r = 10, walk length
l = 80, and window size w = 10. To facilitate the comparisons,
we use the experimental procedure as in [13, 34, 43]: we randomly
select a portion of labeled code snippets described in Section 4.1
(ranging from 10% to 90%) for training and the remaining ones for
testing. For all the baselines, the SVM is used as the classification
model; for ICSD, based on the four given sets of meta-path schemes,
it will generate four different kinds of node representations using
snippet2vec and then use multi-view fusion classifier proposed in
Section 3.4 to train the classification model. Table 3 illustrates the
detection results of different network representation learning mod-
els. From Table 3, we can see that ICSD integrating the proposed
snippet2vec model consistently and significantly outperforms all
baselines for insecure code snippet detection in terms of ACC and
F1. That is to say, snippet2vec learns significantly better code snippet
representation than current state-of-the-art methods. The success
of snippet2vec lies in the proper consideration and accommodation
of the heterogeneous property of HIN (i.e., the multiple types of
nodes and relations), and the advantage of random walk guided
by different meta-paths for sampling the node paths. Furthermore,
from Table 2 and Table 3, we can also observe that using the multi-
view fusion classifier proposed in Section 3.4 to aggregate different
node representations learned based on different sets of meta-graph
schemes can significantly improve the detection performance.
4.4 Comparisons with Traditional Machine
Learning Methods
In this set of experiments, based on the dataset described in Sec-
tion 4.1, we compare ICSD which integrates our proposed method
with other traditional machine learning methods by 10-fold cross
validations. For these methods, we construct three types of fea-
tures: f–1: content-based features (i.e., keywords extracted from
code snippets described in Section 3.1); f–2: two relation-based
features associated with code snippets (i.e., R1 and R2 introduced
in Section 3.1); f–3: augmented features of content-based features
and R1–R2. Based on these features, we consider two typical classi-
fication models, i.e., Naive Bayes (NB) and SVM. The experimental
results are illustrated in Table 4. From the results we can observe
that feature engineering (f-3: concatenation of different features
altogether) helps the performance of machine learning, but ICSD
added the knowledge represented as HIN significantly outperforms
other baselines. This again demonstrates that, to detect the insecure
code snippets, ICSD utilizing both code content and social coding
properties represented by the HIN is able to build the higher-level
semantic and structural connection between code snippets with a
more expressive and comprehensive view and thus achieves better
detection performance.
Table 4: Comparisons of other machine learning methods
Metric
f-1
NB
f-2
f-3
f-1
SVM
f-2