### 515
**Authorized licensed use limited to: Tsinghua University. Downloaded on March 20, 2021 at 09:58:41 UTC from IEEE Xplore. Restrictions apply.**

Extended Hamming codes can be replaced by nonlinear extended Vasil’ev SEC-DED (Single Error Correction - Double Error Detection) codes, as described in Section 4, resulting in improved reliability in the presence of multi-bit distortions. The rest of the paper is organized as follows:

- **Section 2**: Summarizes previous work on error-correcting codes for memory protection.
- **Section 3**: Provides definitions of robust codes.
- **Section 4**: Describes the construction methods for robust and partially robust codes with minimum distance. It compares the error detection kernels of different codes and explains why the extended Vasil’ev code was selected.
- **Section 5**: Details the architecture utilizing extended Vasil’ev codes and presents the error-correcting algorithm. The hardware overhead and error-correcting and detecting properties of the extended Vasil’ev code are compared with those of the extended Hamming code to demonstrate the advantage of the proposed approach.

### 2. Previous Work
Since the basic construction of SEC-DED codes was presented by Hamming in 1950 [13], several modifications have been proposed. In [14], a class of optimal minimum odd-weight-column SEC-DED codes was constructed for better performance, cost, and reliability. To further simplify encoding and decoding complexity, the author in [22] proposed a coding technique requiring fewer 1’s in the parity check matrix than the code presented in [14]. In [2], a hardware-efficient method was proposed to construct SEC-DED-AUED (All Unidirectional Error Detecting) systematic codes that can also detect all unidirectional errors. For protecting byte-oriented memories, SEC-DED-SBD (Single Byte Error Detecting) codes were proposed in [30], [4], and [6]. These codes can detect all single-byte errors. SEC-DED-SBD codes that can also correct any odd number of erroneous bits per byte were proposed in [26].

To enhance the error correction capability of SEC-DED codes, the author in [7] constructed a single-error-correcting, double-error-detecting, double-adjacent-error-correcting (SEC-DED-DAEC) code by selectively avoiding certain types of linear dependencies in the parity check matrix. These codes use the same number of redundant bits and similar overhead to other SEC-DED codes and have the advantage of correcting all adjacent double errors. In [5], the author constructed single-byte-error-correcting, double-byte-error-detecting codes (SBC-DBD) which provide complete single-byte error correction capabilities. In [21], a double-error-correcting and triple-error-detecting code was proposed to correct all double-bit errors. The well-known Reed-Solomon code, as another example, was utilized in the Hubble Space Telescope to protect 16 Mbit DRAMs manufactured by IBM [36].

All the codes mentioned above are classical linear codes. They concentrate their error detection and correction capabilities on a specific type of error (e.g., errors with small multiplicities or belonging to the same byte). The reliability of the system cannot be guaranteed when the MBU (Multi-Bit Upset) rate is high. Robust codes have been proposed as a solution to the limitations of minimum distance linear error-detecting codes in the presence of multi-bit errors. Nonlinear robust codes are designed to provide equal protection against all errors, thereby eliminating possible weak areas in the protection. Several variants of robust codes have been proposed, allowing trade-offs in terms of robustness and hardware overhead for many architectures. Robust, partially robust, and minimum distance partially robust codes have been described in [16], [17], and [10].

Robust and partially robust codes with a minimum distance larger than 2 can correct errors with small multiplicities and are promising alternatives to linear error-correcting codes in applications where protection against multi-bit errors is important. These codes have a smaller number of undetectable and miscorrected multi-bit errors than traditional linear error-correcting codes (Sections 4 and 5.2). We will overview several constructions for these codes in Section 4.

### 3. Definitions
Throughout the paper, we denote by “+” the component-wise addition of binary vectors. We focused the analysis on the number of errors that are undetected/miscorrected by all codewords to show the worst-case error detection/correction properties of the codes. Analysis of these properties allows a comparison of the codes for the most problematic errors, such as repeating errors (Section 5.3) caused by permanent faults.

**Definition 3.1 (Kernels of the Code)**: For any error-correcting code \( C \subseteq \text{GF}(2^n) \), the detection kernel \( K_d \) is the set of errors \( e \in \text{GF}(2^n) \) that are masked for all codewords.
\[ K_d = \{ e \mid e + c \in C, \forall c \in C \} \]
It is easy to show that \( K_d \) is a linear subspace of \( C \), and if \( C \) is linear, then \( K_d = C \).

Denote by \( A \) the correction algorithm for code \( C \) and \( E \) the set of errors that \( A \) attempts to correct. The correction kernel \( K_c \) is the set of errors \( e \notin E \) which have the same result of \( A \) as some \( e' \in E \) for all codewords.
\[ K_c = \{ e \mid e \notin E, \forall c \in C, \exists e' \in E, A(e, c) = A(e', c) \} \]

Errors that are undetected/miscorrected by some but not all of the codewords are called conditionally detectable/miscorrected errors. The detection kernels of different codes will be analyzed and compared in this section. The correction kernel, which is related to the error correction algorithms of the code, will be discussed in Section 5.2.

**Example 3.1 (Kernels of Linear Hamming Codes)**: A \((n, n - \lfloor \log_2(n+1) \rfloor, 3)\) linear Hamming code \( C \subseteq \text{GF}(2^n) \) has a minimum distance of 3 and can correct all single-bit errors. Denote by \( H \) the parity check matrix of \( C \). An error \( e \) is undetectable if and only if \( e \) is a codeword (\( He = 0 \)). Therefore, the detection kernel \( K_d \) of a Hamming code is \( C \) itself. For single error-correcting codes, \( E = \{ e \mid \| e \| = 1 \} \), where \( \| e \| \) is the number of ones in \( e \). A multi-bit error \( e \) with \( \| e \| > 1 \) will be miscorrected if and only if it has the same syndrome as some single-bit error. So, the correction kernel of the Hamming code is \( \{ e \mid He = He_i \} \), where \( e_i \) is an error vector with only one 1. Clearly, \( K_d \) and \( K_c \) are disjoint. For perfect linear Hamming codes, \( K_d \cup K_c \cup E = \text{GF}(2^n) \).

A main characteristic of traditional linear error-detecting codes is that they concentrate their error-detecting power on a small subset of errors which are assumed to be the most likely to occur. Typically, such codes concentrate their error detection on errors of small multiplicity. They are designed to guarantee detection of all errors with a multiplicity less than \( d \). Error detection beyond the minimum distance of the code is typically not part of the design criteria and can be unpredictable and ineffective. While for some classes of errors the codes provide 100% protection, for a very large class of errors, linear codes offer no protection for all messages. In other words, traditional linear error-detecting codes have large \( K_d \).

Robust codes, on the other hand, are designed to provide a guaranteed level of detection against all errors. These codes are characterized by their error-masking probability \( Q(e) \), which is the fraction of codewords that mask each error, assuming that all codewords are equally probable.
\[ Q(e) = \frac{| \{ c \mid c \in C, c + e \in C \} |}{|C|} \]

**Definition 3.2**: The code \( C \) is robust if \( \max_{e \neq 0} Q(e) < 1 \) or equivalently, the detection kernel of the code contains only the zero vector \( K_d = \{ 0 \} \).

A possible variant of the traditional robust codes is to include a minimum distance in the design criteria.

**Definition 3.3**: Let \( \| e \| \) denote the multiplicity of an error \( e \). A robust code where \( Q(e) = 0 \) for all errors where \( \| e \| < d \) is a minimum distance robust code. Minimum distance robust codes have no undetectable errors, and the worst-case error-masking probability is bounded and predictable. Moreover, a larger minimum distance makes them able to guarantee 100% detection for a predefined class of errors, so that they can be useful for providing the highest protection against the most likely or most dangerous threats while maintaining a detection guarantee in case of unexpected behavior or attack.

For some applications, the error characteristics of robust codes can be considered too pessimistic. Variants of robust codes that fill the gap between the optimistic linear codes and pessimistic robust codes are possible. Partially robust codes and minimum distance partially robust codes allow for a trade-off between robustness, encoding complexity, and overhead.

**Definition 3.4**: A systematic \((n, k, d)\) code with a detection kernel smaller than \( 2^k \) is a partially robust code. If the code also has a minimum distance greater than one, it is referred to as a minimum distance partially robust code. Partially robust codes reduce the number of undetectable errors while preserving some structures of linear codes, which can be exploited to build efficient prediction hardware that generates redundant bits of a message. Like linear codes, partially robust codes still have undetectable errors (hence they are not completely robust). The number of undetectable errors is reduced by many orders of magnitude. For practical partially robust constructions, the number of undetectable errors can be reduced from \( 2^k \) to \( 2^{k-r} \), \( r = n - k \), compared to a linear \((n, k, d)\) code [19]. The probability of masking for the errors that are detectable is bounded as in robust codes.

For memory applications, we are mostly interested in minimum distance robust or partially robust codes that can be used for error corrections. Compared with traditional linear error-correcting codes, the advantage of these codes is that they can provide better protection against multi-bit errors due to the fact that they have fewer undetectable/miscorrected errors. Several constructions and examples of minimum distance robust/partially robust codes will be described in the next section.

### 4. Constructions of Codes

#### 4.1 Minimum Distance Robust Codes
Systematic robust and partially robust codes are highly related to nonlinear functions. The nonlinearity of a function \( f: \text{GF}(2^k) \to \text{GF}(2^s) \) can be measured using derivatives:
\[ D_a f(x) = f(x + a) + f(x) \]
The nonlinearity measure can be defined by (from [3]):
\[ P_f = \max_{0 \neq a \in \text{GF}(2^k)} \max_{b \in \text{GF}(2^s)} \Pr(D_a f(x) = b) \]
where \( \Pr(E) \) denotes the probability of occurrence of event \( E \). The smaller the value of \( P_f \), the higher the corresponding nonlinearity of \( f \). When \( P_f = 2^{-s} \), \( f \) is a perfect nonlinear function.

The simplest way to construct minimum distance robust codes is to append extra nonlinear redundant bits to the codewords of an existing code with a given distance \( d \).

**Theorem 4.1** [20]: Let \( V \) be a systematic \((n, k, d)\) code and let \( f: \text{GF}(2^k) \to \text{GF}(2^s) \) be a nonlinear function with nonlinearity \( P_f \). The code:
\[ C = \{ (x, \varphi(x), f(x)) \mid (x, \varphi(x)) \in V \} \]
where \( \varphi \) is the encoding function for code \( V \), is an \((n+s, k, d)\) minimum distance robust code where \( \max_{e \neq 0} Q(e) \leq P_f \).

**Example 4.1 (Shortened Robust Hamming)**: Let \( C = \{ (x, Px) \} \) be a \((38, 32, 3)\) shortened Hamming code, where \( x \in \text{GF}(2^{32}) \), \( P \) is a \( (6 \times 32) \) encoding matrix, and \( Px \in \text{GF}(2^6) \). Let \( f: \text{GF}(2^{32}) \to \text{GF}(2) \) be a perfect nonlinear function defined by:
\[ f(x = (x_1, x_2, \ldots, x_{32})) = x_1 x_2 + x_3 x_4 + \ldots + x_{31} x_{32} \]
(non-repetitive quadratic function). Then the code \( C = \{ (x, Px, f(x)) \} \) is a robust code with a minimum distance of 3. For this code, \( Q(e) = 0 \) when \( \| e \| < 3 \) and \( Q(e) \leq 0.5 \) when \( \| e \| \geq 3 \). The shortened robust Hamming code has no undetectable errors. The only element in \( K_d \) is the zero vector. It is able to correct any single-bit error and provide nearly equal protection to most of the multi-bit errors. However, the advantage of the shortened robust Hamming code comes at the price of one more redundant bit. The code has only a minimum distance of 3, although it needs the same number of redundant bits as \((39, 32, 4)\) SEC-DED codes, which have a minimum distance of 4.

#### 4.2 Minimum Distance Partially Robust Codes
Many classical constructions of nonlinear codes are partially robust minimum distance codes. They have a minimum distance larger than 1 and have much fewer undetectable errors than linear codes. Such codes can even be perfect with respect to the classical Hamming bound. The first nonlinear perfect code was constructed by Vasil’ev in [35] and was generalized by Mollard in [24]. We first review the basic construction of the Vasil’ev code.

**Theorem 4.2 (Vasil’ev Code [35])**: For \( x \in \text{GF}(2^m) \), let \( p(x) = \| x \| \mod 2 \). Let \( V \) be a perfect (not necessarily linear) Hamming code of length \( m = 2^r - 1 \) with \( k_V = m - r \) information bits. Let \( f: V \to \{0, 1\} \) be an arbitrary nonlinear mapping such that \( f(0) = 0 \) and \( f(v) + f(v') \neq f(v + v') \) for some \( v, v' \in V \). The code \( C \) defined by:
\[ C = \{ (x, x + v, p(x) + f(v)) \mid x \in \text{GF}(2^m), v \in V \} \]
(where \( + \) is over \( \text{GF}(2) \)) is a \((2m + 1, 2m - r, 3)\) perfect nonlinear Hamming code.

**Remark 4.1**: We note that the above construction can be generalized to generate robust codes with any given distance \( d \). Denote by \( P \) a binary matrix. The code:
\[ C = \{ (x, x + v, Px + f(v)) \mid x \in \text{GF}(2^m), v \in V \} \]
is a nonlinear code with minimum distance \( d \) if \( V \) has distance \( d \) and the code composed of all vectors \( (x, Px) \) has distance \( d - 1 \). Vasil’ev code is a special case where \( (x, Px) \) is a linear parity code with minimum distance 2. Some partially robust codes as good as BCH codes in terms of the number of redundant bits can be generated based on this construction.

**Theorem 4.3** [20]: Vasil’ev code is a \((2m + 1, 2m - r, 3)\) partially robust code with \( |K_d| = 2^m \) and \( \max_{e \notin K_d} Q(e) = P_f \), where \( P_f \) is the nonlinearity of \( f \), \( K_d \) is the detection kernel of the code, and \( m = 2^r - 1 \).

Vasil’ev codes are perfect single-error-correcting codes and have the same parameters as linear Hamming codes. The basic construction of Vasil’ev code can be further generalized as follows. The theorem can be proved in a similar way to the proof of Theorem 4.2 presented in [20].

**Theorem 4.4 (Shortened Vasil’ev Code)**: For \( x \in \text{GF}(2^a) \), let \( p(x) = \| x \| \mod 2 \). Let \( V \) be a \((m, k_V, 3)\) (not necessarily linear) Hamming code with \( r = m - k_V \) redundant bits. Without loss of generality, assume that the first \( k_V \) bits in any codeword of \( V \) are information bits. Denote by \( v = (y, z) \), \( y \in \text{GF}(2^{k_V}) \), \( z \in \text{GF}(2^r) \) the codewords of \( V \). Let \( f: \text{GF}(2^{k_V}) \to \{0, 1\} \) be an arbitrary mapping such that \( f(0) = 0 \) and \( f(y) + f(y') \neq f(y + y') \) for some \( y, y' \in \text{GF}(2^{k_V}) \). The code \( C \) defined by:
\[ C = \{ (x, (x, 0) + v, p(x) + f(y)) \}, \]
where \( x \in \text{GF}(2^a) \), \( 0 \in \text{GF}(2^{m-a}) \), \( 0 < a \leq m \), \( v \in V \) is an \((a + m + 1, a + k_V, 3)\) code with \( |K_d| = 2^a \), and \( \max_{e \notin K_d} Q(e) = P_f \). Adding one more overall linear parity bit (exclusive-or of all other bits) to \( C \) will result in a nonlinear SEC-DED code with the same \( K_d \) and \( \max_{e \notin K_d} Q(e) \) as \( C \) and minimum distance 4, which is called the extended Vasil’ev code.

The significance of Theorem 4.4 is twofold. First, it can generate robust SEC-DED codes of arbitrary lengths. These codes have the same number of redundant bits as the best linear codes.