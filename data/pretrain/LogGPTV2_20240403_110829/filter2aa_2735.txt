# Improving Web Vulnerability Scanning
## Daniel Zulla

### 1. Introduction
Hello, everyone!

- My name is Dan, and this is my first year at DEFCON.
- I work in programming and security startups.
- I also conduct penetration testing.

### 2. More Introduction
- Today, I will discuss web vulnerability scanning, with a focus on the cloud and network security.
- I will include several demonstrations to illustrate key points.
- Thank you for joining me, and I hope you enjoy the presentation.

### 3. Some Facts
- There are numerous web vulnerability scanners, fuzzers, and penetration testing tools available.
- While some of these tools are effective, many have limitations.
- A common issue is that most of these tools do not attack web applications at the application layer; they primarily fuzz HTTP and sometimes perform injection attacks.

### 4. Additional Facts
- The fundamental design of web scanners has remained largely unchanged for over a decade.
- However, the web itself has evolved significantly.
- This mismatch suggests a need for updated approaches.

### 5. Software Architecture
- **Current Structure:**
  - **Core Components:**
    - Output Engine
    - HTTP Library
    - Multithreading/Forking
    - Plugins
  - **Vulnerabilities:**
    - RXSS (Reflected Cross-Site Scripting)
    - PXSS (Persistent Cross-Site Scripting)
    - SQL (SQL Injection)
    - BSQLI (Blind SQL Injection)
    - LFI (Local File Inclusion)
    - RFI (Remote File Inclusion)
    - EVAL (Code Evaluation)
    - OSC (Operating System Command Execution)

### 6. Challenges and Perspectives
#### From a Penetration Tester's View:
- JavaScript/Ajax-rich applications are often unsupported.
- Authenticated scanning remains challenging and unreliable.
- Exploitation techniques are generally subpar.
- Toolchains are often used due to the unpredictability of individual scanner effectiveness.

#### From a Developer's View:
- HTTP libraries lack support for JavaScript, making them unsuitable for modern web applications.
- Web logins are not standardized, complicating detection.
- Significant time is spent addressing encoding issues, malformed HTML, redirects, and binary content.
- False positives are often preferred over false negatives.

### 7. My Perspective
- Both perspectives highlight valid issues.
- The web is complex, with many sites deviating from RFC standards.
- Modern URL structures differ from traditional query strings, making it difficult for scanners to identify dynamic components.
- Fuzzing HTTP is important but does not equate to effective web vulnerability scanning.
- Handling JavaScript, images, and other dynamic content is a significant challenge.

### 8. Web 2.0 and Beyond
- Security professionals should focus on their core responsibilities rather than dealing with complex web content.
- Current efforts are disproportionately focused on crawling and less on actual payloads.
- **Solution:** Utilize an open-source tool like WebKit, which is adept at handling broken and unpredictable web content.

### 9. WebKit Capabilities
- **Supported Features:**
  - JavaScript
  - JavaScript events
  - Redirects
  - Flash
  - Images
  - WebSockets
  - WebGL
  - CSS rendering
  - Binary downloads
  - Broken HTML/CSS
  - Performance
  - Forking/multiprocessing

### 10. Proposed Software Architecture
- **Core Components:**
  - Reporting Engine
  - HTTP Library
  - Exploitation Engine
  - Front-End
- **Changes and Improvements:**
  - Replace the HTTP library with a WebKit engine.
  - Reduce code complexity.
  - Ensure 100% support for JavaScript, Ajax, and other web technologies.
  - Simulate human user behavior.
  - Enhance CSS rendering capabilities.

### 11. Scalability
- **Challenges:**
  - WebKit is slower compared to plain HTTP communication.
  - Downloading images and executing JavaScript can be time-consuming.
  - Flash content further slows down the process.
- **Solution:**
  - Use a preforking TCP server to manage multiple processes efficiently.
  - Enable simultaneous downloads and improve performance through multiprocessing.

### 12. Missing Pieces
- **Key Areas:**
  - Authentication
  - Exploitation and privilege escalation
  - Geographically distributed scanning
  - Reporting

### 13. Mastering Authentication
- **Challenges:**
  - Lack of standardized web logins.
  - Diverse access control implementations.
- **Detection Methods:**
  - Identify login forms using attributes and geometry.
  - Use strategies to handle authentication, including error message verification and logout functionality.

### 14. Exploitation and Privilege Escalation
- **Scope:**
  - Beyond injection vulnerabilities.
  - Detect and exploit privilege escalation in multi-user systems.
- **Demo:**
  - Demonstrate privilege escalation in a multi-user system.

### 15. Geographically Distributed Scanning
- **Scenario:**
  - Backend logging IP addresses and User-Agent strings.
  - Vulnerable log entry creation function.
- **Solution:**
  - Use cloud services to generate new IP addresses and bypass limitations.
- **Demo:**
  - Show how tools like SQLMap and w3af can be enhanced with cloud-based scanning.

### 16. Further Research and Additional Ideas
- **Areas for Exploration:**
  - Automated bypassing of country-specific restrictions.
  - Parsing and interpreting error messages using tools like Wolfram Alpha.
  - Integrating Bloom filters.
  - Implementing additional strategies for more comprehensive scanning.

### 17. Live Demos
- **Demonstrations:**
  - Logical layer beyond authentication (e.g., payment, search, sorting).
  - Error message interpretation.
  - Pivoting on penetrated hosts.
  - Comprehensive reporting.

### 18. Conclusion
Thank you for your attention! I hope this presentation provided valuable insights into improving web vulnerability scanning.