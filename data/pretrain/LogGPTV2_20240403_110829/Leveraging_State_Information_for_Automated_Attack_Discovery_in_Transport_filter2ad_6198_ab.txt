### Receiver to Determine the Sending Order
The receiver is responsible for determining the sending order of packets. If packets are received out of order, they are buffered until the missing packets are received. Once all packets are available, they can be delivered to the application in the correct order. A failure in ordered delivery can lead to buffer overflow at the receiver or the delivery of out-of-order data to the application.

### Flow Control
Flow control ensures that a sender does not overwhelm a slow receiver with more data than it can handle. The goal is for the sender to transmit data at the same rate that the receiver can process it. Flow control is specified using a sliding window mechanism, which indicates the amount of data the receiver can currently buffer. The sender is limited to sending only the data within this window before receiving an acknowledgment that the window has moved forward or increased in size. Issues with flow control can result in unnecessarily slow throughput, receiver buffer overflows, and data retransmissions.

### Congestion Control
Congestion control serves two main purposes: preventing congestion collapse in the network and ensuring fairness between competing flows. Congestion collapse occurs when severe network congestion leads to a persistent drop in throughput, as the network spends most of its time retransmitting data that will eventually be dropped. Congestion control operates by detecting indicators of congestion (such as dropped packets or increased Round-Trip Time, RTT) and reducing the sending rate in response. The methods for detecting congestion and the specific responses vary significantly between different transport protocols and even within the same protocol. Issues with congestion control can cause the sending rate to be improperly adjusted, leading to unnecessary performance degradation.

A particularly important aspect of congestion control is fairness. When two flows compete for bandwidth on a bottleneck link, they should share the bandwidth equally. The networking community generally considers this to mean that the flows should achieve throughputs within a factor of two of each other [23], [24]. Issues with fairness can lead to unfair competition between flows, potentially causing starvation for some connections.

### Connection Tear Down
After all desired data has been transferred, the client and server must signal to each other that they are ready to close the connection and release all associated state. This process, similar to connection establishment, involves a handshake where both hosts indicate that they are done sending data and are ready to terminate the connection. Failure to properly tear down the connection can result in the state lingering on both hosts longer than necessary, with resources remaining allocated.

### Attack Goals
We focus on attacks targeting any phase of a transport protocol: connection establishment, data transfer, or connection tear down. For data transfer, we consider attacks against reliability, ordered delivery, flow control, and congestion control (including fairness).

### Ordered Delivery
Ordered delivery ensures that data sent by one application is received by the other in the same order. Connection-related attacks can interfere with the connection establishment or tear down processes.

### Attacker Interaction with the Protocol
We consider a client-server setup where the attacker can be either a compromised client or an off-path third party. Note that on-path attacks, such as modifying data in transit or dropping connection initiation requests, are not considered here, as transport protocols like TCP are not typically designed to address these types of attacks.

#### Malicious Client
In this scenario, the attacker is a compromised client. As shown in Figure 1(a), the attacker can view all packets in the connection, create arbitrarily formed packets, and respond arbitrarily to incoming packets. This may include ignoring received packets, delaying or duplicating responses, or setting unusual field values in sent packets. Such an attacker can target the fairness of the network protocol by seeking to gain more than their fair share of network bandwidth. They may also seek to deny bandwidth to other flows by abusing their connection with the server or use repeated connections to cause resource exhaustion on the server.

#### Off-Path Attacker
In this case, the attacker is not one of the endpoints but a third party placed off-path. As shown in Figure 1(b), the attacker cannot view or modify the packets in the target connection. Instead, they are limited to spoofing packets, either individually or in sequences, to make them appear as if they originated from the client or the server. An off-path attacker is likely to target the ability to establish the connection or the congestion control of that connection.

### Design
In this section, we discuss the design of SNAKE. We first provide an overview of our approach, then describe how we utilize the state machine of the protocol to reduce the search space and generate attack strategies. Finally, we describe the packet-level basic attacks we consider.

#### Overview
We focus on finding attacks in unmodified implementations of transport protocols. We consider attacks on connection establishment, resource exhaustion, throughput degradation, and fairness. These attacks can be identified by examining the results of an attempted data transfer. Specifically, connection establishment attacks can be identified by observing a target connection that transfers no data. Resource exhaustion attacks result in incomplete socket cleanup at the server. Throughput degradation and fairness attacks can be identified by unfair competition between a target connection and its competitor; throughput degradation targets the low-throughput connection, while fairness attacks target the high-throughput connection. All these attacks can be detected by running the protocol for a relatively short period of time.

We select an environment that combines virtualization with network emulation. Virtualization allows us to test a wide range of implementations independent of language, operating system, or access to source code. Network emulation provides reproducible measurements and attack isolation.

#### Attack Injection
An important aspect of determining an attack search strategy is identifying the attack injection points, where attacks can be inserted into a test run.

##### Send-Packet-Based Attack Injection
One simple approach is to have the proxy intercept each packet generated by the client application running in the virtual machine, apply any basic attacks desired, and forward the packet to its destination. This means that an attack injection point occurs whenever there is a send for a particular packet type. While this approach is relatively simple and can find many attacks, it also results in redundant executions and lengthens the time required to complete the search. Additionally, it does not work well for off-path attackers and fails to find attacks not connected with packet send events in the code, which is problematic for transport protocols because many attacks against connection establishment and tear down fall into this category.

##### Time-Interval-Based Attack Injection
Another approach is to divide the running time into fixed intervals and, for each interval, attempt to inject packets following all basic attacks. While this approach is also relatively simple, a small time interval must be used to catch many attacks, resulting in testing thousands of strategies that either do not inject attacks or inject many redundant attacks based on the semantics of the protocol. This approach also has a high execution time overhead and can take a very long time to complete.

##### Protocol State Aware Attack Injection
Our approach to eliminate redundant testing scenarios, support off-path attackers, and provide finer granularity for injecting attacks is to take into account the semantics of the protocol when injecting attacks. We can obtain information about the semantics of the protocol from its state machine. Many transport protocols have well-documented state machines describing their connection lifecycles, and in the absence of such documentation, state machine inference techniques can be leveraged [20].

We propose a state-based search strategy that leverages several characteristics of the protocol state machine to reduce the attack search space. Specifically, we inject attacks at specific states in the protocol execution. Because the protocol state machine defines key points in the operation of the protocol, this approach allows us to quickly gain wide coverage within the search space by focusing on each of these states. We also treat all attack injection points in the same state in the same manner, further pruning the number of search paths to be explored. The motivation behind our approach is that two packets of the same type received in the same protocol state usually cause similar results; however, an identical packet received in two different states may cause significantly different results.

To apply our protocol state-aware attack injection, we need a mechanism to infer which protocol state an endpoint is in. Since we do not require access to the source code, we use packet monitoring to infer the state. This is accomplished by a state tracking component (see Figure 2) that uses a description of the protocol state machine supplied by the user. The state machine provides information about what packets determine transitions from one state to another. At runtime, the state machine tracker infers changes in the state machines of each endpoint by observing the packets exchanged and matching them with the state transition rules. The state tracking component also keeps track of some basic information about each observed state, including the packet types observed in that state.

Note that this strategy assumes that implementations have correctly implemented the protocol state machine as described in their specification. Existing work on state machine verification [25] could be leveraged to overcome this limitation. However, the high-granularity state machines, describing connection lifecycle, that we use are unlikely to be implemented incorrectly due to their simplicity and importance to the protocols. Taking TCP as an example, the state machine has 11 states in total, and all data transfer, along with associated retransmissions and congestion control, takes place in a single state [26]. A mistake in this state machine would have a similar impact to getting the packet header formats wrong; while the implementation may work with itself, it will fail simple interoperability tests.

#### Attack Strategy Generation
Based on the packet types and state machine information, we automatically generate attack strategies. For each packet type, we generate the basic attacks described below. We conducted an extensive study of the literature on transport protocol attacks to develop our basic attacks. All of these attacks are conducted by our attack proxy at the packet level.