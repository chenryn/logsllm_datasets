receiver to determine the sending order. Packets received out of
order are buffered at the receiver until the missing packets are
received. The packets can then be delivered to the application
in order. A failure of ordered delivery would result in receiver
buffer overﬂow or the delivery of out-of-order data to the
application.
Flow control. Flow control ensures that a sender does not
overwhelm a slow receiver with more data than it can buffer.
The goal is for the sender to send at the same rate that the
receiver is receiving. Flow control is speciﬁed as a sliding
window indicating the data that the receiver can currently
buffer. The sender is then limited to sending that window of
data before receiving an acknowledgment indicating that the
window has either slid forward or increased in size. Issues
with ﬂow control will cause unnecessarily slow throughput or
receiver buffer overﬂows and data retransmissions.
Congestion control. Congestion control serves two related
purposes. First, it protects against congestion collapse in the
network, and second, it provides fairness between competing
ﬂows. Congestion collapse occurs when severe network con-
gestion, or over-utilization, results in the network spending
the majority of its time sending data that will eventually
be dropped. This results in a persistent drop in throughput.
Ultimately, congestion control operates by detecting indicators
of congestion and slowing down the sending rate in response.
The means of detecting congestion and the precise details of
the response to congestion vary signiﬁcantly between transport
protocols and even within the same protocol. Often, dropped
packets or increased RTT are used to identify congestion.
Issues with congestion control will cause the sending rate to
be increased or decreased improperly and unnecessarily.
A particularly important property of congestion control is
fairness. That is, if two ﬂows are competing over bandwidth
on a bottleneck link, they should share the bandwidth equally.
The networking community has generally understood this to
mean that the ﬂows achieve throughput within a factor of two
of each other [23], [24]. Issues with fairness may cause unfair
competition between ﬂows, possibly resulting in starvation.
Connection tear down. After all desired data has been
transferred, there must be a way for client and server to
signal this to each other and release all state associated with
the connection. Like connection establishment, connection tear
down takes place through a handshake in which the two hosts
indicate that they are done sending data and are ready to close
the connection. A failure to properly tear down the connection
may result in the associated state staying around on both hosts
much longer than desired and resources remaining allocated.
B. Attack Goals
We focus on attacks that target any of the phases of a
transport protocol: connection establishment, data transfer, or
connection tear down. In the case of data transfer, we consider
attacks against all goals: reliability, ordered delivery, ﬂow
control, and congestion control (including fairness).
Ordered delivery. Ordered delivery guarantees that data
sent by one application is received at the other in the same
Connection-related attacks. An attacker can interfere
with the connection establishment or connection tear down
33
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:11:45 UTC from IEEE Xplore.  Restrictions apply. 
C. Attacker Interaction with the Protocol
We consider a client-server setup where the attacker is
either a compromised client or an off-path third party. Note that
an attacker can also conduct on-path attacks. For example,
modifying data in transit or dropping connection initiation
requests. We do not consider such attacks since transport
protocols such as TCP are not usually designed to address
these attacks.
Malicious client. In this case, the attacker is a compro-
mised client. As shown in Figure 1(a), the attacker is one of the
endpoints so he can view all packets in the connection, create
arbitrarily formed packets, and respond arbitrarily to incoming
packets. This may include ignoring received packets, delaying
or duplicating responses, or setting unusual ﬁeld values in sent
packets or sequences there of. Such an attacker can target the
fairness of the network protocol by seeking to gain more than
his fair share of network bandwidth. He may also seek to deny
bandwidth to other ﬂows by abusing his connection with the
server or use repeated connections to cause resource exhaustion
on the server.
Off-path attacker. In this case, the attacker is not one
of the endpoints of the connection, but a third party, placed
off-path. As shown in Figure 1(b), the attacker cannot view
or modify the packets in the target connection. Instead, he is
limited to spooﬁng packets, either individually or in sequences,
such that they appear to originate at either the client or the
server. An attacker in this position is likely to seek to attack
the ability to establish the target connection or the congestion
control of that connection.
IV. DESIGN
In this section, we discuss the design of SNAKE. We ﬁrst
provide an overview of our approach, then describe how we
utilize the state machine of the protocol to reduce the search
space and generate attack strategies. Finally, we describe the
packet-level basic attacks we consider.
A. Overview
We focus on ﬁnding attacks in unmodiﬁed implementations
of transport protocols. We consider attacks on connection es-
tablishment as well as resource exhaustion attacks, throughput
degradation attacks, and fairness attacks. These attacks can
be identiﬁed by examining the results of an attempted data
transfer. Speciﬁcally, connection establishment attacks can be
identiﬁed by observing a target connection that transfers no
data. Resource exhaustion attacks result in incomplete socket
cleanup at
the server. Throughput degradation attacks and
attacks on fairness can be identiﬁed by unfair competition
between a target connection and its competitor; throughput
degradation attacks target the low throughput connection while
attacks on fairness target the high throughput connection. All
of these attacks can be detected by running the protocol for a
relatively short period of time.
We select an environment that combines virtualization with
network emulation. Virtualization allows us to test a wide
range of implementations independent of language, operating
system, or access to source code. The network emulation
provides us the reproducible measurements and attack isolation
(a) A malicious client manipulates
packets belonging to the A-C con-
nection,
trying to increase or de-
crease its performance relative to the
B-C connection
(b) An off-path attacker
injects
packets, targeting the B-C connec-
tion
Fig. 1. Examples of attacker location and target connections
protocols by preventing them from achieving their goals:
establishing a connection or cleanly terminating a connection.
Preventing connection establishment attacks are actions
taken by a malicious host to prevent some target connection
from being established and transferring useful data. These
actions occur at
the same approximate time as the target
connection attempt and target the very core of the transport
protocol by preventing a user from successfully initiating a
connection.
End-host resource exhaustion attacks are actions taken by
a malicious host to force the other end of the connection to
exhaust some limited resource (memory, sockets, etc) in order
to deny service to other (legitimate) requests, creating a denial
of service condition. These actions occur in already established
connections and target future connections that have yet to be
attempted. These attacks are conducted by malicious clients
against a server in an attempt to prevent legitimate users from
accessing the provided service.
We do not consider connection hijacking attacks. These
attacks require sampling from the target implementation or the
collusion of a low-privilege component on the victim.
Performance-related attacks. An attacker can also target
the performance of an individual connection, either by seeking
to degrade the throughput of some target connection or by
seeking to compromise the fairness of the protocol’s conges-
tion control algorithm.
Throughput degradation attacks are actions taken by a
malicious host to decrease the throughput of some target con-
nection, often with the intention of making the connection so
slow that it is useless to the initiating application. These attacks
target the congestion control and ﬂow control algorithms of the
transport protocol.
Fairness attacks are actions taken by a malicious host
to unfairly increase its throughput at the expense of other
competing connections. This type of attack directly targets
the fairness of the transport protocol’s congestion control
algorithm. Many of these attacks also indirectly compromise
the reliability of the transport protocol.
We do not consider denial of service conditions that result
from an attacker consuming all of a service’s network band-
width nor those resulting from a sheer overwhelming number
of connections. The transport layer can do nothing to prevent
these attacks.
44
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:11:45 UTC from IEEE Xplore.  Restrictions apply. 
Fig. 2. Design of SNAKE
needed to detect performance-related attacks. Figure 2 presents
our system design.
The attack strategies we consider can be created by packet
manipulation and injection based on the packet type and the
individual packet ﬁelds. These strategies are selected from a set
of basic attacks derived from information about packet formats.
For instance, an attack strategy may be to duplicate packets of
type W ten times, or to inject a new packet of type X with ﬁeld
3 set to Y, or to modify ﬁeld 5 of packet type Z to 555. Each
of these attack strategies are performed in particular protocol
states.
To determine what kinds of basic attacks would be most
useful, we performed a detailed literature study on transport
protocol attacks and identiﬁed some common components, or
building blocks, used in many of these attacks. Based on this
study, we deﬁned a set of packet-based basic attacks that we
use to compose attack strategies.
As we do not require access to the source code, our
approach relies on intercepting and modifying or injecting net-
work trafﬁc. We place an attack proxy between one of our test
hosts and the emulated network. This attack proxy intercepts
packets and can apply basic attacks such as inﬂuencing the
delivery of packets or modifying the packets ﬂowing through
it. We can also use the proxy to emulate an off-path attacker
that injects new packets into the network.
We detect if an attack was successful or not by comparing
the connection performance under attack with a baseline
generated from a test with no attacks and by checking for
open sockets on the server after the test completes. Attack
strategies that appear successful are tested a second time to
ensure repeatability.
B. Attack Injection
An important aspect of determining an attack search strat-
egy is identifying the attack injection points, that is, the points
where attacks can be inserted into a test run.
Send-packet-based attack injection. One simple approach
is to have the proxy intercept each packet generated by
the client application running in the virtual machine, apply
any basic attacks desired, and forward the packet on to its
destination. This means that an attack injection point occurs
whenever there is a send for a particular packet type.
While this approach is relatively simple and can ﬁnd
many attacks, it also results in repeatedly performing attacks
that have the same semantics for the protocol, thus resulting
in redundant executions and lengthening the time required
to complete the search. In addition, this approach does not
work well for off-path attackers and fails to ﬁnd attacks
not connected with packet send events in the code. This is
particularly problematic for transport protocols because many
attacks against connection establishment and tear down fall
into this category.
Time-interval-based attack injection. One approach to
provide support for off-path attackers and ﬁner time granularity
is to divide the running time into ﬁxed intervals and, for each
of these intervals, attempt to inject packets following all basic
attacks. While this approach is also relatively simple, a small
time interval must be used in order to catch many attacks. This
will result in testing thousands of strategies that either do not
inject attacks or inject many redundant attacks, based on the
semantics of the protocol. As a result, this approach also has
a high execution time overhead and can take a very long time
to complete.
Protocol state aware attack injection. Our approach to
eliminate some of the redundant testing scenarios, support
off-path attackers, and provide ﬁner granularity for inject-
ing attacks is to take into account
the semantics of the
protocol when injecting attacks. We can obtain information
about the semantics of the protocol from its state machine.
Many transport protocols have well documented state machines
describing their connection lifecycles, and in the absence of
such documentation, work in state machine inference may be
leveraged [20].
We propose a state-based search strategy that leverages sev-
eral characteristics of the protocol state machine to reduce the
attack search space. Speciﬁcally, we inject attacks at speciﬁc
states in the protocol execution. Because the protocol state
machine deﬁnes key points in the operation of the protocol, this
approach allows us to quickly gain wide coverage within the
search space by focusing on each of these states. We also treat
all attack injection points in the same state in the same manner.
This further prunes the number of search paths to be explored.
The motivation behind our approach is that two packets of the
same type received in the same protocol state usually cause
similar results; however, an identical packet received in two
different states may cause signiﬁcantly different results.
In order to apply our protocol state aware attack injection,
we need a mechanism to infer which protocol state an endpoint
is in. As we do not require access to the source code, we
55
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:11:45 UTC from IEEE Xplore.  Restrictions apply. 
use packet monitoring to infer the state. This is accomplished
by a state tracking component (see Figure 2) that uses a
description of the protocol state machine supplied by the user.
The state machine provides information about what packets
determine transitions from one state to another. At run time,
the state machine tracker infers changes in the state machines
of each endpoint by observing the packets exchanged and
matching them with the state transition rules. The state tracking
component also keeps track of some basic information about
each observed state, including the packet types observed in
that state.
Note that this strategy assumes that implementations have
correctly implemented the protocol state machine as described
in their speciﬁcation. Existing work on state machine veriﬁ-
cation [25] could be leveraged to overcome this limitation.
However, the high granularity state machines, describing con-
nection lifecycle, that we use are unlikely to be implemented
incorrectly because of their simplicity and importance to the
protocols. Taking TCP as an example,
the state machine
has 11 states in total and all data transfer, and associated
retransmissions and congestion control, takes place in a single
state [26]. A mistake in this state machine has a similar
impact to getting the packet header formats wrong; while
the implementation may work with itself, it will fail simple
interoperability tests.
C. Attack Strategy Generation
Based on the packet types and state machine information,
we automatically generate attack strategies. For each packet
type we generate the basic attacks described below.
We conducted an extensive study of the literature on
transport protocol attacks to develop our basic attacks. All of
these attacks are conducted by our attack proxy at a packet