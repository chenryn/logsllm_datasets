Under this app splitting model, our data-ﬂow analysis ﬁrst com-
putes the split data-ﬂow summary (SDS) for each split in the app. It
then starts the permutation process and, for each possible sequence
of splits, generates permutation data-ﬂow summary (PDS) by link-
ing the SDS of each split in the sequence. As the permutation pro-
ceeds, each PDS is checked for interesting data-ﬂows speciﬁed by
pre-deﬁned policies. Eventually, all possible data-ﬂows can happen
in the app are enumerated.
Figure 3 shows two SDS marked by dashed boxes. They are
generated based on the two entry points, handleMessage and
doInBackground, in our example discussed in Section 3.1. An
SDS consists of intra-split data-ﬂows whose end nodes represent:
(i) heap variables5 entering or exiting the split scope (depicted by
5Variables with a global scope, as opposed to local variables.
233information or requester’s input. We also deﬁne three general
sinks to mark end points of interesting-ﬂows that are to make data
publicly accessible (Tag_PublicSink), make data accessible
to speciﬁed entities (Tag_SpecifiedSink), or write data into
critical data regions (Tag_CriticalSink). With these tags de-
ﬁned, we can easily convert Deﬁnition 1 into three simple policies
to capture hijack-enabling ﬂows:
{Tag_SensSrc ; Tag_PublicSink}
P1 :
P2 : {Tag_InputSrc ; Tag_CriticalSink 1
Tag_SensSrc ; Tag_SpecifiedSink}
P3 : {Tag_InputSrc ; Tag_CriticalSink}
These policies are checked on every newly generated PDS as the
split permutation continues. As for the example discussed in Sec-
tion 3.1, our analyzer can detect the hijack-enabling ﬂows, satisfy-
ing P2 and P3, from a PDS that links the SDS of handleMessage
with that of doInBackGround, as shown in Figure 3.
The PDS generation is carried out by two basic operations –
link and unlink an SDS. The link operation adds a new SDS into a
PDS if inter-split data-ﬂows exist from the latter to the former. It
draws data-ﬂow edges (e.g. the two thick edges in Figure 3) from
leaf nodes in the PDS to those reachable root nodes in the new
SDS. For Android apps, the only two channels through which data
can ﬂow across splits are: heap variables sharing the same loca-
tion key tuple, and framework API pairs that transit data among
splits. We introduce a pair of special tags, Tag_TransSink and
Tag_TransSrc, to model these API pairs. The link operation
can reject the SDS if no edge can be drawn and the SDS does not
contain ﬂows starting with any pre-deﬁned source. A rejection sug-
gests that the new SDS has no effect on any potential propagation
of interesting-ﬂows in the current PDS, and thus, there is no need
to add it. Unlink operation simply reverts the last link operation.
Intuitively iterating through all split permutations can be a pro-
hibitively expensive operation for apps with a large number of en-
try points. We leverage on the continuity of data-ﬂows across splits
to carry out a simple but effective search pruning. The depth-ﬁrst
search only appends an SDS to the current permutation if it is ac-
cepted by the link operation and then continues iterating along that
path. As shown in Section 5, this pruning greatly reduces the search
space and time overhead of the permutation process. The permu-
tation also considers a few constraints on the launch order of splits
that handle life-cycle events of basic components (e.g. entry points
relating to component initialization and termination are called in
ﬁxed orders).
Finally, C4 is addressed, because all interesting-ﬂows in an app,
both intra-split and inter-split ones, are constructed during the split
permutation process. Our app splitting technique enables a data-
ﬂow analysis that is more efﬁcient and better accommodates the
event-driven nature of Android apps, than the conventional meth-
ods, which synthesize a main function explicitly invoking event
handlers. App splitting creates a divide-and-conquer theme. The
sub-problems (i.e. constructing intra-split data-ﬂows and SDS) are
signiﬁcantly easier and smaller in scale than the original problem
(i.e. constructing data-ﬂows for an entire app, as faced in the con-
ventional methods). The merge process (i.e. permuting splits) can
be very fast, as shown in Section 5. Moreover, due the mutual inde-
pendence among SDS, they can be built in parallel and cached for
reuse (e.g. SDS for common libraries can be built once and reused
when analyzing all apps that make use of them) to further improve
the performance.
Figure 3: Linked-SDS for the running example
octagons); or (ii) pre-deﬁned sources or sinks (depicted by rectan-
gles). We omitted intermediate nodes in the SDS in Figure 3 to ease
illustration. In essence, an SDS only contains data-ﬂows within a
split that may contribute to connecting a source to a sink (may re-
sides in another split). We refer to these data-ﬂows as interesting-
ﬂows hereafter. The upper SDS in Figure 3 has two isolated data-
ﬂows: the one on the left propagates the location data (a sensitive
source, tagged as Tag_SensSrc) to a heap variable currLoc,
and the one on the right carries the requester’s input (tagged as
Tag_InputSrc) to a transit sink; The lower SDS captures the
convergence of a heap variable and a transit source at a sink associ-
ated with two tags (Tag_DataSink and Tag_CriticalSink,
explained shortly). We compute SDS via a context- and ﬁeld-
sensitive data dependence analysis, identifying interesting-ﬂows in
the current split. As Figure 3 shows, heap variables are represented
by their heap location key, which is a three-tuple in the form of
(f ield, allocSite, method), indicating the f ield whose contain-
ing object was allocated at allocSite in method (f ield of any ar-
ray object is null). Pre-deﬁned sources and sinks (data entry or
exit points of the analysis’s interest) are represented by a four-tuple,
(method, paramIndex, tag, callSite), indicating that a parame-
ter of a method called at callSite is a source or sink depending on
the tag. Note that in Figure 3 the line numbers of allocSites and
callSites that are not shown in Figure 2 are substituted by capital
letters (e.g. Ln.X).
Our analysis method allows for a fairly ﬂexible way of deﬁning
and extending tags associated with sources and sinks. Tags are used
to differentiate sources and sinks with different semantic meanings
given by the analyzer users based on their speciﬁc usage scenarios.
Policies that specify interesting-ﬂows can be deﬁned based on the
tags associated with their end nodes:
P := Fint 1 [Fint | ∅]n, Fint
:= [T ag] ; [T ag],
where 1 deﬁnes a join relationship exists between two interesting-
ﬂows (i.e. two ﬂows, or their extensions, intersect or converge with
each other), and ; deﬁnes an interesting ﬂow with two end nodes
of speciﬁed tags. By supporting customizable tags and the join
relationship in deﬁning interesting-ﬂows, our analyzer provides a
means of expressing the side-effects of converged ﬂows on a se-
mantic level, which solves C3.
For component hijacking vulnerability detection, we deﬁne two
general source tags, Tag_SensSrc and Tag_InputSrc, to
mark the start points of interesting-ﬂows that propagate sensitive
SDS: handleMessage(getLastKnownLocation, -1, Tag_SensSrc, Ln.15)(handleMessage, 1, Tag_InputSrc, Ln.N)(SendToNetwork.execute, 1, Tag_TransSink, Ln.21)SDS: doInBackground(currLoc, Ln.X, )(doInBackground,(1, Tag_TransSrc, Ln.M)(HttpClient.execute,1, Tag_DataSink^Tag_CriticalSink, Ln.36)(currLoc, Ln.X, )2344.
IMPLEMENTATION OF DALYSIS AND
CHEX
We built a generic Android app analysis framework named Dal-
ysis, which stands for Dalvik bytecode analysis. As suggested by
its name, Dalysis directly works on off-the-shelf app packages (or
Dalvik bytecode) without requiring source code access or any de-
compilation assistance. Previous app analysis efforts that relied
on decompiled source code have two major drawbacks — heavy
performance overhead and incomplete code coverage. As reported
by Enck et al. [16], the state of the art technique to decompile
an app, on average, takes about 27 minutes and leaves 5.56% of
the source code failed to be recovered. Conducting analysis at the
dalvik bytecode level overcomes these issues. In addition, unlike
x86 binary code, bytecode retains sufﬁcient program information
from the high level language and does not have any parsing ambi-
guity, thus serves as an ideal analysis subject.
To our best knowledge, Dalysis is the ﬁrst generic analysis
framework that operates on Dalvik bytecode and intended to sup-
port multiple types of program analysis tasks. Next, we introduce
the internals of Dalysis that can facilitate the understanding of the
implementation of CHEX, our component hijacking analyzer built
based on Dalysis. We leave out the low-level system building de-
tails as they are out of the scope of this paper.
4.1 Dalysis framework
The front end of Dalysis consumes an Android app package
(.apk) at a time.
It retrieves package information from meta-
data ﬁles and translates the Dalvik bytecode into an intermediate
representation (IR), based on which the back end analyzers carry
out their tasks. The front end starts the IR generation process by
parsing the input bytecode ﬁle. Dalysis employs an open source
Dalvik bytecode parser named DexLib, part of a well-known dis-
assembler for Android apps [2]. DexLib provides useful inter-
faces to programmatically read embedded data, type information,
and Dalvik instructions from a bytecode ﬁle. Dalysis allows differ-
ent analysis to choose either include the entire Android framework
code or model its external behaviors, which is achieved by linking
two different versions of the runtime library into the analysis scope.
The front end constructs the class hierarchy, performs an semanti-
cal IR translation from Dalvik and Java bytecode (Android frame-
work libraries are compiled into java bytecode), and then hands
over the IR to backend analyzers.
We adopted our IR from the WALA project [5], a popular static
analysis framework for Java, for two reasons: the semantic prox-
imity between Dalvik bytecode and the IR and a wide selection of
basic analyzers developed for the IR by the WALA community. The
translation process is mostly straightforward, since both instruction
sets follow the register-machine model and retain a similar amount
of information from the same high level language (i.e. Java).
However, a handful of instructions that are unique to Dalvik vir-
tual machine require special handling during the translation pro-
cess. For example, the filled-new-array instruction allo-
cates and initializes an array in one step; And the move-result
instruction retrieves the result of the previous call from the spe-
cial result-register. Following the semantic translation is
the ﬁnal task for the front end – static single assignment (SSA)
conversion. The conversion performs an abstract interpretation on
each method, wherein the deﬁne-use chain is determined for each
Dalvik register as well as its mapping to the local variable on Java
level. New instructions are generated, as a side effect incurred by
the ﬂow function of the abstract interpretation. As a result of vari-
able renaming (i.e. a register model conversion), newly generated
Figure 4: CHEX workﬂow
instructions operate on a conceptual register model with unlimited
registers, each of which can only be assigned once as required by
SSA form. Meet operations happen at basic block boundaries.
As a result, φ variables are generated to merge two or more val-
ues that may ﬂow into a same variable in the current basic block
from predecessors in the control ﬂow graph. Converting the IR into
SSA form can simplify various types of program analysis, espe-
cially data-ﬂow related ones, such as deﬁnition reachability test,
constant propagation and etc. In fact, many existing analyzers for
WALA assume an SSA IR.
The back end of Dalysis hosts a variety of analyzers and provides
them the interfaces to access the IR, the class hierarchy, and other
useful information. Some basic analyzers released by WALA, such
as the point-to analysis and the call graph builders, are included
in Dalysis. These building-block analyzers can be found useful
by many advanced analyzers. Dalysis itself is not speciﬁc to any
particular ﬂavor of app analysis — it is designed to be a generic
framework that can enable as many types of analysis as possible on
Android apps. For example, CHEX demonstrates how we imple-
mented the data-ﬂow analysis methods, introduced in Section 3.2,
by using the Dalysis framework.
Dalysis is implemented in Java with 15,897 lines of source code,
excluding 3rd party libraries. The building process took us a signif-
icant amount of efforts due to a lack of similar work and reusable
code. But most efforts were spent on tackling engineering related
issues or implementing existing algorithms from the programming
language community, therefore we do not intend to claim these ef-
forts as contributions in this paper. We also omit the implementa-
tion details of Dalysis that should be oblivious to analyzer design-
ers, which is out of the scope of this paper.
4.2 CHEX: Component hijacking examiner
CHEX realizes our data-ﬂow analysis methods and models dis-
cussed in Section 3.2.
It detects hijack-enabling ﬂows based on
policies P1-3, with a set of 180 sources and sinks that match the
tags deﬁned by these two policies. This set was constructed semi-
automatically to cover a relatively wide range of hijack-enabling
ﬂows that affect the sensitive resources managed by the system
(i.e. protected by Android permissions and accessed uniformly
across apps). Parts of the sensitive sources (Tag_SensSrc) were
selected based on the API-to-permission mapping provided by [19].
This set is adequate for our testing and evaluation purpose, but it is
not meant to be complete. In fact, it can be extended with source
and sinks speciﬁc to individual apps, so that CHEX can capture
hijack-enabling ﬂows in app’s semantics.
As shown in Figure 4, entry point discovery starts at ﬁrst.
It
queries Dalysis front-end for information necessary to the ini-
APKSDSSDSPDSHijack-enablingFlow RecordsEntry PointDiscovery1SDSGeneration2Split Permutation & PDS Generation34235tialization process, such as event listeners deﬁned in manifest
and method overloading relationships (shown in Algorithm 1).
CHEX makes multiple different uses of the call graph builder from
WALA, which can be conﬁgured to have different degrees of context
sensitivity. For each iteration in the entry point discovery process,
we generate a context-insensitive call graph, for the least perfor-
mance overhead and the unnecessity of context sensitivity in this
scenario (i.e. we use the call graph only to conservatively estimate
if a method was called or a class was instantiated before).
For each discovered entry point, or more speciﬁcally, the split
started by that entry point, CHEX builds an SDS to summarize
its data-ﬂow behaviors that may contribute to forming any hijack-
enabling ﬂow (Step 2 in Figure 4). Building SDS is a computation
heavy step in the entire analysis because it is where all intra-split
data-ﬂows are constructed directly by analyzing the IR. In compar-
ison, in a later step, the permuter generates inter-split ﬂows and
PDS based on simple rules determining the connectivity between
two intra-split ﬂows.
Conventional data-ﬂow analysis approaches solve data-ﬂow equa-
tions through an iterative process. This process is expected to
reach a ﬁx-point after limited iterations of basic-block state changes
made by transfer functions. However, for the purpose of build-
ing SDS, we can safely avoid this procedure and still be able to
check interesting-ﬂows, thanks to the SSA IR and our abstraction of
the ﬂow checking problem. Speciﬁcally, the SSA conversion car-
ried out by the front end has already conducted a basic data-ﬂow
analysis and saved information (e.g. variable use-deﬁne chains and
etc.) that can greatly facilitate the construction of system depen-
dence graphs. Inspired by the way of utilizing system dependence