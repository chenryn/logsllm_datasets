displayed in a permissions dialog, mischievously taking ad-
vantage of the plain English interpretation of the question
displayed in the permission dialog. More speciﬁcally, the ad-
versary selects this app as their attack app’s internal name
and the question in the permission dialog will now read as
“Allow this app to access your contacts?”, as shown in Fig-
ure 1c. Clearly, this question’s plain English meaning does
not distinguish between apps and is capable of referring to
any app that is currently in the foreground for a given permis-
sion request. We have veriﬁed that such an app is accepted to
GP and can be installed on a user device without any issue.
We have also veriﬁed with our user study that the majority
of users (199 out of 200) do not seem to notice anything un-
usual with this particular app name, which we believe is an
indication that users are generally not aware of the identity
guarantee provided by app names in permission dialogs.
In addition, it is worth mentioning that our attack beneﬁts
from certain UI tricks for its successful execution. First, we ob-
served that after a user makes their permission decision, since
the adversary is using an invisible activity, the top notiﬁcation
bar of the Android system also appears as a part of the transi-
tion effect, creating a suspicious look. In order to ensure the vi-
sual effect is subtle enough to not be noticed, we ﬁrst temporar-
ily hide the top bar at the time of the permission request using
the Window.setFlags() API with the FLAG_FULLSCREEN
ﬂag. After the user is done with their decision, the top bar is
automatically re-enabled by the system. Second, users can
view running apps via the recents screen, which is an avenue
of detection or at the very least for getting killed for the at-
tacker. To avoid this, the attack app can hide itself from this
screen by setting the android:excludeFromRecents ﬂag
of its activities in its manifest.
Attack steps. As we have explained the overall idea of our
attacks and our methodologies, we will now give a step by
step guide to launching false transparency attacks.
1) Lurk in the background. The attack app creates a service to
continuously run in the background and periodically collects
information about the running apps to determine when to
attack. Prior to Android 8, running background services could
be achieved by using Service or IntentService classes.
However, Android 8 brings restrictions to background execu-
tion of apps in order to preserve device resources to improve
user experience. Background services are now killed a few
minutes after the app moves to the background; hence, the
use of JobScheduler is more appropriate for our attacks [8]
as JobSchedulers can indeﬁnitely run in the background to pe-
riodically execute jobs. Additionally, the adversary will also
avoid situations that might arouse suspicion in the user. In
particular, the app will not use its spoofed name in its launcher
name shown in the app menu and instead set it according to
the declared legitimate use of the app listed in the respective
app store, in order to prevent a possible detection by the user.
2) Choose your victim carefully. The attack app runs our
ProcHarvester-based implementation to detect victims in the
foreground. This entails continuously monitoring the proc
ﬁlesystem and running our real-time foreground app inference
algorithm, which we will describe in more detail in Section 5.
3) Choose your permission carefully. Once we obtain the
foreground app, we will query the PackageManager to ob-
tain the requested permissions of this app and prompt the
user for a permission that was granted to the victim but not to
the attacker. If there are multiple such permissions, we will
randomly pick one to request. Please note that more intricate
selection algorithms can be used to more properly pick the
permission to be requested. For example, previous work has
shown that microphone permission is the most denied per-
mission and hence can be considered the most valuable from
the perspective of our attack [2]. In this case, the attacker
USENIX Association
29th USENIX Security Symposium    421
might want to prioritize the microphone permission if the
foreground app can make a very good case of needing the mi-
crophone (e.g., music app or communication app). However,
we do not perform this kind of advanced permission selection
as our main purpose is to demonstrate our attacks realistically
without overly complicating our implementation.
4) Cloak and dagger. Once the attacker determines that a
certain permission should be requested from the victim in
the foreground, they will start an invisible activity from the
background service via the startActivity() API. This ac-
tivity will then be automatically moved to the foreground as
we have previously explained in Section 4.1. Then, the at-
tacker requests the chosen permission from the context of this
invisible activity using the requestPermissions() API.
5) Leave no trace behind. Once the user completes the per-
mission request, the attacker will call the moveTaskToBack()
API in order to move to the back of the activity stack to evade
detection and continue running silently. This way, the victim
app will be restored back to the foreground and the user can
continue interacting with the victim.
5 Foreground App Inference
As we have described in Section 4, the adversarial app running
in the background will continuously monitor the foreground
to detect known victim apps to target with false transparency
attacks. Here, we will explain the previous efforts for fore-
ground app inference, why they fail to work in realistic scenar-
ios, and our approach for effectively inferring the foreground
app in real time.
Past efforts for foreground app inference. Previously, An-
droid offered convenient APIs, such as getRunningTasks(),
that could be used to infer the identity of the foreground tasks;
however, these APIs have been deprecated in Android 5 in
an effort to maintain the privacy of the running apps and pre-
vent phishing attacks on the platform. This has consequently
led to a search to identify other avenues that can accomplish
the same task. Having inherited many features and security
mechanisms from Linux, Android, too, has a proc ﬁlesystem
(procfs) that provides information about the running processes
and general system statistics in an hierarchical structure that
resides in memory. Security researchers have discovered that
Android’s proc ﬁlesystem provides numerous opportunities
for attackers to infer the foreground app [9, 10]. In response,
Android has been gradually closing access to all the sensitive
parts of the procfs pointed out by researchers in order to pre-
vent phishing attacks. In the most recent Android versions,
all of per-process information on the proc ﬁlesystem has been
made private (i.e., accessible only by the process itself) and
only some of the global system information have been left to
be still publicly available due to utility reasons, rendering the
efforts to identify the foreground app virtually impossible.
More recently, though, Spreitzer et al. discovered that de-
spite all the strict restrictions on the procfs, there are still
public parts of this ﬁlesystem that initially seem innocuous
but in fact can be utilized to effectively identify the foreground
app by employing a relatively more complex analysis in com-
parison to the previous efforts. To this end, they introduced
a tool named ProcHarvester that uses machine learning tech-
niques to automatically identify the procfs information leaks
(i.e., foreground app, keyboard gestures, visited websites) on
potentially all Android versions, including the newer versions
with limited procfs availability, by performing a time series
analysis based on dynamic time warping (DTW) [7]. Then,
they showed that these identiﬁed parts can be utilized for fore-
ground app inference via a similar technique, yielding a high
accuracy. In particular, ProcHarvester comprises of two main
components: 1) a monitoring app that logs the public parts
of procfs on the user device and 2) a server as an analysis
unit (connected by wire to the phone) that collects this infor-
mation from the monitoring app to ﬁrst build proﬁles of app
starts for the apps in their dataset and then perform DTW to
identify information leaks. ProcHarvester currently works as
an ofﬂine tool in a highly-controlled environment and is not
capable of inferring the foreground app in real time, which is
an absolute necessity for our attack scenario.
Real-time foreground app inference under realistic sce-
narios. In our work, we build on ProcHarvester for infer-
ring the foreground app in our attacks. More speciﬁcally, we
modiﬁed ProcHarvester to adapt to realistic scenarios and
implemented real-time inference of time series to identify the
foreground app. Here, we utilize 20 high-proﬁle apps to serve
as the victim apps that the adversary will primarily target for
permissions. In addition, we have 380 apps that we will not
utilize as victims but use in our experiments to show we can
distinguish between victim and non-victim apps at runtime.
We chose our victim apps to be from the same dataset as in the
original ProcHarvestor work in [7] while we utilized the top
apps from each category on Google Play as our non-victim
apps. Coverage of permission groups utilized by the apps
in our dataset can be observed in Table 2. We deployed our
implementation and performed our experiments on a Google
Pixel device that runs Android 7.0.
We ﬁrst ran the original ProcHarvester implementation
to create proﬁles of only the procfs resources that yielded
high accuracy for app inference [7], for each victim app in
our dataset. Additionally, in original ProcHarvester system,
the analysis unit (server) is directly connected to the user
device by wire and is collecting data from the device through
this connection. However, in our case, adversaries cannot
assume a wired connection to a user device as this does not
constitute a realistic attack scenario. Hence, we modiﬁed the
monitoring app to send continuous data to a remote server,
which is running our foreground app inference algorithm in
422    29th USENIX Security Symposium
USENIX Association
Table 2: Permission distribution for the apps in our dataset.
Permission Group
# of victim
# of
non-victim
CALENDAR
CALL_LOG
CAMERA
CONTACTS
LOCATION
MICROPHONE
PHONE
SENSORS
SMS
STORAGE
1
0
7
14
12
6
20
0
2
20
28
7
207
170
228
95
376
2
9
315
real time. This is a plausible assumption as adversaries can
easily obtain the install-time INTERNET permission, which is
of normal protection level, to communicate over the Internet.
Most importantly, we implemented a real-time dynamic
time warping (DTW) algorithm to detect the foreground app.
Currently, ProcHarvester can only be used as an ofﬂine infer-
ence tool, as it works based on the assumption that app launch
times will be known to the tool in advance and the tool can
run its DTW-based analysis starting from those launch times.
However, this assumption is unrealistic in real-life scenarios
as an attacker cannot assume to have a priori knowledge re-
garding app launch times since an app launch is either at the
user’s discretion or is initiated by the system or other apps
via IPC. In our work, we devise a technique to identify an
interval of possible values for the app start time and run DTW
starting from all possible values in this interval, rather than
using a single starting point as in the original ProcHarvester,
to obtain the foreground app in real time.
First, in order to obtain the starting time of an app
launch, we utilize the getRunningTasks() API to moni-
tor foreground changes. Even though this method was pre-
viously deprecated as a countermeasure for phishing, we
observed that it still provides limited information regard-
ing the foreground of the device. For example, on An-
droid 5-8, whenever there is an app in the foreground, the
getRunningTasks() API outputs the package name of
the caller app (regardless of it being in the foreground or
not), and if there is no app in the foreground, it outputs
com.google.android.apps.nexuslauncher, which corre-
sponds to the Android launcher menu. By continuously moni-
toring such foreground changes, we can know if an app launch
has been completed if the foreground state changed from “no
app” to “some app”, providing us the approximate end time
(α) for the launch operation. The same information can be
obtained on Android 9 with a similar technique as explained
in Section 4.2. Now, if we know the duration of an app launch
event, we can subtract this from the end time to ﬁnd the ap-
proximate start time of the app launch event. To identify this
duration, we run an experiment on our victim dataset and
show that app launch takes around 379ms on average with a
standard deviation of 32.99ms, which gives us the ﬁnal range
of [α− 379− 32.99,α− 379 + 32.99]ms for all possible app
start times. For each app in our dataset, we then calculate the
DTW-based distance using each of the possible values in this
interval as the starting point of the analysis and take their
average to obtain the ﬁnal distance. Lowest of these distances
corresponds to the foreground app.
Please note that the original ProcHarvester also makes a
closed-world assumption: it assumes the app in the foreground
that is to be identiﬁed is always a known, proﬁled app. This
means that the distance reported by ProcHarvester for an
unproﬁled app by itself does not provide much value in terms
of correctly inferring the foreground app since this app’s
proﬁle is unknown by ProcHarvester. It is imperative for our
attacks to be launched only when one of our victim apps is in
the foreground. In addition, it is simply impractical to proﬁle
all existing Android apps. Hence, we need a mechanism to
extend ProcHarvester to distinguish between victim (proﬁled)
and non-victim (unproﬁled) apps at any given time. For this
purpose, we ﬁngerprint each of our victim apps (app i) by
recording the mean (µi) and the standard deviation (di) for 10
runs where the algorithm correctly identiﬁes app i to be in
the foreground. Then, if the lowest calculated distance for a
given foreground app is less than or equal to µi + di ms to its
closest match, we consider this app to be one of our victims.
In order to evaluate our foreground app inference imple-
mentation, we conducted experiments where we launched
each of the 400 apps in our dataset 10 times and reported the
overall accuracy and performance. Our experiments indicate
that our algorithm correctly infers the foreground app (i.e.,
output its identity if it is a victim app or report if it is a non-
victim app) 90% of the time. Furthermore, we ﬁnd the total
time to infer the identity of an app in the foreground (after
its launch) to be 7.44s on average with a standard deviation
of 1.62s. We consider this to be a reasonable delay for our
attacks as we expect users to stay engaged with one app be-
fore they switch to another for much longer than this duration
(18.9s or more on average) [11]. Since the foreground app
will presumably not change during the analysis, the adversary
should not have a problem targeting the identiﬁed app in their
attack after this introduced delay. In addition, please note that
the original ProcHarvester itself needs around ﬁve seconds of
procfs data to correctly compute the foreground app.
It is worth mentioning that ProcHarvester is inherently
device-dependent since an app can have distinct proﬁles for
a given procfs resource on different mobile devices, which
would affect the performance of foreground app inference.
Hence, in order to launch a “full-blown attack” that can work
on multiple mobile devices, adversaries would have to obtain
the procfs proﬁles of their victim apps on all those devices.
Here, adversaries could conveniently adopt a strategy to col-
lect the proﬁles for only the most commonly-used Android
devices in order to quickly cover a satisfactory user base. Note
that this extra proﬁle data should not greatly affect the per-
USENIX Association
29th USENIX Security Symposium    423
formance or accuracy of the foreground app inference, as an
attacker can ﬁrst identify the type of the device in real time via
utilizing existing tools [12] and only use the respective pro-
ﬁles in their analysis, avoiding DTW-based comparisons with
proﬁles belonging to other devices. In our work, we utilize
the proﬁles from only one Android device (Google Pixel) as
we primarily intend our attacks to serve as a proof of concept.
Gender
Male
Female
Table 3: Participant demographics
Participants
Participants
125
75