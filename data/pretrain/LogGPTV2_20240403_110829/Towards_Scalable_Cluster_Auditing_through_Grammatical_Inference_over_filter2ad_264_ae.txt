4
12
5
TABLE III: Summary of Winnower performance in attack scenarios.
Winnower (WIN) again reduces log size by three orders of magnitude
compared to auditd/SPADE (ASD), and improves query perfor-
mance by two orders of magnitude.
scenarios, Winnower is also able to respond to queries in
just a handful of milliseconds, compared to hundreds of
milliseconds for auditd. Figures 16-18 visualize the models
demonstrated by Winnower in each scenario. For clarity, we
have annotated each model
to draw the reader’s attention
to the attack; however, please note that the boxed subgraph
corresponds perfectly to the conﬁdence level legend, such that
an administrator would be able to accurately interpret the graph
even without this annotation.
A. ImageTragick Attack
Scenario. We ﬁrst consider an image manipulation webservice
that allows users to perform different operations on uploaded
images such as crop and resize. We created this webservice
with 10 Nginx webserver docker containers for sending/re-
ceiving web requests and 10 ImageMagick containers for
image manipulation. Unfortunately, the image manipulation
workers were susceptible to the ImageTragick10 attack. After
sending heterogeneous requests for some period, we initiated
the attack by uploading a malicious image ﬁle mal.jpg capable
of opening a remote shell back to the attacker’s host. The
uploaded ﬁle contained the following payload:
image over 0,0 0,0 ’https://127.0.0.1/x.php?x=‘bash -i >\&
/dev/tcp/X.X.X.X/9999 0>\&1‘’
The server executes this code when the image is processed by
the identify tool of the ImageMagick library, causing a bash
shell to be linked to the attacker’s remote host.
Fig. 16: The concise provenance graph generated by Winnower for
imagetragick attack.
Detection. Figure 16 shows the monitor node’s view of the
10 Available at https://imagetragick.com/
11
Fig. 15: Network throughput (log scaled) for transmitting provenance
logs to central node over time on 3 nodes during our experiments.
grammatical inference, whereas in subsequent inductions the
structure of the model is quite stable and only incremental
updates occur. As we noted in §III-F that parsing is a linear
time operation we omit parsing computation cost for brevity.
Setting aside the initial induction, these results show that
the smallest safe epoch size for our current implementation is
about 5 seconds. This value represents an upper bound on the
frequency with which the provenance model can be updated.
However, we are conﬁdent
that smaller epochs could be
supported through optimizing our prototype. Speciﬁcally, we
are currently investigating on re-implementing our induction
algorithm as a parallelizable C/C++ program.
C. Network Activity
Finally, we proﬁled the network activity of Winnower
as compared to auditd for each workﬂow. Our results are
shown in Figure 15 for MySQL benchmark. Other application
benchmarks follow the same trend. Following the ﬁrst epoch,
Winnower transmits a model that summarizes the activities of
the ﬁrst 50 seconds, leading to a brief spike in network trans-
mission. It is important to acknowledge that this behavior could
lead to minor performance issues during the initial deployment
of Winnower. However, following the ﬁrst epoch Winnower
visibly outperforms auditd/SPADE. Over the course of the
entire test (21 mins), Winnower transmits just 178KB of data
compared to 130MB by auditd/SPADE in the whole cluster.
Winnower thus offers a dramatic improvement over auditd,
which continually transmits redundant audit data and may even
saturate network links in larger clusters.
VI. CASE STUDIES
In this section, we will demonstrate the efﬁcacy of Win-
nower in assisting attack investigation by considering ﬁve
real-world attacks against a Docker Swarm cluster. For each
scenario, we setup the ﬁve node cluster as used in §V, with
one node acting as the monitor and the other four acting as
worker nodes. We then ran a series of different multi-container
applications for a period of time before launching an attack. We
ﬁrst generated the concise provenance model using Winnower,
then determined if it was adequate for attack investigation by
performing forward and backward tracing over the graph. To
ensure the completeness of Winnower, we also repeated each
trial using auditd/SPADE and compared the two results.
A summary of our ﬁndings is shown in Table III. In
addition to recording adequate context to explain all attack
 1 10 100 0 50 100 150Elapsed Time [sec]Network Tx [KB/sec]Node 3Node 2Node 1auditd/SPADEWinnower 0 50 100 150Elapsed Time [sec]Network Tx [KB/sec]Node 3Node 2Node 1auditd/SPADEWinnower 0 50 100 150Elapsed Time [sec]Network Tx [KB/sec]Node 3Node 2Node 1auditd/SPADEWinnowerNginx Worker*/etc/ImageMagick/policy.xml/usr/lib64/libuuid.so.1.3.0ImagemagickOther 35 library verticescurlbash -I /dev/tcpx.x.x.xAttack ProvenanceNginx*bash/usr/bin/identify/usr/bin/convertConﬁdence levelLegend110/uploads/**bashattack as provided by the Winnower provenance model. The
provenance graph generated by Winnower is remarkably con-
cise, allowing the administrator to easily spot the anomalous
activities annotated by the dashed line (Attack Provenance).
On the other hand with the auditd/SPADE, the administrator
would have had to navigate a provenance graph of 64,811
vertices in order to detect and investigate the attack.
B. Ransomware Attack
Scenario. In this scenario, we consider a Ransomware attack11
against a vulnerable version (<3.2.0) of the Redis database.
The attack exploits a vulnerability that permits an attacker
to view and modify the database by executing a CONFIG
command on an open TCP port. We created an online storage
service using Nginx webserver backed by Redis-3.0.0 with
sharded database. All Redis containers had public IP assigned,
but one of service was permitted to run on a default port,
which allowed an attacker to ﬁnd the vulnerable instance
through internet-wide scanning. We generated a workload for
the webservice by uploading and downloading content from
the site, then executed a ransomware attack: the attacker ﬁrst
connects directly to Redis container over the default port,
executes the Flushall command to erase the whole database,
uploads their SSH key to the database, then obtains root access
to the container by using CONFIG to copy the database to
the root’s .ssh directory and renames it to authorized keys.
After obtaining root access, the attacker connects and leaves
a note in the home directory asking for bitcoins to get the
encrypted database back.
Fig. 17: The provenance graph generated by Winnower for ran-
somware attack.
Detection. Winnower’s utility in this scenario is two-fold.
First, as Winnower generates a concise provenance model
as shown in Figure 17,
the administrator will be able to
quickly identify the malicious activity on the cluster, po-
tentially preventing the attack from spreading to the other
containers. In contrast, the raw provenance graph generated
by auditd/SPADE have 78,149 vertices. Second, by using the
complete attack provenance, the administrator will be able
to see that the database was not actually sent to internet or
encrypted, meaning that this was a fake ransomware attack
and the data was irrevocably lost.
11See
ransomware
https://duo.com/blog/over-18000-redis-instances-targeted-by-fake-
12
C. Inexperienced Administrator
Scenario.
In this case study, we consider the inexperienced
administrator of a Hadoop container cluster that runs analysis
jobs on different datasets12. The admin of the cluster left the
Docker daemon REST API TCP port open to the Internet,
permitting any remote user to create and run a container in
the cluster13. An attacker can run a reverse TCP shell from the
container, then use the container for malicious purposes such
as DDoS attacks. In this scenario, we spawned 10 Hadoop
containers executing a built-in example of distributed grep on
different datasets, then launched a reverse shell attack.
Fig. 18: The provenance graph generated by Winnower for inexperi-
enced administrator case study. We have simpliﬁed this diagram for
readability.
Investigation. The provenance model generated by Winnower
is shown in Figure 18. We have simpliﬁed this diagram
for readability by making dashed line vertices for different
library/System ﬁles; regardless, the graph is concise with 319
vertices as compared to auditd/SPADE, which generated a
graph of 87,345 vertices. The administrator can easily see in
the Winnower model that one container is acting differently
than the other workers in the cluster. The admin can then run
a backward tracing query on the suspicious vertex to produce
a complete explanation of the attack, trail as annotated by blue
dashed line, to identify the open Docker port as the method of
entry.
D. Dirty Cow Attack
Scenario. In this case study, we consider an online Distributed
Continuous Integration (CI) service such as Travis CI14 or
AppVeyor15 which automatically build and test projects. Users
can provide custom scripts which install all dependencies (e.g.
maven, etc.) and build the project. These services provide
users with a terminal-like interface to view all the logging
output generated during the project’s build process. Consider
a CI service that uses Docker and spans a new container for
12Available at https://hadoop.apache.org/docs/stable/hadoop-yarn/hadoop-
yarn-site/DockerContainerExecutor.html
13See https://threatpost.com/attack-uses-docker-containers-to-hide-persist-
plant-malware/126992/
14Available at https://travis-ci.org/
15Available at https://www.appveyor.com/
Worker*/uploads/*redis-serverx.x.x.xAttack ProvenanceNginx*bashConﬁdence levelLegend110/root/.ssh/authorized_keys*172.17.0.0/24/var/lib/redis/dump.rdb/proc/12743/stat/var/log/redis/redis.logx.x.x.xsshdbash/root/ransomware.notevim/dev/ttyOther library ﬁles/uploads/*Complete Attack Provenancejava164 other .jar ﬁle verticesbashConﬁdence levelLegend110172.17.0.3/tmp/hadoop-root/nm-local-dir/*x.x.x.xdockerdsudo/usr/lib64/libc-2.17.so31 other library ﬁle vertices share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.0.jarjava/usr/lib64/libcap.so129 other library ﬁles verticesjavajavabashOther verticessudo/usr/local/hadoop/share/*16 other java processesbash -I /dev/tcpx.x.x.xInside attacker containereach build, which is the case for Travis CI. Here, the CI
administrator needs to make sure that the user is never able
to break the isolation of the container, as this would allow
them to view source code from other (possibly proprietary)
builds. However, the base image (e.g., Ubuntu, CentOS) used
by this CI service is vulnerable to the Dirty Cow privilege
escalation bug (CVE-2016-5195) 16. Since any user can upload
custom bash scripts on the CI service this bug can be exploited
to escape isolation and read other users source code [6].
To setup the CI service, we created 10 Docker containers
with vulnerable base image kernels. We then ran the build
processes of different open source maven-based java projects
from Github. During one of the builds, we executed a Dirty
Cow attack script from [8].
MATCH (a:Agent {UID="0"}) WasControlledBy
(a: Process {name:"/bin/sh"})
Fig. 19: Provenance Policy which will be deployed on each worker
node in the cluster to monitor container breakout attacks.
Monitoring. As it is possible to express a breach of container
isolation in policy language, this scenario shows Winnower’s
utility as an active monitoring tool in addition to an adminis-
trative aid. As there is no condition under which a container
should interact with system objects outside of the container,
the administrator can deﬁne a provenance policy on each
worker node like the one shown in Figure 19. This policy
is matched when there is some /bin/sh process controlled
by UID 0. If the policy is triggered at runtime, a notiﬁcation
is sent to the administrator. Once the administrator has been
notiﬁed they can run backward tracing query on the bash vertex
to reconstruct the attack, which will aid in identifying the
vulnerable base image. One might argue that the CI service
could block all ports by using SELinux to stop such behaviour;
however, CI services cannot do that because they provide
software testing services that may require access to these ports.
In this attack scenario, since each container in the cluster
was building a different project, Winnower does not provide
a signiﬁcant decrease in log size, as shown in Table III. In
order for Winnower to work as a compression mechanism, it
would be necessary to maintain a separate provenance model
for each project, which would eliminate audit redundancy over
sequential builds.
E. Backdoor attack.
We describe this attack in §II-B and visualize the concise
provenance model in Figure 3b. Our results compared to the
auditd/SPADE are shown in Table III.
VII. RELATED WORK
In Section II-B we described the limitations with existing
provenance collection tools that Winnower addresses, and
complement the discussion on related work here.
System-level Provenance. To the best of our knowledge, this
is the ﬁrst work to study an efﬁcient system-level provenance
collection mechanism for clusters and solve the challenges
16Dirty Cow Bug is a privilege escalation bug in the Linux Kernel
discovered on October 20th, 2016. It stems from a race condition in the way
that the Linux kernel’s memory subsystem handles read only private mappings
when a Copy On Write situation is triggered.
(a)
(b)
Fig. 20: Provenance of two httpd server executions. (a) shows
normal execution, but execution (b) shows evidence of an attack.
Comparing these provenance graphs with existing techniques leads
to false alarms, a limitation that we address with Winnower.
associated with it. However,
in recent years, a signiﬁcant
progress has been made to capture system-level provenance
and leverage them for forensics [47], [61], [46], [20], [60],
[37], [67]. Winnower complements all these OS-level logging
systems. However, using existing system logs accumulate very
quickly; which makes them impractical to collect and query
logs for the scale of clusters. Winnower applies novel graph
grammars approach which substantially reduces the cost of
storing and processing logs. LogGC [51] provides ofﬂine
techniques to garbage collect redundant events which have
no forensic value. These techniques can be applied alongside
our model construction to further decrease storage overheads.
Finally, our work also complements the execution partitioning
systems such as BEEP/MPI [50], [53] which improve post-
mortem analysis by solving the problem of dependency explo-
sion. Liu et al. [52] proposed PrioTracker which accelerates
the attack causality analysis by adding priority to rare events
in attack graph construction. Winnower can be used along with
PrioTracker to reduce the overhead of storing and transmitting
provenance graphs in a large distributed system before attack
causality analysis.
Distributed System Tracing. Existing academic tools [55],
[64], [33], [16] and commercial tools [11], [10] on distributed
system tracing are mainly targeted towards runtime proﬁling,
ﬁnding limping hardware and software misconﬁgurations. Pin-
point [29] collects execution traces as paths through the system
and diagnose anomalies by generating a probabilistic context-
free grammar from the paths. However, these systems do not
provide causal relationships between kernel-level events which
is necessary for security auditing and forensics. Moreover, they
also suffer from the challenges of log storage/transmission
overhead on central node which are outlined in §II-B.
Graph Comparison Techniques. Winnower leverages graph
comparison techniques to identify similarities and differences
between provenance graphs across different executions. Graph
comparison algorithms accept two graphs G and G(cid:48) as in-
put and output a value quantifying the similarity/difference
between these two input graphs [62], [42], [24]. For our
13
falsealarmevidenceof attackfalse alarmfalsealarmis the Docker API call stack (consists of 150 LoC) which
polls Docker Swarm for different operations such as checking