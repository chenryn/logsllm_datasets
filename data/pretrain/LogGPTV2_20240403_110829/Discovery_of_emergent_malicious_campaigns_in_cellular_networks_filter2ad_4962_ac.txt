100
150
Size of the cluster
200
250
Figure 6: Cluster size distribution.
Figure 6 shows a histogram of the average size of clusters
over test windows. In total, approximately 10 clusters are
bigger than one hundred high degree nodes while 30 clusters
have the size between ten and one hundred, and around 50
clusters have a size of between ﬁve and ten nodes. Most
clusters have less than ﬁve nodes.
A new cluster is a cluster which has no overlap with any
clusters in the previous sliding window. Similarly, an obso-
lete cluster is one which has no overlap with any clusters
in the next test window. Any clusters which have non-zero
overlap with any cluster in the previous window are active
34
clusters, which means the nodes in those clusters are still
high degree nodes with users regularly communicating with
them. For active clusters, we measure the similarity between
two versions of the same cluster in diﬀerent test windows us-
ing the Jaccard similarity coeﬃcient.
Figure 7 shows the Jaccard similarity coeﬃcient (=
|A∩B|
|A|∪|B| )
for clusters in two adjacent sliding windows. If one cluster
overlaps with two clusters, which means that the cluster is
regrouped into two, the larger similarity coeﬃcient is cho-
sen. The ﬁgure shows that on an average day 85% of the
clusters do not change from one test window to the next.
Almost all of the 15% of clusters that change daily are of
the size greater than 5. Since only around 100 clusters are
of the size greater than 5, roughly ∼15 clusters change each
day.
)
J
(
F
1
0.8
0.6
0.4
0.2
0
0
0.1
0.2
0.3
0.4
Empirical CDF
0.5
0.6
Jaccard similarity (J)
0.7
0.8
0.9
1
Figure 7: Average Jaccard similarity of the same
clusters between two successive test windows (85%
of clusters remain identical).
150
100
50
s
e
z
i
s
l
l
a
h
t
i
w
s
r
e
t
s
u
l
c
f
o
r
e
b
m
u
N
0
6
4
2
0
1
2
3
4
5
1
2
3
4
5
6
10
Index of the sliding window
7
8
9
7
6
10
Index of the sliding window
8
9
11
12
13
14
15
11
12
13
14
15
3
e
z
i
s
n
a
h
t
r
e
t
a
e
r
g
s
r
e
t
s
u
l
c
f
o
r
e
b
m
u
N
Figure 8: The number of new clusters (top) and the
number of new clusters of size > 3 in 15 successive
sliding test windows.
Figure 8 shows the number of new clusters generated for
several successive sliding test windows, along with the num-
ber of clusters of size > 3. Additionally, 96% to 97% of
obsolete and new clusters are size of less than or equal to
3 nodes. Only ∼3% of new clusters are of size > 3 nodes.
Of the average ∼ 100 new clusters that are generated daily,
only ∼ 3 are large clusters per day.
Therefore, with approximately ∼ 3 new and ∼15 changed
clusters per day, the system generates a reasonable amount
of work that a human analyst should further investigate.
3.7 The Role of the Analyst
All the steps up to this stage have involved automated
processing to winnow data down as much as possible, while
retaining suspicious activity. The role of the human ana-
lyst is to decide whether a cluster presented to her is ma-
licious or benign. Figure 10 shows an example of a cluster
presented visually to an analyst. We have found that our
post-processing steps add signiﬁcant value to the decision
making process of an analyst.
At times, it is relatively easier to determine that a cluster
is not malicious by noticing patterns in the domains names
involved in the cluster. For example, some benign cluster
that we have clearly identiﬁed as such include: “current
event clusters”, “political clusters”, and “holiday clusters”.
After the analyst has removed what appear to be benign
clusters, a ﬁner level of manual analysis is required for sus-
picious clusters. The analyst can scrutinize the domains
contained within the cluster and identify malicious or fraud-
ulent intent. As with most malicious activity investigations,
a certain amount of ﬁne grained research into the event or
activity is required.
4. EVALUATION & CASE STUDIES
Traditional evaluation of a detection algorithm calls for
a true positive and false positive rate with a calculation of
the tradeoﬀ between them, typically visually illustrated in
a Receiver operating characteristic (ROC) curve. However,
the diﬃculty in establishing ground truth when dealing with
real data and our system’s role as a tool for analysts rather
than a standalone blocking/detection mechanism forces us
to look for other evaluation mechanisms. At the network
provider level, the process for blocking abusive users such
as those involved in spam and malware campaigns centers
around analysts who gather suﬃcient information before ac-
tion is taken to block.
With this reality in mind, we want to answer two ques-
tions: Does our system detect widespread attacks in the
clusters it produces, and do we miss some widespread at-
tacks? To answer the ﬁrst question, we have conﬁrmation
that two premium numbers in our large example cluster were
blocked due to fraud (details in section 4.1), and we also
successfully detected the resurge of the Android “NotComa-
patible” malware on the ﬁrst day that the malware broke
out (details in section 4.2). Furthermore, by comparing our
clusters to user reports such as SMS spam and domain repu-
tation, we observe that the number of entities in clusters be-
ing blacklisted increases over time. This demonstrates that
our system detects malicious entities ahead of the existing
blacklisting systems.
For the second question, we note that there have been a
few malware campaigns that were published in media re-
ports. Two campaigns have been successfully detected. But
the system did not detect a small campaign where malware
infects devices and controls them via commands to send SMS
spam [17]. The reason is that the malware download sites
are high degree nodes without enough overlap to be clus-
tered, and the C&C domains do not appear due to a low
volume of infected users. If the campaign had increased in
size, our algorithm would have detected the correlation in
the initial infection vectors. No other widespread mobile
malware campaigns are reported in the news and other in-
vestigated methods during our experiment period.
Growth in blacklisted members. One way to check
whether our system works is to check the members of each
cluster against several public and private blacklists, and see
if the fraction of entities in a cluster that are blacklisted
)
B
R
(
F
1
0.8
0.6
0.4
0.2
0
0
Empirical CDF
September 1st
October 5th
November 15th
0.1
0.2
0.8
0.9
The ratio of anomalous high degree nodes that are blacklisted over time (RB)
0.3
0.4
0.5
0.6
0.7
1
Figure 9: The number of anomalous high degree
nodes that are blacklisted increases over time.
somewhere goes up with time. We use 3 sources of blacklists:
• For SMS numbers, we check against 7726 data, which
is a feed of user reported SMS spam and an internal
list of numbers sending spam URLs. Both of these
data sets are noisy so we only match against numbers
that are highly likely to be spammers.
• For domain names, we check our internal URL spam
list and Web of Trust’s score [2]. Again, as user reports
are noisy we only consider high conﬁdence listings, in
this case a score of 10 or less on Web of Trust, which
means the domain is either blacklisted by Spamhaus
[1] or has many user reports.
Figure 9 shows the ratio of cluster members that are la-
belled as malicious by the blacklists above. It can be seen
that the number of blacklisted members increases over time.
Also some of our clusters are identiﬁed as 100% malicious
by the blacklists, which provides further conﬁdence that we
are detecting malicious campaigns.
Furthermore, we ran queries against domain name and
IP address lists known to belong to botnet C&C servers, to
check if any known widespread botnets, are active in our
cellular network’s IP data, but were missed by our detection
method. After checking against thousands of active fastﬂux
domain names, we only came up with a dozen users sparsely
communicating with 3 blacklisted domains. As a result, we
concluded that we did not miss any signiﬁcant known botnet
activity in the cellular network. Finally, from public media
reports and internal investigation, we found only evidence
of the one small botnet described earlier and no widespread
mobile botnet incidents in the cellular world, so to the best of
our knowledge, our system did not miss any well discovered
widespread attacks during the reported period.
In the remainder of this paper, we describe a few case
studies centered around the most interesting malicious clus-
ters encountered by us to date in the cellular network. The
purpose of these case studies is to give the reader a taste of
the types of malicious campaigns we unearthed in the cel-
lular network.
In each case, we describe why the cluster
piqued an analyst’s interest, and the manual analysis con-
ducted to dig deeper into ascertaining the true nature of the
cluster.
4.1 SMS Giftcard Scam
Suspicious cluster During July - Sept 2012, we detected
a cluster consisting of 10-digit phone numbers, SMS short-
codes and domain names. This cluster continued to evolve
35
constantly throughout this period. Over time, several enti-
ties in this cluster appeared in domain name blacklists and
the 7726 blacklist. Figure 10 shows this cluster evolving over
time starting with the day it was ﬁrst detected.
The very fact that this cluster contains at various times,
phone numbers, short codes and domain names, is interest-
ing, because it suggests activity that involves all three types
of entities. Several interesting changes occur in the cluster
from August to September. The cluster ﬁrst grows in size,
by adding several 10-digit phone numbers, which are soon
blacklisted in the 7726 blacklist as SMS spammers. New
domain names continually appear, while old ones disappear
from the cluster. One speciﬁc domain name seems to be at
the center of a star shaped region of the cluster, suggest-
ing a series of redirect that lead up to it. A shortcode then
appears and remains in the cluster, strongly correlated with
the cluster center. Successive incarnations of this cluster are
visualized in Figure 10. Figure 11 shows the Jaccard sim-
ilarity between successive versions of the cluster across a 1
month time frame.
Jaccard similarity for spam campain from Early September to Early October
1
y
t
i
r
a
l
i
m
i
s
d
r
a
c
c
a
J
0.8
0.6
0.4
0.2
0
5
10
15
20
25
30
35
Index of the sliding window
Figure 11: Jaccard similarity across successive days
for the giftcard scam cluster from early September
to early October.
Manual analysis In order to conﬁrm the malicious na-
ture of this cluster, our analyst performed a detailed analysis
of the attack starting with one of the URLs present in the
SMS messages. We found the following malicious campaign.
A carefully crafted URL with a well-known brand name
in the 3rd or 4th level domain name position is placed into
an SMS spam message promising a free gift card from that
brand. This initial URL redirects the user to another URL,
where the user is asked to enter the “winning code” provided
in the SMS spam message along with their phone number
and address in order to “claim their prize”. Next, the user
is redirected to yet another URL where they are told they
must complete a “survey” to receive the gift card. This “sur-
vey” actually elicits the user to participate in receiving one
of the products advertised on the site.