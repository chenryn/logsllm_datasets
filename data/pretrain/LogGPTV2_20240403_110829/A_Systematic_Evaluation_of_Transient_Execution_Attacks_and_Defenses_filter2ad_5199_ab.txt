28th USENIX Security Symposium    251
preface1reconstruct5trigger instruction 2transient instructions 3fixup4timearchitecturalarchitecturaltransient execution Table 1: Spectre-type attacks and the microarchitectural ele-
).
ment they exploit (
), partially target (
), or not affect (
Element
B
T
B
B
H
B
T
H
P
B
S
R
L
T
S
Attack
Spectre-PHT (Variant 1) [50]
Spectre-PHT (Variant 1.1) [48]
Spectre-BTB (Variant 2) [50]
Spectre-RSB (ret2spec) [52, 59]
Spectre-STL (Variant 4) [29]
Glossary: Branch Target Buffer (BTB), Branch History Buffer (BHB), Pattern
History Table (PHT), Return Stack Buffer (RSB), Store To Load (STL).
in the pipeline. Note that, while Meltdown-type attacks so
far exploit out-of-order execution, even elementary in-order
pipelines may allow for similar effects [86]. Essentially, the
different root cause of the trigger instruction (Spectre-type
misprediction vs. Meltdown-type fault) determines the nature
of the subsequent unauthorized transient computations and
hence the scope of the attack.
That is, in the case of Spectre, transient instructions can
only compute on data which the application is also allowed
to access architecturally. Spectre thus transiently bypasses
software-deﬁned security policies (e.g., bounds checking,
function call/return abstractions, memory stores) to leak se-
crets out of the program’s intended code/data paths. Hence,
much like in a “confused deputy” scenario, successful Spec-
tre attacks come down to steering a victim into transiently
computing on memory locations the victim is authorized to
access but the attacker not. In practice, this implies that one or
more phases of the transient execution attack ﬂow in Figure 2
should be realized through so-called code gadgets executing
within the victim application. We propose a novel taxonomy
of gadgets based on these phases in Section 5.
For Meltdown-type attacks, on the other hand, transient ex-
ecution allows to completely “melt down” architectural isola-
tion barriers by computing on unauthorized results of faulting
instructions. Meltdown thus transiently bypasses hardware-
enforced security policies to leak data that should always
remain architecturally inaccessible for the application. Where
Spectre-type leakage remains largely an unintended side-
effect of important speculative performance optimizations,
Meltdown reﬂects a failure of the CPU to respect hardware-
level protection boundaries for transient instructions. That is,
the mere continuation of the transient execution after a fault
itself is required, but not sufﬁcient for a successful Meltdown
attack. As further explored in Section 6, this has profound con-
sequences for defenses. Overall, mitigating Spectre requires
careful hardware-software co-design, whereas merely replac-
ing the data of a faulting instruction with a dummy value
sufﬁces to block Meltdown-type leakage in silicon, e.g., as it
is done in AMD processors, or with the Rogue Data Cache
Load resistance (RDCL_NO) feature advertised in recent Intel
CPUs from Whiskey Lake onwards [40].
out-of-place/
same-address-
space
in-place/
same-address-
space
Victim
Congruent
branch
s
s
e
r
d
d
A
n
o
i
s
i
l
l
o
c
Attacker
Congruent
branch
s
s
e
r
d
d
A
n
o
i
s
i
l
l
o
c
Victim branch
Shadow branch
Shared Branch Prediction State
out-of-place/
cross-address-
space
in-place/
cross-address-
space
Figure 3: A branch can be mistrained either by the victim
process (same-address-space) or by an attacker-controlled
process (cross-address-space). Mistraining can be achieved
either using the vulnerable branch itself (in-place) or a branch
at a congruent virtual address (out-of-place).
3 Spectre-type Attacks
In this section, we provide an overview of Spectre-type at-
tacks (cf. Figure 1). Given the versatility of Spectre variants in
a variety of adversary models, we propose a novel two-level
taxonomy based on the preparatory phases of the abstract
transient execution attack ﬂow in Figure 2. First, we distin-
guish the different microarchitectural buffers that can trigger
a prediction (phase 2), and second, the mistraining strategies
that can be used to steer the prediction (phase 1).
Systematization of Spectre Variants. To predict the out-
come of various types of branches and data dependencies,
modern CPUs accumulate an extensive microarchitectural
state across various internal buffers and components [19]. Ta-
ble 1 overviews Spectre-type attacks and the corresponding
microarchitectural elements they exploit. As the ﬁrst level of
our classiﬁcation tree, we categorize Spectre attacks based on
the microarchitectural root cause that triggers the mispredic-
tion leading to the transient execution:
• Spectre-PHT [48, 50] exploits the Pattern History Table
(PHT) that predicts the outcome of conditional branches.
• Spectre-BTB [50] exploits the Branch Target Buffer
(BTB) for predicting branch destination addresses.
• Spectre-RSB [52, 59] primarily exploits the Return Stack
Buffer (RSB) for predicting return addresses.
• Spectre-STL [29] exploits memory disambiguation for
predicting Store To Load (STL) data dependencies.
Note that NetSpectre [74], SGXSpectre [63], and SGXPec-
tre [13] focus on applying one of the above Spectre variants
in a speciﬁc exploitation scenario. Hence, we do not consider
them separate variants in our classiﬁcation.
Systematization of Mistraining Strategies. We now pro-
pose a second-level classiﬁcation scheme for Spectre vari-
ants that abuse history-based branch prediction (i.e., all of
the above except Spectre-STL). These Spectre variants ﬁrst
go through a preparatory phase (cf. Figure 2) where the mi-
croarchitectural branch predictor state is “poisoned” to cause
intentional misspeculation of a particular victim branch. Since
branch prediction buffers in modern CPUs [19, 50] are com-
252    28th USENIX Security Symposium
USENIX Association
monly indexed based on the virtual address of the branch
instruction, mistraining can happen either within the same
address space or from a different attacker-controlled process.
Furthermore, as illustrated in Figure 3, when only a subset of
the virtual address is used in the prediction, mistraining can
be achieved using a branch instruction at a congruent virtual
address. We thus enhance the ﬁeld of Spectre-type branch
poisoning attacks with 4 distinct mistraining strategies:
1. Executing the victim branch in the victim process (same-
address-space in-place).
2. Executing a congruent branch in the victim process (same-
address-space out-of-place).
3. Executing a shadow branch in a different process (cross-
address-space in-place).
4. Executing a congruent branch in a different process (cross-
address-space out-of-place).
In current literature [6,13,48,50], several of the above branch
poisoning strategies have been overlooked for different Spec-
tre variants. We summarize the results of an assessment of
vulnerabilities under mistraining strategies in Table 2. Our
systematization thus reveals clear blind spots that allow an
attacker to mistrain branch predictors in previously unknown
ways. As explained further, depending on the adversary’s ca-
pabilities (e.g., in-process, sandboxed, remote, enclave, etc.)
these previously unknown mistraining strategies may lead to
new attacks and/or bypass existing defenses.
3.1 Spectre-PHT (Input Validation Bypass)
Microarchitectural Element. Kocher et al. [50] ﬁrst intro-
duced Spectre Variant 1, an attack that poisons the Pattern
History Table (PHT) to mispredict the direction (taken or
not-taken) of conditional branches. Depending on the un-
derlying microarchitecture, the PHT is accessed based on a
combination of virtual address bits of the branch instruction
plus a hidden Branch History Buffer (BHB) that accumulates
global behavior for the last N branches on the same physical
core [18, 19]
Reading Out-of-Bounds. Conditional branches are com-
monly used by programmers and/or compilers to maintain
memory safety invariants at runtime. For example, consider
the following code snippet for bounds checking [50]:
if (x < len(array1)) { y = array2[array1[x] * 4096]; }
At the architectural level, this program clearly ensures that the
index variable x always lies within the bounds of the ﬁxed-
length buffer array1. However, after repeatedly supplying
valid values of x, the PHT will reliably predict that this branch
evaluates to true. When the adversary now supplies an invalid
index x, the CPU continues along a mispredicted path and
transiently performs an out-of-bounds memory access. The
above code snippet features an explicit example of a “leak
gadget” that may act as a microarchitectural covert channel:
depending on the out-of-bounds value being read, the transient
Table 2: Spectre-type attacks performed in-place, out-of-place,
same-address-space (i.e., intra-process), or cross-address-
space (i.e., cross-process).
Attack
Method
Intel
intra-process
cross-process
ARM
intra-process
cross-process
AMD
intra-process
cross-process
in-place
out-of-place
in-place
out-of-place
in-place
out-of-place
in-place
out-of-place
in-place
out-of-place
in-place
out-of-place
S p e ctre- P
B
T
T
H
S p e ctre- B
S p e ctre- R
B
S
[59]
[52, 59]
[52, 59]
[52]
[6]
[6]
[48, 50]
[48, 50]
[50]
[13]
[13, 50]
[50]
[6, 50]
[50]
L
T
S p e ctre- S
[29]
[6]
[29]
Symbols indicate whether an attack is possible and known (
and known (
tested and did not work and previously unknown or not shown (
performed with no defenses enabled.
), possible and previously unknown or not shown (
), not possible
), or
). All tests
instructions load another memory page belonging to array2
into the cache.
Writing Out-of-Bounds. Kiriansky and Waldspurger [48]
showed that transient writes are also possible by following
the same principle. Consider the following code line:
if (x < len(array)) { array[x] = value; }
After mistraining the PHT component, attackers controlling
the untrusted index x can transiently write to arbitrary out-
of-bounds addresses. This creates a transient buffer overﬂow,
allowing the attacker to bypass both type and memory safety.
Ultimately, when repurposing traditional techniques from
return-oriented programming [75] attacks, adversaries may
even gain arbitrary code execution in the transient domain by
overwriting return addresses or code pointers.
Overlooked Mistraining Strategies. Spectre-PHT attacks
so far [48, 50, 63] rely on a same-address-space in-place
branch poisoning strategy. However, our results (cf. Table 2)
reveal that the Intel, ARM, and AMD CPUs we tested are
vulnerable to all four PHT mistraining strategies. In this, we
are the ﬁrst to successfully demonstrate Spectre-PHT-style
branch misprediction attacks without prior execution of the
victim branch. This is an important contribution as it may
open up previously unknown attack avenues for restricted
adversaries.
Cross-address-space PHT poisoning may, for instance, en-
able advanced attacks against a privileged daemon process
that does not directly accept user input. Likewise, for Intel
SGX technology, remote attestation schemes have been de-
veloped [76] to enforce that a victim enclave can only be run
exactly once. This effectively rules out current state-of-the-art
SGXSpectre [63] attacks that repeatedly execute the victim
enclave to mistrain the PHT branch predictor. Our novel out-
of-place PHT poisoning strategy, on the other hand, allows us
to perform the training phase entirely outside the enclave on
USENIX Association
28th USENIX Security Symposium    253
the same physical core by repeatedly executing a congruent
branch in the untrusted enclave host process (cf. Figure 3).
3.2 Spectre-BTB (Branch Target Injection)
Microarchitectural Element. In Spectre Variant 2 [50], the
attacker poisons the Branch Target Buffer (BTB) to steer the
transient execution to a mispredicted branch target. For di-
rect branches, the CPU indexes the BTB using a subset of
the virtual address bits of the branch instruction to yield the
predicted jump target. For indirect branches, CPUs use dif-
ferent mechanisms [28], which may take into account global
branching history accumulated in the BHB when indexing
the BTB. We refer to both types as Spectre-BTB.
Hijacking Control Flow. Contrary to Spectre-PHT, where
transient instructions execute along a restricted mispredicted
path, Spectre-BTB allows redirecting transient control ﬂow
to an arbitrary destination. Adopting established techniques
from return-oriented programming (ROP) attacks [75], but
abusing BTB poisoning instead of application-level vulnera-
bilities, selected code “gadgets” found in the victim address
space may be chained together to construct arbitrary transient