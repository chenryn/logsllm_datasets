apply our challenge harvesting technique. We ﬁrst present
a storage application, then we give an example of a client
puzzle system, and, ﬁnally, we introduce a novel approach
to backward security of cryptographic signature schemes.
Remote Storage and Auditing Applications.
In the introduction we motivated our challenge harvest-
ing problem with the application of auditing remote storage
systems such as SafeStore [14]. Here we elaborate on a few
2Ideally, we would like s to be as large as the size of secu-
rity parameters used in cryptographic systems. For exam-
ple, several systems use 1024-bit RSA keys and 160-bit hash
functions which roughly corresponds to “80-bit security.”
DeriverVerifierDerivationPolicyPolicyChallenge:=H(Derivation)Challenge:=H(Derivation)Timestamp(OrFailure)Source 1Source 2Source 3…One technique that may be used to mitigate Sybil attacks
is to require that a machine solve a client puzzle in order to
gain an identity on a P2P system. A regular user will only
need to solve a single puzzle, but an attacker must solve
many in order to be eﬀective. In this setting we have two
conﬂicting goals. First, we want the client puzzle challenge
to include some fresh randomness. Otherwise, an attacker
could build up an increasing number of identities over time.
Second, we want a user’s proof of work to be veriﬁed by many
other users, but the computational eﬀort to gain an identity
should be independent of this number (i.e., we don’t want
to require the user to provide a fresh proof of work for each
veriﬁer). Ideally, the user should not even need to interact
with every party that veriﬁes his puzzle solution.
We can use our framework to provide a straightforward
solution to this problem. Let H1 and H2 be two independent
hash functions that we will model as ideal hash functions. A
node in a client puzzle system will ﬁrst derive a harvested
challenge u with appropriate freshness. Then, the node will
choose random r until H1(u|r) satisﬁes some client puzzle
condition (e.g., its ﬁrst k bits are 0’s). Then H2(u|r) = ID
will be the user’s identity in the system.
The harvested challenge was output from a random ora-
cle that had a suﬃcient amount of entropy outside of the
attacker’s control. Therefore, precomputation before deriv-
ing u will not help an attacker. Although an attacker could
always derive a diﬀerent value of u by manipulating the in-
puts from the sources he has control over (or falsifying some
parts of the derivation), this would only have the eﬀect of
calling the random oracle again and starting the client puz-
zle over.
Backward Secure Signatures.
In several applications of digital signatures a party will
sign a message along with a timestamp denoting when it
was signed. Forward secure signatures [3] are a method for
evolving a private signature key forward in time such that
if it is compromised at time t an attacker cannot use it to
sign messages at an earlier time period t0.
Here we explore the opposite idea of preventing an at-
tacker from being able to sign messages in the future if he
compromises a machine at time t. At ﬁrst this might seem
impossible, since, if an attacker steals the private key mate-
rial from a victim, there is nothing to prevent the attacker
from posing as the victim himself. However, we show how
to accomplish this in a more limited model known as the
bounded retrieval model [6].
In the bounded retrieval model we assume that an attacker
who compromises a machine will be limited in the amount
of information he can steal from the machine due to con-
straints on his bandwidth or the possibility that exﬁltrating
large amounts of data will be detected. Previous work [6]
under this model has suggested increasing the private key
material in password systems so that an attacker who only
manages to steal partial private key material will not be able
to subvert the system.
Here we show how to build a signature system that pre-
vents an attacker from forward dating a message. A user will
create n private signing key/certiﬁcate pairs (k1, c1), . . . , (kn, cn)
(The certiﬁcates can be
and store them on his machine.
signed with a signature key that is associated to the user
and then discarded.) To sign a message M , at time t the
user derives a harvested challenge u and hashes this to get
a set, S, of k indices between 1 and n (where k is a system
parameter). The user then signs M under all the private
keys in the set S and also includes the certiﬁcates for the
keys in S. A veriﬁer will check that u was derived correctly
and that all signatures verify.
If an attacker compromises a machine at time t and then
subsequently leaves, he will only be able to sign with the
keys he was able to retrieve. Therefore, if suﬃciently many
keys remain uncompromised at a future time t0, the attacker
will not be able to sign a message since he will not have all
the keys dictated by the challenge u.
4. OUR FRAMEWORK
In this section we describe a generic policy framework for
challenge harvesting that is suitable for a wide variety of ap-
plications with diﬀerent freshness and security requirements.
We believe this framework is simple enough to be used by
application developers while ﬂexible enough to adapt to a
variety of data sources, including future ones that we have
not anticipated.
4.1 Basic Operation
Tools that implement our system operate in two modes,
which correspond to the role of the deriver and the role of
the veriﬁer, as shown in Figure 1. In deriver mode, the tool
takes as input a policy ﬁle, which describes a set of content
sources and a set of policies that specify what combinations
of content from those sources will be acceptable to a veri-
ﬁer. The tool queries some of the sources and breaks the
content from each source into content chunks based on the
date and time when each piece of content was ﬁrst posted
at the source. When it has gathered enough content chunks
to satisfy the policy, the tool packages them into a deriva-
tion, which it hashes with SHA-1 to derive the harvested
challenge. The derivation is then passed to veriﬁers.
A derivation consists of a list of hex-encoded SHA-1 hashes
of content chunks from each source, together with a times-
tamp (represented as an integer in the style of the UNIX
time function) for each chunk that indicates when the data
was ﬁrst published according to the source. Time is an im-
portant aspect of both the derivation and veriﬁcation pro-
cesses. Policies may specify a maximum age for acceptable
content chunks. Derivers interpret this age relative to the
time when the derivation process began. This time (again,
in UNIX format) is included as the ﬁrst line of the derivation.
Here is the format of a derivation:
derivation_timestamp
source1_name :
source1_chunk1_hash
source1_chunk1_timestamp
source1_chunk2_hash
source1_chunk2_timestamp
...
source2_name :
source2_chunk1_hash
source2_chunk1_timestamp
...
Optionally, a chunk timestamp may be followed by a comma
and an source-speciﬁc data ﬁeld used to verify the chunk
hash.
Derivations contain the sources and chunks in a canonical
order so that the derived challenge can be deﬁned as the
SHA-1 hash of the derivation. Sources are ordered lexico-
graphically by name, and content chunks within each source
are ordered lexicographically by hash.
In veriﬁer mode, the tool again takes a policy ﬁle as in-
put, as well as a derivation created by a deriver. The tool
inspects the derivation according to the policy and attempts
to contact some of the content sources to verify a subset of
the content chunks from the derivation.
If enough of the
chunks can be veriﬁed to satisfy the policy, the tool hashes
the derivation to obtain the same challenge as the deriver.
Otherwise, the tool returns an error. Veriﬁers interpret con-
tent age constraints as relative to the timestamp included in
the derivation, and they output this timestamp along with
the derived challenge if veriﬁcation is successful. Applica-
tions can use this timestamp to decide whether the challenge
is fresh enough for their purposes.
The policy ﬁles used in our framework are speciﬁed with
a policy language that we introduced later in this section.
(A Python YACC grammar is included with Combine and
should be considered the authoritative description.)
4.2 Data Sources
Our framework abstracts all types of content providers
into a notion of a source. Sources can encapsulate many
diﬀerent kinds of data, such as news stories, stock quotes,
web pages, and blog entries, delivered in diﬀerent kinds of
formats, such as HTML, RSS, and other XML schemas.
Policy ﬁles deﬁne sources using the following syntax:
source source_name (
type = source_type
attribute = "string_value "
attribute = numeric_value
...
)
A source’s type attribute refers to a source handler mod-
ule within the tool, and all other attributes speciﬁed for the
source are passed directly to that module. Each module
oversees the way source data is retrieved, divided into con-
tent chunks, cached, used in challenge derivation, packaged
into a derivation, and applied to challenge veriﬁcation. This
level of abstraction means the framework can be extended
to support many other kinds of sources. In this section we
describe the sources we have implemented in Combine.
RSS Feeds.
RSS feeds [17] are well suited as a source for harvested
challenges. There are many feeds available—the aggrega-
tion site Technorati tracks about 69 million [18]—and they
represent many kinds of content, from newswire stories to
personal journals entries, in a consistent data format. An
RSS feed typically includes the most recent 10–50 pieces of
content posted to the site providing the feed, so tools can
retrieve several content chunks with a single HTTP request.
Each content item includes the date when it was posted or
last updated, which helps tools ensure the freshness of de-
rived challenges.4 Sites that provide popular RSS feeds are
equipped to serve a large volume of subscribers whose RSS
reader software refreshes the content at regular intervals, so
4These timestamps can sometimes be wrong, but applica-
tions that depend on freshness should create policies that
incorporate a number of sites that have a history of main-
taining accurate clocks.
they are likely to have the capacity to absorb extra load
from being used as a challenge source by a smaller number
of users.
Despite these advantages, RSS feeds also pose speciﬁc dif-
ﬁculties for our purposes. Sites publish new entries to their
RSS feed at widely varying rates—ranging from many times
an hour to once every few months. Since feeds only contain
the most recent entries, if they are updated too quickly, con-
tent may age out of the feed so fast that veriﬁers will be
unable to check them, even though they would otherwise be
fresh enough to meet the application’s needs. On the other
hand, if entries are published too infrequently, derivers may
not be able to collect enough recent content to satisfy the
policy. A similar diﬃculty stems from the tendency for sites
to update items that have already been published to a feed,
replacing the old content. If many of the entries in an RSS
feed change between derivation and veriﬁcation, the policy
may not be satisﬁed.
Clearly, not every RSS feed will be a suitable challenge
source for every application, but developers can select spe-
ciﬁc feeds based on their past publication rate and tendency
to replace entries. Applications that require ﬁne-grained
freshness over long-term veriﬁability should select feeds that
are published frequently, while ones where challenges from
longer in the past need to be veriﬁed should choose feeds that
are updated less frequently. We have conducted empirical
tests of RSS publication and update frequency that suggest
there are many feeds suitable to each kind of application.
These results are reported in Section 6.
RSS feeds are represented in policy ﬁles as sources with
the following attributes:
source source_name (
type = RSSFeed
url = "url "
min_entries = m
max_entries = n
max_age = t
)
(optional, default 1)
(optional, default ∞)
(optional, default ∞)
The url attribute speciﬁes the feed location. Derivers
will include up to max_entries content chunks from the
feed in derivations. Only chunks that are up to max_age
seconds old will be used. Veriﬁers will also check that at
least min_entries of them match entries still present in the
feed and unmodiﬁed when the derivation is veriﬁed. They
will check that the entries are dated no more than max_age
seconds before the derivation’s timestamp.
For example, this source represents an RSS feed provided
by a national newspaper:
source NYTimes (
type = RSSFeed
url = "http://www.nytimes.com/services/xml/rss/-
nyt/HomePage.xml"
min_entries = 5
max_entries = 20
max_age = 86400
)
Here, derivers will include up to 20 entries from the past
24 hours and veriﬁers require at least 5 to match.
Historical Stock Market Data.
Stock market data has been proposed as a source of public
randomness because it is widely disseminated from reputable
sources and diﬃcult to exactly predict [20]. (An adversary
who can accurately predict stock prices is likely to have
more lucrative uses for this skill than guessing harvested
challenges.) Furthermore, online sources provide daily his-
torical share prices extending years into the past. Such data
is suitable for constructing challenges with time granularity
to within one trading day that can be veriﬁed long after they
are derived.
Historical market data sources ﬁt neatly within our frame-
work. Policy ﬁles deﬁne them with the following syntax:
source source_name (
type = DailyQuotes
symbols = "ticker_symbols "
min_entries = n
(optional, default 1)
)
The deriver creates one content chunk for each quote using
data from the last full trading day. Each chunk consists of
the SHA-1 hash of the concatenation of the symbol, the
date, the opening, high, low, and closing share prices, and
the trading volume. Consistent data can be retrieved from
several diﬀerent online sources.
For example:
source TechStocks (
type = DailyQuotes
symbols = "GOOG,YHOO,MSFT,INTC,IBM"
min_entries = 4
)
Here, derivers will include content chunks for up to all
ﬁve stocks, and veriﬁers will require at least four of them
to match ﬁgures obtained from a trusted historical market
data provider for the last full trading day prior to the date
of the derivation.
Explicit Randomness Servers.
Many traditional client puzzle schemes have relied on ex-
plicit servers to issue random challenges. For some appli-
cations, it may be appropriate to use an explicit server as
the main challenge source, but to use challenges harvested
from oblivious online sources as a backup in case the server
is unavailable. Our framework can accommodate dedicated
challenge servers using the RandomServer source type. This
allows applications to create policies that use explicit ran-
domness but fail over to derived randomness for added ro-
bustness.
An explicit random server is deﬁned like this:
source AppsRandomServer (
type = RandomServer
url = "url "
max_age = t
verify_key = "filename "
)
When the tool derives a challenge from this source, it
makes an HTTP request to url. The server responds with
three lines: a 160-bit hex-encoded pseudorandom value, a
UNIX-format timestamp, and a DSA signature of the ﬁrst
two lines that can be veriﬁed with verify_key. The deriver
uses the pseudorandom value and timestamp as the sole con-
tent chunk for the server. The derivation also includes the
signature as the optional veriﬁcation value. When verifying
the challenge, the source is considered valid if the signature
can be veriﬁed with verify_key and the signed timestamp
is no more than max_age seconds older than the derivation.
Thus, the content chunk can be veriﬁed without further in-
teraction with the server.