title:Automated Bug Hunting With Data-Driven Symbolic Root Cause Analysis
author:Carter Yagemann and
Simon P. Chung and
Brendan Saltaformaggio and
Wenke Lee
Automated Bug Hunting With Data-Driven Symbolic Root
Cause Analysis
Carter Yagemann
Georgia Institute of Technology
Atlanta, Georgia, USA
Brendan Saltaformaggio
Georgia Institute of Technology
Atlanta, Georgia, USA
ABSTRACT
The increasing cost of successful cyberattacks has caused a mindset
shift, whereby defenders now employ proactive defenses, namely
software bug hunting, alongside existing reactive measures (fire-
walls, IDS, IPS) to protect systems. Unfortunately the path from
hunting bugs to deploying patches remains laborious and expen-
sive, requires human expertise, and still misses serious memory
corruptions. Motivated by these challenges, we propose bug hunt-
ing using symbolically reconstructed states based on execution
traces to achieve better detection and root cause analysis of over-
flow, use-after-free, double free, and format string bugs across user
programs and their imported libraries. We discover that with the
right use of widely available hardware processor tracing and partial
memory snapshots, powerful symbolic analysis can be used on
real-world programs while managing path explosion. Better yet,
data can be captured from production deployments of live software
on end-host systems transparently, aiding in the analysis of user
clients and long-running programs like web servers.
We implement a prototype of our design, Bunkerbuster, for Linux
and evaluate it on 15 programs, where it finds 39 instances of our
target bug classes, 8 of which have never before been reported and
have lead to 1 EDB and 3 CVE IDs being issued. These 0-days were
patched by developers using Bunkerbuster’s reports, independently
validating their usefulness. In a side-by-side comparison, our system
uncovers 8 bugs missed by AFL and QSYM, and correctly classifies
4 that were previously detected, but mislabeled by AddressSanitizer.
Our prototype accomplishes this with 7.21% recording overhead.
CCS CONCEPTS
• Security and privacy → Systems security; Software and ap-
plication security.
KEYWORDS
symbolic analysis, processor tracing, bug hunting
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior specific permission and/or a
fee. Request permissions from permissions@acm.org.
CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea
© 2021 Association for Computing Machinery.
ACM ISBN 978-1-4503-8454-4/21/11...$15.00
https://doi.org/10.1145/3460120.3485363
Simon P. Chung
Georgia Institute of Technology
Atlanta, Georgia, USA
Wenke Lee
Georgia Institute of Technology
Atlanta, Georgia, USA
ACM Reference Format:
Carter Yagemann, Simon P. Chung, Brendan Saltaformaggio, and Wenke
Lee. 2021. Automated Bug Hunting With Data-Driven Symbolic Root Cause
Analysis. In Proceedings of the 2021 ACM SIGSAC Conference on Computer
and Communications Security (CCS ’21), November 15–19, 2021, Virtual Event,
Republic of Korea. ACM, New York, NY, USA, 17 pages. https://doi.org/10.
1145/3460120.3485363
1 INTRODUCTION
As pressure on companies to swiftly identify and remediate sys-
tem vulnerabilities has increased [47], corporations have adopted
bug hunting strategies. They proactively search for and remediate
problems in their adopted software before adversaries can exploit
them in an attack [70]. Unfortunately, the path from corporate bug
hunting to developer software patch is cumbersome and laborious,
leaving less-equipped companies vulnerable.
Human bug hunters, lacking good inputs to test programs, rely
on fuzz testing (fuzzing) [23, 72, 85, 86, 110] to brute force test cases,
starting from seeds provided by the developers (e.g., regression
tests) or scraped from public databases (e.g., ImageNet [33]) that
offer limited coverage. Such tools often require manually written
scaffolding code to reach deep libraries or APIs [10, 52, 56] and rely
on crashes to signal buggy behavior [11, 93, 99, 111], which is not
always reliable [34, 37, 44]. The process is further complicated by
binaries that lack source code, requiring bug hunters to engage in
extensive reverse engineering [36, 39, 43].
Worse still, the bug hunter then needs to share their find-
ings with the software’s developers. Crashes can corrupt arti-
facts [14, 21, 38, 49, 50, 53, 65, 71, 73, 79, 89, 96, 102–105, 108, 109]
and bugs can be difficult to reproduce due to environment differ-
ences. Capturing stack traces or re-executing the crashing input
with instrumentation [57, 61, 91, 97] offers some insights, but as we
discover in an in-depth case study, the results can be incomplete,
hindering triage. Prior work shows that developers consistently
undervalue or ignore issues they do not understand [9, 46], but
without their aid, the only other remediation choices are incom-
plete stopgaps like input filters [20, 30, 76, 97] or selective function
hardening [15], which incur significant overhead [67].
However, we observe that software testing need not occur in a
vacuum. Namely, companies already have employees constantly
using the software in question, and their real-world usage already
drives the program into deep behaviors within realistic environments.
The data to automate bug hunting and reporting is already within
their reach, so why are they not using it?
Session 2A: Fuzzing and Bug Finding CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea320We hypothesize that the disconnect that occurs is due to the
traditional definition of “seed as program input” being insufficient.
While program inputs are easy to collect, they offer little insight
into how to build scaffolding, how to get from sound program states
to buggy ones, and how to explain those bugs in a meaningful way.
Instead, we hypothesize that control flow traces are the better seeds
for automating bug hunting and reporting because they can reveal
the solution to all the above problems while still being efficient
enough to collect from real user environments.
To demonstrate this, we first propose how to segment control
flow traces and save sequential memory snapshots to guide sym-
bolic analysis through code where it is otherwise susceptible to
path explosion [13, 88]. We hypothesize that this control oriented
record and replay of user sessions is suitable for discovering serious
classes of memory corruption, such as those arising from overflows,
use-after-free (UAF), double free (DF), and format string (FS) bugs.
Better still, thanks to the prevalence of hardware assisted processor
tracing1 (PT), production systems can securely capture traces with
user transparency and tolerable overhead.
Notice that while prior work has demonstrated the value of snap-
shots for bug hunting [58], they did not combine them with traces.
Without the accompanying segmented control flow traces leveraged
in our design, such systems are still susceptible to path explosion
due to loops and string manipulation, limiting their scalability in
real-world settings.
However, collecting a corpus of new seeds is only half the battle.
To reach new buggy program states, we also propose a technique
to selectively symbolize predicate data, based on the recorded con-
trol flow traces, to facilitate constrained exploration that prioritizes
certain paths while managing path explosion. To inspect deep API
calls, we propose an analysis to automatically recover parameter
prototypes, eliminating the need for human analysts to implement
scaffolding. To find bugs from benign recordings, we employ bug-
class-specific search strategies and detection techniques that check
uncovered states for symbolic indicators of buggy behavior.
The above technical contribution also brings an additional bene-
fit to our design, which is that the same symbolic constraints can
also be used to perform symbolic root cause analysis [106]. This
recently proposed technique for localizing memory corrupting bugs
has only been demonstrated in single path symbolic analysis, start-
ing from the program entry point, limiting its possible applications.
Our design shows how it can be used in a multi-path setting, start-
ing from the main program entry point or entry points to imported
library APIs, increasing its applicability.
We implement our design as a Linux prototype, named Bunker-
buster, and evaluate it on 15 programs, some of which contain
binaries compiled from over 810,000 lines of C/C++ code, invoking
1,710 imported functions and producing traces 19,392,602 basic
blocks long, on average. Bunkerbuster successfully uncovers 39
bugs, of which 8 are newly discovered by our approach. 1 EDB
and 3 CVE IDs have been issued and patched by developers, using
Bunkerbuster’s reports to independently verifying their novelty.2
In a side-by-side comparison, Bunkerbuster finds 8 bugs missed
by AFL and QSYM, and correctly classifies 4 that AddressSanitizer
1Available in Intel®, AMD®, and ARM® processors.
2We report all bugs to developers, MITRE, and Offensive Security for responsible
disclosure.
∗ /
{
c o d e r s / png . c
/ ∗
ReadMNGImage ( )
5 1 2 9 :
5 1 3 0 :
5 1 3 8 :
5 1 4 3 :
}
/ / heap o b j e c t
p r e v i o u s = image ;
mng_info−>image = image ;
ReadOneJNGImage ( mng_info ) ;
D e st r o y Im a g eL i s t ( p r e v i o u s ) ;
/ / 1 s t
f r e e
/ / 2 nd f r e e
∗ /
c o d e r s / png . c
/ ∗
ReadOneJNGImage ( MngInfo ∗ mng_info )
3 1 2 6 :
}
D e st r o y Im a g eL i s t ( mng_info−>image ) ;
{
∗ /
/ ∗ magick / l i s t . c
D e st r o yI m a ge L i s t ( Image ∗
2 3 9 :
}
DestroyImage ( images ) ;
images )
/ /
{
c a l l s
f r e e
Figure 1: Source code pertaining to CVE-2017-11403
in GraphicsMagick,
calls
ReadOneJNGImage without realizing that it may free image,
making Line 5,143 a DF bug for some paths.
summarized.
ReadMNGImage
mislabeled. Our prototype accomplishes this with 7.21% recording
overhead and manageable storage requirements. We have open
sourced our prototype and data to facilitate future work.3
2 OVERVIEW
Bunkerbuster’s analysis replaces the laborious process of proactively
hunting for and reporting software bugs in enterprise networks.
Bug hunting should not be confused with intrusion detection (IDS)
or prevention (IPS), which requires reacting swiftly to ongoing
attacks. In place of a human security expert creating a testbed to
fuzz programs or library APIs, Bunkerbuster gathers data from
end-hosts using a kernel driver, cleverly inferring input structures
and segmenting traces to achieve offline binary symbolic execution.
2.1 Real-World Example
To show how Bunkerbuster benefits a bug hunter tasked with find-
ing problems in software, consider the following example based
on CVE-2017-11403, a UAF vulnerability found in GraphicsMag-
ick. For clarity, we will explain this example using the source code
shown in Figure 1, however the real analysis is on binaries. In this
instance, the function ReadMNGImage always frees the heap object
image before returning, but what it does not account for is that a
child function it invokes, ReadOneJNGImage, can also free image
after a certain error, causing a DF.
Suppose that the bug hunter, having heard about all the recent
vulnerabilities found in image processing libraries, wants to analyze
a program his employees are using that imports the GraphicsMagick
library. Unfortunately, he is not familiar with obscure image formats
like MNG, so building fuzzer scaffolding for all of GraphicsMagick’s
APIs would be tedious, and fuzzing the entire program from startup
would be inefficient due to its complexity.
3https://github.com/carter-yagemann/arcus
Session 2A: Fuzzing and Bug Finding CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea321Figure 2: Bunkerbuster architecture. End-hosts with PT-enabled kernel drivers collect and filter traces of the target program,
forwarding novel segments to the analysis environment. Symbolic states are reconstructed and then expanded by exploration
plugins. When a bug is detected, symbolic root cause analysis pinpoints the source and produces a report.
Instead, he gives the name of the target program to the Bunker-
buster analysis system, which in turn forwards it to all the end-hosts
with the Bunkerbuster kernel driver installed, as shown in Figure 2.
These systems observe the processes being created locally and any-
time the target program starts, they configure PT for recording. As
the data is collected at the end-host, it locally segments the trace
at calls to imported library functions and hashes them on-the-fly.
Each hash is checked against a filter, and if the segment is novel, it
is forwarded for analysis.
Back at the analysis system, Bunkerbuster uses the incoming
traces along with symbolic execution to reconstruct symbolic states
for each executed basic block. Since the conditions leading to CVE-
2017-11403 are rare, these segments do not directly reach the DF
bug, but some contain invocations of the vulnerable function. Using
its search plugins containing bug-class-specific exploration strate-
gies, Bunkerbuster symbolically expands the set of reconstructed
states, yielding additional states within the same function, includ-
ing the one containing the CVE. When Bunkerbuster checks them
for memory corruption, it finds the state containing the DF. It then
switches to localizing a concise root cause. Bunkerbuster compares
the constraints leading to this buggy state against others sharing
the same predecessor guardian (i.e., conditional check) and deter-
mines the difference that makes the DF reachable. It then traces this
back through the predecessor states, pinpointing the error checking
branch. The end result is a concise, human-readable report, iden-
tifying the site of the first and second frees, and the input error
check in GraphicsMagick that caused the DF.
Notice that if no end-user ever loads an MNG image, the analysis
will not find this DF because the traces will not have any invocations
of the vulnerable function to reference. However, code that is never
invoked is a prime candidate for debloating [51, 66, 83, 84, 92],
which is outside the scope of this work. Conversely, Bunkerbuster
will cover all the code used by monitored users.
2.2 Goals & Assumptions
We focus on discovering and localizing overflow, UAF, DF, and FS
bugs within unobfuscated, benign Linux programs without access
to source code or debug symbols. The limitations imposed by this
scope are discussed further in Section 5.
We assume that the end-hosts contain PT-enabled CPUs, which
also form our trusted computing base (TCB). PT is a hardware
feature that writes directly to physical memory, bypassing all
CPU caches, and is only configurable in the privileged CPU
mode, making it a trusted platform in numerous security sys-
tems [31, 32, 40, 62, 107]. We expect collected data to encode benign
behaviors, motivating the need for bug hunting. In the event that
an end-host captures malicious activity, detection becomes easier.
We envision our system being deployed on enterprise computers
and servers, leaving mobile and embedded devices for future work.
To recover the structure of inputs to APIs as accurately as pos-
sible while covering the diverse range of possible use cases, we
consider two scenarios. The first targets open source C/C++ li-
braries, where we assume access to stub code or source headers
that define the API. This is a necessary part of any public release to
allow other developers to integrate their systems with the API. For
all other cases, we assume the most conservative scenario where
only the binary is available.
3 DESIGN & IMPLEMENTATION
In this section, we elaborate on the steps in Bunkerbuster’s record-
ing and analysis, initially presented at a high level in Subsection 2.1.
Stepping through the workflow sequentially, Subsection 3.1 de-
scribes how the end-hosts record and filter the PT traces that the
analysis uses to recover valid program execution paths. Subsec-
tion 3.2 then describes how memory snapshots are taken at the
end-host and how the analysis selectively symbolizes them to boot-
strap symbolic execution. Given a symbolized snapshot as a starting
state and a matching trace segment, Subsection 3.3 describes how
to recover symbolic representations of all the intermediate program
states along the traced path at basic block granularity.
With a linear sequence of symbolic states for the recorded path
constructed, we then describe how to explore additional paths, pri-
oritized using search strategies based on our domain knowledge of
our target bug classes. We also describe how Bunkerbuster uses the
symbolic constraints for the states to detect and then localize bugs.
Since our techniques are bug-class-specific, we split our description
between UAF/DF, which arise from temporal memory safety vio-
lations, and overflow/FS, which arise from spatial memory safety
violations, in Subsections 3.4 and 3.5, respectively.
3.1 Capturing & Filtering Traces
One technical challenge Bunkerbuster has to overcome is how to
efficiently, securely, and transparently record user sessions. To this
end, we center our design around PT, and then propose a novel way
of hashing recorded segments so redundant ones can be discarded.
UserProgramStateReconstructionAnalysis EnvironmentVulnerabilityModulesDetectionReportingEnd-Host KernelCPUIntel PTPT TraceMemorySnapshotsSideband0011101010011101Main0x40000libc.so0x7f2000Sideband12,43,5678APIHooks0011FilterModuleExplorationRootCauseTracesSnapshotsMultiplexerSession 2A: Fuzzing and Bug Finding CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea322However, before explaining filtering, it is important to understand
what PT is and how Bunkerbuster uses it. For brevity, we will focus
on Intel’s implementation of PT, however similar features exist in