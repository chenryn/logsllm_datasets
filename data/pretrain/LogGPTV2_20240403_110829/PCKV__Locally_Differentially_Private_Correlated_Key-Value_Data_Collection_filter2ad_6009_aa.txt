title:PCKV: Locally Differentially Private Correlated Key-Value Data Collection
with Optimized Utility
author:Xiaolan Gu and
Ming Li and
Yueqiang Cheng and
Li Xiong and
Yang Cao
PCKV: Locally Differentially Private Correlated 
Key-Value Data Collection with Optimized Utility
Xiaolan Gu and Ming Li, University of Arizona; Yueqiang Cheng, Baidu X-Lab; 
Li Xiong, Emory University; Yang Cao, Kyoto University
https://www.usenix.org/conference/usenixsecurity20/presentation/gu
This paper is included in the Proceedings of the 29th USENIX Security Symposium.August 12–14, 2020978-1-939133-17-5Open access to the Proceedings of the 29th USENIX Security Symposium is sponsored by USENIX.PCKV: Locally Differentially Private Correlated Key-Value
Data Collection with Optimized Utility
Xiaolan Gu
University of Arizona
PI:EMAIL
Ming Li
University of Arizona
PI:EMAIL
Yueqiang Cheng
Baidu X-Lab
PI:EMAIL
Li Xiong
Emory University
PI:EMAIL
Abstract
Data collection under local differential privacy (LDP) has
been mostly studied for homogeneous data. Real-world appli-
cations often involve a mixture of different data types such
as key-value pairs, where the frequency of keys and mean
of values under each key must be estimated simultaneously.
For key-value data collection with LDP, it is challenging to
achieve a good utility-privacy tradeoff since the data contains
two dimensions and a user may possess multiple key-value
pairs. There is also an inherent correlation between key and
values which if not harnessed, will lead to poor utility. In this
paper, we propose a locally differentially private key-value
data collection framework that utilizes correlated perturba-
tions to enhance utility. We instantiate our framework by two
protocols PCKV-UE (based on Unary Encoding) and PCKV-
GRR (based on Generalized Randomized Response), where
we design an advanced Padding-and-Sampling mechanism
and an improved mean estimator which is non-interactive.
Due to our correlated key and value perturbation mechanisms,
the composed privacy budget is shown to be less than that
of independent perturbation of key and value, which enables
us to further optimize the perturbation parameters via bud-
get allocation. Experimental results on both synthetic and
real-world datasets show that our proposed protocols achieve
better utility for both frequency and mean estimations under
the same LDP guarantees than state-of-the-art mechanisms.
1 Introduction
Differential Privacy (DP) [12, 13] has become the de facto
standard for private data release. It provides provable privacy
protection, regardless of the adversary’s background knowl-
edge and computational power [8]. In recent years, Local
Differential Privacy (LDP) has been proposed to protect pri-
vacy at the data collection stage, in contrast to DP in the
centralized setting which protects data after it is collected and
stored by a server. In the local setting, the server is assumed
to be untrusted, and each user independently perturbs her raw
Yang Cao
Kyoto University
PI:EMAIL
Spider-Man, 3.0
The Godfather, 4.0
Man in Black, 4.5
Spider-Man, 3.5
Man in Black, 3.5
The Godfather, 5.0
(cid:1709)
(cid:1709)
(cid:1709)
(cid:1709)
Perturbed 
Data
Analysis
Movies
# Ratings Avg. Rating
Man in Black
Spider-Man
The Godfather
(cid:1709)
1200
1000
200
(cid:1709)
4.1
3.3
4.7
(cid:1709)
Figure 1: A motivating example (movie rating system).
Ratings are in the range [1, 5]
data using a privacy-preserving mechanism that satisﬁes LDP.
Then, the server collects the perturbed data from all users to
perform data analytics or answer queries from users or third
parties. The local setting has been widely adopted in practice.
For example, Google’s RAPPOR [14] has been employed in
Chrome to collect web browsing behavior with LDP guaran-
tees; Apple is also using LDP-based mechanisms to identify
popular emojis, popular health data types, and media playback
preference in Safari [5].
Early works under LDP mainly focused on simple statis-
tical queries such as frequency/histogram estimation on cat-
egorical data [22] and mean estimation of numerical data
[9, 11, 16]. Later works studied more complex queries or
structured data, such as frequent item/itemset mining of item-
set data [17, 23], computing mean value over a single numeric
attribute of multidimensional data [19, 21, 26], and generating
synthetic social graphs from graph data [18]. However, few of
them studied the hybrid/heterogeneous data types or queries
(e.g., both categorical and numerical data). Key-value data is
one such example, which is widely encountered in practice.
As a motivating example, consider a movie rating system
(shown in Figure 1), each user possesses multiple records of
movies (the keys) and their corresponding ratings (the values),
that is, a set of key-value pairs. The data collector (the server)
can aggregate the rating records from all users and analyze
the statistical property of a certain movie, such as the ratio of
people who watched this movie (frequency) and the average
rating (value mean). Then, the server (or a third party) can
provide recommendations by choosing movies with both high
frequencies and large value means.
USENIX Association
29th USENIX Security Symposium    967
The main challenges to achieve high utility for key-value
data collection under LDP are two-fold: multiple key-value
pairs possessed by each user and the inherent correlation be-
tween the key and value. For the former, if all the key-value
pairs of a user are reported to the server, each pair will split
the limited privacy budget ε (the larger ε is, the more leakage
is allowed), which requires more noise/perturbation for each
pair. For the latter, correlation means reporting the value of
a key also discloses information about the presence of that
key. If the key and value are independently perturbed each
under ε-LDP, overall it satisﬁes 2ε-LDP according to sequen-
tial composition, which means more perturbation is needed
for both key and value to satisfy ε-LDP overall. Intuitively,
jointly perturbing key and value by exploiting such correla-
tion may lead to less overall leakage; however, it is non-trivial
to design such a mechanism that substantially improves the
budget composition.
Recently, Ye et al. [25] are the ﬁrst to propose PrivKVM to
estimate the frequency and mean of key-value data. Because
of key-value correlation, they adopt an interactive protocol
with multiple rounds used to iteratively improve the estima-
tion of a key’s mean value. The mean estimation in PrivKVM
is shown to be unbiased when the number of iterations is
large enough. However, it has three major limitations. First,
multiple rounds will enlarge the variance of mean estimation
(as the privacy budget is split in each iteration) and reduce
the practicality (since users need to be online). Second, they
use a sampling protocol that samples an index from the do-
main of all keys to address the ﬁrst challenge, which does
not work well for a large key domain (explained in Sec. 4.2).
Third, although their mechanism considers the correlation
between key and value, it does not lead to an improved budget
composition for LDP (discussed in Sec. 5.2).
In this paper, we propose a novel framework for Locally
Differentially Private Correlated Key-Value (PCKV) data
collection with a better utility-privacy tradeoff. It enhances
PrivKVM in four aspects, where the ﬁrst three address the
limitations of PrivKVM, and the last one further improves the
utility based on optimized budget allocation.
First, we propose an improved mean estimator which only
needs a single-round. We divide the calibrated sum of values
of a certain key by the calibrated frequency of that key (whose
expectation is the true frequency of keys), unlike PrivKVM
which uses uncalibrated versions of both (value sum and fre-
quency) that is skewed by inputs from the fake keys and their
values. To ﬁll the values of fake keys, we only need to ran-
domly generate values with zero mean (which do not change
the expectation of estimated value sum), eliminating the need
to iteratively estimate the mean for fake value generation. Al-
though the division of two unbiased estimators is not unbiased
in general, we show that it is a consistent estimator (i.e., the
bias converges to 0 when the number of users increases). We
also propose an improved estimator to correct the outliers
when estimation error is large under a small ε.
Second, we adapt an advanced sampling protocol called
Padding-and-Sampling [23] (originally used in itemset data)
to sample one key-value pair from the local pairs that are
possessed by the user to make sure most of sampled data
are useful. Such an advanced sampling protocol can enhance
utility, especially for a large domain size.
Third, as a byproduct of uniformly random fake value gen-
eration (when a non-possessed key is reported as possessed),
we show that the proposed correlated perturbation strategy
consumes less privacy budget overall than the budget sum-
mation of key and value perturbations, by deriving a tighter
bound of the composed privacy budget (Theorem 2 and The-
orem 3). It can provide a better utility-privacy tradeoff than
using the basic sequential composition of LDP which assumes
independent mechanisms. Note that PrivKVM directly uses
sequential composition for privacy analysis.
Fourth, since the Mean Square Error (MSE) of frequency
and mean estimations in our scheme can be theoretically ana-
lyzed (in Theorem 4) with respect to the two privacy budgets
of key and value perturbations, it is possible to ﬁnd the opti-
mized budget allocation with minimum MSE under a given
privacy constraint (budget). However, the MSEs depend on
the true frequency and value mean that are unknown in prac-
tice. Thus, we derive near-optimal privacy budget allocation
and perturbation parameters in closed-form (Lemma 2 and
Lemma 3) by minimizing an approximate upper bound of the
MSE. Our near-optimal allocation is shown (in both theoreti-
cal and empirical) to outperform the naive budget allocation
with an equal split.
Main contributions are summarized as follows:
(1) We propose the PCKV framework with two mecha-
nisms PCKV-UE and PCKV-GRR under two baseline per-
turbation protocols: Unary Encoding (UE) and Generalized
Randomized Response (GRR). Our scheme is non-interactive
(compared with PrivKVM) as the mean of values is estimated
in one round. We theoretically analyze the expectation and
MSE and show its asymptotic unbiasedness.
(2) We adapt the Padding-and-Sampling protocol [23] for
key-value data, which handles large domain better than the
sampling protocol used in PrivKVM.
(3) We show the budget composition of our correlated per-
turbation mechanism, which has a tighter bound than using
the sequential composition of LDP.
(4) We propose a near-optimal budget allocation approach
with closed-form solutions for PCKV-UE and PCKV-GRR un-
der the tight budget composition. The utility-privacy tradeoff
of our scheme is improved by both the tight budget composi-
tion and the optimized budget allocation.
(5) We evaluate our scheme using both synthetic and real-
world datasets, which is shown to have higher utility (i.e., less
MSE) than existing schemes. Results also validate the correct-
ness of our theoretical analysis and the improvements of the
tight budget composition and optimized budget allocation.
968    29th USENIX Security Symposium
USENIX Association
2 Related Work
The main task of local differential privacy techniques is to
analyze some statistic information from the data that has
been perturbed by users. Erlingsson et al. [14] developed
RAPPOR satisfying LDP for Chrome to collect URL click
counts. It is based on the ideas of Randomized Response
[24], which is a technique for collecting statistics on sensitive
queries when a respondent wants to retain conﬁdentiality.
In the basic RAPPOR, they adopt unary encoding to obtain
better performance of frequency estimation. Wang et al. [22]
optimized the parameters of basic RAPPOR by minimizing
the variance of frequency estimation. There are a lot of works
that focus on complex data types and complex analysis tasks
under LDP. Bassily and Smith [6] proposed an asymptotically
optimal solution for building succinct histograms over a large
categorical domain under LDP. Qin et al. [17] proposed a
two-phase work named LDPMiner to achieve the heavy hitter
estimation (items that are frequently possessed by users) over
the set-valued data with LDP, where each user can have any
subset of an item domain with different length. Based on the
work of LDPMiner, Wang et al. [23] studied the same problem
and proposed a more efﬁcient framework to estimate not only
the frequent items but also the frequent itemsets.
To the best of our knowledge, there are only two works on
key-value data collection under LDP. Ye et al. [25] are the
ﬁrst to propose PrivKV, PrivKVM, and PrivKVM+, where
PrivKVM iteratively estimates the mean to guarantee the un-
biasedness. PrivKV can be regarded as PrivKVM with only
one iteration. The advanced version PrivKVM+ selects a
proper number of iterations to balance the unbiasedness and
communication cost. Sun et al. [20] proposed another estima-
tor for frequency and mean under the framework of PrivKV
and several mechanisms to accomplish the same task. They
also introduced conditional analysis (or the marginal statis-
tics) of key-value data for other complex analysis tasks in
machine learning. However, both of them use the naive sam-
pling protocol and neither of them analyzes the tighter budget
composition caused by the correlation between perturbations
nor considers the optimized budget allocation.
Deﬁnition 1 (Local Differential Privacy (LDP) [10]). For
a given ε ∈ R
+, a randomized mechanism M satisﬁes ε-LDP
if and only if for any pair of inputs x,x
, and any output y, the
probability ratio of outputting the same y should be bounded
(cid:3)
Pr(M (x) = y)
Pr(M (x(cid:3)) = y)
(cid:2) eε
(1)
Intuitively, given an output y of a mechanism, an adversary
cannot infer with high conﬁdence (controlled by ε) whether
(cid:3), which provides plausible deniability for
the input is x or x
individuals involved in the sensitive data. Here, ε is a parame-
ter called privacy budget that controls the strength of privacy
protection. A smaller ε indicates stronger privacy protection
because the adversary has lower conﬁdence when trying to
(cid:3). A very good property of
distinguish any pair of inputs x,x
LDP is sequential composition, which guarantees the overall
privacy for a sequence of mechanisms that satisfy LDP.
Theorem 1 (Sequential Composition of LDP [15]). If a
randomized mechanism Mi : D → Ri satisﬁes εi-LDP for
i = 1,2,··· ,k, then their sequential composition M : D →
R1 × R2 ×···× Rk deﬁned by M = (M1,M2,··· ,Mk) satis-
ﬁes (∑k
i=1 εi)-LDP.
According to sequential composition, a given privacy bud-
get for a computation task can be split into multiple portions,
where each portion corresponds to the budget for a sub-task.
3.2 Mechanisms under LDP
Randomized Response. Randomized Response (RR) [24]
is a technique developed for the interviewees in a survey to
return a randomized answer to a sensitive question so that
the interviewees can enjoy plausible deniability. Speciﬁcally,
each interviewee gives a genuine answer with probability p
or gives the opposite answer with probability q = 1− p. In
order to satisfy ε-LDP, the probability is selected as p = eε
eε+1.
RR only works for binary data, but it can be extended to
apply for the general category set {1,2,··· ,d} by Generalized
Randomized Response (GRR) or Unary Encoding (UE).
Generalized Randomized Response. The perturbation
function in Generalized Randomized Response (GRR) [22] is
(cid:2)
p = eε
eε+d−1
q = 1−p
,
d−1
,
if y = x
if y (cid:5)= x
3 Preliminaries
Pr(M (x) = y) =
3.1 Local Differential Privacy
In the centralized setting of differential privacy, the data ag-
gregator (server) is assumed to be trusted who possesses all
users’ data and perturbs the query answers. However, this
assumption does not always hold in practice and may not
be convincing enough to the users. In the local setting, each
user perturbs her input x using a mechanism M and uploads
y = M (x) to the server for data analysis, where the server can
be untrusted because only the user possesses the raw data of
herself; thus the server has no direct access to the raw data.
where x,y ∈ {1,2,··· ,d} and the values of p and q guarantee
ε-LDP of the perturbation (because p
q
Unary Encoding. The Unary Encoding (UE) [22] converts
an input x = i into a bit vector x = [0,··· ,0,1,0,··· ,0] with
length d, where only the i-th position is 1 and other positions
are 0s. Then each user perturbs each bit of x independently
with the following probabilities (q (cid:2) 0.5 (cid:2) p)
= eε).
(cid:2)
Pr(y[k] = 1) =
p,
q,
if x[k] = 1
if x[k] = 0
(∀k = 1,2,··· ,d)
USENIX Association
29th USENIX Security Symposium    969
where y is the output vector with the same size as vector x.
It was shown in [22] that this mechanism satisﬁes LDP with
ε = ln p(1−q)
(1−p)q. The selection of p and q under a given privacy
budget ε varies for different mechanisms. For example, the
eε/2+1 and q = 1− p, while
basic RAPPOR [14] assigns p = eε/2
the Optimized Unary Encoding (OUE) [22] assigns p = 1
2 and
q = 1
eε+1, which is obtained by minimizing the approximate
variance of frequency estimation.
Frequency Estimation for GRR, RAPPOR and OUE.
After receiving the perturbed data from all users (with size
n), the server can compute the observed proportion of users
who possess the i-th item (or i-th bit), denoted by fi. Since
the perturbation is biased for different items (or bit-0 and
bit-1), the server needs to estimate the observed frequency by
an unbiased estimator ˆfi = fi−q
p−q , whose Mean Square Error
(MSE) equals to its variance [22]
= Var[ ˆfi] = q(1− q)
n(p− q)2
+ f
∗
i
(1− p− q)
n(p− q)
MSE ˆfi
∗
i
where f
is the ground truth of the frequency for item i.
4 Key-Value Data Collection under LDP
4.1 Problem Statement
System Model. Our system model (shown in Figure 1) in-
volves one data server and a set of users U with size |U| = n.
Each user possesses one or multiple key-value pairs (cid:8)k,v(cid:9),
where k ∈ K (the domain of key) and v ∈ V (the domain
of value). We assume the domain size of key is d, i.e.,
K = {1,2,··· ,d}, and domain of value is V = [−1,1] (any
bounded value space can be linearly transformed into this
domain). The set of key-value pairs possessed by a user is
denoted as S (or Su for a speciﬁc user u ∈ U). After collecting
the perturbed data from all users, the server needs to estimate
the frequency (the proportion of users who possess a certain
key) and the value mean (the averaged value of a certain key
from the users who possess such key), i.e.,
((cid:8)k,·(cid:9))
f
∑u∈U 1Su
n
∗
k =
((cid:8)k,·(cid:9)) is 1 when (cid:8)k,·(cid:9) ∈ Su and is 0 otherwise.
∗
, m
k =
∑u∈U,(cid:8)k,v(cid:9)∈Su v
n· f ∗
k
where 1Su
Threat Model. We assume the server is untrusted and each
user only trusts herself because the privacy leakage can be
caused by either unauthorized data sharing or breach due to
hacking activities. Therefore, the adversary is assumed to have
access to the output data of all users and know the perturbation
mechanism adopted by the users. Note that we assume all
users are honest in following the perturbation mechanism,
thus we do not consider the case that some users maliciously
upload bad data to fool the server.