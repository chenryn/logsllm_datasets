### System Info
transformers-cli env
  * `transformers` version: 4.24.0
  * Platform: Linux-5.4.0-99-generic-x86_64-with-glibc2.17
  * Python version: 3.8.12
  * Huggingface_hub version: 0.10.1
  * PyTorch version (GPU?): 1.12.1+cu102 (True)
  * onnxruntime-gpu: 1.13.1
  * Tensorflow version (GPU?): not installed (NA)
  * Flax version (CPU?/GPU?/TPU?): not installed (NA)
  * Jax version: not installed
  * JaxLib version: not installed
  * Using GPU in script?: 
  * Using distributed or parallel set-up in script?: 
### Who can help?
ONNX model conversion: @morgan
### Information
  * The official example scripts
  * My own modified scripts
### Tasks
  * An officially supported task in the `examples` folder (such as GLUE/SQuAD, ...)
  * My own task or dataset (give details below)
### Reproduction
This command line:
    python -m transformers.onnx --model pszemraj/long-t5-tglobal-base-16384-book-summary --feature seq2seq-lm-with-past --preprocessor tokenizer --framework pt .
Gives me the following error during export validation:
    Validating ONNX model...
    Floating point exception (core dumped)
### Expected behavior
Having a usable and validated ONNX model.