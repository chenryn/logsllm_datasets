LLDOS 2.0.2
DMZ
DMZ
Inside
Inside
93.18% 94.74% 92.31%
100%
70.69% 85.71% 48.00% 83.33%
93.18% 94.74% 66.67% 62.50%
93.18% 94.74% 66.67% 62.50%
Ms (original)
Ms (sanitized)
Mc (original)
Mc (sanitized)
#alerts
#observable attacks , and false alert rate as 1− #true alerts
In the second set of experiments, our goal is to ver-
ify whether correlation methods can help us differentiate
between true and false alerts. We conjecture that corre-
lated alerts are more likely to be true alerts, and false alerts
have less chance to be correlated. This conjecture has
been experimentally veriﬁed in [11] when original alerts
are available. We try to see the results when alerts are
sanitized. Similar to [11], we compute detection rate as
#detected attacks
. We cal-
culated detection rates and false alert rates for RealSecure
network sensor, the correlation approach based on original
datasets, and the correlation approach (our optimistic ap-
proach) based on sanitized datasets. The results are shown
in Table 3. In Table 3, the numbers of alerts for correla-
tion approaches are the numbers of correlated alerts. We
observe that our optimistic approach still has the ability to
greatly reduce false alert rates, while slightly sacriﬁcing de-
tection rates. In addition, comparing the detection rates and
false alert rates, the approach based on original datasets is
slightly better than our optimistic approach since original
datasets have more precise information than sanitized ones.
In the third set of experiments, our goal is to evaluate the
effectiveness of the aggregation to alert correlation graphs.
Due to space constraint, we only show one case for LL-
DOS 1.0 inside dataset. We aggregated the alert correlation
graph in Figure 3, where we set temporal constraint δ = ∞
and probability threshold θ = 0.1. The result is shown in
Figure 4. In Figure 4, we notice that some false alerts are
ruled out (e.g., Email Debug67705), which is highly prefer-
able. However, we also observe that some true alerts are
pruned (e.g., three Sadmind Ping alerts), which is undesir-
able. Though it is possible to mitigate this undesirable case
through setting a lower probability threshold, we can never
guarantee that only false alerts will be ruled out. Thus the
aggregation should be applied with caution. The alert corre-
lation graphs created from the optimistic approach and the
aggregated correlation graphs are complementary to each
other, and they should be referred to each other to better
understand the security threats.
Proceedings of the 21st Annual Computer Security Applications Conference (ACSAC 2005) 
1063-9527/05 $20.00 © 2005 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 12:08:53 UTC from IEEE Xplore.  Restrictions apply. 
FTP_Syst67211
FTP_Syst67114
FTP_Syst67214
FTP_Syst67243
FTP_Syst67170
Sadmind_Ping67341
Sadmind_Ping67343
FTP_Syst67399
Email_Almail_Overflow67525
Sadmind_Amslverify_Overflow67434
Sadmind_Amslverify_Overflow67438
Email_Almail_Overflow67292
Sadmind_Amslverify_Overflow67436
Sadmind_Amslverify_Overflow67442
Sadmind_Amslverify_Overflow67432
Sadmind_Amslverify_Overflow67440
Sadmind_Amslverify_Overflow67430
Email_Almail_Overflow67304
Email_Almail_Overflow67302
Email_Almail_Overflow67529
Email_Almail_Overflow67533
Sadmind_Amslverify_Overflow67428
Mstream_Zombie67563
Mstream_Zombie67554
Rsh67539
Rsh67535
Rsh67536
Rsh67538
Rsh67562
Rsh67558
Rsh67559
Rsh67560
Rsh67553
Mstream_Zombie67777
Stream_DoS67773
Email_Almail_Overflow67676
Email_Almail_Overflow67628
Email_Almail_Overflow67635
Email_Debug67705
Email_Almail_Overflow67672
Mstream_Zombie67776
Sadmind_Ping67286
Sadmind_Amslverify_Overflow67424
Sadmind_Amslverify_Overflow67417
Sadmind_Amslverify_Overflow67420
Sadmind_Amslverify_Overflow67422
Sadmind_Amslverify_Overflow67416
Sadmind_Amslverify_Overflow67426
Rsh67542
Rsh67545
Rsh67546
Rsh67549
Rsh67547
Rsh67550
Rsh67540
Rsh67543
Mstream_Zombie67767
Mstream_Zombie67537
Figure 3. An alert correlation graph in LLDOS 1.0 inside dataset
Table 3. Detection rates and false alert rates in our experiments
Detection approach
LLDOS 1.0
LLDOS 2.0.2
RealSecure
# alerts
Correlation for original datasets
Correlation for sanitized datasets
Detection rate
Correlation for original datasets
Correlation for sanitized datasets
RealSecure
False alert rate
Correlation for original datasets
Correlation for sanitized datasets
RealSecure
Inside
922
44
58
DMZ
891
57
63
Inside
489
13
25
DMZ
425
5
6
61.67% 57.30% 80.00% 57.14%
60.00% 56.18% 66.67% 42.86%
60.00% 56.18% 66.67% 42.86%
95.23% 93.60% 96.73% 98.59%
6.82%
5.26% 23.08% 40.00%
29.31% 14.29% 60.00% 50.00%
FTP_Syst1
Sadmind_Amslverify_Overflow2
Email_Almail_Overflow3
Rsh4
Mstream_Zombie5
Stream_DoS6
Figure 4. Aggregation to the alert correlation graph in Figure 3
5 Related Work
To our best knowledge, [7] is the only paper that explic-
itly addresses privacy issues in alert correlation. This ap-
proach is complementary to ours. DShield lets audit log
submitters perform partial or complete obfuscation to des-
tination IP addresses to sanitize sensitive information. Our
Proceedings of the 21st Annual Computer Security Applications Conference (ACSAC 2005) 
1063-9527/05 $20.00 © 2005 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 12:08:53 UTC from IEEE Xplore.  Restrictions apply. 
approach can be considered an extension to the DShield ap-
proach; the sanitization process in our approach is guided
by the desirable entropy, which can be determined by the
privacy policy, and thus leaves maximum allowable infor-
mation for further analysis.
Our work is also closely related to the k-Anonymity ap-
proaches [15, 18] where an entity’s information may be re-
leased only if there exist at least k − 1 other entities in
the released data that are indistinguishable from this en-
tity. These approaches also apply generalization hierarchies
to help obfuscate attributes, where k is the pre-deﬁned pa-
rameter to control the generalization process. Our approach
differs in that we use entropy to control the attribute san-
itization as well as to help design satisfactory concept hi-
erarchies. Moreover, we also study methods to correlate
sanitized alerts.
We notice that several other techniques may also be
used to protect the privacy of alerts, such as data pertur-
bation techniques [14, 6] used in statistical databases [1],
and privacy-preserving data mining techniques [2].
6 Conclusion and Future Work
In this paper, we proposed a concept hierarchy based ap-
proach for privacy-preserving alert correlation.
It works
in two phases. The ﬁrst phase is entropy guided alert
sanitization. We sanitize sensitive attributes through con-
cept hierarchies, where original attribute values are gener-
alized to high-level concepts to introduce uncertainty into
the datasets, and also partially maintain attribute seman-
tics. We further proposed to use entropy and differential
entropy to measure the uncertainty of sanitized attributes,
and also guide the generalization of original attributes. The
second phase is sanitized alert correlation, where we focus
on deﬁning similarity functions between sanitized attributes
and building attack scenarios from sanitized alerts.
There are several future research directions. One of the
focuses in this paper is to deﬁne similarity functions for san-
itized attributes. Our results are still preliminary. We are
not clear how to get new similarity functions if the heuris-
tics between original attributes are very complex. We notice
that alert correlation graphs constructed from our optimistic
approach may include false prepare-for relations, we will
investigate how to further reﬁne them in our future work.
References
[1] N. Adam and J. Wortmann. Security-control methods for
statistical databases: A comparison study. ACM Computing
Surveys, 21(4):515–556, 1989.
[2] R. Agrawal and R. Srikant. Privacy-preserving data min-
In Proceedings of the 2000 ACM SIGMOD Interna-
ing.
tional Conference on Management of Data, May 2000.
[3] T. Cover and J. Thomas. Elements of Information Theory.
John Wiley & Sons, Inc., 1991.
[4] F. Cuppens and A. Miege. Alert correlation in a cooperative
intrusion detection framework. In Proceedings of the 2002
IEEE Symposium on Security and Privacy, May 2002.
[5] H. Debar and A. Wespi. Aggregation and correlation of
intrusion-detection alerts. In Recent Advances in Intrusion
Detection, LNCS 2212, pages 85 – 103, 2001.
[6] C. Liew, U. Choi, and C. Liew. A data distortion by proba-
bility distribution. ACM Transactions on Database Systems,
10(3):395–411, September 1985.
[7] P. Lincoln, P. Porras, and V. Shmatikov. Privacy-preserving
sharing and correlation of security alerts. In Proceedings of
13th USENIX Security Symposium, August 2004.
[8] MIT Lincoln Lab. 2000 DARPA intrusion detection scenario
http://www.ll.mit.edu/IST/
speciﬁc datasets.
ideval/data/2000/2000 data index.html,
2000.
[9] B. Morin and H. Debar. Correlation of intrusion symptoms:
an application of chronicles. In Proceedings of the 6th In-
ternational Conference on Recent Advances in Intrusion De-
tection (RAID’03), September 2003.
[10] B. Morin, L. M´e, H. Debar, and M. Ducass´e. M2D2: A
formal data model for IDS alert correlation. In Proceedings
of the 5th International Symposium on Recent Advances in
Intrusion Detection (RAID 2002), pages 115–137, 2002.
[11] P. Ning, Y. Cui, and D. S. Reeves. Constructing attack sce-
narios through correlation of intrusion alerts. In Proceedings
of the 9th ACM Conference on Computer and Communica-
tions Security, pages 245–254, Washington, D.C., Novem-
ber 2002.
[12] P. Ning and D. Xu. Hypothesizing and reasoning about at-
tacks missed by intrusion detection systems. ACM Trans-
actions on Information and System Security, 7(4):591–627,
November 2004.
[13] P. Porras, M. Fong, and A. Valdes. A mission-impact-based
approach to INFOSEC alarm correlation.
In Proceedings
of the 5th International Symposium on Recent Advances in
Intrusion Detection (RAID 2002), pages 95–114, 2002.
[14] S. Reiss. Practical data-swapping: The ﬁrst steps. ACM
Transactions on Database Systems, 9(1):20–37, March
1984.
[15] P. Samarati and L. Sweeney.
Protecting privacy when
disclosing information: k-anonymity and its enforcement
through generalization and suppression. Technical Report
SRI-CSL-98-04, Computer Science Laboratory, SRI Inter-
national, 1998.
[16] C. Shannon. A mathematical theory of communication. The
Bell System Technical Journal, 27:379–423, 623–656, July
1948.
[17] S. Staniford, J. Hoagland, and J. McAlerney. Practical auto-
mated detection of stealthy portscans. Journal of Computer
Security, 10(1/2):105–136, 2002.
[18] L. Sweeney.
k-anonymity: A model for protecting pri-
vacy. International Journal on Uncertainty, Fuzziness and
Knowledge-based Systems, 10(5):557–570, October 2002.
[19] A. Valdes and K. Skinner. Probabilistic alert correlation. In
Proceedings of the 4th International Symposium on Recent
Advances in Intrusion Detection (RAID 2001), pages 54–68,
2001.
[20] V. Yegneswaran, P. Barford, and S. Jha. Global intrusion
detection in the domino overlay system. In Proceedings of
the 11th Annual Network and Distributed System Security
Symposium (NDSS’04), February 2004.
Proceedings of the 21st Annual Computer Security Applications Conference (ACSAC 2005) 
1063-9527/05 $20.00 © 2005 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 12:08:53 UTC from IEEE Xplore.  Restrictions apply.