the loss function of sparse categorical cross-entropy and a
learning rate of 0.001. To avoid over-ﬁtting, we added dropout
regularization and early stopping on a held-out validation set.
D. Metrics
We introduce the following metrics for the evaluation of
system resilience and performance of safety monitors:
• Hazard Coverage is deﬁned as the conditional probability
that given activation of a safety-critical fault in the system
by FI, it leads to an unsafe system state or a hazard.
• Time-to-Hazard (TTH) measures the time between activa-
tion of a fault (tf ) to occurrence of a hazard (th) (Fig. 6).
• Prediction Accuracy represents the performance of the
safety monitors in accurate prediction of hazards, measured
using false positive rate (FPR), false negative rate (FNR),
accuracy (ACC), and F1 score.
– Sample Level with Tolerance Window: Using the tradi-
tional point-wise binary classiﬁcation metrics, an FP is
declared for all the samples in a simulation where the
monitor detects a hazard and the ground truth indicates
no hazard. But for hazard prediction, it is desirable that a
monitor generates alerts before a hazard happens. So we
adopt a modiﬁed version of standard classiﬁcation metrics
[71], proposed for sequential data [72] [73] [74], where
a tolerance window before the start time of hazard (th)
is used for calculation of the metrics (see Fig. 6). Table
IV shows the confusion matrix with a tolerance window.
– Simulation Level with Two Regions: Considering the
whole data trace of a simulation as a single case, we also
calculate accuracy at the simulation level. In that case,
however, a TP is declared whenever an alert is generated
during a hazardous data trace regardless of when hazards
happen. Thus, for simulation level evaluation, we divide a
data trace into two regions based on the time of activation
of a fault (tf ) ([0, tf ] and [tf , te] in Fig. 6), and calculate
the classiﬁcation metrics separately for each region.
• Reaction Time is the time difference between a monitor
alert (td) and the occurrence of a hazard (th) (Fig. 6). This is
the maximum time we have for taking any mitigation action
TABLE IV: Confusion Matrix for Sequential Data with Tolerance
Window δ, Modiﬁed from [72]
t
t
G(t(cid:2)) > 0
G(t(cid:2)) > 0
t(cid:2)=t−δ(cid:2)
t(cid:2)=t−δ(cid:2)
Ground Truth Positive
(cid:2)t
(cid:2)t
Ground Truth Negative
P(t)>0 &&
P(t)==0 &&
(cid:2)t+δ
t(cid:2)=t
(cid:2)t+δ
t(cid:2)=t
(cid:2)t+δ
t(cid:2)=t
(cid:2)t+δ
t(cid:2)=t
P (t(cid:2)) > 0&&
P (t(cid:2)) == 0&&
t: Start time of a window δ, ending with a positive ground truth, that includes t.
G(t(cid:2)) == 0
PP
G(t(cid:2)) == 0
PN
* PP: Predicted positive; PN: Predicted negative; P(t)/G(t): Prediction/Ground truth at time t;
t − δ(cid:2)
before the hazard happens, with positive values representing
early detection, and measures the timeliness of the monitor.
• Recovery Rate is the percentage of potential hazards that are
prevented by the safety monitor’s mitigation strategy and is
affected by both the prediction accuracy and latency.
• Average Risk is a metric for assessing the impact of
monitor performance on patient safety by considering the
consequences of both FP and FN cases and the possibility of
harm to patient. FNs put the patient in a hazardous situation
without any warning or mitigation, and FPs not only bother
the patient with unnecessary alerts but might also cause new
hazards after needless mitigation. It is deﬁned as follows:
(cid:2)
(cid:2)
1
N
(cid:2)
N
P
i=1
¯RI(i)]
¯RI(i) +
[
NF N
i=1
Riskavg =
(9)
where, ¯RI(i) is the average risk index (for APS, deﬁned
as BG Risk Index in Section IV-C) of ith simulation, N
is the total number of simulations, NF N is the number of
FN cases, and N(cid:3)
P is the number of new hazards that are
introduced by mitigation of FP cases.
E. Results
1) Resilience of Baseline APS without Safety Monitor: We
ﬁrst analyzed the resilience of the baseline OpenAPS software,
which is already designed with safety features such as a
maximum threshold and an auto-adjusted control algorithm
[75], without any safety monitors in the presence of faults.
Effectiveness of FI: Experimental results showed that our
FI could achieve an overall 33.9% hazard coverage on the
Glucosym simulator, which reﬂects our FI engine’s efﬁciency
in introducing enough faulty data for adversarial training as
well as OpenAPS’s inadequacy in tolerating safety-critical
faults and attacks. However, as shown in Fig. 7a, the hazard
coverage was quite different across different patient proﬁles,
ranging from 6.7% to 92.4% across ten patients. This shows
some evidence on the importance of specifying patient-speciﬁc
safety requirements for the design of monitors.
OpenAPS Resilience: We further evaluated the resilience of
OpenAPS using the TTH metric. We analyzed the distribution
of this metric (Fig. 7b) to help with the speciﬁcation of time
requirements for hazard prediction and mitigation. Fig. 7b
shows an average TTH of about 3 hours based on all the
simulation data. It should be noted that the human body has a
considerable lag and is a slow dynamic system, and it usually
Fig. 6: Hazard Prediction Accuracy with Tolerance Window δ (green
area): TP: Hazard (red arrow) occurs no latter than δ after a prediction
(blue arrow); FP: No hazard happens in [0,δ] after an alert; FN:
Hazard occurs without a prediction in the window δ ahead; TN: No
hazard happens in [0,δ] after a negative prediction.
Fig. 7: (a) Hazard Coverage; (b) Time to Hazard (TTH) Distribution
Authorized licensed use limited to: Tsinghua University. Downloaded on October 11,2021 at 09:25:48 UTC from IEEE Xplore.  Restrictions apply. 
491
Glucosym
TABLE V: Performance of CAWT Monitor vs. Non-ML Monitors
Simulator Monitor
Guideline
MPC
CAWOT
CAWT
Guideline
MPC
CAWOT
CAWT
No. Sim. Hazard% FPR
0.02
8820
0.02
8820
0.01
8820
<0.01
8820
0.99
8820
8820
0.01
0.05
8820
<0.01
8820
33.90%
33.90%
33.90%
33.90%
39.30%
39.30%
39.30%
39.30%
F1
Score
0.73
0.73
0.84
0.97
0.41
0.96
0.87
0.98
FNR
0.32
0.33
0.21
<0.01
0.00
<0.01
<0.01
0.02
ACC
0.95
0.95
0.96
0.99
0.26
0.99
0.96
1.00
T1DS2013
the Guideline and MPC monitors with 32.1% and 31.7%
increase in average F1 score on the Glucosym simulator and
141.4% and 2.6% on T1DS2013 simulator, along with at least
50.0% reduction in the FPR, while keeping FNR low.
3) Comparison with ML-based Monitors: Table VI shows
the overall performance of the CAWT monitor versus three
ML-based monitors in faulty scenarios (8820 simulations on
each of the Glucosym and T1DS2013 simulators) using both
sample level and simulation level metrics.
Sample level: We observe the CAWT monitor outperformed
all three baseline monitors with low FPR and high accuracy
and F1 score and achieved a lower FNR than the LSTM and
MLP monitors on both Glucosym and T1DS2013 simulators.
Although it kept a lower FNR than the CAWT monitor, the
DT monitor held a much higher FPR (0.08-0.20 vs. 0.01),
which will increase the risk of introducing new hazards due
to unnecessary activation of the mitigation function. Overall
the proposed CAWT monitor achieved the best performance
among all three ML-based monitors with a 4.3%-58.3% in-
crease in F1 score and 81.4%-99.0% reduction in FPR and
retained a competitive performance, if not better, in FNR.
Simulation level: Further, for the same number of sim-
ulations without any hazard, the DT monitor generated false
alarms in 3263 (56.0%) simulations on the Glucosym simula-
tor and 5438 (99.7%) simulations on the T1DS2013 simulator.
In comparison, the CAWT monitor held a much lower FPR
of 0.12 and 0.10 on each simulator, respectively, and thus
achieved a much higher F1 score and prediction accuracy.
4) Monitor Timeliness: Fig. 9 presents the reaction time of
the CAWT monitor vs. all other baseline monitors. We should
emphasize that the human body is a slow system that usually
takes hours to digest food and for the insulin to bring the BG
value back to normal from a severe situation. Therefore, it
makes sense for APS to have the reaction time measured in
the order of hours (instead of seconds or minutes in other CPS
with faster dynamics). We made the following observations:
• The CAWT monitor can detect a UCA before hazard occur-
rence for about two hours on average, which is at least 1.6
hours longer than the MPC and Guideline monitor.
• The CAWT monitor kept the lowest standard deviation of
reaction time, representing a more stable performance on
TABLE VI: Performance of CAWT Monitor vs. ML-based Monitors
Simu
lator
Metric
Monitor
DT
MLP
LSTM
CAWT
DT
MLP
LSTM
CAWT
Sample Level (Tolerance Window)
F1 Score
FPR
0.81
0.08
0.86
0.05
0.88
0.04
0.97
0.01
0.20
0.62
0.67
0.01
0.94
0.01
<0.01
0.98
FNR
<0.01
0.03
0.01
<0.01
<0.01
0.45
0.03
0.02
ACC
0.93
0.96
0.96
0.99
0.83
0.93
0.98
1.00
Simulation Level (Two Regions)
F1 Score
FPR
0.52
0.56
0.70
0.25
0.71
0.24
0.83
0.12
1.00
0.41
0.68
0.12
0.78
0.17
0.10
0.87
FNR
<0.01
0.02
0.01
<0.01
<0.01
0.30
0.03
0.01
ACC
0.57
0.80
0.82
0.91
0.26
0.84
0.87
0.92