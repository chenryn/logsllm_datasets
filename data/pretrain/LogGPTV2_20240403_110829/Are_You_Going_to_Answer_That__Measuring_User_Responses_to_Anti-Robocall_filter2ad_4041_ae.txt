warning placement, screen color, warning label color, and
icon used. Although we cannot conclusively point
to the
effectiveness of each element,
the qualitative results show
that screen and warning label color played a crucial role in
decision making and likability. At the end of each study, the
11
Fig. 7. At the end of each user study, the participants were asked which
design they liked the most. Some participants chose more than one design,
and some had no preference. This bar graph shows that Focus-AID was liked
the most and Avail-Auth and Control were like the least.
participants were asked to indicate which design they preferred
the most and which they liked the least. As shown in Figure 7,
some participants picked more than one design and some liked
or disliked the designs equally and decided not to make a
choice. The Focus-AID was liked the most by the majority
of participants (53%), and no participants mentioned it when
discussing the design they liked the least. Users reported that
the color blue was “pretty assuring” and made them feel “safe”,
thus answering calls they may not have answered otherwise.
They also favored the Authenticated Call label, which Avail-
CID did not have, thus leaving participants with the additional
task of interpreting the blue bar whenever Avail-CID was
shown.
Focus-Spam was the third least liked design. For some,
the color was not alerting enough. Participants expected to see
the color red more and indicated that the “black box is off
putting”. Almost half (48.4%) of the participants suggested
that Focus-Spam could be improved if the black box in the
layout or background color was changed to red. When asked
what stood out in the study experience, half of the participants
(50%) mentioned Avail-Spam’s red bar and alert message.
Since all of the participants understood that the Focus spam
design was indicating that the call was spam and seventy-one
percent (71%) of participants were able to correctly describe
a spoofed call, we conclude that the design elements in the
Focus-Spam design encouraged participants to ultimately not
follow the warning.
E. Warning Design Discussion
Wogalter’s work on warning design criteria [47] and in-
terpretation
[48] will be used to discuss the designs in
Figure 5. Since the designs used in the experiment used
similar signal words, hazard statements, conciseness, and clear
instructions, these will not be mentioned below. However, this
section will discuss areas in which the designs differ, such
as comprehension, notice of consequence, hazard matching,
durability, arousal strength, and noticeability.
1) Comprehension: A comprehensible warning is designed
the
the user can easily understand and interpret
so that
message. Although every participant was able to correctly
interpret the purpose and meaning of each warning during the
debrief, this understanding did not translate into their response.
Participants were not confused by the components of the
Avail-Spam and the Focus-AID design. However, the Focus-
Spam and the Avail-CID designs included an interpretation
challenge. Although some participants (15%) liked the Focus-
Spam design the most, others were confused about the alert
icon used. Participant P03 mentioned that “it [‘X’ mark]
either means that the call is spam or this person is missing
a photo,” which confused some participants. The Avail-CID
design did not offer a new message to participants. Participant
P25 mentioned they were “ still using the number to make a
choice.” The blue color is used to indicate a call that is not
identiﬁed as spam. However, this caused participants to treat
unknown calls under Avail-CID and Control design the same
way (p = 1).
2) Durability and Arousal Strength: Durability originally
refers to a warning’s ability to withstand wear and tear. In this
context, we redeﬁne durability as the ability of the warning to
withstand natural human response. Since Authenticated Caller
ID is not available for the everyday telephone user, it would
be natural to answer spoofed calls from entities that would
likely contact you. A warning should change or interrupt this
behavior. Arousal Strength is the sense of urgency received
by a warning and the ability of a warning to motivate a user
to take an action [49]. Participants declined signiﬁcantly more
calls from known numbers under Avail-Spam and Focus-Spam.
(p< .001 in all cases). Participants were able to bypass their
normal behavior and answer calls from unsaved numbers or
refuse calls from known numbers due to the warning design.
3) Notice of Consequence and Hazard Matching: Hazard
Matching is accurately expressing risk using an appropriate
warning message. This includes a notice of consequence or
adequately expressing the consequence for a speciﬁc action.
The negative effects of receiving or answering spam calls often
push users to download robocall detection applications. Due
to this, it may not be completely necessary to include the
consequence in the warning. In this study, some participants
(17%) mentioned that they liked the fact that the Avail-Spam
warning informed them about why a call was being ﬂagged
and believed it would have been beneﬁcial for the Focus-Spam
warning.
4) Noticeable: At the conclusion of the study, participants
were asked to recall what they saw in the study and discuss
designs that caught their attention. Every participant mentioned
the color red and blue. The call authenticated label was
noted as a positive characteristic of the Focus-AID warning.
However,
the color scheme was most noticeable and thus
the most favored design in the study. Every participant that
stated they liked that design the most because of the color
scheme. The Avail-Spam was noticeable and easy to interrupt.
Participant P12 said the “red banner across the screen...
stood out” which made the decision making process “straight
forward.” Participants understood these warnings and did not
identify any components that were confusing. The Focus-
Spam warning stood out to 27% of participants but 47% of
participants agreed that although they understood what was
being displayed it was not alerting. Participant P31 said the
design was a “clear indication of spam,” but the “background
doesn’t scream warning.” They wanted a red background
instead of the yellow to red gradient. This result contradicts the
Focus Group results and is likely due to the amount of time
each group of participants had to look at the design. In the
Focus Groups and Pilot Testing, participants had more time to
look at each design and see what was being presented. During
that time, red may have been more alerting alongside the other
elements used to warn the viewer of a spam call. However, in
quick 23 second intervals, the red is likely more helpful in that
it can quickly provide the user with the intended message.
Participants also discussed layout and warning elements
that grabbed their attention. The Avail-Spam warning’s Pre-
viously Reported in Community message and the contrast
between the background and foreground for the Potential Spam
label were mentioned as positive elements. However, some
participants noted that the warning placement was a bit low on
the screen. Participant P27 responded to the placement saying,
“it reminds me of an ad” and “it doesn’t feel natural.” The
Avail-CID warning was viewed as similar to Control Design,
and therefore the majority of users noticed there was no label
to verify what the warning was trying to indicate. On the
contrary, the check mark used in the Focus-AID warning, and
the Authenticated Call label placements were mentioned as
positive elements of this design. However, some participants
wanted the design to be bigger, saying that the label was not
noticeable enough. Similarly, in the Focus-Spam warning, the
size and placement of the alert icon were mentioned as positive
design attributes and participants wanted the overall warning
block to be bigger.
VII. DISCUSSION
As indicated in similar studies [10], [50], [8], warning
design can affect user decision making. The results of this
study show that
the same is true for robocall warnings.
Warnings used in this study were sometimes able to effectively
change the user’s original decision to answer or decline a call.
Focus-AID increased the number of calls that were answered
through the use of the Authenticated Call label. Anti-robocall
apps available today do not determine if Caller ID information
is valid. However, the results of this study suggest that users
want that capability and would go so far as to trust the notice,
answering calls they would usually ignore.
Robocalls from Spoofed Known Numbers: Avail-Spam and
Focus-Spam decreased the number of spoofed calls from
known numbers that were answered. However,
the impact
of each was drastically different. Spoofed calls from known
numbers were always answered by 50% of the participants
when Focus-Spam was shown. This decreases to 15% of
participants when Avail-Spam is shown, which is less than the
53% of participants that said they would answer calls from
known numbers regardless of the warning during the focus
groups. Also, more calls were declined under the Avail-Spam
than Focus-Spam. Many participants stated that the presence
of the color red made the difference. Since participants were
given 23 seconds to respond to a call, the color red stood
out, making it easier for participants to decide. However, it
is also possible that the data omitted made a difference as
well. The Avail-Spam omitted the name of the caller, whereas
Focus-Spam displayed all of the Caller ID information. In the
end, only 6% of participants mentioned that the name of the
12
caller was missing on the warning during the study debrief.
Prior work shows that users tend to rely on technology to
recall details [51], including phone numbers [52], [53], and
many of our participants had to review numbers (N1, N2) in
their phone’s contact list before saving them in the research
phone. Removing the names could have pushed users to rely on
numbers, which they may not have memorized, causing them
to trust the warning. The removal of the name could have also
made the call feel less personal, since the number may not
have been recognizable to the participant.
Limitations: Except for the Avail-CID call notice, every user
understood what each design was aiming to communicate.
However, the presence of the Caller ID and the short amount
of time allotted may have affected the success of each warning.
In particular, the Focus-Spam design was inspired by the focus
groups but was disliked by the interactive survey participants.
We believe this is because the two groups had different
viewing experiences. The focus group participants looked at
their designs and the design probes for at least three minutes
each. In the interactive survey, participants saw each call
notiﬁcation for approximately 6 of the 23 seconds given. It
is possible that a design element may be more noticeable
the longer a user sees it, which may have caused the focus
group participants to suggest elements that interactive survey
participants rejected. Focus-Spam also included all of the
Caller ID information, which gave participant’s the option to
respond to the design, Caller ID or both. Additionally, the
lack of consequences for answering a spoofed call could have
also affected the users’ response to spoofed calls over time.
Future work in this area should investigate the effect time
has on user response to warning elements and the effects
of Caller ID and consequences on user response to spoofed
calls. We show the possibility of multiple visual design factors
affecting the participant’s response to spam calls. However,
due to the limitations of this study, we are unable to pinpoint
the design element with the strongest effect but we know
that the Focus-Spam design does not work. Additional studies
in this area should work to identify which element has the
greatest effect. In doing this, researchers should consider the
multimodal warning design which includes investigations of
Caller ID, ringtones, and vibrations.
Authenticated Caller ID: As of the writing of this paper,
Authenticated Caller ID has not been deployed beyond very
small test scenarios. Accordingly, it is not clear that all users
have an understanding of precisely what this mechanism would
provide them. However, the creation of provider-centric (e.g.,
SHAKEN/STIR) and end-to-end (e.g., AuthentiCall [23], [24])
mean that consumers are likely to soon see such solutions. In
fact, SHAKEN/STIR, which provides Authenticated Caller ID
for VOIP, will soon be used by all carriers and is currently used
by T-Mobile. Whether or not greater awareness will further
improve the success of these approaches (in particular, related
to allowing users to conﬁdently answer calls that are strongly
authenticated) remains to be seen.
Lab vs Field Testing: The experiments discussed in this paper
were designed to tightly isolate the security indicators of anti-
robocall applications. This was critical, as it removed issues
related to blacklist quality and environmental stress (e.g., noise,
receiving calls while driving, etc.), both of which would likely
have a signiﬁcant impact on the evaluation. As such, the work
TABLE VIII.
MEAN REACTION TIME FOR EACH ROUND
Rounds
R1
R2
R3
Accepted Calls
%
41%
42%
43%
Mean Reaction Time
2.478
1.774
1.483
TABLE IX.
SPOOFED CALL ACCEPTANCE FOR KNOWN NUMBERS
OVER ROUNDS
Variables
Focus-Spam+N1
Focus-Spam+N2
Avail-Spam+N1
Avail-Spam+N2
Accepted Calls
R3
65%
69%
44%
41%
R2
67%
65%
35%
31%
R1
63%
63%
25%
29%
here can be seen as an early approximation of “best-case”
performance of current mechanisms. Similar to other studies
[54], [31], the user study setup has high internal validity and
thus lower ecological validity [40]. This work investigates the
impact of design and limited external factors to maintain this
focus. Requesting participants to respond to mock calls in a
lab setting allows participants to focus on the task and provide
immediate introspective feedback. This allows us to measure
cause and effect directly.
Future warning designs should be tested in the ﬁeld to
capture these and other factors. For instance, this study was
limited by the absence of consequences for answering spoofed
calls. As seen in Table VIII, the time that participants used
to make decisions decreased the more they saw the designs.
However, because participants typically answer calls from
people they knew based on Caller ID information, they began
to adopt that behavior over time. Participant P14 stated, “At
ﬁrst I declined every call that was labeled as spam. Once I
realized some of those calls were from my friends, I started
answering them, even when it said spam.” This was also
true for other participants, which is shown in Table IX. This
is problematic as targeted spoofed calls can be easily done.
The malicious actor would only need to look at the target’s
phone number, Facebook or Twitter account to determine what
entity they should pretend to be. Participants would need to
experience the consequences of answering these spoofed calls
to observe their true response over time. Instead, because
participants did not experience the consequences of answering
a spoofed call from a known number, they began to answer
more spoofed calls over time. However, similar to what was
found in Tu et. al study [55], spoofed Caller ID affects how
participants respond to calls and should be investigated further.
VIII. RELATED WORK
Previous research has investigated the design and use of
warnings in other areas.
Felt et al. tested the effectiveness of Android permission
warnings [56] and found that the majority of their participants
did not pay attention to permission warnings during installation
and had low permission comprehension scores. To improve,
the researchers suggest conveying risk and other information
related to permissions more clearly.
Egelman et al. [31] tested the effectiveness of active and
passive phishing warnings on browsers. They found that active
13
warnings were more effective than passive warnings in prevent-
ing users from accessing phishing websites. However, their
participants were “highly susceptible” to the spear-phishing
attack the researchers deployed. This was due to the lack of
dynamic warnings, clear choices, and habituation. Habituation
is “the extent
to which individuals will continue to pay
attention to a warning after seeing it multiple times [31].”
Majority of participants were exposed to similar warnings in
their everyday life and considered them not serious, ultimately
ignoring the warning.
To prevent habituation and protect users from dangerous
behaviors, Bravo et al. [57] tested the use of inhibitive attrac-
tors as a solution. These interface modiﬁcations are designed
to draw attention to an area and prevent users from choosing
until a speciﬁc amount of time has passed or a speciﬁc
action has occurred. Their results showed that, although users
disliked experiencing a delay, this method was effective in
“reducing the likelihood” that participants would complete
insecure actions.
Other research investigates SSL warnings [58], [50], [8],
software download warnings [57], warning fatigue [59], indi-
cators [9], browser warnings [10], and malware warnings [60].
From these studies, we can conclude that warnings are an
important aspect of user security. Based on these ﬁndings,
warnings should follow the criteria from Wogalter’s research
and should support users in reaching their primary security
goals [61].
Users want to avoid spam calls, just like they want to avoid
phishing and malware, and multiple apps assist users in doing
so. To our knowledge, there has been no publicly available
study on the effectiveness of indicators for spam call warnings.
Warning in the context of spam or robocalls creates a different
challenge than those of previously researched area. In other
areas, users are often not restricted to a speciﬁc time limit
in which they need to respond before a decision is made for
them. However, telephone users have a limited amount of time