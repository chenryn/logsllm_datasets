if($GET[’MainUser’]) {
document.getElementById(’WelcomeMess’).innerHTML =
"Welcome" + "$GET[’MainUser’]";
}
var divname = document.getElementsByName("status")[0].id;
var Name = divname.split("=")[0]; var Status = divname.split("=")[1];
eval("divname.innerHTML = \"" + Name + " is " + Status + "\"");
Figure 2: Running example showing a snippet of HTML pseudocode generated by a vulnerable social networking web site
server. Untrusted user data is embedded inline, identiﬁed by the $GET[’...’] variables.
Untrusted variable
Attack String
Attack 1
Attack 2
Attack 3
Attack 4
$GET[’FriendID-Status’]
$GET[’MainUser’]
$GET[’FriendID-Status’]
$GET[’MainUser’]
’ onmouseover=javascript:document.location="http://a.com"
Attacker=Online"; alert(document.cookie);+"
Figure 3: Example attacks for exploiting vulnerabilities in Figure 2.
pseudo HTML code is shown here and places where un-
trusted user data is inlined are denoted by elements of
$GET[’...’] array (signifying data directly copied
from GET/POST request parameters). In this example, the
server expects the value of $GET[’MainUser’] to con-
tain the name of the current user logged into the site, and
$GET[’FriendID-Status’] to contain a string with
the name of another user and his status message (“online”
or “ofﬂine”) separated by a delimiter (“=”). Assuming no
sanitization is applied, this code has at least 4 places where
vulnerabilities arise, which we illustrate with possible ex-
ploits1 summarized in Figure 3.
• Attack 1: String split & Attribute injection. In this at-
tack, the untrusted $GET[’FriendID-Status’]
variable could prematurely break out of the id at-
tribute of the  tag on line 3, and inject un-
intended attributes and/or tags.
In this particular in-
stance,
the attack string shown in Figure 3 closes
the string delimited by the single quote character,
which allows the attacker to inject the onmouseover
JavaScript event. The event causes the page to redirect
to http://a.com potentially fooling the user into
trusting the attacker’s website.
A similar attack is possible at line 7, wherein the at-
tacker breaks out of the JavaScript string literal using
an end-of-string delimiter (") character in the value for
the variable $GET[’MainUser’].
• Attack 2: Node splitting. Even if this server san-
itizes $GET[’MainUser’] on line 7 to disallow
JavaScript end-of-string delimiters, another attack is
possible. The attacker could inject a string to split the
enclosing  environment, and then inject a
new script tag, as shown by the second attack string
in Figure 3.
• Attack 3: Dynamic code injection. A more subtle at-
tack is one that targets the integrity of the eval query
on line 11. Notice that JavaScript variable Name and
Status are derived from parsing the untrusted id of
the div element on line 3. Even if the server sanitizes
the $GET[’FriendID-Status’] value for use in
the div element context on line 3 by removing the ’
delimiter, the attacker could still inject code in the dy-
namically generated javascript eval statement. The
vulnerability on line 10 parses the id attribute value
of each div element into separate user name and status
variables, which performs no sanitization for variable
named Status. The attacker can use an attack string
value as shown as the third string in Figure 3 to execute
the arbitrary JavaScript code at line 11.
1The sample attacks are illustrative of attacks seen in the past, and are
not guaranteed to work on all browsers. See Figure 1 for more details.
• Attack 4: Dynamic active HTML update. The at-
tacker could inject active elements inside the 
with id WelcomeMess at line 6-7, by using the
fourth attack string in Figure 3 as the value for
$GET[’MainUser’]. This attack updates the web
page DOM 2 tree dynamically on the client side after
the web page has been parsed and the script code has
been executed.
Motivation for our approach. We observe that all of the
attacks outlined in Figure 3 require breaking the intended
structure of the parse tree on the browser. The resulting
parse trees from all attacks are shown superimposed in Fig-
ure 4. It is worth noting that attacks 1 and 2 break the struc-
ture of the web page during its initial parsing by the HTML
and JavaScript parsers, whereas attack 3 and 4 alter the doc-
ument structure during dynamic client-side operations.
If the browser could robustly isolate untrusted data on
the web page, then it can quarantine untrusted data with
respect to an intended policy. In this example, the server
wishes to coerce untrusted nodes to leaf nodes in the parse
tree, by treating them as string literals. This disallows
injection of any language non-terminal (possible active
HTML/JavaScript content) in the web page.
These examples bring out the complexity in defending
against attacks with sanitization alone. To reinforce our ob-
servations, it is easy to understand that server side sanitiza-
tion would be hard to perform in a moderately large appli-
cation. The application developer would need to understand
all possible contexts in which the data could be used with
respect to multiple languages. Sanitization for each kind of
active content varies based on the policy that server wishes
to enforce, and could also vary based on the target browser’s
mechanism for rendering. Attacks need not be JavaScript
based and may target a variety of goals (scripting with Flash
and click fraud3, in addition to sensitive information steal-
ing).
3 Approach Overview
Web pages are parsed by various language parsers that
are part of the web browser into internal parse trees. Un-
der a benign query, the web server produces a web page
that when parsed, results in a parse tree with a certain struc-
ture. This parse tree represents the structure that the web
server aims to allow in the web document, and hence we
term it as the document structure. In our approach, we en-
sure that the browser can identify and isolate nodes derived
from user-generated data, in the parse tree during parsing.
In principle, we whitelist the intended document structure
and prevent the untrusted nodes from changing this struc-
ture in unintended ways. We call the property of ensuring
2DOM is the parse tree for the HTML code of the web page
3Using XSS to trick the user into clicking a “pay-per-click” link or
advertisement through injecting HTML [11].
intended document structure as enforcing document struc-
ture integrity or DSI.
We clearly separate the notion of a conﬁnement policy
from the parser-level isolation mechanism. As in our run-
ning example, web sites often wish to restrict untrusted data
to leaf nodes in the document structure, as this is an effec-
tive way to stop an attacker from injecting active content.
We refer to this conﬁnement policy as terminal conﬁnement,
i.e., conﬁnement of untrusted data to leaves in the document
structure, or equivalently, to strings derived from terminals
in the grammar representing valid web pages. Figure 5 is
the parse tree obtained by DSI enforcement for our running
example.
The server may wish to instruct the browser to enforce
other higher-level semantic policy, such as specifying a re-
stricted sandbox, but this is possible only if the underly-
ing language or application execution framework provides
primitives that prevent an attacker can from breaking out
of the conﬁnement region. For instance, the new pro-
posal of sandbox attributes for iframe tags (introduced
in HTML 5 [40]) deﬁnes semantic conﬁnement policies for
untrusted data from another domain. However, it relies on
the iframe abstraction to provide the isolation. Similar
to iframes, DSI forms the basis for higher level policy
speciﬁcation on web page regions that contain inline un-
trusted data. Our isolation primitives have no dependence
on escaping/quoting or input sanitization for their internal
working, thus making our mechanism a strong second line
of defense for input validation checks already being used in
web application code.
Key challenges in ensuring DSI in web applications. The
high-level concept of terminal conﬁnement has been pro-
posed to defend against attacks such as SQL injection [35],
but HTML differs from SQL in two signiﬁcant ways.
First, HTML can embed code written in various higher-
order languages which share the same inline data. For
instance, there are both generic (such as JavaScript URI)
and browser-speciﬁc ways to invoke functions in VBScript,
XUL, JavaScript, CSS and so on. To account for this dif-
ﬁculty, we treat the document structure as that implied by
the superimposition of the parse trees obtained from code
written in all languages (including HTML, JavaScript) used
in a web page.
A second distinguishing challenge in securing web ap-
plications, specially AJAX driven applications, is that the
document parse trees can be dynamically generated and
updated on the client side.
In real web pages, code in
client-side scripting languages parses web content asyn-
chronously, which results in repeated invocations of dif-
ferent language parsers. To address dynamic parsing,
we treat the document structure as having two different
components—a static component and a dynamic one. A
div
id
'Welcome!'
'WelcomeMess'
html
body
div
div
script
script
id
=
onmouseover
alert
(document.cookie);
=
Attack 2
iframe
src
www.attacker.com
divname.innerHTML
"Attacker is 
Online";
javascript:document.location=
"http://a.com"
"alert
(document.cookie);"
Attack 1
Attack 4
Attack 3
Figure 4: Coalesced parse tree for the vulnerable web page in Figure 2 showing superimposition of parse trees resulting
from all attacks simultaneously. White node show the valid intended nodes whereas the dark nodes show the untrusted nodes
inserted by the attacker.
web page must have a static document structure, i.e., the
document structure implied by the parse tree obtained from
the initial web page markup received by the browser. Sim-
ilarly, a web page also has a dynamic document structure,
i.e., the structure implied by the set of parse trees created by
different parsers dynamically. To illustrate the distinction,
we point out that attacks 1 and 2 in our running example
violate static DSI, whereas attacks 3 and 4 violate dynamic
DSI.
Goals. Parser-level isolation is a set of mechanisms to
ensure robust isolation of untrusted data in the document
structure throughout the lifetime of the web application.
Using PLI we outline three goals that enforce DSI for a
web page with respect to a server-speciﬁed policy, say
P . First, we aim to enforce static DSI with respect to P ,
from the point web page is generated by the server to the
point at which it is parsed into its initial parse trees in the
browser. As a result, the browser separates untrusted data
from trusted data in its initial parse tree robustly. Second,
we aim to enforce dynamic DSI with respect to P in the
browser, across all subsequent parsing operations. Third,
we require that the attacker can not evade PLI by embed-
ding untrusted content that results in escalated interpreta-
tion of untrusted data. These three goals enforce DSI based
on uniform parser-level isolation.
shaling4) of the content and the static document structure
on the server side, and browser-side parsing of HTML as
the deserialization step. We outline 4 steps that implement
PLI and ensure the document structure is reconstructed by
the browser from the point that the web server generates the
web page.
Server-side. There are two steps that the server takes.
• Step 1—Separation of
trusted and user-generated
data. As a ﬁrst step, web servers need to identify un-
trusted data at their output interface, and should dis-
tinguish it from trusted application code. We make
this assumption to begin with, and discuss some ways
to achieve this step through automatic methods in
Section 5. We believe that this is not an unrealis-
tic assumption—previous work on automatic dynamic
taint tracking [44, 27] has shown that tracking un-
trusted user-generated data at the output interface is
possible; in fact, many popular server-side scripting
language interpreters (such as PHP) now have built-in
support for this. Our goal in subsequent steps is to sup-
plement integrity preserving primitives to ensure that
the server-speciﬁed policy is correctly enforced in the
client browser, instead of the sanitization at the server
output interface for reasons outlined in Section 1.
Outline of Mechanisms. We view the operation of encod-
ing the web page in HTML, merely as serialization (or mar-
4akin to serialization in other programming languages and RPC mech-
anisms
div
id
'WelcomeMess'
html
body
div
id
script
""
"
divname.innerHTML
'onmouseover=javascript:document.location=
"http://a.com"
=
Attack 2
Attack 4
Attack 1
"Attacker is Online"; alert
(document.cookie);"
Attack 3
Figure 5: Coalesced parse tree (corresponding to parse tree in Figure 4) resulting from DSI enforcement with the terminal
conﬁnement policy—untrusted subtrees are forced into leaf nodes.
• Step 2—Serialization: Enhancement of static struc-
ture with markup. The key to robust serialization is
to prevent embedded untrusted data from subverting
the mechanism that distinguishes trusted code from in-
line untrusted data in the browser. To prevent such
attacks, we propose the idea of markup randomiza-
tion, i.e., addition of non-deterministic changes to the
markup. This idea is similar to instruction set random-
ization [17] proposed for preventing traditional vulner-
abilities.
integrity of the dynamic document structure, as it em-
beds a reference monitor in the language parsers them-
selves. Thus, no changes need to be made to existing
client-side code for DSI-compliance.
4 Enforcement Mechanisms
We describe the high level ideas of the mechanisms in
this section. Concrete details for implementing these are
described in Section 5.
Browser-side. There are two steps that the browser takes.