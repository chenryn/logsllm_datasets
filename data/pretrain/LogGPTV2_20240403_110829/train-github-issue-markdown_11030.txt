### Description
When using `scrapy-redis` or a custom dupefilter, the item pipeline processing speed becomes extremely slow. This issue is not related to Redis itself, as moving the deduplication logic to the `DownloadMiddleware` (checking URL fingerprints in `process_request` and adding them in `process_response`) restores the normal speed of the item pipeline. For more detailed information, please refer to the following links:
- [rmax/scrapy-redis#174](https://github.com/rmax/scrapy-redis/issues/174)
- [Stack Overflow: Scrapy-Redis Slows Down Item Pipelines](https://stackoverflow.com/questions/63026873/scrapy-redis-slows-down-item-pipelines)

### Steps to Reproduce
1. Set the `DUPEFILTER_CLASS` to `"project.filename.customize-dupefilter-class"`.

**Expected Behavior:**
- The speed of the item pipeline should remain consistent and not be significantly affected.

**Actual Behavior:**
- The speed of the item pipeline is extremely slow.

**Reproducibility:**
- This issue occurs consistently.

### Versions
- Scrapy: 2.2.0
- lxml: 4.5.2.0
- libxml2: 2.9.10
- cssselect: 1.1.0
- parsel: 1.6.0
- w3lib: 1.22.0
- Twisted: 20.3.0
- Python: 3.7.7 (default, Mar 10 2020, 15:43:33) - [Clang 11.0.0 (clang-1100.0.33.17)]
- pyOpenSSL: 19.1.0 (OpenSSL 1.1.1g 21 Apr 2020)
- cryptography: 2.9.2
- Platform: Darwin-19.5.0-x86_64-i386-64bit

This version of the text is more structured and clearly conveys the problem, steps to reproduce, and the expected and actual behaviors.