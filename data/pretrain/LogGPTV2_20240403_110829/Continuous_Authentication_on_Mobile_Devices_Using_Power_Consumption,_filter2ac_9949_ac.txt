following hypotheses: the null hypothesis that says the test point is a good ﬁt in
the distribution (and in the case of TCMs, whether the point belongs to the class
represented by that distribution), and the alternative hypothesis that says the
point is not a good ﬁt. The test is performed by computing a p-value (measure
of randomness) as the fraction of the points in the sample distribution whose
strangeness is greater or equal to that of the test point. If this p-value is less than
the complement of the conﬁdence level desired for the diagnosis, the alternative
hypothesis is accepted.
StrOUD borrows the idea of TCM with an important change: nature of the
strangeness function utilized. The goal in StrOUD is to ﬁnd anomalies (not to
classify points), so, the strangeness function should be a measure of how anom-
alous a point is within a distribution. Given a sample distribution, or baseline
of observations, the strangeness of the jth point xj can be computed as the sum
of the distances to the k nearest points in the baseline data. Figure 3 presents
an illustration of two sets of data (yellow and blue) in feature space. Strange-
ness calculation has been demonstrated in the ﬁgure for a point each from the
training set and the testing set. Equation 1 shows the deﬁnition of strangeness
utilized by Barbara et al. [16].
416
R. Murmuria et al.
sj =
(cid:2)
i ∈ k
d(xj, xi).
(1)
Calculating all the strangeness measures for points in the baseline and sorting
them in ascending order returns a sample distribution of strangeness (shown in
the Fig. 3 with the width of the bars representing the strangeness values of each
point). For a given new point, its strangeness needs to be computed and its place
on that distribution measured, as the fraction of points (including itself) that
have strangeness equal or greater than its own. As stated before, that fraction
is a measurement of randomness in the form of a p-value, which serves as the
basis for hypothesis testing.
6.2 The Discord Algorithm
The power measurements are viewed as a time-series and for this modality an
algorithm designed by Keogh et al. [17] that allows the discovery of discords on
that kind of data was employed. A discord in a time series is a subsequence of the
series whose distance to the closest subsequence (of the same size) is maximal. A
discord is a particularly desirable indicator of anomaly, because it only requires
a very intuitive parameter for its discovery: the size of the subsequence.
The discord idea is used with the power modality in two phases. In the ﬁrst,
the goal is to obtain a distribution of measures that represent the uniqueness of
a time series, as a baseline distribution. To that end, the power baseline data
collected for a user is divided in two parts. The ﬁrst, of size m is used as a basis
to ﬁnd discords in chunks of the second part. In the Fig. 4, this step has been
illustrated by using the training set time-series partitioned using the vertical
line. Given a ﬁxed size of the subsequence δ, we compare a subsequence from
the second part with all subsequences in the ﬁrst part, and the distance to its
closest neighbor is returned. Doing this over the entire second part of the dataset
results in a distribution of distances that can be sorted in ascending order (shown
Fig. 4. Discord-based outlier detection
Continuous Authentication on Mobile Devices Using Power Consumption
417
on the right side in the ﬁgure). This distribution is viewed as playing the role of
the strangeness distribution.
When analyzing test data, after receiving δ observations, the algorithm com-
putes the distance of that set of δ observations to the ﬁrst part of the baseline
time series (of size m). Doing so, the algorithm obtains a new distance to the
test data’s closest neighbor and proceeds to transduce that distance into the
strangeness distribution, to analyze whether that subsequence is an anomaly or
not. This is repeated for every new observation in the test data (always consid-
ering a window of size δ that spans the current observation).
6.3 User Diagnosis
After calculating the sorted distribution of strangeness any future incoming point
is diagnosed using this distribution, which represents a user’s proﬁle. In an exper-
imental setting, many datasets were tested against each user’s baseline; some of
these datasets came from the same user and some of them from users other than
the one that generated the baseline. Such setting produces a matrix where each
column and row represents one user. Every entry represents the probability of
committing an anomaly for the corresponding pair of baseline/test user data
set. This matrix is called the confusion matrix. The smaller the score, the better
the testing data matched the baseline. Examples for this matrix are shown in
Tables 3, 4, and 5 under Sect. 7.
The mere presence of an anomaly does not conclude presence of an imposter.
The fraction of anomalies in the test dataset is an indication of whether the set
belongs to the original distribution or not. Setting a threshold on the maximum
probability that can be observed and still consider the data as coming from the
same distribution of the baseline gives a way to diagnose a user as an impostor
or not.
From this point onward, there are two ways to proceed while choosing thresh-
olds. The ﬁrst is to select a general threshold and diagnose as reject every matrix
entry whose value is bigger than the threshold. If the reject occurs in a case for
which the row and column are from the same user, it is a false reject (the model
is saying the user is not who they say they are, while the truth says otherwise).
If the reject occurs elsewhere, it is a true reject (the model is correctly saying
this user is diﬀerent than that of the baseline). After computing the rates at
which these two events occur, False Reject Rate (FRR) and False Accept Rate
(FAR) can be calculated as shown in Eq. 2.
F AR = 1 − True Reject/Total Reject Cases
F RR = False Reject/Total Accept Cases.
(2)
Varying the threshold for fraction of anomalies allows computing pairs of
values for FRR and FAR for each threshold, and plotting the Receiving Oper-
ating Characteristic (ROC) curve. If a single column from the matrix is used
to calculate the FRR and FAR, the ROC curve represents performance of the
418
R. Murmuria et al.
corresponding user’s model. This requires having more than one test set that
comes from the same user represented in the column (otherwise the computa-
tion of FRR is trivialized). If the entire matrix is used, the ROC curve represents
overall performance of all the models for every user.
The second alternative is to utilize an individual threshold for each user.
These thresholds are calculated using the fraction of anomalies of each user
(which represent the rate of anomalies that are “normal” to every user). In
this case, from the confusion matrix, the overall FRR and FAR are computed by
varying threshold values per column (i.e., per user) and the ROC is reported with
each FRR/FAR pair resulting from a vector of threshold values. Experiments
show that selecting individual thresholds result in much improved ROC plots,
and thus, better models.
Each modality produces its own confusion matrix. To calculate the overall
result, we used two schemes to calculate the ensemble: majority scheme and
non-imposter consensus. The majority scheme requires at least 2 out of the 3
modalities to vote for having found an imposter. The non-imposter consensus
requires 3 out of the 3 modalities to vote for having found the same user and
any other vote results in a declaration of imposter.
7 Results
We measured our system’s performance in terms of the commonly used met-
rics: False Acceptance Rate (FAR), False Rejection Rate (FRR) and Receiver
Operating Characteristic (ROC) curve. We deﬁned these terms in Sect. 6.3 in
the context of our analysis. Additionally, we make use of another metric called
Equal Error Rate (EER), which is the rate at which the FAR and FRR are
equal. EER is a widely used metric to determine the overall performance of an
authentication system regardless of the choice of parameters.
The parameters we selected for the two algorithms discussed in Sect. 6 are
shown in Table 1. The value of k in the StrOUD algorithm was selected to be 3.
Other selections in the neighborhood of 3 did not result in a signiﬁcant diﬀerence
in the overall performance. The δ in the power consumption data was selected to
be 12, which corresponds to time-series window of 1 min. Other window sizes of
30 s and 5 min performed poorly compared to the 1 min window. The parameter
m splits the power data in two chunks during baseline generation phase of the
discord algorithm. A split of 60-40 was considered appropriate, but other combi-
nations can be explored in future. The conﬁdence level determines how strictly
the user diagnosis phase marks records as imposter. Diﬀerent values between
85 % and 99 % were tested, and the best performing level was chosen.
Table 1. Parameters selected for our algorithms
Parameter k δ m
Value
3 12 60 % 90 %
conf
Continuous Authentication on Mobile Devices Using Power Consumption
419
(a) Using Chrome App
(b) Using Facebook App
Fig. 5. ROC from ensemble model on all users
Our analysis of the experimental results demonstrate that our approach using
the ensemble of modalities allow us to identify imposters with an Equal Error Rate
between 6.1 % and 6.9 % for training times that vary between 20 and 60 min. The
ﬁrst response time to authenticate is as low as 2 s for the gyroscope modality, 1 ges-
ture for the touch screen modality and 60 s for the power modality. Subsequently,
each user action will produce a new authentication score in real-time.
We discussed our use of common thresholds and individualized thresh-
olds in Sect. 6.3. Further, the voting schemes we used to create the ensembles
is described in Sect. 6. Figure 5a shows the detection performance results for
Chrome and Fig. 5b for Facebook. It is clear from the ensemble plots that for
both voting schemes, the individual thresholds for each user gives a signiﬁcant
improvement to the predictions. Further, our voting scheme of Non-imposter
consensus is consistently outperforming the majority scheme. By requiring the
modalities to agree by consensus when a legitimate user is present, we placed a
higher cost on acceptance and thereby improved the overall performance.
We examined the distribution of False Accept Rates (FAR) by ‘clamping’
the False Reject Rates (FRR) to 0.01 (i.e., 1 %). The results are tabulated in
Table 2. The results follow intuition that we have very few users that can cause
an FAR value to be higher than the average. We believe that this can be rectiﬁed
with use of additional biometric modalities complementary to the three we have
developed.
If used separately, each modality cannot generate models that oﬀer good
performance in terms of accuracy and classiﬁcation results because each modality
is a weak classiﬁer. Put it simply, users can happen to closely resemble one of the
Table 2. Distribution of FAR of users at ≤1 % FRR
Range
0–2.5 % 2.5 %–7.5 % 7.5 %–12.5 % 12.5 %–50 %
Users (Chrome)
38
Users (Facebook) 45
10
7
4
0
7
7
420
R. Murmuria et al.
(a) Movement modality (gyro./accel.)
(b) Touch modality
(c) Power modality
Fig. 6. ROC for Chrome App captured on all users
modalities but it is extremely rare that they do so at the same time for all three
modalities given our experimental results. As a result, because the modalities
have non-overlapping weaknesses, together in an ensemble they form a strong
identiﬁer. We use ROC curves produced from the data of Chrome application
as an example, to demonstrate that (see Fig. 6). The performance ranges in
EER from 27.3 % to 32.3 % even with individual thresholds. Figure 5a is the
corresponding ensemble plot that shows EER of 16.9 % for common thresholds
and EER of 6.9 % with individual thresholds which are signiﬁcant improvements.
Modality plots for the Facebook application showed comparable performance and
have been omitted here.
Results also depend on the Application context. See Tables 3, 4 and 5 that
show the performance of the power modality for 5 randomly selected users. These
confusion matrices have been created using the technique discussed in Sect. 6.3.
The light gray color represents the rate of anomaly considered “normal” to the
legitimate user. Using our per-user thresholds method, if any cell in the column
happens to have a fraction of anomaly less than the value in the diagonal (colored
light gray), then these would represent False Accepts, and we have colored them
dark gray. It is clear from observation, that the number of dark gray boxes greatly
Continuous Authentication on Mobile Devices Using Power Consumption
421
Table 3. Randomly selected 5 users
from Chrome App for power modality
Table 4. Randomly selected 5 users
from Facebook App for power modality
Baseline Users
D
C
B
A
%
E
s A 3.6 15.6 19.2 10.7 28.5
8.5 32.5
4.2