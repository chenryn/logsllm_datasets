9http://yann.lecun.com/exdb/mnist
10http://archive.ics.uci.edu/ml/datasets/Adult
9
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:20:35 UTC from IEEE Xplore.  Restrictions apply. 
CIFAR-10, CNN, Membership Inference Attack
CIFAR-10, CNN, Membership Inference Attack
CIFAR-100, CNN, Membership Inference Attack
i
i
n
o
s
c
e
r
P
1
0.9
0.8
0.7
0.6
0.5
2500
5000
10000
15000
i
i
n
o
s
c
e
r
P
1
0.9
0.8
0.7
0.6
0.5
i
i
n
o
s
c
e
r
P
1
0.9
0.8
0.7
0.6
0.5
1
2
3
4
5
6
Classes
7
8
9
10
 0
 2000  4000  6000  8000  10000  12000  14000
 0
 5000
 10000  15000  20000  25000  30000
Training Set Size
Training Set Size
Fig. 4: Precision of the membership inference attack against neural networks trained on CIFAR datasets. The graphs show precision for
different classes while varying the size of the training datasets. The median values are connected across different training set sizes. The
median precision (from the smallest dataset size to largest) is 0.78, 0.74, 0.72, 0.71 for CIFAR-10 and 1, 1, 0.98, 0.97 for CIFAR-100. Recall
is almost 1 for both datasets. The ﬁgure on the left shows the per-class precision (for CIFAR-10). Random guessing accuracy is 0.5.
Purchase Dataset, Amazon (10,1e-6), Membership Inference Attack
Purchase Dataset, Amazon (100,1e-4), Membership Inference Attack
Purchase Dataset, Google, Membership Inference Attack
Precision
Recall
 1
 0.9
 0.8
 0.7
 0.6
 0.5
 0.4
 0.3
 0.2
 0.1
Precision
Recall
 1
 0.9
 0.8
 0.7
 0.6
 0.5
 0.4
 0.3
 0.2
 0.1
s
e
s
s
a
C
l
f
o
n
o
i
t
c
a
r
F
e
v
i
t
a
u
m
u
C
l
Precision
Recall
 1
 0.9
 0.8
 0.7
 0.6
 0.5
 0.4
 0.3
 0.2
 0.1
s
e
s
s
a
C
l
f
o
n
o
i
t
c
a
r
F
e
v
i
t
a
u
m
u
C
l
s
e
s
s
a
C
l
f
o
n
o
i
t
c
a
r
F
e
v
i
t
l
a
u
m
u
C
 0
 0
 0.2
 0.4
 0.6
Accuracy
 0.8
 1
 0
 0
 0.2
 0.4
 0.6
Accuracy
 0.8
 1
 0
 0
 0.2
 0.4
 0.6
Accuracy
 0.8
 1
Fig. 5: Empirical CDF of the precision and recall of the membership inference attack against different classes of the models trained using
Amazon ML (in two different conﬁgurations) and Google Prediction API on 10, 000 purchase records. 50, 75, 90-percentile of precision is
0.74, 0.79, 0.84 on Amazon (10, 1e − 6), 0.84, 0.88, 0.91 on Amazon (100, 1e − 4), and 0.94, 0.97, 1 on Google, respectively. Recall is
close to 1.
We used the platform in two conﬁgurations: the default setting
(10, 1e − 6) and (100, 1e − 4).
Neural networks. Neural networks have become a very
popular approach to large-scale machine learning. We use
Torch7 and its nn packages,11 a deep-learning library that has
been used and extended by major Internet companies such as
Facebook.12
On CIFAR datasets, we train a standard convolutional neural
network (CNN) with two convolution and max pooling layers
plus a fully connected layer of size 128 and a SoftMax layer.
We use Tanh as the activation function. We set the learning
rate to 0.001, the learning rate decay to 1e − 07, and the
maximum epochs of training to 100.
On the purchase dataset (see Section VI-A), we train a fully
connected neural network with one hidden layer of size 128
and a SoftMax layer. We use Tanh as the activation function.
We set the learning rate to 0.001, the learning rate decay to
1e − 07, and the maximum epochs of training to 200.
11https://github.com/torch/nn
12https://github.com/facebook/fblualib
C. Experimental setup
The training set and the test set of each target and shadow
model are randomly selected from the respective datasets, have
the same size, and are disjoint. There is no overlap between the
datasets of the target model and those of the shadow models,
but the datasets used for different shadow models can overlap
with each other.
We set the training set size to 10, 000 for the purchase
dataset as well as the Texas hospital-stay dataset, Adult dataset
and the MNIST dataset. We set it to 1, 200 for the location
dataset. We vary the size of the training set for the CIFAR
datasets, to measure the difference in the attack accuracy.
For the CIFAR-10 dataset, we choose 2, 500; 5, 000; 10, 000;
and 15, 000. For the CIFAR-100 dataset, we choose 4, 600;
10, 520; 19, 920; and 29, 540.
The experiments on the CIFAR datasets were run lo-
cally, against our own models, so we can vary the model’s
conﬁguration and measure the impact on the attack accu-
racy. The experiments on the other datasets (purchases with
{2, 10, 20, 50, 100} classes, Texas hospital stays,
locations,
Adult, and MNIST) were run against models trained using
either Google or Amazon services, where we have no visibility
10
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:20:35 UTC from IEEE Xplore.  Restrictions apply. 
Texas Dataset, Google, Membership Inference Attack
Purchase Dataset, Membership Inference Attack
Precision
Recall
 1
 0.9
 0.8
 0.7
 0.6
 0.5
 0.4
 0.3
 0.2
 0.1
s
e
s
s
a
C
l
f
o
n
o
i
t
c
a
r
F
e
v
i
t
l
a
u
m
u
C
Google
Amazon (100,1e-4)
Amazon (10,1e-6)
Neural Network
 1
 0.9
 0.8
 0.7
 0.6
 0.5
 0.4
 0.3
 0.2
 0.1
s
e
s
s
a
C
l
f
o
n
o
i
t
c
a
r
F
e
v
i
t
l
a
u
m
u
C
 0
 0
 0.2
 0.4
 0.6
Accuracy
 0.8
 1
 0
 0
 0.2
 0.4
 0.6
Accuracy
 0.8
 1
Fig. 6: Precision and recall of the membership inference attack against
the classiﬁcation model trained using Google Prediction API on the
Texas hospital-stay dataset.
Fig. 7: Precision of the membership inference attack against models
trained on the same datasets but using different platforms. The attack
model is a neural network.
into their choice of the model type and structure and little
control over the training process (see Section VI-B).
For the purchase dataset, we built target models on all plat-
forms (Google, Amazon, local neural networks) employing the
same training dataset, thus enabling us to compare the leakage
from different models. We used similar training architectures
for the attack models across different platforms: either a fully
connected neural network with one hidden layer of size 64
with ReLU (rectiﬁer linear units) activation functions and a
SoftMax layer, or a Google-trained black-box model.
We set the number of shadow models to 100 for the CIFAR
datasets, 20 for the purchase dataset, 10 for the Texas hospital-
stay dataset, 60 for the location dataset, 50 for the MNIST
dataset, and 20 for the Adult dataset. Increasing the number
of shadow models would increase the accuracy of the attack
but also its cost.
D. Accuracy of the attack
The attacker’s goal is to determine whether a given record
was part of the target model’s training dataset. We evaluate
this attack by executing it on randomly reshufﬂed records from
the target’s training and test datasets. In our attack evaluation,
we use sets of the same size (i.e, equal number of members
and non-members) in order to maximize the uncertainty of
inference, thus the baseline accuracy is 0.5.
We evaluate the attack using the standard precision and
recall metrics. Precision is the fraction of the records inferred
as members of the training dataset that are indeed members.
Recall measures coverage of the attack, i.e., the fraction of
the training records that the attacker can correctly infer as
members. Most measurements are reported per class because
the accuracy of the attack can vary considerably for different
classes. This is due to the difference in size and composition
of the training data belonging to each class and highly depends
on the dataset.
The test accuracy of our target neural-network models with
training datasets (15, 000 and 29, 540 records,