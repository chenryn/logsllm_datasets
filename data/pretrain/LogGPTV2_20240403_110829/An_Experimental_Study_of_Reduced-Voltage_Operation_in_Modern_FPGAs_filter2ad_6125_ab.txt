typical quantization [34] and pruning [33] techniques with our
proposed hardware-level undervolting technique to further im-
prove the power-efﬁciency of FPGA-based CNN accelerators.
2.2. Undervolting: Supply Voltage Underscaling Below
the Nominal Voltage Level
The total power consumption of any hardware substrate is di-
rectly related to its supply voltage: quadratically and linearly
with dynamic and static power, respectively. Thus, supply volt-
age underscaling toward the threshold voltage signiﬁcantly re-
duces power consumption. Voltage underscaling is a common
power-saving approach as manufacturing technology node size
reduces. For instance, the Vnom of Xilinx FPGAs is 1V , 0.9V ,
and 0.85V for implementations in 28nm, 20nm, and 16nm
technology nodes, respectively. The aim of our undervolting
technique is to reduce the supply voltage below the default
Vnom. However, circuit latency can increase substantially when
supply voltage is reduced below the guardband level, and in
turn, timing faults can appear. These timing faults are man-
ifested as bit-ﬂips in memories or logic timing violations in
data paths. They can potentially cause the application to pro-
duce wrong results, leading to reduced accuracy in CNNs,
or, in the worst-case, they may cause system crashes. There
are several approaches to deal with undervolting faults, such
as preventing these faults by: i) simultaneously decreasing
the frequency [111], which has an associated performance
degradation cost, ii) ﬁxing the faults by using fault mitigation
techniques, such as Error Correction Codes (ECCs) for mem-
3There are also other techniques, such as batching [104], loop un-
rolling [130], and memory compression [49].
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 11:26:55 UTC from IEEE Xplore.  Restrictions apply. 
140
ories [9, 99] and Razor shadow latches for data paths [27],
which comes at the cost of extra hardware, or iii) architectural
improvements, such as additional iterations in CNN train-
ing [133] that may incur hardware and/or software adaptation
costs.
There are two approaches to undervolting studies:
i)
simulation-based studies [89, 108, 127, 132], or ii) direct im-
plementation or testing on real hardware fabrics, mainly per-
formed on CPUs, GPUs, ASICs, and DRAMs [9, 18, 50, 78,
81, 138]. The simulation-based approach requires less engi-
neering effort. However, validation of simulation results on
real hardware is the primary concern with such an approach.
In contrast, the real hardware evaluation approach requires
substantial engineering effort, and it is device- and vendor-
dependent. Such a real hardware approach leads to exact
experimental results and it provides an opportunity to study
device-dependent parameters, such as voltage guardbands and
real power and reliability behavior of underlying hardware. In
this paper, we follow the real hardware approach by evaluating
undervolting on real modern off-the-shelf FPGA devices for
state-of-the-art CNN workloads and benchmarks.
3. Experimental Methodology
Figure 1 depicts the overall methodological ﬂow of our exper-
iments. In this section, we elaborate on its different aspects,
including our implementation methodology, benchmarks, and
undervolting methodology of our FPGA platform.
Convolution (C)
MaxPooling (MP) Convolution (C) MaxPooling (MP) FullyConnected (FC) Softmax (SM)
dog
cat
Xilinx AI APIs
Quantization
Pruning
C
H
W
*
R
Ex: Convolution
S
C
C
C
Ex: MaxPooling
l
e
v
e
l
-
h
c
r
A
i
e
n
ﬂ
f
O
s
t
p
O
s
n
o
i
t
a
r
e
p
O
x
i
r
t
a
M
Programmable Logic (PL)
FPGA Chip Platform- ZCU102
l
m
r
o
f
t
a
P
K
D
N
N
D
x
n
i
l
i
X
M
*
DSP48
+
A
+
D
B
A
D
B
MAC
MAC
.
.
MAC
BRAM
BRAM
.
.
BRAM
Computing Engine
On-chip Memory
)
S
P
(
r
o
t
a
r
t
s
e
h
c
r
O
DDR
Voltage
Regulator
PMBus APIs
Supply Voltage Underscaling
i
g
n
p
p
a
M
A
G
P
F
Figure 1: Our overall methodology (for simplicity, we show a
simpliﬁed block diagram of Xilinx DNNDK [122].).
3.1. CNN Model Development Platform
For our implementation, we leverage the Deep Neural Net-
work Development Kit (DNNDK) [122], a CNN framework
from Xilinx. DNNDK is an integrated framework to facil-
itate CNN development and deployment on Deep learning
Processing Units (DPUs). In this paper, we use DNNDK as
it is a freely-available framework instead of a specialized cus-
tom design, to ensure that the results reported in this paper
are reproducible and general-enough for state-of-the-art CNN
implementations. Although we do not expect a signiﬁcant
difference by experimenting on DNNDK versus other DNN
platforms, our future plan is to verify this by repeating the
experiments on other platforms, such as DNNWeaver [101].
DNNDK provides a complete set of toolchains with compres-
sion, compilation, deployment, and proﬁling, for the mapping
of CNN classiﬁcation phases onto FPGAs integrated with
hard CPU cores via a comprehensive and easy-to-use C/C++
programming interface.
Among the components of DNNDK, the DEep ComprEs-
sioN Tool (DECENT) is responsible for quantization and prun-
ing tasks. The quantization utility of DECENT can convert
a ﬂoating-point CNN model to a quantized model with the
precision of at most INT8 [34]. The pruning utility aims to
minimize the model size by removing unnecessary connec-
tions of the CNN [33]. We perform our baseline evaluation
on a model with INT8 precision and without any pruning opti-
mization. However, in Section 6, we evaluate different conﬁg-
urations to provide a more comprehensive analysis. There are
different sizes of soft DPUs provided by DNNDK with various
hardware utilization rates [123]. Among them, B4096 is the
largest model that utilizes a maximum fraction of BRAMs and
DSPs, i.e., 24.3% and 25.6%, respectively, resulting in a peak
performance of 4096 operations/cycle with a default DPU fre-
quency of 333Mhz and DSP frequency of 666Mhz. In total, a
maximum of three B4096 DPUs can be used in the hardware
platform evaluated in this paper. Our experiments are based
on the B4096 conﬁguration to achieve peak performance.
3.2. CNN Benchmarks
We evaluate undervolting in FPGA-based CNN accelerators
with ﬁve commonly-used image classiﬁcation benchmarks,
shown in Table 1: VGGNet [106], GoogleNet [110], AlexNet
[51], ResNet [35], and Inception [110]. To perform a com-
prehensive analysis and study workload-to-workload variation
better, we choose models whose parameter sizes vary from a
few MBs, e.g., GoogleNet, to hundreds of MBs, e.g., AlexNet.
Our benchmarks have different numbers and types of layers,
as shown in Table 1. The default activation function used in
benchmarks is Relu.
3.3. Undervolting
In this section, we brieﬂy explain the prototype FPGA platform
and the associated voltage control setup.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 11:26:55 UTC from IEEE Xplore.  Restrictions apply. 
141
Dataset
Table 1: Evaluated CNN Benchmarks.
Parameters
Size
Inputs
CNN
Model
VGGNet
GoogleNet
AlexNet
ResNet50
Inception
Name
Cifar-10
Cifar-10
Kaggle Dogs vs. Cats
ILSVRC2012
ILSVRC2012
32*32
32*32
227*227
224*224
224*224
Outputs
10
10
2
1000
1000
#Layers
6
21
8
50
22
8.7MB
6.6MB
233.2MB
102.5MB
107.3MB
Inference Accuracy (%)
Literature
87% [106]
91% [110]
96% [51]
76% [35]
68.7% [110]
Our design @Vnom
86%
91%
92.5%
68.8%
65.1%
3.3.1. Prototype FPGA Platform. Our prototype is based
on the Xilinx ZCU102 FPGA platform fabricated at a 16nm
technology node. We choose this platform because it is i)
equipped with voltage underscaling capability, ii) supported
by DNNDK. We repeat experiments on three identical samples
of ZCU102 to study the effect of hardware platform variability.
ZCU102 is populated with the Zynq UltraScale+ XCZU9EG-
2FFVB1156E MPSoC that combines a Processing System
(PS) and user-Programmable Logic (PL) in the same device.