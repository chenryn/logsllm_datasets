title:Re\(^\mbox3\): relay reliability reputation for anonymity systems
author:Anupam Das and
Nikita Borisov and
Prateek Mittal and
Matthew Caesar
Re3: Relay Reliability Reputation for Anonymity Systems
Anupam Das, Nikita Borisov
University of Illinois at
Urbana-Champaign
{das17,nikita}@illinois.edu
Prateek Mittal
Princeton University
PI:EMAIL
Matthew Caesar
University of Illinois at
Urbana-Champaign
PI:EMAIL
ABSTRACT
To conceal user identities, Tor, a popular anonymity system, for-
wards trafﬁc through multiple relays. These relays, however, are
often unreliable, leading to a degraded user experience. Worse yet,
malicious relays may strategically introduce deliberate failures to
increase their chance of compromising anonymity. In this paper
we propose a reputation system that proﬁles the reliability of relays
in an anonymity system based on users’ past experience. A par-
ticular challenge is that an observed failure in an anonymous com-
munication cannot be uniquely attributed to a single relay. This
enables an attack where malicious relays can target a set of hon-
est relays in order to drive down their reputation. Our system
defends against this attack in two ways. Firstly, we use an adap-
tive exponentially-weighted moving average (EWMA) that ensures
malicious relays adopting time-varying strategic behavior obtain
low reputation scores over time. Secondly, we propose a ﬁltering
scheme based on the evaluated reputation score that can effectively
discard relays involved in such attacks.
We use probabilistic analysis, simulations, and real-world exper-
iments to validate our reputation system. We show that the dom-
inant strategy for an attacker is to not perform deliberate failures,
but rather maintain a high quality of service. Our reputation system
also signiﬁcantly improves the reliability of path construction even
in the absence of attacks. Finally, we show that the beneﬁts of our
reputation system can be realized with a moderate number of ob-
servations, making it feasible for individual clients to perform their
own proﬁling, rather than relying on an external entity.
Categories and Subject Descriptors
C.2.0 [Computer-Communication Networks]: General—Security
and protection
General Terms
Security, Measurement
Keywords
Anonymity; Reputation Systems; Tor Network; Denial of Service
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full cita-
tion on the ﬁrst page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or re-
publish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from permissions@acm.org.
ASIA CCS’14, June 4–6, 2014, Kyoto, Japan.
Copyright 2014 ACM 978-1-4503-2800-5/14/06 ...$15.00.
http://dx.doi.org/10.1145/2590296.2590338.
1.
INTRODUCTION
Anonymous communication systems play a vital role in pro-
tecting users from network surveillance and trafﬁc analysis. The
widely-used Tor network [22] has approximately 5 000 relays and
serves an estimated 300 000 unique users in a day, as of March
2014.1 The effectiveness of Tor depends on the reliability of these
relays. Unreliable relays can both degrade the user experience and
impair the anonymity guarantees provided by Tor. Due to the unre-
liablity of Tor relays certain users will decide to abandon the sys-
tem, thus decreasing the anonymity set, while the remaining users
will end up retransmitting messages, presenting further opportuni-
ties for observation. This latter problem can be exploited by ma-
licious relays where they can strategically affect the reliability of
anonymous communications to increase their odds of compromis-
ing user anonymity [15, 16]. Given previous instances of active
attacks on Tor [2, 10, 11], as well as recent governmental endeav-
ors [24, 26] to deanonymize Tor users, it is important to identify
active attackers in anonymity systems.
We propose a new reputation model, Re3, that can be used to
detect and penalize relays involved in active attacks like selective
DoS. The main challenge in building our model is that it is hard to
pinpoint the single relay responsible for an observed failure. This
enables an attack where malicious relays can target a set of hon-
est relays in order to drive down their reputation. Moreover, mali-
cious relays can oscillate between good and bad behavior in order
to evade detection. To address these challenges we propose using
an exponentially-weighted moving average (EWMA) that can dy-
namically adjust its weighting coefﬁcient to capture the dynamic
behavioral trend of a given Tor relay. Re3 ensures that a malicious
relay that oscillates between reliable and unreliable state obtains a
low reputation score over time. We then propose a ﬁltering protocol
based on relays’ reputation score that can effectively discard relays
mounting active attacks.
We analyze the security of our ﬁltering protocol both probabilis-
tically and through a prototype deployment in the live Tor network.
We ﬁnd that attackers gain no advantage through active attacks like
selective DoS with Re3 deployed. We also show that our ﬁlter-
ing scheme is not vulnerable to strategic attacks like the targeted
attack and a particularly serious form of targeted attack known as
the “creeping death attack” [23]. Furthermore, we study adaptive
attackers who tailor their strategy speciﬁcally against our detec-
tion scheme, performing active dropping only if their reputation is
above a chosen threshold. We conclude that with Re3 deployed
the dominant strategy for such attackers is to not perform any cir-
cuit dropping. Finally, we show that our reputation model provides
beneﬁts even outside the context of active attacks, and is able to
substantially increase the reliability of circuit construction in Tor.
1https://metrics.torproject.org
63Contributions. We offer the following contributions:
• We present a reputation system that assigns quantitative scores
to relays based on their provided reliability during anonymous
communications. Our system captures dynamic behavioral change
and penalizes relays exhibiting behavioral oscillation. (§3)
• We probabilistically analyze the security of our ﬁltering proto-
col against the selective DoS attack, including its randomized
variants. We also study strategic attacks against our reputation
model such as the targeted attack and creeping-death attack. (§5)
• We perform simulation and experiments on the live Tor network
to demonstrate that our reputation model can effectively ﬁlter
out compromised relays. (§6)
• We demonstrate the beneﬁts of our approach even outside the
context of active attacks. Using real world experiments on the
Tor network, we ﬁnd that our ﬁltering protocol is able to signiﬁ-
cantly improve the reliability of circuit construction. (§6.2.2)
• We present two strategies to incorporate our reputation model
into Tor. One way is to run it locally at individual clients and the
other is to run it at shared directory authority (DA) servers. (§7)
2. BACKGROUND
In this paper we take Tor as a case study to proﬁle its participat-
ing relays. Hence, we present a brief overview of the Tor network,
and then discuss how active attacks can lower anonymity in Tor.
We also brieﬂy discuss different types of reputation systems.
2.1 Tor: A Low-latency Anonymity Network
To anonymize TCP connections, a Tor user constructs a circuit
comprised of several Tor relays (also known as routers). The relays
form a pipeline through which trafﬁc is forwarded back and forth
between the user and destination. Circuits typically involve three
the entry, middle, and exit. Tor protects the contents of
relays:
the trafﬁc by using a layered encryption scheme [35], where each
relay decrypts a layer while forwarding. As a result, any individual
router cannot reconstruct the whole circuit and link the source to
the destination. The relays in a circuit are chosen using speciﬁc
constraints [21]. Each user selects the entry relay from a small,
ﬁxed number of relays that are ﬂagged as “fast” and “stable”. These
relays are called guard relays [41]; their use is designed to defend
from the predecessor attack [42]. To choose the exit relay, the user
picks from among those relays that have an exit policy compatible
with the desired destination. After these constraints, the relays for
each position are chosen randomly, weighted by their bandwidth.2
Tor aims to provide low-latency trafﬁc forwarding for its users.
As a result, as trafﬁc is forwarded along the path of a circuit, timing
patterns remain observable, and an attacker who observes two dif-
ferent relays can use timing analysis to determine whether they are
participating in the same circuit [30, 37, 39, 45]. Thus, to compro-
mise anonymity it sufﬁces to observe the entry and the exit relays
for a circuit. Standard security analysis of Tor [22, 39] shows that
if c is the fraction of relays that are observed, an adversary can
violate anonymity on c2 of all of the circuits. Due to bandwidth-
weighted path selection in Tor, c is best thought of as the fraction
of total Tor bandwidth that belongs to relays under observation.3
2This is a simpliﬁed description of the path selection; a detailed speciﬁcation can be
found at [21]. The omitted details do not signiﬁcantly impact our analysis, and we use
the full speciﬁcation in our experiments.
3To be more precise, the correct fraction would be cg · ce, where cg and ce are
the fractions of the guard and exit bandwidth under observation, respectively. For
simplicity of presentation, we will assume cg = ce = cm = c in the rest of the
paper.
The security of Tor, therefore, relies on the assumption that a typ-
ical adversary will not be able to observe a signiﬁcant fraction of
Tor relays. For most adversaries, the easiest way to observe relay
trafﬁc is to run their own relays. It should be noted that other forms
of adversaries do exist, such as ISP- and Internet exchange-level
adversaries [25,27,33], but these adversaries are typically assumed
to be passive and are thus not the focus of this paper.
2.2 Active Attack: Selective DoS in Tor
c2
An adversary who controls a Tor relay can perform a number of
active attacks to increase the odds of compromise [15,16]. One ap-
proach is selective denial-of-service (DoS) [16]. A compromised
relay that participates in a circuit can easily check whether both
the entry and exit relays are under observation. If this is not the
case, the relay can “break” the circuit by refusing to forward any
trafﬁc. This will cause a user to reformulate a circuit for the con-
nection, giving the adversary another chance to compromise the
circuit. A simple analysis shows that this increases the overall frac-
c2+(1−c)3 > c2, because only
tion of compromised circuits to:
circuits with compromised entry and exit relays (c2) or circuits
with no compromised relays ((1 − c)3) will be functional, and
out of those c2 will be compromised. For example, if 20% of the
bandwidth is controlled by an adversary (i.e., c = 0.2) then the
selective DoS attack nearly doubles the overall fraction of compro-
mised circuits from 4% to 7.2%.
The use of guard relays changes the analysis somewhat. If none
of a user’s guards are compromised, then the user is effectively im-
mune from the selective DoS attack, since the user will never use a
compromised entry regardless of the attack. If, on the other hand,
one or more of the guards are malicious then the user is signiﬁ-
cantly impacted, as the dishonest guard(s) chosen for a signiﬁcant
fraction of all circuits will break any circuit that does not use a com-
promised exit. For c = 0.2, if one of the guards is compromised
then the selective DoS attack increases the overall fraction of com-
promised circuits from 6.7% to 13.5% and for two compromised
guards this value increases from 13.3% to 38.5%. Therefore, guard
relays mitigate the selective DoS attack in that it will affect fewer
users if they choose honest guards, but can adversly affect users
who are unlucky enough to choose dishonest guards.
2.3 Reputation Models
A reputation model [36] collects, aggregates, and distributes feed-
back about participants’ past behavior. Reputation models help
users decide whom to trust, encourage trustworthy behavior, and
discourage participation by users who are dishonest. Reputation
models can be classiﬁed as either local or global, based on the way
information is aggregated [32]. In a local reputation model, feed-
back is derived only from direct encounters (ﬁrst-hand experience)
whereas in a global reputation model feedback is also derived indi-
rectly (second-hand evidence) from other users. Hence, in the case
of a global reputation model [28,43,44], a user aggregates feedback
from all users who have ever interacted with a given participant,
thus enabling it to quickly converge to a better decision. However,
global reputation models are much more complex to manage than
local approaches as malicious users have the opportunity to provide
false feedback. Our focus is on building a local reputation model
that accumulates only ﬁrst-hand experience with Tor relays.
3. Re3: OUR REPUTATION MODEL
Our goal is to construct a local reputation model that can be used
by a Tor user to ﬁlter out less reliable Tor relays. This section
discusses the different components of our model.
64As stated earlier we want our reputation function to penalize os-
cillating behavior and to achieve that we update the error function
δn(x) using a reward and punishment strategy where we reward
relays for successful communication and punish them for unsuc-
cessful communication. Incorporating such a strategy enforces re-
lays to behave faithfully. In equation (4), µ and ν represent the re-
ward and punishment factor respectively. Both µ, ν ∈ (cid:60), but we
must ensure that µ > ν because the impact of punishment should
be greater than that of reward. In other words, δn(x) should in-
crease more for unsuccessful communication than successful com-
munication, because that would in turn increase αn(x), giving
higher signiﬁcance to the recent bad evaluation.
To get a better understanding of how Re3 reacts to different
scenarios like random network failures or strategic oscillating be-
havior, we evaluate the reputation score of a relay dropping circuits
at different rates. Figure 2 shows the evaluated reputation score
for different characteristics. We see that any form of circuit drop-
ping results in lowering reputation. Even strategic oscillating be-
havior (i.e., strategically building and milking reputation) is pun-
ished severely and this is evident from the lower reputation score