can see that
DB NewClient Target, DB Illegal File Access} are corre-
sponding to the attack steps with goals to get access to
the server and get the data directly from the host, i.e., the
attacker ﬁrst applies buffer over ﬂow attack against the
database server, then sets up a covert channel to the host and
export malicious code that is used to access to the database
server to get the data. Alert sets {DB NewClient, Loki} are
attack steps that aim to set up covert channel and export
conﬁdential data to the outside. Figure 1(b) also shows that
these two sets of alerts have an indirect relationship but the
same eventual goal that is to steal the data from the database
server and export it to the external. Therefore, applying the
scenario correlation technique as described in Section 4.3,
we can correlate these two scenarios as one integrated sce-
nario, i.e., they are correlated with the same eventual goal,
as shown in Figure 3(b), and group them together as one ev-
idence set.
The advantage of correlating isolated scenarios is that
we can accumulate more comprehensive evidence that can
be used for further analysis, e.g., likelihood evaluation of
each subgoal or ﬁnal goal and attack prediction.
Also using database server as an example, based on the
integrated evidence set, we apply probabilistic inference
to the causal network as shown in Figure 1(b) to com-
pute the likelihood of each subgoal and ﬁnal goal. Ta-
ble 1 shows the assessment of likelihood of some sub-
goals and ﬁnal goal based on the evidence set. In Ta-
ble 1, we show the probability result of two subgoals,
i.e., Get conﬁdential data and Export conﬁdential data,
and the ﬁnal goal, i.e., Steal and export conﬁdential data.
We can see that probabilities of the success of subgoals and
the ﬁnal goal increases with the support of incoming evi-
dence corresponding to the attack steps aimed to get data
from the database server and export data to the external.
The likelihood of each node at causal network based
on on-going evidence can also be used to predict
the attacks. For example, after getting the evidence of
DB FTP Globbing Attack, the probability of the subgoal
Get data from Server directly (as shown in Figure 1(b)) is
increased and equals 0.67. Therefore, we expect a future
attack that enables the attacker to access the ﬁle stored
in the database server. For another example, when we get
the evidence of DB NewClient, the likelihood of Trans-
fer data via covert channel (as shown in Figure 1(b)) is
computed as 0.71 that means it is quite likely that we will
see another attack with which the attacker can export data
via the covert channel in the future. In the GCP Scenario I,
the attacker did launch the attack to access the conﬁden-
tial data stored in database server (indicated by the alert
DB Illegal File Access) after getting the root access to the
database server, and also transferred the stolen data to the
external (indicated by the alert Loki) after setting up the
covert channel (indicated by alert DB NewClient).
Applying our algorithms of scenario correlation and at-
tack prediction to the GCP data set, we can correlate some
isolated attack scenarios resulted from fundamental alert
correlation at low-level, and make correct prediction on the
upcoming type of attack.
In our approach, one of the most important components
8
Proceedings of the 20th Annual Computer Security Applications Conference (ACSAC’04) 
1063-9527/04 $ 20.00 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 11:39:39 UTC from IEEE Xplore.  Restrictions apply. 
DB_FTP_Globbing_Attack
DB_NewClient
DB_NewClient_Target
Loki
DB_FTP_Globbing_Attack
DB_NewClient_Target
DB_NewClient
Loki
DB_Illegal_File_Access
DB_Illegal_File_Access
(a) Two isolated scenarios
(b) Correlated scenarios
Figure 3. Correlation of isolated scenarios
Evidence set
e1
e1, e2
e1, e2, e3
e1, e2, e3, e4
e1, e2, e3, e4, e5
P (subgoal1 = 1|evidence) P (subgoal2 = 1|evidence) P (goal = 1|evidence)
0.58
0.58
0.78
0.78
0.78
0.55
0.71
0.71
0.81
0.85
0.56
0.63
0.74
0.77
0.81
Table 1. Likelihood evaluation of sub-goals and ﬁnal goal with different evidence. De-
note e1: DB FTP Globbing Attack,
e4:
DB NewClient, e5: Loki, subgoal1: Get conﬁdential data, subgoal2: Export conﬁdential data, goal:
Steal and export conﬁdential data.
e3: DB Illegal File Access,
e2: DB NewClient Target,
is the library of attack plans (deﬁned as attack trees). It is
the basis for automatically correlating isolated attack sce-
narios at a higher level and conducting probabilistic infer-
ence for attack prediction. It is true that there exists a limi-
tation in this approach due to the (limited) library of attack
plans. If the attack strategies are beyond the deﬁnition of at-
tack plans, we cannot automatically correlate isolated sce-
narios or make an inference on the future attacks based on
existing attack plan library. Such a task requires the involve-
ment of security experts. However, we argue that, in prac-
tice, the plan library can be deﬁned as comprehensively as
possible by security experts with their knowledge of attacks
and attack strategies, as well as the understanding of net-
works and systems under protection and the mission goals.
The attack plan library can be expanded or re-deﬁned with
the new knowledge of attacks or attack scenarios. There-
fore, we believe that our approach is practical and has the
potential to provide security operators a way to automati-
cally correlate isolated attack scenarios and predict future
attacks based on the observed evidence and networks un-
der protection.
graph-based technique to correlate isolated attack scenarios
derived from low-level alert correlation based on their rela-
tionship in attack plans. We conducted probabilistic infer-
ence to evaluate the likelihood of attack goal(s) and predict
potential upcoming attacks based on causal network con-
verted from attack trees.
There are still some challenges in attack plan recogni-
tion. First, the current approach is based on predeﬁned at-
tack plans built on security experts’ knowledge and under-
standing of networks and systems under protection. If at-
tackers’ activities are beyond the predeﬁned scope of attack
plans, we have to face the challenge of handling and identi-
fying new attack scenarios. Another challenge is how to dis-
tinguish the deceptive plan and the real goal of the attack-
ers. That is, we need to develop a mechanism to identify
and avoid the misleading of attackers. Finally, we also need
to consider how to effectively distinguish the attacks con-
ducted by a single attacker and a group of collaborated at-
tackers. We will study these challenges in our future work.
7. Acknowledgments
6. Conclusions and Future Work
In this paper, we presented an approach to identify at-
tack plans and predict upcoming attacks. We developed a
This work is supported in part by NSF grants CCR-
0133629 and CCR-0208655 and Army Research Ofﬁce
contract DAAD19-01-1-0610. The contents of this work are
solely the responsibility of the authors and do not necessar-
9
Proceedings of the 20th Annual Computer Security Applications Conference (ACSAC’04) 
1063-9527/04 $ 20.00 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 11:39:39 UTC from IEEE Xplore.  Restrictions apply. 
[17] C. W. J. Granger.
Investigating causal relations by econo-
metric methods and cross-spectral methods. Econometrica,
34:424–428, 1969.
[18] J. Haines, D. K. Ryder, L. Tinnel, and S. Taylor. Validation
of sensor alert correlators. IEEE Security & Privacy Maga-
zine, January/February, 2003.
[19] H. Kautz and J. F. Allen. Generalized plan recognition. In
Proceedings of the Fifth National Conference on Artiﬁcia l
Intelligence, pages 32–38, September 1986.
[20] B. Morin and H. Debar. Correlation of intrusion symptoms:
an application of chronicles. In Proceedings of the 6th Inter-
national Symposium on Recent Advances in Intrusion Detec-
tion (RAID 2003), Pittsburgh, PA, September 2003.
[21] P. Ning, Y. Cui, and D. S. Reeves. Constructing attack
scenarios through correlation of intrusion alerts.
In 9th
ACM Conference on Computer and Communications Secu-
rity, November 2002.
[22] J. Pearl. Probabilistic Reasoning in Intelligent Systems: Net-
works of Plausible Inference. Morgan Kaufmann Publishers,
Inc, 1988.
[23] P. A. Porras, M. W. Fong, and A. Valdes. A Mission-Impact-
Based approach to INFOSEC alarm correlation. In Proceed-
ings of the 5th International Symposium on Recent Advances
in Intrusion Detection (RAID), October 2002.
[24] X. Qin and W. Lee. Statistical causality analysis of IN-
FOSEC alert data.
In Proceedings of the 6th Interna-
tional Symposium on Recent Advances in Intrusion Detec-
tion (RAID 2003), Pittsburgh, PA, September 2003.
[25] X. Qin and W. Lee. Discovering novel attack strategies from
INFOSEC alerts. In Proceedings of the 9th European Sym-
posium on Research in Computer Security, Sophia Antipolis,
France, September 2004.
[26] C. Schmidt, N. Sridharan, and J. Goodson. The plan recog-
nition problem: an intersection of psychology and artiﬁcial
intelligence. Artiﬁcial Intelligence, 11:45–83, 1978.
[27] B. Schneier. Secrets and Lies: Digital Security in a Net-
worked World. John Wiley & Sons, August 2000.
[28] G. Shafer. A Mathematical Theory of Evidence. Princeton
University Press, 1976.
[29] O. Sheyner, J. Haines, S. Jha, R. Lippmann, and J. M. Wing.
Automated generation and analysis of attack graphs. In Pro-
ceedings of the 2002 IEEE Symposium on Security and Pri-
vacy, Oakland, CA, May 2002.
[30] A. Valdes and K. Skinner. Probabilistic alert correlation. In
Proceedings of the 4th International Symposium on Recent
Advances in Intrusion Detection (RAID), October 2001.
[31] R. Wilensky. Planning and Understanding. Addison Wes-
ley, 1983.
ily represent the ofﬁcial views of NSF and the U.S. Army.
References
[1] D. Albrecht and A. Nicholson. Bayesian models for keyhole
plan recognition in an adventure game. User Modeling and
User-Adapted Interaction, pages 5–47, 1998.
[2] E. Bauer, D. Koller, and Y. Singer. Update rules for pa-
rameter estimation in Bayesian networks.
In Proceedings
of the Thirteenth Conference on Uncertainty in Artiﬁcial In-
telligence (UAI), pages 3–13, Providence, RI, August 1997.
[3] S. Carberry. Incorporating default inferences into plan recog-
nition.
In Proceedings of the Eighth National Conference
on Artiﬁci al Intelligence, pages 471–478, Boston, Mas-
sachusetts, 1990.
[4] E. Charniak and R. P. Goldman. A probabilistic model of
plan recognition. In Proceedings of the Ninth National Con-
ference on Artiﬁci al Intelligence, pages 160–165, Anaheim,
California, 1991.
[5] E. Charniak and R. P. Goldman. A bayesian model of plan
recognition. Artiﬁcial Intelligence, 64(1):53–79, Novemeber
1993.
[6] E. Charniak and D. McDemott. Introduction to Artiﬁcial In-
telligence. Addison Wesley, 1985.
[7] S. Cheung, U. Lindqvist, and M. W. Fong. Modeling multi-
step cyber attacks for scenario recognition. In Proceedings of
the Third DARPA Information Survivability Conference and
Exposition (DISCEX III), Washington, D.C., April 2003.
[8] I. Cohen, A. Bronstein, and F. G. Cozman. Online learning
of bayesian network parameters. Hewlett Packard Laborato-
ries Technical Report, HPL-2001-55(R.1), June 2001.
[9] P. R. Cohen, C. R. Perrault, and J. F. Allen. Beyond question
answering. In W. Lehnert and M. Ringle, editors, Strategies
for Natural Language Processing, pages 245–274. 1981.
[10] G. F. Cooper. Probabilistic inference using belief networks is
np-hard. Technical Report KSL-87-27, Stanford University,
1988.
[11] F. Cuppens and A. Mi`ege. Alert correlation in a cooperative
intrusion detection framework. In Proceedings of the 2002
IEEE Symposium on Security and Privacy, pages 202–215,
Oakland, CA, May 2002.
[12] DAPRA Cyber Panel Program.
program grand
panel
http://www.grandchallengeproblem.net/, 2003.
challenge
DARPA cyber
problem (GCP).
[13] T. Dean and T. Wellman. Planning and Control. Morgan
Kaufmann, 1991.
[14] H. Debar and A. Wespi. The intrusion-detection console cor-
relation mechanism. In 4th International Symposium on Re-
cent Advances in Intrusion Detection (RAID), October 2001.
[15] C. W. Geib and R. P. Goldman. Plan recognition in intru-
sion detection system. In DARPA Information Survivability
Conference and Exposition (DISCEX II), June 2001.
[16] R. P. Goldman, W. Heimerdinger, and S. A. Harp. Informa-
tion modleing for intrusion report aggregation.
In DARPA
Information Survivability Conference and Exposition (DIS-
CEX II), June 2001.
10
Proceedings of the 20th Annual Computer Security Applications Conference (ACSAC’04) 
1063-9527/04 $ 20.00 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 11:39:39 UTC from IEEE Xplore.  Restrictions apply.