# Undermining an Anomaly-Based Intrusion Detection System Using Common Exploits

## Authors
Kymie M. C. Tan, Kevin S. Killourhy, and Roy A. Maxion

### Abstract
Over the past decade, numerous anomaly-detection techniques have been proposed and deployed to provide early warnings of cyber-attacks, particularly those involving masqueraders and novel methods. However, there has been no systematic study identifying methods that could be used by an attacker to undermine an anomaly-based intrusion detection system (IDS). This paper presents a method for crafting an offensive mechanism that renders an anomaly-based IDS blind to ongoing, common attacks. It identifies the weaknesses of an anomaly-based IDS and demonstrates how an attacker can manipulate common attacks to exploit these weaknesses. The paper also explores the implications of this threat and suggests possible improvements for existing and future anomaly-based IDSs.

## 1. Introduction
In recent years, a vast array of tools and techniques has been developed to ensure the availability, integrity, and confidentiality of electronic information systems. These security measures are often accompanied by equally sophisticated "shadow" arsenals designed to subvert them. While these shadow arsenals pose a significant threat, they also provide valuable insights into the weaknesses of current security tools, facilitating their improvement.

This work focuses on anomaly-based intrusion detection systems (IDSs), which aim to protect electronic information systems by detecting deviations from normal behavior. The assumption is that such deviations may indicate an ongoing or potential intrusion. Anomaly detection is one of two fundamental approaches in automated intrusion detection, the other being signature-based detection. Anomaly detection is particularly effective in identifying new or unforeseen vulnerabilities and abuse-of-privilege attacks, such as masquerading and insider misuse.

The promise of anomaly detection and its integration into various automated intrusion-detection strategies (e.g., AT&T’s ComputerWatch, SRI’s Emerald, SecureNet) highlights the importance of understanding how attackers might counteract these systems. This paper outlines a method to undermine a well-known anomaly-based IDS called stide [2] by first identifying the weaknesses of its detection algorithm and then demonstrating how an attacker can manipulate common attacks to exploit these weaknesses, effectively hiding the attacks from the detector.

To undermine an anomaly-based IDS, an attacker needs to know the three elements described in Table 1, which set the framework for the paper.

| **Table 1: Elements of Methodology for Undermining** |
|---|
| 1. Detection coverage (specifically, blind spots) of an anomaly detector. |
| 2. Where and how an attack manifests in sensor data. |
| 3. How to shift the manifestation from a covered spot to a blind one. |

## 2. Approaches to Undermining Anomaly Detectors
There are two primary approaches to causing an anomaly detector to miss an attack:

1. **Modify the normal to look like the attack:** Incorporate attack manifestations into the model of normal behavior.
2. **Modify the attack to make it appear as normal behavior:** Alter the attack so that it resembles normal behavior.

The most cited method in the literature is to incorporate intrusive behavior into the training data, thereby falsely representing "normal" behavior. This forces the anomaly detector to include the intrusive behavior in its internal model, rendering it unable to flag future instances of that behavior as anomalous. For example, if the system undergoes attacks during retraining, the detector may inadvertently incorporate undesired behavior into its model.

However, this method is imprecise and abstract, requiring time, patience, and system privileges that may not be available to an attacker. Moreover, it does not guarantee success, as the attack's interaction with other conditions in the data environment can still result in detectable anomalies.

To address these issues, it is necessary to determine the specific types of anomalies an anomaly detector can and cannot detect, and the conditions that enable or impede detection. This forms the basis of our approach.

## 3. Detection Coverage of an Anomaly Detector
Current evaluation techniques focus on the ability of an anomaly-based IDS to detect attacks but do not establish whether detected anomalies are attributable to the attack. Typically, claims of detection are based on assumptions that the attack must have manifested in a given data stream, that the manifestation was anomalous, and that the detector could detect that specific anomaly.

### 3.1 Brief Description of the Stide Anomaly Detector
Stide operates on fixed-length sequences of categorical data. It acquires a model of normal behavior by sliding a detector window over the training data, storing each sequence in a "normal database." The degree of similarity between test data and the model of normal behavior is determined by the number of identical matches between sequences from the test data and the normal database. The anomaly signal is based on a user-defined "locality frame," which sums the number of mismatches within a local region. The number of mismatches within a locality frame determines the extent of the anomaly.

### 3.2 Evaluation Strategy for Anomaly Detectors
Stide detects foreign sequences—those not present in the normal database. However, to fully understand its performance, we must consider:
- How foreign sequences manifest in categorical data.
- How the interaction between foreign sequences and the anomaly detection algorithm affects overall performance.

A framework was established to define the structure of anomalous sequences and their interaction with the sliding window of the anomaly-detection algorithm. This allowed for the evaluation of stide's detection efficacy on synthetic data with clearly defined anomalous sequences.

### 3.3 Stide’s Performance Results
The most significant finding from the anomaly-based evaluation of stide is that there are conditions under which the detector is completely blind to a particular type of foreign sequence: the minimal foreign sequence. A minimal foreign sequence is a foreign sequence whose proper subsequences all exist in the normal data. In other words, it contains no smaller foreign sequences.

![Detection Region and Blind Region](detection_blind_region.png)

This paper provides a detailed analysis of these findings and suggests possible improvements for enhancing the robustness of anomaly-based IDSs against such attacks.