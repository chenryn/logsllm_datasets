88%/91% 97%/98% 86%/51%
78%/79% 86%/80% 57%/55%
81%/80% 87%/80% 80%/60%
85%/98% 92%/99% 81%/79%
11%/35% 22%/42% 16%/24%
27%/11% 33%/12%
15%/9%
BITTORRENT 31%/83% 90%/90% 80%/38%
29%/65% 76%/67% 71%/64%
44%/5%
33%/7%
STREAMING 44%/25% 67%/32% 60%/18%
12%/90% 96%/95% 91%/46%
GNUTELLA
19%/19% 39%/21% 34%/14%
UNKNOWN
OVERALL
34%/69% 77%/75% 68%/55%
53%/7%
Table 4: Remaining ﬂows/bytes depending on the
ﬂow deﬁnition.
4.4 Performance Metrics
We use performance metrics to assess the quality of our
statistical classiﬁer that are commonly used in classiﬁca-
tion studies. They are built upon the notion of True Pos-
itives (TPs), True Negatives (TNs), False Positives (FPs)
and False Negatives (FNs). These notions are deﬁned with
respect to a speciﬁc class. Let us consider such a speciﬁc
class, say the WEB class. TPs (resp. FNs) are the fraction
of WEB ﬂows that are labeled (resp. not labeled) as WEB
by the statistical classiﬁer. FPs (resp. TNs) are the fraction
of ﬂows not labeled as WEB by ODT that are labeled (resp.
not labeled) as WEB by the statistical classiﬁer.
We use the following metrics to assess the performance of
the classiﬁcation method:
• Accuracy, a.k.a Recall: Accuracy corresponds to
the fraction of ﬂows of a speciﬁc class correctly classi-
ﬁed. It is the ratio of TPs to the sum of TPs and FNs
for this class. For example, an accuracy of 50% for the
WEB class means that only half of the WEB ﬂows are
labelled correctly by the statistical classiﬁer.
• Precision: For a given class, it is the ratio of TPs of
a class. For example, a precision of 100% for the WEB
class means that the statistical classiﬁer has put in this
class only WEB ﬂows. This result is satisfactory only
if all WEB ﬂows are actually in this class, which is
measured by the accuracy.
• Overall Accuracy: Sum of all True Positives to the
sum of all True Positives and False Positives for all
classes (i.e., the sum of all samples). Overall Accu-
racy is the fraction of correctly classiﬁed ﬂows over all
classes. If one class has more samples, it will have a
larger weight in the overall accuracy.
A classiﬁer works well if it oﬀers, not only high overall ac-
curacy, but both high accuracy and precision for all classes.
To explain speciﬁc misclassiﬁcation results, we further make
use of the confusion matrix, which indicates how the mem-
bers of each class are actually classiﬁed, i.e. in which class
they actually fall. In case we have perfect classiﬁcation this
matrix would be diagonal.
4.5 Training set
With supervised machine learning algorithm, one gener-
ally trains the classiﬁer on a fraction of the dataset and tests
its performance by applying the (trained) classiﬁer on the
remaining of the dataset. Classically, one relies on the 10-
fold cross validation technique: for each trace, the algorithm
is trained on one tenth of the data and then applied on the
remaining ﬂows for each possible slice comprising 10% of
the data. Reported results are averages of those ten experi-
ments.
A problem faced in traﬃc classiﬁcation is that the num-
ber of samples per class is highly varying. This might lead
the most prevalent classes to bias the training phase of the
classiﬁer. As an alternative, one can use a training set with
the same number of ﬂows per class. This approach was ad-
vocated in [3]. With our dataset and classes deﬁnition, we
must limit the number of ﬂows per class to a few hundreds
if one wants to apply this approach.
In order to evaluate the impact of diﬀerent learning sce-
narios, we trained our classiﬁer using two training sets: (i)
200 ﬂows for each class, (ii) 10,000 ﬂows for the applications
with enough ﬂows, and the maximum number of available
ﬂows for the less popular applications.
In both cases we obtained similar results with our datasets:
less popular classes (e.g. HTTP-STREAMING, GAMES,
DB) obtained higher accuracies as compared to the legacy
10-fold cross validation technique, but we observe a decrease
of accuracy for the dominant classes, e.g., it drops from 97%
to 53% for the WEB class in trace R-III. A closer look at
the confusion matrix reveals that by balancing the number
of training ﬂows, we are favoring less popular applications
causing popular classes to be misclassiﬁed. More generaly,
we can conclude that in case of unbalanced data sets like
ours, there apparently exists a tradeoﬀ between the overall
accuracy and the accuracy of less popular traﬃc classes.
Given the above observations, we decided to use 10-fold
cross validation in Section 5 where training and testing are
performed on the same trace. On the contrary, when train-
ing and testing are performed on diﬀerence traces – Section
6 – we use the whole dataset to build the model.
5. CLASSIFICATION - STATIC CASE
In this section we investigate the performance of statistical
classiﬁcation on each site, independently of the others. We
term “static case” this issue, as compared to the cross-site
case that we will detail in Section 6.
1265.1 Number of packets
When using the sizes of the ﬁrst data packets of a transfer
as classiﬁcation features, we must choose the actual number
of packets to be considered. We denote this number as k.
We choose the lowest k value that oﬀers good accuracy and
precision per application. In Figures 2 and 3, we depict the
evolution of accuracy and precision for increasing k values.
Results presented were obtained using trace MS-I, as they
are similar with other traces. Based on those results, we set
k to four packets for the rest of this paper. Note that this
value is in line with the ones recommended in [3].
The second family of classes is characterized by a high
precision but a low accuracy. This means that in such a
class, one ﬁnds mostly correctly classiﬁed ﬂows, but a large
fraction of the ﬂows that should be in this class, have been
classiﬁed elsewhere. This is the case for GAMES, STREAM-
ING and HTTP-STREAMING. In order to better under-
stand the problem of those poorly performing classes, we
use the confusion matrix (see Figure 4 obtained for set A).
To keep the ﬁgure clear we indicate only the misclassiﬁca-
tions higher or equal to 2%. We found that for the case of
HTTP-STREAMING, almost all misclassiﬁed ﬂows fall into
the WEB class, which is understandable as it might be diﬃ-
cult to discriminate between a streaming and a Web brows-
ing transfer. In contrast, Webmail and HTTP-ﬁle transfers,
are correctly classiﬁed in the WEB and FTP class respec-
tively. This outlines that the application semantics is more
important than the lower level protocols in those cases. This
is especially important for the case of HTTP as it becomes
a bearer for more and more diverse applications.
Figure 2: Per-class accuracy vs. number of packets
used.
Figure 4: Confusion Matrix for MSI trace, features
set A.(Class considered on Y axis is classiﬁed as
classes on X axis).
For the case of GAMES and STREAMING, misclassi-
ﬁed ﬂows are scattered mostly in the WEB and EDONKEY
classes. For the case of GAMES, we note that this class ag-
gregates applications with widely diﬀerent behaviors. This
heterogeneity might explain the diﬃculties faced by the sta-
tistical classiﬁer. This observation is further backed by the
fact that classiﬁcation performance are poor for both fea-
tures sets that we use – see Figures 5 and 6.
5.3 Static results - Discussion
Results of statistical classiﬁcation per site are in line with
the current knowledge about the state of the art ﬂow fea-
tures classiﬁers. Using both set of features we obtained good
results for most application classes. However, we would like
to assess feasibility of statistical classiﬁer usage as a stand
alone solution not accompanied by any DPI tool. In such a
case static experiment is not suﬃcient. We need to verify if
the model built over one site is representative enough to be
applied on diﬀerent platforms. We discuss this issue in the
next section.
Figure 3: Per-class precision vs. number of packets
used.
5.2 Static results
When the classiﬁer is run on the trace on which it was
trained, we obtained overall accuracies (over all classes) that
are consistently high, above 90% for both sets A and B. The
reason behind this result is that the dominant classes in each
traces (WEB and EDONKEY) are always very well classiﬁed
by the statistical classiﬁer. Results on a per application
basis are however much more contrasted. Per application
accuracy and precision are presented in Figures 5 and 6 for
set A and B respectively (results for R-III are omitted as
they are similar to the ones of R-II).
The main observation we make is that there exist two
broad families of classes. The ﬁrst family features both
a high accuracy and precision for all traces.
It contains
the following classes: WEB, EDONKEY, BITTORRENT,
GNUTELLA, CHAT, FTP, MAIL and OTHERS
(GNUTELLA and OTHERS classes have lower accuracy for
some traces but the results are still reasonably good).
1234567800.20.40.60.81# of packets used for the evaluationAccuracy  HTTP−STRGAMESSTREAMINGGNUTELLACHATDBFTPOTHERS & MAILWEB & BITTORRENTEDONKEY1234567800.20.40.60.81# of packets used for the evaluationPrecision  BITTORRENT & MAILEDONKEYOTHERSWEBGNUTELLADBCHATHTTP−STRSTREAMINGGAMESWEBEDONKEYMAILCHATHTTP_STROTHERSDBBITTORRENTFTPGAMESSTREAMINGGNUTELLA  WEBEDONKEYMAILCHATHTTP_STROTHERSDBBITTORRENTFTPGAMESSTREAMINGGNUTELLA90 %18 %5 %7 %4 %3 %3 %80%99 %99 %99 %99 %19 %96 %94 %99 %90 %52 %23 %56 %23 %56 %43 %18 %127(a) MS-I
(b) R-II
(c) T-I
Figure 5: Accuracy and Precision using packet sizes (set A) for static case.
(a) MS-I
(b) R-II
(c) T-I
Figure 6: Accuracy and Precision using set B for static case.
6. CLASSIFICATION - CROSS SITE
In this section, we address the problem of training a clas-
siﬁer on one site and then applying it to an other. Such a
technique could be useful for an ISP that would deploy some
deep packet inspection tool on one of its major PoPs, train
a statistical classiﬁer there and then apply it to its other
PoPs. As in the static case, we will ﬁrst look at the overall
performance of the classiﬁer, which means that we focus on
the dominant classes. In a second stage, we will detail re-
sults per application to illustrate the main outcome of this
section, namely the overﬁtting problem faced by statistical
classiﬁers in cross-site studies.
6.1 Overall Results
In Figure 9, we present the overall accuracy obtained using
one trace as a training set (on the y axis) and the others as
test sets (on the x-axis). The left matrix corresponds to the
use of set A (packet sizes) while the right matrix correspond
to set B (ﬂow features). Results are qualitatively similar:
the overall accuracy is in general high for the two feature
sets, though not as large as in the static case - see Figure
5. The more pronounced degradation is when the T-I trace
is considered (as a training or test trace). This might be
due to the fact that this trace is older (Dec. 2006) than the
other ones. Let us now dig into the details of each class for
each diﬀerent feature sets.
6.2 Set A (packet sizes)
Let us now dig into the details of each class. We focus
in this section on the case where the ﬁrst feature set (set
A) is used. Figure 10 depicts the per class accuracy4 in the
cross-site process. Note that we provide results only for the
classes that performed well (high accuracy and precision –
See Figures 5 and 6) in the static case: WEB, BITTOR-
RENT, CHAT, FTP, MAIL, EDONKEY, GNUTELLA and
OTHERS.
4Please note that Figures 9 and 10 use diﬀerent color scales.
Figure 7: CDF of size of the second packet for MAIL
and FTP.
Figure 8: Confusion Matrix for TI (training) on MSI
(testing).(Class considered on Y axis is classiﬁed as
classes on X axis).
00.20.40.60.81  WEBEDONKEYMAILCHATHTTP−STROTHERSDBBITTORRENTFTPGAMESSTREAMINGGNUTELLAAccuracyPrecision00.20.40.60.81  WEBEDONKEYMAILCHATHTTP−STROTHERSDBBITTORRENTFTPGAMESSTREAMINGGNUTELLAAccuracyPrecision00.20.40.60.81  WEBEDONKEYMAILCHATHTTP−STROTHERSDBBITTORRENTFTPGAMESSTREAMINGGNUTELLAAccuracyPrecision00.20.40.60.81  WEBEDONKEYMAILCHATHTTP_STROTHERSDBBITTORRENTFTPGAMESSTREAMINGGNUTELLAAccuracyPrecision00.20.40.60.81  WEBEDONKEYMAILCHATHTTP_STROTHERSDBBITTORRENTFTPGAMESSTREAMINGGNUTELLAAccuracyPrecision00.20.40.60.81  WEBEDONKEYMAILCHATHTTP_STROTHERSDBBITTORRENTFTPGAMESSTREAMINGGNUTELLAAccuracyPrecision−15000150000.20.40.60.81Packet size and direction [+/−]CDF  TI FTPMSI MAILMSI FTPTI MAIL01020304000.51  WEBEDONKEYMAILCHATHTTP_STROTHERSDBBITTORRENTFTPGAMESSTREAMINGGNUTELLA  WEBEDONKEYMAILCHATHTTP_STROTHERSDBBITTORRENTFTPGAMESSTREAMINGGNUTELLA010203040506070809010093 %98 %98 %75 %76 %99 %70 %75 %51 %88 %47 %45 %40 %28 %24 %20 %2 %2 %3 %11 %9 %9 %4 %4 %15 %5 %4 %2 %16 %15 %11 %2 %3 %2%17 %3 %5 %128A ﬁrst striking result is that EDONKEY appears immune
to performance degradation in a crosssite context5. This it
not the case for the other classes, even if most of the prob-
lems seem to stem from the T-I trace (older trace). This is
however not the only explanation behind the observed degra-
dations as there are also problems with BITTORRENT,
GNUTELLA, FTP and OTHER classes for the three traces
captured in 2008 (See Table 1).
As indicated in Section 3.1, we have two interesting pairs
of traces in our dataset. R-II and R-III have been captured
on the same site while MS-I and R-III were captured simulta-
neously. We do observe from Figure 10 that spatial similar-
ity seems more important than temporal similarity. Indeed,
for R-II and R-III results are consistently good: over 95%
for all classes except OTHERS, which is at 85%. However,
the latter class is a potpourri class and we are not certain
of having an homogeneous set of applications for this class
in the two traces. The picture is diﬀerent when we focus on
MS-I and R-III, as here results can degrade signiﬁcantly. For
FTP, accuracy falls to 52% when MS-I is used as a training
trace and R-III as a test trace (and 69% for the other way
around). This is in clear contrast with the static case where
the accuray was above 90% for the two traces.
We further investigated the case of FTP that seems ex-
tremely surprising. We picked on purpose one of the worse
performing cases (T-I against MS-I) in order to highlight
the problem. While the T-I trace is older, our focus is on
FTP and there is no reason to believe that its fundamental