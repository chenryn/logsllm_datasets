### 3. Overview

In this section, we provide an overview of model-based anomaly detection, including the addressed attacker threats, context-sensitive program models, and the purpose of attack discovery.

#### 3.1 Threat Model

Our system automatically constructs potential undetected attack sequences within a specific threat model. This threat model is both simple and robust:

- Let \(\Sigma\) be the set of system calls that invoke kernel operations. If a program \(P\) is under attacker control, then \(P\) can generate any sequence of system calls \(A \in \Sigma^*\).
- Attackers can subvert a vulnerable program's execution at any point, including during process initialization. They can arbitrarily alter the code and data of the program, or even replace the entire memory image with one of their choosing. Alternatively, the attacker could replace the disk image of a program with a trojan before the OS loads it for execution.
- The attacker can generate any sequence of system calls and arguments, and the operating system will execute these calls with the privileges of the original program.

This threat model aligns with real-world attacks, especially in remote execution environments where programs run on untrusted machines but send system calls back to a trusted machine. An attacker controlling the remote host can alter or replace the remote program, sending malicious system calls to the trusted machine.

Common network-based attacks against server programs have a more restrictive threat model. Attackers can only exploit specific vulnerabilities and face greater restrictions in the code they can execute. If our system detects an attack in the strong threat model, it will also detect it in a more restrictive model. However, successful attacks discovered by our system are specific to the strong threat model. Although the program model would fail to detect the attack sequence even in the restricted threat model, a restricted attacker may not be able to cause the program to execute that attack. Our system currently does not make this determination and will report all attacks discovered in the strong threat model.

**Example:**

Consider the example in Figure 2. This is a vulnerable program that reads command characters and filenames from user input, which may come from the network if the program is launched by a network service wrapper daemon like xinetd. The command-code and argument input resemble the usage of programs such as FTP servers or HTTP servers. Suppose the program is executed with stored but inactive privilege: its real and effective user IDs are a low-privilege user, but the saved user ID is root. If the input contains the command character 'x', the program drops all of its saved privilege and executes a filename given in the input. If the input contains the command character 'e', the program echoes the contents of a specified file to its output, which may be a network stream.

In our threat model, an attacker can arbitrarily alter the execution of this program. They might exploit the vulnerable `gets` call or use another attack vector. The attacker can cause the program to execute any system call, including those not in the original program code. The role of host-based intrusion detection is to detect such subverted program execution.

#### 3.2 Program Model

Readers familiar with pushdown automaton (PDA) models may skip this section, as it covers background material and standard notation previously used for PDA-based program models.

Model-based anomaly detection restricts allowed execution to a precomputed model of expected behavior. A program model \(M\) is a language acceptor of system call sequences and represents the program's expected execution behavior. If \(\Sigma\) denotes the alphabet of system calls, then \(L(M) \subseteq \Sigma^*\) denotes the language accepted by \(M\). A system call sequence in \(L(M)\) is valid; sequences outside \(L(M)\) indicate anomalous program execution. In this paper, we implement a program model as a non-deterministic pushdown automaton (PDA).

**Definition 1.** A pushdown automaton (PDA) is a tuple \(M = (S, \Sigma, \Gamma, \delta, s_0, Z_0, F)\), where:
- \(S\) is a set of states.
- \(\Sigma\) is a set of alphabet symbols.
- \(\Gamma\) is a set of stack symbols.
- \(\delta \subseteq \{(s, \gamma) \sigma \rightarrow (s', \gamma') | s, s' \in S, \gamma, \gamma' \in \Gamma \cup \{\epsilon\}, \sigma \in \Sigma \cup \{\epsilon\}\}\) is the transition relation.
- \(s_0 \in S\) is the initial state.
- \(Z_0 \in \Gamma\) is the initial stack configuration.
- \(F \subseteq S\) is a set of final states.

A PDA model closely mirrors program execution. States correspond to program points, the initial state to the entry point, and final states to termination points. Alphabet symbols are system calls, and stack symbols are return addresses. The transition relation \(\delta\) describes valid control flows within a program. Our PDA model has three types of transitions:
- **System calls:** \((s, \epsilon) \sigma \rightarrow (s', \epsilon)\) for \(\sigma \neq \epsilon\) indicates the program can generate a system call \(\sigma\) when transitioning from state \(s\) to state \(s'\).
- **Function calls:** \((s, \epsilon) \sigma \rightarrow (s', \gamma)\) for \(\gamma \neq \epsilon\) indicates the program pushes a return address \(\gamma\) onto the call stack when transitioning from state \(s\) to state \(s'\).
- **Function returns:** \((s, \gamma) \sigma \rightarrow (s', \epsilon)\) for \(\gamma \neq \epsilon\) indicates the program returns from a function call and pops the return address \(\gamma\) from the call stack.

Many program models proposed in academic literature can be characterized as PDAs. Context-free languages recognized by PDAs completely contain the class of regular languages. All known program models accept either regular or context-free languages and can be characterized by a PDA. This includes:
- Window-based models (e.g., Stide, Digraph).
- Non-deterministic finite automata (NFA).
- Bounded-stack PDAs.
- Deterministic PDAs (e.g., VPStatic).
- Stack-deterministic PDAs (e.g., Dyck).
- Non-deterministic PDAs.

**Figure 3** shows four different program models for the code in Figure 2, each expressed as a pushdown automaton.

When a model accepts a regular language, \(\Gamma = \emptyset\) and transitions in \(\delta\) are only of the form \((s, \epsilon) \sigma \rightarrow (s', \epsilon)\). Although our experiments consider the Stide model, a regular language acceptor, our system is designed to analyze pushdown automata, making it relevant to a wide range of program models.

#### 3.3 Finding Undetected Attacks

We have developed a model analysis system that evaluates a PDA-based program model and finds undetected attacks. Key features of our design include:
- **Automation:** A user provides an initial, one-time operating system abstraction that can be reused to analyze the model of any program executing on that OS. Subsequent analysis requires no human input, allowing easy scalability to large collections of program models.
- **Unknown Attacks:** The system does not require prior knowledge of attack sequences. It provides attack sequences as output.
- **System Call Arguments:** The system also provides the necessary system call arguments to effect the attack.

We construct an abstraction of the operating system with respect to its security-critical state. This abstraction can be repeatedly used to find attacks in the models of programs executing on that OS.

**Example:**

Running our tool for each of the four models in Figure 3 shows that none detect all attacks that execute a shell with root privilege. The tool automatically identifies a system call sequence, with arguments, that defeats each model:

```c
read(0);
setreuid(0, 0);
write(0);
execve("/bin/sh");
```

The `read` and `write` calls are nops irrelevant to the attack. The `setreuid` call alters the OS state to gain root access, and the `execve` call executes a shell with that access. One of our long-term goals is to use discovered undetected attacks to guide the future design of program models and intrusion detection systems. Comparing the undetected attack sequence with the original program code suggests a model alteration that would eliminate this undetected attack. If the model constrains statically-known system call argument values, an attacker cannot undetectably use the `setreuid` call to set the effective user ID to root. Although the attacker can still execute the shell, it will not have increased privilege.

We will consider additional examples in Section 5.

### 4. Operating System Model

Given a program model \(M\), answering the question "What attacks does \(M\) fail to detect?" requires understanding what constitutes an "attack." Previous work defined attacks as known, malicious sequences of system calls. Directly searching program models for these sequences has two drawbacks: