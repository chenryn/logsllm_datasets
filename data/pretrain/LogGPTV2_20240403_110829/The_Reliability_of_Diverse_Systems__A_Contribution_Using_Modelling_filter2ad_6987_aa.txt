# The Reliability of Diverse Systems: A Contribution Using Modelling of the Fault Creation Process

**Authors:** Peter T. Popov and Lorenzo Strigini  
**Affiliation:** Centre for Software Reliability, City University, Northampton Square, London, EC1V 0HB, UK  
**Email:** {ptp, strigini}@csr.city.ac.uk

## Abstract

Design diversity is a defense against design faults causing common-mode failures in redundant systems. However, there is a significant lack of knowledge regarding the extent to which it improves reliability in practice, its cost-effectiveness, the situations where it is an appropriate solution, and how it should be evaluated by assessors and safety regulators. Current practices and scientific debates on design diversity are largely based on intuition. More formal probabilistic reasoning would facilitate critical discussion and empirical validation of predictions. To this end, we propose a model of fault generation in two separately developed program versions. Our results address: (i) the degree of reliability improvement that can be expected from diversity, and (ii) how this improvement changes with higher-quality development processes. We also discuss the practical relevance and trustworthiness of these results.

## 1. Introduction

Design diversity is an intuitively appealing method for enhancing the reliability of critical systems, including software, subject to design errors. However, its use is controversial due to the lack of quantitative methods to evaluate its benefits. System designers cannot accurately determine the cost-effectiveness of diversity compared to other methods for improving system dependability. Safety assessors and regulators often lack the means to evaluate the effectiveness of diversity in a given system.

In design diversity, redundant computation channels run separate versions (or "variants") of the software, developed by independent teams without communication between them. Additional precautions, such as using different principles of operation, design methods, notations, and tools, may be taken to minimize the risk of common-cause errors ("forced" diversity).

Experimental evaluation of design diversity is challenging. Real-world diverse systems typically experience too few failures to provide precise indications of the gains from diversity, and controlled experiments are limited by cost and their inability to replicate industrial development processes accurately.

Practical decisions about using diversity, applying it in projects, and assessing its impact on system dependability are often based on industry-specific traditions, intuition, and speculation. This makes design diversity a contentious topic, despite its widespread use in some industries. Opponents argue that its benefits are limited and could be achieved more efficiently by better engineering of a single software version. Proponents counter that these claims are unproven and that diversity is an advantageous and feasible method. Resolving these arguments requires a consensus on how to estimate the benefits of diversity in specific situations.

Discussions on design diversity often rely on extending limited experimental knowledge with assumptions and claims that participants find intuitively plausible. For example, Hatton [1] speculates about the reliability gain from multiple-version software based on the reliability advantage observed in the Knight-Leveson experiment [2] and the assumption that increasing the reliability of individual versions enhances the benefit of diversity. While useful for stimulating debate, this approach lacks a verifiable causal model.

We aim to improve on previous discussions by modeling the effects of diversity using a more concrete representation of the mechanisms believed to produce them. Following the approaches of Eckhardt and Lee [4] and Littlewood and Miller [3], we develop a model that focuses on observable entities in software development and predicts measures of practical interest.

We limit our discussion to a simple but practically important scenario:
- We consider "non-forced" diversity, achieved by enforcing strict separation between the development of two versions. This represents both actual software projects and a worst-case analysis for systems using "forced" and "functional" diversity.
- We analyze the simplest diverse-redundant configuration: two versions with perfect adjudication (simple "OR" combination of binary outputs, forming a 1-out-of-2 diverse system). This configuration is relevant in plant protection systems (Figure 1).

In Section 2, we describe our model. In Section 3, we address two key questions:
- What level of reliability improvement can be expected from using diversity? This is relevant for assessors and project managers.
- How does the reliability improvement change with the quality of the development process? This question concerns the evolution of development processes and the trade-offs in adopting different strategies to enhance dependability.

In Sections 4 and 5, we examine the implications of our model for high-quality and low-probability fault scenarios, respectively. Section 6 discusses the realism of our models, and Section 7 presents our conclusions.

## 2. Our Model

### 2.1. Failure Points and Failures

Consider the demand space, which is the set of all possible demands on the 2-channel system. A demand occurs when the controlled system enters a state requiring the intervention of the protection system. Demands differ in the details of the controlled system's state, leading to different input sequences. A design fault in a version means that for one or more demands, the version will not respond as required (it will fail). Each such demand is a failure point in the demand space for that version. A set of demands on which a version fails is called a failure region for that version. If a failure region of one version overlaps with a failure region of the second version, their intersection is a failure region for the system, causing the two-version system to fail.

Each demand in the demand space has a certain probability of occurring during the operation of the controlled system. Summing the probabilities of all demands that are failure points for both versions gives the probability of failure on demand (PFD) for the two-version protection system. This forms the basis of the models used in [3] and [4].

### 2.2. Faults and Their Introduction

A design mistake typically affects a set of points in the demand space rather than a single point. If the mistake is made, the entire set becomes a failure region; if not, the failure region does not exist. Our model considers a fixed set of possible faults, each with an associated failure region. A mistake here refers to a process error that leaves a fault in the delivered product. 

[The rest of the text continues in a similar manner, following the structure and content of the original text while ensuring clarity, coherence, and professionalism.]