### Relative Ranking of CSPs and CSC for a Specific SLO

For a given Service Level Objective (SLO) \( k \), the relative rank of Cloud Service Provider 1 (CSP1,k) over Cloud Service Provider 2 (CSP2,k) is denoted as \( \text{CSP1,k/CSP2,k} \). Similarly, \( \text{CSP1,k/CSCk} \) indicates the relative rank of CSP1,k with respect to the Customer Security Criteria (CSCk), specifying whether CSP1,k meets the CSCk requirements. This results in a one-to-one comparison matrix (CM) of size \((n + 1) \times (n + 1)\) if there are \( n \) CSPs and one CSC for each SLO, as shown below:

\[
\text{CM}_k =
\begin{bmatrix}
\frac{\text{CSP1,k}}{\text{CSP1,k}} & \frac{\text{CSP2,k}}{\text{CSP1,k}} & \cdots & \frac{\text{CSPn,k}}{\text{CSP1,k}} & \frac{\text{CSCk}}{\text{CSP1,k}} \\
\frac{\text{CSP1,k}}{\text{CSP2,k}} & \frac{\text{CSP2,k}}{\text{CSP2,k}} & \cdots & \frac{\text{CSPn,k}}{\text{CSP2,k}} & \frac{\text{CSCk}}{\text{CSP2,k}} \\
\vdots & \vdots & \ddots & \vdots & \vdots \\
\frac{\text{CSP1,k}}{\text{CSPn,k}} & \frac{\text{CSP2,k}}{\text{CSPn,k}} & \cdots & \frac{\text{CSPn,k}}{\text{CSPn,k}} & \frac{\text{CSCk}}{\text{CSPn,k}} \\
\frac{\text{CSP1,k}}{\text{CSCk}} & \frac{\text{CSP2,k}}{\text{CSCk}} & \cdots & \frac{\text{CSPn,k}}{\text{CSCk}} & \frac{\text{CSCk}}{\text{CSCk}}
\end{bmatrix}
\]

The relative ranking of all cloud providers and the customer for each SLO is calculated as a priority vector (PV) of the CM. The PV is an approximation of the eigenvector of the CM, indicating a numerical ranking of providers that specifies the order of preference based on the ratios of numerical values.

\[
\text{PV}_k = \left( \frac{\text{CSP1,k}}{N_1,k}, \frac{\text{CSP2,k}}{N_2,k}, \ldots, \frac{\text{CSPn,k}}{N_n,k}, \frac{\text{CSCk}}{N_u,k} \right)
\]

Where \( N_1 \) is a numerical value representing the relative rank of CSP1 to other CSPs and the CSC regarding an SLO. \( N_u \) is the relative rank of the CSC's required security level with respect to the security levels offered by the CSPs.

### Phase 4: Services Aggregation

In the final phase, we perform a bottom-up aggregation to provide an overall assessment of the security levels and a final ranking of the CSPs (refer to Figure 7). To achieve this, the priority vector of each SLO (from Phase 3) is aggregated with their relative normalized weights (dependency importance level) specified in Phase 2. This aggregation process is repeated for all SLOs in the hierarchy with their relative weights.

\[
\text{PV}_{\text{aggregated}} = \left( \text{PV}_{k1} \cdot W_{k1} + \text{PV}_{k2} \cdot W_{k2} + \ldots + \text{PV}_{kn} \cdot W_{kn} \right)
\]

Where \( W \) is the set of normalized weights of different SLOs such that \( W = \{ w_{k1}, w_{k2}, \ldots, w_{kn} \} \). Note that the weights are normalized to satisfy the Analytic Hierarchy Process (AHP) requirements. \( \text{PV}_{k1} \) is the PV calculated for SLO \( k1 \). \( \text{PV}_{\text{aggregated}} \) is the aggregated PV, which shows the ranking of all the CSPs based on the customer-defined requirements and weights. We demonstrate and validate the framework presented in this section using a real-world case study in Section 4.

### 4. Case Study: Security Evaluation

This section provides an empirical validation of the proposed framework through two scenarios using real-world security SLA information derived from the Cloud Security Allianceâ€™s STAR repository [8].

#### 4.1 The Customer Perspective: Security Comparison of CSPs

This initial validation scenario demonstrates how a cloud customer can use the framework to compare three different CSPs based on their advertised secSLAs (compliant with the hierarchy in Figure 2) and with respect to a particular set of security requirements (also expressed as a secSLA). Table 2 presents a sample dataset used for this scenario, based on the information available in the CSA STAR repository, where the values associated with 15 SLOs for the three selected CSPs are presented.

To perform a comprehensive validation, the selected SLOs include both qualitative and quantitative metrics. Qualitative metrics are specified as security levels (e.g., monthly, weekly, daily, denoted as level1, level2, and level3). No/yes metrics are denoted as level0 and level1, respectively. All CSPs' security SLOs are normalized to the customer requirements to eliminate masquerading. Table 2 also shows two sets of cloud customer requirements used as a baseline for comparing the selected CSPs:

1. **Case I**: In the column marked as Case I, the customer requirements are expressed at a per-SLO granular level, representing a security-expert customer. The customer specifies their requirements in the "req" column. After validating the customer secSLA to check if each constraint between two dependent SLOs is satisfied, any conflicts found are resolved by specifying new values to the SLOs causing conflicts. These new values are shown in the "rev" column in Table 2.
   
2. **Case II**: The column marked as Case II shows a set of requirements on SLOs that do not depend on any other SLO (identified using the DSM). These SLOs are used to model the customer requirements for the remaining SLOs, suitable for a novice or basic customer who cannot specify all the secSLA SLOs and resolve conflicts if any are found.

Finally, we consider dependencies between services and SLOs, which will be validated using the validation model presented in Section 3.2. For example, AC2.1 is medium dependent on AC1.1.

\[
\text{SLO Dependencies:}
\]
- AC2.1 is medium dependent on AC1.1

This structured approach ensures a thorough and systematic evaluation of CSPs based on the customer's security requirements.