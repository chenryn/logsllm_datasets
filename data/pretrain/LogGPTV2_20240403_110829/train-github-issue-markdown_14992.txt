I've written a code that uses flow_from_directory method to import augmented
images and their masks into a generator.
Then I want to 'reshape' these masks and create 'sample_weight' vector and
build my own custom generator that yields (image, mask, sample_weights).
This is my implementation:
    data_trn_gen_args_mask = dict(preprocessing_function = preprocess_mask,
                                  horizontal_flip=True, 
                                  zoom_range=0.2)
    data_trn_gen_args_image = dict(preprocessing_function = preprocess_input,
                                   horizontal_flip=True, 
                                   zoom_range=0.2)
    mask_datagen = ImageDataGenerator(**data_gen_args_mask)
    image_datagen = ImageDataGenerator(**data_gen_args_image)
    image_generator = image_datagen.flow_from_directory(PATH, 
                                                        classes = ['train'], 
                                                        class_mode=None, 
                                                        batch_size=16, 
                                                        shuffle=True, 
                                                        seed=29)
    mask_generator = mask_datagen.flow_from_directory(PATH, color_mode = 'grayscale'
                                                      classes = ['SegmentationClassAug'], 
                                                      class_mode=None, 
                                                      batch_size=16, 
                                                      shuffle=True, 
                                                      seed=29)
    def segmentation_generator(image_gen, mask_gen):
        while True:
                X = image_gen.next()
                y = mask_gen.next()
                y = np.reshape(y, (mask_gen.batch_size, -1, 1))
                y = y.astype('int32')
                sample_weights = np.ones(y.shape)
                sample_weights[y==0] = .1
                sample_weights[y==255] = 0
                yield X, y, sample_weights[...,0]
    train_gen = segmentation_generator(image_generator, mask_generator)
    model.fit_generator(train_gen, ...)
It works, but I'm concerned since this implementation doesn't avoid duplicate
data when using multiprocessing, as I'm not using **keras.utils.Sequence**
object.
How should I modify **segmentation_generator** then?
Thanks in advance