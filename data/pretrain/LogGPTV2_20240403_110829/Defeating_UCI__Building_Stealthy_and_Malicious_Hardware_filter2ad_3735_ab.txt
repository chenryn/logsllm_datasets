A circuit is in the non-trigger condition whenever
the trigger inputs are not driven with the trigger
values, i.e., when the trigger condition is false.
Under the non-trigger condition, the circuit exhibits
its expected behavior.
Admissible Circuit:
We say that a circuit is admissible if: (1) there
exists exactly one trigger condition, (2) the circuit
has at least one non-trigger input, and (3) under the
non-trigger condition, the trigger inputs become
don’t-cares (do not have any effect on the output
value of the circuit). Our search algorithm only
examines admissible circuits.
The admissibility requirement deﬁnes a clear sep-
aration between trigger and non-trigger inputs and
ensures that any constructed malicious circuits will
still pass design-time testing.
Note that while the deﬁnition of admissibility re-
quires the output of the circuit to be independent
of the particular values on the trigger inputs in the
non-trigger condition, we do not place a similar
66
restriction on non-trigger inputs. In the trigger
condition, the output of the circuit is permitted
to depend upon non-trigger inputs (the non-trigger
inputs do not need to be don’t-cares in this case).
Obviously Malicious Circuit:
We deﬁne a circuit to be obviously malicious if
there exists any two valuations to the inputs to the
circuit x = (i, t), x′ = (i, t′) where t is in the non-
trigger condition and t′ is in the trigger condition
and C(x) 6= C(x′). In other words, the circuit is
malicious if changing just the trigger inputs from
a non-trigger value to the trigger value can change
the output of the circuit (presumably, activating its
hidden functionality).
Stealthy Circuit:
We deﬁne a circuit
to be stealthy if UCI will
not ﬂag any part of the circuit as malicious. We
assume the test suite used by UCI includes every
possible input where the trigger condition is false.
(We discuss the implications of this assumption in
Section VI.) Thus, a circuit will be stealthy if there
is no pair of dependent wires that are always equal
during design-time testing. To be more precise, a
circuit C = (f, S) will be stealthy if there is no
pair si, sj of internal wires (si ∈ S, sj ∈ S ∪ {f })
such that data can ﬂow from si to sj, and such that
si = sj always holds for all inputs satisfying the
non-trigger condition.
B. Deﬁning Malice and Requiring Admissibility
Our deﬁnitions of admissible and obviously malicious cir-
cuits require further discussion. We emphasize that these are
intended to serve as a sufﬁcient, but not necessary, condition
under which a circuit could be used in an attack. They are
by no means an exhaustive characterization of when a circuit
might contain a hidden backdoor. For instance, we can
imagine circuits that do not have a clear separation between
trigger and non-trigger inputs, and which exhibit hidden
behavior if the entire input satisﬁes a certain rare condition;
such circuits might be useful to an attacker, but would not
be found by our search. Our deﬁnitions are intended solely
to make algorithmic search easier, by focusing the search
on a particular type of dangerous circuit. Our results show
that this is sufﬁcient to ﬁnd serious attacks against the UCI
algorithm—but we do not claim that it can be used to create
all possible attacks.
Our focus on circuits that have a clean separation between
trigger and non-trigger inputs is motivated by the need
for some objective way to recognize malicious circuits.
Consider, for example, a single AND gate with two inputs
and one output. Without any further context, there is no
meaningful way to classify this circuit as benign or ma-
licious. Since we can not determine a priori whether a
constructed circuit is malicious, we instead look for hidden
functionality. Hidden functionality should be triggered only
in a special condition that is unlikely to arise in normal
design-time testing. A simple special case arises when some
of the inputs are used only to trigger the hidden functionality,
and do not otherwise affect
the circuit’s behavior. This
motivates separating the inputs into non-trigger vs. trigger
inputs. If the circuit exhibits new behavior when the trigger
inputs are set to a special value, then we consider that the
circuit has hidden behavior and thus may be malicious.
We impose the admissibility requirement only to facilitate
algorithmic search. It is possible to imagine a malicious
circuit in which all inputs affect the output at all times, but
one particular combination of inputs produces an unwanted,
malicious behavior. (Indeed, in a real-world setting, this is a
particularly plausible type of attack.) However, recognizing
that such a circuit
is malicious requires some semantic
knowledge of desirable vs. undesirable behavior.
To see why this is so, we consider an example. Suppose
C is a circuit with two trigger inputs t = (t0, t1) and with
trigger condition t0 ∧ t1 (i.e., the trigger condition holds if
t = (1, 1)). The admissibility constraint requires
∀i . C(i, (0, 0)) = C(i, (1, 0)) = C(i, (0, 1)),
i.e., so long as the trigger inputs are not both “1”, they do not
affect the output of the circuit. If the circuit is admissible,
we can easily recognize it as malicious if we have
∃i, t . C(i, t) 6= C(i, (1, 1)),
since this means that when the trigger inputs are fed with a
special value (namely, (1, 1)), the circuit behaves differently.
Now assume that the circuit C is not admissible. In this
case, it would be easy to ﬁnd a pair of inputs (i, t), (i, t′)
such that C(i, t) 6= C(i, t′), which implies that either
C(i, t) 6= C(i, (1, 1)) or C(i, t′) 6= C(i, (1, 1)). This is true
regardless of whether the circuit is malicious or not. In other
words, if C is not admissible, it is always true that
∃i, t . C(i, t) 6= C(i, (1, 1)),
whether C is malicious or not. Therefore, in the absence
of any kind of speciﬁcation of desirable behavior, there is
no clear basis for distinguishing a malicious circuit from a
non-malicious circuit.
Even though we only include admissible circuits in our
search results, as we show in Section IV-B, we were able
to easily translate one of the circuits from our search results
into a real-world attack.
C. Methodology
With the deﬁnitions in place, we can now explain our
methodology more precisely. We enumerate all circuits in
the class deﬁned by the following parameters:
• 1 or 2 non-trigger inputs: i = (i0, i1) or i = (i0).
• 2 trigger inputs: t = (t0, t1).
67
• Basis of gates given by the set G, where
G ⊆ {AND, OR, NOT, NAND, 2-input MUX}.
• Trigger condition given by t0 ∧ t1 (i.e., the trigger
condition holds if t = (1, 1)).
• Circuit size: N ≤ 3.
For each circuit enumerated, if it is admissible, obviously
malicious, and stealthy, we add it to our set of malicious
circuits that can evade detection by UCI.
D. Searching for Circuits
Our search algorithm works as follows. We maintain a
workqueue of newly formed circuits—these will serve as
building blocks for future circuits. We also maintain a set of
completed circuits R. Roughly speaking, in each iteration of
the algorithm we remove one circuit C from the workqueue,
consider all ways to expand C by adding one gate, add each
new circuit generated in this way to the workqueue, and then
add C to the list of completed circuits.
More precisely, we initialize the search by setting R := ∅
and populating the workqueue with four circuits: C0 =
(i0, ∅), C1 = (i1, ∅), C2 = (t0, ∅), C3 = (t1, ∅). In
each iteration, we remove one circuit from the front of the
workqueue, say C = (f, S). If C is admissible, obviously
malicious, and stealthy, we output C and the search contin-
ues with the next circuit in the queue. Otherwise, for each
gate g ∈ G and each circuit C ′ ∈ R ∪ {C}, we build a new
circuit C ′′ as C ′′ = g(C, C ′). If C ′′ is stealthy and not in R,
it is appended to the workqueue, otherwise it is discarded.
Once C has been combined with every circuit in R ∪ {C},
using every gate in G, C is added to the set R.
there is no point
This approach only explores circuits where every subcir-
cuit is stealthy. Note that for a circuit C to be stealthy,
it is necessary for every subcircuit of C to be stealthy;
therefore,
in exploring circuits with a
subcircuit that is not stealthy. Also, the algorithm does not
distinguish between two circuits C1, C2 with the same output
function and set of internal functions: if C1 = (f, S) and
C2 = (f, S), then these two circuits are indistinguishable
in terms of UCI and in terms of their externally observable
behavior, so we keep one of C1, C2 and discard the other.
This partitions circuits into equivalence classes and only
keeps one representative of each equivalence class in the
workqueue and completed set.
We conducted the above search multiple times, each
time using a different basis G of gates.
In particu-
lar, we conducted a separate search for each subset
of {AND, OR, NOT, NAND, 2-input MUX}, excluding the
empty set. The pseudo-code for the algorithm is shown
below. We summarize the results of this search in Section
V-D.
IV. ATTACKS
From the set of admissible, obviously malicious, and
stealthy circuits returned by our search, we select a small
Algorithm 1 Searching for stealthy, admissible, obviously
malicious circuits
// Initial circuits, one for each input.
C0 = (i0, ∅)
C1 = (i1, ∅)
C2 = (t0, ∅)
C3 = (t1, ∅)
// The set of already-considered circuits.
completed_circuits = ∅
// The circuits to use as building blocks in larger circuits.
workqueue = [C0, C1, C2, C3]
// The set of gates to use in building circuits.
gate_basis = {AND, OR, NOT}
/∗ While there are still circuits in the workqueue, pop
the next one off and combine it with every previously-
considered circuit and with itself. ∗/
while length(workqueue) > 0 do
curr_circuit = workqueue.pop()
if curr_circuit is stealthy, admissible, and obvi-
ously malicious then
print curr_circuit
else
for all gate in gate_basis do
for all circ in completed_circuits ∪
{curr_circuit} do
new_circuit = gate(curr_circuit,
circ)
if new_circuit is
completed_circuits then
stealthy and not
in
workqueue.append(new_circuit)
end if
end for
end for
completed_circuits.add(curr_circuit)
end if
end while
circuit to analyze in order to gain an understanding of how it
evades UCI. We then select a more complex circuit with the
desired trigger condition and non-trigger condition output
behavior for use in creating a privilege escalation attack in
the Leon3 processor. We show that the attack evades UCI
analysis.
A. Example Circuit
The smallest circuit we found that satisﬁed our criteria
was a two-gate circuit with basis G = {MUX}. This circuit
is shown below in Figure 2. The inputs to the circuit are
i = (i0, i1) (non-trigger inputs) and t = (t0, t1) (trigger
inputs). The trigger condition is t0 ∧ t1. The output function
of the circuit is f = (i0 ∧ i1) ∨ (t0 ∧ t1 ∧ ¬i1). Under
68
non-trigger conditions the output function is fN T = i0 ∧ i1.
Under trigger conditions the output is fT = i0 ∨ ¬i1.
i0
t0
h
t1
i1
f
Figure 2. Two-gate, stealthy, admissible, and malicious circuit.
i0
This circuit evades detection by UCI because there is no
pair of dependent signals that are always equal under the
non-trigger condition. The truth table in Figure 3 shows the
input values and associated output values for this stealthy
MUX circuit. In addition to showing the output function f ,
the table shows the values for the lone internal signal h.
The rows below the dashed horizontal line are the signal
values under the trigger condition, which are not seen
during design-time testing. The ﬁnal column notes when
an input makes a dependent pair of signals unequal. The
data in the table shows that if the test suite includes the
inputs (t1, t0, i1, i0) = (0, 0, 0, 1), (0, 1, 0, 1), (1, 0, 0, 1),
and (1, 0, 1, 0), then UCI will not ﬂag any part of the circuit
as malicious. Since the trigger condition for all of these
inputs is false and fN T = i0 ∧ i1, for every test case this
circuit will behave identically to an AND gate applied to i0
and i1.
If a rogue designer has access to the source code of
some security-critical hardware, he can replace any AND
gate with the malicious circuit in Figure 2 and cause it to
behave differently under a special condition that might not
be exercised during design-time testing. If this affects some
security-critical element of the hardware, it might introduce
a hidden vulnerability or backdoor that is not detected by
UCI.
UCI misses this behavior because the way the circuit was
constructed, there is no intermediate function equivalent to
i0 ∧ i1 that UCI can short-circuit the output with. This idea
of creating a non-trigger function which is not equivalent to
any internal function is the key to defeating UCI.
B. Practical Attack
The previous example indicates there are ways to con-
struct simple circuits with hidden behavior that evade UCI.
In this section, we show how an attacker can replace the
functionality of a larger design with one of these circuits
t1
0
0
0
0
0
0
0
0
1
1