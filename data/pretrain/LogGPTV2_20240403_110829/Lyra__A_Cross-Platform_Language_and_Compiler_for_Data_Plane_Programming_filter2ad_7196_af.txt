warding policy via network-wide abstractions such as SNAP [14],
NetKAT [13, 31], Magellan [41], NetCore [33], and Frenetic [19]. In
terms of the programming model, SNAPâ€™s one-big-switch (OBS) ab-
straction [14] is the most relevant to Lyra; however, the OBS model
cannot explicitly specify the fine-grained scope, e.g., a specific set
of switches. P4Runtime [10] offers control plane-level APIs for P4
programs, rather than a compiler generating ASIC code. In general,
the state-of-the-art programming models in SDN aim to generate
the forwarding rules, which have different goals from Lyra.
Programmable ASIC compilers. The state-of-the-art efforts in
programmable ASIC compilers focus on compilation for individual
devices. ğœ‡P4 [39] also targets portability and composition problems;
different from Lyra, however, ğœ‡P4 only supports P4-family program-
ming, and does not target data plane programming across multiple
switches. Jose et al. [26] compiles P4 programs to architectures
such as the RMT and FlexPipe. Domino [37] builds upon the Banzai
machine model that supports stateful packet processing, supporting
a much wider class of data plane algorithms. Chipmunk [20, 21]
leverages slicing, a domain-specific synthesis technique, to optimize
Domino in compilation time and resource usage. Different from the
state of the arts, Lyra offers a new, chip detail-orthogonal language,
generates chip-specific code (like NPL and P4), and supports data
plane programming across multiple switches.
P4 synthesis for programmable NICs. Programmable NICs (e.g.,
Netcope [8], Netronome [9] , and Pensando [11]) support P4. Com-
pared with Lyra, there are two differences. First, Lyra takes as input
an OBP program and generates chip-specific programs for different
ASIC architectures. The P4 compilers for programmable NICs take
as input P4 programs and generate binary code. Second, Lyra can
generate code across a distributed setting consisting of multiple
programmable switches, but P4 NICs do not target such a goal.
We believe Lyra is potentially extendable to programmable NICs,
but this requires non-trivial extensions such as new NIC-function
synthesis algorithm and NIC-specific constraints encoding.
P4 Virtualization. P4 virtualization (e.g., Hyper4 [23], HyperV [42],
HyperVDP [43], and P4Visor [44]) offers a general-purpose P4 pro-
gram that can be dynamically configured to adopt behaviors equiv-
alent to other P4 programs. Different from Lyra, P4 virtualization
aims to mimic the target P4 programâ€™s behavior by configuring
table entries for the underlying â€œhypervisorâ€ program (e.g., hp4.p4
in Hyper4 [23]), rather than generating chip-specific code like Lyra.
10 CONCLUSION
Lyra is the first compiler that allows the network programmers to
program data plane while achieving portability, extensibility, and
composition. Lyra offers a one big pipeline programming model
for the programmers to conveniently express their data plane algo-
rithms, and then generates chip-specific code across multi-vendor
switches. Our evaluation results show that Lyra not only generates
runnable real-world programs (in both P4 and NPL), but also uses
fewer hardware resources than human-written programs.
This work does not raise any ethical issues.
ACKNOWLEDGMENTS
We thank our shepherd, Noa Zilberman, and SIGCOMM review-
ers for their insightful comments. Jiaqi Gao and Minlan Yu are
supported in part by the NSF grant CNS-1413978.
[6] 2020. Barefoot Tofino. https://www.barefootnetworks.com/products/brief-tofino.
[7] 2020. Barefoot Tofinoâ€™s 32Q-model and 64Q-model. https://www.arista.com/en/
[8] 2020. Netcope P4 â€“ Flexible FPGA Programming. https://www.netcope.com/en/
com/p4lang/p4c.
products/7170-series.
products/netcopep4.
REFERENCES
[1] 2019.
Broadcomâ€™s new Trident 4 and Jericho 2 switch devices of-
https://www.broadcom.com/blog/
fer programmability at scale.
trident4-and-jericho2-offer-programmability-at-scale.
[2] 2019. In-band Network Telemetry (INT) Dataplane Specification. https://github.
com/p4lang/p4-applications/blob/master/docs/INT.pdf.
[3] 2019. NPL 1.3 Specification. https://github.com/nplang/NPL-Spec.
[4] 2019. ONE Silicon, ONE Experience, MULTIPLE Roles. https://blogs.cisco.com/
sp/one-silicon-one-experience-multiple-roles.
[5] 2019. p4c, a reference compiler for P4 programming language. https://github.
[9] 2020. Netronome P4. https://www.netronome.com/technology/p4/.
[10] 2020. P4Runtime. https://p4.org/p4-runtime/.
[11] 2020. Pensando Expands What SmartNIC Offloads Can Do. https://pivotnine.
com/2020/05/18/pensando-expands-what-smartnic-offloads-can-do/.
[12] Mohammad Alizadeh, Tom Edsall, Sarang Dharmapurikar, Ramanan
Vaidyanathan, Kevin Chu, Andy Fingerhut, Vinh The Lam, Francis Ma-
tus, Rong Pan, Navindra Yadav, and George Varghese. 2014.
CONGA:
distributed congestion-aware load balancing for datacenters. In ACM SIGCOMM
(SIGCOMM).
[13] Carolyn Jane Anderson, Nate Foster, Arjun Guha, Jean-Baptiste Jeannin, Dexter
Kozen, Cole Schlesinger, and David Walker. 2014. NetKAT: Semantic foundations
for networks. In 41st Annual ACM SIGPLAN-SIGACT Symposium on Principles of
Programming Languages (POPL).
[14] Mina Tahmasbi Arashloo, Yaron Koral, Michael Greenberg, Jennifer Rexford,
and David Walker. 2016. SNAP: Stateful network-wide abstractions for packet
processing. In ACM SIGCOMM (SIGCOMM).
[15] Pat Bosshart, Dan Daly, Glen Gibb, Martin Izzard, Nick McKeown, Jennifer
Rexford, Cole Schlesinger, Dan Talayco, Amin Vahdat, George Varghese, and
David Walker. 2014. P4: programming protocol-independent packet processors.
Computer Communication Review 44, 3 (2014), 87â€“95.
[16] Pat Bosshart, Glen Gibb, Hun-Seok Kim, George Varghese, Nick McKeown, Martin
Izzard, Fernando A. Mujica, and Mark Horowitz. 2013. Forwarding metamorpho-
sis: fast programmable match-action processing in hardware for SDN. In ACM
SIGCOMM (SIGCOMM).
[17] Pat Bosshart, Glen Gibb, Hun-Seok Kim, George Varghese, Nick McKeown, Martin
Izzard, Fernando Mujica, and Mark Horowitz. 2013. Forwarding metamorpho-
sis: Fast programmable match-action processing in hardware for SDN. ACM
SIGCOMM Computer Communication Review 43, 4 (2013).
[18] Leonardo MendonÃ§a de Moura and Nikolaj BjÃ¸rner. 2008. Z3: An efficient SMT
solver. In 14th Tools and Algorithms for the Construction and Analysis of Systems
(TACAS).
[19] Nate Foster, Rob Harrison, Michael J. Freedman, Christopher Monsanto, Jennifer
Rexford, Alec Story, and David Walker. 2011. Frenetic: a network program-
ming language. In 16th ACM SIGPLAN international conference on Functional
Programming (ICFP).
[20] Xiangyu Gao, Taegyun Kim, Aatish Kishan Varma, Anirudh Sivaraman, and
Srinivas Narayana. 2019. Autogenerating fast packet-processing code using
program synthesis. In 18th ACM Workshop on Hot Topics in Networks (HotNets).
[21] Xiangyu Gao, Taegyun Kim, Michael D. Wong, Divya Raghunathan, Aatish Kis-
han Varma, Pravein Govindan Kannan, Anirudh Sivaraman, Srinivas Narayana,
and Aarti Gupta. 2020. Switch code generation using program synthesis. In ACM
SIGCOMM (SIGCOMM).
[22] Arpit Gupta, Rob Harrison, Marco Canini, Nick Feamster, Jennifer Rexford, and
Walter Willinger. 2018. Sonata: query-driven streaming network telemetry. In
ACM SIGCOMM (SIGCOMM).
[23] David Hancock and Jacobus E. van der Merwe. 2016. HyPer4: Using P4 to
virtualize the programmable data plane. In 12th International Conference on
emerging Networking EXperiments and Technologies (CoNEXT).
[24] Xin Jin, Xiaozhou Li, Haoyu Zhang, Nate Foster, Jeongkeun Lee, Robert SoulÃ©,
Changhoon Kim, and Ion Stoica. 2018. NetChain: Scale-free sub-RTT coordination.
In 15th USENIX Symposium on Networked Systems Design and Implementation
(NSDI).
[25] Xin Jin, Xiaozhou Li, Haoyu Zhang, Robert SoulÃ©, Jeongkeun Lee, Nate Foster,
Changhoon Kim, and Ion Stoica. 2017. NetCache: Balancing key-value stores
with fast in-network caching. In 26th Symposium on Operating Systems Principles
(SOSP).
[26] Lavanya Jose, Lisa Yan, George Varghese, and Nick McKeown. 2015. Compiling
packet programs to reconfigurable switches. In 12th USENIX Symposium on
Networked Systems Design and Implementation (NSDI).
[27] Naga Praveen Katta, Mukesh Hira, Changhoon Kim, Anirudh Sivaraman, and
Jennifer Rexford. 2016. HULA: Scalable load balancing using programmable data
SIGCOMM â€™20, August 10â€“14, 2020, Virtual Event, NY, USA
planes. In Symposium on SDN Research (SOSR).
[28] Jialin Li, Ellis Michael, Naveen Kr. Sharma, Adriana Szekeres, and Dan R. K. Ports.
2016. Just say NO to Paxos overhead: Replacing consensus with network ordering.
In 12th USENIX Symposium on Operating Systems Design and Implementation
(OSDI).
[29] Yuliang Li, Rui Miao, Hongqiang Harry Liu, Yan Zhuang, Fei Feng, Lingbo Tang,
Zheng Cao, Ming Zhang, Frank Kelly, Mohammad Alizadeh, and Minlan Yu. 2019.
HPCC: High precision congestion control. In ACM SIGCOMM (SIGCOMM).
[30] Hongqiang Harry Liu, Yibo Zhu, Jitu Padhye, Jiaxin Cao, Sri Tallapragada, Nuno P.
Lopes, Andrey Rybalchenko, Guohan Lu, and Lihua Yuan. 2017. CrystalNet:
Faithfully emulating large production networks. In 26th Symposium on Operating
Systems Principles (SOSP).
[31] Jedidiah McClurg, Hossein Hojjat, Nate Foster, and Pavol CernÃ½. 2016. Event-
driven network programming. In 37th ACM SIGPLAN Conference on Programming
Language Design and Implementation (PLDI).
[32] Rui Miao, Hongyi Zeng, Changhoon Kim, Jeongkeun Lee, and Minlan Yu. 2017.
SilkRoad: Making stateful layer-4 load balancing fast and cheap using switching
ASICs. In ACM SIGCOMM (SIGCOMM).
[33] Christopher Monsanto, Nate Foster, Rob Harrison, and David Walker. 2012. A
compiler and run-time system for network programming languages. In 39th ACM
SIGPLAN-SIGACT Symposium on Principles of Programming Languages (POPL).
[34] Christopher Monsanto, Joshua Reich, Nate Foster, Jennifer Rexford, and David
Walker. 2013. Composing software defined networks. In 10th USENIX Symposium
on Networked Systems Design and Implementation (NSDI).
[35] Srinivas Narayana, Anirudh Sivaraman, Vikram Nathan, Prateesh Goyal, Venkat
Arun, Mohammad Alizadeh, Vimalkumar Jeyakumar, and Changhoon Kim. 2017.
Language-directed hardware design for network performance monitoring. In
ACM SIGCOMM (SIGCOMM).
[36] Arjun Singh, Joon Ong, Amit Agarwal, Glen Anderson, Ashby Armistead, Roy
Bannon, Seb Boving, Gaurav Desai, Bob Felderman, Paulie Germano, Anand
Kanagala, Jeff Provost, Jason Simmons, Eiichi Tanda, Jim Wanderer, Urs HÃ¶lzle,
Stephen Stuart, and Amin Vahdat. 2015. Jupiter rising: A decade of Clos topologies
and centralized control in Googleâ€™s datacenter network. In ACM SIGCOMM
(SIGCOMM).
[37] Anirudh Sivaraman, Alvin Cheung, Mihai Budiu, Changhoon Kim, Mohammad
Alizadeh, Hari Balakrishnan, George Varghese, Nick McKeown, and Steve Licking.
2016. Packet transactions: High-level programming for line-rate switches. In
ACM SIGCOMM (SIGCOMM).
[38] Anirudh Sivaraman, Thomas Mason, Aurojit Panda, Ravi Netravali, and
Sai Anirudh Kondaveeti. 2020. Network architecture in the age of programmabil-
ity. Computer Communication Review 50, 1 (2020).
[39] Hardik Soni, Myriana Rifai, Praveen Kumar, Ryan Doenges, and Nate Foster. 2020.
Composing dataplane programs with ğœ‡P4. In ACM SIGCOMM (SIGCOMM).
[40] Dingming Wu, Ang Chen, T. S. Eugene Ng, Guohui Wang, and Haiyong Wang.
2019. Accelerated service chaining on a single switch ASIC. In 18th ACM Workshop
on Hot Topics in Networks (HotNets).
[41] Yang Richard Yang, Kai Gao, Kerim Gokarslan, Dong Guo, and Christopher Leet.
2019. Magellan: Toward high-level programming and analysis of SDN using flow
algebra. In ACM SIGCOMM Workshop on Networking and Programming Languages
(NetPL).
[42] Cheng Zhang, Jun Bi, Yu Zhou, Adbul Basit Dogar, and Jianping Wu. 2017.
HyperV: A high performance hypervisor for virtualization of the programmable
data plane. In 26th International Conference on Computer Communication and
Networks (ICCCN).
[43] Cheng Zhang, Jun Bi, Yu Zhou, and Jianping Wu. 2019. HyperVDP: High-
Performance virtualization of the programmable data plane. IEEE J. Sel. Areas
Commun. 37, 3 (2019), 556â€“569.
[44] Peng Zheng, Theophilus Benson, and Chengchen Hu. 2018. P4Visor: Lightweight
virtualization and composition primitives for building and testing modular pro-
grams. In 14th International Conference on emerging Networking EXperiments and
Technologies (CoNEXT).
APPENDIX
Appendices are supporting material that has not been peer-reviewed.
A RESOURCE CONSTRAINT ENCODING
In this section, we detail more about how to encode the resource
constraints in the Reconfigurable Match Tables (RMT) architec-
ture [17]. For other ASIC architectures, e.g., Trident-4 and Silicon
One, the constraint encoding principle is the same.
SIGCOMM â€™20, August 10â€“14, 2020, Virtual Event, NY, USA
Gao et al.
A.1 Preliminary
Before detailing each type of resource encoding, we first describe
important preliminaries for the post usage.
Predicate block. Because RMT supports P4 [26], we first analyze
the whole Lyra program and synthesize the P4 program with meth-
ods introduced in Â§5.2.
The synthesizing algorithm returns a list of predicate blocks Lğ‘ 
and the dependency relationship between the predicate blocks. As
we stated earlier, each predicate block is potentially deployed as a
table in the data plane: if any of the instructions ğ‘– that belongs to
the predicate block ğµ is deployed in the switch ğ‘ , then the predicate
block should be in the switch. So we encode the validity ğ‘‰ğµ of a
predicate block ğµ on switch ğ‘  as:
ğ‘‰ğµ =
ğ‘“ğ‘ (ğ‘–)
(4)
where Iğµ denotes the instructions in predicate block ğµ.
Header usage. We say a header is unused if no instruction de-
ployed in the switch reads or writes the fields in the header. The
header usage affects the resource occupation, thus we want to re-
move unused headers as much as possible. Similar to the predicate
block validity computation, the usage of one header â„ on switch ğ‘ 
is encoded as:
ğ‘¢â„ =
ğ‘“ğ‘ (ğ‘–)
(5)

ğ‘–âˆˆIğµ

ğ‘–âˆˆIâ„
where Iâ„ denotes the instructions that read or writes header â„. If a
header is unused, it does not necessarily mean the header takes no
resource in the switch, because we also need to take into account
the header dependency (see below).
Header validity. In the configurable parser, RMT doesnâ€™t provide
any mechanism to skip header bytes. Thus we assume the packet is
parsed from the starting bit until the last valid header. This means if
a TCP header is parsed, then all the headers before the TCP header
(IPv4/IPv6, Ethernet) are also parsed. So we need to compute the
header dependency relationship based on the parser definition. For
two headers â„ğ‘– and â„ ğ‘—, we say â„ğ‘– depends on â„ ğ‘— if in the parser graph
â„ ğ‘— sits on one of the paths from the root to â„ğ‘–. For example, the
TCP header depends on the Ethernet header, but does not depend
on the UDP header. Here, â„ğ‘– depends on â„ ğ‘— means if â„ğ‘– is parsed,
then â„ ğ‘— must also be parsed.
So the validity of a header ğ‘‰â„ (whether the header should be
parsed) is encoded as:
ğ‘‰â„ = ğ‘¢â„ âˆ¨ 
â„ğ‘– âˆˆD(â„)
ğ‘¢â„ğ‘–
(6)
where D(â„) denotes all the headers that depends on header â„.
Variable validity. Because there is no dependency relationship
between variables in the Lyra program, the variableâ€™s validity can be
computed via the header usage computation method. The validity
of the internal, global and external variable is denoted as ğ‘‰ğ‘–, ğ‘‰ğ‘”, and
ğ‘‰ğ‘’ respectively.
A.2 Parser
In RMT, the parser is implemented as a state machine. Each state in
the state machine represents a parser node in the program and the
transition in the state machine maps to the transition of the parser
nodes. In the hardware, the state machine data is stored in a TCAM
and a RAM table. Each entry in the TCAM table matches 32 bits
of incoming data and 8 bits of parser state. The RAM table stores
the next parser state and where the parsed data is stored. When a
packet comes in, the parser checks both the packet header content