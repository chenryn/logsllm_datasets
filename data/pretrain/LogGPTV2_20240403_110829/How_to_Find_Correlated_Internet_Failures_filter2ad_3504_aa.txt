title:How to Find Correlated Internet Failures
author:Ramakrishna Padmanabhan and
Aaron Schulman and
Alberto Dainotti and
Dave Levin and
Neil Spring
How to Find Correlated Internet Failures
Ramakrishna Padmanabhan1,2(B), Aaron Schulman3, Alberto Dainotti2,
Dave Levin1, and Neil Spring1
1 University of Maryland, College Park, USA
{dml,nspring}@cs.umd.edu
2 CAID/UCSD, La Jolla, USA
{ramapad,alberto}@caida.org
3 UCSD, San Diego, USA
PI:EMAIL
Abstract. Even as residential users increasingly rely upon the Internet,
connectivity sometimes fails. Characterizing small-scale failures of last
mile networks is essential to improving Internet reliability.
In this paper, we develop and evaluate an approach to detect Inter-
net failure events that aﬀect multiple users simultaneously using mea-
surements from the Thunderping project. Thunderping probes addresses
across the U.S. When the areas in which they are geo-located are aﬀected
by severe weather alerts. It detects a disruption event when an IP address
ceases to respond to pings. In this paper, we focus on simultaneous dis-
ruptions of multiple addresses that are related to each other by geog-
raphy and ISP, and thus are indicative of a shared cause. Using bino-
mial testing, we detect groups of per-IP disruptions that are unlikely to
have happened independently. We characterize these dependent disrup-
tion events and present results that challenge conventional wisdom on
how such outages aﬀect Internet address blocks.
1 Introduction
Even as residential users rely increasingly upon the Internet, last-mile infras-
tructure continues to be vulnerable to connectivity outages [1–3,5,18,20–24].
Measurement-driven approaches to study residential Internet failures will help
improve reliability by identifying vulnerable networks and their challenges.
Techniques that detect outages at the Internet’s edge often seek, using ter-
minology from Richter et al. [19], disruption events: the abrupt loss of Internet
connectivity of a substantial set of addresses. The set of addresses may com-
prise those belonging to the same /24 address block [18,19], BGP preﬁx [9], or
country [4]. Techniques seek such disruption events because individually, each
large disruption has impact and their size makes them easier to conﬁrm, e.g.,
with operators. In contrast, disruptions aﬀecting only a few users are harder to
detect with conﬁdence. For example, the lack of response from a single address
might best be explained by a user switching oﬀ their home router—hardly an
outage. However, residential Internet outages may be limited to a small neigh-
borhood or apartment block; prior techniques are likely to miss such events.
c(cid:2) Springer Nature Switzerland AG 2019
D. Choﬀnes and M. Barcellos (Eds.): PAM 2019, LNCS 11419, pp. 210–227, 2019.
https://doi.org/10.1007/978-3-030-15986-3_14
How to Find Correlated Internet Failures
211
In this work, we demonstrate a technique that detects disruption events with
quantiﬁable conﬁdence, by investigating the potential dependence between dis-
ruptions of multiple IP addresses in a principled way. We apply a simple statisti-
cal method to a large dataset of active probing measurements towards residential
Internet users in the US. We ﬁnd times when multiple addresses experience a
disruption simultaneously such that they are unlikely to have occurred inde-
pendently; we call the occurrence of such events dependent disruptions. Our
preliminary results shed light on when, how large, and with which structure in
the address space dependent disruptions happen. We show that even some large
outages do not disrupt entire /24 address blocks.
Our contributions are:
– We demonstrate a technique to detect dependent disruption events using the
binomial test.
some ISPs.
– We show that dependent disruption events occur more frequently at night for
– The majority of dependent disruption events last less than an hour.
– We show that dependent disruption events do not always aﬀect entire /24
address blocks and can therefore be missed by prior techniques that detect
disruptions at this granularity [18,19].
2 Background and Related Work
In this section, we begin with a presentation of edge Internet disruption detection
techniques. These techniques typically detect disruptions aﬀecting a large group
of addresses. Next, we provide a description of the Thunderping dataset [21] that
yields per-IP address disruptions required for our detection technique.
2.1 Prior Work
Prior techniques that detect edge Internet disruptions typically detect disrup-
tions that aﬀect a group of addresses collectively. Like us, they also leverage the
dependence among the per-IP address “disruptions” that these disruptions cause.
However, they diﬀer from our technique in that they look for dependence in large
aggregates (that is, so many addresses are aﬀected at the same time that there
must be an evident anomaly) or limit their resolution to small address blocks,
looking only for outages that cause dependent disruptions for most addresses in
a monitored block.
Several systems investigate disruptions aﬀecting a substantial set of
addresses. The IODA system looks for the most impactful outages, those causing
an extensive loss of connectivity for a geographical area or Autonomous Sys-
tem [4,7]. Hubble detects preﬁx-level unreachability problems [9] using a hybrid
monitoring scheme that combines passive BGP monitoring and active probing.
212
R. Padmanabhan et al.
Other systems detect disruptions aﬀecting many addresses within /24 address
blocks. For example, Trinocular uses historical data from the ISI census [6] to
model the responsiveness of blocks and ﬁnds addresses within each block that
are likely to respond to pings. The system pings a few of these addresses from
each block at random in 11-minute rounds. It then employs Bayesian inference
to reason about responses from blocks. When a block’s responsiveness is lower
than expected, Trinocular probes the block at a faster rate and eventually detects
an outage when the follow-up probes also suggest the block’s lack of Internet
connectivity. Since Trinocular may not identify an outage even if a single address
in a block responds to probing, it potentially neglects outages aﬀecting /24 blocks
only partially, including larger outages aﬀecting multiple /24 blocks. Recently,
Richter et al. used proprietary CDN logs to detect disruptions aﬀecting multiple
addresses within /24 address blocks [19]. They showed that many disruptions do
not aﬀect all addresses in a /24; we revisit this result in Sect. 4.4.
Disco [22] shares some features with our work: they also detect simultaneous
disconnects of multiple RIPE Atlas probes within an ISP or geographic region to
infer outages. However, there are two major diﬀerences between the Thunderping
and RIPE Atlas datasets. At any given point in time, the Thunderping dataset
typically consists of pings sent to thousands of addresses in relatively small geo-
graphical areas in the U.S. with active severe weather alerts. The Disco dataset
consists of 10,000 RIPE Atlas probes distributed around the world; this sparse
distribution may prevent the detection of smaller outages localized to one area
(like a U.S. state). The second diﬀerence is that unlike Thunderping ping data
whose timestamps are only accurate to minutes, the timestamps available in the
RIPE Atlas datasets are accurate to seconds, permitting the use of Kleinberg’s
burst detection to detect bursts in probe disconnects.
2.2 The Thunderping Dataset Yields Per-Address Disruptions
The key insight behind our technique is that simultaneous disruptions of multiple
individual IPv4 addresses could occur due to a common underlying cause. We
therefore require per-IP address disruptions.
Such data is present in the Thunderping dataset [21]. Thunderping pings
sampled IPv4 addresses from multiple ISPs in geographic areas in the United
States. Originally designed to evaluate how weather aﬀects Internet outages,
the system uses Planetlab vantage points to ping 100 randomly sampled IPv4
addresses per ISP, from multiple ISPs, in each U.S. county with active weather
alerts. Each address is pinged from multiple Planetlab vantage points (at least
3) every 11 min, and addresses in a county are pinged six hours before, during,
and after a weather alert.
Here, we analyze a dataset of Thunderping’s ping responses to detect disrup-
tions for each probed address using Schulman and Spring’s technique [21]. When
an address that is responsive stops responding to pings from all vantage points
that are currently probing it, we detect a disruption for that address. Since a
disruption is detected only when all vantage points declare unreachability, the
minimum duration of a disruption is 11 min (at the end of 11 min each vantage
How to Find Correlated Internet Failures
213
point has pinged the address at least once).Thunderping continues to probe an
address after it has become unresponsive, allowing us to estimate how long the
unresponsive period lasted.
While per-IP address disruptions allow the detection of small disruption
events, all per-address disruptions are not necessarily the result of Internet con-
nectivity outages (e.g., a user might turn oﬀ their home router). This paper
shows how to detect dependent disruption events using per-address disruptions.
3 Detecting Dependent Disruptions
In this section, we apply binomial testing to identify dependent disruptions in
the outage dataset. First, we show how the binomial test works to rule out
independent events and show how to apply the test to outages in reasonably sized
aggregates of addresses. Second, we apply this method to the outage dataset,
omitting addresses with excessive baseline loss rates and evaluating our chosen
aggregation method. Finally we summarize the dependent disruptions we found
in this dataset. This sets up analysis of these events (time of day, geography,
and scope) which we defer to the following section.
3.1 Finding Dependent Events in an Address Aggregate
When many addresses experience a disruption simultaneously, there could be
a common underlying cause. Such disruptions are statistically dependent. To
identify these dependent events, our insight is to model address disruptions as
independent events; when disruptions co-occur in greater numbers than the inde-
pendent model can explain, the disruptions must be dependent. Binomial test-
ing provides precisely this ability to ﬁnd events that are highly unlikely to have
occurred independently.
Given N addresses, the binomial distribution gives the probability that D of
them were disrupted independently as:
(cid:2)
(cid:3)
Pr[D independent failures] =
N
D
· P D
d (1 − Pd)N−D
(1)
where Pd represents the probability of disruption for the aggregate N. To apply
this formula, we must ﬁrst set a threshold probability below which we con-
sider the simultaneous disruption to be too unlikely to be independent. We set
this threshold to 0.01%. We then solve for Dmin, the smallest (whole) num-
ber of simultaneous disruptions with a smaller than 0.01% chance of occurring
independently. Table 1 in the appendix presents computed values of Dmin for
various values of N and Pd. This table shows that, even for large aggregates
of IP addresses, often few simultaneous disruptions are necessary to be able to
conﬁdently conclude that a dependent disruption has occurred. As we will see,
when applied to our dataset, Dmin values are typically below 8.
There are two practical challenges in applying this test. First, we must choose
aggregates of N IP addresses that deﬁne the scope of a dependent disruption:
214
R. Padmanabhan et al.
too large an aggregate will have too large a chance of simultaneous independent
failures and drive up D, while too small an aggregate may fail to include all
the addresses in an event. Second, we must estimate Pd for each aggregate. We
address each in turn.
3.1.1 Choosing Aggregate Sets of IP Addresses
Our technique assumes some aggregate set of IP addresses among which to detect
a dependent disruption. We note that the correctness of our approach does
not depend on how this set is chosen—the binomial test will apply so long as
independent failures can be modeled by Pd. When applying our technique, IP
addresses must be aggregated into sets that are large enough to span interesting
disruption events, but not so large as to become insensitive to them.
In this paper, we aggregate IP addresses based on the U.S. state and the
ASN they are in.State-ASN aggregates have the beneﬁt of spanning multiple
preﬁxes (so we can observe whether more than one /24 is aﬀected by a given
disruption event), but also being constrained to a common geographic region (so
hosts in an aggregate are likely to share similar infrastructure). There are two
limitations with this approach: states are not of uniform size, though the test
elegantly handles varying N, and a few ISPs use multiple ASNs, which may hide
some dependent failures. Alternate aggregations are possible (Appendix A.4).
3.1.2 Calculating the Probability of Disruption ( Pd)
As a ﬁnal consideration, we discuss how to estimate the probability of disruption,
Pd, from an empirical dataset of disruptions. We assume that the dataset can
be separated into a set of discrete “time bins”; this is common with ping-based
outage detection, such as Thunderping and Trinocular, which both consider 11-
minute bins of time. Pd can be estimated using the following equation:
Pd =
#disruptions
#timebins
(2)
Here, #timebins represents the total number of observation intervals used: if a
single host was measured across 10 time intervals and ﬁve other hosts were all
measured across 3, then #timebins = 10 + 3 · 5 = 25.
We only consider state-ASN aggregates where we were able to obtain a sta-
tistically signiﬁcant value for Pd. For statistical signiﬁcance, we adhere to the
following rule of thumb [25, Chap. 6]: we accept a state-ASN aggregate with t
timebins and estimated probability of disruption Pd only if:
tPd(1 − Pd) ≥ 10
(3)
3.2 Applying Our Method to the Thunderping Dataset
We investigate all ping responses in the Thunderping dataset from January 1,
2017 to December 31, 2017 and detect disruptions according to the methodol-
ogy described above. During this time, Thunderping had sent at least 100 pings
to 3,577,895 addresses and detected a total of 1,694,125 individual address dis-
ruptions aﬀecting 1,193,812 unique addresses. The top ISPs whose addresses
How to Find Correlated Internet Failures
215
Thunderping sampled most frequently include large cable providers (Com-
cast, Charter, Suddenlink), DSL providers (Windstream, Qwest, Centurytel),
WISP providers (RISE Broadband), and satellite providers (Viasat). While most
addresses have low loss rates, 2% of addresses had loss rates exceeding 10%; we
remove these addresses to avoid biasing the analysis. We report additional details
about these addresses in [15,17].
Fig. 1. Potential N and Pd values in the Thunderping dataset: on the left, we show the
distribution of all addresses (across all state-ASN aggregates) pinged by Thunderping
that can potentially fail in each 11 min time bin. On the right, we show the distribution
of the probability of disruption (Pd) for the 1559 state-ASN address aggregates we
studied.
Detecting Dependent Disruptions in the Thunderping Dataset
We use Fig. 1 to describe potential N and Pd values in the Thunderping dataset.
On the left, we show the distribution of addresses pinged by Thunderping in each
11 min timebin in 2017. The median number is roughly 50,000 addresses across
all U.S. states and ISPs. Since many weather alerts tend to be active at any given
point of time, these addresses are likely to be distributed among tens of state-
ASN aggregates. In 2017, the maximum addresses that could potentially fail in
any state-ASN aggregate was 15,863. On the right, we show the distribution
of Pd values for all state-ASN aggregates that we considered. There is extensive
variation: addresses in some of these aggregates experience disruptions only once
every year, whereas in other aggregates they experience disruptions more often
than once per day.1
1 Since disruptions are a superset of outages and dynamic reassignment [16], frequent
disruptions are not necessarily indicative of poor Internet connectivity. Also, the
existence of many aggregates with few disruptions indicates that Thunderping often
pinged addresses during weather conditions that were not conducive to disruptions.
216
R. Padmanabhan et al.
For each state-ASN aggregate, for each 11-min window during which Thun-
derping had pinged addresses, we identify the maximum number of addresses
that can potentially fail, N, i.e., all the addresses that are responsive to pings at
the beginning of the window. Next, we apply the binomial test for each of these
windows since we know N and Pd. When the number of disruptions in a window
is at least Dmin, we determine that a dependent disruption event occurred in
that window with a probability greater than 0.9999.
In total, we detected 20,831 events with dependent disruptions in 2017. We
analyzed our conﬁdence in these dependent disruptions. The detailed results are
included in the appendix (Fig. 8); in summary, the probabillity that detected
events occurred independently is typically much smaller than our choice of 0.01%.
We analyze the characteristics of these events next.
1
0
100
10
1
)
D
(
n
o
i
t
p
u
r
s
i
d
t
n
e
d
n
e
p
e
d
n
i
s
e
s
s
e
r
d
d
a
d
e
t
p
u
r
s
i
D
0
Minimum threshold for dependent disruption (Dmin)
20
5
10
15
0
1
Fig. 2. For each detected dependent disruption event, Fig. 2 shows the Dmin value on
the x-axis and the corresponding number of observed disruptions on the y-axis. 62% of
the 20,831 detected events had more than Dmin observed disruptions. The scatterplot
adds a random gaussian oﬀset to both x and y with mean of 0.1, clamped at 0.45, to
show density.
How Many Addresses Are Disrupted Dependently?
The binomial test does not say that all of the addresses that were observed to
be disrupted during a dependent event were disrupted in a dependent manner.
Consider if Dmin is 4 and we detect an event where 7 addresses were disrupted.
The binomial test shows us that the event took place with very low probabil-
ity. However, that does not necessarily mean all 7 addresses were disrupted in
a dependent manner; up to 3 of them (Dmin − 1) could have been disrupted
independently with up to 99.99% probability.
We call the set of addresses in a state-ASN aggregate that were disrupted
in the time-bin of a dependent event the observed group of addresses that were
disrupted, or the observed disrupted group for short. In the example above, the
observed disrupted group contains 7 addresses. Of the observed disrupted group,
our assumption is that some were disrupted together in a dependent manner:
How to Find Correlated Internet Failures
217
we call this subset the actual group of addresses that were disrupted, or actual
disrupted group. We obtain a minimum bound on the actual disrupted group by
subtracting Dmin − 1 from the observed disrupted group; thus in the example
above, the minimum number of addresses in the actual disrupted group is 4. For
the 20,831 dependent disruption events, the total addresses in all the observed
disrupted groups is 229,413 and the minimum total addresses in all the actual
disrupted groups is 165,328.
We study the relationship between Dmin for a state-ASN aggregate on the
x-axis and the corresponding number of addresses in the observed group of dis-
rupted addresses (on the y-axis) in Fig. 2. Each point corresponds to one of the
20,831 detected events. Sometimes, a state-ASN aggregate had such low Pd that
even a single disruption in a 11-min bin occurred with less than 0.01% probably
and therefore had a Dmin value of 1. However, since we are looking for unlikely
disruptions of multiple addresses, at least two addresses were disrupted in the
same time-bin for all our detected events. For 12,911 (62%) detected events,
more than Dmin addresses experienced disruptions in the same time-bin, cor-
roborating the result from Fig. 8 (in the appendix) that most detected events
would have been detected even with a stricter threshold.
We detected dependent disruption events with various sizes as shown in
Fig. 2. There are 693 (3%) events with more than 50 observed disrupted
addresses. The largest detected event had 913 addresses experience disruptions
in the same time-bin in AS33489 (Comcast) in Florida at 2017-09-13T20:33 UTC
time. This detected event correlates to the minute with a known failure event for
Comcast that was discussed in the Outages mailing list [14]. However, for most
of the events, the size of the observed group of disrupted addresses is small: there
were 2,593 (12%) with two, 2,969 (14%) with three, 2,776 (13%) with four, and
2,175 (10%) with ﬁve observed disrupted addresses. These results highlight the
ability of our technique to detect even small sized disruptions with conﬁdence.
4 Properties of Dependent Disruptions