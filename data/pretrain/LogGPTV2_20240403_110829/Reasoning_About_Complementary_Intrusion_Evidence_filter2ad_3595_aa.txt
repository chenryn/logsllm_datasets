title:Reasoning About Complementary Intrusion Evidence
author:Yan Zhai and
Peng Ning and
Purush Iyer and
Douglas S. Reeves
Reasoning about Complementary Intrusion Evidence∗
Yan Zhai, Peng Ning, Purush Iyer, Douglas S. Reeves
Cyber Defense Laboratory
Department of Computer Science
North Carolina State University
Raleigh, NC 29695-8207
{yzhai, pning, purush, reeves}@ncsu.edu
Abstract
This paper presents techniques to integrate and reason
about complementary intrusion evidence such as alerts gen-
erated by intrusion detection systems (IDSs) and reports by
system monitoring or vulnerability scanning tools. To facil-
itate the modeling of intrusion evidence, this paper classi-
ﬁes intrusion evidence into either event-based evidence or
state-based evidence. Event-based evidence refers to obser-
vations (or detections) of intrusive actions (e.g., IDS alerts),
while state-based evidence refers to observations of the ef-
fects of intrusions on system states. Based on the interde-
pendency between event-based and state-based evidence,
this paper develops techniques to automatically integrate
complementary evidence into Bayesian networks, and rea-
son about uncertain or unknown intrusion evidence based
on veriﬁed evidence. The experimental results in this pa-
per demonstrate the potential of the proposed techniques.
In particular, additional observations by system monitoring
or vulnerability scanning tools can potentially reduce the
false alert rate and increase the conﬁdence in alerts corre-
sponding to successful attacks.
1. Introduction
It is well-known that current intrusion detection systems
(IDSs) produce large numbers of alerts, including both ac-
tual and false alerts. The high volume and the low quality
of those alerts (i.e., missed attacks and false alerts) make it
very hard for human users or intrusion response systems to
understand the alerts and take appropriate actions.
∗
This work is partially supported by the National Science Foundation
(NSF) under grants ITR-0219315 and CCR-0207297, and by the U.S.
Army Research Ofﬁce (ARO) under grant DAAD19-02-1-0219. The
authors would like to thank the anonymous reviewers for their value-
able comments.
Several alert correlation techniques have been proposed
to facilitate the analysis of intrusion alerts, including those
based on the similarity between alert attributes [7, 10, 26,
29], previously known (or partially known) attack scenar-
ios [11, 12], and prerequisites and consequences of known
attacks [8, 21]. However, most of these correlation meth-
ods focus on IDS alerts, overlooking other intrusion evi-
dence provided by system monitoring tools (e.g., anti-virus
software) and vulnerability scanning tools (e.g., Nessus [3],
SATAN [14], Nmap [15]). Since none of the above methods
can perfectly construct attack scenarios due to the imperfec-
tion of the IDSs, it is desirable to include additional, com-
plementary intrusion evidence to further improve the per-
formance of intrusion analysis.
Several researchers recently investigated ways to con-
sider multiple information sources during intrusion analysis
[20,23]. A formal model named M2D2 was proposed to rep-
resent data relevant to alert correlation, including character-
istics of monitored systems, properties of security tools, and
observed events [20]. Though quite useful for alert correla-
tion, M2D2 does not provide a speciﬁc mechanism to au-
tomatically reason about information provided by multiple
sources. Another mission-impact-based method [23] rea-
sons about the relevance of alerts by fusing alerts with the
targets’ topology and vulnerabilities, and ranks alerts based
on their relationships with critical resources and users’ in-
terests. Though the mission-impact based method can auto-
mate the analysis of intrusion alerts, the construction of a
mission-impact based model requires substantial human in-
tervention, and the constructed model is highly dependent
on the monitored systems. Thus, it is desirable to seek other
effective mechanisms that can handle complementary intru-
sion evidence automatically.
In this paper, we develop techniques to automatically in-
tegrate and reason about complementary intrusion evidence,
including IDS alerts, reports from system monitoring or vul-
nerability scanning tools, and human observations. Our ap-
proach is based on the interdependency between attacks and
Proceedings of the 20th Annual Computer Security Applications Conference (ACSAC’04) 
1063-9527/04 $ 20.00 IEEE 
system states. That is, an attack may need certain system
states to be successful, and will modify the system states as
a result. However, IDS alerts, which represent detected at-
tacks, are uncertain due to the imperfection of current IDSs.
To reason about uncertain IDS alerts, our approach auto-
matically builds Bayesian networks that consist of variables
representing IDS alerts and system states. With additional,
complementary evidence about system states provided by
system monitoring tools, vulnerability scanning tools, and
human observations, we can then make further inference
about uncertain IDS alerts. As a result, we can increase our
conﬁdence in alerts corresponding to successful attacks, and
at the same time reduce the conﬁdence in false alerts. More-
over, by combining system state evidence, we can make rea-
sonable hypotheses about attacks possibly missed by IDSs.
The main contribution of this paper is a reasoning frame-
work for complementary intrusion evidence. To our best
knowledge, this is the ﬁrst attempt to automatically inte-
grate and reason about complementary intrusion evidence
such as IDS alerts and vulnerability scanning reports. We
also performed a series of experiments to validate our ap-
proach and gain further insights into the problem. The ex-
perimental results demonstrate the potential of the proposed
approach as well as the effectiveness of our techniques.
The rest of this paper is organized as follows. The next
section describes our techniques to integrate and reason
about complementary intrusion evidence. Section 3 presents
the results of our initial experiments. Section 4 discusses re-
lated work. Section 5 concludes this paper and points out
some future research directions.
2. Reasoning Framework
In this section, we present our techniques to reason about
complementary intrusion evidence, including IDS alerts and
reports from system monitoring tools or vulnerability scan-
ning tools. In the following, we ﬁrst describe our represen-
tation of intrusion evidence, and then present the frame-
work to reason about complementary intrusion evidence us-
ing Bayesian networks.
2.1. Modeling Intrusion Evidence
We classify intrusion evidence into two categories:
event-based evidence and state-based evidence. Event-
based evidence refers to observations (or detections) of
attacks. For example, an IDS alert of a buffer overﬂow at-
tack against sshd is event-based evidence. State-based ev-
idence refers to observations of the effect of attacks on sys-
tem states. For example, the existence of a rootkit1 on a
1 A rootkit is a collection of tools (programs) that a hacker uses to mask
intrusion and obtain administrator-level access to a computer or net-
work (http://searchsecurity.techtarget.com).
machine is state-based evidence indicating that the ma-
chine has been compromised.
2.1.1. System Attributes and State-Based Evidence
We follow [6, 25] to represent system states (e.g., vul-
nerabilities, user access privileges, and network con-
nectivities) as system attributes (or simply attributes),
each of which is a boolean variable representing the sys-
tem’s state. Notation-wise, we use a system attribute di-
rectly to represent that it is True, and use its negation to
represent that it is False. There may be implication re-
lationships between attributes, which also come from
expert knowledge. For example, RootPrivilege im-
plies FileTransferPrivilege, which indicates that
an attacker having the root privilege also has the priv-
ilege to transfer ﬁles from/to the system. Note that
such a representation can be extended to include vari-
ables to provide more ﬂexibility. For example, we may use
RootPrivilege(x) to represent the attacker has ac-
quired root privilege on host x. However, for simplicity, we
do not do so in this paper.
State-based evidence consists of observations on system
attributes related to possible attacks. They may be collected
by system scanning tools. We refer to the change of an at-
tribute as an attribute alteration. Attribute alterations are
detected by system monitoring tools, comparing the sys-
tem scanning reports, and human observations. The times-
tamp of an attribute alteration is the time when the alteration
is detected or inferred. Such a timestamp can be stored to-
gether with each attribute alteration.
For convenience, we refer to the probability for a system
attribute to be True as the conﬁdence in the attribute. When
a system attribute is in negation form, the conﬁdence in the
attribute is the probability that the negation form is True.
Compared with IDS alerts, reports by scanning/monitoring
tools are more reliable due to the veriﬁable nature of most
system attributes. We can assume the conﬁdence in a veri-
ﬁable attribute is 1. However, some system attributes may
not be veriﬁable because of the absence of an appropriate
scanner. In addition, some system attributes are difﬁcult to
check due to the security policy on the target system or per-
formance reasons. In such cases, unless we have any further
knowledge or evidence about the attribute, we assume the
conﬁdence in such an attribute is 0.5. Intuitively, this repre-
sents the lack of information about the state of the attribute.
2.1.2. Event-Based Evidence Typical sources of event-
based evidence include event logs, IDS alerts, network traf-
ﬁc logs, system call logs, etc. Different kinds of logs pro-
vide event-based evidence on the system in different gran-
ularities and toward different aspects of the system. In this
paper, the only event-based evidence we consider is IDS
alert, which is in a coarser granularity but more under-
standable by human compared with other types of system
Proceedings of the 20th Annual Computer Security Applications Conference (ACSAC’04) 
1063-9527/04 $ 20.00 IEEE 
logs. We will use IDS alerts and event-based evidence in-
terchangeably in the rest of the paper. Our representation of
IDS alerts is closely related to our model of attacks. Thus,
we ﬁrst introduce our representation of attacks before dis-
cussing IDS alerts.
Similar to [6,25], we model an attack as an atomic trans-
formation that establishes a set of system attributes called
postcondition, given a logical condition called precondition
over system attributes. Intuitively, if the precondition of an
attack is satisﬁed, the attack can then transform the sys-
tem into the state speciﬁed by its postcondition. IDS alerts
are not exactly the attacks launched toward the target due
to the imperfection of current IDSs. An IDS may report a
false alert or miss an actual attack. To facilitate the reason-
ing about IDS alerts, we use the prior conﬁdence of each
attack to represent its quantitative property. The prior con-
ﬁdence of an attack type T, denoted Pr(T), is the prior be-
lief we have about the probability for a corresponding alert
to represent an actual type T attack. The prior conﬁdence
of each type of attack can be gathered by analyzing histori-
cal data. It represents our prior knowledge about IDS alerts
based on our previous experience. One may observe that the
probability for each attack type varies during different time
period as they are dependent on not only the quality of the
IDSs, but also the attack frequency and background activi-
ties in the network. However, in the later part of this paper,
we will see that our reasoning approach is still useful de-
spite the dynamic nature of the prior conﬁdences, as it re-
duces the uncertainty of intrusion evidence when additional
veriﬁed evidence is considered. In some sense, Pr(T) is the
belief that a type T alert is a real instance of attack, and our
reasoning framework is to increase or decrease our belief
in alerts based on complementary intrusion evidence. Sim-
ilar to the conﬁdence in a system attribute, we refer to the
probability that an IDS alert corresponds to a successful at-
tack as the conﬁdence in the alert.
We summarize our prior knowledge about IDS alerts and
attacks below:
• An IDS alert e of attack type T has the probability
Pr(T) to be a real attack;
• A real attack E has probability 1 to be successful when
its precondition is satisﬁed by the system attributes be-
fore the attack happens;
• A real attack E has probability 0 to be successful if
its precondition is not satisﬁed by the system attributes
before the attack happens;
• The attributes in the postcondition of a successful at-
tack E are True after the attack happens.
2.2. Basic Reasoning framework
In normal situations, a system should stay in a legitimate
state. Starting from a legitimate system state, an attacker
may launch a sequence of attacks to get the system into
some intermediate states, and ﬁnally into the attacker’s ob-
jective state. It is easy to see that there exist causal relation-
ships among attacks and system attributes. Our approach is
to use these causal relationships to reason about comple-
mentary IDS alerts and system attributes reported by scan-
ning/monitoring tools. Speciﬁcally, we organize IDS alerts
and system attributes into Bayesian networks [16] based on
those causal relationships, and use these Bayesian networks
to reason about complementary intrusion evidence.
2.2.1. Network Structure To identify and represent these
causal relationships, we integrate IDS alerts with system at-
tributes based on the preconditions and postconditions of at-
tacks. Speciﬁcally, we place IDS alerts, available system at-
tributes, and system attributes possibly modiﬁed by the cor-
responding attacks into a directed graph, which we call an
alert-attribute network.
Each node in such a graph is a binary variable represent-
ing either an IDS alert or a system attribute. When a node
represents a system attribute, it can denote either a piece
of state-based evidence (e.g., scan report), or an inferred at-
tribute alteration caused by an IDS alert. Each node is times-
tamped. The timestamp of an alert node is the time when the
corresponding activities take place, while the timestamp of
an attribute node is the time when the attribute alteration is
observed or inferred.
All edges in the graph are directed. An edge from an alert
node to an attribute node represents that the correspond-
ing attack changes the system attribute into this new state.
An edge from an attribute node to an alert node represents
that the attribute is a part of the precondition of the corre-
sponding attack. An edge from an attribute node to another
attribute node represents that the ﬁrst attribute implies the
second attribute. There are no edges that connect two alert
nodes together directly.
We construct such a graph starting with the initial sys-
tem state, which is represented in the graph as a set of at-
tribute nodes corresponding to the initial attributes. As time
goes by, new IDS alerts and system monitoring reports are
raised. When a new IDS alert is reported, a corresponding
alert node is added into the graph only if the alert’s pre-
condition is evaluated to be True given the attributes pre-
sented in the graph by the time. Also, edges are added from
the latest attribute nodes corresponding to the attributes in
the alert’s precondition to the newly generated alert node (to
represent the causal relationships). To serve the same pur-
pose, edges from the alert node to its postcondition attribute
nodes are also established when they are created. For each
attribute node in the alert’s postcondition, if nodes related
Proceedings of the 20th Annual Computer Security Applications Conference (ACSAC’04) 
1063-9527/04 $ 20.00 IEEE 
to the same attribute already exist in the graph, which could
either be caused by some previous alerts or reported by sys-
tem monitoring tools, an edge from the latest such node to
the new node is added to represent the implication relation-
ship. By doing so, each attribute node in the graph repre-
sents the accumulative effects on the attribute of all the prior
related alerts. Note that the construction and analysis pro-
cesses can be done ofﬂine following the time sequence of
the evidence in IDS alert logs and scan reports.
sshd_running
vulnerable_sshd
sshd_buffer_overflow
root_access