r
h
T
35000
30000
25000
20000
15000
10000
5000
0
1
2
3
4
Number of threads
1
2
3
4
Number of threads
(a) WAN (50 Mbps, 100 ms latency)
(b) LAN (1 Gbps, 0.1 ms latency)
(c) LAN (10 Gbps, 0.1 ms latency)
Figure 7: Triple generation throughput across different protocols and network settings.
Table IV: Costs of the preprocessing for different operations/applications. Timings are estimates based on triples/random bits needed and are based on a 4
threads execution on a LAN supporting up to 10 Gbps. For SPDZ, Overdrive [24] is used. For bit triple generation the optimized TinyOT protocol by
Wang et al. [36] is used.
Comparison
Equality
DTree (diabetes)
SVM (aloi)
Comparison
Equality
DTree (diabetes)
SVM (aloi)
# triples
0
0
5460
63332
# triples
0
0
5460
63332
SPDZ2k , k = 32, σ = 26
# random bits
# bit-triples
time (ms)
# triples
SPDZ, k = 32, σ = 26 (64 bit ﬁeld)
# bit-triples
# random bits
60
31
15300
27720
33
33
8415
15246
1.43
1.34
571
3055
60
31
20760
91052
0
0
0
0
58
58
14790
26796
time (ms)
4.04
3.04
1216
4030
SPDZ2k , k = 64, σ = 57
# random bits
# bit-triples
124
63
31620
57288
65
65
16575
30030
time (ms)
# triples
7.22
7.04
2417
10006
124
63
37080
120620
(cid:18)(cid:18)(cid:18)(cid:21)
SPDZ, k = 64, σ = 57 (128 bit ﬁeld)
# bit-triples
# random bits
time (ms)
0
0
0
0
121
121
30855
55902
14.9
11.2
4124
10714
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:49:58 UTC from IEEE Xplore.  Restrictions apply. 
Table V: Total theoretical communication complexity counted in (kilo-, mega-, giga-) bytes for the two-party case. Values for SPDZ are based on
Overdrive in Low Gear [24]. For bit triples we use the optimized TinyOT protocol of Wang et al.[36]. The communication of comparison and equality do
not include authenticating input overhead since we assume amortized execution and exclude setup and initialization communication.
k = 32, σ = 26
k = 64, σ = 57
SPDZ2k
SPDZ (64 bit ﬁeld)
SPDZ2k
SPDZ (128 bit ﬁeld)
Preprocessing
627 KB
486 KB
209 MB
908 MB
Online
46 B
24 B
131 KB
1.44 KB
Preprocessing
148 KB
107 KB
40.8 MB
139 MB
Online
1.89 KB
1.01 KB
705 KB
3.24 MB
Preprocessing
3.58 MB
3.08 MB
1.10 GB
4.06 GB
Online
94 B
48 B
262 KB
2.88 MB
Preprocessing
508 KB
366 KB
110 MB
341 MB
Online
7.78 KB
3.97 KB
2.37 MB
8.29 MB
Comparison
Equality
DTree (Diabetes)
SVM (ALOI)
Table IV); our SPDZ2k speciﬁc protocol optimizations allow
us to use fewer random bits, more efﬁcient bit-triples based
on TinyOT, and thus fewer expensive multiplication triples.
Thus, while raw triple preprocessing for SPDZ2k is slower
than Overdrive, we still outperform it for more advanced
operations and real-world applications.
D. Applications
In tables II and III we show online benchmarking results
of Protocols ΠDecTree and ΠSVM from Sec. V. The tables
show the online execution time of these protocols when
obliviously classifying data, both using SPDZ and SPDZ2k.
For both decision tree and SVM evaluation, we measure
evaluation time for a single data point, and the amortized
time of evaluating multiple points in batches of 5 (since a
service will likely classify more than a single data point).
1) Decision Trees: Table II shows online times for obliv-
ious evaluation of some binary data models by De Cock
[28], based on datasets from the UCI repository4.
et al.
The models are used to identify hills vs. valleys on 2-D
graphs (Hill Valley), diabetes in women of Pima Indian
decent (Diabetes) and spam vs. non-spam e-mail based on
textual content (Spambase). We chose these models as they
contain a large variation in the amount of features.
We see a noticeable, relative improvement of SPDZ2k
over SPDZ in all the models we benchmarked, which further
increases with the depth of the tree. As expected, batched
evaluation yields better throughput; the batched runs also
result in a bigger performance improvement for SPDZ2k
over SPDZ. This shows that comparisons, which are needed
for each node of the tree, become the bottleneck. This holds
for both SPDZ and SPDZ2k. Still, the impact is much greater
for SPDZ as a depth increase from 3 to 9 results in a relative
slowdown of up to 25x, whereas for SPDZ2k the slowdown
is at most 18x. We thus see how important an efﬁcient
realization of an operation like comparison is for the real-
world setting of decision trees. Finally, comparing k = 32
with k = 64 we see that the smaller ring gives up to a 1.9x
improvement for SPDZ2k and 2.0x for SPDZ, showing the
importance of ﬂexibility in domain size.
4UC Irvine Machine Learning repository https://archive.ics.uci.edu/ml/
datasets.html.
2) SVMs: Table III show oblivious evaluation of image
classiﬁcation models constructed by Makri et al. [29], and
a model with few features but many classes5. The models
by Makri et al. are built on the datasets CIFAR-10 [45]
and MIT-67 [46] where Inception-v3 is used for feature
extraction [47]. We chose these models to get a difference
in number of classes and features. We see a large relative
improvement of SPDZ2k over SPDZ. This holds even for
a the smallest amount of classes, and thus smallest amount
of comparisons as well. This indicates that the comparison
is the main bottleneck in the SVM execution in both
systems, as this factor is close to the direct improvement
of comparison in SPDZ2k relative to SPDZ, as shown in
Tables I. It is interesting that this holds even for few classes
and many features, as shown by the Cifar row in the batched
setting.
VIII. CONCLUSIONS
In this work we showed how to compute basic func-
tionality like comparison, equality, bit decomposition and
truncation when working in the ring Z2k, thus overcoming
issues such as zero-divisors and lack of invertibility that arise
in this setting.
We conﬁrmed experimentally the conjecture from [17]
that secure computation over the ring Z2k provides many
advantages in the online phase, with only slight increase in
ofﬂine cost. In particular we saw up to a 5-fold improvement
in computation for various tasks, and up to a 85-fold reduc-
tion in online communication costs for secure comparison,
as compared to the ﬁeld setting.
In the future, we plan to explore other applications
of SPDZ2k, e.g., neural network evaluation, where share
conversions are known to help [16]. It also important to
close the performance gap between SPDZ2k pre-processing
and Overdrive; SHE-based techniques present a promising
venue.
5The model
aloi
datasets/multiclass.html#aloi.
at https://www.csie.ntu.edu.tw/∼cjlin/libsvmtools/
(cid:18)(cid:18)(cid:18)(cid:22)
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:49:58 UTC from IEEE Xplore.  Restrictions apply. 
IX. APPENDIX
(cid:7)
(cid:6)
?≥ 2(cid:3)
a + b + u
A. Carry
This subprotocol computes the carry bit of an addition
between a ∈ Z2(cid:2) and b ∈ Z2(cid:2), when the initial carry-in
bit is set to u ∈ {0, 1}. That is, it computes the function
Carry(cid:3)(a, b, u) :=
. We will use a variant
where a and u are public, and the parties have access to the
bits of b in secret-shared form, [b0]2, . . . , [b(cid:3)−1]2. The proto-
col works by simply running a binary circuit on SPDZ2k us-
ing AND triples. A circuit with 2(cid:4)− 2 AND gates and depth
log((cid:4)) can be constructed using standard methods, see for
instance CarryOutL as described in [21]. We denote this pro-
tocol by [v]2 = ΠCarry(a0, . . . , a(cid:3)−1, [b0]2, . . . , [b(cid:3)−1]2, u).
B. Probabilistic Truncation
In this section we describe a protocol for computing
[b] from [a], where b is an approximation of
. With
probability at least 1 − 2(cid:3)−k the error in the approximation
−d, where (cid:4) (cid:13) k is the bit-length of the number
is at most 2
being truncated.
a
2d
This protocol is taken from [16], which suits our set-
ting since it does not require division by powers of 2.
The protocol works by opening a masked version of a,
c = (a− r) mod 2k. This masked value can be truncated in
, and then the truncation of r (which is
the clear to get
(cid:8)
shared since the parties have shares of the bits of r) can be
. However, there is naturally an
added to get shares of
additive rounding error.
(cid:8)
(cid:9)
(cid:9)
c
2d
a
2d
The protocol is stated in detail in Fig. 8. The proof of
correctness is similar to [16], and given in the full version.
(cid:8)
(cid:9)
Protocol Πd
TruncP
(cid:3)
(cid:4)
INPUT: Shared value [a], with a ∈ Z2k.
OUTPUT: Shared value [b], where b ≡k
1) Call [r0], . . . , [rk−1] ← ΠRandBit(). Let [r] =
2) Compute c ← Open([r] − [a]). Let c
(cid:2)k−1
3) Output [b] ← −(cid:3)
(cid:4)
i=d [ri]2i−d.
+ [r
(cid:5)].
(cid:5)] =
a
2d
[r
.
c
2d
(cid:2)k−1
i=0 [ri]2i.