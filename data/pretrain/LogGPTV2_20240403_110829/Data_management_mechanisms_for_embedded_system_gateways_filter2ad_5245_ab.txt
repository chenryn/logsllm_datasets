### Introduction
The motivating example for this paper is an enterprise-to-embedded scenario. In this setup, a stream of vehicle speed data arrives at the gateway via an enterprise network (e.g., wireless or cellular network). The gateway then sends out these messages during periodic time slots on an embedded control network (e.g., TTP, FlexRay, or CAN with rate-monotonic scheduling). In our simulation, we model message arrivals using a Poisson random process and message departures using a deterministic periodic process. Our example involves a single data flow and a single data management mechanism to handle it.

In addition to the specific example used in this paper, we believe that the techniques discussed can be applied to any system that:
1. Uses real-time control or monitors state variables.
2. Has components that are sufficiently remote, plentiful, or mobile, making the use of existing network infrastructures desirable or necessary for economic feasibility.

Most Supervisory Control and Data Acquisition (SCADA) systems, such as pipeline and power grid control systems, fit this description. While current SCADA applications primarily use remote connections for monitoring activities, the expansion of these systems to include real-time control seems likely in the future. We believe that the datasets used in our experiments are representative of some types of data from these applications. Although different types of data might produce different results, the key insights from our experiments are the identification of queue underflow as a major cause of queue delay and the proposed solution (filters) for mitigating this problem. For other types of data, there may be other mechanisms that can be used in the gateway to meet application requirements. By continuing to examine likely scenarios and use cases for embedded system gateways, we can identify and develop additional mechanisms to meet a wide variety of system requirements.

### Related Work
There are numerous network devices referred to as gateways, especially in the Internet domain, but we have found few examples that deal with connections to embedded networks. One design for a gateway between the Internet and CAN is presented in [4], although that work focuses on hardware design and implementation. The timing analysis focuses on the capability of the gateway to process all messages and assumes that the CAN network is strictly event-triggered. It does not address the situation of how to handle arriving messages if they cannot immediately be sent out on the CAN network, which might be the case if transmission is blocked by higher-priority messages.

Queuing is the primary mechanism used to manage packets in Internet routers, and much work has been done with active queue management techniques for optimizing throughput and implementing congestion control algorithms. Random Early Detection (RED) [3] and BLUE [1] are two examples designed to maximize throughput and reduce congestion. These techniques are usually applied to unbounded queues. [12] modifies RED in an attempt to maintain a target queue length, but the proposed method provides only a probabilistic bound.

Although these techniques are quite successful in the Internet domain, they are intended to optimize bandwidth utilization and throughput. In contrast, an embedded system gateway should be designed to provide for the timeliness of the data passed through the gateway. This implies some fundamental differences in the operation of an embedded system gateway. Active queue management techniques in Internet routers use dropped packets as an implicit communication channel to control the sender rate. When a packet is dropped, the TCP retransmission mechanisms cause the packet to be resent, so the dropped packet will eventually be delivered. In contrast, our gateway acknowledges every message and then delivers the message to the data management mechanism. If the mechanism indicates that a message should be dropped, the message is dropped silently, and no notification is given to either the sending or receiving network. This approach is useful for two reasons: First, for the particular case of TCP/IP, it avoids the delay of another round-trip time to resend the packet on the Internet side of the gateway. Second, it allows us to apply the same techniques to networks that do not have an automatic retransmission mechanism.

### Queue Mechanisms
Since queue mechanisms are successfully applied in Internet routers, we begin our examination of data management mechanisms by evaluating their effectiveness for embedded system gateways. All the queues discussed in this paper use the first-in-first-out (FIFO) queue discipline. There are two key parameters for queue design that we consider: queue length and queue management policies.

For queue length, we consider both bounded queues, which are constrained to a certain maximum length, and unbounded queues, which are allowed to grow to any length. While it is not possible to implement a truly unbounded queue, we assume for the sake of analysis that the storage capacity of any practical implementation can be made arbitrarily large.

For queue management policies, we consider behavior during underflow and overflow situations.

#### Queue Underflow Policies
Queue underflow is one exceptional situation that queue management policies must deal with. Queue underflow occurs when the outgoing network schedule is ready for a new message, but the queue is exhausted and no new message has arrived. This situation is likely to arise if the arriving data is bursty (e.g., a Poisson random process), but it could also occur if both the incoming and outgoing networks are periodic with random jitter. We refer to the underflow policy we use as a mailbox policy because of its similarity to the mailbox implementation used in CAN controllers [10]. The mailbox holds the most recently transmitted value, and if no new value is available from the queue, that same value is sent again. Depending on the implementation, a staleness indicator may also accompany the repeated value.

There are two alternatives to the mailbox policy: send an invalid value or send no value. If an invalid value is sent or no value is sent, the application will continue to use the last valid value (e.g., the set point for an actuator remains at the last received value), so the net effect of these other policies is very similar to that of the mailbox policy. If the data being sent is event-oriented data, the mailbox policy could result in the system interpreting repeated values as additional events. In this case, the null or invalid message policies might be preferred. Since the examples discussed in this paper are all concerned with periodic state variable data, all the queue mechanisms discussed use the mailbox policy.

#### Queue Overflow Policies
Queue overflow policies describe the action to be taken when the queue exceeds its designed maximum length. These policies only apply to bounded queues. For an unbounded queue, an overflow condition cannot occur unless the physical limitations of the system are exceeded. Some policies may drop more than one message or cause the incoming message to be dropped. As mentioned in Section 3, when a message is dropped by the gateway, the fact that the message was dropped is not reported to either the sending or receiving network.

We have identified four queue overflow policies, which we describe below:
- **Drop Newest Policy**: This requires that the newest message (the arriving message) be dropped. This is similar to the active queue management technique known as DropTail [3], which has been used in Internet routers.
- **Drop Oldest Policy**: This requires that the oldest message (i.e., the message at the head of the queue) be dropped. This technique is more useful for state-oriented messages where the more recent messages contain a more accurate description of the current system state. This is similar to the DropFront congestion control technique proposed in [7].
- **Drop Random Policy**: This requires that a message be dropped at random from the queue when an incoming message arrives at a full queue. The incoming message is included in the pool of candidate messages to be dropped. This technique is similar to the Random Early Drop technique [8].
- **Drop All Policy**: This requires that the queue be flushed (completely emptied) when a new message arrives at a full queue. The arriving message is not dropped, but all the messages already stored in the queue are dropped. While the Drop All policy is novel, the remaining three are an application of existing queue management techniques to embedded system gateway queue mechanisms.

### Experimental Approach
Here, we describe the experimental setup we used to evaluate the various queue management mechanisms, the apparatus we used to collect input data for the simulations, and the metrics we recorded to evaluate and compare different mechanisms.

#### Simulation Framework
To evaluate the performance of the various queue management mechanisms, we developed a discrete-time event simulator in Java. The simulation models an arrival process that delivers data to the queue and a service process that removes messages from the queue. Both processes can be specified to be deterministic (e.g., periodic) or random according to a probability distribution. All random elements or sequences in the simulation are generated using a deterministic pseudo-random number generator. The software can repeatedly generate the same pseudo-random sequence from a given seed value. Thus, the same pseudo-random arrival sequence can be recreated and applied to gateways that implement different data management mechanisms to allow for a fair comparison of their performance.

#### Input Data Collection
In these experiments, we are concerned with state-oriented periodic data streams. We developed a data collection system that uses the automotive standard OBD-II diagnostic interface [11] to record the speed of a vehicle during operation. The resulting data is a reasonable example of a state-oriented dataset. An example of an application that might generate similar data is a traffic control system that reports the speed of vehicles further up the road via roadside transmitters or ad hoc vehicle-to-vehicle networks. This data could then be delivered via a real-time network to an onboard embedded controller and used to make adjustments to adaptive cruise control settings.

We collected four different datasets to use as inputs to the simulation:
1. A neighborhood driving scenario with low speeds and frequent stops and starts.
2. A medium-speed scenario on roads that are not highways but have few stop signs or stoplights (shown in Figure 2).
3. Highway driving in light traffic.
4. Highway driving in heavy traffic.

#### Metrics
Several relevant metrics were recorded in the simulations. Each metric is aggregated over all values for a single trial, producing a single value for each trial. In the results, we compare the distribution of these values from experiments with different gateway configurations (e.g., different mechanisms).

- **Maximum Queue Length**: The maximum queue length observed during a single trial.
- **Average Queue Delay**: The delay for each message (time between arrival at the queue and departure from the queue) averaged for all messages in a single trial. Dropped messages are not factored into this metric, nor are duplicated deliveries that occur because of the mailbox policy.
- **Dropped Message Count**: The total number of dropped messages in a single trial.
- **Mean Value Error**: A metric designed to capture how well a data management mechanism preserves the data sequence. It is computed by recording the point-by-point difference between the original data sequence and the data sequence output by the gateway. The average of the absolute value of these differences is computed over the whole run.

#### Experimental Setup
Our experiments are designed to model the enterprise-to-embedded scenario described in Section 2. Internet traffic has been shown to be bursty [5], so we choose to model the arriving data with a Poisson random process. [9] discusses several delay models that can be used to model the arrival process: constant delays, independent random delays (e.g., the Poisson process), and Markov chain models (which capture the effect of network load on the distribution of delays). The Poisson process model is simpler because it does not require an exploration of the additional parameters of the Markov chain models, but it captures the bursty nature of the arriving data. We believe that experiments with other bursty arrival processes would have similar results.

For each experiment, the simulator was configured with a Poisson arrival process with a mean inter-arrival time of one message per second and a periodic service process also with a period of one second. We use one of the vehicle speed datasets described in Section 5.2 as input data. The simulated gateway is configured with a particular data management mechanism (e.g., a finite queue of length 50 using the Drop Oldest overflow policy). A trial is a single run of the simulation and produces a single value for each of the metrics described in Section 5.3. In each trial, a different pseudo-random arrival sequence is applied to the gateway. Each experiment consists of 5000 trials. The sequence of data values delivered to the gateway in each trial is the same (such as those pictured in Figure 2). Only the timing of the arrivals changes from trial to trial.

An experiment set is a series of experiments performed with different mechanisms (e.g., a set of experiments on queues of length 10, 20, and 50) intended to compare the performance of the mechanisms with respect to one or more metrics. Experiment sets are repeated using each of the four datasets as inputs.

### Queuing Results
This section describes the queue mechanisms that were used in the various experiments and highlights some of the significant results. Although experiments were performed on all four of the input datasets described in Section 5.2, we have chosen to report only the results from the second dataset (shown in Figure 2) due to limited space. The results from the other datasets are qualitatively similar and also support our conclusions.

Many of the results presented below use box plots to summarize the results for a particular metric for a single experiment. The statistics given in a box plot are summarized in Figure 3. The results from a set of experiments are presented in a single graph to facilitate comparison of the results.

#### Unbounded Queues
Our first experiment used an unbounded queue mechanism. Figure 4 shows a selection of time-series data from a single trial of the experiment. Part (a) shows the input and output data streams and highlights the delay between the input and output. Part (b) shows the size of the queue over time. The delay increases as the queue length increases. As might be expected, the delay is directly proportional to the queue length, since the length of the queue when a message arrives determines how long it remains in the queue.

One goal was to see how long the queues could grow. Figure 5 shows the distribution of maximum queue lengths for this experiment. While the median of the distribution is around 38, the maximum queue length observed was 125. Although longer queues are less likely, there is no theoretical upper bound on the worst-case queue length for an infinitely long dataset.

The mean value error results for unbounded queue experiments are included in Figures 8, where they are compared to the results from the bounded queue experiments described in Section 6.2. These experiments show that transient queue lengths and delays can grow quite large, even if the average rate of the data going in and out of the queue is the same. While this result may be expected, it is important because it leads us to examine bounded queues as a way to mitigate this delay.

#### Bounded Queues
We now examine bounded queues, since a bounded queue should have bounded delay. When we study bounded queues, we consider two parameters: the length of the queue and the overflow policy. First, we examine the effect of queue length on delay and on the number of dropped messages.

Figure 6 shows that the number of dropped messages decreases as the queue length increases. For queues of length 50 or more, very few messages are dropped at all. This is because longer queues are less likely to overflow. On the other hand, Figure 7 shows that the average delay increases as the queue size increases. For queues of length 50 or more, the delay is relatively small, but for shorter queues, the delay can be significant.

### Conclusion
In conclusion, our experiments demonstrate the importance of considering both queue length and queue management policies in the design of embedded system gateways. Unbounded queues can lead to significant delays and potentially unbounded queue lengths, while bounded queues with appropriate overflow policies can provide more predictable and manageable performance. The mailbox policy for queue underflow and the Drop Oldest policy for queue overflow are effective in handling the bursty nature of the arriving data and ensuring the timeliness of the data passed through the gateway. Future work will involve further exploring the trade-offs between different queue management mechanisms and their applicability to a wider range of embedded system scenarios.