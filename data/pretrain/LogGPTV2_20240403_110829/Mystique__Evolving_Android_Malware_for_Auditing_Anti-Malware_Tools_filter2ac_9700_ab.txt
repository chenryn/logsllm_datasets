with the code snippets of features. The output is a collection of
generated malware samples that are labeled with features inside.
Here, we brieﬂy describe the work ﬂow. First, the attack features
(AF) and evasion features (EF) used in the original malware collec-
tion should be identiﬁed and modularised (§ 4.1). Attack features
are the requirements of malware from the prospective of attackers,
and atomic functionalities from the prospective of SPL. They are the
fundamental composition of activities (i.e., behaviors) of apps. Af-
ter ﬁnishing the feature-oriented domain analysis (FODA) for the 49
malware families in GENOME, we remove the duplicated AFs and
add the remaining AFs in the feature model shown in Fig. 2. Mean-
while, the corresponding code of these AFs are also modularised in
separated methods or classes, in such a way that the architecture of
our malware product line is built up. EFs are mainly from evasion
techniques in ﬂow and code. EFs in ﬂow include multiple ways
from source to sink, such as Lifecycle [8] and ICC [38], and EFs in
code are inspired by the transformation of code [41, 42]. Once the
features in our FODA are available and the corresponding feature
code are modularized, we adopt the Indicator-Based Evolutionary
Algorithm [44, 50] to generate malware with the three objectives:
aggressiveness, evasiveness and detectability (§ 5).
Running Example We take DroidKungFu in GENOME as an ex-
ample. DroidKungFu belongs to malware of privacy leakage, which
steals sensitive information (e.g., IMEI code, phone number). Fig. 1
shows the feature model for malicious behaviors contained in Droid-
KungFu. The feature model consists of necessary features for launch-
ing attacks as well as their relationship in between. For example,
DroidKungFu obtains IMEI code and phone number, which belong
to the feature Source. Feature Source has 4 optional sub-features,
among which feature IMEI and PHN NUM require permission feature
READ PHN STE that relates to permission (§ 4.1).
After obtaining the feature model, we encode the attack features
(malicious behaviors) as chromosome in gene. Speciﬁcally, each bit
of the chromosome represents the existence of an attack feature —
1 for existent and 0 for non-existent. The crossover operation and
mutation operations are performed on the chromosome during the
evolution. In step 2 of Fig. 1, we mutate features IMEI and PHN NUM
to feature LOCATION. According to feature dependency, the original
permission feature READ PHN STE for IMEI is not required any more,
while feature LOCATION acquires permission feature ACC LOCATION.
After that, the gene of a new malware variant is produced.
In step 3 of Fig. 1, the code of each feature in gene will be
assembled. Details on assembling triggers and manifest ﬁle are
in Section 5. In addition, to audit the capabilities of AMTs, we
also employ obfuscation to evade the detection, then one malware
variant is created and can be used for auditing AMTs. Owing to the
gene of the generated malware variant, we can evaluate what feature
combinations can evade what defence strategies.
DroidKungFu attack IMEI Packaging PHN_NUM INS_APP  HTTP_POST READ_PHN_STE INTERNET DATA_FLOW LOCATION ACC_LOCATION INTERNET DATA_FLOW M1 M2 Code  Assembly Evasion Application evasion source sink perm DATA_FLOW IMEI PHN_NUM INS_APP INS_APP  HTTP_POST INTERNET READ_PHN_STE ACC_LOCATION  HTTP_POST LOCATION Step 1.  Step 2.  Step 3.  malware attack configuration source sink trigger main listener observer broadcast mandatory optional alternative or requires excludes evasion data control  Transformation  behavior permission Intent filter 3673.2 Technical Challenge
To generate the sound and workable malware, we face the follow-
ing technical challenges:
• C1: Construction of feature model. A variety of features are
contained in malware, and used in different ways. It is difﬁcult
to identify and extract the representative features in malware.
Section 4.1 addresses this challenge.
• C2: Malware measurement. With the feature model (i.e., the
meta-model of malware), we still need some goals to guide au-
tomated malware generation. Thus, we deﬁne three objectives:
aggressiveness, evasiveness and detectability for measuring mal-
ware (§ 5). Since these objectives are competing (e.g., highly
offensive malware is generally more detectable), we use a MOEA
to select feature from feature model in Section 5.
• C3: Validation of generated malware. As the malware is gen-
erated according to the feature model, we want to prove their
maliciousness — whether malicious behaviors can be triggered
and carried out on real Android devices. To address this chal-
lenge, in Section 7, we conduct the following experiments. For
the attack of privacy leakage, we set up a dummy server or device
to receive the sensitive information sent from malware.
4. FEATURE-ORIENTED DOMAIN ANAL-
YSIS OF ANDROID MALWARE
We identify the common building blocks for Android malware
as attack features and evasion features, and propose to use feature
model as the meta model to capture the malware. Different from
focusing on requirements in malware ontology analysis [37], we
consider and maintain the traceability between the features and their
corresponding code in our model. One partial feature model of
malware of privacy leakage in GENOME is shown in Fig. 21. Note
that feature-oriented domain analysis relies much on the domain
knowledge of security experts, and only feature and their code
relevant to attacks are manually modularized. We totally identify
266 attack features and 14 evasion features. Note that our feature
model is not a complete one, but can be extended to covering new
attack behaviors and evasion methods.
4.1 Attack Feature
Attack features refer to features that are generally relevant to the
malicious behaviors of a certain type of attack. They can be further
categorized into the following three types:
Trigger Feature. Trigger deﬁnes the entry points for malicious
attack behaviors. Triggers are roughly categorized into GUI-based
and non GUI-based [51, 52]. Since non GUI-based triggers are not
easy to be discovered by users, thereby more suspicious, we only
consider non GUI-based triggers without the interaction with end
users. There are four kinds of non GUI-based trigger features are
mainly identiﬁed in GENOME: main, broadcast, listener and observer.
The trigger main denotes that malicious behaviors are triggered from
the startup; malicious behaviors can be triggered from a broadcast
message by registering a BroadcastReceiver; malware can also register
a listener to listen the changes on states (e.g., location); malware can
register an observer on a ContentProvider to listen to its changes.
Conﬁguration Feature. Two kinds of conﬁguration features are
relevant to malicious attack behaviors in malware: permission and
intent ﬁlter. Android provides a permission-based mechanism
to avoid the abuse of system sensitive operations, e.g., invoking
sensitive Android APIs. Many malicious behaviors in malware
1The complete feature model of Android malware is available in our web-
site [1].
require certain permissions to attain attack goals. For example,
it needs the permission android.permission.READ PHONE STATE to
obtain the IMEI code of the device. Feature Intent Filter deﬁnes
the acceptable Intent that can be captured by Android components.
For example, if one BroadcastReceiver is assigned with intent ﬁlter
android.provider.Telephony.SMS RECEIVED, it can capture broadcast
messages indicating an incoming SMS.
Behavior Feature. Attack trigger and conﬁguration features are all
assistant to the core attack features — behavior features. In an attack
of privacy leakage, there are mainly two types of features: Source
and Sink. Source is responsible for stealing sensitive information of
device, and sink is responsible for sending out sensitive information.
Based on the manual domain analysis of GENOME, 11 kinds of
source features and 2 kinds of sink features are identiﬁed [1].
Note that the partial feature model in Fig. 2 mainly illustrates the
high-level organization of these features. Each leaf feature in Fig.
2 may have several subfeatures, e.g., feature Source has 11 variant
sub-features in an Or relationship, and each variant feature may
also have several implementation features (modularized code) in an
Alternative relationship. Interested readers can refer to Section 5
and our tool website [1] for more details.
4.2 Evasion Feature
Information ﬂows from source to sink in privacy leakage attack
can be obfuscated in three different ways as follows:
Control based Evasion. Malicious behaviors can be obfuscated
by complicating the control ﬂow of the attack. Android provides
an amount of callback functions to guarantee implicit control ﬂow.
Besides, each component in Android has its own lifecycle together
with a set of built-in APIs for lifecycle management. In an attack of
privacy leakage, the control ﬂow usually involves the interactions
between different components in Android. Thus, it is feasible for
the attacker to hide the malicious code into the different stages of
components and trigger it under certain scenarios. For example,
each Android component has a life cycle, the method invocation
sequence of which is deﬁned in the framework layer of Android.
A certain method will be invoked if the component is in a speciﬁc
state. In Inter-Component Communication (ICC), there is also one
mechanism for implicit control ﬂow if an Intent object is not assigned
with a determined class [27, 38].
Data based Evasion. Attacks like privacy leakage must conduct
data transmission. Such transmission can happen between different
methods, classes, apps, or even different channels (i.e., external
persistent storage and memory).
• Persistent Storage. On Android, applications may exchange
data through persistent storage. There are three types of persistent
storage provided by Android: ﬁle, shared preferences and SQLite
database. They can be used for applications or components to
exchange data — they provide an implicit data ﬂow from one
component to another.
• Memory. Data that is temporarily stored in a speciﬁc memory
location (e.g., an object in the Java heap) might be accessed
globally. As a consequence, once there is a component or method
to fetch data from that memory location, it establishes a data ﬂow
from where the data is stored to where it is fetched.
Both. Attacks can be further complicated by combining the ob-
fuscations on both control and data ﬂow. As Intents are the main
vehicle for app communication, they can be used for a purpose of
advanced obfuscation. One intent can be either explicit or implicit.
Explicit intents have a speciﬁc class to start, while implicit intents
do not specify the corresponding class, and the system will select
the most well-suited class or application to execute. An explicit
intent can only invoke a speciﬁc component, which is deﬁned in
368the constructor, or by calling setComponent(ComponentName) or set-
Class(Context, Class); an implicit intent can be received by many
well-suited components. It appoints potential receivers by setting
an action in the constructor or setAction(String) (Meanwhile, it can be
instrumented with a data type to restrict its receivers). In addition,
an Intent object can be bundled with some data by invoking putExtra,
which generates a data ﬂow from the caller component to the callee
component. Therefore, Intent can inﬂuence the execution order of
the app and also the data ﬂow if enclosed with extras.
In addition, we use the transformation attacks [41, 42] to compli-
cate and transform the source code at the implementation level.
Transformation Attacks. We have selected 12 types of transfor-
mation attacks, such as identiﬁer renaming, data encryption, code
reordering, to obfuscate the generated malware. Different from the
previous evasion techniques, the transformations cannot change the
behaviors or ﬂows from source to sink. It is a kind of non-behavior
evasion technique since the transformations only change the lexical
information or code structure. However, by adding a lot of noise
to the previous code, it may bypass the detection of AMTs which
consider code structure or lexical information. With the reordering
of code, it may break some AMTs based on static analysis.
5. MULTI-OBJECTIVE GUIDED MALWARE
GENERATION
This section is devoted to the Android malware generation process
in MYSTIQUE. As shown in Fig. 3, MYSTIQUE takes a malware
feature model as the input and generates various malware variants.
During the process, each malware is encoded as a DNA sequence
based on their values for AF and EF in the feature model. The
malware evolution is an iterative process in accordance with the
principle of survival of the ﬁttest, where we randomly choose an
initial population of malware satisfying the input feature model, and
select better malware in the each generation afterwards based on the
ﬁtness function, i.e., the malware measurement function in our case.
The four steps in each iteration of malware evolution are as follows.
• Step 1: Feature Selection. Given the previous generation n of
malware, step 1 is to produce new malware by applying crossover
and mutation operations on malware from generation n. Consid-
ering the three objectives, the IBEA is used to choose the ﬁttest
ones in each iteration.
• Step 2: Code Assembly. To make the malware run on a real
device, MYSTIQUE conducts to validate the assembled code and
package it into a deployable app. It includes the setup of triggers
that act as entry points of malicious behaviors, the conﬁguration
of manifest ﬁle, and malware packaging.
• Step 3: Evasion Application. After evasion features are selected,
the corresponding evasion techniques are applied. Note that
the evasion is based on the source code, without changing the
malicious intent or behaviors of the constructed malware.
• Step 4: Objective Evaluation. In this step, we calculate the
objective functions and choose the ﬁttest for the next iteration.
We also need to check whether the evolution is ﬁnished due to
convergence of EA or reaching the upper limit of iteration times.
The selected features of a feature model is encoded using an
array-based chromosome as shown in the step 2 of Fig. 1. Given
a chromosome of length n, array indices are numbered from 0 to
n− 1. Each feature (no matter AF or EF) is assigned with an array
index starting from 0. Each value on the chromosome is zi such
that zi ∈ Z ∧ zi ∈ {0,1}, where 0 (resp. 1) represents the absence
(resp. presence) of the feature. Given a feature model M, we deﬁne
a function fM : Fea(M) → {Z,⊥} that maps each feature f of the
feature model M to an array index. fM(f1) = ⊥ denotes that there
is no array index that is assigned for the feature f1. Similarly, we
−1 : Z → Fea(M) as a function that maps a given array
deﬁne fM
index to the feature it represents. Thus, gene crossover is just the
array exchange at a certain index, and gene mutation is bit ﬂipping
of the value at a certain index of the array.
To serve as the goals of malware generation, we propose three
objective functions in the evolution of malware: aggressiveness, eva-
siveness and detectability. As the results of the arms race, malware
are getting more aggressive with minimum evasion features needed,
but less detectable.
and evasion features, where {f a
features and {f e
objective functions are deﬁned as follows:
Deﬁnition 1 Aggressiveness means the severity of damages that
malware may cause to users, which is measured by the number of
contained AFs and formally deﬁned as
Given a chromosome x, we represent it as a bit vector of attack
n } denotes the set of n attack
m} denotes the set of m evasion features. The
1 ...f a
1 ...f e
F1(x) = ∑n
i=1(cid:107)f a
i (cid:107)
i
i (cid:107) returns 1 if f a
is selected and returns 0 if not.
where (cid:107)f a
Deﬁnition 2 Evasiveness means the efforts to hide the malicious
intent and evade the detection. Attackers want to minimize such
effects of using evasion techniques to evade detection. It is measured
by the number of contained EFs and deﬁned as follows
(1)
(2)
F2(x) = ∑m
i=1(cid:107)f e
i (cid:107)
where (cid:107)f e
i (cid:107) returns 1 if f e
i
is selected and returns 0 if not.
Given a chromosome x and the set of AMTs Sd, {d1...dt}, intro-
duced in Section 6, we have the following deﬁnition for the last
objective function:
Deﬁnition 3 Detectability means the difﬁculty in detecting the mal-
ware. It can be measured by detection results of AMTs and deﬁned
as follows
F3(x) = (∑|Sd|