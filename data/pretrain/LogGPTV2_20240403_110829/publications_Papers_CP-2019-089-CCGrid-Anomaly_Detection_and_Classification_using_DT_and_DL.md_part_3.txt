At every time step, the errors between the predicted vectors
and the actual ones in the validation group are modeled as
1. response time, 2. response time,window size, response time
a Gaussian distribution. Assume that the validation data has
1000 windows of with window size = 32. The MSE for all
Fig. 3. Model architecture.
of them will produce array of 1000 error values. Next, we
Input layer: has window size number of units, each con­ estimate the mean and the variance for the MSE scores and
taining the response time as input. In Figure 3, we use save them on the disk along with the model. These values are
window size — 32. used in test-time prediction. In test-time prediction if the error
First hidden GRU layer: contains (window size/2) 16 between a reconstructed and an observed window of events
GRU cells for each timestep in the input window. Each of is within a high-level of confidence interval of the above
245
Gaussian distribution is considered as normal, otherwise as D. Faulty pattern classification
anomaly.
Identifying the existence of an anomaly without providing
any insight into its nature is of limited value. The user may
C. Test-time prediction
be interested in detecting particular types of anomalies which
Previously, we already showed the architecture, model train­
reflect in the time series (e.g., incremental, mean shift, gradual
ing and dynamic threshold setting. After having the trained
increase, cylinder etc.). Here, we expect that an expert knows
model, this module receives data from the preprocessing
the types of patterns that commonly lead to service or com­
module described previously. The latest model along with the
ponent failure. Therefore, we provide a module based on one
saved training parameters are loaded, and used for prediction.
dimensional convolutional neural networks that, given as input
For each new event, the past values forming a window
a window of the event response time (e.g., 32 events), is able to
xt = {et-w,et-w+i, ...,et} are fed as input for prediction.
classify into one of the user defined patterns described before.
The reconstruction error MSEtest and the probability under
Convolutional Neural Networks (CNNs) [36] are common
the Gaussian are computed:
deep learning technique for image, signal processing, sequence
and time series classification tasks. Typically, the architecture
l\r,i — 1 -P(X> MSEtest) (6)
of the CNN consists combination of convolutional and max­
Remembering that the parameters of the probability density pooling layers followed by softmax layer that distributes the
function p and a2 are computed as parameters in the training probability for a given pattern. Recently, similar work for time
step. series classification is found in [37].
1) Tolerance: false positive reduction: In large-scale sys­ Similar to the preprocessing module, the latest N points
tem architectures, there are thousands of events recorded in from time series are queried and utilized to represent the
short period of time and there are cases where it might happen normal class. After that, we create a dataset which contains
that the response time is greater compared to the expected normal data preprocessed using the preprocessing module
time. If it is only a single anomalous point in the time series described and added to the augmented samples of predefined
or even few of them with increased service response time, patterns (translation and adding small amount of noise) by the
does not mean that anything is wrong with the service. For user.
example, that can be a small bottleneck in the disk usage or The model architecture consists of three (convolutional,
in one of the many components or services. Aiming to detect max-pooling) layers with dropout (0.5) regularization. The last
anomalies that have larger impact, enables the DevOps to pay layer, typical for multi-class classification, is fully connected
only attention to the most critical potential failures. with softmax function for computing the probability distribu­
We define the tolerance and probability error threshold as tion over the classes. The convolutional networks are naturally
parameters. The tolerance represents the allowed number of invariant to translation, which makes them suitable for faulty
anomalous windows that have P{x) greater than the prob­ pattern detection with sliding window over the time series.
ability error threshold before it flags the whole period as The network is trained using the data described and the model
anomalous. In practical scenarios, the tolerance parameter is saved and used for prediction. We used again Adam opti­
usually ranges from 1 to 100, but it is dependent on the mizer with optimal parameters obtained via cross validation
dynamics of the system. The probability outputs Ptest are (ilearning rate = 0.001, number of epochs = 200 and
kept in queue with the same size (tolerance) for each new batch size = 1000). The classifier triggers when the test-time
window. Each time, a new sample is shown to the network prediction detects an anomaly. The classifier module receives
to be reconstructed, assigned with the probability of being the output from test-time prediction and requests the particular
anomalous and is added to the queue, the tolerance module time series within the provided anomalous time interval. Next,
checks whether the average probability: using the trained model, we map each sliding window to the
j predicted class and if the particular pattern is recognized the
tolerance
^ (7) module will output the name of the class in which the pattern
Pm = t, oljerance %' Ptest(i)'
belongs and will flag the interval as anomalous.
of all the points in the queue is greater than the error threshold.
If this is the case, the submodule flags this part of the time V. Eval uat io n
series as unstable and reports an anomaly. In this way we can The deep learning methods are implemented in Python using
deal with the problem of having too many false positives and Keras [38]. The evaluation on the collected datasets were
allow the user to set the sensitivity of the algorithm on his conducted on regular personal computer with the following
or her demand. The output from the whole module is: (first specifications: GPU-NVIDIA GTX 1060 6GB, 1TB HDD, 256
anomaly window timestamp, last anomaly window timestamp). SSD and Intel(R) Core(TM) i7-7700HQ CPU at 2.80GHz.
In our setting, we used window size = 32, hamming In this section, we show evaluations of separate modules
smoothing window with M = 12, confidence interval under on two datasets. First, we show results on the experimental
Gaussian (error threshold = 0.99) and queue size of testbed system based on microservice architecture and later
tolerance = 32 windows. the evaluation on real large-scale production cloud data.
246
Fig. 4. Multiple distributions: We notice existence of multiple distributions that need to be learned as normal. The distribution differs from PI compared to
P2 and P3.
Anomalies • Scenario 4: Network packet loss - Packet loss (10%, 20%,
Latency increase
Kill process 30%) is injected on one of the network links for 1,5, 10
..............0 ............ minutes
Go Python Java • Scenario 5: Network delay - Network delay (1, 2, 3 sec)
(2 instances) (2 instances) (Tomcat, 2 inst.)
is injected on the network for 1, 5, 10 minutes.
Tracing • Scenario 6: Server process dies - One process is killed
Node 1 Node 2 Node 3 on node 1 and 3 for 1, 5, 10 minutes.
B. Dataset: production-cloud data
^ ‘nnnnlir
Network delay Even in small, controlled experimental setups, the amount
Network packet loss
of noise is high and the time series changes rapidly over time.
This already opposes challenges for the anomaly detection
algorithm. However, testing the approach on large-scale pro­
Fig. 5. Experimental microservice system architecture. duction cloud data is required to show the viability of the
approach. The signal-to-noise ratio is even smaller since many
components affect the response time of microservices, the time
A. Experimental microservice system
series evolves faster and changes its distribution over period
We created an experimental microservice system to evaluate of time while having also some stochastic behavior.
representative anomaly scenarios for microservice architec­ We collected the dataset in a period of four days from a
tures. It allows fast preparation of experiments, known data real-world production cloud. We used only the attributes that
format, and precise control on anomalies injected in the are open-sourced by Zipkin [39], removing all the proprietary
system. For the setup, we used 2 physical nodes and 3 virtual instrumentation. Therefore, from all of the attributes that one
machines with tracing enabled, each of them running instances event has (around 80 in total, depending on the event), we
of Python, Go and Java applications respectively. The testbed extract only the http URL and the response time. The number
architecture is shown in Figure 5. For the anomaly injections of unique http URLs was 100168 and after clustering the total
we used stress-ng, traffic control, and simulator parameters. number of time series ( cluster IDs/qndpoints) was 143. Out of
We injected timed anomalies in the physical network in them, we selected three services of interest. The anonymized
form of delay and packet loss, physical node anomalies in names along with the count of the samples is given in Table I
form of CPU stress and event response time increase injected
directly into the event. Thus, we created 6 different scenarios TABLE I
on different endpoints in the system described in following. Selected clusters for analysis
• Scenario 1: Baseline with no anomaly - represents the ClusterlD Count
{host}/v l/{p_id}/cs/limits 12900
normal operation (no anomalies) of the system and is
{host}/v l/{t_id}/cs/delete 2732
used to train the detection algorithms.
{host}/v2/{t_id}/servers/detail 6468
• Scenario 2: Increase service latency - profile 1 (injection
of latency (1 second) for duration of 15 seconds). The time series, as shown in Figure 4, have high level
• Scenario 3: Increase service latency - profile 2 (injection of noise ([0ms, 2000ms] and [0ms, 4000ms]), several distri­
of latency (1, 5, 30 seconds) for duration of 30 seconds, butions changing over time, and no strong anomaly in both
1 and 10 minutes on Nodes 1,2,3). signals except in the neighbourhood of 11500th data point in
247
 .
Fig. 6. Example of predefined patterns
...
                      ...      
event number event number
(a) (b)
Fig. 7. Detected anomalies injected for different scenarios: (a) scenario 5, and (b) scenario 6
the figure. For the evaluation, we will use the part of the time TABLE II
series as normal scenario for training and then inject faults Accuracy for 15 endpoints in 5 anomaly scenarios
to check the model accuracy in the rest of the series. The
Clus. ID S 2 S 3 S 4 S 5 S 6
presence of strong noise leads to low autocorrelation. That 1 - 85 95 98 99
means, simple sequence learning without learning the distribu­ 2 - - 99 98 -
tion (with variational autoencoder) will result in learning only 3 - - 96 99 96
4 - 99 - - -
the running mean of the time series. Moreover, the distribution 5 - - 100 98 97
is skewed negatively. Therefore, the typical log transform of 6 98 - - 86
the data wont help for the model and it is omitted. 7 - 95 98 97 -
8 - 98 - - -
9 - 92 91 99 100
C. Results: variational recurrent model
10 90 95 95 99 98
In the following, we show the results obtained by the models 11 - 96 - - -
on both datasets. 12 85 - 83 99 97
13 95 98 - 94 99
1) Results: microservice system: Accuracy of the unsu­ 14 99 96 - - 98