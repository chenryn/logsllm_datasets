0.0027
0.0040
0.0061
Music dataset, respectively, after injecting 5% fake users. The
possible reason is that the Music dataset is more sparse, mak-
ing the recommender system less stable and more vulnerable
to the poisoning attacks. The standard deviations of the hit
ratios in Table I can be found in Appendix A, and the change
of the hit ratio for each target item is presented in Appendix
B. These results further demonstrate the effectiveness of our
attack.
Impact of the Number of Recommended Items. Table III
shows the results of poisoning attacks with different numbers
of recommended items (i.e., K) in a recommendation list.
Attack size for all poisoning attacks is set to 1% and the
number of ﬁller items (i.e., n) is set to by default 30 for all
methods. We choose unpopular target items to conduct our
experiments. First, we observe that our attack is still the most
effective method among all the poisoning attacks in all cases,
e.g., when K = 20, the hit ratio of our attack on the ML-100K
dataset is about 6.0 times of the best hit ratio achieved by the
baseline attacks. On the Music dataset, we can observe similar
results. For example, the MF attack can increase the hit ratio
to 0.0040 when K = 20, which is the best among the existing
methods, while our attack achieves the performance of 0.0061,
about 1.5 times of the former.
The hit ratios of all methods tend to increase with K. As
we can see, the initial hit ratio with no injected fake users
increase when K increases on the Music dataset. Similarly,
hit ratios for all poisoning attacks gradually become larger
when K increases on both datasets. For instance, the hit ratio
of our attack on the ML-100K dataset when K = 20 is about
3.5 times of that when K = 5. A larger K means a greater
chance for target items to be included in the recommendation
list. This phenomenon is particularly obvious and signiﬁcant
in our attack.
10
Impact of the Number of Filler Items. Figure 3 illustrates
the results of poisoning attacks with different numbers of
ﬁller items (i.e., n) that changes from 10 to 50. We choose
unpopular target items as our target items. We have some
interesting observations. First, our attack always outperforms
other existing poisoning attacks in all test cases, which further
demonstrates the effectiveness and robustness of our attack.
In particular, when n is relatively small, the performance of
our attack is still the best. Therefore, when an attacker tries
to insert as few ﬁller items as possible to evade detection
by the target recommender system, our attack method is the
best choice to implement effective attacks. Second, the hit
ratio may not always increase when n increases. On the ML-
100K dataset, the performance of our attack increases ﬁrst
and then dicreases with the increase of n. It achieves the
best result when n = 20. The attack effectiveness of the
MF attack tends to decrease when n increases, while other
attacks achieve relatively stable performance. However, on the
Music dataset, the hit ratio of our attack descends ﬁrst and
then ascends with the increase of n, while the hit ratios of
other attacks ﬂuctuate.These results show that there is no linear
correlation between the attack effectiveness and n. As with
different datasets, the most suitable n can be different for the
existing poisoning attacks. We suppose that, when n is small,
each fake user can only exert limited inﬂuence on the target
recommender system, while, when n is large, there might be
some items that are ineffective in promoting the target item,
and even competing items included in ﬁller items. Thus, the
best number of ﬁller items is closely related to the attack
methods and the used datasets.
Impact of δ. As an important parameter used in our attack,
δ can affect the diversity of ﬁller items and further impact
the attack effectiveness. We select two random target items
from the ML-100K dataset and the Music dataset respectively
and analyze the diversity of the ﬁller items selected by our
attack. For simplicity, we inject 5% fake users. The results are
shown in Figure 4. First, we observe that ﬁller items on both
datasets have good diversities. The highest frequency of ﬁller
items on the ML-100K dataset is 13, around 1.4% of the total
number of normal users, and all other items have relatively
low frequency. On the Music dataset, the frequency of all ﬁller
items is not larger than 2, indicating a strong diversity. Second,
the ﬁller items on the Music dataset have a stronger diversity
than that on the ML-100K dataset. The ﬁller items on the
Music dataset are more evenly distributed than those on the
ML-100K dataset and the average of their frequency is lower
than that of the ML-100K. The reason is that we use a smaller
δ for the Music dataset, which ensures a better diversity.
To further investigate the impact of δ on the attack effec-
tiveness, we change the value of δ and inject 5% fake users on
the ML-100K dataset for random target items. The results are
illustrated in Figure 5. First, we observe that δ has a signiﬁcant
inﬂuence on the attack effectiveness of our method on the ML-
100K dataset. The hit ratio for target items does not always
ascend when δ increases, and the best δ for the ML-100K
dataset is around 0.9. Second, compared to the hit ratio of
target items when δ = 1, i.e., no change is required for the
selection probability vector after generating a fake user, δ helps
to promote the attack effectiveness when δ < 1. Third, our
attack still outperforms other attack methods in most cases,
which demonstrates the robustness of our attack.
(a) ML-100K
(b) Music
Fig. 3: The impact of the number of ﬁller items on the attack effectiveness.
(a) ML-100K
(b) Music
Fig. 4: The impact of δ on the diversity of ﬁller items.
real ratings and predicted ratings. To accurately evaluate the
impact of the target item rated by fake users, we now consider
what if the target item is not rated by fake users by default
in various poisoning attacks. Note that, we set δ = 1.0 here
and select the (n+1) items with the highest adjusted predicted
rating scores as those items rated by the fake user in our attack,
and the baseline attacks follow their own rules to select the
(n+1) rated items for fake users. We choose the random target
items in the ML-100K dataset to conduct the experiments.
The experimental results are shown in Table IV. Compared
to the results presented in Table I, we can observe that the
effectiveness of all attack methods is reduced signiﬁcantly
when the target items are not selected by default. However,
our method remains effective as the hit ratio of target items
still increases by 1.6 times when injecting 5% fake users, while
other baseline attacks are ineffective in this scenario.
C. Attacks with Partial Knowledge
Fig. 5: The impact of δ on the attack effectiveness for the
ML-100K dataset.
Impact of the Target Item Rated by Fake Users. We assume
that each fake user will certainly rate the target item in the
attacks including our attack as well as the baseline attacks. It
is inspired by the observation that the most effective method to
promote an item is to assign it with high rating scores in the
training dataset due to the strong correlation between users’
In the experiments above, we assume that an attacker has
full access to the whole dataset of the target recommender
system, which does not always hold in practice. The attacker
may only have partial knowledge of the dataset. To evaluate the
effectiveness of different poisoning attacks under this setting,
we conduct further experiments with two different types of
11
1020304050Number of filler items0.00000.00050.00100.00150.0020HR@10NoneRandomBandwagonMFOur attack1020304050Number of filler items0.00050.00100.00150.00200.0025HR@10NoneRandomBandwagonMFOur attack050010001500Item ID024681012Frequency050010001500Item ID012Frequency0.30.40.50.60.70.80.91.00.0070.0080.0090.0100.0110.0120.0130.0140.015HR@10TABLE IV: HR@10 for different attacks without target items
selected by default.
Dataset
Attack
None
Random
ML-100K
Bandwagon
MF
Our attack
0.5%
0.0025
0.0025
0.0026
0.0026
0.0028
Attack size
1%
3%
0.0025
0.0025
0.0026
0.0026
0.0034
0.0025
0.0024
0.0028
0.0027
0.0043
5%
0.0025
0.0025
0.0024
0.0025
0.0064
partial knowledge. One partial knowledge is that the attacker
knows partial rating scores of all normal users, and the other is
that the attacker knows all rating scores of only partial normal
users. Note that, all these experiments are evaluated on the
original dataset that contains all users and all rating scores.
We use the random target items in our experiments. The results
are shown in Table VI and Table VII, respectively. According
to Table VI, we observe that, even with only 30% ratings of
the original rating matrix, the hit ratio of the random target
items in our attack is 0.0092, which is only slightly smaller
than that with full knowledge, i.e., 0.0099, (see Table II) and
much larger than the best result of baseline attacks, i.e., 0.0069
achieved by the random attack. However, the bandwagon attack
and the MF attack are much less effective with only partial
knowledge. Similarly, in Table VII, our attack still outperforms
the baseline attacks, and the hit ratio of our attack is only
slightly smaller than that with full knowledge. The results
demonstrate that our attack is still effective even when the
attacker only has partial knowledge of the training data, while
the bandwagon attack and the MF attack heavily relies on the
information informed from the observed dataset.
D. Transferability
In the previous experiments, we assume a white-box setting
under which an attacker knows the internal structure, the train-
ing data and the hyperparameters of the target recommender
system. As long as we use the known data and the model
structure to train a surrogate model locally, we can obtain a
model having a similar function to the target recommender
system. To further evaluate the transferability of our attack,
we consider the gray-box setting under which the attacker only
knows the algorithm and the training data used by the target
recommender system.
We assume that an attacker generates fake users based on
a surrogate model that is different from the internal structure
of the target recommender system. Speciﬁcally, we change the
number of MLP layers to constitute a different target recom-
mender system. Note that, these target items and ﬁller items
generated for all fake users under this setting are consistent
with that under the white-box setting. Table V shows the hit
ratios of our attacks and the existing attacks for both random
and unpopular target items on two datasets. First, both our
attack and the existing attacks can increase the hit ratio of
target items notably. For instance, our method increases the
hit ratio of random target items by about 22.8 times compared
to the initial hit ratio when the attack size is 5% on the Music
dataset.
12
Second, our method shows the best transferring effective-
ness in most situations, which means that our method has
better transferability than the existing attacks. For example,
our attack achieves the highest hit ratio of random target
items, i.e., 0.0150, with an attack size of 5% on the ML-100K
dataset, which is about 1.6 times of the best performance of
the baseline attacks. Similarly, on the Music dataset, our attack
increases the hit ratio of unpopular target items from 0.0001 to
0.0184 by injecting 5% fake users, while the existing attacks
obtain the highest hit ratio of 0.0101, which is 54.9% of ours.
Third, similar to the results under the white-box setting,
we can observe that the increase of the hit ratio on the Music
dataset is more notable than that on the ML-100K dataset. For
instance, with an attack size of 5% on random target items, our
attacks can increase the hit ratio by around 22.8 times and 5.5
times on the Music and the ML-100K datasets, respectively,
compared with the corresponding initial hit ratios. The reason
is that the Music dataset is more sparse, which makes the
recommender systems trained on it less stable and easier to be
compromised.
In summary, our attack achieves a better transferability
than the baseline attacks, which means that our attack poses a
greater threat to unknown target recommender systems.
VI. DETECTING FAKE USERS
In this section, we evaluate the effectiveness of the attack
under a detector built upon rating scores. Detecting fake users
is also known as Sybil detection. Many methods have been
proposed for Sybil detection. These methods leverage user
registration information [48], user-generated content [3], [44],
and/or social graphs between users [9], [16], [24], [41]–[43],
[47]. Since we have no access to users’ registration information
and social graphs, similar to [13], we utilize a detection method
based on user-generated content, i.e., the ratings of users on
items. We extract useful features from the datasets and generate
certain feature values for each user. We train a fake user
classiﬁer for each poisoning attack to detect fake users. We
will study the effectiveness of the poisoning attacks when the
recommender system has deployed such a detector.
Rating Score Based Detection. Similar to the existing de-
fenses [7], [13], [32] that leverage several statistical features
from rating scores to distinguish normal users from fake users,
we adopt these features to train our detection classiﬁers. The
details of these features are described as follows.
•
Rating Deviation from Mean Agreement (RDMA) [7].
The feature indicates the average deviation of rating
scores of a user to the mean rating scores of the
corresponding items, which is computed as follows
for a user u:
RDMAu = (cid:80)i∈Iu
ci
|yui−y(i)|
| Iu |
(9)
where Iu is the set of items that user u has rated, | Iu |
is the number of items in Iu , yui is user u’s ratings
score for item i, y(i) is the average rating score of
,
TABLE V: HR@10 under the transferability setting.
Attack size
Dataset
Attack
Random target items
Unpopular target items
None
Random
ML-100K
Bandwagon
MF
Our attack
None
Random
Music
Bandwagon
MF
Our attack
0.5%
0.0023