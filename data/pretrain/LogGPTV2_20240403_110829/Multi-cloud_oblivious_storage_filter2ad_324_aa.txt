# Multi-Cloud Oblivious Storage

**Authors:**
- Emil Stefanov, UC Berkeley (Email: [EMAIL])
- Elaine Shi, University of Maryland (Email: [EMAIL])

## Abstract
We present a 2-cloud oblivious storage (ORAM) system that achieves a 2.6X bandwidth cost between the client and the cloud. By distributing an ORAM across two or more non-colluding clouds, we can reduce the client-cloud bandwidth cost by at least one order of magnitude, shifting the higher-bandwidth communication to inter-cloud links where bandwidth is abundant. This approach makes ORAM practical for bandwidth-constrained clients, such as those using home or mobile Internet connections. We provide a full-fledged implementation of our 2-cloud ORAM system and report results from a real-world deployment over Amazon EC2 and Microsoft Azure.

## Categories and Subject Descriptors
K.6.5 [Management of Computing and Information Systems]: Security and Protection

## General Terms
- Algorithms
- Security

## Keywords
- Oblivious RAM
- Outsourced Storage
- Multi-Cloud
- Privacy

## 1. Introduction
Storage outsourcing is a growing industry that relieves users from the burden of in-house infrastructure maintenance and offers economies of scale. However, concerns over data privacy have limited its adoption. Many potential cloud users are hesitant to store sensitive data in the cloud, often only placing less critical information there [8]. Encryption alone is insufficient for ensuring data privacy, as access patterns can leak sensitive information. For example, Islam et al. demonstrated statistical attacks that could infer about 80% of search queries made to an encrypted email repository by analyzing access patterns [18].

### 1.1 Two-Cloud ORAM
We observe that while client-cloud bandwidth is often scarce, especially in settings like cellular networks or slower home Internet connections, the network bandwidth between major cloud providers (e.g., Amazon Web Services and Microsoft Azure) is ample. By spreading data across multiple non-colluding cloud providers, we can shift the high bandwidth cost (typically 20X - 35X) to inter-cloud communication, while keeping the client-cloud bandwidth cost minimal—about 2.6X under typical parameters, with 2X necessary to hide whether each access is a read or write.

While the idea of using multiple non-colluding clouds is intuitive, designing a provably secure and practically efficient scheme is challenging. The main challenge is to avoid passing data through the client during shuffling while ensuring security against a potentially malicious cloud. Our solution involves letting the two clouds shuffle the data among themselves. One cloud shuffles the data blocks, adds an "onion" layer of encryption, and sends them to the other cloud. In this way, one cloud observes the permutation, and the other observes the accesses, but neither observes both. In the next round, the roles are switched.

To enforce honest behavior, we design a novel commutative checksum-encryption construction. The client shares a secret checksum function with each cloud, allowing the clouds to monitor each other's actions. After each shuffle, about 4λ checksum bits per block are transferred between the client and the clouds, enabling the client to verify the correctness of the shuffle. This reduces the cost of transferring entire blocks to the client during shuffling from 20X-35X to 0.1X to 0.2X (out of a total of 2.6X).

Our 2-cloud ORAM scheme requires the client to store less than 1.5GB of data for an ORAM of 1TB capacity (less than 0.15% of the ORAM capacity). This includes caching about \(O(\sqrt{N})\) data blocks and storing about 4 bytes of metadata per block. The metadata size is typically comparable to or smaller than the cached data blocks. With suitable modifications, it is possible to achieve sublinear client storage, but this is rarely necessary in practice.

In addition to minimizing client-cloud bandwidth consumption, our 2-cloud ORAM scheme roughly halves the total bandwidth consumption (including inter-cloud and client-cloud communication) compared to single-cloud counterparts [31].

### Threat Model
We assume that at least one cloud provider is honest and faithfully executes the protocol. The other cloud may be malicious and deviate from the protocol. We do not know in advance which cloud is malicious. Our goal is not to prevent DoS attacks, which are outside the scope of this work. We also cannot prevent a malicious cloud from divulging its local states and views to the honest cloud, potentially allowing the honest cloud to learn additional information. However, we guarantee that as long as there is at least one honest cloud, a malicious cloud cannot learn any information about the client's logical access patterns. Any deviation from the protocol is immediately detectable by the client, and a malicious cloud will be caught if it deviates.

This security model is generalized to the k-cloud setting (where only one out of k clouds needs to be honest) and formally defined using a simulation-based definition in the full online version [29]. We prove that our constructions are secure under this simulation-based definition in the full online version [29].

## 2. Preliminaries
Our algorithm depends on the partitioning framework and the partition ORAM construction proposed by Stefanov, Shi, and Song [31], referred to as the SSS construction. Below, we provide a brief background on the SSS construction.

### 2.1 Partitioning Framework
The SSS partitioning framework [31] allows us to securely break up ORAM read/write operations into read/write operations over smaller partitions, where each partition is an ORAM itself. The framework consists of two main techniques: partitioning and eviction.

Through partitioning, a larger ORAM instance of capacity \(N\) is divided into \(O(\sqrt{N})\) smaller ORAM instances (partitions), each with a capacity of \(O(\sqrt{N})\). While naive partitioning can break security, Stefanov et al. [31] propose a novel approach to allow partitioning without compromising security.

Figure 1 illustrates the partitioning framework. At any point in time, a block resides in a random partition. The client stores a position map to keep track of which partition each block resides in. To access a block with identifier \(u\), the client first looks up the position map to determine the current partition \(p\) of block \(u\). Then, the client issues an ORAM read operation to partition \(p\) and looks up block \(u\). On fetching the block from the server, the client logically assigns it to a freshly chosen random partition without writing the block to the server immediately. Instead, this block is temporarily cached in the client's local eviction cache.

```plaintext
// The SSS partitioning framework [31]
// Divide the ORAM into O(√N) partitions of size O(√N).
Read(u):
- Look up position map and determine that u is assigned to partition p.
- If u is not found in eviction caches:
  - ReadPartition(p, u)
- Else if u is found in local eviction caches:
  - ReadPartition(p, ⊥) // read dummy
- Pick a random partition p', add the block identified by u to the eviction caches, and logically assign u to partition p'.
- Call Evict ν times where ν > 1 is the eviction rate.

Write(u, B):
- Same as Read(u), except that the block written to the eviction cache is replaced with the new block.

Evict:
- Pick a random partition p.
- If a block B exists in the eviction cache assigned to partition p, call WritePartition(p, B).
- Else, call WritePartition(p, ⊥), where ⊥ represents a dummy block.
```

Figure 1: The SSS partitioning framework [31]. Our construction uses this framework to express ORAM Read and Write operations.