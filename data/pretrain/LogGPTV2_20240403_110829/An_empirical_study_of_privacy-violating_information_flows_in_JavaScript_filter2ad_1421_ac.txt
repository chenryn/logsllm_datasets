proach to enforcing information ﬂow policies. Our imple-
mentation handles all of JavaScript including challenging
language features like prototypes, with-scoping, and higher-
order functions. Our implementation also incorporates sev-
eral subtle details pertaining to how taints can be stored
and propagated for unboxed objects, to which a taint ﬁeld
cannot be added. The naive strategy of boxing all objects
breaks several websites as several DOM API functions re-
quire unboxed objects as arguments. We refer the reader to
an accompanying technical report [15] for the details.
3.
IMPLEMENTATION AND PERFOR-
MANCE EVALUATION
This section presents our implementation of rewrite-based
information ﬂow framework for JavaScript in the Chrome
browser, and describes several experiments that quantify the
performance overhead of our approach.
Implementation We implement the rewriting function as
a C++ method (within Chrome) that is invoked on any
JavaScript code just before it gets sent into the V8 execu-
tion engine. Thus, our implementation rewrites every piece
of JavaScript including that which is loaded by 
tags, executed by eval or executed by changing the web
page via document.write. The TSET library is implemented
in pure JavaScript, and we modiﬁed the resource loader of
Chrome to insert the TSET library code into every JavaScript
program it accesses. The TSET library is inserted into each
web page as ordinary JavaScript using a  tag before
any other code is loaded. The ﬂow-enhanced Chrome can
run in normal mode or in taint tracking mode. When the
taint tracking is on, the modiﬁed Chrome tracks the taint
ﬂow as a user surfs on websites.
Optimizations We describe the three most important op-
timizations we performed for the “optimized” bar. The ﬁrst
and most important optimization is that we implemented
the two most frequently executed TSET methods using 65
lines of C++, namely the methods for taint lookup and un-
boxing. Second, in the TSET.direct stack, when there is a
pop followed by a push, and just before the pop there are
no taints stored at the top of the stack, we cache the object
at the top of the stack before poping, and then reuse that
same object at the next push, thus avoiding having to create
a new object. Because the push is called on every assign-
ment, removing the object creation provides a signiﬁcant
275Site and rank
1. google
2. yahoo
3. facebook
4. youtube
5. myspace
6. wikipedia
7. bing
8. blogger
9. ebay
10. craigslist
11. amazon
12. msn
13. twitter
14. aol
15. go
−. Average
Total
KLOC
1.8
7.4
9.1
7.5
12.2
<0.1
0.7
1.8
13.6
0
5.3
7.3
5.6
12.7
1.1
8.2
d
-
-
-
0
9.1
9.1
7.3
5.7
-
8.6
-
-
-
-
-
0
-
12.9
-
-
-
-
6.1
5.6
-
1.3
- <0.1
-
3.0
0.2
4.5
0
7.0
9.1
7.3
11.9
0
0
1.1
13.4
0
4.8
6.7
5.5
9.6
0.9
6.1
Other KLOC
s
w
# Taint Val(k)
s
w
d
s
0
29.5
12.4
21.0
35.3
0
0
0.8
244.9
0
40.1
462.4
48.2
129.8
76.3
63.1
-
-
9.3
20.7
-
-
-
-
-
-
-
462.3
-
-
2.0
52.7
Cookie
d w s
Location
d w
- × × × × × ×
0 × × × × × ×
8.4 × × × × × ×
20.7 (cid:88) (cid:88) (cid:88) × × ×
28.4 (cid:88) (cid:88) (cid:88) × × ×
- × × × × × ×
- × × × × × ×
0.2 (cid:88) (cid:88) × × × ×
244.9 (cid:88) (cid:88) (cid:88) × × ×
- × × × × × ×
- × × × × × ×
462.3 (cid:88) × × × × ×
38.3 × × × × × ×
60.9 (cid:88) (cid:88) × × × ×
- (cid:88) × × × × ×
0
35.9
17
48
38
0
0
Figure 3: Flow results for a subset of the Alexa global 100 (last row summarizes results for all 100 sites).
savings. Third, we also cache ﬁeld reads in our optimized
TSET library. For example, whenever a property a.b is refer-
enced several times in the library, we store the value of the
property in a temporary variable and reuse the value again.
This produces signiﬁcant savings, despite the fact that all
our measurements used the JIT compiler of the V8 engine.
Benchmarks We employ a set of stress experiments us-
ing the standard cookie conﬁdentiality and location integrity
policies to evaluate the eﬃciency of our approach and the
eﬀect of optimizations. These policies require a signiﬁcant
amount of taint propagation, as the cookie and location
properties are heavily accessed. As our benchmarks, we use
the front pages on the websites from the latest Alexa global
top 100 list. Alexa is a company which ranks websites based
on traﬃc. The websites on the Alexa global top 100 vary
widely in size and how heavily they use JavaScript, from 0.1
KLOC to 31.6 KLOC of JavaScript code. We successfully
ran our dynamic analysis on all of the pages of Alexa global
top 100 list, and we visited many of them manually to make
sure that they function properly.
3.1 Policies
To measure eﬃciency, we checked two important policies
on each site. First, document.cookie should remain conﬁ-
dential to the site. Second, document.location should not
be inﬂuenced by another site. Both policies depend on a
deﬁnition of what “another site” is. Unfortunately, using ex-
actly the same URL or domain name often leads to many
false alarms as what looks like a single website is in fact the
agglomeration of several diﬀerent domain names. For ex-
ample, facebook.com refers to fbcdn.net for many of their
major resources, including JavaScript code. Moreover, there
are relatively well known and safe websites for traﬃc statis-
tics and advertisements, which are referenced on many other
websites, and one may want to consider those as safe. Thus,
we considered three URL policies (i.e., three deﬁnitions for
“another site”) (1) the same-origin policy stating that any
website whose hostname is diﬀerent from the hostname of
the current one is considered a diﬀerent site. (2) the same-
domain policy, which is the same as the same-origin policy,
except that websites from the same domain are considered
to be the same (e.g., ads.cnn.com is considered the same as
www.cnn.com). (3) the white-list policy, which is the same
as the same-domain policy, except that there is a global
list of common websites that are considered the same as
the source website. For our experiments, we treat websites
referenced by three or more diﬀerent Alexa benchmarks as
safe. The white-list mainly consists of statistics and adver-
tisement websites. We use a whitelist only to evaluate the
performance of our system under such conditions; we leave
the exact criteria for trusting a given third-party site to fu-
ture work. Our rewriting framework makes it trivial to con-
sider diﬀerent URL policies; we need only alter the notion of
URL equality in the checks done inside TSET.boxAndTaint
and TSET.check.
Detected Flows Figure 3 shows the results of running our
dynamic information framework on the Alexa global top 100
list using the above policies. Because of space constraints,
we only show a subset of the benchmarks, but the average
row is for all 100 benchmarks.
The columns in the table are as follows: “Site and rank” is
the name of the website and its rank in the Alexa global 100
list; “Total KLOC” is the number of lines of JavaScript code
on each website, including code from other sites, as format-
ted by our pretty printer; “Other KLOC” is the number of
lines of code from other sites; “# Taint Val” is the number
of dynamically created taint values; “Cookie” describes the
document.cookie conﬁdentiality policy, and “Location” de-
scribes the document.location integrity policy: (cid:88)indicates
policy violation, and ×indicates no ﬂow i.e., policy satisfac-
tion.
The above columns are sub-categorized into three sub-
columns depending on the applied URL policy: “s” is for the
same-origin policy; “d” is for the same-domain policy; “w”
is for the white-list policy. A dash in a table entry means
that the value for that table entry is the same as the entry
immediately to its left.
The code for each website changes on each visit. Thus, we
ran our enhanced Chrome 10 times on each website. To gain
conﬁdence in our tool, we manually inspected every program
on which a ﬂow is detected, and conﬁrmed that every ﬂow
was indeed real.
Variation based on URL policies The number of lines of
code from other sites decreases as we move from the same-
origin policy to the same-domain policy to the white-list
policy. Note that in some cases, for example facebook, code
from other sites is almost the same as the total lines of code.
276Figure 4: Slowdown for JavaScript (left) and Page Loading (right)
This is because most of the JavaScript code for facebook
comes from a website fbcdn.net. This website is not in
the same domain as facebook, and it is only referenced by
one website and hence, not included in our whitelist.
In
such situations, a site-speciﬁc white-list would help, but we
have not added such white-lists because it would be diﬃcult
for us to systematically decide for all 100 benchmarks what
these white-lists should be. Thus, as we do not use site-
speciﬁc white-lists, our policy violations may not correspond
to undesirable ﬂows.
As the amount of other-site code decreases as we move
from “s” to “d” to “w”, the number of dynamically created
taint values also decreases, at about the same rate. That
is, a large drop in other-site code leads to a correspondingly
large drop in the number of taint values created. Moreover,
as expected, the number of policy violations also decreases,
as shown on the last line of the table: the violations of the
document.cookie policies goes from 48 to 38 to 17. We did
not see a violation of the document.location policy in any
of our benchmarks.
3.2 Timing Measurements
Our rewrite-based information ﬂow technique performs
taint-tracking dynamically, and so it is important to eval-
uate the performance overhead of our approach. We mea-
sure performance using two metrics: total page load time,
and JavaScript run time. We modiﬁed the Chrome browser
to allow us to measure for each website (1) the time
spent executing JavaScript on the site, and (2) the to-
tal time spent to download and display the site. Fig-
ures 4 describes our timing measurements for JavaScript
time, and total download time on the 10 benchmarks with
the largest JavaScript code bases. The measurements were
performed while tracking both the document.cookie conﬁ-
dentiality and document.location integrity policies. The
“average” benchmark represents the average time over all
10 benchmarks. For each benchmark there are ﬁve bars
which represent running time, so smaller bars mean faster
execution. For each benchmark, the 5 bars are normal-
ized to the time for the unmodiﬁed Chrome browser for
that benchmark. Above each benchmark we display the
time in milliseconds for the unmodiﬁed Chrome browser
(which indicates what “1” means for that benchmark). The
left most bar “not-optimized” represents our technique us-
ing the original version of our TSET library, and using the
same-origin URL policy. For the remaining bars, each
bar represents a single change from the bar immediately
to its left: “optimized” uses a hand-optimized version of
our TSET library, rather than the original version; “dmn”
changes the URL policy to same-domain; “whlist” changes
the URL policy to white-list; and “trust-all” changes the
URL policy to the trivial policy where all websites are
trusted.