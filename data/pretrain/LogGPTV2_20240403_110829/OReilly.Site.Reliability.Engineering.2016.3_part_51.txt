• A user of Fred’s service raises the priority of a ticket that’s been assigned to him
since last week, when he was on-call.
• A flag rollout that’s rolling out over 3–4 weeks and is assigned to Fred goes
wrong, forcing Fred to drop everything to examine the rollout, roll back the
change, and so forth.
• A user of Fred’s service contacts Fred to ask a question, because Fred is such a
helpful chap.
• And so on.
The end result is that even though Fred has the entire calendar day free to work on
projects, he remains extremely distractible. Some of these distractions he can manage
himself by closing email, turning off IM, or taking other similar measures. Some dis‐
tractions are caused by policy, or by assumptions around interrupts and ongoing
responsibilities.
You can claim that some level of distraction is inevitable and by design. This assump‐
tion is correct: people do hang onto bugs for which they’re the primary contact, and
people also build up other responsibilities and obligations. However, there are ways
that a team can manage interrupt response so that more people (on average) can
come into work in the morning and feel undistractible.
Polarizing time
In order to limit your distractibility, you should try to minimize context switches.
Some interrupts are inevitable. However, viewing an engineer as an interruptible unit
of work, whose context switches are free, is suboptimal if you want people to be
happy and productive. Assign a cost to context switches. A 20-minute interruption
while working on a project entails two context switches; realistically, this interruption
results in a loss of a couple hours of truly productive work. To avoid constant occur‐
Imperfect Machines | 411
rences of productivity loss, aim for polarized time between work styles, with each
work period lasting as long as possible. Ideally, this time period is a week, but a day or
even a half-day may be more practical. This strategy also fits in with the complemen‐
tary concept of make time [Gra09].
Polarizing time means that when a person comes into work each day, they should
know if they’re doing just project work or just interrupts. Polarizing their time in this
way means they get to concentrate for longer periods of time on the task at hand.
They don’t get stressed out because they’re being roped into tasks that drag them
away from the work they’re supposed to be doing.
Seriously, Tell Me What to Do
If the general model presented in this chapter doesn’t work for you, here are some
specific suggestions of components you can implement piecemeal.
General suggestions
For any given class of interrupt, if the volume of interrupts is too high for one person,
add another person. This concept most obviously applies to tickets, but can poten‐
tially apply to pages, too—the on-call can start bumping things to their secondary, or
downgrading pages to tickets.
On-call
The primary on-call engineer should focus solely on on-call work. If the pager is
quiet for your service, tickets or other interrupt-based work that can be abandoned
fairly quickly should be part of on-call duties. When an engineer is on-call for a week,
that week should be written off as far as project work is concerned. If a project is too
important to let slip by a week, that person shouldn’t be on-call. Escalate in order to
assign someone else to the on-call shift. A person should never be expected to be on-
call and also make progress on projects (or anything else with a high context switching
cost).
Secondary duties depend on how onerous those duties are. If the function of the sec‐
ondary is to back up the primary in the case of a fallthrough, then maybe you can
safely assume that the secondary can also accomplish project work. If someone other
than the secondary is assigned to handling tickets, consider merging the roles. If the
secondary is expected to actually help the primary in the case of high pager volume,
they should do interrupt work, too.
(Aside: You never run out of cleanup work. Your ticket count might be at zero, but
there is always documentation that needs updating, configs that need cleanup, etc.
Your future on-call engineers will thank you, and it means they’re less likely to inter‐
rupt you during your precious make time).
412 | Chapter 29: Dealing with Interrupts
Tickets
If you currently assign tickets randomly to victims on your team, stop. Doing so is
extremely disrespectful of your team’s time, and works completely counter to the
principle of not being interruptible as much as possible.
Tickets should be a full-time role, for an amount of time that’s manageable for a per‐
son. If you happen to be in the unenviable position of having more tickets than can
be closed by the primary and secondary on-call engineers combined, then structure
your ticket rotation to have two people handling tickets at any given time. Don’t
spread the load across the entire team. People are not machines, and you’re just caus‐
ing context switches that impact valuable flow time.
Ongoing responsibilities
As much as possible, define roles that let anyone on the team take up the mantle. If
there’s a well-defined procedure for performing and verifying pushes or flag flips,
then there’s no reason a person has to shepherd that change for its entire lifetime,
even after they stop being on-call or on interrupts. Define a push manager role who
can juggle pushes for the duration of their time on-call or on interrupts. Formalize
the handover process—it’s a small price to pay for uninterrupted make time for the
people not on-call.
Be on interrupts, or don’t be
Sometimes when a person isn’t on interrupts, the team receives an interrupt that the
person is uniquely qualified to handle. While ideally this scenario should never hap‐
pen, it sometimes does. You should work to make such occurrences rare.
Sometimes people work on tickets when they’re not assigned to handle tickets
because it’s an easy way to look busy. Such behavior isn’t helpful. It means the person
is less effective than they should be. They skew the numbers in terms of how manage‐
able the ticket load is. If one person is assigned to tickets, but two or three other peo‐
ple also take a stab at the ticket queue, you might still have an unmanageable ticket
queue even though you don’t realize it.
Reducing Interrupts
Your team’s interrupt load may be unmanageable if it requires too many team mem‐
bers to simultaneously staff interrupts at any given time. There are a number of tech‐
niques you can use to reduce your ticket load overall.
Actually analyze tickets
Lots of ticket rotations or on-call rotations function like a gauntlet. This is especially
true of rotations on larger teams. If you’re only on interrupts every couple of months,
Imperfect Machines | 413
it’s easy to run the gauntlet,2 heave a sigh of relief, and then return to your regular
duties. Your successor then does the same, and the root causes of tickets are never
investigated. Rather than achieving forward movement, your team is bogged down by
a succession of people getting annoyed by the same issues.
There should be a handoff for tickets, as well as for on-call work. A handoff process
maintains shared state between ticket handlers as responsibility switches over. Even
some basic introspection into the root causes of interrupts can provide good solutions
for reducing the overall rate. Lots of teams conduct on-call handoffs and page
reviews. Very few teams do the same for tickets.
Your team should conduct a regular scrub for tickets and pages, in which you exam‐
ine classes of interrupts to see if you can identify a root cause. If you think the root
cause is fixable in a reasonable amount of time, then silence the interrupts until the
root cause is expected to be fixed. Doing so provides relief for the person handling
interrupts and creates a handy deadline enforcement for the person fixing the root
cause.
Respect yourself, as well as your customers
This maxim applies more to user interrupts than automated interrupts, although the
principles stand for both scenarios. If tickets are particularly annoying or onerous to
resolve, you can effectively use policy to mitigate the burden.
Remember:
• Your team sets the level of service provided by your service.
• It’s OK to push back some of the effort onto your customers.
If your team is responsible for handling tickets or interrupts for customers, you can
often use policy to make your work load more manageable. A policy fix can be tem‐
porary or permanent, depending on what makes sense. Such a fix should strike a
good balance between respect for the customer and respect for yourself. Policy can be
as powerful a tool as code.
For example, if you support a particularly flaky tool that doesn’t have many developer
resources, and a small number of needy customers use it, consider other options.
Think about the value of the time you spend doing interrupts for this system, and if
you’re spending this time wisely. At some point, if you can’t get the attention you need
to fix the root cause of the problems causing interrupts, perhaps the component
you’re supporting isn’t that important. You should consider giving the pager back,
deprecating it, replacing it, or another strategy in this vein that might make sense.
2 See http://en.wikipedia.org/wiki/Running_the_gauntlet.
414 | Chapter 29: Dealing with Interrupts
If there are particular steps for an interrupt that are time-consuming or tricky, but
don’t require your privileges to accomplish, consider using policy to push the request
back to the requestor. For example, if people need to donate compute resources, pre‐
pare a code or config change or some similar step, and then instruct the customer to
execute that step and send it for your review. Remember that if the customer wants a
certain task to be accomplished, they should be prepared to spend some effort getting
what they want.
A caveat to the preceding solutions is that you need to find a balance between respect
for the customer and for yourself. Your guiding principle in constructing a strategy
for dealing with customer requests is that the request should be meaningful, be
rational, and provide all the information and legwork you need in order to fulfill the
request. In return, your response should be helpful and timely.
Imperfect Machines | 415
CHAPTER 30
Embedding an SRE to Recover from
Operational Overload
Written by Randall Bosetti
Edited by Diane Bates
It’s standard policy for Google’s SRE teams to evenly split their time between projects
and reactive ops work. In practice, this balance can be upset for months at a time by
an increase in the daily ticket volume. A burdensome amount of ops work is espe‐
cially dangerous because the SRE team might burn out or be unable to make progress
on project work. When a team must allocate a disproportionate amount of time to
resolving tickets at the cost of spending time improving the service, scalability and
reliability suffer.
One way to relieve this burden is to temporarily transfer an SRE into the overloaded
team. Once embedded in a team, the SRE focuses on improving the team’s practices
instead of simply helping the team empty the ticket queue. The SRE observes the
team’s daily routine and makes recommendations to improve their practices. This
consultation gives the team a fresh perspective on its routines that team members
can’t provide for themselves.
When you are using this approach, it isn’t necessary to transfer more than one engi‐
neer. Two SREs don’t necessarily produce better results and may actually cause prob‐
lems if the team reacts defensively.
If you are starting your first SRE team, the approach outlined in this chapter will help
you to avoid turning into an operation team solely focused on a ticket rotation. If you
decide to embed yourself or one of your reports in a team, take time to review SRE
practices and philosophy in Ben Treynor Sloss’s introduction and the material on
monitoring in Chapter 6.
The following sections provide guidance to the SRE who will be embedded on a team.
417
Phase 1: Learn the Service and Get Context
Your job while embedded with the team is to articulate why processes and habits con‐
tribute to, or detract from, the service’s scalability. Remind the team that more tickets
should not require more SREs: the goal of the SRE model is to only introduce more
humans as more complexity is added to the system. Instead, try to draw attention to
how healthy work habits reduce the time spent on tickets. Doing so is as important as
pointing out missed opportunities for automation or simplification of the service.
Ops Mode Versus Nonlinear Scaling
The term ops mode refers to a certain method of keeping a service running. Various
work items increase with the size of the service. For example, a service needs a way to
increase the number of configured virtual machines (VMs) as it grows. A team in ops
mode responds by having a greater number of administrators managing those VMs.
SRE instead focuses on writing software or eliminating scalability concerns so that the
number of people required to run a service doesn’t increase as a function of load on
the service.
Teams sliding into ops mode might be convinced that scale doesn’t matter for them
(“my service is tiny”). Shadow an on-call session to determine whether the assess‐
ment is true, because the element of scale affects your strategy.
If the primary service is important to the business but actually is tiny (entailing few
resources or low complexity), put more focus on ways in which the team’s current
approach prevents them from improving the service’s reliability. Remember that your
job is to make the service work, not to shield the development team from alerts.
On the other hand, if the service is just getting started, focus on ways to prepare the
team for explosive growth. A 100 request/second service can turn into a 10k request/
second service in a year.
Identify the Largest Sources of Stress
SRE teams sometimes fall into ops mode because they focus on how to quickly
address emergencies instead of how to reduce the number of emergencies. A default
to ops mode usually happens in response to an overwhelming pressure, real or imag‐
ined. After you’ve learned enough about the service to ask hard questions about its
design and deployment, spend some time prioritizing various service outages accord‐
ing to their impact on the team’s stress levels. Keep in mind that, due to the team’s
perspective and history, some very small problems or outages may produce an inor‐
dinate amount of stress.
418 | Chapter 30: Embedding an SRE to Recover from Operational Overload
Identify Kindling
Once you identify a team’s largest existing problems, move on to emergencies waiting
to happen. Sometimes impending emergencies come in the form of a new subsystem
that isn’t designed to be self-managing. Other sources include:
Knowledge gaps
In large teams, people can overspecialize without immediate consequence. When
a person specializes, they run the risk of either not having the broad knowledge
they need to perform on-call support or allowing team members to ignore the
critical pieces of the system that they own.
Services developed by SRE that are quietly increasing in importance
These services often don’t get the same careful attention as new feature launches
because they’re smaller in scale and implicitly endorsed by at least one SRE.
Strong dependence on “the next big thing”
People might ignore problems for months at a time because they believe the new
solution that’s on the horizon obviates temporary fixes.
Common alerts that aren’t diagnosed by either the dev team or SREs
Such alerts are frequently triaged as transient, but still distract your teammates
from fixing real problems. Either investigate such alerts fully, or fix the alerting
rules.
Any service that is both the subject of complaints from your clients and lacks a formal
SLI/SLO/SLA
See Chapter 4 for a discussion of SLIs, SLOs, and SLAs.
Any service with a capacity plan that is effectively “Add more servers: our servers were
running out of memory last night”
Capacity plans should be sufficiently forward-looking. If your system model pre‐
dicts that servers need 2 GB, a loadtest that passes in the short term (revealing
1.99 GB in its last run) doesn’t necessarily mean that your system capacity is in
adequate shape.
Postmortems that only have action items for rolling back the specific changes that caused
an outage
For example, “Change the streaming timeout back to 60 seconds,” instead of “Fig‐
ure out why it sometimes takes 60 seconds to fetch the first megabyte of our
promo videos.”
Any serving-critical component for which the existing SREs respond to questions by say‐
ing, “We don’t know anything about that; the devs own it”
To give acceptable on-call support for a component, you should at least know the
consequences when it breaks and the urgency needed to fix problems.
Phase 1: Learn the Service and Get Context | 419
Phase 2: Sharing Context
After scoping the dynamics and pain points of the team, lay the groundwork for
improvement through best practices like postmortems and by identifying sources of
toil and how to best address them.
Write a Good Postmortem for the Team
Postmortems offer much insight into a team’s collective reasoning. Postmortems con‐
ducted by unhealthy teams are often ineffectual. Some team members might consider
postmortems punitive, or even useless. While you might be tempted to review the
postmortem archives and leave comments for improvement, doing so doesn’t help the
team. Instead, the exercise might put the team on the defensive.
Instead of trying to correct previous mistakes, take ownership of the next postmor‐
tem. There will be an outage while you’re embedded. If you aren’t the person on-call,
team up with the on-call SRE to write a great, blameless postmortem. This document
is an opportunity to demonstrate how a shift toward the SRE model benefits the team
by making bug fixes more permanent. More permanent bug fixes reduce the impact
of outages on team members’ time.
As mentioned, you might encounter responses such as “Why me?” This response is
especially likely when a team believes that the postmortem process is retaliatory. This
attitude comes from subscribing to the Bad Apple Theory: the system is working fine,
and if we get rid of all the bad apples and their mistakes, the system will continue to
be fine. The Bad Apple Theory is demonstrably false, as shown by evidence [Dek14]
from several disciplines, including airline safety. You should point out this falsity. The