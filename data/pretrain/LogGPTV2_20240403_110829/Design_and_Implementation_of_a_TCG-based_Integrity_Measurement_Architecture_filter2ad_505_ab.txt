### Dynamic Loader and Executable Code

The dynamic loader is responsible for loading various executables and libraries into the system. On our experimental setup, these include:

- **Apache Server** (e.g., `apachectl`, `httpd`)
- **Apache Modules** (e.g., `mod_access.so`, `mod_auth.so`, `mod_cgi.so`)
- **Tomcat Servlet Container** (e.g., `startup.sh`, `catalina.sh`, `java`)
- **Dynamic Libraries** (e.g., `libjvm.so`, `libcore.so`, `libjava.so`, `libc-2.3.2.so`, `libssl.so.4`)

All of this code can impact system integrity, making it essential to measure and verify it. The kernel detects when executable code is loaded because the related files are memory-mapped with the executable flag. However, the kernel cannot recognize kernel modules when they are loaded from the file system, as they are loaded by applications like `modprobe` or `insmod` and only become memory-mapped as executable after being loaded into memory. Additionally, the kernel does not detect when executable scripts are loaded into interpreters such as `bash`, as they are read as normal files.

### Application-Specific Files and Their Impact on System Integrity

Some other files loaded by the application itself also define its execution behavior. For example, Java class files that define servlets and web services must be measured because they are loaded by the Tomcat server to create dynamic content, such as shopping cart or payment pages. Configuration files, such as the startup files for Apache (`httpd.conf`) and Tomcat (startup scripts), may also alter the behavior of the web server. In our example system, these files include:

- **Apache Configuration File** (`httpd.conf`)
- **Java Virtual Machine Security Configuration** (`java.security`, `java.policy`)
- **Servlets and Web Services Libraries** (e.g., `axis.jar`, `servlet.jar`, `wsdl4j.jar`)

While each of these files may have standard contents that can be identified, it is challenging to determine which files are actually used by an application and for what purpose. Even if `httpd.conf` has the expected contents, it may not be loaded as expected. For instance, Apache has a command-line option to load a different file, and file system links may result in a different file being loaded. Races between when the file is measured and when it is loaded can also occur. Therefore, a Tripwire-like measurement of key system files is insufficient, as the users of the attesting system (attestors) may change the files that determine its integrity, and these users are not necessarily trusted by the challengers. As with the dynamic loader, the integrity impact of opening a file is only known to the requesting program. However, unlike the dynamic loader case, determining the integrity impact of application loads involves instrumenting many more programs, and these may have varying trust levels.

### Integrity of Unstructured Data

The integrity of the web server environment also depends on dynamic, unstructured data consumed by running executables. The key issue is that even if the application knows this data can impact its integrity, its measurement is useless because the challenger cannot predict values that would preserve integrity. In the web server example, the key dynamic data includes:

1. **Requests from Remote Clients, Administrators, and Other Servlets**
2. **Database of Book Orders**

The things that need to be determined include whether order data or administrator commands can be modified only by high-integrity programs (i.e., Biba) and whether low-integrity requests can be converted to high-integrity data or rejected (i.e., Clark-Wilson). Sealed storage is insufficient to ensure the first property, and information flow based on mandatory policy is generally necessary. Enforcing the second property requires trusted upgraders or trust in the application itself.

### Measuring Systems for Integrity Verification

Based on the analysis of the web server example, we list the types of tasks that must be accomplished to achieve a Clark-Wilson level of integrity verification:

- **Verification Scope**: Unless information flows among processes are under a mandatory restriction, the integrity of all processes must be measured. Otherwise, the scope of integrity impacting a process may be reduced to only those processes upon which it depends for high-integrity code and data.
- **Executable Content**: For each process, all code executed must be of sufficient integrity, regardless of whether it is loaded by the operating system, dynamic loader, or application.
- **Structured Data**: For each process, data whose content has identifiable integrity semantics may be treated in the same manner as executable content. However, we must capture the data that is actually loaded by the operating system, dynamic loaders, and applications.
- **Unstructured Data**: For each process, the data whose content does not have identifiable integrity semantics, the integrity of the data is dependent on the integrity of the processes that have modified it or the integrity may be upgraded by explicit upgrade processes or this process (if it is qualified to be a transformation procedure in the Clark-Wilson sense).

For systems using discretionary policy (e.g., NGSCB), the integrity of all processes must be measured because all can impact each other. We must measure all code, including modules, libraries, and code loaded ad hoc by applications, to verify the integrity of an individual process. Some data may have integrity semantics similar to code and can be treated similarly. Dynamic data cannot be verified as code, so data history, security policy, etc., are necessary to determine its integrity. Challengers may assume that some code can handle low-integrity data as input. The lack of correct understanding about particular code's ability to handle low-integrity data is the source of many current security problems, so a clear identification of how low-integrity data is used is ultimately preferred.

### Ensuring Fresh and Complete Measurements

An essential part of our architecture is the ability of challengers to ensure that the measurement list is:

- **Fresh and Complete**: Includes all measurements up to the point in time when the attestation is executed.
- **Unchanged**: The fingerprints are truly from the loaded executable and static data files and have not been tampered with.

A corrupted attestor can try to cheat by truncating measurements or delivering changed measurements to hide the programs that have corrupted its state. Replaying old measurement lists is equivalent to hiding new measurements.

### Challenges and Practical Approach

This analysis indicates that integrity verification for a flexible systems environment is a difficult problem that requires several coordinated tasks. A more practical approach is to provide an extensible method that can identify some integrity bugs now and form a basis for constructing reasonable integrity verification in the future. This approach is motivated by recent work in static analysis, where tools are designed to find bugs and be extensible to finding more complex bugs in the future. Finding integrity bugs is useful for identifying code that needs patching, illegal information flows, or cases where low-integrity data is used without proper safeguards. For example, a challenger can verify that an attesting system is using high-integrity code for its current applications.

In this paper, we define operating systems support for measuring the integrity of code and structured data. The operating system ensures that the code loaded into every individual user-level process is measured, and this is used as a basis for applications to measure other code and data for which integrity semantics may be defined. Thus, our architecture ensures that the breadth of the system is measured (i.e., all user-level processes), but the depth of measurement (i.e., which things are subsequently loaded into the processes) is not complete, but it is extensible, such that further measurements to increase confidence in integrity are possible. At present, we do not measure mandatory access control policy, but the architecture supports extensions to include such measurements, and we are working on how to effectively use them.

### Related Work

Previous efforts to measure a system to improve its integrity and enable remote integrity verification include:

- **Secure Boot vs. Authenticated Boot**: Secure boot enables a system to measure its own integrity and terminate the boot process if an action compromises this integrity. The AEGIS system by Arbaugh provides a practical architecture for implementing secure boot on a PC system. It uses signed hash values to identify and validate each layer in the boot process. Secure boot does not enable a challenging party to verify the integrity of a boot process (i.e., authenticated boot) because it simply measures and checks the boot process but does not generate attestations of the integrity of the process.
- **IBM 4758 Secure Coprocessor**: Implements both secure boot and authenticated boot in a restricted environment. It verifies (flash) partitions before activating them and enforces valid signatures before loading executables into the system. Outgoing authentication enables attestation that links each subsequent layer to its predecessor. Only one application is allowed to run at a time to protect an application from flaws in other applications. Our web server example runs in a much more dynamic environment where multiple processes may access the same data and interact.
- **Trusted Computing Group (TCG)**: A consortium of companies that developed an open interface for a Trusted Platform Module (TPM), a hardware extension to systems that provides cryptographic functionality and protected storage. By default, the TPM enables the verification of static platform configurations, both in terms of content and order, by collecting a sequence of hashes over target code. Researchers have examined how a TPM can be used to prove that a system has booted a valid operating system. The integrity of applications running on the operating system is outside the scope of this work and is exactly where we look to expand the application of the TPM.
- **Marchesini et al.**: Describe an approach that uses signed trustworthy configurations to protect a system’s integrity. Such a configuration stores signatures of sensitive configuration files. An Enforcer checks the integrity of signed files in the configuration against the real file every time the real file is opened. The approach enforces integrity through TPM-sealing of long-lived server certificates and binding of the unsealing to a correct configuration.
- **Terra and Microsoft’s Next Generation Secure Computing Base (NGSCB)**: Both are based on the same hardware security architecture (TCG/TPM) and provide a "whole system solution" to authenticated boot. NGSCB partitions a platform into a trusted and untrusted part, each running its own operating system. Only the trusted portion is measured, limiting the flexibility of the approach. Terra is a trusted computing architecture built around a trusted virtual machine monitor that authenticates the software running in a VM for challenging parties. Terra tries to resolve the conflict between building trusted customized closed-box runtime environments and open systems that offer rich functionality and significant economies of scale but are difficult to trust due to their flexibility.

### Design of an Integrity Measurement Architecture

Our integrity measurement architecture consists of three major components:

- **Measurement Mechanism**: Determines what parts of the runtime environment to measure, when to measure, and how to securely maintain the measurements.
- **Integrity Challenge Mechanism**: Allows authorized challengers to retrieve measurement lists of a computing platform and verify their freshness and completeness.
- **Integrity Validation Mechanism**: Validates that the measurement list is complete, non-tampered, and fresh, as well as validating that all individual measurement entries of runtime components describe trustworthy code or configuration files.

Figure 2 shows how these mechanisms interact to enable remote attestation. Measurements are initiated by measurement agents, which induce a measurement of a file, store the measurement in an ordered list in the kernel, and report the extension of the measurement list to the TPM. The integrity challenge mechanism allows a remote challenger to request the measurement list together with the TPM-signed aggregate of the measurement list. Upon receiving such a challenge, the attesting system retrieves the signed aggregate from the TPM and the measurement list from the kernel.