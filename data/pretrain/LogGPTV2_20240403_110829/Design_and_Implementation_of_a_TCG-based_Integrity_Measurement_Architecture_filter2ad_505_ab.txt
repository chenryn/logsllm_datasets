are done by the dynamic loader. Executables include the fol-
lowing ﬁles on our experimental system:
• Apache server (apachectl, httpd, ... )
• Apache modules
(mod access.so,
mod auth.so,
mod cgi.so, ...)
• Tomcat servlet machine (startup.sh, catalina.sh, java, ...)
• Dynamic libraries (libjvm.so, libcore.so, libjava.so, libc-
2.3.2.so, libssl.so.4, ...)
All of this code impacts system integrity, so we need to mea-
sure them. The kernel knows when executable code is loaded
because the related ﬁle is memory-mapped by using the ex-
ecutable ﬂag. However, the kernel cannot recognize kernel
modules when they are loaded from the ﬁle system because
they are loaded by applications such as modprobe or ins-
mod and are memory-mapped as executable only after they
have been loaded into in memory. Finally, the kernel does
Kernel SpaceBasic Input Output System (BIOS)Linux GRUB Bootstrap LoaderLinux 2.6.5 System KernelKernelModules...User Spaceapachectrl, httpdStatic Data:- httpd.conf-  java.security/policy-  java classesLibrariesLibrariesLibraries/Unstructured / Dynamic Data:- Inter Process Communication- File / Network /User I|O- ...ExecutablesModulescatalina.sh, java e100.koautofs.koagpgart.kostartup.shnot know when executable scripts are loaded into interpreters
such as bash because they are read as normal ﬁles.
Some other ﬁles loaded by the application itself also de-
ﬁne its execution behavior. For example, the Java class ﬁles
that deﬁne servlets and web services must be measured be-
cause they are loaded by the Tomcat server to create dynamic
content, such as shopping cart or payment pages. Applica-
tion conﬁguration ﬁles, such as the startup ﬁles for Apache
(httpd.conf) and Tomcat (startup scripts) may also alter the
behavior of the Web server. These ﬁles in our example sys-
tem include:
• Apache conﬁguration ﬁle (httpd.conf)
• Java
virtual machine
(java.security, java.policy)
security
conﬁguration
• Servlets and web services libraries (axis.jar, servlet.jar,
wsdl4j.jar, ...)
While each of these ﬁles may have standard contents that
can be identiﬁed by the challenger, it is difﬁcult to determine
which ﬁles are actually being used by an application and for
what purpose. Even if http.conf has the expected con-
tents, it may not be loaded as expected. For example, Apache
has a command line option to load a different ﬁle, links in
the ﬁle system may result in a different ﬁle being loaded,
and races are possible between when the ﬁle is measured and
when it is loaded. Thus, a Tripwire-like [8] measurement of
the key system ﬁles is not sufﬁcient because the users of the
attesting system (attestors) may change the ﬁles that actually
determine its integrity, and these users are not necessarily
trusted by the challengers. As in the dynamic loader case,
the integrity impact of opening a ﬁle is only known to the re-
questing program. However, unlike the case for the dynamic
loader, the problem of determining the integrity impact of ap-
plication loads involves instrumentation of many more pro-
grams, and these may be of varying trust levels.
The integrity of the Web server environment also depends
on dynamic, unstructured data that is consumed by running
executables. The key issue is that even if the application
knows that this data can impact its integrity, its measurement
is useless because the challenger cannot predict values that
would preserve integrity. In the web server example, the key
dynamic data are: (1) the various kinds of requests from re-
mote clients, administrators, and other servlets and (2) the
database of book orders. The sorts of things that need to be
determined are whether the order data or administrator com-
mands can be modiﬁed only by high integrity programs (i.e.,
Biba) and whether the low integrity requests can be converted
to high integrity data or rejected (i.e., Clark-Wilson). Sealed
storage is insufﬁcient to ensure the ﬁrst property, informa-
tion ﬂow based on mandatory policy is necessary in general,
and enforcement of the second property requires trusted up-
graders or trust in the application itself.
2.3 Measuring Systems
Based on the analysis of the web server example, we list the
types of tasks that must be accomplished to achieve a Clark-
Wilson level of integrity veriﬁcation.
• Veriﬁcation Scope: Unless information ﬂows among
processes are under a mandatory restriction, the integrity
of all processes must be measured. Otherwise, the scope
of integrity impacting a process may be reduced to only
those processes upon which it depends for high integrity
code and data.
• Executable Content: For each process, all code ex-
ecuted must be of sufﬁcient
integrity regardless of
whether it is loaded by the operating system, dynamic
loader, or application.
• Structured Data: For each process, data whose content
has an identiﬁable integrity semantics may be treated in
the same manner as executable content above. How-
ever, we must be sure to capture the data that is actually
loaded by the operating system, dynamic loaders, and
applications.
• Unstructured Data: For each process, the data whose
content does not have an identiﬁable integrity semantics,
the integrity of the data is dependent on the integrity of
the processes that have modiﬁed it or the integrity may
be upgraded by explicit upgrade processes or this pro-
cess (if it is qualiﬁed to be a transformation procedure in
the Clark-Wilson sense).
The ﬁrst statement indicates that for systems that use dis-
cretionary policy (e.g., NGSCB), the integrity of all processes
must be measured because all can impact each other. Second,
we must measure all code including modules, libraries, and
code loaded in an ad hoc fashion by applications to verify the
integrity of an individual process. Third, some data may have
integrity semantics similar to code, such that it may be treated
that way. Fourth, dynamic data cannot be veriﬁed as code, so
data history, security policy, etc. are necessary to determine
its integrity. The challengers may assume that some code can
handle low integrity data as input. The lack of correct under-
standing about particular code’s ability to handle low integrity
data is the source of many current security problems, so we
would ultimately prefer a clear identiﬁcation of how low in-
tegrity data is used.
Further, an essential part of our architecture is the ability
of challengers to ensure that the measurement list is:
• fresh and complete, i.e., includes all measurements up to
the point in time when the attestation is executed,
• unchanged, i.e., the ﬁngerprints are truly from the loaded
executable and static data ﬁles and have not been tam-
pered with.
An attestor that has been corrupted can try to cheat by ei-
ther truncating measurements or delivering changed measure-
ments to hide the programs that have corrupted its state. Re-
playing old measurement lists is equivalent to hiding new
measurements.
This analysis indicates that integrity veriﬁcation for a ﬂex-
ible systems environment is a difﬁcult problem that requires
several coordinated tasks. Rather than tackle all problems at
once, a more practical approach is to provide an extensible
approach that can identify some integrity bugs now and form
a basis for constructing reasonable integrity veriﬁcation in the
future. This approach is motivated by the approach adopted
by static analysis researchers in recent work [9]. Rather than
proving the integrity of a program, these tools are designed
to ﬁnd bugs and be extensible to ﬁnding other, more com-
plex bugs in the future. Finding integrity bugs is also useful
for identifying that code needs to be patched, illegal informa-
tion ﬂows, or cases where low integrity data is used without
proper safeguards. For example, a challenger can verify that
an attesting system is using high integrity code for its current
applications.
In this paper, we deﬁne operating systems support for mea-
suring the integrity of code and structured data. The operat-
ing system ensures that the code loaded into every individ-
ual user-level process is measured, and this is used as a basis
for applications to measure other code and data for which in-
tegrity semantics may be deﬁned. Thus, our architecture en-
sures that the breadth of the system is measured (i.e., all user-
level processes), but the depth of measurement (i.e., which
things are subsequently loaded into the processes) is not com-
plete, but it is extensible, such that further measurements to
increase conﬁdence in integrity are possible. At present, we
do not measure mandatory access control policy, but the ar-
chitecture supports extensions to include such measurements
and we are working on how to effectively use them.
3 Related Work
Related work includes previous efforts to measure a system
to improve its integrity and/or enable remote integrity veriﬁ-
cation. The key issues in prior work are: (1) the distinction
between secure boot and authenticated boot and (2) the se-
mantic value of previous integrity measurement approaches.
Secure boot enables a system to measure its own integrity
and terminate the boot process if an action compromises this
integrity. The AEGIS system by Arbaugh [1] provides a prac-
tical architecture for implementing secure boot on a PC sys-
tem. It uses signed hash values to identify and validate each
layer in the boot process.
It will abort booting the system
if the hashes cannot be validated. Secure boot does not en-
able a challenging party to verify the integrity of a boot pro-
cess (i.e., authenticated boot) because it simply measures and
checks the boot process, but does not generate attestations of
the integrity of the process.
The IBM 4758 secure coprocessor [10] implements both
secure boot and authenticated boot, albeit in a restricted en-
vironment.
It promises secure boot guarantees by verify-
ing (ﬂash) partitions before activating them and by enforcing
valid signatures before loading executables into the system.
A mechanism called outgoing authentication [5] enables at-
testation that links each subsequent layer to its predecessor.
The predecessor attests to the subsequent layer by generating
a signed message that includes the cryptographic hash and the
public key of the subsequent layer. To protect an application
from ﬂaws in other applications, only one application is al-
lowed to run at a time. Thus, the integrity of the application
depends on hashes of the code and manual veriﬁcation of the
application’s installation data. This data is only accessible to
trusted code after installation. Our web server example runs
in a much more dynamic environment where multiple pro-
cesses may access the same data and may interact. Further,
the security requirements of the challenging party and the at-
testing party may differ such that secure boot based on the
challenging party’s requirements is impractical.
The Trusted Computing Group [11] is a consortium of
companies that together have developed an open interface for
a Trusted Platform Module, a hardware extension to systems
that provides cryptographic functionality and protected stor-
age. By default, the TPM enables the veriﬁcation of static
platform conﬁgurations, both in terms of content and order,
by collecting a sequence of hashes over target code. For ex-
ample, researchers have examined how a TPM can be used to
prove that a system has booted a valid operating system [12].
The integrity of applications running on the operating system
is outside the scope of this work and is exactly where we look
to expand the application of the TPM.
Marchesini et al. [13] describe an approach that uses signed
trustworthy conﬁgurations to protect a system’s integrity.
Such a conﬁguration stores signatures of sensitive conﬁgura-
tion ﬁles. A so-called Enforcer checks the integrity of signed
ﬁles in the conﬁguration against the real ﬁle every time the
real ﬁle is opened. The approach enforces integrity through
TPM- sealing of long-lived server certiﬁcates and binding
of the unsealing to a correct conﬁguration.
In this respect
the work is related to the platform conﬁgurations described
in [12]. None of the known existing work extends the mea-
surement of a software stack from the static boot conﬁgura-
tion seamlessly into the application level.
Terra [14] and Microsoft’s Next Generation Secure Com-
puting Base (NGSCB [7]) are based on the same hardware
security architecture (TCG/TPM) and are similar in provid-
ing a “whole system solution” to authenticated boot. NGSCB
partitions a platform into a trusted and untrusted part each of
which runs its own operating system. Only the trusted por-
tion is measured which limits the ﬂexibility of the approach
(not all programs of interest should be fully trusted) and it
depends on hardware and base software not yet available.
Terra is a trusted computing architecture that
is built
around a trusted virtual machine monitor that –among other
things– authenticates the software running in a VM for chal-
lenging parties. Terra tries to resolve the conﬂict between
building trusted customized closed-box run-time environ-
ments (e.g., IBM 4758) and open systems that offer rich func-
tionality and signiﬁcant economies of scale that, however, are
difﬁcult to trust because of their ﬂexibility. As such, Terra
tries to solve the same problem as we do, however in a very
different way. Terra measures the trusted virtual machine
monitor on the partition block level. Thus, on the one hand,
Terra produces about 20 Megabyte of measurement values
(i.e., hashes) when attesting an exemplary 4 Gigabyte VM
partition. On the other hand, because those measurements
are representative of blocks, it is difﬁcult to interpret varying
measurement values. Thus, our system measures selectively
those parts of the system that contribute to the dynamic run-
time system; it does so on a high level that is rich in semantics
and enables remote parties to interpret varying measurements
on a ﬁle level.
4 Design of an Integrity
Measurement Architecture
Our integrity Measurement architecture consists of three ma-
jor components:
• The Measurement Mechanism on the attested system de-
termines what parts of the run-time environment to mea-
sure, when to measure, and how to securely maintain the
measurements.
• An Integrity Challenge Mechanism that allows autho-
rized challengers to retrieve measurement lists of a com-
puting platform and verify their freshness and complete-
ness.
• An Integrity Validation Mechanism, validating that the
measurement list is complete, non-tampered, and fresh
as well as validating that all individual measurement en-
tries of runtime components describe trustworthy code
or conﬁguration ﬁles.
Figure 2 shows how these mechanisms interact to enable
remote attestation. Measurements are initiated by so-called
measurement agents, which induce a measurement of a ﬁle,
(a) store the measurement in an ordered list in the kernel, and
(b) report the extension of the measurement list to the TPM.
The integrity challenge mechanism allows remote chal-
lenger to request the measurement list together with the TPM-
signed aggregate of the measurement list (step 1 in Fig 2).
Receiving such a challenge, the attesting system ﬁrst retrieves
the signed aggregate from the TPM (steps 2 and 3 in Fig 2)
and afterwards the measurement list from the kernel (step 4