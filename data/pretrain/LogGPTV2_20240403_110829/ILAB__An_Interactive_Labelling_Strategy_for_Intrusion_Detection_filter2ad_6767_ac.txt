200
400
600
800
1,000
Num. Annotations
500
1,000
1,500
2,000
Num. Annotations
(a) Average Number of Families Discovered
1
C
U
A
n
a
e
M
0.95
0.9
1,000
0.85
0
Uncertainty
G¨ornitz et al.
Aladin
ILAB
1,500
Num. Annotations
1,000
2,000
500
40
30
20
10
s
e
i
l
i
m
a
F
.
m
u
N
n
a
e
M
0
0
1
0.95
0.9
0.85
C
U
A
n
a
e
M
0.8
0
200
600
400
800
Num. Annotations
(b) Average Detection performance (AUC) on the Validation Dataset
)
s
d
n
o
c
e
s
(
i
e
m
T
n
o
i
t
u
c
e
x
E
n
a
e
M
60
40
20
0
0
200
600
400
800
Num. Annotations
)
s
d
n
o
c
e
s
(
i
e
m
T
n
o
i
t
u
c
e
x
E
n
a
e
M
1,000
800
600
400
200
0
0
1,000
500
1,000
1,500
Num. Annotations
2,000
(c) Average Annotation Queries Generation Execution Time
Fig. 4. Comparison of the labelling strategies Contagio 10% (on the left) and NSL-
KDD 10% (on the right)
132
A. Beaugnon et al.
Families Detection. Figure 4a shows that uncertainty sampling and G¨ornitz et al.
labelling strategy miss many families during the annotation process. Both
labelling strategies suﬀer from sampling bias. G¨ornitz et al. labelling strategy
relies on k-nearest neighbours to detect yet unknown malicious families but only
close to the decision boundary, that is why many families further from the deci-
sion boundary are not discovered. Their strategy to foster the discovery of yet
unknown families is not eﬀective on both datasets.
ILAB dedicates only a part of its annotation budget to the detection of yet
unknown families, that is why Aladin detects slightly more families than ILAB.
ILAB queries some high likelihood instances which are unlikely to belong to new
families, but they allow to keep the detection performance increasing across the
iterations (see Fig. 4b).
ILAB and Aladin discover about as many families across the iterations on
both datasets. These labelling strategies are eﬀective at avoiding sampling bias.
They are designed to detect rare categories, and they are able to discover almost
all the families on both datasets.
Detection Performance. Figure 4b represents the evolution of the Area Under
the Curve (AUC) [16] on the validation dataset. It shows that ILAB performs
better than the other labelling strategies on both datasets.
G¨ornitz et al. labelling strategy performs very poorly on Contagio 10%.
The detection performance increases at the ﬁrst iteration, but then it keeps
on decreasing when new instances are added to the labelled dataset. This pecu-
liar behaviour can be explained by the simplicity of the SVDD detection model
which cannot discriminate the benign from the malicious instances properly.
The geometry of the data prevents SVDD from isolating the benign instances
from the malicious instances in a sphere. We notice the same behaviour less pro-
nounced on NSL-KDD 10%. A solution to address this issue is to train SVDD
with a kernel to increase the complexity of the model. However, this solution
will considerably increase the execution time which is already too high to ensure
a good expert-model interaction (see Fig. 4c).
labelling strategies.
G¨ornitz et al. labelling strategy performs much better initially on NSL-
KDD 10% than the other
to semi-
supervision, G¨ornitz et al. use not only the 20 initial labelled instances to train
their detection model, but also all the instances from the unlabelled pool. G¨ornitz
et al. semi-supervised detection model is, however, not as eﬀective as logistic
regression initially on Contagio 10%. SVDD makes the assumption that the
unlabelled instances are mostly benign, and so the malicious instances in the
unlabelled pool may damage the detection model performance.
Indeed,
thanks
Uncertainty sampling has a better detection performance than ILAB during
the ﬁrst iterations on NSL-KDD 10% because it allocates all its annotation bud-
get to reﬁning the decision boundary. On the contrary, ILAB dedicates 90% of
its annotation budget to rare category detection to avoid sampling bias. In the
end, uncertainty sampling suﬀers from sampling bias and converges to a poorer
performance.
ILAB: An Interactive Labelling Strategy for Intrusion Detection
133
The detection performance of uncertainty sampling and Aladin decreases dur-
ing the ﬁrst iterations on Contagio 10%. This undesirable behaviour is caused by
sampling bias: non-representative instances are queried for annotation, added to
the training dataset and prevent the detection model from generalizing properly.
Uncertainty sampling queries instances close to the decision boundary that are
hard to classify for the detection model, but not representative of the malicious
or benign behaviours. Aladin queries only uncertain and low likelihood instances
which are not necessarily representative of the malicious and benign behaviours
either. ILAB addresses this problem by dedicating a part of its annotation bud-
get to high likelihood instances to get representative examples of each family.
Therefore, the detection performance keeps on increasing across the iterations.
Scalability. Figure 4c depicts the query generation execution time (in seconds)
across the iterations. G¨ornitz et al. query generation algorithm is very slow. For
NSL-KDD 10%, the expert waits more than 10 min between each iteration while
the labelling strategy computes the annotation queries. A third of the execution
time corresponds to the computation of the semi-supervised SVDD model, and
the remaining two thirds corresponds to the k-nearest neighbour algorithm. The
execution time of G¨ornitz et al. labelling strategy is thus too high to ensure a
good expert-model interaction even on a dataset containing fewer than 100,000
instances.
ILAB has an execution time comparable to uncertainty sampling. For NSL-
KDD 10%, the expert waits less than 1 min between each iteration. On the
contrary, Aladin execution time increases drastically when new instances are
added to the labelled dataset and new families are discovered. Aladin runs rare
category detection on all the instances, while ILAB runs it on the malicious and
the benign instances separately. ILAB divide and conquer approach reduces the
execution time as running rare category detection twice on smaller datasets with
fewer families is faster than running it on the whole dataset. Aladin’s authors
were aware of this high execution time. During their experiments, the expert
was asked to annotate 1000 instances each day, and the new annotation queries
were computed every night. Their solution reduces the expert waiting time, but
it signiﬁcantly damages the expert-model interaction since the expert feedback
is integrated only once a day.
In conclusion, uncertainty sampling and G¨ornitz et al. labelling strategy suf-
fer from sampling bias. Aladin and ILAB are the only labelling strategies able to
avoid sampling bias thanks to rare category detection performed at the family
level (see Fig. 4a). ILAB main advantage over Aladin is its divide and conquer
approach that signiﬁcantly reduces the execution time (see Fig. 4c) and thus
improves the expert-model interaction. Our comparisons show that ILAB is both
an eﬀective and a scalable labelling strategy that can be set up on real-world
annotation projects.
134
A. Beaugnon et al.
6 Real-World Annotation Project on NetFlow Data
In this section, we deploy ILAB on a large unlabelled NetFlow dataset originating
from a production environment.
NetFlow. As stated in [5]: “NetFlow is a network protocol proposed and imple-
mented by Cisco [6] for summarizing network traﬃc as a collection of network
ﬂows. A ﬂow is deﬁned as a unidirectional sequence of packets that share spe-
ciﬁc network properties (e.g. IP source/destination addresses, and TCP or UDP
source/destination ports).” Each ﬂow is described by attributes and summary
statistics: source and destination IP addresses, source and destination ports,
protocol (TCP, UDP, ICMP, ESP, etc.), start and end time stamps, number of
bytes, number of packets, and aggregation of the TCP ﬂags for TCP ﬂows.
Table 2. NetFlow dataset
1.2 · 108
Num. ﬂows
Num. IP addresses 463, 913
Num. features
134
Num. TRW alerts 70
Dataset and Features. The ﬂows are recorded
at the border of a defended network. We
compute features describing each external IP
address communicating with the defended net-
work. from its ﬂows during a given time win-