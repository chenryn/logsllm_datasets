title:Side Channels in Deduplication: Trade-offs between Leakage and Efficiency
author:Frederik Armknecht and
Colin Boyd and
Gareth T. Davies and
Kristian Gjøsteen and
Mohsen Toorani
Side Channels in Deduplication: Trade-offs between Leakage
and Efﬁciency
Frederik Armknecht
University of Mannheim, Mannheim, Germany
PI:EMAIL
Colin Boyd, Gareth T. Davies and Kristian Gjøsteen
NTNU, Norwegian University of Science and Technology, Trondheim, Norway
{colin.boyd@item.,gareth.davies@,kristian.gjosteen@math.}ntnu.no
Mohsen Toorani
University of Bergen, Bergen, Norway
PI:EMAIL
June 27, 2017
Abstract
Deduplication removes redundant copies of ﬁles or data blocks stored on the cloud. Client-
side deduplication, where the client only uploads the ﬁle upon the request of the server, provides
major storage and bandwidth savings, but introduces a number of security concerns. Harnik et
al. (2010) showed how cross-user client-side deduplication inherently gives the adversary access
to a (noisy) side-channel that may divulge whether or not a particular ﬁle is stored on the server,
leading to leakage of user information. We provide formal deﬁnitions for deduplication strategies
and their security in terms of adversarial advantage. Using these deﬁnitions, we provide a criterion
for designing good strategies and then prove a bound characterizing the necessary trade-off between
security and efﬁciency.
1 Introduction
Deduplication is a process used by many cloud storage providers and services to remove redundant
copies of data stored in the cloud. It has been shown [13, 15] to greatly reduce storage requirements
in practice because users, both individuals and corporations, often store identical or similar content.
Deduplication can take place either at the server-side or at the client-side. In server-side deduplication,
the server checks whether a ﬁle uploaded by a client has already been stored. If so, the server does
not store it again but instead records the ownership by the client and allows the client to access the
shared ﬁle using a suitable index. Server-side deduplication achieves the aim of reducing storage but
still requires the client to upload each ﬁle it wishes to store. In client-side deduplication, a user wishing
to upload a ﬁle ﬁrst checks whether the ﬁle is already stored in the cloud, for example by sending a
hash of the ﬁle to the server which checks against its list of stored ﬁle hashes. If the ﬁle is already
stored then the ﬁle is not sent by the client, but the server allows the client access to the shared ﬁle as
before. Thus client-side deduplication greatly reduces the bandwidth requirements in cloud storage in
addition to reducing storage requirements. Since communication costs can be high in comparison with
storage costs, client-side deduplication is generally preferable to server-side deduplication on economic
grounds. Deduplication can take place either with respect to ﬁles or with respect to blocks, but we will
not be concerned with this difference since many of the attacks and countermeasures considered in this
paper can be applied to either approach.
1
Secure Deduplication Despite the great saving in storage and bandwidth, deduplication causes at
least two major security and privacy problems, and this has led to extensive recent work on secure
deduplication [15]. The ﬁrst problem is that deduplication cannot take place if semantically secure end-
to-end encryption is deployed. Under ciphertext indistinguishability the cloud service provider (CSP),
which does not possess the decryption key, would be unable to determine if two ciphertexts correspond
to the same plaintext. Several alternative forms of encryption have been proposed in order to address
this problem [1, 4, 6, 9, 10, 19], deriving the encryption key from the ﬁle itself in various ways. These
works often make strong assumptions regarding ﬁle unpredictability or key distribution. The second
problem is that client-side deduplication can work as a side channel leaking information under different
attacks [8]. This paper focuses on these side-channel attacks.
Harnik et al. [8] identiﬁed three attacks due to side-channels in client-side deduplication. The attacks
apply to the cross-user scenario where different users who upload the same ﬁle will have their data
deduplicated. The basic idea of all the attacks is that one user can obtain information about another user’s
ﬁle by receiving a signal revealing whether or not the ﬁle was previously uploaded. In one example,
sometimes called the salary attack, the adversary attempts to learn private data of Alice (her salary)
in her employment contract which she has stored with the CSP. The adversary inserts guesses on a
template ﬁle and uploads it to the CSP where the corresponding ﬁle of Alice resides. Occurrence of the
deduplication signal will then allow the adversary to infer correctness of the guess.
Having identiﬁed these side-channel attacks, Harnik et al. [8] proposed a countermeasure in which
the signal on whether a ﬁle is already uploaded is hidden by randomization. More speciﬁcally, for each
ﬁle a threshold is chosen uniformly at random and the user is only informed not to upload the ﬁle if the
number of previous uploads meets or exceeds the threshold. This will obviously increase the required
bandwidth compared to basic client-side deduplication. The side-channel does not occur in server-side
deduplication because then the client always uploads the ﬁle and allows the server to decide whether or
not to deduplicate. The random threshold countermeasure can thus be seen as a compromise between
the efﬁciency of client-side deduplicaton and the security of server-side deduplication.
Contributions Although the mitigation idea of Harnik et al. [8] has been discussed and developed in
the literature [11, 18], there has been no formal modeling and analysis of threshold-based solutions for
defending side-channel attacks. This has prevented any opportunity to formally compare the effective-
ness of different solutions. The purpose of this paper is to remedy this situation by:
• providing formal deﬁnitions for side-channel deduplication strategies, including a natural measure
for effectiveness of countermeasures;
• identifying the conditions required for strategies to optimize bandwidth and security;
• characterizing the trade-off between security and efﬁciency necessary for all strategies;
• showing that the original proposal of Harnik et al. [8] provides an optimal defence within one
natural security measure.
There are other scenarios in which similar kinds of side-channels are available to attackers.
In
independent and concurrent work, Ritzdorf et al. [17] consider the information leaked to a curious cloud
provider in deduplicating storage systems, with particular focus on leakage caused by using content-
deﬁned chunking as the segmentation mechanism. They show empirically that under a number of strong
assumptions on the target ﬁles, a cloud provider can infer the contents of low-entropy ﬁles with high
probability even if the encryption key is unknown. This attack vector is tangential to the problem tackled
in this paper, but it does emphasize the need for rigour in analyzing security of cloud storage in the
presence of malicious clients and servers. Another closely related area is cache privacy attacks such as
those considered by Ács et al. [2] in Named Data Networking; we believe that our model can also be
applied to such scenarios.
2
The rest of this paper is organized as follows. Side-channel attacks on cloud storage and some ex-
isting countermeasures are reviewed in Section 2. Our security model and optimality of defences are
discussed in Section 3. Section 4 proves our main theorems relating security and efﬁciency, character-
izing both good dedpulication strategies and the essential trade-off between security and efﬁciency. In
Section 5 we discuss how our work relates to other countermeasures and approaches.
2 Security for Deduplication
This section reviews the current status of side-channel attacks on client-side deduplication and their
countermeasures. For the rest of this paper, we will discuss client-side deduplication only, unless explic-
itly stated otherwise, and focus only on side-channel issues. We deﬁne users as the entities with distinct
logins to a system, and clients as the devices that interact with the server on behalf of their owner, the
user. Users and clients may be adversarially controlled: for the attacks we describe we consider an
adversary that has access (i.e. login credentials) to the cloud storage service and attempts to glean infor-
mation from its interactions with the server. The side-channel attacks we focus on are not the only type
of attack in this scenario. If ﬁles can be retrieved using only a (deterministically-derived) index such as
the hash of the ﬁle then this introduces the issue of users being able to share ﬁles with others, potentially
creating copyright issues [14]. This issue can be solved by incorporating proofs of ownership (PoW) [7]
into the deduplication process.
2.1 Existence-of-File Side-Channel Attack
Harnik et al. [8] identiﬁed the side channel inherent in client-side deduplication and discussed its im-
plications in terms of three closely-related attacks performed by an adversary that follows the upload
protocol correctly.
1. Learning ﬁle contents. An attacker can guess the contents of a ﬁle and infer its existence in the
cloud.
2. Identifying ﬁles. The adversary can identify whether an incriminating ﬁle that should not be in the
cloud, such as pirated media or a leaked document, is stored. If found, the owner could be later
identiﬁed with the help of law enforcement access.
3. Covert channels. The existence of a unique ﬁle in the cloud can be used to signal a bit in a covert
communication channel.
These are three outcomes of the same attack mechanism: an adversary wishes to learn whether or
not a ﬁle has previously been uploaded to the storage of a CSP and then does something with the single
bit of information it learns. We will therefore use the general term existence-of-ﬁle attack to incorporate
any attack in which the adversary aims to learn whether or not a ﬁle has been previously uploaded. This
term includes the notion of the aforementioned salary attack because of the following scenario.
• In order to implement client-side deduplication, the client ﬁrst sends a short identiﬁer to the CSP.
The CSP instructs the client to upload the full ﬁle only if it is not already stored in the cloud.
• The adversary creates a template of an employment contract of Bob and attempts a number of
uploads of ﬁles that only differ in a speciﬁc ﬁeld (e.g. the salary).
• At some point, the upload will be halted by the CSP. The adversary will then learn that this ﬁle is
already stored on the cloud and that her guess on Bob’s salary is correct.
Examples of other sensitive information that an adversary may like to learn via this attack vector are
clinical lab test results, ﬁgures in tax returns, pay stubs and contracts, and bank letters including a
3
password or PIN. Note that these attacks are not just an issue if the ﬁles are unencrypted, they also apply
if the ﬁles are encrypted using a method that allows the server to learn equality of underlying plaintexts,
for example by using a key that is deterministically derived from the ﬁle [4, 6, 10, 12].
In Section 3, we will formalize deduplication and give our security deﬁnition for the existence-of-ﬁle
attack. There are subtleties in the desired outcome of the attack: does the adversary want to know the
answer to “Is Bob’s salary X?” or “What is Bob’s salary?” We address these issues and the challenges
in formally modeling this scenario later on.
In the next section and in the rest of the paper, we will describe a countermeasure used to negate the
effects of these side-channel attacks while still allowing client-side deduplication. We note that other
approaches may also be used to counteract these attacks. For example, the server could ask clients
to separate all ﬁles at the point of upload into sensitive or non-sensitive: ﬁles with the ﬂag sensitive
are encrypted using semantically-secure encryption before they are uploaded, and others are uploaded
normally. However most users will simply bypass this step by marking all ﬁles with one of the ﬂags: This
either increases cost for the CSP by preventing deduplication or leaves the ﬁles vulnerable to attack. Any
such countermeasure that requires the user to make decisions about their ﬁles is unrealistic in practice.
2.2 Randomized Solution of Harnik et al.
An approach to defending against the side-channel attacks is to require users to upload ﬁles even in
the case that they have previously been already uploaded. For a given ﬁle, denote as thr the number
of uploads before the server informs clients that it has enough copies. When a user chooses to store
the same ﬁle, the server checks whether the thr is reached for that ﬁle and if not requires the ﬁle to be
uploaded and increments the counter. Any strategy for which Pr[thr = 1] (cid:54)= 1 for all ﬁles will impose
increased bandwidth until the threshold is reached. In addition, if the adversary knows the threshold thr
for a given ﬁle then she can count the number of uploads allowed and still infer whether the ﬁle initially
existed depending on whether she is required to upload thr times, or thr − 1 times. If this is the case
then the classic attack is just slowed down. Consequently we assume that adversary A does not know
the value of thr (which would differ per ﬁle) but A may know how thr is selected.
Harnik et al. [8] proposed use of a randomized threshold for each ﬁle, and this approach has since
been adopted by Liu et al. [12]. Their intuition was as follows: if thr is chosen uniformly from the range
{1, . . . , B} for some integer B then an adversary launching the existence-of-ﬁle attack will learn nothing
if thr ∈ {2, . . . , B − 1}. For the rest of the paper this value B is the upper bound for the threshold. Note
that for this approach, the expected number of uploads of a ﬁle is B+1
2 .
Note that if the system does not attempt to defend against the side-channel attacks, the ﬁrst up-
loader of a given ﬁle will be required to upload but all subsequent uploads will not be required. This
corresponds to the case B = 1 which is then basic client-side deduplication and is optimal in terms of
bandwidth usage. In contrast, if the system wishes to leak no information then the server will always
require upload of each ﬁle, which will of course incur a signiﬁcant bandwidth cost. This corresponds
to an inﬁnite B which is equivalent to server-side deduplication. Thus from an efﬁciency point of view
using a ﬁnite threshold is considerably better than negating the attacks using server-side deduplication.
The interesting cases are where B is ﬁnite and B > 1. If thr = 1 and on the ﬁrst upload A is not
asked to upload the ﬁle, then A will learn that the ﬁle was already stored. Likewise, if A is asked to
perform B uploads then she will learn that the ﬁle was certainly not already stored. We can see a clear
tradeoff between security and efﬁciency since B indicates the maximum number of times a ﬁle may need
to be uploaded and is thus the worst-case overhead for bandwidth.
A uniformly random choice of thr is an intuitively reasonable option for defending against the side-
channel attacks. However, it is not the only option. Even for a ﬁxed upper bound B, it is not immediate
that a uniform probability distribution is best for security. When taking into account the trade-off be-
tween security and efﬁciency, the question becomes more complex. The threshold thr could be chosen
according to some other probability distribution, for example the geometric distribution. Thus for each
ﬁle, the server tosses a biased coin until it sees a tails and uses the number of heads (plus one) as the
upload threshold. The problem here is the potential for inﬁnite bandwidth overhead, so it makes sense to
4
bound the threshold by the ﬁnite limit B and truncate the distribution at that point. However this means
that, depending on parameter choices, we could get a high probability of thr = B which could aid the
adversary. Alternative distributions [2,11,18] have been proposed in the literature and we compare some