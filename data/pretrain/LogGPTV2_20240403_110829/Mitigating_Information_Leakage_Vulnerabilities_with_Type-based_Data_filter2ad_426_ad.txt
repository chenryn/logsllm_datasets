overhead from 10.4% to 8.4%. We believe that improving our
analysis could probably improve this overhead further; in any
case, the beneﬁt seems worth the implementation effort.
The runtime overhead of TDI on SPEC CPU2017 is shown
in Figure 5;
the geomean (12.5%) is higher than that of
CPU2006. Overall, masking is the source of the majority of
the overhead (geomean 8.0%), although omnetpp suffers from
inefﬁciencies in our heap allocation. This is partially due to
shortcomings in the analysis of our prototype; the CPU2017
versions of x264 and imagick contain signiﬁcant numbers
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:57:47 UTC from IEEE Xplore.  Restrictions apply. 
81056
perlbench_s
gcc_s
mcf_s
lbm_s
omnetpp_s
xalancbmk_s
x264_s
deepsjeng_s
imagick_s
leela_s
nab_s
xz_s
Typed allocation
Masking
Full protection
0%
5% 10% 15% 20% 25% 30% 35% 40%
Fig. 5. CPU2017 runtime overhead
of (non-GEP) pointer arithmetic instructions in situations
unsupported by our analysis, and are conservatively masked.
Our benchmarking of xz shows high variance, with a
standard deviation of ∼5% (including the baseline). Other
benchmarks (e.g., mcf and lbm) have stddev <1%;
the
speedups shown when using typed allocation are consistent.
As discussed by Mytkowicz et al. [45], measurement bias
is difﬁcult to avoid in this form of evaluation. Our instru-
mentation and runtime inevitably have side-effects which will
inﬂuence performance. For example, arena allocations may
cause more cache conﬂicts; allocations at the start of arenas
will share lower bits, and many arenas are only used for
small allocations. This could be mitigated by adding small
offsets to the arena base, e.g., based on internal type IDs or
allocation order. However, we did not observe any signiﬁcant
performance change when subtracting small (cache-line-sized)
offsets from the base pointers of the typed stacks.
Full TDI’s memory overhead (peak RSS) on CPU2006 has
a geomean of 15.5% (vs unmodiﬁed tcmalloc); this is due
to increased memory fragmentation caused by our allocation
strategy, ampliﬁed by tcmalloc conﬁguration (e.g., minimum
page cache sizes) which are inappropriate for arenas. To ensure
fairness of our baseline comparison, we left
these values
unmodiﬁed. Details can be found in Figure 9 in the appendix.
We also compared the runtime overhead of TDI to LLVM’s
Speculative Load Hardening (SLH) mitigation. SLH has a
signiﬁcantly stronger speculative threat model which aims to
prevent loads from executing by mixing predicate state (from
branches) into the pointers being loaded, providing a mitiga-
tion against the majority of Spectre v1 attacks. However, over-
head when applying (x86) SLH to CPU2006 is prohibitively
high (geomean 75.6%), and it provides only speculative safety.
(Overhead should be slightly lower without indirect call/jump
hardening, but we encountered code generation errors when
disabling it.) Again, detailed results are in the appendix.
D. nginx
We tested TDI using the nginx 1.18.0 web server. We used
default options and enabled SSL, but disabled the ‘geo’ mod-
ule (due to undeﬁned behavior, see Appendix A). We linked
against OpenSSL 1.1.1h3 using LTO (and -O2), hardening
3conﬁgured with no-shared, no-asm and no-zlib.
400k
300k
200k
100k
)
s
/
s
q
e
r
(
t
u
p
h
g
u
o
r
h
t
concurrent connections
 100
Fig. 6. nginx throughput
Baseline
Masking
Typed allocation
OpenSSL hooks
Full protection
 1000
both nginx and OpenSSL with TDI. We conﬁrmed that the
OpenSSL tests pass after full hardening, and used a hardened
openssl binary to generate 2048-bit RSA keys for SSL.
Note that nginx does not fully beneﬁt from our automated
type-based protection, since allocations in nginx’s pools (in-
cluding shared memory slab pools) lose the beneﬁt of intra-
pool type isolation. However, since different types of pools are
identiﬁed based on callsites, pools containing disjoint types
remain isolated from each other, as well as from the many
other arenas identiﬁed by the type analysis (Section VII-F).
One improvement could be to allocate each pool instance in
a separate arena, providing ﬁner-grained isolation.
The ‘OpenSSL hooks’ conﬁguration uses TDI’s instrumen-
tation but assigns arenas using OpenSSL’s allocator hooks; as
we discuss later, such arenas are surprisingly coarse-grained.
We evaluated nginx by serving a small ﬁle (64 bytes)
via SSL (with default settings), using two Xeon Silver 4110
machines with 100Gb/s Ethernet (plain HTTP is largely I/O
bound). We conﬁgure nginx to use 16 workers, and use 16
threads of wrk2 [3] to make the requests.
Throughput results are shown in Figure 6 (median of 3 runs
of 30s each); all cores are saturated for ≥96 connections. Sat-
urated throughput at that point is 5.4% lower than the baseline
for full TDI, 3.6% for masking, 3.8% for the typed allocator
and 4.8% for the hook-based allocation. 90th percentile latency
is 4.7% higher for full TDI, and 2.9%, 3.6% and 3.9% for
masking, typed allocator and the hooks respectively.
E. Instrumenting system libraries
TDI’s protection does not rely on complete instrumentation
of system libraries, since pointers passed to external functions
or stored in memory are always masked. For example, a call
to memcpy will always be provided with valid pointers to
the expected arenas, and any pointers copied by memcpy will
already have escaped analysis, and so also have been masked.
Since glibc does not support clang, alternative C libraries
have compatibility issues, and TDI’s stack instrumentation
currently requires LTO, we expect TDI to be used in practice
with an uninstrumented system libc. Despite this, we also
evaluated the overhead of applying TDI’s full stack/heap
protection to libc, by using musl (and libc++) rather than glibc.
Throughput overhead for our nginx+OpenSSL benchmark
libc
the point of saturation (vs 5.4% without
is 8.4% at
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:57:47 UTC from IEEE Xplore.  Restrictions apply. 
91057
gzip
vpr
gcc
mesa
art
mcf
equake
crafty
ammp
parser
eon
perlbmk
gap
vortex
bzip2
twolf
p
a
e
h
f
t
d
e
a
c
o
l
l
o
r
e
b
m
u
N
a
s
t
c
e
b
o
j
Automated (TAT)
TAT + OpenSSL hooks
OpenSSL hooks only
-5% 0%
5% 10% 15% 20% 25% 30% 35%
Fig. 8. Number of objects allocated in each nginx+OpenSSL heap arena.
Full protection
0
25
50
75
100
125
150
175
Fig. 7. CPU2000 runtime overhead
instrumentation), and lower using alternative conﬁgurations
such as using 64kB ﬁles (4%) or (multi)thread pools (6.8%).
Geomean runtime overhead is 10.3% for SPEC CPU2006 (vs
8.4%); as before, xalancbmk and perlbench are largely respon-
sible. Similarly, geomean overhead is 13.9% for CPU2017 (vs
12.5%). Details can be found in Appendix D.
We also evaluated TDI on SPEC CPU2000, to aid com-
parisons with prior work. Again, details of the (mostly minor)
changes are in Appendix A. Figure 7 presents our performance
results for full protection with complete instrumentation (in-
cluding musl/libc++). As shown in the ﬁgure, the geomean
runtime overhead is 8.8%—with the highest overhead (35.8%)
for perlbmk, similar to previous results.
Our CPU2000 overhead is comparable to domain-based
sandboxing solutions such as NaCl [72] (∼ 7%)—despite
our support for arbitrary (rather than NaCl-only) programs
and intra-domain isolation. Moreover, our overhead is much
lower than state-of-the-art software fault isolation techniques
that rely on highly optimized address masking instrumenta-
tion on loads/stores [73] (rather than pointer arithmetic like
TDI). Speciﬁcally, Zeng et al.’s solution [73], which can only
support the limited number of colors allowed by load/store
masking, yields 19% overhead on top of a CFI baseline
and on a CPU2000 subset excluding costly benchmarks like
perlbmk. More ﬁne-grained solutions like WIT [7] can support
more colors (limited by the imprecision of context-insensitive
points-to analysis), but load instrumentation can increase over-
head (10% on a CPU2000 subset excluding costly benchmarks
like perlbmk) “by more than a factor of three” [7]. Note that
these numbers (from [7] and [73]) are not directly comparable
due to the different evaluation platforms.
F. Isolation granularity
Although TDI can be used as a traditional coarse-grained
(e.g., 2-color) isolation scheme even in the absence of any
automated color analysis (signiﬁcantly outperforming prior
load/store address masking solutions, as noted), we brieﬂy
evaluated how arenas are assigned in practice by the automated
type analysis in a ﬁne-grained, many-color conﬁguration.
For our nginx(+OpenSSL) benchmark, the automated type
analysis (TAT) statically identiﬁes 197 colors (and arenas) on
the stack and 649 colors (and arenas) on the heap. On the heap,
the data type analysis assigns a total of 96 types to allocations
at 583 call sites, while the remaining 553 types are identiﬁed
by the context-sensitive callsite ID analysis based on wrapper
detection and inlining (Section VI-C).
We also looked at the per-arena object distribution during
the execution of the benchmark. Figure 8 shows the number
of objects allocated in each heap arena during startup and the
ﬁrst client request. The ‘OpenSSL hooks’ results manually
assign arenas by using OpenSSL’s built-in support for hooking
allocator functions (CRYPTO_set_mem_functions); we
used one-line wrappers which assign an arena ID based on
the callsite information provided by OpenSSL. There were
178, 133, and 106 heap arenas for the automated (TAT),
TAT+hooks, and (manual) hooks conﬁgurations respectively.
The two arenas with the highest number of objects are used
to store OpenSSL object names and their related hashes, and
all conﬁgurations have a relatively large ‘long tail’ of arenas
used only for a single object.
Notably, this shows that attempting to manually assign are-
nas by hooking OpenSSL’s allocator functions leads to coarser
arenas than a fully-automated approach, even when TAT is
also used to assign arenas and can merge allocations of the
same type. The fully-automated approach can produce ﬁner-
grained arenas because OpenSSL’s allocator hooks use indirect
calls and only provide direct callsite information (ﬁlename/line
numbers). For example, OpenSSL provides wrapper functions
for allocating and resizing ‘buffers’; OpenSSL’s allocation
functions are called from these buffer wrapper functions,
resulting in a large number of allocations from a small number
of callsites. TAT instead detects the buffer code as allocator
wrappers, and instead allocates arenas based on the parent
callsite since the buffer data is untyped (char *).
We also inspected arena usage for some of the SPEC
benchmarks. On the CPU2000 subset evaluated by WIT [7],
TDI’s type analysis yields a number of colors comparable to
WIT’s points-to analysis (which fares well on such simple
benchmarks with many stack allocations). However, unlike
WIT, TDI can easily handle the entirety of CPU2000 and
even much more complex programs. Moreover, while WIT
is limited to 256 colors, TDI uses a larger number of colors
even on the slightly more complex CPU2006 benchmarks.
For example, xalancbmk allocates 186 stack and 200 heap
arenas, and gcc allocates 110 stack and 192–198 heap arenas
(depending on the benchmark). Appendix E contains arena
statistics for the other benchmarks.
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:57:47 UTC from IEEE Xplore.  Restrictions apply. 
101058
VIII. RESIDUAL ATTACK SURFACE
D. Pointer arithmetic
A. Spatial safety
TDI’s arena allocation could be applied without masking
(with much lower overhead). However, non-linear memory
vulnerabilities are becoming the primary form of spatial safety
vulnerability in the architectural [43] and speculative [32]
domain, which may allow attackers to bypass guard zones.
These are exactly the situations for which we apply masking.
As for the residual attack surface with full protection, TDI
cannot prevent overﬂows within/across objects of the same
color (i.e., type). This provides strong isolation for info leaks,
although in some cases there is a remaining attack surface for
intra-pool leaks. For example, OpenSSL stores data involving
highly conﬁdential data (private/session keys) in the same
bignum types as data related to public keys; an info leak
bug speciﬁcally revealing bignum data for a public key may
also allow an attacker to obtain conﬁdential bignum data. If
desired, TDI supports annotations to further improve isolation
of critical objects, much like existing data isolation solutions.
TDI also offers limited protection against memory corrup-
tion exploits which are outside our threat model. For instance,
if an attacker can overwrite a pointer (e.g., in a struct), they
can potentially bypass our mitigation. We make such attacks
more difﬁcult by limiting the set of pointers at reach (pointers
within the same object type) and their ability to leak pointers.
B. Spectre
TDI provides the same protection against Spectre-BCB
attacks as it does against non-speculative information leaks—
preventing cross-arena leakage. Most other Spectre variants
are clearly out-of-scope and best mitigated by techniques
such as retpoline or hardware-based mitigations. However,
a theoretical attack surface remains in Spectre V1 gadgets
that exploit speculative issues beyond memory safety (e.g.,
logic bugs). We also do not prevent attacks exposing potential