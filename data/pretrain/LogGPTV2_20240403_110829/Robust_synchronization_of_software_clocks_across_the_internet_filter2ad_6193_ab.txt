### Lute Clock and Precision in Timestamp Recording

In implementations, it is crucial to maintain precision when recording timestamps. For instance, the Time Stamp Counter (TSC) register is typically 64 bits. If a 32-bit counter is used for manipulation, overflow can occur after approximately 4 seconds on a 1 GHz machine (see [5] for a detailed discussion).

### 2.2.1 Timestamping

Even with a perfect clock, its utility is limited if one cannot read it close to the time of the event of interest. This issue, known as timestamping, requires optimization that is specific to the application. In the context of remote clock synchronization, the goal is to accurately timestamp the arrival of NTP packets.

In [5] (and [10]), this problem was thoroughly explored for the Ethernet network interface on a 600 MHz Pentium PC. The solutions ranged from using purely user-space code to leveraging RT-Linux under Linux, a real-time operating system [11], which mitigates scheduling issues that often affect precision timing in multi-tasking environments. It was found that timestamping early in the driver code for the network interface card provided an excellent balance: minimal scheduling problems (one timestamp per 10,000 events, with errors usually under 1 ms), and timestamping noise (primarily due to interrupt latency) of up to 15 µs, while keeping the code simple and mostly at the user level. In contrast, the standard `gettimeofday` system call under Linux suffers from higher system noise due to various factors.

We adopt the same driver-based timestamping approach here. The kernel-level code required is minimal, enabling the raw TSC counter value to be passed to a user process, where it can be stored, processed, or converted to seconds as needed without strict time constraints. In [5], this was achieved by exploiting the existing API under Linux, while in this paper, it is done via a modified Berkeley Packet Filter data structure under BSD Unix. Any remaining timestamping errors, especially those larger than 0.1 ms, will be interpreted as network delay by the generic filtering mechanisms we develop, and thus rejected or dampened. If user-level timestamping were used instead, the algorithms would still function, albeit with higher estimation variance, as the errors would always increase round-trip times and be seen as positive network "noise."

### 2.3 The NTP Server

Network Time Protocol (NTP) servers are networked computers with well-synchronized clocks. Different levels of synchronization accuracy are defined. We focus on stratum-1 servers, whose clocks are synchronized by a local reference time source (using the GPS timescale, which can be converted to UNIX time). Three such servers are used in this paper:
- **ServerLoc**: Located in our laboratory on the same local network as the host.
- **ServerInt**: Located in the same organization but in a different building and network, with a separate GPS receiver.
- **ServerExt**: Located over a thousand kilometers away in another city, synchronized by an atomic clock.

The distances between the host and the servers, along with the minimum Round-Trip Time (RTT) of NTP packets over at least a week and the number of IP hops, are provided in Table 2. The path asymmetry ∆, which is the difference in the minimum one-way delays to and from the server, is also given.

| Server     | Reference | Distance  | RTT       | Hops |
|------------|-----------|-----------|-----------|------|
| ServerLoc  | GPS       | 3 m       | 0.38 ms   | 2    |
| ServerInt  | GPS       | 300 m     | 0.89 ms   | 5    |
| ServerExt  | Atomic    | 1000 km   | 14.2 ms   | ≈ 10 |

Hosts wishing to synchronize their clocks can do so by running an NTP application that communicates with an NTP server via NTP packets. These are User Datagram Packets (UDP) with a 48-byte payload, including four 8-byte Unix timestamp fields (totaling 90 bytes for the Ethernet frame). The typical exchange involves:
- The host generates the ith NTP packet and records the timestamp \( Ta_i \) just before sending.
- Upon arrival at the server, the timestamp \( Tb_i \) is made by the server clock and inserted into the payload.
- The server immediately sends the packet back to the host, adding a new departure timestamp \( Te_i \).
- The host timestamps its return as \( Tf_i \).

The four timestamps \(\{Ta_i, Tb_i, Te_i, Tf_i\}\) are the raw data from the ith exchange, used to synchronize the host clock. However, these timestamps are not perfect due to clock and/or timestamping limitations. The actual times of the corresponding events are denoted by \(\{ta_i, tb_i, te_i, tf_i\}\). The NTP payload also contains processed data related to estimated clock drift, which we do not use, and server identity information, which we plan to use for route change detection in the future.

At the host, we use separate raw TSC timestamps instead of the usual SW-NTP clock timestamps. These are denoted by \( Ta_i \) and \( Tf_i \) even though they are in TSC units rather than seconds.

### 2.4 Reference Timing

Validation of timing methods requires a reliable timing reference. We used a 'DAG3.2e' series measurement card designed for high-accuracy and high-performance passive monitoring of 10/100 Mbps Ethernet, providing timestamping accuracy around 100 ns [8]. The card was synchronized to the Trimble Acutime 2000 GPS receiver, the same one used by ServerLoc, with the antenna permanently mounted on the roof of the building housing the laboratory.

The DAG card was positioned to timestamp the returning NTP packets via a passive tap on the Ethernet cable just before it enters the host’s interface card. Since the DAG and TSC clocks timestamp different events, \( tg_i < tf_i \). One component of this difference is that the DAG timestamps the first bit of each packet, whereas TSC timestamping occurs after the packet has fully arrived. Therefore, \( Tg_i \) denotes a DAG timestamp corrected by adding 7.2 µs. The remaining difference includes the additional length of cable (negligible), the minimum processing time of the card, and the interrupt latency of the host. To estimate these effects, we examined a histogram of the measured offset discrepancy \( Tf_i - Tg_i \). The dominant mode, centered at zero, has a width of 5 µs. Large departures due to rare scheduling errors are easy to detect and exclude, and there are small but significant side modes symmetrically located at 10 and 31 µs, due to interrupt latencies. These can also be reliably detected and corrected. The final limit of verifiability of the offset (but not rate) results is therefore of the order of 5 µs.

The DAG timestamps form the basis of all the "actual performance" results presented here.

### 3. Data Characterization

Any synchronization algorithm must start with an understanding of the nature of the collected data. In this section, we study the basic features of key quantities: the offset of the TSC clock \( C(t) \), the network delay, and the delay at the NTP server.

#### 3.1 The Clock

We examine the clock offset of the same 600 MHz CPU host in two different temperature environments: an open-plan area in a non-air-conditioned building (laboratory) and a closed, temperature-controlled environment (machine room).

To calculate the offset of the clock from the TSC counter timestamp \( Tf_i \), we need a prior rate estimate \( \hat{p} \). In Figure 2, we use \( \hat{p} = 1.82263812 \times 10^{-9} \) (548.65527 MHz) for measurements in the laboratory and \( \hat{p} = 1.82263832 \times 10^{-9} \) (548.65521 MHz) in the machine room, then calculate the offset via \( \theta(tf_i) = Tf_i \times \hat{p} - Tg_i \) for each. These estimates detrend the data, facilitating an initial inspection of the residual clock drifts, which depend on the temperature environment.

From the right plot in Figure 2, it is clear that the Simple Kalman Model (SKM) fails over day timescales, as the residual errors are far from linear, although the variations fall within the narrow cone defined by \( \gamma = \pm 0.1 \) PPM. In the left plot, however, we see that over smaller time scales, the residual offset error grows approximately linearly with time, suggesting that the SKM could be accepted with more accurate local \( \hat{p} \) values (the microsecond-scale irregularities are due to timestamping noise in the host, as corrected \( Tf_i \) timestamps, described in Section 2.4, were not used). These observations hold for all traces collected over many months. In [5], the same result was reported for a host in an air-conditioned (but not temperature-controlled) office environment over a continuous 100-day period.

### Allan Variance Analysis

To examine the clock offset over all scales simultaneously and avoid the need for an arbitrary prior rate estimate, we return to the concept of oscillator stability. A particular estimator of the variance of \( y_\tau(t) \), known as the Allan variance, calculated over a range of \( \tau \) values, is a traditional characterization of oscillator stability [9]. We term the square root of the Allan variance the Allan deviation, interpreting it as the typical size of variations in time-scale-dependent "rate." A study over a range of time scales is essential, as the source and nature of timing errors vary according to the measurement interval. At very small time scales, \( \gamma \) will not be readily visible in \( y_\tau(t) \) as the "rate" error will correspond to system noise affecting timestamping. At intermediate time scales, \( \gamma \) may seem well-defined and constant with some measurement noise, as in the left plot in Figure 2. At large scales, daily and weekly cycles enter, and the issue is not noise in estimates of \( \gamma \) but variations in \( \gamma \) itself.

Four Allan deviation plots for the host oscillator are given in Figure 3, for traces taken under different conditions ranging from 1 to 3 weeks in length. One is when the host was in the laboratory, using ServerInt. The others are from the machine room, using each of the three servers. Corrected \( Tf_i \) timestamps were used, as otherwise, the timestamping noise adds considerable spurious variation at small scales (due to the strong wavelet signatures of discontinuities).

Over small scales, the plots show a consistent \( 1/\tau \) decrease, confirming the applicability of the SKM and the meaningfulness of rate estimates down to 0.01 PPM.