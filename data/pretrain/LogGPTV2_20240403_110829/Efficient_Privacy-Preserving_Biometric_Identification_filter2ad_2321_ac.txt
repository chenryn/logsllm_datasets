For our improved protocol, we measure complexity of the second round only (i.e., we assume pre-processing is
being done, and tabulate the complexity per query). We let κ denote the number of scalars that can be packed into
a single ciphertext. Bandwidth is tabulated in terms of the number of ciphertexts communicated.
3. Our protocol uses less bandwidth.
a single homomorphic operation. The number of ho-
momorphic operations is reduced by the number of
scalars, κ, that can be packed into a single ciphertext.
If we assume a
client making multiple queries, then the communica-
tion cost of the ﬁrst round can be amortized over a large
number of queries (with the client only sending a new
second-round message for each query).
Security. Security of this protocol (as well as the prior pro-
tocols [5, 20]) depends on the r values adequately masking
the entries of d. We stress that addition here is computed
over the integers rather than modulo some value; thus, we
obtain statistical hiding rather than perfect hiding. Con-
cretely, if each di is a δ -bit integer and ri is a uniform ρ-
bit integer, then releasing d߰
i  di  ri gives statistical secu-
rity roughly 2δࢤρ for the value of di.
(Formally, for any
ﬁxed d0
i d1
the statistical difference between the random
i
i  ri is approximately 2δࢤρ.) By
variables d0
i  ri and d1
choosing ρ suitably, we can make this probability arbitrar-
ily low. Increasing the maximum mask value, however, re-
duces κ as discussed next.
Packing Implementation. Suppose each of vi j and v߰
j is
a σ-bit integer and each additive random mask ri is a ρ-
bit integer. From the formulas for computing di and d߰
i, it is
clear that δ  2σ ऄlogNअ bits are sufﬁcient to represent di;
as for d߰
i, since we need ρ  δ for statistical security we see
that δ߰  ρ  1 bit sufﬁce to represent d߰
i.
Let θ ࣙ δ߰ denote the number of bits designated for each
of the κ units being “packed” in one ciphertext. We cannot
set θ  δ߰ because we need to handle possible overﬂow of
intermediate values in the computation. We allocate σ 
ऄlogNअ bits for overﬂow; thus,
θ  δ߰  σ ऄlogNअ
 ρ  1  σ ऄlogNअ
As a concrete example, for σ  8N  640ρ  32 we
get θ  51. Therefore, if a 1024-bit modulus is used in
Paillier’s cryptosystem, κ  20 units can be packed into a
single ciphertext.
Results. Table 2 provides a comparison between our im-
proved distance protocol and the standard protocol (from
Section 4.1) as the size of the modulus for Paillier’s encryp-
tion varies. Details on the implementation and experimental
setup are provided in Section 7.
The results are consistent with our quantitative analy-
sis in Table 1 and demonstrate nearly twenty-fold improve-
ments in both time and bandwidth for a 1024-bit Paillier
modulus. Our distance protocol also has better scalabil-
ity with respect to the security parameter of Paillier’s cryp-
tosystem. This is because as the length of the modulus in-
creases we can pack more values into each ciphertext: thus,
e.g., each encryption with a 2048-bit modulus can be used
to perform twice as many underlying computations as with
a 1024-bit modulus.
5 Finding the Closest Match
1    d߰
This stage begins with the server knowing d߰
M
and the client knowing r1    rM. This stage can be
viewed as allowing the client to learn the index iࢩ minimiz-
i ࢤri, assuming diࢩ  ε. In fact, though, the client
ing di  d߰
does not learn iࢩ explicitly; rather, the client learns wire la-
bels for “active” wires in a garbled circuit prepared by the
server, and this will be sufﬁcient to enable to client to learn
the desired record (that corresponds to index iࢩ) in the back-
tracking stage we describe in Section 6.
Section 5.1 describes the circuit we evaluate securely
to ﬁnd the closest match, and Section 5.2 explains how we
implement the matching phase using this circuit.
5.1 Circuit Design
The overall functionality of this stage is implemented
by the circuit SubReduceMin shown in Figure 3. The
server’s inputs are d߰
M and the client’s inputs are
r1    rM, where each of these values is an l-bit integer;
the parties also know ε, a k-bit threshold value (k  l).
1    d߰
We use several sub-circuits to implement the desired
functionality. The SubReduce circuit is used, roughly, to
i ࢤ ri and then output either the
compute the difference d߰
low-order k bits of the result or ε. Formally, this sub-circuit
Paillier Modulus
Time/Bandwidth
Standard
Improved
Savings
Exec.
1024
2048
3072
s
123.6
6.8
94.5%
KB
190.8
9.8
94.9%
s
574.3
14.4
97.5%
KB
350.6
8.9
97.5%
s
1510.6
23.9
98.4%
KB
511.4
8.3
98.4%
Table 2. Execution Phase Costs for Euclidean Distance Protocols.
computes the function
5K>4A@K?Ad߰
iriε 
 εif d߰
k low-order bits of
i ࢤ ri ࣙ 2k
i ࢤ riotherwise
d߰
Figure 4(a) shows how the SubReduce circuit. Our start-
ing point in building this sub-circuit was the work of
Kolesnikov et al. [8], and the SUB and MUX sub-circuits
are taken directly from their work. However, we reduce the
size of the overall circuit by avoiding unnecessary compar-
isons and removing the need to propagate indexes.
First, instead of computing a full comparison between
i ࢤ ri and ε, we compute the logical OR of the high-order
d߰
l ࢤ k bits of the difference. If the result is 1, then d߰
i ࢤ ri is
greater that ε, and there is no need to compare the other bits.
The output of the lࢤk-bit OR gate (implemented as a tree
of binary OR gates) is used as the selector bit for a MUX
that selects between the low-order k bits of the difference
and ε. Since the bit length of ε is signiﬁcantly smaller than
that of di  ri, this modiﬁcation substantially reduces the
number of gates.
Next, we compute the minimum of the values output by
the M SubReduce circuits. This is done using a M-to-1
Min circuit which is simply a tree of 2-to-1 Min circuits
(with the latter being constructed as in [8]). The output is
then compared with ε using another 2-to-1 Min circuit.
In contrast to the work of [8], we only need to compute
the minimum value rather than the index of the minimum
value. This is a consequence of the backtracking protocol
that we present in the next section. This allows us to reduce
the number of gates by roughly M ࢤ logM overall.
Table 3 summarizes the number of non-XOR gates in
each of our circuits (using the free-XOR technique [9],
XOR gates do not contribute signiﬁcantly to the cost of the
garbled circuit since they do not require any encryption op-
erations).
SubReduce
2l ࢤ 1
2-to-1 Min M-to-1 Min
2kM ࢤ 1
2k
SubReduceMin
2l  2kࢤ 1M
Table 3. The number of non-free binary gates
in each circuit.
5.2
Implementation
To implement the matching phase, we follow the stan-
dard garbled-circuit methodology with the exception that
there is no need to send the client the semantic wire map-
pings at the end of the protocol. Our implementation has
the following stages:
1. The server prepares a garbled version of the circuit de-
scribed in the previous section, in the standard way.
The resulting garbled circuit is sent to the client. The
server also sends the client the wire labels correspond-
ing to its own input bits.
2. The client and server use oblivious transfer so that the
client can obtain the wire labels corresponding to its
Figure 3. SubReduceMin circuit for ﬁnding the closest match.
Figure 4. Circuits for SubReduce and 2-to-1 Min.
own input bits. We use OT extension [6] to reduce
an arbitrary number of OTs to secure evaluation of
just k OTs, where k is a statistical security parame-
ter. As our base OT we use the Naor-Pinkas proto-
col [14] which achieves semi-honest security based on
the decisional Difﬁe-Hellman assumption. We also use
the standard technique of pre-processing [4] to push
most of the cost of the oblivious transfer step into a
pre-computation phase. The details of our oblivious
transfer protocol are described in the Appendix.
Differing from prior work, however, in our implementation
the server does not send the client the mappings from any
of the wire labels to actual bits. Thus, the client receives no
semantic output from this phase. Nevertheless, we show in
the following section how the client can use the wire labels
that it learned in this step to recover the record correspond-
ing to the closest match.
6 Backtracking Protocol
At the end of the circuit evaluation, the client has one of
each pair of wire labels. In traditional garbled circuit proto-
cols, the last step is to convert the ﬁnal output wire labels to
meaningful values. Our solution shows that the overhead of
propagating the indexes and retrieving the information can
be avoided while enabling arbitrary information about the
match to be transmitted obliviously.
In a conventional garbled circuit, wire signals (0 or 1)
are denoted by randomly-chosen nonces known as wire la-
bels. The bindings between wire labels and the wire sig-
nals are known by the circuit generator, but hidden from the
circuit evaluator (except for the bindings for the ﬁnal out-
put wires which are disclosed to reveal the result). Wire
labels are merely used for intermediate computation. How-
ever, these apparently meaningless nonces can be exploited
in later stages of the protocol. We take advantage of the key
property of garbled circuit evaluation:
the evaluator only
learns one of the two possible output wire labels for each
gate, as determined by the obliviously-selected input wire
labels and evaluation of the rest of the circuit. These wire
labels can serve as keys for encrypting useful information.
The wire labels of the output wires of GT comparison
circuits in the n-to-1 Minimum tree can be used to reveal a
path from the inputs to the minimum value. Figure 5 shows
an example comparison tree for a four record database. In
each of the 2-to-1 Min circuits the GT circuit takes two in-
puts and outputs a bit indicating which value is greater. We
denote that bit as ghi and the corresponding wire labels λ 0
hi
(when the greater than comparison is false) and λ 1
hi (when
the comparison is true). When the more closely matching
entry match is on the left side of this gate, the client learns
λ 0
hi; when it is on the right side he learns λ 1
hi. The ﬁnal gate
in the diagram compares the best match with ε. We use
the gε output to prevent the client from learning any infor-
mation from the backtracking tree when there is no match
within the ε threshold.
Our backtracking tree protocol involves a tree generator
(the server), who produces and sends a tree encoding en-
crypted paths to the proﬁle records, and a tree evaluator (the
client), who follows a single path through the tree to open
the best matching proﬁle record. To generate a backtracking
tree, the server starts by ﬁlling the leaf nodes (level 0) with
the desired information corresponding to each database en-
try. Then, she ﬁlls in the internal nodes of a binary tree
with those leaves, as illustrated by the left tree in Figure 6.
Note that the structure of this tree is identical to that of the
comparison tree in Figure 5.
hi or λ 1
Next, she generates new nonces for each non-leaf node
in the tree, and encrypts those nonces with keys that com-
bine the appropriate wire labels and the nonce of its parent
node. The wire label used for node hi (the ith node at level
h) is either λ 0
hi, depending on whether it is the left
or right child of its parent). Thus, the label pair the server
uses for each node comes from the labels of ghi in the cor-
responding 2-to-1 Min circuit she generated for the match-
ﬁnding protocol. The root node is encrypted using λ 0
ε , the
label the client will learn when the closest match is closer
than ε. The right tree in Figure 6 shows the backtracking
tree corresponding to the example circuit in Figure 5.
Starting from the root of the tree, which the client can