# Better Never than Late: Meeting Deadlines in Datacenter Networks

## Authors
- Christo Wilson
- Hitesh Ballani
- Thomas Karagiannis
- Antony I. T. Rowstron

**Microsoft Research, Cambridge, UK**

### Abstract
The soft real-time nature of large-scale web applications in today's datacenters, combined with their distributed workflow, necessitates the association of deadlines with datacenter application traffic. A network flow is useful and contributes to application throughput and operator revenue only if it completes within its deadline. Current transport protocols, including TCP, are agnostic to such flow deadlines and instead aim to share network resources fairly, which can negatively impact application performance.

Motivated by these observations and other known deficiencies of TCP in the datacenter environment, this paper introduces D3, a deadline-aware control protocol tailored for datacenter networks. D3 uses explicit rate control to allocate bandwidth based on flow deadlines. Evaluation on a 19-node, two-tier datacenter testbed shows that D3 outperforms TCP in terms of short flow latency and burst tolerance, even without any deadline information. By utilizing deadline information, D3 effectively doubles the peak load that the datacenter network can support.

**Categories and Subject Descriptors:** C.2.2 [Computer-Communication Networks]: Network Protocols

**General Terms:** Algorithms, Design, Performance

**Keywords:** Online services, Datacenter, SLA, Deadline, Rate control

## 1. Introduction
The proliferation of datacenters over the past few years has been driven by the rapid emergence of user-facing online services such as web search, retail, advertising, social networking, and recommendation systems. These services, while diverse in functionality, share common characteristics: they have soft real-time requirements and a partition-aggregate workflow.

### Soft Real-Time Nature
Online services must serve users in a timely fashion, leading to service level agreements (SLAs) that specify latency targets. User requests are processed within a specified latency target; if the time expires, responses, regardless of completeness, are sent. The completeness of responses directly affects their quality and, consequently, operator revenue. The horizontal scalability of these services involves partitioning tasks among multiple worker layers, whose results are aggregated to form the final response.

### Implications for Datacenter Traffic
Application latency targets cascade to workers at each layer, with common targets ranging from 10 to 100ms. This translates into deadlines for network flows initiated by these workers. For a flow to be useful, it must complete within its deadline.

### Current Limitations
Today's datacenter networks, rooted in Internet protocols, are oblivious to these implications. Congestion control (TCP) and flow scheduling mechanisms (FIFO queuing) are unaware of flow deadlines and focus on maximizing network throughput and fairness. This mismatch can severely impact application performance. Two illustrative examples:

- **Unfair Sharing:** Consider two flows sharing a bottleneck link, one with a tighter deadline. TCP strives for fairness, but only one flow may meet its deadline, wasting network resources on the non-contributing flow.
- **Flow Quenching:** In an application setting where multiple servers respond to an aggregator simultaneously, all flows share a bottleneck link and have the same deadline. If the aggregate capacity is insufficient, all flows will receive fair shares and miss the deadline. Given deadline information, some flows could be quenched to ensure others meet their deadlines.

### Challenges for Deadline-Aware Networks
Designing a deadline-aware datacenter network poses unique challenges:
1. **Flow-Level Deadlines:** All packets of a flow must arrive before the deadline.
2. **Deadline Variability:** Flows can have widely varying deadlines, making traditional scheduling solutions like EDF impractical.
3. **Short Flows and RTTs:** Most flows are very short (<50KB) with minimal RTTs (≈300µsec), requiring fast reaction times and lightweight mechanisms.

## 2. Background: Today’s Datacenters

### 2.1 Datacenter Applications
**Partition-Aggregate Model:** Large-scale web applications achieve horizontal scalability by partitioning tasks among worker machines. This model applies to various applications, including search, social networks, and recommendation systems.

**Application Deadlines:** Interactive web applications have strict latency requirements, typically an SLA of 200-300ms. Worker SLAs lead to deadlines for network flows carrying queries and responses. Missing these deadlines affects response quality and wastes network bandwidth, impacting operator revenue.

**Deadline Variability:** Processing times and flow sizes can vary significantly. Datacenter traffic includes short, time-sensitive messages and long background flows, contributing to deadline variability.

### 2.2 TCP in Datacenters
**Problems with TCP:** The use of TCP in datacenters is well-documented, with issues such as incast (severe drops in network throughput due to bursts of concurrent flows) and the negative impact on query-response latencies. These problems have led to artificial limitations on application design, with designers modifying workflows to address them.

**Recent Proposals:** New congestion control protocols and even UDP-based solutions aim to ensure low latency for short flows and good utilization for long flows. However, these do not inherently address the need for deadline awareness.

## 3. D3: A Deadline-Driven Delivery Protocol

### Design Overview
D3 is a deadline-aware control protocol that uses explicit rate control to allocate bandwidth based on flow deadlines. Applications expose flow deadline and size information at initiation. Endhosts request rates from routers along the data path, and routers allocate sending rates to greedily satisfy as many deadlines as possible.

### Key Features
- **Stateless Routers:** D3 does not require routers to maintain per-flow state. Instead, endhosts manage flow sending rates and rate policing.
- **Lease-Based Assignments:** Rate assignments behave like leases, unaffected by host or router failures.

### Contributions
- **Case for Deadline Awareness:** We present the case for using flow deadline information to apportion bandwidth in datacenters.
- **Design and Implementation:** We detail the design, implementation, and evaluation of D3, showing that it can double the peak load a datacenter can support.
- **Performance Benefits:** Even without deadline information, D3 outperforms TCP in supporting the mix of short and long flows typical in datacenter networks.

## 4. Evaluation
Evaluation on a 19-node, two-tier datacenter testbed demonstrates D3's superior performance in terms of short flow latency and burst tolerance. By leveraging deadline information, D3 effectively doubles the peak load that the datacenter network can support.

## 5. Conclusion
Tailoring datacenter network design to the soft real-time nature of applications is crucial. D3 represents a significant step towards a datacenter network stack optimized for application requirements, rather than a retrofitted Internet design.