title:Triangle inequality variations in the internet
author:Cristian Lumezanu and
Randolph Baden and
Neil Spring and
Bobby Bhattacharjee
Triangle Inequality Variations in the Internet
Cristian Lumezanu, Randy Baden, Neil Spring, Bobby Bhattacharjee
Department of Computer Science
University of Maryland
College Park, MD 20742
{lume, randofu, nspring, bobby}@cs.umd.edu
ABSTRACT
Triangle inequality violations (TIVs) are important for latency sen-
sitive distributed applications. On one hand, they can expose op-
portunities to improve network routing by ﬁnding shorter paths be-
tween nodes. On the other hand, TIVs can frustrate network em-
bedding or positioning systems that treat the Internet as a metric
space where the triangle inequality holds. Even though triangle
inequality violations are both signiﬁcant and curious, their study
has been limited to aggregate data sets that combine measurements
taken over long periods of time.
The limitations of these data sets open crucial questions in the
design of systems that exploit (or avoid) TIVs: are TIVs stable or
transient? Or are they illusions caused by aggregating measure-
ments taken at different times? We collect latency matrices at vary-
ing sizes and time granularities and study dynamic properties of tri-
angle inequality violations in the Internet. We show that TIVs are
not results of measurement error and that their number varies with
time. We examine how latency aggregates of data measured over
longer periods of time preserve TIVs. Using medians to compute
violations eliminates most of the TIVs that appear sporadically dur-
ing the measurement but it misses many of the ones that are present
for more than ﬁve hours.
Categories and Subject Descriptors
C.2.0 [Computer-communication networks]: Data communica-
tions; C.2.4 [Computer-communication networks]: Distributed
systems; C.4 [Performance of systems]: Measurement techniques;
H.4.3 [Information systems applications]: Communications ap-
plications
General Terms
Measurement, design
Keywords
TIV, triangle inequality violation, latency, variation
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
IMC’09, November 4–6, 2009, Chicago, Illinois, USA.
Copyright 2009 ACM 978-1-60558-770-7/09/11 ...$10.00.
1.
INTRODUCTION
End-to-end latencies in the Internet demonstrate triangle inequal-
ity violations (TIVs). TIVs affect network coordinate [1, 2] and
positioning [3] systems and latency-reducing overlays [4]. On one
hand, TIVs can be inconvenient for coordinate and positioning sys-
tems: because these applications treat the Internet as a metric space—
where TIVs are prohibited—inaccurate results may appear. On the
other hand, TIVs expose opportunities to improve network routing
by offering lower-latency one-hop detour [5] paths.
Existing studies on TIVs show that they are widespread and per-
sistent [6, 2, 7]. TIVs are not measurement artifacts, but a natural
consequence of the Internet routing [8, 9]. However, all evidence
about TIVs has been limited to aggregate latency data sets [2, 10,
11, 6, 3, 8, 7, 9] that combine measurements taken at different times
over long periods. These data sets fail to capture the variations of
triangle inequalities and may offer false illusions to applications
that rely on TIVs or the lack thereof. For example, representing
multiple measurements with their median values may reveal TIVs
that are short-lived in reality and thus not necessarily a threat for
network coordinates, or may miss long-lived TIVs that could be
exploited by overlay routing.
The limitations of these data sets open crucial questions for the
design of systems that exploit (or ﬁlter) TIVs: Are TIVs stable or
transient? Are they real or simply illusions caused by aggregating
measurements taken at different times? Are they caused by queuing
delay or load? And ﬁnally, is the performance of these systems
affected by the way data is aggregated?
In this paper, we aim to offer new insight into the properties of
triangle inequality violations in the Internet, as well as to provide
guidelines for better design and evaluation of the systems affected
by TIVs. We collect four new latency data sets of different sizes
and at varying time granularities. We show that the number of TIVs
varies with time and that, when aggregating multiple measurements
using medians or minimums, as all previous evaluations have done,
we underestimate the number of TIVs that existed at any point dur-
ing the measurement. We propose two additional measurement ag-
gregation techniques and discuss the advantages and disadvantages
in applying them in the evaluation of network coordinates and de-
tour routing.
Our contributions can be summarized as follows:
• we collect new data sets, of various sizes and granularities,
better suited for analyzing TIVs in a dynamic network envi-
ronment (§ 3);
• we present a new study on triangle inequality violations in
the Internet; we show that TIVs are real and not illusions of
measurements (§ 4) and that they vary with time (§ 5);
• we analyze four different methods of computing TIVs from
individual measurements and discuss their effects on the per-
17720 + 30 < 62
B
20
A
30
C
62
(a)
time   AB  BC  AC    TIV?
t1    103   40  135    no
t2     90    26  106    no
t3    135   25  139    no
med  103   26  135    yes
time   AB  BC  AC    TIV?
t1     78   47   140    yes
t2     98   15   135    yes
t3    100  50   166    yes
med   98   47   140    no
(b)
(c)
Figure 1: a) Example of triangle inequality violation, b,c) Median values can create the illusion of TIVs. Latencies for AB, BC and
AC are measured several times. We show the values at t1, t2 and t3. The ﬁnal data set is compiled from the medians: although at no
time-step is there a TIV among A, B and C, the medians indicate otherwise (b); alternatively, even if each measurement indicates the
presence of a TIV, the medians do not reﬂect it in the ﬁnal data set (c). All latencies are derived from real measurements.
formance of detour routing and network coordinate applica-
tions (§ 6).
2. MOTIVATION
A triangle inequality violation occurs among a triple of nodes in
the Internet when the latencies between them cannot form a valid
triangle. Figure 1(a) presents such a scenario. We call a triple of
nodes that violates the triangle inequality a bad triangle. In the bad
triangle ABC, AC is the long side while AB and BC are the short
sides. Alternatively, borrowing terminology from Detour [12, 5],
we refer to the path (A,B,C) as the detour path and to the path
(A,C) as the direct path.
TIVs are important for latency-sensitive distributed applications
such as network coordinate systems or latency-reducing overlay
routing. Network coordinates [2, 1] assign positions in a geometric
space to Internet hosts, such that the distance between the positions
estimates the real latency between hosts. Any three points that form
a bad triangle cannot be embedded accurately into a space that pro-
hibits TIVs—such as a geometric space. Thus, the more triangle
inequalities there are, the less precise the embedding is [13, 6].
Conversely, that network coordinates do not work well with metric
spaces can also be helpful [7]. Embedding errors expose shorter
paths between nodes and make them available for overlay routing.
Pairs of nodes that are long sides in bad triangles may beneﬁt from
detours; pairs that are short sides may be part of shorter detours.
These nodes can discover whether they form a long or short side
by simply computing the embedding distance to other nodes and
comparing it with the real network distance.
Existing evidence about TIVs is derived from aggregate all-to-
all latency data sets that combine many measurements [6, 2, 14, 8].
The ﬁnal latency between two nodes is obtained by taking the me-
dian [2] or the minimum [3, 8, 11] of measurements performed over
long periods of time such as days or even weeks. Although these
data sets are meant to reﬂect the real Internet latency space, they
may fail to accurately depict the characteristics of TIVs. Consider
an experiment that measures the latencies among nodes A, B and
C at regular intervals and computes the ﬁnal latency value for each
pair as the median of the measured values. In Figure 1, we show
values of latencies at three intervals, t1, t2, and t3, as well as the
median. These values are derived from real Internet experiments.
Although at no time during the measurement was there a triangle
inequality violation among A, B and C, the medians indicate oth-
erwise (Figure 1(b)). The opposite can also be true: the triple A, B
and C violates the triangle inequality at every time step, but this is
not reﬂected by the medians (Figure 1(c)).
Scenarios such as the ones above reveal the potential pitfalls of
reasoning about triangle inequality violations with aggregates of
data. Some TIVs may appear when computed with median values
A
nsA
2
1
3
S
B
nsB
rtt(A,B) = rtt(S,A,B)−rtt(S,A)
Figure 2: How King works: 1) S measures the RTT to the
closest recursive name server of A, nsA, 2) S sends a recursive
query through nsA for a domain resolved by a name server of
B, nsB and measures its round-trip time, 3) the latency between
A and B is estimated as the difference between the time taken
to perform the previous two operations.
Data set
K200-1000pairs-5min
K200-allpairs-1h
K200-allpairs-3h
K1715-allpairs-2d
Nodes (Pairs) Duration
Interval
200 (1000)
200 (all)
200 (all)
1715 (all)
24h
44h
30h
20d
5min
1h
3h
2d
Table 1: Latency data sets. For each set we show: a) the name,
b) the total number of nodes (and the number of pairs mea-
sured), c) the duration of the experiment, and d) the average
interval between consecutive measurements of the same pair.
All data sets were collected in the period March-April 2008.
for latency but may not be long-lived enough to be signiﬁcant. Fur-
ther, aggregates of data may not capture TIVs that, although do not
appear continuously during the data collection, may still be present
for enough time to be useful for an overlay routing network or to
cause embedding errors in coordinates.
3. METHODOLOGY
We use the King tool [15] to collect latency data sets that are
better suited for studying triangle inequality violations. King is
the only tool that estimates all-to-all round-trip times between any
hosts in the Internet.
3.1 King
King uses recursive DNS queries to estimate the latency between
two hosts in the Internet. Given the IP addresses of two nodes,
King computes the propagation delay between them as the delay
between authoritative name servers for those addresses. Figure 2
shows an example. A user located at S tries to estimate the latency
between hosts A and B. First, S measures the round-trip time to
178F
D
C
 1
 0.9
 0.8
 0.7
 0.6
 0.5
 0.4
 0.3
 0.2
 0.1
 0
K200-allpairs-1h
K200-1000pairs-5min
K200-allpairs-3h
 0
 20
 40
 60
latency (ms)
 80
 100
F
D
C
 1
 0.9
 0.8
 0.7
 0.6
 0.5
 0.4
 0.3
 0.2
 0.1
 0
K200-allpairs-1h
K200-1000pairs-5min
K200-allpairs-3h
 0
 20
 40
 60
latency (ms)
 80
 100
Figure 3: Cumulative distributions for left) Standard deviation and right) Interquartile range for three data sets
nsA, the closest recursive name server of A. In our measurements,
to minimize the error of estimation, we ensure that A and nsA are
in the same subnet. Then, S asks nsA to recursively resolve a name
served by a name server of B, nsB. The latency between nsA and
nsB is obtained by subtracting the times taken to perform the two
operations and represents an estimate of the latency between hosts
A and B.
King is the only tool that estimates all-to-all round-trip times
between any hosts in the Internet. Although King latencies have
been criticized for not being representative for latencies between
end hosts, our goal is not to verify these claims. For the purposes
of analyzing TIVs, we believe that King’s advantages outweigh its
shortcomings.
3.2 Data Sets
We collect four latency data sets of various sizes and at differ-
ent time granularities. The IP addresses of the nodes in our mea-
surements are of users participating in a ﬁle sharing application
and are available through the Vivaldi project [2]. The chosen IPs
share the same subnet with their authoritative name servers so that
better-connected DNS servers would not inﬂuence the estimates of
inter-client latencies.
We describe the properties of the data sets in Table 1. Our goals
are to collect data sets that are synchronous: all pairs of nodes are
measured at least once within a predeﬁned time interval. The size
of the interval determines the granularity of the data set. We use
four sampling intervals: 5 minutes, 1 hour, 3 hours and 2 days. At
the beginning of each interval, we run King for all pairs of nodes in
the data set from a computer at the University of Maryland. Each
individual King measurement consists of four consecutive probes,
out of which we keep the minimum value. Collecting latencies
at smaller time granularities provides more accurate snapshots of
the latency space. However, it also limits the number of pairs that
we can measure accurately, without unnecessarily loading the DNS
servers or the source computer. Thus, for the smaller granularities,
we limit the scope of the measurement to 200 IP addresses (1000
pairs chosen at random for the 5 minute interval and all pairs for
the 1 hour and 3 hour intervals). We collect a much larger data set
(1715 IP addresses) when the granularity is increased to two days.
Because we want to capture the dynamic properties of TIVs, we
present results only for the three data sets with ﬁner granularity.
4. LATENCY VARIABILITY
Latency variation on a path may lead to TIVs; conversely, if we
perceive latencies to be varying (when the underlying path is sta-
ble), we may assert the existence of fake TIVs. In the rest of this
section, we classify the causes of the recorded latency variations
in our measurements. We show that the chances of inferring fake
TIVs is small, and that most latency variation can be attributed to
changes in load or changes in routing.
4.1 Measurements Vary Over Time