We found no signiﬁcant diﬀerences in responses
based on the type of website being visited. We found
that respondents’ abilities to correctly explain each
warning was a predictor of behavior, though not in
the way we expected: respondents who understood
the domain mismatch warnings were less likely to
proceed whereas we observed the opposite eﬀect for
the expired certiﬁcate warnings. This suggests that
participants who understood the warnings viewed the
expired certiﬁcate warnings as low risk. Finally, we
found that risk perceptions were a leading factor in
respondents’ decisions and that many respondents—
regardless of expertise—did not understand the cur-
rent warnings. In this section we provide a detailed
analysis of our results in terms of warning compre-
hension and risk perceptions, the role of context, and
the role of expertise.
5All statistics were evaluated with α=0.05. We used a
Fisher’s exact test for all statistics where we report a p-value
only.
cate warnings were more likely to indicate that they
would ignore these warnings and proceed to the des-
tination website. These results are detailed in Ta-
ble 1 and indicate that users likely perceive less risk
when encountering an expired certiﬁcate, and there-
fore are likely to proceed. However, when encounter-
ing a domain mismatch warning, knowledgeable users
perceive greater risk and are likely to discontinue.
The three warnings that we examined are displayed
when the authenticity of the destination website’s
SSL certiﬁcate cannot be guaranteed. While each
of these warnings represents a diﬀerent underlying
error, they represent the same threat: the user may
not be communicating with the intended website or a
third party may be able to eavesdrop on her traﬃc. In
both cases, sensitive information may be at risk (e.g.
billing information when performing an online pur-
chase). In order to determine whether or not respon-
dents understood the threat model, we asked them
to list the possible consequences of ignoring each of
the warnings. Responses that speciﬁcally mentioned
fraud, identity theft, stolen credentials (or other per-
sonal information), phishing, or eavesdropping were
coded as being correct. We coded as correct 39% of
responses for FF2 warnings, 44% of responses for FF3
warnings, and 37% of responses for IE7 warnings.
Incorrect responses fell into two categories: respon-
dents who had no idea (or said there were no conse-
quences) and respondents who mentioned other se-
curity threats. Many of those in the latter category
mentioned viruses and worms. While it is possible
that a malicious website may exploit web browser
vulnerabilities or trick visitors into downloading mal-
ware, we considered these outside the scope of our
survey because they either impact only users of a spe-
ciﬁc browser version—in the case of a vulnerability—
or they rely on the user taking additional actions—
such as downloading and executing a ﬁle. Several re-
sponses mentioned malware but additionally claimed
that those using up-to-date security software are not
at risk. Others claimed they were not at risk due to
their operating systems:
“I use a Mac so nothing bad would happen.”
“Since I use FreeBSD, rather than Win-
dows, not much [risk].”
Figure 1: Participant responses to the question: If
you saw this message, would you attempt to continue
to the website?
3.2.1 Comprehension and Risk Perceptions
We were primarily interested in whether respondents
would continue to the destination website if they saw
a given warning. As shown in Figure 1, less than half
the participants claimed they would continue.
We expected to see diﬀerences in behavior for each
of the three types of warnings. In order for this to
be the case, participants needed to be able to distin-
guish each of the three warnings. We asked them to
explain what they thought each warning meant and
coded the answers in terms of whether or not they
were correct. As shown in Table 1, we discovered
that FF2 users were signiﬁcantly more likely to un-
derstand the domain mismatch warnings, while FF3
users were signiﬁcantly more likely to understand the
expired certiﬁcate warnings.
We explored warning comprehension further by ex-
amining whether those who understood the meaning
of the warnings were more likely to heed or ignore
them.
In general, we found that users who under-
stood the warnings tended to behave diﬀerently than
those who did not. Across all three browsers, users
who understood the domain mismatch warning were
more likely to say they would heed that warning than
users who did not understand it. In addition, FF3
and IE7 users who understood the expired certiﬁ-
NoMaybeYes  0  20  40  60  80  100IE7FF3FF2IE7FF3FF2IE7FF3FF2Percentage of RespondentsExpired CertificateUnknown CADomain Mismatchr
e
s
w
o
r
B
d
o
o
t
s
r
e
d
n
U
Expired Certiﬁcate
Unknown CA
Domain Mismatch
Ignored
Ignored
Ignored
FF2 Y 48
N 48
FF3 Y 55
N 62
Y 45
N 151
IE7
50% 71%
50% 56%
47% 64% χ2
2 = 21.05
53% 34% p < 0.0005
23% 53% χ2
2 = 11.81
77% 32%
p < 0.003
37
59
35
82
44
152
39%
61%
30%
70%
22%
78%
43%
49%
31%
34%
27%
32%
57
39
46
71
62
134
59% 19% χ2
2 = 9.40
41% 49% p < 0.009
39% 15% χ2
2 = 8.65
61% 41% p < 0.013
32% 16% χ2
2 = 7.50
68% 35% p < 0.024
Table 1: Participants from each condition who could correctly identify each warning, and of those, how
many said they would continue to the website. Diﬀerences in comprehension within each browser condition
were statistically signiﬁcant (FF2: Q2 = 10.945, p < 0.004; FF3: Q2 = 11.358, p < 0.003; IE7: Q2 = 9.903,
p < 0.007). For each browser condition, the ﬁrst line depicts the respondents who could correctly deﬁne the
warnings, while the second depicts those who could not. There were no statistically signiﬁcant diﬀerences
between correctly understanding the unknown CA warning and whether they chose to ignore it.
“On my Linux box, nothing signiﬁcantly
bad would happen.”
Of course, operating systems or the use of secu-
rity software do not prevent a user from submitting
form data to a fraudulent website, nor do they pre-
vent eavesdropping. We further examined risk per-
ceptions by asking participants to specify the likeli-
hood of “something bad happening” when ignoring
each of the three warnings, using a 5-point Likert
scale ranging from “0% chance” to “100% chance.”
We found signiﬁcant diﬀerences in responses to each
warning for all three web browsers: respondents con-
sistently ranked the expired certiﬁcate warning as be-
ing less risky than both of the other warnings. Table
2 depicts the perceived likelihood of risk for each of
the web browsers and each of the three SSL warnings.
To examine whether there were diﬀerences in risk
perception based on the underlying SSL error, we
asked respondents to quantify the severity of the con-
sequences of ignoring each of the SSL warnings using
a 5-point Likert scale that ranged from “none” to
“moderate” to “severe.” As shown in Table 3, we
found that respondents in every web browser condi-
tion were likely to assign signiﬁcantly lesser conse-
quences to ignoring the expired certiﬁcate warning
than when ignoring either of the other two warnings.
3.2.2 The Role of Expertise
Finally, we wanted to examine whether respondents’
level of technical expertise inﬂuenced their decisions
to heed or ignore the warnings. As described in Sec-
tion 3.1, we asked respondents a series of ﬁve ques-
tions to gauge their technical qualiﬁcations. We as-
signed each respondent a “tech score” corresponding
to the number of questions they answered aﬃrma-
tively. The ﬁrst column of Table 4 lists the average
scores for each of the web browser conditions. We
classiﬁed those with tech scores greater than or equal
to two as “experts.” The expert group represented
the top 16.7% of FF2 users, the top 26.5% of FF3
users, and the top 12.2% of IE7 users. We com-
pared our “experts” to the rest of our sample (i.e.
respondents with scores of zero or one) and found
that responses did not signiﬁcantly diﬀer in most
cases. We found signiﬁcant diﬀerences only among
FF3 users when viewing the unknown CA and do-
main mismatch warnings: experts were signiﬁcantly
less likely to proceed to the websites (Table 4).
Finally, we examined whether the experts were bet-
ter able to identify the individual warnings than the
rest of the sample. We found that while the experts
were more likely to identify the warnings than non-
Expired Certiﬁcate Unknown CA Domain Mismatch
FF2
FF3
IE7
37%
42%
47%
45%
52%
52%
54% χ2
50% χ2
53% χ2
2 = 25.19
2 = 13.47
2 = 12.79
p < 0.0005
p < 0.001
p < 0.002
Table 2: Mean perceptions of the likelihood of “something bad happening” when ignoring each warning,
using a 5-point Likert scale ranging from 0 to 100% chance. A Friedman test yielded signiﬁcant diﬀerences
for each browser.
Expired Certiﬁcate Unknown CA Domain Mismatch
2.29
2.32
2.34
1.70
1.96
2.14
2.10
2.36
2.36
FF2
FF3
IE7
χ2
χ2
χ2
2 = 20.49
2 = 9.00
2 = 16.90
p < 0.0005
p < 0.011
p < 0.0005
Table 3: Mean perceptions of the consequences of ignoring each of the three warnings, using a 5-point
Likert scale ranging from 0 to 4. A Friedman test shows that respondents in every web browser condition
were likely to assign signiﬁcantly lesser consequences to ignoring the expired certiﬁcate warning than when
ignoring either of the other two warnings.
experts, even in the best case, the experts were only
able to correctly deﬁne the expired certiﬁcate warn-
ings an average of 52% of the time, the unknown CA
warnings 55% of the time, and the domain mismatch
warnings 56% of the time. This indicates that either
our metric for expertise needs to be improved, or that
regardless of technical skills, many people are unable
to distinguish between the various SSL warnings.
3.2.3 Conclusion
Our survey showed how risk perceptions are corre-
lated with decisions to obey or ignore security warn-
ings and demonstrated that those who understand
security warnings perceive diﬀerent levels of risk as-
sociated with each warning. However, a limitation of
surveys is they collect participants’ self-reported data
about what they think they would do in a hypothet-
ical situation. Thus, it is useful to validate survey
ﬁndings with experimental data.
4.1 Methodology
We designed our laboratory study as a between-
subjects experiment with ﬁve conditions: FF2 (Fig-
ure 2(a)), FF3 (Figure 3), IE7 (Figure 2(b)), a single-
page redesigned warning (Figure 4(b)), and a multi-
page redesigned warning (Figure 4). We asked partic-
ipants to ﬁnd information using four diﬀerent types
of information sources. Each task included a pri-
mary information source—a website—and an alter-
nate source that was either an alternative website or
a phone number. The primary information source
for two of the tasks, the Carnegie Mellon University
(CMU) online library catalog and an online banking
application, were secured by SSL. We removed the
certiﬁcate authorities verifying these websites from
the trusted authorities list in each browser used in the
study.6 Therefore, participants were shown an invalid
certiﬁcate warning when they navigated to the library
and bank websites. We noted how users reacted to
these warnings and whether they completed the task
by continuing to use the website or by switching to
4 Laboratory Experiment
We conducted a laboratory study to determine the
eﬀect of SSL warnings on user behavior during real
tasks.
6Ideally we would have performed a man-in-the-middle at-
tack, for example by using a web proxy to remove the web-
sites’ legitimate certiﬁcates before they reached the browser.
However, due to legal concerns, we instead simulated a man-
in-the-middle attack by removing the root certiﬁcates from the
web browser.
Tech score
Expired
Unknown CA
Domain Mismatch
FF2
FF3
IE7
µ = 0.61 Experts
σ = 1.14 Non-Experts