3 log log (cid:96) + 146
8(cid:96) + 10
2 log (cid:96)((cid:96) + 2) + 3(cid:96) + 8
0
0
8(cid:96) + 7
4(cid:96) + 5k + 4 log k + 13
log (cid:96)(2(cid:96) − 3) − 11
log (cid:96)(2(cid:96) − 3) − 10
27(cid:96) + 3(log log (cid:96)) log (cid:96) + 18 log (cid:96) + 20k + 19
27(cid:96) + 3(log log (cid:96)) log (cid:96) + 18 log (cid:96) + 24k + 17
15(cid:96) + (log log (cid:96)) log (cid:96) + 15 log (cid:96) + 8k + 10
8(cid:96)2 + 9(cid:96) + (cid:96) log (cid:96) + (log (cid:96)) log log (cid:96) + 12k + 9
15(cid:96)2 + 90.5(cid:96) + 0.5(cid:96)(log (cid:96))(log log (cid:96)) +
3(log (cid:96)) log log (cid:96) + 0.5(cid:96)2 log (cid:96) + 11.5(cid:96) log (cid:96) +
4.5(cid:96)k + 28k + 2(cid:96) log k + 16 log k + 128
Table 6: Complexity of the employed SMPC tasks
Table 6 compares the complexities of the SMPC protocols introduced in § 2. The
complexity of SMPC protocols is generally measured in terms of two parameters: in-
teractive operations and rounds. An interactive operation involves every party sending
a message to every other party, while round complexity measures the number of se-
quential invocations of interactive operations. The additional local computations are
not included in the complexity. Note that the overhead to handle exceptions such as
overﬂow, underﬂow, invalid operation, division by zero is not included.
26
ID
Assumptions
Utility (error)
Crypto-scheme &
Perturbation
Mechanism
Adversary
type
Paillier scheme,
malicious aggr.,
Kind of queries
sum-statistics for
time-series data
(counting queries)
k = real #hon. users
Lap noise
no failure
2
γN )
 ( k
O( ∆
),
w.c.: O(N 2)
O( ∆
γ ),
√
w.c.: O(
 β( 1
2 ,
N )
−1),
O( ∆
−1)
w.c.: O(β( 1
˜O(−1(log N )1.5),
1
1−α )
2 , N )
√
w.c: ˜O(
Pollard’s Rho,
diluted∗ DLap noise
modulo-addition
scheme,
Lap noise
malicious aggr.,
failures
HbC aggr.
as above
as above
as above
N (log N )1.5)
Pollard’s Rho ,
diluted DLap noise
HbC aggr.,
failures
RN’10
[49]
SCRCS’11
[51]
AC’11
[6]
CSS’12
[19]
CRFG’12
[21]
ACHFG’12
[7]
#hon. users ≥ γN ,
bidirectional
communication
#hon. users ≥ γN
#failures ≤ αN ,
several keys to
store for user
#hon. users ≥ γN
no collusion
aggr.-publ.,
pre-establ. queries,
bidirectional
communication
as above
JK’12
[41]
no collusion
aggr.-auth.
hon. majority
between
√
O(
log N

)
O( ∆
 )
O( ∆
 )
Goldwasser-
Micali scheme,
binomial noise
Paillier scheme,
Lap noise
Paillier scheme ,
Shamir’s secret
sharing ,
DLap noise
SMPC,
HbC aggr.,
SQL-style queries
(yes/no answers
malicious publ.
per buckets)
as above
as above
malicious aggr.,
HbC auth.,
failures
linear queries for
time-series data
Lap, DLap noise,
multiple kinds
PrivaDA
of queries
∗ Diluted DLap noise: according to a certain probability p it follows the DLap distribution, otherwise it is set to 0.
computation parties
malicious aggr.
Expon. Mech.
O( ∆
 )
Table 7: Comparison between the existing DDP schemes
B Detailed Comparison with Related Work
0
Γ(x) =(cid:82) +∞
Table 7 compares some of the most important works about DDP with ours. Here,
N denotes the total number of users; ∆ is used to denote the sensitivity of the
respective query (see § 2); the function β(·,·) is deﬁned β(x, y) = Γ(x)Γ(y)
Γ(x+y) , where
xt−1e−xdx; γ is a lower bound on the fraction of honest users that we re-
quire as to guarantee DP; and α is an upper bound on the number of failures (i.e., data
that do not reach the aggregator) the system can accept. For the speciﬁcs of how the
noise for sanitization is generated for the individual approaches (i.e., use of Gaussian
or Gamma distributions to generate the Laplace noise) we refer to [36]. We note that
all papers in the table assume some compromised users (or computation parties), that
is, users that follow the protocol correctly but may collude with the aggregator, pass-
ing him some information like the noise they have added or their data. Furthermore,
the table speciﬁes whether third parties, such as data aggregators (aggr.) or website
publishers (publ.), are HbC or malicious (i.e., allowed to deviate from the protocol).
Utility. As the table demonstrates, a central drawback of all fully distributed models
we compare is the poor utility of the result, due to the fact that the amount of noise each
user has to add in order to satisfy privacy guarantees depends on other users’ behaviors
(i.e., the fraction of possibly malicious users and the probability of failure speciﬁed by
γ, α, which are supposed to be known in advance and that must not be exceeded so
27
as to achieve DP). The more users are falsely assumed to be malicious (i.e., small γ,
large k) the lower the ﬁnal accuracy in the worst case (w.c.). In PrivaDA, instead, the
noise is generated in a distributed fashion starting from a random seed, which is jointly
computed by the computation parties: diﬀerently from the fully distributed models,
the ﬁnal amount of noise obtained is exactly the one required to achieve DP (i.e., the
utility is optimal), irrespectively of the number of computation parties, the fraction of
honest entities, or the probability of failures.
Non-Collusion. Similarly to [7,21,41], PrivaDA relies on a non-collusion assumption,
but contrary to those approaches we distribute the trust not only amongst two, but
multiple parties (for which it suﬃces to assume an honest majority). In [41] an exten-
sion to the distributed case is proposed but the authors do not specify a method to
distributively generate the noise. We note that we use mutually distrustful computa-
tion parties to mitigate the computational eﬀort from the users, but that we could in
principle let the users directly execute the perturbation phase if external parties were
to be avoided.
Supported Queries. Another drawback, common to all previous models, is the re-
striction to speciﬁc queries and perturbation mechanisms. Most of the models described
above, indeed, consider only counting queries, where the function is limited to weighted
sums or even only supports sums, and use the Laplace or discrete Laplace mechanism
to perturb data. The exponential mechanism, allowing perturbation in case of non
numerical queries, is studied in [8]. They propose a method to securely apply it using
SMPC. However, the system they propose is valid only for a two-party setting, diﬀer-
ently from ours, that instead targets a multiparty scenario. By contrast, PrivaDA does
support all three of the above mechanisms, providing a uniform framework to answer
diﬀerent kinds of queries in a diﬀerentially private manner.
C Limitations of Finite-precision Instantiations
While the theoretical deﬁnition of sanitization mechanisms for DP operates on reals
r ∈ R (or integers z ∈ Z), the implementations of such mechanisms have to approximate
these mathematical abstractions by ﬁnite-precision representations due to the physical
limitations of actual machines. This mismatch has been shown to give rise to several
attacks, as pointed out by Mironov [45] and Gazeau et al. [32]. Mironov [45] shows that
the irregularities of ﬂoating point implementations result in porous Laplace distribu-
tions, thus undermining the privacy guarantees of ﬂoating point implementations of this
sanitization mechanism. He proposes the snapping mechanism, which truncates large
values and rounds the ﬁnal result so as to achieve DP of the implementation. Gazeau
et al. [32] show that, in general, approximation errors of any kind of ﬁnite-precision
representation of reals can lead to the disclosure of secrets. They provide a solution
to ﬁx such privacy breaches for a large class of sanitization mechanisms. The solution
is based on the concept of closeness and uses rounding and truncation to guarantee a
limited (but acceptable) variant of DP.
28
D Postponed Proof Sketches
D.1 Proof Sketch for Theorem 2
We start our analysis by proving t-secrecy for our protocols and then use this property
to prove -DDP. The SMPC arithmetic protocols over integers, ﬁxed and ﬂoating point
numbers internally use only two basic SMPC primitives over ﬁnite ﬁeld Fq, namely,
the addition and multiplication primitives for shared secret values from Fq. Due to the
linearity of the secret sharing protocol, addition can be performed locally for n > t;
however, multiplication requires one interaction among all parties for n ≥ 2t + 1. As-
suming secure instances of distributed addition and multiplication protocols over Fq [34]
(and secure protocols built on top of them), Aliasgari et al. [9] have proved the cor-
rectness and t-secrecy properties of the SMPC arithmetic protocols employed in our
mechanisms using Canetti’s composition theorem [17]. More formally, they suggested
that one can build a simulator for their arithmetic SMPC protocols by invoking sim-
ulators for the corresponding building blocks such that the resulting environment is
indistinguishable from the real protocol execution of participants.
The proof of t-secrecy for our protocols follows along the same lines, building a
simulator for each of the distributed DP mechanisms using the simulators for the un-
derlying ﬂoating point arithmetic SMPC protocols and the other building blocks, such
that the corresponding environment is indistinguishable from the corresponding real
distributed DP protocol execution.
The correctness and t-secrecy properties of our SMPC protocols allow us to lift the
DP analysis for the LM, DLM, and EM algorithms from § 3 to the corresponding SMPC
protocols. In particular, the correctness property ensures that the result is perturbed
as speciﬁed by the LM, DLM, and EM algorithms, while the t-secrecy of the SMPC
arithmetic protocols ensures that no information about user inputs and the noise is
available to the adversary controlling the t compromised computation parties.
D.2 Proof Sketch for Theorem 3
Since the computational veriﬁable secret sharing (VSS) scheme we use [48] enjoys the
perfect secrecy property, the t-secrecy analysis for the SMPC protocols in the mali-
cious setting remains almost the same as in the HbC setting. Nevertheless, the active
adversary can target the secure communication channels between the honest parties,
whose security relies on the decisional Diﬃe-Hellman assumption (or another stronger
Diﬃe-Hellman variant). However, an active adversary can only break channel secrecy
and consequently t-secrecy of SMPC protocols with a negligible probability (in κ).
The correctness of the computational SMPC protocols is also maintained in the
malicious setting up to a negligible probability in the security parameter κ: For a com-
putational VSS scheme, correctness requires the discrete logarithm assumption [48];
zero-knowledge (ZK) range proofs require the strong RSA assumption [16]; and ﬁnally,
the ZK proofs for the secure multiplication require the discrete logarithm assump-
tion [34].
29
As a result, using the correctness and t-secrecy properties of the computational
SMPC schemes we can lift the DP analysis for the LM, DLM, and EM algorithms
from § 3 to the corresponding SMPC-based protocol by only introducing an additive
negligible factor corresponding to the event that one of the above assumption is broken.
30