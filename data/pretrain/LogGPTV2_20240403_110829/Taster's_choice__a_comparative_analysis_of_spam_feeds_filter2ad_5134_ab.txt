but also may inadvertently collect legitimate correspondence
arising from the domain’s prior use. In general MX honeypots
have low levels of false positives, but since their accounts
are not in active use they will only tend to capture spam
campaigns that are very broadly targeted and hence have
high volume. Since high-volume campaigns are easier to
detect, these same campaigns are more likely to be rejected
by anti-spam ﬁlters. Thus, some of the most prevalent spam
in MX-based feeds may not appear frequently in Web mail
or enterprise e-mail inboxes.
Seeded honey accounts.
Like MX honeypots, seeded
honey accounts capture unsolicited e-mail to accounts whose
sole purpose is to receive spam (hence minimizing false posi-
tives). However, unlike MX honeypots, honey accounts are
created across a range of e-mail providers, and are not lim-
ited to addresses aﬃliated with a small number of domains.
However, since these e-mail addresses must also be seeded—
distributed across a range of vectors that spammers may use
to harvest e-mail address lists (e.g., such as forums, Web
sites and mailing lists)—the “quality” of a honey account
feed is related both to the number of accounts and how well
the accounts are seeded. The greater operational cost of
creating and seeding these accounts means that researchers
generally obtain honey account spam feeds from third parties
(frequently commercial anti-spam providers).
2However, see Section 4.1 for an example of domain poisoning
carried out by the Rustock botnet.
Honey accounts also have many of the same limitations
as MX-based feeds. Since the accounts are not active, such
feeds are unlikely to capture spam campaigns targeted using
social network information (i.e., by friends lists of real e-
mail users) or by mailing lists obtained from compromised
machines [14]. Thus, such feeds mainly include low-quality
campaigns that focus on volume and consequently are more
likely to be captured by anti-spam ﬁlters.
Human identiﬁed.
These feed are those in which hu-
mans actively nominate e-mail messages as being examples of
spam, typically through a built-in mail client interface (i.e.,
a “this is spam” button). Moreover, since it is primarily large
Web mail services that provide such user interfaces, these
datasets also typically represent the application of human-
based classiﬁcation at very large scale (in our case hundreds
of millions of e-mail accounts). For the same reason, human
identiﬁed spam feeds are not broadly available and their use
is frequently limited to large Web mail providers or their
close external collaborators.
Human identiﬁed spam feeds are able to capture “high qual-
ity” spam since, by deﬁnition, messages that users were able
to manually classify must also have evaded any automated
spam ﬁlters. As mentioned before, however, such feeds may
underrepresent the high-volume campaigns since they will
be pre-ﬁltered before any human encounters them. Another
limitation is that individuals do not have a uniform deﬁnition
of what “spam” means and thus human identiﬁed spam can
include legitimate commercial e-mail as well (i.e., relating
to an existing commercial relationship with the recipient).
Finally, temporal signals in human-identiﬁed spamfeeds are
distorted because identiﬁcation occurs at human time scales.
Domain blacklists.
Domain blacklists are the last cat-
egory of spam-derived data we consider and are the most
opaque since the method by which they are gathered is gen-
erally not documented publicly.3 In a sense, blacklists are
meta-feeds that can be driven by diﬀerent combinations of
spam source data based on the organization that maintains
them. Among the advantages of such feeds, they tend to be
broadly available (generally for a nominal fee) and, because
they are used for operational purposes, they are professionally
maintained. Unlike the other feeds we have considered, black-
lists represent domains in a binary fashion—either a domain
is on the blacklist at time t or it is not. Consequently, while
they are useful for identifying a range of spam-advertised
domains, they are a poor source for investigating questions
such as spam volume.
While these are not the only kinds of spam feeds in use
by researchers (notably omitting automatically ﬁltered spam
taken from mail servers, which we did not pursue in our
work due to privacy concerns), they capture some of the
most popular spam sources as well as a range of collection
mechanisms.
3.3 False Positives
No spam source is pure and all feeds contain false positives.
In addition to feed-speciﬁc biases (discussed above), there is
a range of other reasons why a domain name appearing in a
spam feed may have little to do with spam.
3However, they are necessarily based on some kind of real-time
spam data since their purpose is to identify spam-advertised do-
mains that can then be used as a dynamic feature in e-mail ﬁltering
algorithms.
429Feed
Type
Domains
Unique
Human identiﬁed
Hu
uribl Blacklist
dbl
Blacklist
mx1
MX honeypot
mx2
MX honeypot
mx3
MX honeypot
Seeded honey accounts
Ac1
Ac2
Seeded honey accounts
Botnet
Bot
Hyb
Hybrid
10,733,231
n/a
n/a
32,548,304
198,871,030
12,517,244
30,991,248
73,614,895
158,038,776
451,603,575
1,051,211
144,758
413,392
100,631
2,127,164
67,856
79,040
35,506
13,588,727
1,315,292
Table 1: Summary of spam domain sources (feeds)
used in this paper. The ﬁrst column gives the feed
mnemonic used throughout.
First, false positives occur when legitimate messages are
inadvertently mixed into the data stream. This mixing can
happen for a variety of reasons. For example, MX domains
that are lexically similar to other domains may inadvertently
receive mail due to sender typos (see Gee and Kim for one
analysis of this behavior [8]). The same thing can occur with
honeypot accounts (but this time due to username typos).
We have also experienced MX honeypots receiving legitimate
messages due to a user specifying the domain in a dummy
e-mail address created to satisfy a sign-up requirement for
an online service (we have found this to be particularly an
issue with simple domain names such as “test.com”).
The other major source of feed pollution is chaﬀ domains:
legitimate domains that are not themselves being advertised
but co-occur in spam messages.
In some cases these are
purposely inserted to undermine spam ﬁlters (a practice well
documented by Xie et al. [42]), in other cases they are simply
used to support the message itself (e.g., image hosting) or are
non-referenced organic parts of the message formatting (e.g.,
DTD reference domains such as w3.org or microsoft.com).
Finally, to bypass domain-based blacklists some spam mes-
sages will advertise “landing” domains that in turn redirect to
the Web site truly being promoted. These landing domains
are typically either compromised legitimate Web sites, free
hosting Web services (e.g., Google’s Blogspot, Windows Live
domains or Yahoo’s groups) or Web services that provide
some intrinsic redirection capability (e.g., bit.ly) [18]. We
discuss in more detail how these issues impact our feeds in
Section 4.1.
3.4 Meet the Feeds
Table 1 lists the feeds used in this study. We assign
each feed a concise label (e.g., Ac2) identifying its type,
as described earlier. Of these ten feeds, we collected mx1
and Bot directly. We receive both blacklist feeds (dbl and
uribl) by subscription. Provider agreements preclude us
from naming the remaining feeds (Ac1, mx2, Ac2, mx3, Hyb,
Hu). One feed, Hyb, we identify as a “hybrid.” We do not
know the exact collection methodology it uses, but we believe
it is a hybrid of multiple methods and we label it as such.
Referring to Table 1, the Domains column shows the total
number of samples we received from the feed during the
three-month period under consideration. Thus, the Hu feed
included only a bit over ten million samples, while the Bot
feed produced over ten times that number. The Unique
column gives the number of unique registered domain names
in the feed.
With the exception of the two blacklists, we collected the
feeds used in this paper in the context of the Click Trajec-
tories project [18] between August 1st, 2010 and October
31st, 2010. The Click Trajectories project measured the full
set of resources involved in monetizing spam—what we call
the spam value chain. One of the resources in the value
chain is Web hosting. To identify the Web hosting infrastruc-
ture, we visited the spam-advertised sites using a full-ﬁdelity
Web crawler (a specially instrumented version of Firefox),
following all redirections to the ﬁnal storefront page. We
then identiﬁed each storefront using a set of hand-generated
content signatures, thus allowing us to link each spam URL
to the goods it was advertising.
We use the results of this Web crawl to determine whether
a spam domain, at the time it is advertised, led to a live
Web site.4 Furthermore, we determined if this site was the
storefront of either a known online pharmacy selling generic
versions of popular medications, a known replica luxury
goods store, or a known “OEM” software store selling unli-
censed versions of popular software. These three categories
— pharmaceuticals, replica goods, software — are among the
most popular classes of goods advertised via spam [18, 20].
Based on this information, we refer to domains as live if at
least one URL containing the domain led to a live Web site,
and tagged if the site was a known storefront.
Finally, because we obtained the blacklist feeds after the
completion of the Click Trajectories work, we could not
systematically crawl all of their domains. Thus the entries
listed in the table only include the subset that also occurred
in one of the eight base feeds. While this bias leads us to
undercount the domains in each feed (thus underrepresenting
their diversity), this eﬀect is likely to be small. The dbl feed
contained 13,175 additional domains that did not occur in
any of our other base feeds (roughly 3% of its feed volume)
while the uribl feed contained only 3,752 such domains (2.5%
of its feed volume).
4. ANALYSIS
We set out to better understand the diﬀerences among
sources of spam domains available to the researcher or prac-
titioner. The value of a spam domain feed, whether used in
a production system for ﬁltering mail or in a measurement
study, ultimately lies in how well it captures the characteris-
tics of spam. In this paper we consider four qualities: purity,
coverage, proportionality, and timing.
Purity is a measure of how much of a feed is actually
spam domains, rather than benign or non-existent domains.
Coverage measures how much spam is captured by a feed.
That is, if one were to use the feed as an oracle for classifying
spam, coverage would measure how much spam is correctly
classiﬁed by the oracle.
Proportionality is how accurately a feed captures not
only the domains appearing in spam, but also their relative
frequency. If one were tasked with identifying the top 10
most spammed domains, for example, proportionality would
be the metric of interest.
Timing is a measure of how accurately the feed repre-
sents the period during which a domain appears in spam.
4With feeds containing URLs, we visited the received URL. Oth-
erwise, for feeds containing domains only, we prepended http://
to the domain to form a URL.
430Feed
DNS HTTP Tagged ODP Alexa
Hu
dbl
uribl
mx1
mx2
mx3
Ac1
Ac2
Bot
Hyb
88%
100%
100%
96%
6%
97%
95%
96%
<1%
64%