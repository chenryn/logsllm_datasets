---
author: Pk
category: 树莓派
comments_data: []
count:
  commentnum: 0
  favtimes: 0
  likes: 0
  sharetimes: 0
  viewnum: 16870
date: '2017-05-07 09:27:00'
editorchoice: false
excerpt: 今天我将向你展示对大数据的一点探索，不过有点变化，使用的是全世界最流行的微型电脑————树莓派
fromurl: 'https://dqydj.com/raspberry-pi-hadoop-cluster-apache-spark-yarn/ '
id: 8486
islctt: true
largepic: /data/attachment/album/201705/07/023744ysdd41g0e4g45d1k.jpg
permalink: /article-8486-1.html
pic: /data/attachment/album/201705/07/023744ysdd41g0e4g45d1k.jpg.thumb.jpg
related: []
reviewer: ''
selector: ''
summary: 今天我将向你展示对大数据的一点探索，不过有点变化，使用的是全世界最流行的微型电脑————树莓派
tags:
- 大数据
- Hadoop
- 树莓派
thumb: false
title: 大数据探索：在树莓派上通过 Apache Spark on YARN 搭建 Hadoop 集群
titlepic: true
translator: sfantree
updated: '2017-05-07 09:27:00'
---
![](/data/attachment/album/201705/07/023744ysdd41g0e4g45d1k.jpg)
有些时候我们想从 DQYDJ 网站的数据中分析点有用的东西出来，在过去，我们要[用 R 语言提取固定宽度的数据](https://dqydj.com/how-to-import-fixed-width-data-into-a-spreadsheet-via-r-playing-with-ipums-cps-data/)，然后通过数学建模来分析[美国的最低收入补贴](http://dqydj.com/negative-income-tax-cost-calculator-united-states/)，当然也包括其他优秀的方法。
今天我将向你展示对大数据的一点探索，不过有点变化，使用的是全世界最流行的微型电脑————[树莓派](https://www.raspberrypi.org/)，如果手头没有，那就看下一篇吧（可能是已经处理好的数据），对于其他用户，请继续阅读吧，今天我们要建立一个树莓派 Hadoop集群！
### I. 为什么要建立一个树莓派的 Hadoop 集群？
![](/data/attachment/album/201705/07/023809pk52e4yff97f2ke4.png)
*由三个树莓派节点组成的 Hadoop 集群*
我们对 DQYDJ 的数据做了[大量的处理工作](https://dqydj.com/finance-calculators-investment-calculators-and-visualizations/)，但这些还不能称得上是大数据。
和许许多多有争议的话题一样，数据的大小之别被解释成这样一个笑话：
> 
> 如果能被内存所存储，那么它就不是大数据。 ————佚名
> 
> 
> 
似乎这儿有两种解决问题的方法：
1. 我们可以找到一个足够大的数据集合，任何家用电脑的物理或虚拟内存都存不下。
2. 我们可以买一些不用特别定制，我们现有数据就能淹没它的电脑：  
—— 上手树莓派 2B
这个由设计师和工程师制作出来的精致小玩意儿拥有 1GB 的内存， MicroSD 卡充当它的硬盘，此外，每一台的价格都低于 50 美元，这意味着你可以花不到 250 美元的价格搭建一个 Hadoop 集群。
或许天下没有比这更便宜的入场券来带你进入大数据的大门。
### II. 制作一个树莓派集群
我最喜欢制作的原材料。
这里我将给出我原来为了制作树莓派集群购买原材料的链接，如果以后要在亚马逊购买的话你可先这些链接收藏起来，也是对本站的一点支持。(谢谢)
* [树莓派 2B 3 块](http://amzn.to/2bEFTVh)
* [4 层亚克力支架](http://amzn.to/2bTo1br)
* [6 口 USB 转接器](http://amzn.to/2bEGO8g)，我选了白色 RAVPower 50W 10A 6 口 USB 转接器
* [MicroSD 卡](http://amzn.to/2cguV9I)，这个五件套 32GB 卡非常棒
* [短的 MicroUSB 数据线](http://amzn.to/2bX2mwm)，用于给树莓派供电
* [短网线](http://amzn.to/2bDACQJ)
* 双面胶，我有一些 3M 的，很好用
#### 开始制作
1. 首先，装好三个树莓派，每一个用螺丝钉固定在亚克力面板上。（看下图）
2. 接下来，安装以太网交换机，用双面胶贴在其中一个在亚克力面板上。
3. 用双面胶贴将 USB 转接器贴在一个在亚克力面板使之成为最顶层。
4. 接着就是一层一层都拼好——这里我选择将树莓派放在交换机和USB转接器的底下（可以看看完整安装好的两张截图）
想办法把线路放在需要的地方——如果你和我一样购买力 USB 线和网线，我可以将它们卷起来放在亚克力板子的每一层
现在不要急着上电，需要将系统烧录到 SD 卡上才能继续。
#### 烧录 Raspbian
按照[这个教程](https://www.raspberrypi.org/downloads/raspbian/)将 Raspbian 烧录到三张 SD 卡上，我使用的是 Win7 下的 [Win32DiskImager](https://sourceforge.net/projects/win32diskimager/)。
将其中一张烧录好的 SD 卡插在你想作为主节点的树莓派上，连接 USB 线并启动它。
#### 启动主节点
这里有[一篇非常棒的“Because We Can Geek”的教程](http://www.becausewecangeek.com/building-a-raspberry-pi-hadoop-cluster-part-1/)，讲如何安装 Hadoop 2.7.1，此处就不再熬述。
在启动过程中有一些要注意的地方，我将带着你一起设置直到最后一步，记住我现在使用的 IP 段为 192.168.1.50 – 192.168.1.52，主节点是 .50，从节点是 .51 和 .52，你的网络可能会有所不同，如果你想设置静态 IP 的话可以在评论区看看或讨论。
一旦你完成了这些步骤，接下来要做的就是启用交换文件，Spark on YARN 将分割出一块非常接近内存大小的交换文件，当你内存快用完时便会使用这个交换分区。
（如果你以前没有做过有关交换分区的操作的话，可以看看[这篇教程](https://www.digitalocean.com/community/tutorials/how-to-add-swap-on-ubuntu-14-04)，让 `swappiness` 保持较低水准，因为 MicroSD 卡的性能扛不住）
现在我准备介绍有关我的和“Because We Can Geek”关于启动设置一些微妙的区别。
对于初学者，确保你给你的树莓派起了一个正式的名字——在 `/etc/hostname` 设置，我的主节点设置为 ‘RaspberryPiHadoopMaster’ ，从节点设置为 ‘RaspberryPiHadoopSlave#’
主节点的 `/etc/hosts` 配置如下：
```
#/etc/hosts
127.0.0.1       localhost
::1             localhost ip6-localhost ip6-loopback
ff02::1         ip6-allnodes
ff02::2         ip6-allrouters
192.168.1.50    RaspberryPiHadoopMaster
192.168.1.51    RaspberryPiHadoopSlave1
192.168.1.52    RaspberryPiHadoopSlave2
```
如果你想让 Hadoop、YARN 和 Spark 运行正常的话，你也需要修改这些配置文件（不妨现在就编辑）。
这是 `hdfs-site.xml`：
```
  fs.default.name
  hdfs://RaspberryPiHadoopMaster:54310
  hadoop.tmp.dir
  /hdfs/tmp
```
这是 `yarn-site.xml` （注意内存方面的改变）：
```
    yarn.nodemanager.aux-services
    mapreduce_shuffle
    yarn.nodemanager.resource.cpu-vcores
    4
    yarn.nodemanager.resource.memory-mb
    1024
    yarn.scheduler.minimum-allocation-mb
    128
    yarn.scheduler.maximum-allocation-mb
    1024
    yarn.scheduler.minimum-allocation-vcores
    1
    yarn.scheduler.maximum-allocation-vcores
    4
   yarn.nodemanager.vmem-check-enabled
   false
   Whether virtual memory limits will be enforced for containers
   yarn.nodemanager.vmem-pmem-ratio
   4
   Ratio between virtual memory to physical memory when setting memory limits for containers
yarn.resourcemanager.resource-tracker.address  
RaspberryPiHadoopMaster:8025  
yarn.resourcemanager.scheduler.address  
RaspberryPiHadoopMaster:8030  
yarn.resourcemanager.address  
RaspberryPiHadoopMaster:8040  
```
`slaves`：
```
RaspberryPiHadoopMaster
RaspberryPiHadoopSlave1
RaspberryPiHadoopSlave2