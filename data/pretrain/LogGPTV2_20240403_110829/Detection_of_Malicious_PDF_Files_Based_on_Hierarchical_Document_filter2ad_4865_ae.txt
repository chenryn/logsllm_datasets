pletely available to the attackers by means of reverse engi-
neering. In the remaining part of this section, we analyze
the potential impact of feature addition attacks on different
classiﬁcation algorithms deployed in our system.
In order to evade a decision tree classiﬁer, the attacker
has to modify his malicious ﬁle in such a way that will
change the decision path and result in a false negative.
To accomplish this, the attacker inspects the decision tree
and ﬁnds the exact decision which, lead to a terminal node
with the correct classiﬁcation as malicious. Then the at-
tacker must backtrack along this path and ﬁnd the ﬁrst non-
terminal node that leads directly to a terminal node with
the benign class if the test is positive. The test is positive
if a certain feature exists in the ﬁle (as is the case with bi-
nary embedding) or if a feature has a count larger than a
certain threshold (count embedding). In such case, it is usu-
ally straightforward for the attacker to “add” this feature
into the feature vector by adding appropriate content to the
PDF ﬁle. This forces the decision tree classiﬁer into mak-
ing the wrong decision. If the feature in question can not be
added to this ﬁle easily (some parts of the PDF structure are
strictly enforced) the attacker can continue the search for a
better choice of feature. If there are no positive decisions
on the path that lead directly to a benign terminal node but
to a subtree instead, the attacker can still modify his ﬁle,
insert such a feature, get a new decision path and repeat
the search procedure. This algorithm can be easily auto-
mated. We were able to empirically verify its effectiveness
by adding a previously nonexistent feature to a real-world
malicious PDF sample, which forced our decision tree to
misclassify it. Using random forests instead of single deci-
sion trees would make it computationally more challenging
to evade detection, but they are still exposed to the same
underlying problem.
A different attack strategy can be devised for the lin-
ear SVM. Recall that its decision function is computed as
y(x) = w⊤x − ρ. Parameters w and ρ are given by the
model while the attacker controls the input vector x. The
attacker’s goal is to change the prediction from positive
to negative. For the count embedding, this can be easily
achieved by picking the dimension j with the most negative
weight wj in the model and inserting ¯xj content chunks cor-
responding to the feature j such that y(x) becomes negative.
Simple algebra reveals that ¯xj = (y(x) − ρ)/wj. We have
successfully veriﬁed this evasion attack in practice. If the
most negative feature cannot be inserted or can only be in-
serted once, the attacker can ﬁnd the feature with the second
most negative weight, and so on. For the binary embedding,
the attacker must insert multiple features, but this is only a
minor practical constraint.
Evading an SVM with an RBF kernel presents a funda-
mentally harder problem than in the linear case. The reason
lies in the fact that the radial basis function is nonlinear,
which makes the task of modifying an input vector to yield
a negative result a nonconvex optimization problem. The
example that we successfully used for the evasion of lin-
ear SVM did not work for RBF. As a more potent strategy,
we decided to attempt evasion using a mimicry attack, by
masquerading malicious ﬁles to look benign. In our case,
this can be accomplished by copying all features of some
benign ﬁle into a malicious one. To verify the efﬁcacy of
this strategy in practice, we randomly sampled 5,000 mali-
cious and 5,000 benign training ﬁles, trained an RBF SVM
and then classiﬁed another randomly selected 5,000 ma-
licious and 5,000 benign test ﬁles. The benign ﬁle that
was classiﬁed with the greatest distance from the separat-
ing hyperplane; i.e., the one classiﬁed most conﬁdently as
benign, was chosen as a camouﬂage in order to maximize
the chance of a successful attack. We copied all the fea-
tures of this ﬁle to all the 5,000 malicious feature vec-
tors in the test set. As a result, the number of false nega-
tives increased from 28 to 30; i.e., the strongest conceivable
mimicry attack added only 2 misclassiﬁcations in 5,000 ex-
amples (0.025%)! For the linear SVM in the same setting,
the mimicry attack was able to decrease detection accuracy
to about 50%. This experiment practically demonstrates the
strong resistance of RBF SVMs to mimicry attacks.
7 Discussion
The experimental evaluation and the analysis of potential
evasion techniques presented above unequivocally demon-
strate that the structure of PDF documents bears a strong
discriminative power for detecting malicious documents.
This ﬁnding is quite surprising given the fact that the struc-
tural difference is only a side-effect of the presence of ma-
licious content. Although, in principle, it can be expected
that attackers may ﬁnd a way to camouﬂage malicious con-
tent within a benign structure, our experiments with several
evasion strategies suggest that this task may be harder than
one thinks. The most aggressive evasion strategy we could
conceive was successful for only 0.025% of malicious ex-
amples tested against an off-the-shelf nonlinear SVM clas-
siﬁer with the RBF kernel using the binary embedding. Cur-
rently, we do not have a rigorous mathematical explanation
for such a surprising robustness. Our intuition suggests that
the main difﬁculty on attacker’s part lies in the fact that the
input features under his control, i.e., the structural elements
of a PDF document, are only loosely related to the true fea-
tures used by a classiﬁer. The space of true features is “hid-
den behind” a complex nonlinear transformation which is
mathematically hard to invert. This observation is corrob-
orated by the fact that the same attack staged against the
linear classiﬁer with binary embedding had a 50% success
rate; hence, the robustness of the RBF classiﬁer must be
rooted in its nonlinear transformation.
The comparison of interpretations of learned models
with the success of evasion attacks leads us to the hypoth-
esis that explainability and robustness against evasion are
antagonistic qualities of learning methods. Indeed, the most
naturally explained method, the decision tree, was the most
trivial one to evade. In fact, the evasion of decision trees
is so trivial that we would not recommend their use for
any security-related applications. The linear SVM, whose
model is relatively well interpretable (see, e.g., [30, 31] for
exemplary interpretations of linear SVM in security appli-
cations), is attackable with a moderate effort. On the other
hand, SVM with the RBF kernel, which exhibited the best
robustness, is almost impossible to interpret. Further re-
search effort is needed to better understand such trade-offs
for speciﬁc learning methods and for development of prac-
tical compromises.
8 Conclusions
We have proposed a novel method for the detection of
malicious PDF ﬁles based on the difference between the un-
derlying structural properties of benign and malicious PDF
ﬁles. By relying on structure instead of the actual content, it
renders it unnecessary to deal with the very expressive PDF
obfuscation techniques, interpretation of JavaScript and dy-
namic execution – hard problems with which related meth-
ods continue to struggle – and reaps the beneﬁts of remain-
ing a static method: very high throughput and robustness.
Experimental evaluation has demonstrated excellent be-
havior of our method in both laboratory and operational
experiments on a very large dataset of around 660,000 be-
nign and malicious PDF ﬁles. It compares favorably to re-
cent related work from the literature (PJSCAN, MDSCAN,
SHELLOS and MALWARE SLAYER). The proposed method
has proved to be very effective against novel attacks, main-
taining the high detection accuracy even on real PDF mal-
ware ﬁrst seen more than two months after the classiﬁca-
tion model was created. A 10-week operational deployment
in real-world conditions with weekly retraining has demon-
strated an excellent performance of the proposed method,
while also showing its difﬁculty to handle sudden changes
in attack patterns in a timely manner. Techniques for im-
proving its performance on strongly nonstationary data will
be investigated in future work.
Computational efﬁciency of the proposed methods is
on par with the fastest previously known static detection
method (PJSCAN) and attains the throughput of 169 Mbit/s.
Such performance is an order of magnitude higher than that
of hybrid static/dynamic methods and almost two orders of
magnitude higher than established dynamic detection meth-
ods. Thanks to the high efﬁciency of the proposed method,
a 150 GB dataset collected from VIRUSTOTAL and Google
search could be processed in two hours.
In our analysis of potential evasion strategies, we have
speciﬁcally focused on the feature addition attack scenario,
in which an attacker is limited in his ability to remove mali-
cious content but is free to add benign content to avoid de-
tection. Our analysis and experimental evaluation showed
than some classiﬁers that were deployed in our framework,
such as decision trees and linear SVM, can be easily de-
feated by feature addition, whereas others, such as SVM
with the RBF kernel, are almost immune to sophisticated
attack scenarios.
The ﬁndings presented in this paper reveal several im-
portant open issues. The surprising fact that the structure of
PDF documents delivers strong indicators for the presence
of malicious content calls for a deeper investigation of the
syntax of the PDF format to understand the correlation of
its speciﬁc features with semantics of known attacks. Such
investigation should also address further potential evasion
strategies against structure-based detection methods. While
our experiments showed that some non-linear classiﬁcation
algorithms can be robust against feature addition attacks,
detailed consideration of the PDF semantics is essential for
understanding of content modiﬁcation or feature removal
attacks.
References
[1] P. Akritidis, E. Markatos, M. Polychronakis, and K. Anag-
nostakis. STRIDE: Polymorphic sled detection through in-
struction sequence analysis. In 20th International Confer-
ence on Information Security, pages 375–392, 2005.
[2] M. Barreno, B. Nelson, A. Joseph, and J. Tygar. The secu-
rity of machine learning. Machine Learning, 81(2):121–148,
2010.
[3] M. Barreno, B. Nelson, R. Sears, A. Joseph, and J. Tygar.
Can machine learning be secure? In ACM Symposium on
Information, Computer and Communication Security, pages
16–25, 2006.
[4] C. M. Bishop. Pattern Recognition and Machine Learning.
Springer, 2007.
[5] L. Breiman, J. Friedman, J. Olshen, and C. Stone. Classiﬁ-
cation and Regression Trees. Wadsworth, 1984.
[6] D. Canali, M. Cova, G. Vigna, and C. Kruegel. Prophiler:
a fast ﬁlter for the large-scale detection of malicious web
pages.
In International Conference on World Wide Web
(WWW), pages 197–206, 2011.
[7] W. Cohen. Fast effective rule induction.
In International
Conference on Machine Learning (ICML), pages 115–123,
1995.
[8] C. Cortes and V. Vapnik. Support vector networks. Machine
Learning, 20:273–297, 1995.
[9] M. Cova, C. Kruegel, and G. Vigna. Detection and analysis
of drive-by-download attacks and malicious JavaScript code.
In International Conference on World Wide Web (WWW),
pages 281–290, 2010.
[10] C. Curtsinger, B. Livshits, B. Zorn, and C. Seifert. ZOZ-
ZLE: Fast and precise in-browser JavaScript malware detec-
tion. In USENIX Security Symposium, pages 33–48, 2011.
[11] M. Engelberth, C. Willems, and H. T. MalOfﬁce – analysis
of various application data ﬁles. In Virus Bulletin Interna-
tional Conference, 2009.
[12] G. Gu, P. Porras, V. Yegneswaran, M. Fong, and W. Lee.
BotHunter: Detecting malware infection through IDS-
driven dialog correlation. In USENIX Security Symposium,
pages 167–182, 2007.
[13] Google warns of using adobe reader - particularly on
http://www.h-online.com/open/news/item/Google-
linux.
warns-of-using-Adobe-Reader-particularly-on-Linux-
1668153.html.
[14] T. Hastie, R. Tibshirani, and J. Friedman. The Elements of
Statistical Learning: data mining, inference and prediction.
Springer series in statistics. Springer, New York, N.Y., 2009.
2nd edition.
[15] Vorsicht
bei
angeblicher
telekom-onlinerechnung.
http://heise.de/-1545909.
[16] S. Jana and V. Shmatikov. Abusing ﬁle processing in mal-
In IEEE Symposium on
ware detectors for fun and proﬁt.
Security and Privacy, pages 80–94, 2012.
[17] S. Kaplan, B. Livshits, B. Zorn, C. Siefert, and C. Cursinger.
“nofus: Automatically detecting” + string.fromcharcode(32)
+ “obfuscated ”.tolowercase() + “javascript code”. Technical
report, Microsoft Research, 2011.
[18] P. Laskov and M. Kloft. A framework for quantitative secu-
rity analysis of machine learning. In Proceedings of the 2nd
ACM Workshop on AISec, pages 1–4, Nov. 2009.
[19] P. Laskov and N. ˇSrndi´c. Static detection of malicious
JavaScript-bearing PDF documents.
In Annual Computer
Security Applications Conference (ACSAC), pages 373–382,
2011.
[20] W. Lee, S. Stolfo, and K. Mok. A data mining framework
for building intrusion detection models. In IEEE Symposium
on Security and Privacy, pages 120–132, 1999.
[21] W.-J. Li, S. Stolfo, A. Stavrou, E. Androulaki, and
A. Keromytis. A study of malcode-bearing documents. In
Detection of Intrusions and Malware & Vulnerability As-
sessment (DIMVA), pages 231–250, 2007.
[22] M. Mahoney and P. Chan. Learning rules for anomaly detec-
tion of hostile network trafﬁc. In International Conference
on Data Mining (ICDM), 2003.
[23] D. Maiorca, G. Giacinto, and I. Corona. A pattern recogni-
tion system for malicious pdf ﬁles detection. pages 510–524,
2012.
[24] T. V. Overveldt, C. Kruegel, and G. Vigna. FlashDetect:
ActionScript 3 malware detection. In Recent Adances in In-
trusion Detection (RAID), pages 274–293, 2012.
[25] PDF Reference.
http://www.adobe.com/devnet/pdf/pdf reference.html,
2008.
[26] M. Polychronakis, K. Anagnostakis, and E. Markatos. Com-
prehensive shellcode detection using runtime heuristics. In
Annual Computer Security Applications Conference (AC-
SAC), pages 287–296, 2010.
[27] N. Provos, P. Mavrommatis, M. Abu Rajab, and F. Monrose.
All your iFRAMEs point to us. In USENIX Security Sympo-
sium, pages 1–16, 2008.
[28] J. Quinlan. C4.5: Programs for Machine Learning. Morgan
Kaufmann, 1992.
[29] Blackhole
crimeware
kit
spike.
sophos fakeav conﬁcker/.
threat
http://www.theregister.co.uk/2012/01/26/
drives
web
[30] K. Rieck, T. Holz, K. Willems, P. D¨ussel, and P. Laskov.
Learning and classiﬁcation of malware behavior.
In De-
tection of Intrusions and Malware & Vulnerability Assess-
ment (DIMVA), 5th International Conference, pages 108–
125, July 2008.
[31] K. Rieck, T. Kr¨uger, and A. Dewald. Cujo: Efﬁcient de-
tection and prevention of drive-by-download attacks. In An-
nual Computer Security Applications Conference (ACSAC),
pages 31–39, 2010.
[32] Z. Shaﬁq, S. Khayam, and M. Farooq. Embedded malware
detection using markov n-grams. In Detection of Intrusions
and Malware & Vulnerability Assessment (DIMVA), pages
88–107, 2008.
[33] C. Smutz and A. Stavrou. Malicious PDF detection using
metadata and structural features. In Annual Computer Secu-
rity Applications Conference (ACSAC), 2012. To appear.
[34] K. Z. Snow, S. Krishnan, F. Monrose, and N. Provos. Shel-
lOS: Enabling fast detection and forensic analysis of code
injection attacks. In USENIX Security Symposium, 2011.
[35] PDF malware writers
keep
targeting
vulnerability.
http://www.symantec.com/connect/blogs/pdf-malware-
writers-keep-targeting-vulnerability.
[36] T. Toth and C. Kruegel. Accurate buffer overﬂow detection
via abstract payload execution. In Recent Adances in Intru-
sion Detection (RAID), pages 274–291, 2002.
[37] Z. Tzermias, G. Sykiotakis, M. Polychronakis,
and
E. Markatos. Combining static and dynamic analysis for the
detection of malicious documents. In European Workshop
on System Security (EuroSec), 2011.
[38] C. Willems, T. Holz, and F. Freiling. CWSandbox: Towards
automated dynamic binary analysis. IEEE Security and Pri-
vacy, 5(2):32–39, 2007.