accounts deleting their comments and submissions after the
fact to avoid detection. TROLLMAGNIFIER looks for evidence
of accounts deleting their comments and submissions by
comparing the data collected from the Pushshift API data with
real-time data retrieved from the Reddit API.
Creation Date. Many troll accounts are created in waves,
which means that
they have the same creation date [74].
To check for this, TROLLMAGNIFIER extracts the creation
date of detected accounts from Reddit, and groups detected
accounts together with known troll accounts based on this date.
Accounts that were created on the same day as known troll
accounts have a much higher chance to be actual trolls.
Topics Discussed. As discussed in previous work [47, 74, 75],
troll accounts push speciﬁc narratives and common talking
points, which often reﬂect the geopolitical interests of the
countries that control them. To analyze this aspect at an indi-
vidual account granularity, we ﬁrst identify the most important
words shared by known troll accounts, and then check whether
an account detected as a troll by TROLLMAGNIFIER posted
about any of these words. To do this, we calculate the TF-IDF
(Term Frequency-Inverse Document Frequency) of the corpus
of messages shared by known troll accounts [29]. We then
select the top 10 keywords identiﬁed by this approach as a
proxy for the important narratives shared by known trolls, and
check if a detected account included each of those keywords
in any of their submissions or comments.
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 13:00:10 UTC from IEEE Xplore.  Restrictions apply. 
2165
Group-level indicators. In addition to looking at accounts at
an individual level, TROLLMAGNIFIER analyzes all detected
accounts as a whole, to help identify patterns of coordinated
inauthentic activity. In particular, we build language models
on the comments posted by known and detected accounts as
well as analyzing posting time patterns between the two sets
of accounts.
Language Analysis. To further analyze the language used by
detected troll accounts, TROLLMAGNIFIER builds language
models based on word embeddings from the posts made by
Reddit accounts, aiming to compare the language used by the
detected troll accounts to that of known troll accounts and of
undetected accounts. This allows us to measure the similarity
between the language used by known troll accounts, detected
troll accounts, and other accounts, to investigate whether the
detected troll accounts indeed use language that is closer to
the known set of troll accounts.
Time Series Evaluation. Troll accounts often carry out their
disinformation campaigns at speciﬁc points in time [75],
thus,
they will show similar activity pat-
terns. TROLLMAGNIFIER builds time series for known troll
accounts, detected troll accounts, and non-troll accounts. It
then computes correlation and lag between the time series to
conﬁrm that detected accounts show higher coordination with
known troll accounts as compared to non-troll accounts.
is likely that
it
V. EVALUATION
In this section, we present the results of our experiments
running our Reddit dataset through TROLLMAGNIFIER. We
ﬁrst discuss the results for each of TROLLMAGNIFIER’s anal-
ysis steps, from pre-ﬁltering to validation. We then present
additional experiments to estimate TROLLMAGNIFIER’s false
negatives. Finally, we report results on the run-time perfor-
mance of TROLLMAGNIFIER.
A. Pre-ﬁltering
As discussed in Section IV-A, TROLLMAGNIFIER ﬁrst
identiﬁes a set of suspicious accounts that present one of these
traits: 1) posted the same submission title as troll accounts,
or 2) commented on submissions made by troll accounts.
TROLLMAGNIFIER found 12,143 accounts that posted the
same submission titles as troll accounts and 42,001 accounts
that comment on submissions made by troll accounts. There
is an intersection of 381 accounts between the two categories.
In total, this yields 53,763 accounts that are further analyzed.
B. Building threads
We extract the comments and submissions of these accounts
from the Reddit data published by Pushshift. The comments
and submissions are used to calculate features to train the
classiﬁer. In total, we collect 161,906,549 submissions and
938,852,501 comments made by the suspicious accounts.
Then, we build the thread structure for all submissions troll
accounts commented on, resulting in 159,255 threads with an
average depth of 2.69 and a median of 2.
Classiﬁer
KNN
Linear SVM
Decision Tree
Random Forest
Precision Recall Accuracy F1-Score
91.8%
91.9% 91.7%
95.6%
95.7% 95.5%
97.3% 97.3%
97.3%
97.8% 97.7% 97.8% 97.8%
91.8%
95.5%
97.3%
TABLE I: Classiﬁcation performance of TROLLMAGNIFIER
on a 10-fold cross validation over a dataset of 335 troll
accounts and 335 likely benign ones.
C. Building the Detection Model
We extract a balanced dataset for training, with the set
of 335 known troll accounts as the positive class and a
random set of 335 accounts from the pre-ﬁltered dataset as
the negative class. The reason we select accounts from the
pre-ﬁltered dataset instead of random Reddit accounts is to
avoid over-ﬁtting and to train a classiﬁer geared to pick up
subtle differences between the behavior of troll and non-troll
accounts. Without doing so, TROLLMAGNIFIER would likely
learn to ﬂag any account that ever interacted with a known
troll as malicious. When selecting the random accounts for
the negative class, we also ensure that these are not suspended
by Reddit, to reduce the chances of them being troll accounts.
As discussed in Section IV-C, we experiment with four
classiﬁers: KNN, Decision Tree, Linear SVM, and Random
Forest. To select the classiﬁer best suited for the task, we
perform 10-fold cross-validation. We evaluate the performance
of each classiﬁer based on accuracy, precision, recall, and F1-
score. Table I reports the average results using 10-fold cross-
validation for each classiﬁer. Although all classiﬁers perform
well overall, Random Forest performs the best, achieving an
F1-score of 97.8%. Consequently, we use Random Forest
for the detection model of TROLLMAGNIFIER, training on
the whole training set of 335 troll and 335 random Reddit
accounts.
D. Detection in the Wild
After training, we run TROLLMAGNIFIER on the dataset
of 53,763 suspicious accounts to detect more troll accounts.
This results in identifying 1,248 accounts as trolls. In the next
section, we provide further evidence that these accounts are
likely to be troll accounts.
E. Validation — Account-level Indicators
As explained in Section IV-E, as a ﬁrst step, TROLLMAG-
NIFIER checks each detected account individually for four
indicators.
Active Status. As discussed previously, an account’s sus-
pension is further evidence that
is indeed a
troll. To check whether an account exists on Reddit, we can
look up reddit.com/u/.json. If the account was
suspended, we get a 403 HTTP error; if it was deleted, the
HTTP error code is 404. We ﬁnd that 298 out of the 1,248
accounts were either suspended or deleted.
the account
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 13:00:10 UTC from IEEE Xplore.  Restrictions apply. 
2166
Deleted Messages. We use PRAW: The Python Reddit API
Wrapper [41] to query all comments and submissions of
detected trolls that are visible on their Reddit page as of April
14, 2021. We then compare the number of comments and
submissions for each detected troll account with those present
in the data that we previously collected from the Pushshift
API. Our results show that 304 out of the 1,248 detected trolls
have deleted at least a comment or a submission, with 21
accounts having deleted all their comments and submissions.
It is important to note that PRAW only returns the last 1,000
comments/submissions, therefore we only count a deletion
if PRAW returns less than 1,000 elements. There are 14
accounts that hit the API limitation. Also, we exclude the 298
deleted/suspended accounts because PRAW returns an error
code for them.
Creation Date Analysis. We collect the Cake Day (or Account
Creation Date) from the Reddit user’s page of each of the
known and detected troll accounts. This excludes deleted and
suspended accounts as their user page is not accessible on
Reddit. However, the user page of known troll accounts is still
accessible, despite the suspension, as Reddit left them open for
research purposes. We cluster the accounts by their creation
dates and ﬁnd that 66 out of the 1,248 detected accounts
belong to troll clusters making them highly suspicious.
Topic Discussed. To identify relevant words discussed by
the known trolls, we calculate the TF-IDF (Term Frequency-
Inverse Document Frequency) of the corpus of submissions
and comments that they posted [29]. The TF is calculated on
the known troll account dataset and the IDF on the entire
dataset of 53,763 accounts. Table II reports the list of top 10
words shared by known trolls by this metric. We then look
at whether each of the 1,248 detected accounts has posted a
submission or comments containing one of those keywords.
We ﬁnd that 359 of the detected accounts have at least one
post containing one of the top 10 keywords shared by known
trolls, indicating that they might be trying to push the same
narratives as the seed set.
Summary. Out of the 1,248 accounts detected, 298 have
been suspended/deleted, 304 deleted some of their com-
ments/submissions, 66 were created on the same day as known
troll accounts, and 359 posted a comment or submission
containing one of top 10 keywords pushed by known troll
accounts. Overall, 824 accounts satisﬁed at least one of four
conditions, accounting for 66% of the 1,248 detected accounts.
195 accounts satisfy two of the four conditions, 8 accounts
satisfy three, and none of the accounts satisfy four.
F. Validation — Group-level Indicators
As discussed, in addition to looking at detected accounts
in isolation, TROLLMAGNIFIER also analyzes the group of
detected accounts collectively, to uncover additional insights
on their coordination and provide further evidence that they are
part of inﬂuence operations. In the following, we ﬁrst analyze
the language used by the detected accounts compared to the
known trolls; then, we look at the timing of their activity on
Reddit.
Word Detected Trolls and Non-Trolls and Z-score P-Value
Known Trolls
Known Trolls
people
money
crypto
bitcoin
country
police
black
news
cop
trump
0.53
0.35
0.25
0.12
0.12
0.12
0.11
0.08
0.08
0.08
0.01
0.00
0.01
0.01
0.02
0.00
0.00
0.00
0.01
0.00
7.55 <.00001
4.38 <.00001
2.12
1.27
1.58
1.53
1.63
1.57
0.82
1.48
0.03
0.20
0.11
0.13
0.10
0.12
0.41
0.14
TABLE II: For each keyword, we obtain a vector of top-
100 similar words from the word embeddings. The cosine
similarity between the vectors of detected troll accounts and
known troll accounts is higher for each keyword. The z-score
and the corresponding p-value is also given.
Language Analysis. We use Natural Language Processing
techniques to analyze the content of posts made by Reddit
accounts, aiming to provide extra evidence that the detected
accounts likely belong to inﬂuence campaigns. This is partic-
ularly relevant, as TROLLMAGNIFIER is content-agnostic and
does not look at the content posted by accounts. Therefore,
ﬁnding language similarities at this stage of the analysis is a
strong indicator that the detected accounts belong to the same
disinformation campaigns as the set of known trolls.
To this end, we ﬁrst
train word2vec models on three
corpora, each including submissions and comments posted
by: 1) known troll accounts, 2) detected troll accounts, and
3) accounts from the set of 53,763 accounts that were not
detected as trolls by TROLLMAGNIFIER. For our word2vec
models, we use Continuous Bag Of Words (CBOW), with a
window size of 20, using the Python gensim library [18].
In the previous section, we discussed how we identify a set
of the most relevant words shared by known troll accounts
for further validation. At this step, we use this list of relevant
words to further study the use of language by detected troll
accounts. For each of these words, we compute the similarity
between the trained word embeddings by using the method
from Vivek et al. [26]. Since the word embeddings are trained
on different corpora, they have unique vector spaces which
cannot be directly compared. Therefore, for each keyword,
we extract the Top-100 most similar words to it and represent
them as a vector calculated from the word embeddings.