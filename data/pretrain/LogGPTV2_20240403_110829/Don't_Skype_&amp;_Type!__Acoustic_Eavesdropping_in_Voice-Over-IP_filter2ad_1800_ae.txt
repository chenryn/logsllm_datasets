ing scenario, where we have a top-5 accuracy around 40%,
we need 7.79· 1012 tries to reach 50% probability of cracking
the password, which is still one order of magnitude better
than plain brute-force attacks, on average. There is simi-
lar tendency if the attack guesses ten characters for every
character of the password.
2 = 8.39 · 1013 guesses to have
6. POSSIBLE COUNTERMEASURES
In this section, we present and discuss some potential
countermeasures and analyze their eﬃcacy in preventing
S&T and other attacks that use statistical properties of the
sound spectrum.
One simple countermeasure is a short “ducking” eﬀect, a
technique that drastically lowers microphone volume and
overlaps it with a diﬀerent sound, whenever a keystroke is
detected. However, this approach can degrade voice call
quality. Ideally, an eﬀective countermeasure should be min-
imally intrusive and aﬀect only keystroke sounds.
-20dB-15dB-10dB-5dB+0dB+5dB+10dB+15dB+20dBVoicetokeystrokeratio020406080100AccuracyOnerandomguessFiverandomguessesTop-1accuracyTop-5accuracy712A less intrusive countermeasure that might work against
all techniques that use sound spectrum information, is to
perform short random transformations to the sound when-
ever a keystroke is detected. One intuitive way to do this
is to apply a random multi-band equalizer over a number
of small frequency bands of the spectrum. This allows us
to modify the intensity of speciﬁc frequency ranges, called
“bands”. Each band should be selected at random and its in-
tensity should be modiﬁed by a small random amount, thus
eﬀectively changing the sound spectrum. This approach
should allow the speaker’s voice to remain intelligible.
To show the eﬃcacy of this countermeasure, we ran the
following experiment: we considered all data recorded on the
Macbook Pro laptop, one user at a time, in a 10-fold cross-
validation scheme. For every fold, we applied a multiband
equalizer with 100 bands to the test data only, where each
band has a random center between 100 Hz and 3000 Hz, a
very high resonance Q of 50, and a random gain between
-5dB and +5dB. We then tried to classify these samples
using both MFCC and FFT features, in order to see if such
countermeasure are eﬀective even against diﬀerent spectral
features. Results in Figure 13 show S&T accuracy, with and
without the countermeasure, for MFCC and FFT features.
Figure 13: Average accuracy of single key classiﬁca-
tion against a random equalization countermeasure.
The proposed countermeasure successfully disrupts FFT
coeﬃcients, such as those used in [3, 11, 12, 19], by reducing
the accuracy of S&T to the baseline random guess. For
MFCC features, although the countermeasure still manages
to reduce the accuracy by 50%, on average, the features
remain partly robust to this tampering.
A more simplistic approach is to use software or emulated
keyboards, i.e., those that appear on the screen and are op-
erated by the mouse. Similarly trivial ideas include: (1)
activating a mute button before typing, or (2) not to type
at all whenever engaged in a VoIP call.
7. CONCLUSIONS
This paper demonstrated a highly accurate VoIP-based
remote keyboard acoustic eavesdropping attack. We ﬁrst de-
scribed a number of practical attack scenarios, using VoIP as
a novel means to acquire acoustic information under realis-
tic assumptions: random target text and very small training
sets, in Section 3. Then, in Section 4 we demonstrated an
attack with these assumptions in mind and carefully selected
the tools to maximize its accuracy. In Section 5, we thor-
oughly evaluated S&T attack using Skype in several scenar-
ios. Finally, we discussed some potential countermeasures
to S&T and other attacks that leverage spectral features of
keyboard sounds, in Section 6.
We believe that this work, due to its real-world applicabil-
ity, advances the state-of-the-art in acoustic eavesdropping
attacks. S&T attack was shown to be both feasible and ac-
curate over Skype, in all considered attack scenarios, with
none or minimal proﬁling of the victim’s typing style and
keyboard. In particular, it is accurate in the Model Proﬁling
scenario, where the attacker proﬁles a laptop of the same
model as the victim’s laptop, without any additional infor-
mation about the victim. This allows the attacker to learn
private information, such as sensitive text or passwords. We
also took into account VoIP-speciﬁc issues – such as the im-
pact of audible bandwidth reduction, and eﬀects of human
voice mixed with keystroke audio – and showed that S&T
is robust with respect to both. Finally, we discussed some
countermeasures and concluded that S&T is hard to miti-
gate.
8. FUTURE WORK
We believe that our choice of laptops and test users is a
representative sample. The number of tested laptops was in
line with related work, and the number of users was greater.
(In fact, related work was based on collected data of only
one user [3, 11, 12, 19]). However, it would be useful to run
the experiments on more keyboard models (such as external
keyboards with switches) and with more users. This would
oﬀer a more convincing demonstration that S&T works re-
gardless of underlying equipment and typing styles. Another
important direction is analyzing the impact of diﬀerent mi-
crophones to collect both training and test data.
As far as the impact of the actual VoIP software, we fo-
cused on Skype – currently the most popular VoIP tool [20,
1, 22]. We consider it to be representative of other VoIP
software, since its codecs are used in Opus (an IETF stan-
dard [26]) and employed in many VoIP applications, such as
Google Hangouts and Teamspeak [21]. We believe that other
VoIP software is probably vulnerable to S&T attack. We
also ran some preliminary experiments with Google Hang-
outs and the results conﬁrm this assertion. However, a more
thorough assessment of other VoIP software is needed.
We also plan to improve the accuracy of S&T attack, espe-
cially when target-text is meaningful, (e.g., English text) by
including Natural Language Processing (NLP) techniques or
crowd-sourcing approaches. Finaly, we intend to further ex-
plore S&T countermeasures, analyze real-time feasibility of
random equalization in the presence of keystroke audio, eval-
uate its impact on user-perceived call quality, and improve
its performance.
Acknowledgments
Mauro Conti was supported by a Marie Curie Fellowship
funded by the European Commission (agreement PCIG11-
GA-2012-321980), EU TagItSmart! Project (agreement H2020-
ICT30-2015-688061) and EU-India REACH Project (agree-
ment ICI+/2014/342-896). Gene Tsudik was supported, in
part, by the National Security Agency (H98230-15-1-0276)
and the Department of Homeland Security (under subcon-
tract from the HRL Laboratories).
0246810Numberofguesses0%20%40%60%80%100%AccuracyRandomguessMFCC,countermeasureMFCCFFT,countermeasureFFT713References
[1] 2015: Skype’s year in review. url:
http://blogs.skype.com/2015/12/17/2015-skypes-
year-in-review/ (visited on 06/29/2016).
[2] Kamran Ali et al. “Keystroke recognition using WiFi
signals”. In: ACM MobiCom. 2015, pp. 90–102.
[3] Dmitri Asonov and Rakesh Agrawal. “Keyboard
acoustic emanations”. In: IEEE S&P. 2004, pp. 3–11.
[4] Davide Balzarotti, Marco Cova, and Giovanni Vigna.
“Clearshot: Eavesdropping on keyboard input from
video”. In: IEEE S&P. 2008, pp. 170–183.
[5] Yigael Berger, Avishai Wool, and Arie Yeredor.
“Dictionary attacks using keyboard acoustic
emanations”. In: ACM CCS. 2006, pp. 245–254.
[6] Stephen Boyd et al. “Accuracy at the top”. In: NIPS.
2012, pp. 953–961.
[7] Stuart Card, Thomas Moran, and Allen Newell. “The
keystroke-level model for user performance time with
interactive systems”. In: CACM 7 (1980),
pp. 396–410.
[8] Anupam Das, Nikita Borisov, and Matthew Caesar.
“Do you hear what I hear?: ﬁngerprinting smart
devices through embedded acoustic components”. In:
ACM CCS. 2014, pp. 441–452.
[9] Jeﬀrey Friedman. “Tempest: A signal problem”. In:
NSA Cryptologic Spectrum (1972).
[10]
Isabelle Guyon et al. “Gene selection for cancer
classiﬁcation using support vector machines”. In:
Machine Learning 1-3 (2002), pp. 389–422.
[11] Tzipora Halevi and Nitesh Saxena. “A closer look at
[18] Philip Marquardt et al. “(sp) iPhone: decoding
vibrations from nearby keyboards using mobile phone
accelerometers”. In: ACM CCS. 2011, pp. 551–562.
[19] Zdenek Martinasek, Vlastimil Clupek, and
Krisztina Trasy. “Acoustic attack on keyboard using
spectrogram and neural network”. In: TSP. 2015,
pp. 637–641.
[20] Microsoft BUILD 2016 Keynote. url: https:
//channel9.msdn.com/Events/Build/2016/KEY01
(visited on 06/29/2016).
[21] Opus Codec Support. url:
https://wiki.xiph.org/OpusSupport (visited on
07/19/2016).
[22] Over 1 billion Skype mobile downloads. url:
http://blogs.skype.com/2016/04/28/over-1-billion-
skype-mobile-downloads-thank-you/ (visited on
06/29/2016).
[23] Oxford Dictionary - Which letters in the alphabet are
used most often. url:
http://www.oxforddictionaries.com/words/which-
letters-are-used-most (visited on 06/29/2016).
[24] EH Rothauser et al. “IEEE recommended practice for
speech quality measurements”. In: IEEE Transactions
on Audio and Electroacoustics 3 (1969), pp. 225–246.
[25] Diksha Shukla et al. “Beware, your hands reveal your
secrets!” In: ACM CCS. 2014, pp. 904–917.
[26] Jean-Marc Valin, Koen Vos, and T Terriberry.
“Deﬁnition of the Opus audio codec”. In: IETF,
September (2012).
keyboard acoustic emanations: random passwords,
typing styles and decoding techniques”. In: ACM
CCS. 2012, pp. 89–90.
[27] Martin Vuagnoux and Sylvain Pasini. “Compromising
Electromagnetic Emanations of Wired and Wireless
Keyboards.” In: USENIX Security. 2009, pp. 1–16.
[12] Tzipora Halevi and Nitesh Saxena. “Keyboard
acoustic side channel attacks: exploring realistic and
security-sensitive scenarios”. In: International Journal
of Information Security 5 (2015), pp. 443–456.
[13] Tadayoshi Kohno, Andre Broido, and
Kimberly Claﬀy. “Remote physical device
ﬁngerprinting”. In: IEEE TDSC 2 (2005), pp. 93–108.
[14] Paul Lamere et al. “The CMU SPHINX-4 speech
recognition system”. In: IEEE ICASSP. 2003,
pp. 2–5.
[15] Jian Liu et al. “Snooping keystrokes with mm-level
audio ranging on a single phone”. In: ACM
MobiCom. 2015, pp. 142–154.
[16] Beth Logan et al. “Mel Frequency Cepstral
Coeﬃcients for Music Modeling.” In: ISMIR. 2000.
[28] Junjue Wang et al. “Ubiquitous keyboard for small
mobile devices: harnessing multipath fading for
ﬁne-grained keystroke localization”. In: ACM
MobiSys. 2014, pp. 14–27.
[29] RL Wegel and CE Lane. “The auditory masking of
one pure tone by another and its probable relation to
the dynamics of the inner ear”. In: Physical Review 2
(1924), p. 266.
[30] Teng Wei et al. “Acoustic eavesdropping through
wireless vibrometry”. In: ACM MobiCom. 2015,
pp. 130–141.
[31] Tong Zhu et al. “Context-free attacks using keyboard
acoustic emanations”. In: ACM CCS. 2014,
pp. 453–464.
[17] Jan Lukas, Jessica Fridrich, and Miroslav Goljan.
“Digital camera identiﬁcation from sensor pattern
noise”. In: IEEE TIFS 2 (2006), pp. 205–214.
[32] Li Zhuang, Feng Zhou, and Doug Tygar. “Keyboard
acoustic emanations revisited”. In: ACM TISSEC 1
(2009), p. 3.
714APPENDIX
We now analyze the accuracy of S&T attack in the context
of the Complete Proﬁling scenario.
A. FURTHER DATA COMPARISONS
We compare HP and Touch typing data in Figures 14 and
15. Figure 14 shows S&T attack accuracy as a function of
the number of guesses, and Figure 15 highlights top-1 and
top-5 accuracies. We observe that S&T attack is as accurate
with Touch as with HP typing data, within best 4 guesses.
From the 5-th guess onwards, there is a slight advantage
with HP typing data; however, the diﬀerence is very small
– around 1.1% in theworst case.
Next, we compare the following data: unﬁltered, Skype-
ﬁltered and Google Hangouts-ﬁltered in ﬁgures 16 and 17.
Figure 16 shows S&T attack accuracy as a function of the
number of guesses, and Figure 17 highlights top-1 and top-5
accuracies. Once again, we observe that there is only a small
diﬀerence in the accuracies between unﬁltered and Skype-
ﬁltered data – around 1%. We see a slightly worse top-1
accuracy with Google Hangouts, with respect to unﬁltered
data. This diﬀerence of about 5% gets progressively smaller,
and, at top-5, there is no diﬀerence betwen unﬁltered and
Google Hangouts-ﬁltered data.
Figure 14: S&T attack performance – average accu-
racy of HP and Touch typing data.
S&T attack performance – average
Figure 16:
accuracy of unﬁltered, Skype-ﬁltered and Google
Hangouts-ﬁltered data.
Figure 15: S&T attack performance – top-1 and top-
5 accuracies of HP and Touch typing data.
Figure 17: S&T attack performance – top-1 and top-
5 accuracies of unﬁltered, Skype-ﬁltered and Google
Hangouts-ﬁltered data.
0246810Numberofguesses0%20%40%60%80%100%AccuracyRandomguessHPtypingTouchtypingTop-1Top-5Guesses020406080100AccuracyHPtypingTouchtyping0246810Numberofguesses0%20%40%60%80%100%AccuracyRandomguessUnﬁltereddataSkypeGoogleHangoutsTop-1Top-5Guesses020406080100AccuracyPlainSkypeHangouts715