### 5. Attack Analysis and Results

In the scenario where we have a top-5 accuracy of around 40%, it would take approximately \(7.79 \times 10^{12}\) attempts to achieve a 50% probability of cracking the password. This is still one order of magnitude better than a plain brute-force attack, on average. If the attack guesses ten characters for every character in the password, the number of required guesses increases to \(8.39 \times 10^{13}\).

### 6. Possible Countermeasures

In this section, we present and discuss some potential countermeasures and analyze their effectiveness in preventing S&T and other attacks that exploit the statistical properties of the sound spectrum.

**Ducking Effect:**
One simple countermeasure is a short "ducking" effect, which drastically lowers the microphone volume and overlaps it with a different sound whenever a keystroke is detected. However, this approach can degrade voice call quality. Ideally, an effective countermeasure should be minimally intrusive and affect only keystroke sounds.

**Random Sound Transformations:**
A less intrusive countermeasure that could work against all techniques using sound spectrum information is to perform short random transformations to the sound whenever a keystroke is detected. One intuitive way to do this is to apply a random multi-band equalizer over a number of small frequency bands of the spectrum. This allows us to modify the intensity of specific frequency ranges, called "bands." Each band should be selected at random, and its intensity should be modified by a small random amount, effectively changing the sound spectrum while allowing the speaker's voice to remain intelligible.

To demonstrate the efficacy of this countermeasure, we conducted the following experiment: We considered all data recorded on the MacBook Pro laptop, one user at a time, in a 10-fold cross-validation scheme. For each fold, we applied a multiband equalizer with 100 bands to the test data only, where each band had a random center between 100 Hz and 3000 Hz, a very high resonance Q of 50, and a random gain between -5dB and +5dB. We then attempted to classify these samples using both MFCC and FFT features to determine if such a countermeasure is effective even against different spectral features. The results, shown in Figure 13, indicate that the proposed countermeasure successfully disrupts FFT coefficients, reducing the accuracy of S&T to the baseline random guess. For MFCC features, although the countermeasure reduces the accuracy by 50% on average, the features remain partly robust to this tampering.

**Simplistic Approaches:**
More simplistic approaches include using software or emulated keyboards (i.e., those that appear on the screen and are operated by the mouse). Other trivial ideas include:
1. Activating a mute button before typing.
2. Not typing at all during a VoIP call.

### 7. Conclusions

This paper demonstrates a highly accurate VoIP-based remote keyboard acoustic eavesdropping attack. We first described several practical attack scenarios, using VoIP as a novel means to acquire acoustic information under realistic assumptions, such as random target text and very small training sets (Section 3). In Section 4, we demonstrated an attack with these assumptions in mind and carefully selected tools to maximize its accuracy. In Section 5, we thoroughly evaluated the S&T attack using Skype in various scenarios. Finally, in Section 6, we discussed potential countermeasures to S&T and other attacks that leverage spectral features of keyboard sounds.

We believe that this work, due to its real-world applicability, advances the state-of-the-art in acoustic eavesdropping attacks. The S&T attack was shown to be both feasible and accurate over Skype in all considered attack scenarios, with minimal or no profiling of the victim's typing style and keyboard. Specifically, it is accurate in the Model Profiling scenario, where the attacker profiles a laptop of the same model as the victim's without any additional information about the victim. This allows the attacker to learn private information, such as sensitive text or passwords. We also considered VoIP-specific issues, such as the impact of audible bandwidth reduction and the effects of human voice mixed with keystroke audio, and showed that S&T is robust to both. Finally, we discussed some countermeasures and concluded that S&T is difficult to mitigate.

### 8. Future Work

We believe our choice of laptops and test users is representative. The number of tested laptops aligns with related work, and the number of users is greater. (In fact, related work was based on data from only one user [3, 11, 12, 19]). However, it would be useful to run experiments on more keyboard models (such as external keyboards with switches) and with more users to provide a more convincing demonstration that S&T works regardless of underlying equipment and typing styles. Another important direction is analyzing the impact of different microphones for collecting both training and test data.

As for the impact of the actual VoIP software, we focused on Skype, currently the most popular VoIP tool [20, 1, 22]. We consider it representative of other VoIP software, as its codecs are used in Opus (an IETF standard [26]) and employed in many VoIP applications, such as Google Hangouts and Teamspeak [21]. We believe other VoIP software is likely vulnerable to S&T attacks. Preliminary experiments with Google Hangouts confirm this assertion, but a more thorough assessment of other VoIP software is needed.

We also plan to improve the accuracy of S&T attacks, especially when the target text is meaningful (e.g., English text), by incorporating Natural Language Processing (NLP) techniques or crowd-sourcing approaches. Additionally, we intend to further explore S&T countermeasures, analyze the real-time feasibility of random equalization in the presence of keystroke audio, evaluate its impact on user-perceived call quality, and improve its performance.

### Acknowledgments

Mauro Conti was supported by a Marie Curie Fellowship funded by the European Commission (agreement PCIG11-GA-2012-321980), EU TagItSmart! Project (agreement H2020-ICT30-2015-688061), and EU-India REACH Project (agreement ICI+/2014/342-896). Gene Tsudik was supported, in part, by the National Security Agency (H98230-15-1-0276) and the Department of Homeland Security (under subcontract from the HRL Laboratories).

### References

[1] 2015: Skype’s year in review. url: http://blogs.skype.com/2015/12/17/2015-skypes-year-in-review/ (visited on 06/29/2016).
[2] Kamran Ali et al. “Keystroke recognition using WiFi signals”. In: ACM MobiCom. 2015, pp. 90–102.
[3] Dmitri Asonov and Rakesh Agrawal. “Keyboard acoustic emanations”. In: IEEE S&P. 2004, pp. 3–11.
[4] Davide Balzarotti, Marco Cova, and Giovanni Vigna. “Clearshot: Eavesdropping on keyboard input from video”. In: IEEE S&P. 2008, pp. 170–183.
[5] Yigael Berger, Avishai Wool, and Arie Yeredor. “Dictionary attacks using keyboard acoustic emanations”. In: ACM CCS. 2006, pp. 245–254.
[6] Stephen Boyd et al. “Accuracy at the top”. In: NIPS. 2012, pp. 953–961.
[7] Stuart Card, Thomas Moran, and Allen Newell. “The keystroke-level model for user performance time with interactive systems”. In: CACM 7 (1980), pp. 396–410.
[8] Anupam Das, Nikita Borisov, and Matthew Caesar. “Do you hear what I hear?: fingerprinting smart devices through embedded acoustic components”. In: ACM CCS. 2014, pp. 441–452.
[9] Jeffrey Friedman. “Tempest: A signal problem”. In: NSA Cryptologic Spectrum (1972).
[10] Isabelle Guyon et al. “Gene selection for cancer classification using support vector machines”. In: Machine Learning 1-3 (2002), pp. 389–422.
[11] Tzipora Halevi and Nitesh Saxena. “A closer look at keyboard acoustic emanations: random passwords, typing styles and decoding techniques”. In: ACM CCS. 2012, pp. 89–90.
[12] Tzipora Halevi and Nitesh Saxena. “Keyboard acoustic side channel attacks: exploring realistic and security-sensitive scenarios”. In: International Journal of Information Security 5 (2015), pp. 443–456.
[13] Tadayoshi Kohno, Andre Broido, and Kimberly Claffy. “Remote physical device fingerprinting”. In: IEEE TDSC 2 (2005), pp. 93–108.
[14] Paul Lamere et al. “The CMU SPHINX-4 speech recognition system”. In: IEEE ICASSP. 2003, pp. 2–5.
[15] Jian Liu et al. “Snooping keystrokes with mm-level audio ranging on a single phone”. In: ACM MobiCom. 2015, pp. 142–154.
[16] Beth Logan et al. “Mel Frequency Cepstral Coefficients for Music Modeling.” In: ISMIR. 2000.
[17] Jan Lukas, Jessica Fridrich, and Miroslav Goljan. “Digital camera identification from sensor pattern noise”. In: IEEE TIFS 2 (2006), pp. 205–214.
[18] Philip Marquardt et al. “(sp) iPhone: decoding vibrations from nearby keyboards using mobile phone accelerometers”. In: ACM CCS. 2011, pp. 551–562.
[19] Zdenek Martinasek, Vlastimil Clupek, and Krisztina Trasy. “Acoustic attack on keyboard using spectrogram and neural network”. In: TSP. 2015, pp. 637–641.
[20] Microsoft BUILD 2016 Keynote. url: https://channel9.msdn.com/Events/Build/2016/KEY01 (visited on 06/29/2016).
[21] Opus Codec Support. url: https://wiki.xiph.org/OpusSupport (visited on 07/19/2016).
[22] Over 1 billion Skype mobile downloads. url: http://blogs.skype.com/2016/04/28/over-1-billion-skype-mobile-downloads-thank-you/ (visited on 06/29/2016).
[23] Oxford Dictionary - Which letters in the alphabet are used most often. url: http://www.oxforddictionaries.com/words/which-letters-are-used-most (visited on 06/29/2016).
[24] EH Rothauser et al. “IEEE recommended practice for speech quality measurements”. In: IEEE Transactions on Audio and Electroacoustics 3 (1969), pp. 225–246.
[25] Diksha Shukla et al. “Beware, your hands reveal your secrets!” In: ACM CCS. 2014, pp. 904–917.
[26] Jean-Marc Valin, Koen Vos, and T Terriberry. “Definition of the Opus audio codec”. In: IETF, September (2012).
[27] Martin Vuagnoux and Sylvain Pasini. “Compromising Electromagnetic Emanations of Wired and Wireless Keyboards.” In: USENIX Security. 2009, pp. 1–16.
[28] Junjue Wang et al. “Ubiquitous keyboard for small mobile devices: harnessing multipath fading for fine-grained keystroke localization”. In: ACM MobiSys. 2014, pp. 14–27.
[29] RL Wegel and CE Lane. “The auditory masking of one pure tone by another and its probable relation to the dynamics of the inner ear”. In: Physical Review 2 (1924), p. 266.
[30] Teng Wei et al. “Acoustic eavesdropping through wireless vibrometry”. In: ACM MobiCom. 2015, pp. 130–141.
[31] Tong Zhu et al. “Context-free attacks using keyboard acoustic emanations”. In: ACM CCS. 2014, pp. 453–464.
[32] Li Zhuang, Feng Zhou, and Doug Tygar. “Keyboard acoustic emanations revisited”. In: ACM TISSEC 1 (2009), p. 3.

### Appendix

We now analyze the accuracy of the S&T attack in the context of the Complete Profiling scenario.

**Further Data Comparisons:**

- **HP and Touch Typing Data:**
  We compare HP and Touch typing data in Figures 14 and 15. Figure 14 shows the S&T attack accuracy as a function of the number of guesses, and Figure 15 highlights the top-1 and top-5 accuracies. We observe that the S&T attack is as accurate with Touch as with HP typing data within the best 4 guesses. From the 5th guess onwards, there is a slight advantage with HP typing data; however, the difference is very small—around 1.1% in the worst case.

- **Unfiltered, Skype-Filtered, and Google Hangouts-Filtered Data:**
  Next, we compare unfiltered, Skype-filtered, and Google Hangouts-filtered data in Figures 16 and 17. Figure 16 shows the S&T attack accuracy as a function of the number of guesses, and Figure 17 highlights the top-1 and top-5 accuracies. Once again, we observe that there is only a small difference in the accuracies between unfiltered and Skype-filtered data—around 1%. We see a slightly worse top-1 accuracy with Google Hangouts compared to unfiltered data, with a difference of about 5%. This difference gets progressively smaller, and at top-5, there is no difference between unfiltered and Google Hangouts-filtered data.

**Figures:**

- **Figure 14:** S&T attack performance – average accuracy of HP and Touch typing data.
- **Figure 15:** S&T attack performance – top-1 and top-5 accuracies of HP and Touch typing data.
- **Figure 16:** S&T attack performance – average accuracy of unfiltered, Skype-filtered, and Google Hangouts-filtered data.
- **Figure 17:** S&T attack performance – top-1 and top-5 accuracies of unfiltered, Skype-filtered, and Google Hangouts-filtered data.