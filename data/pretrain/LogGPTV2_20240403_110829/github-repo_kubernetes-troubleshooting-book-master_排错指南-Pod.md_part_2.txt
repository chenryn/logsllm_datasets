可能的原因和解决方案：
1. http 类型的 registry，但是没有添加到 dockerd 的 insecure-registry=172.27.129.211:35000 配置参数中：
    dockerd 默认从 https 类型的 registry 拉取镜像，如果使用 https 类型的 registry，则必须将它添加到 insecure-registry 参数中，然后重启或 reload dockerd 生效。
1. https 类型的 registry，但是使用自签名的 ca 证书，dockerd 不识别：
    将 registry 加入到 insecure-registry 参数中，然后重启或 reload dockerd 生效。或者将它的 ca 证书放置到 `/etc/docker/certs.d//ca.crt` 位置；
1. registry 需要认证，但是 Pod 没有配置 imagePullSecret，配置的 Secret 不存在或有误：
    首先创建一个 docker-registry 类型的 Secret：
    ``` bash
    $ kubectl create secret docker-registry my-secret --docker-server=DOCKER_REGISTRY_SERVER --docker-username=DOCKER_USER --docker-password=DOCKER_PASSWORD --docker-email=DOCKER_EMAIL
    ```
    然后在容器中引用这个 Secret:
    ``` bash
    spec:
      containers:
      - name: private-reg-container
        image: 
      imagePullSecrets:
      - name: my-secret
    ```
1. 镜像文件损坏，需要重新 push 镜像文件
    kubectl describe pod 报错：
        Failed to pull image "docker02:35000/env/release/3.2.0/prophet/app/executor-service-kube.tar:release-3.2.0-8": rpc error: code = Unknown desc = error pulling image configuration: unknown blob
1. kubelet 的 --registry-qps、--registry-burst 值太小（默认分别为 5，10)，并发拉取镜像时被限制，kubectl describe pod 报错：
        Failed to pull image "172.27.129.211:35000/metricbeat-prophet:6.0.1": pull QPS exceeded，这时，可以调大这两个参数，然后重启 kubelet 解决。
    --registry-qps 太小导致的并发限制案例：
    ``` bash
    [root@m7-power-k8s01 ~]# kubectl get pods -n env30 -o wide alert-engine-alert-engine-54fd454f64-clbd7
    NAME                                               READY     STATUS                  RESTARTS   AGE       IP               NODE
    alert-engine-alert-engine-54fd454f64-clbd7         0/3       ImagePullBackOff        0          59m       172.30.208.111   m7-power-k8s03
    [root@m7-power-k8s01 ~]# kubectl describe pods -n env30 alert-engine-alert-engine-54fd454f64-clbd7 | tail -3
    Warning  Failed                  44m (x2 over 46m)   kubelet, m7-power-k8s03  Failed to pull image "172.27.129.211:35000/filebeat-with-module:6.0.0": pull QPS exceeded.
    Normal   BackOff                 5m (x83 over 51m)   kubelet, m7-power-k8s03  Back-off pulling image "172.27.129.211:35000/filebeat-with-module:6.0.0"
    Normal   Pulling                 36s (x13 over 51m)  kubelet, m7-power-k8s03  pulling image "172.27.129.211:35000/filebeat-with-module:6.0.0"
    ```
## Pod 一直处于 ImageInspectError 状态
现象：
1. 启动 Pod 失败，kubectl get pods 显示的 STATUS 为 "ImageInspectError"
    ``` bash
    [root@m7-devops-128071 gitlab]# kubectl get pods --all-namespaces|grep Inspect
    fangrong                  pms-558b58dfbd-fpjzl                                              0/1       ImageInspectError   0          13h
    prophet-resource-automl   pas-08a7e677-5c4e-4e2d-992f-7d93cd0f05d5-automl-544ff774b7xgh88   0/1       ImageInspectError   0          13h
    prophet-resource-automl   pas-1ccab6a2-0415-4542-8ccf-348dd28451c4-automl-6c6bd6f4644sqpw   0/1       ImageInspectError   0          13h
    qatest312                 pms-b97bc97fc-5djfl                                               0/1       ImageInspectError   0          6h
    ```
1. kubectl describe pod 显示，ImageInspectError 的原因为 readlink /mnt/disk0/docker/data/overlay2: invalid argument：
    ``` bash
    [root@m7-devops-128071 gitlab]# kubectl describe pods -n fangrong pms-558b58dfbd-fpjzl|tail -2
    Warning  FailedSync             1h (x522 over 13h)  kubelet, m7-devops-128107  Error syncing pod
    Warning  InspectFailed          3m (x590 over 13h)  kubelet, m7-devops-128107  Failed to inspect image "docker02:35000/env/develop/prophet/app/pms.tar:develop-175": rpc error: code = Unknown desc = Error response from daemon: readlink /mnt/disk0/docker/data/overlay2: invalid argument
    ```
1. 打开 dockerd 的 debug 日志级别，查看对应的日志显示 在 readlink /mnt/disk0/docker/data/overlay2 出现了 os.PathError 错误：
    ``` bash
    13 06:00:04 m7-devops-128107 dockerd[34157]: time="2018-08-13T06:00:04.061634901+08:00" level=debug msg="FIXME: Got an API for which error does not match any expected type!!!: readlink /mnt/disk0/docker/data/overlay2: invalid argument" error_type="*os.PathError" module=api
    8月 13 06:00:04 m7-devops-128107 dockerd[34157]: time="2018-08-13T06:00:04.061670830+08:00" level=error msg="Handler for GET /v1.31/images/docker02:35000/grafana/grafana-enhanced:5.2.0/json returned error: readlink /mnt/disk0/docker/data/overlay2: invalid argument"
    8月 13 06:00:04 m7-devops-128107 dockerd[34157]: time="2018-08-13T06:00:04.061704408+08:00" level=debug msg="FIXME: Got an API for which error does not match any expected type!!!: readlink /mnt/disk0/docker/data/overlay2: invalid argument" error_type="*os.PathError" module=api
    ```
原因：
1. 节点上 docker 镜像文件损坏，当使用它启动容器后，容器文件系统错误，进而导致系统调用 readlink() 返回 os.PathError 错误；
1. dockerd 不能正确处理这个 Error https://github.com/allencloud/docker/blob/master/api/server/httputils/errors.go#L65，所以提示 FIXME: Got an API for which error does not match any expected type!!!
1. image 文件损坏可能与重启服务器导致的文件系统不完整有关，可以使用 fsck 命令修复文件系统；
验证节点上镜像文件损坏的步骤：
1. 在该节点上使用 image 起容器，结果启动失败：
    ``` bash
    [root@m7-devops-128107 ~]# docker run -it docker02:35000/env/develop/prophet/app/pms.tar:develop-175 sh
    docker: Error response from daemon: OCI runtime create failed: container_linux.go:348: starting container process caused "exec: \"/bin/bash\": stat /bin/bash: no such file or directory": unknown.
    [root@m7-devops-128107 ~]#
    ```
1. 或者，导出 image 镜像失败，提示文件完整性校验出错：
    ``` bash
    [root@m7-devops-128107 ~]# docker save docker02:35000/env/develop/prophet/app/pms.tar:develop-175 -o pms.img
    Error response from daemon: file integrity checksum failed for "etc/anacrontab"
    ```
解决方案：
1. 删除节点上所有使用损坏 image 的容器，否则不能删除 image：
    ``` bash
    [root@m7-devops-128107 ~]# docker ps -a|grep pms.tar
    ecdad07d835b        docker02:35000/env/develop/prophet/app/pms.tar:develop-175                   "/bin/bash /opt/work…"    About a minute ago   Created                                               competent_meninsky
    f9c805e91ac7        docker02:35000/env/develop/prophet/app/pms.tar:develop-175                   "/bin/bash /opt/work…"    2 minutes ago        Created                                               hopeful_stonebraker
    63b6a12efc3e        docker02:35000/env/develop/prophet/app/pms.tar:develop-175                   "/bin/bash /opt/work…"    8 minutes ago        Created                                               confident_wright
    [root@m7-devops-128107 ~]# docker rm ecdad07d835b # 删除所有使用损坏的 pms.tar 镜像的容器
    ecdad07d835b
    [root@m7-devops-128107 ~]# docker rm f9c805e91ac7
    f9c805e91ac7
    [root@m7-devops-128107 ~]# docker rm 63b6a12efc3e
    63b6a12efc3
    ```
1. 删除节点上损坏的 image (必须要有 Deleted: sha256 开头的输出结果，才表明实际删除了 image layer 文件，否则需要删除使用它的容器后再删除 image)：
    ``` bash
    [root@m7-devops-128107 ~]# docker rmi docker02:35000/env/develop/prophet/app/pms.tar:develop-175
    ```
1. 重新拉取 image 文件：
    ``` bash
    [root@m7-devops-128107 ~]# docker pull docker02:35000/env/develop/prophet/app/pms.tar:develop-175
    ```
参考：
+ https://github.com/allencloud/docker/blob/master/api/server/httputils/errors.go#L65
+ https://github.com/kubernetes/kubernetes/issues/63612
## Pod 一直处于 CrashLoopBackOff 状态
CrashLoopBackOff 状态说明容器曾经启动了，但又异常退出了。此时 Pod 的 RestartCounts 通常是大于 0 的，可以先查看一下容器的日志：
``` bash
kubectl describe pod  -n 
kubectl logs  -n  [-c container_name]
kubectl logs --previous  -n  [-c container_name]
```
从 describe pod 的 State、Last State 里，以及容器日志可以发现一些容器退出的原因，比如：
+ 容器进程退出，如域名解析失败、连接数据库失败；
+ 健康检查失败退出
+ OOMKilled
+ 镜像文件损坏
``` bash
$ kubectl describe pod mypod
...
Containers:
  sh:
    Container ID:  docker://3f7a2ee0e7e0e16c22090a25f9b6e42b5c06ec049405bc34d3aa183060eb4906
    Image:         alpine
    Image ID:      docker-pullable://alpine@sha256:7b848083f93822dd21b0a2f14a110bd99f6efb4b838d499df6d04a49d0debf8b
    Port:          
    Host Port:     
    State:          Terminated
      Reason:       OOMKilled
      Exit Code:    2
    Last State:     Terminated
      Reason:       OOMKilled
      Exit Code:    2
    Ready:          False
    Restart Count:  3
    Limits:
      cpu:     1
      memory:  1G
    Requests:
      cpu:        100m
      memory:     500M
...
```