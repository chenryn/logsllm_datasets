of a new insertion of (label, value) in the HIRB is determined
by a series of pseudorandom biased coin ﬂips based on the
hash of the label4. The distribution of selected heights for
insertions uniquely determines the structure of the HIRB tree
because the process is deterministic, and thus the HIRB is
uniquely-represented.
Parameters and preliminaries. Two parameters are ﬁxed at
initialization: the expected branching factor β, and the height
H. In addition, throughout this section we will write n as the
maximum number of distinct labels that may be stored in the
HIRB tree, and γ as a parameter that affects the length of hash
digests5.
A HIRB tree node with branching factor k consists of k− 1
label hashes, k − 1 values, and k vORAM identiﬁers which
represent pointers to the child nodes. This is described in
Figure 5 where hi indicates Hash(labeli).
Similar to the vORAM itself, the length of the hash function
should be long enough to reduce the probability of collision
−γ, so deﬁne |Hash(label)| = max(2H lg β + γ, λ),
below 2
3We need a random oracle for formal security. In practice, we used a SHA1
initialized with a random string chosen when the HIRB tree is instantiated.
4Note that this choice of heights is more or less the same as the randomly-
chosen node heights in a skip list.
5The parameter γ for HIRB and vORAM serves the same purpose in
avoiding collisions in identiﬁers so for simplicity we assume they are the
same
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:16:59 UTC from IEEE Xplore.  Restrictions apply. 
id0 h1
value1
id1 . . . hk
valuek
idk
Figure 5: HIRB node with branching factor k.
and deﬁne nodesizek to be the size of a HIRB tree node with
branching factor k, given as
nodesizek = (k + 1)(2T + γ + 1) + k(|Hash(label)| +|value|),
where we write |value| as an upper bound on the size of the
largest value stored in the HIRB. (Recall that the size of each
vORAM identiﬁer is 2T + γ + 1.) Each HIRB tree node will
be stored as a single block in the vORAM, so that a HIRB
node with branching factor k will ultimately be a vORAM
block with length nodesizek.
As β reﬂects the expected branching factor of a node, it
must be an integer greater than or equal to 1. This parameter
controls the efﬁciency of the tree and should be chosen
according to the size of vORAM buckets. In particular, using
the results of Theorem 5 in the previous section, and the
HIRB node size deﬁned above, one would choose β according
to the inequality 20nodesizeβ ≤ Z, where Z is the size of
each vORAM bucket. According to our experimental results
in Section VI, the constant 20 may be reduced to 6.
The height H must be set so that H ≥ logβ n; otherwise
we risk the root node growing too large. We assume that H
is ﬁxed at all times, which is easily handled when an upper
bound n is known a priori.
HIRB tree operations. As previously described, the entries
in a HIRB node are sorted by the hash of the labels, and the
search path for a label is also according to the label hashes.
A lookup operation for a label requires fetching each HIRB
node along the search path from the vORAM and returning
the matching value.
Initially, an empty HIRB tree of height H is created, as
shown in Figure 6. Each node has a branching factor of 1 and
contains only the single vORAM identiﬁer of its child.
(cid:11)
(cid:11)
...
(cid:11)
H + 1 nodes
Figure 6: Empty HIRB with height H.
Modifying the HIRB with a set or delete operation on
some label involves ﬁrst computing the height of the label.
The height
is determined by sampling from a geometric
distribution with probability (β−1)/β, which we derandomize
by using a pseudorandom sequence based on Hash(label).
The distribution guarantees that, in expectation, the number
of items at height 0 (i.e., in the leaves) is β−1
β n, the number
of items at height 1 is β−1
β2 n, and so on.
Inserting or removing an element from the HIRB involves
(respectively) splitting or merging nodes along the search path
. . .
. . .
. . .
. . .
. . .
X
. . .
. . .
. . .
. . .
. . .
. . .
. . .
. . .
. . .
. . .
(cid:11) . . .
. . .
. . .
Figure 7: HIRB insertion/deletion of X = (Hash(label),
value): On the left is the HIRB without item X, displaying only
the nodes along the search path for X, and on the right is the
state of the HIRB with X inserted. Observe that the insertion
operation (left to right) involves splitting the nodes below X
in the HIRB, and the deletion operation (right to left) involves
merging the nodes below X.
from the height of the item down to the leaf. This differs from
a typical B-tree in that rather than inserting items at the leaf
level and propagating up or down with splitting or merging, the
HIRB tree requires that the heights of all items are ﬁxed. As
a result, insertions and deletions occur at the selected height
within the tree according to the label hash. A demonstration
of this process is provided in Figure 7.
In a HIRB tree with height H, each get operation requires
reading exactly H +1 nodes from the vORAM, and each set or
delete operation involves reading and writing at most 2H + 1
nodes. To support obliviousness, each operation will require
exactly 2H + 1, accomplished by padding with “dummy”
accesses so that every operation has an indistinguishable
access pattern.
One way of reading and updating the nodes along the search
path would be to read all 2H + 1 HIRB nodes from the
vORAM and store them in temporary memory and then write
back the entire path after any update. However, properties of
the HIRB tree enable better performance because the height of
each HIRB tree element is uniquely determined, which means
we can perform the updates on the way down in the search
path. This only requires 2 HIRB tree nodes to be stored in
local memory at any given time.
Facilitating this extra efﬁciency requires considerable care
in the implementation due to the nature of vORAM identiﬁers;
namely, each internal node must be written back to vORAM
before its children nodes are fetched. Fetching children nodes
will change their vORAM identiﬁers and invalidate the point-
ers in the parent node. The solution is to pre-generate new
random identiﬁers of the child nodes before they are even
accessed from the vORAM.
The full details of the HIRB operations can be found in
Appendix B.
HIRB tree properties.
For our analysis of the HIRB
tree, we ﬁrst need to understand the distribution of items
among each level in the HIRB tree. We assume a subroutine
chooseheight(label) evaluates a random function on label
187187
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:16:59 UTC from IEEE Xplore.  Restrictions apply. 
to generate random coins, using which it samples from a
truncated geometric distribution with maximum value H and
probability (β − 1)/β.
Assumption 6. If
stored in a HIRB, then the heights
label1, . . . , labeln are any n distinct labels
chooseheight(label1), . . . , chooseheight(labeln)
are independent random samples from a truncated geometric
distribution over {0, 1, . . . , H} with probability (β − 1)/β,
where the randomness is determined entirely by the the random
oracle and the random function upon creation of the HIRB.
In practice, the random coins for chooseheight(label) are
prepared by computing coins = PRG(SHA1(seed(cid:12)label)),
where seed is a global random seed, and PRG is a pseudo-
random generator. With SHA1 modeled as a random oracle,
the coins will be pseudorandom.
Theorem 7. The HIRB tree is a dictionary data structure that
associates arbitrary labels to values. If it contains n items,
and has height H ≥ logβ n, and the nodes are stored in a
vORAM, then the following properties hold:
−γ.
• The probability of failure in any operation is at most 2
• Each operation requires exactly 2H + 1 node accesses,
only 2 of which need to be stored in temporary memory
at any given time.
• The data structure itself, not counting the pointers, is
strongly history independent.
The ﬁrst property follows from the fact that the only way
the HIRB tree can fail
to work properly is if there is a
hash collision. Based on the hash length deﬁned above, the
probability that any 2 keys collide amongst the n labels in the
−γ. The second property follows from the
HIRB is at most 2
description of the operations get, set, and delete, and is crucial
not only for the performance of the HIRB but also for the
obliviousness property. The third property is a consequence of
the fact that the HIRB is uniquely represented up to the pointer
values, after the hash function is chosen at initialization.
vORAM+HIRB properties. We are now ready for the main
theoretical results of the paper, which have to do with the
performance and security guaranteed by the vORAM+HIRB
construction.
Theorem 8. Suppose a HIRB tree with n items and height
H is stored within a vORAM with L levels, bucket size Z,
and stash size R. Given choices for Z and γ > 0, set the
parameters as follows:
T ≥ lg(4n + lg n + γ)
β = max{β|Z ≥ 20 · nodesizeβ}
R ≥ γ · nodesizeβ
H ≥ logβ n
Then the probability of
collisions after each operation is at most
Pr[vORAM+HIRB failure] ≤ 30 · (0.883)
failure due to stash overﬂow or
The parameters follow from the discussion above. Again
note that the constants 30 and 0.883 are technical artifacts of
the analysis.
Theorem 9. Suppose a vORAM+HIRB is constructed with
parameters as above. The vORAM+HIRB provides oblivious-
ness, secure deletion, and history independence with leakage
of O(n + nλ/(log n)) operations.
The security properties follow from the previous results on
the vORAM and the HIRB. Note that the HIRB structure
itself provides history independence with no leakage, but when
combined with the vORAM, the pointers may leak information
about recent operations. The factor O(log n) difference from
the amount of leakage from vORAM in Theorem 4 arises
because each HIRB operation entails O(log n) vORAM opera-
tions. Following the discussion after Theorem 4, we could also
reduce the leakage in vORAM+HIRB to O(n/ log
n), with
constant-factor increase in bandwidth, which again is optimal
according to Theorem 1.
2
VI. EVALUATION
two
empirical
of
We
analyses
completed
the
vORAM+HIRB system. First, we sought
to determine
the most effective size for vORAM buckets with respect
to the expected block size, i.e., the ratio Z/B. Second, we
made a complete implementation of the vORAM+HIRB and
measured its performance in storing a realistic dataset of
key/value pairs of 22MB in size. The complete source code
of our implementation is available upon request.
A. Optimizing vORAM parameters
A crucial performance parameter in our vORAM construc-
tion is the ratio Z/B between the size Z of each bucket and
the expected size B of each block. (Note that B = nodesizeβ
when storing HIRB nodes within the vORAM.) This ratio is a
constant factor in the bandwidth of every vORAM operation
and has a considerable effect on performance. In the Path
ORAM, the best corresponding theoretical ratio is 5, whereas
it has been shown experimentally that a ratio of 4 will also
work, even in the worst case [9].
We performed a similar experimental analysis of the ra-
tio Z/B for the vORAM. Our best theoretical ratio from
Theorem 5 is 20, but as in related work, the experimental
performance is better. The goal is then to ﬁnd the optimal,
empirical choice for the ratio Z/B: If Z/B is too large, this
will increase the overall communication cost of the vORAM,
and if it is too small, there is a risk of stash overﬂow and loss
of data or obliviousness.
For the experiments described below, we implemented a
vORAM structure without encryption and inserted a chosen
number of variable size blocks whose sizes were randomly
sampled from a geometric distribution with expected size 68
bytes. To avoid collisions, we ensured the identiﬁer lengths
satisﬁed γ ≥ 40.
Stash size. To analyze the stash size for different Z/B ratios,
we ran a number of experiments and monitored the maximum
γ
.
188188
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:16:59 UTC from IEEE Xplore.  Restrictions apply. 















































	

Figure 8: Maximum stash size, scaled by lg n, observed across
50 simulations of a vORAM for various Z/B values.
Figure 10: Utilization at different levels of ORAM
e
z
i
S
h
s
a
t
S
l
i
t
n
U
.
r
e
p
O
f
o
.
m
u
N
n
a