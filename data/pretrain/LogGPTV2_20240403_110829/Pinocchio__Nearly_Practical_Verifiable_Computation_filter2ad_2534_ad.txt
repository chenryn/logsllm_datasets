value back to the speciﬁed int width. Tracking bit width min-
imizes the cost of split gates.
Signed numbers are handled just as they are in C: a 32-
bit int is a twos-complement number with a sign bit at 1 <<
31. Each C expression value is treated either as an arithmetic
scalar wire or a Boolean expansion, e.g. 32 wires in {0,1}
(§3.2). The format is translated only when values pass from
one operator type to the other; for example, in (aˆbˆc) +
z, the bitwise xor (ˆ) operators manipulate bitwise Booleans,
which are joined into a scalar for the addition +.
4.2 Quadratic Programs and Cryptographic Protocol
The next pipeline stage accepts a Boolean or arithmetic cir-
cuit and builds a QSP or QAP (§2). Then, per §3.1, it com-
piles the quadratic program into a set of cryptographic rou-
tines for the client (key generation and veriﬁcation) and the
worker (computation and proof generation). For comparison,
we also implement the original GGPR [30]; §5.4 shows that
Pinocchio’s enhancements reduce overhead by 18-64%.
The key-generation routine runs at the client, with se-
lectable public veriﬁcation and zero-knowledge features
(§5.3). The code transmits the evaluation key over the net-
work to the worker; to save bandwidth, the program transmits
as C and the worker compiles it locally.
The computation routine runs at the server, collecting input
from the client, using the evaluation key to produce the proof,
and transmitting the proof back to the client (or, if desired, a
different veriﬁer). The veriﬁcation routine uses the veriﬁca-
tion key and proof to determine whether the worker attempted
to cheat.
Our cryptographic code is single-threaded, but each stage
is embarrassingly parallel. Prior work [28] shows that stan-
dard techniques can parallelize work across cores, machines,
or GPUs.
For the cryptographic code, we use a high-
speed elliptic curve library [45] with a 256-bit BN-curve [46]
244
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:52:11 UTC from IEEE Xplore.  Restrictions apply. 
that provides 128 bits of security. The quadratic-program-
construction and protocol-execution code is 10,832 lines of C
and C++ [42].
4.2.1 Optimizing Operations
We summarize some of the key optimizations we imple-
mented, as well as lessons learned.
Faster Exponentiation. Generating the evaluation key EK
requires exponentiating the same base g to many different
powers. We optimize this operation by adapting Pippenger’s
multi-exponentiation [47] algorithm for use with a single
base. Essentially this means that we build a table of inter-
mediate powers of g, allowing us to compute any particular
exponent with only a few multiplications.
1g1
2,g1
1g0
1g0
2,g1
2,g0
In a similar vein, the worker’s largest source of overhead is
applying the coefﬁcients from the circuit “in the exponent” to
compute gY (s) etc. Here Pippinger’s algorithm is less directly
useful, since the worker does a handful of such operations
for a given work instance, but each operation involves hun-
dreds of thousands of different bases, i.e., given g1, . . . ,gm,
e1, . . . ,em, for very large m, the worker needs to compute
∏i gei
i . To optimize this operation, we use a sliding-window
technique to build a small table of powers for each pair of
bases. For example, for the ﬁrst two bases, with a window of
size 1, we compute {g0
2}. In this case, the
1g1
table only requires one multiply to build. We can then con-
sider the high order bit of both e1 and e2; together these bits
select one of four values in our table; we multiply that value
into our accumulator and proceed to the next pair of bases.
After all bases have been considered, we square the accumu-
lator (to “move” the portion of the exponent we’ve computed
into the next higher “slot”), and then repeat. In practice, these
tables can save 3-4x, even counting the time to build the ta-
bles in the ﬁrst place.
Polynomial Asymptotics. To generate a proof, the worker
must compute the polynomial h(x) such that t(x)·h(x) = P(x)
(§2). Since we store P(x) in terms of its evaluations at the
roots of the quadratic program (recall Figure 2), the worker
must ﬁrst interpolate to ﬁnd P(x) and then perform a polyno-
mial division to arrive at h(x).
Note that all of these computations take place in a normal
ﬁeld, whereas all of the worker’s other steps involve crypto-
graphic operations, which §5.1 shows are about three orders
of magnitude more expensive.
Thus, one might na¨ıvely conclude, as we did, that simple
polynomial algorithms, such as Lagrangian interpolation and
“high-school” polynomial multiplication, sufﬁce. However,
we quickly discovered that the O(n2) behavior of these algo-
rithms, at the scale required for veriﬁable computing, dwarfed
the linear number of cryptographic operations (§5.1). Hence
we implemented an FFT-based O(nlogn) polynomial mul-
tiplication library and used a polynomial interpolation algo-
rithm [48] that builds a binary tree of polynomials, giving
total time O(nlog2 n). Even so optimized, solving for h(x) is
the second largest source of worker overhead.
245
Preparing for the Future; Learning from the Past. In our
implementation and evaluation, we assume a worst case sce-
nario in which the client decides, without any warning, to
outsource a new function, and similarly that the worker only
ever computes a single instance for a given client. In prac-
tice, neither scenario is plausible. When the client ﬁrst installs
Pinocchio, the program, could, in theory, build the single base
exponent table discussed above. Further, it can choose a ran-
dom s and begins computing powers of s in the background,
since these are entirely independent of the computation.
Similarly, if the worker performs more than a single com-
putation for the client, he can hold onto the exponentiation
tables he built for the ﬁrst computation and save substantial
time on subsequent computations. He can also save the poly-
nomial tree used to accelerate the computation of h(x). None
of these values have any secret information, so workers could
potentially even share this information amongst themselves.
Working With Elliptic Curves. Our BN curve is deﬁned by
the equation y2 = x3 + b, in that each group element gi is a
point (x,y) on the curve. To speed operations, while comput-
ing on elliptic curve points, we represent them in projective
form, as three coordinates (x,y,z), which corresponds to the
afﬁne point (x/z2,y/z3). This is analogous to representing
a rational number as an integral numerator and denominator.
Projective coordinates reduce EC operation costs by ∼60%.
We save space in the cryptographic keys and proof by con-
verting points back to afﬁne form before storing or transmit-
ting them. Furthermore, rather than store (x,y), we store x
and a bit indicating which square root of x3 + b to use for y,
reducing key and proof size by another 50%.
4.3 Applications
Our system runs several applications, each of which can be
instantiated with some static parameters, and then each in-
stance can be executed with dynamic inputs.
Fixed Matrix multiplies an n × n matrix parameter M by
an n-length input vector A, and outputs the resulting n-length
vector M · A. We choose ﬁve parameter settings that range
from |M| = 200× 200 to |M| = 1000× 1000.
Two Matrices has parameter n, takes as input two n × n
matrices M1 and M2, and outputs the n× n matrix M1 · M2.
Matrix operations are widely used, e.g., in collaborative ﬁl-
tering [49]. (|M| = 30× 30 to |M| = 110× 110)
MultiVar Poly evaluates a k-variable, m-degree multivariate
polynomial. The (m + 1)k coefﬁcients are parameters, the k
variables x1, . . . ,xk are the inputs, and the polynomial’s scalar
value is the output. (k = 5, m = 6, 16,807 coeff. to k = 5,
m = 10; 644,170 coeff.)
Image Matching is parameterized by an iw × ih rectangular
image and parameters kw,kh. It takes as input a kw × kh im-
age kernel, and outputs the minimum difference and the point
(x,y) in the image where it occurs. (iw × ih = 25, kw × kh = 9
to iw × ih = 2025, kw × kh = 9)
Shortest Paths implements the Floyd-Warshall O(n3) graph
algorithm, useful for network routing and matrix inversion.
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:52:11 UTC from IEEE Xplore.  Restrictions apply. 
Op
Fixed Base Exp (naive)
Fixed Base Exp (opt)
Multi Exp, 254-bit exp (naive)
Multi Exp, 254-bit exp (opt)
Multi Exp, 32-bit exp (opt)
Multi Exp,
1-bit exp (opt)
Compress
Decompress
Pairing
Field Add
Field Mul
Base Curve
318.5µs
38.2µs
318.5µs
104.5µs
14.9µs
9.5µs
30.2µs
27.0µs
Twist Curve
1221.4µs
118.3µs
1221.5µs
401.0µs
56.8µs
36.4µs
2160.9µs
2168.3µs
0.9ms
50.2ns
361.1ns
Figure 4: Microbenchmarks. Breakdown of the main sources of
performance overhead in the larger protocol. (N = 100,σ ≤ 1%).
Poly Interp (naive)
Poly Interp (opt)
Poly Mul (naive)
Poly Mul (opt)
10
0.5ms
1.1ms
0.1ms
0.1ms
Degree
100
238.3ms
21.1ms
8.6ms
0.4ms
1000
202013.1ms
331.1ms
799.7ms
4.1ms
Figure 5: Cost of Polynomial Operations. Illustrates the impor-
tance of optimizing polynomial algorithms. (N = 500,σ ≤ 5%).
Its parameter n speciﬁes the number of vertices, its input is
an n× n edge matrix, and its output is an n× n matrix of all-
pairs shortest paths. (n = 8, e = 64 to n = 24, e = 576)
LGCA is a Lattice-Gas Cellular Automata implementation
that converges to Navier-Stokes [50]. It has parameter n, the
ﬂuid lattice size, and k, the iteration count. It inputs one n-cell
lattice and outputs another reﬂecting k steps. (n = 294, k = 5
to n = 294, k = 40)
SHA-1 has no parameters. Its input is a 13-word (416-bit)
input string, and it outputs the 5-word (160-bit) SHA-1 hash
of the input.
5 Evaluation
We experiment on a Lenovo X201 ThinkPad. We run on a
single core of a 2.67 GHz Intel Core i7 with 8 GB of RAM.
Pinocchio’s results use QAPs, since theory (§3.2) and practice
(§5.5) show they offer superior performance.
5.1 Microbenchmarks
We performed a series of microbenchmarks to quantify the
basic cost units of our protocol (Fig. 4). Field operations are
about three orders of magnitude cheaper than cryptographic
exponentiations or multiplications. As §3.1 explained, we use
an asymmetric pairing function, meaning that some group el-
ements live on a (relatively) cheap base curve, while others
live on the “twist” curve. Operations on the latter are 3-4×
as expensive, reinforcing the importance of our optimizations
to the VC protocol to move as many operations as possible
to the base curve. Ultimately, Pinocchio’s protocol requires
only the W polynomials to operate on the twist curve; all
other operations take place on the base curve.
(a) Per-Instance Veriﬁcation Latency
(b) Worker Latency
Figure 6: Performance Relative to Prior Schemes. Pinocchio
reduces costs by orders of magnitude (note the log scale on the y-
axis). We graph the time necessary to (a) verify and (b) produce a
proof result for multiplying two NxN matrices.
Figures 4 and 5 also show the impact of the exponentiation
and polynomial optimizations described in §4.2.1, which re-
duce costs by two to three orders of magnitude for polynomial
operations, and factors of 3-10 for exponentiations.
5.2 Comparison With Previous Work
Figure 6 plots Pinocchio’s performance against that of pre-
vious systems. We use the multiplication of two matrices as
our test application since it has appeared in several prior pa-
pers [25, 27], though simpler, non-cryptographic veriﬁcation
procedures exist [51, §7.1]. Since all of these prior schemes
are designated veriﬁer, we measure against Pinocchio’s des-
ignated veriﬁer mode.
We compare against 1) a na¨ıve version of a PCP-based
scheme [52]; 2) GGP [22], an early scheme that deﬁned veri-
ﬁable computation, but which relies on fully-homomorphic-
encryption (FHE); 3) Pepper [27], an optimized reﬁnement
of (1); and 4) Ginger [28], a further reﬁnement of Pepper.
We omit results from a separate PCP-based effort [25, 26],
since Ginger’s performance dominates it [28]. See Section 6
for more details on these schemes and the tradeoffs between
them. Since most of these schemes are ridiculously imprac-
tical, we model, rather than measure, their performance. For
GGP, we built a model of its performance based on the latest
performance results for FHE [53], while for the others, we
used previously published models [27, 28]. For Pinocchio,
however, we use real numbers from our implementation.
Figure 6 shows that Pinocchio continues the recent trend of
reducing costs by orders of magnitude. Early PCP and FHE-
based schemes are laughably impractical, taking hundreds to
trillions of years to produce or verify a single proof. Pepper
and Ginger have made huge improvements over prior work,
but, as we discuss in more detail in §6, they do not offer public
veriﬁcation or zero knowledge.
In addition to offering new properties, Pinocchio signif-
icantly improves performance and security. The systems
shown in Figure 6 amortize setup work across many work
246
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:52:11 UTC from IEEE Xplore.  Restrictions apply. 
255075100Matrix Dimension (NxN)10-310-1101103105107109101110131015101710191021Time (s)PCPsGGPPepperGingerPinocchio255075100Matrix Dimension (NxN)100102104106108101010121014101610181020Time (s)a parameterized app, and each point represents a particular
parameter setting. Our key ﬁnding is that, for sufﬁciently
large parameters, three apps cross the line where outsourc-
ing makes sense; i.e., verifying the results of an outsourced
computation is cheaper than local native execution.
On the downside, the other three apps, while trending in
the right direction, fail to cross the outsourcing threshold.
The difference is that these three apps perform large numbers
of inequality comparisons and/or bitwise operations. This
makes our circuit-based representation less efﬁcient relative
to native, and hence on our current experimental platform, we
cannot push the application parameter settings to the point
where they would beat local execution. Nonetheless, these
applications may still be useful in settings that require Pinoc-
chio’s zero-knowledge proofs.
Fortunately, additional experiments show that enabling
zero-knowledge proofs adds a negligible, ﬁxed cost to key
generation (213µs), and re-randomizing a proof to make it
zero-knowledge requires little effort (e.g., 300ms or 0.1% for
the multivariate polynomial app).
Figure 8 provides more details of Pinocchio’s performance.
For KeyGen, our experiments conservatively assume that the
client does no precomputation in anticipation of outsourcing