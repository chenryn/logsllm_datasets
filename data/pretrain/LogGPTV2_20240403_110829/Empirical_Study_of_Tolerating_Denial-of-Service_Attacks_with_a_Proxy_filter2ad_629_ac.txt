0.6
0.5
0.4
0.3
0.2
0.1
i
n
o
at
ul
p
o
P
er
s
U
er
v
O
F 
D
C
Direct App Access 
16 Edge Proxies, Height 3
32 Edge Proxies, Height 3
64 Edge Proxies, Height 3
64 Edge Proxies, Height 4
64 Edge Proxies, Height 5
Direct Application Access
1
1.5
2
2.5
Response Time (seconds)
0
0
0.5
1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
i
n
o
at
ul
p
o
P
r
e
s
U
er
v
O
F 
D
C
Vary Proxy Network Topology (10,000-Router Network)
Direct App Access
16 Edge Proxies, Height 3
32 Edge Proxies, Height 3
64 Edge Proxies, Height 3
64 Edge Proxies, Height 4
64 Edge Proxies, Height 5
Direct Application Access
0
0
0.5
1
1.5
2
2.5
Response Time (seconds)
Figure  8  Performance  in  two  simulated  networks  (Top:
R1K network Bottom: R10K network)
To validate the generality of our analysis, we repeat the 
experiments (download 100KB files) for a range of tree
topologies with different heights and widths in the two 
simulated networks described in Section 4.3 (see Figure 
8),  and  see  similar  phenomena.
  Thus,  the  factors 
discussed  above  are  generally  applicable  to  proxy
large  realistic  networks,  and  proxy
in 
networks 
networks 
in  general  can 
improve  user-
experienced  performance. 
is  a moderately
surprising  result,  which  is  not  so obvious  without  our 
large scale simulation study. 
in fact 
  This
These results are different to previous findings such as 
in [7], which evaluated the performance of WebSOS on
the PlanetLab [25] testbed, and reported 2 to 10 times
performance  degradation. We  believe  that  two  main 
factors  contribute  to  this  dramatic  difference.    First, 
WebSOS  uses Chord  routing  which  does  not  provide 
shortest  path  routing,  and  the  deployment  of  overlay
nodes  is  not  optimized  either.    These  factors  may
contribute  to  large  overhead  on the  overlay  route. 
Second, the connections among WebSOS nodes are not
persistent  and  not  necessarily  short.    Therefore,  the
USENIX Association
14th USENIX Security Symposium
57
WebSOS implementation cannot benefit from the TCP
behaviors  discussed  before  which  greatly  improve  our
proxy network performance.  Besides these factors, user
authentication  on  edge  proxies 3 and  less  efficient 
implementation 4 may  also  contribute  to performance 
overhead  for  WebSOS.    Our  results  indicate  that  the
performance of WebSOS can be significantly improved 
via  appropriate  construction, 
implementation,  and
deployment of proxy networks. 
5.2 DoS-Resilience of Proxy Networks 
To explore  the  DoS-resilience  capability  of proxy 
networks,  we study  user-experienced  performance 
under a range of attack scenarios, with or without proxy
networks. We  use  the  same  proxy network,  which 
contains 192 proxies (64 edge proxies), in the simulated
networks (R1K and R10K).  In addition, we constructed
a DDoS network, which contains 100 Trinoo daemons
randomly  distributed  in  the  network.    Each  Trinoo
daemon  has  a  100Mbps  link.    This  Trinoo network  is
comparable 
to one  with  10,000  zombies  using 
DSL/Cable modem links. 
Our first experiment explores whether a proxy network
can really protect an application from DoS attacks.  Our
second experiment studies the DoS-resilience capability
of  the proxy  network  under  two  large-scale  attack
scenarios:  spread  DoS  attacks,  where  attack  load  is 
distributed  evenly  on  all 
the  edge  proxies,  and 
concentrated DoS  attacks,  where  attack 
is 
concentrated  on a  subset  of  edge proxies  to  saturate
their  incoming  links.  We  consider  two  user  access 
schemes  in  these  attack  situations:  static  and  dynamic
edge  proxy  selection.    In the  static  scheme,  a  user
chooses  an  edge proxy  based  on proximity,  and
continue to use it even if the proxy is under attack.  In 
the dynamic scheme, a user can switch to other proxies 
if  the  closest  edge proxy  is  under  attack.    Our  final
experiment  studies  the  scalability  of  proxy  networks
with respect to DoS-resilience, by varying the size and
width of proxy networks.  
load 
5.2.1 Can a proxy network protect 
applications? 
We  compare  the  impact  of  a  DoS  attack on  the 
application and the proxy network. In our experimental 
setting,  the  application  service  is  connected by  a 
250Mbps link, and each edge proxy is connected by a 
100  Mbps  link.    Figure  9  shows  the  CDF  for  user-
observed response  time  of  100KB  requests  with or
without  a  proxy  network  in  the  R1K network.    The 
results show that a 250Mbps attack on the application 
significantly  increases  service  response  time  (about 
10x), and the application becomes unusable.  However,
when  a  proxy  network  is  used,  the  attack has  no
observable 
experienced
performance.  The reason is straightforward.  By having
a  collection  of  edge proxies  to dilute  the  impact  of
attack, a proxy network has a greater capacity than the
application, thereby not as easily being saturated.
impact 
user 
the 
on
Effectiveness of Proxy Networks
no attack (with proxies)
no attack (direct application access)
250Mbps attack (with proxies)
250Mbps attack (direct application access)
Direct App Access, No Attack 
1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
i
n
o
at
ul
p
o
P
er
s
U
er
v
O
F 
D
C
0
0
1
2
3
4
5
6
7
8
9
10
Response Time (seconds)
Figure 9 DoS Resilience of Proxy Network 
5.2.2 Resisting large-scale DoS attacks 
Spread Attack (R1K Network)
1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
i
n
o
at
ul
p
o
P
er
s
U
er
v
O
F 
D
C
0
0
1
2
3
4
5
Response Time (seconds)
No Attack
3.2 Gbps Attack
6.0 Gbps Attack
6.4 Gbps Attack
6
7
8
Spread Attack (R10K Network)
1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
i
n
o
at
ul
p
o
P
r
e
s
U
r
e
v
O
F 
D
C
0
0
1
2
3
Response Time (seconds)
No Attack
3.2 Gbps Attack
6.0 Gbps Attack
6.4 Gbps Attack
4
5
6
7
8
Figure 10 Performance under Spread Attacks
To  investigate  how  well  a  proxy  network can  tolerate 
DoS  attacks, we  launch  both  spread  and  concentrate
DoS attacks on the proxy network described in Section
5.1, which has 64 edge proxies and 192 proxies in total.
58
14th USENIX Security Symposium
USENIX Association
prominent when attack load is higher than the proxiesí 
capacity (e.g. 4.0Gbps attack on 32 proxies). 
Concentrated Attack (R1K Network)
0
0
1
2
No Attack
3.2 Gbps Attack on 32 Proxies
4.0 Gbps Attack on 32 Proxies
6.0 Gbps Attack on 48 Proxies
6.0 Gbps Attack on 60 Proxies
3
4
5
6
7
8
Response Time (seconds)
Concentrated Attack (R10K Network)
Each of the edge proxy has a 100Mbps uplink.  In both 
cases,  we  vary  the  aggregated  attack  magnitude from 
3.2Gbps to 6.4Gbps.
5.2.2.1 Resisting spreading attacks 
Figure  10  shows  the  usersí  experienced  performance 
under  spread  attacks.    It  shows  that  when  attack 
magnitude  is no  more  than  6.0Gbps  (recall  that  the 
aggregated uplink  capacity  for  all  the  edge  proxies  is 
6.4Gbps), more than 95% users observe no significant
performance degradation ñ the spread attacks have been
successfully  tolerated.    The reason  is  that  the  edge
proxies  successfully  dilute  attack  traffic;  even  under 
heavy attack loads, most of the edge proxies still have
sufficient capacity left to serve user requests.  Figure 10
also shows that when attack load reaches 6.4Gbps, all 
the edge proxies are saturated, significant performance 
degradation occurs for all users. 
Interestingly, we can see large performance degradation
for a small fraction of users (<5%) in the R1K network,
when the attack magnitude is 6.0Gbps. It is due to the 
correlation among proxies and users (see Figure 11).
Attack Traffic 
OC3 uplink
Internet 
Attack Traffic 
Edge proxy B 
Edge proxy A 
User
Figure 11 Correlation among Proxies and Users 
  Before  attack 
Two  edge  proxies  A  and  B  share  an  uplink  of  OC3
(155Mbps).
traffic  saturates  both
proxiesí  local  links  (100Mbps),  the  shared  OC3  link 
gets  congested  first.    Therefore,  users  on  these  two
proxies and users in the same network as these proxies 
will be affected.  This effect limits the effectiveness of
proxy networks. 