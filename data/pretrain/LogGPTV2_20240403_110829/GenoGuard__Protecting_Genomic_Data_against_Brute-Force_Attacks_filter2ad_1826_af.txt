(8)
HE,pm,p(cid:2)
where E is the expectation over the randomized password
k (B) with
pruning process, and we approximate Advmr
the maximum weight w(cid:2) in the password distribution p(cid:2)
k. In
the following, we quantify Adv(B(cid:2)
) empirically with real data.
For this purpose, we study a recent work about predicting
hair color from DNA (the HIrisPlex system [31]). The study
collects DNA samples and hair color information from 1551
European subjects and builds a model to predict the hair color.
The results are shown in Table II.
We use the Zipf’s model in [30], where N = 486118,
W = 0.037871 and s = 0.905773. For different hair col-
ors known by adversary B(cid:2), we perform the Bernoulli trials
with corresponding Pret on the password pool, and estimate
Adv(B(cid:2)
) in Equation (8). We repeat the whole experiment 1000
times for each hair color, and the average results are shown in
Figure 12.
With the “Red” hair information, the adversary’s advantage
increases from 0.0379 to 0.0642, which is the worst among the
458458
Fig. 11: Evaluation of ancestry compatibility on GenoGuard.
(a) Ancestry inference with PCA on three populations: ASW
(lower left cluster), CEU (upper left cluster), and CHB (right
cluster). The red crosses are sequences decrypted from an
ASW person with randomly guessed passwords, but with
public haploid genotype dataset from different populations: (b)
ASW; (c) CEU; (d) CHB. We can see that, regardless of the
population which the original sequence belongs to, the ancestry
of the decrypted sequence only depends on population-speciﬁc
haploid genotype dataset used for the decoding.
exposed to the adversary as side information. For instance, the
adversary could have access to a small number of phenotypical
traits by observing a victim’s photographs from online social
networks.
Consider a genetic trait that has a set of possible phe-
notypes {T1, T2,··· , Tu}. For example, the trait “hair color”
can have phenotype set {Red, Blond, Brown, Black}. Let PTi
denote the prior probability of a phenotype Ti. Each phenotype
Ti is also associated with a vector of prediction probabili-
ties ATj
is the
probability that the best classiﬁcation algorithm will associate
the sequence with phenotype Tj. Then, a brute-force attack
proceeds as follows. For each password, the adversary uses
it to decrypt the ciphertext, inputs the result sequence to the
classiﬁer, and excludes the password if the phenotype does not
match; otherwise he retains the password. We assume that the
adversary trusts the classiﬁer and makes a binary decision on
whether he should retain the password.
Ti : given a sequence with phenotype Ti, ATj
Ti
(cid:5)N
Suppose there are totally N unique passwords at
the
beginning, and they are in descending order regarding their
probabilities: P1 ≥ P2 ≥ ··· ≥ PN . The order of a password
Pi = 1. It has been
is usually called its rank. Note that
shown that the distribution of real-life passwords obeys Zipf’s
law [29], [30]. In other words, for a password dataset, the
probability of password with rank i is
Pi = W i−s,
(6)
where W and s are constants depending on the dataset.
i=1
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:07:07 UTC from IEEE Xplore.  Restrictions apply. 
before, we used the Phase 3 data in International HapMap
Project, for the CEU population [22]. We set
the storage
overhead parameter h = 4. As for password-based encryption
(decryption), we followed the standard PKCS #5 [16]. That
is, using HMAC-SHA-1 as the underlying pseudorandom
function, given a password P , we ﬁrst applied a key derivation
function
DK = KDF (P, S),
where DK is a 128-bit derived key and S is a 64-bit random
salt. DK is used as the key for an AES block cipher that en-
crypts the seed in CBC mode. We ran the algorithm on a cluster
of 22 nodes, each with 3.40GHz Intel Xeon CPU E31270
and 64-bit Linux Debian systems. In other words, the task of
encrypting the whole genome was parallelized in 22 nodes
that independently encrypt 22 chromosomes. We evaluated
GenoGuard on 165 CEU samples, and the average performance
is shown in Figure 13. Although encoding (decoding) is more
costly than PBE, it is still acceptable considering the size of a
full genome. Moreover, encoding different chromosomes was
run in parallel, hence the running time depends only on the
longest chromosome.
t
e
g
a
n
a
v
d
A
s
y
r
a
s
r
e
v
d
A
’
0.0642
0.07
0.06
0.05
Adversary B
Adversary B(cid:21)
0.04
0.0379
0.0379
0.0379
0.0379
0.0382
0.0416
0.03
0.02
0.01
0.00
Red
0.0189
Blond
Victim’s Hair Color Known by Adversary B(cid:2)
Brown
Black
Fig. 12: Evaluation of adversary’s advantage with the side
information of hair color. Adversary B has no side information,
and his advantage is approximately w = 0.0379, the maximum
weight in the original password distribution pk. The advantage
of adversary B(cid:2) depends on the prediction accuracy AT∗
T∗ and
the retaining probability Pret for the victim’s hair color T ∗.
k←f (pk)[w(cid:2)
four colors (for the victim). This is explained by the fact that
“Red” hair has a very low prior probability that leads to a small
Pret, hence most wrong passwords are deleted. We observe
that the empirical estimation of Ep(cid:2)
] is consistently
larger for a smaller Pret. On the contrary, because “blond” hair
has a high prior probability, a larger number of passwords are
] and smaller Adv(B(cid:2)
retained, hence smaller Ep(cid:2)
),
compared to the case of “Red” hair. From Equation (8), the
advantage is also positively correlated to the accuracy of the
prediction algorithm. The low accuracies for “Brown” and
“Black” hair (ABrown
Black) explain why the advantage
of adversary B(cid:2) barely increases, or even decreases9, compared
to adversary B.
Brown and ABlack
k←f (pk)[w(cid:2)
Even though side information is a common security con-
cern in cryptography, we propose a general idea to avoid
this problem for GenoGuard: incorporate the side information
during the encoding phase. Nontrivial as this is, we will
elaborate this idea in our future work, especially for traits with
probabilistic genotype-phenotype associations.
VII. DISCUSSION
In this section, we discuss the performance, application
scenarios, some extensions, and limitations of the proposed
scheme.
A. Performance
The time complexity of the encoding phase is O(n) where
n is the length of the sequence. Moreover, the storage overhead
of the encrypted seeds is low as shown in Figure 9. Note
that the ternary tree does not need to be stored. The encoding
and decoding process are completely executed based on public
knowledge; not on a pre-stored tree.
We implemented GenoGuard in Python. It includes mainly
four steps: encode, decode, PBE encrypt, PBE decrypt. As
9When the prediction is unreliable, it’s better for the adversary to ignore
the side information.
Fig. 13: Performance of GenoGuard on 22 chromosomes,
averaging over 165 CEU samples. The dashed line shows the
length of each chromosome, whereas the solid lines show
the running time of the four procedures: encode, decode,
PBE encrypt, PBE decrypt. The number of SNVs roughly
decreases from chromosome 1 to chromosome 22. We can see
that the running time of password-based encryption (decryp-
tion) is negligible compared to encoding (decoding), whose
running time increases almost linearly with the length of a
chromosome).
B. Application Scenarios
GenoGuard can be applied to various scenarios, including
healthcare and recreational genomics, for the protection of
genomic data. The general protocol in Figure 3 can work
in a healthcare scenario without any major changes. In this
scenario, a patient wants a medical unit (e.g., his doctor) to
access his genome and perform medical tests. The medical
unit can request for the encrypted seed on behalf of (and with
consent from) the patient. Hence, there is a negotiation phase
that provides the password to the medical unit. Such a phase
459459
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:07:07 UTC from IEEE Xplore.  Restrictions apply. 
can be completed automatically via the patient’s smart card (or
smart phone), or the patient can type his password himself. In
this setup, the biobank can be a public centralized database
that is semi-trusted. Such a centralized database would be
convenient for the storage and retrieval of the genomes by
several medical units.
his ﬁngerprint template that is stored with some honey tem-
plates (e.g., synthetic ﬁngerprint images [34], or other users’
templates). These templates can also be indexed as what we
propose for the conﬁrmation images above. During retrieval,
only the user can verify whether the decryption is correct or
not using his own ﬁngerprint.
For direct-to-customer (DTC) services, the protocol needs
some adjustments. For instance, Counsyl10 and 23andMe11
provide their customers various DTC genetic tests. In such
scenarios, the biobank is the private database of these service
providers. Thus, such service providers have the obligation to
protect customers’ genomic data in case of a data breach. In
order to perform various genetic tests, the service providers
should be granted permission to decrypt the sequences on
their side, which is a reasonable relaxation of the threat model
because customers share their sequences with the service
providers. Therefore, steps 8 and 9 in Figure 3 should be
moved to the biobank. A user (customer) who requests a
genetic test result logs into the biobank system, provides the
password for password-based decryption and asks for a genetic
test on his sequence. The plaintext sequence is deleted after
the test.
C. Typos
Providing an incorrect password yields a fake but valid-
looking sequence. This is a good security characteristic of
honey encryption, but can be bad for usability if a legitimate
patient or doctor does not realize she has made a mistake when
typing the password. To solve this problem, we propose several
solutions, as discussed below.
The ﬁrst idea is to append to the plaintext some information
that is unique and veriﬁable by the patient but meaningless for
the adversary. We propose encoding such information (such as
a 4-digit PIN chosen by the patient) as a string of bits similar
to the seed. Such a PIN can be appended to the seed and
encrypted together. In other words, the third encryption step
in Figure 1 can be replaced with C ← $ encrypt(K, S||PIN, r).
This option works well if the PIN is a uniformly random string;
otherwise it will cause some security degradation because
S||PIN is no longer uniform. Moreover, it requires the PIN
to be kept secret and that the adversary cannot link it to a
patient.
Another approach might be to leverage the distinction
between recall memory and recognition memory [32]. The
latter is shown to be more robust than the former. For in-
the system can provide a pool of N conﬁrmation
stance,
images, and the user can choose one before encryption. The
conﬁrmation images do not themselves have to be part of the
ciphertext. The system can hash the genome sequence into
ZN = {0, 1, 2,··· , N − 1} to obtain a conﬁrmation index,
for security parameter N. The user might conﬁrm correct
decryption simply by indicating that a displayed image is
familiar. A similar idea has been proposed in previous work
where the authors apply it to anti-phishing techniques [33].
Another idea is based upon concealment of a biometric
template among decoys. For instance, the user can provide
10https://www.counsyl.com/.
11https://www.23andme.com/.
VIII. RELATED WORK
Privacy concerns around genomic data have been exten-
sively investigated by researchers in recent years. Homer et
al. [2] show the possibility of inferring the participation of an
individual in a genotype database with the help of public allele
frequencies. Wang et al. [3] give similar results of inference
power based on p-values released in genome-wide association
studies. As a response to the above privacy breach in pub-
lished genomic statistics, Fienberg et al. [4] propose to apply
Laplacian noise to the released data to achieve differential
privacy. Another approach to achieving differential privacy in
genome-wide association study is proposed by Johnson and
Shmatikov [5]. Yu et al. [6] present scalable privacy-preserving
methods in genome-wide association studies based on Laplace
mechanism and exponential mechanism. In spite of these
works about differentially private genomic data, Fredrikson et
al. [35] demonstrate an unsatisfactory tradeoff between privacy
and utility in an end-to-end case study of personalized warfarin
dosing. A similar unsatisfactory result in an association study
is also mentioned by Erlich and Narayanan [36].
Jha et al. [37] design several privacy-preserving protocols
for some fundamental genomic computations (edit distance
and Smith-Waterman score) that use oblivious transfer and
oblivious circuit evaluation. Kantarcioglu et al. [9] propose the
use of homomorphic encryption to store encrypted genomic
sequence records in a centralized repository, such that queries
can be executed without decryption and thus without violat-
ing participants’ privacy. Baldi et al. [10] propose a set of
techniques based on private set operations to address genomic
privacy in several important applications, namely, paternity
tests, personalized medicine, and genetic compatibility tests.
Ayday et al. [8] introduce a framework that integrates stream
ciphers and order-preserving encryption to store and retrieve
raw genomic data in a privacy-preserving manner. Researchers
also propose to protect privacy in genomic computation by
partitioning the computation through program specialization,
according to the sensitivity levels of different parts of the
genome data [7]. Naveed et al. [38] provide a comprehensive