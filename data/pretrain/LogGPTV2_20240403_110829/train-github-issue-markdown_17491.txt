**Is this a request for help?** (If yes, you should use our troubleshooting
guide and community support channels, see
http://kubernetes.io/docs/troubleshooting/.): kinda
**What keywords did you search in Kubernetes issues before filing this one?**
(If you have found any duplicates, you should instead reply there.): OutOfCPU
* * *
**Is this a BUG REPORT or FEATURE REQUEST?** (choose one): BUG REPORT
**Kubernetes version** (use `kubectl version`):
    Client Version: version.Info{Major:"1", Minor:"3", GitVersion:"v1.3.2", GitCommit:"9bafa3400a77c14ee50782bb05f9efc5c91b3185", GitTreeState:"clean", BuildDate:"2016-07-17T18:30:39Z", GoVersion:"go1.6.2", Compiler:"gc", Platform:"darwin/amd64"}
(cluster is now torn down, but is also 1.3.2 with the same commit)
**Environment** :
  * **Cloud provider or hardware configuration** : AWS - 80 c4.4xlarge nodes
  * **OS** (e.g. from /etc/os-release): CoreOS 1068.8.0 (stable)
**What happened** :
Scheduling roughly 10k Pods on 80 nodes with 16 cores each, lots of pods end
up having issues with being scheduled and end up with an OutOfCPU error. In
the case below, we were experimenting with increasing `limits` to beyond the
node capacity, but we found the behaviour on the `Guaranteed` (limits and
requests set to 14) and `Burstable` classes. To me, it appears like the
scheduler is having problems keeping track of the resources in use and is
trying to over-provision the node.
Here's the `describe pods` Note that the extra 100m CPU reported as being used
is from system containers (fluentd, etc.)
    $ kubectl describe pods worker-7f1df241-5c3f-45cd-8df3-6caa2c972f68
    Name:           worker-7f1df241-5c3f-45cd-8df3-6caa2c972f68
    Namespace:      default
    Node:           
    Start Time:     Tue, 16 Aug 2016 13:02:38 +0800
    Labels:         sample=,submitter=
    Status:         Failed
    Reason:         OutOfCPU
    Message:        Pod Node didn't have enough resource: CPU, requested: 14000, used: 14100, capacity: 16000
    IP:
    Controllers:    
    Containers:
      pod-template:
        Image:      
        Port:
        Command:
        QoS Tier:
          cpu:      Burstable
          memory:   BestEffort
        Limits:
          cpu:      32
        Requests:
          cpu:      14
    Volumes:
      workdir:
        Type:       HostPath (bare host directory volume)
        Path:       /mnt
      default-token-u3fnm:
        Type:       Secret (a volume populated by a Secret)
        SecretName: default-token-u3fnm
    Events:
      FirstSeen     LastSeen        Count   From                                                    SubobjectPath   Type            Reason          Message
      ---------     --------        -----   ----                                                    -------------   --------        ------          -------
      31m           31m             1       {kubelet }                     Warning         OutOfCPU        Node didn't have enough resource: CPU, requested: 14000, used: 14100, capacity: 16000
**What you expected to happen** :
Pod to stay in a `Pending` state whilst resources are not available for
scheduling.
**How to reproduce it** (as minimally and precisely as possible):
Submit 10k jobs requiring 14 CPUs on a cluster containing 16 cores each. Note
that in this case, we are submitting all 10k jobs within a 1 minute time
window.
**Anything else do we need to know** :