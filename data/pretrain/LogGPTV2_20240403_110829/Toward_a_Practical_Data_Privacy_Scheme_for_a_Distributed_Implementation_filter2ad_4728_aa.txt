title:Toward a Practical Data Privacy Scheme for a Distributed Implementation
of the Smith-Waterman Genome Sequence Comparison Algorithm
author:Doug Szajda and
Michael Pohl and
Jason Owen and
Barry G. Lawson
Toward A Practical Data Privacy Scheme for A Distributed Implementation of
the Smith-Waterman Genome Sequence Comparison Algorithm∗
Doug Szajda
Michael Pohl
Jason Owen
Barry Lawson
University of Richmond
Richmond, Virginia
{dszajda, mike.pohl, wowen, blawson}@richmond.edu
Abstract
Volunteer distributed computations utilize spare proces-
sor cycles of personal computers that are connected to the
Internet. The resulting platforms provide computational
power previously available only through the use of ex-
pensive clusters or supercomputers. However, distributed
computations running in untrustworthy environments raise
a number of security concerns, including computation in-
tegrity and data privacy.
This paper introduces a strategy for enhancing data pri-
vacy in some distributed volunteer computations, providing
an important ﬁrst step toward a general data privacy so-
lution for these computations. The strategy is used to
provide enhanced data privacy for the Smith-Waterman
local nucleotide sequence comparison algorithm. Our
modiﬁed Smith-Waterman algorithm provides reasonable
performance, identifying most, and in many cases all, se-
quence pairs that exhibit statistically signiﬁcant similarity
according to the unmodiﬁed algorithm, with reasonable
levels of false positives. Moreover the modiﬁed algorithm
achieves a net decrease in execution time, with no increase
in memory requirements. Most importantly, our scheme
represents an important ﬁrst step toward providing data
privacy for a practical and important real-world algorithm.
Keywords:
distributed computation, data privacy,
Smith-Waterman algorithm
1. Introduction
Distributed volunteer computing platforms, in which
personal computers connected to the Internet volunteer idle
processor cycles to a large-scale distributed computation,
∗This work was partially supported by the National Science Founda-
tion under grant IIS-0524239.
enable computations once feasible only via expensive clus-
ters or supercomputers. The computing power harnessed
by these systems can top several petaﬂops, making them
well suited for solving some SIMD-style parallel computa-
tions. Application domains beneﬁting from this technique
include DNA gene sequence comparisons and protein fold-
ing in the biotechnology industry, advanced graphics ren-
dering in the entertainment industry, exhaustive regression
and other statistical applications in the ﬁnancial industry,
some forms of data mining, and Monte Carlo simulations.
The typical computation in this setting is easily divisible
into independent tasks small enough to be handled in a few
hours by a typical personal computer.
In the common scenario, the supervisor of a volunteer
distributed computing platform recruits participants who
agree to allow the supervisor to execute code on their per-
sonal computers, either in exchange for some form of re-
muneration (in a commercial setting) or on a voluntary ba-
sis. Participants then download code that serves as the local
execution environment for assigned computational tasks.
For a given computation, participants are chosen, tasks are
assigned and transmitted, and, as tasks are completed, sig-
niﬁcant results are returned to the supervisor. Though task
results may be related, the tasks themselves are indepen-
dent, so no communication is necessary between partici-
pants.
Because code is executed in untrustworthy environ-
ments, several security concerns are raised. Among the
major issues is data privacy. Firms may have obtained data
at great expense and are often reluctant to expose this pro-
prietary information to unknown individuals. This is espe-
cially relevant in the biotechnology industry, where genetic
data gleaned from years of experimentation is often closely
guarded.
While there is a small but growing body of literature
dealing with providing greater assurance of the validity of
results of volunteer computations ([21, 22, 25, 32, 34, 35]),
to our knowledge no research has addressed the associated
issue of data privacy. There is a long history of research
concerning computing with encrypted data ([2, 3, 5, 12,
15, 17, 29, 31]) that has resulted in many interesting and
elegant results. Unfortunately, there are few real-world ap-
plications for which these methods are practical.
Our approach to providing data privacy is similar in
spirit to computing with encrypted data. In that scenario,
Alice has a function f and an input x. She wants Bob to
compute f (x) for her, but she does not wish to reveal x.
So she encrypts x (creating E(x)), and asks Bob to com-
pute f 0(E(x)), where f 0 is such that Alice can easily de-
termine f (x) from f 0(E(x)), but Bob cannot determine x
from E(x) and/or f 0(E(x)). If this can be accomplished, f
is said to be encryptable, and the transformations involved
comprise an encryption scheme for f.
For a volunteer distributed computation that seeks to
identify essential (in some sense) inputs the constraints are
signiﬁcantly relaxed. In this case, Alice has several x val-
ues and seeks to determine which are important in her con-
text. Because Alice does not necessarily require the spe-
ciﬁc function values to make this determination, there is
far greater ﬂexibility in the deﬁnition of f 0. We call this
loosely deﬁned notion sufﬁcient accuracy.
Alice enjoys another advantage in the present context:
she has several (possibly millions of) potential suitors of-
fering computing services. Thus, the possibility exists that
for each x, Alice can distribute the work of computing
f 0(E(x)) over several parties. Provided this can be done
in a manner that ensures that no participant possesses suf-
ﬁcient information to determine x, then Alice can, in the
absence of collusion, keep x conﬁdential.
The notion of sufﬁcient accuracy is particularly rele-
vant for distributed optimization computations, i.e., those
computations intended to locate optimum (or sufﬁciently
close to optimum) values of some function f. These com-
putations act as ﬁlters because identiﬁcation of the distin-
guished input(s) is sufﬁcient to determine the associated
extreme value(s). Many important applications deployed
on volunteer distributed computing platforms, including
exhaustive regression, genetic sequence comparisons, and
protein folding, are optimizing computations. In practice,
the data identiﬁed as meaningful by participants are subse-
quently subjected to far more extensive, and typically more
expensive, postprocessing analysis by the supervisor. This
further relaxes problem constraints: data can sometimes be
(mis)identiﬁed as important, provided the number of these
false positives is sufﬁciently small, as long as truly impor-
tant data is rarely, if ever, missed.
The speciﬁc contributions of this paper are to:
• Introduce the concept of sufﬁcient accuracy.
• Present a strategy for enhancing data privacy in a prac-
tical and important real-world application: the Smith-
Waterman local nucleotide sequence comparison al-
gorithm. The importance of this algorithm is under-
scored by the fact that Smith-Waterman has been im-
plemented in commercial distributed computing set-
tings.
• Present a practical and important real-world applica-
tion that requires data privacy and is efﬁciently par-
allelizable. Such applications have so far proven elu-
sive. The present example thus represents a possible
ﬁrst entry for a benchmark suite of applications for
privacy study.
The strategy described here is not applicable to all vol-
unteer distributed optimization computations — there are
cases in which the information required to determine the
importance of data cannot be preserved without revealing
the data itself. Nor do we claim that our scheme repre-
sents the ﬁnal (or only) solution to the problem of data pri-
In many ways,
vacy for the Smith-Waterman algorithm.
our solution for this example is less than ideal.
In the
best possible situation, formal privacy and adversary mod-
els would be developed, and the efﬁcacy of our solutions
proved within that framework. Unfortunately, such mod-
els tend to be far too restrictive for real-world applications.
Our approach, on the other hand, is more heuristic in na-
ture. Heuristic solutions are problematic because they are
not formally veriﬁed, and are thus often vulnerable to unan-
ticipated attack strategies. Regardless, our solution repre-
sents a ﬁrst step: for many conﬁgurations, our modiﬁed
algorithm identiﬁes all statistically signiﬁcant sequences
without a single false positive. Moreover its security can
be reasonably estimated, though not rigorously measured,
via entropy calculations. The second shortcoming of our
strategy is that in no case, and for no speciﬁc conﬁgura-
tion, do we achieve the sensitivity of the unmodiﬁed Smith-
Waterman algorithm, which is theoretically guaranteed to
ﬁnd the best matching substrings from a pair of sequences.
Our methods do, however, in many cases exhibit sensitiv-
ity comparable to Smith-Waterman. Finally, the methods
here apply only to nucleotide sequence comparisons, not
to amino acid sequence comparisons (for reasons that are
discussed in Section 4).
The remainder of the paper is organized as follows. In
Section 2 we present our model for the distributed compu-
tations and platforms under consideration. Section 3 dis-
cusses the general technique as applied to optimizing dis-
tributed volunteer computations. We provide brief intro-
duction to biological sequence analysis in Section 4. Sec-
tions 5 and 6 present the details of our privacy scheme
for Smith-Waterman and present related simulation results.
Related work is discussed in Section 7. We present our
conclusions in Section 8.
2
2. The model
We consider parallel computations in which the primary
computation, the job, is easily divided into tasks small
enough to be solved by a PC in a reasonable amount of
time (typically on the order of several hours of CPU time).
Individual tasks are independent of one another.
The computing platform consists of a trusted central
control server or server hierarchy (which we denote using
the term supervisor) coordinating typically between 104
and 107 personal computers in a master-slave relationship.
These slave nodes, or participants, are assigned tasks by
the supervisor. Participants download code, typically in the
form of a screen saver or applet, that serves as the local ex-
ecution environment for tasks. Because tasks are indepen-
dent, communication between participants is unnecessary
and, assuredly, not permitted.
Formally, a job consists of the evaluation of a function or
algorithm f : D → R for every input value x ∈ D. Tasks
are created by partitioning D into (possibly overlapping)
subsets Di, with the understanding that task T (Di) will
evaluate f (x) for every input x ∈ Di. Each task T (Di)
is assigned a ﬁlter function Gi : P (R) → P (Z+ ∪ {0}),
where P (R) is the power set of R. Each x ∈ D is as-
sumed to have a unique (nonnegative integer) identiﬁer,
id(x). The element x ∈ Di is considered signiﬁcant
(equivalently f (x) is a signiﬁcant result) if and only if
id(x) ∈ Gi(f (Di)), where f (Di) ≡ {f (x)|x ∈ Di}. That
is, the ﬁlter function returns the indices of signiﬁcant el-
ements x ∈ Di. The ﬁlter functions have domain P (R),
rather than R itself, because the signiﬁcance of an input
may depend on its function value relative to the function
values of other elements of Di.
We assume the existence of a global intelligent adver-
sary. The adversary possesses sufﬁcient technical skills to
efﬁciently decompile, analyze, and/or modify executable
code as necessary. In particular, the adversary has knowl-
edge both of the algorithm used for the computation and of
the measures used to prevent data disclosure.
Attacks that result from a compromise of data in transit
are beyond the scope of this paper — we assume the in-
tegrity of such data is veriﬁed by other means. In addition,
we do not consider attacks that result from the compromise
of the central server or other trusted management nodes. Fi-
nally, we do not consider attacks resulting from malicious
participants returning incorrect results or through the col-
lusion of such adversaries.
3. Leveraging Sufﬁcient Accuracy
The theory behind the sufﬁcient accuracy method is
straightforward. The success of a task T (Di) in a ﬁltering
computation is based solely on whether important values
in Di are identiﬁed. Presumably the intrinsic value of in-
put x ∈ Di will depend (at least in part) on the value f (x).
But determination of the importance of x, rather than re-
turning the value f (x), can sometimes be achieved using
inputs x0 and functions f 0 that differ signiﬁcantly from x
and f. In effect, considerable ﬂexibility is introduced into
the precise deﬁnitions of inputs and functions.
Our strategy for achieving data conﬁdentiality with task
T (Di) involves transforming the set Di, function f, and ﬁl-
i, function f 0 and ﬁlter function
ter function G into a set D0
G0 such that T (Di) can be replaced with the task T (D0
i)
consisting of the evaluation of f 0 on D0
i. Ideally, the trans-
formation achieves the following transformation proper-
ties.
1. The task T (D0
i) should not leak any additional infor-
mation about the values in Di other than what can be
learned from public sources and the values, f (Di),
output by the untransformed function.
2. The set of identiﬁers G0(T (D0
i)) returned from T (D0
i)
contains the set of identiﬁers G(T (Di)).
3. The difference G0(T (D0
i)) − G(T (Di)) is reasonably
small, where the deﬁnition of reasonable is application
dependent.
In practice there is ﬂexibility in these requirements. Some
applications may tolerate a few missed important results
provided that a certain proportion of identiﬁed important
results are generated. Others may accept some ﬂexibility
on the number of false positives, provided that no important
results are missed1.
Note that the transformations here differ from tradi-
tional encryption algorithms and hash functions in impor-
tant ways. Good encryption algorithms must be reversible,
and should exhibit a strong avalanche effect. A strong
avalanche effect in the current context, however, will likely
obscure information to a degree that similar inputs will
not be identiﬁed as such. Furthermore, our transforma-
tion, like hash functions, should not be reversible. How-
ever hash functions should also exhibit a strong avalanche
effect. They must also be repeatable, while the transforma-
tions here need not be.
4. Smith-Waterman Sequence Comparison
A thorough treatment of sequence comparison tech-
niques would (and does) ﬁll several texts. This section
gives a brief description of a dynamic programming align-
ment technique developed by Smith and Waterman [33].
1The notion that encryption/decryption schemes can have less than
100% accuracy is not unprecedented in the cryptographic literature (see
e.g., [4], [6], [16])
3
The sequences that biologists study consist of either nu-
cleotide bases (occurring in DNA fragments) or amino
acids (the building blocks of proteins). We consider only
DNA sequences, for which the underlying alphabet, Σ,
consists of the set {A, C, T, G} representing the nucleic
acids adenine, cytosine, thymine, and guanine.
Let U = u1u2 . . . un be a sequence2 over Σ. Sequences
evolve primarily in three ways. Either an element of a se-
quence is removed (a deletion), an element is inserted (an
insertion), or an existing element is transformed into a dif-
ferent element (a substitution). Biologists track evolution-
ary changes by writing the original sequence alongside the
new sequence with appropriate positions aligned. For ex-
ample, if U = CTGTTA, and u2 undergoes a transforma-
tion from T to A, this would be written
U: CTGTTA
V : CAGTTA
If instead u4 is deleted from U, this is written
U: CTGTTA
V : CTG–TA
where the ‘–’ symbol acts as a placeholder, allowing the
other symbols to remain aligned. Positions in a sequence
with the ‘–’ symbol are called gaps. If U is modiﬁed by
inserting the nucleotide G in position 2 , this is represented
by
U: C –TGTTA
V : CGTGTTA
After several such mutations, U may have evolved signiﬁ-
cantly. We can represent this evolution with an alignment
such as the following.
U: C–TGT– –TA– –
V : CTA–TGCT–CG
In the example above, we assume that V evolves from U.
In general, however, when given an alignment of two se-
quences, there is no implied origin — it is impossible to
tell whether a particular gap is caused by a deletion or an
insertion. Because of this symmetry, insertions and dele-
tions are considered the same event, an indel.
Note that two sequences can be aligned in several ways,
and that aligned sequences need not have the same length.
Waterman [37] asserts that the number of alignments of
two sequences of length n is asymptotically equal
to
(25/4/√π)(1 + √2)2n+1(1/√n). Thus, for example, two
2Though computer scientists typically begin sequences with index zero
rather than one, biologists prefer to begin their sequences with index 1. We
adhere to the biologists practice in this paper, so that the Smith-Waterman
description here matches that in the biology literature. In addition, this
convention eliminates the need for negative indices in the resulting dy-
namic programming matrices.
sequences of length 1000 have approximately 7.03× 10763
distinct alignments.