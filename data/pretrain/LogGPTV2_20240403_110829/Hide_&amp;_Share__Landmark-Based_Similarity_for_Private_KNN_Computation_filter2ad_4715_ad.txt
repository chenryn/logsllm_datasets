1) Computational overhead: We observe that the compu-
tational overhead of H&S is negligible from the point of view
of peers. The most computationally intensive elements of the
H&S similarity are (1) the authenticated key agreement (AK)
protocol, (2) the generation of random bits (bit commitment
scheme and mostly landmark generation), (3) the cosine sim-
ilarity computations with landmarks.
(1) Executing cryptographic primitives incurs negligible
cost on modern devices. It is similar to accessing a website
with HTTPS: the end user does not perceive a difference
between accesses over HTTP and HTTPS. (2) Efﬁcient PRNGs
such as Mersenne Twister can generate millions of bit/second
on modern devices and H&S only needs a few thousands
of bits to generate landmarks during a gossip cycle, which
lasts several seconds at least. (3) Cosine similarity is cheap
to compute on binary vectors such as landmarks and compact
proﬁles. This conﬁrms the applicability of our approach.
V. PRIVACY GUARANTEE
We now analyze H&S from an information theoretical
viewpoint and compute an upper bound on the amount of
information leaked during our landmark-based similarity com-
putation. We carry out our analysis from the point of view of
an attacking peer, a, that seeks to obtain information about
another peer, p.
During the protocol, a, and p share three pieces of in-
formation: the common seed they agree upon, the landmarks,
{M1, . . . , ML}, they generate using this seed, and the sim-
ilarity vectors (cid:2)σ containing their similarity with respect to
{M1, . . . , ML}. The ﬁrst two of these items do not depend
on the proﬁle of p and thus do not disclose any information.
So we concentrate our analysis on the information that (cid:2)σp may
leak about the corresponding compact proﬁles.
A. Conditional Entropy as a Measure of Information Leakage
We start our analysis by obtaining a ﬁrst expression for
the amount of information leaked by our landmark-based
similarity computation. From the attacker’s perspective, we
deﬁne C as the random variable for p’s compact proﬁle,
with realization (cid:2)c. Let (cid:2)σ be the vector of similarity values
between (cid:2)c and each of the landmarks in the landmark matrix.
According to the deﬁnition of cosine similarity, we have
σi = cos((cid:2)c, Mi) =
||(cid:2)c||·||Mi||∀i ∈ {1, ..L}.
(cid:2)cMi
Let us now deﬁne an adjusted similarity vector (cid:2)v =
{v1, ..., vn}, such that vi = σi · ||Mi||. Then, vi = (cid:2)c||(cid:2)c|| · Mi.
The goal of an attacker is to guess (cid:2)c based on the knowledge
of M and (cid:2)σ. But knowledge of M and (cid:2)σ implies knowledge
(cid:2)c||(cid:2)c|| implies knowledge of (cid:2)c because
of (cid:2)v, while knowledge of
(cid:2)c is a binary vector. We can therefore analyze the case of an
attacker that tries to guess
(cid:2)c||(cid:2)c|| based on (cid:2)v and M.
270270
To this end, we deﬁne W as the random variable for p’s
normalized compact proﬁle, with realization (cid:2)w = (cid:2)c||(cid:2)c||. We
also deﬁne V as the random variable for the corresponding
adjusted similarity vector with realization (cid:2)v, and M t as the
random variable for the landmark matrix with realization M.
We can then express the uncertainty about W given V
and M t through the conditional entropy H(W|V, M t). Such
uncertainty corresponds to the amount of information protected
from the adversary. According to the deﬁnition of conditional
entropy, we have:
H(W|V, M t) =
p( (cid:2)w, (cid:2)v, M ) log
p((cid:2)v, M )
p( (cid:2)w, (cid:2)v, M )
.
(2)
(cid:3)
(cid:2)w,(cid:2)v,M
(cid:4)
=
(cid:3)
(cid:3)
(cid:3)
We can then express p( (cid:2)w, (cid:2)v, M ) as follows.
p( (cid:2)w, (cid:2)v, M ) = p((cid:2)v| (cid:2)w, M )p( (cid:2)w, M )
1 · p( (cid:2)w, M )
0
if (cid:2)v = (cid:2)wM
if (cid:2)v (cid:11)= (cid:2)wM
This allows us to rewrite Equation (2).
H(W|V, M t) =
(cid:2)w,(cid:2)v,M, s.t. p( (cid:2)w,(cid:2)v,M )(cid:3)=0
p( (cid:2)w)p(M ) log
=
=
p( (cid:2)w)p(M ) log
(cid:3)
(cid:2)w,(cid:2)v,M, s.t. p( (cid:2)w,(cid:2)v,M )(cid:3)=0
(cid:3)
p(M )
p( (cid:2)w)
log
M
(cid:2)w
(cid:2)v= (cid:2)wM
p((cid:2)v|M )
p( (cid:2)w)
We can split Equation (4) into two parts, using the fact
b ) = log(a) − log(b). Let H(W|V, M t) = J + K,
that log( a
we have
(cid:3)
(cid:3)
M
(cid:3)
(cid:3)
(cid:2)w
(cid:3)
(cid:3)
(cid:2)v= (cid:2)wM
J =
p(M )
p( (cid:2)w)
K =
p(M )
p( (cid:2)w)
M
(cid:2)w
(cid:2)v= (cid:2)wM
log p((cid:2)v|M )
− log p( (cid:2)w)
(5)
(6)
Because there is only one (cid:2)v such that (cid:2)v = (cid:2)wM, we can write
K as
(cid:3)
p(M ) ·
(cid:3)
M
(cid:3)
(cid:2)w
K =
= −
p( (cid:2)w) log p( (cid:2)w)
p( (cid:2)w)(− log p( (cid:2)w))
(7)
(cid:2)w
= H(W ).
So we have H(W|V, M t) = H(W ) + J. The quantity L =
−J represents the amount of leaked information, that is the
amount of information that the adversary, a, can learn about
p’s compact proﬁle. Equation (5) provides a ﬁrst expression
for this amount of information. In the following, we reﬁne
this expression and present a way to compute an upper bound
for it.
p((cid:2)v, M )
p( (cid:2)w)p(M )
p((cid:2)v|M )
p( (cid:2)w)
.
(4)
B. Leaked Information and the Landmark Matrix
We now identify a relationship between the amount of
leaked information and the number of non-zero rows in the
landmark matrix, M. We start by taking a closer look at the
term p((cid:2)v|M ) from Equation (5). We expand it as follows.
(cid:3)
(cid:3)
(cid:3)
(cid:3)
(cid:2)w s.t. p((cid:2)v, (cid:2)w|M )(cid:3)=0
(cid:2)w s.t. p((cid:2)v, (cid:2)w|M )(cid:3)=0
(cid:2)w s.t. p((cid:2)v, (cid:2)w|M )(cid:3)=0
p( (cid:2)w).
p((cid:2)v|M ) =
=
=
=
p((cid:2)v, (cid:2)w|M )
p((cid:2)v| (cid:2)w, M )p( (cid:2)w)
(8)
p( (cid:2)w)
(cid:2)w s.t. (cid:2)v= (cid:2)wM
(3)
The ﬁrst line follows from the law of total probability while
the third and fourth result from the same observations on
p((cid:2)v| (cid:2)w, M ) as in Equation (3).
n
√
√
1, . . . ,
To solve the ﬁnal sum in Equation (8), we deﬁne
2} as the set of all compact
S((cid:2)v, M ) = {(cid:2)c|(cid:2)v = (cid:2)c||(cid:2)c|| M, (cid:2)c ∈ Z
proﬁles that have the same adjusted similarity vectors given
a set of landmarks. To evaluate the cardinality of S((cid:2)v, M ),
we observe that ∀(cid:2)c ∈ S((cid:2)v, M ),
||(cid:2)c|| belongs to one of
n. The worst case w.r.t. information
the values 0,
√
leakage occurs when all vectors in S((cid:2)v, M ) have the same
Obviously, (cid:2)v × √
norm
wt, wt being the hamming weight of one such vector.
(cid:2)v × √
wt produces an integer vector. Moreover,
wt must be a sum of some of the non-zero rows of
M, or in other words, a linear combination of the non-zero
rows of M. Then an even worse case occurs when not only
all vectors have one same norm, but also only one such linear
combination exists: in this case, S((cid:2)v, M ) is smallest.
Let k((cid:2)v, M ) be the number of 1’s in the coefﬁcients of such
a unique linear combination, and let j((cid:2)v, M ) = wt− k((cid:2)v, M )
be the number of remaining 1’s, those that correspond to zero
(cid:5)
rows of M. We can then compute the size of S((cid:2)v, M ) as
n−D(M )
where D(M ) is the number of non-zero rows of
j((cid:2)v,M )
M. In the general case, we will therefore have the following
lower bound on |S((cid:2)v, M )|.
(cid:6)
|S((cid:2)v, M )| ≥
(cid:8)
(cid:7)
n − D(M )
j( (cid:2)w, M )
(9)
where with a slight abuse of notation we write j( (cid:2)w, M ) to
mean j( (cid:2)wM, M ). Then, because we assume that all compact
proﬁles are equally likely (p( (cid:2)w) = 1
2n ), we can simplify
Equation (8) into Inequality (10).
(cid:7)
(cid:8)
p((cid:2)v|M ) = p( (cid:2)w)|S((cid:2)v, M )| ≥ 1
2n
n − D(M )
j( (cid:2)w, M )
(10)
This allows us to compute an upper bound on the amount of
leaked information.
271271
(cid:2)w
M
M
≤
p(M )
(cid:3)
p(M )(n − 1
2n
(cid:7)
1
(cid:7)
2n
(cid:7)
1
2n log
(cid:3)
(cid:3)
(cid:3)
L ≤ −
(cid:3)
(cid:8)
n − D(M )
(cid:8)
j( (cid:2)w, M )
n − D(M )
(cid:8)
j( (cid:2)w, M )
n − D(M )
j( (cid:2)w, M )
(cid:5)
(cid:6)
). S(D(M ))
sums over all possible (cid:2)w and thus depends only on M. Since
0 ≤ k( (cid:2)w, M ) ≤ D(M ), S(D(M )) is lowerbounded by
T (D(M )):
Let us deﬁne S(D(M )) =
= n − 1
2n
n−D(M )
j( (cid:2)w,M )
(cid:3)
(cid:2)
p(M )
(cid:2)w log
(11)
log
log
)
)
(cid:2)w
(cid:2)w
M
n−1(cid:3)
T (D(M )) =
wt=D(M )+1
(cid:7)
(cid:8)
(cid:7)
n
wt
n − D(M )
wt − D(M )
(cid:8)
(cid:7)
(cid:8)
n − D(M )
,
wt
log(min(
))
(12)
To further simplify L, let d ∈ [0, nm] be the number of
1’s in the matrix M, and let N (d, D(M )) be the number of
M matrices with d 1’s spread across D(M ) non-zero rows.
Finally, let p(Md) be the probability of a matrix with d 1’s.
Then Inequality (13) decomposes the summation in the last
line of Inequality (11) as follows. The outer sum considers all
the matrices with i non-zero rows. The inner sum considers
all the matrices with d 1’s (at least i and no more than i m,
m being the number of columns).
i m(cid:3)
(cid:3)
M
p(M )T (D(M )) ≥ n(cid:3)
n(cid:3)
n(cid:3)
i=1
i=1
=
d=i
N (d, i)p(Md)T (i)
i m(cid:3)
T (i)
N (d, i)p(Md)
d=i
T (i)p(D(M ) = i)
i=1