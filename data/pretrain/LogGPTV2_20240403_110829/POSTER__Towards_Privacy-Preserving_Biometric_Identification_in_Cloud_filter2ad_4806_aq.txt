order to protect user privacy. To expand the recognition level, their technique
involves vector machine models and a Hamming Distance approach. Finally,
ﬁlters are used for feature extraction to improve the authentication performance.
The work of Dehkordi and Abu-Bakar in [61] introduced a Hamming Distance
technique applied on subsets with an adaptive length. Their results provide a
signiﬁcant increase in accuracy of iris matching.
Thresholds and Performance Rates
The conﬁdence in the functionality of a biometric scheme is determined by
speciﬁc measures that are used to evaluate the accuracy and eﬀectiveness [182].
118
SECURE AND PRIVACY-FRIENDLY MULTIMODAL BIOMETRIC AUTHENTICATION USING
CLOUD-BASED IDENTITY PROVIDERS
Thresholds are deﬁned to decide if a user does or does not correspond to a
claimed identity. In multimodal recognition schemes there are two categories
of metrics, named Reference Thresholds ϑi for the unimodal recognition of the
modality i and Decision Thresholds τ for the multimodal scheme respectively.
During the comparison in the matching process based on Hamming Distance
algorithms, the generated matching score si, after the comparison of the new
and stored templates, can be analyzed on the basis of a predeﬁned threshold ϑi.
In biometric designs, the decision result is represented as 0 which means that
the template is not matching and the authentication is rejected; and 1 that
corresponds to an acceptable match for the user recognition. For recognition
systems that follow a matching algorithm that is based on the calculation of
distances between the new and the stored templates, the decision result is
represented as:
si ≤ ϑi Accept
si > ϑi Reject .
(1)
Similarly, for multimodal recognition approaches that perform matching using
algorithms that compute the dissimilarity of the templates, the fused score sf ,
given the system’s τ is compared as follows:
sf ≤ τ Accept
sf > τ Reject .
(2)
Based on Hamming Distance algorithms, the comparison between the new and
stored templates and consequently the si and ϑi reﬂect a genuine/authentic
person, or an impostor/intruder score if there is an inadmissible distance.
However, biometric data are inherently noisy and thus unimodal and multimodal
biometric recognition suﬀer from error rates [122]. Hence, schemes hardly ever
encounters a user’s fresh biometric trait and a stored template that result in a
100% match. According to the analysis of Malik et al. in [130], the statistical
calculation of ϑi is related to the biometric system’s performance rates. The
most important rates that are used to evaluate the performance of a biometric
recognition scheme are the False Acceptance Rate (FAR) and the False Rejection
Rate (FRR). For each unimodal biometric feature i given a ϑi, for a matching
score si, the p(si | genuine) represents the probability of distance values for
a given matching score si, between the new and stored templates, under the
genuine conditions. Correspondingly p(si | impostor) indicates the probability
for the impostor conditions. Figure 2 illustrates the distribution of matching
scores and its relation to FAR and FRR [182].
PRELIMINARIES
119
Figure 2: The genuine and impostor distributions.
In the literature, for impostor and genuine users, the performance rates are
usually represented as integrals [182]. In practice for our protocol, working on
Hamming Distance algorithms and binary templates, for an impostor who is not
enrolled in the unimodal scheme based on the modality i, for a threshold ϑi and
a given length L of the experimental unimodal templates, the matching score
si = 0 means that two templates match perfectly, while a matching score si = L
reﬂects the condition where the templates present an inadmissible distance. In
this way, the FARi is calculated as follows:
si=ϑiX
FARi(ϑi) =
p(si | impostor) .
Accordingly, the FRRi is given by:
FRRi(ϑi) =
si=0
si=LX
p(si | genuine) .
The accuracy of the unimodal biometric scheme is given by:
si=ϑi+1
Accuracy
i
(%) = 100 − FARi(%) + FRRi(%)
2
.
(3)
(4)
(5)
Training Datasets
The distributions of Figure 2 and Equation (5) illustrate the eﬀect of ϑ on
FAR and FRR on the biometric scheme’s accuracy. For unimodal designs, the
120
SECURE AND PRIVACY-FRIENDLY MULTIMODAL BIOMETRIC AUTHENTICATION USING
CLOUD-BASED IDENTITY PROVIDERS
performance of tests on the biometric data is an essential technique in order to
achieve an acceptable value of FAR, or select an optimum FRR for the purposes
of the recognition schemes [203]. This can be achieved by training the applicable
algorithms for examining how the system behaves under diﬀerent values of ϑ.
Tuning the system’s threshold is a technique to study the performance accuracy
under a given procedure; this process always eﬀects not only on the decision
module represented in (1), but also the corresponding rates of the system,
as underlined in [130, 182]. In real-world deployments, training is not always
adequate, as a result of the time, eﬀort, cost and the privacy regulations for the
collection of biometric information [116,122].
The technique plays an important role in fusion methods that integrate the
results of multiple biometrics to obtain a ﬁnal multimodal score [182]. In
multimodal designs, each contributing biometric modality i provides a user-
speciﬁc FARi and FRRi, given a ϑi. It is noted that these rates cannot be
reduced simultaneously by adjusting the ϑi. For instance, working with Hamming
Distance matching algorithms, a lower threshold decreases the FAR and it
is used for enhancing security, while a higher threshold increases the user’s
convenience [182]. In that way, systems with high requirements in terms of
robustness and security may set a user-speciﬁc FAR approach to determine
the ﬁnal fused result. On the contrary, a higher FRR is considered to be more
convenient in order to increase the number of matching results, expanding the
recognition range for identiﬁcation applications such as government services
that perform investigations for missing persons. However, in practice it is
necessary to select an optimal solution in order to avoid an extensive number
of false acceptances and to reduce the need for human intervention. Section 3.1
analytically presents how these rates can be used in fusion strategies to increase
the accuracy. We emphasize that the purpose of our system is to avoid a re-
enrollment procedure. The user is already enrolled in the remote UAs of the
cloud and thus the ϑi, FARi and FRRi are parameters that these parties in the
cloud hold and tune. It is assumed that the training procedures on the unimodal
datasets are carried out by third parties and any related speciﬁc computations
are outside the scope of this work.
Score Level Fusion
The works in [180,182] have shown that unimodal biometric designs suﬀer from
several issues, for instance noise and spooﬁng attacks. Multibiometrics can
solve these limitations and surpass even multi-factor authentication schemes by
extending the feature space to increase security and identiﬁcation reliability [99].
However, the concept of multimodal integration and the selection of a convenient
fusion model is still a challenging task [143]. In a multimodal recognition system,
PRELIMINARIES
121
biometric fusion represents an active area with numerous approaches; it can be
accomplished at several levels and by several strategies using the biometric data
prior to matching, at the decision or after the matching stages. Furthermore,
multimodal deployments are governed by the type of biometric data and sources,
the acquisition, the processing stages and the ﬁnal application.
Given the purposes of our multimodal AaaS system, user authentication takes
place in a distributed environment where the matching scores of the distinct
subsystems of the UAs are combined to determine a ﬁnal score. In this work, we
use the term fusion to describe the consolidation of matched unimodal templates
in a single score that is called multimodal result, as described in “Handbook
of Multibiometrics” [182]. For the functionality of our proposed system, the
selection of biometric consolidation at the decision level was discarded because
of the inconvenience that current fusion methods may cause in practical
architectures. Techniques such as Daugman rules, conditions in majority voting,
Bayesian decision, Dempster-Shafer theory and behavior knowledge space,
present high values of FAR and FRR, resulting a lower accuracy; even if they
have been used in some commercial multimodal biometric systems, they are
considered ineﬃcient for high security applications, according to the results
presented in [182,203]. Thus, a fusion technique after the matching process is
the preferred option, following the study in [206].
Match score level fusion, also known as fusion at measurement or conﬁdence
level is a widely used fusion approach in current biometric architectures due
to its reliability. Jain et al. in [101] showed that this technique provides an
improved performance in comparison to other methods, while it allows an easy
integration of modalities extracted by diverse sensors. Recently, Tiwari and
Gupta in [206] introduced a score level fusion scheme and tested it on several
biometric datasets. Their experimental evaluation shows a strong authentication
accuracy with low error rates in comparison to the performance of the unimodal
subsystems.
User-Speciﬁc Weighted Score Fusion Predicting the performance of a
multimodal scheme following a particular score level fusion method is almost
impossible. Ross et al. in [182] noted that the performance can only be evaluated
based on empirical results. However, as presented in Section 3.1, every user
exhibits diﬀerent performance rates in biometric schemes, and thus it is possible
to further enhance the accuracy of a multimodal design by using user-speciﬁc
score fusion techniques. According to the ﬁndings in [181], in a fusion model
performance rates can be applied in such a way that they can assign diﬀerent
degrees (weights) of importance to the various modalities on a user-by-user
basis. This means that a set of diﬀerent weights, representing the user’s FAR
122
SECURE AND PRIVACY-FRIENDLY MULTIMODAL BIOMETRIC AUTHENTICATION USING
CLOUD-BASED IDENTITY PROVIDERS
function (3), FRR function (4) or even the overall accuracy, given by Equation
(5) of the unimodal recognition subsystems, were applied to determine the fusion
result. Recent experimental studies such as the works presented in [4,192,219]
have exploited it in order to test it or even suggest complementary measures for
fusion methodologies, presenting important improvements in the performance
of multimodal deployments from uncorrelated unimodal biometrics.
In this work, we utilize a user-speciﬁc weighted score level fusion method to
incorporate the unimodal scores of the cloud-based UAs to achieve a ﬁnal fused
multimodal result for authentication purposes. In real-world deployments, the
matching scores obtained from the biometric matchers are non-homogenous
measures with diﬀerent scales, where {−1, +1} is typically used for faces, a unit
interval {0, 1} for irises, and {0, 100} is the range for ﬁngerprints. Therefore,
a normalization technique is usually followed prior to the fusion phase [101].
However, as presented in [182], setting a sum rule in a user-speciﬁc weighted
fusion to determine the ﬁnal fused result, the normalization process can be
omitted due to the linear weighting coeﬃcients. In a system with M modalities,
where modality i has weight wi, and the unimodal matching score is equal to
si, the ﬁnal fused score is computed as follows:
MX
sf =
wisi .
(6)
i=1
According to the ﬁndings in [4,85] the sum rule in a user-speciﬁc weighted fusion
improves the performance of the scheme. Figure 3 summarizes our experimental
analysis on their ﬁndings based on face and ﬁngerprint biometrics of NIST [152],
and iris datasets found in CASIA [43] public available research DBs. The
Receiver Operating Characteristic (ROC) curve of fusion, following Equation
(6), combines the three unimodal biometrics and presents the quality of the
recognition performance. Moreover, the authors in [182] discussed the eﬀects of
the equal and user-speciﬁc weights on the overall accuracy of the fusion model.
Based on the study of Verma and Singh in [219] and the experiments of Manasa
et al. in [132], Figure 4 illustrates our analysis on the improvement of the
performance on a multimodal scheme of ﬁngerprint on NIST [152], palmprint
and iris on CASIA [43] datasets respectively. When user-speciﬁc diﬀerent weights
are applied according to the FAR of each user, a signiﬁcantly better ROC curve
is obtained than when equal weights are used for the three biometric traits.
From the ﬁgures and the analysis of Tao and Veldhuis in [203], we can assess
the importance of the ﬁnal Decision Thresholds and the training datasets
for the overall performance and robustness of a weighted score level fusion
model. It is noted that the biometric matching algorithms and the size of the
PRELIMINARIES
123
Figure 3: Comparison of unimodals and weighted sum rule fusion.
Figure 4: Comparison of recognition performance for weighted scores.
datasets in the DBs have great impact on the outcome of an evaluation [24]. A
user-speciﬁc weighted fusion with a sum rule is considered to be a beneﬁcial
approach in multimodal designs where unimodal information is provided by
diﬀerent subsystems and the performance varies across the population. Finally,
in our scenario for a multimodal AaaS system, we choose to follow this fusion
technique to incorporate face, ﬁngerprint and iris for user recognition. However,
it is underlined that speciﬁc calculations on thresholds and performance rates
for the selection of user-speciﬁc weights are outside the scope of this paper.
124
SECURE AND PRIVACY-FRIENDLY MULTIMODAL BIOMETRIC AUTHENTICATION USING
CLOUD-BASED IDENTITY PROVIDERS
3.2 Achievable Security with MPC
To handle the privacy concerns, which may limit the design and implementation
of our system for multimodal authentication in the cloud, we use secure
Multi-Party Computation (MPC). This collection of techniques allows any
set of parties to compute a publicly available function without requiring the
parties to reveal their private inputs. Additionally, depending on the model, the
security oﬀered can vary from computational to information theoretic or perfect
security [17]. The ﬁeld was at ﬁrst regarded as purely theoretical, but recently
interest has grown by the emergence of practical Virtual Ideal Functionality
Framework (VIFF) as a tool that implements functionalities for general MPC
on asynchronous networks [71]. The commercial implementations, such as the
Sharemind framework [28], have also led to an increased research attention for
improvements. Recently, protocols such as SPDZ [56,58] and BDOZ [18] have
been added to the mix, providing robust security properties, such as passive
and active security in the presence of dishonest majorities. In our work, MPC
is used to build a protocol that can ensure the secrecy of biometric templates
and protect private information during the authentication stages.
Security under MPC addresses the conﬁdentiality of the private inputs with
respect to the parties involved in any computation stage of the protocol. MPC
is used for security reasons against typical privacy adversarial models, such as
honest but curious and malicious adversaries, oﬀering various security levels,
from statistical to perfect security [17,58]. We deﬁne security under MPC as
follows:
(Security): Consider I = P1, ..., Pn the parties that want to
Deﬁnition 1.
compute a function y = f(x1, ..., xn), where xi is the secret input of Pi. Then,
any protocol π that computes y is secure if the parties do not learn anything but
the output y and what can be inferred from y.
This deﬁnition implies that no party Pi should learn any information from
∀j ∈ I, where i 6= j, except what can be inferred
the private inputs of Pj,
from the output. Note that in our authentication system, the SP knows the
credentials of the user. Finally, access patterns towards the protocol could also
be statistically hidden, as explained in the following sections. To ease security
analysis and the protocol description, we use the following arithmetic black-box
as an abstraction that idealizes access to a certain secure functionality.
Arithmetic Black-Box
We use and extend the arithmetic black-box in [57] based on a composable
eﬃcient MPC from threshold homomorphic encryption. The original arithmetic
PRELIMINARIES
125
black box was built under the composability hybrid model presented by Canetti
in [41] and proved secure against passive and active adversaries. This makes
simulation proofs straightforward, where the simulated view of any Pi is the
same as the adversary’s view, reducing the complexity of our security analysis.
The black box in [57] could be seen as a virtualized entity capable to store ﬁeld
elements over Fp, where p is any suﬃciently large prime number or RSA modulus.
It also provides secure addition and multiplication with a scalar and between
secretly stored values. The basic functionality of our arithmetic black-box FABB
can be achieved by well-known protocols for homomorphic encryption, such as
the cryptosystem in [159], or linear secret sharing schemes [190]. The addition