a total of 700-800 lag measurements from each of the six VMs
for a particular meeting host. We repeat this experiment on
Zoom, Webex and Meet. In the second set of experiments we
use seven VMs deployed in Europe, as shown in Table 3, and
redo the above experiments with meeting hosts in UK-west
and Switzerland.
We observe that the multi-user sessions created in this
experiment are all relayed via platform-operated service end-
points with a designated fixed port number (UDP/8801 for
Zoom, UDP/9000 for Webex, and UDP/19305 for Meet).2 Fig. 3
compares the three videoconferencing systems in terms of
how their clients interact with the service endpoints for con-
tent streaming, which we discover from their traffic traces.
On Zoom and Webex, a single service endpoint is designated
for each meeting session, and all meeting participants send
or receive streaming data via this endpoint. On Meet, each
2One exceptional case we observe is that, on Zoom, if there are only
two users in a session, peer-to-peer streaming is activated, where they
stream to each other directly on an ephemeral port without going
through an intermediary service endpoint.
220
client connects to a separate (geographically close-by) end-
point, and meeting sessions are relayed among these multiple
distinct endpoints.
The number of distinct service endpoints encountered by a
client varies greatly across different platforms. For example,
out of 20 videoconferencing sessions, a client on Zoom, Webex
and Meet encounters, on average, 20, 19.5 and 1.8 endpoints,
respectively. On Zoom and Webex, service endpoints almost
always change (with different IP addresses) across different
sessions, while, on Meet, a client tends to stick with one or
two endpoints across sessions.
Figs. 4‚Äì7 plot the CDFs of streaming lag experienced
by clients in four different scenarios. In Figs. 4 and 5, we
consider videoconferencing sessions among seven US-based
clients (including a meeting host), where the host is located
in either US-east or US-west. In Figs. 6 and 7, similarly we set
up videoconferencing sessions among seven clients in Europe,
with a meeting host in either UK or Switzerland. We make
the following observations from the results.
4.2.1 US-based Videoconferencing. When sessions are cre-
ated from US-east (Fig. 4), across all three platforms, stream-
ing lag experienced by clients increases as they are further
away from US-east, with the US-west clients experiencing the
most lags (about 30 ms higher than the US-east client). This
implies that streaming is relayed via the servers in US-east,
where the meeting host resides. This is in fact confirmed by
Fig. 8, where we plot RTTs between clients and service end-
points they are connected to. In the figure, RTTs measured
by different clients are indicated with distinct dots. Each
dot represents an average RTT (over 100 measurements) in
a particular session. On Zoom and Webex, RTTs measured
by US-east users are much lower than those by US-west
users. On Meet, RTTs are uniform across clients due to its
distributed service endpoint architecture as shown in Fig. 3.
When a meeting host is in US-west (Fig. 5), geographic
locality plays a similar role with Zoom and Meet, where
the most far-away clients in US-east experience the worst
lags. In case of Webex, however, the worst streaming lag is
actually experienced by another user in US-west. According
to the RTTs collected in this scenario for Webex (Fig. 9b),
its service endpoints seem to be provisioned on the east-side
of the US even when sessions are created in US-west, causing
the streaming between US-west users to be detoured via US-
east. Due to the geographically-skewed infrastructure, the lag
distributions for US-west-based sessions are simply shifted by
30 ms from the US-east-based counterparts (Figs. 4b and 5b).
One unexpected observation is that Meet sessions exhibit the
worst lag despite having the lowest RTTs. This might be due
to the fact that Meet sessions are relayed via multiple service
endpoints, unlike Zoom and Webex (Fig. 3). In addition,
although Meet‚Äôs videoconferencing infrastructure appears
to be distributed over wider locations (with lower RTTs),
the total aggregate server capacity at each location may be
smaller, hence leading to more load variation.
User1User2User1User2User3Zoom & WebexGoogle MeetServiceEndpointsUser3IMC ‚Äô21, November 2‚Äì4, 2021, Virtual Event, USA
Hyunseok Chang, Matteo Varvello, Fang Hao, and Sarit Mukherjee
(a) Zoom
(b) Webex
(c) Meet
Figure 4: CDF of streaming lag: meeting host in US-east.
(a) Zoom
(b) Webex
(c) Meet
Figure 5: CDF of streaming lag: meeting host in US-west.
(a) Zoom
(b) Webex
(c) Meet
Figure 6: CDF of streaming lag: meeting host in UK-west.
(a) Zoom
(b) Webex
(c) Meet
Figure 7: CDF of streaming lag: meeting host in Switzerland.
4.2.2 Non-US-based videoconferencing. According to Figs. 6‚Äì
7, when sessions are set up among clients in Europe, Zoom/Webex
clients experience much higher lags than Meet users. When
compared to the Zoom/Webex sessions created in US-east,
clients in Europe experience 55‚Äì75 ms and 45‚Äì65 ms higher
median lags on Zoom and Webex, respectively. The reported
RTTs (Figs. 10 and 11) show that the clients closer to the
east-coast of US (e.g., UK and Ireland) have lower RTTs than
those located further into central Europe (e.g., Germany and
Switzerland). These observations suggest that the service
infrastructures used are located somewhere in US.3
3We are not able to pinpoint the locations of the infrastructures
because traceroute/tcptraceroute-probings are all blocked.
Comparing Zoom and Webex, one can see that RTTs to
service endpoints on Zoom vary much more widely across
different sessions. In fact, as shown in Figs. 10a and 11a,
RTTs tend to spread across three distinct ranges that are
20 ms and 40 ms apart, which causes step-wise lag distribu-
tions in Figs. 6a and 7a. This suggests that Zoom may be
employing regional load balancing within the US when serv-
ing non-US sessions. Whereas in Webex, RTTs to service
endpoints consistently remain close to the trans-Atlantic
RTTs [15], indicating that non-US sessions are relayed via
its infrastructure in US-east. In case of Meet, its distributed
service endpoints allow clients in Europe to enjoy stream lags
that are comparable to US-based counterparts without any
artificial detour. The reason why its streaming lag is lower
221
 0 0.2 0.4 0.6 0.8 1 0 20 40 60 80 100 120 140 160CDFVideo Lag (msec)US-CentralUS-NCentralUS-SCentralUS-East2US-WestUS-West2 0 0.2 0.4 0.6 0.8 1 0 20 40 60 80 100 120 140 160CDFVideo Lag (msec)US-CentralUS-NCentralUS-SCentralUS-East2US-WestUS-West2 0 0.2 0.4 0.6 0.8 1 0 20 40 60 80 100 120 140 160CDFVideo Lag (msec)US-CentralUS-NCentralUS-SCentralUS-East2US-WestUS-West2 0 0.2 0.4 0.6 0.8 1 0 20 40 60 80 100 120 140 160CDFVideo Lag (msec)US-CentralUS-NCentralUS-SCentralUS-EastUS-East2US-West2 0 0.2 0.4 0.6 0.8 1 0 20 40 60 80 100 120 140 160CDFVideo Lag (msec)US-CentralUS-NCentralUS-SCentralUS-EastUS-East2US-West2 0 0.2 0.4 0.6 0.8 1 0 20 40 60 80 100 120 140 160CDFVideo Lag (msec)US-CentralUS-NCentralUS-SCentralUS-EastUS-East2US-West2 0 0.2 0.4 0.6 0.8 1 0 50 100 150 200CDFVideo Lag (msec)DEIENLFRUK-SouthCH 0 0.2 0.4 0.6 0.8 1 0 50 100 150 200CDFVideo Lag (msec)DEIENLFRUK-SouthCH 0 0.2 0.4 0.6 0.8 1 0 50 100 150 200CDFVideo Lag (msec)DEIENLFRUK-SouthCH 0 0.2 0.4 0.6 0.8 1 0 50 100 150 200CDFVideo Lag (msec)DEIENLFRUK-SouthUK-West 0 0.2 0.4 0.6 0.8 1 0 50 100 150 200CDFVideo Lag (msec)DEIENLFRUK-SouthUK-West 0 0.2 0.4 0.6 0.8 1 0 50 100 150 200CDFVideo Lag (msec)DEIENLFRUK-SouthUK-WestCan You See Me Now? A Measurement Study of Zoom, Webex, and Meet
IMC ‚Äô21, November 2‚Äì4, 2021, Virtual Event, USA
(a) Zoom
(b) Webex
(c) Meet
Figure 8: Service proximity: meeting host in US-east.
(a) Zoom
(b) Webex
(c) Meet
Figure 9: Service proximity: meeting host in US-west.
(a) Zoom
(b) Webex
(c) Meet
Figure 10: Service proximity: meeting host in UK-west.
(a) Zoom
(b) Webex
(c) Meet
Figure 11: Service proximity: meeting host in Switzerland.
in Europe than in the US may be because the end-to-end
latency among the clients (connected via service endpoints)
in Europe may be smaller than that in the US. Average RTT
within Europe is indeed smaller than that in the US [15].
4.3 User-Perceived Video Quality
Next we shift our focus to user-perceived quality of video-
conferencing. A videoconferencing client typically captures
a single person view against a stationary background, but
it is also possible to have high-motion features in streamed
content if a participant is joining a session from a mobile
device, sharing a video playback with dynamic scenes, or
showing a media-rich presentation, etc. In general, however,
little is known about how different videoconferencing systems
measure up to one another in terms of user-perceived quality
under different conditions.
For this evaluation we prepare two distinct video feeds
with 640√ó480 resolution: (i) a low-motion feed capturing
the upper body of a single person talking with occasional
hand gestures in an indoor environment, and (ii) a high-
motion tour guide feed with dynamically moving objects
and scene changes. On each videoconferencing system, we
use a designated meeting host VM to create 10 five-minute
long sessions, and inject the low-/high-motion videos into
the sessions in an alternating fashion (hence two sets of five
sessions). In each session, we let ùëÅ clients join the session and
render the received video feed in full screen mode while their
desktop screen is recorded locally. For desktop recording, we
use PulseAudio as audio backend, and set the video/audio
codec to H.264 (30 fps) and AAC (128 Kbps), respectively. We
repeat the whole experiment as we vary ùëÅ from one to five.4
4A typical number of users in a videoconferencing session is less than
five [22].
222
 0 20 40 60 80 100        RTT (msec)US-CUS-EUS-E2US-NCUS-SCUS-WUS-W2 0 20 40 60 80 100        RTT (msec)US-CUS-EUS-E2US-NCUS-SCUS-WUS-W2 0 20 40 60 80 100        RTT (msec)US-CUS-EUS-E2US-NCUS-SCUS-WUS-W2 0 20 40 60 80 100        RTT (msec)US-CUS-EUS-E2US-NCUS-SCUS-WUS-W2 0 20 40 60 80 100        RTT (msec)US-CUS-EUS-E2US-NCUS-SCUS-WUS-W2 0 20 40 60 80 100        RTT (msec)US-CUS-EUS-E2US-NCUS-SCUS-WUS-W2 0 50 100 150 200        RTT (msec)CHDEIENLFRUK-SUK-W 0 50 100 150 200        RTT (msec)CHDEIENLFRUK-SUK-W 0 20 40 60 80 100        RTT (msec)CHDEIENLFRUK-SUK-W 0 50 100 150 200        RTT (msec)CHDEIENLFRUK-SUK-W 0 50 100 150 200        RTT (msec)CHDEIENLFRUK-SUK-W 0 20 40 60 80 100        RTT (msec)CHDEIENLFRUK-SUK-WIMC ‚Äô21, November 2‚Äì4, 2021, Virtual Event, USA
Hyunseok Chang, Matteo Varvello, Fang Hao, and Sarit Mukherjee
(a) Low motion: PSNR
(b) Low motion: SSIM
(c) Low motion: VIFp
(d) High motion: PSNR
(e) High motion: SSIM
(f) High motion: VIFp
Figure 12: Video QoE metrics comparison (US).
4.3.1 US-based Videoconferencing. We use one cloud VM in
US-east designated as a meeting host which broadcasts a
stream, and up to five other VMs in US-west and US-east
receiving the stream as passive participants. Fig. 12 compares
the quality of video streaming for these VMs in terms of
three QoE metrics (PSNR, SSIM & VIFp) as the number of
users in a session (N) increases. The height of bars indicates
average QoE values across all sessions, with the errorbars
being standard deviations. For easy comparison between low-
motion and high-motion feeds, Fig. 14 shows the amount
of QoE reduction with high-motion feeds (compared to low-
motion feeds). Figs. 15a and 15b show the corresponding
data rates for these sessions.
We make the following observations from the figures. Com-
paring Figs. 12a‚Äì12c against Figs. 12d‚Äì12f, one can find that,
across all three platforms, low-motion sessions experience less
quality degradation than high-motion sessions because their
video feeds contain largely static background. The amount
of decrease in QoE values between low-motion/high-motion
sessions (Fig. 14) is significant enough to downgrade mean
opinion score (MOS) ratings by one level [30]. On Webex,
QoE degradation in high-motion scenario tends to become
more severe with more users. Whereas no such consistent
pattern is observed in Zoom and Meet. The QoE results
from low-motion sessions (Figs. 12a‚Äì12c) show that there is
a non-negligible QoE drop between ùëÅ=2 and ùëÅ>2 on Meet.
We find that, on Meet, the data rate for two-user sessions
(1.6‚Äì2.0 Mbps) is significantly higher than other multi-user
sessions (0.4‚Äì0.6 Mbps) (Fig. 15). Such higher traffic rate
with ùëÅ=2 helps with the QoE of low-motion sessions, but
does not contribute much to the QoE of high-motion sessions.
Among the three, Webex exhibits the most stable QoE across
Figure 13: Video screen with padding.
We compare the originally injected videos and recorded
videos in terms of their quality with VQMT [6]. The VQMT
tool computes a range of well-known objective QoE metrics,
including PSNR (Peak Signal-to-Noise Ratio), SSIM (Struc-
tural Similarity Index Measure) [39] and VIFp (Pixel Visual
Information Fidelity) [35]. Each of these metrics produces
frame-by-frame similarity between injected/recorded videos.
We take an average over all frames as a QoE value. One issue
that complicates accurate quality comparison is the fact that
the video screen rendered by a client is partially blocked
by client-specific UI widgets (e.g., buttons, user thumbnails,
etc.), even in full screen mode. To avoid such partial occlu-
sion inside the video viewing area, we prepare video feeds
with enough padding (Fig. 13). When recorded videos are
obtained, we perform the following post-processing on them
before analysis. We first crop out the surrounding padding
and resize video frames to match the content layout and
resolution of the injected videos. On top of that, we syn-
chronize the start/end time of original/recorded videos with
millisecond-level precision by trimming them in a way that
per-frame SSIM similarity is maximized.
223
 0 10 20 3023456PSNRNumber of Users in a SessionZoomWebexMeet 0 0.2 0.4 0.6 0.8 123456SSIMNumber of Users in a SessionZoomWebexMeet 0 0.2 0.4 0.6 0.823456VIFpNumber of Users in a SessionZoomWebexMeet 0 10 20 3023456PSNRNumber of Users in a SessionZoomWebexMeet 0 0.2 0.4 0.6 0.8 123456SSIMNumber of Users in a SessionZoomWebexMeet 0 0.2 0.4 0.6 0.823456VIFpNumber of Users in a SessionZoomWebexMeetCan You See Me Now? A Measurement Study of Zoom, Webex, and Meet
IMC ‚Äô21, November 2‚Äì4, 2021, Virtual Event, USA
(a) PSNR
(b) SSIM
(c) VIFp
Figure 14: Video QoE reduction when video feeds are changed from low-motion to high-motion (US).
(a) US: low-motion
(b) US: high-motion
Figure 15: Upload/download data rates (US). The data rate is computed from Layer-7 payload length in pcap traces. ‚ÄúX-Upload‚Äù
shows the average upload rate of a meeting host (using Zoom, Webex, or Meet) who is broadcasting a video feed, while ‚ÄúX-
Download‚Äù indicates the average download rate of the clients who are receiving the feed. All uploads/downloads occur via
cloud-based relay, except for Zoom with ùëÅ=2 which uses peer-to-peer traffic.
(a) High motion: PSNR