IAD: Indirect Anomalous VMMs Detection in the Cloud-based Environment 7
3.2 Test Module
This component is responsible for generating the synthetic data and evaluating
the algorithm performance by calculating the F1-score on the results from the
algorithm. It consists of multiple sub-component described below:
– Synthetic Data Generator: It takes the number of VMMs, number of
VMs per VMM, percentage of the VMs with a fault; as the input for gen-
erating synthetic timeseries data. This synthetic data follows a Gaussian
distribution based on the input parameters. This component also automat-
ically divides the generated data into true positive and true negative labels
based on the percentage of the VMs with a fault parameter.
– Algorithm Tester:Itisresponsibleforinvokingthealgorithmwithvarious
parametersonthesyntheticdataandtunethealgorithm’shyperparameters.
– Evaluation: The results from the algorithm are passed as the input to this
sub-component, where the results are compared with the actual labels, and
the overall algorithm score in terms of F1-score is reported.
4 Experimental Settings
We design our experiments to answer the following questions:
Q1. Indirect Anomaly Detection Accuracy:howaccurateisIADinthe
detection of anomalous VMM when compared to other popular algorithms?
Q2. Anomalous VMMs finding efficiency and scalability: How does
the algorithm scale with the increase in the data points and number of VMs?
4.1 Datasets
For evaluating the IAD algorithm, we considered four types of datasets listed in
Table 2 along with their information and are described below:
Synthetic: This is the artificially generated dataset using the Test Module
component described in §3.
Experimental-SyntheticMerged:Thisisadatasetwithacombinationof
experimental data and synthetic data. We created two nested virtual machines
on a VM in the Google Cloud Platform to collect the experimental dataset.
The underneath VM instance type is n1-standard-4 with four vCPUs and 15
GB of memory, and Ubuntu 18.04 OS was installed on it. This VM instance
acts as a host for the above VMs. libvirt toolkit is used to manage and create
nested virtualization on top of the host machine. Kernel-based Virtual Machine
(KVM)isusedasaVMM.TheconfigurationofthetwonestedVMsarei)2vCPU
and 2GB memory, ii) 1vCPU and 1GB memory. Cloud-native web applications
wererunonthesetwoVMs.MonitoringdatafromthetwoVMsandunderneath
host is exported using the Prometheus agent deployed on each of them to an
external virtual machine. stress-ng is used for generating the load on the VMM.
Based on this infrastructure, we collected a dataset for various scenarios and
combined it with the synthetic data.
8 Jindal et al.
Table 2: Datasets used in this work for evaluating the algorithms.
Dataset AnomalousNon-Anomalous VMs TimeTicks
Name VMMs VMMs Per VMM per VM
Synthetic 5 5 10 1000
Exp-Synthetic Merged 42 17 2 (experimental) 5400
8 (synthetic)
Azure† [1] 16 10 10 5400
Alibaba† [14] 10 10 10 5400
†These are modified for our usecase.
(a)Synthetic (b)Exp-Synthetic (c)Azure (d)Alibaba
Fig.5: An example profile of an anomalous VMM having 10 VMs in all the datasets
used in this work for evaluation.
Azure Dataset:Thisdatasetisbasedonthepubliclyavailablecloudtraces
data from Azure [1]. We used the VMs data from it and created random groups
of VMs, with each group representing the VMs hosted on a VMM. Afterward,
we feed these timeseries groups in our synthetic data generator for randomly
increasing or decreasing the CPU utilization of the VMs within a VMM based
on the input parameters to create anomalous and non-anomalous VMMs.
Alibaba Dataset: This dataset is based on the publicly available cloud
traces and metrics data from Alibaba cloud [14]. A similar method as the Azure
Dataset was also applied to form this dataset.
Figure5showsanexampleprofileofananomalousVMMforallthedatasets.
4.2 Evaluated Algorithms
We compare IAD to the five other algorithms listed in Table 3 along with their
input dimension and parameters. ECP is a non-parametric-based change detec-
tion algorithm that uses the E-statistic, a non-parametric goodness-of-fit statis-
tic, with hierarchical division and dynamic programming for finding them [3].
BnB(BranchandBorder)anditsonlineversion(BnBO)arealsonon-parametric
change detection methods that can detect multiple changes in multivariate data
by separating points before and after the change using an ensemble of random
partitions [2]. Lastly, we use the popular anomaly detection algorithm: isola-
tionforestfordetectinganomalousVMM[10].Theprimaryisolationforest(IF)
works on the input data directly, while we also created a modified version of it
called the isolation forest features (IFF), which first calculates several features
IAD: Indirect Anomalous VMMs Detection in the Cloud-based Environment 9
Table3:Thedetailsofthealgorithmsusedinthisworkforevaluation,alongwiththeir
input dimension and parameters.
Algorithm Input DimensionParameters
IAD n × d w, minPercentVMsFault
ECP [3] n × d change points, Min. points b/w change points
BNB [2] n × d w, number of trees, threshold for change points
BNBOnline [2] n × d w, number of trees, threshold for change points
IF [10] n × d contamination factor (requires training)
IFF [10] n × features contamination factor (requires training)
such as mean, standard deviation, etc., for all values within a window on the
input dataset and then apply isolation forest on it. The downside of the IF and
IFF is that they require training.
4.3 Other Settings
We have used F1-Score (denoted as F1) to evaluate the performance of the
algorithm. Evaluation tests have been executed on 2.6 GHz 6-Core Intel Core i7
MacBook Pro, 32 GB RAM running macOS BigSur version 11. We implement
ourmethodinPython.Forourexperiments,hyper-parametersaresetasfollows.
The window size w is set as 1 minute (60 samples, with sampling done per
second), threshold k as 5%, and percentVMsFault f as 90%. However, we also
show experiments on parameter sensitivity in this section.
5 Results
Our Initial experiments showed that 1) CPU metric is the most affected and
visualized parameters in the VMs when some load is generated on the VMM; 2)
All or most VMs are affected when a load is introduced on the VMM.
5.1 Q1. Indirect Anomaly Detection Accuracy
Table4showsthebestF1-scorecorrespondingtoeachalgorithmevaluatedinthis
work (§4.2) and on all the datasets (§4.1). We can observe that IAD algorithm
outperforms the others on two datasets, except for the Experiment-Synthetic
dataset (BNB performed best with F1-Score of 0.90) and Alibaba dataset (IFF
performedbestwithF1-Scoreof 0.66.However,ifonewantstofindanalgorithm
thatisperformingwellonallthedatasets(AverageF1-scorecolumninTable4),
inthatcase,IAD algorithmoutperformsalltheotherswithanaverageF1-score
of 0.837 across all datasets.
Furthermore, we present the detailed results of the algorithms on all four
datasets varying with the number of VMs and are shown in Figure 6. One can
observethatIAD performsbestacrossallthedatasets,anditsaccuracyincreases
with the increase in the number of VMs. Additionally, after a certain number of
10 Jindal et al.
Table 4: F1-score corresponding to each algorithm evaluated in this work (§4.2) and
on all the datasets (§4.1)
Algorithm SyntheticExp-SyntheticAzureAlibabaAverage F1-score
IAD 0.96 0.86 0.96 0.57 0.837
ECP 0.67 - 0.76 0.51 0.64
BNB 0.62 0.90 0.8 0.33 0.662
BNBOnline 0.87 0.81 0.86 0.4 0.735
IF 0.76 0.83 0.76 0.2 0.637
IF Features (IFF) 0.76 0.83 0.76 0.66 0.75
(a)Synthetic (b)Exp-Synthetic
(c)Azure (d)Alibaba
Fig.6: F1-score variation with the number of VMs corresponding to each algorithm
evaluated in this work (§4.2) and on all the datasets (§4.1)
VMs, the F1-score of IAD becomes stable. This shows that if, for example, we
havethesyntheticdataset,thenthebestperformanceispossiblewithVMs≥9.
Similarly, in the case of the Azure dataset, while for the Exp-Synthetic dataset,
one needs at least five VMs, and for the Alibaba dataset, seven VMs for the
algorithm to perform well.
5.2 Q2. Anomalous VMMs finding efficiency and scalability
Next, we verify that our algorithm’s detection method scale linearly and com-
pareitagainstotheralgorithms.Thisexperimentisperformedwiththesynthetic
dataset,sincewecanincreasethenumberofVMsperVMMinit.Welinearlyin-
creasedthenumberofVMsfrom1to100andrepeatedlyduplicatedourdataset
in time ticks by adding Gaussian noise. Figure 7 shows various algorithm’s de-
tection method scalability for different parameters. One can observe that IAD’s
IAD: Indirect Anomalous VMMs Detection in the Cloud-based Environment 11
(a)WithnumberofVMs (b)Withnumberoftimeticks
Fig.7: Algorithm’s detection method scalability with respect to different parameters.
detectionmethodscalelinearlyintermsofboththeparameters.However,when
the number of VMs are scaled to 100, IAD takes a longer time as compared
to others, but it provides results under 2.5s which if we see is not that much
consideringtheaccuracywegetwiththatalgorithm.However,onthetimeticks
parameter, BNB, BNBOnline and IAD performed similar to each other, while
IF and IFF provides results under 1 second, but its accuracy is worse as com-
paredtotheothersonallthedatasets,andithastheextraoverheadoftraining.
ECP algorithm’s results are not shown, since it requires more than an hour for
performing the detection with 100 VMs and 100,000 time ticks.
6 Conclusion
We propose IAD algorithm for indirect detection of anomalous VMMs by solely
using the resource’s utilization data of the VM’s hosted on them as the primary
metric. We compared it against the popular change detection algorithms, which
couldalsobeappliedtotheproblem.WeshowcasedthatIAD algorithmoutper-
forms all the others on an average across four datasets by 11% with an average
accuracyscoreof 83.7%.WefurthershowcasedthatIAD algorithmscale’slinear
with the number of VMs hosted on a VMM and number of time ticks. It takes
less than 2.5 seconds for IAD algorithm to analyze 100 VMs hosted on a VMM
fordetectingifthatVMMisanomalousornot.Thisallowsittobeeasilyusable
in the cloud environment where the fault-detection time requirement is low and
can quickly help DevOps to know the problem is of the hypervisor or not.
The future direction includes using other metrics like network and storage
utilization to enhance the algorithm’s accuracy further.
References
1. Cortez, E., Bonde, A., Muzio, A., Russinovich, M., Fontoura, M., Bianchini, R.:
Resource central: Understanding and predicting workloads for improved resource
management in large cloud platforms. In: Proceedings of the 26th Symposium on
Operating Systems Principles. p. 153–167. SOSP ’17, Association for Computing
Machinery,NewYork,NY,USA(2017).https://doi.org/10.1145/3132747.3132772,
https://doi.org/10.1145/3132747.3132772
12 Jindal et al.
2. Hooi, B., Faloutsos, C.: Branch and border: Partition-based change detection in
multivariate time series. In: SDM (2019)
3. James,N.A.,Matteson,D.S.:ecp:Anrpackagefornonparametricmultiplechange
point analysis of multivariate data (2013)
4. Jindal,A.,Gerndt,M.,Bauch,M.,Haddouti,H.:Scalableinfrastructureandwork-
flowforanomalydetectioninanautomotiveindustry.In:2020InternationalCon-
ferenceonInnovativeTrendsinInformationTechnology(ICITIIT).pp.1–6(2020).
https://doi.org/10.1109/ICITIIT49094.2020.9071555
5. Knuth, D.E.: The Art of Computer Programming, Volume 2 (3rd Ed.): Seminu-
merical Algorithms. Addison-Wesley Longman Publishing Co., Inc., USA (1997)
6. Kochend¨orffer, R.: Kreyszig, e.: Advanced engineering mathemat-
ics. j. wiley & sons, inc., new york, london 1962. ix + 856 s. 402
abb. preis s. 79.—. Biometrische Zeitschrift 7(2), 129–130 (1965).
https://doi.org/https://doi.org/10.1002/bimj.19650070232, https://
onlinelibrary.wiley.com/doi/abs/10.1002/bimj.19650070232
7. Le, M., Tamir, Y.: Rehype: Enabling vm survival across hypervisor failures. In:
Proceedingsofthe7thACMSIGPLAN/SIGOPSInternationalConferenceonVir-
tualExecutionEnvironments.p.63–74.VEE’11,AssociationforComputingMa-
chinery, New York, NY, USA (2011). https://doi.org/10.1145/1952682.1952692,
https://doi.org/10.1145/1952682.1952692
8. Li, M.L., Ramachandran, P., Sahoo, S.K., Adve, S.V., Adve, V.S., Zhou, Y.: Un-
derstandingthepropagationofharderrorstosoftwareandimplicationsforresilient
system design. In: ASPLOS 2008 (2008)
9. Ling, R.F.: Comparison of several algorithms for computing sample means
and variances. Journal of the American Statistical Association 69(348),
859–866 (1974). https://doi.org/10.1080/01621459.1974.10480219, https://www.
tandfonline.com/doi/abs/10.1080/01621459.1974.10480219
10. Liu, F.T., Ting, K.M., Zhou, Z.H.: Isolation forest. In: 2008 Eighth
IEEE International Conference on Data Mining. pp. 413–422 (2008).
https://doi.org/10.1109/ICDM.2008.17
11. Nikolai, J., Wang, Y.: Hypervisor-based cloud intrusion detection system. 2014
InternationalConferenceonComputing,NetworkingandCommunications(ICNC)
pp. 989–993 (2014)
12. Parashar, M., AbdelBaky, M., Rodero, I., Devarakonda, A.: Cloud
paradigms and practices for computational and data-enabled science
and engineering. Computing in Science Engineering 15(4), 10–18 (2013).
https://doi.org/10.1109/MCSE.2013.49
13. Reinhardt, S.K., Mukherjee, S.S.: Transient fault detection via simultaneous mul-
tithreading. In: Proceedings of the 27th Annual International Symposium on
Computer Architecture. p. 25–36. ISCA ’00, Association for Computing Machin-
ery, New York, NY, USA (2000). https://doi.org/10.1145/339647.339652, https:
//doi.org/10.1145/339647.339652
14. Shan,Y.,Huang,Y.,Chen,Y.,Zhang,Y.:Legoos:Adisseminated,distributedos
for hardware resource disaggregation. In: Proceedings of the 13th USENIX Con-
ference on Operating Systems Design and Implementation. p. 69–87. OSDI’18,
USENIX Association, USA (2018)
15. Xu, X., Chiang, R.C., Huang, H.H.: Xentry: Hypervisor-level soft error detection.
In:201443rdInternationalConferenceonParallelProcessing.pp.341–350(2014).
https://doi.org/10.1109/ICPP.2014.43