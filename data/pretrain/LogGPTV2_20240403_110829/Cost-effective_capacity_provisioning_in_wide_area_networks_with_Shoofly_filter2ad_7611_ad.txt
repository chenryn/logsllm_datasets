### Impact of Scaling Demands on Cost Savings

Figure 9 illustrates the impact of scaling demands on the cost savings achieved by S. As the demand is scaled to 8X, the cost savings decrease by approximately 2%. This indicates that even with significantly increased traffic demands, the potential cost savings from bypassing remain relatively stable. Network operators can use S with scaled traffic demands to make future-proof bypass decisions without sacrificing significant cost savings.

### Impact of Network Topology

Next, we evaluate S on different network topologies. We have detailed information about the network of a cloud provider, referred to as CP-WAN in the figures. Additionally, we assess S using the network topology and demand matrices for prominent production networks, as released by previous studies [5, 23]. We assume these networks operate a point-to-point optical backbone.

Figure 10a shows the percentage of ports saved by S for the backbone networks of Abilene, B4, Nextgen, CP-WAN, and a custom topology from previous work. S consistently demonstrates the potential to save hardware costs across all network topologies, ranging from over 55% cost savings in the Nextgen topology to 15% in the Custom network topology. Figure 10b illustrates the fraction of regions in the networks that participate in optical bypass. Over 50% of the regions in the CP-WAN are bypassed by one or more wavelengths, confirming the bypass potential found in the inter-regional traffic matrices (§2).

### Lower Data Rates from Optical Bypass

A key concern with optical bypass is that it may reduce the capacity between regions by forcing signals to travel longer distances. Our evaluation of S shows that the bypass-enabled topology not only meets 8X the present-day traffic demands (§4.1) but also enables 30-40% hardware cost savings (Figure 9).

The reduction in capacity between regions occurs due to a downgrade in signal modulation formats on shortcuts, caused by increased transmission distance. Figure 11 shows the modulation formats of the bypasses enabled by S. Fewer shortcut hops allow S to maintain a majority of the wavelengths in higher-order modulation formats. For example, of the 3-hop only shortcuts allocated by S, over 45% can sustain 150 Gbps, and 17% can sustain 200 Gbps per wavelength. As S considers shortcuts with higher hops, it can save more cost (Figure 8), but this comes at the expense of longer shortcut lengths and consequently lower data rates. Figure 11 indicates that the fraction of bypasses supporting higher modulation formats decreases as hop lengths increase. When up to 5-hop shortcuts are allowed, only 11% of shortcuts can sustain 200 Gbps. The split of all links based on modulation formats in the original and bypass-enabled networks is compared in Figure 17 of Appendix A.2.

To mitigate the concern of lowered network capacity due to bypass, we compute the normalized per-link capacity of the original network and the bypass-enabled networks in Table 2. The normalized link capacity in the original network is 160 Gbps, whereas bypass-enabled networks lower it by 4% in the worst-case.

### Failure-Resilient Optical Bypass

Enabling optical bypasses fundamentally changes the impact of individual physical link failures on the IP network's ability to carry traffic. In point-to-point networks, there is a one-to-one mapping from physical to IP links. Therefore, the failure of a physical link (e.g., fiber cut, amplifier failure) leads to an individual IP link's failure. However, in a bypass-enabled topology, one physical link can underpin several IP links, and the failure of one physical link can cause multiple IP links to fail. Thus, we must revisit the failure resilience of the backbone network with optical bypasses.

There is extensive research on link failure resilience in the context of traffic engineering in the WAN. We incorporate their methods to achieve failure resilience in the capacity provisioning problem of S. In doing so, we not only provision network topologies with built-in link failure resilience but also show that S's optimization can be extended to use various reliability objectives. We design and implement two objectives: resilience to deterministic [25] and stochastic link failures [5].

#### K-wise Link Failures

First, we discuss provisioning bypass-enabled cloud topologies resilient to the possibility of \( k \) simultaneous physical link failures. This resilience guarantees that even if \( k \) physical links were to fail, the resulting network after bypasses can continue to meet traffic demands. This is important because \( k \) physical link failures can translate to more than \( k \) failures in the bypass-enabled topology. Today, cloud providers provision to be resilient to 2 link failures [25].

We formulate the problem of provisioning bypasses under \( k \) simultaneous link failures by building on Algorithm 1. In addition to the objective and constraints of Algorithm 1, this formulation includes a set of constraints for each link failure scenario, with a set of failing links \( SRLG_k \). For instance, when \( k = 1 \), each \( SRLG_k \) contains each duplex edge. Thus, for each failure scenario and its set of failing links, the following constraints ensure a feasible allocation of flow that meets all demands in the bypass-enabled network:

\[ \text{Maximize:} \sum_{B} |B| \cdot F_B \]
subject to:
\[ \text{(1)-(8) AllocationConstraints(flow, G, } \tilde{\lambda}, F) \]
\[ \sum_{C \in \pi_3} \text{flow}_C \leq \sum_{C \in \pi_3} \text{flow}^k_C, \quad \forall \pi_3 \in \Pi \]
\[ \text{flow}^k_C \geq 0, \quad \forall C \in \pi_3, \quad \forall \pi_3 \in \Pi \]
\[ \text{flow}^k_C = 0, \quad \forall C \in \pi_3, \quad \forall \pi_3 \in \Pi, \quad \forall C \in SRLG_k \]
\[ \text{(F1}_k\text{)} \sum_{C \in \pi_3} \text{flow}^k_C \leq \sum_{C \in \pi_3} \text{flow}_C, \quad \forall \pi_3 \in \Pi \]
\[ \text{(F2}_k\text{)} \text{AllocationConstraints(flow}^k, G^k, \tilde{\lambda}^k, F) \]

Provisioning under \( k \)-wise failures maximizes cost savings while ensuring feasible flow allocations under all link failure scenarios. The number of constraints grows with the number of failure scenarios considered. Recent work has shown ways to translate such optimization formulations into efficiently solvable models [7]. Our current experiments use a less scalable encoding, which is easier to encode and sufficient for the current evaluation.

S formulates the \( k \)-failure resilient bypass provisioning problem using Algorithm 1 and the constraints from Definition 5.1 for all single and double link failures. We compute vanilla (no additional failure resilience), single link failure resilient, and double link failure resilient bypass-enabled topologies. The cost savings from failure-resilient topologies are virtually indistinguishable from the vanilla topologies (Figure 19 in Appendix). Thus, making S failure-resilient does not reduce hardware cost savings.

**Evaluation.** We implement and solve maximum flow traffic engineering on two bypass-enabled network topologies: one without failure resilience and the other resilient to 2 link failures. We solve several instances of the traffic engineering problem by failing 2 randomly selected links in both topologies for each instance. Figure 12 shows the throughput of traffic engineering on the topologies as the demand between nodes is scaled from present-day demands in the cloud network to 20X the present-day demands. As expected, the throughput rises linearly as demand scale increases until it becomes sub-linear due to network capacity limits. At low demand scales, both networks achieve similar throughput since double link failures do not stress over-provisioned cloud networks. However, at high demand scales, the failure-resilient S topology achieves 5% higher throughput than the vanilla topology.

#### Probabilistic Link Failures

Recent work has proposed a cloud traffic engineering algorithm, TVaR, that computes flow allocations to minimize the expected un-met traffic demands, called loss or \( L_{TVaR} \), under probabilistic link failure scenarios [5]. The algorithm takes as input the likelihood of link failure scenarios (\( P \)) and target network availability (\( V \)) to compute flow allocations. The minimal loss (\( L_{TVaR} \)) is guaranteed with probability \( V \), and the expectation over all scenarios where the loss is greater than \( L_{TVaR} \) is calculated by \( E[L | L > L_{TVaR}] \) or conditional value at risk. We augment S with TVaR’s demand constraints to enhance its resilience to probabilistic link failures.