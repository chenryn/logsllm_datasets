or
⟨{NA,{NA · KAB}
,{NA · {P}KAB
}
K+
B
K+
A
, y}, [P/y]⟩
Recall the example given at the end of Section 4.1, where
the attacker knows NA and {NA · P}KAS . Suppose that it
only makes one explicit guess of KAS and aims to obtain P .
Then, his knowledge is represented by
⃗T = ⟨{NA,{NA · P}KAS , x}, [KAS/x]⟩
Moreover, it can be shown that ⃗T (cid:3)Edy P and T [KAS/x] ⊢Edy
P . That is, P is weakly veri(cid:12)able by ⃗T . Here, the attacker
needs not to explicitly guess P .
On the contrary, in Example 7, we notice that
{NA,{(NA · NB) · {NA}
}KAS , x}[KAS/x] 0Edy K +
B
K+
B
Thus, as noted before, the attacker has to make other ex-
plicit guess(es) (e.g., a guess of K +
B ) to obtain K +
B .
321
5.2 Guessability
Finally, we coin the term guessability (i.e., the attacker’s
ability to guess) in terms of weak veri(cid:12)ability.
De(cid:12)nition 5.4 (Guessability). Let ⃗T be a markup term set
representing the attacker’s knowledge. We say that a ground
term t is guessable by the attacker if ⃗T IE t.
This provides the last step to formalize and justify the long
held intuition between \guess" and \verify".
Noticing that the attacker’s knowledge should be updated
to ⟨T ∪{t}, σ⟩ if ⟨T, σ⟩ IE t, one may reasonably think that
we need to recursively add new guessable terms into the
attacker’s knowledge until no new guessable term can be
found. It seems probable that De(cid:12)nition 5.4 fails to account
for this dynamics.
Somewhat surprisingly, we (cid:12)nd that adding t into the at-
tacker’s knowledge makes no di(cid:11)erence in terms of guessabil-
ity. The following theorem states this formally and justi(cid:12)es
the De(cid:12)nition 5.4.
Theorem 5.5. Suppose that ⟨T, σ0⟩ IE s. Then, ⟨T, σ0⟩ IE
t if and only if ⟨T ∪ {s}, σ0⟩ IE t.
6. HARDNESS OF GUESSING
Until now we have mainly focused on the possibility of
guessing. In this section, we concern ourselves with the hard-
ness of guessing, that is, how much computational e(cid:11)orts are
required to obtain a guessable term t, provided ⃗T I t.
It should be noted that di(cid:11)erent guessing problems in-
cur di(cid:11)erent computational cost. For example, (explicitly)
guessing a 128-bit symmetric key is signi(cid:12)cantly harder than
guessing a poorly chosen password. In fact, there is a phys-
ical argument [37] that implies that guessing a 128-bit sym-
metric key is \practically infeasible". Moreover, even for the
same guessing problem, the e(cid:11)orts can vary considerably in
di(cid:11)erent ways of (explicit) guessing. For instance, in Exam-
ple 4, the attacker can either explicitly guess P or explicitly
−
B is a 1024-bit pri-
guess K
vate key and P is a poorly chosen password. Then, guessing
−
B .
P could be much easier than guessing K
−
B to obtain P . Let us assume K
Thus, despite the guessability results, we also need a new
notion to characterize the hardness of guessing. One may
think of using the binary length of all the explicit guesses.
Unfortunately, this simple way may fail to faithfully charac-
terize the hardness, as the following examples show.
Example 8. Let us consider two scenarios, in which the
attacker’s knowledge is, respectively, represented by
⃗T1 = ⟨{NA,{NA · P}KAB ,{NA · K +
A
[KAB/x, KAS/y]⟩
}KAS
}, x, y},
and
⃗T2 = ⟨{NA,{{NA · P}
[KAB/x, KAS/y]⟩
K+
B
}KAB ,{K
−
B
}KAS , x, y},
Suppose that the attacker wants to obtain {P}
in the (cid:12)rst
scenario and P in the second. In both cases, these can be
done by explicitly guessing KAB and KAS. It is tempting to
conclude that guessing {P}
and P is equally di(cid:14)cult.
K+
A
K+
A
However, a closer examination reveals the di(cid:11)erence.
In the (cid:12)rst scenario, the attacker can use
fst(dec({NA · P}KAB , x))σ =Edy NA
(1)
to obtain the correct guess of KAB. Note that Equation (1)
does not involve the guess of KAS. So, the attacker can
correctly guess KAB without guessing KAS. Similarly, we
see that the attacker can also correctly guess KAS without
guessing KAB. After correctly guessing KAB and KAS, the
attacker can easily get P and K +
.
K+
A
To sum up, the maximum number of times the attacker has
attempted to obtain {P}
A , and thus derive {P}
|KAB|
|KAS|
is 2
+ 2
.
K+
A
On the contrary, in the second scenario, the attacker can
only use
fst(dec(dec({{NA · P}
}KAB , x), y))σ =Edy NA
(2)
K+
B
to obtain the correct guesses of KAB and KAS, and thus
derive P . This means the attacker has to guess KAB and
KAS simultaneously. Hence, the maximum number of times
it has attempted to obtain P is 2
|KAB|+|KAS|
.
Therefore, guessing in the second scenario is considerably
harder than in the (cid:12)rst scenario.
Example 9. Let
⃗T = ⟨{NA,{NA · P}KAB ,{KAS}P ,{NA · K +
B
[KAB/x, KAS/y]⟩
}KAS , x, y},
K+
B
denotes the attacker’s knowledge. Suppose that the attacker
wants to obtain {P}
. Similar to the (cid:12)rst scenario in the
previous example both explicit guesses (of KAB and KAS)
can be made independently. But we have to be careful not
to conclude that the maximum number of times the attacker
has attempted to obtain {P}
Let us take a closer look at ⃗T . We notice that after obtain-
ing the correct guess of KAB the attacker can use snd(dec({NA·
P}KAB , KAB)) =Edy P to derive P , which can be further
used to derive KAS as dec({KAS}P , P ) =Edy KAS. So, the
|KAB|+|KAS|
is also 2
K+
B
.
attacker can derive KAS only by a single explicit guess of
KAB. In other words, the maximum number of times the
attacker has attempted is just 2
|KAB|
.
As noted in the above examples, the number of bits that
the attacker has to guess might be less than that of all ex-
plicit guesses. There are two main reasons for this: (i) some
explicit guess(es) can be readily made without dealing with
other guesses, dividing an overall hard guess problem into
several easier ones; and (ii) the redundancy inherent in all
the explicit guesses makes it possible to derive useful infor-
mation between them.
We thus propose to use the search space, rather than the
number of bits of the explicit guesses, to characterize the
hardness of guess.
De(cid:12)nition 6.1 (Hardness). We de(cid:12)ne minmax( ⃗T I t) as
the minimum maximum number of times one might attempt
to obtain t. Moreover, we say that the hardness of ⃗T I t is
in order of n (or n-bit hard) if n = ⌈log2 minmax( ⃗T I t)⌉.
Now, it is not hard to see that ⃗T1 I{P}
and ⃗T2 I P
|KAB|
|KAS|
) and
in Example 9 is
in Example 8 are in order of log2 (2
|KAB| + |KAS|, respectively; ⃗T I{P}
in order of |KAB|.
K+
A
+ 2
K+
B
322
Remark. Although De(cid:12)nition 6.1 allows us to evaluate the
hardness of guess accurately, it does not provide much in-
sight into how to determine minmax( ⃗T I t) and thus the
hardness of ⃗T I t. Obviously, much future work remains
to be done for solving minmax( ⃗T I t). There are two is-
sues to be considered in addressing this problem: (cid:12)rst, to
explore the redundancy in those explicit guesses, and sec-
ond, to partition the explicit guesses into groups that can
be done without involving others. We do not explore these
issues further in this paper.
7. DETECTING GUESSING ATTACKS
In this section, we brie(cid:13)y discuss how the proposed frame-
work can be used e(cid:11)ectively in detecting guessing attacks.
7.1 A Cognitive Perspective
Before diving into the technical discussion, it helps to have
a clear distinction between passive and active attacks (not
just guessing attacks).
Passive attack.
The passive attacker does not interact with protocol par-
ticipants; whether or not it can launch an attack solely based
upon the eavesdropped data. We thus informally view the
passive attack as a computing problem: given a set of ob-
served messages, whether it is possible to \compute" con(cid:12)-
dential data.
In the literature, intruder deduction [15, 1, 21, 18] and
static equivalence [2, 1, 7, 12] correspond to this computa-
tional view, where computing is regarded as a knowledge
reasoning process.
Active attack.
Besides its ability to reason about knowledge as the pas-
sive attacker, the active attacker can also communicate with
legitimate participants. Bene(cid:12)t from a cognitive perspec-
tive, this can be understood in two complementary ways:
1.
2.
(Communication view) we can think of communication
with external entities as a way of gaining new informa-
tion that cannot be deduced from its current knowledge.
(Computational view) we can regards the external enti-
ties as as an internal oracle that computes new informa-
tion from its current knowledge.
Example 10. Let us consider again the protocol presented
in the introduction:
Message 1.
Message 2.
A → B : {NA}KAB
B → A : {f(NA)}KAB
An active attacker can act in the role of A initiate commu-
nication with B. Assume that the attacker’s knowledge is
represented by term set TI = {I, A, B,{NA}KAB
not know {f(NA)}KAB (i.e., TI 0Edy
{f(NA)}KAB and thus its knowledge becomes
}.
Only after exchanging messages with B, it obtain message
From a communication point of view, the attacker does
{f(NA)}KAB ) at (cid:12)rst.
I = {I, A, B,{NA}KAB ,{f(NA)}KAB
′
T
Clearly,
TI ̸≡Edy T
′
I
}
(3)
323
From a computational point of view, the attacker is en-
dowed with an oracle that takes t as input and outputs
g(t) = enc(f(dec(t, KAB)), KAB)
(4)
where g is a public function symbol that never occurs in the
original term algebra T . As the oracle is internal, we thus
incorporate the above equation to equation theory Edy and
get E
′
dy. Therefore,
TI ≡E
′
T
I
′
dy
(5)
In this light, we can categorize the security protocol mod-
els into two groups: one is based on communication view,
such as Strand Space Model [28], CSP [45], and applied pi-
calculus [2]; the other is based on computational view, such
as multiset rewriting [10], constraint solving[44], Prolog rules
[5], and Horn clauses [6].
We remark that a clear distinction between passive and
active attack enables us to determine whether the attack is
primarily due to the attacker’s knowledge or its interaction
with legitimate participants. Moreover, a thorough under-
standing of passive attacks will shed important light on the
study of active attacks and security protocol design as well.
7.2 Passive Guessing Attacks
In terms of passive guessing attack, the knowledge rea-
soning problem is that, given a set of observed messages,