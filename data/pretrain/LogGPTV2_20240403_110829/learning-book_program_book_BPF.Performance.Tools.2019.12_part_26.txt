176
Chapter 5 bpftrace
bptrace
program
Parse
Kerme
srots,
AST
pranst.arg.
TP& Clang Pa
don
Probe
BPF
Probes
Attached
BPF bytec
Ver
pim_Mp() 4
Asytc Actioni
priast(I
perf buf
Figure 5-3 bpftrace internals
LLVM for compiling the program to BPF bytecode.
bpftrace uses libbcc and libbpf to attach to probes, load programs, and use USDT. It also uses
The bpftrace language is defined by lex and yacc files that are processed by flex and bison. The
output is the program as an abstract syntax tree (AST). Tracepoint and Clang parsers then process
structs. A semantic analyzer checks the use of language elements, and throws errors for misuse.
The next step is code generationconverting the AST nodes to LLVM IR, which LLVM finally
compiles to BPF bytecode.
The next section introduces bpftrace debugging modes that show these steps in action: d prints
the AST and the LVM IR, and v prints the BPF bytecode.
5.17
bpftraceDebugging
There are various ways to debug and troubleshoot bpftrace programs. This section summarizes
printf() statements and bpftrace debug modes. If you are here because you are troubleshooting an
issue, also see Chapter 18, which covers common issues, including missing events, missing stacks,
and missing symbols.
ae peq saqedeo pt8u go pas e wog pasodtuoo Aipeau s a a8enuel [npamod t s aoengdq aM
designed to work safely together and to reject misuse. In comparison, BCC, which allows C and
Python programs, uses a much larger set of capabilities that were not designed solely for tracing
and that may not necessarily work together. The result is that bpftrace programs tend to fail with
human-readable messages that do not require further debugging, whereas BCC programs can fail
in unexpected ways, and require debugging modes to solve.
---
## Page 214
5.17 bpftrace Debugging 177
5.17.1printf() Debugging
printf() statements can be added to show whether probes are really firing and whether variables
are what you think they are. Consider the following program: it prints a histogram of vfs_read()
duration. However, if you run it, you may discover that the output includes outliers with 
unbelievably high durations. Can you spot the bug?
kprobe :vfs_read
fsoesu = [pta]<xessg
kretprobe:vfs_read
$duration_ns = (nsecs - Bstart [tid]] / 1000000;
Bns = hlst (Sduration_ms)
delete (estart[tid]) 
If bpftrace begins running halfway through a vfs_read() call, then only the kretprobe willfire, and
the latency calculation becomes *nsecs - O’′, as @start[tid] is uninitialized. The fix is to use a filter
on the kretprobe to check that @start[tid] is non-zero before you use it in the calculation. This
could be debugged with a printf() statement to examine the inputs:
pcintf (*$duration_ns = (ed - Id) / 1000000^o*, msecs, Bstart [tid]] 
There are bpftrace debug modes (covered next), but bugs like this may be quickly solved with a
well-placed printf().
5.17.2 Debug Mode
The d option to bpftrace runs debug mode, which does not run the program but instead shows
how it was parsed and converted to LLVM IR. Note that this mode may only really be of interest to
developers of bpftrace itself, and it is included here for awareness.
It begins by printing an abstract syntax tree (AST) representation of the program:
.1{)qunco = [prd]e 1 peexsA:x, - p-sseaagdq 
Progran
k:vfs_read
nap: 8
builtin: pid
call: count
---
## Page 215
178
Chapter 5 bpftrace
followed by the program converted to LLVM IR assembly:
 HoduleID = *bpCtrace
source_filename = *bpftrace*
target datalayout = *em:e=p:64:64=164 :64=n32:64-S128*
target triple = *bpf-pc-linux
 Function Attrs1 nourmind
declare 164 e11vm.bpf-paeudo [164, 164] #0
 Function Attrs: argnemonly nounwind
declare void B1lvm.lifetime-start,p0i8 (i64, i8* nocspture) 1
define i64 8*kprobeivfs_read* (i8* nocapture readnone) local_unnaned_addr section
"s_kprobe:vfs_read_1" ↑
entry:
s*B_va1* = alloca 164, allgn B
*B_key* = alloca [8 x i8], align 8
1 = getelementptr 1nbounds [8 × 18, [8 x 18]* s"@_key", 164 0, 164 0
call void ellvm.lifetime,atart,p0i8(i64 -1, i8* nonnull 1)
iget_p1d_tgid = ta11 ca11 164 1nttoptx (164 14 to 164 ()*) ()
$2 = 1she i64 $get_pid_tgid, 32
store 164 s2, 18* $1, align 8
pseudo = tai1 ca1l i64 B11vm.bpf,pseudo (i64 1, i64 1)
s1ookup_elem = ca11 1B* 1nttoptx (164 1 to 18* (18*, 18*) *) (164 与pseudo, [8 x 18]*
ax8 Tnuuou
Inap_lcokup_cond = Losp eq 18* s1ookup_elen, nu11
br i1 msp_lokup_cond, label lokup_nerge, label lookup_succes3
lookup_success1
 preds = lentry
53 = 1oad 164, 18* s1ookup_elem, al1gn B
ephitmp = add i64 43, 1
br labe1 lookup_nerge
lookup_merge:
 preds = lentxy, slcokup_success
$1ookup_elem_vra1.0 = phi i64 [ phitmp, 1ookup_success 1。 [ 1, entry ]
54 = bltcast 164* s*@_val* to 18*
call void e1lm.1ifetine,start,p0i8 (i64 1, i8* nonnul1 4)
store 164 slcokup_elem_val.0, 164* s"8_val*, allgn B
pseudo1 = ca11 i64 e11vm.bpf -pseudio (i64 1, i64 1)
supdate_elem = ca11 164 1nttoptx (164 2 to 164 (18*, 18*, 18*, 164) *) (164 与pseudo1,
[8 x i8]* nonnul] *8_key*。 i64* nonnull *8_val*, i64 0}
---
## Page 216
5.17 bpftrace Debugging  179
call void e1lm. 1ifetine,end.p0i8 (i64 1, i8* nonnull 1)
call void @11vm, 1ifetine,end. p018 (164 -1, 18* nonnull 14)
ret i64 0
 Function Attxs: argmemonly nounvind
declare void Bllvn.lifetime-end.p0ie(i64, i8* nocapture) f1
attributes 0 = ( nounvind )
attributes #1 = (argnemonly nounvind 1
There is also a id mode, verbose debug, that prints extra information: the LLVM IR assembly
before and after optimization.
5.17.3 Verbose Mode
The v option to bpftrace is verbose mode, printing extra information while running the
program. For example:
(:()qunco = [prd]e 1 peexsgA:x, e- a- eoexagdq +
Attaching 1 pzobe..*
Progzan ID: 5994
Bytecode :
0:(85) call bpf_get_current_pid_tgid14
Z =<< 0x 4c1 
0 = [9π-0↑z] [ 9n]  (q) 1
3: (18) r] = Dxfffr892fBc92be00
5: (bf) r2 = r10
9↑- =+ Zx (c0) 9
7: (85) ca11 bpf_nap_lookup_elenf1
[ = [x (ca] :8
9: (15) if r0 == 0x0 goto pc+2
R0=map_value (1d=0 off=0, ks=B, vs=8 inm=0) R1=1nv1 310=fp0
(0+ 02) [< 9n|  = [3 (6c) =0T
R0=αap_value (1d=0, off=0, ks=B, vs=8 inm=0) R1=1nv1 R10=fp0
11: (07) r1 += 1
[a = [g- Dtx) (+ psn) + (c) =zt
13: (1e) r1 = 0xffff892f8c92be00
15: (bf) r2 = r10
16: (07) c2 += -16
17: (bf) r3 = r10
18: (07) r3 += -B
---
## Page 217
180
Chapter 5 bpftrace
19 : (b7) r4 = 0
20 : (85) cal1 bpf_nap_update_elem2
21: (b7) r0 = 0
22: (95) ex1t
fron 9 to 12: safe
processed 22 insns, stack depth 16
Attach.ing kprobe:vfs_resd
Running...
^C
[6169]: 1
[28178]: 1
[...]
The program ID can be used with bpftool to print information on BPF kernel state, as shown in
Chapter 2. The BPF bytecode is then printed, followed by the probe it is attaching to.
As with α, this level of detail may only be of use to developers of bpftrace internals. Users should
not need to be reading BPF bytecode while using bpftrace.
5.18Summary
bpftrace is a powerful tracer with a concise high-level language. This chapter describes its features,
tools, and example one-liners. It also covers programming and provides sections on probes, flow
control, variables, and functions. The chapter finishes with debugging and internals.
The following chapters cover targets of analysis and include both BCC and bpftrace tools. An
advantage of bpftrace tools is that their source code is often so concise that it can be included in
this book
---
## Page 218
pter
CPUs
CPUs execute all software and are a common starting point for performance analysis. If you find
a workload to be limited by the CPUs ("CPU bound°), you can investigate further by using CPU
and processor-centric tools. There are countless sampling profilers and metrics available to help
you understand CPU usage. Nonetheless (if perhaps surprisingly), there are still a number of areas
where BPF tracing can help even further with CPU analysis.
Learning Objectives:
■ Understand CPU modes, the behavior of the CPU scheduler, and CPU caches
 Understand areas for CPU scheduler, usage, and hardware analysis with BPF
 Learn a strategy for successful analysis of CPU performance
 Solve issues of short-lived processes consuming CPU resources
 Discover and quantify issues of run queue latency
■ Determine CPU usage through profiled stack traces and function counts
 Determine reasons why threads block and leave the CPU
Understand system CPU time by tracing syscalls
 Investigate CPU consumption by soft and hard interrupts
 Use bpftrace one-liners to explore CPU usage in custom ways
This chapter begins with the background you need to understand CPU analysis, summarizing the
behavior of the CPU scheduler and CPU caches. I explore what questions BPF can answer, and
provide an overall strategy to follow. To avoid reinventing the wheel and to direct further analysis,
I first summarize traditional CPU tools, then BPF tools, including a list of BPF one-liners. This
chapter ends with optional exercises.
6.1Background
This section covers CPU fundamentals, BPF capabilities, and a suggested strategy for CPU analysis.
---
## Page 219
182
Chapter 6 CPUs
6.1.1
CPU Fundamentals
CPU Modes
CPUs and other resources are managed by the kernel, which runs in a special privileged state
called system mode. User-level applications run in user mode, which can only access resources
through kernel requests. These requests can be explicit, such as system calls, or implicit, such as
CPUs are not idle, as wellas CPU time spent in user mode and system mode. Various performance
page faults triggered by memory loads and stores. The kernel tracks the amount of time that the
tools show this user/system time split.
The kernel usually only runs on demand, triggered by syscalls and interrupts. There are some
exceptions, such as housekeeping threads that run in the background, consuming CPU resources.
An example of this is a kernel routine to balance memory pages on non-uniform memory access
(NUMA) systems, which can consume significant CPU resources without an explicit request from
user-level applications. (This can be tuned or disabled.) Some file systems also have background
routines, such as for periodically verifying checksums for data integrity.
CPU Scheduler
The kernel is also responsible for sharing CPU resources between consumers, which it manages via
a CPU scheduler. The main consumers are threads (also called tasks) which belong to processes
or kernel routines. Other CPU consumers include interrupt routines: These can be soft interrupts
triggered by running software or hard interrupts triggered by hardware.
Figure 6-1 shows the CPU scheduler, picturing threads waiting their turn on run queues and how
they move between different thread states.
VCX
CPU
ICX
CPU
ON-PROC
Thread
RUNNABLE
TimeSharing/
Sleep
Preemption
High
Thread
Priority
Pre-
Thread
Run
uondua
Balancing
Load
Queue
Low
Thread
Migration
SLEEP
Wake up
Thread
Thread
Thread
VCX:Voluntary Context Switch
ICX: Involuntary Context Switch
Figure 6-1 CPU scheduler
---
## Page 220
6.1Background
183
Three thread states are pictured in this diagram: ON-PROC for threads that are running on a CPU,
RUNNABLE for threads that could run but are awaiting their turn, and SLEEP for threads that
are blocked on another event, including uninterruptible waits. Threads waiting on a run queue
are sorted by a priority value, which can be set by the kernel or by user processes to improve the
-a[dtu Aeut3uo sem Stnnpauos moq are sananb ung) sqse sueuodu auotu jo aoueuogad
mented, and the term and mental model are still used to describe waiting tasks. However, the
Linux CFS scheduler actually uses a redl/black tree of future task execution.)
This book uses terminology based on these thread states: *on CPU* refers to ON-PROC, and °off
CPU° refers to all other states, where the thread is not running on a CPU.
Threads leave the CPU in one of two ways: (1) voluntary, if they block on I/O, a lock, or a sleep;
or (2) involuntary, if they have exceeded their scheduled allocation of CPU time and are desched-
uled so that other threads can run or if they are preempted by a higher-priority thread. When a
CPU switches from running one process or thread to another, it switches address spaces and other
metadata; this is called a context switch.
Figure 6-1 also pictures thread migrations. If a thread is in the runnable state and sitting in a run
queue while another CPU is idle, the scheduler may migrate the thread to the idle CPU's run
queue so that it can execute sooner. As a performance optimization, the scheduler uses logic to
avoid migrations when the cost is expected to exceed the benefit, preferring to leave busy threads
running on the same CPU where the CPU caches should still be warm.
CPU Caches
Whereas Figure 6-1 shows a software view of CPUs (the scheduler), Figure 6-2 provides a hardware
view of the CPU caches.
CPU
MMU
ES
DS
TLB
Memory
Main
Level 1
Level 2
Figure 6-2 Hardware caches
Depending on the processor model and type, there are typically multiple levels of CPU cache,
increasing in both size and latency. They begin with the Level 1 cache, which is split into sepa-
rate instruction (IS) and data (D$) caches and is also small (Kbytes) and fast (nanoseconds).
The caches end with the last-level cache (LLC), which is large (Mbytes) and much slower. On a 
processor with three levels of caches, the LLC is also the Level 3 cache. The Level 1 and 2 caches
are usually per CPU core, and the Level 3 cache is usually shared across the socket. The memory
management unit (MMU) responsible for translating virtual to physical addresses also has its own
cache, the translation lookaside buffer (TLB).
1 There are also mode swritches: Linux syscalls that do not block may only (depending on the processor) need to switch
modes between user and kernel-mode.
---
## Page 221
184
4Chapter 6 CPUs
CPUs have been scaling for decades by increasing clock speed, adding cores, and adding more
hardware threads. Memory bandwidth and latency have also improved, especially by adding and
degre as the CPUs. Workloads have become limited by memory performance termed *memory-
increasing the size of CPU caches. However, memory performance has not scaled to the same
bound°) rather than the CPU cores.
Further Reading
This has been a brief summary to arm you with some essential knowledge before you use the
tools. CPU software and hardware are covered in much more depth in Chapter 6 of Systerms
Performance [Gregg 13b].
6.1.2 BPF Capabilities
Traditional performance tools provide various insights for CPU usage. For example, they can show
CPU utilization by process, context switch rates, and run queue lengths. These traditional tools
are summarized in the next section.
BPF tracing tools can provide many addlitional details, answering:
•What new processes are created? What is their lifespan?
8ugop Aa ane pe eudno au seoss ary u8u aur wasis s Au 
• How long do threads spend on-CPU for each wakeup?
 How long do threads spend waiting on the run queues?
· W'hat is the maximum length of the run queues?
■ Are the run queues balanced across the CPUs?
•Why are threads voluntarily leaving the CPU? For how long?
• What soft and hard IRQs are consuming CPUs?
● How often are CPUs idle when work is available on other run queues?
•What is the ILC hit ratio, by application request?
These questions can be answered using BPF by instrumenting tracepoints for scheduler and syscal
events, kprobes for scheduler internal functions, uprobes for application-level functions, and
PMCs for timed sampling and low-level CPU activity. These event sources can also be mixed: A
BPF program could use uprobes to fetch application context and then associate that with instru
mented PMC events. Such a program could show the LLC hit ratio by application request, for
example.
Metrics that BPF provides can be examined per event or as summary statistics, with distributions
shown as histograms. Stack traces can also be fetched to show the reasons for events. All these
activities have been optimized using in-kernel BPF maps and output buffers for efficiency.
---
## Page 222
6.1  Background 185
Event Sources
Table 6-1 lists the event sources for instrumenting CPU usage.
Table 6-1  Event Sources for Instrumenting CPUs
Event Type
Event Source
Kernel functions
Kprobes, kretprobes
User-level functions
uprobes, uretprobes
System calls
syscall tracepoints
Soft interrupts
irq:softirq* tracepoints
Hard interrupts
irq:irq_handler* tracepoints
Workqueue events
workqueue tracepoints (see Chapter 14)
Timed sampling
PMC- or timer-based sampling
CPU power events
power tracepoints
CPU cycles
PMCs
Overhead
When tracing schecduler events, efficiency is especially important because scheduler events such
as context switches may occur millions of times per second. While BPF programs are short and
fast (microseconds), executing them for every context switch may cause this tiny overhead to adld
up to something measurable, or even significant. In the worst case, scheduler tracing can add over
10% overhead to a system. If BPF were not optimized, this overhead would be prohibitively high.
Scheduler tracing with BPF can be used for short-term, ad hoc analysis, with the understanding
that there will be overhead. Such overhead can be quantified using testing or experimentation
to determine: If CPU utilization is steady from second to second, what is it when the BPF tool is
running and not running?
CPU tools can avoid overhead by not instrumenting frequent scheduler events. Infrequent events,