# Title: Anomaly, Application Change, or Workload Change? Towards Automated Detection of Application Performance Anomalies and Changes

## Authors:
- Ludmila Cherkasova
- Kivanc M. Ozonat
- Ningfang Mi
- Julie Symons
- Evgenia Smirni

## Conference:
International Conference on Dependable Systems & Networks: Anchorage, Alaska, June 24-27, 2008

## Abstract
Automated tools for understanding application behavior and its changes during the application lifecycle are essential for many performance analysis and debugging tasks. Application performance issues can significantly impact customer experience and satisfaction. A sudden slowdown in an enterprise-wide application can affect a large population of customers, delay projects, and ultimately result in financial loss for the company. We believe that online performance modeling should be a part of routine application monitoring. Early, informative warnings about significant changes in application performance can help service providers identify and prevent performance problems and their negative impacts. We propose a novel framework for automated anomaly detection and application change analysis, integrating two complementary techniques: (i) a regression-based transaction model reflecting the resource consumption model of the application, and (ii) an application performance signature providing a compact model of the application's runtime behavior. The proposed integrated framework offers a simple and powerful solution for anomaly detection and analysis of essential performance changes. Additionally, our approach is non-intrusive and relies on monitoring data typically available in enterprise production environments.

## 1. Introduction
Today's IT and Services departments face the challenging task of ensuring that business-critical applications are always available and perform adequately. As the complexity of IT systems increases, performance management becomes the largest and most difficult expense to control. This paper addresses the problem of efficiently diagnosing essential performance changes in application behavior to provide timely feedback to application designers and service providers. Typically, initial performance profiling of an application is done using synthetic workloads or benchmarks designed to reflect "typical" application behavior and client transactions. While such profiling can be useful in the early stages of design and development, it may not be adequate for analyzing performance issues in existing production systems. Production systems often experience different workloads compared to those in testing environments, and frequent software releases and updates make thorough performance evaluation challenging. When poorly performing code enters production, it can lead to productivity losses and increased operating costs.

Automated tools for understanding application behavior and its changes during the application lifecycle are essential for many performance analysis and debugging tasks. However, such tools are not readily available to application designers and service providers. The traditional reactive approach of setting thresholds for observed performance metrics and raising alarms when these thresholds are violated is inadequate for understanding performance changes between application updates. A proactive approach based on continuous application performance evaluation can assist enterprises in reducing productivity losses by quickly diagnosing essential performance changes.

With increasing system complexity and growing customer requirements for Quality of Service (QoS), the research challenge is to design an integrated framework of measurement and system modeling techniques to support performance analysis of complex enterprise systems. Our goal is to design a framework that enables automated detection of application performance changes and provides useful classification of the possible root causes. Specifically, we aim to detect and classify:

- **Performance Anomaly:** An observed application behavior (e.g., current CPU utilization) that cannot be explained by the observed application workload (e.g., the type and volume of transactions processed by the application). This might indicate either an unrelated resource-intensive process consuming system resources or unexpected application behavior due to undetected bugs.
- **Application Transaction Performance Change:** An essential change (increase or decrease) in transaction processing time, such as after an application update. If the detected change indicates an increase in transaction processing time, an alarm is raised to assess the additional resources needed and provide feedback to application designers.
- **Workload Change:** Variations in transaction mix and load, which are typical for web-based applications. It is crucial to avoid false alarms due to workload changes, though information on observed workload changes can be made available to the service provider.

The rest of the paper is organized as follows: Section 2 introduces client vs. server transactions. Section 3 provides two motivating examples. Sections 4 and 5 introduce two complementary techniques as an integrated solution for anomaly detection and application performance change. Section 6 presents a case study to validate the proposed techniques. Section 7 describes related work, and Section 8 provides a summary and conclusions.

## 2. Client vs. Server Transactions
The term "transaction" is often used with different meanings. In our work, we distinguish between a client transaction and a server transaction.

- **Client Transaction:** A client communicates with a web service (deployed as a multi-tier application) via a web interface. The unit of activity at the client-side corresponds to the download of a web page, which is composed of an HTML file and several embedded objects such as images. This composite web page is called a client transaction.
- **Server Transaction:** The main HTML file is built via dynamic content generation (e.g., using Java servlets or JavaServer Pages), where the page content is generated by the application server to incorporate customized data retrieved via multiple queries from the back-end database. This main HTML file is called a server transaction. The server transaction is responsible for most of the latency and consumed resources at the server side during client transaction processing.

A client browser retrieves a web page (client transaction) by issuing a series of HTTP requests for all the objects: first, it retrieves the main HTML file (server transaction), and after parsing it, the browser retrieves all the embedded, static images. At the server side, a web page retrieval corresponds to processing multiple smaller objects, which can be retrieved either in sequence or via multiple concurrent connections. It is common for a web server and application server to reside on the same hardware, sharing resources to generate main HTML files and retrieve page-embedded objects.

Since the HTTP protocol does not provide any means to delimit the beginning or end of a web page, it is very difficult to accurately measure the aggregate resources consumed due to web page processing at the server side. There is no practical way to effectively measure the service times for all page objects, although accurate CPU consumption estimates are required for building an effective application provisioning model. To address this problem, we define a client transaction as a combination of all the processing activities at the server side to deliver an entire web page requested by a client, i.e., generate the main HTML file and retrieve embedded objects and perform related database queries.

We use client transactions for constructing a "resource consumption" model of the application. The server transactions reflect the main functionality of the application. We use server transactions for analyzing the application performance changes (if any) during the application lifecycle.

## 3. Two Motivating Examples
Frequent software updates and shortened application development time dramatically increase the risk of introducing poorly performing or misconfigured applications to the production environment. Consequently, effective models for online, automated detection of whether application performance deviates from its normal behavior pattern have become a high priority item on the service provider's "wish list."

### Example 1: Resource Consumption Model Change
In earlier papers [20, 21], a regression-based approach was introduced for resource provisioning of multi-tier applications. The main idea is to use statistical linear regression to approximate the CPU demands of different transaction types (where a transaction is defined as a client transaction). However, the accuracy of the modeling results critically depends on the quality of the monitoring data used in the regression analysis. If the collected data contain periods of performance anomalies or periods when an updated application exhibits very different performance characteristics, this can significantly impact the derived transaction cost and lead to an inaccurate provisioning model.

Figure 1 shows the CPU utilization (red line) of the HP OpenView Service Desk (OVSD) over a one-month period (each point reflects a one-hour monitoring period). Most of the time, CPU utilization is under 10%. Note that for each weekend, there are some spikes in CPU utilization (marked with circles in Fig. 1), which are related to administrator system management tasks and are orthogonal to transaction processing activities of the application. Once provided with this information, we use only weekdays' monitoring data for deriving CPU demands of different transactions of the OVSD service. As a result, the derived CPU cost accurately predicts CPU requirements of the application and can be considered a normal resource consumption model of the application.

Figure 1 also shows the predicted CPU utilization, which is computed using the CPU cost of observed transactions. The predicted CPU utilization accurately models the observed CPU utilization, with the exception of weekends' system management periods. However, if we were not aware of "performance anomalies" over weekends and used all the days (including weekends) of the one-month data set, the accuracy of the regression would be much worse (the error would increase twice), and this would significantly impact the modeling results.

![Figure 1: CPU Utilization of OVSD Service](figure1.png)

### Example 2: Updated Application Performance Change
Another typical situation that requires special handling is the analysis of the application performance when it has been updated or patched. Figure 2 shows the latency of two application transactions, Tr1 and Tr2, over time (here, a transaction is defined as a server transaction). Tools like HP (Mercury) Diagnostics [13] are commonly used in IT environments to observe latencies of critical transactions and raise alarms when these latencies exceed predefined thresholds. While it is useful to have insight into the current transaction latencies, which implicitly reflect the application and system health, this approach provides limited information on the causes of the observed latencies and cannot be used directly to detect performance changes in an updated or modified application. The latencies of both transactions vary over time and get visibly higher in the second half of the figure. This does not look immediately suspicious because the latency increase can simply reflect a higher load in the system.

![Figure 2: Transaction Latency Measured by HP (Mercury) Diagnostics Tool](figure2.png)

The real story behind this figure is that after timestamp 160, we began executing an updated version of the application code where the processing time of transaction Tr1 is increased by 10 ms. However, by looking at the measured transaction latency over time, we cannot detect this: the reported latency metric does not provide enough information to detect the change.

### Problem Definition
While off-line data analysis can detect and filter out time periods corresponding to abnormal application performance or identify periods where application performance experiences significant change, the goal is to design an online approach that automatically detects performance anomalies and application changes. Such a method enables a set of useful performance services:

- Early warnings on deviations in expected application performance,
- Alarms on abnormal resource usage,
- A consistent dataset for modeling the application resource requirements by filtering out performance anomalies and pointing out periods of changed application performance.

The next two sections present our solution, which integrates two complementary techniques: (i) a regression-based transaction model that correlates processed transactions and consumed CPU time to create a resource consumption model of the application, and (ii) an application performance signature that provides a compact model of the application's runtime behavior.

## 4. Regression-Based Approach for Detecting Model Changes and Performance Anomalies
We use statistical learning techniques to model the CPU demand of the application transactions (client transactions) on a given hardware configuration. This approach helps us find statistically significant transaction types, discover time segments where the resource consumption of a given application can be approximated by the same regression model, and identify time segments where the model changes.