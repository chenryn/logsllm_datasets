## PostgreSQL 逻辑复制插件 UDR, 可以愉快的玩类似MySQL的binlog复制了                
### 作者                                                                     
digoal                                                                      
### 日期                                                                    
2015-10-10                                                                       
### 标签                                                                    
PostgreSQL , 事件触发器 , event trigger , 逻辑复制 , UDR                                                                                                                                             
----                                                                    
## 背景                      
PostgreSQL 的流复制素来以高效，实时，稳定著称；  
为企业解决了很多问题，例如容灾，备份，HA，读写分离等等。  
但是流复制有一个无法克服的弊端，下游节点只能做到只读，并且只能复制整个集群（使用walbouncer可以做到基于表空间或库级别的物理流复制）。  
http://www.cybertec.at/en/products/walbouncer-enterprise-grade-partial-replication/  
如果用户确实有表级或行级的复制需求，我们不得不使用其他手段来实施，例如londiste3, dblink, trigger， bucardo, slony-I等。  
这些插件或工具是基于触发器的，所以对上游节点的性能影响比较大，而且复制效率一般般。  
PostgreSQL社区一直在努力将逻辑复制加入到PG的内核中，同样使用的是XLOG，从XLOG中解出row，在下游节点回放。有点类似于MySQL的binlog复制方案。  
在逻辑复制加入PostgreSQL内核代码前（预计9.6的版本可能会加入），用户可以使用2nd提供的bdr插件来实现逻辑复制。  
如果做单向的复制，使用9.4或以上的PostgreSQL版本即可，而如果要使用双向复制（多主），则需要使用2nd提供的PostgreSQL版本。  
地址：  
https://github.com/2ndQuadrant/bdr  
本文以单向复制为例，即UDR，讲解一下这个插件的使用。  
## 插件部署  
下载插件，我们需要的是bdr-plugin的稳定分支。  
```  
# git clone -b bdr-plugin/REL0_9_STABLE git://git.postgresql.org/git/2ndquadrant_bdr.git bdr-plugin  
```  
安装UDR插件  
```  
# export PATH=/opt/pgsql/bin:$PATH  
# cd bdr-plugin  
# ./autogen.sh  
# ./configure BUILDING_UDR=1  
# make; make install  
```  
修改BUG  
```  
# cd /opt/pgsql/share/extension  
[root@digoal extension]# cat bdr.control |grep default_version  
default_version = '0.9.2.0'  
# vi bdr--0.9.2.0.sql   
-- 注释掉这行，应该是bdr的BUG，这个函数依赖的C函数在2nd改版的postgresql下面。  
-- CREATE OR REPLACE FUNCTION bdr.bdr_internal_sequence_reset_cache(seq regclass)  
-- RETURNS void LANGUAGE c AS 'MODULE_PATHNAME' STRICT;  
```  
## 配置  
### 配置上游节点  
```  
$ vi postgresql.conf  
listen_addresses='0.0.0.0'  
port=1921  
max_connections=100  
unix_socket_directories='.'  
ssl=on  
ssl_ciphers='EXPORT40'  
shared_buffers=512MB  
huge_pages=try  
max_prepared_transactions=0  
max_stack_depth=100kB  
dynamic_shared_memory_type=posix  
max_files_per_process=500  
shared_preload_libraries='bdr'  
max_worker_processes=8  
wal_level=logical  
fsync=off  
synchronous_commit=off  
wal_sync_method=open_datasync  
full_page_writes=off  
wal_log_hints=off  
wal_buffers=16MB  
wal_writer_delay=10ms  
checkpoint_segments=8  
archive_mode=off  
archive_command='/bin/date'  
max_wal_senders=10  
max_replication_slots=10  
hot_standby=on  
wal_receiver_status_interval=1s  
hot_standby_feedback=off  
enable_bitmapscan=on  
enable_hashagg=on  
enable_hashjoin=on  
enable_indexscan=on  
enable_material=on  
enable_mergejoin=on  
enable_nestloop=on  
enable_seqscan=on  
enable_sort=on  
enable_tidscan=on  
log_destination='csvlog'  
logging_collector=on  
log_directory='pg_log'  
log_truncate_on_rotation=on  
log_rotation_size=10MB  
log_checkpoints=on  
log_connections=on  
log_disconnections=on  
log_duration=off  
log_error_verbosity=verbose  
log_line_prefix='%i  
log_statement='none'  
log_timezone='PRC'  
autovacuum=on  
log_autovacuum_min_duration=0  
autovacuum_vacuum_scale_factor=0.0002  
autovacuum_analyze_scale_factor=0.0001  
datestyle='iso,  
timezone='PRC'  
lc_messages='C'  
lc_monetary='C'  
lc_numeric='C'  
lc_time='C'  
default_text_search_config='pg_catalog.english'  
bdr.conflict_logging_include_tuples=true  
bdr.log_conflicts_to_table=true  
bdr.temp_dump_directory='pg_bdr_temp_dump_dir'  
$ vi pg_hba.conf  
# "local" is for Unix domain socket connections only  
local   all             all                                     trust  
# IPv4 local connections:  
host    all             all             127.0.0.1/32            trust  
# IPv6 local connections:  
#host    all             all             ::1/128                 trust  
# Allow replication connections from localhost, by a user with the  
# replication privilege.  
local   replication     postgres                                trust  
host    replication     postgres 127.0.0.1/32            trust  
```  
### 配置下游节点  
1\. 只有postgresql.conf中配置的监听端口不一样，其他一样。  
2\. 创建逻辑备份目录。在下游节点初始化订阅时，需要用来存储从上游节点dump的整个被订阅的数据库的数据，所以这个目录的空间要足够大。  
```  
mkdir $PGDATA/pg_bdr_temp_dump_dir  
```  
## 开始使用  
启动数据库  
假设我的上游节点是1921端口，下游节点是1922端口。  
```  
pg_ctl start -D /data01/pgdata_1921  
pg_ctl start -D /data01/pgdata_1922  
```  
在上游节点，我有一个数据库为up，我需要将这个数据库复制到下游节点的数据库down中。  
创建上游数据库，并且在up库创建bdr扩展。  
```  
postgres@digoal-> psql -h 127.0.0.1 -p 1921  
psql (9.4.4)  
Type "help" for help.  
postgres=# create database up;  
CREATE DATABASE  
postgres=# \c up  
You are now connected to database "up" as user "postgres".  
up=# create table tb(id int,info text);  
CREATE TABLE  
up=# insert into tb select generate_series(1,100);  
INSERT 0 100  
up=# create extension btree_gist;  
CREATE EXTENSION  
up=# create extension bdr;  
CREATE EXTENSION  
```  
创建测试表，测试数据类型，测试函数，测试视图  
```  
postgres=# \c up  
You are now connected to database "up" as user "postgres".  
up=# create table t1(id int primary key,info text);  
CREATE TABLE  
up=# create or replace function f1() returns void as $$  
  declare  
  begin  
     raise notice '%', now();  
   end;  
   $$ language plpgsql;  
CREATE FUNCTION  
up=# create view v1 as select count(*) as cnt from t1;  
CREATE VIEW  
up=# create type dt as (c1 int,c2 int,c3 int);  
CREATE TYPE  
up=# insert into t1 select generate_series(1,100);  
INSERT 0 100  
up=# create table t2(id int,c1 dt);  
CREATE TABLE  
up=# insert into t2 values (1,'(1,1,1)');  
INSERT 0 1  
up=# insert into t2 values (2,'(1,1,1)');  
INSERT 0 1  
up=# insert into t2 values (2,'(1,1,1)');  
INSERT 0 1  
up=# insert into t2 values (2,'(1,1,1)');  
INSERT 0 1  
up=# insert into t2 values (2,'(1,1,1)');  
INSERT 0 1  
```  
创建bdr扩展后，新建的表会自动添加TRUNCATE触发器  
```  
up=# \d t1  
      Table "public.t1"  
 Column |  Type   | Modifiers   
--------+---------+-----------  
 id     | integer | not null  
 info   | text    |   
Indexes:  
    "t1_pkey" PRIMARY KEY, btree (id)  
Triggers:  
    truncate_trigger AFTER TRUNCATE ON t1 FOR EACH STATEMENT EXECUTE PROCEDURE bdr.queue_truncate()  
```  
创建下游节点的数据库down，同时也在这个数据库中创建bdr扩展。  
```  
postgres@digoal-> psql -h 127.0.0.1 -p 1922  
psql (9.4.4)  
Type "help" for help.  
postgres=# create database down;  
CREATE DATABASE  
postgres=# \c down  
You are now connected to database "down" as user "postgres".  
down=# create extension btree_gist;  
CREATE EXTENSION  
down=# create extension bdr;  
CREATE EXTENSION  
down=# create database up;  -- 务必创建哦  
```  
为什么在下游节点还需要创建一个up库（虽然我们不是将数据订阅到up库），但是没有这个库，还原会报错，例如：  
这显然是个BUG。  
```  
Dumping remote database "hostaddr=127.0.0.1 port=1921 dbname=up user=postgres fallback_application_name='bdr (6203675445083668497,1,16385,): init_replica dump'" with 1 concurrent workers to "pg_bdr_temp_dump_dir/postgres-bdr-000C837A-1.8393"  
Restoring dump to local DB "hostaddr=127.0.0.1 port=1922 dbname=down user=postgres fallback_application_name='bdr (6203675445083668497,1,16385,): init_replica restore' options='-c bdr.do_not_replicate=on -c bdr.permit_unsafe_ddl_commands=on -c bdr.skip_ddl_replication=on -c bdr.skip_ddl_locking=on'" with 1 concurrent workers from "pg_bdr_temp_dump_dir/postgres-bdr-000C837A-1.8393"  
pg_restore: [archiver (db)] Error while PROCESSING TOC:  
pg_restore: [archiver (db)] Error from TOC entry 3265; 1262 16385 SECURITY LABEL up postgres  
pg_restore: [archiver (db)] could not execute query: ERROR:  database "up" does not exist  
    Command was: SECURITY LABEL FOR bdr ON DATABASE up IS '{ "bdr" : true }';  
pg_restore to hostaddr=127.0.0.1 port=1922 dbname=down user=postgres fallback_application_name='bdr (6203675445083668497,1,16385,): init_replica restore' options='-c bdr.do_not_replicate=on -c bdr.permit_unsafe_ddl_commands=on -c bdr.skip_ddl_replication=on -c bdr.skip_ddl_locking=on' failed, aborting  
```  
在上游节点开启一个更新的压力测试，以测试在上游节点有DML操作时可以复制数据。相互不干扰。  
```  