randomly generated new address.
4.3 Detector
In our system, the function of the detector is to predict the modi-
fied botnet flow and feed the binary result back to the agent. For
comparison, we choose two state-of-art detection models in our
experiments: the composite DL detection model combining CNN
with LSTM and the non-differentiable ML detection model based
on XGBoost as our botnet detector.
BotCatcher detection model. The communication mode between
the C&C server and the bot is significantly different from the com-
munication mode between normal users, so the abnormal traffic
generated by the botnet can be detected through traffic analysis.
BotCatcher [43] uses a deep learning algorithm to automatically
extract temporal and spatial features from network traffic and trains
a softmax classifier accordingly. We show the system framework
in Figure 8.
Considering that CNN has the ability to extract local features
and recognize spatial similarities, RNN has the ability to process
sequence data and recognize temporal similarities. In the feature
learning module, BotCatcher uses CNN to extract spatial features by
converting the botnet session data into a gray image and leverages
LSTM to learn the temporal features of packet sequences. After
processing these two kinds of features through the multilayer neural
network, BotCatcher puts them into a softmax layer to identify
abnormal traffic patterns. The author used the CTU dataset to
verify the effectiveness of the proposed model, while we obtain a
99.6% detection rate on our dataset.
XGBoost detection model. XGBoost stands for eXtreme Gradi-
ent Boosting, which is an efficient implementation of the gradient
boosting machines created by Tianqi Chen. It is designed for speed
and performance, which is the reason why it has recently been
dominating applied machine learning and Kaggle competitions for
structured or tabular data.
200Crafting Adversarial Example to Bypass Flow-&ML- based Botnet Detector via RL
RAID ’21, October 6–8, 2021, San Sebastian, Spain
Figure 8: BotCatcher system framework
Table 3: XGBoost detector’s feature set.
Feature
max_fiat
std_fiat
duration
forward_header_len
total_fiat
mean_fiat
flowPktsPerSecond
fPktsPerSecond
bPktsPerSecond
IOPR
backward_header_len
SameLenPktRatio
max_biat
total_biat
total_packets
mean_biat
std_biat
max_pkt_len
total_fpackets
total_bpackets
Importance
0.188713
0.112026
0.110066
0.103142
0.074335
0.071723
0.066497
0.050493
0.03671
0.028872
0.02652
0.021164
0.01633
0.015546
0.013848
0.012542
0.011431
0.010255
0.007773
0.004377
Feature
max_forward_pkt_len
std_backward_pkt_len
total_pkt_len
std_pkt_len
mean_forward_pkt_len
mean_pkt_len
min_pkt_len
NPEx
max_backward_pkt_len
mean_backward_pkt_len
total_forward_pkt_len
flowBytesPerSecond
min_forward_pkt_len
std_forward_pkt_len
total_backward_pkt_len
fBytesPerSecond
min_backward_pkt_len
min_fiat
min_biat
bBytesPerSecond
Importance
0.003005
0.002809
0.002221
0.001829
0.001568
0.001502
0.001372
0.000719
0.000523
0.000457
0.000392
0.000327
0.000261
0.000261
0.000196
0.000131
6.53E-05
0
0
0
Dhaliwalet et al. [15] chose XGBoost to build an IDS system. The
performance of XGBoost is better than those of many other models
because it can effectively deal with the problem of data surplus and
can be processed in parallel. Therefore, XGBoost is very suitable
for dealing with real-world networks.
In their work, the authors performed a cross-validation exper-
iment using the NSL-KDD dataset (a csv file containing the 41-
dimensional characteristics of malicious traffic), achieving a result
(98.7%) better than those of other machine learning algorithms. The
model structure and hyperparameter settings used in this paper are
completely consistent with they used (they tuned the hyperparam-
eter settings), and we obtain detection result (98.9%) that is as good
as the original work on our dataset. We list the extracted features
and their importance in Table 3.
5 RESULTS
To evaluate our system, we divide the dataset into four disjoint sub-
sets: a detector training set, an agent training set, a detector testing
set, and an agent testing set, at a ratio of 4:4:1:1. The disjointness is
to test the generalization ability of our attack model, and to better
simulate the real attack scenario, where the attacker may not be
able to obtain the training data of the target detector.
To compare the performances of different RL algorithms and de-
tectors, we implement the following four system instances: SARSA
agent–BotCatcher detector, SARSA agent–XGBoost detector, DQN
agent–BotCatcher detector, and DQN agent–XGBoost detector.
Each agent is trained for action_num ∗ sample_num rounds.
5.1 Evasion performance
The evasion rate illustrates the probability that the botnet flow
adversarial example can successfully evade the detector. Table 4
compares the testing evasion rates of four system examples after
training on 10 botnet families. Among them, XGBoost-random and
BotCatcher-random represent the situations in which we use a ran-
dom strategy to select actions from the action space for modifying
the botnet flow. On the one hand, they are the baselines for mea-
suring whether the agent is effective. In other words, if the agent’s
performance is not as good as the random strategy, it means that
the agent has not learned anything useful. From Figure 1, we can
see that the results of the RL algorithm are better than those of
the random strategy in any case. On the other hand, this can also
prove that our action space is indeed effective because even random
selection can bypass the detector with a certain probability.
Contrasts between families. From Table 4, we can find that the
evasion rates vary among different botnet families; Storm even has
an evasion rate of 0 with XGBoost-SARSA. With an unchanging
action space, the influence of existing actions on different family
samples vary. Through a statistical analysis of each family sample,
we find that a lower evasion rates may be due to the sessions
containing the largest numbers of packets (such as Storm, which
is a P2P-based botnet that has a large session size), so the effect
of adding packets or changing the timestamps on eigenvalues is
relatively small. Alternatively, the characteristics of botnet samples
are very diverse from those of benign samples, causing the agent
to fail to convert it into a benign sample within a limited set of
action_num steps. In practical applications, the attacker can trade-
off between the evasion rate and the size of the perturbation to the
traffic sample, and increase the action_num appropriately.
Contrasts between agents. By comparing the evasion rates of the
system instances with the same detector but different agents in
Figure 1, we find that in most cases, the SARSA agent performs
better than the DQN agent. We think that this is caused by the
intrinsic difference between the two RL algorithms. SARSA is an on-
policy algorithm that is more cautious than Q-learning. Q-learning
always thinks about maximizing Q functions, regardless of other
non-maxQ results. SARSA is a conservative algorithm that cares
about every step of the decision and is sensitive to errors and death.
Therefore, when we aim to generate adversarial examples with
201RAID ’21, October 6–8, 2021, San Sebastian, Spain
Wang and Liu, et al.
Table 4: Evasion performances of system instances.
Menti Rbot Murio
87%
76%
XGBoost-SARSA
75%
85%
XGBoost-DQN
68%
75%
XGBoost-Random
24%
21%
BotCatcher-SARSA
BotCatcher-DQN
22%
21%
BotCatcher-Random 17%
20%
83%
77%
72%
26%
22%
19%
virut Miuref Neris HTBot Dridex Trickbot
86%
85%
71%
40%
41%
37%
61%
49%
45%
54%
52%
48%
66%
60%
54%
42%
38%
37%
41%
41%
34%
38%
50%
37%
31%
30%
24%
59%
51%
42%
66%
56%
42%
34%
28%
27%
Storm
0%
1%
0%
73%
64%
59%
Table 5: Time performances of system instances.
Menti
1.35
XGBoost-SARSA
XGBoost-DQN
2.14
6.42
XGBoost-Random
6.54
BotCatcher-SARSA
BotCatcher-DQN
8.3
BotCatcher-Random 11.43
Rbot Murio Virut Miuref Neris HTBot Dridex Trickbot
3.21
5.26
10.26
4.24
6.36
11.91
1.14
1.87
5.14
7.11
7.48
11.14
2.93
4.45
8.05
6.04
4.44
10.11
2.56
4.11
7.12
3.06
3.33
8.05
1.81
3.01
8.56
2.19
2.38
7.13
2.27
3.76
6.05
3.05
3.33
9.03
1.42
2.34
6.17
4.73
5.82
9.18
Storm
-
1.61
-
4.93
4.02
10.16
2.33
4
7.12
2.57
3.54
9.06
We use the average number of queries that are necessary for the agent to craft effective adversarial
samples to evaluate the system’s time performance.
fewer steps and tiny perturbances, SARSA agents may be more
suitable than DQN agents.
Contrasts between detectors. As shown in Table 4, the evasion rate
with XGBoost as the detector is higher than that with BotCatcher in
most of the botnet families’ results, and we believe this is because
actions have a greater impact on statistical features than image
features. By analyzing the statistical features of the XGBoost model
shown in Table 3 and the action space described in section 3, we can
see that (i) actions in the action space all directly or indirectly affect
the statistical features, whether they are designed for statistical
features or image features; (ii) many actions in the action space even
change the most dependent features of XGBoost (action 1-duration,
action 2-foward iat, action add-pps, action 9&10-header_len, etc.).
Therefore, we conclude that the targeted modification and high
consistency between the action space and the detector’s feature
space are largely responsible for the vulnerability of the detector.
5.2 Time performances
A major point in black box adversarial attacks is to issue the least
amount of queries to the target model: if the proposed approach
requires a very high number of queries, then its feasibility in real-
world context would affected. We use the average number of queries
that are necessary for the agent to craft effective adversarial samples
to evaluate the system’s time performance. The results are shown
in Table 5.
From the perspectives of the botnet families. , the time perfor-
mances between different families does not change significantly,
meaning that as long as our agent is well trained, it will have a
better performance than that of the baseline regardless of what
botnet family it deals with. This result also further shows that our
system has high availability. If our system has a large gap in terms
of its time performances when facing different botnet families, the
attacker may carefully consider whether our system can adapt to
his botnet.
From the perspective of the RL algorithms. , the agent equipped
with the DQN algorithm often requires more steps to bypass the
detector than the agent equipped with the SARSA algorithm. This
means that the action selected by DQN according to the greedy pol-
icy may not be the optimal action in the current state, so the agent
needs to perform additional actions to accumulate interferences to
bypass the detector.
From the perspective of the detectors. , the number of steps re-
quired for the agent to bypass BotCatcher is higher than that of
XGBoost, meaning that the agent needs more iterations to mislead
BotCatcher than to mislead XGBoost. In other words, XGBoost
not only has a higher evasion rate but the evasion samples also
require relatively fewer steps than those of BotCatcher. Therefore,
we can conclude that XGBoost is more vulnerable than BotCatcher
according to the experiments of this work.
5.3 Dominant actions
Dominant mutations refer to the most frequent actions taken by the
agent when successfully evading the detector. Each botnet family