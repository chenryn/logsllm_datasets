analyzed the current (July 2016) 100 most popular apps from
the Google Play Store in more detail. AGRIGENTO identiﬁed
privacy leaks in 46 of the 100 apps. We manually veriﬁed the
results of our analysis to measure false positives. We found that
42 of these apps are true positives, that is, they leak private
information, while four apps were likely false positives. Note
that, in some cases, to distinguish true positives from false
positives we had to manually reverse the app. During our manual
analysis, we did not encounter any false negative. Once again,
we acknowledge that, due to the absence of a ground truth, it is
not possible to fully exclude the presence of false negatives. In
particular, as further discussed in §VII, AGRIGENTO is affected
by a number of limitations, which a malicious app could take
advantage of.
We then used our risk analysis to rank the risk associated
with these false positives. Interestingly, we found that while two
of the four apps that caused false positives have high scores (i.e.,
8,527 and 8,677 bits), for the other two apps, one in particular,
AGRIGENTO assigned low scores of 6 and 24 bits. We note that
although for this work we use our risk analysis only to rank the
risk of a data leak in each detected app, we believe it could be
used to build, on top of it, a further ﬁltering layer that discards
low bandwidth leaks. We will explore this direction in future
work.
We further classiﬁed the type of leak in three groups:
plaintext, encrypted, and obfuscated. The ﬁrst group contains
apps that leak the information in plaintext. The second group
contains apps for which we observed the leaked information
only after our decryption phase (i.e., the leaked value has been
encrypted or hashed using the Android APIs). Finally, the third
group contains apps that obfuscate information leaks by other
means (i.e., there is no observable evidence of the leaked value
in the network trafﬁc).
11
IMSI
ICCID Location Phone Number Contacts
1
5
0
6
13
0
0
0
0
13
1
0
1
1
11
0
0
0
0
16
0
0
0
0
13
As a ﬁrst experiment, we considered leaks only at the app
level since we are interested in determining whether an app leaks
information or not, independently from the number of times.
In other words, we are interested to determine whether a given
app leaks any sensitive information. Thus, for each app analysis
we performed just one ﬁnal run for which we modiﬁed all
the sources simultaneously. As a result, AGRIGENTO produces
a boolean output that indicates whether an app leaks private
information or not, without pointing out which particular source
has been leaked. Table III shows the results of this experiment.
For this experiment, we consider an app as a true positive when
it leaks any of the monitored sources and AGRIGENTO ﬂags it,
and as a false positive when AGRIGENTO ﬂags it although it
does not leak any information.
While this experiment provides valuable insights, it provides
only very coarse-grained information. Thus, as a second experi-
ment, we performed the same evaluation but we looked at each
different source of information individually. In this case, we
ran the app and performed the differential analysis changing
only one source at a time, and we consider an app as a true
positive only if it leaks information from the modiﬁed source
and AGRIGENTO correctly identiﬁes the leak. Our evaluation
shows that, while AGRIGENTO produces higher false positives
in identifying leaks for a speciﬁc source of information, it has
very few false positives in detecting privacy leaks in general.
The higher false positive rate is due to some sources of non-
determinism that AGRIGENTO failed to properly handle and
that consequently cause false positives when an app does not
leak data. For instance, consider the scenario in which an app
leaks the Android ID and also contains some non-determinism
in its network trafﬁc that AGRIGENTO could not eliminate.
In this case, when considering leaks at app-level granularity,
we consider the app as a true positive for the Android ID,
since it does leak the Android ID. Instead, for any other
source of information (e.g., the phone number) we consider
the app as a false positive because of the non-determinism in
the network trafﬁc. Finally, we could not classify 9 apps, for
which AGRIGENTO identiﬁed leaks of some of the sources,
because of the complexity of reversing these apps.
F. Case Studies
We manually reversed some apps that AGRIGENTO automat-
ically identiﬁed as leaking obfuscated or encrypted information.
Here, we present some case studies showing that current apps
use sophisticated obfuscation and encryption techniques. Hence,
as conﬁrmed by the results of our evaluation, state-of-the-art
solutions to identify privacy leaks are not enough since they do
not handle these scenarios and mostly only consider standard
encodings.
http://i.w.inmobi.com/showad.asm?u-id-map=iB7WTkCLJv
NsaEQakKKXFhk8ZEIZlnL0jqbbYexcBAXYHH4wSKyCDWVfp+q+Fe
LFTQV6jS2Xg97liEzDkw+XNTghe9ekNyMnjypmgiu7xBS1TcwZmF
xYOjJkgPOzkI9j2lryBaLlAJBSDkEqZeMVvcjcNkx+Ps6SaTRzBb
Yf8UY=&u-key-ver=2198564
____________________________________________________
https://h.online-metrix.net/fp/clear.png?ja=33303426
773f3a3930643667663b33383831303d343526613f2d36383024
7a3f363026663d333539347a31323838266c603d687c76722531
63253066253066616f6e74656e762f6a732c746370626f792663
6f652466723f6a747670253161273266253266616d6d2e65616f
656b69726b7573267270697867636e617730266a683d65616437
613732316431353c65613a31386e676065633037363639363434
3363266d64643f6561633336303b64336a393531666330366663
61373261363a61616335636761266d66733f353b32306d383230
613230643b6534643934383a31663636623b3232376761612661
6d65613d3139333331333331333131333133312661743d636565
6e765f6f6f6a696c6d26617e3f7672777174666566676e666572
2b6d6f606b6c652733632b392e3226342d3b
Example of the requests performed by InMobi and ThreatMetrix
Fig. 8.
libraries. InMobi leaks the Android ID, as described in §VI-F, in the value of
u-id-map. ThreatMetrix leaks the Android ID, location, and MAC address
in the ja variable.
Interestingly, all the leaks we found in these case studies
were performed by third-party libraries, and thus may concern
all the apps using those libraries.
Case study 1: InMobi. We found that InMobi, a popular ad
library, leaks the Android ID using several layers of obfuscation
techniques. The Android ID is hashed and XORed with a
randomly generated key. The XORed content is then encoded
using Base64 and then stored in a JSON-formatted data structure
together with other values. The JSON is then encrypted using
RSA (with a public key embedded in the app), encoded using
Base64 and sent to a remote server (together with the XOR
key). Figure 8 shows an example of such a request leaking the
obfuscated Android ID. AGRIGENTO automatically identiﬁed
20 apps in our entire dataset leaking information to InMobi
domains, including one app in the 100 most popular apps from
the Google Play Store. Indeed, according to AppBrain3, InMobi
is the fourth most popular ad library (2.85% of apps, 8.37% of
installs).
Case study 2: ThreatMetrix. The analytics library Threat-
Metrix leaks multiple sources of private information using
obfuscation. It ﬁrst puts the IMEI, location, and MAC address
in a HashMap. It then XORs this HashMap with a randomly
generated key, hex-encodes it, and then sends it to a remote
server. Figure 8 shows an example of such a request leaking
the obfuscated Android ID, location, and MAC address. We
found 15 instances of this scenario in our entire dataset, one of
which is part of the 100 most popular apps from the Google
Play Store. According to AppBrain, ThreatMetrix SDK is used
by 0.69% of the apps in the Google Play Store, and is included
by 4.94% of the installs.
Further ad libraries. We found several other apps and ad
libraries (MobileAppTracking, Tapjoy) leaking private informa-
tion using the Android encryption and hashing APIs. In the most
common scenario, the values are combined in a single string that
is then hashed or encrypted. In this scenario, even though the
app uses known encodings or cryptographic functions, previous
tools are not able to detect the leak of private information.
3http://www.appbrain.com/stats/libraries/ad
G. Performance Evaluation
We execute each app for 10 minutes during each run. The
analysis time per app mainly depends on the complexity of the
app (i.e., the number of runs required to reach convergence).
Setting K = 3, AGRIGENTO analyzed, on average, one
app in 98 minutes. Note that, while we executed each run
sequentially, our approach can easily scale using multiple
devices or emulators running the same app in parallel.
VII. LIMITATIONS AND FUTURE WORK
While we addressed the major challenges for performing
differential analysis despite the overall non-determinism of the
network trafﬁc of mobile apps, our overall approach and the
implementation of AGRIGENTO still have some limitations.
Even though AGRIGENTO improves over the existing state-
of-the-art, it still suffers from potential false negatives. For
example, as any other approach relying on the actual execution
of an app, AGRIGENTO suffers from limited code coverage, i.e.,
an app might not actually leak anything during the analysis,
even if it would leak sensitive data when used in a real-world
scenario. This could happen for two main reasons: (a) An app
could detect that it is being analyzed and does not perform any
data leaks. We address this issue by performing our analysis on
real devices; (b) The component of the app that leaks the data
is not executed during analysis, for example due to missing
user input. We currently use Monkey, which only generates
pseudorandom user input and cannot bypass, for example, login
walls. Related works such as BayesDroid and ReCon performed
manual exploration of apps at least for part of the dataset, which
also included providing valid login credentials. Unfortunately,
manual exploration is only feasible for small-scale experiments
and not on a dataset of over one thousand apps such as ours,
especially given the fact that AGRIGENTO needs to generate
the same consistent user input over multiple executions. As part
of our future work, we are planning to explore whether it is
possible to provide manual inputs for the ﬁrst run of an app, and
then replaying the same input with tools such as RERAN [20]
in the subsequent runs. One option for collecting the initial
manual inputs at scale is Amazon Mechanical Turk.
Second, AGRIGENTO still suffers from some covert channels
that an attacker could use to leak information without being
detected. For instance, a sophisticated attacker could leak private
information by encoding information in the number of times a
certain request is performed. However, this scenario is highly
inefﬁcient from the attacker point of view. Furthermore, we
could address this issue with a more accurate description of the
“network behavior summary.” As a matter of fact, AGRIGENTO
severely limits the bandwidth of the channel an attacker can
use to stealthily trasmit private data.
We need to run each app multiple times: by nature, an
approach using differential analysis requires at least two execu-
tions, one with the original inputs, and another one with different
inputs to observe changes in the outputs. As we discussed in our
evaluation, the non-deterministic network behavior of modern
apps further requires us to perform the original execution more
than once to build a more accurate network behavior summary.
Since we conservatively ﬂag any changes in the output as a
possible leak, in practice the number of runs is a trade-off
between the overall analysis time and the false positive rate.
12
Furthermore, we perform the ﬁnal run once for each source of
private information that we track. This requirement could be
relaxed if our goal was to ﬁnd privacy leaks in general, and not
speciﬁc types of information. In our evaluation we performed
all runs of a speciﬁc app consecutively on the same device. We
could parallelize this process on different devices, however, with
less control over device-speciﬁc artifacts that could potentially
inﬂuence our analysis.
On the implementation side we suffer from two main
limitations: First, we currently do not
instrument calls to
/dev/random, which could be used by native code directly
as a source of randomness. We leave this issue for future work.
Second, we are limited by the protocols we track: we only
check HTTP GET and POST requests for leaks (and man-
in-the-middle HTTPS even with certiﬁcate pinning in most
cases). However, we share this limitation with other tools, such
as ReCon, and leave an extension of AGRIGENTO to other
protocols for future work.
By design, AGRIGENTO can only determine that a speciﬁc
piece of private information was leaked, but not automatically
determine how it was obfuscated. We can, however, perform
the na¨ıve approach employed by related tool of simple grepping
for widely-used encodings and hashing algorithms of the value,
to ﬁlter out those cases and focus manual reverse engineering
efforts on the more complex and interesting ones.
Finally, we can only speculate why app developers are
adopting the stealth techniques that we have uncovered in our
analysis. This development could be related to the increasing
awareness and opposition of users to the collection of their
private data, as well as the investigative efforts of regulators
such as the FTC. Currently, InMobi is very open about the
data it collects in its privacy policy.4 For future work we could
investigate any malicious intent or deceptive practice behind
sophisticated obfuscation techniques, based on automatically
verifying whether those leaks are in violation of an app’s privacy
policy or not. Related work in this direction by Slavin [38] has
so far only compared privacy policies against information ﬂows
identiﬁed with FlowDroid, but has not considered cases in which
apps are hiding their leaks with the techniques AGRIGENTO
uncovered.
VIII. RELATED WORK
Static taint analysis of Android apps is an active research
topic, as several aspects of Android apps proved to be very
challenging—in particular their component-based architecture
and the multitude of entry points due to their user-centric
nature and complex lifecycle. AndroidLeaks [19] was one of
the ﬁrst static taint analysis approaches, but lacks precision
as it tracks data ﬂow at the object-level instead of tainting
their individual ﬁelds. FlowDroid [6] is more precise in this
regard and one of the most widely used static taint analy-
sis tools. Further approaches include EdgeMiner [9], which
addresses the issue of reconstructing implicit control ﬂow
transitions, and Amandroid [44] and IccTA [25], which deal
with inter-component instead of just intra-component data leaks.
MorphDroid [17] argues that conventional data ﬂow tracking
approaches are too coarse-grained, and tracks atomic units of
private information instead of the complete information (i.e.,
4http://www.inmobi.com/privacy-policy/
longitude and latitude instead of the location) to account for
partial leaks. AppIntent [48] proposes to distinguish between
user-intended and covert data leaks and uses symbolic execution
to determine if a privacy leak is a result of user interaction.
AppAudit [46] addresses the false positives of related static
analysis approaches and veriﬁes the detected leaks through
approximated execution of the corresponding functions.
Dynamic taint analysis tracks information ﬂow between
sources of private information and sinks, e.g., the network,
during runtime, either by modifying the device OS (Taint-
Droid [13]),
the platform libraries (Phosphor [8]), or the
app under analysis (Uranine [33]). AppFence [22] extends
TaintDroid to detect obfuscated and encrypted leaks, and also
performed a small-scale study on the format of leaks, but only
found the ad library Flurry leaking data in non-human readable
format in 2011— a situation that has drastically changed since