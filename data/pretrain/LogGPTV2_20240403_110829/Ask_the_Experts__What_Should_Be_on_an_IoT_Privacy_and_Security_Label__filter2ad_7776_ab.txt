experience (UX). We recruited experts with whom the authors
had interacted professionally or were recommended by other
experts. We carefully selected experts, who are all well-known
in their respective ﬁelds. More speciﬁcally, we looked for
experts, who satisﬁed at least one of the following qualiﬁcation
criteria. Seven experts met two criteria.
security.
privacy and security.
privacy, security, or policy.
• Computer science or engineering professor in the ﬁeld of
• More than 10 years of research or practice in the ﬁeld of
• Author of notable books in the ﬁeld of privacy and
• Active involvement in cybersecurity standardization.
• Leading a corporate IoT product team.
After identifying the experts who met the qualiﬁcations we
were looking for, we contacted them and invited them to either
come to our institution for an in-person interview or join our
interview study online over Skype. All the interviews were
audio recorded and transcribed by a third-party service. We
compensated experts with a $25 Amazon gift card.
2) Delphi Method: As deﬁned by Delbecq et al.,
the
Delphi method is “a method for the systematic solicitation
and collection of judgments on a particular topic through a
set of carefully designed sequential questionnaires interspersed
with summarized information and feedback of opinions derived
from earlier responses” [6]. This method of qualitative research
was originally developed by Dalkey and Helmer in the 1950s
and has been widely used to reach consensus between a group
of experts without face-to-face interactions [29]. The Delphi
method has been used in a number of studies related to policy
design and implementation [2], social science [91], and human-
computer interaction [69].
The Delphi method has three important features. First, the
responses as well as group interactions in each round are
anonymized. Second, the process involves multiple rounds of
data collection procedures (e.g., interview, survey), and ﬁnally,
in each round, the summary of the previous round is shown
to experts as a means to reach consensus [19], [27], [28]. The
study continues until consensus is reached, which generally
occurs after three iterations [63].
3) Expert Interviews: The ﬁrst phase of the Delphi method
is open ended [72]. Therefore, our ﬁrst step was to conduct
Fig. 1: We followed a three-round Delphi method, by conducting an interview study and two rounds of surveys. Finally, we designed a label prototype that
captures the ﬁndings of the process, inputs from authors’ multiple rounds of discussion, and a user study with 15 IoT consumers.
semi-structured interviews with privacy and security experts.
We began the interviews by introducing the idea of a privacy
and security label and its similarity to a food nutrition label.
Following the introduction to the study and its goals, we asked
experts to provide their deﬁnition of privacy and security as it
relates to IoT devices. Next, we asked experts to think about
the content of the label and specify the information that they
think should be on a privacy and security label for IoT devices.
For each piece of information they speciﬁed, we asked them
to consider whether it was relevant to consumers or experts. In
an iterative process, we compiled a list of security and privacy
factors suggested by the experts we interviewed, and added
new factors suggested during each interview. Towards the end
of each interview, we presented the full list of factors so that
each expert reviewed their own factors, as well as the factors
suggested by previously-interviewed experts (see Figure 5).
4) First Round Survey: The expert interviews resulted in
an extensive list of privacy, security, and general factors that
experts wanted to see on an IoT label. We then conducted a
survey of the same experts to understand the rationale behind
their preferences (see Figure 6). In order to decrease fatigue,
we split the factors in the survey so that each expert was
presented with one-third of all the factors. For each expert, the
ordering of factors was randomized.
When introducing the survey to experts, we explained that
in a layered IoT label,
the ﬁrst or primary layer would
include the most important information, and the secondary
layer would contain the information on the primary layer as
well as additional helpful information. We also advised experts
not to worry about the design of the label when answering
the questions. Then, for each factor, we asked the experts to
specify whether they believe that factor is important to include
on the label, and to provide reason(s) that support their answer.
5) Second Round Survey: For agreement over the inclusion
and exclusion of factors, we conducted a second survey with
the same set of experts (see Figure 7). When introducing
the second survey to the experts, we described our two key
objectives for the content of the IoT label: to inform consumers,
and to provide a means for holding companies accountable
for their privacy and security practices. To reduce respondent
fatigue, participants answered questions for one-third of all the
factors, randomly chosen from the three categories—security,
privacy and general—such that they saw approximately the
same number of questions within each category.
In this second survey, we used data collected from our
interviews and ﬁrst survey. We presented each factor from our
dataset alongside the experts’ reasons for inclusion or exclusion.
Then, on a ﬁve-point Likert scale, we asked each expert to
decide whether they believe the factor should be included on
the label and to provide their rationale if different from what
we presented. Next, we asked them to specify on which layer of
the label they would like to place this factor and the rationale
behind their choice. We asked them to classify the factor as
being most relevant to privacy, security, or general information.
Finally, we asked experts to provide any additional comments
about the factor that came to mind.
In addition to the questions we asked for each factor, we
asked experts about their opinion on separating or merging
privacy and security sections on the label. At the end of the
survey, we asked experts to state their privacy and security
expertise and domain of knowledge, followed by some general
demographic questions.
6) Data Analysis: We collected approximately 22 hours
of interview audio recordings. We used thematic analysis to
qualitatively summarize interview transcripts, following the
approach suggested by Braun and Clarke [14]:
• Phase 1: A primary coder read the interview transcripts
and took notes, listening to parts of the audio ﬁles as
needed when the transcripts were incomplete.
• Phase 2: The primary coder created the initial codebook
by examining the notes from the interview phase and the
notes from Phase 1 above, listening for reasons for and
against including factors on an IoT label. This step did
not focus on ﬁnding patterns in the responses.
• Phase 3: The primary coder merged the smaller codes
into broader themes. This step focused on ﬁnding patterns
and themes from the long list of codes from Phase 2.
• Phase 4: The themes that emerged from Phase 3 were
reviewed and discussed by the authors of the paper to
resolve any disagreements. This step helped increase the
validity of the themes. In an iterative process, some of
the themes were removed from the codebook and some
themes were merged into more general themes until we
achieved consensus on the ﬁnal themes.
• Phase 5: The ﬁnalized themes (reasons to include or
exclude each factor) were moved into the ﬁnal codebook.
The ﬁnalized privacy, security, and general factors were used
as input to the ﬁrst round of our survey, where we asked experts
to provide us with their arguments. We then followed the same
coding process described above to code the open-ended survey
responses. After the ﬁrst survey, we revised the themes (reasons
Interview with 22 experts(Fig. 5).First Round Survey with 17 experts. Each expert was randomly assigned to address (cid:932)(cid:2869)(cid:2871)of the factors (Fig. 6).Second Round Survey with 21 experts. Each expert was randomly assigned to address (cid:932)(cid:2869)(cid:2871)of the factors (Fig. 7).47 factorsArguments for and against including a factor on the labelAuthors’ discussionLabel wireframe, including primary layer (Fig. 3) and secondary layer (Fig. 4).Arguments for and against including a factor on the label and the quantitative level of importance for each factorUser study with 15 IoT consumersfor and against including a factor on the label) in the codebook
and presented them to the experts in the second survey.
We reached a point of saturation in terms of ﬁnding new
factors after interviewing 20 experts. In other words, no new
privacy, security, or general factors were mentioned by our
participants in the rest of the interviews as well as the two
follow-up surveys.
Thematic analysis is purely qualitative and inductive [14].
The literature showed that having more than one coder does
not make the codes objective, since two coders could apply the
same subjective perspective to the data [67]. Indeed according
to a survey of CSCW and HCI publications from 2016 to 2018,
only 6% of papers using thematic analysis used multiple coders
and measured Inter-rater reliability [68].
An iterative, yet inductive, analysis approach in thematic
analysis increases the reliability of the theme-ﬁnding process
[42]. All the themes were iteratively and extensively discussed
among the researchers in the group. For any disagreement,
researchers traced the theme back to its corresponding subcodes
and checked whether the source of disagreement was the
subcodes that were used. If not, we traced the subcodes
further back to experts’ quotes from the transcriptions and we
then decided on the appropriate subcodes and the appropriate
themes arising from the subcodes. This iterative approach
is recommended with qualitative methods that are high in
subjectivity [42], [65]. We also improved the reliability by
consulting with the expert participants using the second round
survey mentioned above; this triangulation method is known
as testimonial validity or member checking [82].
B. Semi-Structured Interviews with Non-Expert Consumers
We used the results of our expert study to inform the
development of prototype designs for primary and secondary
labels. We created prototype boxes for two ﬁctitious brands of
security cameras and included a primary-layer label on each
box. We put the corresponding secondary-layer labels on a
mock-up of an online shopping website. Next we conducted a
semi-structured interview study with 15 non-expert consumers
to gain insights into how they would use these labels and how
well the labels convey risk.
1) Participant Recruitment and Compensation: We recruited
participants by posting on Craigslist, Reddit, and our institu-
tion’s recruitment website. Participants were required to be
at least 18 years old and have purchased at least one smart
home device or smart personal device. Prospective participants
completed a short screening survey, in which we collected
demographics and asked about what IoT devices they had
purchased and how they purchased them. We invited a diverse
sample of qualiﬁed participants to our lab for a 1-hour interview.
Each interviewee received a $25 Amazon gift card.
2) Initial Questions: We showed participants a box for a
hypothetical security camera that did not include a label and
asked them what they could tell about the privacy and security
of the device by looking at its box. We then asked participants
whether they had ever seen an informative label on any product.
Next, we presented them with one of the two labeled security
Fig. 2: A user study participant comparing the privacy and security practices
of two hypothetical smart security cameras.
camera boxes and asked them what they could tell about the
privacy and security of the device. We asked a number of
questions to study participants’ understanding of the content
of the label and whether the information conveyed risk.
3) Risk Communication in Comparative Purchase Process:
We showed participants the other labelled security camera box,
and told them this camera had the same price and features,
but with different privacy and security information. We asked
them to compare these two products and discuss which has
better privacy and security, which device would they purchase,
and the information that helped them make this decision.
We then told participants about the secondary layer of the
label, which can be accessed by scanning the QR code or
typing in the URL on the ﬁrst layer. After introducing the idea
of the layered label, we asked participants whether they had
ever seen one on any other product. We asked them to discuss
the pros and cons of a one-layer and two-layer label.
4) Information Comprehension in Non-comparative Pur-
chase Process: We asked participants to look at the information
on the label of the product they decided not to purchase
and to discuss their concerns and their understanding of the
information.
5) Risk Communication in Non-comparative Purchase Pro-
cess: We asked participants to specify the factors that seemed
risky to them from a privacy and security perspective and
discuss what kinds of risk they would be exposed to. We also
asked how the product could be improved to reduce this risk.
6) Secondary-Layer Information Comprehension: We asked
participants whether they would prefer to scan the QR code
or type in the URL to look for additional information. Based
on their preference, we scanned the QR code or typed in the
URL on the primary layer to show the secondary layer to
participants. We then asked them to start from the beginning
of the label and tell us what each factor means to them, how
useful they believe each factor would be, and if they have any
suggestions to make the information more understandable.
7) Label Format: We asked questions about the label format,
including the separation of factors into privacy, security, and
general information sections. We also asked participants to
specify the factors that they believed are currently misplaced,
and should be either removed from the label or moved to
another section or layer of the label.
8) Purchase Behavior: Finally, we asked questions to
understated participants’ purchase behavior related to online
and in store shopping.
9) Data Analysis: We collected about 15 hours of audio
recordings, which we had transcribed. The ﬁrst author was
the primary coder who created the codebook and kept it
updated throughout the coding process. To analyze the data, we
used structural coding, which is appropriate for coding semi-
structured interviews [64], [82]. We deﬁned four structural
codes (e.g., attitudes toward layered labels, reasons to include
or exclude a factor from the label), which we divided into 13
subcodes (e.g., being as informed as possible, lack of relevance
to privacy and security). Unlike thematic analysis, structural
coding is more objective, and results in a codebook used for
categorization [82]. Therefore, having more than one coder and
using inter-rater reliability is helpful in testing the reliability
of the codebook [42]. Each interview was independently coded
by two researchers, who then discussed and iteratively revised
the codebook. After resolving the coding disagreements, we
reached the Cohen’s Kappa inter-coder agreement of 84%.
Cohen’s Kappa inter-coder agreement of over 75% is considered
as “excellent” rate of agreement [41]. In case of disagreement,
we report on the results of the primary coder.
C. Ethics
Both expert and consumer studies were reviewed and
approved by our Institutional Review Board (IRB). All par-
ticipants provided their informed consent to participate in the
surveys and interviews, to have audio recorded, and to have the
recordings transcribed by a third-party transcription service.
D. Limitations
Expert elicitation is prone to overconﬁdence and cognitive
biases [89]. To reduce overconﬁdence, in the second expert
survey, we presented strong arguments for and against having
each factor on the label so that experts could read the
rationale provided by other experts before indicating their
own preferences.
The experts interviewed in this study are not representative
of the entire population of privacy and security experts. Our
aim was to surface a wide variety of expert viewpoints.
Therefore, we recruited experts with diverse expertise related
to IoT security and privacy and from different sectors. We
selected experts based on our inclusion criteria, as discussed
in Section III-A1.
TABLE I: We conducted an expert elicitation study with 22 privacy and security
experts. NGO stands for non-governmental organization and UX stands for
user experience.
Expert
ID
P1