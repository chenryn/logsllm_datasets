Impossible to do parallel numpy computations using python subprocesses,  
because just simple import numpy requires ~1Gb paging file
I have 32Gb ram and 4Gb paging file  
this code causes an error
    import multiprocessing
    import time
    def proc():
        import numpy
        time.sleep(1000)
    if __name__ == '__main__':
        for i in range(50):
            multiprocessing.Process(target=proc).start()
        time.sleep(1000)
### Error message:
      File "D:\DevelopPPP\projects\DeepFaceLive\_internal\python\lib\site-packages\numpy\__init__.py", line 140, in 
        from . import core
      File "D:\DevelopPPP\projects\DeepFaceLive\_internal\python\lib\site-packages\numpy\core\__init__.py", line 72, in 
        from . import numeric
      File "", line 971, in _find_and_load
      File "", line 955, in _find_and_load_unlocked
      File "", line 665, in _load_unlocked
      File "", line 674, in exec_module
      File "", line 764, in get_code
      File "", line 833, in get_data
    MemoryError
OS : Windows 10 64-bit
### NumPy/Python version information:
    1.19.5 3.6.8 (tags/v3.6.8:3c6b436a57, Dec 24 2018, 00:16:47) [MSC v.1916 64 bit (AMD64)]