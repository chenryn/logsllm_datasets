Tor relay. We use the nmap command to scan the Tor-port (OR-
port) of all the available Tor relays to cross-check whether they are
actually online. The whole experiment was rerun every 30 minutes
for a period of one full day. Figure 8 shows the difference between
application level and network level reliability. We see that a cer-
tain fraction of the Tor relays drop circuits more often than others
even though they are reachable. Figure 8 also shows the ratio of
the total number of relays that failed to the total number of relays
that succeed in building our customized circuit over different time
intervals. Again we see a signiﬁcant deviation in the application
and network level reliability across the full day inspection and it is
not the case that the deviation alters signiﬁcantly across the time
axis. We also highlight the distribution of these failures against the
Tor relay’s observed and advertised bandwidth. We computed the
correlation between the advertised bandwidth and reliability. We
found the correlation coefﬁcient to be less than 10−8 in magni-
tude. So, we can say bandwidth is not an indicator of reliability in
Tor network. We also veriﬁed that past performance is an indica-
tion of future results. For this we compute the “Pearson Correla-
tion” between past observed failure probability and next observed
outcome; we found the correlation co-efﬁcient to be 0.72 which
suggests that monitoring the reliability of relays is helpful for pre-
dicting their future performance.
From this, we can see that a client potentially beneﬁts by keeping
track of the reliability of the Tor relays he/she uses. To demonstrate
this we run experiments on the live Tor network where a client cre-
ates circuits from a small set of Tor relays (3 guards, 23 middle
relays and 23 exits). In one setting the client ﬁrst generates a rank-
ing of the Tor relays by probing each possible circuit once and then
ﬁlters out potentially unreliable ones. The client then creates 100
circuits from the ﬁltered list of relays. In the other setting the client
just simply creates 100 circuits randomly from the full set of 49
non-ﬁltered Tor relays. In both cases we record the percentage of
circuits failing at different hops (we take the avg. of 10 runs). Table
7 shows the obtained results and we can see that Re3 assists users
to choose more reliable Tor relays for anonymous communications.
Table 7: Reliability result from the live Tor network
Measurements
Mean
SD
Max
Min
1st hop
(%)
0.00
0.00
0.00
0.00
Our Model
2nd hop
(%)
0.00
0.00
0.00
0.00
3rd hop
(%)
2.55
2.21
6.00
0.00
Conventional Tor
1st hop
2nd hop
3rd hop
(%)
0.00
0.00
0.00
0.00
(%)
4.00
3.01
9.00
0.00
(%)
9.73
8.01
22.00
0.00
7. DEPLOYMENT CONSIDERATIONS
In this section we discuss the following two ways of deploying
Re3 into the live Tor network.
• Localized: Individual clients run Re3
• Centralized: Re3 is run by directory authorities (DA servers).
We also study the convergence of Re3 as this is important for any
practical deployment.
7.1 Localized Approach
The easiest way to incorporate our reputation model is to have
it run in the client side. Each client can accumulate his/her experi-
ence to compute the reputation of Tor relays. Such a local approach
does not require cooperation from any other relays in the system.
However, this approach requires some incubation time to mature.
That being said, clients can speedup the bootstrapping process by
randomly browsing a small number of nonsensitive web sites or re-
playing some nonsensitive browsing history. The client could probe
circuits periodically if needed and can also share reputation score
70(a)
(b)
(c)
Figure 8: (a) Comparison of application and network level reliability of Tor relays. (b) Distribution of the ratio of total failure to success across different time intervals (c) Distribution
of reliability against both observed and advertised bandwidth. We see that there is a signiﬁcant difference between application level and network level availability.
with friends that they trust to speedup the convergence. Addition-
ally, a client can initially concentrate on proﬁling higher bandwidth
Tor relays before proﬁling other relays. For example, about 500 re-
lays provide 80% of the available bandwidth in Tor [9].
7.2 Centralized Approach
In this approach the reputation model is run by the Tor direc-
tory authorities (DA servers). Tor authority servers already gather
statistics of Tor relays (mainly observed bandwidth) to build a con-
sensus database [5]. Each DA server can probe Tor circuits peri-
odically and build its own reputation table. DAs can then include
this information when they participate in the consensus protocol.
The beneﬁt of this approach is that it requires very few modiﬁca-
tions to the existing protocol and the overhead of this approach is
minimal. However, centralized probes need to be indistinguishable
from real user trafﬁc, otherwise malicious relays may alter their be-
havior during periods when they are probed. Randomizing both the
entry relay of a probe and the time at which probes are made can
make it harder for compromised relays to distinguish probes from
actual user trafﬁc.
7.3 Convergence of Re3
For any system to be practically deployable it must converge
quickly to its stable state. In this section we investigate how the
number of interactions affect the accuracy of Re3. For this pur-
pose, we run our simulator where a client iteratively creates circuits
following the default Tor path selection algorithm and then applies
our ﬁltering scheme. We then compute the probability of selecting
a compromised circuit after every 10 interactions. We vary drop
rate d (0 ≤ d ≤ 1) and consider the maximum probability that
an adversary can achieve. Results are averaged over 100 000 runs.
Figure 9 shows the probability of selecting compromised circuits
after every 10 interactions. We can see that as the number of in-
teractions increases this probability dies down. This is expected
because the more a client interacts with relays the more he/she
becomes conﬁdent about those relays’ reliability. However, we
see that this probability quickly descends to a stable value after
≈200 interactions. We also look at the distribution of the number
of unique relays against different number of interactions. Figure
10 shows that after 1000 interactions a client can roughly proﬁle
around 600 Tor relays (or 60% of Tor’s bandwidth). Alternatively,
clients can proﬁle higher bandwidth relays ﬁrst. We conclude that
a user does not need to accumulate too much experience to obtain
a consistent view of the reliability of the Tor relays. Therfore, it is
feasible for individual clients to perform their own proﬁling, rather
than relying on an external entity.
Figure 9: Probability of constructing compromised circuits after various number of
interactions. This probability quickly converges to a stable value after only 200 inter-
actions.
Figure 10: Average fraction of Tor bandwidth and Tor relays observed for different
number of interactions.
8. RELATED WORK
Securing anonymity systems against active attacks is relatively a
new research topic. Borisov et al. [16] ﬁrst showed that a selective
DoS attack can have devastating consequences for both high and
low-latency anonymity systems.
More recently, Danner et al. [19] proposed a detection algorithm
for selective DoS attack in Tor. Their algorithm probes each indi-
vidual Tor relay in the network and requires O(n) probes to de-
tect all compromised relays for a network comprising of n par-
ticipants. However, to handle transient network failures they pro-
posed repeating each probe r number of times, so their approach
requires O(nr) probes. So, at best their approach seems suit-
able for a centralized deployment. However, their algorithm as-
sumes that compromised relays exhibit ﬁxed characteristic of al-
 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 500 1000 1500 2000 2500ReliabilityTor node (sorted by reliability)Application levelNetwork level 0 0.05 0.1 0.15 0.2 0.2500:0500:3501:0501:3502:0502:3503:0503:3504:0504:3505:0505:3506:0506:3507:0507:3508:0508:3509:0509:3510:0510:3511:0511:3512:0512:3513:0513:3514:0514:3515:0515:3516:0516:3517:0517:3518:0518:3519:0519:3520:0520:3521:0521:3522:05Total # of failure/Total # of successTimeApplication levelNetwork level 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 1000 10000 100000 1e+06 1e+07 1e+08 1e+09 1e+10ReliabilityTor nodes (sorted by Bandwidth Bps)Observed BWAdvertised BW 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 200 400 600 800 1000Pr(CXC)InteractionsFor, g=1/3For, g=2/3 0 100 200 300 400 500 600 0 200 400 600 800 1000# of nodes observed# of Interactions 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 200 400 600 800 1000Fraction of BW observed# of Interactions71ways dropping non-compromised circuits. They do not consider
complex attack strategies where compromised relays may perform
random dropping. Such dynamic malicious behavior could poten-
tially increase the number of probes required to successfully iden-
tify compromised relays.
Mike Perry proposed a client-side accounting mechanism that
tracks the circuit failure rate for each of the client’s guards [7]. The
goal is to avoid malicious guard relays that deliberately fail circuits
extending to non-colluding exit relays. However, proﬁling only
guards is not enough because it is less likely that an attacker will
launch selective DoS at guard position, only to sacriﬁce the cost
of obtaining a guard status (guards fulﬁll strong commitments like
minimum bandwidth and minimum uptime). Rather deploying a
moderate number of cheap middle-only relays can boost the effect
of selective DoS attack [14].
Researchers have also leveraged incentive schemes [12, 40] to
encourage good behavior from Tor relays. All incentive schemes
basically encourage participants to be cooperative by providing the
cooperating participants with something that they care about; how-
ever, incentive schemes do not enforce malicious participants to
behave properly.
There are reputation based routing protocols for wireless adhoc
networks [17, 31, 34] that try to identify selﬁsh/malicious routers
with the objective of avoiding them during forward path setup.
While these protocols have similar goal as ours there are differ-
ent challenges in directly using them for anonymity systems. For
example, in all of these protocols routers maintain reputation infor-
mation about their neighbors which they share with other routers in
the network. This information sharing could potentially introduce
new attack vectors where an adversary could ﬁgure out which re-
lays certain users are using. Moreover, to the best of our knowledge
none of these protocols handle strategic malicious behavior.
There are many papers on reputation systems for P2P networks
[28,43,44]. TrustGuard [38] proposes a reputation framework which
is capable of handling strategic malicious behavior. But TrustGuard
is vulnerable to whitewashing attack, we introduce a conﬁdence
metric to hinder whitewashing attack. Moreover, most models fo-
cus on building distributed reputation systems, rather than worrying
about privacy and anonymity as described br Resnick et al. [36].
Dingledine et al. [20] described a reputation system for MIX-net
environment [18]. But their approach relies on trusted witnesses
which are hard to ﬁnd in Tor network. Later on Dingledine et
al. [23] restructured their initially proposed reputation system [20]
to avoid trusted witnesses and proofs in favor of self-rating groups
of remailers. However, their approach does not reduce or prevent
the creeping death attack. They only propose to randomize the
choice of node selection hoping that compromised nodes occupy-
ing the top positions in the reputation spectrum are not selected. In
our case we propose a ﬁltering scheme based on reputation score
to discard such compromised relays, where the reputation metric
itself can handle strategic oscialltions.
9. LIMITATIONS
Our work has a few limitations. First, in the absence of attacks,
a small fraction of honest relays are classiﬁed as outliers due to
random network failures. For anonymity systems, it is much more
critical to blacklist malicious relays than to ensure that all honest
relays are included. Moreover, these discarded honest relays should
reﬂect either low performing or highly congested relays in absence
of attack. Thus, discarding them might actually help in shufﬂing
the overall network load. Second, for the local deployment ap-
proach, our model does not defend against the scenario where all
of a user’s guard relays are malicious. We note that for 20% of ma-
licious relays, the probability of all three of a user’s guard relays
being malicious is less than 1%. Finally, new users beneﬁt from
our reputation model only after a certain amount of usage.
10. CONCLUSION
Anonymity systems are vulnerable to active attacks like selec-
tive denial-of-service. Such attacks, however, can be detected by
proﬁling relay behavior. We proposed a generic reputation model
that proﬁles relays based on their historical behavior. Our model
takes adaptive malicious behavior into consideration and penalizes
any participant exhibiting such behavior. We theoretically analyze
our system under different attack scenarios, including probabilistic
variants of selective DoS, targeted framing attack and the creeping-
death attack. Our simulation and experimental results on the live
Tor network suggest that our reputation model can effectively ﬁlter
compromised relays mounting active attacks. We also show that
our reputation model provides beneﬁts even outside the context of
active attacks; Tor clients using our model experienced signiﬁcant
improvement in the reliability of circuit construction.
Our reputation model has broad applicability, and can be used
in domains such as P2P and recommendation systems, where users
would beneﬁt from proﬁling participants with dynamic behavior.
Acknowledgement
We would like to thank all the anonymous reviewers who have
reviewed our work and have provided us with valuable feedback.