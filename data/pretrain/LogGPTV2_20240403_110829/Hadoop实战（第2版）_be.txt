if（System.getProperty（"test.build.data"）==null）{
System.setProperty（"test.build.data"，"/tmp"）；
}
cluster=new MiniDFSCluster（conf，1，true, null）；
fs=cluster.getFileSystem（）；
OutputStream out=fs.create（new Path（"/dir/file"））；
out.write（"content".getBytes（"UTF-8"））；
out.close（）；
}
@After
public void tearDown（）throws IOException{
if（fs！=null）{fs.close（）；}
if（cluster！=null）{cluster.shutdown（）；}
}
@Test（expected=FileNotFoundException.class）
public void throwsFileNotFoundForNonExistentFile（）throws IOException{
fs.getFileStatus（new Path（"no-such-file"））；
}
@Test
public void fileStatusForFile（）throws IOException{
Path file=new Path（"/dir/file"）；
FileStatus stat=fs.getFileStatus（file）；
assertThat（stat.getPath（）.toUri（）.getPath（），is（"/dir/file"））；
assertThat（stat.isDir（），is（false））；
assertThat（stat.getLen（），is（7L））；
assertThat（stat.getModificationTime（），
is（lessThanOrEqualTo（System.currentTimeMillis（））））；
assertThat（stat.getReplication（），is（（short）1））；
assertThat（stat.getBlockSize（），is（64*1024*1024L））；
assertThat（stat.getOwner（），is（"tom"））；
assertThat（stat.getGroup（），is（"supergroup"））；
assertThat（stat.getPermission（）.toString（），is（"rw-r--r--"））；
}
@Test
public void fileStatusForDirectory（）throws IOException{
Path dir=new Path（"/dir"）；
FileStatus stat=fs.getFileStatus（dir）；
assertThat（stat.getPath（）.toUri（）.getPath（），is（"/dir"））；
assertThat（stat.isDir（），is（true））；
assertThat（stat.getLen（），is（0L））；
assertThat（stat.getModificationTime（），
is（lessThanOrEqualTo（System.currentTimeMillis（））））；
assertThat（stat.getReplication（），is（（short）0））；
assertThat（stat.getBlockSize（），is（0L））；
assertThat（stat.getOwner（），is（"tom"））；
assertThat（stat.getGroup（），is（"supergroup"））；
assertThat（stat.getPermission（）.toString（），is（"rwxr-xr-x"））；
}
}
如果文件或者目录不存在，就会抛出FileNotFoundException异常；如果只对文件或目录是否存在感兴趣，那么用exists（）方法更方便：
public boolean exists（Path f）throws IOException
2.列出目录文件信息
查找文件或者目录信息很有用，但是，有时需要列出目录的内容，这需要使用lis-tStatus（）方法，代码如下：
public FileStatus[]listStatus（Path f）throws IOException
public FileStatus[]listStatus（Path f, PathFilter filter）throws IOException
public FileStatus[]listStatus（Path[]files）throws IOException
public FileStatus[]listStatus（Path[]files, PathFilter filter）throws IOException
当传入参数是一个文件时，它会简单地返回长度为1的FileStatus对象的一个数组。当传入参数为一个目录时，它会返回0个或多个FileStatus对象，代表该目录所包含的文件和子目录。
我们看到listStatus（）有很多重载方法，可以使用PathFilter来限制匹配的文件和目录。如果把路径数组作为参数来调用listStatus（）方法，其结果与一次对多个目录进行查询、再将FileStatus对象数组收集到一个单一的数组的结果是相同的。当然我们可以感受到，前者更为方便。例9-6是一个简单的示范。
例9-6：显示Hadoop文件系统中的一个目录的文件信息
package cn.edn.ruc.cloudcomputing.book.chapter09；
import java.util.*；
import org.apache.hadoop.fs.FSDataInputStream；
import org.apache.hadoop.fs.FileStatus；
import org.apache.hadoop.fs.FileUtil；
import org.apache.hadoop.fs.Path；
import org.apache.hadoop.fs.FileSystem；
public class ListStatus{
public static void main（String[]args）throws Exception{
String uri=args[0]；
Configuration conf=new Configuration（）；
FileSystem fs=FileSystem.get（URI.create（uri），conf）；
Path[]paths=new Path[args.length]；
for（int i=0；i＜paths.length；i++）{
paths[i]=new Path（args[i]）；
}
FileStatus[]status=fs.listStatus（paths）；
Path[]listedPaths=FileUtil.stat2Paths（status）；
for（Path p：listedPaths）{
System.out.println（p）；
}
}
}
配置应用参数可以查看文件系统的目录，可以查看HDFS中对应文件目录下的文件信息。
3.通过通配符实现目录筛选
有时候我们需要批量处理文件，比如处理日志文件，这时可能要求MapRedece任务分析一个月的文件。这些文件包含在大量目录中，这就要求我们进行一个通配符操作，并使用通配符核对多个文件。Hadoop为通配符提供了两个方法，可以在FileSystem中找到：
public FileStatus[]globStatus（Path pathPattern）throws IOException
public FileStatus[]globStatus（Path pathPattern, PathFilter filter）throws IOException
globStatus（）返回了其路径匹配所提供的FileStatus对象数组，再按路径进行排序，其中可选的PathFilter命令可以进一步限定匹配。
表9-2是Hadoop支持的一系列通配符。
下面通过例子进行详细说明，假设一个日志文件的存储目录是分层组织的，其中目录格式为年/月/日：/2009/12/30、/2009/12/31、/2010/01/01、/2010/01/02。表9-3是通配符的部分样例。
4.PathFilter对象
使用通配符有时也不一定能够精确地定位到要访问的文件集合，比如排除一个特定的文件，这时可以使用FileSystem中的listStatus（）和globStatus（）方法提供可选的PathFileter对象来通过编程的办法控制匹配结果，如下面的代码所示。
package org.apache.hadoop.fs；
public interface PathFilter{
boolean accept（Path path）；
}
下面来看一个PathFilter的应用，如例9-7所示。
例9-7：使用PathFilter排除匹配正则表达式的目录
public class RegexExcludePathFilter implements PathFilter{
private final String regex；
public RegexExcludePathFilter（String regex）{
this.regex=regex；
}
public boolean accept（Path path）{
return！path.toString（）.matches（regex）；
}
}
这个过滤器将留下与正则表达式不匹配的文件。
9.6 HDFS中的读写数据流
在本节中，我们将对HDFS的读/写数据流进行详细介绍，以帮助大家理解HDFS具体是如何工作的。
 9.6.1 文件的读取
本节将详细介绍在执行读取操作时客户端和HDFS交互过程的实现，以及NameNode和各DataNode之间的数据流是什么。下面将围绕图9-2进行具体讲解。
图 9-2 客户端从HDFS中读取数据
首先，客户端通过调用FileSystem对象中的open（）函数来读取它需要的数据。FlieSystem是HDFS中DistributedFileSystem的一个实例（参见图9-2第1步）。DistributedFileSystem会通过RPC协议调用NameNode来确定请求文件块所在的位置。这里需要注意的是，NameNode只会返回所调用文件中开始的几个块而不是全部返回（参见图9-2第2步）。对于每个返回的块，都包含块所在的DataNode地址。随后，这些返回的DataNode会按照Hadoop定义的集群拓扑结构得出客户端的距离，然后再进行排序。如果客户端本身就是一个DataNode，那么它将从本地读取文件。
其次，DistributedFileSystem会向客户端返回一个支持文件定位的输入流对象FSDataInput-Stream，用于给客户端读取数据。FSDataInputStream包含一个DFSInputStream对象，这个对象用来管理DataNode和NameNode之间的I/O。
当以上步骤完成时，客户端便会在这个输入流之上调用read（）函数（参见图9-2第3步）。DFSInputStream对象中包含文件开始部分数据块所在的DataNode地址，首先它会连接包含文件第一个块最近的DataNode。随后，在数据流中重复调用read（）函数，直到这个块全部读完为止（参见图9-2第4步）。当最后一个块读取完毕时，DFSInputStream会关闭连接，并查找存储下一个数据块距离客户端最近的DataNode（参见图9-2第5步）。以上这些步骤对客户端来说都是透明的。
客户端按照DFSInpuStream打开和DataNode连接返回的数据流的顺序读取该块，它也会调用NameNode来检索下一组块所在的DataNode的位置信息。当完成所有文件的读取时，客户端则会在FSDataInputStream中调用close（）函数（参见图9-2第6步）。
当然，HDFS会考虑在读取中节点出现故障的情况。目前HDFS是这样处理的：如果客户端和所连接的DataNode在读取时出现故障，那么它就会去尝试连接存储这个块的下一个最近的DataNode，同时它会记录这个节点的故障，这样它就不会再去尝试连接和读取块。客户端还会验证从DataNode传送过来的数据校验和。如果发现一个损坏的块，那么客户端将会再尝试从别的DataNode读取数据块，向NameNode报告这个信息，NameNode也会更新保存的文件信息。
这里要关注的一个设计要点是，客户端通过NameNode引导获取最合适的DataNode地址，然后直接连接DataNode读取数据。这种设计的好处在于，可以使HDFS扩展到更大规模的客户端并行处理，这是因为数据的流动是在所有DataNode之间分散进行的；同时NameNode的压力也变小了，使得NameNode只用提供请求块所在的位置信息就可以了，而不用通过它提供数据，这样就避免了NameNode随着客户端数量的增长而成为系统瓶颈。
9.6.2 文件的写入
本小节将对HDFS中文件的写入过程进行详细介绍。图9-3就是在HDFS中写入一个新文件的数据流图。
第一，客户端通过调用DistributedFileSystem对象中的creat（）函数创建一个文件（参见图9-3）。DistributedFileSystem通过RPC调用在NameNode的文件系统命名空间中创建一个新文件，此时还没有相关的DataNode与之关联。
第二，NameNode会通过多种验证保证新的文件不存在文件系统中，并且确保请求客户端拥有创建文件的权限。当所有验证通过时，NameNode会创建一个新文件的记录，如果创建失败，则抛出一个IOException异常；如果成功，则DistributedFileSystem返回一个FSDataOutputStream给客户端用来写入数据。这里FSDataOutputStream和读取数据时的FSDataInputStream一样都包含一个数据流对象DFSOutputStream，客户端将使用它来处理和DataNode及NameNode之间的通信。
第三，当客户端写入数据时，DFSOutputStream会将文件分割成包，然后放入一个内部队列，我们称为“数据队列”。DataStreamer会将这些小的文件包放入数据流中，DataStreamer的作用是请求NameNode为新的文件包分配合适的DataNode存放副本。返回的DataNode列表形成一个“管道”，假设这里的副本数是3，那么这个管道中就会有3个DataNode。DataStreamer将文件包以流的方式传送给队列中的第一个DataNode。第一个DataNode会存储这个包，然后将它推送到第二个DataNode中，随后照这样进行，直到管道中的最后一个DataNode。
图 9-3 客户端在HDFS中写入数据
第四，DFSOutputStream同时也会保存一个包的内部队列，用来等待管道中的DataNode返回确认信息，这个队列被称为确认队列（ack queue）。只有当所有管道中的DataNode都返回了写入成功的返回信息文件包，才会从确认队列中删除。
当然HDFS会考虑写入失败的情况，当数据写入节点失败时，HDFS会做出以下反应。首先管道会被关闭，任何在确认通知队列中的文件包都会被添加到数据队列的前端，这样管道中失败的DataNode都不会丢失数据。当前存放于正常工作DataNode之上的文件块会被赋予一个新的身份，并且和NameNode进行关联，这样，如果失败的DataNode过段时间从故障中恢复出来，其中的部分数据块就会被删除。然后管道会把失败的DataNode删除，文件会继续被写到管道中的另外两个DataNode中。最后NameNode会注意到现在的文件块副本数没有达到配置属性要求，会在另外的DataNode上重新安排创建一个副本。随后的文件会正常执行写入操作。
当然，在文件块写入期间，多个DataNode同时出现故障的可能性存在，但是很小。只要dfs.replication.min的属性值（默认为1）成功写入，这个文件块就会被异步复制到集群的其他DataNode中，直到满足dfs.replication属性值（默认为3）。
客户端成功完成数据写入的操作后，就会调用6种close（）函数关闭数据流（参见图9-3第6步）。这步操作会在连接NameNode确认文件写入完全之前将所有剩下的文件包放入DataNode管道，等待通知确认信息。NameNode会知道哪些块组成一个文件（通过DataStreamer获得块位置信息），这样NameNode只要在返回成功标志前等待块被最小量（dfs.replication.min）复制即可。
9.6.3 一致性模型
文件系统的一致性模型描述了文件读/写的可见性。HDFS牺牲了一些POSIX的需求来补偿性能，所以有些操作可能会和传统的文件系统不同。
当创建一个文件时，它在文件系统的命名空间中是可见的，代码如下：
Path p=new Path（"p"）；
fs.create（p）；
assertThat（fs.exists（p），is（true））；
但是对这个文件的任何写操作不保证是可见的，即使在数据流已经刷新的情况下，文件的长度很长时间也会显示为0：
Path p=new Path（"p"）；
OutputStream out=fs.create（p）；
out.write（"content".getBytes（"UTF-8"））；
out.flush（）；
assertThat（fs.getFileStatus（p）.getLen（），is（0L））；
一旦一个数据块写入成功，大家提出新的请求就可以看到这个块，而对当前写入的块，大家是看不见的。HDFS提供了所有缓存和DataNode之间的数据强制同步的方法，这个方法是FSDataOutputStream中的sync（）函数。当sync（）函数返回成功时，HDFS就可以保证此时写入的文件数据是一致的并且对于所有新的用户都是可见的。即使HDFS客户端之间发生冲突，也不会发生数据丢失，代码如下：
Path p=new Path（"p"）；