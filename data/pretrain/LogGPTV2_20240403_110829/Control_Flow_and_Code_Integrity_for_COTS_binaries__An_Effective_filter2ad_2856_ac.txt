• No changes, or make read-only: This policy is applied
to original code (OC), new code and data (CD), memory-
mapped data used by CFCI (G), and virtual DSO (VDSO
— used to support fast system calls).
• Cannot make executable: This policy applies to original
data (OD) (unless JIT is enabled — see Section 3.6), and
empty space (ES).
• One-time writable: Original code with text relocation
(OCT) and relro data (RO) can be writable (but not ex-
ecutable). However, once it is writable, it can only be
changed back to read-only (non-executable).
3.3.1 Compatibility with Code Patching
There are legitimate reasons to modify code after it is
loaded, e.g., text relocation. Text relocation allows pro-
grams to run in any memory location by updating the code
pointers at runtime. This code patching does not violate
our policy since only (non-executable) original code will be
patched. In order to execute correctly, the transformed code
needs to make use of this patched-up constant value. This
is accomplished as shown in Figure 3. Suppose that the
original code moves a constant to the eax register, and this
constant is ﬁxed up during the text relocation phase. The
95
Original Code:
mov $const, %eax
... ...
Transformed Code:
call _next
_next: pop %eax
add $offset, %eax
mov (%eax), %eax
Figure 3: Patching for Text Relocation
transformed code retrieves this constant value using PC-
relative addressing. Speciﬁcally, it ﬁrst uses that call/pop
sequence to retrieve the PC-value into eax. Then it adds an
oﬀset that captures the distance between the original and
transformed versions of the instruction being transformed.
Note that now, eax will point to the location of the patched-
up constant value. The last step in the transformed code is
to load the contents of this location into eax.
Using the above transformation, transformed code with
text relocation could be correctly executed. Note that our
transformation defeats the primary objective of text reloca-
tion, namely, avoiding the overhead of PIC code. We accept
this as a reasonable trade-oﬀ for achieving compatibility, es-
pecially because text relocations not frequently used.
3.4 Library Loading Policy
Library loading policy ensures that each executable can
only load a set of dependent libraries. For some high-proﬁle
applications, identifying the speciﬁc set of libraries may be
well worth the eﬀort. Tools such as ldd can be eﬀective for
statically enumerating the library set, especially for command-
line applications. For many other applications, however, this
strict policy can impact usability:
• Identifying the set of all required libraries can be diﬃ-
cult, both due to the large number of libraries loaded by
many applications, and because this list can vary across
localities and conﬁgurations.
• Tasks such as debugging require alternative libraries to
be loaded.
To address these, we permit a more relaxed policy that al-
lows libraries to be loaded from a speciﬁed set of directories.
To support tasks such as debugging, it is often necessary
to use environmental variables such as LD_LIBRARY_PATH and
LD_PRELOAD to change the loading path or add additional
dependencies. Our policy is ﬂexible enough to handle these
needs, since diﬀerent policies can be applied to the same
application run by diﬀerent users and/or in diﬀerent running
environments.
In particular, LD_LIBRARY_PATH and LD_PRELOAD values
will be checked by our specially designed library (details in
Section 4) at load time, and unauthorized values that violate
library loading policy will be rejected.
3.5 Protected Memory
Among SFI approaches [37, 60, 62, 30], the most eﬃcient
one for our platform (32-bit x86) relies on segmentation.
Segmentation is also available for 32-bit applications on 64-
bit x86 processors, and is the option currenly used by NaCl.
CFCI SFI design is similar to vx32 [30]. At the time of
loading an executable, CFCI reserves a region of memory
to be protected by segmentation. Speciﬁcally, we set aside
the top few MBs of the lower 3GB of address space for SFI
protection. This means that the base address of segments
such as ds, es and ss will be 0, and the limit will be some-
thing like 0xbfbfffff. Using a base address of zero provides
maximum compatibility with existing code, as it avoids any
need to adjust pointers in memory, or when passing data to
the kernel.
By default, the OS maps the program stack at a high ad-
dress, and often, this may overlap with the region we want to
set aside. To resolve this conﬂict, CFCI relocates the stack
at process startup time, and then sets aside the high mem-
ory region for SFI protection. Next, CFCI initializes the
segments. Note that segment descriptors are maintained in
two tables in kernel space, LDT and GDT. Our implemen-
tation uses index 7 in GDT, which is currently unused, to
set up protected thread-local storage that can be used by
instrumentation, and index 8 to access unprotected mem-
ory. A system call policy is put in place to prevent further
modiﬁcations to these entries.
For 64-bit applications on the x86-64 architecture, we use
randomization to realize protected memory. CFCI ensures
that protected memory accesses could only be done through
5
with oﬀset. Since segment
the unused TLS register (%gs)
base address is stored in kernel, memory leaks can’t be used
to reveal the location of protected memory, thus strength-
ening our randomization based defense.
3.6 Support for Dynamic Code
Runtime changes to code may take place either due to the
loading/unloading of libraries, or due to the use of just-in-
time (JIT) compilation. The design described so far already
supports the ﬁrst case of dynamic code. The second case,
namely JIT code, poses some diﬃculties, and we explain
below how compatibility with JIT can be obtained.
For best performance, many existing JIT compilers gener-
ate executable binary code in writable memory. This enables
code to be updated very quickly. However, such an approach
is inherently insecure under the threat model we consider, as
an attacker that can corrupt memory can simply overwrite
this code with her own code. For this reason, use of such
JIT compilers is not advisable in this threat environment.
Nevertheless, if compatibility with such JIT environment is
desired, it can be supported by CFCI. Naturally, code pages
generated by such a JIT compiler cannot be protected from
modiﬁcations, but our design can continue to oﬀer full pro-
tection for the rest of the code. This is achieved by marking
JIT code region in a table and transforming JIT code at run-
time. All control ﬂows targeting JIT code will be redirected
to its corresponding instrumented code where all indirect
control transfers in JIT code will be checked.
A more secure approach for JIT support is one that avoids
the use of writable code pages. Recent research work [55]
have proposed a practical and eﬃcient JIT code genera-
tion approach that eliminates writable code pages. This is
achieved by sharing the memory that holds JIT code across
two distinct address spaces (i.e., processes). Code genera-
tion happens in one of these address spaces, called software
dynamic translator (SDT), where the page remains writable
but not executable. JIT code execution happens in the sec-
ond address space, regarded as an untrusted process, where
the page is just readable and executable.
CFCI is compatible with this secure JIT code generator
design as well. Each time new code is generated in the SDT
process, it is instrumented by CFCI.
5In x86-64, %gs register is not used by the glibc
JIT code tends to change frequently, and the changes are
typically small and localized. To obtain full beneﬁts of JIT
code, instrumentation needs to be performed in an incre-
mental fashion. This requires some ﬁne-tuning in the SDT
to ensure that CFCI works correctly. However, since the
source code of secure dynamic code generator [55] is not
available, we have not pursued this incremental design yet.
4.
IMPLEMENTATION
The state model and library loading policy are imple-
mented using code instrumentation on the dynamic loader
(ld.so). We have instrumented code logic in ld.so that is
used for code loading.
In addition, we have instrumented
all the system calls that are located in ld.so, libc.so and
libpthread.so. All the checks added by instrumentation
will redirect control to a specially designed library loaded
ahead of time. To ensure this library is loaded ahead of
all other dependent libraries, we use the environment vari-
able LD_PRELOAD. Note that this library is independent of
any modules including even the loader or libc. This ensures
that the state model, library loading policy and system call
monitor will work immediately when the library is loaded.
To protect the special library from control ﬂow and data
attacks, our design marks the entries in memory map table
that corresponds to location of the special library as empty.
Thus any subverted code pointers targeting the library will
crash the program once used. To further protect our library
from data attacks, our checks only use protected memory
mentioned in Section 3.5. Finally, our special library uses
its own stack in protected memory.
5. EVALUATION
We implemented our system CFCI on top of an open
source CFI tool, PSI [64]. Our test environment is Ubuntu
12.04 LTS 32bit, with Intel i5 CPU and 4GB memory.
5.1 CPU Intensive Benchmark
Since CFCI does not introduce signiﬁcant additional op-
erations at runtime, one would expect that it does not intro-
duce signiﬁcant overhead. Speciﬁcally, the only additional
overhead of CFCI is due to policies on operations for mem-
ory mapping or protection, and ﬁle-related operations such
as open, close and read. Since these operations are relatively
infrequent in comparison with the number of instructions
executed, and since the policy checks themselves are quite
simple, we would expect the overhead to be small.
To validate this assessment, we evaluated CFCI with SPEC
2006 (Figure 4) using the reference dataset. The overall
overhead of CFCI we observed is 14.37%, which is an addi-
tion of just 0.17% over that of our base platform PSI.
Note that PSI has a higher overhead than its initial system
BinCFI. This is because PSI disables some optimizations in
BinCFI such as “violating transparency” and proﬁle-based
optimization (AT.3).
5.2 Micro-benchmark for Program Loading
Runtime overheads arise chieﬂy from the following: (1)
larger size of instrumented binaries, (2) checks performed in
the context of the state model, and (3) checking of library
loading policies. Almost all of these overheads occur at the
time of loading a library, so we focus on load-time overhead
in this experiment. We wrote a small program that loads
a number of randomly chosen libraries. We measured the
runtime needed to load the original version and compared
96
Attack
ROP-CVE-2014-1776
ROP-CVE-2014-1761
ROP-CVE-2014-0497
ROP-CVE-2012-1875
CVE-2013-3906
CVE-2013-0977
CVE-2014-1273
CVE-2010-3847
CVE-2010-3856
CVE-2011-1658
CVE-2011-0570
ROP-CVE-2013-3906
PoC: attack-lder-1
PoC: attack-lder-2
PoC: attack-lder-3
Detail
alloc executable area and jump
launch malicious executable
change page permission, download exe and launch it
make heap executable
alloc executable data and jump
Type
direct
direct
direct
direct
direct
ldr.data malformed binary with overlapping segments
ldr.data malformed binary with text relocation
ldr.data
ldr.data
ldr.data
ldr.data Untrusted search path vulnerability in Adobe Reader
ldr.cr
ldr.cr
ldr.cr
ldr.cr
library hijacking using $ORIGIN in LD AUDIT
library hijacking on LD AUDIT
library hijacking using $ORIGIN in RPATH
load malicious library
code injection via corrupted reloc table and sym table
code injection via making stack executable
loading malicious library by calling d lopen
Blocked? Reason of Rejection
Y
Y
Y
Y
Y
Y
Y
Y
Y
Y
Y
Y
Y
Y
Y
syscall policy
syscall policy
syscall policy
syscall policy