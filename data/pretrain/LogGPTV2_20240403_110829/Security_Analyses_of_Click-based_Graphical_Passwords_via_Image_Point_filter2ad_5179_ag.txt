[14] Chiasson, S., Forget, A., Biddle, R., and van Oorschot, P. C. 
2009. User interface design affects security: Patterns in click-
based graphical passwords. Int. Journal of Information 
Security. Springer, 8, 6 (2009), 387-398. 
[15] van Oorschot, P. C., and Thorpe, J. 2011. Exploiting 
predictability in click-based graphical passwords. Journal of 
Computer Security. 19, 4 (2011), 669-702. 
[16] Thorpe, J., and van Oorschot, P. C. 2007. Human-seeded 
attacks and exploiting hot-spots in graphical passwords. In 
USENIX Security’07. 
[17] Salehi-Abari, A., Thorpe, J., and van Oorschot, P. C. 2008. 
On purely automated attacks and click-based graphical 
passwords. In Proc. 24th Annual Computer Security 
Applications Conference (ACSAC’08). 
[18] van Oorschot, P. C., Salehi-Abari, A., and Thorpe, J. 2010. 
Purely automated attacks on PassPoints-style graphical 
passwords. IEEE Trans. Information Forensics and Security. 
5, 3 (2010), 393-405.  
[19] Chiasson, S., van Oorschot, P. C., and Biddle, R. 2007. 
Graphical password authentication using cued click points. In 
ESORICS’2007. LNCS, vol. 4734/2007, 359–374. 
[20] Juels, A. and Rivest, R. L. 2013. Honeywords: Making 
password-cracking detectable. In ACS CCS 2013. 
[21] Jermyn, I., Mayer, A., Monrose, F., Reiter, M., and Rubin. A. 
1999. The design and analysis of graphical passwords. In 8th 
USENIX Security 1999. 
[22] Blonder, G. 1996. Graphical Passwords. United States 
Patent 5559961.  
[23] Monrose, F. and Reiter, M. K. 2005. Graphical passwords. 
Security and Usability. L. Cranor and S. Garfinkel, editors. 
O’Reilly, Chapter 9, 147–164. 
1229[24] Biddle, R., Chiasson, S., and van Oorschot, P. C. 2012. 
Graphical passwords: Learning from the first twelve years. 
ACM Computing Surveys. 44, 4, Article 19, 1-41. 
[25] B. B. Zhu, D. Wei, M. Yang, and J. Yan. 2013. Security 
implications of password discretization for click-based 
graphical passwords. In WWW 2013. 
[26] Khosla, A., Xiao, J., Torralba, A., and Oliva, A. 2012. 
Memorability of image regions. In Advances in Neural 
Information Processing Systems, 305-313. 
[27] Judd, T., Ehinger, K. A., Durand, F., Torralba, A. 2009. 
Learning to predict where humans look. In Int. Conf. on 
Computer Vision (ICCV’09). 2106-2113. 
[28] Ling, H., and Okada, K. 2006. Diffusion distance for 
histogram comparison. In IEEE. Computer Vision and 
Pattern Recognition (CVPR’06). 1, 246-253. 
[29] Goldberg, A. V., and Radzik T. 1993. A heuristic 
improvement of the Bellman-Form algorithm. Applied 
Mathematics Letters. 6, 3, 3-6.  
[30] Birget, J. C., Hong, D., and Memon, N. 2006. Graphical 
passwords based on robust discretization. IEEE Trans. 
Information Forensics and Security. 1, 3 (2006), 395-399.  
[31] Chiasson, S., Srinivasan, J., Biddle, R., and van Oorschot, P. 
C. 2008. Centered discretization with application to graphical 
passwords. In Proc. 1st Conf. on Usability, Psychology, and 
Security (UPSEC’08).  
[32] Bonneau. J. 2012. The science of guessing: Analyzing an 
anonymized corpus of 70 million passwords. In IEEE Symp. 
on Security and Privacy. 
[33] Mazurek, M.L., Komanduri, S., Vidas, T., Bauer, L., 
Christin, C. Cranor, L.F., Kelley, P.G., Shay, R., and Ur, B. 
2013. Measuring password guessability for an entire 
university. In ACM CCS’13. 173-186. 
11.  APPENDIX 
11.1  Representative Attack Results 
For easy comparison, Table 4 summarizes representative results of 
all prior attacks on click-based graphical passwords, together with 
the results of our attacks on PCCP presented in this paper. The first 
two  columns  list  attack  methods  and  their  targeted  graphical 
password  schemes,  respectively.  The  next  three  columns  list 
success rates they achieved, sizes of their attack dictionaries and of 
their theoretical password spaces, respectively.  
Table 4: Attacks and representative results  
Success 
Dictionary 
Theoretical 
Attack 
Method 
Automated 
[13] 
Automated 
[16] 
Automated 
[17] 
Automated 
[18] 
PassPoints 
Human-seeded
[15,16] 
Our automated PCCP 
Scheme 
PassPoints 
rate 
(%) 
8.45 
61* 
space 
(bits) 
40 
43 
size 
(bits) 
31.6 
24.8* 
35 
24.6 
31.4 
26 
35 
31 to 33 
6-7 
35 
32 
0.9 – 9.1 
8-15 
16 
7-16 
48-54 
20 to 36 
4 to 10 
45.83 
5.21 
Our human-
assisted 
55.21 
2.08 
35 
25 
*This  result  was  obtained  with  image  Bird  shown  in  Figure  4, 
which is much simpler than the images used in other studies. 
11.2  Distinguishability via Color Dissimilarity  
11.2.1  Color Dissimilarity of Two Regions 
Dissimilarity  of  two  regions  can  be  compared  by  their  color 
distributions, i.e., histograms. Ling et al. [28] proposed a metric to 
measure  dissimilarity  between  two  histograms  by  applying  a 
diffusion process to the difference of two histograms. By modeling 
this  diffusion  approach,  we  define  a  metric  4O  to  measure 
dissimilarity  of  regions  P  and  Q  of  size  + × +  for  one  color 
component: 
4O(P, Q) = minV ∑ |P(-, Y) − QZ[(-, Y)\|
(,]
,      (3) 
where  [  is  a  one-to-one  mapping  function  between  pixels  in 
regions P and Q.  
The problem to find the optimal [ in Eq. (3) can be converted to a 
minimum-cost  maximum-flow  problem  as  follows:  a  directed 
graph ^ comprises 2 + 2+7 nodes, i.e., a source _, a sink ‘, and one 
node per pixel in two regions. There is an arrow from source _ to 
each  node  in P and  an  arrow  from  each  node  in Q to  sink ‘,  each 
arrow  has  capacity  1  and  cost  0.  For  each  node  in P,  there  is  an 
arrow from the node to every node in Q, with capacity 1 and cost 
equal to the absolute difference  of their pixel values. In addition, 
for each aforementioned arrow, there is a reverse arrow pointing to 
the opposite direction with capacity 0 and cost being the opposite 
(i.e., negative) of the aforementioned arrow’s cost.  
A method to solve the min-cost max-flow problem is a heuristically 
improved Bellman-Form algorithm [29]. The set of edges from A’s 
node  to  B’s  node  without  any  residual  capacity  in  the  optimal 
solution defines an optimal one-to-one mapping function [ for Eq. 
(3), which is then used to calculate 4O(P, Q) with Eq. (3). 
We use Lab and Luv, two different color spaces, to calculate region 
dissimilarity,  in  hope  that  dissimilarity  manifests  in  at  least  one 
color  component.  The  Euclidean  distance  of  five  dissimilarity 
values each calculated in one of the five color components: L, a, b, 
u, v. is used as a metric of color dissimilarity of the two regions. 
11.2.2  M-Index by Color Dissimilarity 
To calculate color dissimilarity of a detectable point 0, we apply a 
sliding window aO of size n × n to move around 0, with its center 
being inside or on the boundary of a neighboring region ℕc of size 
(2(cid:24) + 1) × (2(cid:24) + 1) centered  at 0,  starting  at (−N, −N) relative 
to 0 and with a moving step of Δ pixels along either direction. At 
each  stop,  unless aO  is  too  close  to 0 ,  we  calculate  the  color 
dissimilarity between aO and the region ac of size n × n centered 
at 0. More specifically, the color dissimilarity between aO and ac 
is  calculated  if  the  center  of aO has  a  Manhattan distance  from 0 
not less than a threshold f% and an Euclidean distance from 0 not 
less  than  another  threshold fg .  Regions  very  close  to ac  are 
excluded  since  the  range  examined  by  dissimilarity  should  be 
significantly  larger  than  that  used  in  corner  detection  wherein 
immediate  neighborhood  is  used.  The  average  of  the  calculated 
dissimilarity  values,  denoted  by h#iii,  is  used  as  a  metric  of  color 
dissimilarity of detectable point 0. 
(cid:12)(cid:13)(cid:14)(cid:15)(cid:14)(cid:16)  in  Eq.  (1)  is  a  step-wise  factor  determined  by  the  color 
dissimilarity of the point: 1) (cid:12)(cid:13)(cid:14)(cid:15)(cid:14)(cid:16) = (cid:12)(cid:6) > 1 to increase M-index 
1230for small dissimilarity: h#iii  h7 ,  whereof  0  is 
considered  likely  distinguishable;  and  3)  (cid:12)(cid:13)(cid:14)(cid:15)(cid:14)(cid:16) = 1 ,  i.e.,  no 
change, for dissimilarity falling between the two cases. 
determine 
aforementioned 
parameters:  we 
In our experiments to be reported, we used an empirical approach 
to 
selected 
representative points on several typical images, and compared their 
relative  orders  given  by  human  labeled  results  (see  Section  4.2) 
with  those  by  M-indices  calculated  with  Eq.  (1)  using  different 
values of the parameters. The set of values that produced best match 
was selected. They were: n = 7, N = 15, Δ = 5, f% = 10, fg =
7, h(cid:6)=240, h7 = 310, (cid:12)(cid:6) = 2, and (cid:12)7 = (cid:6)
√7 ≈ 0.71.  
11.3  Distinguishability via Gradient 
Dissimilarity  
We first calculate gradients of an image. For each detectable point 
0, we use a rectangle k, with its short edge centered at 0, to rotate 
around 0. Starting at 0°, we calculate the average of gradients in k 
per every l degree, resulting in m =  values at m different 
angles around 0.  
Uniformity  of  the  m  values  at  different  angles  indicates  how 
similar  the  point’s  neighborhood  is.  We  use  a  simple  empirical 
metric  to  measure  this  uniformity:  ratio (cid:1) of  the  maximum  to  the 
average  of  the  m  values.  A  large  (cid:1)  means  a  large  change  of 
gradients at different directions around 0.  
(cid:12)(cid:19)(cid:16)(cid:20)(cid:21) in  Eq.  (1)  is  a  step-wise  factor  determined  by  ratio (cid:1) :  1) 
(cid:12)(cid:19)(cid:16)(cid:20)(cid:21) = "(cid:6) ≫ 1 to increase M-index significantly for small (cid:1): (cid:1)  (cid:1)7, 
wherein the point’s neighborhood is very dissimilar, and the point 
is  very  likely  distinguishable,  and  3) (cid:12)(cid:19)(cid:16)(cid:20)(cid:21) = "7 > 1 to  increase 
M-index slightly for (cid:1) between the two cases.  
In our experiments, the above parameters  were determined in the 
same way as those in the color dissimilarity. The following values 
were used: the size of rectangle k was 3 × 15; l = 8°, resulting 
in m = 45; (cid:1)(cid:6) = 1.45, (cid:1)7 = 1.8; "(cid:6) = 10, and "7 = 2.  
11.4  Adjusting M-Index by Click Patterns 
Line is detected by using least-squares to fit 5 points in a word with 
a straight line. If the square root o of the least square error is less 
than  a  preset  threshold op ,  o < op ,  and  the  word’s  sequence 
follows  a  consistent  direction,  the  word  is  determined  to  exhibit 
Line with a confidence level: 
qr = 1 − o/op,    0 ≤ qr ≤ 1, 
(4)  
and its M-index is multiplied by a factor sr ≤ 1 for the automated 
memorability  or  subtracted  by  a  subtrahend  5tr ≥ 0  for  the 
human-assisted memorability, where tr is the subtrahend per point 
in the word. Both sr and tr depend on confidence level qr.  
For  a  sequence  of  points,  one  point  to  the  next  point  forms  a 
directional  line.  Each  pair  of  adjacent  directional  lines  forms  an 
angle.  Regular  is  detected  by  checking  consistency  of  angles  of 
adjacent directional lines in a word. Excluding angles very close to 
0 degree, if the remaining angels are all positive or negative, then 
the  sequence  is  counter  clock-wise  or  clock-wise.  If  they  have 
mixed  signs  but  their  absolute  values  are  all  smaller  than  a 
threshold,  the  sequence  is  roughly  alone  one  direction.  In  both 
cases,  if  the  standard  deviation l of  all  the  angles  is  less  than  a 
preset threshold lp, the word is determined to exhibit Regular with 
a confidence level: 
qu = 1 − l lp⁄ ,    0 ≤ qu ≤ 1, 
(5)  
and its M-index is multiplied by a factor su ≤ 1 for the automated 
memorability  or  by  subtracting 5tu ≥ 0  for  the  human-assisted 
memorability.  Again,  both su and tu depend  on  confidence  level 
qu. 
In our experiments, Line was set twice the effect as Regular at the 
same confidence level. In addition, Regular at confidence level 1 
was set to match multiplication factor (cid:12)7 in Appendix 11.2 for the 
automated  memorability,  and  Line  was  set  to  match  the  adjusted 
range in Section 4.3 per point for the human assisted memorability. 
The parameters were then calculated as: sr = 1 − 0.5qr ∈ [0.5,1] 
and  su = 1 + qu x (cid:6)
√7 , 1] ;  tr = qr ∈ [0, 1]  and  tu =
0.5qu ∈ [0, 0.5].  
√7 − 1y ∈ [ (cid:6)
1231