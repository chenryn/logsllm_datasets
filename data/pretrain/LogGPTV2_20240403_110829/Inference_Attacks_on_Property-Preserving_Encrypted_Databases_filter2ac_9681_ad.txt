where the cost matrix C gives the cost for mapping plaintext
mj to ciphertext ci as the sum of the mismatch in frequencies
plus the mismatch in cumulative frequencies:
Cij =(cid:12)(cid:12)ψi − πj
(cid:12)(cid:12)2 +(cid:12)(cid:12)ϕi − µj
(cid:12)(cid:12)2.
The attack runs in O(|Ck|3) time.
7. SIMULATING A MEDICAL EDB
To evaluate the attacks, we considered the scenario of an
EMR application and its associated database. We chose this
setting for several reasons.
650First, medical DBs hold highly personal and sensitive in-
formation and are often covered by privacy regulations such
as the Health Portability and Accountability Act (HIPAA).
EMRs are vulnerable to insider and outsider threats and
are increasingly targeted by professional attackers includ-
ing state sponsored adversaries and organized crime. This
trend is illustrated by the recent attacks on Anthem—one of
the largest U.S. health insurance providers—which compro-
mised the health records of 80 million individuals. In fact,
the Ponemon Institute’s recent study on Privacy and Secu-
rity of Healthcare Data [1] reports that criminal attacks are
now the number one cause of healthcare data breaches with
a 125% growth in attacks reported in the last 5 years. As
such, the motivation to encrypt medical DBs is very strong.
In fact, medical DBs often appear as the standard moti-
vation in the encrypted database research literature (see,
e.g., [35]).
Another reason we chose this scenario is that a subset of
the data stored in EMRs (e.g., demographic data) is also
held in other types of sensitive DBs including human re-
sources DBs, accounting DBs, and student DBs. Informa-
tion stored in these DBs may also be covered by privacy
regulations such as the Family Educational Rights and Pri-
vacy Act (FERPA). Our results against medical DBs can
therefore tell us something about these other kinds of DBs.
7.1 Target Data
Throughout, we refer to the data we use to populate the
EDB as the target data.
In our experiments we use data
from the National Inpatient Sample (NIS) database of the
Healthcare Cost and Utilization Project (HCUP) [3]. HCUP
makes available the largest collection of longitudinal hospi-
tal care data in the U.S. The NIS database—which includes
data on inpatients (i.e., patients that stay at a hospital for at
least one night) from all the hospital in the U.S.—is avail-
able starting from 1988. The database is made available
to researchers under controlled access: an online training
is required and a data use limitation agreement must be
signed before the data can be purchased and used. The NIS
database includes attributes such as age, drugs, procedures,
diagnosis, length of stay, etc. For our purposes, we only use
a subset of the attributes (mostly due to space limitations)
which we describe in Figure 1.
Large Hospitals
Small Hospitals
Max
121, 664
1, 309
Min Mean
24, 486
12, 975
404
756
SD
12, 015
253
Table 1: Size of hospitals in number of patients
In our experiments we use the data from a subset of 1050
hospitals in the 2009 HCUP/NIS database as our target
data. We note that any other year would have given similar
results. For all but one of our experiments we use the 200
largest hospitals but for the evaluation of the cumulative at-
tack against low-density columns we use data from 200 small
hospitals. The 200 small hospitals are the ones ranked (in
decreasing order) 701 through 900 in terms of patient-size.
Smaller hospitals had too few patients to attack (less than
400 and some even less than 10). The number of patients
in the 200 largest and the 200 small hospitals is shown in
Table 1.
Target attributes. We chose a subset of columns/attributes
from the 2009 HCUP/NIS dataset to attack. These at-
• Sex. Sex can be either male or female. The most prominent
feature of the sex attribute is that most hospitals have more
female patients than male patients. This is possibly due to
pregnancy, births, and the fact that women live longer. Sex is
universally used in all databases that store information about
people.
• Race. Race can have the following values: white, black,
Hispanic, Asian or Paciﬁc Islander, Native American, and
other. Race is stored in most databases dealing with people
for a variety of reasons.
• Age. Age can range from 0 to 124. Age 0 is for babies
less than an year old. Some databases may store birth year
instead of age, e.g., as part of full date of birth. Frequency
counts for age and birth year are exactly the same.
• Admission Month. Admission month has values that range
from January to December.
• Patient died during hospitalization. This attribute in-
dicates whether a patient died during hospitalization.
• Primary Payer. Primary payer has six values: Medicare,
Medicaid, private or health maintenance organization, self-
pay, no charge, and other.
• Length of Stay. Length of stay ranges from 0 to 364 and
represents the number of days a patient spends in a hospital.
It is a very sensitive attribute and reveals information about
other attributes such as the nature of the patient’s disease.
• Mortality Risk. Mortality Risk has four values showing the
likelihood of dying: minor, moderate, major, and extreme. It
indicates the risk of a patient dying in the hospital.
• Disease Severity. Disease Severity has four values showing
loss of function: minor (indicates cases with no comorbidity
or complications), moderate, major, and extreme. It indicates
the severity of the patient’s disease.
• Major Diagnostic Category. Major Diagnostic Category
has 25 values and gives the principal diagnosis such as “Dis-
eases and Disorders of Kidney”, “Burns”, “Human Immunod-
eﬁciency Virus Infection (HIV)”, etc.
• Admission Type. Admission type has six values: emer-
gency, urgent, elective, newborn, trauma center, and other.
• Admission Source. Admission source has ﬁve values: emer-
gency room, another hospital, another facility including long-
term care, court/law enforcement, and routine/birth/other.
It indicates from where the patient was admitted to the hos-
pital.
Figure 1: Attributes/columns used in our evaluation.
tributes are listed in Figure 1. We believe these or similar at-
tributes would be present in most real-world EMR systems.
We conﬁrmed that six of them, including sex, race, age, ad-
mission month, patient died, and primary payer, are used
by OpenEMR [6], which is an open source fully-functional
EMR application. We stress that the form in which these
attributes are stored can vary (e.g., age can be stored as an
integer or computed from a date of birth) but some variant
of these attributes exist in OpenEMR.
To decide whether an attribute should be DTE or OPE-
encrypted we did the following. For the attributes stored
by OpenEMR (in some form), we simply checked the kinds
of operations OpenEMR supported on it.
If it supported
either range queries or sorting operations, we considered it
an OPE attribute. If OpenEMR supported equality queries
on the attribute we considered it a DTE attribute. For the
remaining attributes, we made assumptions which we be-
651lieve to be reasonable. More speciﬁcally, we assumed an
EMR system would support range queries on the length of
stay attribute; sorting queries on the mortality risk, disease
severity, and admission type attributes (e.g., for triage); and
equality queries on major diagnostic category and admission
source.
7.2 Auxiliary Data
All but one of our attacks (sorting) require an auxiliary
dataset to decrypt a PPE-encrypted column. We used the
following two auxiliary datasets:
Texas PUDF data. The ﬁrst auxiliary dataset we use is
the Texas Inpatient Public Use Data File (PUDF), which is
provided by the Texas Department of State Health Services.
This dataset—unlike the HCUP/NIS data—is publicly avail-
able online so there is no reason to believe an adversary
would not use it to her advantage. Speciﬁcally, we use the
2008 Texas PUDF data. The Texas PUDF data until year
2008 can be downloaded from [4]. Usage of the data requires
an acceptance of a data use agreement but we believe it is
reasonable to assume that an adversary would not comply
with such an agreement.
2004 HCUP/NIS. Unfortunately, the Texas PUDF data
has a limited number of attributes which prevents us from
studying the accuracy of our attacks on several attributes
of interest. We therefore also run experiments using the
2004 HCUP/NIS database as auxiliary data (recall that our
target data is the 2009 HCUP/NIS data). Note that each
year of the HCUP/NIS data comes from a random sample
of hospitals from a large number of U.S. hospitals and the
entire data of each sampled hospital is included. This means
that the 2004 HCUP/NIS data is not only diﬀerent in time
from the 2009 HCUP/NIS data but it is also comes from a
diﬀerent set of hospitals. There is a small number of common
hospitals between 2004 and 2009 HCUP/NIS databases (less
than 4%), but that does not have a noticeable impact on our
experimental results.
Remark on additional datasets. Another example of
a publicly-available auxiliary dataset is the Statewide Plan-
ning and Research Cooperative System (SPARCS) Inpatient
data from the state of New York [5]. We do not report re-
sults using SPARCS as auxiliary data due to space limita-
tions, but it gives similar results to those using the Texas
PUDF data.
8. EXPERIMENTAL SETUP
All experiments were conducted on a high-end Mac lap-
top with Intel Core i7 processor and 16GB memory running
OS X Yosemite (v10.10.2). We used Python version 2.7.6
and Matlab version 8.4.0 (R2014b). For our experiments we
developed three tools: Parser, Column Finder, and Revealer
which we now describe.
Parser. Parser is written in Python and parses the tar-
get and auxiliary data to create appropriate histograms. In
the case of the target data, it creates one histogram per at-
tribute/hospital pair. More precisely, for each pair it creates
a histogram that reports the number of times some value v
of the attribute appears in the hospital’s data. In the case
of the auxiliary data, it creates a single histogram for each
attribute (i.e., over all hospitals).
Column Finder. Column Finder is also written in Python.
Since CryptDB-like EDB systems encrypt column names,
an adversary ﬁrst needs to learn which encrypted columns
correspond to the attribute of interest. We do this using
the following approach. First, we determine if the attribute
of interest is present in the EDB by checking the database
schema of the application. Then we run Column Finder
which works as follows:
1. it determines the number of distinct values for the column
of interest in the auxiliary data. We’ll refer to this column
as the auxiliary column. As an example, Column Finder
would use the auxiliary data to learn that age has 125
possible values or that sex has 2 possible values.
2. it then determines the number of distinct values stored
in each DTE- and OPE-encrypted column of the EDB.
This is trivial due to the properties of these encryption
schemes. It then searches through these encrypted columns
to ﬁnd the ones that have approximately the same num-
ber of distinct values as the auxiliary column. We have to
search for approximate matches since some values of an
attribute may not be present in the target data. Since we
know from the database schema of the application that
the EDB contains an encrypted column for the attribute
of interest, this step will ﬁnd at least one column:
(a) If it ﬁnds only one column, then that is the en-
crypted column for the attribute of interest.
(b) If it ﬁnds more than one column with a close-enough
number of distinct values such that it cannot deter-
mine which column belongs to the attribute of in-
terest, then it outputs all of them.
Auxiliary At-
tribute
Primary Payer
Race
Target Attributes
Accuracy
Admission Type, Pri-
mary Payer, Race
Admission Type, Pri-
mary Payer, Race
116
152
Admission Type Admission Type, Pri-
128
Sex
Patient Died
mary Payer, Race
Sex, Patient Died
Sex, Patient Died
200
200
Table 2: Column recovery: the accuracy column reports the num-
ber of hospitals for which the correct attribute (i.e., from the
auxiliary attribute column) had the lowest (cid:96)2-optimization cost
among all target attributes.
Data Revealer. Revealer is written in Matlab and imple-
ments frequency analysis, (cid:96)2-optimization, and the cumula-
tive attack. The last two attacks use the Hungarian algo-
rithm for the optimization step. We did not implement the
sorting attack against dense columns since correctness and
perfect accuracy is trivially true (we do run experiments to
report the prevalence of dense columns in our target dataset
and results are shown in Figure 4). Revealer takes as in-
put the histogram of an auxiliary column from the output
of Parser and the histograms for a set of target encrypted
columns from the output of Column Finder. So, depending
on the output of Column Finder, Revealer can receive either
a single target histogram or multiple target histograms and
in each case it works as follows:
• if it receives a single target histogram, Revealer simply
runs the attack with its two inputs.
652• if it receives multiple target histograms, Revealer runs
one of the optimization-based attacks on the auxiliary
histogram with each of the target histograms. It then
outputs the result with the minimum cost.
Note that only the (cid:96)p-optimization and cumulative attacks
can be executed when there are multiple target histograms
since frequency analysis does not have an inherent notion of
cost that can be used. In our experiments, we found that
when the target and auxiliary attributes are the same, the
cost is signiﬁcantly less than when they are diﬀerent. This
is reported in Table 2.
Time measurements. All the attacks take less than a