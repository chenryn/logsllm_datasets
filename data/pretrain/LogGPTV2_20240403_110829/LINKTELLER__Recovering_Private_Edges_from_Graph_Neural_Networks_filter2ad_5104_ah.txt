### Evaluation of Model Utility and Privacy Tradeoff

#### 1. Dataset and Evaluation Metrics
We evaluate the model utility using the Twitch datasets, PPI, and Flickr datasets. The micro-averaged F1 score is used as the primary metric for performance evaluation. The rationale behind this choice is detailed in Appendix F2.

#### 2. Evaluation Results
The model utility results are presented in Figure 3(a). We plot the change in utility with increasing privacy budget (ε) for two differentially private (DP) mechanisms: EDGERAND and LAPGRAPH. Additionally, we include the utility of two baseline models, GCN and MLP, which are independent of the privacy budget. For each ε value, the reported results are averaged over 10 runs with different random seeds to ensure robustness.

**Comparison of Baseline Models:**
- **GCN (Black Horizontal Line):** Generally, GCN outperforms MLP across most datasets, except on the PPI dataset. This observation aligns with our intuition that the graph structure provides valuable information for learning.
- **MLP (Red Line):** MLP performs well but is generally outperformed by GCN, except on the PPI dataset.

**Utility Trends with Increasing Privacy Budget:**
- For most datasets, the model utility increases as the privacy budget grows, indicating that less noise is added to the graph structure, thus providing better utility.
- **Exception:** The twitch-ENGB dataset shows a slight increase in utility with more privacy noise. This is likely due to the large distributional difference between the training and testing graphs, where the sparse nature of twitch-ENGB (see Table IV(a)) benefits from additional random noise, improving generalization.

**Validation-Based ε Selection:**
- In addition to evaluating the utility across a range of ε values, we also select an appropriate ε based on a validation dataset. The detailed setup and results are provided in Appendix G6.

#### 3. Tradeoff Between Model Utility and Privacy
We analyze the tradeoff between model utility and attack performance. Models with high utility tend to be more vulnerable to LINKTELLER. The optimal balance (sweet spot) varies across datasets and scenarios. Our key observations and conclusions are:

- **High Utility of Vanilla GCN vs. MLP:**
  - If the vanilla GCN significantly outperforms MLP, there is room for some performance degradation while ensuring privacy. For example, on the twitch-RU dataset with ε = 7, the DP model's utility exceeds the MLP baseline, and the attack success rate is relatively low, especially for low-degree nodes.
  - Careful selection of ε can provide good utility and a reasonable level of privacy.

- **Small Margin Performance Difference:**
  - When the vanilla GCN only slightly outperforms MLP, almost all DP models that effectively defend against attacks suffer significant utility loss. Most scenarios fall into this category, where either privacy or utility must be sacrificed, highlighting the effectiveness of LINKTELLER.

- **Graph Structure Impact:**
  - In cases where the graph structure hinders learning (e.g., PPI), using MLP might be a better alternative. Future work could explore other graph neural networks that perform well on such datasets and apply LINKTELLER to these models.

#### 4. Analysis of Node Degree Impact
To understand the impact of node degree on utility, we bin nodes by degree (e.g., 1-5, 6-10, ..., 50-) and investigate the F1 score for each bin. The results, shown in Figure 4, indicate that the utility for low-degree nodes does not drop faster than for high-degree nodes as the privacy budget decreases. This suggests that DP GCN does not disproportionately sacrifice the utility of low-degree nodes.

#### 5. Comparison of DP Mechanisms
- **EDGERAND and LAPGRAPH:**
  - At small ε values, the utility of EDGERAND and LAPGRAPH is similar, especially on the PPI dataset.
  - At larger ε values, EDGERAND generally has better utility, while LAPGRAPH is more robust to LINKTELLER.
  - For the large-scale Flickr dataset under tight privacy budgets (ε ∈ {1, 2, 3, 4}), EDGERAND faces computational issues (OOM errors with an 11 GB GPU) due to increased graph density after perturbation. LAPGRAPH does not suffer from this issue.

### Related Work
1. **Privacy Attacks on Graphs:**
   - Prior studies have focused on identity disclosure, attribute disclosure, and link re-identification [32]–[35]. These attacks often rely on strong prior knowledge, which may not always be available or accurate.
   - He et al. [11] and Duddu et al. [36] have demonstrated the feasibility of link re-identification using clustering and node embeddings, respectively. However, these methods require substantial prior information.
   - Our work aims to recover private edges by probing a trained blackbox GNN model without strong prior knowledge, leveraging the influence propagation property of GNNs.

2. **Differential Privacy for Graphs:**
   - Differential privacy [18] ensures that the outputs of the model on neighboring inputs are close, obscuring the influence of any individual training instance.
   - Extensive research has been conducted on computing graph statistics under differential privacy, such as degree distribution [45], cut queries [46], and sub-graph counting queries [47].
   - To evaluate the strength of the LINKTELLER attack, we adapt the existing EDGERAND algorithm and propose a new Laplacian mechanism, LAPGRAPH, for training DP GCN models.

### Conclusions
We introduce the first edge re-identification attack, LINKTELLER, which uses influence analysis to target GNNs. We evaluate LINKTELLER against differentially private GNNs trained using EDGERAND and LAPGRAPH. Experiments on real-world datasets (8 inductive and 3 transductive) demonstrate the effectiveness of LINKTELLER in revealing private edge information, even with certain privacy guarantees provided by DP mechanisms.

This work lays the foundation for future research by providing a clear problem setup, extensive empirical observations, and a comprehensive analysis of edge privacy. It will inspire further exploration and development in this field.

### Acknowledgements
This work is partially supported by the NSF grant No.1910100, NSF CNS 20-46726 CAR, and Amazon Research Award.

### References
[References listed as provided in the original text]

---

This revised version aims to make the text more coherent, structured, and professional, while maintaining the essential details and insights from the original text.