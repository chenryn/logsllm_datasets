{
"type"："array"，
"items"：{
"type"："record"，
"name"："complex"，
"fields"：[
{
"name"："real"，
"type"："double"
}，
{
"name"："imaginary"，
"type"："double"
}
]
}
}
随着时间的变化，程序模式期望的数据可能与之前存储的数据不同，为了把一个模式转化为另一个模式，Avro提供了不完全一样的模式规则。这种情况下，代码生成工具就有用了，对于每个生成的结构都会建立一个用来读取数据的特别索引结构，即使数据是用不同的模式写的。在example.hh中的索引结构如下：
class complex_Layout：public avro：CompoundOffset{
public：
complex_Layout（size_t offset）：
CompoundOffset（offset）
{
add（new avro：Offset（offset+offsetof（complex, real）））；
add（new avro：Offset（offset+offsetof（complex, imaginary）））；
}
}；
数据前若是float类型而不是double类型，根据模式解决规则，floats可以升级为doubles，只要新旧模式都有用，就会建立一个动态的解析器来读取代码生成结构的数据。如下所示：
void dynamicParse（const avro：ValidSchema＆writerSchema，
const avro：ValidSchema＆readerSchema）{
//实例化布局对象
Math：complex_Layout layout；
//创建已知类型布局和模式的模式解析器
resolverSchema（writerSchema, readerSchema, layout）；
//设置reader
avro：ResolvingReader reader（resolverSchema, data）；
Math：complex c；
//执行解析
avro：parse（reader, c）；
//这时，c中存放的是反序列化后的数据
}
16.3 Avro的Java实现
本节主要介绍Avro在Java中的实现。Java API现在的版本是1.6.3，其中主要的包有如下几个。
org. apache.avro：Avro内核类。
org. apache.avro.file：存放Avro数据的文件容器相关类。
org. apache.avro.generic：Avro数据的一般表示类。
org. apache.avro.io：Avro输入/输出工具类。
org. apache.avro.io.parsing：Avro格式的LL（1）语法实现。
org. apache.avro.ipc：进程间调用支持类。
org. apache.avro.ipc.stats：收集和显示IPC统计数据的工具类。
org. apache.avro.ipc.trace：追踪RPC递归调用的相关类。
org. apache.avro.mapred：使用Avro数据运行Hadoop MapReduce，其Map和Reduce功能用Java实现。
org. apache.avro.mapred.tether：使用Avro数据运行Hadoop MapReduce，其Map和Reduce功能在子进程运行。
org. apache.avro..reflect：使用Java映射为存在的类生成格式和协议。
org. apache.avro.specific：为格式和协议生成特定的Java类。
org. apache.avro.tool：Avro命令行工具类。
org. apache.avro.util：普通工具类。
关于上面各包中包含的类的具体使用可参见Java API，下面通过简单的例子介绍各类的用法。下面是用Java实现学生信息的存储和读取：
package cn.edu.ruc.cloudcomputing.book.chapter16；
/*student.java*/
import java.io.File；
import java.io.IOException；
import org.apache.avro.Schema；
import org.apache.avro.file.DataFileReader；
import org.apache.avro.file.DataFileWriter；
import org.apache.avro.generic.GenericData；
import org.apache.avro.generic.GenericDatumReader；
import org.apache.avro.generic.GenericDatumWriter；
import org.apache.avro.generic.GenericData.Record；
import org.apache.avro.util.Utf8；
public class student{
String fileName="student.db"；
String prefix="{\"type\"：\"record\"，\"name\"：\"Student\"，\"fields\"：["；
String suffix="]}"；
String fieldSID="{\"name\"：\"SID\"，\"type\"：\"int\"}"；
String fieldName="{\"name\"：\"Name\"，\"type\"：\"string\"}"；
String fieldDept="{\"name\"：\"Dept\"，\"type\"：\"string\"}"；
String fieldPhone="{\"name\"：\"Phone\"，\"type\"：\"string\"}"；
String fieldAge="{\"name\"：\"Age\"，\"type\"：\"int\"}"；
Schema studentSchema=Schema.parse（prefix+fieldSID+"，"+fieldName+"，"+
fieldDept+"，"+fieldPhone+"，"+fieldAge+suffix）；
Schema extractSchema=Schema.parse（prefix+fieldName+"，"+fieldPhone+suffix）；
int SID=0；
public static void main（String[]args）throws IOException{
student st=new student（）；
st.init（）；
st.print（）；
st.printExtraction（）；
}
/**
*初始化添加学生记录
**/
public void init（）throws IOException{
DataFileWriter＜Record＞writer=new DataFileWriter＜Record＞（
new GenericDatumWriter＜Record＞（studentSchema））.create（
studentSchema, new File（fileName））；
try{
writer.append（createStudent（"Zhanghua"，"Law"，"15201161111"，25））；
writer.append（createStudent（"Lili"，"Economy"，"15201162222"，24））；
writer.append（createStudent（"Wangyu"，"Information"，
"15201163333"，25））；
writer.append（createStudent（"Zhaoxin"，"Art"，"15201164444"，23））；
writer.append（createStudent（"Sunqin"，"Physics"，"15201165555"，25））；
writer.append（createStudent（"Zhouping"，"Math"，"15201166666"，23））；
}finally{
writer.close（）；
}
}
/**
*将学生信息添加到记录中
**/
private Record createStudent（String name, String dept, String phone, int age）{
Record student=new GenericData.Record（studentSchema）；
student.put（"SID"，（++SID））；
student.put（"Name"，new Utf8（name））；
student.put（"Dept"，new Utf8（dept））；
student.put（"Phone"，new Utf8（phone））；
student.put（"Age"，age）；
System.out.println（"Successfully added"+name）；
return student；
}
/**
*输出学生信息
**/
public void print（）throws IOException{
GenericDatumReader＜Record＞dr=new GenericDatumReader＜Record＞（）；
dr.setExpected（studentSchema）；
DataFileReader＜Record＞reader=new DataFileReader＜Record＞（new
File（fileName），dr）；
System.out.println（"\nprint all the records from database"）；
try{
while（reader.hasNext（））{
Record student=reader.next（）；
System.out.println（student.get（"SID"）.toString（）+""+student.
get（"Name"）+""+student.get（"Dept"）+""+student.get（"Phone"）+"
"+student.get（"Age"）.toString（））；
}
}finally{
reader.close（）；
}
}
/**
*输出学生姓名和电话
**/