istics contribute to Kizzle signatures being less prone to
false positives, as we show in Figure 13.
Signature eﬀectiveness: Figure 12 shows the lengths of
Kizzle-generated signatures over the month-long period of
96%	
  97%	
  98%	
  99%	
  100%	
  8/2/14	
  8/4/14	
  8/6/14	
  8/8/14	
  8/10/14	
  8/12/14	
  8/14/14	
  8/16/14	
  8/18/14	
  8/20/14	
  8/22/14	
  8/24/14	
  8/26/14	
  8/28/14	
  8/30/14	
  50%	
  55%	
  60%	
  65%	
  70%	
  75%	
  80%	
  85%	
  90%	
  95%	
  8/2/14	
  8/4/14	
  8/6/14	
  8/8/14	
  8/10/14	
  8/12/14	
  8/14/14	
  8/16/14	
  8/18/14	
  8/20/14	
  8/22/14	
  8/24/14	
  8/26/14	
  8/28/14	
  8/30/14	
  99%	
  100%	
  8/2/14	
  8/4/14	
  8/6/14	
  8/8/14	
  8/10/14	
  8/12/14	
  8/14/14	
  8/16/14	
  8/18/14	
  8/20/14	
  8/22/14	
  8/24/14	
  8/26/14	
  8/28/14	
  8/30/14	
  10%	
  20%	
  30%	
  40%	
  50%	
  60%	
  70%	
  80%	
  90%	
  100%	
  8/2/14	
  8/4/14	
  8/6/14	
  8/8/14	
  8/10/14	
  8/12/14	
  8/14/14	
  8/16/14	
  8/18/14	
  8/20/14	
  8/22/14	
  8/24/14	
  8/26/14	
  8/28/14	
  8/30/14	
  Fig. 12: Signature lengths over time for a month-long time window. Red call-outs are new signatures issued by AV. Green oval call-outs show delimiter
changes in Nuclear exploit kit.
EK
Nuclear
Sweet Orange
Angler
RIG
Sum
Ground
truth
6,106
11,315
40,026
1,409
58,856
AV
Kizzle
FP
1
0
635
11
647
FN
1,671
2
4,213
30
7,587
FP
25
0
0
241
266
FN
8
1
196
144
349
Fig. 14: False positives and false negatives: absolute counts comparing
Kizzle vs. AV.
\},toString:\(\{\}\)\.constructor\.prototype\
.toString,isPlainObject:function\(c\)\{vara=
this,bif\(!c\|\|a\.rgx\.any\.test\(a\.toString\
.call\(c\)\)\|\|c\.window==c\|\|a\.rgx\.num\
.test\(a\.toString\.call\(c\.nodeType\)\)\)\
{return0\}try\{if\(!a\.hasOwn\(c,"constructor"\)
&&!a\.hasOwn\(c\.constructor\.prototype,
"isPrototypeOf"\)\)\{return0\}\}catch\(b\)\
{return0\}return1\},isDefined:function\(b\)\
{returntypeofb!="undefined"\},isArray:
function\(b\)\{returnthis\.rgx\.arr\.test\
(this\.toString\.call\(b\)\)\},isString:
function\(b\)\{returnthis\.rgx\.str\.test\
(this\.toString\.call\(b\)\)\},isNum:function\(b\)
Fig. 15: A false positive for Kizzle extracted from PluginDetect; it
shares a very high (79%) overlap with Nuclear exploit kit.
Overall, the false negative rate for Kizzle is under 5%
for the month of August. A weakness of our approach is
that, if a kit changes drastically overnight, Kizzle may no
longer be able to connect previous samples to subsequent
ones. In practice this did not occur during the period of
time we examined because kit authors reuse either the
unpacked body of the kit (Figure 11), or because they
reuse the packer. When we experience false negatives, it
is generally because of changes in the kit that are not
numerous enough in our grayware stream to warrant a
separate cluster. An example of this is a small bump in
false negatives for Angler on August 13th in Figure 6,
which produced some, but not enough new variants of
Angler for Kizzle to produce a new signature.
(a) False positives over time for a month-long time window.
(b) False negatives over time for a month-long time window.
Fig. 13: False positives and false negatives over time for a month-long
time window: Kizzle vs. AV.
Figure 13 shows that false negative rates for Kizzle
are smaller than those for AV as well. This shows that
Kizzle successfully balances false positive and false nega-
tive requirements. In particular, there is a spike in false
negatives between August 13th and August 21st for AV
which Kizzle does not suﬀer from. The majority of these
false negatives are due to AV’s failure to detect a variant
of Angler (Figure 6).
RIG.sig1RIG.sig2RIG.sig3RIG.sig4RIG.sig5RIG.sig6RIG.sig7ANG.sig1ANG.sig2ANG.sig3NEK.sig1NEK.sig2sa1asher_vamfber443NEK.sig3UluNNEK.sig402004006008001,0001,2001,4001,6001,8002,0001-Aug2-Aug3-Aug4-Aug5-Aug6-Aug7-Aug8-Aug9-Aug10-Aug11-Aug12-Aug13-Aug14-Aug15-Aug16-Aug17-Aug18-Aug19-Aug20-Aug21-Aug22-Aug23-Aug24-Aug25-Aug26-Aug27-Aug28-Aug29-Aug30-Aug31-AugRIGAnglerSweet orangeNuclear0.00%0.01%0.02%0.03%0.04%0.05%0.06%0.07%1-Aug3-Aug5-Aug7-Aug9-Aug11-Aug13-Aug15-Aug17-Aug19-Aug21-Aug23-Aug25-Aug27-Aug29-Aug31-AugFalse positives for all kitsAV FP %Kizzle FP %0%5%10%15%20%25%30%35%40%45%1-Aug3-Aug5-Aug7-Aug9-Aug11-Aug13-Aug15-Aug17-Aug19-Aug21-Aug23-Aug25-Aug27-Aug29-Aug31-AugFalse negatives for all kitsAV FN %Kizzle FN %V. Discussion
Our approach combines automatically building signa-
tures on the packed versions of exploit kits by reasoning
about maliciousness based on comparing the unpacked
versions to previous known attacks.
Choice of EKs: Our results are based on studying the
behavior of four exploit kits over a period of one month.
We have looked at the same kits over a longer period (and
observed consistent behavior) and these kits do represent
a signiﬁcant fraction of all malware we observe in our
data stream, but our experiments are still limited. Our
choice of kits mostly coincides with the most important
EKs of 2014 and 2015, as identiﬁed by a diﬀerent security
companies [39, 42], and we believe our results will carry
over to other EKs, given that they employ a similar
packing strategy.
Tuning the ML: As with any solution based on clustering
and abstracting streams of data, a number of tuning knobs
control the eﬀectiveness of the approach. For example, how
many samples do we need to deﬁne a cluster, how long
should the generated signatures be, etc. Finding the right
values for these parameters and adjusting them due to the
dynamic nature of a malicious opponent makes keeping
such a system well-tuned challenging. Likely, observing
detection accuracy over time as part of operations with
the attacker adjusting to Kizzle is needed.
EK structure: Our approach is based on the fact that
while the eﬀort to change the outer layer of an EK is rela-
tively small, changing the syntax, yet not the semantics, of
the inner layer is non-trivial. However, research by Payer
has highlighted that for binary ﬁles, automated rewriting
to achieve just such syntactic changes is feasible [27].
While that work aims speciﬁcally at binaries, adoption of
such automated rewriting schemes would impair Kizzle’s
ability to track the kits in their unfolded form, if exploit
kits move closer to a “fully polymorphic” model.
Deployment and avoidance: As shown in Figure 1,
there is an arms race between created signatures and
avoidance by an adversary. Kizzle’s signatures, not un-
like hand-crafted AV signatures, can be circumvented by
simple trial-and-error—the attacker loads a URL contain
his packed kit and checks whether the AV ﬂags it. If the
AV triggers, he can adjust the code to see if that change
allows him to bypass detection. This allows him to produce
a new, undetected variant of his kit. However, the inner-
most layer is not as easy to change, as the code is often
not even originating from the kit author, but taken from
another kit. Therefore, even though the new variant has no
resemblance to the previous versions on the outside, they
will most likely overlap in the inner-most code, allowing
Kizzle to correctly label the resulting clusters as malicious
and thus, producing a signature to match the new variant.
This process is fully automated and therefore does not
require any manual work on the side of the analyst. In
contrast, the malware author is now faced with a signature
capable of detecting his changed EK variant, requiring him
to change the packer again.
One means for an attacker to bypass detection is to
change the inner-most part of the code to such an extend
that Kizzle is no longer able to correctly classify a mali-
cious cluster. This step, however, cannot be automated as
easily since Kizzle does not provide an attacker with the
means of directly checking a given sample for detection.
Rather, he has to create a new variant with major changes
to the inner core and wait for Kizzle to create (or not
create) a signature. To counter such attacks, Kizzle can
be extended to employ hidden signatures on the server
side. Such signatures can either match on speciﬁc strings
contained in the inner layer or even match on execution
behavior. As they never leave the server, the adversary
has no means of learning what they match on and thus, is
not able to circumvent detection. The current generation
of EKs, however, does not change the unpacked code in
such a manner and thus, we opted not to implement such
a detection mechanism.
An attacker aware of the signature creation algorithm
can try to modify his packer such that our algorithm fails.
An example for this is the insertion of a random number
of superﬂuous JavaScript instructions between relevant
operations to beat the structural signatures. We believe,
however, that our approach can be extended to create
signatures which not only match one consecutive token
sequence, but rather consist of multiple, shorter sequences.
VI. Related Work
We cover three most closely related areas of research.
Exploit Kits: Previous work on exploit kits has focused
mainly on examining their server-side components. Ko-
tov et al. analyze the server-side code for 24 (partially inac-
tive) diﬀerent families and found that 82% of the analyzed
kits use some form of obfuscation [19]. Additional research
into the server-side components has been conducted by
De Maio et al. [8]. The authors conclude that several of