# CALM: Consistent Adaptive Local Marginal for Marginal Release under Local Differential Privacy

**Authors:**
- Zhikun Zhang<sup>1,2</sup>
- Tianhao Wang<sup>2</sup>
- Ninghui Li<sup>2</sup>
- Shibo He<sup>3</sup>
- Jiming Chen<sup>1</sup>

**Affiliations:**
1. State Key Laboratory of Industrial Control Technology & Cyber Security Research Center, Zhejiang University
   - {zhangzhk, cjm}@zju.edu.cn
2. Department of Computer Science, Purdue University
   - {zhan3072, tianhaowang, ninghui}@purdue.edu
3. State Key Laboratory of Industrial Control Technology, Zhejiang University
   - PI:EMAIL

## Abstract
Marginal tables are essential for capturing the correlations among a set of attributes. This paper addresses the problem of constructing marginal tables from multi-dimensional user data while ensuring Local Differential Privacy (LDP), a privacy model that protects individual user data without relying on a trusted third party. Existing methods for this problem perform poorly in high-dimensional settings and often incur significant computational overhead. We introduce CALM (Consistent Adaptive Local Marginal), a method that leverages careful error analysis to outperform existing techniques. CALM is scalable with large data dimensions and marginal sizes. Extensive experiments on real-world datasets demonstrate the effectiveness and efficiency of CALM over current methods.

## ACM Reference Format
Zhikun Zhang, Tianhao Wang, Ninghui Li, Shibo He, Jiming Chen. 2018. CALM: Consistent Adaptive Local Marginal for Marginal Release under Local Differential Privacy. In 2018 ACM SIGSAC Conf. on Computer and Communications Security (CCS’18), October 15-19, 2018, Toronto, ON, Canada. ACM, New York, NY, USA, 18 pages. https://doi.org/10.1145/3243734.3243742

## 1. Introduction
Differential privacy (DP) has become the de facto standard for data privacy in research [13, 14]. Early work on DP primarily focused on the centralized setting, where a trusted data curator processes data to protect individual privacy. For example, the curator might publish a private synopsis of the data, enabling analysis while hiding individual information.

Recently, local differential privacy (LDP) has been studied and deployed. In LDP, each user sends randomized information to an aggregator, who infers the data distribution. LDP techniques, used by companies like Google [16, 17], Apple [1], Microsoft [12], and Samsung [9], enable the collection of statistics while preserving individual privacy. Examples include collecting default browser homepages and search engines to detect malicious hijacking, or frequently typed emojis and words to improve keyboard predictions.

Previous LDP works have focused on estimating the frequencies of frequent values [6, 7, 16, 30, 37-39]. A more general setting involves users with multiple attributes, where the aggregator is interested in the joint distribution of some attributes. Marginal tables capture these correlations, which are crucial for many analysis tasks, such as finding correlations or fitting prediction models.

Two recent papers [11, 31] considered publishing marginals under LDP. Kulkarni et al. [11] proposed using Fourier Transformation, while Ren et al. [31] used Expectation Maximization. However, these methods perform poorly with more than a few attributes.

We propose CALM, a new method for computing k-way marginals under LDP. Inspired by PriView [29], which computes k-way marginals for binary datasets, CALM generates multiple marginal tables. We address challenges in transitioning from centralized to local settings, including integrating frequency oracle (FO) protocols and extending methods to non-binary attributes. We also carefully analyze errors and develop a principled approach for choosing key algorithmic parameters.

Our experimental results show that CALM's Sum of Squared Errors is often one to two orders of magnitude lower than the best current method [11]. Additionally, CALM scales better and achieves near-optimal prediction performance when training an SVM model on fixed marginals.

### Main Contributions
1. **CALM for Marginal Release under LDP**: Introduces a method that works with non-binary attributes.
2. **Error Analysis and Parameter Selection**: Conducts a detailed analysis of errors and develops an algorithm for selecting key parameters.
3. **Performance Evaluation**: Extensively evaluates CALM on real-world datasets, demonstrating superior performance compared to state-of-the-art methods.

### Roadmap
- **Section 2**: Background on LDP and FO.
- **Section 3**: Problem definition and existing solutions.
- **Section 4**: Proposed method.
- **Section 5**: Experimental results.
- **Section 6**: Related work.
- **Section 7**: Conclusions.

## 2. Background
In the local setting for DP, there are many users and one aggregator. Each user possesses a value \( v \) from domain \( D \), and the aggregator wants to learn the distribution of values while protecting individual privacy.

### 2.1. Differential Privacy in the Local Setting
To protect privacy, each user perturbs their input value \( v \) using an algorithm \( \Psi \) and sends \( \Psi(v) \) to the aggregator. The formal requirement is:

**Definition 1 (ε-Local Differential Privacy)**: An algorithm \( \Psi(·) \) satisfies ε-local differential privacy (ε-LDP), where \( \epsilon \geq 0 \), if and only if for any inputs \( v_1, v_2 \in D \),
\[ \forall T \subseteq \text{Range}(\Psi) : \Pr[\Psi(v_1) \in T] \leq e^\epsilon \Pr[\Psi(v_2) \in T], \]
where \(\text{Range}(\Psi)\) denotes the set of all possible outputs of \(\Psi\).

### 2.2. Frequency Oracles
A frequency oracle (FO) protocol enables the estimation of the frequency of any value \( x \in D \) under LDP. It consists of two algorithms: \( \Psi \) for users to perturb their input, and \( \Phi \) for the aggregator.

#### 2.2.1. Generalized Randomized Response (GRR)
This FO protocol generalizes the randomized response technique. Each user with private value \( v \in D \) sends the true value \( v \) with probability \( p \), and a randomly chosen \( v' \in D \) with probability \( 1 - p \). Formally,
\[ \forall y \in D, \Pr[\Psi_{\text{GRR}}(\epsilon)(v) = y] = \begin{cases} 
p = \frac{e^\epsilon}{e^\epsilon + d - 1}, & \text{if } y = v \\
q = \frac{1}{e^\epsilon + d - 1}, & \text{if } y \neq v 
\end{cases} \]
This satisfies ε-LDP since \( \frac{p}{q} = e^\epsilon \). To estimate the frequency of \( v \in D \), the aggregator counts the number of times \( v \) is reported, denoted as \( C(v) \), and computes:
\[ \Phi_{\text{GRR}}(\epsilon)(v) = \frac{C(v)/n - q}{p - q} \]

For example, if 20% of users have value \( v \), the expected number of \( v \) in all reports is \( 0.2np + 0.8nq \). If the aggregator sees exactly this number of reports, the estimated value is:
\[ \frac{(0.2np + 0.8nq)/n - q}{p - q} = \frac{0.2p + 0.8q - q}{p - q} = \frac{0.2p - 0.2q}{p - q} = 0.2 \]

The variance for this estimation is:
\[ \text{Var}[\Phi_{\text{GRR}}(\epsilon)(x)] = \frac{|D| - 2 + e^\epsilon}{(e^\epsilon - 1)^2} \cdot \frac{1}{n} \]
The accuracy deteriorates as the domain size \( |D| \) increases.

#### 2.2.2. Optimized Unary Encoding (OUE)
OUE [37] avoids the variance dependence on \( |D| \) by encoding the value into a unary representation. Let \( D = [0..d-1] \); each value \( v \in [0..d-1] \) is encoded into a binary string of length \( d \) with the \( v \)-th bit set to 1 and all other bits set to 0. OUE applies GRR to each bit but transmits 1's and 0's differently. The bit 1 is transmitted as a coin toss, i.e., perturbed to 0 with probability 0.5. This minimizes the estimation variance when \( |D| \) is large.

Given reports \( y_j \) from all users \( j \in [n] \), to estimate the frequency of \( v \), the aggregator counts the number of reports with the bit corresponding to \( v \) set to 1, denoted as \( C(x) \). The unbiased estimation is:
\[ \Phi_{\text{OUE}}(\epsilon)(x) = \frac{C(x)/n - q}{1/2 - q} \]
The variance is:
\[ \text{Var}[\Phi_{\text{OUE}}(\epsilon)(x)] = \frac{4e^\epsilon}{(e^\epsilon - 1)^2} \cdot \frac{1}{n} \]

#### 2.2.3. Adaptive FO
For smaller \( |D| \) (such that \( |D| - 2 < 3e^\epsilon \)), GRR is better; for larger \( |D| \), OUE is better. We use FO to denote the adaptively chosen protocol, with variance:
\[ \text{Var}[\Phi_{\text{FO}}(\epsilon)(x)] = \min \left( \frac{4e^\epsilon}{(e^\epsilon - 1)^2}, \frac{|D| - 2 + e^\epsilon}{(e^\epsilon - 1)^2} \right) \cdot \frac{1}{n} \]

## 3. Problem Definition and Existing Solutions
We consider a setting where each user has multiple attributes, and the aggregator is interested in the joint distribution of some attributes. This multi-dimensional setting is common in LDP applications. Researchers have studied the problem of constructing marginals in the LDP setting [11, 31].

### 3.1. Problem Definition: Centralized Setting
Assume there are \( d \) attributes \( A = \{a_1, a_2, \ldots, a_d\} \). Each attribute \( a_i \) has \( c_i \) possible values. Without loss of generality, assume the values for \( a_i \) are \( [c_i] = \{0, 1, \ldots, c_i - 1\} \). Each user has one value for each attribute, represented as a \( d \)-dimensional vector \( v^j = \langle v_1^j, v_2^j, \ldots, v_d^j \rangle \) with \( v_i^j \in [c_i] \). The full domain for users' values is \( D = [c_1] \times [c_2] \times \cdots \times [c_d] \), with size \( |D| = \prod_{i=1}^d c_i \).

The full contingency table gives the joint distribution of all attributes in \( A \). When the domain size is large, computing the full contingency table can be expensive. Often, one is interested in the joint distribution of some subsets of attributes. Given a set of attributes \( A' \subseteq A \), we use \( V_{A'} = \{\langle v_1, v_2, \ldots, v_d \rangle : v_i \in [c_i] \text{ for } a_i \in A'\} \) to denote the subset of values for \( A' \).

### Example
| Gender | Age |
|--------|-----|
| male   | teenager |
| female | teenager |
| female | adult |
| female | adult |
| ...    | ...   |
| male   | adult |

## 4. Proposed Method
[Detailed description of the proposed method CALM will be added here, including the algorithm, steps, and key features.]

## 5. Experimental Results
[Detailed description of the experimental setup, datasets, and results will be added here, including comparisons with existing methods and performance metrics.]

## 6. Related Work
[Discussion of related work, including previous methods and how they compare to CALM, will be added here.]

## 7. Conclusions
[Summary of the main contributions, future work, and concluding remarks will be added here.]