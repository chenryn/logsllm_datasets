# 十二、Kubernetes 简介
在前一章中，我们学习了 FlowKit 如何使用滚动更新来实现零宕机部署。我们还了解了 Docker 机密，它用于与 Docker Swarm 中运行的应用服务共享机密数据。
在本章中，我们将介绍 Kubernetes。Kubernetes 目前是容器编排领域的明显领导者。我们从 Kubernetes 集群架构的高级概述开始，然后我们将讨论 Kubernetes 中用于定义和运行容器化应用的主要对象。
本章讨论的主题是:
*   体系结构
*   Kubernetes 大师赛
*   群集节点
*   MiniKube 简介
*   Mac Docker 和 Windows Docker 中的无缝支持
*   分离舱
*   立方复制集
*   库比涅斯部署
*   库比涅斯的服务，库比涅斯的服务，库比涅斯的服务，库比涅斯的服务，库比涅斯的服务，库比涅斯的服务，库比涅斯的服务，库比涅斯的服务
*   基于上下文的路由
*   将 FlowKit 与 Kubernetes 进行比较
完成本章后，您将能够:
*   在餐巾纸上绘制 Kubernetes 集群的高层架构
*   解释 Kubernetes 豆荚的三至四个主要特征
*   用两到三个短句描述 Kubernetes 复制集的作用
*   解释 Kubernetes 服务的两到三个主要职责
*   在 Minikube 中创建一个 pod
*   将 Mac 或 Windows 的 Docker 配置为使用 Kubernetes 作为编排器
*   在 Docker 中为 Mac 或 Windows 创建部署
*   创建一个 Kubernetes 服务，向集群内部(或外部)公开一个应用服务
# 技术要求
代码文件的链接可以在这里找到[https://github . com/原教旨主义 docker/labs/tree/master/ch12。](https://github.com/fundamentalsofdocker/labs/tree/master/ch12)
# 体系结构
Kubernetes 集群由一组服务器组成。这些服务器可以是虚拟机或物理服务器。后者也叫*裸机*。集群的每个成员可以有两种角色之一。它要么是一个 Kubernetes 主节点，要么是一个(工作)节点。前者用于管理集群，而后者将运行应用工作负载。我将 worker 放在括号中，因为按照 Kubernetes 的说法，在谈论运行应用工作负载的服务器时，您只谈论节点。但是用 Docker 和 Swarm 的说法，这相当于一个*工人节点*。我认为工作节点的概念比简单的节点更好地描述了服务器的角色。
在集群中，您有少量奇数个主节点和所需数量的工作节点。小型集群可能只有几个工作节点，而更现实的集群可能有几十个甚至几百个工作节点。从技术上讲，一个集群可以有多少工作节点没有限制；然而，实际上，在处理数千个节点时，您可能会经历一些管理操作的显著减速。集群的所有成员都需要通过物理网络连接，即所谓的**底层网络**。
Kubernetes 为整个集群定义了一个平面网络。Kubernetes 不提供任何现成的网络实现，而是依赖于第三方的插件。Kubernetes 只定义了**容器网络接口** ( **CNI** )，将实现留给其他人。CNI 很简单。它基本上规定，集群中运行的每个 pod 必须能够到达集群中运行的任何其他 pod，而其间不会发生任何**网络地址转换** ( **NAT** )。集群节点和 pod 之间也必须如此，也就是说，直接在集群节点上运行的应用或守护程序必须能够到达集群中的每个 pod，反之亦然。
在下图中，我试图说明 Kubernetes 集群的高级架构:
![](img/959240a2-a3dd-461b-a3c5-eb488cc7ba84.jpg)
High-level architecture diagram of Kubernetes
上图解释如下:
*   在顶部，中间有一簇 **etcd** 节点。etcd 是一个分布式键值存储，在 Kubernetes 集群中，用于存储集群的所有状态。etcd 节点的数量必须是奇数，这是 Raft 共识协议规定的，它们用来相互协调。当我们谈论集群状态时，我们不包括在集群中运行的应用产生或使用的数据，而是我们谈论关于集群拓扑、正在运行的服务、网络设置、使用的机密等的所有信息。也就是说，这个 etcd 集群对于集群来说确实是至关重要的，因此，我们永远不应该在生产环境或任何需要高可用性的环境中只运行一台 etcd 服务器。
*   然后我们有一个 Kubernetes**主**节点的集群，它们之间也形成了一个共识组，类似于 etcd 节点。主节点的数量也必须是奇数。我们可以用单个主节点运行集群，但是我们永远不应该在生产或关键任务系统中这样做。在那里，我们总是应该至少有三个主节点。由于主节点用于管理整个集群，所以我们也在谈论管理平面。主节点使用 etcd 集群作为它们的后备存储。将一个**负载平衡器** ( **LB** )放在一个知名的**全限定域名** ( **FQDN** )的主节点前面，比如`https://admin.example.com`，是一个很好的做法。所有用于管理 Kubernetes 集群的工具都应该通过这个 LB 访问它，而不是使用其中一个主节点的公共 IP 地址。这显示在上图的左上角。
*   在图的底部，我们有一个工作者节点集群。节点数量可以低至一个，并且没有上限。Kubernetes 主节点和工作节点相互通信。这是一种双向的交流方式，不同于我们从 Docker Swarm 那里知道的方式。在 Docker Swarm 中，只有管理节点与工作节点通信，而从来没有其他节点。访问集群中运行的应用的所有入口流量应该通过另一个负载平衡器。这是应用负载平衡器或反向代理。我们从不希望外部流量直接访问任何工作节点。
现在我们已经对 Kubernetes 集群的高级架构有了一个概念，让我们深入一点，首先看看 Kubernetes 主节点和工作节点。
# 不可扩展的主节点
Kubernetes 主节点用于管理 Kubernetes 集群。以下是这种主机的高级示意图:
![](img/9a391aea-6d90-40a2-8f9c-bee15240b14f.png)
Kubernetes master
在上图的底部，我们有**基础设施**，它可以是内部部署的虚拟机或云中的虚拟机或服务器(通常称为裸机)，也可以是内部部署的虚拟机或云中的虚拟机。目前，Kubernetes masters 只在 Linux 上运行。支持大多数流行的 Linux 发行版，如 RHEL、CentOS 和 Ubuntu。在这个 Linux 机器上，我们至少运行了以下四个 Kubernetes 服务:
*   **API 服务器**:这里是 Kubernetes 的门户。列出、创建、修改或删除群集中任何资源的所有请求都必须通过此服务。它公开了一个 REST 接口，像`kubectl`这样的工具用来管理集群和集群中的应用。
*   **控制器**:控制器，或者更准确地说是控制器管理器，是一个控制回路，通过 API 服务器观察集群的状态并做出改变，试图将当前或有效状态移向期望状态。
*   **调度器**:调度器是一种在考虑各种边界条件(如资源需求、策略、服务质量需求等)的情况下，尽力在工作节点上调度 pods 的服务。
*   **集群存储**:这是 etcd 的一个实例，用来存储集群状态的所有信息。
更准确地说，用作集群存储的 etcd 不必安装在与其他 Kubernetes 服务相同的节点上。有时，Kubernetes 集群被配置为使用独立的 etcd 服务器集群，如前一节的架构图所示。但是使用哪种变体是高级管理决策，不在本书的讨论范围之内。
我们至少需要一个主节点，但是为了实现高可用性，我们需要三个或更多的主节点。这与我们所了解的 Docker Swarm 的管理器节点非常相似。在这方面，Kubernetes 主节点相当于 Swarm 管理器节点。
Kubernetes masters 从不运行应用工作负载。他们的唯一目的是管理集群。Kubernetes 大师建立一个 Raft 共识小组。Raft 协议是一种标准协议，用于一组成员需要做出决定的情况。它被用在许多著名的软件产品中，如 MongoDB、Docker FlowKit 和 Kubernetes。有关 Raft 协议的更详细讨论，请参见*进一步阅读*部分中的链接。
正如我们在上一节中提到的，Kubernetes 集群的状态存储在 etcd 中。如果 Kubernetes 集群应该是高度可用的，那么 etcd 也必须配置为高可用性模式，这通常意味着一个集群至少有三个 etcd 实例在不同的节点上运行。
让我们再次声明整个集群状态存储在 etcd 中。这包括关于所有集群节点、所有副本集、部署、机密、网络策略、路由信息等的所有信息。因此，我们必须为这个关键价值商店制定一个强大的备份战略。
现在，让我们看看将运行集群实际工作负载的节点。
# 群集节点
集群节点是 Kubernetes 调度应用工作负载的节点。他们是集群中的主力。Kubernetes 集群可以有几个、几十个、几百个甚至几千个集群节点。Kubernetes 是为了高扩展性而从头开始构建的。不要忘记，Kubernetes 是以谷歌博格为模型的，多年来，谷歌博格已经运行了数万个容器:
![](img/4489d700-da92-40f4-a787-eefb413fb0a4.png)
Kubernetes worker node
工作节点可以在虚拟机、裸机、内部部署或云中运行。最初，工作节点只能在 Linux 上配置。但是从 1.10 版本的 Kubernetes 开始，工作节点也可以在 Windows Server 2010 上运行。拥有一个包含 Linux 和 Windows 工作节点的混合集群是非常好的。
在每个节点上，我们有三个需要运行的服务，描述如下:
*   **Kubelet** :这是第一位的服务。Kubelet 就是所谓的主节点代理。kubelet 服务使用 pod 规范来确保相应 pod 的所有容器都运行正常。Pod 规范是以 YAML 或 JSON 格式编写的文件，它们声明性地描述了 pod。我们将在下一节了解什么是豆荚。PodSpecs 主要通过 API 服务器提供给 Kubelet。
*   **容器运行时**:需要出现在每个工作节点上的第二个服务是容器运行时。默认情况下，Kubernetes 使用 1.9 版以来的`containerd`作为其容器运行时。在此之前，它将使用 Docker 守护程序。可以使用其他容器运行时，如 rkt 或 CRI-O。容器运行时负责管理和运行 pod 的各个容器。
*   **kube-proxy** :最后是 kube-proxy。它作为守护程序运行，是在该特定节点上运行的所有应用服务的简单网络代理和负载平衡器。
现在，我们已经了解了 Kubernetes 的体系结构以及主节点和工作节点，是时候介绍我们可以用来开发针对 Kubernetes 的应用的工具了。
# Minikube 简介
Minikube 是一种在 VirtualBox 或 Hyper-V(支持其他虚拟机管理程序)中创建单节点 Kubernetes 集群的工具，准备在容器化应用的开发过程中使用。我们已经在[第 2 章](02.html)、*设置工作环境、*中展示了如何将 Minikube 和工具`kubectl`安装到您的 Mac 或 Windows 笔记本电脑上。如上所述，Minikube 是一个单节点 Kubernetes 集群，因此该节点同时是 Kubernetes 主节点和工作节点。
让我们确保 Minikube 使用以下命令运行:
```
$ minikube start
```
一旦 Minikube 准备好，我们就可以使用`kubectl`访问它的单节点集群。我们应该会看到类似以下截图的内容:
![](img/d297037e-94ad-479f-a496-a0a873d76889.png)
Listing all nodes in Minikube
如前所述，我们有一个单节点集群，节点名为`minikube`。不要被`ROLES`一栏的数值``所迷惑；该节点同时扮演工作节点和主节点的角色。
现在，让我们尝试在这个集群中部署一个 pod。不要担心此时的吊舱到底是什么；在这一章中，我们将深入探讨有关它的所有细节。目前，就这样吧。
我们可以使用`labs`文件夹的子文件夹`ch12`中的文件`sample-pod.yaml`来创建这样一个 pod。它有以下内容:
```
apiVersion: v1
kind: Pod
metadata:
  name: nginx
spec:
  containers:
  - name: nginx
    image: nginx:alpine
    ports:
    - containerPort: 80
    - containerPort: 443
```
让我们使用名为`kubectl`的 Kubernetes 命令行界面来部署这个 pod:
```
$ kubectl create -f sample-pod.yaml
pod "nginx" created
```
如果我们现在列出所有的吊舱，我们应该会看到:
```
$ kubectl get pods
NAME    READY   STATUS    RESTARTS   AGE
nginx   1/1     Running   0          51s
```
为了能够访问这个 pod，我们需要创建一个服务。让我们使用`sample-service.yaml`文件，它有以下内容:
```
apiVersion: v1
kind: Service
metadata:
  name: nginx-service
spec:
  type: LoadBalancer
  ports:
  - port: 8080
    targetPort: 80
    protocol: TCP
    name: http
  - port: 443
    protocol: TCP
    name: https
  selector:
    app: nginx
```
同样，此时不要担心服务到底是什么。我们将进一步详细解释这一切。让我们创建这个服务: