unknown or untargeted locations. On the other hand, the techniques in this paper
detect network monitors through faster, stealthy and lightweight sampling that
does not require a pre-established set of publishing locations.
Zeiton et.al. showed that it is possible to estimate the liveliness of /24 address
preﬁxes by selectively probing IP addresses based on common network admin-
istration practices (e.g., selecting addresses commonly used by router interfaces
such as a.b.c.1 and a.b.c.129). While the technique successfully detected live
preﬁxes in their study with more than 90% accuracy, it is only applicable to /24
preﬁxes. By contrast, the methodology we use provides an upper-bound on the
number of probes and is applicable to preﬁxes of any size.
Over the past few years a number of proposals have highlighted the threat
from fast worms that employ novel scanning techniques. At a high level, these
222
M.A. Rajab, F. Monrose, and A. Terzis
techniques boost worm spreading using various forms of collaboration among
worm instances. For example, Staniford et.al. [33] outline a number of collabo-
rative scanning strategies, including permutation scanning in which the worm
maps the IP space into a large permutation and diversiﬁes the starting point
of scanners to reduce redundant scanning. While this strategy allows worms to
spread much faster, the scanning activity is still visible to network monitors
because the worm still scans the entire IP space. Flash and topological worms
can be even faster, reaching saturation in a few seconds [32]. However, although
inherently evasive, these worms assume a priori knowledge of the vulnerable
population through an already existing large hit-list.
More recently, Chen et.al. presented an alternative strategy to disseminate in-
formation about the vulnerable population distribution and divert worm scans
toward populated address groups [5]. However, as evasion was not a core ob-
jective, the proposed approach suﬀers various limitations from that perspec-
tive. For one, the worm initially scans the IP space uniformly at random to
ﬁnd enough vulnerable hosts to derive an accurate estimate of the vulnerable
population distribution. This activity is easily detected by distributed network
monitors. Second, the vulnerable population distribution is only estimated at
the /8 preﬁx level. Hence, the technique can limit worm scans toward monitors
occupying entire /8 address preﬁxes, but the worm is still detectable by dis-
tributed collections of small monitors deployed in heavily populated preﬁxes (as
recommended in [27]). More problematic is the fact that in order to learn the
vulnerable population distribution, each infected host must contact a centralized
“worm-server”. Such a server is both a single point of failure and an unnecessary
bottleneck.
The coordination mechanism we propose exploits re-infections to dissemi-
nate updated knowledge about the vulnerable population across worm instances.
This idea was independently suggested by Ma et.al. for designing self-stopping
worms [16]. In that case, re-infection is used to share an estimate of the infected
population which is then used to decide when to stop scanning. Although such
worms can hide the infected population past worm saturation, they can still be
detected (and contained) during the spreading phase. In contrast, the exam-
ples we present conceals the worm activity during its spreading phase and is
inherently self-stopping.
Lastly, a number of measurement studies based on packet traces collected
from network monitors have already speculated that persistent port scanning
activities is being used to ﬁngerprint vulnerable hosts (e.g., Pang et.al. [20],
Pouget et.al. [24]). In this paper, we show how such reconnaissance can be per-
formed in a dynamic, fast, and evasive manner.
7 Summary
The use of passive network monitors has played an important role in a myriad of
malware detection and containment studies to date. However, with the increased
use of passive monitoring techniques, it is prudent to expect that attacks will
Fast and Evasive Attacks: Highlighting the Challenges Ahead
223
soon evolve to minimize the practical beneﬁts gained from such techniques. In
this paper, we highlight the challenges posed by evasive techniques that severely
limit the view of the infection as recorded by collections of distributed network
monitors. The techniques we present use lightweight sampling to detect passive
network monitors as well as clusters of live network preﬁxes. We show the ef-
fectiveness of these evasive techniques through trace-based analysis and actual
probing experiments conducted in the wild. Our experimental results verify our
assertion that with a reasonably small number of probes, it is possible to ac-
curately detect the locations of passive network monitors and to identify live
address clusters containing the majority of the vulnerable population. We sub-
stantiate the threat from these techniques by outlining the design of evasive
malware capable of evading extensive collections of network monitors, while sat-
urating the vulnerable population in a matter of seconds. We hope that our
results will stimulate the research community to develop monitoring infrastruc-
tures capable of countering these impending threats.
Acknowledgments
This work is supported in part by National Science Foundation grant SCI-
0334108. We thank DShield for graciously providing access to their IDS logs.
We also extend our gratitude to the reviewers for their insightful comments and
feedback.
References
1. Michael Bailey, Evan Cooke, Farnam Jahanian, Jose Nazario, and David Watson.
Internet motion sensor: A distributed blackhole monitoring system. In Proceedings
of the ISOC Network and Distributed System Security Symposium (NDSS), 2005.
2. Paul Barford, Rob Nowak, Rebecca Willet, and Vinod Yagneswaran. Toward a
In Proceedings of
Model for Source Address of Internet Background Radiation.
Passive and Active Measurement Conference (PAM 2006), March 2006.
3. John Bethencourt, Jason Franklin, , and Mary Vernon. Mapping Internet Sen-
sors with Probe Response Attacks. In Proceedings of the 14th USENIX Security
Symposium, pages 193–212, August 2005.
4. Zesheng Chen, Lixin Gao, and Kevin Kwiat. Modeling the Spread of Active Worms.
In Proceedings of IEEE INFOCOMM, volume 3, pages 1890 – 1900, 2003.
5. Zesheng Chen and Chuanyi Ji. A Self-Learning Worm Using Importance Scanning.
In Proceedings of ACM Workshop On Rapid Malcode (WORM), November 2005.
http://
6. The Distributed Intrusion Detection System (DShield).
see
www.dshield.org/.
7. Xinwen Fu, Bryan Graham, Dan Cheng, Riccardo Bettati, and Wei Zhao. Camou-
ﬂaging Virtual Honeypots. In Texas A&M University technical report #2005-7-3,
2005.
8. Thorsten Holz and Frederic Raynal. Defeating Honeypots. Online article, see
http://www.securityfocus.com/infocus/1826#ref3.
9. Internet Assigned Numbers Authority (IANA), see http://www.iana.org/.
224
M.A. Rajab, F. Monrose, and A. Terzis
10. Internet Systems Consortium (ISC), see http://www.isc.org.
11. Vinod Yegneswaran Jonathon T. Giﬃn Paul Barford Somesh Jha. An architecture
In Proceedings of the 14th USENIX
for generating semantic-aware signatures.
Security Symposium, August 2005.
12. Hyang-Ah Kim and Brad Karp. Autograph: Toward automated, distributed worm
signature detection. In Proceedings of 13th USENIX Security Symposium, 2004.
13. Eddie Kohler, Jinyang Li, Vern Paxson, and Scott Shenker. Observed Structure of
Addresses in IP Traﬃc. In Proceedings of ACM SIGCOMM Internet Measurement
Workshop, November 2002.
14. Christian Kreibich and Jon Crowcroft. Honeycomb—creating intrusion detection
In Proceedings of 2nd Workshop on Hot Topics in
signatures using honeypots.
Networks (Hotnets-II), 2003.
15. Tom Liston, LaBrea Tarpit Project, see http://labrea.sourceforge.net/.
16. Justin Ma, Geoﬀrey Voelker, and Stefan Savage. Self-stopping worms.
In Pro-
ceedings of ACM Workshop On Rapid Malcode (WORM), pages 12–21, November
2005.
17. David Moore. Network Telescopes: Observing Small or Distant Security Events.
In 11th USENIX Security Symposium, Invited Talk, August 2002.
18. David Moore, Vern Paxson, Stefan Savage, Colleen Shannon, Stuart Staniford,
and Nicholas Weaver. Inside the Slammer Worm. IEEE Magazine of Security and
Privacy Magazine, pages 33–39, July 2003.
19. David Moore, Colleen Shannon, Geoﬀrey M. Voelker, and Stefan Savage. Internet
Quarantine: Requirements for Containing Self-Propagating Code. In Proceedings
of IEEE INFOCOM, 2003.
20. Ruoming Pang, Vinod Yegneswaran, Paul Barford, Vern Paxson, and Larry Pe-
terson. Characteristics of Internet Background Radiation. In Proceedings of ACM
IMC, October 2004.
21. Larry Peterson, Tom Anderson, and David Culler. A blueprint for introducing
disruptive technology into the internet. In First ACM Workshop on Hot Topics in
Networks (HotNets-I), October 2002.
22. Phillip Porras, Linda Briesemeister, Keith Skinner, Karl Levitt, Jeﬀ Rowe, and
Yu-Cheng Allen Ting. A hybrid quarantine defense. In Proceedings of the Second
ACM Workshop on Rapid Malcode (WORM), November 2004.
23. Fabien Pouget, Marc Dacier, and Van Hau Pham. Lurre.com: On the Advantages
of Deploying a Large Scale Distributed Honeypot Platform. In Proceeding of the
E-Crime and Computer Conference ECCE, March 2005.
24. Fabien Pouget, Marc Dacier, Van Hau Pham, and Herve Deber. Honeynets: Foun-
dations for the development of early warning systems. In NATO Advanced Research
Workshop, 2004.
25. Neil Provos. A virtual honeypot framework. In Proceedings of the 13th USENIX
Security Symposium, August 2004.
26. Moheeb Abu Rajab, Fabian Monrose, and Andreas Terzis. Fast and Evasive At-
In JHU Computer Science Technical
tacks: Highlighting the challenges ahead.
Report HiNRG-RMT-112205, November 2005.
27. Moheeb Abu Rajab, Fabian Monrose, and Andreas Terzis. On the Eﬀectiveness
In Proceedings of the 14th USENIX Security
of Distributed Worm Monitoring.
Symposium, pages 225–237, August 2005.
28. Moheeb Abu Rajab, Fabian Monrose, and Andreas Terzis. Worm Evolution Track-
In Proceedings of ACM Workshop on Rapid Malware
ing via Timing Analysis.
(WORM), pages 52–59, November 2005.
Fast and Evasive Attacks: Highlighting the Challenges Ahead
225
29. David Meyer, University of Oregon RouteViews Project.
http://www.
routeviews.org/.
30. Colleen Shannon and David Moore. The Spread of the Witty Worm. IEEE Security
and Privacy Magazine, 2(4):46–50, July 2004.
31. Yoichi Shinoda, Ko Ikai, and Motomu Itoh. Vulnerabilities of Passive Internet
Threat Monitors. In Proceedings of the 14th USENIX Security Symposium, pages
209–224, August 2005.
32. Stuart Staniford, David Moore, Vern Paxson, and Nick Weaver. The Top Speed of
Flash Worms. In Proceedings of the ACM Workshop on Rapid Malcode (WORM),
pages 33–42, October 2004.
33. Stuart Staniford, Vern Paxson, and Nicholas Weaver. How to 0wn the internet in
your spare time. In Proceedings of the 11th USENIX Security Symposium, August
2002.
34. George Varghese Sumeet Singh, Cristian Estan and Stefan Savage. Automated
worm ﬁngerprinting. In Proceedings of 6th Symposium on Operating System Design
and Implmentation (OSDI), 2004.
35. Michael Vrable, Justin Ma, Jay Chen, David Moore, Erik Vandekieft, Alex C. Sno-
eren, Geoﬀrey M. Voelker, and Stefan Savage. Scalability, Fidelity and Contain-
ment in the Potemkin Virtual Honeyfarm. Proceedings of ACM SIGOPS Operating
System Review, 39(5):148–162, 2005.
36. Vinod Yegneswaran, Paul Barford, and Somesh Jha. Global intrusion detection in
the domino overlay system. In Proceedings of the ISOC Network and Distributed
Systems Security Symposium (NDSS), 2004.
37. Vinod Yegneswaran, Paul Barford, and David Plonka. On the Design and Use of
Internet Sinks for Network Abuse Monitoring. In Proceedings of the Symposium
on Recent Advances in Intrusion Detection (RAID), Sept. 2004.
38. Amgad Zeitoun and Sugih Jamin. Rapid Exploration of Internet Live Address
Space Using Optimal Discovery Path. In Proceedings of Globecomm, 2003.
Anagram: A Content Anomaly Detector Resistant to 
Mimicry Attack* 
Ke Wang, Janak J. Parekh, and  Salvatore J. Stolfo 
Computer Science Department, Columbia University 
500 West 120th Street, New York, NY, 10027 
{kewang, janak, sal}@cs.columbia.edu 
Abstract. In this paper, we present Anagram, a content anomaly detector that 
models  a mixture of high-order n-grams (n > 1) designed to detect anoma-
lous  and  “suspicious”  network  packet  payloads.  By  using  higher-order  n-
grams, Anagram can detect significant anomalous byte sequences and gener-
ate  robust  signatures  of  validated  malicious  packet  content.  The  Anagram 
content models are implemented using highly efficient Bloom filters, reduc-
ing  space  requirements  and  enabling  privacy-preserving  cross-site  correla-
tion. The sensor models the distinct content flow of a network or host using a 
semi-supervised training regimen. Previously known exploits, extracted from 
the signatures of an IDS, are likewise modeled in a Bloom filter and are used 
during training as well as detection time. We demonstrate that Anagram can 
identify  anomalous  traffic  with  high  accuracy  and  low  false  positive  rates. 
Anagram’s  high-order  n-gram  analysis  technique  is  also  resilient  against 
simple  mimicry  attacks  that  blend  exploits  with  “normal”  appearing  byte 
padding,  such  as  the  blended  polymorphic  attack  recently  demonstrated  in 
[1]. We discuss randomized n-gram models, which further raises the bar and 
makes  it  more  difficult  for  attackers  to  build  precise  packet  structures  to 
evade  Anagram  even  if  they  know  the  distribution of  the  local  site  content 
flow. Finally, Anagram’s speed and high detection rate makes it valuable not 
only as a standalone sensor, but also as a network anomaly flow classifier in 
an  instrumented  fault-tolerant  host-based  environment;  this  enables  signifi-
cant cost amortization and the possibility of a “symbiotic” feedback loop that 
can improve accuracy and reduce false positive rates over time. 
1   Introduction 
The  current  generation  of  Network  Intrusion  Detection  Systems  (NIDS)  are  typi-
cally ill-suited for stealthy worms and targeted attacks. Misuse and anomaly detec-
tors that analyze packet headers and traffic flow statistics may be too slow to react 
to reliably detect worms that are designed to evade detection by shaping their be-
havior  to  look  like  legitimate  traffic  patterns  [2].  Furthermore,  signature  scanners 
are  vulnerable  to  zero-day  exploits  [3]  and  polymorphic  worms/stealthy  attacks 
with obfuscated exploit code [4]. Consequently, there has been an increasing focus 
*  This work has been partially supported by a grant with the Army Research Office, No. DA 
W911NF-04-1-0442. 
D. Zamboni and C. Kruegel (Eds.): RAID 2006, LNCS 4219, pp. 226 – 248, 2006. 
© Springer-Verlag Berlin Heidelberg 2006 
                                                                     Anagram: A Content Anomaly Detector         227 
on payload analysis to detect the early onset of a worm or targeted attack. Ideally, 
one would hope to detect the very first packets of an attack, rather than accumulat-
ing sufficient statistics about connection flows to detect a zero-day attack.    
A  number  of  researchers  (e.g.,  [5-8])  have  focused  on  payload-based  anomaly 
detection. Approaches that have been studied include specification-based anomaly 
detection [7] as well as techniques that aim to detect “code-like” byte sequences in 
network  payloads  [6,  9].  In  our  work,  we  have  focused  on  automated  statistical 
learning approaches to efficiently train content models on a site’s “normal” traffic 
flow  without  requiring  significant  semantic  analysis.  Ideally,  we  seek  to  design  a 
sensor that automatically learns the characteristics of “normal” attack-free data for 
any application, service, network or host. Consequently, a model learned for “nor-
mal” attack-free data may be used to identify “abnormal” or suspicious traffic that 
would be subjected to further analysis to validate whether the data embodies a new 
attack.  
 In our previous work we proposed PAYL (short for “PAYLoad anomaly detec-
tion”)  that  modeled  the  “normal”  attack-free  traffic  of  a  network  site  as  1-gram, 
byte-value frequency distributions [10], and demonstrated an ability to effectively 
detect worm behavior via ingress/egress and cross-site correlation [11]. The sensor 
was  designed  to  be  language-independent,  requiring  no  syntactic  analysis  of  the 
byte stream. Furthermore, PAYL was designed to be efficient and scalable for high-
speed networks and applicable to any network service. Various experiments dem-
onstrated that PAYL achieved a high detection rate and with low false positives for 
“typical” worms and exploits available at the time.  
However,  most  researchers1 correctly  suspected  that  PAYL’s  simplicity  would 
be easily blinded by mimicry attacks. Kolesnikov, Dagon and Lee [1] demonstrated 
a new blended, polymorphic worm designed to evade detection by PAYL and other 
frequency  distribution-based  anomaly  detectors.  This  demonstration  represents  a 
new  class  of  “smart  worms”  that  launch  their  attack  by  first  sniffing  traffic  and 
shaping the datagram to the statistics specific to a given site to appear normal. The 
same principles may be applied to the propagation strategy as well as in, for exam-
ple,  parasitic  worms.    Since  PAYL  only  models  1-gram  distributions,  it  can  be 
easily evaded with proper padding to avoid detection of anomalous byte sequences. 
As a countermeasure, we conjecture that higher-order n-gram modeling may likely 
detect these anomalous byte sequences. Unfortunately, computing a full frequency 
distribution for higher order n-grams is computationally and memory-wise infeasi-
ble, and  would require a prohibitively long training period even  for  modest gram 
sizes.  
In  this  paper  we  present  a  new  sensor,  Anagram,  which  introduces  the  use  of 
Bloom  filters  and  a  binary-based  detection  model.  Anagram  does  not  compute 
frequency distributions of normal content flows; instead, it trains its model by stor-
ing  all  of  the  distinct  n-grams  observed  during  training  in  a  Bloom  filter  without 
counting the occurrences of these n-grams. Anagram also stores n-grams extracted 
from  known  malicious  packets  in  a  second  bad  content  Bloom  filter,  acquired  by 
extracting n-grams from openly available  worm detection rules, such as the latest 
1  Including  ourselves;  a  proposal  to  study  counter-evasion  techniques  led  to  the  work  re-
ported herein.  
228 
K. Wang, J.J. Parekh, and S.J. Stolfo 
Snort rulesets [12]. At detection time, packets are scored by the sensor on the basis 
of the number of unobserved n-grams the packet contains. The score is weighted by 
the number of malicious n-grams it contains as well. In this paper, we demonstrate 
that this  semi-supervised strategy attains remarkably  high  detection and low false 
positive rates, in some cases 100% detection with less than 0.006% false positive 
rate (per packet).  
The use of Bloom filters makes Anagram memory and computationally efficient 
and  allows  for  the  modeling  of  a  mixture  of  different  sizes  of  n-grams  extracted 
from packet payloads, i.e. an Anagram model need not contain samples of a fixed 
size  gram.  This  strategy  is  demonstrated  to  exceed  PAYL  in  both  detection  and 
false positives rates. Furthermore, Anagram’s modeling technique is easier to train, 
and allows for the estimation of when the sensor has been trained enough for de-
ployment. The Bloom filter model representation also provides the added benefit of 
preserving the privacy of shared content models and alerts for cross-site correlation.  