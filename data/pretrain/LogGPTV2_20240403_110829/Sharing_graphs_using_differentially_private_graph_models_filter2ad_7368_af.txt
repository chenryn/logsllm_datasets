### Experimental Setup and Results

In this experiment, we utilize the MontereyBay Facebook graph and the AS (Autonomous System) network topology graph. For both graphs and each of the three influence dissemination models—Linear Threshold, Independent Cascade, and Weighted Cascade—Figure 9 illustrates the expected number of influenced nodes as the number of initial seed nodes increases.

#### Observations

- **AS Graph (Figures 9(a), 9(b), 9(c))**:
  - The results show that Pygmalion with \(\epsilon = 100\) and the dK-synthetic graph without noise are nearly identical to the original AS graph under all three dissemination models.
  - As privacy protection increases (with \(\epsilon = 10\) and \(\epsilon = 5\)), the results progressively diverge from those of the original AS graph.

- **MontereyBay Graph (Figures 9(d), 9(e), 9(f))**:
  - Similar to the AS graph, Pygmalion with \(\epsilon = 100\) produces near-perfect results.
  - Higher privacy protection (\(\epsilon = 10\) and \(\epsilon = 5\)) leads to greater deviations from the original MontereyBay graph.

### Summary of Findings

We have evaluated the feasibility of using differentially private synthetic graphs in research by employing both popular graph metrics and application-level tests. Although our tests are not comprehensive, they provide valuable insights into the impact on graph structure and research outcomes when real graphs are replaced with differentially private Pygmalion graphs.

- **Impact of Privacy Protection**:
  - Our results consistently show that Pygmalion introduces limited impact due to the addition of noise for privacy guarantees.
  - Many of the largest errors can be attributed to the limitations of the dK-2 series. We anticipate that more complex dK models, such as dK-3, will be developed soon, which will reduce these errors significantly.

### Conclusion

We have addressed the challenge of developing a flexible graph privacy mechanism that preserves graph structures while providing user-specified levels of privacy guarantees. We introduce Pygmalion, a differentially-private graph model that uses the dK-series as a graph transformation function. Our analysis shows that this function has high sensitivity, requiring the addition of significant noise to ensure privacy. We confirm this on both social and Internet graphs.

To mitigate this, we develop and prove a partitioned privacy technique, where differential privacy is achieved as a whole when it is achieved in each data cluster. This reduces the level of noise necessary to attain a given level of privacy.

- **Evaluation**:
  - We evaluate our model on numerous graphs ranging from 14K to 1.7 million nodes.
  - Our partitioned privacy technique reduces the required noise by an order of magnitude.
  - For moderate to weak levels of privacy guarantees, the resulting synthetic graphs closely match the original graphs in both structure and behavior under application-level experiments.

### Future Directions

- **Improving Accuracy**:
  - One approach is to use a more descriptive, higher-order dK model, assuming its sensitivity is reasonably low.
  - Another approach is to discover a function or model of graph structure with much lower sensitivity, potentially reducing the noise required for a given privacy level by orders of magnitude.

### Acknowledgments

We thank the anonymous reviewers for their comments. This work was supported in part by the National Science Foundation under grants IIS-0916307 and IIS-847925. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the National Science Foundation. This work is also supported in part by the South Korea National Research Foundation under the World Class University program.

### References

[References listed here, following the format provided in the original text]

This optimized version aims to make the text more coherent, professional, and easier to follow.